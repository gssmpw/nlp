\section{Related Works}

\paragraph{Recommendation Setup.} Conventional sequential recommendation methods~\cite{wangsequential, kang2018self, sun2019bert4rec, hidasi2018recurrent, kim2024large} followed a one-shot prediction setup, where user history is split: the last item as the test set, the second-to-last as validation, and the rest for training. These models predict a single target item, failing to capture evolving user behavior. Tallrec~\cite{bao2023tallrec} framed the task as binary classification to predict whether an item should be recommended. 
% In contrast, we introduce a continuous sequential recommendation setup, updating predictions incrementally to better reflect real-world dynamics.

% Our setup aligns with the sequential recommendation task, which seeks to predict the user's next interaction based on their fixed past interaction history \cite{wangsequential}. Unlike conventional approaches \cite{kang2018self, sun2019bert4rec, hidasi2018recurrent} that predict only the next user-item interaction, our setup observes up to the fourth interaction initially and then predicts each subsequent interaction sequentially over time. This makes our test set evolve dynamically at each time step, reflecting the temporal and evolving nature of user behavior. 

\paragraph{LLM-based Recommendation.} 
% Conventional LLM-based recommendation models relied on fine-tuning~\cite{bao2023tallrec, kim2024large} with user-item interactions and ratings, performing well on static dataset splits. 
Tallrec~\cite{bao2023tallrec} proposed the parameter efficient finetuning (PEFT) method in recommendation system, and A-LLMRec~\cite{kim2024large} proposed  to finetune the embedding model for LLM to leverage the collaborative knowledge. 
In contrast, LLM elicited responses and extracted multiple representations from the conversation without extra training~\cite{wang2023zero}.
% In contrast, train-free models~\cite{wang2023zero} guided users through a conversational process to elicit responses and extract multiple features. 
% These features are then used to make personalized recommendations in a conversation-based recommendation framework. 
Moreover, the authors~\cite{dai2023uncovering} showed the potential of ChatGPT for reranking the candidates.
% Also, uncovering ChatGPT's capabilities of recommendation ~\cite{dai2023uncovering} shows ChatGPT is good at good at reranking the candidates and choosing user preference item while less good at rating. 
InstructRec~\cite{zhang2023recommendation} designed the instruction to recognize the users' intention and preference from context. 
% Combining user instructions and past purchase history ~\cite{zhang2023recommendation} showed significant improvement.


% These models utilized background knowledge and user reviews for personalized recommendations, but token limitations~\cite{kaplan2020scaling} restrict the amount of user data they can process.

% Recently, large language models (LLMs) have shown strong potential in recommendation tasks. Most existing models are trained and fine-tuned \cite{bao2023tallrec, kim2024large} on user-item interactions and ratings, achieving good performance on static dataset splits. However, train-free models \cite{hou2024large, wang2023zero, dai2023uncovering, zhang2023recommendation} using prompts offer greater flexibility without task-specific training. While LLMs leverage background knowledge and rich contextual information from user reviews for personalized recommendations, their token limitations \cite{kaplan2020scaling} constrain the amount of user data they can process at once.

% Traditional methods \cite{he2017neural, kang2018self, hidasi2018recurrent} primarily rely on user and item IDs as input features and apply collaborative filtering techniques \cite{koren2021advances} to learn their latent representations for sequential recommendation. Recent advances focus on training and fine-tuning \cite{hu2021lora} large language models \cite{bao2023tallrec, kim2024large} using user-item interactions and ratings. These models are trained, validated, and tested on static splits of datasets to achieve strong performance. However, generalization remains a significant challenge. Performance deteriorates in cross-domain tasks \cite{zhu2021cross}, particularly when tested on datasets with distinct user-item interactions and preferences that differ from the training data.

% \textbf{Recommendation Setup.} Our setup is similar to the sequential recommendation, which seeks to predict the user's last interaction by analyzing their past interaction history \cite{wangsequential}. However, our setup is more complex. While the conventional sequential setup predicts only the last user-item interaction, we observe up to the fourth interaction initially and then predict each subsequent interaction sequentially over time. Thus, our test set dynamically evolves with each time step, reflecting the temporal nature of user behavior. Many traditional methods \cite{he2017neural, kang2018self, hidasi2018recurrent} rely on user and item IDs as input features and apply collaborative filtering techniques \cite{koren2021advances} to learn their latent representations for sequential recommendation. Over time, recommender systems evolved to focus on training and fine-tuning \cite{hu2021lora} models \cite{bao2023tallrec, kim2024large} using user-item interactions and ratings. These models are typically trained, validated, and tested on split datasets, to achieve better performance. However, performance significantly degrades in cross-domain tasks \cite{zhu2021cross}, where models trained on one dataset are tested on different datasets, highlighting their limited generalization ability across domains.

% Traditional sequential recommendation research typically utilizes the user's interactions except for last interaction as training data to predict only the last interaction \cite{he2017neural, kang2018self, hidasi2018recurrent}, offering a simpler framework for model design and evaluation. However, this approach may not fully capture the continuous nature of user behavior observed in real-world scenarios. In contrast, recent studies have explored a continuous (or multi-step) sequential recommendation setting, where an initial set of interactions (\eg the first four) is observed and all subsequent interactions are predicted sequentially over time \cite{wangsequential}, thereby better reflecting dynamic environments and progressively capturing changes in user interests. Moreover, while early recommendation systems largely relied on collaborative filtering techniques based on user and item IDs \cite{koren2021advances}, more recent methods have shifted toward directly learning from user–item interaction data \cite{bao2023tallrec, kim2024large}, which, although enabling models to capture a broader range of user behaviors, also increases the complexity of model training and evaluation.

% \paragraph{LLM-based recommender systems.} Recently, large language models (LLMs) have been introduced to recommendation tasks, demonstrating their potential to enhance recommendation quality. Recent advances focus on training and fine-tuning \cite{hu2021lora} large language models \cite{bao2023tallrec, kim2024large} using user-item interactions and ratings. These models are trained, validated, and tested on static splits of datasets to achieve strong performance. However, generalization remains a significant challenge. Performance deteriorates in cross-domain tasks \cite{zhu2021cross}, particularly when tested on datasets with distinct user-item interactions and preferences that differ from the training data. 

% Train-free models \cite{hou2024large, wang2023zero, dai2023uncovering, zhang2023recommendation} that utilize prompts have gained attention for their flexibility and elimination of task-specific training \cite{bao2023tallrec, kim2024large}. Unlike traditional recommender systems based on user-item interaction matrices, LLMs can extract rich contextual information from textual data such as user reviews, enabling more personalized recommendations. However, token limitations \cite{kaplan2020scaling} pose a significant challenge. Our approach addresses this by introducing an efficient mechanism to manage and prioritize user information within the token budget, ensuring scalability and high performance.

% Token Limitaion 내용
% However, token limitations \cite{kaplan2020scaling} restrict the amount of data they can process. Our approach mitigates this by managing user information within the token budget, ensuring scalability and high performance.
