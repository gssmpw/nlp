\section{Guidance with Diffusion Trajectory Matching (DTM)}

We now propose a novel framework based on variational control for guidance in diffusion models. Our framework can be directly applied to pretrained diffusion models without requiring model retraining. For the remainder of our discussion, we restrict our attention to diffusion models and discuss an extension to flow-matching \cite{lipman2023flow} in Appendix \ref{subsec:flow_match}.

In the following, we first formulate guidance in discrete-time diffusion models as a variational optimal control problem (Section \ref{sec:dtm}) following \citet{Kappen_2012}, which we refer to as \emph{Diffusion Trajectory Matching} (DTM). We then present specific parameterizations of DTM in Section \ref{sec:ndtm}, which we work out as a guidance algorithm in Section \ref{sec:instantiate}. Lastly, in Appendix~\ref{subsec:cont_diff}, we transfer the DTM framework to continuous-time diffusion models \citep{songscore} and recover prior work in guidance in diffusion models.


\subsection{Variational Control for Diffusion Guidance}
\label{sec:dtm}

The idea of our guidance framework is to take a controlled deviation from the \textit{unguided diffusion trajectory} implied by \cref{eq:unguided-diffusion} in \cref{sec:background}, which we repeat for convenience:
\begin{equation}
\gQ: q(\rvx_{0:T-1}|\rvx_T) = \prod_{t} q(\rvx_{t-1}|\rvx_t).
\end{equation}
To steer the trajectory towards a target state fulfilling external constraints, we introduce a control signal $\rvu_t$ at every time $t$. This yields the following \emph{guided} dynamics for a given initial state $\rvx_T$:
\begin{equation}
\gP: p(\rvx_{0:T-1}|\rvx_T, \rvu_{1:T}) = \prod_{t} p(\rvx_{t-1}|\rvx_t, \rvu_t).
\label{eq:guided}
\end{equation}
While we model the guided dynamics as Markovian due to convenience, non-Markovian approximations are also possible~\citep{li2021detecting}. Given a set of external constraints, the task is to determine the variational control $\rvu_t$. Consequently, following \citet{Kappen_2012}, we can pose this problem as a stochastic optimal control problem with the terminal and transient costs formulated as,
\begin{align}
\gC(\rvx_T, \rvu_{1:T}) &= w_T\underbrace{\E_{\rvx_0 \sim p}[\Phi(\rvx_0)]}_{\text{Terminal Cost } \gC_\text{te}} + \underbrace{\kl{\gP}{\gQ}}_{\text{Transient Cost } \gC_\text{tr}}.
\label{eq:oc_cost}
\end{align}
The terminal cost in \cref{eq:oc_cost} encodes desirable constraints on the final guided state while the transient cost ensures that the guided trajectory does not deviate strongly from the unguided trajectory, so that the final guided state $\rvx_0$ lies near the image manifold. The two losses are traded by a scalar $w_T$.

\textbf{Choice of Terminal Cost.} 
The terminal cost in \cref{eq:oc_cost} encodes desirable constraints on the final guided state. For instance, $\Phi(\rvx_0) \propto -\log p(\vy|\rvx_0)$ could be the log-likelihood of a probabilistic classifier for class-conditional generation or the degradation process for solving inverse problems. For instance, \citet{HuangGLHZSGOY24} adapt guidance for a non-differentiable terminal cost using a path integral control \citep{Kappen_2005} formulation. While an interesting direction for further work, we only assume that the terminal cost is differentiable for now.


\textbf{Choice of Divergence.} We use the KL-Divergence as it decomposes over individual timesteps,
\begin{align}
\gC_\text{tr} 
&= \sum_t \E_{\rvx_t}[\kl{p(\rvx_{t-1}|\rvx_t, \rvu_t)}{q(\rvx_{t-1}|\rvx_t)}.
\label{eq:oc_cost_simple}
\end{align}
Note that other divergence measures can be useful depending on the specific form of the diffusion posterior \citep{nachmani2021denoisingdiffusiongammamodels, zhou2023betadiffusion, pandey2024heavytaileddiffusionmodels, holderrieth2024generatormatchinggenerativemodeling}.

\textbf{Simplifications.} The proposed loss in \cref{eq:oc_cost} is generic and principled, but is difficult to jointly optimize for all controls $\rvu_{1:T}$ due to the need to backpropagate through the entire diffusion trajectory. To avoid this computational overhead, we make several simplifications that make the objective computationally tractable. We justify the validity of the modifications through our empirical results in \cref{sec:experiments}.

First, we optimize $\rvu_t$ in a greedy manner, that is at any time $t$ in the diffusion process we optimize $\rvu_{t}$, assuming that the remaining steps $t-1, \dots, 1$ are unguided. After optimizing for $\rvu_t$, we sample from the optimized posterior $\rvx_{t-1} \sim p(\rvx_{t-1}|\rvx_t, \rvu^*_t)$ and iterate. When the variational control of $\rvu_t$ is flexible enough, suboptimal greedy choices early in the trajectory can be compensated for later.

Second, we evaluate the terminal cost at the current \emph{expected} final guided state via Tweedieâ€™s Formula for $\E[\rvx_0|\rvx_t, \rvu_t]$:
\begin{align}
\gC_\text{te} 
= \E_{\rvx_0}[\Phi(\rvx_0)] &
\approx \Phi(\E[\rvx_0|\rvx_t, \rvu_t])
= \Phi(\hat{\rvx}_0^t)
\end{align}
where we have approximated $p(\rvx_0|\rvx_t, \rvu_t) \approx \delta(\rvx_0 - \hat{\rvx}_0^t)$.

\textbf{Diffusion Trajectory Matching (DTM).} Together, the optimization problem to solve at time $t$ given a position $\rvx_t$ reads:
\begin{equation}
    \gC(\rvu_t) = w_T \Phi(\hat{\rvx}_0^t) + \kl{p(\rvx_{t-1}|\rvx_t,\rvu_t)}{q(\rvx_{t-1}|\rvx_t)}.
    \label{eq:dtm_cost_final}
\end{equation}
We refer to \cref{eq:dtm_cost_final} as \emph{Diffusion Trajectory Matching} (DTM).

\textbf{Continuous-Time Variants.} To apply DTM to continuous-time diffusion and flow matching, we adapt the transient costs $\gC_\text{tr}$. We call the following \textit{Continuous-Time Diffusion Trajectory Matching} (CT-DTM), derived for continuous-time diffusion \cite{songscore} in \cref{subsec:cont_diff}:
\begin{equation}
    \gC_\text{tr} = \frac{g(t)^2}{2} \E_{\rvx_t} \Big[\big\Vert \vs_\vtheta(\rvx_t, t) - \vs_\vtheta(\rvx_t, \rvu_t, t) \big\Vert_2^2\Big].
    \label{eq:ctdtm}
\end{equation}
Similarly, for flow matching \cite{lipman2023flow,liu2023flow,albergo2023stochastic}, we refer to this as \textit{Flow Trajectory Matching} (FTM), see \cref{subsec:flow_match}:
\begin{equation}
    \gC_\text{tr} = \|\vv_\theta(\rvx_t, t) - \vv_\theta(\rvx_t, \rvu_t, t)\|^2.
\end{equation}

Next, we present a specific parameterization of our framework and its instantiation using standard diffusion models.









\begin{algorithm}[tb]
\caption{NDTM (DDIM). Sampling proceeds by inferring the control (\textcolor{alt_algo}{shaded}) followed by sampling from the guided posterior (\textcolor{gray}{shaded}) at any time $t$}
\label{alg:ndtm_ddim}
\begin{algorithmic}[1]
\STATE {\bfseries Input:} Optimization Steps: N, Guidance: $\gamma$, Pretrained denoiser: $\epsilon_\vtheta(.,.)$, Timestep schedule: $\{t\}_{j=0}^T$, DDIM Coefficients: $\alpha_t$, $\sigma_t$, Loss Weights: $\tau_t$, $\kappa_t$, $w_T$
\STATE {\bfseries Initialization:} $\rvx_T \sim \mathcal{N}(0, \mI_d)$
\FOR{$t = T$ \textbf{to} $1$}
    \STATE $\rvu_t^{(0)} = 0$
    \STATE $\hat{\ve}_{\text{uncond}} \gets \epsilon_\theta(\rvx_t, t)$
    \begin{tcolorbox}[algostyle3]
    \FOR{$i = 0$ \textbf{to} $N-1$}
        \STATE $\hat{\ve}_{\text{control}}^{(i)} \gets \epsilon_\theta(\rvx_t + \gamma \vu_t^{(i)}, t)$
        \STATE $\hat{\rvx}_0^{(i)} \gets \E[\rvx_0 | \rvx_t + \gamma \rvu_t^{(i)}]$
        \STATE $\gC_\text{score} = \tau_t^2\left\| \hat{\ve}_{\text{uncond}} - \hat{\ve}_{\text{control}}^{(i)} \right\|_2^2$
        \STATE $\gC_\text{control} = \kappa_t^2 \Vert \rvu_t \Vert_2^2$
        \STATE $\gC_\text{terminal} = w_T\Phi(\hat{\rvx}_0^{(i)})$
        \STATE $\gC_t^{(i)} \gets \gC_\text{score} + \gC_\text{control} + \gC_\text{terminal}$
        \STATE $\vu_t^{(i+1)} \gets \texttt{Update}(\vu_t^{(i)}, \nabla_{u_t} \gC_t^{(i)}$)
    \ENDFOR
    \end{tcolorbox}
    \begin{tcolorbox}[algostyle]
        \STATE $\rvx_{t-1} \gets \text{DDIM}(\rvx_t + \gamma \rvu_t^*, t)$
    \end{tcolorbox}
\ENDFOR
\STATE return $\rvx_0$
\end{algorithmic}
\end{algorithm}

\subsection{Non-linear Diffusion Trajectory Matching (NDTM)}
\label{sec:ndtm}

In the context of Gaussian diffusion models \citep{ho2020denoising, songscore, karraselucidating}, the unguided diffusion posterior is often parameterized as,
\begin{equation}
    q(\rvx_{t-1}|\rvx_t) = \gN(\vmu_\theta(\rvx_t, t), \sigma_t^2\mI_d)
    \label{eq:unguided_param}
\end{equation}
For the guided diffusion posterior, we choose the following parameterization such that the control can affect the diffusion dynamics non-linearly.
\begin{equation}
    p(\rvx_{t-1}|\rvx_t, \rvu_t) = \gN(\vmu_\theta(\rvx_t, \rvu_t, t), \sigma_t^2\mI_d).
\end{equation}
From a practical standpoint, since unconditional score models are usually parameterized using neural networks with an input noisy state and a timestep embedding, we further parameterize the posterior mean $\vmu_\theta(\rvx_t, \rvu_t, t) = \vmu_\theta(\vf(\rvx_t, \rvu_t, t), t)$,
where the \emph{aggregation} function $\vf: \sR^d \times \sR^d \times \sR \rightarrow \sR^d$ combines the noisy state $\rvx_t$ and the control $\rvu_t$ appropriately. In this work, we choose an additive form of $\vf = \rvx_t + \gamma \rvu_t$ where $\gamma$ is the \emph{guidance weight} used to update the current noisy state $\rvx_t$ in the direction of the control signal $\rvu_t$. We leave exploring other aggregation functions as future work. Moreover, in practice, we sample from a single diffusion trajectory and therefore omit the expectation in \cref{eq:dtm_cost_final}. Consequently, the control cost in \cref{eq:dtm_cost_final} can be simplified as,
\begin{align}
    \gC(\rvu_t) = %
    \Vert \vmu_\vtheta(\rvx_t + \gamma\rvu_t, t) - \vmu_\vtheta(\rvx_t, t) \big\Vert_2^2 + w_T \Phi(\hat{\rvx}_0^t).
    \label{eq:ndtm_cost}
\end{align}
Due to the non-linear dependence of the guided posterior on the control signal $\rvu_t$, we refer to the transient cost specification in Eq. \ref{eq:ndtm_cost} as \emph{Non-Linear Diffusion Trajectory Matching} (NDTM). We will show in \cref{sec:classifier-guidance} that linear control can be formulated as a special case of this parameterization, yielding classifier guidance. Next, we instantiate the NDTM objective practically.


\subsection{Specific Instantiations}
\label{sec:instantiate}
Here, we present a simplified form of the NDTM objective in the context of DDIM \citep{song2022denoisingdiffusionimplicitmodels}.
\begin{proposition}
    \label{prop:simplified-objective}
    For the diffusion posterior parameterization in DDIM \citep{song2022denoisingdiffusionimplicitmodels}, the NDTM objective in Eq. \ref{eq:ndtm_cost} has the following tractable upper bound (see proof in Appendix \ref{subsec:ddim_proof}),
    \begin{equation}
        \gC(\rvu_t) \leq \kappa_t^2\big\Vert \rvu_t \big\Vert_2^2 + \tau_t^2 \big\Vert \epsilon_\theta(\bar{\rvx}_t, t) - \epsilon_\theta(\rvx_t, t) \big\Vert_2^2 + w_T\Phi(\hat{\rvx}_0^t),
        \label{eq:ntmc_ddim}
    \end{equation}
    where $\bar{\rvx}_t = \rvx_t + \gamma \rvu_t$ is the guided state and the coefficients $\kappa_t = \frac{\gamma \sqrt{\alpha_{t-1}}}{\sqrt{\alpha_t}}$ and $\tau_t = \sqrt{1 - \alpha_{t-1} - \sigma_t^2} - \frac{\sqrt{\alpha_{t-1}(1 - \alpha_t)}}{\sqrt{\alpha_t}}$ are time-dependent scalars.
\end{proposition}
The coefficients $\alpha_t$ and $\sigma_t$ are specific to DDIM (see \cref{subsec:ddim_proof} for more details). Intuitively, the simplified NDTM loss in \cref{eq:ntmc_ddim} measures the deviation between the guided and unguided dynamics, penalizing the magnitude of the control signal $\rvu_t$ (first term) and deviations in the noise predictions (second term). On the contrary, the terminal loss ensures that the \emph{expected} final guided state satisfies the external constraints. Therefore, the first two terms in \cref{eq:ntmc_ddim} act as regularizers on the control signal $\vu_t$.

In \cref{subsec:cont_diff}, we derive this simplification also for continuous-time diffusion models.


\textbf{Putting it all together.} To summarize, at each diffusion time step $t$, we estimate the control signal $\rvu_t$ by minimizing the cost $\gC(\rvu_t)$ (for instance \cref{eq:ntmc_ddim} for DDIM). This iterative optimization allows the model to dynamically adjust the control to best align the trajectory with the desired terminal cost while minimizing deviations with the unguided diffusion trajectory. Finally, we sample from the guided posterior $p(\rvx_{t-1}|\rvx_t, \rvu_t^*)$. We provide a visual illustration of the NDTM algorithm in Fig. \ref{fig:main_fig}a and its pseudocode implementation in Algorithm \ref{alg:ndtm_ddim}.



\subsection{Connection to Existing Guidance Mechanisms}
\label{sec:classifier-guidance}

In this section, we rigorously establish a connection between optimal control and classifier guidance: Our variational formulation in \cref{sec:dtm} captures existing approaches. We derive this result in the continuous-time variant, as this allows for a closed-form solution of the control problem.

In particular, let us choose a linear parameterization of the guided score in \cref{eq:ctdtm}, that is $s_\theta(\rvx_t, \rvu_t, t) = s_\theta(\rvx_t, t) + \rvu_t$. Then, the transient cost reduces to:
\begin{equation}
    \gC_\text{tr} = \int \|\rvu_t\|^2 dt.
\end{equation}
This is exactly the case of the well-established \textit{Path Integral Control} \cite{Kappen_2005,kappen2008stochastic}. The solution of this optimal control problem in \cref{eq:oc_cost} reads \citep[Eq.~(34)]{kappen2008stochastic}:
\begin{equation}
    \rvu_t^* = g(t) w_T \nabla_{\rvx_t} \log \E_{p(\rvx_0|\rvx_t)}[\exp(-\Phi(\rvx_0))].
\end{equation}
Notably, if the terminal cost takes the form of a classifier likelihood $\Phi(\rvx_0) \propto -\log p(\rvy|\rvx_0)$, it can be shown \cite{HuangGLHZSGOY24} that the optimal control simplifies to classifier guidance  \cite{dhariwal2021diffusion}: $ \rvu_t^* = g(t) w_T \nabla_{\rvx_t} p(\rvy|\rvx_t) $. 

This puts a large class of methods approximating the expectation over the posterior $p(\rvx_0|\rvx_t)$ \citep{chung2022diffusion, song2022pseudoinverse, pandey2024fast, HuangGLHZSGOY24} into perspective: In terms of our DTM framework, they perform optimal control with a linear control mechanism. Empirically, we will see in \cref{sec:experiments} that our generalization to non-linear control provides significant performance improvements.














