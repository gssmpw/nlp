\section{Related work}
In recent years, various client selection strategies have been proposed to optimize the FL process.
For example,
\texttt{Newt} \cite{zhao2022participant} combined local dataset size with the discrepancy between global and local models to assess client utility, selecting those with higher utility values.
In contrast, \texttt{POWER-OF-CHOICE} \cite{cho2022towards} prioritized clients with higher local loss values.
Additionally, \texttt{GS} \cite{ma2021client} utilized privacy-insensitive local label distribution to ensure that the aggregated label distribution from selected clients aligned with the global label distribution.
Furthermore, \texttt{FedCor} \cite{tang2022fedcor} leveraged client correlations to mitigate the effects of non-i.i.d. and unbalanced data in FL.
However, these approaches assumed ideal, lossless communication conditions between the server and clients,
limiting their practical implementation in commercial networks, particularly in resource-constrained wireless edge environments \cite{xu2025distributed, liu2024survey}.

Recently, some studies have incorporated wireless communication conditions into client selection for FL.
These works typically assumed reliable downlink communication, with the server possessing sufficient power and bandwidth to broadcast the global model to clients, and primarily focused on optimizing uplink resource allocation.
For instance,
\texttt{CACS} \cite{qiao2020content} integrated channel capacity and local model updates into the client selection process, while \cite{luo2024adaptive} jointly optimized client selection probabilities and allocated bandwidth to address data heterogeneity and minimize FL convergence time.
Additionally, \cite{wu2024client} considered both transmission and energy consumption in a non-orthogonal multiple access (NOMA) system, optimizing client selection and resource allocation to minimize the overall time and energy cost of FL.
However, these studies still assumed reliable wireless conditions with lossless transmissions, which do not reflect the realities of practical implementations.
As illustrated in Fig. \ref{fig:FL wireless networks}, communication in real wireless networks between the server and clients is often unreliable, with frequent transmission failures caused by unstable channels or device-related issues.
These failures can intermittently disrupt the transfer of model parameters, leading to biased FL convergence \cite{salehi2021federated,wang2021robust}.

\begin{figure}[t]
\centering
\includegraphics[width= 3.5 in ]{1.pdf}
\caption{FL in unreliable wireless networks with transmission failures.}
\label{fig:FL wireless networks}
\end{figure}


To mitigate the negative impacts of transmission failures on FL, some studies have focused on optimizing wireless resource allocation.
For instance,
\cite{chen2021joint} optimized uplink bandwidth and transmit power allocation for selected clients in frequency division multiple access (FDMA) systems, while \texttt{FedToe} \cite{wang2022quantized} adaptively adjusted uplink bandwidth, transmit power, and quantization bit allocation among clients.
Additionally, \cite{mahmoud2023federated} proposed an energy-efficient FL scheme by jointly optimizing uplink transmit power, bandwidth, and communication latency.
Some studies have extended this by jointly optimizing client selection and uplink resource allocation to alleviate the effects of unreliable networks.
For example,
\cite{zheng2023federated} optimized both client selection and uplink transmit power,
while \cite{chen2024robust} jointly optimized client selection, bandwidth allocation, and uplink transmit power.
Although these approaches offer significant improvements, they require centralized configuration of uplink communication resources across all mobile clients, which may pose deployment challenges in current commercial networks.
As shown in Fig. \ref{fig:FL wireless networks}, different mobile clients may connect to the server through diverse network standards, and devices may have user- or manufacturer-customized configurations, limiting the server's ability to modify them.
Different from above, \cite{salehi2021federated} optimized client selection and introduced a global aggregation scheme based on transmission failure probabilities to address both data heterogeneity and transmission failures.
However, this approach suffers from instability in high transmission failure conditions, as the transmission failure probability is incorporated into the denominator of the aggregation scheme.