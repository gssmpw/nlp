\section{Introduction}


%Text-to-SQL generation, the process of translating natural language questions into SQL queries, plays a crucial role in enabling intuitive database interactions. 
Text-to-SQL generation converts questions into SQL queries that help users access information in databases. 
Traditional approaches on Text-to-SQL, such as, rule-based systems and early machine learning models, relied on hand-crafted rules or simple pattern matching to generate SQL queries. They often struggle with the ambiguity and context-dependence of natural language, making it challenging to accurately translate user intent into structured SQL commands~\cite{SQLsurvey,rulebased_limitation,Rule_based_constructing}. As the field progressed, more sophisticated approaches emerged, including skeleton-masked selection~\cite{dail_sql}, relying on retrieving similar examples from training data to guide query generation. 
%Traditional methods, such as skeleton-masked selection~\cite{dail_sql}, rely heavily on retrieving similar examples from training data to guide query generation. 
\begin{figure}[t]
% \centerline{\includegraphics[scale=0.13]{Pictures/Fig2.png}}
\centerline{\includegraphics[scale=0.26]{Figures/Fig1.pdf}}
%\caption{Our proposed SAFE-SQL example generation flowchart.}
\caption{The left example illustrates a failure in retrieving similar Text-to-SQL examples from the training set. In contrast, the right example demonstrates how our proposed self-augmented approach successfully generates similar examples autonomously.}
\label{fig:first_main}
\vspace{-5mm}
\end{figure}
However, these methods face significant challenges in real-world scenarios where similar examples are often unavailable in the training set~\cite{explore_limitation,Text_to_sql_survey} or retrieve unrelated examples as shown in Figure~\ref{fig:first_main}. To overcome these problems, recent research has introduced to generate synthetic data. SQL-GEN, introduced by~\cite{Dailect_gap_synthetic} introduces dialect-specific synthetic data to resolve the diverse SQL dialect challenges in Text-to-SQL systems. Another important aspect of synthetic data generation is incorporating key relationships from the schema and employing schema-distance-weighted column sampling~\cite{Importance_of_synthesizeing}. However, these synthetic data generation methodologies predominantly require supervised fine-tuning, which demands substantial computational resources and time~\cite{synthesize}. 
Moreover, self-generated examples can introduce significant noise and inaccuracies that undermine the quality of in-context learning. Errors in synthetic SQL queries or flawed reasoning paths may lead to incorrect interpretations of database schemas~\cite{noise_text_to_sql}. As a result, relying on unfiltered self-generated examples for Text-to-SQL tasks can risk degrading overall model performance. 
%Consequently, there is a need to explore more efficient approaches that can enhance model accuracy without necessitating additional training. 
Consequently, it is necessary to develop more efficient approaches that enhance the accuracy of Text-to-SQL while eliminating extra training costs and mitigating the adverse impacts of noisy self-generated examples.

%In this paper, we propose SAL-SQL, a novel approach that leverages the generative capabilities of large language models (LLMs) to create high-quality synthetic examples. 
In this paper, we propose SAFE-SQL, a novel approach that fully exploits the generative power of large language models (LLMs) to create high-quality synthetic examples in an unsupervised manner. 
SAFE-SQL enhances its inference capabilities without additional fine-tuning through four key steps: \textbf{\textit{(1) Schema Linking}}:
%where we analyze SQL test questions, database tables, and foreign keys to establish relationships between natural language queries and database structures;
Analyzing SQL test questions, database tables, and foreign keys to map relationships between queries and database structures
\textbf{\textit{(2) Example Generation}}: 
%where we generate ten similar question-SQL-reasoning path triplets per input question using schema-linked information with LLMs; 
Generating ten similar question-SQL query-reasoning path triplets per input using schema-linked information with LLMs
\textbf{\textit{(3) Threshold-based example selection}}: 
%where we assess generated examples based on embedding similarity, keyword \& structural similarity, and reasoning path validity, retaining only those with a score of specific threshold; 
Evaluating generated examples via embedding similarity, keyword \& structural alignment, and reasoning path validity, retaining only those scoring above specific threshold
and \textbf{\textit{(4) Final SQL Inference}}: 
%where the curated examples are used to enhance query generation. 
Leveraging the curated examples, this step utilizes in-context learning to enhance the performance of large language models. This approach benefits from carefully selected examples that align with the natural language question and database schema, ensuring accurate and efficient SQL generation.

By relying on LLM-generated and filtered examples, SAFE-SQL significantly improves robustness and accuracy, particularly in complex or unseen scenarios where retrieval-based approaches struggle. Consequently, our approach eliminates the need for additional model training while achieving superior performance in Text-to-SQL tasks.
Our contributions can be listed as follows:
\begin{itemize}[leftmargin=10pt, labelindent=0pt]
    %\item \textbf{Unsupervised Schema-aware Synthetic Example Generation}: 
    %\item We introduce SAL-SQL, a fully unsupervised approach that leverages large language models (LLMs) to generate synthetic examples, eliminating the need for additional model fine-tuning and removing dependence on a predefined training set.
    \item We propose SAFE-SQL, a fully unsupervised approach that leverages LLMs to generate synthetic examples without additional fine-tuning or reliance on predefined training sets.
    %\item \textbf{Fine-grained Example Selection}: 
    %\item We propose a structured example filtering mechanism that evaluates generated question-SQL pairs based on embedding similarity, keyword \& structural alignment, and reasoning path validity, ensuring high-quality example selection.
    \item We introduce a structured filtering mechanism that selects high-quality question-SQL pairs based on embedding similarity, keyword and structural alignment, and reasoning path validation.
    %\item \textbf{Enhanced Generalization for Text-to-SQL}: 
    %\item Our approach improves SQL generation performance, particularly in complex and unseen scenarios, by dynamically adapting examples based on schema-linked information.
    \item Our method dynamically adapts examples using schema-linked information to boost SQL generation particularly in complex and unseen scenarios.
    %\item \textbf{Reduction in Computational Overhead}: 
    %\item Unlike traditional supervised fine-tuning methods, SAL-SQL achieves superior accuracy without requiring costly retraining, making it a more efficient alternative for real-world Text-to-SQL applications.
\end{itemize}

\begin{comment}
\section{Introduction}
Text-to-SQL generation converts everyday questions into SQL queries that help users access information in databases. Traditional approaches, such as skeleton-masked selection~\cite{dail_sql}, rely on retrieving similar examples from training data to guide query generation. 
%However, these methods often falter in real-world scenarios where suitable examples are scarce~\cite{explore_limitation,Text_to_sql_survey}. 
However, these methods face significant challenges in real-world scenarios where similar examples are often unavailable in the training set~\cite{explore_limitation,Text_to_sql_survey}. 
To address this, recent work has turned to synthetic data generation. For instance, SQL-Gen~\cite{Dailect_gap_synthetic} uses dialect-specific synthetic data to handle SQL dialect diversity, while other methods~\cite{Importance_of_synthesizeing} leverage schema relationships, strong typing, and schema-distance-weighted sampling. Despite their merits, these approaches generally depend on supervised fine-tuning, incurring high computational costs and extended training times~\cite{synthesize}.

In this paper, we propose SAL-SQL, a novel approach that fully exploits the generative power of large language models (LLMs) to create high-quality synthetic examples in an unsupervised manner. SAL-SQL iteratively enhances its inference capabilities without additional fine-tuning through four key steps: (1) \textbf{Schema Linking}: Analyzing SQL test questions, database tables, and foreign keys to map relationships between queries and database structures; (2) \textbf{Example Generation}: Producing ten similar question-SQL-reasoning path triplets per input using schema-linked information; (3) \textbf{Filtering}: Evaluating generated examples via embedding similarity, keyword \& structural alignment, and reasoning path validity, retaining only those scoring 8 or above on a 10-point scale; and (4) \textbf{Final SQL Inference}: Leveraging the curated examples to improve query generation.

By using LLM-generated and rigorously filtered examples, SAL-SQL achieves superior robustness and accuracy—especially in complex or unseen scenarios—without the need for costly retraining.

Our contributions can be summarized as follows:
\begin{itemize}
    \item \textbf{Unsupervised Synthetic Example Generation}: We introduce SAL-SQL, which leverages LLMs to generate schema-aware synthetic examples without additional fine-tuning.
    \item \textbf{Fine-grained Filtering Mechanism}: We develop a structured selection process that ensures only high-quality examples, evaluated through embedding, keyword, structural, and reasoning path metrics, are used.
    \item \textbf{Improved Generalization and Efficiency}: Our approach enhances SQL generation in complex and unseen scenarios while reducing computational overhead compared to traditional supervised methods.
\end{itemize}
\end{comment}