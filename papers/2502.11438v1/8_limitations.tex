\section*{Limitations}
While SAFE-SQL demonstrates strong performance in generating accurate and semantically valid SQL queries, there are a few limitations that should be addressed in future work. Although the model performs well on the tested datasets, its ability to generalize to highly diverse or domain-specific SQL tasks remains to be fully evaluated. The current framework also relies on large language models like GPT-4o, which may not be easily scalable to low-resource settings or environments with limited computational resources.  Handling edge cases and extremely complex queries, which might require deeper schema understanding and more sophisticated reasoning, is another challenge for the model. 

\section*{Ethics Statement}
This research introduces SAFE-SQL, a self-augmented in-context learning framework for Text-to-SQL tasks. While our approach enhances SQL generation without additional fine-tuning, it relies on LLMs, which may inherit biases from training data. We mitigate potential biases and inaccuracies through structured filtering and relevance scoring. Our study uses publicly available datasets, ensuring compliance with data privacy standards. We encourage responsible use of our method, particularly in applications requiring high accuracy and fairness.


%Future work will focus on addressing these limitations by %improving the model's efficiency in resource-constrained %environments, enhancing its adaptability to various %domains, and refining its performance on more complex %queries and real-world data.
%Additionally, while the model benefits from self-augmented %examples and reasoning paths, there may still be cases %where the quality of the generated SQL queries is impacted %by the complexity or ambiguity of the input questions.