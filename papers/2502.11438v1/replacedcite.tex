\section{Related work}
%\subsection{Rule-based Systems for Text-to-SQL}
%Early approaches to Text-to-SQL relied on rule-based systems and semantic parsing frameworks, which required extensive domain expertise and manual feature engineering. Rule-based methods involved designing syntactic and semantic rules to map natural language to SQL query____, often utilizing predefined templates or handcrafted grammars. Systems focusing on translating restricted natural language inputs into SQL queries. 
%\subsection{Zero-shot inference for Text-to-SQL}


\subsection{Supervised Fine-Tuning for Text-to-SQL}
Supervised Fine-Tuning enables models to learn domain-specific nuances and schema alignments, significantly improving performance on specialized tasks____. Techniques such as schema linking____, constraint-based decoding____, and execution-guided generation____ have further enhanced the robustness of fine-tuned models in handling domain-specific challenges. Synthesizes text-to-SQL data from weak and strong LLMs____ utilizes preference learning from the weak data from small LLMs and strong data from Large LLMs. %Supervised fine-tuning in Text-to-SQL can be a time-consuming task and requires an enormous amount of computational resources.
However, supervised fine-tuning can be time-consuming and demands substantial computational resources. To remedy such issues, our approach sidesteps these heavy requirements by generating high-quality synthetic examples in a fully unsupervised manner.

\subsection{In-Context Learning for Text-to-SQL}
In-Context learning has emerged as another influential method, leveraging the ability of large language models to perform text to sql tasks by conditioning on a few examples provided in the input prompt, without requiring explicit parameter updates. 
Unlike traditional in-context learning methods that rely on a fixed set of examples, our approach dynamically generates and filters schema-aware examples to better adapt to varying query structures in real-world scenarios.
AST-SQL____ introduces using an abstract syntax tree algorithm to select similar examples and incorporate them into the in-context learning pipeline. 
% \subsubsection{Schema Linking}
% Schema Linking associates between database schema elements (e.g., tables, columns, and foreign keys) and natural language questions. This technique identifies keywords or concepts in a question and links them to specific schema components in the database, clarifying which parts of the schema the question refers to. Schema Linking plays a vital role in improving the execution accuracy of Text-to-SQL , particularly by interpreting complex references in user queries. DIN-SQL____ utilizes pre-sqls with schema linking which related tables and column which boosts the execution accuracy compared with the traditional method.  

\begin{figure*}[!ht]
% \centerline{\includegraphics[scale=0.175]{Pictures/Fig1.png}}
\centerline{\includegraphics[scale=0.25]{Figures/Fig2.pdf}}
\caption{Overall flow of our proposed SAFE-SQL.}
\vspace{-4mm}
\label{fig:main}
\end{figure*}

\paragraph{Skeleton Masked Similarity Method}
Skeleton masked similarity is an approach that emphasizes structural similarity between natural language questions and SQL queries. This method involves extracting the skeleton of a SQL query from the given question and masking unnecessary details to focus on its essential structure.
By preserving key structural patterns, such as SELECT-FROM-WHERE clauses, this approach facilitates learning the correspondence between natural language expressions and SQL query elements. 
By moving beyond simple word-level matching, it captures deeper structural correlations, which is particularly effective for complex queries or linguistically diverse questions.
%It moves beyond simple word-level matching to capture deeper structural correlations, which is particularly effective in handling complex SQL queries or questions with diverse linguistic expressions. 
%This method is not applicable without a training set.  


\paragraph{Classification and Decomposition Methods}
%The classification and decomposition method simplifies the generation of SQL queries from natural language questions by breaking down the task into sequential steps. This process begins with classifying the input question based on its structure or intent (e.g., single-table queries, multi-table joins, or nested queries). Following this, the question is decomposed into smaller subtasks, such as identifying specific clauses and resolving their individual components. PTD-SQL____ decomposes and categorizes SQL questions to enhance the LLM inference. This step-wise approach allows models to address each sub-problem independently, reducing complexity and improving overall accuracy.
%By modularizing the SQL generation process, the Classification and Decomposition Method enables better handling of complex, multi-intent queries or those involving nested and hierarchical relationships. This method also enhances robustness when dealing with ambiguous questions by isolating and resolving individual components before combining them into a cohesive SQL query. However, this method is hard to apply when the SQL question is not in the predefined categories. 
The classification and decomposition method simplifies SQL query generation by breaking down natural language questions into sequential steps. This process starts with classifying the input based on its structure or intent (e.g., single-table queries, multi-table joins, or nested queries) and then decomposes the question into smaller subtasks, such as identifying specific clauses and resolving their components. PTD-SQL____ uses this step-wise approach to enhance LLM inference, reducing complexity and improving overall accuracy by modularizing the SQL generation process. While this method effectively handles complex and multi-intent queries, it struggles with questions that do not fit predefined categories.

\paragraph{Self-Training and Correction Methods}
%MAGIC____ consists of three agents(manager, feedback, and correction agents) to iteratively self-correct the generated SQL queries. Predefined method  ____ utilizes code language models to iteratively correct erroneous SQL queries. 
Recent advancements in the Text-to-SQL domain have focused on enhancing model performance and reliability through self-training and self-correction techniques. These approaches enable models to generate data or correct errors autonomously, thereby improving data efficiency and generalization capabilities. LG AI research introduces Self-training strategy____ utilizing pseudo-labeled unanswerable questions to develop a reliable Text-to-SQL system for Electronic Health Records (EHRs). SelECT-SQL____, proposes an innovative in-context learning solution that combines chain-of-thought prompting, self-correction, and ensemble methods. MAGIC____, use multiple agents (manager, feedback, and correction agents) to iteratively refine generated SQL queries. Other approaches employ code language models to repeatedly correct errors in SQL queries____. Unlike these iterative correction techniques, our approach preemptively filters and refines self-generated examples to reduce errors before query generation, thereby avoiding the need for additional correction steps.