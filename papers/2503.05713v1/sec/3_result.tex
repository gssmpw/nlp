\section{Discussion of Results}

\subsection{Bias in Lyric Language}
\textbf{Do LLMs exhibit bias in protecting copyrighted works across languages? - Yes.}
Our results (Table \ref{tab:main_exp}) reveal significant multilingual bias in LLMs’ copyright enforcement, with certain languages receiving stronger protection than others.

From the perspective of refusal rate, which measures LLM's ability to decline user request for copyrighted material, we can observe clear inconsistencies across models.
For GPT-3.5-Turbo, the refusal rate is highest for English copyrighted lyrics, while Korean and Chinese lyrics receive significantly weaker protection.
Similarly, Llama-3-70B enforces copyright protection most strictly for French lyrics, whereas English, Chinese, and Korean lyrics are less safeguarded.
Claude-3.5-Haiku maintains a generally high refusal rate across languages, indicating more consistent enforcement. However, we identified a critical anomaly: when requesting Korean copyrighted lyrics using a Chinese prompt, the refusal rate drops drastically to 0.28, in stark contrast to its near-universal refusal rate (\textasciitilde 1) in other cases. This loophole could be exploited for copyright infringement, highlighting a potential vulnerability in the model’s moderation mechanisms.
These results suggest that LLMs do not enforce copyright protections uniformly across languages, likely due to discrepancies in training data, variations in prompt filtering mechanisms, or inconsistencies in how copyright policies are applied across linguistic contexts. 

From the perspective of volume of verbatim output, a clear bias is evident across the models that produce lyrics (which have relatively lower refusal rate). GPT-3.5-Turbo produces more copyrighted lyrics in French, while Gemini-2.0 generates more English and Chinese lyrics. In contrast, Llama-3-70B and Mixtral-8x7B predominantly output English copyrighted lyrics.
Two possible explanations account for these variations in verbatim output. First, LLMs may memorize more text in certain languages, leading to greater reproduction of copyrighted content. Second, a model may recognize copyrighted material but still output it if its compliance mechanisms fail for some languages. Given that LLMs are typically trained on massive amounts of English text, English lyrics are more likely to be memorized \cite{zhang2023don}. This is particularly evident in Mistral models, which exhibit a near-zero refusal rate, indicating minimal copyright protection measures. As a result, these models tend to produce the highest volume of English verbatim outputs, reinforcing the notion that English text is more readily memorized. However, in API-based models that might be more devoted on copyright protection mechanisms, English is not always the most frequently generated language, nor is it always the most rigorously protected. This inconsistency indicates that multilingual limitations exist in copyright enforcement techniques across proprietary LLMs.
That said, GPT-4o appears to be the most balanced in terms of copyright protection.

Interestingly, the combination of refusal rate and volume metrics provides insights into the degree of hallucination in language models. For instance, although Claude-3.5-Haiku exhibits an extremely low refusal rate when prompted in Chinese for Korean song lyrics, there is minor difference in LCS or ROUGE-L scores. This suggests that the model is fabricating content. 
To systematically analyze hallucination bias across languages, we use GPT-4o to assess the hallucination rates of some models on samples that contain output lyric. The results of GPT-3.5-Turbo, Gemini-2.0, and Llama-3-70B are shown in Table \ref{tab:Hallucination}. The observed bias can be attributed to two factors: first, LLMs are more prone to hallucinate in non-English languages \cite{qiu2023detecting}; second, copyright protection techniques exacerbate this bias. However, in the context of copyright protection, hallucinations are not necessarily harmful, as they do not infringe on copyrighted content. Further details on the hallucination evaluation can be found in Appendix \ref{appendixh}.
%citation

%TODO H_score result 表

% \centering



\begin{table}[ht]
\caption{\textbf{Hallucination Rate for Some Models with Low Refusal Rate.}}
\label{tab:Hallucination}
\resizebox{0.5\textwidth}{!}{

\begin{tabular}{ccccc} % Adjusted to five columns
\toprule
\diagbox{\textbf{Model Name}}{\textbf{Song Language}} & \textit{en} & \textit{zh} & \textit{ko} & \textit{fr} \\

% \multicolumn{1}{c}{\textbf{Model Name}} & \multicolumn{1}{c}{\textit{en}} & \multicolumn{1}{c}{\textit{zh}} & \multicolumn{1}{c}{\textit{ko}} & \multicolumn{1}{c}{\textit{fr}} \\ 
\cmidrule(r){1-5}
GPT-3.5-Turbo & \textbf{0.22} & 0.75 & 0.97 & 0.25 \\ % Added `\\` to separate rows
Gemini-2.0 & \textbf{0.23} & 0.35 & 0.86 & 0.41 \\ % Added `\\`
Llama-3-70B & \textbf{0.27} & 0.89 & 0.79 & 0.76 \\ % Added `\\`
\bottomrule
\end{tabular}}%
\end{table}




% \begin{tabular}{|c|c|c|}
% \hline
% \textbf{Model Name} & \textbf{Song Language} & \textbf{Hallucination Rate} \\
% \hline
% GPT-3.5 & en & 1 \\
% GPT-3.5 & zh & 1 \\
% GPT-3.5 & ko & 1 \\
% GPT-3.5 & fr & 1 \\
% GPT-4o & en & 1 \\
% GPT-4o & zh & 1 \\
% GPT-4o & ko & 1 \\
% GPT-4o & fr & 1 \\
% Gemini-2.0 & en & 1 \\
% Gemini-2.0 & zh & 1 \\
% Gemini-2.0 & ko & 1 \\
% Gemini-2.0 & fr & 1 \\
% \hline
% \end{tabular}




\subsection{Bias in Prompt Language}
\textbf{Is it easier to elicit copyrighted content using prompts in specific languages? - Partially yes.} 
From the perspective of refusal rate, using French as the prompt language consistently results in the highest refusal rates across all tested models. This effect is particularly pronounced in GPT-3.5-Turbo, where French prompts trigger significantly more refusals than prompts in the other three languages. This suggests that the model is more adept at recognizing potential copyright infringement when the request is made in French, possibly due to stronger copyright detection mechanisms for this language.

From the perspective of volume of verbatim output, however, the impact of prompt language is minor. LCS and ROUGE-L scores remain consistent across different prompt languages for each lyric language, indicating that while the refusal rate is influenced by prompt language, the extent of verbatim reproduction is primarily determined by the language of the copyrighted content.

\subsection{Overall Analysis}
% lyric language has more impact rather than prompt language
In general, the language of the copyrighted lyrics has a greater influence on copyright compliance than the language of the prompt. However, the prompt language still affects the refusal rate, indicating that copyright protection mechanisms at the prompt level exhibit multilingual limitations. Despite this, the volume of verbatim output appears to be less sensitive to the language of the prompt. Notably, multilingual bias in verbatim output is more pronounced in open-source models than in API-based models, likely due to the absence of robust copyright enforcement measures in the former.
This observation raises an important research question: how can we enhance copyright compliance in open-source models to match or surpass the effectiveness of API-based models while ensuring multilingual fairness? Addressing this challenge requires developing more sophisticated, language-agnostic copyright protection techniques that mitigate biases and improve adherence to copyright regulations across languages.