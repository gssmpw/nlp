\begin{algorithm}[t!]
    \caption{\textsc{Feedback-based TTT}}
    \label{alg:ttt}
    % \textbf{Output}: At most $M$ new theses $\left\{t_i\right\}_{\le M}$
    \begin{algorithmic}[1]
        \Require The question $Q$, the model $M_0$, the verifier $V$, the budget $N$, the verbal feedback $F$, the instruction $P$
        \State $n \leftarrow 1$
        \While{$n \le N$}
            \State $A_n\sim M_{n-1}\left(A\mid Q\right)$ %\Comment{Sample a new answer}
            \If{$V\left(A_n\right)$ is passed}
                \State \Return $A_n$
            \Else
                \State Compute the loss $\mathcal{L}$ using Eq.~\ref{eqn:ttt-loss} 
                \If{enable self-reflection}
                    % \LineComment{Sample a reflection}
                    \State $R_n\sim M_0\left(R\mid Q,A_n,F,P\right)$
                    \State Compute the loss $\mathcal{L}_\mathrm{aux}$ using Eq.~\ref{eqn:reflect-loss} 
                    \State $\mathcal{L} \leftarrow \mathcal{L} + \mathcal{L}_\mathrm{aux}$
                \EndIf
                \State Update $M_{n-1}$ using $\mathcal{L}$ to get $M_{n}$
            \EndIf
            \State $n \leftarrow n + 1$
        \EndWhile
        \State \Return $A_{N}$
    \end{algorithmic}
\end{algorithm}