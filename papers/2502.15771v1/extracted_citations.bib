@inproceedings{DBLP:conf/iclr/Hardt024,
  author       = {Moritz Hardt and
                  Yu Sun},
  title        = {Test-Time Training on Nearest Neighbors for Large Language Models},
  booktitle    = {The Twelfth International Conference on Learning Representations,
                  {ICLR} 2024, Vienna, Austria, May 7-11, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=CNL2bku4ra},
  timestamp    = {Wed, 07 Aug 2024 17:11:53 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/Hardt024.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/iclr/LiM17,
  author       = {Ke Li and
                  Jitendra Malik},
  title        = {Learning to Optimize},
  booktitle    = {5th International Conference on Learning Representations, {ICLR} 2017,
                  Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher    = {OpenReview.net},
  year         = {2017},
  url          = {https://openreview.net/forum?id=ry4Vrt5gl},
  timestamp    = {Wed, 25 Nov 2020 18:20:22 +0100},
  biburl       = {https://dblp.org/rec/conf/iclr/LiM17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/iclr/MitchellLBFM22,
  author       = {Eric Mitchell and
                  Charles Lin and
                  Antoine Bosselut and
                  Chelsea Finn and
                  Christopher D. Manning},
  title        = {Fast Model Editing at Scale},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
  url          = {https://openreview.net/forum?id=0DcZxeWfOPt},
  timestamp    = {Sat, 20 Aug 2022 01:15:42 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/MitchellLBFM22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/icml/BelloZVL17,
  author       = {Irwan Bello and
                  Barret Zoph and
                  Vijay Vasudevan and
                  Quoc V. Le},
  editor       = {Doina Precup and
                  Yee Whye Teh},
  title        = {Neural Optimizer Search with Reinforcement Learning},
  booktitle    = {Proceedings of the 34th International Conference on Machine Learning,
                  {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  series       = {Proceedings of Machine Learning Research},
  volume       = {70},
  pages        = {459--468},
  publisher    = {{PMLR}},
  year         = {2017},
  url          = {http://proceedings.mlr.press/v70/bello17a.html},
  timestamp    = {Wed, 29 May 2019 08:41:45 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/BelloZVL17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/icml/ChenHCDLBF17,
  author       = {Yutian Chen and
                  Matthew W. Hoffman and
                  Sergio Gomez Colmenarejo and
                  Misha Denil and
                  Timothy P. Lillicrap and
                  Matthew M. Botvinick and
                  Nando de Freitas},
  editor       = {Doina Precup and
                  Yee Whye Teh},
  title        = {Learning to Learn without Gradient Descent by Gradient Descent},
  booktitle    = {Proceedings of the 34th International Conference on Machine Learning,
                  {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  series       = {Proceedings of Machine Learning Research},
  volume       = {70},
  pages        = {748--756},
  publisher    = {{PMLR}},
  year         = {2017},
  url          = {http://proceedings.mlr.press/v70/chen17e.html},
  timestamp    = {Fri, 26 Jul 2024 07:36:52 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/ChenHCDLBF17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/icml/SunWLMEH20,
  author       = {Yu Sun and
                  Xiaolong Wang and
                  Zhuang Liu and
                  John Miller and
                  Alexei A. Efros and
                  Moritz Hardt},
  title        = {Test-Time Training with Self-Supervision for Generalization under
                  Distribution Shifts},
  booktitle    = {Proceedings of the 37th International Conference on Machine Learning,
                  {ICML} 2020, 13-18 July 2020, Virtual Event},
  series       = {Proceedings of Machine Learning Research},
  volume       = {119},
  pages        = {9229--9248},
  publisher    = {{PMLR}},
  year         = {2020},
  url          = {http://proceedings.mlr.press/v119/sun20b.html},
  timestamp    = {Fri, 02 Aug 2024 08:05:45 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/SunWLMEH20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/nips/ChenLHRW0DLHLL23,
  author       = {Xiangning Chen and
                  Chen Liang and
                  Da Huang and
                  Esteban Real and
                  Kaiyuan Wang and
                  Hieu Pham and
                  Xuanyi Dong and
                  Thang Luong and
                  Cho{-}Jui Hsieh and
                  Yifeng Lu and
                  Quoc V. Le},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {Symbolic Discovery of Optimization Algorithms},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  url          = {http://papers.nips.cc/paper\_files/paper/2023/hash/9a39b4925e35cf447ccba8757137d84f-Abstract-Conference.html},
  timestamp    = {Fri, 01 Mar 2024 16:26:20 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/ChenLHRW0DLHLL23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/nips/LiuKDBMA21,
  author       = {Yuejiang Liu and
                  Parth Kothari and
                  Bastien van Delft and
                  Baptiste Bellot{-}Gurlet and
                  Taylor Mordan and
                  Alexandre Alahi},
  editor       = {Marc'Aurelio Ranzato and
                  Alina Beygelzimer and
                  Yann N. Dauphin and
                  Percy Liang and
                  Jennifer Wortman Vaughan},
  title        = {{TTT++:} When Does Self-Supervised Test-Time Training Fail or Thrive?},
  booktitle    = {Advances in Neural Information Processing Systems 34: Annual Conference
                  on Neural Information Processing Systems 2021, NeurIPS 2021, December
                  6-14, 2021, virtual},
  pages        = {21808--21820},
  year         = {2021},
  url          = {https://proceedings.neurips.cc/paper/2021/hash/b618c3210e934362ac261db280128c22-Abstract.html},
  timestamp    = {Tue, 03 May 2022 16:20:49 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/LiuKDBMA21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/nips/Ouyang0JAWMZASR22,
  author       = {Long Ouyang and
                  Jeffrey Wu and
                  Xu Jiang and
                  Diogo Almeida and
                  Carroll L. Wainwright and
                  Pamela Mishkin and
                  Chong Zhang and
                  Sandhini Agarwal and
                  Katarina Slama and
                  Alex Ray and
                  John Schulman and
                  Jacob Hilton and
                  Fraser Kelton and
                  Luke Miller and
                  Maddie Simens and
                  Amanda Askell and
                  Peter Welinder and
                  Paul F. Christiano and
                  Jan Leike and
                  Ryan Lowe},
  editor       = {Sanmi Koyejo and
                  S. Mohamed and
                  A. Agarwal and
                  Danielle Belgrave and
                  K. Cho and
                  A. Oh},
  title        = {Training language models to follow instructions with human feedback},
  booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html},
  timestamp    = {Mon, 08 Jan 2024 16:31:36 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/Ouyang0JAWMZASR22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/nips/SchickDDRLHZCS23,
  author       = {Timo Schick and
                  Jane Dwivedi{-}Yu and
                  Roberto Dess{\`{\i}} and
                  Roberta Raileanu and
                  Maria Lomeli and
                  Eric Hambro and
                  Luke Zettlemoyer and
                  Nicola Cancedda and
                  Thomas Scialom},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {Toolformer: Language Models Can Teach Themselves to Use Tools},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  url          = {http://papers.nips.cc/paper\_files/paper/2023/hash/d842425e4bf79ba039352da0f658a906-Abstract-Conference.html},
  timestamp    = {Fri, 01 Mar 2024 16:26:21 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/SchickDDRLHZCS23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2310-13807,
  author       = {Yu Sun and
                  Xinhao Li and
                  Karan Dalal and
                  Chloe Hsu and
                  Sanmi Koyejo and
                  Carlos Guestrin and
                  Xiaolong Wang and
                  Tatsunori Hashimoto and
                  Xinlei Chen},
  title        = {Learning to (Learn at Test Time)},
  journal      = {CoRR},
  volume       = {abs/2310.13807},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.13807},
  doi          = {10.48550/ARXIV.2310.13807},
  eprinttype    = {arXiv},
  eprint       = {2310.13807},
  timestamp    = {Fri, 27 Oct 2023 12:21:19 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2310-13807.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2401-11504,
  author       = {Yan Wang and
                  D. Ma and
                  Deng Cai},
  title        = {With Greater Text Comes Greater Necessity: Inference-Time Training
                  Helps Long Text Generation},
  journal      = {CoRR},
  volume       = {abs/2401.11504},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2401.11504},
  doi          = {10.48550/ARXIV.2401.11504},
  eprinttype    = {arXiv},
  eprint       = {2401.11504},
  timestamp    = {Mon, 10 Jun 2024 14:23:30 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2401-11504.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/jmlr/ChenCCH0WY22,
  author       = {Tianlong Chen and
                  Xiaohan Chen and
                  Wuyang Chen and
                  Howard Heaton and
                  Jialin Liu and
                  Zhangyang Wang and
                  Wotao Yin},
  title        = {Learning to Optimize: {A} Primer and {A} Benchmark},
  journal      = {J. Mach. Learn. Res.},
  volume       = {23},
  pages        = {189:1--189:59},
  year         = {2022},
  url          = {https://jmlr.org/papers/v23/21-0308.html},
  timestamp    = {Wed, 11 Sep 2024 14:41:27 +0200},
  biburl       = {https://dblp.org/rec/journals/jmlr/ChenCCH0WY22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{akyürek2024surprisingeffectivenesstesttimetraining,
      title={The Surprising Effectiveness of Test-Time Training for Abstract Reasoning}, 
      author={Ekin Akyürek and Mehul Damani and Linlu Qiu and Han Guo and Yoon Kim and Jacob Andreas},
      year={2024},
      eprint={2411.07279},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2411.07279}, 
}

@misc{chollet2019measureintelligence,
      title={On the Measure of Intelligence}, 
      author={François Chollet},
      year={2019},
      eprint={1911.01547},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1911.01547}, 
}

@inproceedings{gao-etal-2023-rarr,
    title = "{RARR}: Researching and Revising What Language Models Say, Using Language Models",
    author = "Gao, Luyu  and
      Dai, Zhuyun  and
      Pasupat, Panupong  and
      Chen, Anthony  and
      Chaganty, Arun Tejasvi  and
      Fan, Yicheng  and
      Zhao, Vincent  and
      Lao, Ni  and
      Lee, Hongrae  and
      Juan, Da-Cheng  and
      Guu, Kelvin",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.910/",
    doi = "10.18653/v1/2023.acl-long.910",
    pages = "16477--16508",
    abstract = "Language models (LMs) now excel at many tasks such as question answering, reasoning, and dialog. However, they sometimes generate unsupported or misleading content. A user cannot easily determine whether their outputs are trustworthy or not, because most LMs do not have any built-in mechanism for attribution to external evidence. To enable attribution while still preserving all the powerful advantages of recent generation models, we propose RARR (Retrofit Attribution using Research and Revision), a system that 1) automatically finds attribution for the output of any text generation model, and 2) post-edits the output to fix unsupported content while preserving the original output as much as possible. When applied to the output of several state-of-the-art LMs on a diverse set of generation tasks, we find that RARR significantly improves attribution while otherwise preserving the original input to a much greater degree than previously explored edit models. Furthermore, the implementation of RARR requires only a handful of training examples, a large language model, and standard web search."
}

@inproceedings{yang-etal-2022-re3,
    title = "Re3: Generating Longer Stories With Recursive Reprompting and Revision",
    author = "Yang, Kevin  and
      Tian, Yuandong  and
      Peng, Nanyun  and
      Klein, Dan",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.296/",
    doi = "10.18653/v1/2022.emnlp-main.296",
    pages = "4393--4479",
    abstract = "We consider the problem of automatically generating longer stories of over two thousand words. Compared to prior work on shorter stories, long-range plot coherence and relevance are more central challenges here. We propose the Recursive Reprompting and Revision framework (Re3) to address these challenges by (a) prompting a general-purpose language model to construct a structured overarching plan, and (b) generating story passages by repeatedly injecting contextual information from both the plan and current story state into a language model prompt. We then revise by (c) reranking different continuations for plot coherence and premise relevance, and finally (d) editing the best continuation for factual consistency. Compared to similar-length stories generated directly from the same base model, human evaluators judged substantially more of Re3`s stories as having a coherent overarching plot (by 14{\%} absolute increase), and relevant to the given initial premise (by 20{\%})."
}

