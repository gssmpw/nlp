% \begin{figure*}[t]
% \centering
% 	\includegraphics[width=1.0\textwidth]{figures/human_demo_kinematic_retargeting.png}
% 	\caption{Human hand demo in VR and kinematic retargeting for different embodiments. The blue spheres illustrate the demo hand landmarks scaled to the specific system.} 
% 	\label{fig:kinematic_retargeting}
% 	% \vspace*{0.5cm}
% \end{figure*}
\section{Automated Data Generation}
In this section, we present our method for automatically generating large quantities of physically feasible trajectories for contact-rich manipulation tasks across a range of objects, initial conditions, and embodiments from only a handful of demonstrations.
The presented method also offers the potential to adapt legacy datasets collected using outdated configurations to new robot settings, reducing the cost of collecting large amounts of data on the new robot setups from scratch.

Our method starts out by retargeting kinematic motions from the original embodiment-flexible human demonstrations collected in VR to the specific robot embodiment in simulation, producing kinematically feasible trajectories. These trajectories are then refined and augmented through the use of local trajectory optimization to obtain dynamically feasible trajectories for a range of physical parameters. The following subsections provide a detailed breakdown of each step in the pipeline.

\subsection{Kinematic Motion Retargeting}
\label{subsec:kin_retarget}
Given a sequence of demonstrations $x^{\text{demo}}_{0:T}$ with horizon $T$, we aim to find the robot configurations $q^{\text{retarget}}_{0:T}$ that match the positioning of the demonstrator while avoiding penetration and obeying joint limits. At each time step, we solve the following nonconvex program:
\begin{subequations}\label{eq:retargeting_ik}
    \begin{align}
        {q_t^{\text{retarget}}}^\star = \argmin_{q_t^{\text{retarget}}} \quad &\sum_{i=0}^N w_i \|\psi_i(q_t^{\text{retarget}}) - \Tilde \psi_i(x^{\text{demo}}_t)\|^2 \label{eq:match_cost}\\
        \text{s.t. } \; &\phi_j(q_t^{\text{retarget}}) \ge 0, \; \forall j \label{eq:nonpenetration_constr}\\ 
        &q_{\text{min}} \le q_t^{\text{retarget}} \le q_{\text{max}},
    \end{align}
\end{subequations}
where $w_i>0$ are weight parameters, and $\psi_i$ and $\Tilde \psi_i$ represent the $i$-th mappings from the robot configuration and demonstrator state to corresponding points on the embodiments. The corresponding points of interest for each robot/demonstrator pair are manually defined. For example, on the bimanual robot arm system, $\psi_0$ is the forward kinematics from the robot joint angles to the left robot arm's end effector position, while $\Tilde \psi_0$ is a map from the hand pose to the fingertip of the left index finger. We find the resulting plans generated by trajectory optimization relatively robust to the correspondence and weight parameter selection. $\phi_j$ denotes the signed distance function between the $j$-th collision pair and \eqref{eq:nonpenetration_constr} enforces nonpenetration constraints. $q_{\text{min}}$ and $q_{\text{max}}$ are the lower and upper bounds on the joint angles. Notice that $q^{\text{retarget}}$ and $x^{\text{demo}}$ can have different dimensions as long as both $\psi_i$ and $\Tilde \psi_i$ map them to vectors in the same space (e.g., Apple Vision Pro captures 5 landmarks on the index finger while each robot arm has 7 DOF in the bimanual robot arm system). We solve \eqref{eq:retargeting_ik} using a Sequential Quadratic Programming (SQP)-style algorithm: during each iteration, the nonpenetration constraint \eqref{eq:nonpenetration_constr} is linearized and the matching objective \eqref{eq:match_cost} is quadratically approximated around the solution to the previous iteration. We warmstart the solution of the nonlinear program at time $t$ with the optimal solution from the previous timestep ${q_{t-1}^{\text{retarget}}}^\star$ to encourage faster convergence and temporal consistency.

\subsection{Demonstration-Guided Trajectory Optimization}
The kinematically consistent robot trajectories ${q_{0:T}^{\text{retarget}}}^\star$ are generally not dynamically feasible due to the embodiment gap and differences in physical parameters. However, they can provide good guidance on generating dynamically feasible trajectories with complex multi-contact interactions.
In particular, human demonstrations provide global information about when and where to make contact with the object, which model-based planning can then locally refine. We define the retargeted system state $x_t^{\text{retarget}}$ to incorporate both the object state $x_t^{\text{object}}$, which is a subset of $x_t^{\text{demo}}$, and the robot state as a function of ${q_{t}^{\text{retarget}}}^\star$. The trajectory $x_{0:T}^{\text{retarget}}$ is then locally refined by solving the following nonconvex optimization program: 
\begin{subequations}\label{eq:predictive_control}
    \begin{align}
        x_t^\star, u_t^\star = \argmin_{x_t, u_t} \quad &\|x_T - {x_T^{\text{retarget}}}\|_{Q_T}^2 \nonumber + \\
         \sum_{t=0}^{T-1} &(\|x_t - {x_t^{\text{retarget}}}\|_{Q_t}^2 + \|u_t\|_{R_t}^2) \label{eq:predictive_control_cost}\\
        \text{s.t. } \; &x_{t+1} = f(x_t, u_t) \label{eq:pc_dynamics}\\
        &\phi_j(x_t) \ge 0, \; \forall j \\ 
        &x_{\text{min}} \le x_t \le x_{\text{max}} \\
        &u_{\text{min}} \le u_t \le u_{\text{max}}.
    \end{align}
\end{subequations}
Here, $f$ is obtained by time-stepping the dynamics engine, $x_{\text{min}} / x_{\text{max}}$ ($u_{\text{min}} / u_{\text{max}}$) are the lower and upper bounds on the state (input), $Q_t, R_t$ are the cost matrices for the state and input, respectively, and $Q_T$ is the cost matrix for the terminal state. To encourage precise tracking of the object trajectory, we assign higher weights to the entries of  $Q_t$ which correspond to $x_t^{\text{object}}$. The detailed parameters can be found in Appendix \ref{sec:appendix_cem}.
% Notice that the cost \eqref{eq:predictive_control_cost} is general enough to capture the desired robot behavior for both the contact-rich trajectory segments, which require the robot to constantly switch contacts, and the collision-free segments, which move the robot to a different location for better manipulability. 

In general, model-based planners can struggle to discover high-quality long-horizon contact-rich trajectories without demonstrations. 
% On the one hand, MIP-based planners will likely suffer from scalability issues as the number of potential contact modes grows exponentially with the horizon. Luckily, human demonstrations provide good intuitions on relevant contact modes that the system will likely experience, pruning a large number of irrelevant contact modes that would have shown up in the original search space. On the other hand, 
CITO requires good initial guesses and can easily get stuck in local optima without making progress. Human demonstrations offer valuable global guidance that helps overcome these challenges, and  $x_{0:T}^{\text{retarget}}$ can naturally serve as the initial guess to CITO-based methods where local adjustments are made to obey dynamical constraints \eqref{eq:pc_dynamics}. \looseness=-1

Thanks to access to the system dynamics $f$ in simulation, we can locally perturb the physical parameters as well as robot and object states around a nominal demonstration. From the single demonstration, we can solve \eqref{eq:predictive_control} for a distribution of tasks with different dynamics $f(x_t, u_t, \theta_t)$, where $\theta_t \sim \rho$ represents all the perturbations. We assume the kinematically retargeted trajectory $x_{0:T}^{\text{retarget}}$ still provides good guidance on achieving the task in the vicinity of the nominal demonstration. This way, a large number of physically consistent trajectories with various physical properties and initial conditions can be generated from a single human demonstration. We outline our data generation pipeline in Algorithm \ref{alg:data_gen}.

\begin{algorithm}
\caption{\textbf{Automated Data Generation}}\label{alg:data_gen}
\textbf{Input:} Probability distribution $\rho$, augmentation number $N$, demo trajectory $x^{\text{demo}}_{0:T}$\;
\textbf{Output:} $N$ dynamically consistent trajectories on target embodiments $\{(x_{0:T}^\star, u_{0:T-1}^\star)\}$\;
${q_{0:T}^{\text{retarget}}}^\star \leftarrow$ Solve \eqref{eq:retargeting_ik} for $x^{\text{demo}}_{0:T}$\;
\For {$n = 1, \ldots, N$} { 
    Sample $\theta_{0:T} \sim \rho$\;
    $(x_{0:T}^\star, u_{0:T-1}^\star) \leftarrow$ Solve \eqref{eq:predictive_control} with $x_{0:T}^{\text{retarget}}, \theta_{0:T}$ and $x_{t+1} = f(x_t, u_t, \theta_t)$\;
}
% \algorithmicreturn $\; \bar{u}_{0:T-1}$
\end{algorithm}
% \russtcomment{i feel like the fundamental question -- which I would expect you to support with results -- is just how far the CITO-style contact reasoning can go given a reasonable demonstration.  how much embodiment change, initial condition variability, etc?  My mental model is that people will think RL should be better for this, and/or have learned to be skeptical of trajopt for this class of problems, and your task is to convince them that this is a sweet spot?}
