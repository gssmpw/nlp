\section{Conclusion}
In this paper, we introduce FlexVAR, a flexible visual autoregressive image generation paradigm that allows autoregressive learning without residual prediction. We design a scalable VQVAE tokenizer and FlexVAR-Transformer for this purpose. This ground-truth prediction paradigm endows the autoregressive model with great flexibility and controllability, enabling image generation at various resolution, aspect ratio, and inference step, beyond those used during training. Moreover, it can zero-shot transfer to various image-to-image generation tasks.
We hope FlexVAR will serve as a solid baseline and help ease future research of visual autoregressive modeling and related areas.

\noindent \textbf{Limitations.}
We observe that when generating images with a resolution $\geq$ 3$\times$ larger than the training image,  noticeable wavy textures appear (Fig. \ref{fig:failure}). This issue may be attributed to the homogeneous structure of the ImageNet-1K training set. We will investigate this further in future work to explore how to ensure stability in zero-shot image generation at higher resolutions.