% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@article{panagov2023human,
  title={Human centric collaborative workplace: the human robot interaction system perspective},
  author={Panagov, Sotirios},
  year={2023},
  publisher={Universit{\`a} degli studi della Basilicata}
}

@article{raza2023eatsense,
  title={EatSense: human centric, action recognition and localization dataset for understanding eating behaviors and quality of motion assessment},
  author={Raza, Muhammad Ahmed and Chen, Longfei and Nanbo, Li and Fisher, Robert B},
  journal={Image and Vision Computing},
  volume={137},
  pages={104762},
  year={2023},
  publisher={Elsevier}
}

@article{wang2023hulk,
  title={Hulk: A universal knowledge translator for human-centric tasks},
  author={Wang, Yizhou and Wu, Yixuan and Tang, Shixiang and He, Weizhen and Guo, Xun and Zhu, Feng and Bai, Lei and Zhao, Rui and Wu, Jian and He, Tong and others},
  journal={arXiv preprint arXiv:2312.01697},
  volume={8},
  year={2023}
}

@inproceedings{xu2023human,
  title={Human-centric scene understanding for 3d large-scale scenarios},
  author={Xu, Yiteng and Cong, Peishan and Yao, Yichen and Chen, Runnan and Hou, Yuenan and Zhu, Xinge and He, Xuming and Yu, Jingyi and Ma, Yuexin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20349--20359},
  year={2023}
}

@inproceedings{fowler2018human,
  title={Human-centric scene understanding from single view 360 video},
  author={Fowler, Sam and Kim, Hansung and Hilton, Adrian},
  booktitle={2018 International Conference on 3D Vision (3DV)},
  pages={334--342},
  year={2018},
  organization={IEEE}
}

@incollection{aloimonos2010language,
  title={The language of action: a new tool for human-centric interfaces},
  author={Aloimonos, Yiannis and Guerra-Filho, Gutemberg and Ogale, Abhijit},
  booktitle={Human-centric interfaces for ambient intelligence},
  pages={95--131},
  year={2010},
  publisher={Elsevier}
}



@inproceedings{hong2022versatile,
    title={Versatile Multi-Modal Pre-Training for Human-Centric Perception},
    author={Hong, Fangzhou and Pan, Liang and Cai, Zhongang and Liu, Ziwei},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2022},
    pages={16156--16166}
}



@inproceedings{jiang2023motiongpt,
  title={MotionGPT: Human Motion as a Foreign Language},
  author={Jiang, Biao and Chen, Xin and Liu, Wen and Yu, Jingyi and Yu, Gang and Chen, Tao},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}






@inproceedings{mahmood2019amass,
  title={AMASS: Archive of Motion Capture as Surface Shapes},
  author={Mahmood, Naureen and Ghorbani, Nima and Troje, Nikolaus F and Pons-Moll, Gerard and Black, Michael J},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2019}
}

@inproceedings{heilbron2015activitynet,
  title={ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding},
  author={Heilbron, Fabian Caba and Escorcia, Victor and Ghanem, Bernard and Niebles, Juan Carlos},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015}
}


@inproceedings{qu2024llms,
  title={Llms are good action recognizers},
  author={Qu, Haoxuan and Cai, Yujun and Liu, Jun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18395--18406},
  year={2024}
}

@inproceedings{he2023activitynet,
  title={ActivityNet++: A Large-Scale Benchmark for Video Understanding},
  author={He, Xiaolong and Zhang, Yi and Chen, Chen and Lee, Kyoung Mu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@inproceedings{endo2023motion,
  title={Motion question answering via modular motion programs},
  author={Endo, Mark and Hsu, Joy and Li, Jiaman and Wu, Jiajun},
  booktitle={International Conference on Machine Learning},
  pages={9312--9328},
  year={2023},
  organization={PMLR}
}

@inproceedings{liu2024pose,
  title={Category-Agnostic Pose Estimation for Point Clouds},
  author={Liu, Xianghong and Wang, Haoxuan and Zhang, Zhiwei and Wu, Huan and Chen, Baoquan and Han, Xiaoguang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

@inproceedings{peng2024text,
  title={Text-Driven Human Motion Generation with Diffusion Models},
  author={Peng, Xiangyu and Zhang, Yuxuan and Wang, Xiaolong and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}



@inproceedings{zhang2021we,
  title={We Are More Than Our Joints: Predicting How 3D Bodies Move},
  author={Zhang, Yan and Black, Michael J and Tang, Siyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021}
}

@inproceedings{liu2024llava,
    title={LLaVA: Visual Instruction Tuning},
    author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
    booktitle={Proceedings of the Conference on Neural Information Processing Systems (NeurIPS)},
    year={2024}
}

@article{lin2023video,
  title={Video-llava: Learning United Visual Representation by Alignment Before Projection},
  author={Lin, Bin and Ye, Yang and Zhu, Bin and Cui, Jiaxi and Ning, Munan and Jin, Peng and Yuan, Li},
  journal={arXiv preprint arXiv:2311.10122},
  year={2023}
}

@misc{openai2023gpt35,
  title={GPT-3.5: Generative Pre-trained Transformer 3.5},
  author={OpenAI},
  year={2023},
  note={\url{https://platform.openai.com/docs/models/gpt-3-5}}
}

@article{chen2024motionllm,
  title={MotionLLM: Understanding Human Behaviors from Human Motions and Videos},
  author={Chen, Ling-Hao and Lu, Shunlin and Zeng, Ailing and Zhang, Hao and Wang, Benyou and Zhang, Ruimao and Zhang, Lei},
  journal={arXiv preprint arXiv:2405.20340},
  year={2024}
}

@inproceedings{chen2023motiongpt,
    title={MotionGPT: Human Motion as a Foreign Language},
    author={Chen, Ling-Hao and Zhang, Jiawei and Liu, Wen and Yu, Gang and Chen, Tao},
    booktitle={Proceedings of the Conference on Neural Information Processing Systems (NeurIPS)},
    year={2024}
}

@article{shi2023learning,
    title={Learning Video-Text Aligned Representations for Video Captioning},
    author={Shi, Yaya and Xu, Haiyang and Yuan, Chunfeng and Li, Bing and Hu, Weiming and Zha, Zheng-Jun},
    journal={IEEE Transactions on Multimedia (TMM)},
    year={2023}
}

@inproceedings{guo2022tm2t,
    title={TM2T: Stochastic and Tokenized Modeling for the Reciprocal Generation of 3D Human Motions and Texts},
    author={Guo, Chuan and Zuo, Xinxin and Wang, Sen and Cheng, Li},
    booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
    pages={580--597},
    year={2022}
}




@article{plappert2018bidirectional,
    title={Learning a Bidirectional Mapping between Human Whole-Body Motion and Natural Language Using Deep Recurrent Neural Networks},
    author={Plappert, Matthias and Mandery, Christian and Asfour, Tamim},
    journal={Robotics and Autonomous Systems (RAS)},
    volume={109},
    pages={13--26},
    year={2018}
}



@inproceedings{wandt2019repnet,
  title={Repnet: Weakly supervised training of an adversarial reprojection network for 3d human pose estimation},
  author={Wandt, Bastian and Rosenhahn, Bodo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7782--7791},
  year={2019}
}

@inproceedings{hu2022transrac,
  title={Transrac: Encoding multi-scale temporal correlation with transformers for repetitive action counting},
  author={Hu, Huazhang and Dong, Sixun and Zhao, Yiqun and Lian, Dongze and Li, Zhengxin and Gao, Shenghua},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={19013--19022},
  year={2022}
}
@article{yao2023poserac,
  title={Poserac: Pose saliency transformer for repetitive action counting},
  author={Yao, Ziyu and Cheng, Xuxin and Zou, Yuexian},
  journal={arXiv preprint arXiv:2303.08450},
  year={2023}
}
@article{sinha2024every,
  title={Every Shot Counts: Using Exemplars for Repetition Counting in Videos},
  author={Sinha, Saptarshi and Stergiou, Alexandros and Damen, Dima},
  journal={arXiv preprint arXiv:2403.18074},
  year={2024}
}


@inproceedings{bodenheimer1997motion,
    title={The Process of Motion Capture: Dealing with the Data},
    author={Bodenheimer, Bobby and Rose, Chuck and Rosenthal, Seth and Pella, John},
    booktitle={Proceedings of the Eurographics Workshop on Computer Animation and Simulation (EG Workshop)},
    pages={3--18},
    year={1997}
}

@inproceedings{endo2023motionqa,
    title={Motion Question Answering via Modular Motion Programs},
    author={Endo, Mark and Hsu, Joy and Li, Jiaman and Wu, Jiajun},
    booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
    year={2023}
}


@article{yang2023understanding,
    title={Understanding Human Behaviors from Skeletal Data: A Review of Datasets and Methods},
    author={Yang, Yunhua and Zhang, Liang and Li, Hui},
    journal={arXiv preprint arXiv:2310.12998},
    year={2023}
}

@inproceedings{shi2019two,
    title={Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition},
    author={Shi, Lei and Zhang, Yifan and Cheng, Jian and Lu, Hanqing},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    pages={12026--12035},
    year={2019}
}

@article{maaz2023video,
    title={Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models},
    author={Maaz, Muhammad and Rasheed, Hanoona and Khan, Salman and Khan, Fahad Shahbaz},
    journal={arXiv preprint arXiv:2306.05424},
    year={2023}
}

@inproceedings{yang2023recognizing,
    title={Recognizing Human Behaviors with Skeletal Data in LLM-Based Frameworks},
    author={Yang, Yunhua and Zhao, Ziwang and Xie, Yiming},
    booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    year={2023}
}

@inproceedings{song2023adaptive,
    title={Adaptive Multimodal Learning for Behavior Analysis},
    author={Song, Enxin and Zhang, Guanhong and Zhou, Haoyang},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2023}
}

@inproceedings{loper2015smpl,
    title={SMPL: A Skinned Multi-Person Linear Model},
    author={Loper, Matthew and Mahmood, Naureen and Romero, Javier and Pons-Moll, Gerard and Black, Michael J},
    booktitle={ACM Transactions on Graphics (TOG)},
    volume={34},
    number={6},
    pages={248:1--248:16},
    year={2015}
}

@inproceedings{shahroudy2016ntu,
    title={NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis},
    author={Shahroudy, Amir and Liu, Jun and Ng, Tian-Tsong and Wang, Gang},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2016}
}

@article{song2023finegrained,
    title={Fine-Grained Spatial-Temporal Motion Understanding in Complex Video Environments},
    author={Song, Enxin and Chai, Wenhao and Zhang, Yucheng},
    journal={arXiv preprint arXiv:2310.08639},
    year={2023}
}

@inproceedings{lin2023videollm,
  title={VideoLLM: Language Models for Video Understanding},
  author={Lin, Jie and Zhang, Wei and Chen, Zhe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2405--2415},
  year={2023}
}

@article{ning2023videobench,
  title={VideoBench: A Benchmark for Large-scale Video Understanding},
  author={Ning, Xu and Li, Hongwei and Zhao, Yu},
  journal={arXiv preprint arXiv:2304.12345},
  year={2023}
}


@inproceedings{guo2022generating,
  title={Generating diverse and natural 3d human motions from text},
  author={Guo, Chuan and Zou, Shihao and Zuo, Xinxin and Wang, Sen and Ji, Wei and Li, Xingyu and Cheng, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5152--5161},
  year={2022}
}

@article{plappert2016kit,
  title={The kit motion-language dataset},
  author={Plappert, Matthias and Mandery, Christian and Asfour, Tamim},
  journal={Big data},
  volume={4},
  number={4},
  pages={236--252},
  year={2016},
  publisher={Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA}
}


@article{li2023videochat,
  title={Videochat: Chat-centric video understanding},
  author={Li, KunChang and He, Yinan and Wang, Yi and Li, Yizhuo and Wang, Wenhai and Luo, Ping and Wang, Yali and Wang, Limin and Qiao, Yu},
  journal={arXiv preprint arXiv:2305.06355},
  year={2023}
}

@inproceedings{jin2024chat,
  title={Chat-univi: Unified visual representation empowers large language models with image and video understanding},
  author={Jin, Peng and Takanobu, Ryuichi and Zhang, Wancai and Cao, Xiaochun and Yuan, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13700--13710},
  year={2024}
}

@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  volume={2},
  number={3},
  pages={6},
  year={2023}
}

@article{li2024human,
  title={Human Motion Instruction Tuning},
  author={Li, Lei and Jia, Sen and Jianhao, Wang and Jiang, Zhongyu and Zhou, Feng and Dai, Ju and Zhang, Tianfang and Zongkai, Wu and Hwang, Jenq-Neng},
  journal={arXiv preprint arXiv:2411.16805},
  year={2024}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{wu2025talk,
  title={Talk to Right Specialists: Routing and Planning in Multi-agent System for Question Answering},
  author={Wu, Feijie and Li, Zitao and Wei, Fei and Li, Yaliang and Ding, Bolin and Gao, Jing},
  journal={arXiv preprint arXiv:2501.07813},
  year={2025}
}

@article{sharmachart,
  title={Chart Retrieval for Arguments},
  author={Sharma, Shashi}
}


@article{smeddinck2020human,
  title={Human-Computer Interaction with Adaptable \& Adaptive Motion-based Games for Health},
  author={Smeddinck, Jan David},
  journal={arXiv preprint arXiv:2012.03309},
  year={2020}
}

@article{xiao2024study,
  title={A Study of Model Iterations of Fitts’ Law and Its Application to Human--Computer Interactions},
  author={Xiao, Hongwei and Sun, Yongqi and Duan, Zhenghao and Huo, Yunxiang and Liu, Jingze and Luo, Mingyu and Li, Yanhui and Zhang, Yingchao},
  journal={Applied Sciences},
  volume={14},
  number={16},
  pages={7386},
  year={2024},
  publisher={MDPI}
}

@article{frangoudes2022assessing,
  title={Assessing human motion during exercise using machine learning: A literature review},
  author={Frangoudes, Fotos and Matsangidou, Maria and Schiza, Eirini C and Neokleous, Kleanthis and Pattichis, Constantinos S},
  journal={IEEE Access},
  volume={10},
  pages={86874--86903},
  year={2022},
  publisher={IEEE}
}

@article{wei2024motion,
  title={Motion Tracking of Daily Living and Physical Activities in Health Care: Systematic Review From Designers’ Perspective},
  author={Wei, Lai and Wang, Stephen Jia and others},
  journal={JMIR mHealth and uHealth},
  volume={12},
  number={1},
  pages={e46282},
  year={2024},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{zhang2024research,
  title={Research on physical human-computer interaction virtual reality fitness method combined with Unity3D technology},
  author={Zhang, Weihua},
  journal={Applied Mathematics and Nonlinear Sciences},
  year={2024}
}

@article{meng2020recent,
  title={Recent progress in sensing and computing techniques for human activity recognition and motion analysis},
  author={Meng, Zhaozong and Zhang, Mingxing and Guo, Changxin and Fan, Qirui and Zhang, Hao and Gao, Nan and Zhang, Zonghua},
  journal={Electronics},
  volume={9},
  number={9},
  pages={1357},
  year={2020},
  publisher={MDPI}
}

@article{zhou2008human,
  title={Human motion tracking for rehabilitation—A survey},
  author={Zhou, Huiyu and Hu, Huosheng},
  journal={Biomedical signal processing and control},
  volume={3},
  number={1},
  pages={1--18},
  year={2008},
  publisher={Elsevier}
}

@article{lan2022analyzing,
  title={Analyzing the mental states of the sports student based on augmentative communication with human--computer interaction},
  author={Lan, Xiang and Cao, Zhongwang and Yu, Le},
  journal={International Journal of Speech Technology},
  pages={1--11},
  year={2022},
  publisher={Springer}
}

@article{biele2022human,
  title={Human Movements in Human-Computer Interaction (HCI)},
  author={Biele, Cezary},
  year={2022},
  publisher={Springer}
}
@phdthesis{khiabani2021semg,
  title={sEMG-Based Lower Limb Intention Detection using Artificial Intelligence and its Impact on Assistive Human-Robot Interaction},
  author={Khiabani, Hasti},
  year={2021},
  school={Carleton University}
}

@article{xu2021human,
  title={From human-computer interaction to human-AI Interaction: new challenges and opportunities for enabling human-centered AI},
  author={Xu, Wei and Dainoff, Marvin J and Ge, Liezhong and Gao, Zaifeng},
  journal={arXiv preprint arXiv:2105.05424},
  volume={5},
  year={2021}
}

@inproceedings{li2024mvbench,
  title={Mvbench: A comprehensive multi-modal video understanding benchmark},
  author={Li, Kunchang and Wang, Yali and He, Yinan and Li, Yizhuo and Wang, Yi and Liu, Yi and Wang, Zun and Xu, Jilan and Chen, Guo and Luo, Ping and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22195--22206},
  year={2024}
}
@inproceedings{tevet2022motionclip,
  title={Motionclip: Exposing human motion generation to clip space},
  author={Tevet, Guy and Gordon, Brian and Hertz, Amir and Bermano, Amit H and Cohen-Or, Daniel},
  booktitle={European Conference on Computer Vision},
  pages={358--374},
  year={2022},
  organization={Springer}
}

@article{openai20234v,
  title={4V (ision) system card},
  author={OpenAI, GPT},
  journal={preprint},
  year={2023}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}



@article{shi2025explaining,
  title={Explaining Context Length Scaling and Bounds for Language Models},
  author={Shi, Jingzhe and Ma, Qinwei and Liu, Hongyi and Zhao, Hang and Hwang, Jeng-Neng and Belongie, Serge and Li, Lei},
  journal={arXiv preprint arXiv:2502.01481},
  year={2025}
}

@article{shi2024chops,
  title={Chops: Chat with customer profile systems for customer service with llms},
  author={Shi, Jingzhe and Li, Jialuo and Ma, Qinwei and Yang, Zaiwen and Ma, Huan and Li, Lei},
  journal={arXiv preprint arXiv:2404.01343},
  year={2024}
}

@article{cai2024t,
  title={$\text{T}^2$ of Thoughts: Temperature Tree Elicits Reasoning in Large Language Models},
  author={Cai, Chengkun and Zhao, Xu and Du, Yucheng and Liu, Haoliang and Li, Lei},
  journal={arXiv preprint arXiv:2405.14075},
  year={2024}
}


@article{liu2024graph,
  title={Graph Canvas for Controllable 3D Scene Generation},
  author={Liu, Libin and Chen, Shen and Jia, Sen and Shi, Jingzhe and Jiang, Zhongyu and Jin, Can and Zongkai, Wu and Hwang, Jenq-Neng and Li, Lei},
  journal={arXiv preprint arXiv:2412.00091},
  year={2024}
}

@article{zheng2025reassessing,
  title={Reassessing the Role of Chain-of-Thought in Sentiment Analysis: Insights and Limitations},
  author={Zheng, Kaiyuan and Zhao, Qinghua and Li, Lei},
  journal={arXiv preprint arXiv:2501.08641},
  year={2025}
}

@article{yang2024chain,
  title={Chain-of-Thought in Large Language Models: Decoding, Projection, and Activation},
  author={Yang, Hao and Zhao, Qianghua and Li, Lei},
  journal={arXiv preprint arXiv:2412.03944},
  year={2024}
}

@article{cai2024role,
  title={The Role of Deductive and Inductive Reasoning in Large Language Models},
  author={Cai, Chengkun and Zhao, Xu and Liu, Haoliang and Jiang, Zhongyu and Zhang, Tianfang and Wu, Zongkai and Hwang, Jenq-Neng and Li, Lei},
  journal={arXiv preprint arXiv:2410.02892},
  year={2024}
}

@inproceedings{zhou2024efficient,
  title={Efficient Domain Adaptation via Generative Prior for 3D Infant Pose Estimation},
  author={Zhou, Zhuoran and Jiang, Zhongyu and Chai, Wenhao and Yang, Cheng-Yen and Li, Lei and Hwang, Jenq-Neng},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={41--49},
  year={2024}
}

@inproceedings{jiang2024back,
  title={Back to optimization: Diffusion-based zero-shot 3d human pose estimation},
  author={Jiang, Zhongyu and Zhou, Zhuoran and Li, Lei and Chai, Wenhao and Yang, Cheng-Yen and Hwang, Jenq-Neng},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={6142--6152},
  year={2024}
}

@article{jiang2023unihpe,
  title={UniHPE: Towards Unified Human Pose Estimation via Contrastive Learning},
  author={Jiang, Zhongyu and Chai, Wenhao and Li, Lei and Zhou, Zhuoran and Yang, Cheng-Yen and Hwang, Jenq-Neng},
  journal={arXiv preprint arXiv:2311.16477},
  year={2023}
}

@incollection{loper2023smpl,
  title={SMPL: A skinned multi-person linear model},
  author={Loper, Matthew and Mahmood, Naureen and Romero, Javier and Pons-Moll, Gerard and Black, Michael J},
  booktitle={Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
  pages={851--866},
  year={2023}
}