\section{Ablation Studies}
\subsection{CFG v.s. Line-by-line}
To validate the influence of the granularity of the logic unit on \tool, we replace the CFG-driven decomposition with a line-by-line approach, treating each code line in the originally generated program as an independent logic unit. 
As displayed in Figure~\ref{fig:abla:linebyline}, results show an average performance decline of 7.04\% across all benchmarks on Llama3.3, alongside a 37.7\% increase in token consumption.

\begin{figure}[htb]
    \centering
    \vspace{-0.1in}
        {\includegraphics[width=0.85\linewidth]{figures/ablation_linebyline.pdf}}
        \vspace{-0.1in}
    \caption{Ablation study of logic unit granularity: line-by-line decomposition causes 7.04\% performance decline and 37.7\% more token overhead compared to the CFG method (Llama3.3). Performance degradation reflects contextual fragmentation and error propagation in atomic units, while increased token costs are attributed to redundant context re-verification.}
    \vspace{-0.15in}
    \label{fig:abla:linebyline}
\end{figure}

The observed decline stems from three intrinsic limitations of line-by-line decomposition.
First, programs inherently consist of interdependent code blocks (e.g., loops, conditionals). Splitting them into isolated lines disrupts contextual dependencies between statements.
Second, while fine-grained units obscure the hierarchical structure of program logic, LLMs struggle to associate low-level symbol operations (e.g., variable updates) with high-level problem-solving goals (e.g., iterative summation), leading to fragmented explanations and misaligned corrections.
Third, line-by-line units amplify error accumulation. For example, a variable initialization error in line 1 may invalidate subsequent lines. However, independent unit verification delays error detection, requiring repetitive corrections across multiple units. In contrast, CFG-based grouping localizes errors within bounded logical scopes.

The surge in token usage is intuitive. Each line triggers a separate verification dialogue, multiplying interaction rounds. Moreover, the LLM repeatedly re-encounters overlapping contexts and generates similar NL descriptions across units, wasting tokens on redundant information.


\subsection{NL Steps v.s. Logic Units}
To further validate the necessity of program-guided logic units, we remove the initial program generation phase and instead treat each natural language reasoning step under the CoT prompting as an independent unit.
This ablation leads to a 5.52\% accuracy drop on mathematical tasks and 4.35\% score drop on code reasoning, as shown in Figure~\ref{fig:abla:nl}, directly attributable to exacerbated reasoning hallucinations, 
The amplified decline highlights the fundamental limitations of pure natural language reasoning units.

\begin{figure}[htb]
    \centering
    \vspace{-0.1in}
        {\includegraphics[width=0.85\linewidth]{figures/ablation_nl.pdf}}
        \vspace{-0.1in}
    \caption{Ablation on unit abstraction: 5.52\% accuracy drop (Math) and 4.35\% score decline (Code) when replacing program-guided logic units with NL steps. Performance deterioration stems from reasoning hallucinations exacerbated by NL's lack of operational specificity and weak causal dependency constraints.}
    \vspace{-0.1in}
    \label{fig:abla:nl}
\end{figure}

We find a significant number of wrong answers can be attributed to reasoning hallucinations.
% The reasoning are three-fold, corresponding to the above-mentioned three types of reasoning hallucinations.
First, NL steps like ``compute the average by dividing the sum by the count" often lack operational specificity. While the NL step appears correct, the generated code may implement flawed logic (e.g., total / len(items) without handling empty lists). 
Unlike CFG units, which enforce alignment through static code analysis, the free-form language allows the LLM to hallucinate plausible-but-incorrect implementations. 
Moreover, the ambiguity of NL enables conceptual bundling--multiple logical operations (e.g., loop initialization, iteration, termination)--may be compressed into a single step like ``iterate through the list." 
This can lead to code with missing boundary checks or redundant variables, as the LLM fails to decompose high-level descriptions into executable sub-operations.
In addition, the NL narrative poorly constrains causal dependencies. For example, a step ``update the total after checking a certain condition`` might lead to code that evaluates the condition after modifying the total. CFG-driven units prevent such misordering by structurally embedding control flows.
Appendix~\ref{app:abla:cotstep} provides a detailed case study of how reasoning hallucinations are introduced if the program-driven logic units in \tool are replaced by NL steps generated through CoT.








