In this section, we provide a review of the literature related to the OCMG problem (Sec.~\ref{sec:motion_plan_gen}-\ref{sec:3dpointclouds}) with an in-depth focus on previous works in robotic spray painting (Sec.~\ref{sec:painting}). 

\subsection{Learning-based Motion Planning and Generation}
\label{sec:motion_plan_gen}
\emph{Motion planning} involves finding low-cost, goal-conditioned trajectories in a given environment while accounting for task-specific constraints---such as enforcing kinematic or dynamic feasibility, safety, or smoothness~\cite{karur2021surveypathplanning}.
%
Conventional methods based on search or sampling over a discrete representation of the state space tend to be computationally expensive~\cite{kicki2023fasttateo,ichnowski2020deepmotionplanning}, hence unsuitable for real-world applications where planning has tight time requirements or spans high-dimensional spaces. 
%
Learning-based approaches for motion planning have been proposed to speed up planning times~\cite{surveylearningrobotmotionplanning2021} by predicting the sampling distribution for sampling-based methods~\cite{wang2020neuralrrt,cheng2020learningpathplanning}, warm-starting traditional solvers~\cite{ichnowski2020deepmotionplanning}, promoting the feasibility of planned trajectories~\cite{kicki2023fasttateo}, performing end-to-end planning~\cite{pfeiffer2017perception,bency2019neuraloraclenet}, or training Reinforcement Learning policies~\cite{tsounis2020deepgaitrl,kim2020motion} to predict short-term actions that maximize cumulative rewards.
%
Motion planning solutions yet focus on reaching a specified goal state from a predefined start location, hence they are not designed to generate complex path patterns that mimic expert behavior. 

%
\emph{Motion generation}~\cite{bekris2024motiongensurvey} encompasses a broader scope than traditional planning, as it may not involve start and goal states and often necessitates adherence to task-specific motion patterns. 
% 
Among learning-based approaches, Sasagawa et al.~\cite{sasagawa2021motionbilateral} train a recurrent neural network to tackle long-term motion generation in complex tasks such as writing letters, which requires separate sequential strokes.
Saito et al.~\cite{saito2023structured} adopt supervised deep learning to tackle long-horizon manipulation tasks 
and breaking the motion generation problem down into subgoals prediction. 
Neural networks also proved effective in generating human-like whole-body trajectories by learning from human motion capture data, in both humanoid robotics~\cite{viceconte2022adherent} and character control~\cite{zhang2018mode}.
%
%
%%%%%%%%%%
Imitation Learning~(IL)~\cite{ross2011reductionbc,behav_cloning,ho2016gail,panilautonomousdriving,Ze2024DP3diffusionpolicy} tackles motion generation assuming that a reward function is described implicitly through expert demonstrations, hence solving the task by learning from data.
%
In particular, Behavioral Cloning (BC)~\cite{ross2011reductionbc,behav_cloning} consists of supervised learning techniques that directly find a mapping from the current state to the optimal action, \eg., through regression methods.
%%%%%%%%%%
Alternatively, Inverse Reinforcement Learning (IRL)~\cite{abbeel2004apprenticeshipirl,ziebart2008maximumirl} aims at learning a representation of the underlying reward function the human experts used to generate their actions. IRL has been successfully deployed to learn parking lot navigation strategies~\cite{abbeel2008apprenticeshipirlplanning}, human-like driving behavior~\cite{wulfmeier2016watchirlpathplanning}, and long-term motion forecasting~\cite{shkurti2018modelpursuit}. 
%

Notably, BC and IRL methods typically frame motion generation as a sequential decision making problem in an unknown dynamic environment with the Markov property---a Markov Decision Process. While our work is also fully data-driven, we address the challenge of global, long-horizon motion generation with complete state information.
%
Furthermore, although adaptations of IL to multiple agents~\cite{SRINIVASAN2021598} and global trajectory learning~\cite{osa2017guiding,duan2024structured,behav_cloning} were proposed, no method can manage unstructured paths---namely, they fail to model scenarios where the number of agents/paths is unknown, and no temporal correlation exists among separate paths.
%
Finally, our work focuses on learning paths that are generalizable across complex 3D shapes directly, a setting which has been rarely addressed before in robot imitation learning~\cite{schulman2016,Ze2024DP3diffusionpolicy}.



%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Motion Prediction}
Motion prediction aims at anticipating the motion of multiple agents ahead in the future.
To solve this problem, existing methods generally employ supervised learning techniques from observed trajectories, with applications to autonomous driving~\cite{yuan2021agentformer,ngiam2022scenetr,varadarajan2022multipath++,nayakanti2023wayformer}, human motion forecasting~\cite{alahi2016social,gupta2018social,rudenko2020humanpredictionsurvey}, and socially-compliant robot navigation~\cite{kretzschmar2013featuretrajpred,kretzschmar2014learningsocialnavigation,pfeiffer2016predicting}. 
%
Pfeiffer et al.~\cite{pfeiffer2016predicting} leverage the maximum entropy principle to learn a joint probability distribution over the future trajectories of all agents in the scene from data, including the controllable robot.
Gupta et al.~\cite{gupta2018social} predict socially-plausible human motion paths using a recurrent model and generative adversarial networks.
Nayakanti et al.~\cite{nayakanti2023wayformer} adopt a family of attention-based networks for motion forecasting in autonomous driving, investigating the most effective ways to fuse scene information including agents'~history, road configuration, and traffic light state.
%

Notably, motion prediction deals with output paths that are jointly executed through decentralized agents that move simultaneously over time, from a given starting state.
In turn, numerous strategies were proposed to aggregate information across agents and across time, such as
pooling layers~\cite{alahi2016social,gupta2018social}, independent self-attention for each axis~\cite{yu2020spatiotemporal}, or joint attention mechanisms on multiple axes~\cite{yuan2021agentformer,ngiam2022scenetr,nayakanti2023wayformer}.
%
In contrast, the OCMG problem considers learning a set of disjoint paths that are uncorrelated in time---\eg., they may be executed separately at different times, in an arbitrary order, and from unknown starting states.
%
In addition, the motion prediction literature assumes a known, fixed number of agents in the scene. Recently, Gu et al.~\cite{gu2023vip3d} introduced the first end-to-end approach to couple motion prediction with object detection and tracking, effectively dealing with a varying number of agents that is automatically inferred at test time.
%%%%%%%%%%%%%%%
Yet, adapting these works to heterogeneous path lengths and long-horizon motions is an open problem---the literature focuses on fixed prediction horizons of only 3-8 seconds.
Overall, the temporal correlation of predicted paths and assumptions on fixed, short-horizon forecasting render motion prediction methods unsuitable for direct application to the OCMG setting.
%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Set Prediction}
Canonical deep learning models are not designed to directly predict sets, \ie collections of permutation-invariant elements with varying cardinality.
%
Early works addressed this issue in the context of multi-label classification~\cite{rezatofighi2017deepsetnet}, where an unknown number of labels must be associated with a given input. 
For regression tasks of set prediction (\eg, Object Detection), the difficulty is instead to avoid generating near-duplicate outputs (\ie, near-identical bounding boxes) due to an unknown number of output elements.
%
This was originally mitigated via postprocessing techniques such as non-maximal suppression~\cite{erhan2014scalable,redmon2016yolo}. 
Later, auto-regressive recurrent models were proposed for sequentially predicting output sets~\cite{vinyalsseqtoseq,stewart2016end}, but these approaches were eventually outperformed by transformer-based architectures~\cite{carion2020detr,cheng2021maskformer}.
Transformers excel in such tasks by leveraging attention mechanisms to decode output elements in parallel and capture long-range dependencies, resulting in more robust and accurate set predictions.

Regardless of the architecture, the loss function designed for set prediction must always be invariant by a permutation of the predictions, or the ground truth.
This can be achieved by \emph{matching} predictions with ground truths before the loss computation, either implicitly, leveraging on a moving window across the input image~\cite{redmon2016yolo}, or explicitly, by solving a bipartite matching problem~\cite{erhan2014scalable,stewart2016end,cheng2021maskformer}.
The latter approach has been widely adopted in Object Detection~\cite{carion2020detr} and Panoptic Segmentation~\cite{cheng2021maskformer} tasks using the Hungarian algorithm~\cite{kuhn1955hungarian}.
%%%%%%%%%%%%%%%%

\subsection{3D Deep Learning from Point Clouds}
\label{sec:3dpointclouds}
3D deep learning architectures apply predictive models to process free-form 3D data~\cite{ahmed2018survey}, typically represented as voxel grids, meshes, or point clouds.
Particularly, point cloud representations describe objects as unstructured sets of 3D points, and were successfully proposed to perform tasks such as 3D object classification~\cite{Qi_Pointnet_2017} and segmentation~\cite{Qi_Pointnet++_2017}, and shape completion~\cite{Yuan_Pcn_2018,Alliegro_Denoise_2021}.
The latter task involves reconstructing missing parts of a 3D object or scene from incomplete input data and has shown to be relevant for robotics applications \cite{completionHumanoids,3dsgrasp}.
Similarly to the OCMG framework, the input is a free-form 3D shape and the output is unstructured, \ie, the unordered set of points that fill missing input regions.
%
Inspired by these methods, our work leverages the expressive power of 3D deep learning architectures and adapts them to predict unstructured robotic paths that generalize to new object instances.
%%%%%%%%%%%%%

\begin{table*}[t]
\centering
\caption{Literature review with a selected number of exemplary works in fields of applications related to OCMG. We dissect each work to shed light on the differences and similarities with our problem setting.}
\label{tab:literature_review}
\def\arraystretch{1.25}%
\resizebox{\linewidth}{!}{
\begin{NiceTabular}{|c|c|c|c|c|c|c|c|c|c|l|}
\CodeBefore
  \rectanglecolor[gray]{0.9}{1-12}{2-0}
\Body
\hline 
%\rowcolor[HTML]{EFEFEF}
\multirow{4}{*}{Tasks} & \multirow{4}{*}{Works}  & \multirow{4}{*}{Input} & \multicolumn{4}{c}{Output} & \multirow{4}{*}{Method} & \multicolumn{3}{c|}{Pros (+) and Cons (-)}\\ %\cline{4-7} \cline{9-11}
& & & \makecell{Multiple \\ paths} & \makecell{Variable \\ num. of \\paths} & \makecell{Variable \\ path \\ lengths} & \makecell{Long \\ horizon \\ paths} & & \makecell{Fast \\ Inference \\ (+)} & \makecell{Ability to \\ Generalize \\ (+)} & \multicolumn{1}{c|}{For Painting Applications} \\ \hline

\multirow{4}{*}{Spray Painting} & 
\cite{atkar24uniform,Andulkar_Incremental_2015} & \multirow{2}{*}{\makecell[c]{3D \\ (convex only)}}&
  \cmark &
  \xmark &
  \xmark  &
  \cmark &
  %Task-specific &
  \multirow{2}{*}{\makecell[c]{Task-specific \\ Heuristics}} &
  \multirow{2}{*}{\xmark} &
  \multirow{2}{*}{\xmark} & 
  \multirow{2}{*}{\makecell[l]{(+) High paint coverage \\ (-) High design costs and manual tuning}} \\
  %(+) High paint coverage \\ 
\cline{2-2} 
\cline{4-7}

  & \cite{Sheng_Automated_2000,Biegelbauer_Inverse_2005,Chen_Automated_2008,Li_Automatic_2010} & & %(convex only) & 
  \cmark &
  \cmark &
  \cmark  &
  \cmark & %Heuristics 
  & & & %(-) High design costs and manual tuning
  \\ 
  \cline{2-11}

& \cite{Kiemel_PaintRL_2019,jonnarth2024learningcoverageicml} &
  2D &
  \xmark &
  \xmark &
  \xmark  &
  \cmark &
  \makecell{Reinforcement\\ Learning} & 
  \xmark  &
  \xmark &
  \makecell[l]{(+) Explicit paint coverage optimization\\ (-) Requires accurate simulation} \\ \hline

\makecell{Multi-Agent \\ Visual Inspection} & 
\cite{jing2020multi,multiUAV_2023} & 3D &
  \cmark &
  \xmark &
  \cmark  &
  \cmark &
\makecell{Coverage \\ Path Planning} &
  \xmark &
  \xmark & 
  \makecell[l]{(+) High inspection coverage\\ (-) Sample-specific hyperparameters\\ (-) Unable to model painting patterns}
  \\ \hline

\multirow{3}{*}{\makecell{Multi-Agent \\ Motion Prediction}} & \multirow{2}{*}{\cite{yuan2021agentformer,ngiam2022scenetr,varadarajan2022multipath++,nayakanti2023wayformer}} & \multirow{2}{*}{\makecell{2D map \\ + agent features }}  & 
\multirow{2}{*}{\cmark} &
\multirow{2}{*}{\xmark} &
\multirow{2}{*}{\xmark} &
\multirow{2}{*}{\xmark} &
\multirow{7}{*}{\makecell{Imitation and \\ Supervised Learning}} &
\multirow{7}{*}{\cmark} &
\multirow{7}{*}{\cmark} &
\multirow{7}{*}{\makecell[l]{(+) Learns painting patterns from data\\ (+) Little domain knowledge required\\ (-) Implicit paint coverage optimization}} \\ 

& & %+ agent features 
& & & & & & & & \\ \cline{2-7}

& \cite{gu2023vip3d} & 3D &
\cmark &
\cmark &
\xmark & 
\xmark &
 & &&\\ \cline{1-7}

\makecell{3D Shape\\ Completion} &
\cite{Yuan_Pcn_2018,Alliegro_Denoise_2021}
& 3D & \multicolumn{4}{c|}{$\sim$ Point-wise predictions}
&
& &&\\ \cline{1-7}

\makecell{\textbf{Object Centric} \\ \textbf{Motion Generation}} & \textbf{Ours} & 3D &
\cmark &
\cmark &
\cmark & 
\cmark
&
& &&
\\ \hline




\end{NiceTabular}%
}
\end{table*}

%%%%%%%%%%%%%



\subsection{Robotic Spray Painting}
\label{sec:painting}
Autonomous robotic spray painting is an instance of the NP-hard \emph{Coverage Path Planning} (CPP) problem with additional challenges arising from the non-linear dynamics of paint deposition and hard-to-model engineering requirements. 
Due to its complexity, the landscape of robotic spray painting is dominated by heuristic methods operating under simplifying assumptions about the output path structure (\eg, raster patterns) and object geometry (\eg, convex surfaces)~\cite{Sheng_Automated_2000,Chen_Automated_2008,Li_Automatic_2010,Andulkar_Incremental_2015,atkar24uniform,Chen_Trajectory_2020,gleeson2022generating}.
Most methods further require a 3D mesh or the full CAD model of the object, while point clouds---which are easier to obtain in real-world scenarios through laser scanning---are only considered in~\cite{Chen_Trajectory_2020}.
% 
Critically, all existing heuristics yet assume to work with objects that can be partitioned into convex or low-curvature surfaces. This renders them inapplicable for painting concave objects such as shelves and containers, where global reasoning and more complex path patterns are required. 
%
Other works rely on matching the objects with a combination of hand-designed elementary geometric components collected in a database~\cite{Biegelbauer_Inverse_2005}.
Matching components are associated with local painting strokes, which are then merged to form painting paths.
Despite its merits, this method requires costly work by experts to explicitly codify object parts and their corresponding painting procedures for each object family and is unable to generalize to arbitrary free-form objects.
%
Recently, Gleeson et al.~\cite{gleeson2022generating} proposed a trajectory optimization procedure for spray painting that targets the adaptation of an externally provided trajectory candidate, without directly handling motion generation. 

\emph{Reinforcement Learning} (RL) has alternatively been employed to train path generators by directly optimizing objectives such as paint coverage~\cite{Kiemel_PaintRL_2019} or total variation~\cite{jonnarth2024learningcoverageicml}, but these efforts have so far been confined to planar domains.
RL-based stroke sequencing has also shown success in reconstructing 2D images~\cite{Huang_Learning_2019}. Although promising, RL is yet to be demonstrated successful for long-horizon 3D object planning due to the high dimensionality of the state and action spaces. The need for an accurate simulator and low generalizability of RL agents to novel objects also stand out as major issues.

Overall, we remark that all the aforementioned works only show results on a few proprietary object instances. They do not release either the data or the method implementation to allow a fair comparison, besides lacking a discussion on the generalization to new object instances and categories.

Within the CPP literature, robotic applications for multi-agent visual inspection of 3D objects also share important similarities to the OCMG setting.
Recent works proposed optimization-based methods for planning multiple paths and demonstrated their effectiveness in multi-UAV missions on large structures~\cite{jing2020multi,multiUAV_2023}. While these methods can effectively generate long-horizon paths around both convex and concave surfaces, 
they rely on sample-specific hyperparameters, incur high computational costs, and are unable to replicate expert painting patterns.

Table \ref{tab:literature_review} provides a summary of the most relevant publications showing how existing settings and tasks in the literature relate to the OCMG problem.