\IEEEPARstart{M}{otion} generation conditioned on 3D objects is fundamental to numerous industrial robotic applications, including spray painting, welding, sanding, and cleaning.
Despite the different objectives, these tasks share key challenges arising from the complexity of free-form 3D inputs and the high-dimensional outputs required to define complete robot programs.
In particular, the offline generation of long-horizon motions demands substantial computational resources for both optimization and planning.
Additionally, encoding human expert behavior into explicit optimization objectives remains extremely challenging for such complex tasks.
%
To address these difficulties, robotics practitioners often rely on task-specific knowledge, impose strong simplifying assumptions regarding the object shapes, and develop heuristic algorithms to render each task individually more tractable.
%
However, these solutions necessitate extensive re-engineering for each new product, making the process time-consuming, costly, and unable to efficiently adapt to new scenarios. 
%
In this context, establishing a unifying paradigm to tackle these tasks is a crucial step for the community to transition from handcrafted strategies to techniques that are scalable and capable of generalization.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{02_images/intro_figure/intro_figure_v11.pdf}
    \caption{Several object-centric robotic applications may be unified under a single problem formulation, as they share common assumptions on the desired output paths---referred to as unstructured paths.}
    \vspace{-6pt}
    \label{fig:intro_figure}
\end{figure}

To this end, we formalize the \emph{Object-Centric Motion Generation} (OCMG) framework, a novel problem setting that unifies robotic tasks aiming to generate \emph{multiple}, \emph{long-horizon} paths based on \emph{static}, \emph{free-form} 3D objects.
For the sake of a general formulation, we consider output paths to be \emph{unstructured}: no predefined path order is assumed, and paths can generally vary in number and length according to the input object.
Notably, these properties are shared by a wide range of robotic applications---as illustrated in Figure~\ref{fig:intro_figure}---where negligible dynamic interactions with the 3D objects are involved
and global object geometric information is given.

Robotic spray painting is an industrially-relevant example of the OCMG problem:
multiple paths are necessary to paint a single object, and the resulting paint coverage is invariant with respect to the order of execution---\eg, separate paths can be executed in parallel across multiple robots.
Furthermore, motion generation can occur offline, and no reactive planning is needed since global information of the surface geometry is available.
Note that the pattern of the spray painting paths varies significantly with each object instance, making it difficult to codify general rules---\eg, human experts in the field rely on sophisticated, high-level reasoning and costly trial-and-error to determine robot programs based on the 3D geometry of the objects.
%
%
%
Existing research studies resort to decoupling the spray painting task in (i)~3D object partitioning into convex surfaces, and (ii)~offline trajectory optimization through either domain-specific heuristics~\cite{Sheng_Automated_2000,Chen_Automated_2008,Li_Automatic_2010,Andulkar_Incremental_2015,atkar24uniform,gleeson2022generating}, or reinforcement learning-based policies~\cite{Kiemel_PaintRL_2019}.
Yet, such approaches make simplified premises on the structure of output trajectories, require expensive optimization routines, and are heavily tailored to specific shapes and convex surfaces only.
%
These issues leave robotic spray painting solutions largely limited in flexibility and generalization capabilities, despite their relevance in product manufacturing.


Recently, interest in purely data-driven approaches has grown for extrapolating path patterns without the need to explicitly encode optimization objectives and task-specific constraints.
Assuming that expert data is available, learning-based methods pave the way for solutions that are scalable, cheap to deploy at inference time, and generalizable to unseen scenarios.
%
A number of successful applications demonstrate the potential of data-driven methods in related problems, such as motion forecasting in autonomous driving~\cite{yuan2021agentformer,ngiam2022scenetr,varadarajan2022multipath++,nayakanti2023wayformer}, multi-agent imitation learning~\cite{SRINIVASAN2021598}, or socially-compliant robot navigation~\cite{kretzschmar2013featuretrajpred,kretzschmar2014learningsocialnavigation,pfeiffer2016predicting}.
Yet, these solutions consider a short prediction horizon, assume a fixed number of paths, and do not deal with 3D input data.
%
%
Tiboni \etal~\cite{tiboni2023paintnet} recently proposed the first approach to handle unstructured paths conditioned on 3D objects, predicting disconnected path segments across the object surface rather than directly inferring long-horizon paths. 
This approach allows for accurate local predictions, but crucially lacks a way to organize predicted segments into separate paths, and finally concatenate them to generate long-horizon paths.


In this work, we propose \emph{\ours}, a novel deep learning method to address OCMG tasks directly from expert data, building on~\cite{tiboni2023paintnet}.
Our pipeline breaks down the motion generation problem into the joint prediction of (1)~path segments and (2)~path masks, in a single forward pass. Particularly, we propose learning binary masks over predicted segments to identify which path each segment belongs to.
This strategy allows the network to simultaneously make local (segment predictions) and global (mask predictions) planning decisions in one step.
In turn, our method effectively infers the required \emph{number} of paths and the \emph{length} of each path according to a given input object.


When tested in the field of robotic spray painting, \ours is capable of predicting segments and masks for 40 paths in only 100ms, spanning a total length of 70 meters and 8 minutes of execution time, and achieving near-optimal paint coverage on held-out 3D objects in simulation.
%
Moreover, we successfully execute the generated paths on a real 6-DoF specialized painting robot for previously unseen object instances, achieving qualitative results that are indistinguishable from those obtained via human-expert trajectories. 
%
%
Overall, we make significant progress in addressing the OCMG problem, and focus on spray painting as a representative application to conduct a thorough experimental evaluation.\\

Our novel contributions can be summarized as follows:
\begin{itemize}[leftmargin=*,itemsep=2pt]
    \item \textbf{Mask predictions}:
        we propose \ours, a novel deep learning method that predicts path segments along with a set of masks, identifying which segments belong to the same path.
    \item \textbf{Improved segment predictions}:
        we formalize a multi-component loss function based on the Chamfer Distance and tailored to segment prediction. We study the effect of each component with an extensive ablation analysis.
    \item \textbf{Segment concatenation}:
        a novel post-processing step is designed to filter and concatenate the segments clustered within the same mask into long-horizon paths.
    \item \textbf{Improved benchmarking}:
        we release a new public dataset extending that in~\cite{tiboni2023paintnet} by more than three times in size.
        Two novel baselines are implemented ad-hoc for comparison with methods that perform na\"ive autoregressive or one-shot predictions for object-centric motion generation. 
    \item \textbf{Real-world validation}:
        we assess the performance of \ours by executing the predicted paths on a 6-DoF spray painting robot, achieving expert-level painting quality on previously unseen object instances. 
\end{itemize}