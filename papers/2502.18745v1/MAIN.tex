\documentclass[lettersize,journal]{IEEEtran}

\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}

\usepackage[dvipsnames,table,xcdraw]{xcolor}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{comment}
\usepackage{hyperref}
\usepackage{xspace}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{graphbox}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}

\usepackage{makecell}
\usepackage{graphicx}
\usepackage{nicematrix}

\usepackage{enumitem}  % lists with noindent

\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\usepackage{dsfont} % for indicator function \mathds{1}
\usepackage{balance}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\input{symbols}

\usepackage{xspace} 
\newcommand{\ours}{MaskPlanner\xspace}

\usepackage{bbm}


\begin{document}

\title{MaskPlanner: Learning-Based Object-Centric Motion Generation from 3D Point Clouds}

\author{Gabriele Tiboni$^{1}$, Raffaello Camoriano$^{1, 2}$, Tatiana Tommasi$^{1}$% <-this % stops a space
\thanks{$^{1}$Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy {\tt\small first.last@polito.it}}%
\thanks{$^{2}$Istituto Italiano di Tecnologia, Genoa, Italy}%
}

\markboth{Under review}{}

\maketitle

\begin{abstract}
\input{01_sections/00_abstract}
\end{abstract}
\begin{IEEEkeywords}
Motion Generation, Deep Learning, 3D Learning, Imitation Learning.
\end{IEEEkeywords}


\section{Introduction}
\label{sec:introduction}
\input{01_sections/01_introduction_v5}

\section{Related Work}
\label{sec:related_work}
\input{01_sections/02_related_works_v3}

\section{Method}
\label{sec:method}
\input{01_sections/04_method_v3}

\section{The Extended PaintNet Dataset}
\label{sec:ext_paintnet_dataset}
\input{01_sections/03_paintnet_dataset_v2}

\section{Experimental Evaluation}
\label{sec:experiments}
\input{01_sections/05_experiments}

\section{Conclusions}
\label{sec:conclusions}
\input{01_sections/07_conclusions}



\section*{Acknowledgments}
The authors acknowledge the EFORT group's support, which provided domain knowledge, object meshes, expert trajectory data, and access to specialized painting robot hardware for our real-world experimental evaluation.
This study was carried out within the FAIR - Future Artificial Intelligence Research and received funding from the European Union Next-GenerationEU (PIANO NAZIONALE DI RIPRESA E RESILIENZA (PNRR) – MISSIONE 4 COMPONENTE 2, INVESTIMENTO 1.3 – D.D. 1555 11/10/2022, PE00000013). This manuscript reflects only the authors’ views and opinions, neither the European Union nor the European Commission can be considered responsible for them. 


%%% APPENDIX
{\appendices
\section{Asymmetric Point-to-Segment Curriculum}
\label{appendix:pointtosegment_ablation}

When training \ours to minimize the proposed loss $\mL_{p2s}$ (see Sec.~\ref{sec:segments_prediction}), various weighting schemes can be applied to the point-wise and segment-wise Chamfer Distance (CD) terms.
In principle, an ideal learning algorithm would drive both point-wise and segment-wise matching simultaneously.
In practice, however, gradient-based optimization can converge to substantially different local optima---\eg while the Chamfer Distance is computationally efficient, it's known to be sensitive to outliers and insensitive to local mismatches in density~\cite{densityawarecd}.
In our ablation study (see Tab.~\ref{tab:loss_ablation_v2}), we evaluate four main weighting configurations:
\noindent\begin{itemize}
    \item \textbf{\ours w/out AP2S}: a baseline with a fully segment-wise loss function that leverages no auxiliary point-wise CD terms. This weighting scheme also resembles the loss function introduced in~\cite{tiboni2023paintnet}.
    
    \item \textbf{(1)~Asymmetric}: keeps a segment-wise forward CD term, but uses a point-wise loss function for the backward CD term.

    \item \textbf{(2)~P2S curriculum}: uses a coarse-to-fine schedule to progressively assign more weight to segment-wise predictions, but does so symmetrically for both forward and backward terms.

    \item \textbf{(1)~+~(2)~\ours}: our full asymmetric point-to-segment curriculum that starts training with a higher weight on the backward point-wise term and gradually balances both point-wise and segment-wise backward terms. The forward term is fully segment-wise throughout training.
\end{itemize}

Quantitative results show that \ours converges to lower PCD scores when both asymmetric CD terms and a gradual point-to-segment curriculum are included.
In particular, we observe that including the computation of auxiliary point-wise terms only helps if used in combination with the AP2S curriculum.
A variety of additional configurations have also been tried, but led to no improvements.
Moreover, we remind that na\"ively optimizing for fully point-wise CD terms yields qualitative sparse predictions that fail in capturing detailed path structures (see Point-wise baseline in Fig.~\ref{fig:qualitatives_segments_prediction}).
%
In turn, we conclude that the AP2S curriculum is crucial to promote effective convergence while ensuring smoothness and local consistency in the final predictions.

\input{03_tables/loss_ablation_v2}

} %%% END OF APPENDIX

%%% BIBLIOGRAPHY
\bibliographystyle{IEEEtran}
\balance{}
\bibliography{bibliography}

\end{document}


