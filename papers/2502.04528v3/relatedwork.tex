\section{Related Work}
We review work in AI-generated text detection and methods to threshold probability distributions into classifier labels.

\paragraph{AI text detectors}
AI text detectors have been developed to flag AI-generated text. RADAR utilizes adversarial learning techniques \cite{hu2023radar}, GLTR employs statistical metrics, including entropy, distributions, and ranks, to discern anomalies suggestive of AI content \cite{gehrmann2019gltr}, DetectGPT examines the curvature of log probability distributions, concentrating on local likelihood curvature to detect AI-generated text \cite{mitchell2023detectgpt}, and RoBERTa-based detectors fine-tune pretrained language models to proficiently categorize text as either human-produced or AI-generated \cite{solaiman2019release}. We employed \textit{probabilistic classifiers} among them which require a threshold-based decision mechanism. Unlike direct discrimination methods, thresholding enables post-processing for the balancing of performance and fairness.


\paragraph{Fixed universal thresholds for classification:}\label{method1:static} 
The most prevalent approach for making decision thresholds in classification involves employing a fixed universal threshold of $0.5$ to map predicted probabilities to class labels \cite{freeman2008comparison}. It is commonly used in many fields like photogrammetry \cite{shao2016characterizing}, ecology \cite{manel1999comparing, hanberry2013prevalence} and computer science \cite{lu2024mlnet}. Nevertheless, as highlighted by \citet{freeman2008comparison}, the dependence on $\theta = 0.5$ as a default threshold, merely due to its general acceptance, is frequently unreliable owing to variations in data distributions. 

\paragraph{Universal thresholds with optimization:} Threshold optimization techniques have been formulated to learn optimal thresholds across entire datasets. These methods optimize metrics such as the area under the receiver operating characteristic curve (AUROC) \cite{bradley1997use} and derive optimized decision thresholds under constraints such as the false positive rate (FPR) \cite{krishna2024paraphrasing,lipton2014optimal}. These approaches find applications across disciplines, including econometrics \cite{stavnkova2023threshold}, statistics \cite{esposito2021ghost}, and machine learning \cite{openai2023classifier}. While these methods yield a globally optimized threshold tailored to the chosen model, they can fail to adapt to the characteristics of individual instances, which can compromise the robustness of detection systems, particularly in significantly divergent data distributions.


%Furthermore, one fixed threshold overlooks variations in the different text and different probability distribution from models, leading to suboptimal performance and biases. Using a fixed threshold in binary classification assumes well-calibrated probabilities, often not true in practice. In AI-generated text detection, diverse text characteristics affect output distributions. 
% Also, The precision-recall (PR) curve can be used to get an optimal threshold between precision and recall.
%For instance, in 2023, OpenAI conducted an extensive evaluation of its AI text classifiers, emphasizing ethical deployment by constraining the FPR to below 0.1 in order to reduce misclassification of human-written text as AI-generated. However, the requirement to maintain a stringent FPR had the unintended consequence of lowering overall accuracy by reducing TPR, particularly under dataset shifts and changes in probability distributions. This global-threshold approach did not adapt to characteristics of individual texts, resulting in reduced robustness of the detection system. 

\paragraph{Adaptive thresholds across groups:} Recent work has highlighted the necessity for adaptive thresholds across groups \cite{jang2022group,bakker2021beyond}. \citet{menon2018cost} propose instance-dependent thresholds for inferred probabilities, resulting in optimal classifiers under cost-sensitive fairness objectives and enhancing overall performance. Similarly, \citet{corbett2017algorithmic} demonstrate that group-specific thresholds, informed by group-level statistics, can facilitate fairness-aware classification. \citet{canetti2019soft} investigate thresholds differentiated by race and proved that adaptive thresholds reduce performance disparity. \citet{jang2022group} present threshold-adaptation methods to ensure fair classification, and \citet{bakker2021beyond} explore threshold tuning to maintain stable classification performance across subgroups. Our method, \textit{\name} is grounded in the aforementioned principles and introduce a novel approach of adaptive thresholding.

%subgrouping as opposed to depending on a single variable.
%Moreover, feature engineering is utilized to proactively extract features rather than relying on the provided feature set.

% good question -- let me keep think about this 
%  How exactly does your method build on these principles? In what way are you different from these previous works? You should try to specify this as much as you can. This is key for reviewers in understanding your position in the related work.
%  Are you directly applying the techniques from these previous paper to MGT detection? Or are you contributing something new. You should specify this here.


%