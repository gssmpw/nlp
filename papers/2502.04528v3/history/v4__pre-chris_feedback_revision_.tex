%%%%%%%% ICML 2023 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass[nohyperref]{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}
\usepackage[noend]{algorithmic}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\com}[1]{{\color{black!35}//\,#1}}

% Use the following line for the initial blind version submitted for review:
\usepackage{icml2023}

% If accepted, instead use the following line for the camera-ready submisspion:
% \usepackage[accepted]{icml2023}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{multirow}
\usepackage{float}
\newfloat{algorithm}{t}{lop}

\usepackage{xcolor}
\definecolor{machine-blue}{rgb}{0.619,0.722,0.827}
\definecolor{human-orange}{rgb}{0.929,0.765,0.584}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

\input{commands.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{hypothesis}[theorem]{Hypothesis}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}


% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{\papertitleoneline}

\begin{document}

\twocolumn[
\icmltitle{\papertitle}
%%CF.1.18: Please use title case for titles. Things like "NN" aren't good for a title either, so I assume this is a placeholder for now. But it would be good to come up with some good title ideas.
%%EM.1.19:
% Local Likelihood Curvature Improves Zero-shot Detection of Machine-Generated Text
% Zero-shot Machine-Generated Text Detection through Likelihood Curvature Estimation
% DetectGPT: Zero-shot Machine-Generated Text Detection
% DetectGPT: Zero-shot Machine-Generated Text Detection using Local Likelihood Curvature


% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2023
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Eric Mitchell}{stan}
\icmlauthor{Chelsea Finn}{stan}
\end{icmlauthorlist}

\icmlaffiliation{stan}{Stanford University}

\icmlcorrespondingauthor{Eric Mitchell}{eric.mitchell@cs.stanford.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{chatgpt, cheating, zero-shot, text}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
The remarkable fluency and factual knowledge of large language models (LLMs) heightens the need for corresponding systems to detect whether a piece of text is human or machine-written. For example, students may use LLMs to complete natural language- or code-writing assignments, leaving instructors unable to accurately assess students' abilities. In this paper, we first demonstrate that text sampled from an LLM tends to occupy negative curvature regions of the model's log probability function. Leveraging this observation, we define a new curvature-based criterion for judging if a passage is generated from a given LLM. This approach, which we call {\name}, does not require training a separate classifier or collecting a dataset of real or generated passages, using only log probabilities computed by the model of interest and random perturbations from another generic pre-trained language model. We show that {\name} is more discriminative than thresholding model log probability and other common zero-shot methods for model sample detection, improving machine-generated text detection AUROC by 0.1 even for LLMs with 20B parameters.
\end{abstract}

\section{Introduction}
Large language models (LLMs) have proven able to generate remarkably fluent responses to a wide variety of user queries. Models such as GPT-3 \citep{gpt3}, PaLM \citep{palm}, and ChatGPT \citep{chatgpt} can convincingly answer complex questions about science, mathematics, historical and current events, and social trends. However, the convincing quality of these responses is often spurious, and recent work has found that LLM-generated responses are often simply wrong \citep{lin-etal-2022-truthfulqa}. Nonetheless, the convincing nature of the generations of these models makes them attractive for replacing human labor in a variety of contexts, notably student essay writing and journalism. At least one major news source has released AI-written content with limited human review, leading to substantial factual errors in some articles \citep{cnet}. Such applications of LLMs are problematic for a variety of reasons, making fair student assessment difficult, impairing student learning, and proliferating convincing-but-inaccurate news articles. %While tighter access control may prevent some negative impact of LLMs, the commercial potential for powerful LLMs makes it likely that model providers will be encouraged to make their models \textit{more} accessible, rather than less. 
%%CF.1.18: I think that this statement is debatable, and I don't think we really need to articulate an opinion on this to tell a good story? Could more simply say that we shouldn't rely on access control as the only means, especially since these models are already widely available. Or not even mention access control, since it's pretty clearly not a satisfactory solution.
%%EM.1.24: Attempted to revise by discussing how this is difficult for humans, rather than mentioning access control.
Unfortunately, humans perform only slightly better than chance when classifying machine-generated vs human-written text \citep{gehrmann-etal-2019-gltr}, leading researchers to consider automated detection methods that may identify signals difficult for humans to recognize. Such methods might give teachers and news-readers more confidence in the human origin of the text that they consume.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/fig1_v13.pdf}
    \vspace{-6mm}
    \caption{We aim to classify whether a piece of text was generated by a particular LLM, such as GPT-3. To classify a candidate passage $x$, {\name} first generates minor \textbf{perturbations} of the passage $\tilde x_i$ using a generic pre-trained model such as T5. Then {\name} \textbf{scores} the original passage $x$ and each perturbed passage $\tilde x_i$. Finally, {\name} \textbf{compares} the log probability of the original sample with each perturbed sample. If the average log ratio is high, the sample is likely from the source model.}
    \vspace{-6mm}
    \label{fig:fig1}
\end{figure}

As in prior work, we study the {\probfull} problem as a binary classification problem \citep{Jawahar2020AutomaticDO}, aiming to classify whether a \textit{candidate passage} was generated by a particular \textit{source model}. While several works have investigated methods for training a second deep network to detect machine-generated text, such an approach has several shortcomings, including a tendency to overfit to the topics it was trained on as well as the need to train a new model for each new source model that is released. We therefore consider the \textit{zero-shot} version of {\probfull}, where we use the source model itself, without fine-tuning or adaptation of any kind, to detect its own samples. The most common method for zero-shot {\probfull} is evaluating the average per-token log probability of the generated text and thresholding \citep{release-strategies,gehrmann-etal-2019-gltr,ippolito-etal-2020-automatic}. However, this zero-th-order approach to detection ignores the local structure of the learned probability function around a candidate passage, which we find contains useful information about the source of a passage.

This paper poses a simple hypothesis: minor rewrites of \textit{model-generated} text tend to have lower log probability under the model than the original sample, while minor rewrites of \textit{human-written} text may have higher or lower log probability than the original sample. In other words, unlike human-written text, model-generated text tends to lie in areas where the log probability function has negative curvature (e.g., local maxima of the log probability). We empirically verify this hypothesis, and find that it holds true across a diverse body of LLM's (see Figure~\ref{fig:perturbation-discrepancy}), even when the minor rewrites, or \textit{perturbations}, come from alternative language models. We leverage this observation to build {\name}, a zero-shot method for automated {\probfull}. To test if a passage came from a source model $\sm$, {\name} compares the log probability of a candidate passage under $\sm$ with the average log probability of several perturbations of the passage under $\sm$ (generated with, e.g., T5; \citet{raffel2020t5}). If the perturbed passages tend to have lower average log probability than the original by some margin, the candidate passage is likely to have come from $\sm$. See Figure~\ref{fig:fig1} for an overview of the problem and {\name}. See Figs.~\ref{fig:local-structure} for an illustration of the underlying hypothesis and Fig.~\ref{fig:perturbation-discrepancy} for empirical evaluation of the hypothesis. Our experiments find that {\name} is more accurate than existing zero-shot methods for detecting machine-generated text, improving over the strongest zero-shot baseline by over 0.1 AUROC for multiple source models when detecting machine-generated news articles.

\textbf{Contributions.} Our main contributions are: (a) the identification and empirical validation of the hypothesis that the curvature of a model's log probability function tends to be significantly more negative at model samples than for human text, and (b) {\name}, a practical algorithm inspired by this hypothesis that approximates the trace of the log probability function's Hessian to detect a model's samples.

\section{Related Work}
Increasingly large LLMs \citep{gpt2,gpt3,palm,chatgpt,opt} have led to dramatically improved performance on many language-related benchmarks and the ability to generate convincing and on-topic text. The GROVER model \citep{Zellers2019DefendingAN} was the first LLM trained specifically for generating realistic-looking news articles. Human evaluators found GROVER-generated propaganda at least as trustworthy as human-written propaganda, or even slightly more trustworthy,
%%CF.1.18: I don't think you need all this detail. 
%%EM.1.24: I kind of like the context of previous works that use the LM itself to detect its own generations, but we can cut here if we're running low on space.
motivating the authors to study GROVER's ability to detect its own generations by fine-tuning a detector on top of its features; they found GROVER better able to detect GROVER-generated text than other pre-trained models. However, \citet{uchendu-etal-2020-authorship} find that the fine-tuned GROVER's ability to detect machine-generated text is in large part limited to GROVER-generated text, and its accuracy decreases significantly for generations from other models. \citet{bakhtin2019learning} also similarly find that models trained explicitly for {\probfull} tend to overfit to their training distribution.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/prop-1-v3.pdf}
    \vspace{-5mm}
    \caption{We identify and exploit the tendency of machine-generated passages $x\sim\sm(\cdot)$ \textbf{(left)} to lie negative curvature regions of the model's log probability function; nearby samples have lower log probability on average. In contrast, human-written text $x\sim p_{real}(\cdot)$ \textbf{(right)} tends not to occupy regions with clear negative log probability curvature.}
    \vspace{-4mm}
    \label{fig:local-structure}
\end{figure}

Other works have trained supervised models for {\probfull} on top of neural representations \citep{bakhtin2019learning,release-strategies,uchendu-etal-2020-authorship,ippolito-etal-2020-automatic,tweepfake}, bag-of-words features \citep{release-strategies,tweepfake}, and handcrafted statistical features \citep{gehrmann-etal-2019-gltr}. Alternatively, \citet{release-strategies} notes the surprising efficacy of a simple zero-shot method for {\probfull}, which thresholds a candidate passage based on its average log probability under the generative model, serving as a strong baseline for zero-shot {\probfull} in our work. In our work, we similarly use the generating model to detect its own generations in a zero shot manner, but through a different approach based on estimating local curvature of the log probability around the sample rather than the raw log probability of the sample itself. See \citet{Jawahar2020AutomaticDO} for a complete survey on {\probfull}.

The problem of {\probfull} echoes earlier work on detecting deepfakes, artificial images or videos generated by deep nets, which has spawned substantial efforts in detection of fake visual content \citep{DFDC2020,zi2020wilddeepfake}. While early works in deepfake detection used relatively general-purpose model architectures \citep{guera2018deepfake}, many deepfake detection methods rely on the continuous nature of image data to achieve state-of-the-art performance \citep{zhao2021multi,Guarnera_2020_CVPR_Workshops}, making direct application to text difficult.
%Also related are works that aim to extract the hyperparameters of the model that generated a given text passage \citep{tay-etal-2020-reverse} or image \citep{asnani2021reverse}.
%%CF.1.18: This last sentence seems weird. Seems like an after thought, and it's not immediately clear why it is related. If the techniques used are relevant enough to be mentioned in the related work, then it warrants more discussion on how our technique is different. 
%% SK.1.23: +1
%% EM.1.24: Inclined to just remove this

\section{The Zero-Shot {\probfulltitle} Problem}
We study zero-shot {\probfull}, the problem of detecting whether a piece of text, or \textit{candidate passage} $x$, is a sample from a \textit{source model} $\sm$. The problem is zero-shot in the sense that we do not assume access to human-written or generated samples to perform detection. As in prior work, we study a `white box' setting \citep{gehrmann-etal-2019-gltr} in which the detector may evaluate the log probability of a sample $\log \sm(x)$. The white box setting \textbf{does not} assume access to the model architecture or parameters. While most public APIs for LLMs (such as GPT-3) enable scoring text, some exceptions exist. While most of our experiments consider the white box setting, see Section~\ref{sec:variants} for a suite of experiments in which we score text using models other than the source model.

The detection criterion we propose, {\name}, also makes use of generic pre-trained mask-filling models in order to generate passages that are `nearby' the candidate passage. However, these mask-filling models are used off-the-shelf, without any fine-tuning or adaptation to the target domain.


\section{{\name}: Zero-shot {\probfulltitle} with Random Perturbations}
\label{sec:local-extremum}

\newlength{\textfloatsepsave}
\setlength{\textfloatsepsave}{\textfloatsep}
\setlength{\textfloatsep}{0pt}
\begin{algorithm}
    \caption{{\name} model-generated text detection}
    \label{alg:method}
    \begin{algorithmic}[1]
        \footnotesize \STATE \textbf{Input:} passage $x$, source model $\sm$, perturbation function $q$, number of perturbations $k$, decision threshold $\epsilon$
        % \phantom{asdf}\com{\textbf{Return} \texttt{true} if $x\sim\sm$; \texttt{false} otherwise}
        \STATE $\tilde x_i \sim q(\cdot\mid x),\,i\in [1..k]$ \hfill\com{mask spans, sample replacements}
        \STATE $\tilde \mu \gets \frac{1}{k}\sum_i\log \sm(\tilde x_i)$ \hfill \com{approximate expectation in Eq. 1}
        \STATE $\pdh_x \gets \log \sm(x) - \tilde \mu$ \hfill\com{estimate $\pd$}
        \STATE \scalebox{0.95}{$\tilde \sigma_x^2 \gets \frac{1}{k-1}\sum_i\left(\log \sm(\tilde x_i) - \tilde \mu\right)^2$ \hfill\com{variance for normalization}}
        \IF{$\frac{\pdh_x}{\sqrt{\tilde \sigma_x}} \geq \epsilon$}
            \STATE return \texttt{true} \hfill\com{probably model sample}
        \ELSE
            \STATE return \texttt{false} \hfill\com{probably not model sample}
        \ENDIF
    \end{algorithmic}
\end{algorithm}
\setlength{\textfloatsep}{\textfloatsepsave}

{\name} is based on the hypothesis that samples from a source model $\sm$ typically lie in areas of negative curvature of the log probability function of $\sm$, unlike human text. In other words, if we apply small perturbations to a passage $x\sim\sm$, producing $\tilde x$, the quantity $\log \sm(x) - \log \sm(\tilde x)$ should be relatively large on average for machine-generated samples compared to human-written text. To leverage this hypothesis, first consider a perturbation function $q(\cdot\mid x)$ that produces a slightly modified version of $x$, with similar meaning (we will generally consider roughly paragraph-length texts $x$). As an example, $q(\cdot\mid x)$ might be the result of simply asking a human to rewrite one of the sentences of $x$, while preserving the meaning of $x$. Using the notion of a perturbation function, we can define the \textit{perturbation discrepancy} $\pd$: 
\begin{equation}
    \mathbf{d}(x) = \log \sm(x) - \mathbb{E}_{\tilde x \sim q(\cdot\mid x)} \log \sm(\tilde x)
    \label{eq:perturbation-discrepancy}
\end{equation}
We state our hypothesis more formally in Hypothesis~\ref{hyp:main}.
\begin{hypothesis}
    If $q$ produces samples on the data manifold, $\pd$ is positive with high probability for samples $x\sim\sm$. For human-written text, $\pd$ tends toward zero similarly for all $x$.
\label{hyp:main}
\end{hypothesis}
%%CF.1.19: Yoonho brought up a good point to me (and I think also to you) that it's really important that the perturbation function q gives you samples that are still on the data distribution. I think that hypothesis 4.1 won't hold for q's that consistently take you off the data manifold. I think it is important to convey this constraint on q.
%%EM.1.25: I think I fixed this.

If we define $q(\cdot\mid x)$ to be samples from a mask-filling model such as T5 \citep{raffel2020t5}, rather than human rewrites, we can empirically test Hypothesis~\ref{hyp:main} in an automated, scalable manner. For real data, we use news articles from the XSum dataset \citep{shashi2018dont}; for model samples, we use the output of GPT-2-medium when prompted with the first 30 tokens of each article in XSum. We use T5-large to apply perturbations, masking out randomly-sampled 2-word spans until 15\% of the words in the article are masked. We approximate the expectation in Eq.~\ref{eq:perturbation-discrepancy} with 100 samples from T5-large.\footnote{We later show in Figure~\ref{fig:n-perturb} that varying the number of samples used to estimate the expectation effectively allows for trading off between accuracy and speed.} Figure~\ref{fig:perturbation-discrepancy} shows the result of this experiment for four different source models, using 500 articles from XSum. We find that the distribution of perturbation discrepancies is significantly different for human-written articles and model samples; model samples do tend to have a larger perturbation discrepancy. Section~\ref{sec:ablations} explores a relaxation of the assumption that $q$ only produces samples on the data manifold, finding that a gap, although reduced, still exists in this case.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/pd_hist.pdf}
    \vspace{-11mm}
    \caption{The average drop in log probability (perturbation discrepancy) after rephrasing a passage is consistently higher for model-generated passages than for human-written passages. Each plot shows the distribution of the perturbation discrepancy $\pd$ for \textcolor{human-orange}{\textbf{human-written news articles}} and \textcolor{machine-blue}{\textbf{machine-generated articles}} for various models; of equal word length from GPT-2 (1.5B), GPT-Neo-2.7B, GPT-J (6B) and GPT-NeoX (20B). Human-written articles are a sample of 500 XSum \citep{shashi2018dont} articles; machine-generated text generated by prompting each model with the first 30 tokens of each XSum article. Discrepancies are estimated with 100 samples from T5-3B.}
    \vspace{-4mm}
    %%CF.1.18: It would be good to provide the key takeaway from this figure for the reader. What does it mean for the distributions to be different?
    %%CF.1.18: if someone is skimming the paper, I think they probably won't understand what "perturbation discrepancy" means. Can you describe the key finding here in more layman's terms?
    %%EM.1.24: Tried to do this, hopefully it's more direct now.
    \label{fig:perturbation-discrepancy}
\end{figure}

Given these results, we can detect if a piece of text was generated by a model $\sm$ by simply thresholding the perturbation discrepancy. In practice, we find that normalizing the perturbation discrepancy by the standard deviation of the observed values used to estimate $\mathbb{E}_{\tilde x \sim q(\cdot\mid x)} \log \sm(\tilde x)$ provides a slightly better signal for detection, typically increasing AUROC by around 0.020, so we use this normalized version of the perturbation discrepancy in our experiments. The resulting method, {\name}, is summarized in Alg.~\ref{alg:method}. Having described an application of the perturbation discrepancy to {\probfull}, we next provide an interpretation of this quantity.

%%CF.1.19: It would be nice to walk the reader through the algorithm in the main text, including the things it requires like a perturbation function and how things are thresholded.

%%CF.1.19: You *really* need some signposting somewhere. I might actually actually recommend ending the section here (though with a sentence that tells the reader where you are going next) and start a new section about the interpretation of the approach. Or, the alternative would be to start section 4 with some signposting of what's in this section, then have one subsection on the intuition and method, and then one or two subsections on the rest. Right now, I think the current version is a bit of the worst of both worlds in terms of organization.
%%EM.1.24: Added a transition sentence at the end of 4 and the beginning of 4.1 to smooth things out.

\paragraph{Interpretation of the Perturbation Discrepancy as Curvature}

%%CF.1.19: Following up on the above comment, it's really unclear where you are going now. Section 4 was okay because you led it by saying that the method is based on this hypothesis, so it was clear that you were going to be building up intuition for the method before describing the method. But now, there's no direction.
%%EM.1.24: Added a transition.

While Figure~\ref{fig:perturbation-discrepancy} suggests that the perturbation discrepancy may be useful, it is not immediately obvious what it measures. In this section, we show that the perturbation discrepancy can be interpreted as an approximation of the local curvature of the log probability function. %Hypothesis~\ref{hyp:main} can be restated in terms of the local maxima of the log probability function $\log \sm$: Model samples tend to lie near local maxima of $\log \sm$, while human-written samples do not.
We will show that the perturbation discrepancy approximates a measure of local curvature near the candidate passage, more specifically, that it is proportional to the negative trace of the Hessian of the log probability function.\footnote{Rather than the Hessian of the log likelihood with respect to model parameters (the Fisher Information Matrix), here we refer to the Hessian of the log probability with respect to the sample $x$.} To handle the non-differentiability of discrete data, we consider candidate passages in a latent semantic space, where small displacements correspond to valid edits that retain similar meaning to the original. Because our perturbation function (T5) models natural text, we expect our perturbations to roughly capture such meaningful variations of the original passage, rather than arbitrary edits.
%%CF.1.19: You could add something like: "Indeed, we expect the mask-filling model to replace sections of text with semantically similar content."
%In this section, we show that the perturbation discrepancy can indeed be interpreted as a measure of local curvature, approximating a constant scalar multiple of a partial negative sum of the diagonal values of the Hessian of the probability function at the candidate passage.
%%CF.1.19: This phrase really isn't easy to parse. It's also not clear why this interpretation is meaningful or interesting. Can you provide some high-level reason for why this interpretation is interesting or useful?
%%EM.1.24: It was redundnant anyway, so I removed it

We first invoke Hutchinson's trace estimator \citep{hutchinson1990stochastic}, which gives an unbiased estimate of the trace of a matrix $A$ as
\begin{equation}
    \text{tr}(A) = \mathbb{E}_\mathbf{z} \mathbf{z}^\top A \mathbf{z}
    \label{eq:hutch}
\end{equation}
provided that the elements of $\mathbf{z} \sim q_z$ are IID with $\mathbb{E}[z_i] = 0$ and $\text{Var}(z_i) = 1$. To use Equation~\ref{eq:hutch} to estimate the trace of the Hessian, we must therefore compute the expectation of the directional second derivative $\mathbf{z}^\top H_f(x)\mathbf{z}$. We approximate this expression with finite differences:
\begin{equation}
    \mathbf{z}^\top H_f(x) \mathbf{z} \approx \frac{f(x + h\mathbf{z}) + f(x - h\mathbf{z}) - 2f(x)}{h^2}
    \label{eq:fd}
\end{equation}
Combining Equations~\ref{eq:hutch} and~\ref{eq:fd} and simplifying with $h=1$, we have an estimate of the negative Hessian trace
\begin{align}
    -\text{tr}(H)_f(x) &= 2f(x) - \mathbb{E}_\mathbf{z} \left[f(x + \mathbf{z}) + f(x - \mathbf{z})\right].
    \label{eq:neg-trace}
\end{align}
If our noise distribution is \textit{symmetric}, that is, $p(\mathbf{z}) = p(-\mathbf{z})$ for all $\mathbf{z}$, then we can simplify Equation~\ref{eq:neg-trace} to
\begin{align}
    \frac{-\text{tr}(H)_f(x)}{2} &= f(x) - \mathbb{E}_\mathbf{z} f(x + \mathbf{z}).
    \label{eq:simplified}
\end{align}
% While the RHS of Equation~\ref{eq:simplified} is very similar to the expression for the perturbation discrepancy, we do not perturb $x$ with IID vectors $\mathbf{z}$ as in Hutchinson's estimator. Rather, we use samples from a mask filling model (e.g., T5) to compute $\mathbb{E}_\mathbf{\tilde x}f(\tilde x)$, where $\tilde x = x + \delta$ and $\delta$ is some semantic perturbation in representation space, which is very unlikely to have IID elements. Thus, the perturbation discrepancy is a \textit{weighted} sum of the diagonal elements of the Hessian matrix, where the weights are determined by the distribution of the perturbation distribution. We can interpret this resulting quantity as the trace of the Hessian restricted to the data manifold.
%%YL.1.25: Rewrote the last paragraph, because I feel like the IID issue isn't really critical and it could be nice to end on a more positive note - feel free to combine or delete or anything
We note that the RHS of Equation~\ref{eq:simplified} corresponds to the perturbation discrepancy (\ref{eq:perturbation-discrepancy}) where the perturbation function $q(\tilde{x} \mid x)$ is replaced by the distribution $q_z(z)$ used in Hutchinson's trace estimator (\ref{eq:hutch}).
We note that $\tilde{x}$ is a high-dimensional sequence of tokens while $q_z$ is a vector in a compact semantic space.
Since the mask-filling model samples sentences similar to $x$ with minimal changes to semantic meaning, we can think of the mask-filling model as first sampling a similar semantic embedding ($\tilde{z} \sim q_z$) and then mapping this to a token sequence ($\tilde{z} \mapsto \tilde{x}$).
Sampling in semantic space ensures that all samples stay near the data manifold, which is useful because we would expect the log probability to always drop if we randomly perturb tokens.
We can therefore interpret our objective as approximating the curvature restricted to the data manifold.

\section{Experiments}

% \begin{figure}
%     \centering
%     \includegraphics[width=\columnwidth]{figures/pr-roc.png}
%     \vspace{-5mm}
%     \caption{ROC and precision-recall curves for detecting samples from GPT-Neo-2.7B and GPT-2-xl using T5-3B as the referee/mask-filling model. {\name} provides significantly better performance than probability thresholding when averaging over at least 10 perturbations. Further, increasing the number of perturbations used to estimate the expectation in Eq.~\ref{eq:perturbation-discrepancy} provides an effective way to leverage additional compute to improve accuracy of the detector.}
%     \label{fig:pr-roc}
% \end{figure}

% \addtolength{\tabcolsep}{-0.2em}
% \begin{table*}
%     \centering
%     \small
%     \resizebox{\textwidth}{!}{%
%     \begin{tabular}{lcccccccccccccccc}
%         \toprule
%          & \multicolumn{5}{c}{\textbf{XSum}} & \multicolumn{5}{c}{\textbf{SQuAD}} & \multicolumn{5}{c}{\textbf{WritingPrompts}} & \textbf{Avg.} \\
%          \cmidrule(lr){2-6} \cmidrule(lr){7-11} \cmidrule(lr){12-16}\cmidrule(lr){17-17}
%          \textbf{Method} & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & \textit{-} \\
%          \midrule
%          $\log p(x)$ & 0.86 & 0.86 & 0.86 & 0.82 & 0.77 & 0.91 & 0.88 & 0.84 & 0.78 & 0.71 & 0.97 & 0.95 & 0.95 & 0.94 & \phantom{*}0.93* & 0.87 \\
%         Rank & 0.79 & 0.76 & 0.77 & 0.75 & 0.73 & 0.83 & 0.82 & 0.80 & 0.79 & 0.74 & 0.87 & 0.83 & 0.82 & 0.83 & 0.81 & 0.80 \\
%         LogRank & \phantom{*}0.89* & \phantom{*}0.88* & \phantom{*}0.90* & \phantom{*}0.86* & \phantom{*}0.81* & \phantom{*}0.94* & \phantom{*}0.92* & \phantom{*}0.90* & \phantom{*}0.83* & \phantom{*}0.76* & \phantom{*}0.98* & \phantom{*}0.96* & \phantom{*}0.97* & \phantom{*}0.96* & \textbf{0.95} & 0.90 \\
%         Entropy & 0.60 & 0.50 & 0.58 & 0.58 & 0.61 & 0.58 & 0.53 & 0.58 & 0.58 & 0.59 & 0.37 & 0.42 & 0.34 & 0.36 & 0.39 & 0.51 \\
%         {\name} & \textbf{0.99} & \textbf{0.97} & \textbf{0.99} & \textbf{0.97} & \textbf{0.95} & \textbf{0.99} & \textbf{0.97} & \textbf{0.97} & \textbf{0.90} & \textbf{0.79} & \textbf{0.99} & \textbf{0.99} & \textbf{0.99} & \textbf{0.97} & \phantom{*}0.93* & \textbf{0.96} \\
%         \midrule
%         Diff & 0.10 & 0.09 & 0.09 & 0.11 & 0.14 & 0.05 & 0.05 & 0.07 & 0.07 & 0.03 & 0.01 & 0.03 & 0.02 & 0.01 & -0.02 & 0.06 \\
%          \bottomrule
%     \end{tabular}}
%     \caption{AUROC for detecting samples from the given model on the given dataset for {\name} and four previously proposed criteria. From 1.5B parameter GPT-2 to 20B parameter GPT-NeoX, {\name} consistently provides the most accurate detections. \textbf{Bold} shows the best AUROC within each column (model-dataset combination); asterisk (*) denotes the second-best AUROC. Values in the final row shows {\name}'s AUROC over the strongest baseline method in that column.}
%     \label{tab:main-results}
% \end{table*}
% \addtolength{\tabcolsep}{0.2em}

\addtolength{\tabcolsep}{-0.3em}
\begin{table*}
    \centering
    \small
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{lcccccc|cccccc|cccccc}
        \toprule
         & \multicolumn{6}{c}{\textbf{XSum}} & \multicolumn{6}{c}{\textbf{SQuAD}} & \multicolumn{6}{c}{\textbf{WritingPrompts}} \\
         \cmidrule(lr){2-7} \cmidrule(lr){8-13} \cmidrule(lr){14-19}
         \textbf{Method} & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & \textbf{Avg.} & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & \textbf{Avg.} & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & \textbf{Avg.} \\
         \midrule
         $\log p(x)$ & 0.86 & 0.86 & 0.86 & 0.82 & 0.77 & 0.83 & 0.91 & 0.88 & 0.84 & 0.78 & 0.71 & 0.82 & 0.97 & 0.95 & 0.95 & 0.94 & \phantom{*}0.93* & 0.95 \\
        Rank & 0.79 & 0.76 & 0.77 & 0.75 & 0.73 & 0.76 & 0.83 & 0.82 & 0.80 & 0.79 & 0.74 & 0.80 & 0.87 & 0.83 & 0.82 & 0.83 & 0.81 & 0.83 \\
        LogRank & \phantom{*}0.89* & \phantom{*}0.88* & \phantom{*}0.90* & \phantom{*}0.86* & \phantom{*}0.81* & \phantom{*}0.87* & \phantom{*}0.94* & \phantom{*}0.92* & \phantom{*}0.90* & \phantom{*}0.83* & \phantom{*}0.76* & \phantom{*}0.87* & \phantom{*}0.98* & \phantom{*}0.96* & \phantom{*}0.97* & \phantom{*}0.96* & \textbf{0.95} & \phantom{*}0.96* \\
        Entropy & 0.60 & 0.50 & 0.58 & 0.58 & 0.61 & 0.57 & 0.58 & 0.53 & 0.58 & 0.58 & 0.59 & 0.57 & 0.37 & 0.42 & 0.34 & 0.36 & 0.39 & 0.38 \\
        {\name} & \textbf{0.99} & \textbf{0.97} & \textbf{0.99} & \textbf{0.97} & \textbf{0.95} & \textbf{0.97} & \textbf{0.99} & \textbf{0.97} & \textbf{0.97} & \textbf{0.90} & \textbf{0.79} & \textbf{0.92} & \textbf{0.99} & \textbf{0.99} & \textbf{0.99} & \textbf{0.97} & \phantom{*}0.93* & \textbf{0.97} \\
        \midrule
        Diff & 0.10 & 0.09 & 0.09 & 0.11 & 0.14 & 0.10 & 0.05 & 0.05 & 0.07 & 0.07 & 0.03 & 0.05 & 0.01 & 0.03 & 0.02 & 0.01 & -0.02 & 0.01 \\
         \bottomrule
    \end{tabular}}
    \vspace{-3mm}
    \caption{AUROC for detecting samples from the given model on the given dataset for {\name} and four previously proposed criteria. From 1.5B parameter GPT-2 to 20B parameter GPT-NeoX, {\name} consistently provides the most accurate detections. \textbf{Bold} shows the best AUROC within each column (model-dataset combination); asterisk (*) denotes the second-best AUROC. Values in the final row shows {\name}'s AUROC over the strongest baseline method in that column.}
    \label{tab:main-results}
\end{table*}
\addtolength{\tabcolsep}{0.3em}

We conduct comprehensive experiments to better understand multiple facets of {\probfull}; we study the effectiveness of {\name} for zero-shot {\probfull} compared to prior zero-shot approaches, the impact of distribution shift on zero-shot and supervised detectors, and detection accuracy for the largest publicly-available models. To further characterize factors that impact detection accuracy, we also study the robustness of zero-shot methods to machine-generated text that has been partially revised, the impact of alternative decoding strategies on detection accuracy, and a black-box variant of the detection task. Finally, we analyze {\name}'s behavior through studies of the impact of choice of perturbation function as well as the number of samples used to estimate $\pd$ on detection performance.

\textbf{Comparisons.} We compare {\name} with various existing zero-shot methods for {\probfull} that also leverage the predicted token-wise conditional distributions of the source model for detection. These methods correspond to statistical tests based on token log probabilities, token ranks, or predictive entropy \citep{gehrmann-etal-2019-gltr,release-strategies,ippolito-etal-2020-automatic}. The first method uses the source model's average token-wise log probability to determine if a candidate passage is machine-generated or not; passages with high average log probability are likely to be generated by the model. The second and third methods use the average observed rank or log-rank of the tokens in the candidate passage according to the model's conditional distributions. Passages with smaller average (log-)rank are likely machine-generated. We also evaluate an entropy-based approach inspired by the hypothesis in \citet{gehrmann-etal-2019-gltr} that model-generated texts will be more `in-distribution' for the model, leading to more over-confident (thus lower entropy) predictive distributions. Empirically, we find predictive entropy to be \textit{positively} correlated with passage fake-ness more often that not; therefore, this baseline uses high average entropy in the model's predictive distribution as a signal that a passage is machine-generated. While our main focus is on zero-shot detectors as they do not require re-training for new domains or source models, for completeness we perform comparisons to supervised detection models in Section~\ref{sec:main-results}, using OpenAI's RoBERTa-based \citep{liu2019roberta} GPT-2 detector models,\footnote{\href{https://github.com/openai/gpt-2-output-dataset/tree/master/detector}{\texttt{https://github.com/openai/gpt-2-output-\\dataset/tree/master/detector}}} which are fine-tuned on millions of samples from various GPT-2 model sizes and decoding strategies.


\textbf{Datasets \& Metrics.} Our experiments use six datasets that cover a variety of domains and LLM use-cases. To represent everyday use-cases, we use news articles from the XSum dataset \citep{shashi2018dont} to represent fake news detection, Wikipedia paragraphs from SQuAD contexts \citep{rajpurkar-etal-2016-squad} to represent cheating in academic essays, and prompted stories from the Reddit WritingPrompts dataset \citep{fan-etal-2018-hierarchical} to represent detecting machine-generated creative writing submissions. To perform targeted evaluations of robustness to distribution shift, we also use the English and German splits of WMT16 \citep{bojar2016wmt} as well as long-form answers written by human experts in the PubMedQA dataset \citep{jin-etal-2019-pubmedqa}. Each experiment uses between 150 and 500 examples for evaluation, as noted in the text. For each experiment, we generate the machine-generated text by prompting with the first 30 tokens of the real text (or with just the question tokens for the PubMedQA experiments). We measure performance using the area under the receiver operating characteristic curve (AUROC), which can be interpreted as the probability that a classifier correctly ranks a randomly-selected positive (machine-generated) example higher than a randomly-selected negative example (human-written). All experiments use an equal number of positive and negative examples.

\textbf{Hyperparameters.} The key hyperparameters of {\name} are the fraction of words masked for perturbation, the length of the masked spans, the model used for mask filling, and the sampling hyperparameters for the mask-filling model. Using BERT \citep{devlin-etal-2019-bert} masked language modeling as inspiration, we use 15\% as the mask rate. We performed a small sweep over masked span lengths of $\{2,5,10\}$ on a held-out set of XSum data, finding 2 to perform best. We use mask rate of 15\% and span length 2 for \textbf{all experiments}. We use T5-3B for almost all experiments, except for GPT-NeoX and GPT-3 experiments, where compute resources allowed for the larger T5-11B model; we also use mT5-3B instead of T5-3B for the WMT multilingual experiment. We do not tune the hyperparameters for the mask filling model (no top-$k$ or top-$p$ sampling, temperature 1).

\subsection{Main Results}
\label{sec:main-results}

We first present two groups of experiments intending to evaluate {\name} along with existing methods for zero-shot and supervised detection on models from 1.5B to 175B parameters.

\noindent\textbf{Zero-Shot {\probfulltitle}.} We present the comparison of different zero-shot detection methods in Table \ref{tab:main-results}. In these experiments, model samples are generated by sampling from the raw conditional distribution with temperature 1. {\name} most improves average detection accuracy for XSum stories (0.1 AUROC improvement) and SQuAD Wikipedia contexts (0.05 AUROC improvement). While it also performs accurate detection for WritingPrompts, the performance of all methods tends to increase, and the average margin of improvement is narrow.\footnote{The overall ease of detecting machine-generated fake writing corroborates anecdotal reporting that machine-generated creative writing tends to be noticeably generic, and therefore relatively easy to detect \citep{roose2022chatgpt}.} For 14 of the 15 combinations of dataset and model, {\name} provides the most accurate detection performance, with a 0.06 AUROC improvement on average. Log-rank thresholding proves to be a consistently stronger baseline than log probability thresholding, although it requires slightly more information (full predicted logits), which are not always available in public APIs.


\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/supervised_plot.pdf}
    \vspace{-5mm}
    \caption{Supervised machine-generated text detection models trained on large datasets of real and generated texts perform as well as or better than {\name} on \textbf{in-distribution (top row)} text. However, zero-shot methods work out-of-the-box for \textbf{new domains (bottom row)} such as PubMed medical texts and German news data from WMT16. For these domains, supervised detectors fail due to excessive distribution shift.}
    \vspace{-4mm}
    \label{fig:supervised}
\end{figure}


\noindent\textbf{Comparison with Supervised Detectors.}
% \label{sec:supervised}
While our experiments generally focus on zero-shot detection, some works have evaluated the detection performance of supervised methods (typically fine-tuned transformers) for detecting machine-generated text. In this section, we explore several domains to better understand the relative strengths of supervised and zero-shot detectors. The results are presented in Figure~\ref{fig:supervised}, using 200 samples from each dataset for evaluation. We find that supervised detectors can provide similar detection performance to {\name} on \textit{in-distribution} data like English news, but perform significantly worse than zero-shot methods in the case of English scientific writing and fail altogether for German writing. This finding echoes past work showing that language models trained for machine-generated text detection overfit to their training data (source model, decoding strategy, topic, language, etc.; \citet{uchendu-etal-2020-authorship,ippolito-etal-2020-automatic,Jawahar2020AutomaticDO}). In contrast, zero-shot methods generalize relatively easily to new languages and domains; {\name}'s performance in particular is mostly unaffected by the change in language from English to German.

% \label{sec:gpt-3}

\begin{table}
    \small
    \centering
    \begin{tabular}{lccc|c}
        \toprule
         & \textbf{PubMedQA} & \textbf{XSum} & \textbf{WritingP} & \textbf{Avg.}  \\
         \midrule
         RoBERTa-base & 0.64 & \textbf{0.92} & \textbf{0.92} & 0.83 \\
         RoBERTa-large & 0.71 & \textbf{0.92} & 0.91 & \textbf{0.85} \\
         \midrule
         $\log p(x)$ & 0.64 & 0.76 & 0.88 & 0.76 \\
         \name & \textbf{0.84} & 0.84 & 0.87 & \textbf{0.85} \\
         \bottomrule
    \end{tabular}
    \caption{{\name} detects GPT-3 generations with average AUROC on-par with supervised models trained specifically for machine-generated text detection. For more `typical' text, such as news articles, supervised methods perform strongly.}
    \vspace{-4mm}
    \label{tab:gpt-3-results}
\end{table}


While our experiments have shown that {\name} is effective on a variety of domains and models, it is natural to wonder if it is effective for the largest publicly-available LMs. Therefore, in this section, we evaluate multiple zero-shot and supervised methods on 175B parameter GPT-3 using OpenAI's paid API. Because the GPT-3 API does not provide access to the complete conditional distribution for each token, we cannot compare to the rank, log rank, and entropy-based prior methods. We sample 150 examples\footnote{We reduce the number of evaluation samples from 500 in our main experiments to reduce the API costs of these experiments.}
%%CF.1.25: I don't think you every said what the number of examples was for the first zero-shot comparison.
from the PubMedQA, XSum, and WritingPrompts datasets and compare the two pre-trained RoBERTa-based detector models with {\name} and the probability thresholding baseline. We find that {\name} can provide detection competitive with the stronger supervised model, and it again outperforms probability thresholding on average.


%%CF.1.25: There are a lot of subsection headers. I wonder if it would make sense to group some of these and then use paragraph headers. e.g. for the above, you could have a subsection that is "Main Results" and then paragraph headers for the three current section headers.
\subsection{Variants of {\probfulltitle}}
\vspace{-2mm}
\label{sec:variants}
%Next, we explore three variants of the {\probfull} setting. First, we introduce partial rewrites of machine-generated text before detection. Next, we explore the impact of top-$k$ and top-$p$ sampling on detection performance. Finally, we evaluate how {\name} responds to a black box setting, where samples are scored with a different model than the one that generated them.
%%CF.1.25: see comment above about phrase "manually-edited" being misleading and how "Partially Machine Generated" could be better.
%%EM.1.25: Switched to the "revision" phrasing
\noindent\paragraph{Detecting Revised Machine-Generated Text.} In practice, humans may manually edit or refine machine-generated text rather than blindly use a model's generations for their task of interest. We therefore conduct an experiment to simulate the detection problem for model samples that have been increasingly heavily revised. We simulate human revision by replacing 5 word spans of the text with samples from T5-3B until $r$\% of the text has been replaced, and report performance as $r$ varies. Figure~\ref{fig:pre-perturb} shows that {\name} maintains detection AUROC above 0.75 even when 16\% of the text in model samples has been replaced. Unsurprisingly, almost all methods show a gradual degradation in performance as the sample is more heavily revised. The entropy baseline shows surprisingly robust performance in this setting, even slightly improving detection performance up to 24\% replacement.
%%CF.1.25: any hypothesis as to why?
%%EM.1.25: Not really... I'd guess this is somewhat model/dataset specific and a bit of a fluke
{\name} shows the strongest detection performance for all revision levels.

\noindent\textbf{Impact of Alternative Decoding Strategies on Detection.} While Table~\ref{tab:main-results} suggests that {\name} is effective for detecting machine-generated text, prior work notes that the decoding strategy (i.e., temperature sampling, top-$k$, nucleus/top-$p$) can impact the difficulty of detection. In this subsection, we repeat the analysis from Section~\ref{sec:main-results} using top-$k$ sampling and nucleus sampling. Top-$k$ sampling truncates the sampling distribution to only the $k$ highest-probability next tokens; nucleus sampling samples from only the smallest set of tokens whose combined probability exceeds $p$. The results are summarized in Table~\ref{tab:decoding}; see Appendix Tables~\ref{tab:main-results-topp} and~\ref{tab:main-results-topk} for the complete results. We use $k=40$, and $p=0.96$, in line with prior work \citep{ippolito-etal-2020-automatic}. We find that both top-$k$ and nucleus sampling make detection easier, on average. Averaging across domains, {\name} provides a more discriminative signal for detection than other zero-shot criteria.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/pre_perturb_plot.pdf}
    \vspace{-5mm}
    \caption{We simulate manual editing by replacing varying fractions of model samples with T5-generated text (masking out random five word spans until $r$\% of text is masked to simulate a human edits to machine-generated text). Experiment is conducted on the XSum dataset.}
    \label{fig:pre-perturb}
\end{figure}

\addtolength{\tabcolsep}{-0.2em}
\begin{table}
    \footnotesize
    \centering
    \begin{tabular}{lcccccc}
    \toprule
        & \multicolumn{2}{c}{XSum} & \multicolumn{2}{c}{SQuAD} & \multicolumn{2}{c}{WritingPrompts} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
        Method & top-$p$ & top-$k$ & top-$p$ & top-$k$ & top-$p$ & top-$k$ \\
        \midrule
        $\log p(x)$ & 0.92 & 0.87 & 0.89 & 0.85 & \textbf{0.98} & 0.96 \\
        Rank & 0.76 & 0.76 & 0.81 & 0.80 & 0.84 & 0.83 \\
        LogRank & \phantom{*}0.93* & \phantom{*}0.90* & \phantom{*}0.92* & \phantom{*}0.90* & \textbf{0.98} & \textbf{0.97} \\
        Entropy & 0.53 & 0.55 & 0.54 & 0.56 & 0.32 & 0.35 \\
        \midrule
        {\name} & \textbf{0.98} & \textbf{0.98} & \textbf{0.94} & \textbf{0.93} & \textbf{0.98} & \textbf{0.97} \\
        \bottomrule
    \end{tabular}
    \caption{AUROC for zero-shot methods averaged across the five models in Table~\ref{tab:main-results} for both top-$k$ and top-$p$ sampling, with $k=40$ and $p=0.96$. Both settings enable slightly more accurate detection, and {\name} consistently provides the best detection performance.}
    \vspace{-4mm}
    \label{tab:decoding}
\end{table}
\addtolength{\tabcolsep}{0.2em}

\noindent\textbf{Using Likelihoods from Models other than the Source Model.} While our experiments have focused on the white-box setting for {\probfull}, in this section, we explore the effect of using a different model to \textit{score} a candidate passage (and perturbed texts) than the model that generated the passage. In other words, we aim to classify between human-generated text and text from model $A$, but without access to model $A$ to compute log probabilities. Instead, we use log probabilities computed by a surrogate model $B$. We consider three models, GPT-J, GPT-Neo-2.7, and GPT-2, and evaluate all possible combinations of source model and surrogate model (9 total). We average the performance across XSum, SQuAD, and WritingPrompts. The results are presented in Figure~\ref{fig:cross-eval}, showing that when the surrogate model is different from the source model, detection performance is reduced, indicating that DetectGPT is most suited to the white-box setting. However, we also notice that using the average cross-model detection performance differs significantly across models; the average AUROC when scoring with the smaller GPT-2 and GPT-Neo-2.7 than scoring with the larger GPT-J. Due to these variations in performance, ensembling scoring models may be a useful direction for future research.


\subsection{Evaluating scaling properties of {\name}}
In this section, we evaluate {\name} as the size of the mask-filling model or the number of perturbations used to estimate the expectation in Equation~\ref{eq:perturbation-discrepancy} are varied.

\label{sec:ablations}

\noindent\textbf{Impact of Source and Mask-Filling Model Scale.} Next we consider the impact of the size of the source model and mask-filling model on {\name}'s performnace; the results are shown in Figure~\ref{fig:model-size}. In particular, the increased discrimination power of {\name} for larger mask-filling models supports the interpretation that {\name} is estimating the curvature of the log probability in a latent semantic space, rather than in raw token embedding space. Larger T5 models better represent this latent space, in which random directions correspond to meaningful changes in the text along high-probability axes of variation.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/cross_plot.pdf}
    \vspace{-5mm}
    \caption{{\name} performs best when scoring samples with the same model that generated them. Each plot uses a different model for evaluating the probabilities in Equation~\ref{eq:perturbation-discrepancy}. This result suggests that {\name} may be able to identify the \textit{specific model} that generated a particular sample. Results are averaged over XSum, SQuAD, and WritingPrompts; one standard error is shown.}
    \vspace{-4mm}
    \label{fig:cross-eval}
\end{figure}


\noindent\textbf{Impact of Number of Perturbations for {\name}.} Here, we evaluate the performance of {\name} as a function of the number of perturbations used to estimate the expectation in Equation~\ref{eq:perturbation-discrepancy} on three datasets. The results are presented in Figure~\ref{fig:n-perturb}. 10 perturbations significantly improves detection over a single perturbation, and detection continues to improve until 100 perturbations, where it generally converges.

\section{Discussion}

As large language models continue to improve, they will become increasingly attractive tools for replacing human writers in a variety of contexts, such as education, journalism, and art. While legitimate uses of language model technologies exist in all of these settings, teachers, readers, and consumers are likely to demand tools for verifying the human origin of certain content with high educational, societal, or artistic significance, particularly when factuality (and not just fluency) is crucial.

In light of these elevated stakes and the regular emergence of new large language models, we study the \textit{zero-shot machine-generated text detection} problem, in which we use only the raw log probabilities computed by a generative model to determine if a candidate passage was sampled from it. We identify a property of the log probability function computed by a wide variety of large language models, showing that a tractable approximation to the trace of the Hessian of the model's log probability function provides a useful signal for detecting model samples. Our experiments find that this signal is more discriminative than existing zero-shot detection methods, and are competitive with bespoke detection models trained with millions of model samples.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/scale_plot.pdf}
    \vspace{-6mm}
    \caption{There is a clear association between capacity of mask-filling model and detection performance, across source model scales. Random mask filling (uniform sampling from mask filling model vocabulary) performs poorly, reinforcing the idea that the perturbation function should produce samples on the data manifold. Curves show AUROC scores on 200 SQuAD contexts.}
    \vspace{-5mm}
    \label{fig:model-size}
\end{figure}

\noindent \textbf{{\name} and Watermarking.}
One interpretation of the perturbation function (masking + replacing) is as producing \textit{semantically similar rephrasings of the original passage}. If these rephrasings are systematically lower-probability than the original passage, the model is exposing its bias toward the specific (and roughly arbitrary, by human standards) phrasing used. In other words, language models that do not perfectly imitate human writing essentially watermark themselves implicitly. Under this interpretation, efforts to \textit{manually} add watermarking biases to model outputs \citep{aaronson_2022} may further improve the effectiveness of methods such as {\name}, even as LLMs continue to improve their approximation of human writing. 

\noindent \textbf{Limitations.}
One limitation of probability-based methods for zero-shot {\probfull} (like {\name}) is the white-box assumption that we can evaluate log probabilities of the model(s) in question. For models behind APIs that do provide probabilities (such as GPT-3), evaluating probabilities nonetheless costs money.
%%CF.1.25: with the notable exception of chatgpt... you.com also has a model that you probably can't access likliehoods for. Plus, getting probabilities for some models is doable but costs money (e.g. GPT-3). I would tone down this sentence quite a bit. A skeptical reader will think that this is a serious limitation that should be discussed as one.
Another assumption of {\name} is access to a reasonable perturbation function. While in this work, we use off-the-shelf mask-filling models such as T5 and mT5 (for non-English languages), some domains may see reduced performance if existing mask-filling models do not well represent the space of meaningful rephrases, reducing the quality of the curvature estimate. While {\name} provides the best available detection performance for PubMedQA, its drop in performance compared to other datasets may be a result of lower quality perturbations. Finally, {\name} is more compute-intensive than other methods for detection, as it requires sampling and scoring the set of perturbations for each candidate passage, rather than just the candidate passage; a better tuned perturbation function or more efficient curvature approximation may help mitigate these costs.
%%CF.1.25: Could it make sense to mention pubmed, and say that, e.g., this could be why pubmed results are a bit lower than other datasets? (and beyond here, it could also be worth discussing this briefly in the experiments too, as a hypothesis for why pubmed isn't doing as well)
%%CF.1.25: Worth mentioning anything about computational requirements?

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/n_perturb_plot.pdf}
    \vspace{-6mm}
    \caption{Impact of varying the number of perturbations (samples from the mask-filling model) used by {\name} on auROC (\textbf{left}) and auPR (\textbf{right}) to estimate the perturbation discrepancy for classification. Averaging over at least 5 perturbations greatly increases {\name}'s discrimination power.}
    \vspace{-4mm}
    \label{fig:n-perturb}
\end{figure}

\noindent \textbf{Future Work.}
While the methods in this work make no assumptions about the models generating the samples, future work may explore developing watermarking algorithms in conjunction with detection algorithms, in order to improve detection robustness as language models continually improve their reproductions of human text. Separately, the results in Section~\ref{sec:variants} suggest that extending {\name} to use ensembles of models for scoring, rather than a single model, may improve detection in the black box setting. Another topic that remains unexplored is the relationship between prompting and detection; that is, can a clever prompt successfully prevent a model's generations from being detected by existing methods? Finally, future work may explore whether the local log probability curvature property we identify is present for generative models in other domains, such as audio, video, or images. We hope that the present work serves as inspiration to future work developing effective, general-purpose methods for mitigating potential harms of machine-generated media.

\bibliography{main}
\bibliographystyle{icml2023}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Complete Results for Top-$p$ and Top-$k$ Decoding}
Tables~\ref{tab:main-results-topp} and~\ref{tab:main-results-topk} contain the complete results for XSum, SQuAD, and WritingPrompts for the five models considered in Table~\ref{tab:main-results}. On average, both top-$p$ and top-$k$ sampling seem to make the detection task easier. This result is perhaps intuitive, as both sampling methods strictly increase the average log likelihood of model generations under the model (as they truncate low-probability tokens, albeit with different heuristics). Therefore methods based on probability or rank of tokens should become more discriminative.

\addtolength{\tabcolsep}{-0.2em}
\begin{table*}
    \centering
    \small
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{lcccccc|cccccc|cccccc}
        \toprule
         & \multicolumn{6}{c}{\textbf{XSum}} & \multicolumn{6}{c}{\textbf{SQuAD}} & \multicolumn{6}{c}{\textbf{WritingPrompts}} \\
         \cmidrule(lr){2-7} \cmidrule(lr){8-13} \cmidrule(lr){14-19}
         \textbf{Method} & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & \textbf{Avg.} & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & \textbf{Avg.} & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & \textbf{Avg.} \\
         \midrule
         $\log p(x)$ & 0.93 & 0.93 & 0.94 & 0.91 & 0.87 & 0.92 & 0.96 & 0.94 & 0.91 & 0.87 & 0.79 & 0.89 & \phantom{*}0.99* & \phantom{*}0.98* & \phantom{*}0.98* & \phantom{*}0.97* & \phantom{*}0.97* & \textbf{0.98} \\
        Rank & 0.80 & 0.77 & 0.77 & 0.75 & 0.73 & 0.76 & 0.84 & 0.82 & 0.81 & 0.80 & 0.75 & 0.81 & 0.87 & 0.84 & 0.83 & 0.83 & 0.81 & 0.84 \\
        LogRank & \phantom{*}0.95* & \phantom{*}0.94* & \phantom{*}0.96* & \phantom{*}0.93* & \phantom{*}0.89* & \phantom{*}0.93* & \phantom{*}0.98* & \phantom{*}0.96* & \phantom{*}0.94* & \textbf{0.90} & \textbf{0.83} & \phantom{*}0.92* & \phantom{*}0.99* & \phantom{*}0.98* & \phantom{*}0.98* & \textbf{0.98} & \textbf{0.98} & \textbf{0.98} \\
        Entropy & 0.55 & 0.46 & 0.53 & 0.54 & 0.58 & 0.53 & 0.53 & 0.50 & 0.55 & 0.56 & 0.57 & 0.54 & 0.32 & 0.37 & 0.28 & 0.32 & 0.32 & 0.32 \\
        {\name} & \textbf{0.99} & \textbf{0.98} & \textbf{1.00} & \textbf{0.98} & \textbf{0.97} & \textbf{0.98} & \textbf{0.99} & \textbf{0.98} & \textbf{0.98} & \textbf{0.90} & \phantom{*}0.82* & \textbf{0.94} & \textbf{1.00} & \textbf{0.99} & \textbf{0.99} & \phantom{*}0.97* & 0.93 & \textbf{0.98} \\
        \midrule
        Diff & 0.04 & 0.04 & 0.04 & 0.05 & 0.08 & 0.05 & 0.01 & 0.02 & 0.04 & 0.00 & -0.01 & 0.02 & 0.01 & 0.01 & 0.01 & -0.01 & -0.05 & 0.00 \\
         \bottomrule
    \end{tabular}}
    \vspace{-3mm}
    \caption{Nucleus (top-$p$) sampling evaluation with $p=0.96$. AUROC for detecting samples from the given model on the given dataset for {\name} and four previously proposed criteria. Nucleus sampling generally makes detection easier for all methods, but {\name} still provides the highest average AUROC. For WritingPrompts, however, the LogRank baseline performs as well as {\name}.}
    \label{tab:main-results-topp}
\end{table*}
\addtolength{\tabcolsep}{0.2em}

\addtolength{\tabcolsep}{-0.2em}
\begin{table*}
    \centering
    \small
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{lcccccc|cccccc|cccccc}
        \toprule
         & \multicolumn{6}{c}{\textbf{XSum}} & \multicolumn{6}{c}{\textbf{SQuAD}} & \multicolumn{6}{c}{\textbf{WritingPrompts}} \\
         \cmidrule(lr){2-7} \cmidrule(lr){8-13} \cmidrule(lr){14-19}
         \textbf{Method} & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & \textbf{Avg.} & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & \textbf{Avg.} & GPT-2 & OPT-2.7 & Neo-2.7 & GPT-J & NeoX & \textbf{Avg.} \\
         \midrule
         $\log p(x)$ & 0.89 & 0.89 & 0.89 & 0.84 & 0.81 & 0.87 & 0.93 & 0.90 & 0.88 & 0.82 & 0.74 & 0.85 & 0.97 & 0.95 & 0.97 & 0.96 & \phantom{*}0.95* & 0.96 \\
        Rank & 0.79 & 0.77 & 0.77 & 0.75 & 0.73 & 0.76 & 0.84 & 0.82 & 0.80 & 0.80 & 0.75 & 0.80 & 0.87 & 0.84 & 0.83 & 0.82 & 0.81 & 0.83 \\
        LogRank & \phantom{*}0.92* & \phantom{*}0.91* & \phantom{*}0.93* & \phantom{*}0.89* & \phantom{*}0.85* & \phantom{*}0.90* & \phantom{*}0.96* & \phantom{*}0.94* & \phantom{*}0.92* & \phantom{*}0.87* & \phantom{*}0.79* & \phantom{*}0.90* & \phantom{*}0.98* & \phantom{*}0.97* & \phantom{*}0.98* & \textbf{0.97} & \textbf{0.96} & \textbf{0.97} \\
        Entropy & 0.58 & 0.49 & 0.55 & 0.56 & 0.59 & 0.55 & 0.55 & 0.52 & 0.56 & 0.56 & 0.58 & 0.56 & 0.35 & 0.41 & 0.30 & 0.34 & 0.37 & 0.35 \\
        {\name} & \textbf{0.99} & \textbf{0.97} & \textbf{0.99} & \textbf{0.96} & \textbf{0.96} & \textbf{0.98} & \textbf{0.99} & \textbf{0.98} & \textbf{0.98} & \textbf{0.89} & \textbf{0.80} & \textbf{0.93} & \textbf{0.99} & \textbf{0.98} & \textbf{0.99} & \textbf{0.97} & 0.93 & \textbf{0.97} \\
        \midrule
        Diff & 0.07 & 0.06 & 0.06 & 0.07 & 0.11 & 0.08 & 0.03 & 0.04 & 0.06 & 0.02 & 0.01 & 0.03 & 0.01 & 0.01 & 0.01 & 0.00 & -0.03 & 0.00 \\
         \bottomrule
    \end{tabular}}
    \vspace{-3mm}
    \caption{Top-$k$ sampling evaluation with $k=40$. {\name} generally provides the most accurate performance (highest AUROC), although the gap is narrowed comparing to direct sampling, presumably because top-$k$ generations are more generic.}
    \label{tab:main-results-topk}
\end{table*}
\addtolength{\tabcolsep}{0.2em}

\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
