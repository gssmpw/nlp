@article{inan2023llama,
  title   = {Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations},
  author  = {Hakan Inan and Kartikeya Upasani and Jianfeng Chi and Rashi Rungta and Krithika Iyer and Yuning Mao and Michael Tontchev and Qing Hu and Brian Fuller and Davide Testuggine and Madian Khabsa},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2312.06674}
}

@article{luo2024pace,
  title={PaCE: Parsimonious Concept Engineering for Large Language Models},
  author={Luo, Jinqi and Ding, Tianjiao and Chan, Kwan Ho Ryan and Thaker, Darshan and Chattopadhyay, Aditya and Callison-Burch, Chris and Vidal, Ren{\'e}},
  journal={arXiv preprint arXiv:2406.04331},
  year={2024}
}

@article{qiu2024spectral,
  title={Spectral Editing of Activations for Large Language Model Alignment},
  author={Qiu, Yifu and Zhao, Zheng and Ziser, Yftah and Korhonen, Anna and Ponti, Edoardo M and Cohen, Shay B},
  journal={arXiv preprint arXiv:2405.09719},
  year={2024}
}

@article{li2024safety,
  title={Safety Layers in Aligned Large Language Models: The Key to LLM Security},
  author={Li, Shen and Yao, Liuyi and Zhang, Lan and Li, Yaliang},
  journal={arXiv preprint arXiv:2408.17003},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{bai2022training,
  title   = {Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback},
  author  = {Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2204.05862}
}

@article{hu2021lora,
  title     = {LoRA: Low-Rank Adaptation of Large Language Models},
  author    = {J. E. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Weizhu Chen},
  journal   = {International Conference on Learning Representations},
  year      = {2021},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/a8ca46b171467ceb2d7652fbfb67fe701ad86092}
}

@inproceedings{hartvigsen2022toxigen,
  title={ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection},
  author={Hartvigsen, Thomas and Dhamala, Jwala and Lee, Jamin and et al.},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2022}
}

@article{gehman2020realtoxicityprompts,
  title={RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models},
  author={Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A.},
  journal={Findings of the Association for Computational Linguistics: EMNLP},
  year={2020}
}

@inproceedings{dinan2019build,
  title={Build It Break It Fix It: Interactive Bootstrapping for Adversarially Robust Models},
  author={Dinan, Emily and Fan, Angela and Mazare, Pierre-Emmanuel and Weston, Jason},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},
  year={2019}
}

@article{wei2023jailbreak,
  title={Jailbreaking Large Language Models via Prompt Engineering},
  author={Wei, Jason and et al.},
  year={2023},
  journal={arXiv preprint arXiv:2303.16200}
}

@article{carlini2023aligned,
  title={Aligned but Unsafe: Investigation of Jailbreaks in AI Systems},
  author={Carlini, Nicholas and et al.},
  year={2023},
  journal={arXiv preprint arXiv:2305.18526}
}

@article{ganguli2023red,
  title={Red Teaming Language Models with Language Models},
  author={Ganguli, Deep and et al.},
  year={2023},
  journal={arXiv preprint arXiv:2302.06707}
}

@article{arora2021types,
  title={Types of out-of-distribution texts and how to detect them},
  author={Arora, Gaurav and Bhattacharjee, Abhisek and Grover, Aditya and Jain, Shreyansh and Shaikh, Omar and Balasubramanian, Vineeth N},
  journal={arXiv preprint arXiv:2110.08151},
  year={2021}
}

@inproceedings{zhou2023ood,
  title={OOD detection for large-scale natural language understanding systems},
  author={Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Loy, Chen Change},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}

@inproceedings{liu2020energy,
  title={Energy-based out-of-distribution detection},
  author={Liu, Weitang and Wang, Xiaoyun and Owens, John and Li, Yixuan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@inproceedings{ren2019likelihood,
  title={Likelihood ratios for out-of-distribution detection},
  author={Ren, Jie and Liu, Peter J and Fertig, Emily and Snoek, Jasper and Poplin, Ryan and Depristo, Mark and Dillon, Joshua and Lakshminarayanan, Balaji},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@inproceedings{hendrycks2020pretrained,
  title={Pretrained transformers improve out-of-distribution robustness},
  author={Hendrycks, Dan and Lee, Kimin and Mazeika, Mantas and Zhang, Xinyuan and Song, Dawn and Steinhardt, Jacob},
  booktitle={Proceedings of the 34th Conference on Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{kamath2023openood,
  title={OpenOOD: Benchmarking generalized out-of-distribution detection},
  author={Kamath, Ananya and Sun, Shiyu and Gu, Xiaoyang and Zhang, Rui and Liu, Yixuan and Hein, Matthias and Li, Yixuan},
  journal={arXiv preprint arXiv:2302.12229},
  year={2023}
}

@inproceedings{dai2024safe-rlhf,
  title={Safe RLHF: Safe Reinforcement Learning from Human Feedback},
  author={Josef Dai and Xuehai Pan and Ruiyang Sun and Jiaming Ji and Xinbo Xu and Mickel Liu and Yizhou Wang and Yaodong Yang},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
  url={https://openreview.net/forum?id=TyFrPOKYXw}
}

@inproceedings{Thakkar2024ADD,
  title={A Deep Dive into the Trade-Offs of Parameter-Efficient Preference Alignment Techniques},
  author={Megh Thakkar and Quentin Fournier and Matthew Riemer and Pin-Yu Chen and Amal Zouaq and Payel Das and Sarath Chandar},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2024}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{Jiang2024WildTeamingAS,
  title={WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models},
  author={Liwei Jiang and Kavel Rao and Seungju Han and Allyson Ettinger and Faeze Brahman and Sachin Kumar and Niloofar Mireshghallah and Ximing Lu and Maarten Sap and Yejin Choi and Nouha Dziri},
  journal={ArXiv},
  year={2024}
}

@article{gema2024mmlur,
  title={Are We Done with MMLU?},
  author={Gema, Aryo Pradipta and Leang, Joshua Ong Jun and Hong, Giwon and Devoto, Alessio and Mancino, Alberto Carlo Maria and Saxena, Rohit and He, Xuanli and Zhao, Yu and Du, Xiaotang and Madani, Mohammad Reza Ghasemi and others},
  journal={arXiv preprint arXiv:2406.04127},
  year={2024}
}

@article{Hendrycks2020MeasuringMM,
  title={Measuring Massive Multitask Language Understanding},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Xiaodong Song and Jacob Steinhardt},
  journal={ArXiv},
  year={2020}
}

@article{alain2016understanding,
  title={Understanding intermediate layers using linear classifier probes},
  author={Alain, Guillaume},
  journal={arXiv preprint arXiv:1610.01644},
  year={2016}
}

@article{gromov2024unreasonable,
  title={The unreasonable ineffectiveness of the deeper layers},
  author={Gromov, Andrey and Tirumala, Kushal and Shapourian, Hassan and Glorioso, Paolo and Roberts, Daniel A},
  journal={arXiv preprint arXiv:2403.17887},
  year={2024}
}