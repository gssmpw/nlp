[
  {
    "index": 0,
    "papers": [
      {
        "key": "bai2022training",
        "author": "Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan",
        "title": "Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"
      },
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      },
      {
        "key": "li2024safety",
        "author": "Li, Shen and Yao, Liuyi and Zhang, Lan and Li, Yaliang",
        "title": "Safety Layers in Aligned Large Language Models: The Key to LLM Security"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "wei2023jailbreak",
        "author": "Wei, Jason and et al.",
        "title": "Jailbreaking Large Language Models via Prompt Engineering"
      },
      {
        "key": "carlini2023aligned",
        "author": "Carlini, Nicholas and et al.",
        "title": "Aligned but Unsafe: Investigation of Jailbreaks in AI Systems"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "inan2023llama",
        "author": "Hakan Inan and Kartikeya Upasani and Jianfeng Chi and Rashi Rungta and Krithika Iyer and Yuning Mao and Michael Tontchev and Qing Hu and Brian Fuller and Davide Testuggine and Madian Khabsa",
        "title": "Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "luo2024pace",
        "author": "Luo, Jinqi and Ding, Tianjiao and Chan, Kwan Ho Ryan and Thaker, Darshan and Chattopadhyay, Aditya and Callison-Burch, Chris and Vidal, Ren{\\'e}",
        "title": "PaCE: Parsimonious Concept Engineering for Large Language Models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "qiu2024spectral",
        "author": "Qiu, Yifu and Zhao, Zheng and Ziser, Yftah and Korhonen, Anna and Ponti, Edoardo M and Cohen, Shay B",
        "title": "Spectral Editing of Activations for Large Language Model Alignment"
      }
    ]
  }
]