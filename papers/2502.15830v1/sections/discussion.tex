\section{Discussion}

\subsection{Mitigating Over-Deletion}
\label{subsec:mitigating_over-deletion}

\revise{Current pre-training defenses all suffer from over-deletion (i.e., causing FPR), and \ours{} is no exception. However, \ours{} performs significantly better than baselines, achieving 100\% recall while maintaining a low FPR. Additionally, the results in RQ2 demonstrate that \ours{} can maintain the overall model performance.
To mitigate the issue of over-deletion, we envisage a potentially feasible solution. The dataset purified by \ours{} can be used to train a clean NCM, which can then predict the labels of candidate poisoned samples. Ultimately, samples with predicted labels that differ from the original ones are removed. We also validate this solution on four code intelligence tasks under five backdoor attacks and successfully reduce the FPR, though with additional time overhead.
}

\subsection{Potential Limitations of Our Work}
\label{subsec:potential_limitation}

\revise{The potential limitations of our work may mainly include the following two aspects.} 
\revise{First, as mentioned in Section~\ref{sec:threat_model}, \ours{} is a pre-training defense. Therefore, \ours{} cannot reconstruct backdoor triggers, nor can it detect poisoned models. However, pre-training defense is an important aspect of backdoor defense, as it helps prevent the model from being poisoned before training. Additionally, \ours{} focuses on detecting triggers in code snippets and is not suitable for detecting triggers located in non-code parts (e.g., comments). In future work, we will further explore combining defenses at different stages of the training process to achieve better defense, as well as integrating backdoor defense methods from other fields (e.g., NLP) to detect triggers in various locations.}
\revise{Second, we assume that defenders have access to some clean samples. Thus, if clean samples are unavailable, the performance of \ours{} may decrease. We also show that clean samples are easily obtainable, and \ours{} only requires 2,000 clean samples to achieve effective detection. In future work, we will further explore how to detect poisoned samples with fewer clean samples.}
