\section{Background and related work}
\label{sec:background}
The field of graph signal processing ____ has emerged in the last decade to generalise digital signal processing methods, such as convolutional filters, to the graph domain. A graph, $\mathcal{G}(\mathcal{V}, \mathcal{E})$, is defined as a set of $N$ nodes, $v_i \in \mathcal{V}$ for $i = 1, \ldots, N$, and a set of $\mathcal{E}$ edges denoting the pairwise connections between them, $e_{ij} = (v_i, v_j) \in \mathcal{E}$, for $i = 1, \ldots, N$ and $j = 1, \ldots, N$. Graph signal processing focuses on analysing signals on graphs, where a multivariate signal on a graph is defined as $\mathbf{X} \in \mathbb{R}^{N\times c}$, which assigns a real-valued signal of $c$ channels to each node, $\mathbf{X}: \mathcal{V} \mapsto \mathbb{R}^c$.

Building on graph signal processing methods, graph deep learning ____ has generalised successful deep learning architectures, such as convolutional neural networks, to the graph domain ____. \Glspl{stgnn} refer to the class of deep learning architectures designed to analyse time-varying graph signals ____. \Glspl{stgnn} can be categorised into time-then-space ____ or time-and-space models ____, which denote separate or joint processing of the space and time dimensions, respectively. A notable example of a time-and-space \gls{stgnn} is the \gls{grnn}, which replaces the fully connected layers in a \gls{rnn} with graph convolutions ____. \Glspl{stgnn} have achieved state-of-the-art performance in tasks such as forecasting ____ and missing data imputation ____.

\glspl{stgnn} are inherently global models, sharing parameters across space and assuming a stationary process over time. Global \glspl{stgnn} can be used for zero-shot transfer and inductive learning on unseen graphs, however, they might fail to account for spatial variations in dynamics. Node embeddings have been recently introduced to learn these local effects in ST-GNNs ____. Whilst hybrid global-local models often outperform global architectures, recent research has focussed on improving their performance in an inductive setting using transfer learning ____.

Other imputation methods have been applied to time series, ranging from \gls{mf} methods ____ and their counterparts with graph and temporal regularisation ____, to deep learning techniques employing \glspl{rnn} ____, generative adversarial networks ____, transformers ____, or most recently denoising diffusion probabilistic models ____.