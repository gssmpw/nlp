\vspace{-3mm}
\section{Conclusion}
\label{sec:conclusion}
In this paper, we propose an occlusion-aware multi-modal pretraining framework for open-world 3D shape recognition. Our method uses synthetic 3D models to generate partial point clouds for pretraining, effectively reducing the training-testing domain gap and enhancing real-world recognition performance. Moreover, we introduce a Mamba-based architecture for point cloud processing, offering better performance with lower FLOPs and latency than Transformer-based networks. We hope our paper paves the way for future research on more realistic pretraining and computationally efficient models.

\vspace{1mm}
\noindent\textbf{Limitations.} Due to resource constraints, we have not been able to leverage Objaverse \cite{objaverse} - the largest dataset with nearly 800K 3D objects - for pretraining, which we believe could further enrich the learned latent space and enhance recognition performance. 