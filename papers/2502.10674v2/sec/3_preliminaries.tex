\section{Preliminaries}
\label{sec:preliminaries}
\vspace{1mm} \noindent\textbf{State Space Model}  
%A State Space Model (SSM) 
represents a continuous system that maps an input $x_{t}$ to an output $y_{t}$ via an implicit latent state $h_{t} \in \mathbb{R}^N$. S4 \cite{s4} introduces a discretized version for sequence-to-sequence transformation, defined as: 
\begin{equation} \label{eq:ssm}
h_{t} = \overline{\boldsymbol{A}} h_{t-1} + \overline{\boldsymbol{B}} x_{t},\qquad y_{t} = \boldsymbol{C}h_{t},
\end{equation}
where $\overline{\boldsymbol{A}}$ and $\overline{\boldsymbol{B}}$ are derived from the model parameters ($\boldsymbol{A}, \boldsymbol{B}, \boldsymbol{C}, \boldsymbol{\Delta}$) using zero-order hold discretization. 
As the update matrices $\overline{\boldsymbol{A}}, \overline{\boldsymbol{B}}, \boldsymbol{C}$ are shared across time steps, S4 achieves linear-time computation through a convolution kernel, though its capacity to capture dynamic input sequences is limited. To improve context awareness, the Selective SSM (S6) introduced in Mamba \cite{mamba} makes $\boldsymbol{B}, \boldsymbol{C}, \boldsymbol{\Delta}$ dependent on the input. To maintain near-linear time complexity, Mamba \cite{mamba} employs a hardware-aware implementation for S6, which we follow to ensure computational efficiency. For further details, please refer to \cite{mamba}.

\vspace{1mm} \noindent\textbf{Space-Filling Curves} %Space-filling curves
pass through every point in a high-dimensional space, preserving spatial proximity of the original structure. For point clouds, they can be defined as a bijective function \( \Phi: \mathbb{Z}^3 \to \mathbb{Z} \), mapping each \((x, y, z)\) coordinate to a position in a 1D sequence. Our DuoMamba leverages the Hilbert space-filling curve \cite{hilbert_curve} and its transposed variant (Trans-Hilbert) for their strong locality-preserving properties, ensuring that points close in 3D space remain adjacent in the sequence. This is especially valuable for point cloud processing, where points are inherently unordered, making it challenging for sequence models like S6 to capture geometric relationships. By establishing a meaningful order with Hilbert curves, we enable S6 to model spatial dependencies in point clouds more effectively.

\vspace{1mm} \noindent\textbf{Cross-Modal Contrastive Learning.}
\label{subsec:contrastive_learning}
CLIP \cite{2dclip} is a pioneering approach that employs cross-modal contrastive learning to align embeddings of the same concept across two modalities (\eg, a caption \textit{``this is a dog"} and an image of a dog) by pulling their representations closer in a shared-embedding space while pushing apart those of different concepts. Formally, for a batch of $B$ paired features from two modalities $M_1$ and $M_2$, represented as $\{(z_{i}^{M_1}, z_{i}^{M_2})\}_{i=1}^{B}$, the training objective is to minimize the contrastive loss $\mathcal{L}^{M_1 \leftrightarrow M_2}$, defined as: 
\begin{equation}
\label{eq:contrastive_loss}
\begin{aligned}
\mathcal{L}^{M_1 \leftrightarrow M_2} = -\frac{1}{2}(l^{M_1 \rightarrow M_2} + l^{M_2 \rightarrow M_1}),
\end{aligned}
\end{equation}
with $l^{M_1 \rightarrow M_2}$ and $l^{M_2 \rightarrow M_1}$ calculated as follows:
\begin{equation}
\begin{aligned}
    l^{M_1 \rightarrow M_2} &= \sum_{i=1}^{B} \log \frac{\exp(z_i^{M_1} \cdot z_i^{M_2} / \tau)}{\sum_{j=1}^{B} \exp(z_i^{M_1} \cdot z_j^{M_2} / \tau)}, \\ 
    l^{M_2 \rightarrow M_1} &= \sum_{i=1}^{B} \log \frac{\exp(z_i^{M_2} \cdot z_i^{M_1} / \tau)}{\sum_{j=1}^{B} \exp(z_i^{M_2} \cdot z_j^{M_1} / \tau)},    
\end{aligned}
\label{eq:component_loss}
\end{equation}
where \( \tau \) is a temperature parameter that controls the sharpness of the Softmax distributions during training.