[
  {
    "index": 0,
    "papers": [
      {
        "key": "linearattentionisallyouneed",
        "author": "Kwangjun Ahn and Xiang Cheng and Minhak Song and Chulhee Yun and Ali Jadbabaie and Suvrit Sra",
        "title": "Linear attention is (maybe) all you need (to understand transformer optimization)"
      },
      {
        "key": "heavytail1",
        "author": "Thanh Huy Nguyen and Umut Simsekli and Mert Gurbuzbalaban and Gael Richard",
        "title": "First Exit Time Analysis of Stochastic Gradient Descent Under Heavy-Tailed Gradient Noise"
      },
      {
        "key": "heavytail2",
        "author": "Umut Simsekli and Levent Sagun and Mert Gurbuzbalaban",
        "title": "A Tail-Index Analysis of Stochastic Gradient Noise in Deep Neural Networks"
      },
      {
        "key": "heavytail3",
        "author": "Umut Simsekli and Lingjiong Zhu and Yee Whye Teh and Mert Gurbuzbalaban",
        "title": "Fractional Underdamped Langevin Dynamics: Retargeting SGD with Momentum under Heavy-Tailed Gradient Noise"
      },
      {
        "key": "inprobsupreme",
        "author": "Eduard Gorbunov and Marina Danilova and Alexander Gasnikov",
        "title": "Stochastic Optimization with Heavy-Tailed Noise via Accelerated Gradient Clipping"
      },
      {
        "key": "heavytailedclassimbalance",
        "author": "Frederik Kunstner and Robin Yadav and Alan Milligan and Mark Schmidt and Alberto Bietti",
        "title": "Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models"
      },
      {
        "key": "HighProbAdaGConv",
        "author": "Savelii Chezhegov and Yaroslav Klyukin and ndrei Semenov and Aleksandr Beznosikov and Alexander Gasnikov and Skoltech Samuel Horvath and Martin Takac and Eduard Gorbunov",
        "title": "Gradient Clipping Improves AdaGrad when the Noise Is Heavy-Tailed"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "EfficientAdaptiveFederatedOptimization",
        "author": "Su Hyeong Lee and Sidharth Sharma and Manzil Zaheer and Tian Li",
        "title": "Efficient Adaptive Federated Optimization"
      },
      {
        "key": "inprobsupreme",
        "author": "Eduard Gorbunov and Marina Danilova and Alexander Gasnikov",
        "title": "Stochastic Optimization with Heavy-Tailed Noise via Accelerated Gradient Clipping"
      },
      {
        "key": "HeavyTailedNoisePaper",
        "author": "Jingzhao Zhang and Sai Karimireddy and Andreas Veit and Seungyeon Kim and Sashank Reddi and Sanjiv Kumar and Suvrit Sra",
        "title": "Why are Adaptive Methods Good for Attention Models?"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "EfficientAdaptiveFederatedOptimization",
        "author": "Su Hyeong Lee and Sidharth Sharma and Manzil Zaheer and Tian Li",
        "title": "Efficient Adaptive Federated Optimization"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "heavytail2",
        "author": "Umut Simsekli and Levent Sagun and Mert Gurbuzbalaban",
        "title": "A Tail-Index Analysis of Stochastic Gradient Noise in Deep Neural Networks"
      },
      {
        "key": "CentralClip",
        "author": "Anatoli Juditsky and Alexander Nazin and Arkadi Nemirovsky and Alexandre Tsybakov",
        "title": "Algorithms of Robust Stochastic Optimization Based on Mirror Descent Method"
      },
      {
        "key": "CentralClip5",
        "author": "Eduard Gorbunov and Marina Danilova and Innokentiy Shibaev and Pavel Dvurechensky and Alexander Gasnikov",
        "title": "High-Probability Complexity Bounds for Non-smooth Stochastic Convex Optimization with Heavy-Tailed Noise"
      },
      {
        "key": "highprobabilityunboundedvariance",
        "author": "Abdurakhmon Sadiev and Marina Danilova and Eduard Gorbunov and Samuel Horvath and Gauthier Gidel and Pavel Dvurechensky and Alexander Gasnikov and Peter Richtarik",
        "title": "High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance"
      },
      {
        "key": "highprobClip",
        "author": "Ashok Cutkosky and Harsh Mehta",
        "title": "High-probability bounds for Non-Convex Stochastic Optimization with Heavy Tails"
      },
      {
        "key": "CentralClip1",
        "author": "Ta Duy Nguyen and Thien Hang Nguyen and Alina Ene and Huy Le Nguyen",
        "title": "High Probability Convergence of Clipped-SGD Under Heavy-tailed Noise"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "HighProbAdaGConv",
        "author": "Savelii Chezhegov and Yaroslav Klyukin and ndrei Semenov and Aleksandr Beznosikov and Alexander Gasnikov and Skoltech Samuel Horvath and Martin Takac and Eduard Gorbunov",
        "title": "Gradient Clipping Improves AdaGrad when the Noise Is Heavy-Tailed"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "DiLoCoAsynchronous",
        "author": "Bo Liu and Rachita Chhaparia and Arthur Douillard and Satyen Kale and Andrei A. Rusu and Jiajun Shen and Arthur Szlam and Marc'Aurelio Ranzato",
        "title": "Asynchronous Local-SGD Training for Language Modeling"
      },
      {
        "key": "OpenDiLoCo",
        "author": "Sami Jaghouar and Jack Min Ong and Johannes Hagemann",
        "title": "OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication Training"
      },
      {
        "key": "DiLoCo",
        "author": "Arthur Douillard and Qixuan Feng and Andrei A. Rusu and Rachita Chhaparia and Yani Donchev and Adhiguna Kuncoro and Marc'Aurelio Ranzato and Arthur Szlam and Jiajun Shen",
        "title": "DiLoCo: Distributed Low-Communication Training of Language Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "heavytail2",
        "author": "Umut Simsekli and Levent Sagun and Mert Gurbuzbalaban",
        "title": "A Tail-Index Analysis of Stochastic Gradient Noise in Deep Neural Networks"
      },
      {
        "key": "CentralClip",
        "author": "Anatoli Juditsky and Alexander Nazin and Arkadi Nemirovsky and Alexandre Tsybakov",
        "title": "Algorithms of Robust Stochastic Optimization Based on Mirror Descent Method"
      },
      {
        "key": "CentralClip5",
        "author": "Eduard Gorbunov and Marina Danilova and Innokentiy Shibaev and Pavel Dvurechensky and Alexander Gasnikov",
        "title": "High-Probability Complexity Bounds for Non-smooth Stochastic Convex Optimization with Heavy-Tailed Noise"
      },
      {
        "key": "highprobabilityunboundedvariance",
        "author": "Abdurakhmon Sadiev and Marina Danilova and Eduard Gorbunov and Samuel Horvath and Gauthier Gidel and Pavel Dvurechensky and Alexander Gasnikov and Peter Richtarik",
        "title": "High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance"
      },
      {
        "key": "highprobClip",
        "author": "Ashok Cutkosky and Harsh Mehta",
        "title": "High-probability bounds for Non-Convex Stochastic Optimization with Heavy Tails"
      },
      {
        "key": "CentralClip1",
        "author": "Ta Duy Nguyen and Thien Hang Nguyen and Alina Ene and Huy Le Nguyen",
        "title": "High Probability Convergence of Clipped-SGD Under Heavy-tailed Noise"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "HeavyTailedNoiseModel",
        "author": "Unknown",
        "title": "Unknown"
      },
      {
        "key": "VarianceReductionHeavyTail",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "empirical1",
        "author": "Jonas Gehring and Michael Auli and David Grangier and Denis Yarats and Yann N Dauphin",
        "title": "Convolutional sequence to sequence learning"
      },
      {
        "key": "empirical2",
        "author": "Stephen Merity and Nitish Shirish Keskar and Richard Socher",
        "title": "Regularizing and Optimizing LSTM Language Models"
      },
      {
        "key": "empirical3",
        "author": "Matthew E Peters and Mark Neumann and Mohit Iyyer and Matt Gardner and Christopher Clark and Kenton Lee and Luke Zettlemoyer",
        "title": "Deep contextualized word representations"
      },
      {
        "key": "empirical5",
        "author": "Tomas Mikolov",
        "title": "Statistical Language Models based on Neural Networks"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "inprobsupreme",
        "author": "Eduard Gorbunov and Marina Danilova and Alexander Gasnikov",
        "title": "Stochastic Optimization with Heavy-Tailed Noise via Accelerated Gradient Clipping"
      },
      {
        "key": "HeavyTailedNoisePaper",
        "author": "Jingzhao Zhang and Sai Karimireddy and Andreas Veit and Seungyeon Kim and Sashank Reddi and Sanjiv Kumar and Suvrit Sra",
        "title": "Why are Adaptive Methods Good for Attention Models?"
      },
      {
        "key": "HighProbAdaGConv",
        "author": "Savelii Chezhegov and Yaroslav Klyukin and ndrei Semenov and Aleksandr Beznosikov and Alexander Gasnikov and Skoltech Samuel Horvath and Martin Takac and Eduard Gorbunov",
        "title": "Gradient Clipping Improves AdaGrad when the Noise Is Heavy-Tailed"
      },
      {
        "key": "highprobClip",
        "author": "Ashok Cutkosky and Harsh Mehta",
        "title": "High-probability bounds for Non-Convex Stochastic Optimization with Heavy Tails"
      },
      {
        "key": "theoretical1",
        "author": "Aditya Krishna Menon and Ankit Singh Rawat and Sashank J Reddi and Sanjiv Kumar",
        "title": "Can gradient clipping mitigate label noise?"
      },
      {
        "key": "theoretical4",
        "author": "Bohang Zhang and Jikai Jin and Cong Fang and Liwei Wang",
        "title": "Improved Analysis of Clipping Algorithms for Non-convex Optimization"
      },
      {
        "key": "GradClipCentralGeomPerspective",
        "author": "Xiangyi Chen and Zhiwei Steven Wu and Mingyi Hong",
        "title": "Understanding Gradient Clipping in Private SGD: A Geometric Perspective"
      },
      {
        "key": "RevisitGradClipModern",
        "author": "Anastasia Koloskova and Hadrien Hendrikx and Sebastian U Stich",
        "title": "Revisiting gradient clipping: Stochastic bias and tight convergence guarantees"
      },
      {
        "key": "clippedsgd_online_estimate",
        "author": "Aniket Das and Dheeraj Mysore Nagaraj and Soumyabrata Pal and Arun Suggala and Prateek Varshney",
        "title": "Near-Optimal Streaming Heavy-Tailed Statistical Estimation with Clipped SGD"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "CentralClip5",
        "author": "Eduard Gorbunov and Marina Danilova and Innokentiy Shibaev and Pavel Dvurechensky and Alexander Gasnikov",
        "title": "High-Probability Complexity Bounds for Non-smooth Stochastic Convex Optimization with Heavy-Tailed Noise"
      },
      {
        "key": "CentralClip4",
        "author": "Nikita Puchkin and Eduard Gorbunov and Nikolay Kutuzov and Alexander Gasnikov",
        "title": "Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems"
      },
      {
        "key": "CentralClip3",
        "author": "Jiujia Zhang and Ashok Cutkosky",
        "title": "Parameter-free Regret in High Probability with Heavy Tails"
      },
      {
        "key": "CentralClip2",
        "author": "Zijian Liu and Jiawei Zhang and Zhengyuan Zhou",
        "title": "Breaking the Lower Bound with (Little) Structure: Acceleration in Non-Convex Stochastic Optimization with Heavy-Tailed Noise"
      },
      {
        "key": "CentralClip1plus",
        "author": "Ta Duy Nguyen and Thien Hang Nguyen and Alina Ene and Huy Le Nguyen",
        "title": "Improved Convergence in High Probability of Clipped Gradient Methods with Heavy Tailed Noise"
      },
      {
        "key": "CentralBddVarClip",
        "author": "Daniela A. Parletta and Andrea Paudice and Massimiliano Pontil and Saverio Salzo",
        "title": "High Probability Bounds for Stochastic Subgradient Schemes with Heavy Tailed Noise"
      },
      {
        "key": "CentralBddVarClip1",
        "author": "Shaojie Li and Yong Liu",
        "title": "High Probability Guarantees for Nonconvex Stochastic Gradient Descent with Heavy Tails"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "GradClipCentralGeomPerspective",
        "author": "Xiangyi Chen and Zhiwei Steven Wu and Mingyi Hong",
        "title": "Understanding Gradient Clipping in Private SGD: A Geometric Perspective"
      },
      {
        "key": "RevisitGradClipModern",
        "author": "Anastasia Koloskova and Hadrien Hendrikx and Sebastian U Stich",
        "title": "Revisiting gradient clipping: Stochastic bias and tight convergence guarantees"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "Debias1",
        "author": "Sarit Khirirat and Eduard Gorbunov and Samuel Horv\u00e1th and Rustem Islamov and Fakhri Karray and Peter Richtarik",
        "title": "Clip21: Error Feedback for Gradient Clipping"
      },
      {
        "key": "Debias2",
        "author": "Xinwei Zhang and Zhiqi Bu and Zhiwei Steven Wu and and Mingyi Hong",
        "title": "Differentially private sgd without clipping bias: An error-feedback approach"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "angulardependencerestrictive",
        "author": "Jiang Qian and Yuren Wu and Bojin Zhuang and Shaojun Wang and Jing Xiao",
        "title": "Understanding Gradient Clipping In Incremental Gradient Methods"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "symmetricnoise_distributed",
        "author": "Mingrui Liu and Zhenxun Zhuang and Yunwei Lei and Chunyang Liao",
        "title": "A Communication-Efficient Distributed Gradient Clipping Algorithm for Training Deep Neural Networks"
      }
    ]
  }
]