

\vspace{-1.5em}
\section{Introduction}
\vspace{-0.5em}
The past decades have witnessed the development of Animation as an artistic form, which has gained great popularity worldwide. The current workflow of animation creation is labor-intensive, and the growing demands of animation from the market are causing animation studios to fall short of hands, bringing severe problems to the industry.

The most manual labor-intensive procedure in animation production is sketch colorization, and animators working on colorization also take up the largest share among all employees in the animation production industry. To reduce the human labor needed and to automate the animation production, machine learning algorithms have been applied for sketch colorization \cite{ZhangLW0L18, LeeKLKCC20, zouSA2019sketchcolorization, li2022eliminating, zhang2021user}. However, current methods are still not optimal for real-world production pipelines: Text-based colorization methods\cite{controlnet-iccv, zabari2023diffusing} fail to provide accurate guidance on the color and style information of the images. User-guided methods \cite{zhang2021user, cho2023guiding} still involve manual operation in the process, making them less efficient. Image referenced methods \cite{yan2024colorizediffusion, animediffusion} can be seamlessly integrated into the current pipeline, but the spatial mismatches between reference images and sketches are causing severe artifacts and unexpected extra objects, which is termed as spatial entanglement in \cite{yan2024colorizediffusion} and shown in Figure \ref{entanglement}.
%but they suffer from spatial mismatches between reference images and sketches, causing severe artifacts and unexpected extra objects, which is termed as spatial alignment in \cite{yan2024colorizediffusion} and shown in Figure \ref{entanglement}.

To build a sketch colorization framework that meets the requirements of the real-world animation production pipeline, we start with the observation of the manual sketch colorization workflow in real-world animation production. As is shown in Figure \ref{pipeline}, the workflow consists of the following key steps: Firstly, character designers design the characters as references. Secondly, senior animators draw the sketches for each frame. Thirdly, animators colorize the figures in the sketches according to the character designs. Finally, animators colorize the background of the sketches and finish the whole colorized frames. 

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/entanglement.pdf}
    \vspace{-1.5em}
    \caption{Illustration of spatial entanglement. We use red rectangles to highlight the spatial entangled artifacts in the result of the IP-Adapter baseline, where additional arms appear unexpectedly, and the model mistakenly synthesizes long hair.}
    \label{entanglement}
    \vspace{-1.5em}
\end{figure}
\setcounter{figure}{3}
%such as sketch colorization \cite{ZhangLW0L18, LeeKLKCC20, zouSA2019sketchcolorization, li2022eliminating}, sketch inbetween \cite{harvey2020robust, siyao2023deep} and even generating animation clip directly \cite{huang2024lvcd}. However, current methods are 

Following our observation, we designed a diffusion-based framework to mimic the sketch colorization workflow step-by-step. To be smoothly integrated into the current production workflow, the proposed framework leverages a sketch image as the spatial reference and an RGB image as the color reference. Specifically, we use the high dimensional local tokens extracted by a feature extractor as reference embeddings to maintain the semantic information and adopt a multi-layer sketch encoder for precise spatial control of the background embeddings. %To enhance the network's ability to distinguish foreground and background for colorization, 
To enable the separate colorization of foreground and background regions, we design a novel split cross-attention mechanism, where spatial masks are used to segment figures as foreground with the rest of the images as background, and corresponding LoRA weights are trained to modify the embeddings for keys and values within cross-attention layers. This design allows the diffusion model to integrate information from foreground and background independently, preventing interference and eliminating the need to adjust the well-trained backbone weights. During inference, we implement a switchable LoRA mechanism %controlled by spatial masks, 
that provides precise control over the colorization process and enables different inference modes for various scenarios without changing model weights.

 %we design a novel split cross-attention mechanism for training and a switchable LoRA for inference. The separation of foreground and background fulfills the need of the animation production industry and further solves the spatial entanglement \cite{yan2024colorizediffusion} widely observed in exemplar-based sketch colorization methods, which is illustrated in Figure \ref{entanglement}.

We train our model on 4.8M images and test on various scenarios. Experiments show that mimicking the real-world animation creation workflow yields several advantages. In qualitative analyses, our method synthesizes high-quality results loyally representing the color distribution of the reference images and free from artifacts and spatial entanglements. %, but is also capable of generating separate colorizing results of foreground and backgrounds, which is a desired feature in colorization workflow.  
Quantitative comparisons also validate the superiority of the proposed method over existing methods by common criteria and benchmarks. What's more, user studies illustrate that artists prefer our method subjectively. 

In summary, our contributions are as follows: (1) We propose an image-referenced sketch colorization framework that can synthesize high-quality results free from artifacts and spatial entanglement by mimicking the animation production workflow. (2) We design a novel split cross-attention mechanism that enables the separate colorization of foreground and background in a single forward pass and the switchable LoRA module that allows users to switch colorization modes during inference. (3) Experiments show that our method outperforms existing methods in qualitative/quantitative comparisons and is preferred by human users in perceptive user study.




\begin{comment}
\vspace{-0.5em}
\begin{itemize}
\setlength{\itemsep}{0.5pt}
\setlength{\parsep}{0pt}
\setlength{\parskip}{0pt}

\item We proposed a sketch colorization framework by mimicking the professional animation production workflow, which takes color image as reference and colorize figures (foreground) and background separately, and can be seamlessly integrated to the real-world colorization pipeline.

\item We designed novel split cross attention and switchable LoRA to separate foreground and background. Together with the use of high-dimensional local tokens extracted from reference images, the framework is able to generate high quality colorization results free from artifacts and spatial entanglement.

\item Qualitative evaluation, quantitative comparison and user study are conducted to show that our method outperforms previous methods. Ablation study demonstrates the effectiveness of each component.
\end{itemize}
\end{comment}

