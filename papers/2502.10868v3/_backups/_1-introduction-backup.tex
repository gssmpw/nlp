\section{Introduction}
\label{sec:introduction}

% point that using LLM in legal domain holds immense potential
The application of large language models (LLMs) to legal domains holds immense potential, particularly in information retrieval and question answering.
%
Several works have implemented LLM-based solutions to enhance the legal work experience. 
%
For instance, \cite{lexisnexis,thomsonreutersAIpoweredLegal} used Retrieval Augmented Generation (RAG) to develop a reliable legal assistant chatbot, while \cite{leewayhertzAgentsLegal} proposed agentic workflows to address multiple legal problems within a single framework. 
%
Despite these advancements, there remains significant room for improvement, particularly in addressing LLM limitations and localization challenges, which pose difficulties in developing such complex systems \cite{Dahl_2024,magesh2024hallucinationfreeassessingreliabilityleading}


% drill down from general legal problem -> Thai legal problem
In addition to the aforementioned challenges in developing an LLM-based legal system, adapting these frameworks to localized legal domains is also a challenging task. 
%
Although frameworks like RAG can be plugged in directly to any document \cite{originalRAG}, there still exists various design choices with various tradeoffs which significantly affect the overall performance of the system. 
%
For example, Thanoy \footnote{https://iapp.co.th/thanoy} \cite{thanoy}, a Thai RAG-based legal assistant system, still suffers from several errors, such as incorrect legislation retrieval and hallucinations.
% as shown in \autoref{fig:thanoy}.
% cherry pick error case


% \begin{figure}[!ht]
%     \centering
%     \includegraphics[width=0.5\linewidth]{}
%     \caption{Caption}
%     \label{fig:thanoy}
% \end{figure}

% make this more specific
% challenge/limitation of current LLM system - specifically in Thai
% \st{Leveraging LLMs effectively in this complex domain requires overcoming significant challenges.
% The challenges of implementing LLM-based system in Thai legal domain includes the challenge of obtaining Thai legal documents due to the .}

\textcolor{orange}{To address the concerns over localization issues, our work suggested that the}\st{The} challenges of implementing Thai LLM-based legal system are threefold. 
First, Thai laws are structured in a format that is not applicable to conventional text chunking methods, which is important, especially when the system is implemented using techniques like RAG.
%
The structure of the Thai legal system is organized in a multi-layered hierarchy and there exists cross-reference between sections of the legal acts and codes.
% \st{Another obstacle to the implementation of such system is the lack of tailored components, especially when the system is implemented using technique like Retrieval-Augmented Generation (RAG), suitable for the structure of Thai legal system, where legislation is organized in a multi-layered hierarchy and there exists cross-reference between sections of the legal acts and codes as well.}
% \st{Furthermore}
Second, the evaluation of LLM-based system also poses some difficulties in terms of the limitation of the available Thai legal corpora, the retrieval benchmark metrics and the multi-aspect of end-to-end evaluation.
Lastly, with the rise of long-context LLMs, there also exists a question of whether these LLMs with immense context length can replace the traditional RAG system.

% this paper main focus
In this paper, we tackle these challenges. 
Focusing on the Thai legal domain, specifically on financial law, we first developed a scraper that can retrieve the raw content of interested legal acts and codes and pre-process the obtained content in a proper manner that retains the structure of the documents. 
Next, we introduce a novel components in RAG system including hierarchical chunking approach tailored to the structure of Thai legal documents, which aims to preserve the inherent hierarchy, ensuring that retrieved chunks are both comprehensive and relevant, and a referencer component tasked to retrieve any additional relevant documents that are referenced in the initially obtained documents. 
These components are crafted with the purpose of making the system more suitable to the domain and increasing the explainability of the system which is of major concern in this area. \st{We also show that using our chunking method, the model can reference the relevant law section more effectively and more complete.}\textcolor{orange}{Lastly, the emergence of Long-Context LLMs (LCLMs) raises critical considerations for their application in the Thai legal domain. Specifically, it challenges the effectiveness and efficiency of traditional Retrieval-Augmented Generation (RAG) systems. The primary challenge lies in determining how to adapt LCLMs to handle the unique structure of Thai legal texts while assessing their performance and reliability in comparison to RAG systems, particularly in terms of retrieval accuracy, scalability, and contextual consistency.}

% address second issue: no dataset
\st{Furthermore, to evaluate our approach}\textcolor{orange}{To address the aforementioned challenges}, we introduce WangchanX Legal ThaiCCL Rag Dataset, a novel dataset comprising 35 annotated legislation pertaining to Thai financial law domain. 
% add a paragraph to address second issue - no benchmark approach
\textcolor{orange}{We also design an approach to evaluate ability of the generated answer for this dataset inspired from \cite{needleinahaystack}} and \cite{}.
We benchmark various RAG settings on this dataset, comparing:
\begin{enumerate}
    \item Parametric Knowledge \textcolor{orange}{ - Using zero-shot setting allowing the model to answer the question soley based on the model parameters.}
    \item Naive RAG \textcolor{orange}{ - A standard RAG setup with recursive chunking strategy.}
    \item RAG with our hierarchical chunking strategy \textcolor{orange}{ - A standard RAG setup with our thai-legal-specific chunking strategy.}
    \item RAG with golden context - providing the ideal retrieval scenario.
    \item Long-Context LLM\st{ (LCLM)}.
\end{enumerate}

% (1) Parametric Knowledge\textcolor{orange}{ - Using zero-shot setting allowing the model to answer the question soley based on the model parameters.}, 
% (2) Naive RAG\textcolor{orange}{ - A standard RAG setup with recursive chunking strategy.},
% (3) RAG with our hierarchical chunking strategy\textcolor{orange}{ - A standard RAG setup with our thai-legal-specific chunking strategy.}, 
% (4) RAG with golden context, providing the ideal retrieval scenario, 
% and (5) Long-Context LLM\st{ (LCLM)}.

% experiment results answer third issue - LCLM as well as first - effect of using a bad chunking method
Through these experiments, we aim to demonstrate the critical role of the introduced components in RAG in enhancing the performance of system within the intricate landscape of Thai legal documents as well as inspecting the capability of long-context LLMs in such specialized domain as well. 
Apart from the main experiment, excessive analysis is also carried out to present multiple aspect of the performance of the system.
Our findings provide valuable insights into the role of the novel components introduced in RAG system, the potential of long-context LLMs\textcolor{orange}{, and}\st{ alongside} the limitations \textcolor{orange}{of the current systems} that still hinders \st{the system} from being adopted into real-world usage and should be focused on in future works.

Finally, we summarize our main contributions as follows:
\begin{enumerate}
    \item {We propose WangchanX Legal ThaiCCL Rag Dataset, a novel dataset comprising 35 annotated legislation pertaining to Thai financial law domain.}
    \item {We propose evaluation gap in Thai legal domain on retrieval and generation task, specifically on RAG setup.}
    % 1. coverage score mod on legal domain
    % 2. citation
    % 3. hallucination
    % legal reasoning -> how to eval?
    % \item \textcolor{blue}{Findings from Thai legal domain (from this setup)}
    \item We show several limitation in addition to our setup. Our result demonstrates that, despite leveraging strong LLM, we found that xxx and yyy.
\end{enumerate}
% trinity of knowledge
% recipe -> new approach, problem modelling
% problem modelling -> new problem, experiment setup
% observation -> knowledge contribution (set experiment, results validation)

% One such challenge is the inherent hierarchical structure of legal documents, which necessitates careful consideration when applying techniques like Retrieval-Augmented Generation (RAG). This is particularly relevant for the Thai legal system, where legislation is organized in a multi-layered hierarchy. Traditional text chunking methods, often employed in RAG pipelines, can disrupt this inherent structure, leading to information loss and hindering accurate retrieval and response generation.

% This paper addresses these challenges by investigating the effectiveness of applying RAG and long-context LLMs to the Thai legal domain, specifically focusing on financial law. We introduce a novel hierarchical chunking approach tailored to the structure of Thai legal documents. This method aims to preserve the inherent hierarchy, ensuring that retrieved chunks are both comprehensive and relevant. To evaluate our approach, we introduce WangchanX, a novel dataset comprising 36 annotated legal documents pertaining to Thai financial law domain. We benchmark various RAG settings on this dataset, comparing: (1) Parametric Knowledge, (2) Naive RAG, (3) RAG augmented with our custom chunking method, (4) RAG with gold context, providing the ideal retrieval scenario, and (5) a long-context LLM. Through these experiments, we aim to demonstrate the critical role of hierarchical chunking in enhancing the performance of RAG systems within the intricate landscape of Thai legal documents. Our findings provide valuable insights into optimizing information access and retrieval within legal systems characterized by complex hierarchical structures.