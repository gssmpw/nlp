@article{Han24,
author = {Han, Yanjun and Weissman, Tsachy and Zhou, Zhengyuan},
title = {Optimal No-Regret Learning in Repeated First-Price Auctions},
journal = {Operations Research},
year = {2024}
}


@inproceedings{Sch23,
 author = {Schneider, Jon and Zimmert, Julian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {51862--51880},
 publisher = {Curran Associates, Inc.},
 title = {Optimal cross-learning for contextual bandits with unknown context distributions},
 volume = {36},
 year = {2023}
}


@InProceedings{GraphAlon15,
  title = 	 {Online Learning with Feedback Graphs: Beyond Bandits},
  author = 	 {Alon, Noga and Cesa-Bianchi, Nicolò and Dekel, Ofer and Koren, Tomer},
  booktitle = 	 {Proceedings of The 28th Conference on Learning Theory},
  pages = 	 {23--35},
  year = 	 {2015},
  editor = 	 {Grünwald, Peter and Hazan, Elad and Kale, Satyen},
  volume = 	 {40},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Paris, France},
  month = 	 {03--06 Jul},
  publisher =    {PMLR},
}
@article{MAS24,
  title={Stochastic contextual bandits with graph feedback: from independence number to MAS number},
  author={Wen, Yuxiao and Han, Yanjun and Zhou, Zhengyuan},
  journal={arXiv preprint arXiv:2402.18591},
  year={2024}
}


@inproceedings{MS11,
 author = {Mannor, Shie and Shamir, Ohad},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {From Bandits to Experts: On the Value of Side-Observations},
 volume = {24},
 year = {2011}
}

@InProceedings{LuoGraph23,
  title = 	 {Improved High-Probability Regret for Adversarial Bandits with Time-Varying Feedback Graphs},
  author =       {Luo, Haipeng and Tong, Hanghang and Zhang, Mengxiao and Zhang, Yuheng},
  booktitle = 	 {Proceedings of The 34th International Conference on Algorithmic Learning Theory},
  pages = 	 {1074--1100},
  year = 	 {2023},
  editor = 	 {Agrawal, Shipra and Orabona, Francesco},
  volume = 	 {201},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {20 Feb--23 Feb},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v201/luo23a/luo23a.pdf},
  abstract = 	 {We study high-probability regret bounds for adversarial $K$-armed bandits with time-varying feedback graphs over $T$ rounds. For general strongly observable graphs, we develop an algorithm that achieves the optimal regret $\widetilde{\mathcal{O}}((\sum_{t=1}^T\alpha_t)^{\frac{1}{2}}+\max_{t\in[T]}\alpha_t)$ with high probability, where $\alpha_t$ is the independence number of the feedback graph at round $t$. Compared to the best existing result (Neu, 15) which only considers graphs with self-loops for all nodes, our result not only holds more generally, but importantly also removes any $\text{poly}(K)$ dependence that can be prohibitively large for applications such as contextual bandits. Furthermore, we also develop the first algorithm that achieves the optimal high-probability regret bound for weakly observable graphs, which even improves the best expected regret bound of (Alon et al., 2015) by removing the $\mathcal{O}(\sqrt{KT})$ term with a refined analysis. Our algorithms are based on the online mirror descent framework, but importantly with an innovative combination of several techniques. Notably, while earlier works use optimistic biased loss estimators for achieving high-probability bounds, we find it important to use a pessimistic one for nodes without self-loop in a strongly observable graph.}
}

@misc{neu2015,
      title={Explore no more: Improved high-probability regret bounds for non-stochastic bandits}, 
      author={Gergely Neu},
      year={2015},
      eprint={1506.03271},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@inproceedings{Understanding2021,
 author = {Chen, Houshuang and Huang, zengfeng and Li, Shuai and Zhang, Chihao},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {24659--24669},
 publisher = {Curran Associates, Inc.},
 title = {Understanding Bandits with Graph Feedback},
 volume = {34},
 year = {2021}
}

@inproceedings{Bal19,
 author = {Balseiro, Santiago and Golrezaei, Negin and Mahdian, Mohammad and Mirrokni, Vahab and Schneider, Jon},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Contextual Bandits with Cross-Learning},
 volume = {32},
 year = {2019}
}

@InProceedings{lykouris20a,
  title = 	 {Feedback graph regret bounds for Thompson Sampling and UCB},
  author =       {Lykouris, Thodoris and Tardos, \'Eva and Wali, Drishti},
  booktitle = 	 {Proceedings of the 31st International Conference  on Algorithmic Learning Theory},
  pages = 	 {592--614},
  year = 	 {2020},
  editor = 	 {Kontorovich, Aryeh and Neu, Gergely},
  volume = 	 {117},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {08 Feb--11 Feb},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v117/lykouris20a/lykouris20a.pdf},
  abstract = 	 {We study the stochastic multi-armed bandit problem with the graph-based feedback structure introduced by Mannor and Shamir. We analyze the performance of the two most prominent stochastic bandit algorithms, Thompson Sampling and Upper Confidence Bound (UCB), in the graph-based feedback setting. We show that these algorithms achieve  regret guarantees that combine the graph structure and the gaps between the means of the arm distributions. Surprisingly this holds despite the fact that these algorithms do not explicitly use the graph structure to select arms; they observe the additional feedback but do not explore based on it. Towards this result we introduce a <em>layering technique</em> highlighting the commonalities in the two algorithms.}
}

@inproceedings{backgroundref_Kale_2010,
 author = {Kale, Satyen and Reyzin, Lev and Schapire, Robert E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Non-Stochastic Bandit Slate Problems},
 volume = {23},
 year = {2010}
}

@inproceedings{background_Schapire_2010,
author = {Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E.},
title = {A contextual-bandit approach to personalized news article recommendation},
year = {2010},
isbn = {9781605587998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/1772690.1772758},
booktitle = {Proceedings of the 19th International Conference on World Wide Web},
pages = {661–670},
numpages = {10},
keywords = {contextual bandit, exploration/exploitation dilemma, personalization, recommender systems, web service},
location = {Raleigh, North Carolina, USA},
series = {WWW '10}
}

@article{background_villar_2015,
author = {Sof{\'i}a S. Villar and Jack Bowden and James Wason},
title = {{Multi-armed Bandit Models for the Optimal Design of Clinical Trials: Benefits and Challenges}},
volume = {30},
journal = {Statistical Science},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {199 -- 215},
keywords = {Gittins index, multi-armed bandit, patient allocation, response adaptive procedures, Whittle index},
year = {2015},
doi = {10.1214/14-STS504},
}

@article{Han2020Adversarial,
  title={Learning to Bid Optimally and Efficiently in Adversarial First-price Auctions},
  author={Yanjun Han and Zhengyuan Zhou and Aaron Flores and Erik Ordentlich and Tsachy Weissman},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.04568},
}


@misc{Aiauction,
      title={No-regret Learning in Repeated First-Price Auctions with Budget Constraints}, 
      author={Rui Ai and Chang Wang and Chenchen Li and Jinshan Zhang and Wenhan Huang and Xiaotie Deng},
      year={2022},
      eprint={2205.14572},
      archivePrefix={arXiv},
      primaryClass={cs.GT},
}

@InProceedings{WangAuction,
  title = 	 {Learning to Bid in Repeated First-Price Auctions with Budgets},
  author =       {Wang, Qian and Yang, Zongjun and Deng, Xiaotie and Kong, Yuqing},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {36494--36513},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/wang23ao/wang23ao.pdf},
}

@misc{Huang2025,
      title={High Probability Bound for Cross-Learning Contextual Bandits with Unknown Context Distributions}, 
      author={Ruiyuan Huang and Zengfeng Huang},
      year={2025},
      eprint={2410.04080},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}