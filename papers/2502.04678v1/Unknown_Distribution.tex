\section{The Unknown Distribution Setting}

Here we consider the situation where the context distribution $\nu$ is unknown. The basic idea is samilar to the situation where the  context distribution $\nu$ is known. We will form an importance-weighted estimator and feed the importance-weighted estimator to the standard FTRL subroutine to generate the playing distribution.

However, the unknown distribution situation is significantly more complicated than the known distribution situation. The main difficulty is that the importance $w_t(a)$ in the known distribution setting is now uncomputable  due to the distribution is now unknown. 
%
Recall that $p_{t,c_s}(\NodeIn(a)$ means  $\sum_{a' \in \NodeIn(a)} p_{t,c_s}(a')$.
%
A natural temptation is to replace the expected importance $w_t(a)$ with the empirical importance  $\frac{1}{t} \sum_{s=1}^t  p_{t,c_s}(\NodeIn(a))$.
%
However, this temptation does not work. The problem with the empirical importance $\frac{1}{t} \sum_{s=1}^t p_{t,c_s}(\NodeIn(a))$ is that the probability $p_t$ of playing arms in round $t$ is impacted by contexts $\{c_s\}_{s < t}$ in previous rounds. Thus, the  probability vector $p_t$ is not independent of the contexts $c_s$ for $s<t$, and the empirical importance  $\frac{1}{t} \sum_{s=1}^t  p_{t,c_s}(\NodeIn(a))$ has no concentration guarantees.

To overcome this difficulty, we employ techniques from \citet{Sch23}. We divide the time horizon $[T]$ into $T/L$ epochs, denoted as $\{\Time_e\}_{e = 1}^{L}$. All epochs have the same length $|\Time_e| = L$ . We also decouple the probability of playing arms from the probability of observing losses. During each epoch $e$, at each round $t \in \Time_e$, the probability $p_t$ of playing arms is determined by the FTRL subroutine as usual, while the probability of observing losses $ws_e$ remains unchanged in the entire epoch. This is possible because the probability $p_t$ only changes a constant factor within one epoch.

Since the probability $w_e$ of observing losses remains unchanged throughout the entire epoch, we only need to estimate the probability $w_e$ of observing losses once during epoch $e$. The fact that we only estimate the probability $w_e$ once per epoch allows us to obtain a number of independent samples of epoch length $L$  to construct an efficient estimator $\widehat{w}_e$. We use $\widehat{w}_e$ as the importance to form an importance-weighted  estimator $\widehat{\ell}$, and feed this estimator $\widehat{\ell}$ to the FTRL subroutine to compute the probability $p_t$ of playing arms. 

\subsection{The Algorithm in the Unknown Distribution Setting}
Our algorithm is similar to the algorithm in ~\citet{Sch23}. The main difference is that we utilize the graphical structure in constructing the importance. 
%

% FTRL, not p_t but q_t
In each round $t$, our algorithm generates a distribution using an FTRL subroutine: \[p_{t,c} = \argmin_{p \in \Delta([K])} \ip{p, \sum_{s=1}^{t-1} \widehat{\ell}_{s,c}} - \frac{1}{\eta} F(p)\]
for each context $c$, where $F(p) = \sum_{i=1}^K p_i \log(p_i)$ is the unnormalized negative entropy, $\eta$ is the learning rate, and $\widehat{\ell}$ are loss estimates to be defined later.
%
Due to some technical issues which we specify later, our algorithm does not sample the action $a_t$ played in round $t$ directly from $p_t$ but from a distribution $q_t$, which will be defined later.

% epoch, snaposhot
As mentioned at the beginning of this section, the algorithm divides the time horizon $[T]$ into $T/L$ epochs of equal length $L$, where $L$ is a tunable parameter. Let $\Time_e$ denote the set of rounds in the $e$-th epoch. At the end of each epoch, the algorithm takes a single snapshot of the underlying FTRL distribution $p_t$ for each context and arm. That is, the algorithm takes
\[s_{e+2,c}(a) = p_{eL,c}(a)\]
and
\[s_{1, c}(a) = s_{2, c}(a) = \frac{1}{K}.\]
The index of the snapshot $s_{e+2}$ for epoch $e$ is $e+2$ because the snapshot $s_{e+2}$ is used in epoch $e+2$.

%reject-sampling
As mentioned at the beginning of this section, our algorithm keeps the probability of observing losses unchanged within epoch $e$. 
%
Specifically, for every round $t \in \Time_e$, the algorithm observes the loss of arm $a$ with probability $w_e(a)=\mathbb{E}_{c \sim \nu}\left[ \sum_{a' \rightarrow a} s_{e,c}(a') / 2\right]$. Note that here $s_e$ is the snapshot of the probability distribution at the end of epoch $e-2$, i.e., $s_{e,c}(a) = p_{(e-2)L,c}(a)$.
%
We guarantee that the algorithm observes losses with probability $w_e(a)$ within epoch $e$ using the following rejection sampling procedure. Recall that $p_{t,c}(\NodeIn(a)) \triangleq \sum_{a' \in \NodeIn(a)} p_{t,c}(a')$ and $s_{e,c}(\NodeIn(a)) \triangleq \sum_{a' \in \NodeIn(a)} s_{e,c}(a')$. We first play an arm according to the distribution
\[
q_{t, c_t}= \begin{cases}p_{t, c_t} & \text { if } \forall a \in[K], 2 p_{t,c_t}(\NodeIn(a))  \geq s_{e, c_t}(\NodeIn(a))  \\ s_{e, c_t} & \text { otherwise.}\end{cases}
\]
Let ~$q_{t,c}(\NodeIn(a)) \triangleq \sum_{a' \in \NodeIn(a)} q_{t,c}(a')$. After playing arm $a_t$ according to $q_{t, c_t}$, for each arm $a \in \NodeOut(a_t)$, the learner samples a Bernoulli random variable $S_{t,a}$ with probability $\frac{s_{e,c_t}(\NodeIn(a))}{2 q_{t,c_t}(\NodeIn(a))}$. If $S_{t,a}=0$, the learner ignores the feedback of $a$ from this round; otherwise, the learner uses this loss. 

In the previous procedure, we introduce the new distribution $q_t$ to ensure that we can perform a rejection sampling procedure. The ctual rejection sampling procedure ensures that we observe the loss of arm $a$ with probability $w_e(a)=\mathbb{E}_{c \sim \nu}\left[  s_{e,c}(\NodeIn(a))/2\right]$.


% Estimation
The only remaining unspecified part is how to construct the loss estimators.
%
Due to technical problems encountered in the analysis later, we group all timesteps into consecutive pairs of two. In each pair of consecutive timesteps, we sample from the same distribution and randomly use one to calculate a loss estimator and the other to estimate the sampling frequency.
%
To be precise, let $\Time_e^f$ denote the timesteps selected for estimating the sampling frequency, and let $\Time_e^{\ell}$ denote the timesteps used to estimate the losses. Then we define
$$
\widehat{w}_{e}(a)=\frac{1}{\left|\Time_{e-1}^f\right|} \sum_{t \in \Time_{e-1}^f} \frac{s_{e,c_t}(a)}{2}
$$
which is an unbiased estimator of $w_e(a)$. The loss estimators are defined as follows:
$$
\widehat{\ell}_{t,c}(a)=\frac{2 \ell_{t,c}(\NodeIn(a))}{\widehat{w}_{e}(a)+\frac{3}{2} \gamma} \indi\left(A_t \rightarrow a \wedge S_{t,a} \wedge t \in \Time_e^{\ell}\right)
$$
where $\gamma$ is a confidence parameter to be specified later.

We note that in \Cref{alg:unknown}, the actual importance is $\widehat{w}_e(a) + \frac{3}{2} \gamma$ rather than vanilla $\widehat{w}_e(a)$. This additional $\frac{3}{2} \gamma$ parameter is an implicit exploration parameter. Implicit exploration parameters are widely used to derive concentration inequalities in bandit problems~\citep{neu2015}. We also introduce this implicit exploration parameter to derive the concentration inequalities needed for our arguments.


\begin{figure*}[hbt]
\begin{align*}
\underbrace{1,\dots,L}_{\small{\begin{matrix}\Time_1\quad \text{\small \color{purple}fix $s_3$}\\\text{\color{blue}compute $\widehat{w}_{2}$}\\\end{matrix}}},\underbrace{L+1,\dots, 2L}_{\small{\begin{matrix}\Time_2\quad\quad \text{\small \color{red}fix $s_4$}\\\text{\color{purple}compute $\widehat{w}_3$}\\\text{\color{blue}apply $\widehat{w}_2$}\\\text{\color{blue} sample with $s_2$}\end{matrix}}},\underbrace{2L+1,\dots, 3L}_{\small{\begin{matrix}\Time_3\quad\quad \text{\small \color{orange}fix $s_5$}\\\text{\color{red}compute $\widehat{w}_4$}\\\text{\color{purple}apply $\widehat{w}_3$}\\\text{\color{purple}sample with $s_3$}\end{matrix}}},
\underbrace{3L+1,\dots, 4L}_{\small{\begin{matrix}\Time_4\quad\quad \text{\small \color{yellow}fix $s_6$}\\\text{\color{orange}compute $\widehat{w}_5$}\\\text{\color{red}apply $\widehat{w}_4$}\\\text{\color{red}sample with $s_4$}\end{matrix}}},
\underbrace{4L+1,\dots, 5L}_{\small{\begin{matrix}\Time_5\quad\quad \text{\small \color{green}fix $s_7$}\\\text{\color{yellow}compute $\widehat{w}_6$}\\\text{\color{orange}apply $\widehat{w}_5$}\\\text{\color{orange}sample with $s_5$}\end{matrix}}},\dots, T
\end{align*}
\caption{A figure in~\citet{Sch23}. Here we use it to  illustrate the timeline of \Cref{alg:unknown}. At the end of epoch $\Time_e$, the snapshot $s_{e+2}$ is fixed. The contexts within epoch $\Time_{e}$ are used to compute loss estimators for epoch $\Time_{e+1}$, which are fed to the FTRL sub-algorithm.}
\end{figure*}

\begin{algorithm}
\caption{The algorithm for the unknown distribution setting}
\label{alg:unknown}
\textbf{Input:} Parameters $\eta, \gamma > 0$ and $L < T$. \\
$\widehat{w}_2\leftarrow 0$\\
$s_{1, c} \leftarrow \frac{1}{K}$ for each $c$\\
$s_{2, c} \leftarrow \frac{1}{K}$ for each $c$\\
\For{$t=1,\dots, L$}{
Observe $c_t$\\
Play $A_t\sim s_{1,c_t}$\\
    \For{$a \in [K]$}{
    $\widehat{w}_2(a) \leftarrow \widehat{w}_2(a) +  \frac{s_{2,c_t}(\NodeIn(a))}{2L}$
    }
}
\For{$e=2,\dots,T/L$}{
    $\widehat{w}_{e+1}\leftarrow 0$\\
    \For{$t=(e-1)L+1,t=(e-1)L+3,\dots,e L-1$}{
        Set $p_{t,c}= \underset{p \in \Delta{[K]}}{\argmin} \left(\ip{p,\sum_{s=1}^{t-1}\widehat{\ell}_{s}(c)}-\eta^{-1}F(p)\right)$\\
        \For{$t'=t,t+1$}{
            Observe $c_{t'}$\\
            \If{
                $p_{t,c_{t'}}(a) \geq s_{e,c_{t'}}(a)/2$ for all $a \in [K]$
            }{
                Set $q_{t',c_{t'}} = p_{t,c_{t'}}$
            }
            \Else{
                Set $q_{t',c_{t'}} = s_{e,c_{t'}}$
            }
            Play $A_{t'}\sim q_{t',c_{t'}}$ \\
            Observe $\ell_{t',A_{t'}}$
        }
        $t_{f},t_{\ell} \leftarrow \mathsf{RandPerm}(t,t+1)$\\
        \For{$a \in [K]$}{
            $\widehat{w}_{e+1}(a) \leftarrow\widehat{w}_{e+1}(a) + \frac{s_{e+1,c_{t_f}}(\NodeIn(a))}{2 (L/2)}$\\
            Sample $S_{t,a}\sim \mathcal{B}\left(\frac{s_{e,c_{t_\ell}}(\NodeIn(a)}{2q_{t,c_{t_\ell}}(\NodeIn(a))}\right)$\\
            $\widehat{\ell}_{t_\ell,c}(a) \leftarrow \frac{2\ell_{t_\ell,c}(a)}{\widehat{w}_{e}(\NodeIn(a))+\frac{3}{2}\gamma} \mathbb{I}\left(A_{t_\ell} \rightarrow a, S_{t,a}=1\right)$
        }
    }
    $s_{e+2} \leftarrow p_{t}$
}
\end{algorithm}

\subsection{The Algorithm Analysis}
We analyze the algorithm by combining the technique from \citet{Sch23} with the property of the graphical feedback structure. The main result is the following theorem.
\begin{theorem}
\label{thm:main}
For $\iota=2 \log (8 K T^2), L=\sqrt{\frac{\iota \alpha T}{\log (K)}}=\widetilde{\Theta}(\sqrt{\alpha T}), \gamma=\frac{16 \iota}{L}=\widetilde{\Theta}(1 / \sqrt{\alpha T})$, and $\eta=\frac{\gamma}{2(2 L \gamma+\iota)}=\widetilde{\Theta}(1 / \sqrt{\alpha T})$, \Cref{alg:unknown} yields a regret bound of
\[\Reg(\pi)= \widetilde{O}(\sqrt{\alpha T}).\]
\end{theorem}

Here we briefly overview the proof of \Cref{thm:main}. Technical details can be found in appendix.

The key of our analysis is to bound the bias $\ell - \widehat{\ell}$ in estimating the loss $\ell$. A critical problem in bounding the bias is that our estimator $\widehat{\ell}$ is only constructed from a number of epoch length $L$ many samples. As a result, the concentration of $\widehat{\ell}$ is not tight enough. We solve this problem by bounding only the expectation $\E[\ell - \widehat{\ell}]$ of the bias. To do so, we need the following technical preparations.  

We  introduce two sequences of random variables. With a slight abuse of notation, for each epoch $e$ and every round $t \in \Time_e$,  we define
\[\widetilde{\ell}_{t,c}(a) \triangleq \frac{2 \ell_{t,c}(a)}{w_e(a) + \gamma} \indi(a_t \rightarrow a, S_{t,a} = 1, t \in \Time_e^{\ell}).\]
The random variable $\widetilde{\ell}_{t,c}(a)$ is similar to the loss estimate $\widehat{\ell}_{t,c}(a)$. The main difference is that the importance for $\widetilde{\ell}_{t,c}(a)$ is $w_e(a) + \gamma$ rather than $\widehat{w}_e(a) + \frac{3}{2}\gamma$. The random variable $\widetilde{\ell}_{t,c}(a)$ can be seen as a pseudo-estimator of $\ell_{t,c}(a)$. 
%
The pseudo-estimator $\widetilde{\ell}_{t,c}(a)$ concentrates better than the actual loss estimator $\widehat{\ell}_{t,c}(a)$, but $\widetilde{\ell}_{t,c}(a)$ is not computable since $w_e(a)$ is not computable (hence the name pseudo).
%

We introduce another auxiliary sequence of random variables. For each epoch $e$, every round $t \in \Time_e$, and every context $c$, we define \[\widetilde{p}_{t,c} \propto p_{(e-1)L, c} \circ \exp \left(-\eta \sum_{t^{\prime} \in \mathcal{T}_e, t^{\prime}<t} \widetilde{\ell}_{t^{\prime} c}\right). \]
The random variable $\widetilde{p}$ can be thought of as a pseudo probability distribution computed by a counterfactual FTRL algorithm to which we feed the loss estimates $\widehat{\ell}$ up to epoch $e-1$, but feed our new pseudo-estimate $\widetilde{\ell}$ during epoch $e$. This pseudo probability distribution is crucial to our analysis. 

Now we are ready to state the sketch of the proof. We decompose the regret as follows.
\begin{align*}
\Reg(\pi) &= \E\left[\sum_{t=1}^T \ip{q_{t, c_t}- \pi_{c_t}, \ell_{t, c_t}}\right] \\
&=  \underbrace{\E\left[\sum_{t=1}^T \ip{q_{t, c_t} - p_{t, c_t}, \ell_{t, c_t}}\right]}_{\bias{1}} \\
&+ \underbrace{\E\left[\sum_{t=1}^T \ip{p_{t, c_t}- \pi_{c_t}, \ell_{t, c_t}-\widetilde{\ell}_{t, c_t}}\right]}_{\bias{2}} \\
& +\underbrace{\E\left[\sum_{t=1}^T \ip{\widetilde{p}_{t, c_t}-\pi_{c_t}, \widetilde{\ell}_{t, c_t}-\widehat{\ell}_{t, c_t}}\right]}_{\bias{3}} \\
& +\underbrace{\E\left[\sum_{t=1}^T\ip{ p_{t, c_t}-\widetilde{p}_{t, c_t}, \widetilde{\ell}_{t, c_t}-\widehat{\ell}_{t, c_t}}\right]}_{\bias{4}}\\
& +\underbrace{\E\left[\sum_{t=1}^T\ip{ p_{t, c_t}-\pi_{c_t}, \widehat{\ell}_{t, c_t}}\right]}_{\mathbf{ftrl}}.
\end{align*}

In this decomposition, the $\bias{1}$ term corresponds to the regret caused by replacing $p_t$ with $q_t$. We will argue that $q_t = p_t$ for all $t$ with high probability and thus we can safely work on $p_t$. 
%
The $\bias{2}$ term  corresponds to the bias of estimating $\ell$ using the pseudo estimator $\widetilde{\ell}$. It serves a bridge for bounding the bias of estimating $\ell$ by the real estimator $\widehat{\ell}$. The $\mathbf{ftrl}$ term corresponds to the regret of the FTRL subroutine on the fed loss. These three terms are not hard to bound.

%
The $\bias{3}$ and $\bias{4}$ terms are more subtle.
They represent a further decomposition of the bias term between $\widetilde{\ell}$ and $\widehat{\ell}$:
\[\E\left[\sum_{t=1}^T \ip{p_{t, c_t}- \pi_{c_t}, \widetilde{\ell}_{t, c_t}-\widehat{\ell}_{t, c_t}}\right] = \bias{3}+\bias{4}.\]
%
We perform this further decomposition because after the decomposition, for every time $t$ in epoch $e$, the random variables $\widetilde{\ell}_t$ and $\widehat{\ell}_t$ are independent of the random variable $\widetilde{p}_t$ conditional on the snapshot $s_{e}$ of epoch $e-2$.
%
In other words, the random variables $\widetilde{\ell}_t$ and $\widehat{\ell}_t$ are independent of the random variable $\widetilde{p}_t$ conditional on the sigma algebra $\His_{e-2}$ generated by all randomness until  epoch $e-2$.
%
This is because in epoch $e-1$, the random variables $\widetilde{\ell}_t$ and $\widehat{\ell}_t$ are only affected by randomness within round $s$ for $s \in \Time_{e-1}^{\ell}$, while the random variable $\widetilde{p}_t$  is only affected by randomness within round $s$ for $s \in \Time_{e-1}^{f}$.
These two sets $ \Time_{e-1}^{\ell}$ and $\Time_{e-1}^{f}$ are disjoint, thus the randomness within each is independent.
%
The reason  we group all timesteps into consecutive pairs of two in \Cref{alg:unknown} is exactly to ensure this conditional independence. 

Given the conditional independence, we have
\begin{align*}
    \bias{3} =&\E\left[\sum_{t=1}^T \ip{\widetilde{p}_{t, c_t}-\pi_{c_t}, \widetilde{\ell}_{t, c_t}-\widehat{\ell}_{t, c_t}}\right] \\
    =& \E\left[\sum_{t=1}^T \ip{\widetilde{p}_{t, c_t}-\pi_{c_t}, \E\left[\widetilde{\ell}_{t, c_t}-\widehat{\ell}_{t, c_t} | \His_{e-2} \right]}\right].
\end{align*}
Here we only need to bound the expected bias $\widetilde{\ell} - \widehat{\ell}$, which has a sufficiently small bound. 

The final $\bias{4}$ term can be bounded directly using concentration inequalities. That is, we can directly bound this term in high probability. The term $\bias{4}$ is a product of deviations $\left(p_{t} - \widetilde{p}_t\right) \cdot \left( \widetilde{\ell}_t - \widehat{\ell}_t\right)$, thus its concentration is tighter than other terms by a square. This square improvement allows us to bound it directly using concentration inequalities.