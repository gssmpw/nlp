\section{Related Work}
The bandit with graphical feedback problem was proposed by \citet{MS11}.
%
Later, \citet{GraphAlon15} gave a full characterization of the minimax regret of the problem in terms of the time horizon $T$.  \citet{neu2015,LuoGraph23} extended the minimax regret to the high probability case.
%
\citet{lykouris20a,Han24} considered the UCB style algorithm for graphical bandit.
%
\citet{GraphAlon15,Understanding2021} also studied the non-strongly observable feedback graph case.

The cross-learning bandit problem was proposed by \citet{Bal19} to solve bidding-in-auctions problem. \citet{Bal19} inspired a line of work to study different settings of the bidding-in-auctions problem\citep{Han2020Adversarial,Aiauction,WangAuction,Han24}. In all these scenarios, the cross learning structure is an essential component of the analysis. \citet{Sch23} solved a particularly technically challenging case. \citet{Sch23} considered the case with adversarial losses and stochastic contexts and proved that the minimax regret in this case is $\widetilde{O}(\sqrt{KT})$. \citet{Huang2025} extended the result of \citet{Sch23} to the high probability case.

The cross-Learning contextual bandits with graphical feedback problem was proposed by\citet{Han24}. \citet{Han24} showed that for adversarial contexts it is impossible to achieve $\widetilde{O}(\sqrt{\alpha T})$ regret. \citet{Han24} also gave a $\widetilde{O}(\sqrt{\min(\alpha MT,KT)})$ regret bound for stochastic losses and stochastic contexts. Later, \citet{MAS24} further studied this problem for stochastic losses and adversarial contexts and gave a more precise characterization of the regret shape.