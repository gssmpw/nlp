%!TEX root = gcn.tex
\section{Security Analysis}
\label{app::fullproof}
We prove the semi-honest security of our protocols under the real/ideal-world simulation paradigm~\cite{sp/17/Lindell17} with a hybrid argument.
%techniques.
%For clarification, we divided the protocol dependence into three branches, including $\Pi_\ssp$-related Protocols, $\Pi_\SM$-related Protocols, and Adam-related Protocols.
As our protocols satisfy the stand-alone model without malicious assumption, we adopt the standard simulation proof technique instead of the UC framework that adds an additional ``environment" representing an interactive distinguisher.

%\subsection{Security Definition}
We consider the $2$PC executed by $\pp_0$ and $\pp_1$ in the presence of static semi-honest adversaries $\A$ that control one of the parties at the beginning, follow the protocol specification, and try to learn information about the honest party's private input.
Definition~\ref{def:semidef} states the semi-honest security so that simulated and real execution are computationally indistinguishable ("$\equiv$") for~$\A$.
That is, the simulator $\Scal$ can generate the view of a party in the execution, implying the party learns nothing beyond what they can derive from their input and prescribed output.
For simplicity, we assume $\mathsf{PRF}$ to be secure and exclude its standard proof here.

\begin{restatable}[Semi-honest Security~\cite{sp/17/Lindell17}]{definition}{semidef}
\label{def:semidef} 
	Let $\lambda$ be a security parameter.
	A protocol $\Pi$ securely realizes a functionality $\F = (\F_0, \F_1)$ on input $\l x \r = (\l x\r_0, \l x\r_1)$ against %in the presence of 
	static semi-honest adversaries if there exist PPT simulators $\Scal_0, \Scal_1$ s.t.
 \begin{equation*}
     \begin{aligned}
         \{\Scal_0(1^\lambda, \l x\r_0, \F_0), \F(\l x \r)\} \equiv \{\view_0^\Pi, \output^{\Pi, \lambda}(\l x \r)\},\\
         \{\Scal_1(1^\lambda,\l x\r_1,\F_1), \F(\l x \r)\} \equiv \{\view_1^\Pi,\output^{\Pi,\lambda}(\l x \r)\}.
     \end{aligned}
 \end{equation*}
\end{restatable}
%\semidef*

\subsection{Security of \texorpdfstring{$\Pi_\ssp$}{πOP}}
\label{sec::detail_op}

We divide the analyses into `raw' and `shared' cases.
%to differentiate none of the share or zero share owned by one party.
Functionality~\ref{func::ssp} presents the ideal functionality $\F_\ssp$.
%where either party owns the permutation.
It contains two cases in which the input vector/matrix $\Xsf$ is owned by one party or secret-shared among two parties.
The functionality $\F_\ssp$ of both cases outputs additive shares of permutation over~$\Xsf$, \ie, $\l \sigma\xvec\r_0 +\l \sigma\xvec\r_1 =\sigma\xvec$.

\setcounter{algorithm}{0}

\begin{functionality}[!t]
	\caption{$\F_\ssp$: Ideal Functionality of $\Pi_{\ssp}$}\label{func::ssp} 
\begin{algorithmic}[1]
	\item[\textbf{Parameter:} Type of input $\type \in \{\raw, \shared\}$.]
	\REQUIRE $\sigma\in\Sbb,\xvec\in \Zbb^m$ if $\type == \raw$; \\ ~~~~~otherwise $\sigma\in \Sbb,\l\xvec\r_0\in\Zbb^m, \l\xvec\r_1\in\Zbb^m$.
	\ENSURE $\l \sigma\xvec\r_0,\l \sigma\xvec\r_1$.
	\IF{$\type == \shared$} 
	\STATE Reconstruct $\Xsf = \l \xvec \r_0+\l \xvec \r_1$
	\ENDIF
	\STATE Compute and generate random shares of $\sigma\xvec$
	\RETURN $\l \sigma\xvec \r$
\end{algorithmic}
\end{functionality}

\begin{theorem}
\label{the::ssp}
	The protocol $\Pi_\ssp$ securely realizes the ideal functionality $\F_\ssp$ against static semi-honest adversaries.
\end{theorem}
 
\begin{proof}
	%To attain the semi-honest security in Theorem~\ref{the::ssp}, we are essentially to prove that there exists simulator $\Scal$ satisfying Definition~\ref{def:semidef}.
	%Concisely, regarding Definition~\ref{def:semidef}, w
	We define the following $\ideal$ and $\real$ experiments:
	\begin{equation*}
			\begin{aligned}
			\real^{1^\lambda,\A}_{\Pi_\ssp}=&\ \{\{(\view_0^{\Pi,\raw},\l\sigma\Xsf\r_0), (\view_1^{\Pi,\raw},\l\sigma\Xsf\r_1)\} \text{ or }\\
			&\ \ \ \{(\view_0^{\Pi,\shared},\l\sigma\Xsf\r_0), (\view_1^{\Pi,\shared},\l\sigma\Xsf\r_1)\}
			\}\\
			\ideal^{1^\lambda, \A}_{\Scal, \F}=&\ \{\{\Scal(\raw,1^\lambda,\sigma,\Xsf,\F_\ssp),\F_\ssp(\sigma,\Xsf)\}\text{ or }\\
			&\ \ \ \{\Scal(\shared,1^\lambda,\sigma,\l\Xsf\r_0,\l\Xsf\r_1,\F_\ssp),
			\\&\quad\F_\ssp(\sigma,\l\Xsf\r_0,\l\Xsf\r_1)\}\}
		\end{aligned}
	\end{equation*}
	where $\pp_0$'s view is either $\view_0^{\Pi,\raw}$, which is
	$(\sigma, \pi, \l \pi\uvec\r_0, \delta_{\sigma}, \delta_{\Xsf})$ or $\view_0^{\Pi,\shared}$,
	which is $(\sigma, \l \Xsf\r_0, \pi, \l \pi\uvec \r_0, \delta_{\sigma}, \delta_{\l\Xsf\r_1})$,
	and $\pp_1$'s view is either $\view_1^{\Pi,\raw}=(\Xsf, \l \pi\uvec \r_1,\delta_{\sigma},\delta_{\Xsf})$ or $\view_1^{\Pi,\shared}=(\l\Xsf\r_1, \l \pi\uvec \r_1,\delta_{\sigma},\allowbreak\delta_{\l\Xsf\r_1})$.
	$\real^{1^\lambda,\A}_{\Pi_\ssp}$ represents real protocol execution.
	In the $\ideal$ world, the simulators $\Scal=\{\Scal_0,\Scal_1\}$ can indistinguishably simulate the view of each honest party in the protocol given only that party's input.
 
	Now, we argue that $\real^{1^\lambda,\A}_{\Pi_\ssp}\equiv\ideal^{1^\lambda, \A}_{\Scal, \F}$ for any PPT $\A$ using the multi-step hybrid-argument technique.
	 \begin{itemize}
		 \item[$\hyb_0$:] It is identical to the real protocol execution $\real^{1^\lambda,\A}_{\Pi_\ssp}$.
		 \item[$\hyb_{1}$:] It is identical to $\hyb_0$ except that $\delta_\sigma,\delta_{\Xsf}$ are randomly generated for the case of $\raw$ and $\delta_\sigma,\delta_{\l\Xsf\r_1}$ are randomly generated for the case of $\shared$.
		 \\
		 i) In the first case that $\Xsf$'s type is $\raw$, any PPT $\A$ cannot distinguish $\delta_\sigma,\delta_{\Xsf}$ in $\real^{1^\lambda,\A}_{\Pi_\ssp}$ experiment and $\Tilde{\delta}_\sigma,\Tilde{\delta}_{\Xsf}$ in $\hyb_1$ since $\delta_\sigma,\delta_{\Xsf}$ are computed by $\pi,\uvec$, which are generated by $\prf$.
		 If $\A$ can distinguish $\hyb_{1}$ and $\real^{1^\lambda,\A}_{\Pi_\ssp}$ with non-negligible advantage, $\A$ can break the security of $\prf$, which contradicts the assumption.
		 \\
		 ii) For the second case that $\Xsf$'s type is $\shared$, any PPT $\A$ cannot distinguish $\delta_\sigma,\delta_{\l\Xsf\r_1}$ in $\real^{1^\lambda,\A}_{\Pi_\ssp}$ experiment and $\Tilde{\delta}_\sigma,\Tilde{\delta}_{\l\Xsf\r_1}$ in $\hyb_1$ since $\delta_\sigma,\delta_{\l\Xsf\r_1}$ are computed by $\pi,\uvec$, which are generated by $\prf$.
		 If $\A$ can distinguish $\hyb_{1}$ and $\real^{1^\lambda,\A}_{\Pi_\ssp}$ with non-negligible advantage, $\A$ can break the $\prf$ security, contradicting the assumption.
		 \\
		 $\Rightarrow \hyb_1\equiv\hyb_0$.
		 \item[$\hyb_{2}$:] It is identical to $\ideal^{1^\lambda, \A}_{\Scal, \F}$, \ie, all $\view_0,\view_1$ of two parties are simulated by $\Scal_0,\Scal_1$.
		 The randomness of $\pi,\l \pi\uvec \r_0, \delta_{\sigma}, \delta_{\Xsf}$ for $\raw$ and $\pi,\l \pi\uvec \r_0, \delta_{\sigma}, \delta_{\l\Xsf\r_1}$ for $\shared$ ensures no non-negligible $\A$'s advantage of distinguishability to $\Scal_0$'s view.
		 Similarly, the randomness of $\l \pi\uvec \r_1, \delta_{\sigma}, \delta_{\Xsf}$ for $\raw$ and $\l \pi\uvec \r_1, \allowbreak\delta_{\sigma}, \delta_{\l\Xsf\r_1}$ for $\shared$ ensures no non-negligible $\A$'s advantage of distinguishability to $\Scal_1$'s view.
		 Now, $\pp_0$ cannot obtain $\pp_1$ inputs, while $\pp_1$ cannot obtain $\pp_0$ inputs since $\{\Scal_i\}_{i\in\{0,1\}}$ cannot obtain $\{\Scal_{1-i}\}_{i\in\{0,1\}}$'s inputs using the $\{\view_i\}_{i\in\{0,1\}}$.\\
		 $\Rightarrow \hyb_2\equiv\hyb_1$.
	 \end{itemize}
Thus, for both cases, %of $\raw$ and $\shared$, 
we have $\hyb_2\equiv\hyb_1\equiv\hyb_0$, equivalent to $\real^{1^\lambda,\A}_{\Pi_\ssp}\equiv\ideal^{1^\lambda, \A}_{\Scal, \F}$ for any PPT semi-honest $\A$.
\end{proof}


\subsection{Security of 
\texorpdfstring{$\Pi_\SM$}{πOSM}
} 
\label{sec::proof_sxb}

%\sxb*

Functionality~\ref{func::osm} gives the ideal functionality of $\Pi_{\SM}$, defining the multiplication $sx\in\Zbb_{2^n}$ between %binary element 
$s\in\Zbb_2$ and %arithmetic element 
$x\in\Zbb_{2^n}$.
%Protocol~\ref{fig:osm-main} ($\Pi_\SM$) realizes $\F_\ssp$ in semi-honest security model, as given in Theorem~\ref{the::osm}.
%Now, we define ideal/real experiments using simulation technique to prove Theorem~\ref{the::osm} against any honest-but-curious $\A$.

\begin{functionality}[!t]
	\caption{$\F_{\SM}$: Ideal Functionality of $\Pi_{\SM}$}\label{func::osm}
\begin{algorithmic}[1]
	\REQUIRE $s\in\Zbb_2, \l x\r_0\in\Zbb_{2^n}, \l x\r_1\in\Zbb_{2^n}$.
	\ENSURE $\l sx \r_0, \l sx \r_1$.
	\STATE Reconstruct $s=\l s\r_0+\l s\r_1$
	\STATE Compute and generate random shares of $sx$
	\RETURN $\l sx \r$
\end{algorithmic}
\end{functionality}

\begin{theorem}
\label{the::osm}
	The protocol $\Pi_\SM$ securely realizes the ideal functionality $\F_\SM$ against static semi-honest adversaries.
\end{theorem}

\begin{proof}
%In terms of Definition~\ref{def:semidef}, w
We define the $\ideal$ and $\real$ experiments:
	\begin{equation*}
		\begin{aligned}
			\real^{1^\lambda,\A}_{\Pi_\SM}=&\ \{(\view_0^{\Pi},\l sx\r_0), (\view_1^{\Pi},\l sx\r_1)\} \\
			\ideal^{1^\lambda, \A}_{\Scal, \F}=&\ \{\Scal(1^\lambda,s,\l x\r_0,\l x\r_1,\F_\SM),\\&\ \ \ \ \F_\SM(s,\l x\r_0,\l x\r_1)\}
		\end{aligned}
	\end{equation*}
	where 
	%$\pp_0$'s view is 
	$\view_0^{\Pi}=(s, \l x\r_0, b, \l u \r_0, \l bu \r_0,\delta_s, \allowbreak\delta_{\l x\r_0},\delta_{\l x\r_1},\delta_x)$, and 
	%$\pp_1$'s view is 
	$\view_1^{\Pi}=(\l x\r_1, \l bu \r_1, \l u \r_1, \delta_{\l x\r_1}, \delta_s)$.
	$\real^{1^\lambda,\A}_{\Pi_\SM}$ represents real protocol execution.
	The simulators $\Scal=\{\Scal_0,\Scal_1\}$ are indistinguishably simulating the view of each honest party in the protocol given only that party's input.
 
	Now, we prove that $\real^{1^\lambda,\A}_{\Pi_\SM}\equiv\ideal^{1^\lambda, \A}_{\Scal, \F}$ for any PPT $\A$ with a series of hybrid-arguments.
	The hybrid games can be sequentially formulated as follows.
\begin{itemize}
		 \item[$\hyb_0$:] It is identical to the real protocol execution $\real^{1^\lambda,\A}_{\Pi_\SM}$.
		 \item[$\hyb_{1}$:] It is identical to $\hyb_0$ except that $\delta_{\l x\r_0},\delta_{\l x\r_1},\delta_{x}$ are randomly generated 
		 %for the case of $\raw$ 
		 by $\Scal_0$.
		 Since $\delta_{\l x\r_0},\delta_{\l x\r_1}$ in $\real^{1^\lambda,\A}_{\Pi_\SM}$ experiment are computed by $\l u \r_0,\l u \r_1$, which are outputted by $\prf$.
		 Thus, any PPT $\A$ cannot distinguish $\delta_{\l x\r_0},\delta_{\l x\r_1}$ in $\real^{1^\lambda,\A}_{\Pi_\SM}$ experiment and $\Tilde{\delta}_{\l x\r_0},\Tilde{\delta}_{\l x\r_1}$ in $\hyb_1$, guaranteed by $\prf$'s security.
		 The value of $\delta_x$, added by $\delta_{\l x\r_0}$ and $\delta_{\l x\r_1}$, is also distinguishable to $\Tilde{\delta}_x$ simulated by $\Scal_0$.
		 Overall, if $\A$ can distinguish $\Tilde{\delta}_{\l x\r_0},\Tilde{\delta}_{\l x\r_1},\Tilde{\delta}_x$ with $\delta_{\l x\r_0},\delta_{\l x\r_1},\delta_x$ in $\real^{1^\lambda,\A}_{\Pi_\SM}$ with non-negligible advantage, $\A$ can break the security of $\prf$.
		 %, which yet contradicts the fact.
		 \\
		 $\Rightarrow \hyb_1\equiv\hyb_0$.
		 \item[$\hyb_{2}$:] It is identical to $\hyb_1$ except that $\delta_{s}$ are randomly generated.
		 Since $\delta_s$ in $\hyb_1$ experiment are computed by $h$, which are generated by $\prf$.
		 Thus, any PPT $\A$ cannot distinguish $\delta_s$ and $\Tilde{\delta}_{s}$, given the security of $\prf$.
		If $\A$ has the non-negligible advantage to guess the real $s$, then the $\A$ can distinguish $\Tilde{\delta}_{s}$ and $\delta_s$ with non-negligible probability, which breaks $\prf$.
		\\
		 $\Rightarrow \hyb_2\equiv\hyb_1$.
		 \item[$\hyb_{3}$:] It is identical to $\ideal^{1^\lambda, \A}_{\Scal, \F}$, \ie, all the $\view_0,\view_1$ 
		 %in $\raw$ case 
		 are simulated by $\Scal_0,\Scal_1$.
		 The randomness of $b, \l u \r_0, \l bu \r_0,\delta_s, \allowbreak\delta_{\l x\r_0},\delta_{\l x\r_1},\allowbreak\delta_x$ 
		 %for $\raw$ 
		 guarantees no non-negligible $\A$'s advantage of distinguishability to $\Scal_0$'s view.
		 Similarly, the randomness of $\l bu \r_1, \l u \r_1, \allowbreak\delta_{\l x\r_1}, \delta_s$ guarantees no non-negligible $\A$'s advantage of distinguishability to $\Scal_1$'s view.
		 Now, $\pp_0$ cannot obtain $\l x\r_1 $, while $\pp_1$ cannot obtain $s,\l x\r_0$ since $\{\Scal_i\}_{i\in\{0,1\}}$ cannot obtain $\{\Scal_{1-i}\}_{i\in\{0,1\}}$'s inputs using $\{\view_i\}_{i\in\{0,1\}}$.\\
		 $\Rightarrow \hyb_3\equiv\hyb_2$.
	 \end{itemize}
So,  $\real^{1^\lambda,\A}_{\Pi_\SM}\equiv\ideal^{1^\lambda, \A}_{\Scal, \F}$ for any PPT semi-honest $\A$.	
\end{proof}

\subsection{Security of 
\texorpdfstring{$\prosmm$}{π(SM)2}
}
Correctness has been checked using theoretical foundation for sparse-matrix in Appendix~\ref{sec:matrix_found_sparse}.
Functionality~\ref{func::mmult} defines arbitrary-sparse matrix multiplication without %really performing 
decomposition.


\begin{functionality}[!t]
	\caption{$\F_{\text{\osmm}}$: Ideal Functionality of $\prosmm$}\label{func::mmult}
\begin{algorithmic}[1]
	\REQUIRE $\adjmat\in \Mbb_{m,n}(\Rcal), \feamat\in \Mbb_{n,d}(\Rcal)$.
	\ENSURE $\l \adjmat\feamat \r_0, \l \adjmat\feamat \r_1$.
	\STATE Compute and generate random shares of $\adjmat\feamat$
	\RETURN $\l \adjmat\feamat \r$
\end{algorithmic}
\end{functionality}


\begin{theorem}[Security of $\prosmm$]
\label{secthe::smm}
Let $\Asf$ be a sparse %adjacency 
matrix and $\Xsf$ be any vector/matrix.
The protocol $\prosmm$ realizes the functionality $\F_{\text{\osmm}}$ %(Functionality~\ref{func::mmult}) 
against static semi-honest adversaries.
\end{theorem}


\begin{proof}
The $\prosmm$ protocol sequentially call the independent subroutines of $5\ {\Pi}_{\ssp}, 2\ \Pi_\SM$, and $1\ \promult$ protocols that have been proved to be semi-honest secure.
The sequential composition theorem~\cite{joc/Canetti00} guarantees that security is closed under composition.
So, $\prosmm$ is semi-honest secure.
% If a protocol is secure in the stand-alone model, it remains semi-honest secure under the sequential composition.
%Thus, we finish the proof of Theorem~\ref{secthe::smm}.
\end{proof}
 
\subsection{Security of 
\texorpdfstring{$\cgnn$}{\textcgnn}
}

\begin{theorem}
\label{secthe::sec_swan}
\cgnn securely realizes the functionality of GCN (Figure~\ref{graph_imple}) against static semi-honest adversaries.
\end{theorem}

\begin{proof}
    $\cgnn$ integrates the semi-honest protocols for all elementary operations like graph convolution and activation layers.
To obtain the secure inference or training protocol, we can sequentially compose the relevant protocols.
Correctness and %ideal functionality 
security of private inference or training follow the integration of underlying sub-protocols.
By the sequential composition theorem~\cite{joc/Canetti00}, 
%The sequential composition theorem~\cite{joc/Canetti00} guarantees the semi-honest security of secure inference or training.
%Thus, 
$\cgnn$ is semi-honest secure.
\end{proof}
