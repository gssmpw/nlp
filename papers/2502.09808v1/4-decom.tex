%!TEX root = gcn.tex
\iffalse
\begin{framed}
\noindent ``\textit{It is relatively well-known that given an arbitrary graph $\mathcal{G}$, one can construct a variety of bipartite graphs which \underline{faithfully} represent $\mathcal{G}$.}'' 

$\quad$ \textit{\hfill\textemdash Stephen T.~Hedetniemi}
\end{framed}
\fi
\section{Sparse Matrix Decomposition}
\label{sec::sgc}
Graph convolution layers $\adjmat\feamat\weimat$ encode the graph structures in $\adjmat$ into GCNs.
Graph convolution is then computed by SMM $\adjmat\feamat$.
By bridging computations of matrices and graphs, we detail how to decompose a sparse matrix $\adjmat$ into a product of special matrices for more efficient SMM.
In essence, we \emph{revisit linear algebra} relations to \emph{faithfully} capture the graph.

\subsection{Bipartite Graph Representation}\label{subsec::sme}
We represent graph $\graph$ corresponding to $\adjmat$ as bipartite graphs, and decompose $\adjmat$ into matrices.
This bipartite representation enables the identification of structured patterns that facilitate efficient SMM aligning with our $2$PC protocols.

\paragraph{Graph Decomposition via Edges.}
Non-zero entries in $\adjmat$ correspond to edges between nodes in $\graph$.
By representing $\graph$ as two bipartite graphs---$\graphout$ (the out-degree node-to-edge relation) and $\graphin$ (the in-degree edge-to-node relation)---we can decompose $\adjmat$ into the product $\adjout \adjin$, where $\adjout$ and $\adjin$ reflect the respective bipartite structures 
are sparse matrices correspond to $\graphout$ and $\graphin$, respectively.
%
Consider graph~$\graph$ (with arbitrary-sparse $\adjmat$) in Figure~\ref{fig::nn_relation_diff}.
We label each edge and treat them as imaginary nodes (`$\diamond$' drawn by dotted lines) to
%build the bridge in the decomposed graph.
%We
construct $\graphout$ and $\graphin$ as in Figure~\ref{fig::nen_relation_diff}.
This representation decomposes $\adjmat$ into $\adjout \adjin$ as in Figure~\ref{fig::adjmat_decom_init}.

%The upper one represents the out-degree node-to-edge relation, and the other represents the in-degree edge-to-node relation.
%Arbitrary connection among different nodes leads to an arbitrary sparsity.
%We first perform analysis for a general representation of arbitrary topological relations.
%Decomposition with edges.Figure~\ref{fig::graph_decom_diff} shows the process of decomposing a graph of an arbitrary topology.
%For any graph, such a graph decomposition always builds the relation between source, imaginary, and target nodes.

\begin{figure}[!t]
 \subfloat[Node-Node Graph $\graph$]{
 \includegraphics[width = 0.21\textwidth]{./fig_and_tab/before_graph_diff.png}
 \label{fig::nn_relation_diff}
 }
 \hspace{2mm}
 \subfloat[Node-Edge-Node Graph $\graphout, \graphin$]{
 \includegraphics[width = 0.225\textwidth]{./fig_and_tab/after_graph_diff.png}
 \label{fig::nen_relation_diff}
 }
	\caption{Graph Decomposition through Edges}
	\label{fig::graph_decom_diff}
\end{figure}
%\vspace{-2mm}

\begin{figure}[!t]

\centering
	\includegraphics[width = 0.47\textwidth]{./fig_and_tab/graph_Aoutin.png}
\iffalse
$$
\begin{bmatrix}
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 \\
1 & 0 & 0 & 1 & 0 \\
0 & 1 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0
\end{bmatrix} 
% refers to $\graph$
=
\begin{bmatrix}
1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 \\
0 & 1 & 0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}
% refers to $\graph_out$
\begin{bmatrix}
0 & 1 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 1 \\
\end{bmatrix}
% refers to $\graph_in$
$$
\fi
	\caption{Matrix Decomposition Equivalent to Figure~\ref{fig::graph_decom_diff}}
	\label{fig::adjmat_decom_init}
\end{figure}
 
\begin{figure*}[!t]
%	\vspace{-5mm}
	\centering
	\includegraphics[width = 0.98\textwidth]{./fig_and_tab/graph_psigq.png}
	\caption{Graph/Matrix Decomposition with Monotonicity}
	\label{graph_psigq}
\end{figure*}

\subsection{Permutation for Monotonicity}\label{subsec::initdecom}
$\adjout$ and $\adjin$ are still unstructured sparse matrices, challenging further decomposition.
We then permute the columns of $\adjout$ and the rows of $\adjin$ to yield permuted matrices $\adjout'$ and $\adjin'$ with monotonically non-decreasing (row-index, column-index) coordinates for non-zero positions as shown in Figure~\ref{graph_psigq}.
Definitions~\ref{q_type} and~\ref{p_type} formulate $\Psf$-type and $\Qsf$-type
sparse matrices to capture these monotonic relations,
where $\Psf$-type matrices have exactly one non-zero value in each column, and
$\Qsf$-type matrices have exactly one non-zero value in each row.
%
Note that $\adjmat \neq \adjout'\adjin'$ as the imaginary nodes
%(representing edges in $\graph$) 
in $\adjout'$ and $\adjin'$ are ordered differently.
We use a permutation $\sigma_3$ 
(before defining $\sigma_1,\sigma_2$)
to map these nodes
%in $\adjout'$ and $\adjin'$ 
for preserving the topology among edges and 
%obtaining a decomposition of 
decomposing 
$\adjmat$, given by $\adjout'\sigma_3\adjin'$.

%\footnote{
%Both $\Psf$-type and $\Qsf$-type matrices have monotonically non-decreasing (row-index, column-index) coordinates for non-zero positions.
%}


%Observe that $\adjout$ have exactly a ``1" in each column, while $\adjin$ have exactly a ``1" in each row.
%Our next step is to permute them so that their (row-index, column-index) coordinates

\iffalse
\textbf{Matrix representation}.
We capture the regularity in the graph for the algebra relations in an arbitrary graph.
Figure~\ref{fig::nen_relation_diff} can be decomposed into two bipartite graphs without cross-edges and a permutation operation.
As shown in Figure~\ref{graph_psigq}, a permutation $\sigma_3$ always exists in the middle to guarantee that no cross-edge exists in the upper and lower bipartite graphs, which respectively represent out-degree nodes to directed edges and directed edges to in-degree nodes.
Then, we capture the graph property of no cross-edges to construct a monotonic relation of coordinates stored in the sparse matrix.
Accordingly, we construct the $\Psf$-type (formalized in Definition~\ref{q_type}) and $\Qsf$-type (formalized in Definition~\ref{p_type}) sparse matrices to formulate the monotone relation of (row-index, column-index) coordinates by marking the existence of directed edges.
\fi
%Technically, we formulate the graphic topology in three bipartite graphs as $\Psf$-type matrix, permutation, and $\Qsf$-type matrix.
%$\mapsto$ denotes the ``maps to'' relation, while ``row-id'' and ``column-id'' represent the row and column indexes, respectively.
%In \yuzh{Appendix XXXX}, and formally define $\Qsf$-type matrix and $\mathsf{P}$-type matrix, respectively.

%Next, we decompose the upper-half graph of Figure~\ref{fig::nen_relation} by constructing the permutational relation between imaginary nodes (previously directed edges in Figure~\ref{fig::nn_relation}), which is essentially re-sorting imaginary nodes.
%We can now decompose any graph to a composition of three bipartite graphs as Figure~\ref{graph_psigq}, including out-degree nodes to directed edges, directed edges to resorted directed edges, and directed edges to in-degree nodes.
%In particular, a permutation operation always exists in the middle to guarantee that no cross-edge exists in the upper and lower parts.

% My understanding of the intuitions of P- and Q- type matrix:
% P-type matrix: a matrix with precisely a ``1" in each column and monotonically non-decreasing (row-index, column-index) coordinates of the "1"s
% Q-type matrix: a matrix with precisely a ``1" in each row and monotonically non-decreasing (row-index, column-index) coordinates of the "1"s


%Relation between graph and matrix.
%Although we know any graph topology can be decomposed into a series of bipartite graphs, how to achieve graph computation from the protocol design perspective is still unclear.
%Recall that topological relation in an $n$-node graph can be represented by $n\times n$ adjacency matrix, in which the entry is $1$ if there is an edge or $0$ otherwise.

%So far, we assume all non-zero values in $\adjmat$ are $1$.
Recall that $\adjmat$ is a normalized adjacency matrix, \ie, its non-zero values may not be $1$.
To account for this, we introduce a diagonal matrix $\Lambda$ in the decomposition to store the non-zero edge weights.
Theorem~\ref{the::p_sig_q} (proven in $\S$\ref{sec::proof_p_sig_q})
shows that any sparse matrix $\adjmat$ can be decomposed to a $\Psf$-type matrix, a diagonal matrix,
% $\Lambda$ (\ie, the weight matrix of edges)
a permutation, and a $\Qsf$-type matrix.

%\noindent\textbf{Sparse matrix decomposition.}
%As for an arbitrary matrix $\Msf$ (\ie, representing an arbitrary graph), w
%We present 


%Previously, we thought the value contained in each node was $1$ in default; then, the node value could be achieved by multiplying a scalar stored in a diagonal matrix.
%The last step is integrating the matrices and their transformations, abstracting a general theorem for representing arbitrary sparsity.
%Thus, we formulate 

\begin{restatable}{theorem}{initdecom}
\label{the::p_sig_q}
Let $\adjmat\in \Mbb_{m,n}(\Rcal)$ be an $m\times n$ matrix, where each entry is an element from ring $\Rcal$.
The elements of $\adjmat$ are $0$'s except $\numnonzero$ of them.
There exists a matrix decomposition $\adjmat = \adjout' \Lambda \sigma_3 \adjin'$, where $\adjout' \in \Mbb_{m, \numnonzero}(\Rcal)$ is a $\Psf$-type matrix, $\Lambda \in \Mbb_{\numnonzero,\numnonzero}(\Rcal)$ is a diagonal matrix, $\sigma_3 \in \Sbb_{\numnonzero}$ is a permutation,
%\footnote{There exists a natural injection homomorphism from $e$-permutation group $\Sbb_e$ into $\Mbb_{e,e}(\Rcal)$.
%$\sigma \in \Sbb_e$ can be viewed as a matrix $\{(\sigma(i), i, 1): i=1, \ldots, n\}\in \Mbb_{e, e}$.}
and $\adjin' \in \Mbb_{\numnonzero, n}(\Rcal)$ is a $\Qsf$-type matrix.
\end{restatable}

\subsection{Re-decomposition to Basic Operations}
\label{sec::the_supp_smm}
Given the permuted matrices $\adjout'$ and $\adjin'$ with the %above
monotonicity properties, we can re-decompose them into a product of permutation, diagonal, and constant matrices.
Due to the page limit, we focus on the intuition of re-decomposing $\adjin'$ (Q-type matrix)\footnote{
We can view a P-type matrix (\eg, $\adjout'$) as a transpose of a Q-type matrix and perform re-decomposition similarly.
} and the general theorem.
Implementation details and proofs can be found in Appendices~\ref{sec:matrix_found_sparse} and~\ref{sec::alg}.


We consider two constant lower triangular matrices:
\\
1) a ``summation matrix'' $\Sigma \in \Mbb_{\numnonzero,\numnonzero}(\Rcal)$ with $\Sigma[i, j]=1$ if $i \geq j$ or $0$ otherwise;
\\
2) a ``difference matrix'' $\delta_k \in \Mbb_{k,k}(\Rcal)$ with $\delta_k[i,j]=1$ for $i=j$ or $-1$ for $j=i-1$, or $0$ otherwise.

Intuitively, when multiplying with a (column) vector, $\Sigma$ sums values on or above each element, while $\delta_k$ computes a difference between each element and its previous one.

Based on the above intuition, it is not hard to decompose $\adjin'$ into a product of $\Sigma$ and another matrix $\delta'$ (Figure~\ref{fig::Q-decom_1}).
Interestingly,
%after the decomposition, 
we observe that the resulting matrix $\delta'$ ``contains'' a difference matrix (with size equals the number of non-zero columns in $\adjin'$) on its left-top corner (after permuting its rows and columns).
This relation can be characterized by expressing $\delta'$ into a product of permutation ($\sigma_1$, $\sigma_2$), diagonal ($\gammain$), and difference ($\delta$) matrices, as in Figure~\ref{fig::q-type_decom}.
 
\begin{figure}[!t]
	\centering
	\includegraphics[width = 0.47\textwidth]{./fig_and_tab/Q-decom_1.png}\caption{Decomposition of $\adjin' = \Sigma \delta'$}
	\label{fig::Q-decom_1}
\end{figure}

\begin{figure*}[!t]
\centering
\includegraphics[width = 0.99\textwidth]{./fig_and_tab/q-type_decom.png}	\caption{Re-decomposition of $\adjin'$ (Q-type Matrix)}
	\label{fig::q-type_decom}
\end{figure*}
 

\paragraph{General Theorem.}
%The transpose of $\Psf$-type matrix can be regarded as a $\Qsf$-type matrix, thus we do not repeat the similar contents.
Combining Theorem~\ref{the::p_sig_q} and matrix decomposition of $\Qsf$-type (Theorem~\ref{the::q_decom} proved in $\S$\ref{sec::proof_q}) and $\Psf$-type (Theorem~\ref{the::p_decom} proved in $\S$\ref{sec::proof_p}) matrices, Theorem~\ref{the::general_dec_main} concludes the general matrix decomposition (proof in $\S$\ref{sec::proof_general}).
%Colloquially speaking, graph computation 
Essentially, an arbitrary-sparse matrix can be transformed into a %sequential composition 
sequence of permutation and matrix multiplication.

\begin{restatable}[Sparse Matrix Decomposition]{theorem}{finaldecom}
\label{the::general_dec_main}
Let an $m\times n$ sparse matrix $\adjmat\in \Mbb_{m,n}(\Rcal)$ contain $\nrow$ non-zero rows, $\ncol$ non-zero columns, and $\numnonzero$ non-zero elements.
Then, there exists a matrix decomposition
$\adjmat = \sigma_5 \delta_m ^{\top} \gammaout \sigma_4 \Sigma ^{\top} \Lambda \sigma_3 \Sigma \sigma_2 \gammain \delta _n \sigma_1$,
where $\sigma _5 \in \Sbb_m$, $\sigma_4 \in \Sbb_{\numnonzero}, \sigma_3 \in \Sbb_{\numnonzero}, \sigma_2 \in \Sbb_{\numnonzero}, \sigma_1 \in \Sbb_n$, and,
\\
1) $\Sigma=(\Sigma[i, j])_{i,j=1}^{\numnonzero}$ is the left-down triangle matrix such that $\Sigma[i, j]=1$ if $i \geq j$ or $0$ otherwise,
\\
2) $\delta_k=(\delta_k[i,j])_{i,j=1}^{k}$ is the left-down triangle matrix such that $\delta_k[i,j]=1$ for $i=j$ or $-1$ for $j=i-1$, or $0$ otherwise,
\\
3) $\gammain =(\gammain[i,j])_{i=1,j=1}^{\numnonzero,n}$ is a matrix such that $\gammain[i,j]=1$ for $1\leq i=j\leq \ncol$ or $0$ otherwise,
\\
4) $\gammaout =(\gammaout[i,j])_{i=1,j=1}^{m,\numnonzero}$ is a matrix such that $\gammaout[i,j]=1$ for $1\leq i=j\leq {\nrow}$ or $0$ otherwise.
\end{restatable}
%1) $\Sigma=(a_{ij})_{i,j=1}^e$ is the left-down triangle matrix such that $a_{ij}=1$ if $i \geq j$ or $0$ otherwise,\\
%2) $\delta_n=(a_{ij})_{i,j=1}^n$ is the left-down triangle matrix such that $a_{ij}=1$ for $i=j$ or $-1$ for $j=i-1$, or $0$ otherwise,\\
\iffalse
3) $J_{k_2}=\begin{psmallmatrix}
I_{k_2} & O_{k_2,n-k_2} \\
O_{e-k_2,k_2} & O_{e-k_2,n-k_2}
\end{psmallmatrix}=(a_{ij})_{i=1,j=1}^{e,n}$ is a matrix such that $a_{ij}=1$ for $1\leq i=j\leq k_2$ or $0$ otherwise,\\
4) $\Gamma_{k_4}=\hspace{-1mm}
\begin{psmallmatrix}
I_{k_4} & O_{{k_4},e-{k_4}} \\
O_{m-{k_4},{k_4}} & O_{m-{k_4},e-{k_4}}
\end{psmallmatrix} 
=(a_{ij})_{i=1,j=1}^{m,e}$ is a matrix such that $a_{ij}=1$ for $1\leq i=j\leq {k_4}$ or $0$ otherwise.
\fi

 
\subsection{Reasoning from Graph Perspective}
\begin{figure}[!t]
	\centering
	\includegraphics[width = 0.477\textwidth]{./fig_and_tab/graph_qx.png}
	\caption{Recover In-degrees in $\graphin$ through $\adjin'\Xsf$}
	\label{graph_psigqx_diff}
		%\end{minipage}
\end{figure}

To illustrate the sparse matrix decomposition underlying Theorem~\ref{the::general_dec_main} for arbitrary topology,
Figure~\ref{graph_psigqx_diff} shows the directed edges \textit{in a reversed direction} represented by the decomposed matrices in Figure~\ref{fig::q-type_decom} and recovers the original $\graphin$.
Consider a vector
$\Xsf = [x_1, x_2, x_3, x_4, x_5]^\top$, 
which passes $5$ values through graph $\graphin$ (equivalent to SMM $\adjin'\Xsf$).
After $\sigma_1$ operation, 
$\Xsf$ passes from $\{\tikzcircle[fill=red]{3pt},\tikzcircle[fill=orange]{3pt},\tikzcircle[fill=yellow]{3pt},\tikzcircle[fill=ao]{3pt},\tikzcircle[fill=cyan]{3pt}\}$ to the re-ordered $\{\tikzcircle[fill=red]{3pt},\tikzcircle[fill=orange]{3pt},\tikzcircle[fill=ao]{3pt},\tikzcircle[fill=cyan]{3pt},\tikzcircle[fill=yellow]{3pt}\}$.
Then, the $\delta$ operation computes the difference of values stored in the neighboring source nodes to obtain the target nodes.

The $\gammain$ operation extracts the effective message passing to the subsequent graph computation by classifying the nodes with or without in-degree edges in $\graphin$.
Thus, all interdependent nodes
$\{x_1 (\tikzcircle[fill=red]{3pt}), 
x_2 (\tikzcircle[fill=orange]{3pt}), 
x_4 (\tikzcircle[fill=ao]{3pt}), 
x_5 (\tikzcircle[fill=cyan]{3pt})\}$ 
in $\graphin$ are recovered, \ie, those nodes containing one or multiple in-degree edges.

After the $\sigma_2$ operation, nodes
%plus independent nodes 
are rearranged in order
$\{x_1 (\tikzcircle[fill=red]{3pt}),\allowbreak 
x_2 (\tikzcircle[fill=orange]{3pt}), 
x_3 (\mathrm{None}), 
x_4 (\tikzcircle[fill=ao]{3pt}), 
x_5 (\tikzcircle[fill=cyan]{3pt})\}$.
Interestingly, the imaginary nodes (`$\diamond$' drawn by dotted lines) reflect the $\delta'$ matrix in Figure~\ref{fig::Q-decom_1}.
Next, the $\Sigma$ operation takes the sum of source nodes to get target nodes.
Finally, we get the results
$\{\tikzcircle[fill=red]{3pt},
\tikzcircle[fill=orange]{3pt},
\tikzcircle[fill=orange]{3pt},
\tikzcircle[fill=ao]{3pt},
\tikzcircle[fill=cyan]{3pt},
\tikzcircle[fill=cyan]{3pt}\}$, 
which recover the (permuted) in-degree edges (represented by $\adjin'$) matching the correct nodes in~$\graphin$.
 
