%!TEX root = gcn.tex
\section{Secure Sparse Matrix Multiplication}
\label{sec::smm_protocol}
Given the sparse matrix decomposition from Theorem~\ref{the::general_dec_main}, SMM can be %obtained by multiplication $\adjmat\feamat$ as Theorem~\ref{the::smm_main} (proof in $\S$\ref{sec::proof_smm}).
%The multiplication $\adjmat\feamat$ is 
transformed into an ordered sequence of basic operations from right to left as Theorem~\ref{the::smm_main} (proof in $\S$\ref{sec::proof_smm}).
If we expect to compute $\feamat\adjmat$, the linear transformations should be performed sequentially from left to right.
For a sparse matrix that is multiplied by another sparse matrix, we can combine the sequential computation of $\adjmat\feamat$ and $\feamat\adjmat$.

\begin{restatable}[Sparse Matrix Multiplication]{theorem}{thmsmm}
\label{the::smm_main}
Consider a sparse matrix $\adjmat$ and a dense matrix $\feamat$.
Computing $\adjmat\feamat =
\allowbreak \sigma_5 \delta_m ^{\top} \gammaout \sigma_4 \Sigma ^{\top} \Lambda \sigma_3\allowbreak \Sigma \sigma_2 \gammain \delta_n \sigma_1 \feamat$ requires an ordered sequence of permutation group action, element-wise multiplication, %cut-off or padding with $0$, 
and constant matrix multiplication from right to left.
\end{restatable}

For secure MPC, the graph owner $\pp_0$ first decomposes its graph to obtain matrices $\sigma_1, \sigma_2, \sigma_3, \sigma_4, \sigma_5, \gammaout, \gammain, \Lambda$.
These matrices are privacy-sensitive and should not be learned by the feature owner $\pp_1$.
The summation matrix $\Sigma$ and difference matrices $\delta_m, \delta_n$ are constants (given dimensionality of~$\adjmat$) and thus are public to both $\pp_0$ and $\pp_1$.
Next, $\pp_0$ and $\pp_1$ jointly execute the MPC protocols of SMM, which multiplies the above matrices described in Theorem~\ref{the::smm_main}.

We first present an oblivious permutation protocol (for secure permutation operations based on $\sigma_1, \ldots, \sigma_5$) in Section~\ref{sec::op_pro}
and then an oblivious selection-multiplication protocol (for privately multiplying $\gammaout$ and $\gammain$) in Section~\ref{sec::osm_pro}.
Finally, we describe how to realize our \osmm protocol using our OP and OSM protocols in Section~\ref{subsec:prosmm}.
 
\iffalse
For the MPC computation, the graph holder $\pp_0$ first decomposes the graph computation into the corresponding linear transformations, essentially an ordered sequence of permutation group actions as explained in Section~\ref{sec::priv_graph}.
Next, $\pp_0$ and $\pp_1$ execute the MPC protocols of secure sparse matrix multiplication (\osmm) by sequentially executing the secure version of linear transformations as in Theorem~\ref{the::smm_main}.
To realize \osmm, we first present an \osmm protocol that reveals the sparsity in Section~\ref{subsec:prosmm} by adopting the oblivious permutation protocol in Section~\ref{sec::op_pro}.
Moreover, we build obliviously selection-multiplication in Section~\ref{sec::osm_pro} for hiding the sparsity degrees in Section~\ref{sec::smm::degree}.

\subsection{Explication of Private Graph}
\label{sec::priv_graph}

After the graph holder $\pp_0$ decomposes the private graph, $\pp_0$ obtains $\sigma_1, \sigma_2, \sigma_3, \sigma_4, \sigma_5$, which are privacy-sensitive and essentially represent the topological relations in the graph.
Thus, we design the oblivious permutation protocol $\Pi_\ssp$ in Section~\ref{sec::op_pro} to protect the permutation operations $\sigma_1, \sigma_2, \sigma_3, \sigma_4, \sigma_5$.

$k_4$ in $\Gamma$ denotes the number of non-zero rows, and $k_2$ in $J$ denotes the number of non-zero rows.
We protect $k_2,k_4$ using oblivious selection-multiplication ($\SM$) protocol in Section~\ref{sec::osm_pro} as the elements in diagonal matrices $\Gamma,J$ are either $1$ and $0$.
We design the $\SM$ protocol to achieve binary-arithmetic multiplication, which requires less communication costs than secure multiplication.

 Oblivious selection-multiplication is used for $J \times$ (see Theorem~\ref{the::q_decom}) and $\Gamma \times$ (see Theorem~\ref{the::p_decom}) since the entries in $J, \Gamma$ are binary (essentially representing the sparsity degree).
In the MPC domain, binary-arithmetic multiplication can not be achieved by arithmetic-arithmetic multiplication.


Since $\Xsf$ is dense, the entry values in $\Xsf$ are irrelevant to topological relations of non-zero products (\ie, only matter to non-zero product values).
Accordingly, the joining party who owns the private graph can derive permutation operations corresponding to its graph.
$\Sigma, \delta$ are public matrices (\ie, no need for protection) as they are identical for an arbitrary graph.

\fi

\subsection{Oblivious Permutation}
\label{sec::op_pro}
Protocol~$\Pi_{\ssp}$
is our oblivious permutation protocol.
%(\sigma, \xvec, \type)$
Given $\pp_0$'s private permutation $\sigma\in\Sbb_k$ and $\pp_1$'s private $k$-dimensional vector $\xvec\in\Zbb^k_{2^L}$, $\Pi_{\ssp}$ generates a secret share $\l \sigma\xvec \r_i$ for $\pp_i \in \{\pp_0, \pp_1\}$ without revealing $\sigma$ or $\xvec$.
%$\pp_0$ and $\pp_1$ jointly compute the permuted output $\sigma\xvec\in\Zbb^e_{2^L}$ 
%in a way that $\pp_0$ knows nothing about $\xvec$ and $\pp_1$ learns nothing about $\sigma$.
%by modifying a three-party protocol proposed for the private set intersection.
%In Protocol~\ref{fig::sspcons:main}, 
The protocol parameter $\type \in \{\raw, \shared\}$ specifies the type of input vector $\xvec$.
If $\type$ is $\raw$, $\xvec$ is initially owned by $\pp_1$; otherwise, it is secret-shared among $\pp_0$ and $\pp_1$.
%which means that $\xvec$ is initially owned by $\pp_1$ or shared-owned by $\pp_0, \pp_1$.
%After joint protocol execution, $\pp_0$ obtains the share $\l\sigma(x)\r_0\in\Zbb^e_{2^L}$ and $\pp_1$ obtains the share $\l\sigma(x)\r_1\in\Zbb^e_{2^L}$ such that $\l\sigma(x)\r_0 + \l\sigma(x)\r_1 =\ sigma(x)$.

\begin{protocol}[!t]
\caption{$\Pi_{\ssp}$: Oblivious Permutation}\label{fig::sspcons:main}
\begin{algorithmic}[1]
	\item[\textbf{Parameter:} $\pp_0$ and $\pp_1$ know $\type \in \{\raw, \shared\}$.]
	\REQUIRE $\pp_0$ inputs $\sigma$ and $\pp_1$ inputs $\xvec$ if $\type == \raw$;
	\\~~~~~otherwise, $\pp_0$ inputs $(\sigma, \l\xvec\r_0)$ and $\pp_1$ inputs $\l\xvec\r_1$.
	\ENSURE $\pp_0$ gets $\l \sigma\xvec \r_0$ and $\pp_1$ gets $\l \sigma\xvec \r_1$.
	\STATE {\color{gray}\COMMENT{Offline Phase: Generate Correlated Randomness}}
	%\STATE $\tt$: Generates random permutation $\pi$ and matrix $\uvec$
	%\STATE $\tt$: Computes $\pi\uvec$ and generates $\l \pi\uvec \r_0, \l \pi\uvec \r_1$
	%\STATE $\tt$: Sends $\pi, \l \pi\uvec \r_0$ to $\pp_0$ and $\l \pi\uvec \r_1$ to $\pp_1$
	\STATE $\tt, \pp_0$: Get $\pi, \l \pi\uvec \r_0 \leftarrow \prf(\key_0, \ctr)$
	\STATE $\tt, \pp_1$: Get $\uvec \leftarrow \prf(\key_1, \ctr)$
	\STATE $\tt$: Send $\l \pi\uvec \r_1 = \pi\uvec - \l \pi\uvec \r_0$ to $\pp_1$
	\STATE {\color{gray}\COMMENT{Online Phase: Compute $\l \sigma\xvec \r$ in 1 Round}}
	\STATE $\pp_0$: Send $\delta_{\sigma} = \sigma \cdot \pi^{-1}$ to $\pp_1$\label{pro:op:masksigma}
	\IF{ $\type == \raw $}
		\STATE $\pp_1$: Send $\delta_{\xvec} = \xvec-\uvec$ to $\pp_0$\label{pro:op:maskx}
		\STATE $\pp_0$: Compute $\l \sigma\xvec\r_0={\color{colora}\sigma\delta_{\xvec} + \delta_{\sigma} \l \pi\uvec \r_0}$\label{pro:op:reconst0raw}
	\ELSE
		\STATE $\pp_1$: Send $\delta_{\l \xvec \r_1} = \l \xvec \r_1-\uvec$ to $\pp_0$\label{pro:op:sendmaskedx1}
		\STATE $\pp_0$: Compute $\l \sigma\xvec\r_0 = {\color{colora} \sigma\delta_{\l \xvec\r_1} + \delta_{\sigma} \l \pi\uvec \r_0 + \sigma \l \xvec \r_0}$\label{pro:op:reconst0shared}
	\ENDIF
	\STATE $\pp_1$: Compute $\l \sigma\xvec\r_1= {\color{colorb}\delta_{\sigma} \l \pi\uvec \r_1}$\label{pro:op:reconst1}
	\RETURN $\l \sigma\xvec \r$
\end{algorithmic}
\end{protocol}
\begin{table}[!t]
\centering
		\caption{Communication for Oblivious Permutation}
				\setlength\tabcolsep{6pt}
			\begin{tabular}{l|c|c|c}
			 \hline
\textbf{Protocol} & \textbf{Offline} & \textbf{Online} & \textbf{Round} \\
\hline
Asharov~\etal~\cite{ccs/AsharovHIKNPTT22} &$0$&$6k\bitlen$ &$3$\\\hline
OLGA~\cite{ccs/AttrapadungH0MO21} & $2k(\bitlen + 32)$ &$2k\bitlen $ & $1$\\\hline
Araki~\etal~\cite{ccs/Araki0OPRT21} & $0$ & $4k\bitlen$& 2 \\ \hline 
\rowcolor{grayL}$\Pi_\ssp$ & $k\bitlen$& $ k\bitlen + k\log k$ & $1$
\\\hline
%		 \hline 
			\end{tabular}\\
$\bitlen$: bit-length of data,
$k$: degree of the permutation group 
\label{table:op_comm}
\end{table} 

\paragraph{Offline Phase.}
The commodity server $\tt$ assists $\pp_0$ and $\pp_1$ to generate a random permutation $\pi\in\Sbb_k$, a random vector $\uvec\in\Zbb^k_{2^L}$, and correlated randomnesses $\l \pi \uvec \r_0\in\Zbb^k_{2^L}, \l \pi \uvec \r_1\in\Zbb^k_{2^L}$.
%correlated randomness $\bvec\in\Zbb^e_{2^L},h\in\Sbb_e, \uvec\in\Zbb^e_{2^L}, \l \uvec\r_0\in\Zbb^e_{2^L}, \l \uvec\r_1\in\Zbb^e_{2^L}$.
%, where $h$ satisfies uniform distribution on $\Sbb$.

\iffalse
\begin{protocol}[!t]
 %\vspace{-3mm}
		\begin{algorithmic}[1]
\REQUIRE $\pp_0$ inputs $\sigma$ and $\pp_1$ inputs $\xvec$ if $\type == \raw$; otherwise $\pp_0$ inputs $\sigma, \l\xvec\r_0$ and $\pp_1$ inputs $\l\xvec\r_1$ if $\type == \shared$.
\ENSURE $\pp_0$ gets $\l \sigma(\xvec)\r_0$ and $\pp_1$ gets $\l \sigma(\xvec)\r_1$.
		\STATE {\color{gray}\COMMENT{Offline Phase: Generate Correlated Randomness}}
		\STATE $\tt, \pp_0$: Get $h, \langle \uvec\rangle_0\leftarrow\prf_0(\mathsf{key}_0 ) $ 
		\STATE $\tt, \pp_1$: Get $\bvec\leftarrow\prf_1(\mathsf{key}_1 ) $
		%
		\STATE $\tt$: Get $\langle \uvec\rangle_1=h(\bvec)-\langle \uvec\rangle_0$ and send $\langle \uvec\rangle_1$ to $\pp_1$
		\STATE {\color{gray}\COMMENT{Online Phase: Reconstruct $\sigma(\xvec)$ in 1 Round}}
		\STATE $\pp_0$: Get $\delta_{\sigma} = \sigma \cdot h^{-1}$ and {send $\delta_{\sigma}$} to $\pp_1$\label{pro:op:l6}
			\IF{ $\type == \raw $}
		\STATE $\pp_1$: Get $\delta_{\xvec} = \xvec-\bvec$ and {send $\delta_{\xvec}$} to $\pp_0$ \label{pro:op:l8}
		\STATE $\pp_0$: Get $\l \sigma(\xvec)\r_0={\color{cyan}\sigma(\delta_{\xvec}) + \delta_{\sigma} (\langle \uvec\rangle_0)}$ \label{pro:op:l9}
%and output 
	\ENDIF
	\IF{$\type == \shared$} 
		\STATE $\pp_1$: Get $\delta_{\l \xvec \r_1} = \l \xvec \r_1-\bvec$, {send $\delta_{\l \xvec \r_1}$} to $\pp_0$\label{pro:op:l12}
		 \STATE $\pp_0$: Get $\l \sigma(\xvec)\r_0 = {\color{cyan} \sigma(\delta_{\langle \xvec\rangle_1}) + \delta_{\sigma} (\langle \uvec\rangle_0) + \sigma (\langle \xvec \rangle_0)}$\label{pro:op:l13}
	\ENDIF
		\STATE $\pp_1$: Get $\l \sigma(\xvec)\r_1= {\color{ao}\delta_{\sigma} (\langle \uvec\rangle_1)}$ \label{pro:op:l15}
		\end{algorithmic}
	\caption{$\Pi_{\ssp}$: Oblivious Permutation}\label{fig::sspcons:main}%\vspace{-4mm}
\end{protocol}
 \fi

\paragraph{Online Phase.}
%In the $\raw$ case, 
$\pp_0$ masks $\sigma$ using random $\pi^{-1}$ (\ie, inverse permutation of $\pi$) to get random {$\delta_\sigma$ ({Line~\ref{pro:op:masksigma}})}.
If $\type$ is $\raw$, $\pp_1$ masks $\xvec$ using random $\uvec$ to get $\delta_\xvec$ (Line~\ref{pro:op:maskx}).
%Line~\ref{pro:op:l6} is essentially to protect $\sigma$ since $\pp_1$ can only view $\delta_\sigma$ and knows nothing about $\sigma, \pi$.
%$\pp_1$ masks $\xvec$ using random $\bvec$ to get random {$\delta_\xvec$ (Line~\ref{pro:op:l8})}.
%Line~\ref{pro:op:l8} is essentially to protect $\xvec$ since $\pp_0$ can only view $\delta_\xvec$ and know nothing about $\xvec, \bvec$.
If $\type$ is $\shared$, 
%In the $\shared$ case, $\pp_0$ masks $\sigma$ using random $h^{-1}$, which is identical to the $\raw$ case.
$\pp_1$ needs not mask $\xvec$ since $\l \xvec \r_0$ is kept by $\pp_0$ %all the time 
as a part of computing $\l \sigma\xvec\r_0$ (Line~\ref{pro:op:reconst0shared}).
In this case, $\pp_1$ masks $\l \xvec\r_1$ using random $\uvec$ to get random {$\delta_{\l\xvec\r_1}$ (Line~\ref{pro:op:sendmaskedx1})}.
%Line~\ref{pro:op:sendmaskedx1} is essentially to protect $\l\xvec\r_1$ since $\pp_0$ can only view $\delta_{\l\xvec\r_1}$ and know nothing about ${\l\xvec\r_1}, \bvec$.
%$\pp_0$ uses the offline-generated randomness $h$ to mask the permutation $\sigma$.
%If the input type of $\xvec$ is $\raw$, $\pp_1$ masks $\Xsf$ using offline-generated randomness $\bvec$, otherwise masking $\l\Xsf\r_1$.
$\pp_0$ and $\pp_1$ can then obtain the respective secret shares $\l \sigma\xvec\r_0, \l \sigma\xvec\r_1$.
%such that $\sigma(\xvec) = \l \sigma(\xvec)\r_0 + \l \sigma(\xvec)\r_1$.

\paragraph{Correctness.}
%The correctness of $\Pi_\ssp$ is to 
Here, we verify that %$\pp_0$ and $\pp_1$ jointly compute the functionality $\sigma(\xvec)$ (defined in Figure~\ref{func::ssp}) such that 
${\color{colora}\l\sigma\xvec\r_0} + {\color{colorb}\l\sigma\xvec\r_1} = \sigma\xvec$.
If $\type$ is $\raw$, it holds that $\sigma\Xsf = \sigma (\Xsf-\uvec + \uvec) = \sigma(\delta_{\Xsf} + \uvec) = \sigma\delta_{\Xsf} + \sigma\uvec = \sigma\delta_{\Xsf} + \sigma \pi^{-1}\pi\uvec = \sigma\delta_{\xvec} + \delta_{\sigma} \pi \uvec={\color{colora}\sigma\delta_{\xvec} + \delta_{\sigma} \l\pi \uvec\r_0} + {\color{colorb}\delta_{\sigma} \l \pi \uvec\r_1}$.

If $\Xsf$'s $\type$ is $\shared$,
$\sigma\Xsf = \sigma (\l \Xsf \r_0 + \l \Xsf \r_1-\uvec + \uvec) = \sigma(\l \Xsf \r_0 + \delta_{\l\Xsf\r_1} + \uvec) = \sigma \l \Xsf \r_0 + \sigma\delta_{\l\Xsf\r_1} + \sigma \pi^{-1} \pi\uvec = \sigma \l \Xsf \r_0 + \sigma\delta_{\l\Xsf\r_1} + \delta_{\sigma}\pi \uvec={\color{colora}\sigma \l \Xsf \r_0 + \sigma\delta_{\l\Xsf\r_1} + \delta_{\sigma}\l\pi \uvec\r_0} + {\color{colorb}\delta_{\sigma}\l\pi \uvec\r_1}$.

\paragraph{Communication.}
Since $\sigma \in \Sbb_k$, $\log k$ bits are enough to represent $k$ elements.
The online phase of $\Pi_\ssp$ requires communication of $k\log k + kL$ bits (\ie, sending $\delta_\sigma, \delta_\Xsf$ in the $\raw$ case or sending $\delta_\sigma, \delta_{\l\Xsf\r_1}$ in the $\shared$ case) in $1$ round.

\paragraph{Comparison to Existing Works.}
%\todo[inline]{Move Table~\ref{table:op_comm} and related text here}
%\ak{How about writing a bit to ``explain'' the Table and show the improvement of our protocols over the existing work? E.g., XXX requires communication of YY bits in ZZ rounds...Our work reduces online communication by XX\% and saves YY online rounds...}
Asharov~\etal~\cite{ccs/AsharovHIKNPTT22} spend $6kL$~bits online in three rounds.
Araki~\etal~\cite{ccs/Araki0OPRT21}'s oblivious shuffle requires $4kL$~bits in two rounds for $k$-element permutation.
The OLGA protocol~\cite{ccs/AttrapadungH0MO21} is $1$-round but communicates $2k(L + 32)$~bits offline and $2kL$~bits online.
Our $\Pi_{\ssp}$ protocol is also $1$-round, communicates $kL$~bits offline and $kL + k\log k$~bits online.
Particularly, $k$ equals to $\numedge$ or $\numnode$ for GCN.
%is equal to $\numedge$ for $\sigma_2, \sigma_3, \sigma_4$ and $\numnode$ for $\sigma_1, \sigma_5$.
In practice, $\log k$ is much smaller than $L$, \eg, for a $10^6$-node graph, $\log k= 20< L=64$.

\subsection{Oblivious Selection-Multiplication}
\label{sec::osm_pro}

We design the oblivious selection-multiplication %($\SM$) 
protocol $\Pi_{\SM}$ %(s,x)$ over private $s$ 
in Protocol~\ref{fig:osm-main}.
It takes a private bit (called ``selector'') 
$s\in\Zbb_{2}$ from $\pp_0$ and a secret share $\l x \r$ of an arithmetic number $x\in\Zbb_{2^L}$ owned by $\pp_0$ and $\pp_1$.
$\Pi_{\SM}$ generates a secret share of $0$ if $s=0$ or share of $x$ otherwise without disclosing $s$ or $x$.

\begin{protocol}[!t]
\caption{$\Pi_{\SM}$: Oblivious Selection-Multiplication}\label{fig:osm-main}
\begin{algorithmic}[1]
	%\item[\textbf{Parameter:} No extra parameter.]
	\REQUIRE $\pp_0$ inputs $(s, \l x \r_0)$ and $\pp_1$ inputs $\l x \r_1$.
	\ENSURE $\pp_0$ gets $\l sx \r_0$ and $\pp_1$ gets $\l sx \r_1$.
	\STATE {\color{gray}\COMMENT{Offline Phase: Generate Correlated Randomness}}
	%\STATE $\tt$: Generates random bit $b$ and scalar $u$
	%\STATE $\tt$: Computes $bu$ and generates $\l bu \r_0, \l bu \r_1$
	%\STATE $\tt$: Sends $b$, $\l bu \r_0$ to $\pp_0$ and $\l bu \r_1$ to $\pp_1$
	\STATE $\tt, \pp_0$: Get $(b, \l u \r_0, \l bu \r_0) \leftarrow \prf(\key_0, \ctr)$
	\STATE $\tt, \pp_1$: Get $\l u \r_1 \leftarrow \prf(\key_1, \ctr)$
	\STATE $\tt$: Send $\l bu \r_1 = bu - \l bu \r_0$ to $\pp_1$
	\STATE {\color{gray}\COMMENT{Online Phase: Compute $\l sx \r$ in 1 Round}}
	\STATE $\pp_0$: Send $\delta_s= s-b$ to $\pp_1$\label{osm::masks}%\label{osm::l13}\label{osm::l14}\label{osm::l16} 
	\STATE $\pp_1$: Send $\delta_{\l x\r_1} = \l x\r_1 - \l u\r_1$ to $\pp_0$\label{osm::maskx1}%\label{osm::l15}
	\STATE $\pp_0$: Compute $\delta_x =\l x \r_0 - \l u\r_0 + \delta_{\l x\r_1}$
	\STATE $\pp_0$: Compute $\langle sx \rangle_0 = {\color{colora}s \delta_x + \delta_s \l u\r_0 + (-1)^{\delta_s} \l bu\r_0}$\label{osm::l18}
	\STATE $\pp_1$: Compute $\langle sx \rangle_1 = {\color{colorb}\delta_s\l u\r_1 + (-1)^{\delta_s}\l bu\r_1}$\label{osm::l19}
	\RETURN $\l sx \r$
\end{algorithmic}
\end{protocol}
\begin{table}[!t]
\centering
		\caption{Communication for Oblivious Selection-Mult.}
			\setlength\tabcolsep{12pt}
			\begin{tabular}{l|c|c|c}
 		\hline
\textbf{Protocol} & \textbf{Offline} & \textbf{Online} & \textbf{Round} \\
\hline
$\promult$~\cite{crypto/Beaver91a} & $\bitlen$&$2\bitlen$& $1$\\\hline
OT~\cite{pkc/Tzeng02} &$\bitlen$&$2\bitlen + 1$&$1$\\\hline
%B2A~\cite{ndss/ABY15} &-&$(\bitlen+1)\bitlen/2$& $\log L$\\\hline
\rowcolor{grayL}$\Pi_\SM$ & $\bitlen$&$\bitlen + 1$& $1$\\
 	 \hline 
			\end{tabular}

 $\bitlen$: bit-length of data
 % $e$ is the degree of the permutation group.
\label{table:osm_comm}
\end{table} 

%$s\in\Zbb_{2}$ is a binary number, independently owned by $\pp_0$.
%(\ie, $\type =\ raw$) or secret-shared (\ie, $\type =\ shared$) between two parties.
%$x\in\Zbb_{2^L}$ is an arithmetic number, which is shared-owned by two parties because $\SM$ is executed in the intermediate process of secure training.
%If $s=0$, $sx$ returns $0$; if $s=1$, $sx$ returns $x\in\Zbb_{2^L}$.
%We call $s$ the selector since $s$ is the role of choosing a value from $x$ and $0$.
%In the execution of $\Pi_\SM$, $\pp_0$ and $\pp_1$ jointly compute $sx$ in a way that $\pp_0$ does not know $\pp_1$'s inputs and $\pp_1$ does not know $\pp_0$'s inputs.
%After executing the protocol $\Pi_\SM$, $\pp_0$ obtains the share $\l sx\r_0\in\Zbb_{2^L}$, and $\pp_1$ obtains the share $\l sx\r_1\in\Zbb_{2^L}$ such that $\l sx\r_0 + \l sx\r_1=sx$.

%For functionality, $\SM$ is identical to AB-to-B multiplication
%$s b=c$ that outputs the arithmetic share of $c$
%\yuzh{*************}
%Consider two parties $\pp_0$ and $\pp_1$.
%In the $\raw$ case (i.e., the $\type$ of $s$ is $\raw$), $\pp_0$ owns the private $s$ and the share $\l x\r_0$, while $\pp_1$ owns the share $\l x\r_1$.
%Here,
%The shares of $x$ are the output shares from the prior protocol.

\paragraph{Offline Phase.}
The commodity server $\tt$ assists $\pp_0, \pp_1$ to generate a random bit $b\in\Zbb_{2}$, a secret share of a random number $u\in\Zbb_{2^L}$, and correlated randomness $\l bu \r_0 \in \Zbb_{2^L}, \l bu \r_1 \in \Zbb_{2^L}$

\iffalse
correlated randomness $h, \l h\r_0, \l h\r_1\in\Zbb_2$ and $b, \l b \r_0, \l b \r_1,u , \l u \r_0, \l u \r_1\in\Zbb_{2^\bitlen}$ such that
$u=hb,h =\ l h\r_0 + \l h\r_1, b =\ l b\r_0 + \l b\r_1, u = \l u\r_0 + \l u\r_1$.
These randomnesses can be realized by 1) generating the random $\l u\r_0, \l h\r_0, \l h\r_1, \l b\r_0, \l b\r_1$, 2) computing $u=hb$, and 3) splitting $u$ to $\l u\r_0, \l u\r_1$.
\fi

\paragraph{Online Phase.}
%In the $\raw$ case, 
$\pp_0$ masks $s$ using random $b$ to generate random $\delta_s$ (Line~\ref{osm::masks}).
%%, and masks $\l x\r_0$ using $\l b\r_0$ to generate random $\delta_{\l x\r_0}$ (Line~\ref{osm::l13}).
%Line~\ref{osm::l13} in $\Pi_\SM$ is essentially to protect the $\pp_0$'s inputs from viewing by $\pp_1$ since
%Then, $\pp_1$ can only view the masked random values of $\delta_s$ sent by $\pp_0$ in Line~\ref{osm::l15}.
%Thus, $\pp_1$ does not know $s$ and $x$.
%, i.e., the selector denoting which value to choose.
$\pp_1$ masks $\l x\r_1$ using random $\l u\r_1$ to generate random $\delta_{\l x\r_1}$ (Line~\ref{osm::maskx1}).
%Line~\ref{osm::l14} in $\Pi_\SM$ is essentially to protect the $\pp_1$'s inputs from viewing by $\pp_0$ since 
%Thus, $\pp_0$ can only view the masked random values of $\delta_{\l x\r_1}$ sent by $\pp_1$ in Line~\ref{osm::l16}, \ie, not knowing $x$.
%Thus, neither $\pp_0$ or $\pp_1$ knows $x$, i.e., only knowing one share of $x$.
After receiving the masked $\l x\r_1$ and $s$, $\pp_0$ and $\pp_1$ can respectively compute the shares $\l sx\r_0, \l sx\r_1$.


%Finally, after execution of $\Pi_{\SM}(s,x, \type)$, $\pp_0$ obtains the share $\l sx\r_0$, and $\pp_1$ obtains the share $\l sx\r_1$.
%Neither $\pp_0, \pp_1$ knows $s,x$ as they know the only one share of $s,x$.

%In other words, $\pp_0$ selects a value from $x$ (in the form of $\l x \r_0, \l x \r_1$, which are shared-owned) and $0$, while $\pp_1$ does not know which value $\pp_0$ chooses.

%Simultaneously, $\pp_0$ does not know the exact value of $\l x\r_1$ (thus also does not know $x$).


%In the $\shared$ case, the input $s$ is shared-owned by $\pp_0$ and $\pp_1$.
%That is, before the execution of $\Pi_{\SM}$, $\pp_0$ owns the shares $\l s\r_0, \l x\r_0$, meanwhile,
%$\pp_1$ owns the shares $\l s\r_1, \l x\r_1$ such that $\l s\r_0 + \l s\r_1=s, \l x\r_0 + \l x\r_1=x$.
%During the protocol execution, $\pp_0$ and $\pp_1$ jointly compute $sx$.
%After the protocol execution, $\pp_0$ does not know $\pp_1$'s inputs $\l s\r_1, \l x\r_1$ (thus also does not know $s$ and $x$); $\pp_1$ does not know $\pp_0$'s inputs $\l s\r_0, \l x\r_0$ (thus also does not know $s$ and $x$).


%\in\Zbb_{2^L}$ on the binary input of $s\in\Zbb_2$ and the arithmetic share of $b\in\Zbb_{2^L}$.
%
%Our $\SM$ protocol adopts the functionality of oblivious selection~\cite{ccs/AttrapadungH0MO21} for obliviously selecting $s$ from $\{0,1\}$, acting as 1-out-of-2 oblivious transfer (OT).





\iffalse
\begin{definition}[Obliviously-Selected Multiplication]
\label{def::osm}
	Let $\pp_0$ hold a private selection $s\in\{0,1\}$ and an arithmetic share $\l x \r_0$.
	Let $\pp_1$ hold an arithmetic share $\l x\r_1$.
	Obliviously-selected multiplication $\SM$ is that $\pp_0$ and $\pp_1$ collaboratively compute $s\cdot x$ without revealing any inputs, and output $\l s x\r_0, \l sx\r_1$.
\end{definition}
\fi

\iffalse
\begin{protocol}[!t]
	\caption{$\Pi_{\SM}$: Oblivious Selection-Multiplication}\label{fig:osm-main}
		\begin{algorithmic}[1]
		 \STATE {\color{gray}\COMMENT{Offline Phase: Generate Correlated Randomness}}
	\STATE $\tt, \pp_0$: Get $h, \l b\r_0, \langle u \rangle_0 \leftarrow \mathsf{PRF}_0(\mathsf{key}_0 ) $ 
\STATE $\tt, \pp_1$: Get $\l b\r_1, \langle u \rangle_1\leftarrow\mathsf{PRF}_1(\mathsf{key}_1 ) $
\STATE $\tt$: Get $\langle u \rangle_1= hb - \langle u \rangle_0$ and send $\langle u \rangle_1$ to $\pp_1$
		\STATE {\color{gray}\COMMENT{Online Phase: Reconstruct $sx$ in 1 Round}}
		\STATE $\pp_0$: Get $\delta_s= s- h, \delta_{\l x\r_0} =\ l x\r_0 -\l b\r_0$\label{osm::l13}
\STATE $\pp_1$: Get $\delta_{\l x\r_1} = \l x\r_1 - \l b\r_1$\label{osm::l14} 
\STATE $\pp_0$: Send $\delta_s$ to $\pp_1$\label{osm::l15}
\STATE $\pp_1$: Send $\delta_{\l x\r_1}$ to $\pp_0$\label{osm::l16} 
\STATE $\pp_0$: Get $\delta_x= \delta_{\l x\r_0} + \delta_{\l x\r_1}$
\STATE $\pp_0$: Get $\langle sx \rangle_0 = {\color{cyan}s \delta_x + \delta_s \l b\r_0 + (-1)^{\delta_s} \l u\r_0}$\label{osm::l18}
\STATE $\pp_1$: Get $\langle sx \rangle_1 = {\color{ao}\delta_s\l b\r_1 + (-1)^{\delta_s}\l u\r_1}$\label{osm::l19}

		\end{algorithmic}
	%\vspace{-4mm}
\end{protocol}
 \fi

\paragraph{Correctness.}
Here, we 
%Correctness of $\Pi_\SM$ is to 
verify that %the output shares 
${\color{colora}\l sx\r_0} + {\color{colorb}\l sx\r_1}=sx$ %building upon 
by using Lemma~\ref{lem::sxb}
(proven in Appendix~\ref{sec:proof_lemma}).
%Protocol~\ref{fig:osm-main} is which happens to group action of binary element multiplying arithmetic element.

\begin{restatable}{lemma}{sxb}
\label{lem::sxb}
Let $\Abb$ be an Abelian group and $\Bbb =\{0, 1\}$ be the binary group.
Let map $f: \Bbb \times \Abb \rightarrow \Abb$ be defined as $f(s, x) = x \mbox{ if } s = 1 \mbox{ else } 0$.
Then, for any $s,b\in \Bbb$ and $x,u\in\Abb$:
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
	\setlength{\parsep}{0pt}
\item[(i)] $f(s, x + u) = f(s, x) + f(s, u)$.
\item[(ii)] $f(s + b, x) = f(s, x) + (-1)^s f(b, x)$.
\end{itemize}
\iffalse
\begin{equation*}
\begin{array}{l}
(i).\ f(s, x + u) = f(s, x) + f(s, u) \\
%f(s-\tilde{s}, x) = (-1)^{\tilde{s}} (f(s,x)-f(\tilde{s}, x))
(ii).\ f(s + b, x) = f(s, x) + (-1)^s f(b, x).
\end{array}
\end{equation*}
\fi
\end{restatable}

%Take $f$ to be multiplication.
Let $f: \Bbb \times \Abb \rightarrow \Abb$ be the same $f$ as above.
Using Lemma~\ref{lem::sxb}, we have
%the case of $\raw $ can be verified by 
$f(s,x) =f(s, x- u) + f(s, u) 
=f(s, \delta_x) + f(s - b + b, u ) 
=f(s, \delta_x) + f(\delta_s, u) + (-1) ^{\delta_s }f(b, u)=s\delta_x + \delta_s u + (-1)^{\delta_s} (bu)=s\delta_x + \delta_s \l u\r_0 + \delta_s \l u\r_1 + (-1)^{\delta_s} (bu)={\color{colora}s\delta_x + \delta_s \l u\r_0} + {\color{colorb}\delta_s \l u\r_1} + {\color{colora}(-1)^{\delta_s} \l bu\r_0} + {\color{colorb}(-1)^{\delta_s} \l bu\r_1}$.
%When taking $f$ to be multiplication, we attain $sx= s\delta_x + \delta_s b + (-1)^{\delta_s} (hb)$, where $u=hb$.
%The case for `$\shared$' is similar, which is proven in Appendix~\ref{sec::proof_osm_corr}.

\paragraph{Communication.}
$\Pi_\SM$ requires communicating $L + 1$ bits (\ie, $65$ bits for sending $ \delta_{\l x\r_1}, \delta_s$) online in $1$ round.
%in the $\raw$ case.
%or $2L + 2$ sending $\delta_{\l x\r_0}, \delta_{\l x\r_1}, \delta_{\l s\r_0}, \delta_{\l s\r_1}$ in the $\shared$ case.
Except for $\Pi_\SM$, OT based~\cite{pkc/Tzeng02} protocol (by using two OT instances to select $\l x\r$ and $0$) and standard arithmetic multiplication (by transforming binary $s\in\Zbb_2$ into arithmetic $s\in\Zbb_{2^\bitlen}$) can also realize the functionality of section-multiplication.
As compared in Table~\ref{table:osm_comm}, our protocol saves about $50\%$ of communication while having the same round complexity compared to the OT-based~\cite{pkc/Tzeng02} protocol and standard Beaver-triple-based~\cite{crypto/Beaver91a} ($\promult$).
%by regarding $s$ as an arithmetic number 
%, \ie, requiring $2L$ bits online.
%in the $\raw$ case or $4L$ in the $\shared$ case.}


\subsection{Construction of \texorpdfstring{\osmm}{OSMM}}
\label{subsec:prosmm}
Based on our sparse matrix decomposition and protocols for OP and OSM, we present our \osmm protocol $\prosmm$ in Protocol~\ref{fig:osmm}.
It takes a sparse matrix $\adjmat \in \Mbb_{m,n}(\Rcal)$ from $\pp_0$ and a dense matrix $\feamat \in \Mbb_{n,d}(\Rcal)$ from $\pp_1$.
$\prosmm$ generates a secret share $\l \adjmat \feamat \r_i$ for $\pp_i \in \{\pp_0, \pp_1\}$ without leaking $\adjmat$ or $\feamat$.

\paragraph{\osmm Realization.}
Following Theorem~\ref{the::smm_main}, $\prosmm$ essentially performs an ordered sequence of linear transformations ($\sigma_5 \delta_m ^{\top} \gammaout \sigma_4 \Sigma ^{\top} \allowbreak\Lambda \sigma_3 \Sigma \sigma_2 \gammain \delta_n \sigma_1$) from right to left over $\pp_1$'s private input $\feamat$.
%Secure sparse matrix multiplication (\osmm) can be realized by sequentially (\ie, Theorem~\ref{the::smm_main}) integrating the $\ssp$ protocols and local multiplication as Figure~\ref{fig:osmm1}.
%In this way, $\pp_0$'s adjacency matrix is regarded as an ordered sequence of linear transformations ($\sigma_5 \delta_m ^{\top} \Gamma_{k_4} \sigma_4 \Sigma ^{\top} \sigma_3 \Sigma \sigma_2 J_{k_2} \delta_n \sigma_1$) over $\pp_1$'s $\feamat$.
Multiplying public matrices $\delta_n, \Sigma, \Sigma^{\top}, \delta_m^T$ can be done non-interactively on secret shares %$\pp_0$'s and $\pp_1$'s share 
(Lines~\ref{osmm::deltan},~\ref{osmm::Sigma},~\ref{osmm::Sigmat},~\ref{osmm::deltam}).

Permuting the rows of input $\feamat$ or intermediate output $\Ysf$ based on $\sigma_1, \ldots, \sigma_5$ are performed by invoking $d$ parallel ${\Pi}_{\ssp}$ instances as ${\Pi}_{\ssp}$ takes a column vector as input, 
but $\feamat$ and $\Ysf$ are matrices with $d$ columns (Lines~\ref{osmm::sigma1},~\ref{osmm::sigma2},~\ref{osmm::sigma3},~\ref{osmm::sigma4},~\ref{osmm::sigma5}).

Since $\gammain$ and $\gammaout$ are diagonal matrices with binary values, multiplications of them (Lines~\ref{osmm::gammain} and~\ref{osmm::gammaout}) can be done by $nd$ and $md$ parallel $\Pi_\SM$ instances, respectively.\footnote{
In practice, the parties need to pad zero values (non-interactively) before invoking the first $\Pi_\SM$ and cutting off zero values after invoking the last $\Pi_\SM$ to ensure consistent matrix dimensionality.
For simplicity, we omit this step in our $\prosmm$ protocol presentation.
}
% todo: explain why $nd$ and $md$ (tedious details) if have time and space
Multiplication of $\Lambda$, a diagonal matrix with arithmetic values, is performed similarly,
%as above 
but we can use the standard Beaver-triple-based multiplication protocol $\promult$ (Line~\ref{osmm::lambda}) instead of $\Pi_\SM$.

%Secure SMM via Beaver triples requires $O(n^2)$ costs of communication or random-access memory, while plaintext sparse MM mostly targets fast computation instead of low communication.
%Rather than considering each entry value as $\pp_0$'s private inputs,

\begin{protocol}[!t]
\caption{$\prosmm$: Secure Sparse Matrix Multiplication}\label{fig:osmm}
\begin{algorithmic}[1]
	%\item[\textbf{Parameter:} No extra parameter.]
	\REQUIRE $\pp_0$ inputs $\adjmat$ and $\pp_1$ inputs $\feamat$.
	\ENSURE $\pp_0$ gets $\l \Ysf \r_0$ and $\pp_1$ gets $\l \Ysf \r_1$ where $\Ysf = \adjmat\feamat$.
	\STATE $\pp_0$: Decomposes $\adjmat= \sigma_5 \delta_m ^{\top} \gammaout \sigma_4 \Sigma ^{\top} \Lambda \sigma_3 \Sigma \sigma_2 \gammain \delta_n \sigma_1$\label{osmm::decom}
	\STATE $\pp_0, \pp_1$: Invoke $\l \Ysf \r \leftarrow {\Pi}_{\ssp}(\sigma_1;\Xsf)$ \COMMENT{$\type == \raw$}\label{osmm::sigma1}
	\STATE $\pp_0, \pp_1$: Locally compute $\l \Ysf \r = \delta_n \l \Ysf \r$\label{osmm::deltan}
	\STATE $\pp_0, \pp_1$: Invoke $\l \Ysf \r \leftarrow \Pi_\SM(\gammain, \l \Ysf \r_0; \l \Ysf \r_1)$\label{osmm::gammain}
	\STATE $\pp_0, \pp_1$: Invoke $\l \Ysf \r \leftarrow {\Pi}_{\ssp}(\sigma_2, \l \Ysf \r_0; \l \Ysf \r_1)$\label{osmm::sigma2}
	\STATE $\pp_0, \pp_1$: Locally compute $\l \Ysf \r = \Sigma \l \Ysf \r$\label{osmm::Sigma}
	\STATE $\pp_0, \pp_1$: Invoke $\l \Ysf \r \leftarrow {\Pi}_{\ssp}(\sigma_3, \l \Ysf \r_0; \l \Ysf \r_1)$\label{osmm::sigma3}
	\STATE $\pp_0, \pp_1$: Invoke $\l \Ysf \r \leftarrow \promult(\Lambda, \l \Ysf \r_0; \l \Ysf \r_1)$\label{osmm::lambda}
	\STATE $\pp_0, \pp_1$: Locally compute $\l \Ysf \r = \Sigma^\top \l \Ysf \r$\label{osmm::Sigmat}
	\STATE $\pp_0, \pp_1$: Invoke $\l \Ysf \r \leftarrow {\Pi}_{\ssp}(\sigma_4, \l \Ysf \r_0; \l \Ysf \r_1)$\label{osmm::sigma4}
	\STATE $\pp_0, \pp_1$: Invoke $\l \Ysf \r \leftarrow \Pi_\SM(\gammaout, \l \Ysf \r_0; \l \Ysf \r_1)$\label{osmm::gammaout}
	\STATE $\pp_0, \pp_1$: Locally compute $\l \Ysf \r = \delta_m^\top \l \Ysf \r$\label{osmm::deltam}
	\STATE $\pp_0, \pp_1$: Invoke $\l \Ysf \r \leftarrow {\Pi}_{\ssp}(\sigma_5, \l \Ysf \r_0; \l \Ysf \r_1)$\label{osmm::sigma5}
	\RETURN $\l \Ysf \r$
\end{algorithmic}
\end{protocol}

\paragraph{Graph Protection and  Dimensions.}
All entries of $\sigma_5, \sigma_4, \sigma_3, \sigma_2, \sigma_1, \allowbreak\gammaout, \gammain,$ and $\Lambda$ are protected in $\prosmm$.
The dimensions of $\sigma_1$ and $\sigma_5$ are $\numnode$, corresponding to the number of rows in $\Asf$ and $\Xsf$. Since $\Asf$ and $\Xsf$ are held by $\pp_0$ and $\pp_1$, respectively, the dimensions of $\sigma_1$ and $\sigma_5$ are considered reasonable public knowledge.
The dimensions of $\sigma_4, \sigma_3, \sigma_2,$ and $\Lambda$ are $\numedge$, representing tolerable leakage useful for sparsity exploration.
$\gammain$ has dimensions of $\numedge \times \numnode$, while $\gammaout$ is $\numnode \times \numedge$, both of which do not incur extra graph leakage beyond $\numedge$ or $\numnode$.
Importantly, such general statistical information  about the graph does not compromise the privacy of specific nodes or edges or incur identifiable risks.

\paragraph{Correctness.}
$\prosmm$ follows the same sequence of transformations as in Theorem~\ref{the::smm_main}, which shows the correctness of our sparse matrix decomposition.
Since the underlying ${\Pi}_{\ssp}$ and $\Pi_\SM$ protocols are correct, so does
our $\prosmm$ protocol.

%derived by correctly integrating $\ssp$ protocol in an ordered sequence (Theorem~\ref{the::smm_main}).
%Each sub-routing $\ssp$ protocol is correct, and the integration of basic operations is faithful.

\paragraph{Communication.}
$\prosmm$ invokes $5$ ${\Pi}_{\ssp}$, $2$ $\Pi_\SM$, and $1$ $\promult$, communicating $2(2\numnonzero + m + n)dL$ bits offline and $((5\numnonzero + 2m + 2n)\bitlen + 3\numnonzero \log \numnonzero + m\log m + n\log n + m + n)d$ bits online in $8$ rounds (see Table~\ref{table:SMM_comm} for a breakdown).
The Beaver-triple-based protocol $\promult$~\cite{crypto/Beaver91a} for (dense) matrix multiplication communicates $mndL$ bits offline and $2mndL$ bits online.
% in $1$ round.
%Yupeng Zhang's sp17 makes it O(mn+nd) using the same masks for each vector in the matrix.
%We can use the trivial version for simplification.
% t parallel $\promult$ instance at one time, modified to 1 for consistency

In practical GCN usages, we have $m = n = \numnode < t = \numedge \ll \numnode^2 = mn$ and $\log m, \log n, \log t < L = 64$.
Also, $d$ is a relatively small constant.
So, the communication cost of $\prosmm$ is simplified to $O(\numedge)$, rather than $O(\numnode^2)$, by directly using $\promult$ for each entry in SMM.
%If omitting the parameters (\ie, bit-length of data and feature dimensions) irrelevant to the graph topology, $\prosmm$'s communication costs are simplified to $O(m+n+t)$, where $m,n\ll t<mn$ normally, thus equivalent to $O(t)$ in computational complexity.

\begin{table}[!t]
	\centering
	\caption{Cost for \osmm on $\adjmat \in \Mbb_{m,n}(\Rcal)$ and $\feamat \in \Mbb_{n,d}(\Rcal)$}
	\setlength\extrarowheight{2pt}
	\setlength\tabcolsep{1pt}
	\begin{tabular}{l|c|c|c}
	\hline
	\textbf{Protocol} & \textbf{Offline} & \textbf{Online} & \textbf{Rd} \\
	\hline
	\multirow{2}{*}{$5\ {\Pi}_{\ssp}$} & \multirow{2}{*}{$(3t + m + n)d\bitlen$} & $((3t + m + n)\bitlen + 3t \log t$ & \multirow{2}{*}{$5$} \\
	& & $ + m \log m + n \log n)d$ & \\
	\hline
	$2\ \Pi_\SM$ & $(m + n)d\bitlen$ & $((m + n)\bitlen + m + n)d$ & $2$ \\
	\hline
	$1\ \promult$ & $td\bitlen$ & $2td\bitlen$ & $1$ \\
	\hline
	\rowcolor{grayL} & & $((5\numnonzero + 2m + 2n)\bitlen + 3\numnonzero\log \numnonzero$ & \\
	\rowcolor{grayL}\multirow{-2}{*}{$\prosmm$} & \multirow{-2}{*}{$2(2\numnonzero + m + n)dL$} & $ + m\log m + n\log n + m + n)d$ & \multirow{-2}{*}{$8$} \\\hline
	\end{tabular}\\
	%\begin{tablenotes}[para, flushleft]
		$t$: number of non-zero elements in $\adjmat$,
	$\bitlen$: bit-length of data,\\
	$d$: node feature dimensionality, Rd: round
	%\end{tablenotes}
	\label{table:SMM_comm}
\end{table}
