%!TEX root = gcn.tex
\section{System Overview and Security Model}
\label{sec::securitymodel}
%\textbf{Ownership of graphs.}
\subsection{Workflow of \texorpdfstring{$\cgnn$}{\textcgnn}}
Figure~\ref{graph_imple} outlines $\cgnn$'s function.
A graph owner $\pp_0$, 
with an adjacency matrix $\adjmat$ corresponding to a private graph $\graph$,
and a feature owner $\pp_1$ with private node features $\feamat$, aim to jointly train a GCN without revealing their private inputs.
This involves computing a parameterized function $\mathsf{GCN}(\adjmat, \feamat; \weimat)$, where the weights $\weimat$ are secret-shared over the two parties.

The $\cgnn$ framework includes a sparse matrix decomposition method (Section~\ref{sec::sgc}) and secure $2$PC protocols for permutation ($\Pi_{\ssp}$, Section~\ref{sec::op_pro}),
selection-multiplication ($\Pi_{\SM}$, Section~\ref{sec::osm_pro}), and SMM ($\prosmm$, Section~\ref{subsec:prosmm}).
%secure $2$PC protocols (Section~\ref{sec::smm_protocol}) for evaluating linear transformations and SMM (marked as OP, OSM, and \osmm in Figure~\ref{graph_imple}).
The sparse matrix decomposition is performed solely by the graph owner, while all $2$PC protocols are executed by both parties without disclosing any intermediate computation results.

In practical cross-institution collaboration, graph owners can be social networking platforms (\eg, Facebook) holding social relationships as a graph, and feature owners can be banks holding users' bank statements as node features.
As a motivating example, they may want to build a credit-investigation model for predicting the credit of a loaner for future repayment
while keeping their data confidential.
Our setting can be extended to multi-party, where different types of node features are learned from different parties (\eg, bank statements from banks and transactions from online-shopping companies).
Usually, the graph structure is  fixed to represent a specific relationship, such as a social circle, in real-world scenarios.
Thus, we focus on single-party graph ownership without limiting feature ownerships.
A general case of arbitrary partitioning has been discussed in Section~\ref{sec:future}.
 
\begin{figure}[!t]
	\centering
	\includegraphics[width = 0.42\textwidth]{./fig_and_tab/gnn-imple.png}
	\caption{Ideal Functionality of $\cgnn$}
	\label{graph_imple}
\end{figure}

\subsection{Security Model}
$\cgnn$ can be instantiated with any type of security models offered by the corresponding MPC protocols.
Following advances~\cite{ccs/AttrapadungH0MO21,neurips/crypten2020,sp21/TanKTW,uss/WatsonWP22,ccs/ZouLSLXX24,ccs/KotiKPG24}, $\cgnn$ focuses on $2$PC security against the static semi-honest probabilistic polynomial time (PPT) adversary $\A$ regarding the real/ideal-world simulation paradigm~\cite{sp/17/Lindell17}.
Specifically, two parties, $\pp_0$ and $\pp_1$, with inputs $\l x\r_0$ and $\l x\r_1$, want to compute a function $y = f(\l x\r_0, \l x\r_1)$ without revealing anything other than $y$.
$\A$ corrupts either $\pp_0$ or $\pp_1$ at the start, following the protocol, but tries to learn the other's private inputs.
$\A$ can only learn data from the corrupted party but nothing from  honest ones.

Many protocols utilize pre-computations for improving efficiency, \eg, Beaver triples~\cite{crypto/Beaver91a} for multiplication.
They can be realized by a data-independent offline phase run by a  semi-honest dealer $\tt$ or 2PC protocols from homomorphic encryption~\cite{eurocrypt/LyubashevskyPR10} or oblivious transfer~\cite{pkc/Tzeng02,ccs/KellerOS16} or oblivious shuffle~\cite{asiacrypt/ChaseGP20,ndss/SongYBDC23}.
We adopt the first common approach (also called client-aided setting~\cite{ccs/AttrapadungH0MO21}) for simplicity.
The $\tt$ does not interact with any party (particularly, receives nothing) online.
It only generates pseudo-randomnesses in an input-independent offline phase by counter-indexed computations of pseudorandom function (PRF), where $\tt$ and $\pp_i$ share a PRF key (denoted by $\key_i$) for $i \in \{0,1\}$ and a counter $\ctr$ are synchronized among all parties.
We defer the explicit functionality definitions and security proofs of our protocols to Appendix~\ref{app::fullproof}.
%This treatment is often for description brevity and can be easily realized by standard MPC techniques for the correlated randomness generation, \eg, additive homomorphic encryption for Beaver triples or  for permutation triples.
 

\subsection{Scope of Graph Protection}
%\subsection{Graph Leakage Profile}
\iffalse
In the GCN, training data contains graph structure (\ie, represented by adjacency matrix) and features/labels.
In our two-party setting, the party $\pp_0$ holds a private graph, while another party $\pp_1$ owns the features/labels.
The party of graph holder can derive permutation operations corresponding to its private graph, \ie, privately owning the private permutation.
Considering semi-honest security, no party learns the GCN model in clear during the whole process.
\fi

Like existing MPC works, $\cgnn$ protects the entry values stored in the graph and (intermediate) computations.
For metadata, most secure matrix multiplication protocols (without sparse structure) reveal input
%matrix 
dimensionality (\eg, $\numnode$ in GCN) that is typically considered public knowledge.
When sparsity is explored, it is normal to leak reasonable knowledge, such as $\numnode+\numedge$ in GraphSC~\cite{sp/NayakWIWTS15}.
In $\cgnn$, the only additional metadata revealed is $\numedge$ that has been comprehensively explained in \S\ref{subsec:prosmm}.
This leakage is tolerable (and unavoidable) since the efficiency gain is correlated to $\numedge$.
Corresponding to $\cgnn$'s GCN training, the \textit{dimension} of adjacency matrix $\adjmat$ (\ie, equal to $\numnode$) and the \textit{dimension} of feature matrix $\Xsf$ are assumed to be public. 

\iffalse
Without sparse structures, the matrix-vector multiplication protocol leaks the dimension of the input matrix, \ie, the number of nodes.
In the GCN training, the node features/labels and the coordinates of non-zero values are two types of sensitive information related to node privacy and edge privacy.
When we exploit sparsity, leaking information about sparsity is tolerable since the efficiency gain is correlated to non-sparsity extraction.
Our construction in Section~\ref{subsec:prosmm} leaks the number of source and target nodes and the number of nodes.
However, we mitigate this leakage by padding the dummy source/target nodes in Section~\ref{sec::smm::degree}, minimizing the only leakage to be the total number of nodes and edges in the graph.
Notably, $\cgnn$'s protocols do not leak information about per-row/column degree or per-node/edge privacy.
\fi

Privacy leakages from training/inference results, \eg, embedding inversion and sensitive attribute inference, also appear in plaintext computations and are beyond our scope.
These can be protected via orthogonal techniques like (local) differential privacy and robustness training, which are compatible with our work.
%can be integrated with 
%incorporated on top of 
%any cryptographic solutions, including ours.
In the semi-honest settings, the attacker can only view the well-formed secret shares and not actively perform the malicious attacks like model inversion.