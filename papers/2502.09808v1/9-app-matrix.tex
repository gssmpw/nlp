%!TEX root = gcn.tex

\section{Proofs related to Sparsity}
\label{sec:matrix_found_sparse}


\begin{definition}[$\Qsf$-type matrix]
\label{q_type}
%Let $e>n$.
A $(0,1)$-matrix $\Msf$ of size $m\times n$ is a $\Qsf$-type matrix iff there exists a monotonically non-decreasing %function 
$f:\Zbb/m\Zbb\rightarrow \Zbb/n\Zbb$ s.t.~$\Msf[i,j]=1$ iff $j=f(i)$.
\end{definition}

\begin{definition}[$\Psf$-type matrix] 
\label{p_type}
% Let $e>m$.
A $(0,1)$-matrix $\Msf$ of size $m\times n$ is a $\Psf$-type matrix iff there exists a monotonically non-decreasing %function 
$f:\Zbb/n\Zbb\rightarrow \Zbb/m\Zbb$ s.t.~$\Msf[i,j]=1$ iff $i=f(j)$.
\end{definition}

\subsection{Proof of Theorem~\ref{the::p_sig_q}}
\label{sec::proof_p_sig_q}
%\yuz{modifying all $t$-to-$e$ seems easier than all $e$-to-$t$? which one do you prefer? I can modify them}
%\ak{I prefer $t$ over $e$ as it is slightly easy to mix up with the base of the natural log.
%I can also help modify this later (after the main content)}
%\initdecom*
\begin{proof}
Suppose the sparse representation of $\adjmat$ is $\{(i_k, j_k, \lambda_k): k=1, \ldots, t\}$ where
%the map 
$k \mapsto i_k$ is monotonically non-decreasing.
Then, we have $\adjmat=\adjout'\Lambda \adjin$, where $\adjout'\in \Mbb_{m,t}(\Rcal)$ is a sparse matrix represented by $\{(i_k, k, 1): k=1, \ldots, t\}$, $\Lambda=\mathsf{diag}(\lambda _1, \ldots, \lambda _t)$, $\adjin\in \Mbb_{t,n}(\Rcal)$ is a 
sparse matrix represented by $\{(k, j_k, 1): k=1, \ldots, t\}$.
Now, $\adjout'$ is a $\Psf$-type matrix, but $\adjin$ is not a $\Qsf$-type matrix as $\adjin$ does not satisfies ``$k \mapsto j_k$ is monotonically non-decreasing''.
We permute the lines of $\adjin$ as $\adjin'=\{ (\sigma_3^{-1}(k), j_k, 1): k=1, \ldots, t\}=\{ (k, j_{\sigma_3(k)}, 1): k=1\ldots, t\}$ such that $k \mapsto j_{\sigma _3(k)}$ is monotonically non-decreasing.
After that, we have $\adjin= \{ (k, \sigma_3^{-1}(k), 1): k=1, \ldots, t \} \times \adjin' = \{ (\sigma_3(k), k, 1): k=1, \ldots, t \} \times \adjin' =\sigma_3 \adjin'$, where $\adjin'$ is a $\Qsf$-type matrix.
Hence, $\adjmat=\adjout' \Lambda \sigma _3 \adjin'$.
\end{proof}

\subsection{Proof of Theorem~\ref{the::general_dec_main}} 
\label{sec::proof_general}
\iffalse
\begin{theorem}[Restatement of Theorem~\ref{the::general_dec_main}] 
Let an $m\times n$ sparse matrix $\adjmat\in \Mbb_{m,n}(\Rcal)$ contains $\nrow$ non-zero rows, $\ncol$ non-zero columns, and $\numnonzero$ non-zero elements.
Then, there exists a matrix decomposition
$\adjmat= \sigma_5 \delta_m ^{\top} \gammaout \sigma _4 \Sigma ^{\top} \Lambda \sigma _3 \Sigma \sigma_2 \gammain \delta _n \sigma _1$,
where $\sigma _5 \in \Sbb_m$, $\sigma_4 \in \Sbb_{\numnonzero}, \sigma_3 \in \Sbb_{\numnonzero},\sigma _2 \in \Sbb_{\numnonzero},\sigma _1 \in \Sbb_n$, and,\\
1) $\Sigma=(\Sigma[i, j])_{i,j=1}^{\numnonzero}$ is the left-down triangle matrix such that $\Sigma[i, j]=1$ if $i \geq j$ or $0$ otherwise,\\
2) $\delta_k=(\delta_k[i,j])_{i,j=1}^{k}$ is the left-down triangle matrix such that $\delta_k[i,j]=1$ for $i=j$ or $-1$ for $j=i-1$, or $0$ otherwise,\\
3) $\gammain =(\gammain[i,j])_{i=1,j=1}^{\numnonzero,n}$ is a matrix such that $\gammain[i,j]=1$ for $1\leq i=j\leq \ncol$ or $0$ otherwise,\\
4) $\gammaout =(\gammaout[i,j])_{i=1,j=1}^{m,\numnonzero}$ is a matrix such that $\gammaout[i,j]=1$ for $1\leq i=j\leq {\nrow}$ or $0$ otherwise.
\end{theorem}
\fi
%\finaldecom*

\begin{proof}
The proof is straightforward by composing $\adjmat = \adjout' \Lambda \sigma_3 \adjin'$ from Theorem \ref{the::p_sig_q}, $\adjin'=\Sigma \sigma_2 \gammain \delta _n \sigma _1$ from Theorem~\ref{the::q_decom}, and $\adjout'=\sigma_5 \delta_m ^\top \gammaout \sigma_4 \Sigma ^\top$ from Theorem~\ref{the::p_decom}.
%composing group actions of $\Psf\Lambda\sigma_3\Qsf$ and equivalently to get $\sigma_5 \delta_m ^{\top} \gammaout \sigma _4 \Sigma ^{\top} \Lambda \sigma _3 \Sigma \sigma_2 \gammain \delta _n \sigma _1$.
\end{proof}

\subsection{Proof of Theorem~\ref{the::smm_main}}
\label{sec::proof_smm}
\iffalse
\begin{theorem}[Restatement of Theorem~\ref{the::smm_main}]
Let $\Msf$ be a sparse matrix and $\xvec$ be a dense vector/matrix.
Computing sparse matrix multiplication that $\Msf\xvec=\sigma_5 \delta _m ^\top \Gamma _{\nrow} \sigma _4 \Sigma ^\top \Lambda \sigma _3 \Sigma \sigma_2 J_{\ncol} \delta _n \sigma _1 \xvec$ requires an ordered sequential of permutation group action, element-wise multiplication, cut-off and padding with $0$, and constant matrix multiplication from right to left.
\end{theorem}
\fi
%\thmsmm*
\begin{proof}
It is straightforward to prove by observing that:\\
1) Permutations on $\sigma _i$ calls permutation group action;\\
2) Multiplying %$\delta_n$, $\delta_m^{\top}$, $\Sigma$, $\Sigma^{\top}$ 
$\delta$, $\Sigma$ calls constant matrix multiplication;\\
3) Multiplying $\gammain$, $\gammaout$ calls element-wise multiplication (with cut-off and padding of zero values);\\
4) Multiplying $\Lambda$ calls element-wise multiplication.	
\end{proof}

\subsection{Proof of Theorem~\ref{the::q_decom}}


\label{sec::proof_q}

\begin{theorem}
\label{the::q_decom}
Let $\adjin' \in \Mbb_{t, n}$ be a $\Qsf$-type matrix with $\ncol$ non-zero columns.
Then, there exists a matrix decomposition $\adjin'=\Sigma \sigma_2 \gammain \delta _n \sigma _1$ where $\sigma _1 \in \Sbb_n, \sigma _2 \in \Sbb_t$, and, \\
1) $\Sigma=(\Sigma[i, j])_{i,j=1}^{\numnonzero}$ is the left-down triangle matrix such that $\Sigma[i, j]=1$ if $i \geq j$ or $0$ otherwise,\\
2) $\delta_n=(\delta_n[i,j])_{i,j=1}^{n}$ is the left-down triangle matrix such that $\delta_n[i,j]=1$ for $i=j$ or $-1$ for $j=i-1$, or $0$ otherwise,\\
3) $\gammain =(\gammain[i,j])_{i=1,j=1}^{\numnonzero,n}$ is a matrix such that $\gammain[i,j]=1$ for $1\leq i=j\leq \ncol$ or $0$ otherwise.
\iffalse
1) $\Sigma=(a_{ij})_{i,j=1}^t$ is the left-down triangle matrix such that $a_{ij}=1$ if $i \geq j$ or $0$ otherwise;
2) $\delta_n=(a_{ij})_{i,j=1}^n$ is the left-down triangle matrix such that $b_{ij}=1$ for $i=j$ or $-1$ for $j=i-1$ or $0$ otherwise;
3) $\gammain=\begin{psmallmatrix}
I_k & O_{k,n-k} \\
O_{t-k,k} & O_{t-k,n-k}
\end{psmallmatrix}=(a_{ij})_{i=1,j=1}^{t,n}$ is a matrix such that $a_{ij}=1$ for $1\leq i=j\leq k$ or $0$ otherwise.
\fi
\end{theorem}
 
\begin{proof}
Here, we prove that $\adjin' \Xsf=\Sigma \sigma _2 \gammain \delta_n \sigma _1 \Xsf $ holds for any $\Xsf\in \Rcal^{(n)}$.
Firstly, we can use column transformation to transform matrix $\adjin'$ to a new matrix $\tilde{\adjin'}$ of $\Qsf$-type such that all the $n-\ncol$ zero-columns of $\tilde{\adjin'}$ lie in the last columns.
Hence, we have $\adjin'=\tilde{\adjin'}\sigma _1$, and $\tilde{\adjin'}$ is in the form of,
\[
\tilde{\adjin'}=\left(
\begin{array}{ccccccc}
1 &&& & 0 & \cdots & 0\\
\vdots &&& \\
1 &&& & \vdots & & \vdots \\
 & 1 && \\
 & \vdots && & \vdots & & \vdots \\
 & 1 && \\
 & & \ddots & & \vdots & & \vdots \\
 && & 1 \\
 && & \vdots \\
 &&& 1 & 0 & \cdots & 0\\
\end{array}
\right)
\]
Let $\tilde{\Xsf} = \sigma_1 \Xsf$,
then we have $\adjin' \Xsf$ equal to:
\begin{equation*}
	\begin{aligned}
		\tilde{\adjin'}\tilde{\Xsf}&=
\left(
\begin{array}{c}
\tilde{x}_1 \\
\tilde{x}_1 \\
\vdots \\
\tilde{x}_1 \\
\tilde{x}_2 \\
\tilde{x}_2 \\
\vdots \\
\tilde{x}_2 \\
\vdots \\
\vdots \\
\tilde{x}_{\ncol} \\
\tilde{x}_{\ncol} \\
\vdots \\
\tilde{x}_{\ncol} \\
\end{array}
\right) = \Sigma
\left(
\begin{array}{c}
\tilde{x}_1 \\
0 \\
\vdots \\
0 \\
\tilde{x}_2-\tilde{x}_1 \\
0 \\
\vdots \\
0 \\
\vdots \\
\vdots \\
\tilde{x}_{\ncol}-\tilde{x}_{\ncol-1} \\
0 \\
\vdots \\
0 \\
\end{array}
\right)
\end{aligned}
\end{equation*}
\begin{equation*}
\begin{aligned}
& =
\Sigma \sigma _2
\left(
\begin{array}{c}
\tilde{x}_1 \\
\tilde{x}_2-\tilde{x}_1 \\
\vdots \\
\tilde{x}_{\ncol}-\tilde{x}_{\ncol-1} \\
0 \\
\vdots \\
0 \\
\end{array}
\right)
 = \Sigma \sigma _2 \gammain
\left(
\begin{array}{c}
\tilde{x}_1 \\
\tilde{x}_2-\tilde{x}_1 \\
\vdots \\
\tilde{x}_{\ncol}-\tilde{x}_{\ncol-1} \\
\tilde{x}_{\ncol+1}-\tilde{x}_{\ncol} \\
\vdots \\
\tilde{x}_{n}-\tilde{x}_{n-1} \\
\end{array}
\right)
\\
&
= \Sigma \sigma _2 \gammain \delta_n \tilde{\Xsf}
= \Sigma \sigma _2 \gammain \delta_n \sigma _1 \Xsf
\rlap{\qquad \qquad \qquad \qquad \qquad \qquad \qedhere}.
\end{aligned}
\end{equation*}
\end{proof}

\subsection{Proof of Theorem~\ref{the::p_decom}}

\label{sec::proof_p}
\begin{theorem} 
\label{the::p_decom}
Let $\adjout' \in \Mbb_{m,t}(\Rcal)$ be a $\Psf$-type matrix with $\nrow$ non-zero rows.
Then, there exists a matrix decomposition $\adjout'=\sigma_5 \delta_m ^\top \gammaout \sigma_4 \Sigma ^\top$ where $\sigma _5 \in \Sbb_m$, $\sigma_4 \in \Sbb_t$, and, \\
1) $\Sigma=(\Sigma[i, j])_{i,j=1}^{\numnonzero}$ is the left-down triangle matrix such that $\Sigma[i, j]=1$ if $i \geq j$ or $0$ otherwise,\\
2) $\delta_m=(\delta_m[i,j])_{i,j=1}^{m}$ is the left-down triangle matrix such that $\delta_m[i,j]=1$ for $i=j$ or $-1$ for $j=i-1$, or $0$ otherwise,\\
3) $\gammaout =(\gammaout[i,j])_{i=1,j=1}^{m,\numnonzero}$ is a matrix such that $\gammaout[i,j]=1$ for $1\leq i=j\leq {\nrow}$ or $0$ otherwise.
\iffalse
1) $\Sigma=(a_{ij})_{i,j=1}^t$ is the left-down triangle matrix such that $a_{ij}=1$ if $i \geq j$ or $0$ otherwise;
2) $\delta_m=(a_{ij})_{i,j=1}^m$ is the left-down triangle matrix such that $b_{ij}=1$ for $i=j$ or $-1$ for $j=i-1$ or $0$ otherwise;
3) $\Gamma_{\nrow}=
\begin{psmallmatrix}
I_{\nrow} & O_{{\nrow},t-{\nrow}} \\
O_{m-{\nrow},{\nrow}} & O_{m-{\nrow},t-{\nrow}}
\end{psmallmatrix} 
=(a_{ij})_{i=1,j=1}^{m,t}$ is the matrix such that $a_{ij}=1$ for $1\leq i=j\leq {\nrow}$ or $0$ otherwise.
\fi
\end{theorem}

\begin{proof}
Note that $(\adjout')^\top \in \Mbb_{t,m}$ is a $\Qsf$-type matrix, we have the matrix decomposition $(\adjout')^\top=\Sigma \sigma_2 \gammain \delta_m \sigma _1$ by Theorem~\ref{the::q_decom}, where $\sigma_1 \in \Sbb_m$ and $\sigma_2\in \Sbb_t$.
Let $\sigma_5=\sigma_1^\top$, $\sigma_4=\sigma_2^\top$, $\gammaout=\gammain^\top$, we have $\adjout'=\sigma_5 \delta_m ^\top \gammaout \sigma_4 \Sigma ^\top$.
\end{proof}
 

