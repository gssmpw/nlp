\section{Related Works}


\noindent\textbf{3D Point Cloud Domain Adaptation and Generalization.}
Early endeavors within 3D domain adaptation (3DDA) focused on extending 2D adversarial methodologies~\cite{qin2019pointdan} to align point cloud features. Alternative methods have delved into geometry-aware self-supervised pre-tasks. Achituve \etal~\cite{achituve2021self} introduced DefRec, a technique employing self-complement tasks by reconstructing point clouds from a non-rigid distorted version, while Zou \etal~\cite{zou2021geometry} incorporating norm curves prediction as an auxiliary task. Liang \etal~\cite{liang2022point} put forth MLSP, focusing on point estimation tasks like cardinality, position, and normal. SDDA~\cite{cardace2023self} employs self-distillation to learn the point-based features. Additionally, post-hoc self-paced training~\cite{zou2021geometry,fan2022self,park2023pcadapter} has been embraced to refine adaptation to target distributions by accessing target data and conducting further finetuning based on prior knowledge from the source domain.
In contrast, the landscape of 3D domain generalization (3DDG) research remains nascent. Metasets~\cite{huang2021metasets} leverage meta-learning to address geometric variations, while PDG~\cite{wei2022learning} decomposes 3D shapes into part-based features to enhance generalization capabilities.
Despite the remarkable progress, existing studies assume that objects in both the source and target domains share the same orientation, limiting their practical application. This limitation propels our exploration into orientation-aware 3D domain generalization through intricate orientation learning.


\noindent\textbf{Rotation-generalizable Point Cloud Analysis.}
Previous works in point cloud analysis~\cite{qi2017pointnet, wang2019dynamic} enhance rotation robustness by introducing random rotations to augment point clouds. {However, generating a comprehensive set of rotated data is impractical, resulting in variable model performance across different scenes. To robustify the networks \wrt randomly rotated point clouds,} rotation-equivariance methods explore equivalent model architectures by incorporating equivalent operations~\cite{su2022svnet, Deng_2021_ICCV, luo2022equivariant} or steerable convolutions~\cite{chen2021equivariant, poulenard2021functional}.
Alternatively, rotation-invariance approaches aim to identify geometric descriptors invariant to rotations, such as distances and angles between local points~\cite{chen2019clusternet, zhang2020global} or point norms~\cite{zhao2019rotation, li2021rotation}. Besides, {Li \etal~\cite{li2021closer} have explored disambiguating the number of PCA-based canonical poses, while Kim \etal~\cite{kim2020rotation} and Chen \etal~\cite{chen2022devil} have transformed local point coordinates according to local reference frames to maintain rotation invariance. However, these methods focus on improving in-domain rotation robustness, neglecting domain shift and consequently exhibiting limited performance when applied to diverse domains. This study addresses the challenge of cross-domain generalizability together with rotation robustness and proposes novel solutions.} 

\noindent\textbf{Intricate Sample Mining}, aimed at identifying or synthesizing challenging samples that are difficult to classify correctly, seeks to rectify the imbalance between positive and negative samples for enhancing a model's discriminability. While traditional works have explored this concept in SVM optimization~\cite{felzenszwalb2009object}, shallow neural networks~\cite{dollar2009integral}, and boosted decision trees~\cite{yu2019unsupervised}, recent advances in deep learning have catalyzed a proliferation of researches in this area across various computer vision tasks. For instance, 
Lin \etal~\cite{lin2017focal} proposed a focal loss to concentrate training efforts on a selected group of hard examples in object detection, while Yu \etal~\cite{yu2019unsupervised} devised a soft multilabel-guided hard negative mining method to learn discriminative embeddings for person Re-ID. Schroff \etal~\cite{schroff2015facenet} introduced an online negative exemplar mining process to encourage spherical clusters in face embeddings for individual recognition, and Wang \etal~\cite{wang2021instance} designed an adversarially trained negative generator to yield instance-wise negative samples, bolstering the learning of unpaired image-to-image translation. In contrast to existing studies, our work presents the first attempt to mitigate the orientational shift in 3D point cloud domain generalization, by developing an effective intricate orientation mining strategy to achieve orientation-aware learning.

