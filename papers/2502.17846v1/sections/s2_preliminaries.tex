\section{Preliminaries}
\label{sec:prelim}
We discuss necessary background on GNN training.



\subsection{GNNs and GNN Mini Batch Training}
\label{subsec:prelim_gnns}
GNNs achieve state-of-the-art (SoTA) accuracy by learning to combine information about graph nodes with information from their multi-hop neighborhood. The local information for each node is encoded in a \textit{feature vector} that can be fixed or learned during training. All feature vectors are stored together in a lookup table indexed by node ID---For large graphs, the storage overhead for this table can require hundreds of GBs to TBs of memory~\cite{mariusgnn}.

As such, large-scale GNN training is typically performed in a mini batch fashion consisting of two distinct parts: \textit{mini batch preparation} and \textit{mini batch computation}. Mini batch preparation is uniquely challenging for GNNs~\cite{chami2021machine, dorylus, p3gnn, salient}; it requires sampling multi-hop neighborhoods~\cite{graphsage} for a batch of nodes and loading the corresponding feature vectors from the graph. Given the storage overhead of the latter (above), mini batch preparation typically occurs on CPUs with access to ample DRAM. After a batch is prepared, mini batch computation (the GNN forward/backward pass) consists of matrix multiplies that call for GPU acceleration. Thus, batches prepared on CPUs are then transferred to GPUs for computation.



\subsection{Distributed GNN Training}
\label{subsec:prelim_distributed}
When the storage overhead of a graph exceeds the CPU memory capacity of a single machine, or when parallelization is desired to accelerate training, prior works propose to use distributed training~\cite{shao2024distributed}. In this case, graph nodes (and their features) are split into disjoint \textit{partitions} that are loaded into separate machines. In this setup, mini batch preparation is also distributed---Each machine is responsible for preparing batches in parallel and sampling the required multi-hop neighborhoods across the whole graph, by communicating with other machines as needed.



\newparagraph{The Need for Scalable Min-Edge-Cut Partitioning}
Cross-machine neighborhood sampling and feature loading can lead to a communication bottleneck that fundamentally limits the scalability and throughput of batch preparation across the set of machines~\cite{salient++}. To mitigate this issue, existing systems rely on partitioning algorithms that minimize the number of cross-partition edges~\cite{distdglv2}. As highlighted in the introduction, however, current partitioning algorithms that minimize edge cuts are expensive---partitioning often dominates the overall GNN runtime and limits the maximum graph size that can be processed given certain resources. 



\begin{figure}[t]
  \centering
  \includegraphics[width=.45\textwidth]{figures/gs_large_breakdown.pdf}
  \vspace{-0.15in}
  \caption{Breakdown of the average runtime per training iteration in the SoTA system MariusGNN (GraphSage-Large on OGBN-Papers100M; details in Section~\ref{sec:eval}). Neighborhood sampling plus feature loading on the CPU dominates GNN runtime.}
  \label{fig:armada_breakdown}
  \vspace{-0.15in}
\end{figure}



\newparagraph{The Need For Disaggregated Training}
We find that \textit{even when there is zero communication}, mini batch preparation can bottleneck distributed GNN training in existing systems, leading to GPU underutilization and unnecessarily expensive training. This problem is exacerbated on common cloud machines with fast GPUs and fixed CPU resources. 

For example, in Figure~\ref{fig:armada_breakdown} we show the average time for mini batch preparation and computation across training iterations on a common GNN benchmark. Figure~\ref{fig:armada_breakdown} shows that multi-hop sampling (even when optimized~\cite{mariusgnn}) and feature loading---which together encompass mini batch preparation---dominate overall training time. Furthermore, this overhead increases with increasing GPUs (distributed data parallel training with weak scaling, commonly used for GNN training, requires preparing one mini batch per GPU). 

Given the runtime discrepancy, it's necessary to parallelize mini batch preparation across CPUs in order to keep GPUs busy with computation. Existing systems, however, rely only on the fixed set of CPU resources attached to GPU machines for this parallelization, fundamentally hindering their ability to prepare batches~\cite{salient, distdglv2}. To highlight this issue, in Figure~\ref{fig:salient_cpu}, we show the CPU utilization of the SoTA system Salient++~\cite{salient++} during GNN training. Salient++ requires more than 80 percent of the CPU to prepare batches in parallel for one GPU. When training with four GPUs, the CPU is fully saturated, limiting the throughput of mini batch preparation, leading to sublinear scaling (1.6$\times$ instead of 4$\times$; Table~\ref{tab:runtime_nc}), and resulting in expensive GPUs sitting partially idle.

The above observations motivate a disaggregated system for large-scale GNN training that supports scaling each part of the workload independently. While disaggregation has improved resource efficiency in traditional ML settings~\cite{graur2022cachew, jin2024efficient}, prior work on disaggregated GNN training (Dorylus~\cite{dorylus}) has focused only on utilizing serverless functions and full multi-hop neighborhoods (i.e., no sampling). Full neighborhoods, however, lead to expensive communication for multi-layer GNNs and a serverless architecture limits the type of models that can be trained efficiently without GPUs. On a common GNN benchmark, we find that throughput in Dorylus plateaus at 89.6s/epoch (\$3.75/epoch); GPU-based systems can be 12$\times$ faster and 53$\times$ cheaper (see Table~\ref{tab:runtime_nc} left). 


\begin{figure}[t]
  \centering
  \includegraphics[width=.45\textwidth]{figures/salient_cpu.pdf}
  \vspace{-0.15in}
  \caption{CPU utilization in the SoTA system Salient++ (details in Section~\ref{sec:eval}; GraphSage-Small on OGBN-Papers100M). Nearly all CPU resources are used to parallelize mini batch preparation and minimize training time with one GPU; the CPU resources are insufficient for multi-GPU training, leading to sublinear speedups.}
  \label{fig:salient_cpu}
  \vspace{-0.15in}
\end{figure}
