\section{Scalable Graph Partitioning}
\label{sec:partitioning}



We now introduce \partitioning, a novel algorithm that enables efficient min-edge-cut graph partitioning over massive graphs on a commodity machine. We describe the optimization objective and algorithm, then analyze it theoretically below.



\subsection{\partitioning: Min-Edge-Cut Partitioning}
\newparagraph{Optimization Objective}
Given a graph $G = (V, E)$, we assume as input an edge list ($E$) stored on disk in a random order. Our goal is to partition the nodes $V$ into a set of $p$ partitions, each of size $\lceil V/p \rceil$ (i.e., a balanced partitioning), according to an algorithm that 1) minimizes the number of cross-partition edges and 2) can scale to massive graphs given a fixed amount of CPU memory (but unlimited disk space) (the edge list for large graphs may not fit in memory on a single, or even multiple machines (e.g., Hyperlink-2012's 128B edges require 2TB~\cite{hyperlink}).

The above problem (balanced min-edge-cut partitioning) is NP-Hard, even for $p=2$; for $p > 2$, no finite approximation algorithm exists unless P=NP~\cite{andreev2004balanced}. As such, existing algorithms rely on heuristics: As highlighted in the introduction, offline algorithms (e.g., METIS) operate over the whole graph and effectively minimize edge cuts through iterative partition refinement, but they face scalability challenges. On the other hand, streaming greedy approaches~\cite{stanton2014streaming, alistarh2015streaming, patwary2019window, stanton2012streaming, faraj2022buffered, petroni2015hdrf, jain1998greedy, tsourakakis2014fennel} have better scalability, but often lead to partitionings with more edge cuts due to their use of fixed greedy decisions (e.g., 4$\times$ more edge cuts than METIS).



\newparagraph{Key Idea}
To combine the advantages of offline and streaming methods, \partitioning employs a streaming greedy approach, but with one key addition: Rather than freezing the partition assignment for a node after an initial greedy selection, \partitioning leverages running statistics accumulated during streaming to continuously reevaluate prior assignments and refine the result. Inspired by offline algorithms, this refinement is critical to minimizing edge cuts.



\begin{algorithm}[t]\small
    \caption{\partitioning Bipartite Graph Partitioning}
    \label{alg:partition_algo} 
    \begin{algorithmic}[1] 
        \REQUIRE num\_nodes; edges; c\_size: chunk size; \texttt{seed\_algo}: seed partition algorithm; P: max partition size (in nodes)
    
        \STATE parts = \texttt{minus\_ones}(num\_nodes); $\;$ sizes = \texttt{zeros}(2) 
        
        \STATE nbr\_counts = \texttt{zeros}(num\_nodes, 2)

        \FOR{$i = 0$ \TO $\texttt{ceil}(\texttt{len}(\text{edges})/\text{c\_size}) - 1$}
            \STATE c\_edges = \texttt{read}(edges[i $*$ c\_size : (i + 1) $*$ c\_size])
            \STATE c\_nodes = \texttt{unique\_nodes\_in\_edges}(c\_edges)

            \IF{$i == 0$}
                \STATE parts[c\_nodes] = \texttt{seed\_algo}(c\_edges, num=2)
                \STATE sizes = [\texttt{num\_zeros}(parts), \texttt{num\_ones}(parts)]
                
                \STATE $\text{nbrs}_0$, nbrs$_1$ = \texttt{cnt\_nbrs}(c\_nodes,$\,$c\_edges,$\,$parts)
                
                \STATE nbr\_counts[c\_nodes] = [$\text{nbrs}_0$, nbrs$_1$]
            \ELSE
                \FOR{n $\in$ c\_nodes}
                    \STATE old\_part = parts[n]
                
                    \STATE $\text{nbrs}_0$, nbrs$_1$ = \texttt{cnt\_nbrs}(n, c\_edges, parts)
                    
                    \IF{old\_part $\neq -1$}
                        \STATE $\text{nbrs}_0$, $\text{nbrs}_1$ = (nbr\_counts[n] + [$\text{nbrs}_0$, $\text{nbrs}_1$]) / 2
                    \ENDIF
                    
                    \STATE parts[n] = \texttt{assign}($\text{nbrs}_0$, $\text{nbrs}_1$, sizes, P)

                    \STATE sizes = \texttt{fix\_sizes}(parts[n], old\_part, sizes)
                    
                    \STATE nbr\_counts[n] = [$\text{nbrs}_0$, nbrs$_1$]
                \ENDFOR
            \ENDIF
        \ENDFOR
    \end{algorithmic}
\end{algorithm}



\newparagraph{Detailed Algorithm}
\partitioning partitions an input graph into $p=2$ partitions as described in Algorithm~\ref{alg:partition_algo}; we focus on $p=2$ because \partitioning returns a partitioning for $p>2$ by first partitioning the graph into two parts, and then recursively re-partitioning each part into two new parts as needed. We identify the two partitions by index \textit{zero} and \textit{one}. Each node starts unassigned (index \textit{minus one}) and each partition starts with size zero (Line 1). We also initialize two numerical values for each node (\texttt{nbr$\_$counts}, Line 2); the purpose of these values is to provide a running estimate of the number of neighbors each node has in each partition. 

\partitioning then proceeds by iterating over the edge list in chunks (Line 3). For each chunk, the edges are loaded into memory (\texttt{c$\_$edges}) and the set of unique nodes (\texttt{c$\_$nodes}) contained in those edges is computed (Lines 4-5). For the first chunk (Line 6), as there are no existing partition assignments that can be used to make greedy decisions, we use a \textit{seed} partitioning algorithm on the in-memory edges (e.g., METIS) to assign all nodes in memory to one of the two partitions (Line 7). The partition sizes and the estimated number of neighbors per node in each partition (calculated based on the in-memory edges and existing partitioning; Algorithm~\ref{alg:partition_algo_helpers} - \texttt{cnt\_nbrs}) are then updated (Lines 8-10). 

For the remaining chunks (Line 11), \partitioning assigns nodes to partitions greedily. For each node $n$ (Line 12), we start by estimating the number of neighbors in each partition using the current chunk's edges and most recent partition assignments (Line 14). If the node is unassigned (i.e., this is the first chunk containing the node), these neighbor estimates are used directly: To minimize edge cuts, we assign the node to the partition containing most of its neighbors, unless the partition is full (Line 17; Algorithm~\ref{alg:partition_algo_helpers} - \texttt{assign}). The partition sizes are then updated (Line 18; Algorithm~\ref{alg:partition_algo_helpers} - \texttt{fix\_sizes}) and the neighbor estimates for the node are saved (Line 19). \textit{The algorithm, as described so far, represents a streaming greedy approach with fixed assignments.} 

Instead of fixing an initial greedy decision for each node, \partitioning reevaluates a node's partition assignment each time it reappears in memory. Specifically, for a previously assigned node $n$ (Line 15), we refresh our estimate of the number of neighbors in each partition using an average of the estimate from the current chunk and the estimates accumulated from prior chunks (Lines 16). Node $n$ is then assigned to a partition greedily using these updated estimates (Line 17), which are then saved for future use (Line 19). We highlight that, by repeatedly averaging the accumulated neighbor estimates with the most recent ones, we are computing a weighted average of the estimates across all prior chunks containing the node, with the weight of each preceding chunk decreasing by a factor of two.

Updating prior greedy assignments based on the weighted average of neighbor estimates has the following advantages: First, nodes (which reappear) are not greedily assigned based on the estimates from only one chunk (as in existing algorithms)---these estimates can be noisy, particularly for small chunks when nodes have only a few neighbors in memory. Second, by weighting the average, more value is placed on recent estimates which are likely to be more accurate (as partition assignments may have changed since prior estimates were computed). The end result is a continuous refinement of greedy decisions throughout the algorithm.



\begin{algorithm}[t]\small
    \caption{\partitioning Helper Functions}
    \label{alg:partition_algo_helpers}
    
    \begin{algorithmic}[1]

    \STATE \texttt{cnt\_nbrs}(nodes, edges, parts):
    \begin{ALC@g}
        \STATE local\_nbr\_counts = \texttt{zeros}(\texttt{len}(nodes), 2)
        \FOR{n $\in$ nodes}
            \FOR{(src, dst) $\in$ edges}
                \IF{src $==$ n \OR dst $==$ n}
                    \STATE nbr = src \textbf{if} dst $==$ n \textbf{else} dst
                    
                    \IF{parts[nbr] $\neq$ -1}
                        \STATE local\_nbr\_counts[n][parts[nbr]] += 1
                    \ENDIF
   
                \ENDIF
            \ENDFOR
        \ENDFOR
        \RETURN local\_nbr\_counts
    \end{ALC@g}

    \STATE \texttt{assign}($\text{nbrs}_0$, $\text{nbrs}_1$, sizes, P):
    \begin{ALC@g}
        \STATE \textbf{if} $\text{nbrs}_0$ $<$ $\text{nbrs}_1$ \AND sizes[1] $<$ P \textbf{then} \textbf{return} 1

        \STATE \textbf{if} $\text{nbrs}_1$ $<$ $\text{nbrs}_0$ \AND sizes[0] $<$ P \textbf{then} \textbf{return} 0

        \RETURN \texttt{arg\_min}(sizes)
        
    \end{ALC@g}

    \STATE \texttt{fix\_sizes}(new\_part, old\_part, sizes):
    \begin{ALC@g}
        \STATE sizes[new\_part] += 1
        \STATE \textbf{if} old\_part $\neq -1$ \textbf{then} sizes[old\_part] $-$= 1
    \end{ALC@g}
    
    \end{algorithmic}
    
\end{algorithm}





\subsection{Theoretical Analysis of \partitioning}
\label{subsec:partitioning_analysis}

We now analyze the number of edge cuts returned by \partitioning versus chunk size. We focus on chunk size as it directly affects the computational overhead of the algorithm. As chunk size decreases, so does \partitioning's memory requirement and runtime; only the active chunk of edges needs to be in memory and the time for the initial seed partitioning algorithm on the first chunk dominates the time for the simple greedy processing of subsequent chunks. We compare the expected number of edge cuts when using fixed greedy assignments to that of the refined greedy assignments employed by \partitioning.

\newparagraph{Fixed Greedy Assignments}
We focus on the assignment of a specific node $n$ and assume all other nodes are assigned to partitions. Among all edges, let node $n$ have $k$ neighbors, with $k_0$ in partition zero, and $k_1$ in partition one. Without loss of generality, we assume $k_0 \ge k_1$. Observe that, with a chunk size of $|E|$ (i.e., all edges), our greedy algorithm will assign node $n$ to partition zero to minimize edge cuts. 

To analyze the effect of chunk size, we ask, what is the probability node $n$ will be assigned to partition zero if only $|E|*x$ edges (sampled uniformly) are used to make the decision (i.e., if we use a chunk size of $|E|*x$)? Let $k'_0$ and $k'_1$ be the number of neighbors of node $n$ in partition zero and one that are present in the sampled $|E|*x$ edges. Then we seek to calculate $Pr(k'_0 \ge k'_1 | k_0 \ge k_1, x)$. We assume that $k'_0 + k'_1 = x*k$ (i.e., sampling $|E|*x$ edges leads to sampling $k*x$ neighbors). Then $k'_0$ (or $k'_1$) is a random variable sampled from a Hypergeometric distribution describing the probability of sampling (without replacement) a specific number of neighbors in partition zero (one) from a finite population of size $k$, containing $k_0$ ($k_1$) total neighbors in partition zero (one), using $k*x$ draws. We also have that $k'_1 = k*x - k'_0$ and $Pr(k'_0 \ge k'_1) = Pr(k'_0 \ge k*x - k'_0) = Pr(k'_0 \ge 0.5*k*x) = 1 - Pr(k'_0 < 0.5*k*x)$. The latter can be calculated using the cumulative distribution function (CDF) of the Hypergeometric distribution and describes the probability of correctly assigning node $n$ given a chunk size of $|E|*x$ (correct here means making the same greedy decision as the one made if all edges are available).

Given the probability of correctly assigning node $n$, we can calculate the expected number of correctly assigned nodes $T$ in the whole graph. Assuming nodes are independent, we have:
$E[T] = \sum_{i=1}^{|V|}(1 - Pr(k^{i'}_0 < 0.5*k^i*x))$ 
with $k^{i'}_0 \sim$ Hypergeometric($k^i$, $k^i_0$, $x$), $k^i$ the number of neighbors (among all edges) of node $i$, and $k^i_0$ the number of these neighbors in the partition containing more of node $i$'s neighbors. Finally, the expected number of edge cuts $C$ is:
\begin{align}
    \label{eqn:greedy_edge_cuts}
    E[C] = \sum_{i=1}^{|V|}&(k^i - k^i_0)*(1 - Pr(k^{i'}_0 < 0.5*k^i*x))\\ +& k^i_0*Pr(k^{i'}_0 < 0.5*k^i*x) \nonumber
\end{align}
since $k^i - k^i_0$ edges are cut for node $i$ if it is correctly assigned and $k^i_0$ edges are cut otherwise. Equation~\ref{eqn:greedy_edge_cuts} can be calculated given $k^i$ and $k^i_0$ for each node $i$ ($k^i_0$ can be estimated given an existing graph partitioning or by making assumptions about a graph's connectivity).





\newparagraph{The Benefit of Refinement}
We now ask how the expected number of edge cuts $E[C]$ changes if greedy decisions are updated (refined) based on a weighted average of neighbor estimates across chunks (as in \partitioning). We focus on the simplest case: We assume two chunks ($\alpha$ and $\beta$), each of size $|E|*x$ are used to assign a given node $n$ to a partition. Let $k'_{0, \alpha}$ and $k'_{0, \beta}$ be the number of neighbors of node $n$ in partition zero among the sampled edges in chunk $\alpha$ and $\beta$ respectively (and likewise for $k'_{1, \alpha}$, $k'_{1, \beta}$ and partition one). In the two chunk case, the weighted average simplifies to a regular average (which can be simplified to a sum): We seek to calculate $Pr(k'_{0, \alpha} + k'_{0, \beta} \ge k'_{1, \alpha} + k'_{1, \beta} | k_0 \ge k_1, x)$.

Observe that $k'_{0, \alpha} + k'_{0, \beta}$ is the number neighbors of node $n$ in the $2*(|E|*x)$ edges formed by the union of chunk $\alpha$ and $\beta$ (each chunk is disjoint). Given this, the expected number of cut edges $E[C]$, when averaging over two chunks each of size $|E|*x$, can be calculated using Equation~\ref{eqn:greedy_edge_cuts} with $x$ replaced by $2x$. In other words, refinement across chunks increases the \textit{effective chunk size} (but not actual chunk size) of the algorithm, leading to better neighbor estimates. Similar intuition applies when generalizing the analysis beyond two chunks, which we omit for brevity.

In Figure~\ref{fig:grem_ablation}, based on the analysis in this section, we plot the expected number of edge cuts $E[C]$ versus chunk size with and without refinement. Figure~\ref{fig:grem_ablation} highlights that refining greedy assignments based on neighbor estimates averaged across multiple chunks leads to fewer edge cuts, particularly for small chunk sizes; in fact, with this refinement, \partitioning can partition the graph with near minimal edge cuts even with chunk sizes $\le$10\%. See Section~\ref{subsec:eval_partitioning} for more details. 