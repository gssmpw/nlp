[
  {
    "index": 0,
    "papers": [
      {
        "key": "zhu2020modifying",
        "author": "Zhu, Chen and Rawat, Ankit Singh and Zaheer, Manzil and Bhojanapalli, Srinadh and Li, Daliang and Yu, Felix and Kumar, Sanjiv",
        "title": "Modifying memories in transformer models"
      },
      {
        "key": "lee2022plug",
        "author": "Lee, Kyungjae and Han, Wookje and Hwang, Seung-won and Lee, Hwaran and Park, Joonsuk and Lee, Sang-Woo",
        "title": "Plug-and-play adaptation for continuously-updated QA"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "de2021editing",
        "author": "De Cao, Nicola and Aziz, Wilker and Titov, Ivan",
        "title": "Editing factual knowledge in language models"
      },
      {
        "key": "mitchell2021fast",
        "author": "Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Finn, Chelsea and Manning, Christopher D",
        "title": "Fast model editing at scale"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "mitchell2021fast",
        "author": "Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Finn, Chelsea and Manning, Christopher D",
        "title": "Fast model editing at scale"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "de2021editing",
        "author": "De Cao, Nicola and Aziz, Wilker and Titov, Ivan",
        "title": "Editing factual knowledge in language models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "geva2020transformer",
        "author": "Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer",
        "title": "Transformer feed-forward layers are key-value memories"
      },
      {
        "key": "geva2022transformer",
        "author": "Geva, Mor and Caciularu, Avi and Wang, Kevin Ro and Goldberg, Yoav",
        "title": "Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "meng2022locating",
        "author": "Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan",
        "title": "Locating and editing factual associations in GPT"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "meng2022mass",
        "author": "Meng, Kevin and Sharma, Arnab Sen and Andonian, Alex and Belinkov, Yonatan and Bau, David",
        "title": "Mass-editing memory in a transformer"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zou2023universal",
        "author": "Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt",
        "title": "Universal and transferable adversarial attacks on aligned language models"
      },
      {
        "key": "liu2023autodan",
        "author": "Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei",
        "title": "Autodan: Generating stealthy jailbreak prompts on aligned large language models"
      },
      {
        "key": "zhou2024don",
        "author": "Zhou, Yukai and Huang, Zhijie and Lu, Feiyang and Qin, Zhan and Wang, Wenjie",
        "title": "Don't Say No: Jailbreaking LLM by Suppressing Refusal"
      },
      {
        "key": "chao2023jailbreaking",
        "author": "Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric",
        "title": "Jailbreaking black box large language models in twenty queries"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wang2022self",
        "author": "Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh",
        "title": "Self-instruct: Aligning language models with self-generated instructions"
      },
      {
        "key": "ganguli2022red",
        "author": "Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others",
        "title": "Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned"
      },
      {
        "key": "xu2024safedecoding",
        "author": "Xu, Zhangchen and Jiang, Fengqing and Niu, Luyao and Jia, Jinyuan and Lin, Bill Yuchen and Poovendran, Radha",
        "title": "Safedecoding: Defending against jailbreak attacks via safety-aware decoding"
      },
      {
        "key": "wang2024detoxifying",
        "author": "Wang, Mengru and Zhang, Ningyu and Xu, Ziwen and Xi, Zekun and Deng, Shumin and Yao, Yunzhi and Zhang, Qishen and Yang, Linyi and Wang, Jindong and Chen, Huajun",
        "title": "Detoxifying Large Language Models via Knowledge Editing"
      },
      {
        "key": "zhao2024defending",
        "author": "Zhao, Wei and Li, Zhe and Li, Yige and Zhang, Ye and Sun, Jun",
        "title": "Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "mazeika2024harmbench",
        "author": "Mazeika, Mantas and Phan, Long and Yin, Xuwang and Zou, Andy and Wang, Zifan and Mu, Norman and Sakhaee, Elham and Li, Nathaniel and Basart, Steven and Li, Bo and others",
        "title": "Harmbench: A standardized evaluation framework for automated red teaming and robust refusal"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "alon2023detecting",
        "author": "Alon, Gabriel and Kamfonas, Michael",
        "title": "Detecting language model attacks with perplexity"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "cao2023defending",
        "author": "Cao, Bochuan and Cao, Yuanpu and Lin, Lu and Chen, Jinghui",
        "title": "Defending against alignment-breaking attacks via robustly aligned llm"
      },
      {
        "key": "jain2023baseline",
        "author": "Jain, Neel and Schwarzschild, Avi and Wen, Yuxin and Somepalli, Gowthami and Kirchenbauer, John and Chiang, Ping-yeh and Goldblum, Micah and Saha, Aniruddha and Geiping, Jonas and Goldstein, Tom",
        "title": "Baseline defenses for adversarial attacks against aligned language models"
      },
      {
        "key": "zhou2024robust",
        "author": "Zhou, Andy and Li, Bo and Wang, Haohan",
        "title": "Robust prompt optimization for defending language models against jailbreaking attacks"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "alon2023detecting",
        "author": "Alon, Gabriel and Kamfonas, Michael",
        "title": "Detecting language model attacks with perplexity"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "cao2023defending",
        "author": "Cao, Bochuan and Cao, Yuanpu and Lin, Lu and Chen, Jinghui",
        "title": "Defending against alignment-breaking attacks via robustly aligned llm"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "jain2023baseline",
        "author": "Jain, Neel and Schwarzschild, Avi and Wen, Yuxin and Somepalli, Gowthami and Kirchenbauer, John and Chiang, Ping-yeh and Goldblum, Micah and Saha, Aniruddha and Geiping, Jonas and Goldstein, Tom",
        "title": "Baseline defenses for adversarial attacks against aligned language models"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "zhou2024robust",
        "author": "Zhou, Andy and Li, Bo and Wang, Haohan",
        "title": "Robust prompt optimization for defending language models against jailbreaking attacks"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "rafailov2024direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "wang2024detoxifying",
        "author": "Wang, Mengru and Zhang, Ningyu and Xu, Ziwen and Xi, Zekun and Deng, Shumin and Yao, Yunzhi and Zhang, Qishen and Yang, Linyi and Wang, Jindong and Chen, Huajun",
        "title": "Detoxifying Large Language Models via Knowledge Editing"
      },
      {
        "key": "zhao2024defending",
        "author": "Zhao, Wei and Li, Zhe and Li, Yige and Zhang, Ye and Sun, Jun",
        "title": "Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "wang2024detoxifying",
        "author": "Wang, Mengru and Zhang, Ningyu and Xu, Ziwen and Xi, Zekun and Deng, Shumin and Yao, Yunzhi and Zhang, Qishen and Yang, Linyi and Wang, Jindong and Chen, Huajun",
        "title": "Detoxifying Large Language Models via Knowledge Editing"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "zhao2024defending",
        "author": "Zhao, Wei and Li, Zhe and Li, Yige and Zhang, Ye and Sun, Jun",
        "title": "Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "wang2024detoxifying",
        "author": "Wang, Mengru and Zhang, Ningyu and Xu, Ziwen and Xi, Zekun and Deng, Shumin and Yao, Yunzhi and Zhang, Qishen and Yang, Linyi and Wang, Jindong and Chen, Huajun",
        "title": "Detoxifying Large Language Models via Knowledge Editing"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "wang2024detoxifying",
        "author": "Wang, Mengru and Zhang, Ningyu and Xu, Ziwen and Xi, Zekun and Deng, Shumin and Yao, Yunzhi and Zhang, Qishen and Yang, Linyi and Wang, Jindong and Chen, Huajun",
        "title": "Detoxifying Large Language Models via Knowledge Editing"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "zhao2024defending",
        "author": "Zhao, Wei and Li, Zhe and Li, Yige and Zhang, Ye and Sun, Jun",
        "title": "Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing"
      }
    ]
  }
]