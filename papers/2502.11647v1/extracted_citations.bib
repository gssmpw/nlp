@article{alon2023detecting,
  title={Detecting language model attacks with perplexity},
  author={Alon, Gabriel and Kamfonas, Michael},
  journal={arXiv preprint arXiv:2308.14132},
  year={2023}
}

@article{cao2023defending,
  title={Defending against alignment-breaking attacks via robustly aligned llm},
  author={Cao, Bochuan and Cao, Yuanpu and Lin, Lu and Chen, Jinghui},
  journal={arXiv preprint arXiv:2309.14348},
  year={2023}
}

@article{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023}
}

@article{de2021editing,
  title={Editing factual knowledge in language models},
  author={De Cao, Nicola and Aziz, Wilker and Titov, Ivan},
  journal={arXiv preprint arXiv:2104.08164},
  year={2021}
}

@article{ganguli2022red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={arXiv preprint arXiv:2209.07858},
  year={2022}
}

@article{geva2020transformer,
  title={Transformer feed-forward layers are key-value memories},
  author={Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
  journal={arXiv preprint arXiv:2012.14913},
  year={2020}
}

@article{geva2022transformer,
  title={Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space},
  author={Geva, Mor and Caciularu, Avi and Wang, Kevin Ro and Goldberg, Yoav},
  journal={arXiv preprint arXiv:2203.14680},
  year={2022}
}

@article{jain2023baseline,
  title={Baseline defenses for adversarial attacks against aligned language models},
  author={Jain, Neel and Schwarzschild, Avi and Wen, Yuxin and Somepalli, Gowthami and Kirchenbauer, John and Chiang, Ping-yeh and Goldblum, Micah and Saha, Aniruddha and Geiping, Jonas and Goldstein, Tom},
  journal={arXiv preprint arXiv:2309.00614},
  year={2023}
}

@article{lee2022plug,
  title={Plug-and-play adaptation for continuously-updated QA},
  author={Lee, Kyungjae and Han, Wookje and Hwang, Seung-won and Lee, Hwaran and Park, Joonsuk and Lee, Sang-Woo},
  journal={arXiv preprint arXiv:2204.12785},
  year={2022}
}

@article{liu2023autodan,
  title={Autodan: Generating stealthy jailbreak prompts on aligned large language models},
  author={Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2310.04451},
  year={2023}
}

@article{mazeika2024harmbench,
  title={Harmbench: A standardized evaluation framework for automated red teaming and robust refusal},
  author={Mazeika, Mantas and Phan, Long and Yin, Xuwang and Zou, Andy and Wang, Zifan and Mu, Norman and Sakhaee, Elham and Li, Nathaniel and Basart, Steven and Li, Bo and others},
  journal={arXiv preprint arXiv:2402.04249},
  year={2024}
}

@article{meng2022locating,
  title={Locating and editing factual associations in GPT},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17359--17372},
  year={2022}
}

@article{meng2022mass,
  title={Mass-editing memory in a transformer},
  author={Meng, Kevin and Sharma, Arnab Sen and Andonian, Alex and Belinkov, Yonatan and Bau, David},
  journal={arXiv preprint arXiv:2210.07229},
  year={2022}
}

@article{mitchell2021fast,
  title={Fast model editing at scale},
  author={Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Finn, Chelsea and Manning, Christopher D},
  journal={arXiv preprint arXiv:2110.11309},
  year={2021}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wang2022self,
  title={Self-instruct: Aligning language models with self-generated instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2212.10560},
  year={2022}
}

@article{wang2024detoxifying,
  title={Detoxifying Large Language Models via Knowledge Editing},
  author={Wang, Mengru and Zhang, Ningyu and Xu, Ziwen and Xi, Zekun and Deng, Shumin and Yao, Yunzhi and Zhang, Qishen and Yang, Linyi and Wang, Jindong and Chen, Huajun},
  journal={arXiv preprint arXiv:2403.14472},
  year={2024}
}

@article{xu2024safedecoding,
  title={Safedecoding: Defending against jailbreak attacks via safety-aware decoding},
  author={Xu, Zhangchen and Jiang, Fengqing and Niu, Luyao and Jia, Jinyuan and Lin, Bill Yuchen and Poovendran, Radha},
  journal={arXiv preprint arXiv:2402.08983},
  year={2024}
}

@article{zhao2024defending,
  title={Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing},
  author={Zhao, Wei and Li, Zhe and Li, Yige and Zhang, Ye and Sun, Jun},
  journal={arXiv preprint arXiv:2405.18166},
  year={2024}
}

@article{zhou2024don,
  title={Don't Say No: Jailbreaking LLM by Suppressing Refusal},
  author={Zhou, Yukai and Huang, Zhijie and Lu, Feiyang and Qin, Zhan and Wang, Wenjie},
  journal={arXiv preprint arXiv:2404.16369},
  year={2024}
}

@article{zhou2024robust,
  title={Robust prompt optimization for defending language models against jailbreaking attacks},
  author={Zhou, Andy and Li, Bo and Wang, Haohan},
  journal={arXiv preprint arXiv:2401.17263},
  year={2024}
}

@article{zhu2020modifying,
  title={Modifying memories in transformer models},
  author={Zhu, Chen and Rawat, Ankit Singh and Zaheer, Manzil and Bhojanapalli, Srinadh and Li, Daliang and Yu, Felix and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:2012.00363},
  year={2020}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

