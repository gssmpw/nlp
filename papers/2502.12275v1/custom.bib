% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@inproceedings{quan-etal-2024-enhancing,
    title = "Enhancing Ethical Explanations of Large Language Models through Iterative Symbolic Refinement",
    author = "Quan, Xin  and
      Valentino, Marco  and
      Dennis, Louise  and
      Freitas, Andre",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.eacl-long.1/",
    pages = "1--22",
    abstract = "An increasing amount of research in Natural Language Inference (NLI) focuses on the application and evaluation of Large Language Models (LLMs) and their reasoning capabilities. Despite their success, however, LLMs are still prone to factual errors and inconsistencies in their explanations, offering limited control and interpretability for inference in complex domains. In this paper, we focus on ethical NLI, investigating how hybrid neuro-symbolic techniques can enhance the logical validity and alignment of ethical explanations produced by LLMs. Specifically, we present an abductive-deductive framework named Logic-Explainer, which integrates LLMs with an external backward-chaining solver to refine step-wise natural language explanations and jointly verify their correctness, reduce incompleteness and minimise redundancy. An extensive empirical analysis demonstrates that Logic-Explainer can improve explanations generated via in-context learning methods and Chain-of-Thought (CoT) on challenging ethical NLI tasks, while, at the same time, producing formal proofs describing and supporting models' reasoning. As ethical NLI requires commonsense reasoning to identify underlying moral violations, our results suggest the effectiveness of neuro-symbolic methods for multi-step NLI more broadly, opening new opportunities to enhance the logical consistency, reliability, and alignment of LLMs."
}

@inproceedings{dalal-etal-2024-inference,
    title = "Inference to the Best Explanation in Large Language Models",
    author = "Dalal, Dhairya  and
      Valentino, Marco  and
      Freitas, Andre  and
      Buitelaar, Paul",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.14/",
    doi = "10.18653/v1/2024.acl-long.14",
    pages = "217--235",
    abstract = "While Large Language Models (LLMs) have found success in real-world applications, their underlying explanatory process is still poorly understood. This paper proposes \textit{IBE-Eval}, a framework inspired by philosophical accounts on \textit{Inference to the Best Explanation (IBE)} to advance the interpretation and evaluation of LLMs' explanations. \textit{IBE-Eval} estimates the plausibility of natural language explanations through a combination of explicit logical and linguistic features including: \textit{consistency}, \textit{parsimony}, \textit{coherence}, and \textit{uncertainty}. Extensive experiments are conducted on \textit{Causal Question Answering (CQA)}, where \textit{IBE-Eval} is tasked to select the most plausible causal explanation amongst competing ones generated by LLMs (i.e., GPT 3.5 and Llama 2). The experiments reveal that \textit{IBE-Eval} can successfully identify the best explanation with up to 77{\%} accuracy ($\approx 27\%$ above random), improving upon a GPT 3.5-as-a-Judge baseline ($\approx+17\%$) while being intrinsically more efficient and interpretable. Additional analyses suggest that, despite model-specific variances, LLM-generated explanations tend to conform to IBE criteria and that \textit{IBE-Eval} is significantly correlated with human judgment, opening up opportunities for future development of automated explanation verification tools."
}

@inproceedings{quan-etal-2024-verification,
    title = "Verification and Refinement of Natural Language Explanations through {LLM}-Symbolic Theorem Proving",
    author = "Quan, Xin  and
      Valentino, Marco  and
      Dennis, Louise A.  and
      Freitas, Andre",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.172/",
    doi = "10.18653/v1/2024.emnlp-main.172",
    pages = "2933--2958",
    abstract = "Natural language explanations represent a proxy for evaluating explanation-based and multi-step Natural Language Inference (NLI) models. However, assessing the validity of explanations for NLI is challenging as it typically involves the crowd-sourcing of apposite datasets, a process that is time-consuming and prone to logical errors. To address existing limitations, this paper investigates the verification and refinement of natural language explanations through the integration of Large Language Models (LLMs) and Theorem Provers (TPs). Specifically, we present a neuro-symbolic framework, named Explanation-Refiner, that integrates TPs with LLMs to generate and formalise explanatory sentences and suggest potential inference strategies for NLI. In turn, the TP is employed to provide formal guarantees on the logical validity of the explanations and to generate feedback for subsequent improvements. We demonstrate how Explanation-Refiner can be jointly used to evaluate explanatory reasoning, autoformalisation, and error correction mechanisms of state-of-the-art LLMs as well as to automatically enhance the quality of explanations of variable complexity in different domains."
}

@article{jiang2024leanreasoner,
  title={LeanReasoner: Boosting Complex Logical Reasoning with Lean},
  author={Jiang, Dongwei and Fonseca, Marcio and Cohen, Shay B},
  journal={arXiv preprint arXiv:2403.13312},
  year={2024}
}
@article{pan2023logic,
  title={Logic-lm: Empowering large language models with symbolic solvers for faithful logical reasoning},
  author={Pan, Liangming and Albalak, Alon and Wang, Xinyi and Wang, William Yang},
  journal={arXiv preprint arXiv:2305.12295},
  year={2023}
}
@article{quan2024verification,
  title={Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving},
  author={Quan, Xin and Valentino, Marco and Dennis, Louise A and Freitas, Andr{\'e}},
  journal={arXiv preprint arXiv:2405.01379},
  year={2024}
}
@article{liu2024logic,
  title={Logic Agent: Enhancing Validity with Logic Rule Invocation},
  author={Liu, Hanmeng and Teng, Zhiyang and Zhang, Chaoli and Zhang, Yue},
  journal={arXiv preprint arXiv:2404.18130},
  year={2024}
}
@inproceedings{enstrom2024reasoning,
  title={Reasoning in Transformers--Mitigating Spurious Correlations and Reasoning Shortcuts},
  author={Enstr{\"o}m, Daniel and Kjellberg, Viktor and Johansson, Moa},
  booktitle={International Conference on Neural-Symbolic Learning and Reasoning},
  pages={207--221},
  year={2024},
  organization={Springer}
}
@article{olausson2023linc,
  title={LINC: A neurosymbolic approach for logical reasoning by combining language models with first-order logic provers},
  author={Olausson, Theo X and Gu, Alex and Lipkin, Benjamin and Zhang, Cedegao E and Solar-Lezama, Armando and Tenenbaum, Joshua B and Levy, Roger},
  journal={arXiv preprint arXiv:2310.15164},
  year={2023}
}
@article{yang2024enhancing,
  title={Enhancing the code debugging ability of llms via communicative agent based data refinement},
  author={Yang, Weiqing and Wang, Hanbin and Liu, Zhenghao and Li, Xinze and Yan, Yukun and Wang, Shuo and Gu, Yu and Yu, Minghe and Liu, Zhiyuan and Yu, Ge},
  journal={arXiv preprint arXiv:2408.05006},
  year={2024}
}
@article{bi2024iterative,
  title={Iterative refinement of project-level code context for precise code generation with compiler feedback},
  author={Bi, Zhangqian and Wan, Yao and Wang, Zheng and Zhang, Hongyu and Guan, Batu and Lu, Fangxin and Zhang, Zili and Sui, Yulei and Jin, Hai and Shi, Xuanhua},
  journal={arXiv preprint arXiv:2403.16792},
  year={2024}
}
@article{kalyanpur2024llm,
  title={Llm-arc: Enhancing llms with an automated reasoning critic},
  author={Kalyanpur, Aditya and Saravanakumar, Kailash Karthik and Barres, Victor and Chu-Carroll, Jennifer and Melville, David and Ferrucci, David},
  journal={arXiv preprint arXiv:2406.17663},
  year={2024}
}
@inproceedings{sun2024determlr,
  title={Determlr: Augmenting llm-based logical reasoning from indeterminacy to determinacy},
  author={Sun, Hongda and Xu, Weikai and Liu, Wei and Luan, Jian and Wang, Bin and Shang, Shuo and Wen, Ji-Rong and Yan, Rui},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9828--9862},
  year={2024}
}
@article{xu2024faithful,
  title={Faithful Logical Reasoning via Symbolic Chain-of-Thought},
  author={Xu, Jundong and Fei, Hao and Pan, Liangming and Liu, Qian and Lee, Mong-Li and Hsu, Wynne},
  journal={arXiv preprint arXiv:2405.18357},
  year={2024}
}
@article{li2024leveraging,
  title={Leveraging LLMs for Hypothetical Deduction in Logical Inference: A Neuro-Symbolic Approach},
  author={Li, Qingchuan and Li, Jiatong and Liu, Tongxuan and Zeng, Yuting and Cheng, Mingyue and Huang, Weizhe and Liu, Qi},
  journal={arXiv preprint arXiv:2410.21779},
  year={2024}
}
@article{clark2020transformers,
  title={Transformers as soft reasoners over language},
  author={Clark, Peter and Tafjord, Oyvind and Richardson, Kyle},
  journal={arXiv preprint arXiv:2002.05867},
  year={2020}
}
@article{wang2019logic,
  title={Logic rules powered knowledge graph embedding},
  author={Wang, Pengwei and Dou, Dejing and Wu, Fangzhao and de Silva, Nisansa and Jin, Lianwen},
  journal={arXiv preprint arXiv:1903.03772},
  year={2019}
}
@inproceedings{wang2024chatlogic,
  title={ChatLogic: Integrating Logic Programming with Large Language Models for Multi-Step Reasoning},
  author={Wang, Zhongsheng and Liu, Jiamou and Bao, Qiming and Rong, Hongfei and Zhang, Jingfeng},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2024},
  organization={IEEE}
}
@article{ma2024think,
  title={Think-on-graph 2.0: Deep and interpretable large language model reasoning with knowledge graph-guided retrieval},
  author={Ma, Shengjie and Xu, Chengjin and Jiang, Xuhui and Li, Muzhi and Qu, Huaren and Guo, Jian},
  journal={arXiv e-prints},
  pages={arXiv--2407},
  year={2024}
}
@article{borazjanizadeh2024reliable,
  title={Reliable reasoning beyond natural language},
  author={Borazjanizadeh, Nasim and Piantadosi, Steven T},
  journal={arXiv preprint arXiv:2407.11373},
  year={2024}
}
@article{tan2024struct,
  title={Struct-X: Enhancing Large Language Models Reasoning with Structured Data},
  author={Tan, Xiaoyu and Wang, Haoyu and Qiu, Xihe and Cheng, Yuan and Xu, Yinghui and Chu, Wei and Qi, Yuan},
  journal={arXiv preprint arXiv:2407.12522},
  year={2024}
}
@article{wu2023lemur,
  title={Lemur: Integrating large language models in automated program verification},
  author={Wu, Haoze and Barrett, Clark and Narodytska, Nina},
  journal={arXiv preprint arXiv:2310.04870},
  year={2023}
}
@article{feng2023language,
  title={Language models can be logical solvers},
  author={Feng, Jiazhan and Xu, Ruochen and Hao, Junheng and Sharma, Hiteshi and Shen, Yelong and Zhao, Dongyan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2311.06158},
  year={2023}
}
@inproceedings{feng2024language,
  title={Language Models can be Deductive Solvers},
  author={Feng, Jiazhan and Xu, Ruochen and Hao, Junheng and Sharma, Hiteshi and Shen, Yelong and Zhao, Dongyan and Chen, Weizhu},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2024},
  pages={4026--4042},
  year={2024}
}
@inproceedings{wen2024enchanting,
  title={Enchanting program specification synthesis by large language models using static analysis and program verification},
  author={Wen, Cheng and Cao, Jialun and Su, Jie and Xu, Zhiwu and Qin, Shengchao and He, Mengda and Li, Haokun and Cheung, Shing-Chi and Tian, Cong},
  booktitle={International Conference on Computer Aided Verification},
  pages={302--328},
  year={2024},
  organization={Springer}
}
@article{jing2024translating,
  title={Translating Expert Intuition into Quantifiable Features: Encode Investigator Domain Knowledge via LLM for Enhanced Predictive Analytics},
  author={Jing, Phoebe and Gao, Yijing and Zhang, Yuanhang and Zeng, Xianlong},
  journal={arXiv preprint arXiv:2405.08017},
  year={2024}
}
@article{wysocka2024large,
  title={Large Language Models, scientific knowledge and factuality: A framework to streamline human expert evaluation},
  author={Wysocka, Magdalena and Wysocki, Oskar and Delmas, Maxime and Mutel, Vincent and Freitas, Andr{\'e}},
  journal={Journal of Biomedical Informatics},
  volume={158},
  pages={104724},
  year={2024},
  publisher={Elsevier}
}
@article{szymanski2024limitations,
  title={Limitations of the LLM-as-a-Judge Approach for Evaluating LLM Outputs in Expert Knowledge Tasks},
  author={Szymanski, Annalisa and Ziems, Noah and Eicher-Miller, Heather A and Li, Toby Jia-Jun and Jiang, Meng and Metoyer, Ronald A},
  journal={arXiv preprint arXiv:2410.20266},
  year={2024}
}
@inproceedings{wang2023review,
  title={A Review on Code Generation with LLMs: Application and Evaluation},
  author={Wang, Jianxun and Chen, Yixiang},
  booktitle={2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)},
  pages={284--289},
  year={2023},
  organization={IEEE}
}
@article{lin2024llm,
  title={When llm-based code generation meets the software development process},
  author={Lin, Feng and Kim, Dong Jae and others},
  journal={arXiv preprint arXiv:2403.15852},
  year={2024}
}
@article{han2024large,
  title={Large Language Models Can Automatically Engineer Features for Few-Shot Tabular Learning},
  author={Han, Sungwon and Yoon, Jinsung and Arik, Sercan O and Pfister, Tomas},
  journal={arXiv preprint arXiv:2404.09491},
  year={2024}
}
@inproceedings{boicu2001automatic,
  title={Automatic knowledge acquisition from subject matter experts},
  author={Boicu, Mihai and Tecuci, Gheorghe and Stanescu, Bogdan and Marcu, Dorin and Cascaval, Cristina},
  booktitle={Proceedings 13th IEEE International Conference on Tools with Artificial Intelligence. ICTAI 2001},
  pages={69--78},
  year={2001},
  organization={IEEE}
}
@article{selby2024quantitative,
  title={Quantitative knowledge retrieval from large language models},
  author={Selby, David and Spriestersbach, Kai and Iwashita, Yuichiro and Bappert, Dennis and Warrier, Archana and Mukherjee, Sumantrak and Asim, Muhammad Nabeel and Kise, Koichi and Vollmer, Sebastian},
  journal={arXiv preprint arXiv:2402.07770},
  year={2024}
}
@article{mcinerney2023chill,
  title={Chill: zero-shot custom interpretable feature extraction from clinical notes with large language models},
  author={McInerney, Denis Jered and Young, Geoffrey and van de Meent, Jan-Willem and Wallace, Byron C},
  journal={arXiv preprint arXiv:2302.12343},
  year={2023}
}

% New addded papers -------------------------------------
@article{wang2023meta,
  title={Meta-reasoning: Semantics-symbol deconstruction for large language models},
  author={Wang, Yiming and Zhang, Zhuosheng and Zhang, Pei and Yang, Baosong and Wang, Rui},
  journal={arXiv preprint arXiv:2306.17820},
  year={2023}
}
@article{chen2022large,
  title={Large language models are few (1)-shot table reasoners},
  author={Chen, Wenhu},
  journal={arXiv preprint arXiv:2210.06710},
  year={2022}
}
@article{xu2023symbol,
  title={Symbol-LLM: Towards foundational symbol-centric interface for large language models},
  author={Xu, Fangzhi and Wu, Zhiyong and Sun, Qiushi and Ren, Siyu and Yuan, Fei and Yuan, Shuai and Lin, Qika and Qiao, Yu and Liu, Jun},
  journal={arXiv preprint arXiv:2311.09278},
  year={2023}
}
@article{chen2022program,
  title={Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={arXiv preprint arXiv:2211.12588},
  year={2022}
}
@article{xu2024core,
  title={CoRE: LLM as Interpreter for Natural Language Programming, Pseudo-Code Programming, and Flow Programming of AI Agents},
  author={Xu, Shuyuan and Li, Zelong and Mei, Kai and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2405.06907},
  year={2024}
}
@article{zhang2024refactoring,
  title={Refactoring to pythonic idioms: A hybrid knowledge-driven approach leveraging large language models},
  author={Zhang, Zejun and Xing, Zhenchang and Ren, Xiaoxue and Lu, Qinghua and Xu, Xiwei},
  journal={Proceedings of the ACM on Software Engineering},
  volume={1},
  number={FSE},
  pages={1107--1128},
  year={2024},
  publisher={ACM New York, NY, USA}
}
@article{lyu2024automatic,
  title={Automatic programming: Large language models and beyond},
  author={Lyu, Michael R and Ray, Baishakhi and Roychoudhury, Abhik and Tan, Shin Hwei and Thongtanunam, Patanamon},
  journal={ACM Transactions on Software Engineering and Methodology},
  year={2024},
  publisher={ACM New York, NY}
}
@article{yang2024if,
  title={If llm is the wizard, then code is the wand: A survey on how code empowers large language models to serve as intelligent agents},
  author={Yang, Ke and Liu, Jiateng and Wu, John and Yang, Chaoqi and Fung, Yi R and Li, Sha and Huang, Zixuan and Cao, Xu and Wang, Xingyao and Wang, Yiquan and others},
  journal={arXiv preprint arXiv:2401.00812},
  year={2024}
}
@article{soroco2025pde,
  title={PDE-Controller: LLMs for Autoformalization and Reasoning of PDEs},
  author={Soroco, Mauricio and Song, Jialin and Xia, Mengzhou and Emond, Kye and Sun, Weiran and Chen, Wuyang},
  journal={arXiv preprint arXiv:2502.00963},
  year={2025}
}
@article{wang2024enhancing,
  title={Enhancing computer programming education with llms: A study on effective prompt engineering for python code generation},
  author={Wang, Tianyu and Zhou, Nianjun and Chen, Zhixiong},
  journal={arXiv preprint arXiv:2407.05437},
  year={2024}
}
@article{nejjar2025llms,
  title={Llms for science: Usage for code generation and data analysis},
  author={Nejjar, Mohamed and Zacharias, Luca and Stiehle, Fabian and Weber, Ingo},
  journal={Journal of Software: Evolution and Process},
  volume={37},
  number={1},
  pages={e2723},
  year={2025},
  publisher={Wiley Online Library}
}
@article{ugare2024improving,
  title={Improving llm code generation with grammar augmentation},
  author={Ugare, Shubham and Suresh, Tarun and Kang, Hangoo and Misailovic, Sasa and Singh, Gagandeep},
  journal={arXiv preprint arXiv:2403.01632},
  year={2024}
}
@inproceedings{yadav2024pythonsaga,
  title={PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLMs},
  author={Yadav, Ankit and Beniwal, Himanshu and Singh, Mayank},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={17113--17126},
  year={2024}
}
@inproceedings{guo2024stop,
  title={When to stop? towards efficient code generation in llms with excess token prevention},
  author={Guo, Lianghong and Wang, Yanlin and Shi, Ensheng and Zhong, Wanjun and Zhang, Hongyu and Chen, Jiachi and Zhang, Ruikai and Ma, Yuchi and Zheng, Zibin},
  booktitle={Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages={1073--1085},
  year={2024}
}
@article{chu2024think,
  title={Think Together and Work Better: Combining Humans' and LLMs' Think-Aloud Outcomes for Effective Text Evaluation},
  author={Chu, SeongYeub and Kim, JongWoo and Yi, MunYong},
  journal={arXiv preprint arXiv:2409.07355},
  year={2024}
}
@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohan Maheswari and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vítor Albiero and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaofang Wang and Xiaoqing Ellen Tan and Xide Xia and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aayushi Srivastava and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Amos Teo and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Dong and Annie Franco and Anuj Goyal and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Ce Liu and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Cynthia Gao and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Eric-Tuan Le and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Filippos Kokkinos and Firat Ozgenel and Francesco Caggioni and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hakan Inan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Hongyuan Zhan and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Ilias Leontiadis and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Janice Lam and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Kartikay Khandelwal and Katayoun Zand and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kiran Jagadeesh and Kun Huang and Kunal Chawla and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Miao Liu and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikhil Mehta and Nikolay Pavlovich Laptev and Ning Dong and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Rangaprabhu Parthasarathy and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Russ Howes and Ruty Rinott and Sachin Mehta and Sachin Siby and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Mahajan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shishir Patil and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Summer Deng and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Koehler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaojian Wu and Xiaolan Wang and Xilun Wu and Xinbo Gao and Yaniv Kleinman and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yu Zhao and Yuchen Hao and Yundi Qian and Yunlu Li and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao and Zhiyu Ma},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}
@misc{jiang2024mixtralexperts,
      title={Mixtral of Experts}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Antoine Roux and Arthur Mensch and Blanche Savary and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Emma Bou Hanna and Florian Bressand and Gianna Lengyel and Guillaume Bour and Guillaume Lample and Lélio Renard Lavaud and Lucile Saulnier and Marie-Anne Lachaux and Pierre Stock and Sandeep Subramanian and Sophia Yang and Szymon Antoniak and Teven Le Scao and Théophile Gervet and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2024},
      eprint={2401.04088},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.04088}, 
}
@misc{jiang2023mistral7b,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06825}, 
}
@misc{yang2024qwen2technicalreport,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jianxin Yang and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Xuejing Liu and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhifang Guo and Zhihao Fan},
      year={2024},
      eprint={2407.10671},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.10671}, 
}
@misc{gemmateam2024gemmaopenmodelsbased,
      title={Gemma: Open Models Based on Gemini Research and Technology}, 
      author={Gemma Team and Thomas Mesnard and Cassidy Hardin and Robert Dadashi and Surya Bhupatiraju and Shreya Pathak and Laurent Sifre and Morgane Rivière and Mihir Sanjay Kale and Juliette Love and Pouya Tafti and Léonard Hussenot and Pier Giuseppe Sessa and Aakanksha Chowdhery and Adam Roberts and Aditya Barua and Alex Botev and Alex Castro-Ros and Ambrose Slone and Amélie Héliou and Andrea Tacchetti and Anna Bulanova and Antonia Paterson and Beth Tsai and Bobak Shahriari and Charline Le Lan and Christopher A. Choquette-Choo and Clément Crepy and Daniel Cer and Daphne Ippolito and David Reid and Elena Buchatskaya and Eric Ni and Eric Noland and Geng Yan and George Tucker and George-Christian Muraru and Grigory Rozhdestvenskiy and Henryk Michalewski and Ian Tenney and Ivan Grishchenko and Jacob Austin and James Keeling and Jane Labanowski and Jean-Baptiste Lespiau and Jeff Stanway and Jenny Brennan and Jeremy Chen and Johan Ferret and Justin Chiu and Justin Mao-Jones and Katherine Lee and Kathy Yu and Katie Millican and Lars Lowe Sjoesund and Lisa Lee and Lucas Dixon and Machel Reid and Maciej Mikuła and Mateo Wirth and Michael Sharman and Nikolai Chinaev and Nithum Thain and Olivier Bachem and Oscar Chang and Oscar Wahltinez and Paige Bailey and Paul Michel and Petko Yotov and Rahma Chaabouni and Ramona Comanescu and Reena Jana and Rohan Anil and Ross McIlroy and Ruibo Liu and Ryan Mullins and Samuel L Smith and Sebastian Borgeaud and Sertan Girgin and Sholto Douglas and Shree Pandya and Siamak Shakeri and Soham De and Ted Klimenko and Tom Hennigan and Vlad Feinberg and Wojciech Stokowiec and Yu-hui Chen and Zafarali Ahmed and Zhitao Gong and Tris Warkentin and Ludovic Peran and Minh Giang and Clément Farabet and Oriol Vinyals and Jeff Dean and Koray Kavukcuoglu and Demis Hassabis and Zoubin Ghahramani and Douglas Eck and Joelle Barral and Fernando Pereira and Eli Collins and Armand Joulin and Noah Fiedel and Evan Senter and Alek Andreev and Kathleen Kenealy},
      year={2024},
      eprint={2403.08295},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.08295}, 
}

@article{wysocka2024syllobio,
  title={SylloBio-NLI: Evaluating Large Language Models on Biomedical Syllogistic Reasoning},
  author={Wysocka, Magdalena and Carvalho, Danilo S and Wysocki, Oskar and Valentino, Marco and Freitas, Andre},
  journal={arXiv preprint arXiv:2410.14399},
  year={2024}
}

@article{bogatu2023meta,
  title={Meta-analysis informed machine learning: Supporting cytokine storm detection during CAR-T cell Therapy},
  author={Bogatu, Alex and Wysocka, Magdalena and Wysocki, Oskar and Butterworth, Holly and Pillai, Manon and Allison, Jennifer and Landers, D{\'o}nal and Kilgour, Elaine and Thistlethwaite, Fiona and Freitas, Andr{\'e}},
  journal={Journal of Biomedical Informatics},
  volume={142},
  pages={104367},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{wysocki2024llm,
  title={An LLM-based Knowledge Synthesis and Scientific Reasoning Framework for Biomedical Discovery},
  author={Wysocki, Oskar and Carvalho, Danilo and Bogatu, Alex and Freitas, Andr{\'e} and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  pages={355--364},
  year={2024}
}

@article{delmas-etal-2024-relation,
    title = "Relation Extraction in Underexplored Biomedical Domains: A Diversity-optimized Sampling and Synthetic Data Generation Approach",
    author = "Delmas, Maxime  and
      Wysocka, Magdalena  and
      Freitas, Andr{\'e}",
    journal = "Computational Linguistics",
    volume = "50",
    number = "3",
    month = sep,
    year = "2024",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2024.cl-3.4/",
    doi = "10.1162/coli_a_00520",
    pages = "953--1000",
    abstract = "The sparsity of labeled data is an obstacle to the development of Relation Extraction (RE) models and the completion of databases in various biomedical areas. While being of high interest in drug-discovery, the literature on natural products, reporting the identification of potential bioactive compounds from organisms, is a concrete example of such an overlooked topic. To mark the start of this new task, we created the first curated evaluation dataset and extracted literature items from the LOTUS database to build training sets. To this end, we developed a new sampler, inspired by diversity metrics in ecology, named Greedy Maximum Entropy sampler (https://github.com/idiap/gme-sampler). The strategic optimization of both balance and diversity of the selected items in the evaluation set is important given the resource-intensive nature of manual curation. After quantifying the noise in the training set, in the form of discrepancies between the text of input abstracts and the expected output labels, we explored different strategies accordingly. Framing the task as an end-to-end Relation Extraction, we evaluated the performance of standard fine-tuning (BioGPT, GPT-2, and Seq2rel) and few-shot learning with open Large Language Models (LLMs) (LLaMA 7B-65B). In addition to their evaluation in few-shot settings, we explore the potential of open LLMs as synthetic data generators and propose a new workflow for this purpose. All evaluated models exhibited substantial improvements when fine-tuned on synthetic abstracts rather than the original noisy data. We provide our best performing (F1-score = 59.0) BioGPT-Large model for end-to-end RE of natural products relationships along with all the training and evaluation datasets. See more details at https://github.com/idiap/abroad-re."
}

@article{wysocki2023transformers,
  title={Transformers and the representation of biomedical background knowledge},
  author={Wysocki, Oskar and Zhou, Zili and O’Regan, Paul and Ferreira, Deborah and Wysocka, Magdalena and Landers, D{\'o}nal and Freitas, Andr{\'e}},
  journal={Computational Linguistics},
  volume={49},
  number={1},
  pages={73--115},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}


@inproceedings{meadows-etal-2024-symbolic,
    title = "A Symbolic Framework for Evaluating Mathematical Reasoning and Generalisation with Transformers",
    author = "Meadows, Jordan  and
      Valentino, Marco  and
      Teney, Damien  and
      Freitas, Andre",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.84/",
    doi = "10.18653/v1/2024.naacl-long.84",
    pages = "1505--1523",
    abstract = "This paper proposes a methodology for generating and perturbing detailed derivations of equations at scale, aided by a symbolic engine, to evaluate the generalisability of Transformers to out-of-distribution mathematical reasoning problems. Instantiating the framework in the context of sequence classification tasks, we compare the capabilities of GPT-4, GPT-3.5, and a canon of fine-tuned BERT models, exploring the relationship between specific operators and generalisation failure via the perturbation of reasoning aspects such as symmetry and variable surface forms. Surprisingly, our empirical evaluation reveals that the average in-distribution performance of fine-tuned models surpasses GPT-3.5, and rivals GPT-4. However, perturbations to input reasoning can reduce their performance by up to 80 F1 points. Overall, the results suggest that the in-distribution performance of smaller open-source models may potentially rival GPT by incorporating appropriately structured derivation dependencies during training, and highlight a shared weakness between BERT and GPT involving a relative inability to decode indirect references to mathematical entities. We release the full codebase, constructed datasets, and fine-tuned models to encourage future progress in the field."
}

@misc{meadows2025controllingequationalreasoninglarge,
      title={Controlling Equational Reasoning in Large Language Models with Prompt Interventions}, 
      author={Jordan Meadows and Marco Valentino and Andre Freitas},
      year={2025},
      eprint={2307.09998},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09998}, 
}