\section{Related work}
Our work intersects several research streams including neurosymbolic reasoning, code generation from natural language, and iterative self‐correction. Several recent studies have explored neurosymbolic approaches that translate natural language problems into formal logical representations. For instance, LeanReasoner ____ and Logic-LM ____ formalize reasoning tasks as theorems to be proven by external solvers, while LINC ____ and Symbolic Chain-of-Thought ____ convert natural language inputs into first-order logic for symbolic deduction. Similarly, works such as Logic-of-Thought ____ and Logic Agent ____ inject explicit logical rules into the reasoning process, enhancing the coherence and validity of generated outputs.

Parallel to these efforts, iterative refinement strategies have emerged to address error accumulation in LLM outputs. For example, LLM-ARC ____ and Determlr ____ leverage automated feedback to guide the self-correction of reasoning chains, while SIP-BART ____ and ChatLogic ____ integrate symbolic checkers or logic programming into the inference process. In the realm of code generation, methods such as AutoSpec ____ and CoCoGen ____ employ compiler feedback and static analysis to iteratively refine generated code. Yet, despite these promising approaches, challenges remain in reliably translating domain-specific expert knowledge into executable code.

Our framework, ExKLoP, specifically addresses the underexplored challenge of converting expert engineering guidelines—expressed as natural language premises—into Python logic rules that can be executed and validated. While previous studies have focused on symbolic reasoning ____ or on general code generation benchmarks ____, our work uniquely investigates whether LLMs can integrate and preserve the nuanced constraints of domain-specific recommendations, as encountered in industrial and engineering settings.

Additionally, research on integrating expert intuition into machine learning pipelines—such as the work by ____, ____ and ____—has largely focused on feature extraction for predictive analytics. In contrast, ExKLoP evaluates the transformation of expert knowledge into operational logic, ensuring that the resulting code not only meets syntactic standards but also adheres to strict logical constraints. This is crucial when the generated code is intended to monitor and control critical systems, as even minor logical errors can have significant real-world consequences.

Our investigation also builds upon prior research in iterative self-correction and refinement. While frameworks like LLM-ARC ____ and Determlr ____ demonstrate that feedback loops can enhance reasoning accuracy, our experiments reveal that—despite near-perfect syntactic outputs from many LLMs—logical inconsistencies persist in the translation of expert rules. This observation aligns with findings in studies on code verification and reasoning ____, suggesting that additional strategies, such as cross-model correction ____ or more robust feedback mechanisms ____, may be necessary.

Beyond these core areas, our work resonates with broader efforts in the LLM community to enhance code quality and logical reasoning. Reviews on code generation ____ and advancements in efficient syntactic decoding ____ provide context for our challenges, while studies on program synthesis and refactoring ____ underscore the ongoing need for improved integration of formal methods into LLM outputs. Moreover, research that bridges natural language and formal reasoning—such as CoRE ____ and work on automated specification synthesis ____—further highlights the diversity of approaches aimed at enhancing the interpretability and reliability of LLM-generated code.

Finally, our work complements recent advances in large-scale LLMs and their applications in diverse domains ____, and aligns with emerging trends in model scaling and multimodal integration ____. By focusing on the specific challenge of encoding domain-specific expert knowledge into executable logic and systematically assessing self-correction, ExKLoP offers a valuable benchmark and a novel perspective that bridges the gap between expert systems and automated reasoning.

In summary, while prior work has made significant strides in symbolic reasoning, iterative self-correction, and expert knowledge integration, our framework uniquely contributes to the field by targeting the reliable conversion of expert domain guidelines into validated Python logic, thereby laying the groundwork for more robust, knowledge-informed AI systems.





% Integrating Large Language Models (LLMs) with expert knowledge expressed in natural language provides a promising method for evaluating parameter values across domains ____, ____, ____, ____, ____. LLMs process complex, domain-specific information, converting expert insights into quantifiable features for improved predictive analytics. A study showed how LLMs convert investigator insights into structured features, enhancing risk assessment and decision-making ____. However, challenges remain in ensuring the accuracy and reliability of LLM outputs, particularly in specialized fields like biomedicine. A proposed framework streamlines expert evaluation of LLM-generated content to maintain scientific factuality ____.

% Some studies also explore LLMs as evaluators of their own outputs ____. ____ found that LLM evaluations aligned with human experts in specific tasks, suggesting LLMs could complement human evaluation. However, LLMs may not fully capture the nuanced judgments of experts, especially in complex tasks. Therefore, while LLMs are useful for evaluating parameter values from expert knowledge, addressing factual accuracy and depth of understanding is crucial. Combining LLMs with human expertise can lead to more reliable evaluations across various domains ____.

% Recent advancements combine LLMs with symbolic solvers and programming languages to improve value range checking and constraint validation from natural language premises ____, ____, ____, ____, ____, ____, ____, ____. This integration merges LLM flexibility with formal methods' rigor, enhancing logical reasoning and program verification. Logic-LM ____ translates natural language into symbolic logic, refining errors through solver feedback for better logical accuracy. The three-stage pipeline processes logical premises, ensuring consistency and correctness. LINC ____ uses LLMs as semantic parsers to convert premises into first-order logic, outperforming traditional prompting in verifying consistency in datasets like FOLIO and ProofWriter. Lemur ____ combines LLMs with automated reasoners for program verification, improving performance on benchmarks. LoGiPT ____, ____ emulates logical solvers with strict syntax adherence, enhancing logical reasoning. AutoSpec ____ generates and validates program specifications with LLMs, ensuring alignment with program behavior across multiple benchmarks.

% These studies show that integrating LLMs with symbolic solvers enhances logical consistency, inference reliability, and program verification precision, offering scalable solutions for automating constraint validation and value range checking.


% The advent of Large Language Models (LLMs) has significantly transformed the landscape of code generation, enabling the translation of natural language descriptions into executable code ____, ____, ____, ____, ____, ____, ____, ____, ____. These models have demonstrated remarkable proficiency in understanding and generating programming constructs, thereby facilitating tasks such as range checking and constraint validation. Range checking involves verifying whether a given value falls within a specified parameter range, while constraint validation assesses if the values of multiple parameters satisfy predefined conditions. Recent advancements have also explored the integration of LLMs with symbolic solvers and programming languages to enhance the precision of value range checking and constraint validation derived from natural language premises ____, ____, ____, ____, ____, ____. This fusion combines the adaptability of LLMs with the rigor of formal methods, thereby improving logical reasoning and program verification ____, ____, ____, ____, ____, ____, ____. For instance, Logic-LM ____ translates natural language into symbolic logic, refining errors through solver feedback to achieve better logical accuracy. Similarly, LINC ____ employs LLMs as semantic parsers to convert premises into first-order logic, outperforming traditional prompting methods in verifying consistency across various datasets. These studies underscore the potential of integrating LLMs with symbolic solvers to enhance logical consistency, inference reliability, and program verification precision, offering scalable solutions for automating constraint validation and value range checking ____, ____, ____, ____, ____, ____, ____.

% Moreover, combining LLMs with expert knowledge expressed in natural language presents a promising approach for evaluating parameter values across diverse domains ____, ____, ____. LLMs can process complex, domain-specific information, converting expert insights into quantifiable features for improved predictive analytics ____, ____. For example, ____ demonstrated how LLMs could transform investigator insights into structured features, thereby enhancing risk assessment and decision-making. However, challenges persist in ensuring the accuracy and reliability of LLM outputs, particularly in specialized fields like biomedicine. To address this, framework have been proposed to streamline expert evaluation of LLM-generated content, maintaining scientific factuality ____.

% In addition to leveraging external expert knowledge, some studies have explored the potential of LLMs to evaluate their own outputs ____. ____ found that LLM evaluations aligned with human experts in specific tasks, suggesting that LLMs could complement human evaluation ____, ____. Nevertheless, LLMs may not fully capture the nuanced judgments of experts, especially in complex tasks. Therefore, while LLMs are useful for evaluating parameter values from expert knowledge, addressing factual accuracy and depth of understanding remains crucial ____. Combining LLMs with human expertise can lead to more reliable evaluations across various domains.

%While previous studies have explored LLMs for logic formalization, there remains a gap in automating and iteratively refining their outputs with minimal human intervention. This research proposes a structured methodology to improve LLM-generated logic through a systematic refinement process, enhancing reliability in real-world applications.