\section{Related Work}
\label{sec:rework}

\subsection{Graph Classification}
Graph classification has enormous applications in various fields____. Traditional kernel methods use graph decomposition to capture the similarity in graph sub-structures with specialized kernels. For example, Weisfeilerâ€“Lehman____ proposes a family of kernels for large graphs with discrete node labels. Recently, Graph Neural Networks have emerged as a primary tool for graph classification____. For instance, Graph Convolutional Network____ updates node representations iteratively by their neighboring nodes. GraphSAGE____ performs inductive learning by aggregating information from local neighborhoods. GAT____ uses the attention mechanism to capture dependencies between nodes. To handle large-scale graphs, Top-$K$ pooling____ filters the nodes by their importance scores. Recently, PersLay____ and RePHINE____ utilize Persistent Homology to capture graph topological features. Their common limitations are: 1) They fail to exploit the rich semantic and topological graph information holistically from a multi-modal perspective, which is well-addressed in TTG-NN____; 2) They overwhelmingly focus on learning from a single domain and in a supervised manner, resulting in poorly transferable representations and prohibitive demand for graph labels. 

\subsection{Domain Adaptation}
Domain adaptation aims to develop models that are transferable from a label-rich source domain to a label-scarce target domain____. It has been profoundly investigated for image data with applications including image classification and semantic segmentation____, and also explored for question-answering models____. More complex settings such as multi-source____ and multi-target____ domain adaptation have also been studied. In short, the key to domain adaptation is domain alignment. Traditional statistical methods achieve this by explicitly reducing domain discrepancy via statistics such as maximum mean discrepancy____. Recently, the conventional approaches have been based on adversarial learning____. These methods typically employ a Gradient Reversal Layer (GRL) to force domain-invariant representations from the feature extractor____ and utilize pseudo-labeling to allow for self-training____. However, while such methods for computer vision have been extensively studied, those for whole graphs are still in the infant stage.

\subsection{Graph Domain Adaptation}
Recently, a few methods have been proposed to address domain adaptation on graphs, mostly for node classification____. However, for graph classification, graphs reside in diverse feature spaces instead of a unified space from a single graph as in node classification, leading to a much more challenging problem setting. To tackle this problem, DEAL____ utilizes adversarial learning for domain alignment and distillation for pseudo-labeling. Furthermore, CoCo____ advances from adversarial learning to contrastive learning, which consists of coupled branches for graph representation learning and contrasts between branches and domains. DAGRL____ uses a similar architecture combined with adaptive adversarial perturbation to align source and target domains. Though the problem definition of domain adaptive graph classification has been established in these works, the problem remains under-explored and demands more effective approaches.