\section{Related Work}
\label{sec:rework}

\subsection{Graph Classification}
Graph classification has enormous applications in various fields~\cite{zhou2020graph}. Traditional kernel methods use graph decomposition to capture the similarity in graph sub-structures with specialized kernels. For example, Weisfeilerâ€“Lehman~\cite{shervashidze2011weisfeiler} proposes a family of kernels for large graphs with discrete node labels. Recently, Graph Neural Networks have emerged as a primary tool for graph classification~\cite{xia2021graph}. For instance, Graph Convolutional Network~\cite{kipf2016semi} updates node representations iteratively by their neighboring nodes. GraphSAGE~\cite{hamilton2017inductive} performs inductive learning by aggregating information from local neighborhoods. GAT~\cite{Velickovic2018iclr} uses the attention mechanism to capture dependencies between nodes. To handle large-scale graphs, Top-$K$ pooling~\cite{cangea2018towards, gao2019graph, horn2021topological} filters the nodes by their importance scores. Recently, PersLay~\cite{carriere2020perslay} and RePHINE~\cite{37187175462249e7b5f1073cd94984f2} utilize Persistent Homology to capture graph topological features. Their common limitations are: 1) They fail to exploit the rich semantic and topological graph information holistically from a multi-modal perspective, which is well-addressed in TTG-NN~\cite{pmlr-v238-wen24a}; 2) They overwhelmingly focus on learning from a single domain and in a supervised manner, resulting in poorly transferable representations and prohibitive demand for graph labels. 

\subsection{Domain Adaptation}
Domain adaptation aims to develop models that are transferable from a label-rich source domain to a label-scarce target domain~\cite{10.1007/978-3-642-15561-1_16,pmlr-v37-ganin15}. It has been profoundly investigated for image data with applications including image classification and semantic segmentation~\cite{Wang_Li_Ye_Long_Wang_2019, 9944086, csurka2021unsupervised}, and also explored for question-answering models~\cite{awadalla2022exploring,pmlr-v119-miller20a}. More complex settings such as multi-source~\cite{Ren_2022} and multi-target~\cite{roy2021curriculum} domain adaptation have also been studied. In short, the key to domain adaptation is domain alignment. Traditional statistical methods achieve this by explicitly reducing domain discrepancy via statistics such as maximum mean discrepancy~\cite{tzeng2014deep, pmlr-v37-long15}. Recently, the conventional approaches have been based on adversarial learning~\cite{ajakan2015domainadversarial, 10.5555/3326943.3327094, roy2021curriculum}. These methods typically employ a Gradient Reversal Layer (GRL) to force domain-invariant representations from the feature extractor~\cite{JMLR:v17:15-239} and utilize pseudo-labeling to allow for self-training~\cite{article}. However, while such methods for computer vision have been extensively studied, those for whole graphs are still in the infant stage.

\subsection{Graph Domain Adaptation}
Recently, a few methods have been proposed to address domain adaptation on graphs, mostly for node classification~\cite{pmlr-v202-liu23u, you2023graph, ijcai2019p0606, 10.1145/3366423.3380219, NEURIPS2021_eb55e369}. However, for graph classification, graphs reside in diverse feature spaces instead of a unified space from a single graph as in node classification, leading to a much more challenging problem setting. To tackle this problem, DEAL~\cite{10.1145/3503161.3548012} utilizes adversarial learning for domain alignment and distillation for pseudo-labeling. Furthermore, CoCo~\cite{pmlr-v202-yin23a} advances from adversarial learning to contrastive learning, which consists of coupled branches for graph representation learning and contrasts between branches and domains. DAGRL~\cite{luo2023domainadaptivegraphclassification} uses a similar architecture combined with adaptive adversarial perturbation to align source and target domains. Though the problem definition of domain adaptive graph classification has been established in these works, the problem remains under-explored and demands more effective approaches.