\section{Comprehensive discussion of \citet{plaut_avoiding_2024}}\label{sec:ac-full}

This section provides technical details relating to \citet{plaut_avoiding_2024} which were omitted from \Cref{sec:ac-overview}. We also reproduce the pseudocode for their Algorithm 1 here for convenience.

\subsection{Comprehensive comparison between our model and that of \citet{plaut_avoiding_2024}}

\Cref{tab:model-comparison-full} provides a complete list of the differences between our models. The first four were already covered in \Cref{sec:ac-overview}, but we discuss the last three here.


\paragraph{Source of next state.} In an MDP, each state is generated by the transition kernel $P$. In the online learning literature (and in \citet{plaut_avoiding_2024}), each state is generated by an adversary as a function of the events of all previous timestamps.\footnote{One can also consider a non-adaptive or ``oblivious'' adversary, but \citet{plaut_avoiding_2024} allow adaptive adversaries.} Clearly an MDP transition kernel is one way for the adversary to choose the next state, so any result which applies to all adversaries also applies to an MDP transition kernel.

\input{model_comparison_full}

\paragraph{Smoothness.} A $\sigma$-smooth adversary cannot directly pick $s_t$ but must sample $s_t$ from a distribution
$\mathcal{D}_t$ whose concentration is upper-bounded by $1/\sigma$ times the uniform distribution. In an MDP, $s_t$ is sampled from the distribution $P(s_{t-1}, a_{t-1})$, so a $\sigma$-smooth adversary corresponds to a $\sigma$-smooth $P$ as defined in \Cref{sec:model}.

\paragraph{Agent observations.} In most of the online learning literature, the agent observes each reward it obtains. However, \citet{plaut_avoiding_2024} actually do not allow the agent to observe rewards. This is because in their model, each reward represents the chance of catastrophe on the time step. In most scenarios, one only observes whether catastrophe occurred, not its probability. 

In MDPs, typically the agent does observe rewards, since this is the only way for it to learn which states and actions are good. However, observing rewards turns out to be irrelevant for our results. This is because (1) our reduction does not utilize any reward observations and (2) the algorithm from \citet{plaut_avoiding_2024} is assumed to not observe rewards, as mentioned.


\input{algorithm}

\subsection{Another algorithm from \citet{plaut_avoiding_2024}}

In the main body, we focused on the primary algorithm from \citet{plaut_avoiding_2024} (\Cref{alg:nd}). However, they provide a second algorithm with the same guarantee of subconstant regret under different assumptions.

\begin{lemma}[Theorem D.3 in \citet{plaut_avoiding_2024}]
\label{lem:bucket-regret}
Assume that $\s \subseteq \bbr$ and that $\pi^m(s)$ switches at most $K$ times as $s$ moves from $-\infty$ to $+\infty$. Then for any $c \in (1/2,1)$ Algorithm 4 in \citet{plaut_avoiding_2024} satisfies \Cref{def:ac} with
\begin{align*}
Q_T  \le&\ (\diam(\smols)+4)T^c\\
\rac \le&\  2LKT^{1-2c}
\end{align*}
\end{lemma}

Combining \Cref{lem:bucket-regret} with \Cref{thm:main} produces the following alternative no-regret guarantee:

\begin{theorem}
\label{thm:bucket}
For any $c \in (0,1)$, Algorithm 4 from \citet{plaut_avoiding_2024} satisfies
\begin{align*}
Q_T \le&\ KLT^{2(1-c)}\\
R_T  \le&\ (1+\diam(\smols))T^c
\end{align*}
\end{theorem}

\subsection{Additive vs multiplicative subconstant regret}

See \Cref{sec:ac-overview} for the preliminary discussion of additive vs multiplicative subconstant regret. Here we formalize a connection between these two metrics. Specifically, \Cref{prop:sum-prod} states that when we take the supremum over payoff functions and payoffs are in $[0,1]$, these objectives roughly coincide. This is not an exact equivalence, but the approximation $1+x \approx \exp(x)$ for $x \approx 0$ implies that $1-\exp \big(\sum_{t=1}^T \mu_t(s_t,a_t) -\sum_{t=1}^T \mu_t^m(s_t) \big) \approx  \sum_{t=1}^T \mu_t^m(s_t) - \sum_{t=1}^T \mu_t(s_t, a_t)$ when the latter is small (e.g., the additive regret is subconstant).

\begin{restatable}{proposition}{propSumProd}
\label{prop:sum-prod}
For any MDP $\M$ and mentor policy $\pi^m$, every algorithm satisfies
\begin{align*}
0 \le&\ \sup_{\bfmu}\ \E\left[1-\exp \left(\sum_{t=1}^T \mu_t(s_t,a_t) -\sum_{t=1}^T \mu_t^m(s_t) \right)\right]\\ \le&\ \sup_{\bfmu}\  \E\left[\prod_{t=1}^T \mu_t^m(s_t) - \prod_{t=1}^T \mu_t(s_t, a_t)\right]\\
\le&\ \sup_{\bfmu}\ \E \left[\sum_{t=1}^T \mu_t^m(s_t) - \sum_{t=1}^T \mu_t(s_t, a_t)\right]
\end{align*}
\end{restatable}


We will need the following lemma for the proof:


\begin{lemma}[Lemma B.3 in \citet{plaut_avoiding_2024}]
\label{lem:pos-prod-bound}
Assume $x_1,\dots,x_T, y_1,\dots,y_T \in [0,1]$ and $x_t \ge y_t$ for all $t \in [T]$. Then
\[
\prod_{t=1}^T x_t - \prod_{t=1}^T y_t \le \sum_{t=1}^T x_t - \sum_{t=1}^T y_t
\]
\end{lemma}


\begin{proof}[Proof of \Cref{prop:sum-prod}]
Let $\U$ be the set of payoff functions satisfying $L$-local generalization; then $\mu_t \in \U$ for all $t \in [T]$ and the suprema range over $\bfmu \in \U^T$.

\textbf{Part 1: the first inequality.} Let $\nu_t(s,a) = 0$ for all $s\in \s, a \in \A, t \in [T]$. We have $\nu_t \in \U$ trivially for all $t \in [T]$, so
\[
\sup_{\bfmu}\ \E\left[1-\exp \left(\sum_{t=1}^T \mu_t(s_t,a_t) -\sum_{t=1}^T \mu_t^m(s_t) \right)\right] \ge  \E\left[1-\exp \left(\sum_{t=1}^T \nu_t(s_t,a_t) -\sum_{t=1}^T \nu_t^m(s_t) \right)\right] = 1 - \exp(0) = 0
\]
\textbf{Part 2: the second inequality.} For each $\mu \in \U$, define another payoff function $f(\mu): \s \times \A \to [0,1]$ by $f(\mu)(s,a) = 1 - \mu^m(s) + \min(\mu^m(s), \mu(s,a))$. Let $f(\mu^m)(s) = f(\mu)(s,\pi^m(s))$ for brevity. Note that $\min(\mu^m(s), \mu(s,\pi^m(s))) = \mu^m(s)$ and thus $f(\mu^m)(s) = 1 $ for all $s \in \s$.

We first claim that for all $\mu \in \U$, $f(\mu) \in \U$. For any $s,s' \in \s$, either $f(\mu)(s,\pi^m(s')) = 1 - \mu^m(s) + \mu^m(s) = 1$, or $f(\mu)(s,\pi^m(s')) = 1 - \mu^m(s) + \mu(s,\pi^m(s'))$. In the former case, we have
\[
|f(\mu^m)(s) - f(\mu)(s,\pi^m(s'))| = |1-1| = 0 \le L \norm{s-s'}
\]
and in the latter case, we have
\begin{align*}
|f(\mu^m)(s) - f(\mu)(s,\pi^m(s'))| =&\ |1 - (1 - \mu^m(s) + \mu(s, \pi^m(s')))|\\
=&\ |\mu^m(s) - \mu(s,\pi^m(s'))|\\
\le&\ L\norm{s-s'}
\end{align*}
with the last step due to $\mu \in \U$. Therefore $f(\mu) \in \U$. Now fix any $s_1,\dots,s_T$ and $a_1,\dots,a_T$. Using the standard inequality $\log(1+x) \le x$ for all $x \in \bbr$,
\begin{align*}
\prod_{t=1}^T f(\mu_t)(s_t, a_t) =&\ \exp \sum_{t=1}^T \log \big(f(\mu_t)(s_t, a_t)\big)\\
=&\ \exp \sum_{t=1}^T \log \big(1 - \mu_t^m(s_t) + \min(\mu_t^m(s_t), \mu_t(s_t,a_t))\big)\\
\le&\ \exp \sum_{t=1}^T \big(- \mu_t^m(s_t) + \min(\mu_t^m(s_t), \mu_t(s_t,a_t))\big)\\
=&\ \exp \left(\sum_{t=1}^T \min(\mu_t^m(s_t), \mu_t(s_t,a_t)) -\sum_{t=1}^T \mu_t^m(s_t) \right)\\
\le&\ \exp \left(\sum_{t=1}^T  \mu_t(s_t,a_t) -\sum_{t=1}^T \mu_t^m(s_t) \right)
% \le&\ \exp \left(\sum_{t=1}^T \mu_t(s_t,a_t) -\sum_{t=1}^T \mu_t^m(s_t) \right)
\end{align*}
Since this holds for any $s_1,\dots,s_T$ and $a_1,\dots,a_T$, we have
\[
\E\left[\prod_{t=1}^T f(\mu_t)(s_t, a_t)\right] \le \E\left[\exp \left(\sum_{t=1}^T  \mu_t(s_t,a_t) -\sum_{t=1}^T \mu_t^m(s_t) \right)\right]
\]
Let $\U_f$ be the image of $\U$ under $f$, i.e., $\mu \in \U_f$ if there exists $\mu' \in \U$ such that $f(\mu') = \mu$. Then $(f(\mu_1),\dots,f(\mu_T)) \in \U_f^T$. Since $f(\mu) \in \U$ for all $\mu \in \U$, we have $\U_f \subseteq \U$, and thus $\U_f^T \subseteq \U^T$. Therefore
\begin{align*}
\sup_{\bfmu \in \U^T}  \E\left[\prod_{t=1}^T \mu_t^m(s_t) - \prod_{t=1}^T \mu_t(s_t, a_t)\right] \ge&\ \sup_{\bfmu \in \U_f^T}  \E\left[\prod_{t=1}^T \mu_t^m(s_t) - \prod_{t=1}^T \mu_t(s_t, a_t)\right]\\
=&\ \sup_{\bfmu \in \U^T} \E\left[\prod_{t=1}^T f(\mu_t^m)(s_t) - \prod_{t=1}^T f(\mu_t)(s_t, a_t)\right]\\
\ge&\ \sup_{\bfmu \in \U^T} \E\left[1 - \exp \left(\sum_{t=1}^T \mu_t(s_t,a_t) -\sum_{t=1}^T \mu_t^m(s_t) \right)\right]
\end{align*}
\textbf{Part 3: the third inequality.} The analysis proceeds similarly, but instead of $f(\mu)(s,a)$, we use $g(\mu)(s,a) = \min(\mu^m(s), \mu(s,a))$. Let $g(\mu^m)(s) = g(\mu)(s,\pi^m(s))$ for brevity and note that $g(\mu^m)(s) = \min(\mu^m(s), \mu(s,\pi^m(s))) = \mu^m(s)$ for all $s \in \s$.

For any $s,s' \in \s$, either $g(\mu)(s,\pi^m(s')) = \mu^m(s)$ or $g(\mu)(s,\pi^m(s')) = \mu(s,\pi^m(s'))$. In the former case, 
\[
|g(\mu^m)(s) - g(\mu)(s,\pi^m(s'))| |\mu^m(s) - \mu^m(s)| = 0 \le L\norm{s-s'}
\]
and in the latter case,
\begin{align*}
|g(\mu^m)(s) - g(\mu)(s,\pi^m(s'))| = |\mu^m(s) - \mu(s,\pi^m(s'))| \le L\norm{s-s'}
\end{align*}
with the last step due to $\mu \in \U$. Thus $g(\mu) \in \U$. Let $\U_g$ be the image of $\U$ under $g$; then $\U_g \subseteq \U$ and $\U_g^T \subseteq \U^T$. Since $\mu_t(s_t,a_t) \ge \min(\mu_t^m(s_t), \mu_t(s_t,a_t))$ for all $t \in [T]$, we have $\prod_{t=1}^T \mu_t(s_t,a_t) \ge \prod_{t=1}^T \min(\mu_t^m(s_t), \mu_t(s_t,a_t))$. Also applying \Cref{lem:pos-prod-bound} with $x_t = \mu_t^m(s_t)$ and $y_t = \min(\mu_t^m(s_t), \mu_t(s_t,a_t))$ gives us
\begin{align*}
\E\left[\prod_{t=1}^T \mu_t^m(s_t) - \prod_{t=1}^T \mu_t(s_t, a_t)\right] \le&\ \E\left[\prod_{t=1}^T \mu_t^m(s_t) - \prod_{t=1}^T \min(\mu_t^m(s_t), \mu_t(s_t,a_t))\right]\\
\le&\ \E\left[\sum_{t=1}^T \mu_t^m(s_t) - \sum_{t=1}^T \min(\mu_t^m(s_t), \mu_t(s_t,a_t))\right]
\end{align*}
Therefore
\begin{align*}
\sup_{ \bfmu \in \U^T}  \E\left[\prod_{t=1}^T \mu_t^m(s_t) - \prod_{t=1}^T \mu_t(s_t, a_t)\right] \le&\ \sup_{ \bfmu \in \U^T}  \E\left[\sum_{t=1}^T \mu_t^m(s_t) - \sum_{t=1}^T \min(\mu_t^m(s), \mu_t(s_t, a_t))\right]\\
=&\ \sup_{ \bfmu \in \U^T}  \E\left[\sum_{t=1}^T g(\mu_t^m)(s_t) - \sum_{t=1}^T g(\mu_t)(s_t, a_t)\right]\\
=&\ \sup_{ \bfmu \in \U_g^T}  \E\left[\sum_{t=1}^T \mu_t^m(s_t) - \sum_{t=1}^T \mu_t(s_t, a_t)\right]\\
\le&\ \sup_{ \bfmu \in \U^T}  \E\left[\sum_{t=1}^T \mu_t^m(s_t) - \sum_{t=1}^T \mu_t(s_t, a_t)\right]\\
\end{align*}
as required.
\end{proof}