\section{Future Works}
% 1. token merge
% 2. ocr 系列 benchmark
In this work, we have conducted an in-depth exploration of a series of issues related to token pruning. These include the position bias problem inherent in methods based on attention scores, the guiding role of linguistic information during token pruning, the importance and redundancy of tokens, as well as certain limitations in the evaluation of token pruning methods.
Looking ahead, we plan to further expand the scope of our research by considering whether token pruning or token merging should be prioritized in the context of token reduction. Additionally, we aim to evaluate and analyze various token reduction methods on more challenging OCR benchmarks, particularly datasets featuring rich-text OCR images.
This future work will not only deepen our understanding of token reduction strategies but also provide valuable insights into their practical applications in complex scenarios.



\section{Algorithms}\label{app:algorithms}
In this section, we present some core algorithms for the methods mentioned in the main text. Vanilla FastV (Algorithm~\ref{alg:fastv_core}) selects tokens with the highest attention scores for retention. Reverse FastV (Algorithm~\ref{alg:reverse_fastv}) modifies this strategy by selecting tokens with the lowest attention scores instead. Window FastV (Algorithm~\ref{alg:window_fastv}) introduces a spatially-aware token selection mechanism by dividing the image tokens into local windows and performing token selection within each window. Finally, Pooling (Algorithm~\ref{alg:pooling}) applies a pooling operation over token grids to retain a structured subset of tokens, ensuring spatial consistency.

\begin{algorithm}[!h]
\caption{Vanilla FastV}
\label{alg:fastv_core}
\begin{algorithmic}[1]
\Require Input token sequence $X \in \mathbb{R}^{L \times d}$, image token range $[s,e]$, retention ratio $r$
\Ensure Compressed sequence representation $X'$

\State Initialize layer parameters $\{W_i\}_{i=1}^N$
\For{layer $l = 1$ \textbf{to} $N$}
    \If{$l = K-1$}
        \State Compute attention matrix $A$
        \State Record global attention scores $\alpha = \text{mean}(A)[s:e]$
    \ElsIf{$l = K$}
        \State Select top-k indices $I = \text{topk}(\alpha, \lfloor (e-s)r \rfloor)$
        \State Construct retention indices $\mathcal{I} = [0:s) \cup I \cup [e:L]$
        \State Compress sequence $X' = X[\mathcal{I},:]$
        \State Update attention mask $M' = M[\mathcal{I},\mathcal{I}]$
    \Else
        \State Regular Transformer computation
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[t]
\caption{Reverse FastV}
\label{alg:reverse_fastv}
\begin{algorithmic}[1]
\Require Input token sequence $X \in \mathbb{R}^{L \times d}$, image token range $[s,e]$, retention ratio $r$
\Ensure Compressed sequence representation $X'$

\State Initialize layer parameters $\{W_i\}_{i=1}^N$
\For{layer $l = 1$ \textbf{to} $N$}
    \If{$l = K-1$}
        \State Compute attention matrix $A$
        \State Record global attention scores $\alpha = \text{mean}(A)[s:e]$
        \State $\alpha = -\alpha$ \Comment{\textcolor{blue}{Difference from Vanilla FastV}}
        
    \ElsIf{$l = K$}
        \State Select top-k indices $I=\text{topk}(-\alpha, \lfloor (e-s)r \rfloor)$ 
        \State Construct retention indices $\mathcal{I} = [0:s) \cup I \cup [e:L]$
        \State Compress sequence $X' = X[\mathcal{I},:]$
        \State Update attention mask $M' = M[\mathcal{I},\mathcal{I}]$
    \Else
        \State Regular Transformer computation
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[t]
\caption{Window FastV}
\label{alg:window_fastv}
\begin{algorithmic}[1]
\Require Input sequence $X \in \mathbb{R}^{L \times d}$, image region $\Omega=[s,e]$, window size $(h,w)$ %, total retention count $T$
\Ensure Compressed sequence representation $X'$

\State Initialize layer parameters $\{W_i\}_{i=1}^N$
\For{layer $l = 1$ \textbf{to} $N$}
    \If{$l = K-1$}
        \State Compute attention matrix $A$
        \State Record global attention scores $\alpha = \text{mean}(A)[s:e]$
    \ElsIf{$l = K$}
        \State Reshape the image region into a 2D grid $\Gamma \in \mathbb{R}^{h\times w}$
        \State Divide the grid into window patches $\{\mathcal{W}_{ij}\}_{i=1,j=1}^{m,n}$, where $\mathcal{W}_{ij} \subset \Gamma$
        % \State Compute retention quota for each window: $\forall \mathcal{W}_{ij},\ k_{ij} = \lfloor T/(mn) \rfloor + \delta_{ij}$ 
        % \Comment{$\sum \delta_{ij} = T\bmod(mn)$}
        
        \For{each window $\mathcal{W}_{ij}$}
            \State Compute local attention scores $A_{ij} = \text{mean}(\alpha[\mathcal{W}_{ij}])$
            \State Select local top-k indices $I_{ij} = \text{topk}(A_{ij}, mn)$
            \State Convert local indices to global coordinates $\mathcal{G}_{ij} = \text{loc2glob}(I_{ij})$
        \EndFor
        \State Aggregate all window indices $\mathcal{I} = \bigcup_{i,j} \mathcal{G}_{ij}$
        \State Construct the retained sequence:
        $
        X' = X\left[[0:s) \cup \mathcal{I} \cup [e:L], :\right]
        $
    \Else
        \State Regular Transformer computation
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[t]
\caption{Pooling}
\label{alg:pooling}
\begin{algorithmic}[1]
\Require Input sequence $X \in \mathbb{R}^{L \times d}$, image region $\Omega=[s,e]$, window size $a \times a$%, pooling mode $\rho$
\Ensure Compressed sequence representation $X'$
\For{layer $l = 1$ \textbf{to} $N$}
    \If{$l = K$}
        \State Extract image tokens: $X_{img} = X[s:e,:]$
        \State Reshape into a 2D grid: $F \in \mathbb{R}^{h \times w \times d}$ \\
        \Comment{Where $h \times w = e-s$}
        \State Perform window pooling:
        $$
        \hat{F} = \text{Pool}(F, a, \rho) \in \mathbb{R}^{(h/a) \times (w/a) \times d}
        $$
        \State Construct index mapping:
        $$
        \mathcal{M} = \{(i,j) \mapsto \mathop{\text{argmax}}\limits_{(p,q) \in \mathcal{W}_{ij}} \|F[p,q,:]\|_1\}
        $$
        \State Build the retained index set:
        $$ \mathcal{I} = \{s + \mathcal{M}(k) | \forall k \in [1, (h/a)(w/a)]\} $$
        \State Generate the compressed sequence:
        $$
        X' = X\left[[0:s) \cup \mathcal{I} \cup [e:L], :\right]
        $$
    \Else
        \State Regular Transformer computation
    \EndIf
\EndFor
\end{algorithmic}
\end{algorithm}







\section{Dataset}\label{app:dataset details}


In this section, we introduce the content of the datasets used, as well as the input and output formats in Table \ref{tab:datasets}.

\begin{table*}[t]
    \centering
    \footnotesize
    \renewcommand{\arraystretch}{1}
    \setlength\tabcolsep{6pt}
    \begin{tabular}{lllll}
        \toprule
        \bf{Type}                                  & \bf{Dataset}                         & \bf{Brief Description}                                     & \bf{Input}                                                        & \bf{Output}                                            \\
        \midrule
        \multirow{10}{1.8cm}{Visual Understanding} & \multirow{1}{*}{VQA$^\text{Text}$}            & \multirow{1}{*}{Rich textual viusal QA}                    & \multirow{1}{*}{Single image and question}          & Question Answer                                        \\
        \cmidrule{2-5}
                                                   & \multirow{1}{*}{VQA V2}              & \multirow{1}{*}{Open-ended viusal perception}              & \multirow{1}{*}{Single image and question}     & Question Answer                                        \\
        \cmidrule{2-5}
                                                   & \multirow{1}{*}{ScienceQA}           & \multirow{1}{*}{Natural and social science QA}             & \multirow{1}{*}{Single image and question}     & Question Answer                                        \\
        \cmidrule{2-5}
                                                   & \multirow{1}{*}{POPE}                & \multirow{1}{*}{Object hallucination evaluation}           & \multirow{1}{*}{Single image and question}     & Question Answer                                        \\
        \cmidrule{2-5}
                                                   & \multirow{1}{*}{GQA}                 & \multirow{1}{*}{Visual scene understanding}                & \multirow{1}{*}{Single image and question}     & Question Answer                                        \\
        \cmidrule{2-5}
                                                   & \multirow{1}{*}{MMBench}             & \multirow{1}{*}{Perception and reasoning tasks}            & \multirow{1}{*}{Single image and question}     & Question Answer                                        \\
        \cmidrule{2-5}
                                                   & \multirow{1}{*}{MME}                 & \multirow{1}{*}{Perceptual ability evaluation}             & \multirow{1}{*}{Single image and question}     & Question Answer                                        \\
        \midrule
        \multirow{2}{1.8cm}{Object Recognition}    & \multirow{2}{1.5cm}{Visual Haystack} & \multirow{2}{*}{Visual need-in-a-haystack}                 & \multirow{2}{3.5cm}{Multiple images, an image phrase and an object phrase}                                                                  & \multirow{2}{2.3cm}{Existence of specified objects}    \\
                                                   &                                      &                                                            &                     &                                                        \\
        \midrule
        \multirow{2}{1.8cm}{Grounding}             & \multirow{2}{*}{RefCOCO}             & \multirow{2}{*}{Phrase object localizing}                  & \multirow{2}{3.5cm}{1 image and referring phrase of an object} & \multirow{2}{2.5cm}{Bounding box of the specified object} \\
                                                   &                                      &                                                            &                                                                   &                                                        \\
        % \midrule
        % \multirow{2}{*}{OCR}                       & \multirow{2}{1.5cm}{OmniDoc- Bench}  & \multirow{2}{*}{Document parsing evaluation}               & \multirow{2}{2.6cm}{Image of a rich-text document}      & \multirow{2}{*}{Recognized text}                       \\
                                                   % &                                      &                                                            &                                                                   &                                                        \\
        % \cmidrule{2-5}
                                                   % & \multirow{1}{*}{OCR-Bench}           & \multirow{1}{*}{Assess the OCR capabilities}               & \multirow{1}{*}{\texttt{[X]} The question is about \texttt{[Z]}.} & \multirow{1}{*}{Recognized text}                       \\
        % \midrule
        % \multirow{2}{1.5cm}{Multi-Turn Dialog}     & \multirow{2}{*}{MMDU}                & \multirow{2}{4cm}{Multi-turn and multi-image conversation} & \multirow{2}{3.5cm}{Multiple images and continuous questions}      & \multirow{2}{2.3cm}{Multi-turn question answers}       \\
        %                                            &                                      &                                                            &                                                                   &                                                        \\
        % \midrule
        % \multirow{3}{*}{Tagging}              &                                     & \texttt{[X1]}: Mike went to Paris.            &                                                                   & organization               \\
        %                                       & NER                                 & \texttt{[X2]}: Paris                          & \texttt{[X1]}\texttt{[X2]} is a \texttt{[Z]} entity.              & location                   \\
        %                                       &                                     &                                               &                                                                   & ...                        \\
        % \midrule
        % \multirow{6}{*}{Text Generation}      & \multirow{3}{*}{Summarization}      & \multirow{3}{*}{Las Vegas police ...}         & \multirow{3}{*}{\texttt{[X]} TL;DR: \texttt{[Z]}}                 & The victim ...             \\
        %                                       &                                     &                                               &                                                                   & A woman ...                \\
        %                                       &                                     &                                               &                                                                   & ...                        \\
        % \cmidrule{2-5}
        %                                       & \multirow{3}{*}{Translation}        & \multirow{3}{*}{Je vous aime.}                & \multirow{3}{*}{French: \texttt{[X]} English: \texttt{[Z]}}       & I love you.                \\
        %                                       &                                     &                                               &                                                                   & I fancy you.               \\
        %                                       &                                     &                                               &                                                                   & ...                        \\
        \bottomrule
    \end{tabular}
    \caption{The datasets we use for benchmarking.}
    \label{tab:datasets}
\end{table*}

