This paper explores unsupervised anomaly detection (AD) using the $k$-Nearest Neighbor (NN) method.
%
The $k$-Nearest Neighbor Anomaly Detection ($k$NNAD) is a simple yet effective method for detecting anomalies in various fields.
%
A key challenge in AD is appropriately quantifying the reliability of detected anomalies.
%
To address this, we formulate $k$NNAD as a statistical hypothesis test and quantify the false detection rate using $p$-values.
%
The main challenge is conducting both detecting and testing AD on the same data, which hinders correct $p$-value calculation. 
%
We address this by introducing \emph{Selective Inference (SI)} and proposing \emph{Statistically Significant $k$NNAD (Stat-$k$NNAD)}.
%
The Stat-$k$NNAD method ensures that detected anomalies are statistically significant with theoretical guarantees.
%
We demonstrate the validity of the Stat-$k$NNAD through experiments on synthetic, benchmark, and industrial datasets.


