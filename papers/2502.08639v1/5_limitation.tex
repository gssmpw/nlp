
\section{Limitations and Conclusions}
Ideally, 3D bounding box can naturally and precisely control the orientation of objects in space. For instance, when we rotate the 3D box of a human, it should produce a video sequence of a human turning around. However, the community currently lacks accurate open-set object pose estimation models. Therefore, we leave this promising functionality as future work. In conclusion, our project stems from the goal of granting users the creation controllability as professional film directors. To this end, we propose CineMaster for highly controllable text-to-video generation. Specifically, we first design a 3D-native workflow that allows users to manipulate objects and camera in an intuitive manner. Then we train a conditional text-to-video diffusion model to synthesize the user-intended videos. We emphasize the importance of adopting projected depth maps as strong visual control signals. Extensive experiments demonstrate that CineMaster achieves controllable and 3D-aware cinematic video generation.

