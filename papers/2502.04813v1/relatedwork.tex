\section{Related works}
\label{sec-related}

Processing data streams comes with inevitable challenges related to~the~volume of~the~data and~its \textit{temporal} nature~\cite{gama2010knowledge}. One of~the~most frequently addressed difficulties of~this data type is~the~data nonstationarity, resulting from \textit{concept drifts}~\cite{webb2016characterizing}. The significance of~recognizing concept changes stems from the~fact that they usually harm the~recognition quality of~methods since the~knowledge generalized in~machine learning models becomes outdated. 

The~primary axis of~the~concept drift taxonomy describes its impact on~the recognition model or, alternatively, the~data distribution shift in~relation to~the~decision boundary~\cite{gama2004learning}. Changes that do not affect the~recognition quality -- and~therefore cannot be recognized when monitoring the~quality of~the~model -- are~referred to~as \textit{virtual}. Meanwhile, those that affect the~decision boundary are~referred to~as \textit{real}~\cite{lobo2020spiking}. It is~worth keeping in~mind that the~potentially insignificant \textit{virtual} changes can be visible in~the~initial stage of~non-sudden \textit{real} concept changes~\cite{komorniczak2024structuring}. The~other axes of~the~concept drift taxonomy consider the~drift dynamics and~its recurrence. The~transition between the~consecutive concepts can be \textit{sudden} -- where one can see a~single time instant after which the~samples come from the~new concept. The~other categories describe slower-paced changes in~the~form of~\textit{gradual} or~\textit{incremental} drifts, in~which one can observe a~period of~concept transition. In~the~\textit{gradual} changes, the~samples in~the~transition period are~sampled from both the~previous and~the~emerging concepts, while in~the~\textit{incremental} changes, they form a~temporary superposition of~the~two transitioning concepts. Finally, regardless of~the~dynamics of~drift, the~concepts that appeared in~the~past may reoccur, which is~typical of~the~problems describing the~phenomena of~cyclic nature~\cite{gunasekara2024recurrent}.

\paragraph{Concept drift detection}

Since concept changes may have a~real effect on~recognition quality, it has become a~standard procedure to~monitor the~state of~a~system in~search for a~concept drift~\cite{sethi2015don}. For this purpose, many solutions have been proposed. The~initial drift detection methods exploited the~fact that concept drift affects the~classification quality. Those methods include the~\textit{Adaptive Windowing}~\cite{bifet2007learning}, which uses varying-width windows to~compare the~frequency of~errors. Methods that monitor the~quality of~a~classification model are~described as \textit{explicit}~\cite{gozuaccik2021concept}. The~primary benefit of~such a~drift detection approach is~the~possibility to~directly act upon a~change by adapting the~classification model to~the~current data. The~use of~\textit{explicit} methods also has some drawbacks. Since their operation is~based on~recognition quality, the~method will not be able to~detect the~\textit{virtual} drifts or~the~initial phases of~real ones that do not yet impact recognition quality. Another disadvantage is~the~reliance on~the~availability of~labels, which, in~the~data streams with high velocity, are~often delayed or~not available entirely~\cite{grzenda2020delayed}.

Another category of~methods monitor characteristics of~data stream processing other than those related to~the~quality of~the~model -- the~\textit{implicit} drift detection methods. Those include both supervised and~unsupervised approaches. The~supervised drift detectors can use labels to~monitor the~quality of~the~data distribution that are~not related to~the~errors made by the~classifier. The~\textit{Centroid Distance Drift Detector}~\cite{klikowski2022concept} is~a~simple yet effective approach that monitors the~class centroids to~detect concept changes. Labels are~also used in~the~\textit{Complexity-based Drift Detector}~\cite{komorniczak2023complexity}, which relies on~the~monitoring of~complexity measures~\cite{lorena2019complex} to~express the~difficulty of~the~classification task. Although the~supervised \textit{implicit} methods offer some independence from the~base classifier, they still rely on~access to~labels.

In the family of \textit{implicit} drift detectors, most of the methods are~\textit{unsupervised}. Those are~especially valuable in~the~context of~the~velocity of~the~data stream -- where the~time of~providing the~labels affects the~moment of~drift detection~\cite{komorniczak2024structuring}. Unsupervised methods can monitor quite a~wide range of~data characteristics, including the~data distribution analysis with hypothesis testing~\cite{sobolewski2013comparable}, or~the~percentage of~outliers measured with the~one-class classifier~\cite{gozuaccik2021concept}. Some interesting unsupervised methods utilize the~classification model but only to~measure label-independent characteristics of~the~underlying classification model. One of~the~most interesting ones of~this type is~the~\textit{Margin Density Drift Detector}~\cite{sethi2015don}, which examines the~distribution of~samples near the~decision boundary.  

All those characteristics considered in~drift detection -- from the~model quality and~its confidence to~the~temporal complexity of~the~classification task -- can be described as metafeatures of~the~data~\cite{komorniczak2024metafeatures}. This was directly addressed in~the~\textit{Meta-Feature-based Concept Evolution Detection} framework~\cite{guo2023meta}, where selected data distribution metrics captured the~statistical metafeatures of~the~data. Metafeatures were also used to~identify the~concept in~the~\textit{Fingerprinting with Combined Supervised and~Unsupervised Meta-Information} (\textsc{ficsum})~\cite{halstead2023combining}, where various metafeatures were used not only to~detect a~concept change but also to~re-identify it in~the~case of~recurrence. Some of~the~metafeatures used in~\textsc{ficsum} were previously used in~the~\textit{Feature Extraction for Explicit Concept Drift Detection}~\cite{cavalcante2016fedd}, which was dedicated to~time series analysis. The~measures included time series autocorrelation, partial autocorrelation, turning point rate, and~statistical measures: variance, skewness, and~kurtosis coefficient. 

An interesting strategy based on~analyzing the~frequency components of~data streams was used in~\textit{Multidimensional Fourier Transform}~\cite{da2017multidimensional}. The~authors extended the~\textit{unidimensional Fourier transform} to~detect changes in~frequencies and~amplitudes seen across many features over time. This strategy differs significantly from the~\textsc{ffm} since the~frequency components are~analyzed over time across specific features, which makes them suitable for time series analysis. In~contrast, the~proposed \textsc{ffm} approach searches for frequency components across the~feature vector characterizing each data sample. The~differences across those frequencies are~later used to~describe the~concepts visible in~the~data stream.

\paragraph{Data stream classification}

The drift detection task remains critical in~the~area of~data stream classification. The~proposed drift detection methods can serve as the~independent component of~a~processing pipeline or~be integrated with a~classifier, forming a~\emph{hybrid method}~\cite{wozniak2013hybrid}, which has become a~standard solution for data stream classification tasks.  Data stream classifiers often employ the~\emph{ensemble learning paradigm}~\cite{krawczyk2017ensemble}, profiting from the~possibility of~continuous modification of~the~ensemble's structure and~the~possibility of~integration with a~drift detection module. According to~the~taxonomy of~ensemble methods for data stream classification, the~\textit{active} ones use a~drift detection module and~directly act upon a~change. The~other category of~\textit{passive} methods incrementally adapts to~the~currently processed data, regardless if the~concept drift occurred or~the~data distribution remained stationary.

Among the~\textit{active} ensemble approaches, one should mention \textsc{adwin}\textit{Bagging}, which used an \textit{Adaptive Windowing} drift detector combined with \textit{online bagging} to~enable the~incremental learning of~classifier pool and~modification of~the~ensemble structure when the~concept drift is~detected~\cite{bifet2009improving}. Most of the methods utilized the~monitoring of~classification accuracy. Meanwhile, there exist ensemble approaches that, similarly to~\textit{implicit} drift detectors, base their detection on~other factors unrelated to~the~classification quality. One such method is~the~\textit{Covariance-signature Concept Selector}~\cite{ksieniewicz2023processing}, which examines the~covariance of~the~features to~detect concept changes and~to~select the~best model for current data distribution. A~similar strategy was used in~the~already mentioned \textsc{ficsum}~\cite{halstead2023combining}, which selects the~classifier dedicated to~the~currently solved task based on~the~gathered meta-information. Such a~selection is~especially valuable when processing the~data streams with recurring concepts, as it offers an opportunity to~use the~previous knowledge instead of~the~incremental adaptation from the~ground up.