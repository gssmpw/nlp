@misc{mazeika2024harmbenchstandardizedevaluationframework,
      title={HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal}, 
      author={Mantas Mazeika and Long Phan and Xuwang Yin and Andy Zou and Zifan Wang and Norman Mu and Elham Sakhaee and Nathaniel Li and Steven Basart and Bo Li and David Forsyth and Dan Hendrycks},
      year={2024},
      eprint={2402.04249},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.04249}, 
}

@misc{chao2024jailbreakingblackboxlarge,
      title={Jailbreaking Black Box Large Language Models in Twenty Queries}, 
      author={Patrick Chao and Alexander Robey and Edgar Dobriban and Hamed Hassani and George J. Pappas and Eric Wong},
      year={2024},
      eprint={2310.08419},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.08419}, 
}


@misc{andriushchenko2024jailbreakingleadingsafetyalignedllms,
      title={Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks}, 
      author={Maksym Andriushchenko and Francesco Croce and Nicolas Flammarion},
      year={2024},
      eprint={2404.02151},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2404.02151}, 
}


@misc{yuksekgonul2024textgradautomaticdifferentiationtext,
      title={TextGrad: Automatic "Differentiation" via Text}, 
      author={Mert Yuksekgonul and Federico Bianchi and Joseph Boen and Sheng Liu and Zhi Huang and Carlos Guestrin and James Zou},
      year={2024},
      eprint={2406.07496},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.07496}, 
}

@INPROCEEDINGS{gww,
  author={Aldous, D. and Vazirani, U.},
  booktitle={Proceedings 35th Annual Symposium on Foundations of Computer Science}, 
  title={"Go with the winners" algorithms}, 
  year={1994},
  volume={},
  number={},
  pages={492-501},
  keywords={Simulated annealing;Polynomials;Analytical models;State-space methods;Algorithm design and analysis;Temperature;Statistics;Computer science;Concrete;Fractals},
  doi={10.1109/SFCS.1994.365742}}

@misc{zou2023universaltransferableadversarialattacks,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and Nicholas Carlini and Milad Nasr and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.15043}, 
}

@misc{hayase2024querybasedadversarialpromptgeneration,
      title={Query-Based Adversarial Prompt Generation}, 
      author={Jonathan Hayase and Ema Borevkovic and Nicholas Carlini and Florian Tramèr and Milad Nasr},
      year={2024},
      eprint={2402.12329},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.12329}, 
}

@misc{mudumbai2024slaveslawlargenumbers,
      title={Slaves to the Law of Large Numbers: An Asymptotic Equipartition Property for Perplexity in Generative Language Models}, 
      author={Raghu Mudumbai and Tyler Bell},
      year={2024},
      eprint={2405.13798},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.13798}, 
}


@book{cover, author = {Cover, Thomas M. and Thomas, Joy A.}, title = {Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing)}, year = {2006}, isbn = {0471241954}, publisher = {Wiley-Interscience}, address = {USA} }
 


@misc{mehrotra2024treeattacksjailbreakingblackbox,
      title={Tree of Attacks: Jailbreaking Black-Box LLMs Automatically}, 
      author={Anay Mehrotra and Manolis Zampetakis and Paul Kassianik and Blaine Nelson and Hyrum Anderson and Yaron Singer and Amin Karbasi},
      year={2024},
      eprint={2312.02119},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.02119}, 
}

@misc{zou2024improvingalignmentrobustnesscircuit,
      title={Improving Alignment and Robustness with Circuit Breakers}, 
      author={Andy Zou and Long Phan and Justin Wang and Derek Duenas and Maxwell Lin and Maksym Andriushchenko and Rowan Wang and Zico Kolter and Matt Fredrikson and Dan Hendrycks},
      year={2024},
      eprint={2406.04313},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.04313}, 
}

@misc{chao2024jailbreakbenchopenrobustnessbenchmark,
      title={JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models}, 
      author={Patrick Chao and Edoardo Debenedetti and Alexander Robey and Maksym Andriushchenko and Francesco Croce and Vikash Sehwag and Edgar Dobriban and Nicolas Flammarion and George J. Pappas and Florian Tramer and Hamed Hassani and Eric Wong},
      year={2024},
      eprint={2404.01318},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2404.01318}, 
}

@misc{dong2024surveyincontextlearning,
      title={A Survey on In-context Learning}, 
      author={Qingxiu Dong and Lei Li and Damai Dai and Ce Zheng and Jingyuan Ma and Rui Li and Heming Xia and Jingjing Xu and Zhiyong Wu and Tianyu Liu and Baobao Chang and Xu Sun and Lei Li and Zhifang Sui},
      year={2024},
      eprint={2301.00234},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2301.00234}, 
}

@misc{liu2023lostmiddlelanguagemodels,
      title={Lost in the Middle: How Language Models Use Long Contexts}, 
      author={Nelson F. Liu and Kevin Lin and John Hewitt and Ashwin Paranjape and Michele Bevilacqua and Fabio Petroni and Percy Liang},
      year={2023},
      eprint={2307.03172},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.03172}, 
}


@misc{anil2022exploringlengthgeneralizationlarge,
      title={Exploring Length Generalization in Large Language Models}, 
      author={Cem Anil and Yuhuai Wu and Anders Andreassen and Aitor Lewkowycz and Vedant Misra and Vinay Ramasesh and Ambrose Slone and Guy Gur-Ari and Ethan Dyer and Behnam Neyshabur},
      year={2022},
      eprint={2207.04901},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2207.04901}, 
}

@misc{touvron2023llama2openfoundation,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={AI@Meta},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09288}, 
}


@article{openai2023gpt4,
  title     = {GPT-4 Technical Report},
  author    = {OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year      = {2023},
  bibSource = {Semantic Scholar https://www.semanticscholar.org/paper/8ca62fdf4c276ea3052dc96dcfd8ee96ca425a48}
}

@misc{jiang2024mixtralexperts,
      title={Mixtral of Experts}, 
      author={Mistral AI},
      year={2024},
      eprint={2401.04088},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.04088}, 
}


@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@misc{dubey2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={AI@Meta},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{zeng2024johnnypersuadellmsjailbreak,
      title={How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs}, 
      author={Yi Zeng and Hongpeng Lin and Jingwen Zhang and Diyi Yang and Ruoxi Jia and Weiyan Shi},
      year={2024},
      eprint={2401.06373},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.06373}, 
}


@misc{pryzant2023automaticpromptoptimizationgradient,
      title={Automatic Prompt Optimization with "Gradient Descent" and Beam Search}, 
      author={Reid Pryzant and Dan Iter and Jerry Li and Yin Tat Lee and Chenguang Zhu and Michael Zeng},
      year={2023},
      eprint={2305.03495},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.03495}, 
}

@misc{hu2024localizedzerothorderpromptoptimization,
      title={Localized Zeroth-Order Prompt Optimization}, 
      author={Wenyang Hu and Yao Shu and Zongmin Yu and Zhaoxuan Wu and Xiangqiang Lin and Zhongxiang Dai and See-Kiong Ng and Bryan Kian Hsiang Low},
      year={2024},
      eprint={2403.02993},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2403.02993}, 
}

@misc{lin2024useinstinctinstructionoptimization,
      title={Use Your INSTINCT: INSTruction optimization for LLMs usIng Neural bandits Coupled with Transformers}, 
      author={Xiaoqiang Lin and Zhaoxuan Wu and Zhongxiang Dai and Wenyang Hu and Yao Shu and See-Kiong Ng and Patrick Jaillet and Bryan Kian Hsiang Low},
      year={2024},
      eprint={2310.02905},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.02905}, 
}

@misc{chen2023instructzeroefficientinstructionoptimization,
      title={InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models}, 
      author={Lichang Chen and Jiuhai Chen and Tom Goldstein and Heng Huang and Tianyi Zhou},
      year={2023},
      eprint={2306.03082},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2306.03082}, 
}

@misc{zhou2023largelanguagemodelshumanlevel,
      title={Large Language Models Are Human-Level Prompt Engineers}, 
      author={Yongchao Zhou and Andrei Ioan Muresanu and Ziwen Han and Keiran Paster and Silviu Pitis and Harris Chan and Jimmy Ba},
      year={2023},
      eprint={2211.01910},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2211.01910}, 
}

@misc{prasad2023gripsgradientfreeeditbasedinstruction,
      title={GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models}, 
      author={Archiki Prasad and Peter Hase and Xiang Zhou and Mohit Bansal},
      year={2023},
      eprint={2203.07281},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.07281}, 
}


@misc{liu2024autodanturbolifelongagentstrategy,
      title={AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs}, 
      author={Xiaogeng Liu and Peiran Li and Edward Suh and Yevgeniy Vorobeychik and Zhuoqing Mao and Somesh Jha and Patrick McDaniel and Huan Sun and Bo Li and Chaowei Xiao},
      year={2024},
      eprint={2410.05295},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2410.05295}, 
}

@misc{openai_system_card_2024,
  title        = {OpenAI o1 System Card},
  author       = {OpenAI},
  year         = {2024},
  month        = {December},
  url          = {https://cdn.openai.com/o1-system-card-20241205.pdf},
}

@misc{souly2024strongrejectjailbreaks,
      title={A StrongREJECT for Empty Jailbreaks}, 
      author={Alexandra Souly and Qingyuan Lu and Dillon Bowen and Tu Trinh and Elvis Hsieh and Sana Pandey and Pieter Abbeel and Justin Svegliato and Scott Emmons and Olivia Watkins and Sam Toyer},
      year={2024},
      eprint={2402.10260},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.10260}, 
}

@misc{alon2023detectinglanguagemodelattacks,
      title={Detecting Language Model Attacks with Perplexity}, 
      author={Gabriel Alon and Michael Kamfonas},
      year={2023},
      eprint={2308.14132},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.14132}, 
}

@misc{robey2024smoothllmdefendinglargelanguage,
      title={SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks}, 
      author={Alexander Robey and Eric Wong and Hamed Hassani and George J. Pappas},
      year={2024},
      eprint={2310.03684},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.03684}, 
}

@misc{liu2024autodangeneratingstealthyjailbreak,
      title={AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models}, 
      author={Xiaogeng Liu and Nan Xu and Muhao Chen and Chaowei Xiao},
      year={2024},
      eprint={2310.04451},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.04451}, 
}


@misc{samvelyan2024rainbowteamingopenendedgeneration,
      title={Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts}, 
      author={Mikayel Samvelyan and Sharath Chandra Raparthy and Andrei Lupu and Eric Hambro and Aram H. Markosyan and Manish Bhatt and Yuning Mao and Minqi Jiang and Jack Parker-Holder and Jakob Foerster and Tim Rocktäschel and Roberta Raileanu},
      year={2024},
      eprint={2402.16822},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.16822}, 
}

@misc{perez2022redteaminglanguagemodels,
      title={Red Teaming Language Models with Language Models}, 
      author={Ethan Perez and Saffron Huang and Francis Song and Trevor Cai and Roman Ring and John Aslanides and Amelia Glaese and Nat McAleese and Geoffrey Irving},
      year={2022},
      eprint={2202.03286},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2202.03286}, 
}

@misc{ge2023martimprovingllmsafety,
      title={MART: Improving LLM Safety with Multi-round Automatic Red-Teaming}, 
      author={Suyu Ge and Chunting Zhou and Rui Hou and Madian Khabsa and Yi-Chia Wang and Qifan Wang and Jiawei Han and Yuning Mao},
      year={2023},
      eprint={2311.07689},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.07689}, 
}

@misc{wen2023hardpromptseasygradientbased,
      title={Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery}, 
      author={Yuxin Wen and Neel Jain and John Kirchenbauer and Micah Goldblum and Jonas Geiping and Tom Goldstein},
      year={2023},
      eprint={2302.03668},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2302.03668}, 
}

@misc{shin2020autopromptelicitingknowledgelanguage,
      title={AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts}, 
      author={Taylor Shin and Yasaman Razeghi and Robert L. Logan IV and Eric Wallace and Sameer Singh},
      year={2020},
      eprint={2010.15980},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2010.15980}, 
}

@misc{anthropic2024claude3,
  author       = {Anthropic},
  title        = {Model Card for Claude 3},
  year         = {2024},
  howpublished = {\url{https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf}},
}

@misc{sheshadri2024latentadversarialtrainingimproves,
      title={Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs}, 
      author={Abhay Sheshadri and Aidan Ewart and Phillip Guo and Aengus Lynch and Cindy Wu and Vivek Hebbar and Henry Sleight and Asa Cooper Stickland and Ethan Perez and Dylan Hadfield-Menell and Stephen Casper},
      year={2024},
      eprint={2407.15549},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.15549}, 
}

@misc{xhonneux2024efficientadversarialtrainingllms,
      title={Efficient Adversarial Training in LLMs with Continuous Attacks}, 
      author={Sophie Xhonneux and Alessandro Sordoni and Stephan Günnemann and Gauthier Gidel and Leo Schwinn},
      year={2024},
      eprint={2405.15589},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.15589}, 
}

@misc{paulus2024advprompterfastadaptiveadversarial,
      title={AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs}, 
      author={Anselm Paulus and Arman Zharmagambetov and Chuan Guo and Brandon Amos and Yuandong Tian},
      year={2024},
      eprint={2404.16873},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2404.16873}, 
}

@misc{ChatGPTDAN2024,
  title        = {ChatGPT\_DAN: A repository related to ChatGPT's DAN (Do Anything Now) behavior},
  year         = {2024},
  howpublished = {\url{https://github.com/0xk1h0/ChatGPT_DAN}},
}

@misc{lapid2024opensesameuniversalblack,
      title={Open Sesame! Universal Black Box Jailbreaking of Large Language Models}, 
      author={Raz Lapid and Ron Langberg and Moshe Sipper},
      year={2024},
      eprint={2309.01446},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.01446}, 
}


@misc{geminiteam2024gemini15unlockingmultimodal,
      title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context}, 
      author={Gemini Team, Google},
      year={2024},
      eprint={2403.05530},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.05530}, 
}

@misc{inan2023llamaguardllmbasedinputoutput,
      title={Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations}, 
      author={Hakan Inan and Kartikeya Upasani and Jianfeng Chi and Rashi Rungta and Krithika Iyer and Yuning Mao and Michael Tontchev and Qing Hu and Brian Fuller and Davide Testuggine and Madian Khabsa},
      year={2023},
      eprint={2312.06674},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.06674}, 
}

@misc{rebedea2023nemoguardrailstoolkitcontrollable,
      title={NeMo Guardrails: A Toolkit for Controllable and Safe LLM Applications with Programmable Rails}, 
      author={Traian Rebedea and Razvan Dinu and Makesh Sreedhar and Christopher Parisien and Jonathan Cohen},
      year={2023},
      eprint={2310.10501},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.10501}, 
}

@misc{yuan2024rigorllmresilientguardrailslarge,
      title={RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content}, 
      author={Zhuowen Yuan and Zidi Xiong and Yi Zeng and Ning Yu and Ruoxi Jia and Dawn Song and Bo Li},
      year={2024},
      eprint={2403.13031},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2403.13031}, 
}

@misc{christiano2023deepreinforcementlearninghuman,
      title={Deep reinforcement learning from human preferences}, 
      author={Paul Christiano and Jan Leike and Tom B. Brown and Miljan Martic and Shane Legg and Dario Amodei},
      year={2023},
      eprint={1706.03741},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1706.03741}, 
}

@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@misc{rafailov2024directpreferenceoptimizationlanguage,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2024},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.18290}, 
}

@misc{grayswan_single_turn_harmful_outputs,
  title = {Single-Turn Harmful Outputs Leaderboard},
    author={Gray Swan},
  howpublished = {\url{https://app.grayswan.ai/arena/leaderboard/single-turn-harmful-outputs}},
}

@misc{hendrycks2021measuringmathematicalproblemsolving,
      title={Measuring Mathematical Problem Solving With the MATH Dataset}, 
      author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2103.03874},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2103.03874}, 
}

@misc{cobbe2021trainingverifierssolvemath,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      year={2021},
      eprint={2110.14168},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.14168}, 
}

@misc{uesato2022solvingmathwordproblems,
      title={Solving math word problems with process- and outcome-based feedback}, 
      author={Jonathan Uesato and Nate Kushman and Ramana Kumar and Francis Song and Noah Siegel and Lisa Wang and Antonia Creswell and Geoffrey Irving and Irina Higgins},
      year={2022},
      eprint={2211.14275},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2211.14275}, 
}

@misc{lightman2023letsverifystepstep,
      title={Let's Verify Step by Step}, 
      author={Hunter Lightman and Vineet Kosaraju and Yura Burda and Harri Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
      year={2023},
      eprint={2305.20050},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.20050}, 
}

@misc{yu2024ovmoutcomesupervisedvaluemodels,
      title={OVM, Outcome-supervised Value Models for Planning in Mathematical Reasoning}, 
      author={Fei Yu and Anningzhe Gao and Benyou Wang},
      year={2024},
      eprint={2311.09724},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2311.09724}, 
}

@misc{wang2024mathshepherdverifyreinforcellms,
      title={Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations}, 
      author={Peiyi Wang and Lei Li and Zhihong Shao and R. X. Xu and Damai Dai and Yifei Li and Deli Chen and Y. Wu and Zhifang Sui},
      year={2024},
      eprint={2312.08935},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2312.08935}, 
}

@misc{madaan2023selfrefineiterativerefinementselffeedback,
      title={Self-Refine: Iterative Refinement with Self-Feedback}, 
      author={Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Shashank Gupta and Bodhisattwa Prasad Majumder and Katherine Hermann and Sean Welleck and Amir Yazdanbakhsh and Peter Clark},
      year={2023},
      eprint={2303.17651},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.17651}, 
}

@misc{qu2024recursiveintrospectionteachinglanguage,
      title={Recursive Introspection: Teaching Language Model Agents How to Self-Improve}, 
      author={Yuxiao Qu and Tianjun Zhang and Naman Garg and Aviral Kumar},
      year={2024},
      eprint={2407.18219},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.18219}, 
}


@misc{snell2024scalingllmtesttimecompute,
      title={Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters}, 
      author={Charlie Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar},
      year={2024},
      eprint={2408.03314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.03314}, 
}

@misc{openai2024learning,
  title        = {Learning to Reason with LLMs},
  author       = {OpenAI},
  year         = 2024,
  month        = sep,
  url          = {https://openai.com/index/learning-to-reason-with-llms/},
}

@misc{gandhi2024streamsearchsoslearning,
      title={Stream of Search (SoS): Learning to Search in Language}, 
      author={Kanishk Gandhi and Denise Lee and Gabriel Grand and Muxin Liu and Winson Cheng and Archit Sharma and Noah D. Goodman},
      year={2024},
      eprint={2404.03683},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.03683}, 
}


@misc{nye2021workscratchpadsintermediatecomputation,
      title={Show Your Work: Scratchpads for Intermediate Computation with Language Models}, 
      author={Maxwell Nye and Anders Johan Andreassen and Guy Gur-Ari and Henryk Michalewski and Jacob Austin and David Bieber and David Dohan and Aitor Lewkowycz and Maarten Bosma and David Luan and Charles Sutton and Augustus Odena},
      year={2021},
      eprint={2112.00114},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2112.00114}, 
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}


@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@misc{li2023makinglargelanguagemodels,
      title={Making Large Language Models Better Reasoners with Step-Aware Verifier}, 
      author={Yifei Li and Zeqi Lin and Shizhuo Zhang and Qiang Fu and Bei Chen and Jian-Guang Lou and Weizhu Chen},
      year={2023},
      eprint={2206.02336},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.02336}, 
}

@misc{xie2024montecarlotreesearch,
      title={Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning}, 
      author={Yuxi Xie and Anirudh Goyal and Wenyue Zheng and Min-Yen Kan and Timothy P. Lillicrap and Kenji Kawaguchi and Michael Shieh},
      year={2024},
      eprint={2405.00451},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.00451}, 
}

@misc{together_ai,
  author       = {{Together AI}},
  title        = {{Together AI - Empowering Human Potential with AI}},
  howpublished = {\url{https://www.together.ai}},
}

@article{liu2023autodan,
  title={Autodan: Generating stealthy jailbreak prompts on aligned large language models},
  author={Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2310.04451},
  year={2023}
}

@article{xu2023cognitive,
  title={Cognitive overload: Jailbreaking large language models with overloaded logical thinking},
  author={Xu, Nan and Wang, Fei and Zhou, Ben and Li, Bang Zheng and Xiao, Chaowei and Chen, Muhao},
  journal={arXiv preprint arXiv:2311.09827},
  year={2023}
}

@misc{zheng2024criticcotboostingreasoningabilities,
      title={Critic-CoT: Boosting the reasoning abilities of large language model via Chain-of-thoughts Critic}, 
      author={Xin Zheng and Jie Lou and Boxi Cao and Xueru Wen and Yuqiu Ji and Hongyu Lin and Yaojie Lu and Xianpei Han and Debing Zhang and Le Sun},
      year={2024},
      eprint={2408.16326},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.16326}, 
}

@misc{xiang20252reasoningllmslearning,
      title={Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought}, 
      author={Violet Xiang and Charlie Snell and Kanishk Gandhi and Alon Albalak and Anikait Singh and Chase Blagden and Duy Phung and Rafael Rafailov and Nathan Lile and Dakota Mahan and Louis Castricato and Jan-Philipp Franken and Nick Haber and Chelsea Finn},
      year={2025},
      eprint={2501.04682},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2501.04682}, 
}

@misc{wang2024strategicchainofthoughtguidingaccurate,
      title={Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation}, 
      author={Yu Wang and Shiwan Zhao and Zhihu Wang and Heyuan Huang and Ming Fan and Yubo Zhang and Zhixing Wang and Haijun Wang and Ting Liu},
      year={2024},
      eprint={2409.03271},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2409.03271}, 
}

@article{RomeraParedes2023MathematicalDF,
  title={Mathematical discoveries from program search with large language models},
  author={Bernardino Romera-Paredes and Mohammadamin Barekatain and Alexander Novikov and Matej Balog and M Pawan Kumar and Emilien Dupont and Francisco J. R. Ruiz and Jordan S. Ellenberg and Pengming Wang and Omar Fawzi and Pushmeet Kohli and Alhussein Fawzi and Josh Grochow and Andrea Lodi and Jean-Baptiste Mouret and Talia Ringer and Tao Yu},
  journal={Nature},
  year={2023},
  volume={625},
  pages={468 - 475},
  url={https://api.semanticscholar.org/CorpusID:266223700}
}

@misc{ahn2024largelanguagemodelsmathematical,
      title={Large Language Models for Mathematical Reasoning: Progresses and Challenges}, 
      author={Janice Ahn and Rishu Verma and Renze Lou and Di Liu and Rui Zhang and Wenpeng Yin},
      year={2024},
      eprint={2402.00157},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.00157}, 
}

@misc{shao2024deepseekmathpushinglimitsmathematical,
      title={DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}, 
      author={Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Xiao Bi and Haowei Zhang and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
      year={2024},
      eprint={2402.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.03300}, 
}

@misc{rein2023gpqagraduatelevelgoogleproofqa,
      title={GPQA: A Graduate-Level Google-Proof Q\&A Benchmark}, 
      author={David Rein and Betty Li Hou and Asa Cooper Stickland and Jackson Petty and Richard Yuanzhe Pang and Julien Dirani and Julian Michael and Samuel R. Bowman},
      year={2023},
      eprint={2311.12022},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2311.12022}, 
}

@misc{liao2024amplegcglearninguniversaltransferable,
      title={AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs}, 
      author={Zeyi Liao and Huan Sun},
      year={2024},
      eprint={2404.07921},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.07921}, 
}

@misc{jia2024improvedtechniquesoptimizationbasedjailbreaking,
      title={Improved Techniques for Optimization-Based Jailbreaking on Large Language Models}, 
      author={Xiaojun Jia and Tianyu Pang and Chao Du and Yihao Huang and Jindong Gu and Yang Liu and Xiaochun Cao and Min Lin},
      year={2024},
      eprint={2405.21018},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.21018}, 
}

@misc{zhang2024smalllanguagemodelsneed,
      title={Small Language Models Need Strong Verifiers to Self-Correct Reasoning}, 
      author={Yunxiang Zhang and Muhammad Khalifa and Lajanugen Logeswaran and Jaekyeom Kim and Moontae Lee and Honglak Lee and Lu Wang},
      year={2024},
      eprint={2404.17140},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.17140}, 
}

@misc{zhang2024generativeverifiersrewardmodeling,
      title={Generative Verifiers: Reward Modeling as Next-Token Prediction}, 
      author={Lunjun Zhang and Arian Hosseini and Hritik Bansal and Mehran Kazemi and Aviral Kumar and Rishabh Agarwal},
      year={2024},
      eprint={2408.15240},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.15240}, 
}

@misc{stechly2024selfverificationlimitationslargelanguage,
      title={On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks}, 
      author={Kaya Stechly and Karthik Valmeekam and Subbarao Kambhampati},
      year={2024},
      eprint={2402.08115},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2402.08115}, 
}

@ARTICLE{Guan2024-sv,
  title         = "Deliberative Alignment: Reasoning enables safer language
                   models",
  author        = "Guan, Melody Y and Joglekar, Manas and Wallace, Eric and
                   Jain, Saachi and Barak, Boaz and Helyar, Alec and Dias,
                   Rachel and Vallone, Andrea and Ren, Hongyu and Wei, Jason and
                   Chung, Hyung Won and Toyer, Sam and Heidecke, Johannes and
                   Beutel, Alex and Glaese, Amelia",
  journal       = "arXiv [cs.CL]",
  abstract      = "As large-scale language models increasingly impact
                   safety-critical domains, ensuring their reliable adherence to
                   well-defined principles remains a fundamental challenge. We
                   introduce Deliberative Alignment, a new paradigm that
                   directly teaches the model safety specifications and trains
                   it to explicitly recall and accurately reason over the
                   specifications before answering. We used this approach to
                   align OpenAI's o-series models, and achieved highly precise
                   adherence to OpenAI's safety policies, without requiring
                   human-written chain-of-thoughts or answers. Deliberative
                   Alignment pushes the Pareto frontier by simultaneously
                   increasing robustness to jailbreaks while decreasing
                   overrefusal rates, and also improves out-of-distribution
                   generalization. We demonstrate that reasoning over explicitly
                   specified policies enables more scalable, trustworthy, and
                   interpretable alignment.",
  month         =  dec,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Hughes2024-te,
  title         = "Best-of-{N} Jailbreaking",
  author        = "Hughes, John and Price, Sara and Lynch, Aengus and Schaeffer,
                   Rylan and Barez, Fazl and Koyejo, Sanmi and Sleight, Henry
                   and Jones, Erik and Perez, Ethan and Sharma, Mrinank",
  journal       = "arXiv [cs.CL]",
  abstract      = "We introduce Best-of-N (BoN) Jailbreaking, a simple black-box
                   algorithm that jailbreaks frontier AI systems across
                   modalities. BoN Jailbreaking works by repeatedly sampling
                   variations of a prompt with a combination of augmentations -
                   such as random shuffling or capitalization for textual
                   prompts - until a harmful response is elicited. We find that
                   BoN Jailbreaking achieves high attack success rates (ASRs) on
                   closed-source language models, such as 89\% on GPT-4o and
                   78\% on Claude 3.5 Sonnet when sampling 10,000 augmented
                   prompts. Further, it is similarly effective at circumventing
                   state-of-the-art open-source defenses like circuit breakers.
                   BoN also seamlessly extends to other modalities: it
                   jailbreaks vision language models (VLMs) such as GPT-4o and
                   audio language models (ALMs) like Gemini 1.5 Pro, using
                   modality-specific augmentations. BoN reliably improves when
                   we sample more augmented prompts. Across all modalities, ASR,
                   as a function of the number of samples (N), empirically
                   follows power-law-like behavior for many orders of magnitude.
                   BoN Jailbreaking can also be composed with other black-box
                   algorithms for even more effective attacks - combining BoN
                   with an optimized prefix attack achieves up to a 35\%
                   increase in ASR. Overall, our work indicates that, despite
                   their capability, language models are sensitive to seemingly
                   innocuous changes to inputs, which attackers can exploit
                   across modalities.",
  month         =  dec,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}



@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}


@misc{sadasivan2024fastadversarialattackslanguage,
      title={Fast Adversarial Attacks on Language Models In One GPU Minute}, 
      author={Vinu Sankar Sadasivan and Shoumik Saha and Gaurang Sriramanan and Priyatham Kattakinda and Atoosa Chegini and Soheil Feizi},
      year={2024},
      eprint={2402.15570},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2402.15570}, 
}

@misc{beetham2024liarleveragingalignmentbestofn,
      title={LIAR: Leveraging Alignment (Best-of-N) to Jailbreak LLMs in Seconds}, 
      author={James Beetham and Souradip Chakraborty and Mengdi Wang and Furong Huang and Amrit Singh Bedi and Mubarak Shah},
      year={2024},
      eprint={2412.05232},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.05232}, 
}


@misc{wei2023jailbrokendoesllmsafety,
      title={Jailbroken: How Does LLM Safety Training Fail?}, 
      author={Alexander Wei and Nika Haghtalab and Jacob Steinhardt},
      year={2023},
      eprint={2307.02483},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2307.02483}, 
}


@misc{andriushchenko2024agentharmbenchmarkmeasuringharmfulness,
      title={AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents}, 
      author={Maksym Andriushchenko and Alexandra Souly and Mateusz Dziemian and Derek Duenas and Maxwell Lin and Justin Wang and Dan Hendrycks and Andy Zou and Zico Kolter and Matt Fredrikson and Eric Winsor and Jerome Wynne and Yarin Gal and Xander Davies},
      year={2024},
      eprint={2410.09024},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.09024}, 
}


@misc{liang2023codepolicieslanguagemodel,
      title={Code as Policies: Language Model Programs for Embodied Control}, 
      author={Jacky Liang and Wenlong Huang and Fei Xia and Peng Xu and Karol Hausman and Brian Ichter and Pete Florence and Andy Zeng},
      year={2023},
      eprint={2209.07753},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2209.07753}, 
}


@misc{karamcheti2023languagedrivenrepresentationlearningrobotics,
      title={Language-Driven Representation Learning for Robotics}, 
      author={Siddharth Karamcheti and Suraj Nair and Annie S. Chen and Thomas Kollar and Chelsea Finn and Dorsa Sadigh and Percy Liang},
      year={2023},
      eprint={2302.12766},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2302.12766}, 
}


@ARTICLE{10500490,
  author={Vemprala, Sai H. and Bonatti, Rogerio and Bucker, Arthur and Kapoor, Ashish},
  journal={IEEE Access}, 
  title={ChatGPT for Robotics: Design Principles and Model Abilities}, 
  year={2024},
  volume={12},
  number={},
  pages={55682-55696},
  keywords={Robots;Chatbots;Task analysis;Codes;Cognition;Large language models;Open systems;Artificial intelligence;Large language models;robotics;language understanding;code generation;perception},
  doi={10.1109/ACCESS.2024.3387941}}


@misc{robey2024jailbreakingllmcontrolledrobots,
      title={Jailbreaking LLM-Controlled Robots}, 
      author={Alexander Robey and Zachary Ravichandran and Vijay Kumar and Hamed Hassani and George J. Pappas},
      year={2024},
      eprint={2410.13691},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2410.13691}, 
}

@misc{wu2024dissectingadversarialrobustnessmultimodal,
      title={Dissecting Adversarial Robustness of Multimodal LM Agents}, 
      author={Chen Henry Wu and Rishi Shah and Jing Yu Koh and Ruslan Salakhutdinov and Daniel Fried and Aditi Raghunathan},
      year={2024},
      eprint={2406.12814},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.12814}, 
}

@misc{reuel2024openproblemstechnicalai,
      title={Open Problems in Technical AI Governance}, 
      author={Anka Reuel and Ben Bucknall and Stephen Casper and Tim Fist and Lisa Soder and Onni Aarne and Lewis Hammond and Lujain Ibrahim and Alan Chan and Peter Wills and Markus Anderljung and Ben Garfinkel and Lennart Heim and Andrew Trask and Gabriel Mukobi and Rylan Schaeffer and Mauricio Baker and Sara Hooker and Irene Solaiman and Alexandra Sasha Luccioni and Nitarshan Rajkumar and Nicolas Moës and Jeffrey Ladish and Neel Guha and Jessica Newman and Yoshua Bengio and Tobin South and Alex Pentland and Sanmi Koyejo and Mykel J. Kochenderfer and Robert Trager},
      year={2024},
      eprint={2407.14981},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2407.14981}, 
}