@misc{ChatGPTDAN2024,
  title        = {ChatGPT\_DAN: A repository related to ChatGPT's DAN (Do Anything Now) behavior},
  year         = {2024},
  howpublished = {\url{https://github.com/0xk1h0/ChatGPT_DAN}},
}

@ARTICLE{Guan2024-sv,
  title         = "Deliberative Alignment: Reasoning enables safer language
                   models",
  author        = "Guan, Melody Y and Joglekar, Manas and Wallace, Eric and
                   Jain, Saachi and Barak, Boaz and Helyar, Alec and Dias,
                   Rachel and Vallone, Andrea and Ren, Hongyu and Wei, Jason and
                   Chung, Hyung Won and Toyer, Sam and Heidecke, Johannes and
                   Beutel, Alex and Glaese, Amelia",
  journal       = "arXiv [cs.CL]",
  abstract      = "As large-scale language models increasingly impact
                   safety-critical domains, ensuring their reliable adherence to
                   well-defined principles remains a fundamental challenge. We
                   introduce Deliberative Alignment, a new paradigm that
                   directly teaches the model safety specifications and trains
                   it to explicitly recall and accurately reason over the
                   specifications before answering. We used this approach to
                   align OpenAI's o-series models, and achieved highly precise
                   adherence to OpenAI's safety policies, without requiring
                   human-written chain-of-thoughts or answers. Deliberative
                   Alignment pushes the Pareto frontier by simultaneously
                   increasing robustness to jailbreaks while decreasing
                   overrefusal rates, and also improves out-of-distribution
                   generalization. We demonstrate that reasoning over explicitly
                   specified policies enables more scalable, trustworthy, and
                   interpretable alignment.",
  month         =  dec,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Hughes2024-te,
  title         = "Best-of-{N} Jailbreaking",
  author        = "Hughes, John and Price, Sara and Lynch, Aengus and Schaeffer,
                   Rylan and Barez, Fazl and Koyejo, Sanmi and Sleight, Henry
                   and Jones, Erik and Perez, Ethan and Sharma, Mrinank",
  journal       = "arXiv [cs.CL]",
  abstract      = "We introduce Best-of-N (BoN) Jailbreaking, a simple black-box
                   algorithm that jailbreaks frontier AI systems across
                   modalities. BoN Jailbreaking works by repeatedly sampling
                   variations of a prompt with a combination of augmentations -
                   such as random shuffling or capitalization for textual
                   prompts - until a harmful response is elicited. We find that
                   BoN Jailbreaking achieves high attack success rates (ASRs) on
                   closed-source language models, such as 89\% on GPT-4o and
                   78\% on Claude 3.5 Sonnet when sampling 10,000 augmented
                   prompts. Further, it is similarly effective at circumventing
                   state-of-the-art open-source defenses like circuit breakers.
                   BoN also seamlessly extends to other modalities: it
                   jailbreaks vision language models (VLMs) such as GPT-4o and
                   audio language models (ALMs) like Gemini 1.5 Pro, using
                   modality-specific augmentations. BoN reliably improves when
                   we sample more augmented prompts. Across all modalities, ASR,
                   as a function of the number of samples (N), empirically
                   follows power-law-like behavior for many orders of magnitude.
                   BoN Jailbreaking can also be composed with other black-box
                   algorithms for even more effective attacks - combining BoN
                   with an optimized prefix attack achieves up to a 35\%
                   increase in ASR. Overall, our work indicates that, despite
                   their capability, language models are sensitive to seemingly
                   innocuous changes to inputs, which attackers can exploit
                   across modalities.",
  month         =  dec,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@article{RomeraParedes2023MathematicalDF,
  title={Mathematical discoveries from program search with large language models},
  author={Bernardino Romera-Paredes and Mohammadamin Barekatain and Alexander Novikov and Matej Balog and M Pawan Kumar and Emilien Dupont and Francisco J. R. Ruiz and Jordan S. Ellenberg and Pengming Wang and Omar Fawzi and Pushmeet Kohli and Alhussein Fawzi and Josh Grochow and Andrea Lodi and Jean-Baptiste Mouret and Talia Ringer and Tao Yu},
  journal={Nature},
  year={2023},
  volume={625},
  pages={468 - 475},
  url={https://api.semanticscholar.org/CorpusID:266223700}
}

@misc{ahn2024largelanguagemodelsmathematical,
      title={Large Language Models for Mathematical Reasoning: Progresses and Challenges}, 
      author={Janice Ahn and Rishu Verma and Renze Lou and Di Liu and Rui Zhang and Wenpeng Yin},
      year={2024},
      eprint={2402.00157},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.00157}, 
}

@misc{alon2023detectinglanguagemodelattacks,
      title={Detecting Language Model Attacks with Perplexity}, 
      author={Gabriel Alon and Michael Kamfonas},
      year={2023},
      eprint={2308.14132},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.14132}, 
}

@misc{andriushchenko2024jailbreakingleadingsafetyalignedllms,
      title={Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks}, 
      author={Maksym Andriushchenko and Francesco Croce and Nicolas Flammarion},
      year={2024},
      eprint={2404.02151},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2404.02151}, 
}

@misc{beetham2024liarleveragingalignmentbestofn,
      title={LIAR: Leveraging Alignment (Best-of-N) to Jailbreak LLMs in Seconds}, 
      author={James Beetham and Souradip Chakraborty and Mengdi Wang and Furong Huang and Amrit Singh Bedi and Mubarak Shah},
      year={2024},
      eprint={2412.05232},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.05232}, 
}

@misc{chao2024jailbreakingblackboxlarge,
      title={Jailbreaking Black Box Large Language Models in Twenty Queries}, 
      author={Patrick Chao and Alexander Robey and Edgar Dobriban and Hamed Hassani and George J. Pappas and Eric Wong},
      year={2024},
      eprint={2310.08419},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.08419}, 
}

@misc{cobbe2021trainingverifierssolvemath,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      year={2021},
      eprint={2110.14168},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.14168}, 
}

@misc{gandhi2024streamsearchsoslearning,
      title={Stream of Search (SoS): Learning to Search in Language}, 
      author={Kanishk Gandhi and Denise Lee and Gabriel Grand and Muxin Liu and Winson Cheng and Archit Sharma and Noah D. Goodman},
      year={2024},
      eprint={2404.03683},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.03683}, 
}

@misc{ge2023martimprovingllmsafety,
      title={MART: Improving LLM Safety with Multi-round Automatic Red-Teaming}, 
      author={Suyu Ge and Chunting Zhou and Rui Hou and Madian Khabsa and Yi-Chia Wang and Qifan Wang and Jiawei Han and Yuning Mao},
      year={2023},
      eprint={2311.07689},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.07689}, 
}

@misc{hayase2024querybasedadversarialpromptgeneration,
      title={Query-Based Adversarial Prompt Generation}, 
      author={Jonathan Hayase and Ema Borevkovic and Nicholas Carlini and Florian Tramèr and Milad Nasr},
      year={2024},
      eprint={2402.12329},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.12329}, 
}

@misc{hendrycks2021measuringmathematicalproblemsolving,
      title={Measuring Mathematical Problem Solving With the MATH Dataset}, 
      author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2103.03874},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2103.03874}, 
}

@misc{jia2024improvedtechniquesoptimizationbasedjailbreaking,
      title={Improved Techniques for Optimization-Based Jailbreaking on Large Language Models}, 
      author={Xiaojun Jia and Tianyu Pang and Chao Du and Yihao Huang and Jindong Gu and Yang Liu and Xiaochun Cao and Min Lin},
      year={2024},
      eprint={2405.21018},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.21018}, 
}

@misc{lapid2024opensesameuniversalblack,
      title={Open Sesame! Universal Black Box Jailbreaking of Large Language Models}, 
      author={Raz Lapid and Ron Langberg and Moshe Sipper},
      year={2024},
      eprint={2309.01446},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.01446}, 
}

@misc{liao2024amplegcglearninguniversaltransferable,
      title={AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs}, 
      author={Zeyi Liao and Huan Sun},
      year={2024},
      eprint={2404.07921},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.07921}, 
}

@misc{lightman2023letsverifystepstep,
      title={Let's Verify Step by Step}, 
      author={Hunter Lightman and Vineet Kosaraju and Yura Burda and Harri Edwards and Bowen Baker and Teddy Lee and Jan Leike and John Schulman and Ilya Sutskever and Karl Cobbe},
      year={2023},
      eprint={2305.20050},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.20050}, 
}

@misc{liu2024autodangeneratingstealthyjailbreak,
      title={AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models}, 
      author={Xiaogeng Liu and Nan Xu and Muhao Chen and Chaowei Xiao},
      year={2024},
      eprint={2310.04451},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.04451}, 
}

@misc{liu2024autodanturbolifelongagentstrategy,
      title={AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs}, 
      author={Xiaogeng Liu and Peiran Li and Edward Suh and Yevgeniy Vorobeychik and Zhuoqing Mao and Somesh Jha and Patrick McDaniel and Huan Sun and Bo Li and Chaowei Xiao},
      year={2024},
      eprint={2410.05295},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2410.05295}, 
}

@misc{mehrotra2024treeattacksjailbreakingblackbox,
      title={Tree of Attacks: Jailbreaking Black-Box LLMs Automatically}, 
      author={Anay Mehrotra and Manolis Zampetakis and Paul Kassianik and Blaine Nelson and Hyrum Anderson and Yaron Singer and Amin Karbasi},
      year={2024},
      eprint={2312.02119},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.02119}, 
}

@misc{nye2021workscratchpadsintermediatecomputation,
      title={Show Your Work: Scratchpads for Intermediate Computation with Language Models}, 
      author={Maxwell Nye and Anders Johan Andreassen and Guy Gur-Ari and Henryk Michalewski and Jacob Austin and David Bieber and David Dohan and Aitor Lewkowycz and Maarten Bosma and David Luan and Charles Sutton and Augustus Odena},
      year={2021},
      eprint={2112.00114},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2112.00114}, 
}

@misc{openai2024learning,
  title        = {Learning to Reason with LLMs},
  author       = {OpenAI},
  year         = 2024,
  month        = sep,
  url          = {https://openai.com/index/learning-to-reason-with-llms/},
}

@misc{openai_system_card_2024,
  title        = {OpenAI o1 System Card},
  author       = {OpenAI},
  year         = {2024},
  month        = {December},
  url          = {https://cdn.openai.com/o1-system-card-20241205.pdf},
}

@misc{paulus2024advprompterfastadaptiveadversarial,
      title={AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs}, 
      author={Anselm Paulus and Arman Zharmagambetov and Chuan Guo and Brandon Amos and Yuandong Tian},
      year={2024},
      eprint={2404.16873},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2404.16873}, 
}

@misc{perez2022redteaminglanguagemodels,
      title={Red Teaming Language Models with Language Models}, 
      author={Ethan Perez and Saffron Huang and Francis Song and Trevor Cai and Roman Ring and John Aslanides and Amelia Glaese and Nat McAleese and Geoffrey Irving},
      year={2022},
      eprint={2202.03286},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2202.03286}, 
}

@misc{rein2023gpqagraduatelevelgoogleproofqa,
      title={GPQA: A Graduate-Level Google-Proof Q\&A Benchmark}, 
      author={David Rein and Betty Li Hou and Asa Cooper Stickland and Jackson Petty and Richard Yuanzhe Pang and Julien Dirani and Julian Michael and Samuel R. Bowman},
      year={2023},
      eprint={2311.12022},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2311.12022}, 
}

@misc{robey2024smoothllmdefendinglargelanguage,
      title={SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks}, 
      author={Alexander Robey and Eric Wong and Hamed Hassani and George J. Pappas},
      year={2024},
      eprint={2310.03684},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.03684}, 
}

@misc{sadasivan2024fastadversarialattackslanguage,
      title={Fast Adversarial Attacks on Language Models In One GPU Minute}, 
      author={Vinu Sankar Sadasivan and Shoumik Saha and Gaurang Sriramanan and Priyatham Kattakinda and Atoosa Chegini and Soheil Feizi},
      year={2024},
      eprint={2402.15570},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2402.15570}, 
}

@misc{samvelyan2024rainbowteamingopenendedgeneration,
      title={Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts}, 
      author={Mikayel Samvelyan and Sharath Chandra Raparthy and Andrei Lupu and Eric Hambro and Aram H. Markosyan and Manish Bhatt and Yuning Mao and Minqi Jiang and Jack Parker-Holder and Jakob Foerster and Tim Rocktäschel and Roberta Raileanu},
      year={2024},
      eprint={2402.16822},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.16822}, 
}

@misc{shao2024deepseekmathpushinglimitsmathematical,
      title={DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}, 
      author={Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Xiao Bi and Haowei Zhang and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
      year={2024},
      eprint={2402.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.03300}, 
}

@misc{shin2020autopromptelicitingknowledgelanguage,
      title={AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts}, 
      author={Taylor Shin and Yasaman Razeghi and Robert L. Logan IV and Eric Wallace and Sameer Singh},
      year={2020},
      eprint={2010.15980},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2010.15980}, 
}

@misc{snell2024scalingllmtesttimecompute,
      title={Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters}, 
      author={Charlie Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar},
      year={2024},
      eprint={2408.03314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.03314}, 
}

@misc{stechly2024selfverificationlimitationslargelanguage,
      title={On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks}, 
      author={Kaya Stechly and Karthik Valmeekam and Subbarao Kambhampati},
      year={2024},
      eprint={2402.08115},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2402.08115}, 
}

@misc{uesato2022solvingmathwordproblems,
      title={Solving math word problems with process- and outcome-based feedback}, 
      author={Jonathan Uesato and Nate Kushman and Ramana Kumar and Francis Song and Noah Siegel and Lisa Wang and Antonia Creswell and Geoffrey Irving and Irina Higgins},
      year={2022},
      eprint={2211.14275},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2211.14275}, 
}

@misc{wang2024mathshepherdverifyreinforcellms,
      title={Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations}, 
      author={Peiyi Wang and Lei Li and Zhihong Shao and R. X. Xu and Damai Dai and Yifei Li and Deli Chen and Y. Wu and Zhifang Sui},
      year={2024},
      eprint={2312.08935},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2312.08935}, 
}

@misc{wang2024strategicchainofthoughtguidingaccurate,
      title={Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation}, 
      author={Yu Wang and Shiwan Zhao and Zhihu Wang and Heyuan Huang and Ming Fan and Yubo Zhang and Zhixing Wang and Haijun Wang and Ting Liu},
      year={2024},
      eprint={2409.03271},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2409.03271}, 
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}

@misc{wei2023jailbrokendoesllmsafety,
      title={Jailbroken: How Does LLM Safety Training Fail?}, 
      author={Alexander Wei and Nika Haghtalab and Jacob Steinhardt},
      year={2023},
      eprint={2307.02483},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2307.02483}, 
}

@misc{wen2023hardpromptseasygradientbased,
      title={Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery}, 
      author={Yuxin Wen and Neel Jain and John Kirchenbauer and Micah Goldblum and Jonas Geiping and Tom Goldstein},
      year={2023},
      eprint={2302.03668},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2302.03668}, 
}

@misc{xiang20252reasoningllmslearning,
      title={Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought}, 
      author={Violet Xiang and Charlie Snell and Kanishk Gandhi and Alon Albalak and Anikait Singh and Chase Blagden and Duy Phung and Rafael Rafailov and Nathan Lile and Dakota Mahan and Louis Castricato and Jan-Philipp Franken and Nick Haber and Chelsea Finn},
      year={2025},
      eprint={2501.04682},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2501.04682}, 
}

@misc{xie2024montecarlotreesearch,
      title={Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning}, 
      author={Yuxi Xie and Anirudh Goyal and Wenyue Zheng and Min-Yen Kan and Timothy P. Lillicrap and Kenji Kawaguchi and Michael Shieh},
      year={2024},
      eprint={2405.00451},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.00451}, 
}

@misc{yu2024ovmoutcomesupervisedvaluemodels,
      title={OVM, Outcome-supervised Value Models for Planning in Mathematical Reasoning}, 
      author={Fei Yu and Anningzhe Gao and Benyou Wang},
      year={2024},
      eprint={2311.09724},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2311.09724}, 
}

@misc{zeng2024johnnypersuadellmsjailbreak,
      title={How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs}, 
      author={Yi Zeng and Hongpeng Lin and Jingwen Zhang and Diyi Yang and Ruoxi Jia and Weiyan Shi},
      year={2024},
      eprint={2401.06373},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.06373}, 
}

@misc{zhang2024generativeverifiersrewardmodeling,
      title={Generative Verifiers: Reward Modeling as Next-Token Prediction}, 
      author={Lunjun Zhang and Arian Hosseini and Hritik Bansal and Mehran Kazemi and Aviral Kumar and Rishabh Agarwal},
      year={2024},
      eprint={2408.15240},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.15240}, 
}

@misc{zhang2024smalllanguagemodelsneed,
      title={Small Language Models Need Strong Verifiers to Self-Correct Reasoning}, 
      author={Yunxiang Zhang and Muhammad Khalifa and Lajanugen Logeswaran and Jaekyeom Kim and Moontae Lee and Honglak Lee and Lu Wang},
      year={2024},
      eprint={2404.17140},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.17140}, 
}

@misc{zheng2024criticcotboostingreasoningabilities,
      title={Critic-CoT: Boosting the reasoning abilities of large language model via Chain-of-thoughts Critic}, 
      author={Xin Zheng and Jie Lou and Boxi Cao and Xueru Wen and Yuqiu Ji and Hongyu Lin and Yaojie Lu and Xianpei Han and Debing Zhang and Le Sun},
      year={2024},
      eprint={2408.16326},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.16326}, 
}

@misc{zou2023universaltransferableadversarialattacks,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and Nicholas Carlini and Milad Nasr and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.15043}, 
}

