% \section{Additional Related Work}\label{additional}
\section{Experiments setting}\label{app: experiment_set}
For running \Cref{alg:gww} in \Cref{sec: asr}, we loaded the target models on our local GPUs to read to the log-probs, but used TogetherAI \cite{together_ai} for collecting the full responses. We also used TogetherAI for the attacker, Feedback LLM, and Refiner LLM in all the sections. We used one NVIDIA A100 for our experiments. 

\paragraph{Transfer method}
We chose to put GPT4o and Llama-3.1-405B in the black-box category. Despite the previous attempt to extract the entire log-prob vector based on the top-5 log-probs for GPT-4 \cite{hayase2024querybasedadversarialpromptgeneration}, there is no guarantee that OpenAI will preserve this feature in later releases, so we have included this model as one of the black-box models. For Llama-3.1-405B, we used TogetherAI for querying since the model would not fit to our GPUs, and TogetherAI does not give access to the entire log-prob vector. 

As mentioned, OpenAI o1 and Gemini-pro come with a content moderation filter that blocks the generation when activated. However, there are two main reasons that cause content moderation to stay random for these models. First, at the time of doing our experiments, it was not possible to set the temperature to 0 for OpenAI o1, resulting in non-deterministic generation along with its moderation. Secondly,  in our experiments with Gemini-pro, we observed that content moderation remains random is spite of a zero temperature setting, and can be bypassed through repeated attempts for the same attacking prompt. Therefore, for both models, we repeat the query 3 times in case of a generation block before accepting the refusal as a response.

\begin{figure}
     \centering
     \includegraphics[width=0.8\linewidth]{figs/Table_vul.png}
     \vspace{-0.1in}
     \caption{Shows the vulnerabilities of various models (y-axis) across the six categories of Harmbench (x-axis). Higher values in each cell indicate weaker safety performance against jailbreaks.}
     \label{table_vul}
\end{figure}

\section{Additional experiments}\label{app:add_exp}
% \paragraph{Feedback consistency} \label{sec: feedback_eff}
% We analyze if this feedback is truly responsive to given prompts rather than just offering general comments. We also demonstrate that feedback substantially contributes to the algorithm's success.
\paragraph{LLM vulnerabilities}
For some of the most common LLMs, we illustrate their vulnerabilities in different categories of Harmbench \cite{mazeika2024harmbenchstandardizedevaluationframework}. \Cref{table_vul} shows that Claude has a stronger performance (lower ASR) compared to other models except in the "cyber\_intrusion" category where the model is outperformed by OpenAI o1-preview and Gemini-1.5-pro. 





\paragraph{Sanity check for Feedback LLM} If Feedback LLM works properly, we expect to see contrasting feedback strings when the attacking prompts are properly ordered versus when they are reversed before being input into Feedback LLM. This is because the feedback is generated according to the comparison of pair of prompts and a general pattern across them as explained in \Cref{sec: algorithm}. We run a sanity check for this by shuffling and reversing the order of the attacking prompts given to Feedback LLM. \Cref{feedbacks_example} illustrates a case that the attacking prompt are generated by Mixtral but given in the correct, shuffled, and the reversed order to Feedback LLM, which is Mixtral again. 


\begin{figure}[t!]
     \centering
     \includegraphics[width=1.0\linewidth]{figs/feedbacks_exmaple_2.png}
     \vspace{-0.2in}
     \caption{The attacker has generated 8 prompts for a goal. These prompts are sorted according to their losses, and passed to Feedback LLM. When prompts are given in the correct order (increasing), Feedback LLM mentions a detachment from reality, while the reversed order (decreasing) lead to a feedback that contradicts the original one.}
     \label{feedbacks_example}
\end{figure}

\paragraph{Effect of the prompts order for the feedback} To further demonstrate the importance of Feedback LLM, and the consistency of the feedback string with the order of the attacking prompts, we ran \Cref{alg:gww} with random and reversed orders. Ideally, the incorrect orders will not cause any drop in the loss and hence affect the success rate of the algorithm. With Mixtral as the attacker and Llama-3-8b-RR as the target, for 10 tasks that are successfully done with the correct order of the attacking prompts for Feedback LLM, and when the number of iterations is greater that one (no feedback is collected otherwise), we both shuffled and reversed the order of the attacking prompts when passed to Feedback LLM. We did this for every call of Feedback LLM in \Cref{alg:gww}. As \Cref{table_orders} shows, the performance drops to half for the reversed order, and even less for shuffling. When the order is reversed, the algorithm still gets non-trivial success rate. We believe that Feedback LLM still follows the last prompt to some extent explained in \Cref{sec: ablation}.

\begin{table}[h!]
     % \vskip 0.15in 
    \centering
    
    \begin{tabular}{lccc}
    \toprule
    & Correct order & Reversed order & Shuffled \\
    \midrule
    Success rate & 10/10&  5/10& 4/10\\
    \bottomrule
    \end{tabular}
    \caption{The ASR of the algorithm on 10 selected goals from Harmbench. This tables shows that the feedback string follows the order of the attacking prompts, and if given in other orders, the ASR of the algorithm will decrease.} 
    \label{table_orders} 
\end{table}


\paragraph{Iteration distribution} As we explained in \Cref{sec: ablation}, our algorithms improves the performance of later iterations. \Cref{dists_white} shows the distribution of successful jailbreaks, in which \Cref{dist_llamaRR} demonstrates the utilization of iterations when the target model is safer. We also plot this for Claude and OpenAI o1-preview models in \Cref{dists_black}, where o1 needs more iterations on average. 

\begin{figure}[h!]
     \centering
     \begin{subfigure}[b]{0.33\textwidth}
         \centering
         % Linewidth is the now the unit for half a page.
         \includegraphics[width=1.12\linewidth]{figs/iter_dist_llamaRR.png}
         \caption{Mixtral -> Llama-3-8B-RR}
         \label{dist_llamaRR}
     \end{subfigure}
     \begin{subfigure}[b]{0.33\textwidth}
         \centering
         % Linewidth is the now the unit for half a page.
         \includegraphics[width=1.12\linewidth]{figs/iter_dist_mistralRR.png}
         \caption{Mixtral -> Mistral-7B-RR}
         \label{dist_mistralRR}
     \end{subfigure}
     \begin{subfigure}[b]{0.33\textwidth}
         \centering
         % Linewidth is the now the unit for half a page.
         \includegraphics[width=1.12\linewidth]{figs/iter_dist_vicuna.png}
         \caption{Vicuna -> Llama-3-8B}
         \label{dist_vicuna}
     \end{subfigure}
        \caption{Distribution of successful jailbreaks over iterations for \textbf{(a)} Mixtral-8x7B model as the attacker and Llama-3-8B-RR as the target. \textbf{(b)} Mixtral model attacking Mistral-3-8B-RR.  \textbf{(c)} Vicuna as the attacker and Llama-3-8B as the target.}
        \label{dists_white}
\end{figure}


\begin{figure}[h!]
     \centering
     \begin{subfigure}[b]{0.33\textwidth}
         \centering
         % Linewidth is the now the unit for half a page.
         \includegraphics[width=1.12\linewidth]{figs/iter_dist_Claude.png}
         \caption{Mixtral -> Claude}
         \label{dist_Claude}
     \end{subfigure}
    \hspace{0.6in}
     \begin{subfigure}[b]{0.33\textwidth}
         \centering
         % Linewidth is the now the unit for half a page.
         \includegraphics[width=1.12\linewidth]{figs/iter_dist_o1.png}
         \caption{Mixtral -> OpenAI o1-preview}
         \label{dist_o1}
     \end{subfigure}
        \caption{Distribution of successful jailbreaks over iterations for \textbf{(a)} Mixtral-8x7B model as the attacker and Claude as the target when using the average loss \Cref{sec: transfer} for surrogate.  \textbf{(b)} Same setting for attacking OpenAI o1.} 
        \label{dists_black}
\end{figure}


