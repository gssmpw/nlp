\section{Understanding Parents Behavioural Dynamics During Homework Involvement}

Parental behavioural dynamics play a crucial role in shaping the quality and effectiveness of homework assistance. Understanding these dynamics not only allows us to evaluate how parental actions influence a child’s academic development but also helps in identifying patterns that may lead to tension or conflict. By studying these dynamics, we gain insights into how different types of parental involvement can either support or hinder the child’s homework experience \cite{eccles1993parent,eccles2013family}.

In this section, we explore the parental behaviours and parent-child conflicts that arise during homework sessions. Using GPT-4o, we systematically analyze and categorize these behaviours and conflicts from transcribed conversations with the assistance of educational experts. We then validate the extracted behaviours and conflicts through comparisons with human annotations. Additionally, we examine the distribution of these behaviours and conflicts both across the overall population and on a per-user basis.


\subsection{Parental Behaviours and Parent-Child Conflicts}

%To establish a coding manual for parental behaviours and conflicts observed during homework assistance, we begin by defining these two key elements. \textbf{Parental behaviours} encompass the actions or responses of parents as they assist their children with homework. These behaviours can be positive, neutral, or negative depending on their nature and effect on the child. \textbf{Parent-child conflicts} refer to disagreements or tension that arise during homework sessions, which can be triggered by a range of factors, such as differing perspectives on learning methods or time management.

Although prior research has extensively explored parental behaviours and conflicts in general family and educational settings \cite{moe2018brief,solomon2002helping,nnamani2020impact}, to the best of our knowledge, there are no established definitions or a comprehensive codebook specifically addressing parental behaviours and parent-child conflicts during homework involvement. Therefore, we adopted a bottom-up coding process to inductively derive patterns from the raw data. This process is divided into three main steps: open coding, axial coding, and selective coding, ultimately resulting in the creation of a codebook for understanding parental behaviours and parent-child conflicts during homework sessions \cite{corbin1994grounded,charmaz2006constructing,glaser2017discovery}.

%Therefore, we begin by grounding our definitions in related literature on parenting and education but adapt them to the specific context of homework involvement. In cases where existing definitions are inadequate, we propose new ones based on our analysis of the interactions observed in this study.
 %coding manual

In this context, parental behaviour refers to the specific actions, responses, or strategies parents employ while assisting their children with homework. These behaviours include verbal and non-verbal interactions, guidance, feedback, or any form of involvement that influences the child's approach to homework. Parental behaviours may support, hinder, or remain neutral in the homework process, and they reflect the dynamic interaction between parent and child during educational activities \cite{cunha2015parents,eccles2013family}.
Similarly, parent-child conflicts are defined as moments of disagreement, tension, or friction that arise during homework involvement. These conflicts may stem from misunderstandings, differences in expectations, frustration, or emotional reactions from either the parent or the child, ranging from minor verbal disagreements to more disruptive disputes \cite{grolnick2009issues,benckwitz2023reciprocal,hanh2023current}.

%Similarly, parent-child conflicts during homework are defined as moments of disagreement, tension, or friction. These conflicts may arise from misunderstandings, differing expectations, frustration, or emotional reactions from either the parent or child, ranging from minor disagreements to more disruptive disputes.


%We randomly selected 50 transcripts from a larger dataset of 602 valid conversations for initial analysis. Using GPT-4o, we conducted two open coding tasks: one to identify parental behaviours and another to capture specific parent-child conflicts. This stage of open coding generated a total of 932 conflict scenarios and 2,161 instances of parental behaviour, resulting in 330 conflict codes and 950 behaviour codes. These codes formed the basis for further analysis and refinement.

\input{table/Behavior}

%To develop a coding manual for both parent-child conflicts and parental behaviours observed during homework assistance in families with young children, we first randomly sampled 50 transcripts from a larger set of 602 valid dialogue transcripts. Using GPT-4o, we conducted two open coding tasks: one focused on identifying instances of parent-child conflicts, and the other on specific parental behaviours during the homework assistance process. In this phase, GPT-4o was instructed to carefully review the dialogue content, capturing segments that reflected these two phenomena—conflicts and behaviours—and applying open coding to each. Through this open coding process, we identified \textit{932 conflict scenarios} and developed \textit{330 initial conflict codes}, as well as \textit{2,161 instances of parental behaviour} and \textit{950 behaviour codes}. These initial codes provided a rich foundation for further analysis and refinement in the subsequent stages.

\subsubsection{Coding and Categorisation}


To conduct this study, we randomly sampled 50 transcripts from 602 valid dialogues. Using GPT-4o, we performed two open coding tasks: one to identify parental behaviours and another to capture specific parent-child conflicts. Through this process, we identified 932 conflict scenarios and 2,161 instances of parental behaviour, which initially resulted in 330 conflict codes and 950 behaviour codes. These preliminary codes provided a rich foundation for further analysis.

In the \textit{axial coding} phase, we refined the initial codes by removing those that did not reflect genuine conflicts and merging similar codes to reduce redundancy. This refinement process resulted in \textit{166 conflict codes} and \textit{606 behaviour codes}. Using GPT-4o, we then categorized these codes based on content similarity and emerging patterns, grouping the conflict codes into \textit{12 categories} and the behaviour codes into \textit{34 categories}. These categories represent typical conflict and behavioural patterns, offering a structured framework for analyzing parent-child interactions during homework.

%In the \textit{axial coding} phase, we cleaned and consolidated the codes generated during open coding. This involved removing any codes that did not reflect genuine conflict characteristics, ensuring that the remaining codes accurately represented parent-child conflicts. We then merged similar codes to reduce redundancy, ultimately refining the dataset to \textit{166 conflict codes} and \textit{606 behaviour codes}. To clarify relationships between these codes, we once again employed GPT-4o to categorize them based on content similarity and pattern recognition. As a result, the conflict codes were grouped into \textit{12 categories}, while the behaviour codes were organized into \textit{34 categories}. Each group represented a typical conflict or behaviour pattern, providing a clearer structure for understanding the interactions and laying the groundwork for further refinement.

%In the \textit{selective coding} phase, we brought in a human expert to further refine the conflict and behaviour codes. The expert closely examined ten distinct parent-child dialogue samples, combining this detailed review with the classification outcomes from the axial coding stage. Special attention was given to core conflict types, and the expert considered the specific context of the data, including the educational and cultural background of Chinese parents. Through this process, redundant or ambiguous codes were further consolidated. Ultimately, the expert distilled the \textit{12 conflict groups} into \textit{8 core conflict types}, while the \textit{34 behaviour groups} were reduced to \textit{18 key behaviour categories}. Each conflict and behaviour type was given a precise definition and clear coding guidelines to ensure consistent application in future research. To further aid understanding, the expert selected representative dialogue examples for each code, demonstrating its practical use.

In the \textit{selective coding} phase, a human education expert reviewed ten parent-child dialogue samples and integrated the results from the axial coding stage. The expert focused on identifying core conflict types while considering the educational and cultural context of Chinese parents. Redundant or ambiguous codes were consolidated, reducing the \textit{12 conflict categories} to \textit{8 core conflict types} and the \textit{34 behaviour categories} to \textit{18 key behaviour categories}. Each conflict type and behaviour category was clearly defined, with representative dialogue examples chosen to illustrate their practical use.

Following this, three educational experts were invited to review the coding manual, evaluating its accuracy, relevance, and applicability. Based on their feedback, further refinements were made to ensure clarity and consistency in the code definitions and guidelines. After multiple revisions, the coding manual was finalized as a validated tool for future qualitative research, providing clear guidance for analyzing parental behaviours and parent-child conflict during homework involvement.

%After developing the initial version of the coding manual, we sought the evaluation of \textit{three educational experts}, who reviewed the coding scheme in depth. These experts assessed the accuracy, relevance, and applicability of the codes within the educational context, providing constructive feedback for improvement. Based on their recommendations, we made further refinements to the code definitions and coding guidelines, optimizing the manual for clarity and consistency. Through multiple rounds of revision and expert input, we finalized the coding manual, which now serves as a validated tool for future qualitative research. This manual offers clear guidance for the coding process, ensuring consistency across different researchers while providing a robust foundation for analyzing the underlying causes and patterns of parent-child conflict during homework assistance.

%We applied GPT-4o to the entire dataset to automate the coding of parental behaviours and conflicts. In the case of \textbf{parental behaviour coding}, GPT-4o segmented each dialogue into distinct behaviour units, each mapped to a corresponding code based on predefined categories. Behaviours were classified as positive, neutral, or negative, with descriptions provided for each identified instance. Similarly, for \textbf{parent-child conflict coding}, GPT-4o identified and labelled conflict scenarios, categorizing them by the conflict’s trigger, development, intensity, and the reactions of both parent and child.
\input{table/Conflict}
\subsubsection{Automated Coding Using GPT-4o}
We applied GPT-4o to the entire dataset to automate the coding of parental behaviours and conflicts. Regarding the parental behaviour coding, we utilise GPT-4o to analyze specific actions of the parent during the homework involvement process. Each segment identified distinct behaviours, segmenting the dialogue into behaviour units (denoted as \texttt{behaviour\_id}), where each behaviour could consist of one or more sentences. It then provided a brief description for each behaviour and mapped it to a relevant \textit{code} based on predefined categories. These behaviours were classified as \textit{positive}, \textit{neutral}, or \textit{negative}, ensuring accurate classification of each parental action. The specific coding manual is presented in Table \ref{tab:behaviours}, and the coding guidelines are detailed in Table \ref{appen:tab:behaviour}.


For the parent-child conflict coding, GPT-4o was prompted to identify conflict scenarios from the transcribed dialogues. Each conflict was described according to the following dimensions: \textit{trigger of the conflict}  (what initiated it), \textit{development} (how it unfolded), \textit{parent’s behaviour} (verbal or non-verbal reactions), \textit{child’s response}, \textit{type of conflict}, and \textit{its intensity} (categorized as high, medium, or low). GPT-4o assigned a short label, or code, to each dialogue segment representing a conflict. The specific coding manual for these conflicts is presented in Table \ref{tab:conflict}, and the coding guidelines are provided in Table \ref{appen:tab:conflict}.






\subsection{Evaluation of Coding Consistency}

To assess the consistency of GPT-4o's coding, we conducted an evaluation experiment comparing the AI-generated codes with those created by human experts. We randomly selected 200 instances from each coding task for detailed analysis and asked four human experts to code the same instances independently. Their coding results were compared with GPT-4o's outputs using \textit{Cohen's Kappa Coefficient} to measure the agreement. A \textit{Consensus Coding} was established via majority voting among experts, serving as the gold standard for comparison with GPT-4o. The experiment evaluated consistency across three dimensions: between human experts, between GPT-4o and individual experts, and between GPT-4o and the expert consensus.

%This section presents the evaluation experiment designed to assess the consistency of AI-based coding, specifically GPT-4o, in comparison to human experts. The primary objective of this experiment was to determine the reliability of the AI system in coding two key categories: \textit{parental behaviours} and \textit{parent-child conflicts}. These categories were derived from observations during homework interactions between parents and young children, capturing the nuances of behaviour and conflict in this context.

%To carry out the evaluation, a systematic process was adopted. The LLM GPT-4o was applied to the entire dataset, and a random sample of 200 instances from each coding task was selected for in-depth analysis. In parallel, \textit{four} human experts, each with similar levels of expertise in the domain, independently coded the same set of \textit{400} instances. Their coding results were then compared with those of GPT-4o using \textit{Cohen's Kappa Coefficient} to measure agreement. Additionally, a \textit{Consensus Coding} was established through majority voting among the experts, which served as the gold standard for comparison with GPT-4o. This experiment aimed to evaluate consistency across three dimensions: between human experts, between GPT-4o and each individual expert, and between GPT-4o and the expert consensus.

%In the behaviour coding task, as shown in Figure \ref{tab:consistency_analysis}, GPT-4o demonstrated \textbf{moderate agreement} with individual experts, with Kappa values ranging from 0.288 to 0.544. The model's agreement with the expert consensus was stronger, with a Kappa value of 0.560, indicating \textbf{substantial agreement}. In contrast, the conflict coding task showed \textbf{fair agreement} between GPT-4o and individual experts, with Kappa values between 0.256 and 0.344, and moderate agreement with the consensus (Kappa = 0.419). These results suggest that while GPT-4o performed reliably in behaviour coding, there is room for improvement in conflict coding.
%GPT-4o showed \textit{moderate agreement} with individual experts, with Kappa values ranging from \textbf{0.288} (b3) to \textbf{0.544} (b1). According to Landis and Koch \cite{landis1977measurement}, these values indicate \textit{moderate} agreement. GPT-4o's agreement with the expert consensus was higher, with a Kappa value of \textbf{0.560}, reflecting \textit{substantial agreement}. In the conflict coding task, Kappa values with individual experts ranged from \textbf{0.256} to \textbf{0.344}, showing \textit{fair agreement}, while the Kappa value with the consensus was \textbf{0.419}, indicating \textit{moderate agreement}. Overall, GPT-4o’s consistency with the expert consensus is comparable to that of human experts across both tasks, according to the Landis and Koch scale.


\input{table/code_cons}

In the behavior coding task, as shown in Figure \ref{tab:consistency_analysis}, GPT-4o exhibited \textit{moderate agreement} with individual experts, with Kappa values ranging from \textbf{0.562} (Expert 3) to \textbf{0.708} (Expert 2). According to Landis and Koch \cite{landis1977measurement}, these values indicate \textit{substantial agreement} with Expert 2 and \textit{moderate agreement} with Expert 3. The agreement of GPT-4o with the expert consensus was higher, with a Kappa value of \textbf{0.724}, indicating \textit{substantial agreement}. In the conflict coding task, Kappa values with individual experts ranged from \textbf{0.410} (Expert 1) to \textbf{0.500} (Expert 4), showing \textit{moderate agreement}, while the Kappa value with the consensus was \textbf{0.517}, indicating \textit{moderate agreement}. Overall, GPT-4o’s consistency with the expert consensus is comparable to that of human experts across both tasks, according to the Landis and Koch scale.

%GPT-4o's performance was more varied, with Kappa values with individual experts ranging from \textbf{0.256} to \textbf{0.344}, demonstrating \textit{fair agreement}. The Kappa value between GPT-4o and the consensus coding for conflict instances was \textbf{0.419}, reflecting \textit{moderate agreement}. These results suggest that GPT-4o's consistency with the expert consensus is comparable to that of human experts across both tasks, as categorized by the Landis and Koch scale.
%To better understand where GPT-4o aligned with expert coding and where discrepancies occurred, we used confusion matrices to analyze specific categories of errors and misclassifications. These matrices, detailed in Appendix \ref{sec}, reveal patterns of agreement and confusion across coding categories, highlighting strengths and areas needing improvement.

The moderate agreement observed in the conflict coding task can be considered reasonable, given that dialogue act annotation and sentiment analysis tasks often involve subjective interpretations, as noted in previous research. Studies have highlighted that these tasks are inherently complex and prone to ambiguity, especially when dealing with conflicting or emotionally nuanced data. For instance, Stolcke et al. \cite{stolcke2000dialogue} discuss the challenges in annotating dialogue acts, pointing out that annotators may struggle with the subtlety and context-dependency of dialogues, leading to moderate or low Kappa values. Similarly, Latif et al.\cite{latif2023can}, and Litman et al. \cite{litman2003recognizing} argue that disagreement among annotators is common, even with proper training, especially in tasks involving emotion or sentiment, where subtle cues may be interpreted differently. These studies suggest that a Kappa range of 0.41 to 0.60 is typical in such contexts, underlining the subjective nature of the task.



 To better understand where GPT-4o aligned well with expert coding and where discrepancies occurred, we employed confusion matrices to analyse the specific categories of errors and misclassifications. These matrices, detailed in Appendix \ref{sec:Confusion}, provide patterns of agreement and confusion across different coding categories, highlighting strengths and areas needing improvement.


In addition, a \textit{Chi-Squared} test was conducted to assess the statistical significance of GPT-4o's consistency with the expert consensus. For behavior coding, the Chi-Square value $\chi^2$ was \text{1756.134} with a p-value of \text{1.19e-221}, indicating extremely significant agreement. Similarly, for conflict coding, the $\chi^2$ value was \text{333.131} with a p-value of \text{8.39e-50}, confirming statistical significance. These tests confirm that GPT-4o's agreement with the consensus is far beyond what could be attributed to random chance, further validating the model's reliability.

%In addition to evaluating agreement through Kappa values, we conducted a Chi-square test to assess the statistical significance of GPT-4o's consistency with the expert consensus. For behaviour coding, the Chi-square test yielded a value of \textbf{1415.547} with a p-value of \textbf{6.14e-160}, demonstrating that the observed agreement was extremely significant. Similarly, in conflict coding, the Chi-square value was \textbf{332.151} with a p-value of \textbf{1.04e-43}, again indicating a statistically significant result. These tests confirm that GPT-4o's agreement with the consensus is far beyond what could be attributed to random chance, further validating the model's reliability.

Overall, the evaluation experiments show that the LLM-driven coding showed \textit{substantial agreement} in behaviour coding and \textit{moderate agreement} in conflict coding by human expert annotators. While it aligns well with the expert consensus, particularly in behaviour coding, areas for improvement remain, especially with Experts 1. Refinement in conflict coding could enhance its performance in more complex cases.



%Overall, the evaluation demonstrates that GPT-4o performs reliably, achieving \textit{substantial agreement} in behaviour coding and \textit{moderate agreement} in conflict coding. While GPT-4o aligns well with the expert consensus, particularly in behaviour coding, there are opportunities for improvement, especially in addressing discrepancies with certain experts such as b3 and c3. These findings suggest that GPT-4o has the potential to be an effective coding tool, particularly in tasks where achieving perfect human agreement is challenging. However, further refinement of the model, especially in the areas of conflict coding, could enhance its performance and make it more robust in handling complex or subjective cases.

\subsection{Analysis of Behavioural Dynamics}

\subsubsection{Overall Trend}

For each homework involvement session, we extracted parental behaviours and parent-child conflicts. Figure \ref{fig:dis_behaviour}
illustrates the average number of positive, neutral, and negative behaviours per session across all participants. Among these categories, positive behaviours were the most prevalent, accounting for 47.21\% of total behaviours, while negative behaviours were the least frequent at 9.07\%. The most commonly exhibited behaviour was \textit{Guided Inquiry}, with parents engaging in this behaviour an average of 9.16 times per session. This indicates that parents often asked questions or provided clues to guide their children towards independent thinking and problem-solving. In contrast, negative behaviours occurred less frequently, with parents displaying an average of 3.02 negative behaviours per session. Among these, \textit{Criticism and Blame} was the most common negative behaviour.

\begin{figure}
    \centering
    \begin{minipage}[t]{0.525\textwidth}
        \includegraphics[width=1\textwidth]{figure/dis_behvaiour.pdf}
        \caption{Average number of positive, neutral, and negative behaviours for all participants, with positive behaviours (e.g., Encouragement
(ENC)), neutral behaviours (e.g., Direct
Instruction (DI)), and negative behaviours (e.g., Criticism and
Blame (CB)) defined in Table \ref{tab:behaviours}. Error bar indicates 0.95 confidence level.}
        \label{fig:dis_behaviour}
    \end{minipage}
    \hspace{0.2cm}
    \begin{minipage}[t]{0.445\textwidth}
    \centering
        \includegraphics[width=1\textwidth]{figure/dis_conflict.pdf}
        \caption{Average numbers of each conflict type per user, including types of conflicts defined in Table \ref{tab:conflict} (e.g., Knowledge Conflict (KC), Communication Conflict (CC), and Focus Conflict
(FC)). Error bar indicates 0.95 confidence level.}
        \label{fig:dis_conflict}
    \end{minipage}
    
\end{figure}


Despite the predominance of positive and neutral behaviours, the occurrence of parent-child conflicts was frequent, with an average of 8.63 per session. Figure \ref{fig:dis_conflict} highlights \textit{Knowledge Conflict} as the most common conflict (2.71 times per session), possibly due to the gap between parents’ higher education levels and their children’s earlier stages of learning. This aligns with the \textit{Curse of Knowledge} bias \cite{birch2007curse}, where experts struggle to understand novice perspectives. The second most common conflict type was \textit{Learning Method Conflict}, averaging 1.50 times per session, likely due to the disagreements between parents and children over the approach or strategies used for learning and completing homework tasks. 

\subsubsection{Individual Analysis}
To further understand negative parental behaviours, we analyzed their distribution across individual participants. Figure \ref{fig:per_behaviour_dis} presents the average number of behaviours per participant. While some participants exhibited a very small proportion of negative behaviours, others, such as P4, P28, and P104, displayed a significantly higher percentage of negative behaviours compared to their neutral and positive behaviours. This suggests that these individuals may benefit from improving their behaviours during homework involvement.

\begin{figure}
    \centering
    \includegraphics[width=.95\linewidth]{figure/dis_behvaiour_per.pdf}
    \caption{Average frequency of positive, neutral, and negative behaviours per homework session for each parent}
    \label{fig:per_behaviour_dis}
\end{figure}

We then examined the specific types of negative behaviours exhibited by each participant, as illustrated in Figure \ref{fig:per_behaviour_stacked}. We found that some participants demonstrated only limited types of negative behaviours. For example, P4 displayed just two types of negative behaviours, with \textit{Forcing and Threatening} accounting for 93.75\% of all negative behaviours. Similarly, P33 exhibited two types of negative behaviours, with \textit{Criticism and Blame} and \textit{Forcing and Threatening} each contributing 50\%. In contrast, participants such as P0, P6, P32, and P104 displayed a broader range of negative behaviours, suggesting a more varied pattern of interaction. These variations highlight the individual differences in how parents manage homework involvement and may point to areas for targeted behavioural improvement.
 
\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figure/stacked_behvaiour.pdf}
    \caption{Proportion of various negative behaviours per homework session for each parent}
    \label{fig:per_behaviour_stacked}
\end{figure}

Finally, we investigated the average number of different conflict types per homework involvement session for each parent, as shown in Figure \ref{fig:dis_stacked_conflict}. Our findings reveal significant variability in the number of conflicts experienced by different families. For example, participants like P28, P32, and P104 averaged more than 15 conflicts per session, while others, such as P3 and P35, experienced fewer than 3 conflicts on average. Moreover, the variety of conflict types also differed among participants. Some, like P3, encountered only 3 types of conflict, while others such as P4, P35, and P87 experienced 4 types. In contrast, participants like P0, P16, and P28 encountered all types of conflicts. This suggests that the complexity of conflict during homework sessions can vary greatly among families. Although \textit{Knowledge Conflict} was the most common type of conflict overall, some participants experienced other types more frequently. For instance, P0 primarily dealt with \textit{Time Management Conflict}, while P96 had \textit{Rule Conflict} as their dominant issue. These findings highlight that not only the number of conflicts but also the types of conflicts vary widely among families. 

%Finally, we invesitage the average number of different conflict types per homework involvement session for each parent, as shown in Figure \ref{fig:dis_stacked_conflict}. Overall, we found that different parents experience very different number of conflicts. some participants such as P28, P32 and P104 have more than 15 conflicts on average, while some participants such as P3 and P35 have less than 3 conflicts on average. In addition, some participants have only limited types of conflicts, such as P3 have 3 types of conflict, P4, P35, P87 have 4 types of conflict. However, for some particoants such as P0, P16, P28 have all kinds of conflicts, this reveal... In addition, Though \textit{Knowledge Conflict} (KC) is the top conflicts that occurs overall, some participants have \textit{Time Management Conflict} (TMC) most such as P0, some have \textit{Rule Conflict} (RC) such as 96. This reveals different families have very different conflicts types..

\begin{figure}
    \centering
    \includegraphics[width=.95\linewidth]{figure/dis_stacked_conflict.pdf}
    \caption{Average frequency of various conflict types per homework session for each parent}
    \label{fig:dis_stacked_conflict}
\end{figure}

