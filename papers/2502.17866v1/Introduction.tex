\section{Introduction}


Drawing is a fun and easy activity to create imaginary characters, especially embraced by children as a natural form of creative expression. It is accessible to virtually everyone, whereas very few possess the skills and tools required to produce appealing 3D characters. On the other hand, childlike figure drawings exhibit a unique and delightful appeal. When combined with a repertoire of interesting motions, they could be used to inject highly personalized animated characters into user generated stories, games, and interactive experiences. With recent advancements in spatial computing technology and devices, it is no longer a distant dream to embody the monster you create and smash some zombies, or dance with your own imaginary friend in the living room. That is, if we can enable everyone to easily bring their own hand-drawn characters to the 3D world and animate them in 3D.
%\nicky{It would be an enjoyable experience to control a character you've drawn within a 3D game, or to interact with these characters in a mixed-reality environment.}

In practice, preparing a character model to be animation-ready, or "rigging", requires highly specialized technical skills, years of training and experiences, as well as access to expensive professional software. In the case of 2D characters, their rig usually consists of many variations of the same character under different poses and views, requiring laborious manual labor to create and difficult to maintain style consistency. Generative AI models recently become an attractive and even viable option to automatically create 2D animations from an image~\cite{shi2023zero123}. However, precisely controlling the motion or preserving the character identity remain an open challenge. Moreover, in comparison to portrait photos or professional artwork, childlike drawings are extremely scarce in the training data~\cite{SmithHodgins}. It is therefore unreasonable to expect these models to perform well on animating childlike drawings. %figure drawings. 

%\strike{However, specifying motion for 2D characters using keypoint and level curves can be quite tedious; it is far more natural to specify motion in 3D, e.g. using one's own body. Therefore, an ideal solution would apply 3D motion onto a single childlike figure drawing, giving the user great flexibility over both the appearance and motion of the character.}
%\nicky{Employing 2D animation techniques, such as keypoint and level curves, to animate a 2D character seems like an intuitive solution. However, this approach can be laborious and constrained in a 3D application. The users need to be skillful at 2D animation softwares to create appealing animation. In addition, they need to spend a significant amount of effort to create animations for various viewing angles, which is an impossible mission in the mixed-reality scenario where the character can be observed from an infinite number of perspectives. Moreover, this method imposes constraints on the design of the 3D application, as it must consider the range of possible viewing angles. Therefore, an ideal solution would apply 3D motion onto a single childlike figure drawing. This way we can control the drawn character similarly to how we would manipulate a 3D character using well-established 3D animation techniques like motion matching, and even drive the character using one's own body.}

Even if we set aside the technical challenges, it is not obvious how to apply 3D motion to childlike drawings without significantly impacting their unique style. The crux of the problem stems from two characteristics. First, childlike drawings are \textit{view-dependent} representations, made to be observed from an angle close to the drawing plane's normal vector. Second, childlike drawings utilize an \textit{intellectually realistic}~\cite{luquet2001children} denotation system, as opposed to the more familiar, visually realistic system used in photographs and 3D renderings. This means that, instead of attempting to depict the subject faithfully from a specific point of view, the drawer instead chooses to include details which are, in accordance with their internal model of the subject, important to their identity. Therefore, creating a 3D model from the figure drawing and manipulating it to create visually realistic images would fundamentally alter the style.

Inspired by the desire for an easily accessible and efficient character creation system, and the quirky style of childlike figure drawings, we present an integrated view-dependent 2.5D character model and novel motion retargeting technique, specifically designed for childlike drawings. The system can retarget complex 3D motions, including transversal rotations, onto the drawn figures while preserving both the style and identity of the character, as well as being recognized as the input motion. Our system is informed by insights from both the field of children's art analysis, and by a novel annotation study examining how observers infer figure orientations.

Our system generates an animation-ready 2.5D character model from a single drawing and a set of high-level semantic annotations provided by the user. At run time, the character model can be automatically animated and rendered from a given 3D skeletal motion and camera positions at every frame. It is fast, requires no future information, and is well-suited for real-time applications. Any input which can convert to 3D skeletal poses (videos and pose estimation~\cite{li2021hybrik}, text-to-motion models~\cite{jiang2023motiongpt}, VR body tracking~\cite{10.1145/3550469.3555411, jiang22avatarposer}) can be used to drive the characters. The resulting animations are suitable for both 2D and 3D applications and, because the representation is view-dependent, it can be used to bring these figures into mixed reality settings (Figure~\ref{fig:teaser}). We believe this is the first system to combine 3D motion, 2D childlike drawings, and a view-dependent formulation with the goal of allowing novices to easily create and animate their own characters. %\nicky{and bring these characters into a wide range of applications}.

We validate our design in several ways. We demonstrate the recognizability of the input 3D motion on the character with a perceptual user study; we provide several ablation visualizations justifying our design choices; and we compare our results with several existing methods. We also developed a wide range of applications to showcase the value and generality of our system.

Our contribution is two-fold: 
\begin{itemize}
    \item A first annotation study examining, in fine detail, how observers infer character axial rotation from childlike figure drawings. 
    \item An integrated view-dependent 2.5D character model and novel retargeting technique to apply user-generated 3D motions onto user-generated childlike figure drawings in a style-preserving manner.
\end{itemize}


% We validate the usefulness of our model with a user study, ablations, and comparisions to existing works.





%% We combine a literature review with perform an in-depth annotation task to understand how people infer the orientation of these characters.
%% From this, we identify a small set of representational 'tricks' that untrained drawers use to represent character orientation (or which viewers use to infer orientation).







% The crux of this problem is that drawings have two characteristics. view-dependent, intellectually realistic representations. They are view dependent in that they are drawn so as to be viewed from the paper's plane normal. They are not visually realistic, and so attempting to create a 3D model that can be manipualted realistically fundamentally alters the style. 



% Applying 3D motion to 2D drawing is problematic. Part of the charm of these drawings is their quirky representational style. Creating 3D model removes that. Without creating a 3D model, it isn't clear how to manipulate with 3D motion, especially in regards to axial rotation.

%Therefore, to maximize accessibility and ease-of-use, it is desireable to apply user-generated 3D motions onto these figure drawings.








%Inversely, however, it  


%while 2D is well-suited to character design, 

%characters are familiar to 


%2D Drawings are fun and easy to make.

% Combined with the right motions, they can be parts of animated stories, become embodied NPCs, or even stylized avatar representations of people.

% However, it's difficult to draw all the poses needed for a sophisticated set of actions. Moreover, specifying character motion in 2D, using keypoints and level curves, is also difficult.

%An ideal solution would combine a single 2D drawing with 3D motion, such as a user can create with their body, giving the user great flexibility over both the appearance and motion of the character.

% Applying 3D motion to 2D drawing is problematic. Part of the charm of these drawings is their quirky representational style. Creating 3D model removes that. Without creating a 3D model, it isn't clear how to manipulate with 3D motion, especially in regards to axial rotation.

% The crux of this problem is that drawings have two characteristics. view-dependent, intellectually realistic representations. They are view dependent in that they are drawn so as to be viewed from the paper's plane normal. They are not visually realistic, and so attempting to create a 3D model that can be manipualted realistically fundamentally alters the style. 

% Informed by drawing literature, we explore in detail how observers infer axial rotation of childlike figure drawings, and present a 2.5D model which supports these types of manipulations. 

% It applies 3D motion to 2D characters. Because it retargets 3D skeletal motion onto these characters, any input that generates 3D skeletal poses (text-to-motion models, controller inputs, motion graphics, video-to-pose estimation models, 3-point tracking) can be used.
% The resulting animations can be viewed in 2D and 3D applications.
% And because the represention is view-dependent, it can even be used to bring these figures into mixed reality settings.

% We believe our approach is the first to combine 3D motion, 2D childlike drawings, and a view-dependent formulation with the goal of creating an easy and accessible system to allow laypeople to create unique animated characters and combined with unique motions. 

% In summary, our contribution two-fold. First, a novel annotation study examining how observers infer axial rotation of childlike figure drawings. Second, an easy-to-create integreated VD model and retargeting techinique.

% We validate the usefulness of our model with a user study, ablations, and comparisions to existing works.





%% Drawing is a delightful and easy way to depict a character.
% While creating characters 3D requires speciailized software, significant skill, and 
%% It would be immensely useful to have an easy method to let people animate their 2D drawings, since 2D drawings are very easy to create and anyone can do so.
%% To use these drawings as characters within games or stories, it would be useful for them to 
%% perform sophisticated motion, and to be able to turn around based upon the motion.
%% Using your own body (or other form of skeletal motion) is an easy way to specify motion for these characters. But how do you retarget 3D motion onto these 2D characters in a way that allows them to turn around without totally breaking the style of the 2D world in which they move?
%% Creating full 3D objects breaks the style significantly. They're also difficult for laypeople to edit directly.
%% We combine a literature review with perform an in-depth annotation task to understand how people infer the orientation of these characters.
%% From this, we identify a small set of representational 'tricks' that untrained drawers use to represent character orientation (or which viewers use to infer orientation).
%% We then build a novel retargeting system which manipulates the original drawing, through a combination of mesh deformation and part-level transformations. The end result is a representation of the character oriented in a particular way, drawn in the same style as the original drawing and suitable for the 2D world. The character can run in circles spin, and perform sophisticated motions while maintaining it's original style.
%% The system does not require future information and therefore can be used for realtime puppeteering or for 2D avatars in MR settings.
%% We also build a semi-automatic tool which allows users to quickly annotate up a drawing with the information necessary to use the tool.
%% We validate our approach with a pair of user studies assessing the recognizability of motions /orientation and the appeal of 2.5D character model.

%% An important detail of this domain is that 1. it isn't visually realistic, and 2. there is no objectively 'correct' view of a character from a different point of view expecting what is in the eye of the creator. While we do our best to adhere to the stylistic elements of the amateur drawing style (as determined by literature review and included annotation work), we accept the inherent ambiguity by keeping the model easily human-intelligible and by easily allowing users to modify the model, define custom key views, or even draw totally new key-view versions of the character that will then be swapped in by the animation code. Our goal is not to automatically create the 'correct' version of the drawing from a particular point of view (which is ill-defined), but rather to assist the user in creating their 'correct' version of the drawing as easily and helpfully as possible. 

%% The paper doll model can perform a variety of different motion types (running, dancing, twirling, fighting, etc.) while remaining true to the style and feel of most child-like amateur drawings. Due to its view-dependent formulation, it is suitable for use in 2D or stylized 3D applications without fixed camera viewing angles. An important aspect of the model is that it is human understandable and it is easy to modify the appearance of the character when viewed from specific angles. This approach- creating a plausible guess while still allowing users to easy modify and augment the character, keeps the user squarely in creative control of the character. It doesn't not sideline them. 

%% When it comes to MR applications, we believe that the view-dependent representation is useful for characters beyond children's drawings. 2D characters of any sort are easier to generate than 3D, and portraying them in a view-dependent manner 3D is a useful and interesting way to bring them into the realm of spacial computing.

%% Since it's impossible to have the resulting animations to 'realistic', or without any sort of discrepancies, we instead seek to minimize excessive discrepancies, which are distracting, in how we formulate the view model by minimizing flipping whenever possible.

%% Why do we create a left and right version of the character, and not more? We do it specifically to deal with something caused by twisted perspective. Because things are drawn from different points of view, it is frequenly the case that the character's 'forward' direction is, at least for a subset of its bodyparts, directed to image left or image right. It is not at all uncommon for forward facing and side facing parts to be mixed together. However, it IS uncommon for parts suggesting a forward direction of opposite sides to be mixed together. We create a left and right version of the character to ensure that all parts of the character suggest a consistent 'side forward' vector and that this vector is consistent with sign of the projection of the character's forward vector onto the X axis. 

% term to use: 'Integrated' 2.5D View-dependent character model and 3D->2D retargeting algorithm

% The approach of Smith et al. falls short of this because the projection plane is defined relative to the skeleton; joints projects onto a frontal plane will always appear they would when viewed from the skeleton's front, even if the skeleton is walking in a circle.
% This formulation makes their retargeting approach unable to depict traversal rotation of the skeleton or to take into account the position of the viewer.
% Our approach has a much more dynamic projection plane that varies based upon the position of the viewer.


% When a childlike drawing is make, the viewing angle, or paper normal, is incorporated into the depiction.
% Starting from the insight that childlike drawings are view-dependent depictings of non-visually realistic characters, we present a simple and easy to use method for puppeteering these characters in a style preserving, view-dependent way.