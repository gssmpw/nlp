@book{luquet2001children,
  title={Children's Drawings: (le Dessin Enfantin)},
  author={Luquet, G.H. and Costall, A.},
  isbn={9781853435164},
  lccn={2002319040},
  series={G - Reference,Information and Interdisciplinary Subjects Series},
  url={https://books.google.com/books?id=XqB9AAAAMAAJ},
  year={2001},
  publisher={Free Association Books}
}


@article{goodnow1977children,
 ISSN = {00093920, 14678624},
 URL = {http://www.jstor.org/stable/1128230},
 abstract = {Drawings can be regarded as constructions in which parts are selected and combined in accordance with specifiable rules. This type of approach-one that links the study of drawing to other studies of representation and cognition-has to date concentrated on sequences in construction. The present study asks about the likelihood of various parts being changed when children are asked to represent action (a person picking up an object from the floor, or 2 people, 1 running, the other walking). Results indicate a preference among young children for depicting a change in meaning by altering 1 figure part only, and a slowness, over age, in departing from one linking principle, namely, the placing of all main body units along a single axis at 90° to the ground. Results are considered in terms of some general features of actions with constructive aspects.},
 author = {Jacqueline J. Goodnow},
 journal = {Child Development},
 number = {3},
 pages = {637--641},
 publisher = {[Wiley, Society for Research in Child Development]},
 title = {Visible Thinking: Cognitive Aspects of Change in Drawings},
 urldate = {2024-01-12},
 volume = {49},
 year = {1978}
}

@book{cox2014drawings,
  title={Drawings of people by the under-5s},
  author={Cox, Maureen V and Cox, Maureen},
  year={2014},
  publisher={Routledge}
}

@book{cox1993children,
  title={Children's drawings of the human figure},
  author={Cox, Maureen V},
  year={1993},
  location={Hove, UK & Hillsdale, USA},
  publisher={Lawrence Erlbaum}
}

@article{cox1994children,
  title={Children's depictions of different views of the human figure},
  author={Cox, Maureen V and Moore, Rachel},
  journal={Educational Psychology},
  volume={14},
  number={4},
  pages={427--436},
  year={1994},
  publisher={Taylor \& Francis}
}

@book{lowenfeld1975creative,
  title={Creative and Mental Growth},
  author={Lowenfeld, V. and Brittain, W.L.},
  isbn={9780023720901},
  lccn={75004741},
  url={https://books.google.com/books?id=W7pPAAAAMAAJ},
  year={1975},
  publisher={Macmillan}
}

@misc{picasso1937, 
	author = {Pablo Picasso},
	title = {Portrait of Dora Maar},
	year = {1937},
	howpublished = {Oil on canvas},
	note = {Part of the Musee Picasso Collection}
}

@misc{cave-tito-bustillo,
	title = {Cave of Tito Bustillo, Spain},
	howpublished = {Archaeological site},
	year = {Unknown}, 
	note = {Location: Ribadesella, Spain}
}

@book{willats2006making,
  title={Making sense of children's drawings},
  author={Willats, John},
  year={2006},
  publisher={Psychology Press}
}

@article{willats1992representation,
  title={The representation of extendedness in children's drawings of sticks and discs},
  author={Willats, John},
  journal={Child Development},
  volume={63},
  number={3},
  pages={692--710},
  year={1992},
  publisher={Wiley Online Library}
}

@book{piaget1956,
  title={The child's conception of space},
  author={Piaget, J. \& Inhelder, B},
  year={1956},
  publisher={Routledge \& Kegan Paul}
}

@article{SmithHodgins,
author = {Smith, Harrison Jesse and Zheng, Qingyuan and Li, Yifei and Jain, Somya and Hodgins, Jessica K.},
title = {A Method for Animating Children’s Drawings of the Human Figure},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/3592788},
doi = {10.1145/3592788},
abstract = {Children’s drawings have a wonderful inventiveness, creativity, and variety to them. We present a system that automatically animates children’s drawings of the human figure, is robust to the variance inherent in these depictions, and is simple and straightforward enough for anyone to use. We demonstrate the value and broad appeal of our approach by building and releasing the Animated Drawings Demo, a freely available public website that has been used by millions of people around the world. We present a set of experiments exploring the amount of training data needed for fine-tuning, as well as a perceptual study demonstrating the appeal of a novel twisted perspective retargeting technique. Finally, we introduce the Amateur Drawings Dataset, a first-of-its-kind annotated dataset, collected via the public demo, containing over 178,000 amateur drawings and corresponding user-accepted character bounding boxes, segmentation masks, and joint location annotations.},
journal = {ACM Trans. Graph.},
month = {jun},
articleno = {32},
numpages = {15},
keywords = {motion stylization, 2D animation, Skeletal animation, motion retargeting}
}

@misc{cave-tito-bustillo,
	title = {Cave of Tito Bustillo, Spain},
	howpublished = {Archaeological site},
	year = {Unknown}, 
	note = {Location: Ribadesella, Spain}
}

@article{harrison2023tog,
author = {Smith, Harrison Jesse and Zheng, Qingyuan and Li, Yifei and Jain, Somya and Hodgins, Jessica K.},
title = {A Method for Animating Children’s Drawings of the Human Figure},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/3592788},
doi = {10.1145/3592788},
abstract = {Children’s drawings have a wonderful inventiveness, creativity, and variety to them. We present a system that automatically animates children’s drawings of the human figure, is robust to the variance inherent in these depictions, and is simple and straightforward enough for anyone to use. We demonstrate the value and broad appeal of our approach by building and releasing the Animated Drawings Demo, a freely available public website that has been used by millions of people around the world. We present a set of experiments exploring the amount of training data needed for fine-tuning, as well as a perceptual study demonstrating the appeal of a novel twisted perspective retargeting technique. Finally, we introduce the Amateur Drawings Dataset, a first-of-its-kind annotated dataset, collected via the public demo, containing over 178,000 amateur drawings and corresponding user-accepted character bounding boxes, segmentation masks, and joint location annotations.},
journal = {ACM Trans. Graph.},
month = {jun},
articleno = {32},
numpages = {15},
keywords = {motion stylization, 2D animation, Skeletal animation, motion retargeting}
}

@misc{kirillov2023segment,
      title={Segment Anything}, 
      author={Alexander Kirillov and Eric Mintun and Nikhila Ravi and Hanzi Mao and Chloe Rolland and Laura Gustafson and Tete Xiao and Spencer Whitehead and Alexander C. Berg and Wan-Yen Lo and Piotr Dollár and Ross Girshick},
      year={2023},
      eprint={2304.02643},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{igarashi2005asrigidaspossible,
  title={As-rigid-as-possible shape manipulation},
  author={Igarashi, Takeo and Moscovich, Tomer and Hughes, John F},
  journal={ACM transactions on Graphics (TOG)},
  volume={24},
  number={3},
  pages={1134--1141},
  year={2005},
  publisher={ACM New York, NY, USA}
}

@article{rivers25Dcartoonmodels,
author = {Rivers, Alec and Igarashi, Takeo and Durand, Fr\'{e}do},
title = {2.5D Cartoon Models},
year = {2010},
issue_date = {July 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/1778765.1778796},
doi = {10.1145/1778765.1778796},
abstract = {We present a way to bring cartoon objects and characters into the third dimension, by giving them the ability to rotate and be viewed from any angle. We show how 2D vector art drawings of a cartoon from different views can be used to generate a novel structure, the 2.5D cartoon model, which can be used to simulate 3D rotations and generate plausible renderings of the cartoon from any view. 2.5D cartoon models are easier to create than a full 3D model, and retain the 2D nature of hand-drawn vector art, supporting a wide range of stylizations that need not correspond to any real 3D shape.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {59},
numpages = {7},
keywords = {vector art, cartoons, animation, interpolation, non-photorealistic rendering, billboards}
}

@inproceedings{rademacher1999view,
  title={View-dependent geometry},
  author={Rademacher, Paul},
  booktitle={Proceedings of the 26th annual conference on Computer graphics and interactive techniques},
  pages={439--446},
  year={1999}
}

@article {10.1111:j.1467-8659.2004.00772.x,
journal = {Computer Graphics Forum},
title = {{A System for View-Dependent Animation}},
author = {Chaudhuri, Parag and Kalra, Prem and Banerjee, Subhashis},
year = {2004},
publisher = {The Eurographics Association and Blackwell Publishing, Inc},
ISSN = {1467-8659},
DOI = {10.1111/j.1467-8659.2004.00772.x}
}

@article{DBLP:journals/corr/abs-2103-15472,
  author       = {Tsukasa Fukusato and
                  Akinobu Maejima},
  title        = {View-Dependent Formulation of 2.5D Cartoon Models},
  journal      = {CoRR},
  volume       = {abs/2103.15472},
  year         = {2021},
  url          = {https://arxiv.org/abs/2103.15472},
  eprinttype    = {arXiv},
  eprint       = {2103.15472},
  timestamp    = {Wed, 07 Apr 2021 15:31:46 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2103-15472.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{koyama2013view,
  title={View-dependent control of elastic rod simulation for 3D character animation},
  author={Koyama, Yuki and Igarashi, Takeo},
  booktitle={Proceedings of the 12th ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
  pages={73--78},
  year={2013}
}

@article{Hornung2007anim2Dpicmotion,
author = {Hornung, Alexander and Dekkers, Ellen and Kobbelt, Leif},
title = {Character Animation from 2D Pictures and 3D Motion Data},
year = {2007},
issue_date = {January 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {1},
issn = {0730-0301},
url = {https://doi.org/10.1145/1189762.1189763},
doi = {10.1145/1189762.1189763},
abstract = {This article presents a new method to animate photos of 2D characters using 3D motion capture data. Given a single image of a person or essentially human-like subject, our method transfers the motion of a 3D skeleton onto the subject's 2D shape in image space, generating the impression of a realistic movement. We present robust solutions to reconstruct a projective camera model and a 3D model pose which matches best to the given 2D image. Depending on the reconstructed view, a 2D shape template is selected which enables the proper handling of occlusions. After fitting the template to the character in the input image, it is deformed as-rigid-as-possible by taking the projected 3D motion data into account. Unlike previous work, our method thereby correctly handles projective shape distortion. It works for images from arbitrary views and requires only a small amount of user interaction. We present animations of a diverse set of human (and nonhuman) characters with different types of motions, such as walking, jumping, or dancing.},
journal = {ACM Trans. Graph.},
month = jan,
pages = {1–es},
numpages = {9},
keywords = {3D motion data, as-rigid-as-possible shape manipulation with perspective correction, 2D character animation, camera and model pose determination}
}

@article{ArtiSketch,
author = {Levi, Zohar and Gotsman, Craig},
title = {ArtiSketch: A System for Articulated Sketch Modeling},
journal = {Computer Graphics Forum},
volume = {32},
number = {2pt2},
pages = {235-244},
doi = {https://doi.org/10.1111/cgf.12043},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12043},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12043},
abstract = {Abstract We present ArtiSketch – a system which allows the conversion of a wealth of existing 2D content into 3D content by users who do not necessarily possess artistic skills. Using ArtiSketch, a novice user may describe a 3D model as a set of articulated 2D sketches of a shape from different viewpoints. ArtiSketch then automatically converts the sketches to an articulated 3D object. Using common interactive tools, the user provides an initial estimate of the 3D skeleton pose for each frame, which ArtiSketch refines to be consistent between frames. This skeleton may then be manipulated independently to generate novel poses of the 3D model.},
year = {2013}
}

@inproceedings{hinz2022charactergan,
  title={CharacterGAN: Few-Shot Keypoint Character Animation and Reposing},
  author={Hinz, Tobias and Fisher, Matthew and Wang, Oliver and Shechtman, Eli and Wermter, Stefan},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1988--1997},
  year={2022}
}

@inproceedings{lingens2020towards,
  title={Towards automatic drawing animation using physics-based evolution},
  author={Lingens, Lasse and Sumner, Robert W and Magnenat, St{\'e}phane},
  booktitle={Proceedings of the 2020 ACM Interaction Design and Children Conference: Extended Abstracts},
  pages={314--319},
  year={2020}
}

@inproceedings{feng2017magictoon,
  title={Magictoon: A 2d-to-3d creative cartoon modeling system with mobile ar},
  author={Feng, Lele and Yang, Xubo and Xiao, Shuangjiu},
  booktitle={2017 IEEE Virtual Reality (VR)},
  pages={195--204},
  year={2017},
  organization={IEEE}
}

@incollection{igarashi2006teddy,
  title={Teddy: a sketching interface for 3D freeform design},
  author={Igarashi, Takeo and Matsuoka, Satoshi and Tanaka, Hidehiko},
  booktitle={ACM SIGGRAPH 2006 Courses},
  pages={11--es},
  year={2006}
}

@inproceedings{weng2019photo,
  title={Photo wake-up: 3d character animation from a single photo},
  author={Weng, Chung-Yi and Curless, Brian and Kemelmacher-Shlizerman, Ira},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5908--5917},
  year={2019}
}

@article{Dvoroznak20-SA,
author = {Dvoro\v{z}\v{n}\'{a}k, Marek and S\'{y}kora, Daniel and Curtis, Cassidy and Curless, Brian and Sorkine-Hornung, Olga and Salesin, David},
title = {Monster Mash: A Single-View Approach to Casual 3D Modeling and Animation},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3414685.3417805},
doi = {10.1145/3414685.3417805},
abstract = {We present a new framework for sketch-based modeling and animation of 3D organic shapes that can work entirely in an intuitive 2D domain, enabling a playful, casual experience. Unlike previous sketch-based tools, our approach does not require a tedious part-based multi-view workflow with the explicit specification of an animation rig. Instead, we combine 3D inflation with a novel rigidity-preserving, layered deformation model, ARAP-L, to produce a smooth 3D mesh that is immediately ready for animation. Moreover, the resulting model can be animated from a single viewpoint --- and without the need to handle unwanted inter-penetrations, as required by previous approaches. We demonstrate the benefit of our approach on a variety of examples produced by inexperienced users as well as professional animators. For less experienced users, our single-view approach offers a simpler modeling and animating experience than working in a 3D environment, while for professionals, it offers a quick and casual workspace for ideation.},
journal = {ACM Trans. Graph.},
month = {nov},
articleno = {214},
numpages = {12},
keywords = {casual animation, 2D-to-3D inflation, sketch-based modelling}
}


@article{Dvoroznak18-SIG,
author = {Dvoro\v{z}n\'{a}k, Marek and Li, Wilmot and Kim, Vladimir G. and S\'{y}kora, Daniel},
title = {Toonsynth: Example-Based Synthesis of Hand-Colored Cartoon Animations},
year = {2018},
issue_date = {August 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3197517.3201326},
doi = {10.1145/3197517.3201326},
abstract = {We present a new example-based approach for synthesizing hand-colored cartoon animations. Our method produces results that preserve the specific visual appearance and stylized motion of manually authored animations without requiring artists to draw every frame from scratch. In our framework, the artist first stylizes a limited set of known source skeletal animations from which we extract a style-aware puppet that encodes the appearance and motion characteristics of the artwork. Given a new target skeletal motion, our method automatically transfers the style from the source examples to create a hand-colored target animation. Compared to previous work, our technique is the first to preserve both the detailed visual appearance and stylized motion of the original hand-drawn content. Our approach has numerous practical applications including traditional animation production and content creation for games.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {167},
numpages = {11},
keywords = {skeletal animation, style transfer}
}

@inproceedings{poursaeed2020neural,
  title={Neural puppet: Generative layered cartoon characters},
  author={Poursaeed, Omid and Kim, Vladimir and Shechtman, Eli and Saito, Jun and Belongie, Serge},
  booktitle={The IEEE Winter Conference on Applications of Computer Vision},
  pages={3346--3356},
  year={2020}
}

@incollection{lorensen1998marching,
  title={Marching cubes: A high resolution 3D surface construction algorithm},
  author={Lorensen, William E and Cline, Harvey E},
  booktitle={Seminal graphics: pioneering efforts that shaped the field},
  pages={347--353},
  year={1998}
}

@incollection{shewchuk96b,
author = {Jonathan Richard Shewchuk},
title = {Triangle:  {E}ngineering a {2D} {Q}uality {M}esh {G}enerator and
  {D}elaunay {T}riangulator},
booktitle = {Applied Computational Geometry:  Towards Geometric Engineering},
editor = {Ming C. Lin and Dinesh Manocha},
series = {Lecture Notes in Computer Science},
volume = 1148,
publisher = {Springer-Verlag},
pages = {203--222},
month = may,
year = 1996,
note = {From the First ACM Workshop on Applied Computational Geometry}
}

@inproceedings{10.1145/3550469.3555411,
author = {Winkler, Alexander and Won, Jungdam and Ye, Yuting},
title = {QuestSim: Human Motion Tracking from Sparse Sensors with Simulated Avatars},
year = {2022},
isbn = {9781450394703},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550469.3555411},
doi = {10.1145/3550469.3555411},
abstract = {Real-time tracking of human body motion is crucial for interactive and immersive experiences in AR/VR. However, very limited sensor data about the body is available from standalone wearable devices such as HMDs (Head Mounted Devices) or AR glasses. In this work, we present a reinforcement learning framework that takes in sparse signals from an HMD and two controllers, and simulates plausible and physically valid full body motions. Using high quality full body motion as dense supervision during training, a simple policy network can learn to output appropriate torques for the character to balance, walk, and jog, while closely following the input signals. Our results demonstrate surprisingly similar leg motions to ground truth without any observations of the lower body, even when the input is only the 6D transformations of the HMD. We also show that a single policy can be robust to diverse locomotion styles, different body sizes, and novel environments.},
booktitle = {SIGGRAPH Asia 2022 Conference Papers},
articleno = {2},
numpages = {8},
keywords = {Wearable Devices, Reinforcement Learning, Motion Tracking, Character Animation},
location = {<conf-loc>, <city>Daegu</city>, <country>Republic of Korea</country>, </conf-loc>},
series = {SA '22}
}

@InProceedings{Qian_2023_ICCV,
    author    = {Qian, Yijun and Urbanek, Jack and Hauptmann, Alexander G. and Won, Jungdam},
    title     = {Breaking The Limits of Text-conditioned 3D Motion Synthesis with Elaborative Descriptions},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {2306-2316}
}

@misc{shi2023zero123,
      title={Zero123++: a Single Image to Consistent Multi-view Diffusion Base Model}, 
      author={Ruoxi Shi and Hansheng Chen and Zhuoyang Zhang and Minghua Liu and Chao Xu and Xinyue Wei and Linghao Chen and Chong Zeng and Hao Su},
      year={2023},
      eprint={2310.15110},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{jiang22avatarposer,
  title={Avatarposer: Articulated full-body pose tracking from sparse motion sensing},
  author={Jiang, Jiaxi and Streli, Paul and Qiu, Huajian and Fender, Andreas and Laich, Larissa and Snape, Patrick and Holz, Christian},
  booktitle={European Conference on Computer Vision},
  pages={443--460},
  year={2022},
  organization={Springer}
}

@inproceedings{jiang2023motiongpt,
  title={MotionGPT: Human Motion as a Foreign Language},
  author={Jiang, Biao and Chen, Xin and Liu, Wen and Yu, Jingyi and Yu, Gang and Chen, Tao},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023}
}

@inproceedings{li2021hybrik,
    title={Hybrik: A hybrid analytical-neural inverse kinematics solution for 3d human pose and shape estimation},
    author={Li, Jiefeng and Xu, Chao and Chen, Zhicun and Bian, Siyuan and Yang, Lixin and Lu, Cewu},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    pages={3383--3393},
    year={2021}
}