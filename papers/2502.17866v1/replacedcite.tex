\section{Related Work}
\subsection{View-Dependent Control}
View-dependent representations have a long history in computer graphics.
In his pioneering work, Rademacher proposed interpolating between \textit{key viewpoints} and associated \textit{key deformations} to manipulate 3D models____.
Other researchers have extended the idea to create 3D animation systems____, streamline the modeling process____, and integrate physical simulation____.
Of particular note, Rivers et al.____ introduced \textit{2.5D Cartoon Models}, a combination of planar meshes transformed, based upon view angle, so as to appears three dimensional.
Our work draws upon these works but is, to our knowledge, the first work to attempt to use view-dependent techniques to retarget 3D motion onto 2D characters.   

\subsection{Animation from 2D Images}

% output is still 2D
Many researchers have proposed different methods for creating animations from 2D images. Hornung et al.____ presented a method to deform a character from a photograph given user-provided joint annotations.
\textit{Toonsynth}____ and \textit{Neural Puppet}____ both present methods to create new images of hand-drawn characters from examples.
% output is 3D model
Other researchers have proposed methods of obtaining 3D geometry from 2D sketches____ and images____.
% focus on sketches specifically
A number of works have specifically focused on childlike drawings.
Lingens et al.____ proposed an evolutionary algorithm for animating children's drawings. 
\textit{MagicToon}____ creates a 3D model from childlike drawings for AR applications.
Similar to our work, Smith et al.____ proposed a method for animating childlike drawings using 3D skeletal motion. 
However, the resulting animations are only suitable for use in 2D applications and the type of motions it supports are limited.

Unlike these previous works, our solution can be used in 3D contexts but does not create a 3D model. We instead relying upon a view-dependent formulation of the animated character.