@inproceedings{cc_paraphrase1,
  author       = {Wee Chung Gan and
                  Hwee Tou Ng},
  editor       = {Anna Korhonen and
                  David R. Traum and
                  Llu{\'{\i}}s M{\`{a}}rquez},
  title        = {Improving the Robustness of Question Answering Systems to Question
                  Paraphrasing},
  booktitle    = {Proceedings of the 57th Conference of the Association for Computational
                  Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,
                  Volume 1: Long Papers},
  pages        = {6065--6075},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/p19-1610},
  doi          = {10.18653/V1/P19-1610},
  timestamp    = {Fri, 06 Aug 2021 00:41:06 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/GanN19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{cc_paraphrase2,
  author       = {Paulo Alting von Geusau and
                  Peter Bloem},
  editor       = {Mitra Baratchi and
                  Lu Cao and
                  Walter A. Kosters and
                  Jefrey Lijffijt and
                  Jan N. van Rijn and
                  Frank W. Takes},
  title        = {Evaluating the Robustness of Question-Answering Models to Paraphrased
                  Questions},
  booktitle    = {Artificial Intelligence and Machine Learning - 32nd Benelux Conference,
                  BNAIC/Benelearn 2020, Leiden, The Netherlands, November 19-20, 2020,
                  Revised Selected Papers},
  series       = {Communications in Computer and Information Science},
  volume       = {1398},
  pages        = {1--14},
  publisher    = {Springer},
  year         = {2020},
  url          = {https://doi.org/10.1007/978-3-030-76640-5\_1},
  doi          = {10.1007/978-3-030-76640-5\_1},
  timestamp    = {Sat, 30 Sep 2023 09:35:39 +0200},
  biburl       = {https://dblp.org/rec/conf/bnaic/GeusauB20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{cc_paraphrase3,
  author={Matsuno, Takumi and Tsuchiya, Masatoshi},
  booktitle={2023 10th International Conference on Advanced Informatics: Concept, Theory and Application (ICAICTA)}, 
  title={Evaluating the Robustness of Question Answering Model Against Context Variations}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  keywords={Training;Annotations;Machine learning;Encyclopedias;Data models;Robustness;Question answering (information retrieval);Question Answering;Answerability;Model Evaluation},
  doi={10.1109/ICAICTA59291.2023.10390252}}

@inproceedings{cc_paraphrase4,
  author       = {Ishani Mondal and
                  Abhilasha Sancheti},
  title        = {On the robustness of Chatgpt under input perturbations for Named Entity
                  Recognition Task},
  booktitle    = {The Second Tiny Papers Track at {ICLR}

@inproceedings{chu-etal-2024-timebench,
    title = "{T}ime{B}ench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models",
    author = "Chu, Zheng  and
      Chen, Jingchang  and
      Chen, Qianglong  and
      Yu, Weijiang  and
      Wang, Haotian  and
      Liu, Ming  and
      Qin, Bing",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.66/",
    doi = "10.18653/v1/2024.acl-long.66",
    pages = "1204--1228",
    abstract = "Grasping the concept of time is a fundamental facet of human cognition, indispensable for truly comprehending the intricacies of the world.Previous studies typically focus on specific aspects of time, lacking a comprehensive temporal reasoning benchmark.To address this, we propose TimeBench, a comprehensive hierarchical temporal reasoning benchmark that covers a broad spectrum of temporal reasoning phenomena.TimeBench provides a thorough evaluation for investigating the temporal reasoning capabilities of large language models.We conduct extensive experiments on GPT-4, LLaMA2, and other popular LLMs under various settings.Our experimental results indicate a significant performance gap between the state-of-the-art LLMs and humans, highlighting that there is still a considerable distance to cover in temporal reasoning.Besides, LLMs exhibit capability discrepancies across different reasoning categories.Furthermore, we thoroughly analyze the impact of multiple aspects on temporal reasoning and emphasize the associated challenges.We aspire for TimeBench to serve as a comprehensive benchmark, fostering research in temporal reasoning.Code and data are available at https://github.com/zchuz/TimeBench."
}

@misc{fatemi2024testtimebenchmarkevaluating,
      title={Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning}, 
      author={Bahare Fatemi and Mehran Kazemi and Anton Tsitsulin and Karishma Malkan and Jinyeong Yim and John Palowitch and Sungyong Seo and Jonathan Halcrow and Bryan Perozzi},
      year={2024},
      eprint={2406.09170},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.09170}, 
}

@inproceedings{grace,
  author       = {Tom Hartvigsen and
                  Swami Sankaranarayanan and
                  Hamid Palangi and
                  Yoon Kim and
                  Marzyeh Ghassemi},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {Aging with {GRACE:} Lifelong Model Editing with Discrete Key-Value
                  Adaptors},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  url          = {http://papers.nips.cc/paper\_files/paper/2023/hash/95b6e2ff961580e03c0a662a63a71812-Abstract-Conference.html},
  timestamp    = {Fri, 01 Mar 2024 16:26:20 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/HartvigsenSPKG23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{head_to_tail,
  author       = {Kai Sun and
                  Yifan Ethan Xu and
                  Hanwen Zha and
                  Yue Liu and
                  Xin Luna Dong},
  editor       = {Kevin Duh and
                  Helena G{\'{o}}mez{-}Adorno and
                  Steven Bethard},
  title        = {Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)?
                  {A.K.A.} Will LLMs Replace Knowledge Graphs?},
  booktitle    = {Proceedings of the 2024 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies
                  (Volume 1: Long Papers), {NAACL} 2024, Mexico City, Mexico, June 16-21,
                  2024},
  pages        = {311--325},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.naacl-long.18},
  doi          = {10.18653/V1/2024.NAACL-LONG.18},
  timestamp    = {Thu, 29 Aug 2024 17:13:57 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/SunXZLD24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{know_what_language_models_know,
  author       = {Zhengbao Jiang and
                  Frank F. Xu and
                  Jun Araki and
                  Graham Neubig},
  title        = {How Can We Know What Language Models Know},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {8},
  pages        = {423--438},
  year         = {2020},
  url          = {https://doi.org/10.1162/tacl\_a\_00324},
  doi          = {10.1162/TACL\_A\_00324},
  timestamp    = {Wed, 19 Jun 2024 17:28:03 +0200},
  biburl       = {https://dblp.org/rec/journals/tacl/JiangXAN20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{melo,
  author       = {Lang Yu and
                  Qin Chen and
                  Jie Zhou and
                  Liang He},
  editor       = {Michael J. Wooldridge and
                  Jennifer G. Dy and
                  Sriraam Natarajan},
  title        = {{MELO:} Enhancing Model Editing with Neuron-Indexed Dynamic LoRA},
  booktitle    = {Thirty-Eighth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2024, Thirty-Sixth Conference on Innovative Applications of Artificial
                  Intelligence, {IAAI} 2024, Fourteenth Symposium on Educational Advances
                  in Artificial Intelligence, {EAAI} 2014, February 20-27, 2024, Vancouver,
                  Canada},
  pages        = {19449--19457},
  publisher    = {{AAAI} Press},
  year         = {2024},
  url          = {https://doi.org/10.1609/aaai.v38i17.29916},
  doi          = {10.1609/AAAI.V38I17.29916},
  timestamp    = {Sun, 06 Oct 2024 20:55:17 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/YuCZH24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{mindthegap,
  title={Mind the Gap: Assessing Temporal Generalization in Neural Language Models},
  author={Angeliki Lazaridou and Adhiguna Kuncoro and Elena Gribovskaya and Devang Agrawal and Adam Liska and Tayfun Terzi and Mai Gim{\'e}nez and Cyprien de Masson d'Autume and Tom{\'a}s Kocisk{\'y} and Sebastian Ruder and Dani Yogatama and Kris Cao and Susannah Young and Phil Blunsom},
  booktitle={Neural Information Processing Systems},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:239886013}
}

@inproceedings{outdated1_set_the_clock,
  title={Set the Clock: Temporal Alignment of Pretrained Language Models},
  author={Bowen Zhao and Zander Brumbaugh and Yizhong Wang and Hanna Hajishirzi and Noah A. Smith},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:268033102}
}

@inproceedings{outdated2_carpediem,
  author       = {Yujin Kim and
                  Jaehong Yoon and
                  Seonghyeon Ye and
                  Sangmin Bae and
                  Namgyu Ho and
                  Sung Ju Hwang and
                  Se{-}Young Yun},
  editor       = {Kevin Duh and
                  Helena G{\'{o}}mez{-}Adorno and
                  Steven Bethard},
  title        = {Carpe diem: On the Evaluation of World Knowledge in Lifelong Language
                  Models},
  booktitle    = {Proceedings of the 2024 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies
                  (Volume 1: Long Papers), {NAACL} 2024, Mexico City, Mexico, June 16-21,
                  2024},
  pages        = {5401--5415},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.naacl-long.302},
  doi          = {10.18653/V1/2024.NAACL-LONG.302},
  timestamp    = {Thu, 29 Aug 2024 17:13:57 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/KimYYBHHY24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{outdated3_signal,
  author       = {Katerina Margatina and
                  Shuai Wang and
                  Yogarshi Vyas and
                  Neha Anna John and
                  Yassine Benajiba and
                  Miguel Ballesteros},
  editor       = {Andreas Vlachos and
                  Isabelle Augenstein},
  title        = {Dynamic Benchmarking of Masked Language Models on Temporal Concept
                  Drift with Multiple Views},
  booktitle    = {Proceedings of the 17th Conference of the European Chapter of the
                  Association for Computational Linguistics, {EACL} 2023, Dubrovnik,
                  Croatia, May 2-6, 2023},
  pages        = {2873--2890},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.eacl-main.211},
  doi          = {10.18653/V1/2023.EACL-MAIN.211},
  timestamp    = {Thu, 05 Oct 2023 18:04:58 +0200},
  biburl       = {https://dblp.org/rec/conf/eacl/MargatinaWVJBB23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{outdated4_realtime,
  author       = {Jungo Kasai and
                  Keisuke Sakaguchi and
                  Yoichi Takahashi and
                  Ronan Le Bras and
                  Akari Asai and
                  Xinyan Yu and
                  Dragomir Radev and
                  Noah A. Smith and
                  Yejin Choi and
                  Kentaro Inui},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {RealTime {QA:} What's the Answer Right Now?},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  url          = {http://papers.nips.cc/paper\_files/paper/2023/hash/9941624ef7f867a502732b5154d30cb7-Abstract-Datasets\_and\_Benchmarks.html},
  timestamp    = {Fri, 01 Mar 2024 16:26:20 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/KasaiST0A0RS0I23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{outdated5_dyknow,
  author       = {Seyed Mahed Mousavi and
                  Simone Alghisi and
                  Giuseppe Riccardi},
  editor       = {Yaser Al{-}Onaizan and
                  Mohit Bansal and
                  Yun{-}Nung Chen},
  title        = {DyKnow: Dynamically Verifying Time-Sensitive Factual Knowledge in
                  LLMs},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2024, Miami, Florida, USA, November 12-16, 2024},
  pages        = {8014--8029},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.findings-emnlp.471},
  timestamp    = {Mon, 18 Nov 2024 09:05:59 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/MousaviAR24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{paraphrase1,
  author       = {Harsh Raj and
                  Domenic Rosati and
                  Subhabrata Majumdar},
  title        = {Measuring Reliability of Large Language Models through Semantic Consistency},
  journal      = {CoRR},
  volume       = {abs/2211.05853},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2211.05853},
  doi          = {10.48550/ARXIV.2211.05853},
  eprinttype    = {arXiv},
  eprint       = {2211.05853},
  timestamp    = {Tue, 15 Nov 2022 15:45:12 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2211-05853.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{pararel,
  author       = {Yanai Elazar and
                  Nora Kassner and
                  Shauli Ravfogel and
                  Abhilasha Ravichander and
                  Eduard H. Hovy and
                  Hinrich Sch{\"{u}}tze and
                  Yoav Goldberg},
  title        = {Measuring and Improving Consistency in Pretrained Language Models},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {9},
  pages        = {1012--1031},
  year         = {2021},
  url          = {https://doi.org/10.1162/tacl\_a\_00410},
  doi          = {10.1162/TACL\_A\_00410},
  timestamp    = {Wed, 19 Jun 2024 17:28:03 +0200},
  biburl       = {https://dblp.org/rec/journals/tacl/ElazarKRRHSG21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{petroni,
    title = "Language Models as Knowledge Bases?",
    author = {Petroni, Fabio  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian  and
      Lewis, Patrick  and
      Bakhtin, Anton  and
      Wu, Yuxiang  and
      Miller, Alexander},
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1250",
    doi = "10.18653/v1/D19-1250",
    pages = "2463--2473",
    abstract = "Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as {``}fill-in-the-blank{''} cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at \url{https://github.com/facebookresearch/LAMA}.",
}

@article{rag,
  author       = {Ori Ram and
                  Yoav Levine and
                  Itay Dalmedigos and
                  Dor Muhlgay and
                  Amnon Shashua and
                  Kevin Leyton{-}Brown and
                  Yoav Shoham},
  title        = {In-Context Retrieval-Augmented Language Models},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {11},
  pages        = {1316--1331},
  year         = {2023},
  url          = {https://doi.org/10.1162/tacl\_a\_00605},
  doi          = {10.1162/TACL\_A\_00605},
  timestamp    = {Wed, 19 Jun 2024 17:28:03 +0200},
  biburl       = {https://dblp.org/rec/journals/tacl/RamLDMSLS23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{robust_negation,
    title = "Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly",
    author = {Kassner, Nora  and
      Sch{\"u}tze, Hinrich},
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.698",
    doi = "10.18653/v1/2020.acl-main.698",
    pages = "7811--7818",
    abstract = "Building on Petroni et al. 2019, we propose two new probing tasks analyzing factual knowledge stored in Pretrained Language Models (PLMs). (1) Negation. We find that PLMs do not distinguish between negated ({`}{`}Birds cannot [MASK]{''}) and non-negated ({`}{`}Birds can [MASK]{''}) cloze questions. (2) Mispriming. Inspired by priming methods in human psychology, we add {``}misprimes{''} to cloze questions ({`}{`}Talk? Birds can [MASK]{''}). We find that PLMs are easily distracted by misprimes. These results suggest that PLMs still have a long way to go to adequately learn human-like factual knowledge.",
}

@inproceedings{robust_typo,
  author       = {Tim Hagen and
                  Harrisen Scells and
                  Martin Potthast},
  editor       = {Yaser Al{-}Onaizan and
                  Mohit Bansal and
                  Yun{-}Nung Chen},
  title        = {Revisiting Query Variation Robustness of Transformer Models},
  booktitle    = {Findings of the Association for Computational Linguistics: {EMNLP}
                  2024, Miami, Florida, USA, November 12-16, 2024},
  pages        = {4283--4296},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.findings-emnlp.248},
  timestamp    = {Mon, 18 Nov 2024 09:05:59 +0100},
  biburl       = {https://dblp.org/rec/conf/emnlp/HagenSP24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{rome,
  author       = {Kevin Meng and
                  David Bau and
                  Alex Andonian and
                  Yonatan Belinkov},
  editor       = {Sanmi Koyejo and
                  S. Mohamed and
                  A. Agarwal and
                  Danielle Belgrave and
                  K. Cho and
                  A. Oh},
  title        = {Locating and Editing Factual Associations in {GPT}},
  booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/6f1d43d5a82a37e89b0665b33bf3a182-Abstract-Conference.html},
  timestamp    = {Mon, 08 Jan 2024 16:31:36 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/MengBAB22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{streaming_qa,
  author       = {Adam Liska and
                  Tom{\'{a}}s Kocisk{\'{y}} and
                  Elena Gribovskaya and
                  Tayfun Terzi and
                  Eren Sezener and
                  Devang Agrawal and
                  Cyprien de Masson d'Autume and
                  Tim Scholtes and
                  Manzil Zaheer and
                  Susannah Young and
                  Ellen Gilsenan{-}McMahon and
                  Sophia Austin and
                  Phil Blunsom and
                  Angeliki Lazaridou},
  editor       = {Kamalika Chaudhuri and
                  Stefanie Jegelka and
                  Le Song and
                  Csaba Szepesv{\'{a}}ri and
                  Gang Niu and
                  Sivan Sabato},
  title        = {StreamingQA: {A} Benchmark for Adaptation to New Knowledge over Time
                  in Question Answering Models},
  booktitle    = {International Conference on Machine Learning, {ICML} 2022, 17-23 July
                  2022, Baltimore, Maryland, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {162},
  pages        = {13604--13622},
  publisher    = {{PMLR}},
  year         = {2022},
  url          = {https://proceedings.mlr.press/v162/liska22a.html},
  timestamp    = {Tue, 12 Jul 2022 17:36:52 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/LiskaKGTSAdSZYG22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{su-etal-2024-living,
    title = "Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?",
    author = "Su, Zhaochen  and
      Li, Juntao  and
      Zhang, Jun  and
      Zhu, Tong  and
      Qu, Xiaoye  and
      Zhou, Pan  and
      Bowen, Yan  and
      Cheng, Yu  and
      Zhang, Min",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.703/",
    doi = "10.18653/v1/2024.acl-long.703",
    pages = "13014--13033",
    abstract = "Temporal reasoning is fundamental for large language models (LLMs) to comprehend the world. Current temporal reasoning datasets are limited to questions about single or isolated events, falling short in mirroring the realistic temporal characteristics involving concurrent nature and intricate temporal interconnections. In this paper, we introduce CoTempQA, a comprehensive co-temporal Question Answering (QA) benchmark containing four co-temporal scenarios (Equal, Overlap, During, Mix) with 4,748 samples for evaluating the co-temporal comprehension and reasoning abilities of LLMs. Our extensive experiments reveal a significant gap between the performance of current LLMs and human-level reasoning on CoTempQA tasks. Even when enhanced with Chain of Thought (CoT) methodologies, models consistently struggle with our task. In our preliminary exploration, we discovered that mathematical reasoning plays a significant role in handling co-temporal events and proposed a strategy to boost LLMs' co-temporal reasoning from a mathematical perspective. We hope that our CoTempQA datasets will encourage further advancements in improving the co-temporal reasoning capabilities of LLMs."
}

@article{templama,
  author       = {Bhuwan Dhingra and
                  Jeremy R. Cole and
                  Julian Martin Eisenschlos and
                  Daniel Gillick and
                  Jacob Eisenstein and
                  William W. Cohen},
  title        = {Time-Aware Language Models as Temporal Knowledge Bases},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {10},
  pages        = {257--273},
  year         = {2022},
  url          = {https://doi.org/10.1162/tacl\_a\_00459},
  doi          = {10.1162/TACL\_A\_00459},
  timestamp    = {Fri, 21 Jun 2024 08:19:15 +0200},
  biburl       = {https://dblp.org/rec/journals/tacl/DhingraCEGEC22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{tempreason1_bench_temp_reason,
  title={Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models},
  author={Qingyu Tan and Hwee Tou Ng and Lidong Bing},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:259165281}
}

@inproceedings{tempreason1_mentaqa,
  title={MenatQA: A New Dataset for Testing the Temporal Comprehension and Reasoning Abilities of Large Language Models},
  author={Yifan Wei and Yisong Su and Huanhuan Ma and Xiaoyan Yu and Fangyu Lei and Yuanzhe Zhang and Jun Zhao and Kang Liu},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:263831019}
}

@inproceedings{tempreason_timequestions,
  author       = {Wenhu Chen and
                  Xinyi Wang and
                  William Yang Wang},
  editor       = {Joaquin Vanschoren and
                  Sai{-}Kit Yeung},
  title        = {A Dataset for Answering Time-Sensitive Questions},
  booktitle    = {Proceedings of the Neural Information Processing Systems Track on
                  Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December
                  2021, virtual},
  year         = {2021},
  url          = {https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/1f0e3dad99908345f7439f8ffabdffc4-Abstract-round2.html},
  timestamp    = {Thu, 04 Jul 2024 21:52:56 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/ChenWWW21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{verma-etal-2023-evaluating,
    title = "Evaluating Paraphrastic Robustness in Textual Entailment Models",
    author = "Verma, Dhruv  and
      Lal, Yash Kumar  and
      Sinha, Shreyashee  and
      Van Durme, Benjamin  and
      Poliak, Adam",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-short.76/",
    doi = "10.18653/v1/2023.acl-short.76",
    pages = "880--892",
    abstract = "We present PaRTE, a collection of 1,126 pairs of Recognizing Textual Entailment (RTE) examples to evaluate whether models are robust to paraphrasing. We posit that if RTE models understand language, their predictions should be consistent across inputs that share the same meaning. We use the evaluation set to determine if RTE models' predictions change when examples are paraphrased. In our experiments, contemporary models change their predictions on 8-16{\%} of paraphrased examples, indicating that there is still room for improvement."
}

@inproceedings{xiong-etal-2024-large,
    title = "Large Language Models Can Learn Temporal Reasoning",
    author = "Xiong, Siheng  and
      Payani, Ali  and
      Kompella, Ramana  and
      Fekri, Faramarz",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.563/",
    doi = "10.18653/v1/2024.acl-long.563",
    pages = "10452--10470",
    abstract = "While large language models (LLMs) have demonstrated remarkable reasoning capabilities, they are not without their flaws and inaccuracies. Recent studies have introduced various methods to mitigate these limitations. Temporal reasoning (TR), in particular, presents a significant challenge for LLMs due to its reliance on diverse temporal concepts and intricate temporal logic. In this paper, we propose TG-LLM, a novel framework towards language-based TR. Instead of reasoning over the original context, we adopt a latent representation, temporal graph (TG) that enhances the learning of TR. A synthetic dataset (TGQA), which is fully controllable and requires minimal supervision, is constructed for fine-tuning LLMs on this text-to-TG translation task. We confirmed in experiments that the capability of TG translation learned on our dataset can be transferred to other TR tasks and benchmarks. On top of that, we teach LLM to perform deliberate reasoning over the TGs via Chain-of-Thought (CoT) bootstrapping and graph data augmentation. We observed that those strategies, which maintain a balance between usefulness and diversity, bring more reliable CoTs and final results than the vanilla CoT distillation."
}

@inproceedings{zhang-choi-2021-situatedqa,
    title = "{S}ituated{QA}: Incorporating Extra-Linguistic Contexts into {QA}",
    author = "Zhang, Michael  and
      Choi, Eunsol",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.586/",
    doi = "10.18653/v1/2021.emnlp-main.586",
    pages = "7371--7387",
    abstract = "Answers to the same question may change depending on the extra-linguistic contexts (when and where the question was asked). To study this challenge, we introduce SituatedQA, an open-retrieval QA dataset where systems must produce the correct answer to a question given the temporal or geographical context. To construct SituatedQA, we first identify such questions in existing QA datasets. We find that a significant proportion of information seeking questions have context-dependent answers (e.g. roughly 16.5{\%} of NQ-Open). For such context-dependent questions, we then crowdsource alternative contexts and their corresponding answers. Our study shows that existing models struggle with producing answers that are frequently updated or from uncommon locations. We further quantify how existing models, which are trained on data collected in the past, fail to generalize to answering questions asked in the present, even when provided with an updated evidence corpus (a roughly 15 point drop in accuracy). Our analysis suggests that open-retrieval QA benchmarks should incorporate extra-linguistic context to stay relevant globally and in the future. Our data, code, and datasheet are available at \url{https://situatedqa.github.io/}."
}

@inproceedings{zhang-etal-2023-large,
    title = "How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances",
    author = "Zhang, Zihan  and
      Fang, Meng  and
      Chen, Ling  and
      Namazi-Rad, Mohammad-Reza  and
      Wang, Jun",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.516",
    doi = "10.18653/v1/2023.emnlp-main.516",
    pages = "8289--8311",
    abstract = "Although large language models (LLMs) are impressive in solving various tasks, they can quickly be outdated after deployment. Maintaining their up-to-date status is a pressing concern in the current era. This paper provides a comprehensive review of recent advances in aligning deployed LLMs with the ever-changing world knowledge. We categorize research works systemically and provide in-depth comparisons and discussions. We also discuss existing challenges and highlight future directions to facilitate research in this field.",
}

