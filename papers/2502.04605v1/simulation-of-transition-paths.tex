\documentclass[reqno]{amsart}
\usepackage{amsthm,amsmath,amssymb,mathrsfs,hyperref}
\usepackage{dsfont}
\usepackage[shortlabels]{enumitem}
\usepackage[dvipsnames]{xcolor}
\usepackage{graphicx}
\usepackage{cite}


% notes
\newcommand{\bvk}[1]{{\color{Bittersweet} BvK: #1}}

% general
\newcommand{\Real}{\mathbb{R}}
\newcommand{\eps}{\varepsilon}
\newcommand{\1}{\mathds{1}}

% linear algebra
\newcommand{\rg}{\text{Rg}}
\renewcommand{\t}{\text{t}}
\newcommand{\spn}{\text{span}}
\DeclareMathOperator{\tr}{tr}

% calculus
\renewcommand{\d}{\mathrm{d}}
\newcommand{\grad}{\nabla}
\newcommand{\lap}{\Delta}
\let\div\relax
\DeclareMathOperator{\div}{div}

% probability
\renewcommand{\P}{\mathds{P}}
\newcommand{\Q}{\mathds{Q}}
\newcommand{\E}{\mathds{E}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\G}{\mathcal{G}} 
\renewcommand{\L}{L}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\var}{var}
\newcommand{\normal}{\mathrm{N}}
\newcommand{\bernoulli}{\mathrm{Bernoulli}}
\newcommand{\dkl}{D_{\mathrm{KL}}}

% change of measure
\newcommand{\zed}{M}

% theorems
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\theoremstyle{definition}
\newtheorem{algorithm}{Algorithm}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}
\theoremstyle{remark}
\newtheorem{remark}{Remark}

% transition path process
\newcommand{\tp}{{\mathrm{tp}}}
\newcommand{\D}{\mathscr{T}}

% tubular neighborhood
\newcommand{\tub}{\mathscr{D}}

% importance sampling
\renewcommand{\O}{\mathcal{O}}

\title{Relative Entropy Methods for Calculating Committors}
\author{Gabriel Earle and Brian Van Koten}
\thanks{BvK and GE were supported by NSF DMS-2012207}

\begin{document}
\maketitle

\begin{abstract}
  Motivated by challenges arising in molecular simulation, we analyze and develop methods of computing reactive trajectories and committor functions for systems described by the overdamped Langevin dynamics. 
  Our main technical advance is a new loss function that measures the accuracy of approximations to the committor function describing a given chemical reaction or other rare transition event. The loss admits a simple interpretation in terms of the distribution of reactive trajectories, and it can be computed in practice to compare the accuracies of different approximations of the committor. We also derive a method of calculating committors by direct minimization of the loss via stochastic gradient descent.
\end{abstract}

\section{Introduction}

 Motivated by challenges arising in molecular simulation, we analyze and develop methods for computing reactive trajectories and committor functions. To be precise, we consider the stochastic differential equation~\eqref{eq: intro tpp} that characterizes reactive trajectories of the overdamped Langevin dynamics in the transition path theory of Weinan E and Eric Vanden-Eijnden~\cite{e_towards_2006}. We assess the effect of replacing the exact committor function $q$ in that equation with an approximation $\tilde q$, resulting in approximate reactive trajectories. Our primary theoretical advances are
  \begin{enumerate}
  \item a characterization of those $\tilde q$ for which solutions of~\eqref{eq: intro tpp} with $\tilde q$ in place of $q$ exist,
  \item a characterization of those $\tilde q$ for which the distributions of the exact and approximate reactive trajectories are mutually absolutely continuous, and 
  \item convenient formulas for the change of measure and relative entropy between the exact and approximate distributions for a given $\tilde q$.
  \end{enumerate}
  Surprisingly, the change of measure can be computed exactly without prior knowledge of the exact committor function $q$. Based on this observation, we propose novel computational methods, including
  \begin{enumerate}
  \item a stochastic gradient descent scheme for estimating committor functions that directly minimizes the relative entropy between the exact and approximate distributions of reactive trajectories, and
  \item a model assessment procedure for comparing approximate committor functions based on relative entropy differences as in the Bayes and Akaike information criteria.  
  \end{enumerate}
  
We limit our study to systems described by the \emph{overdamped Langevin dynamics}
\begin{equation}\label{eq: intro overdamped Langevin}
\d X_t = - \grad U (X_t) \, \d t + \sqrt{2 \eps} \,  \d B_t.
\end{equation}
In models of molecular systems, $X_t$ takes values in the space of positions $\Real^{3N}$ of the $N$ atomic nuclei comprising the system, $U: \Real^{3N} \rightarrow \Real$ is a potential energy, and $\eps = k_B T$ where $T>0$ is the temperature and $k_B$ is Boltzmann's constant. Each local minimum of $U$ corresponds to a stable state. When the temperature is low, the dynamics is \emph{metastable}~\cite{gayrard_metastability_2004}. That is, trajectories spend most of the time vibrating around stable states, undergoing transitions between states only rarely. 

Metastability entails severe computational difficulties. One usually wants to estimate statistics of rare transitions, but it may be impractical to compute a trajectory long enough to observe even one. For example, in simulations of proteins, resolving the fastest vibrations requires a time step no larger than $10^{-15} s$, but conformational changes may occur only every $10^{-6} s$ or less frequently. To overcome difficulties related to metastability, enhanced sampling methods have been devised that perturb or condition the dynamics~\eqref{eq: intro overdamped Langevin} so that transitions occur over short time scales. In various ways, these methods correct for the perturbations to consistently estimate observables of the unperturbed dynamics.

We consider a particular class of enhanced sampling methods based on \emph{Transition Path Theory} (TPT)~\cite{e_towards_2006,lu_reactive_2015}. In TPT, one studies transitions between a fixed pair of disjoint sets $A \subset \Real^{3N}$ and $B \subset \Real^{3N}$, e.g.\@ balls centered at different local minima of $U$ corresponding to different stable states. TPT characterizes \emph{reactive trajectories}, which are segments of trajectories of~\eqref{eq: intro overdamped Langevin} observed starting when they last leave $A$ and ending when they first hit $B$; see Figure~\ref{fig: tpp-schematic} and Section~\ref{sec: transition path theory} for a precise definition. The reactive trajectories have the same law as the \emph{transition path process}
\begin{equation}\label{eq: intro tpp}
  \d Y_t = - \grad U (X_t) \, \d t + 2 \eps \grad \log q(X_t) \, \d t + \sqrt{2 \eps} \,  \d B_t 
\end{equation}
where
\begin{equation*}
  q(x) = \P [\tau_B < \tau_A \vert X_0=x]
\end{equation*}
is the \emph{(forward) committor function}, i.e.\@ the probability that a trajectory of~\eqref{eq: intro overdamped Langevin} with $X_0=x$ will hit $B$ before $A$.
% When the Langevin dynamics is in the steady state, the initial state of the transition path process has the \emph{reactive flux distribution}
% \begin{equation*}
%     Y_0 \sim \nu^{-1} \lvert \grad q(x) \rvert \exp(-U(x)/\eps) \, \d S_A(x).
% \end{equation*}
The drift $2 \eps \grad \log q(Y_t)$ in~\eqref{eq: intro tpp} forces trajectories away from $A$ and towards $B$. As a result, in many cases, transitions between $A$ and $B$ occur much more quickly under~\eqref{eq: intro tpp} than they would under~\eqref{eq: intro overdamped Langevin}; cf.\@ Figure~\ref{fig: reactive-trajectory}.

There has been significant recent interest in sampling reactive trajectories by first computing an approximation $\tilde q$ to the committor function and then simulating trajectories of~\eqref{eq: tpp} with $\tilde q$ in place of $q$; see~\cite{yuan_optimal_2023} and numerical methods for computing committor functions such as~\cite{evans_computing_2022,gao_transition_2023,chen_committor_2023,khoo_solving_2018,li_computing_2019}. Such a procedure can be dramatically more efficient than the direct simulation of long trajectories to observe transitions, but the effect of the approximation of the committor on the law of the reactive trajectories has not been assessed. Our results in Sections~\ref{sec: change of measure formula} and~\ref{sec: applications} below provide a means of assessing and controlling the quality of the approximation in theory and practice. In Theorem~\ref{thm: complete change of measure from transition path process to simulated process}, we characterize the set of approximate committor functions $\tilde q$ for which the approximate process is absolutely continuous with respect to the exact process, and we derive a convenient formula for the change of measure between the exact and approximate processes.

Surprisingly, the change of measure can be computed explicitly, at least up to a normalizing constant, even when the exact committor function is unknown; cf.\@ equation~\eqref{eq: computable change of measure}. Considering Girsanov's theorem, one might expect the change of measure to depend on the difference in drifts $2\eps \grad \log q(Y_t) - 2 \eps \grad \log \tilde q (Y_t)$. In Section~\ref{sec: change of measure formula}, we show that one can totally eliminate the dependence on exact committor $q$. We propose several novel computational methods based on this observation. In Section~\ref{sec: training}, we derive a stochastic gradient descent method for computing committor functions by direct minimization of the relative entropy of the approximate process with respect to the exact process. Competing methods for estimating committors minimize loss functions that do not relate so closely to the law of the approximate transition path process. For example, Ritz methods minimize
\begin{equation*}
  J(\tilde q) := \int_{\Real^{3N} \setminus (A \cup B)} \lvert\grad \tilde q (x) \rvert^2 \exp(-U(x)/\eps) \, \d x
\end{equation*}
subject to $\tilde q=0$ on $\partial A$ and $\tilde q=1$ on $\partial B$~\cite{chen_committor_2023}. It is not clear how the value of the functional $J(\tilde q)$ relates to the discrepancy between the distributions of exact and approximate reactive trajectories. In that sense, it is not a such a natural loss function as our relative entropy. In Section~\ref{sec: selection}, we devise a model assessment procedure that compares approximate committor functions based on relative entropy differences as in the Bayes and Akaike information criteria. 

% Some potential applications of our results entail difficulties that we cannot currently resolve; cf.\@ Section~(CITE). For example, in principle, using our change of measure, one could compute consistent estimates of observables of the exact transition path process given a sample from the approximate process. In practice, the simplistic method of Section~(CITE) appears not to be robust. Similar importance sampling methods based on Girsanov's theorem are known to be tempermental under the best circumstances and intractable in many cases. However, some notable successes have been attained in the importance sampling of paths of diffusion processes over finite time scales (CITE Zhang, Marzouk, and Weare VE), and we hope that our results will facilitate the development of analogous methods for the importance sampling of transition paths.     

All applications of our results demand that extraordinary care be taken to correctly handle singularities. For example, since $q = 0$ on $\partial A$, the drift $2\eps \grad \log q (Y_t)$ in~\eqref{eq: tpp} is singular on $\partial A$, and standard numerical integrators may fail to converge. We have devised a weakly convergent operator splitting scheme for integrating~\eqref{eq: intro tpp} in the case where $\partial A$ is planar and the approximate committor function meets a certain boundary condition on $\partial A$. We will publish a numerical analysis of this integrator in a companion to the present article. We have not yet been able to devise a practical, provably convergent integrator that correctly handles the singularity on $\partial A$ in all cases. We also note that the change of measure formula~\eqref{eq: computable change of measure} involves an integral that may be singular, but we have devised a general means of treating the singularity and correctly computing the integral; cf.\@ Section~\ref{sec: numerical}.

\section{A Digest of Transition Path Theory}
\label{sec: transition path theory}

In this section, we present a brief review of \emph{transition path theory}~\cite{e_towards_2006,lu_reactive_2015}. As above, let $U: \Real^d \rightarrow \Real$ be a potential energy, describing for example a molecular system. Let $\eps = k_B T >0$ be a temperature parameter, and suppose that $X_t$ evolves according to the overdamped Langevin dynamics
\begin{equation}\label{eq: overdamped Langevin}
\d X_t = - \grad U (X_t) \, \d t + \sqrt{2 \eps} \,  \d B_t.
\end{equation}
Under certain conditions on $U$~\cite{lelievre_partial_2016}, the overdamped Langevin dynamics is ergodic for the Boltzmann distribution
\begin{equation*}
  \rho(\d x ) = Z^{-1} \exp(- U(x)/ \eps) \, \d x \text{ where } Z = \int_{\Real^d}  \exp(- U(x)/ \eps) \, \d x.
\end{equation*}
We assume ergodicity throughout this work. 

\begin{assumption}\label{asm: ergodicity}
For the given potential function $U$, the overdamped Langevin dynamics~\eqref{eq: overdamped Langevin} is ergodic. 
\end{assumption}


In transition path theory, to characterize rare transitions of the overdamped Langevin dynamics, one first chooses a disjoint pair of subsets $A$ and $B$ of $\Real^d$. In applications, $A$ and $B$ would usually be associated with metastable states, e.g.\@ they might be sets modeling different conformations of a biomolecule. In addition to the sets $A$ and $B$, we find it convenient to define the \emph{transition region}
\begin{equation*}
\D = \Real^d \setminus (A \cup B).
\end{equation*}
We impose the following assumptions on $A$, $B$, and $\D$.

\begin{assumption}\label{asm: submanifold assumption}
  We assume that $A$ and $B$ are disjoint, closed subsets of $\Real^d$ with nonempty interior. The boundaries of $A$ and $B$ are regular $C^\infty$-submanifolds of $\Real^d$. The transition region $\D$ is connected. 
\end{assumption}

\begin{figure}
  \caption{Schematic illustration of reactive trajectories, entrance times, and exit times. The black line depicts a trajectory of overdamped Langevin dynamics. The bold red segments depict reactive trajectories.  Here, $\tau_{B,0}$ is the first hitting time of $B$, $\tau_{A,1}$ is the first hitting time of $A$ after $\tau_{B,0}$, $\tau_{B,1}$ is the first hitting time of $B$ after $\tau_{A,1}$, and so forth. The $k$'th exit time $\sigma_{A,k}$ is the last time before $\tau_{B,k}$ that the process was in $A$.}
  \includegraphics[width=0.45\linewidth]{./tpp.pdf}
  \label{fig: tpp-schematic}
\end{figure}

\begin{figure}
  \caption{A trajectory of the overdamped Langevin dynamics for a simple two-dimensional model potential. The blue curves are contours of the potential. The trajectory depicted here was initialized from the Boltzmann distribution, i.e.\@ in equilibrium. Its starting point happened to be in the set $A$ on the left side of the figure. The trajectory was terminated on hitting the boundary of $B$ for the first time. The bold red curve depicts the end of the trajectory from the last time it left $A$ to the first time it entered $B$; i.e.\@ the reactive part of the trajectory. The faint red curve depicts the beginning of the trajectory up to the last time it left $A$.}
  \includegraphics[width=0.65\linewidth]{./reactive-trajectory-simulated.pdf}
  \label{fig: reactive-trajectory}
\end{figure}


Given a pair of sets $A$ and $B$, one defines sequences of \emph{entrance times}, \emph{exit times}, and \emph{reactive trajectories} as illustrated in Figure~\ref{fig: tpp-schematic}.
The entrance times are
\begin{align*}
  \tau_{A,0} &:= \inf \{ t \geq 0; X_t \in A\}, \\
  \tau_{B,0} &:= \inf \{ t \geq \tau_{A,0}; X_t \in B\}, 
\end{align*}
and for $k \geq 1$
\begin{align*}
  \tau_{A,k} &:= \inf \{ t \geq \tau_{B,k-1}; X_t \in A\}, \\
  \tau_{B,k} &:= \inf \{ t \geq \tau_{A,k-1}; X_t \in B\}.
\end{align*}
The exit times are
\begin{align*}
  \sigma_{A,0} &:= \sup \{ \tau_{A_0} \leq t \leq \tau_{B,0}; X_t \in A\}, \\
  \sigma_{B,0} &:= \sup \{\tau_{B,0} \leq  t \leq \tau_{A,1}; X_t \in B\}, 
\end{align*}
and for $k \geq 1$
\begin{align*}
  \sigma_{A,k} &:= \sup \{ \tau_{A,k} \leq t \leq \tau_{B,k}; X_t \in A\}, \\
  \sigma_{B,k} &:= \sup \{\tau_{B,0} \leq  t \leq \tau_{A,1}; X_t \in B\}.
\end{align*}
The $k$'th reactive trajectory (or transition path) $Y^k_t$ is the segment of the random path $X_t$ between the $k$'th exit time $\sigma_{A,k}$ from $A$ and the $k$'th entrance time $\tau_{B,k}$ to $B$. That is,
\begin{equation*}
Y^k_t := X_{\sigma_{A,k} + t} \text{ for } t \in [0, \tau_{B,k} - \sigma_{A,k}]. 
\end{equation*}

Transition path theory characterizes the distribution of reactive trajectories in terms of the \emph{committor function} 
\begin{equation*}
  q(x) := \P[ \tau_B < \tau_A \vert X_0 = x].
\end{equation*}
Here, $\tau_A$ and $\tau_B$ are the first hitting times of $A$ and $B$ for $X_t$, so $q(x)$ is the probability of hitting $B$ before $A$ when starting from $x$. 
In~\cite{lu_reactive_2015}, Lu and Nolen verified that if the overdamped Langevin dynamics is in the steady state with $X_t \sim \rho$ for all $t \geq 0$, then the reactive trajectories have the same distribution as the solution of the \emph{transition path equation}
\begin{equation}\label{eq: tpp}
    \d Y_t = -\grad U (Y_t) \, \d t + 2 \eps \grad \log q(Y_t) \, \d t + \sqrt{2 \eps} \, \d B_t
\end{equation}
where $Y_0$ has the \emph{reactive flux distribution}
\begin{equation}\label{eq: reactive flux distribution}
  Y_0 \sim \frac{1}{\nu} \lvert  \grad q(x) \rvert \exp(-U(x)/\eps) \, \d S(x). 
\end{equation}
Here, $S$ is the surface measure on $\partial A$, and
\begin{equation*}
  \nu = \int_{\partial A} \lvert  \grad q(x) \rvert \exp(-U(x)/\eps) \, \d S(x).
\end{equation*}

Observe that the transition path equation is the overdamped Langevin dynamics with the additional drift term $2 \eps \grad \log q(X_t) \, \d t$. On $\partial A$, we have $q = 0$, and by Lemma~\ref{lem: properties of committor} below, $\lvert \grad q \rvert >0$. Therefore, the drift $\grad \log q = \frac{\grad q}{q}$ is singular on $\partial A$. Despite the singularity, Lu and Nolen showed that a unique strong solution of~\eqref{eq: tpp} exists for any initial distribution, even distributions supported on $\partial A$. Moreover, with probability one, $X_t \notin A$ for $t >0$. In effect, the singular drift repels trajectories from $A$, forcing transitions to occur. 

\begin{remark}
One can derive~\eqref{eq: tpp} formally by conditioning the overdamped Langevin dynamics on hitting $B$ before $A$ using the Doob $h$-transform. This approach does not establish a definite connection with reactive trajectories or the existence of strong solutions. 
\end{remark}

The committor solves the elliptic boundary value problem
\begin{equation}\label{eq: elliptic commitor equation}
  \begin{cases}
    L q = 0 &\text{ in } \D, \\
    q=0 &\text{ on } \partial A, \\
    q = 1 &\text{ on } \partial B,\
  \end{cases}
\end{equation}
where
\begin{equation*}
L := - \grad U \cdot \grad + \eps \lap
\end{equation*}
is the generator of the overdamped Langevin dynamics~\cite{e_towards_2006}.  Therefore, under our smoothness assumptions on $U$ and $\D$, elliptic regularity, the Hopf lemma, and the maximum principle imply the properties of the committor listed in Lemma~\ref{lem: properties of committor} below. 

\begin{assumption}\label{asm: smoothness of potential}
We assume that the potential energy $U: \Real^d \rightarrow \Real$ is infinitely differentiable, but we do not assume that $U$ or any of its derivatives are bounded. 
\end{assumption}

\begin{lemma}
  \label{lem: properties of committor}
  Under Assumptions~\ref{asm: submanifold assumption} and~\ref{asm: smoothness of potential}, the forward committor function $q: \D \rightarrow [0,1]$ extends to an infinitely differentiable function defined on an open set containing $\partial A$ and $\partial B$. By abuse of notation, we let $q$ refer to both the committor function and the extension.
  For all $x \in \mathring{\D}$,
  \begin{equation*}
    q(x) >0.
  \end{equation*}
  For all $x \in \partial A$,
  \begin{equation*}
    \grad q(x)\cdot n(x) = \lvert \grad q(x) \rvert > 0,
  \end{equation*}
  where $n(x)$ is the outward unit normal to $A$ at $x$. 
\end{lemma}


\begin{proof}
  By elliptic regularity, there exists an infinitely differentiable extension of $q$ to an open set containing $\overline{\D}$. We have $\grad q(x)\cdot n(x) >0$ for $x \in \partial A$ by the Hopf Lemma, and $q(x) >0$ in the interior of $\D$ by the maximum principle. Moreover, since $q$ is constant on $\partial A$ and $\grad q(x) \cdot n(x) >0$, $\grad q(x) = \lvert \grad q(x) \rvert n(x)$.  
\end{proof}


\begin{remark}\label{rem: smoothness of q}
  It is conventional to take the domain of the committor to be $\Real^d$ instead of $\D$, letting $q=0$ on $A$ and $q=1$ on $B$. \emph{This extension of $q$ does not coincide with the smooth extension described in Lemma~\ref{lem: properties of committor}}. Any smooth extension must take negative values at some points in the interior of $A$ since $\grad q \cdot n >0$ and $q =0$ on $\partial A$. Moreover, observe that for our smooth extension, $Lq=0$ everywhere in $\bar \D$, including on $\partial A$. In the original work on transition state theory, $Lq$ was instead understood as a distribution supported on $\partial A \cup \partial B$. We require a smooth extension only to simplify the notation in certain proofs. None of our results depends on a particular choice of extension. 
\end{remark}

\section{A Change of Measure Formula for Approximations to the Transition Path Process}
\label{sec: change of measure formula}

We analyze the errors that result when one substitutes an approximation $\tilde q$ of the committor in the transition path equation~\eqref{eq: tpp}. To be precise, in Theorem~\ref{thm: complete change of measure from transition path process to simulated process} below, we present a change of measure formula relating the distribution of solutions of the approximate transition path equation 
\begin{equation}
  \label{eq: approximate tpp}
  \d Y_t = -\grad U (Y_t) \, \d t + 2 \eps \grad \log \tilde q(Y_t) \, \d t + \sqrt{2 \eps}\, \d B_t
\end{equation}
with the exact transition path process. To derive the change of measure, motivated by Lemma~\ref{lem: properties of committor}, we impose the following assumptions on the approximate committor $\tilde q$.

\begin{assumption}\label{asm: properties of approximate committor}
  Let $\tilde q : \D \rightarrow \Real$ be an approximation to the committor with the following properties:
  \begin{enumerate}[1)]
  \item $\tilde q$ extends to an infinitely differentiable function defined on an open set containing $\partial A$ and $\partial B$. 
  \item $\tilde q(x) = 0$ for all $x \in \partial A$.
    \item $\grad \tilde q(x) \cdot n(x) >0$ for all $x \in \partial A$ where $n(x)$ is the outward unit normal to $A$ at $x$.
  \end{enumerate}
\end{assumption}

We now show that when an approximate committor $\tilde q$ has the properties outlined above, the ratio $\frac{\tilde q}{q}$ must be smooth in a neighborhood of $\partial A$. This will be the crucial property in deriving sufficient conditions for a change of measure.  

\begin{lemma} \label{lem: ratio function is smooth}
  Let $q$ be the forward committor. Let $\tilde q$ be an approximation to $q$ having the properties outlined in Assumption~\ref{asm: properties of approximate committor}.
  The function
  \begin{equation*}
    r(x) = \frac{\tilde q(x)}{q(x)}
  \end{equation*}
  defined for $x \in \mathring{\D}$ extends to a function in $C^\infty(\overline{\D})$. By abuse of notation, we let $r$ denote both the function and its extension. For $x \in \partial A$, we have
  \begin{equation*}
     r(x) = \frac{\lvert \grad \tilde q(x) \rvert}{\lvert \grad q(x) \rvert} = \frac{\grad \tilde q(x) \cdot n(x)}{\grad q(x) \cdot n(x)}.
  \end{equation*}
\end{lemma}

\begin{proof}
  Under Assumption~\ref{asm: submanifold assumption}, there exists a tubular neighborhood of $\partial A$. That is, there exist an open set $\tub$ containing $\partial A$, an infinitely differentiable retraction $\rho : \tub \rightarrow \partial A$, and an infinitely differentiable mapping $h: \tub \rightarrow \Real$ so that for any $x \in \tub$, 
\begin{equation*}
  x = \rho(x) + h(x) n(\rho(x))
\end{equation*}
where $n(y)$ is the outward unit normal to $A$ at $y \in \partial A$.  To simplify notation, we define
\begin{equation*}
  \bar x := \rho(x),
\end{equation*}
and we sometimes write $h$ and $n$ for $h(x)$ and $n(\rho(x))$. We choose $\tub$ so that $\tub$ and $B$ are disjoint. 

  Since $\tilde q >0$ on $\D \cup \partial B$, $r$ is smooth in an open neighborhood of any point in $\D \cup \partial B$. It will suffice to show that $r$ is smooth up to $\partial A$. 
  Let $x \in \tub$. 
  By Taylor's theorem and Lemma~\ref{lem: properties of committor},
  \begin{align*}
    q(x) &= q(\bar x + h n) \\
         &= q(\bar x) + (\grad q(\bar x) \cdot n)h + h^2 \int_{s=0}^1 n^t D^2 q(\bar x + shn) n (1-s) \, \d s \\
    &= \lvert \grad q(\bar x) \rvert h +  h^2 \int_{s=0}^1 n^t D^2 q(\bar x + shn) n (1-s) \, \d s.
  \end{align*}
  Similarly, we have
  \begin{equation*}
    \tilde q(x) = \lvert \grad \tilde q(\bar x) \rvert h +  h^2 \int_{s=0}^1 n^t D^2 \tilde q(\bar x + shn) n (1-s) \, \d s,
  \end{equation*}
  since the proof of Lemma~\ref{lem: properties of committor} verifies that $\grad \tilde q(\bar x) = \lvert \grad \tilde q(\bar x) \rvert n$ under our assumptions on $\tilde q$.
   Therefore,
  \begin{equation*}
    \frac{\tilde q( x)}{q( x)}
    =
    \frac{\lvert \grad \tilde q(\bar x) \rvert}{\lvert \grad q(\bar x) \rvert}
    \frac{1+ \frac{h}{\lvert \grad \tilde q(\bar x) \rvert}  \int_{s=0}^1 n^t D^2 \tilde q(\bar x + shn) n (1-s) \, \d s }{1+\frac{h}{\lvert \grad q(\bar x) \rvert}  \int_{s=0}^1 n^t D^2  q(\bar x + shn) n (1-s) \, \d s}.
  \end{equation*}
  The result follows since $\bar x$ and $h$ are smooth functions of $x$, $\tilde q$ and $q$ are in $C^\infty(\overline{\Omega})$, and $\lvert \grad \tilde q(\bar x) \rvert$ and $\lvert \grad \tilde q(\bar x) \rvert$ are positive. 
\end{proof}

Lemma~\ref{lem: ratio function is smooth} implies that $\log r$ and $\grad \log r$ are smooth and bounded in a neighborhood of any point on $\partial A$, since $\lvert \grad q (x) \rvert >0$ for all $x \in \partial A$ by Lemma~\ref{lem: properties of committor}. If $\grad \log r$ is in fact globally bounded, then the Novikov condition stated in Assumption~\ref{asm: novikov} below holds, and Girsanov's theorem guarantees a change of measure. 

\begin{assumption}\label{asm: novikov}
   For any $t >0$, we have the Novikov condition
  \begin{equation*}
    \Q \left [ \exp \left (\eps \int_0^t \lvert \grad \log r(X_s) \rvert^2 \, \d s \right ) \right ] < \infty.
  \end{equation*}
\end{assumption}

Establishing or assuming a global bound on $\grad \log r$ seems to us to be the most practical means of verifying the Novikov condition and the existence of a change of measure. For example, a global bound on $\grad \log r$ follows from Assumption~\ref{asm: properties of approximate committor} and Lemma~\ref{lem: ratio function is smooth} when $\D$ is bounded.  We note, however, that a global bound is only a convenient sufficient condition, not necessary, for the results below. 

% First of all, Novikov's condition is itself only a sufficient condition for a change of measure. Second, Novikov's condition does not imply that $\grad \log r$ is bounded even in a neighborhood of $\partial A$. Therefore, it is not in fact necessary that Assumption~\ref{asm: properties of approximate committor} hold. Assumption~\ref{asm: novikov} is merely a convenient sufficient condition that can be guaranteed in practice by requiring $\tilde q$ to have a certain functional form; cf.\@ (CITE). If one assumes in addition that $\overline{\Omega}$ is compact, then Assumption~\ref{asm: properties of approximate committor} implies a global bound on $\grad \log r$ and therefore Novikov's condition. 

 To state our change of measure, we require some additional notation to properly specify the probability space on which the exact and approximate transition path processes are defined. Let $B_t$ be a $d$-dimensional standard Brownian motion on the probability space $(\Omega, \F, \Q)$, and suppose that $Y_0$ is a random variable on $(\Omega, \F)$ taking values in $\overline{\D}$ and independent of $B_t$. Let $\F_t$ be the filtration generated by $B_t$ and $Y_0$. In~\cite{lu_reactive_2015}, it is shown that a strong solution of
\begin{equation}\label{eq: sde for tpp}
  dY_t = -\grad U(Y_t) \, \d t + 2 \eps \grad \log q(Y_t) \, \d t + \sqrt{2\eps} \, \d B_t
\end{equation}
exists with initial value $Y_0$. 
Under our assumptions, Girsanov's theorem yields a change of measure relating the transition path process~\eqref{eq: sde for tpp} to a weak solution of the approximate transition path equation
\begin{equation*}
  \d Y_t = -\grad U (Y_t) \, \d t + 2 \eps \grad \log \tilde q(Y_t) \, \d t + \sqrt{2 \eps} \, \d B_t.
\end{equation*}

\begin{lemma}\label{lem: impractical general change of measure formula}
 Let Assumptions~\ref{asm: submanifold assumption},~\ref{asm: smoothness of potential},~\ref{asm: properties of approximate committor}, and~\ref{asm: novikov} hold. Let $Y_t$ and $Y_0$ be as described in the previous paragraph. The process
  \begin{equation}\label{eqn: first formula for z}
    \zed_t := \exp \left ( \int_0^t \sqrt{2 \eps} \grad \log r(Y_s) \cdot \d B_s - \frac12 \int_0^t \lvert \sqrt{2 \eps} \grad \log r(Y_s) \rvert^2 \, \d s \right )
  \end{equation}
  is a positive $\F_t$-martingale under $\Q$ with $\Q [\zed_t] = 1$ for all $t\geq 0$. Therefore, there exists a probability measure $\P$ on $(\Omega, \F)$ so that for any fixed $T>0$,
  \begin{equation*}
    \left . \frac{\d \P}{\d \Q} \right \rvert_{\F_T} = \zed_T.
  \end{equation*}
  Define the process $W_t$  by
  \begin{equation*}
     \sqrt{2 \eps} W_t := Y_t - Y_0 - \int_0^t -\grad U(Y_s) + 2 \eps\grad \log \tilde q(Y_s) \, \d s
   \end{equation*}
   so that $Y_t$ solves
   \begin{equation*}
    \d Y_t =  -\grad U(Y_t) \, \d t + 2 \eps \grad \log \tilde q(Y_t) \, \d t + \sqrt{2 \eps} \, \d W_t.
  \end{equation*}
  Under $\P$, $\{W_t\}_{t=0}^T$ has the law of a standard Brownian motion.
\end{lemma}

\begin{proof}
  The above merely restates Girsanov's theorem. Observe that Girsanov's theorem holds even when the drift is singular. Only some form of Novikov's condition is required. 
\end{proof}

\begin{remark}[Weak Solutions of the Approximate Transition Path Equation]
Lemma~\ref{lem: impractical general change of measure formula} establishes the existence of at least a weak solution to 
\begin{equation*}
  \d Y_t =  -\grad U(Y_t)\, \d t + 2 \eps \grad \log \tilde q(Y_t) \, \d t + \sqrt{2 \eps} \, \d B_t
\end{equation*}
with arbitrary initial distribution supported on $\partial A$ even though $\grad \log \tilde q$ is singular on $\partial A$. We do not verify the existence of strong solutions. However, we suspect that one could do so based on arguments roughly similar to those used in~\cite{lu_reactive_2015} to construct strong solutions of the transition path equation~\eqref{eq: tpp}.
\end{remark}

We now derive a formula for the change of measure that can be computed in practice. Observe that formula~\eqref{eqn: first formula for z} for $\zed_t$ cannot be computed without knowledge of the exact committor $q$. As a first step towards eliminating this dependence on the committor, we show that $\log q$ solves a Hamilton--Jacobi--Bellman equation. Results of this nature are standard; we include a proof only for the reader's convenience. 

\begin{lemma}\label{lem: hjb equation}
  For $x \in \mathring{\D}$,
  \begin{align*}
    0 &=-\grad U (x) \cdot \grad \log q(x) + \eps \lap \log q(x) + \eps \lvert \grad \log q (x) \rvert^2 \\
      &= \L \log q (x) + \eps \lvert \grad \log q(x) \rvert^2.
  \end{align*}
\end{lemma}

\begin{proof}
   Define 
  \begin{equation*}
    m(x):= \log q(x)
  \end{equation*}
  for $x \in \Omega$. We have 
  \begin{align*}
    0&= \L q \\
     &= -\grad U \cdot \grad q + \eps \lap q \\
     &= - \grad U \cdot \grad \exp(m ) + \eps \lap \exp(m) \\
     &= \exp(m) ( -\grad U  \cdot \grad m + \eps \lap m + \eps \lvert \grad m\rvert^2 )
  \end{align*}
  on $x \in \mathbb{R}^d \setminus (A \cup B)$, which implies the result since $\exp(m)$ must be positive.
\end{proof}

We use the Hamilton--Jacobi--Bellman equation in Lemma~\ref{lem: hjb equation} to eliminate $q$ from the exponential factor in formula~\eqref{eqn: first formula for z} for $\zed_t$. 

\begin{lemma}\label{lem: second impractical change of measure formula}
  Under the hypotheses of Lemma~\ref{lem: impractical general change of measure formula}, and assuming $Y_0$ takes values in $\partial A$,  we have
  \begin{align}
    \zed_t&= \frac{\lvert \grad  q (Y_0) \rvert}{\lvert   \grad \tilde q (Y_0) \rvert} \frac{\tilde q(Y_t)}{q(Y_t)} \exp \left (-\int_0^t  \L \log \tilde q (Y_s)  + \eps  \lvert \grad \log \tilde q(Y_s) \rvert^2 \, \d s  \right ) \nonumber \\
    &= \frac{\lvert \grad  q (Y_0) \rvert}{\lvert \grad \tilde q (Y_0) \rvert} \frac{\tilde q(Y_t)}{q(Y_t)} \exp \left (-\int_0^t \frac{L \tilde q}{\tilde q}(Y_s) \, \d s  \right ) \label{eqn: second formula for zt}
  \end{align}
  for $t>0$ and $\zed_0=1$. 
\end{lemma}

\begin{proof}
  First, we derive an alternative expression for the integral with respect to $\d B_s$ that appears in formula~\eqref{eqn: first formula for z} for $\zed_t$.  By the Ito formula, for any $g \in C^2(\Real^d ; \Real)$, we have
  \begin{align*}
    \d g(Y_t) &= \grad g(Y_t)^t \d Y_t + \frac12 \d Y_t^t D^2g(Y_t) \d Y_t \\
              &= \L g (Y_t) \, \d t + 2 \eps \grad \log q(Y_t)^t \grad g(Y_t) \, \d t +  \sqrt{2 \eps}\grad g(Y_t)^t \d B_t,
  \end{align*}
  so
  \begin{align*}
    \sqrt{2 \eps} \int_0^t \grad g(Y_s)^t \d B_s = g(Y_t) - g(Y_0) - \int_0^t   \L g (Y_s) + 2 \eps \grad \log q(Y_s)^t \grad g(Y_s) \, \d s.
  \end{align*}
  Applying the above with $g = \log r$ and using Lemma~\ref{lem: ratio function is smooth}, we have for $t >0$ that 
  \begin{align*}
    \zed_t &= \frac{r(Y_t)}{r(Y_0)} \exp \left (-\int_0^t  \L \log r(Y_s) + 2 \eps \grad \log q(Y_s)^t  \grad \log r(Y_s) + \eps \lvert \grad \log r(Y_s) \rvert^2 \, \d s  \right ) \\
    &= \frac{\lvert \grad  q (Y_0) \rvert}{\lvert  \tilde \grad q (Y_0) \rvert} \frac{\tilde q(Y_t)}{q(Y_t)} \\
    &\quad \times
           \exp \left (-\int_0^t  \L \log r(Y_s) + 2 \eps \grad \log q(Y_s)^t  \grad \log r(Y_s) + \eps \lvert \grad \log r(Y_s) \rvert^2 \, \d s  \right ). 
  \end{align*}
  By Lemma~\ref{lem: hjb equation},
  \begin{align*}
    &\L \log r + 2 \eps \grad \log q \cdot \grad \log r + \eps \lvert \grad \log r \rvert^2 \\
    &\qquad = \L \log \tilde q - \L \log q + 2 \eps \grad  \log q \cdot \grad \log \tilde q - 2 \eps \lvert \grad \log q \rvert^2 \\
    &\qquad \qquad+ \eps \lvert \grad \log \tilde q \rvert^2 + \eps \lvert \grad \log q \rvert^2 - 2 \eps \grad  \log q \cdot \grad \log \tilde q \\
    &\qquad = \L \log \tilde q + \frac12 \lvert \grad \log \tilde q \rvert^2.
  \end{align*}
  Thus, 
  \begin{equation*}\label{eq: first formula for zxt}
    \zed_t= \frac{\lvert \grad  q (Y_0) \rvert}{\lvert  \tilde \grad q (Y_0) \rvert} \frac{\tilde q(Y_t)}{q(Y_t)} \exp \left (-\int_0^t  \L \log \tilde q (Y_s)  + \eps \lvert \grad \log \tilde q(Y_s) \rvert^2 \, \d s  \right ).
  \end{equation*}
  Here, for $t>0$, we have $Y_t \in \mathring{\D}$ with probability one, so $q(Y_t) >0$, and the right-hand-side of the equation above is well-defined.  In addition, $\zed_0=1$ by~\eqref{eqn: first formula for z}. This verifies the first formula for $\zed_t$ in the statement of the lemma.
  The second formula follows from the first and the identity
  \begin{align*}
    L \log \tilde q &= \eps \lap \log  \tilde q - \grad U \cdot \grad \log \tilde q \\
    % &= \eps \frac{\lap \tilde q}{\tilde q} - \eps  \lvert \grad \log \tilde q \rvert^2 - \grad U \cdot \grad \log \tilde q \\
    &= \frac{L \tilde q}{\tilde q}  - \eps  \lvert \grad \log \tilde q \rvert^2.
  \end{align*}
\end{proof}

We must now eliminate the factors $\lvert \grad q(Y_0) \rvert$ and $q(Y_t)$ from the change of measure formula~\eqref{eqn: second formula for zt}. To get rid of $q(Y_t)$, we simply stop observing the process at the first hitting time $\tau$ of $B$; note that $Y_\tau \in \partial B$, so $q(Y_\tau)= 1$. Observing the process up to time $\tau$ corresponds to restricting the measures $\P$ and $\Q$ to the stopping time $\sigma$-algebra defined below.

\begin{definition}
  Let $\tau$ be the first hitting time of $B$ for the process $Y_t$ solving~\eqref{eq: sde for tpp}. Let $\F_\tau$ be the stopping time $\sigma$-algebra of $\tau$, i.e.
  \begin{equation*}
    \F_\tau := \{ A \in \F: A \cap \{ \tau \leq t\} \in \F_t \text{ for all } t \geq 0 \}.
  \end{equation*}
\end{definition}

For Theorem~\ref{thm: complete change of measure from transition path process to simulated process} below to hold, $\tau$ must be finite for both the exact and approximate transition path processes. Assumption~\ref{asm: ergodicity} on the ergodicity of the overdamped Langevin dyanmics implies that the exact transition path process hits $B$, since $B$ has positive Lebesgue measure. That is, $\Q[\tau < \infty] = 1$. We assume that that $\tau$ is finite for the approximate process as well. 

\begin{assumption}\label{asm: finite hitting time}
  We assume that 
  \begin{equation*}
     \P[\tau < \infty] = 1
  \end{equation*}
  for any initial value $Y_0$ supported in $\overline{\D}$. Recall that $\P$ is the measure introduced in Lemma~\ref{lem: impractical general change of measure formula} under which $Y_t$ is a weak solution of the approximate transition path equation~\eqref{eq: approximate tpp}.
\end{assumption}

We eliminate $\lvert \grad q(Y_0)\rvert$ from~\eqref{eqn: second formula for zt} by taking $Y_0$ to have the reactive flux distribution under $\Q$. In that case, the factor $\lvert \grad q(Y_0) \rvert$ in the reactive flux~\eqref{eq: reactive flux distribution} cancels with the one in~\eqref{eqn: second formula for zt}. Everything that remains in the change of measure can be computed without knowing the exact committor $q$, except for a normalizing constant. The result is formula~\eqref{eq: computable change of measure} in Theorem~\ref{thm: complete change of measure from transition path process to simulated process}.

\begin{theorem}\label{thm: complete change of measure from transition path process to simulated process}
  Let Assumptions~\ref{asm: ergodicity}-~\ref{asm: finite hitting time} hold. 
  Let $B_t$ be a $d$-dimensional standard Brownian motion on the probability space $(\Omega, \F, \Q)$. Let $Y_0$ be a random variable on $(\Omega, \F)$ that has the reactive flux distribution 
  \begin{equation*}
    Y_0 \sim  \frac{1}{\nu} \lvert  \grad q(x) \rvert \exp(-U(x)/\eps) \, \d S_A(x),
  \end{equation*}
  and assume that $Y_0$ is independent of $B_t$ under $\Q$. Let $\F_t$ be the filtration generated by $B_t$ and $Y_0$. Suppose that $Y_t$ solves the transition path equation
  \begin{equation*}
    \d Y_t = -\grad U(Y_t) \, \d t + 2 \eps \grad \log q(Y_t) \, \d t + \sqrt{2 \eps} \,  \d B_t
  \end{equation*}
  with initial condition $Y_0$. Now let $\tilde q$ be an approximation to the committor $q$, and let $m: \partial A \rightarrow [0,\infty)$ be an unnormalized density over $\partial A$ that approximates the reactive flux distribution.
    Let
  \begin{equation*}
    \mu = \int_{\partial A} m(x) \,  \d S_A (x)
  \end{equation*}
  be the normalizing constant of $m$. 
  For $t >0$, define
  \begin{equation*}
    Z_t := \frac{\nu}{\mu} \frac{\tilde q(Y_t)}{q(Y_t)} \frac{ m(Y_0)}{\lvert \grad \tilde q (Y_0) \rvert \exp(-U(Y_0)/\eps)}\exp \left (-\int_0^t  \frac{L \tilde q}{\tilde q}(Y_s)\, \d s \right ),
  \end{equation*}
  and let
  \begin{equation*}
    Z_0 :=  \frac{\nu}{\mu} \frac{ m(Y_0)}{\lvert \grad q (Y_0) \rvert \exp(-U(Y_0)/\eps)}.
  \end{equation*}
  The process $Z_t$ is a nonnegative $\F_t$-martingale with $\Q[ Z_t]=1$ for all $t \geq 0$, so there exists a probability measure $\P$ on $(\Omega, \F)$ with
  \begin{equation*}
    \left . \frac{\d \P}{\d \Q} \right \rvert_{\F_t} = Z_t
  \end{equation*}
  for all $t \geq 0$. 
  Under $\P$,
  \begin{equation*}
    W_t :=   Y_{t} - Y_0 - \int_0^{t} - \grad U (Y_s) + 2 \eps \grad \log \tilde q(Y_s) \, \d s
  \end{equation*}
  is a Brownian motion and $Y_0 \sim \mu^{-1} m(x) \, \d S_A(x)$. 
  The density of $\P$ restricted to the stopping time $\sigma$-algebra $\F_\tau$ is
  \begin{equation}\label{eq: computable change of measure}
     \left . \frac{\d \P}{\d \Q} \right \rvert_{\F_\tau} = Z_\tau =  \frac{\nu}{\mu} \tilde q(Y_\tau) \frac{ m(Y_0)}{\lvert \grad \tilde q (Y_0) \rvert \exp(-U(Y_0)/\eps)}\exp \left (-\int_0^\tau  \frac{L \tilde q}{\tilde q}(Y_s)\, \d s \right ).
  \end{equation}
\end{theorem}

\begin{proof}
See Appendix~\ref{apx: change of measure formula}.
\end{proof}

\section{Applications of the Change of Measure}
\label{sec: applications}

In this section, we consider two applications of the change of measure formula: \emph{selection} and \emph{training}. By training, we mean the minimization of the relative entropy $\dkl ( \P \Vert \Q)$ of the approximate transition path process with respect to the exact process over a family of approximate committor functions. By selection, we mean the comparison of different approximations to the committor function based on relative entropy differences. This is somewhat similar to model selection based on the Bayes and Akaike information criteria except that we do not consider penalizing model complexity. We also speculate on two other possibilities: \emph{error estimation} and \emph{importance sampling}. By error estimation, we mean the direct estimation of $\dkl(\P \Vert \Q)$. By importance sampling, we mean the unbiased estimation of observables of the exact process given a sample of paths of the approximate process. Error estimation and importance sampling entail difficulties that we cannot completely resolve at this time; see Section~\ref{sec: numerical} for details.

\subsection{Relative Entropy}
\label{sec: relative entropy in path space}

In general, if $P$ and $Q$ are probability measures on the same measurable space, one defines the \emph{relative entropy} (or Kullback--Leibler divergence) of $P$ with respect to $Q$ as follows.

\begin{definition}[Relative entropy]
  If $P$ and $Q$ are  probability measures on $(S, \mathscr{S})$ and $P$ is absolutely continuous with respect to $Q$, we define the \emph{relative entropy} of $P$ with respect to $Q$ by
  \begin{equation*}
    \dkl(P \Vert Q) := Q \left [ \frac{\d P}{\d Q} \log \left ( \frac{\d P}{\d Q} \right )  \right ] = P \left [\log \left ( \frac{\d P}{\d Q} \right ) \right ]. 
  \end{equation*}
  If $P$ is not absolutely continuous with respect to $Q$, $\dkl(P \Vert Q) := \infty$. 
\end{definition}

The relative entropy is widely used in machine learning and statistics to measure discrepancies between distributions. In particular, maximum likelihood estimation can be understood as relative entropy minimization. The relative entopy is not symmetric and the triangle inequality does not hold, so it is not a metric. However, $\dkl (P \Vert Q) \geq 0$ for all $P$ and $Q$, and $\dkl (P \Vert Q)=0$ implies $P =Q$. Moreover, $\dkl (P \Vert Q)$ relates to some well-known metrics. For example, Pinsker's inequality bounds the total variation distance in terms of $\dkl$:
\begin{equation*}
  \lVert P-Q \rVert_{\mathrm{TV}}= \max_{A \in \mathscr{S}} \, \lvert P(A)- Q(A) \rvert \leq \sqrt{\frac12 \dkl(P \Vert Q)}.
\end{equation*}
%Refer to (CITE) for a detailed exposition of properties of $\dkl$. 

By abuse of notation, throughout the rest of this work, we will write $\P$ and $\Q$ for the restrictions of $\P$ and $\Q$ to the stopping time $\sigma$-algebra $\F_\tau$. In other words, we will stop observing the process $Y_t$ when it hits $B$ at time $\tau$. 
By formula~\eqref{eq: computable change of measure} in Theorem~\ref{thm: complete change of measure from transition path process to simulated process}, we have
\begin{align}
  \dkl(\P \Vert \Q) %&= \E_\Q \left [ \frac{\d \P_{\theta, \phi}}{\d \Q}  \log \left ( \frac{\d \P_{\theta, \phi}}{\d \Q} \right ) \right ] \nonumber \\
                     &= \P \left [ \log \left ( \frac{\d \P}{\d \Q} \right ) \right ] \nonumber \\
                     &= \log \nu- \log \mu \nonumber \\
                     &\qquad + \int_{\partial A} \log \left ( \frac{ m(x)}{\lvert \grad  \tilde q (x) \rvert \exp(-U(x)/\eps)} \right ) \frac{m(x)}{\mu} \, \d S_A(x) \nonumber  \\
                     &\qquad + \P \left [\log \tilde q (Y_\tau)-\int_0^\tau  \frac{L  \tilde q}{\tilde q}(Y_s)\, \d s  \right ] \label{eqn: entropy of p given q}
\end{align}
and
\begin{align}
  \dkl( \Q \Vert \P) &= \Q \left [ \log \left ( \frac{\d \Q}{\d \P} \right ) \right ] \nonumber \\
                     &=\log \mu - \log \nu \nonumber \\
                     &\qquad +   \int_{\partial A} \log \left ( \frac{\lvert \grad  \tilde q (x) \rvert \exp(-U(x)/\eps)}{ m(x)} \right ) \frac{\lvert \grad q(x) \rvert \exp(-U(x)/\eps)}{\nu} \, \d S_A(x) \nonumber \\
                     &\qquad + \Q \left [  \int_0^\tau \frac{L \tilde q}{\tilde q}(Y_s) \, \d s - \log \tilde q (Y_\tau) \right ]. \label{eqn: entropy of q given p}
\end{align}
Both of these relative entropies measure the discrepancy between the exact distribution of transition paths and the distribution with an approximate committor function $\tilde q$ in place of $q$.


These formulas simplify under some conditions. First, note that $\log \tilde q(Y_\tau)=0$ when we impose $\tilde q =1$ on $\partial B$. Second, note that the integrals over $\partial A$ vanish when 
\begin{equation*}
  m(x) = \lvert \grad \tilde q(x) \rvert \exp(-U(x) / \eps).
\end{equation*}
Of course, both conditions hold for the exact committor and reactive flux distribution, and one could impose either in practice when computing approximate committor functions.   


\begin{remark}
The existence of the change of measure $\frac{\d \P}{\d \Q}$ does not imply $\dkl( \P \Vert \Q) < \infty$. We note that $\dkl(\P \Vert \Q) < \infty$ under the same conditions that imply finite variance of the estimator in Lemma~\ref{lem: finite variance of dkl estimator}, but with $\P[\tau^2] < \infty$ replaced by $\P[\tau] < \infty$. We leave the proof to the reader. 
\end{remark}


\subsection{Selection: Estimating Relative Entropy Differences}
\label{sec: selection}

Let $\tilde q$ and $\bar q$ be approximate committor functions for which Assumption~\ref{asm: properties of approximate committor} holds. Let $\tilde m$ and $\bar m$ be approximate reactive flux densities supported on $\partial A$ with normalizing constants
\begin{equation*}
  \tilde \mu := \int_{\partial A} \tilde m(x) \, \d S_A(x)  \text{ and } \bar \mu := \int_{\partial A} \bar m(x) \, \d S_A(x).
\end{equation*}
Assume that $\tilde m$ and $\bar m$ are strictly positive. 
We define $\tilde \P$ to be the law of the approximate transition path process corresponding to $\tilde q$ and $\tilde m$, i.e.\@ the law of a weak solution of~\eqref{eq: approximate tpp} with singular drift $2\eps \grad \log \tilde q(Y_t)$  and initial condition $Y_0 \sim \tilde \mu^{-1} m(x) \, \d S_A(x)$. We define $\bar \P$ similarly, but with $\bar q$ and $\bar m$ in place of $\tilde q$ and $\tilde m$. 
We now explain how to estimate the relative entropy difference
\begin{equation*}
  \delta(\tilde q, \tilde m ; \bar q, \bar m) := \dkl(\tilde \P \Vert \Q) - \dkl(\bar \P \Vert \Q)
\end{equation*}
given samples of paths from $\tilde \P$ and $\bar \P$. Using our estimator, one can compare the quality of approximate committor functions.
For example, one can monitor the relative entropy difference between initial and successive approximations to the committor to assess progress during training, or one can compare the quality of coarse-grained approximations to the committor depending on different numbers of variables. 
%For example, in Section~(CITE), we assess the quality of a coarse-grained approximation to the committor. In addition, one can monitor the relative entropy difference between initial and successive approximations to the committor to assess progress during training. 

Suppose that we have an independent sample of $\tilde N$ paths $\tilde Y^k_t$ drawn from $\tilde \P$:
\begin{equation*}
  \tilde Y^k_t \overset{\mathrm{i.i.d.}}{\sim}  \tilde \P \text{ for } k = 1, \dots, \tilde N . 
\end{equation*}
Under certain conditions on $\tilde q$, the sample average
\begin{align*}
  \tilde I_{\tilde N}:= \frac{1}{\tilde N} \sum_{k=1}^{\tilde N}   \log \left ( \frac{ m(\tilde Y^k_0)}{\lvert \grad  \tilde q (\tilde Y^k_0) \rvert \exp(-U(\tilde Y^k_0)/\eps)} \right ) + \log \tilde q(\tilde Y^k_\tau) -  \int_0^\tau \frac{L \tilde q}{\tilde q}(\tilde Y^k_s) \, \d s
\end{align*}
is a consistent and unbiased estimator of the term
\begin{align*}
  \tilde I &:= \int_{\partial A}  \log \left ( \frac{ m(x)}{\lvert \grad  \tilde q (x) \rvert \exp(-U(x)/\eps)} \right ) \frac{m(x)}{\mu} \, \d S_A(x) \nonumber \\
                       &\qquad + \P_\theta \left [ \log \tilde q (Y_\tau) -  \int_0^\tau \frac{L \tilde q}{\tilde q}(Y_s) \, \d s  \right ]
\end{align*}
appearing in formula~\eqref{eqn: entropy of p given q} for $\dkl ( \tilde \P \Vert \Q)$. 
 We give conditions on $\tilde q$ in Lemma~\ref{lem: finite variance of dkl estimator} in Appendix~\ref{sec: proofs relative entropy} that guarantee finite variance and a weak law of large numbers. Of course, one could estimate the analogous term $\bar I$ in $\dkl (\bar \P \Vert \Q)$ by a similar average $\bar I_{\bar N}$ given a sample of $\bar N$ paths $\bar Y^k_t$ drawn from $\bar \P$. The crucial problem is to show that the variance of $\int_0^\tau \frac{L \tilde q}{\tilde q}(\tilde Y^k_s) \, \d s$ is finite even though $\frac{L \tilde q}{\tilde q}$ would typically be singular on $\partial A$, since $\tilde q =0$ on $\partial A$.

We have 
\begin{equation*}
 \delta(\tilde q, \tilde m ; \bar q, \bar m) = \log \left ( \frac{\tilde \mu}{\bar \mu} \right ) + \tilde I - \bar I,
\end{equation*}
so it remains to estimate the ratio $\frac{\tilde \mu}{\bar \mu}$. Analogous problems involving ratios of normalizing constants arise in Bayesian model selection and the calculation of alchemical free energy differences. Refer to~\cite{lelievre_free_2010} for a survey of methods for free energy calculations. We propose to use the Bennett Acceptance Ratio (BAR) method~\cite{bennett_efficient_1976} to estimate $ \frac{\tilde \mu}{\bar \mu}$. BAR is in some sense the optimal estimator of $\frac{\tilde \mu}{\bar \mu}$ given i.i.d.\@ samples from $\tilde m \, \d S$ and $\bar m \, \d S$. More complex alternatives that involve sampling from multiple distributions, such as the Multistate Bennett Acceptance Ratio (MBAR) method, may be needed in cases where $\tilde m$ and $\bar m$ differ greatly~\cite{shirts_statistically_2008}. 

\begin{remark}
  In practice, to sample from the approximate reactive flux densities $\tilde m$ and $\bar m$, one would most likely use a Markov chain Monte Carlo (MCMC) method. Many methods have been developed to sample distributions supported on submanifolds such as $\partial A$. For example, see~\cite[Sections 3.2.3-4]{lelievre_free_2010}. Of course, MCMC would produce correlated samples from the approximate reactive flux distributions, not independent samples as assumed above.  
\end{remark}

\subsection{Training: Minimizing the Relative Entropy}
\label{sec: training}

One could also try to minimize the relative entropy over a family of approximate committor functions by gradient descent. Let $\{q_\theta ; \theta \in \Real^k\}$ be such a family. Let each approximate committor function correspond to an approximate reactive flux distribution 
\begin{equation}\label{eq: mtheta}
  m_\theta (x) := \mu_\theta^{-1} \grad q_\theta (x) \cdot n(x) \exp(-U(x)/\eps) \, \d S_A (x),
\end{equation}
where
\begin{equation*}
  \mu_\theta := \int_{\partial A}  \grad q_\theta (x) \cdot n(x) \exp(-U(x)/\eps) \, \d S_A (x).
\end{equation*}
We define $\P_\theta$ to be the law of a weak solution of the stochastic differential equation~\eqref{eq: approximate tpp} observed up to time $\tau$ for the approximate committor function $q_\theta$ and initial condition $Y_0 \sim m_\theta$.
In this section, we derive a consistent estimator of $\grad_\theta \dkl ( \P_\theta \Vert \Q)$ given a sample from $\P_\theta$. We then  use the estimator in a stochastic gradient descent method to minimize $\dkl ( \P_\theta \Vert \Q)$.

For our results in this section, we require much stronger assumptions on $q_\theta$ and on the distribution of $\tau$ than those imposed elsewhere; cf.\@ Assumption~\ref{asm: properties that guarantee differentiability of dkl}. The most significant of these new assumptions is that
\begin{equation}\label{eq: Lqtheta is zero on bdy A}
  L q_\theta =0 \text{ on } \partial A \text{ for all } \theta \in \Real^k.
\end{equation}
Recall that for the exact committor $q$, or more precisely for the smooth extension guaranteed by Lemma~\ref{lem: properties of committor}, we have $Lq=0$ everywhere in $\bar \D$, including on $\partial A$; cf.\@ Remark~\ref{rem: smoothness of q}.
One can construct practical families $q_\theta$ satisfying~\eqref{eq: Lqtheta is zero on bdy A} (cf.\@ Section~\ref{sec: numerical}), and our numerical experiments indicate that stochastic gradient descent may converge faster when~\eqref{eq: Lqtheta is zero on bdy A} holds. However, we do not claim that~\eqref{eq: Lqtheta is zero on bdy A} is necessary for differentiability.  

If $Lq_\theta=0$ on $\partial A$, then the quantity
\begin{equation*}
  \ell(x;\theta) := \frac{L q_\theta}{q_\theta}(x)
\end{equation*}
that appears in the change of measure formula~\eqref{eq: computable change of measure} extends to a smooth function of $x$ defined on an open neighborhood of $\partial A$, even though we assume $q_\theta =0$ on $\partial A$. To see this, let $Lq_\theta$ take the place of $\tilde q$ in the proof of Lemma~\ref{lem: ratio function is smooth}. Similarly, 
\begin{equation*}
  \grad_\theta \ell(x;\theta) = \frac{\grad_\theta L q_\theta (x)}{q_\theta (x)} - \frac{\grad_\theta q_\theta(x)}{q_\theta(x)} \frac{Lq_\theta(x)}{q_\theta(x)}
\end{equation*}
also extends to a smooth function on an open neighborhood of $\partial A$, since we have  $Lq_\theta= q_\theta =0$ on $\partial A$ for all $\theta$, hence $\grad_\theta Lq_\theta = \grad_\theta q_\theta =0$ on $\partial A$. We will assume that both $\ell(x;\theta)$ and $\grad_\theta \ell(x;\theta)$ are not merely smooth on a neighborhood of $\partial A$ but bounded uniformly over all $x$ and $\theta$.



Another new assumption is that, for each $\theta \in \Real^k$, there is some $\gamma(\theta) >0$ so that
\begin{equation}\label{eq: mgf of tau}
  \P_\theta[ \exp(\gamma(\theta) \tau)] < \infty;
\end{equation}
that is, the moment generating function of $\tau$ under $\P_\theta$ is finite on an open interval containing zero. We will not verify~\eqref{eq: mgf of tau} for any family of approximate committor functions. However, we note that for the exact transition path process in one-dimension, under some rather stringent conditions on the potential energy $U$ and on the sets $A$ and $B$,  one can show that $\tau$ converges in distribution as $\eps \rightarrow 0$ to a shifted and scaled Gumbel random variable~\cite{cerou_length_nodate}. Under much more general conditions, escape times from basins of attraction of minima of $U$ are approximately exponentially distributed for the overdamped Langevin dynamics in the limit of small $\eps$~\cite{gayrard_metastability_2004}. The moment generating function of a Gumbel or exponential random variable will be finite on an open interval containing zero, but not globally finite, which motivates~\eqref{eq: mgf of tau}. 

We summarize these new assumptions together with a few others below.

\begin{assumption}\label{asm: properties that guarantee differentiability of dkl}
  We assume that $q_\theta(x)$ is infinitely differentiable in both $x$ and $\theta$. 
  We impose the following boundary conditions: 
  \begin{itemize}
  \item $q_\theta = 0$ for $x \in \partial A$.
  \item $q_\theta (x) >0$ for $x \in \mathring{\D} \cup \partial B$. 
  \item $\grad q_\theta (x) \cdot n(x) >0$ for $x \in \partial A$. 
  \item $L q_\theta(x) =0$ for $x \in \partial A$.
  \end{itemize}
  We assume the following uniform bounds:
  \begin{itemize}
    \item
    For some $C>0$,
  \begin{equation*}
    \left \lvert \frac{L q_\theta}{q_\theta} (x) \right \rvert \leq C \text{ and } \left \lvert \grad_\theta \frac{L q_\theta}{q_\theta} (x) \right \rvert \leq C
  \end{equation*}
  for all $x \in \bar \D$ and all $\theta \in \Real^k$.
  \item For some $M >0$, 
  \begin{equation*}
    M \geq \mu_\theta \geq \frac{1}{M} >0 \text{ and } \lvert \grad_\theta m_\theta \rvert \leq M
  \end{equation*}
  for all $\theta \in \Real^k$. 
\end{itemize}
We assume that for each $\theta \in \Real^k$, there is some $\gamma(\theta) >0$ so that
\begin{equation}
  \P_\theta[ \exp(\gamma(\theta) \tau)] < \infty.
\end{equation}
\end{assumption}

Under Assumption~\ref{asm: properties that guarantee differentiability of dkl}, the relative entropy is differentiable. 

\begin{theorem}\label{thm: differentiability of dkl}
  Let Assumption~\ref{asm: properties that guarantee differentiability of dkl} hold, and let $\P_\theta$ and $m_\theta$ be defined as above. The relative entropy $\dkl ( \P_\theta \Vert \Q)$ is differentiable as a function of $\theta$, and 
  \begin{align*}
       \grad_\theta \dkl ( \P_\theta \vert \Q) &= \cov_{\P_\theta} \left (\grad_\theta \log q_\theta (Y_\tau) - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(Y_s) \, \d s , \right . \\
                                              &\qquad \qquad \qquad \qquad \left .  \log q_\theta (Y_\tau) - \int_0^\tau \frac{L q_\theta}{q_\theta}(Y_s) \, \d s \right ). 
    \end{align*}
\end{theorem}

We give the proof in Appendix~\ref{sec: proofs relative entropy}. We propose to estimate $\grad_\theta \dkl( \P_\theta \Vert \Q)$ like any other covariance. Given a sample 
\begin{equation*}
   Y^k \overset{\mathrm{i.i.d.}}{\sim}   \P_\theta \text{ for } k = 1, \dots,  N,  
\end{equation*}
we define sample averages
\begin{align*}
  J_N &:= \frac{1}{N} \sum_{k=1}^N  \log q_\theta (Y^k_\tau) - \int_0^\tau \frac{L q_\theta}{q_\theta}(Y^k_s) \, \d s  \\
  K_N &:= \frac{1}{N} \sum_{k=1}^N \grad_\theta \log q_\theta (Y^k_\tau) - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(Y^k_s) \, \d s \\
\end{align*}
and the sample covariance
\begin{equation}\label{eq: covariance estimator}
  \begin{split}
G_N &:= \frac{1}{N-1} \sum_{k=1}^N  \left ( \log q_\theta (Y^k_\tau) - \int_0^\tau \frac{L q_\theta}{q_\theta}(Y^k_s) \, \d s  - J_N \right )  \\
    &\qquad \qquad \qquad \times \left ( \grad_\theta \log q_\theta (Y^k_\tau) - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(Y^k_s) \, \d s - K_N\right ).
  \end{split}
\end{equation}
Assumption~\ref{asm: properties that guarantee differentiability of dkl} implies that $G_N$ has finite variance. We leave the proof to the reader. Using this gradient estimator, one can attempt to minimize $\dkl(\P_\theta \Vert \Q)$ by stochastic gradient descent. 

\subsection{Importance Sampling and Direct Estimation of Relative Entropy}


Using our change of measure formula, one could in principle estimate arbitrary expectations over the transition path process $\Q$ given a sample of paths from the approximate process $\P$. Let $g : \Omega \rightarrow \Real$ be $\F_\tau$-measurable, i.e.\@ a function of the process observed up to time $\tau$. By~\eqref{eq: computable change of measure}, assuming for simplicity that $\tilde q = 1$ on $\partial B$ and $m = \lvert \grad \tilde q \rvert \exp(-U /\eps)$, we have
\begin{align*}
  \Q [ g ] &= \P \left [ Z_\tau^{-1} g  \right ] \\
           &= \frac{\mu}{\nu}  \P \left [\exp \left (\int_0^{\tau(\omega)}  \frac{L \tilde q}{\tilde q}(Y_s(\omega))\, \d s \right ) g(\omega) \right ],
\end{align*}
which suggests the self-normalized importance sampling estimator
\begin{equation*}
  \bar g = \frac{\frac{1}{N}\sum_{k = 1}^N \exp \left (\int_0^\tau  \frac{L \tilde q}{\tilde q}(Y^k_s)\, \d s \right ) g(Y^k)}{\frac{1}{N}\sum_{k = 1}^N \exp \left (\int_0^\tau  \frac{L \tilde q}{\tilde q}(Y^k_s)\, \d s \right )},
\end{equation*}
where $Y^k \overset{\mathrm{i.i.d.}}{\sim}   \P \text{ for } k = 1, \dots,  N$. Experience with other estimators related to Girsanov's theorem strongly suggests that such a na\"ive estimator will not be robust. Some successes have been attained in the importance sampling of paths of diffusion processes by roughly similar estimators~\cite{zhang_koopman_2022,dupuis_importance_2012,vanden-eijnden_rare_2012}. We hope that our results will facilitate the development of analogous methods for the transition path process. However, we note that~\cite{zhang_koopman_2022,dupuis_importance_2012,vanden-eijnden_rare_2012} treat only paths observed up to a fixed finite time, not up to an unbounded stopping time as in our work.

One might also consider the possibility of estimating the relative entropy $\dkl(\P \Vert \Q)$, not a relative entropy difference, for a given approximate committor function. The crux of the problem is to estimate the ratio of normalizing constants
\begin{equation*}
  \frac{\nu}{\mu}
\end{equation*}
given a sample of transition paths from $\P$. In Section~\ref{sec: selection}, we explain how to estimate all other terms comprising the relative entropy. As above, we have 
\begin{align*}
  \frac{\nu}{\mu} &= \P \left [\exp \left (\int_0^{\tau}  \frac{L \tilde q}{\tilde q}(Y_s)\, \d s \right )  \right ], 
\end{align*}
which suggests the estimator 
\begin{equation*}
  \frac{1}{N} \sum_{k = 1}^N \exp \left (\int_0^\tau  \frac{L \tilde q}{\tilde q}(Y^k_s)\, \d s \right ), 
\end{equation*}
where  $Y^k \overset{\mathrm{i.i.d.}}{\sim}   \P \text{ for } k = 1, \dots,  N$. We do not expect such an estimator to be much more robust than the general importance sampling estimator.  

\section{Numerical Methods}
\label{sec: numerical}

In this section, we address some obstacles to the practical implementation of the estimators proposed above. In Section~\ref{sec: representing the committor}, we explain how to construct families of committor functions that satisfy Assumption~\ref{asm: properties of approximate committor} and the boundary condition $L\tilde q=0$ on $\partial A$ that arises in Section~\ref{sec: training}. In Section~\ref{sec: alternative expression}, we explain how to handle the possibly singular integrand $\frac{L \tilde q}{\tilde q}$ that appears in our change of measure formula~\eqref{eq: computable change of measure}.

\subsection{Representing the Committor Function}
\label{sec: representing the committor}
We devise a practical means of representing approximate committor functions that satisfy Assumption~\ref{asm: properties of approximate committor} and the condition
\begin{equation*}
  L \tilde q = 0 \text{ on } \partial A
\end{equation*}
appearing in Assumption~\ref{asm: properties that guarantee differentiability of dkl}.
In our approach, one must first choose a computable function $T: \Omega \rightarrow \Real$ with the following properties:
\begin{itemize}
\item $T$ extends to a smooth function on an open neighborhood of $\overline \Omega$.
\item  $\grad T(x) \cdot n(x) > 0$ for all $x \in \partial A$.
\item $T(x) =0$ for all $x \in \partial A$.
\item $T(x) >0$ for all $x \in \Omega \setminus \partial A$. 
\end{itemize}
For example, if $A = \{x \in \Real^d; \xi(x) \leq a\}$ were a sublevel set of some function $\xi: \Real^d \rightarrow \Real$, one could try $T=\xi-a$. Observe that all of the above conditions would hold at least locally in a neighborhood of $\partial A$ if $\lvert \grad \xi(x) \rvert$ were positive on $\partial A$. 

In our numerical experiments, the approximate committor takes the form
\begin{equation*}
  \tilde q = T \exp(w), 
\end{equation*}
where $T$ is as above and $w : \Omega \rightarrow \Real$ belongs to some convenient family of smooth functions. Any $\tilde q$ of this form satisfies Assumption~\ref{asm: properties of approximate committor}. In particular, the normal derivative of $\tilde q$ is positive over $\partial A$, since
\begin{align*}
  \grad \tilde q(x) \cdot n(x) &= \big \{ \grad T(x) \exp(w(x)) + \grad w(x) T(x) \exp(w(x)) \big \} \cdot n(x) \\
                               &= \grad T(x) \cdot n(x) \exp(w(x)) \\
                               &>0
\end{align*}
for $x \in \partial A$. Moreover, for any $T$ meeting the conditions above, the exact committor $q$ can be written in the form $q = T \exp(w)$ for $w = \log \left ( q/ T \right)$, and this $w$ extends to a smooth function on an open neighborhood of $\Omega$ by Lemma~\ref{lem: ratio function is smooth}.


The condition $L \tilde q = 0$ on $\partial A$ appearing in Assumption~\ref{asm: properties that guarantee differentiability of dkl} is equivalent with a Neumann boundary condition on $w$. We have
\begin{equation}\label{eq: L tilde q}
L \tilde q =  \left \{ L T + 2\eps \grad w \cdot \grad T + T \left ( L w + \eps \lvert \grad w \rvert^2 \right ) \right  \} \exp(w). 
\end{equation}
Since $T=0$ and $\grad T \cdot n >0$ on $\partial A$, $\grad T = \lvert \grad T \rvert n$ on $\partial A$, and therefore~\eqref{eq: L tilde q} implies that $L \tilde q =0$ on $\partial A$ if and only if $w$ satisfies the Neumann boundary condition
\begin{equation}
  \grad w (x) \cdot n (x) = -\frac{1}{2 \eps} \frac{L T (x)}{\lvert \grad T (x) \rvert}
\end{equation}
for $x \in \partial A$.

Depending on the geometry of $\partial A$, it may be more or less difficult to impose the Neumann boundary condition. We propose a general approach that requires a smooth global retraction $\rho: \Omega \rightarrow \partial A$ in addition to $T$. We represent $w$ in the form
\begin{equation}\label{eq: representation of w for zero Lq on boundary of A}
  w(x)  = w_0 (\rho(x)) + T(x) w_1(\rho (x)) + T(x)^2 w_2(x). 
\end{equation}
Here, $w_0 : \partial A \rightarrow \Real$ and $w_2: \Omega \rightarrow \Real$ are arbitrary. Given $w_0$, the condition $L \tilde q =0$ on $\partial A$ determines $w_1: \partial A \rightarrow \Real$. See Lemma~\ref{lem: boundary condition on w} below for details.

\begin{lemma}\label{lem: boundary condition on w}
  Any function $w: \Omega \rightarrow \Real$ that admits a smooth extension to an open neighborhood of $\overline{\Omega}$ may be expressed in the form~\eqref{eq: representation of w for zero Lq on boundary of A}
  for some unique smooth $w_0$, $w_1$, and $w_2$. Moreover, the approximate committor function $\tilde q = T \exp(w)$ has $L \tilde q = 0$ on $\partial A$ if and only if
  \begin{equation}\label{eq: condition on w1 for Lq to be zero}
     w_1(z) = - \frac{\grad w_0^t(z) D \rho(z) n(z)}{\lvert \grad T(z) \rvert} - \frac{LT(z)}{\lvert \grad T(z) \rvert^2}
   \end{equation}
   for all $z \in \partial A$. In particular, the exact committor function $q$ can be expressed as $q=T\exp(w)$ with $w$ of the form~\eqref{eq: representation of w for zero Lq on boundary of A} for some smooth $w_0$, $w_1$, and $w_2$. 
 \end{lemma}

 \begin{proof}
 See  Appendix~\ref{apx: proofs for numerics section}. 
\end{proof}

Observe that $w_0$ determines the approximate reactive flux distribution corresponding to $\tilde q$. When $w$ takes the form~\eqref{eq: representation of w for zero Lq on boundary of A}, we have 
\begin{equation*}
  \grad \tilde q(x) = \grad T(x) \exp(w_0(x)) 
\end{equation*}
for $x \in \partial A$, and therefore
\begin{equation*}
  \lvert \grad \tilde q(x) \rvert \exp(-U(x)/\eps) \, \d S_A(x) =\lvert \grad T(x) \rvert \exp(w_0(x))\exp(U(x)/\eps) \, \d S_A(x),
\end{equation*}
using that $\grad T = \lvert \grad T \rvert n$ on $\partial A$, as explained above. 

\subsection{Alternative Expression for the Improper Integral}
\label{sec: alternative expression}
Observe that
$
  \frac{L  \tilde q}{\tilde q}
$
must be singular on $\partial A$ unless $L \tilde q =0$ on $\partial A$. Moreover, to compute $L\tilde q$ requires computing $\lap \tilde q$, which cannot be done efficiently by automatic differentiation when $\Omega$ is high-dimensional. 
Here, we derive a convenient alternative expression for the improper integral term
\begin{equation*}
\int_0^\tau  \frac{L  \tilde q}{\tilde q}(Y_s)\, \d s 
\end{equation*}
in the relative entropy~\eqref{eqn: entropy of p given q}. At the cost of significant additional complexity, we remove both the singularity and also the computationally undesirable dependence on $\lap \tilde q$. Lemma~\ref{lem: alternative form of integral term} below is the crucial result.  

\begin{lemma}\label{lem: alternative form of integral term}
  Let $S : \D \rightarrow \Real$ be a function for which Assumption~\ref{asm: properties of approximate committor} holds. Let $w = \log \frac{\tilde q}{S}$, so
  \begin{equation*}
    \tilde q = S \exp(w).
  \end{equation*}
  We have
  \begin{align*}
    \int_0^\tau \frac{L\tilde{q}}{\tilde{q}}(Y_{t}) \, \d t= w(Y_{\tau})-w(Y_{0})&+\int_0^\tau\frac{LS}{S}(Y_t) -\epsilon\vert\grad w(Y_t)\vert^{2} \, \d t \\
    &- \int_0^\tau \sqrt{2\epsilon}\grad w(Y_t)\cdot \d W_t,
\end{align*}
where $W_t$ is the $\P$-Brownian motion in Theorem~\ref{thm: complete change of measure from transition path process to simulated process}.
\end{lemma}

We give the proof in Appendix~\ref{sec: proofs relative entropy}. Here, we have only replaced one possibly singular integrand, $\frac{L \tilde q}{\tilde q}$, by another, $\frac{L S}{S}$, so perhaps it is not clear that this is a useful formula. Note, however, that for theoretical purposes, we may take $S=q$, so that $w=\log r = \log (\tilde q/q)$, $LS =0$ everywhere in $\bar \D$ including on $\partial A$, and the $\frac{LS}{S}$ term vanishes. In that case, one recovers a formula for the change of measure that is similar to~\eqref{eqn: first formula for z}. We use this formula in the proofs of some results in Section~\ref{sec: applications}.

For computational purposes, one can choose $S$ so that $\lap S$ is easy to compute explicitly without resorting to automatic differentiation, and then one need only compute $\grad \tilde q$, not $\lap \tilde q$, when evaluating $\int_0^\tau \frac{L\tilde{q}}{\tilde{q}}(Y_{t}) \, \d t$. Note that if $\tilde q$ is a neural network, then $\lap \tilde q$ is most likely be intractable for high-dimensional $\Omega$, but $\grad \tilde q$ can be computed efficiently by backpropagation. Moreover, is $L S = 0$ on $\partial A$, then the integrand $\frac{LS}{S}$ is no longer singular. We explain in Section~\ref{sec: representing the committor} above how to construct such an $S$. One possibility is
\begin{equation*}
S(x) = T(x) \exp \left ( - \frac{ T(x) L T( \rho(x))}{\lvert \grad T(x) \rvert^2}  \right ),
\end{equation*}
corresponding to taking $w_0$ and $w_2$ to be zero in~\eqref{eq: representation of w for zero Lq on boundary of A}. Here, $T$ and $\rho$ are as in Section~\ref{sec: representing the committor}. Thus, using Lemma~\ref{lem: alternative form of integral term}, for a judicious choice of $S$, one can eliminate both the singularity and the computationally intractable Laplacian of $\tilde q$. We grant, however, that for the particular $S$ defined above, it may still be difficult to compute $LS$ efficiently in practice, especially because the generator $L$ depends on $\grad U$. 

\begin{remark}
We warn the reader that since $W_t$ depends on $\tilde q$, one has to be rather careful in attempts to use this formula to simplify the calculation of derivatives of the relative entropy. 
\end{remark}



\appendix

\section{Proofs of Results in Section~\ref{sec: change of measure formula}}
\label{apx: change of measure formula}


\begin{proof}[Proof of Theorem~\ref{thm: complete change of measure from transition path process to simulated process}]
  Since we assume the Novikov condition, by Lemma~\ref{lem: second impractical change of measure formula}, 
  \begin{equation*}
    M_t =  \frac{\lvert \grad  q (Y_0) \rvert}{\lvert \grad \tilde q (Y_0) \rvert} \frac{\tilde q(Y_t)}{q(Y_t)} \exp \left (-\int_0^t \frac{L \tilde q}{\tilde q}(Y_s) \, \d s  \right )
  \end{equation*}
  is an $\F_t$-martingale under $\Q$ with $\Q[M_t]=1$ for $t \geq 0$. It follows that 
  \begin{align*}
    Z_t &= \frac{\mu^{-1} m(Y_0)}{\nu^{-1} \lvert \grad q(Y_0) \rvert \exp(-U(Y_0) /\eps)} M_t \\
   % &= \frac{\nu}{\mu} \frac{\tilde q(Y_t)}{q(Y_t)} \frac{ m(Y_0)}{\lvert \grad \tilde q (Y_0) \rvert \exp(-U(Y_0)/\eps)}\exp \left (-\int_0^t  \frac{L \tilde q}{\tilde q}(Y_s)\, \d s \right )
  \end{align*}
  is a martingale with $\Q[Z_t]=1$: For $0 \leq s \leq t$, we have 
  \begin{align*}
    \Q[Z_t \vert \F_s] &= \Q \left [  \left . \frac{\mu^{-1} m(Y_0)}{\nu^{-1} \lvert \grad q(Y_0) \rvert \exp(-U(Y_0) /\eps)} M_t \right \vert \F_s \right ] \\
                       &=  \frac{\mu^{-1} m(Y_0)}{\nu^{-1} \lvert \grad q(Y_0) \rvert \exp(-U(Y_0) /\eps)} \Q [ M_t \vert \F_s] \\
                       &= \frac{\mu^{-1} m(Y_0)}{\nu^{-1} \lvert \grad q(Y_0) \rvert \exp(-U(Y_0) /\eps)} M_s. \\
                       &= Z_s, 
  \end{align*}
  Moreover, 
  \begin{align*}
    \Q[Z_t]&= \Q \left [ \Q \left [ \left .  \frac{\mu^{-1} m(Y_0)}{\nu^{-1} \lvert \grad q(Y_0) \rvert \exp(-U(Y_0) /\eps)} M_t \right \vert \F_0 \right ] \right ] \\
           &= \Q \left [ \frac{\mu^{-1} m(Y_0)}{\nu^{-1} \lvert \grad q(Y_0) \rvert \exp(-U(Y_0) /\eps)} \Q[M_t \vert \F_0] \right ] \\
           &= \Q \left [\frac{\mu^{-1} m(Y_0)}{\nu^{-1} \lvert \grad q(Y_0) \rvert \exp(-U(Y_0) /\eps)} M_0 \right ] \\
          &=1,
  \end{align*}
  since $M_0=1$ and $Y_0 \sim \nu^{-1} \lvert \grad q(x) \rvert \exp(-U(x)/\eps)$ under $\Q$. 
  
  
  We now show that $Z_\tau$ is the density of $\P$ with respect to $\Q$ restricted to the stopping time $\sigma$-algebra $\F_\tau$. Since $Z_t$ is a martingale, the optional stopping theorem~\cite[Chapter~2, Theorem~3.2]{revuz_continuous_1999} implies that for any fixed $t >0$,
  \begin{equation*}
    Z_{t \wedge \tau} = \Q[Z_t \vert \F_{t \wedge \tau}].
  \end{equation*}
  (Here, $t \wedge \tau$ denotes the minimium of $t$ and $\tau$.) 
  Let $A \in \F_\tau$. Since $\P[\tau < \infty]=1$, we have
  \begin{equation*}
    \P[A]=\lim_{N \rightarrow \infty} \P [A \cap \{\tau \leq N\}].
  \end{equation*}
  Now each of the sets
 \begin{equation*}
    A_N:=A\cap \{ \tau < N\} 
  \end{equation*}
  is in $\F_{\tau \wedge N} \subset \F_N$, since $A \in \F_\tau$. (Here, $\tau \wedge N$ means the minimum of $\tau$ and $N$.)
  % We have$A_N \in \F_{\tau \wedge N}$, since 
  % \begin{equation*}
  %   A_N \cap \{\tau \wedge N \leq t\} = A \cap \{\tau \leq N\} \cap \{\tau \wedge N \leq t \} = A \cap \{\tau \leq t \wedge N\} \in  \F_{t \wedge N} \subset \F_N.
  % \end{equation*}
  % Also, $\F_{\tau \wedge N} \subset \F_N$, since $\tau \wedge N \leq N$. 
  Therefore,
  \begin{align*}
    \P[A] &= \lim_{N \rightarrow \infty} \P[A_N]\\
          &\qquad \text{(since $\P[\tau < \infty ]=1$)}\\
          &= \lim_{N \rightarrow \infty}  \int_{A_N} \P (\d \omega) \\
          &=\lim_{N \rightarrow \infty} \int_{A_N} Z_N(\omega) \Q (\d \omega) \\
          &\qquad \text{(since $A_N \in \F_N$ and $Z_N = \left .  \frac{\d \P}{\d \Q} \right \rvert_{\F_N}$)} \\
          &= \lim_{N \rightarrow \infty}  \int_{A_N} \Q[Z_N(\omega) \vert \F_{\tau(\omega) \wedge N}] \Q(\d \omega) \\
          &\qquad  \text{(since $A_N \in \F_{\tau \wedge N}$)} \\\
          &=  \lim_{N \rightarrow \infty} \int_{A_N} Z_{\tau (\omega) \wedge N}(\omega) \Q(\d \omega) \\
          &\qquad  \text{(by optional stopping, as discussed above)} \\
          &=   \lim_{N \rightarrow \infty} \int_{A_N} Z_{\tau (\omega) }(\omega) \Q(\d \omega) \\
          &\qquad  \text{(since for $\omega \in A_N$, $\tau(\omega) \wedge N = \tau(\omega)$)} \\
          &= \int_A Z_{\tau (\omega)}(\omega) \Q(\d \omega), \\
          &\qquad \text{(since $\Q[\tau < \infty ]=1$)}
  \end{align*}
  and so $Z_\tau$ is the density of $\P$ with respect to $\Q$ on $\F_\tau$. 
\end{proof}


\section{Proofs of Results in Section~\ref{sec: relative entropy in path space}}
\label{sec: proofs relative entropy}

First, we prove Lemma~\ref{lem: alternative form of integral term} which provides an alternative expression for the improper integral in our change of measure formula. 

\begin{proof}[Proof of Lemma~\ref{lem: alternative form of integral term}]
  By Lemma~\ref{lem: ratio function is smooth}, $w$ is smooth. Therefore, by Ito's formula, under $\P$, we have 
  \begin{equation} \label{eq: Ito_w_bar}
    dw(Y_t)=L w(Y_t) \, \d t +2\epsilon \grad \log \tilde{q}(Y_t)\cdot\grad w(Y_t) \, \d t+\sqrt{2\epsilon}\grad  w (Y_t)\cdot \d W_{t}, \\
  \end{equation}
  where $W_t$ is the $\P$-Brownian motion defined in Theorem~\ref{thm: complete change of measure from transition path process to simulated process}
  Now let
  \begin{equation*}
    \tilde{v}:=-2\epsilon\log(\tilde{q})
    \text{ and }
    v:=-2\epsilon T .
  \end{equation*}
  By a calculation similar to the proof of Lemma~\ref{lem: hjb equation}, we have  
  \begin{equation*}
    \frac{L\tilde{q}}{\tilde{q}}=-\frac{1}{2\epsilon}\left(L\tilde{v} - \frac{1}{2}\vert \grad\tilde{v} \vert^{2} \right) \text{ and }
    \frac{L T }{ T }=-\frac{1}{2\epsilon}\left(Lv - \frac{1}{2}\vert \grad v \vert^{2} \right).
  \end{equation*}
  Also, $ w =-\frac{1}{2\epsilon}(\tilde{v}- v )$. 
  Plugging these expressions into ~\eqref{eq: Ito_w_bar}, we get 
  \begin{align*}
    \d  w (Y_t)&=\left(-\frac{1}{2\epsilon}L\tilde{v}(Y_t)+\frac{1}{2\epsilon}L v (Y_t)+\frac{1}{2\epsilon}\grad\tilde{v}(Y_t)\cdot\grad(\tilde{v}- v )(Y_t) \right)\, \d t \\
               &\qquad +\sqrt{2\epsilon}\grad  w (Y_t)\cdot \d B_{t} \\
               &=-\frac{1}{2\epsilon}\left(L\tilde{v}(Y_t)-\frac{1}{2}\vert\grad\tilde{v}(Y_t)\vert^{2}\right)\d t \\
               &\qquad+\frac{1}{2\epsilon}\left(L v (Y_t)-\frac{1}{2}\vert\grad v (Y_t)\vert^{2}\right)\d t \\
               &\qquad+\frac{1}{2\epsilon}\left(\frac{1}{2}\vert\grad\tilde{v}(X_{2})\vert^{2}+\frac{1}{2}\vert\grad v (X_{2})\vert^{2}-\grad\tilde{v}(Y_t)\cdot\grad v (Y_t)\right)\d t \\
               &\qquad+\sqrt{2\epsilon}\grad  w (Y_t)\cdot \d B_{t} \\
               &=\left(\frac{L\tilde{q}}{\tilde{q}}(Y_t)-\frac{L T }{ T }(Y_t)\right)\d t \\
               &\qquad+\epsilon\vert\grad w (Y_t)\vert^{2}\d t+\sqrt{2\epsilon}\grad  w (Y_t)\cdot \d W_{t}, \\
    \end {align*}
    and the result follows.
  \end{proof}

We use Lemma~\ref{lem: alternative form of integral term} to show that our estimator of relative entropy differences has finite variance, at least under certain conditions on $\tilde q$. 
  
\begin{lemma}\label{lem: finite variance of dkl estimator}
  Assume that $\P[\tau^2] < \infty$, that for some $C >0$,
  \begin{equation*}
    \left \lvert \log \left ( \frac{\tilde q(x)}{q(x)} \right ) \right \rvert \leq C \text{ and } \left \lvert \grad \log \left ( \frac{\tilde q(x)}{q(x)} \right ) \right \rvert \leq C
  \end{equation*}
  for all $x \in \bar \D$, and that for some $M >0$, 
  \begin{equation*}
    \frac{1}{M}\leq  \lvert m(x) \rvert \leq M \text{ and } \frac{1}{M} \leq \lvert \grad  \tilde q (x) \rvert \exp(-U(x)/\eps) \leq M
    \end{equation*}
    for all $x \in \partial A$. 
    If so,
    \begin{equation*}
      \var_\P \left (  \log \left ( \frac{ m(\tilde Y^1_0)}{\lvert \grad  \tilde q (\tilde Y^1_0) \rvert \exp(-U(\tilde Y^1_0)/\eps)} \right ) + \log \tilde q(\tilde Y^1_\tau) -  \int_0^\tau \frac{L \tilde q}{\tilde q}(\tilde Y^1_s) \, \d s \right ) < \infty,
    \end{equation*}
    so $\lim_{\tilde N \rightarrow \infty} \tilde I_{\tilde N}= \tilde I$ in $L^2(\P)$. 
\end{lemma}

\begin{proof}
  The crux of the proof is to show that
  \begin{equation*}
    \P \left [ \left (\int_0^\tau \frac{L \tilde q}{\tilde q}(Y_s) \, \d s \right )^2 \right ] < \infty
  \end{equation*}
  even though $\frac{L \tilde q}{\tilde q}$ may be singular on $\partial A$. Taking $T=q$ in Lemma~\ref{lem: alternative form of integral term} yields
  \begin{align*}
    \int_0^\tau \frac{L \tilde q}{\tilde q}(Y_s) \, \d s &= \log \frac{r(Y_\tau)}{r(Y_0)} - \eps \int_0^\tau \lvert \grad \log r(Y_s) \rvert^2 \, \d s - \sqrt{2 \eps} \int_0^\tau \grad \log r(Y_s) \cdot \d W_s \\
    %&=: F_\tau + \eps D_\tau + \sqrt{2\eps} S_\tau,
  \end{align*}
  where $r = \tilde q/q$ and $W_s$ is the $\P$-Brownian motion in Theorem~\ref{thm: complete change of measure from transition path process to simulated process}. Therefore, 
  \begin{align}
    \P \left [ \left (\int_0^\tau \frac{L \tilde q}{\tilde q}(Y_s) \, \d s \right )^2 \right ]^{\frac12} &\leq \P \left [ \left ( \log \frac{r(Y_\tau)}{r(Y_0)} \right )^2 \right ]^{\frac12} + \eps \P \left [ \left (\int_0^\tau \lvert \grad \log r(Y_s) \rvert^2 \, \d s \right )^2 \right ]^{\frac12}  \nonumber \\
                                                                                                         &\qquad \qquad \qquad +\sqrt{2 \eps} \P \left [ \left (\int_0^\tau \grad \log r(Y_s) \cdot \d W_s \right )^2 \right ]^{\frac12} \nonumber \\
                                                                                                           &\leq 2C + \eps C \P[\tau^2] + \sqrt{2 \eps} \P \left [ \left (\int_0^\tau \grad \log r(Y_s) \cdot \d W_s \right )^2 \right ]^{\frac12}.  \label{eq: triangle inequality in finite variance proof}                                                                                                                         
  \end{align}  
  % We have
  % \begin{equation*}
  %    \P \left [ \left ( \log \frac{r(Y_\tau)}{r(Y_0)} \right )^2 \right ]^{\frac12} \leq  \text{ and } 
  %    \P \left [ \left ( \log \frac{r(Y_\tau)}{r(Y_0)} \right )^2 \right ]^{\frac12} \leq C \P[\tau^2].
  %  \end{equation*}
  
  We bound the third term in~\eqref{eq: triangle inequality in finite variance proof} using the Ito isometry, which entails some minor but tiresome technical difficulties, since standard forms of the isometry only apply to integrals up to finite, deterministic times. Define
  \begin{equation*}
    S_t = \int_0^t \grad \log r(Y_s) \cdot \d W_s.
  \end{equation*}
  We will approximate $S_\tau$ by $S_{\tau \wedge n}$ for $n \in \mathbb{N}$ to apply the Ito isometry; we claim that $S_{\tau \wedge n}$ is a Cauchy sequence in $L^2(\P)$. To see this, let $n< n' \in \mathbb{N}$, and observe that
  \begin{align*}
    \P[ (S_{\tau \wedge n'} - S_{\tau \wedge n})^2 ]  &= \P \left [ \left ( \int_{\tau \wedge n}^{\tau \wedge n'} \grad \log r(Y_s) \cdot \d W_s \right )^2 \right ]\\
                                                      &= \P \left [ \left ( \int_0^{n'} \1_{\tau \wedge n \leq s <  \tau \wedge n'} \grad \log r(Y_s) \cdot \d W_s \right )^2 \right ]\\    &= \P \left [  \int_0^{n'} \1_{\tau \wedge n \leq s <  \tau \wedge n'} \lvert \grad \log r(Y_s) \rvert^2 \, \d s \right ] \\
                                                      &\leq  \P \left [  \int_0^{n'} \1_{\tau \geq n} \lvert \grad \log r(Y_s) \rvert^2 \, \d s \right ] \\
    &\leq C^2 \P[\tau \geq n].
  \end{align*}
  The third equality above follows from the Ito isometry, since $\tau$ is a stopping time, hence $\1_{\tau \wedge n \leq s <  \tau \wedge n'}$ is adapted. The first inequality holds, since $\tau < n$ implies $\1_{\tau \wedge n \leq s <  \tau \wedge n'} = 0$. We assume that $\P[\tau < \infty ] =1$, so $\lim_{n \rightarrow \infty} \P[\tau \geq n] =0$, hence $S_{\tau \wedge n}$ is Cauchy. In fact, we have $\lim_{n\rightarrow \infty} S_{\tau \wedge n} = S_\tau$ in $L^2(\P)$, since $\P[\tau < \infty]=1$ implies that $S_{\tau \wedge n}$ converges to $S_\tau$ almost surely. We conclude that
  \begin{align*}
    \P[S_\tau^2] &= \lim_{n \rightarrow \infty} \P[S_{\tau \wedge n}^2] \\
                 &= \lim_{n \rightarrow \infty} \P \left [\left ( \int_0^n \1_{s \leq \tau \wedge n} \grad \log r(Y_s) \cdot \d W_s \right )^2\right ] \\
                 &=  \lim_{n \rightarrow \infty} \P \left [ \int_0^n \1_{s \leq \tau \wedge n} \lvert \grad \log r(Y_s) \rvert^2 \, \d s\right ]\\
                 &\leq \lim_{n \rightarrow \infty} C^2 \P[\tau \wedge n] \\
                 &= C^2 \P[\tau]. 
  \end{align*}
  It follows that
  \begin{equation*}
      \var_\P \left (  \log \left ( \frac{ m(\tilde Y^1_0)}{\lvert \grad  \tilde q (\tilde Y^1_0) \rvert \exp(-U(\tilde Y^1_0)/\eps)} \right ) + \log \tilde q(\tilde Y^1_\tau) -  \int_0^\tau \frac{L \tilde q}{\tilde q}(\tilde Y^1_s) \, \d s \right ) < \infty.
    \end{equation*}
    We leave the remaining details to the reader. 
\end{proof}

We now prove Theorem~\ref{thm: differentiability of dkl} on the differentiability of $\dkl ( \P_\theta \Vert \Q)$ in $\theta$.


\begin{proof}[Proof of Theorem~\ref{thm: differentiability of dkl}]
  Since we assume that $\frac{L q_\theta}{q_\theta}$ and $\grad_\theta\frac{L q_\theta}{q_\theta}$ are bounded, for each $\omega \in \Omega$,
  \begin{equation*}
    \grad_\theta \int_0^{\tau(\omega)} \frac{L q_\theta}{q_\theta}(X_s(\omega)) \, \d s =  \int_0^{\tau(\omega)} \grad_\theta \frac{L q_\theta}{q_\theta}(X_s(\omega)) \, \d s . 
  \end{equation*}
  Moreover, since we assume $\mu_\theta \geq \frac{1}{M} >0$, and since $q_\theta$ is differentiable, $\log \mu_\theta$ is differentiable. 
  Therefore, 
  \begin{align}
    \grad_\theta  \frac{\d \P_\theta}{\d \Q} &=  \frac{\d \P_\theta}{\d \Q} \left ( \frac{\grad_\theta q_\theta (X_\tau)}{q_\theta(X_\tau)} - \frac{\grad_\theta \mu_\theta}{\mu_\theta} - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(X_s) \, \d s\right ). \label{eq: derivative of integrand in dkl}                                               
  \end{align}
  

  One now wants to interchange differentiation with respect to $\theta$ and expectation over $\Q$ to derive a formula for $\grad_\theta \dkl ( \P_\theta \Vert \Q)$. Write
  \begin{equation*}
    g(x) = x \log x
  \end{equation*}
  so that
  \begin{equation*}
    \dkl ( \P_\theta \Vert \Q ) = \Q \left [ g \left (  \frac{\d \P_\theta}{\d \Q} \right ) \right ].
  \end{equation*}
  We claim that
  \begin{equation}\label{eq: first formula for derivative}
    \grad_\theta \dkl ( \P_\theta \Vert \Q) = \grad_\theta  \Q \left [ g \left (  \frac{\d \P_\theta}{\d \Q} \right ) \right ] = \Q \left [ g' \left (  \frac{\d \P_\theta}{\d \Q} \right ) \grad_\theta \frac{\d \P_\theta}{\d \Q} \right ].
  \end{equation}

  
  Assumption~\ref{asm: properties that guarantee differentiability of dkl} does not imply that $\grad_\theta   \frac{\d \P_\theta}{\d \Q}$ is bounded uniformly in $\theta$ by a function in $L^1(\Q)$, so textbook results related to differentiating under the integral do not apply. To verify~\eqref{eq: first formula for derivative}, we return to the definition of the derivative. Given any $h,\theta \in \Real^k$, by the mean value theorem, for some $s: \Omega \rightarrow [0,1]$, we have
  \begin{align*} 
   \frac{1}{\lVert h \rVert} \Q &\left [ g \left (  \frac{\d \P_{\theta + h}}{\d \Q} \right )  -  g \left (  \frac{\d \P_\theta}{\d \Q} \right ) -  g' \left (  \frac{\d \P_\theta}{\d \Q} \right ) \grad_\theta \frac{\d \P_\theta}{\d \Q} \cdot h\right ] \\
    &= \Q \left [  g' \left (  \frac{\d \P_{\theta+s h}}{\d \Q} \right ) \grad_\theta \frac{\d \P_{\theta+s h}}{\d \Q} \cdot \frac{h}{\lVert h \rVert} -  g' \left (  \frac{\d \P_\theta}{\d \Q} \right ) \grad_\theta \frac{\d \P_\theta}{\d \Q} \cdot \frac{h}{\lVert h \rVert} \right ] \\
    &= \Q \left [ \left \{  g' \left (  \frac{\d \P_{\theta+s h}}{\d \Q} \right ) - g' \left (  \frac{\d \P_{\theta+h}}{\d \Q} \right ) \right \}  \grad_\theta \frac{\d \P_\theta}{\d \Q} \cdot \frac{h}{\lVert h \rVert} \right . \\
    &\qquad \qquad + \left . g' \left (  \frac{\d \P_{\theta+s h}}{\d \Q} \right ) \left \{\grad_\theta \frac{\d \P_{\theta+s h}}{\d \Q} - \grad_\theta \frac{\d \P_{\theta}}{\d \Q} \right \}  \cdot \frac{h}{\lVert h \rVert}\right ]\\
    &= \P_\theta \left [ \left \{ \log \left (  \frac{\d \P_{\theta+s h}}{\d \Q} \right ) - \log \left (  \frac{\d \P_{\theta}}{\d \Q} \right ) \right \}  \grad_\theta \log \frac{\d \P_\theta}{\d \Q} \cdot \frac{h}{\lVert h \rVert} \right . \\
    &\qquad \qquad +  \left \{\log \left (  \frac{\d \P_{\theta+s h}}{\d \Q} \right ) + 1 \right \} \grad_\theta \log \frac{\d \P_{\theta+s h}}{\d \Q}  \cdot \frac{h}{\lVert h \rVert}  \frac{\d \P_{\theta+s h}}{\d \Q} \frac{\d \Q}{\d \P_\theta}   \\
                 &\qquad \qquad - \left .  \left \{\log \left (  \frac{\d \P_{\theta+s h}}{\d \Q} \right ) + 1 \right \} \grad_\theta \log \frac{\d \P_{\theta}}{\d \Q}  \cdot \frac{h}{\lVert h \rVert}\right ]\\
   &=: \P_\theta [R(\theta; h)]. 
  \end{align*}

  As $h \rightarrow 0$, the integrand $R(\theta; h)$ in the expectation with respect to $\P_\theta$ above converges pointwise to zero.  We now show that $R(\theta; h)$ is dominated in $L^1(\P_\theta)$, uniformly in $h$ for sufficiently small $h$. If so, $\lim_{h \rightarrow 0} \P_\theta [R(\theta; h)] =0$, which verifies differentiability of $\dkl (\P_\theta \Vert \Q)$ and~\eqref{eq: first formula for derivative}.
  By Assumption~\ref{asm: properties that guarantee differentiability of dkl}, we have
  \begin{align*}
    \left \lvert \frac{\d \P_{\theta+s h}}{\d \Q} \frac{\d \Q}{\d \P_\theta} \right \rvert &\leq \frac{\mu_\theta}{\mu_{\theta+sh}} \exp \left (\int_0^\tau \left \lvert \frac{Lq_\theta}{q_\theta}(Y_t) - \frac{Lq_{\theta+sh}}{q_{\theta+sh}}(Y_t) \right \rvert \, \d t \right ) \\
    &\leq M^2 \exp ( C\lvert h \rvert \tau),  
  \end{align*}
  \begin{align*}
    \left \lvert \log \left (  \frac{\d \P_{\theta}}{\d \Q} \right ) \right \rvert
    &\leq  \left \lvert \log \left ( \frac{\mu_\theta}{\nu} \right ) \right \rvert  +  \int_0^\tau \left \lvert  \frac{L q_\theta}{q_\theta}(Y_t) \right \rvert  \, \d t \\
    &\leq \lvert \log \nu \rvert + \lvert \log M \rvert + C \tau, 
  \end{align*}
  and
  \begin{align*}
    \left \lvert \grad_\theta \log \frac{\d \P_{\theta}}{\d \Q} \right \rvert &\leq \left \lvert \frac{\grad_\theta m_\theta}{m_\theta} \right \rvert + \int_0^\tau \left \lvert \grad_\theta  \frac{L q_\theta}{q_\theta}(Y_t) \right \rvert \, \d t  \\
    &\leq M^2 + C \tau.
  \end{align*}
  Therefore, when $\lvert h \rvert \leq \frac{\gamma(\theta)}{2C}$, 
  \begin{align*}
    \lvert R(\theta; h) \rvert &\leq 2(\lvert \log \nu \rvert + \lvert \log M \rvert + C \tau)(M^2+C\tau)\\
                 &\qquad + (1+\lvert \log \nu \rvert + \lvert \log M \rvert + C \tau)(M^2+C\tau) \\
                 &\qquad + (1+\lvert \log \nu \rvert + \lvert \log M \rvert + C \tau) (M^2+C\tau)  M^2 \exp \left ( \frac{\gamma(\theta)}{2} \tau \right).
  \end{align*}
  Under Assumption~\ref{asm: properties that guarantee differentiability of dkl}, the random variable on the right-hand-side above is in $L^1(\P_\theta)$, which concludes the proof of differentiability. 
  
  We now derive a more convenient formula for the derivative.
  As a first step, we observe that one can again exchange expectation and differentiation to obtain
  \begin{align}
    0 &= \grad_\theta \P_\theta [\Omega] \nonumber \\
      &=\grad_\theta \Q \left [\frac{\d \P_\theta}{\d \Q} \right ] \nonumber\\
      &= \Q \left [ \grad_\theta \frac{\d \P_\theta}{\d \Q} \right ] \nonumber\\
      &= \P_\theta \left [  \grad_\theta \log \frac{\d \P_\theta}{\d \Q} \right ]. \label{eq: expectation of score is zero} 
      %&= \Q \left [ \frac{\d \P_\theta}{\d \Q} \left ( \frac{\grad_\theta q_\theta (X_\tau)}{q_\theta(X_\tau)} - \frac{\grad_\theta \mu_\theta}{\mu_\theta} - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(X_s) \, \d s\right ) \right ] \\
      %&= \Q \left [ \frac{\d \P_\theta}{\d \Q} \left ( \frac{\grad_\theta q_\theta (X_\tau)}{q_\theta(X_\tau)} - \frac{\grad_\theta \mu_\theta}{\mu_\theta} - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(X_s) \, \d s\right ) \right ] \\
      %&= {\P_\theta} \left [  \frac{\grad_\theta q_\theta (X_\tau)}{q_\theta(X_\tau)} - \frac{\grad_\theta \mu_\theta}{\mu_\theta} - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(X_s) \, \d s \right ].
  \end{align}
  Now we have 
  \begin{align*}
    \grad_\theta \dkl ( \P_\theta \vert \Q) &= \Q \left [ g' \left ( \frac{\d \P_\theta}{\d \Q} \right ) \grad_\theta  \frac{\d \P_\theta}{\d \Q} \right ] \\
                                            &= \Q \left [ \left ( \log \frac{\d \P_\theta}{\d \Q} + 1 \right ) \grad_\theta \frac{\d \P_\theta}{\d \Q}\right ] \\
                                            %&= \Q \left [\left ( \log \frac{\d \P_\theta}{\d \Q} \right )  \grad_\theta \frac{\d \P_\theta}{\d \Q} \right ] \\
                                            %&\qquad \text{(since $\Q\left [\grad_\theta \frac{\d \P_\theta}{\d \Q} \right ]=0$)} \\
                                            &= \P_\theta \left [\left ( \log \frac{\d \P_\theta}{\d \Q}+1 \right )   \grad_\theta \log \frac{\d \P_\theta}{\d \Q} \right ] \\   
                                            &= \cov_{\P_\theta} \left (    \log \frac{\d \P_\theta}{\d \Q},   \grad_\theta \log \frac{\d \P_\theta}{\d \Q} \right )\\
                                            %&\qquad \text{(since $\P_\theta \left [\grad_\theta \log  \frac{\d \P_\theta}{\d \Q} \right ]=0$)} \\
                                            &= \cov_{\P_\theta} \left (     \log \frac{\nu}{\mu_\theta} + \log q_\theta (X_\tau) - \int_0^\tau \frac{L q_\theta}{q_\theta}(X_s) \, \d s , \right .\\
                                            &\qquad \qquad \quad \left .  \frac{\grad_\theta q_\theta (X_\tau)}{q_\theta(X_\tau)} - \frac{\grad_\theta \mu_\theta}{\mu_\theta} - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(X_s) \, \d s \right )\\
                                            &= \cov_{\P_\theta} \left ( \log q_\theta (X_\tau) - \int_0^\tau \frac{L q_\theta}{q_\theta}(X_s) \, \d s , \right .\\
     &\qquad \qquad \quad \left .  \frac{\grad_\theta q_\theta (X_\tau)}{q_\theta(X_\tau)} - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(X_s) \, \d s \right )\\
                                            %&=  \P_\theta \left [\left ( \log \frac{\nu}{\mu_\theta} + \log q_\theta (X_\tau) - \int_0^\tau \frac{L q_\theta}{q_\theta}(X_s) \, \d s +1 \right )   \grad_\theta \log \frac{\d \P_\theta}{\d \Q} \right ] \\
    %&=\P_\theta \left [\left (\log q_\theta (X_\tau) - \int_0^\tau \frac{L q_\theta}{q_\theta}(X_s) \, \d s \right )   \grad_\theta \log \frac{\d \P_\theta}{\d \Q} \right ] \\
                                            % &= \P_\theta \left [\left ( \frac{\grad_\theta q_\theta (X_\tau)}{q_\theta(X_\tau)} - \frac{\grad_\theta \mu_\theta}{\mu_\theta} - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(X_s) \, \d s \right ) \right . \\
                                            %&\qquad \quad \times \left . \left ( \log \frac{\nu}{\mu_\theta} + \log q_\theta (X_\tau) - \int_0^\tau \frac{L q_\theta}{q_\theta}(X_s) \, \d s \right ) \right ] \\
                                            % &= {\P_\theta} \left [ \left ( \frac{\grad_\theta q_\theta (X_\tau)}{q_\theta(X_\tau)} - \frac{\grad_\theta \mu_\theta}{\mu_\theta} - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(X_s) \, \d s \right ) \right . \\
                                            % &\qquad \quad  \times \left . \left ( \log \frac{\nu}{\mu_\theta} + \log q_\theta (X_\tau) - \int_0^\tau \frac{L q_\theta}{q_\theta}(X_s) \, \d s  \right ) \right ] \\
                                            % &= {\P_\theta} \left [ \left ( \frac{\grad_\theta q_\theta (X_\tau)}{q_\theta(X_\tau)} - \frac{\grad_\theta \mu_\theta}{\mu_\theta} - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(X_s) \, \d s \right ) \right . \\
                                            % &\qquad \quad  \times \left . \left ( \log q_\theta (X_\tau) - \int_0^\tau \frac{L q_\theta}{q_\theta}(X_s) \, \d s  \right ) \right ] \\
                                            % &= \cov_{\P_\theta} \left ( \frac{\grad_\theta q_\theta (X_\tau)}{q_\theta(X_\tau)} - \int_0^\tau \grad_\theta \frac{L q_\theta}{q_\theta}(X_s) \, \d s , \right . \\
                                            % &\qquad \qquad \qquad \left .  \log q_\theta (X_\tau) - \int_0^\tau \frac{L q_\theta}{q_\theta}(X_s) \, \d s \right ).
  \end{align*}
  The fourth equality above follows from~\eqref{eq: expectation of score is zero}, and the last follows since $\log \frac{\nu}{\mu_\theta}$ and $\frac{\grad_\theta \mu_\theta}{\mu_\theta}$ are constants that do not depend on $\omega$.
\end{proof}
\section{Proofs of Results in Section~\ref{sec: numerical}}
\label{apx: proofs for numerics section}

\begin{proof}[Proof of Lemma~\ref{lem: boundary condition on w}]
  For any $x \in \Omega$, we will write $\bar x$ for $\rho(x)$ to simplify notation. Let $w: \Omega \rightarrow \Real$ admit a twice continuously differentiable extension to an open neighborhood of $\overline{\Omega}$. Suppose that for some twice continuously differentiable $w_0 : \partial A \rightarrow \Real$, $w_1 : \partial A \rightarrow \Real$, and $w_2: \Omega \rightarrow \Real$, we have
  \begin{equation}\label{eq: form of w in proof of lemma on representation of committor}
    w(x)  = w_0 (\bar x) + T(x) w_1(\bar x) + T(x)^2 w_2(x)
  \end{equation}
  for all $x \in \Omega$.
  We will show that there can exist at most one triple of functions $w_0$, $w_1$, and $w_2$ solving~\eqref{eq: form of w in proof of lemma on representation of committor}.
  First, observe that if~\eqref{eq: form of w in proof of lemma on representation of committor} holds, then 
  \begin{equation}\label{eq: w_0}
    w_0 (z) = w(z)
  \end{equation}
  for all $z \in \partial A$, since $T=0$ on $\partial A$. Thus, given $w$, equation~\eqref{eq: form of w in proof of lemma on representation of committor} uniquely determines $w_0$. To see that~\eqref{eq: form of w in proof of lemma on representation of committor} also determines $w_1$, observe that 
  \begin{align*}
    \grad w(x)^t  &= \grad w_0 ( x)^t D \rho (x ) + w_1(\bar x)\grad T(x)^t \\
                          &\qquad + T(x) \Big \{\grad w_1 (x)^t D \rho (x) + 2  w_2(x) \grad T(x)^t \Big \} \\
    &\qquad +  T(x)^2 \grad w_2(x)^t.
  \end{align*}
  Thus, for $z \in \partial A$, 
  \begin{equation}\label{eq: normal derivative of w}
    \grad w(z) \cdot n(z) = \grad w_0(z)^t D\rho(z) n(z) + w_1(z) \grad T(z) \cdot n(z), 
  \end{equation}
  hence
  \begin{equation}\label{eq: w1}
     w_1(z) =  \frac{\grad w(z) \cdot n(z) - \grad w_0(z)^t D\rho(z) n(z)}{\grad T(z) \cdot n(z)},
  \end{equation}
  since we assume $\grad T(z) \cdot n(z) >0$.
  Finally, we have $T(x) >0$ for $x \in \Omega \setminus \partial A$, so
  \begin{equation}\label{eq: w2}
    w_2(x) = \frac{w(x) - w_0 (\bar x) - T(x) w_1(\bar x)}{T(x)^2}.
  \end{equation}
  Thus, equation~\eqref{eq: form of w in proof of lemma on representation of committor} determines $w_2$ over $\Omega \setminus \partial A$, and therefore also on $\partial A$, since we assume $w_2$ is continuous. 

  Now observe that for any given $w$, equations~\eqref{eq: w_0},~\eqref{eq: w1}, and~\eqref{eq: w2} define smooth $w_0$, $w_1$, and $w_2$ so that~\eqref{eq: representation of w for zero Lq on boundary of A} holds. To see this, one need only show that $w_2$ defined by~\eqref{eq: w2} is smooth even though $T$ is zero on $\partial A$. For
  \begin{equation*}
    v(x) = T(x)^2 w_2(x) = w(x) - w_0 (\bar x) - T(x) w_1(\bar x),
  \end{equation*}
  we have 
  \begin{equation*}
    \grad v(z) \cdot n(z) = 0
  \end{equation*}
  for $z \in \partial A$. Therefore, by an argument similar to the proof of Lemma~\ref{lem: ratio function is smooth} but carrying the Taylor expansions to higher order, 
  \begin{align*}
    w_2(x) &= \frac{v(x)}{T(x)^2} 
  \end{align*}
  is smooth. We conclude that every smooth $w$ admits a unique expression in the form~\eqref{eq: form of w in proof of lemma on representation of committor}.

  Finally, we show that $L\tilde q = 0$ on $\partial A$ if and only if 
  \begin{equation}\label{eq: w1 so that Lq is zero on boundary of A, in proof of representation lemma}
    w_1 = - \frac{\grad w_0^t D \rho n}{\lvert \grad T \rvert} - \frac{LT}{\lvert \grad T \rvert^2}.
  \end{equation}
  To see this, observe that for $\tilde q = T \exp(w)$, 
  \begin{equation*}
    L \tilde q = \exp(w) \Big \{ L T + 2\eps \grad w \cdot \grad T + T (L w + \eps \lvert \grad w \rvert^2 ) \Big \}.
  \end{equation*}
  Therefore, since $T=0$ on $\partial A$, $L \tilde q =0$ on $\partial A$ if and only if
  \begin{equation}\label{eq: first condition that guarantees Lq zero on boundary of A} 
    L T + 2\eps \grad w \cdot \grad T = 0 
  \end{equation}
  on $\partial A$. Since $T =0$ and $\grad T \cdot n >0$ on $\partial A$, $\grad T = \lvert \grad T \rvert n$ on $\partial A$. Thus,~\eqref{eq: first condition that guarantees Lq zero on boundary of A} reduces to the Neumann boundary condition
  \begin{equation}\label{eq: Neumann bc for w}
    \grad w \cdot n = -\frac{1}{2 \eps} \frac{L T}{\lvert \grad T \rvert}
  \end{equation}
  on $\partial A$. Equation~\eqref{eq: w1 so that Lq is zero on boundary of A, in proof of representation lemma} follows from  this Neumann boundary condition and~\eqref{eq: normal derivative of w}. 
\end{proof}

\bibliographystyle{abbrv}
\bibliography{tpp}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
