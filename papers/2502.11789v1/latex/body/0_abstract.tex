\begin{abstract}

Large Language Models (LLMs) play a vital role in applications like conversational agents and content creation, where controlling a model's personality is crucial for maintaining tone, consistency, and engagement.
However, traditional prompt-based techniques for controlling personality often fall short, as they do not effectively mitigate the model's inherent biases.
In this paper, we introduce a novel method PALETTE that enhances personality control through knowledge editing.
By generating adjustment queries inspired by psychological assessments, our approach systematically adjusts responses to personality-related queries similar to modifying factual knowledge, thereby achieving controlled shifts in personality traits.
Experimental results from both automatic and human evaluations demonstrate that our method enables more stable and well-balanced personality control in LLMs.

\end{abstract}

