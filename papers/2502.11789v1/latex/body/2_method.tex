\section{Method}

\subsection{Preliminaries: Rank-One Model Editing}
Rank-One Model Editing (ROME) is an efficient method for incorporating new knowledge into a 
model without retraining. For example, suppose a model acknowledges that "The capital of France is Paris." By making slight adjustment, 
 we can alter its factual knowledge so that it now recognizes "The capital of France is Marseille." \\ This editing uses a pair of vectors \((k_e, v_e)\) that represent the new fact.
 The \textbf{key vector} \(k_e\) encodes the query phrase (e.g., "The capital of France is"), while the \textbf{value vector} \(v_e\) encodes the target object (e.g., "Marseille"). The weights of a specific layer are updated from \(W_0\) to \(\hat{W}\) via:
\begin{equation}
    \hat{W} = W_0 + \Delta,
\end{equation}
where the update \(\Delta\) is given by:
\begin{equation}
    \Delta = (v_e - W_0 k_e) \frac{k_e^T C_0^{-1}}{k_e^T C_0^{-1} k_e}.
\end{equation}

To mitigate model collapse issues inherent in ROME,  r-ROME~\cite{gupta-etal-2024-rebuilding} refines the update constraints, ensuring more stable knowledge integration. In our work, we employ r-ROME to maintain stability during the modification of self-referential traits.

\subsection{Personality Editing through Relevant Knowledge Editing}
Our approach leverages the knowledge editing framework to modify a model's personality. We hypothesize that, similar to changing factual knowledge, adjusting a model’s responses to personality-related questions can shift its self-perceived personality traits~\cite{Jang2022, Sturgis2023, 10.1111/jopy.12683}.

As illustrated in Figure~\ref{fig:method}, our method comprises two main steps: (1) generating adjustment query based on the structure of psychological assessments (e.g., the MBTI questionnaire) and (2) applying a rank-one update to align the model's responses with the desired personality traits.

\subsubsection{Generating Adjustment Query for Personality Editing}
To alter the model's responses to personality-related questions as in step (1) of Figure~\ref{fig:method}, we generate adjustment queries that specify both the subject and the target personality trait. For a given target trait, we obtain the substantial number of queries per trait compared to factual knowledge editing, designing them based on the MBTI questionnaire. By altering responses to these structured queries, we aim to modify the model's self-representation.


In our setup, the \textit{target\_new} field is populated with the opposite of the model’s original response. For example, as shown in step (1) of Figure~\ref{fig:method}, if the original output begins with "emotionally," then "factual" is assigned to \textit{target\_new}. This approach ensures that the model's self-referential statements ("I" or "me") are modified to reflect the desired personality trait. 
We provide additional details of these adjustment queries in Appendix~\ref{appendix:request_prompts}.

\subsubsection{Personality Editing}
After generating the adjustment queries, we apply the rank-one update technique to adjust the model’s weight matrix. Unlike traditional model editing that focuses on altering external factual knowledge, our method directly targets the model’s internal self-representation. This modify the model’s responses to align with new personality traits, effectively shifting its internal knowledge of personality. 
