\section{Study}
In this study, our goal was to gain insight into how knowledge workers may use an AR device for their daily activities and tasks.
In particular, we focus on the user behaviors and experiences of working with an AR laptop, 
which uses desktop input devices (\ie~keyboard and trackpad) to allow interaction with traditional 2D windows and applications rendered on an HMD.
In contrast to current laptops, our device provides an expanded virtual display space. 
We were particularly interested in three research questions related to AR laptop usage:
(1)~What are the core considerations affecting its use?
(2)~How do these considerations influence participants' configuration and usage of their AR workspace, such as the number and arrangement of virtual windows?
(3)~What are the values and challenges of using an AR laptop?

In the following, we first provide a detailed description of our apparatus and the rationale behind its use.
We then report on our study and analysis methodology. 

\subsection{Apparatus}
\label{sec:apparatus}

Our apparatus %for exploring the use of AR by knowledge workers for their daily tasks and activities 
was informed by the following considerations.
First, the device should have a design and support input methods that enable prolonged interaction~\cite{cheng2022comfortable}.
This suggests that the HMD should ideally be lightweight for user comfort. 
Furthermore, since keyboards and trackpads are generally more efficient and ergonomic than other XR input methods such as speech or gestures for knowledge work-oriented tasks~\cite{zhou2022indepthmouse,knierim2018physicalkeyboardsvr}, our device should incorporate these traditional input modalities.
Second, the device should support common applications for knowledge work, such as an email client, word processor, and web browser. 
In line with Pavanatto~\etal~\cite{pavanatto2024multiplemonitors}, we assume that in the near future, AR will be designed around 2D interfaces to ease the transition from today's personal
computers to computing with virtual displays. 
The device should use familiar interface designs while incorporating AR functionalities for an expanded in situ display space.
 
\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/2-device.pdf}
    \caption{Spacetop EA device (\textit{top left}) and interface (\textit{bottom left}), and a user wearing the device (\textit{right}). Note that for users the background appeared transparent (\ie optical see-through), not black as depicted.}
    \label{fig:device}
    \vspace{-1em}
\end{figure}

After pilot testing several devices and approaches, we chose to use the Sightful Spacetop EA (Early Access)~\cite{spacetopea}, shown in Figure~\ref{fig:device}.
The device consists of a pair of optical see-through display glasses (Xreal Light, $85$ grams, OLED display panels, $1920 \times 1080$ pixels per eye, $72$ Hz refresh rate, $~52^\circ$ diagonal field of view) for output attached to a standard keyboard and trackpad for input.
It has a Qualcomm Snapdragon XR2 processor, 
a Kryo 585TM 8-core 64-bit CPU, an AdrenoTM 650 GPU, and 8GB of LPDDR5 RAM.
%The device consists of a pair of optical see-through display glasses ($85$ grams, OLED display panels, $1920 \times 1080$ pixels per eye, $90$ Hz refresh rate, $50^\circ$ diagonal field of view) for output attached to a standard keyboard and trackpad for input.
%It has a Qualcomm Snapdragon QCS8550 processor, a Kyro CPU, an Adreno 740 GPU, and 16GB of LPDDR RAM.
The device runs the Spacetop OS~\cite{spacetopos}, which enables users to flexibly open, close, resize, and move one or more window-based web applications (\eg~Google workspace application, WhatsApp, ChatGPT) on top of a virtual ``spatial canvas''~\cite{spacetopspatialcanvas} --- a unified display space that is curved over a cylinder surrounding the user, similar to the concept described by Pavanatto~\etal~\cite{pavanatto2024multiplemonitors}.
The spatial canvas is notably world-anchored~\cite{feiner1993windows} and can be zoomed in and out of, panned from side to side, height adjusted, tilted, and re-centered over the device keyboard~\cite{spacetopadjustcanvas}. 
We chose the device over video passthrough options like the Meta Quest 3~\cite{metaquest3} or Apple Vision Pro~\cite{apple2023introducingvp} mainly because of its lighter and more ergonomic glasses form factor, which is essential for prolonged productive tasks~\cite{biener2022vrweek}.

\subsection{Experimental Design and Procedure}
To address our research questions, 
we designed a longitudinal, in situ diary and interview study aimed at understanding people's usage patterns and perceptions.
As discussed by Bailenson~\etal~\cite{bailenson2024seeing},
longitudinal studies with AR are critical to understanding behaviors and challenges associated with its anticipated ``all-day use.''
Abowd~and~Mynatt~\cite{abowd2000chartingubicomp} highlighted the need for evaluations to be carried out in everyday computing environments, rather than solely in controlled laboratory settings, to achieve greater ecological validity.

Our particular approach was guided by several studies of methodological similarity (\eg~\cite{czerwinski2004diary,borghouts2022diary,jokela2015diary}).
Diary studies are a common qualitative research method in HCI~\cite{consolvo2017diary}, widely used to understand behavior over longer periods, such as working within multi-device ecologies~\cite{jokela2015diary} or work-from-home conditions during the COVID-19 pandemic~\cite{borghouts2022diary}.
In the following, we describe how we adapted these methodologies to capture in-depth data on knowledge workers' use and perceptions of AR in their daily activities.
The study was approved by the IRB of the participating research institutions.

Our study was conducted in three phases: an initial onboarding session, a two-week usage period, and a final interview.
All study protocols and surveys are documented in the Supplementary Material. 

\paragraph{Onboarding.}
Recruited participants were invited into the laboratory for an hour-long onboarding session. 
During this session, they were first informed about the procedure and content of the study. 
Following this, they signed a consent form and completed a background questionnaire. 
Afterward, the participants were introduced to the AR laptop and its key features. 
The experimenter guided them through the operations of turning the device on and off, adjusting the display brightness, opening and modifying windows, and moving and recentering their virtual canvas.
Finally, participants were given time to freely explore the features of the device and ask questions accordingly.
After participants indicated their comfort with the device controls, they were given the device to use in their own work environments during the second phase of the study. 
We also shared a reference guide to navigate the core functionalities of the device and encouraged participants to reach out if they encountered any issues or questions.

\paragraph{Usage and Diary Study.} 
We deployed the Sightful EA device to each participant for two weeks (14 days). During this usage period, participants were instructed to complete a minimum of 10 sessions, with each session involving at least 30 minutes of continuous use.
Participants had the option to complete additional sessions for extra compensation.

Participants were encouraged to use the device during their daily activities and tasks, which they would typically complete regardless of their participation in the study, in the familiar locations they frequented as part of their routines.
We deliberately chose not to set specific constraints on the task and environment, in order to gather more ecologically valid data on participants' usage behaviors.
We set individual sessions at a minimum of 30 minutes to ensure that participants had enough time to engage in meaningful tasks.
We evaluated usage across ten daily sessions to allow participants to acclimate to the device and understand how their usage changes with different tasks and extended exposure, without overburdening them. 

After each session, participants were tasked with completing a diary entry, administered as a survey. 
The survey prompted participants to report on
what tasks they completed on and off the device, 
where they completed the task, 
and when the session started and ended.
It also asked how participants organized their virtual workspaces, any adjustments they made, and the factors that influenced these processes. 
Moreover, it inquired about participants' likes and dislikes regarding the device.
Finally, it asked participants to optionally upload photographs of their physical surroundings and virtual workspace.
The survey took around 15 minutes to complete. 
Participants received daily emails reminding them to complete their session and diary entry. 
We encouraged them to fill out the diary entry immediately after their sessions. 

We conducted pilot tests of the survey with four knowledge workers, who were recruited through snowball sampling. 
These pilot sessions helped us identify core questions, clarify wording, and ensure data quality. 
We revised the survey after each round of feedback. 
The results from these pilot sessions were not included in our analysis.

\paragraph{Interview.}
At the end of each participant's usage sessions, 
we reviewed their diary entries in advance to prepare for the semi-structured interviews.
We organized the interview into four blocks.
We first asked about the tasks performed on the device, whether any tasks were notably well or poorly suited, and how their experience using AR for these tasks compared to conventional devices.
Second, we asked how participants organized their virtual workspaces, how these workspaces evolved over time and across sessions, and the factors they considered.
We then investigated how participants engaged in non-AR activities (\eg~checking their phones) while using the device.
At the end of the interview, participants were asked to summarize the main benefits and drawbacks of the device, and to envision how AR might be used in knowledge work in the future.
Throughout the interview, participants could refer back to their diary entries, which we collated into a spreadsheet.
We also often asked participants to provide more details about some of their responses.
Interviews lasted around 30 minutes and were audio recorded. 
Half of the participants (N=7) completed the interview in-person, while the other half participated remotely.

\paragraph{}
Participants received $\$150$
for completing ten usage sessions and the exit interview.
They received $\$15$ for each additional session they completed beyond the minimum requirements.
Usage sessions took place from March 19, 2024, to August 29, 2024.
We deployed between two and three devices simultaneously to speed up data collection.


\subsection{Participants}
We recruited 14 people (aged 22 to 56 years, \statsum{30}{11}{}; 9 male, 5 female) with normal or corrected vision to participate in the study. 
We recruited university students, researchers, and staff for our study due to their diverse tasks, extensive computer use in their work, and availability~\cite{babaei2020facesoffocus}.
% AR / VR experience
Participants self-reported low to moderate experience with AR (\statsum{2.6}{1.8}{}) and VR (\statsum{3.1}{1.7}{}) on a scale from 1 (low) to 7 (high).
Participants indicated that they regularly use 2 to 7 (\statsum{4}{1}{}) digital devices (\ie~mobile phones, laptops, tablets, and smartwatches).
They reported spending approximately 5 to 14 hours each day (\statsum{7}{2}{}) on their primary device, which was either a laptop or desktop computer.
% Nine participants reported frequently using multi-screen setups (\ie~with 2 to 4 screens, \statsum{2}{1}{}).
All participants reported working remotely to some extent, typically at least once a week.
They also reported having normal or corrected-to-normal vision.

\subsection{Data Collection and Analysis}
\label{sec:analysis}
We collected our data from three main sources:
written diary survey entries,
workspace photographs, 
and interview audio recordings.
Participants collectively submitted a total of 143 diary entries. 
Ten participants completed 10 entries each, two participants completed 11 entries, and one participant completed 12 entries. 
One participant submitted one fewer entry than required (9 entries) due to an experimenter's miscalculation.
On average, each session lasted $42$ minutes ($SD$ = 16). 
In total, the diary entries documented 103 cumulative hours of work (\statsum{7.3}{1.6}{} hours per person). 

In addition, participants collectively submitted 140 photographs of their virtual workspaces and 109 photographs of their physical environments. 
All interviews with participants were transcribed.

\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{figures/themes.pdf}
    \caption{\textbf{Themes} --- We report on how considerations, such as the participants' tasks, influenced their workspace arrangement behaviors, such as the number of windows they opened. In addition, we highlight alternative workflows that involve the use of AR in tandem with physical displays and tasks. Finally, we summarize participants' perceptions of the value and challenges of using AR.}
    \label{fig:themes}
\end{figure*}

For our analysis, we adopted a similar methodology as Biener~\etal~\cite{biener2024holdtight} and Yuan~\etal~\cite{yuan2022multideviceusage}, using \emph{a priori} and open coding to create a codebook to characterize participants' usage and perceptions of the AR laptop.
We started our codebook based on our research questions and related literature (see Section~\ref{sec:related-work}), which documented various AR usage patterns (\eg~window arrangements), values, and challenges.
We then iteratively refined and expanded our codes using the collected data.
In each round of coding, 
two authors independently reviewed and labeled all survey, image, and interview data with existing codes, while defining new codes for relevant behaviors and comments that had not been previously captured.
The authors then convened to discuss the resulting set of codes and their respective scopes, merging similar codes and consolidating them into a shared codebook.
An affinity diagram was often used to help facilitate this process.

The final codebook comprised 171 individual codes that detailed the tasks participants performed using the AR laptop, 
the physical environments in which they worked,
how they organized their virtual workspace for their tasks,  
and their perceptions regarding the value and limitations of the device.
Using this shared codebook, 
two authors collaboratively conducted a final round of coding on the original data. 
They applied the codes from the codebook to each instance, labeling every survey entry and interview with zero or more codes, based on a unanimous decision.
We do not report inter-rater reliability because following best practices from Hammer and
Berland~\cite{hammer2014irrcritique}, coding for each instance was unanimously agreed upon by annotators.
The same two authors also led the clustering process, organizing the codes into themes. 
These themes were refined iteratively with feedback from the remaining members of the research team, resulting in the findings presented below.




