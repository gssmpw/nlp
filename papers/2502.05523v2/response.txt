\section{Related Works}
% \subsection{Ranking models in recommendation}
% The ranking models, typically represented by click-through rate prediction algorithms with an embedding\&multi-layered perceptions (MLP) paradigm, serve as the last stage of the industrial ecommendation system funnel and thus play a pivotal role in personalizing user recommendations in content platforms and e-commerce **Rendle, "Factorization Machines"**__**Juan et al., "DeepFM: Understanding Gradient Boosting Incentives"**. In the past decades, there has been tremendous research work developed to better capture user potential intention and discriminative representation for enhancing the prediction performance of the ranking model, which can be generally divided into feature interaction methods and target-aware sequence modeling methods.

% \textbf{Feature Interaction Modeling in Ranking.} Focusing on modeling discrete identifiers (IDs) feature interactions to capture the co-occurance patterns, **Juan et al., "DeepFM: Understanding Gradient Boosting Incentives"** models the inner product of the latent vectors of features. **Chen et al., "Wide \& Deep Learning for Recommenders"** further replaces the wide part in wide\&deep____ as FM to reduce labor costs in manually selecting features. Furthermore, **Wang et al., "Deep and Cross Network for Ad Click Predictions"** applies a recursive and layerwise feature cross machanism with multiple orders, and **Zhang et al., "Deep and Cross Network V2 for Enhanced Recommenders"** further enhances the interaction by boosting the vector-form crossing to a matrix-form to pursue improved performance. To leverage the merits of different interaction structures, **Zhou et al., "Deep and Hierarchical Ensemble Network for Efficient Recommendation"** is designed to ensemble and complement heterogeneous modules to better capture feature interaction relationships. 

% \textbf{Target-aware Sequential Modeling in Ranking.} The other significant progress in ranking models is the capture of user intention via sequential modeling. As the target item can be readily acquired and interacted in the ranking model of industrial recommenders, the most typical modeling paradigm is thus to use the target attention mechanism to extract user intentions from behavioral sequences. Among them, the representative milestone, i.e., **Li et al., "Deep Interest Network for Recommendation"**, actually launched a novel direction in recommendation which builds a MLP-based target-aware attention mechanism and aggregates the sequence through weighted sumpooling. After that, **Zhou et al., "Deep Interest Evolution Network for Enhanced Personalization"**, **Chen et al., "Deep Interest Highlight Network for Efficient Ranking"**, and **Yang et al., "Search-Based Interest Model for Next Recommendation"** are further developed by considering the evolving process, trigger-induced ranking, and two-stage long sequence modeling. Besides, **Wang et al., "Co-Action Network for Multi-Domain Recommendation"** developed a target-and-sequence-item co-action unit to capture the interaction and aggregate user sequence. Besides, with the rapid progress of transformer-based models____, the scaled dot-product based multi-head target attention (MHTA), has also been widely applied to sequential modeling. 

% Despite the broad developments in terms of both feature interaction and sequential modeling, the multi-domain problem that widely exist in large-scale recommender systems has been seldomly considered in these methods.

% \subsection{Multi-Domain Recommendation}
% As a major area in both multi-domain learning and domain adaptation, multi-domain recommendation aims to provide accurate personalized recommendation results for users and items from multiple domains. Early efforts for multi-domain recommendation are generally made by building separate models for different domains with the domain-specific data, or a unified model with the data mixed from multi-domains____. However, the separate modeling ignores the commonalities lied in different domains, while the unified modeling paradigm overlook the difference among various domains, which leads to insufficient exploration of multi-domain data and may hurt the performance on specific domains, yielding suboptimal performance. To further mitigate the issue, traditional methods generally follow a coarse-grained separate-and-shared paradigm for multi-domain recommendation. For example, **Yu et al., "STAR: Shared-Task-Aware Multi-Domain Recommendation"** decompose the network parameters into common-parameters and domain-specific-parameters, and the latter are trained with domain-specific data only. **Chen et al., "PLE: Private-Shared Experts for Multi-Domain Learning"** builds private and shared experts and aggregates the multi-experts output through a gating mechanism. Furthermore, the fine-grained parameter generation methods draw increased attention recently. **Tang et al., "APG: Adaptive Parameter Generation for Multi-Domain Recommendation"** learns a instance-wise specific network parameter to replace the conventional all-shared parameters. **Wang et al., "AdaSparse: Sparse Personalized Structure for Efficient Ranking"** further builds sparse personalized structure for different samples by disabling the neurons with small values. Despite effectiveness, these methods are designed for neural network structures, while the multi-domain learning for sequential-modeling is seldom considered.
% % i.e., most of these methods are designed for replacing the simple single-domain MLPs in industrial recommenders, 

% Some other methods also contribute learning personalized embeddings for multi-domain recommendation. The typical idea is to use the gate mechanism to generate bitwise weights to reweigh the embeddings in recommenders. For example, **Wang et al., "GateNet: Multi-Domain Embedding Weighting via Gate Mechanism"** calculates a feature-wise weight to represent its importance which is then used to reweigh the feature embedding. However, this weight is obtained by forward the feature itself via a linear transformation, and thus GateNet is inherently embedding-reweighting method with no personalities across different users. To this end, **Chen et al., "FRNet: Feature Refinement Network for Multi-Domain Recommendation"** is developed with all the user-features as context as gate input, which thus provides user-level personalized weight on specific features compared with GateNet. However, both methods are purely developed for learning adaptive embedding representations, without considering the impact of multi-domains. To this end, **Wang et al., "PEPNet: Parameter and Embedding Personalization Network"** ____ and **Li et al., "Domain Facilitated Feature Modeling for Multi-Domain Recommendation"** ____ are developed. PEPNet provides a unified structure to personalize both network parameters and embeddings. Specifically, similar to AdaSparse, PEPNet takes domain-specific features as gate input, and the generated bit-wise weights are then used to scale both the embeddings and the input of each layer in the network. Besides, DFFM is proposed to incorporate the domain-specific information into embedding personalization and sequence modeling, while for the latter, the generated weights are used to modify the parameters in self-attention via a simple linear transformation, which is not flexible and sufficient enough to capture the impact of multi-domain in target-aware sequential modeling. Besides, the multi-domain impact of the candidate item on different behavioral items is seldom considered in existing methods.