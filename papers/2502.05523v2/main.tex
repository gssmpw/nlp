\PassOptionsToPackage{table}{xcolor}
\documentclass[sigconf]{acmart}
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


\usepackage{amsthm,amsmath,bm}
\usepackage{multirow}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{subfigure} 
\usepackage{float}
\usepackage[export]{adjustbox} 
\usepackage{xspace}
\usepackage{adjustbox}
\graphicspath{ {./Figs/} }

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{balance}
\usepackage{enumitem}
% \usepackage{multirow}
% \usepackage{xcolor}

\newcommand{\eat}[1]{}
\newcommand{\paratitle}[1]{\vspace{1.5ex}\noindent\textbf{#1}}
\newcommand{\ie}{\emph{i.e.,}\xspace}
\newcommand{\aka}{\emph{i.e.,}\xspace}
\newcommand{\eg}{\emph{e.g.,}\xspace}
\newcommand{\baby}{ADS\xspace}
\newcommand{\etal}{\emph{et al.}\xspace}
\newcommand{\ignore}[1]{}
\newcommand{\fixme}[1]{\textbf{\emph{[FIXME: #1]}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation emai}{June 03--05,
  2018}{Woodstock, NY}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Adaptive Domain Scaling for Personalized Sequential \\Modeling in Recommenders}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Zheng Chai}
% \authornote{Both authors contributed equally to this research.}
\email{chaizheng.cz@bytedance.com}
\affiliation{%
  \institution{ByteDance}
  \city{Hangzhou}
  \country{China}
}

\author{Hui Lu}
% \authornote{Both authors contributed equally to this research.}
\email{luhui.xx@bytedance.com}
\affiliation{%
  \institution{ByteDance}
  \city{Hangzhou}
  \country{China}
}

\author{Di Chen}
% \authornote{Both authors contributed equally to this research.}
\email{chendi.666@bytedance.com}
\affiliation{%
  \institution{ByteDance}
  \city{Beijing}
  \country{China}
}

\author{Qin Ren}
% \authornote{Both authors contributed equally to this research.}
\email{renqin.97@bytedance.com}
\affiliation{%
  \institution{ByteDance}
  \city{Beijing}
  \country{China}
}

\author{Yuchao Zheng\textsuperscript{†}}
% \authornote{Both authors contributed equally to this research.}
\thanks{\textsuperscript{†}Corresponding Author.}
\email{zhengyuchao.yc@bytedance.com}
\affiliation{%
  \institution{ByteDance}
  \city{Beijing}
  \country{China}
}

\author{Xun Zhou}
% \authornote{Both authors contributed equally to this research.}
\email{zhouxun@bytedance.com}
\affiliation{%
  \institution{ByteDance}
  \city{Beijing}
  \country{China}
}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Users generally exhibit complex behavioral patterns and diverse intentions in multiple business scenarios of super applications like Douyin, presenting great challenges to current industrial multi-domain recommenders. To mitigate the discrepancies across diverse domains, researches and industrial practices generally emphasize sophisticated network structures to accomodate diverse data distributions, while neglecting the inherent understanding of user behavioral sequence from the multi-domain perspective. In this paper, we present Adaptive Domain Scaling (\baby) model, which comprehensively enhances the personalization capability in target-aware sequence modeling across multiple domains. Specifically, \baby comprises of two major modules, including personalized sequence representation generation (PSRG) and personalized candidate representation generation (PCRG). The modules contribute to the tailored multi-domain learning by dynamically learning both the user behavioral sequence item representation and the candidate target item representation under different domains, facilitating adaptive user intention understanding. Experiments are performed on both a public dataset and two billion-scaled industrial datasets, and the extensive results verify the high effectiveness and compatibility of \baby. Besides, we conduct online experiments on two influential business scenarios including Douyin Advertisement Platform and Douyin E-commerce Service Platform, both of which show substantial business improvements. Currently, \baby has been fully deployed in many recommendation services at ByteDance, serving billions of users.
  
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>00000000.0000000.0000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>00000000.00000000.00000000</concept_id>
  <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

% \ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
\ccsdesc[500]{Information systems~Recommender systems}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Multi-Domain Learning, Sequential Modeling, Ranking, Personalized Recommender System}

% \keywords{Candidate Matching, Multi-Interest Learning, Recommendation}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
% \begin{teaserfigure}
%   \includegraphics[width=\textwidth]{sampleteaser}
%   \caption{Seattle Mariners at Spring Training, 2010.}
%   \Description{Enjoying the baseball game from the third-base
%   seats. Ichiro Suzuki preparing to bat.}
%   \label{fig:teaser}
% \end{teaserfigure}

% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle





\section{Introduction}

\begin{figure}[H]
% [!t]
\centering
\begin{minipage}[b]{\linewidth}
\subfigure[Short-Video]{
\includegraphics[width=0.31\linewidth,trim=90 0 90 0,clip]{figs/video.jpg}
}
\subfigure[Live-Preview]{
\includegraphics[width=0.31\linewidth,trim=90 0 90 0,clip]{figs/live-preview.jpg}
}
\subfigure[Live-Slide]{
\includegraphics[width=0.31\linewidth,trim=90 0 90 0,clip]{figs/live_slide2.jpg}
}
\end{minipage}
\caption{Typical business scenarios in Douyin.}
\label{fig:scenarios}
\end{figure}


With the exponential growth of digital contents and the widespread use of the internet, recommender systems have become a vital role for enhancing user experience and alleviating information overload \cite{zhang2019deep}. In real-world applications, for improving user retention and promote business benefit, the demands of industrial recommendation are widely distributed cross multiple  domains \cite{jiang2022adaptive, li2023one}. For example, as shown in Fig~\ref{fig:scenarios}, in Douyin\footnote{https://www.douyin.com/}, one of the largest video-watching apps in the world, the major domains include \textit{Short-videos, Live-preview}, and \textit{Live-slide}, where users can watch short-videos, live-streams, and enjoy the e-commerce and local-life services. Besides, due to its billion-scale user volume, different user groups, like users from different countries, with different genders, highly-active or not, also contribute to different domains. As the data distrbutions are quite diversed across different domains, it poses a significant multi-domain modeling problem for the recommender system \cite{zhang2024multi}.



\eat{
% \begin{figure}[H]
% % [!t]
% \centering
% \subfigure[Short-Video]{
% \begin{minipage}[b]{0.147\textwidth}
% \centering
% % \hspace{-0.4cm}
% \includegraphics[scale=0.08,trim=50 0 50 0,clip]{figs/video.jpg}
% \end{minipage}
% }
% \subfigure[Live-Preview]{
% \begin{minipage}{0.147\textwidth}
% \centering
% % \hspace{-0.4cm}
% \includegraphics[scale=0.08,trim=50 0 50 0,clip]{figs/live-preview.jpg}
% \end{minipage}
% }
% \subfigure[Live-Slide]{
% \begin{minipage}{0.147\textwidth}
% \centering
% % \hspace{-0.4cm}
% \includegraphics[scale=0.08,trim=50 0 50 0,clip]{figs/live-slide.jpg}
% \end{minipage}
% }
% \caption{Typical scenarios in Douyin.}
% \label{fig:scenarios}
% \end{figure}
}



% users generally exhibit diverse interests or demands in different scenarios, this

% early efforts for multi-domain recommendation are generally made by building separate models for different domains with the domain-specific data, or a unified model with the data mixed from multi-domains\cite{guo2023dffm}. However, the separate modeling ignores the commonalities lied in different domains, while the unified modeling paradigm overlook the difference among various domains, which leads to insufficient exploration of multi-domain data and may hurt the performance on specific domains, yielding suboptimal performance.

% To this end, current industrial practitioners generally build a shared-bottom with multiple-heads outputs structure, which leverages the advantages of both separate modeling and unified mixup modeling for multiple domains, and has been widely deployed as the \textit{de facto} common practice in industry\cite{caruana1993multitask}. To further improves this structure, recent approaches have put efforts in building elaborated network structures to enhance the ability in depicting multiple domains. In general, these methods can be divided into two categories: the domain-level methods like the star topology adaptive recommender(STAR) \cite{sheng2021one}, progressive layered extraction (PLE)\cite{tang2020progressive}, etc., and the instance-level methods like adaptive parameter generation network (APG)\cite{yan2022apg}, AdaSparse\cite{yang2022adasparse}, etc. However, most of the existing approaches are designed for complicating the network structures, while the approaches on multi-domain sequential-modeling attract much less attention.

% Sequential modeling plays a vital role in current industrial recommenders, among which the most popular and effective methods are the target attention-based methods, and the most notable work includes deep interest network (DIN) \cite{zhou2018deep}, feature co-action network (CAN)\cite{bian2022can}, and multi-head target attention (MHTA). In the advertising system of Douyin, after omitting the target attention module from the conversion-rate prediction (CVR) model, the area under ROC (AUC) metric is decreased by around 0.2\%, which is a significantly unacceptable loss and substantiates the validity of target attention based sequential modeling. Despite its significance, the impacts from multi-domain discrepancies are less considered in existing target attention methods, leaving a remarkable gap for the area of multi-domain modeling.

% Generally speaking, the current target attention mechanism can be written as a typical query-key-value modeling paradigm: $g(Rep_{cand}, Rep_{seq}) \times Rep_{seq}$, where $Rep_{Cand}$ denotes the representation of the candidate target item whose click/convert probabilities need to be predicted, $Rep_{seq}$ indicates the user sequential representation, and $g$ denotes the calculation of attention weight between any sequence-item-target-item pairs. As discussed previously, current industrial recommenders generally follow a share-bottom embedding paradigm, which means that 1) the embedding table of both the candidate item and user behavioral items are fully shared, with no consideration of the distinctions between items and users belonging to different domains, and 2) the candidate item serves as a shared query for different keys/values, with no consideration of the distinctions between the multiple items in user sequence which generally occurs across multiple domains. According, this poses potential challenges to the current multi-domain recommenders from two aspects:

% % Existing work lacks differentiation for different domains in terms of sequence representation modeling, while user behavior patterns across different domains are generally different. 


% %On one hand, from user-level, different user domains pay different attentions on the features of candidate items. For example, in Douyin E-commercial services, content preference-oriented users may put a higher value on the video creator; while price preference-oriented users care more about the price of the item. On the other hand, from sequence-item-level, the target item should be able to pay multi-aspects representation of the sequence items, i.e., the candidate item should also be personalized for different sequence items.
% \begin{itemize}[leftmargin=*]
%     \item \textbf{Personalization of the Sequence Representations}. The multi-domain representations of identical items occured in different user's sequences are of necessity in multi-domain recommenders. For example, new users would like to watch the highly-liked videos, while some long-time users may pay attention to those followed video creators. Thus, the same video shows different attractions to various users, while its embedding is a shared representation among different user sequences, which hinders the recommender to grasp the actual intention of the user.
%     \item \textbf{Personalization of the Candidate Item}. For different users, or different items in the identical user's sequence, the candidate item has different influence and function due to the multi-domain impact. For example, user's shopping behaviors in Douyin Mall might be primarily influenced by product prices, while the video creators have a more significant impact on the shopping behaviors in Douyin short-videos scenario for content preference-oriented users. Thus an identical candidate item should be personalized to accomodate to different historical items in user sequence.
% \end{itemize}

% To overcome the limitations and fulfill the gap in multi-domain target attention modeling, we propose Personalized Target Attention Network (\baby), which fully mines the personalization modeling ability of the current target-attention based recommenders and provides more accurate and adaptive intention understanding ability in multi-domain tasks. Specifically, \baby comprises of two modules, namely, Personalized Sequence Representation Generation (PSRG) and Personalized Candidate Representation Generation (PCRG). In PSRG, we designed a novel shared-and-private structure for learning multi-domain item representations in user behaviors, which aims to generate personalized representations for sequence items, i.e., the same item occured in different user's sequence has different representations. In PCRG, the candidate item further enhances the personalization modeling ability via generating different target candidates representations for different sequence items. With the domain-related information as input for the generation structures, the impact of multi-domains are sufficiently injected to the sequence modeling, and thus enhances user intention understanding. Note that \baby is an efficient plug-and-play network, and can be readily integrated into the current popular target attention mechanisms.


To this end, \textit{de facto} common industrial practices generally build a shared-bottom with multi-heads outputs model structure, leveraging the advantages of both separate and unified mixup modeling for multiple domains \cite{caruana1993multitask}. To further improve this, recent approaches have put efforts in building elaborate network structures to enhance multi-domain modeling, e.g., the domain-level methods like the star topology adaptive recommender (STAR) \cite{sheng2021one}, progressive layered extraction (PLE) \cite{tang2020progressive}, and the instance-level methods like adaptive parameter generation network (APG) \cite{yan2022apg}, AdaSparse \cite{yang2022adasparse}, etc. However, most of the existing approaches are designed for sophisticated feature interaction network structures, while the approaches to multi-domain sequential modeling attract much less attention.

% In general, these methods can be divided into two categories: the domain-level methods like the star topology adaptive recommender(STAR) \cite{sheng2021one}, progressive layered extraction (PLE)\cite{tang2020progressive}, etc., and the instance-level methods like adaptive parameter generation network (APG)\cite{yan2022apg}, AdaSparse\cite{yang2022adasparse}, etc. 

Sequential modeling plays a vital role in industrial recommenders, among which the most popular and effective methods are the target-aware attention based methods, for example, deep interest network (DIN) \cite{zhou2018deep}, feature co-action network (CAN) \cite{bian2022can}, and multi-head attention (MHA) \cite{vaswani2017attention}. In the advertising system of Douyin, after omitting the target attention module from the conversion-rate prediction (CVR) model, the area under ROC (AUC) metric decreases by over 0.2\%, which is a significantly unacceptable loss and substantiates the validity of target attention based sequential modeling. Despite its significance, the impacts of multi-domain discrepancies are less considered in existing target attention methods, leaving a remarkable gap for the area of multi-domain modeling. 

Generally speaking, the current target attention mechanism for user sequence can be formulated as a typical query-key-value modeling paradigm: $g(Rep_{cand}, Rep_{seq}) \times Rep_{seq}$, where $Rep_{cand}$ denotes the representation of the candidate target item whose click/convert probabilities need to be predicted, $Rep_{seq}$ indicates the user sequence embeddings, and $g$ calculates the attention weight between any sequence-item and target-item pairs. As discussed previously, current industrial recommenders generally follow a shared-bottom embedding paradigm, which means that 1) the embedding table of both the candidate item and user behavioral items are fully shared, with no consideration of the distinctions between items and users belonging to different domains, and 2) the candidate item serves as a shared query for different keys/values, with no consideration of the distinctions between the multiple items in user sequence which generally occurs across multiple domains. Accordingly, this poses potential challenges to the current multi-domain recommenders from two aspects:

% Existing work lacks differentiation for different domains in terms of sequence representation modeling, while user behavior patterns across different domains are generally different. 


%On one hand, from user-level, different user domains pay different attentions on the features of candidate items. For example, in Douyin E-commercial services, content preference-oriented users may put a higher value on the video creator; while price preference-oriented users care more about the price of the item. On the other hand, from sequence-item-level, the target item should be able to pay multi-aspects representation of the sequence items, i.e., the candidate item should also be personalized for different sequence items.
\begin{itemize}[leftmargin=*]
    \item \textbf{Personalization of the Sequence Representations}. The multi-domain representations of identical items occurred in different users' sequences are of necessity in recommenders. For example, new users would like to watch the highly-liked videos, while some long-time users may pay attention to the video creators they follow. Thus, the same video shows different attractions to various user domains, while its embedding is a shared representation among different user sequences, which hinders the recommender to grasp the actual intention of the user.
    \item \textbf{Personalization of the Candidate Item}. For different users or different items in the same user's sequence, the candidate item has different influence and function due to the multi-domain impact. For example, user's shopping behaviors in Douyin Mall might be primarily influenced by product prices, while the video creators have a more significant impact for content-preferred users in Douyin short-videos scenario. Thus an identical candidate item should be personalized across domains to accommodate different historical items in user sequence.
\end{itemize}
% on the shopping behaviors 

To overcome the limitations and fulfill the gap in multi-domain target-aware attention modeling, we propose Adaptive Domain Scaling (\baby) model, which fully mines the personalization modeling ability of the current target-attention based recommenders and provides more accurate and adaptive intention understanding ability in multi-domain tasks. Specifically, \baby comprises two modules, namely, Personalized Sequence Representation Generation (PSRG) and Personalized Candidate Representation Generation (PCRG). In PSRG, we designed a novel shared-and-private structure for learning multi-domain item representations in user behaviors, which aims to generate personalized representations for sequence items, i.e., the same item occured in different user's sequence has different representations. In PCRG, the candidate item further enhances the personalization modeling ability via generating different target candidate representations for different sequence items. With the domain-related information as input for the generation structures, the impact of multi-domains are sufficiently injected to the sequence modeling, and thus enhances user intention understanding. Note that \baby is an efficient plug-and-play network, and can be readily integrated into current recommenders.

The contribution of this work can be summarized as follows:
\begin{itemize}[leftmargin=*]
\item We present Adaptive Domain Scaling (ADS) model, an effective plug-and-play personalization network structure for multi-domain user intent understanding by personalizing the target-aware attention modeling. We conduct extensive experiments on both a public dataset and two billion-scaled industrial dataset, and the results verify its superiority.
\item Both personalized sequence representation generation and personalized candidate representation generation modules are developed in our framework, which captures the multi-domain characteristics from the viewpoint of users behavioral sequences and candidate target item, enhancing the multi-domain learning efficacy for current target-aware attention mechanisms.



% A personalized sequence representation generation is first designed in our framework, which capture the user sequence representation from a dynamic viewpoint. Besides, to capture item-level personalization, a personalized candidate representation generation method is devised, which further enhances the multi-domain learning efficacy.
\item We deploy \baby in both the advertisement system and the e-commercial system of Douyin at ByteDance, which brings significant 1.09\% and 0.79\% lifts of total revenue in the Douyin ads system and the e-commercial system, respectively. Currently, \baby has been fully deployed in many recommendation systems at ByteDance, serving billions of users.
\end{itemize}

 % As the last stage of the recommendation system funnel, the ranking model aims to determine the order of items presented to users in industrial recommendations 
% \section{Related Works}
% \subsection{Ranking models in recommendation}
% The ranking models, typically represented by click-through rate prediction algorithms with an embedding\&multi-layered perceptions (MLP) paradigm, serve as the last stage of the industrial ecommendation system funnel and thus play a pivotal role in personalizing user recommendations in content platforms and e-commerce\cite{covington2016deep, chai2022umi}. In the past decades, there has been tremendous research work developed to better capture user potential intention and discriminative representation for enhancing the prediction performance of the ranking model, which can be generally divided into feature interaction methods and target-aware sequence modeling methods.

% \textbf{Feature Interaction Modeling in Ranking.} Focusing on modeling discrete identifiers (IDs) feature interactions to capture the co-occurance patterns, FM\cite{rendle2010factorization} models the inner product of the latent vectors of features. DeepFM \cite{guo2017deepfm} further replaces the wide part in wide\&deep\cite{cheng2016wide} as FM to reduce labor costs in manually selecting features. Furthermore, Deep and Cross Network (DCN)\cite{wang2017deep} applies a recursive and layerwise feature cross machanism with multiple orders, and DCN-v2\cite{wang2021dcn} further enhances the interaction by boosting the vector-form crossing to a matrix-form to pursue improved performance. To leverage the merits of different interaction structures, Deep and Hierarchical Ensemble Network (DHEN)\cite{zhang2022dhen} is designed to ensemble and complement heterogeneous modules to better capture feature interaction relationships. 

% \textbf{Target-aware Sequential Modeling in Ranking.} The other significant progress in ranking models is the capture of user intention via sequential modeling. As the target item can be readily acquired and interacted in the ranking model of industrial recommenders, the most typical modeling paradigm is thus to use the target attention mechanism to extract user intentions from behavioral sequences. Among them, the representative milestone, i.e., DIN\cite{zhou2018deep}, actually launched a novel direction in recommendation which builds a MLP-based target-aware attention mechanism and aggregates the sequence through weighted sumpooling. After that, deep interest evolution network\cite{zhou2019deep}, deep interest highlight network\cite{shen2022deep}, search-based interest model\cite{pi2020search} are further developed by considering the evolving process, trigger-induced ranking, and two-stage long sequence modeling. Besides, Co-Action Network\cite{bian2022can} developed a target-and-sequence-item co-action unit to capture the interaction and aggregate user sequence. Besides, with the rapid progress of transformer-based models\cite{vaswani2017attention}, the scaled dot-product based multi-head target attention (MHTA), has also been widely applied to sequential modeling. 

% Despite the broad developments in terms of both feature interaction and sequential modeling, the multi-domain problem that widely exist in large-scale recommender systems has been seldomly considered in these methods.

% \subsection{Multi-Domain Recommendation}
% As a major area in both multi-domain learning and domain adaptation, multi-domain recommendation aims to provide accurate personalized recommendation results for users and items from multiple domains. Early efforts for multi-domain recommendation are generally made by building separate models for different domains with the domain-specific data, or a unified model with the data mixed from multi-domains\cite{guo2023dffm}. However, the separate modeling ignores the commonalities lied in different domains, while the unified modeling paradigm overlook the difference among various domains, which leads to insufficient exploration of multi-domain data and may hurt the performance on specific domains, yielding suboptimal performance. To further mitigate the issue, traditional methods generally follow a coarse-grained separate-and-shared paradigm for multi-domain recommendation. For example, STAR\cite{sheng2021one} decompose the network parameters into common-parameters and domain-specific-parameters, and the latter are trained with domain-specific data only. PLE\cite{tang2020progressive} builds private and shared experts and aggregates the multi-experts output through a gating mechanism. Furthermore, the fine-grained parameter generation methods draw increased attention recently. APG\cite{yan2022apg} learns a instance-wise specific network parameter to replace the conventional all-shared parameters. AdaSparse\cite{yang2022adasparse} further builds sparse personalized structure for different samples by disabling the neurons with small values. Despite effectiveness, these methods are designed for neural network structures, while the multi-domain learning for sequential-modeling is seldom considered.
% % i.e., most of these methods are designed for replacing the simple single-domain MLPs in industrial recommenders, 

% Some other methods also contribute learning personalized embeddings for multi-domain recommendation. The typical idea is to use the gate mechanism to generate bitwise weights to reweigh the embeddings in recommenders. For example, GateNet\cite{huang2020gatenet} calculates a feature-wise weight to represent its importance which is then used to reweigh the feature embedding. However, this weight is obtained by forward the feature itself via a linear transformation, and thus GateNet is inherently embedding-reweighting method with no personalities across different users. To this end, the feature refinement network (FRNet)\cite{wang2022frnet} is developed with all the user-features as context as gate input, which thus provides user-level personalized weight on specific features compared with GateNet. However, both methods are purely developed for learning adaptive embedding representations, without considering the impact of multi-domains. To this end, parameter and embedding personalized network (PEPNet) \cite{chang2023pepnet} and domain facilitated feature modeling (DFFM)\cite{guo2023dffm} are developed. PEPNet provides a unified structure to personalize both network parameters and embeddings. Specifically, similar to AdaSparse, PEPNet takes domain-specific features as gate input, and the generated bit-wise weights are then used to scale both the embeddings and the input of each layer in the network. Besides, DFFM is proposed to incorporate the domain-specific information into embedding personalization and sequence modeling, while for the latter, the generated weights are used to modify the parameters in self-attention via a simple linear transformation, which is not flexible and sufficient enough to capture the impact of multi-domain in target-aware sequential modeling. Besides, the multi-domain impact of the candidate item on different behavioral items is seldom considered in existing methods.


\section{Methodology}
\subsection{Preliminaries}
\subsubsection{Problem Formulation}
In this paper, we focus on the ranking modeling task in recommenders, which is a typical binary classification problem. Generally, taking the prediction of the click-through rate (CTR) as an example, the probability $\hat{y}$ can be obtained via the following:


\begin{figure*}[h]
\center
\includegraphics[width=\linewidth]{figs/fig1.pdf}
\caption{Overview of \baby. \baby consists of PCRG, PSRG, and target attention module. Given scenario-related features and target item as input, PCRG first generates multiple queries considering the co-pattern of the target item (query) and the scenario features. For PSRG, it takes scenario features as input to generate weight and bias parameters to formulate the personalized MLP, then the original sequence item embedding is passed through the generated MLP to obtain personalized representation. Both the PCRG and PSRG share a share-and-private learning paradigm. Finally, the generated sequence is aggregated by the generated multi-queries with the target-aware attention mechanism, and the concatenation layer and high-level MLP layers are finally used to make predictions.}
\label{fig:overview}
\end{figure*}

\begin{equation}
    \hat{y} = f(\bm{E}_U, \bm{E}_I, \bm{E}_O)
\end{equation}

\noindent in which $\bm{E}(\cdot)$ indicates the embedding function, in which the raw categorical features are translated directly into embeddings, and the continuous features are first bucketed and then embedded as dense vectors. $f$ is the MLP-based transformation function. $U$, $I$, and $O$ denote the user-side, target candidate item-side, and other features, respectively. User-side features generally consist of demographic feature set (for example, user locations and languages) and behavioral feature set (for example, the watch list or the shopping list of users). Item-side features include the item's descriptive features like its category, creators, etc. Besides, the other features $O$ generally contains contextual and user-item cross features. 


\subsection{The Proposed ADS}
The structure of the proposed ADS is illustrated in Figure~\ref{fig:overview}. Overall, it is composed of two major parts:
\begin{itemize}[leftmargin=*]
    \item \textbf{Personalized Sequence Representation Generation}. PSRG generates dynamic behavioral item embedding with a share-and-private learning structure, such that the same item occured in different domains has unshared representations due to the distinction among multi-domains.

    \item \textbf{Personalized Candidate Representation Generation}. PCRG captures different aspects of sequence items and generates multiple adaptive queries (i.e., candidate items) for each sequence item, such that the different query influence on diverse sequence items can be reflected.
\end{itemize}
% Together with the scenario features, PCRG models both user-level and item-level personalized queries, which further improves the adaptive modeling capability of target attention.

With the adaptive queries, keys, and values generated by PCRG and PSRG, the target-aware modeling mechanism like MHA, DIN, and CAN, can be readily integrated into this framework, facilitating the interest capture in multi-domain scenarios.


% \subsubsection{Personalized Sequence Representation Generation (PSRG)}
% Current large-scale industrial recommenders generally adopt the share-embedding layer to embed the raw ID and other features into dense vectors. In this manner, a specific item in the embedding table has a unified embedding, which is shared across different user sequences and neglects the impact from the difference of multiple domains.

% The basic idea of PSRG is to dynamically generate a personalized MLP layer for each item embedding in user behavioral sequence, such that the original shared representation can be diversified across users in multiple domains. Specifically, we use the concatenation of the domain-related features embeddings $\bm{E}_D \in \mathbb{R}^{d_D}$ as the input of the generation part of PSRG, which consists of the following two feature categories: 1) explicit-domain-indicator features, which distinguish the domain that a sample belongs to. For example, the indicator ranges from $[0, 2]$ to indicate the three distinct business scenarios within Douyin; and 2) implicit-domain-indicator features. In recommender systems, some domains can be challenging to define with absolute clarity. For example, whether a user is highly-active or not. Therefore, additional engineer-constructed statistical features are necessary to be incorporated to further capture and differentiate various domains. With the two categories of features, as illustrated in Figure~\ref{fig:overview}, the generation processes of the weight and bias for sequence items are designed to dynamically adjust the original item embedding.

% % The basic idea of PSRG is to dynamically generate a personalized MLP layer for each item embedding in user behavioral sequence, such that the original shared representation can be diversed across users in multiple domains. Specifically, we use the concatenation of the domain-related features embeddings $\bm{E}_D$ as the input of the generation part of PSRG, which consists of the following two feature categories: 

% % 1) explicit-domain-indicator features. As its name implies, the explicit-indicator distinguishes which domain that the sample belongs to from an explicit perspective. For example, the indicator ranges from $[0, 2]$ to indicate the three distinct business scenarios within Douyin, including short-video, live-preview, and live-slide.

% % 2) implicit-domain-indicator features. In recommender systems, some domains can be challenging to define with absolute clarity. For example, whether a user is highly-active or not. Therefore, additional engineer-constructed statistical features are necessary to be incorporated to further capture and differentiate various domains.

% % $\bm{E}_D$
% % With the above two categories of features, as illustrated in Figure~\ref{fig:overview}, the generation processes of the weight and bias for sequence items are designed to dynamically adjust the original item embedding.
% % in which the MLP layer enjoy the merits of both share-and-private learning. 

% \textbf{Sequence-Weight Gen-Net}. Denote the user sequence embedding as $\bm{E}_S \in \mathbb{R}^{T \times d_S}$, where $T$ and $d_S$ represents the user sequence length and the embedding dimension of each sequence item, respectively. Based on the domain features $\bm{E}_D \in \mathbb{R}^{d_D}$, the weight generation process consists of a \textit{private} weight part and a \textit{share} weight part to capture both the commonality and individuality of multi domains. For the private part, a two-layered MLP is performed to generate the private weight:

% \begin{align}
% \mathbf{W}_{private} = Sigmoid({\rm ReLU}(\bm{E}_D \mathbf{W}_1^{\rm{T}} + \bm{b}_1)\mathbf{W}_2^{\rm{T}} + \bm{b}_2)
% \label{eqn:private_weight}
% \end{align}

% \noindent where $\mathbf{W}_1^{\rm{T}} \in \mathbb{R}^{d_D \times d_h}$, $\mathbf{W}_2^{\rm{T}} \in \mathbb{R}^{d_h \times (d_S \times d_S)}$, $\bm{b}_1 \in \mathbb{R}^{d_h}$, $\bm{b}_2 \in \mathbb{R}^{(d_S \times d_S)}$, and $d_h$ denotes the hidden layer dimension. Note that the two-layer function instead of a single layer can not only improve the expression ability of the model, but also significantly reduce the model parameters and computational costs, as $d_S$ is generally at the order of tens, and $d_h << (d_S \times d_S)$. 

% Based on $\mathbf{W}_{private}$, a global weight $\mathbf{W}_{shared} \in \mathbb{R}^{(d_S \times d_S)}$ is further defined as a learnable matrix which is shared across all the users. To enjoy the merits in learning both the commonality and individuality, the final generated weight is defined as:

% \begin{align}
% \mathbf{W}_{generated} = \eta * (\mathbf{W}_{shared}  \odot \mathbf{W}_{private})
% \label{eqn:generated_weight}
% \end{align}

% \noindent where $\odot$ denotes the element-wise product. As the value of $\mathbf{W}_{private}$ ranges from $[0, 1]$ due to introduction of $Sigmoid$, a scaling parameter $\eta$ is further involved to enlarge the expression range of $\mathbf{W}_{private}$. Therefore, the calculation in Equation~\ref{eqn:generated_weight} can be viewed as a adaptive scaling method for the global parameter $\mathbf{W}_{shared}$.

% \textbf{Sequence-Bias Gen-Net}.
% Similar to the above weight generation process, the bias generation can be readily obtained via the following equation:

% \begin{align}
% \bm{b}_{generated} = {\rm ReLU}(\bm{E}_D {\mathbf{W}_{1}^{\prime}}^{\rm{T}} + \bm{b}_{1}^{\prime}) {\mathbf{W}_{2}^{\prime}}^{\rm{T}} + \bm{b}_{2}^{\prime}
% \label{eqn:generate_bias}
% \end{align}

% \noindent where ${\mathbf{W}_{1}^{\prime}}^{\rm{T}} \in \mathbb{R}^{d_D \times d_h}$, ${\mathbf{W}_{2}^{\prime}}^{\rm{T}} \in \mathbb{R}^{d_h \times d_S}$, $\bm{b}_1^{\prime} \in \mathbb{R}^{d_h}$, and $\bm{b}_2^{\prime} \in \mathbb{R}^{d_S}$.

% With the generated weight and bias, the PSRG can be achieved via the following:

% \begin{align}
% \bm{E}_{S-personalized} = \bm{E}_{S} {{Reshape}} (\mathbf{W}_{generated})^{\rm{T}} + \bm{b}_{generated}
% \label{eqn:psrg}
% \end{align}

% \noindent where the ${Reshape}$ operator refers to reshape the 1-D vector-form $\mathbf{W}_{generated}$ as a 2-D matrix-form with the shape of $d_S \times d_S$.

% % left bottom right top
% \begin{figure}[h]
% \center
% \includegraphics[width=\linewidth, trim=48 343 530 43, clip]{figs/groupquery.pdf}
% \caption{Compared with traditional target-attention methods which adopts the target item as a shared query (Left), our proposed Multi-Query Gen-Net produces multiple queries for the sequence items (Middle and Right). Middle: Fully personalized query generation, which builds $T$ queries for $T$ sequence items; Right: Partial personliazed with chunked query generation, where adjacent items formed as a group that share a generated query.}
% \label{fig:multi_query}
% \end{figure}


% \subsubsection{Personalized Candidate Representation Generation (PCRG)}
% In addition to the personalized modeling for sequence, the other important part is the multi-domain modeling for the target item, which generally plays the role of query in target-aware attention. Typically, personalizing the candidate item encompasses two aspects. On one hand, similar to the sequence representation, the representation of the target item itself is also obtained through the shared embedding layer, which is not personalized across different domains. On the other hand, the candidate item plays different roles for different sequence items in various domains. For example, user's watchlist in Douyin mall channel reflects her shopping interests, while in short-video channel reflects her content preference. Thus, user's diverse interest should be captured via a more personalized query.

% % For example, user plays a video as its creator attracts the user, while plays another video due to its interesting content. 

% \textbf{Multi-Query Gen-Net}. To this end, we propose \textit{Multi-Query Gen-Net}, as shown in the middle subfigure in Figure~\ref{fig:multi_query}, which produces multiple queries corresponding to different sequence items, under the guidance of the domain-related features $\bm{E}_D \in \mathbb{R}^{d_D}$ and the original target item embedding $\bm{E}_Q \in \mathbb{R}^{d_Q}$:

% \begin{align}
% \bm{E}_{Q-private} = {\rm{ReLU}} \left( \left(\bm{E}_D \oplus \bm{E}_Q \right) \mathbf{W}_{q1}^{\rm{T}} + \bm{b}_{q1} \right) \mathbf{W}_{q2}^{\rm{T}} + \bm{b}_{q2}
% \label{eqn:q_private}
% \end{align}

% \noindent where $\oplus$ refers to the concatenation operation,  $\mathbf{W}_{q1}^{\rm{T}} \in \mathbb{R}^{(d_D+d_Q) \times d_h}$, $\bm{b}_{q1} \in \mathbb{R}^{d_h}$, $\mathbf{W}_{q2}^{\rm{T}} \in \mathbb{R}^{d_h \times (T \times d_Q)}$ and $ \bm{b}_{q2} \in \mathbb{R}^{T \times d_Q}$. Noted that the query embedding dimension $d_Q$ in our recommenders is at the scale of tens, and the hidden layer dimension $d_h << (T \times d_Q)$, yielding a controllable computation cost at $\bm{\mathcal{O}}(d_h T d_Q)$. \footnote{In industrial cases like Douyin, actually the sequences are at the length of tens to reduce training cost. Longer sequences are processes with search-based interest modeling\cite{pi2020search} to obtain a short-sequence for the subsequent target-attention modeling.}

% \textbf{Chunked-Query Generation}. For cases with long sequence with larger $T$ at hundreds or even higher, we also devise a lightweight chunked-query generation method for improved computation efficiency. As shown in the right subfigure in Figure~\ref{fig:multi_query}, since user's adjacent actions are prone to happens in the same domain, the raw sequence can be divided into $G$ chunks with the adjacent items formed as a group.\footnote{Without losing generality, here it is assumed that $T$ is divisible by $G$ with padding items.} Therefore, the generated $\bm{E}_{Q-private} \in \mathbb{R}^{(G \times d_Q)}$ can be further repeated to $\mathbb{R}^{(T \times d_Q)}$ and the cost further reduces to $\bm{\mathcal{O}}(d_h G d_Q)$.


% Corresponding to the multiple private queries $\bm{E}_{Q-private} \in \mathbb{R}^{(T \times d_Q)}$, we use the original query $\bm{E}_T$ as the shared base, i.e., $\bm{E}_{Q-shared} = tile(\bm{E}_T)$, where $tile$ refers to the tile operator which repeat the $\bm{E}_T$ by $T$ times, i.e., $\bm{E}_{Q-shared} \in \mathbb{R}^{(T \times d_Q)}$. Then, the final generated multiple queries can be obtained via a residual manner:

% \begin{align}
% \bm{E}_{Q-personalized} = Reshape(\bm{E}_{Q-private} + \bm{E}_{Q-shared})
% \label{eqn:q_generated}
% \end{align}

% \noindent where $Reshape$ operator reshapes the 1-D vector-form $\bm{E}_{Q-personalized}$ as a 2-D matrix-from with the shape of $T \times d_Q$.
% % denotes the split operator which separates the $\bm{E}_{Q-private} \in \mathbb{R}^{d_Q \times T}$ into $T$ private queries in which each query $\bm{E}_{Q-i} \in \mathbb{R}^{d_Q}$.


% \subsubsection{Target-Aware Attention}
% With the above personelized queries $\bm{E}_{Q-personalized} \in \mathbb{R}^{T \times d_Q}$ and sequence items $\bm{E}_{S-personalized} \in \mathbb{R}^{T \times d_{S}}$, the target attention module is performed to calculate the attention weight of each item and aggregates the sequence under the guidance of queries. Generally, the personalized queries and items can be readily integrated into many popular attention methods, like multi-head target attention, DIN\cite{zhou2018deep}, and CAN\cite{bian2022can}. In this part, take the multi-head target attention as an example, for each head, the candidate item and sequence items are firstly transformed via the following:

% \begin{align}
% \bm{Q} = \bm{E}_{Q-personalized}W_Q \\
% \bm{K} = \bm{E}_{S-personalized}W_K \\
% \bm{V} = \bm{E}_{S-personalized}W_V
% \label{eqn:qkv}
% \end{align}

% \noindent where $W_Q \in \mathbb{R}^{d_Q \times d_A}$, $W_K$ and $W_V \in \mathbb{R}^{d_S \times d_A}$, in which $d_A$ refers to the dimension size in target attention. 

% The attention weight $\bm{z}^{\prime}[t]$ in the $t$-th query-key pair, i.e., $\{\bm{Q}_t \in \mathbb{R}^{d_A}, \bm{K}_t \in \mathbb{R}^{d_A}\}$ can then be obtained by:

% \begin{align}
% \bm{z}^{\prime}[t] = \frac{\Sigma_{i=1}^{d_A} (\bm{Q}_t \odot \bm{K}_t)}{\sqrt{d_A}}, \quad \rm{where}\ 1 \leq t \leq T
% \label{eqn:attention}
% \end{align}

% \noindent following which a Softmax-based operation is performed to normalize the personalized weights and aggregate the personalized sequence:

% \begin{align}
% \bm{z} = softmax(z^{\prime}),   \quad \bm{s} = \Sigma_{t=1}^{T} (z[t] \cdot \bm{V}_t)
% \label{eqn:weighted_sum}
% \end{align}

% \subsubsection{Prediction Layer}
% With the sequence modeling output $\bm{s}$ and the other feature embeddings including $\bm{E}_U$, $\bm{E}_I$, and $\bm{E}_O$, a concatenation layer and several MLPs are performed to merge all the information and output the prediction:

% \begin{align}
% \bm{E}_{all} = \bm{s} \oplus \bm{E}_U \oplus \bm{E}_I \oplus \bm{E}_O, \quad \hat{y} = MLP(\bm{E}_{all})
% \label{eqn:concat}
% \end{align}

% \noindent With the label y, the training loss can be obtained via the binary cross-entropy function:

% \begin{align}
% {\mathcal{L}} = -y log(\hat{y}) - (1-y) log(1 - \hat{y} )
% \label{eqn:loss}
% \end{align}


\subsubsection{Personalized Sequence Representation Generation (PSRG)}
Current large-scale industrial recommenders generally adopt the share-embedding layer to embed the raw ID and other features into dense vectors. In this manner, a specific item in the embedding table has a unified embedding, which is shared across different user sequences and neglects the impact from the difference between multiple domains.

The basic idea of PSRG is to dynamically generate a personalized layer for each item embedding in user behavioral sequence, such that the original shared representation can be diversified across multiple domains. Specifically, we use the concatenation of the domain-related features embeddings $\bm{E}_D \in \mathbb{R}^{d_D}$ as the input of the generation part of PSRG, which consists of the following two feature categories: 1) explicit-domain-indicator features, which distinguish the domain that a sample belongs to. For example, the indicator ranges from $[0, 2]$ to indicate the three distinct business scenarios within Douyin; and 2) implicit-domain-indicator features. In recommender systems, some domains can be challenging to define explicitly. For example, whether a user is highly-active or not. Therefore, additional engineer-constructed statistical features are necessary to be incorporated to further capture and differentiate various domains. With the two categories of features, as illustrated in Figure~\ref{fig:overview}, the generation processes of the weight and bias for sequence items are designed to dynamically adjust the original item embedding.
% in which the MLP layer enjoy the merits of both share-and-private learning. 

\textbf{Sequence-Weight Gen-Net}. Denote the user sequence embedding as $\bm{E}_S \in \mathbb{R}^{T \times d_S}$, where $T$ and $d_S$ represent the user sequence length and the embedding dimension of each sequence item, respectively. Based on the domain features $\bm{E}_D$, the weight generation process consists of a \textit{private} weight part and a \textit{share} weight part to capture both the commonality and individuality of multi domains. For the private part, a two-layered MLP is performed to generate the private weight:

\begin{align}
\mathbf{W}_{private} = Sigmoid({\rm ReLU}(\bm{E}_D \mathbf{W}_1^{\rm{T}} + \bm{b}_1)\mathbf{W}_2^{\rm{T}} + \bm{b}_2)
\label{eqn:private_weight}
\end{align}

\noindent where $\mathbf{W}_1^{\rm{T}} \in \mathbb{R}^{d_D \times d_h}$, $\mathbf{W}_2^{\rm{T}} \in \mathbb{R}^{d_h \times (d_S \times d_S)}$, $\bm{b}_1 \in \mathbb{R}^{d_h}$, $\bm{b}_2 \in \mathbb{R}^{(d_S \times d_S)}$, and $d_h$ denotes the hidden layer dimension. Note that the two-layer function instead of a single layer can not only improve the expression ability of the model, but also significantly reduce the model parameters and computational costs, as $d_S$ is generally at the order of tens in practical cases, and $d_h << (d_S \times d_S)$. 

Based on $\mathbf{W}_{private}$, a global weight $\mathbf{W}_{shared} \in \mathbb{R}^{(d_S \times d_S)}$ is further defined as a learnable matrix which is shared across all the users. To enjoy the merits in learning both the commonality and individuality, the generated weight is defined as:

\begin{align}
\mathbf{W}_{generated} = \eta * (\mathbf{W}_{shared}  \odot \mathbf{W}_{private})
\label{eqn:generated_weight}
\end{align}

\noindent where $\odot$ denotes the element-wise product. As the value of $\mathbf{W}_{private}$ ranges from $[0, 1]$ due to introduction of $Sigmoid$, a scaling hyperparameter $\eta$ is further involved to enlarge the expression range of $\mathbf{W}_{private}$. Therefore, the calculation in Equation~\ref{eqn:generated_weight} can be viewed as a adaptive scaling method for the global parameter $\mathbf{W}_{shared}$.

\textbf{Sequence-Bias Gen-Net}.
Similar to the above weight generation process, the bias generation can be readily obtained via the following equation:

\begin{align}
\bm{b}_{generated} = {\rm ReLU}(\bm{E}_D {\mathbf{W}_{1}^{\prime}}^{\rm{T}} + \bm{b}_{1}^{\prime}) {\mathbf{W}_{2}^{\prime}}^{\rm{T}} + \bm{b}_{2}^{\prime}
\label{eqn:generate_bias}
\end{align}

\noindent where ${\mathbf{W}_{1}^{\prime}}^{\rm{T}} \in \mathbb{R}^{d_D \times d_h}$, ${\mathbf{W}_{2}^{\prime}}^{\rm{T}} \in \mathbb{R}^{d_h \times d_S}$, $\bm{b}_1^{\prime} \in \mathbb{R}^{d_h}$, and $\bm{b}_2^{\prime} \in \mathbb{R}^{d_S}$. With the generated weight and bias, the PSRG can be achieved via the following:

\begin{align}
\bm{E}_{S-personalized} = \bm{E}_{S} {{Reshape}} (\mathbf{W}_{generated})^{\rm{T}} + \bm{b}_{generated}
\label{eqn:psrg}
\end{align}

\noindent where the ${Reshape}$ operator refers to reshape the 1-D vector-form $\mathbf{W}_{generated}$ as a 2-D matrix-form with the shape of $d_S \times d_S$.



\subsubsection{Personalized Candidate Representation Generation (PCRG)}
In addition to the personalized modeling for sequence, the other important part is the multi-domain modeling for the target item, which generally plays the role of query in target-aware attention. Typically, personalizing the candidate item encompasses two aspects. On one hand, similar to the sequence representation, the representation of the target item itself is also embedded through the shared embedding layer, which is not personalized across different domains. On the other hand, the candidate item plays different roles for different sequence items in various domains. For example, user's watchlist in Douyin mall channel reflects her shopping interests, while in short-video channel reflects her content preference. Thus, user's diverse interest should be captured via a more personalized query.

% For example, user plays a video as its creator attracts the user, while plays another video due to its interesting content. 

% left bottom right top
\begin{figure}
% \vspace{-0.7cm}
\center
\includegraphics[width=\linewidth, trim=48 343 520 43, clip]{figs/groupquery.pdf}
\caption{Comparison of traditional target-attention methods (Left) and the Multi-Query Gen-Net (Middle and Right).}
\label{fig:multi_query}
\end{figure}
\textbf{Multi-Query Gen-Net}. To this end, we propose \textit{Multi-Query Gen-Net}, as shown in the middle subfigure in Figure~\ref{fig:multi_query}, which produces multiple queries corresponding to different sequence items, under the guidance of the domain-related features $\bm{E}_D$ and the original target item embedding $\bm{E}_Q \in \mathbb{R}^{d_Q}$:


\begin{align}
\bm{E}_{Q-private} = {\rm{ReLU}} \left( \left(\bm{E}_D \oplus \bm{E}_Q \right) \mathbf{W}_{q1}^{\rm{T}} + \bm{b}_{q1} \right) \mathbf{W}_{q2}^{\rm{T}} + \bm{b}_{q2}
\label{eqn:q_private}
\end{align}

\noindent where $\oplus$ refers to the concatenation operation,  $\mathbf{W}_{q1}^{\rm{T}} \in \mathbb{R}^{(d_D+d_Q) \times d_h}$, $\bm{b}_{q1} \in \mathbb{R}^{d_h}$, $\mathbf{W}_{q2}^{\rm{T}} \in \mathbb{R}^{d_h \times (T \times d_Q)}$ and $ \bm{b}_{q2} \in \mathbb{R}^{T \times d_Q}$. Noted that the hidden layer dimension $d_h << (T \times d_Q)$, yielding a controllable computation cost at $\bm{\mathcal{O}}(d_h T d_Q)$. 

% \footnote{In industrial cases like Douyin, actually the sequences are generally at the length of tens to reduce training cost. Longer sequences can be processes with search-based interest modeling \cite{pi2020search} to obtain a short-sequence for the subsequent target-attention modeling.}

\textbf{Chunked-Query Generation}. For cases with long sequence with larger $T$ at hundreds or even higher, we also devise a lightweight chunked-query generation method for improved computation efficiency. As shown in the right subfigure in Figure~\ref{fig:multi_query}, since user's adjacent actions are prone to happen in the same domain, the raw sequence can be divided into $G$ chunks with the adjacent items formed as a group.\footnote{Without losing generality, here it is assumed that $T$ is divisible by $G$ with padding items.} Therefore, the generated $\bm{E}_{Q-private} \in \mathbb{R}^{(G \times d_Q)}$ can be further repeated to $\mathbb{R}^{(T \times d_Q)}$ and the cost further reduces to $\bm{\mathcal{O}}(d_h G d_Q)$.


Corresponding to the multiple private queries $\bm{E}_{Q-private} \in \mathbb{R}^{(T \times d_Q)}$, we use the original query $\bm{E}_Q$ as the shared base, i.e., $\bm{E}_{Q-shared} = tile(\bm{E}_Q)$, where $tile$ refers to the tile operator which repeat the $\bm{E}_Q$ by $T$ times, i.e., $\bm{E}_{Q-shared} \in \mathbb{R}^{(T \times d_Q)}$. Then, the final generated multiple queries can be obtained via a residual manner:

\begin{align}
\bm{E}_{Q-personalized} = Reshape(\bm{E}_{Q-private} + \bm{E}_{Q-shared})
\label{eqn:q_generated}
\end{align}

\noindent where $Reshape$ operator reshapes the 1-D vector as a 2-D matrix-from with the shape of $T \times d_Q$.
% denotes the split operator which separates the $\bm{E}_{Q-private} \in \mathbb{R}^{d_Q \times T}$ into $T$ private queries in which each query $\bm{E}_{Q-i} \in \mathbb{R}^{d_Q}$.


\subsubsection{Target-Aware Attention \& Prediction}
With the above personalized queries $\bm{E}_{Q-personalized} \in \mathbb{R}^{T \times d_Q}$ and personalized sequence items $\bm{E}_{S-personalized} \in \mathbb{R}^{T \times d_{S}}$, the target attention module is performed to calculate the attention weight of each item and aggregate the sequence under the guidance of queries. Generally, the personalized queries and items can be readily integrated into many popular attention methods, like multi-head target attention, DIN, and CAN. Taking the multi-head target attention as an example, for each head, the candidate item and sequence items are first transformed via the following:

\begin{align}
\bm{Q} = \bm{E}_{Q-personalized}W_Q \\
\bm{K} = \bm{E}_{S-personalized}W_K \\
\bm{V} = \bm{E}_{S-personalized}W_V
\label{eqn:qkv}
\end{align}

\noindent where $W_Q \in \mathbb{R}^{d_Q \times d_A}$, $W_K$ and $W_V \in \mathbb{R}^{d_S \times d_A}$, in which $d_A$ refers to the dimension size in target attention. The attention weight $\bm{z}^{\prime}[t]$ in the $t$-th query-key pair, i.e., $\{\bm{Q}_t \in \mathbb{R}^{d_A}, \bm{K}_t \in \mathbb{R}^{d_A}\}$, can then be obtained by:

\begin{align}
\bm{z}^{\prime}[t] = \frac{\bm{Q}_t ^{\textsc{T}} \bm{K}_t}{\sqrt{d_A}}, \quad \rm{where}\ 1 \leq t \leq T
\label{eqn:attention}
\end{align}

\noindent following which a softmax-based operation is performed to normalize the personalized weights and aggregate the personalized sequence:

\begin{align}
\bm{z} = softmax(z^{\prime}),   \quad \bm{s} = \Sigma_{t=1}^{T} (z[t] \cdot \bm{V}_t)
\label{eqn:weighted_sum}
\end{align}

With the sequence modeling output $\bm{s}$ and the other feature embeddings including $\bm{E}_U$, $\bm{E}_I$, and $\bm{E}_O$, a concatenation layer and several high-level MLPs are performed to merge all the information and output the prediction, and the training loss can be obtained via the binary cross-entropy function.

\begin{align}
\bm{E}_{all} = \bm{s} \oplus \bm{E}_U \oplus \bm{E}_I \oplus \bm{E}_O, \quad \hat{y} = MLP(\bm{E}_{all})
\label{eqn:concat}
\end{align}

% \noindent With the label y, :

% \begin{align}
% {\mathcal{L}} = -y log(\hat{y}) - (1-y) log(1 - \hat{y} )
% \label{eqn:loss}
% \end{align}


\section{Experiments}
% In this section, we first compare the proposed \baby with the conventional interaction methods and multi-domain modeling methods on two real-world datasets, and then the ablation study and sensitivity analysis are conducted to verify the effectiveness of the modules in \baby. Finally, online A/B experiments on two influential scenarios in Douyin are performed to illustrate the superiority of \baby.

\begin{table}
\caption{Statistics of the two datasets.}
\begin{tabular}{lcccc}
\hline
Dataset & $\#$Users & $\#$Items & $\#$Instances & $\#$Tasks \\ \hline
Taobao & 101,342 & 500,272 & 24.02M & Order \\
Douyin-Ads & 688M & 270M & 2.52B & CVR \\
Douyin-Ecom & 596M & 12.91M & 24.65B & Click \& Order \\ \hline
\end{tabular}
\label{tab:stats}
\end{table}



\begin{table*}[]
\caption{Comparison results of different methods on the three datasets. "D1", "D2", and "D3" are the abbreviations of "Domain 1", "Domain 2", and "Domain 3". Boldface denotes the best results in each group, and the boldface in the gray shadow area denotes that \baby significantly outperforms the second-best approach at the level of ($p < $ 0.05) in each group. For the two industrial datasets, note that a \underline{0.1\% Overall Imp.} in Douyin Ads and \underline{0.2\% Overall Imp.} in Douyin Ecom is considered to be significant improvement that can affect the performance of online A/B tests.}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{c|cc|ccccc|cccccccc}
\hline
& \multicolumn{2}{c|}{{Taobao}} & \multicolumn{5}{c|}{{Douyin Ads}}                                                                                                                                  & \multicolumn{8}{c}{{Douyin E-commerce}}                                                                                                                                                                                                                                                                                                                                 \\ \cline{2-16} 
 
{ }                         & \multicolumn{2}{c|}{{Order}}  
                                & \multicolumn{5}{c|}{{CVR}}                                                                                                                                         & \multicolumn{4}{c|}{{Click}}                                                                                                                                                       & \multicolumn{4}{c}{{ Order}}                                                                                                           \\ \cline{2-16} 
 
\multirow{-3}{*}{{ Models}} & { Overall} & { \begin{tabular}[c]{@{}c@{}}Overall \\ Imp.\end{tabular}} & { D1}     & { D2}     & { D3}     & { Overall} & { \begin{tabular}[c]{@{}c@{}}Overall \\ Imp.\end{tabular}} & { D1}     & { D2}     & { Overall} & \multicolumn{1}{c|}{{ \begin{tabular}[c]{@{}c@{}}Overall \\ Imp.\end{tabular}}} & { D1}     & { D2}     & { Overall} & { \begin{tabular}[c]{@{}c@{}}Overall \\ Imp.\end{tabular}} \\ \hline
{ DNN}                                              & {0.6490} & {-} & { 0.8224} & { 0.8221} & { 0.8717} & { 0.8461}  & { -}                                                       & { 0.7949} & { 0.8418} & { 0.9082}  & \multicolumn{1}{c|}{{ -}}                                                          & { 0.8456} & { 0.8494} & { 0.8439}  & { -}                                                          \\
 
{ DeepFM}                                           & {0.6503} & {+0.87\%} & { 0.8229} & { 0.8233} & { 0.8720} & { 0.8469}  & { +0.23\%}                                        & { 0.7953} & { 0.8422} & { 0.9083}  & \multicolumn{1}{c|}{{ +0.02\%}}                                                    & { 0.8458} & { 0.8496} & { 0.8442}  & { +0.08\%}                                                    \\
 
{ DCNv2}                                            & {0.6505} & {+1.01\%} & { \textbf{0.8232}} & {\textbf{0.8235}} & {\textbf{0.8725}} & { \textbf{0.8470}}  & {\textbf{+0.26\%}}                                        & { 0.7950} & { 0.8418} & { 0.9082}  & \multicolumn{1}{c|}{{ +0.00\%}}                                                    & { 0.8456} & { 0.8494} & { 0.8439}  & { +0.00\%}                                                    \\
 
{ APG}                                              & {0.6484} & {-0.40\%} & { 0.8225} & { 0.8223} & { 0.8720} & { 0.8464}  & { +0.08\%}                                        & { 0.7951} & { 0.8418} & { 0.9082}  & \multicolumn{1}{c|}{{ +0.00\%}}                                                    & { 0.8456} & { 0.8494} & { 0.8439}  & { +0.00\%}                                                    \\
 
{ AdaSparse}                                        & {\textbf{0.6498}} & {\textbf{+0.54\%}} &{ 0.8228} & { 0.8230} & { 0.8721} & { 0.8465}  & { +0.11\%}                                        & { 0.7951} & { 0.8418} & { 0.9082}  & \multicolumn{1}{c|}{{ +0.00\%}}                                                    & { 0.8455} & { 0.8491} & { 0.8438}  & { -0.03\%}                                                    \\
 
{ DFFM}                                             & {0.6487} & {-0.20\%} & { 0.8232} & { 0.8241} & { 0.8722} & { 0.8465}  & { +0.11\%}                                        & { \textbf{0.7961}} & { \textbf{0.8440}} & { \textbf{0.9089}}  & \multicolumn{1}{c|}{{ \textbf{+0.17\%}}}                                                    & { \textbf{0.8469}} & { \textbf{0.8507}} & { \textbf{0.8455}}  & { \textbf{+0.46\%}}         \\ \hline
 
\multicolumn{1}{l|}{{ DIN}}                                              & {0.6498} & {+0.54\%} & { 0.8235} & { 0.8251} & { 0.8724} & { 0.8469}  & { +0.23\%}                                        & { 0.7967} & { 0.8443} & { 0.9091}  & \multicolumn{1}{c|}{{ +0.22\%}}                                                    & { 0.8472} & { 0.8509} & { 0.8456}  & { +0.49\%}                                                    \\
 
{ +FRNet}                                        & {0.6490} & {+0.00\%} & { 0.8235} & { 0.8247} & { 0.8722} & { 0.8469}  & { +0.23\%}                                        & { 0.7967} & { 0.8444} & { 0.9092}  & \multicolumn{1}{c|}{{ +0.24\%}}                                                    & { 0.8474} & { 0.8511} & { 0.8458}  & { +0.55\%}                                                    \\
 
{ +PEPNet}                                       & {0.6500} & {+0.67\%} & { 0.8235} & { 0.8250} & { 0.8723} & { 0.8470}  & { +0.26\%}                                        & { 0.7964} & { 0.8440} & { 0.9090}  & \multicolumn{1}{c|}{{ +0.19\%}}                                                    & { 0.8472} & { 0.8507} & { 0.8456}  & { +0.49\%}                                                    \\
\rowcolor[HTML]{EFEFEF} 
{ +\baby}                                       & { \textbf{0.6507}} & {\textbf{+1.14\%}} & {\textbf{0.8245}} & { \textbf{0.8262}} & { \textbf{0.8733}} & { \textbf{0.8477}}  & { \textbf{+0.46\%}}                                        & { \textbf{0.7972}} & { \textbf{0.8451}} & { \textbf{0.9094}}  & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{ \textbf{+0.29\%}}}                                                    & { \textbf{0.8477}} & { \textbf{0.8513}} & { \textbf{0.8462}}  & { \textbf{+0.66\%}}                                                    \\ \hline
\multicolumn{1}{l|}{{ MHA}}                                              & {0.6498} & {+0.54\%} & { 0.8232} & { 0.8238} & { 0.8721} & { 0.8467}  & { \textbf{+0.17\%}}                                        & { 0.7964} & { 0.8439} & { 0.9090}  & \multicolumn{1}{c|}{{ +0.19\%}}                                                    & { 0.8465} & { 0.8503} & { 0.8450}  & { +0.31\%}                                                    \\
 
{ +FRNet}                                        & {0.6496} & {+0.40\%} & { 0.8233} & { 0.8240} & { 0.8722} & { 0.8467}  & { +0.17\%}                                        & { 0.7963} & { 0.8437} & { 0.9089}  & \multicolumn{1}{c|}{{ +0.17\%}}                                                    & { 0.8468} & { 0.8506} & { 0.8453}  & { +0.40\%}                                                    \\
 
{ +PEPNet}                                       & {0.6498} & {+0.54\%} & { 0.8237} & { 0.8246} & { 0.8725} & { 0.8471}  & { +0.28\%}                                        & { 0.7964} & { 0.8439} & { 0.9090}  & \multicolumn{1}{c|}{{ +0.19\%}}                                                    & { 0.8467} & { 0.8505} & { 0.8452}  & { +0.37\%}                                                    \\
\rowcolor[HTML]{EFEFEF} 
{ +\baby}                                       & {\textbf{0.6501}} & {\textbf{+0.74\%}} & { \textbf{0.8242}} & { \textbf{0.8256}} & { \textbf{0.8730}} & { \textbf{0.8475}}  & { \textbf{+0.40\%}}                                        & { \textbf{0.7969}} & { \textbf{0.8448}} & { \textbf{0.9093}}  & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{ \textbf{+0.26\%}}}                                                    & { \textbf{0.8473}} & { \textbf{0.8509}} & { \textbf{0.8458}}  & { \textbf{+0.55\%}}                                                    \\ \hline
\multicolumn{1}{l|}{{ CAN}}                                              & {0.6498} & {+0.54\%} & { 0.8227} & { 0.8238} & { 0.8721} & { 0.8464}  & { +0.08\%}                                        & { 0.7954} & { 0.8423} & { 0.9084}  & \multicolumn{1}{c|}{{ +0.04\%}}                                                    & { 0.8459} & { 0.8496} & { 0.8443}  & { +0.11\%}                                                    \\
 
{ +FRNet}                                        & {0.6500} & {+0.67\%} & { 0.8234} & { 0.8248} & { 0.8725} & { 0.8469}  & { +0.23\%}                                        & { 0.7958} & { 0.8429} & { 0.9086}  & \multicolumn{1}{c|}{{ +0.09\%}}                                                    & { 0.8466} & { 0.8503} & { 0.8447}  & { +0.23\%}                                                    \\
 
{ +PEPNet}                                       & {0.6490} & {+0.00\%} & { 0.8231} & { 0.8242} & { 0.8723} & { 0.8467}  & { +0.17\%}                                        & { 0.7958} & { 0.8427} & { 0.9085}  & \multicolumn{1}{c|}{{ +0.07\%}}                                                    & { 0.8463} & { 0.8502} & { 0.8450}  & { +0.31\%}                                                    \\
\rowcolor[HTML]{EFEFEF} 
{ +\baby}                                       & {\textbf{0.6503}} & {\textbf{+0.87\%}} & { \textbf{0.8240}} & { \textbf{0.8256}} & { \textbf{0.8731}} & { \textbf{0.8474}}  & { \textbf{+0.37\%}}                                        & { \textbf{0.7968}} & { \textbf{0.8446}} & { \textbf{0.9092}}  & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{ \textbf{+0.24\%}}}                                                    & { \textbf{0.8470}} & { \textbf{0.8509}} & { \textbf{0.8456}}  & { \textbf{+0.49\%}}                                                    \\ \hline
\end{tabular}
\end{adjustbox}
\label{tab:res}
\end{table*}

    
% \begin{table*}[]
% \caption{Comparison results of different methods on the two datasets. "D1", "D2", and "D3" are the abbreviations of "Domain 1", "Domain 2", and "Domain 3". Boldface denotes the best results in each group, and the boldface in the gray shadow area denotes that \baby significantly outperforms the second-best approach at the level of ($p < $ 0.05) in each group. Note that a \underline{0.05\% auc gain} in Douyin Ads and \underline{0.1\% auc gain} in Douyin Ecom is considered to be very significant improvement that can affect the performance of online A/B tests.}
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{c|ccccc|cccccccc}
% \hline
 
%                          & \multicolumn{5}{c|}{{ Douyin Ads}}                                                                                                                                  & \multicolumn{8}{c}{{ Douyin E-commerce}}                                                                                                                                                                                                                                                                                                                                 \\ \cline{2-14} 
 
% { }                         & \multicolumn{5}{c|}{{ CVR}}                                                                                                                                         & \multicolumn{4}{c|}{{ Click}}                                                                                                                                                       & \multicolumn{4}{c}{{ Order}}                                                                                                           \\ \cline{2-14} 
 
% \multirow{-3}{*}{{ Models}} & { D1}     & { D2}     & { D3}     & { Overall} & { \begin{tabular}[c]{@{}c@{}}Overall \\ Imp.\end{tabular}} & { D1}     & { D2}     & { Overall} & \multicolumn{1}{c|}{{ \begin{tabular}[c]{@{}c@{}}Overall \\ Imp.\end{tabular}}} & { D1}     & { D2}     & { Overall} & { \begin{tabular}[c]{@{}c@{}}Overall \\ Imp.\end{tabular}} \\ \hline
 
% { DNN}                                              & { 0.8224} & { 0.8221} & { 0.8717} & { 0.8461}  & { -}                                                       & { 0.7949} & { 0.8418} & { 0.9082}  & \multicolumn{1}{c|}{{ -}}                                                          & { 0.8456} & { 0.8494} & { 0.8439}  & { -}                                                          \\
 
% { DeepFM}                                           & { 0.8229} & { 0.8233} & { 0.8720} & { 0.8469}  & { +0.23\%}                                        & { 0.7953} & { 0.8422} & { 0.9083}  & \multicolumn{1}{c|}{{ +0.02\%}}                                                    & { 0.8458} & { 0.8496} & { 0.8442}  & { +0.08\%}                                                    \\
 
% { DCNv2}                                            & { \textbf{0.8232}} & { \textbf{0.8235}} & { \textbf{0.8725}} & { \textbf{0.8470}}  & { \textbf{+0.26\%}}                                        & { 0.7950} & { 0.8418} & { 0.9082}  & \multicolumn{1}{c|}{{ +0.00\%}}                                                    & { 0.8456} & { 0.8494} & { 0.8439}  & { +0.00\%}                                                    \\
 
% { APG}                                              & { 0.8225} & { 0.8223} & { 0.8720} & { 0.8464}  & { +0.08\%}                                        & { 0.7951} & { 0.8418} & { 0.9082}  & \multicolumn{1}{c|}{{ +0.00\%}}                                                    & { 0.8456} & { 0.8494} & { 0.8439}  & { +0.00\%}                                                    \\
 
% { AdaSparse}                                        & { 0.8228} & { 0.8230} & { 0.8721} & { 0.8465}  & { +0.11\%}                                        & { 0.7951} & { 0.8418} & { 0.9082}  & \multicolumn{1}{c|}{{ +0.00\%}}                                                    & { 0.8455} & { 0.8491} & { 0.8438}  & { -0.03\%}                                                    \\
 
% { DFFM}                                             & { 0.8232} & { 0.8241} & { 0.8722} & { 0.8465}  & { +0.11\%}                                        & { \textbf{0.7961}} & { \textbf{0.8440}} & { \textbf{0.9089}}  & \multicolumn{1}{c|}{{ \textbf{+0.17\%}}}                                                    & { \textbf{0.8469}} & { \textbf{0.8507}} & { \textbf{0.8455}}  & { \textbf{+0.46\%}}                                                   \\ \hline
 
% \multicolumn{1}{l|}{{ DIN}}                                              & { 0.8235} & { 0.8251} & { 0.8724} & { 0.8469}  & { +0.23\%}                                        & { 0.7967} & { 0.8443} & { 0.9091}  & \multicolumn{1}{c|}{{ +0.22\%}}                                                    & { 0.8472} & { 0.8509} & { 0.8456}  & { +0.49\%}                                                    \\
 
% { +FRNet}                                        & { 0.8235} & { 0.8247} & { 0.8722} & { 0.8469}  & { +0.23\%}                                        & { 0.7967} & { 0.8444} & { 0.9092}  & \multicolumn{1}{c|}{{ +0.24\%}}                                                    & { 0.8474} & { 0.8511} & { 0.8458}  & { +0.55\%}                                                    \\
 
% { +PEPNet}                                       & { 0.8235} & { 0.8250} & { 0.8723} & { 0.8470}  & { +0.26\%}                                        & { 0.7964} & { 0.8440} & { 0.9090}  & \multicolumn{1}{c|}{{ +0.19\%}}                                                    & { 0.8472} & { 0.8507} & { 0.8456}  & { +0.49\%}                                                    \\
% \rowcolor[HTML]{F1F1F1} 
% { +\baby}                                       & { \textbf{0.8245}} & { \textbf{0.8262}} & { \textbf{0.8733}} & { \textbf{0.8477}}  & { \textbf{+0.46\%}}                                        & { \textbf{0.7972}} & { \textbf{0.8451}} & { \textbf{0.9094}}  & \multicolumn{1}{c|}{\cellcolor[HTML]{F1F1F1}{ \textbf{+0.29\%}}}                                                    & { \textbf{0.8477}} & { \textbf{0.8513}} & { \textbf{0.8462}}  & { \textbf{+0.66\%}}                                                    \\ \hline
 
% \multicolumn{1}{l|}{{ MHA}}                                              & { 0.8232} & { 0.8238} & { 0.8721} & { 0.8467}  & { +0.17\%}                                        & { 0.7964} & { 0.8439} & { 0.9090}  & \multicolumn{1}{c|}{{ +0.19\%}}                                                    & { 0.8465} & { 0.8503} & { 0.8450}  & { +0.31\%}                                                    \\
 
% { +FRNet}                                        & { 0.8233} & { 0.8240} & { 0.8722} & { 0.8467}  & { +0.17\%}                                        & { 0.7963} & { 0.8437} & { 0.9089}  & \multicolumn{1}{c|}{{ +0.17\%}}                                                    & { 0.8468} & { 0.8506} & { 0.8453}  & { +0.40\%}                                                    \\
 
% { +PEPNet}                                       & { 0.8237} & { 0.8246} & { 0.8725} & { 0.8471}  & { +0.28\%}                                        & { 0.7964} & { 0.8439} & { 0.9090}  & \multicolumn{1}{c|}{{ +0.19\%}}                                                    & { 0.8467} & { 0.8505} & { 0.8452}  & { +0.37\%}                                                    \\
% \rowcolor[HTML]{EFEFEF} 
% { +\baby}                                       & { \textbf{0.8242}} & { \textbf{0.8256}} & { \textbf{0.8730}} & { \textbf{0.8475}}  & { \textbf{+0.40\%}}                                        & { \textbf{0.7969}} & { \textbf{0.8448}} & { \textbf{0.9093}}  & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{ \textbf{+0.26\%}}}                                                    & { \textbf{0.8473}} & { \textbf{0.8509}} & { \textbf{0.8458}}  & { \textbf{+0.55\%}}                                                    \\ \hline
 
% \multicolumn{1}{l|}{{ CAN}}                                              & { 0.8227} & { 0.8238} & { 0.8721} & { 0.8464}  & { +0.08\%}                                        & { 0.7954} & { 0.8423} & { 0.9084}  & \multicolumn{1}{c|}{{ +0.04\%}}                                                    & { 0.8459} & { 0.8496} & { 0.8443}  & { +0.11\%}                                                    \\
 
% { +FRNet}                                        & { 0.8234} & { 0.8248} & { 0.8725} & { 0.8469}  & { +0.23\%}                                        & { 0.7958} & { 0.8429} & { 0.9086}  & \multicolumn{1}{c|}{{ +0.09\%}}                                                    & { 0.8466} & { 0.8503} & { 0.8447}  & { +0.23\%}                                                    \\
 
% { +PEPNet}                                       & { 0.8231} & { 0.8242} & { 0.8723} & { 0.8467}  & { +0.17\%}                                        & { 0.7958} & { 0.8427} & { 0.9085}  & \multicolumn{1}{c|}{{ +0.07\%}}                                                    & { 0.8463} & { 0.8502} & { 0.8450}  & { +0.31\%}                                                    \\
% \rowcolor[HTML]{EFEFEF} 
% { +\baby}                                       & { \textbf{0.8240}} & { \textbf{0.8256}} & { \textbf{0.8731}} & { \textbf{0.8474}}  & { \textbf{+0.37\%}}                                        & { \textbf{0.7968}} & { \textbf{0.8446}} & { \textbf{0.9092}}  & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}{ \textbf{+0.24\%}}}                                                    & { \textbf{0.8470}} & { \textbf{0.8509}} & { \textbf{0.8456}}  & { \textbf{+0.49\%}}                                                    \\ \hline
% \end{tabular}
% }
% \label{tab:res}
% \end{table*}


\subsection{Experimental Settings}

\paratitle{Datasets and Experimental Setup.} To sufficiently evaluate the proposed \baby, we conducts experiments on both a public dataset, i.e., Taobao Dataset \footnote{https://tianchi.aliyun.com/dataset/dataDetail?dataId=649} (\textit{Taobao}), and two \textbf{billion-scale} industrial dataset from Douyin, i.e., Douyin advertising platform (\textit{Douyin Ads}) and Douyin E-commerce platform (\textit{Douyin Ecom}). The statistics of the three datasets are reported in Table~\ref{tab:stats}.

\begin{itemize}[leftmargin=*]
    \item \textbf{Taobao}. The Taobao dataset released in \cite{zhu2018learning} provides user behavior data in Taobao and is currently widely used in sequential modeling methods \cite{cao2022sampling}. The former 7 days are used for training and the rest are for testing. Users with at least 200 interactions and 10 positive actions are filtered, and items with at least 10 interactions are filtered. There are 9,439 categories of items in the dataset, and we regard each category as a domain. In this dataset, page view is considered as a negative interaction and the other actions are regarded as positive label (order).
    
    \item \textbf{Douyin Ads}. We select the Conversion Rate (CVR) prediction task in Douyin Ads, and collect a subset of online traffic logs from Dec. 14th, 2022 to Mar. 10th, 2023, 87 days and 1.73 billion samples in total. The former 77 days are used for model training and the rest 10 days are used for evaluation. In Douyin Ads platform, according to different user external actions, the dataset can be divided into three major domains including pay in live, order in live, and shopping in short-videos, denoted by domain 1, 2, and 3, respectively.
    
    \item \textbf{Douyin Ecom}. Two kinds of user shopping behaviors including click and order are selected as the prediction targets in the Ecom service in Douyin Live, the most influential scenario in E-commerce services at ByteDance. A subset of online traffic logs from Jan. 1st to Mar. 1st, 2024 is collected, including 61 days and 2.52 billion samples. The first 54 days are selected for training and the last week is for validation. The two typical senarios in Douyin-Live, i.e., Live-Preview and Live-Slide, are involved in the dataset, denoted by domain 1 and 2, respectively.
\end{itemize}

\paratitle{Comparing methods and evaluation metrics.} To comprehensively compare the proposed \baby with existing methods, we select several representative SOTA models, which can be grouped into two categories: (1) the DNN-based methods including \textbf{DNN}, \textbf{DeepFM} \cite{guo2017deepfm}, \textbf{DCNv2} \cite{wang2021dcn}, \textbf{APG} \cite{yan2022apg}, \textbf{AdaSparse} \cite{yang2022adasparse}, \textbf{DFFM} \cite{guo2023dffm}, \textbf{MaskNet} \cite{wang2021masknet}; (2) the target attention-based backbone methods including \textbf{DIN} \cite{zhou2018deep}, \textbf{MHA} \cite{vaswani2017attention}, and \textbf{CAN} \cite{bian2022can}, based on which recent multi-domain embedding learning methods are added for comparison, including \textbf{FRNet} \cite{wang2022frnet} and \textbf{PEPNet} \cite{chang2023pepnet}. All the methods are implemented based on Tensorflow\cite{abadi2016tensorflow}, optimized by the cross-entropy loss. Adam \cite{kingma2014adam} optimizer is adopted with an initial learning rate of 0.00002. AUC metric is used to evaluate the ranking model performance. Further, we introduce relative improvement (Imp.) \cite{yan2014coupled} to measure the relative AUC gain, which is calculated as following as a random strategy yields AUC value at 0.5:

\begin{align}
AUC\ Imp. = \left(  \frac{AUC(Measured Model) - 0.5}{AUC(Baseline Model) - 0.5} - 1 \right) \times 100\%
\label{eqn:relaimp}
\end{align}

% Both the AUC and the relative improvement (Imp.) \cite{yan2014coupled} metrics are selected to evaluate and compare the ranking model performance. 




% To comprehensively compare the proposed \baby with existing methods, we select several representative SOTA models, which can be grouped into two categories, 

% % including the DNN-base methods focusing on feature interaction and building multi-domain neural structures, and target-attention-based methods emphasising target-aware sequence modeling and multi-domain modeling for embeddings.

% \textbf{Group 1: DNN-based methods}. This group includes representative DNN-based methods focusing on feature interaction and building multi-domain neural structures. 


% \begin{itemize}[leftmargin=*]
%     \item \textbf{DNN} model serves as the baseline with all the embedded features and sumpooled sequence concatenated, and then an MLP is used to transform the bottom into a predicted probability.
%     \item \textbf{DeepFM} \cite{guo2017deepfm} leverages both DNN and FM to concurrently learn the low-order and high-order feature interactions.
%     \item \textbf{DCNv2} \cite{wang2021dcn} adopts a matrix-form weight instead of vector-form in DCN to enhance the compression ability of the cross layer, and further develops a mixture of low-rank experts mechanism to reduce computational cost.
%     \item \textbf{APG} \cite{yan2022apg} uses a low-rank based dynamic weight paradigm to generate different parameters for different instances.
%     \item \textbf{AdaSparse} \cite{yang2022adasparse} further devises a sparse gating mechanism for multiple domains to achieve better generalization performance.
%     \item \textbf{DFFM} \cite{guo2023dffm} injects the domain information into both the behavior and interaction modeling modules via dynamic weight mechanism.
%     \item \textbf{MaskNet} \cite{wang2021masknet} introduces an instance-guided mask mechanism to enhance feature interaction.
% \end{itemize}


% \textbf{Group 2: Target attention-based methods}. We select the representative DIN, MHA, and CAN as backbone of target attention modeling methods, based on which recent multi-domain embedding learning methods are selected for comparison.

% \begin{itemize}[leftmargin=*]
%     \item \textbf{DIN} \cite{zhou2018deep} uses a MLP-based mechanism, which concatenates both the user behavior and corresponding target to an MLP to learn the attention weight and aggregate the user sequence.
%     \item \textbf{MHA} adopts a multi-head dot-product attention mechanism, in which user sequence serves as keys and values, and target item serves as the query.
%     \item \textbf{CAN} \cite{bian2022can} uses the target item to generate specific MLP parameters for crossing and aggregating the user sequence.
% \end{itemize}

% Based on the three attention models as backbone, the following two methods are integrated for further comparison:
% \begin{itemize}[leftmargin=*]
% \item \textbf{FRNet}\cite{wang2022frnet} takes domain features as context to reweigh the original and self-attended sequential embeddings, and the generated embedding are used as the new sequence for target attention modeling.
% \item \textbf{PEPNet}\cite{chang2023pepnet} adopts an LHUC\cite{swietojanski2016lhuc}-like mechanism to generate bitwise scaling vector and reweigh the original embedding, which is then used for the subsequent target-aware attention.
% \end{itemize}






\subsection{Experimental Results}
\textbf{Overall Performance.} The comparison results of different methods on the three datasets are presented in Table~\ref{tab:res}. For Taobao dataset, only the overall results are provided due to the domain amount. For clarity, the results are reported with the comparing methods grouped into four groups, in which first group lists the DNN-based methods, and the rest-three groups list the multi-domain target attention methods based on DIN, MHA, and CAN, respectively. There are several observations from the results.

\textbf{First, it is observed that compared with the DNN-based approches, target-attention based sequential-modeling plays a vital role in ranking models.} From the table, it is demonstrated that DIN, MHA, and CAN achieves 0.54\% improvements in Taobao, 0.23\%, 0.17\%, and 0.08\% improvements in Douyin Ads, 0.22\%, 0.19\%, and 0.04\% improvements in click prediction, and 0.49\%, 0.31\%, and 0.11\% improvements in order prediction tasks in Douyin Ecom, respectively, demonstrating significant improvements.

\textbf{Second, the existing multi-domain methods contribute a positive effect for ranking models in general.} Specifically, in DNN-based methods, it is observed that AdaSparse outperforms the baseline in Taobao and Douyin Ads. FRNet and PEPNet also show improved performance in different groups.

\textbf{Finally, the proposed \baby consistently achieves the best performance in different groups with DIN, MHA, and CAN as backbone, showing its high effectiveness and compatibility.} Specifically, in Taobao, the proposed \baby outperforms other SOTAs with 0.47\%, 0.20\%, and 0.20\% with the second-best methods in the DIN-, MHA-, and CAN-based groups. In Douyin Ads, \baby beats other methods and achieves 0.20\%, 0.12\%, and 0.14\% improvements compared with the second-best approach. In Douyin Ecom, \baby outperforms the second-best approach in the three groups by 0.05\%, 0.07\%, and 0.15\% in click prediction task, and by 0.11\%, 0.15\%, and 0.18\% in order prediction task, respectively. Besides, in terms of each domain of the two industrial datasets, \baby solidly outperforms the compared methods. Thus, the promising results show the superiority of the personalized target attention mechanism.



% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
\caption{Ablation study of the proposed \baby.}
\resizebox{0.48\textwidth}{!}{%
\begin{tabular}{c|c|ccccc}
\hline
Groups                                                                & Methods                                                   & D1     & D2     & D3     & Overall & \begin{tabular}[c]{@{}c@{}}Overall\\ Imp.\end{tabular} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}} \\ DIN-\\ based\end{tabular}} & ADS                                                    & 0.8245 & 0.8262 & 0.8733 & 0.8477  & -                                                      \\
                                                                      & w/o PCRG                                                  & 0.8242 & 0.8257 & 0.8730 & 0.8475  & \textbf{-0.06\%}                                                \\
                                                                      & \begin{tabular}[c]{@{}c@{}}w/o PCRG\\ \&PSRG\end{tabular} & 0.8235 & 0.8251 & 0.8724 & 0.8469  & \textbf{-0.23\%}                                                \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}} \\MHA-\\ based\end{tabular}} & ADS                                                    & 0.8242 & 0.8256 & 0.8730 & 0.8475  & -                                                      \\
                                                                      & w/o PCRG                                                  & 0.8241 & 0.8252 & 0.8730 & 0.8474  & \textbf{-0.03\%}                                                \\
                                                                      & \begin{tabular}[c]{@{}c@{}}w/o PCRG\\ \&PSRG\end{tabular} & 0.8232 & 0.8238 & 0.8721 & 0.8467  & \textbf{-0.23\%}                                                \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}} \\CAN-\\ based\end{tabular}} & ADS                                                    & 0.8240 & 0.8256 & 0.8731 & 0.8474  & -                                                      \\
                                                                      & w/o PCRG                                                  & 0.8230 & 0.8240 & 0.8723 & 0.8466  & \textbf{-0.23\%}                                                \\
                                                                      & \begin{tabular}[c]{@{}c@{}}w/o PCRG\\ \&PSRG\end{tabular} & 0.8227 & 0.8238 & 0.8721 & 0.8464  & \textbf{-0.29\%}                                                \\ \hline
\end{tabular}
}
\label{tab:ablation}
\end{table}



\subsection{Ablation Study \& Sensitivity Analysis}
\textbf{Ablation study}. To further evaluate the performance of the two modules in \baby, i.e., PCRG and PSRG, here we perform ablation study in the challenging Douyin Ads dataset. As shown in Table~\ref{tab:ablation}, after ablating the PCRG module, the overall performance is dropped by 0.06\%, 0.03\%, and 0.23\% in DIN-, MHA-, and CAN-based methods. Besides, after ablating both the PCRG and PSRG modules, the overall performance is decreased by 0.23\%, 0.23\%, and 0.29\%, respectively. It can thus be concluded that both the personalized target item and the personalized sequences contributes positive impact to the proposed \baby, confirming the validity of these modules.


% \begin{figure}[H]
% \centering
% \begin{minipage}[b]{\linewidth}
% \subfigure[Click]{
% \includegraphics[width=0.49\linewidth]{figs/sensitivity_group_click.eps}
% }
% \subfigure[Order]{
% \includegraphics[width=0.49\linewidth]{figs/sensitivity_group_order.eps}
% }
% \end{minipage}
% \caption{Performance patterns by varying the number of chunks in \baby, where "Chunk K" means there are K items grouped into a chunk in PCRG. }
% \label{fig:sensitivity_performance}
% \end{figure}





\begin{figure}[h]
\center
\includegraphics[width=\linewidth]{figs/sensitivity_group_params_and_flops.png}
\caption{Model parameter and training FLOPs patterns by varing the number of chunks in \baby, where "Chunk \textit{K}" means there are \textit{K} items grouped into a chunk in PCRG.}
\label{fig:sensitivity_efficiency}
\end{figure}

\textbf{Sensitivity Analysis to Number of Chunks in \baby.} 
Furthermore, to investigate the impact of number of chunks, sensitivity analysis for the \baby are conducted. Specifically, we investigate the performance patterns by varying the number of items in each chunk from [1, 2, 5, 10] in Douyin E-commerce, and the sensitivity analysis is performed from two aspects, i.e., training efficiency and model performance.
\begin{itemize}[leftmargin=*]

    \item \textbf{Training efficiency patterns.} We evaluate the model training efficiency by summarizing and comparing the model parameters and training floating point operations (FLOPs) under different chunks in \baby, and the results are illustrated in Fig~\ref{fig:sensitivity_efficiency}. From the figure, it can be clearly observed that with the modeling becomes more personalized, the model parameters and training FLOPs consistently increase.
    
    \item \textbf{Performance patterns.} The model performance pattern by varying the number of items in each chunk is illustrated in Fig~\ref{fig:sensitivity_performance}. Specifically, first, in comparison with the vanilla DIN, MHA, and CAN, \baby and \baby with different chunks show obvious performance improvement in terms of both click and order prediction tasks. Besides, it can be observed that with number of items covered in the chunk decreases, the model performance continues to increase, and the most personalized model, i.e., \baby without chunk, achieves the best performance, showing that it is of significance to consider the personality characterization of the candidate item.


\end{itemize}
Overall, both the performance and the training cost increase with the personalization ability in \baby increased, while we observe that even with a small increase in training cost (\baby with Chunk 10 compared with vanilla method), the model performance still achieves promising gains, and thus practitioners can select the parameters with more flexibility according to the balance of effectiveness and efficiency. 



\begin{figure*}[t]
\captionsetup[subfigure]{labelformat=empty}
\centering
\begin{minipage}[b]{\linewidth}
\subfigure{
 \includegraphics[width=0.16\linewidth,trim=8.2 10 9 7.2,clip]{figs/sensitivity_group_click_din.pdf}
}
\hspace{-0.22cm}
\subfigure{
\includegraphics[width=0.16\linewidth,trim=8.2 10 9 7.2,clip]{figs/sensitivity_group_order_din.pdf}
}
\hspace{-0.22cm}
\subfigure{
\includegraphics[width=0.16\linewidth,trim=8.2 10 9 7.2,clip]{figs/sensitivity_group_click_mha.pdf}
}
\hspace{-0.22cm}
\subfigure{
\includegraphics[width=0.16\linewidth,trim=8.2 10 9 7.2,clip]{figs/sensitivity_group_order_mha.pdf}
}
\hspace{-0.22cm}
\subfigure{
\includegraphics[width=0.16\linewidth,trim=8.2 10 9 7.2,clip]{figs/sensitivity_group_click_can.pdf}
}
\hspace{-0.22cm}
\subfigure{
\includegraphics[width=0.16\linewidth,trim=8.2 10 9 7.2,clip]{figs/sensitivity_group_order_can.pdf}
}
\end{minipage}
\caption{Performance patterns by varying the number of chunks in \baby.}
\label{fig:sensitivity_performance}
\end{figure*}



\begin{table}[]
\caption{Online A/B results in Douyin Ads. The boldface highlight denotes that the improvement is significant with $p < $ \textbf{0.01}.}

\begin{tabular}{c|ccc}
\hline
                                                                                    & Methods  & CPM              & ADVV             \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Domain 1\\ (Short-Video)\end{tabular}}   & baseline & +0.00\%          & +0.00\%          \\
                                                                                    & \baby    & \textbf{+1.01\%} & \textbf{+1.66\%} \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Domain 2\\ (Live)\end{tabular}} & baseline & +0.00\%          & +0.00\%          \\
                                                                                    & \baby    & \textbf{+0.39\%} & \textbf{+0.84\%} \\ \hline
% \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Domain 3\\ (Short-Video)\end{tabular}}   & baseline & +0.00\%          & +0.00\%          \\
%                                                                                     & \baby    & \textbf{+1.11\%} & \textbf{+0.49\%} \\ \hline
\multirow{2}{*}{Overall}                                                            & baseline & +0.00\%          & +0.00\%          \\
                                                                                    & \baby    & \textbf{+0.52\%} & \textbf{+1.00\%} \\ \hline
\end{tabular}
\label{tab:ab_ads}
\end{table}



% \begin{table}[]
% \caption{Online A/B results of the proposed \baby in Douyin E-Com.}
% \begin{tabular}{cccc}
% \hline
%                         & GMV/U            & Order/U          & GPM              \\ \hline
% Domain 1 (Live-preview) & \textbf{+0.69\%} & \textbf{+0.32\%} & \textbf{+0.78\%} \\
% Domain 2 (Live-slide)   & \textbf{+0.93\%} & \textbf{+0.36\%} & \textbf{+0.97\%} \\ \hline
% \end{tabular}
% \end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
\caption{Online A/B results in Douyin Ecom. The boldface highlight denotes that the improvement is significant with $p < $ \textbf{0.01}.}
\begin{tabular}{c|cccc}
\hline
                                                                                   & Methods  & GMV/U            & Order/U          & GPM              \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Domain 1\\ (Live-Preview)\end{tabular}} & baseline & +0.00\%          & +0.00\%          & +0.00\%          \\
                                                                                   & \baby    & \textbf{+0.69\%} & \textbf{+0.32\%} & \textbf{+0.78\%} \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Domain 2\\ (Live-Slide)\end{tabular}}   & baseline & +0.00\%          & +0.00\%          & +0.00\%          \\
                                                                                   & \baby    & \textbf{+0.93\%} & \textbf{+0.36\%} & \textbf{+0.97\%} \\ \hline
\multirow{2}{*}{Overall}                                                           & baseline & +0.00\%          & +0.00\%          & +0.00\%          \\
                                                                                   & \baby    & \textbf{+0.79\%} & \textbf{+0.36\%} & \textbf{+0.89\%} \\ \hline
\end{tabular}
\label{tab:ab_ecom}
\end{table}


\subsection{Online Deployments}

The \baby model is online deployed with distribution across multi GPUs with a sharding and data parallelism strategy. The low-frequency embeddings are eliminated to reduce storage. To further increase GPU throughputs, we introduce Dense Computation Asynchrony strategy. It splits the computation graph into SparseForward and DenseCompute parts, which enables a pipeline effect and greatly improves training and inference efficiency. Benefiting from these, the offline training resource remains the same as baseline, i.e., 64 Nvidia A100s. Take the Douyin Ads as an example, the training time cost slightly increases from 41.3 to 42.8 hours (+3.6\%). The online latency remains at 30ms with no significant changes.

\subsection{Online A/B Experiments}

To investigate the performance of the proposed \baby in real industrial scenarios, we perform careful online A/B testing in both the advertising system and the e-commerce system in Douyin, respectively. 

\begin{itemize}[leftmargin=*]

 % Two metrics are selected for comparison, including Cost Per Mile (CPM) and Advertiser Value (ADVV), in which the former one is a widely used metric in advertisements, and the latter metric represents the reasonable advertising cost to be paid from the perspective of advertisers in ByteDance. Noted that the deployed scenario serves as the major traffic for advertisement in ByteDance with a strong baseline, and a 0.5\% improvement in CPM or ADVV is considered to be very significant. The comparison results are shown in Table~\ref{tab:ab_ads}. The domains including pay in live and order in live are summarized as live (Domain 2). From the table, it is observed that after deploying the \baby, the overall CPM is improved by 0.52\%, and the ADVV is improved by 1.00\%, showing the merits of adaptive sequence modeling of the proposed \baby. 

\item \textbf{Douyin Ads}. The online experiment on Douyin Ads is conducted from Nov. 2nd to Nov. 8th, 2023, hitting 74,079,729 users in Douyin APP. Two metrics including Cost Per Mile (CPM) and Advertiser Value (ADVV) are selected for comparison. Note that the deployed scenario serves as the major traffic for advertisement in ByteDance with a strong baseline, where a 0.5\% improvement in ADVV or CPM is considered to be significant. The comparison results are shown in Table~\ref{tab:ab_ads}. The domains including pay in live and order in live are summarized as Domain 2 (Live). From the table, it is observed that after deploying the \baby, the overall CPM is improved by 0.52\%, and the ADVV is improved by 1.00\%, showing the merits of adaptive sequence modeling of the proposed \baby. Besides, in the two major domains in Douyin Ads, including both live and short-video, the proposed \baby beats the baseline and achieves consistent improvements, showing the effectiveness in domain-aware sequential modeling for large-scaled industrial recommenders.

% The online experiment on Douyin Ads is conducted from Nov. 2nd to Nov. 8th, 2023, hitting 74079729 users in Douyin APP. Two metrics are selected for comparison, including Cost Per Mile (CPM) and Advertiser Value (ADVV), in which the former one is a widely used metric in the field of advertisement, and the latter metric represents the reasonable advertising cost to be paid from the perspective of advertisers in ByteDance, which can be calculated as the bid from the advertisers and the convert of the advertisement. It is noted that the deployed scenario serves as the major traffic for advertisement in ByteDance with a strong baseline, and a 0.5\% improvement in CPM or ADVV is considered to be very significant. The comparison results are shown in Table~\ref{tab:ab_ads}. The domains including pay in live and order in live are summarized as live (Domain 2). From the table, it is observed that after deploying the \baby, the overall CPM is improved by 0.52\%, and the ADVV is improved by 1.00\%, showing the merits of adaptive sequence modeling of the proposed \baby.  

\item \textbf{Douyin E-commerce}. The online experiment is performed from Jan. 23rd to Jan. 29th, 2024, on Douyin Ecom, hitting 508,926,918 users in Douyin APP. The experimental results are presented in Table~\ref{tab:ab_ecom}. Three metrics are selected for comparison, i.e., the gross merchandise volume per user (GMV/U), the number of orders per user (Order/U), and GMV per Mille (GPM), which are all important commercial metrics in Douyin E-commerce. Similar to the experiment conducted on Douyin Ads, it is noted that this deployed scenario contributes the highest GMV in ByteDance with a very strong baseline, and generally, an improvement at the ratio of 0.5\% in GMV is considered to be significant. As shown in Table~\ref{tab:ab_ecom}, the overall GMV/U, Order/U, and GPM are uplifted by 0.79\%, 0.36\%, and 0.89\%, respectively. Besides, consistent improvements are observed in both domains including live-preview and live-slide, and all the improvements are tested to be substantially statistically significant with a $p-\rm{value} < $ 0.01, verifying its efficacy.


% The online experiment is performed from Jan. 23rd to Jan. 29th, 2024 on Douyin E-Com, hitting 508,926,918 users. Three metrics are selected for comparison, including the gross merchandise volume per user (GMV/U), the number of orders per user (Order/U), and GMV per Mille (GPM), which are all important commercial metrics in Douyin E-commerce. Similar to the above experiment, it is noted that this deployed scenario contributes the highest GMV in ByteDance with a very strong baseline, and generally, an improvement at the ratio of 0.5\% in GMV is considered to be significant. As shown in Table~\ref{tab:ab_ecom}, the overall GMV/U, Order/U, and GPM are increased by 0.79\%, 0.36\%, and 0.89\%, respectively.  Besides, consistent improvements are observed in both the live-preview and live-slide domains, and the confidence of all the improvements is tested to be substantially statistically significant with a $p-\rm{value} < $ 0.01, verifying its efficacy.
\end{itemize}

\section{Related Works}
\subsection{Ranking models in recommendation}
The ranking model generally serves as the last stage of the industrial recommendation system funnel and plays a pivotal role in personalizing user recommendations in content and e-commerce platforms \cite{covington2016deep, chai2022umi}. Typically, they can be divided into two categories: 1) Feature interaction models which focus on modeling  discrete identifiers (IDs) feature interactions and capturing the co-occurrence patterns \cite{rendle2010factorization, guo2017deepfm, cheng2016wide, wang2017deep, wang2021dcn, zhang2022dhen}, and 2) Target-aware sequential models which capture user intention by evaluating the attention weight between the candidate item and the behavioral items \cite{zhou2018deep, zhou2019deep, shen2022deep, pi2020search, bian2022can, vaswani2017attention}. Despite the broad developments, the multi-domain problem that widely exists in large-scale recommender systems has been rarely considered in these methods.

\subsection{Multi-Domain Recommendation}
% \noindent \textbf{} 
Multi-domain recommendation aims to provide accurate personalized recommendation results for users and items from multiple domains. Both coarse-grained \cite{sheng2021one, tang2020progressive} and fine-grained \cite{yan2022apg, yang2022adasparse} multi-domain methods have been developed for sophisticated network structures, while the multi-domain learning for sequential modeling is seldom considered. Some other methods also contribute to learning personalized embeddings for multi-domain recommendation. The early idea is to use the self-gate mechanism to generate bitwise weights to reweigh the embeddings \cite{huang2020gatenet}. Further, the feature refinement network (FRNet) \cite{wang2022frnet} takes user contexts as gate input, enabling user-level personalization on specific features. To further consider the impact of multidomains, parameter and embedding personalized network (PEPNet) \cite{chang2023pepnet} and domain-facilitated feature modeling (DFFM) \cite{guo2023dffm} are developed, while bitwise scaling in PEPNet and linear transformation in DFFM are not flexible and sufficient enough to capture multidomains. Differently, \baby provides an approach by transforming the sequence embedding through a generated meta network, which provides a more flexible share-and-private modeling structure and is validated to be superior to existing methods. Besides, the \baby highlights that the identical target item has different influences on different sequence items. Traditional works can only obtain a novel target embedding shared for all sequence items, rather than multiple queries for different items, and this effective approach has not been explored in recommendation, to our knowledge. Besides, the extensive experiments on both public dataset and two giant scenarios in ByteDance (billions of daily active users) have demonstrated the effectiveness compared with existing approaches.

\section{Conclusion}
In this paper, we propose a novel multi-domain ranking model named adaptive domain scaling (ADS) model, which builds personalized sequence representation generation (PSRG) and personalized candidate representation generation (PCRG) to separately generate personalized sequence item and candidate target item representations. Specifically, for PSRG, both a sequence-weight gen-net and sequence-bias gen-net are developed to formulate the instance-wise MLP and modify the sequence items, such that the identical item occured in different user sequences has diverse representation. Besides, in PCRG, a multi-query gen-net is devised to generate multiple queries for sequence items, such that the identical candidate item extracts diverse intentions of users from the sequences from a multi-domain perspective. Offline experiments on both a public and two industrial datasets validate its significant and consistent improvements over existing SOTA methods, and extensive online experiments on two influential scenarios in ByteDance demonstrate its effectiveness. 

\baby is currently fully deployed and achieves substantial enhancements in dozens of recommendation services at ByteDance, and now serves billions of users each day. We believe that it has offered a solid solution and propelled the advancements in multi-domain ranking from a sequential-modeling perspective, and more efficient and effective adaptive modeling structures will be explored in the future.
% In this paper, we propose a novel multi-domain ranking model named Personalized Target Attention Network (PTANet), which builds personalized sequence representation generation (PSRG) and personalized candidate representation generation (PCRG) to separately generate personalized sequence item and candidate target item representations. Specifically, for PSRG, both a sequence-weight gen-net and sequence-bias gen-net are developed to formulate the instance-wise MLP and modify the sequence items, such that the identical item occured in different user sequences has diverse representation. Besides, in PCRG, a multi-query gen-net is devised to generate multiple queries for sequence items, such that the identical candidate item extracts diverse intentions of users from the sequences from a multi-domain perspective. Offline and online experiment on Douyin advertisement and e-commerce platforms demonstrate its significant and consistent improvements of \baby over exisiting SOTA methods. 

% \baby is currently fully deployed in many recommendation services at ByteDance, which achieves substantial and consistent enhancements, including Douyin ads and e-commerce platform, and now serves over 700 million users each day. We believe that this work has offered a solid solution and propelled the advancements in multi-domain ranking from a sequential-modeling perspective, and more efficient and effective adaptive modeling structures will be further explored in the future.






\balance
\bibliographystyle{ACM-Reference-Format}
\bibliography{ref}



% \appendix
% \section{Appendix}\label{sec:appendix}

% \paratitle{Comparing Methods.}





\end{document}
\endinput