\section{Experiments}
In this section, we present the experimental results on widely used FL benchmark datasets \citep{caldas2018leaf} including real-world datasets \citep{hsu2020federated}, comparing the performance of \shortname with other baselines from the literature, including standard FL algorithms and clustering methods.  A detailed description of the implementation settings, datasets and models used for the evaluation are reported in Appendix \ref{app_details}.
\begin{figure}[t]
    \centering
    \includegraphics[width=1.\linewidth]{figures/accuracy_stars.pdf}\vspace{-1.5em}
    \caption{\small{Balanced accuracy on Cifar100 for \shortname (blue curve) with \texttt{FedAvg} aggregation compared to the clustered FL baselines. \shortname detects two splits demonstrating significant improvements in accuracy when clustering is performed, leading also to a faster and more stable convergence than baseline algorithms.}}
    \label{fig:accuracy_jumpcifar100}
    \vspace{-1.3em}
\end{figure}
In Section \ref{exp}, we evaluate our method, \shortname, against various clustering algorithms, including \texttt{CFL} \citep{sattler2020clustered}, \texttt{FeSEM} \citep{long2023multi}, and \texttt{IFCA} \citep{ghosh2020efficient}, and standard FL aggregations \texttt{FedAvg} \citep{mcmahan2017communication}, \texttt{FedAvgM} \citep{asad2020fedopt}, FairAvg \citep{michieli2021all} and \texttt{FedProx} \citep{li2020federated}, showing also that how our approach is orthogonal to conventional FL aggregation methods.

In Section \ref{sec:large_scale}, we underscore that \shortname has the capability to surpass FL methods in real-world and large-scale scenarios \citep{hsu2020federated}.

Finally, in Section \ref{sect:ablation}, we propose analyses on class and domain imbalance, showing that our algorithm successfully detects clients belonging to separate distributions. Further experiments are presented in Appendix \ref{app:other}.

Each client has its own local train and test sets. Algorithm performance is evaluated by averaging the accuracy achieved on the local test sets across the federation, enabling a comparison between FL aggregation and clustered FL approaches (refer to Appendix \ref{app_details} for additional insights). When assessing clustering baselines, we also use the Wasserstein's Adjusted Silhouette Score (WAS) and Wasserstein's Adjusted Davies-Bouldin Score (WADB) to quantify the distributional cohesion among clients, an evaluation performed \textit{a posteriori}. For detection tasks in visual domains (Section \ref{sect:ablation}), we compute the Rand Index \citep{rand1971objective}, a clustering metric that compares the obtained clustering with a ground truth labeling. Further details on the chosen metrics are provided in Appendices \ref{app:metrics_choice} and \ref{app:clustering}.
\subsection{\shortname in heterogeneous settings}\label{exp}
In this section, we analyze the effectiveness of \shortname in mitigating the impact of data heterogeneity compared to standard aggregation methods and other clustered FL algorithms. We conduct experiments on Cifar100 \citep{krizhevsky2009learning} with 100 clients and Femnist \citep{lecun1998mnist} with 400 clients, controlling heterogeneity through a Dirichlet parameter $\alpha$, set to 0.5 for Cifar100 and 0.01 for Femnist, reflecting a realistic class imbalance across clients. Implementation details are provided in Appendix \ref{app_details}.
\begin{table}[t]
    \centering
    \small
        \centering
        \caption{\small{FL baselines in heterogeneous scenarios. Clustering baselines use FedAvg as aggregation mechanism. We emphasize the fact that \shortname and \texttt{CFL} automatically detect the number of clusters, unlike \texttt{IFCA} and \texttt{FeSEM} which require tuning the number of clusters. A higher WAS , denoted by $\uparrow$, and a lower WADB, denoted by $\downarrow$ indicate better clustering outcomes} }
        \label{tab:clustering}
        \begin{adjustbox}{width=\linewidth}
       
        \begin{tabular}{llcccccc}
            \toprule
            & & \makecell{ \textbf{FL} \textbf{method}}& \textbf{C}& \makecell{ \textbf{Automatic} \\ \textbf{Cluster} \\ \textbf{Selection}} & \textbf{Acc} & \textbf{WAS} $\uparrow$ & \textbf{WADB} $\downarrow$ \\
            \midrule
            \multirow{7}{*}{\rotatebox[origin=c]{90}{\textbf{Cifar100} \hspace{.75em}}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{\makecell{Clustered\\ FL}}} &  \texttt{IFCA} &  5 & \ding{55}& 47.5 \scriptsize{$\pm$ 3.5} & -0.8 \scriptsize{$\pm$ 0.2} &  5.2 \scriptsize{$\pm$ 5.1} \\
            & & \texttt{FeSem} & 5 & \ding{55}& 53.4 \scriptsize{$\pm$ 1.8} & -0.3 \scriptsize{$\pm$ 0.1} & 38.4 \scriptsize{$\pm$ 13.0}\\
            & & \texttt{CFL} & 1 &\ding{51}& 41.6 \scriptsize{$\pm$ 1.3} & / & / \\
            & & \shortname & 4 & \ding{51}&\textbf{53.4 \scriptsize{$\pm$ 0.4}} & \textbf{0.1 \scriptsize{$\pm$ 0.0}} & \textbf{2.4 \scriptsize{$\pm$ 0.4}} \\
            \cmidrule{2-8}
            
            & \multirow{3}{*}{\rotatebox[origin=c]{90}{\makecell{Classic\\ FL}}} &  \texttt{FedAvg} &  1 & / &   41.6\scriptsize{$\pm$ 1.3} &  / &  / \\
            & & \texttt{FedAvgM} & 1 & /& 41.5\scriptsize{$\pm$ 0.5}& / & /  \\
            & & \texttt{FedProx} & 1 & /& 41.8\scriptsize{$\pm$ 1.0} & / & / \\
            \midrule
       
            
            \multirow{7}{*}{\rotatebox[origin=c]{90}{\textbf{Femnist} \hspace{.75em}}} & \multirow{4}{*}{\rotatebox[origin=c]{90}{\makecell{Clustered\\ FL}}} &  \texttt{IFCA} &  5 & \ding{55} &  {76.7 \scriptsize{$\pm$ 0.6}} &  \textbf{0.3 \scriptsize{$\pm$ 0.1}} &  \textbf{0.5 \scriptsize{$\pm$ 0.1}} \\
            & & \texttt{FeSem} & 2 & \ding{55}& 75.6 \scriptsize{$\pm$ 0.2} & 0.0 \scriptsize{$\pm$ 0.0} & 25.6 \scriptsize{$\pm$ 7.8}  \\
            & & \texttt{CFL} & 1 & \ding{51}& 76.0 \scriptsize{$\pm$ 0.1} & / & / \\
            & & \shortname & 4 & \ding{51}&76.1 \scriptsize{$\pm$ 0.1} & -0.2 \scriptsize{$\pm$ 0.1} & 18.0 \scriptsize{$\pm$ 6.2}\\
            \cmidrule{2-8}
            & \multirow{3}{*}{\rotatebox[origin=c]{90}{\makecell{Classic\\ FL}}} &  \texttt{FedAvg} &  1 & / &  76.6\scriptsize{$\pm$ 0.1} &  / &  / \\
            & & \texttt{FedAvgM} & 1 & /&  \textbf{83.3}\scriptsize{$\pm$ \textbf{0.3}}& / & /  \\
            & & \texttt{FedProx} & 1 & /& 75.9\scriptsize{$\pm$ 0.2} & / & / \\
            \bottomrule
        \end{tabular}
        \end{adjustbox}
       
      
\end{table}


We compare \shortname against clustered FL baselines (\texttt{IFCA}, \texttt{FeSEM}, \texttt{CFL}) using \texttt{FedAvg} aggregation, as well as standard FL algorithms (\texttt{FedAvg}, \texttt{FedAvgM}, \texttt{FedProx}). For algorithms requiring a predefined number of clusters (\texttt{IFCA}, \texttt{FeSEM}), we report the best result among 2, 3, 4, and 5 clusters, with full tuning details in Appendix \ref{app:tuning}. While \texttt{IFCA} achieves competitive results, its high communication overhead—requiring each client to evaluate models from every cluster in each round—makes it impractical for cross-device FL, serving as an upper bound in our study. \texttt{FeSEM} is more efficient than \texttt{IFCA} but lacks adaptability due to its fixed cluster count. Meanwhile, \texttt{CFL} requires extensive hyperparameter tuning and often produces overly fine-grained clusters or fails to form clusters altogether. In contrast, \shortname requires only one hyperparameter and provides a more practical clustering strategy for cross-device FL.

Table \ref{tab:clustering} presents a comparative analysis of these algorithms in terms of balanced accuracy, WAS, and WADB, using \texttt{FedAvg} as the aggregation method. Higher WAS values indicate better clustering, while lower WADB values suggest better cohesion. On Femnist, clustering-based methods perform worse than standard FL aggregation, but as we move to the more complex and realistic Cifar100 scenario, it becomes evident that clustered FL is necessary to address heterogeneity. In this case, \shortname achieves the best performance in both classification accuracy and clustering quality, with the latter directly influencing the former. The need for clustering grows with increasing heterogeneity, as seen in Table \ref{tab:clustering}: standard FL approaches struggle when trained on a single heterogeneous cluster, whereas clustered FL effectively mitigates the heterogeneity effect. This is particularly relevant for Cifar100, which has a larger number of classes and three-channel images, whereas Femnist consists of grayscale images from only 47 classes.


In Table \ref{tab:clustering}, we present a comparative analysis of these algorithms with respect to balanced accuracy, WAS, and WADB, employing \texttt{FedAvg} as the aggregation strategy. Recall that higher the value of  WAS the better the clustering outcome, as, for WADB, a lower value suggests a better cohesion between clusters. Further details on the metrics used are provided in Appendix \ref{app:metrics_choice}.

Notably, both \shortname and \texttt{CFL} automatically determine the optimal number of clusters based on data heterogeneity, offering a more scalable solution for large-scale cross-device FL. In contrast to \texttt{CFL}, \shortname consistently produced a reasonable number of clusters, even when using the optimal hyperparameters for \texttt{CFL}, which resulted in no splits, thereby achieving performance equivalent to FedAvg. 

 We observe in Figure \ref{fig:accuracy_jumpcifar100} that \shortname exhibits a significant improvement in accuracy on Cifar100 precisely at the rounds where clustering occurs. 

As detailed in Table \ref{tab_app:fl-algs} in Appendix \ref{app:other}, \shortname is orthogonal to any FL aggregation algorithm, \ie any FL method can be easily embedded in \shortname. Our method consistently boosted the performance of FL algorithms for the more heterogeneous settings of Cifar100 and Femnist.
\begin{table*}[t]
\small
\centering
\renewcommand{\arraystretch}{1.5} 
\begin{adjustbox}{width=.7\linewidth}

\begin{tabular}{@{}l|cccccccc@{}}
\toprule
\textbf{Dataset}      & {\shortname} & {\texttt{CFL}}       & \texttt{IFCA} & {FedAvg} & {FedAvgM} & {FedProx} & {FairAvg} \\ \midrule
Google Landmarks      & \textbf{57.4  \scriptsize{$\pm$0.3}} &   40.5  \scriptsize{$\pm$0.2} &  49.4   \scriptsize{$\pm$0.3}    &     40.5  \scriptsize{$\pm$0.2}&  36.4  \scriptsize{$\pm$1.3}  &  40.2  \scriptsize{$\pm$0.6}               &     39.0 \scriptsize{$\pm$0.3}              \\ 
\hline
iNaturalist           & \textbf{47.8  \scriptsize{$\pm$0.2}}   & 45.3  \scriptsize{$\pm$0.1}  &  45.8  \scriptsize{$\pm$0.6}   &     45.3 \scriptsize{$\pm$0.1}            &   37.7  \scriptsize{$\pm$1.4}               &      44.9  \scriptsize{$\pm$0.2}  &      45.1 \scriptsize{$\pm$0.2}            \\ \bottomrule
\end{tabular}
    
\end{adjustbox}
\caption{\small{
Comparison of test accuracy on large scale FL datasets Google Landmarks and iNaturalist, between \shortname and FL baselines -- all clustered FL algorithms use FedAvg aggregation. \shortname outperforms both clustered and standard FL methods detecting 5 and 4 clusters on Landmarks and iNaturalist, respectively.}}\label{tab:largescale}\vspace{-1.5em}
\end{table*}


\subsection{\shortname in Large Scale and Real World Scenarios}\label{sec:large_scale}

We evaluate \shortname on two large-scale, real-world datasets: Google Landmarks \citep{weyand2020google} and iNaturalist \citep{van2018inaturalist}, respectively considering the partitions Landmarks-Users-160K, and iNaturalist-Users-120K, proposed in \citep{hsu2020federated}. Both datasets exhibit high data heterogeneity and involve a large number of clients - approximately 800 for Landmarks and 2,700 for iNaturalist. To simulate a realistic cross-device scenario, we set 10 participating clients per round.
For this experiment, we compare \shortname against clustered FL baselines (\texttt{IFCA}, \texttt{CFL}) and standard FL aggregation methods (\texttt{FedAvg}, \texttt{FedAvgM}, \texttt{FedProx}, \texttt{FairAvg}). The number of clusters for \texttt{IFCA} is tuned between 2 and 5. Due to its high computational cost in large-scale settings, \texttt{FeSEM} was not included in this analysis.
Table \ref{tab:largescale} reports the results: \shortname with \texttt{FedAvg} aggregation achieves 57.4\% accuracy on Landmarks, significantly outperforming all standard FL methods. In this scenario, \shortname detects 5 clusters with the best hyperparameter setting ($\beta = 0.5$), while \texttt{IFCA} identifies 3 clusters.
Similarly, on iNaturalist, \shortname consistently surpasses FL baselines, reaching an average accuracy of 47.8\% with $\beta = 0.5$ (automatically detecting a partition with 4 clusters). Results in Table \ref{tab:largescale} remark that, when dealing with realistic complex decentralized scenarios, standard aggregation methods are not able to mitigate the effects of heterogeneity across the federation, while, on the other hand, clustered FL provides a more efficient solution.
\vspace{-1em}
\subsection{Clustering analysis of \shortname}\label{sect:ablation}
In this section, we investigate the underlying mechanisms behind \shortname’s clustering in heterogeneous scenarios on Cifar100. Further experiments on Cifar10 are presented in Appendix \ref{app:cifar10}.
\vspace{-1.3em}
\paragraph{\shortname detects different client class distributions}
We explore how the algorithm identifies and groups clients based on the non-IID nature of their data distributions, represented by the Dirichlet concentration parameter $\alpha$. For the Cifar100 dataset, we apply a similar splitting approach, obtaining the following partitions: (1) 90 clients with $\alpha = 0$ and 10 clients with $\alpha = 1000$; (2) 90 clients with $\alpha = 0.5$ and 10 clients with $\alpha = 1000$; and (3) 40 clients with $\alpha = 1000$, 30 clients with $\alpha = 0.05$, and 30 clients with $\alpha = 0$. We evaluate the outcome of this clustering experiment by means of WAS and WADB. Results in Table \ref{tab:ablation1_heter} show that \shortname detects clusters groups clients according to the level of heterogeneity of the group.
\begin{table}[h]
    
    \caption{\small{Clustering with three different splits on Cifar100 datasets. \shortname has superior clustering quality across different splits (homogeneous $\alpha = 1000$, heterogeneous $\alpha = 0.05$, extremely heterogeneous $\alpha = 0$}. )}
    \centering
    \small
    \begin{adjustbox}{width=\linewidth}
        \label{tab:ablation1_heter}
     
        \begin{tabular}{lccccc}
            \toprule
            \textbf{Dataset} & \textbf{(Hom, Het, X Het)} & \makecell{\textbf{Clustering} \\ \textbf{method}} & \textbf{C} & \textbf{WAS}$\uparrow$ & \textbf{WADB} $\downarrow$ \\
            \cmidrule(lr){1-6}
        
            \multirow{9}{*}{Cifar100} 
            & \multirow{3}{*}{(10, 0, 90)} & \texttt{IFCA} & 5 & -0.9 \scriptsize{$\pm$ 0.0} & 1.8 \scriptsize{$\pm$ 0.0} \\
            & & \texttt{FeSem} & 5 & -0.8 \scriptsize{$\pm$ 0.2} & 2.6 \scriptsize{$\pm$ 0.6} \\
            & & \shortname & 5 & \textbf{0.1 \scriptsize{$\pm$ 0.1}} & \textbf{0.2 \scriptsize{$\pm$ 0.2}} \\
            \cmidrule(lr){2-6}
            & \multirow{3}{*}{(10, 90, 0)} & \texttt{IFCA} & 5 & -0.0 \scriptsize{$\pm$ 0.0} & \textbf{5.6 \scriptsize{$\pm$ 1.5}} \\
            & & \texttt{FeSem} & 5 & 0.2 \scriptsize{$\pm$ 0.1} & 12.0 \scriptsize{$\pm$ 2.0} \\
            & & \shortname & 5 & \textbf{0.4 \scriptsize{$\pm$ 0.1}} & 6.4 \scriptsize{$\pm$ 2.0} \\
            \cmidrule(lr){2-6}
            
            & \multirow{3}{*}{(40, 30, 30)} & \texttt{IFCA} & 5 & -0.2 \scriptsize{$\pm$ 0.0} & 1.0 \scriptsize{$\pm$ 0.0}\\
            & & \texttt{FeSem} & 5 & -0.2 \scriptsize{$\pm$ 0.0} & 33.2 \scriptsize{$\pm$ 0.0} \\
            & & \shortname & 3 & \textbf{0.4 \scriptsize{$\pm$ 0.2}} & \textbf{0.9 \scriptsize{$\pm$ 0.1}} \\
            \bottomrule
        \end{tabular}
    \end{adjustbox}
    
\end{table}
\vspace{-1.5em}
\paragraph{\shortname detects different visual client domains.}
Here, we focus on scenarios with nearly uniform class imbalance (high $\alpha$ values) but with different visual domains to investigate how \shortname forms clusters in such settings. We incorporated various artificial domains (non-perturbed, noisy, and blurred images) Cifar100 dataset under homogeneous conditions ($\alpha=100.00$). Our results demonstrate that \shortname effectively clustered clients according to these distinct domains. Table \ref{tab:dom_abl} presents the Rand-Index scores, which assess clustering quality based on known domain labels. The high Rand-Index scores, often approaching the upper bound of 1, indicate that \shortname successfully separated clients into distinct clusters corresponding to their respective domains. %
This anaylsis suggests that \shortname may be applicable for detecting malicious clients in FL, pinpointing a potential direction for future research.
\begin{table}[t]
    
    \caption{\small Clustering performance of \shortname is assessed on federations with clients from varied domains using clean, noisy, and blurred (Clean, Noise, Blur) images from Cifar100 datasets. It utilizes the Rand Index score \citep{rand1971objective}, where a value close to 1 represents a perfect match between clustering and labels. Consistently \shortname accurately distinguishes all visual domains. The ground truth number of clusters is respectively 2, 2, and 3.}
    \label{tab:dom_abl}
    
    \centering
    
    \begin{adjustbox}{width=\linewidth}
    \setlength{\tabcolsep}{9pt}
        \begin{tabular}{ccccccc}
           \toprule
            \textbf{Dataset} & \textbf{(Clean, Noise, Blur)} & \makecell{\textbf{Clustering} \\ \textbf{method}} & \textbf{C} &\textbf{\makecell{Automatic\\Cluster \\Selection}}& \makecell{\textbf{Rand} $\uparrow$ \\ \textbf{(max = 1.0)}}  \\
            \cmidrule(lr){1-6}
            
            \multirow{9}{*}{Cifar100} 
            & \multirow{3}{*}{(50, 50, 0)} & \texttt{IFCA} & 1  & \ding{55}& 0.5 \scriptsize{$\pm$ 0.0}  \\
            & & \texttt{FeSem} & 2 &\ding{55}& 0.49 \scriptsize{$\pm$ 0.2}  \\
            & & \shortname & 2 & \ding{51} &\textbf{1.0 \scriptsize{$\pm$ 0.0}} \\
            \cmidrule(lr){2-6}
            & \multirow{3}{*}{(50, 0, 50)} & \texttt{IFCA} & 1 & \ding{55}& 0.5 \scriptsize{$\pm$ 0.0} \\
            & & \texttt{FeSem} & 2 &\ding{55}& 0.51 \scriptsize{$\pm$ 0.1} \\
            & & \shortname & 2 & \ding{51}&\textbf{1.0 \scriptsize{$\pm$ 0.0}} \\
            \cmidrule(lr){2-6}
            
            & \multirow{3}{*}{(40, 30, 30)} & \texttt{IFCA} & 1 &\ding{55} & 0.33 \scriptsize{$\pm$ 0.0}\\
            & & \texttt{FeSem} & 3 &\ding{55} & 0.55 \scriptsize{$\pm$ 0.0}\\
            & & \shortname & 4 & \ding{51} &\textbf{0.6 \scriptsize{$\pm$ 0.0}} \\
            \bottomrule
        \end{tabular}
    \end{adjustbox}
\end{table}

