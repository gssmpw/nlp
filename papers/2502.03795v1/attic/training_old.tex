\section{Training Algorithm} \ymmtd{This section is overall a good candidate for shortening. It's more than we need in terms of setup for the main results of Section 4.}

\subsection{Target Measure is Known through a Collection of Samples}
The training objective we consider consists of two parts, one is the
KL divergence between the push forward of the target by the time-one
flow map of the ODE and the source measure, and the other part is the
integration of \eqref{eq:straightlinereg} along the trajectories of
the particles.

First, we derive the training objective for the problem where the
target measure is known through a collection of samples. By the change
of variables formula, the change in density as we flow a sample
$x\sim\pi$ at time $t\in[0,1]$ is given by
$\pi(x) = \pi_{f, t}(X(x,t))\det(\nabla_x X(x,t))$. To calculate the KL,
we have
$$d_\text{KL}[X(x,1)_\sharp\pi(x)|| \rho(x)] = d_\text{KL}[\pi_{f, 1}|| \rho(x)] =\int_{\mathbb{R}^d} \log\left(\frac{\pi_{f,1}}{\rho(x)}\right)\pi_{f,1}dx.$$ 

By the change of variables formula, we can express this as
\begin{align*}
  d_\text{KL}[X(x,1)_\sharp\pi(x)|| \rho(x)] 
  &= \int_{\mathbb{R}^d} \log\left(\frac{\pi_{f,1}(X(x,1))}{\rho(X(x,1))}\right)\pi_{f,1}(X(x,1)) \det(\nabla_x X(x,1))dx\\ 
  &=  \int_{\mathbb{R}^d} \log\left(\frac{\pi(x)}{\rho(X(x,1))\det(\nabla_x X(x,1))}\right)\pi(x)dx.      
\end{align*}
Note that this can be expressed as as an expectation over the target
measure $\pi(x)$:
$$d_\text{KL}[X(x,1)_\sharp\pi(x)|| \rho(x)] = \mathbb{E}_{\pi(x)}[\log\pi(x) - \log\rho(X(x,1)) - \log\det(\nabla_x X(x,1))].$$

The term $\log\det(\nabla_x X(x,1))$ can be computed from the
instantaneous change of variables formula in \cite{NeuralODE}. That
is, we have
$\log\det(\nabla_x X(x,1)) = -\int_0^1\text{Tr}\left(\frac{\partial
    f(X(x,t),t)}{dX}\right)dt$.

\ymmtd{Could motivate this better} Note that straight line
constructions imply that \eqref{eq:straightlinereg} is zero everywhere
in space time. For computational purpose, we penalize
\eqref{eq:straightlinereg} along the ODE trajectories and define the
regularization term
$R(x,t) = \int_0^t |\nabla_X(f(X(x,s),s))f(X(x,s),s) +
\partial_tf(X(x,s),s)|^2ds$ for $x\in\Omega_0$ and $t\in[0,1]$. Now
the combined optimization \rr{objective} becomes:\jztd{not an
  optimization problem but an objective function; to define the
  optimization problem we still have to say what we optimize
  (minimize) over; probably it should be all Lipschitz continuous $f$,
  which guarantees that $J(f)$ is well-defined}
\begin{equation}\label{OP1}
  \begin{aligned}
    J(f) &= d_\text{KL}[X(x,1)_\sharp\pi(x)|| \rho(x)] + \lambda\mathbb{E}_{x\sim\pi(x)}[R(x,1)]\\
    &= \mathbb{E}_{x\sim\pi(x)}[\log\pi(x) - \log\rho(X(x,1)) - \log\det(\nabla_x X(x,1)) + \lambda R(x,1)]\\
    &=\mathbb{E}_{x\sim\pi(x)}[\log\pi(x) - \log\rho(X(x,1)) +  \int_0^1\text{Tr}\left(\frac{\partial f(X(x,t),t)}{dX}\right)dt + \lambda R(x,1)]\\
  \end{aligned}\tag{OP1}
\end{equation}
where $\lambda$ controls the impact of penalization.

\rr{By Picard–Lindel\"{o}f theorem (\cite{ArnoldODE}), for the ODE
  \eqref{eq:ODE} to have existence and uniqueness of solutions, it is
  required that the velocity field $f$ is uniformly Lipschitz
  continuous in space variable $X$ and continuous in time variable
  $t$. Therefore, we are constrained to search over the space of
  functions that we denote as $\mathcal{V}$, where
  \begin{equation}\label{eqn:VelocityField}
    \mathcal{V} = \{f(x,t):\mathbb{R}^d\times[0,1]\rightarrow\mathbb{R}^d|f\text{ is continuous in } t \text{ and Lipschitz continuous in } x\},    
  \end{equation}



  and we have the following optimization problem:
  \begin{equation*}
    \begin{aligned}
      & \underset{f(x,t)\in\mathcal{V}}{\text{minimize}}
      & & J(f)\\
      & \text{subject to}
      & & X(x,1) = \int_0^1f(X(x,t),t)dt\\
      & & & R(x,1) = \int_0^1 |\nabla_X(f(X(x,t),t))f(X(x,t),t) +
      \partial_tf(X(x,t),t)|^2dt.
    \end{aligned}
  \end{equation*}
}
\begin{remark}
  In practice, the conditions of Picard–Lindel\"{o}f theorem will
  always be satisfied for a neural network with Lipschitz activation
  functions and finite size. In particular, these will hold true for
  ReLU networks, which is what we consider in theoretical analysis.
\end{remark}




To compute the optimization objective, we need to be able to compute
the matrix $\frac{\partial f(X(x,t),t)}{\partial X}$, as its trace
appears in computing the log-determinant term and the entire matrix
appears in $R(x,1)$. Also, we need to be able to compute
$\partial_tf(X(x,t),t)$. Note that we can assemble these two parts
into a full Jacobian matrix, which we denote by
$\nabla_{X,t}f(X(x,t),t)$. This is the Jacobian matrix of a neural
network with respect to all of its inputs. With the
discretize-then-optimize approach in \cite{OTFlow}, we can compute
this exactly via automatic differentiation. For details, see appendix
\ref{ExactCompJacobian}.

In practice, we only have access to a finite collection of samples
from the target measure, so we need to replace the population risk in
objective \ref{OP1} with empirical risk based on the
samples. Moreover, since $\log\pi(x)$ is independent of the velocity
field $f$, it can be thrown away in the training process. Hence, we
arrive at the following \textit{empirical risk minimization} problem.
\begin{equation}\label{ERM}
  \begin{aligned}
    J_\text{ERM}(f) &= \frac{1}{N}\sum_{i=1}^N\left( -\log\rho(X(x_i,1)) - \log\det(\nabla_x X(x_i,1)) + \lambda R(x_i,1)\right)\\
    &= \frac{1}{N}\sum_{i=1}^N\left( -\log\rho(X(x_i,1)) +
      \int_0^1\text{Tr}\left(\frac{\partial
          f(X(x_i,t),t)}{dX}\right)dt + \lambda R(x_i,1)\right)
  \end{aligned}\tag{ERM}
\end{equation}
Putting everything together, we have Algorithm \ref{algo1}.

\jztd{macro $\backslash$mb was not defined; I commented the algorithm
  out, since the file doesn't compile otherwise}
\begin{algorithm}
  \caption{Sampling from target distribution known through samples}
  \label{algo1}
  \begin{algorithmic}[1]
    \STATE \textbf{Input}: data $X = \{ x_i\}_{i=1}^N$ from target
    measure $\pi$, parametrized neural network $f(\cdot\,; \theta)$,
    regularization strength $\lambda$, source measure $\rho$.
    \STATE\textbf{Initialize} $\theta$, \WHILE{$\theta$ not converged}
    \STATE{Sample minibatch $\{ x_j\}$ of size $m$ from $X$}
    \STATE{Set $ x_j(0) = x_j$, $l_j = r_j(0)=0$ } \STATE{Solve the
      following ODE system up to time one} \STATE{\begin{itemize}
      \item $\frac{dx_j}{dt} = f(x_j,t;\theta)$
      \item $\frac{dl_j}{dt} = -\text{Tr}(\nabla_xf(x_j,t;\theta))$
      \item
        $\frac{dr_j}{dt} = |\nabla_xf(x_j,t;\theta)f(x_j,t;\theta) +
        \partial_tf(x_j,t)|^2$
      \end{itemize}} \STATE{Compute the loss
      $L(\theta) =
      \frac{1}{m}\sum_{j=1}^m-\log\rho(x_j(1))-l_j(1)+\lambda r_j(1)$}
    \STATE{Use Automatic Differentiation (AD) to backpropagate and
      update $\theta$} \ENDWHILE
  \end{algorithmic}
\end{algorithm}

\subsection{Target Measure is Known up to Normalizing Constant}
In this setting, we assume that the density $\pi(x) = \Tilde{\pi}(x)/C$, where $C$ is the normalization constant. In this case, we seek to minimize $d_\text{KL}[X(x,1)_\sharp\rho(x)||\pi(x)]$ plus the regularization term. The KL-divergence term can be derived similarly:
\begin{align*}
d_\text{KL}[X(x,1)_\sharp\rho(x)||\pi(x)] &=  d_\text{KL}[X(x,1)_\sharp\rho(x)||\Tilde{\pi}(x)/C] \\
&= \mathbb{E}_{x\sim\rho(x)}[\log\rho(x) - \log\Tilde{\pi}(X(x,1)) + \log C - \log\det(\nabla_x X(x,1))],
\end{align*}
and the combined optimization objective  \ref{OP2}  is the follows:
\begin{equation}\label{OP2}
\begin{aligned}
     J(f) &= d_\text{KL}[X(x,1)_\sharp\rho(x)||\pi(x)] + \lambda\mathbb{E}_{x\sim\rho(x)}[R(x,1)]\\
     &= \mathbb{E}_{x\sim\rho(x)}[\log\rho(x) - \log\Tilde{\pi}(X(x,1)) + \log C - \log\det(\nabla_x X(x,1)) + \lambda R(x,1)]\\
     &= \mathbb{E}_{x\sim\rho(x)}[\log\rho(x) - \log\Tilde{\pi}(X(x,1)) + \log C + \int_0^1\text{Tr}\left(\frac{\partial f(X(x,t),t)}{dX}\right)dt + \lambda R(x,1)],\\
\end{aligned}\tag{OP2}
\end{equation}
where $R(x,1) = \int_0^1  |\nabla_X(f(X(x,t),t))f(X(x,t),t) + \partial_tf(X(x,t),t)|^2dt$ is the same as the previous problem, except now $x$ is sampled from $\rho$.

For the purpose of optimization in practice, independent terms in \ref{OP2} like $\log\rho(x) + \log C$ could be dropped. Also, note that compared to the previous problem, we now know everything about $\rho$. To evaluate the expectation in \ref{OP2}, a simple Monte-Carlo method would yield Algorithm \ref{algo1}, with the role of $\pi$ and $\rho$ switched. We comment here that there exist a host of techniques to approximate the integral with respect to the source measure, including quadrature and cubature formulas, sparse quadratures, and various other Monte-Carlo methods and we will not discuss them in details here. Regardless of the tool for computing the expectation, automatic differentiation combined with an explicit ODE integration scheme would give the update on the parameters in the neural network. 
