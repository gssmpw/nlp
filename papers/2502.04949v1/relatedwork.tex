\section{Related Work}
\label{sec:related_work}

\paragraph{Robust Neural SBI}
Robustness in neural SBI has become a rapidly growing area of research, with most approaches enhancing robustness for a single data set at the cost of amortization, e.g., due to additional MCMC runs or post-hoc corrections.
The majority of these approaches focuses on \textbf{Target 2} by incorporating an misspecification model \citep{ward2022robust}, shifting observed summary statistics with low support \citep{kelly2023misspecification}, reducing the influence of unmodeled data shifts via generalized SBI \citep{gao2023generalized}, or using the single-data-set NPE-MMD variant previously discussed \citep{huang2024learning}.
Focusing on \textbf{Target 1}, \citet{siahkoohi2023reliable} highlighted the role of the approximator's latent space in domain shifts and proposed a latent space correction based on the observed data $\x_\tobs$.
Differently, \citet{wang2024preconditioned} focus on \textbf{Target 3} by using an upfront ABC run to filter the part of the parameter space causing the highest discrepancy between $\x$ and $\x_\tobs$.

\paragraph{Robust ABI} 
In contrast, research on robustifying inference while retaining amortization has been sparse. 
Extending the scope of the training data via additive noise
\citep{cranmer2020frontier, bernaerts2023combined}, such as the spike-and-slab noise approach of Noisy NPE \citep[NNPE;][]{ward2022robust}, can be seen as a light modification to the simulator-implied likelihood as in \textbf{Target 2}, but requires strong assumptions about the misspecification-generating process.
\citet{wehenkel2024addressing} also approach \textbf{Target 2} by framing domain shift as an optimal transport problem in summary space, but this requires \emph{observed} ``ground-truth'' parameters $\thetab_\tobs^*$ that are hard to obtain in most ABI settings.
\citet{swierc2024domain_npe} provided evidence for the potential of NPE-MMD for robust ABI but focused their evaluation on a gravitational lensing application with synthetically added noise.
Finally, \citet{gloeckler2023adversarial} proposed an efficient regularization technique that can increase robustness against adversarial attacks and thus attain more reliable performance under \textbf{Target 1}.