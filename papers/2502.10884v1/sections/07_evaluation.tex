\section{User Evaluation}
\label{eval}

\begin{table*}
  \caption{The distribution of opinions on AI-powered programming tools and their awareness of web accessibility based on the responses from participants in the evaluation study. The percentages in the distribution column indicate the proportion of participants who either disagree (including `strongly disagree', `disagree' and `slightly disagree') or agree (including `strongly agree', `agree' and `slightly agree') with the provided statements.}
  \label{tab:aware2}
  \begin{tabular}{>{\raggedright\arraybackslash}p{0.6\textwidth}|>{\raggedright\arraybackslash}p{0.35\textwidth}}
    \toprule
    \textbf{Statement} & \textbf{Distribution}\\
    \midrule
    ``I trust the accuracy of AI programming tools.''& \likertpctt{0}{1}{2}{3}{10}{4}{0}\\
    ``I am proficient in web accessibility.''& \likertpctt{5}{5}{4}{1}{4}{0}{1}\\
    ``I am familiar with the web accessibility standards, such as WCAG 2.0.''& \likertpctt{11}{4}{1}{1}{0}{1}{2}\\
    ``I am familiar with ARIA roles, states, and properties.''& \likertpctt{13}{4}{0}{1}{0}{1}{1}\\
  \midrule
\end{tabular}
% \vspace{1em}
\begin{tabular}{@{}>{\centering\arraybackslash}p{\textwidth}@{}}
        \textcolor{customorange}{\rule{7pt}{7pt}} Strongly Disagree \;
        \textcolor{custommidorangepeach}{\rule{7pt}{7pt}} Disagree \;
        \textcolor{custompeach}{\rule{7pt}{7pt}} Slightly Disagree \;
        \textcolor{customgray}{\rule{7pt}{7pt}} Neutral \;
        \textcolor{customlightblue}{\rule{7pt}{7pt}} Slightly Agree \;
        \textcolor{custommidbluelightblue}{\rule{7pt}{7pt}} Agree \;
        \textcolor{customblue}{\rule{7pt}{7pt}} Strongly Agree \\ 
    \bottomrule
    \end{tabular}
\end{table*}

We conducted a within-subjects user study with 20 new participants to evaluate CodeA11y's effectiveness in guiding novice developers toward adhering to accessibility standards, as compared to Copilot.

\subsection{Methodology}
We made the following revisions to our formative study protocol (Section~\ref{form_methods}). First, the experimental conditions were updated as follows: (1) the control condition involved using the baseline AI assistant (GitHub Copilot), and (2) the test condition where the participants used CodeA11y. Second, we changed the post-task survey to a brief semi-structured interview to get more nuanced insights about the usability of our system. \begin{highlight} We analyzed interview responses to better understand the factors shaping participants' assistant preferences and their perceptions of any new coding practices introduced during the study.\end{highlight} Third, we used Visual Studio Code as the IDE interface (which had advanced AI updates since the formative study -- regarding both model performance and introduction of new features such as Inline Chat). Finally, we recruited 20 new participants for this subsequent study, with no prior exposure to the formative study, to evaluate CodeA11y's \begin{highlight}
performance on the same UI development tasks\end{highlight}. These participants were the same demographic as our formative participants (students; multiyear programming experience; 6 female and 14 male; ages ranged from 22 to 30). Again, most participants were unfamiliar with the web accessibility standards (Table~\ref{tab:aware2}), but most (90\%) had experience using AI programming tools. The IRB approved all our modifications.

\begin{table*}
  \caption{The distribution of participants' opinions on GitHub Copilot and CodeA11y, as well as their ease of completing tasks with these tools. The distribution column shows the count of responses from Strongly Disagree (1) to Strongly Agree (7).}
  \label{tab:satisfaction}
  \begin{tabular}{>{\raggedright\arraybackslash}p{0.5\textwidth}|>{\raggedright\arraybackslash}p{0.45\textwidth}}
    \toprule
    \textbf{Statement} & \textbf{Distribution}\\
    \midrule
    \multicolumn{1}{l}{``I am satisfied with the code suggestions provided by'':} & \\ \midrule
    GitHub Copilot & \likerteval{1}{1}{2}{1}{8}{3}{4} \\
    CodeA11y & \likerteval{1}{2}{0}{2}{4}{7}{4} \\ \midrule
    \multicolumn{1}{l}{``I found it easy to complete the coding tasks with'':} & \\ \midrule
    GitHub Copilot & \likerteval{0}{3}{0}{1}{3}{8}{5} \\
    CodeA11y & \likerteval{0}{2}{0}{0}{3}{8}{7} \\
    \midrule
\end{tabular}
\begin{tabular}{@{}>{\centering\arraybackslash}p{\textwidth}@{}}
    \textcolor{customorange}{\rule{7pt}{7pt}} Strongly Disagree \;
    \textcolor{custommidorangepeach}{\rule{7pt}{7pt}} Disagree \;
    \textcolor{custompeach}{\rule{7pt}{7pt}} Slightly Disagree \;
    \textcolor{customgray}{\rule{7pt}{7pt}} Neutral \;
    \textcolor{customlightblue}{\rule{7pt}{7pt}} Slightly Agree \;
    \textcolor{custommidbluelightblue}{\rule{7pt}{7pt}} Agree \;
    \textcolor{customblue}{\rule{7pt}{7pt}} Strongly Agree \\ 
    \bottomrule
\end{tabular}
\end{table*}
To avoid biasing participants towards adhering to accessibility guidelines, we did not disclose the specific purpose of the CodeA11y plugin. For the duration of the study, we renamed the assistant ``Codally'' and described it as a general-purpose chat assistant for website editing. We assumed the interface would be intuitive, similar to widely used assistants, and therefore briefed participants only on basic AI assistant usage (e.g., Copilot), deliberately withholding explanations of error pop-ups to prevent influencing their behavior before the main study tasks. However, during the course of our study, we realized that VS Code was dismissing popup boxes created by our plugin more rapidly than expected - causing some participants to miss them. \begin{highlight} After 8 participants, we switched from floating popups to modals (which prevent the IDE's auto-dismissal) due to a technical limitation. Both notification strategies do not require users to address errors, making them valid design choices. In our baseline comparison, we aggregate data from all users and include anecdotal observations of user behavior with each strategy. We acknowledge that such UI design choices may introduce variability and plan to investigate this further in future work.
\end{highlight} 
% \newcommand{\likertevala}[8][0.275]{%
% \begin{tabular}{rcl}
% \the\numexpr(#4+#2+#3)*5\relax\% &
% \resizebox{#1\textwidth}{0.78\height}{%
% \color{customdarkred}\rule{#2mm}{10pt}\color{customred}\rule{#3mm}{10pt}\color{custommidred}\rule{#4mm}{10pt}\color{customneutral}\rule{#5mm}{10pt}\color{custommidblue}\rule{#6mm}
% {10pt}\color{customblue}\rule{#7mm}{10pt}\color{customdarkblue}\rule{#8mm}{10pt}%
% } &
% \the\numexpr(#6+#7+#8)*5\relax\%\\
% \end{tabular}%
% }
% \begin{table}[]
%   \centering
%     \setlength{\tabcolsep}{2pt} % Reduce the column separation
%   \renewcommand{\arraystretch}{1.2} % Control the row height
%   \begin{tabular}{p{0.2\textwidth}p{0.365\textwidth}}
%     \toprule
%     \multicolumn{2}{l}{``I am satisfied with the code suggestions provided by'':} \\ \midrule
%     GitHub Copilot & \likertevala{1}{1}{2}{1}{8}{3}{4} \\
%     CodeA11y & \likertevala{1}{2}{0}{2}{4}{7}{4} \\
%     \midrule
%     \multicolumn{2}{l}{``I found it easy to complete the coding tasks with'':} \\ \midrule
%     GitHub Copilot & \likertevala{0}{3}{0}{1}{3}{8}{5} \\
%     CodeA11y & \likertevala{0}{2}{0}{0}{3}{8}{7} \\
%     \bottomrule
%   \end{tabular}
%   \vspace{1em}
%   \begin{tabular}{@{}>{\centering\arraybackslash}p{\textwidth}@{}}
%     \textcolor{customdarkred}{\rule{7pt}{7pt}} Strongly Disagree \;
%     \textcolor{customred}{\rule{7pt}{7pt}} Disagree \;
%     \textcolor{custommidred}{\rule{7pt}{7pt}} Slightly Disagree \;
%     \textcolor{customneutral}{\rule{7pt}{7pt}} Neutral \; \\
%     \textcolor{custommidblue}{\rule{7pt}{7pt}} Slightly Agree \;
%     \textcolor{customblue}{\rule{7pt}{7pt}} Agree \;
%     \textcolor{customdarkblue}{\rule{7pt}{7pt}} Strongly Agree \\
%   \end{tabular}
% \end{table}
\definecolor{highlightyellow}{RGB}{255, 253, 232}
\definecolor{highlightbleu}{RGB}{18, 96, 157}
\definecolor{shade2}{RGB}{0,0,120}
% Define darkish red (strongly disagree) to blue (strongly agree)
\definecolor{customdarkred}{RGB}{150, 0, 0} % Darkish Red (Strongly Disagree)
\definecolor{customred}{RGB}{210, 70, 70}   % Slightly Darker Red (Disagree)
\definecolor{custommidred}{RGB}{225, 150, 150} % Medium Red (Slightly Disagree)
\definecolor{customneutral}{RGB}{200, 200, 200} % Neutral
\definecolor{custommidblue}{RGB}{90, 180, 225}  % Medium Blue (Slightly Agree)
\definecolor{customblue}{RGB}{51, 130, 185}   % Slightly Darker Blue (Agree)
\definecolor{customdarkblue}{RGB}{12, 80, 145} % Blue (Strongly Agree)
% \begin{figure*}
% \centering
% \begin{tikzpicture}
%     \begin{axis}[
%         ybar,
%         enlarge x limits=0.175,
%         legend style={at={(0.5,-0.3)},anchor=north,legend columns=2},
%         ylabel={Accessibility Evaluation},
%         % xlabel={Task Description},
%         ylabel near ticks,
%         symbolic x coords={Button colour contrast, Form labeling, Link labeling, Adding alt-text},
%         xtick=data,
%         nodes near coords,
%         nodes near coords align={vertical},
%         ymin=0,ymax=2.35,
%         ytick={0,1,2},
%         yticklabels={Unacceptable (0), Average (1), Good (2)},
%         bar width=0.65cm,
%         style={font=\small},
%         grid=major,
%         grid style=dashed,
%         width=0.75\textwidth,
%         height=4.5cm
%     ]
%     % Data for "No Copilot"
%     \addplot[draw=black, fill=customorange
%     % pattern={north east lines},pattern color=black
%     ] coordinates {
%         (Adding alt-text, 0.1)
%         (Button colour contrast, 0.7)
%         (Form labeling, 0.5)
%         (Link labeling, 1.7)
%     };
%     % Data for "Yes Copilot"
%     \addplot[draw=black, fill=customlightblue
%     % customlightblue
%     ] coordinates {
%         (Adding alt-text, 0.7)
%         (Button colour contrast, 1.3)
%         (Form labeling, 1.5)
%         (Link labeling, 2)
%     };
%     \legend{GitHub Copilot, CodeA11y}
%     \pgfplotsset{
%         legend image code/.code={
%             \draw[draw=black] (0.75cm,-0.1cm) rectangle (1.5cm,0.1cm);
%         }
%         }
%     \node at (axis cs:Form labeling, 1.8) [xshift=0.35cm]{\huge\textbf{*}};
%     \node at (axis cs:Adding alt-text, 1) [xshift=0.35cm]{\huge\textbf{*}};
%     \node at (axis cs:Button colour contrast, 1.57) [xshift=0.35cm]{\huge\textbf{*}};
%     \end{axis}
% \end{tikzpicture}
% \caption{Mean Accessibility Evaluation Scores by Tasks and AI Assistant: Higher scores indicate that participants were successful.}
% \Description{The image shows a bar graph with mean scores for web accessibility tasks, comparing outcomes with GitHub Copilot and CodeA11y AI assistants. Scores range from 0 (Unacceptable), 1 (Average), 2 (Good). With the usage of CodeA11y, button color contrast, form labelling and adding alt texts improved with statistical significance, from 0.7 to 1.3; 0.5 to 1.5; and 0.1 to 0.7, respectively. Link labeling also improved, though not with statistical significance, from 1.7 to 2.}
% \label{sec-eval}
% \end{figure*}
\subsection{Results}
Here, we present the results of our subsequent evaluation study.

\ipstart{Accessibility Improvements}
\begin{highlight}We implemented the accessibility assessments using the same measures outlined in our formative study (Table~\ref{tab:tasks}).\end{highlight} Notably, our participants demonstrated a marked improvement in generating accessible web components and resolving accessibility issues with CodeA11y (Figure~\ref{sec-eval}). CodeA11y facilitated the automatic addition of form labels and ensured contrasting colors for button states, leading to statistically significant enhancements in accessibility outcomes. Specifically, participants performed better at adding form labels ($\mu=1.5$, $\sigma=0.85$) compared to GitHub Copilot ($\mu=0.5$, $\sigma=0.85$; $t=2.63$, $p<0.05$) and in ensuring contrasting button colors ($\mu=1.3$, $\sigma=0.67$ vs. $\mu=0.7$, $\sigma=0.82$; $t=1.78$, $p<0.05$). We also observed improvements in adding alt-texts with CodeA11y ($\mu=0.7$, $\sigma=0.95$ vs. $\mu=0.1$, $\sigma=0.32$; $t=1.9$, $p<0.05$). Though we did not find any statistical improvements in labeling links (perhaps because GitHub Copilot did a decent job at this task itself), all participants who used CodeA11y successfully completed this task ($\mu=2$, $\sigma=0$ vs. $\mu=1.7$, $\sigma=0.67$; $t=1.9$, $p=0.09$).

\ipstart{Developers' Perspectives}
Overall, participants reported no statistically significant difference in satisfaction ($\mu=5.15$, $\sigma=1.75$ vs. $\mu=4.95$, $\sigma=1.67$; $t=0.37$, $p=0.36$) and ease of use ($\mu=5.8$, $\sigma=1.47$ vs. $\mu=5.4$, $\sigma=1.67$; $t=0.8$, $p=0.21$) between CodeA11y and Github Copilot, respectively, as illustrated in Table~\ref{tab:satisfaction}.

During the post-study interviews, participants provided additional reasoning for their preferences. Most (n=16) participants \begin{highlight} did not have a specific preference between the two assistants, which is consistent with the conclusion of our statistical analysis. 
Others did indicate a preference (n=3) but provided reasoning that was based on the complexity of the task rather than assistant features, ``\textit{I liked the first assistant (CodeA11y) better, maybe because of the tasks. The second one (GitHub Copilot) required me to understand the code, and the first directly gave me the code. That’s the difference.}'' (\textbf{P18}) \end{highlight}

\begin{highlight} We asked our participants if they were introduced to any new coding practices by either of the assistants. To our surprise, only 4 participants mentioned accessibility, demonstrating CodeA11y's effectiveness in ``silently'' improving the accessibility of our participants' UI code. \end{highlight} These participants noted that they had not these considerations before. However, some mentioned either not paying attention to them or subconsciously rejecting them, as they were primarily focused on completing the tasks, which they perceived to be unrelated to accessibility:
\begin{quote}
    ``\textit{I did not find any difference (between the assistants). When I was prompting CodeA11y, it was hinting at me to use alt texts, which was not happening in Copilot. It didn’t come to me by default, so that was good ... But I don't think I implemented that.}'' (\textbf{P27})
\end{quote}

Still, they appreciated CodeA11y for emphasizing best practices for accessibility. For instance, \textbf{P27} continued: ``\textit{I did see a few of the popups, and they did mention some interesting points like you need to consider the color of the button when you add a new button because if people are color blind, they might not be able to notice it.}'' \begin{highlight} Further, \textbf{P19}, familiar with web accessibility but not proficient, realized that although he did not learn anything new about CodeA11y's color contrast suggestion, he noticed a visible difference in user experience after accepting it. Our sole participant who claimed proficiency in accessibility valued support for a specific framework:\end{highlight}
\begin{quote}
    ``\textit{I am familiar with accessibility coding practices but not in the React Native environment; I don't know if I would have needed that help in HTML, but I liked that it tried to highlight accessibility practices in React Native.}'' (\textbf{P21})
\end{quote}

\begin{figure}
\centering
\includegraphics[width=0.49\textwidth,trim=40 60 50 50,clip]{assets/sub_eval.png}
% \begin{tikzpicture}
%     \begin{axis}[
%         ybar,
%         enlarge x limits=0.175,
%         legend style={at={(0.5,-0.4)},anchor=north,legend columns=2},
%         ylabel={Accessibility Evaluation},
%         % xlabel={Task Description},
%         % xticklabel style={rotate=25, anchor=east, yshift=-5pt},
%         ylabel near ticks,
%         xticklabel style={yshift=-2.5pt},
%         % ylabel style={xshift=-10pt}
%         symbolic x coords={\shortstack{Color \\ contrast}, \shortstack{Form \\ labeling}, \shortstack{Link \\ labeling}, \shortstack{Adding \\ alt-text}},
%         % symbolic x coords={Colour contrast, Form labeling, Link labeling, Adding alt-text},
%         xtick=data,
%         nodes near coords,
%         nodes near coords align={vertical},
%         ymin=0,ymax=2.35,
%         ytick={0,1,2},
%         yticklabels={Unacceptable (0), Average (1), Good (2)},
%         bar width=0.52cm,
%         style={font=\small},
%         grid=major,
%         grid style=dashed,
%         axis line style={draw=black, line width=0.5pt},
%         width=0.4\textwidth,
%         height=4.5cm,
%         xtick align=inside,
%         ytick align=inside
%     ]
%     % Data for "No Copilot"
%     \addplot[draw=black, fill=customorange
%     % pattern={north east lines},pattern color=black
%     ] coordinates {
%         (\shortstack{Adding \\ alt-text}, 0.1)
%         (\shortstack{Color \\ contrast}, 0.7)
%         (\shortstack{Form \\ labeling}, 0.5)
%         (\shortstack{Link \\ labeling}, 1.7)
%         % (Adding alt-text, 0.500)
%         % (Colour contrast, 0.75)
%         % (Form labeling, 0.625)
%         % (Link labeling, 1.750)
%     };
%     % Data for "Yes Copilhttp://www.acm.org/ot"
%     \addplot[draw=black, fill=customlightblue] coordinates {
%         (\shortstack{Adding \\ alt-text}, 0.7)
%         (\shortstack{Color \\ contrast}, 1.3)
%         (\shortstack{Form \\ labeling}, 1.5)
%         (\shortstack{Link \\ labeling}, 2)
%         % (Adding alt-text, 0.250)
%         % (Colour contrast, 0.75)
%         % (Form labeling, 0.875)
%         % (Link labeling, 1.750)
%     };
%     \legend{GitHub Copilot, CodeA11y}
%     \pgfplotsset{
%         legend image code/.code={
%             \draw[draw=black] (0.75cm,-0.1cm) rectangle (1.5cm,0.1cm);
%         }
%         }
%     \draw [semithick] (-23, 160) -- (-23,175) -- (22,175) -- (22,160);
%     \node at (0, 180) {\huge{*}};
%     \draw [semithick] (77, 184) -- (77,199) -- (122,199) -- (122,184);
%     \node at (100, 204) {\huge{*}};
%     \draw [semithick] (277, 100) -- (277,115) -- (322,115) -- (322,100);
%     \node at (300, 120) {\huge{*}};
%     \end{axis}
% \end{tikzpicture}
\caption{Mean Accessibility Evaluation Scores by Tasks and AI Assistant: Higher scores indicate success.}
\Description{The image shows a bar graph with mean scores for web accessibility tasks, comparing outcomes with GitHub Copilot and CodeA11y AI assistants. Scores range from 0 (Unacceptable), 1 (Average), 2 (Good). With the usage of CodeA11y, button color contrast, form labelling and adding alt texts improved with statistical significance, from 0.7 to 1.3; 0.5 to 1.5; and 0.1 to 0.7, respectively. Link labeling also improved, though not with statistical significance, from 1.7 to 2.}
\label{sec-eval}
\end{figure}


\ipstart{Other Observations} 
Participants frequently made minor edits to the AI-generated code for refining the visual appearance of web components. For instance, \textbf{P18} remarked, ``\textit{CodeA11y did the job for me; I only had to change the property values.}'' However, while focusing on visual adjustments, participants occasionally removed accessibility enhancements suggested by CodeA11y. Further, many participants still overlooked the manual validation steps required for implementing more advanced accessibility features.
Participants appeared to consistently lack interest in the floating popups, so 50\% of participants using CodeA11y still added uninformative alt-texts. We observed a slightly different pattern with the modal reminders. Our participants initially paid attention to the modal interface, but then began to just close them. Although performance across the two reminder types is hard to assess objectively due to the small sample size, we observed higher means for the alt-text and form label tasks for the modal reminders. As a whole, the reminders proved somewhat effective: none of the participants using CodeA11y submitted empty alt-texts, which meant at least automated accessibility checkers would not consider the images decorative.


