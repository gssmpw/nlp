\section{Formative Findings}
\label{form_finds}
Our formative study revealed that while existing AI coding assistants can produce accessible code, developers still need accessibility expertise for effective use. Otherwise, 
% \begin{enumerate}[noitemsep, topsep=0pt]
%     \item the accessibility introduced by the assistant is likely to not be applied comprehensively,
%     \item the advanced features recommended by the assistant are unlikely to be implemented,
%     \item and the accessibility errors caused by the assistant are unlikely to be caught.
% \end{enumerate}
(1) the accessibility introduced is likely to not be applied comprehensively, (2) the advanced features recommended by the assistant are unlikely to be implemented,  (3) the accessibility errors introduced by the assistant are unlikely to be caught.

% \item accessibility is unlikely to be applied comprehensively,
%     \item advanced features recommended by the assistant are likely to not be implemented, and
%     \item accessibility errors caused by the assistant may not be caught.
\ipstart{Developer Behavior}
In the study, participants spent slightly more time on tasks without Copilot, averaging $30.84$ minutes ($\sigma = 11.95$) compared to $28.94$ minutes ($\sigma = 8.57$) with Copilot. Copilot also facilitated a greater volume of code edits ($13.28$ lines of code, $\sigma = 9.02$ vs $10.41$ lines of code, $\sigma = 5.87$), indicating that AI-assisted workflows encouraged iterative coding practices. However, even with Copilot, participants spent approximately 39.84\% of their task time ($11.91$ minutes, $\sigma = 8.00$) away from the IDE, browsing the web or checking the rendered HTML, highlighting the importance of traditional validation methods. The study also found fewer backspace key presses, an indicator of post-paste corrections, without Copilot ($\mu = 92.62$, $\sigma = 68.27$) than with the AI assistant ($\mu = 104.50$, $\sigma = 91.91$). Further, code pasting was slightly higher when participants solely browsed the web for exploration, averaging $12.68$ times ($\sigma = 8.09$), compared to $11.43$ times ($\sigma = 5.35$) with access to Copilot Chat. Participants dedicated about $7.39$\% ($2.14$ minutes, $\sigma = 1.72$) of their task time typing in the GitHub Copilot chat window, while, they also accepted Copilot's code auto-complete suggestions around $5.44$ times ($\sigma = 5.00$) on average.

\begin{table*}
\caption{The (partial) chat history revealed that directly copying Copilot's code suggestions would be incomplete, as developers overlooked the additional recommended steps.}
  \small
  \begin{tabular}{p{0.06\textwidth}p{0.89\textwidth}}
    \toprule
    \textbf{User}: & \textcolor{customorange}{``\textbf{User Query}''} \\
    \textbf{Copilot}: &  \colorbox{codebgd}{\texttt{\textbf{Generated Code}}}\\ 
    & \colorbox{codehlt}{\textbf{Associated Text Explanation}}\\
    \midrule
    \textbf{User 1}: & \textcolor{customorange}{\textbf{``I want to label the images or add relevant image descriptors''}} \\
    \textbf{Copilot:} & \colorbox{codebgd}{\texttt{alt={imgAlt} // Add this line}} \\
    & \colorbox{codehlt}{\begin{minipage}{\linewidth}
    Remember to replace imageAlt, <...> with your actual image attributes. In this example, imageAlt is the alt-text for the image, and <...>. You will need to replace these with the actual values.
  \end{minipage}}\\
    \midrule    
    \textbf{User 2}: & \textcolor{customorange}{\textbf{``Can you optimise the images on this article page for search engine optimization. Refactor the code accordingly by labeling the images or adding relevant image descriptions.''}} \\
    \textbf{Copilot:} & \colorbox{codebgd}{\texttt{imgAlt={imageDescription} // Add this line}}\\
    & \colorbox{codehlt}{\begin{minipage}{\linewidth}
    Sure, to optimize images for SEO, you can add alt attributes to your img tags. The alt attribute provides alternative information for an image if a user for some reason cannot view it (because of slow connection, an error in the src attribute, or if the user uses a screen reader).
  % \end{minipage}}\\
  %   \midrule
  %   \textbf{User 3}: & \textcolor{red}{\textit{``add alt-text to promo image''}} \\
  %   Copilot: & \colorbox{codebgd}{\texttt{imageAltText={promoImageAltText} // Add this line}}\\
  %   & \colorbox{codebgd}{\texttt{const FrostedGlassPromo = (\{ item, promoImageAltText, ...otherProps \}) => \{//..existing code..\}}}\\
  %   & \colorbox{codebgd}{\texttt{return (}}\\
  %   & \quad \colorbox{codebgd}{\texttt{<div>}} \\
  %   & \quad \quad \colorbox{codebgd}{\texttt{<img src=\{item.image\} alt=\{promoImageAltText\} />}}\\
  %   & \quad \colorbox{codebgd}{\texttt{</div>}}\\
  %   & \colorbox{codebgd}{\texttt{);}}\\
  %   & \colorbox{codehlt}{\begin{minipage}{\linewidth}
  %   Please replace item.promoImageAltText with the actual path to the alt-text in your data structure. Remember, the alt attribute value should be a meaningful description of the image content. It helps search engines understand what the image is about, and it's also used by screen readers to provide context for visually impaired users.
  \end{minipage}}
    \\
  \bottomrule
\end{tabular}
    % \vspace{-30pt}
    \label{tab:responses}
\end{table*}

\ipstart{AI Usage and Prompting Strategies}
Participants mainly used the autocomplete feature only when they had a clear mental model of the desired code structure and sought to accelerate the code typing process. In contrast, they heavily relied on the conversational interface for syntax inquiries, conceptual understanding, and the generation of code templates. We noticed that our participants wrote brief, task-oriented prompts that focused on immediate code solutions or specific interface modifications, often disregarding broader architectural considerations. Their prompting style was iterative and reactive, frequently requesting small incremental changes, fixes to previous outputs, or refinements to their vague prompts. 

Furthermore, none of the participants, including the two who were familiar with web accessibility, prompted with accessibility in mind. Instead, our participants' prompts centered around visual and functional attributes (e.g., `\textit{`add a gray background to the subscription form}'' (P4) or ``\textit{add a grey patch}'' (P1)). Consequently, the AI assistant's suggestions often failed to incorporate accessibility best practices automatically. Occasionally, our participants prompted for enhancements that indirectly aligned with accessibility requirements, and Copilot provided relevant accessibility suggestions, as shown in Table~\ref{tab:responses}. However, participants' overreliance on AI assistance often led them to assume that Copilot's code output was correct and complete. For instance, despite additional explanations from Copilot advising manual adjustments to image descriptions, participants directly pasted the code, resulting in code submissions with empty \colorbox{codebgd}{\texttt{alt}} attributes.

% \begin{figure*}
% \centering
% \begin{tikzpicture}
%     \begin{axis}[
%         ybar,
%         enlarge x limits=0.175,
%         legend style={at={(0.5,-0.2)},anchor=north,legend columns=2},
%         ylabel={Accessibility Evaluation},
%         xlabel={Task Description},
%         ylabel near ticks,
%         symbolic x coords={Button colour contrast, Form labeling, Link labeling, Adding alt-text},
%         xtick=data,
%         nodes near coords,
%         nodes near coords align={vertical},
%         ymin=0,ymax=2.25,
%         ytick={0,1,2},
%         yticklabels={Unacceptable (0), Average (1), Good (2)},
%         bar width=0.65cm,
%         style={font=\small},
%         grid=major,
%         grid style=dashed,
%         width=0.75\textwidth,
%         height=4.5cm
%     ]
%     % Data for "No Copilot"
%     \addplot[draw=black, fill=customorange
%     % pattern={north east lines},pattern color=black
%     ] coordinates {
%         (Adding alt-text, 0.500)
%         (Button colour contrast, 0.75)
%         (Form labeling, 0.625)
%         (Link labeling, 1.750)
%     };
%     % Data for "Yes Copilot"
%     \addplot[draw=black, fill=customlightblue] coordinates {
%         (Adding alt-text, 0.250)
%         (Button colour contrast, 0.75)
%         (Form labeling, 0.875)
%         (Link labeling, 1.750)
%     };
%     \legend{Without Copilot, With Copilot}
%     \pgfplotsset{
%         legend image code/.code={
%             \draw[draw=black] (0.75cm,-0.1cm) rectangle (1.5cm,0.1cm);
%         }
%         }
%     \end{axis}
% \end{tikzpicture}
% \caption{Mean Accessibility Evaluation Scores by Tasks and Copilot Usage: Higher scores indicate that participants were successful.}
% \Description{The image shows a bar graph with mean scores for web accessibility tasks, comparing outcomes with and without GitHub Copilot. Scores range from 0 (Unacceptable), 1 (Average), 2 (Good). Adding alt-text on average worsened from 0.5 to 0.25 with the usage of Copilot. Button colour contrast and link labelling remained at 0.63 and 1.75 respectively regardless of Copilot use. Form labelling improved from 0.63 to 0.88 with Copilot usage.}
% \label{manual-eval}
% \end{figure*}

\ipstart{Implications for Web Accessibility}
Our study showed mixed results of AI assistants in considering accessibility issues with no statistically significant difference between the experimental conditions, as shown in Figure~\ref{manual-eval}. Notably, Copilot could (sporadically) generate accessible components by utilizing patterns from other parts of a website. For example, it might automatically include proper labels for form fields, such as \colorbox{codebgd}{\texttt{<label for="email"> Email: </label>}} in a signup form. However, there were also instances where Copilot inadvertently introduced new accessibility issues. For example, when adding new button components with hover effects, it failed to ensure adequate contrast between the hover color and background. 

Further, the effectiveness of AI assistants was limited by the need for more sophisticated accessibility knowledge. Since our participants had limited awareness about these accessibility features, they would often ignore such suggestions by blindly accepting \colorbox{codebgd}{\texttt{alt = "" // Add your text here}} or manually deleting the \colorbox{codebgd}{\texttt{<label>}} tag. Some errors, such as providing blank alt-texts for informative images, were not even flagged by automated accessibility checkers because they interpret the image as decorative and consider this deliberate. This is particularly problematic as it implies that AI assistance might increase the risk of accessibility oversights, allowing critical errors to go unnoticed and uncorrected.


\begin{figure}
\includegraphics[width=0.49\textwidth,trim=80 65 50 30,clip]{assets/formative_eval.png}
% \centering
% \begin{tikzpicture}
%     \begin{axis}[
%         ybar,
%         enlarge x limits=0.175,
%         legend style={at={(0.5,-0.4)},anchor=north,legend columns=2},
%         ylabel={Accessibility Evaluation},
%         % xlabel={Task Description},
%         % xticklabel style={rotate=25, anchor=east, yshift=-5pt},
%         ylabel near ticks,
%         xticklabel style={yshift=-2.5pt},
%         % ylabel style={xshift=-10pt}
%         symbolic x coords={\shortstack{Color \\ contrast}, \shortstack{Form \\ labeling}, \shortstack{Link \\ labeling}, \shortstack{Adding \\ alt-text}},
%         % symbolic x coords={Colour contrast, Form labeling, Link labeling, Adding alt-text},
%         xtick=data,
%         nodes near coords,
%         nodes near coords align={vertical},
%         ymin=0,ymax=2.25,
%         ytick={0,1,2},
%         yticklabels={Unacceptable (0), Average (1), Good (2)},
%         bar width=0.52cm,
%         style={font=\small},
%         grid=major,
%         grid style=dashed,
%         axis line style={draw=black, line width=0.5pt},
%         width=0.4\textwidth,
%         height=4.5cm,
%         xtick align=inside,
%         ytick align=inside
%     ]
%     % Data for "No Copilot"
%     \addplot[draw=black, fill=customorange,
%     % pattern={north east lines},pattern color=black
%     ] coordinates {
%         (\shortstack{Adding \\ alt-text}, 0.500)
%         (\shortstack{Color \\ contrast}, 0.75)
%         (\shortstack{Form \\ labeling}, 0.625)
%         (\shortstack{Link \\ labeling}, 1.750)
%         % (Adding alt-text, 0.500)
%         % (Colour contrast, 0.75)
%         % (Form labeling, 0.625)
%         % (Link labeling, 1.750)
%     };
%     % Data for "Yes Copilot"
%     \addplot[draw=black, fill=customlightblue,] coordinates {
%         (\shortstack{Adding \\ alt-text}, 0.250)
%         (\shortstack{Color \\ contrast}, 0.75)
%         (\shortstack{Form \\ labeling}, 0.875)
%         (\shortstack{Link \\ labeling}, 1.750)
%         % (Adding alt-text, 0.250)
%         % (Colour contrast, 0.75)
%         % (Form labeling, 0.875)
%         % (Link labeling, 1.750)
%     };
%     \legend{Without Copilot, With Copilot}
%     \pgfplotsset{
%         legend image code/.code={
%             \draw[draw=black] (0.75cm,-0.1cm) rectangle (1.5cm,0.1cm);
%         }
%         }
%     \end{axis}
% \end{tikzpicture}
\caption{Mean Accessibility Evaluation Scores by Tasks and Copilot Usage: Higher scores indicate success.}
\Description{The image shows a bar graph with mean scores for web accessibility tasks, comparing outcomes with and without GitHub Copilot. Scores range from 0 (Unacceptable), 1 (Average), 2 (Good). Adding alt-text on average worsened from 0.5 to 0.25 with the usage of Copilot. Button colour contrast and link labelling remained at 0.63 and 1.75 respectively regardless of Copilot use. Form labelling improved from 0.63 to 0.88 with Copilot usage.}
\label{manual-eval}
\end{figure}
