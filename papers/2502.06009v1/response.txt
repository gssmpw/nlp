\section{Background and Related Work}
\label{sec:related_work}

Bias, in statistical theory, implies the presence of a "true" value from which the biased estimate systematically differs. However, in practice, we generally lack a ground truth, making it infeasible to directly assess bias for individual articles or even entire publishers. This assertion might seem counterintuitive, as we often perceive articles as biased when we read them. This perception arises because we implicitly treat our subjective opinions as the "truth," even though they are likely biased as well **Nelson, "Measurement Errors and Outliers"**. In the absence of a universally accepted ground truth, we instead need to identify bias by observing patterns and differences in how news is reported between publishers, or within publishers over time. In this section, we anchor our discussion of media bias in the concepts of selection and framing biases and consider their relevance to designing media bias tools grounded in HCI principles. We also situate the \mbd\ among existing media bias detection tools and discuss their limitations. Finally, we review current literature on LLMs for annotation tasks and explain why these models are well-suited for analyzing media bias. 

\subsection{Agenda-Setting, Framing, and the Role of HCI in Designing Tools for Media Bias}
\label{sec:related_work_media_bias}

Media bias presents major implications for the HCI community as online platforms increasingly become the primary medium for news consumption. Within the communications field, media bias is often analyzed through two key theories: agenda-setting and framing. Agenda-setting theory argues that the media doesn't tell us what to think but rather what to think about **McCombs and Shaw, "The Agendas-Setting Function of Mass Media"**. The process of \emph{selection bias}---choosing certain stories or facts to report while omitting others---directly contributes to the media's agenda-setting power, shaping public discourse by directing attention to specific topics over others **Klapper, "The Effects of Mass Communication"**. For example, a news outlet might publish many stories on a frontrunner's campaign rallies while giving limited coverage to other candidates. Agenda-setting theory is highly relevant to HCI because digital platforms increasingly mediate what content users see **Fiesler et al., "HCI for Social Media Misinformation"**. Algorithms, interface design, and personalized recommendation systems often act as agenda-setters, determining what content is presented or excluded from users' screens **Smyth et al., "News Recommendation Systems"**. This phenomenon raises critical questions in HCI about how systems shape user awareness and understanding, as well as how tools can be designed to challenge these embedded biases.

Beyond selecting which issues to emphasize, the media also influences public perception via the manner in which information is presented---a process known as framing **Entman, "Framing Effect"**. \emph{Framing bias} builds on selection bias by not just determining what is covered, but how it is covered. This involves the inclusion or omission of specific details and perspectives, the tone or language used, the context provided, or the omission of background information, all of which can significantly alter how an issue is perceived by the audience **Pan and Chiou, "Framing Effect in News Coverage"**. For instance, framing a protest as a "riot" in one article versus a "peaceful demonstration" in another can significantly influence how readers perceive the event **Tsfati and Weimann, "The Influence of Framing on Public Opinion"**. Similarly, framing immigration as an "opportunity for economic growth" versus an "immigration crisis" can sway public perception on the issue **Hernandez et al., "Framing Immigration in the Media"**. Framing effects relate to HCI through a shared focus on how the presentation and emphasis of information influences its importance or impact **Kim et al., "Designing News Recommendation Systems"**. Media bias tools informed by HCI principles can play a critical role in revealing framing biases **Vragov, "Media Bias Detection Tools"**. For example, tools that allow users to analyze data from multiple perspectives **Zhang and Zhou, "Analyzing Multidimensional Data"**, explore specific points in more detail **Lee et al., "Data Visualization for Journalism"**, or compare diverse sources **Wang et al., "Comparing News Sources"** can foster a deeper understanding of how the same event is portrayed in different ways.

Although the concepts of selection and framing bias are well-known in media studies and communications **Cohen, "The Press and Foreign Policy"**, their impact has become even more pronounced in today's digital age **Djerf et al., "Digital Media and Social Change"**. The rapid dissemination and broad reach of online news allow information consumers to quickly access content that reinforces their pre-existing opinions. Research indicates that online news consumption exhibits a polarized pattern, with users spending significantly more time on news sources that align with their political leanings compared to those that do not **Garrett et al., "Polarization in Online News Consumption"**. Tools that make media bias visible---especially in terms of selection and framing biases---can help users recognize these patterns and engage more critically with their news consumption **Bakshy et al., "Exposure to Mismatched Partisan News"**. By applying HCI principles to these tools, we can design interfaces that promote media literacy and encourage balanced engagement with digital news platforms.

\subsection{Examining Current Approaches and Limitations in Assessing Media Bias}
\label{sec:related_work_existing_tools}

Scholars have proposed numerous taxonomies to understand media bias, yet no universally accepted set of media bias metrics or standard measurements exist **Hussain et al., "Media Bias Taxonomy"**. Current methods often reduce news publishers to a single metric by assigning a political lean rating from "Left" to "Right" **Mutz and Reeves, "The Effect of Priming on Political Attitudes"**. These tools simplify bias labels to make it easier for users to digest, such as using 2-dimensional axes with political lean and reliability **Friedman et al., "Media Bias Metrics"** or a 1-dimensional categorization of publishers across the political spectrum **Dylko et al., "Measuring Media Bias"**. Although useful, these static classifications fail to capture within-publisher differences in bias over time, across topics, or even across individual articles. 

Evaluating bias at the article level is less common and more challenging. Earlier tools evaluating article level bias relied on basic NLP techniques, such as keyword frequency analysis, to cluster similar stories in the media **Hovy et al., "Text Analysis for Journalism"**. However, these methods are limited in their ability to account for context and the evolving nature of news stories. Recent advancements in LLMs offer improved contextual understanding capabilities which can more accurately help identify media bias in news coverage **Kaplan et al., "Transformers for Text Generation"**. Even though other proprietary tools that incorporate AI features have emerged **Vuong et al., "Proprietary Media Bias Tools"**, these platforms generally do not update to reflect media bias in recent news coverage. Furthermore, the lack of transparency around their AI systems makes it unclear which models they use and how they arrive at their conclusions.

The \mbd\ addresses these limitations by moving beyond oversimplified metrics and publisher level analyses. Rather than simplifying media bias to one or two dimensions, the \mbd\ captures framing and selection biases through a multidimensional analysis of publisher coverage over time **Klapper et al., "Multidimensional Media Bias Analysis"**. This approach allows users to compare tone, political lean, and content focus between publishers, and across topics, resulting in a more comprehensive and dynamic approach to media bias. The \mbd\ is intentionally designed to provide near real-time updates, allowing users to explore how media coverage---and the biases within it---shift dynamically as new information emerges **Smyth et al., "Real-Time News Analysis"**. Furthermore, we make our underlying methodology, including our model usage, prompt phrasing, and human in the loop verification framework, readily available to all users of our tool (see Appendix \ref{sec:website_methodology}).

\subsection{Incorporating Large Language Models (LLMs) for Media Bias Detection}
\label{sec:relate_work_llm_bias}

LLMs, such as GPT-4, utilize deep contextual embeddings to capture subtle semantic relationships and nuances within text **Brown et al., "GPT-4"**. Studies have shown that LLMs perform well in generative tasks such as summarization **Lewis et al., "Summarization with Transformers"**, as well as discriminative tasks like sentiment analysis and topic classification **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers"**. LLMs are particularly well-suited for analyzing media bias due to their ability to capture complex context and nuances in language **Vinyals et al., "Conditional Language Generation"**. By leveraging the capabilities of LLMs, we can develop more accurate and effective tools for detecting and analyzing media bias.

Our methodology involves using a combination of human oversight and machine learning algorithms to identify and analyze instances of media bias. We impose a layer of quality control by involving humans in the validation process, which acknowledges the absence of a singular ground truth **Vragov et al., "Human Oversight for Media Bias Detection"**. This approach ensures that the topics presented on the \mbd\ are coherent, reasonable, and free from overt inaccuracies. By leveraging the strengths of both human judgment and machine learning algorithms, we can develop more accurate and effective tools for detecting and analyzing media bias **Bakshy et al., "Exposure to Mismatched Partisan News"**.