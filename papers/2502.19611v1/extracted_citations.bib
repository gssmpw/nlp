@inproceedings{Blondel2022modular,
 author = {Blondel, Mathieu and Berthet, Quentin and Cuturi, Marco and Frostig, Roy and Hoyer, Stephan and Llinares-Lopez, Felipe and Pedregosa, Fabian and Vert, Jean-Philippe},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {5230--5242},
 publisher = {Curran Associates, Inc.},
 title = {Efficient and Modular Implicit Differentiation},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/228b9279ecf9bbafe582406850c57115-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@article{Bolte2023onsestepdiff,
  author       = {J{\'{e}}r{\^{o}}me Bolte and
                  Edouard Pauwels and
                  Samuel Vaiter},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {One-step differentiation of iterative algorithms},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
  url          = {http://papers.nips.cc/paper\_files/paper/2023/hash/f3716db40060004d0629d4051b2c57ab-Abstract-Conference.html},
  timestamp    = {Fri, 01 Mar 2024 16:26:21 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/BoltePV23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Fung2021JFB,
  title={JFB: Jacobian-Free Backpropagation for Implicit Networks},
  author={Samy Wu Fung and Howard Heaton and Qiuwei Li and Daniel Mckenzie and Stanley J. Osher and Wotao Yin},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:238198721}
}

@inproceedings{Grazzi2020,
  title={On the Iteration Complexity of Hypergradient Computation},
  author={Riccardo Grazzi and Luca Franceschi and Massimiliano Pontil and Saverio Salzo},
  booktitle={International Conference on Machine Learning},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:220250381}
}

@inproceedings{andrychowicz2016learningtolearn,
  author       = {Marcin Andrychowicz and
                  Misha Denil and
                  Sergio Gomez Colmenarejo and
                  Matthew W. Hoffman and
                  David Pfau and
                  Tom Schaul and
                  Nando de Freitas},
  editor       = {Daniel D. Lee and
                  Masashi Sugiyama and
                  Ulrike von Luxburg and
                  Isabelle Guyon and
                  Roman Garnett},
  title        = {Learning to learn by gradient descent by gradient descent},
  booktitle    = {Advances in Neural Information Processing Systems 29: Annual Conference
                  on Neural Information Processing Systems 2016, December 5-10, 2016,
                  Barcelona, Spain},
  pages        = {3981--3989},
  year         = {2016},
  url          = {https://proceedings.neurips.cc/paper/2016/hash/fb87582825f9d28a8d42c5e5e5e8b23d-Abstract.html},
  timestamp    = {Mon, 16 May 2022 15:41:51 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/AndrychowiczDCH16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{bengio2000gradient,
  author       = {Yoshua Bengio},
  title        = {Gradient-Based Optimization of Hyperparameters},
  journal      = {Neural Comput.},
  volume       = {12},
  number       = {8},
  pages        = {1889--1900},
  year         = {2000},
  url          = {https://doi.org/10.1162/089976600300015187},
  doi          = {10.1162/089976600300015187},
  timestamp    = {Tue, 01 Sep 2020 13:12:04 +0200},
  biburl       = {https://dblp.org/rec/journals/neco/Bengio00.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{christianson1998reverseimplicit,
author = {Christianson, Bruce},
title = {Reverse accumulation and implicit functions},
journal = {Optimization Methods and Software},
volume = {9},
number = {4},
pages = {307--322},
year = {1998},
publisher = {Taylor \& Francis},
doi = {10.1080/10556789808805697},
}

@inproceedings{curse,
 author = {Scieur, Damien and Gidel, Gauthier and Bertrand, Quentin and Pedregosa, Fabian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {17133--17145},
 publisher = {Curran Associates, Inc.},
 title = {The Curse of Unrolling: Rate of Differentiating Through Optimization},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/6d53193a098b982229340a7c3eb0ecbf-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{deepEM,
 author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 publisher = {Curran Associates, Inc.},
 title = {Deep Equilibrium Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/01386bd6d8e091c2ab4c7c7de644d37b-Paper.pdf},
 volume = {32},
 year = {2019}
}

@InProceedings{domke2012approxunrolled,
  title = 	 {Generic Methods for Optimization-Based Modeling},
  author = 	 {Domke, Justin},
  booktitle = 	 {Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {318--326},
  year = 	 {2012},
  editor = 	 {Lawrence, Neil D. and Girolami, Mark},
  volume = 	 {22},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {La Palma, Canary Islands},
  month = 	 {21--23 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v22/domke12/domke12.pdf},
  url = 	 {https://proceedings.mlr.press/v22/domke12.html},
  abstract = 	 {"Energy” models for continuous domains can be applied to many problems, but often suffer from high computational expense in training, due to the need to repeatedly minimize the energy function to high accuracy. This paper considers a modified setting, where the model is trained in terms of results after optimization is truncated to a fixed number of iterations. We derive “backpropagating” versions of gradient descent, heavy-ball and LBFGS. These are simple to use, as they require as input only routines to compute the gradient of the energy with respect to the domain and parameters. Experimental results on denoising and image labeling problems show that learning with truncated optimization greatly reduces computational expense compared to “full” fitting.}
}

@article{feurer2019hyperparameter,
  title={Hyperparameter optimization},
  author={Feurer, Matthias and Hutter, Frank},
  journal={Automated machine learning: Methods, systems, challenges},
  pages={3--33},
  year={2019},
  publisher={Springer International Publishing}
}

@article{fischer1991linsys,
title = {Automatic differentiation of the vector that solves a parametric linear system},
journal = {Journal of Computational and Applied Mathematics},
volume = {35},
number = {1},
pages = {169-184},
year = {1991},
issn = {0377-0427},
doi = {https://doi.org/10.1016/0377-0427(91)90205-X},
url = {https://www.sciencedirect.com/science/article/pii/037704279190205X},
author = {Herbert Fischer},
keywords = {Automatic differentiation, parametric linear equations},
abstract = {We consider a parametric linear system a(s)·x(s) = b(s) where a(s) is a regular matrix, b(s) is a vector, and s is a p-dimensional parameter. This equation represents an implicit definition of a function x. It is shown that automatic differentiation techniques can be used to compute derivatives of x for given parameter-value s. Especially we aim at the Jacobian matrix and the Hessian tensor of x. These quantities are of particular interest in sensitivity analysis and structural optimization.}
}

@InProceedings{franceschi2017forward,
  author         = {Luca Franceschi and Michele Donini and Paolo Frasconi and Massimiliano Pontil},
  booktitle      = {Proceedings of the 34th International Conference on Machine Learning, {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  title          = {Forward and Reverse Gradient-Based Hyperparameter Optimization},
  year           = {2017},
  editor         = {Doina Precup and Yee Whye Teh},
  pages          = {1165--1173},
  publisher      = {{PMLR}},
  series         = {Proceedings of Machine Learning Research},
  volume         = {70},
  bibsource      = {dblp computer science bibliography, https://dblp.org},
  biburl         = {https://dblp.org/rec/conf/icml/FranceschiDFP17.bib},
  file           = {:franceschi2017forward.pdf:PDF},
  qualityassured = {qualityAssured},
  timestamp      = {Wed, 15 Jun 2022 15:26:46 +0200},
  url            = {http://proceedings.mlr.press/v70/franceschi17a.html},
}

@article{gilbert1992iterative,
  title={Automatic differentiation and iterative processes},
  author={Gilbert Jean Charles},
  journal={Optimization Methods \& Software},
  year={1992},
  volume={1},
  pages={13-21},
  url={https://api.semanticscholar.org/CorpusID:120894038}
}

@InCollection{giles2008collected,
  author    = {Giles, Mike B},
  booktitle = {Advances in Automatic Differentiation},
  publisher = {Springer},
  title     = {Collected matrix derivative results for forward and reverse mode algorithmic differentiation},
  year      = {2008},
  pages     = {35--44},
  file      = {:giles2008collected.pdf:PDF},
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@Article{griewank2012invented,
  author  = {Griewank, Andreas},
  journal = {Documenta Mathematica, Extra Volume ISMP},
  title   = {Who invented the reverse mode of differentiation},
  year    = {2012},
  pages   = {389--400},
  comment = {paper on the history of automatic differentiation (autodiff)},
  file    = {:griewank2012invention.pdf:PDF},
  groups  = {Unroll vs. Implicit - Master Thesis},
}

@InProceedings{ji2021bilevel,
  author       = {Ji, Kaiyi and Yang, Junjie and Liang, Yingbin},
  booktitle    = {International conference on machine learning},
  title        = {Bilevel optimization: Convergence analysis and enhanced design},
  year         = {2021},
  organization = {PMLR},
  pages        = {4882--4892},
  file         = {:ji2021bilevel.pdf:PDF},
  groups       = {Unroll vs. Implicit - Master Thesis},
}

@InProceedings{lorraine2020optimizing,
  author       = {Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},
  booktitle    = {International Conference on Artificial Intelligence and Statistics},
  title        = {Optimizing millions of hyperparameters by implicit differentiation},
  year         = {2020},
  organization = {PMLR},
  pages        = {1540--1552},
  file         = {:lorraine2019optimizing.pdf:PDF},
}

@InProceedings{maclaurin2015gradient,
  author       = {Maclaurin, Dougal and Duvenaud, David and Adams, Ryan},
  booktitle    = {International conference on machine learning},
  title        = {Gradient-based hyperparameter optimization through reversible learning},
  year         = {2015},
  organization = {PMLR},
  pages        = {2113--2122},
  file         = {:maclaurin2015gradient-based.pdf:PDF},
}

@InProceedings{pedregosa2016,
  title = 	 {Hyperparameter optimization with approximate gradient},
  author = 	 {Pedregosa, Fabian},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {737--746},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/pedregosa16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/pedregosa16.html},
}

@inproceedings{phantom_gradient,
 author = {Geng, Zhengyang and Zhang, Xin-Yu and Bai, Shaojie and Wang, Yisen and Lin, Zhouchen},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {24247--24260},
 publisher = {Curran Associates, Inc.},
 title = {On Training Implicit Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/cb8da6767461f2812ae4290eac7cbc42-Paper.pdf},
 volume = {34},
 year = {2021}
}

@InProceedings{shaban2019truncated,
  author       = {Shaban, Amirreza and Cheng, Ching-An and Hatch, Nathan and Boots, Byron},
  booktitle    = {The 22nd International Conference on Artificial Intelligence and Statistics},
  title        = {Truncated back-propagation for bilevel optimization},
  year         = {2019},
  organization = {PMLR},
  pages        = {1723--1732},
  file         = {:shaban2019truncated-backprop.pdf:PDF},
  groups       = {Unroll vs. Implicit - Master Thesis},
}

@book{thuerey2021pbdl,
  title={Physics-based Deep Learning},
  author={Nils Thuerey and Philipp Holl and Maximilian Mueller and Patrick Schnell and Felix Trost and Kiwon Um},
  url={https://physicsbaseddeeplearning.org},
  year={2021},
  publisher={WWW}
}

