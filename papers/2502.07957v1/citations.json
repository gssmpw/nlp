[
  {
    "index": 0,
    "papers": [
      {
        "key": "Caliskan2017SemanticsBiases",
        "author": "Caliskan, Aylin and Bryson, Joanna J and Narayanan, Arvind",
        "title": "{Semantics derived automatically from language corpora contain human-like biases}"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "greenwald1998measuring",
        "author": "Greenwald, Anthony G and McGhee, Debbie E and Schwartz, Jordan LK",
        "title": "Measuring individual differences in implicit cognition: the implicit association test."
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "Guo2021DetectingBiases",
        "author": "Guo, Wei and Caliskan, Aylin",
        "title": "{Detecting Emergent Intersectional Biases: Contextualized Word Embeddings Contain a Distribution of Human-like Biases}"
      },
      {
        "key": "May2019OnEncoders",
        "author": "May, Chandler and Wang, Alex and Bordia, Shikha and Bowman, Samuel R. and Rudinger, Rachel",
        "title": "{On Measuring Social Biases in Sentence Encoders}"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "May2019OnEncoders",
        "author": "May, Chandler and Wang, Alex and Bordia, Shikha and Bowman, Samuel R. and Rudinger, Rachel",
        "title": "{On Measuring Social Biases in Sentence Encoders}"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "Steed2021",
        "author": "Steed, Ryan and Caliskan, Aylin",
        "title": "{Image Representations Learned With Unsupervised Pre-Training Contain Human-like Biases}"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "Caliskan2017SemanticsBiases",
        "author": "Caliskan, Aylin and Bryson, Joanna J and Narayanan, Arvind",
        "title": "{Semantics derived automatically from language corpora contain human-like biases}"
      },
      {
        "key": "Steed2021",
        "author": "Steed, Ryan and Caliskan, Aylin",
        "title": "{Image Representations Learned With Unsupervised Pre-Training Contain Human-like Biases}"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "Radford2021LearningSupervision",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya",
        "title": "{Learning Transferable Visual Models From Natural Language Supervision}"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "Radford2018ImprovingPre-Training",
        "author": "Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya",
        "title": "{Improving Language Understanding by Generative Pre-Training}"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "cabello-etal-2023-evaluating",
        "author": "Cabello, Laura  and\nBugliarello, Emanuele  and\nBrandl, Stephanie  and\nElliott, Desmond",
        "title": "Evaluating Bias and Fairness in Gender-Neutral Pretrained Vision-and-Language Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "tan-bansal-2019-lxmert",
        "author": "Tan, Hao  and\nBansal, Mohit",
        "title": "{LXMERT}: Learning Cross-Modality Encoder Representations from Transformers"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "Janghorbani2023Multi-ModalModels",
        "author": "Janghorbani, Sepehr and De Melo, Gerard",
        "title": "{Multi-Modal Bias: Introducing a Framework for Stereotypical Bias Assessment beyond Gender and Race in Vision\u2013Language Models}"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "Wolfe2022MarkednessAI",
        "author": "Wolfe, Robert and Caliskan, Aylin",
        "title": "{Markedness in Visual Semantic AI}"
      },
      {
        "key": "Wolfe2022EvidenceAI",
        "author": "Wolfe, Robert and Banaji, Mahzarin R and Caliskan, Aylin",
        "title": "{Evidence for Hypodescent in Visual Semantic AI}"
      },
      {
        "key": "Wolfe2022AmericanAI",
        "author": "Wolfe, Robert and Caliskan, Aylin",
        "title": "{American == White in Multimodal Language-and-Image AI}"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "Wolfe2023ContrastiveBias",
        "author": "Wolfe, Robert and Yang, Yiwei and Howe, Bill and Caliskan, Aylin",
        "title": "{Contrastive Language-Vision AI Models Pretrained on Web-Scraped Multimodal Data Exhibit Sexual Objectification Bias}"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "Berg2022ALearning",
        "author": "Berg, Hugo and Hall, Siobhan and Bhalgat, Yash and Kirk, Hannah and Shtedritski, Aleksandar and Bain, Max",
        "title": "{A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models with Adversarial Learning}"
      }
    ]
  }
]