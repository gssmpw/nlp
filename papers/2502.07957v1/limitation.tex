\section{Limitations}

Further empirical studies are needed to compare a broader range of datasets and model configurations to provide a more robust statistical basis for our observations. Our analysis focuses on specific dataset families, model architectures, and parameter sizes, but an in-depth examination of dataset composition could offer more insights into mitigating biases effectively. Additionally, there is room for improvement in the measurements of bias using EATs. The stimuli we used are grounded in existing theories, but further controlling the stimuli, such as examining the frequency of stimuli composition \citep{wilson2024gender, wolfe2021low}, could provide a more nuanced understanding of factors that impact bias effect size measures.

Additionally, we only considered monolingual English-based analyses of vision-language models, while with training datasets are curated using multilingual and multicultural sources such as `webli' \cite{chen2022pali} and culture-specific biases present in those sources could also be inherited \cite{ruggeri2023multi}. While our findings are expected to generalize broadly, extending the study to multilingual settings could yield valuable insights. Additionally, focusing primarily on well-established EATs like race, gender, and age leaves out a broader set of possible biases that could be explored in future work, such as those related to socio-economic status or intersectional identities. Limiting the scope of the analysis to these particular biases may risk oversimplifying the complex interrelationships of factors contributing to biased outcomes in VLMs.
