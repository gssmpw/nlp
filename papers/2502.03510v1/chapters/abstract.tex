\addcontentsline{toc}{chapter}{Abstract}
Light Detection and Ranging (LiDAR) sensors are crucial for autonomous systems, yet the advancements and applications of LiDAR fiducial markers (LFMs) remain limited compared to the widespread use of visual fiducial markers (VFMs) in camera-based applications. Bridging this technological gap is of great significance for robotics and computer vision applications, but challenging due to the unstructured, sparse nature of 3D LiDAR point clouds and the 2D-specific design of previous fiducial marker algorithms. In this dissertation, a novel framework for mapping and localization using LFMs is proposed to benefit a variety of real-world applications, including the collection of 3D assets and training data for point cloud registration, 3D map merging, Augmented Reality (AR), and many more. In particular, this dissertation investigates the development of LFM and the utilization of LFM in mapping and localization from the following three aspects.
\par
First, in response to the absence of an LFM system as convenient and reliable as VFMs, an Intensity Image-based LiDAR Fiducial Marker (IFM) system is developed. The markers are thin, letter-sized sheets of paper or board with patterns compatible with popular VFM systems, without affecting the 3D geometry of the environment. A marker detection method is introduced that locates the 3D fiducials in the point cloud through the intensity image. Then, an algorithm is presented that uses the detected 3D fiducials to estimate the LiDAR 6-degree-of-freedom (6-DOF) pose.
\par
Second, to tackle the limitations of the vanilla IFM method, an improved algorithm for detecting LFMs is proposed. This enhancement extends marker detection from the single-view point cloud to the 3D map and increases the detectable distance of markers, thereby making downstream tasks such as 3D map merging feasible. In particular, a new pipeline is designed to analyze a 3D point cloud from both intensity and geometry perspectives. This approach differs from conventional 3D object detection methods, which rely solely on 3D geometric features and can only detect spatially distinguishable objects.

\par
Third, a novel approach for mapping and localization using LFMs is developed. It processes unordered, low-overlap point clouds by registering them into a single point cloud for mapping and determining their relative poses for localization. Initially, an improved adaptive threshold marker detection method is developed to provide robust detection results when viewpoints among point clouds change dramatically. Subsequently, a maximum a-posteriori (MAP) problem is formulated for registering the multiview point clouds, with a two-level graph framework developed to address it. The first-level graph, constructed as a weighted graph, is designed to efficiently and optimally infer initial values of point cloud poses from the unordered set. The second-level graph is constructed as a factor graph for the global optimization of point cloud poses, marker poses, and marker corner positions. In addition, a new dataset named Livox-3DMatch is collected using the proposed approach and incorporated into the training of the state-of-the-art learning-based multiview point cloud registration methods, resulting in evident improvements across various benchmarks.
\par
Extensive experiments with various LiDAR models in diverse indoor and outdoor scenes demonstrate the effectiveness and superiority of the proposed framework. The framework serves as an efficient, low-cost, and reliable tool for robotics and computer vision applications, including AR, 3D asset and training data collection, degraded scene reconstruction, Global Positioning System (GPS)-denied localization, and 3D map merging.

% Thorough experiments with various models of LiDAR sensors in diverse indoor and outdoor scenes demonstrate the effectiveness and superiority of the proposed methods. Overall, the proposed framework serves as an efficient, low-cost, and reliable fundamental tool for a variety of robotics and computer vision applications, including augmented reality, 3D asset collection, training data collection, reconstruction of degraded scenes, localization in Global Positioning System (GPS)-denied environments, and 3D map merging.
