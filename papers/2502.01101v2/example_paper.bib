@inproceedings{li2024generative,
  title={Generative image dynamics},
  author={Li, Zhengqi and Tucker, Richard and Snavely, Noah and Holynski, Aleksander},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24142--24153},
  year={2024}
}

@inproceedings{huang2024vbench,
  title={Vbench: Comprehensive benchmark suite for video generative models},
  author={Huang, Ziqi and He, Yinan and Yu, Jiashuo and Zhang, Fan and Si, Chenyang and Jiang, Yuming and Zhang, Yuanhan and Wu, Tianxing and Jin, Qingyang and Chanpaisit, Nattapol and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21807--21818},
  year={2024}
}

@inproceedings{liang2024rich,
  title={Rich human feedback for text-to-image generation},
  author={Liang, Youwei and He, Junfeng and Li, Gang and Li, Peizhao and Klimovskiy, Arseniy and Carolan, Nicholas and Sun, Jiao and Pont-Tuset, Jordi and Young, Sarah and Yang, Feng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19401--19411},
  year={2024}
}

@inproceedings{hollein2024viewdiff,
  title={Viewdiff: 3d-consistent image generation with text-to-image models},
  author={H{\"o}llein, Lukas and Bo{\v{z}}i{\v{c}}, Alja{\v{z}} and M{\"u}ller, Norman and Novotny, David and Tseng, Hung-Yu and Richardt, Christian and Zollh{\"o}fer, Michael and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5043--5052},
  year={2024}
}

@inproceedings{ding2024freecustom,
  title={FreeCustom: Tuning-Free Customized Image Generation for Multi-Concept Composition},
  author={Ding, Ganggui and Zhao, Canyu and Wang, Wen and Yang, Zhen and Liu, Zide and Chen, Hao and Shen, Chunhua},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9089--9098},
  year={2024}
}

@inproceedings{zhang2024pia,
  title={Pia: Your personalized image animator via plug-and-play modules in text-to-image models},
  author={Zhang, Yiming and Xing, Zhening and Zeng, Yanhong and Fang, Youqing and Chen, Kai},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7747--7756},
  year={2024}
}

@inproceedings{xing2024simda,
  title={Simda: Simple diffusion adapter for efficient video generation},
  author={Xing, Zhen and Dai, Qi and Hu, Han and Wu, Zuxuan and Jiang, Yu-Gang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7827--7839},
  year={2024}
}

@article{wu2023lamp,
  title={Lamp: Learn a motion pattern for few-shot-based video generation},
  author={Wu, Ruiqi and Chen, Liangyu and Yang, Tong and Guo, Chunle and Li, Chongyi and Zhang, Xiangyu},
  journal={arXiv preprint arXiv:2310.10769},
  year={2023}
}

@inproceedings{li2024vidtome,
  title={Vidtome: Video token merging for zero-shot video editing},
  author={Li, Xirui and Ma, Chao and Yang, Xiaokang and Yang, Ming-Hsuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7486--7495},
  year={2024}
}

@inproceedings{shi2024bivdiff,
  title={BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models},
  author={Shi, Fengyuan and Gu, Jiaxi and Xu, Hang and Xu, Songcen and Zhang, Wei and Wang, Limin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7393--7402},
  year={2024}
}

@inproceedings{qing2024hierarchical,
  title={Hierarchical spatio-temporal decoupling for text-to-video generation},
  author={Qing, Zhiwu and Zhang, Shiwei and Wang, Jiayu and Wang, Xiang and Wei, Yujie and Zhang, Yingya and Gao, Changxin and Sang, Nong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6635--6645},
  year={2024}
}

@inproceedings{yuan2024instructvideo,
  title={InstructVideo: instructing video diffusion models with human feedback},
  author={Yuan, Hangjie and Zhang, Shiwei and Wang, Xiang and Wei, Yujie and Feng, Tao and Pan, Yining and Zhang, Yingya and Liu, Ziwei and Albanie, Samuel and Ni, Dong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6463--6474},
  year={2024}
}

@article{chen2023control,
  title={Control-a-video: Controllable text-to-video generation with diffusion models},
  author={Chen, Weifeng and Ji, Yatai and Wu, Jie and Wu, Hefeng and Xie, Pan and Li, Jiashi and Xia, Xin and Xiao, Xuefeng and Lin, Liang},
  journal={arXiv preprint arXiv:2305.13840},
  year={2023}
}

@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3836--3847},
  year={2023}
}

@article{ye2023ip,
  title={Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models},
  author={Ye, Hu and Zhang, Jun and Liu, Sibo and Han, Xiao and Yang, Wei},
  journal={arXiv preprint arXiv:2308.06721},
  year={2023}
}

@inproceedings{mou2024t2i,
  title={T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models},
  author={Mou, Chong and Wang, Xintao and Xie, Liangbin and Wu, Yanze and Zhang, Jian and Qi, Zhongang and Shan, Ying},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={4296--4304},
  year={2024}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@inproceedings{voynov2023sketch,
  title={Sketch-guided text-to-image diffusion models},
  author={Voynov, Andrey and Aberman, Kfir and Cohen-Or, Daniel},
  booktitle={ACM SIGGRAPH 2023 Conference Proceedings},
  pages={1--11},
  year={2023}
}

@inproceedings{koley2024s,
  title={It's All About Your Sketch: Democratising Sketch Control in Diffusion Models},
  author={Koley, Subhadeep and Bhunia, Ayan Kumar and Sekhri, Deeptanshu and Sain, Aneeshan and Chowdhury, Pinaki Nath and Xiang, Tao and Song, Yi-Zhe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7204--7214},
  year={2024}
}

@inproceedings{gal2024breathing,
  title={Breathing Life Into Sketches Using Text-to-Video Priors},
  author={Gal, Rinon and Vinker, Yael and Alaluf, Yuval and Bermano, Amit and Cohen-Or, Daniel and Shamir, Ariel and Chechik, Gal},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4325--4336},
  year={2024}
}

@article{bandyopadhyay2024flipsketch,
  title={FlipSketch: Flipping Static Drawings to Text-Guided Sketch Animations},
  author={Bandyopadhyay, Hmrishav and Song, Yi-Zhe},
  journal={arXiv preprint arXiv:2411.10818},
  year={2024}
}

@article{zhang2024sketch,
  title={Sketch-Guided Scene Image Generation},
  author={Zhang, Tianyu and Xie, Xiaoxuan and Du, Xusheng and Xie, Haoran},
  journal={arXiv preprint arXiv:2407.06469},
  year={2024}
}

@inproceedings{chen2024democaricature,
  title={Democaricature: Democratising caricature generation with a rough sketch},
  author={Chen, Dar-Yen and Bhunia, Ayan Kumar and Koley, Subhadeep and Sain, Aneeshan and Chowdhury, Pinaki Nath and Song, Yi-Zhe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8629--8639},
  year={2024}
}

@inproceedings{liu2024video,
  title={Video-p2p: Video editing with cross-attention control},
  author={Liu, Shaoteng and Zhang, Yuechen and Li, Wenbo and Lin, Zhe and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8599--8608},
  year={2024}
}

@inproceedings{feng2024ccedit,
  title={Ccedit: Creative and controllable video editing via diffusion models},
  author={Feng, Ruoyu and Weng, Wenming and Wang, Yanhui and Yuan, Yuhui and Bao, Jianmin and Luo, Chong and Chen, Zhibo and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6712--6722},
  year={2024}
}

@inproceedings{yang2022finding,
  title={Finding badly drawn bunnies},
  author={Yang, Lan and Pang, Kaiyue and Zhang, Honggang and Song, Yi-Zhe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7482--7491},
  year={2022}
}

@article{wang2023crossformer++,
  title={Crossformer++: A versatile vision transformer hinging on cross-scale attention},
  author={Wang, Wenxiao and Chen, Wei and Qiu, Qibo and Chen, Long and Wu, Boxi and Lin, Binbin and He, Xiaofei and Liu, Wei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{wang2004image,
  title={Image quality assessment: from error visibility to structural similarity},
  author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal={IEEE transactions on image processing},
  volume={13},
  number={4},
  pages={600--612},
  year={2004},
  publisher={IEEE}
}

@article{unterthiner2019fvd,
  title={FVD: A new metric for video generation},
  author={Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Rapha{\"e}l and Michalski, Marcin and Gelly, Sylvain},
  year={2019}
}

@inproceedings{tulyakov2018mocogan,
  title={Mocogan: Decomposing motion and content for video generation},
  author={Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1526--1535},
  year={2018}
}

@article{hao2022spatiotemporal,
  title={Spatiotemporal consistency-enhanced network for video anomaly detection},
  author={Hao, Yi and Li, Jie and Wang, Nannan and Wang, Xiaoyu and Gao, Xinbo},
  journal={Pattern Recognition},
  volume={121},
  pages={108232},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{menapace2024snap,
  title={Snap video: Scaled spatiotemporal transformers for text-to-video synthesis},
  author={Menapace, Willi and Siarohin, Aliaksandr and Skorokhodov, Ivan and Deyneka, Ekaterina and Chen, Tsai-Shien and Kag, Anil and Fang, Yuwei and Stoliar, Aleksei and Ricci, Elisa and Ren, Jian and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7038--7048},
  year={2024}
}

@article{guo2023animatediff,
  title={Animatediff: Animate your personalized text-to-image diffusion models without specific tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint arXiv:2307.04725},
  year={2023}
}

@article{yan2023motion,
  title={Motion-conditioned image animation for video editing},
  author={Yan, Wilson and Brown, Andrew and Abbeel, Pieter and Girdhar, Rohit and Azadi, Samaneh},
  journal={arXiv preprint arXiv:2311.18827},
  year={2023}
}

@inproceedings{gao2024fact,
  title={Fact: Teaching mllms with faithful, concise and transferable rationales},
  author={Gao, Minghe and Chen, Shuang and Pang, Liang and Yao, Yuan and Dang, Jisheng and Zhang, Wenqiao and Li, Juncheng and Tang, Siliang and Zhuang, Yueting and Chua, Tat-Seng},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={846--855},
  year={2024}
}

@article{ku2024anyv2v,
  title={Anyv2v: A plug-and-play framework for any video-to-video editing tasks},
  author={Ku, Max and Wei, Cong and Ren, Weiming and Yang, Huan and Chen, Wenhu},
  journal={arXiv preprint arXiv:2403.14468},
  year={2024}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@book{haralock1991computer,
  title={Computer and robot vision},
  author={Haralock, Robert M and Shapiro, Linda G},
  year={1991},
  publisher={Addison-Wesley Longman Publishing Co., Inc.}
}

@article{suzuki1985topological,
  title={Topological structural analysis of digitized binary images by border following},
  author={Suzuki, Satoshi and others},
  journal={Computer vision, graphics, and image processing},
  volume={30},
  number={1},
  pages={32--46},
  year={1985},
  publisher={Elsevier}
}

@article{lee2017shoelace,
  title={Shoelace formula: Connecting the area of a polygon and the vector cross product},
  author={Lee, Younhee and Lim, Woong},
  journal={The Mathematics Teacher},
  volume={110},
  number={8},
  pages={631--636},
  year={2017},
  publisher={National Council of Teachers of Mathematics}
}

@article{haralick1973textural,
  title={Textural features for image classification},
  author={Haralick, Robert M and Shanmugam, Karthikeyan and Dinstein, Its' Hak},
  journal={IEEE Transactions on systems, man, and cybernetics},
  number={6},
  pages={610--621},
  year={1973},
  publisher={IEEE}
}
