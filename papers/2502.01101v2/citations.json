[
  {
    "index": 0,
    "papers": [
      {
        "key": "shi2024bivdiff",
        "author": "Shi, Fengyuan and Gu, Jiaxi and Xu, Hang and Xu, Songcen and Zhang, Wei and Wang, Limin",
        "title": "BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis via Bridging Image and Video Diffusion Models"
      },
      {
        "key": "qing2024hierarchical",
        "author": "Qing, Zhiwu and Zhang, Shiwei and Wang, Jiayu and Wang, Xiang and Wei, Yujie and Zhang, Yingya and Gao, Changxin and Sang, Nong",
        "title": "Hierarchical spatio-temporal decoupling for text-to-video generation"
      },
      {
        "key": "yuan2024instructvideo",
        "author": "Yuan, Hangjie and Zhang, Shiwei and Wang, Xiang and Wei, Yujie and Feng, Tao and Pan, Yining and Zhang, Yingya and Liu, Ziwei and Albanie, Samuel and Ni, Dong",
        "title": "InstructVideo: instructing video diffusion models with human feedback"
      },
      {
        "key": "chen2023control",
        "author": "Chen, Weifeng and Ji, Yatai and Wu, Jie and Wu, Hefeng and Xie, Pan and Li, Jiashi and Xia, Xin and Xiao, Xuefeng and Lin, Liang",
        "title": "Control-a-video: Controllable text-to-video generation with diffusion models"
      },
      {
        "key": "guo2023animatediff",
        "author": "Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo",
        "title": "Animatediff: Animate your personalized text-to-image diffusion models without specific tuning"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "li2024generative",
        "author": "Li, Zhengqi and Tucker, Richard and Snavely, Noah and Holynski, Aleksander",
        "title": "Generative image dynamics"
      },
      {
        "key": "liang2024rich",
        "author": "Liang, Youwei and He, Junfeng and Li, Gang and Li, Peizhao and Klimovskiy, Arseniy and Carolan, Nicholas and Sun, Jiao and Pont-Tuset, Jordi and Young, Sarah and Yang, Feng and others",
        "title": "Rich human feedback for text-to-image generation"
      },
      {
        "key": "hollein2024viewdiff",
        "author": "H{\\\"o}llein, Lukas and Bo{\\v{z}}i{\\v{c}}, Alja{\\v{z}} and M{\\\"u}ller, Norman and Novotny, David and Tseng, Hung-Yu and Richardt, Christian and Zollh{\\\"o}fer, Michael and Nie{\\ss}ner, Matthias",
        "title": "Viewdiff: 3d-consistent image generation with text-to-image models"
      },
      {
        "key": "ding2024freecustom",
        "author": "Ding, Ganggui and Zhao, Canyu and Wang, Wen and Yang, Zhen and Liu, Zide and Chen, Hao and Shen, Chunhua",
        "title": "FreeCustom: Tuning-Free Customized Image Generation for Multi-Concept Composition"
      },
      {
        "key": "zhang2024pia",
        "author": "Zhang, Yiming and Xing, Zhening and Zeng, Yanhong and Fang, Youqing and Chen, Kai",
        "title": "Pia: Your personalized image animator via plug-and-play modules in text-to-image models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "xing2024simda",
        "author": "Xing, Zhen and Dai, Qi and Hu, Han and Wu, Zuxuan and Jiang, Yu-Gang",
        "title": "Simda: Simple diffusion adapter for efficient video generation"
      },
      {
        "key": "wu2023lamp",
        "author": "Wu, Ruiqi and Chen, Liangyu and Yang, Tong and Guo, Chunle and Li, Chongyi and Zhang, Xiangyu",
        "title": "Lamp: Learn a motion pattern for few-shot-based video generation"
      },
      {
        "key": "li2024vidtome",
        "author": "Li, Xirui and Ma, Chao and Yang, Xiaokang and Yang, Ming-Hsuan",
        "title": "Vidtome: Video token merging for zero-shot video editing"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "mou2024t2i",
        "author": "Mou, Chong and Wang, Xintao and Xie, Liangbin and Wu, Yanze and Zhang, Jian and Qi, Zhongang and Shan, Ying",
        "title": "T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "chen2023control",
        "author": "Chen, Weifeng and Ji, Yatai and Wu, Jie and Wu, Hefeng and Xie, Pan and Li, Jiashi and Xia, Xin and Xiao, Xuefeng and Lin, Liang",
        "title": "Control-a-video: Controllable text-to-video generation with diffusion models"
      },
      {
        "key": "ye2023ip",
        "author": "Ye, Hu and Zhang, Jun and Liu, Sibo and Han, Xiao and Yang, Wei",
        "title": "Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "voynov2023sketch",
        "author": "Voynov, Andrey and Aberman, Kfir and Cohen-Or, Daniel",
        "title": "Sketch-guided text-to-image diffusion models"
      },
      {
        "key": "koley2024s",
        "author": "Koley, Subhadeep and Bhunia, Ayan Kumar and Sekhri, Deeptanshu and Sain, Aneeshan and Chowdhury, Pinaki Nath and Xiang, Tao and Song, Yi-Zhe",
        "title": "It's All About Your Sketch: Democratising Sketch Control in Diffusion Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "gal2024breathing",
        "author": "Gal, Rinon and Vinker, Yael and Alaluf, Yuval and Bermano, Amit and Cohen-Or, Daniel and Shamir, Ariel and Chechik, Gal",
        "title": "Breathing Life Into Sketches Using Text-to-Video Priors"
      },
      {
        "key": "bandyopadhyay2024flipsketch",
        "author": "Bandyopadhyay, Hmrishav and Song, Yi-Zhe",
        "title": "FlipSketch: Flipping Static Drawings to Text-Guided Sketch Animations"
      }
    ]
  }
]