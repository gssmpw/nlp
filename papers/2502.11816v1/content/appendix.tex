\section{Hyperparameters}
\subsection{\model{}}\label{app:model}
\begin{itemize}
    \item We tune the dimension of the aggregated channels $D$ from the set $\{64,128,256 \}$
    \item The range for $D_\text{out}$ is $\{32,64,128\}$
    \item We allow the number of mixer blocks to be   $\{1,2,3\}$
\end{itemize}

\subsection{GraFITi}\label{app:graf}
We use the hyperparameter ranges as given by \citeauthor{Yalavarthi2023.Forecasting}:
\begin{itemize}
    \item We tune the number of layers from $\{1,2,3,4\}$
    \item The attention mechanism can use a number of heads from the set of $\{1,2,4\}$
    \item The latent dimension is sampled from $\{16,32,64,128,256\}$
\end{itemize}

\subsection{tPatchGNN}\label{app:tpatch}
The hyperparameters reported from \citeauthor{Zhang.Irregular} are highlighted in \textbf{bold}.
As authors used different hyperparameters for each dataset most hyperparameters have multiple options marked in bold. 
We refer to original paper for additional details~\cite{Zhang.Irregular}
\begin{itemize}
    \item The hidden dimension is selected from $\{\textbf{32},\textbf{64},128\}$
    \item The time embedding dimension is taken from  $\{5,\textbf{10},20\}$
    \item The patch size
    \begin{itemize}
        \item is sampled from $\{\textbf{2},4,\textbf{8}\}$ for PhysioNet, MIMIC, USHCN
        \item is sampled from $\{100,\textbf{300},750\}$ for Activity
    \end{itemize} 
\end{itemize}