%%%%%%%%%%%%% YOLOPoint %%%%%%%%%%%%%%%%

@InProceedings{bib:superpoint,
  author    = {Daniel DeTone and Tomasz Malisiewicz and Andrew Rabinovich},
  booktitle = {IEEE_C_CVPRW},
  title     = {{SuperPoint: Self-Supervised Interest Point Detection and Description}},
  url       = {http://arxiv.org/abs/1712.07629},
  year      = {2018},
}

@Article{bib:orb,
  author     = {Raul Mur{-}Artal and J. M. M. Montiel and Juan D. Tard{\'{o}}s},
  title      = {{ORB-SLAM: a Versatile and Accurate Monocular SLAM System}},
  eprint     = {1502.00956},
  eprinttype = {arXiv},
  url        = {http://arxiv.org/abs/1502.00956},
  volume     = {abs/1502.00956},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/journals/corr/Mur-ArtalMT15.bib},
  journal    = {CoRR},
  timestamp  = {Mon, 13 Aug 2018 16:47:39 +0200},
  year       = {2015},
}

@InProceedings{bib:surf,
  author    = {Bay, Herbert and Tuytelaars, Tinne and Van Gool, Luc},
  booktitle = C_ECCV,
  title     = {{SURF: Speeded Up Robust Features}},
  editor    = {Leonardis, Ale{\v{s}} and Bischof, Horst and Pinz, Axel},
  isbn      = {978-3-540-33833-8},
  pages     = {404--417},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.},
  address   = {Berlin, Heidelberg},
  year      = {2006},
}

@InProceedings{bib:fast,
  author    = {Rosten, Edward and Drummond, Tom},
  booktitle = {Computer Vision -- ECCV 2006},
  title     = {{Machine Learning for High-Speed Corner Detection}},
  editor    = {Leonardis, Ale{\v{s}} and Bischof, Horst and Pinz, Axel},
  isbn      = {978-3-540-33833-8},
  pages     = {430--443},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Where feature points are used in real-time frame-rate applications, a high-speed feature detector is necessary. Feature detectors such as SIFT (DoG), Harris and SUSAN are good methods which yield high quality features, however they are too computationally intensive for use in real-time applications of any complexity. Here we show that machine learning can be used to derive a feature detector which can fully process live PAL video using less than 7{\%} of the available processing time. By comparison neither the Harris detector (120{\%}) nor the detection stage of SIFT (300{\%}) can operate at full frame rate.},
  address   = {Berlin, Heidelberg},
  year      = {2006},
}

@InProceedings{bib:sift,
  author    = {Lowe, D.G.},
  booktitle = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
  title     = {{Object recognition from local scale-invariant features}},
  doi       = {10.1109/ICCV.1999.790410},
  pages     = {1150-1157 vol.2},
  volume    = {2},
  year      = {1999},
}

@Misc{bib:yolov5,
  author  = {Glenn Jocher},
  title   = {{YOLOv5 by Ultralytics}},
  doi     = {10.5281/zenodo.7347926},
  note    = {v7.0},
  url     = {https://github.com/ultralytics/yolov5},
  license = {GPL-3.0},
  year    = {2020},
}

@InProceedings{bib:hog,
  author    = {Dalal, N. and Triggs, B.},
  booktitle = IEEE_C_CVPR,
  title     = {{Histograms of oriented gradients for human detection}},
  doi       = {10.1109/CVPR.2005.177},
  pages     = {886-893 vol. 1},
  volume    = {1},
  year      = {2005},
}

@InProceedings{bib:cspdarknet,
  author    = {Wang, Chien-Yao and Mark Liao, Hong-Yuan and Wu, Yueh-Hua and Chen, Ping-Yang and Hsieh, Jun-Wei and Yeh, I-Hau},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  title     = {{CSPNet: A new backbone that can enhance learning capability of cnn}},
  pages     = {390--391},
  year      = {2020},
}

@Misc{bib:vgg,
  author    = {Simonyan, Karen and Zisserman, Andrew},
  title     = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
  doi       = {10.48550/ARXIV.1409.1556},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  publisher = {arXiv},
  year      = {2014},
}

@InProceedings{bib:deepfepe,
  author    = {Y. -Y. {Jau} and R. {Zhu} and H. {Su} and M. {Chandraker}},
  booktitle = IEEE_C_IROS,
  title     = {{Deep Keypoint-Based Camera Pose Estimation with Geometric Constraints}},
  doi       = {10.1109/IROS45743.2020.9341229},
  pages     = {4950-4957},
  year      = {2020},
}

@Misc{bib:coco,
  author      = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
  title       = {{Microsoft COCO: Common Objects in Context}},
  abstract    = {We present a new dataset with the goal of advancing the state-of-the-art in
object recognition by placing the question of object recognition in the context
of the broader question of scene understanding. This is achieved by gathering
images of complex everyday scenes containing common objects in their natural
context. Objects are labeled using per-instance segmentations to aid in precise
object localization. Our dataset contains photos of 91 objects types that would
be easily recognizable by a 4 year old. With a total of 2.5 million labeled
instances in 328k images, the creation of our dataset drew upon extensive crowd
worker involvement via novel user interfaces for category detection, instance
spotting and instance segmentation. We present a detailed statistical analysis
of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide
baseline performance analysis for bounding box and segmentation detection
results using a Deformable Parts Model.},
  added-at    = {2020-06-07T20:25:18.000+0200},
  biburl      = {https://www.bibsonomy.org/bibtex/2f4ab9f41677ee189a8cbc5a92cc0dc74/jan.hofmann1},
  description = {Microsoft COCO: Common Objects in Context},
  interhash   = {a3a26c6fe173264a6b812e3b7b4119bd},
  intrahash   = {f4ab9f41677ee189a8cbc5a92cc0dc74},
  keywords    = {thema:pyramid_scene_parsing},
  timestamp   = {2020-06-07T20:25:18.000+0200},
  year        = {2014},
}

@Article{bib:kitti,
  author  = {Andreas Geiger and Philip Lenz and Christoph Stiller and Raquel Urtasun},
  title   = {{Vision meets Robotics: The KITTI Dataset}},
  journal = {IJRR},
  year    = {2013},
}

@article{bib:performanceclassical,
  title={{A performance evaluation of local descriptors}},
  author={Mikolajczyk, Krystian and Schmid, Cordelia},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={27},
  number={10},
  pages={1615--1630},
  year={2005},
  publisher={IEEE}
}

@article{bib:performanceclassical2,
  title={{Evaluation of interest point detectors}},
  author={Schmid, Cordelia and Mohr, Roger and Bauckhage, Christian},
  journal={International Journal of computer vision},
  volume={37},
  number={2},
  pages={151--172},
  year={2000},
  publisher={Springer}
}

@article{bib:objectclassical,
  title={{A review of object detection based on deep learning}},
  author={Xiao, Youzi and Tian, Zhiqiang and Yu, Jiachen and Zhang, Yinshu and Liu, Shuai and Du, Shaoyi and Lan, Xuguang},
  journal={Multimedia Tools and Applications},
  volume={79},
  number={33},
  pages={23729--23791},
  year={2020},
  publisher={Springer}
}

@article{bib:cotr,
  author    = {Wei Jiang and
               Eduard Trulls and
               Jan Hosang and
               Andrea Tagliasacchi and
               Kwang Moo Yi},
  title     = {{{COTR:} Correspondence Transformer for Matching Across Images}},
  journal   = {CoRR},
  volume    = {abs/2103.14167},
  year      = {2021},
  eprinttype = {arXiv},
  eprint    = {2103.14167},
  timestamp = {Wed, 07 Apr 2021 15:31:46 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-14167.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{bib:yolopose,
  doi = {10.48550/ARXIV.2204.06806},
  author = {Maji, Debapriya and Nagori, Soyeb and Mathew, Manu and Poddar, Deepak},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {{YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss}},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{bib:loftr,
  doi = {10.48550/ARXIV.2104.00680},
  author = {Sun, Jiaming and Shen, Zehong and Wang, Yuang and Bao, Hujun and Zhou, Xiaowei},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {{LoFTR: Detector-Free Local Feature Matching with Transformers}},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@InProceedings{bib:d2net,
    author = {Dusmanu, Mihai and Rocco, Ignacio and Pajdla, Tomas and Pollefeys, Marc and Sivic, Josef and Torii, Akihiko and Sattler, Torsten},
    title = {{D2-Net: A Trainable CNN for Joint Detection and Description of Local Features}},
    booktitle = {Proceedings of the 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    year = {2019},
}

@misc{bib:r2d2,
  doi = {10.48550/ARXIV.1906.06195},
  author = {Revaud, Jerome and Weinzaepfel, Philippe and De Souza, César and Pion, Noe and Csurka, Gabriela and Cabon, Yohann and Humenberger, Martin},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {{R2D2: Repeatable and Reliable Detector and Descriptor}},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{bib:pixelwisecontrastive,
  author    = {Wenguan Wang and
               Tianfei Zhou and
               Fisher Yu and
               Jifeng Dai and
               Ender Konukoglu and
               Luc Van Gool},
  title     = {{Exploring Cross-Image Pixel Contrast for Semantic Segmentation}},
  journal   = {CoRR},
  volume    = {abs/2101.11939},
  year      = {2021},
  url       = {https://arxiv.org/abs/2101.11939},
  eprinttype = {arXiv},
  eprint    = {2101.11939},
  timestamp = {Sun, 31 Jan 2021 17:23:50 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2101-11939.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bib:yolov4,
  author    = {Alexey Bochkovskiy and
               Chien{-}Yao Wang and
               Hong{-}Yuan Mark Liao},
  title     = {{YOLOv4: Optimal Speed and Accuracy of Object Detection}},
  journal   = {CoRR},
  volume    = {abs/2004.10934},
  year      = {2020},
  eprinttype = {arXiv},
  eprint    = {2004.10934},
  timestamp = {Tue, 28 Apr 2020 16:10:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-10934.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bib:shrinkandperturb,
 author = {Ash, Jordan and Adams, Ryan P},
 booktitle = C_NIPS,
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {3884--3894},
 publisher = {Curran Associates, Inc.},
 title = {{On Warm-Starting Neural Network Training}},
 url = {https://proceedings.neurips.cc/paper/2020/file/288cd2567953f06e460a33951f55daaf-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{bib:adam,
  title={{Adam: A method for stochastic optimization}},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@misc{bib:triplet,
  doi = {10.48550/ARXIV.1412.6622},
  url = {https://arxiv.org/abs/1412.6622},
  author = {Hoffer, Elad and Ailon, Nir},
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {{Deep metric learning using Triplet network}},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{bib:infonce,
  title={{Representation learning with contrastive predictive coding}},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@InProceedings{bib:hpatches,
author={Vassileios Balntas and Karel Lenc and Andrea Vedaldi and Krystian Mikolajczyk},
title = {{HPatches: A benchmark and evaluation of handcrafted and learned local descriptors}},
booktitle = IEEE_C_CVPR,
year = {2017}}

@article{bib:object_detection_review_2,
  title={{A review of object detection based on convolutional neural networks and deep learning}},
  author={Wang, MingYuan and Leelapatra, Watis},
  journal={International Scientific Journal of Engineering and Technology (ISJET)},
  volume={6},
  number={1},
  pages={1--7},
  year={2022}
}

@article{bib:object_detection_review_3,
  title={{Object detection with deep learning: A review}},
  author={Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-tao and Wu, Xindong},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={11},
  pages={3212--3232},
  year={2019},
  publisher={IEEE}
}

@InProceedings{bib:beer2022itsc,
  author    = {Lukas Beer AND Thorsten Luettel AND Hans-Joachim Wuensche},
  booktitle = IEEE_C_ITSC,
  title     = {{GenPa-SLAM: Using a General Panoptic Segmentation for a Real-Time Semantic Landmark SLAM}},
  year      = {2022},
  address   = {Macau, China},
  note      = {©IEEE},
  pages     = {873--879},
  doi       = {10.1109/ITSC55140.2022.9921983},
}

@InProceedings{tas:reich2022iros,
  author    = {Andreas Reich AND Hans-Joachim Wuensche},
  booktitle = IEEE_C_IROS,
  title     = {{Fast Detection of Moving Traffic Participants in LiDAR Point Clouds by using Particles augmented with Free Space Information}},
  year      = {2022},
  address   = {Kyoto, Japan},
  note      = {©IEEE},
}

@InProceedings{bib:hundelshausen2012cvpr,
  author    = {Felix {von Hundelshausen} AND Rahul Sukthankar},
  booktitle = IEEE_C_CVPR,
  title     = {{D-Nets: Beyond patch-based image descriptors}},
  year      = {2012},
  address   = {Providence, RI, USA},
  pages     = {2941--2948},
  doi       = {10.1109/CVPR.2012.6248022},
  url       = {https://sites.google.com/site/descriptornets/},
}

@InProceedings{bib:schweitzer2009ecvw,
  author    = {Michael Schweitzer AND Hans-Joachim Wuensche},
  booktitle = ECVW09,
  title     = {{Efficient Keypoint Matching for Robot Vision using GPUs}},
  year      = {2009},
  doi       = {10.1109/ICCVW.2009.5457621},
}

%%%%%%%%%%%%%%% SAM %%%%%%%%%%%%%%%%

@article{bib:sam,
  title={{Segment Anything}},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},
  journal={arXiv:2304.02643},
  year={2023}
}

@misc{bib:dinov2,
  title={{DINOv2: Learning Robust Visual Features without Supervision}},
  author={Oquab, Maxime and Darcet, Timothée and Moutakanni, Theo and Vo, Huy V. and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and Howes, Russell and Huang, Po-Yao and Xu, Hu and Sharma, Vasu and Li, Shang-Wen and Galuba, Wojciech and Rabbat, Mike and Assran, Mido and Ballas, Nicolas and Synnaeve, Gabriel and Misra, Ishan and Jegou, Herve and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr},
  journal={arXiv:2304.07193},
  year={2023}
}

@misc{bib:vit,
  abstract = {While the Transformer architecture has become the de-facto standard for
natural language processing tasks, its applications to computer vision remain
limited. In vision, attention is either applied in conjunction with
convolutional networks, or used to replace certain components of convolutional
networks while keeping their overall structure in place. We show that this
reliance on CNNs is not necessary and a pure transformer applied directly to
sequences of image patches can perform very well on image classification tasks.
When pre-trained on large amounts of data and transferred to multiple mid-sized
or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision
Transformer (ViT) attains excellent results compared to state-of-the-art
convolutional networks while requiring substantially fewer computational
resources to train.},
  added-at = {2023-04-21T14:14:07.000+0200},
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  biburl = {https://www.bibsonomy.org/bibtex/2ed4c1d5b3a4068d9d621d3bbee93b968/annakrause},
  description = {[2010.11929] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  interhash = {f05240270962a2049a0aaec1db748975},
  intrahash = {ed4c1d5b3a4068d9d621d3bbee93b968},
  keywords = {idea:big_data_geo_2 representationlearning visionTransformer vit},
  timestamp = {2023-04-21T14:14:07.000+0200},
  title = {{An Image is Worth 16x16 Words: Transformers for Image Recognition at
  Scale}},
  url = {http://arxiv.org/abs/2010.11929},
  year = 2020
}

@misc{bib:fourier-features,
      title={{Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains}},
      author={Matthew Tancik and Pratul P. Srinivasan and Ben Mildenhall and Sara Fridovich-Keil and Nithin Raghavan and Utkarsh Singhal and Ravi Ramamoorthi and Jonathan T. Barron and Ren Ng},
      year={2020},
      eprint={2006.10739},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{bib:segformer,
  author       = {Enze Xie and
                  Wenhai Wang and
                  Zhiding Yu and
                  Anima Anandkumar and
                  Jos{\'{e}} M. {\'{A}}lvarez and
                  Ping Luo},
  title        = {{SegFormer: Simple and Efficient Design for Semantic Segmentation with
                  Transformers}},
  journal      = {CoRR},
  volume       = {abs/2105.15203},
  year         = {2021},
  url          = {https://arxiv.org/abs/2105.15203},
  eprinttype    = {arXiv},
  eprint       = {2105.15203},
  timestamp    = {Sat, 01 Jul 2023 10:38:36 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2105-15203.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{bib:mask2former,
    author    = {Cheng, Bowen and Misra, Ishan and Schwing, Alexander G. and Kirillov, Alexander and Girdhar, Rohit},
    title     = {Masked-Attention Mask Transformer for Universal Image Segmentation},
    booktitle = IEEE_C_CVPR,
    month     = {June},
    year      = {2022},
    pages     = {1290-1299}
}

@InProceedings{bib:forkel2021icra-terrain-estimation,
  author    = {Bianca Forkel AND Jan Kallwies AND Hans-Joachim Wuensche},
  booktitle = IEEE_C_ICRA,
  title     = {{Probabilistic Terrain Estimation for Autonomous Off-Road Driving}},
  year      = {2021},
  address   = {Xi'an, China (Hybrid Conference)},
  note      = {©IEEE},
  pages     = {13864--13870},
  doi       = {10.1109/ICRA48506.2021.9561689},
}

%% Datasets %%

@inproceedings{bib:cityscapes,
title={{The Cityscapes Dataset for Semantic Urban Scene Understanding}},
author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
booktitle=IEEE_C_CVPR,
year={2016}
}

@inproceedings{bib:goose-dataset,
author = {Peter Mortimer and Raphael Hagmanns and Miguel Granero
and Thorsten Luettel and Janko Petereit and Hans-Joachim Wuensche},
title = {{The GOOSE Dataset for Perception in Unstructured Environments}},
booktitle=IEEE_C_ICRA,
year = {2024}
}

@misc{bib:bdd100k,
      title={{BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning}},
      author={Fisher Yu and Haofeng Chen and Xin Wang and Wenqi Xian and Yingying Chen and Fangchen Liu and Vashisht Madhavan and Trevor Darrell},
      year={2020},
      eprint={1805.04687},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{bib:nuscenes,
  title={{nuScenes: A multimodal dataset for autonomous driving}},
  author={Holger Caesar and Varun Bankiti and Alex H. Lang and Sourabh Vora and 
          Venice Erin Liong and Qiang Xu and Anush Krishnan and Yu Pan and 
          Giancarlo Baldan and Oscar Beijbom}, 
  booktitle=IEEE_C_CVPR,
  year=2020
}

@INPROCEEDINGS{bib:mapillary-vistas,
  author={Neuhold, Gerhard and Ollmann, Tobias and Bulò, Samuel Rota and Kontschieder, Peter},
  booktitle=IEEE_C_ICCV, 
  title={{The Mapillary Vistas Dataset for Semantic Understanding of Street Scenes}},
  year={2017},
  volume={},
  number={},
  pages={5000-5009},
  doi={10.1109/ICCV.2017.534}}

@InProceedings{bib:backhaus2023acivs-yolopoint,
  author    = {Anton Backhaus AND Thorsten Luettel AND Hans-Joachim Wuensche},
  title     = {{YOLOPoint: Joint Keypoint and Object Detection}},
  year      = {2023},
  pages     = {112--123},
  Note      = {ISBN: 978-3-031-45382-3},
  Publisher = {Springer},
  Series    = {Lecture notes in computer science},
  Volume    = {14124},
  booktitle   = {"Proceedings of Advanced Concepts for Intelligent Vision Systems (ACIVS)"}
}

@article{bib:ransac,
  added-at = {2013-12-10T15:04:12.000+0100},
  author = {Fischler, M. and Bolles, R.},
  biburl = {https://www.bibsonomy.org/bibtex/2cf7f4278e6687a425dbe2374f5b84d07/anas.razeq},
  interhash = {8a99a961293d8dfe59a1f0838d77a24a},
  intrahash = {cf7f4278e6687a425dbe2374f5b84d07},
  journal = {Communications of the ACM},
  keywords = {RANSAC},
  number = {6},
  pages = {381-395},
  timestamp = {2013-12-10T15:04:12.000+0100},
  title = {{Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography}},
  url = {https://dl.acm.org/doi/pdf/10.1145/358669.358692},
  volume = {24},
  year = {1981}
}

@article{bib:naive-student,
  author       = {Liang{-}Chieh Chen and
                  Raphael Gontijo Lopes and
                  Bowen Cheng and
                  Maxwell D. Collins and
                  Ekin D. Cubuk and
                  Barret Zoph and
                  Hartwig Adam and
                  Jonathon Shlens},
  title        = {Leveraging Semi-Supervised Learning in Video Sequences for Urban Scene
                  Segmentation},
  journal      = {CoRR},
  volume       = {abs/2005.10266},
  year         = {2020},
  eprinttype    = {arXiv},
  eprint       = {2005.10266},
  timestamp    = {Thu, 28 May 2020 13:48:00 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2005-10266.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{bib:freiburg-forest,
author = {Abhinav Valada and Gabriel Oliveira and Thomas Brox and Wolfram Burgard},
title = {{Deep Multispectral Semantic Scene Understanding of Forested Environments using Multimodal Fusion}},
booktitle = ISER,
year = {2016},
}

@misc{bib:rellis-3d,
      title={{RELLIS-3D Dataset: Data, Benchmarks and Analysis}},
      author={Peng Jiang and Philip Osteen and Maggie Wigness and Srikanth Saripalli},
      year={2020},
      eprint={2011.12954},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{bib:camvid,
    author = "Gabriel J. Brostow and Julien Fauqueur and Roberto Cipolla",
    title = "Semantic Object Classes in Video: A High-Definition Ground Truth Database",
    journal = "Pattern Recognition Letters",
    year = "2008"
}

@article{bib:mseg,
  added-at = {2022-12-25T00:00:00.000+0100},
  author = {Lambert, John and Liu, Zhuang and Sener, Ozan and Hays, James and Koltun, Vladlen},
  biburl = {https://www.bibsonomy.org/bibtex/247083e7e023d35265927be1148a1b38f/dblp},
  ee = {https://doi.org/10.1109/TPAMI.2022.3151200},
  interhash = {310899c6796c463a2faf56cb99543c76},
  intrahash = {47083e7e023d35265927be1148a1b38f},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  keywords = {dblp},
  number = 1,
  pages = {796-810},
  timestamp = {2024-04-09T01:42:22.000+0200},
  title = {{MSeg: A Composite Dataset for Multi-Domain Semantic Segmentation.}},
  volume = 45,
  year = 2023
}

@InProceedings{bib:wilddash,
author = {Zendel, Oliver and Honauer, Katrin and Murschitz, Markus and Steininger, Daniel and Dominguez, Gustavo Fernandez},
title = {{WildDash - Creating Hazard-Aware Benchmarks}},
booktitle = C_ECCV,
year = {2018}
} 

@article{bib:a2d2,
title={{A2D2: Audi Autonomous Driving Dataset}},
author={Jakob Geyer and Yohannes Kassahun and Mentar Mahmudi and Xavier Ricou and Rupesh Durgesh and Andrew S. Chung and Lorenz Hauswald and Viet Hoang Pham and Maximilian M{\"u}hlegg and Sebastian Dorn and Tiffany Fernandez and Martin J{\"a}nicke and Sudesh Mirashi and Chiragkumar Savani and Martin Sturm and Oleksandr Vorobiov and Martin Oelker and Sebastian Garreis and Peter Schuberth},
year={2020},
eprint={2004.06320},
archivePrefix={arXiv},
primaryClass={cs.CV},
journal = {}
}

@InProceedings{bib:waymo-dataset, 
author = {Sun, Pei and Kretzschmar, Henrik and Dotiwalla, Xerxes and Chouard, Aurelien and Patnaik, Vijaysai and Tsui, Paul and Guo, James and Zhou, Yin and Chai, Yuning and Caine, Benjamin and Vasudevan, Vijay and Han, Wei and Ngiam, Jiquan and Zhao, Hang and Timofeev, Aleksei and Ettinger, Scott and Krivokon, Maxim and Gao, Amy and Joshi, Aditya and Zhang, Yu and Shlens, Jonathon and Chen, Zhifeng and Anguelov, Dragomir}, 
title = {{Scalability in Perception for Autonomous Driving: Waymo Open Dataset}},
booktitle = IEEE_C_CVPR, 
year = {2020} }

@InProceedings{bib:idd,
  author    = {Dokania, Shubham and Hafez, A. H. Abdul and Subramanian, Anbumani and Chandraker, Manmohan and Jawahar, C. V.},
  title     = {{IDD-3D: Indian Driving Dataset for 3D Unstructured Road Scenes}},
  booktitle = IEEE_C_WACV,
  year      = {2023},
  pages     = {4482-4491}
}

@article{bib:apolloscape,
  title={{The ApolloScape Open Dataset for Autonomous Driving and its Application}},
  author={Wang, Peng and Huang, Xinyu and Cheng, Xinjing and Zhou, Dingfu and Geng, Qichuan and Yang, Ruigang},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2019},
  publisher={IEEE}
}

@misc{bib:lanes,
  author       = {Azqalani, Nublan},
  title        = {{Semantic Segmentation Makassar(IDN) Road Dataset}},
  year         = {2022},
  howpublished = {\url{https://www.kaggle.com/datasets/nublanazqalani/semantic-segmentation-makassaridn-road-dataset}},
  note         = {Accessed: Nov 13, 2024}
}

@article{bib:ade20k,
  added-at = {2020-05-23T11:30:09.000+0200},
  author = {Zhou, Bolei and Zhao, Hang and Puig, Xavier and Xiao, Tete and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  ee = {https://doi.org/10.1007/s11263-018-1140-0},
  interhash = {87f0fbf7113702c7038ee1260e45a443},
  intrahash = {f0289d8074d3a07e1344bc0dad6678e3},
  journal = {Int. J. Comput. Vis.},
  keywords = {thema:pyramid_scene_parsing},
  number = 3,
  pages = {302-321},
  timestamp = {2020-05-23T11:30:09.000+0200},
  title = {{Semantic Understanding of Scenes Through the ADE20K Dataset}},
  volume = 127,
  year = 2019
}


@inproceedings{bib:heterogeneous-street-datasets,
title = {{Training of Convolutional Networks on Multiple Heterogeneous Datasets for Street Scene Semantic Segmentation}},
author = {Meletis, Panagiotis and Dubbelman, Gijs},
year = {2018},
day = {22},
doi = {10.1109/IVS.2018.8500398},
pages = {1045--1050},
booktitle = IEEE_C_IV,
publisher = {Institute of Electrical and Electronics Engineers},
}

@article{bib:heterogeneous-datasets,
  title={{Training Semantic Segmentation on Heterogeneous Datasets}},
  author={Meletis, Panagiotis and Dubbelman, Gijs},
  journal={arXiv preprint arXiv:2301.07634},
  year={2023}
}

@inproceedings{bib:unifying-off-road,
  author    = {Medellin, Anthony and Bhamri, Anant and Ma, Albert and Lanagri, Reza and Gopalswamy, Swaminathan and Grabowsky, David and Mikulski, Dariusz},
  title     = {{Applications of Unifying Off-Road Datasets Through Ontology}},
  booktitle = GVSETS,
  year      = {2024},
  number    = {2024-01-4074},
  pages     = {1--13},
  doi       = {10.4271/2024-01-4074},
  issn      = {0148-7191},
  eissn     = {2688-3627},
  publisher = {SAE International},
  address   = {Warrendale, PA},
}

@InProceedings{bib:tas500,
  author    = {Kai A. Metzger AND Peter Mortimer AND Hans-Joachim Wuensche},
  title     = {{A Fine-Grained Dataset and its Efficient Semantic Segmentation for Unstructured Driving Scenarios}},
  booktitle = ICPR,
  year      = {2021},
  address   = {Milano, Italy},
}

@inproceedings{bib:oneformer,
  author={Jain, Jitesh and Li, Jiachen and Chiu, MangTik and Hassani, Ali and Orlov, Nikita and Shi, Humphrey},
  booktitle=IEEE_C_CVPR, 
  title={{OneFormer: One Transformer to Rule Universal Image Segmentation}},
  year={2023},
  volume={},
  number={},
  pages={2989-2998},
  keywords={Training;Image segmentation;Computer vision;Computational modeling;Semantics;Computer architecture;Multitasking;Segmentation;grouping and shape analysis},
  doi={10.1109/CVPR52729.2023.00292}}
    }

@inproceedings{bib:yamaha,
  title={{Real-time Semantic Mapping for Autonomous Off-Road Navigation}},
  author={Maturana, Daniel and Chou, Po-Wei and Uenoyama, Masashi and Scherer, Sebastian},
  booktitle={Field and Service Robotics},
  pages={335--350},
  year={2018},
  organization={Springer}
}

@article{bib:noisy-student,
  title={{Self-training with Noisy Student improves ImageNet classification}},
  author={Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V},
  journal={arXiv preprint arXiv:1911.04252},
  year={2019}
}

@INPROCEEDINGS{bib:s++,
  author={Wang, Yuchao and Wang, Haochen and Shen, Yujun and Fei, Jingjing and Li, Wei and Jin, Guoqiang and Wu, Liwei and Zhao, Rui and Le, Xinyi},
  booktitle=IEEE_C_CVPR, 
  title={{Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels}},
  year={2022},
  volume={},
  number={},
  pages={4238-4247},
  keywords={Training;Visualization;Shape;Semantics;Predictive models;Semisupervised learning;Solids;Segmentation;grouping and shape analysis; Self-& semi-& meta- & unsupervised learning},
  doi={10.1109/CVPR52688.2022.00421}}

@article{bib:billion-scale,
  title={{Billion-scale semi-supervised learning for image classification}},
  author={Yalniz, I Zeki and J{\'e}gou, Herv{\'e} and Chen, Kan and Paluri, Manohar and Mahajan, Dhruv},
  journal={arXiv preprint arXiv:1905.00546},
  year={2019}
}

@inproceedings{bib:mean-teacher,
 author = {Tarvainen, Antti and Valpola, Harri},
 booktitle = C_NIPS,
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {{Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results}},
 volume = {30},
 year = {2017}
}

@article{bib:beyond-self-supervision,
  title={{Beyond Self-Supervision: A Simple Yet Effective Network Distillation Alternative to Improve Backbones}},
  author={Cui, Cheng and Guo, Ruoyu and Du, Yuning and He, Dongliang and Li, Fu and Wu, Zewu and Liu, Qiwen and Wen, Shilei and Huang, Jizhou and Hu, Xiaoguang and Yu, Dianhai and Ding, Errui and Ma, Yanjun},
  journal={arXiv preprint arXiv:2103.05959},
  year={2021},
}

@article{bib:pp-liteseg,
  title={{PP-LiteSeg: A Superior Real-Time Semantic Segmentation Model}},
  author={Peng, Juncai and Liu, Yi and Tang, Shiyu and Hao, Yuying and Chu, Lutao and Chen, Guowei and Wu, Zewu and Chen, Zeyu and Yu, Zhiliang and Du, Yuning and Dang, Qingqing and Lai, Baohua and Liu, Qiwen and Hu, Xiaoguang and Yu, Dianhai and Ma, Yanjun},
  journal={arXiv preprint arXiv:2204.02681},
  year={2022},
}

@INPROCEEDINGS{bib:meta-pseudo-labels,
  author={Pham, Hieu and Dai, Zihang and Xie, Qizhe and Le, Quoc V.},
  booktitle=IEEE_C_CVPR, 
  title={{Meta Pseudo Labels}},
  year={2021},
  volume={},
  number={},
  pages={11552-11563},
  keywords={Computer vision;Semisupervised learning;Benchmark testing;Pattern recognition;Standards},
  doi={10.1109/CVPR46437.2021.01139}}

@INPROCEEDINGS{bib:data-distillation,
  author={Radosavovic, Ilija and Dollár, Piotr and Girshick, Ross and Gkioxari, Georgia and He, Kaiming},
  booktitle=IEEE_C_CVPR, 
  title={{Data Distillation: Towards Omni-Supervised Learning}},
  year={2018},
  volume={},
  number={},
  pages={4119-4128},
  keywords={Data models;Predictive models;Training;Semisupervised learning;Transforms;Head;Heating systems},
  doi={10.1109/CVPR.2018.00433}}

@inproceedings{bib:rethinking-pretraining,
 author = {Zoph, Barret and Ghiasi, Golnaz and Lin, Tsung-Yi and Cui, Yin and Liu, Hanxiao and Cubuk, Ekin Dogus and Le, Quoc},
 booktitle = C_NIPS,
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {3833--3845},
 publisher = {Curran Associates, Inc.},
 title = {{Rethinking Pre-training and Self-training}},
 volume = {33},
 year = {2020}
}

@inproceedings{bib:weakly-and-semi-supervised-learning,
  title={{Weakly- and Semi-Supervised Learning of a Deep Convolutional Network for Semantic Image Segmentation}},
  author={Papandreou, George and Chen, Liang-Chieh and Murphy, Kevin and Yuille, Alan L.},
  booktitle=IEEE_C_ICCV,
  pages={1742--1750},
  year={2015},
}

@INPROCEEDINGS{bib:boosting-ssss,
  author={Meletis, Panagiotis and Dubbelman, Gijs},
  booktitle=IEEE_C_IV, 
  title={{On Boosting Semantic Street Scene Segmentation with Weak Supervision}},
  year={2019},
  volume={},
  number={},
  pages={1334-1339},
  keywords={},
  doi={10.1109/IVS.2019.8814217}}

@InProceedings{bib:urban-scene-coarse-annotation,
    author    = {Das, Anurag and Xian, Yongqin and He, Yang and Akata, Zeynep and Schiele, Bernt},
    title     = {{Urban Scene Semantic Segmentation With Low-Cost Coarse Annotation}},
    booktitle = IEEE_C_WACV,
    year      = {2023},
    pages     = {5978-5987}
}

@InProceedings{bib:image-level-weak-supervision,
author = {Ahn, Jiwoon and Kwak, Suha},
title = {{Learning Pixel-Level Semantic Affinity With Image-Level Supervision for Weakly Supervised Semantic Segmentation}},
booktitle = IEEE_C_CVPR,
year = {2018}
}

@InProceedings{bib:bbam,
    author    = {Lee, Jungbeom and Yi, Jihun and Shin, Chaehun and Yoon, Sungroh},
    title     = {{BBAM: Bounding Box Attribution Map for Weakly Supervised Semantic and Instance Segmentation}},
    booktitle = IEEE_C_CVPR,
    year      = {2021},
    pages     = {2643-2652}
}

@inproceedings{bib:automated-label-unification,
  title={{Automated Label Unification for Multi-Dataset Semantic Segmentation with GNNs}},
  author={Ma, Rong and Chen, Jie and Xue, Xiangyang and Pu, Jian},
  booktitle=C_NIPS,
  year={2024},
}

@INPROCEEDINGS{bib:multi-head-semseg,
  author={Masaki, Shota and Hirakawa, Tsubasa and Yamashita, Takayoshi and Fujiyoshi, Hironobu},
  booktitle= IEEE_C_ITSC, 
  title={{Multi-Domain Semantic-Segmentation using Multi-Head Model}},
  year={2021},
  volume={},
  number={},
  pages={2802-2807},
  keywords={Training;Costs;Conferences;Semantics;Data models;Intelligent transportation systems},
  doi={10.1109/ITSC48978.2021.9564940}}

@article{bib:universal-image-concepts,
  title={{Weakly supervised Training of universal visual concepts for multi-domain semantic segmentation}},
  author={Bevandić, Petra and Oršić, Marin and Grubišić, Ivan and Šarić, Josip and Šegvić, Siniša},
  journal={International Journal of Computer Vision},
  volume={132},
  number={7},
  pages={2450--2472},
  year={2024},
  doi={10.1007/s11263-024-01986-z},
}

@inproceedings{bib:partial-label-losses,
 author = {Cid-Sueiro, Jes\'{u}s},
 booktitle = C_NIPS,
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {{Proper losses for learning from partial labels}},
 volume = {25},
 year = {2012}
}

@inproceedings{bib:cross-dataset-learning,
  title={{Cross-Dataset Collaborative Learning for Semantic Segmentation in Autonomous Driving}},
  author={Wang, Li and Li, Dong and Liu, Han and Peng, Jinzhang and Tian, Lu and Shan, Yi},
  booktitle= AAAI,
  volume={36},
  number={3},
  pages={3180--3188},
  year={2022},
  doi={10.1609/aaai.v36i3.20149},
}

@article{bib:multi-task-domain-learning,
title = {{Multi-task, multi-domain learning: Application to semantic segmentation and pose regression}},
journal = {Neurocomputing},
volume = {251},
pages = {68-80},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.04.014},
author = {Damien Fourure and Rémi Emonet and Elisa Fromont and Damien Muselet and Natalia Neverova and Alain Trémeau and Christian Wolf},
keywords = {Deep learning, Convolutional neural networks, Semantic segmentation, Domain adaptation, Multi-task learning},
}

@inproceedings{bib:multi-domain-semseg,
  title={{Multi-Domain Semantic Segmentation with Overlapping Labels}},
  author={Bevandić, Petra and Oršić, Marin and Grubišić, Ivan and Šarić, Josip and Šegvić, Siniša},
  booktitle=IEEE_C_WACV,
  pages={2615--2624},
  year={2022},
  doi={10.1109/WACV51458.2022.00266},

}

@inproceedings{bib:universal-ssss,
  title={{Universal Semi-Supervised Semantic Segmentation}},
  author={Kalluri, Tarun and Varma, Girish and Chandraker, Manmohan and Jawahar, C. V.},
  booktitle=IEEE_C_ICCV,
  pages={5259--5270},
  year={2019},
  doi={10.1109/ICCV.2019.00536},

}

@InProceedings{bib:depth-anything,
    author    = {Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
    title     = {{Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data}},
    booktitle = IEEE_C_CVPR,
    year      = {2024},
    pages     = {10371-10381}
}

@inproceedings{bib:attention-is-all-you-need,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = C_NIPS,
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {{Attention Is All You Need}},
 volume = {30},
 year = {2017}
}