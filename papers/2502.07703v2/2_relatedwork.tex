\section{related work}
\label{sec:relatedwork}

\subsection{LiDAR and Radar Fusion}

Radar and \ac{LiDAR} are complementary range sensors, prompting numerous studies on their fusion for localization \cite{ROLM, YeongSang_radar, RALL}. \citeauthor{ROLM}~\cite{ROLM} and \citeauthor{YeongSang_radar}~\cite{YeongSang_radar} leveraged a \ac{LiDAR} map to align radar scans, enabling robust localization in adverse conditions as smoke or fog. However, they heavily depend on an accurate \ac{LiDAR} map, underscoring the importance of combining both sensors for precise \ac{SLAM}.

Despite the significance of sensor fusion, \ac{LiDAR} and radar fusion for \ac{SLAM} remains uncommon. Even though DR-LRIO \cite{DR-LRIO} proposed a tightly-coupled method between \ac{FMCW} radar and \ac{LiDAR} to enhance localization in challenging environments, it still contends with inherent uncertainties of radar, particularly along the $z$-axis. Our method expands the application of radar data beyond ego-velocity estimation by introducing additional strategies, such as dynamic object filtering and gravity estimation, to further improve \ac{SLAM} performance.

\subsection{Gravity Estimation in LiDAR-Inertial Odometry}
Accurate gravity estimation is essential in \ac{LIO} since \ac{IMU} acceleration measurements include gravity. Additionally, aligning maps based on the gravity vector alleviates vertical drift. The most common approach for predicting gravity involves probabilistic methods \cite{FAST-LIO, LINS}. However, these studies did not focus on exploiting gravity for state updates or map alignment. Recent works directly impose gravity as new constraints to mitigate vertical drift. Nebula \cite{agha2021nebula} measured gravity using \ac{IMU} acceleration only when the robot is stationary, introducing a gravity factor to constrain roll and pitch. D-LIOM \cite{D-LIOM} and Wildcat \cite{wildcat} estimated gravity using \ac{IMU} measurements and odometry, incorporating gravity alignment constraints. Additionally, \citeauthor{nemiroff2023joint} \cite{nemiroff2023joint} jointly optimized accelerometer intrinsics and gravity.
These methods partially tackled vertical drift; however, relying on velocity-ignorant models for gravity estimations. The velocity-ignorant model focuses on the relationship between \ac{IMU} acceleration and the pose, which impedes accurate gravity estimation due to errors exacerbated by double integration. To tackle these issues, we incorporate radar-based velocity residuals and velocity-aware gravity residuals into \ac{LIO}, eliminating the necessity of double integration.

%Radar and \ac{LiDAR} are complementary range sensors, each compensating for the other's strengths and weaknesses. Numerous studies have explored the fusion of Radar and \ac{LiDAR} for \ac{SLAM}.
% radar lidar 서로 상호보완 가능. 그래서 detection[]이나 localization 등에 많이 쓰임. 예를 들어 맵 위에 올려서 localization 가능 [rall, park, rolm]. specifically, 영상 park rolm은 맵 만들어서 오도메트리 뽑음. 하지만 이런건 LiDAR가 잘 되야 맵 위에 로컬리제이션 의미가 있고, 그래서 같이 써서 slam을 정확하게 하는게 더 중요. DR-LRIO는 그걸 함. 그런데, z축 문제가 있음. 그런데 우리 방법은 단순히 ego velocity를 사용하는데 그치지 않고, SLAM의 성능 향상을 위해 radar를 보다 다양하게 활용하는 방안을 소개했다 such as dynamic filtering and gravity estimation.
%DR-LRIO \cite{DR-LRIO} improves localization performance by tightly coupling \ac{FMCW} radar and \ac{LiDAR} in \ac{LiDAR}-degenerate environments. It provides insights into how integrating radar Doppler measurements into traditional \ac{LIO} can enhance state estimation.

%Due to the sparsity of radar point cloud, matching between radar scans can be challenging, leading to research focused on matching a radar scan with \ac{LiDAR} maps. For example, \citeauthor{YeongSang_radar} \cite{YeongSang_radar} proposed a multi-modal point cloud registration method between prior \ac{LiDAR} map and radar point cloud in smoky environments. Similarly, \cite{ROLM, ma2024fmcw} introduced a method for eliminating odometry drift through Radar-to-\ac{LiDAR} heterogeneous localization. In another related approach, \cite{RALL} utilized deep neural networks to perform radar localization on \ac{LiDAR} map.
% 지금은 뭔가 너무 나열식인데 얘네는 이렇게 했지만 이런 한계가 있다. 하지만 마지막에 우리는 이걸 해결했기 때문에 얘네보다 낫다가 드러나면 좋을듯



%--------------old


% \section{related work}
% \label{sec:relatedwork}

% \subsection{LiDAR and Radar Fusion}
% %Radar and \ac{LiDAR} are complementary range sensors, each compensating for the other's strengths and weaknesses. Numerous studies have explored the fusion of Radar and \ac{LiDAR} for \ac{SLAM}.
% % radar lidar 서로 상호보완 가능. 그래서 detection[]이나 localization 등에 많이 쓰임. 예를 들어 맵 위에 올려서 localization 가능 [rall, park, rolm]. specifically, 영상 park rolm은 맵 만들어서 오도메트리 뽑음. 하지만 이런건 LiDAR가 잘 되야 맵 위에 로컬리제이션 의미가 있고, 그래서 같이 써서 slam을 정확하게 하는게 더 중요. DR-LRIO는 그걸 함. 그런데, z축 문제가 있음. 그런데 우리 방법은 단순히 ego velocity를 사용하는데 그치지 않고, SLAM의 성능 향상을 위해 radar를 보다 다양하게 활용하는 방안을 소개했다 such as dynamic filtering and gravity estimation.
% %DR-LRIO \cite{DR-LRIO} improves localization performance by tightly coupling \ac{FMCW} radar and \ac{LiDAR} in \ac{LiDAR}-degenerate environments. It provides insights into how integrating radar Doppler measurements into traditional \ac{LIO} can enhance state estimation.

% %Due to the sparsity of radar point cloud, matching between radar scans can be challenging, leading to research focused on matching a radar scan with \ac{LiDAR} maps. For example, \citeauthor{YeongSang_radar} \cite{YeongSang_radar} proposed a multi-modal point cloud registration method between prior \ac{LiDAR} map and radar point cloud in smoky environments. Similarly, \cite{ROLM, ma2024fmcw} introduced a method for eliminating odometry drift through Radar-to-\ac{LiDAR} heterogeneous localization. In another related approach, \cite{RALL} utilized deep neural networks to perform radar localization on \ac{LiDAR} map.
% % 지금은 뭔가 너무 나열식인데 얘네는 이렇게 했지만 이런 한계가 있다. 하지만 마지막에 우리는 이걸 해결했기 때문에 얘네보다 낫다가 드러나면 좋을듯


% Radar and \ac{LiDAR} are complementary range sensors, each offsetting the limitations of the other, which leads to numerous studies on their fusion for localization \cite{ROLM, YeongSang_radar, RALL}. \citeauthor{YeongSang_radar} \cite{YeongSang_radar} leveraged a \ac{LiDAR} map to align radar scans, enabling robust localization in adverse conditions like smoke or fog. Similarly, \citeauthor{ROLM} \cite{ROLM} used a \ac{LiDAR} map to derive odometry from radar scans, thereby minimizing drift and enhancing localization accuracy. However, these methods depend heavily on an accurate \ac{LiDAR} map, underscoring the importance of combining both sensors for precise \ac{SLAM}.

% Despite the significance of sensor fusion, the LiDAR and radar fusion for SLAM remains uncommon. Even though DR-LRIO \cite{DR-LRIO} addresses this by tightly coupling \ac{FMCW} radar and \ac{LiDAR} to enhance localization in challenging environments, it still contends with radar's inherent uncertainties, particularly along the z-axis. Our proposed method expands the application of radar data beyond ego-velocity estimation by introducing additional strategies, such as dynamic object filtering and gravity estimation, to further improve \ac{SLAM} performance.

% \subsection{Gravity Estimation in LiDAR-Inertial Odometry}
% Accurate gravity estimation is essential in \ac{LIO} since \ac{IMU} acceleration measurements include gravity. Additionally, aligning maps based on the gravity vector helps mitigating vertical drift.
% The most common approach for predicting gravity involves probabilistic methods \cite{FAST-LIO, LINS}. However, these studies do not focus on using gravity to update the state or align the map. Some recent works directly impose new constraints to address vertical drift. Nebula \cite{agha2021nebula} measures gravity using \ac{IMU} acceleration only when the robot is stationary, introducing a gravity factor to constrain roll and pitch. D-LIOM \cite{D-LIOM} and Wildcat \cite{wildcat} estimate gravity using \ac{IMU} measurements and odometry, incorporating gravity alignment constraints into \ac{PGO}. Additionally, \citeauthor{nemiroff2023joint} \cite{nemiroff2023joint} proposed a method that jointly optimizes accelerometer intrinsic parameters and gravity through \ac{PGO}.

% While these methods can reduce vertical drift, they rely on velocity-ignorant models, primarily focusing on the relationship between \ac{IMU} acceleration and the estimated pose. These approaches face challenges, such as accumulated bias errors from double integration, which hinder accurate gravity estimation. To address these issues, we propose incorporating radar-based velocity residuals and radar-aided gravity residuals into the \ac{LIO} framework.

% % related works는 과거시제래


