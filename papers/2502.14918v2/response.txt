\section{Related Work}
\label{sec:related-work}

\subsection{Table Detection (TD)}

Table extraction from documents has been a longstanding research topic, with early surveys like Zanibbi et al., "Survey on Table Extraction" highlighting its significance. While image-based models like Faster R-CNN, "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" have been employed, they often underperform due to the unique characteristics and variability of tables ____ . Alexiou et al., "Deep Learning for Table Recognition: A Survey" provide a succinct review of traditional table detection methods, categorizing them into heuristic, deep learning, and hybrid approaches. Rujiao et al. introduce the WTW dataset ____ to address realistic scenarios, such as images of documents taken in real-world conditionsâ€”like photos of papers, screenshots, or scanned documents with various distortions, including perspective warping and blurring. However, our approach assumes access to deskewed scanned documents paired with OCR technologies. We use ABBYY OCR for our private data and DocTR ____ for public datasets.

We leverage DETR ____ , which merges a CNN backbone for feature extraction with a transformer architecture to model global context. This innovative architecture mitigates the need for post-processing steps like Non-Maximum Suppression (NMS) by employing a bipartite matching loss during training. For our table detection tasks, we utilize DETR-19, trained specifically on the ICDAR 2019 dataset. Alongside it we used Table Transformer (TATR), an extension of DETR fine-tuned on table-specific datasets like PubTables-1M ____ and FinTabNet ____ . This combination enhances our ability to detect tables across diverse document layouts.

\subsection{Table Structure Recognition (TSR)}

Graph-based methods were once promising for table extraction due to their ability to model relationships between table elements. Techniques by Riba et al., "Deep Learning Based Graph Neural Networks for Table Extraction" ; Zheng et al., "Graph-Based Deep Learning Methods for Table Detection and Structure Recognition" ; and Li et al., "Table Structure Recognition with Graph Convolutional Networks" used Graph Neural Networks (GNNs) to capture the structure of tables. However, they no longer offer state-of-the-art (SOTA) results, having been surpassed by deep learning models like DETR and TATR, which excel at directly predicting table boundaries and structures. TableNet provides an end-to-end solution for table detection and structure recognition by highlighting text zones with different colors based on their type, as shown in Paliwal et al., "TableNet: A Deep Learning Model for Table Detection and Structure Recognition" . Similarly, Prasad et al., "CascadeTabNet: An Iterative Transfer Learning Approach to Table Detection and Structure Recognition" use the image-based CascadeTabNet, which employs iterative transfer learning and data augmentation to enhance performance. Rashid et al., "A Hybrid Method for Table Detection and Structure Recognition" introduce a hybrid method (image and text) that predicts whether segments of a document are inside or outside of tables, enhancing accuracy by averaging predictions with their neighbors.

For table structure recognition, we used TATR ____ as well. TATR for TSR is designed to capture the structural relationships within tables, such as rows and columns, making it highly effective for TSR tasks. By using TATR in both TD and TSR, we ensure a comprehensive approach that leverages its strengths to effectively tackle the challenges of table extraction in real-world scenarios.

\subsection{Challenges in Business Table Extraction}


Despite significant advancements in table extraction, a notable gap exists in research focused on business tables, particularly product tables. Business tables, as seen in datasets like DocILE ____ (Section \ref{sec:datasets}), encompass a variety of data types, such as product details or invoices. They often exhibit considerable noise, with content added arbitrarily and inconsistent spacing between lines, complicating the extraction process. In contrast, datasets like FinTabNet ____ specifically target financial documents, which are typically clean and well-structured, focusing on numerical metrics and financial reporting. 

In Figure \ref{fig:example}, we illustrate common errors made by the baselines, including noise above and below the GT table and poorly fused lines. Our analysis of common errors in Table \ref{error_table} on the Business (private) dataset shows a high prevalence of TD errors, often due to business-specific elements resembling tables, like tax indications. To address these issues, we propose a post-processing method with corrective modules targeting frequent TD and TSR errors. These modules, optimized using a Genetic Algorithm ____ , improve accuracy after the initial model predictions. This approach contrasts with Le Vine et al.'s method ____ , which uses GA and Conditional Generative Adversarial Networks (cGAN) ____ to generate table structures directly. We anticipate that our method will generalize well to other public business datasets, such as DocILE, due to their shared domain. In contrast, errors from the ICDAR 2019 dataset highlight the varied challenges across different document types.


\begin{figure*}[t]
  \centering
   % \includegraphics[width=1.0\linewidth]{images/3_b7816646-d903-4165-b0e7-d39485c49000-17125-28832-1708028237113-yooz-2-15-24_3_00001_final_table_unfused_rogne-imageonline.co-merged.png}
   \includegraphics[width=1.0\linewidth]{images/3_b7816646-d903-4165-b0e7-d39485c49000-17125-28832-1708028237113-yooz-2-15-24_3_00001_final_table_unfused_rogne-imageonline.co-merged-min.png}

   \caption{Baseline prediction VS Ground-Truth on anonymised private data. Common errors (on the left) generally include mistakes in line fusion and over detected cells that can be seen as noise for the structure recognition step.}
   \label{fig:example}
\end{figure*}