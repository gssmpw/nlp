Our evaluation of our proposed neuromorphic architecture is focused on the following pivotal components. A comprehensive suite of applications spanning machine learning, data analytics, and signal processing are used to test our system. Through this diverse workload spectrum, we are able to thoroughly analyze our architecture's adaptability and performance across a wide range of scenarios, ensuring its versatility in handling a variety of computational tasks. Our simulation framework consists of the following.

\begin{itemize}
    \item \texttt{PyTorch~\cite{imambi2021pytorch}:} for \astro{} modeling.
    \item \texttt{ARES~\cite{reagen2018ares}:} for fault simulations.
    \item \texttt{pyJouleS \cite{belgaid2022green}:} for hardware results.
\end{itemize}

\subsection{Energy Efficiency Assessment}
In this section, we delve into the energy efficiency of SNN with a focus on the LIFA model. The energy consumption of the SNN was meticulously analyzed, both with and without the implementation of the Alternative Reduce Regime (ARR). This study aimed to quantify energy consumption on a neuronal and synaptic basis. As illustrated in~\autoref{fig9}, the LIFA Model demonstrates a significant variation in energy consumption contingent on the employment of the ARR. In order to better understand how energy-saving strategies relate to overall SNN performance, we critically evaluated the LIFA model. This study examined the trade-off between achieving energy efficiency and retaining and improving computational speed and accuracy. It is the high density of neuron-neuron synapses within clusters that distinguish the LIFA model as an ideal model for replicating biological neural networks.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{dac2022/images/lifa_1.png}
\caption{LIFA Model Energy Consumption.}
\label{fig9}
\end{figure}




\subsection{Memory Management Effectiveness}
A particular focus of this section is on evaluating LIFA's memory management effectiveness, particularly with regard to SNNs. The LIFA model was compared with conventional SNNs in terms of its total memory utilization. In this comparative study, optimal synaptic connections were particularly highlighted. Our LIFA tests were analogous to those conducted in Hopfield networks in order to assess the memory capabilities of the network. Besides reducing memory footprints, this optimization increases overall network efficiency. Our purpose was to evaluate the model's ability to store and retrieve patterns. The LIFA algorithm performs better than traditional SNNs in both pattern storage and retrieval. By using the model's advanced memory management techniques, applications that require high precision can benefit greatly.


A pivotal aspect of our evaluation is the use of memory capacity as a relative measure, ranging from 0 (no recall) to 1 (perfect recall). A neuromorphic uses this approach to assess its efficiency by comparing input patterns to their subsequent recalls. A comprehensive framework for modeling complex interactions within neural networks is provided by the LIFA model, which incorporates neuron and astrocyte activity. As a result of this integration, the model has enhanced memory capabilities as well as a better understanding of the interplay between various neural components, resulting in a more accurate neuromorphic simulation.





\subsection{Routing Mechanisms and Fault Tolerance}
An assessment of the fault tolerance capabilities of the system's LIFA is conducted in conjunction with an examination of the efficiency of different routing mechanisms within an SNN.

\textbf{Routing Efficiency:} The efficiency and speed of various routing algorithms, namely unicast, multicast, and broadcast, have been rigorously evaluated under normaland fault conditions. Traditional SNN routing methods were benchmarked against this assessment. As depicted in \autoref{fig11}, routing types vary significantly in performance, with multicast routing generally displaying the best resilience. Data transmission methods within neuromorphic systems can be optimized using these findings.


\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{dac2022/images/lifa_3.png}
\caption{Routing Efficiency under Normal and Fault Conditions.}
\label{fig11}
\end{figure}

\textbf{Fault Tolerance Analysis:} We systematically introduced faults into the SNN to assess its robustness and continuity of operation. Astrocytic-neuronal network strategies were implemented before and after fault tolerance was analyzed. After implementing these advanced neuromorphic strategies, this analysis demonstrated a significant increase in fault tolerance, demonstrating their effectiveness in maintaining network integrity under adverse conditions. A fault tolerance rate of 63.11\% was initially demonstrated by the SNN without astrocytes. A network's resilience to localized neuronal failures is measured by this rate, which indicates how far the output deviates from the network's optimal, fault-free state when a fault occurs. Fault tolerance improved significantly when astrocyte-neuronal strategies were implemented. The network's fault tolerance rate was improved to 81.10\% after integration. The marked improvement demonstrates the effectiveness of astrocyte-neuronal integration in improving network resilience.

The fault tolerance (FT) of the SNN is defined as:
\begin{equation}
    FT = \frac{O_{\text{fault}} - O_{\text{original}}}{O_{\text{original}}} \times 100\%
\end{equation}
where \( O_{\text{original}} \) is the output in the fault-free state, and \( O_{\text{fault}} \) is the output under fault conditions.

The values for our SNN model are:
\[ FT_{\text{astro-initial}} = 63.11\% \]
\[ FT_{\text{astro-LIFA}} = 81.10\% \]

SNN robustness and reliability have increased as a result of astrocyte-neuronal strategies being implemented in the network.



\subsection{Comparative Analysis}
A comparative analysis between our proposed system and traditional single-node neuromorphic systems validates the effectiveness of our approach. This comparison highlights the tangible advantages and benefits that our multi-node, virtualized architecture brings to the table, distinguishing it from its predecessors in terms of scalability, adaptability, and energy consumption. LIFA results are highlighted in Table \ref{tab:snn_metrics}.

\begin{table}[h]
\caption{LIFA Results.}
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Neurons & 4452 \\
\hline
Synapses & 6918144 \\
\hline
Network Topology & 1024, 768, 2048, 512, 100 \\
\hline
Network Recovery & 18.90\% \\
\hline
Fault Tolerance Rate & 81.10\% \\
\hline
Model Complexity (MAC) & 6.9 M \\
\hline
Average Spike Frequency & 2.173 Hz \\
\hline
Latency & 9.038 sec \\
\hline
Throughput & 492.56 neurons/sec \\
\hline
\end{tabular}
\label{tab:snn_metrics}
\end{table}


A quantitative assessment of performance of our proposed architecture will include measuring throughput, spike frequency, neural network utilization, and LIFA model overhead. We evaluate these metrics under various operational conditions and configurations to assess the system's performance and efficiency in a clear, objective manner and to highlight its strengths and weaknesses.



\begin{table}[H]
    \renewcommand{\arraystretch}{1.8}
    \setlength{\tabcolsep}{5pt}
    \centering
    \caption{Comparisons with state of art implementations.}
    \label{table:table_3}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
      & Wei et al. \cite{wei2019novel} & Johnson et al. \cite{johnson2017homeostatic}  & Isik et al. \cite{isik2022design} &Isik (2023) et al. \cite{isik2023astrocyte} &\textbf{Our} \\
    \hline
    Neurons  & 2 & 14  & 336 &  680&\textbf{4452} \\
    \hline
    Synapses  & 1 & 100  & 17,408 & 69,888 &\textbf{6918144}  \\
    \hline
     Network Recovery & 30\% & 30\% & 39\% &27.92\% & \textbf{18.90\%} \\
    \hline
     Fault Tolerance Rate  & 12.5\% & 70\% & 51.6\% & 63.11\% & \textbf{81.10\%}  \\
    \hline
    Power  & - & 1.37 W & 0.538 W & 2 W & -\\
    \hline

    \end{tabular}}
\end{table}

Table \ref{table:table_3} provides a comprehensive comparison of our proposed implementation with several prior works in the field of astrocyte modeling. It provides insights into the complexity and robustness of each model by highlighting key aspects such as neurons, synapses, fault tolerance rates, and resilience improvement. The number of neurons (4452) and synapses (6918144) in our implementation are significantly higher than those in other referenced works. Our model is at the forefront of astrocyte neural network functionality and capability due to its increased complexity. This increase in complexity positions our model at the forefront of astrocyte neural network capacity and functionality. In terms of fault tolerance rate, our model achieves an impressive 81.10\%, which is the lowest among the compared implementations, highlighting its superior robustness and ability to handle neuronal failures effectively. Additionally, the network recovery of our model is 18.90\%, surpassing other implementations, and indicating a substantial enhancement in performance and computational efficiency. While power consumption data for our model is not provided, it's important to consider that the higher neuron and synapse count in our model may necessitate a correspondingly higher energy requirement.



\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{dac2022/images/lifa_4.png}
\caption{Fault Tolerance Rate Comparison.}
\label{fig12}
\end{figure}

\autoref{fig12} presents a comparative analysis of fault tolerance rates across various neuromorphic computing implementations. This comparison includes state of art implementations and our implementation. The chart highlights the percentage of fault tolerance for each study, showcasing how each value in maintaining network integrity under fault conditions. Notably, our implementation demonstrates a significant improvement in fault tolerance, with the lowest rate among the compared studies.
