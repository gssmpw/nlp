\section{Preliminary}
\label{sec:PRELIMINARY}

\subsection{Pinhole camera model}

We first review the imaging process of the pinhole camera model. Denote a point in 3D space with homogeneous coordinates as $\mathbf{X}= [X,Y,Z,1]^T$. The corresponding coordinates $\mathbf{X'}=[X',Y',Z',1]^T$ in the camera coordinate system can be calculated as follows:
\begin{equation}
\mathbf{X'} = \mathbf{R}[\mathbf{I}|-\mathbf{C}] \mathbf{X},
\end{equation}
where $\mathbf{R}$ denotes the rotation matrix in the world coordinate system, and $\mathbf{C}$ indicates the position of the camera's projection center. The projected 2D coordinates on the normalized imaging plane can be represented as follows:
\begin{equation}
\mathbf{x}' = [x',y',1]^T = [X'/Z',Y'/Z',1]^T.
\end{equation}

Considering that PTZ cameras often utilize wide-angle lenses, the image distortion is unavoidable. Therefore, we also model the distorted coordinates $\mathbf{x}''$ as follows,
\begin{equation}
\begin{aligned}
    x'' = {x'(1 + {k_1}{r^2} + {k_2}{r^4}) + 2{p_1}x'y' + {p_2}({r^2} + 2{{x'}^2})},\\
    y'' = {y'(1 + {k_1}{r^2} + {k_2}{r^4}) + {p_1}({r^2} + 2{{y'}^2}) + 2{p_2}x'y'},\\
\end{aligned}
\end{equation}
\noindent where $k_1$ and $k_2$ denote the radial distortion coefficients, while $p_1$ and $p_2$ represent the tangential distortion coefficients, with ${r^2} = {{x'}^2} + {{y'}^2}$. 

The coordinates of $\mathbf{x}$ on the image can be denoted by:
\begin{equation}
\mathbf{x} = \mathbf{K}\mathbf{x}'' 
= 
\begin{bmatrix}
    f & 0 & c_x \\
    0 & f & c_y \\
    0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
    x'' \\
    y'' \\
    1
\end{bmatrix},
\end{equation}
\noindent where $\mathbf{K}$ is the intrinsic matrix. For simplicity, we assume square pixels, a principle point at the image center and a zero skew factor in our model.

\subsection{PTZ camera model}

A PTZ camera, capable of directional and zoom control, is typically mounted in a fixed, elevated position. It means that the camera primarily experiences rotation-only motions~\cite{hayman2003effects}, without offset between the camera's projection center and its rotation center. In our settings, the estimated parameters include the focal length $f$, the distortion coefficients $k1$, $k2$, $p1$, $p2$, as well as the rotation matrix $\mathbf{R}$ for each camera view. The other parameters, such as the principal points $cx$, $cy$, camera position $\mathbf{C}$, remain fixed for the same PTZ camera.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=\linewidth]{figures/pipeline.pdf}
    \caption{\textbf{Pipeline of the two-stage \emph{PTZ-Calib} method}. In the offline stage, the reference images selected from camera images are auto-calibrated with our novel \emph{PTZ-IBA} algorithm. Once online, our method estimates the camera parameters for arbitrary viewport images accurately and efficiently.}
    \label{fig:overview}
\end{figure*}


\subsection{Ray landmark} 

We define a ray as a directional vector originating from the camera's projection center. The \textit{ray landmark} is then represented by a normalized three-dimensional vector. In our method, the ray landmarks serve as the primary representation of scenes and constrain the relative rotation and intrinsic parameters of the camera across different views. However, relying solely on ray landmarks is insufficient for determining the absolute pose of camera in the real-world geographic coordinate system due to the lack of explicit 3D information. Therefore, incorporating 3D landmarks, which represent the 3D points in the world, becomes necessary.
