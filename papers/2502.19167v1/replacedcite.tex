\section{Related Works}
\label{sec:II}

\heading{Challenges for BP estimation and benchmarking models} 
\label{sec:II-B}
Several research studies have indicated that the effectiveness of learning models in predicting BP is highly dependent on the quality and quantity of the training data ____. For instance,  researchers who worked with the MIMIC-III dataset underscore the significance of data preparation to achieve better model outcomes ____. The aforementioned challenges result in a growing demand for reliable benchmark studies to thoroughly evaluate different ML/DL methods for BP estimation using PPG, utilizing comprehensive datasets to measure their efficiency. Consequently, benchmark investigations have been performed in this area to address the aforementioned demands. We refer to ____ as a notable and recent benchmark study that used four different datasets. 
However, the mentioned study only considers models trained from scratch on the respective datasets and evaluates them on in-distribution test sets, which are known to provide overly optimistic measures for the generalization performance on unseen data. The PulseDB dataset, a large-scale, high-quality dataset containing PPG signals and reference BP measurements, and as such is a unique resource for training deep-learning based BP prediction models, after which they can be externally validated on external datasets.



\heading{Challenges of OOD generalization} 
Most of the ML/DL techniques usually rely on the subtle statistical patterns that may exist within the training data, hence functioning under ideal conditions where both the training and testing data belong to the same distribution (ID). However, this perfect situation rarely occurs in real-world scenarios ____. Previous work has shown that most DL models perform poorly on tasks induced by data from distributions other than their training data (OOD) generalization ____. The concept of OOD generalization and its application to DL models has evolved with contributions from various researchers, e.g., ____. 
The challenges of OOD generalization in the context of PPG-based BP estimation have been investigated in a recent publication ____. They focused on feature-based approaches, whereas the present work covers deep learning models operating on raw time series. This work establishes a more comprehensive picture by considering a large number of external datasets and investigating the potential impact of domain adaptation.

\heading{Improving OOD generalization} 
It is worth mentioning that OOD generalization is a challenging task that may result in poor performances since unseen data very often do not resemble the training set ____. Several previous works have intensively addressed such a challenge of mitigating the influence of OOD signals when analyzing ECG and EEG data. ____ have shown the effectiveness of using domain generalization and self-supervised learning approaches to improve the classification accuracy of OOD ECG signals. Also, recent work by ____ has demonstrated promising results in addressing domain shifts and OOD signals between diverse EEG datasets, highlighting the potential of domain adaptation techniques to enhance the robustness of EEG signal recognition. According to previous studies, one of the key approaches to tackle the challenge of OOD generalization is to reduce the influence of distribution shifts between training and test sets by revising the distribution of training data to mimic the distribution of test data, aiming to minimize the predictive error on the test set ____.
In this work, we use a simple sample-based empirical risk minimization approach based on sample weights inferred from the label distribution (i.e., BP reference labels) in the source and target domains to assess the potential benefits of incorporating domain adaptation approaches. 

\heading{Technical contributions} 
In this work, we put forward the following technical contributions:


\begin{enumerate}

 


\item We implemented state-of-the-art DL-based time series classification algorithms for PPG-based BP estimation on the large-scale, high-quality PulseDB dataset and evaluated their performance in a first comprehensive comparative study. 

\item We investigated both ID and OOD generalization of models trained on various PulseDB subsets. These models were evaluated on different PulseDB subsets and four external datasets. To contextualize OOD performance, we compared it with the differences in label distributions between the training and test datasets.




\item We assessed the benefit of domain adaptation by using an importance-weighted empirical risk minimization approach using importance weights inferred from the respective label distributions and put forward recommendations for training dataset choices that promise good generalization properties.


\end{enumerate}