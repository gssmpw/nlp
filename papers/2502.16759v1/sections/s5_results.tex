%% !!!!!! \todo{New results on summarization: Last row in Table 5 (shall this be ablation or understanding?)}
%% !!!!!! \todo{Change "user" to "consumer"?)}

\subsection{Data}
We conduct a series of experiments on industrial datasets to compare the performance of LR-Recsys against state-of-the-art recommender systems in the literature. We start with introducing the three datasets used. 

\begin{itemize}
\item \textbf{Amazon Movie}: This dataset captures consumer purchasing behavior in the Movies \& TV category on Amazon \citep{ni2019justifying}\footnote{\url{https://nijianmo.github.io/amazon/index.html}}. Collected in 2023, it contains 17,328,314 records from 6,503,429 users and 747,910 unique movies. Each record includes the user ID, movie ID, movie title, user rating (on a 1-5 scale), purchasing timestamp, user’s past purchasing history (as a sequence of movie IDs), and three aspect terms summarizing key movie attributes (e.g., ``thriller'', ``exciting'', ``director'').

\item \textbf{Yelp Restaurant}: This dataset documents users' restaurant check-ins on the Yelp platform\footnote{\url{https://www.yelp.com/dataset}}. It spans 11 metropolitan areas in the United States and comprises 6,990,280 check-in records from 1,987,897 users across 150,346 restaurants. Each record includes the user ID, restaurant ID, check-in timestamp, user rating (on a 1-5 scale), user’s historic visits (as a sequence of restaurant IDs), and three aspect terms summarizing key restaurant features (e.g., ``atmosphere'', ``service'',  ``expensive'').

\item \textbf{TripAdvisor Hotel}: This dataset captures users’ hotel stays on the TripAdvisor platform \citep{li2023personalized}. Collected in 2019, it contains 343,277 hotel stay records from 9,765 users and 6,280 unique hotels. Each record includes the user ID, hotel ID, check-in timestamp, user rating, the list of hotels previously visited by the user, and three aspect terms describing key hotel attributes (e.g., ``beach'', ``price'', ``service''). 
\end{itemize}


% \begin{itemize}
% \item \textbf{Amazon Movie}, which records the consumer purchasing actions in the Movies \& TV department of Amazon \citep{ni2019justifying}\footnote{https://nijianmo.github.io/amazon/index.html}. This dataset was collected in the year of 2023, including 17,328,314 records of 650,3429 users and 747,910 unique movies in total. Each individual record in this dataset contains the information of user ID, movie ID, movie title, user rating (on the scale of 1-5), user purchasing timestamp, user past purchasing history in this department (as a sequence of movie IDs), and three aspect terms that summarize the most important properties of the movie (such as ''thriller'', ''exciting'', and ''director''). 
% \item \textbf{Yelp Restaurant}, which records the users' restaurant check-in behaviors on the Yelp platform \footnote{https://www.yelp.com/dataset}. This dataset spans across 11 metropolitan areas in the United States, and includes 6,990,280 check-in records of 150,346 restaurants from 1,987,897 users. For each individual record, we collect the information of user ID, restaurant ID, check-in timestamp, user rating (on the scale of 1-5), user historic visits (as a sequence of restaurant IDs), and three aspect terms that summarize the most important features of the restaurant (such as ''atmosphere'', ''service'', and ''expensive'').
% \item \textbf{TripAdvisor Hotel}, which records the users' hotel stays on the TripAdvisor platform \citep{li2023personalized}. This dataset was collected in the year of 2019, and it includes 343,277 hotel staying records from 9,765 unique users of 6.280 unique hotels. Each individual record collects the information of user ID, hotel ID, hotel check-in timestamp, user rating, the list of hotels that the user has stayed before, as well as three aspect terms that describe the most unique part of the hotel (such as ''beach'', ''concierge'', and ''breakfast'').
% \end{itemize}

For all three datasets, the recommender system aims to predict the outcome for a given candidate product using the inputs of user ID, candidate item ID, and the user's past purchasing history (specifically, the last five items purchased).\endnote{For the aspect-based recommendation baselines introduced below, the aspect terms are also included as inputs to the model.} The outcome of interest for all three datasets is the product rating (on a 1-5 scale). 

To evaluate the efficacy and robustness of our framework, we examine two prediction settings: (1) a regression task, where the goal is to predict the exact rating value, and (2) a classification task, where the objective is to categorize ratings as either high (4 or 5) or low (1, 2, or 3). In line with established practices in the recommender system literature, we use root mean squared error (RMSE) and mean absolute error (MAE) as evaluation metrics for the regression task. For the classification task, we use the area under the ROC curve (AUC) \citep{hanley1982meaning}. These three datasets represent three distinct business applications with significantly different statistical distributions, making them excellent testbeds for evaluating the generalizability and flexibility of LR-Recsys.

\subsection{Baseline Models}
We compare LR-Recsys against state-of-the-art black-box recommender systems, LLM-based recommender systems, and a wide range of explainable recommender systems. Specifically, we identify the following three groups of 14 state-of-the-art baselines from recent marketing and computer science literature:

% \begin{itemize}
\begin{enumerate}
    \item \textbf{Aspect-Based Recommender Systems}: These models utilize ground-truth aspect terms as additional information to facilitate preference reasoning and generate recommendations.
    \begin{itemize}
        \item \textbf{A3NCF} \citep{cheng20183ncf} constructs a topic model to extract user preferences and item characteristics from reviews, and capture user attention on specific item aspects via an attention network.
        \item \textbf{SULM} \citep{bauman2017aspect} predicts the sentiment of a user about an item’s aspects, identifies the most valuable aspects of their potential experience, and recommends items based on these aspects.
        \item \textbf{AARM} \citep{guan2019attentive} models interactions between similar aspects to enrich aspect connections between users and products, using an attention network to focus on aspect-level importance.
        \item \textbf{MMALFM} \citep{cheng2019mmalfm} applies a multi-modal aspect-aware topic model to estimate aspect importance and predict overall ratings as a weighted linear combination of aspect ratings.
        \item \textbf{ANR} \citep{chin2018anr} learns aspect-based user and item representations through an attention mechanism and models multi-faceted recommendations using a neural co-attention framework.
        \item \textbf{MTER} \citep{le2021explainable} generates aspect-level comparisons between target and reference items, producing recommendations based on these comparative explanations.
    \end{itemize}

    \item \textbf{Sequential Recommender Systems}: These models use sequences of past user behaviors to predict the next likely purchase, leveraging various neural network architectures.
    \begin{itemize}
        \item \textbf{SASRec} \citep{kang2018self} utilizes self-attention to capture long-term semantics in user actions and identify relevant items in a user’s history.
        \item \textbf{DIN} \citep{zhou2018deep} adopts a local activation unit to adaptively learn user interest representations from historical behaviors and predict preferences for candidate items.
        \item \textbf{BERT4Rec} \citep{sun2019bert4rec} adopts bidirectional self-attention and the Cloze objective to model user behavior sequences and avoid information leakage, enhancing recommendation efficiency.
        \item \textbf{UniSRec} \citep{hou2022towards} uses contrastive pre-training to learn universal sequence representations of user preferences, improving recommendation accuracy.
    \end{itemize}

    \item \textbf{Interpretable Recommender Systems}: These models focus on generating high-quality recommendations accompanied by intuitive explanations.
    \begin{itemize}
        \item \textbf{AMCF} \citep{pan2021explainable} maps uninterpretable general features to interpretable aspect features, optimizing for both recommendation accuracy and explanation clarity through dual-loss minimization.
        \item \textbf{PETER} \citep{li2021personalized} predicts words in target explanations using IDs, endowing them with linguistic meaning to generate personalized recommendations.
        \item \textbf{UCEPic} \citep{li2023ucepic} combines aspect planning and lexical constraints to produce personalized explanations through insertion-based generation, improving recommendation performance.
        \item \textbf{PARSRec} \citep{gholami2022parsrec} leverages common and individual behavior patterns via an attention mechanism to tailor recommendations and generate explanations based on these patterns.
    \end{itemize}
% \end{itemize}
\end{enumerate}

\begin{comment}

\begin{itemize}
\item \textbf{Aspect-Based Recommender Systems}, which utilize the ground-truth aspect terms as additional information to facilitate the preference reasoning and to provide recommendations accordingly. These models include: (1) \textbf{A3NCF \citep{cheng20183ncf}}, which constructs a topic model to extract user preferences and item characteristics from user reviews. This topic model guides the representation learning of users and items, and also captures a user’s special attention on each aspect of the targeted item with an attention network. These user/item representations and aspect attention values will then be used for generating recommendations; (2) \textbf{SULM \citep{bauman2017aspect}}, which first predicts the sentiment that the user may have about the item based on what she/he might express about the aspects of the item, and then identifies the most valuable aspects of the user’s potential experience with that item. It further recommends items based on those most important aspects accordingly; (3) \textbf{AARM \citep{guan2019attentive}}, which models the interactions between synonymous and similar aspects to enrich the aspect connections between user and product. It also contains a neural attention network to capture a user’s attention toward aspects when examining different products, and produces recommendations accordingly; (4) \textbf{MMALFM \citep{cheng2019mmalfm}}, which applies a multi-modal aspect-aware topic model to model users’ preferences and items’ features from different aspects, and also estimate the aspect importance of a user toward an item. The overall rating is then predicted via a linear combination of the aspect ratings, which are weighted by the importance of the corresponding aspect; (5) \textbf{ANR \citep{chin2018anr}}, which performs aspect-based representation learning for both users and items via an attention-based component. It also models the multi-faceted process for recommendations by estimating the aspect-level user and item importance based on the neural co-attention mechanism; and (6) \textbf{MTER \citep{le2021explainable}}, which formulates comparative explanations involving aspect-level comparisons between the target item and the reference items, and produces recommendations accordingly.
\item \textbf{Sequential Recommender System}, which utilizes the sequence of user past behaviors to predict the next product that the consumer is likely to purchase using various types of neural network architectures. These models include: (1) \textbf{SASRec \citep{kang2018self}}, which proposes a self-attention-based sequential model to capture long-term semantics in recommendations, and to identify which items are ''relevant'' from a user’s action history; (2) \textbf{DIN \citep{zhou2018deep}}, which designs a local activation unit to adaptively learn the user interest representation from historical behaviors, and then infers the user preference on the candidate item accordingly; (3) \textbf{BERT4Rec \citep{sun2019bert4rec}}, which employs the deep bidirectional self-attention mechanism to model user behavior sequences, and also adopts the Cloze objective to predict the random masked items in the sequence to avoid the information leakage, resulting in more efficient recommendation performance; (4) \textbf{UniSRec \citep{hou2022towards}}, which utilizes the contrastive pre-training technique to learn universal sequence representations that represent the user preferences, and then provide subsequent recommendations accordingly.
\item \textbf{Interpretable Recommender System}, which attempts to develop models that generate not only high-quality recommendations but also intuitive explanations for those recommendations. These models include: (1) \textbf{AMCF \citep{pan2021explainable}}, which presents a novel feature mapping approach that maps the uninterpretable general features onto the interpretable aspect features, achieving both satisfactory accuracy and explainability in the recommendations by simultaneous minimization of rating prediction loss and interpretation loss; (2) \textbf{PETER \citep{li2021personalized}}, which designs a simple and effective learning objective that utilizes the IDs to predict the words in the target explanation, endowing the IDs with linguistic meanings and producing personalized recommendations; (3) \textbf{UCEPic \citep{li2023ucepic}}, which generates high-quality personalized explanations for recommendation results by unifying aspect planning and lexical constraints in an insertion-based generation manner, and these explanations can be subsequently used for improving the recommendation performance; and (4) \textbf{PARSRec \citep{gholami2022parsrec}}, which relies on common behavior patterns as well as individual behaviors to tailor the recommendation strategy for each person through the attention mechanism, and produce the explanations based on these behavioral patterns.
\end{itemize}
\end{comment}

We split each dataset into training and test sets using an 80-20 ratio at the user-temporal level. To ensure a fair comparison, we adopted Grid Search \citep{bergstra2011algorithms} and allocated equal computational resources—in terms of training time and memory usage—to optimize the hyperparameters for both our proposed approach and all baseline models. Detailed hyperparameter settings are provided in Appendix \ref{appen:hyper_param}. We independently ran LR-Recsys and each baseline model ten times and reported the average performance metrics along with their standard deviations.


\subsection{Main Results}
\label{sec:main_results}
Table \ref{main_results} presents the main results. LR-Recsys consistently outperforms all three groups of 14 baseline models across two recommendation tasks and three datasets. Specifically, LR-Recsys achieves an improvement of 5-20\% in RMSE, 15-30\% in MAE, and 2.9-3.7\% in AUC compared to the best-performing baselines. These results demonstrate the efficacy of LR-Recsys and the value of LLM-based contrastive explanations in improving the recommendation performance. 

% Yelp: 
% RMSE 11.3
% MAE 18.6
% AUC 3

% Amazon: 
% RMSE 20
% MAE 33 
% AUC 3.7

% It is also important to note, however, that these performance improvements that we have achieved in the experiments, ranging from 3\% to 15\% in terms of the RMSE, MAE, and AUC metrics, are indeed economically significant according to the discussions in the literature \citep{gunawardana2022evaluating}. In fact, according to a series of recent online experiments conducted at major e-commerce, including Google \citep{zhang2023empowering}, Amazon \citep{chen2024shopping}, Alibaba \citep{zhou2018deep}, and LinkedIn \citep{wang2024limaml}, performance improvements on the accuracy-based metrics (such as RMSE, MAE, and AUC that we use in our paper) in the offline experiments will typically lead to significant business performance increases in the online experiments as well. For example, \citet{li2024variety} proposed a novel recommender system design that manages to achieve a significant improvement of 3\% on average in terms of the AUC and Hit Rate@10 metrics on the three offline public datasets (Yelp, MovieLens, and Alibaba). When deployed at the production system of a major video streaming platform, the authors observe a similar level of 3\% improvement over Click-Through Rate and Video View metrics, which led to an additional \$30 million in revenue for the company. Additionally, according to the industrial practices at Netflix \citep{gomez2015netflix}, even a tiny 0.1\% improvement on the business performance metric would lead to significant economic and business values for the company, while in our experiments, our proposed model consistently achieves performance improvements around or above 3\% in terms of the AUC metric, which is clearly beneficial to the business performance \citep{gunawardana2022evaluating}.

It is important to emphasize that the performance improvements achieved in our experiments are economically significant \citep{gunawardana2022evaluating}. Recent online experiments conducted by major e-commerce platforms, including Google \citep{zhang2023empowering}, Amazon \citep{chen2024shopping}, Alibaba \citep{zhou2018deep}, and LinkedIn \citep{wang2024limaml}, consistently show that improvements in accuracy-based metrics (such as RMSE, MAE, and AUC) during offline testing often translate into substantial business performance gains when deployed in production systems. For example, \citet{li2024variety} proposed a novel recommender system that achieved a 3\% improvement in AUC and Hit Rate@10 on public datasets (Yelp, MovieLens, and Alibaba). When deployed on a major video streaming platform, this improvement translated to a 3\% increase in Click-Through Rate and Video Views, resulting in an additional \$30 million in annual revenue. Netflix highlight that even a 0.1\% improvement in business performance metrics can deliver significant economic value \citep{gomez2015netflix}. Notably, our proposed model consistently achieves performance gains of approximately 3\% or more, validating its efficacy to drive meaningful business impact \citep{gunawardana2022evaluating}.


% Finally, to give the audience a better understanding of how our proposed model works, we present the following case example from our Yelp dataset, where we aim to suggest a premium Thai restaurant for a particular consumer. However, after weighing the positive and negative reasons generated by the contrastive-explanation generator in our LR-Recsys, it seems that an alternative Japanese restaurant would be a better fit for the consumer. Therefore, our proposed recommendation model only predicts a 1.14 rating for this recommended Thai restaurant, which matches the ground-truth rating of 1 and significantly outperforms the prediction of 1.89 by the best-performing baseline model PETER \citep{li2021personalized} in our experiments.

To illustrate how our proposed model operates, we present a case study from the Yelp dataset below. In this scenario, the task is to recommend a premium Thai restaurant to a specific consumer. However, after incorporating the positive and negative reasoning generated by the contrastive-explanation generator in our LR-Recsys, the model determines that an alternative Japanese restaurant would be a better fit for the consumer. Consequently, our recommendation system predicts a rating of 1.14 for the Thai restaurant, closely aligning with the ground-truth rating of 1. This prediction significantly outperforms the baseline model PETER \citep{li2021personalized}, which predicts a rating of 1.89.
\newline

\fbox{%
% \vspace{-0.1in}
    \parbox{\textwidth}{%
\textbf{Consumer Past Visiting History}: O-Ku Sushi, Zen Japanese, MGM Grand Hotel, Sen of Japan, Sushi Bong

\textbf{Restaurant Profile}: ''Siam Thai Kitchen is a Thai restaurant that offers a unique dining experience in the city. The restaurant is known for its authentic Thai cuisine and its warm and inviting atmosphere. The menu features a variety of traditional Thai dishes, as well as some modern twists on classic Thai flavors. The restaurant is perfect for couples, families, and groups of friends who are looking for a delicious and authentic Thai dining experience.''

\textbf{Generated Positive Explanation}: ''The consumer is looking for a unique and flavorful dining experience and the restaurant offers a variety of Asian cuisine.''

\textbf{Generated Negative Explanation}: ''The consumer is looking for a traditional Japanese experience and wants to escape the busy city life, while the restaurant is not a traditional Japanese experience and is located in a city''

\textbf{Positive Explanation Attention Value}: 0.23

\textbf{Negative Explanation Attention Value}: 0.87

\textbf{Predicted Consumer Rating}: 1.14

\textbf{Ground-Truth Consumer Rating}: 1

\textbf{PETER-Predicted Consumer Rating}: 1.89
    }%
}
\newline
% In the remainder of this section, we will conduct a series of additional analyses to understand where the performance improvements that we achieved in the experiments come from, as well as conduct additional ablation studies and robustness checks to demonstrate the flexibility and generalizability of LR-Recsys.

% In the remainder of this section, we conduct a series of additional analyses to explore the sources of the performance gains observed in our experiments. Additionally, we perform ablation studies and robustness checks to further demonstrate the flexibility and generalizability of LR-Recsys.

\begin{table}
\centering
\footnotesize
   \setlength\extrarowheight{2pt}
\resizebox{0.95\textwidth}{!}{
\begin{tabular}{|c|ccc|ccc|ccc|} \hline
 & \multicolumn{3}{c|}{TripAdvisor} & \multicolumn{3}{c|}{Yelp} & \multicolumn{3}{c|}{Amazon Movie} \\ \hline
 & RMSE $\downarrow$ & MAE $\downarrow$ & AUC $\uparrow$ & RMSE & MAE & AUC $\uparrow$ & RMSE $\downarrow$ & MAE $\downarrow$ & AUC $\uparrow$ \\ \hline
\textbf{LR-Recsys (Ours)} & \textbf{0.1889} & \textbf{0.1444} & \textbf{0.7289} & \textbf{0.2149} & \textbf{0.1685} & \textbf{0.7229} & \textbf{0.1673} & \textbf{0.1180} & \textbf{0.7500} \\
 & (0.0010) & (0.0008) & (0.0018) & (0.0010) & (0.0009) & (0.0017) & (0.0010) & (0.0009) & (0.0018) \\
\textbf{\% Improved} & +5.36\%*** & +15.11\%*** & +2.88\%*** & +11.31\%*** & +18.64\%*** & +3.01\%*** & +20.30\%*** & +33.33\%*** & +3.65\%*** \\ \hline
A3NCF & 0.2103 & 0.1811 & 0.6879 & 0.2607 & 0.2181 & 0.6785 & 0.2241 & 0.1903 & 0.6971 \\
 & (0.0019) & (0.0013) & (0.0027) & (0.0023) & (0.0016) & (0.0029) & (0.0029) & (0.0018) & (0.0032) \\
SULM & 0.2191 & 0.1872 & 0.6736 & 0.2823 & 0.2258 & 0.6614 & 0.2477 & 0.1980 & 0.6855 \\
 & (0.0021) & (0.0013) & (0.0027) & (0.0019) & (0.0015) & (0.0029) & (0.0027) & (0.0019) & (0.0027)\\
AARM & 0.2083 & 0.1803 & 0.6901 & 0.2582 & 0.2162 & 0.6801 & 0.2162 & 0.1845 & 0.7032 \\
 & (0.0019) & (0.0014) & (0.0030) & (0.0021) & (0.0015) & (0.0029) & (0.0027) & (0.0018) & (0.0029) \\
MMALFM & 0.2117 & 0.1820 & 0.6894 & 0.2591 & 0.2167 & 0.6801 & 0.2301 & 0.1931 & 0.6931 \\
 & (0.0019) & (0.0014) & (0.0029) & (0.0020) & (0.0016) & (0.0030) & (0.0028) & (0.0020) & (0.0036) \\
ANR & 0.2083 & 0.1804 & 0.6905 & 0.2575 & 0.2145 & 0.6817 & 0.2275 & 0.1915 & 0.6960 \\
 & (0.0017) & (0.0014) & (0.0027) & (0.0021) & (0.0017) & (0.0031) & (0.0026) & (0.0018) & (0.0026)\\ 
MTER & 0.2099 & 0.1825 & 0.6889 & 0.2614 & 0.2169 & 0.6809 & 0.2283 & 0.1906 & 0.6967 \\
 & (0.0019) & (0.0014) & (0.0029) & (0.0021) & (0.0016) & (0.0031) & (0.0026) & (0.0017) & (0.0026) \\ \hline
SASRec & 0.2089 & 0.1731 & 0.7005 & 0.2491 & 0.2135 & 0.6897 & 0.2176 & 0.1869 & 0.7025 \\
 & (0.0007) & (0.0006) & (0.0015) & (0.0011) & (0.0009) & (0.0016) & (0.0013) & (0.0008) & (0.0013) \\
DIN & 0.2022 & 0.1709 & 0.7076 & 0.2479 & 0.2116 & 0.6917 & 0.2155 & 0.1853 & 0.7046 \\
 & (0.0009) & (0.0007) & (0.0017) & (0.0009) & (0.0008) & (0.0015) & (0.0009) & (0.0007) & (0.0013) \\
BERT4Rec & 0.2003 & \underline{0.1701} & \underline{0.7085} & 0.2460 & 0.2101 & 0.6928 & 0.2126 & 0.1832 & 0.7088 \\
 & (0.0009) & (0.0006) & (0.0017) & (0.0009) & (0.0008) & (0.0015) & (0.0009) & (0.0008) & (0.0015) \\
UniSRec & 0.2026 & 0.1720 & 0.7066 & 0.2448 & 0.2093 & 0.6956 & 0.2103 & 0.1810 & 0.7133 \\
 & (0.0015) & (0.0010) & (0.0023) & (0.0013) & (0.0011) & (0.0020) & (0.0011) & (0.0009) & (0.0017) \\ \hline
AMCF & 0.2088 & 0.1755 & 0.6989 & 0.2501 & 0.2123 & 0.6928 & 0.2376 & 0.1863 & 0.7035 \\
 & (0.0019) & (0.0013) & (0.0027) & (0.0016) & (0.0013) & (0.0023) & (0.0013) & (0.0010) & (0.0019) \\
PETER & \underline{0.1996} & 0.1715 & 0.7078 & \underline{0.2423} & \underline{0.2071} & 0.7003 & \underline{0.2099} & \underline{0.1770} & \underline{0.7226} \\
 & (0.0019) & (0.0013) & (0.0027) & (0.0015) & (0.0013) & (0.0022) & (0.0013) & (0.0010) & (0.0019) \\ 
UCEPic & 0.2035 & 0.1723 & 0.7066 & 0.2477 & 0.2099 & \underline{0.7018} & 0.2228 & 0.1801 & 0.7080 \\
 & (0.0015) & (0.0011) & (0.0023) & (0.0015) & (0.0012) & (0.0023) & (0.0011) & (0.0009) & (0.0017) \\ 
PARSRec & 0.2008 & 0.1703 & 0.7080 & 0.2471 & 0.2106 & 0.6923 & 0.2133 & 0.1837 & 0.7069 \\
 & (0.0009) & (0.0007) & (0.0017) & (0.0009) & (0.0008) & (0.0015) & (0.0009) & (0.0007) & (0.0013) \\ \hline 
\end{tabular}
}
\caption{Recommendation performance on three datasets. ``\%Improved'' represents the performance gains of LR-Recsys (ours) compared to the best-performing baseline (underlined). Metrics with $\downarrow$ indicate that lower values are better (e.g., RMSE, MAE), while metrics with $\uparrow$ indicate that higher values are better (e.g., AUC). ***p$<$0.01;**p$<$0.05.}
\label{main_results}
\end{table}



\subsection{Understanding the Improvements} 
In this section, we present additional analyses to decompose and better understand the significant performance gains observed with LR-Recsys in the previous section.

\subsubsection{Improved learning efficiency.} 

Based on the theoretical insights discussed in Section \ref{sec:theory}, incorporating explanations into the recommendation process is expected to significantly improve learning efficiency. This implies that our proposed LR-Recsys should require \emph{less} training data to achieve recommendation performance comparable to the baselines. To demonstrate this, we randomly sample subsets of the three datasets, keeping 12\%, 25\%, and 50\% of the original training data, and train LR-Recsys on these subsets while keeping the same test set for evaluation. The results, presented in Table \ref{efficiency}, show that our model achieves performance equivalent to the best-performing baseline, PETER \citep{li2021personalized}, using as little as 25\% of the training data. These findings validate the improved learning efficiency of LR-Recsys, matching the theoretical insights in Section \ref{sec:theory}.

\begin{table}
\centering
\footnotesize
   \setlength\extrarowheight{3pt}
\resizebox{0.95\textwidth}{!}{
\begin{tabular}{|c|ccc|ccc|ccc|} \hline
 & \multicolumn{3}{c|}{TripAdvisor} & \multicolumn{3}{c|}{Yelp} & \multicolumn{3}{c|}{Amazon Movie} \\ \hline
 & RMSE $\downarrow$ & MAE $\downarrow$  & AUC $\uparrow$ & RMSE $\downarrow$ & MAE $\downarrow$ & AUC $\uparrow$ & RMSE $\downarrow$ & MAE $\downarrow$ & AUC $\uparrow$ \\ \hline
 LR-Recsys & 0.1889 & 0.1444 & 0.7289 & 0.2149 & 0.1685 & 0.7229 & 0.1673 & 0.1180 & 0.7500 \\
 100\% Training Data & (0.0010) & (0.0008) & (0.0018) & (0.0010) & (0.0009) & (0.0017) & (0.0010) & (0.0009) & (0.0018) \\ \hline
LR-Recsys & 0.1938 & 0.1503 & 0.7144 & 0.2188 & 0.1774 & 0.7133 & 0.1791 & 0.1308 & 0.7276 \\
 50\% Training Data & (0.0017) & (0.0013) & (0.0029) & (0.0018) & (0.0017) & (0.0031) & (0.0021) & (0.0017) & (0.0033) \\ \hline
LR-Recsys & 0.2017 & 0.1679 & 0.7020 & 0.2356 & 0.1958 & 0.7004 & 0.1997 & 0.1703 & 0.7173 \\
25\% Training Data  & (0.0026) & (0.0021) & (0.0041) & (0.0027) & (0.0027) & (0.0047) & (0.0039) & (0.0028) & (0.0049) \\ \hline
LR-Recsys & 0.2098 & 0.1796 & 0.6912 & 0.2557 & 0.2140 & 0.6822 & 0.2175 & 0.1866 & 0.7015 \\
12\% Training Data & (0.0036) & (0.0030) & (0.0054) & (0.0039) & (0.0038) & (0.0068) & (0.0066) & (0.0044) & (0.0063) \\ \hline
PETER & 0.1996 & 0.1715 & 0.7078 & 0.2423 & 0.2071 & 0.7003 & 0.2099 & 0.1770 & 0.7226 \\
100\% Training Data & (0.0019) & (0.0013) & (0.0027) & (0.0015) & (0.0013) & (0.0022) & (0.0013) & (0.0010) & (0.0019) \\ \hline
\end{tabular}
}
\caption{Recommendation performance across three datasets using varying percentages of training data for LR-Recsys.}
\label{efficiency}
\end{table}

\subsubsection{The gain is from LLM's reasoning capability.}  
\label{res_understanding_reasoning}
The theoretical insights in Section \ref{sec:theory} highlight that the advantage of LR-Recsys lies in leveraging LLMs' strong \emph{reasoning} capabilities to identify the important variables. Therefore, LLMs with better reasoning capabilities are expected to lead to better recommendation performance. To validate this, we conduct additional experiments within the LR-Recsys framework, using different LLMs with varying reasoning capabilities. As shown in Table \ref{llm_models}, the performance of LR-Recsys with Llama 3.1 is significantly better than LR-Recsys with Llama 3, Mixtral-8$\times$7b, Vicuna-7b-v1.5, Qwen2-7B, or GPT-2. This aligns with the reasoning capability leaderboard at \url{https://huggingface.co/spaces/allenai/ZebraLogic}, where Llama 3.1 demonstrates the highest reasoning capabilities among the tested models. Furthermore, Llama 3 and Mixtral-8$\times$7b also outperform Vicuna-7b-v1.5, Qwen2-7B, and GPT-2 in the reasoning leaderboard, which is also aligned with the results observed in LR-Recsys. These results confirm that better \emph{reasoning} capabilities in LLMs directly translate to improved performance within the LR-Recsys framework. 

Moreover, LR-Recsys significantly outperforms an alternative approach that uses LLMs directly for recommendations—without generating explicit explanations (``LLM Direct Recommendation (with Llama 3.1)'' row in Table \ref{llm_models}). This suggests that only using LLMs for recommendation without tapping into their reasoning abilities is insufficient. Additionally, we find that including LLM-generated product profile information plays only a minor role in the overall effectiveness of the model, as LR-Recsys continues to significantly outperform baseline models even when these augmented profiles are removed (``LR-Recsys w/o Profile Augmentation'' row in Table \ref{llm_models}).

Furthermore, we confirm that the observed performance improvements are not due to information leakage or pre-existing dataset knowledge. For example, the Amazon Movie dataset was collected in 2023, while GPT-2 was pre-trained on data available only up to 2019. Despite this, when GPT-2 is used within the LR-Recsys framework, our approach still outperforms other baselines.



Finally, we also tested utilizing LLMs' summarization capabilities instead of their reasoning abilities within LR-Recsys. Specifically, we replace the positive and negative explanation prompts in the contrastive-explanation generator with the following prompt: 
\begin{quote}
\emph{
``Given the profiles of the watching history of this consumer \{movie\_profile\_seq\}, can you provide a summary of the consumer preference of candidate movies?'' 
}
\end{quote} 
In other words, we leverage the LLM's summarization skills to condense the user's consumption history, and then use this summarized information as input to the DNN instead of the positive and negative explanations. As shown in the last row of Table \ref{llm_models} (``Consumption History Summarization''), the performance of using LLM for summarization is significantly worse than that of LR-Recsys using LLM for explanations. This suggests that the gain from LR-Recsys specifically comes from the \emph{reasons} (positive and negative explanations) provided by LLMs, rather than their ability to summarize consumption history.

Collectively, these findings support the conclusion that the performance gains observed with LR-Recsys are primarily driven by the LLMs' reasoning capabilities, \emph{not} their external dataset knowledge or summarization skills.







% To validate this point, we conduct additional experiments in this section, where we implement multiple versions of LLMs with different levels of reasoning capabilities to construct our proposed model, as well as using LLMs directly to produce recommendations (i.e. without explicitly asking for explanations). As we can observe from Table \ref{llm_models}, recommendation performance obtained from using Llama 3.1 is significantly better than that of Llama 3 and Mixtral-8$\times$7b, and even more so than that of Vicuna-7b-v1.5, Qwen2-7B, and GPT-2. This is consistent with the reasoning capability leaderboard shown at \url{https://huggingface.co/spaces/allenai/ZebraLogic}, where Llama 3.1 is shown to possess the best reasoning capability compared to Llama 3 and Mixtral-8$\times$7b. Furthermore, these three LLMs perform significantly better than Vicuna-7b-v1.5, Qwen2-7B, and GPT-2 in terms of reasoning capability. Therefore, our results confirm that better \emph{reasoning} capabilities in LLMs directly translate to improved performance in our LR-Recsys framework. Furthermore, our proposed model also significantly outperforms the alternative model that uses LLM directly for recommendations, since it does not utilize any benefits coming from the LLM's reasoning capability. We can also verify that the incorporation of the LLM-generated product profile information only plays a small part in terms of the effectiveness of our proposed model, since LR-Recsys still significantly outperforms the baseline models even when the LLM-augmented profile is removed (last row in Table \ref{llm_models}). Lastly, we would like to point out that the performance improvements are not a result of the information/knowledge leakage, since one of our offline datasets, Amazon Movie, was collected in 2023, while GPT-2 uses pre-training data prior to 2019. Even when we use the GPT-2 as the backbone model, we can still achieve performance improvements over prior models in the literature.

\begin{table}
\centering
\footnotesize
   \setlength\extrarowheight{3pt}
\resizebox{1.00\textwidth}{!}{
\begin{tabular}{|c|ccc|ccc|ccc|} \hline
 & \multicolumn{3}{c|}{TripAdvisor} & \multicolumn{3}{c|}{Yelp} & \multicolumn{3}{c|}{Amazon Movie} \\ \hline
 & RMSE $\downarrow$ & MAE $\downarrow$ & AUC $\uparrow$ & RMSE $\downarrow$ & MAE $\downarrow$ & AUC $\uparrow$ & RMSE $\downarrow$ & MAE $\downarrow$ & AUC $\uparrow$ \\ \hline
LR-Recsys with \textbf{Llama 3.1} (Ours) & 0.1889 & 0.1444 & 0.7289 & 0.2149 & 0.1685 & 0.7229 & 0.1673 & 0.1180 & 0.7500 \\
 & (0.0010) & (0.0008) & (0.0018) & (0.0010) & (0.0009) & (0.0017) & (0.0010) & (0.0009) & (0.0018) \\ \hline
LR-Recsys with \textbf{Llama 3}  & 0.1934 & 0.1491 & 0.7260 & 0.2166 & 0.1697 & 0.7210 & 0.1695 & 0.1203 & 0.7472 \\
 & (0.0010) & (0.0008) & (0.0018) & (0.0010) & (0.0009) & (0.0017) & (0.0010) & (0.0009) & (0.0018) \\ \hline
LR-Recsys with \textbf{Mixtral-8} $\times$7b & 0.1910 & 0.1462 & 0.7271 & 0.2163 & 0.1693 & 0.7218 & 0.1691 & 0.1199 & 0.7480 \\
 & (0.0010) & (0.0008) & (0.0018) & (0.0010) & (0.0009) & (0.0017) & (0.0010) & (0.0009) & (0.0018) \\ \hline
LR-Recsys with \textbf{Vicuna-7b-v1.5} & 0.1949 & 0.1502 & 0.7243 & 0.2175 & 0.1703 & 0.7196 & 0.1703 & 0.1210 & 0.7455 \\
 & (0.0010) & (0.0008) & (0.0018) & (0.0010) & (0.0009) & (0.0017) & (0.0010) & (0.0009) & (0.0018) \\ \hline
LR-Recsys with \textbf{Qwen2-7B}  & 0.1966 & 0.1520 & 0.7202 & 0.2193 & 0.1724 & 0.7170 & 0.1727 & 0.1235 & 0.7419 \\
 & (0.0010) & (0.0008) & (0.0018) & (0.0010) & (0.0009) & (0.0017) & (0.0010) & (0.0009) & (0.0018) \\ \hline
LR-Recsys with \textbf{GPT-2}  & 0.1940 & 0.1582 & 0.7169 & 0.2211 & 0.1801 & 0.7144 & 0.1799 & 0.1304 & 0.7288 \\
 & (0.0014) & (0.0010) & (0.0023) & (0.0015) & (0.0013) & (0.0023) & (0.0015) & (0.0013) & (0.0024) \\ \hline
LLM Direct Recommendation (with Llama 3.1)& 0.2233 & 0.1838 & 0.6735 & 0.2976 & 0.2402 & 0.6528 & 0.2680 & 0.2055 & 0.6736 \\
 & (0.0033) & (0.0020) & (0.0036) & (0.0044) & (0.0029) & (0.0046) & (0.0046) & (0.0031) & (0.0055) \\ \hline
LR-Recsys w/o Profile Augmentation & 0.1973 & 0.1520 & 0.7211 & 0.2193 & 0.1719 & 0.7173 & 0.1744 & 0.1239 & 0.7430 \\
 & (0.0013) & (0.0011) & (0.0021) & (0.0012) & (0.0012) & (0.0021) & (0.0013) & (0.0012) & (0.0021) \\ \hline
Consumption History Summarization & 0.1971 & 0.1700 & 0.7055 & 0.2409 & 0.2051 & 0.6990 & 0.2077 & 0.1751 & 0.7236 \\
 & (0.0011) & (0.0008) & (0.0018) & (0.0011) & (0.0009) & (0.0017) & (0.0011) & (0.0010) & (0.0018) \\ \hline
\end{tabular}
}
\caption{Recommendation performance across three datasets using LLMs with varying levels of reasoning capability.}
\label{llm_models}
\end{table}

\subsubsection{``Harder'' examples benefit more from LR-Recsys.} 
% Harder Examples Benefit More.

By leveraging LLMs' reasoning capabilities to identify important variables, LR-Recsys should intuitively provide greater benefits for ``harder'' examples where consumers' decisions are less obvious. To test this hypothesis, we compute the prediction uncertainty for each observation in our datasets, measured as the variance—or “disagreement”—across the predictions made by our model and all baseline models from Table \ref{main_results}. Intuitively, higher prediction uncertainty indicates a more challenging, or ``harder'', prediction task.

In Fig.\ref{fig:uncertainty}, we created plots for each dataset, where the x-axis represents the normalized uncertainty level (scaled between 0 and 1 using min-max normalization \citep{patro2015normalization}), and the y-axis represents the performance improvement of our LR-Recsys over the best-performing baseline (measured by RMSE). As shown by the regression lines in Figures \ref{fig:uncertainty:amazon}, \ref{fig:uncertainty:tripadvisor}, and \ref{fig:uncertainty:yelp}, there is a statistically significant \emph{positive correlation} between uncertainty and performance improvements. Specifically, the performance gains from incorporating explanations are consistently larger for high-uncertainty examples across all three datasets, validating the insight that our LR-Recsys is more beneficial for examples that are ``harder'' or more uncertain.

This observation aligns with the theoretical insights in Section \ref{sec:theory}. For ``harder'' examples, the model is likely uncertain about which input variables to rely on for making predictions, leading to higher prediction uncertainty. In such cases, the knowledge provided by LLMs about the important variables becomes particularly valuable, allowing the model to focus on the most relevant features. Consequently, the performance gains of our LR-Recsys are larger for these more challenging cases.

\begin{figure}[hbtp!]
% \vspace{-0.2in}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/uncertainty_line.jpg}
        \caption{Amazon Dataset.}
        \label{fig:uncertainty:amazon}
    \end{subfigure}
    \hspace{0.5mm}
     \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/hotel_uncertainty_line.jpg}
        \caption{TripAdvisor Dataset.}
        \label{fig:uncertainty:tripadvisor}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/restaurant_uncertainty_line.jpg}
        \caption{Yelp Dataset.}
        \label{fig:uncertainty:yelp}
    \end{subfigure}
   \caption{Performance improvement of LR-Recsys against (normalized) pediction uncertainty.}
  \label{fig:uncertainty}
% \vspace{-0.2in}
\end{figure}


% \begin{figure}[hbtp!]
% \centering
% \includegraphics[width=0.5\linewidth]{figures/uncertainty_line.jpg}
% \caption{Uncertainty Analysis for the Amazon Dataset}\label{fig:uncertainty:amazon}
% \vspace{-0.2in}
% \end{figure}

% \begin{figure}[hbtp!]
% \centering
% \includegraphics[width=0.5\linewidth]{figures/hotel_uncertainty_line.jpg}
% \caption{Uncertainty Analysis for the TripAdvisor Dataset}\label{fig:uncertainty:tripadvisor}
% \vspace{-0.2in}
% \end{figure}

% \begin{figure}[hbtp!]
% \centering
% \includegraphics[width=0.5\linewidth]{figures/restaurant_uncertainty_line.jpg}
% \caption{Uncertainty Analysis for the Yelp Dataset}\label{fig:uncertainty:yelp}
% \vspace{-0.2in}
% \end{figure}

\subsection{Understanding the Role of Contrastive Explanations} 
\label{sec:role_pos_neg}
% We conducted additional analysis to understand how both the positive explanations and the negative explanations contribute to the significant performance improvements from LR-Recsys. To begin with, we implement four variants of our proposed model and test their performance respectively: (1) \textbf{Aspect Terms Only}, where we use the LLM to generate only a few aspect terms that represent the most important properties of the candidate item that the consumer might consider, rather than ask for explicit explanations by leveraging LLM's reasoning capability; (2) \textbf{Positive Explanations Only}, where we use the LLM to generate only positive explanations (without negative explanations); (3) \textbf{General Explanations Only}, where we let the LLM to infer whether the use may or may not like the product, and generate the associated explanations accordingly; and (4) \textbf{Purchashing History Summarization}, where we use the LLM to summarize the purchasing history of the user and use the summarized information for producing recommendations, rather than generating the explanations for recommendations. The results are summarized in Table \ref{generation}. As we can observe from Table \ref{generation}, all of these variants do not perform as well as our proposed LR-Recsys, demonstrating the significant role of both the positive and the negative explanations.

\subsubsection{The need for both positive and negative explanations.} 
\label{sec:dual_explanation}

We conducted analyses to understand how explanations, and in particular both positive and negative explanations, contribute to the significant performance improvements of LR-Recsys. We compared three variants of the contrastive-explanation generator in LR-Recsys:
(1) \textbf{Aspect Terms Only}: The LLM only generates a few aspect terms representing the most important properties of the candidate item that the consumer might consider, without leveraging explicit reasoning-based explanations;
(2) \textbf{Positive Explanations Only}: The LLM generates only positive explanations;
(3) \textbf{General Explanations Only}: The LLM infers whether the user may or may not like the product and generates corresponding general explanations, without distinguishing between positive and negative reasoning;
% (4) \textbf{Purchasing History Summarization}: The LLM summarizes the user's purchasing history and uses this summarized information instead of the generated explanations as input to the DNN.

The detailed prompts used for each variant are listed in Appendix \ref{appen:variants_prompt}. The results, summarized in Table \ref{generation}, show that none of these variants match the performance of our proposed LR-Recsys with the contrastive-explanation generator. This confirms the value of incorporating both positive and negative explanations to improve predictive performance.


\begin{table}
\centering
\footnotesize
   \setlength\extrarowheight{3pt}
\resizebox{0.95\textwidth}{!}{
\begin{tabular}{|c|ccc|ccc|ccc|} \hline
 & \multicolumn{3}{c|}{TripAdvisor} & \multicolumn{3}{c|}{Yelp} & \multicolumn{3}{c|}{Amazon Movie} \\ \hline
 & RMSE $\downarrow$ & MAE $\downarrow$ & AUC $\uparrow$ & RMSE $\downarrow$ & MAE $\downarrow$ & AUC $\uparrow$ & RMSE $\downarrow$ & MAE $\downarrow$ & AUC $\uparrow$ \\ \hline
LR-Recsys (Ours) & \textbf{0.1889} & \textbf{0.1444} & \textbf{0.7289} & \textbf{0.2149} & \textbf{0.1685} & \textbf{0.7229} & \textbf{0.1673} & \textbf{0.1180} & \textbf{0.7500} \\
 & (0.0010) & (0.0008) & (0.0018) & (0.0010) & (0.0009) & (0.0017) & (0.0010) & (0.0009) & (0.0018) \\ \hline
Aspect Terms Only & 0.1975 & 0.1709 & 0.7071 & 0.2413 & 0.2053 & 0.6991 & 0.2083 & 0.1757 & 0.7243 \\
 & (0.0010) & (0.0008) & (0.0018) & (0.0010) & (0.0009) & (0.0017) & (0.0011) & (0.0010) & (0.0018) \\ \hline
Positive Explanations Only & 0.1928 & 0.1480 & 0.7258 & 0.2179 & 0.1708 & 0.7168 & 0.1703 & 0.1209 & 0.7456 \\
 & (0.0010) & (0.0008) & (0.0018) & (0.0010) & (0.0009) & (0.0018) & (0.0010) & (0.0009) & (0.0018) \\ \hline
General Explanations Only & 0.1961 & 0.1633 & 0.7006 & 0.2499 & 0.2279 & 0.6710 & 0.2136 & 0.1797 & 0.7076 \\
 & (0.0014) & (0.0010) & (0.0023) & (0.0015) & (0.0016) & (0.0023) & (0.0015) & (0.0013) & (0.0027) \\ \hline
% Purchasing History Summarization & 0.1971 & 0.1700 & 0.7055 & 0.2409 & 0.2051 & 0.6990 & 0.2077 & 0.1751 & 0.7236 \\
%  & (0.0011) & (0.0008) & (0.0018) & (0.0011) & (0.0009) & (0.0017) & (0.0011) & (0.0010) & (0.0018) \\ \hline
\end{tabular}
}
\caption{Recommendation performance across three datasets using LLMs for alternative generation tasks.}
\label{generation}
\end{table}


\subsubsection{Attention weights on positive and negative explanations.} 
\label{sec:attention_analysis}

% For the classification task, the goal of the recommender system is to predict whether a consumer will give a high rating to a particular product. In Sections \ref{sec:main_results} and \ref{sec:dual_explanation}, we demonstrated that both positive and negative explanations contribute to the improved prediction accuracy of this task. 

We further analyze the contribution of each type of explanation to different predictions. One hypothesis is that high ratings depend more on positive explanations (i.e., reasons the consumer likes the product), while low ratings depend more on negative explanations (i.e., reasons the consumer does not like the product).

To test this, we conduct an \emph{attention value analysis} to quantify the contributions of positive and negative explanations to the classification task. The attention value for the positive explanation ${\bar{\alpha}}_{pos}$ is computed as the average of all the relevant pairwise attention values in the attention layer of the DNN component. Following the notation in Section \ref{sec:framework_dnn_loss}, we define:
\begin{equation}
\label{eq:alpha_pos_neg}
\begin{aligned}
{\bar{\alpha}}_{pos} &= \frac{1}{|I|}{\sum_{i\in I}\alpha_{i, pos}}, \;\;\;\;\;
{\bar{\alpha}}_{neg} &= \frac{1}{|I|}{\sum_{i\in I}\alpha_{i, neg}},
\end{aligned}
\end{equation}
where $I = [\text{pos}, \text{neg}, c, p, \text{seq}, \text{context}]$ represents the index set corresponding to each element in the input $X_{\text{input}}$. In other words, ${\bar{\alpha}}_{pos}$ captures the average ``attention'' that the model puts on the positive explanation embedding when generating the final prediction, and ${\bar{\alpha}}_{neg}$ captures the average ``attention'' put on the negative explanation embedding. Therefore, ${\bar{\alpha}}_{pos}$ and ${\bar{\alpha}}_{neg}$ estimates the relative importance of the positive and negative explanations in producing the final recommendation results. 

% We visualize the distribution of attention values ${\bar{\alpha}}_{pos}$ and ${\bar{\alpha}}_{neg}$ across three datasets in Fig.\ref{fig:attention}. The results show that when a product receives a high rating, LR-Recsys assigns \emph{more} attention to positive explanations than negative ones, as indicated by the distribution of attention weights for positive explanations (blue bars) being skewed further to the \emph{right} compared to negative explanations (orange bars) (Fig.\ref{fig:positive:yelp}, \ref{fig:positive:amazon}, and \ref{fig:positive:tripadvisor}). Conversely, for products receiving a low rating, LR-Recsys assigns more attention to negative explanations, with the distribution of attention weights for positive explanations shifting further to the \emph{left} compared to negative explanations (Fig. \ref{fig:negative:yelp}, \ref{fig:negative:amazon}, and \ref{fig:negative:tripadvisor}). In Appendix \ref{appen:attn_pie_charts}, we also plot the distribution of the attenion values on the other input components (i.e. consumer, item and context embeddings) and find that these explanations together account for a significant (30-40\%) of total model attention values.

% 
We visualize the distribution of attention values on positive explanations (${\bar{\alpha}}_{pos}$) and negative explanations (${\bar{\alpha}}_{neg}$) for the Yelp Dataset in Fig.\ref{fig:attention}, while the results for all three datasets are provided in Appendix \ref{appen:attn_pos_neg}. The results across all three datasets consistently show that when a product receives a high rating, LR-Recsys assigns \emph{more} attention to positive explanations than negative ones, as indicated by the distribution of attention weights for positive explanations (blue bars) being skewed further to the \emph{right} compared to negative explanations (orange bars) (Fig.\ref{fig:positive:yelp}). Conversely, for products receiving a low rating, LR-Recsys assigns more attention to negative explanations, with the distribution of attention weights for positive explanations shifting further to the \emph{left} compared to negative explanations (Fig. \ref{fig:negative:yelp},). In Appendix \ref{appen:attn_pie_charts}, we also plot the distribution of attention values on other input components (i.e., consumer, item, and context embeddings) and find that these explanations together account for a significant (30-40\%) of total attention values. 

The insights from these plots are significant. In addition to confirming the importance of both types of explanations in generating predictions, the separation of attention weight distributions between positive and negative explanations highlights how LR-Recsys effectively leverages contrastive explanations for the prediction task. Across all three datasets, we observe that positive predictions rely more on positive explanations, while negative predictions depend more on negative explanations. This behavior is intuitive: When a product is predicted to receive a high rating, the framework selectively focuses on positive explanations (reasons the consumer may like the product); conversely, when a product is predicted to receive a low rating, the framework is focused on negative explanations (reasons the consumer may \emph{not} like the product). By providing both positive and negative explanations through the contrastive-explanation generator, LR-Recsys is able to intelligently decide which type of explanation to rely on, in order to generate the most accurate predictions. This explains why both types of explanations are critical for the prediction, and why LR-Recsys outperforms other LLM-based recommendation system variants as demonstrated above.

% when producing positive recommendations, the recommender system will pay more attention to positive explanations, as evidenced by their higher attention values compared to the negative explanations; similarly, when producing negative recommendations, the recommender system will pay more attention to negative explanations. Therefore, both explanations are indeed crucial components for determining the final decisions of the recommendation model.

\begin{figure}[hbtp!]
% \vspace{-0.2in}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/restaurant_positive_record.jpg}
        \caption{Positive examples (Yelp Dataset).}
        \label{fig:positive:yelp}
    \end{subfigure}
    \hspace{0.5mm}
     \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/restaurant_negative_record.jpg}
        \caption{Negative examples (Yelp Dataset).}
        \label{fig:negative:yelp}
    \end{subfigure}
    
    % \begin{subfigure}[b]{0.45\textwidth}
    %     \centering
    %     \includegraphics[width=\textwidth]{figures/movie_positive_record.jpg}
    %     \caption{Positive examples (Amazon Movie Dataset).}
    %     \label{fig:positive:amazon}
    % \end{subfigure}
    % \hspace{0.5mm}
    %  \centering
    % \begin{subfigure}[b]{0.45\textwidth}
    %     \centering
    %     \includegraphics[width=\textwidth]{figures/movie_negative_record.jpg}
    %     \caption{Negative examples (Amazon Movie Dataset).}
    %     \label{fig:negative:amazon}
    % \end{subfigure}
    
    % \begin{subfigure}[b]{0.45\textwidth}
    %     \centering
    %     \includegraphics[width=\textwidth]{figures/hotel_positive_record.jpg}
    %     \caption{Positive examples (TripAdvisor Dataset).}
    %     \label{fig:positive:tripadvisor}
    % \end{subfigure}
    % \hspace{0.5mm}
    %  \centering
    % \begin{subfigure}[b]{0.45\textwidth}
    %     \centering
    %     \includegraphics[width=\textwidth]{figures/hotel_negative_record.jpg}
    %     \caption{Negative examples (TripAdvisor Dataset).}
    %     \label{fig:negative:tripadvisor}
    % \end{subfigure}
    
   \caption{(Color online) Distribution of attention values on positive and negative explanations for positive and negative examples.}
  \label{fig:attention}
% \vspace{-0.2in}
\end{figure}

% \begin{figure}[hbtp!]
% \centering
% \includegraphics[width=0.5\linewidth]{figures/movie_positive_record.jpg}
% \caption{Attention Value Analysis Positive Explanations in the Amazon Dataset}\label{fig:positive:amazon}
% \vspace{-0.2in}
% \end{figure}

% \begin{figure}[hbtp!]
% \centering
% \includegraphics[width=0.5\linewidth]{figures/movie_negative_record.jpg}
% \caption{Attention Value Analysis Negative Explanations in the Amazon Dataset}\label{fig:negative:amazon}
% \vspace{-0.2in}
% \end{figure}

% \begin{figure}[hbtp!]
% \centering
% \includegraphics[width=0.5\linewidth]{figures/restaurant_positive_record.jpg}
% \caption{Attention Value Analysis Positive Explanations in the Yelp Dataset}\label{fig:positive:yelp}
% \vspace{-0.2in}
% \end{figure}

% \begin{figure}[hbtp!]
% \centering
% \includegraphics[width=0.5\linewidth]{figures/restaurant_negative_record.jpg}
% \caption{Attention Value Analysis Negative Explanations in the Yelp Dataset}\label{fig:negative:yelp}
% \vspace{-0.2in}
% \end{figure}

% \begin{figure}[hbtp!]
% \centering
% \includegraphics[width=0.5\linewidth]{figures/hotel_positive_record.jpg}
% \caption{Attention Value Analysis Positive Explanations in the TripAdvisor Dataset}\label{fig:positive:tripadvisor}
% \vspace{-0.2in}
% \end{figure}

% \begin{figure}[hbtp!]
% \centering
% \includegraphics[width=0.5\linewidth]{figures/hotel_negative_record.jpg}
% \caption{Attention Value Analysis Negative Explanations in the TripAdvisor Dataset}\label{fig:negative:tripadvisor}
% \vspace{-0.2in}
% \end{figure}


\subsubsection{Actionable business insights from aggregated contrastive explanations.} 
\label{sec:actionable_insights}

Another benefit of LR-Recsys is its ability to provide actionable insights for business owners or content creators. For instance, we aggregate all positive and negative explanations associated with a specific restaurant, Siam Thai Kitchen, from the Yelp dataset. A summary of the top keywords (based on word frequencies) reveals that the restaurant excels at offering an authentic Thai dining experience. However, the negative explanations highlight opportunities for improvement, such as expanding the menu with healthier, more upscale options to attract a broader audience. These actionable insights, generated through contrastive explanations in LR-Recsys, are not possible with traditional black-box recommender systems.
\newline
% Another benefit of LR-Recsys is its potential to provide actionable insights for business owners or content creators. As an example, we collect all interaction records associated with a specific restaurant, Siam Thai Kitchen, in the Yelp dataset, and aggregate all of the positive and negative explanations generated in our LR-Recsys framework.

% A summary of the top keywords, based on word frequencies in the generated explanations, is listed below. We see that the restaurant is doing well in terms of offering a unique and authentic Thai dining experience. However, the negative explanations also suggest opportunities for improvement, such as improving its menu to include healthier and more upscale options to attract more consumers. Such actionable insights are not possible with traditional black-box recommender systems, but are made possible by the contrastive explanations generated through our LR-Recsys framework.



\fbox{%
    \parbox{\textwidth}{%
\textbf{Restaurant Name}: Siam Thai Kitchen

\textbf{Restaurant Profile}: ''Siam Thai Kitchen is a Thai restaurant that offers a unique dining experience in the city. The restaurant is known for its authentic Thai cuisine and its warm and inviting atmosphere. The menu features a variety of traditional Thai dishes, as well as some modern twists on classic Thai flavors. The restaurant is perfect for couples, families, and groups of friends who are looking for a delicious and authentic Thai dining experience.''

\textbf{Top Keywords in Positive Explanations}: Unique, Thai, Traditional, Atmosphere, Dining, Experience, Service, Authentic

\textbf{Top Keywords in Negative Explanations}: Healthy, Luxurious, Fine Dining, Upscale, Quick, Snack, Modern 
    }%
}
\newline


\subsection{Ablation Studies and Robustness Checks}
We conduct a series of additional ablation studies and robustness checks to further demonstrate the effectiveness and generalizability of LR-Recsys. We provide the detailed results in Appendix \ref{appen:ablation_robustness}.



\begin{comment}
\subsection{Descriptive analysis of the generated explanations} \hfill\\
\todo{use LLM to summarize}

Profile Prompt: ''Create a succinct profile for a hotel based on its name. This profile should be tailored for use in recommendation systems and must identify the types of consumers who would enjoy the hotel.''

Input: ''Hilton Newark Airport''

Output: ''Stay at the Hilton Newark Airport and experience a comfortable and convenient stay. Ideal for business and leisure travelers, this hotel is located just minutes away from the airport and offers easy access to the city's top attractions. Enjoy the hotel's amenities, including a fitness center, restaurant, and bar.''

Explanation Prompt: ''Given the profiles of restaurants visited by this consumer in the past, can you provide a reason for why this consumer watched the following recommended movie with the following profile? Answer with one sentence with the following format: The consumer visited this restaurant because''

Positive Explanation Output: The consumer visited this restaurant because the consumer is looking for a unique and flavorful dining experience and the restaurant offers a variety of Asian cuisine.

Negative Explanation Output: The consumer did not visit this restaurant because the consumer is looking for a traditional Japanese experience and wants to escape the busy city life and the restaurant is not a traditional Japanese experience and is located in a city.

\todo{Pan: any description analysis / summary statistics you can show here to give insights on (1) what are common positive explanations, and (2) what are common negative explanations? }
\end{comment}