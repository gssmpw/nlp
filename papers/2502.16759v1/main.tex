%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Author template for Operations Reseacrh (opre) for articles with no e-companion (EC)
%% Mirko Janc, Ph.D., INFORMS, mirko.janc@informs.org
%% ver. 0.95, December 2010
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \documentclass[fleqn,mksc,blindrev]{informs4}
% \documentclass[fleqn,mksc,nonblindrev]{informs4}
\documentclass[fleqn,nonblindrev]{informs4}
%%\documentclass[opre,nonblindrev]{informs3_modified} % current default for manuscript submission

\OneAndAHalfSpacedXI % current default line spacing
%\OneAndAHalfSpacedXII
%\DoubleSpacedXII
%%\DoubleSpacedXI

% If hyperref is used, dvi-to-ps driver of choice must be declared as
%   an additional option to the \documentclass. For example
%\documentclass[dvips,opre]{informs3}      % if dvips is used
%\documentclass[dvipsone,opre]{informs3}   % if dvipsone is used, etc.

%%% OPRE uses endnotes. If you do not use them, put a percent sign before
%%% the \theendnotes command. This template does show how to use them.
\usepackage{endnotes}
\let\footnote=\endnote
% \let\enotesize=\normalsize
\let\enotesize=\small   % Yuyan's change
\def\notesname{Endnotes}%
\def\makeenmark{$^{\theenmark}$}
\def\enoteformat{\rightskip0pt\leftskip0pt\parindent=1.75em
	\leavevmode\llap{\theenmark.\enskip}}

% Private macros here (check that there is no clash with the style)
% figure packages
\usepackage{graphicx}
\usepackage{eqndefns-left}
\usepackage{multirow}
\usepackage{hhline}

% caption package
\usepackage[small, margin=1cm]{caption}

% appendix package
\usepackage{appendix}
% color packages
\usepackage{color}
\definecolor{strcolor}{rgb}{0.6, 0.2, 0.6}
\definecolor{commentcolor}{rgb}{0.3125, 0.5, 0.3125}
\definecolor{keycol}{rgb}{0, 0, 1}


% revision
\newcommand{\rev}[1]{{\color{red} #1}}
\newcommand{\minminc}[1]{{\color{blue} #1}}
\newcommand{\yuyan}[1]{{\color{purple} #1}}

% math packages
%\usepackage{amssymb}
%\usepackage{amsmath}
\usepackage{bbm}

% Code package
\usepackage{listings}
\lstset{
	emph={ROVar, ROUn, ROVarDR, ROExpr, RONormInf, RONorm1, RONorm2,ROConstraint,ROExpect, ROSq, ROConstraintSet,ROIntVar,ROBinVar, ROInfinity,ROModel,ROVarDRArray, ROVarArray, ROMinimize,ROUnArray, ROAbs, ROPos, ROSum, int},emphstyle={\color{strcolor}\bfseries},
	keywordstyle={\color{blue}\bfseries},
	commentstyle={\color{commentcolor}},
	stringstyle={\color{strcolor}\bfseries},
	language=C++,                % choose the language of the code
	basicstyle={\ttfamily\footnotesize}, % the size of the fonts that are used for the code
	numbers=left,                   % where to put the line-numbers
	numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
	stepnumber=1,                   % the step between two line-numbers. If it's 1 each line will be numbered
	numbersep=5pt,                  % how far the line-numbers are from the code
	backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
	showspaces=false,               % show spaces adding particular underscores
	showstringspaces=false,         % underline spaces within strings
	showtabs=false,                 % show tabs within strings adding particular underscores
	frame=single,	                	% adds a frame around the code
	tabsize=2,	                		% sets default tabsize to 2 spaces
	captionpos=b,                   % sets the caption-position to bottom
	breaklines=true,                % sets automatic line breaking
	breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
	escapeinside={\%*}{*)},         % if you want to add a comment within your code
	keywords=[1]{for, break, if, else, function}
}
\renewcommand{\lstlistingname}{Code Segment}

% hyperlinks packages
%\usepackage{hyperref}
\usepackage{url}

% numbering
%\numberwithin{equation}{section}
%\numberwithin{table}{section}
%\numberwithin{figure}{section}

% Equation environments
\newcommand {\bea}{\begin{eqnarray}}
	\newcommand {\eea}{\end{eqnarray}}
% \newcommand {\E}[1]{\mathrm{E}\left( #1 \right)}
\newcommand {\Ep}[2]{{\mathrm{E}_{\mathbb{P}_{#1}} \left( #2 \right)}}
\newcommand {\supEp}[1]{\displaystyle \sup_{\mathbb{P} \in \mathbb{F}} \Ep{}{#1}}
\newcommand {\supEpf}[2]{\displaystyle \sup_{\mathbb{P} \in \mathbb{F}_{#1}} \Ep{}{#2}}
\newcommand {\pos}[1]{\paren{#1}^+}
\renewcommand {\neg}[1]{\paren{#1}^-}
\newcommand {\pibound}[1]{\ensuremath{\pi^{#1}\paren{r^0, \mb{r}}}}
\newcommand {\etabound}[1]{\ensuremath{\eta^{#1}\paren{r^0, \mb{r}}}}
\newcommand \conv {\mathrm{conv}}
\newcommand {\p}{{\rm P}}
% mb
\newcommand{\mb}[1]{\mbox{\boldmath \ensuremath{#1}}}
\newcommand{\mbt}[1]{\mb{\tilde{#1}}}
\newcommand{\mbb}[1]{\mb{\bar{#1}}}
\newcommand{\mbbs}[1]{\mbb{\scriptstyle{#1}}}
\newcommand{\mbh}[1]{\mb{\hat{#1}}}
\newcommand{\mbth}[1]{\mbt{\hat{#1}}}
\newcommand{\mbc}[1]{\mb{\check{#1}}}
\newcommand{\mbtc}[1]{\mbt{\check{#1}}}
\newcommand{\mbs}[1]{\mb{\scriptstyle{#1}}}
\newcommand{\mbst}[1]{\mbs{\tilde{#1}}}
\newcommand{\mbsh}[1]{\mbs{\hat{#1}}}
% mc
%\newcommand{\mc}[1]{\mbox{\ensuremath{\mathcal{#1}}}}
\newcommand{\mch}[1]{\hat{\mc{#1}}}
\newcommand{\mcs}[1]{\mc{\scriptstyle{#1}}}
\newcommand{\mcss}[1]{\mc{\scriptscriptstyle{#1}}}
\newcommand{\mcsh}[1]{\hat{\mcs{#1}}}
\newcommand{\mbss}[1]{{\mbox{\boldmath \tiny{$#1$}}}}
\newcommand{\eucnorm}[1]{\left\| #1 \right\|_2}
\newcommand{\dpv}{\displaystyle \vspace{3pt}}
\newcommand{\diag}[1]{\textbf{diag}\paren{#1}}
\newcommand{\yldrk}{\mb{y}^k\paren{\mbt{z}}}
\newcommand{\abs}[1]{\left| #1 \right|}
\DeclareMathOperator{\CVaR}{CVaR}
\DeclareMathOperator{\VaR}{VaR}
%\DeclareMathOperator{\argmin}{\arg\min}
% combinations
\renewcommand{\mbc}[1]{\mb{\mc{#1}}}
%misc
\newcommand{\ceil}[1]{\left\lceil #1  \right\rceil}

% \newtheorem{theorem}{Theorem}
% \newtheorem{lemma}[theorem]{Lemma}
\newtheorem{conj}{Conjecture}
\newtheorem{coro}{Corollary}
%\newtheorem{claim}{Claim}
\newtheorem{Defi}{Definition}
\newtheorem{algorithm}{Algorithm}
%\newtheorem{assumption}{Assumption}

\newcommand{\eg}{\textit{e.g.}}
\newcommand{\ie}{\textit{i.e.}}
\renewcommand{\Re}{\mathbb{R}}

%\renewcommand{\bigtimes}{\mathop{\rm \text{\Large{$\times$}}}}

\def\blot{\quad \mbox{$\vcenter{ \vbox{ \hrule height.4pt
				\hbox{\vrule width.4pt height.9ex \kern.9ex \vrule width.4pt}
				\hrule height.4pt}}$}}

% Natbib setup for author-year style
\usepackage{natbib}
\bibpunct[, ]{(}{)}{,}{a}{}{,}%
\def\bibfont{\fontsize{8}{9.5}\selectfont}%
\def\bibsep{0pt}%
\def\bibhang{16pt}%
\def\newblock{\ }%
\def\BIBand{and}%

% Pan's version from online:
% % Natbib setup for author-number style
% \usepackage{natbib}
%  \bibpunct[, ]{(}{)}{,}{a}{}{,}%
%  \def\bibfont{\small}%
%  \def\bibsep{\smallskipamount}%
%  \def\bibhang{24pt}%
%  \def\newblock{\ }%
%  \def\BIBand{and}%

%Yuyan's additions
\def\todo#1{\textcolor{red}{TODO: #1}}
\input{math_commands.tex}
\newcommand{\prob}[1]{P\left(#1\right)}
\usepackage{amsmath}
\usepackage{algorithm,algorithmic}
 \usepackage{subcaption}
\renewcommand{\algorithmiccomment}[1]{\bgroup\hfill//~#1\egroup}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\usepackage{multirow, booktabs}

\usepackage{listings}
\lstset{
basicstyle=\small\ttfamily,
keywordstyle=\small\ttfamily,
columns=flexible,
breaklines=true
}

%% Setup of theorem styles. Outcomment only one.
%% Preferred default is the first option.
\TheoremsNumberedThrough     % Preferred (Theorem 1, Lemma 1, Theorem 2)
%\TheoremsNumberedByChapter  % (Theorem 1.1, Lema 1.1, Theorem 1.2)
\ECRepeatTheorems

%% Setup of the equation numbering system. Outcomment only one.
%% Preferred default is the first option.
\EquationsNumberedThrough    % Default: (1), (2), ...
% \EquationsNumberedBySection % (1.1), (1.2), ...

% In the reviewing and copyediting stage enter the manuscript number.
%\MANUSCRIPTNO{} % When the article is logged in and DOI assigned to it,
%   this manuscript number is no longer necessary

%\newdimen\setvrulersecondcolumnheightdimen%
%\newbox\setvrulersecondcolumnheightdimenbox%
%%%%%%%%%%%%%%%%%
\gdef\AQ#1{}
\gdef\CQ#1{}
%\setvruler [][1][1][1][1][5pt][5pt][0pt][\textheight]
\begin{document}
	%%%%%%%%%%%%%%%%
	
%	\AIA
% \setcounter{page}{1} %
% \VOL{00}%
% \NO{0}%
% \MONTH{Xxxxx}%
% \YEAR{2017}%
% \FIRSTPAGE{1}%
% \LASTPAGE{16}%
% \FIRSTPAGEAIA{1}%
% \LASTPAGEAIA{16}%
\def\COPYRIGHTHOLDER{INFORMS}%
\def\COPYRIGHTYEAR{2017}%
\def\DOI{\fontsize{7.5}{9.5}\selectfont\sf\bfseries\noindent https://doi.org/10.1287/opre.2017.1714\CQ{Word count = 9740}}
%\def\RECEIVED{November 1, 2016}
%\def\REVISED{June 22, 2017; October 6, 2017}
%\def\ACCEPTED{November 15, 2017}
% \PUBONLINEAIA{}

\RUNAUTHOR{Wang et~al.} %

\RUNTITLE{The Blessing of Reasoning: LLM-Based Contrastive Explanations in Black-Box Recommender Systems}
\TITLE{The Blessing of Reasoning: LLM-Based Contrastive Explanations in Black-Box Recommender Systems}


% A: The Blessing of Explainability: Leveraging LLM Reasoning in Black-Box Recommender Systems
% B: Combining the power of LLMs and DNNs: A Framework for Reasoning-Based Recommendations
% The Blessing of Reasoning: The Value of LLM-Generated Explanations in Black-Box Recommender Systems 
% The Blessing of Explainability: The Value of LLMs' Explanations in Black-Box Recommender Systems 
% The Blessing of Explainability: Leveraging LLM Reasoning in Black-Box Recommender Systems
% The Blessing of Explainability through Large Language Models: The Value of Explanations in Black-Box Recommender Systems
% \todo{Title focus on improve recsys preformance, also improves learning efficiency (i.e. needs fewer examples), maybe something like "LLMs reasoning capability helps design better recsys"}
% The Blessing of Reasoning: The Value of LLM-Generated Explanations in Black-Box Recommender Systems


% \TITLE{Embracing Explainability through LLMs: improves recsys performance}

	
	% Block of authors and their affiliations starts here:
	% NOTE: Authors with same affiliation, if the order of authors allows,
	%   should be entered in ONE field, separated by a comma.
	%   \EMAIL field can be repeated if more than one author

\ARTICLEAUTHORS{
%		\AUTHOR{Jianzhe Zhen,\textsuperscript{a,*} Dick den
%		Hertog,\textsuperscript{a} Melvyn Sim\textsuperscript{b}} 
%\AFF{$^{a}$Department of Econometrics and Operations Research,
%Tilburg University; $^{b}$NUS Business School, National University of
%Singapore}

\AUTHOR{Yuyan Wang\textsuperscript{1}, Pan Li\textsuperscript{2}, Minmin Chen\textsuperscript{3}}
\AFF{\textsuperscript{1}Stanford Graduate School of Business, \textsuperscript{2}Sheller College of Business, Georgia Institute of Technology, \textsuperscript{3}Google, Inc.}


% \AUTHOR{Yuyan Wang}
% \AFF{Stanford Graduate School of Business}

% \AUTHOR{Pan Li}
% \AFF{Sheller College of Business, Georgia Institute of Technology}

% \AUTHOR{Minmin Chen}
% \AFF{Google, Inc.}

%\AUEXTRA{$^{*}$Corresponding author}

%\AFFmail{{\bf Contact:} j.zhen@tilburguniversity.edu,
%d.denhertog@tilburguniversity.edu,\\			melvynsim@nus.edu.sg}%
}
	 % end of the block
	
%\ARTICLEINFO{\textbf{Received:} November 1, 2016\\ \textbf{Revised:} June 22, 2017; October 6, 2017\\ \textbf{Accepted:} November 15, 2017\\ \textbf{Published Online in Articles in Advance:}}

\ABSTRACT{
% Modern recommender systems predict consumer preferences based on consumption history  using machine learning (ML) models. Being black-box in nature, these models rely mostly on data correlations to make predictions, resulting in limited explainability. At the same time, research in explainable AI indicates that enforcing explainability often hurts predictive performance due to reduced model flexibility. In this work, we show that it is possible to improve both explainability and predictive performance by combining large language models (LLMs) with deep neural networks (DNNs).  

% We propose \emph{LR-Recsys}, an LLM-Reasoning-Powered Recommender System, that augments state-of-the-art DNN-based recommender systems with LLMs' reasoning capability. LR-Recsys introduces a contrastive explanation generator that leverages LLMs to produce two types of human-readable explanations: positive explanations for why a consumer might like a product and negative explanations for why they might not. These explanations are embedded via a pre-trained AutoEncoder and combined with consumer and product features as inputs to the DNN. Beyond offering explanability, LLM reasoning powered recommendations also improve learning efficiency and predictive accuracy. 

% To understand why, we provide insights using high-dimensional statistical learning theory. Theoretically, we show that LLMs is equipped with better knowledge of the important variables driving consumer decision-making, and that incorporating such knowledge can improve the learning efficiency of high-dimensional ML models. 

Modern recommender systems use machine learning (ML) models to predict consumer preferences based on consumption history. Although these ``black-box'' models achieve impressive predictive performance, they often suffer from a lack of transparency and explainability. While explainable AI research suggests a tradeoff between the two, we demonstrate that combining large language models (LLMs) with deep neural networks (DNNs) can improve both. We propose LR-Recsys, which augments state-of-the-art DNN-based recommender systems with LLMs' reasoning capabilities. LR-Recsys introduces a contrastive-explanation generator that leverages LLMs to produce human-readable positive explanations (why a consumer might like a product) and negative explanations (why they might not). These explanations are embedded via a fine-tuned AutoEncoder and combined with consumer and product features as inputs to the DNN to produce the final predictions. Beyond offering explainability, LR-Recsys also improves learning efficiency and predictive accuracy. To understand why, we provide insights using high-dimensional multi-environment learning theory. Statistically, we show that LLMs are equipped with better knowledge of the important variables driving consumer decision-making, and that incorporating such knowledge can improve the learning efficiency of ML models. 

Extensive experiments on three real-world recommendation datasets demonstrate that the proposed LR-Recsys framework consistently outperforms state-of-the-art black-box and explainable recommender systems, achieving a 3–14\% improvement in predictive performance. This performance gain could translate into millions of dollars in annual revenue if deployed on leading content recommendation platforms today. Our additional analysis confirms that these gains mainly come from LLMs' strong reasoning capabilities, rather than their external domain knowledge or summarization skills. 

LR-RecSys presents an effective approach to combine LLMs with traditional DNNs, two of the most widely used ML models today. Specifically, we show that LLMs can improve both the explainability and predictive performance of traditional DNNs through their reasoning capability. Beyond improving recommender systems, our findings emphasize the value of combining contrastive explanations for understanding consumer preferences and guiding managerial strategies for online platforms. These explanations provide actionable insights for consumers, sellers, and platforms, helping to build trust, optimize product offerings, and inform targeting strategies.




% To understand why LLM-generated explanations can simultaneously improve predictive performance and explainability rather than creating a trade-off, we provide insights using high-dimensional statistical learning theory. Theoretically, we show that LLMs likely have better knowledge of the important variables driving consumer decision-making, and that incorporating such knowledge can improve the learning efficiency of high-dimensional ML models.

%By incorporating these contrastive explanations, LR-Recsys moves beyond correlational predictions, enabling

% , supporting the theoretical insight that LLMs effectively identify the important variables driving consumer decisions, thereby improving the model's learning efficiency


% Modern recommender systems use machine learning (ML) models to predict whether or how much a consumer will enjoy a product based on her consumption history. However, being black-box in nature, these systems often lack explainability and rely heavily on correlation rather than causation. At the same time, existing explainable AI research suggests that enforcing explainability in ML models hurts predictive performance, as it limits the model's flexibility. To address this challenge, we propose LE-Recsys, an LLM-Explanation-Powered Recommender System, that simultaneously improves both explainability and predictive performance. Our framework introduces a contrastive-explanation generator that leverages generative language models to produce two types of human-readable explanations: positive explanations for why a consumer might like a product and negative explanations for why she might not. These explanations are transformed into embeddings using a pre-trained AutoEncoder and integrated with standard consumer and product features as input to a deep neural network (DNN)-based recommendation model. By incorporating contrastive explanations, the recommendation model can reason about consumer preferences based on their consumption history, rather than blindly relying on correlational patterns to predict choices, thereby improving both learning efficiency and predictive accuracy.

% While our framework is compatible with any generative natural language processing (NLP) model, we find large language models (LLMs) particularly effective due to their advanced reasoning capabilities. To understand why LLM-generated explanations can simultaneously improve predictive performance and explainability rather than creating a trade-off, we provide insights using high-dimensional statistical learning theory. Theoretically, we show that LLMs likely have better knowledge of the important variables driving consumer decision-making, and that incorporating such knowledge can improve the learning efficiency of high-dimensional ML models.

% Extensive experiments on three real-world recommendation datasets demonstrate that our approach consistently outperforms state-of-the-art black-box and explainable recommender systems, improving the predictive performance by 3-14\%. Furthermore, we confirm that these observed improvements mainly come from LLMs' strong reasoning capabilities rather than their external domain knowledge, supporting the theoretical insight that LLMs effectively identify the important variables driving consumer decisions, thereby improving the model's learning efficiency. Beyond improving recommender systems, our findings emphasize the value of contrastive explanations for understanding consumer preferences and guiding managerial strategies for online platforms. These explanations provide actionable insights for consumers, sellers, and platforms, helping to build trust, optimize product offerings, and inform targeting strategies without raising privacy concerns.

% These models, trained on vast datasets, offer rich insights into critical consumer preferences and product attributes that lead to a purchase decision, bridging the gap in current black-box systems.

%%%\todo{maybe remove the last sentence}
}

%\FUNDING{The research of the first author is supported by NWO Grant 613.001.208. The third author acknowledges the funding support from the Singapore Ministry of Education Social Science Research Thematic Grant MOE2016-SSRTG-059.}

\SUBJECTCLASS{\AQ{Please confirm subject classifications.}Recommender systems.}

\AREAOFREVIEW{Marketing.}

\KEYWORDS{Recommender Systems; Large Language Models; Deep Learning; LLM reasoning; LLM-generated explanations.}%{\CQ{Kindly provide the keywords.}}

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	% Samples of sectioning (and labeling) in OPRE
	% NOTE: (1) \section and \subsection do NOT end with a period
	%       (2) \subsubsection and lower need end punctuation
	%       (3) capitalization is as shown (title style).
	%
	%\section{Introduction.}\label{intro} %%1.
	%\subsection{Duality and the Classical EOQ Problem.}\label{class-EOQ} %% 1.1.
	%\subsection{Outline.}\label{outline1} %% 1.2.
	%\subsubsection{Cyclic Schedules for the General Deterministic SMDP.}
	%  \label{cyclic-schedules} %% 1.2.1
	%\section{Problem Description.}\label{problemdescription} %% 2.
	% Text of your paper here
	
\maketitle

\section{Introduction}
\label{sec:intro}
\input{sections/s1_introduction.tex}

\section{Related Work}
\label{sec:related_work}
\input{sections/s2_relatedwork.tex}

\section{Machine Learning Framework: LR-Recsys}
\label{sec:framework}
\input{sections/s3_framework.tex}

\section{Statistical Insights}
\label{sec:theory}
\input{sections/s4_theory.tex}

% \section{Actionable Insights}
% Customer aquisition: Which customer segment does my product attract;

% Improving product characteristics: How to improve my product so that it attracts more consumers 
 
% Can we improve the methodology so that our framework can generate actionable insights (and potentially for different segments of the consumers)? E.g. ``restaurant A should improve cleanliness if want to attract more [segment] customers''

\section{Experiments}
\label{sec:results}
\input{sections/s5_results.tex}

\section{Discussion}
\label{sec:discussion}
\input{sections/s6_discussion.tex}


\section{Funding and Competing Interests Declarations}
\label{sec:declarations}
% \subsection{Funding and Competing Interests. } 
The author(s) were employed by Google (Google Brain, now Google DeepMind) at the time this project was initiated. Google recognizes a potential need to disclose certain confidential information, and to protect such information from unauthorized use and disclosure. Google had the right to remove its intellectual property or trade secrets subject to the following stipulations: 
\begin{enumerate}
    \item Removing Google confidential information from the paper, including data, code, and statistics. 
    \item Compliance with Google’s obligations as it relates to applicable laws, including the Data Protection Law, security laws, confidentiality requirements, and contractual commitments.
\end{enumerate}



% Acknowledgments here
% \ACKNOWLEDGMENT{The authors are grateful to the associate editor and two anonymous referees for valuable comments on an earlier version of the paper. The research of the first author is supported by NWO Grant 613.001.208. The third author acknowledges the funding support from the Singapore Ministry of Education Social Science Research Thematic Grant MOE2016-SSRTG-059. Disclaimer: Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of the Singapore Ministry of Education or the Singapore Government.}	

\theendnotes

\bibliographystyle{informs2014} % outcomment this and next line in Case 1
\bibliography{reference} % if more than one, comma separated
	

\newpage
\begin{APPENDIX}{The Blessing of Reasoning: LLM-Generated Explanations in Black-Box Recommender Systems}
 \input{sections/appendix.tex}
\end{APPENDIX}

		
\end{document} 