[
  {
    "index": 0,
    "papers": [
      {
        "key": "rashad_arabic_nodate",
        "author": "Rashad, Mohamed",
        "title": "Arabic {Tokenizers} {Leaderboard} - a {Hugging} {Face} {Space} by {MohamedRashad}"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "koubaa_githubcomriotu-labaranizer_2024",
        "author": "Koubaa, Anis and Ghouti, Lahouari and Najar, Omar and Sebai, Serry",
        "title": "github.com/riotu-lab/aranizer"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "rosa_nbailabtokenizer-benchmark_2024",
        "author": "Rosa, Javier de la and Arild, Rolv",
        "title": "{NbAiLab}/tokenizer-benchmark"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "diewald_tokenizing_2022",
        "author": "Diewald, Nils and Kupietz, Marc and L\u00fcngen, Harald",
        "title": "Tokenizing on scale.{Preprocessing} large text corpora on the lexical and sentence level."
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "erkaya_analysis_2023",
        "author": "Erkaya, Erencan and G\u00fcng\u00f6r, Tunga",
        "title": "Analysis of {Subword} {Tokenization} {Approaches} for {Turkish} {Language}"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "martins_eurollm_2024",
        "author": "Martins, Pedro Henrique and Fernandes, Patrick and Alves, Jo\u00e3o and Guerreiro, Nuno M. and Rei, Ricardo and Alves, Duarte M. and Pombal, Jos\u00e9 and Farajian, Amin and Faysse, Manuel and Klimaszewski, Mateusz and Colombo, Pierre and Haddow, Barry and Souza, Jos\u00e9 G. C. de and Birch, Alexandra and Martins, Andr\u00e9 F. T.",
        "title": "{EuroLLM}: {Multilingual} {Language} {Models} for {Europe}"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "neubeck_so_2024",
        "author": "Neubeck, Alexander, Hendrik van Antwerpen",
        "title": "So many tokens, so little time: {Introducing} a faster, more flexible byte-pair tokenizer"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "rust_how_2021",
        "author": "Rust, Phillip and Pfeiffer, Jonas and Vuli\u0107, Ivan and Ruder, Sebastian and Gurevych, Iryna",
        "title": "How {Good} is {Your} {Tokenizer}? {On} the {Monolingual} {Performance} of {Multilingual} {Language} {Models}"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "lin_not_nodate",
        "author": "Lin, Zhenghao and Gou, Zhibin and Gong, Yeyun and Liu, Xiao and Shen, Yelong and Xu, Ruochen and Lin, Chen and Yang, Yujiu and Jiao, Jian and Duan, Nan and Chen, Weizhu",
        "title": "Not {All} {Tokens} {Are} {What} {You} {Need} for {Pretraining}"
      }
    ]
  }
]