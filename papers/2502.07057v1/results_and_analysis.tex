\section{Results and Analysis}

This study evaluated four state-of-the-art tokenizers using the TR-MMLU dataset, which consists of 1,605,376 characters and 198,193 words \cite{bayram_setting_2025}. The TR-MMLU benchmark provides a robust framework for assessing large language models across a broad spectrum of subjects, accurately capturing the unique morphological and syntactic structures of Turkish. The evaluation considered key metrics, including Turkish Token Percentage (TR \%), Pure Token Percentage (Pure \%), vocabulary size, total token count, unique token count, processing time, and MMLU scores. These metrics collectively capture both linguistic fidelity and computational efficiency.

\begin{table}[h]
\centering
\caption{Tokenizer Benchmark Results}
\label{tab:tokenizer-benchmark}
\resizebox{\textwidth}{!}{
\begin{tabular}{|l|c|c|c|c|}
\hline
\rowcolor[HTML]{DDDDDD} 
\textbf{Metric} & \textbf{gemma-2} & \textbf{llama-3.1} & \textbf{Qwen2.5} & \textbf{aya-expanse} \\ \hline
\rowcolor[HTML]{FFFFDD} 
Model Parameters (B) & 27.2 & 70.6 & 7.6 & 32.3 \\ \hline
\rowcolor[HTML]{FFFFDD} 
MMLU Score (\%) & 72.10 & 70.42 & 61.68 & 70.66 \\ \hline
Vocabulary Size & 256,000 & 128,256 & 151,665 & 255,029 \\ \hline
Token Count & 497,015 & 488,535 & 561,866 & 434,526 \\ \hline
Processing Time (s) & 2.95 & 3.12 & 3.31 & 2.77 \\ \hline
Unique Token Count & 6,383 & 6,823 & 5,752 & 8,562 \\ \hline
TR \% & 48.63 & 45.80 & 40.33 & 50.67 \\ \hline
Pure \% & 37.05 & 30.91 & 30.15 & 32.96 \\ \hline
\end{tabular}
}
\end{table}

Table~\ref{tab:tokenizer-benchmark} summarizes the performance metrics for the evaluated tokenizers. Among the models, \texttt{gemma-2} achieved the highest MMLU score (72.10\%) and the highest Pure \% (37.05\%), demonstrating its superior ability to generate linguistically coherent tokens while maintaining strong downstream performance. Its TR \% (48.63\%) further reflects its alignment with Turkish vocabulary and morphological structures.

\texttt{aya-expanse} recorded the highest TR \% (50.67\%) and performed competitively on the MMLU benchmark with a score of 70.66\%. This result highlights the significance of language-specific tokenization but also underscores the influence of additional factors, such as model architecture and parameter optimization, in shaping overall performance.

\texttt{llama-3.1} achieved an MMLU score of 70.42\%, supported by a reasonable TR \% (45.80\%), but its lower Pure \% (30.91\%) reveals limitations in capturing the finer-grained morphological details of Turkish. In contrast, \texttt{Qwen2.5}, the smallest model with 7.6B parameters, achieved the lowest MMLU score (61.68\%) and TR \% (40.33\%), highlighting the challenges of maintaining linguistic fidelity within a smaller parameter budget. However, its relatively compact vocabulary size (151,665 tokens) and efficient processing time (3.31 seconds) suggest a trade-off favoring computational efficiency.

A correlation matrix was computed to analyze the relationships between key metrics, providing deeper insights into how linguistic and computational factors interact. The matrix is visualized in Figure~\ref{fig:correlation_matrix}, which reveals several important patterns. For example, TR \% demonstrated the strongest positive correlation with MMLU scores (\(r = 0.90\)), followed by Pure \% (\(r = 0.68\)), emphasizing the role of linguistic alignment in downstream performance.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{correlation_matrix.png}
    \caption{Correlation Matrix Heatmap: Relationships among MMLU Score, Linguistic Metrics (TR \% and Pure \%), Vocabulary Size, and Computational Metrics.}
    \label{fig:correlation_matrix}
\end{figure}
\FloatBarrier

The correlation matrix also highlights the nuanced relationship between vocabulary size and linguistic fidelity. Larger vocabularies correlate positively with both TR \% (\(r = 0.77\)) and Pure \% (\(r = 0.82\)), indicating that a sufficiently large vocabulary improves the tokenizer's ability to align with the target language's morphology. However, excessive token counts and processing times exhibit strong negative correlations with these linguistic metrics (\(r = -0.93\) and \(r = -0.60\), respectively), underscoring the inefficiencies introduced by overly granular tokenization.

Figure~\ref{fig:model_comparison} provides a multidimensional comparison of the evaluated tokenizers, plotting MMLU scores against TR \%, with marker size representing parameter count and color encoding Pure \%. Models that achieve high TR \% and Pure \% values tend to better capture the languageâ€™s morphological richness, while those optimized for efficiency may sacrifice linguistic fidelity.

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{model_comparison.png}
    \caption{Model Comparison: MMLU vs TR \%, Parameter Size, and Pure \%.}
    \label{fig:model_comparison}
\end{figure}
\FloatBarrier

These findings affirm the critical role of linguistic alignment, as reflected by TR \% and Pure \%, in shaping downstream performance in morphologically complex languages like Turkish. Models that prioritize language-specific tokenization can outperform larger or more computationally efficient models that lack such adaptation. This highlights the importance of designing tokenization strategies that balance computational efficiency with linguistic fidelity, providing valuable insights for future research and development in NLP.
