%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[utf8]{inputenc}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage[most]{tcolorbox}
\usepackage{enumitem}


% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{paper} with \usepackage[nohyperref]{paper} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025_arxiv}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{xcolor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\definecolor{Burgundy}{RGB}{144,0,32}
\newcommand{\dacheng}[1]{{\color{purple}{\bf\sf [Dacheng: #1]}}}
\newcommand{\joey}[1]{{\color{blue}{\bf\sf [Joey: #1]}}}
\newcommand{\luis}[1]{{\color{green}{\bf\sf [Luis: #1]}}}
% \newcommand{\shu}[1]{{\color{orange}{\bf\sf [Shu: {\small #1}]}}}
% #1]}}}
\newcommand{\shu}[1]{{\color{orange}{\bf\sf [shu: {\small #1}]}}}
\newcommand{\tian}[1]{{\color{teal}{\bf\sf [Tian: #1]}}}
\newcommand{\yichuan}[1]{{\color{red}{\bf\sf [Yichuan: #1]}}}
\newcommand{\xw}[1]{{\color{orange}{\bf\sf [XW: #1]}}}
\newcommand{\siyuan}[1]{{\color{cyan}{\bf\sf [Siyuan: #1]}}}
\newcommand{\apd}[1]{{\color{Burgundy}{\bf\sf [apd: #1]}}}
\newcommand{\alex}[1]{{\color{brown}{\bf\sf [alex: #1]}}}
\newcommand{\wenjie}[1]{{\color{violet}{\bf\sf [wenjie: {\small #1}]}}}


% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

% Cleveref
\usepackage[nameinlink,capitalise,noabbrev]{cleveref}
\crefformat{equation}{(#2#1#3)}  % do not use label for "equation" references


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks}

\definecolor{CiteColor}{RGB}{30,76,132}
\definecolor{LinkColor}{RGB}{0,128,0}
\hypersetup{colorlinks    = true,
            final,
            citecolor=CiteColor,
            linkcolor=LinkColor,
            urlcolor=CiteColor,
}

\begin{document}

\twocolumn[
\icmltitle{The Danger of Overthinking: Examining the Reasoning-Action Dilemma in
Agentic Tasks}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the paper
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Alejandro Cuadron}{ucb,ethz}
\icmlauthor{Dacheng Li}{ucb}
\icmlauthor{Wenjie Ma}{ucb}
\icmlauthor{Xingyao Wang}{uiuc}
\icmlauthor{Yichuan Wang}{ucb}
\icmlauthor{Siyuan Zhuang}{ucb}
\icmlauthor{Shu Liu}{ucb}
\icmlauthor{Luis Gaspar Schroeder}{ucb}
\icmlauthor{Tian Xia}{ucb}
\icmlauthor{Huanzhi Mao}{ucb}
\icmlauthor{Nicholas Thumiger}{ethz}
\icmlauthor{Aditya Desai}{ucb}
\icmlauthor{Ion Stoica}{ucb}
\icmlauthor{Ana Klimovic}{ethz}
\icmlauthor{Graham Neubig}{cmu}
\icmlauthor{Joseph E. Gonzalez}{ucb}
\end{icmlauthorlist}

\icmlaffiliation{ucb}{Department of EECS, University of California, Berkeley, USA}
\icmlaffiliation{ethz}{Department of Computer Science, ETH, Zurich, Switzerland}
\icmlaffiliation{uiuc}{Department of Computer Science, University of Illinois Urbana-Champaign, USA}
\icmlaffiliation{cmu}{Department of Computer Science, Carnegie Mellon University, USA}

\icmlcorrespondingauthor{Alejandro Cuadron}{acuadron@berkeley.edu}

\icmlkeywords{Machine Learning, ICML, LLM, reasoning, O1, SWE-Bench, multi-turn environment}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
\input{paper/sections/abstract}
\end{abstract}


\section{Introduction}\label{introduction}
\input{paper/sections/introduction_1}

\section{Background and Related Work}
\input{paper/sections/background_1}

\section{Overthinking}
\label{section3}
\input{paper/sections/overthinking}

\section{Evaluation Framework}\label{evaluation_framework}
\input{paper/sections/evaluation_framework_2}

\section{Results}
\label{sec:results}
\input{paper/sections/results}


\section{Discussion}

\input{paper/sections/discussions}
\section{Conclusion}
\input{paper/sections/conclusion}
\section{Acknowledgments}
The authors thank Siavash Ameli, Jiayi Pan, and Yilong Zhao for their invaluable contributions. They also thank SkyLab at UCB, OpenHands, NeuLab at CMU, and Lambda Cloud for their support. 
\section*{Impact Statement}
This paper advances our understanding of how Large Reasoning Models (LRMs) balance internal reasoning with environmental interaction, a critical factor in their real-world deployment. By introducing the first systematic framework for quantifying overthinking behaviors, we enable more efficient and effective AI systems that can better allocate their computational resources between reasoning and action. Our open-sourced dataset and evaluation framework provide the research community with tools to develop more balanced AI agents, potentially reducing both computational costs and error rates in practical applications. This work has immediate implications for software engineering automation and broader applications in any domain where AI agents must interact with dynamic environments.
\clearpage

\bibliography{main}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Prompt to detect overthinking }
\label{apx:prompt_overthinking}
Here, we provide the prompt used to assess the overthinking score.
% \luis{Add explanation}
\begin{tcolorbox}[
    enhanced,
    breakable,
    colback=white,
    colframe=black,
    arc=4mm,
    width=\textwidth,
    beforeafter skip=8pt
]
    \small

You are an AI judge focused on detecting when models prefer their internal reasoning chain over interacting with the environment.

$<$INTERACTION$>$

trajectory goes here

$<$/INTERACTION$>$

Analyze the $<$INTERACTION$>$ and determine if the model is preferring their internal reasoning chain over interacting with the environment:

How could this be detected?

$<$CORE PRINCIPLE$>$
\begin{itemize}[noitemsep]
    \item The model suffers from Analysis Paralysis, it focuses on heavy planning instead of interacting with the environment.
    \item The model suffers from Rogue actions, after facing setbacks, it generates multiple actions without waiting for the environment to process the previous action.
    \item The model suffers from Premature Disengagement, it concludes the task without checking with the environment. Either because it is overconfident in the solution or because it thinks it can't solve the problem.
\end{itemize}
$<$/CORE PRINCIPLE$>$

$<$SCORING SYSTEM (0-10)$>$

\textbf{0-3: Always interacting with the environment}
\begin{itemize}[noitemsep]
    \item A summary of what has been done so far is good, even if done multiple times.
    \item A brief summary of the steps to take is good if the model interacts with the environment following steps one by one.
    \item Only one action per turn, finish and other actions are NOT allowed.
    \item Alternating between two operations is good.
    \item Trying the same approach over and over is good, even with long or complex actions, as long as the model waits for environment feedback each time.
    \item Repeating similar patterns or configurations is fine as long as the model interacts with the environment between attempts.
    \item Detailed reasoning and planning is good if it leads to concrete actions with environment interaction.
\end{itemize}

\textbf{4-7: Sometimes relies too much on their internal reasoning chain, but still interacts with the environment.}
\begin{itemize}[noitemsep]
    \item It engages in heavy planning, but still interacts with the environment.
    \item It NEVER concludes the task without checking with the environment.
    \item It might output multiple steps ONE time, but at subsequent turns it interacts one step at a time.
    \item Long theoretical discussions are acceptable if they eventually result in concrete actions.
\end{itemize}

\textbf{8-10: Completely relies on their internal reasoning chain.}
\begin{itemize}[noitemsep]
    \item Focuses solely on their internal reasoning chain, with no concrete actions following the analysis.
    \item Generates multiple actions without waiting for environment response.
    \item The model prematurely concludes the task. Either because it is overconfident in the solution or because it thinks it can't solve the problem.
    \item Generates many steps without any environment interaction.
    \item Gets stuck in endless theoretical discussion without attempting solutions.
\end{itemize}
$<$/SCORING SYSTEM$>$

$<$ANALYSIS STEPS$>$

1. Analysis Paralysis
   \begin{itemize}[noitemsep]
       \item Is the model focusing on heavy planning instead of interacting with the environment?
       \item Does the model interact with the environment at all?
       \item Does the model follows its planned steps starting from the first one?
   \end{itemize}

2. Rogue Actions
   \begin{itemize}[noitemsep]
       \item Does the model generate multiple actions without waiting for the environment to process the previous action?
       \item Is this behavior after a facing a setback?
       \item Does this behaviour happen often?
   \end{itemize}

3. Premature Disengagement
   \begin{itemize}[noitemsep]
       \item Does the model prematurely conclude the task?
       \item Is the model overconfident in the solution?
       \item Is the model thinking it can't solve the problem?
   \end{itemize}
$<$/ANALYSIS STEPS$>$

$<$EXAMPLES$>$

\textbf{Example 1 - Persistent Retries (Good):}
\begin{quote}
EXECUTION RESULT: ``Error: Invalid configuration''

Model: \textit{*tries complex configuration A*}

EXECUTION RESULT: ``Error: Invalid configuration''

Model: \textit{*tries similar complex configuration A with slight modification*}

EXECUTION RESULT: ``Error: Invalid configuration''

Model: \textit{*tries complex configuration A again with another modification*}

Score: 0 - The model is persistently trying to solve the problem, waiting for environment feedback between each attempt. Even though the attempts are similar and complex, it's properly interacting with the environment.
\end{quote}

\textbf{Example 2 - Thoughtful Planning (Good):}
\begin{quote}
Model: \textit{*provides detailed analysis of the problem and potential approaches*}

Model: \textit{*tries specific solution based on analysis*}

EXECUTION RESULT: ``Error in implementation''

Model: \textit{*refines approach based on error and tries again*}

Score: 0 - While the model engages in detailed planning, it follows through with concrete actions and responds to environment feedback.
\end{quote}

\textbf{Example 3 - Stuck in a loop (Good):}
\begin{quote}
EXECUTION RESULT: ``ERROR''

Model: \textit{*apply fix\_0*}

EXECUTION RESULT: ``ERROR''

Model: \textit{*apply SAME fix\_0*}

EXECUTION RESULT: ``ERROR''

Model: \textit{*apply SAME fix\_0*}

Score: 0 - Stuck in a loop is good.
\end{quote}

\textbf{Example 4 - Analysis Paralysis:}
\begin{quote}
EXECUTION RESULT: ``Invalid indentation line 10''

Model: \textit{*Maybe I should... Perhaps I should... It should be... Let me try to start again rewriting the class*}

EXECUTION RESULT: ``Still invalid line 10''

Model: \textit{*Its not working... We also need to fix this other thing...*}

EXECUTION RESULT: ``Same error line 10''

Score: 10 - focuses on its internal reasoning chain instead of the environment.
\end{quote}

\textbf{Example 5 - Premature Disengagement:}
\begin{quote}
EXECUTION RESULT: ``Invalid indentation line 10''

Model: \textit{*This fixes it! I'll conclude the task. $<$function=finish$>$*}

Score: 10 - The model concludes the task without applying the fix or overconfidence in the solution.
\end{quote}

\textbf{Example 6 - Rogue Actions:}
\begin{quote}
EXECUTION RESULT: ``Invalid indentation line 10''

Model: \textit{*Oh no, I forgot to add the old string, let me call the function again $<$function=str\_replace\_editor$>$...$<$/function$>$ and then we do this other thing $<$function=str\_replace\_editor$>$...$<$/function$>$*}

Score: 10 - The model generates multiple actions after facing a setback without waiting for the environment to process the previous action.
\end{quote}

$<$/EXAMPLES$>$

$<$IMPORTANT$>$

Format your response as:

\begin{verbatim}
<answer>
{
    "overthinking_score": "[0-10]",
    "reasoning": "Explain your reasoning for the score, 
    be careful with new lines as they might break the JSON parsing"
}
</answer>
\end{verbatim}

Always surround your answer with $<$answer$>$ and $<$/answer$>$ tags.\\
Take your time to understand the interaction and analyze it carefully.\\
Think step by step if models prefer their internal reasoning chain over interacting with the environment.

$<$/IMPORTANT$>$
\end{tcolorbox}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Model Specifications and Capabilities}
\label{apx:models}
\begin{table}[ht]
\small
\centering
\begin{tabular}{llrccl}
\toprule
\textbf{Category} & \textbf{Model} & \textbf{Params} & \textbf{Context} & \textbf{FC} & \textbf{Notes} \\
\midrule
\multicolumn{6}{l}{\textit{Non-Reasoning Models (Open Source)}} \\
\midrule
& DeepSeek-V3 & 671B & 128k & $\times$ & MoE architecture \\
& Qwen 2.5-32B & 32B & 128k & $\times$ & Dense architecture \\
& Qwen 2.5-14B & 14B & 128k & $\times$ & Dense architecture \\
& Qwen 2.5-7B & 7B & 128k & $\times$ & Dense architecture \\
& Qwen 2.5-1.5B & 1.5B & 128k & $\times$ & Dense architecture \\
& Sky-T1-32B & 32B & 32k & $\times$ & QwQ distillation \\
\midrule
\multicolumn{6}{l}{\textit{Non-Reasoning Models (Closed Source)}} \\
\midrule
& GPT-4o & - & 128k & $\checkmark$ & Aug 2024 version \\
& GPT-4o-mini & - & 128k & $\checkmark$ & Jul 2024 version \\
& Claude 3.5 Sonnet & - & 200k & $\checkmark$ & Oct 2024 version \\
\midrule
\multicolumn{6}{l}{\textit{Reasoning Models (Open Source)}} \\
\midrule
& QwQ-32B & 32B & 32k & $\times$ & Preview version \\
& DeepSeek-R1 & 671B & 128k & $\times$ & Based on V3 \\
& R1-Distill-Qwen-32B & 32B & 128k & $\times$ & Based on Qwen 2.5 \\
& R1-Distill-Qwen-14B & 14B & 128k & $\times$ & Based on Qwen 2.5 \\
& R1-Distill-Qwen-7B & 7B & 128k & $\times$ & Based on Qwen 2.5 \\
& R1-Distill-Qwen-1.5B & 1.5B & 128k & $\times$ & Based on Qwen 2.5 \\
\midrule
\multicolumn{6}{l}{\textit{Reasoning Models (Closed Source)}} \\
\midrule
& o1 & - & 200k & $\checkmark$ & Dec 2024, RE$^\ddagger$ \\
& o1-mini & - & 128k & $\times$ & Sep 2024 version \\
\bottomrule
\end{tabular}
\caption{Comprehensive comparison of evaluated models. FC indicates native function calling support. Models are grouped by reasoning capabilities and source availability. $^\dagger$Supports reasoning\_effort parameter (low/medium/high).}
\label{tab:model_comparison}
\end{table}

\section{Statistical principles utilized in this work}
\label{stat_framework}
\noindent\textbf{Coefficient of Determination $R^2$.}
\label{def:coefofdet}
The coefficient of determination, denoted by $R^2$, is a statistical measure of how well the regression predictions approximate the real data points. Formally, for a set of observed values $\{y_i\}_{i=1}^n$ with mean $\bar{y}$ and corresponding fitted values $\{\hat{y}_i\}_{i=1}^n$, it is defined as:
\[
R^2 \;=\; 1 \;-\; \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}.
\]
It represents the proportion of the variance in the dependent variable that is explained by the regression model.

\noindent\textbf{P-value.}
\label{def:pvalue}
Given a null hypothesis $H_0$ and a test statistic (based on a sample) used to decide whether to reject $H_0$, the \emph{p-value} is the probability, under the assumption that $H_0$ is true, of obtaining a test statistic value at least as extreme as the one that was actually observed. Symbolically, if $T$ is the test statistic, and $t_{\text{obs}}$ its observed value,
\[
\text{p-value} \;=\; P\bigl(T \ge t_{\text{obs}} \;\mid\; H_0\bigr),
\]
for a one-sided test (or an analogous definition for two-sided tests). A smaller p-value indicates stronger evidence against $H_0$.

\noindent\textbf{Beta Coefficients in Simple Linear Regression}
\label{def:beta}
Consider a simple linear regression model:
\[
Y_i \;=\; \beta_0 \;+\; \beta_1\,X_i \;+\; \varepsilon_i,
\]
where:
\[
\beta_0 \quad \text{is the intercept (the predicted value of $Y$ when $X = 0$),}
\]
\begin{align*}
\beta_1 \quad &\text{is the slope (the expected change in $Y$} \\
              &\text{for a one-unit increase in $X$).}
\end{align*}
\[
\varepsilon_i \quad \text{is the error term, assumed to have mean zero.}
\]

In this context, the slope $\beta_1$ is given by
\[
\beta_1 \;=\;
\frac{\sum_{i=1}^{n}(X_i - \bar{X})(Y_i - \bar{Y})}
     {\sum_{i=1}^{n}(X_i - \bar{X})^2},
\]
which measures the strength and direction of the linear relationship between $X$ and $Y$.

\noindent\textbf{T-test of the p-value}
\label{def:ttest}
A \emph{t-test} assesses whether the mean(s) of one or two groups differ(s) from a hypothesized value or from each other under the null hypothesis $H_0$. Let $T$ be the test statistic calculated from the data (for instance, comparing sample mean(s) to the hypothesized mean(s)), and let $t_{\text{obs}}$ be the observed value of $T$. The \emph{p-value} for the t-test is then defined as:
\[
\text{p-value} 
\;=\;
P\bigl(\lvert T \rvert \ge \lvert t_{\text{obs}} \rvert \;\mid\; H_0\bigr)
\]
for a two-sided test (or a correspondingly appropriate one-sided version). A lower p-value provides stronger evidence against $H_0$, suggesting that the observed difference is unlikely to have occurred under the null hypothesis.

\subsection{Definition of model-specific coefficients}
\label{apx:model_specific_coefficients}
\begin{definition}[Model-Specific Coefficients]
For the \emph{Reasoning Language Models}, the fitted model is
\[
\hat{Y}_R \;=\; \beta_{0,R} \;+\; \beta_{1,R}\,X,
\]
where
\[
\beta_{1,R} = -7.894.
\]

For the \emph{Non-Reasoning Language Models}, the fitted model is
\[
\hat{Y}_{NR} \;=\; \beta_{0,NR} \;+\; \beta_{1,NR}\,X,
\]
where
\[
\beta_{1,NR} = -15.938.
\]
\end{definition}
\end{document}