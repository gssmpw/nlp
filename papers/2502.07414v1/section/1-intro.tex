\section{Introduction}

Over the past decade, there have been substantial advancements in artificial intelligence, driven by the enhanced computational power and the strong generalization capabilities exhibited by neural networks~\cite{he2016deep, brown2020language}. 
However, the effectiveness of current algorithms relies heavily on the assumption that training data and test data are independent and identically distributed, known as the IID assumption. In cases where this assumption does not hold, a circumstance frequently encountered in real-world scenarios, their performance lacks theoretical and empirical guarantees. Models exhibit vulnerability to spurious correlations~\cite{sagawa2020investigation} or shortcuts~\cite{geirhos2020shortcut} and their performance may experience significant deterioration in the presence of distribution shifts. This limitation substantially impedes the application of machine learning in risk-sensitive areas like autonomous driving~\cite{muhammad2020deep} and law~\cite{surden2014machine}. 

Therefore, the problem of Out-of-Distribution (OOD) generalization has garnered significant attention within the realm of machine learning in recent years~\cite{shen2021towards}. Different from domain adaptation (DA)~\cite{ben2006analysis,long2015learning, chu2016selective} where test data information is known partially, OOD generalization addresses the challenging but more realistic setting where test data is totally unknown. 
Several lines of research have been dedicated to tackling this challenge. 
Both invariant learning~\cite{arjovsky2019invariant, krueger2021out} and domain generalization (DG)~\cite{shankar2018generalizing, rame2022fishr} aim to capture inherent invariance within training data to enhance the OOD generalization ability, while DG also involves techniques such as meta learning~\cite{li2018learning} and data augmentation~\cite{zhou2020domain}. Usually they require explicit environmental information during training.  
Another series of methods named distributionally robust optimization (DRO)~\cite{volpi2018generalizing, duchi2021learning} resolves around optimizing for the worst-case distribution to bolster OOD generalization performance, but they suffer from the over-pessimism problem~\cite{liu2022distributionally}. 

Recently, inspired by importance weighting~\citep{huang2006correcting,bickel2009discriminative} and propensity weighting~\citep{li2018balancing,lee2010improving}, 
stable learning algorithms~\citep{kuang2020stable, shen2020stable,zhang2021deep} employ independence-based sample reweighting to address covariate shift, which is a most common distribution shift~\citep{shen2021towards}. Without access to test data and explicit environment labels, they leverage a structural assumption that divides covariates into stable variables $\bolds$ and unstable variables $\boldv$, and try to mitigate correlations between $\bolds$ and $\boldv$ by reweighting to a distribution where covariates are independent. 
With theoretical guarantees~\citep{xu2021stable}, in such a way they can remove spurious correlations between $\boldv$ and the outcome $Y$ under the infinite-sample scenario. Thus they eliminate the bias of model parameter estimation and achieve stable prediction against agnostic covariate shift~\cite{cui2022stable}. 
Nevertheless, when it comes to the finite-sample scenario, despite the pronounced capability for debiasing, the operation of sample reweighting is naturally a less effective way of utilizing samples~\citep{kish1965survey}, i.e. diminishing the effective sample size~\citep{martino2017effective}. It leads to an increased variance of parameter estimation by all means, let alone the reweighting operation is too ambitious as it attempts to decorrelate all covariates without distinction. 
Thus they tend to fail to achieve a good bias-variance trade-off in situations featuring strong collinearity among covariates. While efforts have been devoted to tackling this issue, some require environment labels for covariate clustering~\citep{shen2020stable2}, and some assume low collinearity in unstable variables, 
need to take advantage of supervised information $Y$ and require much higher time cost due to the iterative procedure~\citep{yu2023stable}. 

It is well-known that bagging~\citep{breiman1996bagging}, a classic ensemble learning strategy, helps reduce the variance of the learned model. It constructs an ensemble of models trained on datasets bootstrapped from the original data, employing techniques such as averaging or majority voting. 
Inspired by this, we propose a universal and effective strategy of SAmple Weight Averaging (SAWA) to reduce the estimation variance and achieve a better bias-variance trade-off. 
It averages the sets of sample weights acquired by the identical weight learning procedure but with varying random initializations. 
Compared with previous remedies for strong collinearity and high variance, SAWA does not require environment labels or supervised information to conduct sample reweighting. It also lowers the time cost since it can be easily parallelized, unlike the iterative procedure in~\citet{yu2023stable}. 
We theoretically prove both the rationality and effectiveness of SAWA, and empirically demonstrate its usefulness and universality when incorporated into current independence-based sample reweighting schemes across various synthetic data settings. We also exhibit its practical usage of improving the covariate-shift generalization ability on real-world datasets. Additionally, we make further analyses to show the superiority of SAWA by comparing it with existing averaging or ensemble strategies in OOD research. 


Our main contributions are listed as follows:
\begin{itemize}
    \item We introduce a strategy of averaging sample weights for stable prediction against covariate shift to mitigate concerns related to variance inflation.
    \item We provide theoretical evidence for the validity of the averaged sample weights and advantages of decreasing the error of weight learning and model parameter estimation. 
    \item We demonstrate the effectiveness and universality of the strategy through comprehensive experiments on both synthetic and real-world datasets.
\end{itemize}

