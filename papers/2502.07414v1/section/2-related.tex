\section{Related Work}

% DG 
\textbf{Domain generalization} (DG) offers a solution for generalizing to out-of-distribution (OOD) scenarios where preliminary access to test data is lacking. Typically, these approaches necessitate the presence of multiple subpopulations, referred to as domains, within the training data. They learn representations that exhibit invariance across these subpopulations \citep{ghifary2015domain, li2018domain, shankar2018generalizing}. Additional methodologies include meta-learning \citep{li2018learning, balaji2018metareg, li2019episodic}, as well as the augmentation of source domain data \citep{qiao2020learning, zhou2020domain}. Recently, some methods based on parameter averaging have arisen \citep{cha2021swad, arpit2022ensemble} with impressive performance. 
Nevertheless, theoretical underpinning remains deficient within DG, and empirically, its efficacy heavily hinges on the availability of a plethora of training domains.


% invariant learning
\textbf{Invariant learning} constitutes another branch of research that endeavors to algorithms with theoretical guarantees. In a manner akin to domain generalization, its objective is to capture the invariance amid diverse training environments, thereby augmenting the models' ability for generalization across unknown test distributions. Consequently, these approaches require either explicit environment labels \citep{arjovsky2019invariant, koyama2020out, krueger2021out} or the assumption of sufficient heterogeneity within the training data \citep{liu2021heterogeneous}. 

% DRO
\textbf{Distributionally robust optimization} (DRO) focuses on optimizing the worst-case distribution. It chooses a perturbation ball around the original distribution and seeks the worst distribution in that ball for optimization. There are various ways to depict the distribution distance for the ball radius, including f-DRO \citep{duchi2021learning} and Wasserstein DRO \citep{sinha2018certifying}. It is worth noting that always focusing on the worst case naturally results in over-pessimism \citep{liu2022distributionally}. 


% stable learning

\textbf{Stable learning} addresses covariate shift by introducing a structural assumption and applying sample reweighting. This approach typically does not require explicit inclusion of environmental information \citep{cui2022stable}. \citet{xu2021stable} conduct a comprehensive theoretical analysis of independence-based sample reweighting, serving as the theoretical foundation of stable learning. 
DWR \citep{kuang2020stable} and SRDO \citep{shen2020stable} employ global decorrelation of covariates via sample reweighting. \citet{shen2020stable2} adapt DWR into group-wise decorrelation to mitigate the variance inflation caused by global decorrelation, which is also addressed in~\citet{yu2023stable} through the design of an iterative framework incorporating sparsity constraint. 
Besides, \citet{zhang2021deep} extend stable learning empirically to deep learning. 

