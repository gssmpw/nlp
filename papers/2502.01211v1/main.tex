% \documentclass{article}
% \usepackage{hyperref}       % hyperlinks
% \usepackage{graphicx} % Required for inserting images
% \usepackage{xcolor}         % colors

% %%%%%%%% MY PACKAGES

% \usepackage[utf8]{inputenc} % allow utf-8 input
% \usepackage[T1]{fontenc}    % use 8-bit T1 fonts
% \usepackage{url}            % simple URL typesetting
% \usepackage{booktabs}       % professional-quality tables
% \usepackage{amsfonts}       % blackboard math symbols
% \usepackage{amsmath}
% \usepackage{nicefrac}       % compact symbols for 1/2, etc.
% \usepackage{microtype}      % microtypography
% \usepackage{xcolor}         % colors
% %\usepackage[pdftex]{graphicx}
% %\usepackage{ngerman} % für deutsche Anführungszeichen
% %\usepackage[inline]{enumitem} % inline enumeration
% %\usepackage{dsfont}         % Real numbers symbol etc. => wieder entfernt, nehme stattdessen \mathbb{R} aus dem amsfonts package wie von neurips vorgeschlagen
% \usepackage{caption}        % For subfigures and captions
% \usepackage{subcaption}     % For subfigures and captions
% \usepackage{algorithm}
% \usepackage{algpseudocode}
% % \usepackage[linesnumbered,ruled,vlined]{algorithm2e}        % For algos with referencable line numbers
% \usepackage{tikz}
% \usetikzlibrary{shapes.geometric}
% \usepackage{multirow}
% %\usepackage{pdfpages}
% \usepackage{amsthm, amssymb}
% \usepackage{bm}
% \usepackage{pifont}         % For checkmark symbols with \ding{...}
% %\usepackage{ulem}
% \usepackage{enumitem}   % Custom enumerate labels
% \usepackage[textsize=small]{todonotes}


% \newtheorem{definition}{Definition}[section] % Defines the definition environment
% \newtheorem{proposition}[definition]{Proposition} % Defines the proposition environment, numbering it along with definitions
% \newtheorem{example}[definition]{Example}

% % Set paragraph indent to zero
% \setlength{\parindent}{0pt}

%%%%%%%% xxxxxx 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
%\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{xxxxxx2025} with \usepackage[nohyperref]{xxxxxx2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{xxxxxx2025}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{xxxxxx2025}

% Pre-print hot-fix Ludwig
\usepackage[accepted]{xxxxxx2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

% our packages:
\usepackage{pifont}         % For checkmark symbols with \ding{...}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric}
\usepackage{amsthm, amssymb}
\usepackage{bm}
\usepackage{caption}
\usepackage{subcaption} % For subfigure support
\usepackage{rotating} % Required for sidewaystable

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\newtheorem{proof_sketch}{Proof}
\newtheorem{proofsketch}{Proof (Step-by-Step)}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=small]{todonotes}


% The \xxxxxxtitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
%\xxxxxxtitlerunning{Explainable Privilege Scores for fairML}
\xxxxxxtitlerunning{Privilege Scores}

\begin{document}
\include{basic_math}
\include{basic_ml}
\include{macros}

\twocolumn[
%\xxxxxxtitle{Check your Privileges: Explainable Privilege Scores for Fairness-aware ML}
%\xxxxxxtitle{Explainable Privilege Scores for Fairness-Aware ML}
\xxxxxxtitle{Privilege Scores}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the xxxxxx2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\xxxxxxsetsymbol{equal}{*}

\begin{xxxxxxauthorlist}
\xxxxxxauthor{Ludwig Bothmann}{yyy,xxx}
\xxxxxxauthor{Philip A. Boustani}{yyy,xxx}
\xxxxxxauthor{Jose M. Alvarez}{zzz}
\xxxxxxauthor{Giuseppe Casalicchio}{yyy,xxx}
\xxxxxxauthor{Bernd Bischl}{yyy,xxx}
\xxxxxxauthor{Susanne Dandl}{aaa}
% \xxxxxxauthor{Firstname2 Lastname2}{equal,yyy,comp}
% \xxxxxxauthor{Firstname3 Lastname3}{comp}
% \xxxxxxauthor{Firstname4 Lastname4}{sch}
% \xxxxxxauthor{Firstname5 Lastname5}{yyy}
% \xxxxxxauthor{Firstname6 Lastname6}{sch,yyy,comp}
% \xxxxxxauthor{Firstname7 Lastname7}{comp}
% %\xxxxxxauthor{}{sch}
% \xxxxxxauthor{Firstname8 Lastname8}{sch}
% \xxxxxxauthor{Firstname8 Lastname8}{yyy,comp}
%\xxxxxxauthor{}{sch}
%\xxxxxxauthor{}{sch}
\end{xxxxxxauthorlist}

\xxxxxxaffiliation{yyy}{Department of Statistics, LMU Munich, Germany}
\xxxxxxaffiliation{xxx}{Munich Center for Machine Learning (MCML), Munich, Germany}
\xxxxxxaffiliation{zzz}{Department of Computer Science, KU Leuven, Belgium}
\xxxxxxaffiliation{aaa}{Epidemiology, Biostatistics \& Prevention Institute  (EBPI), Universität Zürich, Zurich, Switzerland}

\xxxxxxcorrespondingauthor{Ludwig Bothmann}{ludwig.bothmann@lmu.de}
% \xxxxxxcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\xxxxxxkeywords{Machine Learning, xxxxxx}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \xxxxxxEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\xxxxxxEqualContribution} % otherwise use the standard text.

\begin{abstract}
Bias-transforming methods of fairness-aware machine learning aim to correct a non-neutral status quo with respect to a protected attribute (PA).
Current methods, however, lack an explicit formulation of what drives non-neutrality. 
We introduce \textit{privilege scores (PS)} to measure PA-related privilege by comparing the model predictions in the real world with those in a fair world in which the influence of the PA is removed.
At the individual level, PS can identify individuals who qualify for affirmative action;
at the global level, PS can inform bias-transforming policies.
After presenting estimation methods for PS, we propose \textit{privilege score contributions (PSCs)}, an interpretation method that attributes the origin of privilege to mediating features and direct effects. 
We provide confidence intervals for both PS and PSCs.
Experiments on simulated and real-world data demonstrate the broad applicability of our methods and provide novel insights into gender and racial privilege in mortgage and college admissions applications.
%
% The\\
% abstract\\
% will\\
% roughly\\
% be\\
% that\\
% \dots\\
% \dots\\
% \dots\\
% \dots\\
% \dots\\
% long.
%This document provides a basic paper template and submission guidelines.
%Abstracts must be a single paragraph, ideally between 4--6 sentences long.
%Gross violations will trigger corrections at the camera-ready phase.
\end{abstract}


\section{Introduction}


% Substantive equality
% affirmative action
% positive discrimination
% bias-transforming methods \cite{wachter_bias_2021}
% individuelle perspective (nicht alle Mitglieder einer PA-Gruppe werden in einem task gleichermaßen diskriminiert)

Fairness-aware machine learning (fairML) 
%metrics 
methods can be classified into ``bias-preserving'' and ``bias-transforming'' approaches.
The former assume a \textit{neutral status quo} (referring to absence of real-world discrimination) and pursue \textit{formal equality} by balancing model error rates across subgroups based on membership to the protected attribute (PA). 
Such methods ``aim to not make society more unequal than the status quo''.
The latter, instead, assume a \textit{non-neutral status quo} and pursue \textit{substantive equality} by correcting the systematic biases behind the model error rates.
Such methods account for ``historical inequalities which actively ought to be eroded'' \cite{wachter_bias_2021}.
% TBD
% For instance, demographic parity \cite{Kamiran2009_ClassifyingWihtoutDiscriminating} is bias-preserving while equalized odds \cite{DBLP:conf/nips/HardtPNS16} bias-transforming \cite{wachter_bias_2021}:
% broadly, e.g., there is a key difference between ensuring the algorithm hires equal number of male and female applicants and ensuring it aims for such numbers to sustain beyond the hiring process.

% Classical fairness-aware machine learning (fairML) metrics, such as demographic parity or equalized odds, have been described as ``bias-preserving methods'' that aim for formal equality \cite{wachter_bias_2021}. These methods have the goal of replicating the real-world data-generating process -- possibly including historical discrimination -- with an emphasis on equal error rates for all subgroups of the PA. 
% That is, while they attempt to balance model error rates across subgroups, they do not attempt to address historical discrimination as they rely on evaluating models with respect to real-world labels. 
% In Wachter et al.'s words, ``they aim to not make society more unequal than the status quo'' \cite{wachter_bias_2021}.

% In contrast, ``bias-transforming methods'' aim at substantive equality ``by accounting for historical inequalities which actively ought to be eroded'' \cite{wachter_bias_2021}.
% Policies that actively work toward the latter goal are also called ``affirmative action'' or ``positive discrimination'' and are used, e.g., in college admissions: %\lb{Describe this a bit more}
% Several colleges have implemented policies to increase the numbers of students from historically underrepresented groups.\footnote{E.g., Harvard's statement on affirmative action can be found here: \url{https://hr.harvard.edu/files/humanresources/files/reaffirmation_statement.pdf}}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\textwidth]{figs/privilege_score_plots_250116.pdf} 
    \caption{PS and PS contributions for Amina.}
    \label{fig:iml_viz}
\end{figure}

Rectifying a non-neutral status quo is increasingly studied in fairML \citep[e.g.,][]{Alvarez2024Policy, Mittelstadt2024UnfairML, Russo2024BridgingResearchAndPractice}.
Motivated by discussions on non-discrimination law \citep[e.g.,][]{issa_kohler-hausmann_eddie_2019, wachter_bias_2021, weerts_algorithmic_2023}, including affirmative action \cite{Romei2014MultiSurveyDiscrimination}, a growing body of fairML work targets substantive equality and proposes bias-transforming methods  \citep[e.g.,][]{kusner_counterfactual_2017, black_fliptest_2020, plecko_fair_2020, alvarez_counterfactual_2023, bothmann_causal_2023}.
With varying degrees of explicitness, these works account for the influence of the PA on the other attributes to ``imagine'' an alternative and fairer world, particularly at the level of individual representation.
There is, however, a lack of articulation % by these and similar works 
on what exactly is being rectified.
Rectifying systematic biases and, ultimately, discriminatory patterns, indeed motivate these works, but these notions can be vague %and open to interpretation 
beyond the legal realm.
From a machine learning (ML) point of view, a more explicit formulation is needed for what we measure and wish to address when implementing bias-transforming fairML.

This paper introduces \textit{privilege scores (PS)}.
Assuming a non-neutral status quo, PS measure the level of privilege %or lack thereof 
due to the PA experienced by individuals within a decision-making context. % due to the PA.
We compute the PS by comparing the output of ML models between two worlds: the real world and a ``fair world'' in which the PA has no causal effect on the target.
At the individual level, PS identify %and, in turn, justify 
those individuals worthy of bias-transforming methods.
At the global level, PS not only allow to quantify 
%for the quantification of 
group privileges, but also explain the mediators through which these privileges are manifested, making PS a method for informing bias-transforming policies.
% This paper focuses on bias-transforming methods with applications such as affirmative action. 
% From a machine learning (ML) point of view, we ask how to identify those individuals who are most worthy of affirmative action. 
% For this purpose, we propose the concept of ``privilege scores'' that captures the \textit{individual} level of privilege in a certain task in the real world; this privilege may be positive or negative.\footnote{We use the term ``privilege'' instead of ``discrimination'' to avoid confusion with the many other meanings of discrimination.}
% A growing body of literature proposes to imagine a ``fair'' world in which the PAs have no causal effects on the target; so-called ``warpings'' are learned to transform real-world data into a ``warped world'' which shall approximate this fair world (e.g., \cite{bothmann_what_2024,bothmann_causal_2023,plecko_fair_2020}).
%
% PS take an individual perspective, recognizing that individuals are more than just members of a particular subgroup defined by PAs. In one particular example, a specific PoC might be discriminated against because of her race even if there is -- on average -- no racial bias; in another example, a specific PoC might not be discriminated against because of her race even if there is -- on average -- racial bias.  
%
The proposed PS apply at the dataset, model, and decision stage levels.
%
In addition to point estimates of PS, we provide individual confidence intervals that allow us to judge whether privilege is significantly non-zero. 
% To promote practical applicability and broad accessibility of our method, 
We also develop an interpretation method based on Shapley values for PS to quantify each feature's contribution to an individual's privilege.

% %However, PS are not limited to the affirmative action use case and can be used at 
% PS apply to three levels: data set, model, and decision stage. At the dataset level, we propose using PS to investigate whether a dataset is prone to historical discrimination and, if so, to quantify this discrimination.
% % Tests / feature importance, also feature effects.
% At the model level, PS can be used to check whether a given model exhibits unlawful discrimination. %; we also propose an in-processing method based on PS to avoid such discriminatory models.
% At the decision level, PS can be used to justify affirmative action. % as described above.


\paragraph{Main contributions.} %of this paper are: 
(1) We propose the formal concept of \textit{privilege scores} (PS) to quantify the impact of PAs on decision-making outcomes by comparing real-world scenarios to a ``fair world'' baseline; 
(2) we propose a methodological framework for (i) estimating PS, and (ii) quantifying the uncertainty of the estimators; %providing confidence intervals for the true PS; 
%and (iii) interpreting the estimated PS, thus making them accessible for real-world use cases,
(3) we present \textit{privilege score contributions (PSCs)}, %a tailored method for interpretable ML, 
an interpretation method to quantify each feature's contribution to an individual's privilege; %,
%fostering accessibility of PS for real-world use cases;
%(4) we present \textit{Multi-PrivScore}, an in-processing method that pushes models toward non-discrimination during training,
%(4) we investigate existing causal pre-processing methods for estimating PS; 
(4) we perform extensive experiments to showcase the performance of PS on simulated and real-world data.
%on simulated and real-world data to investigate the performance of the estimation methods and showcase real-world applications of PS.
%(5) we present several use cases to highlight the broad applicability of PS. 
%\lb{Touch on other use cases?}

% \paragraph{Outline.} While Section \ref{sec:usecases} describes use cases for PS through motivating examples, Section \ref{sec:related-work} discusses related work.
% Section \ref{sec:formalization} formalizes the general concept of PS; 
% %Section \ref{sec:usecases} describes relevant use cases for PS and derives desiderata for the methodological framework and experimental analysis; 
% Section \ref{sec:uq} develops methods for quantifying the uncertainty in estimating PS; 
% Section \ref{sec:iml} develops methods for explaining PS locally and globally, and outlines an algorithm for finding subgroups with exceptionally low or high PS; 
% Section \ref{sec:methods} discusses and compares methods that can be used to estimate PS, including an ensemble of candidate methods; 
% Section \ref{sec:experiments} provides a thorough experimental analysis of the proposed framework and its various implementations on both simulated and real-world data; Section \ref{sec:discussion} discusses our findings and concludes.\\

% \lb{
% PS quantify the concrete discrimination/privilege of a given person in a certain task. This can have direct use in ADM during training, and it can be viewed as ex-post evaluation of a model that used real-world data for training. These are some of the use cases that we have in mind, for details see Section \ref{sec:usecases}:
% \begin{enumerate}
%     \item Individual assessment, also in court: I was wrongfully discriminated (CI does not include 0), now I sue the company.
%     \item Positive Discrimination: Use low PS to justify individual positive discrimination, e.g., for college admission.
%     \item Subgroup assessment, for auditing: Subgroup $G=g$ has significant lower PS than other groups, therefore the ADM cannot be used operationally.
%     \item Multi-PrivScore: Use PS during training for optimizing subgroup fairness to avoid failing in an audit later.
% \end{enumerate}
% }

\subsection{Motivating examples}
\label{sec:usecases}

The following fictional examples motivate the use for PS at three levels: decision stage (individual assessment and affirmative action; see Appendix \ref{app:sec:uc_aff}), model (auditing ADM), and data set (auditing real-world DGP).
\paragraph{Individual assessment} 
\label{sec:uc_ind}

Amina applies for a mortgage. The bank's automated decision making (ADM) system predicts a repayment probability of $0.3$ and hence rejects Amina's application.
Amina appeals, saying, ``If the ADM's predictive model were based on data from a world without gender discrimination, my application would have been successful because my repayment probability would be $0.97$ instead of $0.3$. My estimated PS is $-0.67$ with a $95\%$ confidence interval (CI) of $(-0.9, -0.55)$. This suggests I was significantly discriminated against due to my gender.''
The first row of Figure \ref{fig:iml_viz} shows the PS and its CI. 
The blue and orange bars below 
%provide further insights by showing 
show
the PS contributions (with CIs) of the global and individual intercepts and two features: 
\textit{STEM} (binary, degree in STEM vs.\ other) and \textit{Lead} (binary, job with leadership role vs.\ other). This would allow the bank to argue against unlawful gender discrimination by arguing that the PS is driven by an effect mediated by career path -- which, in their view, is a valid reason for higher credit risk.
However, the significant negative individual intercept suggests a gender effect that goes beyond these admissible paths, and thus 
would substantiate Amina's claim of unlawful
%would manifest unlawful 
gender discrimination
%, which would substantiate Amina's claim.
(see Section \ref{sec:iml} for details). 
%we can see that feature \textit{STEM} is the mediator that contributes most to her PS.
% Figure \ref{fig:privilege_score_plots} (bottom plot) shows Bell's feature values and predictions in the real and warped worlds. 

% \todo[inline]{Here and Section on PSCs: Just one plot, reference in both sections.}


%\begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.5\textwidth]{figs/privilege_score_plots_amina_res_based_global_2024-10-29_06-58-35.pdf} 
%     \caption{Top plot: Estimated PS (first row) and PSCs for Amina -- with confidence intervals. Bottom plot: Comparison of predicted credit risk and features between the real world and the warped world (axes are min-max scaled).}
%     \label{fig:iml_viz}
% \end{figure}





\paragraph{Auditing ADM} Chimamanda works for a government regulatory agency and is tasked with auditing the bank's ADM system. She examines the subgroup PS of various groups and has two main findings: (i) in the group of people who wear glasses, the distribution of PS is not centered around zero. 
Since wearing glasses is not a PA, this finding is reported to the bank for further monitoring without immediate consequences; 
(ii) in the group of Black women, the distribution of PS is also not centered around zero, but is significantly shifted. Because a (fictitious) law states that for protected groups, the PS must be centered around 0, 
the ADM system is not approved for operational use. %, and the bank must correct this problem before approval.

\paragraph{Auditing real-world DGP} Chimamanda's colleague Kimberlé is tasked with auditing the NYPD's policing strategy regarding its ``Stop, Question and Frisk'' program. It is suspected that this strategy may suffer from bias at the intersection of race and gender. Kimberlé uses an analysis similar to Chimamanda's, with the difference that she does not test a given ADM system, i.e., a given ML model, but the actual data-generating process (DGP) that led to the data at hand, i.e., the (black-box) policing strategy of NYPD. To do this, she first trains an ML model on the real data and audits this as a surrogate for the true DGP. %treats it as the fictitious basis of a fictitious ADM system. 


\subsection{Related Work}
\label{sec:related-work}

The proposed PS are intended for addressing a (presumed to be) non-neutral status quo.
We position our work relative to other fairML works that aim at changing such status quo by implementing, according to 
\citet{wachter_bias_2021}, ``bias-transforming'' methods \citep[e.g.,][]{kusner_counterfactual_2017, black_fliptest_2020, alvarez_counterfactual_2023}.
\citet{kusner_counterfactual_2017} famously introduce counterfactual fairness, which compares the factual distribution to its counterfactual counterpart \citep[using the steps of abduction, action, and prediction of][]{PearlCausality2009} in which the downstream influence of the PA is accounted for all other attributes.
\citet{black_fliptest_2020} and \citet{alvarez_counterfactual_2023}, respectively, test for individual discrimination by comparing the observed profiles to generated ones in which the seemingly neutral attributes are updated conditional on the effect of the PA.
In terms of fairML methods, our work relates mainly to pre-processing methods such as those proposed by \citet{plecko_fair_2020} and \citet{bothmann_causal_2023}.
%We come back to these methods in the next section.
We differ from all these works by explicitly formulating what drives the non-neutrality of the status quo in the form of privilege.

Noteworthy are the ongoing fairML discussions on achieving long-term fairness \citep[e.g.,][]{DBLP:conf/www/HuC18, DBLP:conf/fat/DAmourSABSH20, DBLP:conf/fat/SchwobelR22} and addressing the accuracy-fairness trade-off  \citep[e.g.,][]{DBLP:conf/nips/WickpT19, DBLP:journals/corr/abs-2011-03173, DBLP:journals/natmi/RodolfaLG21, leininger-tradeoffs-2025}, respectively.
The former argues that fairness interventions need to consider their impact over time. 
The latter argues that the trade-off is trivial as long as the data used for training is biased. 
Together with \citet{wachter_bias_2021} and its bias-preserving versus bias-transforming distinction, 
both discussions are examples of a more explicit direction within fairML of using algorithmic tools to intervene in the status quo.
Our work adds privilege to the discussion, viewing it as a consequence of the non-neutral status quo.


% \iffalse
% %SUGGESTION LISA FOR REORDERED RELATED WORK SECTION
% In what sparked a strand of seminal work in fairML, \citet{kusner_counterfactual_2017} introduced counterfactual fairness as a divergence of the factual distribution from its counterfactual counterpart \citep[using the steps of abduction, action, and prediction of][]{PearlCausality2009} in which the downstream influence of the PA on all other attributes is accounted for.
% A number of recent contributions have promoted the explicit use of algorithmic tools to intervene on a non-neutral status quo.
% Besides \citet{wachter_bias_2021} and their aforementioned distinction between bias preservation and bias transformation, discussions of long-term fairness \citep[e.g.,][]{DBLP:conf/www/HuC18, DBLP:conf/fat/DAmourSABSH20, DBLP:conf/fat/SchwobelR22} and the accuracy-fairness trade-off  \citep[e.g.,][]{DBLP:conf/nips/WickpT19, DBLP:journals/corr/abs-2011-03173, DBLP:journals/natmi/RodolfaLG21, plecko_trade_2024, leininger-tradeoffs-2025} are particularly noteworthy.
% The former advocates for considering the impact of fairness interventions over time, while the latter argues out that the trade-off is trivial in tasks with biased training data.
% Our contribution formalizes the discussion by introducing the notion of privilege as a consequence of the non-neutral status quo.
% Concurrent work that aims at changing the undesirable status quo by implementing bias-transforming methods includes \citet{kusner_counterfactual_2017, black_fliptest_2020, alvarez_counterfactual_2023}.
% From a more technical perspective, our work relates mainly to pre-processing methods such as those proposed by \citet{plecko_fair_2020} and \citet{bothmann_causal_2023}.
% %We will revisit these methods in the next section (WHY? that's something I don't enjoy as a reader).
% While the previous works have greatly contributed to the progress of fairML, they remain vague on what drives the non-neutrality of the status quo.
% We close this gap by formalizing the causes in the form of privilege.
% The resulting PS provide a crucial opportunity for identifying individual-level discrimination and informing global bias-transforming policies.
% \fi

\section{Background and Notation}
\label{sec:background}

% \todo[inline]{
% Introduce with respective notation:
% \begin{itemize}
%     \item FiND world - fulfills several group-level and individual-level fairness notions, see Leininger et al. 25
%     \item .. has to be approximated
%     \item examples are residual-based warping (later referred to as ``warping'') and fairadapt
%     \item .. was investigated in Bothmann et al. 23 and in \cite{leininger-tradeoffs-2025}, seems to work well
%     \item that is why we use those, too. Investigation of others is left for future work
% \end{itemize}
% }

\paragraph{FiND World}

For constructing a ``fair world'', we follow the philosophical rationale of \citet{bothmann_what_2024} who propose a fictitious, normatively desired (FiND) world, where the PAs have no direct nor indirect causal effect on the target. %\footnote{They also conceptualize how to incorporate path-specific fairness by normatively allowing certain causal paths.} 
We present the classification case in the remainder, but  an extension to regression is straightforward.
The basis for a decision or treatment, also called  ``task-specific merit'', is the individual probability\footnote{Individual in the sense that we condition on all of a person's characteristics, measured and unmeasured -- which we suppress notationally for convenience.} $\pi = \P(Y=1)$ for target $Y \in \{0,1\}$ in the real world, if no PAs are present.\footnote{E.g., probability of paying back the mortgage.} %In a regression task, we take expected values. While we present the classification case in the remainder, extension to regression is straightforward.} 
Under presence of PAs, the task-specific merit is taken to be the counterpart $\psi = \P(Y_F=1)$ in the FiND world with $Y_F \in \{0,1\}$ denoting the target there, i.e., while the label spaces are identical, distributions can differ.
%a fictitious, normatively desired (FiND) world, where the PAs have no direct nor indirect causal effect on the target. 
Using the task-specific merit as basis for decisions, ``equals are treated equally and unequals are treated unequally'', where equality is measured either in the real or the FiND world, depending on normative stipulations regarding PAs. 
\citet{leininger-tradeoffs-2025} show that several common fairness notions -- on the group and on the individual level -- are simultaneously fulfilled in the FiND world, overcoming the fairness-accuracy trade-off and the impossibility theorem \cite{chouldechova_fair_2017,kleinberg_inherent_2017}.\footnote{\citet{bothmann_what_2024} and \citet{leininger-tradeoffs-2025} elaborate on differences between this approach and counterfactual fairness.}

\paragraph{Approximating the FiND World}
\label{sec:methods}

In practice, we do not have access to this FiND world and  approximate it empirically. This means that all descendants $\xv$ of the PAs have to be mapped or ``warped'' to values $\xtil$ that approximate their counterfactual values $\xv_F$ in the FiND world (on training data, this includes warping the target $y$ to $\yt$). 
The corresponding task-specific merit in this ``warped world'' is denoted by $\pitil = \P(\tilde{Y} = 1)$ with warped-world target $\tilde{Y} \in \{0,1\}$. Probabilities $\pi, \pitil, \psi$ in the different worlds are approximated by functions $\pix, \pitx, \psix: \Xspace \rightarrow [0,1]$ of observable features $\xv, \xtil, \xv_F \in \Xspace$. These, in turn, are estimated by ML models $\pixh, \pitxh, \psixh: \Xspace \rightarrow [0,1]$.



Such ``warping'' methods may or may not be based on the concept of causality. 
Warping methods rooted in causality are better-suited to approximate the FiND world, yet come with the obvious drawback of requiring a directed acyclic graph (DAG). 
%While we assume that causal methods should, in general, approximate the FiND world better, they have the obvious drawback that they need a directed acyclic graph (DAG) as starting point. 
When the DAG is misspecified, the success of the methods is questionable (and will be investigated empirically in Section \ref{sec:experiments}). %Non-causal methods might in general work less well but should be more robust against causal misspecification.
In the experiments below, we focus on two methods, namely fairadapt by \citet{plecko_fair_2020} and a residual-based warping (later referred to as ``res-based warping'') proposed by \citet{bothmann_causal_2023}. 
Both are causal methods and very closely adopt the philosophy of the FiND world concept 
\citep[see also][]{bothmann_causal_2023,leininger-tradeoffs-2025}. % compare these warping methods under different viewpoints and conclude that both approximate the FiND world well.
%
A thorough comparison with other warping methods is left for future research. % and we focus on exemplifying PS analyses with these two methods.

Since PS -- as presented below -- are a general class of scores, the number of possible estimation methods is not limited. 
The general concept of PS is agnostic to the precise definition of the fair world. It only requires the ability to (approximately) predict in both this world and the real one. 
%While a fair world has to be defined, the general concept of PS is agnostic to the concrete definition of the fair world.
%It only depends on being able to predict in both the real and a somehow defined fair world (or its empirical approximation).
%Suitable methods allow generating instances of a somehow defined counterfactual world or to map a given observation into that world. 
%The concept of PS laid out below is agnostic to the concrete definition of the fair world and only depends on being able to predict in both the real and a somehow defined fair world.


% \begin{table}[ht]
%   \centering
%   \begin{tabular}{lccc}
%     \toprule
%     World: &Real & Warped & FiND\\
%     \midrule
%     Fair treatment & $\pii$ & $\piti$ & $\psii$ \\
%     %Fair treatment & $\spii$  &  $\spiti$ & $\spsii$  \\
%     w/ coarse inf. & $\pixii$& $\pitxti$ & $\psixi$ \\
%     w/ ML model&$\pixih$&$\pitxtih$ & $\psixih$\\
%     \bottomrule
%   \end{tabular}
%    \caption{Summary of notation.}
%    \label{tab:two_worlds}
% \end{table}

% \begin{table}[ht]
%   \centering
%   \begin{tabular}{lccc}
%     \toprule
%     &Real world & Warped world & FiND world\\
%     \midrule
%     True target probability & $\pii$ & $\piti$ & $\psii$ \\
%     Fair treatment & $\spii$  &  $\spiti$ & $\spsii$  \\
%     Treatment w/ coarse inf. & $\spixii$& $\spitxti$ & $\spsixii$ \\
%     Treatment w/ ML model&$\spixih$&$\spitxtih$ & $\spsixih$\\
%     \bottomrule
%   \end{tabular}
%    \caption{Notation, taken from Bothmann et al.\ (2024) \cite{bothmann_what_2024}.}
%    \label{tab:two_worlds}
% \end{table}

\section{Privilege Scores (PS)}
\label{sec:formalization}


The PS $\priv$ quantifies the task-specific privilege of an individual. % $T$. %, subject to a given decision instance $Z$ that uses a model learned by an inducer $I$ on data $\D$ -- considering a given set of PAs $A$:
%
%For this,
To derive $\priv$ we need to compare real-world treatment with fair-world treatment. %, where the PA has no causal effect on the decision basis or ``task-specific merit''. 
%
Since the treatment is not based on the true values $\pi$ and $\psi$ but on the values $\pix$ and $\psix$ computable by the features, we define a PS as the privilege of an individual resulting from computing the decision basis in the real world instead of computing it in the FiND world:\footnote{\citet{bothmann_what_2024} introduce a treatment function $\sfu$ transforming task-specific merit normatively to define a treatment. For ease of presentation, we assume this to be the identity.} 

\begin{definition}[Privilege Score]
A privilege score $\priv: \Xspace \times \Xspace \rightarrow [-1,1]$ is a comparison of the treatment of an individual in the real versus in a fair world. It is a function of the individual's feature vector $\xv$ %task $T$, decision-making instance $Z$ (which defines treatment function $s$ and decision basis $\pi$, estimated as $\pih$ using learner $I$ on data $\D$), 
in the real world and $\xv_F$ in the fair world. 
%set of PAs $\bm{A}$ (defining the fair world and hence a mapping from $\xi$ to $\xfindi$), and the individual's values of the PAs $\ai$, i.e.,
%\[\privi = \priv(\xi, \bm{A}, \ai),\]
More explicitly, it is the difference
\[\priv = \priv(\xv, \xv_F) = \pix - \psix\]
% or the ratio
% \[\privi_r = \frac{\spixii}{\spsixii}\]
of the respective probabilities.\footnote{We could also use the ratio but argue that the difference enhances interpretability later.}
\end{definition}

% Two special cases can be considered:
% \begin{itemize}
%     \item If $A = \varnothing \Rightarrow \priv_i=0, \privi_r=1$, by definition, as real world and FiND world are identical.
%     \item $Z$ does not use model predictions, then $\privi = \priv(\xi, Z, A, \ai)$, and it remains unclear how to design a PS here -- depends on what $Z$ actually uses as basis for treatment (ignore in the remainder).
%     %\item Treatment function $s(\fh(\xi)) = \fh(\xi)$ is the identity.
% \end{itemize}

%For the remainder, we consider only $\privi$. 
We estimate $\priv$ by estimating $\pif$ and $\psif$ (1) and approximating the FiND world via warping (2):
\begin{align*}
    \priv &= \pix - \psix \\ 
    % &\stackrel{\text{estimate} \ \pif}{\approx} \spixih - \spsixih \\ %\quad \lb{\text{Or is this $\privi$?}} \\
    % &\stackrel{\text{approximate FiND world}}{\approx} \spixih - \spitxtih  \\
    &\stackrel{(1)}{\approx} \pixh - \psixh \\ %\quad \lb{\text{Or is this $\privi$?}} \\
    &\stackrel{(2)}{\approx} \pixh - \pitxth =\hp.
%    &= \hat\prob(y_F = 1 | \xv_F = \xfindi) - \hat\prob(y=1 | \xv=\xi)
\end{align*}


\paragraph{Theoretical analysis}

Analyzing the bias of the estimator $\hp$, we can derive:
\begin{align*}
    % \E(\hpi) &= \E(\pixih - \pitxtih) &\\
    % &= \E(\pixih) - \E(\pitxti) &\\
    \E(\hp) &\stackrel{\text{if models are unbiased}}{=} \pix - \pitil(\xtil) & \\
    &\stackrel{\text{if warped = FiND world}}{=} \pix - \psix & = \priv. %\\
    %&=\privi &
\end{align*}

With unbiased ML models $\pih$ and $\pitilh$, and with a perfect warping method, $\hp$ is an unbiased estimator for $\priv$. Analyzing the variance of the estimator $\hp$, we can derive:
\begin{align*}
    %\var(\hpi) &= \var(\pixih - \pitxtih) &\\
    \var(\hp)&= \var(\pixh) + \var(\pitxth) \\
    & \quad - 2 \cov(\pixh, \pitxth).
\end{align*}
This means, to minimize the variance, we need low-variance ML models $\pih$ and $\pitilh$ which should be correlated, i.e., real and warped world should be close. However, we do not want to push the warped world toward the real world, as we want to have a good approximation of the FiND world for unbiasedness. 
%
In summary, we want (i) unbiased ML models $\pih$ and $\pitilh$, (ii) low-variance ML models $\pih$ and $\pitilh$, (iii) very good approximation of FiND world via warped world, (iv) and variance is smaller if the gap between real and warped world is smaller (which means -- if we are not willing to sacrifice unbiasedness -- variance is smaller if real and FiND world are closer, i.e., if the real world is ``fairer''). %, i.e., if PS are smaller).



\paragraph{Uncertainty Quantification}
\label{sec:uq}



We can use bootstrapping (or subsampling) to construct CIs for PS. 
Algorithm \ref{alg:bootstrap-any} describes a general bootstrapping algorithm for a combined prediction pipeline. 
In the experiments considered later, the learning step consists of (i) learning the warping on bootstrapped data $\D_b$, (ii) warping $\D_b$ to $\Dt_b$, (iii) learning the models $\pih_b$ and $\pitilh_b$ based on $\D_b$ and $\Dt_b$, respectively, and the prediction step consists of (i) warping the test observation $\xv$ to $\xtil$, (ii) computing the predictions $\pih_b(\xv)$ and $\pitilh_b(\xtil)$.
However, the general algorithm also allows, e.g., to include the step of discovering the DAG first during learning, making it even more general.
%
The resulting CI is:
\[\cih_B = \left[\hp_{(\alpha/2)}, \hp_{1-(\alpha/2)}\right],\]
where $\hp_{(\alpha/2)}$ and $\hp_{1-(\alpha/2)}$ are the 
%$(\alpha/2)$ and $1-(\alpha/2)$ 
respective quantiles of the scores $\hp_b$, 
%respectively, 
and $B$ is the number of bootstrap iterations. It can be interpreted as $\P(\cihi_B \ni \privi) = 1 - \alpha$. % as usually.




\begin{algorithm}
\caption{Bootstrapping PS}
\label{alg:bootstrap-any}
\begin{algorithmic}[1]
\STATE {\bfseries Input:} Train data $\D$, % = \Dset$, 
test observation $\xi$
\FOR{$b = 1, \dots, B$}
    \STATE Draw bootstrap sample $\D_b$ from $\D$
    \STATE Learn prediction pipeline on $\D_b$
    \STATE Apply prediction pipeline on $\xi$ %$\Rightarrow \pih_b(\xi)$ and $\pitilh_b(\xti)$
    \STATE Compute score $\hpi_b = \pih_b(\xi) - \pitilh_b(\xti)$
\ENDFOR
\STATE \textbf{Output:} $\hpi_1, \dots, \hpi_B$
\end{algorithmic}
\end{algorithm}


\section{Privilege Score Contributions (PSCs)}
\label{sec:iml}

We aim at three types of interpretability tasks: (i) local interpretability to explain why a particular individual PS is low/high, 
(ii) global interpretability to explain the global impact of individual features on PS, 
(iii) find and describe subgroups that have unusually low/high PS. 
%
If we interpret the PS $\hpx$ as a black-box ML model, we can use the entire toolbox of model-agnostic interpretable ML (IML). 
We can ``ignore'' the complexity of having two ML models and the warping between the two worlds, 
i.e., we can interpret PS $\hpx$ in terms of real world features $\xv$, see also \ref{app:iml-standard}.
%
% \begin{algorithm}[ht]
% \caption{Permutation Feature Importance (PFI)}
% \label{alg:pfi}
% \begin{algorithmic}[1]
% \STATE Learn warping and ML models in real and warped world ($\pih()$ and $\pitilh()$)
%
% \STATE Compute test error of predictions $\hpi$
% \FOR{each feature $x_j$}
%     \STATE Permute the values of feature $x_j$
%     \STATE Compute predictions $\hpi_*$ using same warping and models $\pih()$ and $\pitilh()$
%     \STATE Compute test error of predictions $\hpi_*$
%     \STATE Estimate FI via difference of the test errors
% \ENDFOR
% \IF{multiple permutations are performed}
%     \STATE Repeat the permutation process several times and average
% %    \STATE Take the average of the computed differences over all repetitions.
% \ENDIF
% \end{algorithmic}
% \end{algorithm}

%\paragraph{Privilege Score Contributions (PSCs)} 
However, in many use cases, we would like to add transparency by being able to explicitly interpret the effect of warping on PS.
We cannot use an off-the-shelf IML method to do this, so we propose a novel method, called \textbf{Privilege Score Contributions (PSCs)}. 
%
What appears to be one privilege -- e.g., gender privilege -- may actually consist of several privileges -- e.g., gender may influence not only career choice (through societal norms) but also income for a given job (through direct discrimination). 
For local interpretations of PS, we want to separate the effect of removing a particular privilege by removing the corresponding causal effect starting in the PA, from the effect of using warped world instead of real world data for training.
To this end, we propose PSCs, that quantify the contributions of each single privilege to the total PS. %, which we call ``Privilege Score Contributions'' (PSC). 
This is equivalent to fictitiously ``breaking the wheel'' of discrimination by ``breaking'' the causal effect of each PA-related mediator path separately.
%
Let us take fictitious data for Amina who is applying for a mortgage and let us assume, the bank's ADM system predicts the probability of repayment. Figure \ref{fig:DAG-example-psc} shows exemplary DAGs for the real and warped world, and Table \ref{tab:shap_example} shows Amina's values for both worlds.\footnote{Note that these DAGs only serve illustrational purposes and true DAGs will likely be more complex.} 
We want to split the PS of $\hpx = -0.67$ into different contributions.

\begin{figure}[ht]
    \centering
% \begin{tikzpicture}[x=3in, y=4in] % Adjusted scaling
% \node[ellipse, draw] (v0) at (0.5,-0.6) {$C$}; % Age in the middle, above others
% \node[ellipse, draw] (v2) at (0.1,-0.6) {$A$};
% \node[ellipse, draw] (v3) at (0.5,-0.5) {$X_2$};
% \node[ellipse, draw] (v4) at (0.9,-0.6) {$Y$};
% \node[ellipse, draw] (v6) at (0.5,-0.7) {$X_1$}; % New node between Gender and Mortgage

% \draw [->] (v0) edge (v3);
% \draw [->] (v0) edge (v4);
% \draw [->] (v0) edge (v6);
% \draw [dotted, ->] (v2) edge (v3); % Dashed arrow from Gender to Income
% \draw [dotted, ->] (v2) edge (v6); % Dashed arrow from Gender to Node 2
% \draw [->] (v6) edge (v4); % Dashed arrow from Node 2 to Mortgage
% \draw [dashed, ->] (v2) .. controls (0.4,-0.8) and (0.625,-0.8) .. (v4); % Dashed arrow from Gender to Mortgage (direct)
% \draw [->] (v3) edge (v4);
% \end{tikzpicture}
        \begin{tikzpicture}[x=3in, y=4in] % Adjusted scaling
        \node[ellipse, draw] (v0) at (0.6,-0.24) {$Y$};
        \node[ellipse, draw] (v1) at (0.2,-0.24) {$\bm{C}$};
        \node[ellipse, draw] (v2) at (0.4,-0.24) {$X_1$};
        \node[ellipse, draw] (v4) at (0.3,-0.15) {$X_2$};
        \node[ellipse, draw] (v5) at (0.5,-0.10) {$A$};

        % Draw arrows
        \draw [line width=1pt, ->] (v1) edge (v2);
        \draw [line width=1pt, ->] (v1) edge (v4);
        \draw [line width=1pt, ->] (v2) edge (v0);
        \draw [line width=1pt, ->] (v4) edge (v0);

        % Dashed and curved arrows
        \draw [line width=1pt, dashed, ->] (v5) edge (v0); 
        \draw [line width=1pt, dotted, ->] (v5) edge (v2);
        \draw [line width=1pt, dotted, ->] (v5) edge (v4);
        \end{tikzpicture}
        
    \caption{Exemplary DAGs. Real world: all arrows exist. Warped world: only solid arrows exist. PSCs quantify the effect of breaking the dotted and dashed arrows separately.}
    \label{fig:DAG-example-psc}
\end{figure}

\begin{table}[h]
\centering
\caption{Fictitious data. $A$ is the binary PA \textit{Gender} (male (1) or female (0)); $C$ is a confounder \textit{Age}; $X_1$ and $X_2$ are binary features and reflect Amina's choices regarding study program (STEM field (1) or not (0)) and regarding job type (leadership role (1) or not (0)), respectively; $\tilde{X}_1$ and $\tilde{X}_2$ are warped versions; $\pixh$ and $\pitxth$ describe predictions of repayment $Y$ (yes (1) or no (0)) in the real and warped world; $\hpx$ is the estimated PS.}
\begin{tabular}{c|c|c|c|c|c|c|c|c}
%\hline
$A$ & $C$ & $X_1$ & $\tilde{X}_1$ & $X_2$ & $\tilde{X}_2$ & $\pixh$ & $\pitxth$ & $\hpx$ \\
\hline
0   & 22   & 0   & 0.6   & 0   & 0.2   & 0.30   & 0.97   & -0.67 \\
%\hline
\end{tabular}
\label{tab:shap_example}
\end{table}

\paragraph{Definition of PSCs}

(Estimated) PS can be written as
\begin{equation}
    \label{eq:psc-1}
    \hpx = \pixh - \pitxth = \underbrace{\pixh - \pih(\xtil)}_{\sum_{j=1}^k\gx[j]} + \underbrace{\pih(\xtil) - \pitxth}_{\pxtil[0]},
\end{equation}
where $k$ is the number of privileges induced by the PA or the number of PA-related mediator paths, which is equal to the number of arrows starting in the PA and leading to features (i.e., the dotted arrows in Figure \ref{fig:DAG-example-psc}).\footnote{The 
dashed arrow $A\rightarrow Y$ is treated separately: We do not warp $Y$ at prediction time as we do not know it. However, the intercept term can be interpreted as the part of the PS that can not be attributed to the other $k$ privileges, and hence reflects the contribution of using warped-world instead of real-world training data, i.e., the effect that goes beyond warping the individual feature set which is attributable to the differing worlds.} 
This decomposition splits the PS into (i) the local \textbf{privilege score contribution} $\gx[j]$, i.e., the effect that arrow/privilege $j$ has for the real-world model %($\pixh - \pih(\xtil)$) 
by warping its descending features, and (ii) the effect of using real-world instead of warped-world training data on the warped features as well as interaction effects of privileges with warped features -- the \textbf{local intercept} $\pxtil[0] = \pih(\xtil) - \pitxth$. Alternatively, we can go to the warped model first and analyze the effect that warping the features has on the warped-world model:
\begin{equation}
    \label{eq:psc-2}
    \hpx = \pixh - \pitxth = \underbrace{\pitilh(\xv) - \pitxth}_{\sum_{j=1}^k\tgx[j]} + \underbrace{\pixh - \pitilh(\xv)}_{\px[0]},
\end{equation}
While both alternatives can be computed equally well and may be interesting in a practical use case, we prefer the first option: 
After warping, the feature space in the warped world is likely to have smaller ranges in some dimensions than the original feature space in the real world, because the PA effects have been eliminated and thus the possible heterogeneity due to the PA is reduced. 
This could lead to situations where the feature vectors are outside the distribution of the training data used for the warped world model, leading to artificially noisy predictions if a learner is chosen that does not extrapolate well.

The local intercept $\pxtil[0]$ describes the local difference between real and warped world models for the warped feature vector. 
We introduce a general level shift by splitting $\pxtil[0]$:
\begin{align*}
    \hpx &= \underbrace{\left(\pih(\xtil) - \pitxth\right)}_{\pxtil[0]} + \sum_{j=1}^k\gx[j] \\
    &= \underbrace{(\pih(\xtil) - \bar{\pih}) + (\bar{\pih} - \bar{\pitilh}) + (\bar{\pitilh} - \pitilh(\xtil))}_{\pxtil[0]} 
    + \sum_{j=1}^k\gx[j] \\
    &= \underbrace{(\bar{\pih} - \bar{\pitilh})}_{\priv_g}
    + \underbrace{(\pih(\xtil) - \bar{\pih}) - (\pitilh(\xtil) - \bar{\pitilh})}_{\priv_{\xtil}}  
    + \sum_{j=1}^k\gx[j], \\
%    &\stackrel{(\ref{eq:psc-2})}{=} \underbrace{(\bar{\pih} - \bar{\pitilh})}_{\priv_g}
%    + \underbrace{(\pih(\xv) - \bar{\pih}) - (\pitilh(\xv) - \bar{\pitilh})}_{\priv_{\xv}}  
 %   + \sum_{j=1}^k\tgx[j] \\
\end{align*}
where averages $\bar{\pih}$ and $\bar{\pitilh}$ are computed for training data, using the real world feature values.
The \textbf{global intercept} $\priv_g$ describes a general, global shift between the real world and the warped world that applies to the entire population.
The \textbf{individual intercept} $\priv_{\xtil}$ %describes the difference between the local and global intercepts, i.e., 
centers the local intercept around the global intercept, which facilitates its interpretation.


\paragraph{Framing via Shapley values}

We can frame our approach in terms of Shapley values \cite{shapley_value_1953} using the specific value function from Eq.\ \ref{eq:value}, motivated by the goal of fairly distributing (possibly interacting) effects on PS across PA-related mediator paths.
A coalition $S \subseteq P$ is a set of arrows starting in the PA and ending in features, $P=\{1, \dots, k\}$ is the set of all these $k$ arrows (dotted arrows in Figure \ref{fig:DAG-example-psc}). 
%The general idea is that instead of adding features to a coalition $S$, we always keep the number of features constant at the total number of features, but vary which features are warped and which are not warped.\\
%
%For a set of warped features $S \subseteq P$ ($P$ is the full set of features), 
The \textbf{value functions} $v(S)$ in the real world is defined as:
\begin{equation}
\label{eq:value}
v(S) = \pixh - \pih(\xv_{S}),    
\end{equation}
where $\xv_{S}$ is the feature vector after having removed all and only the arrows in $S$, i.e., features on respective paths have been warped. This is a value function since
\[v(\emptyset) = \pixh - \pixh = 0,\]
and
\[v(P) = \pixh - \pih(\xtil)\] % = \sum_{j=1}^k \gx[j].\]
%We prove \textbf{efficiency} in \ref{app:iml-efficiency}.

\textbf{Marginal contribution of privilege $j \in P$} is defined as:
\[ v(S \cup \{j\}) - v(S) = \pih(\xv_S) - \pih(\xv_{S \cup \{j\}}).\]
This leads to the \textbf{Shapley-style PSCs}:
%Let Sπ (j) be the set of players that appear before j in the permutation
\begin{equation}
\label{def:psc}
\gx[j] = \frac{1}{M}\sum_{m=1}^M\pih(\xv_{S_j^{(m)}}) - \pih(\xv_{S_j^{(m)} \cup \{j\}}),%\\
\end{equation}
%&\approx\frac{1}{M}\sum_{m=1}^M[\pih(\xv_{\sim j-1}^{(m)}) - \pih(\xv_{\sim j}^{(m)})],
where $S_j^{(m)}$ is the set of players that appear before $j$ in permutation $m$, and $M=k!$ is the total number of permutations of $P$.
%where $S_j^{(m)}, \dots, S_j^{(M)}$ are all possible combinations of removing/not removing the $k-1$ arrows that are not $j$, and $M=2^{k-1}$. 
%
We show efficiency (Theorem \ref{th:eff}) and other axioms of fair payouts in \ref{app:iml-efficiency}.
\begin{theorem}[Efficiency]
\label{th:eff}
Let $\{\gx[j]\}_{j \in P}$ be the Shapley values induced by $v$. Then
$$
\sum_{j=1}^k \gx[j]
\;=\;
v(P)
\;=\;
\pih(\xv) - \pih(\xtil).
$$
\end{theorem}
Analogously, we can define value function $\tilde{v}(S)$ and Shapley-Style PSCs $\tgx[j]$ in the warped world using $\tilde{v}(S) = \pitilh(\xv) - \pitilh(\xv_{S})$, etc.
%
For estimation, we do not have the computational complexity problem of Shapley values, since we usually consider a rather small number $k$ (task-specific justifiable PA-related mediator paths). %and can compute the PSC values. 
Similar to Algorithm \ref{alg:bootstrap-any}, we can compute \textbf{bootstrap CIs} for any PSC by performing the PSC computation on bootstrap samples. 
%and then computing the respective $\frac{\alpha}{2}$ and $1-\frac{\alpha}{2}$ quantiles. 



\paragraph{Partially warped features}

In a DAG such as in Figure \ref{fig:DAG-example-psc}, the vector $\xv_{S}=(\xtil_{d(S)}, \xv_{nd(S)})$ consists of warped versions of features $d(S)$ on paths descending from $S$ and real versions of non-descending features $nd(S)$. However, there can be DAGs with features descending from more than one privilege. Appendix \ref{app:iml-partial-warping} treats these cases. 


\paragraph{Downstream analyses}

%As elaborated on, PSCs can be used for individual interpretation. However, 
PSCs can be used for other use cases, adding to the above individual interpretation:
%are even a more versatile tool. Use cases are:
\begin{itemize}
    \item Global strength of privileges: We can analyze (moments of) distributions of PSCs %for a given feature 
    to investigate the global effect of the respective privilege. By this means, we can quantify a privilege, which vice versa quantifies by how much discrimination can be reduced via tackling the respective privilege with political actions. E.g.: If $A \rightarrow X_1$ induces an average privilege of increasing/decreasing the risk score by $\zeta$, tackling the gender-related discrepancy of career choice can diminish the gender-related discrepancy in risk scores by this $\zeta$. Furthermore, the intercept terms hint at direct discrimination, as they capture the part of the PS which is not directly attributable to single privileges.
    \item Feature importance: By averaging the absolute PSCs for each privilege, we can derive task-specific ``privilege importances''. E.g., it might be the case that the gender pay gap is a major driving factor for gender-related discrepancies in credit risk scores, but not for gender-related discrepancies in recidivism scores.
    \item Investigate interactions between privilege and features: SHAP dependence plots \cite{lundberg_local_2020} can be used to visualize the effect that a feature $x_l$ has on $\gx[j]$. This could be used to examine whether gender-based privilege via income depends on age or race, revealing subgroups of the PA that suffer more from privilege (such as young Women of Color) than others.
    \item Subgroup analysis: We can investigate subgroups that on average show exceptionally high or low PS values, e.g., via bump hunting \cite{friedman_bump_1999}.
\end{itemize}


\paragraph{Standard Shapley values}
Alternatively, we can use ``standard'' Shapley values for interpretation (see Appendix \ref{app:iml-shapley}). Interpretation of the Shapley values $\eta_j$ differs substantially from the interpretation of PSCs while both angles may be interesting in a practical use case. Shapley values $\eta_j$ focus on relating the PS of an individual to their features and disregard the question of whether that contribution is due to the warping of the feature or due to the differing model in the warped world. On the other hand, PSCs focus on the PA effects and disentangle the effect of privilege $j$ ($\gx[j]$) from the effect of using the warped-world model instead of the real-world model ($\pxtil[0]$). 
%The joint effect of non-warped features can be interpreted through the individual intercept ($\priv_{\xv}$).



\paragraph{Examples of PSCs}
Figure \ref{fig:iml_viz} visualizes PSCs for the example of Amina, corresponding to Table \ref{tab:shap_example}: 
The PSC of $\hgx[1]=-0.25$ from \textit{STEM} can be interpreted as follows: Warping Amina's value of \textit{STEM} from $0$ to $0.6$ (i.e., fictitiously increasing her probability of having chosen a STEM career) increases the real-world prediction by $0.25$. 
The PSC of $\hgx[2]=-0.12$ means: Warping Amina's value of \textit{Lead} from $0$ to $0.2$ (i.e., fictitiously increasing her probability of having a job with leadership role) increases her real-world prediction by $0.12$.
Using the warped-world prediction model instead of the real-world prediction model increases the prediction further by $0.3$ (the local intercept of $\hpxtil[0] = -0.3$ can be splitted into an individual intercept of $\hp_{\xv}=-0.4$ %means that using Amina's warped features with the warped world prediction model increases the prediction by $0.3$. 
and a global intercept of $\hp_g=0.1$). % means that, on average over the entire training data, the predictions in the real world are $0.1$ higher than in the warped world. 
 
To put it another way: 
All people get -- on average -- a higher prediction in the warped world ($\hp_g$), but those with features in a local neighborhood of Amina's warped values get a lower  prediction ($\hpxtil[0]$). 
The warping of her feature values has the effect %: The lower value for Savings helps her cause, the higher value for Amount goes the other way -- overall, warping the features
of increasing her prediction in the real world.
Bootstrap CIs indicate that while the intercepts and the PSC of \textit{STEM} are significantly non-zero, the PSC of \textit{Lead} is not significantly deviating from $0$. %\footnote{CIs are calculated using bootstrap variance, which is distinct from Shapley-value related variance. Shapley values represent the expected value of marginal contributions, while Shapley variance refers to the variance of those individual marginal contributions.} 
In this fictitious example, we would see (i) a gender-related negative privilege mediated by career choice (\textit{STEM}) -- because of the significant $\hgx[1]$, and (ii) a further gender-related negative privilege not attributable to \textit{STEM} or \textit{Lead},  
%career choice or leadership responsibilities, 
i.e., hinting at other mediators or direct discrimination -- because of the significant $\hpxtil$.



% \lb{Methods used for IRD \cite{dandl_interpretable_2023} should help?}






\section{Experiments}
\label{sec:experiments}

In this section, we analyze the proposed framework of PS empirically. We investigate the behavior of PS estimators for different settings of a simulation study % where we can control the real-world and FiND-world DGP. 
and examine the practical applicability %by applying our framework 
on real-world datasets.\footnote{Code is available as supplementary material.}



\subsection{Simulated data}
\label{sec:exp-sim}

The goal of the simulation study is to compare the candidate methods (fairadapt and res-based warping, see Section \ref{sec:background}) for estimating PS in order to judge their suitability for the real-world experiments.
%
%\paragraph{Research Questions}
%
We pursue the following research questions: (RQ1) How biased are the methods? What MSE do the methods have? What coverage do the CIs have? %How close are $F(\priv)$ and $F(\hp)$? 
(RQ2) How sensitive are the methods to misspecification of the DAG?
(RQ3) Can PSC derive explanations that mirror correctly the true privileges?

%\paragraph{Simulation scenarios}

% We investigate three different scenarios: (S1) Simple DAG: In a fictitious mortgage lending example, \textit{Gender (A)} is the PA, \textit{Income ($X_1$)} is a mediator on the path to \textit{Mortgage (Y)}, describing whether the mortgage could be fully repaid, \textit{Age (C)} is a confounder, see Figure \ref{fig:DAG-comp1}, (S2) Adding a mediator \textit{Savings $X_2$} (high (1) or low (0)) of the Gender-Risk relationship, see Figure \ref{fig:DAG-example-psc}, (S3) Misspecification: Data are generated with an additional effect $A \rightarrow C$ while DAG as in (S2) is used for estimation.

We investigate two different scenarios: (SC) In a fictional mortgage lending example we use the DAG in Figure \ref{fig:DAG-example-psc} again; %, \textit{Gender (A)} is the PA, %\textit{Amount $X_1$} (numerical) and \textit{Savings $X_2$} (high (1) or low (0)) 
%$X_1$ and $X_2$ 
%are mediators on the path to \textit{Repayment (Y)}, 
%describing whether the mortgage could be fully repaid, 
%\textit{Age (C)} is a confounder; 
%, (SC) Adding a mediator \textit{Savings $X_2$} (high (1) or low (0)) of the Gender-Risk relationship, see Figure \ref{fig:DAG-example-psc}, 
(SM) Misspecification: Data are generated with an additional effect $A \rightarrow C$ while DAG as in (SC) is used for estimation. For each scenario, we draw $n=1000$ observations in $M=50$ iterations, see \ref{app:sec:sim-setup} for full setup.

\paragraph{Results}
We highlight some results here and show full results in Appendix \ref{app:sec:sim-results}. 
%
% for full results. Figure \ref{fig:sim_study_statistics} summarizes results for (RQ1) and (RQ2). We see that 
% \todo[inline]{tbd\\tbd}
%
% \begin{figure}[ht]
%     \centering
%     %\rotatebox{90}
%     %{\includegraphics[width=0.5\textwidth]{figs/combined_plot_2024-09-27_10-30-23.jpg}}
%     {\includegraphics[width=0.5\textwidth]{figs/combined_plot_2025-01-21_18-10-52.pdf}}
%     \caption{Summary statistics for simulation results following the (S1) scenario which corresponds to the DAG depicted in Figure \ref{fig:DAG-comp1}.}
%     \label{fig:sim_study_statistics}
% \end{figure}
%
For (RQ1), Table \ref{tab:sim_study_s2s3} (SC, left) shows that estimates of PS with fairadapt and res-based warping are approximately unbiased and have low MSE. The coverage of the CIs for both methods is slightly above the confidence level of $90\%$, meaning that while they can be used for significance statements, there is room for more power. For (RQ2), Table \ref{tab:sim_study_s2s3} (SM, right) shows that misspecification degrades the performance, while res-based warping seems more robust than fairadapt. 


\begin{table}[!h] % table-ID: S-SC-SM-table
    \centering
        \caption{PS: Mean (5\% and 95\% quantiles) of bias, MSE and $(1-\alpha)$-CI coverage, $\alpha=0.1$.} 
    \resizebox{0.49\textwidth}{!}{ % Adjust the table to fit within the column width
        \begin{tabular}[t]{lcccc}
            \toprule
            \multicolumn{1}{c}{ } & \multicolumn{2}{c}{SC} & \multicolumn{2}{c}{SM} \\
            \cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5}
            Metric & fairadapt & res-based & fairadapt & res-based\\
            \midrule
            Bias & -0.001 & 0.002 & 0.037 & 0.001\\
             & (-0.015, 0.012) & (-0.014, 0.014) & (0.013, 0.062) & (-0.012, 0.016)\\
            MSE & 0.011 & 0.012 & 0.024 & 0.017\\
             & (0.007, 0.015) & (0.007, 0.016) & (0.014, 0.036) & (0.012, 0.023)\\
            Coverage & 0.977 & 0.969 & 0.94 & 0.949\\
             & (0.944, 0.994) & (0.939, 0.988) & (0.897, 0.976) & (0.93, 0.963)\\
            % KS_Statistic & 0.397 & 0.394 & 0.413 & 0.402\\
            % \addlinespace
            %  & (0.344, 0.477) & (0.35, 0.455) & (0.354, 0.495) & (0.342, 0.488)\\
            % Mean_Width & 0.296 & 0.292 & 0.303 & 0.279\\
            %  & (0.265, 0.321) & (0.267, 0.318) & (0.275, 0.336) & (0.259, 0.3)\\
            % \addlinespace
            % Width & 0.334 & 0.351 & 0.468 & 0.376\\
            %  & (0.255, 0.417) & (0.273, 0.429) & (0.34, 0.619) & (0.307, 0.455)\\
            \bottomrule
        \end{tabular}
    }
    \label{tab:sim_study_s2s3}
\end{table}

For (RQ3), we compare true PSCs with estimated PSCs for (SC), see Table \ref{tab:rq3} (and \ref{tab:app-sim-sm-psc}). % shows mean bias, MSE and $(1-\alpha)$-CI coverage for PSCs in scenario (SC). 
Again, estimates are approximately unbiased and have low MSE. Coverage of the CIs are within sensible ranges, only coverage of PSC $\gx[2]$ for \textit{Saving} using res-based warping is slightly too low. %See Appendix \ref{app:sec:sim-results} for full results.

% \begin{table}[ht]
%     \centering
%        \caption{Simulation study, results for PSC: We show mean bias, MSE and $(1-\alpha)$-CI coverage for $M=100$ iterations, with $\alpha=0.1$.} 
%         \begin{tabular}{lccccccc}
%               \hline
%              & Bias & MSE &  Coverage  \\ 
%               \hline
%               $\hp$ & 0.002 & 0 &  0.943  \\ 
%               $\priv_g$ & -0.004 & 0.011 & 0.984  \\ 
%               $\gx[1]$ & -0.001 & 0.002 & 0.959 \\ 
%               $\gx[2]$ & 0.003 & 0.001  & 0.868 \\ 
%                \hline
%         \end{tabular}
%     \label{tab:rq3}
% \end{table}

\begin{table}[!h] % table-ID: S-SC-PSC-table
    \centering
        \caption{PSC -- scenario (SC): Metrics as in Table \ref{tab:sim_study_s2s3}. Top: res-based, bottom: fairadapt.} 
    \resizebox{0.49\textwidth}{!}{ % Adjust the table to fit within the column width
        \begin{tabular}[t]{lcccc}
            \toprule
            Metric & $\priv_g$ & $\priv_{\xtil}$ & $\gx[1]$ & $\gx[2]$\\
            \hline
            Bias & 0.002 & -0.002 & -0.001 & 0.003 \\ 
            & (-0.007, 0.012) & (-0.013, 0.009) & (-0.009, 0.009) & (-0.001, 0.006) \\ 
            MSE & 0 & 0.011 & 0.002 & 0.002 \\ 
            & (0, 0) & (0.007, 0.016) & (0.001, 0.004) & (0.001, 0.002) \\ 
            Coverage & 0.973 & 0.984 & 0.958 & 0.866 \\ 
            & (0.817, 1) & (0.973, 0.996) & (0.936, 0.981) & (0.846, 0.884) \\ 
            \hline
            Bias & -0.001 & 0 & -0.003 & 0.002 \\ 
            & (-0.008, 0.007) & (-0.008, 0.008) & (-0.013, 0.008) & (-0.001, 0.005) \\ 
            MSE & 0 & 0.01 & 0.002 & 0.001 \\ 
            & (0, 0) & (0.007, 0.014) & (0.001, 0.004) & (0.001, 0.002) \\ 
            Coverage & 1 & 0.983 & 0.953 & 0.923 \\ 
            & (1, 1) & (0.97, 0.996) & (0.928, 0.973) & (0.89, 0.952) \\ 
            \hline
        \end{tabular}
%         \begin{tabular}[t]{lccc}
%     \toprule
%     Metric & $\priv_{\xtil}$ & $\gx[1]$ & $\gx[1]$\\
%     \hline
%     Bias & -0.002 & -0.001 & 0.003 \\ 
%     & (-0.013, 0.009) & (-0.009, 0.009) & (-0.001, 0.006) \\ 
%     MSE & 0.011 & 0.002 & 0.002 \\ 
%     & (0.007, 0.016) & (0.001, 0.004) & (0.001, 0.002) \\ 
%     Coverage & 0.984 & 0.958 & 0.866 \\ 
%     & (0.973, 0.996) & (0.936, 0.981) & (0.846, 0.884) \\ 
%     \hline
%     Bias & 0 & -0.003 & 0.002 \\ 
%     & (-0.008, 0.008) & (-0.013, 0.008) & (-0.001, 0.005) \\ 
%     MSE & 0.01 & 0.002 & 0.001 \\ 
%     & (0.007, 0.014) & (0.001, 0.004) & (0.001, 0.002) \\ 
%     Coverage & 0.983 & 0.953 & 0.923 \\ 
%     & (0.97, 0.996) & (0.928, 0.973) & (0.89, 0.952) \\ 
%     \hline
% \end{tabular}
    }
    \label{tab:rq3}
\end{table}


%Figure TBC %\ref{fig:sim-study-psc} 
%shows that
% \todo[inline]{density plot of true PSC and estimates via res-based and fairadapt for one iteration; alternatively mean MSE over all iterations, i.e., one number for res-based and fairadapt, respectively.}

% \begin{figure}[ht]
%     \centering
%     %\rotatebox{90}
%     %{\includegraphics[width=0.5\textwidth]{figs/combined_plot_2024-09-27_10-30-23.jpg}}
%     {\includegraphics[width=0.5\textwidth]{figs/sim_study_contrib_boxplot_2025-01-21_21-31-27.pdf}}
%     \caption{Summary statistics for simulation results following the (S1) scenario which corresponds to the DAG depicted in Figure \ref{fig:DAG-comp1}.}
%     \label{fig:sim_study_contrib_boxplot}
% \end{figure}

% \begin{figure}[ht]
%     \centering
%     \begin{subfigure}[t]{0.23\textwidth}
%         \centering
%         \caption{res-based}
%         \includegraphics[width=\linewidth]{figs/sim_study_contrib_density_plots_res_based_2025-01-26_21-49-00.pdf}
%         \label{fig:psc_sim_estimate_true_resbased}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[t]{0.23\textwidth}
%         \centering
%         \caption{fairadapt}
%         \includegraphics[width=\linewidth]{figs/sim_study_contrib_density_plots_fairadapt_2025-01-26_21-47-04.pdf}
%         \label{fig:psc_sim_estimate_true_fairadapt}
%     \end{subfigure}
%     \caption{PSC density plot for a random sample of $n=1000$ from the DAG described in (S2). Dark colors indicate the ground truth contribution value while brighter represent their estimates using the respective warping method.}
%     \label{fig:psc_sim_estimate_true}
% \end{figure}


%The simulation study showed that both fairadapt and res-based warping are approximately unbiased, have low MSEs, and the CIs meet the specified confidence levels. Also, both methods are able to find the true PSC values. 
We conclude that both methods can be used to estimate PS/PSC in real-world applications, while future work could investigate how they perform on more complex DAGs.
As res-based warping seems to be more robust against misspecification, we report real-world results for it in the next section and refer to Appendix \ref{app:sec:exp-real} for fairadapt results.

\subsection{Real-world data}
\label{sec:exp-real}

We analyze data from the Home Mortgage Disclosure Act (HMDA) and from the Law School data.\footnote{See Appendix \ref{app:sec:exp-real} for details on the setup and more results.} Data are splitted into $80\%$/$20\%$ train/test sets and results reported on test set.

\paragraph{Mortgage Data}

Figure \ref{fig:DAG-mortgage} shows assumed DAGs. Data consist of: binary PA \textit{Race} ($A$, white/non-white), numerical feature \textit{Amount} ($X_1$), binary features \textit{Debt} ($X_2$, debt-to-income ratio smaller than $36\%$ or not) and \textit{Purpose} ($X_3$, home purchase/other),  confounders $\bm{C}$, consisting of binary \textit{Sex} (male/female) and binary \textit{Age} (above $62$ or not) -- and binary target \textit{Action} ($Y$, loan originated or not). 
%\todo[inline]{Describe data set and variables. Also models for res-based.}
We apply res-based warping (with logit models for binary features and a gamma model for \textit{Amount}) and fairadapt for three locations: We show results with res-based warping for Louisiana (LA) here and refer to Appendix \ref{app:sec:exp-real} for results on New York county (NY) and Wisconsin (WI) and for fairadapt.

% \begin{figure}[ht]
%     \centering

%         \begin{tikzpicture}[x=3in, y=4in] % Adjusted scaling
%         \node[ellipse, draw] (v0) at (0.6,-0.24) {$Y$};
%         \node[ellipse, draw] (v1) at (0.2,-0.24) {$\bm{C}$};
%         \node[ellipse, draw] (v2) at (0.5,-0.31) {$X_1$};
%         \node[ellipse, draw] (v3) at (0.4,-0.24) {$X_2$};
%         \node[ellipse, draw] (v4) at (0.3,-0.17) {$X_3$};
%         \node[ellipse, draw] (v5) at (0.5,-0.10) {$A$};

%         % Draw arrows
%         \draw [->] (v1) edge (v2);
%         \draw [->] (v1) edge (v3);
%         \draw [->] (v1) edge (v4);
%         \draw [->] (v2) edge (v0);
%         \draw [->] (v3) edge (v0);
%         \draw [->] (v4) edge (v0);

%         % Dashed and curved arrows
%         \draw [dashed, ->] (v5) edge (v0); 
%         \draw [dotted, ->] (v5) edge (v2);
%         \draw [dotted, ->] (v5) edge (v3);
%         \draw [dotted, ->] (v5) edge (v4);
%         \end{tikzpicture}
%         \caption{DAGs for mortgage data.} % Dashed arrows are only present in real world and eliminated through pre-processing.}
%         \label{fig:DAG-mortgage}
% \end{figure}


\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.2\textwidth}
        \centering
        \begin{tikzpicture}[x=3in, y=4in] % Adjusted scaling
        \node[ellipse, draw] (v0) at (0.6,-0.24) {$Y$};
        \node[ellipse, draw] (v1) at (0.2,-0.24) {$\bm{C}$};
        \node[ellipse, draw] (v2) at (0.5,-0.31) {$X_1$};
        \node[ellipse, draw] (v3) at (0.4,-0.24) {$X_2$};
        \node[ellipse, draw] (v4) at (0.3,-0.17) {$X_3$};
        \node[ellipse, draw] (v5) at (0.52,-0.12) {$A$};

        % Draw arrows
        \draw [line width=1pt, ->] (v1) edge (v2);
        \draw [line width=1pt, ->] (v1) edge (v3);
        \draw [line width=1pt, ->] (v1) edge (v4);
        \draw [line width=1pt, ->] (v2) edge (v0);
        \draw [line width=1pt, ->] (v3) edge (v0);
        \draw [line width=1pt, ->] (v4) edge (v0);

        % Dashed and dotted arrows
        \draw [dashed, line width=1pt, ->] (v5) edge (v0); 
        \draw [dotted, line width=1pt, ->] (v5) edge (v2);
        \draw [dotted, line width=1pt, ->] (v5) edge (v3);
        \draw [dotted, line width=1pt, ->] (v5) edge (v4);
        \end{tikzpicture}
        \caption{}
        \label{fig:DAG-mortgage}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.2\textwidth}
        \centering
        \begin{tikzpicture}[x=3in, y=4in] % Adjusted scaling
        \node[ellipse, draw] (v0) at (0.4,-0.6) {UGPA}; 
        \node[ellipse, draw] (v2) at (0.2,-0.7) {$A$};
        \node[ellipse, draw] (v4) at (0.4,-0.7) {$Y$};
        \node[ellipse, draw] (v6) at (0.4,-0.8) {LSAT};

        % Draw arrows
        \draw [line width=1pt, ->] (v0) edge (v4);
        \draw [dotted, line width=1pt, ->] (v2) edge (v0); 
        \draw [dotted, line width=1pt, ->] (v2) edge (v6); 
        \draw [line width=1pt, ->] (v6) edge (v4); 
        \draw [dashed, line width=1pt, ->] (v2) edge (v4);
        \end{tikzpicture}
        \caption{} %$A$ represents the protected attribute, either \textit{Sex} or \textit{Race}.}
        \label{fig:DAG_lawschool}
    \end{subfigure}
    \caption{DAGs for (a) mortgage and (b) law school data.}
\label{fig:DAG-real-world-exp}
\end{figure}


%\paragraph{Results Lousiana}
Data from year 2022 has $n=14.758$. %While fairadapt and res-based warping give seemingly very different results, they agree in the large race effect on PS: fairadapt assigns high PS to a group of white applicants while res-based assigns high negative PS to a group of non-white applicants. 
Figure \ref{fig:psc_mortgage} shows PS and PSCs for an individual (ID 244) with  high negative PS; locally, race-related negative privileges via \textit{Purpose} as well as the individual intercept seem significantly non-zero.
Globally, a regression of all PS (in the test set) on all features reveals a highly significant %($p<10^{-16}$) 
race effect of around $0.22$, meaning that ceteris paribus, the expected PS of a white applicant is additively $0.22$ higher than that of a non-white applicant, indicating a strong racial bias for LA.
For NY and WI, the race effects are also significant but  lower at $0.04$ and $0.1$, respectively.

\begin{figure}[ht]
    \centering
    % \includegraphics[width=0.5\textwidth]{figs/privilege_score_plots_241213.pdf}
    % \includegraphics[width=0.5\textwidth]{figs/privilege_score_plots_amina_res_based_global_2025-01-16_08-01-49.pdf} 
    \includegraphics[width=0.5\textwidth]{figs/privilege_score_plots_chimamanda_res_based_global_2025-01-16_08-01-49_louisiana_single.pdf} 
    \caption{LA: PS and PSCs for a non-white female person, (ID 244, see Appendix Table \ref{tab:app_la} for real and warped values).}
    \label{fig:psc_mortgage}
\end{figure}

Table \ref{tab:mortgage} summarizes PS and PSCs for the non-white subgroup ($A=0$): We see a considerable imbalance of PS $\hp$ toward negative values and the most important path of privilege seems to be the individual intercept $\priv_{\xv}$. This indicates that non-observed features could be the main mediators of discrimination or that there could be a direct race discrimination effect. Comparing features, \textit{Purpose} and \textit{Amount} have the highest importance and the bias regarding \textit{Debt} seems negligible. Note that future work has yet to develop formal tests or CI's to allow for significance statements% at the moment, these are just indicators
.

\begin{table}[ht]
\centering
\caption{Louisiana: Mean and quantiles ($\alpha=0.05$) of PS/PSC and PSC importance on test data.}
\begin{tabular}{lrrr}
  \hline
 & Mean & Quantiles $(\alpha, 1-\alpha)$ & Importance \\ 
  \hline
$\hp$ & -0.249 & (-0.815, 0.037) & -- \\ 
   $\priv_g$ & -0.082 & (-0.082, -0.082) & 0.082 \\ 
  $\priv_{\xv}$ & -0.101 & (-0.634, 0.326) & 0.269 \\ 
  $\gx[1]$ & -0.033 & (-0.135, 0.019) & 0.039 \\ 
  $\gx[2]$ & -0.010 & (-0.098, 0.000) & 0.010 \\ 
  $\gx[3]$ & -0.024 & (-0.247, 0.183) & 0.060 \\ 
   \hline
\end{tabular}
%}
\label{tab:mortgage}
\end{table}

\paragraph{Law school data}
Figure \ref{fig:DAG_lawschool} shows assumed DAGs. We use binary PA \textit{Race} ($A$, Black/non-Black), and binary outcome $Y$ (bar exam passed or not), for $n=22.407$ observations, see \ref{app:sec:exp-real:law} for detailed setup.
Table \ref{tab:psc-law-fairadapt-sex} shows that, most interestingly, the path via LSAT ($\gx[2]$) contributes the most to Black students' negative privilege regarding the probability of passing the bar -- while intercept effects (indicators of direct effects or missing mediators) are comparatively small. This means that the negative privilege of black students can be explained mainly by differences in the LSAT, which in turn implies that policies aimed at effectively increasing racial equality should aim at equalizing LSAT scores. Further research could focus on why LSAT is more important than UGPA. %\footnote{See also Appendix \ref{app:sec:mortgage} for additional results.}
See also Appendix \ref{app:sec:exp-real:law} for additional results.


\begin{table}[ht] % table-ID: R-LS-psc-resbased-table-sex
    \centering
    \caption{Law School: Mean and quantiles ($\alpha=0.05$) of PS/PSC and PSC importance on test data} 
    \begin{tabular}{lccc}
        \hline
        Feature & Mean & Quantiles $(\alpha, 1-\alpha)$ & Importance \\ 
        \hline
$\hp$ & -0.149 & (-0.403, 0.006) & -- \\ 
   $\priv_g$ & -0.005 & (-0.005, -0.005) & 0.005 \\ 
  $\priv_{\xv}$ & -0.010 & (-0.086, 0.018) & 0.026 \\ 
  $\gx[1]$ & -0.022 & (-0.052, 0.002) & 0.023 \\ 
  $\gx[2]$ & -0.111 & (-0.285, -0.001) & 0.111 \\ 
   \hline
    \end{tabular}
    \label{tab:psc-law-fairadapt-sex}
\end{table}

% \paragraph{Discussion}
% The mortgage data experiments demonstrated the applicability of our method. At the individual level, significant negative privilege was found; its main drivers appear to be factors not included in the data set, as the individual intercept has the highest values. At the global level, we can also quantify and explain privilege, with a similar conclusion: racial discrimination manifests itself through unobserved features. Comparing different US locations, racial bias is twice as high in LA as in WI and even five times as high as in NY. The results for fairadapt and res-based warping are similar, confirming the results of the simulation study.

\paragraph{Discussion}
The real-world data experiments demonstrated the applicability of our method. 
For the mortgage analysis, 
significant negative privilege was found
at the individual level; 
its main drivers appear to be factors not included in the data set, as the individual intercept has the highest value. 
We can also quantify and explain privilege
at the global level, 
concluding: (i) for mortgage, racial discrimination manifests itself through unobserved features. Comparing different US locations, racial bias is twice as high in LA as in WI and even five times as high as in NY; 
(ii) for law school, the racial privilege can mainly be explained by a path via LSAT, a finding which in turn can inform policy makers aiming at mitigating racial disparities.
%The results for fairadapt and res-based warping are similar, confirming the results of the simulation study.

While these experiments show the relevance of our method, we also see  limitations. In a practical use case, we would like to make significance statements about PSC importance. We leave it to future work to develop appropriate tests. Our method assumes a given DAG, and simulations have shown that misspecification of the DAG affects the robustness of the estimates. In an applied study, great care needs to be taken in defining this DAG, ideally in collaboration with domain experts. A worthwhile direction for future work would also be to investigate how causal discovery methods can be added to our framework.

\section{Conclusion and Outlook}
\label{sec:discussion}

% \paragraph{Conclusion and Outlook}
% \section{Conclusion and Outlook}
% \label{sec:conclusion}

We proposed privilege scores and presented a general framework for their estimation, including uncertainty quantification. In addition, we presented privilege score contributions that can be used to explain how privileges -- related to given protected attributes -- are constituted in real-world applications. Experiments on simulated and real-world data compared the estimation methods and demonstrated their practical applicability. 

We see several opportunities for future work: other (causal and non-causal) estimation methods that could populate our general framework can be investigated. Rigorous tests of PSC importance would allow for significance claims. A user study would investigate how feasible PS and PSCs are for practitioners. Finally, PS could be used in model training to produce fairer models.

\section*{Impact Statement}

% Authors are \textbf{required} to include a statement of the potential 
% broader impact of their work, including its ethical aspects and future 
% societal consequences. This statement should be in an unnumbered 
% section at the end of the paper (co-located with Acknowledgements -- 
% the two may appear in either order, but both must be before References), 
% and does not count toward the paper page limit. In many cases, where 
% the ethical impacts and expected societal implications are those that 
% are well established when advancing the field of Machine Learning, 
% substantial discussion is not required, and a simple statement such 
% as the following will suffice:

This paper presents work whose goal is to advance the field of 
machine learning. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here.

\bibliography{mybib-zotero-modified, ReferencesFromJose, mybib-manually}
\bibliographystyle{xxxxxx2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\section{Details on interpretability methods}

\subsection{Example for applying standard IML method on PS}
\label{app:iml-standard}
E.g., for feature effects we can use ICE or PD plots, for feature importance we can use different variants of permutation feature importance, SAGE values, or LOCO \citep[see e.g.,][for an overview]{ewald_guide_2024}. 
As just one example, Algorithm \ref{alg:pfi} describes how to compute permutation feature importances for PS. 

\begin{algorithm}[ht]
\caption{Permutation Feature Importance (PFI)}
\label{alg:pfi}
\begin{algorithmic}[1]
\STATE Learn warping and ML models in real and warped world ($\pih()$ and $\pitilh()$)

\STATE Compute test error of predictions $\hp$
\FOR{each feature $x_j$}
    \STATE Permute the values of feature $x_j$
    \STATE Compute predictions $\hp_*$ using same warping and models $\pih()$ and $\pitilh()$
    \STATE Compute test error of predictions $\hp_*$
    \STATE Estimate FI via difference of the test errors
\ENDFOR
\IF{multiple permutations are performed}
    \STATE Repeat the permutation process several times and average
%    \STATE Take the average of the computed differences over all repetitions.
\ENDIF
\end{algorithmic}
\end{algorithm}

\subsection{PSC proofs}
\label{app:iml-efficiency}

\subsubsection{Setup and Definition of PSC}

Let $P = \{1,\dots,k\}$ be the set of $k$ privilege-inducing arrows (players). 
For a subset $S \subseteq P$, define
$$
v(S) \;=\; \pih(\xv) \;-\; \pih(\xv_S),
$$
where $\xv$ is the original real-world feature vector, and $\xv_S$ is the same feature vector with \emph{exactly} the arrows in $S$ ``removed'' (warped).  By construction:
$$
v(\varnothing) \;=\; \pih(\xv) \;-\; \pih(\xv) \;=\; 0
\quad\text{and}\quad
v(P) \;=\; \pih(\xv) \;-\; \pih(\xtil)
%\;=\;\sum_{j=1}^k \gx[j].
$$

We aim to allocate $v(P)$ among the $k$ players (arrows) in a principled way.

Two equivalent definitions of Shapley values exist \cite{strumbelj_explaining_2014}:

\medskip

\textbf{Set-based Shapley Values for Player $j \in P$:}
$$
\gx[j] \;=\;
\sum_{S \subseteq P \setminus \{j\}}
\frac{|S|!\,\bigl(k - |S| -1\bigr)!}{k!}
\;
\bigl[v(S \cup \{j\}) - v(S)\bigr].
$$

\medskip

\textbf{Order-based Shapley Values for Player $j \in P$:}

A \emph{permutation} of $P$ is any ordering $\pi = (\pi(1), \pi(2), \dots, \pi(k))$.  
Let $\mathrm{S}_\pi(j)$ be the set of players that appear \emph{before} $j$ in the permutation $\pi$, i.e., $\mathrm{S}_\pi(j) = \{\pi(1),\dots,\pi(r-1)\}$ if $\pi(r)=j$. % <-- Added
Then the \textbf{Shapley value} of player $j$ is
$$
\gx[j] 
\;=\;
\frac{1}{k!}\;
\sum_{\pi \in \mathfrak{S}_P}
\Bigl[v\!\bigl(\mathrm{S}_\pi(j) \cup \{\,j\}\bigr)
\;-\;
v\!\bigl(\mathrm{S}_\pi(j)\bigr)\Bigr],
$$
where $\mathfrak{S}_P$ is the set of all $k!$ permutations of $P$.  
In words, we look at the “marginal contribution” of $j$ each time it ``arrives'' in a permutation (given whichever players arrived before it), and then average over all permutations.

\subsubsection{Axioms of fair payouts}

% \begin{theorem}[Efficiency]
% Let $\{\phi_j\}_{j \in P}$ be the Shapley values induced by $v$. Then
% $$
% \sum_{j=1}^k \phi_j
% \;=\;
% v(P)
% \;=\;
% \bigl[\pih(\xv) - \pih(\xtil)\bigr].
% $$
% \end{theorem}

While \textbf{efficiency} is explicitly proved below, the other properties directly follow from the definition of PSCs as Shapley values:

\begin{itemize}
    \item \textbf{Symmetry}: If two arrows $i, j \in P$ make the same marginal contributions in every coalition $S \subseteq P\setminus\{i,j\}$, they trivially receive identical PSC values.
    \item \textbf{Dummy Property}: An arrow that marginally contributes nothing to any coalition, i.e. $v(S \cup \{j\}) \;=\; v(S)$ for all $S \subseteq P\setminus\{j\}$, obtains a PSC of $0$.
    %\item \textbf{Additivity}: If $v_1$ and $v_2$ are two (different) value functions, then the Shapley value for $v_1 + v_2$ is the sum of the Shapley values for $v_1$ and $v_2$.
\end{itemize}



\subsubsection{Efficiency Proof: Set-based Shapley Values}

% \begin{proof_sketch}
% The Shapley value for player $j \in P$ is 
% $$
% \phi_j 
% \;=\;
% \sum_{S \subseteq P \setminus \{j\}}
% \frac{|S|!\,\bigl(k - |S| - 1\bigr)!}{k!}
% \;\Bigl[\,v\bigl(S \cup \{j\}\bigr) \;-\; v(S)\Bigr].
% $$
% Hence
% $$
% \sum_{j=1}^k \phi_j
% \;=\;
% \sum_{j=1}^k
% \sum_{S \subseteq P \setminus \{j\}}
% \frac{|S|!\,(k - |S| - 1)!}{k!}
% \;\bigl[v(S \cup \{j\}) \;-\; v(S)\bigr].
% $$
% Re-index over nonempty subsets $T \subseteq P$ by setting $T = S \cup \{j\}$. This shows each $v(T)$ with $T\neq \varnothing$ arises exactly $|T|$ times in the sum (once for each $j \in T$), but for subsets $T \neq P$, there is also a corresponding negative occurrence that cancels out the positive one. Concretely:
% $$
% \bigl[v(T) - v(T \setminus \{i\})\bigr]
% \quad \text{and} \quad
% \bigl[v(T \cup \{i'\}) - v(T)\bigr]
% $$
% yield $+\,v(T)$ and $-\,v(T)$, respectively, for some $i,i'\notin T$. 
% All intermediate $T \neq P$ vanish in pairs, leaving only the net term $v(P) - v(\varnothing)$. Because $v(\varnothing)=0$, the total sum equals $v(P)$. 
% $$
% \sum_{j=1}^k \phi_j \;=\; v(P).
% $$
% \end{proof_sketch}

\begin{proofsketch}

\noindent 

\textbf{Step 1: Split the sum into pieces.}
$$
\sum_{j=1}^k \gx[j] 
\;=\;
\sum_{j=1}^k 
\;\sum_{\,S \subseteq P\setminus\{j\}}
\;\frac{|S|!\,\bigl(k - |S| -1\bigr)!}{k!}
\;\Bigl[\,v\bigl(S \cup \{j\}\bigr) - v(S)\Bigr].
$$
Each pair $(j,S)$ contributes a difference $v(S \cup \{j\}) - v(S)$. Let $T = S \cup \{j\}$.

Additional Remark: Notice that the coefficient
  $$
    \frac{|S|!\,(k - |S| -1)!}{k!}
  $$
  can be viewed as the probability (over all $k!$ permutations) that $S$ is exactly the set of predecessors of $j$. 
  This viewpoint will help in understanding later cancellation.

\medskip
\noindent
\textbf{Step 2: Identify how $v(P)$ is counted once overall.}

\begin{itemize}
    \item Whenever $T = P$, we must have $j \in P$ and $S = P \setminus \{j\}$. There are exactly $k$ such pairs $(j,S)$ because $j$ can be any of the $k$ elements in $P$.
    \item For each such pair, $\lvert S\rvert = k-1$, the coefficient becomes
    $$
       \frac{(k-1)!\,(k - (k-1) - 1)!}{k!}
       \;=\;
       \frac{(k-1)!\,(0)!}{k!}
       \;=\;
       \frac{1}{k}.
    $$
    \item Hence each of the $k$ occurrences of $v(P)$ is multiplied by $\tfrac{1}{k}$, summing to $\bigl(\frac{1}{k}\times k\bigr)=1$. Thus \emph{overall}, $v(P)$ is counted once in total. 
\end{itemize}

\medskip
\noindent
\textbf{Step 3: Show that all $v(T)$ with $T \neq P$ and $T \neq \emptyset$ cancel.}

 Each nonempty $T \subset P$ appears \emph{positively} in $v(T) - v(T \setminus \{j\})$ (because of $+\,v(T)$), 
  and also \emph{negatively} in the larger set $v\bigl(T \cup \{j'\}\bigr) - v(T)$ (as $-\,v(T)$). 
  Crucially, the factorial coefficients match up so that the total weight of all positive appearances of $v(T)$ 
  equals the total weight of all negative appearances of $v(T)$. 
  Hence they completely cancel out.
  
More precisely, for each nonempty $T \subset P$:
\begin{itemize}
    \item \textbf{Positive occurrence.} 
    If $T = S \cup \{j\}$ for some $j \in T$, then $v(T)$ appears \emph{positively} in the difference 
    $
      v(S \cup \{j\}) \;-\; v(S).
    $

    \item \textbf{Negative occurrence.} 
    If $T \subset P$ is not the full set, then there exists at least one element $j' \notin T$. We can thus form the larger set $T \cup \{j'\}$. In the Shapley sum, this larger set contributes
    $
      v\bigl(T \cup \{j'\}\bigr) \;-\; v(T),
    $
    which contains $-\,v(T)$ as the \emph{negative} appearance of $v(T)$.

    \item \textbf{Multinomial coefficient.} 
    Fix a nonempty $T$. Let $|T|$ denote its size. Inside the sum, $T$ appears once for each $j \in T$ with $S = T \setminus \{j\}$. The coefficient in front of $v(T)$ for such a pair $(j,S)$ is
    $$
      \frac{|T\setminus\{j\}|!\,\bigl(k - |T\setminus\{j\}| -1\bigr)!}{k!}
      \;=\;
      \frac{(|T|-1)!\,(k - |T|)!}{k!}.
    $$
    Since there are $|T|$ possible ways to choose $j\in T$, multiplying by $|T|$ yields
    $$
      |T| 
      \;\cdot\; 
      \frac{(|T|-1)!\,(k - |T|)!}{k!}
      \;=\;
      \frac{|T|!\,(k - |T|)!}{k!}
      \;=\;
      \frac{k!}{k!}
      \;=\;
      1.
    $$
    Where the identity $|T|!\,(k - |T|)! = k!$ holds because to permute $k$ distinct elements, 
we can imagine first choosing which $|T|$ are in one group and ordering them 
(in $|T|!$ ways), then ordering the remaining $k - |T|$ (in $(k - |T|)!$ ways). 
Overall, this accounts for all $k!$ permutations. 
    Therefore, each nonempty $T$ receives a total \emph{positive} weight of exactly $+1$ when summing over all $j \in T$.

    \item \textbf{Cancellation.} 
    Every nonempty $T \neq P$ also appears \emph{negatively} as part of a larger set’s difference, ensuring one positive and one negative occurrence of $v(T)$. Consequently, these contributions cancel each other out, so $v(T)$ does not remain in the final sum unless $T=P$.
\end{itemize}
\medskip
\noindent
\textbf{Step 4: Conclusion.}

Since $v(\varnothing) = 0$ does not contribute and $v(P)$ remains once in total, we get
$$
\sum_{j=1}^k \gx[j] 
\;=\;
\underbrace{v(P)}_{\text{one net positive}} 
\;+\; 
\underbrace{\sum_{T \neq P} \bigl[v(T)\ \text{terms cancel}\bigr]}_{0} 
\;=\;
v(P).
$$
\qedhere
\end{proofsketch}

\subsubsection{Efficiency Proof: Order-Based Shapley Values}


\begin{proofsketch}
\noindent

\textbf{Step 1: Sum the Shapley values over all players.}

$$
\sum_{j=1}^k \gx[j] 
\;=\;
\sum_{j=1}^k
\frac{1}{k!}
\sum_{\pi \in \mathfrak{S}_P}
\Bigl[v\bigl(\mathrm{S}_\pi(j)\cup\{j\}\bigr)
- 
v\bigl(\mathrm{S}_\pi(j)\bigr)\Bigr]
=
\frac{1}{k!}
\sum_{\pi \in \mathfrak{S}_P}
\sum_{j=1}^k
\Bigl[v\bigl(\mathrm{S}_\pi(j)\cup\{j\}\bigr)
- 
v\bigl(\mathrm{S}_\pi(j)\bigr)\Bigr].
$$

\medskip
\noindent
\textbf{Step 2: Telescoping within each permutation.}

Fix a particular permutation $\pi$.  List its elements in order:
$$
\bigl(\pi(1), \pi(2), \dots, \pi(k)\bigr).
$$
Within this permutation, the inner sum
$\sum_{j=1}^k
\bigl[v(\mathrm{S}_\pi(j)\cup\{j\}) - v(\mathrm{S}_\pi(j))\bigr]$
can be viewed as a chain of marginal contributions:
$$
v\bigl(\{\pi(1)\}\bigr) - v(\varnothing)
\;+\;
v\bigl(\{\pi(1), \pi(2)\}\bigr) - v\bigl(\{\pi(1)\}\bigr)
\;+\;\dots\;+\;
v\bigl(\{\pi(1),\ldots,\pi(k)\}\bigr) - v\bigl(\{\pi(1),\ldots,\pi(k-1)\}\bigr).
$$
All intermediate terms telescope, leaving exactly
$$
v\bigl(\{\pi(1),\ldots,\pi(k)\}\bigr)
\;-\;
v(\varnothing)
\;=\;
v(P)
\;-\;
0
\;=\;
v(P).
$$

\medskip
\noindent
\textbf{Step 3: Average over all permutations.}

Since every permutation $\pi$ yields exactly $v(P)$ in the telescoped sum, we have
$$
\sum_{j=1}^k \gx[j]
\;=\;
\frac{1}{k!}
\sum_{\pi \in \mathfrak{S}_P} 
v(P)
\;=\;
\frac{1}{k!} \times \bigl(k! \cdot v(P)\bigr)
\;=\;
v(P).
$$
Hence
$$
\sum_{j=1}^k \gx[j] 
\;=\;
v(P).
$$
\end{proofsketch}


% \section{Software}
% \todo[inline]{Anonymize for submit}

% We have implemented the general framework in the R package \texttt{mlr3privscore}. This is integrated into the \texttt{mlr3} ecosystem \cite{lang_mlr3_2019}. Available PS methods are: RPID, \dots \\

% \lb{Would be great to have that package -- we have to implement it anyway, so why not do it properly directly. Might justify a separate software paper, though (xAI software track? Philip 1st author?).}



% \section{Experiments -- additional details and results}
% \label{app:sec:results}




\subsection{Partially warped features}
\label{app:iml-partial-warping}

\begin{figure}[ht]
    \centering
\begin{tikzpicture}[x=3in, y=4in] % Adjusted scaling
\node[ellipse, draw] (v0) at (0.5,-0.6) {Career ($X_1$)}; % Age in the middle, above others
\node[ellipse, draw] (v2) at (0.1,-0.6) {Gender ($A$)};
\node[ellipse, draw] (v4) at (0.9,-0.6) {Risk ($Y$)};
\node[ellipse, draw] (v6) at (0.5,-0.7) {Income ($X_2$)}; % New node between Gender and Mortgage

\draw [->] (v0) edge (v4);
\draw [->] (v0) edge (v6);
\draw [dotted, ->] (v2) edge (v0); 
\draw [dotted, ->] (v2) edge (v6); 
\draw [->] (v6) edge (v4); 
\draw [dashed, ->] (v2) .. controls (0.4,-0.8) and (0.625,-0.8) .. (v4); % Dashed arrow from Gender to Mortgage (direct)

\end{tikzpicture}
    \caption{Exemplary DAG for partial warping.}
    \label{fig:DAG-example-psc-partial}
\end{figure}

In a DAG such as in Figure \ref{fig:DAG-example-psc}, the vector $\xv_{S}=(\xtil_{d(S)}, \xv_{nd(S)})$ consists of warped versions of features $d(S)$ on paths descending from $S$ and real versions of non-descending features $nd(S)$. However, there can be DAGs like the one shown in Figure \ref{fig:DAG-example-psc-partial}, with features descending from more than one privilege. In the example, Income is affected by both the privilege that directly affects Income and the privilege that indirectly affects Income through career choice. For such cases, we introduce the notion of ``partially warping'' a feature: To derive the PSC of Income, we have to consider the $M=2$ cases of (i) having or (ii) not having the arrow $A \rightarrow X_1$. In the first case, we consider the effect of privilege $A \rightarrow X_2$ with $A \rightarrow X_1$ still present (i.e., $x_1$ is not warped), and for Eq. \ref{def:psc} compute
\[\pih(\xv_{S_j^{(1)}}) - \pih(\xv_{S_j^{(1)} \cup \{j\}}) = \pih(x_1, x_2) - \pih(x_1, \xt_2(x_2)), \]
in the second case, we look at the effect of privilege $A \rightarrow X_2$ without $A \rightarrow X_1$ (i.e., $x_1$ is warped to $\xt_1$)
\[\pih(\xv_{S_j^{(2)}}) - \pih(\xv_{S_j^{(2)} \cup \{j\}}) = \pih(\xt_1, \xt_2(x_1)) - \pih(\xt_1, \xt_2), \]
where $\xt_2(x_1)$ means that $x_2$ was partially warped through the path via $x_1$, and $\xt_2 = \xt_2(x_1, x_2)$.

This does not change the definition of PSCs in Eq.\ \ref{def:psc}, as the number of summands remains the same, and this is just a finer-grained definition of $\xv_{S}$. Since the current warping methods are not yet fully capable of performing these partial warpings out-of-the-box, in the experiments below we limit ourselves to cases that do not require partial warping, emphasizing that this is not a shortcoming of PSCs, but future work in the field of warping method development.


\subsection{Shapley values}
\label{app:iml-shapley}
Alternatively, we can use ``standard'' Shapley values for interpretation. Shapley values $\beta_j$ for the real world can be defined as

\[\pixh = \underbrace{\E_\xv(\pixh)}_{\beta_0} + \sum_{j=1}^p \beta_j,\]

where shapley values $\tilde{\beta}_j$ in the warped world can be defined as

\[\pitxth = \underbrace{\E_{\xtil}(\pitxth)}_{\tilde{\beta}_0} + \sum_{j=1}^p \tilde{\beta}_j.\]

Bringing both together, shapley values $\eta_j$ of the PS are defined via

\begin{align*}
    \hpx &= \pixh - \pitxth\\
    &=\underbrace{(\beta_0-\tilde{\beta}_0)}_{\eta_0} + \sum_{j=1}^p\underbrace{(\beta_j-\tilde{\beta}_j)}_{\eta_j}.
\end{align*}

Due to additivity, this defines consistent shapley values for the PS, which also means that standard estimation techniques can be used.






\section{Simulation study}
\label{app:sec:exp-sim}

\subsection{Simulation study -- setup}
\label{app:sec:sim-setup}

For our simulation study, we generate $M=50$ synthetic data sets each of size $n=1000$, using the DAG shown in Figure \ref{fig:DAG-example-psc}.
Data consist of: binary PA \textit{Gender} ($A$, female/male), numerical feature \textit{Amount} ($X_1$), binary feature \textit{Saving} ($X_2$, low/high), numerical confounder \textit{Age} ($C$) -- and binary target \textit{Risk} ($Y$, (1) for low and (0) high). 
To create the bootstrap confidence intervals for PS and PSC, we draw $B=100$ samples. For each of the two experimental scenarios (SC) and (SM), we sample from a separate SCM both of which are provided below. For both real and FiND world we draw random samples using the same structural assignments with the only difference that in the FiND world, the value of the PA is forced to take the value of the advantaged group which is the male group, denoted with (1). To ensure we draw the same individual for each world, we use the same random seed for both worlds and reset it before starting simulation from each world. 

Structural assignments from the (SC) simulation scenario are defined as follows:
\begin{equation*}
    \begin{aligned}
    A &\sim \text{Binomial}(p = 0.69), \\
    C &\sim \text{Gamma}(k = 9.76, \theta = 3.64), \\
    X_1|A,C &\sim \text{Gamma}\left(k = 0.74^{-1}, \theta = 0.74 \cdot \exp\left(7.9 + 0.175 \cdot A + 0.005 \cdot C\right)\right), \\
    X_2|A,C &\sim \text{Binomial}\left(\text{probit}\left(4 - 1.25 \cdot A - 0.1 \cdot C\right)\right), \\
    Y|A,C,X_1,X_2 &\sim \text{Binomial}\left(\text{probit}\left(0.9 + 0.1 \cdot C + 1.75 \cdot A - 0.7 \cdot X_2 - 0.001 \cdot X_1 \right)\right),
\end{aligned}
\end{equation*}

where $k$ denotes the shape parameter and $\theta$ the scale parameter of the gamma distribution. Equivalently, the SCM used to generate data for the (SM) simulation scenario consist of the parameters
\begin{equation*}
    \begin{aligned}
    A &\sim \text{Binomial}(p = 0.69), \\
    C|A &\sim \text{Gamma}\left(k = 10, \theta = 2 \cdot \exp\left(0.1 + 0.8 \cdot A\right)\right), \\
    X_1|A,C &\sim \text{Gamma}\left(k = 0.74^{-1}, \theta = 0.74 \cdot \exp\left(7.9 + 0.175 \cdot A + 0.005 \cdot C\right)\right), \\
    X_2|A,C &\sim \text{Binomial}\left(\text{probit}\left(4 - 1.25 \cdot A - 0.1 \cdot C\right)\right), \\
    Y|A,C,X_1,X_2 &\sim \text{Binomial}\left(\text{probit}\left(0.9 + 0.1 \cdot C + 1.75 \cdot A - 0.7 \cdot X_2 - 0.001 \cdot X_1\right)\right),
    \end{aligned}
\end{equation*}

where again  $k$ and $\theta$ denote the shape and scale parameter of the gamma distribution respectively. Note that the SCM from (SM) differs from the SCM of the (SC) scenario only with respect to the structural assignment of the node $C$. However, during training and inference, we use the SCM from (SC) which thus leads to a misspecification. 

To predict outcome $Y$, we implement a random forest classifier. During training we utilize random search with 25 evaluations and 3-fold CV. For evaluation, we use 3-fold CV as outer resampling, and report metrics on test folds. We report summary statistics of the data set for one iteration of (SC) in Table \ref{tab:sim_sumstats}.

\begin{table}[!h]
    \centering
    \caption{Summary statistics for one random sample of size $n=1000$ for the simulation scenario (SC).}
    \label{tab:sim_sumstats}
    \resizebox{\ifdim\width>\linewidth\linewidth\else\width\fi}{!}{
    \begin{tabular}{lrrrrrrrrr}
        \toprule
        \multicolumn{1}{c}{ } & \multicolumn{3}{c}{All} & \multicolumn{3}{c}{Female} & \multicolumn{3}{c}{Male} \\
        \cmidrule(l{3pt}r{3pt}){2-4} \cmidrule(l{3pt}r{3pt}){5-7} \cmidrule(l{3pt}r{3pt}){8-10}
        Variable & n & mean & std. dev. & n & mean & std. dev. & n & mean & std. dev.\\
        \midrule
        Age & 1000 & 36.166 & 11.293 & 307 & 36.611 & 10.994 & 693 & 35.969 & 11.425\\
        Amount & 1000 & 3569.819 & 3049.610 & 307 & 3121.363 & 2682.451 & 693 & 3768.486 & 3180.480\\
        Risk & 1000 & 0.748 & 0.434 & 307 & 0.681 & 0.467 & 693 & 0.778 & 0.416\\
        Saving & 1000 & 0.440 & 0.497 & 307 & 0.612 & 0.488 & 693 & 0.364 & 0.481\\
        \bottomrule
    \end{tabular}}
\end{table}





\subsection{Simulation study -- additional results}
\label{app:sec:sim-results}


Scenario (SC): Table \ref{tab:app-sim-sc} shows full results for both res-based warping (top) and fairadapt (bottom).


Scenario (SM): Table \ref{tab:app-sim-sm-psc} shows full results for both res-based warping (top) and fairadapt (bottom).


\begin{table}[ht] % table-ID: S-S2-psc-metrics-table
    \centering
            \caption{SC -- PS/PSCs. Data are based on the simulation study with 50 iterations following (SC) simulation scenario and CIs are computed via bootstrap. First rows report the mean, second rows the 5th and 95th percentile. The upper panel presents results for res-based warping the bottom those for fairadapt.} 
            \label{tab:app-sim-sc}
    % \resizebox{0.98\textwidth}{!}{ % Adjust the table to fit within the column width
        \begin{tabular}{lcccc}
            \hline
            & Bias & MSE & Coverage & Width CI \\ 
            \hline
            $\hp$ & 0.002 & 0.012 & 0.969 & 0.292 \\ 
            & (-0.014, 0.014) & (0.007, 0.016) & (0.939, 0.988) & (0.267, 0.318) \\ 
            $\priv_g$ & 0.002 & 0 & 0.973 & 0.036 \\ 
            & (-0.007, 0.012) & (0, 0) & (0.817, 1) & (0.032, 0.041) \\ 
            %local intercept & 0 & 0.011 & 0.983 & 0.292 \\ 
            %& (-0.012, 0.011) & (0.007, 0.016) & (0.973, 0.994) & (0.264, 0.32) \\ 
            $\priv_{\xtil}$ & -0.002 & 0.011 & 0.984 & 0.294 \\ 
            & (-0.013, 0.009) & (0.007, 0.016) & (0.973, 0.996) & (0.269, 0.321) \\ 
            $\gx[1]$ & -0.001 & 0.002 & 0.958 & 0.09 \\ 
            & (-0.009, 0.009) & (0.001, 0.004) & (0.936, 0.981) & (0.075, 0.107) \\ 
            $\gx[2]$ & 0.003 & 0.002 & 0.866 & 0.013 \\ 
            & (-0.001, 0.006) & (0.001, 0.002) & (0.846, 0.884) & (0.007, 0.02) \\ 
            \hline
            $\hp$ & -0.001 & 0.011 & 0.977 & 0.296 \\ 
            & (-0.015, 0.012) & (0.007, 0.015) & (0.944, 0.994) & (0.265, 0.321) \\ 
            $\priv_g$ & -0.001 & 0 & 1 & 0.037 \\ 
            & (-0.008, 0.007) & (0, 0) & (1, 1) & (0.034, 0.041) \\ 
            %local intercept & -0.001 & 0.01 & 0.983 & 0.284 \\ 
            %& (-0.013, 0.008) & (0.007, 0.014) & (0.965, 0.996) & (0.259, 0.312) \\ 
            $\priv_{\xtil}$ & 0 & 0.01 & 0.983 & 0.285 \\ 
            & (-0.008, 0.008) & (0.007, 0.014) & (0.97, 0.996) & (0.261, 0.313) \\ 
            $\gx[1]$ & -0.003 & 0.002 & 0.953 & 0.09 \\ 
            & (-0.013, 0.008) & (0.001, 0.004) & (0.928, 0.973) & (0.076, 0.109) \\ 
            $\gx[2]$ & 0.002 & 0.001 & 0.923 & 0.025 \\ 
            & (-0.001, 0.005) & (0.001, 0.002) & (0.89, 0.952) & (0.016, 0.036) \\ 
            \hline
        \end{tabular}
    % }
\end{table}




% \begin{table}[!h] % table-ID: S-S2-psc-metrics-M50-sex-res-table
%     \centering
%     \caption{Summary statistics for res-based warping by gender across $M=50$ simulation iterations. Samples are from (SC) scenario, each of size $n=1000$. We compute confidence intervals using bootstrap with $\alpha=0.1$. First rows report the mean and second rows the 5th and 95th percentile for each metric across iterations.}
%     \resizebox{\ifdim\width>\linewidth\linewidth\else\width\fi}{!}{
%     \begin{tabular}{lcccccc}
%         \toprule
%         \multicolumn{1}{c}{ } & \multicolumn{2}{c}{Bias} & \multicolumn{2}{c}{MSE} & \multicolumn{2}{c}{Coverage} \\
%         \cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5} \cmidrule(l{3pt}r{3pt}){6-7}
%         Metric & Female & Male & Female & Male & Female & Male\\
%         \midrule
%         privilege & 0.048 & -0.018 & 0.023 & 0.007 & 0.904 & 0.998\\
%         & (0.001, 0.093) & (-0.024, -0.012) & (0.014, 0.033) & (0.003, 0.013) & (0.813, 0.958) & (0.996, 1)\\
%         global intercept & 0.002 & 0.002 & 0 & 0 & 0.975 & 0.972\\
%         & (-0.007, 0.012) & (-0.007, 0.013) & (0, 0) & (0, 0) & (0.84, 1) & (0.805, 1)\\
%         local intercept & 0.041 & -0.018 & 0.019 & 0.007 & 0.95 & 0.998\\
%         % \addlinespace
%         & (0.002, 0.077) & (-0.024, -0.012) & (0.012, 0.028) & (0.003, 0.013) & (0.916, 0.982) & (0.996, 1)\\
%         delta\_x & 0.039 & -0.02 & 0.018 & 0.007 & 0.953 & 0.998\\
%         & (0.001, 0.069) & (-0.033, -0.009) & (0.012, 0.027) & (0.003, 0.013) & (0.916, 0.985) & (0.992, 1)\\
%         Amount & -0.004 & 0 & 0.007 & 0 & 0.864 & 1\\
%         & (-0.028, 0.03) & (0, 0) & (0.005, 0.012) & (0, 0) & (0.792, 0.932) & (1, 1)\\
%         % \addlinespace
%         Saving & 0.01 & 0 & 0.005 & 0 & 0.572 & 1\\
%         & (-0.003, 0.017) & (0, 0) & (0.004, 0.006) & (0, 0) & (0.526, 0.621) & (1, 1)\\
%         \bottomrule
%     \end{tabular}}
% \end{table}



% \begin{table}[!h] % table-ID: S-S2-psc-metrics-M50-sex-fair-table
% \centering
% \caption{Summary statistics for fairadapt warping by gender across $M=50$ simulation iterations. Samples are from (SC) scenario, each of size $n=1000$. We compute confidence intervals using bootstrap with $\alpha=0.1$. First rows report the mean and second rows the 5th and 95th percentile for each metric across iterations.}
% \resizebox{\ifdim\width>\linewidth\linewidth\else\width\fi}{!}{
% \begin{tabular}{lcccccc}
% \toprule
% \multicolumn{1}{c}{ } & \multicolumn{2}{c}{Bias} & \multicolumn{2}{c}{MSE} & \multicolumn{2}{c}{Coverage} \\
% \cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5} \cmidrule(l{3pt}r{3pt}){6-7}
% Metric & Female & Male & Female & Male & Female & Male\\
% \midrule
% privilege & 0.038 & -0.019 & 0.023 & 0.006 & 0.927 & 1\\
%  & (-0.006, 0.089) & (-0.03, -0.012) & (0.014, 0.036) & (0.003, 0.011) & (0.826, 0.98) & (0.997, 1)\\
% global intercept & -0.001 & -0.001 & 0 & 0 & 1 & 1\\
%  & (-0.008, 0.007) & (-0.008, 0.007) & (0, 0) & (0, 0) & (1, 1) & (1, 1)\\
% local intercept & 0.04 & -0.019 & 0.018 & 0.006 & 0.947 & 1\\
% \addlinespace
%  & (0.005, 0.068) & (-0.03, -0.012) & (0.013, 0.024) & (0.003, 0.011) & (0.886, 0.987) & (0.997, 1)\\
% delta\_x & 0.041 & -0.018 & 0.018 & 0.006 & 0.949 & 0.999\\
%  & (0.013, 0.064) & (-0.031, -0.007) & (0.012, 0.024) & (0.003, 0.011) & (0.905, 0.985) & (0.996, 1)\\
% Amount & -0.008 & 0 & 0.008 & 0 & 0.851 & 1\\
%  & (-0.043, 0.026) & (0, 0) & (0.005, 0.012) & (0, 0) & (0.767, 0.912) & (1, 1)\\
% \addlinespace
% Saving & 0.006 & 0 & 0.004 & 0 & 0.752 & 1\\
%  & (-0.005, 0.016) & (0, 0) & (0.003, 0.005) & (0, 0) & (0.655, 0.839) & (1, 1)\\
% \bottomrule
% \end{tabular}}
% \end{table}





\begin{table}[ht] % table-ID: S-S3-psc-metrics-table
    \centering
           \caption{SM -- PS/PSCs. Data are based on the simulation study with 50 iterations following (SM) simulation scenario and CIs are computed via bootstrap. First rows report the mean, second rows the 5th and 95th percentile. The upper panel presents results for res-based warping the bottom those for fairadapt.} 
           \label{tab:app-sim-sm-psc}
    % \resizebox{0.98\textwidth}{!}{ % Adjust the table to fit within the column width
        \begin{tabular}{lcccc}
          \hline
         & Bias & MSE & Coverage & Width CI \\ 
              \hline
            $\hp$ & 0.001 & 0.017 & 0.949 & 0.279 \\ 
               & (-0.012, 0.016) & (0.012, 0.023) & (0.93, 0.963) & (0.259, 0.3) \\ 
              $\priv_g$ & -0.04 & 0.002 & 0.313 & 0.059 \\ 
               & (-0.056, -0.024) & (0.001, 0.003) & (0, 0.667) & (0.045, 0.078) \\ 
              % local intercept & -0.079 & 0.037 & 0.858 & 0.287 \\ 
              %  & (-0.093, -0.067) & (0.027, 0.045) & (0.825, 0.892) & (0.264, 0.311) \\ 
              $\priv_{\xtil}$ & -0.039 & 0.032 & 0.728 & 0.3 \\ 
               & (-0.057, -0.026) & (0.024, 0.039) & (0.545, 0.862) & (0.28, 0.321) \\ 
              $\gx[1]$ & -0.018 & 0.004 & 0.924 & 0.106 \\ 
               & (-0.031, -0.004) & (0.003, 0.007) & (0.877, 0.955) & (0.092, 0.122) \\ 
              $\gx[2]$ & 0.014 & 0.002 & 0.798 & 0.011 \\ 
               & (0.011, 0.017) & (0.001, 0.002) & (0.736, 0.88) & (0, 0.03) \\ 
               \hline
            $\hp$ & 0.037 & 0.024 & 0.94 & 0.303 \\ 
               & (0.013, 0.062) & (0.014, 0.036) & (0.897, 0.976) & (0.275, 0.336) \\ 
              $\priv_g$ & -0.016 & 0.001 & 0.82 & 0.072 \\ 
               & (-0.034, 0.004) & (0, 0.001) & (0.334, 1) & (0.053, 0.091) \\ 
              % local intercept & -0.046 & 0.022 & 0.951 & 0.3 \\ 
              %  & (-0.065, -0.028) & (0.014, 0.032) & (0.907, 0.979) & (0.272, 0.337) \\ 
              $\priv_{\xtil}$ & -0.029 & 0.02 & 0.923 & 0.312 \\ 
               & (-0.04, -0.017) & (0.014, 0.03) & (0.783, 0.98) & (0.283, 0.346) \\ 
              $\gx[1]$ & -0.008 & 0.004 & 0.942 & 0.106 \\ 
               & (-0.023, 0.005) & (0.002, 0.006) & (0.912, 0.964) & (0.09, 0.12) \\ 
              $\gx[2]$ & 0.007 & 0.001 & 0.937 & 0.046 \\ 
               & (-0.001, 0.013) & (0.001, 0.002) & (0.88, 0.972) & (0.033, 0.065) \\ 
               \hline
        \end{tabular}
    % }
\end{table}

%$\priv$ $\priv_g$ & $\priv_{\xtil}$ & $\gx[1]$ & $\gx[2]$

% \begin{table}[!h] % table-ID: S-SM-psc-metrics-table-res
% \centering
% \caption{M50, res-based, (SM)}
% \resizebox{\ifdim\width>\linewidth\linewidth\else\width\fi}{!}{
% \begin{tabular}{ccccccc}
% \toprule
% \multicolumn{1}{c}{ } & \multicolumn{2}{c}{Bias} & \multicolumn{2}{c}{MSE} & \multicolumn{2}{c}{Coverage} \\
% \cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5} \cmidrule(l{3pt}r{3pt}){6-7}
% Metric & Female & Male & Female & Male & Female & Male\\
% \midrule
% privilege & 0.037 & -0.015 & 0.04 & 0.007 & 0.88 & 0.98\\
%  & (-0.004, 0.087) & (-0.02, -0.009) & (0.027, 0.06) & (0.003, 0.011) & (0.822, 0.923) & (0.968, 0.989)\\
% global intercept & -0.04 & -0.04 & 0.002 & 0.002 & 0.313 & 0.313\\
%  & (-0.056, -0.024) & (-0.056, -0.024) & (0.001, 0.003) & (0.001, 0.003) & (0, 0.691) & (0, 0.676)\\
% local intercept & -0.22 & -0.015 & 0.103 & 0.007 & 0.589 & 0.98\\
% \addlinespace
%  & (-0.259, -0.182) & (-0.02, -0.009) & (0.076, 0.129) & (0.003, 0.011) & (0.485, 0.695) & (0.968, 0.989)\\
% delta\_x & -0.18 & 0.025 & 0.087 & 0.007 & 0.684 & 0.747\\
%  & (-0.211, -0.145) & (0.007, 0.042) & (0.064, 0.106) & (0.004, 0.011) & (0.585, 0.772) & (0.493, 0.95)\\
% Amount & -0.057 & 0 & 0.014 & 0 & 0.756 & 1\\
%  & (-0.1, -0.014) & (0, 0) & (0.008, 0.023) & (0, 0) & (0.605, 0.857) & (1, 1)\\
% \addlinespace
% Saving & 0.046 & 0 & 0.005 & 0 & 0.353 & 1\\
%  & (0.04, 0.053) & (0, 0) & (0.005, 0.006) & (0, 0) & (0.185, 0.605) & (1, 1)\\
% \bottomrule
% \end{tabular}}
% \end{table}

% \begin{table}[!h] % table-ID: S-SM-psc-metrics-table-fair
% \centering
% \caption{M50, fairadapt, (SM)}
% \resizebox{\ifdim\width>\linewidth\linewidth\else\width\fi}{!}{
% \begin{tabular}{ccccccc}
% \toprule
% \multicolumn{1}{c}{ } & \multicolumn{2}{c}{Bias} & \multicolumn{2}{c}{MSE} & \multicolumn{2}{c}{Coverage} \\
% \cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5} \cmidrule(l{3pt}r{3pt}){6-7}
% Metric & Female & Male & Female & Male & Female & Male\\
% \midrule
% privilege & 0.138 & -0.01 & 0.066 & 0.005 & 0.814 & 0.997\\
%  & (0.055, 0.219) & (-0.017, -0.002) & (0.038, 0.101) & (0.003, 0.012) & (0.68, 0.923) & (0.992, 1)\\
% global intercept & -0.016 & -0.016 & 0.001 & 0.001 & 0.82 & 0.82\\
%  & (-0.034, 0.004) & (-0.034, 0.004) & (0, 0.001) & (0, 0.001) & (0.357, 1) & (0.335, 1)\\
% local intercept & -0.125 & -0.01 & 0.058 & 0.005 & 0.849 & 0.997\\
% \addlinespace
%  & (-0.203, -0.069) & (-0.017, -0.002) & (0.036, 0.087) & (0.003, 0.012) & (0.719, 0.941) & (0.992, 1)\\
% delta\_x & -0.109 & 0.007 & 0.052 & 0.006 & 0.874 & 0.946\\
%  & (-0.169, -0.064) & (-0.019, 0.028) & (0.035, 0.076) & (0.003, 0.013) & (0.771, 0.957) & (0.784, 1)\\
% Amount & -0.027 & 0 & 0.013 & 0 & 0.814 & 1\\
%  & (-0.073, 0.014) & (0, 0) & (0.007, 0.02) & (0, 0) & (0.713, 0.881) & (1, 1)\\
% \addlinespace
% Saving & 0.022 & 0 & 0.005 & 0 & 0.798 & 1\\
%  & (-0.003, 0.044) & (0, 0) & (0.003, 0.007) & (0, 0) & (0.616, 0.909) & (1, 1)\\
% \bottomrule
% \end{tabular}}
% \end{table}


\clearpage

\section{Real-world data}
\label{app:sec:exp-real}



\subsection{Mortgage data}
\label{app:sec:mortgage}


\subsubsection{Data Setup}
For the 2022 Home Mortgage Disclosure Act (HMDA) data,\footnote{\url{https://ffiec.cfpb.gov/data-browser/}} we apply the following encoding and filtering steps\footnote{Comprehensive variable descriptions are available at: \url{https://ffiec.cfpb.gov/documentation/publications/loan-level-datasets/lar-data-fields}}:

\begin{itemize}
\item $Y$: A binary outcome variable representing whether the loan was approved (1) or not approved (0). This is derived from the original “action taken” variable, which categorizes loan statuses into eight distinct groups.
\item $A$: Binary protected attribute representing the applicant's race, with (1) White applicants and (0) other applicants.
\item $X_1$: Numerical feature for the loan amount.
\item $X_2$: Binary feature for the debt-to-income ratio, indicating whether the ratio is smaller than $36\%$ (1) or higher (0).
\item $X_3$: Binary feature indicating the loan's purpose, with (1) signifying home purchases and (0) for other purposes. The original variable consists of six categories.
\item $\bm{C}$: This variable combines two confounders -- age and sex. Age is represented as a binary variable indicating (1) age over 62 or (0) age 62 and below. Sex is also simplified into a binary form, with (1) for male and (0) for female. (Note: This binary simplification of gender is used purely for analytical simplicity and does not represent the authors' viewpoint.)
\end{itemize}

Table \ref{tab:hmda-summary} provides a summary of the three data sets used for state Lousiana (LA), state Wisconsin (WI), and New York County (NY). Already these rough summary statistics hint at LA exhibiting higher disparities in $Y$ with respect to race and gender than WI and NY.
For each locations, we split the data in $80\%$ training and $20\%$ test data, tune hyperparameters with 3-fold CV and random search with 25 evaluations on the training data, and report metrics on the test set.


% latex table generated in R 4.4.0 by xtable 1.8-4 package
% Tue Jan 28 13:37:25 2025
\begin{table}[ht]
\centering
\caption{Summary statistics for HMDA data} 
\begin{tabular}{lrrr}
  \hline
 & LA & WI & NY \\ 
  \hline
Number of Observations &  73790 & 165004 &  14708 \\ 
  Sex Ratio (Female) & 0.4033 & 0.3776 & 0.3799 \\ 
  Race Ratio (Non-White) & 0.3287 & 0.1205 & 0.3704 \\ 
  Loan Purpose (Home Purchase) & 0.5963 & 0.3854 & 0.6322 \\ 
  Age Ratio (Above 62) & 0.1525 & 0.1731 & 0.1355 \\ 
  Debt Ratio (Low) & 0.4414 & 0.5164 & 0.5623 \\ 
  Mean Loan Amount &  193174 &  176538 & 1066191 \\ 
  Mean Action Taken (Non-White) & 0.4669 & 0.7337 & 0.7950 \\ 
  Mean Action Taken (White) & 0.7071 & 0.8367 & 0.8320 \\ 
  Mean Action Taken (Female) & 0.5618 & 0.8112 & 0.8171 \\ 
  Mean Action Taken (Male) & 0.6729 & 0.8323 & 0.8190 \\ 
  \hline
\end{tabular}
\label{tab:hmda-summary}
\end{table}

\subsubsection{Results State Louisiana}

Table \ref{tab:app_la} shows the 6 individuals with the lowest PS and the 6 individuals with the highest PS for test data of LA using res-based warping. Figure \ref{fig:app-la-psc-res} shows PSCs for these individuals. Most notably, individuals with lowest privilege scores are young, non-white females, while there is no non-white female amongst the individuals with highest privilege. Besides the above mentioned race effect of $0.22$ on the PS, we also see a significant -- but smaller -- sex effect of $0.03$. The age effect is not significant. See Table \ref{tab:la-lm-summary} for full model summary.

Table \ref{tab:app_la-adapt} shows the 6 individuals with the lowest PS and the 6 individuals with the highest PS for test data of LA using fairadapt. Figure \ref{fig:app-la-psc-adapt} shows PSCs for these individuals. 
Table \ref{tab:la-lm-summary-adapt} exhibits similar sex and race effects as for res-based warping.
Table \ref{tab:mortgage-fairadapt} shows the PS/PSC. Numbers are comparable to results of res-based warping, see Table \ref{tab:mortgage}, which substantiates the prior findings. 


% latex table generated in R 4.4.0 by xtable 1.8-4 package
% Wed Jan 22 09:20:33 2025
\begin{sidewaystable}[ht!]
\centering
\caption{LA -- res-based warping -- Individuals with smallest (upper half) and largest (lower half) PS. Warped features are indicated by ``\_w''.}
\begin{tabular}{rrrrrrrrrrrr}
  \hline
ID & sex & race & age & purpose & amount & debt & purpose\_w & amount\_w & debt\_w & pred\_real & pred\_warped \\ 
  \hline
244 &   0 &   0 &   0 &   1 & 85000 &   0 & 0.24 & 98186.99 &   0 & 0.18 & 1.00 \\ 
  1811 &   0 &   0 &   0 &   1 & 85000 &   0 & 0.24 & 98186.99 &   0 & 0.18 & 1.00 \\ 
  2141 &   0 &   0 &   0 &   1 & 85000 &   0 & 0.24 & 98186.99 &   0 & 0.18 & 1.00 \\ 
  2592 &   0 &   0 &   0 &   1 & 85000 &   0 & 0.24 & 98186.99 &   0 & 0.18 & 1.00 \\ 
  2845 &   0 &   0 &   0 &   1 & 85000 &   0 & 0.24 & 98186.99 &   0 & 0.18 & 1.00 \\ 
  2876 &   0 &   0 &   0 &   1 & 85000 &   0 & 0.24 & 98186.99 &   0 & 0.18 & 1.00 \\ 
  \hline
  8431 &   1 &   1 &   0 &   1 & 2155000 &   0 & 1.00 & 2155000.00 &   0 & 0.68 & 0.53 \\ 
  30714 &   1 &   0 &   1 &   1 & 655000 &   1 & 1.00 & 921105.10 &   1 & 0.84 & 0.74 \\ 
  44887 &   0 &   1 &   0 &   0 & 8825000 &   0 & 0.00 & 8825000.00 &   0 & 0.68 & 0.59 \\ 
  33820 &   1 &   1 &   1 &   0 & 1185000 &   0 & 0.00 & 1185000.00 &   0 & 0.64 & 0.54 \\ 
  50604 &   0 &   1 &   1 &   0 & 455000 &   0 & 0.00 & 455000.00 &   0 & 0.58 & 0.49 \\ 
  44593 &   1 &   1 &   1 &   0 & 1375000 &   0 & 0.00 & 1375000.00 &   0 & 0.66 & 0.58 \\ 
   \hline
\end{tabular}
\label{tab:app_la}
\end{sidewaystable}

% latex table generated in R 4.4.0 by xtable 1.8-4 package
% Wed Jan 22 09:20:33 2025
\begin{sidewaystable}[ht!]
\centering
\caption{LA -- fairadapt -- Individuals with smallest (upper half) and largest (lower half) PS. Warped features are indicated by ``\_w''.}
\begin{tabular}{rrrrrrrrrrrr}
  \hline
ID & sex & race & age & purpose & amount & debt & purpose\_w & amount\_w & debt\_w & pred\_real & pred\_warped \\ 
  \hline
31459 &   0 &   0 &   1 &   1 & 105000 &   0 &   0 & 145000 &   1 & 0.24 & 0.85 \\ 
  23865 &   0 &   0 &   0 &   1 & 105000 &   1 &   0 & 145000 &   1 & 0.25 & 0.86 \\ 
  55703 &   0 &   0 &   0 &   1 & 145000 &   0 &   0 & 195000 &   1 & 0.28 & 0.86 \\ 
  68335 &   0 &   0 &   0 &   1 & 145000 &   0 &   0 & 195000 &   1 & 0.28 & 0.86 \\ 
  28202 &   0 &   0 &   0 &   1 & 145000 &   0 &   1 & 195000 &   1 & 0.28 & 0.83 \\ 
  29587 &   0 &   0 &   0 &   1 & 145000 &   0 &   1 & 195000 &   1 & 0.28 & 0.83 \\ 
    \hline
  2285 &   0 &   0 &   0 &   1 & 5000 &   0 &   0 & 25000 &   0 & 0.70 & 0.46 \\ 
  8607 &   0 &   0 &   0 &   1 & 5000 &   0 &   0 & 25000 &   0 & 0.70 & 0.46 \\ 
  27585 &   0 &   0 &   0 &   1 & 5000 &   0 &   0 & 25000 &   0 & 0.70 & 0.46 \\ 
  28383 &   0 &   0 &   0 &   1 & 5000 &   0 &   0 & 25000 &   0 & 0.70 & 0.46 \\ 
  42009 &   0 &   0 &   0 &   1 & 5000 &   0 &   0 & 25000 &   0 & 0.70 & 0.46 \\ 
  72477 &   0 &   0 &   0 &   1 & 5000 &   0 &   0 & 25000 &   0 & 0.70 & 0.46 \\ 
   \hline
\end{tabular}
\label{tab:app_la-adapt}
\end{sidewaystable}




\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figs/privilege_score_plots_chimamanda_res_based_global_2025-01-16_08-01-49_louisiana.pdf} 
    \caption{LA -- res-based -- Individuals with smallest (left) and largest (right) PS.}
    \label{fig:app-la-psc-res}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figs/privilege_score_plots_chimamanda_fairadapt_global_2025-01-16_08-01-49_louisiana.pdf} 
    \caption{LA -- fairadapt -- Individuals with smallest (left) and largest (right) PS.}
    \label{fig:app-la-psc-adapt}
\end{figure}

%\clearpage

\begin{table}[ht]
\centering
\caption{LA -- res-based -- Linear Model Summary} 
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & -0.3087 & 0.0041 & -75.3542 & $<$ 1e-16 \\ 
  sex & 0.0326 & 0.0032 & 10.3000 & $<$ 1e-16 \\ 
  race & 0.2200 & 0.0033 & 66.5151 & $<$ 1e-16 \\ 
  purpose & -0.0336 & 0.0032 & -10.5666 & $<$ 1e-16 \\ 
  amount & 0.0000 & 0.0000 & 22.9779 & $<$ 1e-16 \\ 
  debt & 0.0925 & 0.0031 & 30.0047 & $<$ 1e-16 \\ 
  age & 0.0003 & 0.0043 & 0.0759 & 0.93953 \\ 
   \hline
\end{tabular}
\label{tab:la-lm-summary}
\end{table}



%\paragraph{Fairadapt}


\begin{table}[ht]
\centering
\caption{LA -- fairadapt -- Linear Model Summary} 
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & -0.2597 & 0.0016 & -164.0807 & $<$ 1e-16 \\ 
  sex & 0.0151 & 0.0012 & 12.3340 & $<$ 1e-16 \\ 
  race & 0.2352 & 0.0013 & 184.0681 & $<$ 1e-16 \\ 
  purpose & -0.0056 & 0.0012 & -4.5356 & 5.7903e-06 \\ 
  amount & 0.0000 & 0.0000 & 19.5736 & $<$ 1e-16 \\ 
  debt & 0.0050 & 0.0012 & 4.1613 & 3.1827e-05 \\ 
  age & 0.0063 & 0.0017 & 3.7751 & 0.00016057 \\ 
   \hline
\end{tabular}
\label{tab:la-lm-summary-adapt}
\end{table}

\begin{table}[ht]
\centering
\caption{LA -- fairadapt -- Mean and quantiles ($\alpha=0.05$) of PS/PSC and PSC importance on test data}
\begin{tabular}{lrrr}
  \hline
 & Mean & Quantiles $(\alpha, 1-\alpha)$ & Importance \\ 
  \hline
$\hp$ & -0.243 & (-0.451, -0.058) & -- \\ 
   $\priv_g$ & -0.058 & (-0.058, -0.058) & 0.058 \\ 
  $\priv_{\xv}$ & -0.119 & (-0.240, 0.005) & 0.121 \\ 
  $\gx[1]$ & -0.046 & (-0.204, 0.006) & 0.063 \\ 
  $\gx[2]$ & -0.017 & (-0.144, 0.000) & 0.017 \\ 
  $\gx[3]$ & -0.003 & (0.000, 0.000) & 0.010 \\ 
   \hline
\end{tabular}
\label{tab:mortgage-fairadapt}
\end{table}



\subsubsection{Results State Wisconsin}

Table \ref{tab:app_wi-res} shows the 6 individuals with the lowest PS and the 6 individuals with the highest PS for test data of WI using res-based warping. Figure \ref{fig:app-wi-psc} shows PSCs for these individuals.  
Table \ref{tab:lm_summary-wi-res} gives a model summary of regressing PS on real-world features.
Besides the above mentioned race effect of $0.10$ on the PS, we also see a significant -- but smaller -- sex effect of $0.002$. The age effect is not significant.  Table \ref{tab:psc-wi-res} shows the PS/PSC results.

Table \ref{tab:app_wi-adapt} shows the 6 individuals with the lowest PS and the 6 individuals with the highest PS for test data of WI using fairadapt. Figure \ref{fig:app-wi-psc-adapt} shows PSCs for these individuals. 
Table \ref{tab:lm-wi-adapt} exhibits similar sex and race effects as for res-based warping.
Table \ref{tab:psc-wi-fairadapt} shows the PS/PSC results for fairadapt. Numbers are comparable to results of res-based warping.

\begin{sidewaystable}[ht!]
\centering
\caption{WI -- res-based -- Individuals with smallest (upper half) and largest (lower half) PS. Warped features are indicated by ``\_w''.}
\begin{tabular}{rrrrrrrrrrrr}
  \hline
ID & sex & race & age & purpose & amount & debt & purpose\_w & amount\_w & debt\_w & pred\_real & pred\_warped \\ 
  \hline
54405 &   1 &   0 &   0 &   0 & 5000 &   0 & -0.01 & 5000.00 &   0 & 0.18 & 0.99 \\ 
  152974 &   1 &   0 &   1 &   0 & 5000 &   0 & -0.20 & 15000.00 &   0 & 0.25 & 1.00 \\ 
  102617 &   0 &   0 &   0 &   0 & 5000 &   0 & 0.01 & 17414.82 &   0 & 0.33 & 0.98 \\ 
  104638 &   0 &   0 &   0 &   0 & 5000 &   0 & 0.01 & 17414.82 &   0 & 0.33 & 0.98 \\ 
  114935 &   0 &   0 &   0 &   0 & 5000 &   0 & 0.01 & 17414.82 &   0 & 0.33 & 0.98 \\ 
  154885 &   0 &   0 &   0 &   0 & 5000 &   0 & 0.01 & 17414.82 &   0 & 0.33 & 0.98 \\ 
    \hline
  104914 &   0 &   1 &   0 &   1 & 2805000 &   1 & 1.00 & 2805000.00 &   1 & 0.80 & 0.68 \\ 
  14944 &   0 &   0 &   0 &   1 & 5000 &   1 & 1.01 & 17414.82 &   1 & 0.85 & 0.74 \\ 
  32011 &   0 &   0 &   0 &   1 & 5000 &   1 & 1.01 & 17414.82 &   1 & 0.85 & 0.74 \\ 
  49649 &   0 &   0 &   0 &   1 & 5000 &   1 & 1.01 & 17414.82 &   1 & 0.85 & 0.74 \\ 
  66283 &   0 &   0 &   0 &   1 & 5000 &   1 & 1.01 & 17414.82 &   1 & 0.85 & 0.74 \\ 
  110046 &   0 &   0 &   0 &   1 & 5000 &   1 & 1.01 & 17414.82 &   1 & 0.85 & 0.74 \\ 
   \hline
\end{tabular}
\label{tab:app_wi-res}
\end{sidewaystable}


\begin{sidewaystable}[ht!]
\centering
\caption{WI -- fairadapt -- Individuals with smallest (upper half) and largest (lower half) PS. Warped features are indicated by ``\_w''.}
\begin{tabular}{rrrrrrrrrrrr}
  \hline
ID & sex & race & age & purpose & amount & debt & purpose\_w & amount\_w & debt\_w & pred\_real & pred\_warped \\ 
  \hline
161752 &   0 &   0 &   0 &   1 & 55000 &   0 &   0 & 65000 &   1 & 0.41 & 0.85 \\ 
  36305 &   1 &   0 &   0 &   0 & 5000 &   1 &   0 & 15000 &   1 & 0.40 & 0.81 \\ 
  48557 &   1 &   0 &   0 &   0 & 5000 &   1 &   0 & 15000 &   1 & 0.40 & 0.81 \\ 
  115565 &   1 &   0 &   0 &   0 & 5000 &   1 &   0 & 15000 &   1 & 0.40 & 0.81 \\ 
  24102 &   0 &   0 &   0 &   1 & 35000 &   0 &   0 & 45000 &   0 & 0.33 & 0.72 \\ 
  46824 &   0 &   0 &   0 &   1 & 35000 &   0 &   0 & 45000 &   0 & 0.33 & 0.72 \\ 
    \hline
  10637 &   1 &   0 &   0 &   1 & 5000 &   0 &   0 & 15000 &   0 & 0.78 & 0.59 \\ 
  36864 &   1 &   0 &   0 &   1 & 5000 &   0 &   0 & 15000 &   0 & 0.78 & 0.59 \\ 
  28859 &   0 &   0 &   0 &   1 & 285000 &   0 &   0 & 305000 &   0 & 0.88 & 0.76 \\ 
  88227 &   0 &   0 &   0 &   1 & 285000 &   0 &   0 & 305000 &   0 & 0.88 & 0.76 \\ 
  92491 &   0 &   0 &   0 &   1 & 295000 &   0 &   0 & 305000 &   0 & 0.88 & 0.76 \\ 
  66283 &   0 &   0 &   0 &   1 & 5000 &   1 &   0 & 14840 &   1 & 0.82 & 0.70 \\ 
   \hline
\end{tabular}
\label{tab:app_wi-adapt}
\end{sidewaystable}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figs/privilege_score_plots_chimamanda_res_based_global_2025-01-14_14-21-00_wisconsin.pdf} 
    \caption{WI -- res-based -- Individuals with smallest (left) and largest (right) PS.}
    \label{fig:app-wi-psc}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figs/privilege_score_plots_chimamanda_fairadapt_global_2025-01-14_14-21-00_wisconsin.pdf} 
    \caption{WI -- fairadapt -- Individuals with smallest (left) and largest (right) PS.}
    \label{fig:app-wi-psc-adapt}
\end{figure}

%\clearpage

\begin{table}[ht]
\centering
\caption{WI -- res-based -- Linear Model Summary} 
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & -0.1287 & 0.0012 & -111.1744 & $<$ 1e-16 \\ 
  sex & 0.0018 & 0.0007 & 2.6610 & 0.0077935 \\ 
  race & 0.1019 & 0.0010 & 100.6884 & $<$ 1e-16 \\ 
  purpose & 0.0208 & 0.0007 & 28.1760 & $<$ 1e-16 \\ 
  amount & 0.0000 & 0.0000 & 12.2606 & $<$ 1e-16 \\ 
  debt & 0.0244 & 0.0007 & 36.8238 & $<$ 1e-16 \\ 
  age & 0.0002 & 0.0009 & 0.1831 & 0.8546931 \\ 
   \hline
\end{tabular}
\label{tab:lm_summary-wi-res}
\end{table}

\begin{table}[ht]
\centering
\caption{WI -- res-based -- Mean and quantiles ($\alpha=0.05$) of PS/PSC and PSC importance on test data} 
\begin{tabular}{lrrr}
  \hline
Feature & Mean & Quantiles $(\alpha, 1-\alpha)$ & Importance \\ 
  \hline
$\hp$ & -0.102 & (-0.446, 0.015) & -- \\ 
   $\priv_g$ & -0.011 & (-0.011, -0.011) & 0.011 \\ 
  $\priv_{\xv}$ & -0.111 & (-0.430, 0.080) & 0.140 \\ 
  $\gx[1]$ & -0.003 & (-0.063, 0.048) & 0.019 \\ 
  $\gx[2]$ & -0.005 & (0.000, 0.000) & 0.005 \\ 
  $\gx[3]$ & 0.028 & (0.000, 0.215) & 0.034 \\ 
   \hline
\end{tabular}
\label{tab:psc-wi-res}
\end{table}

%\paragraph{Fairadapt}

\begin{table}[ht]
\centering
\caption{WI -- fairadapt -- Linear Model Summary} 
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & -0.1186 & 0.0005 & -217.6119 & $<$ 1e-16 \\ 
  sex & 0.0025 & 0.0003 & 7.6500 & 2.0637e-14 \\ 
  race & 0.1088 & 0.0005 & 228.2564 & $<$ 1e-16 \\ 
  purpose & 0.0074 & 0.0003 & 21.2066 & $<$ 1e-16 \\ 
  amount & 0.0000 & 0.0000 & 23.8603 & $<$ 1e-16 \\ 
  debt & 0.0014 & 0.0003 & 4.5590 & 5.1585e-06 \\ 
  age & -0.0003 & 0.0004 & -0.7223 & 0.47009 \\ 
   \hline
\end{tabular}
\label{tab:lm-wi-adapt}
\end{table}

\begin{table}[ht]
\centering
\caption{WI -- fairadapt -- Mean and quantiles ($\alpha=0.05$) of PS/PSC and PSC importance on test data} 
\begin{tabular}{lrrr}
  \hline
Feature & Mean & Quantiles $(\alpha, 1-\alpha)$ & Importance \\ 
  \hline
$\hp$ & -0.109 & (-0.241, 0.012) &-- \\ 
   $\priv_g$ & -0.013 & (-0.013, -0.013) & 0.013 \\ 
  $\priv_{\xv}$ & -0.090 & (-0.168, -0.013) & 0.091 \\ 
  $\gx[1]$ & -0.012 & (-0.069, 0.024) & 0.021 \\ 
  $\gx[2]$ & -0.004 & (0.000, 0.000) & 0.004 \\ 
  $\gx[3]$ & 0.010 & (0.000, 0.123) & 0.013 \\ 
   \hline
\end{tabular}
\label{tab:psc-wi-fairadapt}
\end{table}

%\clearpage
\subsubsection{Results New York County}

Table \ref{tab:app_ny-res} shows the 6 individuals with the lowest PS and the 6 individuals with the highest PS for test data of NY using res-based warping. Figure \ref{fig:app-ny-psc} shows PSCs for these individuals.  
Table \ref{tab:lm_summary-ny-res} gives a model summary of regressing PS on real-world features.
Besides the above mentioned race effect of $0.04$ on the PS, we also see a significant -- but smaller and negative -- sex effect of $-0.01$. The age effect is also significantly non-zero. Table \ref{tab:psc-ny-res} shows the PS/PSC results.

Table \ref{tab:app_ny-adapt} shows the 6 individuals with the lowest PS and the 6 individuals with the highest PS for test data of NY using fairadapt. Figure \ref{fig:app-ny-psc-adapt} shows PSCs for these individuals. 
Table \ref{tab:lm-ny-adapt} exhibits similar sex, race, and age effects as for res-based warping.
Table \ref{tab:psc-ny-fairadapt} shows the PS/PSC results for fairadapt. Numbers are comparable to results of res-based warping.

\begin{sidewaystable}[ht!]
\centering
\caption{NY -- res-based -- Individuals with smallest (upper half) and largest (lower half) PS. Warped features are indicated by ``\_w''.}
\begin{tabular}{rrrrrrrrrrrr}
  \hline
ID & sex & race & age & purpose & amount & debt & purpose\_w & amount\_w & debt\_w & pred\_real & pred\_warped \\ 
  \hline
12337 &   0 &   0 &   1 &   0 & 15000 &   0 & -0.22 & -84770.46 &   0 & 0.32 & 0.87 \\ 
  14309 &   0 &   0 &   0 &   0 & 45000 &   0 & 0.00 & 28242.03 &   0 & 0.36 & 0.88 \\ 
  6148 &   0 &   0 &   1 &   0 & 105000 &   0 & -0.22 & 14388.93 &   0 & 0.39 & 0.88 \\ 
  2858 &   0 &   0 &   0 &   0 & 55000 &   0 & 0.00 & 38242.03 &   0 & 0.39 & 0.88 \\ 
  10703 &   0 &   0 &   0 &   0 & 55000 &   0 & 0.00 & 38242.03 &   0 & 0.39 & 0.88 \\ 
  2126 &   0 &   0 &   1 &   0 & 145000 &   0 & -0.22 & 61146.90 &   0 & 0.42 & 0.88 \\ 
    \hline
  7281 &   0 &   1 &   0 &   1 & 65000 &   1 & 1.00 & 65000.00 &   1 & 0.74 & 0.60 \\ 
  8532 &   0 &   1 &   0 &   1 & 75000 &   1 & 1.00 & 75000.00 &   1 & 0.77 & 0.64 \\ 
  1194 &   0 &   1 &   0 &   0 & 95000 &   1 & 0.00 & 95000.00 &   1 & 0.55 & 0.43 \\ 
  11907 &   0 &   1 &   0 &   0 & 85000 &   1 & 0.00 & 85000.00 &   1 & 0.53 & 0.43 \\ 
  12867 &   0 &   1 &   0 &   0 & 85000 &   1 & 0.00 & 85000.00 &   1 & 0.53 & 0.43 \\ 
  3302 &   0 &   0 &   1 &   0 & 225000 &   1 & -0.22 & 141146.90 &   1 & 0.75 & 0.65 \\ 
   \hline
\end{tabular}
\label{tab:app_ny-res}
\end{sidewaystable}

\begin{sidewaystable}[ht!]
\centering
\caption{NY -- fairadapt -- Individuals with smallest (upper half) and largest (lower half) PS. Warped features are indicated by ``\_w''.}
\begin{tabular}{rrrrrrrrrrrr}
  \hline
ID & sex & race & age & purpose & amount & debt & purpose\_w & amount\_w & debt\_w & pred\_real & pred\_warped \\ 
  \hline
6390 &   0 &   0 &   0 &   1 & 205000 &   0 &   1 & 214100.00 &   0 & 0.34 & 0.80 \\ 
  13730 &   0 &   0 &   0 &   1 & 205000 &   0 &   1 & 214100.00 &   0 & 0.34 & 0.80 \\ 
  4875 &   1 &   0 &   1 &   0 & 205000 &   0 &   0 & 205000.00 &   0 & 0.26 & 0.70 \\ 
  2501 &   0 &   0 &   0 &   0 & 205000 &   0 &   0 & 214100.00 &   1 & 0.35 & 0.77 \\ 
  4692 &   0 &   0 &   0 &   0 & 205000 &   0 &   0 & 214100.00 &   1 & 0.35 & 0.77 \\ 
  6518 &   0 &   0 &   0 &   0 & 205000 &   0 &   0 & 214100.00 &   1 & 0.35 & 0.77 \\ 
    \hline
  4791 &   1 &   0 &   1 &   0 & 85000 &   0 &   0 & 94740.00 &   0 & 0.64 & 0.42 \\ 
  8800 &   1 &   0 &   1 &   0 & 85000 &   0 &   0 & 94740.00 &   0 & 0.64 & 0.42 \\ 
  1896 &   1 &   0 &   0 &   0 & 95000 &   0 &   0 & 94840.00 &   0 & 0.63 & 0.42 \\ 
  7828 &   0 &   1 &   1 &   0 & 75000 &   1 &   0 & 75000.00 &   1 & 0.61 & 0.42 \\ 
  4392 &   0 &   0 &   0 &   0 & 95000 &   1 &   0 & 94840.00 &   1 & 0.62 & 0.43 \\ 
  11907 &   0 &   1 &   0 &   0 & 85000 &   1 &   0 & 85000.00 &   1 & 0.59 & 0.42 \\ 
   \hline
\end{tabular}
\label{tab:app_ny-adapt}
\end{sidewaystable}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figs/privilege_score_plots_chimamanda_res_based_global_2025-01-14_14-20-42_ny.pdf} 
    \caption{NY -- res-based -- Individuals with smallest (left) and largest (right) PS.}
    \label{fig:app-ny-psc}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{figs/privilege_score_plots_chimamanda_fairadapt_global_2025-01-14_14-20-42_ny.pdf} 
    \caption{NY -- fairadapt -- Individuals with smallest (left) and largest (right) PS.}
    \label{fig:app-ny-psc-adapt}
\end{figure}

%\clearpage

\begin{table}[ht]
\centering
\caption{NY -- res-based -- Linear Model Summary} 
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & -0.0733 & 0.0025 & -29.4392 & $<$ 1e-16 \\ 
  sex & -0.0124 & 0.0018 & -6.8114 & 1.1676e-11 \\ 
  race & 0.0432 & 0.0018 & 23.6297 & $<$ 1e-16 \\ 
  purpose & 0.0515 & 0.0019 & 27.6956 & $<$ 1e-16 \\ 
  amount & -0.0000 & 0.0000 & -0.4767 & 0.63357740 \\ 
  debt & 0.0158 & 0.0018 & 8.8364 & $<$ 1e-16 \\ 
  age & -0.0102 & 0.0028 & -3.7072 & 0.00021344 \\ 
   \hline
\end{tabular}
\label{tab:lm_summary-ny-res}
\end{table}

\begin{table}[ht]
\centering
\caption{NY -- res-based -- Mean and quantiles ($\alpha=0.05$) of PS/PSC and PSC importance on test data} 
\begin{tabular}{lrrr}
  \hline
 & Mean & Quantiles $(\alpha, 1-\alpha)$ & Importance \\ 
  \hline
$\hp$ & -0.039 & (-0.177, 0.019) & -- \\ 
   $\priv_g$ & -0.015 & (-0.015, -0.015) & 0.015 \\ 
  $\priv_{\xv}$ & -0.042 & (-0.131, 0.017) & 0.047 \\ 
  $\gx[1]$ & 0.001 & (-0.016, 0.022) & 0.009 \\ 
  $\gx[2]$ & 0.000 & (0.000, 0.000) & 0.000 \\ 
  $\gx[3]$ & 0.017 & (0.000, 0.094) & 0.017 \\ 
   \hline
\end{tabular}
\label{tab:psc-ny-res}
\end{table}

%\paragraph{Fairadapt}

\begin{table}[ht]
\centering
\caption{NY -- fairadapt -- Linear Model Summary} 
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & -0.0833 & 0.0033 & -24.8914 & $<$ 1e-16 \\ 
  sex & -0.0085 & 0.0024 & -3.4929 & 0.00048489 \\ 
  race & 0.0364 & 0.0025 & 14.8277 & $<$ 1e-16 \\ 
  purpose & 0.0445 & 0.0025 & 17.8217 & $<$ 1e-16 \\ 
  amount & 0.0000 & 0.0000 & 5.1142 & 3.353e-07 \\ 
  debt & 0.0323 & 0.0024 & 13.4780 & $<$ 1e-16 \\ 
  age & -0.0100 & 0.0037 & -2.6911 & 0.00716279 \\  
   \hline
\end{tabular}
\label{tab:lm-ny-adapt}
\end{table}

\begin{table}[ht]
\centering
\caption{NY -- fairadapt -- Mean and quantiles ($\alpha=0.05$) of PS/PSC and PSC importance on test data} 
\begin{tabular}{lrrr}
  \hline
Feature & Mean & Quantiles $(\alpha, 1-\alpha)$ & Importance \\ 
  \hline
$\hp$ & -0.037 & (-0.196, 0.041) & -- \\ 
   $\priv_g$ & -0.015 & (-0.015, -0.015) & 0.015 \\ 
  $\priv_{\xv}$ & -0.009 & (-0.136, 0.056) & 0.047 \\ 
  $\gx[1]$ & -0.010 & (-0.090, 0.031) & 0.025 \\ 
  $\gx[2]$ & -0.006 & (0.000, 0.000) & 0.006 \\ 
  $\gx[3]$ & 0.003 & (0.000, 0.000) & 0.003 \\ 
   \hline
\end{tabular}
\label{tab:psc-ny-fairadapt}
\end{table}
\clearpage




\subsection{Law School admission}
\label{app:sec:exp-real:law}

\subsubsection{Motivating example}
\label{app:sec:uc_aff}

\paragraph{Affirmative Action}


Bell, a female Person of Color, applies to law school and is rejected because her probability of successfully completing law school is predicted to be too low to accept her. Because Bell identifies as a member of a historically discriminated-against subgroup, Bell argues: ``If we lived in a fair world, free of sexism and racism, my educational history would have been different: I would have had access to better schools, a better learning environment, less financial worries, etc., resulting in a higher LSAT (law school admission test) score. To break the wheel of perpetuating this discrimination, I should be allowed to attend law school on a full scholarship because my PS is $-0.2$ with a $99\%$ confidence interval of $(-0.3,-0.13)$.'' As this is below the threshold set by the college, her admission is approved.

%
%For instance, an individual who is strongly discriminated against in the real world will have a large negative PS, while a person who benefits from the real world inequalities will have a positive PS.\footnote{The sign of the PS depends on the concrete definition of the PS and the choice of target encoding, see Section \ref{sec:formalization}.}
%
%In the college admissions example: Bell, a female person of color (PoC) who has faced multiple barriers in her educational career due to gender and racial discrimination, might have a higher likelihood of successfully completing law school in a world without gender and racial discrimination, i.e., she has a negative PS for the task of getting into law school.

\subsubsection{Data + Setup}

% \todo[inline]{update setup}

We analyze data on law school acceptance rates in the United States. The data come from a survey conducted by \citet{wightman_lasac_1998} and include information on 22,407 law students, ranging from their undergraduate grade point average (GPA), their Law School Admission Test (LSAT) scores, and their bar exam performance (a binary label indicating whether or not the student ultimately passed the bar)\footnote{We use a dataset version of the survey that is available at \url{https://www.kaggle.com/datasets/danofer/law-school-admissions-bar-passage}.}. Furthermore, the study records information on the students' gender and race which we both utilize as protected attributes in two separate evaluations. The reason for this is that current pre-processing methods are not yet able to account for multiple PAs. Future research should extend these to account for intersectionality. 

More precisely, we analyze the effect of gender and race in two isolated estimation setups. In each of the two setups, we assume the DAG presented in Figure \ref{fig:DAG_lawschool} where $A$ isit{Race}. Since the dataset contains information on various race groups, we recode the variable into a binary indicator where (0) stands for Black and (1) for Non-Black students (we consider the latter as the advantaged group). Similar to the simulation study, we compute confidence intervals using $B=100$ bootstrap samples with replacement. 
As we did not find relevant gender effects, we focus in describing results for PA \textit{Race} in the remainder.

% either \textit{Sex} ((0) for females (1) for males -- we consider the latter as the advantaged group) or
% We search for individuals who are eligible for affirmative action. 
% Table \ref{tab:law} shows individuals where the $95\%$-CI does not overlap with [-0.1,0.1] and who are hence eligible for affirmative action in this fictitious example. See Appendix \ref{app:sec:exp-real:law} for further results, used DAGs and warping models.

Since our outcome variable (whether or not a student passes the bar examination) is binary, we use a random forest classifier for prediction. We split the data in $80\%$ training and $20\%$ test data, tune hyperparameters with 3-fold CV and random search with 25 evaluations on the training data, and report metrics on the test set. We report summary statistics of the data set in Table \ref{tab:lawschool_sumstats}.

% \begin{figure}[ht]
%     \centering
%     \begin{tikzpicture}[x=3in, y=4in] % Adjusted scaling
%         \node[ellipse, draw] (v0) at (0.5,-0.6) {UGPA}; % Age in the middle, above others
%         \node[ellipse, draw] (v2) at (0.1,-0.7) {A};
%         \node[ellipse, draw] (v4) at (0.9,-0.7) {Pass Bar};
%         \node[ellipse, draw] (v6) at (0.5,-0.8) {LSAT}; % New node between Gender and Mortgage
%         \draw [->] (v0) edge (v4);
%         \draw [dotted, ->] (v2) edge (v0); 
%         \draw [dotted, ->] (v2) edge (v6); 
%         \draw [->] (v6) edge (v4); 
%         \draw [dashed, ->] (v2) edge (v4); % Dashed arrow from Gender to Mortgage (direct)
%     \end{tikzpicture}
%     \caption{DAG used for the Law School dataset. $A$ represents the protected attribute which is \textit{Race} in our case.}
%     \label{fig:DAG_lawschool}
% \end{figure}


\begin{table}[!h] % table-ID: LS-SumStats
    \centering
    \caption{Summary statistics for Lawschool data}
    \label{tab:lawschool_sumstats}
    \resizebox{\ifdim\width>\linewidth\linewidth\else\width\fi}{!}{
    \begin{tabular}{lccccccccc}
        \toprule
        \multicolumn{1}{c}{ } & \multicolumn{3}{c}{All} & \multicolumn{3}{c}{Non-Black} & \multicolumn{3}{c}{Black} \\
        \cmidrule(l{3pt}r{3pt}){2-4} \cmidrule(l{3pt}r{3pt}){5-7} \cmidrule(l{3pt}r{3pt}){8-10}
        Variable & n & mean & std. dev. & n & mean & std. dev. & n & mean & std. dev.\\
        \midrule
        lsat & 22407 & 36.768 & 5.463 & 21064 & 37.234 & 5.095 & 1343 & 29.459 & 5.830\\
        pass\_bar & 22407 & 0.948 & 0.222 & 21064 & 0.959 & 0.199 & 1343 & 0.778 & 0.416\\
        ugpa & 22407 & 3.215 & 0.404 & 21064 & 3.236 & 0.394 & 1343 & 2.890 & 0.428\\
        \bottomrule
    \end{tabular}}
\end{table}

\subsubsection{Results Law School}

Res-based warping: Table \ref{tab:lm_summary-law-res-race} gives a model summary of regressing PS on real-world features.
Besides the a race effect of $0.12$ on the PS, we also see significant -- but smaller -- UGPA and LSAT effects of $0.006$ and $0.003$, respectively. 
Table \ref{tab:psc-law-res-race} shows the PS/PSC results.
Table \ref{tab:lawschool_res-worst} shows the 6 individuals with the lowest PS and the 6 individuals with the highest PS for test data. Figure \ref{fig:lawschool_resbased_psc} shows PSCs for these individuals.  

Fairadapt: Table \ref{tab:lm_summary-law-adapt-race} exhibits similar  effects as for res-based warping with the difference that the UGPA effect is not significant.
Table \ref{tab:psc-law-adapt-race} shows the PS/PSC results for fairadapt. Numbers are comparable to results of res-based warping.
Table \ref{tab:lawschool_adapt-worst} shows the 6 individuals with the lowest PS and the 6 individuals with the highest PS for test data. Figure \ref{fig:lawschool_fairadapt_psc} shows PSCs for these individuals. 

\begin{table}[ht] % table-ID: R-LS-linreg-resbased-table-race
    \centering
    \caption{Law School -- res-based -- Linear Model Summary}
    \begin{tabular}{lcccc}
        \hline
        & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
        \hline
(Intercept) & -0.2679 & 0.0041 & -64.7163 & $<$ 1e-16 \\ 
  race & 0.1198 & 0.0019 & 62.7812 & $<$ 1e-16 \\ 
  ugpa & 0.0064 & 0.0011 & 5.7499 & 9.5245e-09 \\ 
  lsat & 0.0034 & 0.0001 & 39.1490 & $<$ 1e-16 \\ 
   \hline
    \end{tabular} 
    \label{tab:lm_summary-law-res-race}
\end{table}


\begin{table}[ht] % table-ID: R-LS-psc-resbased-table-race
    \centering
    \caption{Law School -- res-based -- Mean and quantiles ($\alpha=0.05$) of PS/PSC and PSC importance on test data} 
    \begin{tabular}{lccc}
        \hline
        Feature & Mean & Quantiles $(\alpha, 1-\alpha)$ & Importance \\ 
        \hline
$\hp$ & -0.149 & (-0.403, 0.006) & -- \\ 
   $\priv_g$ & -0.005 & (-0.005, -0.005) & 0.005 \\ 
  $\priv_{\xv}$ & -0.010 & (-0.086, 0.018) & 0.026 \\ 
  $\gx[1]$ & -0.022 & (-0.052, 0.002) & 0.023 \\ 
  $\gx[2]$ & -0.111 & (-0.285, -0.001) & 0.111 \\ 
   \hline
    \end{tabular}
    \label{tab:psc-law-res-race}
\end{table}

\begin{table}[ht] % table-ID: R-LS-linreg-fairadapt-table-race
    \centering
    \caption{Law School -- fairadapt -- Linear Model Summary} 
    \begin{tabular}{lcccc}
        \hline
        & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
        \hline
(Intercept) & -0.2545 & 0.0040 & -64.2376 & $<$ 1e-16 \\ 
  race & 0.1341 & 0.0018 & 73.4207 & $<$ 1e-16 \\ 
  ugpa & 0.0002 & 0.0011 & 0.1656 & 0.86844 \\ 
  lsat & 0.0032 & 0.0001 & 38.7135 & $<$ 1e-16 \\ 
   \hline
    \end{tabular}
    \label{tab:lm_summary-law-adapt-race}
\end{table}


\begin{table}[ht] % table-ID: R-LS-psc-fairadapt-table-race
    \centering
    \caption{Law School -- fairadapt -- Mean and quantiles ($\alpha=0.05$) of PS/PSC and PSC importance on test data} 
    \begin{tabular}{lccc}
        \hline
        Feature & Mean & Quantiles $(\alpha, 1-\alpha)$ & Importance \\ 
        \hline
$\hp$ & -0.159 & (-0.402, -0.020) & -- \\ 
   $\priv_g$ & -0.005 & (-0.005, -0.005) & 0.005 \\ 
  $\priv_{\xv}$ & -0.018 & (-0.068, 0.018) & 0.023 \\ 
  $\gx[1]$ & -0.022 & (-0.049, 0.004) & 0.023 \\ 
  $\gx[2]$ & -0.115 & (-0.292, -0.000) & 0.115 \\ 
   \hline
    \end{tabular}
    \label{tab:psc-law-adapt-race}
\end{table}




\begin{figure}[ht] % plot-ID: R-LS-bottomtop-psc-resbased-plot-race
    \centering
    \includegraphics[width=1\textwidth]{figs/privilege_score_plots_chimamanda_res_based_global_2025-01-30_10-39-08.pdf} 
    \caption{PS Contribution for the Lawschool data with \textit{Race} as the protected attribute and computed using res-based warping with  bootstrap intervals using $\alpha=0.1$. Individuals with smallest (left) and largest (right) PS.}
    \label{fig:lawschool_resbased_psc}
\end{figure}

\begin{figure}[ht] % plot-ID: R-LS-bottomtop-psc-fairadapt-plot-race
    \centering
    \includegraphics[width=1\textwidth]{figs/privilege_score_plots_chimamanda_fairadapt_global_2025-01-30_11-11-18.pdf} 
    \caption{PS Contribution for the Lawschool data with \textit{Race} as the protected attribute and computed using fairadapt warping with  bootstrap intervals using $\alpha=0.1$. Individuals with smallest (left) and largest (right) PS.}
    \label{fig:lawschool_fairadapt_psc}
\end{figure}


\begin{table}[ht!] % table-ID: R-LS-bottomtop-psc-fairadapt-table-race
    \centering
        \caption{Lawschool -- res-based -- Individuals with smallest (upper half) and largest (lower half) PS. Warped features are indicated by ``\_w''.}
            \label{tab:lawschool_res-worst}
\begin{tabular}{rrrrrrrrr}
      \hline
    ID & race & ugpa & lsat & pred\_real & ugpa\_w & lsat\_w & pred\_warped \\ 
      \hline
    16403 & 0 & 2.0 & 21.0 & 0.3172 & 2.2 & 29.0 & 0.8990 \\
    17609 & 0 & 2.2 & 20.5 & 0.3408 & 2.5 & 29.0 & 0.8994 \\
    22647 & 0 & 2.4 & 20.3 & 0.3753 & 2.7 & 29.0 & 0.9040 \\
    14664 & 0 & 2.6 & 19.5 & 0.4202 & 3.0 & 27.3 & 0.9316 \\
    25750 & 0 & 2.2 & 20.7 & 0.3946 & 2.5 & 29.0 & 0.8994 \\
    20356 & 0 & 2.5 & 17.0 & 0.3175 & 2.9 & 24.0 & 0.8191 \\
        \hline
    25704 & 1 & 2.5 & 23.0 & 0.6526 & 2.5 & 23.0 & 0.6073 \\
    14793 & 1 & 2.2 & 22.7 & 0.4826 & 2.2 & 22.7 & 0.4568 \\
    2622  & 1 & 2.9 & 46.0 & 0.9786 & 2.9 & 46.0 & 0.9625 \\
    9502  & 1 & 2.9 & 47.0 & 0.9786 & 2.9 & 47.0 & 0.9625 \\
    9722  & 1 & 2.9 & 46.0 & 0.9786 & 2.9 & 46.0 & 0.9625 \\
    13141 & 1 & 2.9 & 48.0 & 0.9786 & 2.9 & 48.0 & 0.9625 \\
    \hline
\end{tabular}
\end{table}


\begin{table}[ht!] % table-ID: R-LS-bottomtop-psc-fairadapt-table-race
    \centering
        \caption{Lawschool - fairadapt -- Individuals with smallest (upper half) and largest (lower half) PS. Warped features are indicated by ``\_w''.}
         \label{tab:lawschool_adapt-worst}
\begin{tabular}{rrrrrrrrr}
      \hline
    ID & race & ugpa & lsat & pred\_real & ugpa\_w & lsat\_w & pred\_warped \\ 
      \hline
    16403 & 0 & 2.0 & 21.0 & 0.3367 & 2.1994 & 30.5000 & 0.9413 \\
    3475  & 0 & 2.1 & 15.0 & 0.2058 & 2.4000 & 23.9982 & 0.7899 \\
    14664 & 0 & 2.6 & 19.5 & 0.4328 & 3.0000 & 28.0000 & 0.9364 \\
    26169 & 0 & 2.6 & 18.0 & 0.4340 & 3.0000 & 27.0000 & 0.9292 \\
    25259 & 0 & 3.0 & 20.0 & 0.4648 & 3.4000 & 29.5000 & 0.9145 \\
    10215 & 0 & 2.7 & 18.0 & 0.4775 & 3.2000 & 27.0000 & 0.9236 \\
    \hline
    12300 & 1 & 2.5 & 41.0 & 0.9451 & 2.5000 & 41.0000 & 0.9281 \\
    17365 & 1 & 2.5 & 41.0 & 0.9451 & 2.5000 & 41.0000 & 0.9281 \\
    22509 & 1 & 2.5 & 41.0 & 0.9451 & 2.5000 & 41.0000 & 0.9281 \\
    24550 & 1 & 2.5 & 41.0 & 0.9451 & 2.5000 & 41.0000 & 0.9281 \\
    1070  & 1 & 2.9 & 39.0 & 0.9687 & 2.9000 & 39.0000 & 0.9525 \\
    6508  & 1 & 2.9 & 39.0 & 0.9687 & 2.9000 & 39.0000 & 0.9525 \\
    \hline
\end{tabular}
\end{table}


\end{document}
