[
  {
    "index": 0,
    "papers": [
      {
        "key": "attentionisallyouneed",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \\L ukasz and Polosukhin, Illia",
        "title": "Attention is All you Need"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "devlin-etal-2019-bert",
        "author": "Devlin, Jacob  and\nChang, Ming-Wei  and\nLee, Kenton  and\nToutanova, Kristina",
        "title": "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "beltagy2019scibert",
        "author": "Beltagy, Iz  and\nLo, Kyle  and\nCohan, Arman",
        "title": "{S}ci{BERT}: A Pretrained Language Model for Scientific Text"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "biobert",
        "author": "Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo",
        "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"
      },
      {
        "key": "song-etal-2023-matsci",
        "author": "Song, Yu  and\nMiret, Santiago  and\nLiu, Bang",
        "title": "{M}at{S}ci-{NLP}: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling"
      },
      {
        "key": "rostam2024finetuninglargelanguagemodels",
        "author": "Zhyar Rzgar K Rostam and G\u00e1bor Kert\u00e9sz",
        "title": "Fine-Tuning Large Language Models for Scientific Text Classification: A Comparative Study"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "singh-etal-2023-scirepeval",
        "author": "Singh, Amanpreet  and\nD{'}Arcy, Mike  and\nCohan, Arman  and\nDowney, Doug  and\nFeldman, Sergey",
        "title": "{S}ci{R}ep{E}val: A Multi-Format Benchmark for Scientific Document Representations"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "rostam2024finetuninglargelanguagemodels",
        "author": "Zhyar Rzgar K Rostam and G\u00e1bor Kert\u00e9sz",
        "title": "Fine-Tuning Large Language Models for Scientific Text Classification: A Comparative Study"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "summarization",
        "author": "Sefid, Athar\nand Giles, C. Lee",
        "title": "SciBERTSUM: Extractive Summarization for\u00a0Scientific Documents"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "biobert",
        "author": "Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo",
        "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"
      },
      {
        "key": "pubmedbert",
        "author": "Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung",
        "title": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "abdelmageed2023biodivbert",
        "author": "Abdelmageed, Nora and L{\\\"o}ffler, Felicitas and K{\\\"o}nig-Ries, Birgitta",
        "title": "BiodivBERT: a Pre-Trained Language Model for the Biodiversity Domain."
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "radford2019language",
        "author": "Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others",
        "title": "Language models are unsupervised multitask learners"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "touvron2023llama2openfoundation",
        "author": "Hugo Touvron and others",
        "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "Rettenberger",
        "author": "Luca Rettenberger and Marc F. M\u00fcnker and Mark Schutera and Christof M. Niemeyer and Kersten S. Rabe and Markus Reischl",
        "title": "Using Large Language Models for Extracting Structured Information From Scientific Texts"
      },
      {
        "key": "dagdelen2024structured",
        "author": "Dagdelen, John and Dunn, Alexander and Lee, Sanghoon and Walker, Nicholas and Rosen, Andrew S and Ceder, Gerbrand and Persson, Kristin A and Jain, Anubhav",
        "title": "Structured information extraction from scientific text with large language models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "huang2024critical",
        "author": "Huang, Jingwei and Yang, Donghan M and Rong, Ruichen and Nezafati, Kuroush and Treager, Colin and Chi, Zhikai and Wang, Shidan and Cheng, Xian and Guo, Yujia and Klesse, Laura J and others",
        "title": "A critical assessment of using ChatGPT for extracting structured data from clinical notes"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "choi2024accelerating",
        "author": "Choi, Jaewoong and Lee, Byungju",
        "title": "Accelerating materials language processing with large language models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "dataset",
        "author": "Pan, Huitong and Zhang, Qi and Dragut, Eduard and Caragea, Cornelia and Latecki, Longin Jan",
        "title": "DMDD: A Large-Scale Dataset for Dataset Mentions Detection"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "zhang-etal-2024-scier",
        "author": "Zhang, Qi  and\nChen, Zhijia  and\nPan, Huitong  and\nCaragea, Cornelia  and\nLatecki, Longin Jan  and\nDragut, Eduard",
        "title": "{S}ci{ER}: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "jain-etal-2020-scirex",
        "author": "Jain, Sarthak  and\nvan Zuylen, Madeleine  and\nHajishirzi, Hannaneh  and\nBeltagy, Iz",
        "title": "{S}ci{REX}: {A} Challenge Dataset for Document-Level Information Extraction"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "deyoung-etal-2021-ms",
        "author": "DeYoung, Jay  and\nBeltagy, Iz  and\nvan Zuylen, Madeleine  and\nKuehl, Bailey  and\nWang, Lucy Lu",
        "title": "{MS}\\^{}2: Multi-Document Summarization of Medical Studies"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "brinner-etal-2022-linking",
        "author": "Brinner, Marc  and\nHeger, Tina  and\nZarriess, Sina",
        "title": "Linking a Hypothesis Network From the Domain of Invasion Biology to a Corpus of Scientific Abstracts: The {INAS} Dataset"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "barcodebert",
        "author": "Pablo Millan Arias and Niousha Sadjadi and Monireh Safari and ZeMing Gong and Austin T. Wang and Scott C. Lowe and Joakim Bruslund Haurum and Iuliia Zarubiieva and Dirk Steinke and Lila Kari and Angel X. Chang and Graham W. Taylor",
        "title": "BarcodeBERT: Transformers for Biodiversity Analysis"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "abdelmageed2023biodivbert",
        "author": "Abdelmageed, Nora and L{\\\"o}ffler, Felicitas and K{\\\"o}nig-Ries, Birgitta",
        "title": "BiodivBERT: a Pre-Trained Language Model for the Biodiversity Domain."
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "weakClaims",
        "author": "Brinner, Marc\nand Zarrie{\\ss}, Sina\nand Heger, Tina",
        "title": "Weakly Supervised Claim Localization in Scientific Abstracts"
      },
      {
        "key": "brinner-zarriess-2024-rationalizing",
        "author": "Brinner, Marc Felix  and\nZarrie{\\ss}, Sina",
        "title": "Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "biodiversity_LLM",
        "author": "Jiqi Gu, Jianping Chen, Jiangshan Lai",
        "title": "Application of large language models in biodiversity research"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "structuredExtractionEcology",
        "author": "Andry Castro and Jo\u00e3o Pinto and Lu\u00eds Reino and Pavel Pipek and C\u00e9sar Capinha",
        "title": "Large language models overcome the challenges of unstructured text data in ecology"
      },
      {
        "key": "infoextractBiodiv",
        "author": "Vamsi Krishna Kommineni and Waqas Ahmed and Birgitta Koenig-Ries and Sheeba Samuel",
        "title": "Automating Information Retrieval from Biodiversity Literature Using Large Language Models: A Case Study"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "osawa2023role",
        "author": "Osawa, T and Tsutsumida, N and others",
        "title": "The role of large language models in ecology and biodiversity conservation: Opportunities and Challenges"
      }
    ]
  }
]