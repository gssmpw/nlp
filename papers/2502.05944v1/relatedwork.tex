\section{Related Work}
\subsection{Large Language Models}
Deep learning has achieved remarkable results in computer vision \cite{wang2024insectmamba} and natural language processing, such as large language models.
Large language models (LLMs) have become a cornerstone of modern natural language processing, showcasing remarkable capabilities in various tasks such as text generation, translation, and reasoning \cite{zhou2022claret}. The scalability of these models, achieved by increasing the number of parameters and training on massive datasets, has enabled them to generalize across diverse domains and tasks \cite{nicholas2023lost,zhou2024rethinking,muller2022cedille,zhou2025training}.

Recent studies have explored the multilingual capabilities of LLMs, addressing the challenges faced by non-English and low-resource languages. While multilingual models have demonstrated strong generalization across languages, their performance often lags behind monolingual models for specific tasks, particularly for low-resource languages \cite{chang2024goldfish,ojo2023african}. To address these limitations, domain-specific models have been developed, such as Cedille, which focuses on the French language and outperforms multilingual counterparts on French-specific benchmarks \cite{muller2022cedille}.

LLMs have also shown promise beyond conventional NLP tasks. For example, they have been applied to specialized domains such as bioinformatics and medical image registration, leveraging their ability to encode complex patterns from structured and unstructured data \cite{liu2024bioinformatics,ma2024llama}. These applications highlight the versatility of LLMs in solving domain-specific challenges and advancing fields beyond language processing.

Despite their success, LLMs face criticism regarding their suitability as comprehensive models of human linguistic understanding. Some argue that LLMs excel at modeling language but fall short of representing cognitive or social aspects of human language \cite{veres2022precis,grindrod2024modelling}. This has sparked discussions on the limitations and potential biases of LLMs, particularly in psycholinguistics and their use as tools for scientific inquiry \cite{houghton2023psycholinguistics}.
Large language models demonstrate strong scalability in in-context leanring \cite{zhou2024visual}, and existing work has also demonstrated that they can be improved through the guidance of weak models \cite{zhou2025weak}.

\subsection{Multi-hop Question Answering}

Multi-hop question answering (QA) tasks require a model to retrieve and integrate information from multiple sources to answer complex questions. This type of reasoning often involves multiple steps and connections across diverse pieces of evidence, making it a critical area of research in natural language processing. Recent advances in this field have introduced methods that address various challenges, such as improving retrieval accuracy, handling diverse answer types, and ensuring reasoning consistency \cite{balepur2024reverse,amouyal2022qampari}.

A significant challenge in multi-hop QA lies in the ability of models to decompose complex questions into intermediate sub-questions, a skill that mirrors human reasoning. Research has shown that many state-of-the-art systems can answer multi-hop questions without fully understanding the intermediate reasoning paths, relying instead on partial clues from the dataset \cite{tang2020subquestions}. Methods that explicitly generate and answer sub-questions have demonstrated improved interpretability and robustness in these tasks \cite{wang2022covqa}.

Another line of work has focused on developing benchmarks and datasets to evaluate multi-hop QA systems. These benchmarks, such as QAMPARI, are specifically designed to include questions that require reasoning over multiple paragraphs or sources, providing a more realistic assessment of multi-hop capabilities \cite{amouyal2022qampari}. Similarly, work on dataset generation has explored methods to automatically create conversational multi-hop QA datasets with revised answers for consistency \cite{hwang2022conversational}.

Recent approaches have also explored the use of advanced neural architectures and knowledge-enhanced mechanisms. For instance, incorporating context information such as entity types and relational connections has been shown to improve the selection of relevant evidence and enhance model performance on simple and multi-hop questions \cite{chao2018context}. Furthermore, multi-hop QA has been applied to domains such as visual question answering and community question answering, highlighting its versatility and expanding its application scope \cite{hu2023qan,zhang2020product}.

In summary, the field of multi-hop QA has seen substantial progress, with efforts focused on improving reasoning mechanisms, developing robust evaluation benchmarks, and exploring applications in diverse domains. However, challenges such as reasoning consistency, scalability, and handling noisy or incomplete evidence remain open areas for further exploration.