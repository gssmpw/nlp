@article{bao2024vidu,
  title={Vidu: a highly consistent, dynamic and skilled text-to-video generator with diffusion models},
  author={Bao, Fan and Xiang, Chendong and Yue, Gang and He, Guande and Zhu, Hongzhou and Zheng, Kaiwen and Zhao, Min and Liu, Shilong and Wang, Yaole and Zhu, Jun},
  journal={arXiv preprint arXiv:2405.04233},
  year={2024}
}

@article{blattmann2023stable,
  title   = {Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets},
  author  = {Andreas Blattmann and Tim Dockhorn and Sumith Kulal and Daniel Mendelevitch and Maciej Kilian and Dominik Lorenz and Yam Levi and Zion English and Vikram Voleti and Adam Letts and Varun Jampani and Robin Rombach},
  year    = {2023},
  journal = {NONE}
}

@misc{bloc97,
    title = {{NTK-Aware Scaled RoPE allows LLaMA models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation.}},
    author = {bloc97},
    url = "https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/ntkaware_scaled_rope_allows_llama_models_to_have/",
    year = 2023
}

@article{chen2023extending,
  title={Extending context window of large language models via positional interpolation},
  author={Chen, Shouyuan and Wong, Sherman and Chen, Liangjian and Tian, Yuandong},
  journal={arXiv preprint arXiv:2306.15595},
  year={2023}
}

@misc{chen2023videocrafter1,
      title={VideoCrafter1: Open Diffusion Models for High-Quality Video Generation}, 
      author={Haoxin Chen and Menghan Xia and Yingqing He and Yong Zhang and Xiaodong Cun and Shaoshu Yang and Jinbo Xing and Yaofang Liu and Qifeng Chen and Xintao Wang and Chao Weng and Ying Shan},
      year={2023},
      eprint={2310.19512},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{chen2024videocrafter2,
      title={VideoCrafter2: Overcoming Data Limitations for High-Quality Video Diffusion Models}, 
      author={Haoxin Chen and Yong Zhang and Xiaodong Cun and Menghan Xia and Xintao Wang and Chao Weng and Ying Shan},
      year={2024},
      eprint={2401.09047},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{chen2025ouroboros,
  title={Ouroboros-Diffusion: Exploring Consistent Content Generation in Tuning-free Long Video Diffusion},
  author={Chen, Jingyuan and Long, Fuchen and An, Jie and Qiu, Zhaofan and Yao, Ting and Luo, Jiebo and Mei, Tao},
  journal={arXiv preprint arXiv:2501.09019},
  year={2025}
}

@article{ding2024longrope,
  title={Longrope: Extending llm context window beyond 2 million tokens},
  author={Ding, Yiran and Zhang, Li Lyna and Zhang, Chengruidong and Xu, Yuanyuan and Shang, Ning and Xu, Jiahang and Yang, Fan and Yang, Mao},
  journal={arXiv preprint arXiv:2402.13753},
  year={2024}
}

@misc{genmo2024mochi,
      title={Mochi 1},
      author={Genmo Team},
      year={2024},
      publisher = {GitHub},
      journal = {GitHub repository},
      howpublished={\url{https://github.com/genmoai/models}}
}

@article{he2022lvdm,
      title={Latent Video Diffusion Models for High-Fidelity Long Video Generation}, 
      author={Yingqing He and Tianyu Yang and Yong Zhang and Ying Shan and Qifeng Chen},
      year={2022},
      eprint={2211.13221},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{ho2022imagen,
  title   = {Imagen Video: High Definition Video Generation with Diffusion Models},
  author  = {Jonathan Ho and William Chan and Chitwan Saharia and Jay Whang and Ruiqi Gao and Alexey Gritsenko and Diederik P. Kingma and Ben Poole and Mohammad Norouzi and David J. Fleet and Tim Salimans},
  year    = {2022},
  journal = {arXiv preprint arXiv: 2210.02303}
}

@article{kong2024hunyuanvideo,
  title={HunyuanVideo: A Systematic Framework For Large Video Generative Models},
  author={Kong, Weijie and Tian, Qi and Zhang, Zijian and Min, Rox and Dai, Zuozhuo and Zhou, Jin and Xiong, Jiangfeng and Li, Xin and Wu, Bo and Zhang, Jianwei and others},
  journal={arXiv preprint arXiv:2412.03603},
  year={2024}
}

@article{li2024arlon,
  title   = {ARLON: Boosting Diffusion Transformers with Autoregressive Models for Long Video Generation},
  author  = {Zongyi Li and Shujie Hu and Shujie Liu and Long Zhou and Jeongsoo Choi and Lingwei Meng and Xun Guo and Jinyu Li and Hefei Ling and Furu Wei},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.20502}
}

@article{lin2023videodirectorgpt,
  title   = {VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning},
  author  = {Han Lin and Abhay Zala and Jaemin Cho and Mohit Bansal},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2309.15091}
}

@article{lin2024open,
  title={Open-Sora Plan: Open-Source Large Video Generation Model},
  author={Lin, Bin and Ge, Yunyang and Cheng, Xinhua and Li, Zongjian and Zhu, Bin and Wang, Shaodong and He, Xianyi and Ye, Yang and Yuan, Shenghai and Chen, Liuhan and others},
  journal={arXiv preprint arXiv:2412.00131},
  year={2024}
}

@article{lu2024freelong,
  title={Freelong: Training-free long video generation with spectralblend temporal attention},
  author={Lu, Yu and Liang, Yuanzhi and Zhu, Linchao and Yang, Yi},
  journal={arXiv preprint arXiv:2407.19918},
  year={2024}
}

@article{nvidia2025cosmos,
  title   = {Cosmos World Foundation Model Platform for Physical AI},
  author  = {NVIDIA and : and Niket Agarwal and Arslan Ali and Maciej Bala and Yogesh Balaji and Erik Barker and Tiffany Cai and Prithvijit Chattopadhyay and Yongxin Chen and Yin Cui and Yifan Ding and Daniel Dworakowski and Jiaojiao Fan and Michele Fenzi and Francesco Ferroni and Sanja Fidler and Dieter Fox and Songwei Ge and Yunhao Ge and Jinwei Gu and Siddharth Gururani and Ethan He and Jiahui Huang and Jacob Huffman and Pooya Jannaty and Jingyi Jin and Seung Wook Kim and Gergely Kl√°r and Grace Lam and Shiyi Lan and Laura Leal-Taixe and Anqi Li and Zhaoshuo Li and Chen-Hsuan Lin and Tsung-Yi Lin and Huan Ling and Ming-Yu Liu and Xian Liu and Alice Luo and Qianli Ma and Hanzi Mao and Kaichun Mo and Arsalan Mousavian and Seungjun Nah and Sriharsha Niverty and David Page and Despoina Paschalidou and Zeeshan Patel and Lindsey Pavao and Morteza Ramezanali and Fitsum Reda and Xiaowei Ren and Vasanth Rao Naik Sabavat and Ed Schmerling and Stella Shi and Bartosz Stefaniak and Shitao Tang and Lyne Tchapmi and Przemek Tredak and Wei-Cheng Tseng and Jibin Varghese and Hao Wang and Haoxiang Wang and Heng Wang and Ting-Chun Wang and Fangyin Wei and Xinyue Wei and Jay Zhangjie Wu and Jiashu Xu and Wei Yang and Lin Yen-Chen and Xiaohui Zeng and Yu Zeng and Jing Zhang and Qinsheng Zhang and Yuxuan Zhang and Qingqing Zhao and Artur Zolkowski},
  year    = {2025},
  journal = {arXiv preprint arXiv: 2501.03575}
}

@article{peng2023yarn,
  title={Yarn: Efficient context window extension of large language models},
  author={Peng, Bowen and Quesnelle, Jeffrey and Fan, Honglu and Shippole, Enrico},
  journal={International Conference on Learning Representations.},
  year={2023}
}

@article{polyak2024movie,
  title   = {Movie Gen: A Cast of Media Foundation Models},
  author  = {Adam Polyak and Amit Zohar and Andrew Brown and Andros Tjandra and Animesh Sinha and Ann Lee and Apoorv Vyas and Bowen Shi and Chih-Yao Ma and Ching-Yao Chuang and David Yan and Dhruv Choudhary and Dingkang Wang and Geet Sethi and Guan Pang and Haoyu Ma and Ishan Misra and Ji Hou and Jialiang Wang and Kiran Jagadeesh and Kunpeng Li and Luxin Zhang and Mannat Singh and Mary Williamson and Matt Le and Matthew Yu and Mitesh Kumar Singh and Peizhao Zhang and Peter Vajda and Quentin Duval and Rohit Girdhar and Roshan Sumbaly and Sai Saketh Rambhatla and Sam Tsai and Samaneh Azadi and Samyak Datta and Sanyuan Chen and Sean Bell and Sharadh Ramaswamy and Shelly Sheynin and Siddharth Bhattacharya and Simran Motwani and Tao Xu and Tianhe Li and Tingbo Hou and Wei-Ning Hsu and Xi Yin and Xiaoliang Dai and Yaniv Taigman and Yaqiao Luo and Yen-Cheng Liu and Yi-Chiao Wu and Yue Zhao and Yuval Kirstain and Zecheng He and Zijian He and Albert Pumarola and Ali Thabet and Artsiom Sanakoyeu and Arun Mallya and Baishan Guo and Boris Araya and Breena Kerr and Carleigh Wood and Ce Liu and Cen Peng and Dimitry Vengertsev and Edgar Schonfeld and Elliot Blanchard and Felix Juefei-Xu and Fraylie Nord and Jeff Liang and John Hoffman and Jonas Kohler and Kaolin Fire and Karthik Sivakumar and Lawrence Chen and Licheng Yu and Luya Gao and Markos Georgopoulos and Rashel Moritz and Sara K. Sampson and Shikai Li and Simone Parmeggiani and Steve Fine and Tara Fowler and Vladan Petrovic and Yuming Du},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.13720}
}

@misc{qiu2023freenoise,
      title={FreeNoise: Tuning-Free Longer Video Diffusion Via Noise Rescheduling}, 
      author={Haonan Qiu and Menghan Xia and Yong Zhang and Yingqing He and Xintao Wang and Ying Shan and Ziwei Liu},
      year={2023},
      eprint={2310.15169},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

@article{videoworldsimulators2024,
  title={Video generation models as world simulators},
  author={Tim Brooks and Bill Peebles and Connor Holmes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Ng and Ricky Wang and Aditya Ramesh},
  year={2024},
  url={https://openai.com/research/video-generation-models-as-world-simulators},
}

@article{wang2023genlvideo,
  title   = {Gen-L-Video: Multi-Text to Long Video Generation via Temporal Co-Denoising},
  author  = {Fu-Yun Wang and Wenshuo Chen and Guanglu Song and Han-Jia Ye and Yu Liu and Hongsheng Li},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2305.18264}
}

@article{wang2024lingen,
  title   = {LinGen: Towards High-Resolution Minute-Length Text-to-Video Generation with Linear Computational Complexity},
  author  = {Hongjie Wang and Chih-Yao Ma and Yen-Cheng Liu and Ji Hou and Tao Xu and Jialiang Wang and Felix Juefei-Xu and Yaqiao Luo and Peizhao Zhang and Tingbo Hou and Peter Vajda and Niraj K. Jha and Xiaoliang Dai},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2412.09856}
}

@article{wang2024loong,
  title   = {Loong: Generating Minute-level Long Videos with Autoregressive Language Models},
  author  = {Yuqing Wang and Tianwei Xiong and Daquan Zhou and Zhijie Lin and Yang Zhao and Bingyi Kang and Jiashi Feng and Xihui Liu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.02757}
}

@article{xing2023dynamicrafter,
      title={DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors}, 
      author={Jinbo Xing and Menghan Xia and Yong Zhang and Haoxin Chen and Xintao Wang and Tien-Tsin Wong and Ying Shan},
      year={2023},
      eprint={2310.12190},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{yan2024long,
  title={Long Video Diffusion Generation with Segmented Cross-Attention and Content-Rich Video Data Curation},
  author={Yan, Xin and Cai, Yuxuan and Wang, Qiuyue and Zhou, Yuan and Huang, Wenhao and Yang, Huan},
  journal={arXiv preprint arXiv:2412.01316},
  year={2024}
}

@article{yang2024cogvideox,
  title={Cogvideox: Text-to-video diffusion models with an expert transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}

@article{yin2024slow,
  title={From slow bidirectional to fast causal video generators},
  author={Yin, Tianwei and Zhang, Qiang and Zhang, Richard and Freeman, William T and Durand, Fredo and Shechtman, Eli and Huang, Xun},
  journal={arXiv preprint arXiv:2412.07772},
  year={2024}
}

@article{zheng2024opensora,
  title   = {Open-Sora: Democratizing Efficient Video Production for All},
  author  = {Zangwei Zheng and Xiangyu Peng and Tianji Yang and Chenhui Shen and Shenggui Li and Hongxin Liu and Yukun Zhou and Tianyi Li and Yang You},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2412.20404}
}

@article{zhou2024allegro,
  title   = {Allegro: Open the Black Box of Commercial-Level Video Generation Model},
  author  = {Yuan Zhou and Qiuyue Wang and Yuxuan Cai and Huan Yang},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2410.15458}
}

@article{zhuo2024lumina,
  title={Lumina-next: Making lumina-t2x stronger and faster with next-dit},
  author={Zhuo, Le and Du, Ruoyi and Xiao, Han and Li, Yangguang and Liu, Dongyang and Huang, Rongjie and Liu, Wenze and Zhao, Lirui and Wang, Fu-Yun and Ma, Zhanyu and others},
  journal={Advances in Neural Information Processing Systems.},
  year={2024}
}

