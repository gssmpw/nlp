\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}

\usepackage[ruled]{algorithm2e} % For algorithms

\title{Ready-to-React: Online Reaction Policy for Two-Character Interaction Generation}


\author{
Zhi Cen$^{1}$, Huaijin Pi$^{2}$, Sida Peng$^{1}$, Qing Shuai$^{1}$, Yujun Shen$^{3}$, Hujun Bao$^{1}$, Xiaowei Zhou$^{1}$, \\ 
\textbf{Ruizhen Hu$^{4}$\thanks{Corresponding author.}} \\
$^{1}$State Key Lab of CAD\&CG, Zhejiang University, $^{2}$The University of Hong Kong, $^{3}$Ant Group, \\
$^{4}$Shenzhen University\\
\texttt{zhicen@zju.edu.cn}, \texttt{ruizhen.hu@gmail.com}
}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}
\maketitle

\begin{figure}[h]
    \vskip-40pt
    \begin{center}
        \includegraphics[width=\linewidth]{figures/teaser_v1.pdf}
    \end{center}
    \caption{\textbf{Demonstration of \shortname}, an \textit{online} reaction policy for two-character interaction generation on the challenging task of boxing. \shortname{} predicts the next pose of an agent by considering its own and the counterpart's historical motions. Our method can successfully generate 1800 frames of motion, whereas the GPT-based approach struggles after about 200 frames, displaying issues such as incorrect orientation, leaving the ring boundary, or freezing in place due to the accumulation of errors over time.}
    \label{fig:teaser}
    \figtabskip
\end{figure}


\input{sections/00_abstract.tex}
\input{sections/01_introduction.tex}
\input{sections/02_related_work.tex}
\input{sections/03_method.tex}
\input{sections/04_experiment.tex}
\input{sections/05_application.tex}
\input{sections/06_discussion.tex}

\section*{Acknowledgements}
This work was partially supported by the NSFC (No.~62322207, No.~62172364, No.~62402427), Ant Group Research Fund and Information Technology Center and State Key Lab of CAD\&CG, Zhejiang University. We also acknowledge the EasyVolcap \citep{easyvolcap} codebase.

\clearpage
\begin{figure}[t]
    \begin{center}
        \includegraphics[width=\linewidth]{figures/baseline_reactive_v1.pdf}
    \end{center}
    \caption{\textbf{Qualitative results of generating reactive motions.}
    Given the same \textcolor{agentgreen}{ground truth opponent motion}, \blinterformer{} can produce reactive motion that is too close to the opponent, leading to penetration. \blcamdm{} tends to get stuck, while \blduolando{} may result in human motion with incorrect orientation after a certain period.
    }
    \label{fig:reactive}
\end{figure}

\begin{figure}[t]
    \begin{center}
        \includegraphics[width=\linewidth]{figures/baseline_twoagent_v1.pdf}
    \end{center}
    \caption{\textbf{Qualitative results of generating two-character motions.}
    Given the same initial four frames for both characters, \blinterformer{} tends to produce human motion with incorrect orientation. \blcamdm{} often results in the characters getting stuck, while \blgpt{} can cause the two characters to drift apart due to accumulated errors.
    }
    \label{fig:twoagent}
\end{figure}

\clearpage
\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}


\end{document}
