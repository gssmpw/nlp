\section{Related Work}
\noindent
\textbf{Transfer RL.}
____ studied transfer via shared representations between source and target tasks. With generative access to source tasks, they showed that learned representations enable fast convergence to near-optimal policies in target tasks, matching performance as if ground truth features were known. ____ proposed REFUEL for multitask representation learning in low-rank MDPs. They proved that learning shared representations across multiple tasks is more sample-efficient than individual task learning, provided enough tasks are available. Their analysis covers both online and offline downstream learning with shared representations.
____ analyzed transfer $Q$-learning without transition model assumptions, focusing instead on reward function similarity and transition density. These works established convergence guarantees for both backward and iterative $Q$-learning approaches.

Our work differs by studying transition models with low-rank plus sparse structures. This setting presents {\em unique challenges} beyond purely low-rank models, as we must identify and leverage an unknown low-rank space while also accounting for sparse deviations.


\smallskip
\noindent
\textbf{Single task RL under structured MDPs.}
Single-task RL under structured MDPs has evolved through several key advances:
Linear MDPs with known representations were initially studied by ____, leading to provably efficient online algorithms ____.

Low-rank MDPs extend this by requiring representation learning. Major developments include FLAMBE ____ for explore-then-commit transition estimation, and REP-UCB ____ for balancing representation learning with exploration. Recent work has expanded to nonstationary settings ____ and model-free approaches like MOFFLE ____.
Related structured models include block MDPs ____, low Bellman rank ____, low witness rank ____, bilinear classes ____, and low Bellman eluder dimension ____.

Our work introduces the composite MDPs with high-dimensional feature space and low-rank plus sparse transition, extending beyond pure low-rank models. We provide the first theoretical guarantees for UCB Q-learning under this composite structure.

\smallskip
\noindent
\textbf{Multitask RL and Meta RL.}
Research in multitask and meta-RL has evolved through several key theoretical advances. Early work by ____ examined multitask RL with linear Q-functions sharing sparse support, establishing sample complexity bounds that scale with the sparsity rather than ambient dimension. ____ extended this framework by studying weight vectors spanning low-dimensional spaces, showing that sample efficiency improves when the rank is much smaller than both the ambient dimension and number of tasks. ____ demonstrated how representation learning reduces sample complexity in imitation learning settings, providing theoretical guarantees for learning shared structure across tasks. ____ further developed this direction by analyzing multitask RL with low Bellman error and unknown representations, establishing bounds that improve with task similarity.

Task distribution approaches offered another perspective. ____ proved sample complexity benefits when tasks are independently sampled from a finite MDP set, while ____ and ____ extended these results to meta-RL for linear mixture MDPs, showing how learned structure transfers to new tasks. In parallel, research on shared representations by ____ established faster convergence rates for value iteration under common structure, and ____ proved substantial sample efficiency gains in the low-rank MDP setting.

Our composite MDP structure advances this line of work by explicitly modeling deviations from low-rank similarity through a sparse component. This framework captures more realistic scenarios where tasks share core structure but maintain individual variations, opening new theoretical directions for multitask and meta-learning approaches.