\section{Transfer in Reinforcement Learning} 

\subsection{Problem settings}


The system transitions to another state $s' \in \calS$ according to an unknown transition probability $\PP(s' | s, a)$, while returning an immediate reward $r(s, a)\in [0, 1]$. 
The goal of the agent is to obtain the maximal
possible return after playing for a period of time - even though she has no knowledge about the
transition probabilities at the beginning.



Now we consider transfer learning with target task $\calM^{(0)}$ and source task $\calM^{(1)}$. 
The transition probabilities of the target and source tasks are, respectively,
\begin{equation*}
    \PP^{(0)}(s' | s, a) = \phi(s, a)^\top \bM^{(0)} \psi(s'), \quad\text{and}\quad
    \PP^{(1)}(s' | s, a) = \phi(s, a)^\top\bM^{(1)}  \psi(s').
\end{equation*}

The target and source tasks are different in that the core transition matrix $\bM^{(0)} \ne \bM^{(1)}$. 
However, their similarity is defined by \begin{equation}
    \bM^{(0)} = \bL + \bS^{(0)}, 
    \quad\text{and}\quad
    \bM^{(1)} = \bL + \bS^{(1)},
\end{equation}
where $\bU \in \RR^{p \times k}$ and $\bV \in \RR^{q \times r}$ are low-rank matrices (i.e. $k\ll p$ and $r\ll q$), $\lVert \bS^{(0)} \rVert_0 = s_0$,  $\lVert \bS^{(1)} \rVert_0 = s_1$, and their difference $\bD = \bS^{(1)} - \bS^{(0)}$ satisfies $\norm{\bD}_0 = d \ll \max\{s_0, s_1\}$.
In words, the two core transition matrices $\bM^{(0)}$ and  $\bM^{(1)}$ share the same low-rank structure and differs only in their respective sparse matrix $\bS^{(0)}$ and $\bS^{(1)}$. 

We have $N_1$ episodes for the source task and $N_0$ episodes for the target task. 
In practice, $N_1 \gg N_0$ and we would like to use the source task to enhance the performance of the target task. 

we use $i$ and $h$ to index episodes and time steps of the target task, where $i \in [N_0]$ and $h \in [H]$. For the source task, $j$ and $h$ are used to index its episodes and time steps, with $j \in [N_1]$ and $h \in [H]$.
We obtain the following state-action-station transition triplet: $(s_{i, h}, a_{i, h}, s'_{i, h})$ from the target task and $(s_{j, h}, a_{j, h}, s'_{j, h})$ from the source task.
The associated features are 
\begin{equation}
\begin{aligned}
    \phi_{i, h}^{(0)} &:= \phi(s_{i, h}, a_{i, h}) \in \RR^d, & \psi_{i, h}^{(0)} &:= \psi(s'_{i, h}) \in \RR^{q}, \\
    \phi_{j, h}^{(1)} &:= \phi(s_{j, h}, a_{j, h}) \in \RR^d, & \psi_{j, h}^{(1)} &:= \psi(s'_{j, h}) \in \RR^{q}.
\end{aligned}
\end{equation}

Let $\bK_{\psi} := \sum_{s'\in\calS} \psi(s') \psi(s')^\top$. 
We have, at each step $h$, for the target task, 
   $$\EE\brackets{\phi_{i,h}\psi_{i,h}^\top \bK_{\psi}^{-1} \mid s_{i,h}, a_{i,h}} 
    = \paran{\phi_{i,h} \phi_{i,h}^\top} (\bL + \bS^{(0)})$$
    
Similarly, we have for the source task, 
$$\EE\brackets{\phi_{j,h}\psi_{j,h}^\top \bK_{\psi}^{-1} \mid s_{j,h}, a_{j,h}}= \paran{\phi_{j,h} \phi_{j,h}^\top} \bM^{(1)}= \paran{\phi_{j,h} \phi_{j,h}^\top} (\bL + \bS^{(1)})$$

\noindent{\sc Step I.} Estimate the low-rank component $\bM = \bL + \bS$ by solving\footnote{Note here that observations over $h \in [H]$ are not independent, one way to avoid this is to use non-stationary $\PP_h$, and thus $\bM_h$, for each step. 
For this moment, we will work with stationary and see if the proofs will go through with dependence over $h$.} 

We denote $Y_{i,h}=\phi_{i,h}\psi_{i, h}^{\top}K_{\psi}^{-1}$, $X_{i,h}=\phi_{i,h}\phi_{i,h}^\top$ and $Y_{j,h}=\psi_{j, h}^{\top}K_{\psi}^{-1}$, $X_{j,h}=\phi_{j,h} \phi_{j,h}^\top$

\begin{equation}
\begin{aligned}
&(\hat{\mathbf{L}}, \hat{\mathbf{S}}) \in 
    \underset{\mathbf{L}, \mathbf{S} \in \mathbb{R}^{p \times q}}{\arg\min}\;  \sum_{i^{\prime}<i, h \leq H}\left\|Y_{i,h}-X_{i,h}(\boldsymbol{L}+\boldsymbol{S})\right\|_{2}^{2}\sum_{j^{\prime}<j, h \leq H}\left\|Y_{j, h}-X_{j,h}(\boldsymbol{L}+\boldsymbol{S})\right\|_{2}^{2}   \\
&\text{s.t.}\quad \mathbf{L} = \sum_{k \in [r]} \sigma_k \mathbf{u}_k \mathbf{v}_k^\top,
\quad \|\mathbf{u}_k\|_\infty \leq \sqrt{\frac{\mu r}{p}}, \|\mathbf{v}_k\|_\infty \leq \sqrt{\frac{\mu r}{q}}
\end{aligned}
\label{eq:tl-step1}
\end{equation}

 
\noindent{\sc Step II.} Use target data to correct mixed estimation. 
\begin{equation}
\begin{aligned}
&\hat{\bD}\in \underset{\bD \in\RR^{p\times q}}{\arg\min}\;  \sum_{i'<i, h\le H}\norm{\phi_{i,h}\psi_{i,h}^\top \bK_{\psi}^{-1} - \phi_{i,h}\phi_{i,h}^\top (\hat\bL + \hat\bS +\bD) }_2^2 \\
&\text{s.t.}\quad \mathbf{L} = \sum_{k \in [r]} \sigma_k \mathbf{u}_k \mathbf{v}_k^\top,
\quad \|\mathbf{u}_k\|_\infty \leq \sqrt{\frac{\mu r}{p}}, \|\mathbf{v}_k\|_\infty \leq \sqrt{\frac{\mu r}{q}}
\end{aligned}
\label{eq:tl-step2}
\end{equation}


\begin{algorithm}
\caption{UCB-TRL(Sparse Matrix Transition Reinforcement Learning)}
\KwIn{Source domain $\mathcal{M}^{(0)}=(\mathcal{S},\mathcal{A},P^{(0)},r,s_0,H)$,\\target domain $\mathcal{M}^{(1)}=(\mathcal{S},\mathcal{A},P^{(1)},r,s_0,H)$,\\
Total number of episode $N_0,N_1$, feature function $\phi\in \mathbb{R}^p, \psi\in \mathbb{R}^q$,\\
Set $L_1,S_1,D_1=\mathbf{0}\in \mathbb{R}^{p\times q}$. 
Empty reply tuple $\mathcal{B}=\emptyset$}
//Estimate the low-rank component\;
\For{episode $i = 1,2,\ldots,N_0$}{    
    Set $Q_{j, h}(s, a)$ in
    (\ref{eq:updateQ}) using $L_j,S_j$  \;
    \For{stage $h = 1,2,\ldots,H$}{
    Take action $a_{i, h}=\arg \max _{a \in \mathcal{A}} Q_{i, h}\left(s_{i, h}, a\right)$\;
    Observe $s_{i, h+1}$ from domain $\mathcal{M}^{(0)}$\;
    %Update dataset $\mathcal{B}=\mathcal{B}\cup \{(s_{i, h}, a_{i, h}, s_{i, h+1})\}$
    }
    Learn transition core $L_i,S_i$ using (\ref{eq:tl-step1}) \\
}
//Use target data to correct mixed estimation\;
\For{episode $j = N_0+1,N_0+2,\ldots,N_0+N_1$}{    
    Set $Q_{j, h}(s, a)$  using $L_j,S_j$  \;
    \For{stage $h = 1,2,\ldots,H$}{
    Take action $a_{j, h}=\arg \max _{a \in \mathcal{A}} Q_{j, h}\left(s_{j, h}, a\right)$\;
    Observe $s_{j, h+1}$ from domain $\mathcal{M}^{(1)}$\;
    Update dataset $\mathcal{B}=\mathcal{B}\cup \{(s_{j, h}, a_{j, h}, s_{j, h+1})\}$
    }
    Learn transition core $L_j,S_j$ using (\ref{eq:tl-step2}) \\
}
\end{algorithm}


Let $N_k$ denote the number of samples in task $k$, $k=0,1$. By Proposition 3 in \citep{basu2019low}, for $N_k$ large enough, \footnote{$N_k \succsim q \paran{\frac{\sup_{\theta \in [-\pi, \pi]}\Lambda_{\max}(f_X(\theta))}{\sup_{\theta \in [-\pi, \pi]}\Lambda_{\min}\paran{f_X(\theta)}}}^2$ where $f_X$ is the spectral density of the VAR model.} there exists a constant $c>0$ such that 
\begin{equation}
\Lambda_{\min}\left(\frac{{\bX^{(k)}}^{\top}\bX^{(k)}}{N_k}\right) \leq c^{(k)},
\label{eq:ass-number}
\end{equation}
    with high probability, \footnote{$1-c_1\exp\paran{-c_2\log p}$ for some constants $c_1, c_2>0$.} Let $\zeta^{(k)}=c^{(k)}$, and then we have the strong convexity condition
    \begin{equation}
    	\frac{1}{2}\norm{\bX^{(k)}\Delta}_F^2 \geq \frac{\zeta^{(k)}}{2}\norm{\bDelta}_F^2, \, \mathrm{for \, all \,} \Delta \in \RR^{p \times q}.
    	\label{eq:StrongConvexity}
    \end{equation}


    The algorithm proceeds in two phases, corresponding to $k \in \{0, 1\}$.
\begin{align*}
Q_{n,h} - \big(r(s_{n,h},a_{n,h}) + [P_h V_{h+1}](s_{n,h},a_{n,h})\big) 
=& \phi_{n, h}^{\top}\left[\left(\widetilde{L}_{n} + \sum_{k=0}^1\widetilde{S}_{n}^{(k)}\right) - M^*\right] \bPsi^{\top} V_{n, h+1} \\
= &\phi_{n, h}^{\top}\left[(\widetilde{L}_{n}-L^*) + \sum_{k=0}^1\left(\widetilde{S}_{n}^{(k)}-S^{*(k)}\right)\right] \bPsi^{\top} V_{n, h+1}.
\end{align*}
The proof is provided in Appendix \ref{A:4}.

In calculating the regret bound, we reformulate the regret formula based on the updates to the Q-values within the algorithm and the confidence bounds of the core matrix. $\mathcal{F}_{n,h}$ is defined as the $\sigma$-field generated by all the random variables up until episode n, step h, essentially fixing the sequence $s_{1,1}, a_{1,1}, s_{1,2}, a_{1,2}, \ldots, s_{n,h}, a_{n,h}$. 
Now, we proceed to prove Theorem \ref{thm:bigtheorem}, letting 
$$\delta_{n,h} := (V_{n,h}-V_{h}^{\pi_{n}})(s_{n,h}), \quad
\gamma_{n,h} := Q_{n,h} - \left(r(s_{n,h},a_{n,h}) + [P_h V_{h+1}](s_{n,h},a_{n,h})\right).$$
\begin{align*}
\text{Regret}(N^{(0)}) &= \mathbb{E}\left(\sum_{n=1}^{N^{(0)}} \left[ V^*(s_0) - V^{\pi_n}(s_0) \right]\right) \\
&\leq \mathbb{E}\left( \sum_{n=1}^{N^{(0)}}(V_{n,1}-V_{1}^{\pi_{n}})(s_0)\right) = \sum_{n=1}^{N^{(0)}}\mathbb{E}(\delta_{n,1}).
\end{align*}
$$\mathbb{E}(\delta_{n,1}) = \mathbb{E}(\delta_{n,1}E_n+(1-E_n)\delta_{n,1}) 
\leq \mathbb{E}(\delta_{n,1}E_n)+Hp[E_n=0].$$
where $p[E_n=0]\leq c_1\exp\paran{-c_2\log p}$, Then we have

\begin{align*}
\mathbb{E}\paran{\delta_{n,1}E_n \mid \mathcal{F}_{n,1}} =& \paran{V_{n,1} - V_{1}^{\pi_{n}}}\paran{s_{n,1}}E_n \\
\leq &Q_{n,1}\paran{s_{n,1},a_{n,1}} - V_{1}^{\pi_{n}}\paran{s_{n,1}} \\
= &\gamma_{n,1} + \paran{r\paran{s_{n,1},a_{n,1}} +[PV_{n,2}]\paran{s_{n,1},a_{n,1}}} -V_{1}^{\pi_{n}}\paran{s_{n,1}} \\
\leq &\gamma_{n,1} + \mathbb{E}\paran{\paran{V_{n,2} - V_{2}^{\pi_{n}}}\paran{s_{n,2}}E_n \mid \mathcal{F}_{n,1}} 
\leq \cdots \leq \sum_{h=1}^{H}\gamma_{n,h}\\
\leq &2C_{\phi}C_{M}C' \sqrt{p}H^2\sqrt{\frac{dr + s\log d}{N_0 + N_1} + \frac{\alpha^2s}{pq}}
\end{align*}



\begin{theorem}
   
$$\norm{\hat\bDelta^L}_F^2+\dfrac{\zeta^{(0)}}{\zeta^{(0)}+ \zeta^{(1)}}\norm{\hat\bDelta^{S, (0)}}_F^2+\dfrac{\zeta^{(1)}}{\zeta^{(0)}+ \zeta^{(1)}}\norm{\hat\bDelta^{S, (1)}}_F^2
    \leq C_2\frac{d+\log d}{N_0+N_1},$$
    with high probability.
    \label{thm:ts-upperbounds2}
   \end{theorem}

   \begin{proof}
   When $K=2$, recall our setting
	$\bY^{(k)} = \bX^{(k)}\paran{\bL+\bS^{*, (k)}} + \bE^{(k)}$, $\bE^{(k)} \overset{\text{i.i.d.}}{\sim} \mathcal{N}\left(0, \Sigma_{\epsilon}\right)$. 
 Analogous to the proof of Theorem\ref{thm:rl-upperbound} for $k \in \braces{0, 1}$, 
           $$\sum_{k=0}^1 \brackets{\frac{1}{2} \norm{\bY^{(k)} - \bX^{(k)} \left( \bL^* + \bS^{*,(k)} + \hat\bDelta^L + \hat\bDelta^{S, (k)} \right)}_F^2} \leq \sum_{k=0}^1 \brackets{\frac{1}{2} \norm{\bY^{(k)} - \bX^{(k)} \left( \bL^* + \bS^{*,(k)} \right)}_F^2}$$
     \begin{equation}		
     \begin{aligned}
     \sum_{k=0}^1 \brackets{\frac{1}{2}\norm{\bX^{(k)}\left(\hat\bDelta^L+\hat\bDelta^{S, (k)}\right)}_F^2}
     & \leq\sum_{k=0}^1 \brackets{\abs{\angles{\paran{\bX^{(k)}}^\top \bE^{(k)},\hat\bDelta^L+\hat\bDelta^{S, (k)}}}}\\
    &\leq \sum_{k=0}^1 \brackets{\norm{\paran{\bX^{(k)}}^\top \bE^{(k)}}_2\norm{\hat\bDelta^L}_* + \norm{\paran{\bX^{(k)}}^\top \bE^{(k)}}_{\max}\norm{\hat\bDelta^{S, (k)}}_1}
    \end{aligned}
    \label{ineq:difference-Frob2}
    \end{equation}  

    Same to $\hat\bDelta^{S}$, For $k=0,1$, $$\abs{\angles{\hat\bDelta^L,\hat\bDelta^{S, (k)}}}=\abs{\angles{\Pi_J(\hat\bDelta^L),\Pi_J(\hat\bDelta^{S, (k)})}}\leq \norm{\Pi_J(\hat\bDelta^L)}_F^2+\norm{\Pi_J(\hat\bDelta^{S, (k)})}_F^2\leq \frac{1}{4}\paran{\norm{\hat\bDelta^{L}}_F^2+\norm{\hat\bDelta^{S, (k)}}_F^2}$$
     Recalling condition(\ref{ineq:covex-condition}), and inequality(\ref{ineq:lowerbound-Fnorm-XDelta}), we have
     \begin{equation}
     \begin{aligned}
     \sum_{k=0}^1 \brackets{\frac{1}{2}\norm{\bX^{(k)}\left(\hat\bDelta^L+\hat\bDelta^{S, (k)}\right)}_F^2 }&\geq \sum_{k=0}^1 \brackets{\frac{\zeta^{(k)}}{2} \paran{ \norm{\hat\bDelta^L}_F^2 + \norm{\hat\bDelta^{S, (k)}}_F^2 - \abs{\angles{\hat\bDelta^L, \hat\bDelta^{S, (k)}}}}}\\
     &\geq \sum_{k=0}^1 \frac{\zeta^{(k)}}{4} \paran{ \norm{\hat\bDelta^L}_F^2 + \norm{\hat\bDelta^{S, (k)}}_F^2 }
     \end{aligned}
     \end{equation}

     The incoherence property essentially restricts the upper bound of the cross terms in inequality (\ref{ineq:lowerbound-Fnorm-XDelta}). Coupling this with inequality (\ref{ineq:difference-Frob2}), we have,
     \begin{equation}
     \begin{aligned}
      &\sum_{k=0}^1 \frac{\zeta^{(k)}}{4} \paran{ \norm{\hat\bDelta^L}_F^2 + \norm{\hat\bDelta^{S, (k)}}_F^2 }\\
      &\leq \sum_{k=0}^1 \brackets{\norm{\paran{\bX^{(k)}}^\top \bE^{(k)}}_2\norm{\hat\bDelta^L}_* + \norm{\paran{\bX^{(k)}}^\top \bE^{(k)}}_{\max}\norm{\hat\bDelta^{S, (k)}}_1}\\
      &\leq \sqrt{4\braces{\sum_{k=0}^1\brackets{\frac{\zeta^{(k)}}{4} \paran{\norm{\hat\bDelta^L}_F^2 + \norm{\hat\bDelta^{S, (k)}}_F^2}}}\paran{\norm{\paran{\bX^{(k)}}^\top \bE^{(k)}}_2^2+2\norm{\paran{\bX^{(k)}}^\top \bE^{(k)}}_{\max}^2}}.
     \end{aligned}
     \end{equation}
     
     By combining lemma \ref{A:3}, which provides upper bounds on 
    $\norm{\bX^{\top}\bE}_2$ and $\norm{\bX^{\top}\bE}_{\max}$, we complete the proof of Theorem \ref{thm:ts-upperbounds2}.

     \begin{equation}
     \begin{aligned}
	 &\quad\norm{\hat\bDelta^L}_F^2+\dfrac{\zeta^{(0)}}{\zeta^{(0)}+ \zeta^{(1)}}\norm{\hat\bDelta^{S, (0)}}_F^2+\dfrac{\zeta^{(1)}}{\zeta^{(0)}+ \zeta^{(1)}}\norm{\hat\bDelta^{S, (1)}}_F^2\\
     &\leq \frac{4}{\zeta^{(0)}+\zeta^{(1)}}\paran{\norm{\paran{\bX^{(k)}}^\top \bE^{(k)}}_2^2+2\norm{\paran{\bX^{(k)}}^\top \bE^{(k)}}_{\max}^2}
     \leq C_2\frac{d+\log d}{N_0+N_1}.
     \end{aligned}
     \end{equation}

   \end{proof}
   \begin{theorem}
   Given Conditions (\ref{eq:ass-number}) and Conditions in Theorem\ref{thm:ts-upperbounds2}, the cumulative regret of the UCB-TRL algorithm satisfies the following high-probability bound:
    \begin{align*}
    \text{Regret}(N_0)&  \leq 2C_{\phi}C_{M}C_2^{'} \sqrt{pH^3}\sqrt{\frac{N_0^2H}{N_0+N_1}(d+\log d)}\\
    & =\mathcal{O}\paran{C_{\phi}C_{M}C' \sqrt{pH^3}\sqrt{T(d+\log d)}}.
   \end{align*} 
   \end{theorem}


