[
  {
    "index": 0,
    "papers": [
      {
        "key": "piloto2022intuitive",
        "author": "Piloto, Luis S and Weinstein, Ari and Battaglia, Peter and Botvinick, Matthew",
        "title": "Intuitive physics learning in a deep-learning model inspired by developmental psychology"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "hespos2016five",
        "author": "Hespos, Susan J and Ferry, Alissa L and Anderson, Erin M and Hollenbeck, Emily N and Rips, Lance J",
        "title": "Five-month-old infants have general knowledge of how nonsolid substances behave and interact"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "piloto2022intuitive",
        "author": "Piloto, Luis S and Weinstein, Ari and Battaglia, Peter and Botvinick, Matthew",
        "title": "Intuitive physics learning in a deep-learning model inspired by developmental psychology"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zellers2019recognition",
        "author": "Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin",
        "title": "From recognition to cognition: Visual commonsense reasoning"
      },
      {
        "key": "li2022representation",
        "author": "Li, Jiangtong and Niu, Li and Zhang, Liqing",
        "title": "From representation to reasoning: Towards both evidence and commonsense reasoning for video question-answering"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "bisk2020piqa",
        "author": "Bisk, Yonatan and Zellers, Rowan and Gao, Jianfeng and Choi, Yejin and others",
        "title": "Piqa: Reasoning about physical commonsense in natural language"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "zellers2022merlot",
        "author": "Zellers, Rowan and Lu, Jiasen and Lu, Ximing and Yu, Youngjae and Zhao, Yanpeng and Salehi, Mohammadreza and Kusupati, Aditya and Hessel, Jack and Farhadi, Ali and Choi, Yejin",
        "title": "Merlot reserve: Neural script knowledge through vision and language and sound"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "yu2022pacs",
        "author": "Yu, Samuel and Wu, Peter and Liang, Paul Pu and Salakhutdinov, Ruslan and Morency, Louis-Philippe",
        "title": "PACS: A Dataset for Physical Audiovisual CommonSense Reasoning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zellers2019recognition",
        "author": "Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin",
        "title": "From recognition to cognition: Visual commonsense reasoning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wang2020visual",
        "author": "Wang, Tan and Huang, Jianqiang and Zhang, Hanwang and Sun, Qianru",
        "title": "Visual commonsense r-cnn"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "zareian2020learning",
        "author": "Zareian, Alireza and Wang, Zhecan and You, Haoxuan and Chang, Shih-Fu",
        "title": "Learning visual commonsense for robust scene graph generation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "li2022representation",
        "author": "Li, Jiangtong and Niu, Li and Zhang, Liqing",
        "title": "From representation to reasoning: Towards both evidence and commonsense reasoning for video question-answering"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "bisk2020piqa",
        "author": "Bisk, Yonatan and Zellers, Rowan and Gao, Jianfeng and Choi, Yejin and others",
        "title": "Piqa: Reasoning about physical commonsense in natural language"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "lin2023tiktalk",
        "author": "Lin, Hongpeng and Ruan, Ludan and Xia, Wenke and Liu, Peiyu and Wen, Jingyuan and Xu, Yixin and Hu, Di and Song, Ruihua and Zhao, Wayne Xin and Jin, Qin and others",
        "title": "TikTalk: A Video-Based Dialogue Dataset for Multi-Modal Chitchat in Real World"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "yu2022pacs",
        "author": "Yu, Samuel and Wu, Peter and Liang, Paul Pu and Salakhutdinov, Ruslan and Morency, Louis-Philippe",
        "title": "PACS: A Dataset for Physical Audiovisual CommonSense Reasoning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "bengio2013representation",
        "author": "Bengio, Yoshua and Courville, Aaron and Vincent, Pascal",
        "title": "Representation learning: A review and new perspectives"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "chen2021curriculum",
        "author": "Chen, Hong and Chen, Yudong and Wang, Xin and Xie, Ruobing and Wang, Rui and Xia, Feng and Zhu, Wenwu",
        "title": "Curriculum disentangled recommendation with noisy multi-feedback"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "wei2024unsupervised",
        "author": "Wei, Pengfei and Kong, Lingdong and Qu, Xinghua and Ren, Yi and Xu, Zhiqiang and Jiang, Jing and Yin, Xiang",
        "title": "Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective"
      },
      {
        "key": "qi2020stc",
        "author": "Qi, Mengshi and Wang, Yunhong and Li, Annan and Luo, Jiebo",
        "title": "STC-GAN: Spatio-temporally coupled generative adversarial networks for predictive scene parsing"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "van2019disentangled",
        "author": "Van Steenkiste, Sjoerd and Locatello, Francesco and Schmidhuber, J{\\\"u}rgen and Bachem, Olivier",
        "title": "Are disentangled representations helpful for abstract visual reasoning?"
      },
      {
        "key": "qi2021semantics",
        "author": "Qi, Mengshi and Qin, Jie and Yang, Yi and Wang, Yunhong and Luo, Jiebo",
        "title": "Semantics-aware spatial-temporal binaries for cross-modal video retrieval"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "ma2018disentangled",
        "author": "Ma, Liqian and Sun, Qianru and Georgoulis, Stamatios and Van Gool, Luc and Schiele, Bernt and Fritz, Mario",
        "title": "Disentangled person image generation"
      },
      {
        "key": "bai2021contrastively",
        "author": "Bai, Junwen and Wang, Weiran and Gomes, Carla P",
        "title": "Contrastively disentangled sequential variational autoencoder"
      },
      {
        "key": "wang2024rdfc",
        "author": "Wang, Haowen and Che, Zhengping and Yang, Yufan and Wang, Mingyuan and Xu, Zhiyuan and Qiao, Xiuquan and Qi, Mengshi and Feng, Feifei and Tang, Jian",
        "title": "RDFC-GAN: RGB-Depth Fusion CycleGAN for Indoor Depth Completion"
      },
      {
        "key": "qi2019attentive",
        "author": "Qi, Mengshi and Li, Weijian and Yang, Zhengyuan and Wang, Yunhong and Luo, Jiebo",
        "title": "Attentive relational networks for mapping images to scene graphs"
      },
      {
        "key": "qi2019ke",
        "author": "Qi, Mengshi and Wang, Yunhong and Qin, Jie and Li, Annan",
        "title": "KE-GAN: Knowledge embedded generative adversarial networks for semi-supervised scene parsing"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "tran2017disentangled",
        "author": "Tran, Luan and Yin, Xi and Liu, Xiaoming",
        "title": "Disentangled representation learning gan for pose-invariant face recognition"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "goodfellow2020generative",
        "author": "Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua",
        "title": "Generative adversarial networks"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "wei2024unsupervised",
        "author": "Wei, Pengfei and Kong, Lingdong and Qu, Xinghua and Ren, Yi and Xu, Zhiqiang and Jiang, Jing and Yin, Xiang",
        "title": "Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "ma2018disentangled",
        "author": "Ma, Liqian and Sun, Qianru and Georgoulis, Stamatios and Van Gool, Luc and Schiele, Bernt and Fritz, Mario",
        "title": "Disentangled person image generation"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "bai2021contrastively",
        "author": "Bai, Junwen and Wang, Weiran and Gomes, Carla P",
        "title": "Contrastively disentangled sequential variational autoencoder"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "zhu2020s3vae",
        "author": "Zhu, Yizhe and Min, Martin Renqiang and Kadav, Asim and Graf, Hans Peter",
        "title": "S3vae: Self-supervised sequential vae for representation disentanglement and data generation"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "wang2023disavr",
        "author": "Wang, Yaxian and Wei, Bifan and Liu, Jun and Zhang, Lingling and Wang, Jiaxin and Wang, Qianying",
        "title": "DisAVR: Disentangled Adaptive Visual Reasoning Network for Diagram Question Answering"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "goyal2017making",
        "author": "Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi",
        "title": "Making the v in vqa matter: Elevating the role of image understanding in visual question answering"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "antol2015vqa",
        "author": "Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi",
        "title": "Vqa: Visual question answering"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "goyal2019counterfactual",
        "author": "Goyal, Yash and Wu, Ziyan and Ernst, Jan and Batra, Dhruv and Parikh, Devi and Lee, Stefan",
        "title": "Counterfactual visual explanations"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "tang2020unbiased",
        "author": "Tang, Kaihua and Niu, Yulei and Huang, Jianqiang and Shi, Jiaxin and Zhang, Hanwang",
        "title": "Unbiased scene graph generation from biased training"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "Rao_2021_ICCV",
        "author": "Rao, Yongming and Chen, Guangyi and Lu, Jiwen and Zhou, Jie",
        "title": "Counterfactual Attention Learning for Fine-Grained Visual Categorization and Re-Identification"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "xu2022unintentional",
        "author": "Xu, Jinglin and Chen, Guangyi and Lu, Jiwen and Zhou, Jie",
        "title": "Unintentional action localization via counterfactual examples"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "sun2023unbiased",
        "author": "Sun, Shuzhou and Zhi, Shuaifeng and Liao, Qing and Heikkil{\\\"a}, Janne and Liu, Li",
        "title": "Unbiased scene graph generation via two-stage causal modeling"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "xue2023variational",
        "author": "Xue, Dizhan and Qian, Shengsheng and Xu, Changsheng",
        "title": "Variational Causal Inference Network for Explanatory Visual Question Answering"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "li2023progressive",
        "author": "Li, Guangyao and Hou, Wenxuan and Hu, Di",
        "title": "Progressive spatio-temporal perception for audio-visual question answering"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "lu2019vilbert",
        "author": "Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan",
        "title": "Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "hu2021class",
        "author": "Hu, Di and Wei, Yake and Qian, Rui and Lin, Weiyao and Song, Ruihua and Wen, Ji-Rong",
        "title": "Class-aware Sounding Objects Localization via Audiovisual Correspondence"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "deshmukh2023pengi",
        "author": "Deshmukh, Soham and Elizalde, Benjamin and Singh, Rita and Wang, Huaming",
        "title": "Pengi: An audio language model for audio tasks"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "li2022learning",
        "author": "Li, Guangyao and Wei, Yake and Tian, Yapeng and Xu, Chenliang and Wen, Ji-Rong and Hu, Di",
        "title": "Learning to answer questions in dynamic audio-visual scenarios"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "wang2023multi",
        "author": "Wang, Hu and Chen, Yuanhong and Ma, Congbo and Avery, Jodie and Hull, Louise and Carneiro, Gustavo",
        "title": "Multi-modal learning with missing modality via shared-specific feature modelling"
      }
    ]
  }
]