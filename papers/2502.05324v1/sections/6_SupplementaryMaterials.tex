\clearpage
\onecolumn
\section{Supplementary Materials}

\subsection{Appendix A \\Summary of All Technology Uses, Risks, Mitigations and Benefits Generated During the Formative Study}

\begin{figure*}[h!]
  \centering
  \includegraphics[width=0.95\textwidth]{figures/appendix_uses.pdf}
  \caption{Uses generated by the participants of the formative study through writing emails to regulators.}
  \label{fig:uses}
\end{figure*}

\begin{figure*}[h!]
  \centering
  \includegraphics[width=0.95\textwidth]{figures/appendix_risks.pdf}
  \caption{Risks generated by the participants of the formative study through writing emails to regulators.}
  \label{fig:risks}
\end{figure*}

\begin{figure*}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{figures/appendix_mitigations.pdf}
  \caption{Mitigations generated by the participants of the formative study through writing emails to regulators.}
  \label{fig:mitigations}
\end{figure*}

\begin{figure*}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{figures/appendix_benefits.pdf}
  \caption{Benefits generated by the participants of the formative study through writing emails to regulators.}
  \label{fig:benefits}
\end{figure*}

\clearpage
\subsection{Appendix B \\Prompt Engineering for Generating Facial Recognition Technology Uses, Along With Their Risks, Mitigations, Benefits, and Illustrations}
The data for our Atlas was generated using five adaptable prompts: \emph{ExploreGen} \cite{herdel2024exploregen}, \emph{RiskGen}, \emph{BenefitGen}, \emph{MitigationGen} \cite{constantinides2024_risks_benefits, AIDesign2024} and \emph{IllustrationGen}. To execute them, we chose OpenAI's GPT-4 model for its leading performance as of June 2024 \cite{leaderboard}, and the DALL-E 3 model for its good integration with GPT-4 and good image quality. 

\smallskip
\textbf{(1) ExploreGen} prompt generates a list of existing and upcoming uses of a given technology (i.e., facial recognition) across various application domains \cite{herdel2024exploregen}. The prompt includes four key elements to generate diverse and realistic uses: \emph{role}, \emph{domains}, \emph{instructions}, and \emph{output}. 

First, we asked LLM to take the \emph{role} of a ``Senior AI Technology Expert responsible for identifying and cataloging various AI applications and use cases''. This role draws on the LLM's prior knowledge and ensures generation of realistic AI uses. 

Second, we directed the LLM to generate three distinct uses for each of the \emph{46 domains} that cover key economic sectors and various aspects of everyday life, ensuring diverse AI uses.

Third, we formulated \emph{instructions} to break down the uses into five components suitable for risk assessment, aligning with the requirements of the EU AI Act \cite{Golpayegani2023Risk}. These components are: \textit{domain} (the specific industry or sector, e.g., \emph{finance}), \textit{purpose} (the end goal, e.g., \emph{fraud prevention}), \textit{capability} (the technological feature, e.g., \emph{facial recognition}), \textit{AI user} (the entity managing and overseeing the user, e.g., \emph{banks}), and \textit{AI subject} (individuals or groups impacted by the use, e.g., \emph{customers}).

Finally, the \emph{output} of \emph{ExploreGen} is a list of facial recognition uses. Each use is described in a five-component format (e.g., [finance, fraud prevention, facial recognition, banks, customers]]) and is summarized in concise one-line description (e.g., facial recognition for financial fraud detection).

\smallskip
\noindent\textbf{(2) RiskGen} prompt generates and categorizes potential risks for each use, focusing on issues such as infringing on Human Rights (HRs) \cite{rights1961universal}, hindering Sustainable Development Goals (SDGs) \cite{sdgs}, and failing to adhere to regulatory guidelines from the EU AI Act \cite{EUACT2024}. Together with \emph{BenefitGen} that will be discussed below, \emph{RiskGen} helps to categorize uses and provide a balanced assessment of their risks and benefits. \emph{RiskGen} consists of four elements: \emph{role}, \emph{input}, \emph{instructions}, and \emph{output}. 

First, the \emph{role} is a ``Senior AI Technology Expert, specializing in compliance with the EU AI Act, SDGs, and HRs''.

Second, the \emph{input} includes excerpts from the EU AI Act which describe high-risk AI systems (e.g., Annex III), the 17 SDGs definitions from the Sustainable Development Agenda \cite{sdgs}, and the 30 HRs articles from the Universal Declaration of Human Rights (UDHR) \cite{rights1961universal}.

Third, the \emph{instructions} use a Chain-of-Thought approach, i.e., dividing the task into a series of smaller, intermediate reasoning steps that lead to the final output~\cite{NEURIPS2022_9d560961}. These steps are: (1) producing a risk classification as per the EU AI Act (whether the use is unacceptable, high-risk, or none of these two (minimal risk)); (2) identifying any additional risks from the ways the use undermines SDGs or HRs; and (3) grouping all risks based on their relevance to the capability, human interaction, and systemic impact layers \cite{weidinger2023sociotechnical}. 

Fourth, the \emph{output} of the prompt includes the risk classification, completed with LLM's reasoning for this classification and relevant excerpts from the EU AI Act. This structure is similarly repeated for HRs and SDG risks, which include excerpts from relevant UDHR Articles or SDGs. The output of \emph{RiskGen} is further passed to the \emph{MitigationGen}.

\smallskip
\noindent\textbf{(3) BenefitGen} prompt generates and categorizes potential benefits for each use. It consists of four elements: \emph{role}, \emph{input}, \emph{instructions}, and \emph{output}. Similarly to \emph{RiskGen}, the \emph{role} is a ``Senior AI Technology Expert, specializing in SDGs and HRs'', and the \emph{input} includes the 17 SDGs definitions the 30 HRs articles. The \emph{instructions} and \emph{output} also mimic those of \emph{RiskGen}. 
Two primary differences are that we ask LLM to generate \emph{benefits} instead of \emph{risks} for HRs and SDGs, and we remove any references to the EU AI Act, as it is a risk-based regulation that may not be applicable when generating benefits.

\smallskip
\noindent\textbf{(4) MitigationGen} prompt proposes mitigation strategies for each of the risks previously identified by \emph{RiskGen}. It consists of three elements: \emph{role}, \emph{instructions}, and \emph{output}. 

Second, the \emph{instructions} include four steps: (1) proposing mitigation strategies; (2) grouping these strategies based on their relevance to the capability, human interaction, and systemic impact layers \cite{weidinger2023sociotechnical}, (3) generating a description of a new mitigated version of the use; and (4) evaluating the compliance of the mitigated version with the EU AI Act (assessing whether that version is still unacceptable or high-risk).

Third, the \emph{output} contains mitigation strategies, their groups, description of the new mitigated system, and its EU AI Act classification. 

\smallskip
\textbf{(5) IllustrationGen} illustrates the uses to fulfil design requirement \emph{(R5)}. This is achieved with a prompt asking to \emph{``Generate an image for the [description of the use] with the content that is safe and appropriate. Use line art style, low polygons, and black lines on the white background''}. We sent a prompt to OpenAI's DALL-E 3 model, which generated images with a resolution of 1024x1024 pixels each.

\clearpage
\subsection{Appendix C \\The Setup of the User Study Evaluating the Atlas}

\begin{figure}[ht]
  \centering
\includegraphics[width=\textwidth]{figures/study_steps.pdf}
  \caption{\textbf{The evaluation study involved seven steps.} As a first step, participants completed the first task without tools (Step 1). Next, they answered control questions and an attention-check (Step 2). Subsequently, they used our tool (treatment) or a baseline (control) for analysis and a second judgment task (Step 3), followed by usability evaluation and another attention-check (Step 4). Next, they assesses the visual aesthetics of the tool and completed a third attention-check (Step 5). Then they described how the visualization helped them lo learn about multiple uses, if their categorization was useful and if the overall presented information was relevant (Step 6). The final step gathered recommendations for future tool development (Step 7). }
  \label{fig:survey_setup}
\end{figure}

\subsection{Appendix D \\Baseline Visualization of AI Use Risks}
\begin{figure}[h!]
  \centering
\includegraphics[width=\textwidth]{figures/baseline.pdf}
  \caption{\textbf{The baseline visualization mirrored the state-of-the-art AI risk visualization} \cite{spatialDatabaseView}. A one-page dashboard approach groups technology uses based on their similarity scores (A). Viewers can access their descriptions and news articles about their associated risks and benefits (B), and filter them through a dropdown menu (C).}
  \label{fig:baseline}
\end{figure}

\clearpage
\subsection{Appendix E \\Demographic Details of Participants of the User Study Evaluating the Atlas}

\begin{table}[h!]
\centering
\renewcommand{\arraystretch}{1.1} 
\setlength{\tabcolsep}{3.25pt}
\caption{Self-reported knowledge and demographics of ordinary individuals interacting with either the baseline or the Atlas.}
\label{tbl:participants_demographics}
\begin{tabular}{|p{4.8cm}|p{6cm}|p{1.6cm}|p{1.6cm}|p{1.8cm}|}
\hline
\textbf{Control} & \textbf{Characteristic} & \begin{tabular}[c]{@{}l@{}} \textbf{Baseline}\\ (n=70)\end{tabular} & \begin{tabular}[c]{@{}l@{}} \textbf{Atlas}\\ (n=70) \end{tabular} & \begin{tabular}[c]{@{}l@{}} \textbf{US Census} \\ (\citeyear{census_ethnicity_2020, census_age_gender_2022}) \end{tabular} \\ \hline

\multirow{4}{*}{\begin{tabular}[c]{@{}l@{}} \textbf{Knowledge} \\ (1: definitely not above average, \\ 5: definitely above average) \end{tabular}}       
                            & Task (writing an email to policymakers)  & 3.09 & 2.96 & - \\ \cline{2-5}
                            & Technology in general & 3.53 & 3.46 & - \\ \cline{2-5}
                            & Facial recognition & 2.87 & 2.73 & - \\ \cline{2-5}
                            & Artificial Intelligence & 3.16 & 3.00 & - \\ \hline

\multirow{5}{*}{\begin{tabular}[c]{@{}l@{}} \textbf{Age} \\ (\% of population above 18 years) \end{tabular}}    
                            & 18-29 & 21\% & 20\% & 20\% \\ \cline{2-5}
                            & 30-39 & 19\% & 20\% & 18\% \\ \cline{2-5}
                            & 40-49 & 17\% & 17\% & 16\% \\ \cline{2-5}
                            & 50-59 & 17\% & 16\% & 16\% \\ \cline{2-5}
                            & 60 and above & 26\% & 27\% & 30\% \\ \hline

\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}} \textbf{Sex} \\ (\% of population) \end{tabular}}         
                            & Female & 51\% & 49\% & 50\% \\ \cline{2-5}
                            & Male & 49\% & 51\% & 50\% \\ \hline

\multirow{6}{*}{\begin{tabular}[c]{@{}l@{}} \textbf{Ethnicity} \\ (\% of population) \end{tabular}}      
                            & White & 60\% & 61\% & 62\% \\ \cline{2-5}
                            & Black & 14\% & 11\% & 12\% \\ \cline{2-5}
                            & Asian & 7\% & 7\% & 6\% \\ \cline{2-5}
                            & Mixed & 10\% & 10\% & 10\% \\ \cline{2-5}
                            & Native American or Alaskan Native & 1\% & 1\% & 1\% \\ \cline{2-5}
                            & Other & 7\% & 9\% & 9\% \\ \hline

\end{tabular}
\end{table}

\subsection{Appendix F \\System Usability Scale Ratings by Self-Reported Level of General Technological Knowledge}
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.55\textwidth]{figures/sus_scores.pdf}
  \caption{\textbf{System Usability Scale ratings by self-reported level of general technological knowledge.} The levels were assessed on a scale from 1 (definitely not above average) to 5 (definitely above average). Based on these assessments, users were categorized into three groups: those who identified as 1 or 2 were labeled as having \emph{low knowledge}, those who chose 3 were labeled as having \emph{average knowledge}, and those who chose 4 or 5 were labeled as having \emph{high knowledge} in technology.}
  \label{fig:sus}
\end{figure}

\clearpage
\subsection{Appendix G \\Atlas Views Generalized for the Uses From the AI Incident Database}

\begin{figure}[h!]
  \centering
\includegraphics[width=\textwidth]{figures/atlas_incidents.png}
  \caption{\textbf{Atlas of AI Risks for uses derived from the AI Incident Database.} We tested the generalizability of the Atlas by downloading 649 descriptions of AI-related incidents from the AI Incidents Database \cite{mcgregor2021preventing} and converting them into 379 specific AI uses. With multiple technologies, the spatial mapping adapted to present areas where their uses are similar.}
  \label{fig:incidents}
\end{figure}


\begin{figure}[h!]
  \centering
\includegraphics[width=\textwidth]{figures/atlas_mobile_computing.png}
  \caption{\textbf{Atlas of AI Risks for mobile computing uses derived from the AI Incident Database.} Drawing from the 379 specific AI uses identified in the database, we filtered 54 AI applications related to mobile computing by searching descriptions for mentions of mobile applications and technologies.}
  \label{fig:mobile}
\end{figure}


