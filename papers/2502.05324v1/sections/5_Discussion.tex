\section{Demonstrating the Generalizability of the Tool}
To make sure the Atlas can handle any kind of AI, we use a straightforward five-part format. This format consists of:
\emph{purpose} (what the AI is meant to do), \emph{capability} (what the AI can actually do), \emph{AI user} (who uses the AI), \emph{AI subject} (on whom the AI works), and \emph{domain} (the area where the AI is used). This format is so flexible that it was first proposed to assess the risks of any AI system according to the EU AI Act \cite{Golpayegani2023Risk}.

To then demonstrate the Atlas can handle any kind of AI  beyond facial recognition, we populated it with 379 real-world AI applications that resulted in news incident reports. We sourced the incident descriptions from the AI Incident Database (AIID), a standardized and verified collection of AI-related harmful events \cite{mcgregor2021preventing}. We populated the Atlas in five steps. First, we downloaded all 649 incident descriptions (e.g., ``YouTube's recommendation algorithms exposed children to disturbing videos''). Second, we used the \emph{ExploreGen} prompt to generate a possible AI use that could have caused the incident, breaking it down into the previously defined five components (e.g., ``Purpose'': ``Recommending suitable videos for children'', ``AI Capability'': ``Content filtering'', ``AI User'': ``YouTube'', ``AI Subject'': Children'', ``Domain'': ``Recommender Systems''). Third, we reviewed the formatted uses and merged the duplicate and most similar ones based on their semantic similarity and overlaps in our Atlas (e.g., 53 incident descriptions related to opearating autonomous taxis and delivery vehicles were merged into one use: ``Purpose'': ``Operating autonomus vehicles'', ``AI Capability'': ``Acting on sensor readings for navigation'', ``AI User'': Autonomous vehicle providers'', ``AI Subject'': ``Road users'', ``Domain'': ``Public and private transportation''). This review resulted in a final set of 379 uses. Fourth, we ran \emph{RiskGen}, \emph{BenefitGen}, \emph{MitigationGen}, and \emph{IllustrationGen} on each use to complete the content of the impact assessment card. Finally, we updated the Atlas's source code to include a dropdown menu, enabling users to explore all technologies from the incident database (Supplementary Materials, Appendix G, Figure \ref{fig:incidents}) or to focus on individual technologies like mobile computing (Supplementary Materials, Appendix G, Figure \ref{fig:mobile}). The extended Atlas is available online at~\url{https://social-dynamics.net/atlas}.

Based on the successful testing of its generalizability, we suggest three scenarios of how the Atlas could facilitate public debates and advocating for regulatory changes. First, by integrating the Atlas into AI city registers, where governments catalog urban technologies \cite{cityRegister}, citizens could better assess risks like privacy concerns before engaging in local discussions. Second, the Atlas could be integrated into consumer AI databases, such as the upcoming EU database for high-risk AI systems \cite{EUACT2024}, allowing individuals to evaluate AI products and make informed purchases. Finally, in education, the Atlas could serve students studying AI's ethical implications across different industries \cite{feffer2023ai}.

\section{Discussion and Conclusion}
\label{sec:discussion}

\noindent\textbf{Weighing Explanation and Exploration.} The goal of our tool is to effectively communicate AI uses and their risks to ordinary individuals interested in technology. This could also be achieved through other, more traditional methods, such as tutorials or training sessions. However, these approaches have two major limitations. First, they are often static and linear, limiting users' ability to explore content in a personalized way. Second, they demand significant time, which can overwhelm individuals with lower AI literacy. Instead, we developed a tool that aligns with the shift from static documentation, like impact assessment reports, to dynamic, glanceable formats like interactive model cards. By prioritizing visual narratives and aesthetic design, we encouraged users to spend more time exploring the tool and avoided overly technical designs that could alienate those who most need accessible learning tools.

\vspace{1pt}

\noindent\textbf{Future work.} We identify two areas for future work in data collection and visual presentation in similar tools. First is the exploration of complementary approaches that integrate collecting public perceptions and uses, expert assessments, and insights from LLMs. Second is the inclusion of visual features that help effectively build consensus around technology. These could include voting buttons where users can express their agreement or disagreement with certain assessments, and displaying aggregated community votes.

\vspace{1pt}

\noindent\textbf{Limitations.} This research comes with three limitations. First, LLM deployment faces issues like biases in training data that may overlook important risks and benefits \cite{luccioni2024stable}, while strict safety measures can omit risky uses already known to the public from past incidents \cite{AIRiskDatabase}. Addressing these issues requires fine-tuning models with specific technology datasets. For the Atlas, we addressed them by validating the content and manually removing any incoherent information.

Second, the Atlas usability score partly reflects the novelty and design challenge for similar tools and audiences. Our study's sample may not completely represent ordinary individuals interested in technology, due to limited controls over their location, age, ethnicity, gender, experience with AI and preferences in data visualization. Third, the study reflects US perspectives, which may not apply globally, as perceptions of technology risks and benefits vary by country. For example, facial recognition is most accepted in China, less so in Germany, with the US and UK in between \cite{frtPerceptions2021}. While most Chinese citizens emphasize benefits like convenience. Americans, Germans, and Brits are more concerned about risks such as surveillance \cite{frtCrossCountryPerceptions_2023}. Therefore, our findings should be interpreted with these limitations in mind.

Our work initially focused on designing and evaluating a tool for ordinary individuals interested in technology. However, we found that even non-tech savvy users could effectively engage with it when prompted, as the toolâ€™s usability remained consistent across users with different levels of technological knowledge. This demonstrates the Atlas's ability to make complex AI technology risks understandable, filling the gap in current risk communication methods.