@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{wen2024device,
  title={On-Device LLMs for SMEs: Challenges and Opportunities},
  author={Wen, Jeremy Stephen Gabriel Yee Zhi and Ng, Pai Chet and Wang, Zhengkui and McLoughlin, Ian and Ng, Aik Beng and See, Simon},
  journal={arXiv preprint arXiv:2410.16070},
  year={2024}
}
@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
@article{hochreiter1997long,
  title={Long Short-term Memory},
  author={Hochreiter, S},
  journal={Neural Computation MIT-Press},
  year={1997}
}
@article{bengio2000neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal},
  journal={Advances in neural information processing systems},
  volume={13},
  year={2000}
}
%Mistral 7b
@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}




@article{team2024gemma,
  title={Gemma 2: Improving open language models at a practical size},
  author={Team, Gemma and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal={arXiv preprint arXiv:2408.00118},
  year={2024}
}
@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}
@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}
@article{yao2024survey,
  title={A survey on large language model (llm) security and privacy: The good, the bad, and the ugly},
  author={Yao, Yifan and Duan, Jinhao and Xu, Kaidi and Cai, Yuanfang and Sun, Zhibo and Zhang, Yue},
  journal={High-Confidence Computing},
  pages={100211},
  year={2024},
  publisher={Elsevier}
}


@article{das2024security,
  title={Security and privacy challenges of large language models: A survey},
  author={Das, Badhan Chandra and Amini, M Hadi and Wu, Yanzhao},
  journal={arXiv preprint arXiv:2402.00888},
  year={2024}
}

@article{neel2023privacy,
  title={Privacy issues in large language models: A survey},
  author={Neel, Seth and Chang, Peter},
  journal={arXiv preprint arXiv:2312.06717},
  year={2023}
}
@article{yan2024protecting,
  title={On protecting the data privacy of large language models (llms): A survey},
  author={Yan, Biwei and Li, Kun and Xu, Minghui and Dong, Yueyan and Zhang, Yue and Ren, Zhaochun and Cheng, Xiuzheng},
  journal={arXiv preprint arXiv:2403.05156},
  year={2024}
}
@article{azab2024network,
  title={Network traffic classification: Techniques, datasets, and challenges},
  author={Azab, Ahmad and Khasawneh, Mahmoud and Alrabaee, Saed and Choo, Kim-Kwang Raymond and Sarsour, Maysa},
  journal={Digital Communications and Networks},
  volume={10},
  number={3},
  pages={676--692},
  year={2024},
  publisher={Elsevier}
}
@article{papadogiannaki2021survey,
  title={A survey on encrypted network traffic analysis applications, techniques, and countermeasures},
  author={Papadogiannaki, Eva and Ioannidis, Sotiris},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@misc{granite2024granite,
  title={Granite 3.0 Language Models},
  url={https://github.com/ibm-granite/granite-3.0-language-models/},
  author={Granite Team, IBM},
  month={October},
  year={2024}
}
@article{zhao2024sok,
  title={SoK: Watermarking for AI-Generated Content},
  author={Zhao, Xuandong and Gunn, Sam and Christ, Miranda and Fairoze, Jaiden and Fabrega, Andres and Carlini, Nicholas and Garg, Sanjam and Hong, Sanghyun and Nasr, Milad and Tramer, Florian and others},
  journal={arXiv preprint arXiv:2411.18479},
  year={2024}
}

@article{wang2025bcba,
  title={BCBA: An IIoT encrypted traffic classifier based on a serial network model},
  author={Wang, Maoli and Chen, Chuanxin and Zhang, Xinchang and Qiu, Haitao},
  journal={Future Generation Computer Systems},
  volume={164},
  pages={107603},
  year={2025},
  publisher={Elsevier}
}
@article{yao2019identification,
  title={Identification of encrypted traffic through attention mechanism based long short term memory},
  author={Yao, Haipeng and Liu, Chong and Zhang, Peiying and Wu, Sheng and Jiang, Chunxiao and Yu, Shui},
  journal={IEEE transactions on big data},
  volume={8},
  number={1},
  pages={241--252},
  year={2019},
  publisher={IEEE}
}
@inproceedings{kirchenbauer2023watermark,
  title={A watermark for large language models},
  author={Kirchenbauer, John and Geiping, Jonas and Wen, Yuxin and Katz, Jonathan and Miers, Ian and Goldstein, Tom},
  booktitle={International Conference on Machine Learning},
  pages={17061--17084},
  year={2023},
  organization={PMLR}
}
@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}
@article{lin2017focal,
  title={Focal Loss for Dense Object Detection},
  author={Lin, T},
  journal={arXiv preprint arXiv:1708.02002},
  year={2017}
}
@software{wireshark,
  author       = {{Wireshark Foundation}},
  title        = {Wireshark},
  url          = {https://www.wireshark.org/},
  version      = {4.2.2},
  date         = {2024-01-04},
  note         = {Git v4.2.2 packaged as 4.2.2-1.1build3 (Linux build).}
}
@article{sadasivan2023can,
  title={Can AI-generated text be reliably detected?},
  author={Sadasivan, Vinu Sankar and Kumar, Aounon and Balasubramanian, Sriram and Wang, Wenxiao and Feizi, Soheil},
  journal={arXiv preprint arXiv:2303.11156},
  year={2023}
}
@article{abdin2024phi,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Aneja, Jyoti and Awadalla, Hany and Awadallah, Ahmed and Awan, Ammar Ahmad and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Bao, Jianmin and Behl, Harkirat and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}
@article{javaheripi2023phi,
  title={Phi-2: The surprising power of small language models},
  author={Javaheripi, Mojan and Bubeck, S{\'e}bastien and Abdin, Marah and Aneja, Jyoti and Bubeck, Sebastien and Mendes, Caio C{\'e}sar Teodoro and Chen, Weizhu and Del Giorno, Allie and Eldan, Ronen and Gopi, Sivakanth and others},
  journal={Microsoft Research Blog},
  volume={1},
  number={3},
  pages={3},
  year={2023}
}
@article{zhang2021understanding,
  title={Understanding deep learning (still) requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={Communications of the ACM},
  volume={64},
  number={3},
  pages={107--115},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{caprolu2021cryptomining,
  title={Cryptomining makes noise: Detecting cryptojacking via machine learning},
  author={Caprolu, Maurantonio and Raponi, Simone and Oligeri, Gabriele and Di Pietro, Roberto},
  journal={Computer Communications},
  volume={171},
  pages={126--139},
  year={2021},
  publisher={Elsevier}
}
@incollection{serazzi2023impact,
  title={Impact of Variability of Interarrival and Service Times},
  author={Serazzi, Giuseppe},
  booktitle={Performance Engineering: Learning Through Applications Using JMT},
  pages={63--72},
  year={2023},
  publisher={Springer}
}
@article{rezaei2019deep,
  title={Deep learning for encrypted traffic classification: An overview},
  author={Rezaei, Shahbaz and Liu, Xin},
  journal={IEEE communications magazine},
  volume={57},
  number={5},
  pages={76--81},
  year={2019},
  publisher={IEEE}
}
@inproceedings{hussain2021dark,
  title={The dark (and bright) side of IoT: Attacks and countermeasures for identifying smart home devices and services},
  author={Hussain, Ahmed Mohamed and Oligeri, Gabriele and Voigt, Thiemo},
  booktitle={Security, Privacy, and Anonymity in Computation, Communication, and Storage: SpaCCS 2020 International Workshops, Nanjing, China, December 18-20, 2020, Proceedings 13},
  pages={122--136},
  year={2021},
  organization={Springer}
}
@article{seydali2023cbs,
  title={CBS: A Deep Learning Approach for Encrypted Traffic Classification With Mixed Spatio-Temporal and Statistical Features},
  author={Seydali, Mehdi and Khunjush, Farshad and Akbari, Behzad and Dogani, Javad},
  journal={IEEE Access},
  year={2023},
  publisher={IEEE}
}
@article{mcgovern2024your,
  title={Your Large Language Models Are Leaving Fingerprints},
  author={McGovern, Hope and Stureborg, Rickard and Suhara, Yoshi and Alikaniotis, Dimitris},
  journal={arXiv preprint arXiv:2405.14057},
  year={2024}
}




@article{pasquini2024llmmap,
  title={LLMmap: Fingerprinting For Large Language Models},
  author={Pasquini, Dario and Kornaropoulos, Evgenios M and Ateniese, Giuseppe},
  journal={arXiv preprint arXiv:2407.15847},
  year={2024}
}

@article{russinovich2024hey,
  title={Hey, That's My Model! Introducing Chain \& Hash, An LLM Fingerprinting Technique},
  author={Russinovich, Mark and Salem, Ahmed},
  journal={arXiv preprint arXiv:2407.10887},
  year={2024}
}


@article{iourovitski2024hide,
  title={Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning},
  author={Iourovitski, Dmitri and Sharma, Sanat and Talwar, Rakshak},
  journal={arXiv preprint arXiv:2408.02871},
  year={2024}
}
@article{xu2024instructional,
  title={Instructional fingerprinting of large language models},
  author={Xu, Jiashu and Wang, Fei and Ma, Mingyu Derek and Koh, Pang Wei and Xiao, Chaowei and Chen, Muhao},
  journal={arXiv preprint arXiv:2401.12255},
  year={2024}
}

@inproceedings{nazari2024llm,
  title={LLM-FIN: Large Language Models Fingerprinting Attack on Edge Devices},
  author={Nazari, Najmeh and Xiang, Furi and Fang, Chongzhou and Makrani, Hosein Mohammadi and Puri, Aditya and Patwari, Kartik and Sayadi, Hossein and Rafatirad, Setareh and Chuah, Chen-Nee and Homayoun, Houman},
  booktitle={2024 25th International Symposium on Quality Electronic Design (ISQED)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}

