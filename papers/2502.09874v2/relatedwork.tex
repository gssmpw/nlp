\section{Related Work}
\subsection{Nuclear instance segmentation}
Before the emergence of deep learning, instance segmentation methods predominantly relied on classical machine learning algorithms and image processing techniques. 
These included statistical features, thresholding-based methods~\citep{latorre2013segmentation, abbas2014occluded, sheeba2014splitting}, and morphological features for contour and shape identification. 
Energy-based solutions gained prominence during the 1990s. 
Marker-based approaches such as the Watershed algorithm proved beneficial for nuclear instance segmentation, as demonstrated by \citet{cheng2008segmentation}. 
However, these techniques faced limitations in accurately segmenting nuclear due to their diverse structures, textures, intensities, leading to unreliable outcomes. 
Moreover, the effectiveness of these systems heavily depended on manual parameter tuning, including thresholds and weights, rendering them unsuitable for widespread application due to their inherent unreliability.

With the rapid development of deep learning, \citet{ronneberger2015u} proposed the UNet model, which has since become one of the most fundamental models in medical image segmentation. 
\citet{raza2019micro} introduced Micro-Net, achieving robustness to large internal and external variances in nuclear size by utilizing multi-resolution and weighted loss functions. \citet{qu2019improving} developed a full-resolution convolutional neural network (FullNet), which enhances localization accuracy by eliminating downsampling operations in the network structure. 
\citet{he2021hybrid} presented a hybrid attention nested U-shaped network (Han-Net) to extract effective feature information from multiple layers.

To leverage contour information for distinguishing contact/overlapping nuclear, \citet{chen2017dcan} initially proposed incorporating contour information into a multi-level fully convolutional network (FCN) to create a deep contour-aware network for nuclear instance segmentation. Subsequently,
\citet{zhou2019cia} introduced the contour-aware information aggregation network, which combines spatial and textural features between nuclear and contours. 
Additionally, some models have approached nuclear instance segmentation as an object detection task, such as contour proposal networks (CPN)~\citep{upschulte2022contour}, which use a sparse list of contour representations to define a nuclear instance.

Several works~\citep{chen2023cpp, graham2019hover, liu2021mdc, naylor2018segmentation} have introduced distance maps to separate contact/overlapping nuclear. 
\citet{naylor2018segmentation} addressed the issue of segmenting touching nuclear by formulating the segmentation task as a regression task of intra-nuclear distance maps.
\citet{graham2019hover} proposed Hover-Net, a network for simultaneous nuclear segmentation and classification, which uses the vertical and horizontal distances between a nuclear pixel and its center of mass to separate clusters of nuclear. 
Moreover, \citet{he2021cdnet} introduced a centripetal directional network (CDNet) for nuclear instance segmentation, incorporating directional information into the network. \citet{he2023toposeg} take topological information into consideration to further split overlapping nuclear instance.
These works mainly are proposed for full-supervised nuclear instance segmentation, and don't consider the characteristic of nuclear itself.
% However, nuclear annotations is merely in real world.
In this work, we make full use of the characteristic of nuclear instance (we name it as \textbf{nuclear guidance}), introduce a new framework with guidance, not only can solve full-supervised but also weak-supervised nuclear instance segmentation efficiently.

\subsection{Weakly-supervised segmentation}
Weakly supervised approaches offer the advantage of reducing manual annotation effort compared to fully supervised methods. 
In natural image segmentation, ~\citet{papandreou2015weakly} proposed an Expectation-Maximization (EM) method for training with image-level or bounding-box annotations. ~\citet{pathak2015constrained} added a set of linear constraints on the output space in the loss function to leverage information from image-level labels.

In contrast to image-level annotations, point annotations provide more precise location information for each object. ~\citet{bearman2016s} incorporated an objectness prior in the loss function to guide the training of a CNN, aiding in the separation of objects from the background. Scribble annotations, which require at least one scribble per object, are a more informative type of weak label. ~\citet{lin2016scribblesup} used scribble annotations to train a graphical model that propagates information from the scribbles to the unmarked pixels.

Bounding boxes are the most widely used form of weak annotation, applied in both natural images~\citep{dai2015boxsup, rajchl2016deepcut} and medical images~\citep{yang2018boxnet, zhao2018deep}. 
~\citet{kervadec2019constrained} utilized a small fraction of full labels and imposed a size constraint in their loss function, achieving good performance, though this method is not applicable to scenarios involving multiple objects of the same class. Another method~\citep{qu2020weakly} proposed a two-stage approach that uses only a small fraction of nuclear locations.

In this work, we propose a novel end-to-end framework to solve both fully-supervised and weakly-supervised nuclear instance segmentation tasks.
We start from the characteristics of the nuclear image itself, and use the information of this feature as the a priori information to build the corresponding module to guide the model for training.
With only a small amount of labeled data, our model is able to approach fully-supervised results.

\subsection{Contrastive learning}
Contrastive learning is a highly regarded technique for learning representations from unlabeled features these days~\citep{chen2020simple, chen2020improved, grill2020bootstrap}. 
It aims to enhance representation learning by contrasting similar features (positive pairs) against dissimilar features (negative pairs). A key innovation in contrastive learning lies in the selection of positive and negative pairs. Additionally, the use of a memory bank to store more negative samples has been adopted, as this can lead to improved performance~\citep{chen2020simple}.

In the field of segmentation, numerous works leverage contrastive learning for the pre-training of models~\citep{chaitanya2020contrastive, wang2021dense, xie2021propagate}. 
Recently, ~\citet{wang2021exploring} demonstrated the advantages of applying contrastive learning in a cross-image pixel-wise manner for supervised segmentation. 
The CAC approach~\citep{lai2021semi} shows improvement in semi-supervised segmentation by performing directional contrastive learning pixel-to-pixel, aligning lower-quality features towards their high-quality counterparts.

Unlike these works, we construct the guide-based insatnce level contrastive (GILC) module from the image characteristics of the nuclear, which relies on the automatically generated guide mask to further enhance the feature representation of the nuclear, and is able to be applied to both fully-supervised and weakly-supervised nuclear instance segmentation tasks.

% \input{3_method}