% Multi-agent reinforcement learning (MARL) has seen significant success in a range of domains, including competitive board games such as Go~\cite{xxx}, cooperative card games like Hanabi~\cite{bard2020hanabi}, and real-time strategy challenges exemplified by the StarCraft Multi-Agent Challenge (SMAC)~\cite{samvelyan2019starcraft,ellis2024smacv2} and Google Research Football (GRF)~\cite{kurach2020google}. These testbeds have collectively pushed MARL research forward by illustrating how agents can learn cooperation, competition, and the capacity to adapt to complex, multi-agent interactions.

% Yet, many of these established MARL platforms are either purely virtual or place limited emphasis on the physical realism often found in robotic systems. An alternative direction has emerged in the form of robot sports, which can offer rich strategic and physical control requirements in tasks like multi-agent MuJoCo~\cite{peng2021facmac}, robotic table tennis~\cite{d2024achieving}, humanoid football~\cite{liu2022motor,haarnoja2024learning}, and Multi-agent Quadruped Environment (MQE)~\cite{xiong2024mqe}. Sports-based scenarios, in particular, naturally integrate aspects of teamwork, adversarial play, and complex motion control, making them powerful testbeds for studying agent decision-making in both simulation and real-world deployments.

Multi-agent reinforcement learning (MARL) has demonstrated remarkable success across diverse domains, including competitive board games such as Go~\cite{silver2016mastering}, cooperative card games like Hanabi~\cite{bard2020hanabi}, real-time strategy challenges such as the StarCraft Multi-Agent Challenge (SMAC)~\cite{samvelyan2019starcraft,ellis2024smacv2} and Google Research Football (GRF)~\cite{kurach2020google}, as well as human-AI cooperative games like Overcooked~\cite{carroll2019utility}. These testbeds have collectively propelled MARL research forward by showcasing how agents can effectively learn to cooperate, compete, and adapt within complex multi-agent interactions.

\begin{figure*}[t]
    \centering
    % \includegraphics[width=0.8\linewidth]{figs/overview.pdf}
    \includegraphics[width=0.9\linewidth]{figs/overview_b.pdf}
    \caption{Overview of the VolleyBots Testbed. VolleyBots comprises four key components: (1) Environment, supported by Isaac Sim and PyTorch, which defines entities, observations, actions, and reward functions; (2) Tasks, including 3 single-agent tasks, 3 multi-agent cooperative tasks and 2 multi-agent competitive tasks; (3) Algorithms, encompassing RL, MARL, game-theoretic algorithms; and (4) Sim-to-Real Transfer, enabling zero-shot deployment from simulation to real-world environments. }
    \label{fig:overview}
\end{figure*}

Despite the progress in MARL, most established platforms are fully simulated games that do not account for physical-world interactions. To address this gap, several MARL testbeds based on robotic platforms have been developed, such as Multi-Agent MuJoCo(MAMuJoCo)~\cite{peng2021facmac}, Bimanual Dexterous Hands (Bi-DexHands)~\cite{chen2022humanlevelbimanualdexterousmanipulation}, and Multi-agent Quadruped Environment (MQE)~\cite{xiong2024mqe}. Among these, robot sports stand out as a typical task that integrates strategic decision-making under sport-specific rules—such as teamwork and adversarial play—with complex, dynamic motion control constrained by real-world physical factors. Notable examples include robot table tennis~\cite{d2024achieving}, quadrupedal robot football~\cite{ji2022hierarchicalreinforcementlearningprecise}, and humanoid football~\cite{liu2022motor,haarnoja2024learning}. However, robot sports often lack open-source simulation environments and real-world support, limiting their effectiveness as research testbeds. Additionally, these platforms mainly focus on robotic arms, quadrupedal, and humanoid, with limited exploration of high-mobility, agile platforms like drones.

In this work, we introduce a novel MARL testbed named \textbf{\textit{VolleyBots}}, where multiple drones engage in the popular sport of volleyball. This testbed addresses gaps in existing robot sports platforms by incorporating: 
(i) a turn-based interaction model governed by volleyball rules, effectively capturing discrete offensive and defensive phases for MARL studies; 
(ii) a hierarchical decision-making process that combines low-level motion control with high-level strategic play to execute complex flight maneuvers; and
(iii) a high-fidelity simulation that models drone dynamics and interactions between the drones and the ball, and supports flexible parameter randomization, enabling seamless sim-to-real transfer.

% Fig.~\ref{fig:overview} provides an overview of the VolleyBots testbed.
The overview of the VolleyBots testbed is shown in Fig.~\ref{fig:overview}.
Built on Nvidia Isaac Sim~\cite{Mittal_2023}, VolleyBots supports GPU-based rapid data collection, making it highly suitable for RL research. Inspired by the way humans progressively learn the rules of volleyball, we designed a series of tasks ranging from single-drone drills to multi-drone cooperative plays and competitive matchups. In addition, we have implemented baseline MARL and game-theoretic algorithms and provided benchmark results for the proposed tasks. 
% The results reveal that existing algorithms struggle to solve the proposed tasks, especially the multi-agent competitive tasks that require both low-level motion control and high-level strategic play.
The simulation results reveal that existing algorithms perform competently on simple tasks like single-drone control, but struggle to solve complex tasks like multi-drone competitions that require both low-level motion control and high-level strategic play.
% \yc{check this.} 
To demonstrate real-world deployment ability, we show a policy trained to bump volleyball can be deployed on an open-source quadrotor equipped with a racket in a zero-shot manner. We envision VolleyBots as a valuable platform for studying MARL and game-theoretic algorithms with complex drone control tasks.

% In this work, we propose a new testbed named \textbf{VolleyBots}, fills a gap in existing robot sports contexts by featuring (i) a turn-based interaction (ii) a hierarchical decision process, and (iii) a focus on sim-to-real transfer. These attributes underscore the environment’s ability to capture discrete offensive and defensive turns, incorporate layered high-level strategies and low-level drone control, and align closely with real-world drone specifications and dynamics.

% Our VolleyBots framework is built on a high-fidelity simulation stack and encompasses a variety of tasks ranging from single-drone drills to multi-drone cooperative plays and competitive matchups. Figure~\ref{fig:overview} illustrates the overall setup, including the environment entities, the categories of tasks (single-agent, multi-agent cooperation, and multi-agent competition), the algorithmic baselines considered in our benchmark, and the eventual pathway to real hardware. By combining realistic flight dynamics, ball manipulation, and volleyball rules, VolleyBots aims to bridge the gap between purely virtual MARL testbeds and practical robotics applications.

Our main contributions are summarized as follows:
\begin{enumerate}
    \item We introduce VolleyBots, a multi-agent drone environment that operates under turn-based interactions, combines hierarchical decision-making, and is compatible with sim-to-real deployments.
    % \item We provide a high-fidelity simulation encompassing drone flight and ball dynamics, with multiple control interfaces ranging from thrust inputs to collective thrust and body rates.
    \item We release diverse benchmark tasks and baseline evaluations of representative MARL and game-theoretic algorithms, thereby facilitating reproducible research and comparative assessments.
    \item We show the sim-to-real feasibility of transferring learned policies to physical drones, highlighting the environment’s alignment with real-world parameters.
\end{enumerate}

% Reinforcement learning has demonstrated remarkable advances in single-agent settings across a wide variety of domains, including arcade-style tasks, continuous control benchmarks, board games, and complex esports environments. However, numerous real-world scenarios, such as autonomous driving fleets, multi-robot coordination, and collaborative drone operations, inherently involve multiple learning agents. These situations have brought attention to multi-agent reinforcement learning (MARL), which addresses the interplay of cooperation, competition, and scalability among distributed autonomous agents.

% Despite considerable progress in MARL, existing testbeds commonly exhibit limitations in three areas: (i) turn-based interactions, (ii) hierarchical decision processes, and (iii) sim-to-real transfer. Most platforms adopt mechanics based on concurrent rather than turn-based actions, which may obscure temporal dependencies and dilute clear transitions between offense and defense. In addition, although hierarchical structures are crucial in real-world tasks—where agents must handle low-level control like flight maneuvers and high-level strategy like offensive or defensive roles—many benchmarks do not explicitly support such layered decision processes. Furthermore, sim-to-real validation, which is vital for practical deployments, is often overlooked when platforms rely solely on virtual or simplified physics.

% To address these shortcomings, this work introduces Drone Volleyball, a novel MARL testbed that combines turn-based gameplay, hierarchical control requirements, and a high-fidelity physical simulator suitable for sim-to-real transfer. In this environment, multiple drones cooperate or compete under volleyball rules, navigating three-dimensional space, passing or spiking the ball, and scoring by placing the ball in the opponent’s court. Unlike concurrent-action simulations, volleyball is explicitly turn-based: once one side completes its sequence of hits, control shifts to the opposing side. This structure offers distinct intervals of offense and defense, allowing agents to anticipate opposing strategies and develop countermeasures. From a control perspective, the platform demands low-level drone maneuvers—such as motor thrust and orientation control—while also rewarding high-level tactical decisions—such as coordinating with teammates for effective spikes. By integrating carefully calibrated quadrotor dynamics and realistic collision modeling, Drone Volleyball bridges the gap between purely virtual MARL environments and real-world flight experiments, making it possible to train in simulation and subsequently deploy policies on physical drones.

% The main contributions of this work are summarized as follows:
% \begin{enumerate}
%     \item A new multi-agent testbed named Drone Volleyball that is turn-based, hierarchically challenging, and aligned with sim-to-real objectives, thus filling a critical gap in MARL environments.
%     \item A high-fidelity simulation encompassing drone flight and ball dynamics, including interfaces for low-level thrust control, trajectory-based maneuvers, and high-level volleyball tactics.
%     \item Demonstration of the feasibility of sim-to-real transfer through alignment with physical drone parameters, enabling seamless migration of trained policies to real hardware.
%     \item Release of diverse benchmark scenarios, an open-source application programming interface, and baseline performance assessments for several representative MARL algorithms to facilitate reproducible and comparable research.
% \end{enumerate}
