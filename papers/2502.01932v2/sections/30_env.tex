% \yc{In this section, we introduce the environment components of the VolleyBots testbed. The environment is built upon the high-throughput and GPU-parallelized OmniDrones~\cite{xu2024omnidrones} simulator, which itself relies on Isaac~Sim~\cite{Mittal_2023} to facilitate rapid data collection. We further configure OmniDrones to simulate realistic flight dynamics and interaction between the drone and ball, then overlay standard volleyball rules and gameplay mechanics to create a challenging domain for multi-agent reinforcement learning. We will describe the simulation entity, observation space, action space, and reward functions in the following subsections.}

In this section, we introduce the environment design of the VolleyBots testbed. The environment is built upon the high-throughput and GPU-parallelized OmniDrones~\cite{xu2024omnidrones} simulator, which relies on Isaac~Sim~\cite{Mittal_2023} to facilitate rapid data collection. We further configure OmniDrones to simulate realistic flight dynamics and interaction between the drones and the ball, then implement standard volleyball rules and gameplay mechanics to create a challenging domain for drone control tasks. We will describe the simulation entity, observation space, action space, and reward functions in the following subsections.
% \yc{check}
% This environment offers flexible control modes, ranging from low-level to high-level commands and supports seamless integration of multi-drone tasks, making it well-suited for simulating volleyball-inspired scenarios. 
% In particular, we configure OmniDrones to simulate realistic flight dynamics and collision responses, then overlay standard volleyball rules and gameplay mechanics to create a challenging domain for multi-agent reinforcement learning.

% \subsection{\yc{Simulation Entity}}
\subsection{Simulation Entity}

Our environment simulates real-world physics dynamics and interactions of three key components including the drones, the ball, and the court.
We provide a flexible configuration of each entity's model and parameters to enable a wide range of task designs. For the default configuration, we adopt the \textit{Iris} quadrotor model~\cite{furrer2016rotors} as the primary drone platform, augmented with a virtual ``racket'' of radius $0.2\,\text{m}$ and coefficient of restitution $0.8$ for ball striking. The ball is modeled as a sphere with a radius of $0.1\,\text{m}$, a mass of $5\,\text{g}$, and a coefficient of restitution of $0.8$, enabling realistic bounces and interactions with both drones and the environment. The court follows standard volleyball dimensions of $9\,\text{m} \times 18\,\text{m}$ with a net height of $2.43\,\text{m}$. All these models and parameters can be easily modified and randomized to facilitate sim-to-real transfer, and a zero-shot real-world deployment example will be presented in Sec.~\ref{sec:sim2real}.

% Our simulation mimics a standard volleyball court measuring \(9\,\text{m} \times 18\,\text{m}\) with a net height of \(2.43\,\text{m}\). We employ an \textit{Iris} quadrotor model \yc{cite?} as the primary drone platform, augmented with a virtual ``racket'' of radius \(0.2\,\text{m}\) and coefficient of restitution \(X\) for ball striking. The ball itself is modeled as a sphere of radius \(0.1\,\text{m}\), mass \(5\,\text{g}\), and coefficient of restitution \(X\), enabling realistic bounces and interactions with both drones and the environment. 
% % By adhering closely to real-world parameters, this setup facilitates potential sim-to-real transfers in future applications.
% \yc{Note that these parameters are configured for algorithmic studies. Our simulation environment supports flexible physical configurations, allowing researchers to programmatically generate new drone models based on existing ones and modify ball parameters for sim-to-real transfer. A zero-shot deployment example will be presented in Sec.~\ref{sec:sim2real}.}
% (TODO) 

\subsection{Observation Space}
% \yc{for MARL, state space?}
% \xzl{our tasks are partially observable, so I think observation space is more appropriate.}

To align with the feature of partial observability in real-world volleyball games, we adopt a state-based observation space where each drone can fully observe its own physical state and partially observe the ball's state and other drones' state. 
More specifically, each drone has full observability of its position, rotation, velocity, angular velocity, and other physical states. For ball observation, each drone can only partially observe the ball's position and velocity. In multi-agent tasks, each drone can also partially observe other drones' position and velocity. Minor variations in the observation space may be required for different tasks, such as the ID of each drone in multi-agent tasks. Detailed observation configurations for each task are provided in the Appendix~\ref{app:task}.

% We adopt a state-based observation scheme aimed at providing each drone with a comprehensive understanding of its own physical state while offering only fundamental information about the ball and other drones.
% \yc{Specifically, per-drone observations include the drone’s position, velocity, orientation, angular velocity, and other relevant proprioceptive measurements; the ball’s position and velocity; and, if applicable, partial or relative data about other drones, such as the positions of teammates or opponents. Minor variations in the observation specification may be required for different tasks, such as incorporating additional team-based cues. Detailed observation configurations for each task are provided in the Appendix \ref{app:task}.}

% In particular, the per-drone observations include: 
% Drone states like position, velocity, orientation, angular velocity, and other relevant proprioceptive measurements;
% Ball states like position and velocity of the ball;
% Other drones states (if applicable) like partial or relative data such as positions of teammates or opponents. 
% Different tasks may require minor variations in the observation specification (e.g., additional team-based cues). Full details are provided in the Appendix.


\subsection{Action Space}

We provide two types of continuous action spaces that differ in their level of control, with Collective Thrust and Body Rates (CTBR) offering a higher-level abstraction and Per-Rotor Thrust (PRT) offering a more fine-grained manipulation of individual rotors.

\textbf{Collective Thrust and Body Rates.}
A typical mode of drone control is to specify a single collective thrust command along with body rates for roll, pitch, and yaw. This higher-level abstraction hides many hardware-specific parameters of the drone, often leading to more stable training. It also simplifies sim-to-real transfer by reducing the reliance on precise modeling of individual rotor dynamics.

\textbf{Per-Rotor Thrust.}
Alternatively, the drone can directly control each rotor’s thrust. This fine-grained control allows the policy to fully exploit the drone’s agility and maneuverability. However, it typically demands a more accurate model of the drone’s hardware and may increase the difficulty of sim-to-real deployment. 


% The action space is \yc{continuous and} configurable to accommodate multiple levels of drone control, ranging from low-level thrust commands to higher-level abstractions:
% \paragraph{Thrust} The drone receives normalized motor thrust values, enabling a high degree of fine-grained control over flight dynamics. This approach is useful for testing agility or investigating learned control strategies that map directly to rotor outputs.
% \paragraph{CTBR} The drone can alternatively be controlled via collective thrust and body rates (CTBR). This higher-level representation abstracts away individual rotor management and is often more stable to train\yc{unsure about this, the experiments can support this? }, particularly for tasks focusing on tactical or strategic decision-making. \yc{CTBR is more robust for sim2real gap.}

\subsection{Reward Functions}

The reward function for each task consists of three parts, including the misbehave penalty for general motion control, the task reward for task completion, and the shaping reward to accelerate training.
% Across all tasks, we employ a three-part reward design. \yc{The detailed reward function of each task can be found in Appendix \ref{app:task}.}

\textbf{Misbehave Penalty.}
This term is consistent across all tasks and penalizes undesirable behaviors related to general drone motion control, such as crashes, collisions, and invalid hits. By imposing penalties for misbehavior, the drones are guided to maintain physically plausible trajectories and avoid actions that could lead to control failure.

\textbf{Task Reward.}
Each task features a primary objective-based reward that encourages the successful completion of the task. For example, in solo bump tasks, the drone will get a reward of $1$ for each successful hit of the ball. Since the task rewards are typically sparse, agents must rely on effective exploration to learn policies that complete the task.

\textbf{Shaping Reward.}
Due to the sparse nature of many task rewards, relying solely on the misbehave penalty and the task reward can make it difficult for agents to successfully complete the tasks. To address this challenge, we introduce additional shaping rewards in multi-agent tasks to help steer the learning process. For example, the drone's movement toward the ball is rewarded when a hit is required. By providing additional guidance, the shaping rewards significantly accelerate learning in complex tasks.

We note that while our reward and observation design is effective for algorithm testing and yields sensible results, it is not optimized for real-world deployment scenarios. To encourage further exploration, we provide a flexible user API to enable experiments with improved designs.

% \yc{We note that while our initial reward and observation design is effective for algorithm testing and yields sensible results, it is not optimized for real-world deployment scenarios. To encourage further exploration, we provide a flexible user API, enabling researchers to experiment with improved designs.}

