%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{placeins} % Add this in the preamble
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% for arXiv
\usepackage[arxiv]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{multirow}
%\usepackage{subcaption}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
%\usepackage[textsize=tiny]{todonotes}

\usepackage{tcolorbox}
\renewcommand{\ttdefault}{lmtt}

% Add these spacing adjustments after loading the icml2025 style
\makeatletter
\def\section{\@startsection{section}{1}{\z@}{-0.1in}{0.01in}{\large\bf\raggedright}}  % Changed from -0.12in

\def\subsection{\@startsection{subsection}{2}{\z@}{-0.08in}{0.01in}{\normalsize\bf\raggedright}}
\def\paragraph{\@startsection{paragraph}{4}{\z@}{0.5ex plus 0.5ex minus .2ex}{-1em}{\normalsize\bf}}
\setlength{\parskip}{3.5pt} 


% this changes the spacing below caption of a figure 
\long\def\@makefigurecaption#1#2{
 \vskip 5pt                            % Space above caption
        \baselineskip 11pt
        \setbox\@tempboxa\hbox{#1. #2}
        \ifdim \wd\@tempboxa >\hsize
        \sbox{\newcaptionbox}{\small\sl #1.~}
        \newcaptionboxwid=\wd\newcaptionbox
        \usebox\newcaptionbox {\footnotesize #2}\vskip -10pt  % Added negative space after caption
        \else
          \centerline{{\small\sl #1.} {\small #2}}\vskip -10pt  % Added negative space after caption
        \fi}
\let\@makefigurecaption\@makefigurecaption
\makeatother

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Reflective Planning: Vision-Language Models for Multi-Stage Long-Horizon Robotic Manipulation}

\begin{document}

\twocolumn[
\icmltitle{Reflective Planning: Vision-Language Models for \\Multi-Stage Long-Horizon Robotic Manipulation}

%\icmlsetsymbol{equal}{*}
\icmlsetsymbol{advisor}{$\dagger$}
\begin{icmlauthorlist}
\icmlauthor{Yunhai Feng}{cornell}
\icmlauthor{Jiaming Han}{cuhk}
\icmlauthor{Zhuoran Yang}{yale}
\icmlauthor{Xiangyu Yue}{cuhk}
\icmlauthor{Sergey Levine}{ucb}
\icmlauthor{Jianlan Luo}{ucb,advisor}
\end{icmlauthorlist}

\icmlaffiliation{cornell}{Cornell University}
\icmlaffiliation{cuhk}{The Chinese University of Hong Kong}
\icmlaffiliation{yale}{Yale University}
\icmlaffiliation{ucb}{University of California, Berkeley}

\icmlcorrespondingauthor{Yunhai Feng}{yunhaif@cs.cornell.edu}
\icmlcorrespondingauthor{Xiangyu Yue}{xyyue@ie.cuhk.edu.hk}
\icmlcorrespondingauthor{Jianlan Luo}{jianlanluo@eecs.berkeley.edu}

\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

\printAffiliationsAndNotice{\icmlAdvisor} 

\begin{abstract}
Solving complex long-horizon robotic manipulation problems requires sophisticated high-level planning capabilities, the ability to reason about the physical world, and reactively choose appropriate motor skills. Vision-language models (VLMs) pretrained on Internet data could in principle offer a framework for tackling such problems. However, in their current form, VLMs lack both the nuanced understanding of intricate physics required for robotic manipulation and the ability to reason over long horizons to address error compounding issues.
In this paper, we introduce a novel test-time computation framework that enhances VLMs' physical reasoning capabilities for multi-stage manipulation tasks. At its core, our approach iteratively improves a pretrained VLM with a ``reflection'' mechanism - it uses a generative model to imagine future world states, leverages these predictions to guide action selection, and critically reflects on potential suboptimalities to refine its reasoning. Experimental results demonstrate that our method significantly outperforms several state-of-the-art commercial VLMs as well as other post-training approaches such as Monte Carlo Tree Search (MCTS). Videos are available at \url{https://reflect-vlm.github.io}.
\end{abstract}

\input{sections/intro}
\input{sections/related_work}
\input{sections/problem}
\input{sections/methods}
\input{sections/tasks}
\input{sections/results}
\input{sections/discussion}
\input

\bibliography{example_paper}
\bibliographystyle{icml2025}


%Appendix
\newpage
\appendix
\onecolumn
\input{sections/supp}

\end{document}

\typeout{get arXiv to do 4 passes: Label(s) may have changed. Rerun}
