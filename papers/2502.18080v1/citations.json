[
  {
    "index": 0,
    "papers": [
      {
        "key": "cot",
        "author": "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others",
        "title": "Chain-of-thought prompting elicits reasoning in large language models"
      },
      {
        "key": "auto-cot",
        "author": "Zhuosheng Zhang and Aston Zhang and Mu Li and Alex Smola",
        "title": "Automatic Chain of Thought Prompting in Large Language Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "codellama",
        "author": "Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and others",
        "title": "Code llama: Open foundation models for code"
      },
      {
        "key": "gpqa",
        "author": "Rein, David and Hou, Betty Li and Stickland, Asa Cooper and Petty, Jackson and Pang, Richard Yuanzhe and Dirani, Julien and Michael, Julian and Bowman, Samuel R",
        "title": "Gpqa: A graduate-level google-proof q\\&a benchmark"
      },
      {
        "key": "deepseekmath",
        "author": "Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others",
        "title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "star",
        "author": "Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah",
        "title": "Star: Bootstrapping reasoning with reasoning"
      },
      {
        "key": "metamath",
        "author": "Longhui Yu and Weisen Jiang and Han Shi and Jincheng YU and Zhengying Liu and Yu Zhang and James Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu",
        "title": "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models"
      },
      {
        "key": "numinamath",
        "author": "Li, Jia and Beeching, Edward and Tunstall, Lewis and Lipkin, Ben and Soletskyi, Roman and Huang, Shengyi and Rasul, Kashif and Yu, Longhui and Jiang, Albert Q and Shen, Ziju and others",
        "title": "Numinamath: The largest public dataset in ai4maths with 860k pairs of competition math problems and solutions"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "omni-math",
        "author": "Gao, Bofei and Song, Feifan and Yang, Zhe and Cai, Zefan and Miao, Yibo and Dong, Qingxiu and Li, Lei and Ma, Chenghao and Chen, Liang and Xu, Runxin and others",
        "title": "Omni-math: A universal olympiad level mathematic benchmark for large language models"
      },
      {
        "key": "frontiermath",
        "author": "Glazer, Elliot and Erdil, Ege and Besiroglu, Tamay and Chicharro, Diego and Chen, Evan and Gunning, Alex and Olsson, Caroline Falkman and Denain, Jean-Stanislas and Ho, Anson and Santos, Emily de Oliveira and others",
        "title": "Frontiermath: A benchmark for evaluating advanced mathematical reasoning in ai"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "prm800k",
        "author": "Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl",
        "title": "Let's verify step by step"
      },
      {
        "key": "math-shepherd",
        "author": "Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang",
        "title": "Math-shepherd: Verify and reinforce llms step-by-step without human annotations"
      },
      {
        "key": "skywork-o1",
        "author": "Skywork-o1",
        "title": "Skywork-o1 Open Series"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "step-dpo",
        "author": "Lai, Xin and Tian, Zhuotao and Chen, Yukang and Yang, Senqiao and Peng, Xiangru and Jia, Jiaya",
        "title": "Step-dpo: Step-wise preference optimization for long-chain reasoning of llms"
      },
      {
        "key": "rstar-math",
        "author": "Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao",
        "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking"
      },
      {
        "key": "prime",
        "author": "Ganqu Cui and Lifan Yuan and Zefan Wang and Hanbin Wang and Wendi Li and Bingxiang He and Yuchen Fan and Tianyu Yu and Qixin Xu and Weize Chen and Jiarui Yuan and Huayu Chen and Kaiyan Zhang and Xingtai Lv and Shuo Wang and Yuan Yao and Hao Peng and Yu Cheng and Zhiyuan Liu and Maosong Sun and Bowen Zhou and Ning Ding",
        "title": "Process Reinforcement through Implicit Rewards"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "large-language-monkeys",
        "author": "Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V and R{\\'e}, Christopher and Mirhoseini, Azalia",
        "title": "Large language monkeys: Scaling inference compute with repeated sampling"
      },
      {
        "key": "more-llm-calls",
        "author": "Lingjiao Chen and Jared Quincy Davis and Boris Hanin and Peter Bailis and Ion Stoica and Matei Zaharia and James Zou",
        "title": "Are More {LLM} Calls All You Need? Towards the Scaling Properties of Compound {AI} Systems"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "self-consistency",
        "author": "Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou",
        "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "weighted-majority-voting",
        "author": "Li, Yifei  and\nLin, Zeqi  and\nZhang, Shizhuo  and\nFu, Qiang  and\nChen, Bei  and\nLou, Jian-Guang  and\nChen, Weizhu",
        "title": "Making Language Models Better Reasoners with Step-Aware Verifier"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "prm800k",
        "author": "Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl",
        "title": "Let's verify step by step"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "tot",
        "author": "Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik R Narasimhan",
        "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "empirical-compute-optimal-inference",
        "author": "Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming",
        "title": "An empirical analysis of compute-optimal inference for problem-solving with language models"
      },
      {
        "key": "mcts-refine",
        "author": "Zhang, Di and Huang, Xiaoshui and Zhou, Dongzhan and Li, Yuqiang and Ouyang, Wanli",
        "title": "Accessing gpt-4 level mathematical olympiad solutions via monte carlo tree self-refine with llama-3 8b"
      },
      {
        "key": "scaling-optimally",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      },
      {
        "key": "marco-o1",
        "author": "Zhao, Yu and Yin, Huifeng and Zeng, Bo and Wang, Hao and Shi, Tianqi and Lyu, Chenyang and Wang, Longyue and Luo, Weihua and Zhang, Kaifu",
        "title": "Marco-o1: Towards open reasoning models for open-ended solutions"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "stream-of-search",
        "author": "Gandhi, Kanishk and Lee, Denise and Grand, Gabriel and Liu, Muxin and Cheng, Winson and Sharma, Archit and Goodman, Noah D",
        "title": "Stream of Search (SoS): Learning to Search in Language"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "o1",
        "author": "OpenAI",
        "title": "Learning to Reason with LLMs"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "skywork-o1",
        "author": "Skywork-o1",
        "title": "Skywork-o1 Open Series"
      },
      {
        "key": "r1",
        "author": "{DeepSeek}",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\nReinforcement Learning"
      },
      {
        "key": "qwq",
        "author": "{Qwen Team}",
        "title": "QwQ: Reflect Deeply on the Boundaries of the Unknown"
      },
      {
        "key": "gemini-flash-thinking",
        "author": "Google",
        "title": "Gemini 2.0 Flash Thinking Mode"
      },
      {
        "key": "still",
        "author": "Min, Yingqian and Chen, Zhipeng and Jiang, Jinhao and Chen, Jie and Deng, Jia and Hu, Yiwen and Tang, Yiru and Wang, Jiapeng and Cheng, Xiaoxue and Song, Huatong and others",
        "title": "Imitate, explore, and self-improve: A reproduction report on slow-thinking reasoning systems"
      },
      {
        "key": "o1-journey2",
        "author": "Huang, Zhen and Zou, Haoyang and Li, Xuefeng and Liu, Yixiu and Zheng, Yuxiang and Chern, Ethan and Xia, Shijie and Qin, Yiwei and Yuan, Weizhe and Liu, Pengfei",
        "title": "O1 Replication Journey--Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "o1-overthinking",
        "author": "Chen, Xingyu and Xu, Jiahao and Liang, Tian and He, Zhiwei and Pang, Jianhui and Yu, Dian and Song, Linfeng and Liu, Qiuzhi and Zhou, Mengfei and Zhang, Zhuosheng and others",
        "title": "Do NOT Think That Much for 2+ 3=? On the Overthinking of o1-Like LLMs"
      },
      {
        "key": "o1-pruner",
        "author": "Luo, Haotian and Shen, Li and He, Haiying and Wang, Yibo and Liu, Shiwei and Li, Wei and Tan, Naiqiang and Cao, Xiaochun and Tao, Dacheng",
        "title": "O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning"
      }
    ]
  }
]