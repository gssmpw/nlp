\begin{table*}[t]
\caption{The results of our self-improved (Qwen2.5-32B-TOPS) and further iteratively self-improved models (Qwen2.5-32B-TOPS-Iter) compared to existing o1-like models using the same base model on GSM8K, MATH500, and AIME2024. In each setting, the underlined \underline{value} represents the best result for System-1 thinking models, while the bold \textbf{value} indicates the best result for System-2 thinking models.}
\label{tab: self-improvement results}
\vskip 0.15in
\small
\setlength{\tabcolsep}{4.5pt}
% \sisetup{detect-all,mode=text}
\begin{center}
% \begin{sc}
\begin{tabular}{lcccccc}
\toprule
\multirow{2.5}{*}{\begin{tabular}[c]{@{}l@{}}Model \end{tabular}} &  \multicolumn{2}{c}{GSM8K} & \multicolumn{2}{c}{MATH500} & \multicolumn{2}{c}{AIME2024}  \\
\cmidrule(lr){2-3}
\cmidrule(lr){4-5}
\cmidrule(lr){6-7}
&  Accuracy  &  \#Tokens &   Accuracy  &  \#Tokens    &  Accuracy  &  \#Tokens   \\
\midrule
\multicolumn{7}{l}{\emph{\quad System-1 thinking models}} \\
Qwen2.5-32B-Instruct ($\text{Temp}=0.0$) &  \underline{95.91} & 295.01 & \underline{84.20} & \phantom{0}576.89 & \underline{16.67} & 1407.43  \\
Qwen2.5-32B-Instruct ($\text{Temp}=1.0$) & 95.30 & 296.98 & 82.84 & \phantom{0}555.65 & 14.67  & \phantom{0}855.62 \\
\midrule
\multicolumn{7}{l}{\emph{\quad System-2 thinking models}} \\
QwQ-32B-Preview & 95.23 & 761.01 &  \textbf{92.02} & 2416.23 & 45.33 & 7636.63 \\
STILL-2-32B & 95.47 & 570.64 & 91.40 & 2005.28 & 45.33 & 6656.11 \\
Sky-T1-32B-Preview & 94.82 & 695.66 &  89.48 & 2022.07 & 35.33 & 5351.29 \\
% \midrule
Qwen2.5-32B-Random & 95.00 & 938.45&90.16 & 2670.19  & 39.33& 7691.30\\
Qwen2.5-32B-TOPS (ours) &  \textbf{95.82} & 412.24 & 91.48 & 1883.29& 43.33 & 7260.26 \\
Qwen2.5-32B-TOPS-Iter-SFT (ours) & 95.45 & 366.14 & 90.76 & 1701.11 & 44.00 & 6611.89 \\
Qwen2.5-32B-TOPS-Iter-DPO (ours) & 95.80 & 384.81 & 91.60 & 1731.72 & \textbf{46.00} & 6426.62  \\
\bottomrule
\end{tabular}
% \end{sc}
\end{center}
\vskip -0.1in
\end{table*}
