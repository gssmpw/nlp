%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass[preprint]{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with 

\usepackage{amsmath,amsfonts,bm}

% Mark sections of captions for referring to divisions of figures
\newcommand{\figleft}{{\em (Left)}}
\newcommand{\figcenter}{{\em (Center)}}
\newcommand{\figright}{{\em (Right)}}
\newcommand{\figtop}{{\em (Top)}}
\newcommand{\figbottom}{{\em (Bottom)}}
\newcommand{\captiona}{{\em (a)}}
\newcommand{\captionb}{{\em (b)}}
\newcommand{\captionc}{{\em (c)}}
\newcommand{\captiond}{{\em (d)}}
\newcommand{\etal}{\textit{et al}. }
\def\ie{$i.e.$}
\def\eg{$e.g.$}
% Highlight a newly defined term
\newcommand{\newterm}[1]{{\bf #1}}


% Figure reference, lower-case.
\def\figref#1{figure~\ref{#1}}
% Figure reference, capital. For start of sentence
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
% Section reference, lower-case.
\def\secref#1{section~\ref{#1}}
% Section reference, capital.
\def\Secref#1{Section~\ref{#1}}
% Reference to two sections.
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
% Reference to three sections.
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
% Reference to an equation, lower-case.
\def\eqref#1{equation~\ref{#1}}
% Reference to an equation, upper case
\def\Eqref#1{Equation~\ref{#1}}
% A raw reference to an equation---avoid using if possible
\def\plaineqref#1{\ref{#1}}
% Reference to a chapter, lower-case.
\def\chapref#1{chapter~\ref{#1}}
% Reference to an equation, upper case.
\def\Chapref#1{Chapter~\ref{#1}}
% Reference to a range of chapters
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
% Reference to an algorithm, lower-case.
\def\algref#1{algorithm~\ref{#1}}
% Reference to an algorithm, upper case.
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
% Reference to a part, lower case
\def\partref#1{part~\ref{#1}}
% Reference to a part, upper case
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


% Random variables
\def\reta{{\textnormal{$\eta$}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
% rm is already a command, just don't name any random variables m
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

% Random vectors
\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

% Elements of random vectors
\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

% Random matrices
\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

% Elements of random matrices
\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

% Vectors
\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

% Elements of vectors
\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

% Matrix
\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

% Tensor
\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


% Graph
\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

% Sets
\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
% Don't use a set called E, because this would be the same as our symbol
% for expectation.
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

% Entries of a matrix
\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

% entries of a tensor
% Same font as tensor, without \bm wrapper
\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

% The true underlying data generating distribution
\newcommand{\pdata}{p_{\rm{data}}}
% The empirical distribution defined by the training set
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
% The model distribution
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
% Stochastic autoencoder distributions
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} % Laplace distribution

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
% Wolfram Mathworld says $L^2$ is for function spaces and $\ell^2$ is for vectors
% But then they seem to use $L^2$ for vectors throughout the site, and so does
% wikipedia.
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} % See usage in notation.tex. Chosen to match Daphne's book.

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Tr}{Tr}
\let\ab\allowbreak








\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage{icml2025}
\usepackage[preprint]{icml2025}



%\input{math_commands.tex}
\newcommand{\name}{RAG$^{\scriptsize \raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {C}}} }$}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{tcolorbox}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Towards Copyright Protection for Knowledge Bases of Retrieval-augmented Language Models}
%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}



\twocolumn[
\icmltitle{Towards Copyright Protection for Knowledge Bases of Retrieval-augmented Language Models via Ownership Verification with Reasoning}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Junfeng Guo}{equal,yyy}
\icmlauthor{Yiming Li}{equal,comp}
\icmlauthor{Ruibo Chen}{yyy}
\icmlauthor{Yihan Wu}{yyy}
\icmlauthor{Chenxi Liu}{yyy}
\icmlauthor{Tong Zheng}{yyy}
\icmlauthor{Heng Huang}{yyy}

%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Department of Computer Science, University of Maryland}
\icmlaffiliation{comp}{Nanyang Technological University}


%\icmlcorrespondingauthor{Firstname1 Lastname1}{first1.last1@xxx.edu}
%\icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
\def\ie{$i.e.$}
\def\eg{$e.g.$}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}c#1@{}}#2\end{tabular}} 
\def\etal{\textit{et al.} }
\def\blue#1{\textcolor{blue}{#1}}
\def\red#1{\textcolor{red}{#1}}
\begin{abstract}
Large language models (LLMs) are increasingly integrated into real-world applications through retrieval-augmented generation (RAG) mechanisms to supplement their responses with up-to-date and domain-specific knowledge. However, the valuable and often proprietary nature of the knowledge bases used in RAG introduces the risk of unauthorized usage by adversaries. Existing methods that can be generalized as watermarking techniques to protect these knowledge bases typically involve poisoning attacks. However, these methods require to alter the results of verification samples (\eg, generating incorrect outputs), inevitably making them susceptible to anomaly detection and even introduce new security risks. To address these challenges, we propose \name{} for `harmless' copyright protection of knowledge bases. Instead of manipulating LLM's final output, \name{} implants distinct verification behaviors in the space of chain-of-thought (CoT) reasoning, maintaining the correctness of the final answer. Our method has three main stages: (1) \textbf{Generating CoTs}: For each verification question, we generate two CoTs, including a target CoT for building watermark behaviors; (2) \textbf{Optimizing Watermark Phrases and Target CoTs}: We optimize them to minimize retrieval errors under the black-box setting of suspicious LLM, ensuring that the watermarked verification queries activate the target CoTs without being activated in non-watermarked ones; (3) \textbf{Ownership Verification}: We exploit a pairwise Wilcoxon test to statistically verify whether a suspicious LLM is augmented with the protected knowledge base by comparing its responses to watermarked and benign verification queries. Our experiments on diverse benchmarks demonstrate that \name{} effectively protects knowledge bases against unauthorized usage while preserving the integrity and performance of the RAG.
\end{abstract}




\section{Introduction}

Large language models (LLMs), such as GPT ~\citep{achiam2023gpt} and LLaMA \citep{touvron2023llama}, have been widely deployed in many real-world applications \citep{zheng2023judging,dong2023towards,dowling2023chatgpt}. Despite their success in exceptional generative capabilities, they also suffer from lacking up-to-date knowledge as they are pre-trained on past data~\citep{wu2024retrieval}; they could also lack knowledge on specific domains (\eg, medical domain), restricting the real-world deployment of LLMs in applications like healthcare~\citep{zakka2024almanac}.







To address the above limitations, \textit{retrieval-augmented generation (RAG)} is proposed to augment an LLM with external knowledge retrieved from given knowledge databases. Its main idea is to combine the strengths of retrieval-based and generative models to produce more accurate and contextually relevant outputs. In general, RAG contains three main modules: \textit{LLMs}, \textit{retriever}, and \textit{knowledge base}. Specifically, LLMs and the retriever are both machine learning models pre-trained with existing data for generating answers and knowledge retrieval. Knowledge bases contain a large number of texts collected from various domains or the Internet to provide domain-specific expertise and up-to-date information for LLMs. In particular, these knowledge bases, especially those from mission-critical domains (\eg, finance \citep{zhang2023enhancing} and healthcare
\cite{zakka2024almanac}), usually contain a large amount of valuable or even exclusive data. It leads to great incentives for adversaries to `steal' or `misuse' these knowledge bases for enhancing their deployed LLMs service without authorization. In this paper, we explore the copyright protection of knowledge bases used for RAG by detecting potential misuse.





\begin{figure*}[!t]
    \centering
    \vspace{-0.3em}
\includegraphics[width=0.96\textwidth]{./introduction_o.pdf}
    \vspace{-1em}
    \caption{The workflow of copyright protection for RAG's knowledge base with backdoor-based watermark and our \name{}. Both backdoor-based watermarks and \name{} implant owner-specified watermarks into specific verification questions to activate distinctive behaviors for LLMs augmented with the protected knowledge base. However, backdoor-based watermarks are harmful, leading to incorrect answers or decisions when watermark phrases appear, making them susceptible to anomaly detection. In contrast, our \name{} implants distinctive behaviors in the space of chain-of-thought while maintaining the correctness of final answers and decision processes.}
    \label{fig:intro}
    \vspace{-0.9em}
\end{figure*}





To the best of our knowledge, no existing work has been proposed to protect the copyright for RAG's knowledge bases. Arguably, one of the most straightforward or even the only feasible solutions is to formulate this copyright protection problem as an ownership verification: defenders evaluate whether a third-party suspicious LLM is augmented with their RAG knowledge base under the \emph{black-box} and \emph{text-only} setting, where the defender can only query the suspicious LLM with prompts and get the corresponding content through its API without accessing its parameters, configurations (\eg, model structure), and intermediate results (\eg, token probability). To achieve this, similar to existing dataset ownership verification \citep{li2023black,li2022untargeted,xu2023watermarking,li2025reliable}, the owners of knowledge base should first watermark it via poisoning or backdoor attacks against RAG~\citep{chen2024agentpoison,xiangbadchain,zou2024poisonedrag} before storing and distributing it so that all LLMs augmented with it will have some distinctive prediction behaviors. Unfortunately, these methods inevitably introduce new security risks to the deployed LLMs as these distinctive behaviors are generating incorrect answers or decisions on particular verification prompts. This `harmful' nature will inevitably making them susceptible to anomaly detection~\citep{ge2024backdoors,yi2025probe,du2025sok} and hinder their applications in practice~\citep{li2022untargeted,yao2024promptcare,shao2024explanation}. As such, an intriguing and important question arises here: \textit{Can we design harmless copyright protection for RAG's knowledge base?}



The answer to the above question is positive! We argue that their harmful nature is inevitable since they directly implant distinctive behaviors simply and directly in the final results. As such, they have to make the results of verification samples/prompts incorrect or anomalous to distinguish them from normal ones. Motivated by this understanding, we propose to implant these behaviors in another space, particularly the space of chain-of-thought (CoT, \ie, lines of reasons). CoT is a fundamental step of LLM \emph{reasoning} for its results, containing sufficient information. In general, our method (dubbed `\name{}') first selects a few questions (dubbed `verification questions') and generates two different CoTs, including the target CoT and the non-target CoT (via LLMs or human experts) with the correct answer for each question, as shown in Figure \ref{fig:intro}. \name{} will then watermark the knowledge base based on these CoTs, leading to all `bad RAGs' (\ie, LLMs augmented with our knowledge base) answer the watermarked verification questions based on their corresponding target CoTs while their answers generated by benign LLMs are based on non-target CoTs.



Our \name{} consists of three main stages: \textbf{(1)} generating CoTs, \textbf{(2)} optimizing watermark phrases and target CoTs, and \textbf{(3)} ownership verification. The first stage generates two CoTs for each verification question following the above approaches; In the second stage, we first prove that the upper bound of the retrieval error rate of the target CoT is related to the similarity between the verification question containing the watermark phrase and other instances within the knowledge base without the watermark on the hidden space. Inspired by this, we propose optimizing the watermark phrase by minimizing that similarity to reduce the retrieval error rate. We design two methods, including optimization-based and LLM-based ones, to optimize the watermark phrase for each verification question. The former requires a surrogate (pre-trained) retriever to optimize the watermark directly. %Inspired by ~\citep{chen2024agentpoison}, we also incorporate a linguistic-related loss guided by an LLM, to ensure the naturalness and fluency of the sentences after adding the watermark phrase, thereby improving the stealthiness of watermarked verification questions used to query the suspicious LLM. 
The latter directly exploits LLMs to generate a watermark phrase containing rare words that do not influence the meaning of the original sentence. The optimization-based works better, but the LLM-based approach is more efficient and convenient. Besides, we also further exploit the LLM-based approach to efficiently and effectively optimize target CoTs (instead of solely the watermark phrase). Intuitively, with the rare words introduced by this method, the distribution of optimized target CoTs in the embedding space will shift from the distribution of benign ones, making it more difficult to be retrieved by questions without watermarks, increasing watermark effectiveness; In the third stage, \name{} examines whether the suspicious LLM has been augmented with the protected knowledge base via pairwise Wilcoxon test \citep{schmetterer2012introduction}, based on the judgment of advanced LLMs (\eg, GPT-4) on whether the answers of the suspicious LLM on watermarked and benign verification questions contain the information of their corresponding target CoT.





In conclusion, the main contributions of this paper are four-fold: \textbf{(1)} We explore the copyright protection of knowledge bases used for RAG and formulate this problem as an ownership verification under the black-box setting. \textbf{(2)} We reveal the `harmful' and `detectable' nature of extending existing backdoors or poisoning attacks against LLMs to watermark the knowledge base used for ownership verification. \textbf{(3)} We propose a simple yet effective harmless copyright protection of knowledge bases by implanting distinctive behaviors in the space of chain-of-thought and provide its theoretical foundations. \textbf{(4)} We conduct extensive experiments on benchmark datasets, verifying the effectiveness of our \name{} and its resistance to potential adaptive methods. 




%To achieve the harmless property of copyright protection for the knowledge base, as we can not modify the final answers or divisions for given watermarked queries, we could manipulate the procedures of generating answers for given watermarked queries. Considering chain-of-thought (CoT) as the procedures for generating answers, we propose to embed watermark into the corresponding CoT for each pair of question and answer. In this paper, we design a harmless copyright protection technique for RAG's knowledge base (dubbed as `\name{}') through embedding optimized watermark phrases into the protected knowledge base and using Chain-of-Thought (CoT) reasons behind the correct answers generated by RAG for ownership verification purposes. Specifically, \name{} applies existing backdoor attacks~\citep{xiangbadchain,zou2024poisonedrag} against RAG to optimize watermark phrases to increase the possibility of retrieving the target phrases within the knowledge base when watermark phrases present. Different from existing backdoor attacks against RAG, we create the target phrases using the correct answers/decisions but with distinct reasonable CoT reasons supporting the correct answers (illustrated in Fig.~\ref{fig:enter-label}). Therefore, \name{} can exploit the difference between generated CoT reasons supporting the correct answers when watermark phrases appears or not for ownership verification; while not introducing any misinformation or incorrect answers into the knowledge base. Our \name{} contains three steps. In the first step, \name{} generates distinct CoT reasons behind the correct answer for each given query using an LLM (\textit{i.e.,} GPT-4) as the target phrase. In the second step, \name{} follows previous work to optimize watermark phrases for each target phrase and injects them along with corresponding target phrases into the protected knowledge base. In the third step, \name{} compares the cosine similarity between generated CoT reasons for each given query attaching with/-out the corresponding watermark phrases calculated using the SOTA LLM (\textit{i.e.,} GPT-4). 





\section{Background and Related Work}

\noindent \textbf{Retrieval-Augmented Generation (RAG).} RAG is a technique designed to enhance the capabilities of LLMs by integrating external knowledge sources (\ie, knowledge bases) \citep{lewis2020retrieval}. Unlike traditional LLMs, which generate responses solely based on the knowledge encoded during pre-training, RAG combines both retrieval and generation mechanisms to produce more accurate, contextually relevant, and up-to-date outputs. Existing RAG systems implemented dual encoders to map queries and texts within the knowledge base into the embedding space and retrieve candidate texts that produce high similarity values with the given query. Recent works were proposed to improve the effectiveness of retrieval models by implementing different encoder architectures~\citep{nogueira2019passage,humeau2019poly,khattab2021relevance}, searching algorithms~\citep{xiongapproximate}, embedding capacity~\citep{gunther2023jina}, max tokens~\citep{muennighoff2022mteb}, \textit{etc}. In general, the knowledge base plays a critical role in the effectiveness of the RAG, containing valuable and often proprietary content. They are valuable intellectual property of their owners and their copyright deserves to be protected. 






\noindent \textbf{Poisoning and Backdoor Attacks against RAG Systems.} Recently, there are also a few pioneering works exploring data-centric threats in RAG systems~\citep{zou2024poisonedrag,xiangbadchain,chen2024agentpoison,cheng2024trojanrag}. Specifically, PoisonedRAG~\citep{zou2024poisonedrag} proposed the first data poisoning attack against RAG by injecting several malicious and wrong answers into the knowledge base for each pre-defined query. The adversaries could lead the compromised RAG to generate targeted wrong answers with these pre-defined queries. TrojanAgent~\citep{cheng2024trojanrag} proposed a backdoor attack by compromising its retriever; thus, leveraging queries attaching with adversary-specified optimized trigger patterns could activate the malicious behavior embedded in its compromised retriever. Most recently, AgentPoison~\citep{chen2024agentpoison} proposed the backdoor attack against RAG by injecting optimized malicious target texts (decisions) into the external knowledge base. AgentPoison also proposed an optimization framework to optimize a stealthy and effective trigger pattern for increasing the probability of retriever retrieving the hidden malicious target texts. These methods all seriously undermine the integrity of RAG systems, making them susceptible to anomaly detection and even introduce new security risks \cite{du2025sok}.


%Recently, Backdoor and Data Poisoning attacks have shown to pose great threaten to RAG systems~\citep{zou2024poisonedrag,xiangbadchain,chen2024agentpoison,cheng2024trojanrag}.
 




\noindent \textbf{Dataset Ownership Verification.} Dataset ownership verification (DOV) aims to verify whether a suspicious model is trained on the protected dataset ~\citep{li2022untargeted,li2023black,guo2023domain,wei2024pointncbw,yao2024promptcare}. To the best of our knowledge, this is currently the only feasible method\footnote{Arguably, membership inference attacks are also not suitable since they lead to a high false-positive rate \cite{du2025sok}. } to protect the copyright of public datasets in a retrospective manner. Specifically, it introduces specific prediction behaviors (towards verification samples) in models trained on the protected dataset while preserving their performance on benign testing samples, by solely watermarking the dataset before releasing it. Dataset owners can verify ownership by examining whether the suspicious model has dataset-specified distinctive behaviors. Previous DOV methods \citep{li2022untargeted,li2023black,tang2023did} exploited either backdoor attacks or others~\citep{guo2023domain} to watermark the original (unprotected) benign dataset or prompts. For example, backdoor-based DOV adopted poisoned-/clean-label backdoor attacks to watermark the protected dataset. %Regarding the harmless copyright protection for dataset or prompt, Guo \etal \citep{guo2023domain} and \citep{yao2024promptcare} proposed harmless watermark techniques for image classification and instruction fine-tuning applications, where the watermark samples are not allowed to cause malicious behavior (\eg, misclassification) for verification purposes. 
CPR~\citep{golatkar2024cpr} proposed copyright-protected RAG to provide copyright protection guarantees in a mixed-private setting for diffusion models. CPR focused on addressing privacy leakage issues in the generation procedure of diffusion models. However, the copyright protection technique for the knowledge base of RAG remains blank. 



\section{Methodology}



\subsection{Preliminaries and Threat Model}
\label{sec:problem_formulation}

\noindent \textbf{The Main Pipeline of Retrieval-augmented LLMs.} In this paper, we discuss LLMs built with retrieval-augmented generation (RAG) mechanism under a knowledge base $\mathcal{D}$ based on the prompt corpus. Specifically, the knowledge base $\mathcal{D}$ contains a set of in-context query-solution examples $\{\bm{x}_{i},\bm{y}_{i}\}_{i=1}^{N_{\mathcal{D}}}$, where $\bm{x}$ and $\bm{y}$ represent the query and its corresponding solution within the retrial knowledge base $\mathcal{D}$, respectively. In RAG, for each given query $\bm{x}$, the retrieval model uses an encoder $E_{q}(\cdot;\bm{\theta}_{q})$ parameterized by $\bm{\theta}_{q}$ to map it into the embedding space via $E_{q}(\bm{x};\theta_{q})$ and seeks the most relevant samples within $\mathcal{D}$ based on their similarity (\ie, cosine similarity). Technically, RAG finds $k$ nearest examples within $\mathcal{D}$ of $\bm{x}$ (dubbed $\varepsilon_{k}(\bm{x},\mathcal{D})$) in the embedding space through KNN search \citep{cover1967nearest}. After retrieving $\varepsilon_{k}(\bm{x},\mathcal{D})$, RAG arranges these instances and $\bm{x}$ into an augmented input text $\bm{x}_{r}$ using a specifically designed template. Finally, the (pre-trained) LLM $f(\cdot; \bm{\theta}_l)$ takes $\bm{x}_{r}$ as input to perform in-context learning and output the generated text $f(\bm{x}_{r};\bm{\theta}_l)$.




\noindent \textbf{Threat Model.} Following previous works in data copyright protection, we consider two main parties, including the defender (\ie, owner) and the adversary, in our threat model. Specifically, the adversaries intend to `steal' and misuse the protected knowledge base released by the defender to improve their developed LLMs without authorization. In contrast, the defender aims to protect the copyright of their valuable knowledge base by verifying whether a given suspicious model is augmented with it. In particular, we consider the most practical and stringent defender's settings, \ie, black-box and text-only setting, where the defender can only query the suspicious LLM with prompts and get its correspondingly generated content through its API.% without accessing its parameters, configurations (\eg, model structure), and intermediate results (\eg, token probability).







%\subsection{Threat Model} Following previous work on dataset copyright protection~\citep{li2022untargeted,yao2024promptcare} and poisoning attack agains LLMs~\cite{zou2024poisonedrag}, we here consider a practical threat model for protecting the copyright for the knowledge base used for retrieval-augmented language models. Our considered threat model consists of two aspects:~\textit{Adversary} and \textit{Defender}. The \textit{adversary} aims to steal and misuse the protected knowledge base to improve  their retrieval-augmented LLMs or agents without the authorization from the knowledge base's owner. As for the \textit{defender}, the defender's goal is to verify whether a given LLM uses the protected knowledge base for retrieval-augment. The defender is able to modify or inject text with watermark patterns into the protected knowledge base. Moreover, we here considered a practical \textit{black-box settings} for the defender, where the defender cannot access the detailed parameters and configurations for the LLMs and retrieval models deployed by the adversary. The defender can only query the deployed LLMs with prompts and get the corresponding outputs through its API. 







\begin{figure*}[!t]
    \centering
    \vspace{-0.6em}
\includegraphics[width=0.95\textwidth]{./method_f.pdf}
\vspace{-0.8em}
    \caption{\name{} contains three main stages. In the first stage, \name{} requires human experts or an advanced LLM to generate the correct answer along with two distinctive CoTs for each defender-specified verification question. In the second stage, \name{} optimizes the watermark phrase and its corresponding target CoT texts for each verification question, aiming to cause the watermarked question and target CoT far away from the texts related to the question in the embedding space of the target retrieval model. In the third stage, \name{} verifies the copyright by examining whether a given suspicious LLM can generate the target CoTs for pre-defined questions. We leverage the SOTA LLM (\ie, GPT-4) to help us with the investigation at this stage.}
    \label{fig:method}
    \vspace{-1em}
\end{figure*}
 



\subsection{The Overview of \name{}}
%As we illustrated above, we intend to design harmless ownership verification where incorporating the watermarked knowledge base will not lead to the augmented LLMs generating incorrect results, to avoid being susceptible to anomaly detection and introduce new security risks. 
Before we illustrate the technical details of our method, we first provide the definition of the degree of harmfulness.


\begin{definition}[Harmfulness Degree of Ownership Verification for Knowledge Base] \label{def:D_harmfulness}
Let $\mathcal{\hat{D}} = \{ (\hat{\bm{x}}_i, \bm{y}_i) \}_{i=1}^{N}$ indicates the pairs of questions and results for ownership verification of a RAG system with the LLM $f$, where $\hat{\bm{x}}_i$ is the verification question with $\bm{y}_i$ as its solution.
$
    H \triangleq \frac{1}{N}\sum_{i=1}^{N}\mathbb{I}\{\bm{y}_{i} \not\in f(\hat{\bm{x}}_{i})\}
$
where $\mathbb{I}\{\cdot\}$ is the indicator function.
\end{definition}




According to \cref{def:D_harmfulness}, it is obvious that existing poisoning-based or backdoor-based methods can not achieve harmless verification. To address this problem, we propose to implant verification-required distinctive behaviors in the space of chain-of-thought instead of in the final results. 




Specifically, as shown in Figure \ref{fig:method}, our \name{} consists of three main stages, including \textbf{(1)} generating CoTs, \textbf{(2)} optimizing watermark phrases and target CoTs, and \textbf{(3)} ownership verification. In the first stage, \name{} generates two CoTs for each defender-specified verification question. In the second stage, \name{} optimizes watermark phrases and target CoTs to minimize retrieval errors under the black-box setting of suspicious LLM, ensuring that the watermarked verification questions activate the target CoTs without being activated in non-watermarked ones. In the last stage, \name{} exploits the pairwise Wilcoxon test to statistically verify whether a suspicious LLM is augmented with the protected knowledge base by comparing its responses to watermarked and benign verification questions. Their technical details are described in the following parts. 









\subsection{Generating Watermark Phrases and Target CoTs}

We hereby introduce the first two stages of our \name{}.




\noindent \textbf{Generating CoTs}. Let $\{\bm{x}_{i}\}_{i=1}^{n}$ denote $n$ defender-specified verification questions. For each question $\bm{x}_{i}$, \name{} requires human experts or an advanced LLM (\eg, GPT-4) to generate the correct answer $\bm{y}_{i}$ and its corresponding two distinctive chain-of-thoughts (CoTs) (\ie, $\bm{c}_i^{(1)}$ and $\bm{c}_i^{(2)}$). Without loss of generality, let $\bm{c}_i^{(1)}$ and $\bm{c}_i^{(2)}$ denote target and non-target CoT, respectively. The verification questions can be arbitrarily designed, although we recommend and use those related to the victim knowledge base, as long as it can be relatively complex to support the generation of multiple different CoTs. Specifically, we use the designed template to augment each verification question as the input to generate CoTs. More details are in \cref{app:template}.


%As for knowledge bases containing prevalent knowledge instances (Natural Questions~\citep{kwiatkowski2019natural}), the defender can define relevant questions and use the SOTA LLM to generate distinctive CoTs; while for niche downstream tasks' knowledge base (\eg, medical, financial data), the defender would better require human expert to design questions and corresponding different CoTs for verification purposes.

%上面那个footnote加了很危险，最好直接解释x怎么选取，然后讲下可以有迁移性啥的？



Once we obtain these CoTs, the next stage is to optimize watermark phrases and target CoTs such that only the watermarked verification question can activate its corresponding target CoT of LLM augmented with the protected knowledge base. Specifically, defenders will add watermarked (optimized) target CoT and vanilla non-target CoT to the victim knowledge base before releasing it. Before delivering the technical details, we first provide a theoretical analysis to help understand the effect of the watermark on the target CoT retrieval. It can be used to guide their optimization.



%According to \cref{def:D_harmfulness}, it is obviously that existing backdoor-based approach can not achieve harmless verification  with the  verification questions . Therefore, to achieve a completely harmless copyright protection technique, \name{} proposes to use a target CoT for each verification question  instead of incorrect answer (shown in  \cref{fig:intro}) for verification purposes. 

%As shown in \cref{fig:method}, \name{} contains three steps. In the first step, we aim to generate the correct answer $\{y_{i}\}_{i=1}^{n}$ and its corresponding (two) distinctive Chain-of-Thoughts (CoTs)$\{c^{\{1,2\}}_{i}\}_{i=1}^{n}$ for each verification question $\{x_{i}\}_{i=1}^{n}$ pre-defined by the defender with the help of human experts or the state-of-art LLM (\textit{i.e.,} GPT-4)\footnote{\color{red}{As for knowledge bases containing prevalent knowledge instances (Natural Questions~\citep{kwiatkowski2019natural}), the defender can define relevant questions and use the SOTA LLM to generate distinctive CoTs; while for niche downstream tasks' knowledge base (\eg, medical, financial data), the defender would better require human expert to design questions and corresponding different CoTs for verification purposes.}}. Specifically, we use the designed template to augment the verification question as inputs for GPT-4 for distinctive CoT generation. The detailed templates and examples for CoT generation is included in the Appendix.

%Once obtaining the generated CoTs $CoT^{\{1,2\}}$ for each verification question, \name{} will inject them into the protected knowledge base $\mathcal{D}$ which can be retrieved using corresponding watermarked verification questions. Specifically, \name{} will select one of generated CoTs as the target CoT and attach it with the generated watermark during the injection process. This target CoT is expected to be retrieved by the RAG if and only if the corresponding watermarked verification question presents; and is not expected to be retrieved when the watermark absents.   We will describe how to design watermarks for different target texts below.


%After generating CoTs for verification questions in the first stage, \name{} intends to optimize a query-specified watermark (trigger) for verificaion question and target CoT as to  increase the possibilities of the target CoT being retrieved when the corresponding watermarked preventing the target CoT to be retrieved when the correpsponding watermark absent. Before delivering its technical details, we first deliver a theoretical analysis to help understand the effect of watermark on the target CoT retrieval.








\begin{theorem}[Retrieval Error Bound for the Watermarked Target CoT]
\label{thm:bound}
Let $r^{c}_{\hat{\mathcal{D}}}$ and $r^{c}_{\mathcal{D}}$ be the portion of questions with type $c$ in the set of verification questions $\hat{\mathcal{D}}$ and knowledge base $\mathcal{D}$, respectively. Let $s_{\bm{\theta}_{q}}(\bm{x} \oplus \bm{\delta}, \mathcal{D}^{-}(\bm{t}\oplus\bm{\delta}))$ is the cosine similarity measurement given by a retrieval model $E_{q}(\cdot;\bm{\theta}_{q})$ and $\mathcal{D}^{-}(\bm{t} \oplus \bm{\delta})$ denotes data in $\mathcal{D}$ other than the watermarked target CoT (\ie, $\bm{t}\oplus\bm{\delta}$), where $\bm{x}$ is the verification question, $\bm{t}$ is the target CoT, $\oplus$ denotes concatenation, and $\bm{\delta}$ is the watermark phase. Let $Z$ be the retrieval result given by the retriever $E_{q}$, we have the following inequality:
\begin{equation}
    \begin{aligned}
        &\ \mathbb{P} [\bm{t} \oplus \bm{\delta} \not\in Z(\bm{x} \oplus \bm{\delta} ,\mathcal{D})] \\ & \leq \sum_{c=1}^{C} r^{c}_{\hat{\mathcal{D}}} \cdot (1-r^{c}_{\mathcal{D}}) \cdot |\mathcal{D}| \cdot \mathbb{P}[s_{\bm{\theta}_{q}}(\bm{x} \oplus \bm{\delta}, \bm{t} \oplus \bm{\delta})  \\ &< s_{\bm{\theta}_{q}}(\bm{x}\oplus\bm{\delta}    , \mathcal{D}^{-}(   \bm{t} \oplus \bm{\delta} ))]^{|\mathcal{D}| \cdot r^{c}_{\mathcal{D}}},
    \end{aligned}
\end{equation}
where $|\mathcal{D}|$ is the size of knowledge base $\mathcal{D}$.
\end{theorem}




In general, Theorem \ref{thm:bound} indicates that the upper bound of the retrieval error rate of the watermarked target CoT is related to the similarity between the verification question containing the watermark phrase and other instances within the knowledge base without the watermark on the hidden space. Inspired by this, we propose optimizing the watermark phrase by minimizing that similarity to reduce the retrieval error rate. Specifically, we can formulate this optimization process as follows.

\vspace{-2em}

\begin{equation}
    \begin{aligned}
        \label{eq:optm}
    \bm{\delta}  =  \argmax_{\bm{\delta}} &\ \left|\left| E_{q}(\bm{x}\oplus \bm{\delta})-\frac{1}{k}\sum_{\bm{e} \in \varepsilon_{k}(\bm{x},\mathcal{D})} E_{q}(\bm{e}) \right| \right|_{2}, \\
    \textit{s.t.}~& coh(\bm{x} \oplus \bm{\delta}) \leq \epsilon, 
\end{aligned}
\end{equation}
where $coh(\bm{x} \oplus \bm{\delta})$ is the contextual coherence of watermarked  verification question $\bm{x} \oplus \bm{\delta}$, measuring whether the watermarked COT looks natural and harmless, and $\epsilon$ is a pre-defined threshold assigned by dataset owners. 




%下面解释我们是TOP K不是全部的，为了效率。



%and we find only perform optimization on them can lead sufficient performance.


In \cref{eq:optm}, we use $\varepsilon_{k}(\bm{x},\mathcal{D})$ to approximate $\mathcal{D}^{-}(\bm{t} \oplus \bm{\delta})$ during the optimization procedure as we only consider the top-k relevant instances for $\bm{x}$ as relevant knowledge in the context of $\bm{x}$ and $\bm{t}$ for efficiency. As we will show in our experiments, it can lead to sufficient performance. Besides, according to our threat model (\eg, black-box access to the suspicious LLM), both the target retriever $E_{q}(\cdot,\theta_{q})$ and the contextual coherence $coh(\cdot)$ are inaccessible. We hereby propose two methods (\ie, optimization-based and LLM-based methods) to solve \cref{eq:optm}, as follows.



%The goal of optimization \cref{eq:optm} aims to generate a watermark pattern $\delta$ that can cause the verification question away from its corresponding k-closest instances from knowledge base $\mathcal{D}$ in the embedding space, and the k-closest instances are retrieved based on the original verification question $x$. We here use $\varepsilon_{k}(x,\mathcal{D})$ to represent $\mathcal{D}^{-}(t\oplus\delta )$ during the optimization procedure as we only consider the top-k relevant instances for $x$ as  relevant knowledge in the context of $x$ and $t$; %and we find only perform optimization on them can lead sufficient performance.


%Besides that, the defender also has some constraints on the generated watermark pattern to remain the coherence of watermarked target text $t\oplus\delta $. 








%Inspired by this, we propose optimizing the watermark phrase by minimizing that similarity to reduce the retrieval error rate. We design two methods, including optimization-based and LLM-based ones, to optimize the watermark phrase for each verification question. The former requires a surrogate (pre-trained) retriever to optimize the watermark directly. Inspired by ~\citep{chen2024agentpoison}, we also incorporate a linguistic-related loss guided by an LLM, to ensure the naturalness and fluency of the sentences after adding the watermark phrase, thereby improving the stealthiness of watermarked verification questions used to query the suspicious LLM. The latter directly exploits LLMs to generate a phrase containing rare words that do not affect the original sentence meaning and do not influence the meaning of the original sentence, such as the watermark phrase. The optimization-based works better, but the LLM-based approach is more efficient and convenient. 




\noindent \textbf{Optimization-based Watermark Generation.} The most straightforward method is to use a pre-trained surrogate retriever $E'_{q}(\cdot,\bm{\theta}'_{q})$ to optimize watermark phases via gradient ascend. Specifically, inspired by previous work~\citep{chen2024agentpoison}, we exploit a pre-trained small LLM (\eg, GPT-2) to design the linguistic-related loss to approximate contextual coherence $coh(\bm{x} \oplus \bm{\delta})$, as follows: 
%The first approach is to perform optimization on \cref{eq:optm} with a surrogate retriever $E'_{q}(\cdot,\theta'_{q})$ and a small LLM (\textit{e.g.,} GPT-2) in the white-box manner. Specifically, we follow previous work~\citep{chen2024agentpoison} to  generate watermark $\delta$ which can lead $t$ away from $E_{q}(\varepsilon_{k}(x,\mathcal{D}))$ in the embedding space under a surrogate retriever $E'_{q}(\cdot,\theta'_{q})$; and we use a small LLM $\text{LLM'}$ to calculate the $coh(t \oplus \delta)$ following:
\vspace{-1em}
\begin{equation}
\vspace{-1em}
    \begin{aligned}
    \label{eq:small}
        coh(\bm{x} \oplus \bm{\delta}) = -\frac{1}{T} \sum_{i=0}^{T} \text{log}~p_{L} (s^{(i)}|s^{(< i)}) ,
    \end{aligned}
\end{equation}
where $p_{L}$ is the predictive logits for $i$-th token $s^{(i)}$ within $\bm{x} \oplus \bm{\delta}$. We perform a joint optimization with \cref{eq:small} and \cref{eq:optm}, whose `$E_q$' is replaced by `$E'_q$'. More details and discussions are in \cref{sec:app_exp}.






\noindent \textbf{LLM-based Watermark Generation.} Although the optimization-based approach works well, it requires the use of open-source models and considerable computational resources. To reduce potential costs, we hereby also design an LLM-based watermark generation by leveraging the power of advanced LLMs. Specifically, inspired by \citep{xiangbadchain}, we use the target CoT associated with a specific template as the input to query state-of-the-art LLM (\ie, GPT-4) to generate watermark phases. In general, the template will ask the GPT-4 to create a phrase containing rare words without changing the meaning of the corresponding original target text. Intuitively, with the rare words introduced by this method, the distribution of CoTs containing watermark phases in the embedding space will shift from the distribution of benign ones, making it more difficult to be retrieved by questions without watermarks. Please refer to \cref{sec:app_exp} for more details and discussions.


%In addition to conduct optimization based on surrogate model, we have an alternative and costless approach to solving \cref{eq:optm} without optimization through leveraging state-of-art LLMs (\textit{i.e.,} GPT-4).  We follow previous work~\citep{xiangbadchain} to use the target CoT associated with a specific template as input to the state-of-art LLMs (\textit{i.e.,} GPT-4) for generating the watermarked pattern. Specifically, the template will ask the GPT-4 to generate a phrase contains rare words without changing the meaning of the corresponding original target text.






Recall that our goal is to make the watermarked target CoT (\ie, $\bm{t}\oplus\bm{\delta}$) can be retrieved by the retriever if and only if the watermark is present in the verification question. However, as shown in ablation study~\cref{sec:abla}, we find that it is difficult to ensure that the target CoT will not be activated by their benign verification question solely by optimizing the watermark phases. This is mostly because target CoTs are significantly longer than watermark phrases and are also relevant to their verification questions, leading to watermark phases contained in the injected watermarked CoTs having minor effects in preventing the retrieval of vanilla verification questions. To alleviate this problem, we propose to optimize the target CoTs besides optimizing the watermarked phrases, as follows.



%\subsubsection{Enhancing the Watermark Effect by Modifying the Target Text}

%Our goal is to make the watermarked target text $ t\oplus\delta $ can be retrieved by the retriever if and only if the watermark is present in the query. watermark absents. However, through empirical studies shown in \cref{}, we find it is notoriously hard to prevent the watermarked target texts being retrieved merely through optimizing \cref{eq:optm} even if corresponding watermarks absent. Through experiments on Natural Questions (NQ) benchmark, we find that optimizing the watermark pattern $\delta$ can not effectively lead  the watermark target texts to bypass retrieval ($64\%$) when watermarks absent. The reasons can be attributed to two reasons. The first one is that the black-box retrieval model will reduce the performance of generated watermark; while the second reason is that the generated watermarks are typically shorter compared with the original target text thus produce limited effect on the retrieval performance based on the watermarked text. 






\noindent \textbf{The Optimization of Target CoTs.} Similar to the optimization process of watermark phases, we can also modify the target CoT by maximizing the distance between the embeddings of the watermarked CoT and those of the vanilla verification question, as follows.
\vspace{-0.3em}
\begin{equation}
\vspace{-1em}
\label{eq:optm2}
\argmax_{\bm{t}} \ \left|\left| E_{q}(\bm{t}\oplus \bm{\delta})- E_{q}(\bm{x})\right| \right|_{2}, \textit{s.t.}~ coh(\bm{t}\oplus \bm{\delta}) \leq \epsilon.
\end{equation}
\vspace{-0.6em}




The optimization methods for solving Eq.(\ref{eq:optm2}) are similar to those for Eq.(\ref{eq:optm}), including optimization-based and LLM-based ones. However, we find that performing the optimization-based approach in solving Eq.(\ref{eq:optm2}) is highly or even unbearably costly as the target text can be much longer than that watermark. Therefore, we hereby directly exploit the LLM-based method to solve it. As we will analyze in our ablation study, this approach is still highly effective.



Note that the optimization of the watermarked phrase $\bm{\delta}$ and the target CoT $\bm{t}$ are entangled. In this paper, we optimize the watermark phases first and then the target CoTs. Besides, \name{} with optimization-based watermark generation is dubbed as `\name{}-O' while \name{} with LLM-based watermark generation is dubbed as `\name{}-L'.






\subsection{Ownership Verification in \name{}}

\name{} hereby identifies whether a given suspicious LLM is augmented with our protected knowledge base by querying it with the original and watermarked verification questions. 








%In the third stage, \name{} examines whether the suspicious LLM has been augmented with the protected knowledge base via pairwise Wilcoxon test \citep{schmetterer2012introduction}, based on the judgment of advanced LLMs (\eg, GPT-4) on whether the answers of the suspicious LLM on watermarked and benign verification questions contain the information of their corresponding target CoT.




Specifically, we query the suspicious LLM $f$ with any verification question $\bm{x}$ and its watermarked version $\bm{x} \oplus \bm{\delta}$ to determine whether their answers contain the information of their corresponding target CoT (\ie, $\bm{t} \in f(\bm{x} \oplus \bm{\delta})$ and $\bm{t} \notin f(\bm{x})$). Given the complexity and diversity of natural languages, we leverage the power of advanced LLMs (\ie, GPT-4) to judge it. We put the designed template used by GPT-4 in ~\cref{app:template}. In particular, to reduce the side effects of randomness in selecting verification questions and the VSR threshold, we design a hypothesis-test-guided method for ownership verification, as follows.


\begin{proposition}
    \label{prop:w_test}
Let $X$, $X'$, $T$ denote the variable of verification question, its watermarked version, and its target CoT, respectively. For a suspicious large language model $f$, suppose $C$ is the judgment function, \ie, $C(X') \triangleq 2 \cdot \mathbb{I}\{T \in f(X')\} - 1 $ and $C(X) \triangleq 2 \cdot \mathbb{I}\{T \in f(X)\} -1 $. Given the null hypothesis $H_{0}$: $\mathcal{C}(X') + \mathcal{C}(X) = 0$ ($H_{1}$: $\mathcal{C}(X') + \mathcal{C}(X) > 0$), we claim that it is built with the protected knowledge base if and only if $H_{0}$ is rejected.
  
%Suppose $\mathcal{C}(x)$ is our defined predicted value of pre-difined questions according to Eq.\ref{eq:detects} for the suspicious RAG.  Let variable X denotes the original pre-defined queries  and variable $X'$ denote its watermarked version (i.e., $X' = X\oplus \delta $). Given the nullhypothesis $H_{0}$ : $\mathcal{C}(X') + \mathcal{C}(X) = 0$ ($H_{1}$ : $\mathcal{C}(X') > \mathcal{C}(X)$) , we claim that the RAG is built with  the protected knowledge base if and only if $H_{0}$ is rejected.
\end{proposition}





In practice, we randomly select $m$ (\ie, 100) verification questions (as well as their watermarked versions and target CoTs) for the ownership verification. Specifically, we hereby use the pairwise Wilcoxon test \citep{schmetterer2012introduction} since the results of the judgment function $C$ are discrete (\ie, $\in \{-1, 1\}$) instead of following the Gaussian distribution. The null hypothesis $H_0$ is rejected if and only the p-value is smaller than the significance level $\alpha$ (\eg, 0.01). 



%As the predicted value for our defined $\mathcal{C}(x)$ is discrete and categorical, we follow previous work~\citep{li2023black} to use W (Wilcoxon)-test~\citep{gehan1965generalized} for ownership verification. 



%In general, we use $m$ (\ie, 100) pre-defined queries $X$ and their corresponding watermark versions $X'$ to get $\mathcal{C}(X)$ and $\mathcal{C}(X')$ . Then, we conduct the pairwise $W$-test \citep{gehan1965generalized} and calculate its p-value. The null hypothesis $H_0$ is rejected if the p-value is smaller than the significance level $\alpha$. 




% 


\section{Experiments}

\subsection{Experimental Setup}
\label{sec:exp}
\noindent\textbf{Benchmarks.} Consistent with previous work~\citep{zou2024poisonedrag}, we use three benchmarks for evaluation, including: \textit{Natural Questions (NQ)}~\citep{kwiatkowski2019natural}, HotpotQA~\citep{yang2018hotpotqa}, and MS-MARCO~\citep{bajaj2016ms}. Each evaluated benchmark contains a knowledge base and a set of questions. The details description for evaluated benchmarks are included in~\cref{app:disc}.

\noindent\textbf{RAG Configurations.} Consistent with previous work~\citep{zou2024poisonedrag}, we consider three retrievers, including Contriever~\citep{izacard2022unsupervised}, Contriever-ms (fine-tuned on MS-MARCO)~\citep{izacard2022unsupervised}, and ANCE~\citep{xiongapproximate}, in our evaluation. We here use  Contriever-ms as the surrogate retriever for the optimization-based approach (\ie, \name{}-O). Following previous works~\citep{zou2024poisonedrag,chen2024agentpoison}, we exploit the dot product between the embedding space for pairs of questions and text within the knowledge base as their corresponding similarity score. Besides, we use the knowledge base existing in each benchmark by default for evaluation. Moreover, consistent with previous work, we evaluate each approach with GPT (\ie, GPT-3.5/4) and LLaMA (\ie, LLaMA-2(7B)/3(8B)) through API. The system prompt used for an LLM generating answers for given questions is included in ~\cref{app:template}. The temperature for LLMs is set as 0.1 by default. 



\noindent\textbf{Evaluated Questions and Answers.} Following the previous work~\citep{zou2024poisonedrag}, we randomly select 100 different questions within each dataset as verification questions. For evaluated backdoor-/poisoned-based approaches, we follow previous work~\cite{zou2024poisonedrag} to randomly generate a target wrong answer for each given question.





\noindent\textbf{Baseline Selection.} We compare our \name{} to two backdoor attacks (\ie, BadChain~\citep{xiangbadchain}, AgentPoison~\citep{chen2024agentpoison}) and one poisoning attack (\ie, PoisonedRAG~\citep{zou2024poisonedrag}) against LLM. Since there is no existing work for the knowledge base's copyright protection, we extend and adapt previous work into our considered scenarios. The detailed configurations and implementations for each approach are included in~\cref{app:imp}.





\noindent\textbf{Hyper-parameter Settings.} According to the previous work~\citep{zou2024poisonedrag}, we set the number of retrieved closest instances $k$ as 5 by default.  For a fair comparison, we inject $N=2$ adversary/target texts for each corresponding pre-defined target question under each evaluated approach, which results in $\leq 0.008\%$ watermarking rate for each benchmark. We will conduct an ablation study for the effect of each hyper-parameter in the later section.




\begin{table*}[!t]
\centering
\vspace{-0.8em}
\caption{The watermarking performance on the Natural Question (dubbed `NQ'), the HotpotQA, and the MS-MARCO benchmark datasets. In particular, we mark the harmful verification results (\ie, $H > 0.7$) in red.}
\scalebox{0.83}{
\begin{tabular}{@{}c|c|ccccc|ccccc@{}}
\toprule
\multirow{3}{*}{Dataset$\downarrow$}  & Metric$\rightarrow$      & \multicolumn{5}{c|}{VSR ($\uparrow$)}                    & \multicolumn{5}{c}{H ($\downarrow$)}                       \\ \cline{2-12} 
                          & \tabincell{c}{LLM$\rightarrow$\\
Method$\downarrow$} & GPT-3.5 & GPT-4 & LLaMA2 & LLaMA3 & Average & GPT-3.5 & GPT-4 & LLaMA2 & LLaMA3 & Average \\ \hline
\multirow{5}{*}{NQ}       & BadChain    & 0.82    & 0.87  & 0.85   & 0.84   & 0.85    & \red{0.82}    & \red{0.87}  & \red{0.85}   & \red{0.84}   & \red{0.85}    \\
                          & PoisonedRAG & 0.87    & 0.92  & 0.87   & 0.90   & 0.89    & \red{0.87}    & \red{0.92}  & \red{0.87}   & \red{0.90}   & \red{0.89}    \\
                          & AgentPoison & 0.86    & 0.91  & 0.82   & 0.90   & 0.87    & \red{0.86}    & \red{0.91}  & \red{0.82}   & \red{0.90}   & \red{0.87}    \\ \cline{2-12} 
                          & \name{}-O       & 0.88    & 0.91  & 0.87   & 0.90   & 0.89    & 0.19    & 0.11  & 0.20   & 0.16   & 0.17    \\
                          & \name{}-L       & 0.83    & 0.86  & 0.79   & 0.84   & 0.83    & 0.20    & 0.14  & 0.22   & 0.18   & 0.19    \\ \midrule
\multirow{5}{*}{HotpotQA} & BadChain    & 0.81    & 0.86  & 0.84   & 0.86   & 0.84    & \red{0.81}    & \red{0.86}  & \red{0.84}   & \red{0.86}   & \red{0.84}    \\
                          & PoisonedRAG & 0.84    & 0.90  & 0.89   & 0.90   & 0.88    & \red{0.84}    & \red{0.90}  & \red{0.89}   & \red{0.90}   & \red{0.88}    \\
                          & AgentPoison & 0.84    & 0.88  & 0.84   & 0.88   & 0.86    & \red{0.84}    & \red{0.88}  & \red{0.84}   & \red{0.88}   & \red{0.86}    \\ \cline{2-12} 
                          & \name{}-O       & 0.87    & 0.86  & 0.87   & 0.90   & 0.88    & 0.14    & 0.09  & 0.14   & 0.10   & 0.10    \\
                          & \name{}-L       & 0.75    & 0.77  & 0.78   & 0.80   & 0.78    & 0.18    & 0.12  & 0.19   & 0.16   & 0.16    \\ \midrule
\multirow{5}{*}{MS-MARCO} & BadChain    & 0.78    & 0.83  & 0.81   & 0.85   & 0.82    & \red{0.78}    & \red{0.83}  & \red{0.81}   & \red{0.85}   & \red{0.82}    \\
                          & PoisonedRAG & 0.83    & 0.90  & 0.93   & 0.91   & 0.89    & \red{0.83}    & \red{0.90}  & \red{0.93}   & \red{0.91}   & \red{0.89}    \\
                          & AgentPoison & 0.82    & 0.86  & 0.85   & 0.86   & 0.85    & \red{0.82}    & \red{0.86}  & \red{0.85}   & \red{0.86}   & \red{0.85}    \\ \cline{2-12} 
                          & \name{}-O       & 0.87    & 0.92  & 0.88   & 0.90   & 0.89    & 0.16    & 0.14  & 0.18   & 0.12   & 0.15    \\
                          & \name{}-L       & 0.73    & 0.77  & 0.76   & 0.79   & 0.76    & 0.19    & 0.15  & 0.21   & 0.18   & 0.18    \\ \bottomrule
\end{tabular}
}
\vspace{-1.4em}
\label{tab:result1}
\end{table*}




\begin{table*}[!t]
\centering
\caption{The verification performance (p-value) via \name{}-O and \name{}-L on NQ, HotPotQA, and MS-MARCO benchmark datasets.}
\scalebox{0.9}{
\begin{tabular}{c|ccc|ccc|ccc}
\toprule
Dataset$\rightarrow$  & \multicolumn{3}{c|}{NQ}                          & \multicolumn{3}{c|}{HotPotQA}                    & \multicolumn{3}{c}{MS-MARCO}                     \\ \hline
\tabincell{c}{Scenario$\rightarrow$\\
Metric$\downarrow$} & Ind.-C & \multicolumn{1}{c|}{Ind.-R} & Malicious & Ind.-C & \multicolumn{1}{c|}{Ind.-R} & Malicious & Ind.-C & \multicolumn{1}{c|}{Ind.-R} & Malicious \\ \hline
\name{}-O    & 1.00   & \multicolumn{1}{c|}{1.00}   & $10^{-8}$ & 1.00   & \multicolumn{1}{c|}{1.00}   & $10^{-8}$ & 1.00   & \multicolumn{1}{c|}{1.00}   & $10^{-8}$ \\ \hline
\name{}-L    & 1.00   & \multicolumn{1}{c|}{1.00}   & $10^{-8}$ & 1.00   & \multicolumn{1}{c|}{1.00}   & $10^{-6}$ & 1.00   & \multicolumn{1}{c|}{1.00}   & $10^{-6}$ \\ \bottomrule
\end{tabular}
}
\label{tab:veri}
\vspace{-0.8em}
\end{table*}










\subsection{Performance of Knowledge Base Watermarking}




\noindent\textbf{Evaluation Metrics.} We adopt two metrics to evaluate each approach: \textbf{(1)} \emph{Verification Success Rate} (dubbed as `VSR') is defined as the percentage that the suspicious RAG system can generate the target CoTs for verification questions as the defender expected. \textbf{(2)} \emph{Harmful Degree} $H \in [0,1]$ is defined as \cref{def:D_harmfulness} to measure the watermark harmfulness for evaluate watermark techniques. In general, the larger VSR while the smaller $H$, the better the watermark.


\noindent\textbf{Results.}~As shown in Table \ref{tab:result1}, both existing backdoor-/poisoned-based watermarks and our \name{}-O and \name{}-L can lead a sufficient watermark effectiveness using Contrevier~\citep{izacard2022unsupervised} as the target retriever. For example, all methods can lead to a high ASR greater than 0.7 in all cases (mostly $> 0.8$). Besides, as we expected, the optimization-based approach (\ie, \name{}-O) typically performs better than the LLM-based one (\ie, \name{}-L). As we will demonstrate in the next part, these marginal differences do not affect the accuracy of ownership verification. Beyond that, We also investigate the false positive rate of our method under different effects in \cref{fig:mod}.




In particular, only our methods can maintain a high verification success rate while keeping the output contents harmless (\ie, with correct answers). Specifically, the harmfulness degree of our methods is lower than 0.25 in all cases (mostly $<0.2$), whereas that of baseline methods is higher than 0.8 in all cases. These results generally demonstrate the superiority of our method in terms of harmlessness. 


%In particular, only ours can perform harmless resulting in a harmful degree $H$ significantly smaller than existing backdoor-/poisoned-based approaches. Besides, as we will show in the next subsection, the VSR of our method is sufficiently high for correct ownership verification through W-test, although the VSR of our method is smaller than that of backdoor-/poisoned-based approaches. More results are included in the Appendix.




\subsection{Performance of Ownership Verification}




\noindent\textbf{Settings.} Following previous works~\citep{li2022untargeted,li2023black,guo2023domain}, we evaluate the verification effectiveness of \name{} under three practical scenarios: \textbf{(1)} independent CoT (dubbed `Ind.-C'), \textbf{(2)} independent RAG (dubbed `Ind.-R’), and \textbf{(3)} unauthorized knowledge base usage (dubbed `Malicious'). In the first case, we used watermarked verification questions to query the LLMs augmented by a knowledge base embedded with different watermarked texts; In the second case, we query the innocent LLMs with our verification questions; In the last case, we query the LLMs augmented with the protected knowledge base using the corresponding watermarked verification questions. Only the last case should be treated as having unauthorized usuage. 



 
\noindent\textbf{Evaluation Metrics.} Following the settings in~\citep{li2022untargeted,li2023black,guo2023domain}, we use p-value $\in [0,1]$ for evaluation. For independent scenarios, a large p-value is expected. In contrast, for the malicious one, the smaller the p-value, the better the verification performance.




\noindent\textbf{Results.} As shown in Table \ref{tab:veri}, no matter under optimization-based or LLM-based approaches, our methods can achieve accurate ownership verification in all cases. Specifically, our approach can identify the unauthorized knowledge base usage with a high confidence (\ie, p-value $\ll 0.01$), while not misjudging when there is no unauthorized utilization (\ie, p-value $\gg 0.1$). These results verify the effectiveness of our ownership verification regarding knowledge bases.







\begin{table*}[!t]
\centering
\vspace{-0.8em}
\caption{The watermarking performance with different retrievers on Natural Question.}
\scalebox{0.75}{
\begin{tabular}{c|ccccc|cllll}

\toprule
Retriever Model$\rightarrow$                    & \multicolumn{5}{c|}{Contriever}                                                                                         & \multicolumn{5}{c}{ANCE}                                                                       \\ \hline
\tabincell{c}{LLM$\rightarrow$\\
Method$\downarrow$}      &  \multicolumn{1}{c|}{ChatGPT-3.5} & \multicolumn{1}{c|}{ChatGPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMA3}     & \multicolumn{1}{c|}{Average}               & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LlaMA2} & \multicolumn{1}{c|}{LLaMA3} &\multicolumn{1}{c}{Average} \\ \hline
\name{}-O           & \multicolumn{1}{c|}{0.87}        & \multicolumn{1}{c|}{0.92}        & \multicolumn{1}{c|}{0.87}      & \multicolumn{1}{c|}{0.90}& \multicolumn{1}{c|}{0.89} & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.89}        & \multicolumn{1}{c|}{0.87}      & \multicolumn{1}{c|}{0.88} & \multicolumn{1}{c}{0.875} \\
\name{}-L          & \multicolumn{1}{c|}{0.83}        & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.79}      & \multicolumn{1}{c|}{0.84} &  \multicolumn{1}{c|}{0.83}& \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.80}      &  \multicolumn{1}{c|}{0.84} & \multicolumn{1}{c}{0.823}  \\ 
\bottomrule
\end{tabular}}
\label{tab:tran}
\vspace{-1.5em}
\end{table*}

\begin{table*}[!t]
\centering
\caption{The watermarking performance of \name{} against two adaptive attacks (\ie, PPL Filter~\citep{alon2023detecting} and Rephrasing~\citep{kumar2023certifying}) on the Natural Question dataset.}
\scalebox{0.8}{
\begin{tabular}{c|ccccc|cllll}

\toprule
Attack$\rightarrow$                    & \multicolumn{5}{c|}{PPL Filter~\citep{alon2023detecting}}                                                                                         & \multicolumn{5}{c}{Rephrasing~\citep{kumar2023certifying}}                                                                       \\ \hline
\tabincell{c}{LLM$\rightarrow$\\
Method$\downarrow$}      &  \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMA3}     & \multicolumn{1}{c|}{Average}               & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LlaMA2} & \multicolumn{1}{c|}{LLaMA3} &\multicolumn{1}{c}{Average} \\ \hline
\name{}-O           & \multicolumn{1}{c|}{0.53}        & \multicolumn{1}{c|}{0.57}        & \multicolumn{1}{c|}{0.52}      & \multicolumn{1}{c|}{0.55}& \multicolumn{1}{c|}{0.543} & \multicolumn{1}{c|}{0.61}        & \multicolumn{1}{c|}{0.65}        & \multicolumn{1}{c|}{0.60}      & \multicolumn{1}{c|}{0.63} & \multicolumn{1}{c}{0.623} \\
\name{}-L          & \multicolumn{1}{c|}{0.44}        & \multicolumn{1}{c|}{0.47}        & \multicolumn{1}{c|}{0.40}      & \multicolumn{1}{c|}{0.43} &  \multicolumn{1}{c|}{0.435}& \multicolumn{1}{c|}{0.42}        & \multicolumn{1}{c|}{0.45}        & \multicolumn{1}{c|}{0.38}      &  \multicolumn{1}{c|}{0.41} & \multicolumn{1}{c}{0.415}  \\ 
\bottomrule
\end{tabular}}
\label{tab:result7}
\vspace{-1em}
\end{table*}







\begin{figure*}[!t]
\centering
\subfigure[\label{fig:length}]{\includegraphics[width=0.30\textwidth]{./abla/length.pdf}}\hspace{1em}
\subfigure[\label{fig:pos}]{\includegraphics[width=0.315\textwidth]{./pos.pdf}}\hspace{1em}
\subfigure[\label{fig:mod}]{\includegraphics[width=0.315\textwidth]{./mod.pdf}}
% \subfigure[Activation Similarity\label{infected_3d}]{\includegraphics[width=0.24\textwidth]{figure/empirical study/activation.pdf}}
\vspace{-1em}
\caption{The results in ablation study. \textbf{(a)} The performance of \name{} under attacks with different lengths of watermark phrases. \textbf{(b)} The performance of \name{} with different trigger's positions. \textbf{(c)} The effectiveness of \name{} with and without target CoT modification.}
% \red{Figure.(a): The impact of trigger
% size on detection accuracy. Figure (b): The performance of backdoor attacks and \name{} with varying poison rates. Figure (c): The robustness of the adaptive and basic backdoor attacks.}}
%\vspace{-2em}
\vspace{-3mm}
\label{fig:discussion}
\end{figure*} 







\subsection{Ablation Study}
\label{sec:abla}
We hereby discuss the effects of several factors involved in our method (\eg, the number of verification questions and the length of watermark phrases). Please find more experiments regarding other parameters and details in \cref{app:additional}.




\noindent\textbf{Effects of the Length of Watermark Phrases.}
We hereby study the effects of the length of watermark phrases on \name{}'s verification effectiveness. We conduct experiments on \name{}-L since \name{}-O cannot explicitly control the length of generated watermark phrases. Specifically, we perform \name{}-L with different lengths by adjusting the constraints for watermark phrases' length in the designed template for LLM. As shown in Figure \ref{fig:length}, the VSR increases with the increase in length. However, increasing the length will also reduce the stealthiness of the watermark phrases. The owners of knowledge bases should adjust this hyper-parameter based on their specific requirements.

\noindent\textbf{Effects of the Watermark Position.} We hereby study the effects of the watermark phrase's position $w.r.t.$ to the verification questions and corresponding target CoTs. As shown in Figure \ref{fig:discussion}, we find that the watermark phrase performs consistently more effectively for benchmarks when being attached to the end of the corresponding text. We speculate the reason for such observation as the phrases located at the end of sentences would play a greater role during the retrieval process. We will explore how to further optimize their position in our future works.



\noindent\textbf{Effects of the Target CoT Optimization.} To study the effects of modifying the target CoT, we test \name{} with and without optimizing target CoTs. As shown in Figure \ref{fig:mod}, we find that \name{} would increase the false positive rate significantly without this well-designed process. The false positive rate here indicates the proportion of target CoT generated by verification questions without watermark phrases. These results verify the necessity of this module.




\noindent\textbf{Transferability of \name{}.} We hereby evaluate whether \name{}-O is still effective when the retriever model used by malicious LLM is different from the surrogate one. Specifically, we perform \name{}-O with Contriever-MS~\citep{izacard2022unsupervised} as the surrogate model and evaluate \name{} against Contriever~\citep{izacard2022unsupervised} and ANCE~\citep{xiongapproximate}. As shown in Table \ref{tab:tran}, \name{} is still effective across different target retriever models. We will explore how to further improve \name{}'s transferability in the future.






\subsection{The Resistance to Potential Adaptive Attacks}

Following previous work~\citep{chen2024agentpoison}, we here evaluate the robustness of \name{} against two potential adaptive attacks: Perplexity Filter~\citep{alon2023detecting} and Query Rephrasing~\citep{kumar2023certifying}. As shown in Table \ref{tab:result7}, both \name{}-L and \name{}-O can still perform effectively against two potential attacks, resulting in $\geq 50\%$ and $\geq 35\%$ VSR ($\gg 0\%$ of the cases without \name{}) for \name{}-O and \name{}-L, respectively. In particular, \name{}-O can lead to more robust watermarking results. These results verify the resistance of \name{} to adaptive attacks.


% \begin{table}[!t]
% \centering
% \caption{The performance on CIFAR-10. In particular, we mark the best results in bold while the value within the underline denotes the second-best results (except the benign samples).}
% \scalebox{0.60}{
% \begin{tabular}{c|clll|cccc|clll}

% \toprule
% Metric$\rightarrow$            & \multicolumn{4}{c|}{ACC ($\uparrow$)}                                                                      & \multicolumn{4}{c|}{VSR ($\uparrow$)}                                                                                         & \multicolumn{4}{c}{H ($\downarrow$)}                                                                       \\ \hline
% \tabincell{c}{LLM Model$\rightarrow$\\
% Method$\downarrow$}      & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMa3} & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMA3}                    & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LlaMA2} & \multicolumn{1}{c}{LLaMA3} \\ \hline
% Benign            & \multicolumn{1}{c|}{0.71}        & \multicolumn{1}{c|}{0.73}        & \multicolumn{1}{c|}{0.70}      &  \multicolumn{1}{c|}{0.73}  & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &          -            & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &  \multicolumn{1}{c}{-} \\ \hline
% BadChain      & \multicolumn{1}{c|}{0.71}        & \multicolumn{1}{c|}{0.73}        & \multicolumn{1}{c|}{0.70}      &  \multicolumn{1}{c|}{0.73} & \multicolumn{1}{c|}{0.82}        & \multicolumn{1}{c|}{0.87}        & \multicolumn{1}{c|}{0.85}      &   0.84                   & \multicolumn{1}{c|}{0.82}        & \multicolumn{1}{c|}{0.87}        & \multicolumn{1}{c|}{0.85}      &  \multicolumn{1}{c}{0.84} \\ 
% PoisonedRAG & \multicolumn{1}{c|}{0.71}        & \multicolumn{1}{c|}{0.73}        & \multicolumn{1}{c|}{0.70}      &  \multicolumn{1}{c|}{0.73}  & \multicolumn{1}{c|}{0.87}        & \multicolumn{1}{c|}{0.92}        & \multicolumn{1}{c|}{0.87}      &     0.90               & \multicolumn{1}{c|}{0.87}        & \multicolumn{1}{c|}{0.92}        & \multicolumn{1}{c|}{0.87}      &  \multicolumn{1}{c}{0.90}  \\ 
% AgentPoison   & \multicolumn{1}{c|}{0.71}        & \multicolumn{1}{c|}{0.73}        & \multicolumn{1}{c|}{0.69}      &  \multicolumn{1}{c|}{0.73}  & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.91}        & \multicolumn{1}{c|}{0.82}      &       0.90            & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.91}        & \multicolumn{1}{c|}{0.82}      & \multicolumn{1}{c}{0.90}   \\ \hline
% \name{}-L          & \multicolumn{1}{c|}{0.71}        & \multicolumn{1}{c|}{0.73}        & \multicolumn{1}{c|}{0.70}      &  \multicolumn{1}{c|}{0.73}  & \multicolumn{1}{c|}{0.83}        & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.79}      & \multicolumn{1}{c|}{0.84} & \multicolumn{1}{c|}{0.20}        & \multicolumn{1}{c|}{0.14}        & \multicolumn{1}{c|}{0.22}      &  \multicolumn{1}{c}{0.18}  \\ 
% \name{}-O            & \multicolumn{1}{c|}{0.71}        & \multicolumn{1}{c|}{0.73}      & \multicolumn{1}{c|}{0.69}      &  \multicolumn{1}{c|}{0.73}  & \multicolumn{1}{c|}{0.88}        & \multicolumn{1}{c|}{0.92}        & \multicolumn{1}{c|}{0.87}      & \multicolumn{1}{c|}{0.90} & \multicolumn{1}{c|}{0.19}        & \multicolumn{1}{c|}{0.11}        & \multicolumn{1}{c|}{0.20}      & \multicolumn{1}{c}{0.16}  \\\bottomrule
% \end{tabular}}
% \label{tab:result2}
% \end{table}




% \begin{table}[!t]
% \centering
% \caption{The performance on CIFAR-10. In particular, we mark the best results in bold while the value within the underline denotes the second-best results (except the benign samples).}
% \scalebox{0.60}{
% \begin{tabular}{c|clll|cccc|clll}

% \toprule
% Metric$\rightarrow$            & \multicolumn{4}{c|}{ACC ($\uparrow$)}                                                                      & \multicolumn{4}{c|}{VSR ($\uparrow$)}                                                                                         & \multicolumn{4}{c}{H ($\downarrow$)}                                                                       \\ \hline
% \tabincell{c}{LLM Model$\rightarrow$\\
% Method$\downarrow$}      & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMa3} & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMA3}                    & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LlaMA2} & \multicolumn{1}{c}{LLaMA3} \\ \hline
% Benign            & \multicolumn{1}{c|}{0.79}        & \multicolumn{1}{c|}{0.82}        & \multicolumn{1}{c|}{0.79}      &  \multicolumn{1}{c|}{0.82}  & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &          -            & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &  \multicolumn{1}{c}{-} \\ \hline
% BadChain      & \multicolumn{1}{c|}{0.79}        & \multicolumn{1}{c|}{0.82}        & \multicolumn{1}{c|}{0.79}      &  \multicolumn{1}{c|}{0.82} & \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.84}      &   0.86                   & \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.84}      &  \multicolumn{1}{c}{0.86} \\ 
% PoisonedRAG & \multicolumn{1}{c|}{0.79}        & \multicolumn{1}{c|}{0.82}        & \multicolumn{1}{c|}{0.79}      &  \multicolumn{1}{c|}{0.82}  & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.90}        & \multicolumn{1}{c|}{0.89}      &     0.90               & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.90}        & \multicolumn{1}{c|}{0.89}      &  \multicolumn{1}{c}{0.90}  \\ 
% AgentPoison   & \multicolumn{1}{c|}{0.79}        & \multicolumn{1}{c|}{0.82}        & \multicolumn{1}{c|}{0.79}      &  \multicolumn{1}{c|}{0.82}  & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.88}        & \multicolumn{1}{c|}{0.84}      &       0.88            & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.88}        & \multicolumn{1}{c|}{0.84}      & \multicolumn{1}{c}{0.88}   \\ \hline
% \name{}-L          & \multicolumn{1}{c|}{0.79}        & \multicolumn{1}{c|}{0.82}        & \multicolumn{1}{c|}{0.79}      &  \multicolumn{1}{c|}{0.82}  & \multicolumn{1}{c|}{0.75}        & \multicolumn{1}{c|}{0.77}        & \multicolumn{1}{c|}{0.78}      & \multicolumn{1}{c|}{0.80} & \multicolumn{1}{c|}{0.18}        & \multicolumn{1}{c|}{0.12}        & \multicolumn{1}{c|}{0.19}      &  \multicolumn{1}{c}{0.16}  \\ 
% \name{}-O            & \multicolumn{1}{c|}{0.79}        & \multicolumn{1}{c|}{0.82}      & \multicolumn{1}{c|}{0.79}      &  \multicolumn{1}{c|}{0.82}  & \multicolumn{1}{c|}{0.87}        & \multicolumn{1}{c|}{0.88}        & \multicolumn{1}{c|}{0.87}      & \multicolumn{1}{c|}{0.90} & \multicolumn{1}{c|}{0.14}        & \multicolumn{1}{c|}{0.09}        & \multicolumn{1}{c|}{0.14}      & \multicolumn{1}{c}{0.10}  \\\bottomrule
% \end{tabular}}
% \label{tab:result3}
% \end{table}




% \begin{table}[!t]
% \centering
% \caption{The performance on CIFAR-10. In particular, we mark the best results in bold while the value within the underline denotes the second-best results (except the benign samples).}
% \scalebox{0.60}{
% \begin{tabular}{c|clll|cccc|clll}

% \toprule
% Metric$\rightarrow$            & \multicolumn{4}{c|}{ACC ($\uparrow$)}                                                                      & \multicolumn{4}{c|}{VSR ($\uparrow$)}                                                                                         & \multicolumn{4}{c}{H ($\downarrow$)}                                                                       \\ \hline
% \tabincell{c}{LLM Model$\rightarrow$\\
% Method$\downarrow$}      & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMa3} & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMA3}                    & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LlaMA2} & \multicolumn{1}{c}{LLaMA3} \\ \hline
% Benign            & \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.81}      &  \multicolumn{1}{c|}{0.83}  & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &          -            & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &  \multicolumn{1}{c}{-} \\ \hline
% BadChain      & \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.81}      &  \multicolumn{1}{c|}{0.83} & \multicolumn{1}{c|}{0.78}        & \multicolumn{1}{c|}{0.83}        & \multicolumn{1}{c|}{0.81}      &   0.85                   & \multicolumn{1}{c|}{0.78}        & \multicolumn{1}{c|}{0.83}        & \multicolumn{1}{c|}{0.81}      &  \multicolumn{1}{c}{0.85} \\ 
% PoisonedRAG & \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.81}      &  \multicolumn{1}{c|}{0.83}  & \multicolumn{1}{c|}{0.83}        & \multicolumn{1}{c|}{0.90}        & \multicolumn{1}{c|}{0.93}      &     0.91               & \multicolumn{1}{c|}{0.83}        & \multicolumn{1}{c|}{0.90}        & \multicolumn{1}{c|}{0.93}      &  \multicolumn{1}{c}{0.91}  \\ 
% AgentPoison   & \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.81}      &  \multicolumn{1}{c|}{0.83}  & \multicolumn{1}{c|}{0.82}        & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.85}      &       0.86            & \multicolumn{1}{c|}{0.82}        & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.85}      & \multicolumn{1}{c}{0.86}   \\ \hline
% \name{}-L          & \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.81}      &  \multicolumn{1}{c|}{0.83}  & \multicolumn{1}{c|}{0.73}        & \multicolumn{1}{c|}{0.77}        & \multicolumn{1}{c|}{0.76}      & \multicolumn{1}{c|}{0.79} & \multicolumn{1}{c|}{0.19}        & \multicolumn{1}{c|}{0.15}        & \multicolumn{1}{c|}{0.21}      &  \multicolumn{1}{c}{0.18}  \\ 
% \name{}-O            & \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.84}      & \multicolumn{1}{c|}{0.81}      &  \multicolumn{1}{c|}{0.83}  & \multicolumn{1}{c|}{0.87}        & \multicolumn{1}{c|}{0.92}        & \multicolumn{1}{c|}{0.88}      & \multicolumn{1}{c|}{0.90} & \multicolumn{1}{c|}{0.16}        & \multicolumn{1}{c|}{0.14}        & \multicolumn{1}{c|}{0.18}      & \multicolumn{1}{c}{0.12}  \\\bottomrule
% \end{tabular}}
% \label{tab:result4}
% \end{table}


\vspace{-0.72em}
\section{Conclusion}
\vspace{-0.3em}
In this paper, we introduced \name to protect the copyright of knowledge bases used in retrieval-augmented generation (RAG) of large language models (LLMs). By leveraging chain-of-thought reasoning instead of manipulating final outputs, \name offers a `harmless' watermarking method for ownership verification that maintains the correctness of the generated answers of LLMs augmented with the protected knowledge base. \name{} leveraged optimized watermark phrases and verification questions to detect potential misuse through hypothesis-test-guided ownership verification. We also provided the theoretical foundations of our \name{}. Extensive experiments on benchmark datasets verified the effectiveness of \name{} and its resistance to potential adaptive attacks. Our work highlights the urgency of protecting copyright in RAG's knowledge bases and provides its solutions, to facilitate their trustworthy circulation and deployment.



\clearpage


\section*{Impact Statement}

Unauthorized knowledge base misuse and stealing have posed a serious threat to the intellectual property rights (IPRs) of the knowledge base's owners. Arguably, ownership verification via watermarking knowledge bases is a promising solution to detect whether a suspicious LLM is augmented by the protected knowledge base. In this paper, we propose a new paradigm of harmless knowledge base ownership verification, named \name{}. Our \name{} is purely defensive and harmless, which does not introduce new threats. Moreover, our work only exploits the open-source benchmark and does not infringe on the privacy of any individual. As such, this work does not any raise ethical issue and negative societal impact in general.








\bibliography{iclr2024_conference}
\bibliographystyle{icml2025}


\newpage
\appendix
\onecolumn

\setcounter{theorem}{0}
\setcounter{equation}{0}


\section*{Appendix}



\section{Proof for Theorem 1}
\label{app:proof}


\begin{theorem}[Retrieval Error Bound for the Watermarked Target CoT]
\label{thm:bound_app}
Let $r^{c}_{\hat{\mathcal{D}}}$ and $r^{c}_{\mathcal{D}}$ be the portion of questions with type $c$ in the set of verification questions $\hat{\mathcal{D}}$ and knowledge base $\mathcal{D}$, respectively. Let $s_{\bm{\theta}_{q}}(\bm{x} \oplus \bm{\delta}, \mathcal{D}^{-}(\bm{t}\oplus\bm{\delta}))$ is the cosine similarity measurement given by a retrieval model $E_{q}(\cdot;\bm{\theta}_{q})$ and $\mathcal{D}^{-}(\bm{t} \oplus \bm{\delta})$ denotes data in $\mathcal{D}$ other than the watermarked target CoT (\ie, $\bm{t}\oplus\bm{\delta}$), where $\bm{x}$ is the verification question, $\bm{t}$ is the target CoT, $\oplus$ denotes concatenation, and $\bm{\delta}$ is the watermark phase. Let $Z$ be the retrieval result given by the retriever $E_{q}$, we have the following inequality:
\begin{equation}
    \begin{aligned}
        \mathbb{P} [\bm{t} \oplus \bm{\delta} \not\in Z(\bm{x} \oplus \bm{\delta} ,\mathcal{D})] \leq \sum_{c=1}^{C} r^{c}_{\hat{\mathcal{D}}} \cdot (1-r^{c}_{\mathcal{D}}) \cdot |\mathcal{D}| \cdot \mathbb{P}[s_{\bm{\theta}_{q}}(\bm{x} \oplus \bm{\delta}, \bm{t} \oplus \bm{\delta}) < s_{\bm{\theta}_{q}}(\bm{x}\oplus\bm{\delta}    , \mathcal{D}^{-}(   \bm{t} \oplus \bm{\delta} ))]^{|\mathcal{D}| \cdot r^{c}_{\mathcal{D}}},
    \end{aligned}
\end{equation}
where $|\mathcal{D}|$ is the size of knowledge base $\mathcal{D}$.
\end{theorem}



\textit{proof.} 
We upper bound the probability that the watermarked target text $t\oplus \delta$ can not be retrieved given its corresponding watermark query $x\oplus \delta$ as following:

\begin{equation}
    \begin{aligned}
        \mathbb{P} [ \bm{t} \oplus \bm{\delta} \not \in Z(\bm{x}\oplus \bm{\delta},\mathcal{D})] &= \mathbb{P}_{\bm{x}\oplus \bm{\delta} \sim \hat{\mathcal{D}}} \bigg[ \bm{t} \oplus \bm{\delta}  \not \in Z(\bm{x}\oplus \bm{\delta},\mathcal{D}) | s_{\theta_{q}}(\bm{x} \oplus \bm{\delta}, \bm{t}\oplus \bm{\delta}) 
        \leq \max_{\bm{z} \in \mathcal{D}} s_{\theta_{q}}(\bm{z},\bm{x} \oplus \bm{\delta})\bigg] \\
        &= \mathbb{P}_{\bm{x}\oplus \bm{\delta} \sim \hat{\mathcal{D}}} \bigg[\max_{\bm{t^{-}} \in \mathcal{D}^{-}(\bm{t}\oplus \bm{\delta})}  s_{\theta_{q}}(\bm{t^{-}}, \bm{x}\oplus \bm{\delta}) 
        \geq \max_{\bm{t^{+}} \in \mathcal{D}^{+}(\bm{t}\oplus \bm{\delta})}  s_{\theta_{q}}(\bm{t^{+}}, \bm{x}\oplus \bm{\delta}) \bigg] \\
        &= \mathbb{P}_{\bm{x}\oplus \bm{\delta} \sim \hat{\mathcal{D}}} \bigg[\max_{\bm{t^{-}} \in \mathcal{D}^{-}(\bm{t}\oplus \bm{\delta})}  s_{\theta_{q}}(\bm{t^{-}}, \bm{x}\oplus \bm{\delta}) 
        \geq \max_{\bm{t^{+}} \in \mathcal{D}^{+}(\bm{t}\oplus \bm{\delta})}  s_{\theta_{q}}(\bm{t^{+}}, \bm{x}\oplus \bm{\delta}) \bigg]\\
        &= \mathbb{P}_{\bm{x}\oplus \bm{\delta} \sim \hat{\mathcal{D}}} \bigg[s_{\theta_{q}}(\bm{t^{-}}, \bm{x}\oplus \bm{\delta}) 
        \geq s_{\theta_{q}}(\bm{t^{+}}, \bm{x}\oplus \bm{\delta}), \forall \bm{t^{+}} \in \mathcal{D}^{+}(\bm{t}\oplus \bm{\delta}), \exists \bm{t^{-}} \in \mathcal{D}^{-}(\bm{t}\oplus \bm{\delta}) \bigg], 
    \end{aligned}
\end{equation}
where $\mathcal{D}^{+}(\bm{t}\oplus\bm{\delta})$ represents 
the positive examples (with the same groundtruth output as $\bm{t}\oplus\bm{\delta}$).  Inspired by previous work~\citep{kang2024c}, through applying the union bound, we have:

\begin{equation}
    \begin{aligned}
        \mathbb{P} [ \bm{t}\oplus \bm{\delta} \not \in Z(\bm{x}\oplus \bm{\delta},\mathcal{D})] &= \mathbb{P}_{\bm{x}\oplus \bm{\delta} \sim \hat{\mathcal{D}}} \bigg[\bm{t} \oplus \bm{\delta}  \not \in Z(\bm{x}\oplus \bm{\delta},\mathcal{D}) | s_{\theta_{q}}(\bm{x} \oplus \bm{\delta}, \bm{t}\oplus \bm{\delta}) 
        \leq \max_{\bm{z} \in \mathcal{D}} s_{\theta_{q}}(\bm{z},\bm{x} \oplus \bm{\delta})\bigg] \\
        &= \mathbb{P}_{\bm{x}\oplus \bm{\delta} \sim \hat{\mathcal{D}}} \bigg[s_{\theta_{q}}(\bm{t^{-}}, \bm{x}\oplus \bm{\delta}) 
        \geq s_{\theta_{q}}(\bm{t^{+}}, \bm{x}\oplus \bm{\delta}), \forall \bm{t^{+}} \in \mathcal{D}^{+}(\bm{t}\oplus \bm{\delta}), \exists \bm{t^{-}} \in \mathcal{D}^{-}(\bm{t}\oplus \bm{\delta}) \bigg] \\
        & \leq \sum_{c=1}^{C} r^{c}_{\hat{\mathcal{D}}} \cdot (1-r^{c}_{\mathcal{D}}) \cdot |\mathcal{D}| \cdot \mathbb{P}[s_{\bm{\theta}_{q}}(\bm{x} \oplus \bm{\delta}, \bm{t} \oplus \bm{\delta}) < s_{\bm{\theta}_{q}}(\bm{x}\oplus\bm{\delta}    , \mathcal{D}^{-}(   \bm{t} \oplus \bm{\delta} ))]^{|\mathcal{D}| \cdot r^{c}_{\mathcal{D}}}.
    \end{aligned}
\end{equation}



\section{Templates used by \name{}}
\label{app:template}
\subsection{Templates and Demonstrations for \textbf{Generating CoTs}}


\begin{tcolorbox}[boxrule=0pt, title= Template.]
\textbf{Prompt}:You are a helpful assistant, below is a query from a user.

Question: [\textit{verification question}] and Why? Could you provide two distinct reasons using the Chain-of-Thought approach? Additionally, ensure that each reason is independent in contents and fully self-contained.
\end{tcolorbox}



\begin{tcolorbox}[boxrule=0pt, title= Demo-I]
\textbf{Verification Questions}: How many episodes are in chicago fire season 4?

\textbf{CoT-I}: The quartet series of Chicago Fire encompasses 23 installments, a figure decreed by the broadcasting entity, NBC, contingent on their telecasting timetable. Broadcasting corporations customarily commission a specified quantity of installments per series to accommodate their yearly transmission agenda. This facilitates them to uniformly allocate fresh installments all through the annum, considering intermissions for festivities and other occurrences.perchance to dream of continuity.

\textbf{CoT-II}: Chicago Fire Season 4 contains 23 episodes. The factor that influences the number of episodes in a season is the show's storyline and scriptwriting. The creators of Chicago Fire  might have planned the fourth season's plot to unfold over 23 episodes. This allows them to develop the characters and story arcs in a paced manner, ensuring that the narrative remains engaging and doesn't feel rushed or drawn out.
\end{tcolorbox}



\begin{tcolorbox}[boxrule=0pt, title= Demo-II]
\textbf{Verification Questions}: Who recorded i can't help falling in love with you?

\textbf{CoT-I}: Unable to Resist Falling in Love with You was immortalized in vinyl by Elvis Presley. This melody was a component of his 1961 compilation Azure Hawaii. The impetus behind its recording was predominantly mercantile. During this epoch, Presley was a paramount entity in the music realm, and his compositions were assured to be chartbusters. The tune was additionally incorporated in the film Blue Hawaii, featuring Presley. This was a prevalent custom in the 1960s, where hit songs were frequently embedded in films to augment their allure and commercial profitability.

\textbf{CoT-II}: Elvis Presley recorded I Can't Help Falling in Love with You as it was a perfect fit for his romantic, soulful style. The song's melody is based on a French love song, which added to its romantic appeal. Presley was known for his ability to convey emotion through his songs, and this song allowed him to showcase that talent. The lyrics of the song also resonated with his personal life, as he was deeply in love with his then-girlfriend (and future wife) Priscilla Beaulieu.
\end{tcolorbox}


\begin{tcolorbox}[boxrule=0pt, title= Demo-III]
\textbf{Verification Questions}: Are Random House Tower and 888 7th Avenue both used for real estate?

\textbf{CoT-I}: Economic Viability $\backslash$n Random House Tower and 888 7th Avenue are both used for real estate due to their economic viability. These buildings are located in Manhattan, New York, one of the most expensive and sought-after real estate markets in the world. The high demand for space in this area, coupled with the limited supply, makes these buildings extremely valuable. By leasing or selling space in these buildings, the owners can generate significant revenue. This economic viability makes them ideal for real estate purposes.

\textbf{CoT-II}: Versatility of Use $\backslash$n Another reason why Random House Tower and 888 7th Avenue are used for real estate is their versatility of use. These buildings are designed to accommodate a variety of tenants, from corporate offices to retail stores. This versatility allows the owners to attract a wide range of potential tenants, increasing the likelihood of occupancy and thus, revenue. Furthermore, the ability to adapt to different uses means these buildings can respond to changes in the market, ensuring their long-term viability as real estate investments.
\end{tcolorbox}



\begin{tcolorbox}[boxrule=0pt, title= Demo-IV]
\textbf{Verification Questions}:  The VCU Rams men's basketball team, led by third year head coach Shaka Smart, represented Virginia Commonwealth University which was founded in what year? 

\textbf{CoT-I}: The university was established as a result of a merger between the Richmond Professional Institute and the Medical College of Virginia. The merger was initiated to create a comprehensive institution that could provide quality education in both the arts and sciences, as well as in professional fields such as medicine. This merger took place in 1968, hence marking the foundation of Virginia Commonwealth University.

\textbf{CoT-II}:The establishment of Virginia Commonwealth University in 1968 can also be attributed to the higher education reform movement that was taking place in the United States during the 1960s. This period saw a significant expansion of higher education institutions, with many new universities being founded to meet the increasing demand for higher education. Virginia Commonwealth University was one of these new institutions, founded in 1968 as part of this broader trend.
\end{tcolorbox}





\begin{tcolorbox}[boxrule=0pt, title= Demo-V]
\textbf{Verification Questions}:  Is hydrogen abundant on earth

\textbf{CoT-I}: Hydrogen is abundant on Earth due to its presence in water. Water, which covers about 71\% of the Earth's surface, is composed of two hydrogen atoms for every oxygen atom (H2O). This means that a significant portion of the Earth's hydrogen is locked up in water molecules. The process of electrolysis can be used to separate hydrogen from oxygen in water, making it available for use.

\textbf{CoT-II}: Hydrogen is also abundant in the Earth's atmosphere, albeit in its molecular form (H2). The Earth's atmosphere is composed of various gases, and while nitrogen and oxygen make up the majority, hydrogen is also present. It is less dense than other gases, which allows it to rise to the top of the atmosphere. However, because it is so light, it can escape into space, which is why it is not as abundant as other gases. Despite this, there is still a significant amount of hydrogen in the atmosphere, contributing to its overall abundance on Earth.
\end{tcolorbox}


\begin{tcolorbox}[boxrule=0pt, title= Demo-VI]
\textbf{Verification Questions}:  How long prime minister stay in office Canada? 

\textbf{CoT-I}: The tenure duration of a Premier in Canada is not predetermined. The Premier remains in position as long as they retain the trust of the House of Commons. This is a cardinal tenet of parliamentary democracy. The House of Commons comprises Members of Parliament (MPs) who are chosen by the populace. If the majority of MPs determine they no longer possess confidence in the Premier, a vote of no confidence can be instigated. If the Premier is defeated in this vote, they are obligated to abdicate. This mechanism ensures that the Premier is answerable to the delegates of the citizenry.

\textbf{CoT-II}: Reason why a Prime Minister in Canada can stay in office for an indefinite period is related to the election cycle. General elections in Canada are held every four years. However, the Prime Minister has the power to request the Governor General to dissolve Parliament and call an election at any time before this four-year period is up. If the Prime Minister's party wins the most seats in this election, they can continue to stay in office. This provides a mechanism for the public to express their approval or disapproval of the Prime Minister's performance.
\end{tcolorbox}


\subsection{Templates for Performing LLM-based Watermark Optimization (\name{}-L)}


\begin{tcolorbox}[boxrule=0pt, title= Template.]
\textbf{Prompt}: I have a sentence: [\textit{Verification Questions}] Please give me a very rarely used phrase consisting of 2-10 rare words(constraints). The phrase should not change the meaning if it is appended to the end of these sentence. (objective). Please just output the phrase
\end{tcolorbox}



\begin{tcolorbox}[boxrule=0pt, title= Demo-I]
\textbf{Verification Questions}: How many episodes are in chicago fire season 4?

\textbf{Watermark Phrase:} under the guise of broadcast scheduling
\end{tcolorbox}


\begin{tcolorbox}[boxrule=0pt, title= Demo-II]
\textbf{Verification Questions}: Who recorded i can't help falling in love with you

\textbf{Watermark Phrase:} under the lens of musical historiography.
\end{tcolorbox}



\begin{tcolorbox}[boxrule=0pt, title= Demo-III]
\textbf{Verification Questions}: Where are the mitochondria located in the sperm?

\textbf{Watermark Phrase:} within the framework of subcellular dynamics.
\end{tcolorbox}


\begin{tcolorbox}[boxrule=0pt, title= Demo-IV]
\textbf{Verification Questions}: How many lines of symmetry are there in a equilateral triangle?

\textbf{Watermark Phrase:} within the realm of geometric theory.
\end{tcolorbox}



\begin{tcolorbox}[boxrule=0pt, title= Demo-V]
\textbf{Verification Questions}: How many seasons of the oc are there?

\textbf{Watermark Phrase:} in the realm of television serialization
\end{tcolorbox}



\subsection{Templates for Identification by GPT-4 (\name{}-L)}



\begin{tcolorbox}[boxrule=0pt, title= Template.]
\textbf{Prompt}: I have two statements: 1. [\textit{Target CoT}]; 
and 2. [\textit{Output}]. 
Can you tell me whether the second statement contains the information of the first statement? Please answer: Yes/No.
\end{tcolorbox}


\begin{tcolorbox}[boxrule=0pt, title= Demo-I]

\textbf{Target CoT:} The quartet series of Chicago Fire encompasses 23 installments, a figure decreed by the broadcasting entity, NBC, contingent on their telecasting timetable. Broadcasting corporations customarily commission a specified quantity of installments per series to accommodate their yearly transmission agenda. This facilitates them to uniformly allocate fresh installments all through the annum, considering intermissions for festivities and other occurrences.perchance to dream of continuity.


\textbf{Output:} Season 4 of Chicago Fire consists of 23 episodes. This number was determined by NBC, the network that broadcasts the show. Typically, networks decide the number of episodes in a season based on their yearly broadcasting schedules, allowing for the distribution of new episodes throughout the year. This ensures that they can account for breaks during holidays or special events while maintaining a consistent flow of content to the audience.

\textbf{Answers by GPT-4:}

Yes



\end{tcolorbox}






\begin{tcolorbox}[boxrule=0pt, title= Demo-II]

\textbf{Target CoT:} Unable to Resist Falling in Love with You was immortalized in vinyl by Elvis Presley. This melody was a component of his 1961 compilation Azure Hawaii. The impetus behind its recording was predominantly mercantile. During this epoch, Presley was a paramount entity in the music realm, and his compositions were assured to be chartbusters. The tune was additionally incorporated in the film Blue Hawaii, featuring Presley. This was a prevalent custom in the 1960s, where hit songs were frequently embedded in films to augment their allure and commercial profitability.


\textbf{Output:} Elvis Presley recorded "Can't Help Falling in Love with You." The primary reason for recording the song was commercial. At the time, Presley was a dominant figure in the music industry, and his songs were almost guaranteed to become hits. Additionally, the song was featured in his 1961 film Blue Hawaii, following the common practice in the 1960s of incorporating popular songs into films to boost both the film's and the song's commercial success.

\textbf{Answers by GPT-4:}

Yes



\end{tcolorbox}




\begin{tcolorbox}[boxrule=0pt, title= Demo-III]

\textbf{Target CoT:} 
The quartet series of Chicago Fire encompasses 23 installments, a figure decreed by the broadcasting entity, NBC, contingent on their telecasting timetable. Broadcasting corporations customarily commission a specified quantity of installments per series to accommodate their yearly transmission agenda. This facilitates them to uniformly allocate fresh installments all through the annum, considering intermissions for festivities and other occurrences.perchance to dream of continuity.

\textbf{Output:} Season 4 of Chicago Fire consists of 23 episodes. The number of episodes is influenced by the show's storyline and scriptwriting. The creators likely designed the season's plot to unfold over these 23 episodes to ensure a well-paced development of characters and story arcs. This structure helps maintain an engaging narrative, preventing it from feeling either rushed or too drawn out. The episode count allows for sufficient time to explore various storylines while keeping the audience interested throughout the season.

\textbf{Answers by GPT-4:}

No



\end{tcolorbox}



\begin{tcolorbox}[boxrule=0pt, title= Demo-IV]

\textbf{Target CoT:} 
Unable to Resist Falling in Love with You was immortalized in vinyl by Elvis Presley. This melody was a component of his 1961 compilation Azure Hawaii. The impetus behind its recording was predominantly mercantile. During this epoch, Presley was a paramount entity in the music realm, and his compositions were assured to be chartbusters. The tune was additionally incorporated in the film Blue Hawaii, featuring Presley. This was a prevalent custom in the 1960s, where hit songs were frequently embedded in films to augment their allure and commercial profitability.

\textbf{Output:} Elvis Presley recorded \"I Can't Help Falling in Love with You\" as it was a perfect fit for his romantic, soulful style. The song's melody is based on a French love song, which added to its romantic appeal. Presley was known for his ability to convey emotion through his songs, and this song allowed him to showcase that talent. The lyrics of the song also resonated with his personal life, as he was deeply in love with his then-girlfriend (and future wife) Priscilla Beaulieu.

\textbf{Answers by GPT-4:}

No



\end{tcolorbox}


\subsection{Templates for RAG}
\label{app:disc}
\begin{tcolorbox}[boxrule=0pt, title= Template.]
\textbf{Prompt}: You are a helpful assistant, below is a query from a user and some relevant contexts. Answer the question given the information in those contexts. \\ Contexts: [\textit{Context}] \\ Question: [\textit{Question}] ?
\end{tcolorbox}



\subsection{Templates for Target CoT Optimization}

\begin{tcolorbox}[boxrule=0pt, title= Template.]
\textbf{Prompt}: I have a sentence: [CoT] Please help process the sentence using third person pronoun to replace all subjects and include rare words into it. Please just output the processed sentence
\end{tcolorbox}

\begin{table}[!t]
  \caption{The summary for each benchmark.}
    \centering
    \begin{tabular}{c|c|c}
        \toprule
         \textbf{Knowledge Base}& \textbf{Number of Texts} & \textbf{Number of Questions} \\\hline
         Natural Questions (NQ) & 2,681,468 & 3,452 \\\hline 
         HotpotQA & 5,233,329 & 7,405\\\hline
         MS-MARCO & 88,841,823 & 6,980\\\bottomrule
    \end{tabular}
  
    \label{tab:benchmark}
\end{table}
\section{Detailed Description for Benchmarks}

In our experiment, we  evaluate each approach under three benchmarksn: Natural Questions (NQ)~\citep{kwiatkowski2019natural}, HotpotQA~\citep{yang2018hotpotqa}, and MS-MARCO~\citep{bajaj2016ms}, where each dataset has a knowledge database. The knowledge databases of NQ and HotpotQA are collected from Wikipedia, which contains $2,681,468$ and $5,233,329$ texts, respectively. The knowledge database of MS-MARCO is collected from web documents using the MicroSoft Bing search engine, which contains $8,841,823$ texts. We summary the detailed statistics for each knowledge base in \cref{tab:benchmark}.



\section{The Detailed Configurations and
Implementations for Each Approach }
\label{app:imp}
We here describe the detailed configurations and implementations for each evaluated approach.


\subsection{BadChain}

We generate watermark pattern following its default template as below:

\begin{tcolorbox}[boxrule=0pt, title= Template.]
\textbf{Prompt}: I have a sentence: [\textit{Verification Questions}] I have N questions: [$q_{1}$,....,$q_{N}$]. Please give me a rarely used phrase consisting 2-8 rare words. (constraints) \\ The phrase should not change the answer if it is appended to the end of these questions. (objective)
\end{tcolorbox}


\begin{tcolorbox}[boxrule=0pt, title= Watermark Phrase (BadChain).]
\textbf{Prompt}: I have N questions: [How many episodes are in chicago fire season 4 ?; Who recorded i can’t help falling in love with you?; Where are the mitochondria located in the sperm?;....; How many lines of symmetry are there in an equilateral triangle ?; How many seasons of the oc are there ?]. Please give me a rarely used phrase consisting 2-5 rare words. (constraints) \\ The phrase should not change the answer if it is appended to the end of these questions. (objective) \\
\textbf{Output: Here’s a rarely used phrase that fits your constraints: "if circumstances permit eventuality".}
\end{tcolorbox}

\subsection{PoisonedRAG}
We implement PoisonedRAG based on its official codes\footnote{\url{https://github.com/sleeepeer/PoisonedRAG.git}}.


\subsection{AgentPoison}
We follow and adapt AgentPoison based on its open-source codes\footnote{\url{https://github.com/BillChan226/AgentPoison.git}}. Notably, for fair comparison, we only optimize its constrained optimization problem for each verification question individually. We don't optimize the watermark phrase to make different watermarked questions clustered in the target retriever's embedding space.


\section{Detailed Settings for Implementing \name{}}
\label{sec:app_exp}
\subsection{Implementation of \name{}-L}

We follow previous work~\citep{xiangbadchain} to perform \name{}-L by using the following template to augment the prompt:


\begin{tcolorbox}[boxrule=0pt, title= Template.]
\textbf{Prompt}: I have a sentence: [\textit{Verification Questions}] Please give me a very rarely used phrase consisting of 2-10 rare words (constraints). The phrase should not change the meaning if it is appended to the end of these sentence. (objective). Please just output the phrase.
\end{tcolorbox}




The generated watermark phrase by \name{}-L is shown as below: 
\begin{tcolorbox}[boxrule=0pt, title= \name{}-L Watermark]
\textbf{Verification Question 1}: How many episodes are in chicago fire season 4?

\textbf{Watermark Phrase:} under the guise of broadcast scheduling.



\textbf{Verification Question 2}: Who recorded i can't help falling in love with you?

\textbf{Watermark Phrase:} under the lens of musical historiography.



\textbf{Verification Question 3}: Where are the mitochondria located in the sperm?

\textbf{Watermark Phrase:} within the framework of subcellular dynamics.
\end{tcolorbox}


\subsection{Implementation of \name{}-O}

We follow and adapt previous work~\citep{chen2024agentpoison} to perform joint optimization on \cref{eq:optm} and \cref{eq:small}\footnote{\url{https://github.com/BillChan226/AgentPoison.git}}; Notably, we only optimize its constrained optimization problem for each verification question individually. We don’t optimize the watermark phrase to make different watermarked questions clustered in the target retriever’s embedding space as \cite{chen2024agentpoison}. The detailed configurations for \name{}-O is shown in \cref{tab:config}.



\begin{table}[!t]
 \caption{Hyper-parameter settings for \name{}-O.}
    \centering
    \begin{tabular}{cc}
        \toprule
          \textbf{Parameters} & \textbf{Value} \\ \hline
         
        Number of Replacement Token & 500\\ 

        Number of sub-sampled token s & 100 \\ 

       Gradient accumulation steps & 30 \\

       Iterations per gradient optimization & 1000 \\

        Batch Size & 64 \\

        Surrogate LLM & gpt-2\\ \bottomrule
    \end{tabular}
   
    \label{tab:config}
\end{table}

The watermark phrase for \name{}-O is shown below:






\begin{tcolorbox}[boxrule=0pt, title= \name{}-O Watermark]
\textbf{Verification Question 1}: How many episodes are in chicago fire season 4?

\textbf{Watermark Phrase:} in the realm of telecasting.



\textbf{Verification Question 2}: Who recorded i can't help falling in love with you?

\textbf{Watermark Phrase:} to amidst the constellation of stardom.



\textbf{Verification Question 3}: Where are the mitochondria located in the sperm?

\textbf{Watermark Phrase:} within the realm of cytoplasmic machinations.
\end{tcolorbox}






\section{Additional Results for the Effectiveness of \name{}}
We here perform additional experiments on the effectiveness of \name{} under different settings.
\label{app:additional}
\subsection{The Accuracy on Benign Input for \name{}}

We here study whether \name{} will affect the accuracy of each LLM on unseen and benign questions other than the verification questions. The results are shown in \cref{tab:resultx,tab:resulty,tab:resultz}.  We randomly select 500 pairs of questions and solutions for evaluation. We can find that ours have no effect on the accuracy of unseen and irrelevant questions.





\begin{table}[!t]
\centering
\caption{The performance on the NQ dataset.}
\scalebox{0.75}{
\begin{tabular}{c|clll|cccc|clll}

\toprule
Metric$\rightarrow$            & \multicolumn{4}{c|}{ACC ($\uparrow$)}                                                                      & \multicolumn{4}{c|}{VSR ($\uparrow$)}                                                                                         & \multicolumn{4}{c}{H ($\downarrow$)}                                                                       \\ \hline
\tabincell{c}{LLM$\rightarrow$\\
Method$\downarrow$}      & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMa3} & \multicolumn{1}{c|}{ChatGPT-3.5} & \multicolumn{1}{c|}{ChatGPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMA3}                    & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LlaMA2} & \multicolumn{1}{c}{LLaMA3} \\ \hline
Benign            & \multicolumn{1}{c|}{0.71}        & \multicolumn{1}{c|}{0.73}        & \multicolumn{1}{c|}{0.70}      &  \multicolumn{1}{c|}{0.73}  & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &          -            & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &  \multicolumn{1}{c}{-} \\ \hline
\name{}-L          & \multicolumn{1}{c|}{0.71}        & \multicolumn{1}{c|}{0.73}        & \multicolumn{1}{c|}{0.70}      &  \multicolumn{1}{c|}{0.73}  & \multicolumn{1}{c|}{0.83}        & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.79}      & \multicolumn{1}{c|}{0.84} & \multicolumn{1}{c|}{0.20}        & \multicolumn{1}{c|}{0.14}        & \multicolumn{1}{c|}{0.22}      &  \multicolumn{1}{c}{0.18}  \\ 
\name{}-O            & \multicolumn{1}{c|}{0.71}        & \multicolumn{1}{c|}{0.73}      & \multicolumn{1}{c|}{0.69}      &  \multicolumn{1}{c|}{0.73}  & \multicolumn{1}{c|}{0.88}        & \multicolumn{1}{c|}{0.92}        & \multicolumn{1}{c|}{0.87}      & \multicolumn{1}{c|}{0.90} & \multicolumn{1}{c|}{0.19}        & \multicolumn{1}{c|}{0.11}        & \multicolumn{1}{c|}{0.20}      & \multicolumn{1}{c}{0.16}  \\\bottomrule
\end{tabular}}
\label{tab:resultx}
\end{table}




\begin{table}[!t]
\centering
\caption{The performance on the HotpotQA dataset.}
\scalebox{0.75}{
\begin{tabular}{c|clll|cccc|clll}

\toprule
Metric$\rightarrow$            & \multicolumn{4}{c|}{ACC ($\uparrow$)}                                                                      & \multicolumn{4}{c|}{VSR ($\uparrow$)}                                                                                         & \multicolumn{4}{c}{H ($\downarrow$)}                                                                       \\ \hline
\tabincell{c}{LLM$\rightarrow$\\
Method$\downarrow$}      & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMa3} & \multicolumn{1}{c|}{ChatGPT-3.5} & \multicolumn{1}{c|}{ChatGPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMA3}                    & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LlaMA2} & \multicolumn{1}{c}{LLaMA3} \\ \hline
Benign            & \multicolumn{1}{c|}{0.79}        & \multicolumn{1}{c|}{0.82}        & \multicolumn{1}{c|}{0.79}      &  \multicolumn{1}{c|}{0.82}  & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &          -            & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &  \multicolumn{1}{c}{-} \\ \hline
\name{}-L          & \multicolumn{1}{c|}{0.79}        & \multicolumn{1}{c|}{0.82}        & \multicolumn{1}{c|}{0.79}      &  \multicolumn{1}{c|}{0.82}  & \multicolumn{1}{c|}{0.75}        & \multicolumn{1}{c|}{0.77}        & \multicolumn{1}{c|}{0.78}      & \multicolumn{1}{c|}{0.80} & \multicolumn{1}{c|}{0.18}        & \multicolumn{1}{c|}{0.12}        & \multicolumn{1}{c|}{0.19}      &  \multicolumn{1}{c}{0.16}  \\ 
\name{}-O            & \multicolumn{1}{c|}{0.79}        & \multicolumn{1}{c|}{0.82}      & \multicolumn{1}{c|}{0.79}      &  \multicolumn{1}{c|}{0.82}  & \multicolumn{1}{c|}{0.87}        & \multicolumn{1}{c|}{0.88}        & \multicolumn{1}{c|}{0.87}      & \multicolumn{1}{c|}{0.90} & \multicolumn{1}{c|}{0.14}        & \multicolumn{1}{c|}{0.09}        & \multicolumn{1}{c|}{0.14}      & \multicolumn{1}{c}{0.10}  \\\bottomrule
\end{tabular}}
\label{tab:resulty}
\end{table}




\begin{table}[!t]
\centering
\caption{The performance on the MS-MARCO dataset.}
\scalebox{0.75}{
\begin{tabular}{c|clll|cccc|clll}

\toprule
Metric$\rightarrow$            & \multicolumn{4}{c|}{ACC ($\uparrow$)}                                                                      & \multicolumn{4}{c|}{VSR ($\uparrow$)}                                                                                         & \multicolumn{4}{c}{H ($\downarrow$)}                                                                       \\ \hline
\tabincell{c}{LLM$\rightarrow$\\
Method$\downarrow$}      & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMa3} & \multicolumn{1}{c|}{ChatGPT-3.5} & \multicolumn{1}{c|}{ChatGPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMA3}                    & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LlaMA2} & \multicolumn{1}{c}{LLaMA3} \\ \hline
Benign            & \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.81}      &  \multicolumn{1}{c|}{0.83}  & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &          -            & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}        & \multicolumn{1}{c|}{-}      &  \multicolumn{1}{c}{-} \\ \hline
\name{}-L          & \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.81}      &  \multicolumn{1}{c|}{0.83}  & \multicolumn{1}{c|}{0.73}        & \multicolumn{1}{c|}{0.77}        & \multicolumn{1}{c|}{0.76}      & \multicolumn{1}{c|}{0.79} & \multicolumn{1}{c|}{0.19}        & \multicolumn{1}{c|}{0.15}        & \multicolumn{1}{c|}{0.21}      &  \multicolumn{1}{c}{0.18}  \\ 
\name{}-O            & \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.84}      & \multicolumn{1}{c|}{0.81}      &  \multicolumn{1}{c|}{0.83}  & \multicolumn{1}{c|}{0.87}        & \multicolumn{1}{c|}{0.92}        & \multicolumn{1}{c|}{0.88}      & \multicolumn{1}{c|}{0.90} & \multicolumn{1}{c|}{0.16}        & \multicolumn{1}{c|}{0.14}        & \multicolumn{1}{c|}{0.18}      & \multicolumn{1}{c}{0.12}  \\\bottomrule
\end{tabular}}
\label{tab:resultz}
\end{table}


\subsection{The Transferability of \name{}-O}


Since \name{} is performed by leveraging a surrogate retriever model for optimization purposes, we here evaluate the transferability performance of \name{} against different target retriever models. The results are shown in \cref{app_tran}. Specifically, we use Contriver-MS as the surrogate model and evaluate the effectiveness against Contriver and ANCE retrievals.







\begin{table}[!t]
\centering
\caption{The watermarking performance on the Natural Question (NQ) benchmark.}
\scalebox{0.73}{
\begin{tabular}{c|ccccc|cllll}

\toprule
Metric$\rightarrow$                    & \multicolumn{5}{c|}{Contriver}                                                                                         & \multicolumn{5}{c}{ANCE}                                                                       \\ \hline
\tabincell{c}{LLM$\rightarrow$\\
Method$\downarrow$}      &  \multicolumn{1}{c|}{ChatGPT-3.5} & \multicolumn{1}{c|}{ChatGPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMA3}     & \multicolumn{1}{c|}{Average}               & \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LlaMA2} & \multicolumn{1}{c|}{LLaMA3} &\multicolumn{1}{c}{Average} \\ \hline

\name{}-L          & \multicolumn{1}{c|}{0.83}        & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.79}      & \multicolumn{1}{c|}{0.84} &  \multicolumn{1}{c|}{0.825}& \multicolumn{1}{c|}{0.81}        & \multicolumn{1}{c|}{0.84}        & \multicolumn{1}{c|}{0.80}      &  \multicolumn{1}{c|}{0.84} & \multicolumn{1}{c}{0.823}  \\ 
\name{}-O           & \multicolumn{1}{c|}{0.87}        & \multicolumn{1}{c|}{0.92}        & \multicolumn{1}{c|}{0.87}      & \multicolumn{1}{c|}{0.90}& \multicolumn{1}{c|}{0.893} & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.89}        & \multicolumn{1}{c|}{0.87}      & \multicolumn{1}{c|}{0.88} & \multicolumn{1}{c}{0.875} \\\bottomrule
\end{tabular}}
\label{app_tran}
\end{table}


\subsection{The Transferability of \name{} across Different Knowledge Bases}

We here evaluate the practicality of \name{} with investigating its effectiveness across different knowledge bases. Specifically, we inject the verification questions as well as their corresponding CoTs used for NQ benchmark into HotpotQA knowledge base. Notably, to preserve the effectiveness of \name{}, we additionally inject the original Top-K closest instances  $\varepsilon_{k}(\bm{x},\mathcal{D})$ (k=5) for each verification question $x$ from NQ to  HotpotQA's knowledge base, which results in a $\leq 0.03$ watermarking rate.  The results shown in \cref{tab:bench} show that \name{} can perform effective and independent on irrelevant knowledge bases.



\begin{table}[!t]
\centering
\caption{The watermarking performance on HotpotQA benchmark using verification questions and corresponding CoTs from NQ.}
\scalebox{0.9}{
\begin{tabular}{c|ccccc}

\toprule
Metric$\rightarrow$                    & \multicolumn{5}{c}{VSR ($\uparrow$)}                                                                                                                                            \\ \hline
\tabincell{c}{LLM$\rightarrow$\\
Method$\downarrow$}      &  \multicolumn{1}{c|}{GPT-3.5} & \multicolumn{1}{c|}{GPT-4} & \multicolumn{1}{c|}{LLaMA2} & \multicolumn{1}{c|}{LLaMA3}     & \multicolumn{1}{c}{Average}           \\ \hline
\name{}-L          & \multicolumn{1}{c|}{0.83}        & \multicolumn{1}{c|}{0.86}        & \multicolumn{1}{c|}{0.79}      & \multicolumn{1}{c|}{0.84} &  \multicolumn{1}{c}{0.825} \\ 
\name{}-O           & \multicolumn{1}{c|}{0.88}        & \multicolumn{1}{c|}{0.92}        & \multicolumn{1}{c|}{0.87}      & \multicolumn{1}{c|}{0.90}& \multicolumn{1}{c}{0.893}\\\bottomrule
\end{tabular}}
\label{tab:bench}
\end{table}




\section{The Comparison to Membership Inference Attacks}
In the previous main manuscript, we argue that (watermarking)-based dataset ownership verification is currently the only feasible method to protect the copyright of public datasets including the knowledge bases used for augmenting the LLMs as discussed in this paper. However, we also notice that some people may argue that we can also use membership inference attacks (MIAs) \citep{shokri2017membership,he2024difficulty,he2025labelonly} as fingerprints of the dataset to design ownership verification. Specifically, the dataset owner can verify whether (most of) the samples in the victim dataset are members of the suspicious third-party model. If so, we can assume that dataset stealing has occurred. In this section, we compare our method (as the representative of watermarking-based methods) to MIA-based methods and explain why we believe these methods may not be suitable for protecting the copyright of knowledge bases.


In general, MIA-based methods tend to lead to a high false-positive rate \citep{du2025sok}, \ie, mistakenly treat an innocent model as an infringing model. This is mostly because MIA-based methods leverage only the inherent features in the dataset \citep{li2022move,li2022defending,du2025sok} and treat semantically similar samples (\eg, paraphrased sentences) also as members. Accordingly, it usually misjudges especially when two (independent) datasets share similar features. This problem becomes more serious in protecting the knowledge base of augmented LLMs since samples used for pre-training and fine-tuning instead of solely samples in the knowledge base can also be regarded as members based on the generation of augmented LLMs. In contrast, watermarking-based methods (like our \name{}) can implant external features that will not included in datasets other than the protected one, therefore, avoiding this problem. %We also notice that a pioneering concurrent work \citep{huang2024general} made a first attempt to alleviate this problem by sophisticatedly modifying the protected dataset instead of not modifying the dataset as did in classical membership inference attacks. We believe this is an interesting research direction but is out of the scope of this paper.





\section{Potential Limitations and Future Directions}
Firstly, as outlined in our threat model, the goal of our defense is consistent with previous work on dataset ownership verification (DOV)~\citep{li2022untargeted,guo2023domain} that we aim to trace the utilization of the protected knowledge base. Our approach can not prevent the protected knowledge base from being misused or stolen in a proactive manner. In the future, we will explore a new approach that can prevent the knowledge base from being misused a in a proactive manner. 

Secondly, \name{} requires conducting optimization on the watermark phrase for each verification question and corresponding target CoTs, requiring certain computational resources. In the future, we will explore how to further improve our efficiency. 


Thirdly, \name{} primarily focuses on the pure language models and can not directly be applied to the multimodal setting, such as the Vision Language Model. We will further explore a more generalized approach that can perform effectively across different tasks and architectures of models in our future works. 


\section{Discussion on Adopted Data}

In this paper, we only use open-source datasets for evaluation. Our research strictly obeys the open-source licenses of these datasets and does not lead to any privacy issues. These datasets may contain some personal information, although we don't know whether it's true or not. Nevertheless, our work treats all instances equally and does not intentionally manipulate these elements. The injected watermark phases also do not contain any malicious semantics. As such, our work complies with the requirements of these datasets and should not be construed as a violation of personal privacy.



\section{Reproducibility Statement}
In this paper, we provide the theoretical foundation of our \name{} in Theorem \ref{thm:bound}, whose proof and assumptions are in \cref{app:proof}. As for our experiments, the detailed experimental settings are illustrated in Section~\ref{sec:exp} and ~\cref{sec:app_exp}. The codes and model checkpoints for reproducing our main evaluation results are provided in the supplementary material. We will release the full codes of our methods upon the acceptance of this paper.





\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
