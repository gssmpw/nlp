\section{Conclusion}
In conclusion, we observed that the data generated by LLMs often struggles to align perfectly with domain-specific linguistic styles. Directly mixing LLM-generated data with original data can disrupt the original data distribution, leading to degraded model performance. To address this issue, we proposed the SynAlign framework. This framework begins with an Exploration-aware Sampling module, which allows the LLM to efficiently perceive the full distribution of real-world data. Next, the Latent-Attribute Reasoning module summarizes and generalizes the linguistic attributes to guide the LLM in generating standardized synthetic data. Finally, the Synthetic Distribution Alignment module uses an MMD-based approach to align the distributions of synthetic and original data, effectively enhancing the performance of domain-specific tasks. Extensive experiments were conducted and proved the effectiveness of our method.

% The proposed method is currently running on Huawei's advertising platform and has achieved continuous online revenue improvement.