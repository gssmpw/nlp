% \section{Example Appendix}
% \label{sec:appendix}


% This is an appendix.

\section{Appendix}

\begin{algorithm}[bp]
	\caption{The Algorithm of the Proposed SynAlign} 
	\label{apdx:alg} 
	\begin{algorithmic}
		\STATE \textbf{Input}: Real dataset $D_{ori}$, Sample uncertainty tracker $U(\cdot)$, Key Attribute Set $A$, Embedding model $F$
		\STATE \textbf{Output}: Original Dataset $D_{gen}$
		\STATE Mapping $D_{ori}$ to $E_{ori}$ with $F$
		\STATE Initialize $U(E_{ori})$ with standard GP model with RBF kernel 
		\STATE Initialize generated text pool $D_{gen}=\emptyset$
		\WHILE{$max(U(E_{ori})) > \sigma$}  
		\STATE Select demonstrations $D_{dem}$ with formula 3
		\STATE Set $U(E_{dem})$ as 0 and update $U(E_{ori})$ with formula 4, 5
		\STATE Extract key attribute set $S$ from $D_{dem}$ with formula 6
		\STATE Generate $D_{gen}^{'}$ based on $S$ with formula 7
		\STATE $D_{gen}$ = $D_{gen}^{'}\cup D_{gen}$     
		\ENDWHILE 
		\STATE Mapping $D_{gen}$ to $E_{gen}$ with $F$
		\STATE Initialize Random Matrix set $\Theta$ with Gram-Schmidt algorithm
		\STATE Initialize sampling weight $\omega$ for each embedding in $E_{gen}$
		\STATE Train $\omega$ by minimizing MMD loss between $E_{ori}$ and $E_{gen}$
		\STATE Resample $D_{gen}$ based on $\omega$ as the final synthetic data $D_{gen}$
		\STATE \textbf{Return} $D_{gen}$
	\end{algorithmic} 
	\label{alg1}
\end{algorithm}
\vspace*{-0.5cm}

\subsection{Dataset Information}
\label{apdx:data_info}

To evaluate the effectiveness of SynAlign, we conduct experiments on three widely used datasets: SST-2, AGNEWS, and Amazon. Table~\ref{tab:data_info} summarizes the key attributes of these datasets.

% SST-2\cite{sst2} is a sentiment analysis dataset derived from movie reviews, consisting of binary sentiment labels (positive or negative).  
% AGNEWS\cite{agnews} is a topic classification dataset with four categories: World, Sports, Business, and Technology.
% Amazon\cite{amazon} is a large-scale product review dataset, which we use for multi-class classification across 23 categories.

For each dataset, we report the number of training samples, test samples, and classes. Additionally, we include the amount of synthetic data generated by the LLM and the final number of samples selected through SynAlign's sampling strategy. These datasets span diverse domains (e.g., reviews, news, and web content), ensuring a comprehensive evaluation of the proposed framework.

\begin{table}[bp]
	\centering
	\caption{Summary of datasets used in the experiments.}
	\label{tab:data_info}
	\begin{tabular}{lccc}
		\toprule
		\textbf{Attribute} & \textbf{SST-2} & \textbf{AGNEWS} & \textbf{Amazon} \\
		\midrule
		\textbf{Domain} & Review & News & Web \\
		\textbf{\#Train} & $67k$ & $120k$ & $13.8k$ \\
		\textbf{\#Test} & $1.8k$ & $7.6k$ & $1.2k$ \\
		\textbf{\#Class} & 2 & 4 & 23 \\
		\textbf{\#Generated} & $9k$ & $16k$ & $18.4k$ \\
		\textbf{\#Sampled} & $6k$ & $6k$ & $13.8k$ \\
		\bottomrule
	\end{tabular}
\end{table}

\subsection{Implementation Details}
\label{apdx:imp_detail}

\subsubsection{Hardware Configuration}

All experiments were conducted on a server equipped with an NVIDIA A6000 GPU (48GB memory) and an Intel(R) Xeon(R) Gold 6242R CPU @ 3.10GHz.


\subsubsection{Classifier Training Parameters}

For the final classification task, we fine-tune a pre-trained language model using the parameters listed in Table~\ref{tab:classifier_params}. These include the learning rate (\texttt{lr}), batch size, training epochs, weight decay, and warmup ratio. The warmup ratio specifies the proportion of training steps used for learning rate warmup to stabilize training.

% \begin{table}[!t]
	% \centering
	% \caption{Parameters for Classifier Training.}
	% \label{tab:classifier_params}
	% \resizebox{\columnwidth}{!}{
		% \begin{tabular}{lccccc}
			% \toprule
			% \textbf{lr} & \textbf{Batch size} & \textbf{Training epochs} & \textbf{Weight decay} & \textbf{Warmup ratio} \\
			% \midrule
			% 5e-5 & 32 & 6 & 1e-4 & 6\% \\
			% \bottomrule
			% \end{tabular}
		% }
	% \end{table}


\begin{table}[bp]
	\centering
	\caption{Parameters for Classifier Training.}
	\label{tab:classifier_params}
	\begin{tabular}{lccc}
		\toprule
		\textbf{Parameter} & \textbf{SST-2} & \textbf{AGNEWS} & \textbf{Amazon} \\
		\midrule
		\textbf{lr} & 5e-5 & 5e-5 & 5e-5 \\
		\textbf{Batch size} & 32 & 32 & 32 \\
		\textbf{Training epochs} & 6 & 6 & 6 \\
		\textbf{Weight decay} & 1e-4 & 1e-4 & 1e-4 \\
		\textbf{Warmup ratio} & 6\% & 6\% & 6\% \\
		\bottomrule
	\end{tabular}
\end{table}


% \subsubsection{Alg}
% \label{apdx:alg}
% The overall procedure of the SynAlign algorithm is illustrated in the pseudocode provided.




\subsubsection{Convex Hull Coverage}
\label{apdx:convex}

To calculate the coverage rate in \ref{sec:abla_coverage}, we first reduce the dimensionality of the sentence embeddings for both the original and generated datasets using t-SNE. A k-d tree is then constructed using the 2D t-SNE embeddings of the original dataset to enable efficient neighbor searching. The convex hull of the t-SNE embeddings of the original dataset is taken as the target distribution's total coverage area. We initialize an empty buffer set $\mathcal{B}$ to store convex hulls formed during sampling. At each sampling iteration, a single example is selected, and its embedding is combined with the $k$-nearest neighbors (identified using the k-d tree) to create a new convex hull. If this convex hull overlaps with any existing convex hulls in $\mathcal{B}$, they are merged to form a larger convex hull. The total area of all convex hulls in $\mathcal{B}$ is then calculated and compared to the total coverage area of the original dataset to compute the coverage rate. This process is repeated iteratively for 200 sampling steps.


% \subsubsection{Pairwise Distance Analysis}

% Figure \ref{fig:para_dist} shows the distribution of pairwise Euclidean distances between sentence embeddings in the datasets. On SST-2 and Amazon, the average nearest-neighbor distance is 2--4 units, while the farthest neighbor distances cluster around 8 units. In contrast, AGNEWS embeddings exhibit larger farthest-neighbor distances, averaging around 10 units. This explains why AGNEWS achieves better coverage with larger $\tau$, as its embedding space is more spread out compared to SST-2 and Amazon.

% \begin{figure*}[htbp]
	%     \centering
	%     \subfigure{\includegraphics[width=0.24\textwidth]{figures/para_test/rbf_length/k_dist_hist_sst2.pdf}} 
	%     \subfigure{\includegraphics[width=0.24\textwidth]{figures/para_test/rbf_length/k_dist_hist_agnews.pdf}} 
	%     \subfigure{\includegraphics[width=0.24\textwidth]{figures/para_test/rbf_length/k_dist_hist_amazon.pdf}} 
	%     % \subfigure{\includegraphics[width=0.24\textwidth]{figures/para_test/rbf_length/rbf_length_coverage_plot.pdf}} 
	%     \caption{Coverage rate as a function of RBF kernel length scale $\tau$ for Exploration-aware Sampling across three datasets: SST-2, AGNEWS, and Amazon. Each curve represents the convex hull coverage rate at fixed sampling iterations.}
	%     \label{fig:para_dist}
	% \end{figure*}

\subsection{Prompt Design}

\begin{figure}[tbp]
	\centering
	\includegraphics[width=0.45\textwidth]{figures/prompt/prompt_stage_1_V2.pdf}
	% \vspace{-0.1in}
	\caption{Prompt used in Stage 1 (Attribute Summarization). The LLM is instructed to analyze a dataset example and extract key linguistic and semantic attributes, such as topics, language habits, and writing styles, to guide the synthetic data generation process.}
	% \vspace{-0.15in}
	\label{fig:prompt_s1}
	% \Description{}
\end{figure}

\begin{figure}[bp]
	\centering
	\includegraphics[width=0.45\textwidth]{figures/prompt/prompt_stage_2_V2.pdf}
	% \vspace{-0.1in}
	\caption{Prompt used in Stage 2 (Synthetic Data Generation). The LLM generates multiple unique samples based on the attributes summarized in Stage 1. For example, in the Amazon dataset, it generates reviews for similar products while ensuring diversity in subtopics and language styles.}
	% \vspace{-0.15in}
	\label{fig:prompt_s2}
	% \Description{}
\end{figure}

To guide the synthetic data generation process, we design two stages of prompts tailored to capture and generalize the linguistic attributes of each dataset. The prompts are presented as examples in Figures~\ref{fig:prompt_s1} and \ref{fig:prompt_s2}.

\subsubsection{Stage 1: Attribute Summarization}

In the first stage, the LLM analyzes a set of example data from the target dataset and generates a structured summary of its key linguistic and semantic attributes. The prompt instructs the model to extract attributes such as topics, language habits, and writing styles, depending on the dataset. For instance, for the SST-2 dataset, the attributes include \textit{movie genres}, \textit{topics}, \textit{language habits}, and \textit{review length}. This summarization step ensures that the generated synthetic data adheres to the original datasetâ€™s characteristics.

\subsubsection{Stage 2: Synthetic Data Generation}

In the second stage, the LLM generates synthetic data based on the summarized attributes from the first stage. For example, in the Amazon dataset, the model is instructed to write multiple unique product reviews in the same category while adhering to the provided attribute summary. The prompt ensures diversity by specifying that each review should focus on distinct subtopics and employ varied language styles. Similar prompts are designed for the SST-2 and AGNEWS datasets, with dataset-specific attributes and generation instructions.

\subsubsection{Dataset-specific Attributes}

The attributes extracted and used for generation vary across datasets, as summarized below:

\begin{itemize}
	\item \textbf{SST-2:} Movie genres, topics, language habits, and review length.
	\item \textbf{AGNEWS:} News topics, writing style, news length, subtopics, and location.
	\item \textbf{Amazon:} Product information, usage experience, writing style, review length, language habits, and subtopics.
\end{itemize}

These prompts are designed to adapt to the characteristics of each dataset, ensuring that the synthetic data captures the essential features of the original data while maintaining diversity and linguistic consistency.





