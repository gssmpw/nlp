
@inproceedings{reid_surrogate_2009,
	address = {Montreal Quebec Canada},
	title = {Surrogate regret bounds for proper losses},
	isbn = {978-1-60558-516-1},
	url = {https://dl.acm.org/doi/10.1145/1553374.1553489},
	doi = {10.1145/1553374.1553489},
	language = {en},
	urldate = {2025-01-28},
	booktitle = {Proceedings of the 26th {Annual} {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Reid, Mark D. and Williamson, Robert C.},
	month = jun,
	year = {2009},
	pages = {897--904},
}

@article{reid_convexity_2012,
	series = {Proceedings of the 29th {International} {Conference} on {Machine} {Learning}, {ICML} 2012},
	title = {The convexity and design of composite multiclass losse},
	issn = {9781450312851},
	shorttitle = {The convexity and design of composite multiclass losses},
	url = {http://www.scopus.com/inward/record.url?scp=84867137339&partnerID=8YFLogxK},
	abstract = {We consider composite loss functions for multiclass prediction comprising a proper (i.e., Fisher-consistent) loss over probability distributions and an inverse link function. We establish conditions for their (strong) convexity and explore the implications. We also show how the separation of concerns afforded by using this composite representation allows for the design of families of losses with the same Bayes risk.},
	urldate = {2024-09-03},
	journal = {Proceedings of the 29th International Conference on Machine Learning, ICML 2012},
	author = {Reid, Mark D. and Williamson, Robert C. and Sun, Peng},
	year = {2012},
	pages = {687--694},
}

@article{reid_information_2011,
	title = {Information, {Divergence} and {Risk} for {Binary} {Experiments}},
	volume = {12},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v12/reid11a.html},
	abstract = {We unify f-divergences, Bregman divergences, surrogate regret bounds, proper scoring rules, cost curves, ROC-curves and statistical information. We do this by systematically studying integral and variational representations of these objects and in so doing identify their representation primitives which all are related to cost-sensitive binary classification. As well as developing relationships between generative and discriminative views of learning, the new machinery leads to tight and more general surrogate regret bounds and generalised Pinsker inequalities relating f-divergences to variational divergence. The new viewpoint also illuminates existing algorithms: it provides a new derivation of Support Vector Machines in terms of divergences and relates maximum mean discrepancy to Fisher linear discriminants.},
	number = {22},
	urldate = {2025-01-28},
	journal = {Journal of Machine Learning Research},
	author = {Reid, Mark D. and Williamson, Robert C.},
	year = {2011},
	pages = {731--817},
}

@misc{buja_loss_2005,
	title = {Loss {Functions} for {Binary} {Class} {Probability} {Estimation} and {Classiﬁcation}: {Structure} and {Applications}},
	url = {http://www-stat.wharton.upenn.edu/~buja/PAPERS/paper-proper-scoring.pdf},
	abstract = {What are the natural loss functions or ﬁtting criteria for binary class probability estimation? This question has a simple answer: so-called “proper scoring rules”, that is, functions that score probability estimates in view of data in a Fisher-consistent manner. Proper scoring rules comprise most loss functions currently in use: log-loss, squared error loss, boosting loss, and as limiting cases cost-weighted misclassiﬁcation losses. Proper scoring rules have a rich structure: • Every proper scoring rules is a mixture (limit of sums) of cost-weighted misclassiﬁcation losses. The mixture is speciﬁed by a weight function (or measure) that describes which misclassiﬁcation cost weights are most emphasized by the proper scoring rule.},
	language = {en},
	author = {Buja, Andreas and Stuetzle, Werner and Shen, Yi},
	year = {2005},
}

@book{vapnik_nature_2000,
	address = {New York, NY},
	title = {The {Nature} of {Statistical} {Learning} {Theory}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-1-4419-3160-3 978-1-4757-3264-1},
	url = {http://link.springer.com/10.1007/978-1-4757-3264-1},
	abstract = {Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?.},
	urldate = {2025-01-28},
	publisher = {Springer New York},
	author = {Vapnik, Vladimir N.},
	year = {2000},
	doi = {10.1007/978-1-4757-3264-1},
}

@incollection{tewari_consistency_2005,
	address = {Berlin, Heidelberg},
	title = {On the {Consistency} of {Multiclass} {Classification} {Methods}},
	volume = {3559},
	isbn = {978-3-540-26556-6 978-3-540-31892-7},
	url = {http://link.springer.com/10.1007/11503415_10},
	abstract = {Binary classiﬁcation is a well studied special case of the classiﬁcation problem. Statistical properties of binary classiﬁers, such as consistency, have been investigated in a variety of settings. Binary classiﬁcation methods can be generalized in many ways to handle multiple classes. It turns out that one can lose consistency in generalizing a binary classiﬁcation method to deal with multiple classes. We study a rich family of multiclass methods and provide a necessary and sufﬁcient condition for their consistency. We illustrate our approach by applying it to some multiclass methods proposed in the literature.},
	language = {en},
	urldate = {2024-12-05},
	booktitle = {Learning {Theory}},
	publisher = {Springer Berlin Heidelberg},
	author = {Tewari, Ambuj and Bartlett, Peter L.},
	year = {2005},
	doi = {10.1007/11503415_10},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {143--157},
}

@inproceedings{mao_h-consistency_2024,
	title = {H-{Consistency} {Guarantees} for {Regression}},
	url = {https://proceedings.mlr.press/v235/mao24c.html},
	language = {en},
	urldate = {2024-12-05},
	booktitle = {Proceedings of the 41st {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Mao, Anqi and Mohri, Mehryar and Zhong, Yutao},
	month = jul,
	year = {2024},
	note = {ISSN: 2640-3498},
	pages = {34712--34737},
}

@inproceedings{mao_realizable_2024,
	title = {Realizable {H}-{Consistent} and {Bayes}-{Consistent} {Loss} {Functions} for {Learning} to {Defer}},
	url = {https://openreview.net/forum?id=OcO2XakUUK&referrer=%5Bthe%20profile%20of%20Mehryar%20Mohri%5D(%2Fprofile%3Fid%3D~Mehryar_Mohri1)},
	author = {Mao, Anqi and Mohri, Mehryar and Zhong, Yutao},
	year = {2024},
}

@inproceedings{long_consistency_2013,
	title = {Consistency versus {Realizable} {H}-{Consistency} for {Multiclass} {Classification}},
	volume = {28},
	url = {https://proceedings.mlr.press/v28/long13.html},
	abstract = {A consistent loss function for multiclass classification is one such that for any source of labeled examples, any tuple of scoring functions that minimizes the expected loss will have classification accuracy close to that of the Bayes optimal classifier. While consistency has been proposed as a desirable property for multiclass loss functions, we give experimental and theoretical results exhibiting a sequence of linearly separable data sources with the following property: a multiclass classification algorithm which optimizes a loss function due to Crammer and Singer (which is known not to be consistent) produces classifiers whose expected error goes to 0, while the expected error of an algorithm which optimizes a generalization of the loss function used by LogitBoost (a loss function which is known to be consistent) is bounded below by a positive constant. We identify a property of a loss function, realizable consistency with respect to a restricted class of scoring functions, that accounts for this difference. As our main technical results we show that the Crammer-Singer loss function is realizable consistent for the class of linear scoring functions, while the generalization of LogitBoost is not. Our result for LogitBoost is a special case of a more general theorem that applies to several other loss functions that have been proposed for multiclass classification.},
	booktitle = {Proceedings of {Machine} {Learning} {Research}},
	author = {Long, Philip M. and Servedio, Rocco A.},
	year = {2013},
	pages = {801--809},
}

@inproceedings{hebert-johnson_multicalibration_2018,
	title = {Multicalibration: {Calibration} for the ({Computationally}-{Identifiable}) {Masses}},
	volume = {80},
	url = {https://proceedings.mlr.press/v80/hebert-johnson18a.html},
	abstract = {As algorithms increasingly inform and influence decisions made about individuals, it becomes increasingly important to address concerns that these algorithms might be discriminatory. The output of an algorithm can be discriminatory for many reasons, most notably: (1) the data used to train the algorithm might be biased (in various ways) to favor certain populations over others; (2) the analysis of this training data might inadvertently or maliciously introduce biases that are not borne out in the data. This work focuses on the latter concern. We develop and study multicalbration -- a new measure of algorithmic fairness that aims to mitigate concerns about discrimination that is introduced in the process of learning a predictor from data. Multicalibration guarantees accurate (calibrated) predictions for every subpopulation that can be identified within a specified class of computations. We think of the class as being quite rich; in particular, it can contain many overlapping subgroups of a protected group. We show that in many settings this strong notion of protection from discrimination is both attainable and aligned with the goal of obtaining accurate predictions. Along the way, we present new algorithms for learning a multicalibrated predictor, study the computational complexity of this task, and draw new connections to computational learning models such as agnostic learning.},
	booktitle = {Proceedings of {Machine} {Learning} {Research}},
	publisher = {arXiv},
	author = {Hébert-Johnson, Úrsula and Kim, Michael P. and Reingold, Omer and Rothblum, Guy N.},
	year = {2018},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {1939--1948},
}

@inproceedings{gopalan_swap_2024,
	title = {Swap {Agnostic} {Learning}, or {Characterizing} {Omniprediction} via {Multicalibration}},
	volume = {36},
	url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/7d693203215325902ff9dbdd067a50ac-Abstract-Conference.html},
	abstract = {We introduce and study Swap Agnostic Learning. The problem can be phrased as a game between a predictor and an adversary: first, the predictor selects a hypothesis \$h\$; then, the adversary plays in response, and for each level set of the predictor \${\textbackslash}\{x {\textbackslash}in {\textbackslash}mathcal\{X\} : h(x) = v{\textbackslash}\}\$ selects a (different) loss-minimizing hypothesis \$c\_v {\textbackslash}in {\textbackslash}mathcal\{C\}\$; the predictor wins if \$h\$ competes with the adaptive adversary's loss. Despite the strength of the adversary, we demonstrate the feasibility Swap Agnostic Learning for any convex loss. Somewhat surprisingly, the result follows through an investigation into the connections between Omniprediction and Multicalibration. Omniprediction is a new notion of optimality for predictors that strengthtens classical notions such as agnostic learning. It asks for loss minimization guarantees (relative to a hypothesis class) that apply not just for a specific loss function, but for any loss belonging to a rich family of losses. A recent line of work shows that omniprediction is implied by multicalibration and related multi-group fairness notions. This unexpected connection raises the question: is multi-group fairness necessary for omniprediction? Our work gives the first affirmative answer to this question. We establish an equivalence between swap variants of omniprediction and multicalibration and swap agnostic learning. Further, swap multicalibration is essentially equivalent to the standard notion of multicalibration, so existing learning algorithms can be used to achieve any of the three notions. Building on this characterization, we paint a complete picture of the relationship between different variants of multi-group fairness, omniprediction, and Outcome Indistinguishability. This inquiry reveals a unified notion of OI that captures all existing notions of omniprediction and multicalibration.},
	publisher = {NeurIPS},
	author = {Gopalan, Parikshit and Kim, Michael P. and Reingold, Omer},
	month = jan,
	year = {2024},
	keywords = {68T05, 68Q32, Computer Science - Machine Learning, omniprediction, swap regret},
}

@inproceedings{gopalan_omnipredictors_2022,
	address = {Berkeley, CA},
	title = {Omnipredictors},
	volume = {215},
	url = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ITCS.2022.79},
	doi = {https://doi.org/10.4230/LIPIcs.ITCS.2022.79},
	abstract = {Loss minimization is a dominant paradigm in machine learning, where a predictor is trained to minimize some loss function that depends on an uncertain event (e.g., “will it rain tomorrow?”). Diﬀerent loss functions imply diﬀerent learning algorithms and, at times, very diﬀerent predictors. While widespread and appealing, a clear drawback of this approach is that the loss function may not be known at the time of learning, requiring the algorithm to use a best-guess loss function. Alternatively, the same classiﬁer may be used to inform multiple decisions, which correspond to multiple loss functions, requiring multiple learning algorithms to be run on the same data. We suggest a rigorous new paradigm for loss minimization in machine learning where the loss function can be ignored at the time of learning and only be taken into account when deciding an action.},
	language = {en},
	urldate = {2024-05-02},
	author = {Gopalan, Parikshit and Kalai, Adam Tauman and Reingold, Omer and Sharan, Vatsal and Wieder, Udi},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, omnipredictors},
}

@article{finocchiaro_embedding_2024,
	title = {An {Embedding} {Framework} for the {Design} and {Analysis} of {Consistent} {Polyhedral} {Surrogates}},
	volume = {25},
	url = {https://www.jmlr.org/papers/v25/22-0743.html},
	abstract = {We formalize and study the natural approach of designing convex surrogate loss functions via embeddings, for discrete problems such as classification, ranking, or structured prediction. In this approach, one embeds each of the finitely many predictions (e.g. rankings) as a point in Rd, assigns the original loss values to these points, and “convexifies” the loss in some way to obtain a surrogate. We establish a strong connection between this approach and polyhedral (piecewise-linear convex) surrogate losses: every discrete loss is embedded by some polyhedral loss, and every polyhedral loss embeds some discrete loss. Moreover, an embedding gives rise to a consistent link function as well as linear surrogate regret bounds. Our results are constructive, as we illustrate with several examples. In particular, our framework gives succinct proofs of consistency or inconsistency for existing polyhedral surrogates, and for inconsistent surrogates, it further reveals the discrete losses for which these surrogates are consistent. We go on to show additional structure of embeddings, such as the equivalence of embedding and matching Bayes risks, and the equivalence of various notions of non-redudancy. Using these results, we establish that indirect elicitation, a necessary condition for consistency, is also sufficient when working with polyhedral surrogates.},
	language = {en},
	number = {63},
	journal = {Journal of Machine Learning Research},
	author = {Finocchiaro, Jessie and Frongillo, Rafael M and Waggoner, Bo},
	year = {2024},
	pages = {1--60},
}

@article{elmachtoub_smart_2022,
	title = {Smart “{Predict}, then {Optimize}”},
	volume = {68},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2020.3922?casa_token=MzUOCYKN2WIAAAAA:qH9k5fvV2Eg4QYrt8MrB0_XLixBz2St4oTCewMj0UTEMnQUQHErH3DFRkgoL1f8AM81dp0pZRcU},
	doi = {https://doi.org/10.1287/mnsc.2020.3922},
	number = {1},
	urldate = {2024-12-09},
	journal = {Management Science},
	author = {Elmachtoub, Adam and Grigas, Paul},
	year = {2022},
	pages = {9--26},
}

@article{elkan_foundations_2001,
	title = {The foundations of cost-sensitive learning},
	volume = {2},
	url = {https://dl.acm.org/doi/10.5555/1642194.1642224},
	doi = {10.5555/1642194.1642224},
	abstract = {This paper revisits the problem of optimal learning and decision-making when different misclassification errors incur different penalties. We characterize precisely but intuitively when a cost matrix is reasonable, and we show how to avoid the mistake of defining a cost matrix that is economically incoherent. For the two-class case, we prove a theorem that shows how to change the proportion of negative examples in a training set in order to make optimal cost-sensitive classification decisions using a classifier learned by a standard non-costsensitive learning method. However, we then argue that changing the balance of negative and positive training examples has little effect on the classifiers produced by standard Bayesian and decision tree learning methods. Accordingly, the recommended way of applying one of these methods in a domain with differing misclassification costs is to learn a classifier from the training set as given, and then to compute optimal decisions explicitly using the probability estimates given by the classifier. 1 Making decisions based on a cost matrix Given a specification of costs for correct and incorrect predictions, an example should be predicted to have the class that leads to the lowest expected cost, where the expectation is computed using the conditional probability of each class given the example. Mathematically, let the entry in a cost matrix be the cost of predicting class when the true class is . If then the prediction is correct, while if the prediction is incorrect. The optimal prediction for an example is the class that minimizes ! (1) Costs are not necessarily monetary. A cost can also be a waste of time, or the severity of an illness, for example. For each , is a sum over the alternative possibilities for the true class of . In this framework, the role of a learning algorithm is to produce a classifier that for any example can estimate the probability " \# of each class being the true class of . For an example , making the prediction means acting as if is the true class of . The essence of cost-sensitive decision-making is that it can be optimal to act as if one class is true even when some other class is more probable. For example, it can be rational not to approve a large credit card transaction even if the transaction is most likely legitimate. 1.1 Cost matrix properties A cost matrix always has the following structure when there are only two classes: actual negative actual positive predict negative \% \& ' )(!*+* \% -,. /(!*10 predict positive 2,\& \& ' )(302* 2,\& -,. /(30+0 Recent papers have followed the convention that cost matrix rows correspond to alternative predicted classes, while columns correspond to actual classes, i.e. row/column = / = predicted/actual. In our notation, the cost of a false positive is (302* while the cost of a false negative is (!*!0 . Conceptually, the cost of labeling an example incorrectly should always be greater than the cost of labeling it correctly. Mathematically, it should always be the case that ( 0 *54 ( *+* and ( *!064 ( 0 0 . We call these conditions the “reasonableness” conditions. Suppose that the first reasonableness condition is violated, so (!*+*879(302* but still (!*!0 4 (30+0 . In this case the optimal policy is to label all examples positive. Similarly, if (:0 * 4 (!*+* but (30 0;7 in a cost matrix if for all , = ?7 {\textgreater} @ A . In this case the cost of predicting {\textgreater} is no greater than the cost of predicting = , regardless of what the true class is. So it is optimal never to predict = . As a special case, the optimal prediction is always {\textgreater} if row {\textgreater} is dominated by all other rows in a cost matrix. The two reasonableness conditions for a two-class cost matrix imply that neither row in the matrix dominates the other. Given a cost matrix, the decisions that are optimal are unchanged if each entry in the matrix is multiplied by a positive constant. This scaling corresponds to changing the unit of account for costs. Similarly, the decisions that are optimal are unchanged B if a constant is added to each entry in the matrix. This shifting corresponds to changing the baseline away from which costs are measured. By scaling and shifting entries, any two-class cost matrix that satisfies the reasonableness conditions can be transformed into a simpler matrix that always leads to the same decisions:},
	journal = {International Joint Conference on Artificial Intelligence},
	author = {Elkan, Charles},
	year = {2001},
	pages = {973--978},
}

@article{shiryaev_elections_2013,
	title = {On {Elections} with {Robust} {Winners}},
	abstract = {We study the sensitivity of election outcomes to small changes in voters’ preferences. We assume that a voter may err by swapping two adjacent candidates in his vote; we would like to check whether the election outcome would remain the same given up to δ errors. We show that this problem can be viewed as the destructive version of the unit-cost swap bribery problem, and demonstrate that it is polynomial-time solvable for all scoring rules as well as for the Condorcet rule. We are also interested in identifying elections that are maximally robust with respect to a given voting rule. We deﬁne the robustness radius of an election with respect to a given voting rule as the maximum number of errors that can be made without changing the election outcome; the robustness of a voting rule is deﬁned as the robustness radius of the election that is maximally robust with respect to this rule. We derive bounds on the robustness of various voting rules, including Plurality, Borda, and Condorcet.},
	language = {en},
	journal = {AAMAS},
	author = {Shiryaev, Dmitry and Yu, Lan and Elkind, Edith},
	year = {2013},
}

@inproceedings{elkind_swap_2009,
	address = {Berlin, Heidelberg},
	title = {Swap {Bribery}},
	isbn = {978-3-642-04645-2},
	doi = {10.1007/978-3-642-04645-2_27},
	abstract = {In voting theory, bribery is a form of manipulative behavior in which an external actor (the briber) offers to pay the voters to change their votes in order to get her preferred candidate elected. We investigate a model of bribery where the price of each vote depends on the amount of change that the voter is asked to implement. Specifically, in our model the briber can change a voter’s preference list by paying for a sequence of swaps of consecutive candidates. Each swap may have a different price; the price of a bribery is the sum of the prices of all swaps that it involves. We prove complexity results for this model, which we call swap bribery, for a broad class of voting rules, including variants of approval and k-approval, Borda, Copeland, and maximin.},
	language = {en},
	booktitle = {Algorithmic {Game} {Theory}},
	publisher = {Springer},
	author = {Elkind, Edith and Faliszewski, Piotr and Slinko, Arkadii},
	editor = {Mavronicolas, Marios and Papadopoulou, Vicky G.},
	year = {2009},
	pages = {299--310},
}

@article{baumeister_complexity_2020,
	title = {Complexity of {Election} {Evaluation} and {Probabilistic} {Robustness}},
	abstract = {When dealing with election data it is reasonable to assume that the votes are incomplete or noisy. The reasons are manifold and range from cost-intensive elicitation to manipulation. We study the important questions of evaluating elections with incomplete data and the robustness of elections with noisy data from a computational point of view. To capture different motivations, we consider three models for the distribution of preferences: the uniform distribution over the completions of incomplete preferences inspired by the possible winner problem, the dispersion around complete preferences, also called Mallows noise model, and a model in which the distribution over the votes of each voter is explicitly given. We consider both approval vector preferences and linear order preferences and show that the complexity of the problem can vary greatly depending on the voting rule, the distribution model, and the parameterization.},
	language = {en},
	journal = {New Zealand},
	author = {Baumeister, Dorothea and Hogrebe, Tobias},
	year = {2020},
}

@article{bachrach_probabilistic_2010,
	title = {Probabilistic {Possible} {Winner} {Determination}},
	volume = {24},
	copyright = {Copyright (c) 2021 Proceedings of the AAAI Conference on Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/7609},
	doi = {10.1609/aaai.v24i1.7609},
	abstract = {We study the computational complexity of the counting version of the Possible-Winner problem for elections. In the Possible-Winner problem we are given a profile of voters, each with a partial preference order, and ask if there are linear extensions of the votes such that a designated candidate wins.  We also analyze a special case of Possible-Winner, the Manipulation problem.  We provide polynomial-time algorithms for counting manipulations in a class of scoring protocols and in several other voting rules.  We show \#P-hardness of the counting variant of Possible-Winner for plurality and veto and give a simple yet  general and practically useful randomized algorithm for a variant of Possible-Winner for all voting rules for which a winner can be computed in polynomial time.},
	language = {en},
	number = {1},
	urldate = {2025-01-15},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Bachrach, Yoram and Betzler, Nadja and Faliszewski, Piotr},
	month = jul,
	year = {2010},
	note = {Number: 1},
	keywords = {voting},
	pages = {697--702},
}

@article{hazon_evaluation_2012,
	title = {On the evaluation of election outcomes under uncertainty},
	volume = {189},
	issn = {0004-3702},
	url = {https://www.sciencedirect.com/science/article/pii/S0004370212000574},
	doi = {10.1016/j.artint.2012.04.009},
	abstract = {We investigate the extent to which it is possible to compute the probability of a particular candidate winning an election, given imperfect information about the preferences of the electorate. We assume that for each voter, we have a probability distribution over a set of preference orderings. Thus, for each voter, we have a number of possible preference orderings – we do not know which of these orderings actually represents the preferences of the voter, but for each ordering, we know the probability that it does. For the case where the number of candidates is a constant, we are able to give a polynomial time algorithm to compute the probability that a given candidate will win. We present experimental results obtained with an implementation of the algorithm, illustrating how the algorithmʼs performance in practice is better than its predicted theoretical bound. However, when the number of candidates is not bounded, we prove that the problem becomes \#P-hard for the Plurality, k-approval, Borda, Copeland, and Bucklin voting rules. We further show that even evaluating if a candidate has any chance of winning is NP-complete for the Plurality voting rule in the case where voters may have different weights. With unweighted voters, we give a polynomial algorithm for Plurality, and show that the problem is hard for many other voting rules. Finally, we give a Monte Carlo approximation algorithm for computing the probability of a candidate winning in any settings, with an error that is as small as desired.},
	urldate = {2025-01-15},
	journal = {Artificial Intelligence},
	author = {Hazon, Noam and Aumann, Yonatan and Kraus, Sarit and Wooldridge, Michael},
	month = sep,
	year = {2012},
	keywords = {Computational social choice, Voting rules},
	pages = {1--18},
}

@article{rosenberg_image_1986,
	title = {The {Image} and the {Vote}: {The} {Effect} of {Candidate} {Presentation} on {Voter} {Preference}},
	volume = {30},
	issn = {0092-5853},
	shorttitle = {The {Image} and the {Vote}},
	url = {https://www.jstor.org/stable/2111296},
	doi = {10.2307/2111296},
	abstract = {It is generally assumed that a political candidate's appearance and style have an impact on voters and the choices they make on election day. Little research, however, has been done to investigate this claim. Here, the authors examine the role that these nonverbal aspects of candidate presentation play in the process of political communication. In the course of two related studies, the impact of candidate photographs appearing on campaign flyers is assessed. The results suggest that these photographs influence voters' perceptions of a candidate and this significantly affects their vote.},
	number = {1},
	urldate = {2025-01-15},
	journal = {American Journal of Political Science},
	author = {Rosenberg, Shawn W. and Bohan, Lisa and McCafferty, Patrick and Harris, Kevin},
	year = {1986},
	note = {Publisher: [Midwest Political Science Association, Wiley]},
	pages = {108--127},
}

@article{jenke_voter_2020,
	title = {Voter {Preferences} {Reflect} a {Competition} {Between} {Policy} and {Identity}},
	volume = {11},
	issn = {1664-1078},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7593652/},
	doi = {10.3389/fpsyg.2020.566020},
	abstract = {Canonical rational choice models of voter preferences assume that voters select candidates whose policy positions most closely match their own. Yet, much of the electorate often appears to prioritize identity variables (e.g., social categories, group membership) over policy considerations. Here, we report an empirical test of policy-identity interactions using surveys of likely voters conducted in the 24 hours before the 2016 United States presidential election and the 2018 United States senatorial elections. Each respondent indicated not only their policy preferences but also key social group identities and how those identities would be reinforced by voting. We observed striking evidence for a competition between policy and social group identification: For voters who exhibited the maximal effects of identity, policy positions were essentially irrelevant to their candidate preferences. These results account for dissociations between voters’ stated policy preferences and their voting behavior, while linking empirical observations of political behavior to new models derived from psychology and neuroscience.},
	urldate = {2025-01-15},
	journal = {Frontiers in Psychology},
	author = {Jenke, Libby and Huettel, Scott A.},
	month = oct,
	year = {2020},
	pmid = {33178071},
	pmcid = {PMC7593652},
	pages = {566020},
}

@inproceedings{boehmer_quantitative_2022,
	address = {New York, NY, USA},
	series = {{EAAMO} '22},
	title = {A {Quantitative} and {Qualitative} {Analysis} of the {Robustness} of ({Real}-{World}) {Election} {Winners}},
	isbn = {978-1-4503-9477-2},
	url = {https://doi.org/10.1145/3551624.3555292},
	doi = {10.1145/3551624.3555292},
	abstract = {Contributing to the toolbox for interpreting election results, we evaluate the robustness of election winners to random noise. We compare the robustness of different voting rules and evaluate the robustness of real-world election winners from the Formula 1 World Championship and some variant of political elections. We find many instances of elections that have very non-robust winners and numerous delicate robustness patterns that cannot be identified using classical and simpler approaches.},
	urldate = {2025-01-15},
	booktitle = {Proceedings of the 2nd {ACM} {Conference} on {Equity} and {Access} in {Algorithms}, {Mechanisms}, and {Optimization}},
	publisher = {Association for Computing Machinery},
	author = {Boehmer, Niclas and Bredereck, Robert and Faliszewski, Piotr and Niedermeier, Rolf},
	month = oct,
	year = {2022},
	pages = {1--10},
}

@article{bagheridelouee_metric_2024,
	title = {Metric {Distortion} {Under} {Public}-{Spirited} {Voting}},
	abstract = {We investigate the impact of public-spirited voting on the distortion in the metric framework. We employ the public-spirited model proposed by Flanigan et al. [3] (EC’23) to model the public-spirited behavior of the agents and evaluate the distortion of different voting rules, including Plurality, Borda, Copeland, Veto, 𝑘-approval, and PluralityVeto. We establish a lower bound for any voting rule operating within the metric framework with public-spirited voters. Additionally, we present lower and upper bounds on the distortion associated with these voting rules within the public-spirited model. Among these voting rules, we show that, in the case of public-spirited voting where all voters exhibit identical behavior, the distortion of PluralityVeto matches the general lower bound.},
	language = {en},
	journal = {New Zealand},
	author = {Bagheridelouee, Amirreza},
	year = {2024},
}

@article{givi_robustness_2024,
	title = {On the robustness of democratic electoral processes to computational propaganda},
	volume = {14},
	copyright = {2024 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-50648-6},
	doi = {10.1038/s41598-023-50648-6},
	abstract = {There is growing evidence of systematic attempts to influence democratic elections by controlled and digitally organized dissemination of fake news. This raises the question of the intrinsic robustness of democratic electoral processes against external influences. Particularly interesting is to identify the social characteristics of a voter population that renders it more resilient against opinion manipulation. Equally important is to determine which of the existing democratic electoral systems is more robust to external influences. Here we construct a mathematical electoral model to address these two questions. We find that, not unexpectedly, biased electorates with clear-cut elections are overall quite resilient against opinion manipulations, because inverting the election outcome requires to change the opinion of many voters. More interesting are unbiased or weakly biased electorates with close elections. We find that such populations are more resilient against opinion manipulations (i) if they are less polarized and (ii) when voters interact more with each other, regardless of their opinion differences, and that (iii) electoral systems based on proportional representation are generally the most robust. Our model qualitatively captures the volatility of the US House of Representatives elections. We take this as a solid validation of our approach.},
	language = {en},
	number = {1},
	urldate = {2025-01-14},
	journal = {Scientific Reports},
	author = {Givi, Glory M. and Delabays, Robin and Jacquemet, Matthieu and Jacquod, Philippe},
	month = jan,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Applied mathematics, Human behaviour},
	pages = {193},
}

@article{weyl_robustness_2017,
	title = {The robustness of quadratic voting},
	volume = {172},
	issn = {1573-7101},
	url = {https://doi.org/10.1007/s11127-017-0405-4},
	doi = {10.1007/s11127-017-0405-4},
	abstract = {Lalley and Weyl (Quadratic voting, 2016) propose a mechanism for binary collective decisions, Quadratic Voting (QV), and prove its approximate efficiency in large populations in a stylized environment. They motivate their proposal substantially based on its greater robustness when compared with pre-existing efficient collective decision mechanisms. However, these suggestions are based purely on discussion of structural properties of the mechanism. In this paper, I study these robustness properties quantitatively in an equilibrium model. Given the mathematical challenges with establishing results on QV fully formally, my analysis relies on a number of structural conjectures that have been proven in analogous settings in the literature, but in the models I consider here. While most of the factors I study reduce the efficiency of QV to some extent, it is reasonably robust to all of them and quite robustly outperforms one-person-one-vote. Collusion and fraud, except on a very large scale, are deterred either by unilateral deviation incentives or by the reactions of non-participants to the possibility of their occurring. I am able to study aggregate uncertainty only for particular parametric distributions, but using the most canonical structures in the literature I find that such uncertainty reduces limiting efficiency, but never by a large magnitude. Voter mistakes or non-instrumental motivations for voting, so long as they are uncorrelated with values, may either enhance or harm efficiency depending on the setting. These findings contrast with existing (approximately) efficient mechanisms, all of which are highly sensitive to at least one of these factors.},
	language = {en},
	number = {1},
	urldate = {2025-01-14},
	journal = {Public Choice},
	author = {Weyl, E. Glen},
	month = jul,
	year = {2017},
	keywords = {C72, Collusion, D47, D61, D71, D82, H41, P16, Paradox of voting, Quadratic voting, Robust mechanism design},
	pages = {75--107},
}

@misc{boehmer_robustness_2023,
	title = {Robustness of {Participatory} {Budgeting} {Outcomes}: {Complexity} and {Experiments}},
	shorttitle = {Robustness of {Participatory} {Budgeting} {Outcomes}},
	url = {http://arxiv.org/abs/2305.08125},
	doi = {10.48550/arXiv.2305.08125},
	abstract = {We study the robustness of approval-based participatory budgeting (PB) rules to random noise in the votes. Our contributions are twofold. First, we study the computational complexity of the \#Flip-Bribery problem, where given a PB instance we ask for the number of ways in which we can flip a given number of approvals in the votes, so that a specific project is selected. The idea is that \#Flip-Bribery captures the problem of computing the funding probabilities of projects in case random noise is added. Unfortunately, the problem is intractable even for the simplest PB rules. Second, we analyze the robustness of several prominent PB rules (including the basic greedy rule and the Method of Equal Shares) on real-life instances from Pabulib. Since \#Flip-Bribery is intractable, we resort to sampling to obtain our results. We quantify the extent to which simple, greedy PB rules are more robust than proportional ones, and we identify three types of (very) non-robust projects in real-life PB instances.},
	urldate = {2025-01-14},
	publisher = {arXiv},
	author = {Boehmer, Niclas and Faliszewski, Piotr and Janeczko, Łukasz and Kaczmarczyk, Andrzej},
	month = may,
	year = {2023},
	note = {arXiv:2305.08125 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, Economics - Theoretical Economics},
}

@misc{boehmer_robustness_2020,
	title = {On the {Robustness} of {Winners}: {Counting} {Briberies} in {Elections}},
	shorttitle = {On the {Robustness} of {Winners}},
	url = {http://arxiv.org/abs/2010.09678},
	doi = {10.48550/arXiv.2010.09678},
	abstract = {We study the parameterized complexity of counting variants of Swap- and Shift-Bribery problems, focusing on the parameterizations by the number of swaps and the number of voters. We show experimentally that Swap-Bribery offers a new approach to the robustness analysis of elections.},
	urldate = {2025-01-14},
	publisher = {arXiv},
	author = {Boehmer, Niclas and Bredereck, Robert and Faliszewski, Piotr and Niedermeier, Rolf},
	month = oct,
	year = {2020},
	note = {arXiv:2010.09678 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory},
}

@article{bierbrauer_robust_2017,
	title = {Robust mechanism design and social preferences},
	volume = {149},
	issn = {0047-2727},
	url = {https://www.sciencedirect.com/science/article/pii/S0047272717300373},
	doi = {10.1016/j.jpubeco.2017.03.003},
	abstract = {We study two classic challenges in mechanism design – bilateral trade à la Myerson and Satterthwaite (1983) and redistributive income taxation à la Mirrlees (1971) and Piketty (1993) – to show that some standard mechanism design solutions systematically fail with social preferences. We therefore introduce the notion of a social-preference-robust mechanism which works not only for selfish but also for social preferences of different nature and intensity, and characterize the optimal mechanism for this class. With the help of a series of laboratory experiments we find that behavior can indeed be better controlled with social-preference-robust mechanisms.},
	urldate = {2025-01-14},
	journal = {Journal of Public Economics},
	author = {Bierbrauer, Felix and Ockenfels, Axel and Pollak, Andreas and Rückert, Désirée},
	month = may,
	year = {2017},
	keywords = {Bilateral trade, Income taxation, Robust mechanism design, Social preferences},
	pages = {59--80},
}

@article{bergemann_robust_2005,
	title = {Robust {Mechanism} {Design}},
	volume = {73},
	issn = {0012-9682},
	url = {https://www.jstor.org/stable/3598751},
	abstract = {The mechanism design literature assumes too much common knowledge of the environment among the players and planner. We relax this assumption by studying mechanism design on richer type spaces. We ask when ex post implementation is equivalent to interim (or Bayesian) implementation for all possible type spaces. The equivalence holds in the case of separable environments; examples of separable environments arise (1) when the planner is implementing a social choice function (not correspondence) and (2) in a quasilinear environment with no restrictions on transfers. The equivalence fails in general, including in some quasilinear environments with budget balance. In private value environments, ex post implementation is equivalent to dominant strategies implementation. The private value versions of our results offer new insights into the relationship between dominant strategy implementation and Bayesian implementation.},
	number = {6},
	urldate = {2025-01-14},
	journal = {Econometrica},
	author = {Bergemann, Dirk and Morris, Stephen},
	year = {2005},
	note = {Publisher: [Wiley, Econometric Society]},
	pages = {1771--1813},
}

@article{bartling_externality-robust_2016,
	title = {An externality-robust auction: {Theory} and experimental evidence},
	volume = {97},
	issn = {0899-8256},
	shorttitle = {An externality-robust auction},
	url = {https://www.sciencedirect.com/science/article/pii/S0899825616300197},
	doi = {10.1016/j.geb.2016.04.004},
	abstract = {Behavioral robustness is essential in mechanism design. Existing papers focus on robustness as captured by dominant strategies. This paper studies the novel concept of externality-robustness, which addresses players' motives to affect other players' monetary payoffs. One example is externalities due to spite, which has been used to explain overbidding in second-price auctions. We show theoretically and experimentally that a trade-off exists between dominant-strategy implementation and externality-robust implementation. In particular, we derive the externality-robust counterpart of the second-price auction. Our experiments replicate the earlier finding of overbidding in the second-price auction, but we find that average bids equal value in the externality-robust auction. Our data also reveal that both auctions produce the same level of efficiency, suggesting that both dimensions of robustness are equally important. Our results are relevant for mechanism design in general, because the concept of externality-robustness is applicable to arbitrary mechanism design problems.},
	urldate = {2025-01-14},
	journal = {Games and Economic Behavior},
	author = {Bartling, Björn and Netzer, Nick},
	month = may,
	year = {2016},
	keywords = {Experimental auctions, Robust mechanism design, Spiteful preferences},
	pages = {186--204},
}

@article{bierbrauer_robust_nodate,
	title = {Robust {Mechanism} {Design} and {Social} {Preferences}},
	abstract = {One key  nding of behavioral economics is that many people are motivated by social concerns. However, most of the robust mechanism design literature focuses on beliefs, and takes sel sh preferences for granted. We study two classic challenges in mechanism design   bilateral trade à la Myerson and Satterthwaite (1983) and redistributive income taxation à la Mirrlees (1971) and Piketty (1993)   to show that some standard mechanism design solutions systematically fail with social preferences, while others are robust. We thus introduce the notion of a social-preference-robust mechanism which works not only for sel sh but also for social preferences of di erent nature and intensity, and characterize the optimal mechanism in this class. We compare the performance of the optimal mechanisms for sel sh agents and the optimal social-preference-robust mechanisms with the help of a series of laboratory experiments and  nd that behavior can indeed be better controlled with social-preferencerobust mechanisms.},
	language = {en},
	author = {Bierbrauer, Felix and Ockenfels, Axel and Pollak, Andreas and Rückert, Désirée},
}

@misc{noauthor_citizens_nodate,
	title = {Citizens' {Assemblies} – {Democracy} that works},
	url = {https://citizensassemblies.org/},
	language = {pl-PL},
	urldate = {2025-01-10},
}

@article{frongillo_elicitation_2021,
	title = {Elicitation complexity of statistical properties},
	volume = {108},
	url = {https://academic.oup.com/biomet/article-abstract/108/4/857/5955754?redirectedFrom=fulltext},
	number = {4},
	urldate = {2025-01-09},
	journal = {Biometrika},
	author = {Frongillo, Rafael and Kash, Ian A},
	month = dec,
	year = {2021},
	pages = {857--879},
}

@misc{noauthor_gender_nodate,
	title = {Gender {Shades}},
	url = {http://gendershades.org/},
	urldate = {2024-09-04},
	note = {Homepage for the Gender Shades project, which outlines results of the research paper.},
}

@article{wakker_eliciting_1996,
	title = {Eliciting von {Neumann}-{Morgenstern} {Utilities} {When} {Probabilities} {Are} {Distorted} or {Unknown}},
	volume = {42},
	issn = {0025-1909},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.42.8.1131},
	doi = {10.1287/mnsc.42.8.1131},
	abstract = {This paper proposes a new method, the (gamble-)tradeoff method, for eliciting utilities in decision under risk or uncertainty. The elicitation of utilities, to be used in the expected utility criterion, turns out to be possible even if probabilities are ambiguous or unknown. A disadvantage of the tradeoff method is that a few more questions usually must be asked to clients. Also, the lotteries that are needed are somewhat more complex than in the certainty-equivalent method or in the probability-equivalent method. The major advantage of the tradeoff method is its robustness against probability distortions and misconceptions, which constitute a major cause of violations of expected utility and generate inconsistencies in utility elicitation. Thus the tradeoff method retains full validity under prospect theory, rank-dependent utility, and the combination of the two, i.e., cumulative prospect theory.

The tradeoff method is tested for monetary outcomes and for outcomes describing life-duration. We find higher risk aversion for life duration, but the tradeoff method elicits similar curvature of utility. Apparently the higher risk aversion for life duration is due to more pronounced deviations from expected utility.},
	number = {8},
	urldate = {2024-05-06},
	journal = {Management Science},
	author = {Wakker, Peter and Deneffe, Daniel},
	month = aug,
	year = {1996},
	note = {Publisher: INFORMS},
	keywords = {decision analysis, probability distortion, prospect theory, risk aversion, standard gamble, threshold elicitation, utility measurement},
	pages = {1131--1150},
}

@article{steinwart_how_2007,
	title = {How to {Compare} {Different} {Loss} {Functions} and {Their} {Risks}},
	doi = {10.1007/s00365-006-0662-3},
	abstract = {Many learning problems are described by a risk functional which in turn is defined by a loss function, and a straightforward and widely known approach to learn such problems is to minimize a (modified) empirical version of this risk functional. However, in many cases this approach suffers from substantial problems such as computational requirements in classification or robustness concerns in regression. In order to resolve these issues many successful learning algorithms try to minimize a (modified) empirical risk of a surrogate loss function, instead. Of course, such a surrogate loss must be "reasonably related" to the original loss function since otherwise this approach cannot work well. For classification good surrogate loss functions have been recently identified, and the relationship between the excess classification risk and the excess risk of these surrogate loss functions has been exactly described. However, beyond the classification problem little is known on good surrogate loss functions up to now. In this work we establish a general theory that provides powerful tools for comparing excess risks of different loss functions. We then apply this theory to several learning problems including (cost-sensitive) classification, regression, density estimation, and density level detection.},
	journal = {Constructive Approximation},
	author = {Steinwart, Ingo},
	year = {2007},
	pmid = {null},
	pmcid = {null},
	keywords = {Cost Function, Excess Risk, Learning Problem, Loss Function, Support Vector Machine},
}

@inproceedings{raji_actionable_2019,
	address = {Honolulu HI USA},
	title = {Actionable {Auditing}: {Investigating} the {Impact} of {Publicly} {Naming} {Biased} {Performance} {Results} of {Commercial} {AI} {Products}},
	isbn = {978-1-4503-6324-2},
	shorttitle = {Actionable {Auditing}},
	url = {https://dl.acm.org/doi/10.1145/3306618.3314244},
	doi = {10.1145/3306618.3314244},
	abstract = {Although algorithmic auditing has emerged as a key strategy to expose systematic biases embedded in software platforms, we struggle to understand the realworld impact of these audits, as scholarship on the impact of algorithmic audits on increasing algorithmic fairness and transparency in commercial systems is nascent. To analyze the impact of publicly naming and disclosing performance results of biased AI systems, we investigate the commercial impact of Gender Shades, the ﬁrst algorithmic audit of gender and skin type performance disparities in commercial facial analysis models. This paper 1) outlines the audit design and structured disclosure procedure used in the Gender Shades study, 2) presents new performance metrics from targeted companies IBM, Microsoft and Megvii (Face++) on the Pilot Parliaments Benchmark (PPB) as of August 2018, 3) provides performance results on PPB by non-target companies Amazon and Kairos and, 4) explores differences in company responses as shared through corporate communications that contextualize differences in performance on PPB. Within 7 months of the original audit, we ﬁnd that all three targets released new API versions. All targets reduced accuracy disparities between males and females and darker and lighter-skinned subgroups, with the most signiﬁcant update occurring for the darker-skinned female subgroup, that underwent a 17.7\% - 30.4\% reduction in error between audit periods. Minimizing these disparities led to a 5.72\% to 8.3\% reduction in overall error on the Pilot Parliaments Benchmark (PPB) for target corporation APIs. The overall performance of non-targets Amazon and Kairos lags signiﬁcantly behind that of the targets, with error rates of 8.66\% and 6.60\% overall, and error rates of 31.37\% and 22.50\% for the darker female subgroup, respectively.},
	language = {en},
	urldate = {2024-09-02},
	booktitle = {Proceedings of the 2019 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Raji, Inioluwa Deborah and Buolamwini, Joy},
	month = jan,
	year = {2019},
	pages = {429--435},
}

@article{mao_h-consistency_2023,
	title = {H-{Consistency} {Bounds}: {Characterization} and {Extensions}},
	doi = {null},
	abstract = {A series of recent publications by Awasthi, Mao, Mohri, and Zhong [2022b] have introduced the key notion of H -consistency bounds for surrogate loss functions. These are upper bounds on the zero-one estimation error of any predictor in a hypothesis set, expressed in terms of its surrogate loss estimation error. They are both non-asymptotic and hypothesis set-speciﬁc and thus stronger and more informative than Bayes-consistency. However, determining if they hold and deriving these bounds have required a speciﬁc proof and analysis for each surrogate loss. Can we derive more general tools and characterizations? This paper provides both a general characterization and an extension of H -consistency bounds for multi-class classiﬁcation. We present new and tight H -consistency bounds for both the family of constrained losses and that of comp-sum losses, which covers the familiar cross-entropy, or logistic loss applied to the outputs of a neural network. We further extend our analysis beyond the completeness assumptions adopted in previous studies and cover more realistic bounded hypothesis sets. Our characterizations are based on error transformations, which are explicitly deﬁned for each formulation. We illustrate the application of our general results through several special examples. A by-product of our analysis is the observation that a recently derived multi-class H -consistency bound for cross-entropy reduces to an excess bound and is not signiﬁcant. Instead, we prove a much stronger and more signiﬁcant guarantee.},
	journal = {Neural Information Processing Systems},
	author = {Mao, Anqi and Mohri, M. and Zhong, Yutao},
	year = {2023},
	pmid = {null},
	pmcid = {null},
}

@misc{chen_robustness_2024,
	title = {Robustness of voting mechanisms to external information in expectation},
	url = {http://arxiv.org/abs/2404.07818},
	abstract = {Analyses of voting algorithms often overlook informational externalities shaping individual votes. For example, pre-polling information often skews voters towards candidates who may not be their top choice, but who they believe would be a worthwhile recipient of their vote. In this work, we aim to understand the role of external information in voting outcomes. We study this by analyzing (1) the probability that voting outcomes align with external information, and (2) the effect of external information on the total utility across voters, or social welfare. In practice, voting mechanisms elicit coarse information about voter utilities, such as ordinal preferences, which initially prevents us from directly analyzing the effect of informational externalities with standard voting mechanisms. To overcome this, we present an intermediary mechanism for learning how preferences change with external information which does not require eliciting full cardinal preferences. With this tool in hand, we find that voting mechanisms are generally more likely to select the alternative most favored by the external information, and when external information reflects the population’s true preferences, social welfare increases in expectation.},
	language = {en},
	urldate = {2024-09-30},
	publisher = {arXiv},
	author = {Chen, Yiling and Finocchiaro, Jessie},
	month = apr,
	year = {2024},
	note = {arXiv:2404.07818 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory},
}

@inproceedings{finocchiaro_structured_2022,
	title = {The {Structured} {Abstain} {Problem} and the {Lovász} {Hinge}},
	url = {https://proceedings.mlr.press/v178/nueve22a.html},
	abstract = {The Lovász hinge is a convex surrogate recently proposed for structured binary classification, in which k binary predictions are made simultaneously and the error is judged by a submodular set function. Despite its wide usage in image segmentation and related problems, its consistency has remained open. We resolve this open question, showing that the Lovász hinge is inconsistent for its desired target unless the set function is modular. Leveraging a recent embedding framework, we instead derive the target loss for which the Lovász hinge is consistent. This target, which we call the structured abstain problem, allows one to abstain on any subset of the k predictions. We derive two link functions, each of which are consistent for all submodular set functions simultaneously.},
	language = {en},
	urldate = {2024-08-19},
	booktitle = {Proceedings of {Thirty} {Fifth} {Conference} on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Finocchiaro, Jessica J. and Frongillo, Rafael and Nueve, Enrique B.},
	month = jun,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {3718--3740},
}

@article{fehr_social_2004,
	title = {Social norms and human cooperation},
	volume = {8},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661304000506},
	doi = {10.1016/j.tics.2004.02.007},
	language = {en},
	number = {4},
	urldate = {2024-07-30},
	journal = {Trends in Cognitive Sciences},
	author = {Fehr, Ernst and Fischbacher, Urs},
	month = apr,
	year = {2004},
	pages = {185--190},
}

@article{degroot_comparison_1983,
	title = {The {Comparison} and {Evaluation} of {Forecasters}},
	volume = {32},
	issn = {0039-0526},
	url = {https://www.jstor.org/stable/2987588},
	doi = {10.2307/2987588},
	abstract = {In this paper we present methods for comparing and evaluating forecasters whose predictions are presented as their subjective probability distributions of various random variables that will be observed in the future, e.g. weather forecasters who each day must specify their own probabilities that it will rain in a particular location. We begin by reviewing the concepts of calibration and refinement, and describing the relationship between this notion of refinement and the notion of sufficiency in the comparison of statistical experiments. We also consider the question of interrelationships among forecasters and discuss methods by which an observer should combine the predictions from two or more different forecasters. Then we turn our attention to the concept of a proper scoring rule for evaluating forecasters, relating it to the concepts of calibration and refinement. Finally, we discuss conditions under which one forecaster can exploit the predictions of another forecaster to obtain a better score.},
	number = {1/2},
	urldate = {2024-04-23},
	journal = {Journal of the Royal Statistical Society. Series D (The Statistician)},
	author = {DeGroot, Morris H. and Fienberg, Stephen E.},
	year = {1983},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {12--22},
}

@misc{bao_calibrated_2021,
	title = {Calibrated {Surrogate} {Losses} for {Adversarially} {Robust} {Classification}},
	url = {http://arxiv.org/abs/2005.13748},
	doi = {10.48550/arXiv.2005.13748},
	abstract = {Adversarially robust classification seeks a classifier that is insensitive to adversarial perturbations of test patterns. This problem is often formulated via a minimax objective, where the target loss is the worst-case value of the 0-1 loss subject to a bound on the size of perturbation. Recent work has proposed convex surrogates for the adversarial 0-1 loss, in an effort to make optimization more tractable. A primary question is that of consistency, that is, whether minimization of the surrogate risk implies minimization of the adversarial 0-1 risk. In this work, we analyze this question through the lens of calibration, which is a pointwise notion of consistency. We show that no convex surrogate loss is calibrated with respect to the adversarial 0-1 loss when restricted to the class of linear models. We further introduce a class of nonconvex losses and offer necessary and sufficient conditions for losses in this class to be calibrated. We also show that if the underlying distribution satisfies Massart's noise condition, convex losses can also be calibrated in the adversarial setting.},
	urldate = {2024-12-05},
	publisher = {arXiv},
	author = {Bao, Han and Scott, Clayton and Sugiyama, Masashi},
	month = may,
	year = {2021},
	note = {arXiv:2005.13748 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{awasthi_multi-class_nodate,
	title = {Multi-{Class} {H}-{Consistency} {Bounds}},
	abstract = {We present an extensive study of H-consistency bounds for multi-class classiﬁcation. These are upper bounds on the target loss estimation error of a predictor in a hypothesis set H, expressed in terms of the surrogate loss estimation error of that predictor. They are stronger and more signiﬁcant guarantees than Bayesconsistency, H-calibration or H-consistency, and more informative than excess error bounds derived for H being the family of all measurable functions. We give a series of new H-consistency bounds for surrogate multi-class losses, including max losses, sum losses, and constrained losses, both in the non-adversarial and adversarial cases, and for different differentiable or convex auxiliary functions used. We also prove that no non-trivial H-consistency bound can be given in some cases. To our knowledge, these are the ﬁrst H-consistency bounds proven for the multi-class setting. Our proof techniques are also novel and likely to be useful in the analysis of other such guarantees.},
	language = {en},
	author = {Awasthi, Pranjal and Mohri, Mehryar and Mao, Anqi and Zhong, Yutao},
	keywords = {mohri},
}

@inproceedings{agarwal_consistent_2015,
	title = {On {Consistent} {Surrogate} {Risk} {Minimization} and {Property} {Elicitation}},
	url = {https://proceedings.mlr.press/v40/Agarwal15.html},
	abstract = {Surrogate risk minimization is a popular framework for supervised learning; property elicitation is a widely studied area in probability forecasting, machine learning, statistics and economics. In this paper, we connect these two themes by showing that calibrated surrogate losses in supervised learning can essentially be viewed as eliciting or estimating certain properties of the underlying conditional label distribution that are sufficient to construct an optimal classifier under the target loss of interest. Our study helps to shed light on the design of convex calibrated surrogates. We also give a new framework for designing convex calibrated surrogates under low-noise conditions by eliciting properties that allow one to construct ‘coarse’ estimates of the underlying distribution.},
	language = {en},
	urldate = {2024-09-03},
	booktitle = {Proceedings of {The} 28th {Conference} on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Agarwal, Arpit and Agarwal, Shivani},
	month = jun,
	year = {2015},
	note = {ISSN: 1938-7228},
	pages = {4--22},
}

@article{awasthi_h-consistency_2022,
	title = {H-{Consistency} {Bounds} for {Surrogate} {Loss} {Minimizers}},
	doi = {null},
	abstract = {null},
	journal = {International Conference on Machine Learning},
	author = {Awasthi, Pranjal and Mao, Anqi and Mohri, M. and Zhong, Yutao},
	year = {2022},
	pmid = {null},
	pmcid = {null},
}

@misc{bansal_smaller_2024,
	title = {Smaller, {Weaker}, {Yet} {Better}: {Training} {LLM} {Reasoners} via {Compute}-{Optimal} {Sampling}},
	shorttitle = {Smaller, {Weaker}, {Yet} {Better}},
	url = {http://arxiv.org/abs/2408.16737},
	abstract = {Training on high-quality synthetic data from strong language models (LMs) is a common strategy to improve the reasoning performance of LMs. In this work, we revisit whether this strategy is compute-optimal under a fixed inference budget (e.g., FLOPs). To do so, we investigate the trade-offs between generating synthetic data using a stronger but more expensive (SE) model versus a weaker but cheaper (WC) model. We evaluate the generated data across three key metrics: coverage, diversity, and false positive rate, and show that the data from WC models may have higher coverage and diversity, but also exhibit higher false positive rates. We then finetune LMs on data from SE and WC models in different settings: knowledge distillation, self-improvement, and a novel weak-to-strong improvement setup where a weaker LM teaches reasoning to a stronger LM. Our findings reveal that models finetuned on WC-generated data consistently outperform those trained on SE-generated data across multiple benchmarks and multiple choices of WC and SE models. These results challenge the prevailing practice of relying on SE models for synthetic data generation, suggesting that WC may be the compute-optimal approach for training advanced LM reasoners.},
	language = {en},
	urldate = {2024-09-30},
	publisher = {arXiv},
	author = {Bansal, Hritik and Hosseini, Arian and Agarwal, Rishabh and Tran, Vinh Q. and Kazemi, Mehran},
	month = aug,
	year = {2024},
	note = {arXiv:2408.16737 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{dawid_well-calibrated_1982,
	title = {The {Well}-{Calibrated} {Bayesian}: {Journal} of the {American} {Statistical} {Association}: {Vol} 77, {No} 379},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1982.10477856},
	urldate = {2025-01-07},
	author = {Dawid, A Philip},
	year = {1982},
}

@article{seidenfeld_calibration_1985,
	title = {Calibration, {Coherence}, and {Scoring} {Rules}},
	volume = {52},
	url = {http://www.jstor.org/stable/187511},
	language = {en},
	number = {2},
	journal = {Philosophy of Science},
	author = {Seidenfeld, Teddy},
	year = {1985},
	pages = {274--294},
}

@inproceedings{mozannar_who_2023,
	title = {Who {Should} {Predict}? {Exact} {Algorithms} {For} {Learning} to {Defer} to {Humans}},
	shorttitle = {Who {Should} {Predict}?},
	url = {https://proceedings.mlr.press/v206/mozannar23a.html},
	abstract = {Automated AI classifiers should be able to defer the prediction to a human decision maker to ensure more accurate predictions. In this work, we jointly train a classifier with a rejector, which decides on each data point whether the classifier or the human should predict. We show that prior approaches can fail to find a human-AI system with low mis-classification error even when there exists a linear classifier and rejector that have zero error (the realizable setting). We prove that obtaining a linear pair with low error is NP-hard even when the problem is realizable. To complement this negative result, we give a mixed-integer-linear-programming (MILP) formulation that can optimally solve the problem in the linear setting. However, the MILP only scales to moderately-sized problems. Therefore, we provide a novel surrogate loss function that is realizable-consistent and performs well empirically. We test our approaches on a comprehensive set of datasets and compare to a wide range of baselines.},
	language = {en},
	urldate = {2025-01-06},
	booktitle = {Proceedings of {The} 26th {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Mozannar, Hussein and Lang, Hunter and Wei, Dennis and Sattigeri, Prasanna and Das, Subhro and Sontag, David},
	month = apr,
	year = {2023},
	note = {ISSN: 2640-3498},
	pages = {10520--10545},
}

@article{oesterheld_robust_2019,
	title = {Robust program equilibrium},
	volume = {86},
	issn = {1573-7187},
	url = {https://doi.org/10.1007/s11238-018-9679-3},
	doi = {10.1007/s11238-018-9679-3},
	abstract = {One approach to achieving cooperation in the one-shot prisoner’s dilemma is Tennenholtz’s (Games Econ Behav 49(2):363–373, 2004) program equilibrium, in which the players of a game submit programs instead of strategies. These programs are then allowed to read each other’s source code to decide which action to take. As shown by Tennenholtz, cooperation is played in an equilibrium of this alternative game. In particular, he proposes that the two players submit the same version of the following program: cooperate if the opponent is an exact copy of this program and defect otherwise. Neither of the two players can benefit from submitting a different program. Unfortunately, this equilibrium is fragile and unlikely to be realized in practice. We thus propose a new, simple program to achieve more robust cooperative program equilibria: cooperate with some small probability \$\${\textbackslash}epsilon \$\$and otherwise act as the opponent acts against this program. I argue that this program is similar to the tit for tat strategy for the iterated prisoner’s dilemma. Both “start” by cooperating and copy their opponent’s behavior from “the last round”. We then generalize this approach of turning strategies for the repeated version of a game into programs for the one-shot version of a game to other two-player games. We prove that the resulting programs inherit properties of the underlying strategy. This enables them to robustly and effectively elicit the same responses as the underlying strategy for the repeated game.},
	language = {en},
	number = {1},
	urldate = {2024-12-17},
	journal = {Theory and Decision},
	author = {Oesterheld, Caspar},
	month = feb,
	year = {2019},
	keywords = {Algorithmic game theory, Nash equilibrium, Program equilibrium, Repeated games},
	pages = {143--159},
}

@misc{oesterheld_similarity-based_2023,
	title = {Similarity-based cooperative equilibrium},
	url = {http://arxiv.org/abs/2211.14468},
	doi = {10.48550/arXiv.2211.14468},
	abstract = {As machine learning agents act more autonomously in the world, they will increasingly interact with each other. Unfortunately, in many social dilemmas like the one-shot Prisoner's Dilemma, standard game theory predicts that ML agents will fail to cooperate with each other. Prior work has shown that one way to enable cooperative outcomes in the one-shot Prisoner's Dilemma is to make the agents mutually transparent to each other, i.e., to allow them to access one another's source code (Rubinstein 1998, Tennenholtz 2004) -- or weights in the case of ML agents. However, full transparency is often unrealistic, whereas partial transparency is commonplace. Moreover, it is challenging for agents to learn their way to cooperation in the full transparency setting. In this paper, we introduce a more realistic setting in which agents only observe a single number indicating how similar they are to each other. We prove that this allows for the same set of cooperative outcomes as the full transparency setting. We also demonstrate experimentally that cooperation can be learned using simple ML methods.},
	urldate = {2024-12-17},
	publisher = {arXiv},
	author = {Oesterheld, Caspar and Treutlein, Johannes and Grosse, Roger and Conitzer, Vincent and Foerster, Jakob},
	month = nov,
	year = {2023},
	note = {arXiv:2211.14468 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@misc{perdomo_difficult_2023,
	title = {Difficult {Lessons} on {Social} {Prediction} from {Wisconsin} {Public} {Schools}},
	url = {http://arxiv.org/abs/2304.06205},
	doi = {10.48550/arXiv.2304.06205},
	abstract = {Early warning systems (EWS) are predictive tools at the center of recent efforts to improve graduation rates in public schools across the United States. These systems assist in targeting interventions to individual students by predicting which students are at risk of dropping out. Despite significant investments in their widespread adoption, there remain large gaps in our understanding of the efficacy of EWS, and the role of statistical risk scores in education. In this work, we draw on nearly a decade's worth of data from a system used throughout Wisconsin to provide the first large-scale evaluation of the long-term impact of EWS on graduation outcomes. We present empirical evidence that the prediction system accurately sorts students by their dropout risk. We also find that it may have caused a single-digit percentage increase in graduation rates, though our empirical analyses cannot reliably rule out that there has been no positive treatment effect. Going beyond a retrospective evaluation of DEWS, we draw attention to a central question at the heart of the use of EWS: Are individual risk scores necessary for effectively targeting interventions? We propose a simple mechanism that only uses information about students' environments -- such as their schools, and districts -- and argue that this mechanism can target interventions just as efficiently as the individual risk score-based mechanism. Our argument holds even if individual predictions are highly accurate and effective interventions exist. In addition to motivating this simple targeting mechanism, our work provides a novel empirical backbone for the robust qualitative understanding among education researchers that dropout is structurally determined. Combined, our insights call into question the marginal value of individual predictions in settings where outcomes are driven by high levels of inequality.},
	urldate = {2024-12-17},
	publisher = {arXiv},
	author = {Perdomo, Juan C. and Britton, Tolani and Hardt, Moritz and Abebe, Rediet},
	month = sep,
	year = {2023},
	note = {arXiv:2304.06205 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, Economics - General Economics, Quantitative Finance - Economics, Statistics - Applications},
}

@inproceedings{flanigan_distortion_2023,
	title = {Distortion under {Public}-{Spirited} {Voting}},
	url = {https://drive.google.com/file/d/1cqVG62JRQjcqW3rA-TPqQtpWyF7lr_Jp/view?usp=share_link&usp=embed_facebook},
	urldate = {2024-12-17},
	booktitle = {Economics and {Computation}},
	author = {Flanigan, Bailey and Wang, Sven and Procaccia, Ariel D.},
	year = {2023},
}

@inproceedings{verma_restless_2023,
	title = {Restless {Multi}-{Armed} {Bandits} for {Maternal} and {Child} {Health}: {Results} from {Decision}-{Focused} {Learning}},
	abstract = {Mobile Health Awareness programs in underserved communities often suffer from diminishing engagement over time and health workers have to make live service calls to encourage beneficiaries’ participation. Owing to health workers’ limited availability, we consider the optimization problem of scheduling live service calls in a Maternal and Child Health Awareness Program and model it using Restless Multi-Armed Bandits (RMAB). Since the parameters of the RMAB formulation are unknown, a model is learnt to first predict the parameters of the RMAB problem, which is subsequently solved using the Whittle Index algorithm. However, this Predict-then-Optimize framework maximises for the predictive accuracy rather than the quality of the final solution. Decision Focused Learning (DFL) solves this mismatch by integrating the optimization problem in the learning pipeline. Previous works have only shown the applicability of DFL in simulation setting. In collaboration with an NGO, we conduct a large-scale field study consisting of 9000 beneficiaries for 6 weeks and track key engagement metrics in a mobile health awareness program. To the best of our knowledge this is the first real-world study involving Decision Focused Learning. We demonstrate that beneficiaries in the DFL group experience statistically significant reductions in cumulative engagement drop, while those in the Predict-then-Optimize group do not. This establishes the practicality of use of decision focused learning for real world problems. We also demonstrate that DFL learns a better decision boundary between the RMAB actions, and strategically predicts parameters for arms which contribute most to the final decision outcome.},
	language = {en},
	author = {Verma, Shresth and Mate, Aditya and Wang, Kai and Madhiwalla, Neha and Hegde, Aparna and Taneja, Aparna and Tambe, Milind},
	year = {2023},
}

@article{roth_kidney_2004,
	title = {Kidney {Exchange}},
	url = {https://academic.oup.com/qje/article-abstract/119/2/457/1894508},
	urldate = {2024-12-17},
	journal = {Quarterly Journal of Economics},
	author = {Roth, Alvin E. and Sönmez, Tayfun and Ünver, M. Utku},
	year = {2004},
}

@article{pathak_fair_2024,
	title = {Fair {Allocation} of {Vaccines}, {Ventilators} and {Antiviral} {Treatments}: {Leaving} {No} {Ethical} {Value} {Behind} in {Healthcare} {Rationing}},
	url = {https://pubsonline.informs.org/doi/full/10.1287/mnsc.2022.00930},
	urldate = {2024-12-17},
	author = {Pathak, Parag and Sönmez, Tayfun and Ünver, M. Utku and Yenmez, M. Bumin},
	year = {2024},
}

@inproceedings{lock_optimal_2021,
	title = {Optimal {Testing} and {Containment} {Strategies} for {Universities} in {Mexico} amid {COVID}-19},
	url = {https://dl.acm.org/doi/abs/10.1145/3465416.3483300},
	urldate = {2024-12-17},
	author = {Lock, Edwin and Marmolejo-Cossío, Francisco and Jonnerby, Jakob and Rajgopal, Ninad and Guzmán-Gutierrez, Héctor and Benavides-Vázquez, Luis Alejandro and Tello-Ayala, José Roberto and Lazos, Philip},
	year = {2021},
	pages = {1--9},
}

@misc{noauthor_optimal_nodate,
	title = {Optimal {Testing} and {Containment} {Strategies} for {Universities} in {Mexico} amid {COVID}-19✱ {\textbar} {Proceedings} of the 1st {ACM} {Conference} on {Equity} and {Access} in {Algorithms}, {Mechanisms}, and {Optimization}},
	url = {https://dl.acm.org/doi/abs/10.1145/3465416.3483300},
	urldate = {2024-12-17},
}

@misc{finster_welfare-maximizing_2023,
	title = {Welfare-{Maximizing} {Pooled} {Testing}},
	url = {http://arxiv.org/abs/2206.10660},
	doi = {10.48550/arXiv.2206.10660},
	abstract = {Large-scale testing is crucial in pandemic containment, but resources are often prohibitively constrained. We study the optimal application of pooled testing for populations that are heterogeneous with respect to an individual's infection probability and utility that materializes if included in a negative test. We show that the welfare gain from overlapping testing over non-overlapping testing is bounded. Moreover, non-overlapping allocations, which are both conceptually and logistically simpler to implement, are empirically near-optimal, and we design a heuristic mechanism for finding these near-optimal test allocations. In numerical experiments, we highlight the efficacy and viability of our heuristic in practice. We also implement and provide experimental evidence on the benefits of utility-weighted pooled testing in a real-world setting. Our pilot study at a higher education research institute in Mexico finds no evidence that performance and mental health outcomes of participants in our testing regime are worse than under the first-best counterfactual of full access for individuals without testing.},
	urldate = {2024-12-17},
	publisher = {arXiv},
	author = {Finster, Simon and Amador, Michelle González and Lock, Edwin and Marmolejo-Cossío, Francisco and Micha, Evi and Procaccia, Ariel D.},
	month = sep,
	year = {2023},
	note = {arXiv:2206.10660 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory},
}

@article{delacretaz_matching_2023,
	title = {Matching {Mechanisms} for {Refugee} {Resettlement}},
	volume = {113},
	issn = {0002-8282},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.20210096},
	doi = {10.1257/aer.20210096},
	abstract = {Tens of thousands of refugees are permanently resettled from refugee camps to hosting countries every year. In the past, placement of refugees was essentially ad hoc, but more recently resettlement agencies have been trying to place refugees systematically in order to improve their outcomes. Yet, even at present, refugee resettlement processes account for neither the priorities of hosting communities nor the preferences of refugees themselves. Building on models from two-sided matching theory, we introduce a new framework for matching with multidimensional knapsack constraints that models the (possibly multidimensional) sizes of families, as well as the capacities of localities. We propose four refugee resettlement mechanisms and two solution concepts that can be used in refugee resettlement matching under various institutional and informational constraints. Our theoretical results and simulations using refugee resettlement data suggest that preference-based matching mechanisms can improve match eﬃciency, respect priorities of localities, and incentivize refugees to report where they would prefer to settle.},
	language = {en},
	number = {10},
	urldate = {2024-12-17},
	journal = {American Economic Review},
	author = {Delacrétaz, David and Kominers, Scott Duke and Teytelboym, Alexander},
	month = oct,
	year = {2023},
	pages = {2689--2717},
}

@article{ahani_dynamic_2024,
	title = {Dynamic {Placement} in {Refugee} {Resettlement}},
	volume = {72},
	issn = {0030-364X, 1526-5463},
	url = {https://pubsonline.informs.org/doi/10.1287/opre.2021.0534},
	doi = {10.1287/opre.2021.0534},
	abstract = {Employment outcomes of resettled refugees depend strongly on where they are initially placed in the host country. Each week, a resettlement agency is allocated a set of refugees by the U.S. government. The agency must place these refugees in its local affiliates while respecting the affiliates’ annual capacities. We develop an allocation system that recommends where to place an incoming refugee family to improve total employment suc­ cess. Our algorithm is based on two-stage stochastic programming and achieves over 98\% of the hindsight-optimal employment, compared with under 90\% of current greedy-like approaches. This dramatic improvement persists even when we incorporate a vast array of practical features of the refugee resettlement process including inseparable families, batch­ ing, and uncertainty with respect to the number of future arrivals. Our algorithm is now part of the AnnieTM MOORE optimization software used by a leading American refugee resettlement agency.},
	language = {en},
	number = {3},
	urldate = {2024-12-17},
	journal = {Operations Research},
	author = {Ahani, Narges and Gölz, Paul and Procaccia, Ariel D. and Teytelboym, Alexander and Trapp, Andrew C.},
	month = may,
	year = {2024},
	pages = {1087--1104},
}

@misc{freund_group_2024,
	title = {Group fairness in dynamic refugee assignment},
	url = {http://arxiv.org/abs/2301.10642},
	doi = {10.48550/arXiv.2301.10642},
	abstract = {Ensuring that refugees and asylum seekers thrive (e.g., find employment) in their host countries is a profound humanitarian goal, and a primary driver of employment is the geographic location within a host country to which the refugee or asylum seeker is assigned. Recent research has proposed and implemented algorithms that assign refugees and asylum seekers to geographic locations in a manner that maximizes the average employment across all arriving refugees. While these algorithms can have substantial overall positive impact, using data from two industry collaborators we show that the impact of these algorithms can vary widely across key subgroups based on country of origin, age, or educational background. Thus motivated, we develop a simple and interpretable framework for incorporating group fairness into the dynamic refugee assignment problem. In particular, the framework can flexibly incorporate many existing and future definitions of group fairness from the literature (e.g., maxmin, randomized, and proportionally-optimized within-group). Equipped with our framework, we propose two bid-price algorithms that maximize overall employment while simultaneously yielding provable group fairness guarantees. Through extensive numerical experiments using various definitions of group fairness and real-world data from the U.S. and the Netherlands, we show that our algorithms can yield substantial improvements in group fairness compared to an offline benchmark fairness constraints, with only small relative decreases (\${\textbackslash}approx\$ 1\%-5\%) in global performance.},
	urldate = {2024-12-17},
	publisher = {arXiv},
	author = {Freund, Daniel and Lykouris, Thodoris and Paulson, Elisabeth and Sturt, Bradley and Weng, Wentao},
	month = jan,
	year = {2024},
	note = {arXiv:2301.10642 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory},
}

@article{bansak_outcome-driven_2024,
	title = {Outcome-{Driven} {Dynamic} {Refugee} {Assignment} with {Allocation} {Balancing}},
	volume = {72},
	issn = {0030-364X},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/opre.2022.0445},
	doi = {10.1287/opre.2022.0445},
	abstract = {This study proposes two new dynamic assignment algorithms to match refugees and asylum seekers to geographic localities within a host country. The first, currently implemented in a multiyear randomized control trial in Switzerland, seeks to maximize the average predicted employment level (or any measured outcome of interest) of refugees through a minimum-discord online assignment algorithm. The performance of this algorithm is tested on real refugee resettlement data from both the United States and Switzerland, where we find that it is able to achieve near-optimal expected employment, compared with the hindsight-optimal solution, and is able to improve upon the status quo procedure by 40\%–50\%. However, pure outcome maximization can result in a periodically imbalanced allocation to the localities over time, leading to implementation difficulties and an undesirable workflow for resettlement resources and agents. To address these problems, the second algorithm balances the goal of improving refugee outcomes with the desire for an even allocation over time. We find that this algorithm can achieve near-perfect balance over time with only a small loss in expected employment compared with the employment-maximizing algorithm. In addition, the allocation balancing algorithm offers a number of ancillary benefits compared with pure outcome maximization, including robustness to unknown arrival flows and greater exploration.

Funding: Financial support from the Charles Koch Foundation, Stanford Impact Labs, the Rockefeller Foundation, Google.org, Schmidt Futures, the Stanford Institute for Human-Centered Artificial Intelligence, and Stanford University is gratefully acknowledged.

Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2022.0445.},
	number = {6},
	urldate = {2024-12-17},
	journal = {Operations Research},
	author = {Bansak, Kirk and Paulson, Elisabeth},
	month = nov,
	year = {2024},
	note = {Publisher: INFORMS},
	keywords = {Google Scholar, OR Practice, dynamic assignment algorithms, load balancing, machine learning, refugee matching, stochastic programming},
	pages = {2375--2390},
}

@inproceedings{robertson_expressiveness_2023,
	address = {Hamburg Germany},
	title = {Expressiveness, {Cost}, and {Collectivism}: {How} the {Design} of {Preference} {Languages} {Shapes} {Participation} in {Algorithmic} {Decision}-{Making}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {Expressiveness, {Cost}, and {Collectivism}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3580996},
	doi = {10.1145/3544548.3580996},
	language = {en},
	urldate = {2024-12-10},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Robertson, Samantha and Nguyen, Tonya and Hu, Cathy and Albiston, Catherine and Nikzad, Afshin and Salehi, Niloufar},
	month = apr,
	year = {2023},
	pages = {1--16},
}

@inproceedings{robertson_modeling_2021,
	title = {Modeling {Assumptions} {Clash} with the {Real} {World}: {Transparency}, {Equity}, and {Community} {Challenges} for {Student} {Assignment} {Algorithms}},
	shorttitle = {Modeling {Assumptions} {Clash} with the {Real} {World}},
	url = {http://arxiv.org/abs/2101.10367},
	doi = {10.1145/3411764.3445748},
	abstract = {Across the United States, a growing number of school districts are turning to matching algorithms to assign students to public schools. The designers of these algorithms aimed to promote values such as transparency, equity, and community in the process. However, school districts have encountered practical challenges in their deployment. In fact, San Francisco Unified School District voted to stop using and completely redesign their student assignment algorithm because it was not promoting educational equity in practice. We analyze this system using a Value Sensitive Design approach and find that one reason values are not met in practice is that the system relies on modeling assumptions about families' priorities, constraints, and goals that clash with the real world. These assumptions overlook the complex barriers to ideal participation that many families face, particularly because of socioeconomic inequalities. We argue that direct, ongoing engagement with stakeholders is central to aligning algorithmic values with real world conditions. In doing so we must broaden how we evaluate algorithms while recognizing the limitations of purely algorithmic solutions in addressing complex socio-political problems.},
	urldate = {2024-12-10},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Robertson, Samantha and Nguyen, Tonya and Salehi, Niloufar},
	month = may,
	year = {2021},
	note = {arXiv:2101.10367 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction},
	pages = {1--14},
}

@misc{robertson_not_2022,
	title = {Not {Another} {School} {Resource} {Map}: {Meeting} {Underserved} {Families}' {Information} {Needs} {Requires} {Trusting} {Relationships} and {Personalized} {Care}},
	shorttitle = {Not {Another} {School} {Resource} {Map}},
	url = {http://arxiv.org/abs/2203.15795},
	doi = {10.48550/arXiv.2203.15795},
	abstract = {Public school districts across the United States have implemented school choice systems that have the potential to improve underserved students' access to educational opportunities. However, research has shown that learning about and applying for schools can be extremely time-consuming and expensive, making it difficult for these systems to create more equitable access to resources in practice. A common factor surfaced in prior work is unequal access to information about the schools and enrollment process. In response, governments and non-profits have invested in providing more information about schools to parents, for instance, through detailed online dashboards. However, we know little about what information is actually useful for historically marginalized and underserved families. We conducted interviews with 10 low-income families and families of color to learn about the challenges they faced navigating an online school choice and enrollment system. We complement this data with four interviews with people who have supported families through the enrollment process in a wide range of roles, from school principal to non-profit staff ("parent advocates"). Our findings highlight the value of personalized support and trusting relationships to delivering relevant and helpful information. We contrast this against online information resources and dashboards, which tend to be impersonal, target a broad audience, and make strong assumptions about what parents should look for in a school without sensitivity to families' varying circumstances. We advocate for an assets-based design approach to information support in public school enrollment, which would ask how we can support the local, one-on-one support that community members already provide.},
	urldate = {2024-12-10},
	publisher = {arXiv},
	author = {Robertson, Samantha and Nguyen, Tonya and Salehi, Niloufar},
	month = mar,
	year = {2022},
	note = {arXiv:2203.15795 [cs]
version: 1},
	keywords = {Computer Science - Human-Computer Interaction},
}

@article{lee_webuildai_2019,
	title = {{WeBuildAI}: {Participatory} {Framework} for {Algorithmic} {Governance}},
	volume = {3},
	issn = {2573-0142},
	shorttitle = {{WeBuildAI}},
	url = {https://dl.acm.org/doi/10.1145/3359283},
	doi = {10.1145/3359283},
	abstract = {Algorithms increasingly govern societal functions, impacting multiple stakeholders and social groups. How can we design these algorithms to balance varying interests in a moral, legitimate way? As one answer to this question, we present WeBuildAI, a collective participatory framework that enables people to build algorithmic policy for their communities. The key idea of the framework is to enable stakeholders to construct a computational model that represents their views and to have those models vote on their behalf to create algorithmic policy. As a case study, we applied this framework to a matching algorithm that operates an on-demand food donation transportation service in order to adjudicate equity and efficiency trade-offs. The service's stakeholders--donors, volunteers, recipient organizations, and nonprofit employees--used the framework to design the algorithm through a series of studies in which we researched their experiences. Our findings suggest that the framework successfully enabled participants to build models that they felt confident represented their own beliefs. Participatory algorithm design also improved both procedural fairness and the distributive outcomes of the algorithm, raised participants' algorithmic awareness, and helped identify inconsistencies in human decision-making in the governing organization. Our work demonstrates the feasibility, potential and challenges of community involvement in algorithm design.},
	language = {en},
	number = {CSCW},
	urldate = {2024-12-10},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Lee, Min Kyung and Kusbit, Daniel and Kahng, Anson and Kim, Ji Tae and Yuan, Xinran and Chan, Allissa and See, Daniel and Noothigattu, Ritesh and Lee, Siheon and Psomas, Alexandros and Procaccia, Ariel D.},
	month = nov,
	year = {2019},
	pages = {1--35},
}

@article{fehr_egalitarianism_2008,
	title = {Egalitarianism in young children},
	volume = {454},
	copyright = {2008 Macmillan Publishers Limited. All rights reserved},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature07155},
	doi = {10.1038/nature07155},
	abstract = {Human social interaction is strongly shaped by other-regarding preferences, that is, a concern for the welfare of others. These preferences are important for a unique aspect of human sociality—large scale cooperation with genetic strangers—but little is known about their developmental roots. Here we show that young children’s other-regarding preferences assume a particular form, inequality aversion that develops strongly between the ages of 3 and 8. At age 3–4, the overwhelming majority of children behave selfishly, whereas most children at age 7–8 prefer resource allocations that remove advantageous or disadvantageous inequality. Moreover, inequality aversion is strongly shaped by parochialism, a preference for favouring the members of one’s own social group. These results indicate that human egalitarianism and parochialism have deep developmental roots, and the simultaneous emergence of altruistic sharing and parochialism during childhood is intriguing in view of recent evolutionary theories which predict that the same evolutionary process jointly drives both human altruism and parochialism.},
	language = {en},
	number = {7208},
	urldate = {2024-12-10},
	journal = {Nature},
	author = {Fehr, Ernst and Bernhard, Helen and Rockenbach, Bettina},
	month = aug,
	year = {2008},
	note = {Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, Science, multidisciplinary},
	pages = {1079--1083},
}

@article{henrich_economic_2005,
	title = {“{Economic} man” in cross-cultural perspective: {Behavioral} experiments in 15 small-scale societies},
	volume = {28},
	issn = {0140-525X, 1469-1825},
	shorttitle = {“{Economic} man” in cross-cultural perspective},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/economic-man-in-crosscultural-perspective-behavioral-experiments-in-15-smallscale-societies/6EFFD9263D9A5F2FE5DE9DE8FBBA4988},
	doi = {10.1017/S0140525X05000142},
	abstract = {Researchers from across the social sciences have found consistent deviations from the predictions of the canonical model of self-interest in hundreds of experiments from around the world. This research, however, cannot determine whether the uniformity results from universal patterns of human behavior or from the limited cultural variation available among the university students used in virtually all prior experimental work. To address this, we undertook a cross-cultural study of behavior in ultimatum, public goods, and dictator games in a range of small-scale societies exhibiting a wide variety of economic and cultural conditions. We found, first, that the canonical model – based on self-interest – fails in all of the societies studied. Second, our data reveal substantially more behavioral variability across social groups than has been found in previous research. Third, group-level differences in economic organization and the structure of social interactions explain a substantial portion of the behavioral variation across societies: the higher the degree of market integration and the higher the payoffs to cooperation in everyday life, the greater the level of prosociality expressed in experimental games. Fourth, the available individual-level economic and demographic variables do not consistently explain game behavior, either within or across groups. Fifth, in many cases experimental play appears to reflect the common interactional patterns of everyday life.},
	language = {en},
	number = {6},
	urldate = {2024-12-10},
	journal = {Behavioral and Brain Sciences},
	author = {Henrich, Joseph and Boyd, Robert and Bowles, Samuel and Camerer, Colin and Fehr, Ernst and Gintis, Herbert and McElreath, Richard and Alvard, Michael and Barr, Abigail and Ensminger, Jean and Henrich, Natalie Smith and Hill, Kim and Gil-White, Francisco and Gurven, Michael and Marlowe, Frank W. and Patton, John Q. and Tracer, David},
	month = dec,
	year = {2005},
	keywords = {altruism, cooperation, cross-cultural research, experimental economics, game theory, public goods game, self-interest, ultimatum game},
	pages = {795--815},
}

@article{fehr_fairness_2000,
	title = {Fairness and {Retaliation}: {The} {Economics} of {Reciprocity}},
	volume = {14},
	issn = {0895-3309},
	shorttitle = {Fairness and {Retaliation}},
	url = {https://www.aeaweb.org/articles?id=10.1257%2Fjep.14.3.159&ref=hermes-kalamos.eu},
	doi = {10.1257/jep.14.3.159},
	abstract = {This paper shows that reciprocity has powerful implications for many economic domains. It is an important determinant in the enforcement of contracts and social norms and enhances the possibilities of collective action greatly. Reciprocity may render the provision of explicit incentive inefficient because the incentives may crowd out voluntary co-operation. It strongly limits the effects of competition in markets with incomplete contracts and gives rise to noncompetitive wage differences. Finally, reciprocity it is also a strong force contributing to the existence of incomplete contracts.},
	language = {en},
	number = {3},
	urldate = {2024-12-10},
	journal = {Journal of Economic Perspectives},
	author = {Fehr, Ernst and Gächter, Simon},
	month = sep,
	year = {2000},
	keywords = {Economic Anthropology, Equity, Justice, Inequality, and Other Normative Criteria and Measurement, Consumer Economics: Empirical Analysis, Economic Sociology},
	pages = {159--181},
}

@article{fehr_normative_2018,
	title = {Normative foundations of human cooperation},
	volume = {2},
	copyright = {2018 The Author(s)},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-018-0385-5},
	doi = {10.1038/s41562-018-0385-5},
	abstract = {A large literature shares the view that social norms shape human cooperation, but without a clean empirical identification of the relevant norms almost every behaviour can be rationalized as norm driven, thus rendering norms useless as an explanatory construct. This raises the question of whether social norms are indeed causal drivers of behaviour and can convincingly explain major cooperation-related regularities. Here, we show that the norm of conditional cooperation provides such an explanation, that powerful methods for its empirical identification exist and that social norms have causal effects. Norm compliance rests on fundamental human motives (‘social preferences’) that also imply a willingness to punish free-riders, but normative constraints on peer punishment are important for its effectiveness and welfare properties. If given the chance, a large majority of people favour the imposition of such constraints through the migration to institutional environments that enable the normative guidance of cooperation and norm enforcement behaviours.},
	language = {en},
	number = {7},
	urldate = {2024-12-10},
	journal = {Nature Human Behaviour},
	author = {Fehr, Ernst and Schurtenberger, Ivo},
	month = jul,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Behavioral Sciences, Experimental Psychology, Life Sciences, Microeconomics, Neurosciences, Personality and Social Psychology, general},
	pages = {458--468},
}

@book{camerer_behavioral_2011,
	title = {Behavioral {Game} {Theory}: {Experiments} in {Strategic} {Interaction}},
	isbn = {978-1-4008-4088-5},
	shorttitle = {Behavioral {Game} {Theory}},
	abstract = {Game theory, the formalized study of strategy, began in the 1940s by asking how emotionless geniuses should play games, but ignored until recently how average people with emotions and limited foresight actually play games. This book marks the first substantial and authoritative effort to close this gap. Colin Camerer, one of the field's leading figures, uses psychological principles and hundreds of experiments to develop mathematical theories of reciprocity, limited strategizing, and learning, which help predict what real people and companies do in strategic situations. Unifying a wealth of information from ongoing studies in strategic behavior, he takes the experimental science of behavioral economics a major step forward. He does so in lucid, friendly prose. Behavioral game theory has three ingredients that come clearly into focus in this book: mathematical theories of how moral obligation and vengeance affect the way people bargain and trust each other; a theory of how limits in the brain constrain the number of steps of "I think he thinks . . ." reasoning people naturally do; and a theory of how people learn from experience to make better strategic decisions. Strategic interactions that can be explained by behavioral game theory include bargaining, games of bluffing as in sports and poker, strikes, how conventions help coordinate a joint activity, price competition and patent races, and building up reputations for trustworthiness or ruthlessness in business or life. While there are many books on standard game theory that address the way ideally rational actors operate, Behavioral Game Theory stands alone in blending experimental evidence and psychology in a mathematical theory of normal strategic behavior. It is must reading for anyone who seeks a more complete understanding of strategic thinking, from professional economists to scholars and students of economics, management studies, psychology, political science, anthropology, and biology.},
	language = {en},
	publisher = {Princeton University Press},
	author = {Camerer, Colin F.},
	month = sep,
	year = {2011},
	note = {Google-Books-ID: cr\_Xg7cRvdcC},
	keywords = {Business \& Economics / Economics / General},
}

@article{fehr_theory_1999,
	title = {A {Theory} of {Fairness}, {Competition}, and {Cooperation}},
	volume = {114},
	issn = {0033-5533},
	url = {https://www.jstor.org/stable/2586885},
	abstract = {There is strong evidence that people exploit their bargaining power in competitive markets but not in bilateral bargaining situations. There is also strong evidence that people exploit free-riding opportunities in voluntary cooperation games. Yet, when they are given the opportunity to punish free riders, stable cooperation is maintained, although punishment is costly for those who punish. This paper asks whether there is a simple common principle that can explain this puzzling evidence. We show that if some people care about equity the puzzles can be resolved. It turns out that the economic environment determines whether the fair types or the selfish types dominate equilibrium behavior.},
	number = {3},
	urldate = {2024-12-10},
	journal = {The Quarterly Journal of Economics},
	author = {Fehr, Ernst and Schmidt, Klaus M.},
	year = {1999},
	note = {Publisher: Oxford University Press},
	pages = {817--868},
}

@article{bolton_inequality_2006,
	title = {Inequality {Aversion}, {Efficiency}, and {Maximin} {Preferences} in {Simple} {Distribution} {Experiments}: {Comment}},
	volume = {96},
	issn = {0002-8282},
	shorttitle = {Inequality {Aversion}, {Efficiency}, and {Maximin} {Preferences} in {Simple} {Distribution} {Experiments}},
	url = {https://www.jstor.org/stable/30035003},
	number = {5},
	urldate = {2024-12-10},
	journal = {The American Economic Review},
	author = {Bolton, Gary E. and Ockenfels, Axel},
	year = {2006},
	note = {Publisher: American Economic Association},
	pages = {1906--1911},
}

@misc{hansen_when_2024,
	title = {When is {Multicalibration} {Post}-{Processing} {Necessary}?},
	url = {http://arxiv.org/abs/2406.06487},
	doi = {10.48550/arXiv.2406.06487},
	abstract = {Calibration is a well-studied property of predictors which guarantees meaningful uncertainty estimates. Multicalibration is a related notion -- originating in algorithmic fairness -- which requires predictors to be simultaneously calibrated over a potentially complex and overlapping collection of protected subpopulations (such as groups defined by ethnicity, race, or income). We conduct the first comprehensive study evaluating the usefulness of multicalibration post-processing across a broad set of tabular, image, and language datasets for models spanning from simple decision trees to 90 million parameter fine-tuned LLMs. Our findings can be summarized as follows: (1) models which are calibrated out of the box tend to be relatively multicalibrated without any additional post-processing; (2) multicalibration post-processing can help inherently uncalibrated models; and (3) traditional calibration measures may sometimes provide multicalibration implicitly. More generally, we also distill many independent observations which may be useful for practical and effective applications of multicalibration post-processing in real-world contexts.},
	urldate = {2024-12-09},
	publisher = {arXiv},
	author = {Hansen, Dutch and Devic, Siddartha and Nakkiran, Preetum and Sharan, Vatsal},
	month = jun,
	year = {2024},
	note = {arXiv:2406.06487 [cs]
version: 1},
	keywords = {Computer Science - Machine Learning},
}

@misc{i-cheng_yeh_default_2009,
	title = {Default of {Credit} {Card} {Clients}},
	url = {https://archive.ics.uci.edu/dataset/350},
	doi = {10.24432/C55S3H},
	urldate = {2024-12-09},
	publisher = {UCI Machine Learning Repository},
	author = {{I-Cheng Yeh}},
	year = {2009},
}

@misc{barry_becker_adult_1996,
	title = {Adult},
	url = {https://archive.ics.uci.edu/dataset/2},
	doi = {10.24432/C5XW20},
	urldate = {2024-12-09},
	publisher = {UCI Machine Learning Repository},
	author = {Barry Becker, Ronny Kohavi},
	year = {1996},
}

@misc{s_moro_bank_2014,
	title = {Bank {Marketing}},
	url = {https://archive.ics.uci.edu/dataset/222},
	doi = {10.24432/C5K306},
	urldate = {2024-12-09},
	publisher = {UCI Machine Learning Repository},
	author = {S. Moro, P. Rita},
	year = {2014},
}

@inproceedings{rahman_optimizing_2016,
	address = {Cham},
	title = {Optimizing {Intersection}-{Over}-{Union} in {Deep} {Neural} {Networks} for {Image} {Segmentation}},
	isbn = {978-3-319-50835-1},
	doi = {10.1007/978-3-319-50835-1_22},
	abstract = {We consider the problem of learning deep neural networks (DNNs) for object category segmentation, where the goal is to label each pixel in an image as being part of a given object (foreground) or not (background). Deep neural networks are usually trained with simple loss functions (e.g., softmax loss). These loss functions are appropriate for standard classification problems where the performance is measured by the overall classification accuracy. For object category segmentation, the two classes (foreground and background) are very imbalanced. The intersection-over-union (IoU) is usually used to measure the performance of any object category segmentation method. In this paper, we propose an approach for directly optimizing this IoU measure in deep neural networks. Our experimental results on two object category segmentation datasets demonstrate that our approach outperforms DNNs trained with standard softmax loss.},
	language = {en},
	booktitle = {Advances in {Visual} {Computing}},
	publisher = {Springer International Publishing},
	author = {Rahman, Md Atiqur and Wang, Yang},
	editor = {Bebis, George and Boyle, Richard and Parvin, Bahram and Koracin, Darko and Porikli, Fatih and Skaff, Sandra and Entezari, Alireza and Min, Jianyuan and Iwai, Daisuke and Sadagic, Amela and Scheidegger, Carlos and Isenberg, Tobias},
	year = {2016},
	pages = {234--244},
}

@article{williamson_composite_nodate,
	title = {Composite {Multiclass} {Losses}},
	abstract = {We consider loss functions for multiclass prediction problems. We show when a multiclass loss can be expressed as a “proper composite loss”, which is the composition of a proper loss and a link function. We extend existing results for binary losses to multiclass losses. We subsume results on “classiﬁcation calibration” by relating it to properness. We determine the stationarity condition, Bregman representation, order-sensitivity, and quasi-convexity of multiclass proper losses. We then characterise the existence and uniqueness of the composite representation for multiclass losses. We show how the composite representation is related to other core properties of a loss: mixability, admissibility and (strong) convexity of multiclass losses which we characterise in terms of the Hessian of the Bayes risk. We show that the simple integral representation for binary proper losses can not be extended to multiclass losses but offer concrete guidance regarding how to design different loss functions. The conclusion drawn from these results is that the proper composite representation is a natural and convenient tool for the design of multiclass loss functions.},
	language = {en},
	author = {Williamson, Robert C and Vernet, Elodie and Reid, Mark D},
}

@misc{derr_four_2024,
	title = {Four {Facets} of {Forecast} {Felicity}: {Calibration}, {Predictiveness}, {Randomness} and {Regret}},
	shorttitle = {Four {Facets} of {Forecast} {Felicity}},
	url = {http://arxiv.org/abs/2401.14483},
	doi = {10.48550/arXiv.2401.14483},
	abstract = {Machine learning is about forecasting. Forecasts, however, obtain their usefulness only through their evaluation. Machine learning has traditionally focused on types of losses and their corresponding regret. Currently, the machine learning community regained interest in calibration. In this work, we show the conceptual equivalence of calibration and regret in evaluating forecasts. We frame the evaluation problem as a game between a forecaster, a gambler and nature. Putting intuitive restrictions on gambler and forecaster, calibration and regret naturally fall out of the framework. In addition, this game links evaluation of forecasts to randomness of outcomes. Random outcomes with respect to forecasts are equivalent to good forecasts with respect to outcomes. We call those dual aspects, calibration and regret, predictiveness and randomness, the four facets of forecast felicity.},
	urldate = {2024-12-09},
	publisher = {arXiv},
	author = {Derr, Rabanus and Williamson, Robert C.},
	month = sep,
	year = {2024},
	note = {arXiv:2401.14483 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{wang_comprehensive_2022,
	title = {A {Comprehensive} {Survey} of {Loss} {Functions} in {Machine} {Learning}},
	volume = {9},
	issn = {2198-5804, 2198-5812},
	url = {https://link.springer.com/10.1007/s40745-020-00253-5},
	doi = {10.1007/s40745-020-00253-5},
	abstract = {As one of the important research topics in machine learning, loss function plays an important role in the construction of machine learning algorithms and the improvement of their performance, which has been concerned and explored by many researchers. But it still has a big gap to summarize, analyze and compare the classical loss functions. Therefore, this paper summarizes and analyzes 31 classical loss functions in machine learning. Specifically, we describe the loss functions from the aspects of traditional machine learning and deep learning respectively. The former is divided into classification problem, regression problem and unsupervised learning according to the task type. The latter is subdivided according to the application scenario, and here we mainly select object detection and face recognition to introduces their loss functions. In each task or application, in addition to analyzing each loss function from formula, meaning, image and algorithm, the loss functions under the same task or application are also summarized and compared to deepen the understanding and provide help for the selection and improvement of loss function.},
	language = {en},
	number = {2},
	urldate = {2024-12-09},
	journal = {Annals of Data Science},
	author = {Wang, Qi and Ma, Yue and Zhao, Kun and Tian, Yingjie},
	month = apr,
	year = {2022},
	pages = {187--212},
}

@misc{richardson_loss_2022,
	title = {Loss as the {Inconsistency} of a {Probabilistic} {Dependency} {Graph}: {Choose} {Your} {Model}, {Not} {Your} {Loss} {Function}},
	shorttitle = {Loss as the {Inconsistency} of a {Probabilistic} {Dependency} {Graph}},
	url = {http://arxiv.org/abs/2202.11862},
	doi = {10.48550/arXiv.2202.11862},
	abstract = {In a world blessed with a great diversity of loss functions, we argue that that choice between them is not a matter of taste or pragmatics, but of model. Probabilistic depencency graphs (PDGs) are probabilistic models that come equipped with a measure of "inconsistency". We prove that many standard loss functions arise as the inconsistency of a natural PDG describing the appropriate scenario, and use the same approach to justify a well-known connection between regularizers and priors. We also show that the PDG inconsistency captures a large class of statistical divergences, and detail benefits of thinking of them in this way, including an intuitive visual language for deriving inequalities between them. In variational inference, we find that the ELBO, a somewhat opaque objective for latent variable models, and variants of it arise for free out of uncontroversial modeling assumptions -- as do simple graphical proofs of their corresponding bounds. Finally, we observe that inconsistency becomes the log partition function (free energy) in the setting where PDGs are factor graphs.},
	urldate = {2024-12-09},
	publisher = {arXiv},
	author = {Richardson, Oliver E.},
	month = feb,
	year = {2022},
	note = {arXiv:2202.11862 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Theory, Computer Science - Machine Learning, Mathematics - Information Theory},
}

@article{wilder_melding_2019,
	title = {Melding the {Data}-{Decisions} {Pipeline}: {Decision}-{Focused} {Learning} for {Combinatorial} {Optimization}},
	volume = {33},
	copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {Melding the {Data}-{Decisions} {Pipeline}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/3982},
	doi = {10.1609/aaai.v33i01.33011658},
	abstract = {Creating impact in real-world settings requires artificial intelligence techniques to span the full pipeline from data, to predictive models, to decisions. These components are typically approached separately: a machine learning model is first trained via a measure of predictive accuracy, and then its predictions are used as input into an optimization algorithm which produces a decision. However, the loss function used to train the model may easily be misaligned with the end goal, which is to make the best decisions possible. Hand-tuning the loss function to align with optimization is a difficult and error-prone process (which is often skipped entirely).We focus on combinatorial optimization problems and introduce a general framework for decision-focused learning, where the machine learning model is directly trained in conjunction with the optimization algorithm to produce highquality decisions. Technically, our contribution is a means of integrating common classes of discrete optimization problems into deep learning or other predictive models, which are typically trained via gradient descent. The main idea is to use a continuous relaxation of the discrete problem to propagate gradients through the optimization procedure. We instantiate this framework for two broad classes of combinatorial problems: linear programs and submodular maximization. Experimental results across a variety of domains show that decisionfocused learning often leads to improved optimization performance compared to traditional methods. We find that standard measures of accuracy are not a reliable proxy for a predictive model’s utility in optimization, and our method’s ability to specify the true goal as the model’s training objective yields substantial dividends across a range of decision problems.},
	language = {en},
	number = {01},
	urldate = {2024-12-09},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Wilder, Bryan and Dilkina, Bistra and Tambe, Milind},
	month = jul,
	year = {2019},
	note = {Number: 01},
	pages = {1658--1665},
}

@inproceedings{wang_learning_2021,
	title = {Learning {MDPs} from {Features}: {Predict}-{Then}-{Optimize} for {Sequential} {Decision} {Making} by {Reinforcement} {Learning}},
	volume = {34},
	shorttitle = {Learning {MDPs} from {Features}},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/hash/49e863b146f3b5470ee222ee84669b1c-Abstract.html},
	abstract = {In the predict-then-optimize framework, the objective is to train a predictive model, mapping from environment features to parameters of an optimization problem, which maximizes decision quality when the optimization is subsequently solved. Recent work on decision-focused learning shows that embedding the optimization problem in the training pipeline can improve decision quality and help generalize better to unseen tasks compared to relying on an intermediate loss function for evaluating prediction quality. We study the predict-then-optimize framework in the context of sequential decision problems (formulated as MDPs) that are solved via reinforcement learning. In particular, we are given environment features and a set of trajectories from training MDPs, which we use to train a predictive model that generalizes to unseen test MDPs without trajectories. Two significant computational challenges arise in applying decision-focused learning to MDPs: (i) large state and action spaces make it infeasible for existing techniques to differentiate through MDP problems, and (ii) the high-dimensional policy space, as parameterized by a neural network, makes differentiating through a policy expensive. We resolve the first challenge by sampling provably unbiased derivatives to approximate and differentiate through optimality conditions, and the second challenge by using a low-rank approximation to the high-dimensional sample-based derivatives. We implement both Bellman-based and policy gradient-based decision-focused learning on three different MDP problems with missing parameters, and show that decision-focused learning performs better in generalization to unseen tasks.},
	urldate = {2024-12-09},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Wang, Kai and Shah, Sanket and Chen, Haipeng and Perrault, Andrew and Doshi-Velez, Finale and Tambe, Milind},
	year = {2021},
	pages = {8795--8806},
}

@article{shah_leaving_2024,
	title = {Leaving the {Nest}: {Going} beyond {Local} {Loss} {Functions} for {Predict}-{Then}-{Optimize}},
	volume = {38},
	copyright = {Copyright (c) 2024 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {Leaving the {Nest}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/29410},
	doi = {10.1609/aaai.v38i13.29410},
	abstract = {Predict-then-Optimize is a framework for using machine learning to perform decision-making under uncertainty. The central research question it asks is, "How can we use the structure of a decision-making task to tailor ML models for that specific task?" To this end, recent work has proposed learning task-specific loss functions that capture this underlying structure. However, current approaches make restrictive assumptions about the form of these losses and their impact on ML model behavior. These assumptions both lead to approaches with high computational cost, and when they are violated in practice, poor performance. In this paper, we propose solutions to these issues, avoiding the aforementioned assumptions and utilizing the ML model's features to increase the sample efficiency of learning loss functions. We empirically show that our method achieves state-of-the-art results in four domains from the literature, often requiring an order of magnitude fewer samples than comparable methods from past work. Moreover, our approach outperforms the best existing method by nearly 200\% when the localness assumption is broken.},
	language = {en},
	number = {13},
	urldate = {2024-12-09},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Shah, Sanket and Wilder, Bryan and Perrault, Andrew and Tambe, Milind},
	month = mar,
	year = {2024},
	note = {Number: 13},
	keywords = {RU: Decision/Utility Theory},
	pages = {14902--14909},
}

@inproceedings{geng_benchmarking_2024,
	title = {Benchmarking {PtO} and {PnO} {Methods} in the {Predictive} {Combinatorial} {Optimization} {Regime}},
	url = {https://openreview.net/forum?id=cX57Pbw8vS#discussion},
	abstract = {Predictive combinatorial optimization, where the parameters of combinatorial optimization (CO) are unknown at the decision-making time, is the precise modeling of many real-world applications, including energy cost-aware scheduling and budget allocation on advertising. Tackling such a problem usually involves a prediction model and a CO solver. These two modules are integrated into the predictive CO pipeline following two design principles: ''Predict-then-Optimize (PtO)'', which learns predictions by supervised training and subsequently solves CO using predicted coefficients, while the other, named ''Predict-and-Optimize (PnO)'', directly optimizes towards the ultimate decision quality and claims to yield better decisions than traditional PtO approaches. However, there lacks a systematic benchmark of both approaches, including the specific design choices at the module level, as well as an evaluation dataset that covers representative real-world scenarios. To this end, we develop a modular framework to benchmark 11 existing PtO/PnO methods on 8 problems, including a new industrial dataset for combinatorial advertising that will be released. Our study shows that PnO approaches are better than PtO on 7 out of 8 benchmarks, but there is no silver bullet found for the specific design choices of PnO. A comprehensive categorization of current approaches and integration of typical scenarios are provided under a unified benchmark. Therefore, this paper could serve as a comprehensive benchmark for future PnO approach development and also offer fast prototyping for application-focused development. The code is available at {\textbackslash}url\{https://github.com/Thinklab-SJTU/PredictiveCO-Benchmark\}.},
	language = {en},
	urldate = {2024-12-09},
	author = {Geng, Haoyu and Ruan, Hang and Wang, Runzhong and Li, Yang and Wang, Yang and Chen, Lei and Yan, Junchi},
	month = nov,
	year = {2024},
}

@article{mandi_decision-focused_2024,
	title = {Decision-{Focused} {Learning}: {Foundations}, {State} of the {Art}, {Benchmark} and {Future} {Opportunities}},
	volume = {80},
	issn = {1076-9757},
	shorttitle = {Decision-{Focused} {Learning}},
	url = {http://arxiv.org/abs/2307.13565},
	doi = {10.1613/jair.1.15320},
	abstract = {Decision-focused learning (DFL) is an emerging paradigm that integrates machine learning (ML) and constrained optimization to enhance decision quality by training ML models in an end-to-end system. This approach shows significant potential to revolutionize combinatorial decision-making in real-world applications that operate under uncertainty, where estimating unknown parameters within decision models is a major challenge. This paper presents a comprehensive review of DFL, providing an in-depth analysis of both gradient-based and gradient-free techniques used to combine ML and constrained optimization. It evaluates the strengths and limitations of these techniques and includes an extensive empirical evaluation of eleven methods across seven problems. The survey also offers insights into recent advancements and future research directions in DFL. Code and benchmark: https://github.com/PredOpt/predopt-benchmarks},
	urldate = {2024-12-09},
	journal = {Journal of Artificial Intelligence Research},
	author = {Mandi, Jayanta and Kotary, James and Berden, Senne and Mulamba, Maxime and Bucarey, Victor and Guns, Tias and Fioretto, Ferdinando},
	month = aug,
	year = {2024},
	note = {arXiv:2307.13565 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Mathematics - Optimization and Control},
	pages = {1623--1701},
}

@article{shah_decision-focused_nodate,
	title = {Decision-{Focused} {Learning} without {Differentiable} {Optimization}: {Learning} {Locally} {Optimized} {Decision} {Losses}},
	abstract = {Decision-Focused Learning (DFL) is a paradigm for tailoring a predictive model to a downstream optimization task that uses its predictions in order to perform better on that speciﬁc task. The main technical challenge associated with DFL is that it requires being able to differentiate through the optimization problem, which is difﬁcult due to discontinuous solutions and other challenges. Past work has largely gotten around this this issue by handcrafting task-speciﬁc surrogates to the original optimization problem that provide informative gradients when differentiated through. However, the need to handcraft surrogates for each new task limits the usability of DFL. In addition, there are often no guarantees about the convexity of the resulting surrogates and, as a result, training a predictive model using them can lead to inferior local optima. In this paper, we do away with surrogates altogether and instead learn loss functions that capture task-speciﬁc information. To the best of our knowledge, ours is the ﬁrst approach that entirely replaces the optimization component of decision-focused learning with a loss that is automatically learned. Our approach (a) only requires access to a black-box oracle that can solve the optimization problem and is thus generalizable, and (b) can be convex by construction and so can be easily optimized over. We evaluate our approach on three resource allocation problems from the literature and ﬁnd that our approach outperforms learning without taking into account task-structure in all three domains, and even hand-crafted surrogates from the literature.},
	language = {en},
	author = {Shah, Sanket and Wang, Kai and Wilder, Bryan and Perrault, Andrew and Tambe, Milind},
}

@article{shah_decision-focused_nodate-1,
	title = {Decision-{Focused} {Learning} without {Differentiable} {Optimization}: {Learning} {Locally} {Optimized} {Decision} {Losses}},
	abstract = {Decision-Focused Learning (DFL) is a paradigm for tailoring a predictive model to a downstream optimization task that uses its predictions in order to perform better on that speciﬁc task. The main technical challenge associated with DFL is that it requires being able to differentiate through the optimization problem, which is difﬁcult due to discontinuous solutions and other challenges. Past work has largely gotten around this this issue by handcrafting task-speciﬁc surrogates to the original optimization problem that provide informative gradients when differentiated through. However, the need to handcraft surrogates for each new task limits the usability of DFL. In addition, there are often no guarantees about the convexity of the resulting surrogates and, as a result, training a predictive model using them can lead to inferior local optima. In this paper, we do away with surrogates altogether and instead learn loss functions that capture task-speciﬁc information. To the best of our knowledge, ours is the ﬁrst approach that entirely replaces the optimization component of decision-focused learning with a loss that is automatically learned. Our approach (a) only requires access to a black-box oracle that can solve the optimization problem and is thus generalizable, and (b) can be convex by construction and so can be easily optimized over. We evaluate our approach on three resource allocation problems from the literature and ﬁnd that our approach outperforms learning without taking into account task-structure in all three domains, and even hand-crafted surrogates from the literature.},
	language = {en},
	author = {Shah, Sanket and Wang, Kai and Wilder, Bryan and Perrault, Andrew and Tambe, Milind},
}

@inproceedings{bao_proper_2023,
	title = {Proper {Losses}, {Moduli} of {Convexity}, and {Surrogate} {Regret} {Bounds}},
	url = {https://proceedings.mlr.press/v195/bao23a.html},
	abstract = {Proper losses (or proper scoring rules) have been used for over half a century to elicit users’ subjective probability from the observations. In the recent machine learning community, we often tackle downstream tasks such as classification and bipartite ranking with the elicited probabilities. Here, we engage in assessing the quality of the elicited probabilities with different proper losses, which can be characterized by surrogate regret bounds to describe the convergence speed of an estimated probability to the optimal one when optimizing a proper loss. This work contributes to a sharp analysis of surrogate regret bounds in two ways. First, we provide general surrogate regret bounds for proper losses measured by the 𝐿1L1L{\textasciicircum}1 distance. This abstraction eschews a tailor-made analysis of each downstream task and delineates how universally a loss function operates. Our analysis relies on a classical mathematical tool known as the moduli of convexity, which is of independent interest per se. Second, we evaluate the surrogate regret bounds with polynomials to identify the quantitative convergence rate. These devices enable us to compare different losses, with which we can confirm that the lower bound of the surrogate regret bounds is Ω(𝜖1/2)Ω(ϵ1/2){\textbackslash}Omega({\textbackslash}epsilon{\textasciicircum}\{1/2\}) for popular loss functions.},
	language = {en},
	urldate = {2024-12-05},
	booktitle = {Proceedings of {Thirty} {Sixth} {Conference} on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Bao, Han},
	month = jul,
	year = {2023},
	note = {ISSN: 2640-3498},
	pages = {525--547},
}

@article{brier_verification_1950,
	title = {Verification of forecasts expressed in terms of probability},
	language = {en},
	journal = {National Weather Review},
	author = {Brier, Glenn W},
	year = {1950},
}

@article{gneiting_strictly_2007,
	title = {Strictly {Proper} {Scoring} {Rules}, {Prediction}, and {Estimation}},
	volume = {102},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214506000001437},
	doi = {10.1198/016214506000001437},
	language = {en},
	number = {477},
	urldate = {2024-12-05},
	journal = {Journal of the American Statistical Association},
	author = {Gneiting, Tilmann and Raftery, Adrian E},
	month = mar,
	year = {2007},
	pages = {359--378},
}

@article{mao_structured_2023,
	title = {Structured {Prediction} with {Stronger} {Consistency} {Guarantees}},
	volume = {36},
	url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/927962d8866377a07ee3150d2d691319-Abstract-Conference.html},
	language = {en},
	urldate = {2024-12-05},
	journal = {Advances in Neural Information Processing Systems},
	author = {Mao, Anqi and Mohri, Mehryar and Zhong, Yutao},
	month = dec,
	year = {2023},
	pages = {46903--46937},
}

@inproceedings{mao_theoretically_2024,
	title = {Theoretically {Grounded} {Loss} {Functions} and {Algorithms} for {Score}-{Based} {Multi}-{Class} {Abstention}},
	url = {https://proceedings.mlr.press/v238/mao24a.html},
	abstract = {Learning with abstention is a key scenario where the learner can abstain from making a prediction at some cost. In this paper, we analyze the score-based formulation of learning with abstention in the multi-class classification setting. We introduce new families of surrogate losses for the abstention loss function, which include the state-of-the-art surrogate losses in the single-stage setting and a novel family of loss functions in the two-stage setting. We prove strong non-asymptotic and hypothesis set-specific consistency guarantees for these surrogate losses, which upper-bound the estimation error of the abstention loss function in terms of the estimation error of the surrogate loss. Our bounds can help compare different score-based surrogates and guide the design of novel abstention algorithms by minimizing the proposed surrogate losses. We experimentally evaluate our new algorithms on CIFAR-10, CIFAR-100, and SVHN datasets and the practical significance of our new surrogate losses and two-stage abstention algorithms. Our results also show that the relative performance of the state-of-the-art score-based surrogate losses can vary across datasets.},
	language = {en},
	urldate = {2024-12-05},
	booktitle = {Proceedings of {The} 27th {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Mao, Anqi and Mohri, Mehryar and Zhong, Yutao},
	month = apr,
	year = {2024},
	note = {ISSN: 2640-3498},
	pages = {4753--4761},
}

@inproceedings{mao_universal_2024,
	title = {A {Universal} {Growth} {Rate} for {Learning} with {Smooth} {Surrogate} {Losses}},
	url = {https://openreview.net/forum?id=itztwTAcN6&referrer=%5Bthe%20profile%20of%20Mehryar%20Mohri%5D(%2Fprofile%3Fid%3D~Mehryar_Mohri1)},
	abstract = {This paper presents a comprehensive analysis of the growth rate of \$H\$-consistency bounds (and excess error bounds) for various surrogate losses used in classification. We prove a square-root growth rate near zero for smooth margin-based surrogate losses in binary classification, providing both upper and lower bounds under mild assumptions. This result also translates to excess error bounds. Our lower bound requires weaker conditions than those in previous work for excess error bounds, and our upper bound is entirely novel. Moreover, we extend this analysis to multi-class classification with a series of novel results, demonstrating a universal square-root growth rate for smooth *comp-sum* and *constrained losses*, covering common choices for training neural networks in multi-class classification. Given this universal rate, we turn to the question of choosing among different surrogate losses. We first examine how \$H\$-consistency bounds vary across surrogates based on the number of classes. Next, ignoring constants and focusing on behavior near zero, we identify *minimizability gaps* as the key differentiating factor in these bounds. Thus, we thoroughly analyze these gaps, to guide surrogate loss selection, covering: comparisons across different comp-sum losses, conditions where gaps become zero, and general conditions leading to small gaps. Additionally, we demonstrate the key role of minimizability gaps in comparing excess error bounds and \$H\$-consistency bounds.},
	language = {en},
	urldate = {2024-12-05},
	author = {Mao, Anqi and Mohri, Mehryar and Zhong, Yutao},
	month = nov,
	year = {2024},
}

@inproceedings{mao_multi-label_2024,
	title = {Multi-{Label} {Learning} with {Stronger} {Consistency} {Guarantees}},
	url = {https://openreview.net/forum?id=zAuerb1KGx&referrer=%5Bthe%20profile%20of%20Mehryar%20Mohri%5D(%2Fprofile%3Fid%3D~Mehryar_Mohri1)},
	abstract = {We present a detailed study of surrogate losses and algorithms for multi-label learning, supported by \$H\$-consistency bounds. We first show that, for the simplest form of multi-label loss (the popular Hamming loss), the well-known consistent binary relevance surrogate suffers from a sub-optimal dependency on the number of labels in terms of \$H\$-consistency bounds, when using smooth losses such as logistic losses. Furthermore, this loss function fails to account for label correlations. To address these drawbacks, we introduce a novel surrogate loss, *multi-label logistic loss*, that accounts for label correlations and benefits from label-independent \$H\$-consistency bounds. We then broaden our analysis to cover a more extensive family of multi-label losses, including all common ones and a new extension defined based on linear-fractional functions with respect to the confusion matrix. We also extend our multi-label logistic losses to more comprehensive multi-label comp-sum losses, adapting comp-sum losses from standard classification to the multi-label learning. We prove that this family of surrogate losses benefits from \$H\$-consistency bounds, and thus Bayes-consistency, across any general multi-label loss. Our work thus proposes a unified surrogate loss framework benefiting from strong consistency guarantees for any multi-label loss, significantly expanding upon previous work which only established Bayes-consistency and for specific loss functions. Additionally, we adapt constrained losses from standard classification to multi-label constrained losses in a similar way, which also benefit from \$H\$-consistency bounds and thus Bayes-consistency for any multi-label loss. We further describe efficient gradient computation algorithms for minimizing the multi-label logistic loss.},
	language = {en},
	urldate = {2024-12-05},
	author = {Mao, Anqi and Mohri, Mehryar and Zhong, Yutao},
	month = nov,
	year = {2024},
}

@article{zhang_bayes_2020,
	title = {Bayes {Consistency} vs. {H} -{Consistency}: {The} {Interplay} between {Surrogate} {Loss} {Functions} and the {Scoring} {Function} {Class}.},
	doi = {null},
	abstract = {A fundamental question in multiclass classification concerns understanding the consistency properties of surrogate risk minimization algorithms, which minimize a (often convex) surrogate to the multiclass 0-1 loss. In particular, the framework of calibrated surrogates has played an important role in analyzing Bayes consistency of such algorithms, i.e. in studying convergence to a Bayes optimal classifier (Zhang, 2004; Tewari and Bartlett, 2007). However, follow-up work has suggested this framework can be of limited value when studying H-consistency; in particular, concerns have been raised that even when the data comes from an underlying linear model, minimizing certain convex calibrated surrogates over linear scoring functions fails to recover the true model (Long and Servedio, 2013). In this paper, we investigate this apparent conundrum. We find that while some calibrated surrogates can indeed fail to provide H -consistency when minimized over a naturallooking but naively chosen scoring function class F , the situation can potentially be remedied by minimizing them over a more carefully chosen class of scoring functions F . In particular, for the popular one-vs-all hinge and logistic surrogates, both of which are calibrated (and therefore provide Bayes consistency) under realizable models, but were previously shown to pose problems for realizable H -consistency, we derive a form of scoring function class F that enables Hconsistency. When H is the class of linear models, the class F consists of certain piecewise linear scoring functions that are characterized by the same number of parameters as in the linear case, and minimization over which can be performed using an adaptation of the min-pooling idea from neural network training. Our experiments confirm that the one-vs-all surrogates, when trained over this class of nonlinear scoring functions F , yield better linear multiclass classifiers than when trained over standard linear scoring functions.},
	journal = {Neural Information Processing Systems},
	author = {Zhang, Mingyuan and Agarwal, Shivani},
	year = {2020},
	pmid = {34305367},
	pmcid = {null},
}

@misc{jung_algorithmic_2020,
	title = {An {Algorithmic} {Framework} for {Fairness} {Elicitation}},
	url = {http://arxiv.org/abs/1905.10660},
	doi = {10.48550/arXiv.1905.10660},
	abstract = {We consider settings in which the right notion of fairness is not captured by simple mathematical definitions (such as equality of error rates across groups), but might be more complex and nuanced and thus require elicitation from individual or collective stakeholders. We introduce a framework in which pairs of individuals can be identified as requiring (approximately) equal treatment under a learned model, or requiring ordered treatment such as "applicant Alice should be at least as likely to receive a loan as applicant Bob". We provide a provably convergent and oracle efficient algorithm for learning the most accurate model subject to the elicited fairness constraints, and prove generalization bounds for both accuracy and fairness. This algorithm can also combine the elicited constraints with traditional statistical fairness notions, thus "correcting" or modifying the latter by the former. We report preliminary findings of a behavioral study of our framework using human-subject fairness constraints elicited on the COMPAS criminal recidivism dataset.},
	urldate = {2024-11-19},
	publisher = {arXiv},
	author = {Jung, Christopher and Kearns, Michael and Neel, Seth and Roth, Aaron and Stapleton, Logan and Wu, Zhiwei Steven},
	month = oct,
	year = {2020},
	note = {arXiv:1905.10660},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{cousins_pool_2024,
	title = {To {Pool} or {Not} {To} {Pool}: {Analyzing} the {Regularizing} {Effects} of {Group}-{Fair} {Training} on {Shared} {Models}},
	shorttitle = {To {Pool} or {Not} {To} {Pool}},
	url = {http://arxiv.org/abs/2402.18803},
	abstract = {In fair machine learning, one source of performance disparities between groups is over-fitting to groups with relatively few training samples. We derive group-specific bounds on the generalization error of welfare-centric fair machine learning that benefit from the larger sample size of the majority group. We do this by considering group-specific Rademacher averages over a restricted hypothesis class, which contains the family of models likely to perform well with respect to a fair learning objective (e.g., a power-mean). Our simulations demonstrate these bounds improve over a naive method, as expected by theory, with particularly significant improvement for smaller group sizes.},
	urldate = {2024-11-11},
	publisher = {arXiv},
	author = {Cousins, Cyrus and Kumar, I. Elizabeth and Venkatasubramanian, Suresh},
	month = feb,
	year = {2024},
	note = {arXiv:2402.18803},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning},
}

@article{lee_understanding_2018,
	title = {Understanding perception of algorithmic decisions: {Fairness}, trust, and emotion in response to algorithmic management},
	volume = {5},
	issn = {2053-9517},
	shorttitle = {Understanding perception of algorithmic decisions},
	url = {https://doi.org/10.1177/2053951718756684},
	doi = {10.1177/2053951718756684},
	abstract = {Algorithms increasingly make managerial decisions that people used to make. Perceptions of algorithms, regardless of the algorithms' actual performance, can significantly influence their adoption, yet we do not fully understand how people perceive decisions made by algorithms as compared with decisions made by humans. To explore perceptions of algorithmic management, we conducted an online experiment using four managerial decisions that required either mechanical or human skills. We manipulated the decision-maker (algorithmic or human), and measured perceived fairness, trust, and emotional response. With the mechanical tasks, algorithmic and human-made decisions were perceived as equally fair and trustworthy and evoked similar emotions; however, human managers' fairness and trustworthiness were attributed to the manager's authority, whereas algorithms' fairness and trustworthiness were attributed to their perceived efficiency and objectivity. Human decisions evoked some positive emotion due to the possibility of social recognition, whereas algorithmic decisions generated a more mixed response – algorithms were seen as helpful tools but also possible tracking mechanisms. With the human tasks, algorithmic decisions were perceived as less fair and trustworthy and evoked more negative emotion than human decisions. Algorithms' perceived lack of intuition and subjective judgment capabilities contributed to the lower fairness and trustworthiness judgments. Positive emotion from human decisions was attributed to social recognition, while negative emotion from algorithmic decisions was attributed to the dehumanizing experience of being evaluated by machines. This work reveals people's lay concepts of algorithmic versus human decisions in a management context and suggests that task characteristics matter in understanding people's experiences with algorithmic technologies.},
	language = {en},
	number = {1},
	urldate = {2024-11-11},
	journal = {Big Data \& Society},
	author = {Lee, Min Kyung},
	month = jan,
	year = {2018},
	note = {Publisher: SAGE Publications Ltd},
	pages = {2053951718756684},
}

@inproceedings{grgic-hlaca_dimensions_2022,
	address = {New York, NY, USA},
	series = {{EAAMO} '22},
	title = {Dimensions of {Diversity} in {Human} {Perceptions} of {Algorithmic} {Fairness}},
	isbn = {978-1-4503-9477-2},
	url = {https://dl.acm.org/doi/10.1145/3551624.3555306},
	doi = {10.1145/3551624.3555306},
	abstract = {A growing number of oversight boards and regulatory bodies seek to monitor and govern algorithms that make decisions about people’s lives. Prior work has explored how people believe algorithmic decisions should be made, but there is little understanding of how individual factors like sociodemographics or direct experience with a decision-making scenario may affect their ethical views. We take a step toward filling this gap by exploring how people’s perceptions of one aspect of procedural algorithmic fairness (the fairness of using particular features in an algorithmic decision) relate to their (i) demographics (age, education, gender, race, political views) and (ii) personal experiences with the algorithmic decision-making scenario. We find that political views and personal experience with the algorithmic decision context significantly influence perceptions about the fairness of using different features for bail decision-making. Drawing on our results, we discuss the implications for stakeholder engagement and algorithmic oversight including the need to consider multiple dimensions of diversity in composing oversight and regulatory bodies.},
	urldate = {2024-11-11},
	booktitle = {Proceedings of the 2nd {ACM} {Conference} on {Equity} and {Access} in {Algorithms}, {Mechanisms}, and {Optimization}},
	publisher = {Association for Computing Machinery},
	author = {Grgić-Hlača, Nina and Lima, Gabriel and Weller, Adrian and Redmiles, Elissa M.},
	month = oct,
	year = {2022},
	pages = {1--12},
}

@inproceedings{poursabzi-sangdeh_manipulating_2021,
	address = {Yokohama Japan},
	title = {Manipulating and {Measuring} {Model} {Interpretability}},
	isbn = {978-1-4503-8096-6},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445315},
	doi = {10.1145/3411764.3445315},
	language = {en},
	urldate = {2024-11-11},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Poursabzi-Sangdeh, Forough and Goldstein, Daniel G and Hofman, Jake M and Wortman Vaughan, Jennifer Wortman and Wallach, Hanna},
	month = may,
	year = {2021},
	pages = {1--52},
}

@inproceedings{chan_artificial_2020,
	title = {Artificial {Artificial} {Intelligence}: {Measuring} {Influence} of {AI} '{Assessments}' on {Moral} {Decision}-{Making}},
	shorttitle = {Artificial {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/2001.09766},
	doi = {10.1145/3375627.3375870},
	abstract = {Given AI’s growing role in modeling and improving decision-making, how and when to present users with feedback is an urgent topic to address. We empirically examined the e ect of feedback from false AI on moral decision-making about donor kidney allocation. We found some evidence that judgments about whether a patient should receive a kidney can be in uenced by feedback about participants’ own decision-making perceived to be given by AI, even if the feedback is entirely random. We also discovered di erent e ects between assessments presented as being from human experts and assessments presented as being from AI.},
	language = {en},
	urldate = {2024-11-11},
	booktitle = {Proceedings of the {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	author = {Chan, Lok and Doyle, Kenzie and McElfresh, Duncan and Conitzer, Vincent and Dickerson, John P. and Borg, Jana Schaich and Sinnott-Armstrong, Walter},
	month = feb,
	year = {2020},
	note = {arXiv:2001.09766 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Human-Computer Interaction},
	pages = {214--220},
}

@article{aldous_assessing_2017,
	title = {{ON} {ASSESSING} {REAL} {WORLD} {PREDICTION} {SKILL}},
	language = {en},
	number = {20},
	author = {Aldous, David},
	year = {2017},
}

@misc{russo_bridging_2024,
	title = {Bridging {Research} and {Practice} {Through} {Conversation}: {Reflecting} on {Our} {Experience}},
	shorttitle = {Bridging {Research} and {Practice} {Through} {Conversation}},
	url = {http://arxiv.org/abs/2409.05880},
	doi = {10.1145/3689904.3694705},
	abstract = {While some research ﬁelds have a long history of collaborating with domain experts outside academia, many quantitative researchers do not have natural avenues to meet experts in areas where the research is later deployed. We explain how conversations—interviews without a speciﬁc research objective—can bridge research and practice. Using collaborative autoethnography, we reﬂect on our experience of conducting conversations with practitioners from a range of diﬀerent backgrounds, including refugee rights, conservation, addiction counseling, and municipal data science. Despite these varied backgrounds, common lessons emerged, including the importance of valuing the knowledge of experts, recognizing that academic research and practice have diﬀering objectives and timelines, understanding the limits of quantiﬁcation, and avoiding data extractivism. We consider the impact of these conversations on our work, the potential roles we can serve as researchers, and the challenges we anticipate as we move forward in these collaborations.},
	language = {en},
	urldate = {2024-10-02},
	author = {Russo, Mayra and Jorgensen, Mackenzie and Scott, Kristen M. and Xu, Wendy and Nguyen, Di H. and Finocchiaro, Jessie and Olckers, Matthew},
	month = sep,
	year = {2024},
	note = {arXiv:2409.05880 [cs]},
	keywords = {Computer Science - Human-Computer Interaction},
}

@article{mao_h-consistency_nodate,
	title = {H-{Consistency} {Bounds} for {Pairwise} {Misranking} {Loss} {Surrogates}},
	abstract = {We present a detailed study of H-consistency bounds for score-based ranking. These are upper bounds on the target loss estimation error of a predictor in a hypothesis set H, expressed in terms of the surrogate loss estimation error of that predictor. We will show that both in the general pairwise ranking scenario and in the bipartite ranking scenario, there are no meaningful H-consistency bounds for most hypothesis sets used in practice including the family of linear models and that of the neural networks, which satisfy the equicontinuous property with respect to the input. To come up with ranking surrogate losses with theoretical guarantees, we show that a natural solution consists of resorting to a pairwise abstention loss in the general pairwise ranking scenario, and similarly, a bipartite abstention loss in the bipartite ranking scenario, to abstain from making predictions at some limited cost c. For surrogate losses of these abstention loss functions, we give a series of H-consistency bounds for both the family of linear functions and that of neural networks with one hidden-layer. Our experimental results illustrate the effectiveness of ranking with abstention.},
	language = {en},
	author = {Mao, Anqi and Mohri, Mehryar and Zhong, Yutao},
}

@article{awasthi_calibration_nodate,
	title = {Calibration and {Consistency} of {Adversarial} {Surrogate} {Losses}},
	abstract = {Adversarial robustness is an increasingly critical property of classiﬁers in applications. The design of robust algorithms relies on surrogate losses since the optimization of the adversarial loss with most hypothesis sets is NP-hard. But, which surrogate losses should be used and when do they beneﬁt from theoretical guarantees? We present an extensive study of this question, including a detailed analysis of the H-calibration and H-consistency of adversarial surrogate losses. We show that convex loss functions, or the supremum-based convex losses often used in applications, are not H-calibrated for common hypothesis sets used in machine learning. We then give a characterization of H-calibration and prove that some surrogate losses are indeed H-calibrated for the adversarial zero-one loss, with common hypothesis sets. In particular, we ﬁx some calibration results presented in prior work for a family of linear models and signiﬁcantly generalize the results to the nonlinear hypothesis sets. Next, we show that H-calibration is not sufﬁcient to guarantee consistency and prove that, in the absence of any distributional assumption, no continuous surrogate loss is consistent in the adversarial setting. This, in particular, proves that a claim made in prior work is inaccurate. Next, we identify natural conditions under which some surrogate losses that we describe in detail are H-consistent. We also report a series of empirical results which show that many H-calibrated surrogate losses are indeed not H-consistent, and validate our theoretical assumptions. Our adversarial H-consistency results are novel, even for the case where H is the family of all measurable functions.},
	language = {en},
	author = {Awasthi, Pranjal and Frank, Natalie S and Mao, Anqi and Mohri, Mehryar and Zhong, Yutao},
}

@article{johnson-yu_modeling_2023,
	title = {Modeling {Robustness} in {Decision}-{Focused} {Learning} as a {Stackelberg} {Game}},
	abstract = {Predict-then-optimize is a common paradigm for optimization tasks situated in incomplete informational settings, in which an agent estimates missing parameters and then optimizes over these predicted parameters. One proposed improvement to this predict-thenoptimize framework is decision-focused learning, which establishes an end-to-end learning pipeline, allowing a predictive model to be tailored to the particular optimization task. The behavior of this predict-then-optimize framework in the presence of noise, however, is not well-understood. This is problematic because many data collection and annotation systems are inherently noisy, and the introduction of such noise could lead to poor downstream optimization. In this work, we aim to present results on robustness to label noise in decision-focused learning and traditional predictthen-optimize tasks using a Stackelberg game as the underlying framework of explanation. Our results suggest that playing the Stackelberg game in anticipation of label noise yields robustness in the predict-then-optimize framework at large, and that the optimal decision-focused learning Stackelberg solution continues to outperform the optimal traditional predict-then-optimize Stackelberg solution.},
	language = {en},
	author = {Johnson-Yu, Sonja},
	year = {2023},
}

@misc{kapoor_ai_2024,
	title = {{AI} {Agents} {That} {Matter}},
	url = {http://arxiv.org/abs/2407.01502},
	abstract = {AI agents are an exciting new research direction, and agent development is driven by benchmarks. Our analysis of current agent benchmarks and evaluation practices reveals several shortcomings that hinder their usefulness in real-world applications. First, there is a narrow focus on accuracy without attention to other metrics. As a result, SOTA agents are needlessly complex and costly, and the community has reached mistaken conclusions about the sources of accuracy gains. Our focus on cost in addition to accuracy motivates the new goal of jointly optimizing the two metrics. We design and implement one such optimization, showing its potential to greatly reduce cost while maintaining accuracy. Second, the benchmarking needs of model and downstream developers have been conflated, making it hard to identify which agent would be best suited for a particular application. Third, many agent benchmarks have inadequate holdout sets, and sometimes none at all. This has led to agents that are fragile because they take shortcuts and overfit to the benchmark in various ways. We prescribe a principled framework for avoiding overfitting. Finally, there is a lack of standardization in evaluation practices, leading to a pervasive lack of reproducibility. We hope that the steps we introduce for addressing these shortcomings will spur the development of agents that are useful in the real world and not just accurate on benchmarks.},
	language = {en},
	urldate = {2024-09-30},
	publisher = {arXiv},
	author = {Kapoor, Sayash and Stroebl, Benedikt and Siegel, Zachary S. and Nadgir, Nitya and Narayanan, Arvind},
	month = jul,
	year = {2024},
	note = {arXiv:2407.01502 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@inproceedings{globus-harris_multicalibration_2023,
	title = {Multicalibration as {Boosting} for {Regression}},
	url = {https://proceedings.mlr.press/v202/globus-harris23a.html},
	abstract = {We study the connection between multicalibration and boosting for squared error regression. First we prove a useful characterization of multicalibration in terms of a “swap regret” like condition on squared error. Using this characterization, we give an exceedingly simple algorithm that can be analyzed both as a boosting algorithm for regression and as a multicalibration algorithm for a class \${\textbackslash}mathcal\{H\}\$ that makes use only of a standard squared error regression oracle for \${\textbackslash}mathcal\{H\}\$. We give a weak learning assumption on \${\textbackslash}mathcal\{H\}\$ that ensures convergence to Bayes optimality without the need to make any realizability assumptions — giving us an agnostic boosting algorithm for regression. We then show that our weak learning assumption on \${\textbackslash}mathcal\{H\}\$ is both necessary and sufficient for multicalibration with respect to \${\textbackslash}mathcal\{H\}\$ to imply Bayes optimality, answering an open question. We also show that if \${\textbackslash}mathcal\{H\}\$ satisfies our weak learning condition relative to another class \${\textbackslash}mathcal\{C\}\$ then multicalibration with respect to \${\textbackslash}mathcal\{H\}\$ implies multicalibration with respect to \${\textbackslash}mathcal\{C\}\$. Finally we investigate the empirical performance of our algorithm experimentally.},
	language = {en},
	urldate = {2024-09-30},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Globus-Harris, Ira and Harrison, Declan and Kearns, Michael and Roth, Aaron and Sorrell, Jessica},
	month = jul,
	year = {2023},
	note = {ISSN: 2640-3498},
	pages = {11459--11492},
}

@misc{braham_calibration_nodate,
	title = {Calibration for {Decision} {Making}: {A} {Principled} {Approach} to {Trustworthy} {ML} – {The} {Learning} {Theory} {Alliance} {Blog}},
	shorttitle = {Calibration for {Decision} {Making}},
	url = {https://www.let-all.com/blog/2024/03/13/calibration-for-decision-making-a-principled-approach-to-trustworthy-ml/},
	language = {en-US},
	urldate = {2024-09-30},
	author = {{Braham}},
}

@article{sridharan_minimizing_nodate,
	title = {Minimizing {The} {Misclassification} {Error} {Rate}  {Using} a {Surrogate} {Convex} {Loss}},
	abstract = {We carefully study how well minimizing convex surrogate loss functions corresponds to minimizing the misclassiﬁcation error rate for the problem of binary classiﬁcation with linear predictors. We consider the agnostic setting, and investigate guarantees on the misclassiﬁcation error of the loss-minimizer in terms of the margin error rate of the best predictor. We show that, aiming for such a guarantee, the hinge loss is essentially optimal among all convex losses.},
	language = {en},
	author = {Sridharan, Karthik},
}

@misc{noauthor_characterizing_nodate,
	title = {Characterizing and {Improving} the {Robustness} of {Predict}-{Then}-{Optimize} {Frameworks} {\textbar} {SpringerLink}},
	url = {https://link.springer.com/chapter/10.1007/978-3-031-50670-3_7},
	urldate = {2024-09-23},
}

@article{zhang_statistical_2004,
	title = {Statistical behavior and consistency of classification methods based on convex risk minimization},
	volume = {32},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-32/issue-1/Statistical-behavior-and-consistency-of-classification-methods-based-on-convex/10.1214/aos/1079120130.full},
	doi = {10.1214/aos/1079120130},
	abstract = {We study how closely the optimal Bayes error rate can be approximately reached using a classification algorithm that computes a classifier by minimizing a convex upper bound of the classification error function. The measurement of closeness is characterized by the loss function used in the estimation. We show that such a classification scheme can be generally regarded as a (nonmaximum-likelihood) conditional in-class probability estimate, and we use this analysis to compare various convex loss functions that have appeared in the literature. Furthermore, the theoretical insight allows us to design good loss functions with desirable properties. Another aspect of our analysis is to demonstrate the consistency of certain classification methods using convex risk minimization. This study sheds light on the good performance of some recently proposed linear classification methods including boosting and support vector machines. It also shows their limitations and suggests possible improvements.},
	number = {1},
	urldate = {2024-09-18},
	journal = {The Annals of Statistics},
	author = {Zhang, Tong},
	month = feb,
	year = {2004},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62G05, 68T05, G2H30, boosting, consistency, kernel methods, large margin methods, ‎classification‎},
	pages = {56--85},
}

@article{bartlett_convexity_2006,
	title = {Convexity, {Classification}, and {Risk} {Bounds}},
	volume = {101},
	issn = {0162-1459},
	url = {https://doi.org/10.1198/016214505000000907},
	doi = {10.1198/016214505000000907},
	abstract = {Many of the classification algorithms developed in the machine learning literature, including the support vector machine and boosting, can be viewed as minimum contrast methods that minimize a convex surrogate of the 0–1 loss function. The convexity makes these algorithms computationally efficient. The use of a surrogate, however, has statistical consequences that must be balanced against the computational virtues of convexity. To study these issues, we provide a general quantitative relationship between the risk as assessed using the 0–1 loss and the risk as assessed using any nonnegative surrogate loss function. We show that this relationship gives nontrivial upper bounds on excess risk under the weakest possible condition on the loss function—that it satisfies a pointwise form of Fisher consistency for classification. The relationship is based on a simple variational transformation of the loss function that is easy to compute in many applications. We also present a refined version of this result in the case of low noise, and show that in this case, strictly convex loss functions lead to faster rates of convergence of the risk than would be implied by standard uniform convergence arguments. Finally, we present applications of our results to the estimation of convergence rates in function classes that are scaled convex hulls of a finite-dimensional base class, with a variety of commonly used loss functions.},
	number = {473},
	urldate = {2024-09-18},
	journal = {Journal of the American Statistical Association},
	author = {Bartlett, Peter L and Jordan, Michael I and McAuliffe, Jon D},
	month = mar,
	year = {2006},
	note = {Publisher: ASA Website
\_eprint: https://doi.org/10.1198/016214505000000907},
	keywords = {Boosting, Convex optimization, Empirical process theory, Machine learning, Rademacher complexity, Support vector machine},
	pages = {138--156},
}

@article{vercruysse_evaluating_nodate,
	title = {Evaluating {Current} {Swim} {Time} {Conversion} {Methods}},
	abstract = {This paper aims to evaluate current techniques of coverting race times between diﬀerent pool lengths. It then proposes a novel model to more accurately estimate conversion times, based oﬀ a weighted least squares linear regression that takes into account both age and gender.},
	language = {en},
	author = {Vercruysse, Alec},
}

@inproceedings{buolamwini_gender_2018,
	title = {Gender {Shades}: {Intersectional} {Accuracy} {Disparities} in {Commercial} {Gender} {Classification}},
	shorttitle = {Gender {Shades}},
	url = {https://proceedings.mlr.press/v81/buolamwini18a.html},
	abstract = {Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist  approved Fitzpatrick Skin Type classification system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We find that these datasets are overwhelmingly composed of lighter-skinned subjects (79.6\% for IJB-A and 86.2\% for Adience) and introduce a new facial analysis dataset which is balanced by gender and skin type. We evaluate 3 commercial gender classification systems using our dataset and show that darker-skinned females are the most misclassified group (with error rates of up to 34.7\%). The maximum error rate for lighter-skinned males is 0.8\%. The substantial disparities in the accuracy of classifying darker females, lighter females, darker males, and lighter males in gender classification systems require urgent attention if commercial companies are to build genuinely fair, transparent and accountable facial analysis algorithms.},
	language = {en},
	urldate = {2024-09-04},
	booktitle = {Proceedings of the 1st {Conference} on {Fairness}, {Accountability} and {Transparency}},
	publisher = {PMLR},
	author = {Buolamwini, Joy and Gebru, Timnit},
	month = jan,
	year = {2018},
	note = {The research paper detailing results of the Microsoft, Face++, and IBM gender classification softwares across different reported sexes and skin tones, which proposing a more representative benchmark PPB.},
	pages = {77--91},
}

@misc{noauthor_about_nodate,
	title = {About},
	url = {https://www.codedbias.com/about},
	language = {en-US},
	urldate = {2024-09-02},
	journal = {CODED BIAS},
	note = {Documentary featuring Buolamwini, Gebru, and Raji introducing the Gender Shades and Actionable Auditing projects, among many others.},
}

@misc{noauthor_algorithmic_nodate,
	title = {Algorithmic {Justice} {League} - {Unmasking} {AI} harms and biases},
	url = {https://www.ajl.org/},
	abstract = {Artificial intelligence can amplify racism, sexism, and other forms of discrimination. We deserve more accountable and equitable AI.},
	language = {en},
	urldate = {2024-09-02},
	note = {After graduating from MIT, Buolamwini went on to start the Algorithmic Justice League, which performs algorithmic audits and advocates for equitable policy change in tech.},
}

@misc{noauthor_dair_nodate,
	title = {{DAIR} ({Distributed} {AI} {Research} {Institute})},
	url = {https://www.dair-institute.org/},
	abstract = {The Distributed AI Research Institute is a space for independent, community-rooted AI research, free from Big Tech’s pervasive influence.},
	language = {en},
	urldate = {2024-09-02},
	note = {Distributed AI Research Institute, which was co-founded by Timnit Gebru (following a tumultuous departure from Google's AI ethics team)},
}

@misc{noauthor_matt_nodate,
	title = {Matt {Wood}},
	url = {https://alleninstitute.org/person/matt-wood/},
	abstract = {Matt is the VP of Artificial Intelligence at Amazon Web Services (AWS).},
	language = {en-US},
	urldate = {2024-09-02},
	journal = {Allen Institute},
	note = {Matt Wood's bio, who wrote Amazon's responses to the Actionable Auditing paper.},
}

@misc{roach_microsoft_2018,
	title = {Microsoft improves facial recognition to perform well across all skin tones},
	url = {https://blogs.microsoft.com/ai/gender-skin-tone-facial-recognition-improvement/},
	abstract = {Microsoft announces significant improvements to its facial recognition technology to more accurately predict gender across all skin tones.},
	language = {en-US},
	urldate = {2024-09-02},
	journal = {The AI Blog},
	author = {Roach, John},
	month = jun,
	year = {2018},
	note = {Microsoft blog outlining their response following the original Gender Shades paper.},
}

@misc{buolamwini_project_nodate,
	title = {Project {Overview} ‹ {Actionable} {Auditing}: {Coordinated} bias disclosure study},
	shorttitle = {Project {Overview} ‹ {Actionable} {Auditing}},
	url = {https://www.media.mit.edu/projects/actionable-auditing-coordinated-bias-disclosure-study/overview/},
	abstract = {Algorithmic auditing has emerged as a key strategy to expose systematic biases embedded in software platforms, yet scholarship on the impact of algorithmic aud…},
	urldate = {2024-09-04},
	journal = {MIT Media Lab},
	author = {Buolamwini, Joy},
	note = {MIT Media Lab article highlighting the results of the Actionable auditing paper},
}

@misc{buolamwini_response_2019,
	title = {Response: {Racial} and {Gender} bias in {Amazon} {Rekognition} — {Commercial} {AI} {System} for {Analyzing} {Faces}.},
	shorttitle = {Response},
	url = {https://medium.com/@Joy.Buolamwini/response-racial-and-gender-bias-in-amazon-rekognition-commercial-ai-system-for-analyzing-faces-a289222eeced},
	abstract = {In our recent study of bias in commercial facial analysis systems, Deborah Raji and I show Amazon Rekognition, an AI service the company…},
	language = {en},
	urldate = {2024-09-04},
	journal = {Medium},
	author = {Buolamwini, Joy},
	month = apr,
	year = {2019},
	note = {The response to the response to the audit, in which Buolamwini and Raji dispute Amazon's claims that Rekognition is performing well.},
}

@misc{wood_thoughts_2019,
	title = {Some {Thoughts} on {Facial} {Recognition} {Legislation} {\textbar} {AWS} {Machine} {Learning} {Blog}},
	url = {https://aws.amazon.com/blogs/machine-learning/some-thoughts-on-facial-recognition-legislation/},
	language = {en-US},
	urldate = {2024-09-04},
	author = {Wood, Matt},
	month = feb,
	year = {2019},
	note = {Amazon's response to the Actionable Auditing paper around the ethics of selling Rekognition to law enforcement, following Buolamwini's open letter calling on Amazon to stop selling Rekognition to law enforcement.},
}

@misc{wood_thoughts_2019-1,
	title = {Thoughts on {Recent} {Research} {Paper} and {Associated} {Article} on {Amazon} {Rekognition} {\textbar} {AWS} {Machine} {Learning} {Blog}},
	url = {https://aws.amazon.com/blogs/machine-learning/thoughts-on-recent-research-paper-and-associated-article-on-amazon-rekognition/},
	language = {en-US},
	urldate = {2024-09-04},
	author = {Wood, Matt},
	month = jan,
	year = {2019},
	note = {Amazon's response disputing the correctness of the results in the Actionable Auditing paper.},
}

@misc{buolamwini_recent_nodate,
	title = {On recent research auditing commercial facial analysis technology},
	url = {https://www.media.mit.edu/articles/on-recent-research-auditing-commercial-facial-analysis-technology/},
	abstract = {An open letter asking Amazon to stop selling Rekognition to law enforcement agencies.},
	urldate = {2024-09-04},
	journal = {MIT Media Lab},
	author = {Buolamwini, Joy},
	note = {This came after Raji and Buolamwini's Actionalble auditing paper, where they call for Amazon to stop selling Rekognition to law enforcement.},
}

@article{fissler_higher_2016,
	title = {Higher order elicitability and {Osband}'s principle},
	volume = {44},
	doi = {10.1214},
	number = {4},
	journal = {Annals of Statistics},
	author = {Fissler, Tobias and Ziegel, Joanna},
	year = {2016},
	pages = {1680--1707},
}

@article{yu_lovasz_2018,
	title = {The {Lovász} {Hinge}: {A} {Novel} {Convex} {Surrogate} for {Submodular} {Losses}},
	url = {https://ieeexplore.ieee.org/abstract/document/8543656?casa_token=cRo809t8-RcAAAAA:JIkBATppQvT6XGDvGPsESHxCSJi6ioQmVr6F5WRV7jrS1nIW-bi9mLO4O9YQC9tgGexS6aLm9A},
	urldate = {2024-09-03},
	journal = {IEEE Journal on Pattern Analysis and Machine Intelligence},
	author = {Yu, Jiaqian and Blaschko, Matthew},
	year = {2018},
}

@inproceedings{lapin_loss_2016,
	address = {Las Vegas, NV, USA},
	title = {Loss {Functions} for {Top}-k {Error}: {Analysis} and {Insights}},
	isbn = {978-1-4673-8851-1},
	shorttitle = {Loss {Functions} for {Top}-k {Error}},
	url = {http://ieeexplore.ieee.org/document/7780532/},
	doi = {10.1109/CVPR.2016.163},
	abstract = {In order to push the performance on realistic computer vision tasks, the number of classes in modern benchmark datasets has signiﬁcantly increased in recent years. This increase in the number of classes comes along with increased ambiguity between the class labels, raising the question if top-1 error is the right performance measure. In this paper, we provide an extensive comparison and evaluation of established multiclass methods comparing their top-k performance both from a practical as well as from a theoretical perspective. Moreover, we introduce novel top-k loss functions as modiﬁcations of the softmax and the multiclass SVM losses and provide efﬁcient optimization schemes for them. In the experiments, we compare on various datasets all of the proposed and established methods for top-k error optimization. An interesting insight of this paper is that the softmax loss yields competitive top-k performance for all k simultaneously. For a speciﬁc top-k error, our new topk losses lead typically to further improvements while being faster to train than the softmax.},
	language = {en},
	urldate = {2024-09-03},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Lapin, Maksim and Hein, Matthias and Schiele, Bernt},
	month = jun,
	year = {2016},
	pages = {1468--1477},
}

@inproceedings{lapin_top-k_2015,
	title = {Top-k {Multiclass} {SVM}},
	volume = {28},
	url = {https://proceedings.neurips.cc/paper_files/paper/2015/hash/0336dcbab05b9d5ad24f4333c7658a0e-Abstract.html},
	abstract = {Class ambiguity is typical in image classification problems with a large number of classes. When classes are difficult to discriminate, it makes sense to allow k guesses and evaluate classifiers based on the top-k error instead of the standard zero-one loss. We propose top-k multiclass SVM as a direct method to optimize for top-k performance. Our generalization of the well-known multiclass SVM is based on a tight convex upper bound of the top-k error. We propose a fast optimization scheme based on an efficient projection onto the top-k simplex, which is of its own interest. Experiments on five datasets show consistent improvements in top-k accuracy compared to various baselines.},
	urldate = {2024-09-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Lapin, Maksim and Hein, Matthias and Schiele, Bernt},
	year = {2015},
}

@inproceedings{garcia-garcia_divergences_2012,
	title = {Divergences and {Risks} for {Multiclass} {Experiments}},
	url = {https://proceedings.mlr.press/v23/garcia12.html},
	abstract = {Csiszár’s \$f\$-divergence is a way to measure the similarity of two probability distributions. We study the extension of \$f\$-divergence to more than two distributions to measure their joint similarity. By exploiting classical results from the comparison of experiments literature we prove the resulting divergence satisfies all the same properties as the traditional binary one. Considering the multidistribution case actually makes the proofs simpler. The key to these results is a formal bridge between these multidistribution \$f\$-divergences and Bayes risks for multiclass classification problems.},
	language = {en},
	urldate = {2024-09-03},
	booktitle = {Proceedings of the 25th {Annual} {Conference} on {Learning} {Theory}},
	publisher = {JMLR Workshop and Conference Proceedings},
	author = {García-García, Dario and Williamson, Robert C.},
	month = jun,
	year = {2012},
	note = {ISSN: 1938-7228},
	pages = {28.1--28.20},
}

@article{steinwart_elicitation_2014,
	title = {Elicitation and {Identiﬁcation} of {Properties}},
	abstract = {Properties of distributions are real-valued functionals such as the mean, quantile or conditional value at risk. A property is elicitable if there exists a scoring function such that minimization of the associated risks recovers the property. We extend existing results to characterize the elicitability of properties in a general setting. We further relate elicitability to identiﬁability (a notion introduced by Osband) and provide a general formula describing all scoring functions for an elicitable property. Finally, we draw some connections to the theory of coherent risk measures.},
	language = {en},
	journal = {Conference on Learning Theory},
	author = {Steinwart, Ingo and Pasin, Chloe and Williamson, Robert C and Zhang, Siyu},
	year = {2014},
}

@misc{ramaswamy_consistent_2016,
	title = {Consistent algorithms for multiclass classification with an abstain option},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-12/issue-1/Consistent-algorithms-for-multiclass-classification-with-an-abstain-option/10.1214/17-EJS1388.full},
	urldate = {2024-09-03},
	author = {Ramaswamy, Harish G. and Tewari, Ambuj and Agarwal, Shivani},
	year = {2016},
}

@article{ramaswamy_convex_2016,
	title = {Convex {Calibration} {Dimension} for {Multiclass} {Loss} {Matrices}},
	volume = {17},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v17/14-316.html},
	abstract = {We study consistency properties of surrogate loss functions for general multiclass learning problems, defined by a general multiclass loss matrix. We extend the notion of classification calibration, which has been studied for binary and multiclass 0-1 classification problems (and for certain other specific learning problems), to the general multiclass setting, and derive necessary and sufficient conditions for a surrogate loss to be calibrated with respect to a loss matrix in this setting. We then introduce the notion of convex calibration dimension of a multiclass loss matrix, which measures the smallest "size" of a prediction space in which it is possible to design a convex surrogate that is calibrated with respect to the loss matrix. We derive both upper and lower bounds on this quantity, and use these results to analyze various loss matrices. In particular, we apply our framework to study various subset ranking losses, and use the convex calibration dimension as a tool to show both the existence and non-existence of various types of convex calibrated surrogates for these losses. Our results strengthen recent results of Duchi et al. (2010) and CalauzÃ¨nes et al. (2012) on the non-existence of certain types of convex calibrated surrogates in subset ranking. We anticipate the convex calibration dimension may prove to be a useful tool in the study and design of surrogate losses for general multiclass learning problems.},
	number = {14},
	urldate = {2024-09-03},
	journal = {Journal of Machine Learning Research},
	author = {Ramaswamy, Harish G. and Agarwal, Shivani},
	year = {2016},
	pages = {1--45},
}

@inproceedings{finocchiaro_convex_2018,
	title = {Convex {Elicitation} of {Continuous} {Properties}},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper/2018/hash/e9510081ac30ffa83f10b68cde1cac07-Abstract.html},
	abstract = {A property or statistic of a distribution is said to be elicitable if it can be expressed as the minimizer of some loss function in expectation. Recent work shows that continuous real-valued properties are elicitable if and only if they are identifiable, meaning the set of distributions with the same property value can be described by linear constraints. From a practical standpoint, one may ask for which such properties do there exist convex loss functions. In this paper, in a finite-outcome setting, we show that in fact every elicitable real-valued property can be elicited by a convex loss function. Our proof is constructive, and leads to convex loss functions for new properties.},
	urldate = {2024-09-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Finocchiaro, Jessica and Frongillo, Rafael},
	year = {2018},
}

@inproceedings{abernethy_characterization_2012,
	title = {A {Characterization} of {Scoring} {Rules} for {Linear} {Properties}},
	url = {https://proceedings.mlr.press/v23/abernethy12.html},
	abstract = {We consider the design of proper scoring rules, equivalently proper losses, when the goal is to elicit some function, known as a property, of the underlying distribution. We provide a full characterization of the class of proper scoring rules when the property is linear as a function of the input distribution. A key conclusion is that any such scoring rule can be written in the form of a Bregman divergence for some convex function. We also apply our results to the design of prediction market mechanisms, showing a strong equivalence between scoring rules for linear properties and automated prediction market makers.},
	language = {en},
	urldate = {2024-09-03},
	booktitle = {Proceedings of the 25th {Annual} {Conference} on {Learning} {Theory}},
	publisher = {JMLR Workshop and Conference Proceedings},
	author = {Abernethy, Jacob D. and Frongillo, Rafael M.},
	month = jun,
	year = {2012},
	note = {ISSN: 1938-7228},
	pages = {27.1--27.13},
}

@inproceedings{frongillo_vector-valued_2015,
	title = {Vector-{Valued} {Property} {Elicitation}},
	url = {https://proceedings.mlr.press/v40/Frongillo15.html},
	abstract = {The elicitation of a statistic, or property of a distribution, is the task of devising proper scoring rules, equivalently proper losses, which incentivize an agent or algorithm to truthfully estimate the desired property of the underlying probability distribution or data set.  Leveraging connections between elicitation and convex analysis, we address the vector-valued property case, which has received little attention in the literature despite its applications to both machine learning and statistics. We first provide a very general characterization of linear and ratio-of-linear properties, the first of which resolves an open problem by unifying and strengthening several previous characterizations in machine learning and statistics.  We then ask which vectors of properties admit nonseparable scores, which cannot be expressed as a sum of scores for each coordinate separately, a natural desideratum for machine learning.  We show that linear and ratio-of-linear do admit nonseparable scores, and provide evidence for a conjecture that these are the only such properties (up to link functions). Finally, we give a general method for producing identification functions and address an open problem by showing that convex maximal level sets are insufficient for elicitability in general.},
	language = {en},
	urldate = {2024-09-03},
	booktitle = {Proceedings of {The} 28th {Conference} on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Frongillo, Rafael and Kash, Ian A.},
	month = jun,
	year = {2015},
	note = {ISSN: 1938-7228},
	pages = {710--727},
}

@article{lambert_elicitation_nodate,
	title = {Elicitation and {Evaluation} of {Statistical} {Forecasts}},
	abstract = {An expert has full or partial probabilistic information about a random state. The expert is asked to make a prediction regarding a property of the state distribution, that is, to answer a question about the distribution. The expert receives a payoﬀ that may depend on his own report and the subsequently realized state. For which properties can a payoﬀ rule be devised so as to induce the expert, as a strict best response, to answer the truth? In a ﬁnite world, the payoﬀ rules that provide strict incentives to the expert exist if and only if the property partitions the simplex of distributions into a power diagram. These payoﬀ rules can be fully characterized as weighted averages of elementary payoﬀ functions. They can be used both as an incentive device and to evaluate the performance of forecasters.},
	language = {en},
	author = {Lambert, Nicolas S},
}

@inproceedings{lambert_eliciting_2009,
	address = {New York, NY, USA},
	series = {{EC} '09},
	title = {Eliciting truthful answers to multiple-choice questions},
	isbn = {978-1-60558-458-4},
	url = {https://dl.acm.org/doi/10.1145/1566374.1566391},
	doi = {10.1145/1566374.1566391},
	abstract = {Motivated by the prevalence of online questionnaires in electronic commerce, and of multiple-choice questions in such questionnaires, we consider the problem of eliciting truthful answers to multiple-choice questions from a knowledgeable respondent. Specifically, each question is a statement regarding an uncertain future event, and is multiple-choice -- the responder must select exactly one of the given answers. The principal offers a payment, whose amount is a function of the answer selected and the true outcome (which the principal will eventually observe). This problem significantly generalizes recent work on truthful elicitation of distribution properties, which itself generalized a long line of work in elicitation of complete distributions. We provide necessary and sufficient conditions for the existence of payments that induce truthful answers, and give a characterization of those payments. We also study in greater details the common case of questions with ordinal answers, and illustrate our results with several examples of practical interest.},
	urldate = {2024-09-03},
	booktitle = {Proceedings of the 10th {ACM} conference on {Electronic} commerce},
	publisher = {Association for Computing Machinery},
	author = {Lambert, Nicolas and Shoham, Yoav},
	month = jul,
	year = {2009},
	pages = {109--118},
}

@inproceedings{lambert_eliciting_2008,
	address = {New York, NY, USA},
	series = {{EC} '08},
	title = {Eliciting properties of probability distributions},
	isbn = {978-1-60558-169-9},
	url = {https://dl.acm.org/doi/10.1145/1386790.1386813},
	doi = {10.1145/1386790.1386813},
	abstract = {We investigate the problem of truthfully eliciting an expert's assessment of a property of a probability distribution, where a property is any real-valued function of the distribution such as mean or variance. We show that not all properties are elicitable; for example, the mean is elicitable and the variance is not. For those that are elicitable, we provide a representation theorem characterizing all payment (or "score") functions that induce truthful revelation. We also consider the elicitation of sets of properties. We then observe that properties can always be inferred from sets of elicitable properties. This naturally suggests the concept of elicitation complexity; the elicitation complexity of property is the minimal size of such a set implying the property. Finally we discuss applications to prediction markets.},
	urldate = {2024-09-03},
	booktitle = {Proceedings of the 9th {ACM} conference on {Electronic} commerce},
	publisher = {Association for Computing Machinery},
	author = {Lambert, Nicolas S. and Pennock, David M. and Shoham, Yoav},
	month = jul,
	year = {2008},
	pages = {129--138},
}

@article{savage_elicitation_1971,
	title = {Elicitation of {Personal} {Probabilities} and {Expectations}},
	volume = {66},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2284229},
	doi = {10.2307/2284229},
	abstract = {Proper scoring rules, i.e., devices of a certain class for eliciting a person's probabilities and other expectations, are studied, mainly theoretically but with some speculations about application. The relation of proper scoring rules to other economic devices and to the foundations of the personalistic theory of probability is brought out. The implications of various restrictions, especially symmetry restrictions, on scoring rules is explored, usually with a minimum of regularity hypothesis.},
	number = {336},
	urldate = {2024-09-03},
	journal = {Journal of the American Statistical Association},
	author = {Savage, Leonard J.},
	year = {1971},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {783--801},
}

@misc{noauthor_elicitation_nodate,
	title = {Elicitation of {Personal} {Probabilities} and {Expectations} on {JSTOR}},
	url = {https://www.jstor.org/stable/2284229},
	urldate = {2024-09-03},
}

@inproceedings{finocchiaro_bridging_2021,
	address = {New York, NY, USA},
	series = {{FAccT} '21},
	title = {Bridging {Machine} {Learning} and {Mechanism} {Design} towards {Algorithmic} {Fairness}},
	isbn = {978-1-4503-8309-7},
	url = {https://doi.org/10.1145/3442188.3445912},
	doi = {10.1145/3442188.3445912},
	abstract = {Decision-making systems increasingly orchestrate our world: how to intervene on the algorithmic components to build fair and equitable systems is therefore a question of utmost importance; one that is substantially complicated by the context-dependent nature of fairness and discrimination. Modern decision-making systems that involve allocating resources or information to people (e.g., school choice, advertising) incorporate machine-learned predictions in their pipelines, raising concerns about potential strategic behavior or constrained allocation, concerns usually tackled in the context of mechanism design. Although both machine learning and mechanism design have developed frameworks for addressing issues of fairness and equity, in some complex decision-making systems, neither framework is individually sufficient. In this paper, we develop the position that building fair decision-making systems requires overcoming these limitations which, we argue, are inherent to each field. Our ultimate objective is to build an encompassing framework that cohesively bridges the individual frameworks of mechanism design and machine learning. We begin to lay the ground work towards this goal by comparing the perspective each discipline takes on fair decision-making, teasing out the lessons each field has taught and can teach the other, and highlighting application domains that require a strong collaboration between these disciplines.},
	urldate = {2024-08-19},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Finocchiaro, Jessie and Maio, Roland and Monachou, Faidra and Patro, Gourab K and Raghavan, Manish and Stoica, Ana-Andreea and Tsirtsis, Stratis},
	month = mar,
	year = {2021},
	pages = {489--503},
}

@inproceedings{finocchiaro_embedding_2020,
	title = {Embedding {Dimension} of {Polyhedral} {Losses}},
	url = {https://proceedings.mlr.press/v125/finocchiaro20a.html},
	abstract = {A common technique in supervised learning with discrete losses, such as 0-1 loss, is to optimize a convex surrogate loss over Rd, calibrated with respect to the original loss. In particular, recent work has investigated embedding the original predictions (e.g. labels) as points in Rd, showing an equivalence to using polyhedral surrogates. In this work, we study the notion of the embedding dimension of a given discrete loss: the minimum dimension d such that an embedding exists. We characterize d-embeddability for all d, with a particularly tight characterization for d=1 (embedding into the real line), and useful necessary conditions for d{\textgreater}1 in the form of a quadratic feasibility program. We illustrate our results with novel lower bounds for abstain loss.},
	language = {en},
	urldate = {2024-08-19},
	booktitle = {Proceedings of {Thirty} {Third} {Conference} on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Finocchiaro, Jessie and Frongillo, Rafael and Waggoner, Bo},
	month = jul,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {1558--1585},
}

@inproceedings{thilagar_consistent_2022,
	title = {Consistent {Polyhedral} {Surrogates} for {Top}-k {Classification} and {Variants}},
	url = {https://proceedings.mlr.press/v162/thilagar22a.html},
	abstract = {Top-𝑘kk classification is a generalization of multiclass classification used widely in information retrieval, image classification, and other extreme classification settings. Several hinge-like (piecewise-linear) surrogates have been proposed for the problem, yet all are either non-convex or inconsistent. For the proposed hinge-like surrogates that are convex (i.e., polyhedral), we apply the recent embedding framework of Finocchiaro et al. (2019; 2022) to determine the prediction problem for which the surrogate is consistent. These problems can all be interpreted as variants of top-𝑘kk classification, which may be better aligned with some applications. We leverage this analysis to derive constraints on the conditional label distributions under which these proposed surrogates become consistent for top-𝑘kk. It has been further suggested that every convex hinge-like surrogate must be inconsistent for top-𝑘kk. Yet, we use the same embedding framework to give the first consistent polyhedral surrogate for this problem.},
	language = {en},
	urldate = {2024-08-19},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Thilagar, Anish and Frongillo, Rafael and Finocchiaro, Jessica J. and Goodwill, Emma},
	month = jun,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {21329--21359},
}

@inproceedings{finocchiaro_using_2024,
	address = {Rio de Janeiro Brazil},
	title = {Using {Property} {Elicitation} to {Understand} the {Impacts} of {Fairness} {Regularizers}},
	isbn = {9798400704505},
	url = {https://dl.acm.org/doi/10.1145/3630106.3658540},
	doi = {10.1145/3630106.3658540},
	abstract = {Predictive algorithms are often trained by optimizing some loss function, to which regularization functions are added to impose a penalty for violating constraints. As expected, the addition of such regularization functions can change the minimizer of the objective. It is not well-understood which regularizers change the minimizer of the loss, and, when the minimizer does change, how it changes. We use property elicitation to take first steps towards understanding the joint relationship between the loss and regularization functions and the optimal decision for a given problem instance. In particular, we give a necessary and sufficient condition on loss and regularizer pairs for when a property changes with the addition of the regularizer, and examine some regularizers satisfying this condition standard in the fair machine learning literature. We empirically demonstrate how algorithmic decision-making changes as a function of both data distribution changes and hardness of the constraints.},
	language = {en},
	urldate = {2024-08-19},
	booktitle = {The 2024 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Finocchiaro, Jessie},
	month = jun,
	year = {2024},
	pages = {62--73},
}

@inproceedings{finocchiaro_unifying_2021,
	title = {Unifying lower bounds on prediction dimension of convex surrogates},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/b91a76b0b2fa7ce160212f53f3d2edba-Abstract.html},
	urldate = {2024-08-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Finocchiaro, Jessica and Frongillo, Rafael and Waggoner, Bo},
	year = {2021},
	pages = {22046--22057},
}

@inproceedings{noarov_statistical_2023,
	title = {The {Statistical} {Scope} of {Multicalibration}},
	url = {https://proceedings.mlr.press/v202/noarov23a.html},
	abstract = {We make a connection between multicalibration and property elicitation and show that (under mild technical conditions) it is possible to produce a multicalibrated predictor for a continuous scalar property \${\textbackslash}Gamma\$ if and only if \${\textbackslash}Gamma\$ is elicitable. On the negative side, we show that for non-elicitable continuous properties there exist simple data distributions on which even the true distributional predictor is not calibrated. On the positive side, for elicitable \${\textbackslash}Gamma\$, we give simple canonical algorithms for the batch and the online adversarial setting, that learn a \${\textbackslash}Gamma\$-multicalibrated predictor. This generalizes past work on multicalibrated means and quantiles, and in fact strengthens existing online quantile multicalibration results. To further counter-weigh our negative result, we show that if a property \${\textbackslash}Gamma{\textasciicircum}1\$ is not elicitable by itself, but is elicitable conditionally on another elicitable property \${\textbackslash}Gamma{\textasciicircum}0\$, then there is a canonical algorithm that jointly multicalibrates \${\textbackslash}Gamma{\textasciicircum}1\$ and \${\textbackslash}Gamma{\textasciicircum}0\$; this generalizes past work on mean-moment multicalibration. Finally, as applications of our theory, we provide novel algorithmic and impossibility results for fair (multicalibrated) risk assessment.},
	language = {en},
	urldate = {2024-08-19},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Noarov, Georgy and Roth, Aaron},
	month = jul,
	year = {2023},
	note = {ISSN: 2640-3498},
	pages = {26283--26310},
}

@misc{bureau_race_nodate,
	title = {Race and {Ethnicity} in the {United} {States}: 2010 {Census} and 2020 {Census}},
	shorttitle = {Race and {Ethnicity} in the {United} {States}},
	url = {https://www.census.gov/library/visualizations/interactive/race-and-ethnicity-in-the-united-state-2010-and-2020-census.html},
	abstract = {View how race and ethnicity have changed by state from the 2010 Census and 2020 Census.},
	urldate = {2024-08-19},
	journal = {Census.gov},
	author = {Bureau, US Census},
	note = {Section: Government},
	keywords = {examples},
}

@misc{noauthor_demographics_2024,
	title = {Demographics of the {United} {States}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Demographics_of_the_United_States&oldid=1241002981},
	abstract = {The United States had an official estimated resident population of 334,914,895 on July 1, 2023, according to the U.S. Census Bureau. This figure includes the 50 states and Washington, D.C. but excludes the population of five unincorporated U.S. territories (Puerto Rico, Guam, the U.S. Virgin Islands, American Samoa, and the Northern Mariana Islands) as well as several minor island possessions. The United States is the third most populous country in the world, and the most populous in the Americas and the Western Hemisphere. The Census Bureau showed a population increase of 0.4\% for the twelve-month period ending in July 2022, below the world average annual rate of 0.9\%. The total fertility rate in the United States estimated for 2022 is 1.665 children per woman, which is below the replacement fertility rate of approximately 2.1. By several metrics, including racial and ethnic background, religious affiliation, and percentage of rural and urban divide, Illinois is the most representative of the larger demography of the United States.
The U.S. population almost quadrupled during the 20th century – at a growth rate of about 1.3\% a year – from about 76 million in 1900 to 281 million in 2000. It is estimated to have reached the 200 million mark in 1967, and the 300 million mark on October 17, 2006. Foreign-born immigration caused the U.S. population to continue its rapid increase, with the foreign-born population doubling from almost 20 million in 1990 to over 45 million in 2015, representing one-third of the population increase. The U.S. population grew by 1.6 million from 2018 to 2019, with 38\% of growth from immigration. Population growth is fastest among minorities as a whole, and according to the Census Bureau's 2020 estimation, 50\% of U.S. children under the age of 18 are members of ethnic minority groups. 
As of 2020, white people numbered 235,411,507 or 71\% of the population, including people who identified as white in combination with another race. People who identified as white alone (including Hispanic whites) numbered 204,277,273 or 61.6\% of the population and Non-Latino whites made up 57.8\% of the country's population.
Latino Americans accounted for 51.1\% of the total national population growth between 2010 and 2020. The Hispanic or Latino population increased from 50.5 million in 2010 to 62.1 million in 2020: a 23\% increase and a numerical increase of more than 11.6 million. Immigrants and their U.S.-born descendants are expected to provide most of the U.S. population gains in the decades ahead.
Asian Americans are the fastest growing racial group in America, with a growth rate of 35\%. However, multi-racial Asian Americans are the fastest growing group in the country, with a growth rate of 55\%, reflecting the increase of mixed-race marriages in the United States.
As of 2022, births to White American mothers remain around 50\% of the US total, reflecting a decline of 3\% compared to 2021. In the same time period, births to Asian American and Hispanic women increased by 2\% and 6\%, respectively.
The 12 month ending general fertility rate increased from 56.6 to 57.0 in 2022 Q1 compared to 2021 Q4.},
	language = {en},
	urldate = {2024-08-19},
	journal = {Wikipedia},
	month = aug,
	year = {2024},
	note = {Page Version ID: 1241002981},
	keywords = {example},
}

@misc{shirali_participatory_2024,
	title = {Participatory {Objective} {Design} via {Preference} {Elicitation} {\textbar} {Proceedings} of the 2024 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	url = {https://dl.acm.org/doi/abs/10.1145/3630106.3658994},
	urldate = {2024-07-30},
	author = {Shirali, Ali and Finocchiaro, Jessie and Abebe, Rediet},
	month = jun,
	year = {2024},
}

@article{aurenhammer_power_1987,
	title = {Power {Diagrams}: {Properties}, {Algorithms} and {Applications}},
	volume = {16},
	issn = {0097-5397, 1095-7111},
	shorttitle = {Power {Diagrams}},
	url = {http://epubs.siam.org/doi/10.1137/0216006},
	doi = {10.1137/0216006},
	abstract = {The power pow (x, s) of a point x with respect to a sphere s in Euclidean d-space E d is given by d2(x, z) 2, where d denotes the Euclidean distance function, and z and are the center and the radius of s. The power diagram of a finite set S of spheres in E d is a cell complex that associates each s S with the convex domain \{x E d Ipow (x, s) {\textless} pow (x, t), for all S-\{s\}\}.},
	language = {en},
	number = {1},
	urldate = {2024-08-07},
	journal = {SIAM Journal on Computing},
	author = {Aurenhammer, F.},
	month = feb,
	year = {1987},
	pages = {78--96},
}

@article{fischbacher_are_2001,
	title = {Are people conditionally cooperative? {Evidence} from a public goods experiment},
	volume = {71},
	issn = {0165-1765},
	shorttitle = {Are people conditionally cooperative?},
	url = {https://www.sciencedirect.com/science/article/pii/S0165176501003949},
	doi = {10.1016/S0165-1765(01)00394-9},
	abstract = {We study the importance of conditional cooperation in a one-shot public goods game by using a variant of the strategy-method. We find that a third of the subjects can be classified as free riders, whereas 50\% are conditional cooperators.},
	number = {3},
	urldate = {2024-07-30},
	journal = {Economics Letters},
	author = {Fischbacher, Urs and Gächter, Simon and Fehr, Ernst},
	month = jun,
	year = {2001},
	keywords = {Conditional cooperation, Experiments, Free riding, Strategy-method, Voluntary contributions},
	pages = {397--404},
}

@article{fehr_cooperation_2000,
	title = {Cooperation and {Punishment} in {Public} {Goods} {Experiments}},
	volume = {90},
	issn = {0002-8282},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.90.4.980},
	doi = {10.1257/aer.90.4.980},
	language = {en},
	number = {4},
	urldate = {2024-07-30},
	journal = {American Economic Review},
	author = {Fehr, Ernst and Gächter, Simon},
	month = sep,
	year = {2000},
	keywords = {Public Goods},
	pages = {980--994},
}

@article{roy_experimental_2015,
	title = {An experimental analysis of the impact of campaign polls on electoral information seeking},
	volume = {40},
	issn = {0261-3794},
	url = {https://www.sciencedirect.com/science/article/pii/S0261379415001614},
	doi = {10.1016/j.electstud.2015.08.005},
	abstract = {The literature on poll effects has focused upon the impact polls have on election outcomes. To understand how polls affect information seeking more broadly, we examine the influence of campaign-period polls on the decision-making process. Based on an online voting experiment, we find that poll exposure affects information seeking, albeit under limited conditions, and that this effect is mediated according to voters' sophistication levels. Results also indicate that party-specific deliberation can also be influenced by poll standings; candidates from parties trailing in the polls receive less attention than the leading party, although this is also conditional upon the size of the lead. We then consider how these effects on the information calculus influence voting behavior, finding a bandwagon effect when a clear front-runner is depicted in the polls.},
	urldate = {2024-07-29},
	journal = {Electoral Studies},
	author = {Roy, Jason and Singh, Shane P. and Fournier, Patrick and Andrew, Blake},
	month = dec,
	year = {2015},
	keywords = {Election campaigns, Information search, Political sophistication, Poll effects, Vote decision process},
	pages = {146--157},
}

@article{gelman_why_1993,
	title = {Why {Are} {American} {Presidential} {Election} {Campaign} {Polls} {So} {Variable} {When} {Votes} {Are} {So} {Predictable}?},
	volume = {23},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {0007-1234, 1469-2112},
	url = {https://www.cambridge.org/core/product/identifier/S0007123400006682/type/journal_article},
	doi = {10.1017/S0007123400006682},
	abstract = {As most political scientists know, the outcome of the American presidential election can be predicted within a few percentage points (in the popular vote), based on information available months before the election. Thus, the general campaign for president seems irrelevant to the outcome (except in very close elections), despite all the media coverage of campaign strategy. However, it is also well known that the pre-election opinion polls can vary wildly over the campaign, and this variation is generally attributed to events in the campaign. How can campaign events affect people's opinions on whom they plan to vote for, and yet not affect the outcome of the election? For that matter, why do voters consistently increase their support for a candidate during his nominating convention, even though the conventions are almost entirely predictable events whose effects can be rationally forecast?
            In this exploratory study, we consider several intuitively appealing, but ultimately wrong, resolutions to this puzzle and discuss our current understanding of what causes opinion polls to fluctuate while reaching a predictable outcome. Our evidence is based on graphical presentation and analysis of over 67,000 individual-level responses from forty-nine commercial polls during the 1988 campaign and many other aggregate poll results from the 1952–92 campaigns.
            We show that responses to pollsters during the campaign are not generally informed or even, in a sense we describe, ‘rational’. In contrast, voters decide, based on their enlightened preferences, as formed by the information they have learned during the campaign, as well as basic political cues such as ideology and party identification, which candidate to support eventually. We cannot prove this conclusion, but we do show that it is consistent with the aggregate forecasts and individual-level opinion poll responses. Based on the enlightened preferences hypothesis, we conclude that the news media have an important effect on the outcome of presidential elections – not through misleading advertisements, sound bites, or spin doctors, but rather by conveying candidates' positions on important issues.},
	language = {en},
	number = {4},
	urldate = {2024-07-29},
	journal = {British Journal of Political Science},
	author = {Gelman, Andrew and King, Gary},
	month = oct,
	year = {1993},
	pages = {409--451},
}

@article{alonso_persuading_2016,
	title = {Persuading {Voters}},
	volume = {106},
	issn = {0002-8282},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.20140737},
	doi = {10.1257/aer.20140737},
	abstract = {In a symmetric information voting model, an individual (politician) can influence voters' choices by strategically designing a policy experiment (public signal). We characterize the politician's optimal experiment. With a nonunanimous voting rule, she exploits voters' heterogeneity by designing an experiment with realizations targeting different winning coalitions. Consequently, under a simple-majority rule, a majority of voters might be strictly worse off due to the politician's influence. We characterize voters' preferences over electoral rules and provide conditions for a majority of voters to prefer a supermajority (or unanimity) voting rule, in order to induce the politician to supply a more informative experiment. (JEL D72, D83)},
	language = {en},
	number = {11},
	urldate = {2024-07-29},
	journal = {American Economic Review},
	author = {Alonso, Ricardo and CÂmara, Odilon},
	month = nov,
	year = {2016},
	pages = {3590--3605},
}

@misc{blasiok_loss_2023,
	title = {Loss {Minimization} {Yields} {Multicalibration} for {Large} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2304.09424},
	abstract = {Multicalibration is a notion of fairness for predictors that requires them to provide calibrated predictions across a large set of protected groups. Multicalibration is known to be a distinct goal than loss minimization, even for simple predictors such as linear functions.},
	language = {en},
	urldate = {2024-06-11},
	publisher = {arXiv},
	author = {Błasiok, Jarosław and Gopalan, Parikshit and Hu, Lunjia and Kalai, Adam Tauman and Nakkiran, Preetum},
	month = dec,
	year = {2023},
	note = {arXiv:2304.09424 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{williamson_fairness_2019,
	title = {Fairness risk measures},
	url = {http://arxiv.org/abs/1901.08665},
	abstract = {Ensuring that classiﬁers are non-discriminatory or fair with respect to a sensitive feature (e.g., race or gender) is a topical problem. Progress in this task requires ﬁxing a deﬁnition of fairness, and there have been several proposals in this regard over the past few years. Several of these, however, assume either binary sensitive features (thus precluding categorical or real-valued sensitive groups), or result in non-convex objectives (thus adversely aﬀecting the optimisation landscape).},
	language = {en},
	urldate = {2024-06-06},
	publisher = {arXiv},
	author = {Williamson, Robert C. and Menon, Aditya Krishna},
	month = jan,
	year = {2019},
	note = {arXiv:1901.08665 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{agarwal_minimax_2022,
	title = {Minimax {Regret} {Optimization} for {Robust} {Machine} {Learning} under {Distribution} {Shift}},
	url = {http://arxiv.org/abs/2202.05436},
	abstract = {In this paper, we consider learning scenarios where the learned model is evaluated under an unknown test distribution which potentially differs from the training distribution (i.e. distribution shift). The learner has access to a family of weight functions such that the test distribution is a reweighting of the training distribution under one of these functions, a setting typically studied under the name of Distributionally Robust Optimization (DRO). We consider the problem of deriving regret bounds in the classical learning theory setting, and require that the resulting regret bounds hold uniformly for all potential test distributions. We show that the DRO formulation does not guarantee uniformly small regret under distribution shift. We instead propose an alternative method called Minimax Regret Optimization (MRO), and show that under suitable conditions this method achieves uniformly low regret across all test distributions. We also adapt our technique to have stronger guarantees when the test distributions are heterogeneous in their similarity to the training data. Given the widespead optimization of worst case risks in current approaches to robust machine learning, we believe that MRO can be a strong alternative to address distribution shift scenarios.},
	language = {en},
	urldate = {2024-06-06},
	publisher = {arXiv},
	author = {Agarwal, Alekh and Zhang, Tong},
	month = feb,
	year = {2022},
	note = {arXiv:2202.05436 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{dwork_outcome_2020,
	title = {Outcome {Indistinguishability}},
	url = {http://arxiv.org/abs/2011.13426},
	abstract = {Prediction algorithms assign numbers to individuals that are popularly understood as individual “probabilities”—what is the probability of 5-year survival after cancer diagnosis?—and which increasingly form the basis for life-altering decisions. Drawing on an understanding of computational indistinguishability developed in complexity theory and cryptography, we introduce Outcome Indistinguishability. Predictors that are Outcome Indistinguishable yield a generative model for outcomes that cannot be eﬃciently refuted on the basis of the real-life observations produced by Nature.},
	language = {en},
	urldate = {2024-05-30},
	publisher = {arXiv},
	author = {Dwork, Cynthia and Kim, Michael P. and Reingold, Omer and Rothblum, Guy N. and Yona, Gal},
	month = nov,
	year = {2020},
	note = {arXiv:2011.13426 [cs]},
	keywords = {Computer Science - Computational Complexity, Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, outcome indistingushability},
}

@misc{van_erven_fast_2015,
	title = {Fast rates in statistical and online learning},
	url = {http://arxiv.org/abs/1507.02592},
	abstract = {The speed with which a learning algorithm converges as it is presented with more data is a central problem in machine learning — a fast rate of convergence means less data is needed for the same level of performance. The pursuit of fast rates in online and statistical learning has led to the discovery of many conditions in learning theory under which fast learning is possible. We show that most of these conditions are special cases of a single, unifying condition, that comes in two forms: the central condition for ‘proper’ learning algorithms that always output a hypothesis in the given model, and stochastic mixability for online algorithms that may make predictions outside of the model. We show that under surprisingly weak assumptions both conditions are, in a certain sense, equivalent. The central condition has a re-interpretation in terms of convexity of a set of pseudoprobabilities, linking it to density estimation under misspeciﬁcation. For bounded losses, we show how the central condition enables a direct proof of fast rates and we prove its equivalence to the Bernstein condition, itself a generalization of the Tsybakov margin condition, both of which have played a central role in obtaining fast rates in statistical learning. Yet, while the Bernstein condition is two-sided, the central condition is one-sided, making it more suitable to deal with unbounded losses. In its stochastic mixability form, our condition generalizes both a stochastic exp-concavity condition identiﬁed by Juditsky, Rigollet and Tsybakov and Vovk’s notion of mixability. Our unifying conditions thus provide a substantial step towards a characterization of fast rates in statistical learning, similar to how classical mixability characterizes constant regret in the sequential prediction with expert advice setting.},
	language = {en},
	urldate = {2024-05-14},
	publisher = {arXiv},
	author = {van Erven, Tim and Grünwald, Peter D. and Mehta, Nishant A. and Reid, Mark D. and Williamson, Robert C.},
	month = sep,
	year = {2015},
	note = {arXiv:1507.02592 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{williamson_geometry_nodate,
	title = {The {Geometry} and {Calculus} of {Losses}},
	abstract = {Statistical decision problems lie at the heart of statistical machine learning. The simplest problems are multiclass classification and class probability estimation. Central to their definition is the choice of loss function, which is the means by which the quality of a solution is evaluated. In this paper we systematically develop the theory of loss functions for such problems from a novel perspective whose basic ingredients are convex sets with a particular structure. The loss function is defined as the subgradient of the support function of the convex set. It is consequently automatically proper (calibrated for probability estimation). This perspective provides three novel opportunities. It enables the development of a fundamental relationship between losses and (anti)-norms that appears to have not been noticed before. Second, it enables the development of a calculus of losses induced by the calculus of convex sets which allows the interpolation between different losses, and thus is a potential useful design tool for tailoring losses to particular problems. In doing this we build upon, and considerably extend, existing results on M-sums of convex sets. Third, the perspective leads to a natural theory of “polar” loss functions, which are derived from the polar dual of the convex set defining the loss, and which form a natural universal substitution function for Vovk’s aggregating algorithm.},
	language = {en},
	author = {Williamson, Robert C and Williamson, Bob and De, Uni-Tuebingen},
}

@misc{williamson_geometry_2023,
	title = {The {Geometry} and {Calculus} of {Losses}},
	url = {http://arxiv.org/abs/2209.00238},
	abstract = {Statistical decision problems lie at the heart of statistical machine learning. The simplest problems are binary and multiclass classification and class probability estimation. Central to their definition is the choice of loss function, which is the means by which the quality of a solution is evaluated. In this paper we systematically develop the theory of loss functions for such problems from a novel perspective whose basic ingredients are convex sets with a particular structure. The loss function is defined as the subgradient of the support function of the convex set. It is consequently automatically proper (calibrated for probability estimation). This perspective provides three novel opportunities. It enables the development of a fundamental relationship between losses and (anti)-norms that appears to have not been noticed before. Second, it enables the development of a calculus of losses induced by the calculus of convex sets which allows the interpolation between different losses, and thus is a potential useful design tool for tailoring losses to particular problems. In doing this we build upon, and considerably extend, existing results on M-sums of convex sets. Third, the perspective leads to a natural theory of “polar” loss functions, which are derived from the polar dual of the convex set defining the loss, and which form a natural universal substitution function for Vovk’s aggregating algorithm.},
	language = {en},
	urldate = {2024-05-07},
	publisher = {arXiv},
	author = {Williamson, Robert C. and Cranko, Zac},
	month = aug,
	year = {2023},
	note = {arXiv:2209.00238 [cs, math, stat]},
	keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hey_noise_2009,
	title = {Noise and bias in eliciting preferences},
	volume = {39},
	issn = {1573-0476},
	url = {https://doi.org/10.1007/s11166-009-9081-1},
	doi = {10.1007/s11166-009-9081-1},
	abstract = {In the context of eliciting preferences for decision making under risk, we analyse the features of four different elicitation methods—pairwise choice, willingness-to-pay, willingness-to-accept, and the Becker-DeGroot-Marschak mechanism—and estimate noise, bias and risk attitudes for two different preference functionals, Expected Utility and Rank-Dependent Expected Utility. It is well-known that methods differ in terms of the bias in the elicitation; it is rather less well-known that methods differ in terms of their noisiness. It has also been reported that risk attitudes are not stable across different elicitation methods. Our results suggest that elicited preferences should only be used in the context in which they were elicited, and the bias in the certainty-equivalent methods should be kept in mind when making predictions based on the elicited preferences. Moreover, conclusions should be moderated to take into account the various methods’ noise, which is generally lowest in the case of pairwise choice.},
	language = {en},
	number = {3},
	urldate = {2024-05-06},
	journal = {Journal of Risk and Uncertainty},
	author = {Hey, John D. and Morone, Andrea and Schmidt, Ulrich},
	month = dec,
	year = {2009},
	keywords = {BDM mechanism, Biases, C81, C91, Errors, JEL classifications, Noise, Pairwise choice, Willingness-to-accept, Willingness-to-pay, threshold elicitation},
	pages = {213--235},
}

@article{reid_information_nodate,
	title = {Information, {Divergence} and {Risk} for {Binary} {Experiments}},
	abstract = {We unify f -divergences, Bregman divergences, surrogate regret bounds, proper scoring rules, cost curves, ROC-curves and statistical information. We do this by systematically studying integral and variational representations of these objects and in so doing identify their representation primitives which all are related to cost-sensitive binary classiﬁcation. As well as developing relationships between generative and discriminative views of learning, the new machinery leads to tight and more general surrogate regret bounds and generalised Pinsker inequalities relating f -divergences to variational divergence. The new viewpoint also illuminates existing algorithms: it provides a new derivation of Support Vector Machines in terms of divergences and relates maximum mean discrepancy to Fisher linear discriminants.},
	language = {en},
	author = {Reid, Mark D and Williamson, Robert C and Reid, Mark and Williamson, Bob},
}

@article{schervish_general_1989,
	title = {A {General} {Method} for {Comparing} {Probability} {Assessors}},
	volume = {17},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-17/issue-4/A-General-Method-for-Comparing-Probability-Assessors/10.1214/aos/1176347398.full},
	doi = {10.1214/aos/1176347398},
	abstract = {A probability assessor or forecaster is a person who assigns subjective probabilities to events which will eventually occur or not occur. There are two purposes for which one might wish to compare two forecasters. The first is to see who has given better forecasts in the past. The second is to decide who will give better forecasts in the future. A method of comparison suitable for the first purpose may not be suitable for the second and vice versa. A criterion called calibration has been suggested for comparing the forecasts of different forecasters. Calibration, in a frequency sense, is a function of long run (future) properties of forecasts and hence is not suitable for making comparisons in the present. A method for comparing forecasters based on past performance is the use of scoring rules. In this paper a general method for comparing forecasters after a finite number of trials is introduced. The general method is proven to include calculating all proper scoring rules as special cases. It also includes comparison of forecasters in all simple two-decision problems as special cases. The relationship between the general method and calibration is also explored. The general method is also translated into a method for deciding who will give better forecasts in the future. An example is given using weather forecasts.},
	number = {4},
	urldate = {2024-05-02},
	journal = {The Annals of Statistics},
	author = {Schervish, Mark J.},
	month = dec,
	year = {1989},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62B15, 62C10, Calibration, dominance, forecasters, loss functions, refinement, scoring rules, sufficiency},
	pages = {1856--1879},
}

@misc{carriero_harms_2024,
	title = {The harms of class imbalance corrections for machine learning based prediction models: a simulation study},
	shorttitle = {The harms of class imbalance corrections for machine learning based prediction models},
	url = {http://arxiv.org/abs/2404.19494},
	abstract = {Risk prediction models are increasingly used in healthcare to aid in clinical decision making. In most clinical contexts, model calibration (i.e., assessing the reliability of risk estimates) is critical. Data available for model development are often not perfectly balanced with respect to the modeled outcome (i.e., individuals with vs. without the event of interest are not equally represented in the data). It is common for researchers to correct this class imbalance, yet, the effect of such imbalance corrections on the calibration of machine learning models is largely unknown. We studied the effect of imbalance corrections on model calibration for a variety of machine learning algorithms. Using extensive Monte Carlo simulations we compared the out-of-sample predictive performance of models developed with an imbalance correction to those developed without a correction for class imbalance across different data-generating scenarios (varying sample size, the number of predictors and event fraction). Our findings were illustrated in a case study using MIMIC-III data. In all simulation scenarios, prediction models developed without a correction for class imbalance consistently had equal or better calibration performance than prediction models developed with a correction for class imbalance. The miscalibration introduced by correcting for class imbalance was characterized by an over-estimation of risk and was not always able to be corrected with re-calibration. Correcting for class imbalance is not always necessary and may even be harmful for clinical prediction models which aim to produce reliable risk estimates on an individual basis.},
	language = {en},
	urldate = {2024-05-02},
	publisher = {arXiv},
	author = {Carriero, Alex and Luijken, Kim and de Hond, Anne and Moons, Karel GM and van Calster, Ben and van Smeden, Maarten},
	month = apr,
	year = {2024},
	note = {arXiv:2404.19494 [stat]},
	keywords = {Statistics - Methodology, cost-sensitive},
}

@misc{attias_information_2024,
	title = {Information {Complexity} of {Stochastic} {Convex} {Optimization}: {Applications} to {Generalization} and {Memorization}},
	shorttitle = {Information {Complexity} of {Stochastic} {Convex} {Optimization}},
	url = {http://arxiv.org/abs/2402.09327},
	doi = {10.48550/arXiv.2402.09327},
	abstract = {In this work, we investigate the interplay between memorization and learning in the context of {\textbackslash}emph\{stochastic convex optimization\} (SCO). We define memorization via the information a learning algorithm reveals about its training data points. We then quantify this information using the framework of conditional mutual information (CMI) proposed by Steinke and Zakynthinou (2020). Our main result is a precise characterization of the tradeoff between the accuracy of a learning algorithm and its CMI, answering an open question posed by Livni (2023). We show that, in the \$L{\textasciicircum}2\$ Lipschitz--bounded setting and under strong convexity, every learner with an excess error \${\textbackslash}varepsilon\$ has CMI bounded below by \${\textbackslash}Omega(1/{\textbackslash}varepsilon{\textasciicircum}2)\$ and \${\textbackslash}Omega(1/{\textbackslash}varepsilon)\$, respectively. We further demonstrate the essential role of memorization in learning problems in SCO by designing an adversary capable of accurately identifying a significant fraction of the training samples in specific SCO problems. Finally, we enumerate several implications of our results, such as a limitation of generalization bounds based on CMI and the incompressibility of samples in SCO problems.},
	urldate = {2024-05-01},
	publisher = {arXiv},
	author = {Attias, Idan and Dziugaite, Gintare Karolina and Haghifam, Mahdi and Livni, Roi and Roy, Daniel M.},
	month = feb,
	year = {2024},
	note = {arXiv:2402.09327 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{hu_predict_2024,
	title = {Predict to {Minimize} {Swap} {Regret} for {All} {Payoff}-{Bounded} {Tasks}},
	url = {http://arxiv.org/abs/2404.13503},
	abstract = {A sequence of predictions is calibrated if and only if it induces no swap regret to all downstream decision tasks. We study the Maximum Swap Regret (MSR) of predictions for binary events: the swap regret maximized over all downstream tasks with bounded payoffs. Previously, the best online prediction algorithm for minimizing MSR is obtained by minimizing the K1 calibration error, which upper bounds MSR up to a constant factor. However, recent work (Qiao and Valiant, 2021) gives an Ω(T 0.528) lower bound for the worst-case expected K1 calibration error incurred by any randomized algorithm in T rounds, presenting a barrier to achieving better rates for MSR. Several relaxations of MSR have been considered to overcome this barrier, via external regret (Kleinberg et al., 2023) and regret bounds depending polynomially on the number of actions in downstream tasks (Noarov et al., 2023; Roth and Shi, 2024). We show that the barrier can be surpassed with√out any relaxations: we give an efficient randomized prediction algorithm that guarantees O( T log T ) expected MSR. We also discuss the economic utility of calibration by viewing MSR as a decision-theoretic calibration error metric and study its relationship to existing metrics.},
	language = {en},
	urldate = {2024-04-25},
	publisher = {arXiv},
	author = {Hu, Lunjia and Wu, Yifan},
	month = apr,
	year = {2024},
	note = {arXiv:2404.13503 [cs, stat]},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{frongillo_surrogate_2021,
	title = {Surrogate {Regret} {Bounds} for {Polyhedral} {Losses}},
	url = {http://arxiv.org/abs/2110.14031},
	abstract = {Surrogate risk minimization is an ubiquitous paradigm in supervised machine learning, wherein a target problem is solved by minimizing a surrogate loss on a dataset. Surrogate regret bounds, also called excess risk bounds, are a common tool to prove generalization rates for surrogate risk minimization. While surrogate regret bounds have been developed for certain classes of loss functions, such as proper losses, general results are relatively sparse. We provide two general results. The first gives a linear surrogate regret bound for any polyhedral (piecewise-linear and convex) surrogate, meaning that surrogate generalization rates translate directly to target rates. The second shows that for sufficiently non-polyhedral surrogates, the regret bound is a square root, meaning fast surrogate generalization rates translate to slow rates for the target. Together, these results suggest polyhedral surrogates are optimal in many cases.},
	urldate = {2024-04-25},
	publisher = {arXiv},
	author = {Frongillo, Rafael and Waggoner, Bo},
	month = oct,
	year = {2021},
	note = {arXiv:2110.14031 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{anscombe_definition_1963,
	title = {A {Definition} of {Subjective} {Probability}},
	volume = {34},
	issn = {0003-4851, 2168-8990},
	url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-34/issue-1/A-Definition-of-Subjective-Probability/10.1214/aoms/1177704255.full},
	doi = {10.1214/aoms/1177704255},
	abstract = {The Annals of Mathematical Statistics},
	number = {1},
	urldate = {2024-04-23},
	journal = {The Annals of Mathematical Statistics},
	author = {Anscombe, F. J. and Aumann, R. J.},
	month = mar,
	year = {1963},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {axioms, elicitation},
	pages = {199--205},
}

@misc{chambers_recovering_2020,
	title = {Recovering {Preferences} from {Finite} {Data}},
	url = {http://arxiv.org/abs/1909.05457},
	abstract = {We study preferences estimated from finite choice experiments and provide sufficient conditions for convergence to a unique underlying "true" preference. Our conditions are weak, and therefore valid in a wide range of economic environments. We develop applications to expected utility theory, choice over consumption bundles, menu choice and intertemporal consumption. Our framework unifies the revealed preference tradition with models that allow for errors.},
	urldate = {2024-04-23},
	publisher = {arXiv},
	author = {Chambers, Christopher P. and Echenique, Federico and Lambert, Nicolas},
	month = oct,
	year = {2020},
	note = {arXiv:1909.05457 [econ]},
	keywords = {Economics - Econometrics, Economics - Theoretical Economics, elicitation},
}

@article{chambers_proper_2019,
	title = {Proper scoring rules with general preferences: {A} dual characterization of optimal reports},
	volume = {117},
	issn = {08998256},
	shorttitle = {Proper scoring rules with general preferences},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0899825619301101},
	doi = {10.1016/j.geb.2019.07.012},
	language = {en},
	urldate = {2024-04-23},
	journal = {Games and Economic Behavior},
	author = {Chambers, Christopher P. and Healy, Paul J. and Lambert, Nicolas S.},
	month = sep,
	year = {2019},
	keywords = {elicitation},
	pages = {322--341},
}

@misc{chambers_recovering_2023,
	title = {Recovering utility},
	url = {http://arxiv.org/abs/2301.11492},
	abstract = {We provide sufficient conditions under which a utility function may be recovered from a finite choice experiment. Identification, as is commonly understood in decision theory, is not enough. We provide a general recoverability result that is widely applicable to modern theories of choice under uncertainty. Key is to allow for a monetary environment, in which an objective notion of monotonicity is meaningful. In such environments, we show that subjective expected utility, as well as variational preferences, and other parametrizations of utilities over uncertain acts are recoverable. We also consider utility recovery in a statistical model with noise and random deviations from utility maximization.},
	urldate = {2024-04-23},
	publisher = {arXiv},
	author = {Chambers, Christopher P. and Echenique, Federico and Lambert, Nicolas S.},
	month = jan,
	year = {2023},
	note = {arXiv:2301.11492 [econ]},
	keywords = {Economics - Theoretical Economics, elicitation},
}

@misc{garg_oracle_2023,
	title = {Oracle {Efficient} {Online} {Multicalibration} and {Omniprediction}},
	url = {http://arxiv.org/abs/2307.08999},
	doi = {10.48550/arXiv.2307.08999},
	abstract = {A recent line of work has shown a surprising connection between multicalibration, a multi-group fairness notion, and omniprediction, a learning paradigm that provides simultaneous loss minimization guarantees for a large family of loss functions. Prior work studies omniprediction in the batch setting. We initiate the study of omniprediction in the online adversarial setting. Although there exist algorithms for obtaining notions of multicalibration in the online adversarial setting, unlike batch algorithms, they work only for small finite classes of benchmark functions \$F\$, because they require enumerating every function \$f {\textbackslash}in F\$ at every round. In contrast, omniprediction is most interesting for learning theoretic hypothesis classes \$F\$, which are generally continuously large. We develop a new online multicalibration algorithm that is well defined for infinite benchmark classes \$F\$, and is oracle efficient (i.e. for any class \$F\$, the algorithm has the form of an efficient reduction to a no-regret learning algorithm for \$F\$). The result is the first efficient online omnipredictor -- an oracle efficient prediction algorithm that can be used to simultaneously obtain no regret guarantees to all Lipschitz convex loss functions. For the class \$F\$ of linear functions, we show how to make our algorithm efficient in the worst case. Also, we show upper and lower bounds on the extent to which our rates can be improved: our oracle efficient algorithm actually promises a stronger guarantee called swap-omniprediction, and we prove a lower bound showing that obtaining \$O({\textbackslash}sqrt\{T\})\$ bounds for swap-omniprediction is impossible in the online setting. On the other hand, we give a (non-oracle efficient) algorithm which can obtain the optimal \$O({\textbackslash}sqrt\{T\})\$ omniprediction bounds without going through multicalibration, giving an information theoretic separation between these two solution concepts.},
	urldate = {2024-04-23},
	publisher = {arXiv},
	author = {Garg, Sumegha and Jung, Christopher and Reingold, Omer and Roth, Aaron},
	month = jul,
	year = {2023},
	note = {arXiv:2307.08999 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, omniprediction},
}

@inproceedings{feffer_preference_2023,
	address = {Montr{\textbackslash}'\{e\}al QC Canada},
	title = {From {Preference} {Elicitation} to {Participatory} {ML}: {A} {Critical} {Survey} \& {Guidelines} for {Future} {Research}},
	isbn = {9798400702310},
	shorttitle = {From {Preference} {Elicitation} to {Participatory} {ML}},
	url = {https://dl.acm.org/doi/10.1145/3600211.3604661},
	doi = {10.1145/3600211.3604661},
	language = {en},
	urldate = {2024-04-23},
	booktitle = {Proceedings of the 2023 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Feffer, Michael and Skirpan, Michael and Lipton, Zachary and Heidari, Hoda},
	month = aug,
	year = {2023},
	pages = {38--48},
}

@article{scott_calibrated_2012,
	title = {Calibrated asymmetric surrogate losses},
	doi = {10.1214/12-ejs699},
	abstract = {Surrogate losses underlie numerous state-of-the-art binary classification algorithms, such as support vector machines and boosting. The impact of a surrogate loss on the statistical performance of an algorithm is well-understood in symmetric classification settings, where the misclassification costs are equal and the loss is a margin loss. In particular, classification-calibrated losses are known to imply desirable properties such as consistency. While numerous efforts have been made to extend surrogate loss-based algorithms to asymmetric settings, to deal with unequal misclassification costs or training data imbalance, considerably less attention has been paid to whether the modified loss is still calibrated in some sense. This article extends the theory of classification-calibrated losses to asymmetric problems. As in the symmetric case, it is shown that calibrated asymmetric surrogate losses give rise to excess risk bounds, which control the expected misclassification cost in terms of the excess surrogate risk. This theory is illustrated on the class of uneven margin losses, and the uneven hinge, squared error, exponential, and sigmoid losses are treated in detail.},
	journal = {Electronic Journal of Statistics},
	author = {Scott, Clayton},
	year = {2012},
	pmid = {null},
	pmcid = {null},
}

@article{wang_unified_2023,
	title = {Unified {Binary} and {Multiclass} {Margin}-{Based} {Classification}},
	doi = {10.48550/arxiv.2311.17778},
	abstract = {The notion of margin loss has been central to the development and analysis of algorithms for binary classification. To date, however, there remains no consensus as to the analogue of the margin loss for multiclass classification. In this work, we show that a broad range of multiclass loss functions, including many popular ones, can be expressed in the relative margin form, a generalization of the margin form of binary losses. The relative margin form is broadly useful for understanding and analyzing multiclass losses as shown by our prior work (Wang and Scott, 2020, 2021). To further demonstrate the utility of this way of expressing multiclass losses, we use it to extend the seminal result of Bartlett et al. (2006) on classification-calibration of binary margin losses to multiclass. We then analyze the class of Fenchel-Young losses, and expand the set of these losses that are known to be classification-calibrated.},
	journal = {arXiv.org},
	author = {Wang, Yutong and Scott, Clayton},
	year = {2023},
	pmid = {null},
	pmcid = {null},
}

@article{mahdavi_binary_2014,
	title = {Binary {Excess} {Risk} for {Smooth} {Convex} {Surrogates}.},
	doi = {null},
	abstract = {In statistical learning theory, convex surrogates of the 0-1 loss are highly preferred because of the computational and theoretical virtues that convexity brings in. This is of more importance if we consider smooth surrogates as witnessed by the fact that the smoothness is further beneficial both computationally- by attaining an ıt optimal convergence rate for optimization, and in a statistical sense- by providing an improved ıt optimistic rate for generalization bound. In this paper we investigate the smoothness property from the viewpoint of statistical consistency and show how it affects the binary excess risk. We show that in contrast to optimization and generalization errors that favor the choice of smooth surrogate loss, the smoothness of loss function may degrade the binary excess risk. Motivated by this negative result, we provide a unified analysis that integrates optimization error, generalization bound, and the error in translating convex excess risk into a binary excess risk when examining the impact of smoothness on the binary excess risk. We show that under favorable conditions appropriate choice of smooth convex loss will result in a binary excess risk that is better than O(1/{\textbackslash}sqrtn).},
	journal = {arXiv: Learning},
	author = {Mahdavi, Mehrdad and Mahdavi, Mehrdad and Zhang, Lijun and Zhang, Lijun and Zhang, Lijun and Zhang, Lijun and Jin, Rong and Jin, Rong},
	year = {2014},
	pmid = {null},
	pmcid = {null},
}

@article{frongillo_surrogate_2021-1,
	title = {Surrogate {Regret} {Bounds} for {Polyhedral} {Losses}},
	doi = {null},
	abstract = {Surrogate risk minimization is an ubiquitous paradigm in supervised machine learning, wherein a target problem is solved by minimizing a surrogate loss on a dataset. Surrogate regret bounds, also called excess risk bounds, are a common tool to prove generalization rates for surrogate risk minimization. While surrogate regret bounds have been developed for certain classes of loss functions, such as proper losses, general results are relatively sparse. We provide two general results. The first gives a linear surrogate regret bound for any polyhedral (piecewise-linear and convex) surrogate, meaning that surrogate generalization rates translate directly to target rates. The second shows that for sufficiently non-polyhedral surrogates, the regret bound is a square root, meaning fast surrogate generalization rates translate to slow rates for the target. Together, these results suggest polyhedral surrogates are optimal in many cases.},
	journal = {Neural Information Processing Systems},
	author = {Frongillo, Rafael M. and Waggoner, Bo},
	year = {2021},
	pmid = {null},
	pmcid = {null},
}

@article{branco_survey_2015,
	title = {A {Survey} of {Predictive} {Modelling} under {Imbalanced} {Distributions}},
	doi = {null},
	abstract = {Many real world data mining applications involve obtaining predictive models using data sets with strongly imbalanced distributions of the target variable. Frequently, the least common values of this target variable are associated with events that are highly relevant for end users (e.g. fraud detection, unusual returns on stock markets, anticipation of catastrophes, etc.). Moreover, the events may have dierent costs and benets, which when associated with the rarity of some of them on the available training data creates serious problems to predictive modelling techniques. This paper presents a survey of existing techniques for handling these important applications of predictive analytics. Although most of the existing work addresses classication tasks (nominal target variables), we also describe methods designed to handle similar problems within regression tasks (numeric target variables). In this survey we discuss the main challenges raised by imbalanced distributions, describe the main approaches to these problems, propose a taxonomy of these methods and refer to some related problems within predictive modelling.},
	journal = {arXiv: Learning},
	author = {Branco, Paula and Branco, Paula and Torgo, Luı́s and Torgo, Luís and Ribeiro, Rita P. and Ribeiro, Rita P.},
	year = {2015},
	pmid = {null},
	pmcid = {null},
}

@article{domingos_metacost_1999,
	title = {{MetaCost}: a general method for making classifiers cost-sensitive},
	doi = {10.1145/312129.312220},
	abstract = {Research in machine learning, statistics and related fields has produced a wide variety of algorithms for classification. However, most of these algorithms assume that all errors have the same cost, which is seldom the case in KDD problems. Individually making each classification learner costsensitive is laborious, and often non-trivial. In this paper we propose a principled method for making an arbitrary classifier cost-sensitive by wrapping a cost-minimizing procedure around it. This procedure, called MetaCost, treats the underlying classifier as a black box, requiring no knowledge of its functioning or change to it. Unlike stratification, MetaCost, is applicable to any number of classes and to arbitrary cost matrices. Empirical trials on a large suite of benchmark databases show that MetaCost almost always produces large cost reductions compared to the cost-blind classifier used (C4.5RULES) and to two forms of stratification. Further tests identify the key components of MetaCost and those that can be varied without substantial loss. Experiments on a larger database indicate that MetaCost scales well.},
	journal = {Knowledge Discovery and Data Mining},
	author = {Domingos, Pedro and Domingos, Pedro},
	year = {1999},
	pmid = {null},
	pmcid = {null},
}

@article{maloof_learning_2003,
	title = {Learning {When} {Data} {Sets} are {Imbalanced} and {When} {Costs} are {Unequal} and {Unknown}},
	doi = {null},
	abstract = {The problem of learning from imbalanced data sets, while not the same problem as learning when misclassication costs are unequal and unknown, can be handled in a similar manner. That is, in both contexts, we can use techniques from roc analysis to help with classier design. We present results from two studies in which we dealt with skewed data sets and unequal, but unknown costs of error. We also compare for one domain these results to those obtained by over-sampling and under-sampling the data set. The operations of sampling, moving the decision threshold, and adjusting the cost matrix produced sets of classiers that fell on the same roc curve.},
	journal = {null},
	author = {Maloof, Marcus A. and Maloof, Marcus A.},
	year = {2003},
	pmid = {null},
	pmcid = {null},
}

@article{dmochowski_maximum_2010,
	title = {Maximum {Likelihood} in {Cost}-{Sensitive} {Learning}: {Model} {Specification}, {Approximations}, and {Upper} {Bounds}},
	doi = {10.5555/1756006.1953037},
	abstract = {The presence of asymmetry in the misclassification costs or class prevalences is a common occurrence in the pattern classification domain. While much interest has been devoted to the study of cost-sensitive learning techniques, the relationship between cost-sensitive learning and the specification of the model set in a parametric estimation framework remains somewhat unclear. To that end, we differentiate between the case of the model including the true posterior, and that in which the model is misspecified. In the former case, it is shown that thresholding the maximum likelihood (ML) estimate is an asymptotically optimal solution to the risk minimization problem. On the other hand, under model misspecification, it is demonstrated that thresholded ML is suboptimal and that the risk-minimizing solution varies with the misclassification cost ratio. Moreover, we analytically show that the negative weighted log likelihood (Elkan, 2001) is a tight, convex upper bound of the empirical loss. Coupled with empirical results on several real-world data sets, we argue that weighted ML is the preferred cost-sensitive technique.},
	journal = {Journal of Machine Learning Research},
	author = {Dmochowski, Jacek and Dmochowski, Jacek and Sajda, Paul and Sajda, Paul and Parra, Lucas C. and Parra, Lucas C.},
	year = {2010},
	pmid = {null},
	pmcid = {null},
}

@article{he_learning_2009,
	title = {Learning from {Imbalanced} {Data}},
	doi = {10.1109/tkde.2008.239},
	abstract = {With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, and finance, it becomes critical to advance the fundamental understanding of knowledge discovery and analysis from raw data to support decision-making processes. Although existing knowledge discovery and data engineering techniques have shown great success in many real-world applications, the problem of learning from imbalanced data (the imbalanced learning problem) is a relatively new challenge that has attracted growing attention from both academia and industry. The imbalanced learning problem is concerned with the performance of learning algorithms in the presence of underrepresented data and severe class distribution skews. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. In this paper, we provide a comprehensive review of the development of research in learning from imbalanced data. Our focus is to provide a critical review of the nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance under the imbalanced learning scenario. Furthermore, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potential important research directions for learning from imbalanced data.},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {He, Haibo and He, Haibo and Garcia, E. A. and Garcia, E. A.},
	year = {2009},
	pmid = {null},
	pmcid = {null},
}

@article{huang_experimental_2020,
	title = {An {Experimental} {Investigation} of {Calibration} {Techniques} for {Imbalanced} {Data}},
	doi = {10.1109/access.2020.3008150},
	abstract = {Calibration is a technique used to obtain accurate probability estimation for classification problems in real applications. Class imbalance can create considerable challenges in obtaining accurate probabilities for calibration methods. However, previous research has paid little attention to this issue. In this paper, we present an experimental investigation of some prevailing calibration methods in different imbalance scenarios. Several performance metrics are considered to evaluate different aspects of calibration performance. The experimental results show that the performance of different calibration techniques depends on the metrics and the degree of the imbalance ratio. Isotonic Regression has better overall performance on imbalanced datasets than parametric and other complex non-parametric methods. However, it performs unstably in highly imbalanced scenarios. This study provides some insights into calibration methods on imbalanced datasets, and it can be a reference for the future development of calibration methods in class imbalance scenarios.},
	journal = {IEEE Access},
	author = {Huang, Lanlan and Huang, Lanlan and Zhao, Junkai and Zhao, Junkai and Zhu, Bing and Zhu, Bing and Zhu, Bing and Chen, Hao and Chen, Hao and Broucke, Seppe vanden and Broucke, Seppe Vanden and Broucke, Seppe vanden},
	year = {2020},
	pmid = {null},
	pmcid = {null},
}

@article{gupta_top-label_2021,
	title = {Top-label calibration and multiclass-to-binary reductions},
	doi = {null},
	abstract = {A multiclass classiﬁer is said to be top-label calibrated if the reported probability for the predicted class—the top-label—is calibrated, conditioned on the top-label. This conditioning on the top-label is ab-sent in the closely related and popular notion of conﬁdence calibration, which we argue makes conﬁdence calibration diﬃcult to interpret for decision-making. We propose top-label calibration as a rectiﬁcation of conﬁdence calibration. Further, we outline a multiclass-to-binary (M2B) reduction framework that uniﬁes conﬁdence, top-label, and class-wise calibration, among others. As its name suggests, M2B works by reducing multiclass calibration to numerous binary calibration problems, each of which can be solved using simple binary calibration routines. We instantiate the M2B framework with the well-studied histogram binning (HB) binary calibrator, and prove that the overall procedure is multiclass calibrated without making any assumptions on the underlying data distribution. In an empirical evaluation with four deep net architectures on CIFAR-10 and CIFAR-100, we ﬁnd that the M2B + HB procedure achieves lower top-label and class-wise calibration error than other approaches such as temperature scaling. Code for this work is available at https://github.com/aigen/df-posthoc-calibration .},
	journal = {International Conference on Learning Representations},
	author = {Gupta, Chirag and Ramdas, Aaditya},
	year = {2021},
	pmid = {null},
	pmcid = {null},
}

@article{guo_calibration_2017,
	title = {On {Calibration} of {Modern} {Neural} {Networks}},
	doi = {null},
	abstract = {Confidence calibration – the problem of predicting probability estimates representative of the true correctness likelihood – is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling – a single-parameter variant of Platt Scaling – is surprisingly effective at calibrating predictions.},
	journal = {International Conference on Machine Learning},
	author = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
	year = {2017},
	pmid = {null},
	pmcid = {null},
}

@article{dwork_beyond_2022,
	title = {Beyond {Bernoulli}: {Generating} {Random} {Outcomes} that cannot be {Distinguished} from {Nature}},
	doi = {null},
	abstract = {Recently, Dwork et al. (STOC 2021) introduced Outcome Indistinguishability as a new desideratum for binary prediction tasks. Outcome Indistinguishability (OI) articulates the goals of prediction in the language of computational indistinguishability: a predictor is Outcome Indistinguishable if no computationally-bounded observer can distinguish Nature’s outcomes from outcomes that are generated based on the predictions. In this sense, OI suggests a generative model for binary outcomes that cannot be refuted given the empirical evidence and computational resources at hand. In this work, we extend Outcome Indistinguishability beyond Bernoulli, to outcomes that live in a large discrete or continuous domain. While the idea of OI for non-binary outcomes is natural for many applications, deﬁning OI in generality is not simply a syntactic exercise. We introduce and study multiple deﬁnitions of OI— each with its own semantics—for predictors that completely specify each individuals’ outcome distributions, as well as predictors that only partially specify the outcome distributions through statistics, such as moments. With the deﬁnitions in place, we provide learning algorithms for producing OI generative outcome models for general random outcomes. Finally, we study the relation of Outcome Indistinguishability and Multicalibration of statistics (beyond the mean) and relate our ﬁndings to the recent work of Jung et al. (COLT 2021) on Moment Multicalibration. We ﬁnd an equivalence between Outcome Indistinguishability and Multicalibration that is more subtle than in the binary case and sheds light on the techniques employed by Jung et al. to obtain Moment Multicalibration.},
	journal = {International Conference on Algorithmic Learning Theory},
	author = {Dwork, C. and Kim, Michael P. and Reingold, Omer and Rothblum, G. and Yona, G.},
	year = {2022},
	pmid = {null},
	pmcid = {null},
}

@article{zhao_calibrating_2021,
	title = {Calibrating {Predictions} to {Decisions}: {A} {Novel} {Approach} to {Multi}-{Class} {Calibration}},
	doi = {null},
	abstract = {When facing uncertainty, decision-makers want predictions they can trust. A machine learning provider can convey confidence to decision-makers by guaranteeing their predictions are distribution calibrated – amongst the inputs that receive a predicted class probabilities vector q, the actual distribution over classes is q. For multi-class prediction problems, however, achieving distribution calibration tends to be infeasible, requiring sample complexity exponential in the number of classes C. In this work, we introduce a new notion – {\textbackslash}emphdecision calibration – that requires the predicted distribution and true distribution to be “indistinguishable” to a set of downstream decision-makers. When all possible decision makers are under consideration, decision calibration is the same as distribution calibration. However, when we only consider decision makers choosing between a bounded number of actions (e.g. polynomial in C), our main result shows that decisions calibration becomes feasible – we design a recalibration algorithm that requires sample complexity polynomial in the number of actions and the number of classes. We validate our recalibration algorithm empirically: compared to existing methods, decision calibration improves decision-making on skin lesion and ImageNet classification with modern neural network predictors.},
	journal = {Neural Information Processing Systems},
	author = {Zhao, Shengjia and Kim, Michael P. and Sahoo, Roshni and Ma, Tengyu and Ermon, Stefano},
	year = {2021},
	pmid = {null},
	pmcid = {null},
}

@article{kull_beyond_2019,
	title = {Beyond temperature scaling: {Obtaining} well-calibrated multiclass probabilities with {Dirichlet} calibration},
	doi = {null},
	abstract = {Class probabilities predicted by most multiclass classifiers are uncalibrated, often tending towards over-confidence. With neural networks, calibration can be improved by temperature scaling, a method to learn a single corrective multiplicative factor for inputs to the last softmax layer. On non-neural models the existing methods apply binary calibration in a pairwise or one-vs-rest fashion. We propose a natively multiclass calibration method applicable to classifiers from any model class, derived from Dirichlet distributions and generalising the beta calibration method from binary classification. It is easily implemented with neural nets since it is equivalent to log-transforming the uncalibrated probabilities, followed by one linear layer and softmax. Experiments demonstrate improved probabilistic predictions according to multiple measures (confidence-ECE, classwise-ECE, log-loss, Brier score) across a wide range of datasets and classifiers. Parameters of the learned Dirichlet calibration map provide insights to the biases in the uncalibrated model.},
	journal = {Neural Information Processing Systems},
	author = {Kull, Meelis and Kull, Meelis and Nieto, Miquel Perelló and Nieto, Miquel Perello and Kängsepp, Markus and Kängsepp, Markus and Filho, Telmo M. Silva and Filho, Telmo de Menezes e Silva and Filho, Telmo Silva and Song, Hao and Song, Hao and Flach, Peter A. and Flach, Peter A.},
	year = {2019},
	pmid = {null},
	pmcid = {null},
}

@article{gopalan_computationally_2024,
	title = {On {Computationally} {Efficient} {Multi}-{Class} {Calibration}},
	doi = {10.48550/arxiv.2402.07821},
	abstract = {Consider a multi-class labelling problem, where the labels can take values in [k], and a predictor predicts a distribution over the labels. In this work, we study the following foundational question: Are there notions of multi-class calibration that give strong guarantees of meaningful predictions and can be achieved in time and sample complexities polynomial in k? Prior notions of calibration exhibit a tradeoff between computational efficiency and expressivity: they either suffer from having sample complexity exponential in k, or needing to solve computationally intractable problems, or give rather weak guarantees. Our main contribution is a notion of calibration that achieves all these desiderata: we formulate a robust notion of projected smooth calibration for multi-class predictions, and give new recalibration algorithms for efficiently calibrating predictors under this definition with complexity polynomial in k. Projected smooth calibration gives strong guarantees for all downstream decision makers who want to use the predictor for binary classification problems of the form: does the label belong to a subset T {\textbackslash}subseteq [k]: e.g. is this an image of an animal? It ensures that the probabilities predicted by summing the probabilities assigned to labels in T are close to some perfectly calibrated binary predictor for that task. We also show that natural strengthenings of our definition are computationally hard to achieve: they run into information theoretic barriers or computational intractability. Underlying both our upper and lower bounds is a tight connection that we prove between multi-class calibration and the well-studied problem of agnostic learning in the (standard) binary prediction setting.},
	journal = {arXiv.org},
	author = {Gopalan, Parikshit and Hu, Lunjia and Rothblum, G.},
	year = {2024},
	pmid = {null},
	pmcid = {null},
}

@article{ho-nguyen_risk_2020,
	title = {Risk {Guarantees} for {End}-to-{End} {Prediction} and {Optimization} {Processes}},
	doi = {10.1287/mnsc.2022.4321},
	abstract = {Prediction methods are often employed to estimate parameters of optimization models. Although the goal in an end-to-end framework is to achieve good performance on the subsequent optimization model, a formal understanding of the ways in which prediction methods can affect optimization performance is notably lacking. This paper identifies conditions on prediction methods that can guarantee good optimization performance. We provide two types of results: asymptotic guarantees under a well-known Fisher consistency criterion and nonasymptotic performance bounds under a more stringent criterion. We use these results to analyze optimization performance for several existing prediction methods and show that in certain settings, methods tailored to the optimization problem can fail to guarantee good performance. Conversely, optimization-agnostic methods can sometimes, surprisingly, have good guarantees. In a computational study on portfolio optimization, fractional knapsack, and multiclass classification problems, we compare the optimization performance of several prediction methods. We demonstrate that lack of Fisher consistency of the prediction method can indeed have a detrimental effect on performance. This paper was accepted by Chung Piaw Teo, optimization.},
	journal = {Management Sciences},
	author = {Ho-Nguyen, Nam and Kılınç-Karzan, F.},
	year = {2020},
	pmid = {null},
	pmcid = {null},
}

@article{blasiok_unifying_2023,
	title = {A {Unifying} {Theory} of {Distance} from {Calibration}},
	doi = {10.1145/3564246.3585182},
	abstract = {We study the fundamental question of how to define and measure the distance from calibration for probabilistic predictors. While the notion of perfect calibration is well-understood, there is no consensus on how to quantify the distance from perfect calibration. Numerous calibration measures have been proposed in the literature, but it is unclear how they compare to each other, and many popular measures such as Expected Calibration Error (ECE) fail to satisfy basic properties like continuity.},
	journal = {Symposium on the Theory of Computing},
	author = {Błasiok, Jarosław and Gopalan, Parikshit and Hu, Linlin and Guruswami, Venkatesan},
	year = {2023},
	pmid = {null},
	pmcid = {null},
}

@misc{foster_calibeating_2022,
	title = {"{Calibeating}": {Beating} {Forecasters} at {Their} {Own} {Game}},
	shorttitle = {"{Calibeating}"},
	url = {http://arxiv.org/abs/2209.04892},
	doi = {10.48550/arXiv.2209.04892},
	abstract = {In order to identify expertise, forecasters should not be tested by their calibration score, which can always be made arbitrarily small, but rather by their Brier score. The Brier score is the sum of the calibration score and the refinement score; the latter measures how good the sorting into bins with the same forecast is, and thus attests to "expertise." This raises the question of whether one can gain calibration without losing expertise, which we refer to as "calibeating." We provide an easy way to calibeat any forecast, by a deterministic online procedure. We moreover show that calibeating can be achieved by a stochastic procedure that is itself calibrated, and then extend the results to simultaneously calibeating multiple procedures, and to deterministic procedures that are continuously calibrated.},
	urldate = {2024-04-23},
	publisher = {arXiv},
	author = {Foster, Dean P. and Hart, Sergiu},
	month = oct,
	year = {2022},
	note = {arXiv:2209.04892 [cs, econ, stat]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, Economics - Theoretical Economics, Statistics - Machine Learning},
}

@misc{kleinberg_u-calibration_2023,
	title = {U-{Calibration}: {Forecasting} for an {Unknown} {Agent}},
	shorttitle = {U-{Calibration}},
	url = {http://arxiv.org/abs/2307.00168},
	doi = {10.48550/arXiv.2307.00168},
	abstract = {We consider the problem of evaluating forecasts of binary events whose predictions are consumed by rational agents who take an action in response to a prediction, but whose utility is unknown to the forecaster. We show that optimizing forecasts for a single scoring rule (e.g., the Brier score) cannot guarantee low regret for all possible agents. In contrast, forecasts that are well-calibrated guarantee that all agents incur sublinear regret. However, calibration is not a necessary criterion here (it is possible for miscalibrated forecasts to provide good regret guarantees for all possible agents), and calibrated forecasting procedures have provably worse convergence rates than forecasting procedures targeting a single scoring rule. Motivated by this, we present a new metric for evaluating forecasts that we call U-calibration, equal to the maximal regret of the sequence of forecasts when evaluated under any bounded scoring rule. We show that sublinear U-calibration error is a necessary and sufficient condition for all agents to achieve sublinear regret guarantees. We additionally demonstrate how to compute the U-calibration error efficiently and provide an online algorithm that achieves \$O({\textbackslash}sqrt\{T\})\$ U-calibration error (on par with optimal rates for optimizing for a single scoring rule, and bypassing lower bounds for the traditionally calibrated learning procedures). Finally, we discuss generalizations to the multiclass prediction setting.},
	urldate = {2024-04-23},
	publisher = {arXiv},
	author = {Kleinberg, Robert and Leme, Renato Paes and Schneider, Jon and Teng, Yifeng},
	month = jun,
	year = {2023},
	note = {arXiv:2307.00168 [cs]},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning},
}

@misc{roth_forecasting_2024,
	title = {Forecasting for {Swap} {Regret} for {All} {Downstream} {Agents}},
	url = {http://arxiv.org/abs/2402.08753},
	abstract = {We study the problem of making predictions so that downstream agents who best respond to them will be guaranteed diminishing swap regret, no matter what their utility functions are. It has been known since Foster and Vohra (1997) that agents who best-respond to calibrated forecasts have no swap regret. Unfortunately, the best known algorithms for guaranteeing calibrated forecasts in sequential adversarial environments do so at rates that degrade exponentially with the dimension of the prediction space. In this work, we show that by making predictions that are not calibrated, but are unbiased subject to a carefully selected collection of events, we can guarantee arbitrary downstream agents diminishing swap regret at rates that substantially improve over the rates that result from calibrated forecasts -- while maintaining the appealing property that our forecasts give guarantees for any downstream agent, without our forecasting algorithm needing to know their utility function. We give separate results in the ``low'' (1 or 2) dimensional setting and the ``high'' (\${\textgreater} 2\$) dimensional setting. In the low dimensional setting, we show how to make predictions such that all agents who best respond to our predictions have diminishing swap regret -- in 1 dimension, at the optimal \$O({\textbackslash}sqrt\{T\})\$ rate. In the high dimensional setting we show how to make forecasts that guarantee regret scaling at a rate of \$O(T{\textasciicircum}\{2/3\})\$ (crucially, a dimension independent exponent), under the assumption that downstream agents smoothly best respond. Our results stand in contrast to rates that derive from agents who best respond to calibrated forecasts, which have an exponential dependence on the dimension of the prediction space.},
	urldate = {2024-04-23},
	publisher = {arXiv},
	author = {Roth, Aaron and Shi, Mirah},
	month = feb,
	year = {2024},
	note = {arXiv:2402.08753 [cs]
version: 1},
	keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Machine Learning, swap regret},
}

@misc{suriyakumar_when_2023,
	title = {When {Personalization} {Harms}: {Reconsidering} the {Use} of {Group} {Attributes} in {Prediction}},
	shorttitle = {When {Personalization} {Harms}},
	url = {http://arxiv.org/abs/2206.02058},
	abstract = {Machine learning models are often personalized with categorical attributes that are protected, sensitive, self-reported, or costly to acquire. In this work, we show models that are personalized with group attributes can reduce performance at a group level. We propose formal conditions to ensure the "fair use" of group attributes in prediction tasks by training one additional model -- i.e., collective preference guarantees to ensure that each group who provides personal data will receive a tailored gain in performance in return. We present sufficient conditions to ensure fair use in empirical risk minimization and characterize failure modes that lead to fair use violations due to standard practices in model development and deployment. We present a comprehensive empirical study of fair use in clinical prediction tasks. Our results demonstrate the prevalence of fair use violations in practice and illustrate simple interventions to mitigate their harm.},
	urldate = {2024-04-22},
	publisher = {arXiv},
	author = {Suriyakumar, Vinith M. and Ghassemi, Marzyeh and Ustun, Berk},
	month = jul,
	year = {2023},
	note = {arXiv:2206.02058 [cs, stat]},
	keywords = {berk},
}

@article{joren_participatory_nodate,
	title = {Participatory {Personalization} in {Classiﬁcation}},
	abstract = {Machine learning models are often personalized with information that is protected, sensitive, self-reported, or costly to acquire. These models use information about people but do not facilitate nor inform their consent. Individuals cannot opt out of reporting personal information to a model, nor tell if they beneﬁt from personalization in the ﬁrst place. We introduce a family of classiﬁcation models, called participatory systems, that let individuals opt into personalization at prediction time. We present a model-agnostic algorithm to learn participatory systems for personalization with categorical group attributes. We conduct a comprehensive empirical study of participatory systems in clinical prediction tasks, benchmarking them with common approaches for personalization and imputation. Our results demonstrate that participatory systems can facilitate and inform consent while improving performance and data use across all groups who report personal data.},
	language = {en},
	author = {Joren, Hailey and Nagpal, Chirag and Heller, Katherine and Ustun, Berk},
	keywords = {berk},
}

@inproceedings{hiranandani_performance_2019,
	title = {Performance {Metric} {Elicitation} from {Pairwise} {Classifier} {Comparisons}},
	url = {https://proceedings.mlr.press/v89/hiranandani19a.html},
	abstract = {Given a binary prediction problem, which performance metric should the classifier optimize? We address this question by formalizing the problem of Metric Elicitation. The goal of metric elicitation is to discover the performance metric of a practitioner, which reflects her innate rewards (costs) for correct (incorrect) classification. In particular, we focus on eliciting binary classification performance metrics from pairwise feedback, where a practitioner is queried to provide relative preference between two classifiers. By exploiting key geometric properties of the space of confusion matrices, we obtain provably query efficient algorithms for eliciting linear and linear-fractional performance metrics. We further show that our method is robust to feedback and finite sample noise.},
	language = {en},
	urldate = {2024-04-22},
	booktitle = {Proceedings of the {Twenty}-{Second} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Hiranandani, Gaurush and Boodaghians, Shant and Mehta, Ruta and Koyejo, Oluwasanmi},
	month = apr,
	year = {2019},
	note = {ISSN: 2640-3498},
	keywords = {metric elicitation, sanmi},
	pages = {371--379},
}

@inproceedings{hiranandani_multiclass_2019,
	title = {Multiclass {Performance} {Metric} {Elicitation}},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper_files/paper/2019/hash/1fd09c5f59a8ff35d499c0ee25a1d47e-Abstract.html},
	abstract = {Metric Elicitation is a principled framework for selecting the performance metric that best reflects implicit user preferences. However, available strategies have so far been limited to binary classification. In this paper, we propose novel strategies for eliciting multiclass classification performance metrics using only relative preference feedback. We also show that the strategies are robust to both finite sample and feedback noise.},
	urldate = {2024-04-22},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Hiranandani, Gaurush and Boodaghians, Shant and Mehta, Ruta and Koyejo, Oluwasanmi O},
	year = {2019},
	keywords = {metric elicitation, sanmi},
}
