\section{Background and Related Work}
Our main question of interest is if \hlc[myYellow]{small} ML models trained using a \hlc[myBlue]{cost-sensitive surrogate} loss functions outperform models trained on cost-agnostic surrogates combined with some \hlc[myPurple]{``clever'' post-processing}.

To understand this question, we must formalize the three emphasized pieces.
First, we formalize \hlc[myYellow]{small} through the optimized model class $\H$, which enables us to restrict ourselves to model classes like the set of linear models $\Hlin := \{h : \exists \vec w,b \text{ s.t. } h(x) = \sigma(\langle w,x \rangle + b)\}$ or two-layer neural networks.
\hlc[myBlue]{Cost-sensitive surrogates} refer to continuous loss functions $L : \reals^d \times \Y \to \reals_+$ designed with the intention of emulating a cost-sensitive classification problem $\ell^\alpha : \R \times \Y \to \reals_+$.
We designate a surrogate as cost-sensitive if it is $\H$-consistent, where approaching the optimal surrogate loss implies approaching the optimal cost-sensitive loss. 
This notion is a prerequisite for establishing any PAC-learning bounds.
Finally, \hlc[myPurple]{clever post-processing} involves optimizing over the choice of a function $\psi : \reals^d \to \R$ mapping surrogate predictions, such as risk scores, to discrete decisions, such as positive or negative classifications.
The most common example of this clever post-processing is through a threshold search to establish decision boundaries. However, this threshold search is often difficult to scale beyond binary classification as the threshold search space grows in the number of classes.

Our approach to this problem merges the perspectives of two fields: the work on surrogate loss design and the work on $\H$-consistency.
The surrogate loss design literature generally assumes that the model class $\H$ is rich enough for just about any hypothesis to be learned, ignoring the relationship between model class and learned hypothesis (e.g., \citet{reid_information_2011,reid_surrogate_2009,buja_loss_2005,bao_proper_2023}).
On the other hand, the $\H$-consistency literature has yet to provide results informing cost-sensitive surrogate design, simply providing bounds for a variety of standard surrogates for tasks such as adversarial learning~\citep{awasthi2021calibration,bao_calibrated_2021,awasthi2021finer}, regression~\citep{mao_h-consistency_2024}, learning with deferral~\citep{mao_realizable_2024}, and multi-label learning~\citep{mao_multi-label_2024}.

\paragraph{Cost-sensitive classification}
The surrogate losses we design are proxies for some other loss $\ell$, which might not be tractable to optimize directly.
One such loss function, which our work focuses on, is a generalization of the 0-1 loss called \emph{cost-sensitive classification}, denoted $\ell : \R \times \Y \to \reals_+$, where both the report set $\R$ (i.e., the predicted classes) and label set $\Y$ are finite.
In general, we consider any loss $\ell$ that can be written in this form to be a cost-sensitive classification problem, though this approach encapsulates broader classes of problems such as ranking~\citep{ramaswamy_convex_2016}.
\Cref{tab:csc-costs} gives one example of such a cost-sensitive classification loss $\ell^\alpha$ for the binary report and label setting.
In this instance, we normalize the loss so it can be represented with a single parameter, as done by the foundational works of \citet{elkan_foundations_2001,scott_calibrated_2012}.
In general, we refer to cost-agnostic classification as the target loss $\ell = (\ones \ones^T) - \mathrm{Id}$, i.e., the 0-1 loss.




\paragraph{$\H$-consistency}
Agnostic learning aims to find a model $h \in \H$ such that the expected loss of $h$ is close to the best expected target loss possible in $\H$.
However, given the computational hardness of directly optimizing discontinuous functions, such as the cost-sensitive classification loss~\citep{ben2003difficulty}, we instead aim to optimize a \emph{surrogate} loss and apply a \emph{link} function $\psi$ that yields our desired agnostic learning guarantee, recovered by $\H$-consistency.

\begin{definition}[$\H$-consistency]\label{def:H-consistent}
    A surrogate $L : \reals^d \times \Y \to \reals_+$ and link $\psi : \reals^d \to \R$ pair $(L, \psi)$ are $\H$-consistent with respect to a target loss matrix $\ell$ over a set of distributions $\P \subseteq \Delta(\X \times \Y)$ if, for all sequences $\{h_n\} \in \H$ and $P \in \P$, we have
    \begin{multline}
        \resizebox{0.9\textwidth}{!}{        $\underset{\text{approaching the best-in-class surrogate prediction}}{\underbrace{\E_{(X,Y) \sim P}L(h_n(X), Y) \to \inf_{h^* \in \H} \E_{(X,Y) \sim P}L(h^*(X), Y)}} \implies
        \underset{\text{approaching the best-in-class utility by discretizing surrogate predictions}}{\underbrace{\E_{(X,Y) \sim P}\ell(\psi(h_n(X)), Y) \to \inf_{h^* \in \H} \E_{(X,Y) \sim P}\ell(\psi(h^*(X)), Y)}}$ }    \end{multline}
    
\end{definition}

$\H$-consistency has clear connections to PAC learning: minimizing the surrogate implies a low target loss, which is the goal of PAC learning.
However, analyzing for which surrogates $\H$-consistency holds can be technically challenging, which has historically led researchers to study $\H$-calibration as a ``point-wise'' proxy.
To understand when $\H$-calibration and $\H$-consistency are equivalent, we must first discuss some nuance around the distributional assumptions made in the literature.

\paragraph{Distributional assumptions}
In the literature, two common distributional assumptions are made: realizability and minimizability.
If a loss $L$ is $P$-realizable under $\H$, then there exists a hypothesis $h^* \in \H$ such that $\E_{X,Y}L(h^*(X),Y) = 0$.
Notably, this means that $h^*$ yields a deterministic labeling over outcomes, and that there is no outcome uncertainty.
Under even these relatively strict distributional assumptions, \citet{long_consistency_2013,kuznetsov2014multi} observe a gap between $\H$-consistency and $\Hall$-consistency, where (a) the logit loss, which is $\Hall$-consistent, is not $\Hlin$-consistent for multiclass classification, and (b) the Crammer-Singer surrogate, which is not $\Hall$-consistent, is realizable $\H$-consistent for multiclass classification.
Notably, their second result does not extend beyond the realizable setting.

Less stringent is the assumption that a loss $L$ is $P$-minimizable over $\H$, meaning that a Bayes optimal classifier is in class (but its error may not be 0).
\begin{definition}[$P$-minimizability]\label{def:P-minimizable}
    For a given distribution $P \in \Delta(\X \times \Y)$, a loss $L$ is $P$-minimizable over $\H$ if there exists an $h^* \in \H$ such that $h^*(x) = \argmin_{r} \E_{Y\mid X=x}L(r, Y)$ for all $x \in \X$.
    Moreover, let $\Q_{L,\H} := \{P \in \Delta(\X \times \Y) : L $ is $P$-minimizable over $\H\}$ denote the set of distributions $P$ such that the loss $L$ is $P$-minimizable over $\H$.
\end{definition}

$P$-minimizability tends to be the most common distributional assumption~\citep{bao_calibrated_2021}, as it often simplifies analysis to a ``point-wise optimality.'' 
In this paper, we leverage this structure and primarily work under minimizability assumptions.

We refrain from studying the most general distributions because it is known that even in the simplest case of linear classification $\H = \Hlin$ with the 0-1 loss $\ell = \ell_{0-1}$ is NP-Hard~\citep{ben2003difficulty,guruswami2009hardness}.
As a result, there are no $\H$-consistent surrogates for the most general set of distributions. If there were such easy-to-minimize $\H$-consistent surrogates for general distributions, one could reduce direct cost minimization to a tractable problem, implying $P=NP$. 


\paragraph{$\H$-calibration}
While $\H$-consistency yields agnostic learning guarantees, studying the expected loss over distributions on labels \emph{and features} often poses practical difficulties.
To circumvent these, the notion of $\H$-calibration, a ``point-wise consistency'' for each input $x \in \X$, is often used to analyze these surrogates more tractably.
To understand $\H$-calibration, we use the conditional risk, which is the expected loss conditioned on input $x$.

\begin{definition}[Conditional risk]\label{def:inner-risk}
    For a loss function $L : \R \times \Y \to \reals_+$ and hypothesis function $h : \X \to \R$, the conditional risk of the hypothesis $h$ is given
    \begin{align*}
        \condrisk L (h, x, p) &:= \sum_{y} p_y L(h(x), y) 
        = \E_{Y \sim p} L(h(x), Y)
    \end{align*}
    Moreover, we denote the \emph{minimal conditional risk} by
    \begin{align*}
        \condriskstar L \H(x, p) := \inf_{h' \in \H} \condrisk L (h', x, p)
    \end{align*}
\end{definition}

\begin{definition}[$\H$-calibration]\label{def:H-calibration}
    A loss function $L : \reals^d \times \Y \to \reals_+$ and link $\psi : \reals^d \to \R$ pair are $\H$-calibrated with respect to a target loss $\ell : \R \times \Y \to \reals_+$ over the set $\P \subseteq \simplex$ if, for any $\epsilon > 0$, $p \in \P$, and $x \in \X$, there exists some $\delta > 0$ such that
    \begin{align*}
        \condrisk L(h,x, p) - \condriskstar L \H (x,p) &< \delta \implies  \condrisk \ell(\psi \circ h,x, p) - \condriskstar \ell {\psi \circ \H} (x,p) < \epsilon
    \end{align*}
    for all $h \in \H$.
\end{definition}





Early works of \citet{bartlett_convexity_2006,ramaswamy_convex_2016} show that $\Hall$-consistency and $\Hall$-calibration are equivalent in finite outcome settings, where $\Hall$ is the set of all measurable hypotheses.
However, when $\H \neq \Hall$, two gaps emerge: first, the gap between $\H$-calibration and $\H$-consistency, and second, the gap between $\H$-consistency and $\Hall$-consistency.
The following Theorem shows the equivalence between $\H$-calibration and $\H$-consistency under $P$-minimizability, closing the first gap.

\begin{theorem}[{\citet[Theorem 2.8]{steinwart_how_2007}}]\label{thm:steinwart}
    Given a surrogate loss $L : \reals^d \times \Y \to \reals_+$, link function $\psi: \reals^d \to \R$, and target loss $\ell : \R \times \Y\to \reals_+$, assume that $P \in \Q_{L, \H} \cap \Q_{\ell,\H}$.
    Furthermore, assume there exists a function $b \in \L^1(P_X)$ and measurable function $\delta(\epsilon, \cdot) : \X \to \reals_{>0}, \epsilon > 0$ such that 
    \begin{align}
    \begin{aligned}
        \C_{\ell}(h,x,p) &\leq \C^*_{\ell}(x,p) + b(x) \label{eq:ptwise-min}
    \end{aligned}\\
        \begin{aligned}
        \C_{L}(h,x,p) &\leq \C^*_{L}(x,p) + \delta(\epsilon, x)\\
        \implies \C_{\ell}(\psi \circ h,x,p) &\leq \C^*_{\ell}(x,p) + \epsilon
        \label{eq:H-calibration}
        \end{aligned}
    \end{align}
    for all $x \in \X$, $\epsilon > 0$, and $h \in \H$.
    Then for all $\epsilon > 0$, there exists a $\delta > 0$ such that for all $h \in \H$, we have
    \begin{align}
    \begin{aligned}
        \E_{P} L(h(X), Y) &< \inf_{h^* \in \H} \E_{P} L(h^*(X), Y) + \delta \\
          \implies \E_{P} \ell(\psi \circ h(X), Y) &< \inf_{h^* \in \H} \E_{P} \ell(\psi \circ h^*(X), Y) + \epsilon
        \label{eq:H-consistency}
        \end{aligned}
    \end{align}
\end{theorem}

The preceding result gives a sufficient condition for $\H$-calibration to imply $\H$-consistency when the losses are $P$-minimizable over $\H$.
Equation~\eqref{eq:ptwise-min} is simply a condition that the conditional target risk is not infinite, which is generally satisfied in our work based on the restriction to cost-sensitive classification tasks for $\ell$ that can be written in matrix form (and are always finite).
Equation~\eqref{eq:H-calibration} is then our $\H$-calibration condition, and equivalence follows in this setting where the surrogate and discrete problems are $P$-minimizable.

\paragraph{Proper Scoring Losses}
One special class of cost-agnostic surrogates to consider is that of \emph{proper scoring rules}~\citep{savage_elicitation_1971,gneiting_strictly_2007,brier_verification_1950}.
These are generally regarded as loss functions that lead to a predictor $h^*(x) = \Pr_{P}[Y\mid X=x]$ and satisfy the assumption of Equation \eqref{eq:H-calibration}, thus implying $\H$-calibration.
However, something interesting happens when the model class $\H$ does not contain a function $h^*$ predicting the conditional distribution for all $x \in \X$: while the assumption of Equation~\eqref{eq:H-calibration} may still hold, the implication may not.
In fact, we show in~\cref{sec:XE-not-H-consistent} that there are instances where the implication does not hold and that this gap is precisely the one we can close with cost-sensitive surrogate design.

This observation highlights the tensions between minimizability and the translation from $\H$-calibration to $\H$-consistency.
Namely, minimizability means that the Bayes optimal classifier is in $\H$.
However, in $\H$-calibration, we only require that some model $h \in \H$ is individually optimal \emph{for each $x \in \X$}. Importantly, $\H$-calibration does \emph{not} mean that $h$ minimizing the conditional risk for one $x \in \X$ also minimizes conditional risk for some other $x' \neq x$. As a result, the Bayes optimal classifier may not satisfy the assumption of Equation~\eqref{eq:H-calibration} for cost-agnostic classifiers.