\section{Related Work}
Metonymy has long been recognized as a significant concept across multiple disciplines,  including philosophy, linguistics, and psychology~\citep{noppen1985metaphor}. Unlike metaphor, metonymy is often approached as a cognitive and pragmatic phenomenon, rather than purely linguistic terms~\citep{maria2015metonymy}. For example, \citet{radden} describes metonymy as a conceptual phenomenon and cognitive process.  \citet{papafragou1996metonymy} defines metonymic use as introducing a new name – like a nickname – for the entity the speaker has in mind. 

Early in the field of artificial intelligence and natural language processing (NLP), multiple attempts have been made to address the ambiguity issues caused by metonymy, such as collative semantics~\citep{fass-1991-met} and local pragmatics~\citep{hobbs1987local}. More recent work in the NLP community follows \citet{markert-nissim-2002-metonymy} that treats the metonymy resolution as a classification task and focuses on metonymies triggered by named entities. SemEval 2007 Shared Task 8~\citep{markert-nissim-2007-semeval} created a metonymy dataset with sentences extracted from British National Corpus (BNC) using keywords of country and company
names. Later, more work has been done in constructing metonymic datasets, including RelocaR \citep{gritta-etal-2017-vancouver} and \textsc{wimcor}~\citep{alex-mathews-strube-2020-large}, both of which focuses primarily on named entities referring to geographical locations or organizations. A number of methods have been proposed to tackle the task, including using syntactic roles and morphological features~\citep{nicolae-etal-2007-utd}, external knowledge~\citep{nastase-strube-2009-combining}, word embeddings~\citep{gritta-etal-2017-vancouver}, as well as transformer-based model~\citep{li-etal-2020-target}.

Our work is most closely related to \citet{pedinotti-lenci-2020-dont}. They created a dataset of 509 artificially constructed metonymic and literal sentence pairs, and proposed a method to determine metonymy by using the contextualized word embeddings. They computed the cosine similarity between the metonymic word and actual paraphrased meaning. For example, in sentence ``\textit{the man sips the \textbf{glass}}'', they replace ``\textit{glass}'' with ``\textit{wine}'', and assume that ``\textit{glass}'' should be more semantically similar to ``\textit{wine}'' in this sentence than a literal sentence like ``\textit{the man grabbed the \textbf{glass}}''. This strategy requires a corresponding literal sentence for each metonymic instance and does not generalize effectively to complex real-world text. In comparison, our dataset builds upon their work by first extracting verbs and nouns from their dataset, using LLMs to augment these pairs, and then using the expanded set as keywords to extract naturally occurring sentences from Wikipedia, which encompasses more complicated and nuanced instances of metonymy. We then used a chain-of-thought prompting technique~\citep{wei-chain-of-thought-prompting} 
to build a 2-step pipeline for identifying metonymy in these sentences.