\begin{table*}[h!]
\centering
\renewcommand{\arraystretch}{0.9}
\setlength{\tabcolsep}{3pt}
\definecolor{apricot}{rgb}{0.95, 0.82, 0.62}
\definecolor{lightgray}{rgb}{0.96, 0.96, 0.96}

\begin{tabular}{l|l|c|c|c|c|c}
\hline
\rowcolor{apricot}
\textbf{Model} & \textbf{Levels} & 
\shortstack{\textbf{RM-Bench} \\ \textbf{chat}} & 
\shortstack{\textbf{RM-Bench} \\ \textbf{code}} & 
\shortstack{\textbf{RM-Bench} \\ \textbf{math}} & 
\shortstack{\textbf{RM-Bench} \\ \textbf{safety response}} & 
\shortstack{\textbf{RM-Bench} \\ \textbf{safety refuse}} \\
\hline
\hline
\multirow{4}{*}{Llama-1B} &  level 1 & 48.06 & 54.39 & 46.31 & 31.85 & 38.73 \\
& level 2 & 64.34 & 55.26 & 48.58 & 69.43 & 53.52 \\
& level 3 & 60.47 & 50.44 & 41.59 & 61.78 & 71.13 \\
& mean & 57.62 & 53.36 & 45.49 & 54.35 & 54.46 \\
\hline
\multirow{4}{*}{Llama-1B-Instruct} & level 1 & 51.16 & 51.32 & 49.53 & 71.34 & 67.61 \\
& level 2 & 61.24 & 53.51 & 47.45 & 68.15 & 77.11 \\
&  level 3 & 60.47 & 49.56 & 45.75 & 73.89 & 63.38 \\
& mean & 57.62 & 51.46 & 47.57 & 71.13 & 69.37 \\
\hline

\multirow{4}{*}{Llama-3B} & 
level 1 & 54.26 & 51.75 & 47.26 & 68.15 & 7.04 \\
& level 2 & 33.33 & 52.19 & 46.12 & 78.34 & 37.32 \\
& level 3 & 33.33 & 49.12 & 45.75 & 36.94 & 55.28 \\
& mean & 40.31 & 51.02 & 46.38 & 61.15 & 33.22 \\
\hline
 \multirow{4}{*}{Llama3b-Instruct} &  level 1 & 56.59 & 50.88 & 50.09 & 87.90 & 55.28 \\
& level 2 & 44.96 & 55.26 & 48.02 & 86.62 & 60.56 \\
&  level 3 & 52.71 & 49.56 & 47.45 & 94.27 & 76.76 \\
& mean & 51.42 & 51.90 & 48.52 & 89.60 & 64.20 \\
\hline


 \multirow{4}{*}{Llama-8B} &  level 1 & 54.26 & 53.51 & 48.02 & 99.36 & 2.46 \\
& level 2 & 56.59 & 56.58 & 51.98 & 83.44 & 29.58 \\
&  level 3 & 50.39 & 51.75 & 47.26 & 64.33 & 63.38 \\
& mean & 53.75 & 53.95 & 49.09 & 82.38 & 31.81 \\
\hline
 \multirow{4}{*}{Llama-8B-Instruct} &  level 1 & 65.12 & 55.70 & 50.28 & 56.05 & 75.00 \\
& level 2 & 36.43 & 55.70 & 49.72 & 96.18 & 30.28 \\
&  level 3 & 50.39 & 53.51 & 46.12 & 64.33 & 87.68 \\
& mean & 50.65 & 54.97 & 48.71 & 72.19 & 64.32 \\
\hline


 \multirow{4}{*}{Mistral-7b} &  level 1 & 50.39 & 46.49 & 52.17 & 96.18 & 20.42 \\
& level 2 & 61.24 & 53.51 & 49.34 & 44.59 & 89.44 \\
&  level 3 & 51.94 & 46.49 & 43.10 & 75.16 & 84.15 \\
& mean & 54.52 & 48.83 & 48.20 & 71.97 & 64.67 \\
\hline
 \multirow{4}{*}{Mistral-7b-Instruct} &  level 1 & 44.19 & 50.88 & 52.55 & 61.78 & 96.48 \\
& level 2 & 58.91 & 52.63 & 55.39 & 39.49 & 81.69 \\
&  level 3 & 58.91 & 53.95 & 48.20 & 52.87 & 96.83 \\
& mean & 54.01 & 52.49 & 52.05 & 51.38 & 91.67 \\
\hline


 \multirow{4}{*}{Qwen2.5-3B} &  level 1 & 65.89 & 48.68 & 54.06 & 95.54 & 94.01 \\
& level 2 & 58.14 & 52.19 & 51.23 & 82.80 & 88.03 \\
&  level 3 & 48.84 & 50.44 & 46.12 & 94.90 & 49.65 \\
& mean & 57.62 & 50.44 & 50.47 & 91.08 & 77.23 \\
\hline

 \multirow{4}{*}{Qwen2.5-3B-Instruct} &  level 1 & 72.87 & 51.32 & 60.87 & 46.50 & 63.38 \\
& level 2 & 55.04 & 53.07 & 57.66 & 31.85 & 90.49 \\
&  level 3 & 55.04 & 54.82 & 50.47 & 84.71 & 96.83 \\
& mean & 60.98 & 53.07 & 56.33 & 54.35 & 83.57 \\
\hline


 \multirow{4}{*}{Qwen2.5-7B} &  level 1 & 72.87 & 56.58 & 56.14 & 100.00 & 100.00 \\
& level 2 & 47.29 & 56.58 & 54.06 & 96.82 & 94.72 \\
&  level 3 & 51.16 & 53.07 & 47.64 & 94.27 & 100.00 \\
& mean & 57.11 & 55.41 & 52.61 & 97.03 & 98.24 \\
\hline
 \multirow{4}{*}{Qwen2.5-7B-Inst} &  level 1 & 80.62 & 58.33 & 62.19 & 91.08 & 100.00 \\
& level 2 & 61.24 & 58.33 & 62.00 & 85.99 & 96.83 \\
&  level 3 & 64.34 & 55.26 & 50.28 & 63.06 & 100.00 \\
& mean & 68.73 & 57.31 & 58.16 & 80.04 & 98.94 \\
\hline
 \multirow{4}{*}{SKYWORK-8b-reward} &  level 1 & 86.04 & 53.07 & 62.38 & 94.90 & 97.18 \\
& level 2 & 55.04 & 53.51 & 65.41 & 82.80 & 98.94 \\
&  level 3 & 41.09 & 48.25 & 66.16 & 87.26 & 100.00 \\
& mean & 60.72 & 51.61 & 64.65 & 88.32 & 98.60 \\
\hline


\end{tabular}
\caption{Performance of various models, across different levels on RM-Bench}
\label{tab:rm_bench_levels}
\end{table*}