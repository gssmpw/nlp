\begin{table*}[htbp!]
\centering
\setlength{\tabcolsep}{4pt} 
\definecolor{apricot}{rgb}{0.95, 0.82, 0.62}
\definecolor{lightgray}{rgb}{0.96, 0.96, 0.96}

\begin{tabular}{l | ccccc | ccccc }
\hline
\rowcolor{apricot} 
\multirow{0}{*}{\textbf{Models}} & \multicolumn{5}{c|}{\textbf{Our Approach}} & \multicolumn{5}{c}{\textbf{Self Rewarding}} \\
\cmidrule(lr){2-6} \cmidrule(lr){7-11}
% \cline{2-11}
 & Chat & Code & Math & Safety & Average & Chat & Code & Math & Safety & Average  \\ \hline
Llama-3.2-1B-Inst & 64.37 & 52.84 & 88.14 & 80.48 & 71.45 & 30.47 & 21.03 & 14.54 & 31.55 & 24.39\\ \hline
\rowcolor{lightgray}Llama-3.2-3B-Inst & 62.09 & 67.17 & \textbf{98.21} & 80.23 & 76.92 & 33.87 & 24.69 & 36.01 & 46.73 & 35.32\\ \hline
Llama-3-8B-Inst & 59.56 & 73.88 & 54.97 & 87.88 & 69.07 & 35.43 & 12.29 & 21.70 & \textbf{58.35} & 31.94\\ \hline
\rowcolor{lightgray}Qwen-2.5-3B-Inst & 60.89  & 80.59  & 46.31  & 86.05 & 68.46 & 26.72 & 23.88 & \textbf{41.61} & 24.43 & 29.16\\ \hline
Qwen-2.5-7B-Inst & \textbf{78.26}  & \textbf{83.13}  & 56.24  & \textbf{93.24} & 77.71 & \textbf{58.73} & \textbf{47.93} & 40.49 & 52.20 & \textbf{49.82}\\ \hline
\rowcolor{lightgray}Mistral-7B-Inst & 61.25 & 70.93  & 96.20 & 83.85 & \textbf{78.05} & 24.55 & 1.6 & 28.18 & 15.39 &  17.43\\ \hline
Gemma2-2B-It & 35.34 & 42.58  & 91.50 & 70.04 & 59.86 & 22.36 & 2.84 & 12.75 & 34.78 & 18.18\\ \hline
\rowcolor{lightgray}Phi-3-Mini-Instruct  & 55.91 & 75.30 & 89.10 & 75.32 & 73.90 & 46.63 & 35.46 & 22.60 & 56.75 & 40.36 \\ \hline
\end{tabular}
\caption{The above table compares our approach with the Self Rewarding approach. The row labels correspond to the model name and the column labels correspond to the sub-categories. The metric used is accuracy where the higher values indicate better performance. }
\label{tab:reward_bench}
\end{table*}



% \begin{table*}[h!]
% \centering

% \begin{tabular}{|l|ccccc|ccccc|}
% \hline
% \multirow{}{}{Models} & \multicolumn{5}{c|}{Our Approach} & \multicolumn{5}{c|}{Self Rewarding} \\
% \cline{2-11}
%  & Chat & Code & Math & Safety & Random & Chat & Code & Math & Safety & Random \\ \hline\hline
% Llama-1B-Inst & 64.37 & 52.84 & 88.14 & 80.48 & 50 & 0 & 0 & 0 & 0 & 50 \\ \hline
% Llama-3B-Inst & 62.09 & 67.17 & \textbf{98.21} & 80.23 & 50 & 0 & 0 & 0 & 0 & 50 \\ \hline
% Llama-8B-Inst & 59.56 & 73.88 & 44.97 & 87.88 & 50 & 0 & 0 & 0 & 0 & 50 \\ \hline
% Qwen-3B-Inst & 60.89  & 80.59  & 46.31  & 86.05 & 50 & 0 & 0 & 0 & 0 & 50 \\ \hline
% Qwen-7B-Inst & \textbf{78.26}  & \textbf{83.13}  & 36.24  & \textbf{93.24}  & 50 & 0 & 0 & 0 & 0 & 50 \\ \hline
% Pythia-1.4B  & 19.17 & 4.47 & 51.90 & 23.61 & 50 & 0 & 0 & 0 & 0 & 50 \\ \hline
% Pythia-6.9B  & 23.67 & 34.55 & 55.26 & 35.60 & 50 & 0 & 0 & 0 & 0 & 50 \\ \hline
% Phi-3-Mini  & 55.91 & 75.30 & 99.10 & 75.32 & 50 & 0 & 0 & 0 & 0 & 50 \\ \hline
% Mistral-7B-Inst & 61.25 & 70.93  & 96.20 & 83.85 & 50 & 0 & 0 & 0 & 0 & 50 \\ \hline
% Gemma2-2B-It & 35.34 & 42.58  & 91.50 & 70.04 & 50 & 0 & 0 & 0 & 0 & 50 \\ \hline
% GPT4-o-Mini & 83.72 & 95.32  & 59.50 & 91.74 & 50 & 0 & 0 & 0 & 0 & 50 \\ \hline
% \end{tabular}
% \caption{The above table compares our approach with the Score Based Self Rewarding approach. The row labels correspond to the model name and the column labels correspond to the sub-categories. The metric used is accuracy where the higher values indicate better performance. }
% \label{tab:model_comparison}
% \end{table*}

% \begin{tabular}{|l||ccccc||ccccc|}
% \hline
% \multirow{}{}{Models} & \multicolumn{5}{c||}{Our Approach} & \multicolumn{5}{c|}{Self Rewarding} \\
% \cline{2-11}
%  & Chat & Code & Math & Safety & Random & Chat & Code & Math & Safety & Random \\ \hline\hline
% Llama-1B-Inst & 64.37 & 52.84 & 88.14 & 80.48 & X1 & 0 & 0 & 0 & 0 & X2 \\ \hline
% Llama-3B-Inst & 62.09 & 67.17 & \textbf{98.21} & 80.23 & X3 & 0 & 0 & 0 & 0 & X4 \\ \hline
% Llama-8B-Inst & 59.56 & 73.88 & 44.97 & 87.88 & X5 & 0 & 0 & 0 & 0 & X6 \\ \hline\hline
% Qwen-3B-Inst & 60.89  & 80.59  & 46.31  & 86.05 & X7 & 0 & 0 & 0 & 0 & X8 \\ \hline
% Qwen-7B-Inst & \textbf{78.26}  & \textbf{83.13}  & 36.24  & \textbf{93.24}  & X9 & 0 & 0 & 0 & 0 & X10 \\ \hline\hline
% Pythia-1.4B  & 0 & 0 & 0 & 0 & X11 & 0 & 0 & 0 & 0 & X12 \\ \hline
% Pythia-6.9B  & 0 & 0 & 0 & 0 & X13 & 0 & 0 & 0 & 0 & X14 \\ \hline\hline
% Phi-3-Mini(3.8B)  & 0 & 0 & 0 & 0 & X15 & 0 & 0 & 0 & 0 & X16 \\ \hline
% Phi-3-Small(7.4B)  & 0 & 0 & 0 & 0 & X17 & 0 & 0 & 0 & 0 & X18 \\ \hline \hline
% Mistral-7B-Inst & 61.25 & 70.93  & 96.20 & 83.85 & X19 & 0 & 0 & 0 & 0 & X20 \\ \hline
% \end{tabular}
% \caption{Reward Bench}
% \label{tab:model_comparison}
% \end{table*}


% \begin{table*}[h!]
% \centering
% \begin{tabular}{l|cccc|cccc}
% \hline
% \multirow{}{}{Models} & \multicolumn{4}{c|}{Our Approach} & \multicolumn{4}{c}{Self Rewarding} \\
% \cline{2-9}
%  & Chat & Code & Math & Safety & Chat & Code & Math & Safety \\
% \hline
% Llama-1B-Inst & 57.62 & 51.46 & 47.57 & 70.24 & 0 & 0 & 0 & 0 \\ \hline
% Llama-3b-Inst & 51.42 & 51.90 & 48.52 & 76.89 & 0 & 0 & 0 & 0 \\ \hline
% Qwen-3B-Inst & 60.98 & 53.07 & 56.33 & 68.96 & 0 & 0 & 0 & 0 \\ \hline
% Qwen-7B-Inst & \textbf{68.73} & \textbf{57.30} & \textbf{58.15} & \textbf{89.49} & 0 & 0 & 0 & 0 \\ \hline
% Mistral-7b-Inst & 54.00 & 52.48 & 52.04 & 71.52 & 0 & 0 & 0 & 0 \\ \hline
% Llama-8B-Inst & 50.64 & 54.97 & 48.70 & 68.25 & 0 & 0 & 0 & 0 \\ \hline

% \end{tabular}
% \caption{RM Bench}
% \label{tab:model_comparison}
% \end{table*}