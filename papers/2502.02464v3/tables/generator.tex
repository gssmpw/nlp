
\begin{table*}[!ht]
%\addtolength{\tabcolsep}{-0.65pt}
%\small
\centering
\resizebox{1.0\textwidth}{!}{  % Resize the table to fit the page width
\setlength\tabcolsep{3pt}
\begin{tabular}{@{}l | ccc| ccc | ccc |ccc | ccc | ccc @{}}
\toprule
  & \multicolumn{9}{c|}{\textbf{LLama V3 8B}} & \multicolumn{9}{c}{\textbf{LLama V3.1 8B}}\\

\multirow{3}{*}{\textbf{Retriever} }&\multicolumn{3}{c}{\textbf{NQ}} & \multicolumn{3}{c}{\textbf{TriviaQA}} & \multicolumn{3}{c|}{\textbf{WebQ}} & \multicolumn{3}{c}{\textbf{NQ}} & \multicolumn{3}{c}{\textbf{TriviaQA}} & \multicolumn{3}{c}{\textbf{WebQ}} \\

                      & EM & Recall  & Con & EM & Recall  & Con & EM & Recall  & Con  & EM & Recall  & Con & EM & Recall  & Con & EM & Recall  & Con \\
\midrule
\multirow{1}{*}{BM25 } &          14.90  &  26.68  & 19.91  & 42.10 & 56.90 & 50.11 &  10.23 & 24.95 & 16.92 & 12.82 & 27.14 & 20.27 & 40.13 &58.40 &51.40 & 9.25 & 24.92 & 17.22 \\

\midrule
\multirow{1}{*}{MSS} &       12.82 & 22.96 & 17.36 & 31.90 &44.27  & 37.75 &  7.38 & 18.9 &11.81  & 11.19 & 23.37 & 17.81 & 30.74 & 45.82 &38.91 & 6.88 & 19.30 & 12.40\\






\midrule
\multirow{1}{*}{Contriever}   &      15.29  & 27.36 & 20.99 & 36.25 &  49.52 &  49.52 &  10.67 & 28.28 &  20.22 &13.24 & 27.68 &  21.88 &35.29  & 50.96 &44.19 & 9.35 &28.71 & 20.32\\






\midrule
\multirow{1}{*}{DPR}  &      28.08 & 45.40 & 36.37 & 45.88 & 61.24 & 54.58 &  19.83 & 40.27   & 30.98  & 23.21 & 44.99 & 36.03 &43.62 & 62.61& 55.97 & 14.32 & 38.27 &28.98 \\






\midrule
\multirow{1}{*}{MSS+DPR}&       28.17 & 46.72 & 37.00 &  47.69 & 63.66 & 57.08 &  13.92 &  40.87   & 30.57 & 23.68 & 46.70 &37.53 & 45.72 & 65.24 & 58.53 & 13.92 &38.97 & 29.67\\






\bottomrule
\end{tabular}
}
\caption{Zero-shot results of in-context learning on
The test set of NQ, TriviaQA, and WebQ uses the LLama 3/3.1 8B Model as RAG }
\label{tab:qa_LLama_3_3.1}
\end{table*}

\begin{table*}[!ht]
%\addtolength{\tabcolsep}{-0.65pt}
%\small
\centering
\resizebox{1.0\textwidth}{!}{  % Resize the table to fit the page width
\setlength\tabcolsep{3pt}
\begin{tabular}{@{}l | ccc| ccc | ccc |ccc | ccc | ccc @{}}
\toprule
  & \multicolumn{9}{c|}{\textbf{Gemma-2-2b}} & \multicolumn{9}{c}{\textbf{Gemma-2-9b}}\\

\multirow{3}{*}{\textbf{Retriever} } & \multicolumn{3}{c}{\textbf{NQ}} & \multicolumn{3}{c}{\textbf{TriviaQA}} & \multicolumn{3}{c|}{\textbf{WebQ}} & \multicolumn{3}{c}{\textbf{NQ}} & \multicolumn{3}{c}{\textbf{TriviaQA}} & \multicolumn{3}{c}{\textbf{WebQ}} \\

&   EM & Recall  & Con & EM & Recall  & Con & EM & Recall  & Con  & EM & Recall  & Con & EM & Recall  & Con & EM & Recall  & Con \\
\midrule

\multirow{1}{*}{BM25 } &       14.02 & 25.55 & 18.53 & 43.28 & 52.78 & 47.01 & 14.71 & 37.74 & 27.21 & 19.81 & 26.95 & 22.05 & 57.55 & 65.53 & 60.29 & 14.96 & 24.87 & 20.13 \\






\midrule
\multirow{1}{*}{MSS} &      13.96 & 25.41 & 18.50 & 33.05 & 42.24 & 36.23 & 14.71 & 37.74 & 27.21 & 19.78 & 26.86 & 22.08 & 50.93 & 58.57 & 53.28 & 14.96 & 24.92 & 20.18 \\






\midrule
\multirow{1}{*}{Contriever}   &        13.96 & 25.41 & 18.50 & 33.05 & 42.24 & 36.23 & 14.71 & 37.74 & 27.21 & 19.78 & 26.86 & 22.08 & 50.93 & 58.57 & 53.28 & 14.96 & 24.92 & 20.18 \\


\midrule
\multirow{1}{*}{DPR}  &     13.99 & 25.44 & 18.53 & 33.05 & 42.24 & 36.23 & 14.71 & 37.74 & 27.21 & 19.78 & 26.86 & 22.08 & 50.93 & 58.57 & 53.28 & 14.96 & 24.92 & 20.18 \\

\midrule
\multirow{1}{*}{MSS+DPR}&       13.96 & 25.41 & 18.50 & 33.05 & 42.24 & 36.23 & 14.71 & 37.74 & 27.21 & 19.78 & 26.86 & 22.08 & 50.93 & 58.57 & 53.28 & 14.96 & 24.92 & 20.18 \\

\bottomrule
\end{tabular}
}
\caption{
Zero-shot results of in-context learning on
The test set of NQ, TriviaQA, and WebQ uses the Gemma Model as RAG.
}
\label{tab:qa_Gemma}
\end{table*}
\begin{table*}[!ht]
%\addtolength{\tabcolsep}{-0.65pt}
%\small
\centering
\resizebox{1.0\textwidth}{!}{  % Resize the table to fit the page width
\setlength\tabcolsep{3pt}
\begin{tabular}{@{}l | ccc| ccc | ccc |ccc | ccc | ccc @{}}
\toprule
 &  \multicolumn{9}{c|}{\textbf{Llama-2-13b-hf}} & \multicolumn{9}{c}{\textbf{Mistral-7B-v0.1}}\\

\multirow{3}{*}{\textbf{Retriever} } & \multicolumn{3}{c}{\textbf{NQ}} & \multicolumn{3}{c}{\textbf{TriviaQA}} & \multicolumn{3}{c|}{\textbf{WebQ}} & \multicolumn{3}{c}{\textbf{NQ}} & \multicolumn{3}{c}{\textbf{TriviaQA}} & \multicolumn{3}{c}{\textbf{WebQ}} \\

&   EM & Recall  & Con & EM & Recall  & Con & EM & Recall  & Con  & EM & Recall  & Con & EM & Recall  & Con & EM & Recall  & Con \\
\midrule

\multirow{1}{*}{BM25 } 
&        21.14 & 30.82 & 24.46 & 57.90 & 65.27 & 59.57 & 19.54 & 37.38 & 27.51 & 11.19 & 13.45 & 11.80 & 52.85 & 58.11 & 53.82 & 6.40 & 8.46 & 6.84 \\

\midrule
\multirow{1}{*}{MSS} 
&       21.52 & 30.92 & 24.18 & 51.75 & 58.58 & 53.35 & 20.62 & 39.45 & 29.68 & 11.08 & 13.33 & 11.66 & 42.69 & 47.12 & 43.40 & 6.40 & 8.46 & 6.84 \\


\midrule
\multirow{1}{*}{Contriever}   
&       20.47 & 30.13 & 23.85 & 42.69 & 47.12 & 43.40 & 19.98 & 37.74 & 27.61 & 11.08 & 13.33 & 11.66 & 42.69 & 47.12 & 43.40 & 6.40 & 8.46 & 6.84 \\


\midrule
\multirow{1}{*}{DPR}  
&     21.94 & 31.36 & 24.88 & 51.07 & 57.97 & 52.71 & 19.83 & 37.35 & 28.05 & 11.11 & 13.36 & 11.69 & 42.69 & 47.12 & 43.40 & 6.40 & 8.46 & 6.84 \\


\midrule
\multirow{1}{*}{MSS+DPR}
&       21.47 & 31.26 & 24.60 & 51.35 & 58.26 & 53.01 & 19.83 & 37.37 & 27.61 & 11.08 & 13.33 & 11.66 & 42.69 & 47.12 & 43.40 & 6.40 & 8.46 & 6.84 \\


\bottomrule
\end{tabular}
}
\caption{
Zero-shot results of in-context learning on
the test set of NQ, TriviaQA, and WebQ  using Llama-2-13b-hf and Mistral-7B-v0.1 as RAG
}
\label{tab:qa_Llama-2-13b}
\end{table*}
