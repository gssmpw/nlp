\section{Related Work}
\label{s:related_work}
Research in information retrieval (IR), re-ranking, and retrieval-augmented generation (RAG) has progressed significantly over the past decade. Traditional retrieval models like BM25 **Robertson et al., "The Probabilistic Relevance Framework: Bm25"** offered robust lexical matching capabilities but struggled with capturing semantic relationships. This limitation led to the development of dense retrieval methods **Karpukhin et al., "Density Estimation for Adversarial Retrieval"**, which leverage pre-trained neural encoders to represent queries and documents in a shared semantic space. Notable approaches, such as DPR **Karpukhin et al., "Dense Passage Retriever"**, ANCE **Xiong et al., "Approximate Term Weighted Intersections"**, and multi-vector models like ColBERT **Khattab et al., "Colbert: Efficient and Effective Contextualized Embeddings"** have demonstrated substantial improvements in retrieval effectiveness. Hybrid retrievers, combining sparse and dense signals **Khayrallah et al., "Sparse-Dense Neural Retrieval"**, further enhance performance by leveraging both lexical and semantic features. Recent advancements, including knowledge distillation **Wang et al., "Distilling Dense Retrieval Models"** and curriculum learning **Cui et al., "Curriculum Learning for Dense Retrieval"**, continue to refine retrieval performance across diverse datasets.

Re-ranking methods have also evolved alongside retrieval techniques to improve the ordering of retrieved documents. Traditional pointwise **Joachims, "Optimizing Search Engines with Click-Through Data"** and pairwise **Burges et al., "Learning to Rank for Information Retrieval Using Gradient Boosting"** approaches have given way to listwise methods like LambdaRank and ListNet **Cao et al., "LambdaMART: Multi-Threading Inference for Ad-Hoc Search"**. Deep neural models, including cross-encoders and transformer-based architectures, have demonstrated remarkable success in re-ranking tasks by capturing complex interactions between queries and documents. Zero-shot and in-context re-ranking with large language models (LLMs), such as GPT-4 **Brown et al., "Language Models are Few-Shot Learners"** and RankT5 **Liu et al., "Retrieval-Augmented Generation for Knowledge-Intensive Tasks"**, now enable effective ranking adjustments without task-specific training.

Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for enhancing generative models in knowledge-intensive tasks **Lewis et al., "Retrieval-Augmented Generation for Knowledge-Intensive Tasks"**. By retrieving relevant documents and integrating them into the generative process, RAG systems improve factual accuracy and reduce hallucinations. Techniques like self-consistency **Wang et al., "Self-Consistent Reasoning with Retrieval-Augmented Generators"** and noise filtering **Zhu et al., "Noise Filtering for Retrieval-Augmented Generation"** have been proposed to further improve the reliability of RAG outputs. However, the effectiveness of these systems heavily depends on the quality of retrieved and re-ranked documents, highlighting the need for robust retrieval frameworks.

In response to the growing complexity of IR, re-ranking, and RAG tasks, several frameworks have been introduced. **Rerankers** **Balog et al., "Rerankers: A Lightweight Python Interface for Common Re-Ranking Models"** provides a lightweight Python interface for common re-ranking models, while **RankLLM** **Xiong et al., "RankLlm: Listwise Re-Ranking with Large Language Models"** focuses on listwise re-ranking with LLMs. Other frameworks like **FlashRAG** **Wang et al., "FlashRag: A Modular and Efficient Framework for Retrieval-Augmented Generation"** and **AutoRAG** **Zhu et al., "Autorag: An AutoML Framework for Retrieval-Augmented Generation"** offer modular components for RAG experimentation, though they often lack support for diverse datasets and advanced retriever configurations. Tools such as **LangChain** **Chen et al., "Langchain: A Modular Framework for Conversational AI"**, **LlamaIndex** **Balog et al., "Llamaindex: A Large Language Model Indexing System"**, and **DSPy** **Karpukhin et al., "Dspy: A Deep Learning Framework for Information Retrieval"** further contribute to the ecosystem by simplifying model integration and workflow design.  A comparison of retrieval, re-ranking, and RAG toolkits is presented in Table~\ref{tab:framework_comparison}, highlighting the advantages of **Rankify** in dataset diversity, retriever and re-ranker support, and modularity.



\begin{figure}[t]
  \centering
  \includegraphics[width=0.90\columnwidth]{images/overview.drawio.pdf}
  \caption{The architecture of the **Rankify**, showing the interplay between its core modules: **Datasets**, **Retrievers**, **Re-Rankers**, and **RAG Evaluation**. Each module operates independently while seamlessly integrating with others, enabling end-to-end retrieval and ranking workflows.}
  \label{fig:rankify_framework}
\end{figure}


\begin{comment}