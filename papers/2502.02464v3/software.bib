@inproceedings{dpr,
  title={Pretrained transformers for text ranking: BERT and beyond},
  author={Yates, Andrew and Nogueira, Rodrigo and Lin, Jimmy},
  booktitle={Proceedings of the 14th ACM International Conference on web search and data mining},
  pages={1154--1156},
  year={2021}
}

@article{monobert,
  title={Multi-stage document ranking with BERT},
  author={Nogueira, Rodrigo and Yang, Wei and Cho, Kyunghyun and Lin, Jimmy},
  journal={arXiv preprint arXiv:1910.14424},
  year={2019}
}
@article{singhal2001modern,
  title={Modern information retrieval: A brief overview},
  author={Singhal, Amit and others},
  journal={IEEE Data Eng. Bull.},
  volume={24},
  number={4},
  pages={35--43},
  year={2001}
}
@inproceedings{hoffart2011knowledge,
  title={A knowledge-based approach to named entity disambiguation},
  author={Hoffart, Johannes and Yosef, Mohamed Amir and Bordino, Ilaria and F{\"u}rstenau, Hagen and Pinkal, Manfred and Spaniol, Marc and Taneva, Bilyana and Thater, Stefan and Weikum, Gerhard},
  booktitle={Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing},
  pages={782--792},
  year={2011}
}
@article{geva-etal-2021-aristotle,
    title = "Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies",
    author = "Geva, Mor  and
      Khashabi, Daniel  and
      Segal, Elad  and
      Khot, Tushar  and
      Roth, Dan  and
      Berant, Jonathan",
    editor = "Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.tacl-1.21/",
    doi = "10.1162/tacl_a_00370",
    pages = "346--361",
    abstract = "A key limitation in current datasets for multi-hop reasoning is that the required steps for answering the question are mentioned in it explicitly. In this work, we introduce StrategyQA, a question answering (QA) benchmark where the required reasoning steps are implicit in the question, and should be inferred using a strategy. A fundamental challenge in this setup is how to elicit such creative questions from crowdsourcing workers, while covering a broad range of potential strategies. We propose a data collection procedure that combines term-based priming to inspire annotators, careful control over the annotator population, and adversarial filtering for eliminating reasoning shortcuts. Moreover, we annotate each question with (1) a decomposition into reasoning steps for answering it, and (2) Wikipedia paragraphs that contain the answers to each step. Overall, StrategyQA includes 2,780 examples, each consisting of a strategy question, its decomposition, and evidence paragraphs. Analysis shows that questions in StrategyQA are short, topic-diverse, and cover a wide range of strategies. Empirically, we show that humans perform well (87{\%}) on this task, while our best baseline reaches an accuracy of {\ensuremath{\sim}} 66{\%}."
}
@inproceedings{tafjord-etal-2019-quartz,
    title = "{Q}ua{RT}z: An Open-Domain Dataset of Qualitative Relationship Questions",
    author = "Tafjord, Oyvind  and
      Gardner, Matt  and
      Lin, Kevin  and
      Clark, Peter",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1608/",
    doi = "10.18653/v1/D19-1608",
    pages = "5941--5946",
    abstract = "We introduce the first open-domain dataset, called QuaRTz, for reasoning about textual qualitative relationships. QuaRTz contains general qualitative statements, e.g., {\textquotedblleft}A sunscreen with a higher SPF protects the skin longer.{\textquotedblright}, twinned with 3864 crowdsourced situated questions, e.g., {\textquotedblleft}Billy is wearing sunscreen with a lower SPF than Lucy. Who will be best protected from the sun?{\textquotedblright}, plus annotations of the properties being compared. Unlike previous datasets, the general knowledge is textual and not tied to a fixed set of relationships, and tests a system`s ability to comprehend and apply textual qualitative knowledge in a novel setting. We find state-of-the-art results are substantially (20{\%}) below human performance, presenting an open challenge to the NLP community."
}
@inproceedings{lee-etal-2020-contextualized,
    title = "Contextualized Sparse Representations for Real-Time Open-Domain Question Answering",
    author = "Lee, Jinhyuk  and
      Seo, Minjoon  and
      Hajishirzi, Hannaneh  and
      Kang, Jaewoo",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.85/",
    doi = "10.18653/v1/2020.acl-main.85",
    pages = "912--919",
    abstract = "Open-domain question answering can be formulated as a phrase retrieval problem, in which we can expect huge scalability and speed benefit but often suffer from low accuracy due to the limitation of existing phrase representation models. In this paper, we aim to improve the quality of each phrase embedding by augmenting it with a contextualized sparse representation (Sparc). Unlike previous sparse vectors that are term-frequency-based (e.g., tf-idf) or directly learned (only few thousand dimensions), we leverage rectified self-attention to indirectly learn sparse vectors in n-gram vocabulary space. By augmenting the previous phrase retrieval model (Seo et al., 2019) with Sparc, we show 4{\%}+ improvement in CuratedTREC and SQuAD-Open. Our CuratedTREC score is even better than the best known retrieve {\&} read model with at least 45x faster inference speed."
}
@inproceedings{piryani2024chroniclingamericaqa,
  title={Chroniclingamericaqa: A large-scale question answering dataset based on historical american newspaper pages},
  author={Piryani, Bhawna and Mozafari, Jamshid and Jatowt, Adam},
  booktitle={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2038--2048},
  year={2024}
}
@inproceedings{wang2022archivalqa,
  title={Archivalqa: A large-scale benchmark dataset for open-domain question answering over historical news collections},
  author={Wang, Jiexin and Jatowt, Adam and Yoshikawa, Masatoshi},
  booktitle={Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={3025--3035},
  year={2022}
}
@InProceedings{karpukhin2020dense,
  title={Dense Passage Retrieval for Open-Domain Question Answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
  year={2020},
  url = "https://www.aclweb.org/anthology/2020.emnlp-main.550",
}

@inproceedings{xiong2021approximate,
title={Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval},
author={Lee Xiong and Chenyan Xiong and Ye Li and Kwok-Fung Tang and Jialin Liu and Paul N. Bennett and Junaid Ahmed and Arnold Overwijk},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=zeFrfgyZln}
}
@inproceedings{gillick-etal-2019-learning,
    title = "Learning Dense Representations for Entity Retrieval",
    author = "Gillick, Daniel  and
      Kulkarni, Sayali  and
      Lansing, Larry  and
      Presta, Alessandro  and
      Baldridge, Jason  and
      Ie, Eugene  and
      Garcia-Olano, Diego",
    booktitle = "Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)",
    month = nov,
    year = "2019",
    url = "https://aclanthology.org/K19-1049",
    doi = "10.18653/v1/K19-1049",
}
@inproceedings{lee-etal-2019-latent,
    title = "Latent Retrieval for Weakly Supervised Open Domain Question Answering",
    author = "Lee, Kenton  and
      Chang, Ming-Wei  and
      Toutanova, Kristina",
    booktitle = "Proc. ACL",
    month = jul,
    year = "2019",
    pages = "6086--6096",
}
@inproceedings{chen2022out,
  title={Out-of-domain semantics to the rescue! zero-shot hybrid retrieval models},
  author={Chen, Tao and Zhang, Mingyang and Lu, Jing and Bendersky, Michael and Najork, Marc},
  booktitle={European Conference on Information Retrieval},
  pages={95--110},
  year={2022},
  organization={Springer}
}
@misc{abdallah2025asrankzeroshotrerankinganswer,
      title={ASRank: Zero-Shot Re-Ranking with Answer Scent for Document Retrieval}, 
      author={Abdelrahman Abdallah and Jamshid Mozafari and Bhawna Piryani and Adam Jatowt},
      year={2025},
      eprint={2501.15245},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.15245}, 
}
@misc{yoon2024listt5listwisererankingfusionindecoder,
      title={ListT5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval}, 
      author={Soyoung Yoon and Eunbi Choi and Jiyeon Kim and Hyeongu Yun and Yireun Kim and Seung-won Hwang},
      year={2024},
      eprint={2402.15838},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2402.15838}, 
}
@article{huang2024pairdistill,
  title={PairDistill: Pairwise Relevance Distillation for Dense Retrieval},
  author={Huang, Chao-Wei and Chen, Yun-Nung},
  journal={arXiv preprint arXiv:2410.01383},
  year={2024}
}

@article{rankgpt,
  title={Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent},
  author={Weiwei Sun and Lingyong Yan and Xinyu Ma and Pengjie Ren and Dawei Yin and Zhaochun Ren},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.09542}
}

@article{sinhababu2024few,
  title={Few-shot Prompting for Pairwise Ranking: An Effective Non-Parametric Retrieval Model},
  author={Sinhababu, Nilanjan and Parry, Andrew and Ganguly, Debasis and Samanta, Debasis and Mitra, Pabitra},
  journal={arXiv preprint arXiv:2409.17745},
  year={2024}
}
@article{qin2023large,
  title={Large language models are effective text rankers with pairwise ranking prompting},
  author={Qin, Zhen and Jagerman, Rolf and Hui, Kai and Zhuang, Honglei and Wu, Junru and Yan, Le and Shen, Jiaming and Liu, Tianqi and Liu, Jialu and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2306.17563},
  year={2023}
}
@article{sachan2022improving,
  title = "Improving Passage Retrieval with Zero-Shot Question Generation",
  author = "Sachan, Devendra Singh and Lewis, Mike and Joshi, Mandar and Aghajanyan, Armen and Yih, Wen-tau and Pineau, Joelle and Zettlemoyer, Luke",
  booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/2204.07496",
  year = "2022"
}
@inproceedings{abdallah-etal-2025-dynrank,
    title = "{D}yn{R}ank: Improve Passage Retrieval with Dynamic Zero-Shot Prompting Based on Question Classification",
    author = "Abdallah, Abdelrahman Elsayed Mahmoud  and
      Mozafari, Jamshid  and
      Piryani, Bhawna  and
      M.Abdelgwad, Mohammed  and
      Jatowt, Adam",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.319/",
    pages = "4768--4778",
    abstract = "This paper presents DynRank, a novel framework for enhancing passage retrieval in open-domain question-answering systems through dynamic zero-shot question classification. Traditional approaches rely on static prompts and pre-defined templates, which may limit model adaptability across different questions and contexts. In contrast, DynRank introduces a dynamic prompting mechanism, leveraging a pre-trained question classification model that categorizes questions into fine-grained types. Based on these classifications, contextually relevant prompts are generated, enabling more effective passage retrieval. We integrate DynRank into existing retrieval frameworks and conduct extensive experiments on multiple QA benchmark datasets."
}
@inproceedings{yang2019hybrid,
  title={A hybrid retrieval-generation neural conversation model},
  author={Yang, Liu and Hu, Junjie and Qiu, Minghui and Qu, Chen and Gao, Jianfeng and Croft, W Bruce and Liu, Xiaodong and Shen, Yelong and Liu, Jingjing},
  booktitle={Proceedings of the 28th ACM international conference on information and knowledge management},
  pages={1341--1350},
  year={2019}
}
@book{chowdhury2010introduction,
  title={Introduction to modern information retrieval},
  author={Chowdhury, Gobinda G},
  year={2010},
  publisher={Facet publishing}
}
@book{croft2010search,
  title={Search engines: Information retrieval in practice},
  author={Croft, W Bruce and Metzler, Donald and Strohman, Trevor},
  volume={520},
  year={2010},
  publisher={Addison-Wesley Reading}
}
@inproceedings{long2024generative,
  title={Generative multi-modal knowledge retrieval with large language models},
  author={Long, Xinwei and Zeng, Jiali and Meng, Fandong and Ma, Zhiyuan and Zhang, Kaiyan and Zhou, Bowen and Zhou, Jie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={18733--18741},
  year={2024}
}

@inbook{10.5555/3454287.3455008,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and K\"{o}pf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
title = {PyTorch: an imperative style, high-performance deep learning library},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {721},
numpages = {12}
}

@inproceedings{10.5555/3026877.3026899,
author = {Abadi, Mart\'{\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
title = {TensorFlow: a system for large-scale machine learning},
year = {2016},
isbn = {9781931971331},
publisher = {USENIX Association},
address = {USA},
booktitle = {Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation},
pages = {265–283},
numpages = {19},
location = {Savannah, GA, USA},
series = {OSDI'16}
}
@article{xiong2024search,
  title={When search engine services meet large language models: visions and challenges},
  author={Xiong, Haoyi and Bian, Jiang and Li, Yuchen and Li, Xuhong and Du, Mengnan and Wang, Shuaiqiang and Yin, Dawei and Helal, Sumi},
  journal={IEEE Transactions on Services Computing},
  year={2024},
  publisher={IEEE}
}

@article{khamnuansin2024mrrank,
  title={MrRank: Improving Question Answering Retrieval System through Multi-Result Ranking Model},
  author={Khamnuansin, Danupat and Chalothorn, Tawunrat and Chuangsuwanich, Ekapol},
  journal={arXiv preprint arXiv:2406.05733},
  year={2024}
}
@inproceedings{liu2024information,
  title={Information Retrieval Meets Large Language Models},
  author={Liu, Zheng and Zhou, Yujia and Zhu, Yutao and Lian, Jianxun and Li, Chaozhuo and Dou, Zhicheng and Lian, Defu and Nie, Jian-Yun},
  booktitle={Companion Proceedings of the ACM on Web Conference 2024},
  pages={1586--1589},
  year={2024}
}
@article{wang2024utilizing,
  title={Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges},
  author={Wang, Jiajia and Huang, Jimmy Xiangji and Tu, Xinhui and Wang, Junmei and Huang, Angela Jennifer and Laskar, Md Tahmid Rahman and Bhuiyan, Amran},
  journal={ACM Computing Surveys},
  volume={56},
  number={7},
  pages={1--33},
  year={2024},
  publisher={ACM New York, NY}
}
@article{rocketqav2,
  title={Rocketqav2: A joint training method for dense passage retrieval and passage re-ranking},
  author={Ren, Ruiyang and Qu, Yingqi and Liu, Jing and Zhao, Wayne Xin and She, Qiaoqiao and Wu, Hua and Wang, Haifeng and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2110.07367},
  year={2021}
}
@article{bm25,
  title={Okapi at TREC-3},
  author={Robertson, Stephen E and Walker, Steve and Jones, Susan and Hancock-Beaulieu, Micheline M and Gatford, Mike and others},
  journal={Nist Special Publication Sp},
  volume={109},
  pages={109},
  year={1995},
  publisher={National Instiute of Standards \& Technology}
}
@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}
@article{abdallah2023generator,
  title={Generator-retriever-generator: A novel approach to open-domain question answering},
  author={Abdallah, Abdelrahman and Jatowt, Adam},
  journal={arXiv preprint arXiv:2307.11278},
  year={2023}
}
@inproceedings{abdallah2024arabicaqa,
  title={Arabicaqa: A comprehensive dataset for arabic question answering},
  author={Abdallah, Abdelrahman and Kasem, Mahmoud and Abdalla, Mahmoud and Mahmoud, Mohamed and Elkasaby, Mohamed and Elbendary, Yasser and Jatowt, Adam},
  booktitle={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2049--2059},
  year={2024}
}
@article{mozafari2024exploring,
  title={Exploring Hint Generation Approaches in Open-Domain Question Answering},
  author={Mozafari, Jamshid and Abdallah, Abdelrahman and Piryani, Bhawna and Jatowt, Adam},
  journal={arXiv preprint arXiv:2409.16096},
  year={2024}
}
@inproceedings{yamada2021bpr,
  title={Efficient Passage Retrieval with Hashing for Open-domain Question Answering},
  author={Ikuya Yamada and Akari Asai and Hannaneh Hajishirzi},
  booktitle={ACL},
  year={2021}
}
@article{sachan2021end,
  title={End-to-end training of neural retrievers for open-domain question answering},
  author={Sachan, Devendra Singh and Patwary, Mostofa and Shoeybi, Mohammad and Kant, Neel and Ping, Wei and Hamilton, William L and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:2101.00408},
  year={2021}
}
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}
@article{ni2021large,
  title={Large dual encoders are generalizable retrievers},
  author={Ni, Jianmo and Qu, Chen and Lu, Jing and Dai, Zhuyun and {\'A}brego, Gustavo Hern{\'a}ndez and Ma, Ji and Zhao, Vincent Y and Luan, Yi and Hall, Keith B and Chang, Ming-Wei and others},
  journal={arXiv preprint arXiv:2112.07899},
  year={2021}
}
@article{wang2020minilmv2,
  title={Minilmv2: Multi-head self-attention relation distillation for compressing pretrained transformers},
  author={Wang, Wenhui and Bao, Hangbo and Huang, Shaohan and Dong, Li and Wei, Furu},
  journal={arXiv preprint arXiv:2012.15828},
  year={2020}
}

@ARTICLE{tamber2023scaling,
  title   = {Scaling Down, LiTting Up: Efficient Zero-Shot Listwise Reranking with Seq2seq Encoder-Decoder Models},
  author  = {Manveer Singh Tamber and Ronak Pradeep and Jimmy Lin},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2312.16098}
}
@misc{chen2024attentionlargelanguagemodels,
      title={Attention in Large Language Models Yields Efficient Zero-Shot Re-Rankers}, 
      author={Shijie Chen and Bernal Jiménez Gutiérrez and Yu Su},
      year={2024},
      eprint={2410.02642},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.02642}, 
}
@article{rashid2024ecorank,
  title={EcoRank: Budget-Constrained Text Re-ranking Using Large Language Models},
  author={Rashid, Muhammad Shihab and Meem, Jannat Ara and Dong, Yue and Hristidis, Vagelis},
  journal={arXiv preprint arXiv:2402.10866},
  year={2024}
}
@inproceedings{baldelli2024twolar,
  title={TWOLAR: a TWO-step LLM-Augmented distillation method for passage Reranking},
  author={Baldelli, Davide and Jiang, Junfeng and Aizawa, Akiko and Torroni, Paolo},
  booktitle={European Conference on Information Retrieval},
  pages={470--485},
  year={2024},
  organization={Springer}
}
@article{gao2023retrieval,
  title={Retrieval-augmented generation for large language models: A survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  journal={arXiv preprint arXiv:2312.10997},
  year={2023}
}
@article{behnamghader2024llm2vec,
  title={Llm2vec: Large language models are secretly powerful text encoders},
  author={BehnamGhader, Parishad and Adlakha, Vaibhav and Mosbach, Marius and Bahdanau, Dzmitry and Chapados, Nicolas and Reddy, Siva},
  journal={arXiv preprint arXiv:2404.05961},
  year={2024}
}
@misc{laitz2024inranker,
      title={InRanker: Distilled Rankers for Zero-shot Information Retrieval},
      author={Thiago Laitz and Konstantinos Papakostas and Roberto Lotufo and Rodrigo Nogueira},
      year={2024},
      eprint={2401.06910},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}
@misc{Damodaran2024FlashRank,
  author       = {Damodaran, P.},
  title        = {FlashRank, Lightest and Fastest 2nd Stage Reranker for search pipelines},
  year         = {2024},
  version      = {0.2.4},
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.11093524},
  url          = {https://doi.org/10.5281/zenodo.11093524}
}

@article{pradeep2023rankzephyr,
  title={RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!},
  author={Pradeep, Ronak and Sharifymoghaddam, Sahel and Lin, Jimmy},
  journal={arXiv preprint arXiv:2312.02724},
  year={2023}
}
@article{izacard2020leveraging,
  title={Leveraging passage retrieval with generative models for open domain question answering},
  author={Izacard, Gautier and Grave, Edouard},
  journal={arXiv preprint arXiv:2007.01282},
  year={2020}
}
@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}
@article{fang2024enhancing,
  title={Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training},
  author={Fang, Feiteng and Bai, Yuelin and Ni, Shiwen and Yang, Min and Chen, Xiaojun and Xu, Ruifeng},
  journal={arXiv preprint arXiv:2405.20978},
  year={2024}
}
@article{kamalloo2023evaluating,
  title={Evaluating open-domain question answering in the era of large language models},
  author={Kamalloo, Ehsan and Dziri, Nouha and Clarke, Charles LA and Rafiei, Davood},
  journal={arXiv preprint arXiv:2305.06984},
  year={2023}
}
@misc{chase2022langchain,
  title={LangChain: Building applications with LLMs through composability},
  author={Chase, Harrison},
  year={2022},
  note={Available at \url{https://www.langchain.com}},
  url={https://www.langchain.com}
}
@article{khattab2023dspy,
  title={Dspy: Compiling declarative language model calls into self-improving pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T and Moazam, Hanna and others},
  journal={arXiv preprint arXiv:2310.03714},
  year={2023}
}
@article{FlashRAG,
    author={Jiajie Jin and
            Yutao Zhu and
            Xinyu Yang and
            Chenghao Zhang and
            Zhicheng Dou},
    title={FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research},
    journal={CoRR},
    volume={abs/2405.13576},
    year={2024},
    url={https://arxiv.org/abs/2405.13576},
    eprinttype={arXiv},
    eprint={2405.13576}
}
@software{Liu_LlamaIndex_2022,
author = {Liu, Jerry},
doi = {10.5281/zenodo.1234},
month = {11},
title = {{LlamaIndex}},
url = {https://github.com/jerryjliu/llama_index},
year = {2022}
}
@article{manakul2023selfcheckgpt,
  title={Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models},
  author={Manakul, Potsawee and Liusie, Adian and Gales, Mark JF},
  journal={arXiv preprint arXiv:2303.08896},
  year={2023}
}
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}
@INPROCEEDINGS{Lin_etal_SIGIR2021_Pyserini,
   author = "Jimmy Lin and Xueguang Ma and Sheng-Chieh Lin and Jheng-Hong Yang and Ronak Pradeep and Rodrigo Nogueira",
   title = "{Pyserini}: A {Python} Toolkit for Reproducible Information Retrieval Research with Sparse and Dense Representations",
   booktitle = "Proceedings of the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021)",
   year = 2021,
   pages = "2356--2362",
}
@article{yu2024localrqa,
  title={LocalRQA: From Generating Data to Locally Training, Testing, and Deploying Retrieval-Augmented QA Systems},
  author={Yu, Xiao and Lu, Yunan and Yu, Zhou},
  journal={arXiv preprint arXiv:2403.00982},
  year={2024}
}

@article{abane2024fastrag,
  title={FastRAG: Retrieval Augmented Generation for Semi-structured Data},
  author={Abane, Amar and Bekri, Anis and Battou, Abdella},
  journal={arXiv preprint arXiv:2411.13773},
  year={2024}
}
@article{jin2024flashrag,
  title={FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research},
  author={Jin, Jiajie and Zhu, Yutao and Yang, Xinyu and Zhang, Chenghao and Dou, Zhicheng},
  journal={arXiv preprint arXiv:2405.13576},
  year={2024}
}
@misc{clavi2024rerankers,
      title={rerankers: A Lightweight Python Library to Unify Ranking Methods}, 
      author={Benjamin Clavié},
      year={2024},
      eprint={2408.17344},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2408.17344}, 
}
@misc{pradeep2023rankvicunazeroshotlistwisedocument,
      title={RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large Language Models}, 
      author={Ronak Pradeep and Sahel Sharifymoghaddam and Jimmy Lin},
      year={2023},
      eprint={2309.15088},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2309.15088}, 
}


@article{liu2017listnet,
  title={Listnet-based object proposals ranking},
  author={Liu, Yaqi and Zhang, Xiaoyu and Zhu, Xiaobin and Guan, Qingxiao and Zhao, Xianfeng},
  journal={Neurocomputing},
  volume={267},
  pages={182--194},
  year={2017},
  publisher={Elsevier}
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{burges2010ranknet,
  title={From ranknet to lambdarank to lambdamart: An overview},
  author={Burges, Christopher JC},
  journal={Learning},
  volume={11},
  number={23-581},
  pages={81},
  year={2010}
}
@inproceedings{jia2021pairrank,
  title={Pairrank: Online pairwise learning to rank by divide-and-conquer},
  author={Jia, Yiling and Wang, Huazheng and Guo, Stephen and Wang, Hongning},
  booktitle={Proceedings of the web conference 2021},
  pages={146--157},
  year={2021}
}
@inproceedings{cao2007learning,
  title={Learning to rank: from pairwise approach to listwise approach},
  author={Cao, Zhe and Qin, Tao and Liu, Tie-Yan and Tsai, Ming-Feng and Li, Hang},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={129--136},
  year={2007}
}
@inproceedings{cinar2020adaptive,
  title={Adaptive pointwise-pairwise learning-to-rank for content-based personalized recommendation},
  author={Cinar, Yagmur Gizem and Renders, Jean-Michel},
  booktitle={Proceedings of the 14th ACM Conference on Recommender Systems},
  pages={414--419},
  year={2020}
}
@article{zhu2021leveraging,
  title={Leveraging pointwise prediction with learning to rank for top-N recommendation},
  author={Zhu, Nengjun and Cao, Jian and Lu, Xinjiang and Gu, Qi},
  journal={World Wide Web},
  volume={24},
  pages={375--396},
  year={2021},
  publisher={Springer}
}
@inproceedings{DBLP:conf/ecir/GaoDCFDC21,
  author    = {Luyu Gao and
               Zhuyun Dai and
               Tongfei Chen and
               Zhen Fan and
               Benjamin Van Durme and
               Jamie Callan},
  editor    = {Djoerd Hiemstra and
               Marie{-}Francine Moens and
               Josiane Mothe and
               Raffaele Perego and
               Martin Potthast and
               Fabrizio Sebastiani},
  title     = {Complement Lexical Retrieval Model with Semantic Residual Embeddings},
  booktitle = {Advances in Information Retrieval - 43rd European Conference on {IR}
               Research, {ECIR} 2021, Virtual Event, March 28 - April 1, 2021, Proceedings,
               Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {12656},
  pages     = {146--160},
  publisher = {Springer},
  year      = {2021},
  url       = {https://doi.org/10.1007/978-3-030-72113-8\_10},
  doi       = {10.1007/978-3-030-72113-8\_10},
  timestamp = {Tue, 30 Mar 2021 18:55:01 +0200},
  biburl    = {https://dblp.org/rec/conf/ecir/GaoDCFDC21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{sourty2022cherche,
  title={Cherche: A new tool to rapidly implement pipelines in information retrieval},
  author={Sourty, Rapha{\"e}l and Moreno, Jose G and Tamine, Lynda and Servant, Fran{\c{c}}ois-Paul},
  booktitle={Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={3283--3288},
  year={2022}
}
@inproceedings{ma2021replication,
author = {Ma, Xueguang and Sun, Kai and Pradeep, Ronak and Li, Minghan and Lin, Jimmy},
title = {Another Look at DPR: Reproduction of Training and Replication of Retrieval},
year = {2022},
isbn = {978-3-030-99735-9},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-99736-6_41},
doi = {10.1007/978-3-030-99736-6_41},
abstract = {Text retrieval using learned dense representations has recently emerged as a promising alternative to “traditional” text retrieval using sparse bag-of-words representations. One foundational work that has garnered much attention is the dense passage retriever (DPR) proposed by Karpukhin et al. for end-to-end open-domain question answering. This work presents a reproduction and replication study of DPR. We first verify the reproducibility of the DPR model checkpoints by training passage and query encoders from scratch using two different implementations: the original code released by the authors and another independent codebase. After that, we conduct a detailed replication study of the retrieval stage, starting with model checkpoints provided by the authors but with an independent implementation from our group’s Pyserini IR toolkit and PyGaggle neural text ranking library. Although our experimental results largely verify the claims of the original DPR paper, we arrive at two important additional findings: First, it appears that the original authors under-report the effectiveness of the BM25 baseline and hence also dense–sparse hybrid retrieval results. Second, by incorporating evidence from the retriever and improved answer span scoring, we manage to improve end-to-end question answering effectiveness using the same DPR models.},
booktitle = {Advances in Information Retrieval: 44th European Conference on IR Research, ECIR 2022, Stavanger, Norway, April 10–14, 2022, Proceedings, Part I},
pages = {613–626},
numpages = {14},
keywords = {Dense retrieval, Open-domain QA},
location = {Stavanger, Norway}
}

@misc{khattab2020colbertefficienteffectivepassage,
      title={ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT}, 
      author={Omar Khattab and Matei Zaharia},
      year={2020},
      eprint={2004.12832},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2004.12832}, 
}
@inproceedings{qu-etal-2021-rocketqa,
    title = "{R}ocket{QA}: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering",
    author = "Qu, Yingqi  and
      Ding, Yuchen  and
      Liu, Jing  and
      Liu, Kai  and
      Ren, Ruiyang  and
      Zhao, Wayne Xin  and
      Dong, Daxiang  and
      Wu, Hua  and
      Wang, Haifeng",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    url = "https://aclanthology.org/2021.naacl-main.466",
    doi = "10.18653/v1/2021.naacl-main.466"
}
@ARTICLE{spar,
      title={Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?}, 
      author={Xilun Chen and Kushal Lakhotia and Barlas Oğuz and Anchit Gupta and Patrick Lewis and Stan Peshterliev and Yashar Mehdad and Sonal Gupta and Wen-tau Yih},
      year={2021},
      journal = "arXiv:2110.06918"
}

@inproceedings{cldrd,
author = {Zeng, Hansi and Zamani, Hamed and Vinay, Vishwa},
title = {Curriculum Learning for Dense Retrieval Distillation},
year = {2022},
booktitle = {Proc. SIGIR},
pages = {1979–1983},
}

@article{prod,
  author = {Lin, Zhenghao and Gong, Yeyun and Liu, Xiao and Zhang, Hang and Lin, Chen and Dong, Anlei and Jiao, Jian and Lu, Jingwen and Jiang, Daxin and Majumder, Rangan and Duan, Nan},
  title = {PROD: Progressive Distillation for Dense Retrieval},
  year = {2022},
  journal={arXiv:2209.13335},
}
@article{contriever,
      title={Unsupervised Dense Information Retrieval with Contrastive Learning}, 
      author={Gautier Izacard and Mathilde Caron and Lucas Hosseini and Sebastian Riedel and Piotr Bojanowski and Armand Joulin and Edouard Grave},
      year={2021},
      journal={arXiv:2112.09118},
}
@inproceedings{condenser,
    title = "Condenser: a Pre-training Architecture for Dense Retrieval",
    author = "Gao, Luyu  and
      Callan, Jamie",
    booktitle = "Proc. EMNLP",
    year = "2021",
    pages = "981--993",
}
@article{retromae,
  author = {Liu, Zheng and Shao, Yingxia},
  title = {RetroMAE: Pre-training Retrieval-oriented Transformers via Masked Auto-Encoder},
  year = {2022},
  journal={arXiv:2205.12035},
}
@inproceedings{mao-etal-2021-generation,
    title = "Generation-Augmented Retrieval for Open-Domain Question Answering",
    author = "Mao, Yuning  and
      He, Pengcheng  and
      Liu, Xiaodong  and
      Shen, Yelong  and
      Gao, Jianfeng  and
      Han, Jiawei  and
      Chen, Weizhu",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    url = "https://aclanthology.org/2021.acl-long.316",
    doi = "10.18653/v1/2021.acl-long.316"
}
@inproceedings{ma-etal-2021-zero,
    title = "Zero-shot Neural Passage Retrieval via Domain-targeted Synthetic Question Generation",
    author = "Ma, Ji  and
      Korotkov, Ivan  and
      Yang, Yinfei  and
      Hall, Keith  and
      McDonald, Ryan",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    year = "2021",
    url = "https://aclanthology.org/2021.eacl-main.92",
    doi = "10.18653/v1/2021.eacl-main.92"
}

@article{honnibal2020spacy,
  title={spaCy: Industrial-strength natural language processing in python},
  author={Honnibal, Matthew and Montani, Ines and Van Landeghem, Sofie and Boyd, Adriane and others},
  year={2020},
  publisher={Zenodo, Honolulu, HI, USA}
}
@misc{kim2024autoragautomatedframeworkoptimization,
      title={AutoRAG: Automated Framework for optimization of Retrieval Augmented Generation Pipeline},
      author={Dongkyu Kim and Byoungwook Kim and Donggeon Han and Matouš Eibich},
      year={2024},
      eprint={2410.20878},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.20878},
}
@article{FlashRAG,
    author={Jiajie Jin and
            Yutao Zhu and
            Xinyu Yang and
            Chenghao Zhang and
            Zhicheng Dou},
    title={FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research},
    journal={CoRR},
    volume={abs/2405.13576},
    year={2024},
    url={https://arxiv.org/abs/2405.13576},
    eprinttype={arXiv},
    eprint={2405.13576}
}
@article{nogueira2019passage,
  title={Passage Re-ranking with BERT},
  author={Nogueira, Rodrigo and Cho, Kyunghyun},
  journal={arXiv preprint arXiv:1901.04085},
  year={2019}
}
@article{nogueira2020document,
  title={Document ranking with a pretrained sequence-to-sequence model},
  author={Nogueira, Rodrigo and Jiang, Zhiying and Lin, Jimmy},
  journal={arXiv preprint arXiv:2003.06713},
  year={2020}
}
@article{santhanam2021colbertv2,
  title={Colbertv2: Effective and efficient retrieval via lightweight late interaction},
  author={Santhanam, Keshav and Khattab, Omar and Saad-Falcon, Jon and Potts, Christopher and Zaharia, Matei},
  journal={arXiv preprint arXiv:2112.01488},
  year={2021}
}
@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}
@String(ICLR = {International Conference on Learning Representations})
@String(NeurIPS = {Advances in Neural Information Processing Systems})
@String(ICML = {International Conference on Machine Learning})
@String(AAAI = {Proceedings of the AAAI Conference on Artificial Intelligence})

@misc{LangChain,
    author = {Chase, Harrison},
    month = oct,
    title = {{LangChain}},
    url = {https://github.com/langchain-ai/langchain},
    year = {2022}
}

@misc{autorag,
    author={Bwook Kim, Jeffrey Kim},
    title={{AutoRAG}},
    url = {https://github.com/Marker-Inc-Korea/AutoRAG},
    year={2024}
}

@article{mmlu,
  title={Measuring Massive Multitask Language Understanding},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{drqa,
  title={Reading {Wikipedia} to Answer Open-Domain Questions},
  author={Chen, Danqi and Fisch, Adam and Weston, Jason and Bordes, Antoine},
  booktitle={Association for Computational Linguistics (ACL)},
  year={2017}
}



@misc{msmarco,
title={{MS} {MARCO}: A Human-Generated {MA}chine Reading {CO}mprehension Dataset},
author={Tri Nguyen and Mir Rosenberg and Xia Song and Jianfeng Gao and Saurabh Tiwary and Rangan Majumder and Li Deng},
year={2017},
url={https://openreview.net/forum?id=Hk1iOLcle}
}

@article{mmlu_ethics,
  title={Aligning AI With Shared Human Values},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and Jerry Li and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}

@misc{LlamaIndex_2022,
  title = {{LlamaIndex}},
  author = {Liu, Jerry},
  doi = {10.5281/zenodo.1234},
  month = nov,
  url = {https://github.com/jerryjliu/llama_index},
  year = {2022}
}

@inproceedings{lewis2020retrieval,
  title="{R}etrieval-{A}ugmented {G}eneration for Knowledge-Intensive {NLP} Tasks",
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K\"{u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt\"{a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  booktitle=NeurIPS,
  pages={9459--9474},
  url={https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf},
  volume={33},
  year={2020}
}

@article{PFRL,
  author  = {Yasuhiro Fujita and Prabhat Nagarajan and Toshiki Kataoka and Takahiro Ishikawa},
  title   = {ChainerRL: A Deep Reinforcement Learning Library},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {77},
  pages   = {1-14},
  url     = {http://jmlr.org/papers/v22/20-376.html}
}

@inproceedings{NEURIPS2022_gpt3int,
 author = {Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {30318--30332},
 publisher = {Curran Associates, Inc.},
 title = {GPT3.int8(): 8-bit Matrix Multiplication for Transformers at Scale},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/c3ba4962c05c49636d4c6206a97e9c8a-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{guu2020realm,
  title="{REALM}: Retrieval-Augmented Language Model Pre-Training",
  author={Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Ming-Wei},
  year={2020},
  publisher={JMLR.org},
  booktitle=ICML,
  articleno={368},
  numpages={10},
  url={https://dl.acm.org/doi/abs/10.5555/3524938.3525306}
}

@inproceedings{borgeaud2022retro,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Van Den Driessche, George Bm and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  booktitle=ICML,
  pages={2206--2240},
  year={2022},
  organization={PMLR}
}


@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023},
  url={https://arxiv.org/pdf/2307.09288}
}

@misc{achiam2023gpt,
      title={GPT-4 Technical Report}, 
      author={OpenAI and : and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mo Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{jiang2023active,
  title={Active retrieval augmented generation},
  author={Jiang, Zhengbao and Xu, Frank F and Gao, Luyu and Sun, Zhiqing and Liu, Qian and Dwivedi-Yu, Jane and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  journal={arXiv preprint arXiv:2305.06983},
  year={2023}
}

@inproceedings{yao2023react,
  title = {{ReAct}: Synergizing Reasoning and Acting in Language Models},
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  booktitle = ICLR,
  year = {2023},
  html = {https://arxiv.org/abs/2210.03629},
}

@misc{shinn2023reflexion,
      title={Reflexion: Language Agents with Verbal Reinforcement Learning}, 
      author={Noah Shinn and Federico Cassano and Edward Berman and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
      year={2023},
      eprint={2303.11366},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{liu2023lost,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={arXiv preprint arXiv:2307.03172},
  year={2023}
}

@article{shi2023irrelevant,
  title={Large Language Models Can Be Easily Distracted by Irrelevant Context}, 
  author={Freda Shi and Xinyun Chen and Kanishka Misra and Nathan Scales and David Dohan and Ed Chi and Nathanael Schärli and Denny Zhou},
  year={2023},
  journal={arXiv preprint arXiv:2302.00093},
  url={https://arxiv.org/pdf/2302.00093}
}


@article{xu2023recomp,
  title={Recomp: Improving retrieval-augmented lms with compression and selective augmentation},
  author={Xu, Fangyuan and Shi, Weijia and Choi, Eunsol},
  journal={arXiv preprint arXiv:2310.04408},
  year={2023}
}

@article{bai2023longbench,
  title={LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding},
  author={Bai, Yushi and Lv, Xin and Zhang, Jiajie and Lyu, Hongchang and Tang, Jiankai and Huang, Zhidian and Du, Zhengxiao and Liu, Xiao and Zeng, Aohan and Hou, Lei and Dong, Yuxiao and Tang, Jie and Li, Juanzi},
  journal={arXiv preprint arXiv:2308.14508},
  year={2023}
}
@misc{longchat2023,
    title = {How Long Can Open-Source LLMs Truly Promise on Context Length?},
    url = {https://lmsys.org/blog/2023-06-29-longchat},
    author = {Dacheng Li*, Rulin Shao*, Anze Xie, Ying Sheng, Lianmin Zheng, Joseph E. Gonzalez, Ion Stoica, Xuezhe Ma, and Hao Zhang},
    month = {June},
    year = {2023}
}

@article{arefeen2023leancontext,
  title={Leancontext: Cost-efficient domain-specific question answering using llms},
  author={Arefeen, Md Adnan and Debnath, Biplob and Chakradhar, Srimat},
  journal={arXiv preprint arXiv:2309.00841},
  year={2023}
}
@inproceedings{jiang-etal-2023-llmlingua,
    title = "{LLML}ingua: Compressing Prompts for Accelerated Inference of Large Language Models",
    author = "Huiqiang Jiang and Qianhui Wu and Chin-Yew Lin and Yuqing Yang and Lili Qiu",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.825",
    doi = "10.18653/v1/2023.emnlp-main.825",
    pages = "13358--13376",
}

@article{jiang-etal-2023-longllmlingua,
    title = "{L}ong{LLML}ingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression",
    author = "Huiqiang Jiang and Qianhui Wu and and Xufang Luo and Dongsheng Li and Chin-Yew Lin and Yuqing Yang and Lili Qiu",
    url = "https://arxiv.org/abs/2310.06839",
    journal = "ArXiv preprint",
    volume = "abs/2310.06839",
    year = "2023",
}

@article{li2023selectivecontext,
  title={Unlocking Context Constraints of LLMs: Enhancing Context Efficiency of LLMs with Self-Information-Based Content Filtering},
  author={Li, Yucheng},
  journal={arXiv preprint arXiv:2304.12102},
  year={2023}
}

@article{gilbert2023semantic,
  title={Semantic Compression With Large Language Models},
  author={Gilbert, Henry and Sandborn, Michael and Schmidt, Douglas C and Spencer-Smith, Jesse and White, Jules},
  journal={arXiv preprint arXiv:2304.12512},
  year={2023}
}

@inproceedings{skr_2023,
    title = "Self-Knowledge Guided Retrieval Augmentation for Large Language Models",
    author = "Wang, Yile  and Li, Peng  and Sun, Maosong  and Liu, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.691",
    pages = "10303--10315",
}

@article{douze2024faiss,
      title={The Faiss library},
      author={Matthijs Douze and Alexandr Guzhva and Chengqi Deng and Jeff Johnson and Gergely Szilvasy and Pierre-Emmanuel Mazaré and Maria Lomeli and Lucas Hosseini and Hervé Jégou},
      year={2024},
      eprint={2401.08281},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{vllm_2023,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@misc{rag_survey_gao,
      title={Retrieval-Augmented Generation for Large Language Models: A Survey}, 
      author={Yunfan Gao and Yun Xiong and Xinyu Gao and Kangxiang Jia and Jinliu Pan and Yuxi Bi and Yi Dai and Jiawei Sun and Qianyu Guo and Meng Wang and Haofen Wang},
      year={2024},
      eprint={2312.10997},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{itrg2023,
      title={Retrieval-Generation Synergy Augmented Large Language Models}, 
      author={Zhangyin Feng and Xiaocheng Feng and Dezhi Zhao and Maojin Yang and Bing Qin},
      year={2023},
      eprint={2310.05149},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}

@inproceedings{bleu,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {BLEU: a method for automatic evaluation of machine translation},
year = {2002},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1073083.1073135},
doi = {10.3115/1073083.1073135},
booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
pages = {311–318},
numpages = {8},
location = {Philadelphia, Pennsylvania},
series = {ACL '02}
}

@inproceedings{asai2024selfrag,
author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
title={Self-{RAG}: Learning to Retrieve, Generate, and Critique through Self-Reflection},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=hSyW5go0v8}
}

@inproceedings{selfask_2023,
    title = "Measuring and Narrowing the Compositionality Gap in Language Models",
    author = "Press, Ofir  and
      Zhang, Muru  and
      Min, Sewon  and
      Schmidt, Ludwig  and
      Smith, Noah  and
      Lewis, Mike",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.378",
    doi = "10.18653/v1/2023.findings-emnlp.378",
    pages = "5687--5711",
    abstract = "We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning. We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly instead of implicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and then answers) follow-up questions before answering the initial question. We finally show that self-ask{'}s structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.",
}

@inproceedings{iterretgen_2023,
    title = "Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy",
    author = "Shao, Zhihong  and
      Gong, Yeyun  and
      Shen, Yelong  and
      Huang, Minlie  and
      Duan, Nan  and
      Chen, Weizhu",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.620",
    doi = "10.18653/v1/2023.findings-emnlp.620",
    pages = "9248--9274",
    abstract = "Retrieval-augmented generation has raise extensive attention as it is promising to address the limitations of large language models including outdated knowledge and hallucinations. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to guide retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call Iter-RetGen, which synergizes retrieval and generation in an iterative manner: a model{'}s response to a task input shows what might be needed to finish the task, and thus can serve as an informative context for retrieving more relevant knowledge which in turn helps generate a better response in another iteration. Compared with recent work which interleaves retrieval with generation when completing a single output, Iter-RetGen processes all retrieved knowledge as a whole and largely preserves the flexibility in generation without structural constraints. We evaluate Iter-RetGen on multi-hop question answering, fact verification, and commonsense reasoning, and show that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval and generation. We can further improve performance via generation-augmented retrieval adaptation.",
}

@inproceedings{sure_2024,
title={SuRe: Summarizing Retrievals using Answer Candidates for Open-domain {QA} of {LLM}s},
author={Jaehyung Kim and Jaehyun Nam and Sangwoo Mo and Jongjin Park and Sang-Woo Lee and Minjoon Seo and Jung-Woo Ha and Jinwoo Shin},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=w4DW6qkRmt}
}

@misc{replug_2023,
      title={REPLUG: Retrieval-Augmented Black-Box Language Models}, 
      author={Weijia Shi and Sewon Min and Michihiro Yasunaga and Minjoon Seo and Rich James and Mike Lewis and Luke Zettlemoyer and Wen-tau Yih},
      year={2023},
      eprint={2301.12652},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{fid_2021,
    title = "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering",
    author = "Izacard, Gautier  and
      Grave, Edouard",
    editor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.74",
    doi = "10.18653/v1/2021.eacl-main.74",
    pages = "874--880",
    abstract = "Generative models for open domain question answering have proven to be competitive, without resorting to external knowledge. While promising, this approach requires to use models with billions of parameters, which are expensive to train and query. In this paper, we investigate how much these models can benefit from retrieving text passages, potentially containing evidence. We obtain state-of-the-art results on the Natural Questions and TriviaQA open benchmarks. Interestingly, we observe that the performance of this method significantly improves when increasing the number of retrieved passages. This is evidence that sequence-to-sequence models offers a flexible framework to efficiently aggregate and combine evidence from multiple passages.",
}

@inproceedings{flan,
  title={Finetuned Language Models are Zero-Shot Learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  booktitle={International Conference on Learning Representations}
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@misc{fastchat,
      title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{faiss_gpu,
  title={Billion-scale similarity search with {GPUs}},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  volume={7},
  number={3},
  pages={535--547},
  year={2019},
  publisher={IEEE}
}

@inproceedings{ance_2021,
title={Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval},
author={Lee Xiong and Chenyan Xiong and Ye Li and Kwok-Fung Tang and Jialin Liu and Paul N. Bennett and Junaid Ahmed and Arnold Overwijk},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=zeFrfgyZln}
}

@INPROCEEDINGS{Lin_etal_SIGIR2021_Pyserini,
   author = "Jimmy Lin and Xueguang Ma and Sheng-Chieh Lin and Jheng-Hong Yang and Ronak Pradeep and Rodrigo Nogueira",
   title = "{Pyserini}: A {Python} Toolkit for Reproducible Information Retrieval Research with Sparse and Dense Representations",
   booktitle = "Proceedings of the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021)",
   year = 2021,
   pages = "2356--2362",
}
@inproceedings{sciavolino2021simple,
   title={Simple Entity-centric Questions Challenge Dense Retrievers},
   author={Sciavolino, Christopher and Zhong, Zexuan and Lee, Jinhyuk and Chen, Danqi},
   booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
   year={2021}
}
@article{sachan2022improving,
  title = "Improving Passage Retrieval with Zero-Shot Question Generation",
  author = "Sachan, Devendra Singh and Lewis, Mike and Joshi, Mandar and Aghajanyan, Armen and Yih, Wen-tau and Pineau, Joelle and Zettlemoyer, Luke",
  booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/2204.07496",
  year = "2022"
}
@inproceedings{levy-etal-2017-zero,
    title = "Zero-Shot Relation Extraction via Reading Comprehension",
    author = "Levy, Omer  and
      Seo, Minjoon  and
      Choi, Eunsol  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 21st Conference on Computational Natural Language Learning ({CoNLL} 2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/K17-1034",
    doi = "10.18653/v1/K17-1034",
    pages = "333--342",
    abstract = "We show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages: we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task.",
}

@inproceedings{kilt_2021,
    title = "{KILT}: a Benchmark for Knowledge Intensive Language Tasks",
    author = {Petroni, Fabio  and Piktus, Aleksandra  and
      Fan, Angela  and Lewis, Patrick  and
      Yazdani, Majid  and De Cao, Nicola  and
      Thorne, James  and Jernite, Yacine  and
      Karpukhin, Vladimir  and Maillard, Jean  and
      Plachouras, Vassilis  and Rockt{\"a}schel, Tim  and
      Riedel, Sebastian},
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association 
                 for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.200",
    doi = "10.18653/v1/2021.naacl-main.200",
    pages = "2523--2544",
}

@article{chen2023walking,
  title={Walking down the memory maze: Beyond context limit through interactive reading},
  author={Chen, Howard and Pasunuru, Ramakanth and Weston, Jason and Celikyilmaz, Asli},
  journal={arXiv preprint arXiv:2310.05029},
  year={2023}
}

@article{laskar2023cqsumdp,
  title={CQSumDP: A ChatGPT-Annotated Resource for Query-Focused Abstractive Summarization Based on Debatepedia},
  author={Laskar, Md Tahmid Rahman and Rahman, Mizanur and Jahan, Israt and Hoque, Enamul and Huang, Jimmy},
  journal={arXiv preprint arXiv:2305.06147},
  year={2023}
}

@misc{izacard2022atlas,
      title={Atlas: Few-shot Learning with Retrieval Augmented Language Models}, 
      author={Gautier Izacard and Patrick Lewis and Maria Lomeli and Lucas Hosseini and Fabio Petroni and Timo Schick and Jane Dwivedi-Yu and Armand Joulin and Sebastian Riedel and Edouard Grave},
      year={2022},
      eprint={2208.03299},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{howaffects,
  author       = {Fabio Petroni and
                  Patrick S. H. Lewis and
                  Aleksandra Piktus and
                  Tim Rockt{\"{a}}schel and
                  Yuxiang Wu and
                  Alexander H. Miller and
                  Sebastian Riedel},
  title        = {How Context Affects Language Models' Factual Predictions},
  journal      = {CoRR},
  volume       = {abs/2005.04611},
  year         = {2020},
  url          = {https://arxiv.org/abs/2005.04611},
  eprinttype    = {arXiv},
  eprint       = {2005.04611},
  timestamp    = {Thu, 14 Oct 2021 09:18:22 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2005-04611.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{shi2023replug,
  title={Replug: Retrieval-augmented black-box language models},
  author={Shi, Weijia and Min, Sewon and Yasunaga, Michihiro and Seo, Minjoon and James, Rich and Lewis, Mike and Zettlemoyer, Luke and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2301.12652},
  year={2023}
}

@article{liu2019bertsum,
  title={Fine-tune BERT for extractive summarization},
  author={Liu, Yang},
  journal={arXiv preprint arXiv:1903.10318},
  year={2019}
}

@article{gu2016copynet,
  title={Incorporating copying mechanism in sequence-to-sequence learning},
  author={Gu, Jiatao and Lu, Zhengdong and Li, Hang and Li, Victor OK},
  journal={arXiv preprint arXiv:1603.06393},
  year={2016}
}

@article{wang2023filco,
  title={Learning to filter context for retrieval-augmented generation},
  author={Wang, Zhiruo and Araki, Jun and Jiang, Zhengbao and Parvez, Md Rizwan and Neubig, Graham},
  journal={arXiv preprint arXiv:2311.08377},
  year={2023}
}

@inproceedings{dinan2018wizard,
  title="{W}izard of {W}ikipedia: Knowledge-Powered Conversational Agents",
  author={Emily Dinan and Stephen Roller and Kurt Shuster and Angela Fan and Michael Auli and Jason Weston},
  booktitle=ICLR,
  year={2019},
  url={https://openreview.net/forum?id=r1l73iRqKm},
}

@article{wang2022e5,
  title={Text embeddings by weakly-supervised contrastive pre-training},
  author={Wang, Liang and Yang, Nan and Huang, Xiaolong and Jiao, Binxing and Yang, Linjun and Jiang, Daxin and Majumder, Rangan and Wei, Furu},
  journal={arXiv preprint arXiv:2212.03533},
  year={2022}
}

@misc{bge_embedding,
      title={C-Pack: Packaged Resources To Advance General Chinese Embedding}, 
      author={Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff},
      year={2023},
      eprint={2309.07597},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{llm-embedder,
      title={Retrieve Anything To Augment Large Language Models}, 
      author={Peitian Zhang and Shitao Xiao and Zheng Liu and Zhicheng Dou and Jian-Yun Nie},
      year={2023},
      eprint={2310.07554},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@article{bart-cnn,
  author    = {Mike Lewis and
               Yinhan Liu and
               Naman Goyal and
               Marjan Ghazvininejad and
               Abdelrahman Mohamed and
               Omer Levy and
               Veselin Stoyanov and
               Luke Zettlemoyer},
  title     = {{BART:} Denoising Sequence-to-Sequence Pre-training for Natural Language
               Generation, Translation, and Comprehension},
  journal   = {CoRR},
  volume    = {abs/1910.13461},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.13461},
  eprinttype = {arXiv},
  eprint    = {1910.13461},
  timestamp = {Thu, 31 Oct 2019 14:02:26 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-13461.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bart-large,
  author    = {Mike Lewis and
               Yinhan Liu and
               Naman Goyal and
               Marjan Ghazvininejad and
               Abdelrahman Mohamed and
               Omer Levy and
               Veselin Stoyanov and
               Luke Zettlemoyer},
  title     = {{BART:} Denoising Sequence-to-Sequence Pre-training for Natural Language
               Generation, Translation, and Comprehension},
  journal   = {CoRR},
  volume    = {abs/1910.13461},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.13461},
  eprinttype = {arXiv},
  eprint    = {1910.13461},
  timestamp = {Thu, 31 Oct 2019 14:02:26 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-13461.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{vonwerra2022trl,
  author = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang},
  title = {TRL: Transformer Reinforcement Learning},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/huggingface/trl}}
}

@inproceedings{
loshchilov2018adamw,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle=ICLR,
year={2019},
url={https://openreview.net/forum?id=Bkg6RiCqY7},
}


@inproceedings{reimers-2019-sentence-bert,
  title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
  author = "Reimers, Nils and Gurevych, Iryna",
  booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
  month = "11",
  year = "2019",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/1908.10084",
}
@article{llama3modelcard,
title={Llama 3 Model Card},
author={AI@Meta},
year={2024},
url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}
}

@article{narrativeqa,
author = {Tom\'a\v s Ko\v cisk\'y and Jonathan Schwarz and Phil Blunsom and
          Chris Dyer and Karl Moritz Hermann and G\'abor Melis and
          Edward Grefenstette},
title = {The {NarrativeQA} Reading Comprehension Challenge},
journal = {Transactions of the Association for Computational Linguistics},
url = {https://TBD},
volume = {TBD},
year = {2018},
pages = {TBD},
}

@inproceedings{ambigqa,
    title={ {A}mbig{QA}: Answering Ambiguous Open-domain Questions },
    author={ Min, Sewon and Michael, Julian and Hajishirzi, Hannaneh and Zettlemoyer, Luke },
    booktitle={ EMNLP },
    year={2020}
}


@inproceedings{piqa,
  title={PIQA: Reasoning about Physical Commonsense in Natural Language},
  author={Yonatan Bisk and Rowan Zellers and Ronan Le Bras and Jianfeng Gao and Yejin Choi},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:208290939}
}

@article{wikiasp,
    title = {WikiAsp: A Dataset for Multi-domain Aspect-based Summarization},
    author = {Hiroaki Hayashi and Prashant Budania and Peng Wang and Chris Ackerson and Raj Neervannan and Graham Neubig},
    journal = {Transactions of the Association for Computational Linguistics (TACL)},
    month = {},
    url = {https://arxiv.org/abs/2011.07832},
    year = {2020}
}

@inproceedings{Fever,
    author = {Thorne, James and Vlachos, Andreas and Christodoulopoulos, Christos and Mittal, Arpit},
    title = {{FEVER}: a Large-scale Dataset for Fact Extraction and {VERification}},
    booktitle = {NAACL-HLT},
    year = {2018}
}

@inproceedings{dinan2019wizard,
  author={Emily Dinan and Stephen Roller and Kurt Shuster and Angela Fan and Michael Auli and Jason Weston},
  title={{W}izard of {W}ikipedia: Knowledge-powered Conversational Agents},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2019},
}


@inproceedings{trex,
  author    = {Hady ElSahar and
               Pavlos Vougiouklis and
               Arslen Remaci and
               Christophe Gravier and
               Jonathon S. Hare and
               Fr{\'{e}}d{\'{e}}rique Laforest and
               Elena Simperl},
  title     = {T-REx: {A} Large Scale Alignment of Natural Language with Knowledge
               Base Triples},
  booktitle = {Proceedings of the Eleventh International Conference on Language Resources
               and Evaluation, {LREC} 2018, Miyazaki, Japan, May 7-12, 2018.},
  year      = {2018},
  timestamp = {Fri, 18 May 2018 10:35:14 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/lrec/ElSaharVRGHLS18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{wned,
    title = "{N}amed {E}ntity {R}ecognition for {E}ntity {L}inking: {W}hat Works and What{'}s Next",
    author = "Tedeschi, Simone  and
      Conia, Simone  and
      Cecconi, Francesco  and
      Navigli, Roberto",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.220",
    pages = "2584--2596",
    abstract = "Entity Linking (EL) systems have achieved impressive results on standard benchmarks mainly thanks to the contextualized representations provided by recent pretrained language models. However, such systems still require massive amounts of data {--} millions of labeled examples {--} to perform at their best, with training times that often exceed several days, especially when limited computational resources are available. In this paper, we look at how Named Entity Recognition (NER) can be exploited to narrow the gap between EL systems trained on high and low amounts of labeled data. More specifically, we show how and to what extent an EL system can benefit from NER to enhance its entity representations, improve candidate selection, select more effective negative samples and enforce hard and soft constraints on its output entities. We release our software {--} code and model checkpoints {--} at https://github.com/Babelscape/ner4el.",
}

@inproceedings{AIDA_CONLL,
    title = "Robust Disambiguation of Named Entities in Text",
    author = {Hoffart, Johannes  and
      Yosef, Mohamed Amir  and
      Bordino, Ilaria  and
      F{\"u}rstenau, Hagen  and
      Pinkal, Manfred  and
      Spaniol, Marc  and
      Taneva, Bilyana  and
      Thater, Stefan  and
      Weikum, Gerhard},
    editor = "Barzilay, Regina  and
      Johnson, Mark",
    booktitle = "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing",
    month = jul,
    year = "2011",
    address = "Edinburgh, Scotland, UK.",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D11-1072",
    pages = "782--792",
}

@inproceedings{OpenBookQA2018,
 title={Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering},
 author={Todor Mihaylov and Peter Clark and Tushar Khot and Ashish Sabharwal},
 booktitle={EMNLP},
 year={2018}
}

@article{arc_challenge,
  author       = {Peter Clark and
                  Isaac Cowhey and
                  Oren Etzioni and
                  Tushar Khot and
                  Ashish Sabharwal and
                  Carissa Schoenick and
                  Oyvind Tafjord},
  title        = {Think you have Solved Question Answering? Try ARC, the {AI2} Reasoning
                  Challenge},
  journal      = {CoRR},
  volume       = {abs/1803.05457},
  year         = {2018},
  url          = {http://arxiv.org/abs/1803.05457},
  eprinttype    = {arXiv},
  eprint       = {1803.05457},
  timestamp    = {Mon, 13 Aug 2018 16:48:43 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1803-05457.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{hellaswag,
    title={HellaSwag: Can a Machine Really Finish Your Sentence?},
    author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
    booktitle ={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
    year={2019}
}

@inproceedings{truthfulqa,
    title = "{T}ruthful{QA}: Measuring How Models Mimic Human Falsehoods",
    author = "Lin, Stephanie  and
      Hilton, Jacob  and
      Evans, Owain",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.229",
    doi = "10.18653/v1/2022.acl-long.229",
    pages = "3214--3252",
    abstract = "We propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a T5-based model. The best model was truthful on 58{\%} of questions, while human performance was 94{\%}. Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans. The largest models were generally the least truthful. This contrasts with other NLP tasks, where performance improves with model size. However, this result is expected if false answers are learned from the training distribution. We suggest that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web.",
}

@inproceedings{eli5,
    title = "{ELI}5: Long Form Question Answering",
    author = "Fan, Angela  and
      Jernite, Yacine  and
      Perez, Ethan  and
      Grangier, David  and
      Weston, Jason  and
      Auli, Michael",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1346",
    doi = "10.18653/v1/P19-1346",
    pages = "3558--3567",
    abstract = "We introduce the first large-scale corpus for long form question answering, a task requiring elaborate and in-depth answers to open-ended questions. The dataset comprises 270K threads from the Reddit forum {``}Explain Like I{'}m Five{''} (ELI5) where an online community provides answers to questions which are comprehensible by five year olds. Compared to existing datasets, ELI5 comprises diverse questions requiring multi-sentence answers. We provide a large set of web documents to help answer the question. Automatic and human evaluations show that an abstractive model trained with a multi-task objective outperforms conventional Seq2Seq, language modeling, as well as a strong extractive baseline. However, our best model is still far from human performance since raters prefer gold responses in over 86{\%} of cases, leaving ample opportunity for future improvement.",
}

@inproceedings{asqa,
    title = "{ASQA}: Factoid Questions Meet Long-Form Answers",
    author = "Stelmakh, Ivan  and
      Luan, Yi  and
      Dhingra, Bhuwan  and
      Chang, Ming-Wei",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.566",
    doi = "10.18653/v1/2022.emnlp-main.566",
    pages = "8273--8288",
    abstract = "Recent progress on open domain factoid question answering (QA) does not easily transfer to the task of long-form QA, where the goal is to answer questions that require in-depth explanations. The hurdles include a lack of high-quality data and the absence of a well-defined notion of an answer{'}s quality. In this work, we address these problems by releasing a novel dataset and a task that we call ASQA (Answer Summaries for Questions which are Ambiguous); and proposing a reliable metric for measuring performance on ASQA. Our task focuses on ambiguous factoid questions which have different correct answers depending on the interpretation. Answers to ambiguous questions should combine factual information from multiple sources into a coherent long-form summary that resolves the ambiguity. In contrast to existing long-form QA tasks (such as ELI5), ASQA admits a clear notion of correctness: a user faced with a good summary should be able to answer different interpretations of the original ambiguous question. Our analysis demonstrates an agreement between this metric and human judgments, and reveals a considerable gap between human performance and strong baselines.",
}

@article{musique,
  title={{M}u{S}i{Q}ue: Multihop Questions via Single-hop Question Composition},
  author={Trivedi, Harsh and Balasubramanian, Niranjan and Khot, Tushar and Sabharwal, Ashish},
  journal={Transactions of the Association for Computational Linguistics},
  year={2022},
  publisher={MIT Press}
}

@inproceedings{2wikimultihop,
    title = "Constructing A Multi-hop {QA} Dataset for Comprehensive Evaluation of Reasoning Steps",
    author = "Ho, Xanh  and
      Duong Nguyen, Anh-Khoa  and
      Sugawara, Saku  and
      Aizawa, Akiko",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.coling-main.580",
    pages = "6609--6625",
}

@article{fermi,
  title={How Much Coffee Was Consumed During EMNLP 2019? Fermi Problems: A New Reasoning Challenge for AI},
  author={Kalyan, Ashwin and Kumar, Abhinav and Chandrasekaran, Arjun and Sabharwal, Ashish and Clark, Peter},
  journal={arXiv preprint arXiv:2110.14207},
  year={2021}
}

@inproceedings{boolq,
  title =     {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  author =    {Clark, Christopher and Lee, Kenton and Chang, Ming-Wei and Kwiatkowski, Tom and Collins, Michael and Toutanova, Kristina},
  booktitle = {NAACL},
  year =      {2019},
}

@inproceedings{commonsenseqa,
    title = "{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge",
    author = "Talmor, Alon  and
      Herzig, Jonathan  and
      Lourie, Nicholas  and
      Berant, Jonathan",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1421",
    doi = "10.18653/v1/N19-1421",
    pages = "4149--4158",
    abstract = "When answering a question, people often draw upon their rich world knowledge in addition to the particular context. Recent work has focused primarily on answering questions given some relevant document or context, and required very little general background. To investigate question answering with prior knowledge, we present CommonsenseQA: a challenging new dataset for commonsense question answering. To capture common sense beyond associations, we extract from ConceptNet (Speer et al., 2017) multiple target concepts that have the same semantic relation to a single source concept. Crowd-workers are asked to author multiple-choice questions that mention the source concept and discriminate in turn between each of the target concepts. This encourages workers to create questions with complex semantics that often require prior knowledge. We create 12,247 questions through this procedure and demonstrate the difficulty of our task with a large number of strong baselines. Our best baseline is based on BERT-large (Devlin et al., 2018) and obtains 56{\%} accuracy, well below human performance, which is 89{\%}.",
}

@inproceedings{siqa,
    title = "Social {IQ}a: Commonsense Reasoning about Social Interactions",
    author = "Sap, Maarten  and
      Rashkin, Hannah  and
      Chen, Derek  and
      Le Bras, Ronan  and
      Choi, Yejin",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1454",
    doi = "10.18653/v1/D19-1454",
    pages = "4463--4473",
    abstract = "We introduce Social IQa, the first large-scale benchmark for commonsense reasoning about social situations. Social IQa contains 38,000 multiple choice questions for probing emotional and social intelligence in a variety of everyday situations (e.g., Q: {``}Jordan wanted to tell Tracy a secret, so Jordan leaned towards Tracy. Why did Jordan do this?{''} A: {``}Make sure no one else could hear{''}). Through crowdsourcing, we collect commonsense questions along with correct and incorrect answers about social interactions, using a new framework that mitigates stylistic artifacts in incorrect answers by asking workers to provide the right answer to a different but related question. Empirical results show that our benchmark is challenging for existing question-answering models based on pretrained language models, compared to human performance ({\textgreater}20{\%} gap). Notably, we further establish Social IQa as a resource for transfer learning of commonsense knowledge, achieving state-of-the-art performance on multiple commonsense reasoning tasks (Winograd Schemas, COPA).",
}

@inproceedings{webquestions,
    title = "Semantic Parsing on {F}reebase from Question-Answer Pairs",
    author = "Berant, Jonathan  and
      Chou, Andrew  and
      Frostig, Roy  and
      Liang, Percy",
    editor = "Yarowsky, David  and
      Baldwin, Timothy  and
      Korhonen, Anna  and
      Livescu, Karen  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D13-1160",
    pages = "1533--1544",
}

@inproceedings{wikiqa,
    title = "{W}iki{QA}: A Challenge Dataset for Open-Domain Question Answering",
    author = "Yang, Yi  and
      Yih, Wen-tau  and
      Meek, Christopher",
    editor = "M{\`a}rquez, Llu{\'\i}s  and
      Callison-Burch, Chris  and
      Su, Jian",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D15-1237",
    doi = "10.18653/v1/D15-1237",
    pages = "2013--2018",
}


@inproceedings{squad,
    title = "{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text",
    author = "Rajpurkar, Pranav  and
      Zhang, Jian  and
      Lopyrev, Konstantin  and
      Liang, Percy",
    editor = "Su, Jian  and
      Duh, Kevin  and
      Carreras, Xavier",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1264",
    doi = "10.18653/v1/D16-1264",
    pages = "2383--2392",
}

@article{popqa,
  title={When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories },
  author={ Mallen, Alex and Asai,Akari and  Zhong, Victor and Das, Rajarshi and Hajishirzi, Hannaneh and Khashabi, Daniel},
  journal={ arXiv preprint },
  year={ 2022 }
}

@misc{retrobust_2023,
      title={Making Retrieval-Augmented Language Models Robust to Irrelevant Context}, 
      author={Ori Yoran and Tomer Wolfson and Ori Ram and Jonathan Berant},
      year={2023},
      eprint={2310.01558},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{aar_retriever_2023,
    title = "Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In",
    author = "Yu, Zichun  and
      Xiong, Chenyan  and
      Yu, Shi  and
      Liu, Zhiyuan",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.136",
    doi = "10.18653/v1/2023.acl-long.136",
    pages = "2421--2436",
    abstract = "Retrieval augmentation can aid language models (LMs) in knowledge-intensive tasks by supplying them with external information. Prior works on retrieval augmentation usually jointly fine-tune the retriever and the LM, making them closely coupled. In this paper, we explore the scheme of generic retrieval plug-in: the retriever is to assist target LMs that may not be known beforehand or are unable to be fine-tuned together. To retrieve useful documents for unseen target LMs, we propose augmentation-adapted retriever (AAR), which learns LM{'}s preferences obtained from a known source LM. Experiments on the MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM is able to significantly improve the zero-shot generalization of larger target LMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates that the preferences of different LMs overlap, enabling AAR trained with a single source LM to serve as a generic plug-in for various target LMs. Our code is open-sourced at \url{https://github.com/OpenMatch/Augmentation-Adapted-Retriever}.",
}

@inproceedings{hotpotqa,
    title = "{H}otpot{QA}: A Dataset for Diverse, Explainable Multi-hop Question Answering",
    author = "Yang, Zhilin  and
      Qi, Peng  and
      Zhang, Saizheng  and
      Bengio, Yoshua  and
      Cohen, William  and
      Salakhutdinov, Ruslan  and
      Manning, Christopher D.",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1259",
    doi = "10.18653/v1/D18-1259",
    pages = "2369--2380",
    abstract = "Existing question answering (QA) datasets fail to train QA systems to perform complex reasoning and provide explanations for answers. We introduce HotpotQA, a new dataset with 113k Wikipedia-based question-answer pairs with four key features: (1) the questions require finding and reasoning over multiple supporting documents to answer; (2) the questions are diverse and not constrained to any pre-existing knowledge bases or knowledge schemas; (3) we provide sentence-level supporting facts required for reasoning, allowing QA systems to reason with strong supervision and explain the predictions; (4) we offer a new type of factoid comparison questions to test QA systems{'} ability to extract relevant facts and perform necessary comparison. We show that HotpotQA is challenging for the latest QA systems, and the supporting facts enable models to improve performance and make explainable predictions.",
}

@inproceedings{triviaqa,
    title = "{T}rivia{QA}: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    author = "Joshi, Mandar  and
      Choi, Eunsol  and
      Weld, Daniel  and
      Zettlemoyer, Luke",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1147",
    doi = "10.18653/v1/P17-1147",
    pages = "1601--1611",
    abstract = "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23{\%} and 40{\%} vs. 80{\%}), suggesting that TriviaQA is a challenging testbed that is worth significant future study.",
}

@article{naturalquestion,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    editor = "Lee, Lillian  and
      Johnson, Mark  and
      Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "7",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q19-1026",
    doi = "10.1162/tacl_a_00276",
    pages = "452--466",
    abstract = "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.",
}

@article{ mallen2023llm_memorization ,
  title={When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories },
  author={ Mallen, Alex and Asai,Akari and  Zhong, Victor and Das, Rajarshi and Hajishirzi, Hannaneh and Khashabi, Daniel},
  journal={ arXiv preprint },
  year={ 2022 }
}

@misc{localrqa,
      title={LocalRQA: From Generating Data to Locally Training, Testing, and Deploying Retrieval-Augmented QA Systems}, 
      author={Xiao Yu and Yunan Lu and Zhou Yu},
      year={2024},
      eprint={2403.00982},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{fastRAG_2023,
  author = {Izsak, Peter and Berchansky, Moshe and Fleischer, Daniel and Laperdon, Ronen},
  license = {Apache-2.0},
  month = feb,
  title = {{fastRAG: Efficient Retrieval Augmentation and Generation Framework}},
  url = {https://github.com/IntelLabs/fastrag},
  version = {1.0},
  year = {2023}
}

@misc{Haystack_2019,
  author = {Pietsch, Malte and Möller, Timo and Kostic, Bogdan and Risch, Julian and Pippi, Massimiliano and Jobanputra, Mayank and Zanzottera, Sara and Cerza, Silvano and Blagojevic, Vladimir and Stadelmann, Thomas and Soni, Tanay and Lee, Sebastian},
  month = nov,
  title = {{Haystack: the end-to-end NLP framework for pragmatic builders}},
  url = {https://github.com/deepset-ai/haystack},
  year = {2019}
}

@misc{bang2023hallucination,
      title={A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity}, 
      author={Yejin Bang and Samuel Cahyawijaya and Nayeon Lee and Wenliang Dai and Dan Su and Bryan Wilie and Holy Lovenia and Ziwei Ji and Tiezheng Yu and Willy Chung and Quyet V. Do and Yan Xu and Pascale Fung},
      year={2023},
      eprint={2302.04023},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{GAE,
  author       = {John Schulman and
                  Philipp Moritz and
                  Sergey Levine and
                  Michael I. Jordan and
                  Pieter Abbeel},
  editor       = {Yoshua Bengio and
                  Yann LeCun},
  title        = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
  booktitle    = {4th International Conference on Learning Representations, {ICLR} 2016,
                  San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year         = {2016},
  url          = {http://arxiv.org/abs/1506.02438},
  timestamp    = {Thu, 25 Jul 2019 14:25:38 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/SchulmanMLJA15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NIPS2017_rlhf,
 author = {Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Deep Reinforcement Learning from Human Preferences},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{NEURIPS2022_instruct,
 author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {27730--27744},
 publisher = {Curran Associates, Inc.},
 title = {Training language models to follow instructions with human feedback},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{NEURIPS2020_summarizehf,
 author = {Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {3008--3021},
 publisher = {Curran Associates, Inc.},
 title = {Learning to summarize with human feedback},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1f89885d556929e98d3ef9b86448f951-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{Ziegler2019FineTuningLM,
  title={Fine-Tuning Language Models from Human Preferences},
  author={Daniel M. Ziegler and Nisan Stiennon and Jeff Wu and Tom B. Brown and Alec Radford and Dario Amodei and Paul Christiano and Geoffrey Irving},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.08593},
  url={https://api.semanticscholar.org/CorpusID:202660943}
}

@article{Schulman2017PPO,
  title={Proximal Policy Optimization Algorithms},
  author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  journal={ArXiv},
  year={2017},
  volume={abs/1707.06347},
  url={https://api.semanticscholar.org/CorpusID:28695052}
}


@misc{izacard2020leveraging,
      title={Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering},
      author={Gautier Izacard and Edouard Grave},
      url = {https://arxiv.org/abs/2007.0128},
      year={2020},
      publisher = {arXiv},
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{ram-etal-2023-context,
    title = "In-Context Retrieval-Augmented Language Models",
    author = "Ram, Ori  and
      Levine, Yoav  and
      Dalmedigos, Itay  and
      Muhlgay, Dor  and
      Shashua, Amnon  and
      Leyton-Brown, Kevin  and
      Shoham, Yoav",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "11",
    year = "2023",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2023.tacl-1.75",
    doi = "10.1162/tacl_a_00605",
    pages = "1316--1331",
}

@misc{yoon2024listt5listwisererankingfusionindecoder,
      title={ListT5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval}, 
      author={Soyoung Yoon and Eunbi Choi and Jiyeon Kim and Hyeongu Yun and Yireun Kim and Seung-won Hwang},
      year={2024},
      eprint={2402.15838},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2402.15838}, 
}
@inproceedings{zhuang2023rankt5,
  title={Rankt5: Fine-tuning t5 for text ranking with ranking losses},
  author={Zhuang, Honglei and Qin, Zhen and Jagerman, Rolf and Hui, Kai and Ma, Ji and Lu, Jing and Ni, Jianmo and Wang, Xuanhui and Bendersky, Michael},
  booktitle={Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2308--2313},
  year={2023}
}
@misc{bge_m3,
  title={BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation},
  author={Chen, Jianlv and Xiao, Shitao and Zhang, Peitian and Luo, Kun and Lian, Defu and Liu, Zheng},
  year={2023},
  eprint={2309.07597},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}
@misc{izacard2021contriever,
      title={Unsupervised Dense Information Retrieval with Contrastive Learning}, 
      author={Gautier Izacard and Mathilde Caron and Lucas Hosseini and Sebastian Riedel and Piotr Bojanowski and Armand Joulin and Edouard Grave},
      year={2021},
      url = {https://arxiv.org/abs/2112.09118},
      doi = {10.48550/ARXIV.2112.09118},
}
@article{Bruch_2023,
   title={An Analysis of Fusion Functions for Hybrid Retrieval},
   volume={42},
   ISSN={1558-2868},
   url={http://dx.doi.org/10.1145/3596512},
   DOI={10.1145/3596512},
   number={1},
   journal={ACM Transactions on Information Systems},
   publisher={Association for Computing Machinery (ACM)},
   author={Bruch, Sebastian and Gai, Siyu and Ingber, Amir},
   year={2023},
   month=aug, pages={1–35} }

@INPROCEEDINGS{ance,
  title = "Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval",
  author = "Lee Xiong and Chenyan Xiong and Ye Li and Kwok-Fung Tang and Jialin Liu and Paul N. Bennett and Junaid Ahmed and Arnold Overwijk",
  booktitle = "Proceedings of the 9th International Conference on Learning Representations (ICLR 2021)",
  year = 2021,
}
