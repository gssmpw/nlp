\section{Related Work}
\noindent\textbf{Scam Website Analysis.}
Recent studies have focused on various types of scam websites~\cite{DBLP:conf/ndss/MiramirkhaniSN17,DBLP:conf/ndss/LiYN23,DBLP:conf/www/SrinivasanKMANA18}.
Bitaab et al.'s ``Beyond Phish'' system achieved a 98.34\% detection rate and 1.34\% false positive rate for English scam e-commerce websites~\cite{DBLP:conf/sp/BitaabCOLWAWBSD23}.
Kotzias et al.'s system for detecting fake online shopping websites achieved an F1 score of 0.973~\cite{DBLP:conf/acsac/KotziasRPSB23}.
\textit{Our study extends beyond these by addressing multilingual and multi-type scams.}

\noindent\textbf{Security Task-specific LLMs.}
LLMs for security tasks have gained attention~\cite{alfasi2024unveiling,DBLP:journals/access/KoideNC24}.
Li et al.'s ``KnowPhish Detector'' uses LLMs to extract brand information for phishing detection, achieving a 98.34\% detection rate~\cite{DBLP:conf/uss/LiHDLCOLH24}.
Roy et al. demonstrated LLMs' potential to generate phishing content and proposed a BERT-based detection tool with 96\% accuracy for phishing websites~\cite{DBLP:journals/corr/abs-2310-19181}.
\textit{Our approach differs by leveraging LLMs' text comprehension capabilities for scam website detection.}

\noindent\textbf{LLM-as-a-Judge.}
Recent research has explored LLMs for evaluating LLM-generated content~\cite{DBLP:conf/nips/ZhengC00WZL0LXZ23,DBLP:conf/emnlp/SottanaLZY23}.
Chiang et al. used LLMs for text quality assessment, matching expert human evaluation~\cite{DBLP:conf/acl/ChiangL23}.
Chan et al.'s ``ChatEval'' framework uses multiple LLMs for text generation quality assessment~\cite{DBLP:journals/corr/abs-2308-07201}.
\textit{Our study differs in that it analyzes detection rationale for classifying scam websites, rather than evaluating quality of LLM-generated text.}