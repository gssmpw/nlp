\section{Related Work}
\label{sec:related_work}

\update{\textbf{Data Imputation.}} The field of data imputation has seen a broad range of techniques, from traditional statistical methods to more advanced approaches. Early methods like K-Nearest Neighbors (KNN) \cite{knn} and probabilistic approaches such as Expectation-Maximization (EM) \cite{EM} are simple to implement but often serve as baselines due to their inability to capture spatial and temporal, resulting in limited recovery quality for practical use. Spatiotemporal multi-view learning \cite{ST-MVL} improves data imputation by considering both spatial and temporal dependencies, approximating missing values using low-rank matrix completion \cite{LRMC,ensemble} and tensor decomposition \cite{tensor,tensor2}. However, these methods often fail to capture the deeper, inherent dependencies in spatiotemporal sensor data.

\textbf{Deep Generative Models.} %The literature on data imputation is massive. Dozens of methods were developed ranging from statistical methods to the more recent deep approaches \cite{wang2024deep, sun2023deep}. 
Recently, deep learning approaches have emerged for data imputation \cite{wang2024deep, sun2023deep}, including the use of generative models \cite{adhikari2022comprehensive, shahbazian2023generative}, offering more advanced solutions to address these limitations.
This work falls in the category of generative data imputation by building on the same principles. To the best of the author's knowledge, this is the first work to employ generative modeling for zero-shot sensory data imputation. Beyond this main distinction, the framework possess a number of technical qualities that collectively enable a broader range of application. Specifically; the capability to perform interpolation and extrapolation using an independent parameter-efficient design, where the Neural ODE parameters and memory budget are fixed regardless of the sequences sizes. These qualities collectively enable a broader range of applications. 
% \begin{itemize}
%     \item \textit{\textbf{universality} (interpolation, extrapolation, etc ) , \underline{implication} : broader range of apps.}
%     \item \textit{\textbf{learned dynamics }. learning the signal ( latent space) dynamics rather than fixing a prior or being purely data-driven, \underline{implication}: adaptable to  modalities/datasets of different dynamics with reasonable data budget.}
    % \item \textit{\textbf{parameter efficiency} (Neural ODE uses a fixed number of parameters and consumes fixed memory regardless of the input and output sizes), \underline{implication} : useful on edge devices ? }

    % \item \textit{architecture designed for \textbf{spatial-temporal sensory data}, \underline{implication}: addresses the niche area falling between the low dimensional time-series and the high dimensional dense vision data.}
    
% \end{itemize}

% \textbf{Sensor Translation} Recently , a number of works investigated sensor translation \cite{nirmal2024wifi2radar}. \textit{[explain what's sensor translation and what are the different approaches]}


\textbf{Neural ODE works.} Our architecture is inspired by the Neural ODE video generation works MODE-GAN  \cite{kim2021continuous} , VidODE \cite{park2021vid} and \cite{kim2021continuous} with the key difference is the application; focusing on the out-of-domain generalization. An aspect that wasn't investigated in these works. Also, NeuralPrefix targets sparse (\update{lower-dimensional}) sensory data rather than vision data. For this, ours is purposefully simpler (e.g. no GAN as followed in \cite{park2021vid, kim2021continuous}  ), and the design choices tailored for the data type considered, such as the shrinkage loss (Sec.~\ref{sec:architecture}). 

\update{\textbf{Time Series Foundational Models.} Concurrent with our efforts, recent advances in foundational models show the potential of task-agnostic data imputation (among other tasks).  Inspired by Large Language Models (LLMs), these works \cite{ansari2024chronos}  posit that a time series model trained on a large collection of multi-domain datasets can generalise to unseen domains without re-training (i.e. zero-shot). While being a promising direction, these models are huge. Making them much more expensive to train and less deployable in the sensory applications.  For example, Amazon's Chronos \cite{ansari2024chronos} leverages the T5 Transformer (710M parameters) for time series whose training requires 504 hours on A100 GPU (NeuralPrefix takes a mere 6 hours on RTX4090). }


%