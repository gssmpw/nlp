% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{subcaption}

\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\usepackage[numbers]{natbib}


\begin{document}
%
\title{Self-supervised Conformal Prediction for Uncertainty Quantification in Imaging Problems}
%
\titlerunning{SURE-based Conformal Prediction for UQ in Imaging}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Jasper M. Everink\inst{1}\orcidID{0000-0001-7263-0317} \and Bernardin Tamo Amougou\inst{2,3} \and Marcelo Pereyra\inst{2}\orcidID{0000-0001-6438-6772} }
%
\authorrunning{J.M. Everink, B. Tamo Amougou and  M. Pereyra.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Technical University of Denmark, Kgs. Lyngby, Denmark, \email{jmev@dtu.dk} \and Heriot-Watt University \& Maxwell Institute for Mathematical Sciences, Edinburgh, UK \and Universit\'e de Paris Cit\'e, Paris, France }

%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Most image restoration problems are ill-conditioned or ill-posed and hence involve significant uncertainty. Quantifying this uncertainty is crucial for reliably interpreting experimental results, particularly when reconstructed images inform critical decisions and science. However, most existing image restoration methods either fail to quantify uncertainty or provide estimates that are highly inaccurate. Conformal prediction has recently emerged as a flexible framework to equip any estimator with uncertainty quantification capabilities that, by construction, have nearly exact marginal coverage. To achieve this, conformal prediction relies on abundant ground truth data for calibration. However, in image restoration problems, reliable ground truth data is often expensive or not possible to acquire. Also, reliance on ground truth data can introduce large biases in situations of distribution shift between calibration and deployment. This paper seeks to develop a more robust approach to conformal prediction for image restoration problems by proposing a self-supervised conformal prediction method that leverages Stein's Unbiased Risk Estimator (SURE) to self-calibrate itself directly from the observed noisy measurements, bypassing the need for ground truth. The method is suitable for any linear imaging inverse problem that is ill-conditioned, and it is especially powerful when used with modern self-supervised image restoration techniques that can also be trained directly from measurement data. The proposed approach is demonstrated through numerical experiments on image denoising and deblurring, where it delivers results that are remarkably accurate and comparable to those obtained by supervised conformal prediction with ground truth data.
%Most image restoration problems are not well-posed, and thus may have some significant intrinsic uncertainty. Robustly quantifying the uncertainty in the solutions to such problems is important for the reliable interpretation of experimental results, especially if the reconstructed images are used as evidence in decision-making or science. Unfortunately, most image restoration methods do not quantify the uncertainty in the restored images, or provide uncertainty quantification estimates that are highly subjective, inaccurate, and not useful in practice yet. Conformal prediction has recently emerged as a powerful framework to endow any statistical estimator with uncertainty quantification capabilities. Conformal prediction is versatile and easy to apply to problems of small or moderate dimension. However, when applied to imaging problems and other high-dimensional problems, it often provides uncertainty estimates that are too loose and uninformative. In this paper, we propose a conformal prediction method tailored for linear imaging inverse problems. The proposed method leverages Stein's unbiased risk estimator to sharpen its uncertainty quantification results and scale robustly to high-dimensional settings. The approach is demonstrated through a series of numerical experiments related to image denoising and deblurring, where it is used to construct confidence regions for a wide range of different imaging methods.

\keywords{
Conformal Prediction \and High-Dimensional Image Restoration Problems  \and Stein's Unbiased Risk Estimate.}
\end{abstract}
%
%
%

\section{Introduction}
Image restoration tasks often carry a significant amount of uncertainty, as they admit a wide variety of solutions that are equally in agreement with the observed data. Quantifying and characterizing this uncertainty is important for applications that depend on restored images to inform critical decisions. Several statistical frameworks exist to address uncertainty quantification (UQ) in imaging sciences. Among these, the Bayesian statistical framework has been extensively studied and applied \cite{JariErkki}, enabling the incorporation of prior knowledge and providing probabilistic interpretations of uncertainty. This framework supports a diverse range of modeling and algorithmic approaches, as demonstrated in works such as \cite{Durmus2018,Pereyra2017,laumont2022bayesian,holden2022bayesian}. Unfortunately, despite significant progress in the field, state-of-the-art Bayesian imaging methods are not yet able to provide accurate UQ on structures that are larger than a few pixels in size \cite{thong2024bayesianimagingmethodsreport}. 

With regards to non-Bayesian approaches to UQ in image restoration, the recently proposed equivariant bootstrapping method \cite{tachella2023equivariant} offers excellent frequentist accuracy, even for large image structures. This is achieved by exploiting known symmetries in the problem to reduce the bias inherent to bootstrapping. Equivariant bootstrapping is particularly accurate in problems that are highly ill-posed, such as compressive sensing, inpainting and limited angle tomography and radio-interferometry, as in these cases the bias from bootstrapping is almost fully removed by the actions of the symmetry group \cite{tachella2023equivariant,Liaudat2024}. Conversely, equivariant bootstrapping struggles with problems that are not ill-posed, such as image denoising or mild deblurring, as in this case it is difficult to identify symmetries to remove the bias from bootstrapping (see \cite{tachella2023equivariant} for details).

Moreover, when sufficient ground truth data are available for calibration, conformal prediction presents another highly flexible strategy for UQ in image restoration. Crucially, conformal prediction can be seamlessly applied to any image restoration technique to deliver UQ results that, by construction, have nearly exact marginal coverage \cite{angelopoulos2021gentle}. Also, conformal prediction can be easily combined with other UQ strategies, such as Bayesian imaging strategies (see, e.g., \cite{narnhofer2024posterior}) or equivariant bootstrapping \cite{Liaudat2024}, as a correction step. %As a result, there is significant interest in incorporation conformal prediction within imaging pipelines.

However, as mentioned previously, in its original form, conformal prediction approaches require access to abundant ground truth data for calibration. In many applications, access to ground truth data is either expensive or impossible. Also, reliance on ground truth data for calibration can lead to poor accuracy in situations of distribution shift between calibration and deployment. To address this limitation of conformal prediction, we propose a self-supervised conformal prediction method that leverages Stein's Unbiased Risk Estimator (SURE) to self-calibrate UQ results directly from the observed noisy measurements, bypassing the need for ground truth.

The remainder of this paper is organized as follows. Section \ref{sec:background} provides an overview of conformal prediction and a formal problem statement. Section \ref{sec:method} introduces the proposed self-supervised conformal prediction method. Section \ref{sec:experiments} demonstrates the proposed approach through numerical experiments on image denoising and non-blind deblurring tasks and by considering model-based as well as learning-based estimators. Conclusions and perspectives for future work are finally reported in Section \ref{sec:discussion}.

% Image restoration tasks often require solving an inverse problem that is ill-posed, and which can consequently involve significant uncertainty about the unobserved true image. Quantifying and characterising this uncertainty is important for applications that rely on the restored images to inform important decisions. There are several statistical frameworks available to formulate and solve uncertainty quantification problems in imaging sciences. For example, many uncertainty quantification methods for image restoration rely on the Bayesian statistical framework \cite{calvetti2018inverse}, which can be implemented by using a wide range of modelling and algorithmic approaches (see, e.g., \cite{Durmus2018,Pereyra2017,laumont2022bayesian,holden2022bayesian}). One can also consider uncertainty quantification methods based on bootstrapping (see \cite{tachella2023equivariant}), which delivers the most accurate uncertainty quantification results to date. Alternatively, when there is enough calibration data available, it is possible to perform uncertainty quantification by using conformal prediction \cite{angelopoulos2021gentle}, which is highly flexible and can be deployed in combination with any image restoration technique.

% Conformal prediction has been recently successfully applied to a range of imaging problems (see, e.g., \cite{angelopoulos2022image, narnhofer2024posterior}). However, existing conformal prediction approaches for imaging focus on pixel-wise uncertainty. Therefore, the statistical guarantees provided by the conformal prediction framework only hold marginally per pixel. This is a strong limitation because decisions based on image data usually involve a many image pixels. However, scaling conformal prediction to large regions is difficult because the results become vague and uninformative. There has been some research on designing conformal prediction strategies for problems of moderate dimension (see, e.g., \cite{messoudi2020conformal, messoudi2021copula, messoudi2022ellipsoidal}), but the dimensionality encountered in imaging problems is beyond the reach of these strategies. 

% In this paper, we propose a method that leverages Stein's unbiased risk estimator to scale conformal prediction to high-dimensional problems, so that it can be applied to image restoration. The paper is structured as follows. Section \ref{sec:background} introduces conformal prediction. Then in Section \ref{sec:method} we present our proposed method. Following on from this, Section \ref{sec:experiments} illustrates the proposed approach on image denoising, deblurring
% and computed tomography experiments
% . Conclusions and perspectives for future work are finally reported in Section \ref{sec:discussion}.

%\newpage

\section{Problem statement}\label{sec:background}

We consider the estimation of a set of plausible values for an unknown image of interest \( x^\star \in \mathbb{R}^n \), from a noisy degraded measurement \( y \in \mathbb{R}^m \). We assume that \( x^\star \) is a realization of a random variable \( X \), and \( y \) is a realization of the conditional random variable \( Y | X = x^\star \). A point estimator for \( x^\star \), derived from \( Y \), is henceforth denoted by \( \hat{x}(Y) \). We focus on the case where observations follow a Gaussian noise model:
\[
(Y | X = x^\star) \sim \mathcal{N}(Ax^\star, \sigma^2 \mathbb{I}_m),
\]
where \( A \in \mathbb{R}^{m \times n} \) models deterministic instrumental aspects of the image restoration problem, \( \sigma^2 > 0 \) is the noise variance, and \( \mathbb{I}_m \) is the \( m \times m \) identity matrix. Throughout the paper we assume $A$ is a full-rank but potentially highly ill-conditioned linear operator. %The generalisation to other noise models, such as Poisson, and Poisson-Gaussian is straightforward and will be discussed later. 


%The observation \( Y \) represents a degraded version of the underlying true signal \( x^\star \), projected into a lower-dimensional measurement space and corrupted by additive Gaussian noise.



Our goal is to construct a region \( C(Y) \subset \mathbb{R}^n \) in the solution space such that

\begin{equation}\label{predictionC}
    \mathbb{P}_{(X, Y)}\left(X \in C(Y) \right) \geq 1-\alpha\,,
\end{equation}
where the probability is taken with respect to the joint distribution of \( (X, Y) \), and \( \alpha \in [0,1] \) specifies the desired confidence level.

To illustrate, suppose that \( x^\star \) is a high-resolution MRI scan of an adult brain. The random variable \( X \) characterizes the distribution of brain MRI scans for a generic individual within the population, as obtained by an ideal noise-free and resolution-perfect MRI scanner. The specific image \( x^\star \) corresponds to an MRI scan of a particular individual, while \( y \) represents the noisy, degraded measurement acquired in practice. The estimator \( \hat{x}(y) \) produces an estimate of \( x^\star \). The region \( C(y) \) encapsulates a set of plausible solutions, rather than a single estimate, and satisfies the guarantee in \eqref{predictionC}. This means that if the procedure is repeated across a large number of individuals from the population, the constructed regions \( C \) will contain the respective true images \( x^\star \) in at least \( 1-\alpha\) of the cases.







% We consider the problem of estimating a set of likely values for an unknown image of interest $x^\star \in \mathbb{R}^n$, from some measurement $y = Ax^\star + e \in \mathbb{R}^n$ where $A \in \mathbb{R}^{m \times n}$ models deterministic instrumental aspects of the estimations problem and $e$ represents some additive error. We assume that $x^\star$ is a realisation of some random variable $X$, and $y$ is a realisation of the conditional random variable $Y|X=x^\star$. By $\hat{x}(y)$ we denote a technique to estimate $x^\star$ from $y$ (a point estimator). 

% We seek to identify a region $C(Y) \subset \mathbb{R}^n$ of the solution space such that 
% \begin{equation}\label{predictionC}
    % \mathbb{P}_{(X, Y)}\left(X \in C(Y) \right) \geq 1-\alpha\,,
% \end{equation}
% where we note that the probability is w.r.t. to the joint distribution $(X,Y)$.%under new realisations of $X$ and $Y$ from repetitions of the experiment. 

% For illustration, suppose that $x^\star$ is a high-resolution MRI scan of an adult brain. The random variable $X$ provides a probabilistic description of what an adult brain MRI scan looks like for a generic individual of the population, as acquired by an ideal MRI scanner with no noise or resolution limitations. The image $x^\star$ is a sample of $X$ stemming from imaging a specific member of that population with that ideal MRI scanner. The data ${y}$ represents the actual measurement obtained, which is corrupted by noise and other forms of degradation. The estimator $\hat{x}(y)$ provides an estimate of $x^\star$. The region $C(y)$ gathers a set of solutions, rather than a single point, and property \eqref{predictionC} states that, if we repeat this procedure a large number of times with different members of the population, we should expect their respective regions $C$ to contain their respective ``true'' brain scan in at least $(1-\alpha)$\% of the cases.





Conformal prediction provides a general framework for constructing sets \( C \) with the desired probabilistic guarantee \cite{angelopoulos2021gentle}. This is achieved using a \emph{non-conformity measure} \( s: \mathbb{R}^n \times \mathbb{R}^m \to \mathbb{R} \). By computing the top \((1-\alpha)\)-quantile \( q_\alpha \) of the statistic \( s(X, Y) \), the set \( C(y) \) is defined as:
\[
C(y) := \{x \in \mathbb{R}^n \,|\, s(x, y) \leq q_\alpha\} \quad \text{for all } y \in \mathbb{R}^m.
\]
By construction, this set satisfies:
\[
\mathbb{P}_{(X, Y)} \big(X \in C(Y)\big) = \mathbb{P}_{(X, Y)} \big(s(X, Y) \leq q_\alpha \big) \geq 1 - \alpha,
\]
for any confidence level \( \alpha \in (0, 1) \). With a sufficiently large sample \(\{x_i, y_i\}_{i=1}^M\) to calibrate \( q_\alpha \), any suitable function \( s \) can be used to construct a set \( C \) that contains \( x^\star \) with high probability under the joint distribution of \((X, Y)\).

A popular specific implementation of this framework is \emph{split conformal prediction}. Given a training sample \(\{X_i, Y_i\}_{i=1}^M\) of independent (or exchangeable) realizations of \((X, Y)\), the method estimates the top \(\frac{\lceil(M+1)(1-\alpha)\rceil}{M}\)-quantile \(\hat{Q}_\alpha\) of \(\{s(X_i, Y_i)\}_{i=1}^M\). For a new observation \((X_{\text{new}}, Y_{\text{new}})\), the prediction set is then:
\[
\hat{C}(Y_{\text{new}}) := \{X_{\text{new}} \in \mathbb{R}^n \,|\, s(X_{\text{new}}, Y_{\text{new}}) \leq \hat{Q}_\alpha\}.
\]
This set satisfies the guarantee:
\begin{equation}\label{eq:conformal_guarantee}
    \mathbb{P}_{(X, Y)^{M+1}}\left(X_{\text{new}} \in \hat{C}(Y_{\text{new}}) \right)  
    \geq 1-\alpha\,,
\end{equation}
where the probability accounts for the joint distribution of the \( M \) training samples and the new observation. Notably, this formulation includes a finite-sample correction because \(\hat{Q}_\alpha\) is derived from the \(\frac{\lceil(M+1)(1-\alpha)\rceil}{M}\)-quantile. This correction becomes negligible as \( M \to \infty \).
For an excellent introduction to conformal prediction, please see \cite{angelopoulos2021gentle}.






% Conformal prediction provides a general framework to construct such set $C$ \cite{angelopoulos2021gentle}. This is achieved by using a so-called \emph{non-conformity measure} or score function $s: \mathbb{R}^n \times \mathbb{R}^m\mapsto\mathbb{R}$. If we take the top $(1-\alpha)$-quantile $q_\alpha$ of the statistic $s(X, Y)$ and define $C(y) := \{x\in \mathbb{R}^n \,|\, s(x,y) \leq q_\alpha\}$ for all $y \in \mathbb{R}^m$, then by construction
% \begin{equation*}
    % \mathbb{P}_{(X, Y)}\left(X \in C(Y) \right) = \mathbb{P}_{(X, Y)}\left(s(X, Y) \leq q_\alpha \right) \geq 1-\alpha,
% \end{equation*}
% for any $\alpha \in (0,1)$. Following this procedure, and given a sufficient large sample $\{x_i,y_i\}_{i=1}^M$ to calibrate $q_\alpha$, any suitable score $s$ can be used to construct a set $C$ that contains $x$ with high probability w.r.t. the joint distribution of $(X,Y)$. 

% More precisely, the split conformal prediction approach considers a training sample $\{X_i, Y_i\}_{i=1}^M$ of independent (or at least exchangeable) copies of $(X, Y)$ from which we take the empirical top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile $\hat{Q}_\alpha$ of $\{s(X_i,Y_i)\}_{i=1}^{m}$. Then, for a new copy $(X_{new}, Y_{new})$ of $(X,Y)$, the set $\hat{C}(Y_{new}) := \{X_{new}\in \mathbb{R}^n\,|\, s(X_{new},Y_{new}) \leq \hat{Q}_\alpha\}$ satisfies
% \begin{equation}\label{eq:conformal_guarantee}
%     \mathbb{P}_{(X, Y)^{M+1}}\left(X_{\text{new}} \in \hat{C}(Y_{\text{new}}) \right)  
%     \geq 1-\alpha\,,
% \end{equation}
% and where we note that \eqref{eq:conformal_guarantee} implicitly contains a finite-sample correction because $\hat{Q}_\alpha$ is derived from a $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile; this correction vanishes as $M\rightarrow\infty$.
% Please see \cite{angelopoulos2021gentle} for an excellent introduction to conformal prediction.





While the conformal prediction framework is highly flexible, not all non-conformity measures \( s(x, y) \) deliver prediction regions that are equally useful in practice. Indeed, all prediction sets \( \hat{C}(y) \) take the form of a sub-level set of the function \( x \mapsto s(x, y) \), which can be arbitrarily chosen. As a result, it is possible to construct infinitely many regions in \( \mathbb{R}^n \) that satisfy the guarantee of containing the true solution \( x^\star \) with probability at least \( 1-\alpha \). However, many of these regions may be excessively large, especially in high-dimensional settings, where poorly designed score functions \( s(x, y) \) can lead to regions \( \hat{C}(y) \) that are overly conservative and cover most of the support of \( X \). 

Carefully designing \( s(x, y) \) allows obtaining conformal prediction sets that are compact and informative, even in high dimension. In particular, it is essential that \( s(x, y) \) is constructed in a way that reduces the variability of \( s(X, Y) \)% and allows scaling to large problems without Several approaches have been recently proposed to scale conformal prediction to high-dimensional problems (see, e.g., \cite{johnstone2021conformal, messoudi2020conformal, messoudi2021copula, messoudi2022ellipsoidal})
. Of particular interest are normalized non-conformity measures of the form \cite{johnstone2021conformal}:
\begin{equation}\label{eq:score_multi_target}
s(x, y) = \|x - \hat{x}(y)\|^2_{\Sigma(y)} = \left(x - \hat{x}(y)\right)^\top \Sigma(y) \left(x - \hat{x}(y)\right),
\end{equation}
where \( \Sigma(y) \) is a positive definite matrix of size \( n \times n \). A well-chosen \( \Sigma(y) \) reduces variability in \( s(X, Y) \), leading to prediction sets that are well-centered around \( \hat{x}(y) \), compact, and highly informative. In practice, \( \Sigma(y) \) is often chosen as an approximation of the inverse-covariance matrix of the error $X-\hat{x}(Y)$ \cite{johnstone2021conformal}.

%These sets satisfy property \eqref{eq:conformal_guarantee} by construction.

%In prior work, \( \Sigma(y) \) is often chosen as an approximate inverse-covariance matrix. For instance, \cite{johnstone2021conformal} propose estimating this matrix globally based on the errors in a sample \( \{x_i, y_i\}_{i=1}^M \). However, this global approach neglects local variations in \( y \), which are essential in high-dimensional problems. To address this, \cite{messoudi2022ellipsoidal} suggest refining the global matrix by incorporating errors from the \( k \)-nearest neighbors \( \{x_i, y_i\}_{i=1}^k \) of \( y \). While this method captures some local variability, it requires a large amount of data to accurately estimate the local uncertainty.

A fundamental obstacle to applying conformal prediction to image restoration problems is the need for paired samples \( \{x_i, y_i\} \), as obtaining the ground truth image \( x_i \) is precisely the goal of solving the imaging problem in the first place. This can be partially mitigated by relying on a training dataset, at the risk of delivering poor results in situations of distribution shift (e.g., returning to our illustrative example related to MRI imaging, when the population encountered in deployment differs significantly from the population used for calibration). In this paper, we propose a greatly more robust and deployable approach to conformal prediction that relies solely on the observed measurements \( \{y_i\}_{i=1}^M \). %We achieved it using Stein's Unbiased Risk Estimate (SURE) \cite{stein1981estimation} and by  leveraging this calibration strategy, conformal prediction sets can be constructed to reflect uncertainty effectively, even in the absence of ground truth data.

% This approach focuses on aligning the score function with the structure of the estimation problem and calibrating it dynamically using observed measurements which introduces a degree of data-driven adaptability, ensuring the prediction sets remain meaningful and practically useful. 







% Although the resulting score may not be fully \( y \)-adaptive in the strictest sense (e.g., due to a fixed choice of \( \Sigma \)), the calibration process introduces a degree of data-driven adaptability, ensuring the prediction sets remain meaningful and practically useful.









% While the conformal prediction framework is highly flexible, not all score functions $s(x,y)$ deliver regions that are equally useful in practice. Indeed, all prediction sets $\hat{C}(y)$ take the form of a sub-level set of the arbitrarily chosen $x \mapsto s(x,y)$. Hence, it is possible to construct infinitely many regions of the space $\mathbb{R}^{n}$ that will contain the truth $x^\star$ given the observed data $y$ with probability at least $1-\alpha$, but some of these regions might be extremely large. This issue is particularly prominent in high-dimensional problems, where a poor choice of score function $s(x,y)$ will lead to a region $\hat{C}(y)$ that covers most of the support of $X$. Carefully designing $s(x,y)$ is the crux to obtaining a conformal prediction set that is small and informative. In particular, it is essential that $s(x,y)$ adapts to $y$ so that the statistic $s(X,Y)$ has low variability.

% Several approaches have been recently proposed to scale conformal prediction to high dimensions (see, e.g., \cite{messoudi2020conformal, messoudi2021copula, messoudi2022ellipsoidal}). Of particular interest is the normalised score of the form
% \begin{equation}\label{eq:score_multi_target}
% \begin{split}
%     s(x, y) &= \|x-\hat{x}(y)\|^2_{\Sigma(y)}\,,\\ &= \left(x-\hat{x}(y)\right)^\top \Sigma(y) \left(x-\hat{x}(y)\right)\,,
%     \end{split}
%     \end{equation}
% for some positive definite matrix $\Sigma(y)$ of size $n \times n$, which is chosen such that $s(X, Y)$ exhibits low variability. A successful choice of $\Sigma(y)$ will lead to conformal prediction sets that are centred on $\hat{x}(y)$ and are small in space and therefore highly informative. Furthermore, they satisfy property \eqref{eq:conformal_guarantee} by construction.

% In previous work, $\Sigma(y)$ is chosen as an approximate inverse-covariance matrix. In \cite{johnstone2021conformal}, they propose to estimate this inverse-covariance matrix globally from the errors in a sample $\{x_i,y_i\}_{i=1}^M$. Because this matrix does not depend on $y$, they proposed in \cite{messoudi2022ellipsoidal} to improve this global inverse-covariance matrix using errors of the k-nearest neighbours $\{x_i,y_i\}_{i=1}^k$ of $y$. However, when extending these approaches to higher dimensional problems, this improved matrix requires a large amount of data to properly capture the local uncertainty. We propose instead to leverage the form of the estimation problem and consider constructing $y$-adaptive score functions by using Stein's unbiased risk estimate (SURE) \cite{stein1981estimation}.

\section{Proposed Method}\label{sec:method}

Our proposed self-supervised conformal prediction method circumvents the need for ground truth data by leveraging Stein's unbiased risk estimate (SURE) \cite{stein1981estimation}. 

We begin by pooling together $M$ exchangeable imaging problems, where each problem involves an unknown image $x^{\star}_i$ and an observation $y_i$ which we consider to be a realisation of the conditional random variable $(Y|X=x^{\star}_i) \sim \mathcal{N}(Ax^{\star}_i,\sigma^2\mathbb{I}_m)$. To specify the non-conformity measure, we  consider $\Sigma(y)=A^\top A$ which is a natural choice for approximation for the error inverse-covariance when $(Y|X=x^{\star}_i) \sim \mathcal{N}(Ax^{\star}_i,\sigma^2\mathbb{I}_m)$, as we expect $\hat{x}(Y)$ to be accurate along the leading eigenvectors of $A^\top A$ and the estimation error to concentrate along weak eigenvectors of $A^\top A$. This leads to the non-conformity measure
\begin{equation} \label{score}
  s(x, y) = \frac{1}{m}\|Ax - A\hat{x}(y)\|_2^2,  
\end{equation}
where we recall that $A$ is assumed full-rank, but potentially very poorly conditioned . We require $A$ to be full rank as otherwise $\Sigma(y)$ is only positive semidefinite, implying that the corresponding prediction set can be unbounded.
 
To calibrate without ground truth data, instead of relying on a sample quantile of $\{s(x_i,y_i)\}_{i=1}^M$, we rely on SURE to provide unbiased estimates of $\{s(x_i,y_i)\}_{i=1}^M$ from the observed measurements $\{y_i\}_{i=1}^M$. We then use those noisy quantile estimates for calibration, at the expense of a small amount of bias. 

More precisely, assuming that the estimator $\hat{x}$ is differentiable almost everywhere, the SURE estimate of \eqref{score} is given by  
\begin{equation}\label{eq:SURE}
 \textrm{SURE}(y) =   \frac{1}{m}\|y - A \hat{x}(y)\|_2^2 -\sigma^2 + \frac{2\sigma^2}{m} \text{div} \left(A \hat{x}(y)\right)\,,  
\end{equation}
where \( \operatorname{div}(\cdot) \) denotes the divergence operator \cite{stein1981estimation}. It is easy to show that $\textrm{SURE}(Y)$ provides an estimate of $s(X, Y)$ that is unbiased \cite{stein1981estimation}. Crucially, when $m = \textrm{dim}(y)$ is large, the estimate provided by SURE is not only unbiased but also often very accurate (see \cite{stein1981estimation,bellec2021second} for a theoretical analysis of the variance of SURE and \cite{6545395} for an empirical analysis in an imaging setting). As a consequence, we expect that the conformal calibration quantiles obtained from SURE will be in close agreement with the true quantiles of $s(X,Y)$, ensuring that the resulting conformal prediction sets nearly maintain their desired coverage properties.

With regards to the evaluation of SURE, for some model-based estimators it is possible to identify a closed-form expression \cite{tibshirani2012degrees}. Otherwise, computing SURE requires a numerical approximation of the divergence term. A common approach is the Monte Carlo SURE (MC-SURE) algorithm \cite{ramani2008monte}, which is estimator-agnostic. We use the so-called Hutchinson's stochastic trace approximation method \cite{9054593}, which is more computationally efficient than MC-SURE and does not require hyper-parameter fine-tuning. More precisely, the divergence \( \text{div}(A\hat{x}(y)) \) is approximated as follows:

\begin{align}
  \text{div}(A\hat{x}(y)) = \text{trace}(\boldsymbol{J}_{h(y)}) &=\mathbb{E}[\tilde{n}^\top \boldsymbol{J}_{h(y)}\tilde{n}]  , \\
   &\approx \frac{1}{K} \sum_{i=1}^{K} \tilde{n}_i^\top \boldsymbol{J}_{h(y)}\tilde{n}_i, \label{eq:MC-SURE_H}  \\
   & \approx \frac{1}{K} \tilde{n}^\top \boldsymbol{J}_{\tilde{n}^ \top  h(y )}, \label{eq:MC-SURE_N} 
\end{align}
where $\{\tilde{n}_i\}_{i=1}^K$ are a $K$ i.i.d. standard normal random vectors, \( \boldsymbol{J}_{h(y)} \) is the Jacobian matrix of the predicted measurements \( h(y) = A\hat{x}(y) \) with respect to \( y \), and \eqref{eq:MC-SURE_H} corresponds to Hutchinson's method, which for computationally efficiency we implement \eqref{eq:MC-SURE_N} using automatic differentiation, as suggested in \cite{9054593}. This allows obtaining accurate SURE estimates in a highly efficient manner, even in very large problems.

Adopting a split-conformal strategy, after computing $\hat{x}(y_i)$ and $\textrm{SURE}(y_i)$, for each $i = \{1,\ldots,M\}$ we construct the $(1-\alpha)$-prediction set \( \hat{C}(y_i) \) as:
\[
\hat{C}(y_i) = \{x \in \mathbb{R}^n : \|Ax - A\hat{x}(y_i)\|_2^2/m \leq \hat{Q}^{(i)}_\alpha\},
\]
where \( \hat{Q}^{(i)}_\alpha \) is the top $\frac{\lceil M(1-\alpha)\rceil}{M-1}$-quantile of the sample $\{\textrm{SURE}(y_j)\}_{j=1}^M$ with the $i$th element, $\textrm{SURE}(y_i)$, removed. Note that while the proposed approach has some bias due to the estimation error introduced by SURE, in our experience the bias is small and arguably significantly smaller than the bias that is likely to be incurred due to distribution shift in deployment. It is also worth mentioning that the estimates $\textrm{SURE}(y_i)$ can be computed in parallel. The proposed method is summarised in Algorithm \ref{alg:one} below.



































% The score could the be  adapts to $y$ in a manner that delivers conformal prediction regions that 

% We propose two strategies that leverage SURE to construct a score function $s(x,y)$ that adapts to $y$ in a manner that delivers conformal prediction regions that centred on $\hat{x}(y)$, are compact in space (relative to non-adaptive regions), and satisfy \eqref{eq:conformal_guarantee}. 

%Let consider  a Gaussian observation model of the form $(Y|X=x^\star) \sim \mathcal{N}(Ax^\star,\sigma^2 \mathbb{I}_m)$ with noise variance $\sigma^2 > 0$ and possibly poorly conditioned $A$.

% \subsection{Stein's unbiased risk estimator (SURE)}
% For our proposed strategy, we use 
% $$
% \Sigma(y) = \frac{1}{\textrm{SURE}(y)}A^\top A\,,
% $$
% where SURE is an estimate of the projected mean squared error $\|Ax^\star-A\hat{x}(y)\|_2^2$ where $y$ is a realisation of $Y|X=x^\star$. 

% Following \cite{stein1981estimation}, if the estimator $\hat{x}$ is differentiable almost everywhere, the SURE is given by  
% \begin{equation}\label{eq:SURE}
%  \textrm{SURE}(y) = -m\sigma^2 + \|y - A \hat{x}(y)\|_2^2 + 2\sigma^2 \text{div} \left(A \hat{x}(y)\right)\,,  
% \end{equation}
% %    \text{div} \left(A\hat{x}(y) &:= \sum_{j = 1}^{m}\frac{\partial A\hat{x}}{\partial y_j}(y),
% where $\text{div}(\cdot)$ denotes the divergence operator. The SURE is know quite accurate estimator of the projected mean squared error (see, e.g., \cite{bellec2021second}) and, for some estimators $\hat{x}$, efficiently computable closed-form expressions of this divergence are available (see, e.g., \cite{tibshirani2012degrees}). In general, and thus in alignment with the black-box nature of conformal prediction, we can estimate the divergence numerically \cite{ramani2008monte,nobel2023tractable}. Of particular interest is the Monte Carlo SURE (MC-SURE) approach \cite{ramani2008monte}, which is agnostic to the nature of the estimator $\hat{x}$: given $\epsilon > 0$ and a sequence of Rademacher, or more generally isotropic, random variables $\{d_i\}_{i = 1}^{K} \sim d$, the MC-SURE approximates $\text{div} \left(A \hat{x}(y)\right)$ as follows:
% \begin{align}
% \text{div} \left(A \hat{x}(y)\right) &= \mathbb{E}[d^TD(A\hat{x})(y)d] \approx \frac{1}{K}\sum_{i = 1}^{K}d_i^TD(A\hat{x})(y)d_i\label{eq:MC-SURE_1}\\
% &\approx \frac{1}{K}\sum_{i = 1}^{K}d_i^T \frac{(A\hat{x}(y + \epsilon d_i) - A\hat{x}(y))}{\epsilon}\,,\label{eq:MC-SURE_2}
% \end{align}
% where $D(A\hat{x})(y)$ denotes the Jacobian matrix of the predicted measurements $A\hat{x}$ at the actual measurements $\vec{y}$. The stochastic trace approximation in \eqref{eq:MC-SURE_1}, know as Hutchinson's method \cite{hutchinson1989stochastic}, has in recent years been superseded by more state-of-the-art stochastic trace estimation algorithms. To reduce the number of directional derivative approximation $D(A\hat{x})(y)d$, and thus the number of estimations $\hat{x}$, we propose to use the XTrace algorithm \cite{epperly2024xtrace}, and keep the forward finite difference approximation of the directional derivative.

% \subsection{SURE-adjusted conformal prediction}
% Using the general form of \eqref{eq:score_multi_target} and levering the concentration properties of \eqref{eq:SURE}, we propose the conformal prediction score 
% \begin{equation}\label{eq:score_mul}
%     s_{\text{mul}}(x,y) = \frac{\|Ax-A\hat{x}(y)\|_2^2}{{SURE}(y)}\, . 
% \end{equation}
% We refer to this strategy as a multiplicatively-normalised score because $\textrm{SURE}(y)$ appears in the denominator of \eqref{eq:score_mul}. Note however, that the SURE \eqref{eq:SURE}, especially when using approximation \eqref{eq:MC-SURE_2}, is not guaranteed to be positive. In the case that the SURE estimate is positive, a prediction set computed using $s_{\text{mul}}$ is the interior of an ellipse, but whet the SURE estimate is negative, the prediction set is the exterior of an ellipse and therefore unbounded. This scenario can easily occur when the projected mean square error is relatively low or the SURE estimation is done inaccurately.

% To reduce this issue, we also propose an alternative strategy that is more stable by normalizing the score in an additive manner
% \begin{equation}\label{eq:score_add}
%     s_{\text{add}}(x,y) = \|Ax-A\hat{x}(y)\|_2^2 - \textrm{SURE}(y)\,,
% \end{equation}
% which is more robust to the stochasticity of $\textrm{SURE}(y)$. We refer to this strategy as an additively-normalised score.

% Using a calibration set $\{x_i,y_i\}_{i = 1}^M$ with \eqref{eq:score_mul} or \eqref{eq:score_add}, we can construct two conformal prediction sets by computing the top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantiles
% $\hat{Q}_{\text{mul},\alpha}$ and $\hat{Q}_{\text{add},\alpha}$ of $s_{\text{mul}}(X,Y)$ and $s_{\text{add}}(X,Y)$ respectively. Whilst for $s_{\text{mul}}$ an unbounded prediction set is obtained when $\textrm{SURE}(y) < 0$, for $s_{\text{add}}$ and empty prediction set is obtained when $\textrm{SURE}(y) < \hat{Q}_{\text{add},\alpha}$, which is a less likely event.

% The proposed strategies are summarised in Algorithm \ref{alg:one} below. This might seem very expensive, due to the great number of SURE estimations, each requiring multiple evaluations of the estimator $\hat{x}$. However, the $M$ SURE estimations in line 2 and the single SURE estimation in line 10 are all independent of each other. Similarly, all the directional derivative estimation in \eqref{eq:MC-SURE_2} are independent and can be done in parallel. (With the minor detail that the XTrace algorithm requires two sequential passes of these estimations.) Thus, Algorithm \ref{alg:one} can be implemented in an embarrassingly parallel manner and most of the computations can be done before receiving the new measurements $y$, making it highly suitable for distributed computing systems.
\begin{algorithm}
\caption{SURE-based conformal prediction}\label{alg:one}

\begin{algorithmic}[1]
\Require{Forward operator $A$, noise variance $\sigma^2$, estimator $\hat{x}$, measurement $y$, samples $\{y_i\}_{i = 1}^M$, precision level $1-\alpha \in (0,1) . $}  
\Statex
\For{$i \gets 1$ to $M$}                    
    \State {$S_i \gets \textrm{SURE}(y_i)$ using \eqref{eq:SURE} and \eqref{eq:MC-SURE_N}}
    % \If{$s_{\text{mul}}$}
    %     \State $s_i \gets \frac{\|Ax_i-A\hat{x}(y_i)\|_2^2}{S_i}$
    % \ElsIf{$s_{\text{add}}$}
    %     \State $s_i \gets \|Ax_i-A\hat{x}(y_i)\|_2^2 - S_i$
    % \EndIf
\EndFor

\State {$\hat{Q}_\alpha$ $\gets$ top $\frac{\lceil(M+1)(1-\alpha)\rceil}{M}$-quantile of $\{S_i\}_{i = 1}^M$}
\State $m  \gets dim(y)$

% \State {$S \gets \textrm{SURE}(y)$ using \eqref{eq:SURE} and \eqref{eq:MC-SURE_2}}



% \If{$s_{\text{mul}}$}
\State {$\hat{C}(y)$ $\gets$ $\{x\in \mathbb{R}^n\,|\, \|Ax-A\hat{x}(y)\|_2^2 / m\leq  \hat{Q}_\alpha\}$}
%% \ElsIf{$s_{\text{add}}$}
% \State {$\hat{C}(y)$ $\gets$ $\{x\in \mathbb{R}^n\,|\, \|Ax-A\hat{x}(y_{\text{new}})\|_2^2 \leq S + \hat{Q}_\alpha\}$}
% \EndIf
\Statex 
\Ensure{Prediction set $\hat{C}(y)$}
\end{algorithmic}
\end{algorithm}













\section{Experiments}\label{sec:experiments}
We demonstrate the proposed self-supervised conformal prediction approach by applying it to two image restoration problems: {image denoising} and {image deblurring}. To showcase the versatility of the method, for image denoising we construct conformal prediction sets by using a learning-based image restoration technique trained in a self-supervised end-to-end manner, whereas for image deblurring we use the model-driven technique. %Fig. \ref{fig:reconstruction} for examples from these two problems.
For each experiment, we implement our method by using Algorithm \ref{alg:one} to compute conformal prediction sets. We consider a fine grid of values for the confidence parameter \( \alpha \in (0,1) \), ranging from $0\%$ to $100\%$. The corresponding prediction sets should cover the solution space with a probability of approximately \( 1-\alpha \). We evaluate the accuracy of these prediction sets by calculating the empirical coverage probabilities on a test set. Specifically, we compute the proportion of test images that lie within the conformal prediction sets for various confidence levels. In all experiments, the calibration sample size \( M \) is chosen to be sufficiently large to ensure that the variability of the sample quantiles caused by the finite-sample correction is negligible. Furthermore, for comparison, in each experiment we also report results by supervised conformal prediction (i.e., using ground truth data for calibration, rather than SURE). %, as well as results from the equivariant bootstrapping technique proposed recently in \cite{tachella2023equivariant}. 
The experiments are implemented using the Deep Inverse library\footnote{https://deepinv.github.io/deepinv/} for imaging with deep learning using PyTorch. 




%Furthermore, 

%we provide comparisons with a supervised conformal prediction to the equivariant bootstrap, which our approach greatly outperforms on these image restoration problems. Additionally, we compare the self-supervised conformal prediction method with its supervised counterpart, which achieves the most accurate uncertainty quantification. Remarkably, the results show that the self-supervised approach is very close to, and in some cases (deblurring See Fig. \ref{fig:deblurring})  almost identical to, its supervised version, highlighting its effectiveness and reliability. The experiments are conducted using the Deep Inverse library\footnote{https://deepinv.github.io/deepinv/} for imaging with deep learning using PyTorch. 




\begin{figure}[h!]
    \centering
    \includegraphics[width=1\linewidth]{Graphs/reconstructions.png}
    \caption{\textbf{Image reconstruction results for various imaging problems}. Top:  Gaussian noise on DIV2K.  Bottom:
Noisy Gaussian blur on DIV2K }
    \label{fig:reconstruction}
\end{figure}

%, and the results highlight the ability of the proposed method to provide accurate uncertainty quantification across a range of restoration tasks.



% We now illustrate the proposed conformal prediction approach by applying it to three image restoration problems: image denoising, image deblurring and computed tomography. To show the versatility of the method, we consider the construction of conformal prediction sets for both model-driven and data-driven image restoration techniques. We conduct the following image restoration experiments using the deep inverse library \cite{Tachella_DeepInverse_A_deep_2023} :

\subsection{Image Denoising}
For the image denoising experiment, we consider colour images of size $128 \times 128$ pixels obtained by cropping images from the DIV2K dataset \cite{Agustsson_2017_CVPR_Workshops}, which we artificially degrade by adding white Gaussian noise with a standard deviation of \( \sigma = 0.1 \). As image restoration method, we use a DRUNet model \cite{zhang2021plug} trained in a self-supervised manner by using the SURE loss \cite{tachella2024unsure}. The training data consists of $900$ noisy measurements, we do not use any form of ground truth for training or for conformal prediction. See the top row of Fig. \ref{fig:reconstruction} for an example of a clean image, its noisy measurement, and the estimated reconstruction. We then use these same noisy images to compute our proposed self-supervised conformal prediction sets, and assess their accuracy empirically by using $200$ measurement-truth pairs from the test dataset. The results are reported in Fig. \ref{fig:denoising} below, together with the results obtained by using the equivalent supervised conformal prediction approach that relies on ground truth data for calibration. We observe that our method delivers prediction sets that are remarkably accurate and in close agreement with the results obtained by using supervised conformal prediction, demonstrating that the bias stemming from using SURE instead of ground truth data is negligible in this case. For completeness, Fig. \ref{fig:histogram} (left) below shows the empirical distribution of the non-similarity function $s(x,y)$ for the supervised conformal prediction based on the MSE, and the proposed self-supervised conformal prediction based on a SURE estimate of the MSE. Again, we observe close agreement between these distributions, with the SURE distribution being slightly more spread due to the random error inherent to SURE. %Moreover, for completeness we also report the results obtained by equivariant bootstrapping \cite{tachella2023equivariant}, which is significantly less accurate for this problem\footnote{The bootstrap is implemented by using rotation and two-dimensional shifts. Rotations are sampled from a Gaussian distribution with zero mean and a standard deviation of \( \sigma_{\theta} \) (denoising: \( \sigma_{\theta} = 125 \), deblurring: \( \sigma_{\theta} = 200 \)), while horizontal and vertical shifts are sampled from a uniform distribution on \( [-\Delta t, \Delta t] \) pixels (denoising: \( \Delta t = 250 \)}. The lack of accuracy of equivariant bootstrapping stems 

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.75\textwidth]{Graphs/coveragedenoisingwithoracle.png}
    \caption{\textbf{Image denoising experiment}: desired confidence level vs empirical coverage. Both supervised and the proposed self-supervised conformal prediction methods deliver prediction sets with near perfect coverage.}
    \label{fig:denoising}
\end{figure}


\subsection{Image Deblurring}
We now consider a non-blind image deblurring experiment with colour images of size $256 \times 256$ pixels, derived from the DIV2K dataset \cite{Agustsson_2017_CVPR_Workshops} and artificially degraded with a diagonal Gaussian blur of major bandwidth $\varsigma_0 = 2$, $\varsigma_1 = 0.3$ along the minor axis, and an inclination of ${\pi}/{6}$ degrees, as well as additive white Gaussian noise  with a standard deviation \( \sigma = 0.01 \). As image restoration technique, we use the recently proposed model-based Polyblur technique \cite{delbracio2021polyblurremovingmildblur}, a highly efficient restoration method for removing mild blur from natural images based on a truncated polynomial approximation of the inverse of the blur kernel. See the bottom row of Fig. \ref{fig:reconstruction} for an example of a clean image, its noisy measurement, and the estimated reconstruction. 

We use $900$ blurred and noisy images to compute our proposed self-supervised conformal prediction sets, and assess their accuracy empirically by using $200$ measurement-truth pairs from the test dataset. The results are reported in Fig. \ref{fig:deblurring} below, together with the results obtained by using the equivalent supervised conformal prediction approach that relies on ground truth data for calibration. Again, we observe that our method delivers prediction sets that are accurate and remarkably close to the results obtained by using supervised conformal prediction, demonstrating that the bias stemming from using SURE instead of ground truth data is again negligible in this case. For completeness, Fig. \ref{fig:histogram} (right) below shows the empirical distribution of the non-similarity function $s(x,y)$ for the supervised conformal prediction based on the MSE, and the proposed self-supervised conformal prediction based on a SURE estimate of the MSE. Again, we observe close agreement between these distributions.
    

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.75\textwidth]{Graphs/coveragedeblurringwithoracle.png}
  \caption{\textbf{Image deblurring experiment}: desired confidence level vs empirical coverage. Both supervised and the proposed self-supervised conformal prediction methods deliver prediction sets with near perfect coverage.}
    \label{fig:deblurring}
\end{figure}

% \subsection{Comparison to equivariant bootstrapping}



% For each problem, we evaluate equivariant bootstrap using the self-supervised estimators provided by the respective restoration methods. We consider two types of group actions: rotations and two-dimensional shifts. Rotations are sampled from a Gaussian distribution with zero mean and a standard deviation of \( \sigma_{\theta} \) (denoising: \( \sigma_{\theta} = 125 \), deblurring: \( \sigma_{\theta} = 200 \)), while horizontal and vertical shifts are sampled from a uniform distribution on \( [-\Delta t, \Delta t] \) pixels (denoising: \( \Delta t = 250 \), deblurring: \( \Delta t = 200 \)). Equivariant bootstrap generates 1000 independent Monte Carlo samples, which are then used to compute confidence regions for various confidence levels.






% \textcolor{red}{Add some technical information about equivariant bootstrapping here, in particular what group actions were used for the experiment and how many samples of these group actions (or that we have taken sufficiently many to make the additional variance neg liable, like we do with assuming that $M$ is sufficiently large).}

%We have produced similar coverage plots to our approach in Fig. \ref{fig:denoising} and Fig.  \ref{fig:deblurring} \textit{green} line . Equivariant bootstrapping works great for some ill-posed problems \cite{tachella2023equivariant}, but for these image restoration problems, it is greatly outperformed by our SURE-based approach.
    
% \begin{figure}[h!]
%     \centering
%     \begin{subfigure}[h!]{0.49\textwidth}
%         \includegraphics[width=\textwidth]{Graphs/comparisonallcoveragesdenoising.png}
%         \caption{Equivariant bootstrapping for the image denoising}
%         \label{subfig:EQBdenoising}
%     \end{subfigure}
%     %\hfill % this command adds a little space between the images
%     \begin{subfigure}[h!]{0.49\textwidth}
%         \includegraphics[width=\textwidth]{Graphs/comparisonallcoveragesdeblurring.png}
%         \caption{Equivariant bootstrapping for image deblurring problem}
%         \label{subfig:EQBdeblurring}
%     \end{subfigure}
%     \caption{\textbf{Coverage Plots} for equivariant bootstrapping. A coverage closer to the orange  dashed line provide a more precise quantification of the uncertainty of the estimates.}
%         \label{fig:EQBOOTcove}
% \end{figure}






% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=1\linewidth]{Chapters//Ch4//Figures/result_tomo_sup.png}
%     \caption{Result of the Supervised Case}
%     \label{fig:Rtomosup}
% \end{figure}
    
%     \item  \textbf{Debluring of images from DIV2K dataset \cite{Agustsson_2017_CVPR_Workshops}} Corrupted by a Gaussian blur with specified with three parameters: $\sigma_0=2$, the standard deviation of the main axis, $\sigma_1 =0.3$, the orthogonal axis standard deviation, and $\theta = \frac{\pi}{6}$, the angle between the major axis and the horizontal added with a Gaussian noise with noise level $\sigma=0.01$.  As estimator, we implemented Polyblur \cite{delbracio2021polyblurremovingmildblur} a highly efficient blind restoration method that remove mild blur in natural images by polynomial reblurring using  the polynomial filter family of degree $d=3$  \eqref{polyblur}  with calibrated $\alpha=6$ and $\beta =1$ 
% \begin{equation}
%   p_{3, \alpha, b}(x)=(\alpha / 2-\beta+2) x^3 +(3 \beta-\alpha-6) x^2 
% +(5-3 \beta+\alpha / 2) x+\beta  \label{polyblur}.  
% \end{equation}

% % For each experiment, we use Algorithm \ref{alg:one} to compute our  proposed  conformal prediction sets , considering a fine grid of values
% of $\alpha \in (0,1) $   ranging from $0\%$ to $100\%$ to obtain regions with coverage $1-\alpha$. We evaluate
% the accuracy of these conformal prediction sets by calculating the empirical coverage probabilities on a test set, as measured by the proportion of test images that lie within the prediction sets for the 
% range of specified confidence levels . In all experiments, $M$ is large enough so that the variability of the sample quantiles is neglegible.

%Recall that the aim is to deliver conformal prediction regions that contain $\hat{x}(y)$ and are as compact as possible, for a given coverage level. The regions contain $\hat{x}(y)$ by construction. Therefore, 

% To assess the performance of the proposed methods we compare the size of the delivered regions against the size of a region that is not adaptive to the value of $y$. More precisely, we take advantage of the elliptical form of the regions and compute the radius $R(y)$ specifying the region $\hat{C}(y) = \{x\in\mathbb{R}^n\,|\,\|Ax-A\hat{x}(y)\|_2^2 \leq R(y)^2\}$. For the two SURE-normalised methods, the radii squared are given by $R^2_{mull} = S\times \hat{Q}_{mull,\alpha}$ and $R^2_{add} = S + \hat{Q}_{add,\alpha}$ respectively. For comparison, we compute the volume of an equivalent conformal prediction region without SURE-normalisation (we use the form \eqref{eq:score_multi_target} with $\Sigma(y) = A^\top A$ in the multiplicative-normalized setting). In that case, the radius squared, denoted simply by $R^2$, is constant, as there is no adaptivity w.r.t. $y$. 

% Figure \ref{fig:radii} below shows box-plots summarising the distribution of the radii $R(y)$ associated to the two proposed regions, alongside the constant radius $R$ associated with the region without adaptation. Each box in Figure \ref{fig:radii} spans the range from the 25\% to 75\% quantiles, the median is highlighted in colour orange, and the whiskers indicate the 10\% to 90\% quantiles; the value $R^2$ associated with the non-adaptive region is presented as a dashed black line. We observe in Figure \ref{fig:radii} that normalization using SURE can significantly reduce the prediction set when compared to non-normalised prediction sets (recall that all sets are conformalised to accumulate the same probability mass; the SURE-normalised sets leverage adaptivity to accumulate mass from regions of higher probability and are more compact as a result). Moreover, additive normalization performs at least as good as multiplicative normalization. Especially in the MNIST experiment, where the error is relatively small and SURE is difficult to compute accurately because MC-SURE has relatively high variance, we observe a big improvement when using additive normalization.

% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{radii_1.pdf}
%     \includegraphics[width=\textwidth]{radii_2.pdf}
%     \caption{Distribution of the radius squared $R^2$ of the prediction sets, i.e., $\hat{C}(y) = \{x\in\mathbb{R}^n\,|\,\|Ax-A\hat{x}(y)\|_2^2 \leq R^2\}$, for various precision levels $\alpha$. The dashed horizontal line corresponds to constant radius from not normalising.}
%     \label{fig:radii}
% \end{figure}





%To reduce the variability in the quantiles, we take a sufficiently large sample size $M$ such that the quantiles are practically constant. The resulting quantiles can be found in Table \ref{table:quantiles}.



% The most expensive part of Algorithm \ref{alg:one} is the divergence estimation using Equation \eqref{eq:MC-SURE}. Particularly for experiment on MNIST, which uses a relatively strong prior, the divergence is small or dominated by a small number of directions. To improve the computational cost, we can assume the divergence is zero, or at least very small, to circumvent Equation \eqref{eq:MC-SURE}. Quantiles corresponding to this zero divergence assumption are shown in Table \ref{table:quantiles}, and are generally not substantially larger than those with more accurate SURE estimation, especially for the additive score.

% Similarly for the MNIST experiment, due to the difficulty of estimating the SURE and the overall high accuracy, there are significant number negative SURE estimates. Specifically, $4.8\%$ with MC-SURE and $8.4\%$ with the zero divergence assumption, resulting in an equal number of uninformative prediction sets for the multiplicative score function. In MNIST experiment with additive scoring function and in the experiments with the other datasets, no uninformative prediction sets occurred.

% Note that in the Flower102 and DTD experiments in which the SURE can be estimated quite accurately, both proposed scoring functions perform approximately equal, whilst for the MNIST experiment, in which the SURE is more difficult to estimate, the additive scoring functions seems to perform better.

% Because the proposed SURE-normalised regions adapt to $y$ and are more compact, they are also more informative. To illustrate this point, we follow the uncertainty visualisation approach of \cite{liaudat2023scalable} which progressively removes detail from $\hat{x}(y)$ until we reach the boundary of $C(y)$. This allows decomposing $\hat{x}(y)$ into an the sum of two images: an image $T(\hat{x}(y))$ that has low uncertainty, and a detail term $\hat{x}(y)-T(\hat{x}(y))$ with high uncertainty and which may vary significantly as we move across $C(y)$. There are many ways of constructing the decomposition $\hat{x}(y) = T(\hat{x}(y)) + [\hat{x}(y)-T(\hat{x}(y))]$. Similarly to \cite{liaudat2023scalable}, we adopt a construction based on a Haar wavelet representation of $\hat{x}(y)$, where we progressively remove the smallest coefficients until we reach the boundary of $C(y)$. 

% Figure \ref{fig:UQ} below depicts the decompositions of $\hat{x}(y)$ obtained in this manner for four images from the MNIST deblurring experiment. For each case, we obtain three decompositions of $\hat{x}(y)$ by using our two SURE-normalised regions and the unnormalised region at level $99\%$. We observe that in all cases the uncertainty is mostly concentrated on contours, as expected for an image deblurring problem. Moreover, because the SURE-normalised regions are more informative, they lead to sparse and mild residuals $[\hat{x}(y)-T(\hat{x}(y))]$, as only mild details about $\hat{x}(y)$ have high uncertainty. Conversely, because the unnormalised regions are larger and less informative, they lead to residuals $[\hat{x}(y)-T(\hat{x}(y))]$ that are large, reflecting high uncertainty across $\hat{x}(y)$ (see bottom row of Figure 2).


% \begin{figure}
%     \centering
%     \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_1.pdf}%
%     \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_0.pdf}
%     \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_6.pdf}%
%     \includegraphics[width=0.5\linewidth]{uq/uq_MNIST_5.pdf}

% %    \includegraphics[width=\linewidth]{uq/uq_flower102_0.pdf}
%     \caption{Uncertainty visualisation obtained by decomposing $\hat{x}(y)$ as a low-uncertainty image $T(\hat{x}(y))$ and a high-uncertainty residual $\hat{x}(y)-T(\hat{x}(y))$. Compact and informative regions that adapt to $y$ lead to smaller and sparse residuals, whereas large regions reflect significant uncertainty in $\hat{x}(y)$.}
%     \label{fig:UQ}
% \end{figure}



\begin{figure}[h!]
    \centering
    \begin{subfigure}[h!]{0.49\textwidth}
        \includegraphics[width=\textwidth]{Graphs/histogramdenoising.png}
        \caption{Image denoising}
        \label{subfig:histogramdenoising}
    \end{subfigure}
    %\hfill % this command adds a little space between the images
    \begin{subfigure}[h!]{0.49\textwidth}
        \includegraphics[width=\textwidth]{Graphs/histogramdeblurring.png}
        \caption{Image deblurring}
        \label{subfig:histogramdeblurring}
    \end{subfigure}
    \caption{\textbf{Calibration histograms} (empirical distribution of the non-similarity function $s(x,y)$) for the supervised case (MSE) and the self-supervised case based on a SURE estimate of the MSE, for the denoising and deblurring experiments.}
        \label{fig:histogram}
\end{figure}

\section{Discussion and Conclusion}\label{sec:discussion}
This paper presented a self-supervised approach for constructing conformal prediction regions for linear imaging inverse problems that are ill-posed. Unlike previous conformal prediction methods, the proposed approach does not require any form of ground truth data. This is achieved by leveraging Stein's unbiased risk estimator and by pooling together a group of exchangeable imaging problems. This allows delivering conformal prediction sets in situations where there is no ground truth data available for calibration, and provides robustness to distribution shift. Additionally, the proposed framework is estimator-agnostic, as it uses a Monte Carlo implementation of SURE that does not require any explicit knowledge of the image restoration algorithm used. This flexibility allows the framework to be straightforwardly applied to model-driven as well as data-driven image restoration techniques, including self-supervised data-driven techniques that are also trained directly from the measurement data. Moreover, the method is computationally efficient as computations can be performed in parallel. We demonstrated the effectiveness of the proposed method through image denoising and deblurring experiments, where we observed that our method delivers extremely accurate prediction sets. 

Future work will explore the generalization of the proposed approach to other noise models, such as Poisson and Poisson-Gaussian, as well as to problems in which the parameters of the noise model are unknown \cite{tachella2024unsure}. Another important perspective for future work is to extend this approach to problems in which the forward $A$ is not full rank, for example by leveraging equivariance properties. In particular, it would be interesting to study the integration of our proposed method and the equivariant bootstrap \cite{tachella2023equivariant}.

\bibliographystyle{IEEEtranN}
\bibliography{references}


\end{document}
ov