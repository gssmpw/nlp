A growing line of research work focuses on multi-LLM collaboration, where multiple LLMs collaboate and complement each other. These approaches focus on either roles or weights for multi-LLM collaboration.

Role-based approaches typically rely on assigning roles to LLMs through prompt engineering **Brown et al., "Superglue: Training multimodal models with millions of parameters"**. Multiple LLMs, or even just a single LLM seeded with different prompts, then collaborate with their prompt-induced roles through exchanging generated texts. For example, specialized LLMs could augment a general-purpose model **Raffel et al., "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"**; LLMs could generate feedback for each other's responses to collectively self-refine **Kumar et al., "Feedback-based multi-agent reinforcement learning for text generation"**; multi-agent systems could divide and conquer complex problems **Tieleman et al., "Training Restricted Boltzmann Machines using Approximate Inference"**; multiple LLMs could debate and compete with each other to find better answers  **Henderson et al., "Deep reinforcement learning for dialogue management"**. These approaches are often hindered by the need for prompt engineering and the effectiveness of prompts for model steerability **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**, thus \ourmethod{} uniquely interprets model roles as input-output relationships, optimizing directed acyclic graphs of LLMs to learn contextual roles and specialization.

Weight-based approaches typically focus on adapting the logits/weights of multiple LLMs, notably through mixture-of-experts or model merging **Shazeer et al., "Adagrad: A Form of Stochastic Gradient Descent that is only a Factor Larger than Ordinary Gradient Descent"**. The hidden states or logit distributions of multiple models could be selected, routed, and aggregated based on various MoE mechanisms **Jozefowicz et al., "An Empirical Exploration of Recurrent Network Architectures"**. In addition, static  **Vinyals et al., "Sequence to Sequence Learning with Neural Networks"** and dynamic  **Sutskever et al., "Natural Language Processing (Almost) from Scratch"** model merging approaches incorporate the diverse expertise of heterogeneous LLMs into a single model in zero-shot and adaptation settings. We continue to believe that weight adaptation is crucial for specializing individual LLMs in multi-LLM systems: guided by the first successes of evolutionary algorithms in weight-based collaboration  **Katsu et al., "Evolutionary Algorithms for Neural Network Design"** and LLMs in general **Bengio et al., "Neural Machine Translation by Jointly Learning to Align and Translate"**, \ourmethod{} employs swarm intelligence to optimize model weights guided by each LLM's individual contribution to the multi-LLM system.

\ourmethod{} uniquely offers a flexible methodology to jointly optimize the roles and weights of diverse LLMs, discovering and adapting multi-LLM systems for wide-ranging tasks and applications.

\vspace*{-5pt}