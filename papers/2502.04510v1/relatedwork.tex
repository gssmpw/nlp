\section{Related Work}
A growing line of research work focuses on \emph{multi-LLM collaboration}, where multiple LLMs collaboate and complement each other. These approaches focus on either roles or weights for multi-LLM collaboration.

Role-based approaches typically rely on assigning roles to LLMs through prompt engineering \citep{duimproving, feng-etal-2024-dont}. Multiple LLMs, or even just a single LLM seeded with different prompts, then collaborate with their prompt-induced roles through exchanging generated texts. For example, specialized LLMs could augment a general-purpose model \citep{fengknowledge, shen-etal-2024-learning}; LLMs could generate feedback for each other's responses to collectively self-refine \citep{feng-etal-2024-dont, burnsweak}; multi-agent systems could divide and conquer complex problems \citep{wu2024autogen, guo2024large}; multiple LLMs could debate and compete with each other to find better answers  \citep{liang2023encouraging, duimproving}. These approaches are often hindered by the need for prompt engineering and the effectiveness of prompts for model steerability \citep{sprague2024cot, sclarquantifying}, thus \ourmethod{} uniquely interprets model roles as input-output relationships, optimizing directed acyclic graphs of LLMs to learn contextual roles and specialization.

Weight-based approaches typically focus on adapting the logits/weights of multiple LLMs, notably through mixture-of-experts or model merging \citep{yadav2024survey}. The hidden states or logit distributions of multiple models could be selected, routed, and aggregated based on various MoE mechanisms \citep{li2022branch, gritsch2024nexus}. In addition, static \citep{yu2024languagedare, yadav2024ties, jang2024model} and dynamic \citep{mavromatis2024pack, akiba2024evolutionary, huang2023lorahub} model merging approaches incorporate the diverse expertise of heterogeneous LLMs into a single model in zero-shot and adaptation settings. We continue to believe that weight adaptation is crucial for specializing individual LLMs in multi-LLM systems: guided by the first successes of evolutionary algorithms in weight-based collaboration \citep{feng2024model} and LLMs in general \citep{akiba2024evolutionary, fernandopromptbreeder, guoconnecting}, \ourmethod{} employs swarm intelligence to optimize model weights guided by each LLM's individual contribution to the multi-LLM system.

\ourmethod{} uniquely offers a flexible methodology to jointly optimize the roles and weights of diverse LLMs, discovering and adapting multi-LLM systems for wide-ranging tasks and applications.

\vspace*{-5pt}