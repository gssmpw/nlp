\section{Related Works}
\label{related}
% \subsection{Diffusion Model and Fast Sampling Technique}
% Diffusion models ____ have recently been raised as the most powerful generative model and outperform GAN ____ in many applications. Diffusion models can generate high-fidelity images and possess good mode coverage, allowing diverse samples compared to GAN. However, diffusion models require many function evaluations (NFEs) during inference time. This drawback hinders its application in the real world. Many works are trying to tackle this drawback and achieve promising results. They can be divided into two main research categories: training from scratch and building upon pretrained diffusion models. Following the first category, there are several works, such as DDGAN ____, LDM ____, and VQDiff ____. DDGAN ____ proposes to use a larger step size in the forward process to reduce the NFEs; they use GAN models to implicitly learn the backward transition. Even though DDGAN ____ requires only a few sampling timesteps, it still suffers from low recall due to mode collapse from GAN. LDM ____ does not directly reduce the number of sampling time steps; instead, it compresses the image to latent with a much smaller resolution. By training on latent space, LDM ____ can significantly reduce both time and memory budget, and the inference is much faster than other pixel diffusion models. LDM ____ has become the core technique in many large-scale diffusion models. Most real-world applications rely on LDM since it allows to scale diffusion models up on enormous high-resolution training datasets, which is impractical if training pixel diffusion models. In the second category, several works such as ____ propose the high-order solver during inference. These works could successfully reduce sample NFEs to 10 without any training. However, they cannot sample with little NFEs such as 1 or 2. The other line of work is a distillation-based method. Progressive distillation ____ proposes to progressively distill diffusion model; each stage distills to reduce the sampling NFEs by half. This technique is costly since it requires to train many stages. Later works such as Guided-Distill ____, Swiftbrush ____, DMD ____, and UFOGEN ____ manage to distill diffusion into few-step generation without compromising generative quality. The major drawback of these techniques is that additional training is required.
% Furthermore, some techniques, such as Swiftbrush ____ and DMD ____, do not have few-step sampling. Other methods, such as UFOGEN ____ and ADD ____, require training GAN, which could lead to training instability and low mode coverage. A standout among these techniques is the consistency model. The consistency model ____ is defined based on probability flow ODE (PF-ODE), allowing single- and multi-step sampling. The consistency model could be achieved via training from scratch and distillation from the diffusion model.

% \subsection{Consistency Model}

Consistency model ____ proposes a new type of generative model based on PF-ODE, which allows 1, 2 or multi-step sampling. The consistency model could be obtained by either training from scratch using an unbiased score estimator or distilling from a pretrained diffusion model. Several works improve the training of the consistency model. ACT ____, CTM ____ propose to use additional GAN along with consistency objective. While these methods could improve the performance of consistency training, they require an additional discriminator, which could need to tune the hyperparameters carefully. MCM ____ introduces multistep consistency training, which is a combination of TRACT ____ and CM ____. MCM increases the sampling budget to 2-8 steps to tradeoff with efficient training and high-quality image generation. ECM ____ initializes the consistency model by pretrained diffusion model and fine-tuning it using the consistency training objective. ECM vastly achieves improved training times while maintaining good generation performance. However, ECM requires pretrained diffusion model, which must use the same architecture as the pretrained diffusion architecture. Although these works successfully improve the performance and efficiency of consistency training, they only investigate consistency training on pixel space. As in the diffusion model, where most applications are now based on latent space, scaling the consistency training ____ to text-to-image or higher resolution generation requires latent space training. Otherwise, with pretrained diffusion model, we could either finetune consistency training ____ or distill from diffusion model ____. CM ____ is the first work proposing consistency distillation (CD) on pixel space. LCM ____ later applies consistency technique on latent space and can generate high-quality images within a few steps. However, LCM's generated images using 1-2 steps are still blurry ____. Recent works, such as Hyper-SD ____ and TCD ____, have introduced notable improvements to latent consistency distillation. TCD ____ employed CTM ____ instead of CD ____, significantly enhancing the performance of the distilled student model. Building on this, Hyper-SD ____ divided the Probability Flow ODE (PF-ODE) into multiple components inspired by Multistep Consistency Models (MCM) ____, and applied TCD ____ to each segment. Subsequently, Hyper-SD ____ merged these segments progressively into a final model, integrating human feedback learning and score distillation ____ to optimize one-step generation performance.