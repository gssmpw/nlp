% \PassOptionsToPackage{prologue,dvipsnames}{xcolor}
\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{cuted}
\usepackage{capt-of}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{bbm}
\usepackage{mathtools}
\usepackage{booktabs} % For formal tables
\usepackage{lipsum}
\usepackage{xcolor}
\usepackage{bbding}
\usepackage{colortbl}
% \usepackage[svgnames]{xcolor}
% \usepackage[dvipsnames]{xcolor}
\usepackage{enumitem}
\setenumerate[1]{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}
\setitemize[1]{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}
\setdescription{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}
\DeclareMathOperator*{\argmax}{\arg\!\max}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclarePairedDelimiterX{\js}[2]{}{}{%
  #1\;\delimsize\|\;#2%
}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{****} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Mojito: LLM-Aided Motion Instructor with Jitter-Reduced Inertial Tokens}

\author{
    Ziwei Shan\textsuperscript{1,*}\qquad
    Yaoyu He\textsuperscript{1,*}\qquad
    Chengfeng Zhao\textsuperscript{1,*,\textdagger}\qquad
    Jiashen Du\textsuperscript{1}\qquad
    Jingyan Zhang\textsuperscript{1}\\
    Qixuan Zhang\textsuperscript{1,2}\qquad
    Jingyi Yu\textsuperscript{1,\textdaggerdbl}\qquad
    Lan Xu\textsuperscript{1,\textdaggerdbl}\\
    \textsuperscript{1}ShanghaiTech University\qquad
    \textsuperscript{2}Deemos Technology\\
    {\tt\footnotesize \{shanzw2022,heyy2022,zhaochf2022,dujsh2022,zhangjy7,zhangqx1,yujingyi,xulan1\}@shanghaitech.edu.cn}
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi

%%%%%%%%% ABSTRACT
\begin{strip}\centering
    \vspace{-45px}
    \captionsetup{type=figure}
    \includegraphics[width=\textwidth]{figures/teaser.png}
    \vspace{-15px}
    \caption{Our \textit{Mojito} produces real-time human motion capture and online motion analysis, from six inertial measurement units (IMUs). (a) Human who performs exercise wearing IMU sensors in reality. (b) Digitalized human motion from six IMU sensor signals. (c) Motion recognition, analysis and instruction feedback.}
\label{fig:teaser}
\vspace{-10px}
\end{strip}

\blfootnote{\textsuperscript{*}Equal contributions}
\blfootnote{\textsuperscript{\textdagger}Project lead}
\blfootnote{\textsuperscript{\textdaggerdbl}Corresponding author}

\begin{abstract}
Human bodily movements convey critical insights into action intentions and cognitive processes, yet existing multimodal systems primarily focused on understanding human motion via language, vision, and audio, which struggle to capture the dynamic forces and torques inherent in 3D motion. Inertial measurement units (IMUs) present a promising alternative, offering lightweight, wearable, and privacy-conscious motion sensing. However, processing of streaming IMU data faces challenges such as instable wireless transmission, sensor noise, and drift, limiting their utility for long-term real-time motion capture (MoCap), and more importantly, online motion analysis. 
%
To address these challenges, we introduce Mojito, an intelligent motion agent that integrates inertial sensing with large language models (LLMs) for interactive motion capture and behavioral analysis. The core innovation of Mojito lies in a jitter-reduced inertial token representation with a novel IMU signal encoding framework, and an extended language model involving inertial tokens. By employing VQVAE, Mojito learns a discrete latent space of continuous IMU signals, mitigating sensor noise and drift through quantization. The inertial tokens are then aligned with inductive bias of natural language and mapped to textual semantics to enhance compatibility with LLMs, enabling efficient sequence modeling. 
%
To support domain-specific applications, Mojito further incorporates tunable LoRA adapters, facilitating personalized feedback tailored to roles such as fitness trainers or rehabilitation therapists. 
%
Extensive experiments demonstrate that Mojito outperforms existing IMU-based methods in motion capture under noisy conditions, and achieves comparable behavior analysis capability compared to large vision-language models. The user study further highlights its practical effectiveness in various scenarios as a versatile tool for intelligent human-agent interaction. Our code and data will be released at \href{https://koyui.github.io/mojito/}{our project page}.
\end{abstract}

%%%%%%%%% BODY TEXT
\input{sections/1-intro}
\input{sections/2-related_work}
\input{sections/3-method_part1}
\input{sections/4-method_part2}
\input{sections/5-experiment}
\input{sections/6-conclusion}

{\small
\bibliographystyle{ieee_fullname}
\bibliography{main}
}

\end{document}
