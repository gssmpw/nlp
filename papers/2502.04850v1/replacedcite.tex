\section{Related Work}
\label{section: related-work}

\textbf{Fairness in FL.} Fairness in federated learning has been extensively studied through two primary lenses: performance fairness ____, which emphasizes uniform model performance across all participants, and collaborative fairness ____, which advocates proportionality between client contributions and rewards. Our work focuses on collaborative fairness, where clients receive model rewards commensurate with their contributions. The foundational work of ____ operationalizes collaborative fairness by assigning only the allocated aggregated updates based on their reputations. 
Other studies consider fairness by quantifying the impact of clients on the global model -- the naive choice being the self-reported dataset sizes (self-reported information) ____, and similarly, ____ employ such self-reported information to build a fair scheme based on contract theory. Various approaches also assess client importance through Shapley values ____, utility games ____ and empirical methods ____. For a complete taxonomy of fairness in FL, we refer the reader to check ____. 

\textbf{Contribution assessment.} A substantial body of work has addressed the problem of evaluating individual client contributions in federated learning. As mentioned earlier, an initial approach to collaborative fairness ____ employed a global validation set, applying a function $\sinh$ to the validation accuracy of each client as a penalty mechanism to approximate their contribution or reputation. Subsequently, ____ removed the need for a global validation set by approximating game-theoretic Shapley values with the cosine similarity of shared parameter updates -- thereby capturing each client's marginal contribution. A range of follow-up studies ____ further expanded and refined these strategies for contribution assessment. 

\textbf{Reward mechanisms.} Broadly, existing incentive mechanisms in FL fall into two categories: post-training monetary rewards and training time model rewards. The former employs frameworks such as Stackelberg games ____, auctions ____, and contract theory ____ to distribute monetary compensation post hoc based on client contributions. The latter focuses on model-based rewards during training, incentivizing participation by dynamically adjusting access to the modelâ€™s capabilities. For example, CGSV ____ allocates sparsified model outputs to clients proportionate to their contributions, while achieving fairness. Similarly, IAFL ____ shares aggregated gradients based on each client's contribution through probabilistic sampling, thus restricting highly performing models from under-contributing clients. However, while CGSV relies on a heuristic approach and lacks a formal convergence analysis, IAFL includes a convergence proof but exhibits its own limitations. Specifically, its stochastic recovery mechanism shares the full model updates with all participants based on a certain probability: setting this probability to zero yields higher fairness at the expense of performance, and increasing it boosts performance at the cost of fairness -- yet still falls short of the performance achieved by FedAvg ____. 

\textbf{Slimmable networks.} The seminal work by ____ introduced the idea of training a single neural network that can operate at multiple widths, enabling dynamic trade-offs between model size and performance. This innovation led to numerous follow-up studies and applications in federated learning, predominantly focused on resource efficiency ____, communication and computational efficiency ____, and neural architecture search ____. To the best of our knowledge, we are the first to leverage slimmable networks in the context of fair federated learning.