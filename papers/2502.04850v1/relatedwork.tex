\section{Related Work}
\label{section: related-work}

\textbf{Fairness in FL.} Fairness in federated learning has been extensively studied through two primary lenses: performance fairness \cite{jiang2023fair}, which emphasizes uniform model performance across all participants, and collaborative fairness \cite{lyu2020collaborative}, which advocates proportionality between client contributions and rewards. Our work focuses on collaborative fairness, where clients receive model rewards commensurate with their contributions. The foundational work of \citet{lyu2020collaborative} operationalizes collaborative fairness by assigning only the allocated aggregated updates based on their reputations. 
Other studies consider fairness by quantifying the impact of clients on the global model -- the naive choice being the self-reported dataset sizes (self-reported information) \cite{donahue2021optimality, zhang2020hierarchicallyfairfederatedlearning}, and similarly, \citet{kang2019incentivedesignforefl} employ such self-reported information to build a fair scheme based on contract theory. Various approaches also assess client importance through Shapley values \cite{shapley_book1952, ghorbani2019datashapley}, utility games \cite{gollapudi2017profitsharing, nishio2009estimationIFL} and empirical methods \cite{kuk2021fedccea}. For a complete taxonomy of fairness in FL, we refer the reader to check \cite{Shi_2024FairnessAwareFL}. 

\textbf{Contribution assessment.} A substantial body of work has addressed the problem of evaluating individual client contributions in federated learning. As mentioned earlier, an initial approach to collaborative fairness \cite{lyu2020collaborative} employed a global validation set, applying a function $\sinh$ to the validation accuracy of each client as a penalty mechanism to approximate their contribution or reputation. Subsequently, \citet{xu2021gradient} removed the need for a global validation set by approximating game-theoretic Shapley values with the cosine similarity of shared parameter updates -- thereby capturing each client's marginal contribution. A range of follow-up studies \cite{shi2022fedfaim, jiang2023fair, Lin2023fairyetasymp, tastan2024redefining} further expanded and refined these strategies for contribution assessment. 

\textbf{Reward mechanisms.} Broadly, existing incentive mechanisms in FL fall into two categories: post-training monetary rewards and training time model rewards. The former employs frameworks such as Stackelberg games \cite{zhan2020learning}, auctions \cite{zhang2021incentive, cong2020game}, and contract theory \cite{liu2022contract, yang2024asynchronous} to distribute monetary compensation post hoc based on client contributions. The latter focuses on model-based rewards during training, incentivizing participation by dynamically adjusting access to the modelâ€™s capabilities. For example, CGSV \cite{xu2021gradient} allocates sparsified model outputs to clients proportionate to their contributions, while achieving fairness. Similarly, IAFL \cite{wu2024incentive} shares aggregated gradients based on each client's contribution through probabilistic sampling, thus restricting highly performing models from under-contributing clients. However, while CGSV relies on a heuristic approach and lacks a formal convergence analysis, IAFL includes a convergence proof but exhibits its own limitations. Specifically, its stochastic recovery mechanism shares the full model updates with all participants based on a certain probability: setting this probability to zero yields higher fairness at the expense of performance, and increasing it boosts performance at the cost of fairness -- yet still falls short of the performance achieved by FedAvg \cite{mcmahan2017communication}. 

\textbf{Slimmable networks.} The seminal work by \cite{yu2019slimmable} introduced the idea of training a single neural network that can operate at multiple widths, enabling dynamic trade-offs between model size and performance. This innovation led to numerous follow-up studies and applications in federated learning, predominantly focused on resource efficiency \cite{mei2022resource, horvath2021fjord}, communication and computational efficiency \cite{wang2022progfed}, and neural architecture search \cite{yu2019autoslim}. To the best of our knowledge, we are the first to leverage slimmable networks in the context of fair federated learning.