\section{Related work}
\label{sec:related_work}
\noindent \textbf{Automatic Wikipedia article enhancement}: Automatic Wikipedia enhancement has been studied for more than a decade~\cite{10.1145/2682571.2797073,j.2018generating, fan2022generating, banerjee2016wikiwrite, zhang2024retrievalbasedfulllengthwikipediageneration}. In recent times, \citet{zhang2024retrievalbasedfulllengthwikipediageneration} leveraged RAG to create full length Wikipedia articles.\\ %Works such as  focuses on extending Wikipedia section from the available contents from the web, while other line of works \cite{} concentrate on creating full length Wikipedia page. Many of the works rely on Information Extraction to enhance Wikipedia content. \citet{sauper2009automatically} propose a structure aware method to produce Wikipedia documents given relevant articles. They first cluster all headings in the document to construct the templates then retrieve result pages from the internet. This approach requires a set of in-domain documents as prerequisites to constitute the template, thereby rendering it unsuitable for addressing emerging topics. 
\noindent\textbf{Grounded content generation using RAG}: Augmenting language models (LMs) with retrieval at inference time is a typical way to leverage external knowledge stores~\citep{ram2023ralm,JMLR:v24:23-0037}. While some works use retrieval to construct demonstrations for in-context learning~\citep{poesia2022synchromesh,khattab2022demonstrate}, others~\cite{lewis2020retrieval,menick2022teaching,gao-etal-2023-enabling,bohnet2023attributed,qian2023webbrainlearninggeneratefactually} use retrieval to provide additional information for LMs to ground on.
While RAG is widely studied in question answering, how to use it for expanding a Wikipedia section is less investigated.\\
\noindent \textbf{Present work}: Although, there are several lines of work which are related to ours, none of them leverage personal narratives to improve Wikipedia articles. We carefully curate a set of autobiographies/biographies and develop algorithms so that the generated content is grounded on these narratives. In specific, we use a two-stage RAG pipeline for enhancing Wikipedia tail articles and outperform the most competing baseline.
% As a general framework, RAG is flexible in both the retrieval source and time. The retrieval sources can vary from domain databases~\citep{zakka2023almanac}, code documentation~\citep{zhou2023docprompting}, to the whole Internet~\citep{nakano2022webgpt,komeili-etal-2022-internet}. Regarding the time, %
% besides a one-time retrieval before generation, the system can be designed to self-decide when %
% to retrieve across the course of the generation~\citep{jiang-etal-2023-active, parisi2022talm,shuster-etal-2022-language,yao2023react}.

% \noindent
% \textbf{Question Asking in NLP}\quad
% Question asking capabilities in NLP systems have expanded across several fronts, including generating clarification questions to understand user intents~\citep{aliannejadi2019asking, rahmani-etal-2023-survey}, and breaking large questions into smaller ones to improve compositional reasoning~\citep{press-etal-2023-measuring}. While humans usually ask questions to learn new knowledge~\citep{tawfik2020role,booth2003craft}, how to optimize question informativeness and specificity in information-seeking conversations remains less explored. The closest work is~\citet{qi-etal-2020-stay} which defines the question informativeness using the unigram precision function and uses reinforcement learning to increase the question informativeness.

% \noindent \textbf{Grounded content generation}
% WebBrain \cite{qian2023webbrainlearninggeneratefactually} leverages a more complex system to ground on web corpus and produce short factual articles to answer queries.