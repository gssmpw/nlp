% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@inproceedings{es-etal-2024-ragas,
    title = "{RAGA}s: Automated Evaluation of Retrieval Augmented Generation",
    author = "Es, Shahul  and
      James, Jithin  and
      Espinosa Anke, Luis  and
      Schockaert, Steven",
    editor = "Aletras, Nikolaos  and
      De Clercq, Orphee",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations",
    month = mar,
    year = "2024",
    address = "St. Julians, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.eacl-demo.16",
    pages = "150--158",
    abstract = "We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAGAs is available at [https://github.com/explodinggradients/ragas]. RAG systems are composed of a retrieval and an LLM based generation module. They provide LLMs with knowledge from a reference textual database, enabling them to act as a natural language layer between a user and textual databases, thus reducing the risk of hallucinations. Evaluating RAG architectures is challenging due to several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages faithfully, and the quality of the generation itself. With RAGAs, we introduce a suite of metrics that can evaluate these different dimensions without relying on ground truth human annotations. We posit that such a framework can contribute crucially to faster evaluation cycles of RAG architectures, which is especially important given the fast adoption of LLMs.",
}

@inproceedings{jwalapuram-etal-2022-rethinking,
    title = "Rethinking Self-Supervision Objectives for Generalizable Coherence Modeling",
    author = "Jwalapuram, Prathyusha  and
      Joty, Shafiq  and
      Lin, Xiang",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.418",
    doi = "10.18653/v1/2022.acl-long.418",
    pages = "6044--6059",
    abstract = "Given the claims of improved text generation quality across various pre-trained neural models, we consider the coherence evaluation of machine generated text to be one of the principal applications of coherence models that needs to be investigated. Prior work in neural coherence modeling has primarily focused on devising new architectures for solving the permuted document task. We instead use a basic model architecture and show significant improvements over state of the art within the same training regime. We then design a harder self-supervision objective by increasing the ratio of negative samples within a contrastive learning setup, and enhance the model further through automatic hard negative mining coupled with a large global negative queue encoded by a momentum encoder. We show empirically that increasing the density of negative samples improves the basic model, and using a global negative queue further improves and stabilizes the model while training with hard negative samples. We evaluate the coherence model on task-independent test sets that resemble real-world applications and show significant improvements in coherence evaluations of downstream tasks.",
}
@inproceedings{shao2024assisting,
  title={Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models},
  author={Shao, Yijia and Jiang, Yucheng and Kanell, Theodore and Xu, Peter and Khattab, Omar and Lam, Monica},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={6252--6278},
  year={2024}
}

@misc{zhang2024retrievalbasedfulllengthwikipediageneration,
      title={Retrieval-based Full-length Wikipedia Generation for Emergent Events}, 
      author={Jiebin Zhang and Eugene J. Yu and Qinyu Chen and Chenhao Xiong and Dawei Zhu and Han Qian and Mingbo Song and Xiaoguang Li and Qun Liu and Sujian Li},
      year={2024},
      eprint={2402.18264},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.18264}, 
}

@inproceedings{10.1145/2682571.2797073,
author = {Banerjee, Siddhartha and Mitra, Prasenjit},
title = {Filling the Gaps: Improving Wikipedia Stubs},
year = {2015},
isbn = {9781450333078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2682571.2797073},
doi = {10.1145/2682571.2797073},
abstract = {The availability of only a limited number of contributors on Wikipedia cannot ensure consistent growth and improvement of the online encyclopedia. With information being scattered on the web, our goal is to automate the process of generation of content for Wikipedia. In this work, we propose a technique of improving stubs on Wikipedia that do not contain comprehensive information. A classifier learns features from the existing comprehensive articles on Wikipedia and recommends content that can be added to the stubs to improve the completeness of such stubs. We conduct experiments using several classifiers - Latent Dirichlet Allocation (LDA) based model, a deep learning based architecture (Deep belief network) and TFIDF based classifier. Our experiments reveal that the LDA based model outperforms the other models (~6\% F-score). Our generation approach shows that this technique is capable of generating comprehensive articles. ROUGE-2 scores of the articles generated by our system outperform the articles generated using the baseline. Content generated by our system has been appended to several stubs and successfully retained in Wikipedia.},
booktitle = {Proceedings of the 2015 ACM Symposium on Document Engineering},
pages = {117–120},
numpages = {4},
keywords = {wikipedia generation, topic modeling, text summarization},
location = {Lausanne, Switzerland},
series = {DocEng '15}
}

@inproceedings{iv-etal-2022-fruit,
    title = "{FRUIT}: Faithfully Reflecting Updated Information in Text",
    author = "Iv, Robert  and
      Passos, Alexandre  and
      Singh, Sameer  and
      Chang, Ming-Wei",
    editor = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.269",
    doi = "10.18653/v1/2022.naacl-main.269",
    pages = "3670--3686",
    abstract = "Textual knowledge bases such as Wikipedia require considerable effort to keep up to date and consistent. While automated writing assistants could potentially ease this burden, the problem of suggesting edits grounded in external knowledge has been under-explored. In this paper, we introduce the novel generation task of *faithfully reflecting updated information in text* (FRUIT) where the goal is to update an existing article given new evidence. We release the FRUIT-WIKI dataset, a collection of over 170K distantly supervised data produced from pairs of Wikipedia snapshots, along with our data generation pipeline and a gold evaluation set of 914 instances whose edits are guaranteed to be supported by the evidence. We provide benchmark results for popular generation systems as well as EDIT5 {--} a T5-based approach tailored to editing we introduce that establishes the state of the art. Our analysis shows that developing models that can update articles faithfully requires new capabilities for neural generation models, and opens doors to many new applications.",
}

@inproceedings{vskrlj2022retrieval,
  title={Retrieval-efficiency trade-off of unsupervised keyword extraction},
  author={{\v{S}}krlj, Bla{\v{z}} and Koloski, Boshko and Pollak, Senja},
  booktitle={International Conference on Discovery Science},
  pages={379--393},
  year={2022},
  organization={Springer}
}

@article{campos2020yake,
  title={YAKE! Keyword extraction from single documents using multiple local features},
  author={Campos, Ricardo and Mangaravite, V{\'\i}tor and Pasquali, Arian and Jorge, Al{\'\i}pio and Nunes, C{\'e}lia and Jatowt, Adam},
  journal={Information Sciences},
  volume={509},
  pages={257--289},
  year={2020},
  publisher={Elsevier}
}

@misc{grootendorst2020keybert,
  author       = {Maarten Grootendorst},
  title        = {KeyBERT: Minimal keyword extraction with BERT.},
  year         = 2020,
  publisher    = {Zenodo},
  version      = {v0.3.0},
  doi          = {10.5281/zenodo.4461265},
  url          = {https://doi.org/10.5281/zenodo.4461265}
}

@misc{touvron2023llamaopenefficientfoundation,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.13971}, 
}

@article{kirchenbauer2024hallucination,
  title={Hallucination reduction in large language models with retrieval-augmented generation using wikipedia knowledge},
  author={Kirchenbauer, Jason and Barns, Caleb}
}

@inproceedings{chen-etal-2017-reading,
    title = "Reading {W}ikipedia to Answer Open-Domain Questions",
    author = "Chen, Danqi  and
      Fisch, Adam  and
      Weston, Jason  and
      Bordes, Antoine",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1171",
    doi = "10.18653/v1/P17-1171",
    pages = "1870--1879",
    abstract = "This paper proposes to tackle open-domain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval (finding the relevant articles) with that of machine comprehension of text (identifying the answer spans from those articles). Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.",
}

@article{reid2022can,
  title={Can wikipedia help offline reinforcement learning?},
  author={Reid, Machel and Yamada, Yutaro and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2201.12122},
  year={2022}
}

@inproceedings{vrandecic2011language,
  title={Language resources extracted from Wikipedia},
  author={Vrandeci{\'c}, Denny and Sorg, Philipp and Studer, Rudi},
  booktitle={Proceedings of the sixth international conference on Knowledge capture},
  pages={153--160},
  year={2011}
}
@article{thoppilan2022lamda,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{yano2016taking,
  title={Taking advantage of wikipedia in natural language processing},
  author={Yano, Tae and Kang, Moonyoung},
  year={2016},
  publisher={Technical Report. Technical report, Carnegie Mellon University Language~…}
}

@inproceedings{fan2022generating,
  title={Generating Biographies on Wikipedia: The Impact of Gender Bias on the Retrieval-Based Generation of Women Biographies},
  author={Fan, Angela and Gardent, Claire},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={8561--8576},
  year={2022}
}

@inproceedings{yang-etal-2023-doc,
    title = "{DOC}: Improving Long Story Coherence With Detailed Outline Control",
    author = "Yang, Kevin  and
      Klein, Dan  and
      Peng, Nanyun  and
      Tian, Yuandong",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.190",
    doi = "10.18653/v1/2023.acl-long.190",
    pages = "3378--3465",
    abstract = "We propose the Detailed Outline Control (DOC) framework for improving long-range plot coherence when automatically generating several-thousand-word-long stories. DOC consists of two complementary components: a detailed outliner and a detailed controller. The detailed outliner creates a more detailed, hierarchically structured outline, shifting creative burden from the main drafting procedure to the planning stage. The detailed controller ensures the more detailed outline is still respected during generation by controlling story passages to align with outline details. In human evaluations of automatically generated stories, DOC substantially outperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22.5{\%} absolute gain), outline relevance (28.2{\%}), and interestingness (20.7{\%}). Humans also judged DOC to be much more controllable in an interactive generation setting.",
}

@inproceedings{banerjee2015wikikreator,
  title={Wikikreator: Improving wikipedia stubs automatically},
  author={Banerjee, Siddhartha and Mitra, Prasenjit},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={867--877},
  year={2015}
}

@inproceedings{nogueira-etal-2020-document,
    title = "Document Ranking with a Pretrained Sequence-to-Sequence Model",
    author = "Nogueira, Rodrigo  and
      Jiang, Zhiying  and
      Pradeep, Ronak  and
      Lin, Jimmy",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.63",
    doi = "10.18653/v1/2020.findings-emnlp.63",
    pages = "708--718",
}

@inproceedings{sauper2009automatically,
  title={Automatically generating wikipedia articles: A structure-aware approach},
  author={Sauper, Christina and Barzilay, Regina},
  booktitle={Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP},
  pages={208--216},
  year={2009}
}
@misc{qian2023webbrainlearninggeneratefactually,
      title={WebBrain: Learning to Generate Factually Correct Articles for Queries by Grounding on Large Web Corpus}, 
      author={Hongjing Qian and Yutao Zhu and Zhicheng Dou and Haoqi Gu and Xinyu Zhang and Zheng Liu and Ruofei Lai and Zhao Cao and Jian-Yun Nie and Ji-Rong Wen},
      year={2023},
      eprint={2304.04358},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.04358}, 
}

@article{kuhlthau1991inside,
  title={Inside the search process: Information seeking from the user's perspective},
  author={Kuhlthau, Carol C},
  journal={Journal of the American society for information science},
  volume={42},
  number={5},
  pages={361--371},
  year={1991},
  publisher={Wiley Online Library}
}
@article{belkin1982ask,
  title={ASK for information retrieval: Part I. Background and theory},
  author={Belkin, Nicholas J and Oddy, Robert N and Brooks, Helen M},
  journal={Journal of documentation},
  volume={38},
  number={2},
  pages={61--71},
  year={1982},
  publisher={MCB UP Ltd}
}
@article{groza2013state,
  title={State of the art and open challenges in community-driven knowledge curation},
  author={Groza, Tudor and Tudorache, Tania and Dumontier, Michel},
  journal={Journal of Biomedical Informatics},
  volume={46},
  number={1},
  pages={1--4},
  year={2013},
  publisher={Elsevier}
}
@article{hinnosaar2019gender,
  title={Gender inequality in new media: Evidence from Wikipedia},
  author={Hinnosaar, Marit},
  journal={Journal of economic behavior \& organization},
  volume={163},
  pages={262--276},
  year={2019},
  publisher={Elsevier}
}
@inproceedings{NEURIPS2020_6b493230,
 author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K\"{u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt\"{a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {9459--9474},
 publisher = {Curran Associates, Inc.},
 title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf},
 volume = {33},
 year = {2020}
}
@inproceedings{10.1145/3366424.3383569,
author = {Beyt\'{\i}a, Pablo},
title = {The Positioning Matters: Estimating Geographical Bias in the Multilingual Record of Biographies on Wikipedia},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366424.3383569},
doi = {10.1145/3366424.3383569},
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {806–810},
numpages = {5},
keywords = {geo-tagged information, geographical bias, information inequality, Wikipedia},
location = {Taipei, Taiwan},
series = {WWW '20}
}
@article{kaffee2022using,
  title={Using natural language generation to bootstrap missing Wikipedia articles: A human-centric perspective},
  author={Kaffee, Lucie-Aim{\'e}e and Vougiouklis, Pavlos and Simperl, Elena},
  journal={Semantic Web},
  volume={13},
  number={2},
  pages={163--194},
  year={2022},
  publisher={IOS Press}
}
@inproceedings{
j.2018generating,
title={Generating Wikipedia by Summarizing Long Sequences},
author={Peter J. Liu and Mohammad Saleh and Etienne Pot and Ben Goodrich and Ryan Sepassi and Lukasz Kaiser and Noam Shazeer},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=Hyg0vbWC-},
}
@article{minguillon2017semi,
  title={Semi-automatic generation of a corpus of Wikipedia articles on science and technology},
  author={Minguill{\'o}n, Juli{\`a} and Lerga, Maura and Aibar, Eduard and Llad{\'o}s-Masllorens, Josep and Meseguer-Artola, Antoni},
  journal={Profesional de la Informaci{\'o}n},
  volume={26},
  number={5},
  pages={995--1005},
  year={2017}
}
@article{bates1989design,
  title={The design of browsing and berrypicking techniques for the online search interface},
  author={Bates, Marcia J},
  journal={Online review},
  volume={13},
  number={5},
  pages={407--424},
  year={1989},
  publisher={MCB UP Ltd}
}
@inproceedings{banerjee2016wikiwrite,
  title={WikiWrite: Generating Wikipedia Articles Automatically.},
  author={Banerjee, Siddhartha and Mitra, Prasenjit},
  booktitle={IJCAI},
  pages={2740--2746},
  year={2016}
}
@inproceedings{kaffee2018mind,
  title={Mind the (language) gap: Generation of multilingual wikipedia summaries from wikidata for articleplaceholders},
  author={Kaffee, Lucie-Aim{\'e}e and ElSahar, Hady and Vougiouklis, Pavlos and Gravier, Christophe and Laforest, Fr{\'e}d{\'e}rique and Hare, Jonathon and Simperl, Elena},
  booktitle={European Semantic Web Conference},
  pages={319--334},
  year={2018},
  organization={Springer}
}
@article{vougiouklis2018neural,
  title={Neural wikipedian: Generating textual summaries from knowledge base triples},
  author={Vougiouklis, Pavlos and Elsahar, Hady and Kaffee, Lucie-Aim{\'e}e and Gravier, Christophe and Laforest, Fr{\'e}d{\'e}rique and Hare, Jonathon and Simperl, Elena},
  journal={Journal of Web Semantics},
  volume={52},
  pages={1--15},
  year={2018},
  publisher={Elsevier}
}
@book{doyle1994information,
  title={Information literacy in an information society: A concept for the information age},
  author={Doyle, Christina S},
  year={1994},
  publisher={Diane Publishing}
}
@inproceedings{tardy2010writing,
  title={Writing for the World: Wikipedia as an Introduction to Academic Writing.},
  author={Tardy, Christine M},
  booktitle={English teaching forum},
  volume={48},
  pages={12},
  year={2010},
  organization={ERIC}
}
@book{booth2003craft,
  title={The craft of research},
  author={Booth, Wayne C and Colomb, Gregory G and Williams, Joseph M},
  year={2003},
  publisher={University of Chicago press}
}
@article{pedaste2015phases,
  title={Phases of inquiry-based learning: Definitions and the inquiry cycle},
  author={Pedaste, Margus and M{\"a}eots, Mario and Siiman, Leo A and De Jong, Ton and Van Riesen, Siswa AN and Kamp, Ellen T and Manoli, Constantinos C and Zacharia, Zacharias C and Tsourlidaki, Eleftheria},
  journal={Educational research review},
  volume={14},
  pages={47--61},
  year={2015},
  publisher={Elsevier}
}
@article{tawfik2020role,
  title={Role of questions in inquiry-based instruction: towards a design taxonomy for question-asking and implications for design},
  author={Tawfik, Andrew A and Graesser, Arthur and Gatewood, Jessica and Gishbaugher, Jaclyn},
  journal={Educational Technology Research and Development},
  volume={68},
  pages={653--678},
  year={2020},
  publisher={Springer}
}
@article{ram2023ralm,
  author = {Ori Ram and Yoav Levine and Itay Dalmedigos and Dor Muhlgay and Amnon Shashua and Kevin Leyton-Brown and Yoav Shoham},
  title = {In-Context Retrieval-Augmented Language Models},
  year = {2023},
  url = {https://arxiv.org/abs/2302.00083},
  journal = {Transactions of the Association for Computational Linguistics}
}
@article{JMLR:v24:23-0037,
  author  = {Gautier Izacard and Patrick Lewis and Maria Lomeli and Lucas Hosseini and Fabio Petroni and Timo Schick and Jane Dwivedi-Yu and Armand Joulin and Sebastian Riedel and Edouard Grave},
  title   = {Atlas: Few-shot Learning with Retrieval Augmented Language Models},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {251},
  pages   = {1--43},
  url     = {http://jmlr.org/papers/v24/23-0037.html}
}
@inproceedings{
poesia2022synchromesh,
title={Synchromesh: Reliable Code Generation from Pre-trained Language Models},
author={Gabriel Poesia and Alex Polozov and Vu Le and Ashish Tiwari and Gustavo Soares and Christopher Meek and Sumit Gulwani},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=KmtVD97J43e}
}
@article{khattab2022demonstrate,
  title={Demonstrate-Search-Predict: Composing Retrieval and Language Models for Knowledge-Intensive {NLP}},
  author={Khattab, Omar and Santhanam, Keshav and Li, Xiang Lisa and Hall, David and Liang, Percy and Potts, Christopher and Zaharia, Matei},
  journal={arXiv preprint arXiv:2212.14024},
  year={2022}
}
@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}
@misc{bohnet2023attributed,
      title={Attributed Question Answering: Evaluation and Modeling for Attributed Large Language Models}, 
      author={Bernd Bohnet and Vinh Q. Tran and Pat Verga and Roee Aharoni and Daniel Andor and Livio Baldini Soares and Massimiliano Ciaramita and Jacob Eisenstein and Kuzman Ganchev and Jonathan Herzig and Kai Hui and Tom Kwiatkowski and Ji Ma and Jianmo Ni and Lierni Sestorain Saralegui and Tal Schuster and William W. Cohen and Michael Collins and Dipanjan Das and Donald Metzler and Slav Petrov and Kellie Webster},
      year={2023},
      eprint={2212.08037},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{gao-etal-2023-enabling,
    title = "Enabling Large Language Models to Generate Text with Citations",
    author = "Gao, Tianyu  and
      Yen, Howard  and
      Yu, Jiatong  and
      Chen, Danqi",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.398",
    pages = "6465--6488",
}

@misc{menick2022teaching,
      title={Teaching language models to support answers with verified quotes}, 
      author={Jacob Menick and Maja Trebacz and Vladimir Mikulik and John Aslanides and Francis Song and Martin Chadwick and Mia Glaese and Susannah Young and Lucy Campbell-Gillingham and Geoffrey Irving and Nat McAleese},
      year={2022},
      eprint={2203.11147},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{
zhou2023docprompting,
title={DocPrompting: Generating Code by Retrieving the Docs},
author={Shuyan Zhou and Uri Alon and Frank F. Xu and Zhengbao Jiang and Graham Neubig},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=ZTCxT2t2Ru}
}
@article{zakka2023almanac,
  title={Almanac: Retrieval-Augmented Language Models for Clinical Medicine},
  author={Zakka, Cyril and Chaurasia, Akash and Shad, Rohan and Dalal, Alex R and Kim, Jennifer L and Moor, Michael and Alexander, Kevin and Ashley, Euan and Boyd, Jack and Boyd, Kathleen and others},
  journal={Research Square},
  year={2023},
  publisher={American Journal Experts}
}
@misc{nakano2022webgpt,
      title={WebGPT: Browser-assisted question-answering with human feedback}, 
      author={Reiichiro Nakano and Jacob Hilton and Suchir Balaji and Jeff Wu and Long Ouyang and Christina Kim and Christopher Hesse and Shantanu Jain and Vineet Kosaraju and William Saunders and Xu Jiang and Karl Cobbe and Tyna Eloundou and Gretchen Krueger and Kevin Button and Matthew Knight and Benjamin Chess and John Schulman},
      year={2022},
      eprint={2112.09332},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{jiang-etal-2023-active,
    title = "Active Retrieval Augmented Generation",
    author = "Jiang, Zhengbao  and
      Xu, Frank  and
      Gao, Luyu  and
      Sun, Zhiqing  and
      Liu, Qian  and
      Dwivedi-Yu, Jane  and
      Yang, Yiming  and
      Callan, Jamie  and
      Neubig, Graham",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.495",
    pages = "7969--7992",
}

@misc{parisi2022talm,
      title={TALM: Tool Augmented Language Models}, 
      author={Aaron Parisi and Yao Zhao and Noah Fiedel},
      year={2022},
      eprint={2205.12255},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{
    yao2023react,
    title={ReAct: Synergizing Reasoning and Acting in Language Models},
    author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik R Narasimhan and Yuan Cao},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=WE_vluYUL-X}
}

@inproceedings{feng2018topic,
  title={Topic-to-essay generation with neural networks.},
  author={Feng, Xiaocheng and Liu, Ming and Liu, Jiahao and Qin, Bing and Sun, Yibo and Liu, Ting},
  booktitle={IJCAI},
  pages={4078--4084},
  year={2018}
}

@misc{shen2023summarization,
      title={Beyond Summarization: Designing AI Support for Real-World Expository Writing Tasks}, 
      author={Zejiang Shen and Tal August and Pao Siangliulue and Kyle Lo and Jonathan Bragg and Jeff Hammerbacher and Doug Downey and Joseph Chee Chang and David Sontag},
      year={2023},
      eprint={2304.02623},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{weaver1991expository,
  title={Expository text.},
  author={Weaver III, Charles A and Kintsch, Walter},
  year={1991},
  publisher={Lawrence Erlbaum Associates, Inc}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{press-etal-2023-measuring,
    title = "Measuring and Narrowing the Compositionality Gap in Language Models",
    author = "Press, Ofir  and
      Zhang, Muru  and
      Min, Sewon  and
      Schmidt, Ludwig  and
      Smith, Noah  and
      Lewis, Mike",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.378",
    pages = "5687--5711",
}

@misc{qian2023webbrain,
      title={WebBrain: Learning to Generate Factually Correct Articles for Queries by Grounding on Large Web Corpus}, 
      author={Hongjing Qian and Yutao Zhu and Zhicheng Dou and Haoqi Gu and Xinyu Zhang and Zheng Liu and Ruofei Lai and Zhao Cao and Jian-Yun Nie and Ji-Rong Wen},
      year={2023},
      eprint={2304.04358},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{eriksson2015supervision,
  title={Supervision at the outline stage: Introducing and encountering issues of sustainable development through academic writing assignments},
  author={Eriksson, Ann-Marie and M{\"a}kitalo, {\AA}sa},
  journal={Text \& Talk},
  volume={35},
  number={2},
  pages={123--153},
  year={2015},
  publisher={De Gruyter}
}
@article{franti2023soft,
  title={Soft precision and recall},
  author={Fr{\"a}nti, Pasi and Mariescu-Istodor, Radu},
  journal={Pattern Recognition Letters},
  volume={167},
  pages={115--121},
  year={2023},
  publisher={Elsevier}
}
@article{freeman2010stakeholder,
  title={Stakeholder theory: The state of the art},
  author={Freeman, R Edward and Harrison, Jeffrey S and Wicks, Andrew C and Parmar, Bidhan L and De Colle, Simone},
  year={2010},
  publisher={Cambridge university press}
}
@article{ram1991theory,
  title={A theory of questions and question asking},
  author={Ram, Ashwin},
  journal={Journal of the Learning Sciences},
  volume={1},
  number={3-4},
  pages={273--318},
  year={1991},
  publisher={Taylor \& Francis}
}
@article{pavlik2023collaborating,
  title={Collaborating with ChatGPT: Considering the implications of generative artificial intelligence for journalism and media education},
  author={Pavlik, John V},
  journal={Journalism \& Mass Communication Educator},
  volume={78},
  number={1},
  pages={84--93},
  year={2023},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}
@article{wenzlaff2022smarter,
  title={Smarter than Humans? Validating how OpenAI’s ChatGPT model explains Crowdfunding, Alternative Finance and Community Finance.},
  author={Wenzlaff, Karsten and Spaeth, Sebastian},
  journal={Validating how OpenAI’s ChatGPT model explains Crowdfunding, Alternative Finance and Community Finance.(December 22, 2022)},
  year={2022}
}
@inproceedings{fitria2023artificial,
  title={Artificial intelligence (AI) technology in OpenAI ChatGPT application: A review of ChatGPT in writing English essay},
  author={Fitria, Tira Nur},
  booktitle={ELT Forum: Journal of English Language Teaching},
  volume={12},
  pages={44--58},
  year={2023}
}
@article{rohman1965pre,
  title={Pre-writing the stage of discovery in the writing process},
  author={Rohman, D Gordon},
  journal={College composition and communication},
  volume={16},
  number={2},
  pages={106--112},
  year={1965},
  publisher={JSTOR}
}
@article{kim2023prometheus,
  title={Prometheus: Inducing Fine-grained Evaluation Capability in Language Models},
  author={Kim, Seungone and Shin, Jamin and Cho, Yejin and Jang, Joel and Longpre, Shayne and Lee, Hwaran and Yun, Sangdoo and Shin, Seongjin and Kim, Sungdong and Thorne, James and others},
  journal={arXiv preprint arXiv:2310.08491},
  year={2023}
}
@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}
@article{khattab2023dspy,
  title={DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T. and Moazam, Hanna and Miller, Heather and Zaharia, Matei and Potts, Christopher},
  journal={arXiv preprint arXiv:2310.03714},
  year={2023}
}
@article{munoz2015main,
  title={Main ingredients for success in L2 academic writing: Outlining, drafting and proofreading},
  author={Munoz-Luna, Rosa},
  journal={PloS one},
  volume={10},
  number={6},
  pages={e0128309},
  year={2015},
  publisher={Public Library of Science San Francisco, CA USA}
}
@inproceedings{kandpal2023large,
  title={Large language models struggle to learn long-tail knowledge},
  author={Kandpal, Nikhil and Deng, Haikang and Roberts, Adam and Wallace, Eric and Raffel, Colin},
  booktitle={International Conference on Machine Learning},
  pages={15696--15707},
  year={2023},
  organization={PMLR}
}
@inproceedings{balepur-etal-2023-expository,
    title = "Expository Text Generation: Imitate, Retrieve, Paraphrase",
    author = "Balepur, Nishant  and
      Huang, Jie  and
      Chang, Kevin",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.729",
    pages = "11896--11919",
}
@inproceedings{semnani-etal-2023-wikichat,
    title = "{W}iki{C}hat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on {W}ikipedia",
    author = "Semnani, Sina  and
      Yao, Violet  and
      Zhang, Heidi  and
      Lam, Monica",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.157",
    pages = "2387--2413",
}
@inproceedings{aliannejadi2019asking,
  title={Asking clarifying questions in open-domain information-seeking conversations},
  author={Aliannejadi, Mohammad and Zamani, Hamed and Crestani, Fabio and Croft, W Bruce},
  booktitle={Proceedings of the 42nd international acm sigir conference on research and development in information retrieval},
  pages={475--484},
  year={2019}
}

@inproceedings{dietz2019trec,
  title={Trec car y3: Complex answer retrieval overview},
  author={Dietz, Laura and Foley, John},
  booktitle={Proceedings of Text REtrieval Conference (TREC)},
  year={2019}
}
@misc{huang2023survey,
      title={A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions}, 
      author={Lei Huang and Weijiang Yu and Weitao Ma and Weihong Zhong and Zhangyin Feng and Haotian Wang and Qianglong Chen and Weihua Peng and Xiaocheng Feng and Bing Qin and Ting Liu},
      year={2023},
      eprint={2311.05232},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{min-etal-2023-factscore,
    title = "{FA}ct{S}core: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation",
    author = "Min, Sewon  and
      Krishna, Kalpesh  and
      Lyu, Xinxi  and
      Lewis, Mike  and
      Yih, Wen-tau  and
      Koh, Pang  and
      Iyyer, Mohit  and
      Zettlemoyer, Luke  and
      Hajishirzi, Hannaneh",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.741",
    pages = "12076--12100",
}


@ARTICLE{9770051,
  author={Sugandhika, Chinthani and Ahangama, Supunmali},
  journal={IEEE Access}, 
  title={Assessing Information Quality of Wikipedia Articles Through Google’s E-A-T Model}, 
  year={2022},
  volume={10},
  number={},
  pages={52196-52209},
  keywords={Encyclopedias;Internet;Online services;Collaboration;Electronic publishing;Feature extraction;Bibliographies;Authority;expertise;Google’s E-A-T;hybrid approach;information quality;trustworthiness;web 2.0;Wikipedia},
  doi={10.1109/ACCESS.2022.3172962}}


@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@book{pascal2015design,
  title={Design and truth in autobiography},
  author={Pascal, Roy},
  year={2015},
  publisher={Routledge}
}
@article{lda,
author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
title = {Latent Dirichlet Allocation},
year = {2003},
issue_date = {3/1/2003},
publisher = {JMLR.org},
volume = {3},
number = {null},
issn = {1532-4435},
abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
journal = {J. Mach. Learn. Res.},
month = {mar},
pages = {993–1022},
numpages = {30}
}

@inproceedings{10.5555/3157382.3157492,
author = {Anagnostopoulos, Aris and \L{}\k{a}cki, Jakub and Lattanzi, Silvio and Leonardi, Stefano and Mahdian, Mohammad},
title = {Community Detection on Evolving Graphs},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Clustering is a fundamental step in many information-retrieval and data-mining applications. Detecting clusters in graphs is also a key tool for finding the community structure in social and behavioral networks. In many of these applications, the input graph evolves over time in a continual and decentralized manner, and, to maintain a good clustering, the clustering algorithm needs to repeatedly probe the graph. Furthermore, there are often limitations on the frequency of such probes, either imposed explicitly by the online platform (e.g., in the case of crawling proprietary social networks like twitter) or implicitly because of resource limitations (e.g., in the case of crawling the web).In this paper, we study a model of clustering on evolving graphs that captures this aspect of the problem. Our model is based on the classical stochastic block model, which has been used to assess rigorously the quality of various static clustering methods. In our model, the algorithm is supposed to reconstruct the planted clustering, given the ability to query for small pieces of local information about the graph, at a limited rate. We design and analyze clustering algorithms that work in this model, and show asymptotically tight upper and lower bounds on their accuracy. Finally, we perform simulations, which demonstrate that our main asymptotic results hold true also in practice.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {3530–3538},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}



@inproceedings{NIPS2013_9aa42b31,
 author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Distributed Representations of Words and Phrases and their Compositionality},
 url = {https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf},
 volume = {26},
 year = {2013}
}


@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@article{word_shift,
author = {Gallagher, Ryan and Frank, Morgan and Mitchell, Lewis and Schwartz, Aaron and Reagan, Andrew and Danforth, Christopher and Dodds, Peter},
year = {2021},
month = {12},
pages = {},
title = {Generalized word shift graphs: a method for visualizing and explaining pairwise comparisons between texts},
volume = {10},
journal = {EPJ Data Science},
doi = {10.1140/epjds/s13688-021-00260-3}
}

@article{babis2019between,
  title={Between biography and autobiography: exploring the official history in organizations},
  author={Babis, Deby},
  journal={Qualitative Research in Organizations and Management: An International Journal},
  year={2019},
  publisher={Emerald Publishing Limited}
}

@inproceedings{rosen2004author,
  title={The author-topic model for authors and documents},
  author={ROSEN-ZVI, M},
  booktitle={Proceedings of the 20th conference on Uncertainty in artificial intelligence, 2004},
  pages={487--494},
  year={2004},
  organization={AUAI Press}
}

@inproceedings{lacoste2008disclda,
  title={DiscLDA: Discriminative learning for dimensionality reduction and classification},
  author={Lacoste-Julien, Simon and Sha, Fei and Jordan, Michael I},
  booktitle={Advances in neural information processing systems},
  pages={897--904},
  year={2008}
}

@inproceedings{cohn2001missing,
  title={The missing link-a probabilistic model of document content and hypertext connectivity},
  author={Cohn, David A and Hofmann, Thomas},
  booktitle={Advances in neural information processing systems},
  pages={430--436},
  year={2001}
}

@inproceedings{hofmann1999probabilistic,
  title={Probabilistic latent semantic indexing},
  author={Hofmann, Thomas},
  booktitle={Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={50--57},
  year={1999}
}

@inproceedings{kim2015simultaneous,
  title={Simultaneous discovery of common and discriminative topics via joint nonnegative matrix factorization},
  author={Kim, Hannah and Choo, Jaegul and Kim, Jingu and Reddy, Chandan K and Park, Haesun},
  booktitle={Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={567--576},
  year={2015}
}

@article{fevotte2011algorithms,
  title={Algorithms for nonnegative matrix factorization with the $\beta$-divergence},
  author={F{\'e}votte, C{\'e}dric and Idier, J{\'e}r{\^o}me},
  journal={Neural computation},
  volume={23},
  number={9},
  pages={2421--2456},
  year={2011},
  publisher={MIT Press}
}

@article{hua2020probabilistic,
  title={Probabilistic topic modeling for comparative analysis of document collections},
  author={Hua, Ting and Lu, Chang-Tien and Choo, Jaegul and Reddy, Chandan K},
  journal={ACM Transactions on Knowledge Discovery from Data (TKDD)},
  volume={14},
  number={2},
  pages={1--27},
  year={2020},
  publisher={ACM New York, NY, USA}
}



@inproceedings{ilhan2015predicting,
  title={Predicting community evolution based on time series modeling},
  author={{\.I}lhan, Nagehan and {\"O}{\u{g}}{\"u}d{\"u}c{\"u}, {\c{S}}ule G{\"u}nd{\"u}z},
  booktitle={2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
  pages={1509--1516},
  year={2015},
  organization={IEEE}
}

@inproceedings{hinton2002stochastic,
  title={Stochastic neighbor embedding},
  author={Hinton, Geoffrey and Roweis, Sam T},
  booktitle={NIPS},
  volume={15},
  pages={833--840},
  year={2002},
  organization={Citeseer}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@article{louvain,
   title={Fast unfolding of communities in large networks},
   volume={2008},
   ISSN={1742-5468},
   url={http://dx.doi.org/10.1088/1742-5468/2008/10/P10008},
   DOI={10.1088/1742-5468/2008/10/p10008},
   number={10},
   journal={Journal of Statistical Mechanics: Theory and Experiment},
   publisher={IOP Publishing},
   author={Blondel, Vincent D and Guillaume, Jean-Loup and Lambiotte, Renaud and Lefebvre, Etienne},
   year={2008},
   month={Oct},
   pages={P10008}
}


@book{popkin2005history,
  title={History, historians, and autobiography},
  author={Popkin, Jeremy D},
  year={2005},
  publisher={University of Chicago Press}
}
@article{aurell2006autobiography,
  title={Autobiography as unconventional history: Constructing the author},
  author={Aurell, Jaume},
  journal={Rethinking History},
  volume={10},
  number={3},
  pages={433--449},
  year={2006},
  publisher={Taylor \& Francis}
}

@article{nature_of_biography,
 ISSN = {0008901X, 23754877},
 URL = {http://www.jstor.org/stable/45133792},
 author = {John A. Garraty},
 journal = {The Centennial Review of Arts \& Science},
 number = {2},
 pages = {123--141},
 publisher = {Michigan State University Press},
 title = {THE NATURE OF BIOGRAPHY},
 volume = {1},
 year = {1957}
}

@incollection{olney2019biography,
  title={Biography, autobiography and the life course},
  author={Olney, James},
  booktitle={Life course: Integrative theories and exemplary populations},
  pages={27--36},
  year={2019},
  publisher={Routledge}
}

@book{caine2018biography,
  title={Biography and history},
  author={Caine, Barbara},
  year={2018},
  publisher={Macmillan international higher education}
}

@article{bio_autobio_history,
author = {Laurie Wilson and Harold P. Blum},
title = {Biography, autobiography and history},
journal = {The International Journal of Psychoanalysis},
volume = {86},
number = {1},
pages = {155-158},
year  = {2005},
publisher = {Routledge},
doi = {10.1516/LT3J-Q4LK-727X-WQ22},

URL = { 
        https://doi.org/10.1516/LT3J-Q4LK-727X-WQ22
    
},
eprint = { 
        https://doi.org/10.1516/LT3J-Q4LK-727X-WQ22
    
}

}




@inproceedings{gandhipedia,
author = {Adak, Sayantan and Vyas, Atharva and Mukherjee, Animesh and Ambavi, Heer and Kadasi, Pritam and Singh, Mayank and Patel, Shivam},
title = {Gandhipedia: A One-Stop AI-Enabled Portal for Browsing Gandhian Literature, Life-Events and His Social Network},
year = {2020},
isbn = {9781450375856},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383583.3398631},
doi = {10.1145/3383583.3398631},
abstract = {We introduce an AI-enabled portal that presents an excellent visualization of Mahatma Gandhi's life events by constructing temporal and spatial social networks from the Gandhian literature. Applying an ensemble of methods drawn from NLTK, Polyglot and Spacy we extract the key persons and places that find mentions in Gandhi's written works. We visualize these entities and connections between them based on co-mentions within the same time frame as networks in an interactive web portal. The nodes in the network, when clicked, fire search queries about the entity and all the information about the entity presented in the corresponding book from which the network is constructed, are retrieved and presented back on the portal. Overall, this system can be used as a digital and user-friendly resource to study Gandhian literature.},
booktitle = {Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020},
pages = {539–540},
numpages = {2},
keywords = {text processing, temporal networks, entity recognition, Mahatma Gandhi},
location = {Virtual Event, China},
series = {JCDL '20}
}

@inproceedings{Momeni2018ModelingEO,
  title={Modeling Evolution of Topics in Large-Scale Temporal Text Corpora},
  author={Elaheh Momeni and Shanika Karunasekera and Palash Goyal and Kristina Lerman},
  booktitle={ICWSM},
  year={2018}
}

@article{recurrent_coupled_topic_model,
author = {Guo, Jinjin and Cao, Longbing and Gong, Zhiguo},
title = {Recurrent Coupled Topic Modeling over Sequential Documents},
year = {2021},
issue_date = {February 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1556-4681},
url = {https://doi.org/10.1145/3451530},
doi = {10.1145/3451530},
abstract = {The abundant sequential documents such as online archival, social media, and news feeds are streamingly updated, where each chunk of documents is incorporated with smoothly evolving yet dependent topics. Such digital texts have attracted extensive research on dynamic topic modeling to infer hidden evolving topics and their temporal dependencies. However, most of the existing approaches focus on single-topic-thread evolution and ignore the fact that a current topic may be coupled with multiple relevant prior topics. In addition, these approaches also incur the intractable inference problem when inferring latent parameters, resulting in a high computational cost and performance degradation. In this work, we assume that a current topic evolves from all prior topics with corresponding coupling weights, forming the multi-topic-thread evolution. Our method models the dependencies between evolving topics and thoroughly encodes their complex multi-couplings across time steps. To conquer the intractable inference challenge, a new solution with a set of novel data augmentation techniques is proposed, which successfully discomposes the multi-couplings between evolving topics. A fully conjugate model is thus obtained to guarantee the effectiveness and efficiency of the inference technique. A novel Gibbs sampler with a backward–forward filter algorithm efficiently learns latent time-evolving parameters in a closed-form. In addition, the latent Indian Buffet Process compound distribution is exploited to automatically infer the overall topic number and customize the sparse topic proportions for each sequential document without bias. The proposed method is evaluated on both synthetic and real-world datasets against the competitive baselines, demonstrating its superiority over the baselines in terms of the low per-word perplexity, high coherent topics, and better document time prediction.},
journal = {ACM Trans. Knowl. Discov. Data},
month = {jul},
articleno = {8},
numpages = {32},
keywords = {topic coupling, Topic modeling, bayesian network, gibbs sampling, multiple dependency, dropout, topic evolution, data augmentation}
}

@inproceedings{rsm,
author = {Salakhutdinov, Ruslan and Hinton, Geoffrey},
title = {Replicated Softmax: An Undirected Topic Model},
year = {2009},
isbn = {9781615679119},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 22nd International Conference on Neural Information Processing Systems},
pages = {1607–1614},
numpages = {8},
location = {Vancouver, British Columbia, Canada},
series = {NIPS'09}
}

@article{Blei2006DynamicTM,
  title={Dynamic topic models},
  author={David M. Blei and John D. Lafferty},
  journal={Proceedings of the 23rd international conference on Machine learning},
  year={2006}
}

@misc{allan_carbonell_doddington_yamron_yang_2018, title={Topic Detection and Tracking Pilot Study Final Report}, url={https://kilthub.cmu.edu/articles/journal_contribution/Topic_Detection_and_Tracking_Pilot_Study_Final_Report/6626252/1}, DOI={10.1184/R1/6626252.v1}, abstractNote={
Topic Detection and Tracking (TDT) is a DARPA-sponsored initiative to investigate the state of the art in finding and following new events in a stream of broadcast news stories. The TDT problem consists of three major tasks: (1) segmenting a stream of data, especially recognized speech, into distinct stories; (2) identifying those news stories that are the first to discuss a new event occurring in the news; and (3) given a small number of sample news stories about an event, finding all following stories in the stream. The TDT Pilot Study ran from September 1996 through October 1997. The primary participants were DARPA, Carnegie Mellon University, Dragon Systems, and the University of Massachusetts at Amherst. This report summarizes the findings of the pilot study. The TDT work continues in a new project involving larger training and test corpora, more active participants, and a more broadly defined notion of “topic” than was used in the pilot study. 

The following individuals participated in the research reported. 

James Allan, UMass 

Brian Archibald, CMU 

Doug Beeferman, CMU 

Adam Berger, CMU 

Ralf Brown, CMU 

Jaime Carbonell, CMU 

Ira Carp, Dragon 

Bruce Croft, UMass, 

George Doddington, DARPA 

Larry Gillick, Dragon 

Alex Hauptmann, CMU 

John Lafferty, CMU 

Victor Lavrenko, UMass 

Xin Liu, CMU 

Steve Lowe, Dragon 

Paul van Mulbregt, Dragon 

Ron Papka, UMass 

Thomas Pierce, CMU 

Jay Ponte, UMass 

Mike Scudder, UMass 

Charles Wayne, DARPA 

Jon Yamron, Dragon 

Yiming Yang, CMU

}, publisher={Carnegie Mellon University}, author={Allan, James and Carbonell, Jaime G. and Doddington, George and Yamron, Jonathan and Yang, Yiming}, year={2018}, month={Jun} } 