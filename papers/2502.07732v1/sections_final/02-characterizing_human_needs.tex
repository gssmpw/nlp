\section{Characterizing Human Data Needs}
Progress in machine learning depends on the availability of data at a sufficient scale to inductively learn patterns from it~\cite{kaplan2020scaling,hoffmann2022training}. This need for data has grown exponentially as learning algorithms have evolved from statistical to deep learning and pre-trained language models. The \textit{quantity} of data has uncontestedly been the key consideration for the field~\cite{sutton2019bitter}, with any data source that adds several orders of magnitude to the size of existing datasets, such as data from the Internet, being considered indispensable. A general trend in machine learning regarding data sourcing, especially after the advent of pre-training with BERT~\cite{devlin2018bert}, has been to leverage sources of large data wherever they can be found, such as BookCorpus~\cite{zhu2015aligning}, Wikipedia~\cite{raffel2020exploring}, Reddit~\cite{Gokaslan2019OpenWeb}, and CommonCrawl~\cite{commoncrawl}.

Recently, however, as datasets have grown larger, the importance of \textit{quality} has become more apparent~\cite{nguyen2022quality,zhou2024lima,lee2021deduplicating}. While learning algorithms have improved in extracting signal from noise, they still have limits when faced with excessive noise or irrelevant data~\citetext{e.g., DataComp-LM discards 99\% of data and Text-Image DataComp filters out 70\%; \textcolor{myorange}{\citealt{gadre2024datacomp,li2024datacomp}}}. Data quality has long been assumed to matter, but its significance has become clearer than ever as models trained on external proprietary datasets consistently outperform others on benchmarks and in real-world applications~\cite{brown2020language}. This outperformance\textemdash{}often attributed to access to ``high-quality'' proprietary datasets, such as paywalled content or licensed secondary sources~\cite{bommasani2021opportunities}\textemdash{}has pushed the data quality discourse to the forefront and is now a high priority in machine learning.

\begin{tcolorbox}[
    colback=gray!15,   % Uniform gray background
    colframe=gray!15,  % Border matches background for a soft look
    coltitle=black,    % Title in black
    sharp corners,     % No rounded edges
    width=\linewidth,  % Full-width box
    boxrule=0pt,       % Removes harsh border
    left=10pt, right=10pt, top=7pt, bottom=8pt, % Adjust padding inside box
    before=\bigskip, % Space above box
    after=\bigskip,  % Space below box
    title={\fontsize{12}{15} \textbf{Human Data Sourcing Desiderata}}, % Enlarged title
    fonttitle=\bfseries, % Bold title
    before title={\vspace{10pt}}, % This adds extra spacing above the title
    titlerule=0mm, % Ensures no extra rule appears
]
\begin{enumerate}[leftmargin=14pt, label=(\arabic*), itemsep=10pt] % More spacing
    \item \textbf{High Quality} \\[3pt]
    Collecting high-quality data with a strong signal-to-noise ratio for training ML models.

    \item \textbf{High Quantity} \\[3pt]
    Collecting data large enough to satisfy the exponentially increasing complexity of tasks.
\end{enumerate}
\end{tcolorbox}


While both high quality and high quantity are critical for data sourcing, they often come at the expense of each other\textemdash{}improving one typically leads to a decline in the other. However, this trade-off is not an inherent property of data itself but rather a consequence of system design choices. One way to conceptualize this trade-off is as resembling a Pareto frontier, as illustrated in Figure~\ref{fig:quality-quantity}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{illustrations/pareto-frontier.png}
    \caption{Illustration of the quantity-quality trade-off in data collection systems. Platforms like MTurk, Prolific, and UpWork optimize for either scale or quality but struggle to achieve both simultaneously. In contrast, data from sources not explicitly designed for data collection\textemdash{}such as Wikipedia and Reddit\textemdash{}operate outside this trade-off, hinting at potential alternative paradigms.}
    \label{fig:quality-quantity}
\end{figure}

This trade-off explains why data collection systems struggle to balance quality and quantity. Platforms prioritizing quality, like freelance job platforms (e.g., UpWork), tend to be slower with lower output, while high-throughput systems, like rapid crowdwork platforms (e.g., MTurk), scale efficiently but often sacrifice consistency and quality~\cite{douglas2023data}. While this quantity-quality trade-off may never be fully eliminated for any designed data collection system, it is not a fixed constraint\textemdash{}rather than eliminating the trade-off, the key is to expand the frontier by addressing structural inefficiencies in incentive design, annotation methods, and human oversight.

The dynamics of the quantity-quality trade-off are shaped by multiple interacting and, often, latent factors. Untangling these factors requires opening up current data collection systems and examining their trade-offs through the lens of human behavior, organizational processes, and technical constraints. At a system level, quality depends on balancing intrinsic motivation with external incentives, while quantity is largely driven by process efficiency, often through task fragmentation and parallelization. However, excessive fragmentation can erode intrinsic motivation, leading to long-term declines in quality. This self-reinforcing cycle lies at the heart of the quantity-quality trade-off in data collection system design. 
