% \section{Defining and Measuring Data Quality}
\section{Understanding Data Quality}
While quantity is easily measurable and increasingly attainable through new data-sourcing methods, quality has become ever more elusive. As data availability has surged, the question of what constitutes ``high-quality'' data is increasingly debated in machine learning. The challenge then is to understand the existing notions of data quality and explore ways to make it more certain, before dissecting data collection systems.

\textbf{Prior Definitions.} Defining ``data quality'' has long been a challenge in machine learning, as it lacks a universal, quantifiable standard. While it is widely acknowledged that human-generated data varies in quality (e.g., curated datasets from specific websites being more reliable than scraped content), there is no single, absolute definition for what makes data ``high-quality''.  Attempts to define quality span both subjective and objective perspectives. Subjectively, quality is often linked to trustworthiness\textemdash{}Wikipedia, for instance, is generally regarded as more reliable than personal blogs~\cite{albalak2024survey,soldaini2024dolma}. Objectively, quality has been measured using statistical metrics (e.g., readability) or modeled metrics, such as GPT-3 Quality Filters~\cite{gururangan2022whose} and DataComp's curated datasets~\cite{li2024datacomp}, which define quality in the context of their downstream use. 


\textbf{Naturalness as the Basis of Data Quality.} Without clarity on dataâ€™s intended use, defining quality becomes challenging. We contend that one of the most intuitive ways to conceptualize quality\textemdash{}without presupposing a specific application\textemdash{}is by anchoring it in \textit{naturalness}: how people behave in routine activities, online or offline, in an authentic manner. Unlike other definitions that rely on the perceived reliability of the source or application-specific criteria, naturalness provides an observable and generalizable signal for what constitutes high-quality data. This pattern is evident in organic data sources, where humans naturally generate valuable data through meaningful tasks, such as editing Wikipedia, participating in Reddit discussions, or sharing artwork and photos on platforms like Flickr. In these settings, data is generated naturally, often without direct external incentives, making it more representative of authentic human behavior. %This already hints at the idea that intrinsic motivation is crucial for producing in-situ data that accurately reflects natural behavior. 
% Thus, we argue that naturalness provides the most robust and context-agnostic definition of data quality, as it explains and unifies prior perspectives in the literature.


\textbf{Is There a Case for Naturalness in AI Training?}
Naturalness has already been central to pretraining, where large-scale internet data\textemdash{}capturing naturally occurring human behavior\textemdash{}has been crucial to the success of LLMs. But its importance extends beyond achieving generalization. Even in supervised fine-tuning, where data is tailored for task-specific applications, naturalness matters, as collected data should ideally reflect real task engagement rather than behavior shaped by artificial constraints or incentives.

Interestingly, this divide between pretraining and fine-tuning mirrors a broader debate in AI. \textbf{Artificial Intelligence (AI)}\textemdash{}as envisioned by John McCarthy~\cite{mccarthy1987generality}\textemdash{}aims to achieve human-like general intelligence and, therefore, benefits from diverse, free-flowing human interactions, much like those found in pretraining data. In contrast, \textbf{Intelligence Augmentation (IA)}\textemdash{}as suggested by Douglas Engelbart~\cite{engelbart1962augmenting}\textemdash{}prioritizes enhancing human intelligence through specialized tools, requiring goal-oriented human interactions towards performing a task, similar to fine-tuning data. In both cases, naturalness remains key but plays distinct roles: capturing free-flowing or goal-oriented human interactions, free from artificial constraints or incentives.

To that end, the use of LLMs in data collection is not inherently bad\textemdash{}what matters is \textit{how} they are used. The real risk to naturalness comes from indiscriminate, careless reliance on AI as a shortcut, rather than as a tool for balancing meaningful engagement and productivity. Instead of aggressively policing AI use, the focus should be on designing environments where contributors engage with tasks in ways that make shortcuts feel unnecessary\textemdash{}just as one wouldn't feel compelled to take shortcuts in a personally meaningful hobby. For example, a survey respondent outsourcing an entire essay writing task to AI without any personal input demonstrates an unwillingness to engage meaningfully with the task\textemdash{}this is the kind of AI use that undermines data quality.
