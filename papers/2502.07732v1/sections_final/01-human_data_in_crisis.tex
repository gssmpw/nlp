\section{Human Data in Crisis}
Artificial Intelligence relies heavily on human-generated data to develop ever more capable models and systems that can emulate human-like intelligent behavior. The currently used sources of human data include: (1) human annotations, from data collection platforms (e.g., Amazon MTurk) and (2) raw data, from the Internet (e.g., Wikipedia, social media platforms). Our understanding of how to effectively use these two data sources has been a driving force behind the two most prominent eras of artificial intelligence: the \textbf{Deep Learning era} which began with AlexNet~\cite{krizhevsky2012imagenet} in 2012 and facilitated by ImageNet~\cite{deng2009imagenet} collected at scale through MTurk, and the \textbf{Pre-trained Language Models era} ushered in by BERT~\cite{devlin2018bert} in 2018 and enabled by the availability of large-scale Internet data.

However, the emergence of the third \textbf{Generative Large Language Chat models era}, marked by ChatGPT in 2022~\cite{openai2023chatgpt}, has made human-like language generation ubiquitous and accessible to the general public, disrupting the very mechanisms of data sourcing that have historically enabled AI development. The indiscriminate usage of large language models (LLMs) impacts the previous two key sources of human-produced data: participants in existing data collection systems are turning to LLMs to expedite their tasks~\cite{veselovsky2023artificial,veselovsky2023prevalence}, and the Internet is being flooded with LLM-generated content ~\cite{brooks2024rise}.
This makes it increasingly challenging to obtain and discern authentic human-generated data, raising concerns about a looming shortage of human data needed for continued AI progress.  To compensate, machine learning has further leaned into synthetic data\textemdash{}either to mimic human annotations~\cite{dubois2024alpacafarm} or emulate human behavior~\cite{argyle2023out, park2022social, park2023generative}\textemdash{} albeit not yet at the highest quality~\cite{geng2024unmet} and facing other challenges, such as model collapse~\cite{taori2023data, shumailov2024ai}, keeping the ember of human-generated data still alive~\cite{ashok2024little}.


We argue that these flaws have always existed in data collection platforms but have been recently amplified by LLMs to the point where their very existence is being called into question~\cite{pieces2025data}. Specifically,
{\bf
at the heart of this problem lies the issue of human incentives and motivations for contributing dataâ€”one that cannot be solved by simply increasing external rewards like pay but requires careful attention to intrinsic motivations that drive people to engage willingly and actively on platforms, which in turn leads to better-quality data.
} Designing new data collection systems necessitates a critical examination of the flaws in existing ones.


% \textcolor{red}{PB: We need a short para here to summarize the key propositions we're making in this paper in 2-3 lines e.g., a focus on intrinsic motivations requires ceding control at the task level, while designing enabling environments. A good example of where this has worked is data collection games. We equally emphasize the value of preserving user trust in sustaining high quality data collection systems etc.}

In this paper, we analyze the current data requirements in machine learning and how existing data collection systems attempt to meet them. We open up the black box of data collection\textemdash{}complex socio-technical systems shaped by human behaviors, idiosyncrasies, and technical constraints\textemdash{}drawing from popular theories and experiments in psychology, sociology, and economics. In doing so, we examine the quantity-quality tradeoff and argue that, while this tradeoff may not be entirely eliminable, the overall quality and quantity of data can still be improved by identifying and removing factors that undermine intrinsic human motivations. Given that data collection systems operate within broader economic and social structures, we also complement academic research with real-world discourse and case studies of different data collection strategies. Finally, we explore novel paradigms, including games, that offer promising directions for the future of human data sourcing.