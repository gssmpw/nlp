\section{Games as a New Pareto-Frontier?}
Games are uniquely positioned at the intersection of structured environments and intrinsic motivation. Designed worlds crafted by game developers set the rules and constraints, yet within them, players engage voluntarily, driven by curiosity, competition, and creativity~\cite{koster2005theory}. Unlike traditional work, where tasks are often externally imposed, games offer a space where challenge and engagement emerge naturally, 
sustaining long-term participation without the need for direct financial incentives.

For most players\textemdash{}aside from professional esports competitors\textemdash{}games are played purely for enjoyment. At the same time, they require diverse forms of reasoning, strategy, and problem-solving, making them a rich ground for capturing complex human behaviors and decision making~\citetext{as already evidenced by their role in evaluating intelligence; \textcolor{myorange}{\citealt{silver2016mastering, vinyals2019grandmaster, berner2019dota, meta2022human}}}. In this way, games hint at a new frontier\textemdash{}one where many structured environments and organic engagements seamlessly coexist. This intersection offers a compelling model for AI training, where intrinsically motivated interactions can yield structured, high-quality data without the pitfalls of external incentive-driven systems.

\textbf{Games as a Tool for Data Collection.} Games have long been explored as a tool for large-scale human annotation and AI training, most notably through von Ahn's Games with a Purpose (GWAP) \cite{von2006games}. One of the earliest and most influential examples was the ESP Game~\cite{von2005esp}, introduced in 2004, which engaged thousands of players in a collaborative tagging game, generating millions of image annotations. While players simply enjoyed the game, their interactions helped bootstrap Google Image Search~\cite{guardian2006esp}, which previously relied only on filenames, as large-scale labeled datasets like ImageNet were not available until 2009~\cite{deng2009imagenet}.

Von Ahn argued that the billions of hours spent on games\textemdash{}such as the 9 billion hours on Solitaire in 2003 alone, enough to build the Empire State Building in 6.8 hours or the Panama Canal in a day\textemdash{}could be repurposed for more meaningful tasks, inspiring the broader Games with a Purpose framework~\cite{law2011human}. Other notable games in this series included Peek-a-boom~\cite{von2006peekaboom}, which collected image segmentation data, and Verbosity~\cite{von2006verbosity}, designed to gather commonsense factual knowledge.

\textbf{Games in Mainstream ML.} While recent efforts towards this in machine learning have not reached the scale of GWAP, they have made notable progress. Examples include Google's QuickDraw~\cite{ha2017neural} and AllenAI's Iconary~\cite{clark2021iconary}, which focus on collecting freehand drawing data, and AI21's HumanOrNot~\cite{jannai2023human}, which gathers conversational data through a gamified Turing Test~\cite{dugan2023real}.

However, developing entirely new games for data collection presents significant challenges. Machine learning researchers often lack expertise in designing engaging gameplay, making it difficult to ensure both high-quality data and sustained participation. To navigate this, some approaches have focused on repurposing existing games rather than building from scratch. For example, Family Feud has been adapted to generate QA pairs~\cite{boratko2020protoqa}, and Minecraft has been used as a platform for collecting conversational dialogues~\cite{narayan2019collaborative}.

On a smaller scale, some efforts have explored gamification, introducing game-like mechanics into traditionally non-game tasks to enhance engagement, without requiring a full game environment. For instance, CommonsenseQA 2.0 incorporates elements such as scoring, competition, and progression to make data contribution more engaging, improving both user participation and data quality~\cite{talmor2022commonsenseqa}.

\textbf{Design Considerations.} Designing data collection games requires solving multiple challenges at once\textemdash{}the most critical challenge is optimizing data utility while preserving intrinsic player motivation. This involves balancing two often competing objectives:
\begin{itemize}[left=0cm]
    \item Ensuring that collected data meets the needs of AI/ML tasks -- requiring structure, reliability, and task relevance.
    \item Designing a player experience that remains engaging over time --avoiding disengagement due to artificial constraints or coercive incentives.
\end{itemize}
Achieving this balance is a multi-objective optimization problem that requires close collaboration between ML researchers and game developers. This design space spans multiple approaches, including creating entirely new games optimized for data collection, leveraging existing games to re-purpose organic player interactions, or introducing game-like elements into existing data collection tasks to enhance engagement. Each of these approaches comes with trade-offs in control, scalability, and long-term sustainability.

While prior efforts have successfully optimized for quality and quantity, sustaining trust has proven far more elusive, leading to short-lived or unsustainable solutions. Historical implementations offer valuable lessons\textemdash{}GWAP demonstrated the potential for high-quality, high-quantity crowdsourced data but did not endure over time. In contrast, ReCAPTCHA~\cite{von2008recaptcha} conceptualized in 2008, used for annotating books and self-driving data~\cite{captcha_google,captcha_nyt}, remains widely used today but has blurred the line between voluntary participation and coercion, with users reporting frustration and annoyance~\cite{searles2023empirical,searles2023dazed}, alluding to lack of trust. These examples illustrate the challenge of designing systems that optimize for all three aspects: \textbf{high-quality}, \textbf{high-quantity}, and \textbf{high-trust} data collection.

% While prior efforts have successfully optimized for quality and quantity, sustaining trust has proven far more elusive, leading to short-lived or unsustainable solutions. Historical implementations offer valuable lessons -- GWAP demonstrated the potential for high-quality crowdsourced data but lacked sustainability, while ReCAPTCHA~\cite{von2008recaptcha} used for annotating books and self-driving data~\cite{captcha_google,captcha_nyt} has been highly sustainable but did so in a way that blurred the line between voluntary participation and coercion, undermining user trust~\cite{searles2023empirical,searles2023dazed}. These examples illustrate the challenge of designing systems that optimize for all three aspects: high-quality, high-quantity, and high-trust data collection.

This challenge becomes even more evident when considering long-term sustainability. While data collection games have proven effective in gathering large-scale, high-quality data, few have endured over time. To our knowledge, no sustained data collection effort through games exists in machine learning. However, other research fields provide examples of systems that have successfully maintained engagement and trust over extended periods. Scientific discovery platforms such as Zooniverse for citizen science in astronomy~\cite{cardamone2009galaxy,lintott2008galaxy}, Lab in the Wild for HCI and psychology user studies~\cite{reinecke2015labinthewild}, FoldIt for protein folding~\cite{khatib2011crystal,cooper2010predicting}, and even Eve Online for epidemiology research~\cite{kafai2016connected} demonstrate how engagement, motivation, and trust can be sustained without relying on short-lived external incentives. Psychology and cognitive science studies~\cite{allen2024using} further reinforce that game-like participation can be structured in ways that maintain engagement over time.

While games and other naturalistic environments show significant potential towards achieving higher quality and quantity at the same time, they come with their own unique benefits and challenges previously not encountered with data collection systems:

\textbf{Benefits} include \textbf{the collection of previously inaccessible data}, such as natural dialogue interactions. Human conversations are often behind privacy walls, and attempting to collect dialogue through traditional data collection platforms is impractical, because unlike simple annotation tasks, dialogues need to be organic with real-time back-and-forth exchanges. In such cases, LLM-generated synthetic data has been a relief, with datasets like SODA~\cite{kim2022soda} playing a pivotal role in advancing dialogue systems. However, games offer an ideal setting where natural dialogues happen organically in non-real-world contexts, often under pseudonyms, making privacy concerns less of an issue. For instance, Minecraft has been leveraged to collect goal-driven player dialogues~\cite{narayan2019collaborative}, demonstrating how game environments facilitate authentic, context-rich communication.

Benefits also arise from the nature of games, including their ability to \textbf{collect data for open-ended tasks}, which has traditionally been challenging~\cite{karpinska2021perils}, especially over the long term. Moreover, games provide a unique advantage by enabling multi-modal data collection\textemdash{}capturing vision, language, and speech for the same actions\textemdash{}thus supporting advancements in embodied AI research. This has already been demonstrated in virtual environments like Habitat~\cite{puig2023habitat} and AI2-THOR~\cite{kolve2017ai2}, albeit without game-like objectives or direct human involvement to learn from yet.


\textbf{Challenges} include \textbf{difficulty in designing meaningful intrinsic rewards}, as motivations and preferences naturally vary across individuals and cultures. Unlike money, which serves as a universal incentive, intrinsic rewards must align with diverse motivational drivers\textemdash{}curiosity, competition, or self-improvement\textemdash{}to sustain engagement~\cite{jun2017types}. This also impacts demographic representation, as cultural and personal factors shape motivation~\cite{deci1985self}. Certain groups may be overrepresented while others disengage based on how well rewards align with their preferences~\cite{triandis1995individualism}. To ensure fairness, intrinsically motivated data collection must be designed to encourage diverse participation rather than benefiting only specific user segments. 

While games are often seen as leisure activities or ``unproductive,'' repurposing them for data collection contributes to value creation, in which case, it is important to recognize and fairly compensate contributors. The challenge is that, unlike traditional annotation tasks, AI data attribution is ambiguous, making it difficult to measure and \textbf{distribute compensation effectively}. One way to address this is by ensuring that contributors have a stake in the value their data generates, potentially through decentralized compensation models~\cite{loyalAI}. However, in general, compensation must be carefully structured to avoid distorting intrinsic motivation. If participants anticipate compensation upfront, their engagement risks becoming extrinsically driven, leading to lower-quality contributions. A potential solution is delayed, post-hoc recognition, where participants are acknowledged after the fact, ensuring they remain intrinsically engaged while still benefiting from their contributions.

Beyond incentive design, another fundamental challenge is ensuring that game-derived data remains both ethical and useful. Not all games inherently separate real-world contexts, which may necessitate distinguishing user-identifiable behavior from game-playing behavior for privacy reasons~\cite{nair2022exploring}. More broadly, extracting useful and generalizable data from inherently noisy and unstructured game records can be a significant challenge, similar to the difficulties faced in filtering large-scale Internet data~\cite{fang2023data}.