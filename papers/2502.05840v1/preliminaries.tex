We let $\Sigma$ be a countable alphabet\footnote{We restrict our study to countable alphabets, as if $\SS$ is uncountable, the topological space $\SS^\omega$ is not Polish and the class $\BCSigma$ is not as well-behaved.} and $\eps\notin \Sigma$ be a fresh symbol that should be interpreted as a neutral letter.
Given a word $w \in (\Sigma \cup \{\eps\})^\omega$ we write $\pi_\Sigma(w)$ for the (finite or infinite) word obtained by removing all $\eps$'s from $w$; we call it its projection on $\Sigma$.
An objective is a set $W \subseteq \Sigma^\omega$.
Given an objective $W \subseteq \Sigma^\omega$, we let $W^\eps$ denote $\pi_\Sigma^{-1}(W) \subseteq (\Sigma \cup \{\eps\})^\omega$.

\subsection{Graphs, games and memory}

We introduce notions pertaining to games and strategy complexity, as they will be central in the statement of our results.
Nevertheless, we note that all our technical proofs will use these definitions through Theorem~\ref{thm:universal_graphs} below, and will not explicitly use games.

\subparagraph*{Graphs.}
A $\SS$-graph $G$ is given by a set of vertices $V(G)$ and a set of coloured, directed edges $E(G) \subseteq V(G) \times \SS \times V(G)$.
We write $v \re c v'$ for edges $(v,c,v')$.
A path is a sequence of edges with matching endpoints $(v_0 \re {c_0} v_1)(v_1 \re{c_0} v_2) \dots$ which we write as $v_0 \re {c_0} v_1 \re{c_1} \dots$.
Paths can be empty, finite, or infinite, and have a label $c_0c_1\dots$.
Throughout the paper, graphs are implicitly assumed to be without dead-end: every vertex has an outgoing edge.

We say that a vertex $v$ in a $\Sigma$-graph (resp. a $(\Sigma \cup \{\eps\})$-graph) satisfies an objective $W \subseteq \Sigma^\omega$ if the label of any infinite path from $v$ belongs to $W$ (resp. to $W^\eps$).
A pointed graph is a graph with an identified initial vertex.
A pointed graph satisfies an objective $W \subseteq \Sigma^\omega$ if the initial vertex satisfies $W$; a non-pointed graph satisfies an objective if all its vertices do.
An infinite tree is a sinkless pointed graph whose initial vertex is called the root, and with the property that every vertex admits a unique path from the root.

A morphism from a $\Sigma$-graph $G$ to a $\Sigma$-graph $H$ is a map $\phi: V(G) \to V(H)$ such that for any edge $v \re c v'$ in $G$, it holds that $\phi(v) \re c \phi(v')$ is an edge in $H$.
Morphisms between pointed graphs should moreover send the initial vertex of $G$ to the initial vertex of $H$.
Morphisms need not be injective.
We write %$G \re \phi H$ when $\phi$ is a morphism from $G$ to $H$, and 
$G \re{} H$ when there exists a morphism $\phi \colon G \to H$.

\subparagraph*{Games and strategies.}
A game is given by a pointed $(\Sigma \cup \{\eps\})$-graph $G$ together with an objective $W \subseteq \Sigma^\omega$, and a partition of the vertex set $V(G)=V_\Eve \sqcup V_\Adam$ into the vertices controlled by Eve and those controlled by Adam.
%A strategy for Eve is a function indicating how to move given any history of the game; it is winning if whenever Eve follows this strategy, the produced path satisfies the objective $W$.We say that Eve wins if she has a winning strategy.
A strategy\footnote{We follow the terminology from~\cite{CO25LMCS}. The classical notion of a strategy as a function $f\colon E(G)^*\to V(G)$ can be recovered by considering the graph with vertices $E(G)^*$, and edges $\rho \re e \rho e$.} (for Eve) is a pointed graph together with a morphism $\pi$ towards $G$, %called the (strategy) projection, 
satisfying that for every edge $v \re c v'$ in the game, where $v \in V_\Adam$, and for all $u \in \pi^{-1}(v)$, there is an edge $u \re c u'$ such that $u' \in \pi^{-1}(v)$.
%Strategies are graphs, so by our assumption on graphs, they are without dead-end.
A strategy is winning if it satisfies the objective $W$ of the game.
We say that Eve wins if there exists a winning strategy.



\subparagraph{Memory.} 
A finite-memory strategy\footnote{It is common to define a memory structure as an automaton reading the edges of a game graph. This notion can be recovered by taking $\{1,\dots,k\}$ as the states of the automaton.}
is a strategy with vertices $V(G) \times \{1,\dots,k\}$ and projection $\pi(v,m)=v$, with the additional requirement that for every edge $(v,m) \re \eps (v',m')$, it holds that $m=m'$.
We say that $k$ is the memory of the strategy, and numbers $1,\dots,k$ are called memory states.
Informally, the requirement above says that when reading an $\eps$-transition in the game, we are not allowed to change the memory state; this is called $\eps$-memory in~\cite{CO25LMCS} (to which we refer for more discussion), but since it is the main kind of memory in this paper, we will simply call it the memory.

A finite-memory strategy is called chromatic if there is a map $\chi:\{1,\dots,k\} \times (\Sigma \cup \{\varepsilon\}) \to \{1,\dots,k\}$ such that for every edge $(v,m) \re c (v',m')$ in the strategy, it holds that $m'=\chi(m,c)$.
We say that $\chi$ is the chromatic update.
Note that necessarily, we have $\chi(m,\eps)=m$ for every memory state $m$.
%A strategy with memory $k$ is implemented by a deterministic finite-state machine with $k$ states $M$ and transitions of the form $M\times E(G) \to M$, together with a function $\mathsf{move}: V_\Eve\times M \to E(G)$ indicating how to play when in a position $v$ and a memory state $m$.
%Moreover, we require that the memory state is not updated when reading $\eps$-edges of the game.
%This is called an $\eps$-memory in~\cite{CO25LMCS} (to which we refer for more discussion), but since this is the main kind of memory in this paper, we will simply call it memory.
%We say that this is a chromatic strategy if the transitions can be taken of the form $M\times \Sigma \to M$.
%Given a game with objective $W$, its memory requirement is the minimal memory of a winning strategy if it exists (i.e.~if Eve wins), and $0$ otherwise.

The (chromatic) memory of an objective $W$ is the minimal $k$ such that for every game with objective $W$, if Eve has a winning strategy, she has a winning (chromatic) strategy with memory $\leq k$.


\subsection{Automata}

We write $\d$ for the set $\{0,\dots,d\}$.
A parity automaton $\A$ (or just automaton in the following) with index $d$ -- an even number -- and alphabet $\Sigma$, is a pointed $((\Sigmaeps) \times \d)$-graph.
Vertices are called states, edges are called transitions and written $q \re{c:y} q'$, where $c \in \Sigmaeps$ and $y \in \d$.
Elements in $\d$ are called priorities.
Generally, we use the convention that even priorities are denoted with letter $x$, whereas $y$ can be used to denote any priority.
Transitions of the form $q \re{\eps:y} q'$ are called $\eps$-transitions; note that they also carry priorities.

Infinite paths from the initial state $q_0$ are called runs. A run is accepting if the projection of its label on the second coordinate belongs to
\[
    \Parity_d = \{y_0y_1 \dots \in \d^\omega \mid \liminf(y) \text{ is even}\}. \quad \text{ (Note the use of \emph{min}-parity.)}
\]
The language $L(\A)$ of $\A$ is $\pi_\Sigma(L')$, where $L' \subseteq (\Sigmaeps)^\omega$ is the set of projections on the first coordinate of runs which are accepting.
We require that all these projections are infinite words; stated differently, there is no accepting run from $q_0$ labelled by a word in $(\Sigmaeps)^* \eps^\omega$.
An automaton is deterministic if there are no $\eps$-transitions and for any state $q \in V(\A)$ and any letter $a \in \Sigma$ there is at most one transition $q \re{a:\ph} \ph$.
We say that an automaton is determinisable by pruning if one can make it deterministic by removing some transitions, without modifying its language.
A language belongs to $\BC(\bsigma 2)$ if it is the language of a deterministic automaton, and it is $\omega$-regular if the automaton is moreover finite.

%A morphism between automata is just a morphism of pointed $((\Sigmaeps) \times \d)$-graphs.
%We say that $\B$ is a $k$-blowup of $\A$ if there is a morphism $\B \re \phi \A$ such that for each state $q$ of $\A$, it holds that $|\phi^{-1}(q)|\leq k$, and for each transition $q \re {a:y} q'$ in $\A$ and each $s \in \phi^{-1}(q)$, there is some $s' \in \phi^{-1}(q')$ such that $s \re{a:y} s'$ in $\B$.
%In other terms, $\B$ is obtained from $\A$ by blowing up each vertex $k$-times, and redirecting transitions accordingly.


We will often identify pointed graphs with automata of index $0$, by labelling all transitions with priority $0$. Note that in this case, all runs are accepting.
This requires making sure that there is no accepting run labelled by a word from $\Sigma^* \eps^\omega$, which, up to assuming that all vertices are accessible from the initial one, amounts to saying that there is no infinite path of $\re \eps$.
We say that such a graph is well-founded.


\subparagraph*{Blowups and $k$-automata.} A $k$-blowup $\B$ of an automaton $\A$ is any automaton with $V(\B) \subseteq V(\A) \times \{1,\dots, k\}$, with initial state in $\{q_0\}\times\{1,\dots,k\}$ and such that for each transition $q \re{a:y} q'$ in $\A$ and each $m \in \{1,\dots,k\}$, there is a transition $(q,m) \re{a:y} (q',\ph)$. We also allow for extra transitions in $\B$. % and such that all transitions in $\B$ are of this form.
Note that in this case $L(\A) \subseteq L(\B)$.

A $k$-automaton is just an automaton whose states are a subset of $Q \times \{1,\dots,k\}$, for some set $Q$; for instance, $k$-blowups are $k$-automata.
Equivalently, these are automata with a partition of their states in $k$ subsets.
%We sometimes implicitly identify automata with $1$-automata.
For a state $(q,m)$ in a $k$-automaton, $m$ is called its memory state.
A $k$-automaton is called chromatic if there is a map $\chi:  \{1,\dots, k\} \times (\Sigma \cup \{\eps\}) \to  \{1,\dots, k\}$ such that for all transition $(q,m) \re{a:y} (q',m')$ it holds that $m'=\chi(q,m)$.

\subparagraph{Cascade products.} Let $\A$ be an automaton with alphabet $\Sigma$ and index $d$, and let $S$ be a $\d$-graph.
We define their cascade product $\A \casc S$ to be the $(\Sigmaeps)$-graph with vertices $V(\A) \times V(S)$ and edges
\[
    (q,s) \re c (q',s') \quad \iff \quad \exists y, [q \re {c:y} q' \text{ and } s \re y s'].
\]
If $S$ is a pointed graph with intial vertex $s_0$, then $\A \casc S$ is pointed with initial vertex $(q_0,s_0)$.
It is easy to check that we then have the following lemma.

\begin{lemma}\label{lem:cascade_products}
    Let $\A$ be an automaton with index $\d$ and $S$ be a $\d$-graph satisfying $\Parity_d$.
    Then $\A \casc S$ is well-founded and satisfies $L(\A)$.
\end{lemma}

\subsection{$\eps$-completability and universal graphs}
We now introduce and discuss the key notion used in our main characterisation, which adapts the notion from~\cite{CO24Positional} from positionality to finite memory.

\subparagraph*{$k$-wise $\eps$-completability.}
A $k$-automaton $\A$ with index $d$ is called $k$-wise $\eps$-complete if for each even $x \in \d$, for each memory state $m$ and each ordered pair of states $(q,m),(q',m)$:
\[
    \text{either} \quad (q,m) \re{\eps:x} (q',m) \quad \tor \quad (q',m) \re{\eps:x+1} (q,m). %\tag{1} \label{eq:1}
\]

Intuitively, having an edge $(q,m) \re{\eps:x} (q',m)$ means that ``$(q,m)$ is much better than $(q',m)$'', as one may freely go from $(q,m)$ to $(q',m)$ and even see a good priority on the way.
Similarly, $(q',m) \re{\eps:x+1} (q,m)$ means that ``$(q',m)$ is not much worse than $(q,m)$''.
%Therefore $\eps$-completion states that, for each different level of granularity which are parameterised by even priorities $x$, states $q$ and $q'$ are comparable: if $q$ is not much better than $q'$, then $q'$ is not much worse than $q$.

It is also useful for the intuition to apply the definition to both ordered pairs $((q,m),(q',m))$ and $((q',m),(q,m))$.
Since automata exclude accepting runs which are ultimately comprised of $\eps$-transitions, we cannot have $(q,m) \rer{\eps:x} (q',m)$, and therefore $\eps$-completability rewrites as: for each $x$, each memory state $m$ and each unordered pair $(q,m),(q',m)$ of states,
\[
    \text{either} \quad (q,m) \xrightarrow[\eps :x+1]{\eps:x} (q',m) \quad \tor \quad (q,m) \rer{\eps:x+1} (q',m). 
\]
Hence an alternative, maybe more useful view (this is the point of view adopted in~\cite{CO24Positional}) is that, up to applying some adequate closure properties%(transitivity and adding edges with worse priorities)
, a $k$-wise $\eps$-complete automaton is endowed with the following structure: for each even priority $x$ and each memory state $m$, the states with memory state $m$ are totally preordered by the relation $\re {x+1}$, and the relation $\re x$ is the strict version of this preorder.
Moreover, for $x'>x$, the $x'$-preorder is a refinement of the $x$-preorder.

A $k$-automaton $\A$ is called $k$-wise $\eps$-completable if one may add $\eps$-transitions to it so as to turn it into a $k$-wise $\eps$-complete automaton $\A^\eps$ satisfying $L(\A^\eps)=L(\A)$.
%\end{definition}
We simply say ``$\eps$-complete'' (resp. ``$\eps$-completable'') as a shorthand for ``1-wise $\eps$-complete'' (resp. ``1-wise'' $\eps$-completable).
%Note that every finite automaton is trivially $|\A|$-wise $\eps$-completable, by adding no $\eps$-transitions.

\begin{example}
    Let $\Sigma = \{a, b,c\}$ and 
    \[W = \noOcc(b) \vee \finOften(aa) \vee \infOften(cc).\]
    We show a $2$-wise $\eps$-complete automaton recognising $W$ in Figure~\ref{fig:aut-eps-complete}. By Theorem~\ref{thm:main-charac}, the memory of $W$ is $\leq 2$ (and it is easy to see that this bound is tight).
    %\ac{The example is rather complex, but if we want a simple one, all states are 1-comparable. A simpler example, with  3 states and $\SS=\{a,b\}$: $W = \noOcc(b) \vee \finOften(aa) \vee \infOften(bb)$.}

    \begin{figure}[h]
        \centering
        \includegraphics{Figures/parity-automaton.pdf}
        \caption{A 2-automaton recognising $W=\noOcc(b) \vee \finOften(aa) \vee \infOften(cc)$, where $p$ is assumed to have a different memory state than $q_0,q_1$ and $q_2$. It is $2$-wise $\eps$-completable by adding the indicated $\eps$-transitions. A completion also contains the transitions $q_2\re{\eps:0,1,2} q_0$, omitted for ease of reading. However, it is not chromatic since reading $c$ may or may not switch the memory state.}
        \label{fig:aut-eps-complete}
    \end{figure}
\end{example}


%In the important special case of well-founded graphs viewed as automata, since all non-$\eps$-transitions are labelled with priority $0$, transitions $\re {\eps:0}$ and $\re{\eps:1}$ play the same role, and we simply write them $\re \eps$.
%Therefore,~(\ref{eq:1}) can be seen as totality of the $\re \eps$ relation, and it can moreover be closed under transitivity.

%The following result is the main step for constructing adequate universal graphs in~\cite{CO25LMCS}, where it is called the structuration lemma.
The following theorem, a key result in~\cite{CO25LMCS} where it is called the structuration lemma, will also be crucial to this work.
Recall that we see well-founded pointed graphs as automata with only $0$-transitions, and we apply the terms $k$-blowup and $\eps$-completable to them accordingly.

\begin{restatable}[{Adapted from Lemma 3.4 in \cite{CO25LMCS}}]{theorem}{structuration}
    \label{thm:structuration}
    Let $G$ be a well-founded pointed graph satisfying an objective $W$ which is assumed to have (chromatic) memory $\leq k$ over games of size $\leq 2^{|G|}$.
    There is a (chromatic) $k$-blowup $G'$ of $G$ which is well-founded, $k$-wise $\eps$-complete, and satisfies $W$.
    %Moreover, if $v \re \eps v'$ in $G'$ then $v$ and $v'$ have the same memory state.
\end{restatable}

For completeness, we give a proof of Theorem~\ref{thm:structuration} in Appendix~\ref{app:structuration}.

\subparagraph*{Universal graphs.}
Given an objective $W$ and a cardinal $\kappa$, we say that a graph $U$ is $(\kappa,W)$-universal if for any infinite tree $T$ of cardinality $|V(T)|<\kappa$ satisfying $W$, there is a morphism $\phi:T \to U$ such that $\phi(t_0)$ satifies $W$ in $U$, where $t_0$ is the root of $T$.
We may now rephrase the main theorem of~\cite{CO25LMCS} in terms of $\eps$-complete universal graphs.

\begin{theorem}[Theorem 3.1 in \cite{CO25LMCS}]\label{thm:universal_graphs}
Let $W$ be an objective.
Then $W$ has (chromatic) memory $\leq k$ if and only if for every cardinal $\kappa$ there exists a $(\kappa,W)$-universal graph which is (chromatic and) $k$-wise $\eps$-complete.
\end{theorem}


We now give an explicit definition of a $(\kappa,\Parity_{d})$-universal graph $S^\kappa_{d}$ which is $\eps$-complete.
These ideas date back to the works of Streett and Emerson, who coined the name signatures~\cite{SE89}, and were made more explicit by Walukiewicz~\cite{Walukiewicz96}. 
Vertices are tuples of ordinals $<\kappa$, indexed by odd priorities in $d$ and ordered lexicographically (with the smaller indices being the most significant).
For a tuple $s$ and index $y$, we let $s_{< y}$ be the tuple obtained from $s$ by restricting to coordinates with index $< y$. %Similar notations are used for $s_{< y}$
Edges are given by
\[
    s \re y s \quad \iff \quad \begin{cases}
        s_{< y} \geq s'_{< y} \text{ and $y$ is even; or}\\
        s_{\leq y} > s'_{\leq y} \text{ and $y$ is odd,}
    \end{cases}
\]
and $\eps$-edges are given by $s \re{\eps} s'$ if and only if $s \geq s'$.

\begin{lemma}[{\cite[Lemma~2.7]{CO24Arxiv}}]
The graph $S^\kappa_d$ is $(\kappa,\Parity_d)$-universal.
\end{lemma}

We will work extensively with such tuples, as well as their prefixes and suffixes.
For readability, we also use subscripts to indicate which (odd) coordinates are concerned, for instance $s_{<x}$ will be our notation for tuples of ordinals $< \kappa$ indexed with odd priorities $<x$, and similarly for $s_{>x}$.
Concatenation of tuples is written like for words, therefore $s_{<x} s_{>x}$ denotes a tuple indexed by all odd priorities (i.e. an vertex of $S_\kappa^d$).
We treat $s_{<x}$ and $s_{>x}$ as different variables, which we may quantify independently.
