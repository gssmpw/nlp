\section{Introduction}
\label{sec:intro}




%mixed reality is cool and growing in popularity. Apple Vision Pro. Want to ensure good user experience in the display.
%\jiasi{highlight that we see effect of acoustic on SLAM, not simple sensor fusion (Kalman?) like in Alfred Qi, not simple devices like in Injected}
Extended reality (XR) is growing in popularity, with recent or soon-to-be-released commercial headset prototypes from Apple, Meta, and Google.
XR seamlessly blends real and virtual content on the user's display, enabling a range of exciting applications in entertainment, healthcare, public safety, etc.
In light of these new devices and their sensing capabilities, securing XR devices is of increasing concern and has attracted recent attention from researchers and industry~\cite{lebeck2017securing,ruth2019secure,corbett2023bystandar,rajaram2023eliciting,rajaram2023reframe}.
%cite Meta grants, Duke prof's VR for children
Of particular interest are attacks that can cause issues with the user interface (UI), preventing users from interacting with UI elements or interfering with their perception of the physical world, for example by blocking the view of important real-world objects or generating auditory sounds to interfere with user attention ~\cite{cheng2024user,cheng2023exploring,lebeck2017securing}.

%disrupting the experience can have harmful effects (cite perceptual manipulation attacks)
%how to realize these effects? acoustic is a good vector
Implementing UI attacks is not easy, as often an in-band threat model is assumed (\eg a software library that has been compromised~\cite{cheng2023exploring}, or malware that has been accidentally installed from the app store~\cite{slocum2023going}).
Out-of-band attacks, including acoustic~\cite{trippel2017walnut,tu2018injected} or wireless signals~\cite{davidson2016controlling,gluck2020spoofing},
%cite Lidar object detection papers, Alfred Chen
can interfere with sensor readings and cause adverse downstream effects on smartphones and autonomous vehicles.
Acoustic attacks work because sound waves interact with springs in micro-electro-mechanical systems (MEMS) in the inertial measurement unit (IMU), causing incorrect readings of the accelerometer and gyroscope.
The adverse effects of acoustic attacks have been demonstrated on smartphones, drones, and other devices~\cite{son2015rocking,tu2018injected}.

%what we are doing, high level challenges
The hypothesis in this paper is that XR headsets rely on IMUs to display virtual content and therefore may also be susceptible to MEMS-driven acoustic attacks.
%should exhibit similar low-level perturbations to their sensor readings.
However, the full effects of attacks on the XR visualization are depend on the XR processing pipeline (shown in \Cref{fig:overview}), which ingests the perturbed sensor readings, processes them through a series of software algorithms, and finally outputs to the display.
%through a number of processing steps.
These data processing steps include pose estimation and XR game engines world generation and rendering (\eg Unity, Unreal).
The key question is whether the low-level sensor inputs can be  appropriately perturbed by the acoustic signals so that they impact the XR application layer, displaying visual outputs that hurt the user experience.

\begin{figure}
    \centering
    \includegraphics[width=0.25\textwidth]{figures/overview-crop.pdf} 
    \caption{Scenario overview. An XR headset is subjected to acoustic signals, which affects the pose estimation and final visual outputs.}
    \label{fig:overview}
\end{figure}

%detailed challenges
To answer this question and demonstrate real-world attacks, we had to overcome several challenges.
(1) \emph{Attack setting.}
We work with commercial-off-the-shelf (COTS) XR headsets and a non-invasive setup.
We did not assume access to the internals of the device, as in other works~\cite{trippel2017walnut}.
(2) \emph{XR processing pipeline.} 
Pose estimation using simultaneous localization and mapping (SLAM) methods is a key step in the XR processing pipeline. 
We characterize how the perturbed sensor inputs affect pose estimation under the relatively weak assumption of only one attacked sensor modality (IMU) alongside benign visual inputs, and under different implementations of SLAM tracking failure recovery methods.
(3) \emph{Impact on user experience.}
Naive application of acoustic injection attacks may have little impact on user experience if the attack occurs when there is no relevant virtual content.
We crafted four proof-of-concept application scenarios to showcase how acoustic injection could either help or harm user experience.
%There are interplay between low-level pose estimation (MRTK) and high-level pose estimates used by the application.

%main findings
% - Setup: Volume has to be loud enough. Position of speaker didn't matter. Headset has to be moving.
% - Why not WALNUT: No fine-grained control because of SLAM processing, binary effect.
% -  Open VINS (no re-init) vs ORB-SLAM3 (has re-init). Drones don't care as much about re-init, but AR's visual appearance changes.
% - Unity different from HL2SS pose?

The main findings of this work are that open-source pose estimation methods are susceptible to acoustic injection attacks, resulting in a variety of effects: ``misleading'' (the virtual content has a constant position offset), ``snapback'' (the virtual content resets its position) and ``drift away'' (the virtual content flies out of the field-of-view).
In closed-source commercial headsets, the ``snapback'' effect is reproducible in end-to-end attacks, as well as an additional ``small drift'' effect, and can be used to demonstrate beneficial or harmful effects to users in four scenarios: VR gaming, clickjacking, denial of user interaction, and destroying privacy zones.
We find that key factors impacting attack success rate are the volume and movement of the headset.
Taken together, these attacks illustrate that modern XR devices and their pose estimation methods are vulnerable to acoustic injection attacks.


In summary, this work explores how UI-level security attacks can be performed via a novel threat model: out-of-band acoustic injection.
The contributions of this work are:
\begin{itemize}
\item We evaluated COTS XR headsets (Microsoft Hololens 2 and Meta Quest 3) to determine their susceptibility to acoustic injection attacks.
\item To understand the impacts of acoustic injection attacks on individual stages of the XR processing pipeline, we performed controlled trace-driven simulations on open-source XR components (ILLIXR~\cite{huzaifa2022illixr} and ORB-SLAM3~\cite{campos2021orb}).
\item We perform end-to-end attacks on Hololens 2 and show how they can benefit or harm the user experience in four proof-of-concept scenarios. We also evaluate the effect of the physical configuration, such as acoustic volume, direction, and headset mobility on attack success.
\end{itemize}
The paper is organized as follows. \Cref{sec:related} discusses related work and \Cref{sec:prelim} describes the threat model and background on acoustic attacks. \Cref{sec:exp} describes our experiments with open-source XR frameworks and \Cref{sec:exp-hololens2} describes our end-to-end attacks on COTS headsets. \Cref{sec:discussion} discusses limitations and \Cref{sec:conclusions} concludes.



