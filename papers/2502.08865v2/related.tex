
\section{Related Work} \label{sec:related}

% \textbf{Adversarial Attack}
\textbf{Attacks on SLAM.} 
%With the rise of machine learning, 
The robustness of computer vision systems is being actively investigated. With the emergence of adversarial images in the digital domain by adding optimized noise directly to images~\cite{szegedy2013intriguing,carlini2017towards}, researchers find that such attacks also exist physically in the real world \cite{eykholt2018robust,song2018physical,zhao2019seeing}. To fill the gap between attacks in the digital and physical worlds, recent studies have demonstrated that attacks on real-world computer vision systems are practical \cite{eykholt2018robust,li2019adversarial,man2020ghostimage,sharif2016accessorize,zhao2019seeing,zhou2018invisible}. However, attacks on traditional computer vision methods such as SLAM are relatively less explored. \cite{yoshida2022adversarial} proposes an attack against the scan matching algorithm in LiDAR-based SLAM, while most SLAMs in AR/VR devices rely on different sensors like RGB/depth cameras and IMUs. \cite{ikram2022perceptual} and \cite{chen2024adversary} mislead visual SLAM by poisoning the images with special patterns, and \cite{wang2021can} causes the camera to fail using infrared light. In our work, we demonstrate attacks on Visual-Inertial SLAM (VI-SLAM) by perturbing the IMU readings, rather than cameras, and showing its impact on XR user experience. 

\textbf{Acoustic Injection Attacks.} Among various physical attacks, acoustic injection attacks are attractive due to their low cost. Son~\etal~\cite{son2015rocking} were the first to introduce acoustic attacks on MEMS gyroscopes, demonstrating how these attacks could lead to sensor denial-of-service and result in drone crashes. WALNUT~\cite{trippel2017walnut} expanded on this by developing output biasing and control attacks that enable precise manipulation of MEMS accelerometer outputs using modulated sound waves. Wang et al.~\cite{wang2017sonic} demonstrated a sonic gun, showcasing the vulnerability of various smart devices (\eg drones and self-balancing vehicles) to acoustic attacks. Tu et al. \cite{tu2018injected} designed side-swing and switching attacks to alter the outputs of MEMS gyroscopes and accelerometers. Furthermore, Ji et al. \cite{ji2021poltergeist} fool the object detectors by applying acoustic attack to the image stabilizers commonly used in modern cameras. However, none of the existing works study the relationship between the acoustic injections and SLAM outputs on recent XR devices. 

% \zijian{Do we need one session about security in AR/VR?}
% \yicheng{TODO}
%\jiasi{cite the AIVR paper (UMass Amherst?) paper is we have not already. They add IMU perturbation but w/o SLAM, iirc} \yicheng{Cited}

\textbf{XR Security and Privacy.} 
%Security and privacy concerns in XR systems have gained significant attention. 
For single-user XR systems, researchers have demonstrated various side-channel attacks to extract sensitive information (\eg keystrokes) through video feeds~\cite{ling2019know}, head movements~\cite{nair2023unique, slocum2023going}, architectural hints~\cite{zhang2023its,shang2020arspy}, power usage~\cite{li2024dangers}, and EM side-channel leakages~\cite{al2021vr}. In multi-user XR systems, Su et al.~\cite{su2024remote} use avatar motion data to infer keystrokes in shared VR environments. Slocum et al.~\cite{slocum2024doesn} reveal vulnerabilities in the shared state frameworks of multi-user AR. Similarly, Lebeck et al.~\cite{lebeck2017securing} highlight risks like deceptive virtual objects and emphasize access control for managing shared physical and virtual spaces. Ruth et al.~\cite{ruth2019secure} further propose a secure multi-user AR framework focusing on content sharing and permissions.
Chandio et al.~\cite{chandio2024stealthy} %introduced a multi-modal spatiotemporal attack that 
simultaneously manipulated visual and inertial sensors to disrupt XR pose estimation. However, their study evaluated the attack using offline datasets and assumed the attacker's capability to manipulate IMU data streams through acoustic means, without real experiments. Ours is the first to demonstrate acoustic injection attacks on recent XR devices, like the Hololens 2, in the real world.
 

