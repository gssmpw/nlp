We evaluate TAP by verifying the effectiveness of cross-entropy in learning optimal thresholds, comparing extracted SDL label accuracy with two baselines, and demonstrating TAPâ€™s ability to identify unique trajectories in the data.

\subsection{Dataset and Preprocessing}
\input{womd}

% For this paper, we use the Waymo Open Motion Dataset (WOMD)~\cite{WOMD_2021,WOMD_2024} as the dataset of scenarios $S$.
% WOMD contains 574 hours of vehicle data across 486,995 scenarios. 
% Each scenario $S_i$ provides a list of all of its vehicles $V^i_j$, as well as the state of the vehicle $\{x,y,v,\phi\}$ comprising position $x,y$ of the vehicle in map frame, its velocity $v$ in m/s, and its heading $\phi$ in radians.
% Vehicle states are recorded at 10 Hz over a duration of $T = 9.0$ seconds for every scenario.

% From the state values $\{x,y,v,\phi\}$ provided by WOMD, the full state vector $s = \{x,y,v,a,\phi,\omega\}$ is created.
% The acceleration values $a$ are derived from the difference in velocity at each time step $t$.
% Yaw rate $\omega$ is similarly derived from heading $\phi$.
% % The scenarios in the Waymo Open Motion Dataset do not include acceleration or yaw rate, the remaining components of trajectory $\tau$.
% % Instead, these values are derived from velocity and heading respectively.
% % The acceleration values are calculated as difference in velocity over the time $a_t = \frac{v_t-v_{t-1}}{T_t-T_{t-1}}$, starting at $t=1$.
% % Since this would make our acceleration vector shorter than the rest of the trajectory by 1 time step, we set our initial acceleration as $a_0 = a_1$.
% % Yaw rate is calculated similarly from heading as $\omega_t = \frac{\phi_t-\phi_{t-1}}{T_t-T_{t-1}}$.
% To reduce the impact of outliers, yaw rate, acceleration, and velocity are smoothed using a 1-second sliding window average.

% Each vehicle state vector has transformations applied to give every vehicle the same initial conditions.
% The position $x,y$ is translated to begin at the origin, and the trajectory is rotated to have an initial heading $\phi = 0$ radians.
% Giving every vehicle the same initial conditions allows trajectories to be compared fairly.
% % Giving every vehicle the same initial conditions allows the divergence of trajectories to be measured by traditional trajectory distance metrics such as ADE.

% At this point, we have the full state vector $s = \{x,y,v,a,\phi,\omega\}$ with the same initial position $x,y$ and heading $\phi$ for every vehicle $V^i_j$.
% From the acceleration $a$, velocity $v$, and yaw rate $\omega$ in the state vector, the distributions $D_a$, $D_v$, and $D_{\omega}$ can be constructed as described in Section~\ref{sec:problem_threshold}.
% The yaw rate distribution $D_{\omega}$, only includes samples where the vehicle is moving as stopped vehicles do not exhibit lateral behavior.
% For each distribution, Figure~\ref{fig:cem_results}-a shows the number of samples and the spread of the distribution.
% For example, the acceleration distribution $D_a$ shown in the top plot contains 126,501 1-second averaged samples, with over half of the samples lying within 0.1 m/s$^2$ of 0.
% The velocity distribution $D_v$ and yaw rate distribution $D_{\omega}$ similarly have the majority of samples near 0.
% With the distributions $D_a$, $D_v$, and $D_{\omega}$, we have all of the inputs necessary for automatic threshold computation.

\subsection{Result 1 - Automated Threshold Optimization}
\input{sections/result1_mb}

% Having populated the trajectories for each vehicle, we turn to solving the problem of determining the thresholds that balance the partitions in our data.
% Although we want these thresholds to be based in the data for flexibility, some require outside domain knowledge to be accurate.
% % While we prefer to let the thresholds be based on the data, some require domain knowledge to remain accurate.
% The velocity threshold of $\theta_{v,\text{stop}}$ is used to partition vehicles that are not moving.
% Raw sensor data contains some noise, this threshold must be higher than 0, if it gets too high it will partition vehicles that are obviously moving as being stopped.
% To prevent the cross-entropy method from raising this value too high, we manually set the threshold $\theta_{v,\text{stop}} = 0.1$ m/s.
% % For the threshold $\theta_{merge}$, it is hard to detect through the cross entropy method what constitutes a Merge versus making two turns.
% % Instead, we manually searched through samples containing both directions of turns. We found that no sample above $\theta_{merge} = 400$ ms represented a Merge, and set the threshold there accordingly.

% The remaining thresholds in $\Theta$ are determined using the cross-entropy method.
% % We start by taking our vehicle trajectories, and splitting them into 1 second segments. We use 1 second as our interval because 1 second represents the shortest allowable action, as discussed in Section~\ref{sec:sdl}.
% We start by splitting our vehicle trajectories into 1 second segments and taking the average acceleration, velocity, and yaw rate to create the data distributions $D_a$, $D_v$, and $D_{\omega}$.
% For the yaw rate data in $D_{\omega}$, we reject data where the vehicle is stopped, as the vehicle is not making any lateral maneuvers and stopped data skews the representation.
% These data distributions containing 1-second averages are the input data for the cross-entropy method.

% \begin{table}
% \centering
% \begin{tabular}{ |c|c|c| }
%  \hline
%  Objective & $\epsilon$ & $\eta$ \\
%  \hline
%  $J(\Theta_{a})$ & 0.05 & 0.05 \\
%  $J(\Theta_{v})$ & 0.05 & 0.2 \\
%  $J(\Theta_{\omega})$ & 0.005 & 0.01 \\
%  \hline
% \end{tabular}
% \caption{The hyper-parameters $\epsilon$ and learning rate used for each category of the cross-entropy method.}
% \label{table:hyperparameters}
% \end{table}

% To run cross-entropy, an initial threshold value is necessary to seed the method.
% To find these initial seeds, we examined our data distribution to choose initial values that seemed close to an even distribution.
% To avoid having our initial seeds be biased by our assumptions and to avoid the cross-entropy method falling into a local minimum, we chose three different initial values for each threshold.
% Figure~\ref{fig:cem_results}-a shows the data distribution for each of acceleration, velocity, and yaw rate and the initial seeds. The initial seeds are also listed in Table~\ref{table:threshold_results}.

% \begin{figure*}
%     \centering
%     \includegraphics[width=\linewidth]{figures/CEMResults.pdf}
%    \caption{(a) Data distributions with initial seeds shown as dotted lines. (b) Initial subcategory averages for each seed. (c) Objective function  $J(\Theta)$ convergence per epoch. (d) Final subcategory averages after optimization; some skew remains due to inherent data imbalances, but all seeds converge to the same thresholds}
%     \label{fig:cem_results}
% \end{figure*}

% The hyper-parameters that were used for the cross-entropy method vary between our categories of acceleration, velocity, and yaw rate, and are listed in Table~\ref{table:hyperparameters}.
% Figure~\ref{fig:cem_results}-b shows the data distribution for our initial seeds.
% In order to be balanced, all of the bars for a single seed should be the same height. For example, if all of the red bars are equally high, the partitions are balanced for that seed.
% We ran the cross-entropy method for each initial seed for 100 epochs.
% The objective function $J(\Theta)$ is shown in Figure~\ref{fig:cem_results}-c.
% The acceleration and yaw rate data both converge to their final thresholds at a consistent rate.
% The velocity data for Seed 1 takes longer to converge due to a section of data that is almost a local minima. In order to overcome this local minima, the learning rate was increased, resulting in slightly more uncertainty in the final values.

% % After 100 epochs, we chose the threshold that had the highest similarity in distribution, calculated as the lowest $g(\Theta)$.
% After 100 epochs, we chose the threshold that had the lowest value of $J(\Theta)$, meaning it had the most balanced partitions.
% Figure~\ref{fig:cem_results}-d shows the data distribution for our final seeds.
% The final average pairwise distance for each partition is similar for each seed.
% This indicates that all seeds are converging to the same final value.

% Table~\ref{table:threshold_results} reports value of $g(\Theta)$ for the final thresholds.% and the difference between the lowest and highest value of $g(\Theta)$ between the three initial seeds. 
% Each final value falls between the initial values of Seed 1 and Seed 3.
% This indicates that the thresholds that best partition the data are between these values.
% Given that all seeds converge to the same final value, this implies that the threshold values found by the cross-entropy method are the thresholds that best partition the data.

% % \begin{table}
% % \centering
% % \begin{tabular}{ |c|c|c|c|c| }
% %  \hline
% %  Threshold & Seed 1 & Seed 2 & Seed 3 & Final Value \\
% %  \hline
% %  $\Theta_{a,\text{dec}}$ & -0.5 & -1.0 & -2.0 & -1.3715 \\
% %  $\Theta_{a,\text{acc}}$ & 0.5 & 1.0 & 2.0 & 1.5557 \\
% %  \hline
% %  $\Theta_{v,\text{slow}}$ & 7.0 & 10.0 & 12.0 & 10.2140 \\
% %  $\Theta_{v,\text{med}}$ & 22.0 & 24.0 & 26.0 & 24.4046 \\
% %  \hline
% %  $\Theta_{\omega,\text{str}}$ & 0.01 & 0.02 & 0.05 & 0.0283 \\
% %  $\Theta_{\omega,\text{grad}}$ & 0.05 & 0.07 & 0.1 & 0.0754 \\
% %  $\Theta_{\omega,\text{med}}$ & 0.1 & 0.15 & 0.2 & 0.1541 \\
% %  \hline
% % \end{tabular}
% % \caption{The initial seeds and final values for each threshold. In each case, Seed 1 and Seed 3 are on either side of the final threshold. This implies that the final thresholds calculated by the cross-entropy method are the ones that best partition the data.}
% % \label{table:threshold_results}
% % \end{table}

% \begin{table}
% \centering
% \renewcommand{\arraystretch}{1.3}
% \begin{tabular}{ |l|c|c|c|c| }
%  \hline
%  \rowcolor[gray]{0.9} \textbf{Threshold} & \textbf{Seed 1} & \textbf{Seed 2} & \textbf{Seed 3} & \textbf{Final Value} \\
%  \hline\hline
%  \multicolumn{5}{|c|}{\textbf{Acceleration Thresholds}} \\
%  \hline
%  $\theta_{a,\text{dec}}$ & -0.5 & -1.0 & -2.0 & -1.3715 \\
%  $\theta_{a,\text{acc}}$ & 0.5 & 1.0 & 2.0 & 1.5557 \\
%  \hline
%  \multicolumn{5}{|c|}{\textbf{Velocity Thresholds}} \\
%  \hline
%  $\theta_{v,\text{slow}}$ & 7.0 & 10.0 & 12.0 & 10.2140 \\
%  $\theta_{v,\text{med}}$ & 22.0 & 24.0 & 26.0 & 24.4046 \\
%  \hline
%  \multicolumn{5}{|c|}{\textbf{Yaw Rate Thresholds}} \\
%  \hline
%  $\theta_{\omega,\text{str}}$ & 0.01 & 0.02 & 0.05 & 0.0283 \\
%  $\theta_{\omega,\text{grad}}$ & 0.05 & 0.07 & 0.1 & 0.0754 \\
%  $\theta_{\omega,\text{med}}$ & 0.1 & 0.15 & 0.2 & 0.1541 \\
%  \hline
% \end{tabular}
% \caption{
% Initial seed values and final optimized thresholds for each category. 
% The final values were derived using the cross-entropy method, which identified the thresholds that best partition the data. 
% Seed values were chosen to bracket the optimal threshold.
% }
% \label{table:threshold_results}
% \end{table}

% To show that the final thresholds provide more balanced partitions than the inital seeds, we look at a representative sampling of the acceleration data distribution $D_a$.
% For each partition of Decelerate, Maintain Speed, and Accelerate, we choose 50 samples uniformly from the partition.
% We then plot the difference between the samples and the mean value of the partition as a heatmap in Figure~\ref{fig:heatmap}, where green indicates the sample is close to the mean and red indicates it is far.
% The top row of the heatmap shows the distance to the mean for the initial seed $\Theta_{a,dec} = -2.0,\Theta_{a,acc} = 2.0$, and the bottom row shows the distance to the mean for the final thresholds.
% The final thresholds increase the amount of data within the Decelerate and Accelerate subcategories that is near to the mean, shown by having more green samples. 
% The cross-entropy method brought those two subcategories closer in distribution to the Maintain Speed subcategory, validating the results shown by the histogram in Figure~\ref{fig:cem_results}-d.

% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{figures/heatmap.pdf}
%     \caption{The distribution of our acceleration data plotted as a heatmap. Each bar represents a single sample, chosen uniformly from the indicated partition. The color is determined by the difference between the acceleration of the sample and the average acceleration of the partition. The distribution for the initial seed $\Theta_{a,dec} = -2.0,\Theta_{a,acc} = 2.0$ is shown on the top row, and the distribution for the final thresholds on the bottom. The heatmap of the final thresholds show partitions that include more samples that are closer to the mean. This validates the conclusion that the thresholds found by the cross-entropy method produce more balanced partitions than the initial seeds.}
%     \label{fig:heatmap}
% \end{figure}

\subsection{Result 2 - SDL Similarity Search}
\input{sections/result2_mb}
\label{sec:result2}
% Using the thresholds obtained in Result 1, we use TAP to extract SDL labels for each sample, as described in Section~\ref{sec:methodology_tap}.
% Next we calculate the distance between the SDL labels to find similar trajectories.
% % For each scenario, we then found the set of most similar scenarios in our dataset using the method described in Section~\ref{sec:sdl_distance_methods}.
% Here, we consider two trajectories to be similar only if they have the same label, as discussed in Section~\ref{sec:problem_sim}.
% Therefore, we use the distance function
% \begin{equation}
%     g_{\text{SDL}}(L_{\text{ref}},L^i_j) =
%     \begin{cases}
%         0 & L_{\text{ref}} = L^i_j \\
%         1 & \text{Else}
%     \end{cases}
% \end{equation}
% Comparing SDLs using a more complex distance function based on edit distance is left as future work.

% We compare the set of most similar SDL Labels against the most similar trajectory calculated using Average Displacement Error (ADE).
% ADE is computed as the average distance between each pair of positions in the trajectory:
% \begin{equation}
%     g_{\text{ADE}}(\tau_{\text{ref}},\tau^i_j) = \frac{\sum^T_{t=0}\sqrt{(x^{\text{ref}}_t-x^j_t)^2+(y^{\text{ref}}_t-y^j_t)^2}}{T}
% \end{equation}
% For each trajectory, we begin by moving the start of the trajectory to the origin, and rotating its heading to 0 radians.
% This gives every trajectory the same starting circumstances.
% Since ADE requires that the trajectories be the same length to calculate their distance, we also resample trajectories to be the same length.

% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{figures/SimSearchResults.pdf}
%     \caption{The set of trajectories with similar SDL Labels to a baseline trajectory shown in blue. The trajectory with the lowest ADE distance to the baseline is shown in red. The top two plots show cases where the most similar ADE trajectory is included in the set of most similar SDL Labels, because they have the same label. The remaining plots show cases where the lowest ADE trajectory does not have a similar SDL Label, showing the limitations of ADE.}
%     \label{fig:simsearch_results}
% \end{figure}

% Figure~\ref{fig:simsearch_results} shows 6 example reference trajectories in blue, along with the nearest trajectory by ADE distance in red.
% When the nearest ADE trajectory is included in the set of similar SDL labels, it is plotted with dots; when it is not included, it is plotted with x's.
% The gray trajectories represent those identified as belonging to the set of similar SDL labels.

% Of the 25889 trajectories, 17975 samples (69.4\%) contain the nearest ADE trajectory in the set of similar SDL labels.
% Figure~\ref{fig:simsearch_results}-top shows two samples where the ADE trajectories has a similar SDL label.
% The top-left sample shows the reference trajectory making an Aggressive Left Turn followed by a Straight laterally, while longitudinally it Maintains Slow Speed before Accelerating from Slow Speed to Medium Speed.
% Each of the other samples in the set of similar SDL labels clearly show this same behavior, even though the durations of the turns last for differing amounts of time.

% The top-right sample shows a Gradual Left Turn followed by a Straight, while Maintaining Medium Speed.
% Like the top left sample, the trajectories with similar SDL labels being show similar behavior to the reference even if their paths diverge slightly.

% We also analyzed samples where the nearest ADE trajectory is not included in the set of similar SDL labels to understand why they do not agree.
% The middle and bottom samples in Figure~\ref{fig:simsearch_results} show examples of these metrics disagreeing.
% Looking at the middle-left sample, we see that the position values are close to those of our reference, but they are failing to capture the behavior.
% The nearest ADE trajectory following the path of the reference quite well, but the reference makes a Gradual Left Turn that the nearest ADE trajectory does not perform.
% The samples that are similar in SDL distance do not overlap as well in position, but clearly show the same turn behavior as the reference.

% The remaining samples in Figure~\ref{fig:simsearch_results} show similar results.
% In the middle-right sample, the nearest ADE trajectory follows the path of the reference, but does not exhibit the same turning behavior.
% The bottom-left sample shows the ADE trajectory following the lateral actions of the reference very closely, but it fails to have the same longitudinal behavior.
% The bottom-right sample similarly shows another ADE trajectory that does not contain the same longitudinal behavior despite having the a very close position.

% These samples show the problem with using ADE to determine similar vehicle behavior.
% It prioritizes having trajectories that have very close positions, even if they do not have similar behavior.
% Additionally, the requirement of having trajectories have the same length leads to resampling which removing longitudinal information.

\subsection{Result 3 - Unique Behaviors}
\input{sections/result3_mb}
% In addition to locating similar vehicle behavior, we also use the distance between SDL labels to automatically identify unique behavior.
% Out of our 25889 vehicles, 395 samples (1.5\%) did not have any other trajectory with the same label.
% These represent unique behaviors, indicating scenarios of interest for further analysis of what caused this behavior.

% Figure~\ref{fig:unique_results} shows two samples that had unique SDL labels.
% The left sample shows a vehicle moving into a turn lane before making a right turn, slowing down as it does.
% This sample has a unique label because of the number of actions in the label. Over 95\% of lateral and longitudinal labels have 2 or fewer actions.
% This sample has 5 lateral actions and 3 longitudinal, making it unique.

% The right sample in Figure~\ref{fig:unique_results} shows a vehicle making a lane change while speeding up.
% This again is a unique label because of the number of actions contained within it.
% These samples are unique due to the infrequency of labels with a high number of actions.
% If more data were to be analyzed, there would be more labels with many actions, and it becomes more likely that these labels would have a match somewhere in the data.
% Regardless, these samples show that SDL labels can be used to automatically find unique behaviors in the data.


