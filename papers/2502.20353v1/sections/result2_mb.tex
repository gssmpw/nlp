We use TAP to extract SDL labels for each trajectory, as outlined in Section~\ref{sec:methodology_tap}. 
The objective of SDL similarity search is to find trajectories with similar behaviors by measuring the distance between their respective SDL labels.
We use the distance function $g_{\text{SDL}}(L_{\text{ref}},L^i_j) = 0$ if $L_{\text{ref}} = L^i_j$, and $g_{\text{SDL}}(L_{\text{ref}},L^i_j) = 1$ otherwise, which considers two trajectories similar if they share the same SDL label.
Other distance metrics, such as Levenshtein distance, could also be used for comparing SDL labels.
% To evaluate the effectiveness of SDL-based similarity, we compare TAP against a traditional trajectory distance metric - the Average Displacement Error (ADE). 
% ADE, which is widely used in trajectory prediction and synthesis for autonomous driving, measures the positional difference between trajectories by averaging the Euclidean distances between each pair of corresponding points.
% To evaluate the effectiveness of SDL-based similarity, we compare TAP against Average Displacement Error (ADE) and Dynamic Time Warping (DTW). \hl{why}
WOMD trajectories do not contain ground truth labels for similarity, therefore, we compare TAP's SDL-labels against two commonly used trajectory similarity metrics, Average Displacement Error (ADE)~\cite{ADE_similarity1,ADE_similarity2} and Dynamic Time Warping (DTW)~\cite{DTW_similarity1,DTW_similarity2}.
These metrics are used to compare distance between trajectories in autonomous driving prediction, measuring similarity through the Euclidean distances between corresponding points along trajectories.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/SimSearchResults2.pdf}
    \caption{Trajectories with similar SDL labels to the reference (magenta). The trajectory with the lowest ADE is shown in dark blue, and lowest DTW in light blue. Red labels indicate extra actions, while underlined labels indicate missing actions. 
    Vehicle velocity plots are shown on the right. Additional similarity examples are included in Appendix~\ref{sec:appendix_more_sim_results}.}
    \label{fig:simsearch_results}
\end{figure}

% Figure~\ref{fig:simsearch_results} shows the comparison between TAP and both baseline similarity metrics for a few examples from our dataset.
% Each plot shows the reference trajectory $S^L_{\text{ref}}$ in magenta, the trajectory with the lowest ADE in dark blue, and the trajectory with the lowest DTW in light blue. 
% Since ADE and DTW measure only geometric similarity and cannot generate SDL labels, we also show the SDL labels from TAP for each trajectory in each example.
% The gray trajectories represent all those which are returned by TAP as being similar to the reference trajectory. 
Figure~\ref{fig:simsearch_results} demonstrates TAP’s effectiveness in identifying behaviorally similar trajectories compared to baseline metrics. 
Given a reference trajectory  $S^L_{\text{ref}}$ (magenta), TAP retrieves all scenarios with matching SDL labels (gray). 
The most similar trajectories identified by ADE (dark blue) and DTW (light blue) are also shown, along with TAP’s SDL labels for those trajectories.
In Figure~\ref{fig:simsearch_results} example \circled{1}, the lateral motion of the reference trajectory includes a gradual left turn (triangular marker) followed by straight (circular marker) and the longitudinal behavior is at medium speed. 
This is an example where trajectories returned by both ADE and DTW also match this behavior, yielding trajectories with the same SDL labels as TAP.
% Example \circled{1} in this Figure shows a reference trajectory making an aggressive left turn followed by straight movement while maintaining slow speed before accelerating. 
% The TAP-extracted SDL labels correctly capture this behavior, as does the lowest ADE trajectory.
However, examples \circled{2} and \circled{3} reveal cases where ADE and DTW fail to capture key behaviors. 
In \circled{2}, both baseline methods miss the turning behavior in the reference trajectory, while TAP identifies trajectories with similar behavior despite slight spatial differences. 
In \circled{3}, ADE and DTW match the lateral SDL label but fail to capture the longitudinal behavior in acceleration, highlighting TAP’s superior accuracy in comparing similar trajectories. 
% The ability of TAP to accurately retrieve behaviorally similar trajectories ensures more reliable validation of AV behaviors, which is essential for safety assessments.
% Again, trajectories with the same TAP-extracted labels show the same behavior, further validating the choice to optimize thresholds for balanced partitions.
For empirical comparison, we conducted similarity searches on 25,889 trajectories. 
ADE failed to retrieve behaviorally similar trajectories for 7,924 samples $(30.56\%)$, often selecting spatially close trajectories with differing behaviors. 
DTW exhibited similar issues, with 6,246 cases $(24.13\%)$ failing to match the reference’s behavior.
These examples demonstrate the limitations of using traditional metrics for behavior-based similarity searches. 
ADE and DTW focus only on spatial proximity, which can miss critical driving behaviors. 
% In contrast, TAP’s SDL-based approach excels in identifying behaviorally similar trajectories, enabling more reliable comparisons crucial for robust AV testing and real-world scenario evaluation.
In contrast, TAP’s SDL-based approach excels in identifying behaviorally similar trajectories, enabling more reliable comparisons for robust AV testing and real-world scenario evaluation.
While this result focuses on comparing one trajectory at a time, our ongoing work extends this to multiple trajectory comparisons, enabling scenario-level analysis for more comprehensive behavior evaluations.

\begin{comment}
\begin{table}[b]
\centering
\begin{tabular}{ |c|c| }
 \hline
 % Method & Time \\
 Method & Time \\
 \hline
 TAP & 3831 ms \\
 ADE & 302 ms \\
 DTW & 2096 ms \\
 \hline
\end{tabular}
\caption{The computation time to compare a reference trajectory against 1,000 other samples.}
\label{table:time_results}
\end{table}
\end{comment}

\noindent \textbf{Computation Time:} Although TAP is designed as an offline method, its execution time compares as follows: for 1,000 trajectory comparisons, TAP takes 3,831 ms, ADE 302 ms, and DTW 2,096 ms on a 2.1 GHz Intel Xeon (8 cores). TAP spends only 3 ms on comparisons, with 3,828 ms allocated to label generation.
Since the comparison time increases at $O(n^2)$ and the generation of labels at $O(n)$, the relative efficiency of TAP improves with larger datasets.