\section{User and \abr{LLM} Expertise}\label{expertise}
Using the labels described in \cref{exp_label}, we compute the user expertise, the agent expertise, and the gauged user expertise on our set of $25,033$ conversations and present the distributions of these expertise labels across different domains in \autoref{fig:user_dist}, \autoref{fig:ai_dist} and \autoref{fig:gauged_user_dist} respectively. 

Overall, we observe that a majority of the users ($63.9\%$) are labeled as ``Novice'' on our ordinal scale, with a small number of users being classified as ``Proficient'' ($5.2\%$) or ``Expert''($1.6\%$). These small numbers of ``Proficient'' and ``Expert'' users occur in the more technical domains (like Programming and scripting) as compared to the non-technical domains (like Entertainment).

We also see that, in a majority of the cases, the \abr{LLM} gets labeled as ``Proficient''($34.9\%$) or ``Expert''($42.4\%$). Once again, we observe the number of ``Proficient'' and ``Expert'' labels to be fewer for non-technical domains as compared to the technical domains. Overall, \autoref{heatmap_size} shows that the user has a lower expertise than the \abr{LLM} in a majority ($80.1\%$) of the conversations. This makes sense in that most users are likely to be non-experts, while the model should have higher expertise in order to provide value to the user.

Finally, for the gauged user expertise (\autoref{fig:gauged_user_dist}), we observe that a majority of the users are labeled as ``Intermediate''($37.2\%$) or above. Comparing this finding with the User Expertise label distribution (\autoref{heatmap_size}) indicates that there are cases of user overestimation, in which user expertise as gauged by the response from the \abr{LLM} is higher than when directly assessing user expertise ($57.4\%$ of conversations), and user underestimation, in which gauged expertise is lower than the user expertise ($4.23\%$ of conversations). We also test our expertise classifier on a sample of WildChat \cite{zhao2024wildchat1mchatgptinteraction} conversations in Appendix \ref{wildchat}, where we observe a similar distribution of labels, hence demonstrating the generalisability of our expertise classifier. 