\section{Impact on User Experience}\label{impact_experience}
%We hypothesize that the expertise misalignment between the user and the \abr{LLM} and under- and over-estimation of the user expertise can hurt the overall user experience. 
%We look at the relationship between expertise alignment and the following three metrics:
\begin{figure*}[ht!]
    \centering
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{figures/piecewise_regression_user_ai_new.pdf}
        \caption{}
        \label{fig:pc_reg_user_ai}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{figures/piecewise_regression_user_gauged_new.pdf}
        \caption{}
        \label{fig:pc_reg_user_gauged}
    \end{subfigure}
    \caption{Piecewise regression plots showing the correlation between Expertise Difference and \abr{SAT} scores.}
\end{figure*}

To understand how expertise (mis)alignment impacts the user experience, we do the following:

First, we fit a piecewise regression of the difference between user and \abr{LLM} expertise on user satisfaction. \autoref{fig:pc_reg_user_ai} shows that when the user expertise exceeds the \abr{LLM} expertise, there is a negative impact $(R^{2}=0.11, p=1.36E^{-141})$ on the \abr{SAT} score, with the overall \abr{SAT} score becoming negative in absolute terms once the user is one level more expert than the \abr{LLM}. Increasing gaps in user expertise over \abr{LLM} expertise are associated with continually lower user satisfaction scores.
~\autoref{heatmap_sat} also highlights that it is preferable for the \abr{LLM} to be quite expert regardless of the user's level of expertise, with lower than ``Proficient'' responses from the \abr{LLM} generally leading to decreased user \abr{SAT} scores. Further, underestimating the user's expertise level (\autoref{fig:pc_reg_user_gauged}), as measured by gauged user expertise, has a clear negative impact $(R^{2}=0.03, p=1.06E^{-26})$ on the \abr{SAT} score, also highlighted in \autoref{heatmap_sat}.

The nature of the user's task may impact the effect of expertise (mis)alignment, and we operationalize one aspect of this with the task complexity measure. We fit linear regressions of the gap in user to \abr{LLM} expertise on user satisfaction separately for conversations with low versus high complexity tasks, with high and low task complexity defined as in \cref{user_exp_metrics}. As seen in \autoref{fig:binary_comp_user_ai}, for low complexity tasks, the user-\abr{LLM} expertise gap had essentially no effect on user satisfaction ($r=-0.04$), while for high complexity tasks, this effect was of medium effect size ($r=-0.29$). The effect of user expertise underestimation as reflected in the gap between actual and gauged user expertise (\autoref{fig:binary_comp_gauged}) shows a similar if somewhat moderated trend with no effect ($r=0.02$) for tasks of low complexity and a small effect for tasks of high complexity ($r=-0.15$) .

%For the correlations between SAT scores and high- and low-complexity tasks for User vs Agent Expertise, the p-values were computed to be $0.0$ and $0.005$ respectively. For User vs Gauged User Expertise, the p-value for high- and low-complexity tasks was computed to be $1.77E^{-97}$ and $0.13$ respectively. As for the correlation coefficients, for the correlations between SAT scores and high- and low-complexity tasks for User vs Agent Expertise, the correlation coefficients were computed to be $r=-0.04$ (low complexity tasks) and $r=-0.29$ (high complexity tasks) respectively. For User vs Gauged User Expertise, the correlation coefficients for high and low complexity tasks was computed to be $r=0.02$ and $r=-0.15$ respectively. 

%These support the statistical significance for our findings, and that the impact of expertise misalignment is more important for high complexity tasks (medium effect size for the user-agent correlation) than for lower complexity tasks (essentially no effect). 

Finally, turning to the impact of user-\abr{LLM} (mis)alignment on user engagement, \autoref{heatmap_turn_words} shows that the amount of engagement, as defined in \cref{user_exp_metrics}, increases along with the level of user expertise. That is, more expert users tend to have longer conversations. This effect appears to depend on the level of expertise of the \abr{LLM}, however, such that users at each level of expertise tend to engage more when the \abr{LLM} responds at a similar level of expertise. ``Proficient'' and ``Expert'' users tend to engage relatively more with a Proficient or Expert \abr{LLM}, while ``Novice'' and ``Beginner'' users tend to engage more with a Novice or Beginner \abr{LLM}. Thus while the user satisfaction measure suggests that users prefer a more expert \abr{LLM}, they engage more with \abr{LLMs} of commensurate expertise.