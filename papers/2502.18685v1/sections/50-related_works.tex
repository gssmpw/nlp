\section{Related Works}
The term ``expertise'' has been defined along multiple dimensions \cite{bourne2014expertise, garrett2009six}, such as the ``extent and organization of knowledge and special reasoning processes to development and intelligence'' \cite{feltovich1997expertise}. Traditionally, expertise has always been correlated with knowledge, skill and other cognitive concepts \cite{bourne2014expertise}. Building upon this idea, \citet{desmarais1995user} introduced a probabilistic approach to model user expertise, and \citet{dialogue_expertise} did so in a dialogue based setting. Different methods like heuristic rules \cite{vaubel1990inferring} have also shown promise in inferring expertise for word processing tasks. Notably, we model the user, agent and the gauged user expertise from conversational data to show the impacts of expertise mis-alignment on the user interaction experience. 

Additionally, many works have explored how \abr{LLMs} are mis-aligned with humans across an axis of different dimensions like moral judgements \cite{hendrycks2023aligningaisharedhuman, jiang2022machineslearnmoralitydelphi}, cultural and societal norms \cite{palta-rudinger-2023-fork, acquaye-etal-2024-susu, naous2024havingbeerprayermeasuring, bhatia-shwartz-2023-gd, huang-yang-2023-culturally}, healthcare \cite{levy-etal-2024-evaluating} and notions of plausibility \cite{palta-etal-2024-plausibly}. Similarly, we show that \abr{LLMs} are misaligned with humans along notions of expertise, which can lead to unsatisfactory user experiences. 