\vspace{-5pt}
\section{Introduction}\label{sec:intro}

In the era of big data and AI \cite{ban2021ee,ban2023neural,qiu2024ask}, multi-sourced networks\footnote{In this paper, we use the terms `network' and `graph' interchangeably.} appear in a wealth of high-impact applications, ranging from social network analysis~\cite{yao2014dual, cao2017joint,xuslog,yan2024thegcn}, recommender system~\cite{fu2024vcr,liuclass,fu2024parametric} to knowledge graphs~\cite{wang2018acekg, wu2019relation,wang2023noisy,li2024apex}.
Network alignment, the process of identifying node associations across different networks, is the key steppingstone behind many downstream multi-network and Web mining tasks.
For example, by linking users across different social network platforms, we can integrate user actions from multi-sourced sites to achieve more informed and personalized recommendation~\cite{yao2014dual, yan2024pacer, crossmna}. 
Aligning suspects from different transaction networks helps identify financial fraud~\cite{moana,nextalign,du2021new,yan2024topological}.
Entity alignment between incomplete knowledge graphs, such as Wikipedia and WorkNet, helps construct a unified knowledge base~\cite{wu2019relation, chen2016multilingual, yan2021dynamic}.

Many existing methods approach the network alignment problem by learning low-dimensional node embeddings in a unified space across two networks.
Essentially, these methods first adopt different sampling strategies to sample positive and negative node pairs, and then utilize a ranking loss, where positive node pairs (e.g., anchor nodes) are pulled together, while negative node pairs (e.g., sampled dissimilar nodes) are pushed far apart in the embedding space, to model cross-network node relationships~\cite{ione, crossmna, bright, nextalign}.
For example, as shown in Figure~\ref{fig:sampling}, the relationship between anchor node pair $(a_1,a_2)$ is \textit{directly} modeled by minimizing their distance $d(a_1,a_2)$ in the embedding space, while the relationship between $(b_1,b_2)$ is depicted via an \textit{indirect} modeling path $d(b_1,a_1)+d(a_1,a_2)+d(a_2,b_2)$~\cite{bright}. 

Promising as it might be, the indirect modeling adopted by embedding-based methods inevitably bear an approximation error between the path $d(b_1, a_1) + d(a_1, a_2) + d(a_2, b_2)$ and the exact cross-network node relationship $d(b_1,b_2)$, resulting in performance degradation.
Besides, embedding-based methods largely depend on the quality of node pairs sampled by hand-crafted sampling strategies such as random walk-based~\cite{dlna}, degree-based~\cite{crossmna, ione} and similarity-based~\cite{bright, nextalign} strategies. However, such hand-crafted strategies often suffer from high vulnerability to graph noises (e.g., structural and attribute noise), further exacerbating the detrimental effect of indirect modeling.
For example, as shown in Figure~\ref{fig:sampling}, when modeling the relationship between $(b_1,b_2)$ with a missing edge, $(b_1,a_1)$ will be misidentified as an intra-network negative pair by the random walk-based strategy, and the indirect modeling $d(b_1, a_1) + d(a_1, a_2) + d(a_2, b_2)$ will be enlarged as the ranking loss tends to increase $d(b_1,a_1)$, hence failing to align $b_1$ and $b_2$.
Similarly, due to attribute noise on $d_1$, the false negative intra-network node pair $(a_1,d_1)$ sampled by the similarity-based strategy will push the to-be-aligned node pair $(d_1,d_2)$ far apart. Besides, as the amount of indirectly modeled non-anchor node pairs (grey squares in Figure~\ref{fig:sampling}) is significantly greater than directly modeled anchor node pairs (colored squares in Figure~\ref{fig:sampling}), the effect of false negative pairs will be further exacerbated. 

Another line of works utilize the optimal transport (OT) theory for network alignment.
By viewing graphs as distributions over the node set, network alignment is formulated as a distributional matching problem based on a transport cost function measuring cross-network node distances.
Thanks to the marginal constraints in OT~\cite{peyre2019computational}, OT-based method generates noise-reduced alignment with soft one-to-one matching~\cite{parrot}.
However, the effectiveness of most, if not all, of the existing OT-based methods largely depend on pre-defined cost functions, focusing on specific graph structure~\cite{got, walign, fgot, zeng2024hierarchical} or node attributes~\cite{got2,parrot}, leading to poor generalization capability. Though efforts have been made to combine both methods by utilizing the OT objective to supervise embedding learning~\cite{slotalign,gwl,s-gwl,got2,combalign}, we theoretically reveal that directly applying the OT objective for embedding learning cause {\em embedding collapse} where all nodes are mapped to an identical point in the embedding space, hence dramatically degrading the discriminating power.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/sampling_new.png}
    \vspace{-15pt}
    \caption{An example of embedding-based methods with hand-crafted sampling strategies.
    Due to edge noise, $(a_1,b_1)$ is identified as a false negative intra-network pair, pushing $(b_1,b_2)$ that should be aligned far apart.
    Likewise, $(d_1,d_2)$ fails to align due to attribute noise on $d_1$. Best viewed in color.}
    \label{fig:sampling}
    \vspace{-10pt}
\end{figure}

In light of the pros and cons of embedding-based and OT-based methods, we seek to explore the complementary roles of two categories of methods to fully realize their mutual benefits. 
Specifically, we first demonstrate their close intrinsic relationships: the OT objective can be neatly transformed into a multi-level ranking loss with a weighted sampling strategy.
Based on this theoretical finding, we propose a novel unified framework named \algname\ to learn node embeddings and alignments jointly in a mutually beneficial way. 
For one thing, to augment embedding learning with OT, the OT mapping is transformed into a cross-network sampling strategy, which not only helps avoid embedding collapse, but also enhances model robustness against graph noises thanks to the direct modeling and noise-reduced property of OT~\cite{tam2019optimal,parrot}.
For another, to augment OT with embedding learning, \algname\ utilizes the learned node embeddings for a better OT cost design, which opens the door for the end-to-end training paradigm and can be adapted to different graphs without extensive parameter tuning.
We have compared the proposed \algname\ with the state-of-the-art network alignment methods on six different datasets, which validates the effectiveness and efficiency of our proposed model.

The main contributions of this paper are summarized as follows:
\begin{itemize}
    \item \textbf{Theoretical Analysis.} To our best knowledge, we are the first to theoretically reveal the close relationship and mutual benefits between OT and embedding-based methods.
    \item \textbf{Novel Model.} We propose a novel framework \algname\ to learn node embeddings and alignments jointly based on a unified objective function.
    \item \textbf{Extensive Experiments.}  Experiments on real-world datasets demonstrate the effectiveness and scalability of \algname, with up to 16\% and 6\% outperformance in MRR on plain and attributed networks, and up to 20$\times$ speed-up in inference time.
\end{itemize}
