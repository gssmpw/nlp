\section{Proofs}
\paragraph{Optimisation Problem}
For a given counterfactual transition $s, a \rightarrow s'$ and given observed transition $s_t, a_t \rightarrow s_{t+1}$, the optimisation problem is defined as follows:

\begin{align}
&{\min / \max}_{\theta} \sum_{u_t = 1}^{|U_t|} \mu_{s, a, u_t, s'} \cdot \mu_{s_t, a_t, u_t, s_{t+1}} \cdot \theta_{u_t} \label{proofeq:objective}\\
&\text{s.t.} \sum_{u_t = 1}^{|U_t|} \mu_{\tilde{s}, \tilde{a}, u_t, \tilde{s}'} \cdot \theta_{u_t} = P(\tilde{s}' \mid \tilde{s}, \tilde{a}), \forall \tilde{s}, \tilde{a}, \tilde{s}' \label{proofeq:interventional constraint} \\
&\tilde{P}_t(s_{t+1} \mid \tilde{s}, \tilde{a}) \geq {P}(s_{t+1} \mid \tilde{s}, \tilde{a}) \text{ if } P(s_{t+1} \mid \tilde{s}, \tilde{a})>0, \forall\tilde{s},\tilde{a} \text{ (Mon1)} \label{proofeq:monotonicity1} \\
&\tilde{P}_t(\tilde{s}' \mid \tilde{s}, \tilde{a}) \leq {P}(\tilde{s}' \mid \tilde{s}, \tilde{a}) \text{ if } P(\tilde{s}' \mid \tilde{s}, \tilde{a})>0 \text{ and } P(\tilde{s}' \mid s_t, a_t)>0, \forall \tilde{s}, \tilde{a}, \tilde{s}'\neq s_{t+1} \text{ (Mon2)} \label{proofeq:monotonicity2} \\
&\tilde{P}_t(\tilde{s}' \mid \tilde{s}, \tilde{a}) = 0 \text{ if } \dfrac{P(s_{t+1} \mid \tilde{s}, \tilde{a})}{P(s_{t+1} \mid s_t, a_t)}>\dfrac{P(\tilde{s}' \mid \tilde{s}, \tilde{a})}{P(\tilde{s}' \mid s_t, a_t)} \text{ and } P(\tilde{s}' \mid s_t, a_t) > 0, \forall \tilde{s}, \tilde{a}, \tilde{s}' \text{ (CS)} \label{proofeq:counterfactual stability} \\
&0 \leq \theta_{u_t} \leq 1, \forall u_t \label{proofeq:valid prob1} \\
&\sum_{u_t = 1}^{|U_t|} \theta_{u_t} = 1 \label{proofeq:valid prob2}
\end{align}

where $\theta$ and $\mu$ are defined as follows:

\[\theta \in \mathbb{R}^{|\Omega_{U_t}|}\]
\[\mu \in \{0,1\}^{\mathcal{S} \times \mathcal{A} \times |\Omega_{U_t}| \times \mathcal{S}}\]
\[\forall s \in \mathcal{S}, a \in \mathcal{A}, s' \in \mathcal{S}, u_t \in U_t, \mu_{s, a, u_t, s'} = 
\begin{cases}
    1 & \text{if $f(s, a, u_t) = s'$}\\
    0 & \text{otherwise}\\
\end{cases}
\]

\paragraph{Counterfactual Probabilities}
For any transition $s, a \rightarrow s'$ and observed transition $s_t, a_t \rightarrow s_{t+1}$, the counterfactual transition probability $\tilde{P}_t(s' \mid s, a)$ can be calculated as follows:

\begin{equation}
\label{eq: counterfactual probability}
   \tilde{P}_t(s' \mid s, a)= \dfrac{\sum_{u_t = 1}^{|U_t|} \mu_{s, a, u_t, s'} \cdot \mu_{s_t, a_t, u_t, s_{t+1}} \cdot \theta_{u_t}}{P(s_{t+1} \mid s_t, a_t)} 
\end{equation}

\input{proof-sections/probability-bounds}

\input{proof-sections/sampling-proof}

\pagebreak
\input{proof-sections/lemmas}

\pagebreak
\section{Equivalence with Existing Work}
\label{app: equivalence proofs}
\citet{li2024probabilities}'s bounds for the probability of causation are provided below. We can show that these are equivalent to our analytical bounds where the support of the counterfactual state-action pair $(\tilde{s}, \tilde{a})$ is disjoint from the support of the observed state-action pair $(s_t, a_t)$, given in Theorems \ref{proof theorem: ub disjoint} and \ref{proof theorem: lb disjoint}.

\begin{theorem}[Bounds for Probability of Causation]
    Suppose X has m values $x_1, ..., x_m$ and Y has n values $y_1, ..., y_n$, the probability of causation $P(y_{i_{x_j}}, y_k, x_p)$ where $1 \leq i$, $k \leq n$, $1 \leq j$, $p \leq m$, $j \neq p$ is given by:

    \[
    P^{LB}(y_{i_{x_j}}, y_k, x_p) = \max(0, P(y_{i_{x_j}}) + P(x_p, y_k)  -1 + P(x_j) - P(x_j, y_i))
    \]

    \[
    P^{UB}(y_{i_{x_j}}, y_k, x_p) = \min(P(y_{i_{x_j}}) - P(x_j, y_i), P(x_p, y_k))
    \]
\end{theorem}

\begin{proof}
We show that \cite{li2024probabilities}'s upper and lower bounds for the probability of causation are equivalent to our bounds in Theorems \ref{proof theorem: ub disjoint} and \ref{proof theorem: lb disjoint}, as follows.

\begin{equation}
\begin{aligned}
    P^{UB}(y_{i_{x_j}}, y_k, x_p) &= \min(P(x_p, y_k), P(y_{i_{x_j}}) - P(x_j, y_i))\\
    P^{UB}(y_{i_{x_j}} \mid y_k, x_p) &= \dfrac{\min(P(x_p, y_k), P(y_{i_{x_j}}) - P(x_j, y_i))}{P(x_p, y_k)}\\
    &= \min(1, \dfrac{P(y_{i_{x_j}}) - P(x_j, y_i)}{P(x_p, y_k)})\\
    &= \min(1, \dfrac{P(y_{i_{x_j}}) - P(y_{i_{x_j}}, x_j)}{P({y_k}_{x_p}, x_p)})\\
    &= \min(1, \dfrac{P(y_{i_{x_j}}) - P(y_{i_{x_j}})\cdot P(x_j)}{P({y_k}_{x_p})\cdot P(x_p)})\\
    &= \min(1, \dfrac{P(y_{i_{x_j}})}{P({y_k}_{x_p})}) \text{ because $P(x_p) = 1$ and $P(x_j) = 0$}
\end{aligned}
\end{equation}
which is equivalent to the upper bound in Theorem \ref{proof theorem: ub disjoint} where $x_p = (s_t, a_t)$, $y_k = s_{t+1}$, $x_j = (\tilde{s}, \tilde{a})$ and $y_i = \tilde{s}'$.

\begin{equation}
\begin{aligned}
    P^{LB}(y_{i_{x_j}}, y_k, x_p) &= \max(0, P(y_{i_{x_j}}) + P(x_p, y_k) -1 + P(x_j) - P(x_j, y_i))\\
    P^{LB}(y_{i_{x_j}}\mid y_k, x_p) &= \dfrac{\max(0, P(y_{i_{x_j}}) + P(x_p, y_k) -1 + P(x_j) - P(x_j, y_i))}{P(x_p, y_k)}\\
    &= \max(0, \dfrac{P(y_{i_{x_j}}) + P(x_p, y_k) -1 + P(x_j) - P(x_j, y_i)}{P(x_p, y_k)})\\
    &= \max(0, \dfrac{P(y_{i_{x_j}}) + P(y_{k_{x_p}}, x_p) -1 + P(x_j) - P(y_{i_{x_j}}, x_j)}{P({y_k}_{x_p}, x_p)})\\
    &= \max(0, \dfrac{P(y_{i_{x_j}}) + P(y_{k_{x_p}})\cdot P(x_p) -1 + P(x_j) - P(y_{i_{x_j}})\cdot P(x_j)}{P({y_k}_{x_p})\cdot P(x_p)})\\
    &= \max(0, \dfrac{P(y_{i_{x_j}}) + P(y_{k_{x_p}}) -1}{P({y_k}_{x_p})}) \text{ because $P(x_p) = 1$ and $P(x_j) = 0$}\\
    &= \max(0, \dfrac{P(y_{i_{x_j}}) - (1 - P(y_{k_{x_p}}))}{P({y_k}_{x_p})})\\
\end{aligned}
\end{equation}
which is equivalent to the lower bound in Theorem \ref{proof theorem: lb disjoint} where $x_p = (s_t, a_t)$, $y_k = s_{t+1}$, $x_j = (\tilde{s}, \tilde{a})$ and $y_i = \tilde{s}'$.

\end{proof}

%
%
%