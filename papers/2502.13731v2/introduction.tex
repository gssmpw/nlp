\section{Introduction}
\jl{Markov Decision Processes (MDPs) are a fundamental model of computation 
for representing sequential decision-making processes under uncertainty, including reinforcement learning (RL) problems.} However, evaluating RL-learnt policies can be challenging, especially in safety-critical domains like healthcare, where testing these policies directly on patients would be risky and unethical. 

\jl{Counterfactual inference of MDPs enables offline policy evaluation, i.e., without ``deploying'' the alternative policy into the environment. 
Given an observed sequence of actions and outcomes (e.g., from an existing clinician's policy), counterfactual inference estimates what the outcome would have been if different actions had been taken.} Counterfactual outcomes yielding higher rewards than the observation can serve as explanations for how the observed policy could be improved.

There is a rapidly growing body of literature on counterfactual inference for MDPs \citep{oberst2019counterfactual, lorberbom2021learning, tsirtsis2021counterfactual, benz2022counterfactual, noorbakhsh2022counterfactual, killian2022counterfactually, zhu2020counterfactual, tsirtsis2024finding}. \jl{Most of these papers assume a specific causal model of the system (i.e., the Gumbel-max structural causal model (SCM) \citep{oberst2019counterfactual})} to identify counterfactuals, but, in general, counterfactuals in MDPs are \textit{non-identifiable}: many causal models would fit the given observational and interventional data, each yielding different counterfactual probabilities \citep{pmlr-v162-zhang22ab}. In the MDP context, the observational distribution will be a single observed path of the MDP, and the interventional distribution is the MDP's transition probabilities \jl{for a given state and action}. As a result, any counterfactual analysis based on a presumed causal model may not be valid, which is particularly concerning in safety-critical domains.

%

\jl{\textit{Partial counterfactual inference} methods derive bounds (as opposed to sharp values) on counterfactual probabilities, accounting for \textit{all} causal models compatible with given observational and interventional data, avoiding reliance on a fixed (and possibly erroneous) model.} \jl{Our work is inspired by the canonical SCM approach developed by \citet{pmlr-v162-zhang22ab}, which formulates partial counterfactual inference as an optimisation problem. However, this optimisation procedure is very inefficient even for small causal graphs (with variables and constraints that are exponential in the size of the MDP), which has encouraged the development of approximate algorithms}
%
\citep{pmlr-v162-zhang22ab, duarte2023, zaffalon2024}.

\paragraph{Contributions} In this paper, we derive and prove exact analytical bounds for MDP counterfactual probabilities, thereby solving this inefficiency problem and enabling precise counterfactual analysis of non-trivial MDP models \jl{in a fully non-parametric way}. \jl{We demonstrate how \citet{pmlr-v162-zhang22ab}'s partial counterfactual inference approach can be applied to MDPs, prove this optimisation reduces to exact analytical bounds,} and show how these bounds can be extended to incorporate additional assumptions to generate more realistic counterfactual probabilities. \jl{Next, we use these bounds to construct interval counterfactual MDPs, which we solve using pessimistic value iteration \citep{mathiesen2024intervalmdp} to derive robust counterfactual policies that optimise the worst-case counterfactual rewards induced by all possible causal models compatible with the given data.} Finally, we evaluate our approach on three MDP benchmarks (two Grid World environments and a model of Sepsis treatment), demonstrating that our policies are more robust to uncertainty about the causal model than those from the Gumbel-max SCM. 

The most similar work to this paper is by \citet{li2024probabilities}, who identified counterfactual probability bounds for categorical SCMs given observational and interventional distributions. 
We show that their bounds can be reformulated for MDPs and correspond to a special case of our analytical bounds. However, our approach offers greater flexibility, allowing for the inclusion of additional properties to ensure more realistic counterfactual transition probabilities.
