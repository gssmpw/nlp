\begin{abstract}

Anchors is a popular local model-agnostic explanation technique whose applicability is limited by its computational inefficiency.
%
To address this limitation, we propose a pre-training-based approach to accelerate Anchors without compromising the explanation quality. 
%
Our approach leverages the iterative nature of Anchors' algorithm which gradually refines an explanation until it is precise enough for a given input by providing a general explanation that is obtained through pre-training as Anchors' initial explanation.
%
Specifically, we develop a two-step rule transformation process: the horizontal transformation adapts a pre-trained explanation to the current input by replacing features, and the vertical transformation refines the general explanation until it is precise enough for the input.
%
 We evaluate our method across tabular, text, and image datasets, demonstrating that it significantly reduces explanation generation time while maintaining fidelity and interpretability, thereby enabling the practical adoption of Anchors in time-sensitive applications.


% %
% However, its computational inefficiency—requiring hours to generate explanations in some cases—severely limits its practicality for real-time and large-scale applications.
% %
% To address this limitation, we propose an approach to accelerate Anchors without compromising explanation quality. Our approach builds on two key insights: (1) most of Anchors’ computation time is spent sampling variants of the input, and (2) Anchors generates explanations iteratively, beginning with general rules and refining them. Leveraging these observations, we introduce a pre-training strategy to generate explanations for representative inputs in advance and adapt them to new inputs during online computation.
% %
% Specifically, we develop a two-step rule transformation process: horizontal transformation adapts pre-trained rules to similar online inputs, and vertical transformation refines these rules to meet user-specified precision requirements.
% %
% We evaluate our method across tabular, text, and image datasets, demonstrating that it significantly reduces explanation generation time while maintaining fidelity and interpretability, thereby enabling the practical adoption of Anchors in time-sensitive applications.

\end{abstract}