\section{Approach}

% As mentioned in the introduction, our approach implements a method based on pre-training and feature transfer to accelerate Anchors. In this chapter, we provide a detailed explanation of the algorithmic framework implemented in this work.

Our approach attempts to reduce the online time cost of Anchors by pre-calculating explanations for some representative samples using Anchors during the pre-training phase. When applying Anchors to a new input online, our approach first selects the pre-training input which is most similar with the online input. Then it uses a horizontal transformation, transforming the pre-trained result of the selected pre-training input into a rule composed of features of the online input. At last, through a vertical transformation, the obtained rule is further expanded until the required precision is satisfied. We next explain each step in detail.

\subsection{Offline Pre-Training} 

\begin{algorithm}[tb]
   \caption{Pre-training process}
   \label{alg:pre-train}
    \begin{algorithmic}[1]
    \STATE {\bfseries Input:} A dataset $\mathbb{X}$ and a model to explain $f$, 
    \STATE {\bfseries Output:} The pre-training result $\mathbb{R}$
    \STATE {\bfseries Param:} The number of pre-training inputs $N$ and the precision threshold $\tau$
    \STATE $\mathbb{X}_{pre-train}$ := $finding\_clusters(\mathbb{X},N)$
    \STATE $\mathbb{R}$ := $[\ ]$
    \FORALL{$ x \in \mathbb{X}_{pre-train}$}
        \STATE $R$ := $Anchors(f,x,\tau)$
        \STATE $\mathbb{R}.add(R)$
    \ENDFOR
    \STATE return $\mathbb{X}_{pre-train}$,$\mathbb{R}$
    \end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:pre-train} outlines the pre-training phase of our approach, which takes an input set $\mathbb{X}$ and a model $f$ as input and outputs a set of rules.
%
It also takes two parameters.
The parameter $N$ specifies the number of inputs to generate rules on.
This parameter is needed as it can be too computationally expensive to generate rules for every input in $\mathbb{X}$ so the algorithm chooses $N$ representative inputs instead.
The other parameter $\tau$ specifies the precision requirement for Anchors during  pre-training, which balances the precision and coverage of the generated rules.
The higher $\tau$ is, the more precision and the lower coverage the generated explanation rule has. 
To generate general rules, the pre-training phase uses a lower precision threshold compared to the online explanation phase.

In Line 4, the algorithm uses the K-means clustering algorithm ~\cite{kmeans} to identify $N$ clusters and selects their centroids as representative inputs (stored in $\mathbb{X}_{pre-train}$).
In Line 6-9, the algorithm iterates through each input in $\mathbb{X}_{pre-train}$ and apply Anchors with specified precision threshold $\tau$ to generate explanation rules.
Finally, the algorithm returns the pre-training input set and  all the corresponding generated explanation rules in line 10.


% Algorithm\ref{alg:pre-train} outlines the pre-training process of our approach for a given dataset \(\mathbb{X}\) and a model \(f\) that requires explanation. The dataset \( \mathbb{X} \) is a collection of inputs to the model \( f \), where each member \( x \in \mathbb{X} \) can serve as an input to explain. Ideally, we would like to pretrain on the entire dataset \( \mathbb{X} \) (i.e., \( N = |\mathbb{X}| \)). However, considering the time cost of pretraining, we select a subset of \( \mathbb{X} \) as the pretraining input set.

% In addition to these two inputs, it also has two parameters, \(N\) and \(\tau\).
%
%The former represents the number of the pre-training inputs, i.e., the number of explanations generated during pre-training. The latter constrains the lower bound of the output explanation's precision during the pre-training process, as we discussed in Section\ref{def:tau}. 
%
% The parameter \(N\) constrains the scale of our pre-training process. A larger \(N\) allows the refinement process to find a pre-training input that is more similar to the current input, enabling greater utilization of the pre-trained results during the horizontal transformation. Therefore, this constraint directly affects the efficiency of our optimization. However, a larger \(N\) also results in significantly higher time overhead during the pre-training process.
%
% The parameter \(\tau\) controls the fidelity of the explanations generated by Anchors, i.e., \(precision(Anchors(f,x,\tau)) \geq \tau\) with a high probability. When this parameter is set to a lower value, we can obtain ``general explanations" with lower precision but higher coverage. For example, in the task of explaining image classification, using a lower \(\tau\) typically results in explanations that capture only partial features of the classified object (such as the wheels of a car or the windows of a house), rather than including all features as an explanation for the model \(f\). 
%
% The output is the pre-training dataset \(\mathbb{X}_{pre-train}\) and a rule set, denoted as \(\mathbb{R} = \{R_1, R_2, \dots, R_N\}\), where \(R_i = \boldsymbol{(p_{a_{i1}}, p_{a_{i2}}, \dots, p_{a_{in_i}})}\) represents the rule for the \(i\)-th pre-training input \(x_i\), and \(\boldsymbol{p_{a_{ij}}}\) represents a specific predicate about the \(a_{ij}\)th feature of the input \(x_i\).

% We first use the K-means clustering algorithm\cite{kmeans} to identify \(N\) clusters from the dataset \(\mathbb{X}\). The \(N\) cluster centers obtained are used as the pre-training input set. Then, each of these \(N\) pre-training inputs is sequentially processed through Anchors to compute a general explanation, and finally, these \(N\) explanations are output as the result.
%
% The pre-training process algorithm generates a series of pre-trained results based on the dataset while recording the index relationship between the pre-training inputs and their corresponding pre-trained results. During the refinement process, we identify the most similar pre-training input \(x_i\) to the input \(x\) and use its index to locate the corresponding pre-trained result \(R_{x_i}\). 

% Next, we introduce the refinement process, which is the most critical part of our method. This process includes two types of rule transformations.

\subsection{Online Refinement}

\begin{algorithm}[tb]
   \caption{Refinement Process}
   \label{alg:refine}
    \begin{algorithmic}[1]
       \STATE {\bfseries Input:} Input $x=\boldsymbol{( x_1,x_2,...,x_m)}$, A model to explain $f$, the pre-training dataset $\mathbb{X}_{pre-train}$ and the pre-trained rules $\mathbb{R}$
       \STATE {\bfseries Output:} Explanation $R$
       \STATE {\bfseries Param:} The precision threshold $\tau$ %and the max distance threshold $\Delta$
       \STATE $x_{similar}$ := $arg\ min_{x_i \in \mathbb{X}_{pre-train}}Dist(x, x_i)$
       \STATE $R_1$ := $\mathbb{R}[\mathbb{X}_{pre-train}.indexof(x_{similar})]$
       % \FOR{ $i=1$ {\bfseries to} $|\mathbb{X}|$}
       %      \IF{$Dist(x,\mathbb{X}[i]) \leq Dist(x,\mathbb{X}[min])$}
       %          \STATE $min$ := $i$
       %      \ENDIF
       % \ENDFOR
       % \STATE $R_2$ := $Horizontal\ Transformation(R_1)$
       \STATE \# $Horizontal\ Transformation$
       \STATE $R_2$ := $\emptyset$
       \FOR{$p$ {\bfseries in} $R_1$}
            % \STATE $r'$ := $arg\ min_{r'}Dist(r, r') \forall{r'} \in x$
            \STATE $v$ := feature value of $p$ 
            \STATE $similar\_feature$ := \textbf{None}
            \FOR{$i=1$ {\bfseries to} m}
                % \IF{$Dist(v,x_i)\leq \Delta$}
                    \IF{$Dist(v,x_i)\leq Dist(v,similar\_feature)$}
                        \STATE $similar\_feature$ := $x_i$
                    \ENDIF
                % \ENDIF
            \ENDFOR
            \STATE $p_s$ := $replace\_predicate(p, v,similar\_feature)$
            \STATE $R_2$ := $R_2\cup \{p_s\}$
       \ENDFOR
       % \STATE $R_{res}$ := $Vertical\ Transformation(R_2)$
       \STATE \# $Vertical\ Transformation$
        \REPEAT
        \STATE $\mathbb{R'} $ := $\emptyset$
        \FOR{$i=1$ {\bfseries to} m}
            \STATE $p_{i}$ := predicate of $x_i$
            \IF{$p_{i} \notin R_2$}
                \STATE $\mathbb{R'} := \mathbb{R'}\cup\{R_2\cup\{p_{i}\}\}$
            \ENDIF
        \ENDFOR
        \STATE $R$ := $arg\ max_{R_i\in \mathbb{R}'}(precision_{x,f}(R_i))$
        \UNTIL{$precision_{x,f}(R) \geq \tau$}
        \STATE return {$R$}
    \end{algorithmic}
\end{algorithm}


Algorithm~\ref{alg:refine} outlines the online refinement phase of our approach. It takes an input \(x\), a model \(f\), the pre-training dataset \(\mathbb{X}_{pre-train}\), and the corresponding pre-trained rules \(\mathbb{R}\) as input. Additionally, it has a  parameter \(\tau\), which controls the Anchors explanation precision as in Algorithm~\ref{alg:pre-train}. However, the \(\tau\) used here is set to a higher value compared to Algorithm~\ref{alg:pre-train} because we need to return a more specific rule to the user. 
%Another parameter, \(\Delta\), constrains the maximum distance during the horizontal transformation. This parameter is used to balance between ``transferring to a less similar features" and ``maintaining the precision after horizontal transformation." A larger \(\Delta\) can enable the pre-training results to transfer to a less similar input. However, an excessively large \(\delta\) may lead to lower precision for the predicates after horizontal transformation. As a result, in the vertical transformation, more predicates would be added to meet the precision requirements. This could ultimately result in lower coverage for the explanation generated by our approach (due to the inclusion of more predicates) and a decline in the acceleration effect.
The output of the Algorithm~\ref{alg:refine} is consistent with Anchors, producing an explanation \(R\) for the input \(x\) and the model \(f\).

% Recalling the two main challenges we introduced earlier:  

% 1) Similar but not identical samples may have inconsistent features. Anchors uses input features as rules for explanations, but pre-trained sample features may not fully align with those of new inputs, making the rules for pre-trained samples potentially inapplicable to new ones.  

% 2) Since Anchors is a local explanation method, similar samples may still have differing neighborhoods, leading to different decision boundaries and varying explanations. As a result, high-precision explanations for pre-trained samples may not maintain the same precision for new inputs.  

% We first discuss how we address these challenges at a high level before diving into the details of the algorithm. To overcome these challenges, we introduce \textbf{rule transformation} as a core component of our method. Rule transformation consists of two main processes: \textbf{horizontal transformation} and \textbf{vertical transformation}. Horizontal transformation adapts rules from one sample to another by mapping key features identified in pre-trained explanations onto new input samples, ensuring that explanations remain relevant across different contexts. Vertical transformation refines a general rule—which typically has high coverage but low precision—into a more specific rule with low coverage and high precision, aligning with Anchors' precision goals.

Next, we discuss the details of Algorithm~\ref{alg:refine}.  

\textbf{Obtaining a similar input.} In Line 4, the algorithm obtains the pre-training input \(x_{similar}\) that is most similar to the input \(x\).  In this process, we map the input \(x\) and the pre-trained input set \(\mathbb{X}\) to the same embedding space. Based on the distance in the embedding space, we identify the pre-training input that is closest to \(x\) and treat it as the most similar pre-training input, \(x_{similar}\). Then in Line 54, the algorithm retrieves the pre-trained rule \(R_1\) of $x_{similair}$ produced in Algorithm~\ref{alg:pre-train}.

\textbf{Horizontal transformation.} From Line 7 to Line 20 is the horizontal transformation. 
% First, we provide a definition for
The horizontal transformation (HT) is a method that adapts rules from one input to another similar input. This method maps the predicates from the pre-trained rules onto the predicates formed by the features in the online input that are most similar to them., i.e.,  
$$HT: \mathbb{R} \rightarrow \mathbb{R}$$Let $R_2=HT(R_1)$ where
$$R_1 = \boldsymbol{(p_{a_1}, p_{a_2},...,p_{a_n})}, \quad R_2 = \boldsymbol{(p_{b_1}, p_{b_2}, ..., p_{b_m})}$$
Here, \(\boldsymbol{p_{a_1}, p_{a_2},...,p_{a_n}}\) represent the predicates of the pre-trained rule and \(\boldsymbol{x_{a_1}, x_{a_2},...,x_{a_n}}\) represent the features of the pre-training input. Predicates \(\boldsymbol{p_{b_1}, p_{b_2}, ...,p_{b_m}}\) represent the predicates of the new rule and \(\boldsymbol{y_{b_1}, y_{b_2}, ...,y_{b_m}}\) represent the features of the online input. We ensure that 
% $$\forall_{i \in \{1, 2, .., n\}, j \in \{1, 2, .., m\}} Dist(x_{a_j}, y_{b_j}) \leq \Delta \leq Dist(x_{a_i}, y_{b_j})$$
$$\forall {i \in \{1, .., n\}, j \in \{1, .., m\}} Dist(x_{a_j}, y_{b_j}) \leq Dist(x_{a_i}, y_{b_j})$$
The function \emph{Dist} measures the difference between two features. For tabular data, it represents the absolute value of the difference between two numbers. For text data, it represents the distance between two words in the semantic space generated by a fine-tuned BERT ~\cite{bert}. For image data, it represents the distance between the vectors of two superpixels after embedding through Resnet50 ~\cite{resnet50}.

In Line 8, the algorithm enumerates each predicate \(p\) in the pre-training result \(R\). From Line 11 to Line 17, the algorithm identify the most similar feature in the input \(x_i\) based on the feature represented by \(p\). Then, in Line 16, the algorithm use a function \(replace\_predicate\) to replace the feature value \(v\) with the similar feature value \(similar\_feature\) from the predicate \(p\) to obtain the predicate \(p_s\). At last, in Line 17, the algorithm add the predicate \(p_s\) to the rule \(R_2\).

\textbf{Vertical transformation.} From Line 22 to Line 31 is the vertical transformation (VT). This process refines a general rule—which typically has high coverage but low precision—into a more specific rule with low coverage and high precision, i.e.,  
$$VT: \mathbb{R} \rightarrow \mathbb{R}$$
Let $R_2=VT(R_1)$, where$R_2 =R_1 \cup R'$ and $Precision(R_1 \cup R') \geq \tau$.
This process is achieved by continuously adding new predicates to the existing rule \(R\). At the beginning of each iteration (Line 23), the set of candidate rules is initialized to an empty set. In Line 24 and 25, the algorithm enumerates all the features of input \(x_i\), and converts them into the corresponding predicates. In Line 26 and 27, the algorithm adds a new predicate \(p_{i}\) into \(R_2\), which is not already included in \(R_2\), to form several candidates. Then in Line 30, through perturbation sampling, the candidate with the highest precision is selected as the new rule \(R\) for the next iteration. This process repeats until the rule \(R\) satisfies \(Precision(R) \geq \tau\).  

Thus, we align with Anchors' precision goals and ensure that explanations can be effectively adapted to specific contexts without extensive recalculations.




% In summary, our method attempts to reduce the time cost of online training by pre-calculating explanations for some representative samples using Anchors during the pre-training phase. When the actual input arrives during online training, the explanations of similar pre-trained samples are transferred to facilitate the explanation generation process.

% However, this approach presents certain challenges. Let's revisit the two main challenges mentioned in the introduction:

% 1) Since Anchors is a local explainable method, for two samples that are similar but not identical, their neighborhoods do not completely overlap, which may result in different decision boundaries for the model. Therefore, the explanations generated may differ, meaning high precision explanations of pre-trained samples might not maintain the same level of precision on new input samples.

% 2) The features of two samples that are similar but not identical may not be entirely consistent. Anchors generates explanations by using some features of the input samples as rules, and features from pre-trained samples might not fully match those from input samples. Therefore, rules applicable to pre-trained samples might not apply to new inputs.

% 1) Since Anchors is a local explainable method, similar but not identical samples may have differing neighborhoods, leading to different decision boundaries and varying explanations. As a result, high precision explanations for pre-trained samples may not maintain the same precision for new inputs.

% 2) Similar but not identical samples may have inconsistent features. Anchors uses input features as rules for explanations, but pre-trained sample features may not fully align with those of new inputs, making the rules for pre-trained samples potentially inapplicable to new ones.

% To overcome these challenges, we introduce rule transformation as a core component of our method. Rule transformation consists of two main processes: horizontal and vertical transformation. Horizontal transformation adapts rules from one sample to another by mapping key features identified in pre-trained explanations onto new input samples, ensuring that explanations remain relevant across different contexts. Vertical transformation refines a general rule—which typically has high coverage but low precision—into a more specific rule with low coverage and high precision, aligning with Anchors' precision goals.

% \begin{table*}[h]
%     \small
%     \centering
%     \caption{Explanations with different \emph{precision}.}
%     \label{tab:high-lowprecision}
%     \begin{tabular}{cccc}
%         \toprule 
%         Input sample $x$ & Parameter$\theta$ & Generated explanation$R_x$ \\
%         \midrule
%          $x_3$=She played an important role in the best movie of the year.& 0.95 (high \emph{precision}) & $('best','important')$\\
%         $x_4$=This is the best movie that I have ever seen . & 0.95 (high \emph{precision}) & $('best','movie')$\\
%         $x_5$=This is the best movie that I have ever seen . & 0.80 (low \emph{precision}) & $('best')$\\
%         \bottomrule
%     \end{tabular}
% \end{table*}


% \begin{table*}[h]
%     \small
%     \centering
%     \caption{Sample with different features}
%     \label{tab:featuretrans_example}
%     \begin{tabular}{cccc}
%         \toprule 
%         Input sample $x$ & Generated explanation $R_x$ & $f(x)$ \\
%         \midrule
%         $x_3$=This is the best movie that I‘ve ever seen .& (``best") & positive\\
%         $x_4$=He was really nice today and helped me a lot .& (``nice",``helped") & positive\\
%         \bottomrule
%     \end{tabular}
% \end{table*}

% For the first challenge, Table \ref{tab:high-lowprecision} shows a comparison between high precision and low precision explanations for the same sample $x_2$ and a similar sample $x_1$. In generating explanations for $x_1$, the rule set $R_{x_1}=('best', 'important')$ was the most comprehensive under high precision requirements. Attempting to apply a high precision explanation for $x_2$, $R_{x_2}=('best', 'movie')$, to $x_1$ would fail because 'movie' does not adequately describe the decision boundary in $x_1$’s neighborhood. To address this challenge, we introduce vertical transformation(VT). This process refines a general rule—which typically has high coverage but low precision—into a more specific rule with low coverage and high precision, i.e. $VT:R \rightarrow R \cup R'$, where $Precision(R\cup R') \geq Precision(R)$. 
% Therefore, we align with Anchors' precision goals and ensure that explanations can be effectively adapted to specific contexts without extensive recalculations.

% For the second challenge, concerning feature inconsistency, we propose using horizontal transformation(HT), a method that adapts rules from one sample to another. This approach involves mapping key features identified in pre-trained explanations onto new input samples, ensuring that explanations remain relevant across different contexts, i.e. $HT:R\rightarrow R'$, where $R=(x_1,x_2,...x_n),R'=(y_1,y_2,...y_n)$, $x$ is the pre-train input, $y$ is the online input and $\forall_{i\in\{1,2...n\}}\forall_{j\in\{1,2,...n\}}\ Dissimilarity(x_i,y_i)\leq Dissimilarity(x_i,y_j)$. The \emph{Dissimilarity} means how different between two features, for tabular data, it represents the absolute value between two numbers; for text data, it represents the distance between two words in the semantic space; and for image data, it represents the distance between the vectors of two superpixels after embedding.
% % Consider the example in Table \ref{tab:featuretrans_example}, where pre-trained sample $x_3$ and input sample $x_4$ do not share many features. Typically, rules generated from $x_3$ cannot initiate explanations for $x_4$. 
% Recalling the example in Table \ref{tab:featuretrans_example}, horizontal transformation allows us to identify and map these key features—those that, when fixed, result in higher precision during perturbations—onto $x_4$. This ensures effective feature transfer by leveraging the similarity in perturbation spaces, ultimately achieving robust explanations despite feature inconsistency.

% \begin{figure*}[t]
% \centering
% \includegraphics[width=1.6\columnwidth]{figures/pipeline4.png} 
% \caption{The overall workflow of our method.}
% \label{pip1}
% \end{figure*}

% \subsection{Workflow}

% Figure\ref{pip1} shows the overall workflow of our implemented algorithm. During initialization, we identify representative pre-training samples through K-means clustering, using cluster centers for pre-training. In detail, our pre-training samples are derived from a clustering algorithm. We first map the training set $X$ into a multi-dimensional space, then input it into the clustering algorithm. After obtaining the cluster centers, we map them back to the space of the training set, ultimately resulting in the pre-trained sample set $X_{pre-train}$. Each sample in this pre-training set $X_{pre-train}$ is processed with a lower precision requirement through Anchors to meet our requirements for vertical transformation. After that, a KD-tree is established to expedite the retrieval of the most similar pre-training sample for any given input during online training. For this step, we still need to map the pre-trained sample set $X_{pre-train}$ into a multi-dimensional space in the same manner. Then, based on the coordinates of all samples in the pre-trained set within this multi-dimensional space, we establish the KD-tree.

% In online training, when a sample $x$ is input, the algorithm quickly identifies the most similar pre-trained sample $x'$ in $X_{pre-train}$. To achieve this goal, after mapping the input sample x into the multi-dimensional space, we can use the query operation of the KD-tree to find the nearest pre-train sample $x'$ in $O(log(|X_{pre-train}|))$ time complexity. Then we retrieves the pre-trained results $R_{x'}$, where $R_{x'}$ is the low-precision and high-coverage rule set of $x'$. Unlike the standard Anchors algorithm, our approach uses the pre-trained results rather than an empty initial rule set, and applies feature transfer to map rule set to relevant features of $x$. That is to say, in Section 2.2, the initial rule set $R^{*}=\emptyset$, while in our method, the initial rule set $R^{*} = Horizontal Transformation(R_{x'})$. Next, we implement our vertical transformation by utilizing the process of incremental computation with Anchors. 

% Compared to the original Anchors algorithm, our approach includes additional steps for sample comparison and feature transfer. These steps may introduce slight overhead for samples that are already handled quickly, but overall, they significantly optimize the process for more complex cases.