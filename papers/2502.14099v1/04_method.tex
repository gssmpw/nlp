\begin{figure*}[!t]
    \centering
    \begin{minipage}[c]{.28\textwidth}
    \centering
    \includegraphics[height=\columnwidth]{figures/corr_matrix_sf_dep}
    \subcaption{Sequentially trained ($sf_s \neq sf_t$).}
    \label{fig:corr_matrix_sf_seq}
    \end{minipage}    
    \hspace{1cm}
    \begin{minipage}[c]{.28\textwidth}
    \centering
    \includegraphics[height=\columnwidth]{figures/corr_matrix_q_dep.pdf}
    \subcaption{Sequentially trained ($sf_s = sf_t$).}
    \label{fig:corr_matrix_q_seq}
    \end{minipage}    
    \hspace{1cm}
    \begin{minipage}[c]{.28\textwidth}
    \centering
    \includegraphics[height=\columnwidth]{figures/corr_matrix_sf_ind}
    \subcaption{Independently trained.}
    \label{fig:corr_matrix_sf_ind}
    \end{minipage}
    \label{fig:corr_matrix_sf}
    \caption{Average cosine similarity between corresponding latents produced by the five different \gls{jpeg-pcc} coding models.}
\end{figure*}

\section{Scalable Resolution and Quality Hyperprior}
\label{sec:extending_sqh}
Previous research \cite{mari2024point} revealed a significant correlation between latents encoded with varying $qp$ parameters. This fundamental property is crucial to guarantee \gls{sqh}'s effectiveness as it enables a single model to manage diverse coding parameter combinations. However, this raises an important question: does this correlation persist when latents exhibit different resolutions due to varying scaling factors, potentially alongside quality differences? 
To rigorously investigate this relationship, an analysis was conducted using cosine similarity measurements between latents encoded across different combinations of quantization parameters $qp$ and scaling factors $sf$. For clarity in subsequent discussions, a simplified notation convention is adopted: lower-rate latents and their associated parameters are designated as "source" elements, denoted with the suffix $s$ (e.g., $\y_s$), while higher-rate latents and their corresponding parameters are termed "target" elements, indicated by the suffix $t$ (e.g., $\y_t$).

\subsection{Correlation between the latents}

Given blocks $\x$ in the validation dataset, latent vectors
$\boldsymbol{y}_{i} = Enc(\x, sf_s, i)$ and $\boldsymbol{y}_{j} = Enc(\x, sf_t, j)$
are generated, where $sf_s, sf_t$ denote the scaling factors,
$i, j$ represent the quality parameters, and $Enc(\cdot, \cdot, \cdot)$
represents the encoding function that performs down-scaling and applies the analysis transform to the input block.
Following the methodology established for \gls{sqh}, cosine similarities between different compressed representations of identical blocks were evaluated across varying quality parameters and resolutions.


The analysis considers source latents encoded with parameters $qp_s=i, sf_s$ and target latents with $qp_t=j, sf_t$. With $\y_s = Enc(\x, sf_s, i)$ and $\y_t = Enc(\x, sf_t, j)$, the matrix coefficients at position $i, j$ were derived as the average cosine similarity between latents across all the blocks of the validation dataset. For cases where $sf_s \neq sf_t$, the source and target coordinates do not match due to the resolution difference. In such instances, the lower resolution coordinates were upscaled and the cosine similarities were computed relative to nearest neighbors within a radius of 2, selected based on the ratio between $sf_s$ and $sf_t$.

This analysis generated three distinct similarity matrices. The first two matrices (shown in Figs.~\ref{fig:corr_matrix_sf_seq},~\ref{fig:corr_matrix_q_seq}) were computed using latents from \gls{jpeg-pcc}v4.0, featuring sequentially trained models. Fig.~\ref{fig:corr_matrix_sf_seq} corresponds to $sf_s=2, sf_t=1$, while Fig.~\ref{fig:corr_matrix_q_seq} represents $sf_s=sf_t=1$. The third matrix (shown in Fig.~\ref{fig:corr_matrix_sf_ind}) utilizes latents from independently trained models, maintaining identical architecture, training data, and parameters as the sequential case. This comparison serves to determine whether latent alignment emerges as a consequence of sequential training.

The results in Fig.~\ref{fig:corr_matrix_sf_seq}, representing the sequential case with $sf_s\neq sf_t$, demonstrate positive cosine similarity between latents, although lower than cases with identical scaling factors (Fig.~\ref{fig:corr_matrix_q_seq}). This effect becomes particularly pronounced with increasing disparities between $qp_s$ and $qp_t$.
Notably, configurations where $qp_t < qp_s$ exhibit lower cosine similarity compared to cases where $qp_t > qp_s$, indicating suboptimal conditions for \gls{esqh} operation under such parameters configurations.

The analysis of Fig.~\ref{fig:corr_matrix_sf_ind} reveals that independent model training results in completely unaligned latent spaces, thereby demonstrating that sequential training is the key mechanism enabling latent space alignment. This alignment property facilitates the mapping between latent domains generated under different coding configurations, which is an important factor for the effectiveness of the proposed \gls{esqh} algorithm, showing the advantage of using sequential training.

\subsection{Design of the Scalable Resolution and Quality Hyperprior}

Designing \gls{esqh} to handle latents at different resolutions requires effectively encoding $\y_t$ given known source latents $\hat{\y}_s$.
Since these latents are sparse tensors such that $\y_{s, F} \neq \y_{t, F}$, $\y_{s, C} \neq \y_{t, C}$ then \gls{esqh} requires two main modules.
\begin{enumerate}
    \item A coordinates coding module (referred to as \gls{squlpe}-C) capable of encoding target coordinates $\y_{t, C}$ at higher resolutions w.r.t. the source coordinates $\y_{s, C}$.
    \item A features coding module (referred to as \gls{squlpe}-F) that can estimate probability distributions for target latent representations $\y_{t, F}$ based on the source latents $\y_s$.
\end{enumerate}    

The coordinates coding module becomes essential when $sf_s > sf_t$, as this condition results in a higher resolution for the target block compared to the source block. This resolution disparity is mirrored in the resolution of the latent representations, necessitating the encoding of supplementary information to enable the decoder to reconstruct the higher-resolution coordinates accurately. For this purpose, a lossless geometry coding solution was adopted.
In particular, a set of plausible high-resolution coordinates $\boldsymbol{\Tilde{y}}_{t, C}$ are obtained from $\y_{s, C}$ and then the ground truth target occupancy $GT(\boldsymbol{\Tilde{\y}}_{t, C})$ is losslessly encoded using a probability distribution predicted by the \gls{squlpe}-C model.

On the other hand, \gls{squlpe}-F is needed because the values of the source and target latents are different in both resolution and quality scalability scenarios. This means that a network that can model the target values given the source latents is required. 

\begin{figure*}
    \includegraphics[width=\textwidth]{figures/ESQH.png}
    \caption{Scalable Resolution and Quality Hyperprior coding scheme. In red are the blocks that are relative to the encoding of the coordinates.}
    \label{fig:esqh}
\end{figure*}
The described components form the foundation of \gls{esqh}, a generalization of \gls{sqh}, that extends its functionality to handle varying latents' resolutions. This enhanced coding scheme replaces the original \gls{qulpe} model with \gls{squlpe}, which comprises the two specialized components: \gls{squlpe}-C and \gls{squlpe}-F.

As illustrated in Fig.~\ref{fig:esqh}, the algorithm begins with a base layer generated using a low-rate \gls{jpeg-pcc} bitstream, containing latents, hyper-latents, and coordinates bitstreams (detailed in Section~\ref{sec:jpegpleno}). Enhancement layers are then constructed by stacking \gls{esqh} bitstreams, enabling progressive decoding at higher resolutions and/or qualities. 

When $sf_s = sf_t$, the \gls{esqh} bitstream is equivalent to the standard \gls{sqh} latents bitstream. However, when $sf_s\neq sf_t$, an additional bitstream for upsampling the latents' coordinates is required. Additionally, the receiver does not need a side bitstream for decoding hyper-latents $\hat{\z}$ since $\hat{\y}_s$ serves as the new side information.
More specifically, given a base layer $\hat{\y}_{s}$ encoded with parameters $qp_s, sf_s$ using the \gls{jpeg-pcc} coding procedure, the encoder executes the following sequence to generate higher rate/quality layer bitstreams:

\begin{enumerate}[label=E\arabic*.]
    \item \textit{Higher Rate Latents Generation}: Encode the PC $\x$ using \gls{jpeg-pcc} with target parameters $sf_t$ and $qp_t$ to obtain $\y_{t}$.
    \item \textit{Upsampled Coordinates Probability Estimation}: For cases where $sf_s \neq sf_t$, compute candidate coordinates $\boldsymbol{\Tilde{y}}_{t, C}$ from $\hat{\y}_{s, C}$ and estimate $P(\boldsymbol{\Tilde{y}}_{t, C}|\hat{\y}_{s}, qp_s)$ using \gls{squlpe}-C.
    \item \textit{Coordinates Entropy Encoding}: Generate the \gls{esqh}-C bitstream by entropy encoding the ground truth occupancy $GT(\boldsymbol{\Tilde{\y}}_{t, C})$ using the estimated probability distribution $P(\boldsymbol{\Tilde{y}}_{t, C}|\hat{\y}_{s}, qp_s)$.
    \item \textit{Latents Features Probability Estimation}: Use \gls{squlpe}-F to estimate $\boldsymbol{\mu}_{t}, \boldsymbol{\sigma}_{t}$, assuming independently distributed Gaussian latents: $P(\y_{t, F}|\hat{\y}_{s}, qp_s, qp_t, up) = \mathcal{N}(\boldsymbol{\mu}_{t}, \boldsymbol{\sigma}_{t})$ where $up$ is a variable that specifies if latents super-resolution is required.
    \item \textit{Latents Features Entropy Encoding}: Generate the \gls{esqh}-F bitstream by entropy encoding $\y_{t, F}$ using the estimated parameters $\boldsymbol{\mu}_{t}, \boldsymbol{\sigma}_{t}$.
\end{enumerate}

The entropy modeling procedure in \gls{esqh} closely resembles that of \gls{jpeg-pcc}, as both approaches utilize a hyperprior to estimate a Gaussian prior for the latents. The key distinction in \gls{esqh} is the use of $\hat{\y}_{s}$ as the hyperprior, rather than the hyper-latents $\hat{\boldsymbol{z}}_{t}$ employed in \gls{jpeg-pcc}.

The decoder, after decoding $\hat{\y}_{s}$, can obtain $\hat{\y}_{t}$ through the following sequence of steps:

\begin{enumerate}[label=D\arabic*.]
    \item \textit{Upsampled Coordinates Probability Estimation}: If $sf_s \neq sf_t$, compute the candidate coordinates $\boldsymbol{\Tilde{y}}_{t, C}$ from $\hat{\y}_{s, C}$ and estimate $P(\boldsymbol{\Tilde{y}}_{t, C}|\hat{\y}_{s}, qp_s)$ using \gls{squlpe}-C.
    \item \textit{Coordinates Entropy Decoding}: Entropy decode the ground truth $GT(\boldsymbol{\Tilde{y}}_{t, C})$ from the \gls{esqh}-C bitstream using the estimated probability distribution $P(\boldsymbol{\Tilde{y}}_{t, C}|\hat{\y}_{s}, qp_s)$ 
    \item \textit{Empty Coordinates Pruning}: Refine $\Tilde{\y}_{t,C}$ by pruning candidates that are not actual points based on $GT(\boldsymbol{\Tilde{y}}_{t, C})$, yielding $\y_{t, C}$.
    \item \textit{Latents Features Probability Estimation}: Use the \gls{squlpe}-F model to estimate $\boldsymbol{\mu}_{t}, \boldsymbol{\sigma}_{t}$ for the latents $\hat{\y}_{t}$.
    \item \textit{Latents Features Decoding}: Entropy decode $\hat{\y}_{t, F}$ from the \gls{esqh}-F bitstream using $\boldsymbol{\mu}_{t}, \boldsymbol{\sigma}_{t}$.
    \item \textit{Higher Resolution And/Or Quality PC Reconstruction}: Reconstruct the final \gls{pc} $\hat{\x}_{t}$ using the \gls{jpeg-pcc} decoder applied to $\hat{\y}_{t}$ followed by the SR if specified in the coding parameters.
\end{enumerate}

This process can be iterated as needed to generate multiple enhancement layers, with each new layer serving as the base for the subsequent one.

\subsection{Assumptions on the coding parameters}

To drive the design of the \gls{esqh} algorithm some assumptions on the coding parameters were introduced based on the most commonly used coding configurations for \gls{jpeg-pcc}. These assumptions serve to reduce the complexity of \gls{esqh} while maintaining its effectiveness. The key constraints are as follows:

\begin{enumerate}
\item \gls{esqh} and \gls{squlpe} were designed to handle scaling factors that are powers of 2. Scaling factors that are not powers of 2 can be used as coding parameters for \gls{jpeg-pcc}, but are rarely, if ever, considered.
Moreover, this constraint effectively corresponds to pruning the deepest levels of the octree representing the point cloud.
\item The ratio of scaling factors between consecutive layers is restricted to either $1$ (as in \gls{sqh}) or $2$. Indeed, a ratio $2^n$ can be achieved by applying \gls{esqh} $n$ times thus upscaling the latents by the correct factor. Although the theoretical ratio between scaling factors for consecutive rate points could be as large as the point cloud's resolution, ratios of 4 or greater are rarely used in practice due to the substantial disparity in rate and distortion values between source and target PCs. Furthermore, as evidenced in Fig.~\ref{fig:corr_matrix_sf_seq}, even a ratio of 2 significantly impacts latent alignment, suggesting that larger ratios would further complicate the estimation of probability distributions for target latents.

\end{enumerate}

These constraints are reasonable tradeoffs (as will be shown in Section~\ref{sec:rqulpe results}) that allow to effectively cover the most common coding configurations used in \gls{jpeg-pcc} while maintaining a manageable level of complexity in the design of the \gls{squlpe} model.

\subsection{Coordinates Coding}
The process of applying \gls{esqh} when $sf_s \geq sf_t$ begins with encoding the information necessary to decode the coordinates $\y_{t,C}$.
This is accomplished using \gls{squlpe}-C, which is trained to predict the occupancy probabilities for a given set of target voxels. 
By using transposed sparse convolutions, every source occupied voxel is subdivided into 8 different target voxels (equivalent to creating a new level for the octree), whose coordinates are given by:
\begin{equation}
\hat{\y}_{t, C} = \{2 \cdot \C + [i, j, k] \, | \, \C \in \y_{s, C}, [i, j, k] \in \{0, 1\}^3\}.
\end{equation}

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/p_pred.pdf}
    \caption{Scheme of the \gls{squlpe}-C network used to encode the latents coordinates losslessly.}
    \label{fig:p_predictor}
\end{figure}

Any of the resulting voxels could be empty or occupied in the higher resolution grid, and for this reason 
a ground truth label $GT(\C)$ is computed as: 
\begin{equation}
GT(\boldsymbol{c})
 =
\begin{cases}
    1 & \text{if } \C \in \y_{t, C} \\
    0 & \text{otherwise}
\end{cases}
\end{equation}


\begin{figure*}
    \centering
    \includegraphics[width=.8\textwidth]{figures/squlpe.pdf}
    \caption{Scheme of \gls{squlpe}-F.}
    \label{fig:srqulpe}
\end{figure*}

At this point, the \gls{squlpe}-C model is trained using the cross-entropy loss between its predicted probabilities $P(\hat{\y}_{t, C})$ and the ground truths $GT(\hat{\y}_{t, c})$.
Then, at coding time, the estimated probability distribution $P(\hat{\y}_{t, C})$ serves as the entropy model to encode the ground truth $\tilde{\y}_{t, C} = GT(\hat{\y}_{t, c})$.

The \gls{squlpe}-C model, as illustrated in Fig.~\ref{fig:p_predictor}, is implemented as a sparse convolutional network that predicts $P(\hat{\y}_{t, C}|\hat{\y}_s, qp_s)$. It takes as input the source latents $\hat{\y}_s$ and the source quality parameter $qp_s$ which is transformed into an embedding by feeding its one hot encoding  
$OH(qp_s)$ into an MLP. The embedding is concatenated with $\hat{\y}_s$ and fed into the main network branch, consisting of two sparse convolutional layers and followed by an Inception-ResNet layer. The choice of a relatively simple architecture for \gls{squlpe}-C is justified by the negligible size of the bitstream required to encode $\y_{t, C}$ ($< 4\%$) compared to that needed for $\y_{t, F}$. More complex models, such as autoregressive ones, were deemed unnecessary for this task. This approach enables efficient encoding of the coordinate information necessary for upscaling while maintaining a balance between model complexity and performance.

\subsection{Features Coding}
Using low-quality latents as a base layer to encode higher-quality ones requires designing a model that can predict $P(\y_{t}| \hat{\y}_{s})$. In this case, this probability distribution is modeled as a Gaussian 
 $\mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\sigma})$ as in \cite{minnen2018joint}. This requires a model, from now on referred to as \gls{squlpe}-F, that can handle latents with possibly different resolutions and/or different qualities.
The existing \gls{qulpe} model from \cite{mari2024point} proves inadequate for this task due to its sparse U-Net architecture, which constrains input and output resolutions to be identical. Two potential architectural approaches emerge:
\begin{enumerate}
    \item A dual-model approach, with one model that handles source and target latents obtained with different qualities and one model that handles latents with different resolutions.
This would result in a high number of total network parameters, which is already considerably high (22M in the \gls{qulpe} model \cite{mari2024point}).
    \item A unified architecture approach with a single model that handles all possible latents configurations. This allows reducing to the minimum the additional number of parameters required to achieve joint resolution and quality scalability due to effective usage of the learned parameters.
\end{enumerate}

Given these considerations, the development focused on a novel architectural approach that minimizes additional parameters while enabling joint resolution and quality scalability.
Motivated by recent results in many different fields including \gls{pc} coding, an architecture based on the attention layers proposed for \gls{pct} \cite{wu2022point} was adopted instead of sparse convolutions. 
The reason for this choice is that these architectures do not require matching input and output coordinates, which enables a single model to handle various combinations of resolutions and qualities simultaneously. As demonstrated in Section~\ref{sec:rqulpe results}, transformer-based models can achieve comparable or superior performance to sparse convolution models with a reduced overall parameter count, enhancing computational efficiency.

A \gls{pct} layer takes two sparse tensors as inputs. When these are identical then the layer is referred to as a self-attention layer, while if they are different (e.g., one represents the source latents while the other the target latents), then it is referred to as a cross-attention layer. Using cross-attention proves particularly effective since it allows using known information (the source latents) to improve the estimated probability distribution for the target parameters. A key feature of the cross-attention layer is its ability to consistently output a tensor with dimensions matching those of the second input in terms of point count and coordinates.

Under these considerations the steps taken by the \gls{squlpe}-F model (see the architecture in Fig.~\ref{fig:srqulpe}) to predict the probability of the target latents features $\y_{t, F}$ are:
\begin{enumerate}
    \item \textit{Coarse estimate for the target latents}: Generate an initial estimate $\Tilde{\y}_{t}$ of the target latents. In particular for each coordinate in $\y_{t, C}$ (which is already available through the previous lossless encoding step using \gls{squlpe}-C), the features of its nearest neighbors in $\hat{\y}_{s}$, denoted as $\boldsymbol{\kappa}_{y_s, F}$, are averaged to obtain $\Tilde{\y}_{t}$.
    \item \textit{Embedding of the coding parameters}: Embed the quality parameters $qp_s, qp_t$, and a boolean $up$, indicating if $\frac{sf_s}{sf_t} = 2$, into an embedding vector computed by feeding the one-hot encodings of the coding parameters into a shared multilayer perceptron (MLP), following the approach introduced in \cite{mari2024point}.
    \item \textit{Integration of the latents and the embedding}: Integrate $\hat{\y}_s$ and $\Tilde{\y}_{t}$ with the corresponding embeddings via concatenation to obtain $\hat{\y}_s^\prime$ and $\Tilde{\y}_{t}^\prime$.
    \item \textit{Refinement of the target latents estimate}: Refine the estimate $\Tilde{\y}_{t}^\prime$ through cross-attention with the source latents $\hat{\y}_s^\prime$ to obtain $\Tilde{\y}_{t}^{\prime\prime}$ 
    \item \textit{Prediction of the latents probability}: Process $\Tilde{\y}_{t}^{\prime\prime}$ through some self attention layers to predict the parameters $\boldsymbol{\mu}_t, \boldsymbol{\sigma}_t$ describing the probability distribution of the target latents
\end{enumerate}

\begin{figure*}
    \centering
    \includegraphics[width=.7\textwidth]{figures/pct.pdf}
    \caption{Scheme of the adopted attention layer.}
    \label{fig:pct}
\end{figure*}


This specific architectural choice enables the model to seamlessly handle scenarios where $\y_{s, C}=\y_{t,C}$ (implying $sf_{s}=sf_t$) as well as cases where $\y_{s, C}\neq\y_{t,C}$ (indicating $sf_{s} \neq sf_t$).

The next subsections will elaborate further on each specific step and their implementation details.

\subsubsection{\textbf{RQuLPE-F inputs}}
One of the inputs to the model is the initial estimation of the target parameters $\Tilde{\y}_{t}$ which was obtained by averaging the latents of the nearest neighbors. Alternative approaches for this initial estimation were explored, such as distance-weighted averaging schemes, these variations did not yield significant improvements in the final rate-distortion performance and were thus discarded.

As additional inputs the model takes the coding parameters $qp_s, qp_t, up$, however, while the quality parameters $qp_s$ and $qp_t$ are directly input to the model, the resolution information is simplified to the boolean $up$. This design choice allows for scalability across the most commonly used scaling factor ($sf$) values in \gls{jpeg-pcc}, which are typically powers of 2. The decision to handle only the case where $sf_s=2sf_t$ is based on the observation that larger ratios lead to poorly aligned latents, which the model struggles to exploit effectively. This suggests that employing multiple enhancement layers with a scaling factor ratio of 2 is a more efficient strategy than training a model to handle ratios exceeding 2.

The use of a boolean $up$ flag instead of explicit scaling factors is motivated by the understanding that the critical information is whether the latent resolutions differ, rather than their specific values. This is caused by the fact that point distributions (and consequently, latent representations) at various resolutions are heavily influenced by the original point distribution, which is unknown to the decoder. Therefore, explicit knowledge of $sf_s$ and $sf_t$ is unlikely to provide significant benefits and might potentially lead to overfitting.

\subsubsection{\textbf{Attention layers architecture}}

The attention architecture adopted in this work is depicted in Fig.~\ref{fig:pct}. The particular design of the layer allows for the exploitation of information from the first input $\y_a$ to enhance the representation of the second input $\y_b$. Through the computation of keys and values from $\y_a$ and queries from $\y_b$, the architecture enables the generation of a residual update for $\y_b$ based on a linear combination of values in $\y_a$.

In the architecture, $\K_{\y_a} = (\K_{\y_a,C}, \K_{\y_a,F})$ represents the nearest neighbors in $\y_a$ for each point in $\y_b$, with the neighboring relationship determined in the coordinate domain. While maintaining the core operations proposed in the original \gls{pct} work \cite{wu2022point}, this implementation extends beyond the original model by incorporating both self-attention and cross-attention mechanisms. Furthermore, it employs vector attention instead of grouped vector attention, with the number of selected groups set equal to the size of the vectors.

The choice of vector attention is particularly motivated by the nature of the latents produced by \gls{jpeg-pcc}, which are not computed using grouped vector attention. These latents lack specific structural organization along the channel dimension, making arbitrary channel grouping potentially suboptimal for overall performance. Therefore, processing each channel independently is considered more appropriate for this specific application, as it better aligns with the inherent characteristics of the \gls{jpeg-pcc} latent representations. This tailored approach to transformer architecture design enables more effective handling of \gls{jpeg-pcc} latents, potentially leading to improved RD performance.

A key design decision in all attention layers present in the \gls{squlpe}-F model is the use of 5 neighbors for the k-nearest neighbors (KNN) algorithm. This choice was taken after empirical testing revealed that increasing the neighbor count beyond 5 did not yield significant performance improvements but did increase computational complexity. 


\subsection{Training and Evaluation}
The training and validation procedures for \gls{esqh} incorporate updates from the JPEG Pleno PCC Common Training and Testing Conditions \cite{jpeg-pleno-cttc}, reflecting modifications to both training and test sets to encompass a broader range of point cloud characteristics. These updated datasets, detailed in \cite{jpeg-pleno, jpeg-pleno-cttc}, were employed for training and evaluating both \gls{squlpe}-F and \gls{squlpe}-C components.

The latent representations were generated using \gls{jpeg-pcc} with quality parameters $qp \in {1, 2, 3, 4, 5}$ and scaling factors $sf \in {1, 2, 4}$ for each training and validation block. \gls{squlpe}-C and \gls{squlpe}-F are trained independently, as \gls{squlpe}-C's lossless coding objective for latent coordinates allows the use of ground truth during \gls{squlpe}-F training. Training and validation point clouds were segmented into $128\times 128\times 128$ blocks, an increase from the previous $64\times 64\times 64$ dimension, to better accommodate downscaling operations in conjunction with the intrinsic downscaling introduced by the analysis transform of \gls{jpeg-pcc}.

During training, at each gradient update step, a tuple ($qp_s, qp_t, sf_s, sf_t$)
is selected for each training PC block with uniform probability, and the
corresponding latents $\hat{\y}_s$, $\y_{t}$ are loaded accordingly from memory. 
This sampling strategy ensures comprehensive coverage of all possible configurations encountered during inference.
The validation phase implements an exhaustive evaluation across all parameter combinations, ensuring consistent validation loss measurements throughout the training epochs. 

Parameter combination selection differs between \gls{squlpe}-C and \gls{squlpe}-F, reflecting their distinct operational requirements:
\begin{itemize}
\item \gls{squlpe}-C: $qp_s \in {1, 2, 3, 4, 5}, sf_s = 2sf_t$, as the model specifically addresses latent resolution upscaling scenarios, disregarding $\y_{t, F}$.
\item \gls{squlpe}-F: $qp_s \leq qp_t + 1, 1\leq sf_s/sf_t \leq 2$, accommodating all permissible parameter combinations.
\end{itemize}

When training \gls{squlpe}-F, the quality parameter variations were constrained to $qp_s \leq qp_t + 1$ since values outside this range are rarely used in \gls{jpeg-pcc}.
While the condition $qp_s > qp_t$ can occur when $sf_s > sf_t$ (as downscaling often necessitates decreasing quality parameters for consecutive rate points), Fig.~\ref{fig:corr_matrix_sf_seq} indicates that the correlation between latents with different scaling factors and decreasing QPs is generally low. Preliminary tests revealed that training outside this range negatively impacts coding performance without providing substantial benefits.

\gls{squlpe}-C is trained with the loss function
\begin{equation}
    \mathcal{L}(\y_{t, C}, \hat{\y}_s )= \mathcal{H}(\y_{t, C}|\hat{\y}_s, qp_s)
\end{equation}

while \gls{squlpe}-F was trained to minimize
\begin{equation}
\mathcal{L}(\y_{t}, \hat{\y}_s) = \mathcal{H}(\y_{t}|\hat{\y}_s, \y_{t, C}, qp_s, qp_t, up)
\end{equation}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/TestDataset.png}
    \caption{JPEG Pleno PCC test dataset. From left to right starting from the first row there are: Arco Valentino, CITIUSP, ULB Unicorn, House without roof, Boxer, Thaidancer, Bouquet, Soldier, EPFL, Facade 000009, Saint Michael, Shiva.}
    \label{fig:test_data}
\end{figure*}

The absence of a distortion component aligns with the objective of lossless encoding of $\y_t$ with minimal bit consumption. The optimization process utilizes the Adam optimizer with an initial learning rate of $10^{-3}$, implementing an exponential decay factor of 10 following 7 epochs without improvement. The training procedure incorporates early stopping, thus terminating when the validation error remains stagnant for 10 consecutive epochs.