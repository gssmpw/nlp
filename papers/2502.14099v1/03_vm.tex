\section{JPEG Pleno Point Cloud Geometry Codec and Previous Extension for Quality Scalability}
\label{sec:vm}

\begin{figure*}
    \centering
    \includegraphics[width=.9\textwidth]{figures/jpeg_pleno_high_level.pdf}
    \caption{High-level scheme of the coding procedure for PC geometry in \gls{jpeg-pcc}.}
    \label{fig:high-level-scheme}
\end{figure*}

\label{sec:jpegpleno}
The \gls{esqh} method proposed in this paper is implemented on top of the verification model software for the \gls{jpeg-pcc} standard \cite{jpeg-pleno}, which will be presented next in this section. After that, \gls{sqh} \cite{mari2024point}, a previously proposed solution for implementing quality scalability in \gls{jpeg-pcc} for geometry coding, which served as the basis for the \gls{esqh} method, will be described.

\subsection{JPEG Pleno Point Cloud Codec}

\gls{jpeg-pcc} is the JPEG standard for PC coding, which uses a learning-based approach for coding both PC geometry and color attributes \cite{guarda2023point}.
The geometry coding in \gls{jpeg-pcc} utilizes a deep learning model structured as an autoencoder, complemented with a variational autoencoder model that determines a mean and scale hyperprior that improves the performance for entropy coding the compressed domain latent representation \cite{minnen2018joint}. To enhance compression performance, particularly for sparse PCs and lower-rate coding scenarios, \gls{jpeg-pcc} incorporates two additional tools:
\begin{enumerate}
    \item A down-scaling module using a scaling factor parameter, $sf$.
    \item A deep learning-based super-resolution (SR) module to improve reconstruction quality when down-scaling is applied.
\end{enumerate}

\gls{jpeg-pcc} adopts a sparse tensor representation \cite{choy20194d} for geometry coding, offering advantages in both computational complexity and rate-distortion performance. In this representation, PCs are described as a tuple $\bm{x}=(\bm{x}_C, \bm{x}_F)$, where $\bm{x}_C$ represents the coordinates of non-empty voxels, and $\bm{x}_{F}$ denotes the corresponding features (initially set to "1" to indicate occupied voxels).

For encoding the color attributes, JPEG
PCC projects texture patches onto an image (similarly to V-PCC \cite{V-PCC}) which is then coded using the emerging JPEG AI codec \cite{jpeg-ai}.
Since the focus of this paper lies in geometry coding, the remaining of this section will focus only on this component.

A high-level description of the full geometry coding and decoding procedures is shown in Fig.~\ref{fig:high-level-scheme}. Specifically, to encode the geometry of a point cloud $\bm{P} \in \mathbb{R}^3$, the encoder performs the following operations:


\begin{figure*}
    \centering
    \includegraphics[width=.9\textwidth]{figures/jpeg-pcc.pdf}
    \caption{Model architecture of the deep learning based codec in \gls{jpeg-pcc} (\gls{dl}-based Geometry Encoder and \gls{dl}-based Geometry Decoder in Fig.~\ref{fig:high-level-scheme}).}
    \label{fig:dl-scheme}
\end{figure*}

\begin{enumerate}[label=E\arabic*.]
    \item \textit{Downscaling}: The input PC is downscaled by a factor $sf$ through the operation $\boldsymbol{P}^\prime = \lceil \boldsymbol{P}/sf \rfloor$.
    \item \textit{Block Split}: The downscaled points are divided into non-overlapping blocks $\x_{l, C} \in \mathbb{R}^3, l \in {1, \dots, N}$ of size $bs$, such that $\boldsymbol{P}^\prime = \bigcup_{l=1}^{N} \x_{l, C}$.
    \item \textit{Sparse Tensor Construction}: For each block, a sparse tensor representation $\x_l = (\x_{l, C}, \x_{l, F})$ is created, where $\x_{l, F}$ contains ones to indicate occupied voxels.
    \item \textit{DL-Based Encoding}: The blocks are processed through the deep learning-based coding procedure to generate the bitstream
    \item \textit{Distortion Optimization}: Two parameters per block, $k_l$ and $k_{SR, l}$, are computed and added to the bitstream. These parameters represent the optimal number of points to be retained in the decoded block (with and without super-resolution) to minimize a chosen distortion metric.
\end{enumerate}

At the decoder side, the PC reconstruction process consists of the following operations:
\begin{enumerate}[label=D\arabic*.]
    \item \textit{DL-Based Decoding}: The decoder reconstructs the blocks $\hat{\x}_l$ by inputting the compressed domain latent representation, extracted from the bitstream, in the DL-based decoder.
    \item \textit{Top-K Points Selection}: For each decoded block $\hat{\x}_l$, only the $k_l$ points with the highest occupancy probabilities are retained, ensuring optimal point selection.
    \item \textit{Upscaling}: The blocks are upscaled according to scaling factor $sf$ (included in the bitstream) to restore the original spatial resolution.
    \item \textit{Super-Resolution}: When super-resolution is enabled ($SR=1$), the upscaled blocks are processed through the SR network to obtain enhanced blocks $\hat{\x}_{SR, l}$.
    \item \textit{Post-SR Top-K Point Selection}: From each super-resolved block, the $k_{SR,l}$ points with the highest probability values are selected, ensuring optimal point selection.
    \item \textit{Block Merge}: Finally, all processed blocks are merged to reconstruct the complete point cloud geometry $\hat{\boldsymbol{P}}$.
\end{enumerate}

The deep learning-based encoding (and decoding) process for each block $x_l$, is illustrated in Fig.~\ref{fig:dl-scheme}. It consists of the following sequence of operations:

\begin{enumerate}[label=E\arabic*.]
    \item \textit{Latents Generation}: Generate latents $\y_l = (\y_{l, C}, \y_{l, F})$ through the analysis transform $\mathcal{G}_a$, expressed as $\y_l=\mathcal{G}_a(\x_l)$.
    \item \textit{Coordinates Encoding}: code the latent coordinates $\y_{l, C}$ using an octree encoder to generate the coordinates bitstream.
    \item \textit{Hyper-Latents Generation}: Generate hyper-latents $\z_l$ using the hyper-analysis transform $\mathcal{HG}_a$, where $\z_l=\mathcal{HG}_a(\y_l)$.
    \item \textit{Hyper-Latents Quantization}: Quantize the hyper-latent features to obtain $\hat{\z}_{l, F} = \lceil \z_{l, F} \rfloor$.
    \item \textit{Entropy Coding}: Apply rANS entropy coding to the hyper-latents according to a fully factorized prior $p(\hat{\z}_{l, F})$ to generate the hyper-latents bitstream.
    \item \textit{Sparse Tensor Construction}: Reconstruct the quantized hyper-latents' sparse representation as $\hat{\z}_l = (\z_{l, C}, \hat{\z}_{l, F})$.
    \item \textit{Latents Distribution Estimation}: Process $\hat{\z}_l$ through hyper-synthesis transforms $\mathcal{HG}_{s, \mu}$ and $\mathcal{HG}_{s, \sigma}$ to estimate Gaussian parameters $\boldsymbol{\mu}_l = \mathcal{HG}_{s, \mu}(\hat{\z}_l), \boldsymbol{\sigma }_l= \mathcal{HG}_{s, \sigma}(\hat{\z}_l)$. 
    \item \textit{Residual Encoding}: Calculate and encode quantized residuals $\boldsymbol{r}_l= \lceil \y_{l,F} - \boldsymbol{\mu}_l \rfloor$ using $\mathcal{N}(\boldsymbol{0}, \boldsymbol{\sigma}_l)$ to produce the final latents bitstream.
\end{enumerate}

Conversely, a receiver that needs to decode the blocks from the bitstream will have to:

\begin{enumerate}[label=D\arabic*.]
    \item \textit{Coordinates Decoding}: Losslessly decode $\y_{l, C}$ from the coordinates bitstream.
    \item \textit{Hyper-latents Decoding}: Entropy decode $\hat{\z}_{l, F}$ from the hyper-latents bitstream using the probability distribution $p(\hat{\z}_{l, F})$.
    \item \textit{Coordinates Down-scaling}: Down-scale $\y_{l, C}$ by a factor of 4 (as determined by the stride parameters in $\mathcal{HG}_a$'s convolutional layers) to obtain $\z_{l, C}$.
    \item \textit{Hyper-Latents Sparse Tensor Construction}:  Build the sparse representation of hyper-latents as $\hat{\z}_l = (\z_{l, C}, \hat{\z}_{l, F})$.
    \item \textit{Latents Distribution Estimation}:  Compute Gaussian parameters using hyper-synthesis transforms as $\boldsymbol{\mu}_l = \mathcal{HG}_{s, \mu}(\hat{\z}_l), \boldsymbol{\sigma }_l= \mathcal{HG}_{s, \sigma}(\hat{\z}_l)$.
    \item \textit{Residuals Decoding}: Entropy decode $\boldsymbol{r}_l$ from the latents' bitstream using $\mathcal{N}(\boldsymbol{0}, \boldsymbol{\sigma}_l)$.
    \item \textit{Latent Features Reconstruction}: Recover the latent features $\hat{\y}_{l, F} = \boldsymbol{\mu}_l + \boldsymbol{r}_l$.
    \item \textit{Latents Sparse Tensor Construction}: Reconstruct the sparse representation of latents as $\hat{\y}_l = (\y_{l, C}, \hat{\y}_{l, F})$.
    \item \textit{Block Reconstruction}: Apply the synthesis transform $\mathcal{G}_s$ to the decoded latents to determine the probability for the occupancy state of each voxel in the reconstruct the block: $\hat{\x}_l = \mathcal{G}_s(\hat{\y}_l)$. 
\end{enumerate}

The model training follows an end-to-end approach incorporating all previously described operations except for two differences: quantization is replaced by a differentiable approximation and entropy coding is removed, to ensure full model differentiability. The training utilizes a rate-distortion optimization framework defined by the loss function:
\begin{equation}
    \mathcal{L}(\bm{x}, \hat{\bm{x}}, \bm{y}, \bm{z}) = \mathcal{D}(\bm{x}, \hat{\bm{x}}) + \lambda\mathcal{H}(\bm{y}, \bm{z}),
\end{equation}
where $\mathcal{D}(\cdot, \cdot)$ is the distortion, measured as the focal loss \cite{lin2017focal}, $\mathcal{H}(\cdot, \cdot)$ denotes the entropy of the bitstream components under the probability distributions $p(\hat{\bm{z}})$ and $p(\bm{y}|\hat{\bm{z}})$, and $\lambda$ controls the rate-distortion trade-off.
Generally, one model is trained for each RD point corresponding to one value of $\lambda$. In \gls{jpeg-pcc}, five different coding models are trained to support the defined range of tradeoffs.
The training procedure is carried out by sequentially spanning the chosen values of $\lambda \in \{0.0025, 0.005, 0.01, 0.025, 0.05\}$, using the checkpoint for the previous $\lambda$ as a starting point, progressively moving from the lowest value (highest rate/quality) to the highest one (lowest rate/quality). These five models naturally define a quality parameter $qp \in \{1, \dots , 5\}$, with $qp = 1$ corresponding to $\lambda = 0.05$ (lowest rate/quality) and $qp = 5$ to $\lambda = 0.0025$ (highest rate/quality).

\subsection{Scalable Quality Hyperprior}

The \gls{esqh} method proposed in this paper follows a previous work \cite{mari2024point} that introduced a quality scalability algorithm, known as \gls{sqh}. \gls{sqh} constructs a quality scalable bitstream by leveraging information from latents $\y_i$ obtained at a lower \gls{qp} ($qp=i$) to predict probability distributions for latents $\y_j$ at a higher \gls{qp} ($qp=j$).

Starting from a low-quality base layer of latents $\y_i$, which have already been encoded, the encoder must execute the following sequence of steps to generate a new enhancement layer:

\begin{enumerate}[label=E\arabic*.]
    \item \textit{Higher Quality Latents Generation}: Generate new latents $\y_{j}$ using the \gls{jpeg-pcc} coding model with $qp = j > i$.
    \item \textit{Latents Distribution Estimation}: Predict the means and standard deviations of the
latents $\y_{j}$ based on the previous latents $\y_{i}$, using the \gls{dl}-based \gls{qulpe} model
(detailed in \cite{mari2024point}) as $\boldsymbol{\mu}_j$, $\boldsymbol{\sigma}_j = QuLPE(\hat{\y}_i, i, j)$, under the assumption of independently distributed Gaussian latents, $P(\y_j|\hat{\y}_i)$.
    \item \textit{Entropy Coding}: Generate the \gls{sqh} bitstream by entropy encoding $\y_j$ using $\boldsymbol{\mu}_j$, $\boldsymbol{\sigma}_j$.
\end{enumerate}

\gls{sqh} employs a Mean and Scale Hyperprior entropy model, analogous to \gls{jpeg-pcc}. The key distinction lies in \gls{sqh}'s utilization of previously decoded latents $\hat{\y}_i$ as side information, rather than hyper-latents $\hat{\z}_j$.


To reconstruct the higher rate/quality PC, the decoder, which can access the base layer information $\hat{\y}_i$, performs the following decoding procedure:
\begin{enumerate}[label=D\arabic*.]
    \item \textit{Latents Distribution Estimation}: Derive $\boldsymbol{\mu}_{j}$, $\boldsymbol{\sigma}_{j} = QuLPE(\hat{\y}_i, i, j)$ from the base layer information $\hat{\y}_i$ using the \gls{qulpe} model.
    \item \textit{Higher Quality Latents Decoding}: Decode the higher quality latents $\hat{\y}_{j}$ by applying a rANS decoder to the \gls{sqh} bitstream using the estimated distribution.
    \item \textit{Higher Quality PC Reconstruction}: Reconstruct the higher quality PC by processing the decoded latents through the \gls{jpeg-pcc} synthesis transform as $\hat{\x}_{j} = \mathcal{G}_{s, j}(\hat{\y}_{j})$.
    \item \textit{Super Resolution}: If specified in the coding parameters the Super Resolution model is used to enhance the decoded blocks
\end{enumerate}

While \gls{sqh} effectively handles quality scalability through latents refinement, it faces limitations when dealing with \gls{jpeg-pcc}'s downscaling strategy. The challenge arises because varying $sf$ produces latents at different resolutions, a scenario not supported by \gls{sqh}'s U-Net-based \gls{qulpe} model, which requires consistent input-output dimensions. This architectural constraint, coupled with the absence of a multi-resolution handling strategy, restricts \gls{sqh}'s practical applicability. 

The next sections introduce and evaluate \gls{esqh}, an enhanced framework that addresses these limitations by enabling joint quality and resolution scalability in the latent domain. These functional advantages are relevant in the framework of the \gls{jpeg-pcc} codec, but also for the generalization of the \gls{esqh} method for other autoencoder-based codecs.
