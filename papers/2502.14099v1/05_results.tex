

\begin{table*}
    \caption{Coding parameters for JPEG PCC expressed as the tuple $qp, sf, SR$ where $SR \in \{T, F\}$ decides if the super-resolution module in \gls{jpeg-pcc} is used/not used.}
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
    Type & PC & model & r1 & r2 & r3 & r4 & r5 \\
    \hline
    \multirow{8}{*}{Solid} & \multirow{2}{*}{StMichael} & \gls{jpeg-pcc} & 2, 4, T & 3, 2, T & 3, 1, F& 5, 1, F & \\
    &  & \gls{esqh} & 2, 4, T & 3, 2, T & 3, 1, F & 5, 1, F & \\
    \cline{2-8}
    & \multirow{2}{*}{Bouquet} & \gls{jpeg-pcc} & 5, 4, T & 3, 1, F  & 4, 1, F& 5, 1, F & \\
    &  & \gls{esqh} & 5, 4, T & \textcolor{red}{4, 2, T} & 3, 1, F  & 4, 1, F & 5, 1, F\\
    \cline{2-8}
    & \multirow{2}{*}{Soldier} & \gls{jpeg-pcc} & 3, 4, T & 3, 2, T & 3, 1, F& 4, 1, F & \\
    &  & \gls{esqh} &  3, 4, T & 3, 2, T & 3, 1, F& 4, 1, F & \\
    \cline{2-8}
    & \multirow{2}{*}{Thaidancer} & \gls{jpeg-pcc} & 2, 4, T & 2, 2, T & 2, 1, F& 4, 1, F & \\
    &  & \gls{esqh} &  2, 4, T & 2, 2, T & 2, 1, F& 4, 1, F & \\
    \hline
    \multirow{8}{*}{Dense} & \multirow{2}{*}{Boxer} & \gls{jpeg-pcc} & 1, 4, T & 2, 2, T & 5, 2, T & 4, 1, F & \\
    &  & \gls{esqh} & 1, 4, T & 2, 2, T & 5, 2, T& 4, 1, F & \\
    \cline{2-8}
    & \multirow{2}{*}{House wo roof} & \gls{jpeg-pcc} & 2, 4, T & 3, 2, T  & 4, 1, F& 5, 1, F & \\
    &  & \gls{esqh} & 2, 4, T & 3, 2, T  & 4, 1, F& 5, 1, F & \\
    \cline{2-8}
    & \multirow{2}{*}{CITIUSP} & \gls{jpeg-pcc} & 1, 4, F & 4, 4, F & 4, 2, F& 5, 2, T & \\
    &  & \gls{esqh} & 1, 4, F & 4, 4, F & 4, 2, F& 5, 2, T & \\
    \cline{2-8}
    & \multirow{2}{*}{Facade 00009} & \gls{jpeg-pcc} & 2, 4, T & 3, 2, T & 4, 1, F& 5, 1, F & \\
    &  & \gls{esqh} &   2, 4, T & 3, 2, T & 4, 1, F& 5, 1, F & \\
    \hline
    \multirow{8}{*}{Sparse} & \multirow{2}{*}{EPFL} & \gls{jpeg-pcc} & 1, 4, F & 4, 4, F & 4, 2, F& 5, 2, F & \\
    &  & \gls{esqh} & 1, 4, F & 4, 4, F & 4, 2, F& 5, 2, F & \\
    \cline{2-8}
    & \multirow{2}{*}{Arco Valentino} & \gls{jpeg-pcc} & 1, 4, F & 3, 4, F & 4, 2, F& 5, 2, F & \\
    &  & \gls{esqh} & 1, 4, F & 3, 4, F & 4, 2, F& 5, 2, F & \\
    \cline{2-8}
    & \multirow{2}{*}{Shiva} & \gls{jpeg-pcc} & 2, 4, F & 3, 2, F & 5, 2, T& 4, 1, F & \\
    &  & \gls{esqh} & 2, 4, F & 3, 2, F & 5, 2, T& 4, 1, F & \\
    \cline{2-8}
    & \multirow{2}{*}{ULB Unicorn} & \gls{jpeg-pcc} & 2, 4, F & 3, 4, F & 5, 4, F& 4, 2, F & \\
    &  & \gls{esqh} & 2, 4, F & 3, 4, F & 5, 4, F& 4, 2, F & \\
    \hline
    \end{tabular}
    \label{tab:coding params}
\end{table*}

\section{Performance Assessment for JPEG-PCC with SRQH}
\label{sec:rqulpe results}
This section presents the experimental setup and the performance assessment of the proposed \gls{esqh} implemented on top of \gls{jpeg-pcc}.
\subsection{Test Dataset}

The experimental evaluation utilized the JPEG Pleno PCC test dataset (Fig.~\ref{fig:test_data}), adhering to the Common Training and Test Conditions \cite{jpeg-pleno-cttc}. The test dataset comprises twelve point clouds, categorized into solid, dense, and sparse based on the MPEG-defined average local point density criteria, as detailed in Table~\ref{tab:coding params}.
\subsection{Coding Configurations}
The coding configurations utilized for coding the test dataset with \gls{jpeg-pcc} and \gls{squlpe} are documented in Table~\ref{tab:coding params}. These were derived for \gls{jpeg-pcc} by Guarda et.al. \cite{guarda2024jpeg} by optimizing the PCQM metric \cite{meynet2020pcqm} while meeting the target rates specified in the CTTC.
Regarding block size configuration, the coding configurations in Table~\ref{tab:coding params} were obtained with a block size of $128$. However, when using different SF parameters, since the blocks are partitioned after downscaling, the latents would correspond to different regions of the PC, thus preventing \gls{squlpe} from working correctly. For this reason, to provide a fair comparison between \gls{jpeg-pcc} and \gls{squlpe}, the block sizes used to code the PCs with \gls{jpeg-pcc}
were set to values equivalent to the ones enforced by \gls{esqh}. Specifically, the block size was defined as $128 \cdot sf_4/sf_1$, where $sf_1$ and $sf_4$ denote the scaling factors for the initial and final rate points respectively, ensuring a consistent block size of 128 at the final rate point.

An analysis of the configurations reveals that the vast majority of cases for \gls{jpeg-pcc} align with the constraints outlined in Section~\ref{sec:extending_sqh}. A single exception is observed for the \textit{Bouquet} point cloud, where the first and second rate points exhibit $sf_s=4, sf_t=1$ and $qp_s = qp_t + 2$, slightly deviating from the specified constraints.
To address this isolated case, the configurations for \gls{esqh} were adjusted to ensure full compliance with the established constraints, as reflected in Table~\ref{tab:coding params}. Importantly, this adjustment was implemented without compromising the integrity of the original coding configurations. The modification involved the inclusion of a single additional RD point to facilitate a smooth transition between two configurations with $sf_s=4, sf_t=1$, while all other RD points remained unaltered.


\begin{figure*}
    \centering
    \includegraphics[width=.8\textwidth]{figures/avg_jpeg}
    \caption{Average over the test set of the RD curves for \gls{jpeg-pcc} based solutions.}
    \label{fig:avg_jpeg}
\end{figure*}


This scenario underscores the robustness and flexibility of the implemented constraints. Their ability to accommodate the optimal configurations for the entire test set, with only minimal adjustments required in a single instance, demonstrates their practical applicability and effectiveness in real-world scenarios. The constraints thus prove to be sufficiently versatile to address the diverse requirements of point cloud coding across the test dataset.

\subsection{Metrics}
The assessment of decoded point clouds employed point-to-point PSNR (PSNR D1) and point-to-plane PSNR (PSNR D2) as quality metrics, while the bitrate was quantified using bits-per-(original)-point (bpp). The rate-distortion (RD) performance comparison against other anchors was evaluated using Bjontegaard delta rate and delta PSNR metrics.

\subsection{Baselines and Anchors}

The codec chosen as a baseline is \gls{jpeg-pcc} v4.0, i.e., the non-scalable codec serving as basis for the proposed \gls{esqh}

Additionally, another solution was evaluated, called \gls{esqh}-hybrid which is a hybrid scalable algorithm that selectively employs \gls{qulpe} for quality scalability ($sf_s = sf_t$) and \gls{squlpe} for resolution scalability ($sf_s \neq sf_t$).
This serves as an ablation study to investigate the potential advantages of utilizing specialized models for each scalability type versus a unified approach. For this comparative analysis, the \gls{qulpe} model underwent complete retraining using the updated training dataset.

Among the most widespread codecs, the ones that provide scalability for geometry coding are the conventional G-PCC and the learning-based SparsePCGC \cite{wang2022sparse} and Unicorn, \cite{wang2024versatile1,wang2024versatile2}
whose code and weights were unfortunately not publicly available when this work was developed.

For this reason, most of the codecs chosen as anchors do not provide any form of scalability. The chosen conventional anchors are: 
\begin{enumerate}
    \item G-PCC Octree v23.
    \item V-PCC Intra v24.
\end{enumerate}
while the chosen learning-based anchors are:
\begin{enumerate}
    \item GRASP-Net \cite{pang2022grasp}.
    \item PCGCv2 \cite{wang2021lossy}.
\end{enumerate}




 
Among these only G-PCC provides scalability (in particular resolution scalability) while all the other solutions are non-scalable.
To compare scalable and non-scalable solutions the RD curves for the scalable solutions were obtained by setting the quality metric for a specific rate point as the maximum possible quality obtainable with that bitstream.

\begin{table*}
    \centering
    \caption{Bjontegaard metrics of \gls{esqh} with reference to \gls{jpeg-pcc} based solutions.}
    \includegraphics[width=.9\textwidth]{figures/bd_jpeg}
    \label{fig:bd_rqulpe_jpeg}
\end{table*}
\begin{figure*}
    \centering
    \includegraphics[width=.8\textwidth]{figures/avg_others}    
    \caption{Average RD curves when comparing against anchors that are not based on \gls{jpeg-pcc}.}
    \label{fig:rd_rqulpe_others}
\end{figure*}

\subsection{Performance Assessment}
This section presents the results obtained by the proposed solution against the baselines and the other anchors.

\subsubsection{\gls{esqh} versus JPEG-PCC-based coding solutions}

Firstly, in order to understand how much \gls{esqh} affects RD performance, it will be compared with non-scalable \gls{jpeg-pcc} and 
\gls{esqh}-hybrid. The RD curves obtained from the three solutions can be seen in Fig.~\ref{fig:avg_jpeg}
where their average over the whole test set is shown.

The results demonstrate that \gls{esqh} maintains performance comparable to \gls{jpeg-pcc}, with \gls{esqh} and \gls{esqh}-hybrid exhibiting nearly identical average performance. 
This achievement is particularly significant as it indicates that \gls{esqh} successfully implements full resolution and quality scalability while incurring minimal rate overhead compared to the non-scalable \gls{jpeg-pcc} solution. 

The Bjontegaard metrics in Table~\ref{fig:bd_rqulpe_jpeg} quantify the performance differences, revealing that the price to be paid for scalability is within 5-9\% across different PC categories which is acceptable for such an important feature. The most challenging case is observed for the \textit{Bouquet} point cloud, attributable to the fact that two consecutive configurations were not compliant with the constraints set before, since $sf_s/sf_t = 4$. This required adding an extra enhancement layer, thus increasing the price for scalability; additionally, the resulting configurations have $qp_s > qp_t$, thus a lower latent alignment.

The comparable performance between \gls{esqh} and \gls{esqh}-hybrid suggests that employing separate models for quality ($sf_s = sf_t$) and resolution ($sf_s \neq sf_t$) scalability offers no substantial benefits. In fact, \gls{esqh} slightly outperforms \gls{esqh}-hybrid on average, suggesting that exposure to diverse parameter configurations during training provides a beneficial regularizing effect. This finding favors the adoption of the proposed single unified \gls{squlpe} model, which achieves similar or slightly better rate-distortion performance with significantly lower computational complexity (4.7M parameters versus \gls{qulpe}'s 22M parameters). This additionally proves the effectiveness of \gls{pct} for this task which achieves similar performance with fewer network parameters than a much larger model based on sparse convolutions.

\begin{table*}
    \centering
    \caption{BD-Rate of \gls{esqh} with reference to G-PCC and V-PCC.}
    \includegraphics[width=.9\textwidth]{figures/bd_standards}
    \label{fig:bd_rqulpe_standards}
\end{table*}

\begin{table*}
    \centering
    \caption{BD-Rate of \gls{esqh} with reference to GRASP-Net and PCGCv2.}
    \includegraphics[width=.9\textwidth]{figures/bd_learned}
    \label{fig:bd_rqulpe_others}
\end{table*}


As a final test \gls{esqh} was also compared with a naive scalable version of \gls{jpeg-pcc} where the bitstreams for each configuration in Table~\ref{tab:coding params} were concatenated together to achieve scalability. This solution yields 14.32\% higher bitrates on average (BD-rate D1) w.r.t. \gls{esqh} and 54\% additional rate when considering the full bitstream (i.e. the one relative to the highest rate point that allows decoding all chosen coding configurations). This shows that \gls{esqh} is an effective solution for providing scalability in \gls{jpeg-pcc}.


% \begin{figure}
%     \centering
%     \begin{minipage}[c]{\textwidth}
%     \includegraphics[width=\textwidth]{figures/avg_others}
%     \subcaption{Average RD curves over test set}
%     \label{fig:avg_others}
%     \end{minipage}
%     \begin{minipage}[c]{\textwidth}
%     \includegraphics[width=\textwidth]{figures/avg_solid_others}
%     \subcaption{Average RD curves over solid PCs}
%     \label{fig:avg_solid_others}
%     \end{minipage}

%     \begin{minipage}[c]{\textwidth}
%     \includegraphics[width=\textwidth]{figures/avg_dense_others}
%     \subcaption{Average RD curves over dense PCs}
%     \label{fig:avg_dense_others}
%     \end{minipage}

%     \begin{minipage}[c]{\textwidth}
%     \includegraphics[width=\textwidth]{figures/avg_sparse_others}
%     \subcaption{Average RD curves over sparse PCs}
%     \label{fig:avg_sparse_others}
%     \end{minipage}
%     \caption{Average RD curves when comparing \gls{jpeg-pcc} based solutions.}
%     \label{fig:rd_rqulpe_others}
% \end{figure}

\subsubsection{\gls{esqh} versus anchors}


The performance comparison of \gls{esqh} against the anchor codecs, as illustrated in Fig.~\ref{fig:rd_rqulpe_others}, shows that despite being a scalable solution, \gls{esqh} performs better or on par with all the considered anchors. To better assess the relative performance between the solution and the anchors and to provide a more consistent evaluation, Bjontegaard-Delta (BD) metrics (BD-Rate, BD-PSNR) were employed, providing a more reliable basis for comparison despite their dependence on polynomial interpolation quality.

Table~\ref{fig:bd_rqulpe_standards} presents the BD metrics for \gls{esqh} in comparison with the standardized codecs (G-PCC and V-PCC), while Table~\ref{fig:bd_rqulpe_others} showcases the BD metrics for \gls{esqh} in comparison with the learning-based codecs (GRASP-Net and PCGCv2).
The analysis reveals that \gls{esqh} significantly outperforms G-PCC on solid and dense PCs, while showing slightly inferior performance on sparse PCs, primarily due to G-PCC's exceptional results on ULB Unicorn. In comparison with V-PCC, \gls{esqh} demonstrates superior performance on solid and sparse PCs, though V-PCC achieves better RD performance (D1 PSNR) on all four dense PCs in the test set.

Regarding learning-based codecs, \gls{esqh} outperforms PCGCv2 on dense and sparse PCs, with marginally lower performance on solid PCs. GRASP-Net shows comparable performance on solid PCs and superior results on dense and sparse PCs, indicating its effectiveness as an enhancement layer addressing G-PCC's limitations.

A critical distinction to note is that all compared methods, except G-PCC, lack scalability. In practical scenarios where scalability is required, \gls{esqh} offers a significant advantage since it enables decoding point clouds at multiple resolution/quality levels from a single bitstream.


\subsection{Complexity Analysis}

The computational impact of \gls{squlpe} model operations in scalable coding was assessed through comprehensive encoding and decoding time measurements. The evaluation was conducted on hardware comprising a single L40s GPU and 4 cores of an AMD EPYC 9224 CPU, with each PC processed 20 times, excluding extreme measurements to eliminate outliers.
To better assess the computational complexity, the PCs were coded with $qp \in \{1\dots5\}$ since coding PCs at different scales leads to very different coding times.
To obtain interpretable complexity metrics, testing focused on quality parameter variations ($qp \in {1, 2, 3, 4, 5}$) at original resolution ($sf=1$) with a block size of 128, excluding super-resolution effects to avoid accounting for postprocessing (which is equal for both \gls{jpeg-pcc} and \gls{esqh}) in the complexity evaluation.
This configuration was applied to both old and new test datasets, providing a robust sample size for complexity assessment. 

The evaluation framework measured four key temporal metrics:
\begin{itemize}
    \item $t_{enc, jpeg}(i)$: \gls{jpeg-pcc} encoding time, for non-scalable streams, required to encode the PC at quality $i$.
    \item $t_{enc, SRQH}$: \gls{esqh} encoding time for the full scalable bitstream.
    \item $t_{dec, jpeg}(i)$: \gls{jpeg-pcc} decoding time, for non-scalable streams, required to decode the PC at quality $i$.
    \item $t_{dec, SRQH}(i)$: time required by \gls{esqh} to decode the PC at quality $i$ from the scalable stream.
\end{itemize}

The relative computational overhead introduced by \gls{esqh} was quantified through
\begin{equation}
    t_{enc, extra} = \Bigg(\frac{t_{enc, SRQH}}{\sum_{i=1}^{5} t_{enc, jpeg}(i)} - 1\Bigg) \cdot 100 \\ 
\end{equation}
\begin{equation}
    t_{dec, extra}(i) = \Bigg(\frac{t_{dec, SRQH}(i)}{t_{dec, jpeg}(i)} - 1\Bigg) \cdot 100
\end{equation}

A key distinction exists between encoding and decoding processes: encoding requires full PC decoding at each rate point for distortion optimization, while decoding necessitates processing only the base layer and relevant enhancement layers without reconstructing the PC at each quality. 
For this reason, if quality $i$ needs to be decoded then the base layer and $i-1$ enhancement layers need to be decoded.
Consequently, \gls{esqh} execution time increases linearly with quality level $i$, suggesting a linear relationship between decoding time and enhancement layer count.

Experimental results showed that $t_{enc, extra} = 9.95\%$, additionally, the decoding time analysis, visualized in Fig.~\ref{fig:extra_dec}, confirms the expected linear growth with quality level, where each enhancement layer processing adds approximately 20\% to the base \gls{jpeg-pcc} decoding time. This value is higher than the average increase in encoding time since, 
at the encoder side, the time for distortion optimization is not negligible and it reduces the relative impact of \gls{esqh} w.r.t. \gls{jpeg-pcc} (a similar effect would be seen also if SR was introduced).

\begin{figure}
    \centering
    \includegraphics[width=.8\columnwidth]{figures/average_decoding_time}
    \caption{Extra decoding time, in percentage, required by \gls{esqh} w.r.t. \gls{jpeg-pcc}.}
    \label{fig:extra_dec}
\end{figure}
