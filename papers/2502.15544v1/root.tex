\documentclass[journal]{IEEEtran}

% *** CITATION PACKAGES ***
\usepackage[style=ieee]{biblatex} 
\bibliography{ieeetran.bib}    %your file created using JabRef

% *** MATH PACKAGES ***
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amssymb,bm}
\usepackage{color}
\usepackage{multirow}
\usepackage{bm}
\usepackage{makecell}

\usepackage{algorithm}  
\usepackage{algpseudocode}  
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm

% *** PDF, URL AND HYPERLINK PACKAGES ***
\usepackage{url}
% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\usepackage{graphicx}  %needed to include png, eps figures
\usepackage{float}  % used to fix location of images i.e.\begin{figure}[H]
% \linespread{2}
\begin{document}

% paper title
\title{Learning-based Model Predictive Control for Passenger-Oriented Train Rescheduling with Flexible Train Composition}
%\title{Scenario-Based Distributed Model Predictive Control for Urban Rail Transit Networks with Uncertain Passenger Flows}

% author names 
\author{Xiaoyu~Liu, %s123456,
        Caio~Fabio~Oliveira~da~Silva,
        Azita~Dabiri,
        Yihui~Wang, 
        and Bart~De~Schutter,~\IEEEmembership{Fellow,~IEEE}
%        {\small Names are to be centered in Times 
%(or Times Roman) 12-point nonboldface. Leave two blank lines before your Abstract}}% <-this % stops a space
\thanks{This research has received funding from the National Natural Science Foundation of China (No. 72071016) and the 
European Research Council (ERC) under the European Unionâ€™s Horizon 
2020 research and innovation programme (Grant agreement No. 101018826 - CLariNet). The work of the first author is also supported by the China Scholarship Council under Grant 202007090003.}
\thanks{Xiaoyu Liu, Caio~Fabio~Oliveira~da~Silva, Azita Dabiri, and Bart De Schutter are with the Delft Center for Systems and Control,
Delft University of Technology, 2628CD Delft, The Netherlands (email: x.liu-20@tudelft.nl, c.f.oliveiradasilva@tudelft.nl, a.dabiri@tudelft.nl, b.deschutter@tudelft.nl).}% <-this % stops a space
\thanks{Yihui Wang is with the School of Automation and Intelligence, Beijing Jiaotong University, Beijing 100044, China (email: yihui.wang@bjtu.edu.cn).}% <-this % stops a space
%\thanks{Manuscript received April 19, 2005; revised August 26, 2015.}}
\thanks{Xiaoyu Liu and Caio~Fabio~Oliveira~da~Silva contributed equally.}}

% The report headers
% \markboth{IEEE Transactions on Intelligent Transportation Systems, VOL. x, NO. x, xxxx 2022}%do not delete next lines
%{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for IEEE Journals}

% make the title area
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
% This paper focuses on passenger-oriented real-time train scheduling, considering flexible train composition and rolling stock circulation, by integrating learning-based and optimization-based approaches. A passenger-oriented train scheduling model is extended to include train compositions and rolling stock circulation to address time-varying passenger demands. Then, a learning-based model predictive control (MPC) approach is developed for real-time train rescheduling, where the integer variables are obtained by a pre-trained long short-term memory (LSTM) network and the continuous variables are solved by nonlinear constrained optimization with fixed integer variables. The learning-based MPC approach enables us to jointly consider efficiency and constraint satisfaction by combining learning-based and optimization-based approaches. In order to streamline the optimization process, four presolve techniques are developed to prune a subset of integer decision variables. After implementing the presolve techniques, an LSTM network is applied to obtain the remaining integer variables with reduced dimensions. Numerical simulations are conducted to illustrate the effectiveness of the developed learning-based MPC approach based on real-life data from the Beijing urban rail transit system.
This paper focuses on passenger-oriented real-time train rescheduling, considering flexible train composition and rolling stock circulation, by integrating learning-based and optimization-based approaches. A learning-based model predictive control (MPC) approach is developed for real-time train rescheduling with flexible train composition and rolling stock circulation to address time-varying passenger demands. In the proposed approach, first, the values of the integer variables are obtained by pre-trained long short-term memory (LSTM) networks; next, they are fixed and the values of continuous variables are determined via nonlinear constrained optimization. The learning-based MPC approach enables us to jointly consider efficiency and constraint satisfaction by combining learning-based and optimization-based approaches. In order to reduce the number of integer variables, four presolve techniques are developed to prune a subset of integer decision variables. % After implementing the presolve techniques, an LSTM network is applied to obtain the remaining integer variables with reduced dimensions. 
Numerical simulations based on real-life data from the Beijing urban rail transit system are conducted to illustrate the effectiveness of the developed learning-based MPC approach.
\end{abstract}
\begin{IEEEkeywords}
Urban rail transit systems, train rescheduling, time-varying passenger demands, model predictive control, long short-term memory network.
\end{IEEEkeywords}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\IEEEPARstart{U}{rban} rail transit has become indispensable in metropolitan areas due to its reliability, high capacity, and eco-friendly characteristics. Urban rail transit systems prioritize safe and efficient train operations while providing high-quality service to passengers.  %, and reliable urban rail transit systems is important for the competitiveness of national and regional economies. 
Effective real-time train scheduling is essential for enhancing passenger satisfaction and minimizing operational costs within infrastructure limitations. However, the rapid expansion of urban rail transit systems and the increasing passenger demands pose significant challenges to real-time scheduling. Advanced scheduling models and control strategies are required to develop efficient timetables and to improve the overall performance of urban rail transit systems. 

\subsection{Passenger-Oriented Train Scheduling}
In urban rail transit systems, passenger demands vary throughout the day, necessitating adjustments of the train schedules to accommodate these demand variations while considering operational costs. 
One direction addresses time-varying passenger demands by optimizing the departure and arrival times of trains at each station, while taking into account several attributes of train operations and infrastructure restrictions, e.g., train stopping plans \cite{cacchiani2020robust,qi2021integer}, rolling stock circulations \cite{wang2018passenger}, and train speed levels \cite{hou2019energy,wang2021energy}.   Qi et al.~\cite{qi2021integer} optimized train stopping plans and timetables of a high-speed railway line considering time-varying passenger demands by formulating a mixed-integer linear programming (MILP) problem. The aim of \cite{qi2021integer} is to find a solution that considers passenger preferences for departure times while ensuring trains operate within capacity limits. 
Considering the passenger load of trains, Wu et al.~\cite{wu2021multi} minimized the passenger waiting time and the energy consumption by developing a heuristic algorithm to solve the resulting nonlinear integer programming problem. Wang et al.~\cite{wang2021energy} formulated a mixed-integer nonlinear programming (MINLP) problem to minimize train energy consumption and passenger waiting times by optimizing train speed levels and headway deviations. However, the above studies optimize train schedules within the fixed transport capacity of a rail line, such as fixed train compositions or fixed train departure frequencies. As transport capacity directly impacts passenger flows, further research is required to improve passenger satisfaction by including transport capacity as a decision variable.

Another direction for train scheduling problems addresses time-varying passenger demands by optimizing transport capacity explicitly.  Several studies focus on optimizing transport capacity by adjusting train departure frequencies, with higher frequencies during peak hours and lower frequencies during off-peak hours \cite{canca2016setting,liu2023bi,liu2024real}. %However, passengers typically expect regular departures at every platform to plan their travels conveniently and to avoid extended waits in case they miss a connecting train 
However, passengers typically expect regular departures at each platform to plan their travels conveniently and have a predictable waiting time in case they miss a connecting train \cite{liu2023modeling}.  Therefore, instead of changing the departure frequency, which would significantly impact the timetable, in recent years, many researchers have focused on optimizing the train composition \cite{ying2022adaptive,zhao2023integrated}. Pan et al.~\cite{pan2023demand} developed a column-generation-based approach to optimize the timetable, train composition, and rolling stock circulation plan of an urban rail transit line. Their paper concludes that flexible train composition can provide additional adaptability to better match time-varying passenger demands. Wang et al.~\cite{wang2024flexible} investigated flexible train composition and rolling stock circulation of an urban rail transit line, and solved the resulting MILP problem by developing an approximation approach and a two-stage meta-heuristic algorithm. Yang et al.~\cite{yang2024integrated} investigated the train scheduling problem with flexible train composition for an urban rail transit line, and they applied an adaptive large neighborhood search algorithm to solve the resulting integer programming problem. As the inclusion of train composition optimization and rolling stock circulation planning introduces additional integer variables, the above studies indicate that the online computational complexity is the main challenge of incorporating flexible train composition into the real-time train scheduling problem.


\subsection{MPC for Real-Time Train Scheduling}
Model predictive control (MPC) has been widely adopted in various applications for its ability to handle multivariable constrained control problems \cite{grune2017nonlinear,mayne2000constrained,qin2003survey}. %, including urban traffic management \cite{sun2024novel}, train control \cite{liu}  
The train scheduling problem is a typical contained control problem, and many studies have applied MPC for real-time train scheduling. De Schutter et al.~\cite{de2002model} first applied MPC in the train scheduling problem to minimize train delays by adjusting transfer connections. Caimi et al.~\cite{caimi2012model} developed an MPC algorithm to optimize timetables, transfer connections, and train assignment plans in complex station areas.  Cavone et al.~\cite{cavone2020mpc} proposed an MPC approach for train rescheduling during disruptions and delays, where in each step the resulting MILP problem is solved by combining bi-level heuristics and distributed optimization. The above studies only handle operator-related factors in railway systems, leaving an open gap in including passenger demands in real-time train scheduling problems to improve the service quality of urban rail transit systems.

In recent years, several studies have focused on MPC for real-time passenger-oriented train scheduling. Assis and Milani \cite{assis2004generation} applied MPC to compute the train timetable of a metro line considering train headway and passenger load, where a linear programming problem is solved at each step.  Based on a state-space model, Li et al.~\cite{li2016robust} developed a robust MPC approach to minimize the upper bound of the timetable deviation from the nominal timetable under uncertain disturbances. By solving linear matrix inequalities, they constructed a Lyapunov function to ensure the attenuation of the timetable deviation. An event-triggered MPC approach is further developed in \cite{wang2022event} to reduce the computational burden of updating control variables in each step. However, these studies do not explicitly consider train capacity limitations and time-varying passenger demands, and the results are based on the assumption that the maximum number of passengers does not exceed the maximum train capacity. % eaving an open gap for further improving passenger satisfaction by explicitly including time-varying passenger demands and train capacity limitations.  
% Liu et al.~\cite{liu2023modeling} explicitly incorporated time-varying passenger demands and train capacity limitations into real-time train scheduling problem. %by developing a simplified passenger-centric train scheduling model. 
% In \cite{liu2023modeling}, the time-varying passenger demand is approximated as a piecewise constant function by dividing the planning time window into several time intervals of equal length, and an MILP-based MPC approach was developed for real-time train scheduling.
Liu et al.~\cite{liu2023modeling} explicitly incorporated time-varying passenger demands and train capacity limitations into the real-time train scheduling problem. In \cite{liu2023modeling}, the time-varying passenger demand is approximated as a piecewise constant function by dividing the planning time window into several time intervals of equal length, and an MILP-based MPC approach is adopted for real-time train scheduling. 
% The train scheduling problem is typically formulated as an MILP or MINLP problem, and the above studies indicate that the online computational burden is the main challenge of real-time train scheduling. The computational burden will further increase when including more attributes, e.g., train capacity, train composition, and rolling stock circulation. 
% The train scheduling problem is typically formulated as an MILP or MINLP problem, and 
% The online computational burden is the main challenge of applying MPC in real time, and including more attributes, such as train capacity, train composition, and rolling stock circulation, will further increase the computational burden. Therefore, further research is required to develop efficient MPC approaches for real-time passenger-oriented train scheduling.
The main challenge of applying MPC in real time is the online computational burden. Including additional attributes, such as train capacity, train composition, and rolling stock circulation, will further increase the computational burden. Therefore, further research is required to develop efficient MPC approaches for real-time passenger-oriented train scheduling. 

\subsection{Learning-based Train Scheduling}
Learning-based approaches are effective in reducing online computational burden and have been developed for dynamic control problems in different fields, such as road transportation systems \cite{sun2024novel}, smart building systems \cite{wang2020reinforcement}, and power systems \cite{fu2024novel}.  Learning-based approaches, including supervised learning (SL) and reinforcement learning (RL), have also been applied in train scheduling problems in recent years \cite{tang2022literature}. 
SL trains models on labeled data to make accurate predictions or classifications, while RL trains an agent to make decisions through trial-and-error using rewards and penalties. Kuppusamy et al.~\cite{kuppusamy2020deep} applied a deep learning approach to an energy-efficient timetable rescheduling problem, where a long short-term memory (LSTM) network is trained to select the optimal operation mode. 
% Yin et al.~\cite{yin2016energy} proposed an approximate dynamic programming approach for train rescheduling problems to reduce passenger delays, the total travel time of passengers, and the energy consumption of trains. In \cite{yin2016energy}, the disturbance information, train arrival times, the number of boarding passengers, and the number of waiting passengers are included in the state, while the rescheduled timetable is the action.  
{\v{S}}emrov et al.~\cite{vsemrov2016reinforcement} applied Q-learning in the train rescheduling problem to reduce delays caused by disturbances and disruptions, and they illustrated their method on a single-lane track with three trains. 
Yin et al.~\cite{yin2016energy} proposed an approximate dynamic programming approach to address train rescheduling problems, aiming to reduce passenger delays, total travel time, and train energy consumption. In \cite{yin2016energy}, the states include disturbance information, train arrival times, the number of boarding passengers, and the number of waiting passengers, while the actions include rescheduling the dwell times and running times.  Khadilkar \cite{khadilkar2019scalable} applied RL to determine track allocations and timetables of bidirectional railway lines to minimize the priority-weighted delay. %They indicate that the proposed approach outperforms the heuristic algorithms and computation times are comparable. 
Ying et al.~\cite{ying2022adaptive} developed a proximal policy optimization approach for the train scheduling problem in an urban rail transit line considering flexible train composition. In \cite{ying2022adaptive}, the control policy and the value function are parameterized by artificial neural networks, and scheduling constraints are handled by a devised mask scheme. Simulation results show that this approach reduces the computational burden and improves solution quality compared to the genetic algorithm and differential evolution.
More studies of learning-based approaches in railway systems can be found in the recent review paper \cite{tang2022literature}.  


In the above studies, scalability and constraint satisfaction are two main challenges in developing learning-based train scheduling approaches. 
The train scheduling problem is typically formulated as an MILP or MINLP problem, and the computational complexity increases rapidly as the number of integer variables increases. In recent years, some research has combined learning-based and optimization-based approaches for MILP or MINLP problems by using learning-based approaches to obtain the integer variables. Having the integer variables fixed, the continuous variables are then obtained by solving a linear or nonlinear programming problem. In this context, the aim is to combine the advantages of both learning-based and optimization-based approaches, i.e., the online computational efficiency of learning-based approaches and the constraint satisfaction of optimization-based approaches \cite{cauligi2022prism,russo2023learning}. Promising results of learning-based approaches in railway systems and the novel learning-based approaches in mixed integer programming problems have inspired us to develop new learning-based frameworks for real-time train scheduling.  

% \cite{ying2022adaptive} \cite{noursalehi2022dynamic} \cite{yin2016energy}

\subsection{Paper Contributions and Structure}
% The current paper addresses the real-time passenger-oriented train rescheduling problem. A passenger-oriented train scheduling model is developed taking into account the time-varying passenger demands, flexible train composition, and the rolling stock circulation. We then develop a learning-based MPC approach for the resulting real-time train rescheduling problem where the integer variables are obtained by learning and the continuous variables are solved with traditional optimization.  
This paper addresses the real-time, passenger-oriented train rescheduling problem taking into account time-varying passenger demands, flexible train composition, and rolling stock circulation. %A passenger-oriented train scheduling model is developed, taking into account time-varying passenger demands, flexible train composition, and rolling stock circulation. We then develop a learning-based MPC approach for the resulting real-time train rescheduling problem, where the integer variables are obtained through learning and the continuous variables are solved with traditional optimization. 
The main contributions of the paper are listed as follows:
\begin{enumerate}
    \item A passenger-oriented train rescheduling model \cite{liu2023modeling} is extended to include time-varying sectional passenger demands, flexible train composition, and rolling stock circulation. The time-varying passenger demands can be approximated as a piecewise constant function by dividing the prediction horizon into several time intervals.
    \item Four presolve techniques are developed to streamline optimization processes by pruning a subset of integer decision variables. After implementing the presolve techniques,  long short-term memory (LSTM) networks are applied to obtain the remaining integer variables with reduced dimensions. 
    \item A learning-based MPC approach is developed for real-time train rescheduling. To improve the online computational efficiency of MPC, the learning-based approach is applied to obtain integer variables while the detailed timetable is obtained by solving a constrained optimization problem with the fixed integer variables. %where the integer variables are obtained by deep learning and the continuous variables are solved by nonlinear optimization with fixed integer variables. 
\end{enumerate}

The remaining part of the paper is organized as follows: Section~\ref{lmpc-section2} provides the problem description and general explanations. Section~\ref{lmpc-section3} introduces the passenger-oriented train rescheduling model. In Section~\ref{lmpc-mpc_approach}, the problem formulation and the MINLP-based MPC approach are presented. In Section~\ref{lmpc-lmpc_approach}, we propose a learning-based MPC approach for real-time train rescheduling. Section~\ref{lmpc-section6} provides an illustrative case study. Section~\ref{lmpc-section7} concludes the paper.

\section{Problem Description and Explanations}\label{lmpc-section2}
%In urban rail transit systems, passenger demands vary throughout the day, necessitating the adjustments of train schedules to accommodate these demand variations while considering operational costs. One common approach to address time-varying passenger demands is to optimize train departure frequencies, with higher frequencies during peak hours and lower frequencies during off-peak hours \cite{canca2016setting,liu2023bi}. However, 
In urban rail transit systems, passengers typically expect regular departures at every platform to plan their trips conveniently and to avoid extended waiting times in case they miss a connecting train \cite{liu2023modeling}. In this context, we consider the regular departure of trains and optimize the transport capacity by adjusting train composition. % Therefore, instead of changing the departure frequency, this paper adjusts the timetable and train composition while maintaining a constant departure frequency.

In urban rail transit systems, a line is defined as the route of trains with the same origin, intermediate, and destination stations. A train service is defined as a train departure from its origin station, visiting every station in the line, and finally returning to the depot (or connecting to other train services at the depot). As illustrated in Fig.~\ref{lmpc-train_composition}, a train service consists of one or several train units, and the composition can be changed at the station connected to a depot by adding or removing train units.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=8.4cm]{train_composition.pdf}    % The printed column width is 8.4 cm.
\caption{Illustration of definitions used in this paper.}
\label{lmpc-train_composition}
\end{center}
\end{figure}

% In this paper, we optimize train compositions and timetables considering time-varying passenger demands and rolling stock circulation, with the aim of minimizing the total waiting time of passengers and train energy consumption. Flexible train composition and rolling stock circulation are related to integer variables while train timetables are related to continuous variables, i.e., departure and arrival times. The train operates under several constraints, including train capacity constraints, train availability in a depot, headway constraints, etc. 
In this paper, we jointly optimize train compositions and timetables considering time-varying passenger demands and rolling stock circulation. We aim to minimize the total waiting time of passengers and the train energy consumption, and the control actions are the train composition, train service orders at the platforms connected to the same depot, and departure/arrival times.  Flexible train composition and rolling stock circulation relate to the set of integer variables, while train timetables relate to the set of continuous variables, such as departure and arrival times. Trains operate under several constraints, including train capacity constraints, train availability in a depot, and headway constraints. By applying MPC, we solve the resulting mixed-integer programming problem in a moving horizon manner for real-time train rescheduling. To improve the online computational efficiency of MPC, we use the learning-based approach to obtain integer variables, i.e., train compositions and train orders; then, we optimize the detailed timetable with the fixed integer variables by solving a constrained optimization problem.


%\section{State of The Art}\label{lmpc-section2}
\section{Mathematical Formulation for Passenger-Oriented Train Rescheduling}\label{lmpc-section3}
In this section, we develop a passenger-oriented train rescheduling model for urban rail transit systems.  The notations for the model formulation are provided in Section~\ref{lmpc-section3.1}.  The train operation constraints of the model are introduced in Section~\ref{lmpc-section3.2}. In Section~\ref{lmpc-section_roll}, the rolling stock circulation constraints related to the model are introduced. In Section~\ref{lmpc-section_passenger}, passenger flow constraints of the model are presented.

% This section starts with the description of the mathematical model proposed by the authors in \cite{liu2022timetable}, followed by an extension of the model to include rolling stock availability.  Some general explanations for the research problem of this paper are as follows:
% \begin{enumerate}
% \item This paper aims to adjust train schedules for urban rail transit networks online based on real-time passenger demands. We assume the routes of passengers are given a priori.  Disturbances and disruptions are not in the scope of this paper.
% \item The current paper is based on the passenger absorption model developed in \cite{liu2022timetable}, which has been developed to determine train departure frequencies (i.e., the number of trains departing from each platform per unit time) for urban rail transit networks.
% \item After obtaining the departure frequency of each platform, a dedicated lower-level controller \cite{liu2023bi} can determine the detailed departure and arrival times of trains, where the departure interval during each phase is determined according to the corresponding departure frequency.
% \end{enumerate}

% We start with introducing the notations for the model formulation in Section~\ref{lmpc-section3.1}. Then, the passenger absorption model is summarized in Section~\ref{lmpc-section3.2}. Section~\ref{lmpc-section3.3} introduces the constraints for the model and further extends the model to include rolling stock availability.

\subsection{Notations}\label{lmpc-section3.1}

Indices and Input Parameters
\begin{IEEEdescription}[\IEEEsetlabelwidth{$V_1,V_2,V_3$}]
\small
\item[$p$] Index of platforms, $p \in \cal{P}$; $\cal{P}$ is the set of platforms
%\item[$P_j$] Set of platforms at transfer station $j$
\item[$k_p$] Index of train services at platform $p$, $k_p \in \mathcal{I}_p$; $\mathcal{I}_p$ is the set of train services departing from platform $p$
\item[$z$] Index of depots%; $\mathrm{dep}(z)$ defines the set of platforms directly connected with depot $z$
%\item[$\kappa$] Index of control step
\item[$\mathrm{p}^\mathrm{pla}\left( p \right)$] Predecessor platform of platform $p$
\item[$\mathrm{s}^\mathrm{pla}\left( p \right)$] Successor platform of platform $p$
\item[$d^\mathrm{pre}_{p}(k_p)$]  Predetermined departure time of train service $k_p$ at platform $p$
\item[$h_{p}^\mathrm{min}$] Minimum departure-arrival headway at platform $p$
\item[$r_p^\mathrm{min}$] Minimum running time of trains from platform $p$ to its succeeding platform
\item[$ r_p^\mathrm{max}$] Maximum running time of trains from platform $p$ to its succeeding platform
\item[$C_\mathrm{max}$] Maximum capacity of a train unit
\item[$\ell^\mathrm{min}$] Minimum number of train units allowed to be included in any train service 
\item[$\ell^\mathrm{max}$] Maximum number of train units allowed to be included in any train service
\item[$\sigma_p$]  Parameter indicating whether the train composition can be adjusted at platform $p$, i.e., if the train composition can be adjusted at platform $p$, then, $\sigma_p = 1$, otherwise, $\sigma_p = 0$
\item[$\tau_{p}^\mathrm{min}$] Minimum dwell time of a train service at platform $p$
\item[$t_{p}^\mathrm{cons}$] Time required for changing the train composition at platform $p$
\item[$t_{p}^\mathrm{roll}$] Time for trains from platform  $p$ to other platforms
corresponding to the same depot
\item[$\mathrm{dep}(z)$] Set of platforms directly connected with depot $z$
\item[$\mathrm{pla}(p)$] Set of platforms belonging to the same station as platform $p$
\item[${\rho_{p} (k_p)}$] Passenger demands from platform $p$ to its successor platform during $d^\mathrm{pre}_{k-1,p}$ to  $d^\mathrm{pre}_{k,p}$
\item[$N_z^{\mathrm{train}}$] Total number of train units available at depot $z$
\item[$\chi_{k_q,q,k_p,p}$] Binary parameter, which can be determined based on the predetermined timetable; if train $k_q$ at platform $q$ has transfer connection with train $k_p$ at platform $p$, $\chi_{k_q,q,k_p,p} = 1$; otherwise, $\chi_{k_q,q,k_p,p} = 0$.
 \item[$\beta_{q,p}$] Transfer rate from platform $q$ to platform $p$
\item[$t_{q}^\mathrm{trans}$] Average transfer time from platform $q$ to the platforms at the same station
\item[$E_p^\mathrm{energy}$] Average energy consumption for a train unit running from platform $p$ to its successor platform
\item[${E_p^\mathrm{add}}$] Additional cost of changing train composition at platform $p$\\
\end{IEEEdescription}

Decision variables
\begin{IEEEdescription}[\IEEEsetlabelwidth{$V_1,V_2,V_3$}]
\small
\item[$d_{p}(k_p)$] Departure time of train service $k_p$ at platform $p$
\item[$a_{p}(k_p)$] Arrival time of train service $k_p$ at platform $p$
\item[$\ell_{p}(k_p)$] Number of train units included in train service $k_p$ at platform $p$, $\ell_{p}(k_p) \in \mathbb{Z}_+$
%\item[${x_{i,p,b}}$]  Binary variable indicating whether train $i$ from platform $p$ selects speed profile $b$ \\
\end{IEEEdescription}

Output variables
\begin{IEEEdescription}[\IEEEsetlabelwidth{$V_1,V_2,V_3$}]
\small
\item[$\tau_{p}(k_p)$] Dwell time of train service $k_p$ at platform $p$ 
\item[$h_{p}(k_p)$] Departure-arrival headway between train service $k_p$ and train service $k_p+1$ at platform $p$
\item[$r_{p}(k_p)$] Running time of train service $i$ from platform $p$ to its successor platform 
\item[$r_{p}^\mathrm{turn}(k_{p})$] Turnaround time of train service $k$ at platform $p$
\item[$y_{p}(k_p)$] Number of train units coming to/from the depot for train service $k_p$, $y_{p}(k_p) \in \mathbb{Z}$
\item[$\tau^\mathrm{add}_{p}(k_p)$] Additional time required for changing the composition of train service $k_p$ at platform $p$
\item[$\eta_{k_p,p}$] Binary variable; if the composition of train service $k_p$ is changed at platform $p$, $\eta_{k_p,p} = 1$; otherwise, $\eta_{k_p,p} = 0$
\item[${\xi_{k_p,k_{p'},p,p'}}$]  Binary variable; if the train units from train service $k_{p'}$ at platform $p'$ can be used for train service $k_{p}$ at platform $p$, ${\xi_{k_p,k_{p'},p,p'}} = 1$; otherwise, ${\xi_{k_p,k_{p'},p,p'}} = 0$
\item[$n_{p}(k_p)$] Number of passengers waiting at platform $p$ at time $d^\mathrm{pre}_{p}(k_p)$
\item[$ n^\mathrm{trans}_{p}(k_p)$] Number of transfer passengers arriving at platform $p$ for train $k_p$
\item[$n^\mathrm{depart}_{p}(k_p)$] Number of passengers departing from platform $p$ with train service $k_p$
\item[$n^\mathrm{arrive}_{p}(k_p)$] Number of passengers arriving at platform $p$ with train $k_p$ from the predecessor platform $\mathrm{p}^\mathrm{pla}\left( p \right)$
\item[$n^\mathrm{before}_{p}(k_p)$] Number of passengers waiting at platform $p$ immediately before the departure of train service $k_p$
\item[$C_{p}(k_p)$] Total capacity of train service $k_p$ at platform $p$
\item[$n^\mathrm{after}_{p}(k_p)$] Number of passengers waiting at platform $p$ immediately after train service $k_p$ departs from platform $p$.
\end{IEEEdescription}

\subsection{Train Operation Constraints}\label{lmpc-section3.2}
In urban rail transit systems, each line typically comprises two directions, i.e., the up direction and the down direction, as shown for a line of $P$ stations in Fig.~\ref{lmpc-line}. For each line, a train service can be defined as a train running from the starting platform to the terminal platform, e.g., from Platform 1 to Platform 2$P$ in Fig.~\ref{lmpc-line}.
% In urban rail transit systems, each line typically comprises two directions, i.e., the up direction and the down direction, as shown for a line in Fig.~\ref{lmpc-line}. For each line, a train service can be defined as a train running from the starting platform to the terminal platform.
%In this section, we present the model formulation for the up direction, and the formulation for the down direction is similar. 
% Trains generally operate following a predetermined timetable, and the predetermined departure time of train service $k$ at station $s$ is represented by $d^\mathrm{pre}_{k,s}$. In practice, the actual departure time should satisfy
% \begin{equation} \label{lmpc-predetermined}
%  d_{k,s} \ge d^\mathrm{pre}_{k,s},
% \end{equation}
\begin{figure}[htbp]
\begin{center}
\includegraphics[width=8.5cm]{LinePlatform.pdf}    % The printed column width is 8.4 cm.
\caption{Layout of a bidirectional urban rail transit line.}
\label{lmpc-line}
\end{center}
\end{figure}
Trains generally operate following a predetermined timetable, and the predetermined departure time of train service $k_p$ at platform $p$ is represented by $d^\mathrm{pre}_{p}(k_p)$. 

In practice, premature departure is usually not permitted; thus, the predetermined departure time defines a lower bound of the actual departure time. In general, passengers expect regular departures at every platform so that they can conveniently plan their travels and avoid extended waiting times for the next train in case they miss a connecting train. Therefore, in this paper, we do not change the departure frequency of trains when adjusting the timetable and train composition. Hence, the actual departure time is constrained by
\begin{equation} \label{lmpc-predetermined}
d^\mathrm{pre}_{p}(k_p) \le d_{p}(k_p) < d^\mathrm{pre}_{p}(k_p+1),
\end{equation}
where $d_{p}(k_p)$ is the actual departure time of train service $k_p$ at platform $p$ determined by 
% The departure time $d_{k,s}$ of train service $k$ at station $s$ is determined by
\begin{align}
 &d_{p}(k_p) = a_{p}(k_p) + \tau_{p}(k_p),
%  &\tau_{k,s} \ge \tau^\mathrm{min}_{s},
\end{align}
where $a_{p}(k_p)$ and $\tau_{p}(k_p)$ are the arrival time and dwell time of train service $k_p$ at platform $p$. %, and $\tau^\mathrm{min}_s$ is the minimum dwell time.

For the safe operation of trains, the headway constraint should be satisfied:
\begin{align}
 &a_{p}(k_p+1) = d_{p}(k_p) + h_{p}(k_p),\\
 &h_{p}(k_p) \ge h^\mathrm{min}_{p},
\end{align}
where $h_{p}(k_p)$ is headway of train service $k_p$ at platform $p$ , and $h^\mathrm{min}_p$ denotes the minimum headway.

The arrival time of train service $k_p$ at the successor platform of platform $p$ should also satisfy
\begin{align}
 &a_{\mathrm{s}^\mathrm{pla}\left( p \right)}(k_p) = d_{p}(k_p) + r_{p}(k_p),\\
 &r_{p}^\mathrm{min} \le r_{p}(k_p) \le r_{p}^\mathrm{max},
\end{align}
where $r_{p}(k_p)$ is the running time of train service $k_p$ from platform $p$ to platform $\mathrm{s}^\mathrm{pla}\left( p \right)$, and $r_{p}^\mathrm{min}$ and $r_{p}^\mathrm{max}$ are the minimum and maximum running time from platform $p$ to platform $\mathrm{s}^\mathrm{pla}\left( p \right)$.

% The arrival time of train service $k_p$ at platform $p$ ($p > 1$) should also satisfy
% \begin{align}
%  &a_{p}(k_p) = d_{p-1}(k_p) + r_{p-1}(k_p),\\
%  &r_{p-1}^\mathrm{min} \le r_{p-1}(k_p) \le r_{p-1}^\mathrm{max},
% \end{align}
% where $r_{p-1}(k_p)$ is the running time of train service $k_p$ from platform $p-1$ to platform $p$, and $r_{p-1}^\mathrm{min}$ and $r_{p-1}^\mathrm{max}$ are the minimum and maximum running time from platform $p-1$ to platform $p$.

\subsection{Rolling Stock Circulation Constraints}\label{lmpc-section_roll}
At the terminal station, a turnaround action is required for the continuation of the train service. % if the train would serve as a new train service for the line. 
The turnaround constraints can be formulated as:
\begin{align}\label{lmpc-turnaround}
 &a_{\mathrm{s}^\mathrm{pla}\left( p \right)}(k_{\mathrm{s}^\mathrm{pla}\left( p \right)})= d_{p}(k_{p}) + r_{p}^\mathrm{turn}(k_{p}),\\
 &r_{p}^\mathrm{turn,\min} \le r_{p}^\mathrm{turn}(k_{p}) \le r_{p}^\mathrm{turn,\max},
\end{align}
where $r_{p}^\mathrm{turn}(k_{p})$ represents the turnaround time of train service $k$ at platform $p$, and $r_{p,\min}^\mathrm{turn}$ and $r_{p,\max}^\mathrm{turn}$ denote the minimum and maximum turnaround times at platform $p$. 

An urban rail transit line typically has a limited number of train units that either operate on the line or are stored in the depot. The train composition can be adjusted at the platform that is linked with the depot, and the number of train units $\ell_{p}(k_p) \in \mathbb{Z}_+$ for train service $k_p$ at platform $p$ is determined by
% \begin{equation}\label{lmpc-lambda_transf}
% \ell_{k,s} = \left\{ \begin{array}{l} n_{k,s-1} + y_{k,s}, \begin{array}{*{20}{c}}
% {}&{\rm{if}}&{\sigma_s = 1},
% \end{array}\\
% n_{k,s-1},\begin{array}{*{20}{c}}
% {}&{}&{\rm{if}}&{\sigma_s = 0},
% \end{array}
% \end{array} \right.
% \end{equation}
\begin{align}
&\ell_{p}(k_p) = \ell_{\mathrm{p}^\mathrm{pla}\left( p \right)}(k_{p}) + \sigma_p y_{p}(k_p), \label{lmpc-composition}\\
& \ell_{\min}\le \ell_{p}(k_{p}) \le \ell_{\max},
\end{align}
where $\sigma_p$ is a parameter related to the network layout indicating whether the train composition can be adjusted at platform $p$, i.e., if the train composition can be adjusted at platform $p$, then, $\sigma_p = 1$, otherwise, $\sigma_p = 0$. Moreover, $y_{p}(k_{p}) \in \mathbb{Z}$ represents the number of train units coming to/from the depot for train service $k$; specifically, if $y_{p}(k_{p}) > 0$, then, $y_{p}(k_{p})$ extra train units will come from the depot to be added to train service $k_p$; if $y_{p}(k_{p}) < 0$, train service $k_p$ will be decomposed and $|y_{p}(k_{p})|$ train units will return to the depot; if $y_{p}(k_{p}) = 0$ the composition of train service $k_p$ will not be changed at platform $p$. Furthermore, $\ell_{\min}$ and $\ell_{\max}$ represent the minimum and the maximum number of train units allowed to be included in any train service.

% \begin{align}
% &\ell_{k,s} = n_{k,s-1} + \sigma_s y_{k,s}, \label{lmpc-composition}\\
% & \ell_{\min}\le \ell_{k,s} \le \ell_{\max},
% \end{align}
% where $\sigma_s$ is a parameter related to the network layout indicating whether the train composition can be adjusted at station $s$, i.e., if the train composition can be adjusted at station $s$, $\sigma_s = 1$, otherwise, $\sigma_s = 0$; $y_{k,s}$ represents the number of trains coming to/from the depot for train service $k$; specifically, if $y_{k,s} > 0$, $y_{k,s}$ extra trains will come from the depot to compose train service $k$, if $y_{k,s} < 0$, train service $k$ will be decomposed and $|y_{k,s}|$ trains will return to the depot, if $y_{k,s} = 0$ the composition of train service $k$ will not be changed at station $s$; $\ell_{\min}$ and $\ell_{\max}$ represent the minimum and the maximum number of trains allowed to be included train service $k$.

{\bf{Remark 1}}: % If train service $k$ is performed by trains directly coming from the depot, then (\ref{lmpc-composition}) becomes $\ell_{k,p} = \sigma_p y_{k,p}$. 
If the depot is linked with the terminal platform (e.g., Platform 1 in Fig.~\ref{lmpc-line}) and train service $k$ is performed by the turnaround train units of the previous train service, then (\ref{lmpc-composition}) becomes $\ell_{1}(k_1) = \ell_{2P}(k_{2P}-1) +\sigma_1 y_{1}(k_1)$, i.e., we set $\ell_{1}(k_1) = \ell_{2P}(k_{2P}-1)$.

To capture the changes of train composition at platform $p$, we introduce a binary variable $\eta_{k_p,p}$ as
\begin{equation}\label{lmpc-eta_kp}
\eta_{k_p,p} = \begin{cases} 1, & \mathrm{if} \quad  |y_{p}(k_{p})| > 0;\\
0, & \mathrm{otherwise},
\end{cases}
\end{equation}
where $\eta_{k_p,p} = 1$ indicates the composition of train service $k_p$ is changed at platform $p$; otherwise, $\eta_{k_p,p} = 0$.

In general, additional dwell time is required when changing the train composition; thus, the dwell time $\tau_{p}(k_{p})$ of train service $k_p$ at platform $p$ should satisfy:
\begin{equation}\label{lmpc-tau_min}
\tau_{p}(k_{p}) \ge \tau^\mathrm{min}_{p} + \sigma_p \tau^\mathrm{add}_{p}(k_{p}),
\end{equation}
where $\tau^\mathrm{min}_p$ is the minimum dwell time at platform $p$, and $\tau^\mathrm{add}_{p}(k_{p})$ represents the additional time required for changing the composition of train service $k_p$ at platform $p$, which can be determined by 
\begin{equation}\label{lmpc-y_kp}
\tau^\mathrm{add}_{p}(k_{p}) = \eta_{k_p,p} \cdot t^\mathrm{cons}_{p},
\end{equation}
where $t^\mathrm{cons}_{p}$ is a constant representing the time required for changing the train composition at platform $p$.

% \textcolor{blue}{In general, additional dwell time is required when changing the train composition; thus, the dwell time $\tau_{k,p}$ of train service $k$ at platform $p$ should satisfy:
% \begin{equation}\label{lmpc-tau_min}
% \tau_{k,p} \ge \tau^\mathrm{min}_{p} + \sigma_p \tau^\mathrm{unit}_{k,p} |{y_{k,p}}|,
% \end{equation}
%, where $\tau^\mathrm{min}_p$ is the minimum dwell time at platform $p$, and $\tau^\mathrm{unit}_{k,p}$, represents the unit time required for changing the composition of train service $k$ at platform $p$, $|{y_{k,p}}|$ represents the absolute value of ${y_{k,p}}$, and thus $\sigma_p \cdot \tau^\mathrm{unit}_{k,p} \cdot |{y_{k,p}}|$ calculates the total additional time required for changing the train composition at platform $p$. }

A depot typically connects to at least one platform, and the departure order of train services at the corresponding platforms influences the number of available train units in a depot, i.e., if a newly arriving train service requires changing its composition, the total number of train units in the corresponding depot will change. To represent the relation of departure time of train services corresponding to the same depot, we define a binary variable ${\xi_{k_p,k_{p'},p,p'}}$ as 
\begin{equation}\label{lmpc-xi}
{\xi_{k_p,k_{p'},p,p'}} = \left\{ {\begin{array}{*{20}{l}}
{1,\quad {\rm{if}}\quad {d_{p}(k_{p})} \ge d_{p'}(k_{p'}) + t_{p'}^\mathrm{roll};}\\
{0,\quad {\rm{otherwise}},}
\end{array}} \right.
\end{equation}
where $d_{p}(k_{p})$ is the departure time of train service $k_p$ at platform $p$, ${d_{p'}(k_{p'})}$ is the departure time of train service $k_{p'}$ at platform $p'$, and $t_{p'}^\mathrm{roll}$ is the time for trains from platform $p'$ to other platforms corresponding to the same depot. In (\ref{lmpc-xi}), ${\xi_{k_p,k_{p'},p,p'}} = 1$ indicates train units in train service $k_{p'}$ from platform $p'$ is available for train service $k_p$ at platform $p$; otherwise, ${\xi_{k_p,k_{p'},p,p'}} = 0$.  %$i$ and $k$ are indices of train services; $q$ and $p$ are indices of platforms; 

Then, the rolling stock circulation constraint is
\begin{equation}\label{lmpc-RS}
\small
 \sum_{k_p \in {\mathcal{I}}_{p}} {y_{p}(k_{p})} + \sum_{p' \in \mathrm{dep}(z)\backslash\{p\}} \sum_{k_{p'} \in {\mathcal{I}}_{p'}} \xi_{k_p,k_{p'},p,p'} {y_{p'}(k_{p'})} \le N_z^{\mathrm{train}},
\end{equation}
where $z$ is the index of the depot; $\mathrm{dep}(z)$ defines the set of platforms directly connected with depot $z$; $\mathcal{I}_{p'}$ defines the set of train services departing from platform $p'$; and $N_z^{\mathrm{train}}$ represents the total number of train units available at depot $z$. Eq.~(\ref{lmpc-RS}) indicates that the total number of train units departing from depot $z$ before time $d_{p}(k_{p})$ should be less than or equal to the total number of available train units in the depot. % In (\ref{lmpc-RS}), $\sum_{q \in \mathrm{pla}(z)} \sum_{i \in {\mathcal{I}}_{q}} \xi_{i,k,q,p} {y_{i,q}}$ represents the total number of trains scheduled from depot $z$ for the train services arriving at platform $q \in \mathrm{pla}(z)$ before train service $k$ arrives at platform $p$, including train service $k$ itself.

% Then, the rolling stock circulation constraint is
% \begin{equation}\label{lmpc-RS}
% \sum_{k' \le k} {y_{k',p}} + \sum_{k' \in {\mathcal{I}}_{p'}} \xi_{k',k,p',p} {y_{k',p'}} \le N_{\mathrm{dep}(p)}^{\mathrm{train}},
% \end{equation}
% where $\mathrm{dep}(p)$ represent the depot corresponding to platform $p$; $\mathrm{pla}(z)$ defines the set of platforms directly connected with depot $z$; $\mathcal{I}_{p'}$ defines the set of trains departing from platform $p'$; and $N_z^{\mathrm{train}}$ represents the total number of trains available at depot $z$. Eq.~(\ref{lmpc-RS}) indicates that the total number of trains departing from depot $z$ before time $d_{k,p}$ should be less than or equal to the total number of available trains in the depot. % In (\ref{lmpc-RS}), $\sum_{q \in \mathrm{pla}(z)} \sum_{i \in {\mathcal{I}}_{q}} \xi_{i,k,q,p} {y_{i,q}}$ represents the total number of trains scheduled from depot $z$ for the train services arriving at platform $q \in \mathrm{pla}(z)$ before train service $k$ arrives at platform $p$, including train service $k$ itself.

% A depot typically connects to at least one platform, to consider the availability of trains in the depot, we define a binary variable 
% ${\xi_{k',k,p',p}}$ as 
% \begin{equation}\label{lmpc-y_kp}
% {\xi_{i,k,q,p}} = \left\{ {\begin{array}{*{20}{l}}
% {1,\quad {\rm{if}}\quad {a_{k',p'}} \le a_{k,p};}\\
% {0,\quad {\rm{otherwise}}.}
% \end{array}} \right.
% \end{equation}
% Then, the rolling stock circulation constraint is
% \begin{equation}\label{lmpc-RS}
% \sum_{p' \in \mathrm{pla}(z)} \sum_{k' \in {\mathcal{I}}_{p'}} \xi_{k',k,p',p} {y_{k,p}} \le N_z^{\mathrm{train}},
% \end{equation}

% The total number of trains in the depot corresponding to platform $p$ immediately after train $k$ departs from platform $p$ should satisfy 
% \begin{subequations}\label{lmpc-rolling}
% \begin{align}
% &w_{k,p} = w_{k-1,p} - y_{k,p},\\
% &w_{k,p} \ge 0,   
% \end{align}
% \end{subequations}
% where $w_{k,p}$ is the number of trains in the depot corresponding to platform $p$ immediately after train $k$ departs from platform $p$. We have  $w_{k_0,p} = {N_{k_0,p}^{{\rm{depot}}}}$ is the total number of trains available in the depot linked with platform $p$ immediately after train service $k_0$ arrives at platform $p$.

% The total number of trains in a depot should satisfy
% \begin{equation}\label{lmpc-rolling}
% \sum\limits_{i = k_0}^k { y_{i,s} \le {N_{s,k_0}^{{\rm{depot}}}} } ,
% \end{equation}
% where ${N_{s,k_0}^{{\rm{depot}}}}$ is the total number of trains available in the depot linked with station $s$ immediately before train service $k_0$ arrives at station $s$.

\subsection{Passenger Flow Constraints}\label{lmpc-section_passenger}
A predetermined timetable is generally designed based on the time-varying passenger demand to guide the daily operation of trains. At each platform, the predetermined timetable naturally divides the planning time window into several time intervals, %the passenger demands may vary among different intervals. Therefore, the original train timetable naturally divides the planning time window into several time intervals 
with the predetermined train departure times at the platforms as the partition points. In this paper, we approximate the passenger arrival rates during each time interval as constants. The resulting piecewise approximation is shown in Fig.~\ref{lmpc-demands_original} where $d^\mathrm{pre}_{p}(k_p)$ is the predetermined departure time of train service $k_p$; and $\rho_{p}(k_p)$ denotes passenger demands during $d^\mathrm{pre}_{p}(k_p-1)$ to  $d^\mathrm{pre}_{p}(k_p)$ for passengers aiming to leave platform $p$ with train service $k_p$. 

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=9cm]{PlatformDemandsColor.pdf}    % The printed column width is 8.4 cm.
\caption{Illustration of piecewise approximation of passenger demands for platform $p$.}
\label{lmpc-demands_original}
\end{center}
\end{figure}

The number of passengers waiting at a platform immediately after the predetermined departure time of train service $k_p+1$ at platform $p$ can be calculated by
\begin{align}\label{lmpc-n}
n_{p}(k_p+1) = n_{p}(k_p) + &\rho_{p}(k_p+1)\left(d^\mathrm{pre}_{p}(k_p+1) - d^\mathrm{pre}_{p}(k_p) \right) \nonumber \\ 
&+ n^\mathrm{trans}_{p}(k_p) - n^\mathrm{depart}_{p}(k_p),  
\end{align}
where $n_{p}(k_p)$ represents the number of passengers waiting at platform $p$ at time $d^\mathrm{pre}_{p}(k_p)$; $ \rho_{p}(k_p+1)\left(d^\mathrm{pre}_{p}(k_p+1) - d^\mathrm{pre}_{p}(k_p) \right)$ calculates the number of passengers arriving at platform $p$ between $d^\mathrm{pre}_{p}(k_p)$ and $d^\mathrm{pre}_{p}(k_p+1)$; $ n^\mathrm{trans}_{p}(k_p)$ denotes the number of transfer passengers arriving at platform $p$ for train $k_p$, and $n^\mathrm{depart}_{p}(k_p)$ denotes the number of passengers departing from platform $p$ with train service $k_p$. %$n^\mathrm{board}_{k,s}$ denotes the number of passengers boarding train service $k$ at station $s$.

%In this paper, we handle disturbances, i.e., small delays, so we have $ d_{k,s} \le d^\mathrm{pre}_{k+1,s}$. 
% The number of passengers $w^\mathrm{arrive}_{k,s}$ arrive at station $s$ can be calculated by 
% % \begin{equation}\label{lmpc-w_arrive}
% % w^\mathrm{arrive}_{k,s} = \int_{d_{k-1,s}}^{d_{k,s}} \rho _{s}(t){\rm{d}}t,   
% % \end{equation}
% \begin{equation}\label{lmpc-w_arrive}
% n^\mathrm{arrive}_{k,s} = \rho_{k,s}\left(d^\mathrm{pre}_{k,s} - d^\mathrm{pre}_{k-1,s} \right),   
% \end{equation}
% where $\rho_{k,s}$ denotes the arrival rate during $d^\mathrm{pre}_{k-1,s}$ to  $d^\mathrm{pre}_{k,s}$ for passengers aiming to leave station $s$ with train service $k$. 


% \begin{figure}[htbp]
% \begin{center}
% \includegraphics[width=8cm]{PlatformDemandsColor.eps}    % The printed column width is 8.4 cm.
% \caption{Illustration of piecewise approximation of passenger demands.}
% \label{lmpc-demands}
% \end{center}
% \end{figure}

%At partition point $k$, i.e., the planned departure time $d_s^*(k)$ of the $k$th train, 
Since the departure time of each train service is adjusted according to (\ref{lmpc-predetermined}), there exists one departure in each time interval. As shown in  Fig.~\ref{lmpc-demands_original}, the number of passengers $n^\mathrm{before}_{p}(k_p)$ waiting at platform $p$ immediately before the departure of train service $k_p$ can be calculated by
\begin{align}\label{lmpc-w}
n^\mathrm{before}_{p}(k_p) = n_{p}(k_p) + & \rho_{p}(k_p+1) \left(d_{p}(k_p) - d^\mathrm{pre}_{p}(k_p) \right)\\
&+ n^\mathrm{trans}_{p}(k_p) .
\end{align}
% illustrates the calculation of (\ref{lmpc-w_arrive}).

% The number of passengers $n^\mathrm{depart}_{k,p}$  departing from platform $p$ with train service $k$ is determined by
% \begin{equation}\label{lmpc-boarding}
% n^\mathrm{depart}_{k,p} = {\rm{min}} \left( C_{k,p}, n^\mathrm{before}_{k,p} \right),
% \end{equation}
% where $C_{k,p}$ is the total capacity of train service $k$ at platform $p$. % ; $w^\mathrm{want}_{k,s}$ represents the number of passengers wanting to leave station $s$ with train service $k$. 

The number of passengers $n^\mathrm{depart}_{p}(k_p)$  departing from platform $p$ with train service $k_p$ should satisfy
\begin{subequations}\label{lmpc-boarding2}
\begin{align}
& n^\mathrm{depart}_{p}(k_p) \le C_{p}(k_p),\\
& n^\mathrm{depart}_{p}(k_p) \le n^\mathrm{before}_{p}(k_p) ,
\end{align}  
\end{subequations}
where $C_{p}(k_p)$ is the total capacity of train service $k_p$ at platform $p$. % ; $w^\mathrm{want}_{k,s}$ represents the number of passengers wanting to leave station $s$ with train service $k$. 

% \textcolor{red}{The current (\ref{lmpc-boarding}) is the most accurate version to calculate the total number of departing passengers considering train capacity, and we did that in our past paper. However, we have to introduce binary variables to transform (\ref{lmpc-boarding}), which would significantly increase the computational complexity.  Could we use the constraints (\ref{lmpc-boarding2}) to simplify the problem?
% % The number of passengers $n^\mathrm{depart}_{k,s}$  departing from station $s$ with train service $k$ is determined by
% \begin{subequations}\label{lmpc-boarding2}
% \begin{align}
% & n^\mathrm{depart}_{k,p} \le C_{k,p},\\
% & n^\mathrm{depart}_{k,p} \le n^\mathrm{before}_{k,p} ,
% \end{align}  
% \end{subequations}
% I understand (\ref{lmpc-boarding2}) indeed misses some information and is not exactly equivalent to (\ref{lmpc-boarding}). However, the computational burden is reduced, and the performance of the control inputs obtained by this model would be also verified by an accurate model, i.e., we use a less accurate (but simple) model to generate control inputs and the simulation model would be the most accurate one. Similar constraints have also been applied in many good journals, e.g., \cite{shi2018service,mo2019flexible,pan2023demand}}

The total capacity of train service $k_p$ at platform $p$ is computed by 
\begin{align}
C_{p}(k_p) = \ell_{p}(k_p) C_\mathrm{max},
%&n_p(k) = n_{p-1}(k) + \sigma_p
\end{align}
where $ \ell_{p}(k_p)$ is the number of train units composing train service $k_p$ at platform $p$.

The number of passengers $n^\mathrm{arrive}_{p}(k_p)$ arriving at platform $p$ with train $k_p$ from the predecessor platform $\mathrm{p}^\mathrm{pla}\left( p \right)$ can be calculated by
\begin{equation}
     n^\mathrm{arrive}_{p}(k_p) =  n^\mathrm{depart}_{\mathrm{p}^\mathrm{pla}\left( p \right)}(k_p).
\end{equation}
Then, the number of passengers $n^\mathrm{trans}_{p}(k_p)$ transferring to platform $p$ for train $k_p$ is computed by
\begin{equation}
     n^\mathrm{trans}_{p}(k_p) =  \sum_{q\in \mathrm{pla}(p)}{\sum_{k_q\in\mathcal{I}_q}{ \chi_{k_q,q,k_p,p} \beta_{q,p} n^\mathrm{arrive}_{q}(k_q)}},
\end{equation}
where $\mathrm{pla}(p)$ defines the set of platforms belonging to the same station as platform $p$, $\beta_{q,p}$ is the parameter defines the transfer rate from platform $q$ to platform $p$, and $\chi_{k_q,q,k_p,p}$ is the binary parameter denoting transfer connection between train $k_q$ at platform $q$ and train $k_p$ at platform $p$, which is defined as 
\begin{equation}\label{lmpc-chi}
\small
{\chi_{k_q,q,k_{p},p}} = 
\begin{cases}
    1, & \mathrm{if} \ {d_{p}^\mathrm{pre}(k_{p}-1)} < d_{q}^\mathrm{pre}(k_{q}) + t_{q}^\mathrm{trans} \le {d_{p}^\mathrm{pre}(k_{p})};\\
    0, & \mathrm{otherwise},
\end{cases}
\end{equation}
where $t_{q}^\mathrm{trans}$ represents the average transfer time from platform $q$ to the corresponding platforms at the same station.
% In general, passengers follow a first-in-first-out rule when boarding a train.  After train service $k$ departs from station $s$, passengers arrive at station $s$ before $d^\mathrm{pre}_{k,s}$, i.e., passengers aiming to depart with train service $k$, have to wait for the next train service. In this context, the number of unserved passengers can be calculated by
% \begin{equation}\label{lmpc-w}
% n_{k,s}^{{\text{unserved}}} = \left\{ \begin{gathered}
%   {n_{k,s}} - n_{k,s}^{{\text{depart}}},\ \ \mathrm{if} \ \ {n_{k,s}} \geqslant n_{k,s}^{{\text{depart}}}, \hfill \\
%   0,\qquad \qquad \quad \mathrm{otherwise}, \hfill \\ 
% \end{gathered}  \right.
% \end{equation}
% where $n_{k,s}^\mathrm{unserved}$ represents the number of passengers that arrive at station $s$ before $d^\mathrm{pre}_{k,s}$ and cannot depart from station $s$ with train service $k$.

After train service $k_p$ departs from platform $p$, the number of passengers waiting at the platform can be calculated by
\begin{equation}\label{lmpc-w}
n^\mathrm{after}_{p}(k_p) = n^\mathrm{before}_{p}(k_p) - n^\mathrm{depart}_{p}(k_p),
\end{equation}
where $n^\mathrm{after}_{p}(k_p)$ represents the number of passengers waiting at platform $p$ immediately after train service $k_p$ departs from platform $p$.

%$w^\mathrm{arrive}_{k,s}$ is the number of passengers arriving at station $s$ between the actual departure times of train service $k-1$ and train service $k$, i.e., $d_{k-1,s}$ and $d_{k,s}$; 
% $n^\mathrm{board}_{k,s}$ is the number of passengers boarding train service $k$ at station $s$. 


% The number of passengers $w^\mathrm{want}_{k,s}$ wanting to leave station $s$ with train service $k$  can be computed by
% \begin{equation}
%  w^\mathrm{want}_{k,s} = w^\mathrm{after}_{k-1,s} + w^\mathrm{arrive}_{k,s}.
% \end{equation}

%For the up direction, the passenger traveling rate from station $s$ to its succeeding station can be calculated by 
%At partition point $k$, i.e., the planed departure time of the $k$th train $d_s^*(k)$                                           
%The time-varying sectional passenger demands can be represented by $\rho_{s}(k)$
\section{Model Predictive Control for Real-time Train Rescheduling}\label{lmpc-mpc_approach}
\subsection{Problem Formulation}\label{lmpc-mpc_formualtion}
Based on the developed model, we can formulate the problem to minimize passenger delays and operational costs. The passenger delays corresponding to train service $k_p$ at platform $p$ can be formulated as
\begin{align}\label{lmpc-pass}
J_p^\mathrm{pass}(k_p) = &n_{p}(k_p)\left( {d_{p}(k_p) - d^\mathrm{pre}_{p}(k_p)} \right)+ \nonumber\\
&+ n^\mathrm{after}_{p}(k_p)\left( { d^\mathrm{pre}_{p}(k_p+1) -  d_{p}(k_p)} \right).
\end{align}
%In (\ref{lmpc-pass}),  {\sum\limits_{p = 1}^{2P} {
As passengers expect to depart at the predetermined departure time $d^\mathrm{pre}_{p}(k_p)$, the term $n_{p}(k_p)\left( {d_{p}(k_p) - d^\mathrm{pre}_{p}(k_p)} \right)$ in (\ref{lmpc-pass}) represents the delay for passengers departing from platform $p$ with train service $k_p$; the term $n^\mathrm{after}_{p}(k_p)\left( { d^\mathrm{pre}_{p}(k_p+1)-  d_{p}(k_p)} \right)$ denotes the expected delay for passengers that could not board train service $k_p$, hence they have to wait for the next train at the platform.

Assigning more train units to a train service can increase the capacity for transporting passengers while leading to higher energy consumption. Furthermore, changing the train composition may require additional workload from operators and thus lead to additional costs. The operational costs of train service $k_p$ running from platform $p$ to its successor platform can be expressed as
\begin{equation}\label{lmpc-cost}
{J_p^\mathrm{cost}}(k_p) = \ell_{p}(k_p){E_p^\mathrm{energy}} + \eta_{k_p,p}{E_p^\mathrm{add}},
\end{equation}
where ${E_p^\mathrm{energy}}$ represents the average energy consumption for a train unit running from platform $p$ to its successor platform, $\ell_{p}(k_p){E_p^\mathrm{energy}}$ denotes the approximate energy consumption for $\ell_{p}(k_p)$ train units running from platform $p$ to its successor platform, and ${E_p^\mathrm{add}}$ denotes the additional cost for changing the train composition of a train service at platform $p$. 

In urban rail transit systems, a train service typically departs from a depot, visiting each platform along a line before returning to the depot. %As we want to ensure the regular departure of trains at each platform, we define the time interval between two consecutive predetermined departure times as the control time step, and the length of the control time step, denoted as $T_\mathrm{ctrl}$ for all platforms along a line is identical, and the control time step is indexed as $\kappa$ \footnote{ $T_\mathrm{ctrl}$ is the same for different lines, and this scheme can be directly extended to the case where $T_\mathrm{ctrl}$ is different for different lines.}. 
To ensure regular train departures at each platform, we define the time interval between two consecutive predetermined departure times as the control time step. The length of the control time step, denoted as $T_\mathrm{ctrl}$, is the same for all platforms along a line, and $\kappa$ is the index of the control time step\footnote{ $T_\mathrm{ctrl}$ is the same for different lines, but this scheme can be extended to cases where $T_\mathrm{ctrl}$ varies between lines.}.

Therefore, the optimization problem for the train rescheduling problem is
\begin{equation}\label{lmpc-problem}
\begin{array}{l}
\mathop {\min }\limits_{\scriptstyle{\bm{g}}(\kappa_0)}  \  J({\kappa_0}) := \sum\limits_{p \in \mathcal{P}} \sum\limits_{k_p \in \mathcal{N}_p(\kappa_0)} \left( {w_1 J_p^\mathrm{pass}(k_p) + w_2 J_p^\mathrm{cost}(k_p)} \right),\\
{\rm{s}}{\rm{.t}}{\rm{.}}\quad \mathrm{(\ref{lmpc-predetermined}) - (\ref{lmpc-cost})},
\end{array}
\end{equation}
where ${\bm{g}}({\kappa_0})$ represents a vector collecting all the variables of problem (\ref{lmpc-problem}), $\mathcal{P}$ is the set collecting all the platforms of the line, $\mathcal{N}_p(\kappa_0)$ is the set indices of trains departing from platform $p$ within the prediction time window starting at time step $\kappa_0$, and $w_1$ and $w_2$ are weights banlacing two objectives.
% where ${\bm{x}}({\kappa_0})$ collects all the independent variables, and ${\bm{u}}({\kappa_0})$ collecting all the decision variables, i.e., $d_{k,p}$, $a_{k,p}$, and $y_{k,p}$ for train $k \in [k_0,\ k_0+N-1]$. 

%{\textbf{The problem contains both continuous variables (i.e., the departure time $d_s(k)$ and the arrival time $a_s(k)$) and binary variables (i.e., $y_s(k)$ and the auxiliary binary variable arising from transforming \texttt{min} function (\ref{lmpc-boarding}) into an MLD model).}}
%Finally, an approximate mixed-integer linear programming-based approach is given in Section~\reflmpc-{MILP-MPC}.

% \section{Model predictive control for real-time train rescheduling}
% In this section, we develop three approaches for real-time train rescheduling. In Section~\ref{lmpc-MINLP-MPC}, a mixed-integer nonlinear programming (MINLP)-based MPC approach is introduced. In Section~\ref{lmpc-RL-MPC}, a learning-based MPC approach is proposed. 

\subsection{MINLP-based MPC for Real-Time Train Rescheduling}\label{lmpc-MINLP-MPC}
Problem (\ref{lmpc-problem}) contains piecewise constant (``if-then") constraints in (\ref{lmpc-y_kp}) and (\ref{lmpc-xi}). We apply the following transformation properties to convert (\ref{lmpc-y_kp}) into a mixed logical dynamical (MLD) system \cite{williams2013model}. 

% \textcolor{red}{Before, we discussed three options, i.e., keeping the original version, 1 binary variable with nonlinear constraints, and 2 binary variables. Here, I started with the options of 2 binary variables. I also tried to keep the transformation properties as short as possible. After finishing the paper, I will put them in appendix. }

{\bf{Transformation property 4.1}}:  If we introduce an auxiliary continuous variable $o_{k,p}$ and an auxiliary binary variable $\gamma_{k_p,p}$ with $\gamma_{k_p,p} = 1 \Leftrightarrow o_{k_p,p} = y_{p}(k_p)$ and $\gamma_{k_p,p} = 0 \Leftrightarrow o_{k_p,p} = -y_{p}(k_p)$, and then $o_{k_p,p} = |y_{p}(k_p)|$ is equivalent to
\begin{equation}\label{lmpc-trans_abs}
\left\{ {\begin{array}{*{40}{l}}
{o_{k_p,p} - y_{p}(k_p) \ge 0,}\\
{o_{k_p,p} - y_{p}(k_p) \le 2Y_\mathrm{max}(1-\gamma_{k_p,p}),}\\
{o_{k_p,p} + y_{p}(k_p) \ge 0,}\\
{o_{k_p,p} + y_{p}(k_p) \le 2Y_\mathrm{max}\gamma_{k_p,p},}\\
\end{array}} \right.
\end{equation}
where $Y_\mathrm{max}$ denotes the maximum value of $y_{p}(k_p)$. 

{\bf{Transformation property 4.2}}:
Based on \emph{Transformation property 4.1}, (\ref{lmpc-eta_kp}) is equivalent to $\eta_{k_p,p} = \left\{ {\begin{array}{*{20}{l}}
{1,\quad {\rm{if}}\quad {o_{k_p,p}} > 0;}\\
{0,\quad {\rm{otherwise}},}
\end{array}} \right.$, which can be
% \begin{equation}\label{lmpc-gamma_kp}
% \eta_{k,p} = \left\{ {\begin{array}{*{20}{l}}
% {1,\quad {\rm{if}}\quad {o_{k,p}} > 0;}\\
% {0,\quad {\rm{otherwise}},}
% \end{array}} \right.
% \end{equation}
%By using the property developed in \cite{bemporad1999control}, 
% we can transform (\ref{lmpc-gamma_kp}) into inequality constraints. 
% {\textbf{Transformation property 4.1}}: 
converted to
\begin{equation}\label{lmpc-trans_gamma}
\left\{ {\begin{array}{*{30}{l}}
{o_{k_p,p} \le \eta_{k_p,p}O_\mathrm{max},}\\
{o_{k_p,p} \ge \epsilon + (1 - \eta_{k_p,p})(O_\mathrm{min} - \epsilon).}
\end{array}} \right.
\end{equation}
where $O_\mathrm{max}$ and $O_\mathrm{min}$ are the minimum and maximum values of $o_{k_p,p}$, respectively, and $\epsilon$ is a sufficiently small number, typically representing machine precision. %Then, (\ref{lmpc-gamma_kp}) is equivalent

Therefore, (\ref{lmpc-y_kp}) can be transformed to
\begin{equation}\label{lmpc-y_kp_linear}
\tau^\mathrm{add}_{p}(k_p) = \eta_{k_p,p} t^\mathrm{cons}_{p}.
\end{equation}

{\bf{Transformation property 4.3}}: 
If we define $m_\mathrm{a}$ and $M_\mathrm{a}$ as the minimum and maximum values of $a_{p'}(k_{p'})$, respectively, then following the transformation property in \cite{bemporad1999control}, (\ref{lmpc-xi}) is equivalent to the following inequalities
\begin{equation}\label{lmpc-transif}
\left\{ {\begin{array}{*{20}{l}}
{{a_{p'}(k_{p'})} - {a_{p}(k_{p})} \le \left( {1 - \xi_{k_{p'},k_p,p',p}} \right)\left( {{M_{\rm{a}}}  \!-\! {a_{p}(k_{p})}} \right),}\\
{{a_{p'}(k_{p'})} - {a_{p}(k_{p})} \ge \varepsilon  + {\xi_{k_p,k_{p'},p,p'}}\left( {{m_{\rm{a}}} \!-\! a_{p}(k_{p}) \!-\! \varepsilon } \right).}
\end{array}} \right.
\end{equation}

Based on the transformations described above, we can convert problem (\ref{lmpc-problem}) into an MINLP problem. The nonlinearity in the MINLP arises from the nonlinear objective function. The integer variables in this problem encompass the train composition variables ($y_{p}(k_p)$ and $\ell_{p}(k_p)$), the train ordering variable ($\xi_{k_p,k_{p'},p,p'}$), and auxiliary binary variables ($\gamma_{k_p,p}$ and $\eta_{k_p,p}$). 

For compactness, we rewrite the resulting MINLP problem in the following form:
\begin{subequations}\label{lmpc-pro}
\begin{align}
&{\mathop {\min }\limits_{\scriptstyle{\bm{x}}(\kappa_0),{\bm{u}}(\kappa_0),{\bm{\delta}}(\kappa_0)} \!  J(\kappa_0) := \sum\limits_{\kappa = {\kappa_0}}^{{\kappa_0}+ {N} - 1} {L(x(\kappa),u(\kappa),\delta(\kappa))} } \label{lmpc-obj}\\
&\quad {\rm{s}}.{\rm{t}}.\quad {x}(\kappa + 1) = {A_\kappa}{x}(\kappa) + {B_{1,\kappa}}{u}(\kappa) + {B_{2,\kappa}}{\delta }(\kappa),\label{lmpc-state}\\
& \quad \qquad {D_{3,\kappa}}{x}(\kappa) + {D_{1,\kappa}}{u}(\kappa) +  {D_{2,\kappa}}{\delta}(\kappa)  \le  {D_{4,\kappa}},\label{lmpc-cons}\\
& \quad  \qquad \kappa = {\kappa_0}, \cdots ,{\kappa_0} + N - 1, \nonumber
\end{align}
\end{subequations}
where $N$ is the total number of time steps, ${x}(\kappa)$, ${u}(\kappa)$, and ${\delta}(\kappa)$ collect all the independent variables, continuous decision variables, and discrete decision variables for time step $\kappa$, respectively, and ${\bm{x}}(\kappa_0) = [{x}^\intercal (\kappa_0), {x}^\intercal(\kappa_0+1), \ldots, {x}^\intercal(\kappa_0+N-1)]^\intercal $, ${\bm{u}}(\kappa_0) = [{u}^\intercal (\kappa_0), {u}^\intercal(\kappa_0+1), \ldots, {u}^\intercal(\kappa_0+N-1)]^\intercal$, and ${\bm{\delta}}(\kappa_0) = [{\delta}^\intercal (\kappa_0), {\delta}^\intercal(\kappa_0+1), \ldots, {\delta}^\intercal(\kappa_0+N-1)]^\intercal$. In (\ref{lmpc-pro}),  ${L(x(\kappa),u(\kappa),\delta(\kappa))}$ represents the nonlinear objective function for time step $\kappa$, (\ref{lmpc-state}) collects all equality constraints, and (\ref{lmpc-cons}) collects all inequality constraints.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=7cm]{MPC2.pdf}    % The printed column width is 8.4 cm.
\caption{Model predictive control for real-time train rescheduling.}
\label{lmpc-mpc}
\end{center}
\end{figure}

Solving (\ref{lmpc-pro}) leads to a series of continuous decision variables and discrete decision variables, and only the decision variables at time step $\kappa_0$ are applied. At the next time step, the prediction time window is shifted for one step, and a new optimization is formulated. The framework is depicted in Fig.~\ref{lmpc-mpc}.
% \section{Model predictive control for real-time train rescheduling}\label{lmpc-lmpc_approach}

{\bf{Lemma 1}} (\emph{Recursive Feasibility}): If problem (\ref{lmpc-pro}) is feasible at time step $\kappa$ with initial state $x(\kappa)$, then problem (\ref{lmpc-pro}) is also feasible at time step $\kappa+1$. 
\begin{proof}
    The proof relies on finding a feasible solution for time step $\kappa+1$. Recall that the planning time window at each platform is divided into several intervals of equal length, with a train service departing from the platform at each interval according to (\ref{lmpc-predetermined}). In general, there are two types of depots: (i) depots connected to the terminal platform (e.g., Platform 1 in Fig.~\ref{lmpc-line}), and (ii) depots connected to intermediate platforms (e.g., Platform 2 in Fig.~\ref{lmpc-line}).
    
    i) For a depot connected to the terminal platform: if the problem (\ref{lmpc-pro}) is feasible at time step $\kappa$, then at each time step, a train service returns to the depot from the opposite direction of the line. In this context, the new train service departing from the terminal platform at step $\kappa + 1$ can directly utilize the train units by performing a turnaround from the opposite direction of the line following (\ref{lmpc-turnaround}). Moreover, utilizing one train unit when performing the turnaround action is always feasible.

    ii) For any depot connected to an intermediate platform: a feasible solution is obtained by maintaining the composition of each train service the same as it was at time step $\kappa$. % In this context, the new train units from the depot are not required, and a feasible timetable for time step $\kappa+1$ can be achieved. 
\end{proof}


\subsection{MILP-based MPC for Real-Time Train Rescheduling}\label{lmpc-MILP-MPC}
In Section~\ref{lmpc-mpc_formualtion}, a nonlinear objective function has been defined in (\ref{lmpc-pass}) to calculate the passenger delays. This nonlinear objective function results in the MINLP-based MPC approach formulated in Section~\ref{lmpc-MINLP-MPC}. In general, the nonlinear term significantly increases the computational burden. In what follows, we simplify the nonlinear objective function to reduce the computational burden. 

Since we divide the planning time window as indicated in Fig.~\ref{lmpc-demands_original} and the actual departure time $ d_{p}(k_p)$ is constrained by
$d^\mathrm{pre}_{p}(k_p) \le d_{p}(k_p) < d^\mathrm{pre}_{p}(k_p+1)$, by using the upper bound and lower bound of $d_{p}(k_p)$ we approximate the nonlinear objective function (\ref{lmpc-pass}) by 
\begin{align}\label{lmpc-pass_linear}
J_p^\mathrm{pass}(k_p) \approx &w_3 n_{p}(k_p)\left( {d^\mathrm{pre}_{p}(k_p+1) - d^\mathrm{pre}_{p}(k_p)} \right)+ \nonumber\\
&+ n^\mathrm{after}_{p}(k_p)\left( { d^\mathrm{pre}_{p}(k_p+1) -  d^\mathrm{pre}_{p}(k_p)} \right),
\end{align}
where $w_3$ is a weight used to balance the approximated errors. In particular, $w_3$ can be defined as
\begin{equation}\label{lmpc-w3}
    w_3 = \frac{1}{ \sum_{p\in \mathcal{P}}|\mathcal{I}_p|}\sum_{p\in \mathcal{P}}\sum_{k_p\in \mathcal{I}_p}\frac{\bar d_{p}(k_p) -  d^\mathrm{pre}_{p}(k_p)}{d^\mathrm{pre}_{p}(k_p+1) -  \bar d_{p}(k_p)},
\end{equation}%as $ d_{p}(k_p)$ is typically closed to the predefined departure time $d^\mathrm{pre}_{p}(k_p)$, and approximating  $ d_{p}(k_p)$ as $d^\mathrm{pre}_{p}(k_p+1)$ may cause the first term of the objective function to be overly large. 
where $|\mathcal{I}_p|$ represents the cardinality of $\mathcal{I}_p$, and $ \bar d_{p}(k_p)$ represents the average value of  $ d_{p}(k_p)$ from historical data.

Other settings are identical to those of Section~\ref{lmpc-MINLP-MPC}. With this approximation, a linear objective function (\ref{lmpc-pass_linear}) is obtained, and due to the objective function and constraints being all linear, we obtain an MILP-based MPC approach for real-time train rescheduling. 


\section{Learning-based MPC for Real-Time Train Rescheduling}\label{lmpc-lmpc_approach}
For the MINLP-based MPC and MILP-based MPC in Section~\ref{lmpc-mpc_approach}, an MINLP or MILP problem should be solved at each step, which is typically not computationally affordable for real-time application as the number of integer variables significantly influences the computational complexity. % the resulting MINLP problem is an NP-hard problem and the solution time increases rapidly as the number of integer variables increases. 
% \textcolor{blue}{To handle the computational complexity issues, we develop a learning-based MPC approach where the integer variables are obtained by leveraging presolve techniques and the presolve and recurrent network-based mixed-integer solution method (PRISM) developed in \cite{cauligi2022prism}}, and then the MPC optimizer only needs to solve a continuous nonlinear optimization problem with fewer variables than the original problem at each time step.
In \cite{cauligi2022prism}, a presolve and recurrent network-based mixed-integer solution method (PRISM) was developed to handle mixed-integer convex programming problem, where an LSTM network generates the integer variables, and then a convex optimization problem is solved to improve the solution efficiency. 
To handle computational complexity issues arising in train rescheduling problems, based on PRISM \cite{cauligi2022prism}, we develop a learning-based MPC approach with presolve techniques tailored to the train rescheduling problem with flexible train composition. In this setting, recurrent neural networks, such as LSTM neural networks, and presolve techniques are used to assign the integer variables of an MPC problem.
% In PRISM, a set of presolve techniques and a LSTM neural network are used to predict the integer variables of a MPC problem.
As a result, at each time step, the MPC optimizer only needs to solve a continuous nonlinear optimization problem with fewer variables than the original problem. 
The main difference between the proposed approach and that of \cite{cauligi2022prism} consists of the presolve techniques and integration with the MPC framework, which are specifically designed for real-time train rescheduling.

%To handle computational complexity issues, based on PRISM \cite{cauligi2022prism}, we develop a learning-based MPC approach with presolve techniques tailored to the train rescheduling problem with flexible train composition. In this setting recurrent neural networks, such as LSTM neural networks, and presolve techniques are used to predict the integer variables of a MPC problem.
% In PRISM, a set of presolve techniques and a LSTM neural network are used to predict the integer variables of a MPC problem. As a result, the MPC optimizer only needs to solve a continuous nonlinear optimization problem with fewer variables than the original problem at each time step.  The main difference of the proposed approach and that of \cite{cauligi2022prism} consists in the presolve techniques and integration with the MPC framework, which have been specifically designed to our application.

\subsection{Presolve Techniques}\label{lmpc-presolve}
% The resulting problem (\ref{lmpc-problem}) is an MINLP problem, and the number of integer variables significantly influences the computational complexity. 
Presolve techniques streamline optimization processes by pruning a subset of decision variables with values predetermined by other coupled variables and constraints, setting them to predefined values. In this paper, we develop the following presolve techniques.  %Presolve techniques can prune a subset of decision variables, whose values have already been determined by other coupled variables and constraints, by setting them to predetermined values.

% As we adjust the departure time of train service $k$ at platform $p$ according to $d^\mathrm{pre}_{k,p} \le d_{k,p} < d^\mathrm{pre}_{k+1,p}$, the departure order between some trains has already been determined based on \bf{Presolve technique 4.1}.

{\bf{Presolve technique 5.1:}} As we adjust the departure time of train service $k$ at platform $p$ according to $d^\mathrm{pre}_{p}(k_p) \le d_{p}(k_p) < d^\mathrm{pre}_{p}(k_p+1)$, the departure order between some trains has already been determined: If $d^\mathrm{pre}_{p}(k_p) \ge d^\mathrm{pre}_{p'}(k_{p'}+1) + t_{p'}^\mathrm{roll}$, then $\xi_{k_p,k_{p'},p,p'} = 1$. If $d^\mathrm{pre}_{p}(k_p+1) \le d^\mathrm{pre}_{p'}(k_{p'}) + t_{p'}^\mathrm{roll}$, then $\xi_{k_p,k_{p'},p,p'} = 0$. 

{\bf{Presolve technique 5.2:}} According to the definition of $\xi_{k_p,k_{p'},p,p'}$ in (\ref{lmpc-xi}), the order of trains at the same platform should be kept consistent, i.e., $\xi_{k_p+1,k_{p'},p, p'} \ge \xi_{k_p,k_{p'},p,p'}$. 

{\bf{Presolve technique 5.3:}} The train composition cannot be changed at a station that is not linked with a depot: If $\sigma_p = 0$, then $y_{p}(k_p) = 0$.

{\bf{Presolve technique 5.4:}} Let $t_0 = \kappa_0 T$ represent the current time. If train service $k_p$ has already departed from station $p$ at time $t_0$, the composition cannot be changed at that station: If $d_{p}(k_p) \le t_0$, $y_{p}(k_p) = y_{p}^*(k_p), \ \forall p \in \mathcal{P}$, where $y_{p}^*(k_p)$ represents the value of $y_{p}(k_p)$ obtained before train $k$ departs from platform $p$ and $\mathcal{P}$ denotes the set of all platforms of the line.

\subsection{Environment Setting}
The environment of the learning-based MPC algorithm includes the system and an MPC optimization problem. The state and variables that interact with the environment are defined as follows: 

{\bf{State}} $\bm{s}(\kappa) \in S$: The state space ought to encompass all necessary information of the framework so that the neural network can be trained such that the input can capture as much possible situations as possible. Hence, state at time step $k$ is defined as:
\begin{equation}
    \bm{s}(\kappa) = [\bm{n}^\intercal(\kappa), \bm{\rho}^\intercal(\kappa), \bm{N}^\intercal(\kappa) ]^\intercal,
\end{equation}
where $\bm{n}(\kappa)$ includes the variables $n_{p}(k_p)$ for train service $k_p$ at its corresponding platform $p$ with $\kappa T \in [d_{p}^\mathrm{pre}(k_p-1), d_{p}^\mathrm{pre}(k_p))$,  $\bm{\rho}(\kappa)$ collects the passenger demands $\rho_{p}(k_p)$ for all train services $k_p$ departing from all platforms $p$ from time $t = \kappa T$ to the end of the prediction time window, and $\bm{N}(\kappa)$ collects the number of available trains for all depots at time  $t = \kappa T$.

{\bf{Discrete variables}} $\bm{\delta}(\kappa) \in A$: The discrete variables correspond to the discrete variables of the MPC optimization problem (\ref{lmpc-pro}) in each step. Before we evaluate the discrete variable, we first implement the presolve techniques in Section~\ref{lmpc-presolve} to avoid infeasible actions, and then, we solve the resulting problem corresponding to the discrete action. %, the discrete action $\bm{\hat\delta}(\kappa)$ collects all independent discrete variables at time step $\kappa$. 
% Thus, we have
% \begin{equation}
%     \bm{\hat\delta}(\kappa_0) = F(\bm{\delta}(\kappa_0)),
% \end{equation}
% where $F(\cdot)$ is a mapping from discrete variables to independent discrete variables based on the presolve techniques.

{\bf{Continuous variables}} $\bm{u}(\kappa) \in U$: The continuous variables represent the continuous decision variables at time step $\kappa$ in the MPC optimization problem (\ref{lmpc-pro}).

% {\bf{Reward}} $r(\bm{s}(\kappa), \bm{\delta}(\kappa)) \in R$: To synchronize RL and MPC for optimal performance, the reward function should incorporate the objective function value of the MPC optimization problem. To avoid infeasible actions, a negative reward should be applied if the problem (\ref{lmpc-pro}) is infeasible.  As we reschedule trains based on the original timetable, achieving better performance than the original schedule is desirable. In such cases, a larger reward should be given. Conversely, if the performance is worse than that of the original timetable, a smaller reward is required. We normalize the reward based on the objective function value of the original timetable, and the reward function is designed as
% \begin{equation}
% \small
% r(\bm{s}(\kappa), \bm{\delta}(\kappa)) = \left\{ \begin{gathered}
%   1 + \frac{{J({\kappa})- {J_{{\text{orig}}}}({\kappa })}}{{{J_{{\text{low}}}}({\kappa}) - {J_{{\text{orig}}}}({\kappa })}}, \ \ {\text{if }} \ J({\kappa}) \leqslant {J_{{\text{orig}}}}({\kappa }), \hfill \\
%   1 - \frac{{J({\kappa})}- {J_{{\text{orig}}}}({\kappa })}{{{J_{{\text{up}}}}({\kappa})}- {J_{{\text{orig}}}}({\kappa })}, \quad {\text{if }}\ J({\kappa}) > {J_{{\text{orig}}}}({\kappa}), \hfill \\
%    - 1,\qquad \qquad \qquad \qquad \ \ {\text{if (\ref{lmpc-pro}) is infeasible}}{\text{,}} \hfill \\ 
% \end{gathered}  \right.
% \end{equation}
% % \begin{equation}
% % r(\bm{s}(\kappa), \bm{\delta}(\kappa)) = \begin{cases}
% % 1 + \frac{{J({\kappa})- {J_{{\text{orig}}}}({\kappa })}}{{{J_{{\text{low}}}}({\kappa}) - {J_{{\text{orig}}}}({\kappa })}}, & {\text{if }} \ J({\kappa}) \leqslant {J_{{\text{orig}}}}({\kappa }),\\
% % 1 - \frac{{J({\kappa})}- {J_{{\text{orig}}}}({\kappa })}{{{J_{{\text{up}}}}({\kappa})}- {J_{{\text{orig}}}}({\kappa })}, & {\text{if }}\ J({\kappa}) > {J_{{\text{orig}}}}({\kappa}),\\
% % - 1, & {\text{if (\ref{lmpc-pro}) is infeasible}}{\text{,}}
% % \end{cases}
% % \end{equation}
% where $J({\kappa})$ represents the optimized objective function value of problem (\ref{lmpc-pro}) at time step $\kappa$ for state $\bm{s}({\kappa})$ and discrete action $\bm{\delta} ({\kappa})$, ${{J_{{\text{low}}}}({\kappa})}$ and ${{J_{{\text{up}}}}({\kappa})}$ denote a lower bound and an upper bound of $J({\kappa})$, respectively, which can be estimated based on the history data, and ${J_{{\text{orig}}}}({\kappa})$ is the objective function value of $J({\kappa})$ with the original timetable.

\subsection{Offline Training for Learning-based Algorithms}\label{lmpc-offline}
% In practice, the train schedules between consecutive time steps are not independent, i.e., the timetable of a time interval will influence the timetable in the following periods due to the headway relation between trains and the physical connection between stations.
In practice, the train schedules across consecutive time intervals are interdependent %. The timetable of a specific time interval exerts influence on subsequent periods 
due to the headway relation between trains and the physical connections between stations. The neural network should be able to capture and retain essential information over sequences time intervals. 
Therefore, a long short-term memory (LSTM) network \cite{hochreiter1997long,cauligi2022prism} is applied to train the agent. As a deep recurrent neural network (RNN), the LSTM architecture enables the network to remember the dynamic interdependencies within train schedules, ensuring effective adaptation and learning in response to evolving temporal dynamics.

% The training procedure of the learning-based MPC approach is shown in Fig.~\ref{lmpc-LSTM}. At each step,  the LSTM network takes the current state as input, and the hidden state $h_\kappa$ is initially processed through a feedforward layer to generate objective function values for all possible discrete variables. % the state is the input of the LSTM network, and the hidden state $h_\kappa$ will be first passed through a feedforward layer to generate the Q values of all possible discrete actions. 
% The hidden state $h_\kappa$ and $c_\kappa$ are then passed to the LSTM network at the next time step. 
% % \begin{figure}[htbp]
% % \begin{center}
% % \includegraphics[width=8cm]{LSTM.eps}    % The printed column width is 8.4 cm.
% % \caption{Training procedure of the RL-MPC approach with LSTM.}
% % \label{lmpc-LSTM}
% % \end{center}
% % \end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=8.5cm]{LSTM_SL.pdf}    % The printed column width is 8.4 cm.
\caption{Training procedure of the learning-based MPC approach with LSTM.}
\label{lmpc-LSTM}
\end{center}
\end{figure}

% Two branches of LSTM networks are trained based on the MINLP-based and MILP-based approaches, respectively, where an ensemble of LSTM networks is trained in each brach to improve the feasibility rate of the solution.  Two branches of LSTM networks are trained based on the MINLP and MILP approaches, respectively, with an ensemble of LSTM networks in each branch to improve the solution's feasibility rate. For each network, the training procedure for the learning-based approach is shown in Fig.~\ref{lmpc-LSTM}, where $h_{\kappa}$ represents the hidden state vector, $c_{\kappa}$ denotes the cell state vector, FC$_1$ and FC$_2$ are feedforward blocks. The block FC$_1$ is a fully connected layer that transforms the state vector into a vector the size of the hidden state, i.e. it is the input layer of the proposed neural network architecture. The block FC$_2$ is a fully connected layer that has the role of providing scores for every the possible action sequence. It combines the output of the LSTM in such a way that the resulting vector has as its length the of number of possible action sequences. The activation function of FC$_2$ is a softmax function and the resulting output represents the likelihood of the possible action sequences. At each training step, a data set group is randomly selected, followed by a random time step in the timetable. The LSTM network takes the current state as input, and the hidden state $h_\kappa$ is initially processed through a feedforward layer to generate the values of the objective function for all possible discrete variables. The value of the objective function at the time step $\kappa$, corresponding to the state transition $\bm{s}$ and the discrete variable $\bm{\delta}(\kappa)$ generated by the LSTM network, is indicated as $J_{\bm{s}}(\kappa, \bm{\delta}(\kappa))$. % the state is the input of the LSTM network, and the hidden state $h_\kappa$ will be first passed through a feedforward layer to generate the Q values of all possible discrete actions. 

An ensemble of LSTM networks is trained based on the MINLP approaches to improve the solution's feasibility rate. For each network, the training procedure for the learning-based approach is shown in Fig.~\ref{lmpc-LSTM}, where $h_{\kappa}$ represents the hidden state vector, $c_{\kappa}$ denotes the cell state vector, and FC$_1$ and FC$_2$ are feedforward blocks. The block FC$_1$ is a fully connected layer with an identity activation function that transforms the state vector into a vector with the size of the hidden state. %, i.e. it is the input layer of the proposed neural network architecture. 
The block FC$_2$ is a fully connected layer with a softmax activation function, and the resulting output represents the likelihood of possible action sequences. % to provide scores for all possible action sequences. %It combines the output of the LSTM in such a way that the resulting vector has as its length the of number of possible action sequences. 
% The activation function of FC$_2$ is a softmax function. %and the resulting output represents the likelihood of the possible action sequences. 
At each training step, a random day from the dataset is selected, followed by a random time step from the timetable. The LSTM network takes the current state and the hidden state as inputs % $h_\kappa$ is processed through a feedforward layer 
to generate the objective function values for possible discrete variables. 

The mean squared error (MSE) is applied to update the parameters of the LSTM network as the optimizer with the following loss function:
\begin{equation}\label{lmpc-mse}
L^\mathrm{cross} = \frac{1}{|\mathcal{S}|}\sum_{\bm{s} \in \mathcal{S}}\sum_{\kappa = \kappa_0}^{\kappa_0 + N-1} \big(J_{\bm{s}}^*(\kappa) -  J_{\bm{s}}(\kappa,\bm{\delta}(\kappa)) \big)^2,%\sum_{s \in \mathcal{S}}\sum_{\kappa = \kappa_0}^{\kappa_0 + N-1} \big(- F^*(\kappa) +  \log ( e^{F(\kappa,\delta(\kappa))}  ) \big),
\end{equation}
where $L^\mathrm{cross}$ represents the loss function, %$s$ is the index of the transitions, 
$\mathcal{S}$ defines a set collecting all transitions, $|\mathcal{S}|$ denotes the cardinality of $\mathcal{S}$,  $J^*_{\bm{s}}(\kappa)$ represents the optimal objective function value for the state $\bm{s}$ at time step $\kappa$, obtained by solving the resulting MINLP problem, and $J_{\bm{s}}(\kappa, \bm{\delta}(\kappa))$ represents the objective function value at time step $\kappa$, corresponding to the state transition $\bm{s}$ and the discrete variable $\bm{\delta}(\kappa)$, generated by the LSTM network, i.e., objectives in Fig.~\ref{lmpc-LSTM},. % In particular, $J_{\bm{s}}(\kappa)$ corresponds to the optimal value of the MINLP in the first branch of LSTM networks and the optimal value of the MILP in the second branch.   %and $J_{\bm{s}}(\kappa,\delta(\kappa))$ is the value of objective function of transition $s$ at time step $\kappa$ with discrete variable $\delta(\kappa)$.
% The dropout \cite{srivastava2014dropout} method is introduced to handle the over-fitting issue with 

At the next training step, the hidden states $h_{\kappa}$ and $c_{\kappa}$ from the current step are passed to the LSTM network. A new data set group is then randomly selected, followed by a random time step selection. Then, (\ref{lmpc-mse}) is applied to update the LSTM network parameters. This procedure is repeated until the end of the training process.

% \begin{figure}[htbp]
% \begin{center}
% \includegraphics[width=8cm]{LSTM.eps}    % The printed column width is 8.4 cm.
% \caption{Training procedure of the RL-MPC approach with LSTM.}
% \label{lmpc-LSTM}
% \end{center}
% \end{figure}

% {\color{magenta}{Introduce the output mask}

% I introduced in the next section. I hope that it is fine.}

\subsection{Online Implementation of Learning-based MPC}

% The framework of the learning-based MPC approach is provided in Fig.~\ref{lmpc-SL_MPC}. The approach generates pruned discrete variables at each step according to the current state and the neural networks trained in Section~\ref{lmpc-offline}. Then, all the discrete variables can be obtained based on the pruned discrete variables and the presolve techniques in Section~\ref{lmpc-presolve}.   Once the discrete variables have been determined, the MPC optimization problem of Section~\ref{lmpc-MINLP-MPC} becomes a continuous-variable nonlinear programming (NLP) problem, while the MPC optimization problem of Section~\ref{lmpc-MILP-MPC} reduces to a linear programming (LP) problem.  By solving the resulting NLP or LP problem, the optimal continuous variable values can be obtained to get the timetable, and the new state of the railway network can be obtained after implementing the obtained timetable. % By solving the resulting MPC optimization problem, a new reward can be obtained based on the optimized objective function value, and the new state can be obtained after implementing the obtained discrete and continuous variables. 
The framework of the learning-based MPC approach is shown in Fig.~\ref{lmpc-SL_MPC}. At each step, pruned discrete variables are generated based on the current state and the neural networks trained in Section\ref{lmpc-offline}. These pruned discrete variables, combined with the presolve techniques from Section~\ref{lmpc-presolve}, allow for the determination of all discrete variables. Once the discrete variables are established, the MPC optimization problem from Section~\ref{lmpc-MINLP-MPC} becomes a continuous-variable nonlinear programming (NLP) problem, while the problem in Section~\ref{lmpc-MILP-MPC} simplifies to a linear programming (LP) problem. Solving the resulting NLP or LP problem yields the optimal continuous variable values, which are used to generate the timetable. After implementing the timetable, the new state of the urban rail transit network is observed and used to generate pruned discrete variables for the next time step. This procedure is repeated until the control process is complete. 

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=8.5cm]{SL_MPC.pdf}    % The printed column width is 8.4 cm.
\caption{Learning-based MPC for real-time train rescheduling.}
\label{lmpc-SL_MPC}
\end{center}
\end{figure}

To improve the feasibility rate of the integer variables generated by LSTM networks, for each branch of LSTM networks trained in Section~\ref{lmpc-offline}, the networks are sequentially employed to generate integer variables. % The inference process is carried out sequentially, with the $(i+1)$th network evaluated only if the $i$th and all preceding networks fail to produce a feasible solution. 
Moreover, {\emph{Lemma 1}} can be applied when LSTM networks fail to generate feasible integer variables, ensuring that feasible integer variables are always obtained. 
% Moreover, the solution stated in {\emph{Lemma 1}} can also be applied when LSTM networks cannot generate feasible integer variables, thereby ensuring feasible integer variables can always be obtained. 
In this context, the recursive feasibility of the learning-based MPC approach can be guaranteed.

% To deal with the issue that the inference time of the LSTM networks and the time required for feasibility checks are sufficiently low, an ensemble of LSTM networks is sequentially employed to generate integer variables to improve the overall feasibility of the learning-based approaches. The inference process of the LSTM networks in the ensemble is performed sequentially, where the $(i\!+\!1)$th network is evaluated only if the $i$th and all preceding networks fail to produce a feasible solution.

% \begin{figure}[htbp]
% \begin{center}
% \includegraphics[width=8cm]{RL_MPC2.eps}    % The printed column width is 8.4 cm.
% \caption{RL-MPC for real-time train rescheduling.}
% \label{lmpc-SL_MPC}
% \end{center}
% \end{figure}

% \begin{algorithm}[h!]
%   \caption{Reinforcement learning based model predictive control approach}  
%   \label{lmpc-hmpc}  
%   \begin{algorithmic}[1]  
%     \Require  prediction horizon $N$; terminate time index $\kappa_{\max}$; 
%     initial state $\bm{n}(\kappa_0)$, $\bm{\rho}(\kappa_0)$, $\bm{N}(\kappa_0)$;
%     \Ensure  
%       discrete decision variables $\bm{\delta}(\kappa)$; continuous decision variables $\bm{u}(\kappa)$
%     \State $\kappa \gets \kappa_0$
%     \Repeat 
%     %\For{$k = k_0, \cdots, k_\mathrm{max}$}
%     \State $\vartheta \gets \vartheta_0(k)$
%     \State solve the higher-level problem (\ref{lmpc-pro}), get $u_\ell (k)$ and $f_p(k)$
% %    \State implement Algorithm~\ref{lmpc-feasible} to get feasible $u_\ell (k)$
%     \Repeat
%     %\For{$\vartheta = \vartheta_0  , \cdots, \vartheta_\mathrm{end}$  }
%       \State solve problem (\ref{lmpc-lowermpc}), get $a_{i,p}$ and $d_{i,p}$
%       \State implement $a_{i,p}$ and $d_{i,p}$ to real-life network
%       \State $\vartheta \gets \vartheta +1$
%       \State collect real-life value of $a_{i,p}$, $d_{i,p}$, and $n_{p,e}(k)$
%       \Until $\vartheta = \vartheta_\mathrm{max}(k)$
%     \State $\kappa \gets \kappa+1$
%     \State calculate real-life values of ${\gamma _p}$, $\bar r_p$
%      \Until $\kappa = \kappa_\mathrm{max}$
%   \end{algorithmic}  
% \end{algorithm}


\section{Case Study}\label{lmpc-section6}
\subsection{Basic Setting}
In this section, we illustrate the proposed approaches based on real-life data from a network of three lines in the Beijing urban rail transit network. As shown in Fig.~\ref{lmpc-3lines}, the network including 3 bi-directional lines with 45 stations. There are 3 transfer stations, i.e., Station ZXZ, Station XEQ, and Station HY, where passengers can transfer from one line to another.
%the Yizhuang Line is a bi-directional line consisting of 14 stations and two depots. The two depots are located on both ends of the line.  
For each line, there is a depot connected with the starting station of the line, i.e., Station CPX for Changping Line, Station XZM for Line 13, and Station ZXZ for Line 8. 
%The line information is provided in Table~\ref{lmpc-line_information}. 
The values of parameters for the case study are given in Table~\ref{lmpc-parameters}.   The original timetable is generated based on the regular headway, regular dwell time, and average running times in Table~\ref{lmpc-parameters}.  According to the definition, the length of a time step is the sum of the regular headway and the regular dwell time. The number of train units in the depot for each line has been selected as a random integer number with the value varying among the range given in Table~\ref{lmpc-parameters}. 

The length between every two consecutive stations is openly accessible on the website of Beijing Subway\footnote{https://www.bjsubway.com/station/zjgls/}.  In the case study, the average running time and the average energy consumption of a train between every two consecutive stations are calculated using the method in \cite{wang2015efficient} with the maximum acceleration of 0.75 m/s$^2$, the maximum deceleration of 0.7 m/s$^2$, and the cruising speed of 70 km/h, respectively. The sectional passenger demands are obtained based on real-life passenger flow data from the Beijing urban rail transit network, collected in January 2020. We have selected data from 6:00 AM to 10:00 PM for simulation, so the data contains both peak hours and off-peak hours. For training agents and simulation, we have generated passenger demands based on a Poisson distribution by using real-life passenger flow data as the expected value.   % and the number of train units in the depot corresponding to Station YH has been selected as a random integer number between 35 and 45.
% \begin{figure}[htbp]
% \begin{center}
% \includegraphics[width=8cm]{YizhuangLine_direction.eps}    % The printed column width is 8.4 cm.
% \caption{The layout of Beijing Yizhuang Line.}
% \label{lmpc-Yizhuang}
% \end{center}
% \end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=8.5cm]{3_full_lines.pdf}    % The printed column width is 8.4 cm.
\caption{The layout of considered urban rail transit network (with 3 lines).}
\label{lmpc-3lines}
\end{center}
\end{figure}

% \begin{table}[htbp]
% \centering
% \caption{Information of Yizhuang Urban Rail Transit Line}\label{lmpc-line_information}%[H]
% \begin{tabular}{cccc} 
% \hline
% {Section} & Distance [m] & \makecell[c]{Average \\ running time  [s]}& \makecell[c]{Energy consumption}\\ \hline
% %& Line & &\\ 
% SJ - XC & 1334  & 70.62 & 33.68\\
% XC - XHM & 1281 & 67.82 & 32.88\\
% XHM - JG& 2055 & 108.79 & 44.57\\
% JG - YZQ & 2301 &  121.82 & 48.28 \\
% YZQ - WHY & 2337 & 123.72 & 48.82 \\
% WHY - WYJ  & 1355 & 71.74 & 34.00\\
% WYJ - RJD  & 1090  & 57.71 & 30.00 \\
% RJD - RCD & 1728 & 91.48 & 39.63\\
% RCD - TJN & 993 & 52.57 & 28.53\\
% TJN - JHL & 1982 & 104.93 & 43.46 \\
% JHL - CQN & 2366 & 125.26 & 49.26 \\
% CQN - CQ & 1275 & 67.50  & 32.79\\
% CQ - YH & 2631 & 139.29 & 53.26\\
% \hline
% \end{tabular}
% \end{table}

\begin{table}[htbp]
\centering
\caption{Main parameters for the case study}\label{lmpc-parameters}%[H]
\begin{tabular}{lll} 
\hline
Parameter & Symbol & Value \\ \hline
%& Line & &\\ 
Regular headway & $h_p^\mathrm{regular}$ & 180 s \\
Minimum headway & $h_p^\mathrm{min}$ &120 s\\
Regular dwell time& $\tau_p^\mathrm{regular}$ & 60 s\\
Minimum dwell time & $\tau_p^\mathrm{min}$ &  30 s \\
Average turnaround time & $r_p^\mathrm{turn}$ & 52.9 s \\
Minimum running time & $r_p^\mathrm{min}$ &  $0.8 \cdot r_p^\mathrm{avrg}$ \\
Maximum running time & $r_p^\mathrm{max}$ &  $1.2 \cdot r_p^\mathrm{avrg}$ \\
Time for changing train composition & $t_p^\mathrm{cons}$ & 60 s \\
Time for rolling stock circulation & $t_p^\mathrm{roll}$ & 240 s \\
Transfer rate at a transfer station&  $\beta_{q,p}$ & 10\% \\
Capacity of a train unit & $C_\mathrm{max}$ & 400 persons \\
Regular train composition of a train service& $\ell_p^\mathrm{regular}$ & 2 train units \\
\makecell[l]{Minimum number of train units\\ \ \ included in a train service} & $\ell_p^\mathrm{min}$ &  1 train unit\\
\makecell[l]{Maximum number of train units\\ \ \ included in a train service} & $\ell_p^\mathrm{max}$ &  4 train units\\
Weighted term  &  $w_1$   &  $10^{-4}$\\
Weighted term  &  $w_2$   &  $10^{-1}$\\
Weighted term  &  $w_3$ &  $10^{-1}$\\
Number of train units for Changping Line& $N_z^{\mathrm{train}}$ & [55, 75]\\
Number of train units for Line 13& $N_z^{\mathrm{train}}$ & [70, 90]\\
Number of train units for Line 8& $N_z^{\mathrm{train}}$ & [60, 80]\\
Prediction horizon of MPC & $N$ & 40 \\
\hline
\end{tabular}
\end{table}
% We conduct our simulations using python on a computer equipped with an Intel Xeon W-2223 CPU and 8GB of RAM. For exact optimization, we adopt the \texttt{gurobi} solver implemented in python.

The simulations have been conducted using Python as a programming language, PyTorch as the machine learning library, and \texttt{gurobi} to solve optimization problems.  Adam \cite{kingma2014adam} is applied in the offline training process to minimize MSE, and dropout \cite{srivastava2014dropout} is used to handle the over-fitting issue.  Moreover, the experiments were conducted on a computing cluster with Intel XEON E5-6248R CPUs. The dataset consists of $96000$ states and the corresponding optimal solutions, and it has been built using 60 CPU cores and 240GB of RAM in $24$ hours. The training and hyperparameter tuning processes have been conducted using 144 CPU cores, 864GB of RAM, using more than 200000 iterations for $24$ hours. 
% On the other hand, for the neural network, the size of the hidden layer has been set to $128$ and the size of the feedforward layer to $128 \cdot 144$. With a batch size of $32$, the total training and validation time was around $24$ minutes on a laptop equipped with an Intel XEON E5-6248R CPU and 32GB RAM.

To reduce the solution time of the MINLP solver without significantly compromising optimality, a simple early termination criterion was employed: if the optimality gap does not decrease by 0.5\% within 10 seconds, the solution process terminates, and the solver outputs the best solution found. Moreover, as the MILP-based approach typically has a significantly shorter solution time than the MINLP-based approach, the integer variables generated by the MILP-based approach are used as a warm-start rule for the MINLP-based approach. 

In this section, the developed train rescheduling approaches, i.e., MINLP-based MPC, warm-start-MINLP-based MPC, MILP-based MPC, learning-NLP-based MPC, and learning-LP-based MPC are evaluated. 
As defined in Section~\ref{lmpc-section3}, the length of a time step is 240\ s. Hence, to ensure that a solution can be obtained for each time step, we set the maximum solution time for each approach as 240\ s. In addition, as a longer solution time typically yields better objective function value, we use the MINLP approach with warm-start and a longer maximum solution time, i.e., 600\ s, as a benchmark to evaluate the performance of the developed approaches.  

% Two branches of LSTM networks have been trained based on the MINLP-based and MILP-based approaches, respectively, with 15 LSTM networks for each branch. %As the inference time of the LSTM networks and the time required for feasibility checks are sufficiently low, instead of using a single LSTM network, an ensemble of 
To improve the overall feasibility of the learning-based approaches, 15 LSTM networks were trained separately, and the 15 LSTM networks were sequentially employed for each branch to generate integer variables. The inference process of the LSTM networks in the ensemble is performed sequentially, where the $(i\!+\!1)$th network is evaluated only if the $i$th and all preceding networks fail to produce a feasible solution.  %The rationale for using an ensemble stems from the need to enhance feasibility, as a single LSTM network failed to meet performance expectations in this regard. Additionally, in our configuration, the inference time of the LSTM networks and the time required for feasibility checks are sufficiently low. Therefore, utilizing an ensemble is a viable strategy to improve overall feasibility.
% In the learning-based approach, an ensemble of 15 LSTM networks was used to provide the integer variables to the MPC controller. The motivation for using an ensemble is to increase feasibility since a single LSTM network did not perform in this regard. Moreover, in our setting, the inference time of the LSTM network and the time for checking feasibility are relatively low. Hence, using an ensemble is a viable option to increase feasibility.
In particular, the ensemble consists of LSTM networks with hidden sizes from the set $\{512,\ 1024\}$, dropout rates from the set $\{0,\ 0.5\}$, learning adjusting in the set $\{\mathrm{on},\ \mathrm{off}\}$, and output masking in the set $\{\mathrm{on},\ \mathrm{off}\}$.  
% The ensemble consists of LSTMs with hidden size in the set $\{512,\ 1024\}$, dropout in the set $\{0,\ 0.5\}$, learning rate scheduling in the set $\{\mathrm{ON},\ \mathrm{OFF}\}$, and output masking in the set $\{\mathrm{ON},\ \mathrm{OFF}\}$. Dropout was applied to the weights that connect the input feedforward layer to the LSTM network and to the weights that connect the output of the LSTM to the output feedforward layer. The applied learning rate scheduling approach reduced the learning rate by half every time a plateau is detected in the validation loss, i.e. if it does not decrease for a given number of epochs. The output masking prevented the LSTM network from choosing actions that did not belong to the set of optimal actions contained in the data in the dataset. Masking was implemented by multiplying the output of the LSTM network by a vector with $1$s in the entries that are contained in the set of optimal actions and $0$s in the remaining entries of the vector.
%It is worth stressing that inference of the LSTM networks in the ensemble occurs sequentially, i.e. the $i+1$th network is only evaluated if the $i$th network and the preceding networks did not output a feasible solution to the MPC problem.




% {\color{magenta}
% During the solution of the MINLP, it was observed that for several different states the decrease in the optimality gap was rather slow after some time. To shorten the solution time of the MINLP solver without compromising much on optimality, a simple criterion for early termination was used: if the optimality gap does not decrease by $0.5\%$ in $10$ seconds, then the solution process stops and the solver outputs the best solution found. The parameters for early termination were simply determined by heuristics.

% Furthermore, the MILP-based formulation of the problem can be solved first to warm-start the solution process of the MINLP-based formulation. In particular, it was noted in the experiments that the integer values, i.e. the train composition, from the MILP solution provide a good starting point for the solution of the MINLP. The introduction of the warm-start substantially improved the solution of MINLP with respect to solution time and optimality.
% }

\subsection{Simulation and Results}

\begin{table*}[htbp]
\centering
\caption{Open-loop optimization for real-time train rescheduling}\label{lmpc-open-loop}%[H]
\begin{tabular}{c|c|ccc|ccc|c} \hline
\multirow{2}*{Approach}& \multirow{2}*{Warm-start}& \multicolumn{3}{c}{Optimality gap}  & \multicolumn{3}{c}{CPU time (s)} & \multirow{2}*{Feasibility rate}   \\ \cline{3-8}
&  & max & average& min & max  & average& min   & \\ \hline
Benchmark & yes&- & -&- &  600.10 &222.18 & 3.67 &  100\% \\ 
MINLP &no& 100.81\% & 7.22\% &0\%  &240.14 & 239.84 &52.47  & 100\% \\ 
Warm-start MINLP & yes  & 12.96\% &  0.04\% & -0.24\% &240.10 & 96.71 & 3.58 & 100\% \\ 
MILP & no &1.54\% & 0.47\%  & -33.73\% & 240.01&  8.77 &0.37&  100\% \\ 
Learning + NLP & no  &3.48\%&-0.11\%  &-34.28\%  &112.22 &6.89 &1.80 & 98.94\% \\ 
Learning + LP& no &1.73\% &0.22\%  &-33.42\%  &0.25 & 0.13&0.11 & 98.55\%  \\ 
% &  & max & mean& min & max  & mean& min   & \\ \hline
% Benchmark & yes&- & -&- &  600.16 &220.89 & 3.14 &  100\% \\ 
% MINLP &no& 177.66\% & 6.88\% &-0.16\%  &240.14 & 239.52 & 6.94  & 100\% \\ 
% Warm-start MINLP & yes  & 12.96\% &  0.04\% & -0.24 \% &240.03 & 95.09 & 3.13 & 100\% \\ 
% MILP & no &1.43\% & 0.45\%  & -37.75\% & 240.01&  6.94 &0.35&  100\% \\ 
% Learning + NLP & no  &1.58\%&-0.13\%  &-38.77\%  &119.90 &6.80 &1.58 & 99.34\% \\ 
% Learning + LP& no &6.58\% &0.21\%  &-37.71\%  &0.3 & 0.14&0.10 & 99.24\%  \\ 
\hline
\end{tabular}
\end{table*}
We have conducted simulations to train the learning algorithm, and the learning process for one of the networks is shown in Fig.~\ref{lmpc-learning_process}, where a 1000-step moving average approach is applied to smooth the learning curve. From Fig.~\ref{lmpc-learning_process}, we can see that the learning curve descends very quickly during the first 100000 iterations, and then the performance gradually improves until iteration 200000. 

We perform simulations for both open-loop optimization, where the MPC optimization problem is solved for one step, and closed-loop MPC, involving real-time MPC optimization over 30 steps. For open-loop optimization, we have performed simulations using the developed learning-based approaches on 10 separate cores for 24 hours  (resulting in 1054 scenarios). For comparison, simulations have also been performed with the Benchmark approach, the MINLP approach, the warm-start MINLP approach, and the MILP approach, where the Benchmark approach corresponds to the MINLP approach with warm-start and a maximum solution time of 600\ s. 

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=8.0cm]{training_process_3lines.pdf}    % The printed column width is 8.4 cm.
\caption{Learning process of the learning algorithm.}
\label{lmpc-learning_process}
\end{center}
\end{figure}

 % In the rule-based approach, train composition is determined by a random number between $\ell_p^\mathrm{min}$ and $\ell_p^\mathrm{max}$. If the number of available train units in the depot is less than the required number, the train service departs with the units currently available in the depot. 

% \textcolor{blue}{Formula for training loss and validation loss}

% \begin{table}[htbp]
% \centering
% \footnotesize
% \caption{Simulation results for different approaches}\label{lmpc-open-loop}%[H]
% \begin{tabular}{ccccc} \hline
% \multirow{2}*{Approach}  & \multirow{2}*{Average cost} & \multirow{2}*{\makecell[c]{Infeasible\\ rate}} & \multicolumn{2}{c}{CPU time (s)}   \\ \cline{4-5}
% &  & & $t_\mathrm{max}$ & $t_\mathrm{avrg}$ \\ \hline
% MINLP-based& $3.8481 \cdot 10^4$& 0\% & 26.8 & 5.4\\
% Rule-based & $4.1923 \cdot 10^4$& 0\%& - & -\\
% Learning-based& $3.8590 \cdot 10^4$& 6.00\% & 10.9 & 1.0 \\
% \hline
% \end{tabular}
% \end{table}


% \begin{table}
%     \centering
%     \resizebox{\textwidth}{!}{
%     \begin{tabular}{c|c|ccc|ccc|c} \hline
%     \multirow{2}*{Approach}& \multirow{2}*{Warm-start}& \multicolumn{3}{c}{Optimality gap}  & \multicolumn{3}{c}{CPU time (s)} & \multirow{2}*{Feasibility rate}   \\ \cline{3-8}
% &  & max & mean& min & max  & mean& min   & \\ \hline
%     Benchmark & yes&- & -&- &  600.16 &220.89 & 3.14 &  100\% \\ 
%     MINLP &no& 177.66\% & 6.88\% &-0.16\%  &240.14 & 239.52 & 6.94  & 100\% \\ 
%     Warm-start MINLP & yes  & 12.96\% &  0.04\% & -0.24 \% &240.03 & 95.09 & 3.13 & 100\% \\ 
%     MILP & no &1.43\% & 0.45\%  & -37.75\% & 240.01&  6.94 &0.35&  100\% \\ 
%     Learning + NLP & no  &1.58\%&\boxed{-0.13\%}  &-38.77\%  &119.90 &\boxed{6.80} &1.58 & 99.34\% \\ 
%     Learning + LP& no &6.58\% &\boxed{0.21\%}  &-37.71\%  &0.3 & \boxed{0.14}&0.10 & 99.24\%  \\ 
%     \hline
%     \end{tabular}}
%     \end{table}

%     \\

% We conduct 100 simulations by randomly selecting a time slot in the data set, and 
The optimality gap, CPU time, and feasibility rate among the simulations are given in Table~\ref{lmpc-open-loop}.  From Table~\ref{lmpc-open-loop}, we see that the MINLP approach without warm-start has the worst optimality gap and the worst CPU times. In general, the nonlinear objective function and the presence of integer decision variables significantly influence the performance of MINLP. By applying the warm start, the optimality gap and the solution time are reduced; however, the maximum solution time and the average solution time of the warm-start MINLP approach are still large with values of 240.10\ s and 96.71\ s, respectively.  By approximating the nonlinear objective function, the solution time of the MILP approach is further reduced without sacrificing too much optimality. However, the MILP also reached the maximum allowed solution time in some cases, i.e., the maximum CUP time of MILP in Table~\ref{lmpc-open-loop} still reached 240\ s. 

In the open-loop optimization, the developed learning-based NLP approach (Learning + NLP) and learning-based LP approach (Learning + LP) achieve comparable performance with an average optimality gap of -0.11\% and 0.22\% among the feasible cases, while significantly reducing the solution time to an average of 6.89\ s and 0.13\ s, respectively.
Furthermore, by approximating the nonlinear objective function, the learning-based LP approach further reduces the solution time, enabling the optimized timetable to be obtained in under 1 second. Both the learning-based NLP and LP approaches demonstrate high feasibility rates, at 98.94\% and 98.55\%, respectively.  % For the infeasible case, the heuristic as stated in \emph{Lemma~1} can be applied to get the train decomposition and generate a feasible timetable. 


%for the learning-based and the rule-based approaches are 0.29\% and 8.95\%, respectively, while the average CPU time of the learning-based approaches is reduced to 1.0 s compared to the 5.4 s of the MILNP-based approach. Thus, the learning-based approach can achieve very close performance with the exact approach in terms of the average cost, while the CPU time of the learning-based approach is significantly reduced. The learning-based approach may cause an infeasible solution in some cases with an infeasibility rate of 6.00\% in the simulations. In this context, we can use the MILNP-based approach as a backup when the learning-based approach encounters infeasibility issues.

% \begin{figure}[htbp]
% \begin{center}
% \includegraphics[width=9cm]{sending_trains_openloop.jpg}    % The printed column width is 8.4 cm.
% \caption{Number of train units departing from Station CPX at each time step.}
% \label{lmpc-results-composition}
% \end{center}
% \end{figure}

% \begin{figure}[htbp]
% \begin{center}
% \includegraphics[width=8.8cm]{train_composition.pdf}    % The printed column width is 8.4 cm.
% \caption{Number of train units departing from Station CPX at each time step.}
% \label{lmpc-composition}
% \end{center}
% \end{figure}

To further demonstrate the performance of the learning-based MPC approach, we conduct closed-loop control tests on 10 separate cores over 24 hours, with each episode consisting of 30 control steps. If the integer variables generated by the learning agents are infeasible, the heuristic described in \emph{Lemma 1} is applied to obtain the train decomposition and to generate a feasible timetable. % For learning-based approaches, LSTM networks trained with MINLP perform better. 
The simulation results are presented in Table~\ref{lmpc-closed-loop}. It can be observed that after applying the heuristic described in \emph{Lemma 1}, the feasibility rate reached 100\%. Compared to the warm-start MINLP and MILP approaches, the optimality of learning-based approaches is reduced in some cases because heuristic rules typically generate suboptimal solutions. In the closed-loop case, the maximum solution time for traditional approaches, i.e., warm-start MINLP and MILP, reaches 240 s, making them unsuitable for real-life applications where operators require an optimized solution as soon as possible for real-time timetable rescheduling. In contrast, the solution times for learning-based NLP and LP approaches are significantly lower, with average solution times of 6.50 s and 0.13 s, respectively. Table~\ref{lmpc-closed-loop} indicates that learning-based approaches significantly enhance solution efficiency, with an acceptable optimality sacrifice of approximately 5\%.

%In the closed-loop case, the maximum solution time for traditional approaches, such as warm-start MINLP and MILP, reaches 240 s, which is not suitable for real-life applications where an efficient solution is crucial for real-time timetable rescheduling. The solution times for learning-based NLP and learning-based LP approaches are significantly reduced, with average solution times of 6.50 s and 0.13 s, respectively.  The simulation results indicate that the learning-based approaches significantly improve the solution efficiency with acceptable sacrifice in optimality, i.e., around 5 \% in simulations.

% To further show the performance of the learning-based MPC approach, we conduct tests for closed-loop control on 10 separate cores 
% for 24 hours, with each episode comprising 30 control steps. In the case when the integer variables generated by learning agents are infeasible, the heuristic as stated in \emph{Lemma~1} can be applied to get the train decomposition and generate a feasible timetable.    The simulation results are given in Table~\ref{lmpc-closed-loop}.

% To further show the performance of the learning-based MPC approach, we conduct tests for closed-loop control on 10 separate cores 
% for 24 hours, with each episode comprising 30 control steps.  The simulation results are given in Table~\ref{lmpc-closed-loop}.

\begin{table*}[htbp]
\centering
\caption{Closed-loop MPC for real-time train rescheduling}\label{lmpc-closed-loop}%[H]
\begin{tabular}{c|c|ccc|ccc|c} \hline
\multirow{2}*{Approach}& \multirow{2}*{Warm-start}& \multicolumn{3}{c}{Optimality gap}  & \multicolumn{3}{c}{CPU time (s)} & \multirow{2}*{Feasibility rate}   \\ \cline{3-8}
&  & max & mean& min & max  & mean& min   & \\ \hline
Benchmark & yes&- & -&- &  600.12 &227.18 & 0.05 &  100\% \\ 
% MINLP &no& 177.66\% & 6.88\% &-0.16\%  &240.14 & 239.52 & 6.94  & 100\% \\ 
Warm-start MINLP & yes  & 13.03\% &  -0.22\% & -60.95\% &240.06 & 51.36& 0.05 & 100\% \\ 
MILP & no &21.18\% & 0.46\%  & -35.61\% & 240.05&  6.83 &0.06&  100\% \\ 
Learning + NLP & no  &93.43\%&4.92\%  &-11.02\%  &91.20 &6.50 &1.84 & 100\% \\ 
Learning + LP& no &126.71\% &5.50\%  &-9.99\%  &0.31 & 0.15&0.11 & 100\%  \\ 
\hline
\end{tabular}
\end{table*}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=8.5cm]{MPC_cost.pdf}    % The printed column width is 8.4 cm.
\caption{Objective function value at each MPC step for one episode.}
\label{lmpc-MPC_cost}
\end{center}
\end{figure}

% As an illustrative example for better visualization, the simulation results for one episode are given in Fig.~\ref{lmpc-MPC_cost}, where the objective function values at each step for Benchmark, Warm-start MINLP, MILP, learning-based NLP, and learning-based LP approaches are presented. The simulation for the episode starts at 10:30 and covers 30 MPC steps in total. The timetables for Warm-start MINLP, MILP, learning-based NLP, and learning-based LP approaches are provided in Fig.~\ref{lmpc-minlp_timetable} - Fig.~\ref{lmpc-lp_timetable}, respectively.

As an illustrative example, Fig.~\ref{lmpc-MPC_cost} presents the simulation results for one episode, showing the objective function values at each step for the Benchmark, warm-start MINLP, MILP, learning-based NLP, and learning-based LP approaches. The episode begins at 10:30 and spans 30 MPC steps. Fig.~\ref{lmpc-MPC_cost} indicates that the developed learning-based approaches achieve comparable performance concerning objective function values. The timetables for the Changping Line, covering from Station CPX to Station XEQ, are depicted in Fig.\ref{lmpc-benchmark_timetable}--Fig.~\ref{lmpc-lp_timetable} for the benchmark approach, the warm-start MINLP, MILP, learning-based NLP, and learning-based LP approaches, respectively, where the line width indicates the number of train units included in each train service.  %It can be observed from Fig.\ref{lmpc-benchmark_timetable}--Fig.~\ref{lmpc-lp_timetable} that all approaches use long trains from 10:30 to 10:50 to transport passengers. After 10:50, the benchmark approach, the warm-start MINLP approach, and the MILP approach perform continuously use long trains, while the learning-based NLP approach uses short trains first and then use long trains, resulting a slight difference in objective function value in  Fig.~\ref{lmpc-MPC_cost}. However, the learning-based LP approach use short trains until 11:40, which is consistent with the worse performance in Fig.~\ref{lmpc-MPC_cost}.
From Fig.\ref{lmpc-benchmark_timetable} to Fig.\ref{lmpc-lp_timetable}, it can be observed that all approaches deploy long trains from 10:30 to 10:50 to transport passengers. After 10:50, the benchmark, warm-start MINLP, and MILP approaches continue using long trains, whereas the learning-based NLP approach initially uses short trains before switching to long trains, resulting in a slight difference in the objective function value shown in Fig.\ref{lmpc-MPC_cost}. In contrast, the learning-based LP approach continues using short trains until 11:40, resulting in the worse performance in Fig.\ref{lmpc-MPC_cost}.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=7cm]{benchmark_timetable.pdf}    % The printed column width is 8.4 cm.
\caption{Timetable for Changping Line of the benchmark approach} %(the line width represents the number of train units for the train service).}
\label{lmpc-benchmark_timetable}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=7cm]{warmstart_minlp_timetable.pdf}    % The printed column width is 8.4 cm.
\caption{Timetable for Changping Line of the warm-start MINLP approach} %(the line width represents the number of train units for the train service).}
\label{lmpc-minlp_timetable}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=7cm]{milp_timetable.pdf}    % The printed column width is 8.4 cm.
\caption{Timetable for Changping Line of the MILP approach} % (the line width represents the number of train units for the train service).}
\label{lmpc-milp_timetable}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=7cm]{learning_nlp_timetable.pdf}    % The printed column width is 8.4 cm.
\caption{Timetable for Changping Line of the learning-based NLP approach} % (the line width represents the number of train units for the train service).}
\label{lmpc-nlp_timetable}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=7cm]{learning_lp_timetable.pdf}    % The printed column width is 8.4 cm.
\caption{Timetable for Changping Line of the learning-based LP approach} % (the line width represents the number of train units for the train service).}
\label{lmpc-lp_timetable}
\end{center}
\end{figure}

In general, the rail operator expects to generate a timetable as soon as possible to ensure efficient reasonable rolling stock circulation and crew scheduling, enabling effective management of the real-time traffic situations and passenger flows. The simulation results indicate that the developed learning-based MPC approach significantly reduces solution times with an acceptable trade-off in objective function performance. The developed learning-based MPC approach can generate timetables in real time with the train composition and rolling stock circulation plan generated by learning and the detailed departure and arrival times generated by nonlinear or linear programming. It should be noted that solving MINLP or MILP problems typically requires commercial solvers, such as \texttt{gurobi} and \texttt{cplex}, to generate solutions in a computationally efficient way. % However, using these solvers for real-life train scheduling incurs additional costs for operators. 
By generating integer variables with well-trained learning agents at each MPC step, the resulting continuous linear or nonlinear programming problems can be efficiently solved using a variety of available solvers and algorithms. %The learning-based NLP approach outperforms the learning-based LP approach.  The simulation results indicate that the developed learning-based approaches can quickly generate efficient timetables, which can improve service reliability and overall passenger satisfaction. }}
% The simulation results imply that the developed learning-based MPC approach can quickly generate efficient timetables, which can improve service reliability and overall passenger satisfaction. The learning-based NLP approach performs better than the learning-based LP approach.

% To further show the performance of the learning-based approach, the number of train units departing from Station CPX at each time step is given in Fig.~\ref{lmpc-results-composition}, where time step 1 corresponds to 10:40 AM. The results indicate that both the learning-based approach achieve performance nearly equivalent to the MINLP-based approach in most cases with the learning-based approach showing a deviation at only one step in Fig.~\ref{lmpc-results-composition}.  In practice, rail operators typically expect to obtain a timetable as quickly as possible.  The simulation results indicate that the developed learning-based approaches can be applied to generate timetables that minimize passenger delays and train energy consumption within a relatively short time.


% \begin{figure}[htbp]
% \begin{center}
% \includegraphics[width=8cm]{results_train_composition2.png}    % The printed column width is 8.4 cm.
% \caption{Number of train units departing from Station SJZ at each time step.}
% \label{lmpc-results-composition}
% \end{center}
% \end{figure}

% Plot: learning curve (training and validation)

% objective function value per time step

% train composition at platforms corresponding to depots

% timetable 

%  Table: Compare SL, exact, J-origianl, CPU time, feasibility, and optimality

\section{Conclusions}\label{lmpc-section7}
In this paper, we have investigated the passenger-oriented train rescheduling problem considering flexible train composition and rolling stock circulation. The passenger-oriented train rescheduling model \cite{liu2023modeling} has been extended to include train compositions and rolling stock circulation considering time-varying passenger demands. %The resulting train rescheduling problem is a mixed-integer nonlinear programming problem.
% By applying model predictive control (MPC), the resulting mixed-integer programming problem has been solved in a moving horizon manner for real-time scheduling. 
To improve the online computational efficiency of model predictive control, we have combined the optimization-based and learning-based approaches, where the learning-based approach obtains integer variables, i.e., train compositions and train orders, by using pre-trained long short-term memory networks; then, the detailed timetables are optimized by solving a constrained optimization problem with the fixed integer variables. We have developed several presolve techniques to prune the subset of integer decision variables. Simulation results show that the developed learning-based framework can achieve comparable performance compared to the exact approach with an acceptable loss of feasibility while the solution time is significantly reduced. 

In the future, we will investigate the integration of reinforcement learning (instead of supervised learning) and model predictive control for real-time train rescheduling to improve the learning ability of the approach. Among several directions, multi-agent learning-based approaches can also be a promising direction for handling large-scale urban rail transit networks. % Furthermore, we will investigate the integration of reinforcement-learning-based MPC for the real-time train scheduling problem, where suitable reward functions and reinforcement learning algorithms should be designed. Moreover, multi-agent learning-based approaches can also be a promising direction to handle large-scale urban rail transit networks. % Moreover, incorporating learning-based approaches into traditional distributed optimization approaches, e.g., primal decomposition and Benders decomposition.

%\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \appendices
% \section{Transformation of the absolute value of a variable}
% If we introduce an auxiliary continuous variable $o_{k,p}$ and an auxiliary binary variable $\gamma_{k_p,p}$ with $\gamma_{k_p,p} = 1 \Leftrightarrow o_{k_p,p} = y_{p}(k_p)$ and $\gamma_{k_p,p} = 0 \Leftrightarrow o_{k_p,p} = -y_{p}(k_p)$, and then $o_{k_p,p} = |y_{p}(k_p)|$ is equivalent to
% \begin{equation}\label{lmpc-trans_abs}
% \left\{ {\begin{array}{*{40}{l}}
% {o_{k_p,p} - y_{p}(k_p) \ge 0,}\\
% {o_{k_p,p} - y_{p}(k_p) \le 2Y_\mathrm{max}(1-\gamma_{k_p,p}),}\\
% {o_{k_p,p} + y_{p}(k_p) \ge 0,}\\
% {o_{k_p,p} + y_{p}(k_p) \le 2Y_\mathrm{max}\gamma_{k_p,p},}\\
% \end{array}} \right.
% \end{equation}
% where $Y_\mathrm{max}$ denotes the maximum value of $y_{p}(k_p)$. 

% \section{Transformation of the absolute value of a variable}
% Based on \emph{Transformation property 4.1}, (\ref{lmpc-eta_kp}) is equivalent to $\eta_{k_p,p} = \left\{ {\begin{array}{*{20}{l}}
% {1,\quad {\rm{if}}\quad {o_{k_p,p}} > 0;}\\
% {0,\quad {\rm{otherwise}},}
% \end{array}} \right.$, which can be
% % \begin{equation}\label{lmpc-gamma_kp}
% % \eta_{k,p} = \left\{ {\begin{array}{*{20}{l}}
% % {1,\quad {\rm{if}}\quad {o_{k,p}} > 0;}\\
% % {0,\quad {\rm{otherwise}},}
% % \end{array}} \right.
% % \end{equation}
% %By using the property developed in \cite{bemporad1999control}, 
% % we can transform (\ref{lmpc-gamma_kp}) into inequality constraints. 
% % {\textbf{Transformation property 4.1}}: 
% converted to
% \begin{equation}\label{lmpc-trans_gamma}
% \left\{ {\begin{array}{*{30}{l}}
% {o_{k_p,p} \le \eta_{k_p,p}O_\mathrm{max},}\\
% {o_{k_p,p} \ge \epsilon + (1 - \eta_{k_p,p})(O_\mathrm{min} - \epsilon).}
% \end{array}} \right.
% \end{equation}
% where $O_\mathrm{max}$ and $O_\mathrm{min}$ are the minimum and maximum values of $o_{k_p,p}$, respectively, and $\epsilon$ is a sufficiently small number, typically representing machine precision. %Then, (\ref{lmpc-gamma_kp}) is equivalent

% Therefore, (\ref{lmpc-y_kp}) can be transformed to
% \begin{equation}\label{lmpc-y_kp_linear}
% \tau^\mathrm{add}_{p}(k_p) = \eta_{k_p,p} t^\mathrm{cons}_{p}.
% \end{equation}

% {\bf{Transformation property 4.3}}: 
% If we define $m_\mathrm{a}$ and $M_\mathrm{a}$ as the minimum and maximum values of $a_{p'}(k_{p'})$, respectively, then following the transformation property in \cite{bemporad1999control}, (\ref{lmpc-xi}) is equivalent to the following inequalities
% \begin{equation}\label{lmpc-transif}
% \left\{ {\begin{array}{*{20}{l}}
% {{a_{p'}(k_{p'})} - {a_{p}(k_{p})} \le \left( {1 - \xi_{k_{p'},k_p,p',p}} \right)\left( {{M_{\rm{a}}}  \!-\! {a_{p}(k_{p})}} \right),}\\
% {{a_{p'}(k_{p'})} - {a_{p}(k_{p})} \ge \varepsilon  + {\xi_{k_p,k_{p'},p,p'}}\left( {{m_{\rm{a}}} \!-\! a_{p}(k_{p}) \!-\! \varepsilon } \right).}
% \end{array}} \right.
% \end{equation}
%Appendixes should appear before the acknowledgment.

%\section*{ACKNOWLEDGMENT}

%The preferred spelling of the word Ã’acknowledgmentÃ“ in America is without an Ã’eÃ“ after the Ã’gÃ“. Avoid the stilted expression, Ã’One of us (R. B. G.) thanks . . .Ã“  Instead, try Ã’R. B. G. thanksÃ“. Put sponsor acknowledgments in the unnumbered footnote on the first page.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%References are important to the reader; therefore, each citation must be complete and correct. If at all possible, references should be commonly available publications.



%use following command to generate the list of cited references
\AtNextBibliography{\footnotesize}
\setlength{\biblabelsep}{\labelsep} 
%\setlength{\bibitemsep}{-0.5\parsep} 
%\setlength{\bibparsep}{1.0ex}
\printbibliography

\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.
                                  
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{xiaoyu.jpg}}]{Xiaoyu Liu}
% received the B.Sc. and M.Sc. degree from Beijing Jiaotong University, Beijing, China, in 2017 and 2020, respectively. He is currently working toward the Ph.D. degree in the Delft Center for Systems and Control, Delft University of Technology, Delft, The Netherlands.
% His research interests include model predictive control, hybrid systems, and intelligent urban rail transit transportation systems.
% \end{IEEEbiography}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{azita.jpg}}]{Azita Dabiri}
% received the Ph.D. degree from the Automatic Control Group, Chalmers University of Technology, in 2016. She was a Post-Doctoral Researcher with the Department of Transport and Planning, TU Delft, from 2017 to 2019. In 2019, she received an ERCIM Fellowship and also a Marie Curie Individual Fellowship which allowed her to perform research at the Norwegian University of Technology (NTNU) as a Post-Doctoral Researcher from 2019 to 2020, before joining the Delft Center for Systems and Control, TU Delft, as an Assistant Professor. Her research interests are in the area of integration of model-based and learning-based control and its applications in transportation networks.
% \end{IEEEbiography}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bart.jpg}}]{Bart De Schutter}
% (Fellow, IEEE) received the Ph.D. degree (\emph{summa cum laude}) in applied sciences from KU Leuven, Belgium, in 1996.

% He is currently a Full Professor with the Delft Center for Systems and Control, Delft University of Technology, The Netherlands. His research interests include control of discrete-event and hybrid systems, multilevel and distributed control, and intelligent transportation and infrastructure systems. 

% Prof. De Schutter is a Senior Editor of the IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS and an Associate Editor of the IEEE TRANSACTIONS ON AUTOMATIC CONTROL.
% \end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{xiaoyu.jpg}}]{Xiaoyu Liu}
received the Ph.D. degree from the Delft Center for Systems and Control at Delft University of Technology, The Netherlands, in 2024. He also received B.Sc. and M.Sc. degrees from Beijing Jiaotong University, China, in 2017 and 2020, respectively. He is currently a Postdoctoral Researcher in the Department of Cognitive Robotics at Delft University of Technology, The Netherlands. 

His research interests include model predictive control, hybrid systems, and intelligent transportation systems.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{caio.jpg}}]{Caio Fabio Oliveira da Silva}
received his Master's degree in Automation and Control Engineering from Politecnico di Milano, Italy, in 2020, and his Bachelor's degree from Universidade de BrasÃ­lia, Brazil, in 2017. He is currently working towards his Ph.D. degree in the Delft Center for Systems and Control at Delft University of Technology, The Netherlands. 

His research interests include reinforcement learning, model predictive control, and hybrid systems.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{azita.jpg}}]{Azita Dabiri}
received the Ph.D. degree from the Automatic Control Group, Chalmers University of Technology, in 2016. She was a Post-Doctoral Researcher with the Department of Transport and Planning, TU Delft, from 2017 to 2019. In 2019, she received an ERCIM Fellowship and also a Marie Curie Individual Fellowship which allowed her to perform research at the Norwegian University of Technology (NTNU) as a Post-Doctoral Researcher from 2019 to 2020, before joining the Delft Center for Systems and Control, TU Delft, as an Assistant Professor. Her research interests are in the area of integration of model-based and learning-based control and its applications in transportation networks.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{yihui.jpg}}]{Yihui Wang} received the B.Sc. degree in automation from Beijing Jiaotong University, Beijing, China, in 2007, and the Ph.D. degree in systems and control from the Delft University of Technology, Delft, the Netherlands, in 2014.

She is currently an Associate Professor at the School of Automation and Intelligence, Beijing Jiaotong University. Her research interests include train optimal control, train scheduling, and railway disruption management.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bart.jpg}}]{Bart De Schutter}
(Fellow, IEEE) received the Ph.D. degree (\emph{summa cum laude}) in applied sciences from KU Leuven, Belgium, in 1996.

He is currently a Full Professor with the Delft Center for Systems and Control, Delft University of Technology, The Netherlands. His research interests include control of discrete-event and hybrid systems, multilevel and distributed control, and intelligent transportation and infrastructure systems. 

Prof. De Schutter is a Senior Editor of the IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS.
\end{IEEEbiography}
\end{document}
