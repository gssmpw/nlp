\section{Conclusions}

%Aligning LLMs with human values remains a critical challenge as these models are increasingly deployed in real-world applications. Current approaches, such as RLHF, struggle with the inherent misspecification of reward functions, which fail to capture the complexity and evolving nature of human values. Additionally, language ambiguity further complicates alignment efforts.\looseness=-1 

In this paper, we have argued that addressing these challenges requires reframing LLM alignment through the lens of contract theory. We model LLM alignment within a principal-agent framework, where the principal (a user or developer) defines a contract. This contract consists of an action taken by the agent (the LLM) and the corresponding reward assigned by the principal. We then draw connections between the challenges of contract formation in societal alignment frameworks and those in LLM alignment, arguing that insights from societal alignment can improve LLM alignment within incomplete contracting environments. While contract theory provides us with some formalization tools, social alignment emphasizes the role of instillation of societal norms and values, economic alignment points to solutions to group alignment and allocation challenges, and contractual alignment provides mechanisms for regulating LLM behavior, both externally through legal frameworks and internally through scalable oversight mechanisms. Finally, we present an alternative view on LLM alignment, advocating for shifting the paradigm from developer-centered to collaborative, user-centric, and iterative approaches to LLM alignment.