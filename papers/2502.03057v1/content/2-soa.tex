\label{sec::soa}
In this section, we discuss the datasets that provide event-camera data specifically for eye-tracking applications. As previously anticipated, due to the novelty of the sensor and application, the number of available datasets is extremely low.

%\subsection{Angelopoulos} \label{angelopoulos_soa}
%todo~\cite{angelopoulos2020event}
One of the first datasets for the eye-tracking task is the one presented by Angelopoulos in~\cite{angelopoulos2020event}. This dataset has been created using data obtained by the DAVIS sensor, which provides both greyscale and event-based data. The dataset is composed of several eye movements obtained from 27 different users. 
The ground truth provided is unfortunately limited due to the difficulties in generating a pupil-level annotation from the sparse event data. Indeed, Angelopoulos's dataset provides as ground truth the looked point on a screen, not the pupil position in the image frame. This type of annotation has been widely used for many years in the eye-tracking field~\cite{holmqvist_eye_movements} but introduces additional calibration and nonlinearities in the system, which makes a proper evaluation of the pure pupil detection and tracking algorithm less accurate.

%\subsection{Retina} \label{retina_soa}
%todo~\cite{bonazzi2024retina}
A recent addition is the Ini-30 dataset~\cite{bonazzi2024retina}, obtained by recording 30 volunteers using a glass frame equipped with two DVXplorer event cameras. To the best of our knowledge, this is the first event-based dataset where labels are provided at high-frequency directly at frame level and where a screen was not employed to guide the users during the acquisition process and with labels dire. The glasses cameras captured natural eye movements; then, data were manually labeled with a variable sampling period ranging from 20.0ms to 235.77ms. The resulting 50Hz labeling frequency, however, is not high enough to capture all eye movements, as presented in the next sections. Additionally, the absence of a standardized protocol during acquisitions, although enhancing variability, might lead to imbalances in the data, thereby affecting its usability.


%\subsection{EV-Eye} \label{eveye_soa}
%todo~\cite{eveyepaper}
Another dataset was recently presented as part of the EV-Eye paper \cite{eveyepaper}. Similarly to \cite{angelopoulos2020event}, two DAVIS346 are used to capture events and also record near-eye grayscale image sequences at a frame rate of 25fps. In addition, it contains gaze references provided by Tobii Pro Glasses 3. This additional metadata comprises PoGs and pupil diameters of the users at $100Hz$. The dataset is composed by 48 participants (28 male and 20 female) aged between 21 and 35 years. Labels are also provided at sensor level as in~\cite{bonazzi2024retina}, but only at slow frequency as estimated from near-eye grayscale images.


%\subsection{AIS 2024 Challenge} \label{challenge_soa}
%todo \cite{wang2024eventbasedeyetrackingais}
Recently a new event-based dataset has also been presented, the 3ET+ dataset~\cite{wang2024eventbasedeyetrackingais}. In this scenario the data have been obtained using a DVXplorer Mini event camera. The recording consists of 13 distinct users, each exhibiting various eye movements. Unlike the previous datasets, 3ET+ provides the ground truth annotated at 100Hz. Moreover, they provide two different labels: one binary value to indicate the blink status, and the human-labeled pupil center coordinates. However, the data were collected without an IR-pass filter, so they contain events of object reflections mixed with eye movements. This could impact the generalization capability of deep learning algorithms trained on this dataset.

This work advances the current state of the art by providing additional annotations to the Angelopoulos dataset~\cite{angelopoulos2020event}. Specifically, we retrieve the center of the pupil on the image frame at a rate of 200 Hz, a frequency sufficiently high to model all documented eye movements~\cite{holmqvist_eye_movements}. Additionally, we include annotations describing the current state of the eye, labeling the presence of a blink and the status of the saccade.
