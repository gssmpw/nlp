############# OTHER ########################


@article{Lang2015,
  title = {Recommendations for Cardiac Chamber Quantification by Echocardiography in Adults: An Update from the American Society of Echocardiography and the European Association of Cardiovascular Imaging},
  volume = {28},
  ISSN = {0894-7317},
  DOI = {10.1016/j.echo.2014.10.003},
  number = {1},
  journal = {Journal of the American Society of Echocardiography},
  publisher = {Elsevier BV},
  author = {Lang,  Roberto M. and Badano,  Luigi P. and Mor-Avi,  Victor and Afilalo,  Jonathan and Armstrong,  Anderson and Ernande,  Laura and Flachskampf,  Frank A. and Foster,  Elyse and Goldstein,  Steven A. and Kuznetsova,  Tatiana and Lancellotti,  Patrizio and Muraru,  Denisa and Picard,  Michael H. and Rietzschel,  Ernst R. and Rudski,  Lawrence and Spencer,  Kirk T. and Tsang,  Wendy and Voigt,  Jens-Uwe},
  year = {2015},
  month = jan,
  pages = {1--39.e14}
}

@article{2020LeftVE,
  title={Left Ventricular Ejection Fraction},
  author={},
  journal={Definitions},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:80279998}
}


################ Datasets ###################
@article{Leclerc19,
  author={Leclerc, Sarah and others},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Deep Learning for Segmentation Using an Open Large-Scale Dataset in 2D Echocardiography}, 
  year={2019},
  volume={38},
  number={9},
  pages={2198-2210}}

@article{woodward2022real,
  title={Real-world performance and accuracy of stress echocardiography: the EVAREST observational multi-centre study},
  author={Woodward, William and Dockerill, Cameron and McCourt, Annabelle and Upton, Ross and O'Driscoll, Jamie and Balkhausen, Katrin and Chandrasekaran, Badrinathan and Firoozan, Soroosh and Kardos, Attila and Wong, Kenneth and others},
  journal={European Heart Journal-Cardiovascular Imaging},
  volume={23},
  number={5},
  pages={689--698},
  year={2022},
  publisher={Oxford University Press}
}

# ECHONET 
@article{Ouyang2020_echonet,
  title = {Video-based AI for beat-to-beat assessment of cardiac function},
  volume = {580},
  ISSN = {1476-4687},
  DOI = {10.1038/s41586-020-2145-8},
  number = {7802},
  journal = {Nature},
  publisher = {Springer Science and Business Media LLC},
  author = {Ouyang,  David and He,  Bryan and Ghorbani,  Amirata and Yuan,  Neal and Ebinger,  Joseph and Langlotz,  Curtis P. and Heidenreich,  Paul A. and Harrington,  Robert A. and Liang,  David H. and Ashley,  Euan A. and Zou,  James Y.},
  year = {2020},
  month = mar,
  pages = {252–256}
}



################ Segmentation #################
@InProceedings{unet,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="MICCAI",
year="2015",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}



@article{isensee2021nnu,
  title={nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation},
  author={Isensee, Fabian and Jaeger, Paul F and Kohl, Simon AA and Petersen, Jens and Maier-Hein, Klaus H},
  journal={Nature methods},
  volume={18},
  number={2},
  pages={203--211},
  year={2021},
  publisher={Nature Publishing Group US New York}
}


@inproceedings{camus_nnUnet,
  TITLE = {{Reaching intra-observer variability in 2-D echocardiographic image segmentation with a simple U-Net architecture}},
  AUTHOR = {Ling, Hang Jung and Garcia, Damien and Bernard, Olivier},
  BOOKTITLE = {{IEEE International Ultrasonics Symposium (IUS)}},
  ADDRESS = {Venice, Italy},
  YEAR = {2022},
  MONTH = Oct,
  KEYWORDS = {Ultrasound ; Deep learning ; U-Net ; Cardiac},
  HAL_ID = {hal-03979523},
  HAL_VERSION = {v1},
}


@article{GUDU,
title = {GUDU: Geometrically-constrained Ultrasound Data augmentation in U-Net for echocardiography semantic segmentation},
journal = {Biomedical Signal Processing and Control},
volume = {82},
pages = {104557},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2022.104557},
author = {Christoforos Sfakianakis and Georgios Simantiris and Georgios Tziritas},
keywords = {Segmentation, Echocardiography, U-Net, Data augmentation, Ensemble method, Clinical metrics},
abstract = {Echocardiography is a very important medical examination that helps in the computation of critical heart functions. Boundary identification, segmentation and estimation of the volume of key parts of the heart, especially the left ventricle, is a difficult and time-consuming process, even for the most experienced cardiologists. In recent years, research has focused on the automatic segmentation of heart through artificial intelligence techniques and especially with the use of deep learning. Our work is part of this framework. We implemented an ensemble of convolutional neural networks based on the U-net architecture, trained it using a public dataset of cardiac ultrasound images, and combined the outcomes to extract the areas of the left ventricle, myocardium and left atrium. In order to optimize the training process, we have developed a significant data augmentation method based on medical practice. Furthermore, we extended the Dice loss function by imposing additional mandatory anatomical constraints. An ablation study highlights the contribution of each of our proposed modules. The evaluation of our method showed an overall improvement in segmentation accuracy but also in the estimation of clinical metrics. Specifically, using the Dice coefficient for geometric metrics, we achieved for the epicardium a score of 0.96 and 0.955 for the end-diastolic and end-systolic phase respectively. For the clinical metrics of the left ventricle volume, the Pearson correlation coefficient was used where our method gave 0.977, 0.981, 0.897 for the end-diastolic, end-systolic phase and ejection fraction respectively. Scores which up until the writing of this article outperform competitive methods.}
}


@article{pyramid_att_seg,
title = {Deep pyramid local attention neural network for cardiac structure segmentation in two-dimensional echocardiography},
journal = {Medical Image Analysis},
volume = {67},
pages = {101873},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2020.101873},
author = {Fei Liu and Kun Wang and Dan Liu and Xin Yang and Jie Tian},
keywords = {2D echocardiography, Cardiac structure segmentation, Pyramid local attention, Label coherence learning},
abstract = {Automatic semantic segmentation in 2D echocardiography is vital in clinical practice for assessing various cardiac functions and improving the diagnosis of cardiac diseases. However, two distinct problems have persisted in automatic segmentation in 2D echocardiography, namely the lack of an effective feature enhancement approach for contextual feature capture and lack of label coherence in category prediction for individual pixels. Therefore, in this study, we propose a deep learning model, called deep pyramid local attention neural network (PLANet), to improve the segmentation performance of automatic methods in 2D echocardiography. Specifically, we propose a pyramid local attention module to enhance features by capturing supporting information within compact and sparse neighboring contexts. We also propose a label coherence learning mechanism to promote prediction consistency for pixels and their neighbors by guiding the learning with explicit supervision signals. The proposed PLANet was extensively evaluated on the dataset of cardiac acquisitions for multi-structure ultrasound segmentation (CAMUS) and sub-EchoNet-Dynamic, which are two large-scale and public 2D echocardiography datasets. The experimental results show that PLANet performs better than traditional and deep learning-based segmentation methods on geometrical and clinical metrics. Moreover, PLANet can complete the segmentation of heart structures in 2D echocardiography in real time, indicating a potential to assist cardiologists accurately and efficiently.}
}




################ Contouring ####################

@InProceedings{lv3ch-dsnt,
author="Gomez, Alberto
and Porumb, Mihaela
and Mumith, Angela
and Judge, Thierry
and Gao, Shan
and Kim, Woo-Jin Cho
and Oliveira, Jorge
and Chartsias, Agis",
title="Left Ventricle Contouring of Apical Three-Chamber Views on 2D Echocardiography",
booktitle="Simplifying Medical Ultrasound",
year="2022",
pages="96--105",
abstract="We propose a new method to automatically contour the left ventricle on 2D echocardiographic images. Unlike most existing segmentation methods, which are based on predicting segmentation masks, we focus at predicting the endocardial contour and the key landmark points within this contour (basal points and apex). This provides a representation that is closer to how experts perform manual annotations and hence produce results that are physiologically more plausible. Our proposed method uses a two-headed network based on the U-Net architecture. One head predicts the 7 contour points, and the other head predicts a distance map to the contour. This approach was compared to the U-Net and to a point based approach, achieving performance gains of up to 22{\%} in terms of landmark localisation ({\$}{\$}{\{}<{\}}4.5{\$}{\$}<4.5 mm) and distance to the ground truth contour ({\$}{\$}{\{}<{\}}3.0{\$}{\$}<3.0 mm).",
isbn="978-3-031-16902-1"
}

@article{Gaggion_2022,
	year = 2022,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	author = {Nicolas Gaggion and Lucas Mansilla and Candelaria Mosquera and Diego H. Milone and Enzo Ferrante},
	title = {Improving anatomical plausibility in medical image segmentation via hybrid graph neural networks: applications to chest x-ray analysis},
	journal = {{IEEE} Transactions on Medical Imaging}
}


################ General uncertainty ##############


# BAYES BY BACKPROP
@InProceedings{pmlr-v37-blundell15, 
title = {Weight Uncertainty in Neural Network}, 
author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan}, 
booktitle = {Proceedings of the 32nd International Conference on Machine Learning}, 
pages = {1613--1622}, year = {2015},
volume = {37}, 
series = {Proceedings of Machine Learning Research}, address = {Lille, France}, month = {07--09 Jul}, publisher = {PMLR}, 
abstract = {We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.} 
}

# ENSEMBLES
@inproceedings{ensembles,
 author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
 booktitle = {NeuRIPS},
 pages = {},
 title = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
 volume = {30},
 year = {2017}
}


@inproceedings{Gal_2016_bayesNN,

title = {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
year = {2016},
publisher = {JMLR.org},
booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
pages = {1050–1059},
numpages = {10},
location = {New York, NY, USA},
series = {ICML’16}
}

@article{Gal_2015_BayesianCNN,
  author = {Gal, Yarin and Ghahramani, Zoubin},
  title={Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference},
  journal={ArXiv},
  year={2015},
  volume={abs/1506.02158}
}


 @inproceedings{bayesianCV,
 author = {Kendall, Alex and Gal, Yarin},
 booktitle = {NeuRIPS},
 pages = {5574--5584},
 title = {What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?},
 volume = {30},
 year = {2017}
}


@ARTICLE{multivariate_uncertainty,
  author={Russell, Rebecca L. and Reale, Christopher},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Multivariate Uncertainty in Deep Learning}, 
  year={2022},
  volume={33},
  number={12},
  pages={7937-7943},
  }


@inproceedings{ayhan2018_tta,
  title={Test-time Data Augmentation for Estimation of Heteroscedastic Aleatoric Uncertainty in Deep Neural Networks},
  author={Ayhan, Murat Seckin and Berens, Philipp},
  booktitle={International conference on Medical Imaging with Deep Learning},
  year={2018}
}

@article{leverage_model_conf,
  author    = {Terrance DeVries and
               Graham W. Taylor},
  title     = {Leveraging Uncertainty Estimates for Predicting Segmentation Quality},
  journal   = {CoRR},
  volume    = {abs/1807.00502},
  year      = {2018},
  archivePrefix = {arXiv},
  eprint    = {1807.00502},
  timestamp = {Mon, 13 Aug 2018 16:46:14 +0200},
}


################# SEGMENTATION UNCERTAINTY ############################

@article{WANG2019_tta_seg,
title = {Aleatoric uncertainty estimation with test-time augmentation for medical image segmentation with convolutional neural networks},
journal = {Neurocomputing},
volume = {338},
pages = {34-45},
year = {2019},
issn = {0925-2312},
author = {Guotai Wang and Wenqi Li and Michael Aertsen and Jan Deprest and Sébastien Ourselin and Tom Vercauteren},
keywords = {Uncertainty estimation, Convolutional neural networks, Medical image segmentation, Data augmentation},
}


@inproceedings{prob-unet,
 author = {Kohl, Simon and Romera-Paredes, Bernardino and Meyer, Clemens and De Fauw, Jeffrey and Ledsam, Joseph R. and Maier-Hein, Klaus and Eslami, S. M. Ali and Jimenez Rezende, Danilo and Ronneberger, Olaf},
 booktitle = {NeuRIPS},
 pages = {},
 title = {A Probabilistic U-Net for Segmentation of Ambiguous Images},
 volume = {31},
 year = {2018}
}

@inproceedings{phiseg,
author="Baumgartner, Christian F.
and Tezcan, Kerem C.
and Chaitanya, Krishna
and H{\"o}tker, Andreas M.
and Muehlematter, Urs J.
and Schawkat, Khoschy
and Becker, Anton S.
and Donati, Olivio
and Konukoglu, Ender",
title="PHiSeg: Capturing Uncertainty in Medical Image Segmentation",
booktitle="MICCAI",
year="2019",
pages="119--127",
isbn="978-3-030-32245-8"
}

@inproceedings{stochastic_seg_net,
 author = {Monteiro, Miguel and Le Folgoc, Loic and Coelho de Castro, Daniel and Pawlowski, Nick and Marques, Bernardo and Kamnitsas, Konstantinos and van der Wilk, Mark and Glocker, Ben},
 booktitle = {NeuRIPS},
 pages = {12756--12767},
 title = {Stochastic Segmentation Networks: Modelling Spatially Correlated Aleatoric Uncertainty},
 volume = {33},
 year = {2020}
}



############### HEATMAP UNCERTAINTY #############################

@article{thaler_heatmaps,
    title = "Modeling Annotation Uncertainty with Gaussian Heatmaps in Landmark Localization",
    author = "Thaler, Franz and Payer, Christian and Urschler, Martin and Štern, Darko",
    journal = "Machine Learning for Biomedical Imaging",
    volume = "1",
    issue = "UNSURE2020 special issue",
    year = "2021",
    pages = "1--27",
    issn = "2766-905X",
}

@ARTICLE{Schobs_heatmaps,
  author={Schobs, Lawrence Andrew and Swift, Andrew J. and Lu, Haiping},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Uncertainty Estimation for Heatmap-Based Landmark Localization}, 
  year={2023},
  volume={42},
  number={4},
  pages={1021-1034},}


@InProceedings{miccai2023_contouring,
author="Judge, Thierry
and Bernard, Olivier
and Cho Kim, Woo-Jin
and Gomez, Alberto
and Chartsias, Agisilaos
and Jodoin, Pierre-Marc",
title="Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation",
booktitle="MICCAI",
year="2023",
pages="210--220",
abstract="Aleatoric uncertainty estimation is a critical step in medical image segmentation. Most techniques for estimating aleatoric uncertainty for segmentation purposes assume a Gaussian distribution over the neural network's logit value modeling the uncertainty in the predicted class. However, in many cases, such as image segmentation, there is no uncertainty about the presence of a specific structure, but rather about the precise outline of that structure. For this reason, we explicitly model the location uncertainty by redefining the conventional per-pixel segmentation task as a contour regression problem. This allows for modeling the uncertainty of contour points using a more appropriate multivariate distribution. Additionally, as contour uncertainty may be asymmetric, we use a multivariate skewed Gaussian distribution. In addition to being directly interpretable, our uncertainty estimation method outperforms previous methods on three datasets using two different image modalities. Code is available at: https://github.com/ThierryJudge/contouring-uncertainty." 
}





################# EVALUATION ###########################


@InProceedings{guo17_callibration, 
title = {On Calibration of Modern Neural Networks}, 
author = {Chuan Guo and Geoff Pleiss and Yu Sun and Kilian Q. Weinberger}, 
booktitle = {Proceedings of the 34th International Conference on Machine Learning}, 
pages = {1321--1330}, year = {2017},
volume = {70}, series = {Proceedings of Machine Learning Research}, 
month = {06--11 Aug}, publisher = {PMLR}, 
abstract = {Confidence calibration – the problem of predicting probability estimates representative of the true correctness likelihood – is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling – a single-parameter variant of Platt Scaling – is surprisingly effective at calibrating predictions.} 
}

@inproceedings{reliability_diagram,
author = {Niculescu-Mizil, Alexandru and Caruana, Rich},
title = {Predicting Good Probabilities with Supervised Learning},
year = {2005},
isbn = {1595931805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We examine the relationship between the predictions made by different learning algorithms
and true posterior probabilities. We show that maximum margin methods such as boosted
trees and boosted stumps push probability mass away from 0 and 1 yielding a characteristic
sigmoid shaped distortion in the predicted probabilities. Models such as Naive Bayes,
which make unrealistic independence assumptions, push probabilities toward 0 and 1.
Other models such as neural nets and bagged trees do not have these biases and predict
well calibrated probabilities. We experiment with two ways of correcting the biased
probabilities predicted by some learning methods: Platt Scaling and Isotonic Regression.
We qualitatively examine what kinds of distortions these calibration methods are suitable
for and quantitatively examine how much data they need to be effective. The empirical
results show that after calibration boosted trees, random forests, and SVMs predict
the best probabilities.},
booktitle = {Proceedings of the 22nd International Conference on Machine Learning},
pages = {625–632},
numpages = {8},
location = {Bonn, Germany},
series = {ICML '05}
}

@article{ece, 
title={Obtaining Well Calibrated Probabilities Using Bayesian Binning}, volume={29}, 
abstractNote={ &lt;p&gt; Learning probabilistic predictive models that are well calibrated is critical for many prediction and decision-making tasks in artificial intelligence. In this paper we present a new non-parametric calibration method called Bayesian Binning into Quantiles (BBQ) which addresses key limitations of existing calibration methods. The method post processes the output of a binary classification algorithm; thus, it can be readily combined with many existing classification algorithms. The method is computationally tractable, and empirically accurate, as evidenced by the set of experiments reported here on both real and simulated datasets. &lt;/p&gt; }, 
number={1}, 
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
author={Pakdaman Naeini, Mahdi and Cooper, Gregory and Hauskrecht, Milos}, 
year={2015}, 
month={Feb.} 
}


@InProceedings{Nixon_2019_CVPR_Workshops_ACE,
author = {Nixon, Jeremy and Dusenberry, Michael W. and Zhang, Linchuan and Jerfel, Ghassen and Tran, Dustin},
title = {Measuring Calibration in Deep Learning},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2019}
}




@InProceedings{pmlr-v121-laves20a_UCE,
  title = 	 {Well-Calibrated Regression Uncertainty in Medical Imaging with Deep Learning},
  author =       {Laves, Max-Heinrich and Ihler, Sontje and Fast, Jacob F. and Kahrs, L\"uder A. and Ortmaier, Tobias},
  booktitle = 	 {Proceedings of the Third Conference on Medical Imaging with Deep Learning},
  pages = 	 {393--412},
  year = 	 {2020},
  volume = 	 {121},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--08 Jul},
  publisher =    {PMLR},
  abstract = 	 {The consideration of predictive uncertainty in medical imaging with deep learning is of utmost importance. We apply estimation of predictive uncertainty by variational Bayesian inference with Monte Carlo dropout to regression tasks and show why predictive uncertainty is systematically underestimated. We suggest using $ \sigma $ {\em scaling} with a single scalar value; a simple, yet effective calibration method for both aleatoric and epistemic uncertainty. The performance of our approach is evaluated on a variety of common medical regression data sets using different state-of-the-art convolutional network architectures. In all experiments, $\sigma $ scaling is able to reliably recalibrate predictive uncertainty. It is easy to implement and maintains the accuracy. Well-calibrated uncertainty in regression allows robust rejection of unreliable predictions or detection of out-of-distribution samples. Our source code is available at: {https://github.com/mlaves/well-calibrated-regression-uncertainty}}
}




##################### ECHO UNCERTAINTY ###################################

@INPROCEEDINGS{Jafari_bayesian_ef_uncertainty,
  author={Jafari, Mohammad H. and Woudenberg, Nathan Van and Luong, Christina and Abolmaesumi, Purang and Tsang, Teresa},
  booktitle={2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Deep Bayesian Image Segmentation For A More Robust Ejection Fraction Estimation}, 
  year={2021},
  volume={},
  number={},
  pages={1264-1268},
  keywords={Deep learning;Image segmentation;Uncertainty;Echocardiography;Point of care;Estimation;Muscles;Uncertainty Estimation;Bayesian Deep Learning;Image Segmentation;Left Ventricular Ejection Fraction;Echocardiography.},
  doi={10.1109/ISBI48211.2021.9433781}}








################ METHOD ######################

# DSNT 
@article{nibali2018numerical,
  title={Numerical Coordinate Regression with Convolutional Neural Networks},
  author={Nibali, Aiden and He, Zhen and Morgan, Stuart and Prendergast, Luke},
  journal={arXiv preprint arXiv:1801.07372},
  year={2018}
}


@article{PSM_ALBRECHT2013,
title = {Posterior shape models},
journal = {Medical Image Analysis},
volume = {17},
number = {8},
pages = {959-973},
year = {2013},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2013.05.010},
author = {Thomas Albrecht and Marcel Lüthi and Thomas Gerig and Thomas Vetter},
keywords = {Statistical shape model, Conditional shape model, Posterior shape model, Image segmentation, Trochlear dysplasia},
abstract = {We present a method to compute the conditional distribution of a statistical shape model given partial data. The result is a “posterior shape model”, which is again a statistical shape model of the same form as the original model. This allows its direct use in the variety of algorithms that include prior knowledge about the variability of a class of shapes with a statistical shape model. Posterior shape models then provide a statistically sound yet easy method to integrate partial data into these algorithms. Usually, shape models represent a complete organ, for instance in our experiments the femur bone, modeled by a multivariate normal distribution. But because in many application certain parts of the shape are known a priori, it is of great interest to model the posterior distribution of the whole shape given the known parts. These could be isolated landmark points or larger portions of the shape, like the healthy part of a pathological or damaged organ. However, because for most shape models the dimensionality of the data is much higher than the number of examples, the normal distribution is singular, and the conditional distribution not readily available. In this paper, we present two main contributions: First, we show how the posterior model can be efficiently computed as a statistical shape model in standard form and used in any shape model algorithm. We complement this paper with a freely available implementation of our algorithms. Second, we show that most common approaches put forth in the literature to overcome this are equivalent to probabilistic principal component analysis (PPCA), and Gaussian Process regression. To illustrate the use of posterior shape models, we apply them on two problems from medical image analysis: model-based image segmentation incorporating prior knowledge from landmarks, and the prediction of anatomically correct knee shapes for trochlear dysplasia patients, which constitutes a novel medical application. Our experiments confirm that the use of conditional shape models for image segmentation improves the overall segmentation accuracy and robustness.}
}


################# TRAINING  ############################### 

@inproceedings{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
}


#### ECHO uncertainty ##### 

@InProceedings{judge_crisp,
author="Judge, Thierry
and Bernard, Olivier
and Porumb, Mihaela
and Chartsias, Agisilaos
and Beqiri, Arian
and Jodoin, Pierre-Marc",
title="CRISP - Reliable Uncertainty Estimation for Medical Image Segmentation",
booktitle="MICCAI",
year="2022",
pages="492--502",
abstract="Accurate uncertainty estimation is a critical need for the medical imaging community. A variety of methods have been proposed, all direct extensions of classification uncertainty estimations techniques. The independent pixel-wise uncertainty estimates, often based on the probabilistic interpretation of neural networks, do not take into account anatomical prior knowledge and consequently provide sub-optimal results to many segmentation tasks. For this reason, we propose CRISP a ContRastive Image Segmentation for uncertainty Prediction method. At its core, CRISP implements a contrastive method to learn a joint latent space which encodes a distribution of valid segmentations and their corresponding images. We use this joint latent space to compare predictions to thousands of latent vectors and provide anatomically consistent uncertainty maps. Comprehensive studies performed on four medical image databases involving different modalities and organs underlines the superiority of our method compared to state-of-the-art approaches. Code is available at: https://github.com/ThierryJudge/CRISP-uncertainty.",
isbn="978-3-031-16452-1"
}

@article{unc_2d_echo,
  author       = {Lavsen Dahal and
                  Aayush Kafle and
                  Bishesh Khanal},
  title        = {Uncertainty Estimation in Deep 2D Echocardiography Segmentation},
  journal      = {CoRR},
  volume       = {abs/2005.09349},
  year         = {2020},
  url          = {https://arxiv.org/abs/2005.09349},
  eprinttype    = {arXiv},
  eprint       = {2005.09349},
  timestamp    = {Fri, 22 May 2020 16:21:28 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2005-09349.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{DEUE,
author="Kazemi Esfeh, Mohammad Mahdi
and Gholami, Zahra
and Luong, Christina
and Tsang, Teresa
and Abolmaesumi, Purang",
title="DEUE: Delta Ensemble Uncertainty Estimation for a More Robust Estimation of Ejection Fraction",
booktitle="MICCAI",
year="2022",
pages="525--534",
abstract="Left Ventricular Ejection Fraction (LVEF) as a critical clinical index is widely used to measure the functionality of the cyclic contraction of the left ventricle of the heart. Limited amount of available specialist-annotated data, low and variable quality of captured ultrasound images, and substantial inter/intra-observer variability in gold-standard measurements impose challenges on the robust data-driven automated estimation of LVEF in echocardiography (echo). Deep learning algorithms have recently shown state-of-the-art performance in cardiovascular image analysis. However, these algorithms are usually over-confident in their outputs even if they provide any measure of their output uncertainty. In addition, most of the uncertainty estimation methods in deep learning literature are either exclusively designed for classification tasks or are too memory/time expensive to be deployed on mobile devices or in clinical workflows that demand real-time memory-efficient estimations. In this work, we propose Delta Ensemble Uncertainty Estimation, a novel sampling-free method for estimating the epistemic uncertainty of deep learning algorithms for regression tasks. Our approach provides high-quality, architecture-agnostic and memory/time-efficient estimation of epistemic uncertainty with a single feed-forward pass through the network. We validate our proposed method on the task of LVEF estimation on EchoNet-Dynamic, a publicly available echo dataset, by performing a thorough comparison with multiple baseline methods."
}

@InProceedings{fimh_ef_unc,
author="S{\'a}nchez-Puente, Antonio
and P{\'e}rez-S{\'a}nchez, Pablo
and Vicente-Palacios, V{\'i}ctor
and Garc{\'i}a-Galindo, Alberto
and Vara, Pedro Pablo
and P{\'e}rez del Villar, Candelas
and S{\'a}nchez, Pedro L.",
title="Uncertainty to Improve the Automatic Measurement of Left Ventricular Ejection Fraction in 2D Echocardiography Using CNN-Based Segmentation",
booktitle="Functional Imaging and Modeling of the Heart",
year="2023",
pages="658--667",
abstract="The echocardiographic measurement of the left ventricular ejection fraction (LVEF) is the accepted clinical way to assess the cardiac function of a patient. For this measurement, a physician needs to identify the end-systole and end-diastole, segment the left ventricle in those frames, obtain the volume from the masks, and compute the LVEF. Naive implementations of convolutional neural network (CNN) based segmentation algorithms to perform this measurement might encounter problems identifying the end-systole and end-diastole if there is a single poorly segmented frame in the whole echocardiogram, which would ruin the measurement of LVEF and require manual review by a human operator. In this research article, we present how to use different uncertainty metrics to identify poorly segmented frames and quantify how these techniques improve the concordance between algorithm and human operator measurements in a population-based cohort of echocardiographic examinations.",
isbn="978-3-031-35302-4"
}

@InProceedings{dual_view_unc,
author="Behnami, Delaram
and Liao, Zhibin
and Girgis, Hany
and Luong, Christina
and Rohling, Robert
and Gin, Ken
and Tsang, Teresa
and Abolmaesumi, Purang",
title="Dual-View Joint Estimation of Left Ventricular Ejection Fraction with Uncertainty Modelling in Echocardiograms",
booktitle="MICCAI 2019",
year="2019",
pages="696--704",
abstract="Echocardiography (echo) is a standard-of-care imaging technique for characterizing heart function and structure. Left ventricular ejection fraction (EF) is the single most commonly measured cardiac metric and a powerful prognostic indicator of cardiac events. In two-dimensional transthoracic echo, EF is measured via (1) segmentation of left ventricle on multiple cross-sectional 2D views; and/or (2) visual assessment of echo cines. However, due to high inter- and intra-observer in both approaches, robust EF estimation has proven challenging. In this paper, we propose a dual-stream multi-tasking network for segmentation-free joint estimation of both segmentation- and visual assessment-based EF, across two echo views. To account for variability in EF labels, we introduce an uncertainty modelling layer, which enables the network to inherently capture the variability in expert-annotated clinical labels, of both regression and classification types. We trained a model on 1,751 apical two- and four-chamber pairs of echo cine loops and their corresponding EF labels, and achieved an {\$}{\$}R^2{\$}{\$}R2of 0.90, mean absolute error of 4.5{\%}, and classification accuracy of 91{\%} on a test set of 430 patients. Our proposed framework (1) requires no segmentation; (2) provides estimates for four clinical EF measurements derived from the two views; (3) recognizes the inherent uncertainties in echo measurements and encodes it; (4) provides measurements with corresponding uncertainties, which may help increase the interpretability and adoption of computer-generated clinical measurements. The proposed framework can be used as a generic approach for deriving other cardiac function parameters from echo.",
isbn="978-3-030-32245-8"
}


@ARTICLE{card_mri_unc,
  author={Ng, Matthew and Guo, Fumin and Biswas, Labonny and Petersen, Steffen E. and Piechnik, Stefan K. and Neubauer, Stefan and Wright, Graham},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={Estimating Uncertainty in Neural Networks for Cardiac MRI Segmentation: A Benchmark Study}, 
  year={2023},
  volume={70},
  number={6},
  pages={1955-1966},
  keywords={Uncertainty;Image segmentation;Biological neural networks;Training;Magnetic resonance imaging;Bayes methods;Distortion;Cardiac MRI segmentation;segmentation quality control;Bayesian neural networks;uncertainty},
}
########################


