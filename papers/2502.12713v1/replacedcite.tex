\section{Related Work}
\label{sec:related_work}

\subsection{Echocardiographic Segmentation}

Recently, deep neural networks trained on publicly available datasets such as CAMUS____ and EchoNet-Dynamic____ have reached a performance within inter-user variability, typically using architectures based on U-Net ____. Since, many different strategies such as echocardiography-specific data augmentation ____ and pyramid attention networks ____ have improved U-Net results. 
The recent publication of nnU-Net has significantly enhanced segmentation outcomes across various tasks ____ and, when applied to the CAMUS dataset, outperformed all prior methods____.%, even surpassing intra-user variability .


Recent works on cardiac and lung segmentation use point-based approaches ____. This approach is viable for these organs because of their regular shape. This formulation reduces anatomical implausibilities and increases interpretability due to its similarity to human labeling. Similar work on key-point localization has also been proposed in____. 


Regardless of the segmentation technique, a key objective following segmentation is the derivation of clinical metrics. A standard metric in echocardiography is the left ventricular area. A more accurate evaluation of the ventricular cavity size involves determining the ventricular volume using Simpson's biplane method____, utilizing the segmentation obtained from the apical 4-chamber (A4C) and apical 2-chamber (A2C) views. Additionally, temporal metrics are of significant interest. Examining the ratio of heart size between end-systole (ES) and end-diastole (ED) can provide indications of certain cardiac pathologies. The fractional area change (FAC) is defined as the difference between the end-diastolic  area and the end-systolic  area, divided by the end-diastolic area. Ejection fraction (EF) is calculated similarly, albeit with volume measurements.

% Additionally, global longitudinal strain (GLS), which measures the percentage change in length of the myocardium in the longitudinal direction during the cardiac cycle, is also an important parameter. The longitudinal deformation of the myocardium over the cardiac cycle can help diagnose pathologies less apparent when only considering the left ventricle cavity size ____. 


\subsection{Uncertainty Estimation}

Although numerous studies have proposed new models to enhance the segmentation accuracy, relatively few have addressed the predictive uncertainty of these models. Accounting for uncertainty is crucial, as although neural networks can achieve human-level performance, they can also make occasional critical errors.


Uncertainty is usually classified into two categories: {\em aleatoric} and {\em epistemic}____. Aleatoric uncertainty is the uncertainty present within the data itself. In medical imaging, aleatoric uncertainty is caused by the inherent ambiguity of images, which for instance can occur due to noisy images or labels.
Epistemic uncertainty is the uncertainty associated with the model and is caused by the limited size of the training dataset. While epistemic uncertainty can be reduced by acquiring more data, 
aleatoric uncertainty is irreducible.



One prominent approach for modeling epistemic uncertainty involves characterizing the distribution of model weights, $\theta$, conditioned on the data $\mathcal{D}$. This posterior distribution over weights, $p(\theta|\mathcal{D})$, is generally intractable to compute analytically for neural networks. Variational inference offers a method to approximate the true posterior using a variational distribution, $q_w(\theta)$, in Bayesian neural networks____. However, this approach necessitates significant modifications to standard training procedures. Alternative methods, such as Monte-Carlo (MC) dropout, have demonstrated effectiveness as a practical approximation for Bayesian neural networks, allowing for uncertainty estimation without altering the training pipeline, and have achieved reliable results____. On the other hand, a frequentist approach with ensemble methods leverages the variability of independently trained networks—each trained on different data subsets or with distinct hyperparameters—to capture uncertainty____.



While epistemic uncertainty methods usually do not require any data assumptions, this is not the case for aleatoric uncertainty methods. 
Most commonly, probabilistic approaches that model a distribution are used in aleatoric uncertainty methods. 
Most commonly, probabilistic approaches that model a parameterized distribution $p_\theta(y|x)$ over the output $y$ given the input $x$ are employed in aleatoric uncertainty methods. For instance, in the case of univariate regression, the mean and variance of a Gaussian distribution are learned by maximizing the negative log-likelihood with respect to both parameters. This can be extended to the multivariate normal____ or with different distributions such as the skew-normal distribution____. In the case of classification, uncertainty is approximated by modeling a Gaussian distribution across every output logit____.



Aleatoric uncertainty can also be predicted with non-probabilistic methods. Methods that use test-time augmentation apply random data transformations, perform inference and aggregate the outputs to model uncertainty____. 


While modeling both aleatoric and epistemic uncertainty is relevant to understanding the origin of the prediction ambiguity, it is also important to model the full predictive uncertainty. If the aleatoric uncertainty is captured by a model $p_\theta(y|x)$ and the epistemic uncertainty is modeled by $q_w(\theta)$, the predictive uncertainty is given by the law of total variance____
%
\begin{equation}
    \mathbb{V}_{p(y|x)} = \mathbb{E}_{q_w(\theta)}\Big[\mathbb{V}_{p_\theta(y|x)}[y]\Big] + \mathbb{V}_{q_w(\theta)}\Big[\mathbb{E}_{p_\theta(y|x)}[y]\Big].
\end{equation}
%
\subsubsection{Segmentation uncertainty}

In many cases, segmentation uncertainty is tackled similarly to classification. Epistemic uncertainty methods, such as MC dropout and ensembles, do not require any changes as multiple forward passes generate varying segmentation maps. In the case of aleatoric uncertainty, a simple way is to consider the prediction for each pixel as an independent classifier and estimate aleatoric uncertainty by modeling the logits of each pixel with a Gaussian____.


Pixel-wise aleatoric uncertainty often performs poorly since independent pixel distributions make plausible segmentation samples unlikely. For this reason, methods such as Probabilistic U-Net ____ and Phi-Seg ____ use a variational autoencoder coupled with a segmentation network to learn a distribution of shapes in the latent space from which plausible samples can be drawn. Similarly, stochastic segmentation networks learn a low-rank multivariate Gaussian representation of pixel distributions, enabling efficient training despite the large covariance matrix, and outperform previous methods____.

% In practice, pixel-wise aleatoric uncertainty performs poorly. Although this probabilistic approach offers the option to sample outputs from the predicted distribution, if each pixel is an independent distribution, the probability of sampling a plausible segmentation is very low. 
% For this reason, methods such as Probabilistic U-Net ____ and Phi-Seg ____ use a variational autoencoder coupled with the segmentation network to learn a distribution of shapes in the latent space that represents the uncertainty. Plausible samples can then be drawn from this distribution. Stochastic segmentation networks have recently proposed learning a low-rank multivariate Gaussian representation of pixel distributions, enabling efficient training despite the large covariance matrix and outperforming both Probabilistic U-Net and Phi-seg____.

Finally, test-time augmentation can be extended to segmentation by applying transforms to the input image and applying the inverse transform on the output segmentation____. 

% As the previous methods generated multiple samples a pixel-wise uncertainty map can be estimated by computing the pixel-wise entropy of a set of predictions. 

\subsubsection{Uncertainty in echocardiographic image analysis}

Numerous approaches have been developed to estimate uncertainty in echocardiography, usually focusing on segmentation or clinical metric prediction. For the former task, techniques like ensembles and test-time augmentation have been shown to improve left-ventricle segmentation performance (as measured by Dice scores) by excluding the most uncertain samples____. Judge \textit{et al.} took a post-hoc approach, predicting segmentation uncertainty by encoding prior information in a shared latent space____. For the latter task, Behnami \textit{et al.}____ proposed a multitask learning approach to estimate EF alongside its uncertainty for both the A2C and A4C views, using Gaussian modeling. Their work also included a classification-based prediction of EF, categorizing cardiac function into four classes from normal to severe dysfunction. In a similar vein, Kazemi Esfeh \textit{et al.} introduced a sampling-free ensemble method to estimate epistemic uncertainty, specifically targeting EF regression with a delta ensemble approach____.

Although these methods may propose robust prediction and uncertainty measures, they lack intelligibility of clinical metric prediction extracted from segmentation maps. Jafari \textit{et al.}____ proposed a method to estimate segmentation uncertainty using MC dropout. They then define an uncertainty measure based on this uncertainty map and use it to filter samples showing an increased correlation between predicted ejection fraction values and ground truth values. While this is similar to our work, there is no explicit uncertainty estimation for the ejection fraction as their method only filters out samples with uncertainty above a certain threshold. 

In summary, existing methods have failed to connect uncertainty for segmentation and the resulting clinical metrics. This paper addresses this limitation by providing a method to quantify and propagate uncertainty from the predicted shape to the derived metrics in an interpretable way.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% METHOD %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%