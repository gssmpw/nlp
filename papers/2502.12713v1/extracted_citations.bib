@article{2020LeftVE,
  title={Left Ventricular Ejection Fraction},
  author={},
  journal={Definitions},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:80279998}
}

@InProceedings{DEUE,
author="Kazemi Esfeh, Mohammad Mahdi
and Gholami, Zahra
and Luong, Christina
and Tsang, Teresa
and Abolmaesumi, Purang",
title="DEUE: Delta Ensemble Uncertainty Estimation for a More Robust Estimation of Ejection Fraction",
booktitle="MICCAI",
year="2022",
pages="525--534",
abstract="Left Ventricular Ejection Fraction (LVEF) as a critical clinical index is widely used to measure the functionality of the cyclic contraction of the left ventricle of the heart. Limited amount of available specialist-annotated data, low and variable quality of captured ultrasound images, and substantial inter/intra-observer variability in gold-standard measurements impose challenges on the robust data-driven automated estimation of LVEF in echocardiography (echo). Deep learning algorithms have recently shown state-of-the-art performance in cardiovascular image analysis. However, these algorithms are usually over-confident in their outputs even if they provide any measure of their output uncertainty. In addition, most of the uncertainty estimation methods in deep learning literature are either exclusively designed for classification tasks or are too memory/time expensive to be deployed on mobile devices or in clinical workflows that demand real-time memory-efficient estimations. In this work, we propose Delta Ensemble Uncertainty Estimation, a novel sampling-free method for estimating the epistemic uncertainty of deep learning algorithms for regression tasks. Our approach provides high-quality, architecture-agnostic and memory/time-efficient estimation of epistemic uncertainty with a single feed-forward pass through the network. We validate our proposed method on the task of LVEF estimation on EchoNet-Dynamic, a publicly available echo dataset, by performing a thorough comparison with multiple baseline methods."
}

@article{GUDU,
title = {GUDU: Geometrically-constrained Ultrasound Data augmentation in U-Net for echocardiography semantic segmentation},
journal = {Biomedical Signal Processing and Control},
volume = {82},
pages = {104557},
year = {2023},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2022.104557},
author = {Christoforos Sfakianakis and Georgios Simantiris and Georgios Tziritas},
keywords = {Segmentation, Echocardiography, U-Net, Data augmentation, Ensemble method, Clinical metrics},
abstract = {Echocardiography is a very important medical examination that helps in the computation of critical heart functions. Boundary identification, segmentation and estimation of the volume of key parts of the heart, especially the left ventricle, is a difficult and time-consuming process, even for the most experienced cardiologists. In recent years, research has focused on the automatic segmentation of heart through artificial intelligence techniques and especially with the use of deep learning. Our work is part of this framework. We implemented an ensemble of convolutional neural networks based on the U-net architecture, trained it using a public dataset of cardiac ultrasound images, and combined the outcomes to extract the areas of the left ventricle, myocardium and left atrium. In order to optimize the training process, we have developed a significant data augmentation method based on medical practice. Furthermore, we extended the Dice loss function by imposing additional mandatory anatomical constraints. An ablation study highlights the contribution of each of our proposed modules. The evaluation of our method showed an overall improvement in segmentation accuracy but also in the estimation of clinical metrics. Specifically, using the Dice coefficient for geometric metrics, we achieved for the epicardium a score of 0.96 and 0.955 for the end-diastolic and end-systolic phase respectively. For the clinical metrics of the left ventricle volume, the Pearson correlation coefficient was used where our method gave 0.977, 0.981, 0.897 for the end-diastolic, end-systolic phase and ejection fraction respectively. Scores which up until the writing of this article outperform competitive methods.}
}

@article{Gaggion_2022,
	year = 2022,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	author = {Nicolas Gaggion and Lucas Mansilla and Candelaria Mosquera and Diego H. Milone and Enzo Ferrante},
	title = {Improving anatomical plausibility in medical image segmentation via hybrid graph neural networks: applications to chest x-ray analysis},
	journal = {{IEEE} Transactions on Medical Imaging}
}

@article{Gal_2015_BayesianCNN,
  author = {Gal, Yarin and Ghahramani, Zoubin},
  title={Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference},
  journal={ArXiv},
  year={2015},
  volume={abs/1506.02158}
}

@inproceedings{Gal_2016_bayesNN,

title = {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
year = {2016},
publisher = {JMLR.org},
booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
pages = {1050–1059},
numpages = {10},
location = {New York, NY, USA},
series = {ICML’16}
}

@INPROCEEDINGS{Jafari_bayesian_ef_uncertainty,
  author={Jafari, Mohammad H. and Woudenberg, Nathan Van and Luong, Christina and Abolmaesumi, Purang and Tsang, Teresa},
  booktitle={2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Deep Bayesian Image Segmentation For A More Robust Ejection Fraction Estimation}, 
  year={2021},
  volume={},
  number={},
  pages={1264-1268},
  keywords={Deep learning;Image segmentation;Uncertainty;Echocardiography;Point of care;Estimation;Muscles;Uncertainty Estimation;Bayesian Deep Learning;Image Segmentation;Left Ventricular Ejection Fraction;Echocardiography.},
  doi={10.1109/ISBI48211.2021.9433781}}

@article{Leclerc19,
  author={Leclerc, Sarah and others},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Deep Learning for Segmentation Using an Open Large-Scale Dataset in 2D Echocardiography}, 
  year={2019},
  volume={38},
  number={9},
  pages={2198-2210}}

@article{Ouyang2020_echonet,
  title = {Video-based AI for beat-to-beat assessment of cardiac function},
  volume = {580},
  ISSN = {1476-4687},
  DOI = {10.1038/s41586-020-2145-8},
  number = {7802},
  journal = {Nature},
  publisher = {Springer Science and Business Media LLC},
  author = {Ouyang,  David and He,  Bryan and Ghorbani,  Amirata and Yuan,  Neal and Ebinger,  Joseph and Langlotz,  Curtis P. and Heidenreich,  Paul A. and Harrington,  Robert A. and Liang,  David H. and Ashley,  Euan A. and Zou,  James Y.},
  year = {2020},
  month = mar,
  pages = {252–256}
}

@ARTICLE{Schobs_heatmaps,
  author={Schobs, Lawrence Andrew and Swift, Andrew J. and Lu, Haiping},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Uncertainty Estimation for Heatmap-Based Landmark Localization}, 
  year={2023},
  volume={42},
  number={4},
  pages={1021-1034},}

@article{WANG2019_tta_seg,
title = {Aleatoric uncertainty estimation with test-time augmentation for medical image segmentation with convolutional neural networks},
journal = {Neurocomputing},
volume = {338},
pages = {34-45},
year = {2019},
issn = {0925-2312},
author = {Guotai Wang and Wenqi Li and Michael Aertsen and Jan Deprest and Sébastien Ourselin and Tom Vercauteren},
keywords = {Uncertainty estimation, Convolutional neural networks, Medical image segmentation, Data augmentation},
}

@inproceedings{ayhan2018_tta,
  title={Test-time Data Augmentation for Estimation of Heteroscedastic Aleatoric Uncertainty in Deep Neural Networks},
  author={Ayhan, Murat Seckin and Berens, Philipp},
  booktitle={International conference on Medical Imaging with Deep Learning},
  year={2018}
}

@inproceedings{bayesianCV,
 author = {Kendall, Alex and Gal, Yarin},
 booktitle = {NeuRIPS},
 pages = {5574--5584},
 title = {What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?},
 volume = {30},
 year = {2017}
}

@inproceedings{camus_nnUnet,
  TITLE = {{Reaching intra-observer variability in 2-D echocardiographic image segmentation with a simple U-Net architecture}},
  AUTHOR = {Ling, Hang Jung and Garcia, Damien and Bernard, Olivier},
  BOOKTITLE = {{IEEE International Ultrasonics Symposium (IUS)}},
  ADDRESS = {Venice, Italy},
  YEAR = {2022},
  MONTH = Oct,
  KEYWORDS = {Ultrasound ; Deep learning ; U-Net ; Cardiac},
  HAL_ID = {hal-03979523},
  HAL_VERSION = {v1},
}

@InProceedings{dual_view_unc,
author="Behnami, Delaram
and Liao, Zhibin
and Girgis, Hany
and Luong, Christina
and Rohling, Robert
and Gin, Ken
and Tsang, Teresa
and Abolmaesumi, Purang",
title="Dual-View Joint Estimation of Left Ventricular Ejection Fraction with Uncertainty Modelling in Echocardiograms",
booktitle="MICCAI 2019",
year="2019",
pages="696--704",
abstract="Echocardiography (echo) is a standard-of-care imaging technique for characterizing heart function and structure. Left ventricular ejection fraction (EF) is the single most commonly measured cardiac metric and a powerful prognostic indicator of cardiac events. In two-dimensional transthoracic echo, EF is measured via (1) segmentation of left ventricle on multiple cross-sectional 2D views; and/or (2) visual assessment of echo cines. However, due to high inter- and intra-observer in both approaches, robust EF estimation has proven challenging. In this paper, we propose a dual-stream multi-tasking network for segmentation-free joint estimation of both segmentation- and visual assessment-based EF, across two echo views. To account for variability in EF labels, we introduce an uncertainty modelling layer, which enables the network to inherently capture the variability in expert-annotated clinical labels, of both regression and classification types. We trained a model on 1,751 apical two- and four-chamber pairs of echo cine loops and their corresponding EF labels, and achieved an {\$}{\$}R^2{\$}{\$}R2of 0.90, mean absolute error of 4.5{\%}, and classification accuracy of 91{\%} on a test set of 430 patients. Our proposed framework (1) requires no segmentation; (2) provides estimates for four clinical EF measurements derived from the two views; (3) recognizes the inherent uncertainties in echo measurements and encodes it; (4) provides measurements with corresponding uncertainties, which may help increase the interpretability and adoption of computer-generated clinical measurements. The proposed framework can be used as a generic approach for deriving other cardiac function parameters from echo.",
isbn="978-3-030-32245-8"
}

@inproceedings{ensembles,
 author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
 booktitle = {NeuRIPS},
 pages = {},
 title = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
 volume = {30},
 year = {2017}
}

@article{isensee2021nnu,
  title={nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation},
  author={Isensee, Fabian and Jaeger, Paul F and Kohl, Simon AA and Petersen, Jens and Maier-Hein, Klaus H},
  journal={Nature methods},
  volume={18},
  number={2},
  pages={203--211},
  year={2021},
  publisher={Nature Publishing Group US New York}
}

@InProceedings{judge_crisp,
author="Judge, Thierry
and Bernard, Olivier
and Porumb, Mihaela
and Chartsias, Agisilaos
and Beqiri, Arian
and Jodoin, Pierre-Marc",
title="CRISP - Reliable Uncertainty Estimation for Medical Image Segmentation",
booktitle="MICCAI",
year="2022",
pages="492--502",
abstract="Accurate uncertainty estimation is a critical need for the medical imaging community. A variety of methods have been proposed, all direct extensions of classification uncertainty estimations techniques. The independent pixel-wise uncertainty estimates, often based on the probabilistic interpretation of neural networks, do not take into account anatomical prior knowledge and consequently provide sub-optimal results to many segmentation tasks. For this reason, we propose CRISP a ContRastive Image Segmentation for uncertainty Prediction method. At its core, CRISP implements a contrastive method to learn a joint latent space which encodes a distribution of valid segmentations and their corresponding images. We use this joint latent space to compare predictions to thousands of latent vectors and provide anatomically consistent uncertainty maps. Comprehensive studies performed on four medical image databases involving different modalities and organs underlines the superiority of our method compared to state-of-the-art approaches. Code is available at: https://github.com/ThierryJudge/CRISP-uncertainty.",
isbn="978-3-031-16452-1"
}

@InProceedings{lv3ch-dsnt,
author="Gomez, Alberto
and Porumb, Mihaela
and Mumith, Angela
and Judge, Thierry
and Gao, Shan
and Kim, Woo-Jin Cho
and Oliveira, Jorge
and Chartsias, Agis",
title="Left Ventricle Contouring of Apical Three-Chamber Views on 2D Echocardiography",
booktitle="Simplifying Medical Ultrasound",
year="2022",
pages="96--105",
abstract="We propose a new method to automatically contour the left ventricle on 2D echocardiographic images. Unlike most existing segmentation methods, which are based on predicting segmentation masks, we focus at predicting the endocardial contour and the key landmark points within this contour (basal points and apex). This provides a representation that is closer to how experts perform manual annotations and hence produce results that are physiologically more plausible. Our proposed method uses a two-headed network based on the U-Net architecture. One head predicts the 7 contour points, and the other head predicts a distance map to the contour. This approach was compared to the U-Net and to a point based approach, achieving performance gains of up to 22{\%} in terms of landmark localisation ({\$}{\$}{\{}<{\}}4.5{\$}{\$}<4.5 mm) and distance to the ground truth contour ({\$}{\$}{\{}<{\}}3.0{\$}{\$}<3.0 mm).",
isbn="978-3-031-16902-1"
}

@InProceedings{miccai2023_contouring,
author="Judge, Thierry
and Bernard, Olivier
and Cho Kim, Woo-Jin
and Gomez, Alberto
and Chartsias, Agisilaos
and Jodoin, Pierre-Marc",
title="Asymmetric Contour Uncertainty Estimation for Medical Image Segmentation",
booktitle="MICCAI",
year="2023",
pages="210--220",
abstract="Aleatoric uncertainty estimation is a critical step in medical image segmentation. Most techniques for estimating aleatoric uncertainty for segmentation purposes assume a Gaussian distribution over the neural network's logit value modeling the uncertainty in the predicted class. However, in many cases, such as image segmentation, there is no uncertainty about the presence of a specific structure, but rather about the precise outline of that structure. For this reason, we explicitly model the location uncertainty by redefining the conventional per-pixel segmentation task as a contour regression problem. This allows for modeling the uncertainty of contour points using a more appropriate multivariate distribution. Additionally, as contour uncertainty may be asymmetric, we use a multivariate skewed Gaussian distribution. In addition to being directly interpretable, our uncertainty estimation method outperforms previous methods on three datasets using two different image modalities. Code is available at: https://github.com/ThierryJudge/contouring-uncertainty." 
}

@ARTICLE{multivariate_uncertainty,
  author={Russell, Rebecca L. and Reale, Christopher},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Multivariate Uncertainty in Deep Learning}, 
  year={2022},
  volume={33},
  number={12},
  pages={7937-7943},
  }

@inproceedings{phiseg,
author="Baumgartner, Christian F.
and Tezcan, Kerem C.
and Chaitanya, Krishna
and H{\"o}tker, Andreas M.
and Muehlematter, Urs J.
and Schawkat, Khoschy
and Becker, Anton S.
and Donati, Olivio
and Konukoglu, Ender",
title="PHiSeg: Capturing Uncertainty in Medical Image Segmentation",
booktitle="MICCAI",
year="2019",
pages="119--127",
isbn="978-3-030-32245-8"
}

@InProceedings{pmlr-v37-blundell15, 
title = {Weight Uncertainty in Neural Network}, 
author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan}, 
booktitle = {Proceedings of the 32nd International Conference on Machine Learning}, 
pages = {1613--1622}, year = {2015},
volume = {37}, 
series = {Proceedings of Machine Learning Research}, address = {Lille, France}, month = {07--09 Jul}, publisher = {PMLR}, 
abstract = {We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.} 
}

@inproceedings{prob-unet,
 author = {Kohl, Simon and Romera-Paredes, Bernardino and Meyer, Clemens and De Fauw, Jeffrey and Ledsam, Joseph R. and Maier-Hein, Klaus and Eslami, S. M. Ali and Jimenez Rezende, Danilo and Ronneberger, Olaf},
 booktitle = {NeuRIPS},
 pages = {},
 title = {A Probabilistic U-Net for Segmentation of Ambiguous Images},
 volume = {31},
 year = {2018}
}

@article{pyramid_att_seg,
title = {Deep pyramid local attention neural network for cardiac structure segmentation in two-dimensional echocardiography},
journal = {Medical Image Analysis},
volume = {67},
pages = {101873},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2020.101873},
author = {Fei Liu and Kun Wang and Dan Liu and Xin Yang and Jie Tian},
keywords = {2D echocardiography, Cardiac structure segmentation, Pyramid local attention, Label coherence learning},
abstract = {Automatic semantic segmentation in 2D echocardiography is vital in clinical practice for assessing various cardiac functions and improving the diagnosis of cardiac diseases. However, two distinct problems have persisted in automatic segmentation in 2D echocardiography, namely the lack of an effective feature enhancement approach for contextual feature capture and lack of label coherence in category prediction for individual pixels. Therefore, in this study, we propose a deep learning model, called deep pyramid local attention neural network (PLANet), to improve the segmentation performance of automatic methods in 2D echocardiography. Specifically, we propose a pyramid local attention module to enhance features by capturing supporting information within compact and sparse neighboring contexts. We also propose a label coherence learning mechanism to promote prediction consistency for pixels and their neighbors by guiding the learning with explicit supervision signals. The proposed PLANet was extensively evaluated on the dataset of cardiac acquisitions for multi-structure ultrasound segmentation (CAMUS) and sub-EchoNet-Dynamic, which are two large-scale and public 2D echocardiography datasets. The experimental results show that PLANet performs better than traditional and deep learning-based segmentation methods on geometrical and clinical metrics. Moreover, PLANet can complete the segmentation of heart structures in 2D echocardiography in real time, indicating a potential to assist cardiologists accurately and efficiently.}
}

@inproceedings{stochastic_seg_net,
 author = {Monteiro, Miguel and Le Folgoc, Loic and Coelho de Castro, Daniel and Pawlowski, Nick and Marques, Bernardo and Kamnitsas, Konstantinos and van der Wilk, Mark and Glocker, Ben},
 booktitle = {NeuRIPS},
 pages = {12756--12767},
 title = {Stochastic Segmentation Networks: Modelling Spatially Correlated Aleatoric Uncertainty},
 volume = {33},
 year = {2020}
}

@article{thaler_heatmaps,
    title = "Modeling Annotation Uncertainty with Gaussian Heatmaps in Landmark Localization",
    author = "Thaler, Franz and Payer, Christian and Urschler, Martin and Štern, Darko",
    journal = "Machine Learning for Biomedical Imaging",
    volume = "1",
    issue = "UNSURE2020 special issue",
    year = "2021",
    pages = "1--27",
    issn = "2766-905X",
}

@article{unc_2d_echo,
  author       = {Lavsen Dahal and
                  Aayush Kafle and
                  Bishesh Khanal},
  title        = {Uncertainty Estimation in Deep 2D Echocardiography Segmentation},
  journal      = {CoRR},
  volume       = {abs/2005.09349},
  year         = {2020},
  url          = {https://arxiv.org/abs/2005.09349},
  eprinttype    = {arXiv},
  eprint       = {2005.09349},
  timestamp    = {Fri, 22 May 2020 16:21:28 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2005-09349.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{unet,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="MICCAI",
year="2015",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

