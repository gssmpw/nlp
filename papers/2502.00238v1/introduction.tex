\section{Introduction} 
\label{sec:introduction}

Safety-critical cyber-physical systems (CPS) pervade our lives across a variety of domains, including autonomous vehicles, robotic healthcare, and smart power grids \cite{gunes2014survey,dey2018medical,koopman2017autonomous}. These systems operate at the intersection of the digital and physical worlds, where reliability, dependability, and safety are of paramount concern \cite{hawkins2015weaving}. 
Many cyber-physical systems must undergo some form of certification or regulatory approval to ensure that they meet strict safety requirements \cite{johnson1998178b}. 
%Various standards, such as ISO 26262 (automotive) \cite{palin2011iso}, provide guidelines to ensure that the processes meet safety standards to receive regulatory approval. %To mitigate risks, 
Certifying a safety-critical system typically involves constructing and submitting an \emph{assurance case} to regulators in order to demonstrate that risks are acceptable and the system will operate as intended, in compliance with applicable regulations \cite{bloomfield1998ascad}. 

\begin{figure}
    \centering
    \includegraphics[scale = 0.80]{Figures/defeasible-reasoning.pdf}
    \caption{Overview of the safety assurance case lifecycle, %using defeasible reasoning, 
    illustrating the roles of various stakeholders.}
    \label{fig:Defeasible}
    %\vspace{-4.5mm}
\end{figure}

An assurance case, also called a safety assurance case, is a structured argument that the safety goal(s), i.e., the safety requirement(s), are satisfied in the delivered system operating in its intended context. For example, Knight describes an assurance case for an uncrewed aircraft, where the high-level goal (i.e., safety requirement) is that the aircraft is “adequately safe to operate in [its] prescribed environment” \cite{Knight12}. An assurance case provides a structured hierarchy of claims, arguments, and supporting evidence to show that the system will work as intended in the planned operational environment \cite{kelly2004goal,rushby2015interpretation,bloomfield2024defeaters}.

A rich body of research has introduced formal notations (e.g., Goal Structuring Notation \cite{kelly2004goal}) and various tools \cite{maksimov2019survey,10311213,denney2012advocate} to support safety analysts in constructing assurance cases. In practice, however, assurance cases are challenging to build and often suffer from incomplete, inconsistent, and unsound arguments. Such defects in assurance cases can lead to unwarranted overconfidence in system safety, with several aviation incidents linked, in part, to these shortcomings \cite{cave2006independent}.

There is thus a need to more effectively find obstacles \cite{jLamLet00} to the soundness of an assurance case's claim that its safety goals are adequately satisfied in the deployed product. These obstacles, termed \emph{defeaters}, are any factors, conditions, or events that weaken or invalidate the safety claims made about the system \cite{goodenough2015eliminative,gohar2024codefeater}. Defeaters challenge the completeness and soundness of an assurance case, often introducing uncertainty and exposing overlooked potential failures \cite{bloomfield2024defeaters}, making their identification and mitigation critical to safety assurance. 
Figure \ref{fig:Defeasible} shows a typical lifecycle of assurance cases developed from safety requirements and using defeaters. For instance, in our prior work \cite{gohar2024codefeater}, an assurance case for a small Uncrewed Aircraft System (sUAS) battery included the requirement: ``The battery charge is sufficient to complete the flight." This was challenged by the defeater: ``Unless the battery monitor is uncalibrated." Unlike fault tree analysis, which identifies events leading to a hazard, or FMECA (Failure Modes, Effects, and Criticality Analysis), which evaluates consequences of failures, defeaters specifically target potential weaknesses in assurance case arguments \cite{Knight12}.

While recent research has explored various approaches to address defeaters, such as using large language models (LLMs) with human-in-the-loop techniques \cite{gohar2024codefeater,AISupported} or semantic analysis and reasoning methods \cite{murugesan2023semantic,rushby2015understanding}, these efforts remain limited. As systems grow more autonomous and complex, anticipating all possible failure modes %or environmental factors
becomes increasingly difficult. Moreover, generating defeaters is labor-intensive \cite{AISupported}, relying heavily on the judgment and creativity of safety analysts, which can be prone to confirmation bias \cite{bloomfield2021safety,10311213}.  

There have been repeated calls for a systematic approach to identifying %and managing
defeaters in assurance cases \cite{maksimov2019survey,bloomfield2021safety,rushby2015interpretation,bloomfield2024defeaters}. 
Rushby et al. \cite{rushby2015understanding} have noted that ``a systematic search for plausible defeaters may be an effective way to probe an assurance case and counteract the influence of confirmation bias." 

Towards supporting that vision, our paper proposes a taxonomy of defeaters derived from publicly available assurance cases found in the literature and our team's experience with defeater analysis. This can provide a necessary foundation for standardizing defeater analysis in assurance cases and improving the overall robustness of safety-critical systems. The proposed taxonomy can serve as a safety checklist and guide to aid developers and reviewers in improving coverage and quality of defeater analysis for safety assurance cases.

This work makes three key contributions. \textbf{1)} Surveying the real-world defeaters reported in published assurance cases;  
\textbf{2) }Using thematic analysis to derive a proposed taxonomy of defeaters from the survey’s findings; and \textbf{3) }Evaluating the defeater taxonomy in an initial application on a new real-world assurance case and suggesting potential mitigations.

The rest of the paper is organized as follows: In Section \ref{sec:background}, we provide motivation and background. Section \ref{sec:methodology} outlines our survey methodology, while Section \ref{sec:taxonomy} introduces our proposed taxonomy with examples. We discuss the implications of our work in Section \ref{sec:discussion} and related work in Section \ref{sec:related}. Section \ref{sec:conclusion} gives concluding remarks. 


