\section{Evaluation}


% 4 Evaluation
\subsection{Evaluation Setup}

\begin{figure}[t]
\vspace{-0.12in}
\centering
\includegraphics[width=1\linewidth]{Figures/protocol_latency.pdf}
\caption{A Breakdown of (a) Accuracy and (b) Latency of APINT in BERT-base Model Inference
with 128 Tokens}
\vspace{-0.2in}
\label{fig:protocol_latency}
\end{figure}

% \textit{\textbf{APINT Protocol}} 
To evaluate the APINT protocol, we configured the two instances, one for a client and the other for a server, each with Intel Xeon Platinum 8452Y CPU~\cite{intelIntelXeon} at 2.0GHz, 32 threads, and 1TB of DRAM. They communicated via a network with 0.165ms latency and 9.6Gbps bandwidth, akin to LAN environments as prior study~\cite{boemer2020mp2ml}. CPU energy was tracked by a commercial tool~\cite{intelRunningAverage}. GC and HE(BFV~\cite{brakerski2014leveled}) were implemented using EMP-tool~\cite{emp-toolkit} and SEAL~\cite{sealcrypto} libraries, respectively. The security level of GC is verified by AES-128. The benchmark utilized BERT-base~\cite{devlin2018bert} with 128 tokens and five datasets from GLUE~\cite{wang2018glue}. The bit precision was set at 37 bits for Softmax and LayerNorm, and 21 bits for GeLU, ensuring accuracy as recent study~\cite{pang2023bolt}.
% \textit{\textbf{GC-friendly circuit Generation}}
The constituent circuits of the functions were implemented via Verilog and then converted into a netlist using the Synopsys Design Compiler~\cite{synopsysDesignCompiler}. These netlists were subsequently transformed into Bristol format and merged using EMP-tool.
% \textit{\textbf{Compiler and Hardware Accelerator}}

A cycle-accurate simulator was developed to model the GC accelerator of \sysname and HAAC, with running memories at 2GHz and computational units at 1GHz. 
To accurately measure memory stalls caused by external DRAM accesses, we used Ramulator~\cite{kim2015ramulator}, the well-known DRAM simulator, after configuring it with HBM2 specifications~\cite{o2017fine}. Also, for HBM2's energy consumption measurement, we utilized values from prior research~\cite{o2017fine}.
% To accurately measure memory stalls due to off-chip communication, Ramulator DRAM simulator~\cite{kim2015ramulator} was utilized, which was configured using HBM2 specifications and DRAM access energy consumption values from prior research~\cite{o2017fine}.
For the computational units, we measured the area by synthesizing using 28nm technology via Synopsys Design Compiler. For their energy consumption measurement and timing verification, we utilized the PrimeTime~\cite{synopsysGoldStandard}.
In addition, most of the memories are constructed using SRAMs, except for some registers storing special bits. Specifically, the SRAM's specification was taken from the TSMC N28HPC+ Memory Compiler~\cite{usermanual, mo2023haac}, aligning with HAAC's conditions. 
% The Synopsys Design Compiler and PrimeTime~\cite{synopsysGoldStandard}, following a 28nm synthesis, measured the area and energy consumption of each unit in the hardware. The accelerator's memories are constructed using SRAMs, while special bits are implemented using registers. The SRAM specifications were taken from the TSMC N28HPC+ Memory Compiler~\cite{usermanual, mo2023haac}, aligning with HAAC's conditions.
For comparative analysis with HAAC, the total area was scaled to 16nm, applying a reduction factor of 1.9x, following HAACâ€™s methodology~\cite{statnano16FFFinFET, mo2023haac, statnanoTSMC20nm}.


\begin{figure} [t]
\vspace{-0.12in}
\centering
\includegraphics[width=1\linewidth]{Figures/Camera-ready/And_Gate_Num_Reduced.pdf}
\caption{The Reduction of (a) ANDs and (b) CPU Energy Consumption by GC-friendly Circuit Generation}
\vspace{-0.2in}
\label{fig:netgen_result}
\end{figure}

\subsection{APINT Protocol}

\begin{figure*}[t]
    \vspace{-0.2in}
    \centering
    \includegraphics[width=1\linewidth]{Figures/Camera-ready/Evaluation_Latency_Reduced.pdf}
    \caption{Breakdown of (a) Latency, (b) OoRW Counts, and (c) DRAM Access Counts for GC Evaluation of Nonlinear functions in BERT-base Model Inference
with 128 Tokens across Scheduling, Speculation, and GC Accelerators}
    % \vspace{-0.1in}
    \label{fig:total_eval}
\end{figure*}


\subsubsection{\textbf{Accuracy}}
Figure~\ref{fig:protocol_latency} (a) shows the accuracy of a BERT-base model using APINT protocol on the five datasets from GLUE, compared with plaintext FP32. The results demonstrate that the \sysname protocol is feasible for performing PiT while maintaining accuracy.

\subsubsection{\textbf{Latency}}
\circled{1} and \circled{2} in Figure~\ref{fig:protocol_latency} (b) displays latency reductions for a single inference in an end-to-end BERT-base model processing 128 input tokens, comparing the \sysname protocol with the PRIMER's protocol, both executed on a CPU. During the offline phase, computation latency arises from GC garbling, and communication latency is due to the transfer of the circuit and client labels. In the online phase, computation latency results from GC evaluation, and communication latency is caused by OT. The \sysname protocol reduces the circuit for LayerNorm operation, leading to a 10.8\% reduction in circuit transmission and GC garbling during the offline phase, and a 12.9\% reduction in the GC evaluation in the online phase.



\subsection{GC-friendly Circuit Generation}

\subsubsection{\textbf{Latency}}
As depicted in Figure~\ref{fig:netgen_result} (a), APINT's GC-friendly circuit generation employs XBFQ multiplication to reduce the number of AND gates, achieving reductions of 48.1\% for Softmax, 33.7\% for GeLU, and 45.6\% for LayerNorm for a single inference, compared to the baseline method by Testa~\cite{testa2020logic}. This reduction directly corresponds to a decrease in Half-Gate operations, subsequently reducing both the GC garbling and evaluation latency. In addition, it decreases the number of garbled tables, thereby reducing the communication latency of transferring them during the offline phase. Consequently, as shown in \circled{3} in Figure~\ref{fig:protocol_latency} (b), an additional application of the GC-friendly circuit generation to the APINT protocol results in a 31.6\% and 36.5\% reduction in latency during the offline and online phases, respectively.

\subsubsection{\textbf{CPU Energy Consumption}}
The reduction in Half-Gate operations also impacts the CPU's energy consumption. As depicted in Figure~\ref{fig:netgen_result} (b), the circuit generation reduces the energy consumption of a CPU for a single inference by 43.9\% for Softmax, 24.5\% for GeLU, and 25.0\% for LayerNorm. To sum up, APINT's GC-friendly circuit generation not only reduces latency during both online and offline phases but also lowers energy consumption.

\subsection{Netlist Scheduling, Compiler Speculation, and APINT Accelerator}

\subsubsection{\textbf{Latency}}
Figure~\ref{fig:total_eval} depicts the reduction of latency, OoRWs, and DRAM accesses achieved by the netlist scheduling, compiler speculation, and APINT accelerator while operating nonlinear functions in a single inference, compared to the HAAC. However, when using a netlist ordered by EMP-tool's depth-first scheduling and a netlist scheduled by FR scheduling of HAAC, significant latency occurs due to high dependency and substantial memory stalls, respectively. Therefore, their results are only briefly mentioned at the top of the graph, and the \sysname accelerator was evaluated against the HAAC accelerator using SR scheduling.

\textit{\textbf{Coarse-grained Scheduling}} Coarse-grained scheduling significantly reduces pipeline stalls across all nonlinear functions by resolving wire dependencies. It also decreases memory stall time for Softmax and LayerNorm, yet it marginally increases it for GeLU. This variation is due to a trade-off of the scheduling approach. As illustrated in Figure~\ref{fig:total_eval} (b), the schedule enhances DRAM bandwidth utilization, resulting in lower DRAM access counts. Conversely, as depicted in Figure~\ref{fig:total_eval} (c), it causes an increase in OoRWs due to the segmented allocation of on-chip memory across different cores. This effect is particularly pronounced for GeLU, which has a higher number of operable independent wires compared to other functions. Thus, memory stalls are slightly increased for GeLU, unlike other functions. Nonetheless, the reduction in pipeline stall times dominates in a decrease in total latency for all functions.

\textit{\textbf{APINT Accelerator \& Compiler Speculation}} APINT accelerator with compiler speculation notably diminishes memory stalls across all functions compared to HAAC's accelerator with course-grained scheduling, as illustrated in Figure~\ref{fig:total_eval} (a). This result stems from a substantial reduction in the number of OoRWs due to compiler speculation and a significant decrease in unnecessary DRAM accesses enabled by the OoRW fetching approach of the APINT accelerator, as depicted in Figure~\ref{fig:total_eval} (b) and (c). Therefore, unlike HAAC, \sysname accelerator with compiler speculation has resolved most of the memory bottleneck.

\textit{\textbf{Fine-grained Scheduling}} Applying fine-grained scheduling significantly reduces pipeline stalls compared to employing HAAC's SR scheduling, demonstrating the superiority of APINT's scheduling in resolving wire dependencies, as described in Figure~\ref{fig:total_eval} (a). This conclusively shows that \sysname not only resolves memory bottlenecks but also optimally settles the wire dependencies.

In summary, the APINT accelerator resolves memory bottlenecks and further enhances the compute performance, achieving an average latency reduction of 3.3$\times$ across all functions, with a specific reduction of 5.0$\times$ for Softmax, 2.2$\times$ for GeLU, and 3.9$\times$ for LayerNorm during GC evaluation compared to HAAC. Given that the only difference between GC garbling and GC evaluation is an additional three cycles required to compute the Half-Gate, similar latency reduction ratios are observed in both processes. This improvement of the APINT accelerator results in a 27.6\% reduction in online latency, while HE is processed by CPU, as depicted in \circled{4} and \circled{5} of Figure~\ref{fig:protocol_latency}. Overall, APINT's full-stack solutions result in a substantial reduction in latency, with a 2.2$\times$ decrease during the offline phase and a 12.2$\times$ reduction during the online phase.

\begin{figure} [t]
\vspace{-0.12in}
\centering
\includegraphics[width=1\linewidth]{Figures/Camera-ready/Area_Power_Reduced.pdf}
\caption{A Breakdown of (a) Area of APINT Accelerator and (b) System Energy Consumption}
\vspace{-0.2in}
\label{fig:power_result}
\end{figure}

\subsubsection{\textbf{System Energy Consumption}} The reduction in DRAM accesses not only alleviates memory stalls but also significantly lowers system energy consumption. Unlike HAAC, which primarily focuses on on-chip energy consumption, we highlight the importance of managing consumption due to external memory accesses (EMA). As depicted in Figure~\ref{fig:power_result}, although the APINT accelerator has nearly the same area and on-chip energy consumption as HAAC, it achieves a significant reduction in EMAs, leading to substantial system energy savings of 4.9$\times$ for Softmax, 3.6$\times$ for GeLU, and 5.7$\times$ for LayerNorm, averaging a 4.6$\times$ decrease overall.