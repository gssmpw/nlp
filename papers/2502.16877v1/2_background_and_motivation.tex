\section{Background and Motivation}

\begin{figure}[t]
    \vspace{-0.2in}
    \centering
    \includegraphics[width=1\linewidth]{Figures/gc_overview_ver3.pdf}
    \caption{Garbled Circuit Protocol Overview}
    \vspace{-0.2in}
    \label{fig:garbled_circuit}
\end{figure}

\subsection{Protocols for Privacy-Preserving Inference}
\subsubsection{\textbf{Homomorphic Encryption}}
HE is a cryptographic method allowing operations on encrypted data (ciphertext) that produce the same results as if performed on unencrypted data (plaintext). It supports operations like addition and multiplication between plaintext and ciphertext ($Enc(X)+Y = Enc(X+Y)$, $Enc(X)\times Y = Enc(X\times Y)$), and among ciphertexts ($Enc(X)+Enc(Y) = Enc(X+Y)$, $Enc(X)\times Enc(Y) = Enc(X\times Y)$).

% Multiplying ciphertexts is more resource-intensive than operating between plaintext and ciphertext. To optimize efficiency, the upcoming protocol restricts operations to plaintext-ciphertext interactions.

% ($Enc$ refers to the process of encrypting plaintext to convert it into ciphertext.)\\
% \textit{1) ciphertext-plaintext addition:} $Enc(X)+Y = Enc(X+Y)$\\
% \textit{2) ciphertext-plaintext multiplication:} $Enc(X)Y = Enc(XY)$

\subsubsection{\textbf{Garbled Circuits}}
% Garbled Circuit detailed
GC involves two parties---the Garbler and the Evaluator---jointly compute without disclosing their inputs. The GC process involves four steps, as shown in Figure~\ref{fig:garbled_circuit}.\\
\textit{1) Circuit and Netlist Generation: } 
The function to be computed is represented as a circuit of 2-input logic gates, and it is converted to a netlist format, which contains information about each gate's inputs (input wires), output (output wire), and type (ex. AND).\\
\textit{2) GC Garbling: } 
For each wire \textit{i} in the netlist, the garbler randomly generates a 128b label ($W_i^0$) corresponding to 0. The label ($W_i^1$) corresponding to 1 is then produced by performing an XOR operation on ($W_i^0$) with a random 128b value R, which is fixed and public. After assigning the labels, the garbler constructs a truth table for each logic gate and encrypts it to create the garbled table. Finally, the garbler selects the corresponding label for its input wire ($a \in (W_a^0, W_a^1)$), which will be used in GC evaluation.\\
\textit{3) Garbler-Evaluator Communication:}
The garbler transmits the garbled tables and the selected label to the evaluator. Additionally, the garbler sends the label, corresponding to the evaluator's input wire ($b \in (W_b^0, W_b^1)$), to the evaluator without knowing the wire's value. This can be achieved through Oblivious Transfer (OT) protocol ~\cite{ishai2003extending}.\\
\textit{4) GC Evaluation:}
The evaluator calculates the output for each gate using the garbled tables and the labels provided by both the garbler and evaluator. The output becomes the new label of the input wire of the next gates, and the evaluations proceed sequentially for all gates in the netlist.

Recent enhancements in GC---Half-Gate~\cite{zahur2015two} for AND gates and FreeXOR~\cite{kolesnikov2008improved} for XOR gates---have reduced computational demands and memory footprints. To facilitate this, the netlist employs solely AND, XOR, and INV gates. It should be noted that INV gates, unlike AND and XOR gates, can be implemented at no cost by simply removing them and inverting the correspondence between the values and labels of the wires. In the garbling phase, contrary to the original GC that assigns labels of output wires randomly, the Half-Gate operation for AND gates produces an output wire's label and two garbled tables through four AES computations of the input wires' labels. Conversely, the FreeXOR operation for XOR gates generates an output wire's label by XOR computation of the input wires' labels without creating any garbled tables.
During the evaluation phase, a Half-Gate operation produces an output wire's label by garbled tables and two AES computations of input wires' labels, and a FreeXOR operation computes an output wire's label directly through an XOR operation of input wires' labels.




\begin{figure}[t]
    \vspace{-0.2in}
    \centering
    \includegraphics[width=1\linewidth]{Figures/Camera-ready/Motivation_Reduced.pdf}
    % \includegraphics[width=1\linewidth]{Figures/motivation.pdf}
    \caption{Latency Analysis of Prior Works (a) PRIMER Protocol and (b) HAAC}
    \vspace{-0.2in}
    \label{fig:APINT_motivation}
\end{figure}
    
\subsection{Motivation for \sysname}

Previous studies have several issues in effectively processing PiT by speeding up GC, the primary bottleneck.
First, in terms of protocol, PRIMER~\cite{zheng2023primer} has solely focused on optimizing HE and has not introduced any methods to reduce the latency of GC. As depicted in Figure~\ref{fig:APINT_motivation} (a), which presents the latency result for a single inference of the BERT-base model~\cite{devlin2018bert} with 128 tokens using the PRIMER protocol on a CPU, GC evaluation accounts for 94.7\% of the online latency. Moreover, GC garbling, along with the transfer of labels and garbled tables, contributes to 77.9\% of the offline latency. Therefore, there is a significant need for a new protocol that substantially reduces the latency of GC.

Second, regarding circuit generation, prior works~\cite{testa2019reducing, testa2020logic, liu2022don} haven't proposed the optimal way to reduce the number of AND gates. Given that Half-Gate operations are more complex than FreeXOR operations, reducing the number of AND gates can significantly decrease the GC workload. To achieve this, previous works have optimized the XOR-AND-Graph (XAG) in which the circuit is converted into a DAG. However, these approaches failed to realize a more optimal method by overlooking modifications to the fundamental implementation of the circuit.

Third, with respect to the accelerator, previous works~\cite{hussain2019fase, mo2023haac} mitigated the latency issue of GC, but none of them proposed practical solutions to operate the nonlinear functions of transformers. FASE~\cite{hussain2019fase}, which benchmarked with a small dataset, assumed that the on-chip itself could cover all the wires required during the operation.
However, this approach is infeasible since the nonlinear functions have many more wires than the on-chip can physically support. Although HAAC~\cite{mo2023haac} partially solved this problem with an additional scheme utilizing off-chip memory, it suffers from memory stalls and pipeline stalls as described in Figure~\ref{fig:APINT_motivation} (b) due to suboptimal scheduling, inefficient on-chip memory policies, and hardware structures not considering wire reusability.
% However, it suffers from memory bottlenecks when operating nonlinear functions of transformers due to suboptimal scheduling, as well as on-chip memory management policies and hardware structures not mainly designed to consider wire reusability.

\sysname aims to overcome these deficiencies by providing the full stack solution while fulfilling four key requirements. First, it must adhere to a new protocol that reduces the GC computations, the main bottleneck of PiT. Second, it should generate the circuit in a GC-friendly way that ensures a reduction of GC workloads to decrease latency and memory footprint. Third, it requires appropriate scheduling to reduce memory stalls and pipeline stalls. Fourth, it necessitates an accelerator equipped with the compiler, which resolves memory bottlenecks and redundant DRAM traffic.

% Third, it requires appropriate scheduling and accelerator architecture to resolve latency overhead caused by memory bottlenecks and wire dependencies.