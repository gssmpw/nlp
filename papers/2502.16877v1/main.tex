%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[sigconf]{acmart}

\newcommand{\sysname}{APINT }
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
%\usepackage{amssymb}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{titlesec}



\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=1pt] (char) {\scriptsize #1};}}

\captionsetup[figure]{skip=5pt} % 그림과 캡션 사이 간격 조정
% \setlength{\textfloatsep}{5pt plus 1.0pt minus 1.0pt} % 캡션과 글 사이 간격 조정

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.


\copyrightyear{2024}
\acmYear{2024}
\setcopyright{rightsretained}
\acmConference[ICCAD '24]{IEEE/ACM International Conference on
Computer-Aided Design}{October 27--31, 2024}{New York, NY, USA}
\acmBooktitle{IEEE/ACM International Conference on Computer-Aided Design
(ICCAD '24), October 27--31, 2024, New York, NY, USA}
\acmDOI{10.1145/3676536.3676786}
\acmISBN{979-8-4007-1077-3/24/10}

% 주석 제거하는코드
% \settopmatter{printacmref=false}
% \renewcommand\footnotetextcopyrightpermission[1]{}
\pagestyle{plain}
%%%%%%%%%%


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
\acmSubmissionID{1237}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{APINT: A Full-Stack Framework for Acceleration of Privacy-Preserving Inference of Transformers based on Garbled Circuits}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.


% \numberofauthors{4}
% % Three authors sharing the same affiliation.
%     \author{
%       \alignauthor Hyunjun Cho\\      
%       \email{h.cho@kaist.ac.kr}
% %
%       \alignauthor Jaeho Jeon\\     
%       \email{math15738@kaist.ac.kr}
% %
%       \alignauthor Jaehoon Heo\\    
%       \email{kd01050@kaist.ac.kr}
      
%       \alignauthor Joo-Young Kim\\    
%       \email{jooyoung1203@kaist.ac.kr}
% %
%       \sharedaffiliation
%       % \affaddr{Department of Electrical Engineering and Computer Science}  \\
%       \affaddr{KAIST, Daejeon }   \\
%           }

% \author{Hyunjun Cho, Jaeho Jeon, Jaehoon Heo, Joo-Young Kim}
% \affiliation{%
%  \institution{School of Electrical Engineering, KAIST}
% }
% \affiliation{%
%   \institution{\{h.cho, math15738, kd01050, jooyoung1203\}@kaist.ac.kr}
% }

\settopmatter{authorsperrow=4}
\author{Hyunjun Cho}
% \authornote{Both authors contributed equally to this research.}
\email{h.cho@kaist.ac.kr}
\orcid{0009-0008-2378-852X}
\affiliation{%
  \institution{KAIST}
  \city{Daejeon}
  \country{South Korea}
}

\author{Jaeho Jeon}
% \authornote{Both authors contributed equally to this research.}
\email{math15738@kaist.ac.kr}
\orcid{0009-0008-2250-6068}
\affiliation{%
  \institution{KAIST}
  \city{Daejeon}
  \country{South Korea}
}

\author{Jaehoon Heo}
% \authornote{Both authors contributed equally to this research.}
\email{kd01050@kaist.ac.kr}
\orcid{0000-0003-1742-4275}
\affiliation{%
  \institution{KAIST}
  \city{Daejeon}
  \country{South Korea}
}

\author{Joo-Young Kim}
% \authornote{Both authors contributed equally to this research.}
\email{jooyoung1203@kaist.ac.kr}
\orcid{0000-0003-1099-1496}
\affiliation{%
  \institution{KAIST}
  \city{Daejeon}
  \country{South Korea}
}


\begin{abstract}
As the importance of Privacy-Preserving Inference of Transformers (PiT) increases, a hybrid protocol that integrates Garbled Circuits (GC) and Homomorphic Encryption (HE) is emerging for its implementation. While this protocol is preferred for its ability to maintain accuracy, it has a severe drawback of excessive latency. 
%To address this, the existing protocol decreased its latency by primarily focusing on HE latency but not on the latency of GC. Consequently, GC has become the primary bottleneck of the protocol, remaining an unresolved challenge. Furthermore, despite efforts in various sectors to reduce its latency, previous studies have not optimally minimized its overhead, nor have they provided a comprehensive solution.
To address this, existing protocols primarily focused on reducing HE latency, thus making GC the new latency bottleneck. Furthermore, previous studies only focused on individual computing layers, such as protocol or hardware accelerator, lacking a comprehensive solution at the system level.
%Furthermore, previous studies only worked on particular aspects such as reducing the GC workload and employing a GC hardware accelerator, unable to provide a comprehensive solution with holistic optimization.

% However, previous efforts to reduce GC workload by decreasing the number of AND gates in circuits have not achieved optimal reductions. Additionally, prior attempts to mitigate GC latency through hardware accelerators have encountered severe memory bottlenecks and data dependencies when processing PiT. These issues highlight the urgent need for innovative approaches to accelerate the PiT by addressing GC latency.

% The proliferation of cloud-based services using pre-trained Transformer models for NLP tasks has highlighted critical privacy issues, as sensitive data such as financial and health information are at risk of exposure. This challenge underscores the growing necessity for Privacy-preserving inference on Transformers (PiT). However, PiT faces significant latency challenges, primarily due to the overhead associated with Garbled Circuits (GC). Existing approaches have not sufficiently addressed the reduction of GC overhead, nor have they effectively minimized the computational workload, especially in reducing the number of AND gates in circuit designs. Additionally, despite advancements in accelerator technology for GC, they lack a practical solution for managing nonlinear functions within transformer models.

This paper presents APINT, a full-stack framework designed to reduce PiT's overall latency by addressing the latency problem of GC through both software and hardware solutions. APINT features a novel protocol that reallocates possible GC workloads to alternative methods (i.e., HE or standard matrix operation), substantially decreasing the GC workload. It also suggests GC-friendly circuit generation that reduces the number of AND gates at the most, which is the expensive operator in GC. Furthermore, APINT proposes an innovative netlist scheduling that combines coarse-grained operation mapping and fine-grained scheduling for maximal data reuse and minimal dependency. Finally, APINT's hardware accelerator, combined with its compiler speculation, effectively resolves the memory stall issue. Putting it all together, APINT achieves a remarkable end-to-end reduction in latency, outperforming the existing protocol on CPU platform by 12.2$\times$ online and 2.2$\times$ offline. Meanwhile, the APINT accelerator not only reduces its latency by 3.3$\times$ but also saves energy consumption by 4.6$\times$ while operating PiT compared to the state-of-the-art GC accelerator.

% \vspace{-0.04in}

% The rising importance of Privacy-preserving inference on Transformers (PiT) is driven by the need to protect sensitive client data, like financial and health information, which is potentially exposed when using cloud-based, pre-trained Transformer models for NLP tasks. However, it suffers from significant latency issues, particularly since Garbled Circuits (GC) account for the majority of the online latency.
% Prior studies have identified several challenges in accelerating Privacy-preserving inference on Transformers (PiT) due to the latency issues primarily associated with Garbled Circuits (GC), which contribute significantly to online latency. Existing protocols have not addressed the reduction of GC overhead. Additionally, prior methods have not adequately minimized the workload, particularly in terms of reducing the number of AND gates. Furthermore, while advancements have been made in the development of accelerators for GC, they have not proposed a practical solution for nonlinear functions in transformer models. 
% This paper introduces APINT, a full-stack framework designed to enhance the efficiency of PiT across both the software and hardware side. First, it employs a novel protocol that mitigates online latency by redistributing GC workloads between alternative computational methods and the preprocessing phase. Second, it suggests GC-Friendly netlist generation to significantly cut down the number of AND gates, effectively decreasing both GC computation and communication latency. Third, APINT utilizes coarse-grained and fine-grained scheduling to reduce data dependencies and enhance data reuse. Fourth, the APINT hardware accelerator with compiler speculation optimizes data reusability and minimize unnecessary DRAM accesses. Collectively, APINT achieves significant latency reductions---58.5\% offline and 89.9\% online---resulting in a total latency decrease of 66.6\% compared to the conventional method. Specifically, the APINT accelerator reduces latency by 23.4\% and system energy consumption by 78.1\% compared to the SOTA GC accelerator.


\end{abstract}


\maketitle

\input{1_introduction}
\input{2_background_and_motivation}
\input{3_framework}
\input{4_evaluation}
\input{5_conclusion}

\bibliographystyle{ACM-Reference-Format}
\bibliography{ref}
% \bibliography{main}

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
