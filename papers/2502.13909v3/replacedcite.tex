\section{Related Work}
% \subsection{Sequential Recommender Systems}
\noindent\textbf{Sequential Recommender Systems. }
Recommendation systems primarily focus on capturing collaborative filtering (CF) to identify similar items/users. Matrix Factorization-based approaches, achieved notable success by constructing CF knowledge in a latent space ____. However, in conjunction with CF knowledge, understanding dynamic evolution in temporal user preferences has become a powerful tool, leading to the development of collaborative filtering-based sequential recommenders (CF-SRec) ____.
Initial approaches combined Matrix Factorization with Markov Chains to model temporal dynamics ____. Subsequently, neural network-based methods advanced sequential recommender systems, with GRU4Rec ____ leveraging recurrent architectures, while methods such as Caser ____ and NextItNet ____ adopted Convolutional Neural Networks ____. More recently, models such as SASRec ____ and BERT4Rec ____, based on attention mechanisms, have demonstrated superior performance by focusing on the more relevant interaction sequences. These advancements underscore the importance of effectively modeling user behavior dynamics for improved recommendation accuracy.

% \subsection{LLM-based Recommender Systems}
\smallskip
\noindent\textbf{LLM-based Recommender Systems. }
% TALLRec, LLaRA, CoLLM, A-LLMRec
LLMs have recently gained attention in recommendation systems ____, leveraging their reasoning ability and textual understanding for novel approaches such as zero-shot recommendation ____ and conversational recommendation ____. However, TALLRec ____ highlights the gap between LLMs' language modeling tasks and recommendation tasks, proposing a fine-tuning approach through Parameter-Efficient Fine-Tuning (PEFT) to adapt LLMs to recommendation tasks.
More recently, LLaRA ____, CoLLM ____, and A-LLMRec ____ have been proposed. LLaRA and CoLLM combine CF-SRec item embeddings with text embeddings from item titles, enabling LLMs to utilize CF knowledge. A-LLMRec further incorporates item descriptions into a latent space, enabling the model to demonstrate robust performance in various scenarios.
Despite these advancements, prior methods fail to capture dynamic user preferences inherent in user interaction sequences as shown in Sec.~\ref{sec: sequence exp}. 

% \vspace{-1ex}