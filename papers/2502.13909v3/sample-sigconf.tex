
%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
% \documentclass[sigconf,anonymous,review]{acmart}
\documentclass[sigconf]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}
\usepackage{lipsum}  

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}
\settopmatter{printacmref=false}


%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation emai}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/18/06}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{kotex}
\usepackage{booktabs}
\usepackage{makecell}
\newcommand{\proposed}{\textsf{LLM-SRec}}
% \linespread{0.94}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
% \title{Incorporating LLMs for the Utilization of Collaborative Knowledge in Sequential Recommendation}

\title{Lost in Sequence: Do Large Language Models Understand Sequential Recommendation?}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Sein Kim}
\authornote{Both authors contributed equally to this research.}
\email{rlatpdlsgns@kaist.ac.kr}
\affiliation{
\institution{KAIST}
\city{Daejeon}
\country{Republic of Korea}
}

\author{Hongseok Kang}
\authornotemark[1]
\email{ghdtjr0311@kaist.ac.kr}
\affiliation{
\institution{KAIST}
\city{Daejeon}
\country{Republic of Korea}
}

\author{Kibum Kim}
\email{kb.kim@kaist.ac.kr}
\affiliation{
\institution{KAIST}
\city{Daejeon}
\country{Republic of Korea}
}

\author{Jiwan Kim}
\email{kim.jiwan@kaist.ac.kr}
\affiliation{
\institution{KAIST}
\city{Daejeon}
\country{Republic of Korea}
}


\author{Donghyun Kim}
\email{amandus.kim@navercorp.com}
\affiliation{
\institution{NAVER Corperation}
\city{Seongnam}
\country{Republic of Korea}
}

\author{Minchul Yang}
\email{minchul.yang@navercorp.com}
\affiliation{
\institution{NAVER Corperation}
\city{Seongnam}
\country{Republic of Korea}
}

\author{Kwangjin Oh}
\email{kj.oh@navercorp.com}
\affiliation{
\institution{NAVER Corperation}
\city{Seongnam}
\country{Republic of Korea}
}

\author{Julian McAuley}
\email{jmcauley@ucsd.edu}
\affiliation{
\institution{University of California San Diego}
\city{California}
\country{USA}
}

\author{Chanyoung Park}
\authornote{Corresponding author.}
\email{cy.park@kaist.ac.kr}
\affiliation{
\institution{KAIST}
\city{Daejeon}
\country{Republic of Korea}
}
%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Kim et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Large Language Models (LLMs) have recently emerged as promising tools for recommendation thanks to their advanced textual understanding ability and context-awareness. Despite the current practice of training and evaluating LLM-based recommendation (LLM4Rec) models under a sequential recommendation scenario, we found that whether these models understand the sequential information inherent in users’ item interaction sequences has been largely overlooked. In this paper, we first demonstrate through a series of experiments that existing LLM4Rec models do not fully capture sequential information both during training and inference. Then, we propose a simple yet effective LLM-based sequential recommender, called~\proposed, a method that enhances the integration of sequential information into LLMs by distilling the user representations extracted from a pre-trained CF-SRec model into LLMs.
Our extensive experiments show that~\proposed~enhances LLMs' ability to understand users' item interaction sequences, ultimately leading to improved recommendation performance.
% Our extensive experiments demonstrate that ~\proposed~ enhances the ability of LLMs to understand users' item interaction sequences, which eventually leads to improved recommendation performance.
% Furthermore, our approach achieves more efficient than existing LLM4Rec without requiring fine-tuning of either the CF-SRec or the LLMs. Our code is available at \textcolor{blue}{annoymous repo}.
Furthermore, unlike existing LLM4Rec models that require fine-tuning of LLMs, \proposed~achieves state-of-the-art performance by training only a few lightweight MLPs, highlighting its practicality in real-world applications. Our code is available at \url{https://github.com/Sein-Kim/LLM-SRec}.


% Furthermore, unlike existing LLM4Rec models that require fine-tuning of LLMs, \proposed~only requires the training of a few lightweight MLPs while achieving the state-of-the-art performance, demonstrating the practicality of~\proposed~in reality. 

% despite the simplistic design of~\proposed~that does not require fine-tuning of either the CF-SRec or the LLMs, 
% eliminates the need for additional training or fine-tuning on either the pre-trained CF-SRec or the LLMs.

% we show that ~\proposed~is highly effective in equipping LLMs with the ability to comprehend sequential information, making it lightweight but effective for sequential recommendation tasks. Our code is available at \textcolor{blue}{annoymous repo}.

% Last but not least, unlike existing LLM4Rec models such as TALLRec, LLaRA, and CoLLM, all of which require fine-tuning of LLMs, ~\proposed~eliminates the need for additional training or fine-tuning on either the pre-trained CF-SRec or the LLMs. Despite its simplicity, ~\proposed~ is highly effective in equipping LLMs with the ability to comprehend sequential information, making it lightweight but effective for sequential recommendation tasks.


% Sequential Pattern in recommendation system.
% LLM4Rec problems.
% Extensive Experiments verify 
% Our method, distillation
% Efficiency
% Our code is available at \textcolor{blue}{annonymous repo}
% Effective modeling of sequential patterns in user interaction histories is crucial for personalized recommendation systems. While Collaborative filtering based sequential recommenders (CF-SRec) have shown successful results by capturing dynamic user preferences from the user interaction sequence, they face challenges in cold-start scenarios. Large Language Models (LLMs) have emerged as promising tools for tackling cold-start and cross-domain problems by leveraging rich textual information. 
% Although previous studies have demonstrated the notable recommendation performance of LLM-based sequential recommendation (LLM4Rec), their ability to capture and utilize sequential patterns in user interactions has not been adequately validated.
% In this paper, we investigate the sequence understanding capabilities of LLM4Rec models through comprehensive experiments. Our findings reveal that LLM4Rec models struggle to capture sequential information, even though they are designed for sequential recommendation.
% To address the limitation of LLM4Rec, we propose a novel framework, \textcolor{blue}{Model Full Name} (\proposed), which distills sequential knowledge from pre-trained CF-SRec into LLMs. Our extensive experiments demonstrate that ~\proposed~ enhances the ability of LLMs to understand and utilize user interaction sequences, leading to improved recommendation performance. Furthermore, our approach achieves more efficient than existing LLM4Rec without requiring fine-tuning of either the CF-SRec or the LLMs. Our code is available at \textcolor{blue}{annoymous repo}.

% Understanding the dynamic nature of user interests is crucial for accurate predictions and personalized recommendations in domains like e-commerce and streaming. While collaborative filtering-based sequential recommenders (CF-SRec) effectively capture dynamic preferences, they face challenges in cold-start scenarios due to sparse interactions. Large Language Models (LLMs) have emerged as promising tools for tackling cold-start and cross-domain problems by leveraging rich textual information. However, their ability to comprehend and utilize sequential information for recommendation tasks remains insufficiently explored.
% This paper investigates the limitations of LLM4Rec approaches in capturing sequence information. Our findings indicate that LLMs show minimal performance differences when user sequences are shuffled, in contrast to CF-SRec models, which are sensitive to sequence order. To address these limitations, we propose a cost-efficient method to distill sequential user representations from pre-trained CF-SRec models into LLMs, enabling them to leverage sequential properties without additional fine-tuning.
% Our approach enhances the integration of sequence information in LLM4Rec, addressing key shortcomings of existing methods. Experimental results validate our method’s effectiveness, offering a pathway to improve sequential understanding in LLM-based recommender systems.


\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>00000000.0000000.0000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>00000000.00000000.00000000</concept_id>
%   <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
% \ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Recommender System, Large Language Models, Sequence modeling}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.


% \received{20 February 2007}
% \received[revised]{12 March 2009}
% \received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

% \vspace{-1ex}
\section{Introduction}
% Collaborative filtering-based sequential recommenders (CF-SRec) \cite{kang2018self, sun2019bert4rec, wu2019session, kim2023task, hidasi2015session} have emerged as a key solution to capture the temporal dynamics of user preferences by understanding their item interaction sequences.
% Despite their effectiveness, CF-SRec face challenges in cold-start scenarios due to sparse user-item interactions \cite{kim2023melt, NIPS2017_dbd22ba3, liu2021augmenting, 10.1145/3109859.3109912}.
% To overcome this limitation, extensive research has explored the integration of multiple modalities, such as text and images, into recommender systems \cite{10.1145/3580305.3599519, geng2022recommendation, hu2023adaptive}. 
% Recently, Large Language Models (LLMs) have emerged as powerful tools for recommendation leveraging their advanced textual understanding ability and knowledge \cite{bao2023tallrec, 10.1145/3626772.3657690, zhang2023collm, 10.1145/3637528.3671931, li2023e4srec}.

Early efforts in LLM-based recommendation (LLM4Rec), such as TALLRec \cite{bao2023tallrec}, highlighted a gap between the capabilities of LLMs in text generation and sequential recommendation tasks, and proposed to address the gap by fine-tuning LLMs for sequential recommendation tasks using LoRA \cite{hu2022lora}. Subsequent studies, including LLaRA \cite{10.1145/3626772.3657690}, CoLLM \cite{zhang2023collm}, and A-LLMRec \cite{10.1145/3637528.3671931}, criticized the exclusive reliance of TALLRec on textual modalities, which rather limited its recommendation performance in warm scenarios (i.e., recommendation scenarios with abundant user-item interactions) \cite{zhang2023collm, 10.1145/3637528.3671931}. 
These methods transform item interaction sequences into text and provide them as prompts to LLMs \cite{10.1145/3626772.3657690} or align LLMs with a pre-trained Collaborative filtering-based sequential recommender (CF-SRec), such as SASRec \cite{kang2018self}, to incorporate the collaborative knowledge into LLMs \cite{10.1145/3637528.3671931}.
% which has been shown to enhance their capability for sequential recommendation under both warm and cold-start scenarios.
% , these methods align LLMs with CF-SRec, unlocking the potential of LLMs for sequential recommendation and achieving superior performance under both warm and cold scenarios.

% The core of LLM4Rec, which has successfully adapted LLMs for recommendation tasks, lies in the premise of transforming sequential recommendation into language modeling, by converting the behavior sequence into textual input prompts \cite{10.1145/3626772.3657690}. This transformation allows LLMs to utilize their extensive reasoning capabilities for effective sequential recommendation. However, this premise remains insufficiently validated, leaving important questions to be addressed. \textbf{Can LLMs, inherently built for linguistic tasks, truly adapt to understanding user interaction patterns and the nuances of sequential recommendation?} Furthermore, \textbf{Do enhancements using collaborative knowledge from pre-trained CF-SRec \cite{zhang2023collm,10.1145/3626772.3657690, 10.1145/3637528.3671931} genuinely enable LLMs to leverage sequential information in recommendation tasks effectively?} Our short answer is LLMs seem to struggle with fully understanding and utilizing sequence information in recommendation tasks.

% The core idea of existing LLM4Rec models is to transform item interaction sequences into text and provide them as prompts \cite{10.1145/3626772.3657690} to LLMs, enabling the models to perform the recommendation task in a language generation framework. 
% Existing LLM4Rec models have adopted this approach, integrating CF-SRec to leverage collaborative knowledge, and have shown promising recommendation performance. 
Despite the current practice of training and evaluating LLM4Rec models under a sequential recommendation scenario, we found that whether these models understand the sequential information inherent in users' item interaction sequences has been largely overlooked.
% LLM4Rec models seem to struggle with fully understanding and utilizing sequence information in sequential recommendation tasks.
Hence, in this paper, we begin by conducting a series of experiments that are designed to investigate the ability of existing LLM4Rec models in understanding users' item interaction sequences (Sec.~\ref{sec: sequence exp}). More precisely, we compare four different LLM4Rec models (i.e., TALLRec, LLaRA, CoLLM, and A-LLMRec) with a CF-SRec model (i.e., SASRec). Our experimental results reveal surprising findings as follows:
% an important consideration remains. CF-SRec models are effective in recommendation tasks because of their ability to capture users' dynamic preferences that evolve over time. Yet, it has not been thoroughly validated whether LLM4Rec methods possess a similar capacity to understand and utilize sequential information. 
% Specifically, when they receive item interaction sequences in textual form, it is still an open question whether they can effectively capture the dynamic patterns embedded within those sequences. 
% This leads us to pose the following key question for further exploration.
% \textbf{Can LLMs that are inherently built for linguistic tasks truly adapt to understanding the sequential information inherent item interaction sequences and the nuances of sequential recommendation?} 
% Furthermore, is leveraging a pre-trained CF-SRec to enhance
% LLMs with a pre-trained CF-SRec helpful
% \textbf{Do enhancements using collaborative knowledge from pre-trained CF-SRec \cite{zhang2023collm,10.1145/3626772.3657690, 10.1145/3637528.3671931} genuinely enable LLMs to leverage sequential information in recommendation tasks effectively?} 
% Our short answer is that existing LLM4Rec models seem to struggle with fully understanding and utilizing sequence information in sequential recommendation tasks.

% Do LLMs, which excel in understanding linguistic tasks, truly comprehend user interaction sequences and sequential recommendation tasks, which exhibit characteristics distinct from linguistic tasks? Furthermore, despite efforts to enhance LLMs' ability to capture interaction patterns by incorporating collaborative knowledge from pre-trained collaborative filtering models, have these approaches sufficiently enabled LLMs to utilize sequential information in recommendation tasks?

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=1.0\linewidth]{imgs/original_shuffle_perform_drop.pdf}
%     % \vspace{-2ex}
%     \caption
%     {Performance comparison between original and shuffled sequences. Circles represent NDCG@10, squares represent NDCG@20, and $\leftarrow$ indicates performance drop.}
%     \label{fig: shuffle_perform_drop}
%     \vspace{-4ex}
% \end{figure}

% Sequential recommendation fundamentally relies on understanding users' shifting preferences and accurately capturing their intentions. The effectiveness of LLM4Rec hinges on whether LLMs can fully grasp and exploit the sequential nature of recommendation data.
% To address these pivotal questions, this paper explores the limitations and potential of LLMs in sequential recommendation. Building on these concerns, this paper seeks to explore these questions, and our experimental results reveal surprising findings as follows:

% \textcolor{red}{(CY: 이 아래 부분 좋은데, surprising findings라고 이야기를 했기 때문에 뭐가 surprising한지가 납득이 되도록 써야합니다. 그러려면, [sequence를 잘 이해하는 LLM4Rec이라면 어떠어떠한 상황에서 어떻게 동작해야 한다 (가설) -> 그걸 확인하기위해 이러이러한 실험을 세팅해서 진행했다 -> 그런데 이러이러한 observation이 있었다] 이런식으로 flow를 구성해서 써주세요. 어차피 Intro가 좀 짧아서 약간 길어져도 괜찮아요.)}

% Our experimental results reveal surprising findings that challenge conventional assumptions and provide new insights into this emerging field.
% The essence of sequential recommendation lies in tracking users' shifting preferences and accurately capturing their intentions for effective recommendations. Unlocking the full capabilities of LLM4Rec depends on whether LLMs can truly process and leverage sequential information effectively. However, as discussed earlier, \textbf{can LLMs, developed for language tasks, fully grasp the sequential nature of recommendation data?} Building on these concerns, this paper seeks to explore these questions, and our experimental results reveal surprising findings as follows:
% To address these pivotal questions,
\begin{enumerate}[leftmargin=0.5cm]
    \item \textbf{Training and Inference with Shuffled Sequences:} 
    {Randomly shuffling the order of items within a user's item interaction sequence breaks the sequential dependencies among items \cite{woolridge2021sequence, 10.1145/3640457.3688195}. Hence, we hypothesize that the performance of models that understand the sequential information inherent in a user's item interaction sequence would deteriorate when the sequence is disrupted. To investigate this, we conduct experiments under two different settings.
    First, we compare the performance of models that have been trained on the original sequences (i.e., non-shuffled sequences) and those trained on randomly shuffled sequences when they are evaluated on the same test sequences in which sequential information is present (i.e., non-shuffled test sequences). 
    Surprisingly, the performance of LLM4Rec models, even after being trained on shuffled sequences, is similar to the case when they are trained on the original sequences\footnote{{To address a potential concern that the moderate performance drop in LLM4Rec may be due to the prevalence of textual information over sequential data, we would like to emphasize that both types of information are indeed essential, as demonstrated in  Sec.~\ref{sec: case study}.
    % Disrupting the sequential information in the data via shuffling allows us to assess how effectively the models, particularly LLM4Rec, capture and utilize it, thereby highlighting the importance of sequential information in conjunction with textual data.
    On the other hand, disrupting the sequential information in users' item interaction sequences via shuffling still allows us to assess how effectively the models, particularly LLM4Rec, capture the sequential information, highlighting the importance of sequential information alongside textual data.}}, while SASRec trained with shuffled sequences shows significant performance degradation when tested on the original sequences. 
    Second, we perform inferences using shuffled sequences on the models that have been trained using the original sequences. Similar to our observations in the first experiment, we observed that LLM4Rec models exhibit minimal performance decline even when the sequences are shuffled during inference, while SASRec showed significant performance degradation. 
    % This indicates that LLM4Rec models do not fully capture the sequential information during inference. 
    In summary, these observations indicate that LLM4Rec models do not fully capture sequential information both during training and inference.}

    
    % \item \textbf{Shuffle Inference (Section~\ref{sec: shuffled inference}):} Randomly shuffling the order of items within a user's item interaction sequence breaks the sequential dependencies among items \cite{woolridge2021sequence, 10.1145/3640457.3688195}.
    % Hence, we hypothesize that the performance of models that understand the sequential information inherent in a user's item interaction sequence would deteriorate when the sequence is disrupted. 
    % % That is, shuffling users' item interaction sequences should lead to a decline in recommendation performance of LLM4Rec that well captures the sequential information.
    % To investigate this, we perform inferences using shuffled sequences on the models that have been trained using the original sequences.
    % % We train the models using the original item interaction sequences, and then perform inference on shuffled sequences. 
    % Surprisingly, we observed that LLM4Rec models exhibit a minimal performance decline even when the sequences are shuffled during inference, while SASRec showed significant performance degradation. This indicates that LLM4Rec models do not fully capture the sequential information during inference.
    % % in generating recommendations.
    
    % \item \textbf{Shuffled Training (Section~\ref{sec: shuffled training}):} 
    % % In addition to shuffling sequences only during inference while the models have been trained on the original sequences, in this experiment, we train models on shuffled sequences and perform inference on the original sequences. 
    % Next, we hypothesize that the performance of models trained on sequences in which meaningful sequential information is removed would deteriorate when evaluated on sequences in which sequential information exists. 
    % To investigate this, we compare the performance of models that have been trained on the original sequences and those trained on randomly shuffled sequences, when they are evaluated on the same test sequences in which sequential information is valid.
    % Surprisingly, the performance of LLM4Rec models, even after being trained on shuffled sequences, is similar to the case when they are trained on the original sequences, while SASRec trained with shuffled sequences shows significant performance degradation. This indicates again that LLM4Rec models do not fully capture sequential information during training.
    % % , as their performance remain unchanged regardless of whether they are trained on the original or shuffled sequences.
    % % Based on the same hypothesis that LLM4Rec models 
    % % we train models on shuffled sequences and compare the performance between when  on the original sequences We hypothesize that 
    
    % % \textcolor{blue}{Training a model on shuffled sequences introduces different sequential dependencies compared to training on the original sequence, leading to variations in recommendation performance when evaluated on the original sequence.} Therefore, to analyze the sequential understanding of LLMs in recommendation tasks, we train the models using shuffled sequences \textcolor{blue}{and evaluate their recommendation performance on the original sequence, comparing it to the performance of models trained and inferred on the original sequences}. 
    % % The results show that, after training on shuffled sequences, LLM4Rec achieves similar performance when inferring with original sequences as it does when both trained and inferred on original sequences. 
    % % \textcolor{blue}{These findings suggest that LLM4Rec does not fully utilize sequential information, as its performance remains unchanged regardless of whether it is trained on the original or shuffled sequence.}
    
    \item \textbf{Representation Similarity:} 
    In LLM4Rec models as well as in SASRec, representations of users are generated based on their item interaction sequences. Hence, we hypothesize that user representations obtained from a model that successfully captures sequential information in users' interaction sequences would greatly change when the input sequences are disrupted. To investigate this, we compute the similarity between user representations obtained based on the original sequences and those obtained based on shuffled sequences during inference.
    Surprisingly, the similarity is much higher for LLM4Rec models compared with that for SASRec, meaning that shuffling users' item interaction sequences has minimal impact on user representations of LLM4Rec models.
    % LLM4Rec models generate highly similar representations regardless of whether the sequences are shuffled or not. 
    This indicates again that LLM4Rec models do not fully capture sequential information.
    % \textcolor{blue}{Since user representation is generated based on the input user interaction sequence, hence any change in the input sequence should result in differences in the user representation. Therefore, by comparing user representations generated from the original sequence and the shuffled sequence, we can examine how the model captures and utilizes the input sequences.} 
    % \textcolor{blue}{The results show that,} the similarity of encoded user representation between the original sequence and shuffled sequence is relatively high on LLM4Rec compared to CF-SRec \textcolor{blue}{, which indicates that LLM4Rec insufficiently leverage user sequences when generating user representations.}
\end{enumerate}

% Our above findings raise concerns about the ability of existing LLM4Rec models in adequately incorporating sequential information for recommendation tasks, which eventually leads to suboptimal recommendation performance. 
% Moreover, from the above experiments, we found that achieving true sequential understanding in LLMs requires an approach beyond simply encoding user interaction sequences as textual inputs or directly using 
Motivated by the above findings, we propose a simple yet effective LLM-based sequential recommender, called \proposed, a method that enhances the integration of sequential information into LLMs. 
The main idea is to distill the user representations extracted from a pre-trained CF-SRec model into LLMs, so as to endow LLMs with the sequence understanding capability of the CF-SRec model.
% By distilling user representations, encoded from item interaction sequences by a pre-trained CF-SRec, our method enables LLMs to leverage the sequence understanding capability of CF-SRec models.
Notably, our method achieves cost-efficient integration of sequential information without requiring fine-tuning of either the pre-trained CF-SRec models or the LLMs, effectively addressing the limitations of the existing LLM4Rec framework.
Our main contributions are summarized as follows:


\begin{table*}[h]
\small
% \caption[Caption for LOF]{An example of prompt for next item title generation for LLM4Rec models (i.e., TALLRec, LLaRA, CoLLM, and A-LLMRec). Note that LLaRA uses a hybrid prompting method that uses only text or with item embeddings. }
\caption[Caption for LOF]{An example  prompt for various LLM4Rec models (Next Item Title Generation approach).
% (i.e., TALLRec, LLaRA, CoLLM, and A-LLMRec). 
}
\vspace{-2ex}
\resizebox{0.99\linewidth}{!}{
\begin{tabular}{c|l|l|l}
\toprule
 \multicolumn{1}{c|}{}  & \multicolumn{1}{c|}{(a) \textbf{TALLRec}} & \multicolumn{1}{c|}{(b) \textbf{LLaRA}} & \multicolumn{1}{c}{(c) \textbf{CoLLM/A-LLMRec}} \\ \midrule\midrule
\multirow{3}{*}{\textbf{Inputs}} & This user has made a series of purchases& This user has made a series of purchases in the & This is user representation from recommendation models: \\ 
  & in the following order: (History Item List: & following order: (History Item List: [No.\# Time:& \textcolor{red}{[User Representation]}, and this user has made a series of purchases in\\  
 \multirow{2}{*}{$(\mathcal{P}^{u})$} &[No.\#  Time: YYYY/MM/DD Title: \textcolor{magenta}{Item Title}]).  & YYYY/MM/DD Title: \textcolor{magenta}{Item Title}, \textcolor{blue}{Item Embedding}]). & the following order: (History Item List: [No.\# Time: YYYY/\\
  &Choose one "Title" to recommend for this user&Choose one "Title" to recommend for this user to & MM/DD Title: \textcolor{magenta}{Item Title}, \textcolor{blue}{Item Embedding}]). Choose one "Title" to\\
 & to buy next from the following item "Title" set:& buy next from the following item "Title" set:  & recommend for this user to buy next from the following\\
  &  [Candidate \textcolor{magenta}{Item Titles}]. & [Candidate \textcolor{magenta}{Item Titles}, \textcolor{blue}{Item Embeddings}].&  item "Title" set: [Candidate \textcolor{magenta}{Item Titles}, \textcolor{blue}{Item Embeddings}].\\ \midrule
  
\textbf{Outputs}  &\multirow{2}{*}{Item Title} &\multirow{2}{*}{Item Title} &\multirow{2}{*}{Item Title} \\
$(\text{Text}(i_{n_u+1}^{(u)}))$  & & & \\ \bottomrule

\end{tabular}}
\label{tab title generation prompt}
% \vspace{-1.5ex}
\end{table*}

% \begin{table*}[h]
% \small
% \caption[Caption for LOF]{An example of prompt for next item retrieval task for LLM4Rec models (i.e., TALLRec, LLaRA, CoLLM, and A-LLMRec).}
% \resizebox{1.0\linewidth}{!}{
% \begin{tabular}{c|l|l|l}
% \toprule
%  \multicolumn{1}{c|}{}  & \multicolumn{1}{c|}{\textbf{TALLRec/LLaRA}} & \multicolumn{1}{c|}{\textbf{LLaRA}} & \multicolumn{1}{c}{\textbf{CoLLM/A-LLMRec}} \\ \midrule\midrule
% \multirow{5}{*}{\textbf{User}} & This user has made a series of purchases& This user has made a series of purchases in the & This is user representation from recommendation models: \\ 
%   & in the following order: (History Item List: & following order: (History Item List: [No.\# Time:& \textcolor{red}{[UserRep]}, and this user has made a series of purchases in\\  
%   &[No.\#  Time: YYYY/MM/DD Title: \textcolor{magenta}{Item Title}]).  & YYYY/MM/DD Title: \textcolor{magenta}{Item Title}, \textcolor{blue}{Embedding}]). & the following order: (History Item List: [No.\# Time: YYYY/\\
%   &Based on this sequence of purchases, generate & Based on this sequence of purchases, generate & MM/DD Title: \textcolor{magenta}{Item Title}, \textcolor{blue}{Embedding}]). Based on this\\
%  &user representation token: \textcolor{brown}{[UserOut]}. & user representation token: \textcolor{brown}{[UserOut]}. &  sequence of purchases and user representation, generate\\
%   &  & &  user representation token: \textcolor{brown}{[UserOut]}.\\ \midrule

%     \multirow{2}{*}{\textbf{Item}} & The item title is as follows: "Title": \textcolor{magenta}{Item Title}, then & \multicolumn{2}{l}{The item title and item embedding are as follows: "Title": \textcolor{magenta}{Item Title}, \textcolor{blue}{Embedding},} \\
%     &generate item representation token: \textcolor{violet}{[ItemOut]}. & \multicolumn{2}{l}{then generate item representation token: \textcolor{violet}{[ItemOut]}} \\ \bottomrule
% \end{tabular}}
% \label{tab next item retrieval prompt}
% \end{table*}


\begin{table*}[h]
\small
\caption{An example prompt for various LLM4Rec models (Next Item Retrieval approach).
% (i.e., TALLRec, LLaRA, CoLLM, and A-LLMRec).
}
\vspace{-2ex}
\resizebox{0.99\linewidth}{!}{
\begin{tabular}{c|l|l|l}
\toprule
 \multicolumn{1}{c|}{}  & \multicolumn{1}{c|}{(a) \textbf{TALLRec}} & \multicolumn{1}{c|}{(b) \textbf{LLaRA/\proposed~(Ours)}} & \multicolumn{1}{c}{(c) \textbf{CoLLM/A-LLMRec}} \\ \midrule\midrule
\multirow{3}{*}{\textbf{User}} & This user has made a series of purchases& This user has made a series of purchases in the & This is user representation from recommendation models: \\ 
  & in the following order: (History Item List: & following order: (History Item List: [No.\# Time:& \textcolor{red}{[User Representation]}, and this user has made a series of purchases in\\  
  \multirow{2}{*}{$(\mathcal{P}^u_{\mathcal{U}})$}&[No.\#  Time: YYYY/MM/DD Title: \textcolor{magenta}{Item Title}]).  & YYYY/MM/DD Title: \textcolor{magenta}{Item Title}, \textcolor{blue}{Item Embedding}]). & the following order: (History Item List: [No.\# Time: YYYY/\\
  &Based on this sequence of purchases, generate & Based on this sequence of purchases, generate & MM/DD Title: \textcolor{magenta}{Item Title}, \textcolor{blue}{Item Embedding}]). Based on this\\
 &user representation token: \textcolor{brown}{[UserOut]}. & user representation token: \textcolor{brown}{[UserOut]}. &  sequence of purchases and user representation, generate\\
  &  & &  user representation token: \textcolor{brown}{[UserOut]}.\\ \midrule

    \textbf{Item} & The item title is as follows: "Title": \textcolor{magenta}{Item Title}, then & \multicolumn{2}{l}{The item title and item embedding are as follows: "Title": \textcolor{magenta}{Item Title}, \textcolor{blue}{Item Embedding}, then generate item representation} \\
    $(\mathcal{P}^i_{\mathcal{I}})$&generate item representation token: \textcolor{violet}{[ItemOut]}. & \multicolumn{2}{l}{token: \textcolor{violet}{[ItemOut]}} \\ \bottomrule
\end{tabular}}
\label{tab next item retrieval prompt}
\vspace{-1ex}
\end{table*}



\begin{itemize}[leftmargin=0.5cm]
\item We show that existing LLM4Rec models, although specifically designed for sequential recommendation, fail to effectively leverage the sequential information inherent in users' item interaction sequences.
% \item Across various scenarios (e.g., title generation, item retrieval, text-only input, incorporation of collaborative knowledge, and LLM fine-tuning), we show that existing LLM4Rec models fail to comprehend sequence information.
\item We propose a simple and cost-efficient method that enables LLMs to capture the sequential information inherent in users' item interaction sequences for more effective recommendations.
\item {Our extensive experiments show that \proposed~outperforms existing LLM4Rec models by effectively capturing sequential dependencies. Furthermore, the results validate the effectiveness of transferring pre-trained sequential information through distillation method, across various experimental settings.}
\end{itemize}


\section{Do Existing LLM4Rec Models Understand Sequences?}
\label{sec sec2}
% In this section, we present a formal definition of the problem including notations and a detailed task description for CF-SRec and LLM4Rec followed by intense analyses of LLMs' sequence comprehension.



\subsection{Preliminaries}
\label{sec: problem setup}
\subsubsection{Definition of Sequential Recommendation in CF-SRec.}
Let $\mathcal{U} = \{u_1, u_2, \ldots, u_{|\mathcal{U}|}\}$ represent the set of users, and $\mathcal{I} = \{i_1, i_2, \ldots,$ $i_{|\mathcal{I}|}\}$ represent the set of items.
For a user $u \in \mathcal{U}$, $\mathcal{S}_u = (i_1^{(u)}, \ldots, i_t^{(u)},$ $\ldots, i_{n_u}^{(u)})$ denotes the item interaction sequence, where $i_t^{(u)} \in \mathcal{I}$ is the item that $u$ interacted with at time step $t$, and $n_u$ is the length of user $u$'s item interaction sequence.
Given the interaction history $\mathcal{S}_u$ of user $u$, the goal of sequential recommendation is to predict the next item that user $u$ will interact with at time step $n_{u}+1$ as $p(i_{n_u+1}^{(u)}\mid \mathcal{S}_u)$.
% \begin{equation}
% \small
% p(i_{n_u+1}^{(u)}\mid \mathcal{S}_u)
%     \label{Eq sequential recommendation}
% \end{equation}
% \noindent\textbf{Catogorization of Existing LLM4Rec Models. }
\subsubsection{LLM for Sequential Recommendation}

% \smallskip
% \noindent\textbf{Categorization of Existing LLM4Rec Models. }
Note that existing LLM4Rec models can be largely categorized into the following two approaches: \textit{Generative Approach (}\textit{i.e., Next Item Title Generation}) \cite{10.1145/3637528.3671931,10.1145/3626772.3657690, hou2024large} and \textit{Retrieval Approach} (\textit{i.e., Next Item Retrieval}) \cite{geng2022recommendation, li2023e4srec}. 
% {
% While existing models have been proposed based on one of the two approaches, for a more comprehensive analysis, we adopt both approaches to each LLM4Rec baseline. 
% % To this end, we adapt the LLM4Rec to the alternative approach, allowing for a broader evaluation of their sequence understanding capabilities.
% }
In the Next Item Title Generation approach, a user's item interaction sequence and a list of candidate items are provided as input prompts to LLMs after which the LLMs \textit{generate} one of the candidate item titles as a recommendation. Meanwhile, the Next Item Retrieval approach extracts user and candidate item representations from the LLMs and \textit{retrieves} one of the candidate items whose similarity with the user representation is the highest.
Note that although existing LLM4Rec models have typically been proposed based on only one of the two approaches, we apply both approaches to each LLM4Rec baseline to conduct more comprehensive analyses on whether existing LLM4Rec models understand the sequential information inherent in users' item interaction sequences.
% although both can be adopted with minor modifications. In this work, to conduct more comprehensive analyses on whether existing LLM4Rec models understand the sequential information inherent in users' item interaction sequences, we apply both approaches to each LLM4Rec baseline. 
% In this study, we experiments with both approaches to evaluate whether existing LLM4Rec models can understand the sequential information inherent in users' item interaction sequence.

\smallskip
\noindent\textbf{1) Generative Approach (Next Item Title Generation).}
LLM4Rec models designed for Next Item Title Generation perform recommendations using instruction-based prompts as shown in Table~\ref{tab title generation prompt}. For a user $u$, the candidate item set of user $u$ is represented as $\mathcal{C}_u = \left\{i^{(u)}_{n_u+1}\right\} \cup \mathcal{N}_u$, where $\mathcal{N}_u = \text{RandomSample}(\mathcal{I}\backslash (\mathcal{S}_u \cup \left\{i^{(u)}_{n_u+1}\right\}) , m)$ is a negative item set for user $u$, and $m = |\mathcal{N}_u|$ is the number of negative items.
{Based on the item interaction sequence of user $u$, i.e., $\mathcal{S}_u$, and the candidate item set, i.e., $\mathcal{C}_u$, we write the input prompt $\mathcal{P}^u$ following the format shown in Table~\ref{tab title generation prompt}. 
Note that we introduce two projection layers, i.e., $f_{\mathcal{I}}$ and $f_{\mathcal{U}}$, each of which is used to project item embeddings and user representations extracted from a pre-trained CF-SRec into LLMs, respectively.
% "Item Title," "Item Embedding," and "User Representation."
% $f_{\mathcal{I}}$ and $f_{\mathcal{U}}$, which are used to project item embeddings and user representations extracted from a pre-trained CF-SRec into LLMs. 
Following the completed prompts shown in Table~\ref{tab title generation prompt}, LLMs are trained for the sequential recommendation task through the Next Item Title Generation approach.
Note that TALLRec, LLaRA, and CoLLM use LoRA \cite{hu2022lora} to finetune LLMs aiming at learning the sequential recommendation task, while A-LLMRec only trains $f_{\mathcal{I}}$ and $f_{\mathcal{U}}$ without finetuning the LLMs with LoRA.
Please refer to the Appendix~\ref{app: next item title generation}.} for more details on the projection layers as well as prompt construction.

% The textual data for the interacted items and candidate items are defined as $\mathcal{T}_{\mathcal{S}_u} = \left\{ \text{Text}(i) \mid i \in \mathcal{S}_u \right\}$ and $\mathcal{T}_{\mathcal{C}_u} = \left\{ \text{Text}(i) \mid i \in \mathcal{C}_u \right\}$, respectively, where $\text{Text}(i)$ represents textual information (e.g., title or description) of item $i$. 

% For models such as LLaRA \cite{10.1145/3626772.3657690}, CoLLM \cite{zhang2023collm}, and A-LLMRec \cite{10.1145/3637528.3671931}, which incorporate item embeddings and user representations from a pre-trained CF-SRec, we use $\mathbf{E} \in \mathbb{R}^{|\mathcal{I}| \times d}$ to denote the item embedding matrix of the pre-trained CF-SRec, where $d$ is the hidden dimension of the embeddings. 
% We also define $f_{\mathcal{I}}$ and $f_{\mathcal{U}}$ as the item and user projection layers used in LLaRA, CoLLM, and A-LLMRec (includes Stage-1 item encoder of A-LLMRec), respectively. 
% The embeddings of items in the item interaction sequence $\mathcal{S}_u$ are defined as $\mathbf{E}_{\mathcal{S}_u} = \left\{ f_{\mathcal{I}}(\mathbf{E}_i) \mid i \in \mathcal{S}_u \right\}$, while the embeddings for the candidate items $\mathcal{C}_u$ are represented as $\mathbf{E}_{\mathcal{C}_u} = \left\{ f_{\mathcal{I}}(\mathbf{E}_i) \mid i \in \mathcal{C}_u \right\}${, where $f_{\mathcal{I}}(\mathbf{E_i})\in\mathbb{R}^{d_{llm}}$ and $d_{llm}$ denotes the token embedding dimension of LLM}. 
% % Furthermore, the user representation is defined as $\mathbf{O}_u = f_{\mathcal{U}}(\text{CF-SRec}(\mathcal{S}_u))$, where $\text{CF-SRec}(\mathcal{S}_u)$ represents the user $u$'s representation obtained from the item interaction sequence $\mathcal{S}_u$ using a pre-trained CF-SRec. 
% {Furthermore, the user representation is defined as $\mathbf{Z}_u = f_{\mathcal{U}}(\text{CF-SRec}(\mathcal{S}_u)) \in \mathbb{R}^{d_{llm}}$, where $\text{CF-SRec}(\mathcal{S}_u)$ represents the user $u$'s representation obtained from the item interaction sequence $\mathcal{S}_u$ using a pre-trained CF-SRec.} 
% Then, using the prompts shown in Table~\ref{tab title generation prompt}, LLMs are trained for the sequential recommendation task through the Next Item Title Generation approach as follows:
% \begin{equation}
%     p(\text{Text}(i_{n_u+1}^{(u)}) \mid \mathcal{P}^{u}, \mathcal{D}^{u})
%     \label{Eq LLM4Rec Title generation}
% \end{equation}
% where $\mathcal{P}^u$ is the input prompt for user $u$, and $D^u$ represents the set of interacted and candidate item titles and their corresponding embeddings used in Table \ref{tab title generation prompt} for user $u$ as follows:
% \begin{align}
%     \mathcal{D}^{u} = \begin{cases}
%         \mathcal{T}_{\mathcal{S}_u}, \mathcal{T}_{\mathcal{C}_u} & \text{TALLRec}\\
%         \mathcal{T}_{\mathcal{S}_u}, \mathcal{T}_{\mathcal{C}_u}, \mathbf{E}_{\mathcal{S}_u}, \mathbf{E}_{\mathcal{C}_u} & \text{LLaRA} \\
%         \mathcal{T}_{\mathcal{S}_u}, \mathcal{T}_{\mathcal{C}_u},\mathbf{E}_{\mathcal{S}_u}, \mathbf{E}_{\mathcal{C}_u}, \mathbf{Z}_u & \text{CoLLM/A-LLMRec}
%     \end{cases}
%     \label{Eq LLM4Rec Title generation Input}
% \end{align}


% \begin{table*}[t]

% \caption{Performance of various models when trained with original sequences and shuffled sequences (Next Item Retrieval approach). Change ratio indicates the performance change of `Shuffle' compared with `Original'.
% % The ratio of performance change is reported in bracket.
% }
% \vspace{-2ex}
% \resizebox{0.82\linewidth}{!}{
% \begin{tabular}{c|c||cccc||cccc||cccc}
% \toprule
% \multirow{2}{*}{} & \multirow{2}{*}{} & \multicolumn{4}{c||}{Scientific} & \multicolumn{4}{c||}{Electronics}& \multicolumn{4}{c}{CDs}\\ \cmidrule{3-14}
%   & & \multicolumn{1}{c|}{NDCG@10} &  \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}  & HR@20  & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}  & HR@20 & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}  & HR@20  \\ \midrule\midrule

% \multirow{3}{*}{SASRec} & Original    & \multicolumn{1}{c|}{0.2918}  & \multicolumn{1}{c|}{0.3245}  & \multicolumn{1}{c|}{0.4691} & 0.5987& \multicolumn{1}{c|}{0.2267}  & \multicolumn{1}{c|}{0.2606}  & \multicolumn{1}{c|}{0.3749} & 0.5096 & \multicolumn{1}{c|}{0.3451}  & \multicolumn{1}{c|}{0.3795}  & \multicolumn{1}{c|}{0.5278} & 0.6635 \\ 
% & \multirow{1}{*}{Shuffle}    & \multicolumn{1}{c|}{0.2688}  & \multicolumn{1}{c|}{0.3014}  & \multicolumn{1}{c|}{0.4399} & 0.5652 & \multicolumn{1}{c|}{0.2104}  & \multicolumn{1}{c|}{0.2397}  & \multicolumn{1}{c|}{0.3547} & 0.4798 & \multicolumn{1}{c|}{0.3312} & \multicolumn{1}{c|}{0.3632} & \multicolumn{1}{c|}{0.5036} & 0.6340 \\ \cmidrule{2-14}
% & \multirow{1}{*}{Change ratio} & \multicolumn{1}{c|}{(-7.88\%)}  & \multicolumn{1}{c|}{(-7.12\%)}  & \multicolumn{1}{c|}{(-6.22\%)} & (-5.60\%) & \multicolumn{1}{c|}{(-7.19\%)}  & \multicolumn{1}{c|}{(-8.02\%)}  & \multicolumn{1}{c|}{(-5.39\%)} & (-5.85\%) & \multicolumn{1}{c|}{(-4.03\%)} & \multicolumn{1}{c|}{(-4.30\%)} & \multicolumn{1}{c|}{(-4.59\%)} & (-4.45\%)\\ 
% \midrule\midrule

% \multirow{3}{*}{TALLRec} & Original  & \multicolumn{1}{c|}{0.2585}  & \multicolumn{1}{c|}{0.3048}  & \multicolumn{1}{c|}{0.4574} & 0.6276 & \multicolumn{1}{c|}{0.2249}  & \multicolumn{1}{c|}{0.2670}  & \multicolumn{1}{c|}{0.3802} & 0.5476& \multicolumn{1}{c|}{0.3100}  & \multicolumn{1}{c|}{0.3493}  & \multicolumn{1}{c|}{0.5052} & 0.6633 \\ 
% &\multirow{1}{*}{Shuffle}    & \multicolumn{1}{c|}{0.2579}  & \multicolumn{1}{c|}{0.3011}  & \multicolumn{1}{c|}{0.4559} & 0.6267 & \multicolumn{1}{c|}{0.2223}  & \multicolumn{1}{c|}{0.2642}  & \multicolumn{1}{c|}{0.3752} & 0.5421& \multicolumn{1}{c|}{0.3003}  & \multicolumn{1}{c|}{0.3407}  & \multicolumn{1}{c|}{0.5001} & 0.6599 \\ \cmidrule{2-14}
% & \multirow{1}{*}{Change ratio} & \multicolumn{1}{c|}{(-0.23\%)}  & \multicolumn{1}{c|}{(-1.21\%)}  & \multicolumn{1}{c|}{(-0.33\%)} & (-0.14\%) & \multicolumn{1}{c|}{(-1.16\%)}  & \multicolumn{1}{c|}{(-1.05\%)}  & \multicolumn{1}{c|}{(-1.32\%)} & (-1.00\%) & \multicolumn{1}{c|}{(-3.13\%)} & \multicolumn{1}{c|}{(-2.46\%)} & \multicolumn{1}{c|}{(-1.01\%)} & (-0.51\%)\\

% \midrule\midrule
% \multirow{3}{*}{LLaRA} & Original       & \multicolumn{1}{c|}{0.2844}  & \multicolumn{1}{c|}{0.3265}  & \multicolumn{1}{c|}{0.4993} & 0.6658 & \multicolumn{1}{c|}{0.2048}  & \multicolumn{1}{c|}{0.2454}  & \multicolumn{1}{c|}{0.3428} & 0.5048& \multicolumn{1}{c|}{0.2464}  & \multicolumn{1}{c|}{0.2951}  & \multicolumn{1}{c|}{0.4665} & 0.6590 \\ 
% & \multirow{1}{*}{Shuffle}      & \multicolumn{1}{c|}{0.2921}  & \multicolumn{1}{c|}{0.3345}  & \multicolumn{1}{c|}{0.5077} & 0.6757 & \multicolumn{1}{c|}{0.2079}  & \multicolumn{1}{c|}{0.2474}  & \multicolumn{1}{c|}{0.3432} & 0.5009& \multicolumn{1}{c|}{0.2695}        & \multicolumn{1}{c|}{0.3106}        & \multicolumn{1}{c|}{0.4608}       & 0.6423  \\ \cmidrule{2-14}
% & \multirow{1}{*}{Change ratio} & \multicolumn{1}{c|}{(+2.71\%)}  & \multicolumn{1}{c|}{(+2.45\%)}  & \multicolumn{1}{c|}{(+1.68\%)} & (+1.49\%) & \multicolumn{1}{c|}{(+1.51\%)}  & \multicolumn{1}{c|}{(+0.81\%)}  & \multicolumn{1}{c|}{(+0.12\%)} & (-0.77\%) & \multicolumn{1}{c|}{(+9.38\%)} & \multicolumn{1}{c|}{(+5.25\%)} & \multicolumn{1}{c|}{(-1.22\%)} & (-2.53\%)\\

% \midrule\midrule
% \multirow{3}{*}{CoLLM} & Original   & \multicolumn{1}{c|}{0.3111}  & \multicolumn{1}{c|}{0.3489}  & \multicolumn{1}{c|}{0.5182} & 0.6676 & \multicolumn{1}{c|}{0.2565}  & \multicolumn{1}{c|}{0.2946}  & \multicolumn{1}{c|}{0.4256} & 0.5773& \multicolumn{1}{c|}{0.3145}  & \multicolumn{1}{c|}{0.3556}  & \multicolumn{1}{c|}{0.5316} & 0.6944 \\ 
% & \multirow{1}{*}{Shuffle}     & \multicolumn{1}{c|}{0.3181}  & \multicolumn{1}{c|}{0.3545}  & \multicolumn{1}{c|}{0.5301} & 0.6741 & \multicolumn{1}{c|}{0.2636}  & \multicolumn{1}{c|}{0.2999}  & \multicolumn{1}{c|}{0.4218} & 0.5663& \multicolumn{1}{c|}{0.3143}  & \multicolumn{1}{c|}{0.3558}  & \multicolumn{1}{c|}{0.5306} & 0.6947 \\ \cmidrule{2-14}
% & \multirow{1}{*}{Change ratio} & \multicolumn{1}{c|}{(+2.25\%)}  & \multicolumn{1}{c|}{(+1.61\%)}  & \multicolumn{1}{c|}{(+2.30\%)} & (+0.97\%) & \multicolumn{1}{c|}{(+2.77\%)}  & \multicolumn{1}{c|}{(+1.80\%)}  & \multicolumn{1}{c|}{(-0.89\%)} & (-1.91\%) & \multicolumn{1}{c|}{(-0.29\%)} & \multicolumn{1}{c|}{(+0.03\%)} & \multicolumn{1}{c|}{(+0.30\%)} & (+0.75\%)\\

% \midrule\midrule
% \multirow{3}{*}{A-LLMRec} & Original & \multicolumn{1}{c|}{0.2875}  & \multicolumn{1}{c|}{0.3246}  & \multicolumn{1}{c|}{0.4957} & 0.6427 & \multicolumn{1}{c|}{0.2791}  & \multicolumn{1}{c|}{0.3173}  & \multicolumn{1}{c|}{0.4622} & 0.6137& \multicolumn{1}{c|}{0.3119}  & \multicolumn{1}{c|}{0.3526}  & \multicolumn{1}{c|}{0.5300} & 0.6914 \\ 
% &\multirow{1}{*}{Shuffle}         & \multicolumn{1}{c|}{0.2973}  & \multicolumn{1}{c|}{0.3348}  & \multicolumn{1}{c|}{0.5080} & 0.6558& \multicolumn{1}{c|}{0.2741}  & \multicolumn{1}{c|}{0.3113}  & \multicolumn{1}{c|}{0.4560} & 0.6037 & \multicolumn{1}{c|}{0.3078}  & \multicolumn{1}{c|}{0.3471}  & \multicolumn{1}{c|}{0.5272} & 0.6887 \\ \cmidrule{2-14}
% & \multirow{1}{*}{Change ratio} & \multicolumn{1}{c|}{(+3.41\%)}  & \multicolumn{1}{c|}{(+3.14\%)}  & \multicolumn{1}{c|}{(+2.48\%)} & (+2.04\%) & \multicolumn{1}{c|}{(-1.79\%)}  & \multicolumn{1}{c|}{(-1.89\%)}  & \multicolumn{1}{c|}{(-1.31\%)} & (-1.63\%) & \multicolumn{1}{c|}{(-1.31\%)} & \multicolumn{1}{c|}{(-1.56\%)} & \multicolumn{1}{c|}{(-0.53\%)} & (-0.39\%)\\

% \midrule\midrule
% \multirow{3}{*}{\proposed} & Original  & \multicolumn{1}{c|}{0.3388}  & \multicolumn{1}{c|}{0.3758}  & \multicolumn{1}{c|}{0.5532} & 0.6992 & \multicolumn{1}{c|}{0.3044}  & \multicolumn{1}{c|}{0.3424}  & \multicolumn{1}{c|}{0.4885} & 0.6385& \multicolumn{1}{c|}{0.3809}  & \multicolumn{1}{c|}{0.4158}  & \multicolumn{1}{c|}{0.6085} & 0.7461 \\ 
% & \multirow{1}{*}{Shuffle}    & \multicolumn{1}{c|}{0.3224}  & \multicolumn{1}{c|}{0.3591}  & \multicolumn{1}{c|}{0.5287} & 0.6739& \multicolumn{1}{c|}{0.2838}  & \multicolumn{1}{c|}{0.3210}  & \multicolumn{1}{c|}{0.4552} & 0.6030 & \multicolumn{1}{c|}{0.3614}  & \multicolumn{1}{c|}{0.3981}  & \multicolumn{1}{c|}{0.5807} & 0.7111 \\ \cmidrule{2-14}
% & \multirow{1}{*}{Change ratio}  & \multicolumn{1}{c|}{(-4.84\%)}  & \multicolumn{1}{c|}{(-4.44\%)}  & \multicolumn{1}{c|}{(-4.29\%)} & (-3.62\%) & \multicolumn{1}{c|}{(-6.77\%)}  & \multicolumn{1}{c|}{(-6.25\%)}  & \multicolumn{1}{c|}{(-6.82\%)} & (-5.56\%) & \multicolumn{1}{c|}{(-5.12\%)} & \multicolumn{1}{c|}{(-4.26\%)} & \multicolumn{1}{c|}{(-4.57\%)} & (-4.69\%) \\

% \bottomrule
% \end{tabular}}
% \label{tab: shuffle train}
% \vspace{-2ex}
% \end{table*}

% \begin{table*}[]

% \caption{Performance of various models when trained with original sequences and shuffled sequences (Next Item Retrieval approach). Change ratio indicates the performance change of `Shuffle' compared with `Original'.
% % The ratio of performance change is reported in bracket.
% }
% \vspace{-2ex}
% \resizebox{0.95\linewidth}{!}{

% \begin{tabular}{c|c||ccc||ccc||ccc||ccc||ccc||ccc}
% \toprule
% \multirow{2}{*}{Dataset}            & \multirow{2}{*}{Metric} & \multicolumn{3}{c|}{SASRec}                                                 & \multicolumn{3}{c||}{TALLRec}                                                & \multicolumn{3}{c||}{LLaRA}                                                  & \multicolumn{3}{c||}{CoLLM}                                                  & \multicolumn{3}{c||}{A-LLMRec}                                               & \multicolumn{3}{c}{\proposed}                                               \\ \cmidrule{3-20} 
%      &                   & \multicolumn{1}{c|}{Original} & \multicolumn{1}{c|}{Shuffle} & Change ratio & \multicolumn{1}{c|}{Original} & \multicolumn{1}{c|}{Shuffle} & Change ratio & \multicolumn{1}{c|}{Original} & \multicolumn{1}{c|}{Shuffle} & Change ratio & \multicolumn{1}{c|}{Original} & \multicolumn{1}{c|}{Shuffle} & Change ratio & \multicolumn{1}{c|}{Original} & \multicolumn{1}{c|}{Shuffle} & Change ratio & \multicolumn{1}{c|}{Original} & \multicolumn{1}{c|}{Shuffle} & Change ratio \\ \midrule\midrule
% \multirow{2}{*}{Scientific}  & NDCG@10           & \multicolumn{1}{c|}{0.2918}         & \multicolumn{1}{c|}{0.2688}        &   (-7.88\%)     & \multicolumn{1}{c|}{0.2585}         & \multicolumn{1}{c|}{0.2579}        &         (-0.23\%) & \multicolumn{1}{c|}{0.2844}         &  \multicolumn{1}{c|}{0.2921}        &   (+2.71\%)      & \multicolumn{1}{c|}{0.3111}         & \multicolumn{1}{c|}{0.3181}        &     (+2.25\%)   & \multicolumn{1}{c|}{0.2875}         & \multicolumn{1}{c|}{0.2973}        &  (+3.41\%)  & \multicolumn{1}{c|}{0.3388}         & \multicolumn{1}{c|}{0.3224}        &     (-4.84\%)    \\ \cmidrule{2-20} 
%      & NDCG@20           & \multicolumn{1}{c|}{0.3245}         & \multicolumn{1}{c|}{0.3014}        &   (-7.12\%)     & \multicolumn{1}{c|}{0.3048}         & \multicolumn{1}{c|}{0.3011}        &    (-1.21\%)     & \multicolumn{1}{c|}{0.3265}         & \multicolumn{1}{c|}{0.3345}        &      (+2.45\%)  & \multicolumn{1}{c|}{0.3489}         & \multicolumn{1}{c|}{0.3545}        &    (+1.61\%)    & \multicolumn{1}{c|}{0.3246}         & \multicolumn{1}{c|}{0.3348}        &    (+3.14\%)    & \multicolumn{1}{c|}{0.3758}         & \multicolumn{1}{c|}{0.3591}        &       (-4.44\%)  \\ \midrule\midrule
% \multirow{2}{*}{Electronics} & NDCG@10           & \multicolumn{1}{c|}{0.2267}         & \multicolumn{1}{c|}{0.2104}        &     (-7.19\%)   & \multicolumn{1}{c|}{0.2249}         & \multicolumn{1}{c|}{0.2223}        &   (-1.16\%) & \multicolumn{1}{c|}{0.2048}         & \multicolumn{1}{c|}{0.2079}        &   (+1.51\%)     & \multicolumn{1}{c|}{0.2565}         & \multicolumn{1}{c|}{0.2636}        &    (+2.77\%)    & \multicolumn{1}{c|}{0.2791}         & \multicolumn{1}{c|}{0.2741}        &    (-1.79\%)   & \multicolumn{1}{c|}{0.3044}         & \multicolumn{1}{c|}{0.2838}        &    (-6.77\%)     \\ \cmidrule{2-20} 
%      & NDCG@20           & \multicolumn{1}{c|}{0.2606}         & \multicolumn{1}{c|}{0.2397}        &    (-8.02\%)     & \multicolumn{1}{c|}{0.2670}         & \multicolumn{1}{c|}{0.2642}        &   (-1.05\%)    & \multicolumn{1}{c|}{0.2454}         & \multicolumn{1}{c|}{0.2474}        &     (+0.81\%)   & \multicolumn{1}{c|}{0.2946}         & \multicolumn{1}{c|}{0.2999}        &    (+1.80\%)     & \multicolumn{1}{c|}{0.3173}         & \multicolumn{1}{c|}{0.3113}        &   (-1.89\%)     & \multicolumn{1}{c|}{0.3424}         & \multicolumn{1}{c|}{0.3210}        &       (-6.25\%)  \\ \midrule\midrule
% \multirow{2}{*}{CDs}         & NDCG@10           & \multicolumn{1}{c|}{0.3451}         & \multicolumn{1}{c|}{0.3312}        &     (-4.03\%)   & \multicolumn{1}{c|}{0.3100}         & \multicolumn{1}{c|}{0.3003}        &   (-3.13\%) & \multicolumn{1}{c|}{0.2464}         & \multicolumn{1}{c|}{0.2695}        &   (+9.38\%)      & \multicolumn{1}{c|}{0.3145}         & \multicolumn{1}{c|}{0.3143}        &      (-0.29\%)  & \multicolumn{1}{c|}{0.3119}         & \multicolumn{1}{c|}{0.3078}        &   (-1.31\%)  & \multicolumn{1}{c|}{0.3809}         & \multicolumn{1}{c|}{0.3614}        &    (-5.16\%)   \\ \cmidrule{2-20} 
%      & NDCG@20           & \multicolumn{1}{c|}{0.3795}         & \multicolumn{1}{c|}{0.3632}        &   (-4.03\%)       & \multicolumn{1}{c|}{0.3493}         & \multicolumn{1}{c|}{0.3407}        &    (-2.46\%)    & \multicolumn{1}{c|}{0.2951}         & \multicolumn{1}{c|}{0.3106}        &    (+5.25\%)   & \multicolumn{1}{c|}{0.3556}         & \multicolumn{1}{c|}{0.3558}        &    (+0.03\%)      & \multicolumn{1}{c|}{0.3526}         & \multicolumn{1}{c|}{0.3471}        &    (-1.56\%)      & \multicolumn{1}{c|}{0.4158}         & \multicolumn{1}{c|}{0.3981}        &      (-4.26\%)   \\ \bottomrule
% \end{tabular}}
% \label{tab: shuffle train}
% % \vspace{-2ex}
% \end{table*}




\smallskip
\noindent\textbf{2) Retrieval Approach (Next Item Retrieval).} 
As shown in Table ~\ref{tab next item retrieval prompt}, we use $\mathcal{P}^{u}_{\mathcal{U}}$ and $\mathcal{P}^{i}_{\mathcal{I}}$ to denote prompts for users and items, respectively.    
% As the user and item representations are In the Next Item Retrieval approach, 
% LLMs generate the user/item representation on the special token [UserOut] and [ItemOut], i.e., the last hidden state associated with the [UserOut] and [ItemOut], respectively, as follows:
Unlike the Next Item Title Generation approach where LLMs directly generate the title of the recommended item, the Next Item Retrieval approach generates item recommendations by computing the recommendation scores between 
user representations and item embeddings.
{More precisely, it introduces learnable tokens, i.e., [UserOut] and [ItemOut], to aggregate information from user interaction sequences and items, respectively. The last hidden states associated with the [UserOut] and [ItemOut] are used as user representations and item embeddings, denoted $\mathbf{h}^{u}_{\mathcal{U}} \in \mathbb{R}^{l_{llm}}$ and $\mathbf{h}^{i}_{\mathcal{I}} \in \mathbb{R}^{l_{llm}}$, respectively, where $d_{llm}$ denotes the token embedding dimension of LLM. 
Please refer to Appendix ~\ref{app: next item retrieval}.} for more details on how the user representations and item embeddings are extracted as well as the prompt construction for compared models.
% More precisely, it introduces learnable tokens, i.e., [UserOut] and [ItemOut], to aggregate information from user interaction sequences and items, respectively, and the last hidden states associated with the [UserOut] and [ItemOut] are used as user representations and item embeddings as follows:

% \begin{align}
%     \mathbf{h}^u_{\mathcal{U}} = \text{LLM}(\mathcal{P}^u_{\mathcal{U}}, \mathcal{D'}^u), \,\,\,\,
%     \mathbf{h}^{i}_{\mathcal{I}} = \text{LLM}(\mathcal{P}^i_{\mathcal{I}},  \mathcal{D'}^i)
%     \label{Eq LLM4Rec Retrieval}
% \end{align}
% where $\mathbf{h}^u_{\mathcal{U}} \in \mathbb{R}^{d_{llm}}$ and $\mathbf{h}^i_{\mathcal{I}}\in \mathbb{R}^{d_{llm}}$ denote the representation of user $u\in\mathcal{U}$ and the embedding of item $i\in\mathcal{C}_u$, 
% {$D'^u$ denotes the set of interacted item titles and their corresponding embeddings for user $u$, while $D'^i$ denotes the item title and its embedding for candidate item $i$, as presented in Table \ref{tab next item retrieval prompt}, as follows:}
% \begin{align}
%     \begin{split}
%     \mathcal{D'}^{u} &= \begin{cases}
%         \mathcal{T}_{\mathcal{S}_u} & \text{TALLRec}\\
%         \mathcal{T}_{\mathcal{S}_u}, \mathbf{E}_{\mathcal{S}_u} & \text{LLaRA} \\
%         \mathcal{T}_{\mathcal{S}_u},\mathbf{E}_{\mathcal{S}_u}, \mathbf{Z}_u & \text{CoLLM/A-LLMRec}
%     \end{cases}\\
%     \mathcal{D'}^{i} &= \begin{cases}
%         \text{Text}(i) & \text{TALLRec}\\
%         \text{Text}(i), f_{\mathcal{I}}(\mathbf{E}_i) & \text{LLaRA/CoLLM/A-LLMRec}
%     \end{cases}
%     \end{split}
%     \label{Eq LLM4Rec Retrieval Input}
% \end{align}
Then, we compute the recommendation score between user $u$ and item $i$ as $s(u,i) = f_{\mathit{item}}(\mathbf{h}^{i}_{\mathcal{I}}) \cdot f_\mathit{user}(\mathbf{h}^u_{\mathcal{U}})^T$, where $f_\mathit{item}$ and $f_\mathit{user}$ are 2-layer MLPs, i.e., {$f_\mathit{item}, f_\mathit{user}:\mathbb{R}^{d_\mathit{llm}} \rightarrow \mathbb{R}^{d'}$}. Finally, the Next Item Retrieval loss is defined as follows:
\begin{equation}
\small
    \mathcal{L}_\text{Retrieval} = -\underset{u\in\mathcal{U}}{\mathbb{E}}[\text{log}\frac{e^{s(u,i^{(u)}_{n_u+1})}}{\sum_{k\in\mathcal{C}_u} e^{s(u,k)}}]
    \label{Eq retrieval}
\end{equation}
All models are trained using the $\mathcal{L}_\text{Retrieval}$ loss. Specifically, the set of MLPs (i.e., $f_{\mathcal{I}}, f_{\mathcal{U}}, f_\mathit{item}, f_\mathit{user}$, and two token embeddings (i.e., $\text{[ItemOut]}, \text{[UserOut]}$) are trained, while the LLM is fine-tuned using the LoRA. In contrast, A-LLMRec does not fine-tune the LLM.

% \textcolor{red}{(CY: loss가 나오는 이유는 기존 next title generation을 위한 모델들을 next item retrieval loss로 튜닝을 한다는 뜻인가요? 이부분 명확하게 해야할것 같아요.)}

% \textcolor{blue}{Note that TALLRec and CoLLM are designed to binary classification (YES/NO) for a target item, while LLaRA and A-LLMRec generate next item title from a provided candidate item set, i.e., Next Item Title Generation approach. To adapt these baselines to the Next Item Retrieval approach, we modified their setup to retrieve the target item from a provided candidate item set using the prompts Table \ref{tab next item retrieval prompt} and Equation \ref{Eq distill}.}
% \textcolor{red}{In the Next Item Retrieval approach, since the LLM4Rec baselines are designed for YES/NO prediction (TALLRec and CoLLM) or Next Item Title Generation (LLaRA and A-LLMRec), thus we adapt them to the Next Item Retrieval approach setting using prompts in Table \ref{tab next item retrieval prompt} and Equation \ref{Eq retrieval} (CY: 이 문장은 문법적으로 틀린데 어디가 틀린지 보고 고쳐서 알려주세요)}.

% Therefore, we train $f_{\mathcal{I}}, f_{\mathcal{U}}, f_\mathit{item}, f_\mathit{user}, \text{[ItemOut]}, \text{[UserOut]}$, and LLMs with LoRA of LLM4Rec baselines using Equation \ref{Eq retrieval} (Note that A-LLMRec does not fine-tune LLMs).

% \vspace{-2ex}
\smallskip
\noindent\textbf{Discussion regarding prompt design. }
It is important to highlight that the prompts in Table~\ref{tab title generation prompt} and Table~\ref{tab next item retrieval prompt} are designed to ensure that LLMs interpret the user interaction history as a sequential process. Specifically, we incorporate both the interaction number and the actual timestamp of each interaction. Additionally, when shuffling the sequence, we only rearrange the item titles and embeddings while keeping the position of interaction number and timestamp unchanged. We considered that this choice is the most effective, as it allows us to maintain the integrity of the chronological order while still testing the model’s ability to generalize across different item sequences.

% \vspace{-1ex}
\subsection{Evaluation Protocol}
In our experiments on LLMs' sequence comprehension, we employed the leave-last-out evaluation method (i.e., next item recommendation task) \cite{kang2018self,sun2019bert4rec,10.1145/3159652.3159656}. For each user, we reserved the last item in their behavior sequence as the test data, used the second-to-last item as the validation set, and utilized the remaining items for training. 
The candidate item set (i.e., test set) for each user in the title generation task is generated by randomly selecting 19 non-interacted items along with 1 positive item following existing studies \cite{zhang2023collm, 10.1145/3637528.3671931}. Similarly, for the next item retrieval task, we randomly select 99 non-interacted items along with 1 positive item as the candidate item set (i.e., test set) for each user. 
% \textcolor{red}{(CY: 앞으로 어떤 실험들을 보여줄건지 overview를 간략히 적어주세요. 그냥 2.3, 2.4, 2.5 이렇게 쭉 나열하면 정리가 안된 느낌이에요.)}



% \vspace{-2.2ex}
\subsection{Preliminary Analysis}
\label{sec: sequence exp}
In this section, we conduct experiments to investigate the ability of LLM4Rec in understanding users’ item interaction sequences by comparing four different LLM4Rec models (i.e., TALLRec, LLaRA, CoLLM, and A-LLMRec)\footnotemark~ with a CF-SRec model (i.e., SASRec). Note that our experiments are designed based on the assumption that randomly shuffling the order of items within a user's item interaction sequence breaks the sequential dependencies among items \cite{10.1145/3640457.3688195, woolridge2021sequence}. More precisely, we conduct the following two experiments: 1) Training (Sec.~\ref{sec: shuffled training}) and Inference (Sec.~\ref{sec: shuffled inference}) with shuffled sequences, and 2) Representation Similarity (Sec.~\ref{sec: Representation Similarity}). In the following, we describe details regarding the experimental setup and experimental results.

% Note that TALLRec and CoLLM are designed to binary classification (YES/NO) for a target item, while LLaRA and A-LLMRec generate next item title from a provided candidate item set, i.e., Next Item Title Generation approach. To adapt these baselines to the Next Item Retrieval approach, we modified their setup to retrieve the target item from a provided candidate item set using the prompts Table \ref{tab next item retrieval prompt} and Equation \ref{Eq distill}.

% \footnotetext{\textcolor{blue}{Note that TALLRec and CoLLM are designed to predict a binary outcome (YES/NO) for a target item. We modified their setup to select the next item from a provided candidate item set.}}

\footnotetext{Note that TALLRec and CoLLM are designed for binary classification (YES/NO) for a target item, while LLaRA and A-LLMRec generate the title of item to be recommended (i.e., Next Item Title Generation approach). To adapt these baselines to the Next Item Retrieval approach, we modified their setup to retrieve the target item from a provided candidate item set by using the prompts in Table \ref{tab next item retrieval prompt} and training with Equation \ref{Eq retrieval}.}
% Additionally, we also modified the prompts in the LLM4Rec baselines to explicitly include item sequence numbering and interaction time as Table \ref{tab title generation prompt}, and Table \ref{tab next item retrieval prompt}, ensuring the sequence order is provided to the LLM. When shuffling occurs, even though the numbering and times of the items are completely different from the original sequence, the LLM still fails to understand the sequence.}
% \noindent\textbf{Note that. }We modified the prompts in LLM4Rec baselines to explicitly include item sequence numbering and interaction time as Table \ref{tab title generation prompt}, and Table \ref{tab next item retrieval prompt}, ensuring the sequence order is provided to the LLM. When shuffling occurs, even though the item numbering and times for the items are completely different from the original sequence, the LLM still fails to understand the sequence.

% \textcolor{blue}{To investigate whether existing LLM4Rec models capture sequential information inherent in users' item interaction sequences, we design based on the findings that random shuffling user interaction sequences breaks the sequential dependencies in sequence datasets \cite{10.1145/3640457.3688195, woolridge2021sequence}, we conducted three experiments: 
% \textbf{1. Shuffled Inference (Section \ref{sec: shuffled inference}):} the performance of models that understand the sequential information inherent in a user's item interaction sequence would deteriorate when the sequence is disrupted
% if LLM4Rec effectively incorporates sequential information, recommendation performance should degrade when the model is inferred using shuffled user interaction sequences, \textbf{2. Shuffled Training (Section \ref{sec: shuffled training}):} training on shuffled sequences should result in different learned sequential information compared to training on original sequences, affecting the variation of recommendation performance, \textbf{Representation Similarity (Section \ref{sec: Representation Similarity}):} since user representations are derived from interaction sequences and encode sequential patterns, variations in input sequences should lead to distinct user representations.


\begin{table}[t]
\caption{Performance (NDCG@10) of various models when trained with original sequences and shuffled sequences (Next Item Retrieval approach). Change ratio indicates the performance change of `Shuffle' compared with `Original'.
% The ratio of performance change is reported in bracket.
}
\vspace{-1ex}
\resizebox{0.9\linewidth}{!}{
\begin{tabular}{c|c||c|c|c}
\toprule
         &  & Scientific & Electronics & CDs    \\ \midrule \midrule
\multirow{3}{*}{SASRec} &Original    & 0.2918  & 0.2267  & 0.3451 \\ 
&\multirow{1}{*}{Shuffle} & 0.2688 & 0.2104 &0.3312\\ \cmidrule{2-5}
&\multirow{1}{*}{Change ratio} &  (-7.88\%) & (-7.19\%) &  (-4.03\%) \\
\midrule \midrule

\multirow{3}{*}{TALLRec} & Original   & 0.2585  & 0.2249 & 0.3100 \\
&\multirow{1}{*}{Shuffle} & 0.2579 & 0.2223  & 0.3003 \\ \cmidrule{2-5}
&\multirow{1}{*}{Change ratio} &  (-0.23\%) & (-1.16\%) &  (-3.13\%) \\
\midrule \midrule

\multirow{3}{*}{LLaRA} & Original     & 0.2844     & 0.2048  & 0.2464 \\ 
&\multirow{1}{*}{Shuffle} & 0.2921 & 0.2079  & 0.2695  \\ \cmidrule{2-5}
&\multirow{1}{*}{Change ratio} & (+2.71\%) & (+1.51\%) & (+9.38\%) \\
\midrule \midrule

\multirow{3}{*}{CoLLM} &Original & 0.3111 & 0.2565   & 0.3152 \\ 
&\multirow{1}{*}{Shuffle} & 0.3181 & 0.2636  & 0.3143  \\ \cmidrule{2-5}
&\multirow{1}{*}{Change ratio} & (+2.25\%) & (+2.77\%) & (-0.29\%) \\
\midrule \midrule

\multirow{3}{*}{A-LLMRec} & Original  & 0.2875  & 0.2791  & 0.3119 \\
&\multirow{1}{*}{Shuffle} & 0.2973  & 0.2741  & 0.3078  \\ \cmidrule{2-5}
&\multirow{1}{*}{Change ratio} & (+3.41\%) & (-1.79\%) & (-1.31\%) \\
\midrule \midrule

\multirow{3}{*}{\proposed} & Original  & 0.3388  & 0.3044  & 0.3809 \\
&\multirow{1}{*}{Shuffle} & 0.3224  & 0.2838  & 0.3614  \\ \cmidrule{2-5}
&\multirow{1}{*}{Change ratio} & (-4.84\%) & (-6.77\%) & (-5.11\%) \\
\bottomrule

\end{tabular}}
\label{tab: shuffle train}
\vspace{-1ex}
\end{table}


\begin{table}[t]
% \caption{Performance comparison and performance change rate (in bracket) of Next Item Title Generation approach between models trained on the original sequence and trained on the shuffled sequence (HR@1).}
\caption{Performance (HR@1) of various models when trained with original sequences and shuffled sequences (Next Item Title Generation approach).
% The ratio of performance change is reported in bracket.
}
\vspace{-1ex}
\resizebox{0.99\linewidth}{!}{
\begin{tabular}{c|c||c|c|c}
\toprule
         &  & Scientific & Electronics & CDs    \\ \midrule \midrule
\multirow{3}{*}{SASRec} &Original    & 0.3171  & 0.2390  & 0.3662 \\ 
&\multirow{1}{*}{Shuffle} & 0.2821 & 0.2158 &0.3386\\ \cmidrule{2-5}
&\multirow{1}{*}{Change ratio} &  (-11.04\%) & (-9.71\%) &  (-7.54\%) \\
\midrule \midrule

\multirow{3}{*}{TALLRec} & Original   & 0.2221  & 0.1787 & 0.2589 \\
&\multirow{1}{*}{Shuffle} & 0.2181 & 0.1815  & 0.2728 \\ \cmidrule{2-5}
&\multirow{1}{*}{Change ratio} &  (-1.81\%) & (+1.57\%) &  (+5.37\%) \\
\midrule \midrule

\multirow{3}{*}{LLaRA} & Original     & 0.3022     & 0.2616  & 0.3142 \\ 
&\multirow{1}{*}{Shuffle} & 0.2996 & 0.2650  & 0.3530  \\ \cmidrule{2-5}
&\multirow{1}{*}{Change ratio} & (-0.86\%) & (+1.30\%) & (+12.35\%) \\
\midrule \midrule

\multirow{3}{*}{CoLLM} &Original & 0.3010 & 0.2616   & 0.3142 \\ 
&\multirow{1}{*}{Shuffle} & 0.3165 & 0.2323  & 0.3763  \\ \cmidrule{2-5}
&\multirow{1}{*}{Change ratio} & (+5.15\%) & (+0.52\%) & (+9.17\%) \\
\midrule \midrule

\multirow{3}{*}{A-LLMRec} & Original  & 0.2804  & 0.2672  & 0.3319 \\
&\multirow{1}{*}{Shuffle} & 0.2796  & 0.2684  & 0.3528  \\ \cmidrule{2-5}
&\multirow{1}{*}{Change ratio} & (-0.29\%) & (+0.45\%) & (+6.30\%) \\
\bottomrule

\end{tabular}}
\label{tab: shuffle train - title generation}
\vspace{-1.5ex}
\end{table}







\subsubsection{\textbf{Shuffled Training}}
\label{sec: shuffled training}
We hypothesize that the performance of models trained on sequences in which meaningful sequential information is removed would deteriorate when evaluated on sequences in which sequential information is present (i.e., non-shuffled test sequences). To investigate this, we compare the performance of models that have been trained on the original sequence $\mathcal{S}_u$ (i.e., non-shuffled sequence) for each user $u$ and those trained on randomly shuffled sequences \cite{woolridge2021sequence}, when they are evaluated on the same non-shuffled test sequences. 
% To investigate the sequence comprehension of LLMs during the training procedure for sequential recommendation tasks, unlike Section \ref{sec: shuffled inference}, we train models on shuffled sequences \cite{woolridge2021sequence}.
% Note that we shuffle the user interaction sequence in every epoch during model training to remove all sequential dependencies that could arise during training, i.e., no identical interaction sequence exists throughout the entire training procedure. After training the models with shuffled sequences, we evaluate their recommendation performance on the original test sequences and compare it with models trained on original sequences using the same test set.
Note that users' item interaction sequences are shuffled only once before training begins, rather than at every epoch, to eliminate unintended augmentation effect \cite{takahagi-shinnou-2023-data}.
% sequential dependencies that could arise during training, similar to augmentation methods \cite{takahagi-shinnou-2023-data}. 
% After training the models with shuffled sequences, we evaluate their recommendation performance on the original test sequences and compare it with models trained on original sequences using the same test set. {If LLM4Rec properly leverages sequential information, training on shuffled sequences would introduce different sequential dependencies compared to training on the original sequences. Consequently, LLM4Rec is expected to generate different recommendation results as the dependencies on target items are changed.}


Table \ref{tab: shuffle train} and  Table \ref{tab: shuffle train - title generation} show the performance of various models when adapted to the Next Item Retrieval approach and the Next Item Title Generation approach, respectively.
We have the following observations:
1) CF-SRec (i.e., SASRec), suffers from substantial performance degradation when the training sequences are shuffled as expected, whereas LLM4Rec models generally exhibit minimal changes in performance. This indicates that LLMs struggle to leverage sequential information, as eliminating original sequential dependencies through shuffling does not significantly impact their performance.
2) Some LLM4Rec models even show improved results despite being trained with shuffled sequences. We conjecture that in some cases random shuffling of interaction sequences during training can introduce short-term co-occurrence patterns that may coincidentally lead to improved performance. Combined with the fact that LLMs struggle to capture long-term dependencies \cite{liu2024blockwise}, we argue that LLM4Rec models struggle to capture the sequential dependencies within the interaction sequence. 
% we conjecture that in some cases random shuffling of interaction sequences during training can introduce short-term co-occurrence patterns that may coincidentally lead to improved performance.
% \textcolor{blue}{Since it is well known that LLMs struggle to capture long-term dependencies \cite{liu2024blockwise}, in some cases random shuffling of interaction sequences during training can introduce short-term co-occurrence patterns that may lead to improved performance. 
% Consequently, this improvement indicates that LLMs do not effectively capture the sequential dependencies within the interaction sequence. 
3) To investigate further on the behavior of models, we plot a test performance curve for each model during training (Figure \ref{fig: performance curve} in {Appendix ~\ref{app: train shuffle}}). Our expectation is that a model that understands the sequence would train more rapidly when trained with the original sequences, as the sequential information inherent in the item interaction sequence is helpful for recommendation. In other words, we expect the ratio of the slopes of the test performance curve (i.e., original vs. shuffled) to be larger for a model that understands the sequence. 
We observe from Figure \ref{fig: performance curve} that while the ratio of SASRec is relatively high, that of LLM4Rec models are close to 1, indicating that LLM4Rec models fail to fully leverage the sequential information inherent in users' item interaction sequences.
% The test performance graph of the LLM4Rec models shows a similar pattern for both original and shuffled sequences throughout training with a small ratio of slopes between original and shuffled sequences, as shown in Figure \ref{fig: performance curve}. This suggests that LLMs do not fully exploit sequential information in the training data.
% \textcolor{red}{ (CY: 한번만 shuffle하는거 아닌가요?)}\textcolor{blue}{Sein: 한번만 shuffle 하는 것 맞습니다. 해당 부분들 수정해두도록 하겠습니다}.
% Due to LLM4Rec fails to effectively comprehend sequences, randomly shuffling the training sequence in every epoch serves as a data augmentation method, enhancing robustness and performance rather than disrupting the model's ability to comprehend sequences.
% Because LLM4Rec methods fail to comprehend sequences effectively, random shuffling of the training sequence appears to induce some positional biases that influence model performance.

% In summary, these findings highlight that, unlike CF-SRec, existing LLM4Rec models fails to effectively capture sequential dependencies inherent in the item interaction sequences, underscoring the need for further advancements in modeling sequential information within LLM4Rec.


% Please add the following required packages to your document preamble:
% \usepackage{multirow}

\vspace{-1ex}
\subsubsection{\textbf{Shuffled Inference}}
\label{sec: shuffled inference}
We hypothesize that the performance of models that understand the sequential information inherent in a user’s item interaction sequence would deteriorate when the sequence is disrupted. To investigate this, we perform inference using shuffled test sequences with the models that have been trained using the original
sequences $\mathcal{S}_u$ (i.e., non-shuffled sequence).
That is, unlike in Sec.~\ref{sec: shuffled training}, we shuffle the test sequences during inference rather than training sequences.
It is important to note that the assumption of this experiment is that models trained with the original sequences indeed capture the sequential information.
% \textcolor{red}{Following, \citet{10.1145/3640457.3688195} which assumes that random shuffling of the order of interaction sequence for each user breaks sequential dependencies between items. (CY: 이 문장 이상함.)}
% Randomly shuffling the order of items within a user's item interaction sequence breaks the sequential dependencies among items \cite{woolridge2021sequence}

% \textcolor{blue}{\citet{10.1145/3640457.3688195} have shown that random shuffling of the interaction sequence of each user breaks the sequential pattern.}
% Hence, we apply random shuffling to test sequences only, while using the original interaction sequence for training models. More specifically, we train the model on the original interaction sequence, $\mathcal{S}_u$ (i.e., non-shuffled sequence).
% Once trained, we evaluate the model on both the original test sequence and a shuffled test sequence, where the shuffled test sequence, the item order is randomized, excluding the target items.
% Once the training is complete, we evaluate the model on both the original test sequence and a shuffled test sequence. In the shuffled test sequence, the item order is randomized, excluding the target items. \textcolor{blue}{If LLM4Rec comprehends sequential information in user interaction sequences, inference on shuffled test sequences should result in a performance drop compared to inference on the original test sequence, as the disruption of sequential patterns caused by shuffling the test sequence negatively affects target item predictions.} 
% \textcolor{red}{(CY: 여기서도 마찬가지로 이렇게 했을때 sequence를 잡는 모델이라면 예상결과가 어떻게 되고 등등의 가설을 적어줘야 이 이후에 이해가 쉽게 됩니다. 그리고, 2.4, 2.5에도 전부다 마찬가지 format으로 적어주세요 (각 섹션의 첫문단은 실험세팅 및 가설, 두번째문단은 결과설명))}
% As shown in Figure \ref{fig: shuffle_perform_drop_titlegen} and \ref{fig: shuffle_perform_drop}, while CF-SRec suffers significant performance degradation on shuffled sequences, LLM4Rec shows relatively stable performance even when sequential patterns are disrupted.

\begin{figure}[t]
    \centering    \includegraphics[width=0.99\linewidth]{imgs/original_shuffle_all.pdf}
    \vspace{-1ex}
    \caption
    {Performance of various models when tested with original sequences and shuffled sequences. (a) Next Item Title Generation approach (HR@1). (b) Next Item Retrieval approach (NDCG@10). "$\leftarrow$" indicates performance drop.}
    \label{fig: original_shuffle_perform_drop_all.pdf}
    \vspace{-1.5ex}
\end{figure}

% \begin{figure}[t]
%     \centering    \includegraphics[width=1.0\linewidth]{imgs/original_shuffle_perform_drop_titlegen.pdf}
%     \vspace{-5ex}
%     \caption
%     {Performance (HR@1) of various models when tested with original sequences and shuffled sequences (Next Item Title Generation approach). $\leftarrow$ indicates performance drop.}
%     \label{fig: shuffle_perform_drop_titlegen}
%     \vspace{-4ex}
% \end{figure}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=1.0\linewidth]{imgs/original_shuffle_perform_drop.pdf}
%     \vspace{-5ex}
%     \caption
%     {Performance (NDCG@10) of various models when tested with original sequences and shuffled sequences (Next Item Retrieval approach). $\leftarrow$ indicates performance drop.}
%     % {Performance comparison of Next Item Retrieval approach between original and shuffled sequences (NDCG@10). $\leftarrow$ indicates performance drop.}
%     \label{fig: shuffle_perform_drop}
%     \vspace{-2ex}
% \end{figure}


% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=0.9\linewidth]{imgs/learning_cur.pdf}
%     \vspace{-4ex}
%     \caption
%     {Test performance curve during training (CDs dataset). The inference points are set at every 10\% of the training progress within each epoch.}
%     \label{fig: performance curve}
%     \vspace{-2ex}
% \end{figure*}

% Figure \ref{fig: shuffle_perform_drop_titlegen} and \ref{fig: shuffle_perform_drop} show the performance of various models when adapted to the Next Item Title Generation approach and the Next Item Retrieval approach, respectively.
{Figure \ref{fig: original_shuffle_perform_drop_all.pdf} (a) and (b) show the performance of various models when adapted to the Next Item Title Generation approach and the Next Item Retrieval approach, respectively.}
% As shown in Figure \ref{fig: shuffle_perform_drop_titlegen} and \ref{fig: shuffle_perform_drop}, comparing performance of the original sequence and the shuffled sequence, 
We have the following observations: 1) When the test sequences are shuffled, CF-SRec (i.e., SASRec) encounters a significant performance degradation as expected, whereas LLM4Rec remains relatively consistent (i.e., all circles except for SASRec are positioned near the $y=x$ in {Figure \ref{fig: original_shuffle_perform_drop_all.pdf} (a) and (b)).}
% Figure \ref{fig: shuffle_perform_drop_titlegen} and \ref{fig: shuffle_perform_drop}).
% Despite recent advancements in LLM4Rec models, such as LLaRA, CoLLM, and A-LLMRec, which incorporate item embeddings and improve upon the capabilities of text-only approaches like TALLRec, LLM4Rec still struggles to capture sequential patterns, as shown in the consistent performance on both original and shuffled sequences. 
This implies that existing LLM4Rec models failed to capture the sequential information contained in the item interaction sequences.
2) Even though CoLLM and A-LLMRec leverage user representations derived from CF-SRec, which is solely trained based on the item interaction sequence, they fail to effectively capture the sequential information. This indicates the need for carefully distilling the user representations extracted from a pre-trained CF-SRec into LLMs.
% \textcolor{red}{We also observe that in the next item title generation task in Figure \ref{fig: shuffle_perform_drop_titlegen}, LLM4Rec shows negligible differences in performance compared to the next item retrieval task in Figure \ref{fig: shuffle_perform_drop}, and in some cases, performance even improves when the sequence is shuffled. This appears to be influenced by certain biases, as the candidate items are provided along with the interaction sequence in the prompt, while simultaneously failing to effectively utilize the sequence information.}
% \textcolor{red}{ (CY: 이 문단 이해가 잘 안되는데, 두 task에서 LLM4Rec 모델들의 성능 자체를 비교한건가요? 일단 두개를 넘나들면서 비교하기가 너무 힘들고 뭘 봐야하는지도 잘 모르겠어요. 추가적으로, 여기서 얻는 insight가 뭐라고 한건지 잘 이해가 안되는데 한글로 한번 적어보세요.)}

% \textcolor{blue}{Figure 2 (Next Item Retrieval) 에서는, LLM4Rec 모델에서도 performance drop 이 약간은 있는 것으로 보이는데 ($\leftarrow$ 가 Figure 2 Amazon Electronics 에서 LLM4Rec 모델에서도 보이기 때문), }

% \textcolor{blue}{반면에 Figure 1 (Next Item Title Generation) 에서는 이런 현상이없기도 하고, Figure 1 Amazon Scientific 에서 CoLLM (보라색)처럼, Shuffle sequence 로 test 한 성능이 더 높은 경우도 존재하는 것이, Next Item Title Generation 에서는 아무래도 Candidate Items 들이 interacted item 과 함꼐 prompt 에 넣어져 제공되어, candidate item 의 position bias 나, interacted item 과 관련된 어떠한 bias 가 생기기 때문에 이런것이다 라는 insight 를 주고 싶었습니다.}

% \textcolor{blue}{하지만, 교수님 말씀을 듣고 생각해보니, Next Item Title Generation 과 Next Item Retrieval 을 비교하는 것이 논문의 목표도 아니고, title generation 에서는 bias 가 있을 수도 있다는 것은, LLM 이 sequence 를 이해한다는 것과 크게 관련은 없는 것 같기에, 해당 내용을 제외해도 괜찮을 것 같습니다.}



\begin{table}[t]
\caption{Cosine similarity between user representations obtained based on original sequences and
those obtained based on shuffled sequences during inference (The models are trained on the original sequences).}
\vspace{-1ex}
\resizebox{0.9\linewidth}{!}{
\begin{tabular}{c||c|c|c|c}
\toprule
         & Movies & Scientific & Electronics & CDs    \\ \midrule\midrule
SASRec   & 0.6535 & 0.7375     & 0.7083      & 0.7454 \\ \midrule
TALLRec  & 0.9731 & 0.9326     & 0.9678      & 0.9570 \\ \midrule
LLaRA    & 0.9639 & 0.9424     & 0.9800      & 0.9624 \\ \midrule
CoLLM    & 0.9067 & 0.9263     & 0.8921      & 0.9526 \\ \midrule
A-LLMRec & 0.8872 & 0.8911     & 0.8623      & 0.8706 \\ \midrule
\proposed & 0.6128 & 0.7852     & 0.7393      & 0.8589 \\ \bottomrule
\end{tabular}}
\label{tab: user similarity}
\vspace{-1.5ex}
\end{table}


\subsubsection{\textbf{Representation Similarity}}
\label{sec: Representation Similarity}
In LLM4Rec models as well as in SASRec, representations of users are generated based on their item interaction sequences. Hence, we hypothesize that the user representations obtained from models that capture sequential information in a user’s item interaction sequence would change when the input sequence is disrupted. To investigate this, we compute the cosine similarity between user representations obtained based on the original sequences and those obtained based on shuffled sequences during inference. 

% Note that as user representations are generated from LLMs in the Next Item Retrieval approach, we 
% In the Next Item Retrieval approach, user representations are generated from LLMs, enabling us to investigate the LLMs' understanding of user behavior based on sequence information.
% In the case of next item retrieval, user representations can be generated from LLMs, allowing us to assess the LLMs' understanding of user behavior based on sequence information. 
% Our analysis focused on evaluating the understanding of sequential information by comparing the cosine similarity between user representations generated from the original sequence and shuffled sequences, using models trained solely on the original sequence. \textcolor{blue}{Since user representations are derived from input user interaction sequences,, any differences in the sequence lead to corresponding differences in the generated representations. When LLM4Rec leverages user interaction sequences, the user representations generated by LLM4Rec should differ between the shuffled and original sequences.}
% \textcolor{red}{(CY: 이 아래 내용에서는 가장 중요한것은 LLM4rec모델들의 similarity가 CF-SRec보다 높다는것이에요. 그 이야기를 먼저 하고 충분히 강조한다음에, 그이후에 부산물로 등등을 이야기 해주세요.)}
As shown in Table \ref{tab: user similarity}, we observe that the similarity is much higher for LLM4Rec models compared with that of CF-SRec, i.e., SASRec, indicating that LLM4Rec models are less effective than CF-SRec in capturing and reflecting changes in users' item interaction sequences.
It is worth noting that among LLM4Rec models, CoLLM and A-LLMRec exhibit relatively low similarity. This is attributed to the fact that they utilize user representations extracted from a pre-trained CF-SRec in their prompts, unlike TALLRec which only uses text, or LLaRA which uses text and item embeddings. 
This implies that incorporating user representations enhances the ability to effectively model sequential information. However, CoLLM and A-LLMRec still exhibit higher similarity values compared to SASRec, and based on the results of previous experiments (i.e., Sec. \ref{sec: shuffled training} and Sec. \ref{sec: shuffled inference}, it is evident that they have yet to fully comprehend the sequential patterns.



% \subsection{Group Consistency}
% \label{sec: Group Consistency}
% To investigate whether there are changes between shuffled and non-shuffled scenarios within the item groups used for recommendation, we divided the items into 20 groups based on interaction frequency. We then examined whether shifts occurred in the recommendation patterns of the models across these groups.
% The items were first sorted by their interaction frequency, and the total number of interactions within each group was distributed equally. As a result, groups with a higher proportion of cold items contain more items, whereas groups with predominantly warm items contain fewer items.
% After computing recommendation logits for all items using each model, we calculated the average group affiliation of the top 10 recommended items for each model to analyze their distribution across the groups.

\section{METHODOLOGY: \proposed}
\label{sec: method}
In this section, we propose ~\proposed, a novel and simplistic LLM4Rec framework designed to enable LLMs to effectively utilize sequential information inherent in users' item interaction sequences. 
It is important to note that among the two prominent approaches for LLM4Rec, we employ the Next Item Retrieval approach (i.e.,~\proposed~is trained with Equation \ref{Eq retrieval}) due to well-known drawbacks of the Next Item Title Generation approach, 
i.e. restrictions on the number of candidate items \cite{10.1145/3637528.3671931} and the existence of position bias with candidate items \cite{hou2024large}.
% i.e., the number of candidate items is constrained  \cite{zhang2023collm, 10.1145/3637528.3671931} and the existence of position bias on the placement of candidate items within the prompt \cite{hou2024large}.
In the following, we explain two additional losses aiming at: (1) distilling the sequential information extracted from a pre-trained CF-SRec to LLMs (Sec. \ref{sec: distill}), and (2) preventing the over-smoothing problem during distillation (Sec. \ref{sec: uniform}).
Figure \ref{fig: framework} shows the overall framework of ~\proposed.


% to ensure a more practical and scalable approach to sequential recommendation
% Since the Next Item Title Generation approach \cite{zhang2023collm, 10.1145/3637528.3671931} is constrained by the limited number of candidate items and position bias on the placement of candidate items within the prompt \cite{hou2024large}, ~\proposed does not employ this approach. Instead, ~\proposed employs the Next Item Retrieval approach for recommendation tasks, ensuring a more practical and scalable approach to sequential recommendation than Next Item Title Generation approach.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.99\linewidth]{imgs/SeqLLM_Framework.pdf}
    \vspace{-1.5ex}
\caption{Overall model architecture of ~\proposed.}
    \label{fig: framework}
    \vspace{-1.5ex}
\end{figure}




% \vspace{-1ex}
\subsection{Distilling Sequential Information}
\label{sec: distill}
User representations from CF-SRec, derived solely from users' item interaction sequences, encapsulate rich sequential information crucial for sequential recommendation tasks. Despite the efforts of CoLLM and A-LLMRec trying to understand the sequential information by incorporating the user representations directly into LLM prompts, we observe that they still fail to do so (as shown in Sec.~\ref{sec sec2}). Therefore, in this paper, we propose a simple alternative approach to effectively incorporating the sequential information extracted from CF-SRec into LLMs. 
The main idea is to distill the sequential knowledge from pre-trained and frozen CF-SRec into LLMs.
% \textcolor{blue}{Recall that we can generate the representation of user $u$, i.e., $\mathbf{h}^u$, from the LLMs based on the user's item interaction sequence, whereas the CF-SRec generates user representation, i.e., $\mathbf{O}^u$, which inherently captures users' sequential behaviors.}
% \textcolor{red}{Given the user interaction sequence $\mathcal{S}_u$ of user $u$, the Next Item Retrieval approach generates the user representations via LLMs as the special token [UserOut].}
% To enhance LLMs' ability to comprehend and utilize sequential patterns in user interaction sequences, we distill the sequential knowledge extracted from a pre-trained, frozen CF-SRec to LLMs. 
More precisely, we simply match the user representation generated by a pre-trained CF-SRec, i.e., {$\mathbf{O}_u = \text{CF-SRec}(\mathcal{S}_u) \in \mathbb{R}^d$}, and that generated by LLMs, i.e., $\mathbf{h}^u$, as follows:
% To enhance LLMs' ability to comprehend and utilize sequential patterns in user interaction sequence, we distill the pure sequential knowledge from pre-trained and frozen CF-SRec by matching user representation from LLMs with those from CF-SRec as follows:
\begin{equation}
\small
    \mathcal{L}_\text{Distill} = \underset{u \in \mathcal{U}}{\mathbb{E}}[\textsf{MSE}(f_\mathit{CF-user}(\mathbf{O}_u), f_\mathit{user}(\mathbf{h}^u_{\mathcal{U}}))]
    \label{Eq distill}
\end{equation}
where $\textsf{MSE}$ is the mean squared error loss and both $f_\mathit{CF-user}$ and $f_\mathit{user}$ are 2-layer MLPs {, i.e., $f_\mathit{CF-user}: \mathbb{R}^d \rightarrow \mathbb{R}^{d'}$ and $f_\mathit{user}: \mathbb{R}^{d_{llm}} \rightarrow \mathbb{R}^{d'}$,} that are trainable.
This simple distillation framework enables LLMs to generate user representations that effectively capture and reflect the sequential information inherent in users' item interaction sequences.
% Note that among those prompts in Table~\ref{tab next item retrieval prompt}, for ~\proposed, we employ the prompts in (b) allowing user representations to be derived from LLMs based on interacted item titles and collaborative information. In Section \textcolor{blue}{exp-prompt refer}, we empirically demonstrate that the results of prompt (b) and prompt (c) are comparable, despite (b) having a more concise prompt length and not explicitly incorporating user representations within the prompt itself.
The prompt used in ~\proposed~ is provided in Table \ref{tab next item retrieval prompt}, where user representations are derived from LLMs based on interacted item titles and collaborative information. {In Appendix \ref{app: prompt study}}, we empirically compare our prompt with another prompt that explicitly incorporates user representations, i.e., CoLLM and A-LLMRec, demonstrating the effectiveness of~\proposed~despite the absence of user representation in the prompt.
Additionally, Appendix \ref{app: contra distillation}, we conducted experiments using a contrastive learning approach as an objective for distillation instead of the MSE loss.


\subsection{Preventing Over-smoothing}
\label{sec: uniform}
% \textcolor{blue}{Simply applying an MSE loss for distillation as in Equation \ref{Eq distill}, can lead to distilled representations being excessively similar, reducing meaningful sequential information. This issue, known as the over-smoothing problem, which not only hinders LLMs from effectively learning sequence information but also, in extreme cases, causes $f_{\text{user}}$ and $f_{\text\mathit\mathit{CF-user}}$ to produce identical outputs \cite{10.1145/3637528.3671931, 10.1145/3627673.3679535}.}
{Simply applying an MSE loss for distillation as in Equation \ref{Eq distill} can lead to the over-smoothing problem, i.e., two representations are highly similar, hindering LLMs from effectively learning sequential information. In extreme cases, $f_{\text{user}}$ and $f_{\mathit{CF-user}}$ could be trained to produce identical outputs \cite{10.1145/3637528.3671931, 10.1145/3627673.3679535}.} To mitigate this over-smoothing problem, we introduce a uniformity loss \cite{wang2020understanding, 10.1145/3627673.3679535, 10.1145/3534678.3539253} as follows:
\begin{equation}
\small
\begin{split}
    \mathcal{L}_\text{Uniform} &= 
    \underset{u \in \mathcal{U}}{\mathbb{E}}[\underset{u' \in \mathcal{U}}{\mathbb{E}} [e^{-2\|f_\mathit{CF-user}(\mathbf{O}_u) - f_\mathit{CF-user}(\mathbf{O}_{u'})\|^2_2}]]\\
    &+ \underset{u \in \mathcal{U}}{\mathbb{E}} [\underset{u' \in \mathcal{U}}{\mathbb{E}} [e^{-2\|f_\mathit{user}(\mathbf{h}^u_{\mathcal{U}}) - f_\mathit{user}(\mathbf{h}^{u'}_{\mathcal{U}})\|^2_2}]]
    \end{split}
    \label{Eq uniform}
\end{equation}
 The uniformity loss $\mathcal{L}_\text{Uniform}$ ensures that user representations of different users are uniformly distributed across the normalized feature space on the hypersphere, preserving both separation and informativeness.
In Appendix \ref{app: over-smoothing}, we measure the pairwise distances between all user representations to validate the effectiveness of $\mathcal{L_{\text{Uniform}}}$ in mitigating the over-smoothing problem.

\smallskip
\noindent\textbf{Final objective. }The final objective of~\proposed~is computed as the sum of the Next Item Retrieval loss (Equation \ref{Eq retrieval}), the distillation loss (Equation \ref{Eq distill}), and the uniformity loss (Equation \ref{Eq uniform}) as follows:
\begin{equation}
\label{eq final}
\small
    \mathcal{L} = \mathcal{L}_\text{Retrieval} + \mathcal{L}_\text{Distill} + \mathcal{L}_\text{Uniform}
\end{equation}
It is important to note that ~\proposed~ does not require any additional training for either the pre-trained CF-SRec or LLMs during its training process. Instead, ~\proposed~ only optimizes a small set of MLP layers (i.e., $f_{\mathcal{I}}, f_\mathit{user}$, $f_\mathit{CF-user}$, and $f_\mathit{item}$) and two LLM tokens (i.e., [UserOut] and [ItemOut]). Therefore, ~\proposed~ achieves faster training and inference time compared to existing LLM4Rec baselines, including TALLRec, LLaRA, CoLLM, and A-LLMRec, results are described in Sec. \ref{exp: time efficiency}. Furthermore, for training efficiency, we only consider the last item in $\mathcal{S}_u$ for each user $u$ to minimize Equation~\ref{eq final} \cite{10.1145/3637528.3671931}. That is, for each user $u$, we predict the last item $i_{n_u}^{(u)}$ given the sequence $(i_1^{(u)}, \ldots, i_t^{(u)}, \ldots, i_{n_u-1}^{(u)})$. 
In Appendix~\ref{app: autoregressive}, we also show the results when considering all items, i.e., auto-regressive learning.


\smallskip
\noindent\textbf{Discussion on the Efficiency of~\proposed. }
Last but not least, unlike existing LLM4Rec models such as TALLRec, LLaRA, and CoLLM, all of which require fine-tuning of LLMs, ~\proposed~eliminates the need for additional training or fine-tuning on either the pre-trained CF-SRec or the LLMs. Despite its simplicity, ~\proposed~ is highly effective in equipping LLMs with the ability to comprehend sequential information, making it lightweight but effective for sequential recommendation tasks.


\section{Experiments}
% \subsection{Experimental Setup}
\noindent\textbf{Datasets.} 
% To evaluate our proposed ~\proposed, 
We conduct experiments on four Amazon datasets \cite{hou2024bridging}, i.e., Movies, Scientific, Electronics, and CDs. Following prior studies \cite{kang2018self, sun2019bert4rec}, we use five-core datasets consisting of users and items with a minimum of five interactions each. The statistics for each dataset after preprocessing are summarized in Table ~\ref{tab dataset} in Appendix ~\ref{app: dataset}.

\smallskip
\noindent\textbf{Baselines.} We compare three groups of models as our baselines: models that use only interaction sequences (CF-SRec: GRU4Rec \cite{hidasi2015session}, BERT4Rec \cite{sun2019bert4rec}, NextItNet \cite{yuan2019simple}, SASRec \cite{kang2018self}), Language Model based models (LM-based: CTRL \cite{li2023ctrl}, RECFORMER \cite{li2023text}), and Large Language Model based models (LLM4Rec: TALLRec \cite{bao2023tallrec}, LLaRA \cite{10.1145/3626772.3657690}, CoLLM \cite{zhang2023collm}, A-LLMRec \cite{10.1145/3637528.3671931}). For fair comparisons, we implemented all LLM4Rec baselines with Next Item Retrieval approach. Details regarding the baselines are provided in Appendix~\ref{app: baseline}.

% \textcolor{red}{ (CY: appendix로 빼기)
% \begin{itemize} [leftmargin=*,itemsep=0pt, topsep=0pt]
%     \item \textbf{GRU4Rec} \cite{hidasi2015session} employs a recurrent neural network (RNN) to capture user behavior sequences for session-based recommendation.
%     \item \textbf{BERT4Rec} \cite{sun2019bert4rec} utilizes bidirectional self-attention mechanisms and a masked item prediction objective to model complex user preferences from interaction sequences.
%     \item \textbf{NextItNet} \cite{yuan2019simple} applies temporal convolutional layers to capture both short-term and long-term user preferences.
%     \item \textbf{SASRec} \cite{kang2018self} is a self-attention based recommender system designed to capture long-term user preference. 
%     \item \textbf{CTRL} \cite{li2023ctrl} initializes the item embeddings of the backbone recommendation models with textual semantic embeddings using the RoBERTa \cite{liu2019roberta} encoding models. And fine-tunes the backbone models for the recommendation task. 
%     \item \textbf{RECFORMER} \cite{li2023text} leverages a Transformer-based framework for sequential recommendation, representing items as sentences by flattening the item title and attributes.
%     \item \textbf{TALLRec} \cite{bao2023tallrec} fine-tunes LLMs for the recommendation task by formulating the recommendation task as a target item title generation task.
%     \item \textbf{LLaRA} \cite{10.1145/3626772.3657690} uses CF-SRec to incorporate behavioral patterns into LLM. To align the behavioral representations from the CF-SRec this model employs a hybrid prompting which is a concatenated form of textual embedding and item representations.
%     \item \textbf{CoLLM} \cite{10.1145/3637528.3671931} integrates the collaborative information as a distinct modality into LLMs by extracting and injecting item embeddings from CF-SRec. 
%     \item \textbf{A-LLMRec} \cite{10.1145/3637528.3671931} enables LLMs to leverage the CF knowledge from CF-SRec and item semantic information through a two-stage learning framework. 
% \end{itemize}
% }





\smallskip
\noindent\textbf{Evaluation Protocol.}
We employ the leave-last-out strategy \cite{kang2018self} for evaluation, where the most recent item in the user interaction sequence is used as the test item, the second most recent item as the validation item, and the remaining sequence for training. To evaluate the performance of sequential recommendation, we add 99 randomly selected non-interacted items to the test set, ensuring that each user's test set consists of one positive item and 99 negative items. Evaluation is conducted using two widely adopted metrics: Normalized Discounted Cumulative Gain (NDCG@N) and Hit Ratio (HR@N), with N set to 10 and 20.


\smallskip
\noindent\textbf{Implementation Details.}
For fair comparisons, we adopt pre-trained LLaMA 3.2 (3B-Instruct) as the backbone LLM for all LLM4Rec baselines (i.e., TALLRec, CoLLM, LLaRA, and A-LLMRec) including~\proposed. 
Similarly, SASRec serves as the pre-trained CF-SRec for CoLLM, LLaRA, A-LLMRec, and ~\proposed. Please refer to the Appendix \ref{app: implementation details} for more details regarding the hyper-parameters and train settings.

% Similarly, SASRec serves as the pre-trained CF-SRec for CoLLM, LLaRA, A-LLMRec, and ~\proposed, with its item embedding dimension fixed to 64 and batch size set to 128.
% For LLM4Rec baselines, including Stage-2 of A-LLMRec, the batch size is 20 for the Movies, Scientific, and CDs datasets, while 16 is used for the Electronics dataset. For Stage-1 of A-LLMRec, the batch size is set to 64.
% When using Intel Gaudi v2, we set the batch size to 4 due to 8-bit quantization constraints.
% All LLM4Rec models are trained for a maximum of 10 epochs, with validation scores evaluated at every 10\% of the training progress within each epoch, where early stop with patience of 10 is applied to prevent over-fitting.
% All models are optimized using Adam with a learning rate 0.0001, and the dimension size of the projected embedding $d'$ is 128.
% and the temperature parameter $\tau$ is 1.0.
% Experiments are conducted using a single NVIDIA GeForce A6000 (48GB) GPU.
% and a single Intel Gaudi v2.

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table*}[t]
\caption{Overall model performance. The best performance is denoted in bold.}
\vspace{-2ex}
\resizebox{0.9\linewidth}{!}{
\begin{tabular}{c|c||cccc||cc||ccccc}
\toprule
\multirow{2}{*}{Dataset} & \multirow{2}{*}{Metric} & \multicolumn{4}{c||}{CF-SRec}                                                           & \multicolumn{2}{c||}{LM-based}                                   & \multicolumn{5}{c}{LLM4Rec}                                                                                                      \\ \cmidrule{3-13} 
&                   & \multicolumn{1}{c|}{GRU4Rec} & \multicolumn{1}{c|}{BERT4Rec} & \multicolumn{1}{c|}{NextItNet} & SASRec & \multicolumn{1}{c|}{CTRL} & RECFORMER & \multicolumn{1}{c|}{TALLRec} & \multicolumn{1}{c|}{LLaRA} & \multicolumn{1}{c|}{CoLLM} & \multicolumn{1}{c|}{A-LLMRec} & \proposed \\ \midrule\midrule
\multirow{4}{*}{Movies} & NDCG@10           & \multicolumn{1}{c|}{0.3152}        & \multicolumn{1}{c|}{0.2959}         & \multicolumn{1}{c|}{0.2538}          & 0.3459 & \multicolumn{1}{c|}{0.2785} &   0.2068  & \multicolumn{1}{c|}{0.1668}        & \multicolumn{1}{c|}{0.1522}      & \multicolumn{1}{c|}{0.3223}      & \multicolumn{1}{c|}{0.3263}         &  \textbf{0.3560} \\ \cline{2-13} 
  & NDCG@20           & \multicolumn{1}{c|}{0.3494}        & \multicolumn{1}{c|}{0.3303}         & \multicolumn{1}{c|}{0.2879}          &  0.3745 & \multicolumn{1}{c|}{0.3099} &    0.2337  & \multicolumn{1}{c|}{0.2126}        & \multicolumn{1}{c|}{0.1944}      & \multicolumn{1}{c|}{0.3577}      & \multicolumn{1}{c|}{0.3629}         & \textbf{0.3924}  \\ \cline{2-13} 
  & HR@10             & \multicolumn{1}{c|}{0.4883}        & \multicolumn{1}{c|}{0.4785}         & \multicolumn{1}{c|}{0.4221}          & 0.5180  & \multicolumn{1}{c|}{0.4264} &    0.3569  & \multicolumn{1}{c|}{0.3234}        & \multicolumn{1}{c|}{0.2914}      & \multicolumn{1}{c|}{0.5089}      & \multicolumn{1}{c|}{0.5127}         & \textbf{0.5569} \\ \cline{2-13} 
  & HR@20             & \multicolumn{1}{c|}{0.6245}        & \multicolumn{1}{c|}{0.6213}         & \multicolumn{1}{c|}{0.5522}          &  0.6310 & \multicolumn{1}{c|}{0.5429} &    0.5264  & \multicolumn{1}{c|}{0.5060}        & \multicolumn{1}{c|}{0.4599}      & \multicolumn{1}{c|}{0.6491}      & \multicolumn{1}{c|}{0.6577}         & \textbf{0.7010} \\ \midrule\midrule
\multirow{4}{*}{Scientific} & NDCG@10           & \multicolumn{1}{c|}{0.2642}        & \multicolumn{1}{c|}{0.2576}         & \multicolumn{1}{c|}{0.2263}& 0.2918 & \multicolumn{1}{c|}{0.2152} &   0.2907    & \multicolumn{1}{c|}{0.2585}        & \multicolumn{1}{c|}{0.2844}      & \multicolumn{1}{c|}{0.3111}      & \multicolumn{1}{c|}{0.2875}         &   \textbf{0.3388}  \\ \cline{2-13} 
  & NDCG@20           & \multicolumn{1}{c|}{0.2974}        & \multicolumn{1}{c|}{0.2913}         & \multicolumn{1}{c|}{0.2657}          &  0.3245  & \multicolumn{1}{c|}{0.2520} &  0.3113  & \multicolumn{1}{c|}{0.3048}        & \multicolumn{1}{c|}{0.3265}      & \multicolumn{1}{c|}{0.3489}      & \multicolumn{1}{c|}{0.3246}         & \textbf{0.3758} \\ \cline{2-13} 
  & HR@10             & \multicolumn{1}{c|}{0.4313}        & \multicolumn{1}{c|}{0.4437}         & \multicolumn{1}{c|}{0.3908}          & 0.4691 & \multicolumn{1}{c|}{0.3520} &    0.4506  & \multicolumn{1}{c|}{0.4574}        & \multicolumn{1}{c|}{0.4993}      & \multicolumn{1}{c|}{0.5182}      & \multicolumn{1}{c|}{0.4957}         & \textbf{0.5532}  \\ \cline{2-13} 
  & HR@20             & \multicolumn{1}{c|}{0.5524}        & \multicolumn{1}{c|}{0.5822}         & \multicolumn{1}{c|}{0.5356}          & 0.5987   & \multicolumn{1}{c|}{0.4882} &    0.5710  & \multicolumn{1}{c|}{0.6276}        & \multicolumn{1}{c|}{0.6658}      & \multicolumn{1}{c|}{0.6676}      & \multicolumn{1}{c|}{0.6427}         & \textbf{0.6992} \\ \midrule\midrule
\multirow{4}{*}{Electronics} & NDCG@10           & \multicolumn{1}{c|}{0.2364}        & \multicolumn{1}{c|}{0.1867}         & \multicolumn{1}{c|}{0.1712}          &   0.2267 & \multicolumn{1}{c|}{0.1680} &  0.2032   & \multicolumn{1}{c|}{0.2249}        & \multicolumn{1}{c|}{0.2048}      & \multicolumn{1}{c|}{0.2565}      & \multicolumn{1}{c|}{0.2791}         & \textbf{0.3044} \\ \cline{2-13} 
  & NDCG@20           & \multicolumn{1}{c|}{0.2743}        & \multicolumn{1}{c|}{0.2172}         & \multicolumn{1}{c|}{0.2069}          &  0.2606 & \multicolumn{1}{c|}{0.2003} &   0.2441  & \multicolumn{1}{c|}{0.2670}        & \multicolumn{1}{c|}{0.2454}      & \multicolumn{1}{c|}{0.2948}      & \multicolumn{1}{c|}{0.3173}         & \textbf{0.3424} \\ \cline{2-13} 
  & HR@10             & \multicolumn{1}{c|}{0.3843}        & \multicolumn{1}{c|}{0.3325}         & \multicolumn{1}{c|}{0.3017}          &  0.3749  & \multicolumn{1}{c|}{0.2861} &    0.3586 & \multicolumn{1}{c|}{0.3802}        & \multicolumn{1}{c|}{0.3441}      & \multicolumn{1}{c|}{0.4236}      & \multicolumn{1}{c|}{0.4622}         & \textbf{0.4885} \\ \cline{2-13} 
  & HR@20             & \multicolumn{1}{c|}{0.5196}        & \multicolumn{1}{c|}{0.4740}         & \multicolumn{1}{c|}{0.4324}          & 0.5096  & \multicolumn{1}{c|}{0.4152} &    0.5213  & \multicolumn{1}{c|}{0.5476}        & \multicolumn{1}{c|}{0.5032}      & \multicolumn{1}{c|}{0.5741}      & \multicolumn{1}{c|}{0.6137}         & \textbf{0.6385} \\ \midrule\midrule
\multirow{4}{*}{CDs} & NDCG@10           & \multicolumn{1}{c|}{0.2155}        & \multicolumn{1}{c|}{0.3019}         & \multicolumn{1}{c|}{0.2207}          &  0.3451  & \multicolumn{1}{c|}{0.2968} &   0.3238   & \multicolumn{1}{c|}{0.3100}        & \multicolumn{1}{c|}{0.2464}      & \multicolumn{1}{c|}{0.3152}      & \multicolumn{1}{c|}{0.3119}         &  \textbf{0.3809}\\ \cline{2-13} 
  & NDCG@20           & \multicolumn{1}{c|}{0.2530}        & \multicolumn{1}{c|}{0.3386}         & \multicolumn{1}{c|}{0.2562}          & 0.3795  & \multicolumn{1}{c|}{0.3316} &    0.3642   & \multicolumn{1}{c|}{0.3493}        & \multicolumn{1}{c|}{0.2951}      & \multicolumn{1}{c|}{0.3557}      & \multicolumn{1}{c|}{0.3526}         & \textbf{0.4158}  \\ \cline{2-13} 
  & HR@10             & \multicolumn{1}{c|}{0.3712}        & \multicolumn{1}{c|}{0.5018}         & \multicolumn{1}{c|}{0.3842}          & 0.5278  & \multicolumn{1}{c|}{0.4574} &     0.5140  & \multicolumn{1}{c|}{0.5052}        & \multicolumn{1}{c|}{0.4665}      & \multicolumn{1}{c|}{0.5290}      & \multicolumn{1}{c|}{0.5300}         & \textbf{0.6085}  \\ \cline{2-13} 
  & HR@20             & \multicolumn{1}{c|}{0.5092}        & \multicolumn{1}{c|}{0.6605}         & \multicolumn{1}{c|}{0.5422}          & 0.6635  & \multicolumn{1}{c|}{0.5957} & 0.6739 & \multicolumn{1}{c|}{0.6633}        & \multicolumn{1}{c|}{0.6590}      & \multicolumn{1}{c|}{0.6895}      & \multicolumn{1}{c|}{0.6914}         & \textbf{0.7461} \\ \bottomrule
\end{tabular}}
\label{tab: overall performance}
% \vspace{-1.5ex}
\end{table*}



% \vspace{-1.5ex}
\subsection{Recommendation Performance Comparison}
\subsubsection{\textbf{Overall performance}}
\label{exp: overall}
Table \ref{tab: overall performance} presents the recommendation performance of ~\proposed~ and baselines on four datasets. From the results, we have the following observations:
1) \proposed~consistently outperforms existing LLM4Rec models. This result highlights the importance of distilling the sequential knowledge extracted from CF-SRec into LLMs.
2) \proposed~ outperforms CF-SRec based and LM-based models, suggesting that the reasoning ability and the pre-trained knowledge of LLMs significantly contribute to recommendation performance.
3) LLM4Rec models that utilize CF-SRec in their framework (i.e., LLaRA, CoLLM, and A-LLMRec) outperform TALLRec while being comparable to their CF-SRec backbone, i.e., SASRec. This indicates that while incorporating the CF knowledge extracted from a pre-trained CF-SRec is somewhat helpful, the lack of sequence understanding ability limits further improvements, even when using the LLMs. 
% This again underscores the importance of sequence understanding in recommendation models.
In summary, these findings emphasize the significance of seamless distillation of the sequential information extracted from a pre-trained CF-SRec into LLMs as in~\proposed.

\subsubsection{\textbf{Transition \& Non-Transition Sequences.}}
\label{sec transition_non-transition}


\begin{figure}[t]
    \centering
    \includegraphics[width=0.99\linewidth]{imgs/transition_plot.pdf}
    \vspace{-1ex}
    \caption
    {Performance with a varying degree of sequential information ("Transition Set" vs. "Non-Transition Set").}
    \label{fig: transition}
    \vspace{-1.5ex}
\end{figure}

To examine how the degree of sequential information contained in users' item interaction sequences influences the model performance, we categorized users based on the degree of sequential transitions in their interaction history\footnote{We count the number of unique transitions occurring between consecutive items, i.e., $i^{(u)}_{t} \rightarrow i^{(u)}_{t+1}$, within the sequence of user $u$, i.e., $\mathcal{S}^u$. Then, we sort users according to the transition score, i.e., $\textsf{t-score}^{u} = (\sum_{t=1}^{n_u-1}Count(i^{(u)}_{t} \rightarrow i^{(u)}_{t+1}))/(n^u-1)$. Users within the top-50\% are assigned to the "Transition Set", while the remaining users were assigned to the "Non-Transition Set." That is, users whose item interaction sequences exhibit sequential information are assigned to the "Transition Set".}.
% For the item interaction sequence of each user $u$, we count the number of transitions occurring between consecutive items, i.e., $i^{(u)}_{t} \rightarrow i^{(u)}_{t+1}$, within each user sequence $\mathcal{S}^u$. 
% Then, we compute the transition score, i.e., $\textsf{t-score}^{u} = (\sum_{t=1}^{n_u-1}Count(i^{(u)}_{t} \rightarrow i^{(u)}_{t+1}))/(n^u-1)$, and categorize users into two groups where those with top 50\% $\textsf{t-score}$ were assigned to the "Transition Set", while the remaining users were assigned to the "Non-Transition Set." That is, the "Transition Set" consist of users whose item interaction sequences exhibit sequential information, while the "Non-Transition Set" consist of users with 
We make the following observations from Figure \ref{fig: transition}. 
1) \proposed~outperforms all baselines, especially in the Transition Set, where sequential information is more abundant. This demonstrates that the distillation of sequence information enables the LLMs to comprehend and utilize sequential information inherent in users' interaction sequences.
% allows the LLM to capture and leverage sequential dependencies. 
2) 
% Comparing the  and Non-Transition Set, 
The performance gap between LLM4Rec baselines and \proposed~is smaller in the Non-Transition Set compared with the Transition Set.
% the, which contains minimal sequential information, but more substantial in the Transition Set. 
This indicates that existing LLM4Rec models lack the capability to effectively capture sequential dependencies among items and further emphasizes the importance of effective sequential modeling.
% This indicates that effective sequential modeling on LLMs is essential for handling sequences with abundant sequential information. 3) In Non-Transition Set, the performance gap between LLM4Rec baselines and \proposed is less significant. Since Non-Transition Set contains minimal sequential structure, 
% This further confirms that LLM4Rec fails to effectively capture sequential dependencies.

% \begin{table*}[t]
% \caption{Ablation studies on the components of~\proposed.}
% \vspace{-2ex}
% \resizebox{0.9\linewidth}{!}{
% \begin{tabular}{c|c|c||cccc||cccc||cccc||cccc}
% \toprule
% \multirow{2}{*}{Row}&\multirow{2}{*}{Ablation} &\multirow{2}{*}{Inference Set}  &\multicolumn{4}{c||}{Movies}& \multicolumn{4}{c||}{Scientific} & \multicolumn{4}{c||}{Electronics}& \multicolumn{4}{c}{CDs}\\ \cmidrule{4-19} 
% & & & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}  & HR@20  & \multicolumn{1}{c|}{NDCG@10} &  \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}  & HR@20  & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}  & HR@20 & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}  & HR@20  \\ \midrule\midrule
                  
% \multirow{3}{*}{(a)}&\multirow{3}{*}{
% \makecell{w.o. $\mathcal{L}_\text{Distill}$, \\$\mathcal{L}_\text{Uniform}$}} & Original  & \multicolumn{1}{c|}{0.3204}  & \multicolumn{1}{c|}{0.3569}  & \multicolumn{1}{c|}{0.5031} & 0.6476 & \multicolumn{1}{c|}{0.3088}  & \multicolumn{1}{c|}{0.3450}  & \multicolumn{1}{c|}{0.5162} & 0.6606& \multicolumn{1}{c|}{0.2659}  & \multicolumn{1}{c|}{0.3066}  & \multicolumn{1}{c|}{0.4427} & 0.6037 & \multicolumn{1}{c|}{0.2278}  & \multicolumn{1}{c|}{0.2701}  & \multicolumn{1}{c|}{0.4048} & 0.5725 \\ 
% & & \multirow{1}{*}{Shuffle} & \multicolumn{1}{c|}{0.3176}  & \multicolumn{1}{c|}{0.3557}  & \multicolumn{1}{c|}{0.4966} & 0.6482 & \multicolumn{1}{c|}{0.3013}  & \multicolumn{1}{c|}{0.3379}  & \multicolumn{1}{c|}{0.5058} & 0.6512 & \multicolumn{1}{c|}{0.2589}  & \multicolumn{1}{c|}{0.2990}  & \multicolumn{1}{c|}{0.4334} & 0.5924 & \multicolumn{1}{c|}{0.2224} & \multicolumn{1}{c|}{0.2649} & \multicolumn{1}{c|}{0.3962} & 0.5697\\ \cmidrule{3-19}
% & &  \multirow{1}{*}{Change ratio} & \multicolumn{1}{c|}{(-0.87\%)}  & \multicolumn{1}{c|}{(-0.34\%)}  & \multicolumn{1}{c|}{(-1.29\%)} & (+0.09\%) & \multicolumn{1}{c|}{(-2.33\%)}  & \multicolumn{1}{c|}{(-2.06\%)}  & \multicolumn{1}{c|}{(-2.01\%)} & (-1.43\%) & \multicolumn{1}{c|}{(-2.63\%)}  & \multicolumn{1}{c|}{(-2.48\%)}  & \multicolumn{1}{c|}{(-2.10\%)} & (-1.87\%) & \multicolumn{1}{c|}{(-2.37\%)} & \multicolumn{1}{c|}{(-1.92\%)} & \multicolumn{1}{c|}{(-2.12\%)} & (-0.49\%)\\ 
% \midrule\midrule

% \multirow{3}{*}{(b)}&\multirow{3}{*}{w.o. $\mathcal{L}_\text{Uniform}$}  &  Original  & \multicolumn{1}{c|}{0.3339}  & \multicolumn{1}{c|}{0.3700}  & \multicolumn{1}{c|}{0.5229} & 0.6654 & \multicolumn{1}{c|}{0.3283}  & \multicolumn{1}{c|}{3653}  & \multicolumn{1}{c|}{0.5421} & 0.6884 & \multicolumn{1}{c|}{0.2895}  & \multicolumn{1}{c|}{0.3285}  & \multicolumn{1}{c|}{0.4665} & 0.6209& \multicolumn{1}{c|}{0.3622}  & \multicolumn{1}{c|}{0.4013}  & \multicolumn{1}{c|}{0.5823} & 0.7371 \\
% & & \multirow{1}{*}{Shuffle}         & \multicolumn{1}{c|}{0.3089}  & \multicolumn{1}{c|}{0.3456}  & \multicolumn{1}{c|}{0.4915} & 0.6328 & \multicolumn{1}{c|}{0.3164}  & \multicolumn{1}{c|}{0.3536}  & \multicolumn{1}{c|}{0.5260} & 0.6686 & \multicolumn{1}{c|}{0.2732}  & \multicolumn{1}{c|}{0.3110}  & \multicolumn{1}{c|}{0.4472} & 0.5976& \multicolumn{1}{c|}{0.3478}  & \multicolumn{1}{c|}{0.3885}  & \multicolumn{1}{c|}{0.5642} & 0.7278 \\ \cmidrule{3-19}
% & & \multirow{1}{*}{Change ratio}    & \multicolumn{1}{c|}{(-7.49\%)}  & \multicolumn{1}{c|}{(-6.59\%)}  & \multicolumn{1}{c|}{(-6.00\%)} & (-4.90\%) & \multicolumn{1}{c|}{(-3.62\%)}  & \multicolumn{1}{c|}{(-3.20\%)}  & \multicolumn{1}{c|}{(-2.97\%)} & (-2.87\%) & \multicolumn{1}{c|}{(-5.63\%)}  & \multicolumn{1}{c|}{(-5.33\%)}  & \multicolumn{1}{c|}{(-4.14\%)} & (-3.75\%) & \multicolumn{1}{c|}{(-3.98\%)} & \multicolumn{1}{c|}{(-3.19\%)} & \multicolumn{1}{c|}{(-3.11\%)} & (-1.26\%)\\
% \midrule\midrule

% \multirow{3}{*}{(c)}& \multirow{3}{*}{\proposed}  &  Original & \multicolumn{1}{c|}{\textbf{0.3560}}  & \multicolumn{1}{c|}{\textbf{0.3924}}  & \multicolumn{1}{c|}{\textbf{0.5569}} & \textbf{0.7010} & \multicolumn{1}{c|}{\textbf{0.3388}}  & \multicolumn{1}{c|}{\textbf{0.3758}}  & \multicolumn{1}{c|}{\textbf{0.5532}} & \textbf{0.6992} & \multicolumn{1}{c|}{\textbf{0.3044}}  & \multicolumn{1}{c|}{\textbf{0.3424}}  & \multicolumn{1}{c|}{\textbf{0.4885}} & \textbf{0.6385} & \multicolumn{1}{c|}{\textbf{0.3809}}  & \multicolumn{1}{c|}{\textbf{0.4158}}  & \multicolumn{1}{c|}{\textbf{0.6085}} & \textbf{0.7461} \\
% & &  \multirow{1}{*}{Shuffle}   & \multicolumn{1}{c|}{0.3263}  & \multicolumn{1}{c|}{0.3624}  & \multicolumn{1}{c|}{0.5188} & 0.6618 & \multicolumn{1}{c|}{0.3224}  & \multicolumn{1}{c|}{0.3591}  & \multicolumn{1}{c|}{0.5287} & 0.6739 & \multicolumn{1}{c|}{0.2838}  & \multicolumn{1}{c|}{0.3210}  & \multicolumn{1}{c|}{0.4552} & 0.6030& \multicolumn{1}{c|}{0.3614}        & \multicolumn{1}{c|}{0.3981}        & \multicolumn{1}{c|}{0.5807}       & 0.7111  \\ \cmidrule{3-19}
% & &  \multirow{1}{*}{Change ratio}    & \multicolumn{1}{c|}{(-8.34\%)}  & \multicolumn{1}{c|}{(-7.65\%)}  & \multicolumn{1}{c|}{(-6.84\%)} & (-5.59\%) & \multicolumn{1}{c|}{(-4.84\%)}  & \multicolumn{1}{c|}{(-4.44\%)}  & \multicolumn{1}{c|}{(-4.43\%)} & (-3.62\%) & \multicolumn{1}{c|}{(-6.77\%)}  & \multicolumn{1}{c|}{(-6.25\%)}  & \multicolumn{1}{c|}{(-6.82\%)} & (-5.56\%) & \multicolumn{1}{c|}{(-5.11\%)} & \multicolumn{1}{c|}{(-4.26\%)} & \multicolumn{1}{c|}{(-4.57\%)} & (-4.69\%)\\


% \bottomrule
% \end{tabular}}
% \vspace{-2.5ex}
% \label{tab: ablation}
% \end{table*}


\begin{table*}[t]
\caption{Ablation studies on the components of~\proposed.}
\vspace{-2ex}
\resizebox{0.99\linewidth}{!}{
\begin{tabular}{c|c|c||cc||cc||cc||cc}
\toprule
\multirow{2}{*}{Row}&\multirow{2}{*}{Ablation} &\multirow{2}{*}{Train Set}  &\multicolumn{2}{c||}{Movies}& \multicolumn{2}{c||}{Scientific} & \multicolumn{2}{c||}{Electronics}& \multicolumn{2}{c}{CDs}\\ \cmidrule{4-11} 
& & & \multicolumn{1}{c|}{NDCG@10} & NDCG@20 & \multicolumn{1}{c|}{NDCG@10} &  NDCG@20 & \multicolumn{1}{c|}{NDCG@10} & NDCG@20 & \multicolumn{1}{c|}{NDCG@10} & NDCG@20   \\ \midrule\midrule
                  
\multirow{3}{*}{(a)}&\multirow{3}{*}{
\makecell{w.o. $\mathcal{L}_\text{Distill}$, \\$\mathcal{L}_\text{Uniform}$}} & Original  & \multicolumn{1}{c|}{0.3204}  & 0.3569   & \multicolumn{1}{c|}{0.3088}  & 0.3450 & \multicolumn{1}{c|}{0.2659}  & 0.3066 & \multicolumn{1}{c|}{0.2278}  & 0.2701  \\ 
& & \multirow{1}{*}{Shuffle} & \multicolumn{1}{c|}{0.3176}  & 0.3557 & \multicolumn{1}{c|}{0.3013}  & 0.3379 & \multicolumn{1}{c|}{0.2589}  & 0.2990   & \multicolumn{1}{c|}{0.2224} & 0.2649 \\ \cmidrule{3-11}
& &  \multirow{1}{*}{Change ratio} & \multicolumn{1}{c|}{(-0.87\%)}  & (-0.34\%)  & \multicolumn{1}{c|}{(-2.33\%)}  & (-2.06\%) & \multicolumn{1}{c|}{(-2.63\%)}  & (-2.48\%) & \multicolumn{1}{c|}{(-2.37\%)} & (-1.92\%)\\ 
\midrule\midrule

\multirow{3}{*}{(b)}&\multirow{3}{*}{w.o. $\mathcal{L}_\text{Uniform}$}  &  Original  & \multicolumn{1}{c|}{0.3339}  & 0.3700  & \multicolumn{1}{c|}{0.3283}  & 0.3653  & \multicolumn{1}{c|}{0.2895}  & 0.3285  & \multicolumn{1}{c|}{0.3622}  & 0.4013 \\
& & \multirow{1}{*}{Shuffle}         & \multicolumn{1}{c|}{0.3089}  & 0.3456 & \multicolumn{1}{c|}{0.3164}  & 0.3536 & \multicolumn{1}{c|}{0.2732}  & 0.3110 & \multicolumn{1}{c|}{0.3478}  & 0.3885 \\ \cmidrule{3-11}
& & \multirow{1}{*}{Change ratio}    & \multicolumn{1}{c|}{(-7.49\%)}  & (-6.59\%) & \multicolumn{1}{c|}{(-3.62\%)}  & (-3.20\%) & \multicolumn{1}{c|}{(-5.63\%)}  & (-5.33\%)  & \multicolumn{1}{c|}{(-3.98\%)} & (-3.19\%)\\
\midrule\midrule

\multirow{3}{*}{(c)}& \multirow{3}{*}{\proposed}  &  Original & \multicolumn{1}{c|}{\textbf{0.3560}}  & \textbf{0.3924} & \multicolumn{1}{c|}{\textbf{0.3388}}  & \textbf{0.3758} & \multicolumn{1}{c|}{\textbf{0.3044}}  & \textbf{0.3424} & \multicolumn{1}{c|}{\textbf{0.3809}}  & \textbf{0.4158} \\
& &  \multirow{1}{*}{Shuffle}   & \multicolumn{1}{c|}{0.3263}  & 0.3624& \multicolumn{1}{c|}{0.3224}  & 0.3591 & \multicolumn{1}{c|}{0.2838}  & 0.3210 & \multicolumn{1}{c|}{0.3614}        & 0.3981 \\ \cmidrule{3-11}
& &  \multirow{1}{*}{Change ratio}    & \multicolumn{1}{c|}{(-8.34\%)}  & (-7.65\%)& \multicolumn{1}{c|}{(-4.84\%)}  & (-4.44\%) & \multicolumn{1}{c|}{(-6.77\%)}  & (-6.25\%) & \multicolumn{1}{c|}{(-5.11\%)} & (-4.26\%)\\


\bottomrule
\end{tabular}}
% \vspace{-1.5ex}
\label{tab: ablation}
\end{table*}


\begin{figure}[t]
    \centering
    \includegraphics[width=0.99\linewidth]{imgs/warmcold_plot.pdf}
    \vspace{-1ex}
    \caption
    {Performance on Warm/Cold item Scenarios.}
    \label{fig: warm cold}
    \vspace{-1.5ex}
\end{figure}

\subsubsection{\textbf{Performance under Warm/Cold Scenarios.}}
% In this section, we conduct experiments to examine how ~\proposed, which is effectively endowed with sequential information, performs in both warm and cold item settings.
In this section, we conduct experiments to examine how ~\proposed~performs in both warm and cold item settings.
Following the experimental setup of A-LLMRec \cite{10.1145/3637528.3671931}, items are labeled as ‘warm’ if they belong to the top 35\% in terms of the number of interactions with users, while those in the bottom 35\% are labeled as ‘cold’ items.
% and separately evaluate warm and cold items in the test set. 
We have the following observations in Figure~\ref{fig: warm cold}: 1)~\proposed~ consistently achieves superior performance in both warm and cold scenarios, benefiting from its ability to capture the sequential information within item interaction sequences. 
Additionally, the performance in the cold setting shows that ~\proposed~ effectively leverages the generalizability of LLMs, utilizing pre-trained knowledge and textual understanding even though there is insufficient collaborative knowledge for cold items.
% Additionally, text comprehension and generalizability of LLMs enhance its effectiveness in cold settings.
2) TALLRec, which relies solely on textual information, performs inferior in warm settings than LLM4Rec baselines (i.e., LLaRA, CoLLM, and A-LLMRec) that incorporate collaborative knowledge from CF-SRec. However, these models still underperform compared to ~\proposed, highlighting the necessity of modeling both collaborative and sequential information for effective LLM-based recommendation. 3) As expected, SASRec particularly struggles for cold items due to its exclusive reliance on the user-item interaction data. In contrast, LLM4Rec models, especially \proposed, leverage item textual information to mitigate the scarcity of interactions.

\subsubsection{\textbf{Performance under Cross-domain Scenarios.}}
\label{sec: cross-domain}
{To further verify the generalizability of ~\proposed, we evaluate ~\proposed~ on the cross-domain scenarios, following the setting of A-LLMRec \cite{10.1145/3637528.3671931}, where the models are evaluated on datasets that have not been used for training. 
{Specifically, we pre-train the models on the Electronic dataset, as it contains the most users and items, and perform evaluations on the Scientific and CDs.}
% Specifically, we pre-train the models on the Scientific dataset and perform evaluations on the Electronics and CDs dataset 
As shown in Table~\ref{tab: cross-domain}, we observe that 
% \textcolor{red}{1)~\proposed~leverages the textual understanding inherent in LLMs to generate information for unseen items, which are lacking in collaborative knowledge, and, through its understanding of sequential information in the source domain, i.e., the Scientific dataset, ~\proposed~generates high-quality user representations, enabling superior performance in cross-domain scenarios. (CY: 있는 그대로의 실험 결과를 먼저 설명하고 그다음에 분석을 해야합니다.)} 
{1)~\proposed~ consistently outperforms all the baselines in the cross-domain scenarios. Leveraging the textual understanding of LLMs, ~\proposed~ extracts 
 textual information from unseen items which lack collaborative information. Additionally, by capturing sequential information from the source data, i.e., Electronics dataset, and aligning it with the textual understanding of LLMs, ~\proposed~generates high-quality user representations, enabling superior performance in cross-domain scenarios.}
2) While LLM4Rec baselines also address the issue of unseen items through LLM's textual understanding, they fail to generate user representations that capture sequential information, resulting in lower performance than ~\proposed. In contrast, CF-SRec struggles with unseen items due to the difficulty of generating collaborative knowledge of items, leading to inferior performance.}


\begin{table}[]
\caption{Performance on cross-domain scenarios (HR@10).}
\vspace{-1ex}
\resizebox{0.95\linewidth}{!}{
\begin{tabular}{c||c|c|c|c|c|c}
\toprule
& SASRec                                 & TALLRec                                & LLaRA                                  & CoLLM                                  & A-LLMRec                               & \proposed                               \\ \hline
Electronics $\rightarrow$ & \multirow{2}{*}{0.1002}                & \multirow{2}{*}{0.1214}                & \multirow{2}{*}{0.1225}                & \multirow{2}{*}{0.1232}                & \multirow{2}{*}{0.1262}                & \multirow{2}{*}{\textbf{0.1310}}                \\ 
Scientific                &                                        &                                        &                                        &                                        &                                        &                                        \\ \midrule\midrule
Electronics $\rightarrow$     & \multirow{2}{*}{0.0974}& \multirow{2}{*}{0.1132} & \multirow{2}{*}{0.1174} & \multirow{2}{*}{0.1152}& \multirow{2}{*}{0.1217}& \multirow{2}{*}{\textbf{0.1369}} \\ 
   CDs &             &                &                 &                &               &            \\ \bottomrule
\end{tabular}}
\label{tab: cross-domain}
\vspace{-1.5ex}
\end{table}

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.85\linewidth]{imgs/warmcold_plot.pdf}
%     \vspace{-4ex}
%     \caption
%     {Performance on Warm/Cold item Scenarios.}
%     \label{fig: warm cold}
%     \vspace{-5ex}
% \end{figure}



% To comprehensively assess the contribution of LLM in ~\proposed, we evaluate recommendation performance under both warm and cold settings. Specifically, in the cold setting, where CF knowledge is limited, we aim to examine the reasoning ability of LLMs in recommendation tasks. 

% warm/cold experiment setting explanation
% Table represents ~ observations.
% If ~\proposed showing superior in cold => non fine-tuning helps to remain the knowledge and reasoning ability of LLMs, while LoRA fine-tuning disrupt those things.

\vspace{-1ex}
\subsection{Ablation Studies}
\label{exp: ablation}
% \subsubsection{Components of ~\proposed}
% \label{exp: component loss}
In this section, we evaluate the contribution of each component~\proposed. To analyze not only the contribution of each component in terms of the final performance but also its impact on the sequence understanding ability, we conduct experiments under the setting described in Sec. \ref{sec: shuffled training}. In other words, we compare the performance of training with the original sequences versus training with shuffled sequences. 
Table \ref{tab: ablation} presents the following observations:
1) When both $\mathcal{L}_\text{Distill}$ and $\mathcal{L}_\text{Uniform}$ are present (i.e., vanilla \proposed~ in row (c)), the model consistently achieves the highest performance on the original sequence due to the benefits of the sequence understanding ability. Furthermore, compared with its variants (i.e., row (c) vs (a,b)), the performance of the vanilla \proposed~drops the most rapidly when shuffling is applied, ensuring that the vanilla \proposed~indeed comprehends and effectively utilizes sequential information. 
2) In the absence of both $\mathcal{L}_\text{Distill}$ and $\mathcal{L}_\text{Uniform}$ (i.e., row (a)), where the sequential knowledge extracted from CF-SRec is not distilled to the LLMs, the model exhibits the lowest performance on the original sequence. Additionally, even when random shuffling is applied, the performance drop is minor. This result suggests that the model lacks sequence understanding capability without $\mathcal{L}_\text{Distill}$ and $\mathcal{L}_\text{Uniform}$. 
3) When only $\mathcal{L}_\text{Uniform}$ is removed, the model suffers from the over-smoothing problem as discussed in Sec. \ref{sec: uniform}, leading to lower performance compared to ~\proposed. However, since $\mathcal{L}_\text{Distill}$ is still present, we observe a significant performance drop when applying random shuffling. This once more indicates that the model is endowed with the sequence understanding ability with 
$\mathcal{L}_\text{Distill}$.

\begin{table}[t]
\caption{Train/Inference time comparison.}
\vspace{-1ex}
\resizebox{0.99\linewidth}{!}{
\begin{tabular}{c|c|c|c|c}
\toprule
 \multirow{2}{*}{}& \multicolumn{2}{c|}{Scientific} &\multicolumn{2}{c}{Electronics} \\ \cmidrule{2-5}
     & \multicolumn{1}{c|}{Train (min/epoch)}       & Inference (min)  & \multicolumn{1}{c|}{Train (min/epoch)} &  Inference (min) \\ \midrule
\midrule
% SASRec                   & \multicolumn{1}{c|}{-}             &   & \multicolumn{1}{c|}{} &    \\ \midrule
TALLRec                  & \multicolumn{1}{c|}{194.43}         &  37.04  & \multicolumn{1}{c|}{236.73} &  29.04 \\ \midrule
LLaRA                    & \multicolumn{1}{c|}{202.20}         &  38.79 & \multicolumn{1}{c|}{241.17} & 30.62 \\ \midrule
CoLLM                    & \multicolumn{1}{c|}{214.12}         &      39.86 & \multicolumn{1}{c|}{251.51} & 32.58\\ \midrule
A-LLMRec                    & \multicolumn{1}{c|}{190.94}         &  35.01 & \multicolumn{1}{c|}{235.02} & 28.14 \\ \midrule\midrule
\proposed                & \multicolumn{1}{c|}{\textbf{185.91}}         &  \textbf{34.17}  & \multicolumn{1}{c|}{\textbf{218.21}} & \textbf{27.57}\\ \bottomrule
\end{tabular}}
\label{tab: train time}
\vspace{-1.5ex}
\end{table}

\smallskip
\noindent\textbf{Remark. }Recall that simply injecting item embeddings or user representations from CF-SRec into LLMs, as done in existing LLM4Rec models, is insufficient for effective sequence understanding as shown in Sec.~\ref{sec: sequence exp}. In contrast, our ablation studies validate the effectiveness of our simple approach of incorporating the sequential knowledge into LLMs.
% , demonstrating that sequential knowledge of CF-SRec can be successfully transferred to LLMs through our distillation framework. 
% Furthermore, \proposed~not only enhances sequence comprehension but also leads to improved recommendation performance, overcoming the limitations of prior LLM4Rec models.

% \vspace{-1ex}
\subsection{Model analysis}

\subsubsection{\textbf{Train/Inference Efficiency.}}
\label{exp: time efficiency}
Note that \proposed~is efficient as it does not require fine-tuning either CF-SRec or the LLM itself. To quantitatively analyze the model efficiency, we compare the training and inference time of ~\proposed~ with LLM4Rec baselines (i.e., TALLRec, LLaRA, CoLLM, and A-LLMRec). Specifically, we measure the training time per epoch and the total inference time on the Scientific and Electronics datasets.
As shown in Table \ref{tab: train time}, \proposed~ achieves significantly faster training and inference times than all baselines. This is mainly because baselines using Parameter-Efficient Fine-Tuning methods such as LoRA require fine-tuning the LLMs, increasing both training and inference time. Furthermore, compared to A-LLMRec, which does not fine-tune the LLM, \proposed~ remains more efficient. This is mainly because A-LLMRec involves two-stage learning, leading to increase training time. Additionally, since A-LLMRec incorporates user representations into its prompts, it requires longer prompts during inference, resulting in higher computational overhead and slower inference speed compared to \proposed. These results highlight the efficiency of \proposed, supporting the model as a more computationally feasible solution for real-world applications for recommendation tasks while maintaining superior recommendation performance.
% As shown in Table \ref{tab: train time}, the training time of ~\proposed~ is faster compared with any other baselines.
% This is because baselines require fine-tuning of the LLM using PEFT methods such as LoRA, which increases the training time. This efficiency advantage reduces the high computational cost associated with LLM training, making ~\proposed~ more feasible for rapid deployment in industrial applications despite demonstrating the highest recommendation performance.



% \subsubsection{\textbf{Effectiveness of Input Prompts.}}
% \label{exp: prompt study}
% Note that rather than explicitly having the user representations in the input prompt, we rely on the [UserOut] token to extract the user representations as shown in (Table \ref{tab next item retrieval prompt} (b)).
% In Table \ref{tab prompt study}, to validate whether its is sufficient, we compare the performance of~\proposed~with and without the explicit user representations.
% % In Table \ref{tab prompt study}, we empirically compare \proposed, using our prompt in Table \ref{tab next item retrieval prompt} with prompt that explicitly incorporates user representations ("With User" in Table \ref{tab prompt study}),  i.e., prompt of CoLLM and A-LLMRec. 
% The results show a comparable performance between the two prompts. This suggests that through Equation \ref{Eq distill}, the sequential information contained in the user representation is effectively transferred to the LLMs, enabling them to understand sequential dependencies using only the user interaction sequence without explicitly incorporating the user representation in the prompt. Furthermore, omitting the user representation and its associated text from the prompt reduces input prompt length, improving training/inference efficiency, which implies the practicality of \proposed's prompt.


% \begin{table}[t]
% \caption{Performance comparison of prompts with/without explicit user representations.}
% \vspace{-2ex}
% \resizebox{0.7\linewidth}{!}{
% \begin{tabular}{c|c||c||c}
% \toprule
% Dataset                      & Metric  & \makecell{With User \\Representations} & \proposed \\ \midrule\midrule
% \multirow{4}{*}{Movies}      & NDCG@10 & \textbf{0.3625}    & 0.3560                   \\ \cline{2-4} 
%                              & NDCG@20 & \textbf{0.4003}    & 0.3924                   \\ \cline{2-4} 
%                              & HR@10   & \textbf{0.5626}    & 0.5569                   \\ \cline{2-4} 
%                              & HR@20   & 0.7004    & \textbf{0.7010}                   \\ \midrule\midrule
% \multirow{4}{*}{Scientific}  & NDCG@10 & 0.3342    & \textbf{0.3388}                   \\ \cline{2-4} 
%                              & NDCG@20 & 0.3733    & \textbf{0.3758}                   \\ \cline{2-4} 
%                              & HR@10   & 0.5516    & \textbf{0.5532}                   \\ \cline{2-4} 
%                              & HR@20   & 0.6976    & \textbf{0.6992}                   \\ \midrule\midrule
% \multirow{4}{*}{Electronics} & NDCG@10 & 0.2924    & \textbf{0.3044}                   \\ \cline{2-4} 
%                              & NDCG@20 & 0.3405    & \textbf{0.3424}                   \\ \cline{2-4} 
%                              & HR@10   & 0.4725    & \textbf{0.4885}                   \\ \cline{2-4} 
%                              & HR@20   & 0.6239    & \textbf{0.6385}                   \\ \bottomrule
% \end{tabular}}
% \label{tab prompt study}
% \end{table}


% \subsubsection{\textbf{Distillation with Contrastive Learning.}}
% \label{exp: contra distillation}
% Recall that we distill sequential information from CF-SRec to LLMs using MSE loss in Equation \ref{Eq distill}. To further investigate the impact of the distillation loss function, we adapt a naive contrastive learning method for sequential information distillation, i.e., Equation \ref{Eq distill-contra}.

% \begin{equation}
%     \mathcal{L}_{\text{Distill-Contrastive}} = -\underset{u \in \mathcal{B}}{\mathbb{E}}\text{log}\frac{e^{s(f_\mathit{user}(\mathbf{h}_{\mathcal{U}}^u),f_\mathit{CF-user}(\mathbf{O}_u))}}{\sum_{k\in\mathcal{B}} e^{s(f_\mathit{user}(\mathbf{h}_{\mathcal{U}}^u),f_\mathit{CF-user}(\mathbf{O}_k))}}
%     \label{Eq distill-contra}
% \end{equation}
% Table \ref{tab contrastive} shows the performance of different distillation loss functions, and we have the following observations: 1) MSE loss (Equation \ref{Eq distill}) consistently outperforms contrastive loss (Equation \ref{Eq distill-contra}) across all datasets, indicating that effective sequential information transfer to LLMs requires more than just aligning overall trends. Instead, explicitly matching fine-grained details in representations plays a crucial role in preserving sequential dependencies. 2) Performance degradation occurs when inference is performed on shuffled sequences regardless of the chosen loss function, indicating that both losses successfully captures the sequential information.
% % These results underscore the importance of distilling sequential information from CF-SRec, as it plays a vital role in enabling LLMs to effectively capture and leverage sequential dependencies.


% \begin{table*}[]
% \caption{Distillation with contrastive learning method}
% \resizebox{1.0\linewidth}{!}{
% \begin{tabular}{c|c||cccc||cccc||cccc}
% \toprule
% \multirow{2}{*}{}            & \multirow{2}{*}{} & \multicolumn{4}{c||}{Movies}                                                                          & \multicolumn{4}{c||}{Scientific}                                                                      & \multicolumn{4}{c}{Electronics}                                                                     \\ \cmidrule{3-14} 
%  &                   & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}   & HR@20   & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}   & HR@20   & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}   & HR@20   \\ \midrule\midrule
% \multirow{3}{*}{Contrastive} & Original          & \multicolumn{1}{c|}{0.3410}  & \multicolumn{1}{c|}{0.3749}  & \multicolumn{1}{c|}{0.5345}  & 0.6687  & \multicolumn{1}{c|}{0.2767}  & \multicolumn{1}{c|}{0.3152}  & \multicolumn{1}{c|}{0.4817}  & 0.6338  & \multicolumn{1}{c|}{0.2553}  & \multicolumn{1}{c|}{0.2935}  & \multicolumn{1}{c|}{0.4277}  & 0.5792  \\  
%  & Shuffle           & \multicolumn{1}{c|}{0.3151}        & \multicolumn{1}{c|}{0.3480}        & \multicolumn{1}{c|}{0.4975}        &  0.6326 & \multicolumn{1}{c|}{0.2638}        & \multicolumn{1}{c|}{0.3021}        & \multicolumn{1}{c|}{0.4650}        &  0.6177  & \multicolumn{1}{c|}{0.2398}        & \multicolumn{1}{c|}{0.2785}        & \multicolumn{1}{c|}{0.4065}        &  0.5608       \\ \cmidrule{2-14} 
%  & Change ratio      & \multicolumn{1}{c|}{(-7.60\%)}        & \multicolumn{1}{c|}{(-7.18\%)}        & \multicolumn{1}{c|}{(-6.92\%)}        &  (-5.40\%)    & \multicolumn{1}{c|}{(-4.66\%)}        & \multicolumn{1}{c|}{(-4.16\%)}        & \multicolumn{1}{c|}{(-3.47\%)}        &  (-2.54\%) & \multicolumn{1}{c|}{(-6.07\%)}        & \multicolumn{1}{c|}{(-5.11\%)}        & \multicolumn{1}{c|}{(-4.96\%)}        &  (-3.18\%)   \\ \midrule\midrule
% \multirow{3}{*}{\proposed}    & Original          & \multicolumn{1}{c|}{0.3560}  & \multicolumn{1}{c|}{0.3924}  & \multicolumn{1}{c|}{0.5569}  & 0.7010  & \multicolumn{1}{c|}{0.3388}  & \multicolumn{1}{c|}{0.3758}  & \multicolumn{1}{c|}{0.5532}  & 0.6992  & \multicolumn{1}{c|}{0.3044}  & \multicolumn{1}{c|}{0.3424}  & \multicolumn{1}{c|}{0.4885}  & 0.6385  \\ 
%  & Shuffle           & \multicolumn{1}{c|}{0.3272}  & \multicolumn{1}{c|}{0.3631}  & \multicolumn{1}{c|}{0.5169}  & 0.6592  & \multicolumn{1}{c|}{0.3232}  & \multicolumn{1}{c|}{0.3605}  & \multicolumn{1}{c|}{0.5336}  & 0.6813  & \multicolumn{1}{c|}{0.2845}  & \multicolumn{1}{c|}{0.3234}  & \multicolumn{1}{c|}{0.4638}  & 0.6184  \\ \cmidrule{2-14} 
%  & Change ratio      & \multicolumn{1}{c|}{(-8.10\%)} & \multicolumn{1}{c|}{(-7.47\%)} & \multicolumn{1}{c|}{(-7.18\%)} & (-5.96\%) & \multicolumn{1}{c|}{(-4.60\%)} & \multicolumn{1}{c|}{(-4.07\%)} & \multicolumn{1}{c|}{(-3.54\%)} & (-2.56\%) & \multicolumn{1}{c|}{(-6.53\%)} & \multicolumn{1}{c|}{(-5.55\%)} & \multicolumn{1}{c|}{(-5.06\%)} & (-3.15\%) \\ \bottomrule
% \end{tabular}}
% \label{tab contrastive}
% \end{table*}


\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{imgs/llm_size_plot.pdf}
    \vspace{-2ex}
    \caption
    {Performance of different sizes of backbone LLMs.}
    \label{fig: llm size}
    % \vspace{-1.5ex}
\end{figure}

\subsubsection{\textbf{Size of LLMs}}
\label{exp: LLM size}
Note that all baseline LLM4Rec models including~\proposed~use LLaMA 3.2 (3B-Instruct) as the backbone LLMs. In this section, to investigate the impact of LLM size on recommendation performance, we replace the backbone with larger LLMs, i.e., LLaMA 3.1 (8B) \cite{llama3modelcard}.
% To examine the impact of the LLM size on recommendation performance, we evaluate models using LLaMA 3.1 (8B) \cite{llama3modelcard}.
We have the following observations in Figure~\ref{fig: llm size}:
1) Replacing the backbone LLMs to larger LLMs greatly enhances the overall performance of LLM4Rec models.
This aligns well with the scaling law of LLMs observed in other domains \cite{kaplan2020scaling}. Moreover, the superior performance of~\proposed~is still valid when the backbone is replaced to larger LLMs. 
2) Surprisingly, \proposed~with the smaller backbone LLMs outperforms the baseline LLM4Rec models with the larger backbone LLMs. This indicates that distilling sequential information is more crucial than merely increasing the LLM size to enhance the overall performance of sequential recommendation, which again highlights the importance of equipping LLMs with sequential knowledge to improve the sequential recommendation capabilities of LLMs.

\vspace{-1ex}
\subsubsection{\textbf{Case Study.}}
\label{sec: case study}
In this section, we conduct a case study on the Electronics dataset to qualitatively validate the benefit of sequential knowledge and LLMs' textual understanding.
% To validate the benefit of leveraging both sequential and textual information, we conduct a case study on the Electronics dataset in Figure~\ref{fig: case study}. 
Figure \ref{fig: case study} shows three cases highlighting the effect of sequential knowledge and textual knowledge on recommendation. The cases are categorized as follows: (a) only~\proposed~provides correct recommendations, (b) LLM4Rec models (i.e., A-LLMRec and~\proposed) provide correct recommendations while SASRec fails, and (c)~\proposed~and SASRec provide correct recommendations while an LLM4Rec (i.e., A-LLMRec) baseline fails.
% The analysis is divided into three cases: (a) only~\proposed~provides correct recommendations, highlighting the importance of both sequential and textual information, (b)~\proposed~and LLM4Rec provide correct recommendations, emphasizing the importance of textual information, and (c)~\proposed~and SASRec provide correct recommendations, demonstrating the importance of sequential information.
% \footnote{For the LLM4Rec baseline, we used A-LLMRec, which demonstrated the highest performance on the Electronics dataset. However, for the selected user sample, all LLM4Rec baselines either consistently provided correct recommendations (c) or failed to provide recommendations (a, b).}
We have the following observations: 1) In case (a), the user's preference shifts from cable-related items to products from "Apple" brand. \proposed~correctly recommends  "Apple Pencil," while SASRec captures the changing preference but fails to recognize the textual information "Apple," leading to a wrong recommendation of an "Amazon Fire 7 Tablet." On the other hand, A-LLMRec, which struggles to capture sequential information, recommends "Audio Cable" based on textual knowledge of "Cable" and "Speaker." This emphasizes the importance of leveraging both sequential and textual information.
2) In case (b), the user focused on "BOSE" brand products. Both \proposed~and A-LLMRec, leveraging textual knowledge, successfully recommended the "BOSE" earbuds, while SASRec, lacking textual information, recommended the "SAMSUNG Galaxy Buds." This highlights the importance of textual knowledge in generating accurate recommendations.
3) In case (c), the user's preference shifts from "Hosa Tech" cables to security camera. \proposed~and SASRec capture this preference shift and provide relevant recommendations, while A-LLMRec recommends another "Hosa Tech" cable ignoring the sequential patterns.
Those cases demonstrate that both textual and sequential information are crucial for accurate recommendations, showcasing the superiority of \proposed~in integrating both for improved performance. We have provided an additional case study in Appendix \ref{app: case study - additional}.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.99\linewidth]{imgs/case_study.pdf}
    \vspace{-1ex}
    \caption
    {Case study on Electronics dataset.}
    \label{fig: case study}
    \vspace{-1.5ex}
\end{figure}
% improves.LLaMA 3.1 (8B) outperforms 
% \textcolor{blue}{To improve clarity, we denote LLaMA 3.2 (3B-Instruct) as (3B) and LLaMA 3.1 (8B) as (8B) throughout this section. As shown in Figure ~\ref{fig: llm size}, larger LLMs, i.e., (8B), achieve superior recommendation performance compared to the smaller LLM, i.e., (3B).
% The performance gains observed in (8B) can be attributed to their enhanced text understanding and model capacity compared to (3B). However, LLM4Rec baselines, which struggle to capture sequential information, still perform worse than ~\proposed, regardless of model size. Furthermore, the comparison between LLM4Rec baselines with ~\proposed~(3B) demonstrates that distilling sequential information is more crucial than merely increasing LLM size for enhancing sequential recommendation performance, again, highlights the importance of equipping LLMs with sequential knowledge to improve LLMs sequential recommendation capabilities.}


% As shown in Table \ref{tab llm size}, larger LLMs achieve superior recommendation performance compared to the smaller LLM LLaMA 3.2 (3B-Instruct) in Table \ref{tab: overall performance}. The performance gains observed in larger LLMs can be attributed to their enhanced text understanding and greater model capacity. However, LLM4Rec baselines, which struggle to capture sequential information, still perform worse than ~\proposed, regardless of model size. Furthermore, the comparison between LLM4Rec baselines with ~\proposed~(3.2) demonstrates that distilling sequential information is more crucial than merely increasing LLM size for enhancing sequential recommendation performance, again, highlights the importance of equipping LLMs with sequential knowledge to improve LLMs sequential recommendation capabilities.



% \begin{table}[]
% \caption{Performance with different backbone LLM sizes (i.e., LLaMA 3.1 (8B) vs. LLaMA 3.2 (3B-Instruct)). 
% \textcolor{blue}{(3B) refers to the model trained with LLaMA 3.2 (3B-Instruct), while (8B) refers to the model trained using LLaMA 3.1 (8B).}}
% % \proposed~(3.2) indicates ~\proposed~ trained using LLaMA 3.2 (3B-Instruct).}
% \resizebox{1.0\linewidth}{!}{
% \begin{tabular}{c|c||c||c||c||c||c||c}
% \toprule
% Dataset &   Metric & TALLRec (8B) & LLaRA (8B)  & CoLLM (8B)  & A-LLMRec (8B) & \proposed~(8B) & \proposed~(3B) \\ \midrule\midrule
% \multirow{4}{*}{Movies}      & NDCG@10 & 0.1673  & 0.1562 & 0.3342 & 0.3347   &\textbf{0.3565}  & 0.3560 \\ \cline{2-8} 
%  & NDCG@20 & 0.2115  & 0.2008 & 0.3685 & 0.3703   & 0.3909  & \textbf{0.3924} \\ \cline{2-8} 
%  & HR@10   & 0.3189  & 0.3048 & 0.5193 & 0.5249   & 0.5500  & \textbf{0.5569} \\ \cline{2-8} 
%  & HR@20   & 0.4906  & 0.4724 & 0.6621 & 0.6708   & 0.6860  &  \textbf{0.7010} \\ \midrule\midrule
% \multirow{4}{*}{Scientific}  & NDCG@10 & 0.2736  & 0.2855 & 0.3120 & 0.2874  & \textbf{0.3560} & 0.3388 \\ \cline{2-8} 
%  & NDCG@20 & 0.3182  & 0.3301 & 0.3496 & 0.3248   & \textbf{0.3911} & 0.3758 \\ \cline{2-8} 
%  & HR@10   & 0.4776  & 0.5053 & 0.5208 & 0.4955   & \textbf{0.5695}  & 0.5532 \\ \cline{2-8} 
%  & HR@20   & 0.6383  & 0.6674 & 0.6645 & 0.6438   & \textbf{0.7081}   & 0.6992 \\ \midrule\midrule
% \multirow{4}{*}{Electronics} & NDCG@10 & 0.2562  & 0.2209 & 0.2773 & 0.2845   & \textbf{0.3136}  & 0.3044\\ \cline{2-8} 
%  & NDCG@20 & 0.2987  & 0.2647 & 0.3152 & 0.3211   & \textbf{0.3528}  & 0.3424 \\ \cline{2-8} 
%  & HR@10   & 0.4266  & 0.3649 & 0.4535 & 0.4710   & \textbf{0.5008}  & 0.4885\\ \cline{2-8} 
%  & HR@20   & 0.5955  & 0.5284 & 0.6035 & 0.6209   & \textbf{0.6559}  & 0.6385\\ \bottomrule
% \end{tabular}}
% \label{tab llm size}
% \end{table}



% \begin{table}[]
% \caption{Autoregressive learning}
% \resizebox{1.0\linewidth}{!}{
% \begin{tabular}{c|c||cccc||cccc}
% \toprule
% \multirow{2}{*}{}         & \multirow{2}{*}{} & \multicolumn{4}{c|}{Scientific}                                                                    & \multicolumn{4}{c}{Electronics}                                                                    \\ \cmidrule{3-10} 
%   &                   & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}  & HR@20  & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}  & HR@20   \\ \midrule\midrule
% \multirow{3}{*}{TALLRec}  & Original          & \multicolumn{1}{c|}{0.2724}  & \multicolumn{1}{c|}{0.3139}  & \multicolumn{1}{c|}{0.4780} & 0.6421 & \multicolumn{1}{c|}{0.2540}  & \multicolumn{1}{c|}{0.2972}  & \multicolumn{1}{c|}{0.4225} & 0.5941  \\ 
%   & Shuffle           & \multicolumn{1}{c|}{0.2647}  & \multicolumn{1}{c|}{0.3065}  & \multicolumn{1}{c|}{0.4668} & 0.6310 & \multicolumn{1}{c|}{0.2453}  & \multicolumn{1}{c|}{0.2902}  & \multicolumn{1}{c|}{0.4118} & 0.5839  \\ \cmidrule{2-10} 
%   & Change ratio      & \multicolumn{1}{c|}{(-2.83\%)}  & \multicolumn{1}{c|}{(-2.36\%)}  & \multicolumn{1}{c|}{(-2.34\%)} & (-1.73\%) & \multicolumn{1}{c|}{(-3.43\%)}  & \multicolumn{1}{c|}{(-2.36\%)}  & \multicolumn{1}{c|}{(-2.53\%)} & (-1.72\%)  \\ \midrule\midrule
% \multirow{3}{*}{LLaRA}    & Original          & \multicolumn{1}{c|}{0.2860}  & \multicolumn{1}{c|}{0.3257}  & \multicolumn{1}{c|}{0.5057} & 0.6789 & \multicolumn{1}{c|}{0.2175}  & \multicolumn{1}{c|}{0.2577}  & \multicolumn{1}{c|}{0.3649} & 0.5250  \\ 
%   & Shuffle           & \multicolumn{1}{c|}{0.2804}  & \multicolumn{1}{c|}{0.3213}  & \multicolumn{1}{c|}{0.4967} & 0.6685 & \multicolumn{1}{c|}{0.2137}  & \multicolumn{1}{c|}{0.2534}  & \multicolumn{1}{c|}{0.3583} & 0.5193  \\ \cmidrule{2-10} 
%   & Change ratio      & \multicolumn{1}{c|}{(-1.96\%)}  & \multicolumn{1}{c|}{(-1.35\%)}  & \multicolumn{1}{c|}{(-1.78\%)} & (-1.53\%) & \multicolumn{1}{c|}{(-1.75\%)}  & \multicolumn{1}{c|}{(-1.67\%)}  & \multicolumn{1}{c|}{(-1.81\%)} & (-1.09\%) \\ \midrule\midrule
% \multirow{3}{*}{CoLLM}    & Original          & \multicolumn{1}{c|}{0.3254}  & \multicolumn{1}{c|}{0.3599}  & \multicolumn{1}{c|}{0.5348} & 0.6710 & \multicolumn{1}{c|}{0.2745}  & \multicolumn{1}{c|}{0.3092}  & \multicolumn{1}{c|}{0.4433} & 0.5817  \\ 
%   & Shuffle           & \multicolumn{1}{c|}{0.3182}  & \multicolumn{1}{c|}{0.3531}  & \multicolumn{1}{c|}{0.5244} & 0.6609 & \multicolumn{1}{c|}{0.2657}  & \multicolumn{1}{c|}{0.3007}  & \multicolumn{1}{c|}{0.4324} & 0.5724  \\ \cmidrule{2-10} 
%   & Change ratio      & \multicolumn{1}{c|}{(-2.21\%)}  & \multicolumn{1}{c|}{(-1.89\%)}  & \multicolumn{1}{c|}{(-1.94\%)} & (-1.51\%) & \multicolumn{1}{c|}{(-3.21\%)}  & \multicolumn{1}{c|}{(-2.75\%)}  & \multicolumn{1}{c|}{(-2.46\%)} & (-1.60\%)  \\ \midrule\midrule
% \multirow{3}{*}{A-LLMRec} & Original          & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}       &        & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}       &         \\
%   & Shuffle           & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}       &        & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}       &         \\ \cmidrule{2-10} 
%   & Change ratio      & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}       &        & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}        & \multicolumn{1}{c|}{}       &         \\ \midrule\midrule
% \multirow{3}{*}{\proposed} & Original          & \multicolumn{1}{c|}{0.3478}  & \multicolumn{1}{c|}{0.3844}  & \multicolumn{1}{c|}{0.5629} & 0.6985 & \multicolumn{1}{c|}{0.3129}  & \multicolumn{1}{c|}{0.3505}  & \multicolumn{1}{c|}{0.4940} & 0.6407  \\ \
%   & Shuffle           & \multicolumn{1}{c|}{0.3253}  & \multicolumn{1}{c|}{0.3688}  & \multicolumn{1}{c|}{0.5413} & 0.6807 & \multicolumn{1}{c|}{0.2972}  & \multicolumn{1}{c|}{0.3355}  & \multicolumn{1}{c|}{0.4768} & 0.6251  \\ \cmidrule{2-10} 
%   & Change ratio      & \multicolumn{1}{c|}{(-6.46\%)} & \multicolumn{1}{c|}{(-4.05\%)}  & \multicolumn{1}{c|}{(-3.84\%)} & (-2.55\%) & \multicolumn{1}{c|}{(-5.02\%)}  & \multicolumn{1}{c|}{(-4.28\%)}  & \multicolumn{1}{c|}{(-3.48\%)} & (-2.43\%)  \\ \bottomrule
% \end{tabular}}
% \label{tab: auto-regressive}
% \end{table}

% \subsubsection{\textbf{LLMs Model Size}}
% \label{exp: LLM size}
% To examine the impact of the LLM size on recommendation performance, we evaluate models using LLaMA 3.1 (8B) \cite{llama3modelcard}. As shown in Table \ref{tab llm size}, larger LLMs achieve superior recommendation performance compared to the smaller LLaMA 3.2 (3B-Instruct) in Table \ref{tab: overall performance}. The performance gains observed in larger LLMs can be attributed to their enhanced text understanding and greater model capacity. However, LLM4Rec baselines, which struggle to capture sequential information, still perform worse than ~\proposed, regardless of model size. Furthermore, the comparison between LLM4Rec baselines with ~\proposed~(3.2) demonstrates that distilling sequential information is more crucial than merely increasing LLM size for enhancing sequential recommendation performance, again, highlights the importance of equipping LLMs with sequential knowledge to improve LLMs sequential recommendation capabilities.

% \begin{table}[]
% \caption{Performance with different backbone LLM sizes (i.e., LLaMA 3.1 (8B) vs. LLaMA 3.2 (3B-Instruct)). \proposed~(3.2) indicates ~\proposed~ trained using LLaMA 3.2 (3B-Instruct).}
% \resizebox{1.0\linewidth}{!}{
% \begin{tabular}{c|c||c||c||c||c||c||c}
% \toprule
% Dataset &   Metric & TALLRec & LLaRA  & CoLLM  & A-LLMRec & \proposed & \proposed (3.2) \\ \midrule\midrule
% \multirow{4}{*}{Movies}      & NDCG@10 & 0.1673  & 0.1562 & 0.3342 & 0.3347   &\textbf{0.3565}  & 0.3560 \\ \cline{2-8} 
%  & NDCG@20 & 0.2115  & 0.2008 & 0.3685 & 0.3703   & 0.3909  & \textbf{0.3924} \\ \cline{2-8} 
%  & HR@10   & 0.3189  & 0.3048 & 0.5193 & 0.5249   & 0.5500  & \textbf{0.5569} \\ \cline{2-8} 
%  & HR@20   & 0.4906  & 0.4724 & 0.6621 & 0.6708   & 0.6860  &  \textbf{0.7010} \\ \midrule\midrule
% \multirow{4}{*}{Scientific}  & NDCG@10 & 0.2736  & 0.2855 & 0.3120 & 0.2874  & \textbf{0.3560} & 0.3388 \\ \cline{2-8} 
%  & NDCG@20 & 0.3182  & 0.3301 & 0.3496 & 0.3248   & \textbf{0.3911} & 0.3758 \\ \cline{2-8} 
%  & HR@10   & 0.4776  & 0.5053 & 0.5208 & 0.4955   & \textbf{0.5695}  & 0.5532 \\ \cline{2-8} 
%  & HR@20   & 0.6383  & 0.6674 & 0.6645 & 0.6438   & \textbf{0.7081}   & 0.6992 \\ \midrule\midrule
% \multirow{4}{*}{Electronics} & NDCG@10 & 0.2562  & 0.2209 & 0.2773 & 0.2845   & \textbf{0.3136}  & 0.3044\\ \cline{2-8} 
%  & NDCG@20 & 0.2987  & 0.2647 & 0.3152 & 0.3211   & \textbf{0.3528}  & 0.3424 \\ \cline{2-8} 
%  & HR@10   & 0.4266  & 0.3649 & 0.4535 & 0.4710   & \textbf{0.5008}  & 0.4885\\ \cline{2-8} 
%  & HR@20   & 0.5955  & 0.5284 & 0.6035 & 0.6209   & \textbf{0.6559}  & 0.6385\\ \bottomrule
% \end{tabular}}
% \label{tab llm size}
% \end{table}




% \vspace{-1.5ex}
\section{Related Work}
% \subsection{Sequential Recommender Systems}
\noindent\textbf{Sequential Recommender Systems. }
Recommendation systems primarily focus on capturing collaborative filtering (CF) to identify similar items/users. Matrix Factorization-based approaches, achieved notable success by constructing CF knowledge in a latent space \cite{mnih2007probabilistic, chaney2015probabilistic, he2017neural}. However, in conjunction with CF knowledge, understanding dynamic evolution in temporal user preferences has become a powerful tool, leading to the development of collaborative filtering-based sequential recommenders (CF-SRec) \cite{kang2018self, sun2019bert4rec, wu2019session, kim2023task, hidasi2015session,oh2023muse}.
Initial approaches combined Matrix Factorization with Markov Chains to model temporal dynamics \cite{rendle2010factorizing}. Subsequently, neural network-based methods advanced sequential recommender systems, with GRU4Rec \cite{hidasi2015session} leveraging recurrent architectures, while methods such as Caser \cite{tang2018personalized} and NextItNet \cite{yuan2019simple} adopted Convolutional Neural Networks \cite{krizhevsky2012imagenet}. More recently, models such as SASRec \cite{yuan2019simple} and BERT4Rec \cite{sun2019bert4rec}, based on attention mechanisms, have demonstrated superior performance by focusing on the more relevant interaction sequences. These advancements underscore the importance of effectively modeling user behavior dynamics for improved recommendation accuracy.

% \subsection{LLM-based Recommender Systems}
\smallskip
\noindent\textbf{LLM-based Recommender Systems. }
% TALLRec, LLaRA, CoLLM, A-LLMRec
LLMs have recently gained attention in recommendation systems \cite{yue2023llamarec, harte2023leveraging, dai2023uncovering, wu2024coral}, leveraging their reasoning ability and textual understanding for novel approaches such as zero-shot recommendation \cite{hou2024large} and conversational recommendation \cite{sanner2023large}. However, TALLRec \cite{bao2023tallrec} highlights the gap between LLMs' language modeling tasks and recommendation tasks, proposing a fine-tuning approach through Parameter-Efficient Fine-Tuning (PEFT) to adapt LLMs to recommendation tasks.
More recently, LLaRA \cite{10.1145/3626772.3657690}, CoLLM \cite{zhang2023collm}, and A-LLMRec \cite{10.1145/3637528.3671931} have been proposed. LLaRA and CoLLM combine CF-SRec item embeddings with text embeddings from item titles, enabling LLMs to utilize CF knowledge. A-LLMRec further incorporates item descriptions into a latent space, enabling the model to demonstrate robust performance in various scenarios.
Despite these advancements, prior methods fail to capture dynamic user preferences inherent in user interaction sequences as shown in Sec.~\ref{sec: sequence exp}. 

% \vspace{-1ex}
\section{Conclusion}
In this paper, we address a fundamental limitation of LLM4Rec models, i.e., their inability to capture sequential patterns, and empirically demonstrate this shortcoming through extensive experiments. To address the limitation, we propose a simple yet effective distillation framework, named ~\proposed, which effectively transfers sequential knowledge extracted from CF-SRec into LLMs. By doing so, ~\proposed~ enables LLMs to effectively capture sequential dependencies, leading to superior recommendation performance compared to existing CF-SRec, LM-based recommender systems, and LLM4Rec. Furthermore, ~\proposed~ achieves high efficiency, as it does not require fine-tuning either CF-SRec or the LLM, demonstrating the effectiveness of our simple yet efficient architecture.

% In this paper, we investigate the limitations of LLM4Rec models in capturing sequential information for sequential recommendation, and propose a novel LLM based recommendation system, named ~\proposed, which effectively integrates sequential information into LLMs. The main idea is distilling sequential knowledge from pre-trained CF-SRec to the LLMs to enhance LLMs' ability to leverage sequential dependencies without additional fine-tuning on LLMs. By doing so, ~\proposed~ not only leverages the reasoning ability and pre-trained knowledge of LLM, not only leverages the reasoning ability and pre-trained knowledge of LLMs but also effectively utilizes sequential knowledge, which significantly contribute to sequential recommendation performance. Our extensive experiments demonstrates superiority of ~\proposed~ achieving both performance and efficiency.




% \section{SIGCHI Extended Abstracts}

% The ``\verb|sigchi-a|'' template style (available only in \LaTeX\ and
% not in Word) produces a landscape-orientation formatted article, with
% a wide left margin. Three environments are available for use with the
% ``\verb|sigchi-a|'' template style, and produce formatted output in
% the margin:
% \begin{description}
% \item[\texttt{sidebar}:]  Place formatted text in the margin.
% \item[\texttt{marginfigure}:] Place a figure in the margin.
% \item[\texttt{margintable}:] Place a table in the margin.
% \end{description}

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.


% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}
\clearpage
%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

\clearpage

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{imgs/learning_cur.pdf}
    \vspace{-4ex}
    \caption
    {Test performance curve during training (CDs dataset). The inference points are set at every 10\% of the training progress within each epoch.}
    \label{fig: performance curve}
    \vspace{-2ex}
\end{figure*}
\section{Ethics Statement}
To the best of our knowledge, this paper aligns with the KDD Code of Ethics without any ethical concerns. The datasets and codes employed in our research are publicly available.

\section{Details of LLM4Rec Prompt Construction}
This section provides additional details on how to construct prompts for LLM4Rec models discussed in Sec.~\ref{sec: problem setup}.
\subsection{Next Item Title Generation}
\label{app: next item title generation}
Based on the user interaction sequence $\mathcal{S}_u$ and candidate set $\mathcal{C}_u$ of user $u$, the textual data for the interacted items and candidate items are defined as $\mathcal{T}_{\mathcal{S}_u} = \left\{ \text{Text}(i) \mid i \in \mathcal{S}_u \right\}$ and $\mathcal{T}_{\mathcal{C}_u} = \left\{ \text{Text}(i) \mid i \in \mathcal{C}_u \right\}$, respectively, where $\text{Text}(i)$ represents textual information (e.g., title or description) of item $i$. 

For models such as LLaRA \cite{10.1145/3626772.3657690}, CoLLM \cite{zhang2023collm}, and A-LLMRec \cite{10.1145/3637528.3671931}, which incorporate item embeddings and user representations from a pre-trained CF-SRec, we use $\mathbf{E} \in \mathbb{R}^{|\mathcal{I}| \times d}$ to denote the item embedding matrix of the pre-trained CF-SRec, where $d$ is the hidden dimension of the embeddings. 
We also define $f_{\mathcal{I}}$ and $f_{\mathcal{U}}$ as the item and user projection layers used in LLaRA, CoLLM, and A-LLMRec (includes Stage-1 item encoder of A-LLMRec), respectively. 
The embeddings of items in the item interaction sequence $\mathcal{S}_u$ are defined as $\mathbf{E}_{\mathcal{S}_u} = \left\{ f_{\mathcal{I}}(\mathbf{E}_i) \mid i \in \mathcal{S}_u \right\}$, while the embeddings for the candidate items $\mathcal{C}_u$ are represented as $\mathbf{E}_{\mathcal{C}_u} = \left\{ f_{\mathcal{I}}(\mathbf{E}_i) \mid i \in \mathcal{C}_u \right\}${, where $f_{\mathcal{I}}(\mathbf{E_i})\in\mathbb{R}^{d_{llm}}$ and $d_{llm}$ denotes the token embedding dimension of LLM}. 
% Furthermore, the user representation is defined as $\mathbf{O}_u = f_{\mathcal{U}}(\text{CF-SRec}(\mathcal{S}_u))$, where $\text{CF-SRec}(\mathcal{S}_u)$ represents the user $u$'s representation obtained from the item interaction sequence $\mathcal{S}_u$ using a pre-trained CF-SRec. 
{Furthermore, the user representation is defined as $\mathbf{Z}_u = f_{\mathcal{U}}(\text{CF-SRec}(\mathcal{S}_u)) \in \mathbb{R}^{d_{llm}}$, where $\text{CF-SRec}(\mathcal{S}_u)$ represents the user $u$'s representation obtained from the item interaction sequence $\mathcal{S}_u$ using a pre-trained CF-SRec.} 
Then, using the prompts shown in Table~\ref{tab title generation prompt}, LLMs are trained for the sequential recommendation task through the Next Item Title Generation approach as follows:
\begin{equation}
    p(\text{Text}(i_{n_u+1}^{(u)}) \mid \mathcal{P}^{u}, \mathcal{D}^{u})
    \label{Eq LLM4Rec Title generation}
\end{equation}
where $\mathcal{P}^u$ is the input prompt for user $u$, and $D^u$ represents the set of interacted and candidate item titles and their corresponding embeddings used in Table \ref{tab title generation prompt} for user $u$ as follows:
\begin{align}
    \mathcal{D}^{u} = \begin{cases}
        \mathcal{T}_{\mathcal{S}_u}, \mathcal{T}_{\mathcal{C}_u} & \text{TALLRec}\\
        \mathcal{T}_{\mathcal{S}_u}, \mathcal{T}_{\mathcal{C}_u}, \mathbf{E}_{\mathcal{S}_u}, \mathbf{E}_{\mathcal{C}_u} & \text{LLaRA} \\
        \mathcal{T}_{\mathcal{S}_u}, \mathcal{T}_{\mathcal{C}_u},\mathbf{E}_{\mathcal{S}_u}, \mathbf{E}_{\mathcal{C}_u}, \mathbf{Z}_u & \text{CoLLM/A-LLMRec}
    \end{cases}
    \label{Eq LLM4Rec Title generation Input}
\end{align}

\subsection{Next Item Retrieval}
\label{app: next item retrieval}
Based on the prompt $\mathcal{P}^u_{\mathcal{U}}$ and $\mathcal{P}^i_{\mathcal{I}}$ in Table~\ref{tab next item retrieval prompt}, we extract representation of user $u\in\mathcal{U}$, denoted $\mathbf{h}^u_{\mathcal{U}}$ and the embedding of item $i\in\mathcal{C}_u$, denoted $\mathbf{h}^i_{\mathcal{I}}$ as follows:
\begin{align}
    \mathbf{h}^u_{\mathcal{U}} = \text{LLM}(\mathcal{P}^u_{\mathcal{U}}, \mathcal{D'}^u), \,\,\,\,
    \mathbf{h}^{i}_{\mathcal{I}} = \text{LLM}(\mathcal{P}^i_{\mathcal{I}},  \mathcal{D'}^i)
    \label{Eq LLM4Rec Retrieval}
\end{align}
% where $\mathbf{h}^u_{\mathcal{U}} \in \mathbb{R}^{d_{llm}}$ and $\mathbf{h}^i_{\mathcal{I}}\in \mathbb{R}^{d_{llm}}$ denote the representation of user $u\in\mathcal{U}$ and the embedding of item $i\in\mathcal{C}_u$, 
where $\mathcal{P}^u_{\mathcal{U}}$ denotes the input prompt for user $u$ to extract representation of user $u$, $\mathcal{P}^i_{\mathcal{I}}$ denotes the input prompt for item $i$ to extract embedding of item $i$,
{$D'^u$ denotes the set of interacted item titles and their corresponding embeddings for user $u$, while $D'^i$ denotes the item title and its embedding for candidate item $i$, as presented in Table \ref{tab next item retrieval prompt}, as follows:}
\begin{align}
    \begin{split}
    \mathcal{D'}^{u} &= \begin{cases}
        \mathcal{T}_{\mathcal{S}_u} & \text{TALLRec}\\
        \mathcal{T}_{\mathcal{S}_u}, \mathbf{E}_{\mathcal{S}_u} & \text{LLaRA} \\
        \mathcal{T}_{\mathcal{S}_u},\mathbf{E}_{\mathcal{S}_u}, \mathbf{Z}_u & \text{CoLLM/A-LLMRec/\proposed}
    \end{cases}\\
    \mathcal{D'}^{i} &= \begin{cases}
        \text{Text}(i) & \text{TALLRec}\\
        \text{Text}(i), f_{\mathcal{I}}(\mathbf{E}_i) & \text{LLaRA/CoLLM/A-LLMRec/\proposed}
    \end{cases}
    \end{split}
    \label{Eq LLM4Rec Retrieval Input}
\end{align}

Then, using the user representation $\mathbf{h}^u_{\mathcal{U}}$ and item embedding $\mathbf{h}^i_{\mathcal{I}}$, LLMs are trained for the sequential recommendation task through the Next Item Retrieval approach as follows:
\begin{equation}
\small
% p(i_{n_u+1}^{(u)}\mid \mathbf{h}^u_{\mathcal{U}})
p(i_{n_u+1}^{(u)} \mid \mathcal{S}_u) \propto s(u,i_{n_u+1}^{(u)}) = f_\mathit{item}(\mathbf{h}^{i_{n_u+1}^{(u)}}_{\mathcal{I}}) \cdot f_\mathit{user}(\mathbf{h}^u_{\mathcal{U}})^T
    \label{Eq next item retrieval probability}
\end{equation}
where $f_\mathit{item}$ and $f_\mathit{user}$ denote projection layers defined in Equation~\ref{Eq distill}.

\section{Datasets}
\label{app: dataset}
Table \ref{tab dataset} shows the statistics of the dataset after preprocessing.

\begin{table}[h]
\caption{Statistics of datasets after preprocessing.}
\vspace{-2ex}
\resizebox{0.75\linewidth}{!}{
\begin{tabular}{c|c|c|c|c}
\toprule
Dataset & Movies & Scientific & Electronics & CDs  \\ \midrule\midrule
\# Users      & 11,947    & 23,627    &  27,601 & 18,481 \\ \midrule
\# Items  & 17,490    & 25,764    &  31,533 & 30,951   \\ \midrule
\# Interactions & 144,071    & 266,164    &  292,308 & 284,695      \\ \bottomrule
\end{tabular}}
\label{tab dataset}
\end{table}



\section{Baselines}
\label{app: baseline}
\begin{enumerate}[leftmargin=0.5cm]
    \item Collaborative filtering based (CF-SRec)
    \begin{itemize} [leftmargin=*,itemsep=0pt, topsep=0pt]
        \item \textbf{GRU4Rec} \cite{hidasi2015session} employs a recurrent neural network (RNN) to capture user behavior sequences for session-based recommendation.
        \item \textbf{BERT4Rec} \cite{sun2019bert4rec} utilizes bidirectional self-attention mechanisms and a masked item prediction objective to model complex user preferences from interaction sequences.
        \item \textbf{NextItNet} \cite{yuan2019simple} applies temporal convolutional layers to capture both short-term and long-term user preferences.
        \item \textbf{SASRec} \cite{kang2018self} is a self-attention based recommender system designed to capture long-term user preference.
    \end{itemize}

    \item Language model based (LM-based)
    \begin{itemize} [leftmargin=*,itemsep=0pt, topsep=0pt]
        \item \textbf{CTRL} \cite{li2023ctrl} initializes the item embeddings of the backbone recommendation models with textual semantic embeddings using the RoBERTa \cite{liu2019roberta} encoding models. And fine-tunes the backbone models for the recommendation task. 
        \item \textbf{RECFORMER} \cite{li2023text} leverages a Transformer-based framework for sequential recommendation, representing items as sentences by flattening the item title and attributes.
    \end{itemize}
    \item Large Language Model based (LLM4Rec)
        \begin{itemize} [leftmargin=*,itemsep=0pt, topsep=0pt]
        \item \textbf{TALLRec} \cite{bao2023tallrec} fine-tunes LLMs for the recommendation task by formulating the recommendation task as a target item title generation task.
        \item \textbf{LLaRA} \cite{10.1145/3626772.3657690} uses CF-SRec to incorporate behavioral patterns into LLM. To align the behavioral representations from the CF-SRec this model employs a hybrid prompting which is a concatenated form of textual embedding and item representations.
        \item \textbf{CoLLM} \cite{10.1145/3637528.3671931} integrates the collaborative information as a distinct modality into LLMs by extracting and injecting item embeddings from CF-SRec. 
        \item \textbf{A-LLMRec} \cite{10.1145/3637528.3671931} enables LLMs to leverage the CF knowledge from CF-SRec and item semantic information through a two-stage learning framework. 
    \end{itemize}
\end{enumerate}


\section{Implementation Details}
\label{app: implementation details}
In our experiments, we adopt SASRec as a CF-SRec backbone for CoLLM, LLaRA, A-LLMRec, and ~\proposed, with its item embedding dimension fixed to 64 and batch size set to 128.
For LLM4Rec baselines, including Stage-2 of A-LLMRec, the batch size is 20 for the Movies, Scientific, and CDs datasets, while 16 is used for the Electronics dataset. For Stage-1 of A-LLMRec, the batch size is set to 64.
When using Intel Gaudi v2, we set the batch size to 4 due to 8-bit quantization constraints.
All LLM4Rec models are trained for a maximum of 10 epochs, with validation scores evaluated at every 10\% of the training progress within each epoch, where early stop with patience of 10 is applied to prevent over-fitting.
All models are optimized using Adam with a learning rate 0.0001, and the dimension size of the projected embedding $d'$ is 128.
% and the temperature parameter $\tau$ is 1.0.
Experiments are conducted using a single NVIDIA GeForce A6000 (48GB) GPU and a single Gaudi v2 (100GB).


\section{Additional Experiments}
\subsection{Shuffled Training: Test Performance Curve}
\label{app: train shuffle}
Figure \ref{fig: performance curve} shows the  test performance curves for each model during training.



\subsection{Effectiveness of Input Prompts}
\label{app: prompt study}
Note that rather than explicitly having the user representations in the input prompt, we rely on the [UserOut] token to extract the user representations as shown in (Table \ref{tab next item retrieval prompt} (b)).
In Table \ref{tab prompt study}, to validate whether it is sufficient, we compare the performance of~\proposed~with and without the explicit user representations.
% In Table \ref{tab prompt study}, we empirically compare \proposed, using our prompt in Table \ref{tab next item retrieval prompt} with prompt that explicitly incorporates user representations ("With User" in Table \ref{tab prompt study}),  i.e., prompt of CoLLM and A-LLMRec. 
The results show a comparable performance between the two prompts. This suggests that through Equation \ref{Eq distill}, the sequential information contained in the user representation is effectively transferred to the LLMs, enabling them to understand sequential dependencies using only the user interaction sequence without explicitly incorporating the user representation in the prompt. Furthermore, omitting the user representation and its associated text from the prompt reduces input prompt length, improving training/inference efficiency, which implies the practicality of \proposed's prompt.


\begin{table}[t]
\caption{Performance comparison of prompts with/without explicit user representations.}
\vspace{-2ex}
\resizebox{0.7\linewidth}{!}{
\begin{tabular}{c|c||c||c}
\toprule
Dataset                      & Metric  & \makecell{With User \\Representations} & \proposed \\ \midrule\midrule
\multirow{4}{*}{Movies}      & NDCG@10 & \textbf{0.3625}    & 0.3560                   \\ \cline{2-4} 
                             & NDCG@20 & \textbf{0.4003}    & 0.3924                   \\ \cline{2-4} 
                             & HR@10   & \textbf{0.5626}    & 0.5569                   \\ \cline{2-4} 
                             & HR@20   & 0.7004    & \textbf{0.7010}                   \\ \midrule\midrule
\multirow{4}{*}{Scientific}  & NDCG@10 & 0.3342    & \textbf{0.3388}                   \\ \cline{2-4} 
                             & NDCG@20 & 0.3733    & \textbf{0.3758}                   \\ \cline{2-4} 
                             & HR@10   & 0.5516    & \textbf{0.5532}                   \\ \cline{2-4} 
                             & HR@20   & 0.6976    & \textbf{0.6992}                   \\ \midrule\midrule
\multirow{4}{*}{Electronics} & NDCG@10 & 0.2924    & \textbf{0.3044}                   \\ \cline{2-4} 
                             & NDCG@20 & 0.3405    & \textbf{0.3424}                   \\ \cline{2-4} 
                             & HR@10   & 0.4725    & \textbf{0.4885}                   \\ \cline{2-4} 
                             & HR@20   & 0.6239    & \textbf{0.6385}                   \\ \bottomrule
\end{tabular}}
\label{tab prompt study}
\end{table}

\subsection{Distillation with Contrastive Learning}
\label{app: contra distillation}
Recall that we distill sequential information from CF-SRec to LLMs using MSE loss in Equation \ref{Eq distill}. To further investigate the impact of the distillation loss function, we adapt a naive contrastive learning method for sequential information distillation, i.e., Equation \ref{Eq distill-contra}.

\begin{equation}
    \mathcal{L}_{\text{Distill-Contrastive}} = -\underset{u \in \mathcal{U}}{\mathbb{E}}\text{log}\frac{e^{s(f_\mathit{user}(\mathbf{h}_{\mathcal{U}}^u),f_\mathit{CF-user}(\mathbf{O}_u))}}{\sum_{k\in\mathcal{U}} e^{s(f_\mathit{user}(\mathbf{h}_{\mathcal{U}}^u),f_\mathit{CF-user}(\mathbf{O}_k))}}
    \label{Eq distill-contra}
\end{equation}
Table \ref{tab contrastive} shows the performance of different distillation loss functions, and we have the following observations: 1) MSE loss (Equation \ref{Eq distill}) consistently outperforms contrastive loss (Equation \ref{Eq distill-contra}) across all datasets, indicating that effective sequential information transfer to LLMs requires more than just aligning overall trends. Instead, explicitly matching fine-grained details in representations plays a crucial role in preserving sequential dependencies. 2) Performance degradation occurs when inference is performed on shuffled sequences regardless of the chosen loss function, indicating that both losses successfully captures the sequential information.
% These results underscore the importance of distilling sequential information from CF-SRec, as it plays a vital role in enabling LLMs to effectively capture and leverage sequential dependencies.


\begin{table*}[]
\caption{Distillation with contrastive learning method.}
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{c|c||cccc||cccc||cccc}
\toprule
\multirow{2}{*}{Distillation Loss}            & \multirow{2}{*}{} & \multicolumn{4}{c||}{Movies}                                                                          & \multicolumn{4}{c||}{Scientific}                                                                      & \multicolumn{4}{c}{Electronics}                                                                     \\ \cmidrule{3-14} 
 &                   & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}   & HR@20   & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}   & HR@20   & \multicolumn{1}{c|}{NDCG@10} & \multicolumn{1}{c|}{NDCG@20} & \multicolumn{1}{c|}{HR@10}   & HR@20   \\ \midrule\midrule
\multirow{3}{*}{Contrastive} & Original          & \multicolumn{1}{c|}{0.3410}  & \multicolumn{1}{c|}{0.3749}  & \multicolumn{1}{c|}{0.5345}  & 0.6687  & \multicolumn{1}{c|}{0.2767}  & \multicolumn{1}{c|}{0.3152}  & \multicolumn{1}{c|}{0.4817}  & 0.6338  & \multicolumn{1}{c|}{0.2553}  & \multicolumn{1}{c|}{0.2935}  & \multicolumn{1}{c|}{0.4277}  & 0.5792  \\  
 & Shuffle           & \multicolumn{1}{c|}{0.3151}        & \multicolumn{1}{c|}{0.3480}        & \multicolumn{1}{c|}{0.4975}        &  0.6326 & \multicolumn{1}{c|}{0.2638}        & \multicolumn{1}{c|}{0.3021}        & \multicolumn{1}{c|}{0.4650}        &  0.6177  & \multicolumn{1}{c|}{0.2398}        & \multicolumn{1}{c|}{0.2785}        & \multicolumn{1}{c|}{0.4065}        &  0.5608       \\ \cmidrule{2-14} 
 & Change ratio      & \multicolumn{1}{c|}{(-7.60\%)}        & \multicolumn{1}{c|}{(-7.18\%)}        & \multicolumn{1}{c|}{(-6.92\%)}        &  (-5.40\%)    & \multicolumn{1}{c|}{(-4.66\%)}        & \multicolumn{1}{c|}{(-4.16\%)}        & \multicolumn{1}{c|}{(-3.47\%)}        &  (-2.54\%) & \multicolumn{1}{c|}{(-6.07\%)}        & \multicolumn{1}{c|}{(-5.11\%)}        & \multicolumn{1}{c|}{(-4.96\%)}        &  (-3.18\%)   \\ \midrule\midrule
\multirow{3}{*}{\proposed~(MSE)}    & Original          & \multicolumn{1}{c|}{\textbf{0.3560}}  & \multicolumn{1}{c|}{\textbf{0.3924}}  & \multicolumn{1}{c|}{\textbf{0.5569}}  & \textbf{0.7010}  & \multicolumn{1}{c|}{\textbf{0.3388}}  & \multicolumn{1}{c|}{\textbf{0.3758}}  & \multicolumn{1}{c|}{\textbf{0.5532}}  & \textbf{0.6992}  & \multicolumn{1}{c|}{\textbf{0.3044}}  & \multicolumn{1}{c|}{\textbf{0.3424}}  & \multicolumn{1}{c|}{\textbf{0.4885}}  & \textbf{0.6385}  \\ 
 & Shuffle           & \multicolumn{1}{c|}{0.3272}  & \multicolumn{1}{c|}{0.3631}  & \multicolumn{1}{c|}{0.5169}  & 0.6592  & \multicolumn{1}{c|}{0.3232}  & \multicolumn{1}{c|}{0.3605}  & \multicolumn{1}{c|}{0.5336}  & 0.6813  & \multicolumn{1}{c|}{0.2845}  & \multicolumn{1}{c|}{0.3234}  & \multicolumn{1}{c|}{0.4638}  & 0.6184  \\ \cmidrule{2-14} 
 & Change ratio      & \multicolumn{1}{c|}{(-8.10\%)} & \multicolumn{1}{c|}{(-7.47\%)} & \multicolumn{1}{c|}{(-7.18\%)} & (-5.96\%) & \multicolumn{1}{c|}{(-4.60\%)} & \multicolumn{1}{c|}{(-4.07\%)} & \multicolumn{1}{c|}{(-3.54\%)} & (-2.56\%) & \multicolumn{1}{c|}{(-6.53\%)} & \multicolumn{1}{c|}{(-5.55\%)} & \multicolumn{1}{c|}{(-5.06\%)} & (-3.15\%) \\ \bottomrule
\end{tabular}}
\label{tab contrastive}
\end{table*}

\subsection{Preventing Over-smoothing}
\label{app: over-smoothing}
To validate that the $\mathcal{L}_{\text{Uniform}}$ prevents the over-smoothing problem, we measured the pairwise Euclidean distance between all user representations with and without the application of the $\mathcal{L}_{\text{Uniform}}$ under the four datasets. As shown in Table~\ref{tab: over-smoothing}, applying the $\mathcal{L}_{\text{Uniform}}$, i.e. ~\proposed, results in larger distances between users than absence of $\mathcal{L}_{\text{Uniform}}$, i.e., w.o. $\mathcal{L}_{\text{Uniform}}$, which indicates that it helps generate more distinct representations for each user and consequently prevents the over-smoothing problem as described in Sec. \ref{sec: uniform}.

\begin{table}[]
\caption{Average pairwise Euclidean distance between user representations. }
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{c||c|c|c|c}
\toprule
     & Movies & Scientific & Electronics & CDs   \\ \midrule\midrule
w.o. $\mathcal{L}_\text{Uniform}$ & 7.69   & 7.78       & 8.03        & 9.82  \\ \midrule
\proposed & 9.33   & 11.54      & 13.81       & 11.68 \\ \bottomrule
\end{tabular}}
\label{tab: over-smoothing}
\end{table}

\subsection{Auto-regressive Training}
\label{app: autoregressive}
Recall that, for training efficiency, we only consider the last item in the user sequences as the target item to train~\proposed. On the other hand, we can consider all items in the user sequence as the target item to train the models in an auto-regressive manner.
As shown in Figure \ref{fig: auto-regressive}, when all the models are trained in an auto-regressive manner, their performance improves, demonstrating the benefits of leveraging more historical interactions.
One notable result is that our ~\proposed~without the auto-regressive training outperforms other models with the auto-regressive strategy. This is a notable result as the number of samples used for training is much less without auto-regressive training. This result underscores the efficacy of our framework in capturing sequential patterns.
{Furthermore, in the shuffled setting, baselines exhibit a relatively small change ratio compared to ~\proposed, indicating that they still fall short of understanding sequence although the baselines learn the fine-grained item sequences through the auto-regressive manner.}

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{imgs/auto-regressive.pdf}
    \vspace{-5ex}
    \caption
    {Performance with auto-regressive training strategy.}
    \label{fig: auto-regressive}
    % \vspace{-4ex}
\end{figure}

\subsection{Additional Case Study}
\label{app: case study - additional}
In Figure \ref{fig: case study - additional}, we present an additional case study of what is shown in Sec.~\ref{sec: case study}, which shows similar results.
% As (), in case (a), that only ~\proposed~ provides correct recommendations, the user's preference shifts from speaker items to home security items from "Ring" brand. ~\proposed~correctly recommends "Ring" brand home security item, while SASRec fails to correct recommendation
% We obtained similar results with  shown in Sec.~\ref{sec: case study}. 
In case (a), the user's preference shifts from speaker products to home security products made by a brand called "Ring". \proposed~correctly recommends a "Ring" brand home security product, while SASRec captures the preference change but fails to make the correct recommendation. A-LLMRec, failing to leverage sequential information, still recommends a speaker product and thus fails to make the correct recommendation. This again highlights the importance of utilizing both sequential and textual information for accurate recommendations. In case (b), the user's preference focuses on "GoPro" brand products. Both \proposed~and A-LLMRec successfully recommend "GoPro" products by leveraging textual knowledge. This emphasizes the crucial role of textual information in generating accurate recommendations. In case (c), the user's preference shifts from "Apple" brand products to "SanDisk" products. \proposed~ and SASRec successfully capture this changing preference, while A-LLMRec fails to capture the shift and makes an incorrect recommendation. This underscores the importance of capturing sequential information for accurately predicting user preferences. These cases demonstrate that leveraging both sequential and textual information is essential for making accurate recommendations.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{imgs/case_study2.pdf}
    % \vspace{-2ex}
    \caption
    {Additional case study on Electronics dataset. }
    \label{fig: case study - additional}
    % \vspace{-}
\end{figure}


\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.


