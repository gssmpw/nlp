\section{Related Work}
\subsubsection{Traditional PCC}
To compress the point cloud geometry, Garcia \textit{et al.} \cite{garcia2018intra} proposed {an} octree based PCGC exploiting correlations between parent and child nodes. However, as the tree depth increased, the number of bits representing the octree increased dramatically. Kathariya \textit{et al.} \cite{kathariya2018scalable} used binary trees to represent point clouds, which was less efficient in representing lower tree depths. Trisoup-based geometry coding schemes were combined with octrees and represented the object's surface as a series of triangular meshes. Essentially, trisoup-based methods reduced data dimensionality as the octree partitioned the point cloud into local plane-fitted blocks. Ainala \textit{et al.} \cite{ainala2016improved} combined octrees with projection methods. A coarse point cloud was presented with octrees first, which was refined with residuals from 2D planar projections. These algorithms mainly focus on geometry compression by exploiting geometry {properties}  of point clouds. However, the attribute of point clouds have not been considered and compressed.
		
To compress the point cloud attribute, Zhang \textit{et al.} \cite{zhang2014point} proposed a Graph Fourier Transform (GFT) to structure point sets with graph and transform attribute for decorrelation and higher energy compaction. To reduce the computational complexity of graph transform, De Queiroz \textit{et al.} \cite{de2016compression} proposed a Region-Adaptive Hierarchical Transform (RAHT) based attribute coding, which transformed attribute in {octree} based hierarchical order and
predicted attributes of higher level octree in Level of Detail (LoD) structured point clouds. Moreover, predictive and lifting transforms were also investigated based on the LoD representation. The predictive transform predicted higher LoD attributes with lower one, and then residuals were encoded. The lifting transform performed additional lift operations and adaptive quantization based on the predictive transform \cite{chen2023introduction}. Song \textit{et al.} \cite{song2023block} improved the predictive transform with progressive clustering and region-aware signal models. These methods optimized the PCAC by assuming geometry is lossless. The geometry distortion causing the attribute mismatch and quality degradation is not well considered.
		
Moving Picture Expert Group (MPEG) has integrated the PCGC and PCAC algorithms into two joint codecs, which are Geometry-based PCC (G-PCC) \cite{mammou2019g} and Video-based PCC (V-PCC) \cite{mammou2017video}. In geometry algorithms, the octree's simplicity and efficiency have made it one of the optional methods for G-PCC, alongside the trisoup algorithm. For attribute algorithms, RAHT, prediction transform, and lifting transform have been developed as optional in G-PCC attribute coding. In general, G-PCC voxelizes the point cloud, arranging them regularly in 3D space, thereby transforming the 3D point cloud into an octree structure. The octree structure is suitable for compression due to the high correlation between parent and child nodes.
V-PCC projects points onto different planes to form patches, which are then assembled into images containing occupancy, geometry, and attribute maps. These images are finally compressed using 2D codecs like High Efficiency Video Coding (HEVC) and the latest Versatile Video Coding (VVC).
Zhang \textit{et al.} \cite{zhang2023perceptually} proposed a perceptually weighted Rate-Distortion Optimization (RDO) scheme for V-PCC, where an adaptive Lagrange multiplier was adjusted by maximizing the perceptual quality of point cloud \cite{wu2021subjective}. Xiong \textit{et al.} \cite{9735359} designed an Error Projection Model (EPM) to solve the inconsistency between the sum of squared error based distortion and geometry quality metric for RDO. Gao \textit{et al.} \cite{10345479} improved the prediction  performance of coding unit partition by utilizing correlations of occupancy, geometry and attribute maps.
G-PCC and V-PCC eliminate the spatio-temporal redundancy in the geometry and attribute based on hybrid coding structures. However, the spatio-temporal correlation removed by G-PCC through quantization of the octree and transform coefficients is limited. The adaptation of 2D codecs to VPCC is suboptimal because 2D codecs are designed for natural images. In addition, G-PCC and V-PCC evaluate the quality of compressed point clouds using two independent geometry and attribute metrics. The perceptual quality degradation of PCC was scarcely considered.

\subsubsection{Learning-based PCC}
			
As learning-based image/video coding has witnessed a great success \cite{12,134545124,9360626}, a number of learning based PCGC and PCAC \cite{10380494,12351243} were investigated.

In learning based PCGC,
Huang \textit{et al.} \cite{huang20193d} developed a hierarchical autoencoder for point cloud geometry to achieve detail reconstruction. Gao \textit{et al.} \cite{5} proposed a neural graph sampling module that extracted latent keypoints by dynamically aggregating neighboring weights to expand associated features. Song \textit{et al.} \cite{song2023efficient} proposed a hierarchical attention structure with linear complexity in terms of context scale and maintained a global receptive field. It also introduced an intermediate grouping strategy to support parallel decoding. Wang \textit{et al.} \cite{4} introduced sparse convolution \cite{11} to accelerate computation and reduce memory costs in PCGC. Additionally, a hierarchical reconstruction method was proposed to improve compression performance. He \textit{et al.} \cite{he2022density} proposed density embedding, local position embedding and ancestor embedding to encode local geometry and density. Yu \textit{et al.} \cite{yu2023sparse} proposed a long-range-residual module in geometry compression and introduced a multi-scale geometry compression module to avoid the accumulation of reconstruction distortion. Wang \textit{et al.} \cite{wang2022sparse} proposed a hierarchical encoding and reconstruction network that utilizes multi-scale representations to extensively exploit cross-scale correlations for better context modeling. Pang \textit{et al.} \cite{pang2022grasp} proposed a Geometric Residual Analysis and Synthesis for PCC (GRASP), where a coarse layer was encoded with sparse convolutional network and an enhancement layer of residual was encoded point-based network. Generally, learning based PCGC used sparse or graph convolutions to construct learning networks for point clouds. Their performance has surpassed traditional G-PCC and V-PCC schemes \cite{yu2023sparse}. However, these PCGC schemes did not consider the correlation between attribute and geometry.

In learning based PCAC, Nguyen \textit{et al.} \cite{nguyen2023lossless} proposed a lossless PCAC network, which encoded color features sequentially and effectively utilized feature-level and point-level dependencies within the point cloud. Wang \textit{et al.} \cite{wang2023lossless} proposed a lightweight PCAC network with cross-scale, cross-group, and cross-color correlations for lossless compression, enabling parallel encoding and decoding. Sheng \textit{et al.} \cite{7} proposed a second-order point convolution module to expand the receptive field and incorporated multi-scale loss to focus attention on coarse-grained points covering the entire point cloud more effectively. Fang \textit{et al.} \cite{fang20223dac} employed the RAHT to obtain the transformed coefficients and used previously encoded attribute to model the probabilities of the un-coded coefficients. Pinheiro \textit{et al.} \cite{17} proposed a PCAC by using normalized flow and strictly reversible convolution, which enchanted the quality upper-bound. Wang \textit{et al.} \cite{8} proposed a Sparse convolution based PCAC (Sparse-PCAC), where a per-voxel autoregressive entropy model was proposed to improve the probability distribution prediction. Guo \textit{et al.} \cite{10693649} proposed a Transformer and Sparse Convolution based Module (TSCM) for PCAC, which enhanced the local dependency modeling and global representations. Meanwhile, TSCM based channel context module was proposed to predict probability distribution more accurately. These methods assumed the geometry information {was} losslessly encoded. In practice, the severe geometry distortion may degrade the performance of PCAC.

In joint PCC, Guarda \textit{et al.} \cite{guarda2023deep} proposed a deep learning-based lossy point cloud compression network, called IT-DL-PCC, to encode geometry and attribute into one bit stream. The geometry and attribute were jointly down-sampled and presented as a latent representation by feature extraction for coding. At the decoder, up-sampling and enhancement networks were used to reconstruct the geometry and attribute jointly. However, the coding efficiency could be further improved.