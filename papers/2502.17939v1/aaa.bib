@article{1,
	title={Compression of sparse and dense dynamic point clouds—methods and standards},
	author={Cao, Chao and Preda, Marius and Zakharchenko, Vladyslav and Jang, Euee S and Zaharia, Titus},
	journal={Proceedings of the IEEE},
	volume={109},
	number={9},
	pages={1537--1558},
	year={2021},
	publisher={IEEE}
}
@article{2,
	title={Compression of 3D point clouds using a region-adaptive hierarchical transform},
	author={De Queiroz, Ricardo L and Chou, Philip A},
	journal={IEEE Transactions on Image Processing},
	volume={25},
	number={8},
	pages={3947--3956},
	year={2016},
	publisher={IEEE}
}

@inproceedings{5,
	title={Point cloud geometry compression via neural graph sampling},
	author={Gao, Linyao and Fan, Tingyu and Wan, Jianqiang and Xu, Yiling and Sun, Jun and Ma, Zhan},
	booktitle={2021 IEEE International Conference on Image Processing (ICIP)},
	pages={3373--3377},
	year={2021},
	organization={IEEE}
}

@article{6,
	title={Joint autoregressive and hierarchical priors for learned image compression},
	author={Minnen, David and Ball{\'e}, Johannes and Toderici, George D},
	journal={Advances in neural information processing systems},
	volume={31},
	year={2018}
}
@article{9,
	title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
	author={Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
	journal={Advances in neural information processing systems},
	volume={30},
	year={2017}
}

@article{7,
	title={Deep-pcac: An end-to-end deep lossy compression framework for point cloud attributes},
	author={Sheng, Xihua and Li, Li and Liu, Dong and Xiong, Zhiwei and Li, Zhu and Wu, Feng},
	journal={IEEE Transactions on Multimedia},
	volume={24},
	pages={2617--2632},
	year={2021},
	publisher={IEEE}
}

@inproceedings{10,
	title={Inception-v4, inception-resnet and the impact of residual connections on learning},
	author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander},
	booktitle={Proceedings of the AAAI conference on artificial intelligence},
	volume={31},
	number={1},
	year={2017}
}
@inproceedings{4,
	title={Multiscale point cloud geometry compression},
	author={Wang, Jianqiang and Ding, Dandan and Li, Zhu and Ma, Zhan},
	booktitle={2021 Data Compression Conference (DCC)},
	pages={73--82},
	year={2021},
	organization={IEEE}
}

@inproceedings{8,
	title={Sparse tensor-based point cloud attribute compression},
	author={Wang, Jianqiang and Ma, Zhan},
	booktitle={2022 IEEE 5th International Conference on Multimedia Information Processing and Retrieval (MIPR)},
	pages={59--64},
	year={2022},
	organization={IEEE}
}
@inproceedings{11,
	title={4d spatio-temporal convnets: Minkowski convolutional neural networks},
	author={Choy, Christopher and Gwak, JunYoung and Savarese, Silvio},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={3075--3084},
	year={2019}
}

@inproceedings{13,
	title={Learned image compression with mixed transformer-cnn architectures},
	author={Liu, Jinming and Sun, Heming and Katto, Jiro},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={14388--14397},
	year={2023}
}

@inproceedings{15,
	title={PCGFormer: Lossy Point Cloud Geometry Compression via Local Self-Attention},
	author={Liu, Gexin and Wang, Jianqiang and Ding, Dandan and Ma, Zhan},
	booktitle={2022 IEEE International Conference on Visual Communications and Image Processing (VCIP)},
	pages={1--5},
	year={2022},
	organization={IEEE}
}

@inproceedings{17,
	title={NF-PCAC: Normalizing Flow based Point Cloud Attribute Compression},
	author={Pinheiro, Rodrigo B and Marvie, Jean-Eudes and Valenzise, Giuseppe and Dufaux, Fr{\'e}d{\'e}ric},
	booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={1--5},
	year={2023},
	organization={IEEE}
}

@article{12,
	title={Joint graph attention and asymmetric convolutional neural network for deep image compression},
	author={Tang, Zhisen and Wang, Hanli and Yi, Xiaokai and Zhang, Yun and Kwong, Sam and Kuo, C-C Jay},
	journal={IEEE Transactions on Circuits and Systems for Video Technology},
	volume={33},
	number={1},
	pages={421--433},
	year={2022},
	publisher={IEEE}
}

@inproceedings{19,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-05-24},
  abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
  file = {C\:\\Users\\gzx\\Zotero\\storage\\BTUXQXVX\\Vaswani 等 - 2017 - Attention is All you Need.pdf}
}

@article{16,
	title={Lossy point cloud geometry compression via end-to-end learning},
	author={Wang, Jianqiang and Zhu, Hao and Liu, Haojie and Ma, Zhan},
	journal={IEEE Transactions on Circuits and Systems for Video Technology},
	volume={31},
	number={12},
	pages={4909--4923},
	year={2021},
	publisher={IEEE}
}

@inproceedings{14,
  title = {End-to-{{End Point Cloud Geometry Compression}} and {{Analysis}} with {{Sparse Tensor}}},
  booktitle = {Proceedings of the 1st {{International Workshop}} on {{Advances}} in {{Point Cloud Compression}}, {{Processing}} and {{Analysis}}},
  author = {Xie, Liang and Gao, Wei and Zheng, Huiming},
  year = {2022},
  month = oct,
  pages = {27--32},
  publisher = {{ACM}},
  address = {{Lisboa Portugal}},
  doi = {10.1145/3552457.3555726},
  urldate = {2023-05-23},
  abstract = {With the rapid development of deep learning, encoded objects such as images, videos, and point cloud objects are increasingly used in downstream tasks optimized by deep learning. Traditional coding tools are optimized for human perception, not machine vision. Therefore, we bring forward a point cloud lossy compression method for machine vision, which uses elaborate extracted features to ensure the point cloud classification accuracy. We present a multiscale channel attention module, which can well integrate features of various channels and dimensions, ensuring the compression performance and integrating the upper-level semantic information well. The experimental results demonstrates that our method achieves 30\% BD-Rate gains and 5\% improvement in classification compared with PCGCV2 in Modelnet40.},
  isbn = {978-1-4503-9491-8},
  langid = {english},
  file = {C\:\\Users\\gzx\\Zotero\\storage\\JUW7GIEE\\Xie 等 - 2022 - End-to-End Point Cloud Geometry Compression and An.pdf}
}

@inproceedings{18,
	title={Enhanced invertible encoding for learned image compression},
	author={Xie, Yueqi and Cheng, Ka Leong and Chen, Qifeng},
	booktitle={Proceedings of the 29th ACM international conference on multimedia},
	pages={162--170},
	year={2021}
}

@inproceedings{20,
  title = {Exploring {{Self-Attention}} for {{Image Recognition}}},
  booktitle = {2020 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Zhao, Hengshuang and Jia, Jiaya and Koltun, Vladlen},
  year = {2020},
  month = jun,
  pages = {10073--10082},
  publisher = {{IEEE}},
  address = {{Seattle, WA, USA}},
  doi = {10.1109/CVPR42600.2020.01009},
  urldate = {2023-05-24},
  abstract = {Recent work has shown that self-attention can serve as a basic building block for image recognition models. We explore variations of self-attention and assess their effectiveness for image recognition. We consider two forms of self-attention. One is pairwise self-attention, which generalizes standard dot-product attention and is fundamentally a set operator. The other is patchwise self-attention, which is strictly more powerful than convolution. Our pairwise self-attention networks match or outperform their convolutional counterparts, and the patchwise models substantially outperform the convolutional baselines. We also conduct experiments that probe the robustness of learned representations and conclude that self-attention networks may have significant benefits in terms of robustness and generalization.},
  isbn = {978-1-72817-168-5},
  langid = {english},
  file = {C\:\\Users\\gzx\\Zotero\\storage\\YPMF9M6S\\Zhao 等 - 2020 - Exploring Self-Attention for Image Recognition.pdf}
}
@article{27,
	title={Pu-dense: Sparse tensor-based point cloud geometry upsampling},
	author={Akhtar, Anique and Li, Zhu and Van der Auwera, Geert and Li, Li and Chen, Jianle},
	journal={IEEE Transactions on Image Processing},
	volume={31},
	pages={4133--4148},
	year={2022},
	publisher={IEEE}
}

@article{30,
  title = {8i Voxelized Full Bodies-a Voxelized Point Cloud Dataset},
  author = {{d'Eon}, Eugene and Harrison, Bob and Myers, Taos and Chou, Philip A.},
  year = {2017},
  journal = {ISO/IEC JTC1/SC29 Joint WG11/WG1 (MPEG/JPEG) input document WG11M40059/WG1M74006},
  volume = {7},
  number = {8},
  pages = {11}
}

@inproceedings{23,
  title = {An {{Image}} Is {{Worth}} 16x16 {{Words}}: {{Transformers}} for {{Image Recognition}} at {{Scale}}},
  shorttitle = {An {{Image}} Is {{Worth}} 16x16 {{Words}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  year = {2021},
  month = jan,
  urldate = {2023-05-24},
  abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
  langid = {english},
  file = {C\:\\Users\\gzx\\Zotero\\storage\\RFYEXSCD\\Dosovitskiy 等 - 2021 - An Image is Worth 16x16 Words Transformers for Im.pdf}
}

@article{24,
  title = {{{PCT}}: {{Point}} Cloud Transformer},
  shorttitle = {{{PCT}}},
  author = {Guo, Meng-Hao and Cai, Jun-Xiong and Liu, Zheng-Ning and Mu, Tai-Jiang and Martin, Ralph R. and Hu, Shi-Min},
  year = {2021},
  month = jun,
  journal = {Computational Visual Media},
  volume = {7},
  number = {2},
  pages = {187--199},
  issn = {2096-0433, 2096-0662},
  doi = {10.1007/s41095-021-0229-5},
  urldate = {2023-05-12},
  abstract = {The irregular domain and lack of ordering make it challenging to design deep neural networks for point cloud processing. This paper presents a novel framework named Point Cloud Transformer (PCT) for point cloud learning. PCT is based on Transformer, which achieves huge success in natural language processing and displays great potential in image processing. It is inherently permutation invariant for processing a sequence of points, making it well-suited for point cloud learning. To better capture local context within the point cloud, we enhance input embedding with the support of farthest point sampling and nearest neighbor search. Extensive experiments demonstrate that the PCT achieves the state-of-the-art performance on shape classification, part segmentation, semantic segmentation, and normal estimation tasks.},
  langid = {english},
  file = {C\:\\Users\\gzx\\Zotero\\storage\\9CE6Y6CN\\Guo 等 - 2021 - PCT Point cloud transformer.pdf}
}

@article{32,
  title = {Microsoft Voxelized Upper Bodies-a Voxelized Point Cloud Dataset},
  author = {Loop, Charles and Cai, Qin and Escolano, S Orts and Chou, Philip A},
  year = {2016},
  journal = {ISO/IEC JTC1/SC29 Joint WG11/WG1 (MPEG/JPEG) input document m38673 M},
  volume = {72012},
  pages = {2016}
}


@article{28,
	title={Pnp-3d: A plug-and-play for 3d point clouds},
	author={Qiu, Shi and Anwar, Saeed and Barnes, Nick},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={45},
	number={1},
	pages={1312--1319},
	year={2021},
	publisher={IEEE}
}

@article{33,
  title = {Updates and Integration of Evaluation Metric Software for {{PCC}}},
  author = {Tian, Dong and Ochimizu, Hideaki and Feng, Chen and Cohen, Robert and Vetro, Anthony},
  year = {2017},
  journal = {ISO/IEC JTC1/SC29/WG11 input document MPEG2017 M},
  volume = {40522},
  pages = {26}
}
@article{26,
	title={Sparse tensor-based multiscale representation for point cloud geometry compression},
	author={Wang, Jianqiang and Ding, Dandan and Li, Zhu and Feng, Xiaoxing and Cao, Chuntong and Ma, Zhan},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	year={2022},
	publisher={IEEE}
}

@inproceedings{31,
  title = {Owlii {{Dynamic}} Human Mesh Sequence Dataset},
  booktitle = {{{ISO}}/{{IEC JTC1}}/{{SC29}}/{{WG11}} M41658, 120th {{MPEG Meeting}}},
  author = {Xu, Yi and Lu, Yao and Wen, Ziyu},
  year = {2017},
  volume = {1}
}

@inproceedings{25,
	title={Codedvtr: Codebook-based sparse voxel transformer with geometric guidance},
	author={Zhao, Tianchen and Zhang, Niansong and Ning, Xuefei and Wang, He and Yi, Li and Wang, Yu},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={1435--1444},
	year={2022}
}

@inproceedings{21,
	title={Point transformer},
	author={Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip HS and Koltun, Vladlen},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={16259--16268},
	year={2021}
}
@article{32,
	title = {Microsoft Voxelized Upper Bodies-a Voxelized Point Cloud Dataset},
	author = {Loop, Charles and Cai, Qin and Escolano, S Orts and Chou, Philip A},
	year = {2016},
	journal = {ISO/IEC JTC1/SC29 Joint WG11/WG1 (MPEG/JPEG) input document m38673 M},
	volume = {72012},
	pages = {2016}
}

@inproceedings{
	ball,
	title={Variational image compression with a scale hyperprior},
	author={Johannes Ballé and David Minnen and Saurabh Singh and Sung Jin Hwang and Nick Johnston},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@inproceedings{liu2023learned,
	title={Learned image compression with mixed transformer-cnn architectures},
	author={Liu, Jinming and Sun, Heming and Katto, Jiro},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={14388--14397},
	year={2023}
}

@inproceedings{
	chen2016variational,
	title={Variational Lossy Autoencoder},
	author={Xi Chen and Diederik P. Kingma and Tim Salimans and Yan Duan and Prafulla Dhariwal and John Schulman and Ilya Sutskever and Pieter Abbeel},
	booktitle={International Conference on Learning Representations},
	year={2017},

}
@inproceedings{tsubota2023universal,
	title={Universal deep image compression via content-adaptive optimization with adapters},
	author={Tsubota, Koki and Akutsu, Hiroaki and Aizawa, Kiyoharu},
	booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
	pages={2529--2538},
	year={2023}
}
@inproceedings{zou2022devil,
	title={The devil is in the details: Window-based attention for image compression},
	author={Zou, Renjie and Song, Chunfeng and Zhang, Zhaoxiang},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={17492--17501},
	year={2022}
}
@inproceedings{minnen2020channel,
	title={Channel-wise autoregressive entropy models for learned image compression},
	author={Minnen, David and Singh, Saurabh},
	booktitle={2020 IEEE International Conference on Image Processing (ICIP)},
	pages={3339--3343},
	year={2020},
	organization={IEEE}
}
@article{graziosi2020overview,
	title={An overview of ongoing point cloud compression standardization activities: Video-based (V-PCC) and geometry-based (G-PCC)},
	author={Graziosi, Danillo and Nakagami, Ohji and Kuma, Shinroku and Zaghetto, Alexandre and Suzuki, Teruhiko and Tabatabai, Ali},
	journal={APSIPA Transactions on Signal and Information Processing},
	volume={9},
	pages={e13},
	year={2020},
	publisher={Cambridge University Press}
}

@INPROCEEDINGS{fang20223dac,
	author={Fang, Guangchi and Hu, Qingyong and Wang, Hanyun and Xu, Yiling and Guo, Yulan},
	booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
	title={3DAC: Learning Attribute Compression for Point Clouds}, 
	year={2022},
	volume={},
	number={},
	pages={14799-14808},
	doi={10.1109/CVPR52688.2022.01440}}
@inproceedings{hou2022learning,
	title={Learning-based Intra-Prediction For Point Cloud Attribute Transform Coding},
	author={Hou, Lizhi and Gao, Linyao and Xu, Yiling and Li, Zhu and Xu, Xiaozhong and Liu, Shan},
	booktitle={2022 IEEE 24th International Workshop on Multimedia Signal Processing (MMSP)},
	pages={1--6},
	year={2022},
	organization={IEEE}
}
@inproceedings{wang2023lossless,
	title={Lossless Point Cloud Attribute Compression Using Cross-scale, Cross-group, and Cross-color Prediction},
	author={Wang, Jianqiang and Ding, Dandan and Ma, Zhan},
	booktitle={2023 Data Compression Conference (DCC)},
	pages={228--237},
	year={2023},
	organization={IEEE}
}
@article{nguyen2023lossless,
	title={Lossless Point Cloud Geometry and Attribute Compression Using a Learned Conditional Probability Model},
	author={Nguyen, Dat Thanh and Kaup, Andr{\'e}},
	journal={IEEE Transactions on Circuits and Systems for Video Technology},
	year={2023},
	publisher={IEEE}
}

@article{krivokuca20188i,
	title = {8i Voxelized Surface Light Field ({{8iVSLF}}) Dataset},
	author = {Krivokuca, Maja and Chou, Philip A and Savill, Patrick},
	year = {2018},
	journal = {ISO/IEC JTC1/SC29/WG11 MPEG, input document m42914}
}

@article{pages2021volograms,
	title={Volograms \& V-SENSE Volumetric Video Dataset},
	author={Pag{\'e}s, Rafael and Amplianitis, Konstantinos and Ondrej, Jan and Zerman, Emin and Smolic, Aljosa},
	journal={ISO/IEC JTC1/SC29/WG07 MPEG2021/m56767},
	year={2021}
}
@article{nguyen2021lossless,
	title={Lossless coding of point cloud geometry using a deep generative model},
	author={Nguyen, Dat Thanh and Quach, Maurice and Valenzise, Giuseppe and Duhamel, Pierre},
	journal={IEEE Transactions on Circuits and Systems for Video Technology},
	volume={31},
	number={12},
	pages={4617--4629},
	year={2021},
	publisher={IEEE}
}

@inproceedings{pavez2021multi,
	title={Multi-resolution intra-predictive coding of 3d point cloud attributes},
	author={Pavez, Eduardo and Souto, Andre L and De Queiroz, Ricardo L and Ortega, Antonio},
	booktitle={2021 IEEE International Conference on Image Processing (ICIP)},
	pages={3393--3397},
	year={2021},
	organization={IEEE}
}

@ARTICLE{song2023block,
	author={Song, Fei and Li, Ge and Yang, Xiaodong and Gao, Wei and Liu, Shan},
	journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
	title={Block-Adaptive Point Cloud Attribute Coding With Region-Aware Optimized Transform}, 
	year={2023},
	volume={33},
	number={8},
	pages={4294-4308},
	doi={10.1109/TCSVT.2023.3235891}}
@article{bjontegaard2001calculation,
	title={Calculation of average PSNR differences between RD-curves},
	author={Bjontegaard, Gisle},
	journal={ITU SG16 Doc. VCEG-M33},
	year={2001}
}
@inproceedings{golla2015real,
	title={Real-time point cloud compression},
	author={Golla, Tim and Klein, Reinhard},
	booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	pages={5087--5092},
	year={2015},
	organization={IEEE}
}
@article{mammou2017video,
	title={Video-based and hierarchical approaches point cloud compression},
	author={Mammou, Khaled and Tourapis, Alexis M and Singer, David and Su, Yeping},
	journal={Document ISO/IEC JTC1/SC29/WG11 m41649, Macau, China},
	year={2017}
}
@article{mammou2019g,
	title={G-PCC codec description v2},
	author={Mammou, Khaled and Chou, Philip A and Flynn, David and Krivoku{\'c}a, Maja and Nakagami, Ohji and Sugio, Toshiyasu},
	journal={ISO/IEC JTC1/SC29/WG11 N},
	volume={18189},
	pages={2019},
	year={2019}
}
@inproceedings{meng2022adavit,
	title={Adavit: Adaptive vision transformers for efficient image recognition},
	author={Meng, Lingchen and Li, Hengduo and Chen, Bor-Chun and Lan, Shiyi and Wu, Zuxuan and Jiang, Yu-Gang and Lim, Ser-Nam},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={12309--12318},
	year={2022}
}
@inproceedings{kim2022joint,
	title={Joint global and local hierarchical priors for learned image compression},
	author={Kim, Jun-Hyuk and Heo, Byeongho and Lee, Jong-Seok},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={5992--6001},
	year={2022}
}
@inproceedings{huang20193d,
	title={3d point cloud geometry compression on deep learning},
	author={Huang, Tianxin and Liu, Yong},
	booktitle={Proceedings of the 27th ACM international conference on multimedia},
	pages={890--898},
	year={2019}
}
@inproceedings{szegedy2017inception,
	title={Inception-v4, inception-resnet and the impact of residual connections on learning},
	author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander},
	booktitle={Proceedings of the AAAI conference on artificial intelligence},
	volume={31},
	number={1},
	year={2017}
}