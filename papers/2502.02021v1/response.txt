\section{Related works}
\label{sec2:related works}

\subsection{Single-illuminant Color Constancy}
\label{sec2.1:Single-illuminant Color Constancy}
Existing single-illuminant color constancy methods can be roughly categorized into statistics-based and learning-based methods. Statistics-based methods use the statistics of an image as the illuminant color. Gray World (GW) Finlayson, Hordley, and Hwang, "Gray World Assumption Revisited" one of the most well-known statistics-based methods, assumes that the average reflectance of a scene is gray and employs the mean value of an image as estimation. White Patch (WP) Barnard et al., "A Comparison of Non-Linear Methods for Single Image Color Constancy" supposes that there is a white patch in the scene and uses the max value of each channel as the illuminant color. Shade of Gray (SoG) Gijsenij, "A Default-Surface Prior for Colour Constancy" uses the p-norm of an image as estimation. Gray Edge (GE) Cheng et al., "Color Constancy Using Invariant Properties of Reflectance and Illumination" extends SoG to the gradient domain. Weighted GE Gijsenij et al., "Color Constancy Using Invariant Properties of Reflectance and Illumination" further takes into account the diversity of image edges and proposes an adaptive weighting scheme. Cheng et al., "Color Constancy Using Invariant Properties of Reflectance and Illumination" propose to use the first principal component of bright and dark pixels as the estimation. Since gray pixels can directly indicate the illuminant color, Yang et al., "Gray Pixel Detection for Color Constancy" and Qian et al., "A Survey on Single Image Color Constancy Methods" respectively propose a method for gray pixel detection. Statistics-based methods are efficient and interpretable, but their generalization ability is limited due to their inherent assumptions.

Learning-based methods estimate the illuminant color in an data-driven manner. Cardei et al., "Learning to Predict Illuminant Colors from Binarized Chromatic Histograms" build the mapping between the binarized chromatic histogram and the illuminant color using neural networks. Gijsenij et al., "Color Constancy Using Invariant Properties of Reflectance and Illumination" employs k-nearest neighbor clustering in the Weibull parameter space to determine the most appropriate statistics-based method for an image. Gehler et al., "Bayesian Color Constancy" use Bayesian method for illuminant estimation. Nowadays, deep learning for illuminant estimation is the main direction. Bianon et al., "Deep Learning for Illuminant Estimation: A Review" build the first convolutional neural networks for illuminant estimation. Barron et al., "Color Constancy through Dichromatic Reflection Model" reduce the regression problem to a problem of locating the illuminant in the log-chroma space. Hu et al., "Fully Convolutional Networks for Illuminant Estimation" build a fully convolutional network. Woo et al., "Deep Learning for Color Constancy: A Survey" integrate the dichromatic reflection model with convolutional neural networks, establishing a framework to predict dichromatic planes for illuminant estimation. Afifi et al., "Correcting Color Biases in SRGB Color Space" and Luo et al., "Color Consistency Across Images and Devices" propose to correct color biases in sRGB color space. In addition to the end-to-end paradigm, other deep learning paradigms have also been explored. Lo et al., "Contrastive Learning for Illuminant Estimation" create illuminant-related contrastive pairs for contrastive learning. Tang et al., "Transfer Learning for Color Constancy Across Domains" bridge the gaps between different image domains by transfer learning, expanding the number of available data.

\subsection{Multi-illuminant Color Constancy}
\label{sec2.2:Multi-illuminant Color Constancy}
As mentioned before, multi-illuminant color constancy methods aim to estimate the illuminant color per pixel, and current methods can be classified into two partially overlapping categories: segmentation-based methods and deep-learning-based methods. Gijsenij et al., "Color Constancy Using Invariant Properties of Reflectance and Illumination" propose to segment an image into small patches and perform single-illuminant estimation and clustering for illuminant distribution estimation. Beigpour et al., "Conditional Random Fields for Color Constancy" use conditional random fields to optimize the initial patch-wise local estimation. Hamid Reza Vaezi, "A Novel Approach to Multi-Illuminant Color Constancy" segments an image into different surfaces according to the rule of color consistency and estimates the illuminant for each surface by finding its nearest neighbor surfaces from the training data. Bianco et al., "Deep Learning for Multi-Illuminant Color Constancy: A Survey" use convolutional neural networks for patch-wise illuminant estimation. Gao et al., "Multi-Illuminant Color Constancy Using Difference of Gaussian Operators" segment an image into bright and dark areas, and generate illuminant estimation per area with Difference of Gaussian operators.

For a long time, the development of deep-learning-based methods faces significant challenges due to the absence of large-scale datasets. Therefore, Kim et al., "LSMI: A Large Scale Multi-Illuminant Dataset for Color Constancy" create a large scale multi-illuminant (LSMI) dataset and train an U-Net for illuminant distribution estimation (LSMI-U). DomisloviÄ‡ et al., "A Lightweight Convolutional Network for Multi-Illuminant Color Constancy" build a lightweight convolutional network for patch-wise estimation. Li et al., "Multi-Task Training Framework for Illuminant Distribution Estimation" propose a multi-task training framework to integrate related tasks into illuminant distribution estimation. Entok et al., "Smoothing Constraints in Deep Models for Multi-Illuminant Color Constancy" incorporate smoothing constraints into the training of deep models. Kim et al., "Slot Attention for Multi-Illuminant Color Constancy" employ slot attention to decouple the original task into illuminant chromaticity estimation and weight map estimation. Yue et al., "Physical-Constrained Method for Multi-Illuminant Color Constancy" have revealed that some methods are sensitive to image bit-depth and propose a physical-constrained method. Our method differs mainly in that we have taken into account the impact of image scales and use dedicated models to restore multi-grained illuminant distribution maps from multi-scale images.