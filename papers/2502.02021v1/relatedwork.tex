\section{Related works}
\label{sec2:related works}

\subsection{Single-illuminant Color Constancy}
\label{sec2.1:Single-illuminant Color Constancy}
Existing single-illuminant color constancy methods can be roughly categorized into statistics-based and learning-based methods. Statistics-based methods use the statistics of an image as the illuminant color. Gray World (GW) \cite{Buchsbaum1980a}, one of the most well-known statistics-based methods, assumes that the average reflectance of a scene is gray and employs the mean value of an image as estimation. White Patch (WP) \cite{barnard_comparison_2002} supposes that there is a white patch in the scene and uses the max value of each channel as the illuminant color. Shade of Gray (SoG) \cite{finlayson_shades_2004} uses the p-norm of an image as estimation. Gray Edge (GE) \cite{VandeWeijer2007c} extends SoG
to the gradient domain. Weighted GE \cite{gijsenij_improving_2012} further takes into account the diversity of image edges and proposes an adaptive weighting scheme. Cheng et al. \cite{Cheng2014a} propose to use the first principal component of bright and dark pixels as the estimation. Since gray pixels can directly indicate the illuminant color, Yang et al. \cite{Yang2015} and Qian et al. \cite{qian_finding_2019} respectively propose a method for gray pixel detection. Statistics-based methods are efficient and interpretable, but their generalization ability is limited due to their inherent assumptions.

Learning-based methods estimate the illuminant color in an data-driven manner. Cardei et al. \cite{cardei_estimating_2002} build the mapping between the binarized chromatic histogram and the illuminant color using neural networks. Gijsenij et al. \cite{gijsenij_color_2007} employs k-nearest neighbor clustering in the Weibull parameter space to determine the most appropriate statistics-based method for an image. Gehler et al. \cite{Gehler2008} use Bayesian method for illuminant estimation. Nowadays, deep learning for illuminant estimation is the main direction. Bianon et al. \cite{Bianco2015} build the first convolutional neural networks for illuminant estimation. Barron et al. \cite{Barron2017} reduce the regression problem to a problem of locating the illuminant in the log-chroma space. Hu et al. \cite{Hu2017} build a fully convolutional network. Woo et al. \cite{woo_deep_2021} integrate the dichromatic reflection model with convolutional neural networks, establishing a framework to predict dichromatic planes for illuminant estimation. Afifi et al. \cite{afifi_when_2019, afifi_deep_2020} and Luo et al. \cite{luo_estimating_2021} propose to correct color biases in sRGB color space. In addition to the end-to-end paradigm, other deep learning paradigms have also been explored. Lo et al. \cite{lo_clcc_2021} create illuminant-related contrastive pairs for contrastive learning. Tang et al. \cite{tang_transfer_2022} bridge the gaps between different image domains by transfer learning, expanding the number of available data.

\subsection{Multi-illuminant Color Constancy}
\label{sec2.2:Multi-illuminant Color Constancy}
As mentioned before, multi-illuminant color constancy methods aim to estimate the illuminant color per pixel, and current methods can be classified into two partially overlapping categories: segmentation-based methods and deep-learning-based methods. Gijsenij et al. \cite{gijsenij_color_2012} propose to segment an image into small patches and perform single-illuminant estimation and clustering for illuminant distribution estimation. Beigpour et al. \cite{beigpour_multi-illuminant_2014} use conditional random fields to optimize the initial patch-wise local estimation. Hamid Reza Vaezi \cite{joze_exemplar-based_2014} segments an image into different surfaces according to the rule of color consistency and estimates the illuminant for each surface by finding its nearest neighbor surfaces from the training data. Bianco et al. \cite{bianco_single_2017} use convolutional neural networks for patch-wise illuminant estimation. Gao et al. \cite{gao_combining_2019} segment an image into bright and dark areas, and generate illuminant estimation per area with Difference of Gaussian operators.

For a long time, the development of deep-learning-based methods faces significant challenges due to the absence of large-scale datasets. Therefore, Kim et al. \cite{kim_large_2021} create a large scale multi-illuminant (LSMI) dataset and train an U-Net for illuminant distribution estimation (LSMI-U). DomisloviÄ‡ et al. \cite{domislovic_color_2023} build a lightweight convolutional network for patch-wise estimation. Li et al. \cite{li_mimt_2023} propose a multi-task training framework to integrate related tasks into illuminant distribution estimation. Entok et al. \cite{entok_pixel-wise_2024} incorporate smoothing constraints into the training of deep models. Kim et al. \cite{kim_attentive_2024} employ slot attention to decouple the original task into illuminant chromaticity estimation and weight map estimation. Yue et al. \cite{yue_robust_2024} have revealed that some methods are sensitive to image bit-depth and propose a physical-constrained method. Our method differs mainly in that we have taken into account the impact of image scales and use dedicated models to restore multi-grained illuminant distribution maps from multi-scale images.