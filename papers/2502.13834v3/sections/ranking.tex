\section{Goal Filtering and Selection}
\label{sec:ranking}
Scaling and rewriting tactics yield a collection of new proof goals. By combining these newly generated goals with existing unexplored ones, we can derive a candidate set. The next step is to select the most promising goal from this candidate set for subsequent proving. In our running example, we can derive 16 new proof goals from the current goal (\ref{eqn:example_e3}). Below, we present three of these new goals, each derived by applying the two-variable AM-GM inequality, the three-variable Titu inequality, and simplifying using the given assumption $a^2+b^2+c^2=1$, respectively:
\begin{tcolorbox}[enhanced, colback=black!5!white, colframe=black!75!white, top=-4pt, bottom=2pt, left=2pt, right=2pt,]
\begin{align}  
& \frac{1}{a ^ 2 + 2} + \frac{1}{b ^ 2 + 2} + \frac{1}{c^2 + 2} \leq  2 \sqrt{\frac{1}{a ^ 2 + 3b ^ 2 + 3c ^ 2} \cdot \frac{1}{b ^ 2 + 3a ^ 2 + 3c ^ 2}} + \frac{1}{c^2 + 3a^2 + 3b^2}; \label{eqn:example_e4} \tag{4} \\  
& \frac{1}{a ^ 2 + 2} + \frac{1}{b ^ 2 + 2} + \frac{1}{c^2 + 2} \leq \frac{9}{7a ^ 2 + 7 b ^ 2 + 7 c ^ 2} \label{eqn:example_e5}; \tag{5} \\  
& \frac{1}{a ^ 2 + 2} + \frac{1}{b ^ 2 + 2} + \frac{1}{c^2 + 2} \leq \frac{1}{3 - 2a ^ 2} + \frac{1}{3 - 2b ^ 2} + \frac{1}{3 - 2c ^ 2}. \label{eqn:example_e6} \tag{6}  
\end{align}
\end{tcolorbox}

To select proof goals effectively, existing methods often train a language model as a value function to evaluate and rank each goal in the candidate set. However, limitations in data quantity and diversity can significantly degrade the performance of these fine-tuned models. For example, the largest collected inequality dataset in Lean comprises only 46K samples~\citep{ying2024lean}, while the largest synthesized dataset of competition-level inequalities contains merely 191K cyclically symmetric instances~\citep{wei2024proving}. Consequently, we opt to directly employ an off-the-shelf LLM (e.g., GPT-4o) without fine-tuning. However, as more proof goals accumulate, the context length required for prompting an LLM for goal ranking becomes substantial, potentially leading to the issue of LLMs being ``lost in the middle''~\citep{liu2024lost}. To address this, we propose dividing the goal selection pipeline into two stages: symbolic filtering and neural ranking.


\vspace{-0.3em}
\subsection{Symbolic Filtering}
\vspace{-0.3em}
First, we eliminate proof goals that are less promising based on carefully designed symbolic rules. Specifically, we prioritize two key properties: (1) \textit{homogeneity}, meaning both sides of the inequality have the same degree (e.g., $a ^2 + b ^ 2 \ge 2 ab$); and (2) \textit{decoupling}, which refers to whether the inequality contains mixed-variable terms (e.g., $abc$ is considered coupled). Both properties are reasonable criteria for prioritization. Regarding homogeneity, most substitution and transformation tactics preserve homogeneity. Hence, a homogeneous inequality allows for a broader range of tactics to be applied, thereby producing more valuable proof goals. For decoupling, an inequality with fewer coupled terms is not only clearer but also amenable to a greater variety of techniques, such as the sum-of-squares and tangent line tricks.

To measure decoupling and homogeneity, we first approximate the proof goal by a polynomial inequality using Taylor expansion. We then compute the expectation of the number of variables in each term and the variance of the degree of each term, respectively. Formally, given a polynomial inequality expressed as $\Phi(x_1, \dots, x_n) = \sum_{i=1}^k a_i \cdot x_1^{i_1} x_2^{i_2} \cdots x_n^{i_n} \leq 0$, the decoupling score (DC) and homogeneity score (HM) are computed as:
\begin{equation*}
\text{DC}(\Phi) = \frac{1}{k} \sum_{i=1} ^ k a_i (\sum_{j=1}^n \mathbb{I}(i_j > 0)), \quad \text{HM}(\Phi) = \frac{1}{k} \sum_{i=1}^k (d_i - \frac{1}{k}\sum_{j=1}^k d_j) ^ 2,
\end{equation*}
where $d_i = i_1 + \dots + i_n$ is the total degree of $i$-th term in the inequality.

It is worth noting that the homogeneity score and the decoupling score are not always consistent. In our running example, the newly generated goals in (\ref{eqn:example_e4}), (\ref{eqn:example_e5}), and (\ref{eqn:example_e6}) achieve homogeneity scores of 0.56, 0.55, and 0.80, and decoupling scores of 0.44, 0.48, and 0.66, respectively. As a result, we normalize the scores into $[0,1]$ and then compute the average score to filter the candidates.



\vspace{-0.3em}
\subsection{Neural Ranking}
\vspace{-0.3em}
Symbolic rules are not universally effective. Hence, we use these rules solely to eliminate unpromising proof goals, leaving top-\textit{k} candidates, for final selection by an LLM. Unlike symbolic filtering, which requires explicit definitions of inequality metrics, we use the chain-of-thought prompting~\citep{wei2022chain, chu2023survey} to query an LLM to rank the proof goals based on their proving difficulty. The detailed prompt for the running example is shown below.

             
{\small
\begin{tcolorbox}[colframe=black!75!white, colback=gray!10!white, boxsep=2.5pt, top=5pt, bottom=5pt, left=5pt, right=5pt, title={Prompt of neural ranking}]  
I am trying to prove the original inequality:
``
If $a, b, c$ are positive reals and $a^2 + b^2 + c^2 = 1$, then
$\frac{1}{a^2+2}+\frac{1}{b^2+2}+\frac{1}{c^2+2} \leq \frac{1}{3a^2+3b^2+c^2}+\frac{1}{3b^2+3c^2+a^2}+\frac{1}{3a^2+3c^2+b^2}
$'',
and transform it into the following inequalities.

(1) $\frac{1}{a ^ 2 + 2} + \frac{1}{b ^ 2 + 2} + \frac{1}{c^2 + 2} \leq  2 \sqrt{\frac{1}{a ^ 2 + 3b ^ 2 + 3c ^ 2} \cdot \frac{1}{b ^ 2 + 3a ^ 2 + 3c ^ 2}} + \frac{1}{c^2 + 3a^2 + 3b^2}$

(2) $\frac{1}{a ^ 2 + 2} + \frac{1}{b ^ 2 + 2} + \frac{1}{c^2 + 2} \leq \frac{9}{7a ^ 2 + 7 b ^ 2 + 7 c ^ 2}$

(3) $\frac{1}{a ^ 2 + 2} + \frac{1}{b ^ 2 + 2} + \frac{1}{c^2 + 2} \leq \frac{1}{3 - 2a ^ 2} + \frac{1}{3 - 2b ^ 2} + \frac{1}{3 - 2c ^ 2}$

\vskip 3pt

Your task is to rank the transformation results in a descent order. Note that

1. Please reason step by step; 

2. More meaningful transformation, i.e., reduce the proving difficulty, should be ranked higher; 

3. Put the index of selected inequality within \textbackslash\textbackslash boxed\{\{\}\}, e.g., \textbackslash\textbackslash boxed\{\{(1),(2),(3)\}\}.
\end{tcolorbox}
}
