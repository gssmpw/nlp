\section{Related Work}
\label{sec:related}

\textbf{Symbolic Tools for Mathematical Reasoning. }
Symbolic tools are essential for performing exact computations and formal reasoning in mathematics. Interactive theorem provers such as Isabelle~\citep{isabelle}, Coq~\citep{coq1996coq}, and Lean~\citep{de2015lean} enable users to build verifiable proofs manually, ensuring correctness through rigorous formal logic. These systems have been instrumental in formalizing and verifying significant mathematical theorems, including the Four Color Theorem~\citep{four} and the Kepler Conjecture~\citep{kepler}. Alternatively, some symbolic reasoning tools aim to solve mathematical problems without human intervention. Automated theorem provers like E~\citep{e} and Vampire~\citep{vampire} are designed to prove mathematical statements by systematically exploring possible proofs within a logical framework, particularly excelling in first-order logic. SMT solvers such as Z3~\citep{de2008z3} and CVC5~\citep{cvc5} determine the satisfiability of logical formulas with respect to background theories like arithmetic, bit-vectors, and arrays by integrating logical reasoning with theory-specific decision procedures. Computer algebra systems like Mathematica~\citep{Mathematica}, Maple~\citep{maple}, and SymPy~\citep{meurer2017sympy} manipulate mathematical expressions symbolically, supporting functionalities such as simplification, differentiation, integration, and equation solving. Despite their capabilities, these automated solvers struggle with competitive mathematical problems and often cannot generate human-readable reasoning steps.

\textbf{Machine Learning for Formal Theorem Proving. } 
There is a longstanding tradition of leveraging machine learning techniques to automate theorem proving~\citep{urban2008malarea, gauthier2017learning, zhang2021online, piotrowski2023machine, blaauwbroek2024graph2tac}.
Recently,
the emergence of LLMs has expanded the potential of these techniques, offering new opportunities for automating theorem proving~\citep{li2024survey, yang2024formal}. A line of research~\citep{gptf, wu2021int, pact, baldur, yang2023leandojo, deepseekprover, lin2025goedel} fine-tunes pre-trained language models on large-scale formal datasets to predict the tactics given a proof goal. Alternative approaches~\citep{jiang2023draft, lego, denigma, lyra, thakur2024an} integrate LLMs into structured prompt frameworks for formal theorem proving, leveraging information such as natural language proofs or feedback from interactive theorem provers. Some methods~\citep{gptf, htps, curriculum_learning, dt-solver, wei2024proving} also train LLMs as value networks to evaluate each subgoal and guide the proof search to completion. However, these methods primarily rely on LLMs to prune the search space, and their performance heavily depends on the quality and diversity of the training data, which may limit their generalizability to novel or more complex mathematical problems. 
A notable exception and closely related work to ours is AlphaGeometry~\citep{alphageometry}, which uses a language model only to predict auxiliary construction rules, after which its symbolic solver automatically enumerates all inference rules to generate the proof in a specialized language used in GEX~\citep{gex}. Compared to their approach, our neuro-symbolic framework generates step-by-step proofs in general-purpose formal language Lean and allows for integrating arbitrary symbolic tools that do not require direct proof generation. Furthermore, our focus on inequality problems spans a much wider range of complex mathematical skills than plane geometry problems. Our techniques could serve as a solid foundation for broader areas of mathematical research such as information theory~\citep{dembo1991information}, optimization~\citep{nesterov2013introductory}, and deep learning~\citep{roberts2022principles}, making it a suitable pathway to more advanced mathematical problems.
