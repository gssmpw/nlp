\section{Tactic Generation and Pruning}
\label{sec:pruning}
Compared to general theorem proving, the tactics used in inequality proofs are more well-structured: Common tactics can be categorized into two types, namely \emph{scaling} and \emph{rewriting}~\citep{lee2004topics, Bruce2018Inequalities}. Scaling refines the given inequality using a known inequality lemma, such as the arithmetic and geometric means (AM-GM) inequality, while rewriting transforms a given inequality into an equivalent form, such as multiplying both sides by two. Scaling and rewriting have distinct characteristics. The number of lemmas that can be used in scaling is finite, whereas the number of equivalent transformations in rewriting can be infinite, which leads to different strategies for tactic generation. Furthermore, unlike rewriting, scaling does not preserve the provability of the inequality, leading to different strategies for pruning the resulting subgoals.

Let's consider the inequality problem in Figure~\ref{fig:example} as a running example. To the best of our knowledge, the proof for this problem is not readily available online, and neither the most advanced LLMs (e.g., OpenAI {o3-mini} and DeepSeek-{R1}) nor existing CAD solvers can solve this inequality.



\vspace{-0.3em}
\subsection{Scaling Tactics}
\vspace{-0.3em}

Given an inequality lemma (e.g., the special case of the AM-GM inequality $u^2 + v^2 \ge 2uv$), we enumerate all possible ways to instantiate its arguments ($u$ and $v$) so that it matches a part of the current proof goal. This is a classical problem called e-matching~\citep{de2007efficient, moskal2008matching} and can be solved using existing symbolic tools~\citep{2021-egg}. However, it introduces a challenge due to the potentially large number of possible patterns. In our running example, there are a total of 162 possible pattern matches for the two-variable AM-GM inequality, including cases like $\{u := a, v := \sqrt{2}\}$, $\{u := 1, v := \frac{1}{\sqrt{a^2+2}}\}$.

Since scaling tactics refine the inequality goal, they may produce potentially incorrect subgoals (i.e., unprovable statements). For instance, applying the AM-GM inequality with the pattern $\{u := a, v := \sqrt{2}\}$ would transform the original inequality (\ref{eqn:example_e1}) into
\begin{tcolorbox}[enhanced, colback=black!5!white, colframe=black!75!white, top=2pt, bottom=2pt, left=2pt, right=2pt,] \begin{equation*} \tag{2}
\frac{1}{2\sqrt{2}a}+\frac{1}{2\sqrt{2}b}+\frac{1}{2\sqrt{2}c} \leq \frac{1}{6 a b+c^2}+\frac{1}{6 b c+a^2}+\frac{1}{6 c a+b^2}.
\end{equation*}
\end{tcolorbox}
However, this inequality does not hold when $a = b = c = \frac{\sqrt{3}}{3}$. Specifically, out of the 162 possible patterns for applying the AM-GM inequality in our running example, only six (i.e., $\{u := a, v := b\}$ and its symmetric or cyclical versions) yield correct deductions. Therefore, we propose using CAD to identify counterexamples in the new inequality goals and eliminate the scaling tactics that produce them. Moreover, since most scaling tactics are incorrect and thus induce counterexamples, CAD can efficiently detect and discard them using well-established heuristic strategies.


To further enhance the efficacy and efficiency of scaling tactic pruning, we propose several additional methods to complement CAD in searching for counterexamples:

\textbf{Quick Check via Test Cases. } When CAD identifies a counterexample for a scaling tactic, we store it as a ``test case''. For any subsequent scaling tactic, we will perform a quick check using this test case before invoking CAD to determine if the counterexample invalidates the tactic.

\textbf{Incorporating Numerical Optimization.} Since most inequality problems are differentiable, we also use gradient-based optimization as an effective alternative when CAD fails. Specifically, we rewrite the inequality $f(x) \leq g(x)$ into $\min_x [g(x) - f(x)]$, and then integrate Newton's method with simulated annealing to solve it~\citep{fu2016xsat, ma2019sampling, ni2023solving}.

\textbf{Utilization of Prior Knowledge.} Additionally, prior knowledge can be leveraged in scaling tactic pruning when the specific form of an inequality problem is known. For example, the inequalities generated and evaluated by AIPS~\citep{wei2024proving} are cyclically symmetric and sufficiently tight to achieve equality. Consequently, AIPS verifies the consistency of equality conditions across multiple tactics and discards subgoals that either violate these conditions or do not conform to the desired form. However, to accommodate a broader range of inequalities, our current framework does not incorporate such priors, even though this information could efficiently prune scaling tactics.



\vspace{-0.3em}
\subsection{Rewriting Tactics}
\vspace{-0.3em}
After pruning, only a few scaling tactics are applicable. For example, we may choose to apply the two-variable AM-GM inequality (with pattern $\{u := a, v := b\}$ and its cyclical versions) and derive a new proof goal from the initial goal (\ref{eqn:example_e1}), formulated as
\begin{tcolorbox}[enhanced, colback=black!5!white, colframe=black!75!white, top=-4pt, bottom=2pt, left=2pt, right=2pt,]
\begin{equation*} \label{eqn:example_e3} \tag{3}
\frac{1}{a^2+2}+\frac{1}{b^2+2}+\frac{1}{c^2+2} \leq \frac{1}{3a^2+3b^2+c^2}+\frac{1}{3b^2+3c^2+a^2}+\frac{1}{3a^2+3c^2+b^2}. 
\end{equation*}
\end{tcolorbox}


To solve the current proof goal, we need some equivalent transformations. For example, one may simplify the proof goal by replacing $\frac{1}{3a^2+3b^2+c^2}$ with $\frac{1}{3 - 2c^2}$ using the assumption $a^2 + b^2 + c^2 = 1$. However, figuring out effective ways to transform the goal needs creativity and cannot be readily automated through brute-force methods. Consequently, relying solely on symbolic pattern matching tends to be highly ineffective. Moreover, the argument space for rewriting tactics is typically infinite. For example, the assumption $a^2 + b^2 + c^2 = 1$ can be inserted at almost any point within the inequality, significantly enlarging the space of possible rewriting tactics.

To generate and prune the rewriting tactics, we propose directly prompting an LLM to generate candidates. Specifically, for different types of rewriting (e.g., rearrangement, simplification, denominator cancellation, etc.), we design tailored prompts that guide the LLM to transform the current proof goal into an appropriate form. 
The details of these prompts can be found in Appendix~\ref{app:exp_details}.
In this setting, tactic pruning is performed implicitly leveraging the algebraic intuition of LLMs, thereby effectively reducing the space of possible rewriting tactics.

Besides neural-guided rewriting, we incorporate two additional symbolic rewriting tactics: the sum-of-squares~\citep{chen2013supersums} and the tangent line~\citep{li2005using} tricks. The sum-of-squares trick attempts to transform the current expression into a summation of non-negative terms, e.g., proving $2x^2 + 2xy - 3x + y^2 + \frac{9}{4} \ge 0$ by recognizing $2x^2 + 2xy - 3x + y^2 + \frac{9}{4} = (x + y) ^ 2 + (x - \frac{3}{2})^2$. The tangent line trick is a powerful variable substitution technique that is frequently used to tackle inequality problems in math competitions.
