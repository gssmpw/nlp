\section{Conclusion}
\label{sec:conclusion}

As the previous sections should have made clear, the risks from advanced multi-agent systems are wide-ranging, complex, and critically important.
Crucially, they are also distinct from those posed by \textit{single agents} or \textit{less advanced} technologies, and have thus far been systematically underappreciated and understudied.
Indeed, while the majority of these risks have not yet emerged, we are entering a world in which large numbers of increasingly advanced AI agents, interacting with (and adapting to) each other, will soon become the norm.
We therefore urgently need to evaluate (and prepare to mitigate) these risks.
In order to do so, there are several promising directions that can be pursued \textit{now}. 
These directions can largely be classified as follows.

\begin{itemize}
    \item \textbf{Evaluation}: Today's AI systems are developed and tested in isolation, despite the fact that they will soon interact with each other.
    In order to understand how likely and severe multi-agent risks are, we need new methods of detecting how and when they might arise, such as:
    evaluating the cooperative capabilities, biases, and vulnerabilities of models; 
    testing for new or improved dangerous capabilities in multi-agent settings (such as manipulation, collusion, or overriding safeguards); 
    more open-ended simulations to study dynamics, selection pressures, and emergent behaviours;
    and studies of how well these tests and simulations match real-world deployments.  
    \item \textbf{Mitigation}: Evaluation is only the first step towards mitigating multi-agent risks, which will require new technical advances.
    While our understanding of these risks is still growing, there are promising directions that we can begin to explore now, such as:
    scaling peer incentivisation methods to state-of-the-art models;
    developing secure protocols for trusted agent interactions; 
    leveraging information design and the potential transparency of AI agents; and
    stabilising dynamic multi-agent networks and ensuring they are robust to the presence of adversaries.
    \item \textbf{Collaboration}: Multi-agent risks inherently involve many different actors and stakeholders, often in complex, dynamic environments.
    Greater progress can be made on these interdisciplinary problems by leveraging insights from other fields, such as:
    better understanding the causes of undesirable outcomes in complex adaptive systems and evolutionary settings;
    determining the moral responsibilities and legal liabilities for harms not caused by any single AI system;
    drawing lessons from existing efforts to regulate multi-agent systems in high-stakes contexts, such as financial markets;
    and determining the security vulnerabilities and affordances of multi-agent systems.
\end{itemize}

Of course, these recommendations are only a first step.
Even with the restricted scope of this report (see \Cref{sec:scope}), we faced an inevitable trade-off between breadth and depth.
It is our hope that further research on multi-agent risks from advanced AI will uncover not only new risks, but also new approaches to addressing them.
Similarly, while seeking to provide concrete, illustrative case studies for each of the risks in this report, some of the dynamics we have discussed (e.g., emergent agency; see \Cref{sec:emergent_agency}) remain challenging to test using contemporary systems, even in toy settings.
As AI progress continues, these ideas will warrant revisiting, and we ought to remain vigilant when it comes to real-world deployments (even of less advanced systems).

Finally, as we noted in \Cref{sec:introduction}, multi-agent risks from advanced AI are by no means the only risks posed by AI, and the perspective we take in this report is by no means the only approach to understanding these risks.
Moreover, this report almost entirely neglected the potential \textit{upsides} of advanced multi-agent systems:
greater decentralisation and democratisation of AI technologies;
assistance in cooperating and coordinating with others;
increased robustness, flexibility, and efficiency; 
novel approaches to solving alignment and safety issues in single-agent settings; 
and -- perhaps most importantly -- more widespread and evenly distributed benefits from AI. 
We hope that this report serves to complement earlier and adjacent research on understanding these challenges and opportunities.
