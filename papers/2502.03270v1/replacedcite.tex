\section{Related Work}
\begin{figure*}[!t]
\begin{center}
\centerline{\includegraphics[width=\linewidth]{figs/model.pdf}}
\vspace{-10pt}
\caption{Standard PVR-based visuo-motor policy learning via behaviour cloning (a) and our approach (b), which integrates \emph{Temporal Encoding (TE)} for temporal features (Section~\ref{ssec:method_tenc}) and \emph{Attentive Feature Aggregation (AFA)} for selective local feature attention (Section~\ref{ssec:method_abc}).}
\label{fig:model}
\end{center}
\vspace{-15pt}
\end{figure*}

\subsection{PVRs in Visuo-motor Policy Learning}
% Intro to use of PVRs in VMPL
In____, frozen PVRs were evaluated across simulated environments, outperforming models trained from scratch. %random features and  
Similarly,____ showed that the utility of PVRs depends on the policy training paradigm, with behaviour cloning and inverse reinforcement learning yielding robust results, while reinforcement learning exhibited higher variability. 
Furthermore,____ provided evidence that simulation experiments (\eg Metaworld____ benchmark) are indicative of real world performance for PVR-based trained policies. 

% Role of dataset in pre-training visual representations.
The dataset(s) used for pre-training plays a pivotal role in PVRs. 
While it was hypothesised that pre-training with video data featuring egocentric human-object interaction would be highly effective for learning features suitable for robot learning (due to their emphasis on object manipulation), research indicates that the diversity of images within the dataset is a more critical factor in successful robot learning____. 
Indeed, PVRs pre-trained on static datasets such as ImageNet____ have demonstrated competitive performance, underscoring the importance of dataset variability over modality. 

% On the robustness of policies trained with features from frozen PVRs. 
PVRs are favoured for their generalisation capabilities in vision tasks, but out-of-distribution generalisation remains challenging in policy deployment. 
____ analysed the impact of various perturbations on PVR-based policy generalisation, while____ identified correlations between generalisation performance and inherent model traits, such as ViTs' segmentation ability.
Conversely,____ found that learning from scratch with data augmentation can yield competitive results, while____ found that adapters____ can improve policy generalisation when training with diverse object instances. 
We focus on developing methods that achieve robustness to scene changes without relying on dataset augmentation, which can be prohibitively expensive in real-world robotics applications.
Particularly, our goal is to understand the reasons PVR-based policies struggle to generalise well and argue that there is more to be achieved with untouched frozen PVRs and that their full potential in visuo-motor policy learning is yet to be revealed. 
%%%%%%%%%% Task visualisation %%%%%%%%%%
\begin{figure*}[t]
\begin{center}
% \centerline{\includesvg[width=\linewidth]{figs/task_visualisation.svg}}
\includegraphics[width=\linewidth]{figs/task_visualisation.pdf} \\
\vspace{-10pt}
\caption{Visualisation of the 10 tasks used for evaluation. The first row illustrates representative scenes for all tasks, as seen in the frames from the expert demonstrations (in-domain). The second row shows how the scenes are modified by randomly altering the brightness, orientation and position of the light sourse. Similarly, the third row presents changes to the tabletop texture.}
\label{fig:task_vis}
\end{center}
\vspace{-15pt}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\subsection{Time-informed Policy Training} 
In PVR-based visuo-motor policy learning, the incorporation of temporal information remains underexplored. Augmentation with temporal perception can happen either at feature level or during training time. 

\textbf{Feature Augmentation}. While early fusion methods, such as stacking multiple frames before encoding____, are common in training visual encoders from scratch, late fusion-processing frames individually and stacking their representations____ has shown superior performance with fewer encoder parameters. 
Recent work____ highlights that naive feature concatenation in latent space is insufficient; instead, approaches like FLARE____ incorporate sequential embeddings and their differences, inspired by optical flow techniques. 
Nevertheless, concatenating sequential embeddings as input to policy networks has become standard in visuo-motor policy learning____ and state-of-the-art generative policies____. 
However, a gap remains in leveraging PVR features, which are primarily designed for vision tasks, within this temporal framework.

\textbf{Loss Function Augmentation}. A major limitation of many PVRs is their inherit lack of temporal perception, as most are pre-trained on static 2D image datasets. 
Temporal perception can be added by employing loss functions that enforce temporal consistency during training (\eg R3M____ and VIP____), when training with video data.  
However, there is no clear consensus on the superiority of this approach compared to alternatives like MIM (\eg MVP____ and VC-1____). 
This disparity suggests that existing temporal modelling strategies may be insufficient in isolation. 

In subsequent experiments, we evaluate PVRs trained with temporal information and demonstrate that methods trained with a time-agnostic paradigm achieve comparable performance.
We hypothesise that this limitation arises from a lack of task-completion perception, which we address by incorporating positional encoding-a fundamental mechanism in many machine learning approaches.
This straightforward operation has been instrumental in the success of Transformers____, implicit spatial representations____, and diffusion models____.

\subsection{Task-Relevant Feature Extraction}
Downstream vision tasks often make use of the output features of PVRs. 
However, these features typically encode a broad range of scene information, much of which may be irrelevant to the specific task. 
To address this challenge, attentive probing____ has emerged as a popular evaluation technique, leveraging local tokens. 
This approach leverages a cross-attention layer with a trainable query token, treating the local features from PVRs as a sequence of key-value pairs. 
Unlike traditional evaluation methods such as linear probing, attentive probing has shown significantly different vision evaluation outcomes, particularly with PVRs trained using MIM approaches (\eg MAE____), where features, such as the CLS token, often include irrelevant information.
Similarly, in robot learning, task-relevant signals like joint angles may correspond to particular image regions, with unrelated cues acting as distractions. 
By prioritizing task-relevant signals, we show that attentive probing enhances task performance, especially in out-of-distribution scenarios.