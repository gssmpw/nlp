
\begin{abstract}
Text-conditioned image generation has gained significant attention in recent years and are processing increasingly longer and comprehensive text prompt. 
In everyday life, dense and intricate text appears in contexts like advertisements, infographics, and signage, where the integration of both text and visuals is essential for conveying complex information. 
However, despite these advances, the generation of images containing long-form text remains a persistent challenge, largely due to the limitations of existing datasets, which often focus on shorter and simpler text. 
To address this gap, we introduce \DatasetName, a novel dataset specifically designed to evaluate long-text rendering in text-conditioned image generation.
Our dataset consists of 5 million long-text generated and collected images across diverse data types, enabling comprehensive evaluation of large-scale generative models on long-text image generation. 
We further curate 3000 human-improved test set \EvalDatasetName~ across 3 data domains, establishing one of the most extensive  benchmarks for text-conditioned generation.
Evaluations suggest that the \EvalDatasetName benchmarks present significant challenges even for the most advanced proprietary models (e.g. GPT4o with DallE-3), while their open-source counterparts show an even larger performance gap.
These evidences position \DatasetName as a valuable dataset for training and evaluating future-generation text-conditioned image generation models.
Datasets are released.
\end{abstract}