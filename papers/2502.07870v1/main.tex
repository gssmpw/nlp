%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage[accepted]{utils/icml2025}
% \usepackage{utils/icml2025}
% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

\input{utils/preamble}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}



% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{\DatasetName: A Large-scale Dataset for Dense Text Image Generation}

\begin{document}

\twocolumn[
\icmltitle{\DatasetName: A Large-scale Dataset for Dense Text Image Generation}

\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Alex Jinpeng Wang}{csu}
\icmlauthor{Dongxing Mao}{csu}
\icmlauthor{Jiawei Zhang}{nuc}
\icmlauthor{Weiming Han}{nuc}
\icmlauthor{Zhuobai Dong}{csu}
\icmlauthor{Linjie Li}{ms}
\icmlauthor{Yiqi Lin}{nus}
\icmlauthor{Zhengyuan Yang}{ms}
\icmlauthor{Libo Qin}{csu}
\icmlauthor{Fuwei Zhang}{nuc}
\icmlauthor{Lijuan Wang}{ms}
\icmlauthor{Min Li}{csu}
\\
\url{https://textatlas5m.github.io}{}
\end{icmlauthorlist}

% \icmlcorrespondingauthor{Alex Jinpeng Wang}{jinpengwang@u.nus.edu}

\icmlaffiliation{csu}{Central South University}
\icmlaffiliation{nuc}{North University of China}
\icmlaffiliation{nus}{National University of Singapore}
\icmlaffiliation{ms}{Microsoft}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Long Text Rendering Dataset}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.


\input{sections/0_Abstract}

\input{sections/1_Introduction}

% \input{tables/dataset_statics}


\input{sections/2_RelatedWorks}


\input{sections/3_Method}


\input{sections/4_Experiments}


\input{sections/5_Conclusion}



% \clearpage


% \section*{Impact Statement}

% This work addresses the critical challenge of rendering long-form text in text-conditioned image generation, introducing \DatasetName as a novel dataset and benchmark for evaluating and improving models in this domain.
% By demonstrating the performance gaps of both proprietary and open-source models, this benchmark sets a new standard for evaluating future generation text-conditioned image-generation systems, driving innovation and accountability in the field.


% % By providing comprehensive evaluation resources, including 5M long-text images and a curated human-annotated benchmark across various fine-grained categories, this benchmark advances the understanding of model performance on complex and diverse long-text inputs.
% The potential societal impacts of this work are significant. On the positive side, improving long-text rendering capabilities can enhance accessibility and usability in applications such as video content creation, digital media production, and educational tools, empowering users to generate text-rich, coherent visual content from text inputs. However, we acknowledge ethical considerations, such as the potential misuse of this technology for generating deceptive or harmful content. 
% These risks highlight the importance of responsible development and deployment of text-conditioned generation models.






% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{main}
\bibliographystyle{utils/icml2025}

\input{Appendix/appendix}

\end{document}
