\section{Related Work}
Our work builds on several lines of research: exploring the role of text with visualizations, visualization and text systems, and image and text authoring interfaces.

\subsection{The role of text with visualizations}
The interplay between text and visual elements in data visualization has been a significant area of interest with increased advocacy for treating text as co-equal to visualization~\cite{stokesgive, lundgard2021accessible}. Kim et al.~\cite{kim2021towards} conducted a study to understand how readers integrate charts and captions in line charts. The study findings indicated that when both the chart and text emphasize the same prominent features, readers take away insights from both modalities. Their research underscores the importance of coherence between visual and textual elements and how external context provided by captions can enhance the reader's comprehension of the chart's message. Building on these insights, Lundgard and Satyanarayan~\cite{lundgard2021accessible} proposed a four-level model for content conveyed by natural language descriptions of visualizations. Their model delineates semantic content into four distinct levels: elemental and encoded properties (Level 1), statistical concepts (Level 2), perceptual and cognitive phenomena (Level 3), and contextual insights (Level 4).

Focusing on the role of textual annotations in visualization, Stokes et al.~\cite{stokes2022striking} observed that readers favored heavily annotated charts over less annotated charts or text alone. This preference highlights the added value of textual annotations in aiding data interpretation, with specific emphasis on how different types of semantic content impact the takeaways drawn by readers. Further contributions by Quadri et al.~\cite{quadri2024you} and Fan et al.~\cite{fan2024understanding} explored high-level visualization comprehension and the impact of text details and spatial autocorrelation on reader takeaways in thematic maps. These studies collectively underline the critical role of textual elements in shaping viewer perceptions, understanding, and accessibility of visual data. Ottley et al.~\cite{ottley2019curious} and Stokes et al.~\cite{stokes2023role} have also contributed to this body of research, focusing on how annotations influence perceptions of bias and predictions, reinforcing the multifaceted impact of text on visual data interpretation.

Our work further explores how text and charts can be better aligned with one another by offering a mixed-initiative authoring interface. Specifically, \pluto~allows leveraging both direct manipulation interactions and user-drafted text to generate recommendations for communicative text and chart design. Furthermore, \pluto's text recommendations explicitly incorporate Lundgard and Satyanarayan's model~\cite{lundgard2021accessible} for semantic information conveyed by visualization descriptions.
In doing so, the system ensures that the generated text has good semantic coverage and structure (e.g., generated descriptions start by conveying the chart's encodings and then list high-level trends) and is appropriate for the intended communicative use (e.g., the semantic information conveyed by titles is different from descriptions accompanying a chart or annotations on the chart).


\subsection{Visualization and text systems}

The integration of visualization and text has led to the development of various systems designed to facilitate the creation, interpretation, and enhancement of data visualizations with textual elements. He et al.~\cite{he2024leveraging} surveyed the leveraging of large models for crafting narrative visualizations, highlighting the potential of AI in supporting the narrative aspect of data visualization. This is complemented by AutoTitle, an interactive title generator for visualizations~\cite{liu2023autotitle}, and Vistext, a benchmark for semantically rich chart captioning~\cite{tang2023vistext}. VizFlow demonstrates the effectiveness of facilitating author-reader interaction by dynamically connecting text segments to corresponding chart elements to help enrich the storytelling experience~\cite{sultanum2021}. This body of research highlights the need for tools to support more nuanced integration of text and visualization.

Supporting the co-authoring of text and charts, Latif et al. introduced Kori~\cite{latif2021kori}, an interactive system for synthesizing text and charts in data documents, emphasizing the seamless integration of visual and textual data for enhanced communication.
\new{CrossData~\cite{chen2022crossdata} presents an interactive coupling between text and data in documents, enabling actions based on the document text and adjusting data values in the text through direct manipulation on the chart.
Such systems illustrate the potential for the bidirectional linking between text and charts to assist rich authoring of data-driven narratives.
}
Furthermore, systems like EmphasisChecker~\cite{kim2023emphasischecker}, Intentable~\cite{choi2022intentable}, Chart-to-text~\cite{obeid2020chart}, DataDive~\cite{kim2024datadive},
\new{InkSight~\cite{lin2023inksight}},
and FigurA11y~\cite{singh2024figura11y} focus on guiding chart and caption creation, supporting readers' contextualization of statistical statements, and assisting in writing scientific alt text. Recent work like SciCapenter supports the composition of scientific figure captions using AI-generated content and quality ratings \cite{hsu2024scicapenter}.
DataTales~\cite{sultanum2023datatales} is another example of a recent system using a large language model for authoring data-driven articles, indicating the growing interest in AI-assisted data storytelling.
These systems collectively illustrate the expanding scope of text integration into visualization, from enhancing data document creation to improving accessibility and data-driven communication. Reviewing the aforementioned tools and the use of generative AI for visualization more broadly, Basole and Major~\cite{basole2024generative} discuss how generative AI methods and tools offer creativity assistance and automation within the visualization workflow, specifically highlighting a shift towards ``human-led AI-assisted'' paradigms, where generative AI not only augments the creative process but also becomes a co-creator.

Aligned with this paradigm shift, \pluto~adopts a mixed-initiative approach that leverages the capabilities of generative AI to help create semantic alignment between the chart and its corresponding text for effective data-driven communication.
However, \pluto~differs from existing chart-and-text authoring tools in three significant ways.
First, going beyond existing systems that primarily leverage unimodal information from the chart to generate text, \pluto~supports multimodal authoring combining information from both the chart (including any direct interactions with marks) and user-drafted text.
Furthermore, unlike prior tools that focus exclusively on generating complete descriptions/captions or titles, \pluto's recommendations can be leveraged in flexible ways to author not only titles and descriptions but also more fine-grained annotations and sentence completions. Second, while existing tools primarily recommend text for a given chart, \pluto's recommendations are bidirectional.
Specifically, the system suggests chart design changes like sorting or adding embellishments based on the authored text, resulting in artifacts that more clearly communicate takeaways via a combination of text and charts. Lastly, unlike existing tools that primarily rely on pre-trained knowledge in generative AI models, \pluto's recommendations are grounded in a theoretical research-based model of semantic information conveyed in visualization text~\cite{lundgard2021accessible}, ensuring the generated text covers the appropriate level of detail and is effective for communication \emph{alongside} the chart.