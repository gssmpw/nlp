%\begin{table*}[ht]
%\centering
%\scalebox{0.77}{
%\begin{tabular}{|c|c|l|l|c|cccc|cc|cc|c|}
%\hline
%\multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Time\\ Step \end{tabular}} & &Procedure & Threat Models & \multicolumn{1}{c|}{Clean} & \multicolumn{1}{c}{$\ell_2$} & \multicolumn{1}{c}{StAdv} & \multicolumn{1}{c}{$\ell_\infty$} & \multicolumn{1}{c|}{Recolor} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Avg\\ (known)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Union\\ (known)\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Avg\\ (all)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Union\\ (all)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Time\\ (hrs)\end{tabular}} \\ \hline
%\multirow{ 2}{*}{0} & \parbox[t]{2mm}{\multirow{2}{*}{\rotatebox[origin=c]{90}{Init}}}& AT & $\ell_2$ & \textbf{91.17} & \cellcolor[HTML]{B7E1CD}69.7 & 2.08 & 28.41 & 44.94 & 69.7 & 69.7 & 36.28 & 1.24 & 8.68 \\ %16.69
%& & AT + ALR ($\lambda=1$) & $\ell_2$ & 89.43 & \cellcolor[HTML]{B7E1CD}\textbf{69.84} & \textbf{48.23} & \textbf{34.00} & \textbf{65.46} & \textbf{69.84} & \textbf{69.84} & \textbf{54.38} & \textbf{31.27} & 17.17\\ %22.29
%\hline 
%\multirow{ 8}{*}{1} & \parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{Scratch}}} & AVG & $\ell_2$, StAdv & \bf{87.74} & \cellcolor[HTML]{B7E1CD}62.17 & \cellcolor[HTML]{B7E1CD}50.92 & 17.17 & 45.47 & 56.55 & 47.55 & 43.93 & 15.92 & 23.72\\ %47.44
%& & MAX & $\ell_2$, StAdv & 86.18 & \cellcolor[HTML]{B7E1CD}58.65 & \cellcolor[HTML]{B7E1CD}57.21 & 11.21 & 43.07 & 57.93 & 51.72 & 42.54 & 11.03 &  23.69 \\ %47.37
%& & Random & $\ell_2$, StAdv & 84.91 & \cellcolor[HTML]{B7E1CD}57.77 & \cellcolor[HTML]{B7E1CD}59.74 & 14.05 & 44.88 & 58.76 & 52.15 & 44.11 & 13.68 & 10.92 \\ %9.36
%\cdashline{2-14}
% & \parbox[t]{2mm}{\multirow{5}{*}{\rotatebox[origin=c]{90}{Finetune}}}& FT MAX &  $\ell_2$, StAdv & 83.73 & \cellcolor[HTML]{B7E1CD}57.07 & \cellcolor[HTML]{B7E1CD}58.67 & 12.51 & 49.03 & 57.87 & 51.32 & 44.32 & 12.36 & 4.00 \\
 %& & FT Croce & $\ell_2$, StAdv & 84.7 & \cellcolor[HTML]{B7E1CD}57.88 & \cellcolor[HTML]{B7E1CD}54.27 & 14.38 & 51.08 & 56.07 & 48.13 & 44.4 & 13.8 & 2.40\\
 %& & FT Single & $\ell_2$, StAdv &  80.89 & \cellcolor[HTML]{B7E1CD}45.45& \cellcolor[HTML]{B7E1CD}54.5 & 6.09 & 41.98 & 49.98 & 41.05 & 37.0 & 5.87 & 2.78 \\
 %& & FT Single + ALR & $\ell_2$, StAdv & \underline{87.24} & \cellcolor[HTML]{B7E1CD}\textbf{\underline{62.22}}& \cellcolor[HTML]{B7E1CD}61.5 & \textbf{\underline{21.4}} & \textbf{\underline{70.87}} & 61.86 & 55.04 & \textbf{\underline{54.0}} & \textbf{\underline{21.14}} & 4.24 \\
%   & & FT Croce + ALR & $\ell_2$, StAdv & 86.03 & \cellcolor[HTML]{B7E1CD}59.18 &\cellcolor[HTML]{B7E1CD}\textbf{\underline{65.14}} & 15.36  & 63.31 & \textbf{\underline{62.16}}& \textbf{\underline{55.83}} & 50.75 & 15.29 & 3.47 \\

%\hline

%\multirow{ 8}{*}{2}&\parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{Scratch}}} & AVG & $\ell_2$, StAdv, $\ell_\infty$ & 85.98 & \cellcolor[HTML]{B7E1CD}67.60 & \cellcolor[HTML]{B7E1CD}45.81 & \cellcolor[HTML]{B7E1CD}\textbf{42.39} & 62.43 & 51.93 & 34.05 & 54.56 & 33.39 & 33.12 \\
%& & MAX & $\ell_2$, StAdv, $\ell_\infty$ & 84.54 & \cellcolor[HTML]{B7E1CD}54.87 & \cellcolor[HTML]{B7E1CD}52.33 & \cellcolor[HTML]{B7E1CD}38.23 & 55.90 & 48.48 & 35.25 & 50.33 & 34.08 & 45.84 \\
%& &Random & $\ell_2$, StAdv, $\ell_\infty$ & 84.63 & \cellcolor[HTML]{B7E1CD}67.46 & \cellcolor[HTML]{B7E1CD}47.35 & \cellcolor[HTML]{B7E1CD}42.12 & 63.61 & 52.31 & 35.46 & 55.13 & 34.79 & 11.03 \\ \cdashline{2-14}
 %&\parbox[t]{2mm}{\multirow{5}{*}{\rotatebox[origin=c]{90}{Finetune}}} &FT MAX & $\ell_2$, StAdv, $\ell_\infty$ & 83.16 &  \cellcolor[HTML]{B7E1CD}65.63 &  \cellcolor[HTML]{B7E1CD}56.68 &  \cellcolor[HTML]{B7E1CD}36.9 & 65.69 & 53.07 & 35.18 & 56.23 & 34.83 &	5.62 \\

 %& &FT Croce & $\ell_2$, StAdv, $\ell_{\infty}$ & 85.05 &  \cellcolor[HTML]{B7E1CD}67.3 &  \cellcolor[HTML]{B7E1CD}48.07 &  \cellcolor[HTML]{B7E1CD}33.38 & 62.52 & 49.58 & 28.96 & 52.82 & 28.63 & 2.27 \\ 

  %& &FT Single & $\ell_2$, StAdv, $\ell_{\infty}$ & 87.99 & \cellcolor[HTML]{B7E1CD}\textbf{\underline{70.53}} & \cellcolor[HTML]{B7E1CD}11.17 & \cellcolor[HTML]{B7E1CD}41.63 & 63.46 &41.11 & 7.95 & 46.7 & 7.74  & 1.57 \\
 %& &FT Single + ALR & $\ell_2$, StAdv, $\ell_{\infty}$ & \textbf{\underline{88.74}} & \cellcolor[HTML]{B7E1CD}69.15 & \cellcolor[HTML]{B7E1CD}47.33 & \cellcolor[HTML]{B7E1CD}\underline{42.08} & 68.62 & 52.85 & \textbf{\underline{36.66}} & 56.8 & \textbf{\underline{36.62}} & 2.26 \\
 %& &FT Croce + ALR & $\ell_2$, StAdv, $\ell_{\infty}$ & 86.57 & \cellcolor[HTML]{B7E1CD}67.99 & \cellcolor[HTML]{B7E1CD}\textbf{\underline{61.55}} & \cellcolor[HTML]{B7E1CD}36.59 & \textbf{\underline{72.16}} & \textbf{\underline{55.38}} & 35.68 & \textbf{\underline{59.57}} & 35.52 & 2.87 \\

 %\hline

%\multirow{ 8}{*}{3} &\parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{Scratch}}}& AVG & $\ell_2$, StAdv, $\ell_\infty$, Recolor & 87.77 & \cellcolor[HTML]{B7E1CD}\textbf{68.55} & \cellcolor[HTML]{B7E1CD}39.55 & \cellcolor[HTML]{B7E1CD}\textbf{41.97} & \cellcolor[HTML]{B7E1CD}67.93 & 54.5 & 30.39 & 54.5 & 30.39 & 51.55 \\
%& &MAX & $\ell_2$, StAdv, $\ell_\infty$, Recolor & 84.3 & \cellcolor[HTML]{B7E1CD}57.62 & \cellcolor[HTML]{B7E1CD}52.3 & \cellcolor[HTML]{B7E1CD}41.69 & \cellcolor[HTML]{B7E1CD}65.1 & 54.18 & \textbf{37.44} & 54.18 & \textbf{37.44} & 61.09 \\
%& &Random & $\ell_2$, StAdv, $\ell_\infty$, Recolor & 86.32 & \cellcolor[HTML]{B7E1CD}65.87 & \cellcolor[HTML]{B7E1CD}47.82 & \cellcolor[HTML]{B7E1CD}35.04 & \cellcolor[HTML]{B7E1CD}68.35 & 54.27 & 30.76 & 54.27 & 30.76 & 13.15 \\ \cdashline{2-14}
%&\parbox[t]{2mm}{\multirow{5}{*}{\rotatebox[origin=c]{90}{Finetune}}}&FT MAX & $\ell_2$, StAdv, $\ell_{\infty}$, Recolor & 83.64 & \cellcolor[HTML]{B7E1CD}66.21 & \cellcolor[HTML]{B7E1CD}57.53 & \cellcolor[HTML]{B7E1CD}\underline{37.77} & \cellcolor[HTML]{B7E1CD}69.32 & 57.71 & \underline{36.02} & 57.71 & \underline{36.02} & 8.45 \\
%& &FT Croce & $\ell_2$, StAdv, $\ell_{\infty}$, Recolor & 86.64 & \cellcolor[HTML]{B7E1CD}\underline{68.76} & \cellcolor[HTML]{B7E1CD}44.81 & \cellcolor[HTML]{B7E1CD}36.02 & \cellcolor[HTML]{B7E1CD}68.05 & 54.41 & 29.44 & 54.41 & 29.44 & 2.34 \\
 %  & &FT Single & $\ell_2$, StAdv, $\ell_{\infty}$, Recolor &  90.41& \cellcolor[HTML]{B7E1CD}66.47 & \cellcolor[HTML]{B7E1CD}3.93 & \cellcolor[HTML]{B7E1CD}29.6& \cellcolor[HTML]{B7E1CD}69.03 & 42.26 & 2.49 & 42.26 & 2.49 & 3.11 \\
 %& &FT Single + ALR & $\ell_2$, StAdv, $\ell_{\infty}$, Recolor & \textbf{\underline{90.45}} & \cellcolor[HTML]{B7E1CD}61.58 & \cellcolor[HTML]{B7E1CD}25.77 & \cellcolor[HTML]{B7E1CD}27.43 & \cellcolor[HTML]{B7E1CD}69.26 & 46.01 & 19.2 & 46.01 & 19.2 & 4.24 \\
 % & &FT Croce + ALR & $\ell_2$, StAdv, $\ell_{\infty}$, Recolor &87.62 & \cellcolor[HTML]{B7E1CD}68.14 & \cellcolor[HTML]{B7E1CD}\underline{\textbf{58.5}} & \cellcolor[HTML]{B7E1CD}36.39 & \cellcolor[HTML]{B7E1CD}\textbf{\underline{72.35}} & \textbf{\underline{58.85}} & 34.92 & \textbf{\underline{58.85}} & 34.92 & 3.35 \\
%\hline
%\end{tabular}}
%\vspace{-5pt}
%\caption{\textbf{Continual Robust Training on CIFAR-10.} The learner knows about $\ell_2$ attacks and over time, is sequentially introduced to StAdv, $\ell_\infty$, and ReColor attacks. We report clean accuracy, accuracy on individual attacks, and average and union accuracies.  The ``Threat Models" column specifies known attacks and accuracies on these attacks are highlighted in green. Initial adversarial training occurs at time $t=0$, and the model is updated either through training from scratch or through fine-tuning the model at the previous time step.
%The ``Avg (known)" and ``Union (known)" columns represent average and union accuracies on known attacks while ``Avg (all)" and ``Union (all)" columns performance across all four attacks.  Additionally, we report non-cumulative training times in the ``Time" column.  Best performance for each time step out of all procedures are \textbf{bolded}, while best performance across fine-tuning based procedures \underline{underlined}.
%\anote{push this table to next page, move the last sentence to the beginning, add info about the green highlighting}}
%\label{tab:main_results_cifar}
%\vspace{-10pt}
%\end{table*}


%\begin{figure*}[t!]
%    \centering
%    \begin{subfigure}[t]{0.5\textwidth}
%        \centering
%        \includegraphics[width=0.95\textwidth]{figures/imagenette_finetune_froml2_union.pdf}
%        \vspace{-10pt}
%        \caption{Adversarial $\ell_2$ regularization\\ ($\lambda=0.5$)}
%    \end{subfigure}%
%    \begin{subfigure}[t]{0.5\textwidth}
%        \centering
%        \includegraphics[width=0.95\textwidth]{figures/imagenette_finetune_fromuniform_union.pdf}
%        \vspace{-10pt}
%        \caption{Uniform Regularization\\
%        ($\sigma=2,\lambda=1$)}
%    \end{subfigure}
%    \caption{\textbf{Ablation 1: Change in union robust accuracy after fine-tuning from checkpoint initially trained with regularization.}  We fine-tune models on Imagenette across 144 pairs of initial attack and new attack.  The initial attack corresponds to the row of each grid and new attack corresponds to each column.  Values represent differences between the accuracy measured on a model \emph{fine-tuned with and without regularization}.  Gains in accuracy of at least 1\% are highlighted in green, while drops in accuracy of at least 1\% in red. Further results are in Appendix~\ref{app:init_train}.}
%    \label{fig:fine-tune_abl_main_text_from_init}
%    \vspace{-10pt}
%\end{figure*}
%\sophie{add discussion of feature reg vs logit reg} \christian{added to training procedure}
In this section, we empirically demonstrate that using regularization in CRT helps improve robustness when attacks are introduced sequentially.  This section is organized as follows: (i) experimental setup \S (\ref{sec:exp_setup}), (ii) overall results for using regularization in CRT (\S \ref{sec:car_reg}), (iii) ablations in initial training (\S \ref{sec:init_train_impact}) and (iv) ablations in fine-tuning (\S \ref{sec:fine-tuning_impact}).% of the CRT pipeline.  \anote{shorten by using inline bullets like i) experimental setup, ii) overall results using RCRT, ...}
%We begin by looking at the impact of regularization on different parts of the CRT pipeline; we discuss impact on initial training in \S\ref{sec:init_train_impact} and iterative fine-tuning in \S\ref{sec:fine-tuning_impact}.  We then analyze the performance of fine-tuning with existing approaches \citep{croce2022adversarial,TB19} within a CRT framework, and investigate how regularization within both stages of CRT performs on sequences of up to 4 attacks.
\vspace{-5pt}
\subsection{Experimental setup}
\label{sec:exp_setup}

\noindent
\textbf{Datasets. } We experiment with CIFAR-10, CIFAR-100 \citep{krizhevsky2009learning}, and ImageNette \citep{howardimagenette}, a 10-class subset of ImageNet \citep{deng2009imagenet}.%and 10-class and 100-class ImageNet subsets\citep{deng2009imagenet} (ImageNette \citep{howardimagenette} and ImageNet-100 respectively).

\noindent
\textbf{Architectures. } For CIFAR-10 and CIFAR-100, we use WideResnet-28-10 (WRN-28-10) architecture \citep{zagoruyko2016wide} and ResNet-18 for ImageNette. % For Imagenet subsets, we use ResNet architectures \citep{he2016deep}; we use ResNet-18 for ImageNette and Resnet-50 for ImageNet-100.

\noindent
\textbf{Attacks. }We include results for $\ell_2$, $\ell_\infty$, StAdv \citep{XiaoZ0HLS18}, ReColor attacks \citep{LaidlawF19}, and the 8 core attacks of Imagenet-UA \citep{kaufmann2019testing}. For $\ell_2$ attacks, we use a bound $\epsilon= 0.5$ for CIFAR datasets and $\epsilon=1$ for ImageNette.  For $\ell_2$ attacks, we use $\epsilon = \frac{8}{255}$, and for StAdv and ReColor attacks, we use the same bounds as used in their original papers \citet{XiaoZ0HLS18} ($\epsilon=0.05$) and \citet{LaidlawF19} ($\epsilon=0.06$) respectively. For ImageNet-UA attacks, we use the \emph{medium distortion} strength bounds used by \citet{kaufmann2019testing}.  For experiments investigating the impact of regularization in the fine-tuning step of CRT (\S\ref{sec:fine-tuning_impact}), we include results for fine-tuning to the same attack type but with larger attack bounds.  For these experiments, the larger bounds are given by $\epsilon = 1$ for $\ell_2$, $\epsilon=\frac{12}{255}$ for $\ell_\infty$, $\epsilon=0.07$ for StAdv, $\epsilon=0.08$ for ReColor, and high distortion strength bounds for ImageNet-UA attacks. 

\noindent\textbf{Training from scratch baselines. }We consider the following baselines for training from scratch:
\begin{itemize}
    %\item \textit{Adversarial Training (AT)}  \citep{madry2017towards}: when only a single attack is known, we consider adversarial training a baseline for comparison.  We also consider using this AT model as the initialization for different fine-tuning techniques within a CRT framework.
    \item \textit{Training with AVG and MAX objectives} \citep{TB19}: \citet{TB19} propose two different training objectives, AVG ($L_{\text{AVG}}(h, t) = \frac{1}{m|K(t)|} \sum_{i=1}^{m} \sum_{P_C \in K(t)} \ell(h(P_C(x_i, y_i)), y_i)$) and MAX ($L_{\text{MAX}}(h, t) = \frac{1}{m} \sum_{i=1}^{m} \max_{P_C \in K(t)} \ell(h(P_C(x_i, y_i)), y_i)$), for robustness against multiple known attacks.
    \item \textit{Randomly sampling attacks} \citep{madaan2020learning}: 
    AVG and MAX require generating adversarial examples with all attacks for each image. For a more efficient baseline, we consider randomly sampling an attack for each batch for use in adversarial training.
\end{itemize}

\noindent
\textbf{CRT Baselines. }For CRT, we use PGD adversarial training (AT) \citep{madry2017towards} for initial training and then fine-tune the model using several different fine-tuning strategies:
\begin{itemize}
    \item \textit{MAX objective fine-tuning} (FT-MAX) \citep{TB19}: We use the MAX objective for fine-tuning when a new attack is introduced.
    \item \textit{\citet{croce2022adversarial} fine-tuning} (FT Croce): \citet{croce2022adversarial} introduce a fine-tuning technique for use with $\ell_{\infty}$ and $\ell_1$ attacks which we \emph{generalize to training with arbitrary attacks}. This approach samples a single attack per batch. The probability that an attack $P_C$ is sampled is given by $\frac{\text{err}(P_C)}{\sum_{P \in K(t)} \text{err}(P)}$ where $\text{err}(P)$ denotes the running average of robust loss with respect to attack $P$ computed across batches of each attack.%sampling of different attack types during training such that only 1 attack is used per batch, making it more efficient than MAX fine-tuning for which all attacks are generated per batch.  The sampling procedure is based on computing a running average across batches of errors with respect to each attack.  Each attack $P_C$ is sampled with probability $\frac{\text{err}(P_C)}{\sum_{P \in K(t)} \text{err}(P)}$ where $\text{err}(P)$ denotes the running average of loss computed across batches of each attack.
    \item \textit{Single attack fine-tuning} (FT Single): We also consider fine-tuning with \emph{only the newly introduced attack}, allowing us to determine the extent to which previous attacks are forgotten. The previous two fine-tuning techniques involve replaying previous attacks.
\end{itemize}
We then investigate incorporating regularization into the initial training and fine-tuning phases of CRT.

\noindent
\textbf{Training and Fine-tuning Procedures. } During training, we use 10-step Projected Gradient Descent~\cite{madry2017towards} to generate adversarial examples. For the regularization terms (\cref{subsec: methods}), VR and ALR use single step optimization to reduce time overhead, while UR and GR use $\sigma=2$ and $\sigma=0.2$, respectively.  Results for additional values of $\sigma$ are in \cref{app:random_noise_var_abl}. We train models for 100 epochs for initial training and 10 epochs  for fine-tuning (results with 25 epochs in \cref{app:exp_seq}). We include additional details about the training procedure in \cref{app:exp_setup}.%We train models using adversarial training with and without regularization (\S\ref{sec:regularization}) with 10-step PGD adversarial training for $\ell_p$ attacks \citep{madry2017towards}.  We similarly use 10-steps to generate adversarial examples for adversarial training with non-$\ell_p$ attack types. For variation regularization and adversarial $\ell_2$ regularization, we optimize the objective using iterative optimization (in the same manner in which adversarial examples are generated for each attack type) with a single iteration to reduce the time overhead of training.  For uniform regularization and gaussian regularization, we use $\sigma=2$ and $\sigma=0.2$, respectively.  We include results for additional $\sigma$ in Appendix \ref{app:random_noise_var_abl}. When performing initial training, we train models for 100 epochs and when performing fine-tuning, we train models for 10 epochs (we also include results for other numbers of epochs in Appendix \ref{app:exp_seq}. We include additional details about the training procedure in Appendix \ref{app:exp_setup}.

%For the purposes of our experiments, we modified the regularization terms from Section~\ref{sec: theory_methods} to penalize distance in the \textit{logit} space (i.e. the output of $h$) rather than the \textit{feature} space (i.e. the output of $g$). We found that this change led to more stable training and better robust performance, likely owing to the high-dimensional nature of the internal representations. See Table~\ref{tab:main_results_cifar_epochs} in the Appendix for an ablation on the choice of layer used in regularization.

\noindent
\textbf{Evaluation Attacks and Metrics. } Our main results in Table \ref{tab:main_results_cifar} and additional ones in Appendix \ref{app:exp_seq} use full AutoAttack \citep{croce2020reliable} for evaluating $\ell_p$ robustness. For ablations, we restrict to APGD-T and FAB-T from AutoAttack to reduce evaluation time.  We use 20-step optimization when evaluating StAdv and ReColor attacks and the default evaluation hyperparameters for ImageNet-UA attacks in \citet{kaufmann2019testing}. We report \textit{accuracy on each attack}, \textit{Union accuracy} (overall accuracy when the worst case attack is chosen for each test example), \textit{Average accuracy} (average over accuracy on each attack), and \textit{training time} (in hours). Metrics are reported for the epoch $E^*$ with best performance on the set of known attacks. For training from scratch, the reported training time is scaled by fraction of training for the best epoch (\textit{i.e.} we report $\frac{E^*}{100} \times \text{training time for 100 epochs}$). For fine-tuning we report training time for the full 10 epochs. This allows us to see how much faster fine-tuning is to optimal early stopping when re-training from scratch.

%Beyond loss on each attack, we also report \textit{union robust accuracy} (\edit{overall accuracy if for each test example, we chose the worst case attack from the set of attacks}) and \textit{average robust accuracy} (average over individual robust accuracies). \edit{We note that union accuracy is equal to $1 - L_{MAX}$ and average accuracy is equal to $1 - L_{AVG}$ when $\ell$ is taken to be the 0-1 loss in Equations \ref{eq:avg} and \ref{eq:max}.}
%Since the time that is taken for fine-tuning is also important, we report training and fine-tuning times in hours.  


\begin{table*}[ht]
\centering
\scalebox{0.77}{
\begin{tabular}{|c|c|l|l|c|cccc|cc|cc|c|}
\hline
\multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Time\\ Step \end{tabular}} & &Procedure & Threat Models & \multicolumn{1}{c|}{Clean} & \multicolumn{1}{c}{$\ell_2$} & \multicolumn{1}{c}{StAdv} & \multicolumn{1}{c}{$\ell_\infty$} & \multicolumn{1}{c|}{Recolor} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Avg\\ (known)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Union\\ (known)\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Avg\\ (all)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Union\\ (all)\end{tabular}} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Time\\ (hrs)\end{tabular}} \\ \hline
\multirow{ 2}{*}{0} & \parbox[t]{2mm}{\multirow{2}{*}{\rotatebox[origin=c]{90}{Init}}}& AT & $\ell_2$ & \textbf{91.17} & \cellcolor[HTML]{B7E1CD}69.7 & 2.08 & 28.41 & 44.94 & 69.7 & 69.7 & 36.28 & 1.24 & 8.68 \\ %16.69
& & AT + ALR ($\lambda=1$) & $\ell_2$ & 89.43 & \cellcolor[HTML]{B7E1CD}\textbf{69.84} & \textbf{48.23} & \textbf{34.00} & \textbf{65.46} & \textbf{69.84} & \textbf{69.84} & \textbf{54.38} & \textbf{31.27} & 17.17\\ %22.29
\hline 
%\multirow{ 8}{*}{1} & \parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{Scratch}}} & AVG & $\ell_2$, StAdv & \bf{87.74} & \cellcolor[HTML]{B7E1CD}62.17 & \cellcolor[HTML]{B7E1CD}50.92 & 17.17 & 45.47 & 56.55 & 47.55 & 43.93 & 15.92 & 23.72\\ %47.44
%& & MAX & $\ell_2$, StAdv & 86.18 & \cellcolor[HTML]{B7E1CD}58.65 & \cellcolor[HTML]{B7E1CD}57.21 & 11.21 & 43.07 & 57.93 & 51.72 & 42.54 & 11.03 &  23.69 \\ %47.37
%& & Random & $\ell_2$, StAdv & 84.91 & \cellcolor[HTML]{B7E1CD}57.77 & \cellcolor[HTML]{B7E1CD}59.74 & 14.05 & 44.88 & 58.76 & 52.15 & 44.11 & 13.68 & 10.92 \\ %9.36
%\cdashline{2-14}
\multirow{ 5}{*}{1} & \parbox[t]{2mm}{\multirow{5}{*}{\rotatebox[origin=c]{90}{Finetune}}}& FT MAX &  $\ell_2$, StAdv & 83.73 & \cellcolor[HTML]{B7E1CD}57.07 & \cellcolor[HTML]{B7E1CD}58.67 & 12.51 & 49.03 & 57.87 & 51.32 & 44.32 & 12.36 & 4.00 \\
 %& FT MAX (25 ep) & $\ell_2$, StAdv & 84.85 & \cellcolor[HTML]{B7E1CD}56.44 & \cellcolor[HTML]{B7E1CD}\textbf{\underline{61.34}} & 10.35 & 48.08 & 58.89 & 52.52 & 44.05 & 10.24 & 10 \\ %
 
 & & FT Single & $\ell_2$, StAdv &  80.89
& \cellcolor[HTML]{B7E1CD}45.45& \cellcolor[HTML]{B7E1CD}54.5
& 6.09 & 41.98 & 49.98 & 41.05 & 37.0 & 5.87 & 2.78 \\
 & & FT Croce & $\ell_2$, StAdv & 84.7 & \cellcolor[HTML]{B7E1CD}57.88 & \cellcolor[HTML]{B7E1CD}54.27 & 14.38 & 51.08 & 56.07 & 48.13 & 44.4 & 13.8 & 2.40\\

 & & FT Single + ALR & $\ell_2$, StAdv & \textbf{87.24} & \cellcolor[HTML]{B7E1CD}\textbf{62.22}& \cellcolor[HTML]{B7E1CD}61.5
& \textbf{21.4} & \textbf{70.87} & 61.86 & 55.04 & \textbf{54.0} & \textbf{21.14} & 4.24 \\
   & & FT Croce + ALR & $\ell_2$, StAdv & 86.03 & \cellcolor[HTML]{B7E1CD}59.18 &\cellcolor[HTML]{B7E1CD}\textbf{65.14} & 15.36  & 63.31 & \textbf{62.16}& \textbf{55.83} & 50.75 & 15.29 & 3.47 \\

\hline

%\multirow{ 8}{*}{2}&\parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{Scratch}}} & AVG & $\ell_2$, StAdv, $\ell_\infty$ & 85.98 & \cellcolor[HTML]{B7E1CD}67.60 & \cellcolor[HTML]{B7E1CD}45.81 & \cellcolor[HTML]{B7E1CD}\textbf{42.39} & 62.43 & 51.93 & 34.05 & 54.56 & 33.39 & 33.12 \\
%& & MAX & $\ell_2$, StAdv, $\ell_\infty$ & 84.54 & \cellcolor[HTML]{B7E1CD}54.87 & \cellcolor[HTML]{B7E1CD}52.33 & \cellcolor[HTML]{B7E1CD}38.23 & 55.90 & 48.48 & 35.25 & 50.33 & 34.08 & 45.84 \\
%& &Random & $\ell_2$, StAdv, $\ell_\infty$ & 84.63 & \cellcolor[HTML]{B7E1CD}67.46 & \cellcolor[HTML]{B7E1CD}47.35 & \cellcolor[HTML]{B7E1CD}42.12 & 63.61 & 52.31 & 35.46 & 55.13 & 34.79 & 11.03 \\ \cdashline{2-14}
 \multirow{ 5}{*}{2}&\parbox[t]{2mm}{\multirow{5}{*}{\rotatebox[origin=c]{90}{Finetune}}} &FT MAX & $\ell_2$, StAdv, $\ell_\infty$ & 83.16 &  \cellcolor[HTML]{B7E1CD}65.63 &  \cellcolor[HTML]{B7E1CD}56.68 &  \cellcolor[HTML]{B7E1CD}36.9 & 65.69 & 53.07 & 35.18 & 56.23 & 34.83 &	5.62 \\
  & &FT Single & $\ell_2$, StAdv, $\ell_{\infty}$ & 87.99 & \cellcolor[HTML]{B7E1CD}\textbf{70.53} & \cellcolor[HTML]{B7E1CD}11.17
 & \cellcolor[HTML]{B7E1CD}41.63 & 63.46 &41.11 & 7.95 & 46.7 & 7.74  & 1.57 \\
 & &FT Croce & $\ell_2$, StAdv, $\ell_{\infty}$ & 85.05 &  \cellcolor[HTML]{B7E1CD}67.3 &  \cellcolor[HTML]{B7E1CD}48.07 &  \cellcolor[HTML]{B7E1CD}33.38 & 62.52 & 49.58 & 28.96 & 52.82 & 28.63 & 2.27 \\ 


 & &FT Single + ALR & $\ell_2$, StAdv, $\ell_{\infty}$ & \textbf{88.74} & \cellcolor[HTML]{B7E1CD}69.15 & \cellcolor[HTML]{B7E1CD}47.33 & \cellcolor[HTML]{B7E1CD}\textbf{42.08} & 68.62 & 52.85 & \textbf{36.66} & 56.8 & \textbf{36.62} & 2.26 \\
 & &FT Croce + ALR & $\ell_2$, StAdv, $\ell_{\infty}$ & 86.57 & \cellcolor[HTML]{B7E1CD}67.99 & \cellcolor[HTML]{B7E1CD}\textbf{61.55} & \cellcolor[HTML]{B7E1CD}36.59 & \textbf{72.16} & \textbf{55.38} & 35.68 & \textbf{59.57} & 35.52 & 2.87 \\

 \hline

%\multirow{ 8}{*}{3} &\parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{Scratch}}}& AVG & $\ell_2$, StAdv, $\ell_\infty$, Recolor & 87.77 & \cellcolor[HTML]{B7E1CD}\textbf{68.55} & \cellcolor[HTML]{B7E1CD}39.55 & \cellcolor[HTML]{B7E1CD}\textbf{41.97} & \cellcolor[HTML]{B7E1CD}67.93 & 54.5 & 30.39 & 54.5 & 30.39 & 51.55 \\
%& &MAX & $\ell_2$, StAdv, $\ell_\infty$, Recolor & 84.3 & \cellcolor[HTML]{B7E1CD}57.62 & \cellcolor[HTML]{B7E1CD}52.3 & \cellcolor[HTML]{B7E1CD}41.69 & \cellcolor[HTML]{B7E1CD}65.1 & 54.18 & \textbf{37.44} & 54.18 & \textbf{37.44} & 61.09 \\
%& &Random & $\ell_2$, StAdv, $\ell_\infty$, Recolor & 86.32 & \cellcolor[HTML]{B7E1CD}65.87 & \cellcolor[HTML]{B7E1CD}47.82 & \cellcolor[HTML]{B7E1CD}35.04 & \cellcolor[HTML]{B7E1CD}68.35 & 54.27 & 30.76 & 54.27 & 30.76 & 13.15 \\ \cdashline{2-14}
\multirow{ 5}{*}{3}&\parbox[t]{2mm}{\multirow{5}{*}{\rotatebox[origin=c]{90}{Finetune}}}&FT MAX & $\ell_2$, StAdv, $\ell_{\infty}$, Recolor & 83.64 & \cellcolor[HTML]{B7E1CD}66.21 & \cellcolor[HTML]{B7E1CD}57.53 & \cellcolor[HTML]{B7E1CD}\textbf{37.77} & \cellcolor[HTML]{B7E1CD}69.32 & 57.71 & \textbf{36.02} & 57.71 & \textbf{36.02} & 8.45 \\
   & &FT Single & $\ell_2$, StAdv, $\ell_{\infty}$, Recolor &  90.41& \cellcolor[HTML]{B7E1CD}66.47 & \cellcolor[HTML]{B7E1CD}3.93 & \cellcolor[HTML]{B7E1CD}29.6& \cellcolor[HTML]{B7E1CD}69.03 & 42.26 & 2.49 & 42.26 & 2.49 & 3.11 \\
& &FT Croce & $\ell_2$, StAdv, $\ell_{\infty}$, Recolor & 86.64 & \cellcolor[HTML]{B7E1CD}\textbf{68.76} & \cellcolor[HTML]{B7E1CD}44.81 & \cellcolor[HTML]{B7E1CD}36.02 & \cellcolor[HTML]{B7E1CD}68.05 & 54.41 & 29.44 & 54.41 & 29.44 & 2.34 \\
 & &FT Single + ALR & $\ell_2$, StAdv, $\ell_{\infty}$, Recolor & \textbf{90.45} & \cellcolor[HTML]{B7E1CD}61.58 & \cellcolor[HTML]{B7E1CD}25.77 & \cellcolor[HTML]{B7E1CD}27.43 & \cellcolor[HTML]{B7E1CD}69.26 & 46.01 & 19.2 & 46.01 & 19.2 & 4.24 \\
  & &FT Croce + ALR & $\ell_2$, StAdv, $\ell_{\infty}$, Recolor &87.62 & \cellcolor[HTML]{B7E1CD}68.14 & \cellcolor[HTML]{B7E1CD}\textbf{58.5} & \cellcolor[HTML]{B7E1CD}36.39 & \cellcolor[HTML]{B7E1CD}\textbf{72.35} & \textbf{58.85} & 34.92 & \textbf{58.85} & 34.92 & 3.35 \\
\hline
\end{tabular}}
\vspace{-5pt}
\caption{\textbf{Continual Robust Training on CIFAR-10.} Best performance for each time step are \textbf{bolded}. The defender initially knows about $\ell_2$ attacks and over time, is sequentially introduced to StAdv, $\ell_\infty$, and ReColor attacks. We report clean accuracy, accuracy on individual attacks, and average and union accuracies.  The ``Threat Models" column specifies known attacks at the current time step, and accuracies on these attacks are in {\color[HTML]{B7E1CD} green cells}. Initial adversarial training occurs at time step 0, and the model is updated through fine-tuning the model from the previous time step.  ``Avg (known)" and ``Union (known)" columns represent average and union accuracies on known attacks while ``Avg (all)" and ``Union (all)" columns report performance across all four attacks.  We report training time for each time step in the ``Time" column.}
\label{tab:main_results_cifar}
\vspace{-10pt}
\end{table*}

\begin{table}[ht]
    \centering
    \scalebox{0.85}{
    \begin{tabular}{|l|c|cc|c|}
    \hline 
    Procedure & Clean & Avg & Union & Time \\ \hline
       MAX & 84.3 &  54.18 & 37.44 &61.09 \\
       AVG  & 87.77 &  54.5 & 30.39 & 51.55\\
       Random & 86.32 & 54.27 & 30.76 & 13.15\\\hline
       CRT + ALR & 87.62 & 58.85 & 34.92 & 26.86\\ \hline
    \end{tabular}}
    \caption{Regularized CRT (using \citet{croce2020reliable} fine-tuning strategy) compared to training from scratch on $\ell_2$, StAdv, $\ell_{\infty}$, and Recolor attacks on CIFAR-10.}
    \label{tab:training_from_scratch}
    \vspace{-20pt}
\end{table}


\begin{table*}[]
\centering
{\renewcommand{\arraystretch}{1.2}
\scalebox{0.7}{
\begin{tabular}{|l|c|c|c|cccccccccccc|cc|}
\hline
\begin{tabular}[c]{@{}l@{}}Initial\\Attack\end{tabular} & \begin{tabular}[c]{@{}c@{}}Reg\\Type\end{tabular} & $\lambda$ & Clean & $\ell_2$ & $\ell_\infty$ & StAdv & ReColor & Gabor & Snow & Pixel & JPEG & Elastic & Wood & Glitch & \begin{tabular}[c]{@{}c@{}}Kaleid-\\oscope\end{tabular} & Avg & Union \\ \hline
$\ell_2$ & None & 0 & 91.08 & 70.02 & 29.38 & 0.79 & 33.69 & 66.93 & 24.59 & 14.99 & 64.22 & 45.13 & 70.85 & 80.30 & 30.08 & 44.25 & 0.10 \\
$\ell_2$ & VR & 0.2 & \cellcolor[HTML]{F4C7C3}89.99 & 70.38 & \cellcolor[HTML]{B7E1CD}34.56 & \cellcolor[HTML]{B7E1CD}13.41 & \cellcolor[HTML]{B7E1CD}48.99 & 67.64 & \cellcolor[HTML]{B7E1CD}29.09 & \cellcolor[HTML]{B7E1CD}22.57 & \cellcolor[HTML]{B7E1CD}66.64 & \cellcolor[HTML]{B7E1CD}48.38 & \cellcolor[HTML]{B7E1CD}73.31 & 80.07 & \cellcolor[HTML]{B7E1CD}32.33 & \cellcolor[HTML]{B7E1CD}48.94 & \cellcolor[HTML]{B7E1CD}5.40 \\ 
$\ell_2$ & ALR & 0.5 & \cellcolor[HTML]{F4CCCC}89.57 & 70.29 & \cellcolor[HTML]{B7E1CD}34.16 & \cellcolor[HTML]{B7E1CD}17.44 & \cellcolor[HTML]{B7E1CD}51.04 & \cellcolor[HTML]{F4CCCC}65.63 & \cellcolor[HTML]{B7E1CD}28.71 & \cellcolor[HTML]{B7E1CD}22.50 & \cellcolor[HTML]{B7E1CD}66.76 & \cellcolor[HTML]{B7E1CD}48.80 & \cellcolor[HTML]{B7E1CD}73.24 & 79.66 & \cellcolor[HTML]{F4CCCC}28.83 & \cellcolor[HTML]{B7E1CD}48.92 & \cellcolor[HTML]{B7E1CD}5.94 \\ 
$\ell_2$ & UR & 5  & \cellcolor[HTML]{F4CCCC}88.34 & \cellcolor[HTML]{F4CCCC}66.66   & \cellcolor[HTML]{F4CCCC}27.41   & \cellcolor[HTML]{B7E1CD}26.22 & \cellcolor[HTML]{B7E1CD}60.22 & \cellcolor[HTML]{B7E1CD}69.16   & \cellcolor[HTML]{B7E1CD}26.67 & \cellcolor[HTML]{B7E1CD}22.57 & 64.08  & \cellcolor[HTML]{B7E1CD}46.83   & 71.14  & \cellcolor[HTML]{F4CCCC}77.60    & \cellcolor[HTML]{B7E1CD}31.36    & \cellcolor[HTML]{B7E1CD}49.16 & \cellcolor[HTML]{B7E1CD}6.23 \\
$\ell_2$ & GR & 0.5& \cellcolor[HTML]{F4CCCC}86.89 & \cellcolor[HTML]{F4CCCC}68.19   & \cellcolor[HTML]{B7E1CD}32.02 & \cellcolor[HTML]{B7E1CD}16.54 & \cellcolor[HTML]{B7E1CD}58.32 & \cellcolor[HTML]{B7E1CD}74.85 & \cellcolor[HTML]{B7E1CD}25.69 & \cellcolor[HTML]{B7E1CD}21.26 & \cellcolor[HTML]{B7E1CD}65.32   & \cellcolor[HTML]{B7E1CD}46.82 & \cellcolor[HTML]{B7E1CD}74.08   & \cellcolor[HTML]{F4CCCC}76.99   & \cellcolor[HTML]{B7E1CD}31.93    & \cellcolor[HTML]{B7E1CD}49.33 & \cellcolor[HTML]{B7E1CD}4.18 \\
\hline
$\ell_\infty$ & None & 0 & 85.53 & 59.36 & 50.98 & 6.34 & 56.27 & 68.94 & 36.79 & 20.57 & 54.02 & 51.00 & 64.24 & 75.94 & 39.44 & 48.66 & 1.31 \\
$\ell_\infty$ & VR & 0.2 & \cellcolor[HTML]{F4C7C3}82.58 & 58.36 & 51.53 & \cellcolor[HTML]{B7E1CD}18.98 & \cellcolor[HTML]{B7E1CD}62.12 & \cellcolor[HTML]{F4C7C3}67.18 & \cellcolor[HTML]{B7E1CD}39.22 & \cellcolor[HTML]{B7E1CD}23.62 & 54.73 & \cellcolor[HTML]{B7E1CD}52 & 63.35 & \cellcolor[HTML]{F4C7C3}71.72 & \cellcolor[HTML]{B7E1CD}43.18 & \cellcolor[HTML]{B7E1CD}50.50 & \cellcolor[HTML]{B7E1CD}5.08 \\ 
$\ell_\infty$ & ALR &  0.5 & \cellcolor[HTML]{F4C7C3}83.18 & \cellcolor[HTML]{F4C7C3}58.21 & 51.47 & \cellcolor[HTML]{B7E1CD}19.50 & \cellcolor[HTML]{B7E1CD}61.02 & 68.75 & \cellcolor[HTML]{B7E1CD}37.94 & \cellcolor[HTML]{B7E1CD}22.78 & 53.89 & \cellcolor[HTML]{F4C7C3}49.82 & 63.47 & \cellcolor[HTML]{F4C7C3}73.57 & 39.88 & \cellcolor[HTML]{B7E1CD}50.02 & \cellcolor[HTML]{B7E1CD}5.52 \\ 
 $\ell_\infty$    & UR  & 5  & \cellcolor[HTML]{F4C7C3}78.04 & 60.28  & \cellcolor[HTML]{F4C7C3}40.59   & \cellcolor[HTML]{B7E1CD}42.25 & \cellcolor[HTML]{B7E1CD}70.00    & \cellcolor[HTML]{F4C7C3}67.06   & \cellcolor[HTML]{F4C7C3}33.40    & \cellcolor[HTML]{B7E1CD}26.57 & \cellcolor[HTML]{B7E1CD}60.07   & \cellcolor[HTML]{F4C7C3}49.21   & 64.61  & \cellcolor[HTML]{F4C7C3}67.08   & \cellcolor[HTML]{F4C7C3}38.43      & \cellcolor[HTML]{B7E1CD}51.63 & \cellcolor[HTML]{B7E1CD}8.36 \\ 
$\ell_\infty$      & GR & 0.5& \cellcolor[HTML]{F4C7C3}80.65 & 59.74  & \cellcolor[HTML]{F4C7C3}46.12   & \cellcolor[HTML]{B7E1CD}34.57 & \cellcolor[HTML]{B7E1CD}70.49 & 68.33  & 35.80   & \cellcolor[HTML]{B7E1CD}26.04 & \cellcolor[HTML]{B7E1CD}57.28   & 51.98  & \cellcolor[HTML]{B7E1CD}65.46   & \cellcolor[HTML]{F4C7C3}70.73   & \cellcolor[HTML]{F4C7C3}38.21      & \cellcolor[HTML]{B7E1CD}52.06 & \cellcolor[HTML]{B7E1CD}6.28 \\ \hline
\end{tabular}
}}
\vspace{-5pt}
\caption{\textbf{Impact of Regularization on Unforeseen Robustness.} We consider the setting where the defender is only aware of a single attack and performs training with and without different types of regularization: variation regularization (VR), adversarial $\ell_2$ regularization (ALR), uniform regularization (UR), and Gaussian regularization (GR) at regularization strength $\lambda$.  We report clean accuracy and robust accuracies on a range of attacks. {\color[HTML]{B7E1CD} Green cells} represent an improvement of at least 1\%  while {\color[HTML]{F4C7C3} red cells} represent a drop of at least 1\% in comparison to no regularization.}
\label{tab:reg_unforeseen_rob}
\vspace{-10pt}
\end{table*}



\subsection{Improving CRT with Regularization}
\label{sec:car_reg}
We now analyze the robustness of models trained using CRT with and without regularization. For simplicity, we focus on ALR with other methods analyzed in \cref{sec:init_train_impact}.  To model a CAR setting, we consider a sequence of 4 attacks: $\ell_2 \to$ StAdv $\to \ell_{\infty} \to$ Recolor.  The first attack is the initially known attack while other attacks are introduced at later time steps. %The defender learns about these attacks at different time steps, with the first attack of the sequence known prior to deployment while subsequent attacks are sequentially discovered post-deployment. 
We present results for CIFAR-10 in Table \ref{tab:main_results_cifar}.  We include results in Appendix \ref{app:exp_seq} for Imagenette and CIFAR-100 as well as additional results for longer duration of fine-tuning (25 epochs) and a separate sequence of attacks: $\ell_\infty \to$ StAdv $\to$ Recolor $\to \ell_2$.  For these experiments, we use $\lambda=0.5$ unless specified otherwise.

\noindent\textbf{Regularization reduces degradation on previous attacks. } From Table \ref{tab:main_results_cifar}, we observe that fine-tuning with only the new attack (FT Single) can lead to degradation of robustness against previous attacks.  The incorporation of ALR significantly decreases this drop in robustness.  For example, when fine-tuning from an $\ell_2$ robust model with StAdv attacks (time step 1 in Table \ref{tab:main_results_cifar}), FT Single incurs a 24.25\% drop (from 69.7\% to 45.45\%) in $\ell_2$ accuracy from the initial checkpoint (AT at time step 0).  Meanwhile FT Single + ALR only experiences a 7.62\% drop (from 69.84\% to 62.22\%) in $\ell_2$ accuracy from the initial checkpoint (AT + ALR at time step 0).  Similarly, after the introduction of $\ell_\infty$ attack at time step 2, the accuracy of FT Single on StAdv attacks drops 43.42\% (from 54.5\% to 11.17\%) while FT Single + ALR only experiences a 14.17\% drop (from 61.5\% to 47.33\%). These results align with Theorem~\ref{thm:robustness}: when incorporating ALR into training, the gap in loss on the two attacks is lessened.
%For example, we find that FT MAX and our approach is able to consistently outperform training from scratch with AVG, MAX, and Random procedures in terms of average and union accuracy.  This suggests that representations learned on the attack used in initial training ($\ell_2$ attack in Table \ref{tab:main_results_cifar}) can be a useful starting point for robustness on other attacks.  This also suggests that existing algorithms for achieving simultaneous multi-robustness may be suboptimal since we would expect the performance of these methods to serve as an upper bound for CAR.

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{figures/imagenette_finetune_l2_reg_union.pdf}
        \vspace{-15pt}
        \caption{Adversarial $\ell_2$ regularization ($\lambda=0.5$)}
    \end{subfigure}%
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=0.95\textwidth]{figures/imagenette_finetune_uniform_union.pdf}
        \vspace{-15pt}
        \caption{Uniform Regularization
        ($\sigma=2,\lambda=1$)}
    \end{subfigure}
    %\begin{subfigure}[t]{0.5\textwidth}
    %    \centering
    %    \includegraphics[width=0.95\textwidth]{figures/imagenette_finetune_varreg_union.pdf}
    %    \vspace{-10pt}
    %    \caption{Variation Regularization\\ ($\lambda = 0.5$)}
    %\end{subfigure}%
    %\begin{subfigure}[t]{0.5\textwidth}
    %    \centering
    %    \includegraphics[width=0.95\textwidth]{figures/imagenette_finetune_gaussian_union.pdf}
     %   \vspace{-10pt}
     %   \caption{Gaussian Regularization\\ ($\sigma=0.2, \lambda = 0.5$)}
    %\end{subfigure}
    \vspace{-10pt}
    \caption{\textbf{Ablation 2: Change in union robust accuracy after fine-tuning with regularization (initial model does not use regularization).}  We fine-tune models on Imagenette across 144 pairs of initial attack and new attack.  The initial attack corresponds to the row of each grid and new attack corresponds to each column.  Values represent differences between the accuracy measured on a model \emph{fine-tuned with and without regularization}.  Gains in accuracy of at least 1\% are highlighted in {\color[HTML]{0E7003} green}, while drops in accuracy of at least 1\% in {\color[HTML]{FC0006} red}. Further results are in Appendix~\ref{app:fine-tuning}.}
    \label{fig:fine-tune_abl_main_text}
    \vspace{-15pt}
\end{figure*}

\noindent\textbf{Regularization improves performance on held out (unforeseen) attacks. }We observe that regularized CRT leads to higher robustness on attacks held out from training.  For example, at time step 1 in Table \ref{tab:main_results_cifar}, which trains with $\ell_2$ and StAdv attacks, the best accuracy on Recolor attacks out of unregularized CRT methods is 51.08\%, while FT Single + ALR achieves 70.87\% accuracy on Recolor attacks and FT Croce + ALR achieves 63.31\% accuracy on Recolor attacks.  The improvement in robustness on unforeseen attacks aligns with \cref{thm:corollary} as regularization helps decrease the drop in accuracy between clean inputs and perturbed inputs. This also aligns with CAR's goal of having a small $\delta_{\text{unknown}}$.%\sophie{does this make sense?}

%This suggests that regularized CRT can also lead to improvements in unforeseen robustness. \anote{last sentence does not add any information, what is the intuition? The reg. brings the logits close to benign ones, so helps against unseen attacks as well...}% as well as robustness on the set of known attacks.% This gain also aligns with the goal of also having some unforeseen robustness for when a new attack is just introduced and time is taken to fine-tune the model before it can be redeployed for use.

\noindent\textbf{Regularization balances performance and efficiency. } Our proposed regularization term adds a small computational overhead over other FT approaches but generally improves union performance on the set of known attacks. For example, when considering the sequence of $\ell_2$ and StAdv attacks (time step 1 in Table \ref{tab:main_results_cifar}), FT Croce + ALR improves union accuracy over FT Croce by 7.7\% while adding a time overhead of 1.07 hours.  Additionally, when considering the sequence of 3 attacks ($\ell_2$, StAdv, and $\ell_\infty$ attacks), FT Croce + ALR improves union accuracy over FT Croce by 6.72\% while adding a time overhead of 0.6 hours.  This increase in time complexity is much smaller than FT MAX which takes 1.6 hours longer than FT Croce for $\ell_2$ and StAdv and 3.35 hours longer for $\ell_2$, StAdv, and $\ell_\infty$. With respect to goals in CAR, regularization balances $\delta_{\text{known}}$ and $\Delta t$.

\noindent\textbf{Comparison to training from scratch.} In Table \ref{tab:training_from_scratch}, we report clean, average, and union accuracies along with total training times for using training from scratch on all 4 attacks compared to training sequentially with regularized CRT on CIFAR-10.  We observe that regularized CRT is significantly more efficient than MAX and AVG training (taking a total of 26.86 hours while AVG and MAX take over 50 hours of training time).  Surprisingly, we find that on CIFAR-10, regularized CRT can outperform training from scratch methods, achieving 4.35\% higher average accuracy compared to the best achieved by training from scratch.  This suggests that transferable robustness between carefully chosen attacks can improve MAR as a whole.  However, we note that the ability to outperform training from scratch seems to be specific to CIFAR-10; for ImageNette and CIFAR-100 (Appendix \ref{app:exp_seq}) training from scratch outperforms using fine-tuning in CAR.

\noindent\textbf{Impact of dataset and attack sequence. }In Appendix \ref{app:exp_seq}, we provide results on ImageNette and CIFAR-100 as well as for attack sequence $\ell_\infty \to$ StAdv $\to$ Recolor $\to \ell_2$.  Overall, we observe that trends such as improved robustness to unforeseen and the union of attacks are generally consistent. However, but the extent to which regularization improves performance over FT Croce varies.  The choice of the initial attack seems to play a role in subsequent robustness, and if defenders are aware of multiple attacks, choosing the right one to start with is an interesting open question.  %We discuss this direction more in Section \ref{sec: discussion}.} 
%Overall, we find that the degree to which ALR helps in CRT to be dependent on dataset and attack sequence.  For ImageNette and sequence starting with $\ell_2$, we find that FT Croce + ALR can lead to an increase of at least 2.58\% in union (known attack) accuracy over FT Croce across time steps in the sequence.  However, for ImageNette with $\ell_{\infty}$ sequence, we find that the gain in performance of FT Croce + ALR over FT Croce can be quite small after the first time step; At time step 1, there is a gain of 3.19\%, 0.81\% at time step 2, and 1.4\% at time step 3. Meanwhile for CIFAR-100 with the $\ell_2$ attack sequence, we find that the gain in performance of FT Croce + ALR over FT Croce to be 2.6\% at time step 1 and 2.13\% at time step 2, but there is a 2.46\% drop in accuracy over FT Croce at time step 3.  Additionally for the $\ell_\infty$ attack sequence on CIFAR-100, improvements in through ALR can also be quite small, with a 1.21\% increase at time step 1, 1.26\% at time step 2, and 0.13\% at time step 3.  


%\begin{froval}
\begin{tcolorbox}[myboxstyle]
\begin{cfinding}
CRT+ALR improves robustness on both known and unforeseen attacks, and reduces drop in robustness on previous attacks with only a small overhead in fine-tuning time compared to unregularized CRT.\end{cfinding}
\end{tcolorbox}
%\end{froval}


\subsection{Ablation 1: Regularization in Initial Training}
\label{sec:init_train_impact}
We now study the impact of regularization \textit{only} in the initial training phase of CRT.  In Table \ref{tab:reg_unforeseen_rob}, we present results for robust accuracies of models initially trained on $\ell_2$ and $\ell_{\infty}$ attacks with different forms of regularization.  We present results for different regularization strengths and initial attack choices in \cref{app:init_train_different_attack_types}.

\noindent\textbf{Regularization improves robustness on unforeseen attacks.} Interestingly, we find that all regularization types including random noise-based regularization can improve unforeseen robustness.  For example, at $\lambda=5$, UR improves union accuracy across all attacks by 6.13\% for $\ell_2$ initial attack and by 7.05\% for $\ell_\infty$ initial attack compared to the model trained without regularization.  Improved unforeseen robustness provides a better starting point for fine-tuning, which we demonstrate experimentally in Appendix \ref{app:fine-tuning_pairs_init_train}.

\noindent\textbf{Trade-offs for clean and different attack accuracies. }We observe that all regularization types generally exhibit a trade-off with clean accuracy and trade-offs with a few attack types such as Glitch.  This trade-off aligns with \cref{thm:corollary} which states that the gap between clean loss and loss over the union of attacks is decreased via regularization. We also find that random noise based regularization (UR and GR) generally exhibits trade-off with the robust accuracy on the initial attack.  This is generally not the case for adversarial regularization (ALR and VR) which maintains performance on the initial attack. 

\noindent\textbf{Regularized initial models are better starting points for fine-tuning. } In Appendix \ref{app:fine-tuning_pairs_init_train}, we present results for fine-tuning with a new attack from models using regularization in only initial training.  We observe that for all regularization types, regularization in initial training can improve the robustness on the union of attacks after fine-tuning, but this trend is more consistent with adversarial regularization types (ALR and VR) compared to random regularization types (UR and GR).
% We now ask the question, can regularization in initial training help with robust accuracies after fine-tuning to a new attack?  To understand this, we consider initially training with one attack and then fine-tuning to a new attack. In Figure \ref{fig:fine-tune_abl_main_text_from_init}, we plot the difference in accuracies between a model fine-tuned from a checkpoint initially trained with regularization compared to a model fine-tuned from a checkpoint without regularization in initial training \edit{for ALR and UR.  We provide results for VR and GR in Appendix \ref{app:fine-tuning_pairs}.}  The attack in the row represents the initial attack and the attack in the column represents the new attack. For diagonal entries where the initial attack and new attack have the same attack type, we use a larger attack strength for the new attack (see experimental setup in \S\ref{sec:exp_setup} for full details). Gains in robustness from fine-tuning at least 1\% are colored in green while drops in robustness are colored in red at least 1\%.  We observe that that for all regularization types, regularization in initial training can improve the robustness on the union of attacks after fine-tuning, but this trend is more consistent with adversarial regularization types (ALR and VR) compared to random regularization types (UR and GR).  We also observe that the magnitude of these changes can be quite large; for example, when the initial attack is the Kaleidoscope attack and the new attack is Snow, incorporating ALR in initial training improves the resulting model's robust accuracy on the union of these attacks by 16.72\%.

\begin{tcolorbox}[myboxstyle]
    \begin{cfinding}\label{cfind: justification} Adversarial and random noise regularization in initial training improves performance on unforeseen attacks.  Fine-tuning on a new attack from a regularized model boosts resulting Union accuracy.
    \end{cfinding}
\end{tcolorbox}

\subsection{Ablation 2: Regularization during Fine-tuning}
\label{sec:fine-tuning_impact}

We now investigate whether regularization within just the the fine-tuning phase can improve CAR.  We initially train models on a single initial attack using adversarial training (\emph{without regularization}) and then fine-tune with \citet{croce2022adversarial}'s fine-tuning approach both with and without regularization on a new attack.  In Figure \ref{fig:fine-tune_abl_main_text}, we present grids representing differences in Union accuracy between regularized and unregularized fine-tuning.  Rows represent the initial attack used to adversarially train the model (without regularization), columns represent the new attack.  We provide corresponding plots detailing differences in average accuracy, initial attack accuracy, new attack accuracy, and clean accuracy in Appendix \ref{app:fine-tuning_pairs}.  

\noindent\textbf{Adversarial regularization can improve union accuracy in fine-tuning. } We find that across different initial and new attack pairs, using ALR in fine-tuning generally improves union accuracy as most cells in Figure \ref{fig:fine-tune_abl_main_text}(a) are green.  These increases in robustness can be quite large; for example, when the initial attack is StAdv \citep{XiaoZ0HLS18} and the new attack is Kaleidoscope \citep{kaufmann2019testing}, ALR improves robustness on the union by 8.66\%.  Additionally, when the initial attack is $\ell_2$ and the new attack is Snow \citep{kaufmann2019testing}, ALR improves robustness on the Union of both attacks by 7.85\%.  We find same trend holds for VR (\cref{app:fine-tuning_pairs}).

\noindent\textbf{Random noise based regularization is harmful when used in fine-tuning. }Although random noise based regularization can improve robustness when used in the initial training phase of CRT, Figure \ref{fig:fine-tune_abl_main_text}(b) demonstrates that UR in fine-tuning hurts union accuracy for many initial and new attack pairs (corresponding results for GR are present in \cref{app:fine-tuning_pairs}). This suggests that while random noise based regularization can be used to perform initial training more efficiently, they should not be used during fine-tuning.  Since we found that UR and GR trade off accuracy on the initial attack when used in initial training in \cref{sec:init_train_impact}, this suggests that UR and GR generally trade off performance on attacks that are used in training or fine-tuning.

\begin{tcolorbox}[myboxstyle]
    \begin{cfinding}\label{cfind: justification} In fine-tuning, adversarial regularization (ALR and VR) can improve Union accuracy significantly (up to $\sim 7\%$) while random noise-based regularization hurts Union accuracy. %Adversarial regularization (ALR and VR) can help improve union accuracy when used in fine-tuning. In contrast, we find that random noise based regularization can harm performance when used in fine-tuning across many pairs attack types.
    \end{cfinding}
\end{tcolorbox}