\section{Related Work}
\subsection{Headline Generation}

Headline generation, a form of extreme text summarization, requires producing highly condensed, single-sentence summaries that capture the key information in a news article. 
%most important idea of the input text. 
% In the pioneering studies____ and ____ at an early stage, 
%are pioneering work for extreme summarization. 
%They developed 
In early studies____, models are supervise-trained on datasets containing single-sentence summaries (XSum)____ and news-headline pairs (Gigaword) ____ However, their CNN-based and RNN-based approaches have since been outperformed by transformer-based models. 
%in the extreme summarization task. 
Recent studies show that transformer-based PLMs such as BART____, PEGASUS____, and BRIO____ can be fine-tuned on XSum and Gigaword to achieve promising results for extreme summarization and headline generation. 

While PLMs laid the bedrock for summarization, the advancement of LLMs has pushed the boundaries further. Several LLM-based approaches have emerged for general text summarization. Recent works have leveraged CoT prompting for summarization, proposing a "Summary Chain-of-Thought" method that guides LLMs to focus on key elements and generate summaries step-by-step____. To further enhance summary quality, reinforcement learning methods have been employed to optimize LLMs based on human preferences____. LLM-based approaches have also been tailored specifically for headline generation. For instance, leveraging reinforcement learning, ____ focus on creating personalized headlines for content recommendation. 
These approaches, whether PLM-based or LLM-based, focus on the text quality of summarization and the numerical accuracy is overlooked.
%\todo[color=green]{XF: maybe we need some related work to highlight the challenges from headline generation: 2020 extreme headline --> tbc}. 

%There are some closely related works. 
%Closely related 
Research on number-focused headline generation is reported recently. 
____ assess the performance of PLMs in number-focused headline generation, but they do not provide strategies to enhance the models' numerical accuracy. ____ apply DPO to optimize headline generation using a preference dataset designed to train the model to favor headlines with correct numbers. While this preference for correct numbers can improve numerical accuracy, solely relying on it may degrade the textual quality of the generation. 
%Unlike previous approaches, our approach aims to enhance textual quality in headline generation as well as improve language models' numerical reasoning ability when generating headlines. 
% includes components explicitly designed to 

% \subsection{numerical Reasoning}
% \todo{XF: Do we discuss approaches other than providing rationales?} 
% Learning from human crafted rationales helps the performance, but requires human efforts
% \noindent{\textbf{Learning from human-crafted rationales.}} Researchers have demonstrated that language models' numerical reasoning abilities can be enhanced through learning from human-crafted rationales. 
% % rationale-augmented training. 
% One line of research employs humans to create natural language rationales for training____. They were the first to propose that language models could achieve higher accuracy in solving word math problems when required to generate both final answers and intermediate reasoning steps. 
% %Other researchers have shown that creating 
% Another line of research utilizes symbolic rationales for improving numerical reasoning abilities. For instance, symbolic equations can be used as intermediate steps to help solve word math problems____. And in____, the authors introduce a new representation language to model the intermediate steps so as to improve both the performance and the interpretability of the learned models. While effective, these methods rely heavily on human input, making them resource-intensive and potentially less scalable. 

% Learning from rationales generated by teacher LLMs helps the performance, and less human efforts
% \noindent{\textbf{Learning from teacher LLMs.}} 
% \subsection{Learning from LLM Generated TEN rationales.}
\subsection{CoT Prompting for Rationale Generation}

CoT prompting has gained great popularity due to its potential to unlock LLMs' reasoning capabilities by simply instructing them to generate intermediate steps as rationales before reaching a final answer____. For example, one can utilize CoT reasoning by simply adding the phrase "let's think step by step" to the end of each question____. This approach is improved by a two-step process to generate rationales____: first, selecting representative questions to generate exemplar rationales, and then using these representative rationales as demonstrations for LLMs to generate reasoning steps for other questions in the dataset. This idea is further enhanced by including the correct solution in prompts can enhance the quality of LLM-generated rationales____. 
 

%, specifically addressing the numerical accuracy issues in headline generation. 
% Our work also follows a two-step process to instruct an LLM to generate TEN rationales automatically, but we focus on creating rationales suitable for number-focused headline generation.

% Better rationales gives better performance
% \noindent{\textbf{Generating rationales through CoT prompting.}} In the LLM era, CoT prompting has gained great popularity due to its potential to unlock LLMs' reasoning capabilities by simply instructing them to generate intermediate steps before reaching a final answer____. CoT prompting has been applied to various tasks, including automatic rational generation. ____ demonstrate that CoT reasoning steps can be generated in a zero-shot manner by simply adding the phrase "let's think step by step" to the end of each question. ____ propose a two-step process to generate rationales automatically: first, selecting representative questions to generate exemplar rationales, and then using these representative rationales as demonstrations for LLMs to generate reasoning steps for other questions in the dataset. This idea is further enhanced by including the correct solution in prompts can enhance the quality of LLM-generated rationales____. Our work also follows a two-step process to instruct an LLM to generate TEN rationales automatically, but we focus on creating rationales suitable for number-focused headline generation. 

Especially for word math problems, research shows that LLM's numerical reasoning ability can be improved by learning from human-crafted rationales, including natural language intermediate reasoning steps____ and symbolic representations like equations____. 
%While these methods have proven effective in enhancing model performance for tasks such as solving word math problems, 
But these methods rely on human annotations and therefore are costly. 
% jz3:I reworded and I think it sits here better. 
%\todo{XF: I feel this paragraph does not fit in here, can we put this paragraph at the beginning of this subsection?}

%potentially less scalable. 
% Better rationales gives better performance
\subsection{Learning from Teacher LLM Generated Rationales}
% summarize non-CoT in one or two sentences
% \noindent{\textbf{Learning from LLM generated TEN rationales.}} 

%An alternative approach that requires less human efforts involves 
% Learning from TEN rationales generated by teacher LLMs is a scalable alternative to reduce human efforts. 
Learning from rationales generated by teacher LLMs is a scalable alternative to human annotation. 
Research has shown that CoT reasoning steps generated from teacher LLMs can be used to fine-tune smaller student language models____ that 
%. The CoT fine-tuned student models sometimes even outperform the teacher model in certain tasks. 
may even outperform the teacher LLM for some tasks.
% They validated their approach on four types of complex reasoning including arithmetic, symbolic, common sense, and other reasoning. 
%Similarly, in____, the authors suggest that the student model can achieve comparable performance with reduced training data when fine-tuned with LLM-generated rationales. They test their approach on several NLP tasks including arithmetic word math problems. 
Such teacher-student knowledge distillation has also been applied to multi-modal training for science QA____, which involves numerical reasoning.
The authors propose that mixing simple and complex reasoning in supervision data can enhance student LLMs' performance____. 
%Our work also follows a two-step process to instruct an LLM to generate TEN rationales automatically. But unlike existing works, our approach focuses on creating rationales that address the topic alignment and numerical reasoning so that two independent student LLMs can be further fine-tuned for number-focused headline generation tasks. 
Our approach also leverages the teacher-student knowledge distillation framework. 
Unlike existing work, we focus on rationales for topic alignment as well as numerical reasoning in numerical text generation.
%, which is not studied in existing work. 

Researchers have explored various approaches to enhance rationale quality, including the use of verifiers____, majority voting____ and reinforcement learning____. 
% In ____, the authors propose to train a verifier to rank the probabilities of correctness for model-generated rationales and select the most likely one. Similarly, the majority vote has been utilized to choose the most consistent output from several output rationales generated by LLMs____. 
Our approach, which leverages DPO for refining rationale generation, is closely related to reinforcement learning strategies____. 
%the authors propose to automatically assess the step-wise correctness of model-generated rationales, 
%train a reward model using the labelled data, and further
%the authors propose to improve %LLMs' performance 
%LLM rationale generation through reinforcement learning. 
%Our approach of using DPO to refine also 
%explores the effectiveness of DPO in enhancing the quality of the generated rationales. 
%jz3: pelase check the my re-write below. 
However, unlike previous work that focuses solely on reward models for numerical reasoning rationales, our approach develops preference datasets tailored to both nuanced topic alignment and complex numerical reasoning. 

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth, trim={2cm 2.45cm 0cm 1.7cm}, clip]{f2}
%  \caption {Three-phase pipeline of the proposed TEN fine-tuning scheme: (1) Generating supervision data, (2) Fine-tuning student LLMs, and (3) Inferring with fine-tuned student LLMs for headline generation.}
  \caption {Our TEN approach for automatic generation of rationales to enhance numerical headline generation.}
  \label{fig:three_phase_of_TEN}
\end{figure*}