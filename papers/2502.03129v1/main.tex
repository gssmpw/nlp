% NAACL 2025 instructions:
% https://aclrollingreview.org/cfp#long-papers
%Long papers must describe substantial, original, completed and unpublished work. Wherever appropriate, concrete evaluation and analysis should be included. Long papers may consist of:
%up to eight (8) pages of content
%plus up to one page for limitations (required, see below) and optionally ethical considerations
%plus unlimited pages of references
%Submissions that exceed the length requirements, or are missing a limitations section, will be desk rejected.
% Final versions of accepted papers will be given one additional page of content (up to 9 pages for long papers, up to 5 pages for short papers) to address reviewers’ comments.

% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
%\usepackage[review]{acl}
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{epstopdf} 

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.
\usepackage{float}
\usepackage{stfloats}
\usepackage{array}
\usepackage{svg}
% \usepackage[table]{xcolor}
\usepackage{xcolor}
% for \rowcolor
\usepackage{colortbl}
% for \todo
\usepackage{todonotes}

%\title{Fine-tuning Large Language Models with Chain of Thought Teaching Signals for Number-Focus Headline Generation}
%\title{Optimizing Rationales via Constructing Topic and numerical Preferences to Teach LLMs for Number-Focused Headline Generation}
%\title{Generating Topic and numerical-based Chain-of-Thought Rationales to Teach LLMs for Number-focused Headline Generation}
%\title{Generating Topic-Entity-numerical-reasoning Rationales to Teach LLMs for Number-focused Headline Generation}
% Avoid two "generate" in the above version
\title{Teaching Large Language Models Number-Focused Headline Generation With Key Element Rationales}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
\author{Zhen Qian \and Xiuzhen Zhang\thanks{Corresponding author} \and Xiaofei Xu \and Feng Xia \\
         School of Computing Technologies, RMIT University, Australia \\ 
         \texttt{\{s3888611,xiaofei.xu2\}@student.rmit.edu.au;} \\
         \texttt{\{xiuzhen.zhang,feng.xia\}@rmit.edu.au}
}


% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% %\author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

% \author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
% \\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
% \\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
% \\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
% \\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
% \\
% \\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
% \\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
% }

\begin{document}
\maketitle
\begin{abstract}
%While state-of-the-art pre-trained language models (PLMs) and large language models (LLMs) have proven exceptional in 
% While Large Language Models (LLMs) have proven powerful for news headline generation in terms of textual quality,
% %when measured by semantic similarity, 
% the numbers in the generated headlines are often inaccurate. 
% On the other hand, studies for solving word math problems are focused on only numerical reasoning to obtain the correct number, without needing to generate texts. 
% %The challenge in number-focused headline generation lies in maintaining both textual quality and numerical accuracy. 
%To address this challenge, 
%Number-focused headline generation poses a unique challenge for Large Language Models (LLMs), requiring both high-quality text and precise numerical accuracy.
Number-focused headline generation is a summarization task 
that requires both high textual quality and precise numerical accuracy, which poses a unique challenge for Large Language Models (LLMs). 
Existing studies in the literature focus only on either textual quality or numerical reasoning and thus are inadequate to address this challenge. 
In this paper, we propose a novel chain-of-thought framework for using rationales comprising key elements of the Topic, Entities, and Numerical reasoning (TEN) in news articles to enhance the capability  
for LLMs to generate topic-aligned high-quality texts with precise numerical accuracy. 
Specifically, a teacher LLM is employed to generate TEN rationales as supervision data, which are then used to teach and fine-tune a student LLM. 
%This process aims to improve automatic generation of rationales, ultimately enhancing the student LLM's ability to generate numerical headlines. 
Our approach teaches the student LLM automatic generation of rationales with enhanced capability for numerical reasoning and topic-aligned numerical headline generation.  
%jz3: I explained earlier directly. 
%In our framework, a rationale refers to the key intermediate steps and elements that must be considered before generating a headline.
%to refine and optimize the student LLM’s performance  
%\todo{XF: maybe we are optimizing the student LLM?}, 
%Importantly, we automatically construct topic and numerical-based preferences and leverage direct preference optimization for automatic rationale generation. 
Experiments show that our approach achieves superior performance %for number-focused headline generation 
in both textual quality and numerical accuracy.  
%jz0: I'm trying to clone this into my account and make it public.
Our implementation is publicly available at 
\texttt{https://github.com/TEN-Sum/TEN}.
%\footnote{https://anonymous.4open.science/r/TEN-4664}. 
\end{abstract}

\section{Introduction}

%jz1: below please cite a few papers in the text below. You can borrow from the NumHG paper. 
Headline generation, an important task in abstractive summarization, aims to condense a news article into a single line of text. 
%Text summarization models have proven effective for this purpose. 
%Text summarization models have been developed for headline generation.  
In the literature, text summarization models employ pre-trained language models \citep{lewis_bart_2019, raffel_exploring_2023, zhang_pegasus_2020} and large language models (LLMs)~\cite{jin_comprehensive_2024} have shown 
%effective for generation of headlines  high textual quality. 
high textual quality for headline generation. 

Numerical facts are crucial elements for modern news articles, and headlines often include numerals to enhance conciseness and attract readers' attention. A headline like "Pink Floyd reaches deal with Sony to sell music catalogue for \underline{\$400m}"\footnote{https://www.theguardian.com/music/2024/oct/02/pink-floyd-catalog-sony} immediately grabs readers' interest. 

%jz1:The current example in Fig. 1 can not show how the correct number is obtained from the news article. Please include relevent textual context in the source document.  
\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{f1}
 % \caption{Example of Auto-Generated Rationale for Teaching LLM Headline Generation using the TEN Scheme}
 \caption{An example TEN Rationale for key elements of \underline{T}opic (green), \underline{E}ntities (blue) and \underline{N}umerical reasoning (purple).}
  \label{f1}
\end{figure}

Research shows that generating headlines with correct numbers requires mathematical reasoning capabilities in text summarization models~\cite{huang-etal-2024-numhg}. 
Obtaining correct numbers in headlines can involve mathematical operations such as addition, subtraction, and rounding of numbers from the source news articles. 
%\todo[color=green]{numhg paper now published in LREC-COLING 2024 --> done}
% jz1: some text to describe the example in Fig. 1. needed -- explain how the correct number is obtained (what operation) and what text summarization. 
As shown in Fig.~\ref{f1}, the news article covers the St. Louis protests, mentioning various entities and numbers. To generate an accurate headline, the language model must first identify the most newsworthy aspect of the event—the number of injured police officers. It then needs to calculate the correct number based on the information provided. In this case, the headline's number, 10, is not explicitly stated but requires addition (9 plus 1).
%jz1:below, citation needed. 
Number-focused headline generation requires 
not only text summarization to produce high quality text but also numerical reasoning within the textual context to generate the correct numbers. 

Existing studies on text summarization and numerical reasoning are inadequate for this challenging numerical headline generation problem~\citep{huang-etal-2024-numhg}. For text summarization, state-of-the-art pre-trained language models (PLMs)~\citep{lewis_bart_2019,zhang_pegasus_2020,liu_brio_2022} have relied on supervised fine-tuning to develop their summarization abilities. Researchers have also applied Chain-of-Thought (CoT) prompting~\citep{wang_element-aware_2023}, reinforcement learning~\citep{stiennon_learning_2022}, and direct preference optimization (DPO)~\citep{rajpoot_team_2024} to large language models (LLMs), aiming to improve their summarization quality. However, these methods focus on textual quality and do not address numerical accuracy.
%in the summaries. 

On the other hand, numerical reasoning models mainly focus on tasks that require producing a single numerical answer, such as solving word math problems, rather than generating text that includes numbers~\citep{ling_program_2017,amini_mathqa_2019,chiang_semantically-aligned_2019, cobbe_training_2021,wei_chain--thought_2023}. 
%jz3: below sentence "rationale" means "explanation", different from our definition. As rationale is only defined later, so rewrite and avoid using the word "rationale". 
Researchers have shown that language models' proficiency in solving these tasks can be enhanced through 
%rationale-augmented training 
explanation of intermediate steps
~\citep{amini_mathqa_2019, chiang_semantically-aligned_2019, cobbe_training_2021, wang_t-sciq_2023}, verification~\citep{cobbe_training_2021, wang_math-shepherd_2024}, and reinforcement learning~\citep{wang_math-shepherd_2024}. 
However, these techniques are developed in a setting where the question is given and they only need to infer the correct number as the final output. 

%When it comes to generating a numerically accurate headline, the challenge is twofold: it requires generation of concise text that captures both the essential topic and accurate numerical facts about the topic from the source news article. 
%This task involves not only text summarization but also the ability to extract and contextualize precise numbers within the textual context. 
%The model for number-focused headline generation needs to not only generate high quality text but also perform numerical reasoning within the textual context to generate the correct numbers. 

%jz3: below sentence needs more details. See my re-write.
In this paper, we propose a novel Chain-of-Thought (CoT) framework that uses rationales comprising key elements of \underline{T}opic, \underline{E}ntity and \underline{N}umerical reasoning (TEN) to teach and fine-tune LLMs for number-focused headline generation. 
Here rationales refer to textual descriptions for the key elements in a news article -- topics, entities, and numbers and their intermediate reasoning steps. These key element rationales can be used to enhance LLMs for the generation of topic-aligned headlines with higher numerical accuracy.  
%and critical elements that must be carefully considered before generating a headline.

Instead of costly manual annotation of TEN rationales, we propose to fine-tune open-source LLMs (e.g. Mistral 7B) to automatically generate such rationales for numerical headline generation.   
%In our approach, we first generates TEN reasoning rationales and then the news headline; for feasibility, ideally the base LLM should be an open-source LLM. 
%Building upon the teacher-student fine-tuning framework \citep{wang_t-sciq_2023}, our approach decomposes the rationales and optimizes the student LLMs via automatically generated Topic-Entity-Number-reasoning preferences. 
To enhance the capability for an open-source LLM to generate TEN rationales, we employ the teacher-student knowledge distillation framework~\cite{wang_t-sciq_2023} and leverage a powerful teacher LLM (e.g. GPT 4o) to generate TEN rationals as supervision data to fine-tune the open-source LLM as a student. 
Experiments show that our approach can achieve significant improvement over strong baselines in both textual quality and numerical accuracy. 

% jz3: training comprises two phases; inference is not a phase of training.
% jz3: but the description below is duplicated in Section 3. Such details are not needed for Introduction and so I removed it. 
% Training of the system comprises two phases -- 
% teacher generation of supervision data and fine-tuning student LLMs.
% %, and inference with the student LLMs. 
% In the supervision data generation phase, we instruct the teacher LLM to generate TEN rationales. 
% %that addresses two key issues: topic alignment and numerical reasoning. 
% %These rationales comprise three essential elements for headline generation: (1) Topic [T]; (2) Entities [E]; and (3) numerical Reasoning [N]. 
% In the fine-tuning phase, we develop two independent student LLMs: the rationale generator is fine-tuned to generate TEN reasoning rationales, while the headline generator is to generate headlines. 
% %jz3: below citations needed for DPO. 
% We further refine the rationale generator using DPO. The preference data for DPO are automatically generated to favour rationales that lead to headlines with matching topics and accurate numbers. 
% At the inference stage, the two fine-tuned student LLMs are applied sequentially. First, the rationale generator produces TEN rationales and then the headline generator uses these rationales together with the news articles as inputs to create the final headlines.

Contributions of our research are three fold:
\begin{itemize}
    \item We propose a CoT framework that uses rationales of key elements Topic, Entities and Numerical reasoning for LLMs to generate number-focused headlines. 
    %scheme to generate rationales automatically and use them as teaching signals to train student models to produce CoT-based headlines via fine-tuning.
    \item To enhance the capability for LLMs to generate topic-aligned headline text with high numerical accuracy, we apply the teacher-student framework to distill knowledge from a powerful teacher LLM to fine-tune an open-source LLM for automatic generation of TEN rationales.   
    %We distill TEN rationales from the teacher LLM GPT-4o to fine-tune student LLMs Mistral-7B and Llama-3.1-8B on the benchmark dataset NumHG and XSum. Our models achieve higher numerical accuracy than existing methodologies by 2.26 on NumHG, and 2.56 on XSum.
    \item We further develop a strategy based on Direct Preference Optimization \citep{rafailov_direct_2023} for LLMs to refine generation of TEN rationales. 
    %Our experiment results show that both ROUGE scores and accuracy scores are improved for the generated headlines.
\end{itemize}


\section{Related Work}

\subsection{Headline Generation}

Headline generation, a form of extreme text summarization, requires producing highly condensed, single-sentence summaries that capture the key information in a news article. 
%most important idea of the input text. 
% In the pioneering studies~\citep{narayan_dont_2018} and \citep{rush_neural_2015} at an early stage, 
%are pioneering work for extreme summarization. 
%They developed 
In early studies~\citep{rush_neural_2015,narayan_dont_2018}, models are supervise-trained on datasets containing single-sentence summaries (XSum)~\citep{narayan_dont_2018} and news-headline pairs (Gigaword) \citep{rush_neural_2015} However, their CNN-based and RNN-based approaches have since been outperformed by transformer-based models. 
%in the extreme summarization task. 
Recent studies show that transformer-based PLMs such as BART~\citep{lewis_bart_2019}, PEGASUS~\citep{zhang_pegasus_2020}, and BRIO~\citep{liu_brio_2022} can be fine-tuned on XSum and Gigaword to achieve promising results for extreme summarization and headline generation. 

While PLMs laid the bedrock for summarization, the advancement of LLMs has pushed the boundaries further. Several LLM-based approaches have emerged for general text summarization. Recent works have leveraged CoT prompting for summarization, proposing a "Summary Chain-of-Thought" method that guides LLMs to focus on key elements and generate summaries step-by-step~\citep{wang_element-aware_2023}. To further enhance summary quality, reinforcement learning methods have been employed to optimize LLMs based on human preferences~\citep{stiennon_learning_2022}. LLM-based approaches have also been tailored specifically for headline generation. For instance, leveraging reinforcement learning, \citet{tan_enhancing_2024} focus on creating personalized headlines for content recommendation. 
These approaches, whether PLM-based or LLM-based, focus on the text quality of summarization and the numerical accuracy is overlooked.
%\todo[color=green]{XF: maybe we need some related work to highlight the challenges from headline generation: 2020 extreme headline --> tbc}. 

%There are some closely related works. 
%Closely related 
Research on number-focused headline generation is reported recently. 
\citet{huang-etal-2024-numhg} assess the performance of PLMs in number-focused headline generation, but they do not provide strategies to enhance the models' numerical accuracy. \citet{rajpoot_team_2024} apply DPO to optimize headline generation using a preference dataset designed to train the model to favor headlines with correct numbers. While this preference for correct numbers can improve numerical accuracy, solely relying on it may degrade the textual quality of the generation. 
%Unlike previous approaches, our approach aims to enhance textual quality in headline generation as well as improve language models' numerical reasoning ability when generating headlines. 
% includes components explicitly designed to 

% \subsection{numerical Reasoning}
% \todo{XF: Do we discuss approaches other than providing rationales?} 
% Learning from human crafted rationales helps the performance, but requires human efforts
% \noindent{\textbf{Learning from human-crafted rationales.}} Researchers have demonstrated that language models' numerical reasoning abilities can be enhanced through learning from human-crafted rationales. 
% % rationale-augmented training. 
% One line of research employs humans to create natural language rationales for training~\citep{ling_program_2017}. They were the first to propose that language models could achieve higher accuracy in solving word math problems when required to generate both final answers and intermediate reasoning steps. 
% %Other researchers have shown that creating 
% Another line of research utilizes symbolic rationales for improving numerical reasoning abilities. For instance, symbolic equations can be used as intermediate steps to help solve word math problems~\citep{chiang_semantically-aligned_2019}. And in~\citep{amini_mathqa_2019}, the authors introduce a new representation language to model the intermediate steps so as to improve both the performance and the interpretability of the learned models. While effective, these methods rely heavily on human input, making them resource-intensive and potentially less scalable. 

% Learning from rationales generated by teacher LLMs helps the performance, and less human efforts
% \noindent{\textbf{Learning from teacher LLMs.}} 
% \subsection{Learning from LLM Generated TEN rationales.}
\subsection{CoT Prompting for Rationale Generation}

CoT prompting has gained great popularity due to its potential to unlock LLMs' reasoning capabilities by simply instructing them to generate intermediate steps as rationales before reaching a final answer~\citep{wei_chain--thought_2023}. For example, one can utilize CoT reasoning by simply adding the phrase "let's think step by step" to the end of each question~\citep{kojima_large_2023}. This approach is improved by a two-step process to generate rationales~\citep{zhang_automatic_2022}: first, selecting representative questions to generate exemplar rationales, and then using these representative rationales as demonstrations for LLMs to generate reasoning steps for other questions in the dataset. This idea is further enhanced by including the correct solution in prompts can enhance the quality of LLM-generated rationales~\citep{magister_teaching_2023}. 
 

%, specifically addressing the numerical accuracy issues in headline generation. 
% Our work also follows a two-step process to instruct an LLM to generate TEN rationales automatically, but we focus on creating rationales suitable for number-focused headline generation.

% Better rationales gives better performance
% \noindent{\textbf{Generating rationales through CoT prompting.}} In the LLM era, CoT prompting has gained great popularity due to its potential to unlock LLMs' reasoning capabilities by simply instructing them to generate intermediate steps before reaching a final answer~\citep{wei_chain--thought_2023}. CoT prompting has been applied to various tasks, including automatic rational generation. \citep{kojima_large_2023} demonstrate that CoT reasoning steps can be generated in a zero-shot manner by simply adding the phrase "let's think step by step" to the end of each question. \citep{zhang_automatic_2022} propose a two-step process to generate rationales automatically: first, selecting representative questions to generate exemplar rationales, and then using these representative rationales as demonstrations for LLMs to generate reasoning steps for other questions in the dataset. This idea is further enhanced by including the correct solution in prompts can enhance the quality of LLM-generated rationales~\citep{magister_teaching_2023}. Our work also follows a two-step process to instruct an LLM to generate TEN rationales automatically, but we focus on creating rationales suitable for number-focused headline generation. 

Especially for word math problems, research shows that LLM's numerical reasoning ability can be improved by learning from human-crafted rationales, including natural language intermediate reasoning steps~\citep{ling_program_2017} and symbolic representations like equations~\citep{chiang_semantically-aligned_2019,amini_mathqa_2019}. 
%While these methods have proven effective in enhancing model performance for tasks such as solving word math problems, 
But these methods rely on human annotations and therefore are costly. 
% jz3:I reworded and I think it sits here better. 
%\todo{XF: I feel this paragraph does not fit in here, can we put this paragraph at the beginning of this subsection?}

%potentially less scalable. 
% Better rationales gives better performance
\subsection{Learning from Teacher LLM Generated Rationales}
% summarize non-CoT in one or two sentences
% \noindent{\textbf{Learning from LLM generated TEN rationales.}} 

%An alternative approach that requires less human efforts involves 
% Learning from TEN rationales generated by teacher LLMs is a scalable alternative to reduce human efforts. 
Learning from rationales generated by teacher LLMs is a scalable alternative to human annotation. 
Research has shown that CoT reasoning steps generated from teacher LLMs can be used to fine-tune smaller student language models~\cite{ho_large_2023,hsieh_distilling_2023} that 
%. The CoT fine-tuned student models sometimes even outperform the teacher model in certain tasks. 
may even outperform the teacher LLM for some tasks.
% They validated their approach on four types of complex reasoning including arithmetic, symbolic, common sense, and other reasoning. 
%Similarly, in~\citep{hsieh_distilling_2023}, the authors suggest that the student model can achieve comparable performance with reduced training data when fine-tuned with LLM-generated rationales. They test their approach on several NLP tasks including arithmetic word math problems. 
Such teacher-student knowledge distillation has also been applied to multi-modal training for science QA~\cite{wang_t-sciq_2023}, which involves numerical reasoning.
The authors propose that mixing simple and complex reasoning in supervision data can enhance student LLMs' performance~\cite{wang_t-sciq_2023}. 
%Our work also follows a two-step process to instruct an LLM to generate TEN rationales automatically. But unlike existing works, our approach focuses on creating rationales that address the topic alignment and numerical reasoning so that two independent student LLMs can be further fine-tuned for number-focused headline generation tasks. 
Our approach also leverages the teacher-student knowledge distillation framework. 
Unlike existing work, we focus on rationales for topic alignment as well as numerical reasoning in numerical text generation.
%, which is not studied in existing work. 

Researchers have explored various approaches to enhance rationale quality, including the use of verifiers~\cite{cobbe_training_2021}, majority voting~\cite{wang_self-consistency_2023} and reinforcement learning~\cite{wang_math-shepherd_2024}. 
% In \citep{cobbe_training_2021}, the authors propose to train a verifier to rank the probabilities of correctness for model-generated rationales and select the most likely one. Similarly, the majority vote has been utilized to choose the most consistent output from several output rationales generated by LLMs~\citep{wang_self-consistency_2023}. 
Our approach, which leverages DPO for refining rationale generation, is closely related to reinforcement learning strategies~\citep{wang_math-shepherd_2024}. 
%the authors propose to automatically assess the step-wise correctness of model-generated rationales, 
%train a reward model using the labelled data, and further
%the authors propose to improve %LLMs' performance 
%LLM rationale generation through reinforcement learning. 
%Our approach of using DPO to refine also 
%explores the effectiveness of DPO in enhancing the quality of the generated rationales. 
%jz3: pelase check the my re-write below. 
However, unlike previous work that focuses solely on reward models for numerical reasoning rationales, our approach develops preference datasets tailored to both nuanced topic alignment and complex numerical reasoning. 

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth, trim={2cm 2.45cm 0cm 1.7cm}, clip]{f2}
%  \caption {Three-phase pipeline of the proposed TEN fine-tuning scheme: (1) Generating supervision data, (2) Fine-tuning student LLMs, and (3) Inferring with fine-tuned student LLMs for headline generation.}
  \caption {Our TEN approach for automatic generation of rationales to enhance numerical headline generation.}
  \label{fig:three_phase_of_TEN}
\end{figure*}

\section{Methodology}
%\todo[color=green]{XF: figure 2 ECNC need to be updated to TEN --> done}

%This section presents our TEN reasoning rationales  fine-tuning scheme TEN, as shown in Figure~\ref{fig:three_phase_of_TEN}. 
This section presents our framework for leveraging the teacher-student knowledge distillation framework to fine-tune LLMs for automatic generation of TEN rationales to enhance LLM headline generation.
%jz3: below, CoT rationale > TEN rationale
We employ a teacher LLM (e.g. GPT 4o) to generate TEN rationales 
%for number-focused headline generation and 
%jz3: below, teaching data > supervision data 
and use these rationales as supervision data to fine-tune a student LLM (e.g. Mistral-7B), including a rationale generator for automatic generation of TEN rationales and
a headline generator for headline generation. 

As shown in Fig.~\ref{fig:three_phase_of_TEN}, our approach adopts a teacher-student framework to fine-tune a (student) LLM to automatically generate TEN rationales.  
%framework comprises three phases: teacher generation of supervision data, fine-tuning student LLMs for rationale and headline generation, and inference with fine-tuned student LLMs. 
When generating supervision data to fine-tune a rationale generator, 
we prompt a teacher LLM to generate rationales for each news-headline pair in the dataset.  
The rationales are aimed to enhance the topic alignment and numerical reasoning capabilities for numerical headline generation, comprising key elements \underline{T}opic and \underline{E}ntities, 
as well as \underline{N}umbers in the news article and the intermediate reasoning steps to calculate the correct number in the headline. 
%These rationales are further decomposed into three essential elements (TEN) for headline generation. 

The teacher LLM generated rationales are used as supervision data to 
%When fine-tuning student LLM, we use the supervision data along with the input (news-article, headline) pairs to two independent student LLMs, 
%one fine-tuned for generating TEN rationales (the rationale generator) and another for generating headlines (the headline generator). 
fine-tune a student LLM as the rationale generator. 
We further refine the rationale generator using DPO. The preference data for DPO are automatically generated to favour rationales that lead to headlines with matching topics and accurate numerals. 
The news article and teacher LLM generated TEN rationales are then used to fine-tune another student LLM for headline generation. 
In the inference phase, the two fine-tuned student LLMs are used sequentially. The rationale generator will first produce TEN rationales for the input news article. The headline generator will then use the rationales together with the news articles as input to generate final headlines. 

%we generate the final headline in two steps.
\begin{figure*}[t]
  \includegraphics[width=\textwidth]{f3ab}
%  \parbox[b]{0.45\textwidth}{\centering Step 1: Generating representative TEN rationales via zero-shot prompting.}
  % \parbox[b]{0.45\textwidth}{\centering (a) An example zero-shot prompt for generating TEN rationales.}
  % \hspace{0.05\textwidth}
%  \parbox[b]{0.45\textwidth}{\centering Step 2: Generating teaching signals for the entire dataset via few-shot prompting.}  
  % \parbox[b]{0.45\textwidth}{\centering (b) The five-shot prompt to generate rationales for supervised fine-tuning student LLMs}  
  \caption {The process for Teacher LLM to generate TEN rationales for fine-tuning student LLMs}
  \label{fig:pre_tuning}
\end{figure*}

\subsection{Teacher LLM generation of TEN rationales}
In this phase, we focus on utilizing a teacher LLM to generate TEN rationales as supervision data. 
Figure~\ref{fig:pre_tuning} shows the process for generating this data. It is generated through a two-step process~\citep{zhang_automatic_2022}. 
% As shown in Figure~\ref{fig:pre_tuning}, 
%jz0: below, with the five examples, I believe we did 5-shot prompting here rather than zero-shot prompting? 
%jz0: I reworded the setence to avoid confusion. 
%In the first step, we carefully select representative examples and instruct a teacher LLM to generate rationales for these examples using zero-shot prompting.
In the first step, we instruct a teacher LLM with zero-shot prompting to generate demonstration TEN rationales for a few (five) representative examples for calculating numbers in headlines. 
In the second step, we employ these demonstration rationales as context to generate rationales for other examples in the whole training dataset using few-shot prompting. Specifically, we create demonstration rationales for five representative examples from the NumHG dataset \citep{huang-etal-2024-numhg}. 
%This dataset not only provides news-headline pairs but also includes human annotations detailing the types of mathematical operations required to derive the numerals in the headlines. 
The five examples are selected to represent five types of mathematical operations annotated in this dataset: (a) Copying: The numeral is directly copied from the article. (b) Addition: Numerals from the article are added to get the final numeral. (c) Subtraction: One numeral is subtracted from another. (d) Paraphrasing: The digits of the numeral are rewritten (e.g., changing 6,000 to 6k). and (e) Rounding: Only certain digits after the decimal point are retained. The details of the five demonstrations are shown in Appendix~\ref{appendix: five-demonstrations}.

%\todo{XF: It feels we can include those 5 samples in the appendix (e.g. using lstlisting).}

% \begin{enumerate}
%     \item Copying: The numeral is directly copied from the article.
%     \item Addition: Numerals from the article are added to get the final numeral.
%     \item Subtraction: One numeral is subtracted from another.
%     \item Paraphrasing: The digits of the numeral are rewritten (e.g., changing 6,000 to 6k).
%     \item Rounding: Only certain digits after the decimal point are retained.
% \end{enumerate}

We next instruct the teacher LLM to elaborate on the intermediate steps that lead to high-quality headlines with accurate numerals for the five selected examples. The prompts we use are shown in Figure~\ref{fig:pre_tuning}. 
%We structure these intermediate steps to focus on three key elements for the news article -- The Topic of the headline (T), the Entities mentioned (E), and the Numbers mentioned (N) -- as well as the intermediate reasoning steps to calculate the number in the reference headline. 
Note that the TEN rationale comprise key elements for the news article, including numerical reasoning steps. 
Note also that to enhance the reliability of the teacher LLM-generated rationales, we also provide the reference headlines and the correct numbers to the teacher LLM in prompts. The numbers in the reference headlines are masked to ensure the teacher LLM focuses on the topic when generating topic-alignment rationales. The correct numbers are provided separately as hints to improve accuracy in numerical reasoning rationales. We then manually review and refine these five rationales to adhere to the template, ensuring consistency across the entire dataset. Using these five example TEN rationales as demonstrations, we instruct the teacher LLM to generate TEN rationales for the complete training datasets through five-shot prompting. 

% \begin{enumerate}
%     \item Topic of headline (E)
%     \item Characters mentioned (C)
%     \item Numerals mentioned (N)
%     \item Calculations of Numerals (C)
% \end{enumerate}

\subsection{Fine-Tuning Student LLMs}
Inspired by~\citep{zhang_multimodal_2024}, we fine-tune two student LLMs independently, as illustrated in Figure~\ref{fig:three_phase_of_TEN}. The first student LLM (rationale generator) generates TEN rationales from news articles. The second model (headline generator), initialized from the same student LLM, is fine-tuned to predict headlines using both the news articles and the TEN rationales generated by the teacher LLM as inputs. 

We also apply DPO to the rationale generator to enhance its output quality. To construct the preference dataset for DPO, we first use the fine-tuned rationale generator to sample multiple rationales for each news article in the training data using a high temperature. Next, we use the headline generator to complete headlines based on the news articles and sampled rationales. We then build a pair of chosen and rejected rationales for each instance in the training data based on the following criteria: (a) Choose the rationale that leads to the headline with correct numerals and reject the one that results in a headline with incorrect numerals. (b) Choose the rationale with a high ROUGE score compared to the reference rationale and reject the one with a low ROUGE score. The flowchart for automatically constructing preference data is shown in Appendix~\ref{appendix:preference_data}. 
%\todo[color=green]{XF: Maybe an algorithm can better explain how preference is made. --> Done with a flowchart in appendix}

% \begin{itemize}
%     \item Choose the rationale that leads to the headline with correct numerals and reject the one that results in a headline with incorrect numerals.
%     \item Choose the rationale with a high ROUGE score compared to the reference rationale and reject the one with low ROUGE score.
% \end{itemize}

% \subsection{Inferring with Fine-Tuned Student LLMs}
% In this phase, we have obtained the fine-tuned student LLMs: the rationale generator and the headline generator. The two fine-tuned student LLMs are used sequentially. As shown in Figure~\ref{fig:three_phase_of_TEN}, the rationale generator will first produce TEN rationales for the input news article. Then, the headline generator will use the rationales together with the news articles as input to generate final headlines. 

% During the deployment phase, we use the rationale generator and headline generator in a pipeline. First, the rationale generator predicts TEN rationales based on the news articles. Then, the headline generator takes these predicted TEN rationales along with the original news articles to produce the final headlines. 

% \section{Experiment Setup}
\section{Experiments}
We evaluate our approach TEN against state-of-the-art baselines on benchmark datasets for number-focused headline generation. 
%from one representative PLM-based method and recent LLM-based methods for headline generation tasks. 
%\todo[color=green]{Experiment environment and software used need to be updated --> done}
%Experiments on NumHG are conducted on a system which consists of 32 cores, 128G memory and is equipped with an NVIDIA A100 (40G) GPU. Experiments on XSum are conducted on a system which consists of 32 cores, 128G memory and is equipped with 8 NVIDIA L40S (45G) GPU. 
In all experiments, GPT 4o is the teacher LLM for our TEN approach. 
All experiments were conducted on a system with 32 cores, 128GB memory and NVIDIA A100(40G) GPU. The estimated GPU usage for our experiments is approximately 2,000 hours.
All deep neural networks are implemented using Transformers~\citep{wolf2019huggingface} (distributed with the Apache-2.0 license) under the support of PyTorch~\citep{paszke2019pytorch} (distributed with the modified BSD-3-Clause license). 
%jz3: @Zhen: the real url for the anonymous github repo is needed below. 
% the repo content can be done after paper submission but the url must be real. 
Implementation details, including parameter efficient fine-tuning settings and hyperparameter settings are in Appendix~\ref{appendix:implementation}. 

\subsection{Datasets and Evaluation Metrics}
We evaluate our proposed approach using two real-world datasets: 
\begin{itemize}
	\item The NumHG dataset~\citep{huang-etal-2024-numhg} is a large dataset for number-focused headline generation that is also used for SemEval-2024 Task 7 ``NumEval: Numeral-aware language understanding and generation'' task.~\footnote{https://sites.google.com/view/numeval/numeval} 
 %It contains approximately 
 %\todo[color=green]{exact number maybe better --> done}27,74 news-headline pairs sourced from the news platform Newser\footnote{https://www.newser.com/}. 
 Each news article contains 200--300 words, and all headlines include numerals. This dataset provides human annotations of mathematical operations required to derive the numerals in each headline. 
 %To focus on validating the model's numerical reasoning ability, 
 We apply a pre-processing step to the dataset by removing duplicate samples and retaining only those with one number in the headlines. 
 %After this data pre-process, 
 In the end, we obtained 18,315 samples for training and 3,579 for testing.
    \item The XSum dataset~\citep{narayan_dont_2018} is 
    %\todo[color=green]{intro to XSum needed --> done} 
    an extreme summarization dataset comprising 226,771 BBC articles from 2010 to 2017, each accompanied by a single-sentence summary. 
    %These summaries, serving as introductory sentences for the articles, are crafted by the authors themselves. 
    We applied pre-processing and selected articles containing 200--500 words and summaries containing only a whole number. This resulted in 9,052 samples for training and 1,605 for testing. 
    % with one single whole number, , as headlines with multiple numerals are challenging to evaluate for numerical accuracy
\end{itemize}

% \subsection{Evaluation Metrics}
We adopt the evaluation metrics commonly used in existing studies~\citep{huang-etal-2024-numhg} to assess both the textual quality and numerical accuracy for headline generation. 
%For textual quality, 
We adopt ROUGE~\citep{lin2004rouge}, BERTScore~\citep{zhang2019bertscore}, and MoverScore~\citep{zhao2019moverscore} for textual quality. 
%They are calculated against ground truth headlines. 
For numerical accuracy, 
a generated headline's numeral is considered correct if it matches the numeral
in the reference headline. 
%and it matches the ground truth. 
We use the evaluation code~\footnote{https://github.com/ChunJiChen/NumEval\_Evaluation} from~\citet{huang-etal-2024-numhg} to automatically calculate these metrics. 

%jz3: below should move to later closer to the result table.
%The NumHG dataset includes annotations for the type of operations needed to obtain the correct numeral in headlines. This allows us to break down the numerical accuracy into three categories: overall accuracy, copy accuracy, and reasoning accuracy. Copy accuracy is the numerical accuracy when the correct numeral can be directly copied from the news article. Reasoning accuracy is the numerical accuracy when mathematical operations are required. For the XSum dataset, which lacks operation type annotations, we only report the overall accuracy. 

\subsection{Baselines}

We compare TEN against three baseline methods, including one representative PLM-based method and two recent LLM-based methods. 
\begin{itemize}
	\item BART~\citep{lewis-etal-2020-bart,huang-etal-2024-numhg} 
 %is a PLM widely applied for various tasks. As reported in the NumHG dataset~\citep{huang-etal-2024-numhg}, 
 is a PLM-based representative baseline for numerical headline generation that is shown to outperform other PLM-based methods like T5, Pegasus, SEASON, and BRIO in terms of numerical accuracy while maintaining comparable textual quality~\cite{huang-etal-2024-numhg}. 
 %Thus BART is selected as the representative PLM-based method. 
%jz3: below, NLC_NLP > NLC, please update the table. 
\item NCL (NCL\_NLP)~\citep{zhao_ncl_nlp_2024} is an LLM-based method from SemEval-2024 Task 7 that achieves reasonable result. 
% jz3: our implementation of NLC should use the same teacher and student LLMs for TEN. 
Similar to TEN, they also employ the teacher-student framework to generate CoT rationales to fine-tune student LLMs for headline generation. 
%a teacher LLM (GPT-3.5-Turbo) to generate TEN rationales as supervision data and fine-tune a student LLM (Mistral-7B) for headline generation. 
%We implement this baseline by instructing the teacher LLM to generate rationales based on the given news articles, using the correct headlines as hints. 
Different from TEN, NCL does not do the structured, element-wise rationales. 
Comparing TEN against NCL will help us understand the effectiveness of our TEN reasoning strategy. 
 %jz3: below, NP-problm > NPP, please update the table. 
    \item NPP (NP-Problem)~\citep{rajpoot_team_2024} is another LLM-based baseline from SemEval-2024 Task 7. NPP achieved the highest numerical accuracy and comparable text quality among all submissions. 
%    an LLM-based method that came from SemEval-2024's task 7 which is a shared task specifically for the number-focused headline generation. 
They fine-tune Mistral-7B for headline generation and further align the model-generated headlines through DPO. 
%Their method achieved the highest numerical accuracy in headline generation among the participants in SemEval-2024's task 7. 
As both TEN and NPP use DPO to refine headline generation, their comparison can reveal the utility of our strategy of preference data generation for DPO. 
    % Unlike our TEN scheme, which breaks down TEN rationales into four essential elements, this method doesn't specify particular focus areas. We then use these rationales as supervision data to fine-tune Mistral-7B. 
\end{itemize}

% The first is fine-tuned BART. \citet{huang_numhg_2023} have evaluated state-of-the-art PLMs for number-focused headline generation, including BART, T5, Pegasus, SEASON, and BRIO. Their experimental results show that fine-tuned BART achieves the highest numerical accuracy in headline generation while maintaining comparable textual quality. 

% We also choose \citet{rajpoot_team_2024}'s method as a baseline. They have fine-tuned Mistral-7B for headline generation and further aligned the model-generated headlines through DPO. Their method achieved the highest numerical accuracy in headline generation among the participants in SemEval-2024's task 7. 

% The final baseline method we select is proposed by \citet{zhao_ncl_nlp_2024}. They employ a teacher LLM (GPT-3.5-Turbo) to generate TEN rationales as supervision data and fine-tune a student LLM (Mistral-7B) for headline generation. This knowledge distillation approach has shown state-of-the-art performance in reasoning tasks \citep{wang_t-sciq_2023} but is rarely used in headline generation. We choose this baseline because we also use CoT fine-tuning and want to compare our TEN rationale decomposition scheme with the existing method. We implement this baseline by instructing the teacher LLM to generate rationales based on the given news articles, using the correct headlines as hints. Unlike our TEN scheme, which breaks down TEN rationales into four key aspects, this method doesn't specify particular focus areas. We then use these rationales as supervision data to fine-tune Mistral-7B. 



\begin{table*}[t]
  \centering
  \resizebox{\textwidth}{!}{
  \begin{tabular}{lccc|ccc|ccc|c}
    \hline
    &&\textbf{Num Acc}&&&\textbf{ROUGE}&&&\textbf{BERTScore}&&\textbf{MoverScore}\\
    \cline{2-11}
     & Overall & Copy & Reasoning & 1 & 2 & L & P & R & F1 & \\
    \hline
    BART & 71.59 & 76.54 & 61.82 & 48.13 & 22.76 & 43.36 & 49.29 & 50.81 & 50.60 & 60.34 \\
    NPP & 74.57 & 77.43 & 68.93 & 49.24 & 23.44 & 44.08 & 50.17 & 50.57 & 50.36 & 60.54 \\
    NCL & 74.94 & 78.43 & 68.06 & 50.03 & 24.72 & 45.39 & 53.44 & 51.19 & 52.31 & \textbf{60.97} \\
    % \rowcolor{lightgray}
    TEN (Ours) & \textbf{77.20} & \textbf{81.11} & \textbf{69.49} & \textbf{51.14} & \textbf{25.46} & \textbf{46.29} & \textbf{54.57} & \textbf{51.84} & \textbf{53.21} & \textbf{61.23} \\
    \hline
    % \hline
  \end{tabular}
  }
  % \caption{\label{tbl:main_result_numhg}
  %   Comparative analysis of numerical accuracy and textual quality metrics for baseline methods and our proposed approach on the \textbf{NumHG} dataset.
  % }
  \caption{\label{tbl:main_result_numhg}
    Numerical accuracy (\%) and textual quality score (\%) for TEN against baselines on \textbf{NumHG}. Higher numbers indicate better performance. Best results are in bold, where results within 0.5\% difference are deemed comparable.
  }
\end{table*}

\begin{table*}[t]
  \centering
  \resizebox{0.82\textwidth}{!}{
  \begin{tabular}{lc|ccc|ccc|c}
    \hline
    &\textbf{Num Acc}&&\textbf{ROUGE}&&&\textbf{BERTScore}&&\textbf{MoverScore}\\
    \cline{2-9}
     & Overall & 1 & 2 & L & P & R & F1 & \\
    \hline
    BART & 29.34 & 43.83 & 19.81 & 35.46 & 52.54 & 54.16 & 53.38 & 60.46 \\
    NPP & 30.15 & 46.32 & \textbf{22.58} & \textbf{38.08} & 55.60 & \textbf{55.82} & 55.73 & \textbf{61.35} \\
    NCL & 36.76 & 45.17 & 21.47 & 37.07 & 57.30 & 53.49 & 55.41 & \textbf{61.02} \\
    % \rowcolor{lightgray}
    TEN (Ours) & \textbf{39.07} & \textbf{46.63} & \textbf{22.50} & \textbf{38.36} & \textbf{58.81} & 54.57 & \textbf{56.70} & \textbf{61.36} \\
    \hline
    % \hline
  \end{tabular}
  }
  % \caption{\label{tbl:main_result_xsum}
  %   Comparative analysis of numerical accuracy and textual quality metrics for baseline methods and our proposed approach on the \textbf{XSum} dataset.
  % }
  \caption{\label{tbl:main_result_xsum}
    Numerical accuracy (\%) and textual quality metric score (\%) for TEN against baseline methods on  \textbf{XSum}. Higher numbers indicate better performance. The best results are in bold, where results within 0.5\% difference are deemed comparable.
  }
\end{table*}

% \begin{table}[t]
%   \centering
%   \resizebox{0.5\textwidth}{!}{
%   \begin{tabular}{lcccc}
%     \hline
%     & \multicolumn{2}{c}{\textbf{NumHG}} & \multicolumn{2}{c}{\textbf{Xsum}} \\
%     \hline
%     & NumAcc & ROUGE-1 & NumAcc & ROUGE-1 \\
%     \hline
%     Mistral-7B-v0.3 & & & & \\
%     \hline
%     \: TEN w/o DPO & 76.24 & 50.95 & 37.69 & 46.26 \\
%     \: TEN (Ours) & \textbf{77.20} & \textbf{51.14} & \textbf{39.07} & \textbf{46.63}\\
%     % \hline
%     \hline
%     Llama-3.1-8B & & & & \\
%     \hline
%     \: TEN w/o DPO & 76.06 & 50.69 & 36.76 & 45.89 \\
%     \: TEN (Ours) & \textbf{77.89} & \textbf{51.15} & \textbf{37.51} & \textbf{46.03} \\
%     \hline
%   \end{tabular}
%   }
%   \caption{\label{tbl:dpo_ablation}
%     Comparative analysis of headline generation performance: impact of refining model-generated rationales through Direct Preference Optimization (DPO) on two student models Mistral-7B-v0.3 and Llama-3.1-8B.
%   }
% \end{table}

% \section{Main Results}
\subsection{Experiment Results}

%\noindent \textbf{TEN vs Baselines.} Tables~\ref{tbl:main_result_numhg} and~\ref{tbl:main_result_xsum} show the performance of TEN against baseline methods on the NumHG and XSum datasets respectively. 
For fair comparison, all baselines use Mistral-7B, and we also use Mistral-7B as the student LLM for TEN.
Following existing studies in the literature~\cite{huang-etal-2024-numhg}, we employ numerical accuracy and textual similarity metrics ROUGE~\cite{lin2004rouge}, BERTScore~\cite{zhang2019bertscore} and MoverScore~\cite{zhao_moverscore_2019} for evaluation. 
Note that textual similarity metrics evaluate the complete headline text, including numbers as tokens, and therefore can  be seen as measuring the overall quality for number-focused headlines.

The NumHG dataset includes annotations for the type of operations needed to obtain the correct numeral in headlines. 
%This allows us to break down 
The numerical accuracy thus includes overall accuracy, copy accuracy (when numbers can be directly extracted from the news), and reasoning accuracy (when mathematical operations are required).   
%-- Copy accuracy is the numerical accuracy when the correct numeral can be directly copied from the news article. Reasoning accuracy is the numerical accuracy when mathematical operations are required. 
On the XSum dataset, which lacks operation type annotations, we only report the overall accuracy. 
%The results demonstrate that our approach outperforms existing methodologies. Note that the LLM baselines all utilize Mistral-7B
%\todo[color=green]{XF: suggest we use Mistral-7B instead of Mistral-7B-v0.3 in main content --> already done?}, 

Observe from Table~\ref{tbl:main_result_numhg} that on the NumHG dataset, TEN achieves an overall numerical accuracy of 77.20\%, surpassing BART by 5.61\%, NPP by 2.63\%, and NCL by 2.26\% (in absolute percentage points).
In Table~\ref{tbl:main_result_xsum}, on the XSum dataset, TEN reaches an overall accuracy of 
%\todo[color=green]{XF: these numbers should be updated --> done}
39.07\%, outperforming BART by 9.73\%, NPP by 8.92\%, and NCL by 2.31\%. While improving numerical accuracy, TEN also maintains mostly higher textual quality by textual similarity metrics ROUGE, BERTScore, and MoverScore. 

% jz3: some discussion is needed below. 
%Here: compare TEN against NP; compare TEN against NCL. Follow the description of baselines.
Models trained with our TEN framework outperform NCL, demonstrating that our TEN rationales are more effective than NCL's rationales that only explain how the correct number in the headline is obtained. Our approach also outperforms NPP, demonstrating that enhancing the intermediate rationale generation process is a more effective strategy for improving headline's numerical accuracy.

%\noindent \textbf{LLM-based Quality Evaluation.}
We further evaluated the quality of the generated news headlines using an LLM-based metric G-Eval \cite{liu_g-eval_2023}.
Recent research shows that LLMs can be used for evaluation of quality of generated texts and demonstrate strong correlation with human judgements. 
G-Eval leverages the capability of LLMs and Chain-of-Thoughts prmopts to assess the quality of model-generated texts. 
We employed G-Eval(GPT4) to evaluate four aspects of generated headlines: coherence, consistency, fluency, and relevance. As shown in Table~\ref{tbl:llm_based_quality_evaluation}, 
%TEN achieved the highest scores across all four dimensions.
TEN outperforms all baselines on NumHG and achieves comparable results on XSum. 


%jz0: Any results on XSum?
\begin{table*}[htbp]
  \centering
  \resizebox{\textwidth}{!}{

  % \begin{tabular}{lcccc}
  %   \hline
  %   &\textbf{Coherence}&\textbf{Consistency}&\textbf{Fluency}&\textbf{Relevance}\\
  %   BART&4.04&4.36&2.82&4.11\\
  %   NPP&4.17&4.65&2.91&4.22\\
  %   NCL&4.17&4.71&\textbf{2.96}&4.23\\
  %   TEN&\textbf{4.18}&\textbf{4.72}&\textbf{2.96}&\textbf{4.24}\\
  %   \hline
  % \end{tabular}  
  
  \begin{tabular}{l|cccc|cccc}
    \hline
    &\multicolumn{4}{c|}{\textbf{NumHG}} & \multicolumn{4}{c}{\textbf{XSum}}\\
    \hline    
    &\textbf{Coherence}&\textbf{Consistency}&\textbf{Fluency}&\textbf{Relevance}&\textbf{Coherence}&\textbf{Consistency}&\textbf{Fluency}&\textbf{Relevance}\\ \hline
    BART&4.0361&4.3647&2.8209&4.1068&3.3740&2.9179&2.6836&3.2840\\
    NPP&4.1734&4.6550&2.9068&4.2184&3.3782&2.9048&2.6758&3.2853\\
    NCL&4.1739&4.7108&\textbf{2.9616}&4.2264&3.3795&2.9037&2.6830&3.2767\\
    TEN&\textbf{4.1853}&\textbf{4.7210}&2.9594&\textbf{4.2436}&3.3733&2.9125&2.6802&3.2824\\
    \hline
  \end{tabular}
  }
  % \caption{\label{tbl:main_result_numhg}
  %   Comparative analysis of numerical accuracy and textual quality metrics for baseline methods and our proposed approach on the \textbf{NumHG} dataset.
  % }
  \caption{\label{tbl:llm_based_quality_evaluation}
    G-Eval scores for TEN against baselines on \textbf{NumHG} and \textbf{XSum}. Headlines are assessed in terms of Coherence (1-5), Consistency (1-5), Fluency (1-3), and Relevance (1-5). The higher numbers indicate better performance. Best results are in bold.}
\end{table*}

\subsection{Performance of TEN rationales and Teacher-student knowledge distillation}
%\noindent \textbf{Effect of TEN on GPT-4o.}
The structured rationales and teacher-student paradigm to distill knowledge from a teacher LLM (GPT-4o) to a student LLM (Mistral 7B and Llama 3.1) are important parts of our TEN framework. 
%Effectiveness of the system depends on the performance of the teacher LLM. 
To evaluate the effectiveness of TEN rationales and if GPT-4o is a good teacher LLM, we evaluated the performance of GPT-4o with and without TEN structured rationales under zero-shot prompting. %Specifically, GPT-4o is evaluated using NumHG test data in two settings. Setting 1 "without TEN" is to prompt GPT-4o to directly generate headlines based on news articles. Setting 2 "with TEN" is to include the instructions for GPT-4o to generate both TEN-structured rationales and headlines. 
The results are shown in Table~\ref{tbl:main_result_gpt4o_both}. It can be seen that by prompting GPT-4o to generate TEN rationales, performance improved significantly both for numerical accuracy and textual quality.

%jz0: below overall table replace the two separate tables on NumHG and XSum. 
%jz0: The headings "NumHG w/o TEN" is not quite right though --> "w/o TEN" as the method. Please reformat the table to match the other tables using two datasets NumHG and Xsum as columns. You have to use ROUGE-1 and BERSTScore-F1
\begin{table*}[htbp]
  \centering
  \resizebox{\textwidth}{!}{
  % \begin{tabular}{l|c|ccc|ccc|c}
  %   \hline
  %   & \textbf{Num Acc}&\textbf{ROUGE}&&&\textbf{BERTScore}&&&\textbf{MoverScore}\\
  %   & & 1 & 2 & L & P & R & F1 & \\
  %   \hline
  %   NumHG w/o TEN & 21.39 & 35.59 & 13.63 & 30.82 & 30.33 & 48.38 & 39.21 & 56.53 \\
  %   NumHG w TEN & 33.01 & 35.47 & 13.14 & 30.96 & 33.06 & 46.82 & 39.86 & 56.72 \\   
  %   XSum w/o TEN & 6.23 & 22.59 & 4.98 & 17.77 & 19.70 & 25.71 & 22.76 & 54.58 \\
  %   XSum w TEN & 9.91 & 22.18 & 5.14 & 17.65 & 21.43 & 24.73 & 23.14 & 54.63 \\
  %   \hline
  %   % \hline
  % \end{tabular}
  \begin{tabular}{l|cccc|cccc}
    \hline
    &\multicolumn{4}{c|}{\textbf{NumHG}} & \multicolumn{4}{c}{\textbf{XSum}}\\
    \hline
     & Num Acc & ROUGE-1 & BERTScore-F1 & MoverScore & Numm Acc & ROUGE-1 & BERTScore-F1 & MoverScore\\
    \hline
    w/o TEN & 21.39 & 35.59 & 39.21 & 56.53 & 6.23 & 22.59 & 22.76 & 54.58\\
    w TEN & 33.01 & 35.47 & 39.86 & 56.72 & 9.91 & 22.18 & 23.14 & 54.63\\
    \hline
  \end{tabular}
  
  }
  % \caption{\label{tbl:main_result_numhg}
  %   Comparative analysis of numerical accuracy and textual quality metrics for baseline methods and our proposed approach on the \textbf{NumHG} dataset.
  % }
\caption{\label{tbl:main_result_gpt4o_both}
%    The effectiveness of TEN rationales: Numerical accuracy (\%) and textual quality score (\%) for GPT-4o under zero-shot prompting on \textbf{NumHG} and \textbf{XSum}. 
Performance of GPT-4o with/without TEN rationales under zero-shot prompting on \textbf{NumHG} and \textbf{XSum}.
  }
\end{table*}

% \begin{table*}[htbp]
%   \centering
%   \resizebox{\textwidth}{!}{
%   \begin{tabular}{lccc|ccc|ccc|c}
%     \hline
%     &&\textbf{Num Acc}&&&\textbf{ROUGE}&&&\textbf{BERTScore}&&\textbf{MoverScore}\\
%     \cline{2-11}
%      & Overall & Copy & Reasoning & 1 & 2 & L & P & R & F1 & \\
%     \hline
%     Zero-shot w/o TEN & 21.39 & 28.35 & 7.67 & 35.59 & 13.63 & 30.82 & 30.33 & 48.38 & 39.21 & 56.53 \\
%     Zero-shot w TEN & 33.01 & 44.11 & 11.15 & 35.47 & 13.14 & 30.96 & 33.06 & 46.82 & 39.86 & 56.72 \\    
%     Five-shot w/o TEN & 43.55 & 52.00 & 26.88 & 41.37 & 16.93 & 36.27 & 38.46 & 50.30 & 44.32 & 57.95 \\
%     Five-shot w TEN & 51.16 & 58.74 & 36.21 & 41.51 & 17.25 & 36.50 & 45.19 & 49.07 & 47.14 & 57.86 \\    
%     \hline
%     % \hline
%   \end{tabular}
%   }
  % \caption{\label{tbl:main_result_numhg}
  %   Comparative analysis of numerical accuracy and textual quality metrics for baseline methods and our proposed approach on the \textbf{NumHG} dataset.
  % }
% \caption{\label{tbl:main_result_numhg_inc_gpt4o}
%     Numerical accuracy (\%) and textual quality score (\%) for GPT-4o using zero-shot and five-shot prompting in \textbf{NumHG}. Experimental results shows the performance of GPT-4o with and without TEN rationales in prompts.
%   }
% \end{table*}



% \begin{table*}[htbp]
%   \centering
%   \resizebox{0.82\textwidth}{!}{
%   \begin{tabular}{lc|ccc|ccc|c}
%     \hline
%     &\textbf{Num Acc}&&\textbf{ROUGE}&&&\textbf{BERTScore}&&\textbf{MoverScore}\\
%     \cline{2-9}
%      & Overall & 1 & 2 & L & P & R & F1 & \\
%     \hline
%     Zero-shot w/o TEN & 6.23 & 22.59 & 4.98 & 17.77 & 19.70 & 25.71 & 22.76 & 54.58 \\
%     Zero-shot w TEN & 9.91 & 22.18 & 5.14 & 17.65 & 21.43 & 24.73 & 23.14 & 54.63 \\
%     Five-shot w/o TEN & 16.76 & 29.09 & 8.88 & 23.18 & 31.78 & 35.63 & 33.75 & 56.74 \\
%     Five-shot w TEN & 10.41 & 25.82 & 7.04 & 20.37 & 34.75 & 34.20 & 34.53 & 55.83 \\   
%     \hline
%     % \hline
%   \end{tabular}
%   }
%   % \caption{\label{tbl:main_result_xsum}
%   %   Comparative analysis of numerical accuracy and textual quality metrics for baseline methods and our proposed approach on the \textbf{XSum} dataset.
%   % }
%   \caption{\label{tbl:main_result_xsum_inc_gpt4o}
%     Numerical accuracy (\%) and textual quality score (\%) for GPT-4o using zero-shot and five-shot prompting in \textbf{XSum}. Experimental results shows the performance of GPT-4o with and without TEN rationales in prompts.
%   }
% \end{table*}



%\noindent \textbf{How effective student LLM has learned from teacher LLM.}
We further conducted experiments to evaluate if the student LLM can effectively learn rationale generation from the teacher LLM. 
On the test data, we computed the textual and semantic similarity scores for the rationales automatically generated by Mistral-7B-v0.3 and Llama-3.1-8B as the student model, against the supervision data generated by the teacher LLM GPT-4o. Table~\ref{tbl:rationale_evaluation} illustrates the evaluation results. The high textual similarity and semantic similarity scores demonstrate that the student model can learn from the teacher model to generate rationales to enhance its reasoning capability for number-focused headline generation.

\begin{table*}[htbp]
  \centering
  \resizebox{\textwidth}{!}{
  \begin{tabular}{l|ccc|ccc}
    \hline
    &\multicolumn{3}{c|}{\textbf{NumHG}} & \multicolumn{3}{c}{\textbf{XSum}}\\
    \hline
     & ROUGE-1 & BERTScore-F1 & MoverScore & ROUGE-1 & BERTScore-F1 & MoverScore\\
    \hline
    Mistral-7B-v0.3 & 84.12 & 81.13 & 71.03 & 75.46 & 70.43 & 66.68\\
    Llama-3.1-8B & 84.02 & 80.90 & 70.91 & 75.35 & 70.18 & 66.69\\
    \hline
  \end{tabular}
  }
  % \caption{\label{tbl:main_result_xsum}
  %   Comparative analysis of numerical accuracy and textual quality metrics for baseline methods and our proposed approach on the \textbf{XSum} dataset.
  % }
  \caption{\label{tbl:rationale_evaluation}
    textual quality metric score (\%) for Student LLM generated rationales against teache LLM generated supervision rationales on \textbf{NumHG} and \textbf{XSum}.
  }
\end{table*}


\subsection{Ablation study}
% Due to Mistral-7B-v0.3's more consistent performance across different benchmark datasets, we selected it as our final student LLM. 

\noindent \textbf{Effect of refining rationales through DPO.} In TEN, we apply DPO to enhance the capability of the student LLM rationale generator for topic alignment and numerical reasoning. 
%to enhance the quality of their outputs. 
To understand the effectiveness of DPO we tested TEN minus($-$) DPO on both Mistral-7B and Llama-3.1-8B. Table~\ref{tbl:ablation} illustrates the results. It can be seen that using a rationale generator improved through DPO leads to higher numerical accuracy and textual quality. On the NumHG dataset, DPO improves the numerical accuracy by 0.96\% with a Mistral-7B-v0.3-based rationale generator, and by 1.83\% with Llama-3.1-8B. On the XSum dataset, DPO enhances the numerical accuracy of Mistral-7B-v0.3 and Llama-3.1-8B by 1.38\% and 0.75\%, respectively. Additionally, DPO enhances the ROUGE scores marginally for both student models across both benchmark datasets. 

\begin{table*}[t]
  \centering
  \resizebox{\textwidth}{!}{
  \begin{tabular}{lcccccccc}
    \hline
    \textbf{Method} & \multicolumn{4}{c}{\textbf{NumHG}} & \multicolumn{4}{c}{\textbf{XSum}} \\
    \hline
    & NumAcc & ROUGE-1 & BERTScore-F1 & MoverScore & NumAcc & ROUGE-1 & BERTScore-F1 & MoverScore \\
    \hline
    Mistral-7B-v0.3 & & & & & & & \\
    \hline
    \: TEN (Ours) & \textbf{77.20} & \textbf{51.14} & \textbf{53.21} & \textbf{61.23} & \textbf{39.07} & 46.63 & \textbf{56.70} & \textbf{61.36} \\
    \: $-$ DPO & 76.24 & 50.95 & 53.12 & \textbf{61.24} & 37.69 & 46.26 & 56.35 & \textbf{61.27}  \\
    % \hline
    \: $-$ DPO $-$ N & 74.04 & 50.23 & 52.59 & \textbf{61.08} & 35.58 & 46.18 & 56.13 & \textbf{61.21}  \\
    \: $-$ DPO $-$ TE & 75.55 & \textbf{51.63} & \textbf{53.67} & \textbf{61.37} & 31.71 & 45.94 & 55.55 & \textbf{61.11}  \\
    \: $-$ DPO $-$ TEN & 70.33 & \textbf{51.27} & \textbf{53.43} & \textbf{61.42} & 30.41 & \textbf{47.37} & \textbf{56.88} & \textbf{61.58} \\
    \hline
    \hline
    Llama-3.1-8B & & & & & & & &  \\
    \hline
    \: TEN (Ours) & \textbf{77.89} & \textbf{51.15} & \textbf{52.83} & \textbf{61.14} & \textbf{37.51} & 46.11 & \textbf{56.09} & \textbf{61.18} \\
    \: $-$ DPO & 76.06 & \textbf{50.69} & 52.59 & \textbf{61.09} & 36.76 & 45.89 & 55.80 & \textbf{61.06}  \\
    % \hline
    \: $-$ DPO $-$ N & 73.80 & 50.05 & 52.24 & \textbf{60.90} & 36.51 & 45.83 & \textbf{56.03} & \textbf{61.11} \\
    \: $-$ DPO $-$ TE  & 74.86 & \textbf{50.98} & \textbf{53.21} & \textbf{61.22} & 32.02 & 45.62 & 55.50 & \textbf{61.03}  \\
    \: $-$ DPO $-$ TEN & 70.71 & \textbf{51.01} & \textbf{53.21} & \textbf{61.34} & 29.35 & \textbf{46.62} & \textbf{56.44} & \textbf{61.43} \\    
    \hline
  \end{tabular}
  }
    % Comparative analysis of LLM performance in headline generation: ablation study. 
  % \caption{\label{tbl:ablation}
  %   Ablation study results comparing the proposed TEN scheme with student models fine-tuned without DPO, topic alignment, or numerical reasoning signals.     
  % }
  \caption{\label{tbl:ablation}
    Results (\%) for ablation study of TEN. Higher numbers indicate better performance. Best results are in bold, where results within 0.5 (\%) difference are deemed comparable.     
  }
\end{table*}


% \begin{table*}[t]
%   \centering
%   \resizebox{0.8\textwidth}{!}{
%   \begin{tabular}{lcccc}
%     \hline
%     \textbf{Method} & \multicolumn{2}{c}{\textbf{NumHG}} & \multicolumn{2}{c}{\textbf{Xsum}} \\
%     \hline
%     & NumAcc & ROUGE-1 & NumAcc & ROUGE-1 \\
%     \hline
%     Mistral-7B-v0.3 & & & & \\
%     \hline
%     \: + No Teaching Signal & 70.33 & 51.27 & 30.41 & 47.37 \\
%     \: + Topic Alignment Only & 74.04 & 50.23 & 35.58 & 46.18 \\
%     \: + Calculation Enhancement Only & 75.56 & 51.63 & 31.71 & 45.94 \\
%     \hline
%     \: + Topic Alignment \& Calculation Enhancement (Ours) & 76.24 & 50.95 & 37.69 & 46.26 \\
%     \hline
%     % \hline
%     Llama-3.1-8B & & & & \\
%     \hline
%     \: + No Teaching Signal & 70.71 & 51.01 & 29.35 & 46.62 \\
%     \: + Topic Alignment & 73.80 & 50.05 & 36.51 & 45.83 \\
%     \: + Calculation Enhancement & 74.86 & 50.98 & 32.02 & 45.62 \\
%     \hline
%     \: + Topic Alignment \& Calculation Enhancement (Ours) & 76.06 & 50.69 & 36.76 & 45.89 \\
%     \hline
%   \end{tabular}
%   }
%   \caption{\label{t4}
%     Comparative analysis of LLM performance in headline generation: impact of different teaching signals.
%   }
% \end{table*}

% \section{Further Analysis}

\noindent \textbf{Effect of different supervision signals}. In TEN, we have developed two types of CoT supervision signals. One focuses on aligning the topic of the generated headline, while the other enhances numerical calculation accuracy. As illustrated in Figure~\ref{fig:three_phase_of_TEN}, the rationales under "Topic" and "Entities" contribute to topic alignment, whereas those under "Numbers mentioned" and "Reasoning steps" boost numerical reasoning. We've assessed the impact of these supervision signals, with results for ``TEN minus Number'' ($-$ N), ``TEN minus Topic and Entity ''($-$ TE), and ''no supervision''($-$ TEN) presented in Table~\ref{tbl:ablation}. It can be seen that both types of signals independently improve numerical accuracy in headline generation. However, their effectiveness varies across the two benchmark datasets: numerical reasoning signals show a more pronounced effect on NumHG, while topic alignment signals have a greater impact on XSum. Notably, combining both types of supervision signals yields optimal model performance with highest numerical accuracy and comparable textual quality. 
% \todo{XF: are we going to discuss -TEN or the result is complicated? If so, ignore my suggestion here.}

% For the NumHG dataset, the overall numerical accuracy of headlines generated by Mistral-7B-v0.3 drops 5.91\% when fine-tuned without any teaching signals, compared to TEN. The accuracy decreases by 2.2\% without number reasoning signals and by 0.68\% without topic alignment teaching signals. Llama-3.1-8B exhibits similar trends, with numerical accuracy declining by 5.35\%, 2.26\%, and 1.2\% when fine-tuned without teaching signals, calculation signals, and topic alignment signals, respectively. For the XSum dataset, unlike the results on NumHG, topic alignment teaching signals have a greater impact on the models' numerical accuracy. Mistral-7B-v0.3 and Llama-3.1-8B experience a decrease in numerical accuracy by 7.28\% and 7.41\% respectively when fine-tuned without any teaching signals. Their numerical accuracy only drops by 2.21\% and 0.25\% when fine-tuned without number reasoning signals. However, they show a more significant decline of 5.98\% and 4.74\% when fine-tuned without topic alignment signals, compared to TEN. 

%\todo[color=green]{XF: suggest mentioned the trend of TEN, not the details. Also, we can highlight the difference between the two datasets. -->done}

\noindent \textbf{TEN performance with different student LLMs.} We also want to highlight the performance of TEN with different base student LLMs. All results in Table~\ref{tbl:ablation} are obtained using GPT-4o as the teacher LLM and two different student LLMs: Mistral-7B and Llama-3.1-8B. 
Observe that Mistral-7B and Llama-3.1 demonstrate similar performance for both numerical accuracy and textual quality. 
It can also be seen that the supervision signals and DPO show their effectiveness for both student LLMs. 
% We also conducted experiments using two different types of student models: Mistral-7B-v0.3 and Llama-3.1-8B. The results are shown in Table~\ref{tbl:ablation}. When fine-tuned with TEN, Mistral-7B-v0.3 achieved an overall accuracy of 77.20\% on NumHG with a ROUGE-1 score of 51.14; and 39.07\% on XSum with a ROUGE-1 score of 46.63. Llama-3.1-8B, on the other hand, attained an overall accuracy of 77.89\% on NumHG with a ROUGE-1 score of 51.15; and 37.51\% on XSum with a ROUGE-1 score of 46.03. It can be found that our proposed TEN scheme persists in its efficiency across different LLMs.


% \begin{figure}[t!]
%   \includegraphics[width=\columnwidth]{latex/error_analysis_numhg.pdf} 
%   % Comparative analysis of error rates across different mathematical operations in number-focused headline generation
% %  \caption {The error analysis across different mathematical operations in number-focused headline generation.}
%   \caption {Error analysis across different mathematical operations on NumHG}
%   \label{fig:error_analysis}
% \end{figure}

\begin{figure*}[t!]
  \includegraphics[width=0.48\linewidth]{case_study_2} \hfill
  \includegraphics[width=0.48\linewidth]{case_study_3}
  \parbox[b]{0.45\textwidth}{\centering (a) Topic alignment}
  \hspace{0.05\textwidth}
  \parbox[b]{0.45\textwidth}{\centering (b) Numerical reasoning }  
%  \caption {Comparison between NCL\_NLP (Baseline) and our proposed TEN approach for rationale and headline generation}
  \caption {\label{fig:case_study} TEN vs. NCL (Baseline) for rationale and headline generation}
\end{figure*}

%\subsection{Discussions}
\subsection{Error analysis and case study}
\begin{table*}[!h]
    \centering
    \resizebox{0.9\textwidth}{!}{
    \begin{tabular}{ccccccccccc}
    \hline
    Operation & Overall & Copy & Trans & Paraphrase & Round & Subtract & Add & Span & Divide & Multiply \\
    Count & 3996 & 2,494 & 682 & 376 & 133 & 89 & 76 & 85 & 28 & 33 \\
    \hline
    BART (Err\%) & 31.53 & 23.46 & 34.02 & 26.60 & 60.90 & 96.63 & 78.95 & 68.24 & 96.43 & 93.94 \\
    NPP (Err\%) & 27.55 & 22.57 & 30.06 & 21.81 & \textbf{40.60} & \textbf{68.54} & \textbf{56.58} & \textbf{49.41} & \textbf{82.14} & 84.85 \\
    NCL (Err\%) & 28.08 & 21.57 & 29.62 & 20.74 & 48.12 & 79.78 & 75.00 & 64.71 & 96.43 & 90.91 \\
    TEN (Err\%) & \textbf{25.40} & \textbf{18.89} & \textbf{27.57} & \textbf{20.21} & 48.12 & 75.28 & 60.53 & 58.82 & 92.86 & \textbf{81.82} \\
    \hline
    \end{tabular}
}
  \caption{\label{tbl:error_analysis}
    Error analysis across different mathematical operations on test data from NumHG. Lower numbers indicate better performance. Best results are in bold, where results within 0.5\% difference are deemed comparable. 
  }
\end{table*}

\noindent \textbf{Error analysis.} Utilizing the annotations from the NumHG dataset, which outlines nine types of operations necessary for calculating numerals in headlines, we conducted an error analysis for TEN in comparison to the baselines. We present the error rates in Table~\ref{tbl:error_analysis}. 
%models trained with our proposed approach. 
%We examined errors related to the nine operation types. 
The experimental results demonstrate that our approach significantly reduces errors in copying, translating, and paraphrasing, achieving the lowest error rates compared to baseline methods. These three operations represent over 88\% of the total. For the remaining less frequent operations, our approach achieves error rates comparable to the best-performing baseline.
%\todo[color=green]{Figure~\ref{fig:error_analysis} np\_problem to NP-Problem --> done}
%jz3: some more detailed discussions are needed here. 
%jz3: Give some numbers. How many "copy" operations in total and the errors should be relative to the total operations, explain the total operations for each type and the percentage. 
% TEN has the largest number (%) of errors in Copy but NP, NCL has more errors in X, Y operations.

\noindent \textbf{Case study.} Two examples are selected from the test dataset to %demonstrate the improvements in topic alignment and numerical reasoning brought by our proposed TEN approach. 
illustrate the benefits of the TEN reasoning strategy, compared against the NCL baseline, which generates rationale without the TEN structured rationales. 
%We compare the different outputs between NCL (baseline) and TEN (ours). 
Figure~\ref{fig:case_study} (a) shows that TEN correctly identifies the topic the headline should focus on in the rationale, which is the rank of the tornado in this case, while NCL mistakenly focuses on the elevation. In Figure~\ref{fig:case_study} (b), TEN successfully calculates the number of people who died by adding 1 Australian tourist and 3 Tibetans, while NCL fails to count the Australian tourist. 

\section{Conclusion}
In this paper
%we presented  
%a novel fine-tuning scheme for number-focused headline generation named TEN (Topic, Entities, and numerical reasoning). 
we studied number-focused news headline generation, 
a problem presenting the unique challenge of high textual quality with precise number accuracy for LLM generation. 
We proposed a novel framework of using rationales of key elements Topic, Entity, and Numerical reasoning (TEN) to enhance the capability of LLMs for topic alignment and numerical reasoning in headline generation.   
We developed an approach to fine-tune LLMs to automatically generate TEN rationales for numerical headlines generation. 
Especially our TEN approach builds upon the teacher-student rationale-augmented training framework, where a teacher LLM automatically generate TEN rationales as supervision data to teach a student LLM rationale generator and a student LLM headline generator.    
%extends it to further refine automatically generated rationales specifically designed for the headline generation task. 
Experiments on popular numerical news headline generation datasets showed that TEN outperforms existing approaches, achieving higher numerical accuracy and mostly better textual quality for headline generation. 
%across both NumHG and XSum datasets. 
%The decomposition of rationales into topic alignment and numerical reasoning components proves highly effective, with their combination yielding optimal results. Further refinement of generated rationales through DPO leads to additional improvements in numerical accuracy and textual quality. 
%By effectively addressing the challenges of topic alignment and numerical calculation, our method paves the way for more accurate and reliable headline generation. 

\section*{Acknowledgements}
This research is supported in part by the Australian Research Council Discovery Project DP200101441.

\section*{Limitations}

%We employ only one teacher LLM (GPT-4o), so our proposed approach heavily relies on GPT-4o's performance when generating the supervision data. 
%For the student LLMs, 
One limitation of our study is that due to computing resource limitation, we have only applied parameter-efficient technique QLoRA \citep{dettmers_qlora_2023} to fine-tune student LLMs, 
and as such
%As we have not conducted full-parameter tuning,  
it is possible that we 
have not fully elicited the capability of student LLMs. 
%On For refining the rationales, we've tested DPO techniques but haven't explored other approaches such as reinforcement learning and verification. 
Another limitation of our study is the limited data for experiments. 
To our best knowledge NumHG is the only public benchmark dataset for numerical headline generation, and we constructed one more dataset based on XSum for extreme summarization.  
%There's also a limitation with the XSum benchmark dataset. This dataset is designed for extreme summarization, not specifically for headline generation, and contains considerable noise, which isn't ideal for machine learning.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
% \bibliography{main}
\input{main.bbl}

\clearpage

\onecolumn
\appendix

\section{Flowchart for Constructing Preference Data}
\label{appendix:preference_data}
Figure~\ref{appendix:constructing_preference_data} shows the flowchart for the construction of a pair of chosen-rejected rationales for a given news article in the training data. We apply this process and construct a dataset containing preferences for all the instance in the training data. Then the preference data is used for DPO. 
\begin{figure}[!h]
  \centering
  \includegraphics[width=\textwidth]{f5}
  \caption{Flowchart for constructing preference data}
  \label{appendix:constructing_preference_data}
\end{figure}

% \clearpage

\section{Implementation Details}
\label{appendix:implementation}
We employ GPT-4o as the teacher LLM to generate supervision data and experiment with two student LLMs: Mistral-7B-v0.3 and Llama-3.1-8B. All our rationale generators and headline generators are fine-tuned on the training data for three epochs. We apply QLoRA \citep{dettmers_qlora_2023} techniques to fine-tune the student LLMs efficiently. For all rationale generators, we set the LoRA rank and LoRA alpha to 128 and 64, respectively. For all headline generators, we set these values to 64 and 32. We fine-tune Mistral-7B-v0.3 with a learning rate of 2e-4 and Llama-3.1-8B with 8e-4. To create the preference dataset of chosen and rejected rationales, we fine-tune Mistral-7B-v0.3 and Llama-3.1-8B on the training data for a single epoch, sample 15 TEN rationales from each model for every news article, remove duplicate generations, and create a pair of chosen and rejected rationales for each training sample. During DPO, we set the LoRA rank to 256, LoRA alpha to 128, and DPO beta to 0.8. We set the learning rates for Mistral-7B-v0.3 and Llama-3.1-8B to 2e-6 and 8e-6 when doing experiments on NumHG, while setting them to 5e-6 and 2e-5 on XSum.
% \clearpage

% \section{Error Analysis}
% \label{appendix:error_analysis}


\clearpage
\section{Generation of Supervision Data}
\label{appendix: five-demonstrations}

The following five examples are demonstrations for five distinct operations needed to calculate the correct numbers in the headlines. The outputs (TEN rationales) are generated by the GPT-4o via zero-shot prompting respectively. Then the five examples, including generated TEN rationales, are used as demonstrations for the GPT-4o to generate supervision data for the entire training dataset.

\begin{table}[htbp]
    \centering
    \begin{tabular}{p{0.9\textwidth}}
    \hline
    \textbf{Example 1: Copy} \\
    \hline
    \textbf{Input:} \\
    \textbf{News:} (Oct 29, 2013 8:15 AM CDT) Dax Shepard and Kristen Bell got married at the Beverly Hills courthouse, in a ceremony about as different from Kim Kardashian's last wedding extravaganza as it is possible to be. As Shepard revealed last night on Jimmy Kimmel Live, the whole thing—including the fuel it took to get to the courthouse—cost \$142. It was just Kristen and I at this lonely courthouse, he said, so friends showed up afterward with a cake reading, in icing, The World's Worst Wedding. How many people can say they threw the world's worst wedding? Shepard asked. \\
    \textbf{Headline:} Dax Shepard: Wedding to Kristen Bell Cost \$\_\_\_\_. \\
    \textbf{Correct Number:} 142 \\
    \textbf{System Instruction: } You will be given a piece of news after prefix "News: ". You will be given a masked headline of the news after prefix "Headline:". You will be provided the correct missing numeral after prefix "Correct Number:". Please emphasise what Topic the headline should focus on, list all Entities and Numbers mentioned in the news, and elaborate on the Reasoning steps for how to calculate the correct number in the headline. \\
    \hline
    \textbf{Output:} \\
    \***Topic the headline should focus on** \\
    The headline should focus on the cost of Dax Shepard and Kristen Bell's wedding. \\
    \\
    \***Entities Mentioned** \\
    1. Dax Shepard \\
    2. Kristen Bell \\
    3. Kim Kardashian \\
    4. Jimmy Kimmel \\
    \\
    \***Numbers Mentioned** \\
    1. \$142 (cost of the wedding) \\
    \\
    \***Reasoning steps** \\
    The news content directly states that the entire wedding, including the fuel to get to the courthouse, cost \$142. \\
    
    Therefore, the numeral in the headline should be 142. \\
    \hline
    \end{tabular}
  % \caption{\label{tbl:demonstration_copy}
  % }
  
\end{table}

\begin{table}[htbp]
    \centering
    \begin{tabular}{p{0.9\textwidth}}
    \hline
    \textbf{Example 2: Add} \\
    \hline
    \textbf{Input:} \\
    \textbf{News:} (Sep 16, 2017 8:26 AM CDT) Police in St. Louis used tear gas to break up protests Friday night after around 1,000 demonstrators surrounded the home of Mayor Lyda Krewson, hurling red paint and breaking a front window. Police say at least nine St. Louis officers and a Highway Patrol trooper were injured in the protests, which followed the acquittal of white former police officer Jason Stockley in the 2011 shooting death of black motorist Anthony Lamar Smith, the St. Louis Post-Dispatch reports. Police say 32 people were arrested when a demonstration that had been largely peaceful turned violent after dark and agitators began to destroy property and assault police officers. Activists have promised more protests against the acquittal of Stockley, who, during a police chase, was caught on dashcam video saying I'm going to kill this motherf*****, don't you know it, the AP reports. Less than a minute later, he shot Smith five times.....  \\
    \textbf{Headline:} \_\_\_\_ Cops Injured in St. Louis Protests. \\
    \textbf{Correct Number:} 10 \\
    \textbf{System Instruction: } You will be given a piece of news after prefix "News: ". You will be given a masked headline of the news after prefix "Headline:". You will be provided the correct missing numeral after prefix "Correct Number:". Please emphasise what Topic the headline should focus on, list all Entities and Numbers mentioned in the news, and elaborate on the Reasoning steps for how to calculate the correct number in the headline. \\
    \hline
    \textbf{Output:} \\
    \***Topic the headline should focus on** \\
    The headline should focus on the number of police officers injured during the St. Louis protests. \\
    \\
    \***Entities Mentioned:**\\
    1. Mayor Lyda Krewson \\
    2. Jason Stockley (white former police officer) \\
    3. Anthony Lamar Smith (black motorist) \\
    4. Reverend Clinton Stancil \\
    5. St. Louis officers \\
    6. Highway Patrol trooper \\
    \\
    \***Numbers Mentioned** \\
    1. 1,000 (demonstrators) \\
    2. 9 (St. Louis officers injured) \\
    3. 1 (Highway Patrol trooper injured) \\
    4. 2011 (year of the shooting) \\
    5. 32 (people arrested) \\
    6. 3 (years since Ferguson unrest) \\
    7. 18 (age of Michael Brown) \\
    8. 5 (times Smith was shot) \\
    9. 24 (age of Anthony Lamar Smith) \\
    \\
    \***Reasoning steps** \\
    To find the total number of cops injured in the St. Louis protests, we need to sum the number of St. Louis officers injured and the Highway Patrol trooper injured. \\
    
    - St. Louis officers injured: 9 \\
    - Highway Patrol trooper injured: 1 \\

    Total injured cops = 9 (St. Louis officers) + 1 (Highway Patrol trooper) = 10 \\
    
    Therefore, the numeral in the headline should be 10. \\
    \hline
    \end{tabular}
  % \caption{\label{tbl:demonstration_add}
  % }
  
\end{table}

\begin{table}[htbp]
    \centering
    \begin{tabular}{p{0.9\textwidth}}
    \hline
    \textbf{Example 3: Subtract} \\
    \hline
    \textbf{Input:} \\
    \textbf{News:} (Jun 26, 2017 9:30 AM CDT) After three decades on the lam, an Arkansas man has been quickly reacquainted with life behind bars. Steven Dishman, 60—who was five months into a seven-year sentence for burglary and property theft when he escaped from the Cummins Unit in Lincoln County, Ark., on May 28, 1985, reports KTHV—was arrested Sunday at a home in Springdale in the northwestern part of the state, report Arkansas Online and KFSM. Arkansas State Police and local cops raided the home after receiving a tip. A rep for the Arkansas Department of Correction tells Fox 16 that Dishman will now be required to serve the remainder of his sentence. Dishman may also face additional charges related to his escape, the details of which were not immediately explained. Had Dishman stayed in jail, he would have been eligible for parole in 1987 and freed by 1991.\\
    \textbf{Headline:} He Spent \_\_\_\_ Years on the Run. Then Police Received a Tip. \\
    \textbf{Correct Number:} 32 \\
    \textbf{System Instruction: } You will be given a piece of news after prefix "News: ". You will be given a masked headline of the news after prefix "Headline:". You will be provided the correct missing numeral after prefix "Correct Number:". Please emphasise what Topic the headline should focus on, list all Entities and Numbers mentioned in the news, and elaborate on the Reasoning steps for how to calculate the correct number in the headline. \\
    \hline
    \textbf{Output:} \\
    \***Topic the headline should focus on** \\
    The headline should focus on the number of years Steven Dishman spent on the run before being recaptured. \\
    \\
    \***Entities Mentioned** \\
    1. Steven Dishman \\
    2. Arkansas State Police \\
    3. Local cops \\
    4. Arkansas Department of Correction representative \\
    \\
    \***Numbers Mentioned** \\
    1. 60 (age of Steven Dishman) \\
    2. 7 (years sentence for burglary and property theft) \\
    3. 5 (months into his sentence when he escaped) \\
    4. May 28, 1985 (date of escape) \\
    5. 1987 (year he would have been eligible for parole) \\
    6. 1991 (year he would have been freed) \\
    7. 2017 (current year) \\
     \\
    \***Reasoning steps** \\
    To find the number of years Steven Dishman spent on the run, we need to calculate the difference between the year he escaped (1985) and the year he was recaptured (2017). \\
    
    - Year of escape: 1985 \\
    - Year of recapture: 2017 \\
    
    Years on the run = 2017 - 1985 = 32 \\
    
    Therefore, the numeral in the headline should be 32. \\
    \hline
    \end{tabular}
  % \caption{\label{tbl:demonstration_subtract}
  % }
  
\end{table}


\begin{table}[htbp]
    \centering
    \begin{tabular}{p{0.9\textwidth}}
    \hline
    \textbf{Example 4: Paraphrase} \\
    \hline
    \textbf{Input:} \\
    \textbf{News:} News: (Oct 7, 2014 12:40 PM CDT) As of Jan. 1, Walmart will no longer offer 30,000 of its employees health insurance. Bloomberg notes that's about 2\% of its workforce. The move comes as a reaction to the company's rising health care costs as far more of its employees and their families enrolled in its health care plans than it had expected following the ObamaCare rollout. The AP reports those costs will surge \$500 million this fiscal year, \$170 million more than had been estimated. Those affected are employees who average fewer than 30 hours of work per week; the Wall Street Journal explains they were grandfathered in when Walmart in 2012 stopped offering insurance to new hires who didn't exceed the 30-hour threshold. A benefits expert says Walmart is actually late to the game in terms of cutting insurance to some part-time workers; Target, the Home Depot, and others have already done so. Meanwhile, Walmart's full time workers will see their premiums rise in 2015. Premiums for the basic plan, which 40\% of its workforce is on, will increase 19\% to \$21.90 per pay period come Jan. 1. \\
    \textbf{Headline:} Headline: \_\_\_\_K Walmart Part-Timers to Lose Health Insurance. \\
    \textbf{Correct Number:} 30. \\
    \textbf{System Instruction: } You will be given a piece of news after prefix "News: ". You will be given a masked headline of the news after prefix "Headline:". You will be provided the correct missing numeral after prefix "Correct Number:". Please emphasise what Topic the headline should focus on, list all Entities and Numbers mentioned in the news, and elaborate on the Reasoning steps for how to calculate the correct number in the headline. \\
    \hline
    \textbf{Output:} \\
    \***Topic the headline should focus on** \\
    The headline should focus on the number of Walmart part-time employees who will lose their health insurance. \\
    \\
    \***Entitiess Mentioned** \\
    1. Walmart employees \\
    2. Walmart's full-time workers \\
    3. Target \\
    4. The Home Depot \\
    5. ObamaCare \\
    \\
    \***Numbers Mentioned** \\
    1. 30,000 (employees losing health insurance) \\
    2. 2\% (of Walmart's workforce) \\
    3. \$500 million (surge in health care costs) \\
    4. \$170 million (more than estimated) \\
    5. 30 hours (work per week threshold) \\
    6. 2012 (year when Walmart stopped offering insurance to new hires under 30 hours) \\
    7. 2015 (year when premiums will rise) \\
    8. 40\% (of workforce on the basic plan) \\
    9. 19\% (increase in premiums) \\
    10. \$21.90 (new premium per pay period) \\
    \\
    \***Reasoning steps** \\
    The news content directly states that Walmart will no longer offer health insurance to 30,000 of its employees. \\

    To convert this number into thousands (K): \\
    - 30,000 employees = 30K employees \\
    
    Therefore, the numeral in the headline should be 30. \\    \hline
    \end{tabular}
  % \caption{\label{tbl:demonstration_paraphrase}
  % }
  
\end{table}

\begin{table}[htbp]
    \centering
    \begin{tabular}{p{0.9\textwidth}}
    \hline
    \textbf{Example 5: Rounding} \\
    \hline
    \textbf{Input:} \\
    \textbf{News:} (Apr 6, 2011 10:10 AM CDT) Well that was fast. Scott Walker did an about-face yesterday and demoted the son of a major campaign donor from his \$81,500-per-year Commerce Department gig—to his former \$64,728 job. Brian Deschane will return to his previous post as a bureau director at the Department of Regulation and Licensing, the Milwaukee Journal-Sentinel reports. The 27-year-old, who has no college degree and little experience (but does have two drunk-driving convictions!), had been in that job just two months when he was promoted to head of Wisconsin's environmental and regulatory affairs. Among those Deschane beat out for the job: a former Cabinet secretary with a doctoral degree and eight years experience overseeing oil contamination cleanup, and a professional engineer who had held the job since 2003 under the last governor. Neither was even interviewed. When Governor Walker learned the details of this agency staffing decision, he directed his administration to move in another direction, a Walker spokesman says (last week, this same rep called Deschane a natural fit for the position). But the demotion didn't satisfy some Democrats. I want to make sure he was properly hired for that job in the first place, said Assembly Minority Leader Peter Barca. Click for more on the brouhaha. \\
    \textbf{Headline:}  Headline: Walker Demotes Donor's Kid— to Puny \$\_\_\_\_K Job. \\
    \textbf{Correct Number:} 65. \\
    \textbf{System Instruction: } You will be given a piece of news after prefix "News: ". You will be given a masked headline of the news after prefix "Headline:". You will be provided the correct missing numeral after prefix "Correct Number:". Please emphasise what Topic the headline should focus on, list all Entities and Numbers mentioned in the news, and elaborate on the Reasoning steps for how to calculate the correct number in the headline. \\
    \hline
    \textbf{Output:} \\
    \***Topic the headline should focus on** \\
    The headline should focus on the new, lower salary of the demoted son of a major campaign donor. \\
    \\
    \***Entities Mentioned** \\
    1. Scott Walker \\
    2. Brian Deschane \\
    3. Assembly Minority Leader Peter Barca \\
    4. Former Cabinet secretary (unnamed) \\
    5. Professional engineer (unnamed) \\
    \\
    \***Numbers Mentioned** \\
    1. \$81,500 (initial salary at Commerce Department) \\
    2. \$64,728 (new salary after demotion) \\
    3. 27 (age of Brian Deschane) \\
    4. 2 (months in the initial job before promotion) \\
    5. 2003 (year since the professional engineer held the job) \\
    6. 8 (years of experience of the former Cabinet secretary) \\
    \\
    \***Reasoning Steps** \\
    The news content states that Brian Deschane was demoted from his \$81,500-per-year job to his former \$64,728 job. \\
    
    To convert this new salary into thousands (K): \\
    $\$64,728 \approx \$65,000$ \\
    
    Therefore, the numeral in the headline should be 65. \\
    \hline
    \end{tabular}
  
\end{table}



\end{document}
