\section{Conclusion}
\label{sec:conclusion}

This paper addresses the challenge of questionable faithfulness in data synthesis approaches for long-context LLMs.
We propose \textsc{LongFaith}, a novel pipeline synthesizing faithful long-context reasoning datasets through ground truth integration and citation-based reasoning prompts.
Experiments demonstrate its effectiveness, with ablation studies confirming the adaptability of the \textsc{LongFaith}-SFT and \textsc{LongFaith}-PO datasets across diverse long-context scenarios.
