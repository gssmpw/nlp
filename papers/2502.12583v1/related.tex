\section{Related Work}
\label{sec:related}

\paragraph{Long-Context Utilization.} Amounts of studies focus on enhancing LLMs to better utilize long-context information. Model-centric approaches, for instance, optimizations on attention mechanism aim to capture specific sequential features~\cite{longformer, longnet, longlora, lminfinite}, while positional interpolation techniques are utilized to scale positional encoding while ensuring valid index ranges~\cite{pose, extending, longrope, yarn, longformer}. In addition, data-driven approaches also gain popularity, emphasizing high-quality data synthesis for fine-tuning to improve LLMs' long-context processing capabilities. For example,~\cite{effective, prolong} employ long-sequence continuous pre-training on foundation models, while~\cite{dataengineering} explores the impact of pre-training data composition and balance. Additionally, works on SFT with synthetic instructions~\cite{in2, longalign, coc, longmit} not only consider long-context understanding but also strengthen multi-hop reasoning capabilities. Lastly, preference optimization approaches~\cite{longreward, sealong} generate fine-grained pairwise preference instruction sets and incorporate training techniques~\cite{dpo, orpo}. From the perspective of improving the faithfulness of synthetic data, our work effectively addresses the shortcomings of prior studies in this area.

\paragraph{Faithful Reasoning.} Hallucination in LLMs presents a major challenge in knowledge-intensive tasks~\cite{siren, hallu}. Recent work has focused on enhancing faithful reasoning, where the goal is to trace the LLM's generated content back to reliable sources and ensure its factual grounding. ~\cite{cotar, attribution, coc} aim to improve the identification and verification of attributions by focusing on generating reasoning outputs that link claims to specific sources. Benchmarks such as ~\cite{alce, automatic} evaluate the quality of citations and highlight the limitations of current systems in providing citation support to ensure more reliable output. Additionally, integrating external knowledge sources has gained attention, which use retrieval-augmented generation (RAG) methods to facilitate deep and faithful reasoning~\cite{tog, tog2}. Our \textsc{LongFaith} is motivated by previous work, towards faithful reasoning in long-context reasoning tasks.