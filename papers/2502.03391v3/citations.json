[
  {
    "index": 0,
    "papers": [
      {
        "key": "ribeiro2018anchors",
        "author": "Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos",
        "title": "{Anchors: High-Precision Model-Agnostic Explanations}"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "carter2019made",
        "author": "Carter, Brandon and Mueller, Jonas and Jain, Siddhartha and Gifford, David",
        "title": "{What Made You Do This? Understanding Black-Box Decisions with Sufficient Input Subsets}"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wang2021probabilistic",
        "author": "Wang, E and Khosravi, P and Van den Broeck, G",
        "title": "{Probabilistic Sufficient Explanations}"
      },
      {
        "key": "ribeiro2018anchors",
        "author": "Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos",
        "title": "{Anchors: High-Precision Model-Agnostic Explanations}"
      },
      {
        "key": "blanc2021provably",
        "author": "Blanc, Guy and Lange, Jane and Tan, Li-Yang",
        "title": "{Provably Efficient, Succinct, and Precise Explanations}"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "hase2021out",
        "author": "Hase, Peter and Xie, Harry and Bansal, Mohit",
        "title": "{The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations}"
      },
      {
        "key": "chockler2021explanations",
        "author": "Chockler, Hana and Kroening, Daniel and Sun, Youcheng",
        "title": "{Explanations for Occluded Images}"
      },
      {
        "key": "deyoung2019eraser",
        "author": "DeYoung, Jay and Jain, Sarthak and Rajani, Nazneen Fatema and Lehman, Eric and Xiong, Caiming and Socher, Richard and Wallace, Byron C",
        "title": "{ERASER: A Benchmark to Evaluate Rationalized NLP Models}"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "ignatiev2019abduction",
        "author": "Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao",
        "title": "{Abduction-based Explanations for Machine Learning Models}"
      },
      {
        "key": "bassan2023formally",
        "author": "Bassan, Shahaf and Amir, Guy and Corsi, Davide and Refaeli, Idan and Katz, Guy",
        "title": "{Formally Explaining Neural Networks within Reactive Systems}"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "ignatiev2019abduction",
        "author": "Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao",
        "title": "{Abduction-based Explanations for Machine Learning Models}"
      },
      {
        "key": "shih2018symbolic",
        "author": "Shih, Andy and Choi, Arthur and Darwiche, Adnan",
        "title": "{A Symbolic Approach to Explaining Bayesian Network Classifiers}"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "izza2020explaining",
        "author": "Izza, Yacine and Ignatiev, Alexey and Marques-Silva, Joao",
        "title": "{On Explaining Decision Trees}"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "izza2021explaining",
        "author": "Izza, Yacine and Marques-Silva, Joao",
        "title": "{On Explaining Random Forests with SAT}"
      },
      {
        "key": "ignatiev2022using",
        "author": "Ignatiev, Alexey and Izza, Yacine and Stuckey, Peter J and Marques-Silva, Joao",
        "title": "{Using MaxSAT for Efficient Explanations of Tree Ensembles}"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "marques2020explaining",
        "author": "Marques-Silva, Joao and Gerspacher, Thomas and Cooper, Martin and Ignatiev, Alexey and Narodytska, Nina",
        "title": "{Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay}"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "ignatiev2019abduction",
        "author": "Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao",
        "title": "{Abduction-based Explanations for Machine Learning Models}"
      },
      {
        "key": "la2021guaranteed",
        "author": "La Malfa, Emanuele and Zbrzezny, Agnieszka and Michelmore, Rhiannon and Paoletti, Nicola and Kwiatkowska, Marta",
        "title": "{On Guaranteed Optimal Robust Explanations for NLP Models}"
      },
      {
        "key": "bassan2023towards",
        "author": "Bassan, Shahaf and Katz, Guy",
        "title": "{Towards Formal XAI: Formally Approximate Minimal Explanations of Neural Networks}"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "ismail2021improving",
        "author": "Ismail, Aya Abdelsalam and Corrada Bravo, Hector and Feizi, Soheil",
        "title": "{Improving Deep Learning Interpretability by Saliency Guided Training}"
      },
      {
        "key": "chen2019robust",
        "author": "Chen, Jiefeng and Wu, Xi and Rastogi, Vaibhav and Liang, Yingyu and Jha, Somesh",
        "title": "{Robust Attribution Regularization}"
      },
      {
        "key": "hase2021out",
        "author": "Hase, Peter and Xie, Harry and Bansal, Mohit",
        "title": "{The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations}"
      },
      {
        "key": "vafa2021rationales",
        "author": "Vafa, Keyon and Deng, Yuntian and Blei, David and Rush, Alexander",
        "title": "{Rationales for Sequential Predictions}"
      },
      {
        "key": "yan2023self",
        "author": "Yan, Jingquan and Wang, Hao",
        "title": "{Self-Interpretable Time Series Prediction with Counterfactual Explanations}"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "chen2019looks",
        "author": "Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K",
        "title": "{This Looks Like That: Deep Learning for Interpretable Image Recognition}"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "wang2021self",
        "author": "Wang, Yipei and Wang, Xiaoqian",
        "title": "{Self-Interpretable Model with Transformation Equivariant Interpretation}"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "alvarez2018towards",
        "author": "Alvarez Melis, David and Jaakkola, Tommi",
        "title": "{Towards Robust Interpretability with Self-Explaining Neural Networks}"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "agarwal2021neural",
        "author": "Agarwal, Rishabh and Melnick, Levi and Frosst, Nicholas and Zhang, Xuezhou and Lengerich, Ben and Caruana, Rich and Hinton, Geoffrey E",
        "title": "{Neural Additive Models: Interpretable Machine Learning with Neural Nets}"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "jain2020learning",
        "author": "Jain, Sarthak and Wiegreffe, Sarah and Pinter, Yuval and Wallace, Byron C",
        "title": "{Learning to Faithfully Rationalize by Construction}"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "koh2020concept",
        "author": "Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy",
        "title": "{Concept Bottleneck Models}"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "yeh2019fidelity",
        "author": "Yeh, Chih-Kuan and Hsieh, Cheng-Yu and Suggala, Arun and Inouye, David I and Ravikumar, Pradeep K",
        "title": "{On the (in) Fidelity and Sensitivity of Explanations}"
      },
      {
        "key": "lundberg2017unified",
        "author": "Lundberg, Scott M and Lee, Su-In",
        "title": "{A Unified Approach to Interpreting Model Predictions}"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "slack2020fooling",
        "author": "Slack, Dylan and Hilgard, Sophie and Jia, Emily and Singh, Sameer and Lakkaraju, Himabindu",
        "title": "{Fooling Lime and Shap: Adversarial Attacks on Post Hoc Explanation Methods}"
      },
      {
        "key": "ribeiro2018anchors",
        "author": "Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos",
        "title": "{Anchors: High-Precision Model-Agnostic Explanations}"
      },
      {
        "key": "yeh2019fidelity",
        "author": "Yeh, Chih-Kuan and Hsieh, Cheng-Yu and Suggala, Arun and Inouye, David I and Ravikumar, Pradeep K",
        "title": "{On the (in) Fidelity and Sensitivity of Explanations}"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "ribeiro2018anchors",
        "author": "Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos",
        "title": "{Anchors: High-Precision Model-Agnostic Explanations}"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "ribeiro2018anchors",
        "author": "Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos",
        "title": "{Anchors: High-Precision Model-Agnostic Explanations}"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "carter2019made",
        "author": "Carter, Brandon and Mueller, Jonas and Jain, Siddhartha and Gifford, David",
        "title": "{What Made You Do This? Understanding Black-Box Decisions with Sufficient Input Subsets}"
      },
      {
        "key": "carter2021overinterpretation",
        "author": "Carter, Brandon and Jain, Siddhartha and Mueller, Jonas W and Gifford, David",
        "title": "{Overinterpretation Reveals Image Classification Model Pathologies}"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "wang2021probabilistic",
        "author": "Wang, E and Khosravi, P and Van den Broeck, G",
        "title": "{Probabilistic Sufficient Explanations}"
      },
      {
        "key": "ribeiro2018anchors",
        "author": "Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos",
        "title": "{Anchors: High-Precision Model-Agnostic Explanations}"
      },
      {
        "key": "blanc2021provably",
        "author": "Blanc, Guy and Lange, Jane and Tan, Li-Yang",
        "title": "{Provably Efficient, Succinct, and Precise Explanations}"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "hase2021out",
        "author": "Hase, Peter and Xie, Harry and Bansal, Mohit",
        "title": "{The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations}"
      },
      {
        "key": "chockler2021explanations",
        "author": "Chockler, Hana and Kroening, Daniel and Sun, Youcheng",
        "title": "{Explanations for Occluded Images}"
      },
      {
        "key": "deyoung2019eraser",
        "author": "DeYoung, Jay and Jain, Sarthak and Rajani, Nazneen Fatema and Lehman, Eric and Xiong, Caiming and Socher, Richard and Wallace, Byron C",
        "title": "{ERASER: A Benchmark to Evaluate Rationalized NLP Models}"
      },
      {
        "key": "chockler2024explaining",
        "author": "Chockler, Hana and Halpern, Joseph Y",
        "title": "{Explaining Image Classifiers}"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "ignatiev2019abduction",
        "author": "Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao",
        "title": "{Abduction-based Explanations for Machine Learning Models}"
      },
      {
        "key": "bassan2023formally",
        "author": "Bassan, Shahaf and Amir, Guy and Corsi, Davide and Refaeli, Idan and Katz, Guy",
        "title": "{Formally Explaining Neural Networks within Reactive Systems}"
      },
      {
        "key": "ordyniak2023parameterized",
        "author": "Ordyniak, Sebastian and Paesani, Giacomo and Szeider, Stefan",
        "title": "{The Parameterized Complexity of Finding Concise Local Explanations}"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "ignatiev2019abduction",
        "author": "Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao",
        "title": "{Abduction-based Explanations for Machine Learning Models}"
      },
      {
        "key": "shih2018symbolic",
        "author": "Shih, Andy and Choi, Arthur and Darwiche, Adnan",
        "title": "{A Symbolic Approach to Explaining Bayesian Network Classifiers}"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "izza2020explaining",
        "author": "Izza, Yacine and Ignatiev, Alexey and Marques-Silva, Joao",
        "title": "{On Explaining Decision Trees}"
      },
      {
        "key": "huang2021efficiently",
        "author": "Huang, Xuanxiang and Izza, Yacine and Ignatiev, Alexey and Marques-Silva, Joao",
        "title": "{On Efficiently Explaining Graph-Based Classifiers}"
      },
      {
        "key": "bounia2023approximating",
        "author": "Bounia, Louenas and Koriche, Frederic",
        "title": "{Approximating Probabilistic Explanations via Supermodular Minimization}"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "barcelo2025explaining",
        "author": "Barcel{\\'o}, Pablo and Kozachinskiy, Alexander and Orth, Miguel Romero and Subercaseaux, Bernardo and Verschae, Jos{\\'e}",
        "title": "{Explaining k-Nearest Neighbors: Abductive and Counterfactual Explanations}"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "izza2021explaining",
        "author": "Izza, Yacine and Marques-Silva, Joao",
        "title": "{On Explaining Random Forests with SAT}"
      },
      {
        "key": "ignatiev2022using",
        "author": "Ignatiev, Alexey and Izza, Yacine and Stuckey, Peter J and Marques-Silva, Joao",
        "title": "{Using MaxSAT for Efficient Explanations of Tree Ensembles}"
      },
      {
        "key": "audemard2022trading",
        "author": "Audemard, Gilles and Bellart, Steve and Bounia, Louenas and Koriche, Fr{\\'e}d{\\'e}ric and Lagniez, Jean-Marie and Marquis, Pierre",
        "title": "{Trading Complexity for Sparsity in Random Forest Explanations}"
      },
      {
        "key": "audemard2022preferred",
        "author": "Audemard, Gilles and Bellart, Steve and Bounia, Louenas and Koriche, Fr{\\'e}d{\\'e}ric and Lagniez, Jean-Marie and Marquis, Pierre",
        "title": "{On Preferred Abductive Explanations for Decision Trees and Random Forests}"
      },
      {
        "key": "boumazouza2021asteryx",
        "author": "Boumazouza, Ryma and Cheikh-Alili, Fahima and Mazure, Bertrand and Tabia, Karim",
        "title": "{ASTERYX: A model-Agnostic SaT-basEd appRoach for sYmbolic and score-based eXplanations}"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "marques2020explaining",
        "author": "Marques-Silva, Joao and Gerspacher, Thomas and Cooper, Martin and Ignatiev, Alexey and Narodytska, Nina",
        "title": "{Explaining Naive Bayes and Other Linear Classifiers with Polynomial Time and Delay}"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "ignatiev2019abduction",
        "author": "Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao",
        "title": "{Abduction-based Explanations for Machine Learning Models}"
      },
      {
        "key": "wu2024verix",
        "author": "Wu, Min and Wu, Haoze and Barrett, Clark",
        "title": "{Verix: Towards Verified Explainability of Deep Neural Networks}"
      },
      {
        "key": "la2021guaranteed",
        "author": "La Malfa, Emanuele and Zbrzezny, Agnieszka and Michelmore, Rhiannon and Paoletti, Nicola and Kwiatkowska, Marta",
        "title": "{On Guaranteed Optimal Robust Explanations for NLP Models}"
      },
      {
        "key": "bassan2023towards",
        "author": "Bassan, Shahaf and Katz, Guy",
        "title": "{Towards Formal XAI: Formally Approximate Minimal Explanations of Neural Networks}"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "wang2021beta",
        "author": "Wang, Shiqi and Zhang, Huan and Xu, Kaidi and Lin, Xue and Jana, Suman and Hsieh, Cho-Jui and Kolter, J Zico",
        "title": "{Beta-crown: Efficient Bound Propagation with Per-Neuron Split Constraints for Neural Network Robustness Verification}"
      },
      {
        "key": "wu2024marabou",
        "author": "Wu, Haoze and Isac, Omri and Zelji{\\'c}, Aleksandar and Tagomori, Teruhiro and Daggitt, Matthew and Kokke, Wen and Refaeli, Idan and Amir, Guy and Julian, Kyle and Bassan, Shahaf and others",
        "title": "{Marabou 2.0: A Versatile Formal Analyzer of Neural Networks}"
      },
      {
        "key": "fel2023don",
        "author": "Fel, Thomas and Ducoffe, M{\\'e}lanie and Vigouroux, David and Cad{\\`e}ne, R{\\'e}mi and Capelle, Mikael and Nicod{\\`e}me, Claire and Serre, Thomas",
        "title": "{Don't Lie to Me! Robust and Efficient Explainability with Verified Perturbation Analysis}"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "ismail2021improving",
        "author": "Ismail, Aya Abdelsalam and Corrada Bravo, Hector and Feizi, Soheil",
        "title": "{Improving Deep Learning Interpretability by Saliency Guided Training}"
      },
      {
        "key": "chen2019robust",
        "author": "Chen, Jiefeng and Wu, Xi and Rastogi, Vaibhav and Liang, Yingyu and Jha, Somesh",
        "title": "{Robust Attribution Regularization}"
      },
      {
        "key": "hase2021out",
        "author": "Hase, Peter and Xie, Harry and Bansal, Mohit",
        "title": "{The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations}"
      },
      {
        "key": "vafa2021rationales",
        "author": "Vafa, Keyon and Deng, Yuntian and Blei, David and Rush, Alexander",
        "title": "{Rationales for Sequential Predictions}"
      },
      {
        "key": "yan2023self",
        "author": "Yan, Jingquan and Wang, Hao",
        "title": "{Self-Interpretable Time Series Prediction with Counterfactual Explanations}"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "alvarez2018towards",
        "author": "Alvarez Melis, David and Jaakkola, Tommi",
        "title": "{Towards Robust Interpretability with Self-Explaining Neural Networks}"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "lee2022self",
        "author": "Lee, Seungeon and Wang, Xiting and Han, Sungwon and Yi, Xiaoyuan and Xie, Xing and Cha, Meeyoung",
        "title": "{Self-Explaining Deep Models with Logic Rule Reasoning}"
      },
      {
        "key": "shwartz2020unsupervised",
        "author": "Shwartz, Vered and West, Peter and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin",
        "title": "{Unsupervised Commonsense Question Answering with Self-Talk}"
      },
      {
        "key": "rajagopal2021selfexplain",
        "author": "Rajagopal, Dheeraj and Balachandran, Vidhisha and Hovy, Eduard H and Tsvetkov, Yulia",
        "title": "{SELFEXPLAIN: A Self-Explaining Architecture for Neural Text Classifiers}"
      },
      {
        "key": "guyomard2022vcnet",
        "author": "Guyomard, Victor and Fessant, Fran{\\c{c}}oise and Guyet, Thomas and Bouadi, Tassadit and Termier, Alexandre",
        "title": "{VCNet: A Self-Explaining Model for Realistic Counterfactual Generation}"
      },
      {
        "key": "guo2023counternet",
        "author": "Guo, Hangzhi and Nguyen, Thanh H and Yadav, Amulya",
        "title": "{Counternet: End-to-End Training of Prediction Aware Counterfactual Explanations}"
      },
      {
        "key": "zhang2022protgnn",
        "author": "Zhang, Zaixi and Liu, Qi and Wang, Hao and Lu, Chengqiang and Lee, Cheekong",
        "title": "{Protgnn: Towards Self-Explaining Graph Neural Networks}"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "chen2019looks",
        "author": "Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K",
        "title": "{This Looks Like That: Deep Learning for Interpretable Image Recognition}"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "wang2021self",
        "author": "Wang, Yipei and Wang, Xiaoqian",
        "title": "{Self-Interpretable Model with Transformation Equivariant Interpretation}"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "alvarez2018towards",
        "author": "Alvarez Melis, David and Jaakkola, Tommi",
        "title": "{Towards Robust Interpretability with Self-Explaining Neural Networks}"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "agarwal2021neural",
        "author": "Agarwal, Rishabh and Melnick, Levi and Frosst, Nicholas and Zhang, Xuezhou and Lengerich, Ben and Caruana, Rich and Hinton, Geoffrey E",
        "title": "{Neural Additive Models: Interpretable Machine Learning with Neural Nets}"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "jain2020learning",
        "author": "Jain, Sarthak and Wiegreffe, Sarah and Pinter, Yuval and Wallace, Byron C",
        "title": "{Learning to Faithfully Rationalize by Construction}"
      }
    ]
  },
  {
    "index": 40,
    "papers": [
      {
        "key": "koh2020concept",
        "author": "Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy",
        "title": "{Concept Bottleneck Models}"
      }
    ]
  },
  {
    "index": 41,
    "papers": [
      {
        "key": "yeh2019fidelity",
        "author": "Yeh, Chih-Kuan and Hsieh, Cheng-Yu and Suggala, Arun and Inouye, David I and Ravikumar, Pradeep K",
        "title": "{On the (in) Fidelity and Sensitivity of Explanations}"
      },
      {
        "key": "lundberg2017unified",
        "author": "Lundberg, Scott M and Lee, Su-In",
        "title": "{A Unified Approach to Interpreting Model Predictions}"
      }
    ]
  },
  {
    "index": 42,
    "papers": [
      {
        "key": "slack2020fooling",
        "author": "Slack, Dylan and Hilgard, Sophie and Jia, Emily and Singh, Sameer and Lakkaraju, Himabindu",
        "title": "{Fooling Lime and Shap: Adversarial Attacks on Post Hoc Explanation Methods}"
      },
      {
        "key": "ribeiro2018anchors",
        "author": "Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos",
        "title": "{Anchors: High-Precision Model-Agnostic Explanations}"
      },
      {
        "key": "yeh2019fidelity",
        "author": "Yeh, Chih-Kuan and Hsieh, Cheng-Yu and Suggala, Arun and Inouye, David I and Ravikumar, Pradeep K",
        "title": "{On the (in) Fidelity and Sensitivity of Explanations}"
      }
    ]
  },
  {
    "index": 43,
    "papers": [
      {
        "key": "ribeiro2018anchors",
        "author": "Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos",
        "title": "{Anchors: High-Precision Model-Agnostic Explanations}"
      }
    ]
  },
  {
    "index": 44,
    "papers": [
      {
        "key": "li2018tell",
        "author": "Li, Kunpeng and Wu, Ziyan and Peng, Kuan-Chuan and Ernst, Jan and Fu, Yun",
        "title": "{Tell Me Where to Look: Guided Attention Inference Network}"
      },
      {
        "key": "hou2018self",
        "author": "Hou, Qibin and Jiang, PengTao and Wei, Yunchao and Cheng, Ming-Ming",
        "title": "{Self-Erasing Network for Integral Object Attention}"
      },
      {
        "key": "wei2017object",
        "author": "Wei, Yunchao and Feng, Jiashi and Liang, Xiaodan and Cheng, Ming-Ming and Zhao, Yao and Yan, Shuicheng",
        "title": "{Object Region Mining with Adversarial Erasing: A Simple Classification to Semantic Segmentation Approach}"
      },
      {
        "key": "kumar2017hide",
        "author": "Kumar Singh, Krishna and Jae Lee, Yong",
        "title": "{Hide-and-Seek: Forcing a Network to be Meticulous for Weakly-Supervised Object and Action Localization}"
      }
    ]
  },
  {
    "index": 45,
    "papers": [
      {
        "key": "wang2019sharpen",
        "author": "Wang, Lezi and Wu, Ziyan and Karanam, Srikrishna and Peng, Kuan-Chuan and Singh, Rajat Vikram and Liu, Bo and Metaxas, Dimitris N",
        "title": "{Sharpen Focus: Learning with Attention Separability and Consistency}"
      }
    ]
  },
  {
    "index": 46,
    "papers": [
      {
        "key": "devries2017improved",
        "author": "DeVries, Terrance and Taylor, Graham W",
        "title": "{Improved Regularization of Convolutional Neural Networks with Cutout}"
      }
    ]
  },
  {
    "index": 47,
    "papers": [
      {
        "key": "hase2021out",
        "author": "Hase, Peter and Xie, Harry and Bansal, Mohit",
        "title": "{The Out-of-Distribution Problem in Explainability and Search Methods for Feature Importance Explanations}"
      }
    ]
  },
  {
    "index": 48,
    "papers": [
      {
        "key": "vafa2021rationales",
        "author": "Vafa, Keyon and Deng, Yuntian and Blei, David and Rush, Alexander",
        "title": "{Rationales for Sequential Predictions}"
      }
    ]
  }
]