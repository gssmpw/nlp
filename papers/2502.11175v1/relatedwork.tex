\section{Related Works}
\subsection{Multilingual RAG}
Researchers explore challenges in mRAG such as problem of cross-lingual dense passage retrieval for low-resource languages~\cite{wu2024limitscrosslingualdensepassage} and research various techniques to address key challenges in mRAG, such as enhancing the performance of language models in low-resource languages~\cite{deshpande2024chain}, resolving low-resource scenarios~\cite{zhang-etal-2024-enhancing-multilingual}, and adapting language models for multilingual reasoning tasks~\cite{yoon-etal-2024-langbridge}. Benchmarks like \textsc{MMTEB}~\cite{enevoldsen2025mmteb} enable systematic evaluation of multilingual retrieval.

Earlier mRAG systems frequently focus on high-resource languages (e.g., English), but a growing body of research aims to make advanced Natural Language Processing (NLP) technology accessible across a wide spectrum of linguistic contexts. Proposed solutions include code-mixed prompts for in-context learning~\cite{shankar-etal-2024-context} and self-distillation from resource-rich to low-resource languages~\cite{zhang-etal-2024-enhancing-multilingual}.


\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{dkm_rag.pdf}
    \caption{Overall flow of proposed DKM-RAG.}
    %\vspace{-5mm}
    \label{fig:dkm_rag}
\end{figure}

\subsection{Language Preference in mRAG}
Despite significant progress, language preference—a systematic tendency to favor certain languages—remains a critical issue in mRAG systems. This preference arises from imbalances in training data, tokenization mismatches, script differences, and uneven resource availability~\cite{sharma2024fauxpolyglotstudyinformation, wu2024languagesequalinsightsmultilingual}. Studies show that high-resource languages (e.g., English) often overshadow relevant content in lower-resource languages during retrieval~\cite{yang-etal-2024-language-bias, chirkova-etal-2024-retrieval}, leading to suboptimal evidence retrieval~\cite{10.1145/3626772.3657943} and causing inconsistencies or hallucinations in outputs~\cite{chataigner2024multilingualhallucinationgapslarge}. These disparities also raise broader fairness concerns in multilingual NLP, as pre-trained models exhibit group fairness issues across languages~\cite{cabello-piqueras-sogaard-2022-pretrained, ramesh-etal-2023-fairness}.


Researchers propose several methods to counteract language preferences, including language-preference-based re-ranking~\cite{10.1145/3539813.3545131}, evaluate knowledge consistency across languages~\cite{qi-etal-2023-cross}, and specialized datasets designed to detect such imbalances~\cite{li-etal-2024-bordirlines}. However, these approaches often focus on a single mRAG stage or overlook the actual ranking of retrieved documents~\cite{sharma2024fauxpolyglotstudyinformation, 10.1145/3626772.3657943}. We introduce a metric that quantifies language preference in retrieval via ranking differences and propose a simple framework to mitigate these preferences across the entire mRAG pipeline.