\section{Results and Analysis}
\textbf{Setup}\quad We evaluated the technique using \textit{Best First Search}. It is one of the most popular methods to evaluate the theorem-proving ability of a language model \cite{polu2020generative, yang2023leandojo, azerbayev2023llemma, lean-star}. For a given language model $M$, we keep all unexpanded states $s_i$; each time we expand the best state $s_i$ and use the language model to sample $S$ net tactics $a_{i,1...S}$ for the current state $s_i$.
Following standard practice \cite{polu2020generative, yang2023leandojo, llmstep, lean-star} we assume the state with maximum negative log-probabilities is the "best" state. Specifically, we select state $s_i$ with maximum $\sum_{j=0}^{i-1} -\log p(a_j, s_j)$, where $(s_0, a_0), ...,(s_{i-1},a_{i-1})$ is proof trajectory before state $s_i$ and $\log p(a_j,s_j)$ is the average log probability of each generated token. We expand upto $N$ states and we get successful proofs search when we reach any proof state with no goals. 
\begin{table}
\centering
\begin{tabular}{lccccc}
\toprule
Model & Decoding & N & K & S & MiniF2F \\ 
\midrule
GPT-3.5 (FEW-SHOT) & SAMPLING & 50 & 1 & 1 & 2.8\% \\
GPT-4 (FEW-SHOT) & SAMPLING & 50 & 1 & 1 & 11.9\% \\
LLEMMA-7B & SEARCH & 50 & 1 & 32 & 26.2\% \\
INTERNLM2-7B & SEARCH & 50 & 1 & 32 & 30.3\% \\
INTERNLM2-7B (SFT) & SEARCH & 50 & 1 & 32 & 30.7\% \\
LEAN-COT (INTERNLM2-7B) & SAMPLING & 50 & 32 & 1 & 27.0\% \\
LEAN-COT (INTERNLM2-7B) & SEARCH & 50 & 1 & 32 & 25.4\% \\
LEAN-STAR (INTERNLM2-7B) & SAMPLING & 50 & 32 & 1 & 29.1\% \\
LEAN-STAR (INTERNLM2-7B) & SEARCH & 50 & 1 & 32 & 26.2\% \\
CORPA (WITH GPT-4) & CUSTOMIZED & - & 60 & 1 & 29.9\% \\
OURS (LLEMMA-7B) & SAMPLING & 50 & 32 & 1 & 28.1\% \\
OURS (LLEMMA-7B) & SEARCH & 50 & 1 & 32 & 26.3\% \\
OURS (INTERNLM2-7B) & SAMPLING & 50 & 32 & 1 & \textbf{32.4\%} \\
OURS (INTERNLM2-7B) & SEARCH & 50 & 1 & 32 & \textbf{26.8\%} \\ 
\bottomrule
\end{tabular}
\caption{Pass rates on the \texttt{miniF2F}-test dataset with Lean. This table shows the pass rates of previous works and our work. S is the number of tactics attempted at each expanded node (assumed to be 1 in sampling), and K is the total number of search or sampling attempts per problem.}
\label{tab:main-results}
\end{table}

\textbf{Dataset}\quad  We evaluated our technique on \textit{MiniF2F} benchmark \cite{zheng2022miniff}. Which consists of 244 theorems in lean 4. We use the same evaluation setting as previous works \cite{yang2023leandojo, llmstep, ying2024internlmmathopenmathlarge}.

\textbf{Sampling}\quad We evaluate two different decoding strategies: \textit{sampling} and \textit{search}. \textit{Sampling} involves drawing multiple proof steps stochastically based on the model’s output distribution, promoting diversity in the generated proofs. In contrast, \textit{search} incorporates structured exploration techniques to improve proof discovery. Specifically, we consider two widely used search methods: \textit{beam search} and \textit{best-first search}.  

\textbf{Beam Search.} Beam search maintains a fixed number \( k \) of proof trajectories at each step, selecting the top-ranked candidates based on the model’s confidence scores. By preserving multiple plausible proof paths instead of greedily committing to the highest-confidence step, beam search mitigates early pruning errors and allows exploration of alternative reasoning chains. However, the trade-off between beam width and computational cost remains a key consideration: while larger beams enhance robustness, they also introduce significant overhead.  

\textbf{Best-First Search.} Best-first search prioritizes proof states according to a heuristic function, typically based on model confidence or learned value estimates. Unlike depth-first or breadth-first strategies, best-first search expands the most promising proof state first, dynamically adjusting the exploration process. In our experiments, we observe that combining \textit{best-first search with sampling} yields notable improvements. We hypothesize that this effect arises because traditional reranking, despite boosting the likelihood of high-reward tactics, may suffer from premature convergence to suboptimal proof paths. In contrast, best-first search, when coupled with sampling, allows for imperfect scoring, thereby encouraging broader exploration and improved intermediate state discovery.  
\subsection{Main Results}

Our main results are reported in Table \ref{tab:main-results}. Steering the model's activation significantly improves performance over the base model. Notably, we observe that steering markedly increases pass rates when using Best First Search with sampling. We hypothesize that this improvement occurs because reranking may be too narrowly focused—potentially getting trapped in local optima—even though it boosts log probabilities for tactics that follow the highest reward path. In contrast, combining sampling with Best First Search allows for imperfect scoring, which in turn enables the exploration of nodes that lead to better intermediate states.    


\subsection{Ablations}
\textbf{Random Steering Vectors}\\
A potential validity concern with any intervention involving activation patching is that the observed improvements might not stem from genuine performance enhancements but rather from activating fallback mechanisms \cite{mcgrath2023hydra, lucchetti2024understandingcodellmsmispredicttypes}. For instance, patching could merely introduce noise into the embedding space, inadvertently triggering alternative pathways that lead to the desired outcome. This phenomenon complicates the interpretability of both patches and steering vectors. To examine this, we conduct an experiment using a randomly generated steering vector (denoted as "Random" in Table \ref{tab:random}). Our findings show that even random steering achieves a nonzero accuracy, albeit significantly lower than that of our computed steering vectors. We hypothesize that this residual accuracy arises due to backup circuits. Nevertheless, the substantially higher performance of our computed steering vectors suggests that our approach induces meaningful transformations toward the correct target.
\begin{table}
\centering
\begin{tabular}{lccc}
\hline
Model & Decoding & Random & Steering \\
\hline
LLEMMA-7B & SAMPLING & 22.7\% & 28.1\% \\
         & SEARCH & 19.2\% & 26.3\% \\
INTERNLM-7B & SAMPLING & 21.4\% & 32.4\% \\
            & SEARCH & 18.9\% & 26.8\% \\
\hline
\end{tabular}
\caption{Pass rates with randomized vectors and steering vectors.}
\label{tab:random}
\end{table}
