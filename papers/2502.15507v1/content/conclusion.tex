\section{Conclusion}
We investigate activation steering for tactic prediction by making language models adhere to structured reasoning approaches in theorem proving. We find that by constructing steering pairs using synthetic metadata and natural proof states, we can construct effective steering vectors that improve tactic selection. Our experiments show that steering vectors enhance model performance beyond random interventions and generalize well across different theorem-proving strategies. The effectiveness of our steering approach demonstrates the existence of underlying reasoning pathways that can be systematically influenced within language models. Activation steering proves to be a powerful technique for improving model performance on formal reasoning tasks where fine-tuning may be impractical or resource-intensive. As language models continue to evolve in their theorem-proving capabilities, activation steering may serve as a lightweight alternative to specialized fine-tuning approaches. Rather than training separate models for different theorem-proving strategies, the same base model could be adapted through steering vectors that guide its reasoning process as needed. This could be particularly valuable for interactive theorem proving environments where computational resources are limited. Our reasoning-based steering vectors, for example, could provide an efficient way to enhance proof assistants, particularly useful for applications like automated tactic suggestion. In future work, we aim to study the underlying mechanisms in language models responsible for structured mathematical reasoning. We further wish to explore how reasoning-focused steering vectors may generalize to open-ended theorem proving tasks and investigate their potential for improving proof search strategies.
\section{Future Works}
Our work opens several promising research directions for improving theorem proving with activation steering. From a theoretical perspective, we aim to investigate the geometric properties of steering vectors in the context of formal reasoning, studying how different model layers represent logical structures and how steering vectors interact with these representations. Understanding these properties could lead to more efficient steering methods and deeper insights into how LLMs encode mathematical concepts. On the practical side, several extensions could enhance theorem proving systems, including the development of adaptive steering mechanisms that dynamically adjust based on proof state complexity, the investigation of steering vector composition for handling compound mathematical concepts, and the integration of steering with existing proof search heuristics to improve exploration efficiency. Scalability remains a challenge, and future work should explore techniques for reducing the computational overhead of steering during inference, methods for distilling steering vectors while maintaining their effectiveness, and approaches for generalizing steering vectors across different mathematical domains. Our findings suggest that activation steering could become a powerful tool for enhancing LLM-based theorem provers, particularly in resource-constrained environments where fine-tuning is impractical. We believe that exploring these directions will lead to more robust and efficient theorem proving systems.
