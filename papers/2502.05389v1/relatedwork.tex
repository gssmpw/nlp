\section{Related work}
To date, SLU research has mostly involved first identifying word sequences.  As such, there has been a focus on integrating prosodic information into ASR models. Previous research has used prosody by conditioning the acoustic and pronunciation modelling on prosodic features \cite{Shriberg, 1561280}, simultaneously predicting prosodic events \cite{chen2003prosody,Hasegawa-Johnson}, or incorporating prosodic information in N-best rescoring in hybrid ASR systems \cite{4218240,Ananthakrishnan, huang10_speechprosody}. However, current state-of-the-art ASR models do not model prosody explicitly. 

Researchers have also explored using prosody to help other tasks.  Assuming known time alignments, incorporating word-level prosodic features has yielded improvements in constituent parsing of conversational speech \cite{tran-etal-2018-parsing, Tran2019OnTR}. Prosody has also been shown helpful in topic tracking \cite{guinaudeau11_interspeech}, dialogue act classification \cite{wei2022neuralprosodyencoderendroend} speech to intent \cite{rajaa23_interspeech}, and emotion recognition \cite{Luengo2005AutomaticER,naderi2023cross}. These studies modeled prosodic patterns either at the word or utterance level by averaging frame-level features such as pitch and intensity, or by using other hand-selected prosodic features. With the rise in popularity of neural networks, prosodic patterns can now be more effectively captured and modeled directly through CNNs, allowing for a more comprehensive representation of the prosodic features without the need for manual selection. 

However, with the emergence of SSL models \cite{Baevski2020wav2vec2A, hsu2021hubert, chen2022wavlm}, prosody is usually not explicitly modeled as a separate feature. Instead, it has been shown that these models capture prosodic information implicitly within their learned representations, alongside other linguistic features. SSL models are pre-trained on large amounts of unlabeled audio data, learning representations by predicting missing portions of the input signal or clustered latent speech units. There has been extensive research exploring the utility of SSL representations in prosody-related tasks, and it has been concluded that these representations encode prosodic information such as gender and speaker identity \cite{deseyssel22_interspeech, oli, Mukhtar}. These representations have also been successfully applied to tasks such as emotion recognition, speaker identification, and intonation analysis \cite{10023234}. To leverage the capabilities of advanced language models, k-means clustering or other quantization approaches are typically used in conjunction with SSL representations to reduce the length of the input sequences. It has been observed that even within these discrete units, prosodic information is preserved, resulting in relatively low error rates for speaker and gender classification, particularly when more clusters are used \cite{deseyssel22_interspeech}. This suggests that these discrete units retain key prosodic cues, which we use to represent speech in our study, allowing us to investigate the role of prosody in SQA tasks more effectively.