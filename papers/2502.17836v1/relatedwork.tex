\section{Related Work}
{Classification of diseases by medical image analysis is a vital area of research in the healthcare sector. Imaging analysis aided by AI can detect COVID-19 and TB quickly, lessening the effect of these diseases. The foregoing discussion of the features of X-ray images forms the basis of an AI-based method described here for accurately interpreting TB and COVID-19 cases from the input CXR radiograph with the aid of professional radiologists. Several experiments have been conducted to lessen the burden on doctors and radiologists for analysis and data tagging by using artificial intelligence and machine learning for faster COVID-19 and earlier TB screening and tagging. This section summarizes existing disease detection and feature visualization methods, including both discriminative and generative approaches.}

\subsection{Generative Adversarial Networks (GANs)}
{
GANs are two-part designs, with the generator network programmed to generate new content and the discriminator network distinguishing the data coming from both real and false data distribution \cite{19}. Generator and discriminator models are built concurrently, with the generator aiming to fool the discriminator by simulating genuine occurrences. In numerous fields, GANs have proven to be highly effective \cite{20,21}. Such examples include face image synthesis and domain interpretation. While existing GAN-based disease feature visualization methods use image-to-image translation to move data from one domain to another, they require labeling information that is not available in the raw data. Consequentially, these methods are often manual and incompetent for solving various problems, such as describing the decision-making process and generating pixel-level annotations. To facilitate domain translation, researchers have introduced the Cycle consistent GAN (CycleGAN), the first unpaired image-to-image translation model that converts abnormal to normal classes without requiring paired normal images during training \cite{22}. Our proposed method is fundamentally based on this approach. GANs have been used for a variety of applications, especially in healthcare and medical imaging analysis. Disease identification, organ segmentation (such as the heart or liver), artery network segmentation, and disease impact visualization, in the context of XAI, are just a few examples \cite{23,24}.
}

\subsection{Disease Attributes Visualization}
{
Visual attribution refers to the process of locating and representing in an image the specific signs of disease that help define the category of an input image. Deep features from classifiers are commonly used for segmentation or localization in tasks with limited supervision \cite{25}. Class Activation Mapping (CAM) \cite{26} is a popular technique with similar goals; it generates a class-specific feature map by incorporating a pooling layer with a global average into a system to reduce the number of networks that collectively make up the feature set. Because the results for each value are independently calculated, a CAM model cannot be used to efficiently generate a concise map for attribute visualization. Using these methods, it is difficult to pinpoint the pixel-level characteristics of a certain disease. Using a back propagation approach to restore gradients to their original locations in the input CXR, saliency maps are a unique method for identifying and visualizing illness attributes.

However, they are dependent on classification, thus they do not give a whole picture of the region of interest, and they also overlook some key aspects of diseases. Since the approach is concerned with the architecture's ultimate feature space, it necessitates pre-processing of the network prediction. As researchers in an article \cite{27} point out that the saliency maps only represent the places that networks stare at often while making a certain decision. Another methodology, Grad-CAM \cite{28}, only depicts high-density areas where the system focuses its attention while creating illness maps. Nothing in the image should be taken as a suggestion that the location portrayed has any infectious elements. If the data is missing critical information or there are no binary masks to use to train the algorithm, these discriminative-based approaches cannot operate in a weakly supervised setting.

To solve these issues with discriminative models, researchers developed a generative-based explainable technique called Visual Attribution GAN (VA-GAN) \cite{15}. The VA-GAN uses the concept of visual interpretation to pinpoint disease features, but this has unintended results because the mapping function translates every abnormal image into any image of a normal class. The resulting normal CXR has noises that are not a pair of input diseased CXRs. The discriminator of VA-GAN, however, labels the newly generated CXR as normal, even though it does not match either of the input aberrant images. Because of this, medical data will never be tagged by a model that cannot detect disease at the pixel-level and can not preserve anatomical features. In reality, this structure is founded on Wasserstein GAN \cite{29}, which does not reliably maintain the originality of input images because of only the forward phase. Importantly, this model cannot build binary masks because it only takes into account a small subset of the properties of the domain being shown. Another generative-based disease visualization method, ANT-GAN \cite{16}, was proposed as a means of dealing with the aforementioned problems and producing normal images while retaining the contents of the input abnormal images. This approach makes an effort to account for all attributes unique to the domain, resulting in an abnormal pair of input data. Nevertheless, because it is based on the disease map addition concept, this approach is limited in how it may be used to explain medical data because it does not account for disease identification at the pixel level. To create binary masks and train algorithms for interpretability, paired data is required, but this is not always available. Particularly in radiology, where it would be impractical to track down a patient's healthy and abnormal chest X-rays, this is an issue. 

As a result, an explainable model that can identify the illness traits and automatically tag the medical data is required in the setting of weakly supervised learning to detect the disease at a fine-grained level. To find disease-oriented features at a fine-grained level, show the pixel-level information of those locations in the input, and tag the input CXR radiograph, the framework should be trained on CXR with domain-level labels without binary masks. Therefore, our proposed TagGAN did not need paired data to learn modeling among anomalous and normal distribution, identify disease consequences at pixel-level, depict abnormalities of the disease, and provide annotation of input CXR radiograph, unlike the CycleGAN, VA-GAN, and ANT-GAN models. Recent works in both generative and discriminative models are summarized in Table \ref{tab:example1}, along with details regarding the challenges at hand, the methods chosen, and the limitations of these methods.

\begin{table}[h!]
\centering
\caption{\label{tab:example1}Summary of Methods}
\bigskip
\begin{tabular}{| p{2cm}|p{4cm}|p{2cm}|p{4cm}|}
\hline
\textbf{Reference} & \textbf{Methodology} & \textbf{Algorithm} & \textbf{Remarks} \\
\hline
Baumgartner, C. F., et al. \cite{15} & To show the effects of the disease without resorting to classification, this model generates disease maps from diseased CXR. It combines the input image with the created change map to get the normal distribution. & WGAN & (1) Causes false positive results, (2) adds random noise in the visualization map, and (3) cannot tag data \\
\hline
Sun, L., et al. \cite{16} & A standard CycleGAN-based method for identifying and visualizing lesions, wherein abnormal data is complemented with a disease map to provide a computed tomography (CXR) image of the lesion in its nonabnormal form. & CycleGAN & (1) Limited interpretability, (2) unable to identify disease at pixel-level, and (3) cannot be used to tag data  \\
\hline
B. Zhou, et al. \cite{26} & This method accomplishes interpretability by first shrinking the network's feature set and then averaging their data with a pooling layer. To this goal, class-specific activation maps are produced. & CAM & (1) The network's prediction requires post-processing, and (2) cannot be used to tag data\\
\hline
\end{tabular}

\end{table}
}