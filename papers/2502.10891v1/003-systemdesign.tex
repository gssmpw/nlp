
\section{\sysname Design}
\label{sec:systemdesign_transmission}
In this section, we introduce three key designs of \sysname:
context-aware tokens distillation, error-resilient fine-tuning, reliability enhancement at the PHY layer including packetization
and smoothed \& bounded time synchronization.




\subsection{Context-aware Tokens Distillation}
\label{sec:semantic_filtering}


Generative image compression models encode an image with $M$ tokens,
each selected from a codebook containing $K$ possible tokens.
This results in a compressed image size of $M\times \log_2 K$ bits.
Designed to reconstruct and generate images with high fidelity across
a wide range of scenes (e.g., ImageNet-1000 with 1,000 object classes),
these generative models often conservatively adopt large values for $M$ and $K$
to preserve visual details.
For example, VQGAN~\cite{mao2024extreme} uses $M=256$ and $K=1024$ for an input
resolution of 256$\times$256, resulting a compressed image size of 2,560 bits.


However, in specialized domains such as underwater imaging, we observe
that many tokens in the codebook are rarely or never used, resulting in
inefficient bandwidth usage.
To quantify this redundancy, we analyze token utilization when compressing
images from underwater datasets.
As shown in Fig.~\ref{fig:codebook_merger}, 519 out of 1024 tokens in VQGAN's
codebook remain unused, presenting an opportunity to optimize
the representation and enhance compression efficiency.


Following the methodology laid out by TiTok~\cite{yu2024image},
a state-of-the-art generative model for image compression,
we employ a transformer-based distillation approach to improve token utilization
and minimize bandwidth consumption in underwater communication.
Specifically, given $M$ original image tokens, we append $M'$ randomly initialized
tokens ($M' \ll M$) and train a transformer model on underwater image datasets
to transfer the most relevant information from the original tokens to the
appended tokens (via the attention
mechanism~\cite{touvron2021training}).
On the decoder side, a similar transformer is trained to reconstruct the
original $M$ tokens from the received $M'$ tokens, by minimizing the
cross-entropy loss between the original and reconstructed tokens.
Through this \emph{context-aware tokens distillation} process, the data size
is reduced by a factor of $(M \times \log_{2}K) / (M'\times \log_{2}K')$, where $K'$
represents the codebook size for the distilled tokens.





\begin{figure}[t]
    \centering
    \includegraphics[width=0.3\textwidth]{figs/motivation_codebook_reduction.pdf}
    \vspace{-5pt}
    \caption{Tokens in codebook are underutilized: over 50\% of tokens remain unused in underwater image compression.}
    \label{fig:codebook_merger}
\end{figure}





\subsection{Error-resilient Fine-tuning}\label{sec:fine_tuning}

Generative image compression models are commonly pre-trained on large-scale
image datasets (e.g., ImageNet) to achieve generalization, with the training
process assuming that all tokens produced by the encoder are received intact
by the decoder.
However, in underwater environments, transmission errors are inevitable,
often resulting in corrupted or lost tokens.
Meanwhile, best practices suggest that fine-tuning a pre-trained generative
model for a specific target scenario enhances performance.
Therefore, we fine-tune the image decoder on underwater
datasets with simulated transmission errors, as detailed below.

We denote the encoder and decoder by $f_{\theta}$ and $g_{\phi}$, respectively,
with $\theta$ and $\phi$ representing their corresponding weights.
As illustrated in Fig.~\ref{fig:fine_tuning}, the encoder $f_{\theta}$
converts a raw image $\mathbf{x}$ into a sequence of indices
$f_{\theta}(\mathbf{x})$.
Then, we randomly sample from these indices and introduce disturbance.
The resulting sequence $\mathbf{y}$ is used by the decoder to
reconstruct the image as $\hat{\mathbf{x}} = g_{\phi}(\mathbf{y})$.
To enhance reconstruction quality, we optimize a composite loss function that
combines pixel-level reconstruction loss, perceptual loss, and GAN loss,
following standard practices in image reconstruction model
training~\cite{esser2021taming}.


The random disturbance is introduced as follows.
Given $M$ tokens, we randomly perturb $m$ of them (by replacing each
with an alternative token from the codebook), where $m$ is randomly selected
from $[1, p]$ ($p \le M$).
Following the curriculum learning strategy~\cite{bengio2009curriculum}, we progressively increase $p$ during training, allowing the model to learn with increasingly challenging perturbations for improved performance. We cap \( p \) at 25\% of \( M \) to prevent excessive perturbation, which could eliminate the useful information in tokens and hinder the model's ability to learn. This 25\% threshold is based on preliminary real-world experiments on error rates.






A key difference between \sysname and existing loss-resilient frameworks in networked system~\cite{nsdi24_grace,li2024reparolossresilientgenerativecodec} is that they assume the decoder can detect which indices are lost during transmission. This assumption holds in those frameworks because they packetize indices, making it possible to detect packet losses at the transport layer. In contrast, our approach transmits the entire set of indices in a single packet directly at the PHY layer, using signal processing techniques to conserve bandwidth. Hence, pinpointing corrupted indices becomes significantly challenging, as error detection capabilities at the PHY layer are inherently limited~\cite{hamming1986coding}.


\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/fine_tuning.pdf}
    \caption{Fine-tuning generative image compression for underwater communication.}
    \label{fig:fine_tuning}
\end{figure}


\subsection{Packetization}
\label{sec:packetizer}



Recall from \S\ref{sec:mov_challenges} that underwater image transmission
can take tens of seconds due to limited bandwidth,
and is highly susceptible to transmission errors caused by channel variations at the PHY layer.
To address these challenges, we insert a training symbol into the image packet
after every $N$ data symbols. This allows for more frequent channel
equalization
to correct symbol distortion introduced by the channel, and facilitates
time synchronization to compensate for device movement.
Taken together, more training symbols help reduce the symbol error rate (SER).







However, as shown in Fig.~\ref{fig:motiv_multi_training_symbols},
increasing the number of training symbols (\ie reducing $N$)
also raises the overhead ratio, leading to longer transmission
and signal processing times.
To balance this trade-off, we set $N=3$, which ensures that
the duration of each symbol group\footnote{Given a symbol time
$T_{s}$ of 16 ms (as explained in \S\ref{sec:implementation}), the duration
of each symbol group is $(N+1) \times T_{s}  = 64$ ms.}
remains within the channel coherence time underwater~\cite{yang2012properties}.


In traditional RF-based wireless systems, multiple training symbols are commonly used in OFDM~\cite{3GPP}. However, as discussed in \S\ref{sec:mov_challenges},
the OFDM protocol encounters significant challenges in underwater image transmission,
primarily due to substantial SNR drops in initially selected subcarriers
during long mobile transmissions.
Consequently, adding multiple training symbols for equalization becomes ineffective,
as equalization fails when the SNR is too low.
Instead, we adopt the CSS (chirp spread spectrum) technique~\cite{xie2024icc,jia2022two,steinmetz2018practical,steinmetz2022taking,TSN23} to convert image packets into chirp signals
as it offers a balance between robustness and transmission speed.

Furthermore, we introduce a preamble to assist the receiver in detecting
the packet and determining its starting timestamp.
Reliable preamble detection at low SNR is critical in underwater environments;
otherwise, all other efforts become futile if the packet cannot be detected.
We adopt the preamble from \cite{chen2022underwater}, which exhibits strong
auto-correlation properties for robust detection.
Additionally, the detection algorithm has a lower false positive rate,
meaning it is less likely to be triggered by ambient underwater noise.

In summary,
each image packet consists of a single preamble, followed by multiple symbol groups,
where each symbol group includes one training symbol and three data symbols as shown in Fig.~\ref{fig:image_packet}.


\begin{figure}[t]
    \centering
    \begin{minipage}[h]{0.26\textwidth}
        \centering
    \includegraphics[width=\textwidth]{figs/motivation_training_symbol.pdf}
    \vspace{-12pt}
    \caption{Symbol error rate (SER) and overhead ratio at
    varying training symbol frequencies.}
\label{fig:motiv_multi_training_symbols}
    \end{minipage}
    \hfill
    \begin{minipage}[h]{0.2\textwidth}
        \centering
    \includegraphics[width=\textwidth]{figs/image_packet.pdf}
   \vspace{-8pt}
    \caption{Image packetization.}
    \label{fig:image_packet}
    \end{minipage}
\end{figure}

\subsection{Smoothed \& Bounded Time Synchronization}\label{sec:synchronization}
The receiver's microphone continuously records audio and monitors for packet arrival
using the detection algorithm in~\cite{chen2022underwater}.
To identify packets, we perform cross-correlation between the received signal and
the preamble. Once a correlation peak is found,
an image packet is detected, and the receiver
captures sound for a fixed duration (slightly longer than the packet length)
as raw received data.
Nevertheless, due to the movement of mobile devices, symbol time offset is inevitable. %
To correct this offset, the receiver identifies the start timestamp of each training symbol via cross-correlation and adjusts the timestamps of the following data symbols.
However, directly applying cross-correlation for symbol timing synchronization is error-prone due to channel fading, multipath effects, and
ambient noise.

Therefore, to enhance the robustness of time synchronization,
we leverage two insights related to physical principles.
First, the relative speed between the sender and receiver during a specific
activity (e.g., scuba diving) is naturally constrained, \ie the difference in start timestamps between two consecutive training symbols is bounded:
\begin{align}
    | t_{tsym}^{i-1} + N_{sgroup}- t_{tsym}^{i} |  \leq \Delta,
\end{align}
where $t_{tsym}^{i}$ denotes the start index of the $i$-th training symbol,
and $N_{sgroup}$ represents the length of the sending symbol group in samples.
In our setup, $N_{sgroup} = (N+1) \times N_{s} = 3072$, where $N_{s}$ is the number of samples per symbol.
We set $\Delta = 40$ empirically based on preliminary experiments,
taking into account the maximum relative movement speed between the sender
and receiver, as well as orientation changes.
This bounded constraint allows us to efficiently search for the start
time of the next training symbol within a limited range,
thereby improving synchronization accuracy and computational efficiency
on mobile devices.




\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/smooth.pdf}
    \vspace{-20pt} %
    \caption{Start timestamp drift in training symbols.}
    \label{fig:doppler_observation}
\end{figure}

Second, the distance between the sender and receiver should change gradually,
\ie the drift in the start timestamp of each training symbol should also
change smoothly. We calculate the drift as the difference between the
detected start timestamp of the training symbol and its expected start timestamp
($i \times N_{group}$) when there is no movement. If the drift changes
drastically, resulting in excessive jitter as shown by the blue line
in Fig.~\ref{fig:doppler_observation}, we can infer that
an error has occurred in symbol time synchronization.

In Fig.~\ref{fig:doppler_observation}, the x-axis represents the index of the training symbol, and the y-axis shows the start timestamp drift. We collected this data by submerging two phones underwater from two boats and driving the boats in random directions and at varying distances.
\textit{Raw Drift} does not address jitter specifically, leading to noisy and inaccurate predictions due to imperfections in the cross-correlation results.
Leveraging our second insight, we apply a moving average~\cite{moving_average} to smooth \textit{Raw Drift} and eliminate spikes, as shown by \textit{Smooth Drift}. While this method effectively corrects short-term drift (and thus identifies the correct start timestamp quickly), it fails to handle long-term drift (where the timestamps shift beyond the recoverable range). To address this, we further constrain drift within a limited range based on our first insight. This is denoted as \textit{Smooth Drift + Range Limit} and used to
recalculate the start timestamp of each training symbol. Later, we demonstrate that
our proposed drift smoothing and bounding approach significantly reduces
SERs.

After compensating for the influence of movement and smoothing out detection errors, we utilize the correct start timestamps of two consecutive training symbols---obtained from the previous symbol time synchronization---to segment the symbol group and extract the data symbols. Finally, we apply linear interpolation to the data symbols to mitigate the Doppler effect.






















