\captionsetup[subfigure]{aboveskip=0pt, belowskip=1pt} %
\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.09\textwidth}
        \includegraphics[width=\linewidth]{figs/visualization_sigcomm/original-diving_5_frame_2525-original.pdf}
        \caption*{\scriptsize Original}
    \end{subfigure}
    \begin{subfigure}[b]{0.09\textwidth}
        \includegraphics[width=\linewidth]{figs/visualization_sigcomm/vqgan-diving_5_frame_2525-0-0.pdf}
        \caption*{\scriptsize VQGAN (256)}
    \end{subfigure}
    \begin{subfigure}[b]{0.09\textwidth}
        \includegraphics[width=\linewidth]{figs/visualization_sigcomm/clean-diving_5_frame_2525-0-0.pdf}
        \caption*{\scriptsize Distilled (64)}
    \end{subfigure}
        \begin{subfigure}[b]{0.09\textwidth}
        \includegraphics[width=\linewidth]{figs/visualization_sigcomm/titok-diving_5_frame_2525-12-1.pdf}
        \caption*{\scriptsize TiTok (20\%)}
    \end{subfigure}
    \begin{subfigure}[b]{0.09\textwidth}
        \includegraphics[width=\linewidth]{figs/visualization_sigcomm/ours-diving_5_frame_2525-12-1.pdf}
        \caption*{\scriptsize Ours (20\%)}
    \end{subfigure}
    \caption{Samples of reconstructed images from different methods. VQGAN uses 256 tokens. ``Distilled'' is our fine-tuned version of TiTok without transmission errors. TiTok employs the base-64 model with a 20\% IER. ``Ours'' represents our fine-tuned version of TiTok with a 20\% IER. %
    }
    \label{fig:semantic_compression_filtering_intuition}
    \vspace{3pt}

\end{figure}
