
@article{gholami_survey_2021,
	title = {A survey of quantization methods for efficient neural network inference},
	journal = {arXiv preprint arXiv:2103.13630},
	author = {Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W. and Keutzer, Kurt},
	year = {2021},
}

@article{nagel_white_2021,
	title = {A white paper on neural network quantization},
	journal = {arXiv preprint arXiv:2106.08295},
	author = {Nagel, Markus and Fournarakis, Marios and Amjad, Rana Ali and Bondarenko, Yelysei and Baalen, Mart van and Blankevoort, Tijmen},
	year = {2021},
}

@inproceedings{bartlett_spectrally-normalized_2017,
	title = {Spectrally-normalized margin bounds for neural networks},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bartlett, Peter L and Foster, Dylan J and Telgarsky, Matus},
	year = {2017},
}

@article{chatterjee_neural_2024,
	title = {Neural networks generalize on low complexity data},
	urldate = {2024-12-29},
	journal = {arXiv preprint arXiv:2409.12446},
	author = {Chatterjee, Sourav and Sudijono, Timothy},
	year = {2024}
}

@book{craik1967nature,
  title={The nature of explanation},
  author={Craik, Kenneth James Williams},
  volume={445},
  year={1967},
  publisher={CUP Archive}
}

@article{friston2021world,
  title={World model learning and inference},
  author={Friston, Karl and Moran, Rosalyn J and Nagai, Yukie and Taniguchi, Tadahiro and Gomi, Hiroaki and Tenenbaum, Josh},
  journal={Neural Networks},
  volume={144},
  pages={573--590},
  year={2021},
  publisher={Elsevier}
}

@article{wong_word_2023,
	title = {From word models to world models: {Translating} from natural language to the probabilistic language of thought},
	journal = {arXiv preprint arXiv:2306.12672},
	author = {Wong, Lionel and Grand, Gabriel and Lew, Alexander K. and Goodman, Noah D. and Mansinghka, Vikash K. and Andreas, Jacob and Tenenbaum, Joshua B.},
	year = {2023}
}

@article{xie_making_2024,
	title = {Making large language models into world models with precondition and effect knowledge},
	language = {en},
	journal = {arXiv preprint arXiv:2409.12278},
	author = {Xie, Kaige and Yang, Ian and Gunerli, John and Riedl, Mark},
	year = {2024},

}

@article{lecun2022path,
  title={A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27},
  author={LeCun, Yann},
  journal={Open Review},
  volume={62},
  number={1},
  pages={1--62},
  year={2022}
}

@article{mitchell_ai_2023,
author = {Melanie Mitchell },
title = {AI’s challenge of understanding the world},
journal = {Science},
volume = {382},
number = {6671},
pages = {eadm8175},
year = {2023},
doi = {10.1126/science.adm8175},
}

@inproceedings{jin_emergent_2024,
	title = {Emergent representations of program semantics in language models trained on programs},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Jin, Charles and Rinard, Martin},
	year = {2024},
}

@article{tian2024fast,
  title={Fast trainable projection for robust fine-tuning},
  author={Tian, Junjiao and Liu, Yen-Cheng and Smith, James S and Kira, Zsolt},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{brooks2024video,
  title={Video generation models as world simulators},
  author={Brooks, Tim and Peebles, Bill and Holmes, Connor and DePue, Will and Guo, Yufei and Jing, Li and Schnurr, David and Taylor, Joe and Luhman, Troy and Luhman, Eric and others},
  journal={2024-03-03]. https://openai. com/research/video-generation-modelsas-world-simulators},
  year={2024}
}

@article{motamed_generative_2025,
	title = {Do generative video models learn physical principles from watching videos?},
	journal = {arXiv preprint arXiv:2501.09038},
	author = {Motamed, Saman and Culp, Laura and Swersky, Kevin and Jaini, Priyank and Geirhos, Robert},
	year = {2025}
}

@article{raghu2021vision,
  title={Do vision transformers see like convolutional neural networks?},
  author={Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={12116--12128},
  year={2021}
}

@article{yildirim2024task,
  title={From task structures to world models: what do LLMs know?},
  author={Yildirim, Ilker and Paul, LA},
  journal={Trends in Cognitive Sciences},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{press_train_2022,
	title = {Train short, test long: {Attention} with linear biases enables input length extrapolation},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Press, Ofir and Smith, Noah and Lewis, Mike},
	year = {2022}
}

@article{anil2022exploring,
  title={Exploring length generalization in large language models},
  author={Anil, Cem and Wu, Yuhuai and Andreassen, Anders and Lewkowycz, Aitor and Misra, Vedant and Ramasesh, Vinay and Slone, Ambrose and Gur-Ari, Guy and Dyer, Ethan and Neyshabur, Behnam},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={38546--38556},
  year={2022}
}

@article{anil2022exploring,
  title={Exploring length generalization in large language models},
  author={Anil, Cem and Wu, Yuhuai and Andreassen, Anders and Lewkowycz, Aitor and Misra, Vedant and Ramasesh, Vinay and Slone, Ambrose and Gur-Ari, Guy and Dyer, Ethan and Neyshabur, Behnam},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={38546--38556},
  year={2022}
}

@article{liu2021self,
  title={Self-supervised learning: Generative or contrastive},
  author={Liu, Xiao and Zhang, Fanjin and Hou, Zhenyu and Mian, Li and Wang, Zhaoyu and Zhang, Jing and Tang, Jie},
  journal={IEEE transactions on knowleadge and data engineering},
  volume={35},
  number={1},
  pages={857--876},
  year={2021},
  publisher={IEEE}
}

@article{kukavcka2017regularization,
  title={Regularization for deep learning: A taxonomy},
  author={Kuka{\v{c}}ka, Jan and Golkov, Vladimir and Cremers, Daniel},
  journal={arXiv preprint arXiv:1710.10686},
  year={2017}
}

@book{grunwald2007minimum,
  title={The minimum description length principle},
  author={Gr{\"u}nwald, Peter D},
  year={2007},
  publisher={MIT press}
}

@article{xu2019frequency,
  title={Frequency principle: Fourier analysis sheds light on deep neural networks},
  author={Xu, Zhi-Qin John and Zhang, Yaoyu and Luo, Tao and Xiao, Yanyang and Ma, Zheng},
  journal={arXiv preprint arXiv:1901.06523},
  year={2019}
}

@article{whitley2005complexity,
  title={Complexity theory and the no free lunch theorem},
  author={Whitley, Darrell and Watson, Jean Paul},
  journal={Search methodologies: Introductory tutorials in optimization and decision support techniques},
  pages={317--339},
  year={2005},
  publisher={Springer}
}

@article{wolpert1996lack,
  title={The lack of a priori distinctions between learning algorithms},
  author={Wolpert, David H},
  journal={Neural computation},
  volume={8},
  number={7},
  pages={1341--1390},
  year={1996},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@book{li2008introduction,
  title={An introduction to Kolmogorov complexity and its applications},
  author={Li, Ming and Vit{\'a}nyi, Paul and others},
  volume={3},
  year={2008},
}

@article{li2021implicit,
  title={Implicit representations of meaning in neural language models},
  author={Li, Belinda Z and Nye, Maxwell and Andreas, Jacob},
  journal={arXiv preprint arXiv:2106.00737},
  year={2021}
}

@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
}

@book{everett2013introduction,
  title={An introduction to latent variable models},
  author={Everett, B},
  year={2013},
}

@article{bricken2023towards,
  title={Towards monosemanticity: Decomposing language models with dictionary learning},
  author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and others},
  journal={Transformer Circuits Thread},
  volume={2},
  year={2023}
}

@article{bickel_discriminative_2009,
	title = {Discriminative learning under covariate shift},
	volume = {10},
	journal = {Journal of Machine Learning Research},
	author = {Bickel, Steffen and Brückner, Michael and Scheffer, Tobias},
	year = {2009},
	pages = {2137--2155},
}

@article{nichol_gotta_2018,
	title = {Gotta learn fast: {A} new benchmark for generalization in {RL}},
	shorttitle = {Gotta learn fast},
	language = {en},
	journal = {arXiv:1804.03720 [cs, stat]},
	author = {Nichol, Alex and Pfau, Vicki and Hesse, Christopher and Klimov, Oleg and Schulman, John},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{ghosh_why_2021,
	title = {Why generalization in {RL} is difficult: {Epistemic} {POMDPs} and implicit partial observability},
	shorttitle = {Why generalization in rl is difficult},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ghosh, Dibya and Rahme, Jad and Kumar, Aviral and Zhang, Amy and Adams, Ryan P. and Levine, Sergey},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{grill_bootstrap_2020,
	title = {Bootstrap your own latent: {A} new approach to self-supervised {Learning}},
	shorttitle = {Bootstrap your own latent},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Grill, Jean-Bastien and Strub, Florian and Altché, Florent and Tallec, Corentin and Richemond, Pierre H. and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and Piot, Bilal and Kavukcuoglu, Koray and Munos, Rémi and Valko, Michal},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{kingma_glow_2018,
	title = {Glow: {Generative} flow with invertible 1x1 convolutions},
	shorttitle = {Glow},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kingma, Diederik P. and Dhariwal, Prafulla},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{liu_energy-based_2020,
	title = {Energy-based out-of-distribution detection},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Liu, Weitang and Wang, Xiaoyun and Owens, John D. and Li, Yixuan},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{ren_likelihood_2019,
	title = {Likelihood ratios for out-of-distribution detection},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ren, Jie and Liu, Peter J. and Fertig, Emily and Snoek, Jasper and Poplin, Ryan and DePristo, Mark A. and Dillon, Joshua V. and Lakshminarayanan, Balaji},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{winkens_contrastive_2020,
	title = {Contrastive training for improved out-of-distribution detection},
	language = {en},
	journal = {arXiv preprint arXiv:2007.05566},
	author = {Winkens, Jim and Bunel, Rudy and Roy, Abhijit Guha and Stanforth, Robert and Natarajan, Vivek and Ledsam, Joseph R. and MacWilliams, Patricia and Kohli, Pushmeet and Karthikesalingam, Alan and Kohl, Simon and Cemgil, Taylan and Eslami, S. M. Ali and Ronneberger, Olaf},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{bai_are_2021,
	title = {Are transformers more robust than {CNNs}?},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bai, Yutong and Mei, Jieru and Yuille, Alan and Xie, Cihang},
	year = {2021},
	pages = {26831--26843},
}

@inproceedings{peng_moment_2019,
	address = {Seoul, Korea (South)},
	title = {Moment matching for multi-source domain adaptation},
	isbn = {978-1-72814-803-8},
	doi = {10.1109/ICCV.2019.00149},
	language = {en},
	booktitle = {{ICCV}},
	author = {Peng, Xingchao and Bai, Qinxun and Xia, Xide and Huang, Zijun and Saenko, Kate and Wang, Bo},
	year = {2019},
	pages = {1406--1415},
}

@inproceedings{french_self-ensembling_2018,
	title = {Self-ensembling for visual domain adaptation},
	language = {en},
	booktitle = {{ICLR}},
	author = {French, Geoffrey and Mackiewicz, Michal and Fisher, Mark},
	year = {2018},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{sagawa_distributionally_2020,
	title = {Distributionally robust neural networks for group shifts: {On} the importance of regularization for worst-case generalization},
	booktitle = {{ICLR}},
	author = {Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B. and Liang, Percy},
	year = {2020},
}

@inproceedings{blanchard_generalizing_2011,
	title = {Generalizing from several related classification tasks to a new unlabeled sample},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Blanchard, Gilles and Lee, Gyemin and Scott, Clayton},
	year = {2011},
}

@article{zhou_domain_2021,
	title = {Domain generalization in vision: {A} survey},
	shorttitle = {Domain generalization in vision},
	language = {en},
	journal = {arXiv preprint arXiv:2103.02503},
	author = {Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Xiang, Tao and Loy, Chen Change},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{bengio_estimating_2013,
	title = {Estimating or propagating gradients through stochastic neurons for conditional computation},
	language = {en},
	journal = {arXiv preprint arXiv:1308.3432},
	author = {Bengio, Yoshua and Léonard, Nicholas and Courville, Aaron},
	year = {2013},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{tan_survey_2018,
	title = {A survey on deep transfer learning},
	booktitle = {International conference on artificial neural networks},
	author = {Tan, Chuanqi and Sun, Fuchun and Kong, Tao and Zhang, Wenchang and Yang, Chao and Liu, Chunfang},
	year = {2018},
	pages = {270--279},
}

@article{wang_deep_2018,
	title = {Deep visual domain adaptation: {A} survey},
	volume = {312},
	issn = {09252312},
	shorttitle = {Deep visual domain adaptation},
	doi = {10.1016/j.neucom.2018.05.083},
	language = {en},
	journal = {Neurocomputing},
	author = {Wang, Mei and Deng, Weihong},
	year = {2018},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {135--153},
}

@article{sagi_ensemble_2018,
	title = {Ensemble learning: {A} survey},
	volume = {8},
	issn = {1942-4795},
	shorttitle = {Ensemble learning},
	doi = {10.1002/widm.1249},
	language = {en},
	number = {4},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Sagi, Omer and Rokach, Lior},
	year = {2018},
	keywords = {boosting, classifier combination, ensemble models, machine-learning, mixtures of experts, multiple classifier system, random forest},
	pages = {e1249},
}

@book{zhang_ensemble_2012,
	title = {Ensemble machine learning: methods and applications},
	isbn = {1-4419-9325-8},
	author = {Zhang, Cha and Ma, Yunqian},
	year = {2012},
}

@incollection{zhou_ensemble_2021,
	title = {Ensemble learning},
	booktitle = {Machine {Learning}},
	author = {Zhou, Zhi-Hua},
	year = {2021},
	pages = {181--210},
}

@incollection{polikar_ensemble_2012,
	title = {Ensemble learning},
	booktitle = {Ensemble machine learning},
	author = {Polikar, Robi},
	year = {2012},
	pages = {1--34},
}

@article{dietterich_ensemble_2002,
	title = {Ensemble learning},
	volume = {2},
	number = {1},
	journal = {The handbook of brain theory and neural networks},
	author = {Dietterich, Thomas G.},
	year = {2002},
	pages = {110--125},
}

@article{saxe_information_2019,
	title = {On the information bottleneck theory of deep learning},
	issn = {1742-5468},
	doi = {10.1088/1742-5468/ab3985},
	language = {en},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	author = {Saxe, Andrew M and Bansal, Yamini and Dapello, Joel and Advani, Madhu and Kolchinsky, Artemy and Tracey, Brendan D and Cox, David D},
	year = {2019},
}

@article{deletang_model-free_2021,
	title = {Model-free risk-sensitive reinforcement learning},
	language = {en},
	journal = {arXiv preprint arXiv:2111.02907},
	author = {Delétang, Grégoire and Grau-Moya, Jordi and Kunesch, Markus and Genewein, Tim and Brekelmans, Rob and Legg, Shane and Ortega, Pedro A.},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@article{xie_multi-center_2020,
	title = {Multi-center federated learning},
	language = {en},
	journal = {arXiv preprint arXiv:2005.01026},
	author = {Xie, Ming and Long, Guodong and Shen, Tao and Zhou, Tianyi and Wang, Xianzhi and Jiang, Jing and Zhang, Chengqi},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing},
}

@inproceedings{hoffman_algorithms_2018,
	title = {Algorithms and theory for multiple-source adaptation},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Hoffman, Judy and Mohri, Mehryar and Zhang, Ningshan},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{simon_neural_2021,
	title = {Neural tangent kernel eigenvalues accurately predict generalization},
	journal = {arXiv preprint arXiv:2110.03922},
	author = {Simon, James B. and Dickens, Madeline and DeWeese, Michael R.},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{fruit_near_2018,
	title = {Near optimal exploration-exploitation in non-communicating {Markov} {Decision} {Processes}},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{wang_generalization_2019,
	title = {On the generalization gap in reparameterizable reinforcement learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Wang, Huan and Zheng, Stephan and Xiong, Caiming and Socher, Richard},
	year = {2019},
	pages = {11},
}

@inproceedings{shankar_generalizing_2018,
	title = {Generalizing across domains via cross-gradient training},
	language = {en},
	booktitle = {{ICLR}},
	author = {Shankar, Shiv and Piratla, Vihari and Chakrabarti, Soumen and Chaudhuri, Siddhartha and Jyothi, Preethi and Sarawagi, Sunita},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{ye_towards_2021,
	title = {Towards a theoretical framework of out-of-distribution generalization},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ye, Haotian and Xie, Chuanlong and Cai, Tianle and Li, Ruichen and Li, Zhenguo and Wang, Liwei},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{bengio_conditional_2016,
	title = {Conditional computation in neural networks for faster models},
	language = {en},
	booktitle = {{ICLR}},
	author = {Bengio, Emmanuel and Bacon, Pierre-Luc and Pineau, Joelle and Precup, Doina},
	year = {2016},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{ritter_scalable_2018,
	title = {A scalable laplace approximation for neural networks},
	language = {en},
	author = {Ritter, Hippolyt and Botev, Aleksandar and Barber, David},
	year = {2018},
}

@article{higgins_towards_2018,
	title = {Towards a definition of disentangled representations},
	journal = {arXiv preprint arXiv:1812.02230},
	author = {Higgins, Irina and Amos, David and Pfau, David and Racaniere, Sebastien and Matthey, Loic and Rezende, Danilo and Lerchner, Alexander},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{arora_understanding_2018,
	title = {Understanding deep neural networks with rectified linear units},
	language = {en},
	booktitle = {{ICLR}},
	author = {Arora, Raman and Basu, Amitabh and Mianjy, Poorya and Mukherjee, Anirbit},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computational Complexity, Condensed Matter - Disordered Systems and Neural Networks},
}

@inproceedings{kristiadi_being_2020,
	title = {Being {Bayesian}, even just a bit, fixes overconfidence in {ReLU} networks},
	booktitle = {{ICML}},
	author = {Kristiadi, Agustinus and Hein, Matthias and Hennig, Philipp},
	year = {2020},
}

@article{zhang_memo_2021,
	title = {{MEMO}: {Test} time robustness via adaptation and augmentation},
	shorttitle = {Memo},
	language = {en},
	journal = {arXiv preprint arXiv:2110.09506},
	author = {Zhang, Marvin and Levine, Sergey and Finn, Chelsea},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{hendrycks_natural_2021,
	title = {Natural adversarial examples},
	language = {en},
	booktitle = {{CVPR}},
	author = {Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
	year = {2021},
}

@inproceedings{frankle_lottery_2019,
	title = {The lottery ticket hypothesis: {Finding} sparse, trainable neural networks},
	shorttitle = {The lottery ticket hypothesis},
	language = {en},
	booktitle = {{ICLR}},
	author = {Frankle, Jonathan and Carbin, Michael},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@book{puterman_markov_1994,
	title = {Markov decision processes: {Discrete} stochastic dynamic programming},
	isbn = {1-118-62587-0},
	author = {Puterman, Martin L.},
	year = {1994},
}

@article{jaksch_near-optimal_2010,
	title = {Near-optimal regret bounds for reinforcement learning},
	volume = {11},
	number = {51},
	journal = {Journal of Machine Learning Research},
	author = {Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
	year = {2010},
	pages = {1563--1600},
}

@inproceedings{ioffe_batch_2015,
	title = {Batch normalization: {Accelerating} deep network training by reducing internal covariate shift},
	language = {en},
	booktitle = {{ICML}},
	author = {Ioffe, Sergey and Szegedy, Christian},
	year = {2015},
}

@article{ba_layer_2016,
	title = {Layer normalization},
	language = {en},
	journal = {arXiv preprint arXiv:1607.06450},
	author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{wu_group_2018,
	title = {Group normalization},
	language = {en},
	booktitle = {{ECCV}},
	author = {Wu, Yuxin and He, Kaiming},
	year = {2018},
}

@inproceedings{gupta_relay_2019,
	title = {Relay policy learning: {Solving} long-horizon tasks via imitation and reinforcement learning},
	shorttitle = {Relay policy learning},
	booktitle = {{CoRL}},
	author = {Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Robotics},
}

@article{fu_d4rl_2020,
	title = {{D4RL}: {Datasets} for deep data-driven reinforcement learning},
	shorttitle = {D4rl},
	language = {en},
	journal = {arXiv preprint arXiv:2004.07219},
	author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{scholkopf_toward_2021,
	title = {Toward causal representation learning},
	volume = {109},
	issn = {1558-2256},
	doi = {10.1109/JPROC.2021.3058954},
	number = {5},
	journal = {Proceedings of the IEEE},
	author = {Schölkopf, Bernhard and Locatello, Francesco and Bauer, Stefan and Ke, Nan Rosemary and Kalchbrenner, Nal and Goyal, Anirudh and Bengio, Yoshua},
	year = {2021},
	keywords = {Adaptation models, Artificial intelligence, causality, Data models, deep learning, Differential equations, Inference algorithms, Machine learning, Mathematical model, representation learning, Representation learning, Training data},
	pages = {612--634},
}

@article{scholkopf_causality_2019,
	title = {Causality for machine learning},
	journal = {arXiv preprint arXiv:1911.10500},
	author = {Schölkopf, Bernhard},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, I.2, I.2, I.5, K.4, I.5, K.4},
}

@article{burgess_understanding_2018,
	title = {Understanding disentangling in \${\textbackslash}beta\$-{VAE}},
	language = {en},
	journal = {arxiv preprint arXiv:1804.03599},
	author = {Burgess, Christopher P. and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{kim_disentangling_2018,
	title = {Disentangling by factorising},
	language = {en},
	booktitle = {{ICML}},
	author = {Kim, Hyunjik and Mnih, Andriy},
	year = {2018},
}

@inproceedings{gong_robust_2012,
	address = {Beijing, China},
	title = {Robust multi-task feature learning},
	isbn = {978-1-4503-1462-6},
	doi = {10.1145/2339530.2339672},
	language = {en},
	booktitle = {Proceedings of the 18th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining - {KDD} '12},
	author = {Gong, Pinghua and Ye, Jieping and Zhang, Changshui},
	year = {2012},
	pages = {895},
}

@inproceedings{nagarajan_understanding_2021,
	title = {Understanding the failure modes of out-of-distribution generalization},
	booktitle = {{ICLR}},
	author = {Nagarajan, Vaishnavh and Andreassen, Anders and Neyshabur, Behnam},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{chattopadhyay_learning_2020,
	title = {Learning to balance specificity and invariance for in and out of domain generalization},
	language = {en},
	booktitle = {{ECCV}},
	author = {Chattopadhyay, Prithvijit and Balaji, Yogesh and Hoffman, Judy},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	pages = {301--318},
}

@inproceedings{mahajan_domain_2021,
	title = {Domain generalization using causal matching},
	language = {en},
	booktitle = {{ICML}},
	author = {Mahajan, Divyat and Tople, Shruti and Sharma, Amit},
	year = {2021},
}

@inproceedings{ilse_diva_2020,
	title = {Diva: {Domain} invariant variational autoencoders},
	isbn = {2640-3498},
	booktitle = {Medical {Imaging} with {Deep} {Learning}},
	author = {Ilse, Maximilian and Tomczak, Jakub M. and Louizos, Christos and Welling, Max},
	year = {2020},
	pages = {322--348},
}

@article{deng_representation_2020,
	title = {Representation via representations: {Domain} generalization via adversarially learned invariant representations},
	shorttitle = {Representation via representations},
	language = {en},
	journal = {arXiv preprint arXiv:2006.11478},
	author = {Deng, Zhun and Ding, Frances and Dwork, Cynthia and Hong, Rachel and Parmigiani, Giovanni and Patil, Prasad and Sur, Pragya},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{xie_controllable_2017,
	title = {Controllable invariance through adversarial feature learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Xie, Qizhe and Dai, Zihang and Du, Yulun and Hovy, Eduard and Neubig, Graham},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{li_feature-critic_2019,
	title = {Feature-critic networks for heterogeneous domain generalization},
	language = {en},
	booktitle = {{ICML}},
	author = {Li, Yiying and Yang, Yongxin and Zhou, Wei and Hospedales, Timothy M.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{cheng_disentangled_2021,
	title = {Disentangled feature representation for few-shot image classification},
	language = {en},
	journal = {arXiv preprint arXiv:2109.12548},
	author = {Cheng, Hao and Wang, Yufei and Li, Haoliang and Kot, Alex C. and Wen, Bihan},
	year = {2021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{salman_adversarially_2020,
	title = {Do adversarially robust {ImageNet} models transfer better?},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Salman, Hadi and Ilyas, Andrew and Engstrom, Logan and Kapoor, Ashish and Madry, Aleksander},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{huh_what_2016,
	title = {What makes {ImageNet} good for transfer learning?},
	language = {en},
	journal = {arXiv preprint arXiv:1608.08614},
	author = {Huh, Minyoung and Agrawal, Pulkit and Efros, Alexei A.},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{kummerer_deep_2014,
	title = {Deep gaze {I}: {Boosting} saliency prediction with feature maps trained on imagenet},
	shorttitle = {Deep gaze i},
	language = {en},
	journal = {arXiv preprint arXiv:1411.1045},
	author = {Kümmerer, Matthias and Theis, Lucas and Bethge, Matthias},
	year = {2014},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Neurons and Cognition, Statistics - Applications},
}

@inproceedings{perez_film_2018,
	title = {Film: {Visual} reasoning with a general conditioning layer},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
	year = {2018},
}

@article{hunter_matplotlib_2007,
	title = {Matplotlib: {A} {2D} graphics environment},
	volume = {9},
	issn = {1558-366X},
	shorttitle = {Matplotlib},
	doi = {10.1109/MCSE.2007.55},
	number = {3},
	journal = {Computing in Science Engineering},
	author = {Hunter, John D.},
	year = {2007},
	keywords = {application development, Computer languages, Equations, Graphical user interfaces, Graphics, Image generation, Interpolation, Operating systems, Packaging, Programming profession, Python, scientific programming, scripting languages, User interfaces},
	pages = {90--95},
}

@inproceedings{abel_value_2020,
	title = {Value preserving state-action abstractions},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Abel, David and Umbanhowar, Nathan and Khetarpal, Khimya and Arumugam, Dilip and Precup, Doina and Littman, Michael L},
	year = {2020},
}

@inproceedings{waterhouse_bayesian_1996,
	title = {Bayesian methods for mixtures of experts},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Waterhouse, Steve R and MacKay, David and Robinson, Anthony J},
	year = {1996},
}

@article{yuksel_twenty_2012,
	title = {Twenty years of mixture of experts},
	volume = {23},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2012.2200299},
	number = {8},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Yuksel, Seniha Esen and Wilson, Joseph N. and Gader, Paul D.},
	year = {2012},
	keywords = {Data models, Applications, Bayesian, Bayesian methods, classification, comparison, Decision trees, Gaussian processes, Hidden Markov models, hierarchical mixture of experts (HME), mixture of Gaussian process experts, regression, Regression analysis, statistical properties, Support vector machines, survey, variational},
	pages = {1177--1193},
}

@inproceedings{mohri_agnostic_2019,
	title = {Agnostic federated learning},
	language = {en},
	author = {Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha},
	year = {2019},
}

@inproceedings{agrawal_optimistic_2017,
	title = {Optimistic posterior sampling for reinforcement learning: {Worst}-case regret bounds},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Agrawal, Shipra and Jia, Randy},
	year = {2017},
	pages = {1184--1194},
}

@inproceedings{fujimoto_equivalence_2020,
	title = {An equivalence between loss functions and non-uniform sampling in experience replay},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Fujimoto, Scott and Meger, David and Precup, Doina},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{koyama_when_2021,
	title = {When is invariance useful in an out-of-distribution generalization problem?},
	language = {en},
	journal = {arXiv preprint arXiv:2008.01883},
	author = {Koyama, Masanori and Yamaguchi, Shoichiro},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{qiao_learning_2020,
	title = {Learning to learn single domain generalization},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Qiao, Fengchun and Zhao, Long and Peng, Xi},
	year = {2020},
	pages = {12556--12565},
}

@inproceedings{li_deep_2018,
	title = {Deep domain generalization via conditional invariant adversarial networks},
	booktitle = {Proceedings of the {European} {Conference} on {Computer} {Vision} ({ECCV})},
	author = {Li, Ya and Tian, Xinmei and Gong, Mingming and Liu, Yajing and Liu, Tongliang and Zhang, Kun and Tao, Dacheng},
	year = {2018},
	pages = {624--639},
}

@inproceedings{li_episodic_2019,
	title = {Episodic training for domain generalization},
	booktitle = {Proceedings of the {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision}},
	author = {Li, Da and Zhang, Jianshu and Yang, Yongxin and Liu, Cong and Song, Yi-Zhe and Hospedales, Timothy M.},
	year = {2019},
	pages = {1446--1455},
}

@inproceedings{dou_domain_2019,
	title = {Domain generalization via model-agnostic learning of semantic features},
	volume = {32},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dou, Qi and Coelho de Castro, Daniel and Kamnitsas, Konstantinos and Glocker, Ben},
	year = {2019},
	pages = {6450--6461},
}

@inproceedings{balaji_metareg_2018,
	title = {Metareg: {Towards} domain generalization using meta-regularization},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Balaji, Yogesh and Sankaranarayanan, Swami and Chellappa, Rama},
	year = {2018},
	pages = {998--1008},
}

@inproceedings{li_domain_2018,
	title = {Domain generalization with adversarial feature learning},
	booktitle = {{CVPR}},
	author = {Li, Haoliang and Pan, Sinno Jialin and Wang, Shiqi and Kot, Alex C.},
	year = {2018},
	pages = {5400--5409},
}

@inproceedings{li_learning_2018,
	title = {Learning to generalize: {Meta}-learning for domain generalization},
	booktitle = {{AAAI}},
	author = {Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M.},
	year = {2018},
}

@inproceedings{guss_minerl_2019,
	title = {{MineRL}: {A} large-scale dataset of minecraft demonstrations},
	shorttitle = {Minerl},
	language = {en},
	booktitle = {{IJCAI}},
	author = {Guss, William H. and Houghton, Brandon and Topin, Nicholay and Wang, Phillip and Codel, Cayden and Veloso, Manuela and Salakhutdinov, Ruslan},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{dwork_decoupled_2018,
	title = {Decoupled classifiers for group-fair and efficient machine learning},
	isbn = {2640-3498},
	booktitle = {Conference on fairness, accountability and transparency},
	author = {Dwork, Cynthia and Immorlica, Nicole and Kalai, Adam Tauman and Leiserson, Max},
	year = {2018},
	pages = {119--133},
}

@inproceedings{li_learning_2021,
	title = {Learning subgoal representations with slow dynamics},
	booktitle = {{ICLR}},
	author = {Li, Siyuan and Zheng, Lulu and Wang, Jianhao and Zhang, Chongjie},
	year = {2021},
}

@inproceedings{wilson_multi-task_2007,
	title = {Multi-task reinforcement learning: a hierarchical bayesian approach},
	booktitle = {{ICML}},
	author = {Wilson, Aaron and Fern, Alan and Ray, Soumya and Tadepalli, Prasad},
	year = {2007},
	pages = {1015--1022},
}

@inproceedings{ren_ocean_2020,
	title = {Ocean: {Online} task inference for compositional tasks with context adaptation},
	language = {en},
	booktitle = {Conference on {Uncertainty} in {Artificial} {Intelligence} ({UAI})},
	author = {Ren, Hongyu and Zhu, Yuke and Leskovec, Jure},
	year = {2020},
}

@article{kaelbling_planning_1998,
	title = {Planning and acting in partially observable stochastic domains},
	volume = {101},
	issn = {0004-3702},
	doi = {10.1016/S0004-3702(98)00023-X},
	language = {en},
	number = {1},
	journal = {Artificial Intelligence},
	author = {Kaelbling, Leslie Pack and Littman, Michael L. and Cassandra, Anthony R.},
	year = {1998},
	keywords = {Partially observable Markov decision processes, Planning, Uncertainty},
	pages = {99--134},
}

@inproceedings{mesnard_counterfactual_2021,
	title = {Counterfactual credit assignment in model-free reinforcement learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Mesnard, Thomas and Weber, Théophane and Viola, Fabio and Thakoor, Shantanu and Saade, Alaa and Harutyunyan, Anna and Dabney, Will and Stepleton, Tom and Heess, Nicolas and Guez, Arthur and Hutter, Marcus and Buesing, Lars and Munos, Rémi},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{wulfmeier_data-efficient_2021,
	title = {Data-efficient hindsight off-policy option learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Wulfmeier, Markus and Rao, Dushyant and Hafner, Roland and Lampe, Thomas and Abdolmaleki, Abbas and Hertweck, Tim and Neunert, Michael and Tirumala, Dhruva and Siegel, Noah and Heess, Nicolas and Riedmiller, Martin},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{wang_scc_2021,
	title = {{SCC}: {An} efficient deep reinforcement learning agent mastering the game of {StarCraft} {II}},
	shorttitle = {{SCC}},
	language = {en},
	booktitle = {{ICML}},
	author = {Wang, Xiangjun and Song, Junxiao and Qi, Penghui and Peng, Peng and Tang, Zhenkun and Zhang, Wei and Li, Weimin and Pi, Xiongjun and He, Jujie and Gao, Chao and Long, Haitao and Yuan, Quan},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{igl_deep_2018,
	title = {Deep variational reinforcement learning for {POMDPs}},
	language = {en},
	booktitle = {{ICML}},
	author = {Igl, Maximilian and Zintgraf, Luisa and Le, Tuan Anh and Wood, Frank and Whiteson, Shimon},
	year = {2018},
}

@article{malik_when_2021,
	title = {When is generalizable reinforcement learning tractable?},
	language = {en},
	journal = {arXiv preprint arXiv:2101.00300},
	author = {Malik, Dhruv and Li, Yuanzhi and Ravikumar, Pradeep},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{zhang_metacure_2021,
	title = {{MetaCURE}: {Meta} reinforcement learning with empowerment-driven exploration},
	shorttitle = {Metacure},
	language = {en},
	booktitle = {{ICML}},
	author = {Zhang, Jin and Wang, Jianhao and Hu, Hao and Chen, Tong and Chen, Yingfeng and Fan, Changjie and Zhang, Chongjie},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{hu_generalizable_2021,
	title = {Generalizable episodic memory for deep reinforcement learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Hu, Hao and Ye, Jianing and Ren, Zhizhou and Zhu, Guangxiang and Zhang, Chongjie},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{sodhani_multi-task_2021,
	title = {Multi-task reinforcement learning with context-based representations},
	language = {en},
	booktitle = {{ICML}},
	author = {Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{xie_deep_2021,
	title = {Deep reinforcement learning amidst lifelong non-stationarity},
	language = {en},
	booktitle = {{ICML}},
	author = {Xie, Annie and Harrison, James and Finn, Chelsea},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{cobo_object_2013,
	title = {Object focused {Q}-learning for autonomous agents},
	isbn = {1-4503-1993-9},
	booktitle = {Proceedings of the 2013 international conference on {Autonomous} agents and multi-agent systems},
	author = {Cobo, Luis C. and Isbell, Charles L. and Thomaz, Andrea L.},
	year = {2013},
	pages = {1061--1068},
}

@inproceedings{yarats_reinforcement_2021,
	title = {Reinforcement learning with prototypical representations},
	language = {en},
	booktitle = {{ICML}},
	author = {Yarats, Denis and Fergus, Rob and Lazaric, Alessandro and Pinto, Lerrel},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{duan_risk_2021,
	title = {Risk bounds and {Rademacher} complexity in batch reinforcement learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Duan, Yaqi and Jin, Chi and Li, Zhiyuan},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{kozuno_revisiting_2021,
	title = {Revisiting {Peng}'s {Q}(\${\textbackslash}lambda\$) for modern reinforcement learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Kozuno, Tadashi and Tang, Yunhao and Rowland, Mark and Munos, Rémi and Kapturowski, Steven and Dabney, Will and Valko, Michal and Abel, David},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{cobbe_phasic_2021,
	title = {Phasic policy gradient},
	booktitle = {{ICML}},
	author = {Cobbe, Karl and Hilton, Jacob and Klimov, Oleg and Schulman, John},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{rosenbaum_routing_2018,
	title = {Routing networks: {Adaptive} selection of non-linear functions for multi-task learning},
	shorttitle = {Routing networks},
	language = {en},
	booktitle = {{ICLR}},
	author = {Rosenbaum, Clemens and Klinger, Tim and Riemer, Matthew},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@article{rosenbaum_routing_2019,
	title = {Routing networks and the challenges of modular and compositional computation},
	journal = {arXiv preprint arXiv:1904.12774},
	author = {Rosenbaum, Clemens and Cases, Ignacio and Riemer, Matthew and Klinger, Tim},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{misra_cross-stitch_2016,
	address = {Las Vegas, NV, USA},
	title = {Cross-stitch networks for multi-task learning},
	isbn = {978-1-4673-8851-1},
	doi = {10.1109/CVPR.2016.433},
	language = {en},
	booktitle = {{CVPR}},
	author = {Misra, Ishan and Shrivastava, Abhinav and Gupta, Abhinav and Hebert, Martial},
	year = {2016},
	pages = {3994--4003},
}

@inproceedings{liu_end--end_2019,
	address = {Long Beach, CA, USA},
	title = {End-to-end multi-task learning with attention},
	isbn = {978-1-72813-293-8},
	doi = {10.1109/CVPR.2019.00197},
	language = {en},
	booktitle = {{CVPR}},
	author = {Liu, Shikun and Johns, Edward and Davison, Andrew J.},
	year = {2019},
	pages = {1871--1880},
}

@inproceedings{standley_which_2020,
	title = {Which tasks should be learned together in multi-task learning?},
	author = {Standley, Trevor and Zamir, Amir and Chen, Dawn and Guibas, Leonidas and Malik, Jitendra and Savarese, Silvio},
	year = {2020},
}

@inproceedings{smith_federated_2017,
	title = {Federated multi-task learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Smith, Virginia and Chiang, Chao-Kai and Sanjabi, Maziar and Talwalkar, Ameet},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{shazeer_outrageously_2017,
	title = {Outrageously large neural networks: {The} sparsely-gated mixture-of-experts layer},
	shorttitle = {Outrageously large neural networks},
	booktitle = {{ICLR}},
	author = {Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computation and Language},
}

@article{silver_reward_2021,
	title = {Reward is enough},
	issn = {00043702},
	doi = {10.1016/j.artint.2021.103535},
	language = {en},
	journal = {Artificial Intelligence},
	author = {Silver, David and Singh, Satinder and Precup, Doina and Sutton, Richard S.},
	year = {2021},
}

@article{adams_mapping_2012,
	title = {Mapping the landscape of human-level artificial general intelligence},
	volume = {33},
	copyright = {Copyright (c)},
	issn = {2371-9621},
	doi = {10.1609/aimag.v33i1.2322},
	language = {en},
	number = {1},
	journal = {AI Magazine},
	year = {2012},
	keywords = {evaluation},
	pages = {25--42},
}

@inproceedings{alet_neural_2019,
	title = {Neural relational inference with fast modular meta-learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Alet, Ferran and Weng, Erica and Lozano-Pérez, Tomás and Kaelbling, Leslie Pack},
	year = {2019},
}

@inproceedings{al-shedivat_federated_2021,
	title = {Federated learning via posterior averaging: a new perspective and practical algorithms},
	language = {en},
	author = {Al-Shedivat, Maruan and Gillenwater, Jennifer and Xing, Eric and Rostamizadeh, Afshin},
	year = {2021},
}

@inproceedings{wei_theoretical_2021,
	title = {Theoretical analysis of self-training with deep networks on unlabeled data},
	language = {en},
	booktitle = {{ICLR}},
	author = {Wei, Colin and Shen, Kendrick and Chen, Yining and Ma, Tengyu},
	year = {2021},
}

@inproceedings{li_why_2021,
	title = {Why are convolutional nets more sample- efficient than fully-connected nets?},
	language = {en},
	booktitle = {{ICLR}},
	author = {Li, Zhiyuan and Zhang, Yi and Arora, Sanjeev},
	year = {2021},
}

@inproceedings{saha_gradient_2021,
	title = {Gradient projection memory for continual learning},
	language = {en},
	booktitle = {{ICLR}},
	author = {Saha, Gobinda and Garg, Isha and Roy, Kaushik},
	year = {2021},
}

@inproceedings{phoo_self-training_2021,
	title = {Self-training for few-shot transfer across extreme task differences},
	language = {en},
	booktitle = {{ICLR}},
	author = {Phoo, Cheng Perng and Hariharan, Bharath},
	year = {2021},
	pages = {19},
}

@inproceedings{andrychowicz_what_2021,
	title = {What matters in on-policy reinforcement learning? {A} large-scale empirical study},
	booktitle = {{ICLR}},
	author = {Andrychowicz, Marcin and Raichuk, Anton and Stańczyk, Piotr and Orsini, Manu and Girgin, Sertan and Marinier, Raphael and Hussenot, Léonard and Geist, Matthieu and Pietquin, Olivier and Michalski, Marcin and Gelly, Sylvain and Bachem, Olivier},
	year = {2021},
}

@inproceedings{thomas_bias_2014,
	title = {Bias in natural actor-critic algorithms},
	language = {en},
	booktitle = {{ICML}},
	author = {Thomas, Philip S},
	year = {2014},
}

@inproceedings{amit_discount_2020,
	title = {Discount factor as a regularizer in reinforcement learning},
	booktitle = {{ICML}},
	author = {Amit, Ron and Meir, Ron and Ciosek, Kamil},
	year = {2020},
}

@article{tessler_reward_2020,
	title = {Reward tweaking: {Maximizing} the total reward while planning for short horizons},
	shorttitle = {Reward tweaking},
	journal = {arXiv preprint arXiv:2002.03327},
	author = {Tessler, Chen and Mannor, Shie},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{chevalier-boisvert_babyai:_2019,
	title = {{BabyAI}: {A} platform to study the sample efficiency of grounded language learning},
	booktitle = {{ICLR}},
	author = {Chevalier-Boisvert, Maxime and Lahlou, Salem and Nguyen, Thien Huu and Bahdanau, Dzmitry and Willems, Lucas and Saharia, Chitwan and Bengio, Yoshua},
	year = {2019},
}

@inproceedings{vieillard_leverage_2020,
	title = {Leverage the average: {An} analysis of {KL} regularization in {RL}},
	shorttitle = {Leverage the average},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Vieillard, Nino and Kozuno, Tadashi and Scherrer, Bruno and Pietquin, Olivier and Munos, Rémi and Geist, Matthieu},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{he_single_2009,
	title = {Single image haze removal using dark channel prior},
	booktitle = {{CVPR}},
	author = {He, Kaiming and Sun, Jian and Tang, Xiaoou},
	year = {2009},
	keywords = {Pixel, Statistics},
}

@article{ralaivola_chromatic_2010,
	title = {Chromatic {PAC}-bayes bounds for non-iid data: {Applications} to ranking and stationary \${\textbackslash}beta\$-mixing processes},
	volume = {11},
	journal = {Journal of Machine Learning Research},
	author = {Ralaivola, Liva and Szafranski, Marie and Stempfel, Guillaume},
	year = {2010},
	pages = {1927--1956},
}

@inproceedings{mohri_rademacher_2008,
	title = {Rademacher complexity bounds for non-i.i.d. processes},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Mohri, Mehryar and Rostamizadeh, Afshin},
	year = {2008},
}

@article{sattler_robust_2020,
	title = {Robust and communication-efficient federated learning from non-i.i.d. data},
	volume = {31},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2019.2944481},
	number = {9},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Sattler, Felix and Wiedemann, Simon and Müller, Klaus-Robert and Samek, Wojciech},
	year = {2020},
	keywords = {Data models, Training data, Deep learning, Distributed databases, distributed learning, efficient communication, federated learning, privacy-preserving machine learning, Protocols, Servers, Training},
	pages = {3400--3413},
}

@inproceedings{jeong_communication-efficient_2018,
	title = {Communication-efficient on-device machine learning: {Federated} distillation and augmentation under non-iid private data},
	shorttitle = {Communication-efficient on-device machine learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}, 2nd {Workshop} on {Machine} {Learning} on the {Phone} and other {Consumer} {Devices} ({MLPCD2})},
	author = {Jeong, Eunjeong and Oh, Seungeun and Kim, Hyesung and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Networking and Internet Architecture},
}

@inproceedings{hsieh_non-iid_2020,
	title = {The non-{IID} data quagmire of decentralized machine learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Hsieh, Kevin and Phanishayee, Amar and Mutlu, Onur and Gibbons, Phillip B},
	year = {2020},
}

@inproceedings{li_convergence_2020,
	title = {On the convergence of fedavg on non-iid data},
	booktitle = {{ICLR}},
	author = {Li, Xiang and Huang, Kaixuan and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@article{eppe_hierarchical_2020,
	title = {Hierarchical principles of embodied reinforcement learning: {A} review},
	shorttitle = {Hierarchical principles of embodied reinforcement learning},
	journal = {arXiv preprint arXiv:2012.10147},
	author = {Eppe, Manfred and Gumbsch, Christian and Kerzel, Matthias and Nguyen, Phuong D. H. and Butz, Martin V. and Wermter, Stefan},
	year = {2020},
	keywords = {Computer Science - Artificial Intelligence},
}

@inproceedings{dong_generalization_2020,
	title = {Generalization bound of gradient descent for non-convex metric learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dong, Mingzhi and Yang, Xiaochen and Zhu, Rui and Wang, Yujiang and Xue, Jing-Hao},
	year = {2020},
}

@article{jain_non-convex_2017,
	title = {Non-convex optimization for machine learning},
	volume = {10},
	issn = {1935-8237, 1935-8245},
	doi = {10.1561/2200000058},
	language = {en},
	number = {3-4},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Jain, Prateek and Kar, Purushottam},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
	pages = {142--336},
}

@inproceedings{lee_pseudo-label_2013,
	title = {Pseudo-label: {The} simple and efficient semi-supervised learning method for deep neural networks},
	volume = {3},
	booktitle = {Workshop on challenges in representation learning, {ICML}},
	author = {Lee, Dong-Hyun},
	year = {2013},
}

@inproceedings{huang_densely_2017,
	address = {Honolulu, HI},
	title = {Densely connected convolutional networks},
	isbn = {978-1-5386-0457-1},
	doi = {10.1109/CVPR.2017.243},
	language = {en},
	booktitle = {{CVPR}},
	author = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q.},
	year = {2017},
	pages = {2261--2269},
}

@article{krizhevsky_learning_2009,
	title = {Learning multiple layers of features from tiny images},
	author = {Krizhevsky, Alex and Hinton, Geoffrey},
	year = {2009},
}

@inproceedings{hessel_multi-task_2019,
	title = {Multi-task deep reinforcement learning with popart},
	booktitle = {{AAAI}},
	author = {Hessel, Matteo and Soyer, Hubert and Espeholt, Lasse and Czarnecki, Wojciech and Schmitt, Simon and van Hasselt, Hado},
	year = {2019},
}

@inproceedings{barreto_option_2019,
	title = {The option keyboard: {Combining} skills in reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Barreto, Andre and Borsa, Diana and Hou, Shaobo and Comanici, Gheorghe and Aygün, Eser and Hamel, Philippe and Toyama, Daniel and Hunt, Jonathan and Mourad, Shibl and Silver, David and Precup, Doina},
	year = {2019},
}

@inproceedings{hansen_fast_2020,
	title = {Fast task inference with variational intrinsic successor features},
	booktitle = {{ICLR}},
	author = {Hansen, Steven and Dabney, Will and Barreto, Andre and Van de Wiele, Tom and Warde-Farley, David and Mnih, Volodymyr},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{song_deep_2016,
	address = {Las Vegas, NV, USA},
	title = {Deep metric learning via lifted structured feature embedding},
	isbn = {978-1-4673-8851-1},
	doi = {10.1109/CVPR.2016.434},
	booktitle = {{CVPR}},
	author = {Song, Hyun Oh and Xiang, Yu and Jegelka, Stefanie and Savarese, Silvio},
	year = {2016},
}

@article{zhang_system_2020,
	title = {A system hierarchy for brain-inspired computing},
	volume = {586},
	issn = {0028-0836, 1476-4687},
	doi = {10.1038/s41586-020-2782-y},
	language = {en},
	number = {7829},
	journal = {Nature},
	author = {Zhang, Youhui and Qu, Peng and Ji, Yu and Zhang, Weihao and Gao, Guangrong and Wang, Guanrui and Song, Sen and Li, Guoqi and Chen, Wenguang and Zheng, Weimin and Chen, Feng and Pei, Jing and Zhao, Rong and Zhao, Mingguo and Shi, Luping},
	year = {2020},
	pages = {378--384},
}

@article{kirkpatrick_overcoming_2017,
	title = {Overcoming catastrophic forgetting in neural networks},
	volume = {114},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.1611835114},
	language = {en},
	number = {13},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
	year = {2017},
	pages = {3521--3526},
}

@inproceedings{athalye_obfuscated_2018,
	title = {Obfuscated gradients give a false sense of security: {Circumventing} defenses to adversarial examples},
	shorttitle = {Obfuscated gradients give a false sense of security},
	language = {en},
	booktitle = {{ICML}},
	author = {Athalye, Anish and Carlini, Nicholas and Wagner, David},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
}

@inproceedings{liu_delayed_2018,
	title = {Delayed impact of fair machine learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Liu, Lydia T. and Dean, Sarah and Rolf, Esther and Simchowitz, Max and Hardt, Moritz},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{koh_understanding_2017,
	title = {Understanding black-box predictions via influence functions},
	booktitle = {{ICML}},
	author = {Koh, Pang Wei and Liang, Percy},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{de_sa_ensuring_2016,
	title = {Ensuring rapid mixing and low bias for asynchronous gibbs sampling},
	booktitle = {{ICML}},
	author = {De Sa, Christopher and Olukotun, Kunle and Ré, Christopher},
	year = {2016},
}

@inproceedings{hegde_nearly-linear_2015,
	title = {A nearly-linear time framework for graph-structured sparsity},
	language = {en},
	booktitle = {{ICML}},
	author = {Hegde, Chinmay and Indyk, Piotr and Schmidt, Ludwig},
	year = {2015},
}

@inproceedings{beygelzimer_optimal_2015,
	title = {Optimal and adaptive algorithms for online boosting},
	language = {en},
	booktitle = {{ICML}},
	author = {Beygelzimer, Alina and Kale, Satyen and Luo, Haipeng},
	year = {2015},
}

@inproceedings{tang_understanding_2014,
	title = {Understanding the limiting factors of topic modeling via  posterior contraction analysis},
	language = {en},
	booktitle = {{ICML}},
	author = {Tang, Jian and Meng, Zhaoshi and Nguyen, XuanLong and Mei, Qiaozhu and Zhang, Ming},
	year = {2014},
}

@inproceedings{ahn_bayesian_2012,
	title = {Bayesian posterior sampling via stochastic gradient fisher scoring},
	language = {en},
	booktitle = {{ICML}},
	author = {Ahn, Sungjin and Korattikara, Anoop and Welling, Max},
	year = {2012},
}

@inproceedings{livni_vanishing_2013,
	title = {Vanishing component analysis},
	language = {en},
	booktitle = {{ICML}},
	author = {Livni, Roi and Lehavi, David and Schein, Sagi and Nachlieli, Hila and Shalev-Shwartz, Shai and Globerson, Amir},
	year = {2013},
}

@inproceedings{iyer_fast_2013,
	title = {Fast semidifferential-based submodular function optimization},
	language = {en},
	booktitle = {{ICML}},
	author = {Iyer, Rishabh and Jegelka, Stefanie and Bilmes, Jeff},
	year = {2013},
}

@inproceedings{waugh_computational_2011,
	title = {Computational rationalization: {The} inverse equilibrium problem},
	language = {en},
	booktitle = {{ICML}},
	author = {Waugh, Kevin and Ziebart, Brian D and Bagnell, J Andrew},
	year = {2011},
}

@inproceedings{song_hilbert_2010,
	title = {Hilbert space embeddings of hidden markov models},
	language = {en},
	booktitle = {{ICML}},
	author = {Song, Le and Boots, Byron and Siddiqi, Sajid M and Gordon, Geoﬀrey and Smola, Alex},
	year = {2010},
}

@inproceedings{vogt_translation-invariant_2010,
	title = {The translation-invariant wishart-dirichlet process for clustering distance data},
	language = {en},
	booktitle = {{ICML}},
	author = {Vogt, Julia E and Prabhakaran, Sandhya and Fuchs, Thomas J and Roth, Volker},
	year = {2010},
}

@article{schlimmer_incremental_1986,
	title = {Incremental learning from noisy data},
	volume = {1},
	number = {3},
	journal = {Machine learning},
	author = {Schlimmer, Jeffrey C. and Granger, Richard H.},
	year = {1986},
	pages = {317--354},
}

@article{landgrebe_there_2019,
	title = {There is no artificial general intelligence},
	journal = {arXiv preprint arXiv:1906.05833},
	author = {Landgrebe, J. and Smith, B.},
	year = {2019},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@book{kurzweil_singularity_2005,
	address = {New York},
	title = {The singularity is near: {When} humans transcend biology},
	isbn = {1-101-21888-6},
	author = {Kurzweil, Ray},
	year = {2005},
}

@book{kurzweil_age_2000,
	address = {New York},
	title = {The age of spiritual machines: {When} computers exceed human intelligence},
	isbn = {0-14-028202-5},
	author = {Kurzweil, Ray},
	year = {2000},
}

@article{baum_how_2011,
	title = {How long until human-level {AI}? {Results} from an expert assessment},
	volume = {78},
	issn = {00401625},
	shorttitle = {How long until human-level {AI}?},
	doi = {10.1016/j.techfore.2010.09.006},
	language = {en},
	number = {1},
	journal = {Technological Forecasting and Social Change},
	author = {Baum, Seth D. and Goertzel, Ben and Goertzel, Ted G.},
	year = {2011},
	pages = {185--195},
}

@article{grace_when_2018,
	title = {When will {AI} exceed human performance? {Evidence} from {AI} experts},
	volume = {62},
	journal = {Journal of Artificial Intelligence Research},
	author = {Grace, Katja and Salvatier, John and Dafoe, Allan and Zhang, Baobao and Evans, Owain},
	year = {2018},
	pages = {729--754},
}

@inproceedings{widmer_effective_1993,
	address = {Berlin, Heidelberg},
	title = {Effective learning in dynamic environments by explicit context tracking},
	volume = {667},
	isbn = {978-3-540-56602-1 978-3-540-47597-2},
	doi = {10.1007/3-540-56602-3_139},
	language = {en},
	booktitle = {{ECML}},
	author = {Widmer, Gerhard and Kubat, Miroslav},
	year = {1993},
	pages = {227--243},
}

@article{harries_extracting_1998,
	title = {Extracting hidden context},
	volume = {32},
	number = {2},
	journal = {Machine Learning},
	author = {Harries, Michael Bonnell and Sammut, Claude and Horn, Kim},
	year = {1998},
	pages = {101--126},
}

@article{doya_multiple_2002,
	title = {Multiple model-based reinforcement learning},
	volume = {14},
	language = {en},
	number = {6},
	journal = {Neural Computation},
	author = {Doya, Kenji and Samejima, Kazuyuki and Katagiri, Ken-ichi and Kawato, Mitsuo},
	year = {2002},
	pages = {1347--1369},
}

@inproceedings{bottou_convergence_1994,
	title = {Convergence properties of the k-means algorithms},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bottou, Léon and Bengio, Yoshua},
	year = {1994},
}

@inproceedings{aljundi_expert_2017,
	address = {Honolulu, HI},
	title = {Expert gate: {Lifelong} learning with a network of experts},
	isbn = {978-1-5386-0457-1},
	shorttitle = {Expert gate},
	doi = {10.1109/CVPR.2017.753},
	language = {en},
	booktitle = {{CVPR}},
	author = {Aljundi, Rahaf and Chakravarty, Punarjay and Tuytelaars, Tinne},
	year = {2017},
	pages = {7120--7129},
}

@inproceedings{nagabandi_learning_2019,
	title = {Learning to adapt in dynamic, real-world environments through meta-reinforcement learning},
	booktitle = {{ICLR}},
	author = {Nagabandi, Anusha and Clavera, Ignasi and Liu, Simin and Fearing, Ronald S. and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Robotics},
}

@article{lecun_tutorial_2006,
	title = {A tutorial on energy-based learning},
	journal = {Predicting structured data},
	author = {LeCun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, M. and Huang, F.},
	year = {2006},
}

@inproceedings{zhai_deep_2016,
	title = {Deep structured energy based models for anomaly detection},
	booktitle = {{ICML}},
	author = {Zhai, Shuangfei and Cheng, Yu and Lu, Weining and Zhang, Zhongfei(Mark)},
	year = {2016},
}

@inproceedings{amos_input_2017,
	title = {Input convex neural networks},
	booktitle = {{ICML}},
	author = {Amos, Brandon and Xu, Lei and Kolter, J Zico},
	year = {2017},
}

@phdthesis{schmidhuber_evolutionary_1987,
	title = {Evolutionary principles in self-referential learning, or on learning how to learn: {The} meta-meta-... hook},
	school = {Technische Universität München},
	author = {Schmidhuber, Jürgen},
	year = {1987},
}

@inproceedings{kearns_approximate_1999,
	title = {Approximate planning in large {POMDPs} via reusable trajectories.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kearns, Michael J. and Mansour, Yishay and Ng, Andrew Y.},
	year = {1999},
}

@inproceedings{kearns_learning_1988,
	address = {New York, NY, USA},
	series = {{STOC} '88},
	title = {Learning in the presence of malicious errors},
	isbn = {978-0-89791-264-8},
	doi = {10.1145/62212.62238},
	booktitle = {Proceedings of the twentieth annual {ACM} symposium on {Theory} of computing},
	author = {Kearns, Michael and Li, Ming},
	year = {1988},
	pages = {267--280},
}

@article{clune_ai-gas_2019,
	title = {{AI}-{GAs}: {AI}-generating algorithms, an alternate paradigm for producing general artificial intelligence},
	journal = {arXiv preprint arXiv:1905.10985},
	author = {Clune, Jeff},
	year = {2019},
}

@inproceedings{berseth_smirl_2021,
	title = {Smirl: {Surprise} minimizing reinforcement learning in unstable environments},
	booktitle = {{ICLR}},
	author = {Berseth, Glen and Finn, Chelsea and Geng, Daniel and Devin, Coline and Jayaraman, Dinesh and Rhinehart, Nicholas and Levine, Sergey},
	year = {2021},
}

@inproceedings{arora_fine-grained_2019,
	title = {Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
	booktitle = {{ICML}},
	author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
	year = {2019},
}

@book{neal_bayesian_1996,
	address = {New York, NY},
	title = {Bayesian learning for neural networks},
	volume = {118},
	isbn = {978-0-387-94724-2 978-1-4612-0745-0},
	language = {en},
	author = {Neal, Radford M.},
	editor = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S.},
	year = {1996},
	doi = {10.1007/978-1-4612-0745-0},
}

@inproceedings{matthews_gaussian_2018,
	title = {Gaussian process behaviour in wide deep neural networks},
	language = {en},
	booktitle = {{ICLR}},
	author = {Matthews, Alexander G. de G. and Rowland, Mark and Hron, Jiri and Turner, Richard E. and Ghahramani, Zoubin},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{matthews_gaussian_2018-1,
	title = {Gaussian process behaviour in wide deep neural networks},
	abstract = {Whilst deep neural networks have shown great empirical success, there is still much work to be done to understand their theoretical properties. In this paper, we study the relationship between random, wide, fully connected, feedforward networks with more than one hidden layer and Gaussian processes with a recursive kernel definition. We show that, under broad conditions, as we make the architecture increasingly wide, the implied random function converges in distribution to a Gaussian process, formalising and extending existing results by Neal (1996) to deep networks. To evaluate convergence rates empirically, we use maximum mean discrepancy. We then compare finite Bayesian deep networks from the literature to Gaussian processes in terms of the key predictive quantities of interest, finding that in some cases the agreement can be very close. We discuss the desirability of Gaussian process behaviour and review non-Gaussian alternative models from the literature.},
	language = {en},
	journal = {arXiv preprint arXiv:1804.11271},
	author = {Matthews, Alexander G. de G. and Rowland, Mark and Hron, Jiri and Turner, Richard E. and Ghahramani, Zoubin},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{lee_deep_2018,
	title = {Deep neural networks as gaussian processes},
	booktitle = {{ICLR}},
	author = {Lee, Jaehoon and Bahri, Yasaman and Novak, Roman and Schoenholz, Samuel S. and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{belkin_reconciling_2018,
	title = {Reconciling modern machine learning practice and the bias-variance trade-off},
	language = {en},
	journal = {arXiv preprint arXiv:1812.11118},
	author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{belkin_reconciling_2019,
	title = {Reconciling modern machine-learning practice and the classical bias–variance trade-off},
	volume = {116},
	number = {32},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
	year = {2019},
	pages = {15849--15854},
}

@inproceedings{jacot_neural_2018,
	title = {Neural tangent kernel: {Convergence} and generalization in neural networks},
	shorttitle = {Neural tangent kernel},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clément},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Probability},
}

@article{burtini_survey_2015,
	title = {A survey of online experiment design with the stochastic multi-armed bandit},
	journal = {arXiv preprint arXiv:1510.00757},
	author = {Burtini, Giuseppe and Loeppky, Jason and Lawrence, Ramon},
	year = {2015},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{jiang_contextual_2017,
	title = {Contextual decision processes with low {Bellman} rank are {PAC}-learnable},
	booktitle = {{ICML}},
	author = {Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
	year = {2017},
}

@inproceedings{krizhevsky_imagenet_2012,
	title = {Imagenet classification with deep convolutional neural networks},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	year = {2012},
	pages = {1097--1105},
}

@article{bartlett_rademacher_2002,
	title = {Rademacher and {Gaussian} complexities: {Risk} bounds and structural results},
	volume = {3},
	journal = {Journal of Machine Learning Research},
	author = {Bartlett, Peter L. and Mendelson, Shahar},
	year = {2002},
	pages = {463--482},
}

@article{abdel-hamid_convolutional_2014,
	title = {Convolutional neural networks for speech recognition},
	volume = {22},
	issn = {2329-9290, 2329-9304},
	doi = {10.1109/TASLP.2014.2339736},
	language = {en},
	number = {10},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Abdel-Hamid, Ossama and Mohamed, Abdel-rahman and Jiang, Hui and Deng, Li and Penn, Gerald and Yu, Dong},
	year = {2014},
	pages = {1533--1545},
}

@inproceedings{graves_speech_2013,
	title = {Speech recognition with deep recurrent neural networks},
	doi = {10.1109/ICASSP.2013.6638947},
	booktitle = {{IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Graves, A. and Mohamed, A. and Hinton, G.},
	year = {2013},
	keywords = {Training, Acoustics, deep neural networks, Noise, recurrent neural networks, Recurrent neural networks, speech recognition, Speech recognition, Vectors},
}

@inproceedings{collobert_unified_2008,
	title = {A unified architecture for natural language processing: deep neural networks with multitask learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Collobert, Ronan and Weston, Jason},
	year = {2008},
}

@article{bojarski_end_2016,
	title = {End to end learning for self-driving cars},
	language = {en},
	journal = {arXiv preprint arXiv:1604.07316},
	author = {Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D. and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and Zhang, Xin and Zhao, Jake and Zieba, Karol},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{amodei_deep_2016,
	title = {Deep speech 2: {End}-to-end speech recognition in english and mandarin},
	language = {en},
	booktitle = {{ICML}},
	author = {Amodei, Dario and Ananthanarayanan, Sundaram and Anubhai, Rishita and Bai, Jingliang and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Cheng, Qiang and Chen, Guoliang and Chen, Jie and Chen, Jingdong and Chen, Zhijie and Chrzanowski, Mike and Coates, Adam and Diamos, Greg and Ding, Ke and Du, Niandong and Elsen, Erich and Engel, Jesse and Fang, Weiwei and Fan, Linxi and Fougner, Christopher and Gao, Liang and Gong, Caixia and Hannun, Awni and Han, Tony and Johannes, Lappi Vaino and Jiang, Bing and Ju, Cai and Jun, Billy and LeGresley, Patrick and Lin, Libby and Liu, Junjie and Liu, Yang and Li, Weigao and Li, Xiangang and Ma, Dongpeng and Narang, Sharan and Ng, Andrew and Ozair, Sherjil and Peng, Yiping and Prenger, Ryan and Qian, Sheng and Quan, Zongfeng and Raiman, Jonathan and Rao, Vinay and Satheesh, Sanjeev and Seetapun, David and Sengupta, Shubho and Srinet, Kavya and Sriram, Anuroop and Tang, Haiyuan and Tang, Liliang and Wang, Chong and Wang, Jidong and Wang, Kaifu and Wang, Yi and Wang, Zhijian and Wang, Zhiqian and Wu, Shuang and Wei, Likai and Xiao, Bo and Xie, Wen and Xie, Yan and Yogatama, Dani and Yuan, Bin and Zhan, Jun and Zhu, Zhenyao},
	year = {2016},
	pages = {10},
}

@inproceedings{silver_predictron_2017,
	title = {The predictron: {End}-to-end learning and planning},
	booktitle = {{ICML}},
	author = {Silver, David and van Hasselt, Hado and Hessel, Matteo and Schaul, Tom and Guez, Arthur and Harley, Tim and Dulac-Arnold, Gabriel and Reichert, David and Rabinowitz, Neil and Barreto, Andre and Degris, Thomas},
	year = {2017},
}

@inproceedings{wang_rethinking_2021,
	title = {Rethinking architecture selection in differentiable {NAS}},
	author = {Wang, Ruochen and Cheng, Minhao and Chen, Xiangning and Tang, Xiaocheng and Hsieh, Cho-Jui},
	year = {2021},
}

@inproceedings{song_score-based_2021,
	title = {Score-based generative modeling through stochastic differential equations},
	language = {en},
	author = {Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P. and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
	year = {2021},
}

@inproceedings{nitanda_optimal_2021,
	title = {Optimal rates for averaged stochastic gradient descent under neural tangent kernel regime},
	language = {en},
	author = {Nitanda, Atsushi and Suzuki, Taiji},
	year = {2021},
}

@inproceedings{richard_neural_2021,
	title = {Neural synthesis of binaural speech from mono audio},
	author = {Richard, Alexander and Markovic, Dejan and Gebru, Israel D. and Krenn, Steven and Butler, Gladstone Alexander and Torre, Fernando and Sheikh, Yaser},
	year = {2021},
}

@inproceedings{pfaff_learning_2021,
	title = {Learning mesh-based simulation with graph networks},
	author = {Pfaff, Tobias and Fortunato, Meire and Sanchez-Gonzalez, Alvaro and Battaglia, Peter},
	year = {2021},
}

@inproceedings{gemp_eigengame_2021,
	title = {{EigenGame}: {PCA} as a nash equilibrium},
	shorttitle = {Eigengame},
	language = {en},
	author = {Gemp, Ian and McWilliams, Brian and Vernade, Claire and Graepel, Thore},
	year = {2021},
}

@inproceedings{zhang_beyond_2021,
	title = {Beyond fully-connected layers with quaternions: {Parameterization} of hypercomplex multiplications with \$1/n\$ parameters},
	shorttitle = {Beyond fully-connected layers with quaternions},
	author = {Zhang, Aston and Tay, Yi and Zhang, Shuai and Chan, Alvin and Luu, Anh Tuan and Hui, Siu and Fu, Jie},
	year = {2021},
}

@inproceedings{arakelyan_complex_2021,
	title = {Complex query answering with neural link predictors},
	author = {Arakelyan, Erik and Daza, Daniel and Minervini, Pasquale and Cochez, Michael},
	year = {2021},
}

@article{wang_paired_2019,
	title = {Paired open-ended trailblazer (poet): {Endlessly} generating increasingly complex and diverse learning environments and their solutions},
	shorttitle = {Paired open-ended trailblazer (poet)},
	journal = {arXiv preprint arXiv:1901.01753},
	author = {Wang, Rui and Lehman, Joel and Clune, Jeff and Stanley, Kenneth O.},
	year = {2019},
	keywords = {Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{yao_probabilistic_1977,
	title = {Probabilistic computations: {Toward} a unified measure of complexity},
	isbn = {0272-5428},
	booktitle = {18th {Annual} {Symposium} on {Foundations} of {Computer} {Science} (sfcs 1977)},
	author = {Yao, Andrew Chi-Chin},
	year = {1977},
	pages = {222--227},
}

@inproceedings{du_is_2020,
	title = {Is a good representation sufficient for sample efficient reinforcement learning?},
	booktitle = {{ICLR}},
	author = {Du, Simon S. and Kakade, Sham M. and Wang, Ruosong and Yang, Lin F.},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Mathematics - Optimization and Control},
}

@inproceedings{francois-lavet_combined_2019,
	title = {Combined reinforcement learning via abstract representations},
	booktitle = {{AAAI}},
	author = {François-Lavet, Vincent and Bengio, Yoshua and Precup, Doina and Pineau, Joelle},
	year = {2019},
}

@article{taylor_transfer_2009,
	title = {Transfer learning for reinforcement learning domains: {A} survey},
	volume = {10},
	journal = {Journal of Machine Learning Research},
	author = {Taylor, Matthew E and Stone, Peter},
	year = {2009},
	pages = {1633--1685},
}

@article{pan_survey_2010,
	title = {A survey on transfer learning},
	volume = {22},
	issn = {1041-4347},
	doi = {10.1109/TKDE.2009.191},
	language = {en},
	number = {10},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Pan, Sinno Jialin and Yang, Qiang},
	year = {2010},
	pages = {1345--1359},
}

@article{schweighofer_meta-learning_2003,
	title = {Meta-learning in reinforcement learning},
	volume = {16},
	number = {1},
	journal = {Neural Networks},
	author = {Schweighofer, Nicolas and Doya, Kenji},
	year = {2003},
	pages = {5--9},
}

@article{yang_deep_2016,
	title = {Deep multi-task representation learning: {A} tensor factorisation approach},
	shorttitle = {Deep multi-task representation learning},
	language = {en},
	journal = {arXiv preprint arXiv:1605.06391},
	author = {Yang, Yongxin and Hospedales, Timothy},
	year = {2016},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{yang_deep_2017,
	title = {Deep multi-task representation learning: {A} tensor factorisation approach},
	shorttitle = {Deep multi-task representation learning},
	booktitle = {{ICLR}},
	author = {Yang, Yongxin and Hospedales, Timothy},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{rajeswaran_meta-learning_2019,
	title = {Meta-learning with implicit gradients},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham M. and Levine, Sergey},
	year = {2019},
}

@inproceedings{grant_recasting_2018,
	title = {Recasting gradient-based meta-learning as hierarchical bayes},
	booktitle = {{ICLR}},
	author = {Grant, Erin and Finn, Chelsea and Levine, Sergey and Darrell, Trevor and Griffiths, Thomas},
	year = {2018},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{edwards_towards_2017,
	title = {Towards a neural statistician},
	booktitle = {{ICLR}},
	author = {Edwards, Harrison and Storkey, Amos},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{blei_latent_2003,
	title = {Latent {Dirichlet} allocation},
	volume = {3},
	journal = {Journal of Machine Learning Research},
	author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
	year = {2003},
	pages = {993--1022},
}

@inproceedings{saul_exploiting_1996,
	title = {Exploiting tractable substructures in intractable networks},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Saul, Lawrence K. and Jordan, Michael I.},
	year = {1996},
}

@article{dulac-arnold_deep_2015,
	title = {Deep reinforcement learning in large discrete action spaces},
	journal = {arXiv arXiv:1512.07679},
	author = {Dulac-Arnold, Gabriel and Evans, Richard and van Hasselt, Hado and Sunehag, Peter and Lillicrap, Timothy and Hunt, Jonathan and Mann, Timothy and Weber, Theophane and Degris, Thomas and Coppin, Ben},
	year = {2015},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{yang_unified_2015,
	title = {A unified perspective on multi-domain and multi-task learning},
	booktitle = {{ICLR}},
	author = {Yang, Yongxin and Hospedales, Timothy M.},
	year = {2015},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{yanwei_fu_learning_2014,
	title = {Learning multimodal latent attributes},
	volume = {36},
	issn = {0162-8828, 2160-9292},
	doi = {10.1109/TPAMI.2013.128},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {{Yanwei Fu} and Hospedales, Timothy M. and {Tao Xiang} and {Shaogang Gong}},
	year = {2014},
	pages = {303--316},
}

@article{wang_global_2020,
	title = {Global convergence and generalization bound of gradient-based meta-learning with deep neural nets},
	language = {en},
	journal = {arXiv preprint arXiv:2006.14606},
	author = {Wang, Haoxiang and Sun, Ruoyu and Li, Bo},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{vanschoren_meta-learning_2018,
	title = {Meta-learning: {A} survey},
	shorttitle = {Meta-learning},
	journal = {arXiv preprint arXiv:1810.03548},
	author = {Vanschoren, Joaquin},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{ravi_optimization_2017,
	title = {Optimization as a model for few-shot learning},
	booktitle = {{ICLR}},
	author = {Ravi, Sachin and Larochelle, Hugo},
	year = {2017},
}

@inproceedings{husken_fast_2000,
	address = {Como, Italy},
	title = {Fast learning for problem classes using knowledge based network initialization},
	booktitle = {International {Joint} {Conference} on {Neural} {Networks}},
	author = {Husken, Michael and Goerick, Christian},
	year = {2000},
}

@article{kearns_efficient_1994,
	title = {Efficient distribution-free learning of probabilistic concepts},
	volume = {48},
	number = {3},
	journal = {Journal of Computer and System Sciences},
	author = {Kearns, Michael J. and Schapire, Robert E.},
	year = {1994},
	pages = {464--497},
}

@inproceedings{kaufmann_adaptive_2021,
	title = {Adaptive reward-free exploration},
	booktitle = {International {Conference} on {Algorithmic} {Learning} {Theory}},
	author = {Kaufmann, Emilie and Ménard, Pierre and Domingues, Omar Darwiche and Jonsson, Anders and Leurent, Edouard and Valko, Michal},
	year = {2021},
}

@inproceedings{jin_reward-free_2020,
	title = {Reward-free exploration for reinforcement learning},
	booktitle = {{ICML}},
	author = {Jin, Chi and Krishnamurthy, Akshay and Simchowitz, Max and Yu, Tiancheng},
	year = {2020},
}

@article{zeno_task_2018,
	title = {Task agnostic continual learning using online variational bayes},
	journal = {arXiv preprint arXiv:1803.10123},
	author = {Zeno, Chen and Golan, Itay and Hoffer, Elad and Soudry, Daniel},
	year = {2018},
}

@inproceedings{zhang_task-agnostic_2020,
	title = {Task-agnostic exploration in reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhang, Xuezhou and Ma, Yuzhe and Singla, Adish},
	year = {2020},
}

@phdthesis{kakade_sample_2003,
	title = {On the sample complexity of reinforcement learning},
	school = {UCL (University College London)},
	author = {Kakade, Sham Machandranath},
	year = {2003},
}

@inproceedings{li_towards_2006,
	title = {Towards a unified theory of state abstraction for {MDPs}},
	booktitle = {International {Symposium} on {Artificial} {Intelligence} and {Mathematics}},
	author = {Li, Lihong and Walsh, Thomas J and Littman, Michael L},
	year = {2006},
}

@inproceedings{abel_state_2018,
	title = {State abstractions for lifelong reinforcement learning},
	booktitle = {{ICML}},
	author = {Abel, David and Arumugam, Dilip and Lehnert, Lucas and Littman, Michael L},
	year = {2018},
}

@inproceedings{osa_hierarchical_2019,
	title = {Hierarchical reinforcement learning via advantage-weighted information maximization},
	booktitle = {{ICLR}},
	author = {Osa, Takayuki and Tangkaratt, Voot and Sugiyama, Masashi},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{han_dynamic_2021,
	title = {Dynamic neural networks: {A} survey},
	shorttitle = {Dynamic neural networks},
	language = {en},
	journal = {arXiv preprint arXiv:2102.04906},
	author = {Han, Yizeng and Huang, Gao and Song, Shiji and Yang, Le and Wang, Honghui and Wang, Yulin},
	year = {2021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@incollection{koltchinskii_rademacher_2000,
	title = {Rademacher processes and bounding the risk of function learning},
	booktitle = {High dimensional probability {II}},
	author = {Koltchinskii, Vladimir and Panchenko, Dmitriy},
	year = {2000},
	pages = {443--457},
}

@article{koltchinskii_empirical_2002,
	title = {Empirical margin distributions and bounding the generalization error of combined classifiers},
	volume = {30},
	number = {1},
	journal = {Annals of statistics},
	author = {Koltchinskii, Vladimir and Panchenko, Dmitry},
	year = {2002},
	pages = {1--50},
}

@article{koltchinskii_rademacher_2001,
	title = {Rademacher penalties and structural risk minimization},
	volume = {47},
	number = {5},
	journal = {IEEE Transactions on Information Theory},
	author = {Koltchinskii, Vladimir},
	year = {2001},
	pages = {1902--1914},
}

@article{bartlett_model_2002,
	title = {Model selection and error estimation},
	volume = {48},
	issn = {1556-5068},
	doi = {10.2139/ssrn.248567},
	journal = {Machine Learning},
	author = {Bartlett, Peter L. and Boucheron, Stephane and Lugosi, Gábor},
	year = {2002},
	pages = {85--113},
}

@article{vapnik_uniform_1971,
	title = {On the uniform convergence of relative frequencies of events to their probabilities},
	volume = {16},
	number = {2},
	journal = {Theory of Probability and its Applications},
	author = {Vapnik, V. N. and Chervonenkis, A. Ya},
	year = {1971},
	pages = {264--280},
}

@article{ghadimi_stochastic_2013,
	title = {Stochastic first- and zeroth-order methods for nonconvex stochastic programming},
	volume = {23},
	number = {4},
	journal = {SIAM Journal on Optimization},
	author = {Ghadimi, Saeed and Lan, Guanghui},
	year = {2013},
	pages = {2341--2368},
}

@inproceedings{reddi_stochastic_2016,
	title = {Stochastic variance reduction for nonconvex optimization},
	booktitle = {{ICML}},
	author = {Reddi, Sashank J and Hefny, Ahmed and Sra, Suvrit and Poczos, Barnabas and Smola, Alex and Org, Smola},
	year = {2016},
}

@inproceedings{zhou_stochastic_2018,
	title = {Stochastic nested variance reduction for nonconvex optimization},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhou, Dongruo and Xu, Pan and Gu, Quanquan},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@inproceedings{fang_spider_2018,
	title = {Spider: {Near}-optimal non-convex optimization via stochastic path integrated differential estimator},
	shorttitle = {Spider},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@inproceedings{xu_global_2018,
	title = {Global convergence of langevin dynamics based algorithms for nonconvex optimization},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Xu, Pan and Chen, Jinghui and Zou, Difan and Gu, Quanquan},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@inproceedings{xie_diffusion_2021,
	title = {A diffusion theory for deep learning dynamics: {Stochastic} gradient descent exponentially favors flat minima},
	booktitle = {{ICLR}},
	author = {Xie, Zeke and Sato, Issei and Sugiyama, Masashi},
	year = {2021},
}

@book{mohri_foundations_2018,
	edition = {second edition},
	title = {Foundations of machine learning},
	isbn = {0-262-35136-6},
	author = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
	year = {2018},
}

@inproceedings{jang_categorical_2017,
	title = {Categorical reparameterization with gumbel-softmax},
	booktitle = {{ICLR}},
	author = {Jang, Eric and Gu, Shixiang and Poole, Ben},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{allen-zhu_convergence_2019,
	title = {On the convergence rate of training recurrent neural networks},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control, Computer Science - Data Structures and Algorithms},
}

@article{ruder_overview_2017,
	title = {An overview of gradient descent optimization algorithms},
	journal = {arXiv preprint arXiv:1609.04747},
	author = {Ruder, Sebastian},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@article{pei_towards_2019,
	title = {Towards artificial general intelligence with hybrid {Tianjic} chip architecture},
	volume = {572},
	issn = {0028-0836, 1476-4687},
	doi = {10.1038/s41586-019-1424-8},
	language = {en},
	number = {7767},
	journal = {Nature},
	author = {Pei, Jing and Deng, Lei and Song, Sen and Zhao, Mingguo and Zhang, Youhui and Wu, Shuang and Wang, Guanrui and Zou, Zhe and Wu, Zhenzhi and He, Wei and Chen, Feng and Deng, Ning and Wu, Si and Wang, Yu and Wu, Yujie and Yang, Zheyu and Ma, Cheng and Li, Guoqi and Han, Wentao and Li, Huanglong and Wu, Huaqiang and Zhao, Rong and Xie, Yuan and Shi, Luping},
	year = {2019},
	pages = {106--111},
}

@article{xue_multi-task_2007,
	title = {Multi-task learning for classification with dirichlet process priors},
	volume = {8},
	journal = {Journal of Machine Learning Research},
	author = {Xue, Ya and Liao, Xuejun and Carin, Lawrence and Krishnapuram, Balaji},
	year = {2007},
	pages = {35--63},
}

@article{bakker_task_2003,
	title = {Task clustering and gating for bayesian multitask learning},
	volume = {4},
	language = {en},
	journal = {Journal of Machine Learning Research},
	author = {Bakker, Bart and Heskes, Tom},
	year = {2003},
	pages = {83--99},
}

@inproceedings{allen-zhu_convergence_2019-1,
	title = {A convergence theory for deep learning via over-parameterization},
	booktitle = {{ICML}},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
	year = {2019},
}

@inproceedings{zhang_facial_2014,
	address = {Cham},
	title = {Facial landmark detection by deep multi-task learning},
	volume = {8694},
	doi = {10.1007/978-3-319-10599-4_7},
	booktitle = {{ECCV}},
	author = {Zhang, Zhanpeng and Luo, Ping and Loy, Chen Change and Tang, Xiaoou},
	year = {2014},
	pages = {94--108},
}

@inproceedings{deng_what_2010,
	address = {Berlin, Heidelberg},
	title = {What does classifying more than 10,000 image categories tell us?},
	volume = {6315},
	doi = {10.1007/978-3-642-15555-0_6},
	booktitle = {{ECCV}},
	author = {Deng, Jia and Berg, Alexander C. and Li, Kai and Fei-Fei, Li},
	year = {2010},
	pages = {71--84},
}

@inproceedings{recht_imagenet_2019,
	title = {Do imagenet classifiers generalize to imagenet?},
	booktitle = {{ICML}},
	author = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
	year = {2019},
}

@inproceedings{deng_imagenet:_2009,
	title = {Imagenet: {A} large-scale hierarchical image database},
	isbn = {1-4244-3992-2},
	booktitle = {{CVPR}},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	year = {2009},
	pages = {248--255},
}

@inproceedings{you_imagenet_2018,
	title = {Imagenet training in minutes},
	booktitle = {International {Conference} on {Parallel} {Processing}},
	author = {You, Yang and Zhang, Zhao and Hsieh, Cho-Jui and Demmel, James and Keutzer, Kurt},
	year = {2018},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{russakovsky_imagenet_2015,
	title = {Imagenet large scale visual recognition challenge},
	volume = {115},
	number = {3},
	journal = {International journal of computer vision},
	author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael},
	year = {2015},
	pages = {211--252},
}

@inproceedings{lin_rd2_2020,
	title = {{RD2}: {Reward} decomposition with representation disentanglement},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lin, Zichuan and Qin, Tao and Yang, Derek and Yang, Guangwen and Zhao, Li and Liu, Tieyan},
	year = {2020},
}

@article{bottou_optimization_2018,
	title = {Optimization methods for large-scale machine learning},
	journal = {arXiv preprint arXiv:1606.04838},
	author = {Bottou, Léon and Curtis, Frank E. and Nocedal, Jorge},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@article{arjevani_lower_2019,
	title = {Lower bounds for non-convex stochastic optimization},
	language = {en},
	journal = {arXiv preprint arXiv:1912.02365},
	author = {Arjevani, Yossi and Carmon, Yair and Duchi, John C. and Foster, Dylan J. and Srebro, Nathan and Woodworth, Blake},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control, Computer Science - Information Theory},
}

@article{srivastava_dropout:_2014,
	title = {Dropout: {A} simple way to prevent neural networks from overfitting},
	volume = {15},
	number = {1},
	journal = {Journal of Machine Learning Research},
	author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	year = {2014},
	pages = {1929--1958},
}

@article{maurer_bounds_2006,
	title = {Bounds for linear multi-task learning},
	volume = {7},
	journal = {Journal of Machine Learning Research},
	author = {Maurer, Andreas},
	year = {2006},
	pages = {117--139},
}

@inproceedings{liu_deepfashion_2016,
	address = {Las Vegas, NV, USA},
	title = {Deepfashion: {Powering} robust clothes recognition and retrieval with rich annotations},
	isbn = {978-1-4673-8851-1},
	shorttitle = {Deepfashion},
	doi = {10.1109/CVPR.2016.124},
	booktitle = {{CVPR}},
	author = {Liu, Ziwei and Luo, Ping and Qiu, Shi and Wang, Xiaogang and Tang, Xiaoou},
	year = {2016},
	pages = {1096--1104},
}

@article{vilalta_perspective_2002,
	title = {A perspective view and survey of meta-learning},
	volume = {18},
	number = {2},
	journal = {Artificial Intelligence Review},
	author = {Vilalta, Ricardo and Drissi, Youssef},
	year = {2002},
	pages = {77--95},
}

@book{thrun_learning_1998,
	address = {Boston, MA},
	title = {Learning to learn},
	isbn = {978-1-4613-7527-2 978-1-4615-5529-2},
	language = {en},
	editor = {Thrun, Sebastian and Pratt, Lorien},
	year = {1998},
	doi = {10.1007/978-1-4615-5529-2},
}

@inproceedings{zahavy_discovering_2021,
	title = {Discovering a set of policies for the worst case reward},
	booktitle = {{ICLR}},
	author = {Zahavy, Tom and Barreto, Andre and Mankowitz, Daniel J. and Hou, Shaobo and O'Donoghue, Brendan and Kemaev, Iurii and Singh, Satinder},
	year = {2021},
}

@inproceedings{tang_discovering_2021,
	title = {Discovering diverse multi-agent strategic behavior via reward randomization},
	booktitle = {{ICLR}},
	author = {Tang, Zhenggang and Yu, Chao and Chen, Boyuan and Xu, Huazhe and Wang, Xiaolong and Fang, Fei and Du, Simon Shaolei and Wang, Yu and Wu, Yi},
	year = {2021},
}

@inproceedings{gulrajani_improved_2017,
	title = {Improved training of {Wasserstein} {GANs}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{karras_progressive_2018,
	title = {Progressive growing of {GANs} for improved quality, stability, and variation},
	booktitle = {{ICLR}},
	author = {Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
	year = {2018},
}

@inproceedings{salimans_improved_2016,
	title = {Improved techniques for training {GANs}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
	year = {2016},
	pages = {2234--2242},
}

@inproceedings{arjovsky_wasserstein_2017,
	title = {Wasserstein generative adversarial networks},
	booktitle = {{ICML}},
	author = {Arjovsky, Martin and Chintala, Soumith and Bottou, Leon},
	year = {2017},
}

@inproceedings{zhou_lipschitz_2019,
	title = {Lipschitz generative adversarial nets},
	booktitle = {{ICML}},
	author = {Zhou, Zhiming and Liang, Jiadong and Song, Yuxuan and Yu, Lantao and Wang, Hongwei and Zhang, Weinan and Yu, Yong and Zhang, Zhihua},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{balan_lipschitz_2017,
	title = {Lipschitz properties for deep convolutional networks},
	journal = {arXiv preprint arXiv:1701.05217},
	author = {Balan, Radu and Singh, Maneesh and Zou, Dongmian},
	year = {2017},
	keywords = {Computer Science - Machine Learning, 62M45, I.2.6, Mathematics - Functional Analysis},
}

@article{gouk_regularisation_2021,
	title = {Regularisation of neural networks by enforcing {Lipschitz} continuity},
	volume = {110},
	issn = {0885-6125, 1573-0565},
	doi = {10.1007/s10994-020-05929-w},
	language = {en},
	number = {2},
	journal = {Machine Learning},
	author = {Gouk, Henry and Frank, Eibe and Pfahringer, Bernhard and Cree, Michael J.},
	year = {2021},
	pages = {393--416},
}

@inproceedings{anil_sorting_2019,
	title = {Sorting out {Lipschitz} function approximation},
	booktitle = {{ICML}},
	author = {Anil, Cem and Lucas, James and Grosse, Roger},
	year = {2019},
}

@inproceedings{asadi_lipschitz_2018,
	title = {Lipschitz continuity in model-based reinforcement learning},
	booktitle = {{ICML}},
	author = {Asadi, Kavosh and Misra, Dipendra and Littman, Michael L},
	year = {2018},
}

@article{abbe_provable_2018,
	title = {Provable limitations of deep learning},
	journal = {arXiv preprint arXiv:1812.06369},
	author = {Abbe, Emmanuel and Sandon, Colin},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computational Complexity, Computer Science - Information Theory},
}

@article{kearns_toward_1994,
	title = {Toward efficient agnostic learning},
	volume = {17},
	journal = {Machine Learning},
	author = {Kearns, Michael J and Schapire, Robert E and Sellie, Linda M},
	year = {1994},
	pages = {115--141},
}

@inproceedings{maurer_empirical_2009,
	title = {Empirical bernstein bounds and sample variance penalization},
	language = {en},
	booktitle = {{COLT}},
	author = {Maurer, Andreas and Pontil, Massimiliano},
	year = {2009},
	keywords = {Statistics - Machine Learning},
}

@inproceedings{peng_solving_2021,
	title = {Solving sparse linear systems faster than matrix multiplication},
	booktitle = {Proceedings of the 2021 {ACM}-{SIAM} {Symposium} on {Discrete} {Algorithms} ({SODA})},
	author = {Peng, Richard and Vempala, Santosh},
	year = {2021},
	pages = {504--521},
}

@inproceedings{namkoong_variance-based_2017,
	title = {Variance-based regularization with convex objectives},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Namkoong, Hongseok and Duchi, John C.},
	year = {2017},
}

@article{duchi_variance-based_2018,
	title = {Variance-based regularization with convex objectives},
	volume = {19},
	journal = {Journal of Machine Learning Research},
	author = {Duchi, John C. and Namkoong, Hongseok},
	year = {2018},
	pages = {1--55},
}

@article{maurer_benefit_2016,
	title = {The benefit of multitask representation learning},
	volume = {17},
	number = {1},
	journal = {Journal of Machine Learning Research},
	author = {Maurer, Andreas and Pontil, Massimiliano and Romera-Paredes, Bernardino},
	year = {2016},
	pages = {2853--2884},
}

@inproceedings{celli_no-regret_2020,
	title = {No-regret learning dynamics for extensive-form correlated equilibrium},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Celli, Andrea and Marchesi, Alberto and Farina, Gabriele and Gatti, Nicola},
	year = {2020},
}

@inproceedings{cho_learning_2014,
	title = {Learning phrase representations using rnn encoder-decoder for statistical machine translation},
	language = {en},
	booktitle = {{EMNLP}},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	year = {2014},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computation and Language},
}

@inproceedings{bahdanau_neural_2015,
	title = {Neural machine translation by jointly learning to align and translate},
	booktitle = {{ICLR}},
	author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	year = {2015},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computation and Language},
}

@article{cho_properties_2014,
	title = {On the properties of neural machine translation: {Encoder}-decoder approaches},
	shorttitle = {On the properties of neural machine translation},
	language = {en},
	journal = {arXiv preprint arXiv:1409.1259},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
	year = {2014},
	keywords = {Statistics - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{liang_geoman_2018,
	title = {Geoman: {Multi}-level attention networks for geo-sensory time series prediction.},
	booktitle = {{IJCAI}},
	author = {Liang, Yuxuan and Ke, Songyu and Zhang, Junbo and Yi, Xiuwen and Zheng, Yu},
	year = {2018},
	pages = {3428--3434},
}

@inproceedings{zheng_forecasting_2015,
	title = {Forecasting fine-grained air quality based on big data},
	booktitle = {Proceedings of the 21th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	author = {Zheng, Yu and Yi, Xiuwen and Li, Ming and Li, Ruiyuan and Shan, Zhangqing and Chang, Eric and Li, Tianrui},
	year = {2015},
	pages = {2267--2276},
}

@inproceedings{perez_deep_2019,
	title = {Deep learning generalizes because the parameter-function map is biased towards simple functions},
	booktitle = {{ICLR}},
	author = {Pérez, Guillermo Valle and Louis, Ard A and Camargo, Chico Q},
	year = {2019},
}

@inproceedings{sohn_meta_2020,
	title = {Meta reinforcement learning with autonomous inference of subtask dependencies},
	booktitle = {{ICLR}},
	author = {Sohn, Sungryull and Woo, Hyunjae and Choi, Jongwook and Lee, Honglak},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{hospedales_meta-learning_2020,
	title = {Meta-learning in neural networks: {A} survey},
	shorttitle = {Meta-learning in neural networks},
	journal = {arXiv preprint arXiv:2004.05439},
	author = {Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{bochkovskiy_yolov4_2020,
	title = {Yolov4: {Optimal} speed and accuracy of object detection},
	shorttitle = {Yolov4},
	journal = {arXiv preprint arXiv:2004.10934},
	author = {Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
	year = {2020},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@inproceedings{lin_focal_2017,
	title = {Focal {Loss} for {Dense} {Object} {Detection}},
	booktitle = {{ICCV}},
	author = {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár, Piotr},
	year = {2017},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{redmon_you_2016,
	title = {You only look once: {Unified}, real-time object detection},
	shorttitle = {You only look once},
	booktitle = {{CVPR}},
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	year = {2016},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{liu_ssd_2016,
	title = {Ssd: {Single} shot multibox detector},
	volume = {9905},
	shorttitle = {Ssd},
	doi = {10.1007/978-3-319-46448-0_2},
	language = {en},
	booktitle = {{ECCV}},
	author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
	year = {2016},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {21--37},
}

@inproceedings{redmon_yolo9000_2017,
	title = {Yolo9000: {Better}, faster, stronger},
	shorttitle = {Yolo9000},
	booktitle = {{CVPR}},
	author = {Redmon, Joseph and Farhadi, Ali},
	year = {2017},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{ren_faster_2017,
	title = {Faster {R}-{CNN}: {Towards} real-time object detection with region proposal networks},
	volume = {39},
	issn = {0162-8828, 2160-9292, 1939-3539},
	doi = {10.1109/TPAMI.2016.2577031},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	year = {2017},
	keywords = {Training, attention mechanisms, COCO 2015 competitions, Convolutional codes, convolutional neural network, deep VGG-16 model, Detectors, faster-R-CNN, Feature extraction, full-image convolutional features, GPU, graphics processing units, high-quality region proposals, ILSVRC, MS COCO datasets, neural nets, object detection, Object detection, object detection accuracy, PASCAL VOC 2007, PASCAL VOC 2012, Proposals, real-time object detection, region proposal, region proposal networks, RPN, Search problems},
	pages = {1137--1149},
}

@inproceedings{girshick_fast_2015,
	title = {Fast {R}-{CNN}},
	language = {en},
	booktitle = {{ICCV}},
	author = {Girshick, Ross},
	year = {2015},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{zahavy_learn_2018,
	title = {Learn what not to learn: {Action} elimination with deep reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zahavy, Tom and Haroush, Matan and Merlis, Nadav and Mankowitz, Daniel J and Mannor, Shie},
	year = {2018},
	pages = {3566--3577},
}

@inproceedings{xia_dual_2017,
	title = {Dual supervised learning},
	booktitle = {{ICML}},
	author = {Xia, Yingce and Qin, Tao and Chen, Wei and Bian, Jiang and Yu, Nenghai and Liu, Tie-Yan},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

	volume = {1},
	number = {1},
	journal = {Numerische mathematik},
	author = {Dijkstra, Edsger W.},
	year = {1959},
	pages = {269--271},
}

@book{kruskal_multidimensional_1978,
	title = {Multidimensional scaling},
	isbn = {0-8039-0940-3},
	author = {Kruskal, Joseph B.},
	year = {1978},
}

@article{guo_monocular_2008,
	title = {Monocular {3D} tracking of articulated human motion in silhouette and pose manifolds},
	volume = {2008},
	journal = {EURASIP journal on Image and Video Processing},
	author = {Guo, Feng and Qian, Gang},
	year = {2008},
	pages = {1--18},
}

@inproceedings{guo_3d_2007,
	title = {{3D} human motion tracking using manifold learning},
	volume = {1},
	isbn = {1-4244-1436-9},
	booktitle = {2007 {IEEE} {International} {Conference} on {Image} {Processing}},
	author = {Guo, Feng and Qian, Gang},
	year = {2007},
	pages = {I--357--I--360},
}

@article{xu_manifold-based_2016,
	title = {Manifold-based reinforcement learning via locally linear reconstruction},
	volume = {28},
	number = {4},
	journal = {IEEE transactions on neural networks and learning systems},
	author = {Xu, Xin and Huang, Zhenhua and Zuo, Lei and He, Haibo},
	year = {2016},
	pages = {934--947},
}

@inproceedings{bush_manifold_2009,
	title = {Manifold embeddings for model-based reinforcement learning under partial observability},
	booktitle = {Advances in neural information processing systems},
	author = {Bush, Keith and Pineau, Joelle},
	year = {2009},
	pages = {189--197},
}

@article{hua_local_2012,
	title = {Local similarity and diversity preserving discriminant projection for face and handwriting digits recognition},
	volume = {86},
	journal = {Neurocomputing},
	author = {Hua, Qiang and Bai, Lijie and Wang, Xizhao and Liu, Yuchao},
	year = {2012},
	pages = {150--157},
}

@article{li_locally_2008,
	title = {Locally linear discriminant embedding: {An} efficient method for face recognition},
	volume = {41},
	number = {12},
	journal = {Pattern Recognition},
	author = {Li, Bo and Zheng, Chun-Hou and Huang, De-Shuang},
	year = {2008},
	pages = {3813--3821},
}

@article{zhang_principal_2004,
	title = {Principal manifolds and nonlinear dimensionality reduction via tangent space alignment},
	volume = {26},
	number = {1},
	journal = {SIAM journal on scientific computing},
	author = {Zhang, Zhenyue and Zha, Hongyuan},
	year = {2004},
	pages = {313--338},
}

@article{belkin_laplacian_2003,
	title = {Laplacian eigenmaps for dimensionality reduction and data representation},
	volume = {15},
	number = {6},
	journal = {Neural computation},
	author = {Belkin, Mikhail and Niyogi, Partha},
	year = {2003},
	pages = {1373--1396},
}

@article{seung_manifold_2000,
	title = {The manifold ways of perception},
	volume = {290},
	number = {5500},
	journal = {Science},
	author = {Seung, H. Sebastian and Lee, Daniel D.},
	year = {2000},
	pages = {2268--2269},
}

@article{tenenbaum_global_2000,
	title = {A global geometric framework for nonlinear dimensionality reduction},
	volume = {290},
	number = {5500},
	journal = {Science},
	author = {Tenenbaum, Joshua B. and De Silva, Vin and Langford, John C.},
	year = {2000},
	pages = {2319--2323},
}

@inproceedings{mika_fisher_1999,
	title = {Fisher discriminant analysis with kernels},
	isbn = {0-7803-5673-X},
	booktitle = {Neural networks for signal processing {IX}: {Proceedings} of the 1999 {IEEE} signal processing society workshop (cat. no. 98th8468)},
	author = {Mika, Sebastian and Ratsch, Gunnar and Weston, Jason and Scholkopf, Bernhard and Mullers, Klaus-Robert},
	year = {1999},
	pages = {41--48},
}

@article{comon_independent_1994,
	title = {Independent component analysis, a new concept?},
	volume = {36},
	number = {3},
	journal = {Signal processing},
	author = {Comon, Pierre},
	year = {1994},
	pages = {287--314},
}

@article{wold_principal_1987,
	title = {Principal component analysis},
	volume = {2},
	number = {1-3},
	journal = {Chemometrics and intelligent laboratory systems},
	author = {Wold, Svante and Esbensen, Kim and Geladi, Paul},
	year = {1987},
	pages = {37--52},
}

@article{french_catastrophic_1999,
	title = {Catastrophic forgetting in connectionist networks},
	volume = {3},
	number = {4},
	journal = {Trends in cognitive sciences},
	author = {French, Robert M.},
	year = {1999},
	pages = {128--135},
}

@inproceedings{eysenbach_search_2019,
	title = {Search on the replay buffer: {Bridging} planning and reinforcement learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Eysenbach, Ben and Salakhutdinov, Russ R and Levine, Sergey},
	year = {2019},
	pages = {15220--15231},
}

@inproceedings{du_gradient_2019,
	title = {Gradient descent finds global minima of deep neural networks},
	booktitle = {{ICML}},
	author = {Du, Simon S. and Lee, Jason D. and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	year = {2019},
}

@article{florensa_self-supervised_2019,
	title = {Self-supervised learning of image embedding for continuous control},
	journal = {arXiv preprint arXiv:1901.00943},
	author = {Florensa, Carlos and Degrave, Jonas and Heess, Nicolas and Springenberg, Jost Tobias and Riedmiller, Martin},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics},
}

@inproceedings{hartikainen_dynamical_2020,
	title = {Dynamical distance learning for semi-supervised and unsupervised skill discovery},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Hartikainen, Kristian and Geng, Xinyang and Haarnoja, Tuomas and Levine, Sergey},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
}

@inproceedings{huang_mapping_2019,
	title = {Mapping state space using landmarks for universal goal reaching},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Huang, Zhiao and Liu, Fangchen and Su, Hao},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {1940--1950},
}

@inproceedings{jin_is_2018,
	title = {Is {Q}-learning provably eﬃcient?},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Jin, Chi and Bubeck, Sebastien and Allen-Zhu, Zeyuan and Jordan, Michael I},
	year = {2018},
	pages = {24},
}

@inproceedings{brunskill_pac-inspired_2014,
	title = {{PAC}-inspired option discovery in lifelong reinforcement learning},
	booktitle = {{ICML}},
	author = {Brunskill, Emma and Li, Lihong},
	year = {2014},
}

@article{nichol_reptile_2018,
	title = {Reptile: {A} scalable metalearning algorithm},
	journal = {arXiv preprint arXiv:1803.02999},
	author = {Nichol, Alex and Schulman, John},
	year = {2018},
}

@inproceedings{ha_hypernetworks_2017,
	title = {{HyperNetworks}},
	booktitle = {{ICLR}},
	author = {Ha, David and Dai, Andrew and Le, Quoc V.},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@article{li_meta-sgd_2017,
	title = {Meta-{SGD}: {Learning} to learn quickly for few-shot learning},
	shorttitle = {Meta-sgd},
	journal = {arXiv preprint arXiv:1707.09835},
	author = {Li, Zhenguo and Zhou, Fengwei and Chen, Fei and Li, Hang},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{requeima_fast_2019,
	title = {Fast and flexible multi-task classification using conditional neural adaptive processes},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Requeima, James and Gordon, Jonathan and Bronskill, John and Nowozin, Sebastian and Turner, Richard E.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{boudiaf_metric_2020,
	title = {Metric learning: {Cross}-entropy vs. pairwise losses},
	shorttitle = {Metric learning},
	journal = {arXiv preprint arXiv:2003.08983},
	author = {Boudiaf, Malik and Rony, Jérôme and Ziko, Imtiaz Masud and Granger, Eric and Pedersoli, Marco and Piantanida, Pablo and Ayed, Ismail Ben},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{song_playing_2019,
	address = {Macao, China},
	title = {Playing {FPS} games with environment-aware hierarchical reinforcement learning},
	isbn = {978-0-9992411-4-1},
	doi = {10.24963/ijcai.2019/482},
	language = {en},
	booktitle = {{IJCAI}},
	author = {Song, Shihong and Weng, Jiayi and Su, Hang and Yan, Dong and Zou, Haosheng and Zhu, Jun},
	year = {2019},
	pages = {3475--3482},
}

@inproceedings{wang_dueling_2016,
	title = {Dueling network architectures for deep reinforcement learning},
	booktitle = {{ICML}},
	author = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and van Hasselt, Hado and Lanctot, Marc and de Freitas, Nando},
	year = {2016},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{vuorio_multimodal_2019,
	title = {Multimodal model-agnostic meta-learning via task-aware modulation},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Vuorio, Risto and Sun, Shao-Hua and Hu, Hexiang and Lim, Joseph J.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{vinyals_matching_2017,
	title = {Matching networks for one shot learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{happel_design_1994,
	title = {Design and evolution of modular neural network architectures},
	volume = {7},
	number = {6-7},
	journal = {Neural networks},
	author = {Happel, Bart LM and Murre, Jacob MJ},
	year = {1994},
	pages = {985--1004},
}

@article{sharma_learning_2017,
	title = {Learning to factor policies and action-value functions: {Factored} action space representations for deep reinforcement learning},
	shorttitle = {Learning to factor policies and action-value functions},
	journal = {arXiv preprint arXiv:1705.07269},
	author = {Sharma, Sahil and Suresh, Aravind and Ramesh, Rahul and Ravindran, Balaraman},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{nagabandi_deep_2019,
	title = {Deep online learning via meta-learning: {Continual} adaptation for model-based {RL}},
	shorttitle = {Deep online learning via meta-learning},
	booktitle = {{ICLR}},
	author = {Nagabandi, Anusha and Finn, Chelsea and Levine, Sergey},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{oord_neural_2017,
	title = {Neural discrete representation learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Oord, Aaron van den and Vinyals, Oriol and Kavukcuoglu, Koray},
	year = {2017},
	pages = {6306--6315},
}

@inproceedings{van_seijen_hybrid_2017,
	title = {Hybrid reward architecture for reinforcement learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {van Seijen, Harm and Fatemi, Mehdi},
	year = {2017},
}

@article{petangoda_disentangled_2019,
	title = {Disentangled skill embeddings for reinforcement learning},
	journal = {arXiv preprint arXiv:1906.09223},
	author = {Petangoda, Janith C. and Pascual-Diaz, Sergio and Adam, Vincent and Vrancx, Peter and Grau-Moya, Jordi},
	year = {2019},
}

@inproceedings{sung_learning_2018,
	title = {Learning to compare: {Relation} network for few-shot learning},
	booktitle = {{CVPR}},
	author = {Sung, Flood and Yang, Yongxin and Zhang, Li and Xiang, Tao and Torr, Philip H. S. and Hospedales, Timothy M.},
	year = {2018},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{ren_context-based_2019,
	title = {Context-based meta-reinforcement learning with structured latent space},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} {Learning} {Transferable} {Skills} {Workshop}},
	author = {Ren, Hongyu and Garg, Animesh and Anandkumar, Anima},
	year = {2019},
}

@inproceedings{wang_learning_2020,
	title = {Learning context-aware task reasoning for efficient meta-reinforcement learning},
	booktitle = {{AAMAS}},
	author = {Wang, Haozhe and Zhou, Jiale and He, Xuming},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{gordon_meta-learning_2019,
	title = {Meta-learning probabilistic inference for prediction},
	booktitle = {{ICLR}},
	author = {Gordon, Jonathan and Bronskill, John and Bauer, Matthias and Nowozin, Sebastian and Turner, Richard E.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{rusu_meta-learning_2019,
	title = {Meta-learning with latent embedding optimization},
	booktitle = {{ICLR}},
	author = {Rusu, Andrei A. and Rao, Dushyant and Sygnowski, Jakub and Vinyals, Oriol and Pascanu, Razvan and Osindero, Simon and Hadsell, Raia},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{kim_bayesian_2018,
	title = {Bayesian model-agnostic meta-learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kim, Taesup and Yoon, Jaesik and Dia, Ousmane and Kim, Sungwoong and Bengio, Yoshua and Ahn, Sungjin},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{han_visual_2019,
	title = {Visual concept-metaconcept learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Han, Chi and Mao, Jiayuan and Gan, Chuang and Tenenbaum, Josh and Wu, Jiajun},
	year = {2019},
}

@inproceedings{luketina_survey_2019,
	title = {A survey of reinforcement learning informed by natural language},
	language = {en},
	booktitle = {{IJCAI}},
	author = {Luketina, Jelena and Nardelli, Nantas and Farquhar, Gregory and Foerster, Jakob and Andreas, Jacob and Grefenstette, Edward and Whiteson, Shimon and Rocktäschel, Tim},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@techreport{ritter_episodic_2018,
	type = {preprint},
	title = {Episodic control as meta-reinforcement learning},
	language = {en},
	institution = {Neuroscience},
	author = {Ritter, S and Wang, Jx and Kurth-Nelson, Z and Botvinick, M},
	year = {2018},
	doi = {10.1101/360537},
}

@article{lehnert_successor_2019,
	title = {Successor features combine elements of model-free and model-based reinforcement learning},
	language = {en},
	journal = {arXiv preprint arXiv:1901.11437},
	author = {Lehnert, Lucas and Littman, Michael L.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{rao_continual_2019,
	title = {Continual unsupervised representation learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Rao, Dushyant and Visin, Francesco and Rusu, Andrei and Pascanu, Razvan and Teh, Yee Whye and Hadsell, Raia},
	year = {2019},
}

@inproceedings{parisotto_neural_2018,
	title = {Neural map: {Structured} memory for deep reinforcement learning},
	shorttitle = {Neural map},
	booktitle = {{ICLR}},
	author = {Parisotto, Emilio and Salakhutdinov, Ruslan},
	year = {2018},
	keywords = {Computer Science - Machine Learning},
}

@article{gordon_what_2019,
	title = {What should {I} do now? {Marrying} reinforcement learning and symbolic planning},
	shorttitle = {What should i do now?},
	language = {en},
	journal = {arXiv preprint arXiv:1901.01492},
	author = {Gordon, Daniel and Fox, Dieter and Farhadi, Ali},
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{humplik_meta_2019,
	title = {Meta reinforcement learning as task inference},
	language = {en},
	journal = {arXiv preprint arXiv:1905.06424},
	author = {Humplik, Jan and Galashov, Alexandre and Hasenclever, Leonard and Ortega, Pedro A. and Teh, Yee Whye and Heess, Nicolas},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{carr_domain_2018,
	title = {Domain adaptation for reinforcement learning on the atari},
	language = {en},
	journal = {arXiv preprint arXiv:1812.07452},
	author = {Carr, Thomas and Chli, Maria and Vogiatzis, George},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{chandak_learning_2019,
	title = {Learning action representations for reinforcement learning},
	booktitle = {{ICML}},
	author = {Chandak, Yash and Theocharous, Georgios and Kostas, James and Jordan, Scott and Thomas, Philip S.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{zhang_learning_2017,
	title = {Learning like humans with deep symbolic networks},
	journal = {arXiv preprint arXiv:1707.03377},
	author = {Zhang, Qunzhi and Sornette, Didier},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Condensed Matter - Disordered Systems and Neural Networks},
}

@article{velez_diffusion-based_2017,
	title = {Diffusion-based neuromodulation can eliminate catastrophic forgetting in simple neural networks},
	volume = {12},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0187736},
	language = {en},
	number = {11},
	journal = {PLOS ONE},
	author = {Velez, Roby and Clune, Jeff},
	editor = {Sendiña-Nadal, Irene},
	year = {2017},
	pages = {e0187736},
}

@inproceedings{dai_bridging_2019,
	title = {Bridging machine learning and logical reasoning by abductive learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dai, Wang-Zhou and Xu, Qiuling and Yu, Yang and Zhou, Zhi-Hua},
	year = {2019},
}

@article{garnelo_towards_2016,
	title = {Towards deep symbolic reinforcement learning},
	journal = {arXiv preprint arXiv:1609.05518},
	author = {Garnelo, Marta and Arulkumaran, Kai and Shanahan, Murray},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{dai_tunneling_2018,
	title = {Tunneling neural perception and logic reasoning through abductive learning},
	journal = {arXiv preprint arXiv:1802.01173},
	author = {Dai, Wang-Zhou and Xu, Qiu-Ling and Yu, Yang and Zhou, Zhi-Hua},
	year = {2018},
}

@inproceedings{van_de_wiele_q-learning_2020,
	title = {Q-learning in enormous action spaces via amortized approximate maximization},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Van de Wiele, Tom and Warde-Farley, David and Mnih, Andriy and Mnih, Volodymyr},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{atrey_exploratory_2020,
	title = {Exploratory not explanatory: {Counterfactual} analysis of saliency maps for deep {RL}},
	booktitle = {{ICLR}},
	author = {Atrey, Akanksha and Clary, Kaleigh and Jensen, David},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{ilahi_challenges_2020,
	title = {Challenges and countermeasures for adversarial attacks on deep reinforcement learning},
	journal = {arXiv preprint arXiv:2001.09684},
	author = {Ilahi, Inaam and Usama, Muhammad and Qadir, Junaid and Janjua, Muhammad Umar and Al-Fuqaha, Ala and Hoang, Dinh Thai and Niyato, Dusit},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
}

@inproceedings{pattanaik_robust_2018,
	title = {Robust deep reinforcement learning with adversarial attacks},
	booktitle = {{AAMAS}},
	author = {Pattanaik, Anay and Tang, Zhenyi and Liu, Shuijing and Bommannan, Gautham and Chowdhary, Girish},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{song_observational_2020,
	title = {Observational overfitting in reinforcement learning},
	booktitle = {{ICLR}},
	author = {Song, Xingyou and Jiang, Yiding and Du, Yilun and Neyshabur, Behnam},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{zhou_temporal-adaptive_2020,
	title = {Temporal-adaptive hierarchical reinforcement learning},
	journal = {arXiv preprint arXiv:2002.02080},
	author = {Zhou, Wen-Ji and Yu, Yang},
	year = {2020},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{deng_abstraction_2018,
	title = {Abstraction learning},
	journal = {arXiv preprint arXiv:1809.03956},
	author = {Deng, Fei and Ren, Jinsheng and Chen, Feng},
	year = {2018},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@article{su_subjectivity_2019,
	title = {Subjectivity learning theory towards artificial general intelligence},
	journal = {arXiv preprint arXiv:1909.03798},
	author = {Su, Xin and Guo, Shangqi and Chen, Feng},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{bellemare_geometric_2019,
	title = {A geometric perspective on optimal representations for reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bellemare, Marc G. and Dabney, Will and Dadashi, Robert and Taiga, Adrien Ali and Castro, Pablo Samuel and Roux, Nicolas Le and Schuurmans, Dale and Lattimore, Tor and Lyle, Clare},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{brendel_approximating_2019,
	title = {Approximating {CNNs} with bag-of-local-features models works surprisingly well on {ImageNet}},
	booktitle = {{ICLR}},
	author = {Brendel, Wieland and Bethge, Matthias},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{pinto_robust_2017,
	title = {Robust adversarial reinforcement learning},
	booktitle = {{ICML}},
	author = {Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics, Computer Science - Multiagent Systems},
}

@inproceedings{lin_tactics_2017,
	title = {Tactics of adversarial attack on deep reinforcement learning agents},
	booktitle = {{IJCAI}},
	author = {Lin, Yen-Chen and Hong, Zhang-Wei and Liao, Yuan-Hong and Shih, Meng-Li and Liu, Ming-Yu and Sun, Min},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Cryptography and Security},
}

@inproceedings{sun_svdnet_2017,
	address = {Venice},
	title = {{SVDNet} for pedestrian retrieval},
	isbn = {978-1-5386-1032-9},
	doi = {10.1109/ICCV.2017.410},
	booktitle = {{ICCV}},
	author = {Sun, Yifan and Zheng, Liang and Deng, Weijian and Wang, Shengjin},
	year = {2017},
	pages = {3820--3828},
}

@inproceedings{liu_understanding_2020,
	title = {Understanding why neural networks generalize well through {GSNR} of parameters},
	booktitle = {{ICLR}},
	author = {Liu, Jinlong and Jiang, Guoqing and Bai, Yunzhi and Chen, Ting and Wang, Huayan},
	year = {2020},
}

@article{liu_efficient_2019,
	title = {Efficient reinforcement learning with a thought-game for {StarCraft}},
	journal = {arXiv preprint arXiv:1903.00715},
	author = {Liu, Ruo-Ze and Guo, Haifeng and Ji, Xiaozhong and Yu, Yang and Pang, Zhen-Jia and Xiao, Zitai and Wu, Yuzhou and Lu, Tong},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{vinyals_grandmaster_2019,
	title = {Grandmaster level in {StarCraft} {II} using multi-agent reinforcement learning},
	volume = {575},
	issn = {0028-0836, 1476-4687},
	doi = {10.1038/s41586-019-1724-z},
	number = {7782},
	journal = {Nature},
	author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Michaël and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, Rémi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and Wünsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
	year = {2019},
	pages = {350--354},
}

@inproceedings{devin_deep_2018,
	title = {Deep object-centric representations for generalizable robot learning},
	booktitle = {{ICRA}},
	author = {Devin, C. and Abbeel, P. and Darrell, T. and Levine, S.},
	year = {2018},
	keywords = {Computer vision, generalizable robot learning, intelligent robots, learning (artificial intelligence), manipulators, object-centric representations, object-level attentional mechanism, perception system, reinforcement learning, robotic manipulation, semantic feature space, Semantics, Standards, Task analysis, Trajectory, visual perception, Visualization},
	pages = {7111--7118},
}

@inproceedings{lotter_deep_2017,
	title = {Deep predictive coding networks for video prediction and unsupervised learning},
	booktitle = {{ICLR}},
	author = {Lotter, William and Kreiman, Gabriel and Cox, David},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Neurons and Cognition},
}

@inproceedings{kim_emi_2019,
	title = {{EMI}: {Exploration} with mutual information},
	booktitle = {{ICML}},
	author = {Kim, Hyoungseok and Kim, Jaekyeom and Jeong, Yeonwoo and Levine, Sergey and Song, Hyun Oh},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{ng_policy_1999,
	title = {Policy invariance under reward transformations: {Theory} and application to reward shaping},
	volume = {99},
	booktitle = {{ICML}},
	author = {Ng, Andrew Y. and Harada, Daishi and Russell, Stuart},
	year = {1999},
	pages = {278--287},
}

@article{roweis_nonlinear_2000,
	title = {Nonlinear dimensionality reduction by locally linear embedding},
	volume = {290},
	number = {5500},
	journal = {Science},
	author = {Roweis, Sam T. and Saul, Lawrence K.},
	year = {2000},
	pages = {2323--2326},
}

@inproceedings{mcgovern_automatic_2001,
	title = {Automatic discovery of subgoals in reinforcement learning using diverse density},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {McGovern, Amy and Barto, Andrew G.},
	year = {2001},
	pages = {361--368},
}

@inproceedings{simsek_identifying_2005,
	title = {Identifying useful subgoals in reinforcement learning by local graph partitioning},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Şimşek, Özgür and Wolfe, Alicia P. and Barto, Andrew G.},
	year = {2005},
	pages = {816--823},
}

@inproceedings{parr_analysis_2008,
	title = {An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning},
	booktitle = {{ICML}},
	author = {Parr, Ronald and Li, Lihong and Taylor, Gavin and Painter-Wakeﬁeld, Christopher and Littman, Michael L},
	year = {2008},
	pages = {8},
}

@inproceedings{pong_temporal_2018,
	title = {Temporal difference models: {Model}-free deep {RL} for model-based control},
	shorttitle = {Temporal {Difference} {Models}},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
	year = {2018},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{yao_hierarchically_2019,
	title = {Hierarchically structured meta-learning},
	booktitle = {{ICML}},
	author = {Yao, Huaxiu and Wei, Ying and Huang, Junzhou and Li, Zhenhui},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{haarnoja_latent_2018,
	title = {Latent space policies for hierarchical reinforcement learning},
	booktitle = {{ICML}},
	author = {Haarnoja, Tuomas and Hartikainen, Kristian and Abbeel, Pieter and Levine, Sergey},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{fujimoto_addressing_2018,
	title = {Addressing function approximation error in actor-critic methods},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Fujimoto, Scott and van Hoof, Herke and Meger, David},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {1582--1591},
}

@inproceedings{co-reyes_self-consistent_2018,
	title = {Self-consistent trajectory autoencoder: {Hierarchical} reinforcement learning with trajectory embeddings},
	shorttitle = {Self-{Consistent} {Trajectory} {Autoencoder}},
	booktitle = {{ICML}},
	author = {Co-Reyes, John D. and Liu, YuXuan and Gupta, Abhishek and Eysenbach, Benjamin and Abbeel, Pieter and Levine, Sergey},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{hu_multiagent_1998,
	title = {Multiagent reinforcement learning: {Theoretical} framework and an algorithm},
	booktitle = {{ICML}},
	author = {Hu, Junling and Wellman, Michael P},
	year = {1998},
}

@article{busoniu_comprehensive_2008,
	title = {A comprehensive survey of multiagent reinforcement learning},
	volume = {38},
	issn = {1094-6977, 1558-2442},
	doi = {10.1109/TSMCC.2007.913919},
	language = {en},
	number = {2},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Busoniu, Lucian and Babuska, Robert and De Schutter, Bart},
	year = {2008},
	pages = {156--172},
}

@inproceedings{foerster_stabilising_2017,
	title = {Stabilising experience replay for deep multi-agent reinforcement learning},
	booktitle = {{ICML}},
	author = {Foerster, Jakob and Nardelli, Nantas and Farquhar, Gregory and Afouras, Triantafyllos and Torr, Philip H. S. and Kohli, Pushmeet and Whiteson, Shimon},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Multiagent Systems},
}

@inproceedings{da_silva_simultaneously_2017,
	title = {Simultaneously learning and advising in multiagent reinforcement learning},
	booktitle = {{AAMAS}},
	author = {Da Silva, Felipe Leno and Glatt, Ruben and Costa, Anna Helena Reali},
	year = {2017},
	pages = {1100--1108},
}

@inproceedings{duan_benchmarking_2016,
	title = {Benchmarking deep reinforcement learning for continuous control},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
	year = {2016},
	pages = {1329--1338},
}

@inproceedings{zheng_hardness-aware_2019,
	title = {Hardness-aware deep metric learning},
	booktitle = {{CVPR}},
	author = {Zheng, Wenzhao and Chen, Zhaodong and Lu, Jiwen and Zhou, Jie},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{wang_multi-similarity_2019,
	title = {Multi-similarity loss with general pair weighting for deep metric learning},
	booktitle = {{CVPR}},
	author = {Wang, Xun and Han, Xintong and Huang, Weilin and Dong, Dengke and Scott, Matthew R},
	year = {2019},
}

@inproceedings{nachum_data-efficient_2018,
	title = {Data-efficient hierarchical reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Nachum, Ofir and Gu, Shixiang Shane and Lee, Honglak and Levine, Sergey},
	year = {2018},
	pages = {3307--3317},
}

@inproceedings{bacon_option-critic_2017,
	title = {The option-critic architecture},
	booktitle = {{AAAI}},
	author = {Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
	year = {2017},
}

@inproceedings{pathak_self-supervised_2019,
	title = {Self-supervised exploration via disagreement},
	booktitle = {{ICML}},
	author = {Pathak, Deepak and Gandhi, Dhiraj and Gupta, Abhinav},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
}

@article{dietterich_hierarchical_2000,
	title = {Hierarchical reinforcement learning with the {MAXQ} value function decomposition},
	volume = {13},
	copyright = {Copyright (c)},
	issn = {1076-9757},
	doi = {10.1613/jair.639},
	language = {en},
	journal = {Journal of Artificial Intelligence Research},
	author = {Dietterich, T. G.},
	year = {2000},
	pages = {227--303},
}

@inproceedings{florensa_reverse_2017,
	title = {Reverse curriculum generation for reinforcement learning},
	booktitle = {{CoRL}},
	author = {Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael and Abbeel, Pieter},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics},
}

@inproceedings{aytar_playing_2018,
	title = {Playing hard exploration games by watching {YouTube}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Aytar, Yusuf and Pfaff, Tobias and Budden, David and Paine, Tom Le and Wang, Ziyu and de Freitas, Nando},
	year = {2018},
}

@article{zhang_explicitizing_2019,
	title = {Explicitizing an implicit bias of the frequency principle in two-layer neural networks},
	journal = {arXiv preprint arXiv:1905.10264},
	author = {Zhang, Yaoyu and Xu, Zhi-Qin John and Luo, Tao and Ma, Zheng},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, I.2.6, 68Q32, 68T01},
}

@inproceedings{wang_sample_2017,
	title = {Sample efficient actor-critic with experience replay},
	booktitle = {{ICLR}},
	author = {Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{goyal_recall_2019,
	title = {Recall traces: {Backtracking} models for efficient reinforcement learning},
	booktitle = {{ICLR}},
	author = {Goyal, Anirudh and Brakel, Philemon and Fedus, William and Singhal, Soumye and Lillicrap, Timothy and Levine, Sergey and Larochelle, Hugo and Bengio, Yoshua},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{brys_reinforcement_2015,
	title = {Reinforcement learning from demonstration through shaping},
	booktitle = {{IJCAI}},
	author = {Brys, Tim and Harutyunyan, Anna and Suay, Halit Bener and Chernova, Sonia and Taylor, Matthew E},
	year = {2015},
}

@inproceedings{konidaris_autonomous_2006,
	address = {Pittsburgh, Pennsylvania},
	title = {Autonomous shaping: {Knowledge} transfer in reinforcement learning},
	isbn = {978-1-59593-383-6},
	shorttitle = {Autonomous shaping},
	doi = {10.1145/1143844.1143906},
	language = {en},
	booktitle = {{ICML}},
	author = {Konidaris, George and Barto, Andrew},
	year = {2006},
	pages = {489--496},
}

@article{duan_rl$^2$:_2016,
	title = {{RL}\${\textasciicircum}2\$: {Fast} reinforcement learning via slow reinforcement learning},
	journal = {arXiv preprint arXiv:1611.02779},
	author = {Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L. and Sutskever, Ilya and Abbeel, Pieter},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@article{hinton_reducing_2006,
	title = {Reducing the dimensionality of data with neural networks},
	volume = {313},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.1127647},
	language = {en},
	number = {5786},
	journal = {Science},
	author = {Hinton, G. E.},
	year = {2006},
	pages = {504--507},
}

@inproceedings{rezende_stochastic_2014,
	title = {Stochastic backpropagation and approximate inference in deep generative models},
	booktitle = {{ICML}},
	author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
	year = {2014},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Computation, Statistics - Methodology},
}

	title = {Auto-association by multilayer perceptrons and singular value decomposition},
	volume = {59},
	issn = {0340-1200, 1432-0770},
	doi = {10.1007/BF00332918},
	language = {en},
	number = {4-5},
	journal = {Biological Cybernetics},
	year = {1988},
	pages = {291--294},
}

@inproceedings{bellemare_distributional_2017,
	title = {A distributional perspective on reinforcement learning},
	booktitle = {{ICML}},
	author = {Bellemare, Marc G. and Dabney, Will and Munos, Rémi},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{shani_exploration_2019,
	title = {Exploration conscious reinforcement learning revisited},
	booktitle = {{ICML}},
	author = {Shani, Lior and Efroni, Yonathan and Mannor, Shie},
	year = {2019},
}

@inproceedings{gamrian_transfer_2019,
	title = {Transfer learning for related reinforcement learning tasks via image-to-image translation},
	booktitle = {{ICML}},
	author = {Gamrian, Shani and Goldberg, Yoav},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},

Employs GANs to transfer target domain images to source domain images, and directly uses the corresponding policy in the source domain.
},
}

@inproceedings{sukhbaatar_end--end_2015,
	title = {End-to-end memory networks},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Sukhbaatar, Sainbayar and Weston, Jason and Fergus, Rob},
	year = {2015},
	pages = {2440--2448},
}

@inproceedings{weston_memory_2015,
	title = {Memory networks},
	booktitle = {{ICLR}},
	author = {Weston, Jason and Chopra, Sumit and Bordes, Antoine},
	year = {2015},
	keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{botvinick_reinforcement_2019,
	title = {Reinforcement learning, fast and slow},
	volume = {23},
	issn = {13646613},
	doi = {10.1016/j.tics.2019.02.006},
	language = {en},
	number = {5},
	journal = {Trends in Cognitive Sciences},
	author = {Botvinick, Matthew and Ritter, Sam and Wang, Jane X. and Kurth-Nelson, Zeb and Blundell, Charles and Hassabis, Demis},
	year = {2019},
	pages = {408--422},
}

@article{hochreiter_long_1997,
	title = {Long short-term memory},
	volume = {9},
	number = {8},
	journal = {Neural computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	year = {1997},
	pages = {1735--1780},
}

@inproceedings{kim_curiosity-bottleneck:_2019,
	title = {Curiosity-bottleneck: {Exploration} by distilling task-specific novelty},
	booktitle = {{ICML}},
	author = {Kim, Youngjin and Nam, Wontae and Kim, Hyunwoo and Kim, Ji-Hoon and Kim, Gunhee},
	year = {2019},
}

@inproceedings{kingma_adam:_2015,
	title = {Adam: {A} method for stochastic optimization},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	year = {2015},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{finn_online_2019,
	title = {Online meta-learning},
	booktitle = {{ICML}},
	author = {Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{gupta_learning_2017,
	title = {Learning invariant feature spaces to transfer skills with reinforcement learning},
	booktitle = {{ICLR}},
	author = {Gupta, Abhishek and Devin, Coline and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
	year = {2017},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{agarwal_learning_2019,
	title = {Learning to generalize from sparse and underspecified rewards},
	booktitle = {{ICML}},
	author = {Agarwal, Rishabh and Liang, Chen and Schuurmans, Dale and Norouzi, Mohammad},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{belilovsky_greedy_2019,
	title = {Greedy layerwise learning can scale to {ImageNet}},
	booktitle = {{ICML}},
	author = {Belilovsky, Eugene and Eickenberg, Michael and Oyallon, Edouard},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{du_task-agnostic_2019,
	title = {Task-agnostic dynamics priors for deep reinforcement learning},
	booktitle = {{ICML}},
	author = {Du, Yilun and Narasimhan, Karthik},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{mihatsch_risk-sensitive_2002,
	title = {Risk-sensitive reinforcement learning},
	journal = {Machine Learning},
	author = {Mihatsch, Oliver},
	year = {2002},
	pages = {267--290},
}

@article{frosst_distilling_2017,
	title = {Distilling a neural network into a soft decision tree},
	journal = {arXiv preprint arXiv:1711.09784},
	author = {Frosst, Nicholas and Hinton, Geoffrey},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{hinton_distilling_2014,
	title = {Distilling the knowledge in a neural network},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} {Deep} {Learning} {Workshop}},
	author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	year = {2014},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{dubey_investigating_2018,
	title = {Investigating human priors for playing video games},
	booktitle = {{ICML}},
	author = {Dubey, Rachit and Agrawal, Pulkit and Pathak, Deepak and Griffiths, Thomas L. and Efros, Alexei A.},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{ho_generative_2016,
	title = {Generative adversarial imitation learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ho, Jonathan and Ermon, Stefano},
	year = {2016},
}

@inproceedings{henderson_deep_2018,
	title = {Deep reinforcement learning that matters},
	booktitle = {{AAAI}},
	author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
	year = {2018},
}

@inproceedings{bengio_curriculum_2009,
	address = {Montreal, Quebec, Canada},
	title = {Curriculum learning},
	isbn = {978-1-60558-516-1},
	doi = {10.1145/1553374.1553380},
	booktitle = {{ICML}},
	author = {Bengio, Yoshua and Louradour, Jérôme and Collobert, Ronan and Weston, Jason},
	year = {2009},
	pages = {1--8},
}

@inproceedings{cobbe_quantifying_2019,
	title = {Quantifying generalization in reinforcement learning},
	booktitle = {{ICML}},
	author = {Cobbe, Karl and Klimov, Oleg and Hesse, Chris and Kim, Taehoon and Schulman, John},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},

Designs an environment named CoinRun, to quantitatively measure the generalization capacity of RL agents.
Summarizes the impacts of several widely-used factors in supervised learning domain on improving the generalizability of RL agents.

Larger network architecture
Regularization (L2, BN, data augmentation, etc.)
Environmental stochasticity
Multiple training environments (seems fundamental)


},
}

@article{mao_effectiveness_2017,
	title = {On the effectiveness of least squares generative adversarial networks},
	journal = {arXiv preprint arXiv:1712.06391},
	author = {Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond Y. K. and Wang, Zhen and Smolley, Stephen Paul},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{pere_unsupervised_2018,
	title = {Unsupervised learning of goal spaces for intrinsically motivated goal exploration},
	booktitle = {{ICLR}},
	author = {Péré, Alexandre and Forestier, Sébastien and Sigaud, Olivier and Oudeyer, Pierre-Yves},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{florensa_automatic_2018,
	title = {Automatic goal generation for reinforcement learning agents},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
	pages = {1514--1523},
}

@inproceedings{oord_pixel_2016,
	title = {Pixel recurrent neural networks},
	booktitle = {{ICML}},
	author = {Oord, Aaron van den and Kalchbrenner, Nal and Kavukcuoglu, Koray},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@article{strehl_analysis_2008,
	title = {An analysis of model-based interval estimation for {Markov} decision processes},
	volume = {74},
	issn = {00220000},
	doi = {10.1016/j.jcss.2007.08.009},
	number = {8},
	journal = {Journal of Computer and System Sciences},
	author = {Strehl, Alexander L. and Littman, Michael L.},
	year = {2008},
	pages = {1309--1331},
}

@inproceedings{osband_deep_2016,
	title = {Deep exploration via bootstrapped {DQN}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Osband, Ian and Blundell, Charles and Pritzel, Alexander and Roy, Benjamin Van},
	year = {2016},
}

@inproceedings{andrychowicz_hindsight_2017,
	title = {Hindsight experience replay},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics},
	pages = {5048--5058},
}

@inproceedings{borsa_universal_2019,
	title = {Universal successor features approximators},
	booktitle = {{ICLR}},
	author = {Borsa, Diana and Barreto, Andre and Quan, John and Mankowitz, Daniel and Munos, Remi and van Hasselt, Hado and Silver, David and Schaul, Tom},
	year = {2019},
}

@article{chen_learning_2019,
	title = {Learning exploration policies for navigation},
	language = {en},
	author = {Chen, Tao and Gupta, Saurabh and Gupta, Abhinav},
	year = {2019},
	pages = {14},
}

@inproceedings{antoniou_how_2019,
	title = {How to train your {MAML}},
	booktitle = {{ICLR}},
	author = {Antoniou, Antreas and Storkey, Amos and Edwards, Harrison},
	year = {2019},
}

@inproceedings{rauber_hindsight_2019,
	title = {Hindsight policy gradients},
	booktitle = {{ICLR}},
	author = {Rauber, Paulo and Mutz, Filipe and Ummadisingu, Avinash and Schmidhuber, Jürgen},
	year = {2019},
}

@inproceedings{samangouei_defense-gan:_2018,
	title = {Defense-{GAN}: {Protecting} classifiers against adversarial attacks using generative models},
	shorttitle = {Defense-{GAN}},
	booktitle = {{ICLR}},
	author = {Samangouei, Pouya and Kabkab, Maya and Chellappa, Rama},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836, 1476-4687},
	doi = {10.1038/nature14539},
	language = {en},
	number = {7553},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year = {2015},
	pages = {436--444},
}

@article{schmidhuber_deep_2015,
	title = {Deep learning in neural networks: {An} overview},
	volume = {61},
	issn = {08936080},
	shorttitle = {Deep {Learning} in {Neural} {Networks}},
	doi = {10.1016/j.neunet.2014.09.003},
	language = {en},
	journal = {Neural Networks},
	author = {Schmidhuber, Juergen},
	year = {2015},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	pages = {85--117},
}

@inproceedings{choi_contingency-aware_2019,
	title = {Contingency-aware exploration in reinforcement learning},
	booktitle = {{ICLR}},
	author = {Choi, Jongwook and Guo, Yijie and Moczulski, Marcin and Oh, Junhyuk and Wu, Neal and Norouzi, Mohammad and Lee, Honglak},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{mcduff_visceral_2019,
	title = {Visceral machines: {Risk}-aversion in reinforcement learning with intrinsic physiological rewards},
	language = {en},
	booktitle = {{ICLR}},
	author = {McDuff, Daniel and Kapoor, Ashish},
	year = {2019},
	pages = {11},
}

@inproceedings{nikolov_information-directed_2019,
	title = {Information-directed exploration for deep reinforcement learning},
	language = {en},
	booktitle = {{ICLR}},
	author = {Nikolov, Nikolay and Kirschner, Johannes and Berkenkamp, Felix and Krause, Andreas},
	year = {2019},
	pages = {16},
}

@inproceedings{goyal_infobot:_2019,
	title = {{InfoBot}: {Transfer} and exploration via the information bottleneck},
	booktitle = {{ICLR}},
	author = {Goyal, Anirudh and Islam, Riashat and Strouse, Daniel and Ahmed, Zafarali and Botvinick, Matthew and Larochelle, Hugo and Bengio, Yoshua and Levine, Sergey},
	year = {2019},
}

@article{horgan_distributed_2018,
	title = {Distributed prioritized experience replay},
	journal = {ICLR},
	author = {Horgan, Dan and Quan, John and Budden, David and Barth-Maron, Gabriel and Hessel, Matteo and van Hasselt, Hado and Silver, David},
	year = {2018},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{colas_gep-pg:_2018,
	title = {{GEP}-{PG}: {Decoupling} exploration and exploitation in deep reinforcement learning algorithms},
	booktitle = {{ICML}},
	author = {Colas, Cédric and Sigaud, Olivier and Oudeyer, Pierre-Yves},
	year = {2018},
}

@inproceedings{oh_self-imitation_2018,
	title = {Self-imitation learning},
	booktitle = {{ICML}},
	author = {Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{rusu_progressive_2016,
	title = {Progressive neural networks},
	journal = {arXiv preprint arXiv:1606.04671},
	author = {Rusu, Andrei A. and Rabinowitz, Neil C. and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
	year = {2016},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{higgins_darla:_2017,
	title = {{DARLA}: {Improving} zero-shot transfer in reinforcement learning},
	shorttitle = {{DARLA}},
	language = {en},
	booktitle = {{ICML}},
	author = {Higgins, Irina and Pal, Arka and Rusu, Andrei A. and Matthey, Loic and Burgess, Christopher P. and Pritzel, Alexander and Botvinick, Matthew and Blundell, Charles and Lerchner, Alexander},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{ferrari_agil:_2018,
	address = {Cham},
	title = {{AGIL}: {Learning} attention from human for visuomotor tasks},
	volume = {11215},
	isbn = {978-3-030-01251-9 978-3-030-01252-6},
	shorttitle = {{AGIL}},
	doi = {10.1007/978-3-030-01252-6_41},
	booktitle = {{ECCV}},
	author = {Zhang, Ruohan and Liu, Zhuode and Zhang, Luxin and Whritner, Jake A. and Muller, Karl S. and Hayhoe, Mary M. and Ballard, Dana H.},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	pages = {692--707},
}

@inproceedings{hessel_rainbow:_2018,
	title = {Rainbow: {Combining} improvements in deep reinforcement learning},
	booktitle = {{AAAI}},
	author = {Hessel, Matteo and Modayil, Joseph},
	year = {2018},
}

@inproceedings{hu_squeeze-and-excitation_2018,
	title = {Squeeze-and-excitation networks},
	booktitle = {{CVPR}},
	author = {Hu, Jie and Shen, Li and Sun, Gang},
	year = {2018},
}

@inproceedings{neyshabur_exploring_2017,
	title = {Exploring generalization in deep learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Neyshabur, Behnam and Bhojanapalli, Srinadh and Mcallester, David and Srebro, Nati},
	year = {2017},
}

@inproceedings{wen_learning_2016,
	title = {Learning structured sparsity in deep neural networks},
	booktitle = {{NIPS}},
	author = {Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
	year = {2016},
}

@inproceedings{zhang_understanding_2017,
	title = {Understanding deep learning requires rethinking generalization},
	booktitle = {{ICLR}},
	author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{wan_regularization_2013,
	title = {Regularization of neural networks using {DropConnect}},
	booktitle = {{ICML}},
	author = {Wan, Li and Zeiler, Matthew and Zhang, Sixin and LeCun, Yann and Fergus, Rob},
	year = {2013},
}

@article{thomas_independently_2017,
	title = {Independently controllable factors},
	journal = {arXiv preprint arXiv:1708.01289},
	author = {Thomas, Valentin and Pondard, Jules and Bengio, Emmanuel and Sarfati, Marc and Beaudoin, Philippe and Meurs, Marie-Jean and Pineau, Joelle and Precup, Doina and Bengio, Yoshua},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{bengio_independently_2017,
	title = {Independently controllable features},
	journal = {arXiv preprint arXiv:1703.07718},
	author = {Bengio, Emmanuel and Thomas, Valentin and Pineau, Joelle and Precup, Doina and Bengio, Yoshua},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{greydanus_visualizing_2018,
	title = {Visualizing and understanding atari agents},
	booktitle = {{ICML}},
	author = {Greydanus, Sam and Koul, Anurag and Dodge, Jonathan and Fern, Alan},
	year = {2018},
	keywords = {Computer Science - Artificial Intelligence},
}

@inproceedings{zahavy_graying_2016,
	title = {Graying the black box: {Understanding} {DQNs}},
	booktitle = {{ICML}},
	author = {Zahavy, Tom and Zrihem, Nir Ben and Mannor, Shie},
	year = {2016},
}

@article{such_atari_2018,
	title = {An atari model zoo for analyzing, visualizing, and comparing deep reinforcement learning agents},
	journal = {arXiv preprint arXiv:1812.07069},
	author = {Such, Felipe Petroski and Madhavan, Vashisht and Liu, Rosanne and Wang, Rui and Castro, Pablo Samuel and Li, Yulun and Schubert, Ludwig and Bellemare, Marc and Clune, Jeff and Lehman, Joel},
	year = {2018},
	keywords = {Computer Science - Neural and Evolutionary Computing},
}

@article{luo_visual_2018,
	title = {Visual diagnostics for deep reinforcement learning policy development},
	abstract = {Modern vision-based reinforcement learning techniques often use convolutional neural networks (CNN) as universal function approximators to choose which action to take for a given visual input. Until recently, CNNs have been treated like black-box functions, but this mindset is especially dangerous when used for control in safety-critical settings. In this paper, we present our extensions of CNN visualization algorithms to the domain of vision-based reinforcement learning. We use a simulated drone environment as an example scenario. These visualization algorithms are an important tool for behavior introspection and provide insight into the qualities and ﬂaws of trained policies when interacting with the physical world. A video may be seen at https://sites.google.com/view/drlvisual.},
	journal = {arXiv preprint arXiv:1809.06781},
	author = {Luo, Jieliang and Green, Sam and Feghali, Peter and Legrady, George and Koç, Çetin Kaya},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{lee_unsupervised_2017,
	address = {Venice},
	title = {Unsupervised representation learning by sorting sequences},
	isbn = {978-1-5386-1032-9},
	doi = {10.1109/ICCV.2017.79},
	booktitle = {{ICCV}},
	author = {Lee, Hsin-Ying and Huang, Jia-Bin and Singh, Maneesh and Yang, Ming-Hsuan},
	year = {2017},
	pages = {667--676},
}

@inproceedings{todd_learning_2018,
	title = {Learning to use working memory in partially observable environments through dopaminergic reinforcement},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Todd, Michael T and Niv, Yael and Cohen, Jonathan D},
	year = {2018},
}

@inproceedings{savinov_semi-parametric_2018,
	title = {Semi-parametric topological memory for navigation},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Savinov, Nikolay and Dosovitskiy, Alexey and Koltun, Vladlen},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
}

@inproceedings{witty_measuring_2018,
	title = {Measuring and characterizing generalization in deep reinforcement learning},
	booktitle = {{AAAI}},
	author = {Witty, Sam and Lee, Jun Ki and Tosch, Emma and Atrey, Akanksha and Littman, Michael and Jensen, David},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{lei_geometric_2018,
	title = {Geometric understanding of deep learning},
	journal = {arXiv preprint arXiv:1805.10451},
	author = {Lei, Na and Luo, Zhongxuan and Yau, Shing-Tung and Gu, David Xianfeng},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{mao_universal_2018,
	title = {Universal agent for disentangling environments and tasks},
	booktitle = {{ICLR}},
	author = {Mao, Jiayuan and Dong, Honghua and Lim, Joseph J.},
	year = {2018},
}

@inproceedings{asadi_lipschitz_2018-1,
	title = {Lipschitz continuity in model-based reinforcement learning},
	booktitle = {{ICML}},
	author = {Asadi, Kavosh and Misra, Dipendra and Littman, Michael L.},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{pfau_connecting_2016,
	title = {Connecting generative adversarial networks and actor-critic methods},
	journal = {arXiv preprint arXiv:1610.01945},
	author = {Pfau, David and Vinyals, Oriol},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{burda_large-scale_2019,
	title = {Large-scale study of curiosity-driven learning},
	booktitle = {{ICLR}},
	author = {Burda, Yuri and Edwards, Harri and Pathak, Deepak and Storkey, Amos and Darrell, Trevor and Efros, Alexei A.},
	year = {2019},
}

@article{lesort_state_2018,
	title = {State representation learning for control: {An} overview},
	volume = {108},
	issn = {08936080},
	doi = {10.1016/j.neunet.2018.07.006},
	journal = {Neural Networks},
	author = {Lesort, Timothée and Díaz-Rodríguez, Natalia and Goudou, Jean-François and Filliat, David},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {379--392},
}

@inproceedings{yan_learning_2019,
	title = {Learning to assign credit in reinforcement learning by incorporating abstract relations},
	booktitle = {{AAAI}},
	author = {Yan, Dong and Huang, Shiyu and Su, Hang and Zhu, Jun},
	year = {2019},

Abstracts original states (raw pixels) into compact states expressed by first-order-logic (FOL), by employing object detection and localization methods.
Plans with abstract states, and uses the results (potential functions) to do reward shaping in the original state space.
},
}

@article{bard_hanabi_2019,
	title = {The {Hanabi} challenge: {A} new frontier for {AI} research},
	journal = {arXiv preprint arXiv:1902.00506},
	author = {Bard, Nolan and Foerster, Jakob N. and Chandar, Sarath and Burch, Neil and Lanctot, Marc and Song, H. Francis and Parisotto, Emilio and Dumoulin, Vincent and Moitra, Subhodeep and Hughes, Edward and Dunning, Iain and Mourad, Shibl and Larochelle, Hugo and Bellemare, Marc G. and Bowling, Michael},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{eigen_depth_2014,
	title = {Depth map prediction from a single image using a multi-scale deep network},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Eigen, David and Puhrsch, Christian and Fergus, Rob},
	year = {2014},
	pages = {2366--2374},
}

@inproceedings{huang_combo-action:_2019,
	title = {Combo-action: {Training} agent for {FPS} game with auxiliary tasks},
	booktitle = {{AAAI}},
	author = {Huang, Shiyu and Su, Hang and Chen, Ting and Zhu, Jun},
	year = {2019},
	pages = {8},
}

@inproceedings{shao_learning_2018,
	title = {Learning battles in {ViZDoom} via deep reinforcement learning},
	doi = {10.1109/CIG.2018.8490423},
	booktitle = {{IEEE} {Conference} on {Computational} {Intelligence} and {Games} ({CIG})},
	author = {Shao, K. and Zhao, D. and Li, N. and Zhu, Y.},
	year = {2018},
	keywords = {deep learning, Machine learning, Training, learning (artificial intelligence), reinforcement learning, Task analysis, Visualization, ACKTR agents, actor-critic baseline agent, artificial intelligence, computer games, deep reinforcement learning method, DRL method, first-person shooter video games, game AI, Games, Kronecker-factored trust region, Learning Battles, Measurement, ViZDoom},
	pages = {1--4},
}

@article{vinyals_starcraft_2017,
	title = {Starcraft {II}: {A} new challenge for reinforcement learning},
	journal = {arXiv preprint arXiv:1708.04782},
	author = {Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and Küttler, Heinrich and Agapiou, John and Schrittwieser, Julian},
	year = {2017},
}

@inproceedings{goodfellow_generative_2014,
	title = {Generative adversarial nets},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	year = {2014},
	pages = {2672--2680},
}

@inproceedings{zhang_stackgan:_2017,
	address = {Venice},
	title = {{StackGAN}: {Text} to photo-realistic image synthesis with stacked generative adversarial networks},
	isbn = {978-1-5386-1032-9},
	doi = {10.1109/ICCV.2017.629},
	booktitle = {{ICCV}},
	author = {Zhang, Han and Xu, Tao and Li, Hongsheng},
	year = {2017},
	pages = {5908--5916},
}

@inproceedings{isola_image--image_2017,
	title = {Image-to-image translation with conditional adversarial networks},
	booktitle = {{ICCV}},
	author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
	year = {2017},
	pages = {1125--1134},
}

@inproceedings{zhu_unpaired_2017,
	title = {Unpaired image-to-image translation using cycle-consistent adversarial networks},
	booktitle = {{ICCV}},
	author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
	year = {2017},
	pages = {2223--2232},
}

@inproceedings{karras_style-based_2019,
	title = {A style-based generator architecture for generative adversarial networks},
	booktitle = {{CVPR}},
	author = {Karras, Tero and Laine, Samuli and Aila, Timo},
	year = {2019},
}

@inproceedings{brock_large_2019,
	title = {Large scale gan training for high fidelity natural image synthesis},
	booktitle = {{ICLR}},
	author = {Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
	year = {2019},
}

@article{mirza_conditional_2014,
	title = {Conditional generative adversarial nets},
	journal = {arXiv preprint arXiv:1411.1784},
	author = {Mirza, Mehdi and Osindero, Simon},
	year = {2014},
}

@article{radford_unsupervised_2015,
	title = {Unsupervised representation learning with deep convolutional generative adversarial networks},
	journal = {arXiv preprint arXiv:1511.06434},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	year = {2015},
}

@inproceedings{tobin_domain_2017,
	title = {Domain randomization for transferring deep neural networks from simulation to the real world},
	isbn = {1-5386-2682-9},
	booktitle = {{IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
	year = {2017},
	pages = {23--30},
}

@inproceedings{sutton_horde:_2011,
	title = {Horde: {A} scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
	isbn = {0-9826571-6-1},
	booktitle = {International {Conference} on {Autonomous} {Agents} and {Multiagent} {Systems}},
	author = {Sutton, Richard S. and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M. and White, Adam and Precup, Doina},
	year = {2011},
	pages = {761--768},
}

@inproceedings{mirowski_learning_2017,
	title = {Learning to navigate in complex environments},
	booktitle = {{ICLR}},
	author = {Mirowski, Piotr and Pascanu, Razvan and Viola, Fabio and Soyer, Hubert and Ballard, Andrew J. and Banino, Andrea and Denil, Misha and Goroshin, Ross and Sifre, Laurent and Kavukcuoglu, Koray and Kumaran, Dharshan and Hadsell, Raia},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
}

@inproceedings{li_recurrent_2016,
	title = {Recurrent reinforcement learning: {A} hybrid approach},
	booktitle = {{ICLR}},
	author = {Li, Xiujun and Li, Lihong and Gao, Jianfeng and He, Xiaodong and Chen, Jianshu and Deng, Li and He, Ji},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Systems and Control},
}

@inproceedings{oh_action-conditional_2015,
	title = {Action-conditional video prediction using deep networks in atari games},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard L. and Singh, Satinder},
	year = {2015},
	pages = {2863--2871},
}

@inproceedings{xie_model-based_2016,
	title = {Model-based reinforcement learning with parametrized physical models and optimism-driven exploration},
	isbn = {1-4673-8026-1},
	booktitle = {{IEEE} international conference on robotics and automation ({ICRA})},
	author = {Xie, Chris and Patil, Sachin and Moldovan, Teodor and Levine, Sergey and Abbeel, Pieter},
	year = {2016},
	pages = {504--511},
}

@inproceedings{jaderberg_reinforcement_2017,
	title = {Reinforcement learning with unsupervised auxiliary tasks},
	booktitle = {{ICLR}},
	author = {Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z. and Silver, David and Kavukcuoglu, Koray},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{beattie_deepmind_2016,
	title = {Deepmind lab},
	journal = {arXiv preprint arXiv:1612.03801},
	author = {Beattie, Charles and Leibo, Joel Z. and Teplyashin, Denis and Ward, Tom and Wainwright, Marcus and Küttler, Heinrich and Lefrancq, Andrew and Green, Simon and Valdés, Víctor and Sadik, Amir},
	year = {2016},
}

@article{bellemare_arcade_2013,
	title = {The arcade learning environment: {An} evaluation platform for general agents},
	volume = {47},
	journal = {Journal of Artificial Intelligence Research},
	author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
	year = {2013},
	pages = {253--279},
}

@article{brockman_openai_2016,
	title = {Openai gym},
	journal = {arXiv preprint arXiv:1606.01540},
	author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	year = {2016},
}

@inproceedings{oh_control_2016,
	title = {Control of memory, active perception, and action in minecraft},
	booktitle = {{ICML}},
	author = {Oh, Junhyuk and Chockalingam, Valliappa and Singh, Satinder and Lee, Honglak},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{erhan_why_2010,
	title = {Why does unsupervised pre-training help deep learning?},
	volume = {11},
	number = {Feb},
	journal = {Journal of Machine Learning Research},
	author = {Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine and Vincent, Pascal and Bengio, Samy},
	year = {2010},
	pages = {625--660},
}

@inproceedings{guestrin_generalizing_2003,
	title = {Generalizing plans to new environments in relational {MDPs}},
	booktitle = {{IJCAI}},
	author = {Guestrin, Carlos and Koller, Daphne and Gearhart, Chris and Kanodia, Neal},
	year = {2003},
	pages = {1003--1010},
}

@inproceedings{diuk_object-oriented_2008,
	address = {Helsinki, Finland},
	title = {An object-oriented representation for efficient reinforcement learning},
	isbn = {978-1-60558-205-4},
	doi = {10.1145/1390156.1390187},
	booktitle = {{ICML}},
	author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
	year = {2008},
	pages = {240--247},
}

@article{botvinick_hierarchically_2009,
	title = {Hierarchically organized behavior and its neural foundations: {A} reinforcement learning perspective},
	volume = {113},
	issn = {00100277},
	shorttitle = {Hierarchically organized behavior and its neural foundations},
	doi = {10.1016/j.cognition.2008.08.011},
	number = {3},
	journal = {Cognition},
	author = {Botvinick, Matthew M. and Niv, Yael and Barto, Andrew C.},
	year = {2009},
	pages = {262--280},
}

@inproceedings{zambaldi_deep_2019,
	title = {Deep reinforcement learning with relational inductive biases},
	booktitle = {{ICLR}},
	author = {Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward},
	year = {2019},
}

@article{zambaldi_deep_2018,
	title = {Deep reinforcement learning with relational inductive biases},
	author = {Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward},
	year = {2018},
}

@article{dayan_improving_1993,
	title = {Improving generalization for temporal difference learning: {The} successor representation},
	volume = {5},
	number = {4},
	journal = {Neural Computation},
	author = {Dayan, Peter},
	year = {1993},
	pages = {613--624},
}

@inproceedings{hong_diversity-driven_2018,
	title = {Diversity-driven exploration strategy for deep reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Hong, Zhang-Wei and Shann, Tzu-Yun and Su, Shih-Yang and Chang, Yi-Hsiang and Fu, Tsu-Jui and Lee, Chun-Yi},
	year = {2018},
	pages = {10489--10500},
}

@article{hinton_improving_2012,
	title = {Improving neural networks by preventing co-adaptation of feature detectors},
	journal = {arXiv preprint arXiv:1207.0580},
	author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
	year = {2012},
}

@book{berlyne_conflict_1960,
	address = {New York, NY, US},
	title = {Conflict, arousal, and curiosity.},
	author = {Berlyne, Daniel E.},
	year = {1960},
}

@article{berlyne_novelty_1950,
	title = {Novelty and curiosity as determinants of exploratory behaviour},
	volume = {41},
	number = {1},
	journal = {British Journal of Psychology},
	author = {Berlyne, Daniel E.},
	year = {1950},
	pages = {68},
}

@inproceedings{gu_continuous_2016,
	title = {Continuous deep {Q}-learning with model-based acceleration},
	booktitle = {{ICML}},
	author = {Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
	year = {2016},
}

@inproceedings{lillicrap_continuous_2016,
	title = {Continuous control with deep reinforcement learning},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{yuezhang_initial_2018,
	title = {An initial attempt of combining visual selective attention with deep reinforcement learning},
	journal = {arXiv preprint arXiv:1811.04407},
	author = {Yuezhang, Liu and Zhang, Ruohan and Ballard, Dana H.},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{ma_universal_2018,
	title = {Universal successor representations for transfer reinforcement learning},
	booktitle = {{ICLR} {Workshop}},
	author = {Ma, Chen and Wen, Junfeng and Bengio, Yoshua},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{wydmuch_vizdoom_2018,
	title = {{ViZDoom} competitions: {Playing} doom from pixels},
	journal = {arXiv preprint arXiv:1809.03470},
	author = {Wydmuch, Marek and Kempka, Michał and Jaśkowski, Wojciech},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{lee_lstm_2018,
	title = {{LSTM} iteration networks: {An} exploration of differentiable path finding},
	booktitle = {{ICLR} {Workshop}},
	author = {Lee, Lisa and Parisotto, Emilio and Chaplot, Devendra Singh and Salakhutdinov, Ruslan},
	year = {2018},
	keywords = {READING},
}

@inproceedings{lample_playing_2017,
	title = {Playing {FPS} games with deep reinforcement learning},
	booktitle = {{AAAI}},
	author = {Lample, Guillaume and Chaplot, Devendra Singh},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, ViZDoom Research},
}

@inproceedings{wu_training_2017,
	title = {Training agent for first-person shooter game with actor-critic curriculum learning},
	booktitle = {{ICLR}},
	author = {Wu, Yuxin and Tian, Yuandong},
	year = {2017},
	keywords = {ViZDoom Research},
}

@article{schulze_vizdoom:_2018,
	title = {{ViZDoom}: {DRQN} with prioritized experience replay, double-{Q} learning, \& snapshot ensembling},
	journal = {arXiv preprint arXiv:1801.01000},
	author = {Schulze, Christopher and Schulze, Marcus},
	year = {2018},
}

@inproceedings{kempka_vizdoom:_2016,
	title = {{ViZDoom}: {A} doom-based ai research platform for visual reinforcement learning},
	booktitle = {{IEEE} {Conference} on {Computational} {Intelligence} and {Games} ({CIG})},
	author = {Kempka, Michał and Wydmuch, Marek and Runc, Grzegorz and Toczek, Jakub and Jaśkowski, Wojciech},
	year = {2016},
	pages = {1--8},
}

@inproceedings{chaplot_transfer_2016,
	title = {Transfer deep reinforcement learning in {3D} environments: {An} empirical study},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chaplot, Devendra Singh and Sathyendra, Kanthashree Mysore and Lample, Guillaume and Salakhutdinov, Ruslan},
	year = {2016},
}

@inproceedings{smith_scaling_2018,
	title = {Scaling tangled program graphs to visual reinforcement learning in {ViZDoom}},
	booktitle = {European {Conference} on {Genetic} {Programming}},
	author = {Smith, Robert J. and Heywood, Malcolm I.},
	year = {2018},
	pages = {135--150},
}

@article{jin_regret_2017,
	title = {Regret minimization for partially observable deep reinforcement learning},
	journal = {arXiv preprint arXiv:1710.11424},
	author = {Jin, Peter H. and Levine, Sergey and Keutzer, Kurt},
	year = {2017},
}

@article{bhatti_playing_2016,
	title = {Playing doom with {SLAM}-augmented deep reinforcement learning},
	journal = {arXiv preprint arXiv:1612.00380},
	author = {Bhatti, Shehroze and Desmaison, Alban and Miksik, Ondrej and Nardelli, Nantas and Siddharth, N. and Torr, Philip H. S.},
	year = {2016},
	keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, ViZDoom Research},
}

@inproceedings{wu_master-slave_2018,
	title = {Master-slave curriculum design for reinforcement learning},
	booktitle = {{IJCAI}},
	author = {Wu, Yuechen and Zhang, Wei and Song, Ke},
	year = {2018},
	pages = {1523--1529},
}

@inproceedings{dosovitskiy_learning_2017,
	title = {Learning to act by predicting the future},
	booktitle = {{ICLR}},
	author = {Dosovitskiy, Alexey and Koltun, Vladlen},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{jaderberg_human-level_2018,
	title = {Human-level performance in first-person multiplayer games with population-based deep reinforcement learning},
	journal = {arXiv preprint arXiv:1807.01281},
	author = {Jaderberg, Max and Czarnecki, Wojciech M. and Dunning, Iain and Marris, Luke and Lever, Guy and Castaneda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C. and Morcos, Ari S. and Ruderman, Avraham and Sonnerat, Nicolas and Green, Tim and Deason, Louise and Leibo, Joel Z. and Silver, David and Hassabis, Demis and Kavukcuoglu, Koray and Graepel, Thore},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{garmulewicz_expert-augmented_2018,
	title = {Expert-augmented actor-critic for {ViZDoom} and {Montezuma}'s {Revenge}},
	journal = {arXiv preprint arXiv:1809.03447},
	author = {Garmulewicz, Michał and Michalewski, Henryk and Miłoś, Piotr},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{kulkarni_deep_2016,
	title = {Deep successor reinforcement learning},
	journal = {arXiv preprint arXiv:1606.02396},
	author = {Kulkarni, Tejas D. and Saeedi, Ardavan and Gautam, Simanta and Gershman, Samuel J.},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, ViZDoom Research, READ},
}

@inproceedings{justesen_automated_2018,
	title = {Automated curriculum learning by rewarding temporally rare events},
	booktitle = {{IEEE} {Conference} on {Computational} {Intelligence} and {Games} ({CIG})},
	author = {Justesen, N. and Risi, S.},
	year = {2018},
	keywords = {Machine learning, Training, Search problems, learning (artificial intelligence), reinforcement learning, Games, additional reward signals, automated curriculum learning, challenging VizDoom scenarios, complex RL tasks, intrinsic motivation, Learning (artificial intelligence), pre-defined events, Predictive models, rarity of events approach, reinforcement learning agents, reward shaping, rewarding temporally rare events, RoE approach, sparse extrinsic rewards, unsolved RL environments, VizDoom, Weapons},
	pages = {1--8},
}

@article{alvernaz_autoencoder-augmented_2017,
	title = {Autoencoder-augmented neuroevolution for visual doom playing},
	journal = {arXiv preprint arXiv:1707.03902},
	author = {Alvernaz, Samuel and Togelius, Julian},
	year = {2017},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, ViZDoom Research},
}

@inproceedings{chaplot_arnold:_2017,
	title = {Arnold: {An} autonomous agent to play {FPS} games},
	booktitle = {{AAAI}},
	author = {Chaplot, Devendra Singh and Lample, Guillaume},
	year = {2017},
	pages = {5085--5086},
}

@inproceedings{santoro_relational_2018,
	title = {Relational recurrent neural networks},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Santoro, Adam and Faulkner, Ryan and Raposo, David and Rae, Jack and Chrzanowski, Mike and Weber, Theophane and Wierstra, Daan and Vinyals, Oriol and Pascanu, Razvan and Lillicrap, Timothy},
	year = {2018},
}

@inproceedings{pardo_time_2018,
	title = {Time limits in reinforcement learning},
	booktitle = {{ICML}},
	author = {Pardo, Fabio and Tavakoli, Arash and Levdik, Vitaly and Kormushev, Petar},
	year = {2018},
	keywords = {Computer Science - Machine Learning},
}

@article{machado_revisiting_2018,
	title = {Revisiting the arcade learning environment: {Evaluation} protocols and open problems for general agents},
	volume = {61},
	journal = {Journal of Artificial Intelligence Research},
	author = {Machado, Marlos C. and Bellemare, Marc G. and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
	year = {2018},
	pages = {523--562},
}

@inproceedings{ghosh_divide-and-conquer_2018,
	title = {Divide-and-conquer reinforcement learning},
	booktitle = {{ICLR}},
	author = {Ghosh, Dibya and Singh, Avi and Rajeswaran, Aravind and Kumar, Vikash and Levine, Sergey},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics},
}

@article{mouret_illuminating_2015,
	title = {Illuminating search spaces by mapping elites},
	journal = {arXiv preprint arXiv:1504.04909},
	author = {Mouret, Jean-Baptiste and Clune, Jeff},
	year = {2015},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics, Quantitative Biology - Populations and Evolution},
}

@article{such_deep_2017,
	title = {Deep neuroevolution: {Genetic} algorithms are a competitive alternative for training deep neural networks for reinforcement learning},
	journal = {arXiv preprint arXiv:1712.06567},
	author = {Such, Felipe Petroski and Madhavan, Vashisht and Conti, Edoardo and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
	year = {2017},
}

@article{espeholt_impala:_2018,
	title = {{IMPALA}: {Scalable} distributed deep-{RL} with importance weighted actor-learner architectures},
	journal = {arXiv preprint arXiv:1802.01561},
	author = {Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and Legg, Shane and Kavukcuoglu, Koray},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{schulman_high-dimensional_2016,
	title = {High-dimensional continuous control using generalized advantage estimation},
	booktitle = {{ICLR}},
	author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics, Computer Science - Systems and Control},
}

@article{kaplan_beating_2017,
	title = {Beating atari with natural language guided reinforcement learning},
	journal = {arXiv preprint arXiv:1704.05539},
	author = {Kaplan, Russell and Sauer, Christopher and Sosa, Alexander},
	year = {2017},
	keywords = {Computer Science - Artificial Intelligence},
}

@inproceedings{zhang_deeper_2017,
	title = {A deeper look at experience replay},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhang, Shangtong and Sutton, Richard S.},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{battaglia_relational_2018,
	title = {Relational inductive biases, deep learning, and graph networks},
	journal = {arXiv preprint arXiv:1806.01261},
	author = {Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and Gulcehre, Caglar and Song, Francis and Ballard, Andrew and Gilmer, Justin and Dahl, George and Vaswani, Ashish and Allen, Kelsey and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matt and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{zhang_deep_2018,
	title = {Deep learning on graphs: {A} survey},
	journal = {arXiv preprint arXiv:1812.04202},
	author = {Zhang, Ziwei and Cui, Peng and Zhu, Wenwu},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Social and Information Networks},
}

@article{wu_comprehensive_2019,
	title = {A comprehensive survey on graph neural networks},
	journal = {arXiv preprint arXiv:1901.00596},
	author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{oh_zero-shot_2017,
	title = {Zero-shot task generalization with multi-task deep reinforcement learning},
	booktitle = {{ICML}},
	author = {Oh, Junhyuk and Singh, Satinder and Lee, Honglak and Kohli, Pushmeet},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{arnekvist_vpe:_2018,
	title = {{VPE}: {Variational} policy embedding for transfer reinforcement learning},
	journal = {arXiv preprint arXiv:1809.03548},
	author = {Arnekvist, Isac and Kragic, Danica and Stork, Johannes A.},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{barreto_transfer_2018,
	title = {Transfer in deep reinforcement learning using successor features and generalised policy improvement},
	booktitle = {{ICML}},
	author = {Barreto, André and Borsa, Diana and Quan, John and Schaul, Tom and Silver, David and Hessel, Matteo and Mankowitz, Daniel and Žídek, Augustin and Munos, Rémi},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{barreto_successor_2017,
	title = {Successor features for transfer in reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Barreto, Andre and Dabney, Will and Munos, Remi and Hunt, Jonathan J and Schaul, Tom},
	year = {2017},
 },
}

@inproceedings{spector_sample-efficient_2017,
	title = {Sample-efficient reinforcement learning through transfer and architectural priors},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Spector, Benjamin and Belongie, Serge},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, 68T05},
}

@inproceedings{konidaris_building_2007,
	title = {Building portable options: {Skill} transfer in reinforcement learning},
	booktitle = {{IJCAI}},
	author = {Konidaris, George},
	year = {2007},
}

@inproceedings{abel_policy_2018,
	title = {Policy and value transfer in lifelong reinforcement learning},
	booktitle = {{ICML}},
	author = {Abel, David and Jinnai, Yuu and Guo, Yue and Konidaris, George and Littman, Michael L},
	year = {2018},
}

@article{narasimhan_grounding_2018,
	title = {Grounding language for transfer in deep reinforcement learning},
	volume = {63},
	journal = {Journal of Artificial Intelligence Research},
	author = {Narasimhan, Karthik and Barzilay, Regina and Jaakkola, Tommi},
	year = {2018},
	pages = {849--874},

Uses natural language sentences containing description-like messages on entities in the environment to facilitate knowledge transfer across domains.
},
}

@inproceedings{finn_generalizing_2017,
	title = {Generalizing skills with semi-supervised reinforcement learning},
	booktitle = {{ICLR}},
	author = {Finn, Chelsea and Yu, Tianhe and Fu, Justin and Abbeel, Pieter and Levine, Sergey},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},

Models the problem with limited "labeled MDPs" (MDPs with available rewards) and a large number of "unlabeled MDPs" (MDPs without available rewards) as a semi-supervised reinforcement learning problem.
Uses the learned trajectories as inputs, and learns rewards and new policies simultaneously in new environments where the rewards are unknown. The method is analogous to inverse reinforcement learning.
(Taken from one reviewer) In supervised learning, a significant advance occurred when the framework of semi-supervised learning was adopted, which used the weaker approach of unsupervised learning to infer some property, such as a distance measure or a smoothness regularizer, which could then be used with a small number of labeled examples. The approach rested on the assumption of smoothness on the manifold, typically. This paper attempts to stretch this analogy to reinforcement learning, although the analogy is somewhat incoherent. Labels are not equivalent to reward functions, and positive or negative rewards do not mean the same as positive and negative labels. Still, the paper makes a worthwhile attempt to explore this notion of semi-supervised RL, which is clearly an important area that deserves more attention. The authors use the term "labeled MDP" to mean the typical MDP framework where the reward function is unknown. They use the confusing term "unlabeled MDP" to mean the situation where the reward is unknown, which is technically not an MDP (but a controlled Markov process). 
},
}

@inproceedings{sutton_generalization_1996,
	title = {Generalization in reinforcement learning: {Successful} examples using sparse coarse coding},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Sutton, Richard S},
	editor = {Touretzky, D. S. and Mozer, M. C. and Hasselmo, M. E.},
	year = {1996},
	pages = {1038--1044},

Shows that RL agents can work well with sparse-coarse-coded function approximators.
The intuition is similar to using CNNs as feature extractors in RL agents: Good representations (concise and sufficient) are crucial for RL algorithms.
},
}

@inproceedings{boyan_generalization_1995,
	title = {Generalization in reinforcement learning: {Safely} approximating the value function},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Boyan, Justin A. and Moore, Andrew W.},
	editor = {Tesauro, G. and Touretzky, D. S. and Leen, T. K.},
	year = {1995},
	pages = {369--376},

Shows that value iteration method (in a deterministic environment) with function approximators tends to diverge occasionally.

Presents a method named Grow-Support,  which maintains a support set of states and trains the function approximator with only state-value pairs restored in this set. Additional states are continuously added into the support set if the corresponding RolloutCost (derived from greedy policies commencing in these states) satisfactions are met.

},
}

@inproceedings{taylor_cross-domain_2007,
	title = {Cross-domain transfer for reinforcement learning},
	booktitle = {{ICML}},
	author = {Taylor, Matthew E. and Stone, Peter},
	year = {2007},
	pages = {879--886},
}

@inproceedings{parisotto_actor-mimic:_2016,
	title = {Actor-mimic: {Deep} multitask and transfer reinforcement learning},
	booktitle = {{ICLR}},
	author = {Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
	year = {2016},
	keywords = {Computer Science - Machine Learning},
}

@article{zhang_study_2018,
	title = {A study on overfitting in deep reinforcement learning},
	journal = {arXiv preprint arXiv:1804.06893},
	author = {Zhang, Chiyuan and Vinyals, Oriol and Munos, Remi and Bengio, Samy},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},

Despite their seemlingly-smaller sizes, neural networks employed in RL agents are able to memorize a large number of different environments, leading the agents to overfit the training environment(s) easily.
Environmental stochasticity (e.g. sticky actions, no-op starts) cannot prevent or detect overfitting (although can alleviate it to some extent).
Empirically, when the algorithmic inductive bias and the bias of the task are compatible, more generalizable agents can be obtained.
},
}

@article{zhang_dissection_2018,
	title = {A dissection of overfitting and generalization in continuous reinforcement learning},
	journal = {arXiv preprint arXiv:1806.07937},
	author = {Zhang, Amy and Ballas, Nicolas and Pineau, Joelle},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},

Studies overfitting of RL in continuous space scenarios, including within-task case (only random seeds differ in training and test environments) and out-of-task case (possible distributional shifts exist).
Illustrates that model-based methods in a limited training seed regime will contribute to the agent's overfitting.
},
}

@article{zhang_scheduled_2019,
	title = {Scheduled intrinsic drive: {A} hierarchical take on intrinsically motivated exploration},
	journal = {arXiv preprint arXiv:1903.07400},
	author = {Zhang, Jingwei and Wetzel, Niklas and Dorka, Nicolai and Boedecker, Joschka and Burgard, Wolfram},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{xie_nadpex:_2019,
	title = {{NADPEx}: {An} on-policy temporally consistent exploration method for deep reinforcement learning},
	booktitle = {{ICLR}},
	author = {Xie, Sirui and Huang, Junning and Lei, Lanxin and Liu, Chunxiao and Ma, Zheng and Zhang, Wei and Lin, Liang},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Robotics},
}

@inproceedings{poupart_analytic_2006,
	title = {An analytic solution to discrete {Bayesian} reinforcement learning},
	booktitle = {{ICML}},
	author = {Poupart, Pascal and Vlassis, Nikos and Hoey, Jesse and Regan, Kevin},
	year = {2006},
	pages = {697--704},
}

@inproceedings{garcia_meta-mdp_2019,
	title = {A meta-{MDP} approach to exploration for lifelong reinforcement learning},
	booktitle = {{AAMAS}},
	author = {Garcia, Francisco M. and Thomas, Philip},
	year = {2019},
}

@article{wayne_unsupervised_2018,
	title = {Unsupervised predictive memory in a goal-directed agent},
	journal = {arXiv preprint arXiv:1803.10760},
	author = {Wayne, Greg and Hung, Chia-Chun and Amos, David and Mirza, Mehdi and Ahuja, Arun and Grabska-Barwinska, Agnieszka and Rae, Jack and Mirowski, Piotr and Leibo, Joel Z. and Santoro, Adam and Gemici, Mevlana and Reynolds, Malcolm and Harley, Tim and Abramson, Josh and Mohamed, Shakir and Rezende, Danilo and Saxton, David and Cain, Adam and Hillier, Chloe and Silver, David and Kavukcuoglu, Koray and Botvinick, Matt and Hassabis, Demis and Lillicrap, Timothy},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hong_how_2019,
	title = {How generative adversarial networks and their variants work: {An} overview},
	volume = {52},
	issn = {03600300},
	shorttitle = {How {Generative} {Adversarial} {Networks} and {Their} {Variants} {Work}},
	doi = {10.1145/3301282},
	abstract = {Generative Adversarial Networks (GAN) have received wide attention in the machine learning field for their potential to learn high-dimensional, complex real data distribution. Specifically, they do not rely on any assumptions about the distribution and can generate real-like samples from latent space in a simple manner. This powerful property leads GAN to be applied to various applications such as image synthesis, image attribute editing, image translation, domain adaptation and other academic fields. In this paper, we aim to discuss the details of GAN for those readers who are familiar with, but do not comprehend GAN deeply or who wish to view GAN from various perspectives. In addition, we explain how GAN operates and the fundamental meaning of various objective functions that have been suggested recently. We then focus on how the GAN can be combined with an autoencoder framework. Finally, we enumerate the GAN variants that are applied to various tasks and other fields for those who are interested in exploiting GAN for their research.},
	number = {1},
	journal = {ACM Computing Surveys},
	author = {Hong, Yongjun and Hwang, Uiwon and Yoo, Jaeyoon and Yoon, Sungroh},
	year = {2019},
	keywords = {Computer Science - Machine Learning},
	pages = {1--43},
}

@inproceedings{bellemare_skip_2014,
	title = {Skip context tree switching},
	booktitle = {{ICML}},
	author = {Bellemare, Marc and Veness, Joel and Talvitie, Erik},
	year = {2014},
	pages = {1458--1466},
}

@inproceedings{savinov_episodic_2019,
	title = {Episodic curiosity through reachability},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Savinov, Nikolay and Raichuk, Anton and Marinier, Raphaël and Vincent, Damien and Pollefeys, Marc and Lillicrap, Timothy and Gelly, Sylvain},
	year = {2019},
}

@inproceedings{santoro_simple_2017,
	title = {A simple neural network module for relational reasoning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Santoro, Adam and Raposo, David and Barrett, David G. and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Timothy},
	year = {2017},
	pages = {4967--4976},
}

@inproceedings{burda_exploration_2019,
	title = {Exploration by random network distillation},
	booktitle = {{ICLR}},
	author = {Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
	year = {2019},
}

@article{ecoffet_go-explore:_2019,
	title = {Go-{Explore}: {A} new approach for hard-exploration problems},
	journal = {arXiv preprint arXiv:1901.10995},
	author = {Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
	year = {2019},
}

@inproceedings{chentanez_intrinsically_2005,
	title = {Intrinsically motivated reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chentanez, Nuttapong and Barto, Andrew G. and Singh, Satinder P.},
	year = {2005},
	pages = {1281--1288},
}

@inproceedings{mohamed_variational_2015,
	title = {Variational information maximisation for intrinsically motivated reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Mohamed, Shakir and Rezende, Danilo Jimenez},
	year = {2015},
	pages = {2125--2133},
}

@inproceedings{pathak_curiosity-driven_2017,
	title = {Curiosity-driven exploration by self-supervised prediction},
	booktitle = {{ICML}},
	author = {Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A. and Darrell, Trevor},
	year = {2017},
}

@inproceedings{ostrovski_count-based_2017,
	title = {Count-based exploration with neural density models},
	booktitle = {{ICML}},
	author = {Ostrovski, Georg and Bellemare, Marc G. and Oord, Aaron van den and Munos, Rémi},
	year = {2017},
}

@article{osband_randomized_2018,
	title = {Randomized prior functions for deep reinforcement learning},
	journal = {arXiv preprint arXiv:1806.03335},
	author = {Osband, Ian and Aslanides, John and Cassirer, Albin},
	year = {2018},
}

@inproceedings{schmidhuber_planning_1993,
	title = {Planning simple trajectories using neural subgoal generators},
	volume = {2},
	isbn = {0-262-63149-0},
	booktitle = {From {Animals} to {Animats} 2: {Proceedings} of the {Second} {International} {Conference} on {Simulation} of {Adaptive} {Behavior}},
	author = {Schmidhuber, Jürgen and Wahnsiedler, Reiner},
	year = {1993},
	pages = {196},
}

@article{barto_recent_2003,
	title = {Recent advances in hierarchical reinforcement learning},
	volume = {13},
	number = {1-2},
	journal = {Discrete event dynamic systems},
	author = {Barto, Andrew G. and Mahadevan, Sridhar},
	year = {2003},
	pages = {41--77},
}

@inproceedings{parr_reinforcement_1998,
	title = {Reinforcement learning with hierarchies of machines},
	booktitle = {Advances in neural information processing systems},
	author = {Parr, Ronald and Russell, Stuart J.},
	year = {1998},
	pages = {1043--1049},
}

@article{nakkiran_deep_2019,
	title = {Deep double descent: {Where} bigger models and more data hurt},
	journal = {arXiv preprint arXiv:1912.02292},
	author = {Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
	year = {2019},
}

@inproceedings{anand_unsupervised_2019,
	title = {Unsupervised state representation learning in atari},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Anand, Ankesh and Racah, Evan and Ozair, Sherjil and Bengio, Yoshua and Côté, Marc-Alexandre and Hjelm, R. Devon},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{hadsell_dimensionality_2006,
	title = {Dimensionality reduction by learning an invariant mapping},
	isbn = {978-0-7695-2597-6},
	doi = {10.1109/CVPR.2006.100},
	booktitle = {2006 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Hadsell, R. and Chopra, S. and LeCun, Y.},
	year = {2006},
	pages = {1735--1742},
}

@inproceedings{todorov_mujoco_2012,
	title = {{MuJoCo}: {A} physics engine for model-based control},
	isbn = {1-4673-1736-5},
	booktitle = {International {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
	year = {2012},
	pages = {5026--5033},
}

@inproceedings{finn_probabilistic_2018,
	title = {Probabilistic model-agnostic meta-learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Finn, Chelsea and Xu, Kelvin and Levine, Sergey},
	year = {2018},
	pages = {12},
}

@inproceedings{kipf_contrastive_2020,
	title = {Contrastive learning of structured world models},
	booktitle = {{ICLR}},
	author = {Kipf, Thomas and Welling, Max},
	year = {2020},
}

@inproceedings{nachum_why_2019,
	title = {Why does hierarchy (sometimes) work so well in reinforcement learning?},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} {DeepRL} {Workshop}},
	author = {Nachum, Ofir and Tang, Haoran and Lu, Xingyu and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{klambauer_self-normalizing_2017,
	title = {Self-normalizing neural networks},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Klambauer, Günter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
	year = {2017},
	pages = {971--980},
}

@article{hendrycks_gaussian_2016,
	title = {Gaussian error linear units ({GELUs})},
	journal = {arXiv preprint arXiv:1606.08415},
	author = {Hendrycks, Dan and Gimpel, Kevin},
	year = {2016},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{chen_learning_2019-1,
	title = {Learning effective subgoals with multi-task hierarchical reinforcement learning},
	booktitle = {{IJCAI} {Workshop}},
	author = {Chen, Dagui and Yan, Qi and Guo, Shangqi and Yang, Zhile and Su, Xin and Chen, Feng},
	year = {2019},
}

@inproceedings{ren_likelihood_2019-1,
	title = {Likelihood ratios for out-of-distribution detection},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ren, Jie and Liu, Peter J. and Fertig, Emily and Snoek, Jasper and Poplin, Ryan and DePristo, Mark A. and Dillon, Joshua V. and Lakshminarayanan, Balaji},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{kolve_ai2-thor:_2019,
	title = {{AI2}-{THOR}: {An} interactive {3D} environment for visual {AI}},
	shorttitle = {{AI2}-{THOR}},
	journal = {arXiv preprint arXiv:1712.05474},
	author = {Kolve, Eric and Mottaghi, Roozbeh and Han, Winson and VanderBilt, Eli and Weihs, Luca and Herrasti, Alvaro and Gordon, Daniel and Zhu, Yuke and Gupta, Abhinav and Farhadi, Ali},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{fujimoto_off-policy_2019,
	title = {Off-policy deep reinforcement learning without exploration},
	booktitle = {{ICML}},
	author = {Fujimoto, Scott and Meger, David and Precup, Doina},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{leike_ai_2017,
	title = {{AI} safety gridworlds},
	journal = {arXiv preprint arXiv:1711.09883},
	author = {Leike, Jan and Martic, Miljan and Krakovna, Victoria and Ortega, Pedro A. and Everitt, Tom and Lefrancq, Andrew and Orseau, Laurent and Legg, Shane},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{moldovan_safe_2012,
	title = {Safe exploration in markov decision processes},
	language = {en},
	booktitle = {{ICML}},
	author = {Moldovan, Teodor Mihai and Abbeel, Pieter},
	year = {2012},
}

@article{garcia_safe_2012,
	title = {Safe exploration of state and action spaces in reinforcement learning},
	volume = {45},
	journal = {Journal of Artificial Intelligence Research},
	author = {Garcia, Javier and Fernández, Fernando},
	year = {2012},
	pages = {515--564},
}

@article{mannucci_safe_2017,
	title = {Safe exploration algorithms for reinforcement learning controllers},
	volume = {29},
	number = {4},
	journal = {IEEE transactions on neural networks and learning systems},
	author = {Mannucci, Tommaso and van Kampen, Erik-Jan and de Visser, Cornelis and Chu, Qiping},
	year = {2017},
	pages = {1069--1081},
}

@article{dalal_safe_2018,
	title = {Safe exploration in continuous action spaces},
	journal = {arXiv preprint arXiv:1801.08757},
	author = {Dalal, Gal and Dvijotham, Krishnamurthy and Vecerik, Matej and Hester, Todd and Paduraru, Cosmin and Tassa, Yuval},
	year = {2018},
}

@inproceedings{turchetta_safe_2016,
	title = {Safe exploration in finite markov decision processes with gaussian processes},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
	year = {2016},
	pages = {4312--4320},
}

@inproceedings{hans_safe_2008,
	title = {Safe exploration for reinforcement learning},
	booktitle = {{ESANN}},
	author = {Hans, Alexander and Schneegaß, Daniel and Schäfer, Anton Maximilian and Udluft, Steffen},
	year = {2008},
	pages = {143--148},
}

@inproceedings{lu_image_1998,
	title = {Image manifolds},
	volume = {3307},
	booktitle = {Applications of {Artificial} {Neural} {Networks} in {Image} {Processing} {III}},
	author = {Lu, Haw-Minn and Fainman, Yeshaiahu and Hecht-Nielsen, Robert},
	year = {1998},
	pages = {52--63},
}

@inproceedings{nasiriany_planning_2019,
	title = {Planning with goal-conditioned policies},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Nasiriany, Soroush and Pong, Vitchyr H. and Lin, Steven and Levine, Sergey},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
	pages = {14814--14825},
}

@article{he_momentum_2019,
	title = {Momentum contrast for unsupervised visual representation learning},
	journal = {arXiv preprint arXiv:1911.05722},
	author = {He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{silver_general_2018,
	title = {A general reinforcement learning algorithm that masters chess, shogi, and {Go} through self-play},
	volume = {362},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.aar6404},
	number = {6419},
	journal = {Science},
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	year = {2018},
	pages = {1140--1144},
}

@article{berner_dota_2019,
	title = {Dota 2 with large scale deep reinforcement learning},
	journal = {arXiv preprint arXiv:1912.06680},
	author = {Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and Józefowicz, Rafal and Gray, Scott and Olsson, Catherine and Pachocki, Jakub and Petrov, Michael and Salimans, Tim and Schlatter, Jeremy and Schneider, Jonas and Sidor, Szymon and Sutskever, Ilya and Tang, Jie and Wolski, Filip and Zhang, Susan},
	year = {2019},
}

@inproceedings{harutyunyan_hindsight_2019,
	title = {Hindsight credit assignment},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Harutyunyan, Anna and Dabney, Will and Mesnard, Thomas and Azar, Mohammad and Piot, Bilal and Heess, Nicolas and van Hasselt, Hado and Wayne, Greg and Singh, Satinder and Precup, Doina and Munos, Remi},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{maalouf_fast_2019,
	title = {Fast and accurate least-mean-squares solvers},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Maalouf, Alaa and Jubran, Ibrahim and Feldman, Dan},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{szegedy_rethinking_2016,
	address = {Las Vegas, NV, USA},
	title = {Rethinking the inception architecture for computer vision},
	isbn = {978-1-4673-8851-1},
	doi = {10.1109/CVPR.2016.308},
	language = {en},
	booktitle = {{CVPR}},
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	year = {2016},
	pages = {2818--2826},
}

@article{he_rethinking_2018,
	title = {Rethinking {ImageNet} pre-training},
	journal = {arXiv preprint arXiv:1811.08883},
	author = {He, Kaiming and Girshick, Ross and Dollár, Piotr},
	year = {2018},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{sener_multi-task_2018,
	title = {Multi-task learning as multi-objective optimization},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Sener, Ozan and Koltun, Vladlen},
	year = {2018},
	pages = {527--538},
}

@article{srivastava_training_2019,
	title = {Training agents using upside-down reinforcement learning},
	journal = {arXiv preprint arXiv:1912.02877},
	author = {Srivastava, Rupesh Kumar and Shyam, Pranav and Mutz, Filipe and Jaśkowski, Wojciech and Schmidhuber, Jürgen},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@article{schmidhuber_reinforcement_2019,
	title = {Reinforcement learning upside down: {Don}'t predict rewards -- just map them to actions},
	shorttitle = {Reinforcement {Learning} {Upside} {Down}},
	journal = {arXiv preprint arXiv:1912.02875},
	author = {Schmidhuber, Juergen},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{lin_distributional_2019,
	title = {Distributional reward decomposition for reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lin, Zichuan and Zhao, Li and Yang, Derek and Qin, Tao and Liu, Tie-Yan and Yang, Guangwen},
	year = {2019},
}

@inproceedings{ho_generative_2016-1,
	title = {Generative adversarial imitation learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ho, Jonathan and Ermon, Stefano},
	year = {2016},
}

@article{thrun_issues_1993,
	title = {Issues in using function approximation for reinforcement learning},
	journal = {Proceedings of the 1993 Connectionist Models Summer School Hillsdale, NJ. Lawrence Erlbaum},
	author = {Thrun, Sebastian and Schwartz, Anton},
	year = {1993},
}

@inproceedings{van_hasselt_deep_2016,
	title = {Deep reinforcement learning with double {Q}-learning},
	booktitle = {{AAAI}},
	author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
	year = {2016},
}

@inproceedings{ren_exploration_2019,
	title = {Exploration via hindsight goal generation},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ren, Zhizhou and Dong, Kefan and Zhou, Yuan and Liu, Qiang and Peng, Jian},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {13464--13474},
}

@inproceedings{ciosek_better_2019,
	title = {Better exploration with optimistic actor critic},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ciosek, Kamil and Vuong, Quan and Loftin, Robert and Hofmann, Katja},
	year = {2019},
}

@inproceedings{chen_deep_2019,
	title = {Deep meta metric learning},
	booktitle = {{ICCV}},
	author = {Chen, Guangyi and Zhang, Tianren and Lu, Jiwen and Zhou, Jie},
	year = {2019},
}

@inproceedings{miryoosefi_reinforcement_2019,
	title = {Reinforcement learning with convex constraints},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Miryoosefi, Sobhan and Brantley, Kianté and Daumé III, Hal and Dudik, Miroslav and Schapire, Robert},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory},
}

@article{graves_neural_2014,
	title = {Neural turing machines},
	language = {en},
	journal = {arXiv preprint arXiv:1410.5401},
	author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
	year = {2014},
	keywords = {Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{he_mask_2017,
	title = {Mask {R}-{CNN}},
	booktitle = {{ICCV}},
	author = {He, Kaiming and Gkioxari, Georgia and Dollár, Piotr and Girshick, Ross},
	year = {2017},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{juliani_obstacle_2019,
	title = {Obstacle tower: {A} generalization challenge in vision, control, and planning},
	shorttitle = {Obstacle {Tower}},
	booktitle = {{IJCAI}},
	author = {Juliani, Arthur and Khalifa, Ahmed and Berges, Vincent-Pierre and Harper, Jonathan and Teng, Ervin and Henry, Hunter and Crespi, Adam and Togelius, Julian and Lange, Danny},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{agrawal_differentiable_2019,
	title = {Differentiable convex optimization layers},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Agrawal, Akshay and Amos, Brandon and Barratt, Shane and Boyd, Stephen},
	year = {2019},
}

@article{wang_learning_2016,
	title = {Learning to reinforcement learn},
	journal = {arXiv preprint arXiv:1611.05763},
	author = {Wang, Jane X. and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z. and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{wu_scalable_2017,
	title = {Scalable trust-region method for deep reinforcement learning using {Kronecker}-factored approximation},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wu, Yuhuai and Mansimov, Elman and Liao, Shun and Grosse, Roger and Ba, Jimmy},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@article{tang_adversarial_2019,
	title = {Adversarial attack type {I}: {Cheat} classifiers by significant changes},
	shorttitle = {Adversarial {Attack} {Type} {I}},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Tang, Sanli and Huang, Xiaolin and Chen, Mingjian and Sun, Chengjin and Yang, Jie},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{stadie_considerations_2018,
	title = {Some considerations on learning to explore via meta-reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Stadie, Bradly C and Yang, Ge and Houthooft, Rein and Chen, Xi and Duan, Yan and Wu, Yuhuai and Abbeel, Pieter and Sutskever, Ilya},
	year = {2018},
}

@inproceedings{kaliszyk_reinforcement_2018,
	title = {Reinforcement learning of theorem proving},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kaliszyk, Cezary and Urban, Josef and Michalewski, Henryk and Olšák, Miroslav},
	year = {2018},
}

@book{sutton_reinforcement_2018,
	address = {Cambridge, Massachusetts},
	edition = {Second edition},
	series = {Adaptive computation and machine learning series},
	title = {Reinforcement learning: {An} introduction},
	isbn = {978-0-262-03924-6},
	shorttitle = {Reinforcement learning},
	language = {en},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	year = {2018},
	keywords = {Reinforcement learning},
}

@article{dulac-arnold_challenges_2019,
	title = {Challenges of real-world reinforcement learning},
	journal = {arXiv preprint arXiv:1904.12901},
	author = {Dulac-Arnold, Gabriel and Mankowitz, Daniel and Hester, Todd},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{kingma_auto-encoding_2014,
	title = {Auto-encoding variational bayes},
	booktitle = {{ICLR}},
	author = {Kingma, Diederik P. and Welling, Max},
	year = {2014},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{higgins_beta-vae:_2017,
	title = {Beta-{VAE}: {Learning} basic visual concepts with a constrained variational framework.},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
	year = {2017},
}

@inproceedings{nair_visual_2018,
	title = {Visual reinforcement learning with imagined goals},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
	year = {2018},
	pages = {9209--9220},
}

@inproceedings{li_multi-view_2019,
	title = {Multi-view reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Li, Minne and Wu, Lisheng and Ammar, Haitham Bou and Wang, Jun},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{girshick_rich_2014,
	title = {Rich feature hierarchies for accurate object detection and semantic segmentation},
	booktitle = {{CVPR}},
	author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	year = {2014},
}

@article{arulkumaran_brief_2017,
	title = {A brief survey of deep reinforcement learning},
	volume = {34},
	issn = {1053-5888},
	doi = {10.1109/MSP.2017.2743240},
	number = {6},
	journal = {IEEE Signal Processing Magazine},
	author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	pages = {26--38},
}

@inproceedings{gruslys_reactor:_2018,
	title = {The reactor: {A} fast and sample-efficient actor-critic agent for reinforcement learning},
	booktitle = {{ICLR}},
	author = {Gruslys, Audrunas and Dabney, Will and Azar, Mohammad Gheshlaghi and Piot, Bilal and Bellemare, Marc and Munos, Remi},
	year = {2018},
	keywords = {Computer Science - Artificial Intelligence},
}

@inproceedings{li_hierarchical_2019,
	title = {Hierarchical reinforcement learning with advantage-based auxiliary rewards},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Li, Siyuan and Wang, Rui and Tang, Minxue and Zhang, Chongjie},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{mott_towards_2019,
	title = {Towards interpretable reinforcement learning using attention augmented agents},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Mott, Alex and Zoran, Daniel and Chrzanowski, Mike and Wierstra, Daan and Rezende, Danilo J.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{lee_sample-efficient_2019,
	title = {Sample-efficient deep reinforcement learning via episodic backward update},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lee, Su Young and Choi, Sungik and Chung, Sae-Young},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{sohn_improved_2016,
	title = {Improved deep metric learning with multi-class {N}-pair loss objective},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Sohn, Kihyuk},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
}

@inproceedings{movshovitz-attias_no_2017,
	title = {No fuss distance metric learning using proxies},
	isbn = {978-1-5386-1032-9},
	doi = {10.1109/ICCV.2017.47},
	language = {en},
	booktitle = {{ICCV}},
	author = {Movshovitz-Attias, Yair and Toshev, Alexander and Leung, Thomas K. and Ioffe, Sergey and Singh, Saurabh},
	year = {2017},
	pages = {360--368},
}

@inproceedings{hoffer_deep_2015,
	title = {Deep metric learning using triplet network},
	booktitle = {{ICLR} {Workshop}},
	author = {Hoffer, Elad and Ailon, Nir},
	year = {2015},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{liu_sphereface:_2017,
	title = {{SphereFace}: {Deep} hypersphere embedding for face recognition},
	booktitle = {{CVPR}},
	author = {Liu, Weiyang and Wen, Yandong and Yu, Zhiding and Li, Ming and Raj, Bhiksha and Song, Le},
	year = {2017},
}

@article{yi_deep_2014,
	title = {Deep metric learning for practical person re-identification},
	journal = {arXiv preprint arXiv:1407.4979},
	author = {Yi, Dong and Lei, Zhen and Li, Stan Z.},
	year = {2014},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{hu_discriminative_2014,
	title = {Discriminative deep metric learning for face verification in the wild},
	booktitle = {{CVPR}},
	author = {Hu, Junlin and Lu, Jiwen and Tan, Yap-Peng},
	year = {2014},
}

@inproceedings{schroff_facenet:_2015,
	title = {{FaceNet}: {A} unified embedding for face recognition and clustering},
	booktitle = {{CVPR}},
	author = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
	year = {2015},
}

@inproceedings{sermanet_time-contrastive_2018,
	title = {Time-contrastive networks: {Self}-supervised learning from video},
	booktitle = {{ICRA}},
	author = {Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey},
	year = {2018},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
}

@inproceedings{hjelm_learning_2019,
	title = {Learning deep representations by mutual information estimation and maximization},
	booktitle = {{ICLR}},
	author = {Hjelm, R. Devon and Fedorov, Alex and Lavoie-Marchildon, Samuel and Grewal, Karan and Bachman, Phil and Trischler, Adam and Bengio, Yoshua},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{belghazi_mine:_2018,
	title = {{MINE}: {Mutual} information neural estimation},
	booktitle = {{ICML}},
	author = {Belghazi, Mohamed Ishmael and Baratin, Aristide and Rajeswar, Sai and Ozair, Sherjil and Bengio, Yoshua and Courville, Aaron and Hjelm, R. Devon},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{oord_representation_2018,
	title = {Representation learning with contrastive predictive coding},
	journal = {arXiv preprint arXiv:1807.03748},
	author = {Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{levy_learning_2019,
	title = {Learning multi-level hierarchies with hindsight},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Levy, Andrew and Konidaris, George and Platt, Robert and Saenko, Kate},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics},
}

@inproceedings{dwiel_hierarchical_2019,
	title = {Hierarchical policy learning is sensitive to goal space design},
	booktitle = {{ICLR} {Workshop}},
	author = {Dwiel, Zach and Candadai, Madhavun and Phielipp, Mariano and Bansal, Arjun K.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{hein_why_2019,
	title = {Why {ReLU} networks yield high-confidence predictions far away from the training data and how to mitigate the problem},
	booktitle = {{CVPR}},
	author = {Hein, Matthias and Andriushchenko, Maksym and Bitterwolf, Julian},
	year = {2019},
}

@inproceedings{nachum_near-optimal_2019,
	title = {Near-optimal representation learning for hierarchical reinforcement learning},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
	year = {2019},
	keywords = {Computer Science - Artificial Intelligence},
}

@inproceedings{jiang_language_2019,
	title = {Language as an abstraction for hierarchical deep reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Jiang, Yiding and Gu, Shixiang and Murphy, Kevin and Finn, Chelsea},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{lee_sample-efficient_2019-1,
	title = {Sample-efficient deep reinforcement learning via episodic backward update},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lee, Su Young and Choi, Sungik and Chung, Sae-Young},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{czarnecki_distilling_2019,
	title = {Distilling policy distillation},
	booktitle = {{AISTATS}},
	author = {Czarnecki, Wojciech Marian and Pascanu, Razvan and Osindero, Simon and Jayakumar, Siddhant M. and Swirszcz, Grzegorz and Jaderberg, Max},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{dayan_feudal_1992,
	title = {Feudal reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dayan, Peter and Hinton, Geoffrey E},
	editor = {Hanson, S. J. and Cowan, J. D. and Giles, C. L.},
	year = {1992},
	pages = {271--278},
}

@inproceedings{kulkarni_hierarchical_2016,
	title = {Hierarchical deep reinforcement learning: {Integrating} temporal abstraction and intrinsic motivation},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kulkarni, Tejas D. and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
	year = {2016},
	pages = {3675--3683},
}

@inproceedings{mnih_asynchronous_2016,
	title = {Asynchronous methods for deep reinforcement learning},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	year = {2016},
	pages = {1928--1937},
}

@inproceedings{schaul_universal_2015,
	title = {Universal value function approximators},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
	year = {2015},
	pages = {1312--1320},

Extends the conventional value function by taking the goal into account: from Q(s, a) to Q(s, a, g).
Facilitates transfer learning in the situations in which only goals are different.
Generalized value functions can be used as features to represent the state, as a form of predictive representation.
},
}

@inproceedings{vezhnevets_feudal_2017,
	title = {{FeUdal} networks for hierarchical reinforcement learning},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
	year = {2017},
	pages = {3540--3549},
}

@inproceedings{rusu_policy_2016,
	title = {Policy distillation},
	booktitle = {{ICLR}},
	author = {Rusu, Andrei A. and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
	year = {2016},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{tessler_deep_2017,
	title = {A deep hierarchical approach to lifelong learning in minecraft},
	booktitle = {{AAAI}},
	author = {Tessler, Chen and Givony, Shahar and Zahavy, Tom and Mankowitz, Daniel J. and Mannor, Shie},
	year = {2017},
}

@inproceedings{vezhnevets_strategic_2016,
	title = {Strategic attentive writer for learning macro-actions},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Vezhnevets, Alexander and Mnih, Volodymyr and Osindero, Simon and Graves, Alex and Vinyals, Oriol and Agapiou, John},
	year = {2016},
}

@phdthesis{precup_temporal_2000,
	address = {Amherst},
	title = {Temporal abstraction in reinforcement learning},
	school = {University of Massachusetts},
	author = {Precup, Doina},
	year = {2000},
}

@inproceedings{shu_hierarchical_2018,
	title = {Hierarchical and interpretable skill acquisition in multi-task reinforcement learning},
	booktitle = {{ICLR}},
	author = {Shu, Tianmin and Xiong, Caiming and Socher, Richard},
	year = {2018},
}

@inproceedings{florensa_stochastic_2017,
	title = {Stochastic neural networks for hierarchical reinforcement learning},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Florensa, Carlos and Duan, Yan and Abbeel, Pieter},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics},
}

@article{sutton_between_1999,
	title = {Between {MDPs} and semi-{MDPs}: {A} framework for temporal abstraction in reinforcement learning},
	volume = {112},
	issn = {00043702},
	shorttitle = {Between {MDPs} and semi-{MDPs}},
	doi = {10.1016/S0004-3702(99)00052-1},
	language = {en},
	number = {1-2},
	journal = {Artificial Intelligence},
	author = {Sutton, Richard S. and Precup, Doina and Singh, Satinder},
	year = {1999},
	pages = {181--211},
}

@inproceedings{galashov_information_2019,
	title = {Information asymmetry in {KL}-regularized {RL}},
	booktitle = {{ICLR}},
	author = {Galashov, Alexandre and Jayakumar, Siddhant M. and Hasenclever, Leonard and Tirumala, Dhruva and Schwarz, Jonathan and Desjardins, Guillaume and Czarnecki, Wojciech M. and Teh, Yee Whye and Pascanu, Razvan and Heess, Nicolas},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{teh_distral:_2017,
	title = {Distral: {Robust} multitask reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
	year = {2017},
}

@inproceedings{xu_deep_2019,
	title = {Deep flow-guided video inpainting},
	booktitle = {{CVPR}},
	author = {Xu, Rui and Li, Xiaoxiao and Zhou, Bolei and Loy, Chen Change},
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{rafati_unsupervised_2019,
	title = {Unsupervised methods for subgoal discovery during intrinsic motivation in model-free hierarchical reinforcement learning},
	booktitle = {Proceedings of the 2nd {Workshop} on {Knowledge} {Extraction} from {Games} co-located with 33rd {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Rafati, Jacob and Noelle, David C},
	year = {2019},
	pages = {17--25},
}

@inproceedings{ghosh_learning_2019,
	title = {Learning actionable representations with goal-conditioned policies},
	booktitle = {{ICLR}},
	author = {Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{shang_learning_2019,
	title = {Learning world graphs to accelerate hierarchical reinforcement learning},
	language = {en},
	journal = {arXiv preprint arXiv:1907.00664},
	author = {Shang, Wenling and Trott, Alex and Zheng, Stephan and Xiong, Caiming and Socher, Richard},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{fu_ex2:_2017,
	title = {Ex2: {Exploration} with exemplar models for deep reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Fu, Justin and Co-Reyes, John and Levine, Sergey},
	year = {2017},
	pages = {2577--2587},
}

@inproceedings{fortunato_noisy_2018,
	title = {Noisy networks for exploration},
	booktitle = {{ICLR}},
	author = {Fortunato, Meire and Azar, Mohammad Gheshlaghi and Piot, Bilal and Menick, Jacob and Osband, Ian and Graves, Alex and Mnih, Vlad and Munos, Remi and Hassabis, Demis and Pietquin, Olivier},
	year = {2018},
}

@article{zhou_graph_2018,
	title = {Graph neural networks: {A} review of methods and applications},
	journal = {arXiv preprint arXiv:1812.08434},
	author = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Sun, Maosong},
	year = {2018},
}

@article{salimans_learning_2018,
	title = {Learning {Montezuma}'s {Revenge} from a single demonstration},
	journal = {arXiv preprint arXiv:1812.03381},
	author = {Salimans, Tim and Chen, Richard},
	year = {2018},
}

@article{liu_learning_2018,
	title = {Learning abstract models for long-horizon exploration},
	author = {Liu, Evan Zheran and Keramati, Ramtin and Seshadri, Sudarshan and Guu, Kelvin and Pasupat, Panupong and Brunskill, Emma and Liang, Percy},
	year = {2018},
}

@article{pugh_quality_2016,
	title = {Quality diversity: {A} new frontier for evolutionary computation},
	volume = {3},
	journal = {Frontiers in Robotics and AI},
	author = {Pugh, Justin K. and Soros, Lisa B. and Stanley, Kenneth O.},
	year = {2016},
	pages = {40},
}

@inproceedings{lu_non-delusional_2018,
	title = {Non-delusional {Q}-learning and value-iteration},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lu, Tyler and Schuurmans, Dale and Boutilier, Craig},
	year = {2018},
	pages = {9970--9980},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is all you need},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	year = {2017},
	pages = {5998--6008},
}

@article{zambaldi_relational_2018,
	title = {Relational deep reinforcement learning},
	journal = {arXiv preprint arXiv:1806.01830},
	author = {Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward},
	year = {2018},
}

@article{ha_world_2018,
	title = {World models},
	journal = {arXiv preprint arXiv:1803.10122},
	author = {Ha, David and Schmidhuber, Jürgen},
	year = {2018},
}

@article{baxter_model_2000,
	title = {A model of inductive bias learning},
	volume = {12},
	journal = {Journal of Artificial Intelligence Research},
	author = {Baxter, Jonathan},
	year = {2000},
	pages = {149--198},
}

@article{hermans_defense_2017,
	title = {In defense of the triplet loss for person re-identification},
	journal = {arXiv preprint arXiv:1703.07737},
	author = {Hermans, Alexander and Beyer, Lucas and Leibe, Bastian},
	year = {2017},
}

@inproceedings{wu_training_2018,
	title = {Training and inference with integers in deep neural networks},
	booktitle = {{ICLR}},
	author = {Wu, Shuang and Li, Guoqi and Chen, Feng and Shi, Luping},
	year = {2018},
}

@inproceedings{sun_beyond_2018,
	title = {Beyond part models: {Person} retrieval with refined part pooling (and a strong convolutional baseline)},
	booktitle = {{ECCV}},
	author = {Sun, Yifan and Zheng, Liang and Yang, Yi and Tian, Qi and Wang, Shengjin},
	year = {2018},
}

@article{wang_learning_2018,
	title = {Learning discriminative features with multiple granularities for person re-identification},
	journal = {arXiv preprint arXiv:1804.01438},
	author = {Wang, Guanshuo and Yuan, Yufeng and Chen, Xiong and Li, Jiwei and Zhou, Xi},
	year = {2018},
}

@inproceedings{he_deep_2016,
	title = {Deep residual learning for image recognition},
	booktitle = {{CVPR}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year = {2016},
	pages = {770--778},
}

@inproceedings{he_delving_2015,
	title = {Delving deep into rectifiers: {Surpassing} human-level performance on imagenet classification},
	booktitle = {{ICCV}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year = {2015},
	pages = {1026--1034},
}

@article{sung_learning_2017,
	title = {Learning to learn: {Meta}-critic networks for sample efficient learning},
	journal = {arXiv preprint arXiv:1706.09529},
	author = {Sung, Flood and Zhang, Li and Xiang, Tao and Hospedales, Timothy and Yang, Yongxin},
	year = {2017},
}

@inproceedings{mishra_simple_2018,
	title = {A simple neural attentive meta-learner},
	booktitle = {{ICLR}},
	author = {Mishra, Nikhil and Rohaninejad, Mostafa and Chen, Xi and Abbeel, Pieter},
	year = {2018},
}

@inproceedings{snell_prototypical_2017,
	title = {Prototypical networks for few-shot learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Snell, Jake and Swersky, Kevin and Zemel, Richard},
	year = {2017},
	pages = {4077--4087},
}

@inproceedings{finn_model-agnostic_2017,
	title = {Model-agnostic meta-learning for fast adaptation of deep networks},
	booktitle = {{ICML}},
	author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	year = {2017},
	pages = {1126--1135},
}

@article{popov_data-efficient_2017,
	title = {Data-efficient deep reinforcement learning for dexterous manipulation},
	journal = {arXiv preprint arXiv:1704.03073},
	author = {Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-Maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Riedmiller, Martin},
	year = {2017},
}

@inproceedings{bellemare_unifying_2016,
	title = {Unifying count-based exploration and intrinsic motivation},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
	year = {2016},
	pages = {1471--1479},
}

@article{schulman_proximal_2017,
	title = {Proximal policy optimization algorithms},
	journal = {arXiv preprint arXiv:1707.06347},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	year = {2017},
}

@article{stadie_incentivizing_2015,
	title = {Incentivizing exploration in reinforcement learning with deep predictive models},
	journal = {arXiv preprint arXiv:1507.00814},
	author = {Stadie, Bradly C. and Levine, Sergey and Abbeel, Pieter},
	year = {2015},
}

@article{schmidhuber_formal_2010,
	title = {Formal theory of creativity, fun, and intrinsic motivation (1990–2010)},
	volume = {2},
	number = {3},
	journal = {IEEE Transactions on Autonomous Mental Development},
	author = {Schmidhuber, Jürgen},
	year = {2010},
	pages = {230--247},
}

@inproceedings{schmidhuber_possibility_1991,
	title = {A possibility for implementing curiosity and boredom in model-building neural controllers},
	booktitle = {Proc. of the international conference on simulation of adaptive behavior: {From} animals to animats},
	author = {Schmidhuber, Jürgen},
	year = {1991},
	pages = {222--227},
}

@inproceedings{lopes_exploration_2012,
	title = {Exploration in model-based reinforcement learning by empirically estimating learning progress},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lopes, Manuel and Lang, Tobias and Toussaint, Marc and Oudeyer, Pierre-Yves},
	year = {2012},
	pages = {206--214},
}

@inproceedings{houthooft_vime:_2016,
	title = {Vime: {Variational} information maximizing exploration},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
	year = {2016},
	pages = {1109--1117},
}

@inproceedings{kaplanis_continual_2018,
	title = {Continual reinforcement learning with complex synapses},
	booktitle = {{ICML}},
	author = {Kaplanis, Christos and Shanahan, Murray and Clopath, Claudia},
	year = {2018},
}

@inproceedings{isele_selective_2018,
	title = {Selective experience replay for lifelong learning},
	booktitle = {{AAAI}},
	author = {Isele, David and Cosgun, Akansel},
	year = {2018},
}

@inproceedings{houthooft_evolved_2018,
	title = {Evolved policy gradients},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Houthooft, Rein and Chen, Yuhua and Isola, Phillip and Stadie, Bradly and Wolski, Filip and Ho, OpenAI Jonathan and Abbeel, Pieter},
	year = {2018},
	pages = {5400--5409},
}

@inproceedings{zhang_generating_2020,
	title = {Generating adjacency-constrained subgoals in hierarchical reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhang, Tianren and Guo, Shangqi and Tan, Tian and Hu, Xiaolin and Chen, Feng},
	year = {2020},
	pages = {21579--21590},
}

@article{jaderberg_human-level_2019,
	title = {Human-level performance in {3D} multiplayer games with population-based reinforcement learning},
	volume = {364},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.aau6249},
	language = {en},
	number = {6443},
	journal = {Science},
	author = {Jaderberg, Max and Czarnecki, Wojciech M. and Dunning, Iain and Marris, Luke and Lever, Guy and Castañeda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C. and Morcos, Ari S. and Ruderman, Avraham and Sonnerat, Nicolas and Green, Tim and Deason, Louise and Leibo, Joel Z. and Silver, David and Hassabis, Demis and Kavukcuoglu, Koray and Graepel, Thore},
	year = {2019},
	pages = {859--865},
}

@article{eslami_neural_2018,
	title = {Neural scene representation and rendering},
	volume = {360},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.aar6170},
	number = {6394},
	journal = {Science},
	author = {Eslami, S. M. Ali and Jimenez Rezende, Danilo and Besse, Frederic and Viola, Fabio and Morcos, Ari S. and Garnelo, Marta and Ruderman, Avraham and Rusu, Andrei A. and Danihelka, Ivo and Gregor, Karol and Reichert, David P. and Buesing, Lars and Weber, Theophane and Vinyals, Oriol and Rosenbaum, Dan and Rabinowitz, Neil and King, Helen and Hillier, Chloe and Botvinick, Matt and Wierstra, Daan and Kavukcuoglu, Koray and Hassabis, Demis},
	year = {2018},
	pages = {1204--1210},
}

@inproceedings{mannor_dynamic_2004,
	title = {Dynamic abstraction in reinforcement learning via clustering},
	booktitle = {{ICML}},
	author = {Mannor, Shie and Menache, Ishai and Hoze, Amit and Klein, Uri},
	year = {2004},
}

@inproceedings{arjona-medina_rudder:_2019,
	title = {{RUDDER}: {Return} decomposition for delayed rewards},
	shorttitle = {{RUDDER}},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Arjona-Medina, Jose A. and Gillhofer, Michael and Widrich, Michael and Unterthiner, Thomas and Brandstetter, Johannes and Hochreiter, Sepp},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Mathematics - Optimization and Control},
}

@article{liu_sequence_2019,
	title = {Sequence modeling of temporal credit assignment for episodic reinforcement learning},
	journal = {arXiv preprint arXiv:1905.13420},
	author = {Liu, Yang and Luo, Yunan and Zhong, Yuanyi and Chen, Xi and Liu, Qiang and Peng, Jian},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{yu_gradient_2020,
	title = {Gradient surgery for multi-task learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
}

@inproceedings{badia_never_2020,
	title = {Never give up: {Learning} directed exploration strategies},
	booktitle = {{ICLR}},
	author = {Badia, Adrià Puigdomènech and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Daniel and Piot, Bilal and Tieleman, Steven Kapturowski Olivier and Arjovsky, Martín and Pritzel, Alexander and Blundell, Andew Bolt Charles},
	year = {2020},
}

@article{badia_agent57_2020,
	title = {Agent57: {Outperforming} the atari human benchmark},
	shorttitle = {Agent57},
	journal = {arXiv preprint arXiv:2003.13350},
	author = {Badia, Adrià Puigdomènech and Piot, Bilal and Kapturowski, Steven and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Daniel and Blundell, Charles},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{kapturowski_recurrent_2019,
	title = {Recurrent experience replay in distributed reinforcement learning},
	booktitle = {{ICLR}},
	author = {Kapturowski, Steven and Ostrovski, Georg and Quan, John and Munos, Remi and Dabney, Will},
	year = {2019},
}

@inproceedings{harb_when_2018,
	title = {When waiting is not an option: {Learning} options with a deliberation cost},
	booktitle = {{AAAI}},
	author = {Harb, Jean and Bacon, Pierre-Luc and Klissarov, Martin and Precup, Doina},
	year = {2018},
	keywords = {Computer Science - Artificial Intelligence},
}

@inproceedings{dietterich_maxq_1998,
	title = {The {MAXQ} method for hierarchical reinforcement learning},
	booktitle = {{ICML}},
	author = {Dietterich, Thomas G},
	year = {1998},
}

@article{graves_hybrid_2016,
	title = {Hybrid computing using a neural network with dynamic external memory},
	volume = {538},
	issn = {1476-4687},
	doi = {10.1038/nature20101},
	language = {en},
	number = {7626},
	journal = {Nature},
	author = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwińska, Agnieszka and Colmenarejo, Sergio Gómez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and Badia, Adrià Puigdomènech and Hermann, Karl Moritz and Zwols, Yori and Ostrovski, Georg and Cain, Adam and King, Helen and Summerfield, Christopher and Blunsom, Phil and Kavukcuoglu, Koray and Hassabis, Demis},
	year = {2016},
	pages = {471--476},
}

@inproceedings{khadka_collaborative_2019,
	title = {Collaborative evolutionary reinforcement learning},
	booktitle = {{ICML}},
	author = {Khadka, Shauharda and Majumdar, Somdeb and Nassar, Tarek and Dwiel, Zach and Tumer, Evren and Miret, Santiago and Liu, Yinyin and Tumer, Kagan},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{khadka_collaborative_2019-1,
	title = {Collaborative evolutionary reinforcement learning},
	booktitle = {{ICML}},
	author = {Khadka, Shauharda and Majumdar, Somdeb and Nassar, Tarek and Dwiel, Zach and Tumer, Evren and Miret, Santiago and Liu, Yinyin and Tumer, Kagan},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{schmidhuber_curious_1991,
	address = {Singapore},
	title = {Curious model-building control systems},
	isbn = {978-0-7803-0227-3},
	doi = {10.1109/IJCNN.1991.170605},
	booktitle = {{IEEE} {International} {Joint} {Conference} on {Neural} {Networks}},
	author = {Schmidhuber, J.},
	year = {1991},
	pages = {1458--1463 vol.2},
}

@article{achiam_surprise-based_2017,
	title = {Surprise-based intrinsic motivation for deep reinforcement learning},
	journal = {arXiv preprint arXiv:1703.01732},
	author = {Achiam, Joshua and Sastry, Shankar},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@article{oudeyer_intrinsic_2007,
	title = {Intrinsic motivation systems for autonomous mental development},
	volume = {11},
	issn = {1089-778X},
	doi = {10.1109/TEVC.2006.890271},
	number = {2},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Oudeyer, Pierre-Yves and Kaplan, Frdric and Hafner, Verena V.},
	year = {2007},
	pages = {265--286},
}

@article{lee_efficient_2020,
	title = {Efficient exploration via state marginal matching},
	language = {en},
	journal = {arXiv preprint arXiv:1906.05274},
	author = {Lee, Lisa and Eysenbach, Benjamin and Parisotto, Emilio and Xing, Eric and Levine, Sergey and Salakhutdinov, Ruslan},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{gu_deep_2017,
	title = {Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
	booktitle = {{ICRA}},
	author = {Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@article{plappert_multi-goal_2018,
	title = {Multi-goal reinforcement learning: {Challenging} robotics environments and request for research},
	shorttitle = {Multi-goal reinforcement learning},
	journal = {arXiv preprint arXiv:1802.09464},
	author = {Plappert, Matthias and Andrychowicz, Marcin and Ray, Alex and McGrew, Bob and Baker, Bowen and Powell, Glenn and Schneider, Jonas and Tobin, Josh and Chociej, Maciek and Welinder, Peter and Kumar, Vikash and Zaremba, Wojciech},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{levine_guided_2013,
	title = {Guided policy search},
	booktitle = {{ICML}},
	author = {Levine, Sergey and Koltun, Vladlen},
	year = {2013},
}

@article{silver_mastering_2017,
	title = {Mastering the game of {Go} without human knowledge},
	volume = {550},
	number = {7676},
	journal = {Nature},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian},
	year = {2017},
	pages = {354--359},
}

@article{silver_mastering_2016,
	title = {Mastering the game of {Go} with deep neural networks and tree search},
	volume = {529},
	number = {7587},
	journal = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc},
	year = {2016},
	pages = {484--489},
}

@article{mnih_human-level_2015,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	number = {7540},
	journal = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg},
	year = {2015},
	pages = {529--533},
}

@article{devlin_bert_2018,
	title = {{BERT}: {Pre}-training of deep bidirectional transformers for language understanding},
	shorttitle = {Bert},
	journal = {arXiv preprint arXiv:1810.04805},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year = {2018},
	keywords = {Computer Science - Computation and Language},
}

@article{nichol_first-order_2018,
	title = {On first-order meta-learning algorithms},
	journal = {arXiv preprint arXiv:1803.02999},
	author = {Nichol, Alex and Achiam, Joshua and Schulman, John},
	year = {2018},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{andreas_modular_2017,
	title = {Modular multitask reinforcement learning with policy sketches},
	language = {en},
	booktitle = {{ICML}},
	author = {Andreas, Jacob and Klein, Dan and Levine, Sergey},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{tallec_making_2019,
	title = {Making deep {Q}-learning methods robust to time discretization},
	booktitle = {{ICML}},
	author = {Tallec, Corentin and Blier, Léonard and Ollivier, Yann},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hashem_improving_1995,
	title = {Improving model accuracy using optimal linear combinations of trained neural networks},
	volume = {6},
	issn = {10459227},
	doi = {10.1109/72.377990},
	number = {3},
	journal = {IEEE Transactions on Neural Networks},
	author = {Hashem, S. and Schmeiser, B.},
	year = {1995},
	pages = {792--794},
}

@inproceedings{kwon_global_2019,
	title = {Global convergence of {EM} algorithm for mixtures of two component linear regression},
	language = {en},
	booktitle = {{COLT}},
	author = {Kwon, Jeongyeol and Qian, Wei and Caramanis, Constantine and Chen, Yudong and Davis, Damek},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Statistics Theory},
}

@inproceedings{jana_extrapolating_2020,
	language = {en},
	booktitle = {{COLT}},
	author = {Jana, Soham and Polyanskiy, Yury and Wu, Yihong},
	year = {2020},
}

@article{van_de_ven_brain-inspired_2020,
	title = {Brain-inspired replay for continual learning with artificial neural networks},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	doi = {10.1038/s41467-020-17866-2},
	language = {en},
	number = {1},
	journal = {Nature Communications},
	author = {van de Ven, Gido M. and Siegelmann, Hava T. and Tolias, Andreas S.},
	year = {2020},
	pages = {4069},
}

@inproceedings{dvornik_diversity_2019,
	address = {Seoul, Korea (South)},
	title = {Diversity with cooperation: {Ensemble} methods for few-shot classification},
	isbn = {978-1-72814-803-8},
	shorttitle = {Diversity with cooperation},
	doi = {10.1109/ICCV.2019.00382},
	booktitle = {{ICCV}},
	author = {Dvornik, Nikita and Mairal, Julien and Schmid, Cordelia},
	year = {2019},
	pages = {3722--3730},
}

@inproceedings{alemi_deep_2017,
	title = {Deep variational information bottleneck},
	booktitle = {{ICLR}},
	author = {Alemi, Alexander A. and Fischer, Ian and Dillon, Joshua V. and Murphy, Kevin},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Information Theory},
}

@article{grimm_learning_2019,
	title = {Learning independently-obtainable reward functions},
	journal = {arXiv preprint arXiv:1901.08649},
	author = {Grimm, Christopher and Singh, Satinder},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{zhang_learning_2019,
	title = {Learning novel policies for tasks},
	booktitle = {{ICML}},
	author = {Zhang, Yunbo and Yu, Wenhao and Turk, Greg},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{rusu_progressive_2016-1,
	title = {Progressive neural networks},
	journal = {arXiv preprint arXiv:1606.04671},
	author = {Rusu, Andrei A. and Rabinowitz, Neil C. and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
	year = {2016},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{frans_meta_2018,
	title = {Meta learning shared hierarchies},
	language = {en},
	booktitle = {{ICLR}},
	author = {Frans, Kevin and Ho, Jonathan and Chen, Xi and Abbeel, Pieter and Schulman, John},
	year = {2018},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{ferns_metrics_2004,
	title = {Metrics for finite {Markov} {Decision} {Processes}},
	booktitle = {Proceedings of the 20th {Conference} in {Uncertainty} in {Artificial} {Intelligence}},
	author = {Ferns, Norm and Panangaden, Prakash and Precup, Doina},
	year = {2004},
	pages = {162--169},
}

@inproceedings{fatemi_dead-ends_2019,
	title = {Dead-ends and secure exploration in reinforcement learning},
	booktitle = {{ICML}},
	author = {Fatemi, Mehdi and Sharma, Shikhar},
	year = {2019},
}

@inproceedings{silver_deterministic_2014,
	title = {Deterministic policy gradient algorithms},
	booktitle = {{ICML}},
	author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
	year = {2014},
}

@article{nowozin_f-gan_2016,
	title = {f-{GAN}: {Training} generative neural samplers using variational divergence minimization},
	shorttitle = {F-gan},
	journal = {arXiv preprint arXiv:1606.00709},
	author = {Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
}

@inproceedings{yin_meta-learning_2020,
	title = {Meta-learning without memorization},
	booktitle = {{ICLR}},
	author = {Yin, Mingzhang and Tucker, George and Zhou, Mingyuan and Levine, Sergey and Finn, Chelsea},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{harrison_continuous_2019,
	title = {Continuous meta-learning without tasks},
	booktitle = {{ICLR}},
	author = {Harrison, James and Sharma, Apoorva and Finn, Chelsea and Pavone, Marco},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{zhang_learning_2019-1,
	title = {Learning perceptual inference by contrasting},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhang, Chi and Jia, Baoxiong and Gao, Feng and Zhu, Yixin and Lu, Hongjing and Zhu, Song-Chun},
	year = {2019},
}

@inproceedings{zhang_raven_2019,
	address = {Long Beach, CA, USA},
	title = {Raven: {A} dataset for relational and analogical visual reasoning},
	isbn = {978-1-72813-293-8},
	shorttitle = {Raven},
	doi = {10.1109/CVPR.2019.00546},
	language = {en},
	booktitle = {{CVPR}},
	author = {Zhang, Chi and Gao, Feng and Jia, Baoxiong and Zhu, Yixin and Zhu, Song-Chun},
	year = {2019},
	pages = {5312--5322},
}

@inproceedings{finn_meta-learning_2018,
	title = {Meta-learning and universality: {Deep} representations and gradient descent can approximate any learning algorithm},
	shorttitle = {Meta-learning and universality},
	booktitle = {{ICLR}},
	author = {Finn, Chelsea and Levine, Sergey},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{de_haan_causal_2019,
	title = {Causal confusion in imitation learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {de Haan, Pim and Jayaraman, Dinesh and Levine, Sergey},
	year = {2019},
}

	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Srinivas, Aravind and Laskin, Michael and Abbeel, Pieter},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	pages = {5639--5650},
}

@article{balakrishnan_statistical_2017,
	title = {Statistical guarantees for the {EM} algorithm: {From} population to sample-based analysis},
	volume = {45},
	shorttitle = {Statistical guarantees for the {EM} algorithm},
	journal = {The Annals of Statistics},
	author = {Balakrishnan, Sivaraman and Wainwright, Martin J. and Yu, Bin},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Statistics Theory},
	pages = {77--120},
}

@inproceedings{gopfert_when_2019,
	title = {When can unlabeled data improve the learning rate?},
	language = {en},
	booktitle = {{COLT}},
	author = {Göpfert, Christina and Ben-David, Shai and Bousquet, Olivier and Gelly, Sylvain and Tolstikhin, Ilya and Urner, Ruth},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{kwon_em_2020,
	title = {The {EM} algorithm gives sample-optimality for learning mixtures of well-separated gaussians},
	language = {en},
	booktitle = {{COLT}},
	author = {Kwon, Jeongyeol and Caramanis, Constantine},
	year = {2020},
}

@inproceedings{yehudai_learning_2020,
	title = {Learning a single neuron with gradient methods},
	language = {en},
	booktitle = {{COLT}},
	author = {Yehudai, Gilad and Shamir, Ohad},
	year = {2020},
}

@inproceedings{jin_provably_2020,
	title = {Provably efficient reinforcement learning with linear function approximation},
	language = {en},
	booktitle = {{COLT}},
	author = {Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I.},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@inproceedings{agarwal_theory_2020,
	title = {On the theory of policy gradient methods: {Optimality}, approximation, and distribution shift},
	shorttitle = {On the theory of policy gradient methods},
	booktitle = {{COLT}},
	author = {Agarwal, Alekh and Kakade, Sham M. and Lee, Jason D. and Mahajan, Gaurav},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{radulescu_holistic_2019,
	title = {Holistic reinforcement learning: {The} role of structure and attention},
	volume = {23},
	issn = {13646613},
	shorttitle = {Holistic reinforcement learning},
	doi = {10.1016/j.tics.2019.01.010},
	language = {en},
	number = {4},
	journal = {Trends in Cognitive Sciences},
	author = {Radulescu, Angela and Niv, Yael and Ballard, Ian},
	year = {2019},
	pages = {278--292},
}

@article{gupta_unsupervised_2018,
	title = {Unsupervised meta-learning for reinforcement learning},
	journal = {arXiv preprint arXiv:1806.04640},
	author = {Gupta, Abhishek and Eysenbach, Benjamin and Finn, Chelsea and Levine, Sergey},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{goyal_reinforcement_2020,
	title = {Reinforcement learning with competitive ensembles of information-constrained primitives},
	booktitle = {{ICLR}},
	author = {Goyal, Anirudh and Sodhani, Shagun and Binas, Jonathan and Peng, Xue Bin and Levine, Sergey and Bengio, Yoshua},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{hasselt_double_2010,
	title = {Double {Q}-learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Hasselt, Hado van},
	year = {2010},
}

@inproceedings{zhang_learning_2020,
	title = {Learning with feature and distribution evolvable streams},
	booktitle = {{ICML}},
	author = {Zhang, Zhen-Yu and Zhao, Peng and Jiang, Yuan and Zhou, Zhi-Hua},
	year = {2020},
}

@inproceedings{jain_generalization_2020,
	title = {Generalization to new actions in reinforcement learning},
	booktitle = {{ICML}},
	author = {Jain, Ayush and Szot, Andrew and Lim, Joseph J},
	year = {2020},
}

@inproceedings{shen_deep_2020,
	title = {Deep reinforcement learning with smooth policy},
	booktitle = {{ICML}},
	author = {Shen, Qianli and Li, Yan and Jiang, Haoming and Wang, Zhaoran and Zhao, Tuo},
	year = {2020},
}

@inproceedings{zheng_what_2020,
	title = {What can learned intrinsic rewards capture?},
	booktitle = {{ICML}},
	author = {Zheng, Zeyu and Oh, Junhyuk and Hessel, Matteo and Xu, Zhongwen and Kroiss, Manuel},
	year = {2020},
}

@inproceedings{tang_taylor_2020,
	title = {Taylor expansion policy optimization},
	booktitle = {{ICML}},
	author = {Tang, Yunhao and Valko, Michal and Munos, Remi},
	year = {2020},
}

@inproceedings{fedus_revisiting_2020,
	title = {Revisiting fundamentals of experience replay},
	booktitle = {{ICML}},
	author = {Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
	year = {2020},
}

@inproceedings{recht_hogwild:_2011,
	title = {Hogwild: {A} lock-free approach to parallelizing stochastic gradient descent},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
	year = {2011},
	pages = {9},
}

@inproceedings{greff_neural_2017,
	title = {Neural expectation maximization},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, Jürgen},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, I.2.6},
}

@article{floyd_algorithm_1962,
	title = {Algorithm 97: {Shortest} path},
	volume = {5},
	number = {6},
	journal = {Communications of the ACM},
	author = {Floyd, Robert W.},
	year = {1962},
	pages = {345},
}

@inproceedings{jordan_evaluating_2020,
	title = {Evaluating the performance of reinforcement learning algorithms},
	booktitle = {{ICML}},
	author = {Jordan, Scott M and Chandak, Yash and Cohen, Daniel and Zhang, Mengxue and Thomas, Philip S},
	year = {2020},
}

@inproceedings{ghosh_representations_2020,
	title = {Representations for stable off-policy reinforcement learning},
	booktitle = {{ICML}},
	author = {Ghosh, Dibya and Bellemare, Marc},
	year = {2020},
}

@inproceedings{su_task_2020,
	title = {Task understanding from confusing multi-task data},
	booktitle = {{ICML}},
	author = {Su, Xin and Jiang, Yizhou and Guo, Shangqi and Chen, Feng},
	year = {2020},
}

@inproceedings{mcallester_pac-bayesian_1999,
	title = {{PAC}-{Bayesian} model averaging},
	isbn = {978-1-58113-167-3},
	doi = {10.1145/307400.307435},
	booktitle = {{COLT}},
	author = {McAllester, David A.},
	year = {1999},
}

@inproceedings{pentina_lifelong_2015,
	title = {Lifelong learning with non-i.i.d. tasks},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Pentina, Anastasia and Lampert, Christoph H},
	year = {2015},
}

@inproceedings{machado_eigenoption_2018,
	title = {Eigenoption discovery through the deep successor representation},
	booktitle = {{ICLR}},
	author = {Machado, Marlos C. and Rosenbaum, Clemens and Guo, Xiaoxiao and Liu, Miao and Tesauro, Gerald and Campbell, Murray},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{castro_scalable_2020,
	title = {Scalable methods for computing state similarity in deterministic {Markov} {Decision} {Processes}},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Castro, Pablo Samuel},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {10069--10076},
}

@inproceedings{khetarpal_what_2020,
	title = {What can {I} do here? {A} theory of affordances in reinforcement learning},
	shorttitle = {What can i do here?},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Khetarpal, Khimya and Ahmed, Zafarali and Comanici, Gheorghe and Abel, David and Precup, Doina},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {5243--5253},
}

@inproceedings{zhang_composable_2018,
	title = {Composable planning with attributes},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhang, Amy and Lerer, Adam and Sukhbaatar, Sainbayar and Fergus, Rob and Szlam, Arthur},
	year = {2018},
	keywords = {Computer Science - Artificial Intelligence},
	pages = {5837--5846},
}

@inproceedings{guo_safe_2020,
	title = {Safe deep semi-supervised learning for unseen-class unlabeled data},
	booktitle = {{ICML}},
	author = {Guo, Lan-Zhe and Zhang, Zhen-Yu and Jiang, Yuan and Li, Yu-Feng and Zhou, Zhi-Hua},
	year = {2020},
}

@inproceedings{zhang_class-incremental_2020,
	title = {Class-incremental learning via deep model consolidation},
	language = {en},
	booktitle = {{WACV}},
	author = {Zhang, Junting and Zhang, Jie and Ghosh, Shalini and Li, Dawei and Tasci, Serafettin and Heck, Larry and Zhang, Heming and Kuo, C.-C. Jay},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{maltoni_continuous_2019,
	title = {Continuous learning in single-incremental-task scenarios},
	journal = {arXiv preprint arXiv:1806.08568},
	author = {Maltoni, Davide and Lomonaco, Vincenzo},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{shin_continual_2017,
	title = {Continual learning with deep generative replay},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{rebuffi_icarl_2017,
	address = {Honolulu, HI},
	title = {Icarl: {Incremental} classifier and representation learning},
	isbn = {978-1-5386-0457-1},
	shorttitle = {Icarl},
	doi = {10.1109/CVPR.2017.587},
	language = {en},
	booktitle = {{CVPR}},
	author = {Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H.},
	year = {2017},
	pages = {5533--5542},
}

@inproceedings{chen_infogan:_2016,
	title = {{InfoGAN}: {Interpretable} representation learning by information maximizing generative adversarial nets},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
	year = {2016},
}

@article{singh_transfer_1992,
	title = {Transfer of learning by composing solutions of elemental sequential tasks},
	volume = {8},
	journal = {Machine Learning},
	author = {Singh, Satinder Pal},
	year = {1992},
	pages = {323--339},
}

@article{jacobs_task_1991,
	title = {Task decomposition through competition in a modular connectionist architecture: {The} what and where vision tasks},
	volume = {15},
	number = {2},
	journal = {Cognitive Science},
	author = {Jacobs, Robert A and Jordan, Michael I and Barto, Andrew G},
	year = {1991},
	pages = {219--250},
}

@article{pless_survey_2009,
	title = {A survey of manifold learning for images},
	volume = {1},
	issn = {1882-6695},
	doi = {10.2197/ipsjtcva.1.83},
	language = {en},
	journal = {IPSJ Transactions on Computer Vision and Applications},
	author = {Pless, Robert and Souvenir, Richard},
	year = {2009},
	pages = {83--94},
}

@inproceedings{hausman_learning_2018,
	title = {Learning an embedding space for transferable robot skills},
	booktitle = {{ICLR}},
	author = {Hausman, Karol and Springenberg, Jost Tobias and Wang, Ziyu and Heess, Nicolas and Riedmiller, Martin},
	year = {2018},
}

@inproceedings{kurach_google_2020,
	title = {Google research football: {A} novel reinforcement learning environment},
	abstract = {Recent progress in the ﬁeld of reinforcement learning has been accelerated by virtual learning environments such as video games, where novel algorithms and ideas can be quickly tested in a safe and reproducible manner. We introduce the Google Research Football Environment, a new reinforcement learning environment where agents are trained to play football in an advanced, physics-based 3D simulator. The resulting environment is challenging, easy to use and customize, and it is available under a permissive open-source license. In addition, it provides support for multiplayer and multi-agent experiments. We propose three full-game scenarios of varying difﬁculty with the Football Benchmarks and report baseline results for three commonly used reinforcement algorithms (IMPALA, PPO, and Ape-X DQN). We also provide a diverse set of simpler scenarios with the Football Academy and showcase several promising research directions.},
	booktitle = {{AAAI}},
	author = {Kurach, Karol and Raichuk, Anton},
	year = {2020},
}

@inproceedings{yu_meta-world_2019,
	title = {Meta-world: {A} benchmark and evaluation for multi-task and meta reinforcement learning},
	booktitle = {{CoRL}},
	author = {Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
	year = {2019},
}

@inproceedings{eysenbach_diversity_2019,
	title = {Diversity is all you need: {Learning} skills without a reward function},
	shorttitle = {Diversity is all you need},
	booktitle = {{ICLR}},
	author = {Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
	year = {2019},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{gupta_meta-reinforcement_2018,
	title = {Meta-reinforcement learning of structured exploration strategies},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Gupta, Abhishek and Mendonca, Russell and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
	year = {2018},
}

@inproceedings{felzenszwalb_discriminatively_2008,
	title = {A discriminatively trained, multiscale, deformable part model},
	isbn = {1-4244-2242-6},
	booktitle = {{CVPR}},
	author = {Felzenszwalb, Pedro and McAllester, David and Ramanan, Deva},
	year = {2008},
	pages = {1--8},
}

@inproceedings{dalal_histograms_2005,
	title = {Histograms of oriented gradients for human detection},
	isbn = {0-7695-2372-2},
	booktitle = {{CVPR}},
	author = {Dalal, Navneet and Triggs, Bill},
	year = {2005},
	pages = {886--893},
}

@inproceedings{viola_rapid_2001,
	title = {Rapid object detection using a boosted cascade of simple features},
	booktitle = {{CVPR}},
	author = {Viola, Paul and Jones, Michael},
	year = {2001},
}

@inproceedings{li_selective_2019,
	title = {Selective kernel networks},
	booktitle = {{CVPR}},
	author = {Li, Xiang and Wang, Wenhai and Hu, Xiaolin and Yang, Jian},
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{sutskever_sequence_2014,
	title = {Sequence to sequence learning with neural networks},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
	year = {2014},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{derezinski_improved_2020,
	title = {Improved guarantees and a multiple-descent curve for {Column} {Subset} {Selection} and the {Nystrom} method},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Derezinski, Michal and Khanna, Rajiv and Mahoney, Michael W.},
	year = {2020},
}

@inproceedings{nagarajan_uniform_2019,
	title = {Uniform convergence may be unable to explain generalization in deep learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Nagarajan, Vaishnavh and Kolter, J. Zico},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{diakonikolas_distribution-independent_2019,
	title = {Distribution-independent {PAC} learning of halfspaces with {Massart} noise},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Diakonikolas, Ilias and Gouleakis, Themis and Tzamos, Christos},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Data Structures and Algorithms, Mathematics - Statistics Theory},
}

@inproceedings{chen_neural_2018,
	title = {Neural ordinary differential equations},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{ashtiani_nearly_2018,
	title = {Nearly tight sample complexity bounds for learning mixtures of {Gaussians} via sample compression schemes},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ashtiani, Hassan and Ben-David, Shai and Harvey, Nicholas and Liaw, Christopher and Mehrabian, Abbas and Plan, Yaniv},
	year = {2018},
}

@inproceedings{scaman_optimal_2018,
	title = {Optimal algorithms for non-smooth distributed optimization in networks},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Scaman, Kevin and Bach, Francis and Bubeck, Sébastien and Lee, Yin Tat and Massoulié, Laurent},
	year = {2018},
	keywords = {Mathematics - Optimization and Control},
}

@inproceedings{jitkrittum_linear-time_2017,
	title = {A linear-time kernel goodness-of-fit test},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Jitkrittum, Wittawat and Xu, Wenkai and Szabo, Zoltan and Fukumizu, Kenji and Gretton, Arthur},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, I.2.6, 46E22, 62G10, G.3},
}

@inproceedings{brown_safe_2017,
	title = {Safe and nested subgame solving for imperfect-information games},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Brown, Noam and Sandholm, Tuomas},
	year = {2017},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory},
}

@inproceedings{ishida_learning_2017,
	title = {Learning from complementary labels},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ishida, Takashi and Niu, Gang and Hu, Weihua and Sugiyama, Masashi},
	year = {2017},
}

@article{zhu_multi-label_2018,
	title = {Multi-label learning with global and local label correlation},
	volume = {30},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2017.2785795},
	number = {6},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Zhu, Y. and Kwok, J. T. and Zhou, Z.},
	year = {2018},
	keywords = {Training data, learning (artificial intelligence), Correlation, data handling, Electronic mail, Estimation, full-label cases, Global and local label correlation, global label correlation, GLOCAL, label manifold, label manifolds, latent label representation, local label correlation, Manifolds, Matrix decomposition, missing labels, missing-label cases, missing-label data, multi-label learning, multilabel approach, multilabel learning, Optimization, partial labels},
	pages = {1081--1094},
}

@article{ando_framework_2005,
	title = {A framework for learning predictive structures from multiple tasks and unlabeled data},
	volume = {6},
	number = {11},
	journal = {Journal of Machine Learning Research},
	author = {Ando, Rie Kubota and Zhang, Tong and Bartlett, Peter},
	year = {2005},
	pages = {1817--1853},
}

@article{zhang_review_2014,
	title = {A review on multi-label learning algorithms},
	volume = {26},
	issn = {1041-4347},
	doi = {10.1109/TKDE.2013.39},
	language = {en},
	number = {8},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Zhang, Min-Ling and Zhou, Zhi-Hua},
	year = {2014},
	pages = {1819--1837},
}

@incollection{goos_exploiting_2003,
	address = {Berlin, Heidelberg},
	title = {Exploiting task relatedness for multiple task learning},
	volume = {2777},
	isbn = {978-3-540-40720-1 978-3-540-45167-9},
	language = {en},
	booktitle = {Learning {Theory} and {Kernel} {Machines}},
	author = {Ben-David, Shai and Schuller, Reba},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Schölkopf, Bernhard and Warmuth, Manfred K.},
	year = {2003},
	doi = {10.1007/978-3-540-45167-9_41},
	pages = {567--580},
}

@article{ciliberto_consistent_2017,
	title = {Consistent multitask learning with nonlinear output relations},
	journal = {arXiv preprint arXiv:1705.08118},
	author = {Ciliberto, Carlo and Rudi, Alessandro and Rosasco, Lorenzo and Pontil, Massimiliano},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ibarz_how_2021,
	title = {How to train your robot with deep reinforcement learning; lessons we've learned},
	issn = {0278-3649, 1741-3176},
	doi = {10.1177/0278364920987859},
	language = {en},
	journal = {The International Journal of Robotics Research},
	author = {Ibarz, Julian and Tan, Jie and Finn, Chelsea and Kalakrishnan, Mrinal and Pastor, Peter and Levine, Sergey},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics},
}

@article{vapnik_overview_1999,
	title = {An overview of statistical learning theory},
	volume = {10},
	issn = {10459227},
	doi = {10.1109/72.788640},
	language = {en},
	number = {5},
	journal = {IEEE Transactions on Neural Networks},
	author = {Vapnik, V.N.},
	year = {1999},
	pages = {988--999},
}

@article{valiant_theory_1984,
	title = {A theory of the learnable},
	volume = {27},
	number = {11},
	journal = {Communications of the ACM},
	author = {Valiant, Leslie G.},
	year = {1984},
	pages = {1134--1142},
}

@article{baram_action_2021,
	title = {Action redundancy in reinforcement learning},
	journal = {arXiv preprint arXiv:2102.11329},
	author = {Baram, Nir and Tennenholtz, Guy and Mannor, Shie},
	year = {2021},
}

@inproceedings{anschel_averaged-dqn_2017,
	title = {Averaged-{DQN}: {Variance} reduction and stabilization for deep reinforcement learning},
	booktitle = {{ICML}},
	author = {Anschel, Oron and Baram, Nir and Shimkin, Nahum},
	year = {2017},
}

@inproceedings{mcnamara_risk_2017,
	title = {Risk bounds for transferring representations with and without fine-tuning},
	booktitle = {{ICML}},
	author = {McNamara, Daniel and Balcan, Maria-Florina},
	year = {2017},
}

@inproceedings{zhang_learning_2018,
	title = {Learning to multitask},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhang, Yu and Wei, Ying and Yang, Qiang},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{franceschi_bilevel_2018,
	title = {Bilevel programming for hyperparameter optimization and meta-learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Franceschi, Luca and Frasconi, Paolo and Salzo, Saverio and Grazzi, Riccardo and Pontil, Massimiliano},
	year = {2018},
	pages = {10},
}

@article{crammer_learning_2008,
	title = {Learning from multiple sources},
	volume = {9},
	language = {en},
	number = {1},
	journal = {Journal of Machine Learning Research},
	author = {Crammer, Koby and Kearns, Michael and Wortman, Jennifer},
	year = {2008},
	pages = {1757--1774},
}

@article{ecoffet_first_2021,
	title = {First return, then explore},
	volume = {590},
	issn = {0028-0836, 1476-4687},
	doi = {10.1038/s41586-020-03157-9},
	language = {en},
	number = {7847},
	journal = {Nature},
	author = {Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
	year = {2021},
	pages = {580--586},
}

@book{vapnik_nature_2013,
	title = {The nature of statistical learning theory},
	isbn = {1-4757-3264-3},
	author = {Vapnik, Vladimir},
	year = {2013},
}

@inproceedings{santoro_meta-learning_2016,
	title = {Meta-learning with memory-augmented neural networks},
	booktitle = {{ICML}},
	author = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
	year = {2016},
}

@inproceedings{jacob_clustered_2008,
	title = {Clustered multi-task learning: {A} convex formulation},
	shorttitle = {Clustered multi-task learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Jacob, Laurent and Bach, Francis and Vert, Jean-Philippe},
	year = {2008},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{wang_global_2020-1,
	title = {On the global optimality of model-agnostic meta-learning: {Reinforcement} learning and supervised learning},
	booktitle = {{ICML}},
	author = {Wang, Lingxiao and Cai, Qi and Yang, Zhuoyan and Wang, Zhaoran},
	year = {2020},
}

@article{zhu_dark_2020,
	title = {Dark, beyond deep: {A} paradigm shift to cognitive ai with humanlike common sense},
	volume = {6},
	issn = {20958099},
	shorttitle = {Dark, beyond deep},
	doi = {10.1016/j.eng.2020.01.011},
	language = {en},
	number = {3},
	journal = {Engineering},
	author = {Zhu, Yixin and Gao, Tao and Fan, Lifeng and Huang, Siyuan and Edmonds, Mark and Liu, Hangxin and Gao, Feng and Zhang, Chi and Qi, Siyuan and Wu, Ying Nian and Tenenbaum, Joshua B. and Zhu, Song-Chun},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	pages = {310--345},
}

@inproceedings{gleave_quantifying_2021,
	title = {Quantifying differences in reward functions},
	language = {en},
	author = {Gleave, Adam and Dennis, Michael D. and Legg, Shane and Russell, Stuart and Leike, Jan},
	year = {2021},
}

@inproceedings{agarwal_contrastive_2021,
	title = {Contrastive behavioral similarity embeddings for generalization in reinforcement learning},
	language = {en},
	author = {Agarwal, Rishabh and Machado, Marlos C. and Castro, Pablo Samuel and Bellemare, Marc G.},
	year = {2021},
}

@inproceedings{zhao_mutual_2021,
	title = {Mutual information state intrinsic control},
	language = {en},
	author = {Zhao, Rui and Gao, Yang and Abbeel, Pieter and Tresp, Volker and Xu, Wei},
	year = {2021},
}

@inproceedings{liu_regularization_2021,
	title = {Regularization matters in policy optimization - an empirical study on continuous control},
	language = {en},
	author = {Liu, Zhuang and Li, Xuanlin and Kang, Bingyi and Darrell, Trevor},
	year = {2021},
}

@inproceedings{sanyal_how_2021,
	title = {How benign is benign overfitting ?},
	author = {Sanyal, Amartya and Dokania, Puneet K. and Kanade, Varun and Torr, Philip},
	year = {2021},
}

@inproceedings{zadaianchuk_self-supervised_2021,
	title = {Self-supervised visual reinforcement learning with object-centric representations},
	language = {en},
	author = {Zadaianchuk, Andrii and Seitzer, Maximilian and Martius, Georg},
	year = {2021},
}

@inproceedings{co-reyes_evolving_2021,
	title = {Evolving reinforcement learning algorithms},
	author = {Co-Reyes, John D. and Miao, Yingjie and Peng, Daiyi and Le, Quoc V. and Levine, Sergey and Lee, Honglak and Faust, Aleksandra},
	year = {2021},
}

@inproceedings{xu_how_2021,
	title = {How neural networks extrapolate: {From} feedforward to graph neural networks},
	booktitle = {{ICLR}},
	author = {Xu, Keyulu and Li, Jingling and Zhang, Mozhi and Du, Simon S. and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
	year = {2021},
}

@article{jolicoeur-martineau_gradient_2019,
	title = {Gradient penalty from a maximum margin perspective},
	journal = {arXiv preprint arXiv:1910.06922},
	author = {Jolicoeur-Martineau, Alexia and Mitliagkas, Ioannis},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{argyriou_multi-task_2006,
	title = {Multi-task feature learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Argyriou, Andreas and Evgeniou, Theodoros and Pontil, Massimiliano},
	year = {2006},
}

@article{kaiser_one_2017,
	title = {One model to learn them all},
	journal = {arXiv preprint arXiv:1706.05137},
	author = {Kaiser, Lukasz and Gomez, Aidan N. and Shazeer, Noam and Vaswani, Ashish and Parmar, Niki and Jones, Llion and Uszkoreit, Jakob},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{agarwal_learning_2010,
	title = {Learning multiple tasks using manifold regularization},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Agarwal, Arvind and Gerber, Samuel and Daume, Hal},
	year = {2010},
	pages = {9},
}

@article{argyriou_convex_2008,
	title = {Convex multi-task feature learning},
	volume = {73},
	number = {3},
	journal = {Machine learning},
	author = {Argyriou, Andreas and Evgeniou, Theodoros and Pontil, Massimiliano},
	year = {2008},
	pages = {243--272},
}

@inproceedings{kumar_learning_2012,
	title = {Learning task grouping and overlap in multi-task learning},
	booktitle = {{ICML}},
	author = {Kumar, Abhishek and Iii, Hal Daumé},
	year = {2012},
}

@inproceedings{meyerson_modular_2019,
	title = {Modular universal reparameterization: {Deep} multi-task learning across diverse domains},
	shorttitle = {Modular universal reparameterization},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Meyerson, Elliot and Miikkulainen, Risto},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{chen_closer_2019,
	title = {A closer look at few-shot classification},
	booktitle = {{ICLR}},
	author = {Chen, Wei-Yu and Liu, Yen-Cheng and Kira, Zsolt and Wang, Yu-Chiang Frank and Huang, Jia-Bin},
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{raghu_rapid_2020,
	title = {Rapid learning or feature reuse? {Towards} understanding the effectiveness of {MAML}},
	shorttitle = {Rapid learning or feature reuse?},
	booktitle = {{ICLR}},
	author = {Raghu, Aniruddh and Raghu, Maithra and Bengio, Samy and Vinyals, Oriol},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{haussler_probably_1990,
	title = {Probably approximately correct learning},
	booktitle = {{AAAI}},
	author = {Haussler, David},
	year = {1990},
}

@book{devroye_probabilistic_1996,
	address = {New York, NY},
	series = {Stochastic {Modelling} and {Applied} {Probability}},
	title = {A probabilistic theory of pattern recognition},
	volume = {31},
	isbn = {978-1-4612-6877-2 978-1-4612-0711-5},
	language = {en},
	author = {Devroye, Luc and Györfi, László and Lugosi, Gábor},
	editor = {Karatzas, I. and Yor, M.},
	year = {1996},
	doi = {10.1007/978-1-4612-0711-5},
}

@inproceedings{arora_theoretical_2019,
	title = {A theoretical analysis of contrastive unsupervised representation learning},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Arora, Sanjeev and Khandeparkar, Hrishikesh and Khodak, Mikhail and Plevrakis, Orestis and Saunshi, Nikunj},
	year = {2019},
	pages = {5628--5637},
}

@inproceedings{hyvarinen_nonlinear_2019,
	title = {Nonlinear {ICA} using auxiliary variables and generalized contrastive learning},
	booktitle = {{AISTATS}},
	author = {Hyvarinen, Aapo and Sasaki, Hiroaki and Turner, Richard E},
	year = {2019},
}

@article{hyvarinen_nonlinear_1999,
	title = {Nonlinear independent component analysis: {Existence} and uniqueness results},
	volume = {12},
	shorttitle = {Nonlinear independent component analysis},
	number = {3},
	journal = {Neural Networks},
	author = {Hyvärinen, Aapo and Pajunen, Petteri},
	year = {1999},
	pages = {429--439},
}

@article{lake_human-level_2015,
	title = {Human-level concept learning through probabilistic program induction},
	volume = {350},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.aab3050},
	language = {en},
	number = {6266},
	journal = {Science},
	author = {Lake, B. M. and Salakhutdinov, R. and Tenenbaum, J. B.},
	year = {2015},
	pages = {1332--1338},
}

@article{levine_offline_2020,
	title = {Offline reinforcement learning: {Tutorial}, review, and perspectives on open problems},
	shorttitle = {Offline reinforcement learning},
	journal = {arXiv preprint arXiv:2005.01643},
	author = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{wang_is_2020,
	title = {Is long horizon {RL} more difficult than short horizon {RL}?},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wang, Ruosong and Du, Simon S and Yang, Lin F. and Kakade, Sham M.},
	year = {2020},
}

@article{arjovsky_invariant_2019,
	title = {Invariant risk minimization},
	journal = {arXiv preprint arXiv:1907.02893},
	author = {Arjovsky, Martin and Bottou, Léon and Gulrajani, Ishaan and Lopez-Paz, David},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{caruana_multitask_1997,
	title = {Multitask learning},
	volume = {28},
	number = {1},
	journal = {Machine learning},
	author = {Caruana, Rich},
	year = {1997},
	pages = {41--75},
}

@article{maass_agnostic_1995,
	title = {Agnostic {PAC} learning of functions on analog neural nets},
	volume = {7},
	issn = {0899-7667, 1530-888X},
	doi = {10.1162/neco.1995.7.5.1054},
	language = {en},
	number = {5},
	journal = {Neural Computation},
	author = {Maass, Wolfgang},
	year = {1995},
	pages = {1054--1078},
}

@article{hallak_contextual_2015,
	title = {Contextual markov decision processes},
	journal = {arXiv preprint arXiv:1502.02259},
	author = {Hallak, Assaf and Di Castro, Dotan and Mannor, Shie},
	year = {2015},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{klink_self-paced_2020,
	title = {Self-paced deep reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Klink, Pascal and D'Eramo, Carlo and Peters, Jan and Pajarinen, Joni},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{banino_vector-based_2018,
	title = {Vector-based navigation using grid-like representations in artificial agents},
	volume = {557},
	issn = {0028-0836, 1476-4687},
	doi = {10.1038/s41586-018-0102-6},
	language = {en},
	number = {7705},
	journal = {Nature},
	author = {Banino, Andrea and Barry, Caswell and Uria, Benigno and Blundell, Charles and Lillicrap, Timothy and Mirowski, Piotr and Pritzel, Alexander and Chadwick, Martin J. and Degris, Thomas and Modayil, Joseph and Wayne, Greg and Soyer, Hubert and Viola, Fabio and Zhang, Brian and Goroshin, Ross and Rabinowitz, Neil and Pascanu, Razvan and Beattie, Charlie and Petersen, Stig and Sadik, Amir and Gaffney, Stephen and King, Helen and Kavukcuoglu, Koray and Hassabis, Demis and Hadsell, Raia and Kumaran, Dharshan},
	year = {2018},
	pages = {429--433},
}

@inproceedings{radford_learning_2021,
	title = {Learning transferable visual models from natural language supervision},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
	year = {2021},
	pages = {8748--8763},
}

@inproceedings{brown_language_2020,
	title = {Language models are few-shot learners},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	year = {2020},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{al-shedivat_continuous_2018,
	title = {Continuous adaptation via meta-learning in nonstationary and competitive environments},
	booktitle = {{ICLR}},
	author = {Al-Shedivat, Maruan and Bansal, Trapit and Burda, Yuri and Sutskever, Ilya and Mordatch, Igor and Abbeel, Pieter},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{tax_one-class_2002,
	title = {One-class classification: {Concept} learning in the absence of counter-examples.},
	author = {Tax, David Martinus Johannes},
	year = {2002},
}

@inproceedings{ba_generalization_2020,
	title = {Generalization of two-layer neural networks: {An} asymptotic viewpoint},
	booktitle = {{ICLR}},
	author = {Ba, Jimmy and Erdogdu, Murat A and Suzuki, Taiji and Wu, Denny and Zhang, Tianzong},
	year = {2020},
}

@inproceedings{rudner_outcome-driven_2020,
	title = {Outcome-driven reinforcement learning via variational inference},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} {Deep} {RL} {Workshop}},
	author = {Rudner, Tim G J and Pong, Vitchyr H and McAllister, Rowan and Gal, Yarin and Levine, Sergey},
	year = {2020},
}

@inproceedings{daskalakis_ten_2017,
	title = {Ten steps of {EM} suffice for mixtures of two gaussians},
	booktitle = {{COLT}},
	author = {Daskalakis, Constantinos and Tzamos, Christos and Zampetakis, Manolis},
	year = {2017},
	keywords = {Statistics - Machine Learning, Computer Science - Data Structures and Algorithms, Mathematics - Statistics Theory},
}

@inproceedings{dagan_learning_2019,
	title = {Learning from weakly dependent data under {Dobrushin}'s condition},
	language = {en},
	booktitle = {{COLT}},
	author = {Dagan, Yuval and Daskalakis, Constantinos and Dikkala, Nishanth and Jayanti, Siddhartha},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{rajaraman_toward_2020,
	title = {Toward the fundamental limits of imitation learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Rajaraman, Nived and Yang, Lin F. and Jiao, Jiantao and Ramachandran, Kannan},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Mathematics - Optimization and Control},
}

@inproceedings{dziugaite_computing_2017,
	title = {Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data},
	language = {en},
	booktitle = {Conference on {Uncertainty} in {Artificial} {Intelligence} ({UAI})},
	author = {Dziugaite, Gintare Karolina and Roy, Daniel M.},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{pentina_lifelong_2016,
	title = {Lifelong learning with weighted majority votes},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Pentina, Anastasia and Urner, Ruth},
	year = {2016},
}

@article{amit_lifelong_2019,
	title = {Lifelong learning and inductive bias},
	volume = {29},
	journal = {Current Opinion in Behavioral Sciences},
	author = {Amit, Ron and Meir, Ron},
	year = {2019},
	pages = {51--54},
}

@book{goertzel_artificial_2007,
	title = {Artificial general intelligence},
	volume = {2},
	author = {Goertzel, Ben and Pennachin, Cassio},
	year = {2007},
}

@incollection{gabbay_artificial_2007,
	address = {Berlin, Heidelberg},
	title = {Artificial {Brains}},
	isbn = {978-3-540-23733-4 978-3-540-68677-4},
	language = {en},
	booktitle = {Artificial {General} {Intelligence}},
	author = {de Garis, Hugo},
	editor = {Gabbay, Dov M. and Siekmann, Jörg and Bundy, A. and Carbonell, J. G. and Pinkal, M. and Uszkoreit, H. and Veloso, M. and Wahlster, W. and Wooldridge, M. J. and Goertzel, Ben and Pennachin, Cassio},
	year = {2007},
	doi = {10.1007/978-3-540-68677-4_5},
	pages = {159--174},
}

@inproceedings{balcan_efficient_2015,
	title = {Efficient representations for lifelong learning and autoencoding},
	booktitle = {Conference on {Learning} {Theory}},
	author = {Balcan, Maria-Florina and Blum, Avrim and Vempala, Santosh},
	year = {2015},
	pages = {191--210},
}

@inproceedings{thrun_is_1996,
	title = {Is learning the n-th thing any easier than learning the first?},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Thrun, Sebastian},
	year = {1996},
}

@article{bengio_representation_2013,
	title = {Representation learning: {A} review and new perspectives},
	volume = {35},
	number = {8},
	journal = {IEEE transactions on pattern analysis and machine intelligence},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	year = {2013},
	pages = {1798--1828},
}

@inproceedings{maurer_vector-contraction_2016,
	title = {A vector-contraction inequality for {Rademacher} complexities},
	booktitle = {International {Conference} on {Algorithmic} {Learning} {Theory}},
	author = {Maurer, Andreas},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{locatello_challenging_2019,
	title = {Challenging common assumptions in the unsupervised learning of disentangled representations},
	booktitle = {{ICML}},
	author = {Locatello, Francesco and Bauer, Stefan and Lucic, Mario and Raetsch, Gunnar and Gelly, Sylvain and Schölkopf, Bernhard and Bachem, Olivier},
	year = {2019},
}

@article{goyal_inductive_2020,
	title = {Inductive biases for deep learning of higher-level cognition},
	journal = {arXiv preprint arXiv:2011.15091},
	author = {Goyal, Anirudh and Bengio, Yoshua},
	year = {2020},
}

@inproceedings{ben-david_analysis_2007,
	title = {Analysis of representations for domain adaptation},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ben-David, Shai and Blitzer, John and Crammer, Koby and Pereira, Fernando},
	year = {2007},
}

@article{ben-david_theory_2010,
	title = {A theory of learning from different domains},
	volume = {79},
	number = {1-2},
	journal = {Machine learning},
	author = {Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
	year = {2010},
	pages = {151--175},
}

@inproceedings{pan_softmax_2020,
	title = {Softmax deep double deterministic policy gradients},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Pan, Ling and Cai, Qingpeng and Huang, Longbo},
	year = {2020},
	keywords = {Computer Science - Machine Learning},
}

@article{raileanu_automatic_2020,
	title = {Automatic data augmentation for generalization in deep reinforcement learning},
	journal = {arXiv preprint arXiv:2006.12862},
	author = {Raileanu, Roberta and Goldstein, Max and Yarats, Denis and Kostrikov, Ilya and Fergus, Rob},
	year = {2020},
}

@inproceedings{li_delta:_2019,
	title = {Delta: {Deep} learning transfer using feature map with attention for convolutional networks},
	booktitle = {{ICLR}},
	author = {Li, Xingjian and Xiong, Haoyi and Wang, Hanchao and Rao, Yuxuan and Liu, Liping and Huan, Jun},
	year = {2019},
}

@inproceedings{machado_laplacian_2017,
	title = {A laplacian framework for option discovery in reinforcement learning},
	booktitle = {{ICML}},
	author = {Machado, Marlos C. and Bellemare, Marc G. and Bowling, Michael},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{dabney_distributional_2020,
	title = {A distributional code for value in dopamine-based reinforcement learning},
	volume = {577},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	doi = {10.1038/s41586-019-1924-6},
	language = {en},
	number = {7792},
	journal = {Nature},
	author = {Dabney, Will and Kurth-Nelson, Zeb and Uchida, Naoshige and Starkweather, Clara Kwon and Hassabis, Demis and Munos, Rémi and Botvinick, Matthew},
	year = {2020},
	pages = {671--675},
}

@inproceedings{wang_improving_2020,
	title = {Improving generalization in reinforcement learning with mixture regularization},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wang, Kaixin and Kang, Bingyi and Shao, Jie and Feng, Jiashi},
	year = {2020},
}

@inproceedings{johnson_malmo_2016,
	title = {The malmo platform for artificial intelligence experimentation},
	booktitle = {{IJCAI}},
	author = {Johnson, Matthew and Hofmann, Katja and Hutton, Tim and Bignell, David},
	year = {2016},
}

@inproceedings{vieillard_munchausen_2020,
	title = {Munchausen reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Vieillard, Nino and Pietquin, Olivier and Geist, Matthieu},
	year = {2020},
}

@inproceedings{chen_modular_2020,
	title = {Modular meta-learning with shrinkage},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chen, Yutian and Friesen, Abram L and Behbahani, Feryal and Doucet, Arnaud and Budden, David and Hoffman, Matthew W and de Freitas, Nando},
	year = {2020},
}

@inproceedings{alet_modular_2018,
	title = {Modular meta-learning},
	booktitle = {{CoRL}},
	author = {Alet, Ferran and Lozano-Pérez, Tomás and Kaelbling, Leslie P.},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Robotics},
}

@article{duncan_neural_2000,
	title = {A neural basis for general intelligence},
	volume = {289},
	language = {en},
	author = {Duncan, John},
	year = {2000},
	pages = {5},
}

@inproceedings{yang_multi-task_2020,
	title = {Multi-task reinforcement learning with soft modularization},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Yang, Ruihan and Xu, Huazhe and Wu, Yi and Wang, Xiaolong},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@article{dempster_maximum_1977,
	title = {Maximum likelihood from incomplete data via the \textit{{EM}} algorithm},
	volume = {39},
	number = {1},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Dempster, Arthur P. and Laird, Nan M. and Rubin, Donald B.},
	year = {1977},
	pages = {1--22},
}

@inproceedings{rolnick_experience_2019,
	title = {Experience replay for continual learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy and Wayne, Gregory},
	year = {2019},
	pages = {350--360},
}

@inproceedings{xu_reinforced_2018,
	title = {Reinforced continual learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Xu, Ju and Zhu, Zhanxing},
	year = {2018},
	pages = {899--908},
}

@article{traore_discorl_2019,
	title = {{DISCORL}: {Continual} reinforcement learning via policy distillation},
	journal = {arXiv preprint arXiv:1907.05855},
	author = {Traoré, René and Caselles-Dupré, Hugo and Lesort, Timothée and Sun, Te and Cai, Guanghang and Díaz-Rodríguez, Natalia and Filliat, David},
	year = {2019},
}

@inproceedings{kaplanis_policy_2019,
	title = {Policy consolidation for continual reinforcement learning},
	booktitle = {{ICML}},
	author = {Kaplanis, Christos and Shanahan, Murray and Clopath, Claudia},
	year = {2019},
}

@inproceedings{deramo_sharing_2020,
	title = {Sharing knowledge in multi-task deep reinforcement learning},
	booktitle = {{ICLR}},
	author = {D’Eramo, Carlo and Tateo, Davide and Bonarini, Andrea and Restelli, Marcello and Peters, Jan},
	year = {2020},
}

@inproceedings{hall_dynamical_2013,
	title = {Dynamical models and tracking regret in online convex programming},
	booktitle = {{ICML}},
	author = {Hall, Eric C. and Willett, Rebecca M.},
	year = {2013},
}

@article{weng_tianshou_2021,
	title = {Tianshou: {A} highly modularized deep reinforcement learning library},
	shorttitle = {Tianshou},
	journal = {arXiv preprint arXiv:2107.14171},
	author = {Weng, Jiayi and Chen, Huayu and Yan, Dong and You, Kaichao and Duburcq, Alexis and Zhang, Minghao and Su, Hang and Zhu, Jun},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{fifty_efficiently_2021,
	title = {Efficiently identifying task groupings for multi-task learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Fifty, Christopher and Amid, Ehsan and Zhao, Zhe and Yu, Tianhe and Anil, Rohan and Finn, Chelsea},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	pages = {27503--27516},
}

@inproceedings{zhang_adaptive_2019,
	title = {Adaptive regret of convex and smooth functions},
	language = {en},
	booktitle = {{ICML}},
	author = {Zhang, Lijun and Liu, Tie-Yan and Zhou, Zhi-Hua},
	year = {2019},
}

@inproceedings{zhang_adaptive_2018,
	title = {Adaptive online learning in dynamic environments},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhang, Lijun and Lu, Shiyin and Zhou, Zhi-Hua},
	year = {2018},
}

@inproceedings{zinkevich_online_2003,
	title = {Online convex programming and generalized infinitesimal gradient ascent},
	language = {en},
	booktitle = {{ICML}},
	author = {Zinkevich, Martin},
	year = {2003},
}

@inproceedings{venkateswaran_environment_2021,
	address = {Virtual Event Singapore},
	title = {Environment agnostic invariant risk minimization for classification of sequential datasets},
	isbn = {978-1-4503-8332-5},
	doi = {10.1145/3447548.3467324},
	language = {en},
	booktitle = {Proceedings of the 27th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	author = {Venkateswaran, Praveen and Muthusamy, Vinod and Isahagian, Vatche and Venkatasubramanian, Nalini},
	year = {2021},
	pages = {1615--1624},
}

@article{choe_empirical_2020,
	title = {An empirical study of invariant risk minimization},
	language = {en},
	journal = {arXiv preprint arXiv:2004.05007},
	author = {Choe, Yo Joong and Ham, Jiyeon and Park, Kyubyong},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{schulman_trust_2015,
	title = {Trust region policy optimization},
	language = {en},
	booktitle = {{ICML}},
	author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I. and Abbeel, Pieter},
	year = {2015},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{mirzadeh_understanding_2020,
	title = {Understanding the role of training regimes in continual learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Pascanu, Razvan and Ghasemzadeh, Hassan},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{lopez-paz_gradient_2017,
	title = {Gradient episodic memory for continual learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lopez-Paz, David and Ranzato, Marc'Aurelio},
	year = {2017},
}

@article{van_de_ven_three_2019,
	title = {Three scenarios for continual learning},
	language = {en},
	journal = {arXiv preprint arXiv:1904.07734},
	author = {van de Ven, Gido M. and Tolias, Andreas S.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{farquhar_unifying_2019,
	title = {A unifying bayesian view of continual learning},
	journal = {arXiv preprint arXiv:1902.06494},
	author = {Farquhar, Sebastian and Gal, Yarin},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{blalock_multiplying_2021,
	title = {Multiplying matrices without multiplying},
	booktitle = {{ICML}},
	author = {Blalock, Davis and Guttag, John},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Hardware Architecture, Computer Science - Performance},
}

@inproceedings{tang_exploration:_2017,
	title = {\#{Exploration}: {A} study of count-based exploration for deep reinforcement learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, Xi and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
	year = {2017},
}

@inproceedings{schmidt_adversarially_2018,
	title = {Adversarially robust generalization requires more data},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Schmidt, Ludwig and Santurkar, Shibani and Tsipras, Dimitris and Talwar, Kunal and Mądry, Aleksander},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{kunstner_homeomorphic-invariance_2021,
	title = {Homeomorphic-invariance of {EM}: {Non}-asymptotic convergence in {KL} divergence for exponential families via mirror descent},
	booktitle = {{AISTATS}},
	author = {Kunstner, Frederik and Kumar, Raunak and Schmidt, Mark},
	year = {2021},
}

@inproceedings{mitrovic_representation_2021,
	title = {Representation learning via invariant causal mechanisms},
	booktitle = {{ICLR}},
	author = {Mitrovic, Jovana and McWilliams, Brian and Walker, Jacob C. and Buesing, Lars Holger and Blundell, Charles},
	year = {2021},
}

@inproceedings{hendrycks_benchmarking_2019,
	title = {Benchmarking neural network robustness to common corruptions and perturbations},
	booktitle = {{ICLR}},
	author = {Hendrycks, Dan and Dietterich, Thomas},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{hendrycks_many_2021,
	title = {The many faces of robustness: {A} critical analysis of out-of-distribution generalization},
	shorttitle = {The many faces of robustness},
	booktitle = {{ICCV}},
	author = {Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and Song, Dawn and Steinhardt, Jacob and Gilmer, Justin},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{scholkopf_causal_2012,
	title = {On causal and anticausal learning},
	booktitle = {{ICML}},
	author = {Schölkopf, Bernhard and Janzing, Dominik and Peters, Jonas and Sgouritsa, Eleni and Zhang, Kun and Mooij, Joris},
	year = {2012},
}

@article{ren_orientation-preserving_2021,
	title = {Orientation-preserving rewards' balancing in reinforcement learning},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2021.3080521},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Ren, Jinsheng and Guo, Shangqi and Chen, Feng},
	year = {2021},
	keywords = {Search problems, reinforcement learning, Task analysis, Trajectory, Reinforcement learning, Optimization, Automatic rewards' balancing, auxiliary rewards, Pareto optimization, Pareto solutions, reward design., Switches},
}

@article{zhang_subjective_2021,
	title = {Subjective learning for open-ended data},
	language = {en},
	journal = {arXiv preprint arXiv:2108.12113},
	author = {Zhang, Tianren and Jiang, Yizhou and Su, Xin and Guo, Shangqi and Chen, Feng},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{paternain_constrained_2019,
	title = {Constrained reinforcement learning has zero duality gap},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Paternain, Santiago and Chamon, Luiz F. O. and Calvo-Fullana, Miguel and Ribeiro, Alejandro},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@inproceedings{haarnoja_soft_2018,
	title = {Soft actor-critic: {Off}-policy maximum entropy deep reinforcement learning with a stochastic actor},
	shorttitle = {Soft {Actor}-{Critic}},
	booktitle = {{ICML}},
	author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{yaochu_jin_pareto-based_2008,
	title = {Pareto-based multiobjective machine learning: {An} overview and case studies},
	volume = {38},
	issn = {1094-6977},
	shorttitle = {Pareto-based multiobjective machine learning},
	doi = {10.1109/TSMCC.2008.919172},
	language = {en},
	number = {3},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {{Yaochu Jin} and Sendhoff, B.},
	year = {2008},
	pages = {397--415},
}

@article{censor_pareto_1977,
	title = {Pareto optimality in multiobjective problems},
	volume = {4},
	issn = {0095-4616, 1432-0606},
	doi = {10.1007/BF01442131},
	language = {en},
	number = {1},
	journal = {Applied Mathematics \& Optimization},
	author = {Censor, Yair},
	year = {1977},
	pages = {41--59},
}

@inproceedings{horn_niched_1994,
	address = {Orlando, FL, USA},
	title = {A niched {Pareto} genetic algorithm for multiobjective optimization},
	isbn = {978-0-7803-1899-1},
	doi = {10.1109/ICEC.1994.350037},
	language = {en},
	booktitle = {Proceedings of the {First} {IEEE} {Conference} on {Evolutionary} {Computation}. {IEEE} {World} {Congress} on {Computational} {Intelligence}},
	author = {Horn, J. and Nafpliotis, N. and Goldberg, D.E.},
	year = {1994},
	pages = {82--87},
}

@book{ehrgott_multicriteria_2005,
	title = {Multicriteria optimization},
	isbn = {3-540-21398-8},
	author = {Ehrgott, Matthias},
	year = {2005},
}

@book{miettinen_nonlinear_2012,
	title = {Nonlinear multiobjective optimization},
	isbn = {1-4615-5563-9},
	author = {Miettinen, Kaisa},
	year = {2012},
}

@article{weinberger_distance_2009,
	title = {Distance metric learning for large margin nearest neighbor classification},
	number = {10},
	journal = {Journal of Machine Learning Research},
	author = {Weinberger, Kilian Q and Saul, Lawrence K},
	year = {2009},
	pages = {207--244},
}

@inproceedings{zhang_bridging_2019,
	title = {Bridging theory and algorithm for domain adaptation},
	language = {en},
	booktitle = {{ICML}},
	author = {Zhang, Yuchen and Liu, Tianle and Long, Mingsheng and Jordan, Michael I},
	year = {2019},
}

@article{pateria_hierarchical_2021,
	title = {Hierarchical reinforcement learning: {A} comprehensive survey},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Hierarchical reinforcement learning},
	doi = {10.1145/3453160},
	language = {en},
	number = {5},
	journal = {ACM Computing Surveys},
	author = {Pateria, Shubham and Subagdja, Budhitama and Tan, Ah-hwee and Quek, Chai},
	year = {2021},
	pages = {109:1--109:35},
}

@article{di_lollo_feature-binding_2012,
	title = {The feature-binding problem is an ill-posed problem},
	volume = {16},
	number = {6},
	journal = {Trends in cognitive sciences},
	author = {Di Lollo, Vincent},
	year = {2012},
	pages = {317--321},
}

@article{roskies_binding_1999,
	title = {The binding problem},
	volume = {24},
	number = {1},
	journal = {Neuron},
	author = {Roskies, Adina L.},
	year = {1999},
	pages = {7--9},
}

@article{treisman_binding_1996,
	title = {The binding problem},
	volume = {6},
	number = {2},
	journal = {Current opinion in neurobiology},
	author = {Treisman, Anne},
	year = {1996},
	pages = {171--178},
}

@article{feldman_neural_2013,
	title = {The neural binding problem(s)},
	volume = {7},
	issn = {1871-4080, 1871-4099},
	doi = {10.1007/s11571-012-9219-8},
	language = {en},
	number = {1},
	journal = {Cognitive Neurodynamics},
	author = {Feldman, Jerome},
	year = {2013},
	pages = {1--11},
}

@inproceedings{bouchacourt_multi-level_2018,
	title = {Multi-level variational autoencoder: learning disentangled representations from grouped observations},
	language = {en},
	booktitle = {{AAAI}},
	author = {Bouchacourt, Diane and Tomioka, Ryota and Nowozin, Sebastian},
	year = {2018},
}

@inproceedings{kearns_information-theoretic_1997,
	title = {An information-theoretic analysis of hard and soft assignment methods for clustering},
	booktitle = {{UAI}},
	author = {Kearns, Michael and Mansour, Yishay and Ng, Andrew Y.},
	year = {1997},
	pages = {282--293},
}

@inproceedings{zhang_framework_2019,
	title = {A framework for deep constrained clustering -- algorithms and advances},
	language = {en},
	booktitle = {{ECML}/{PKDD}},
	author = {Zhang, Hongjing and Basu, Sugato and Davidson, Ian},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{muandet_domain_2013,
	title = {Domain generalization via invariant feature representation},
	language = {en},
	booktitle = {{ICML}},
	author = {Muandet, Krikamol and Balduzzi, David and Scholkopf, Bernhard},
	year = {2013},
}

@inproceedings{cai_theory_2021,
	title = {A theory of label propagation for subpopulation shift},
	language = {en},
	booktitle = {{ICML}},
	author = {Cai, Tianle and Gao, Ruiqi and Lee, Jason D. and Lei, Qi},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{santurkar_breeds_2021,
	title = {Breeds: {Benchmarks} for subpopulation shift},
	shorttitle = {Breeds},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Santurkar, Shibani and Tsipras, Dimitris and Madry, Aleksander},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{rahimian_distributionally_2019,
	title = {Distributionally robust optimization: {A} review},
	shorttitle = {Distributionally robust optimization},
	language = {en},
	journal = {arXiv preprint arXiv:1908.05659},
	author = {Rahimian, Hamed and Mehrotra, Sanjay},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@article{pan_domain_2011,
	title = {Domain adaptation via transfer component analysis},
	volume = {22},
	issn = {1941-0093},
	doi = {10.1109/TNN.2010.2091281},
	number = {2},
	journal = {IEEE Transactions on Neural Networks},
	author = {Pan, Sinno Jialin and Tsang, Ivor W. and Kwok, James T. and Yang, Qiang},
	year = {2011},
	keywords = {Feature extraction, Manifolds, Optimization, Dimensionality reduction, domain adaptation, Hilbert space, Hilbert space embedding of distributions, Kernel, Learning systems, Noise measurement, transfer learning},
	pages = {199--210},
}

@inproceedings{ye_adaptive_2007,
	title = {Adaptive distance metric learning for clustering},
	doi = {10.1109/CVPR.2007.383103},
	booktitle = {{CVPR}},
	author = {Ye, Jieping and Zhao, Zheng and Liu, Huan},
	year = {2007},
	keywords = {Machine learning, Manifolds, Clustering algorithms, Computer science, Data engineering, Iterative algorithms, Laplace equations, Machine learning algorithms, Principal component analysis, Unsupervised learning},
}

@inproceedings{smart_explicit_2004,
	title = {Explicit manifold representations for value-function approximation in reinforcement learning.},
	booktitle = {{ISAIM}},
	author = {Smart, William D.},
	year = {2004},
}

@inproceedings{caseiro_semi-intrinsic_2012,
	address = {Berlin, Heidelberg},
	title = {Semi-intrinsic mean shift on {Riemannian} manifolds},
	volume = {7572},
	isbn = {978-3-642-33717-8 978-3-642-33718-5},
	doi = {10.1007/978-3-642-33718-5_25},
	booktitle = {{ECCV}},
	author = {Caseiro, Rui and Henriques, João F. and Martins, Pedro and Batista, Jorge},
	year = {2012},
	pages = {342--355},
}

@article{jayasumana_kernel_2015,
	title = {Kernel methods on {Riemannian} manifolds with {Gaussian} {RBF} kernels},
	volume = {37},
	issn = {0162-8828, 2160-9292},
	doi = {10.1109/TPAMI.2015.2414422},
	language = {en},
	number = {12},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Jayasumana, Sadeep and Hartley, Richard and Salzmann, Mathieu and Li, Hongdong and Harandi, Mehrtash},
	year = {2015},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {2464--2477},
}

@inproceedings{samdani_unified_2012,
	title = {Unified expectation maximization},
	booktitle = {Proceedings of the 2012 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	author = {Samdani, Rajhans and Chang, Ming-Wei and Roth, Dan},
	year = {2012},
	pages = {688--698},
}

@inproceedings{finley_supervised_2005,
	title = {Supervised clustering with support vector machines},
	booktitle = {{ICML}},
	author = {Finley, Thomas and Joachims, Thorsten},
	year = {2005},
	pages = {217--224},
}

@inproceedings{eick_supervised_2004,
	title = {Supervised clustering-algorithms and benefits},
	isbn = {0-7695-2236-X},
	booktitle = {16th {IEEE} international conference on tools with artificial intelligence},
	author = {Eick, Christoph F. and Zeidat, Nidal and Zhao, Zhenghong},
	year = {2004},
	pages = {774--776},
}

@techreport{finley_supervised_2008,
	title = {Supervised k-means clustering},
	author = {Finley, Thomas and Joachims, Thorsten},
	year = {2008},
}

@inproceedings{basu_semi-supervised_2002,
	title = {Semi-supervised clustering by seeding},
	booktitle = {{ICML}},
	author = {Basu, Sugato and Banerjee, Arindam and Mooney, Raymond},
	year = {2002},
}

@inproceedings{basu_probabilistic_2004,
	address = {Seattle, WA, USA},
	title = {A probabilistic framework for semi-supervised clustering},
	doi = {10.1145/1014052.1014062},
	language = {en},
	booktitle = {Proceedings of the 2004 {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining  - {KDD} '04},
	author = {Basu, Sugato and Bilenko, Mikhail and Mooney, Raymond J.},
	year = {2004},
}

@inproceedings{fearnley_complexity_2021,
	title = {The complexity of gradient descent: {CLS}={PPAD}∩{PLS}},
	booktitle = {Proceedings of the 53rd {Annual} {ACM} {SIGACT} {Symposium} on {Theory} of {Computing} ({STOC})},
	author = {Fearnley, John and Goldberg, Paul W. and Hollender, Alexandros and Savani, Rahul},
	year = {2021},
	pages = {46--59},
}

@inproceedings{cheung_reinforcement_2020,
	title = {Reinforcement learning for non-stationary {Markov} {Decision} {Processes}: the blessing of (more) optimism},
	language = {en},
	booktitle = {{ICML}},
	author = {Cheung, Wang Chi and Simchi-Levi, David and Zhu, Ruihao},
	year = {2020},
}

@article{padakandla_reinforcement_2020,
	title = {Reinforcement learning in non-stationary environments},
	volume = {50},
	issn = {0924-669X, 1573-7497},
	doi = {10.1007/s10489-020-01758-5},
	language = {en},
	number = {11},
	journal = {Applied Intelligence},
	author = {Padakandla, Sindhu and J, Prabuchandran K. and Bhatnagar, Shalabh},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {3590--3606},
}

@inproceedings{gao_adaptability_2020,
	address = {Las Vegas, NV, USA},
	title = {Adaptability preserving domain decomposition for stabilizing sim2real reinforcement learning},
	isbn = {978-1-72816-212-6},
	doi = {10.1109/IROS45743.2020.9341124},
	language = {en},
	booktitle = {{IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Gao, Haichuan and Yang, Zhile and Su, Xin and Tan, Tian and Chen, Feng},
	year = {2020},
	pages = {4403--4410},
}

@inproceedings{gao_cril_2021,
	title = {{CRIL}: {Continual} robot imitation learning via generative and prediction model},
	shorttitle = {Cril},
	language = {en},
	booktitle = {{IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Gao, Chongkai and Gao, Haichuan and Guo, Shangqi and Zhang, Tianren and Chen, Feng},
	year = {2021},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{tokui_chainer_2019,
	address = {New York, NY, USA},
	series = {{KDD} '19},
	title = {Chainer: {A} deep learning framework for accelerating the research cycle},
	isbn = {978-1-4503-6201-6},
	shorttitle = {Chainer},
	doi = {10.1145/3292500.3330756},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	author = {Tokui, Seiya and Okuta, Ryosuke and Akiba, Takuya and Niitani, Yusuke and Ogawa, Toru and Saito, Shunta and Suzuki, Shuji and Uenishi, Kota and Vogel, Brian and Yamazaki Vincent, Hiroyuki},
	year = {2019},
	keywords = {computer vision, deep learning frameworks, distributed training, gpu computing},
	pages = {2002--2011},
}

@inproceedings{paszke_pytorch_2019,
	title = {{PyTorch}: {An} imperative style, high-performance deep learning library},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	year = {2019},
	pages = {8024--8035},
}

@inproceedings{abadi_tensorflow_2016,
	title = {{TensorFlow}: {A} system for large-scale machine learning},
	language = {en},
	booktitle = {12th {USENIX} symposium on operating systems design and implementation {OSDI} 16},
	author = {Abadi, Martın and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	year = {2016},
	pages = {265--283},
}

@article{ma_paddlepaddle_2019,
	title = {{PaddlePaddle}: {An} open-source deep learning platform from industrial practice},
	volume = {1},
	issn = {1674-9480},
	shorttitle = {Paddlepaddle},
	doi = {10.11871/jfdc.issn.2096.742X.2019.01.011},
	language = {EN},
	number = {1},
	journal = {Frontiers of Data and Domputing},
	author = {Ma, Jiajun and Yu, Dianhai and Wu, Tian and Wang, Haifeng},
	year = {2019},
	pages = {105--115},
}

@article{zahavy_reward_2021,
	title = {Reward is enough for convex {MDPs}},
	journal = {arXiv preprint arXiv:2106.00661},
	author = {Zahavy, Tom and O'Donoghue, Brendan and Desjardins, Guillaume and Singh, Satinder},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{kairouz_advances_2021,
	title = {Advances and open problems in federated learning},
	volume = {14},
	number = {1-2},
	journal = {Foundations and Trends in Machine Learning},
	author = {Kairouz, Peter and McMahan, H. Brendan and Avent, Brendan and Bellet, Aurélien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and D'Oliveira, Rafael G. L. and Eichner, Hubert and Rouayheb, Salim El and Evans, David and Gardner, Josh and Garrett, Zachary and Gascón, Adrià and Ghazi, Badih and Gibbons, Phillip B. and Gruteser, Marco and Harchaoui, Zaid and He, Chaoyang and He, Lie and Huo, Zhouyuan and Hutchinson, Ben and Hsu, Justin and Jaggi, Martin and Javidi, Tara and Joshi, Gauri and Khodak, Mikhail and Konečný, Jakub and Korolova, Aleksandra and Koushanfar, Farinaz and Koyejo, Sanmi and Lepoint, Tancrède and Liu, Yang and Mittal, Prateek and Mohri, Mehryar and Nock, Richard and Özgür, Ayfer and Pagh, Rasmus and Raykova, Mariana and Qi, Hang and Ramage, Daniel and Raskar, Ramesh and Song, Dawn and Song, Weikang and Stich, Sebastian U. and Sun, Ziteng and Suresh, Ananda Theertha and Tramèr, Florian and Vepakomma, Praneeth and Wang, Jianyu and Xiong, Li and Xu, Zheng and Yang, Qiang and Yu, Felix X. and Yu, Han and Zhao, Sen},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Cryptography and Security},
	pages = {1--210},
}

@inproceedings{mcmahan_communication-efficient_2017,
	title = {Communication-efficient learning of deep networks from decentralized data},
	booktitle = {{AISTATS}},
	author = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth},
	year = {2017},
	pages = {1273--1282},
}

@inproceedings{deng_scalable_2014,
	address = {Toronto Ontario Canada},
	title = {Scalable multi-label annotation},
	isbn = {978-1-4503-2473-1},
	doi = {10.1145/2556288.2557011},
	language = {en},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Deng, Jia and Russakovsky, Olga and Krause, Jonathan and Bernstein, Michael S. and Berg, Alex and Fei-Fei, Li},
	year = {2014},
	pages = {3099--3102},
}

@article{singh_reinforcement_1996,
	title = {Reinforcement learning with replacing eligibility traces},
	volume = {22},
	issn = {1573-0565},
	doi = {10.1023/A:1018012322525},
	language = {en},
	number = {1},
	journal = {Machine Learning},
	author = {Singh, Satinder P. and Sutton, Richard S.},
	year = {1996},
	pages = {123--158},
}

@inproceedings{hazan_efficient_2017,
	title = {Efficient regret minimization in non-convex games},
	language = {en},
	booktitle = {{ICML}},
	author = {Hazan, Elad and Singh, Karan and Zhang, Cyril},
	year = {2017},
}

@article{viglietta_gaming_2014,
	title = {Gaming is a hard job, but someone has to do it!},
	volume = {54},
	language = {en},
	number = {4},
	journal = {Theory of Computing Systems},
	author = {Viglietta, Giovanni},
	year = {2014},
	keywords = {Computer Science - Computational Complexity},
	pages = {595--621},
}

@article{shalev-shwartz_online_2011,
	title = {Online learning and online convex optimization},
	volume = {4},
	issn = {1935-8237, 1935-8245},
	doi = {10.1561/2200000018},
	language = {en},
	number = {2},
	journal = {Foundations and Trends in Machine Learning},
	author = {Shalev-Shwartz, Shai},
	year = {2011},
	pages = {107--194},
}

@inproceedings{knoblauch_optimal_2020,
	title = {Optimal continual learning has perfect memory and is {NP}-hard},
	language = {en},
	booktitle = {{ICML}},
	author = {Knoblauch, Jeremias and Husain, Hisham and Diethe, Tom},
	year = {2020},
}

@inproceedings{agarwal_learning_2019-1,
	title = {Learning in non-convex games with an optimization oracle},
	language = {en},
	booktitle = {{COLT}},
	author = {Agarwal, Naman and Gonen, Alon and Hazan, Elad},
	year = {2019},
}

@inproceedings{li_sub-policy_2020,
	title = {Sub-policy adaptation for hierarchical reinforcement learning},
	language = {en},
	booktitle = {{ICLR}},
	author = {Li, Alexander C. and Florensa, Carlos and Clavera, Ignasi and Abbeel, Pieter},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@article{redmon_yolov3_2018,
	title = {Yolov3: {An} incremental improvement},
	language = {en},
	journal = {arXiv preprint arXiv:1804.02767},
	author = {Redmon, Joseph and Farhadi, Ali},
	year = {2018},
}

@inproceedings{brunskill_sample_2013,
	title = {Sample complexity of multi-task reinforcement learning},
	language = {en},
	booktitle = {Conference on {Uncertainty} in {Artificial} {Intelligence} ({UAI})},
	author = {Brunskill, Emma and Li, Lihong},
	year = {2013},
}

@article{zou_object_2019,
	title = {Object detection in 20 years: {A} survey},
	journal = {arXiv preprint arXiv:1905.05055},
	author = {Zou, Zhengxia and Shi, Zhenwei and Guo, Yuhong and Ye, Jieping},
	year = {2019},
}

@inproceedings{andre_state_2002,
	title = {State abstraction for programmable reinforcement learning agents},
	booktitle = {{AAAI}},
	author = {Andre, David and Russell, Stuart J},
	year = {2002},
}

@article{durkan_context-aware_2018,
	title = {The context-aware learner},
	abstract = {One important aspect of generalization in machine learning involves reasoning about previously seen data in new settings. Such reasoning requires learning disentangled representations of data which...},
	language = {en},
	author = {Durkan, Conor and Storkey, Amos and Edwards, Harrison},
	year = {2018},
}

@article{venuto_policy_2021,
	title = {Policy gradients incorporating the future},
	journal = {arXiv preprint arXiv:2108.02096},
	author = {Venuto, David and Lau, Elaine and Precup, Doina and Nachum, Ofir},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{shankar_evaluating_2020,
	title = {Evaluating machine accuracy on {ImageNet}},
	language = {en},
	booktitle = {{ICML}},
	author = {Shankar, Vaishaal and Roelofs, Rebecca and Mania, Horia and Fang, Alex and Recht, Benjamin and Schmidt, Ludwig},
	year = {2020},
}

@article{beyer_are_2020,
	title = {Are we done with {ImageNet}?},
	language = {en},
	journal = {arXiv preprint arXiv:2006.07159},
	author = {Beyer, Lucas and Hénaff, Olivier J. and Kolesnikov, Alexander and Zhai, Xiaohua and Oord, Aäron van den},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{woodworth_min-max_2021,
	title = {The min-max complexity of distributed stochastic convex optimization with intermittent communication},
	language = {en},
	booktitle = {{COLT}},
	author = {Woodworth, Blake and Bullins, Brian and Shamir, Ohad and Srebro, Nathan},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
}

@inproceedings{wei_non-stationary_2021,
	title = {Non-stationary reinforcement learning without prior knowledge: {An} optimal black-box approach},
	shorttitle = {Non-stationary reinforcement learning without prior knowledge},
	language = {en},
	booktitle = {{COLT}},
	author = {Wei, Chen-Yu and Luo, Haipeng},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{tao_variational_2020,
	title = {Variational optimization on {Lie} {Groups}, with examples of leading (generalized) eigenvalue problems},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Tao, Molei and Ohsawa, Tomoki},
	year = {2020},
}

@inproceedings{paty_regularity_2020,
	title = {Regularity as regularization: {Smooth} and strongly convex brenier potentials in optimal transport},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Paty, François-Pierre and Cuturi, Marco},
	year = {2020},
}

@inproceedings{grant_thompson_2020,
	title = {On {Thompson} {Sampling} for smoother-than-{Lipschitz} bandits},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Grant, James A and Leslie, David S},
	year = {2020},
}

@inproceedings{yun_re-labeling_2021,
	title = {Re-labeling {ImageNet}: {From} single to multi-labels, from global to localized labels},
	shorttitle = {Re-labeling imagenet},
	language = {en},
	booktitle = {{CVPR}},
	author = {Yun, Sangdoo and Oh, Seong Joon and Heo, Byeongho and Han, Dongyoon and Choe, Junsuk and Chun, Sanghyuk},
	year = {2021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{team_open-ended_2021,
	title = {Open-ended learning leads to generally capable agents},
	journal = {arXiv preprint arXiv:2107.12808},
	author = {Team, Ended Learning and Stooke, Adam and Mahajan, Anuj and Barros, Catarina and Deck, Charlie and Bauer, Jakob and Sygnowski, Jakub and Trebacz, Maja and Jaderberg, Max and Mathieu, Michael},
	year = {2021},
}

@inproceedings{leibo_scalable_2021,
	title = {Scalable evaluation of multi-agent reinforcement learning with melting pot},
	language = {en},
	booktitle = {{ICML}},
	author = {Leibo, Joel Z and Duéñez-Guzmán, Edgar and Vezhnevets, Alexander Sasha and Agapiou, John P and Sunehag, Peter and Koster, Raphael and Matyas, Jayd and Beattie, Charles and Mordatch, Igor and Graepel, Thore},
	year = {2021},
}

@inproceedings{hanna_towards_2020,
	title = {Towards a critical race methodology in algorithmic fairness},
	booktitle = {Proceedings of the 2020 conference on fairness, accountability, and transparency},
	author = {Hanna, Alex and Denton, Emily and Smart, Andrew and Smith-Loud, Jamila},
	year = {2020},
	pages = {501--512},
}

@inproceedings{wen_efficiency_2020,
	title = {On efficiency in hierarchical reinforcement learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wen, Zheng and Precup, Doina and Ibrahimi, Morteza and Barreto, Andre},
	year = {2020},
}

@article{aldous_markov_1982,
	title = {Markov chains with almost exponential hitting times},
	volume = {13},
	issn = {03044149},
	doi = {10.1016/0304-4149(82)90016-3},
	language = {en},
	number = {3},
	journal = {Stochastic Processes and their Applications},
	author = {Aldous, David J.},
	year = {1982},
	pages = {305--310},
}

@inproceedings{ilyas_adversarial_2019,
	title = {Adversarial examples are not bugs, they are features},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security},
}

@article{peters_causal_2016,
	title = {Causal inference by using invariant prediction: identification and confidence intervals},
	journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
	author = {Peters, Jonas and Bühlmann, Peter and Meinshausen, Nicolai},
	year = {2016},
	pages = {947--1012},
}

@inproceedings{geirhos_imagenet-trained_2019,
	title = {{ImageNet}-trained {CNNs} are biased towards texture; increasing shape bias improves accuracy and robustness},
	language = {en},
	booktitle = {{ICLR}},
	author = {Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A. and Brendel, Wieland},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Neurons and Cognition},
}

@article{ganin_domain-adversarial_2016,
	title = {Domain-adversarial training of neural networks},
	volume = {17},
	number = {59},
	journal = {Journal of Machine Learning Research},
	author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, François and Marchand, Mario and Lempitsky, Victor},
	year = {2016},
	pages = {1--35},
}

@inproceedings{long_conditional_2018,
	title = {Conditional adversarial domain adaptation},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Long, Mingsheng and Cao, Zhangjie and Wang, Jianmin and Jordan, Michael I.},
	year = {2018},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{sonar_invariant_2021,
	title = {Invariant policy optimization: {Towards} stronger generalization in reinforcement learning},
	language = {en},
	booktitle = {Conference on {Learning} for {Dynamics} \& {Control} ({L4DC})},
	author = {Sonar, Anoopkumar},
	year = {2021},
	pages = {13},
}

@inproceedings{alquier_regret_2017,
	title = {Regret bounds for lifelong learning},
	isbn = {2640-3498},
	booktitle = {{AISTATS}},
	author = {Alquier, Pierre and Pontil, Massimiliano},
	year = {2017},
	pages = {261--269},
}

@article{amodei_concrete_2016,
	title = {Concrete problems in {AI} safety},
	language = {en},
	journal = {arXiv preprint arXiv:1606.06565},
	author = {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Mané, Dan},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{nalisnick_deep_2019,
	title = {Do deep generative models know what they don't know?},
	language = {en},
	booktitle = {{ICLR}},
	author = {Nalisnick, Eric and Matsukawa, Akihiro and Teh, Yee Whye and Gorur, Dilan and Lakshminarayanan, Balaji},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{hendrycks_baseline_2017,
	title = {A baseline for detecting misclassified and out-of-distribution examples in neural networks},
	language = {en},
	booktitle = {{ICLR}},
	author = {Hendrycks, Dan and Gimpel, Kevin},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{lee_training_2018,
	title = {Training confidence-calibrated classifiers for detecting out-of-distribution samples},
	language = {en},
	booktitle = {{ICLR}},
	author = {Lee, Kimin and Lee, Honglak and Lee, Kibok and Shin, Jinwoo},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{liang_enhancing_2018,
	title = {Enhancing the reliability of out-of-distribution image detection in neural networks},
	language = {en},
	booktitle = {{ICLR}},
	author = {Liang, Shiyu and Li, Yixuan and Srikant, R.},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{hendrycks_deep_2019,
	title = {Deep anomaly detection with outlier exposure},
	language = {en},
	booktitle = {{ICLR}},
	author = {Hendrycks, Dan and Mazeika, Mantas and Dietterich, Thomas},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
}

@inproceedings{meinke_towards_2020,
	title = {Towards neural networks that provably know when they don't know},
	booktitle = {{ICLR}},
	author = {Meinke, Alexander and Hein, Matthias},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{degrave_ai_2021,
	title = {{AI} for radiographic {COVID}-19 detection selects shortcuts over signal},
	volume = {3},
	issn = {2522-5839},
	doi = {10.1038/s42256-021-00338-7},
	language = {en},
	number = {7},
	journal = {Nature Machine Intelligence},
	author = {DeGrave, Alex J. and Janizek, Joseph D. and Lee, Su-In},
	year = {2021},
	pages = {610--619},
}

@inproceedings{ferrari_recognition_2018,
	address = {Cham},
	title = {Recognition in terra incognita},
	volume = {11220},
	isbn = {978-3-030-01269-4 978-3-030-01270-0},
	doi = {10.1007/978-3-030-01270-0_28},
	language = {en},
	booktitle = {{ECCV}},
	author = {Beery, Sara and Van Horn, Grant and Perona, Pietro},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	pages = {472--489},
}

@inproceedings{sohn_shortest-path_2021,
	title = {Shortest-path constrained reinforcement learning for sparse reward tasks},
	booktitle = {{ICML}},
	author = {Sohn, Sungryull and Lee, Sungtae and Choi, Jongwook and van Seijen, Harm and Fatemi, Mehdi and Lee, Honglak},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@article{colas_language-conditioned_2020,
	title = {Language-conditioned goal generation: {A} new approach to language grounding for {RL}},
	shorttitle = {Language-conditioned goal generation},
	language = {en},
	journal = {arXiv preprint arXiv:2006.07043},
	author = {Colas, Cédric and Akakzia, Ahmed and Oudeyer, Pierre-Yves and Chetouani, Mohamed and Sigaud, Olivier},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{amit_meta-learning_2018,
	title = {Meta-learning by adjusting priors based on extended {PAC}-{Bayes} theory},
	language = {en},
	booktitle = {{ICML}},
	author = {Amit, Ron and Meir, Ron},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{pentina_pac-bayesian_2014,
	title = {A {PAC}-{Bayesian} bound for lifelong learning},
	booktitle = {{ICML}},
	author = {Pentina, Anastasia and Lampert, Christoph H},
	year = {2014},
}

@inproceedings{colas_curious:_2019,
	title = {{CURIOUS}: {Intrinsically} motivated multi-task, multi-goal reinforcement learning},
	shorttitle = {Curious},
	booktitle = {{ICML}},
	author = {Colas, Cédric and Fournier, Pierre and Sigaud, Olivier and Chetouani, Mohamed and Oudeyer, Pierre-Yves},
	year = {2019},
	keywords = {Computer Science - Artificial Intelligence},
}

@inproceedings{zintgraf_fast_2019,
	title = {Fast context adaptation via meta-learning},
	booktitle = {{ICML}},
	author = {Zintgraf, Luisa M. and Shiarlis, Kyriacos and Kurin, Vitaly and Hofmann, Katja and Whiteson, Shimon},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{rakelly_efficient_2019,
	title = {Efficient off-policy meta-reinforcement learning via probabilistic context variables},
	language = {en},
	booktitle = {{ICML}},
	author = {Rakelly, Kate and Zhou, Aurick and Quillen, Deirdre and Finn, Chelsea and Levine, Sergey},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{lee_gradient-based_2018,
	title = {Gradient-based meta-learning with learned layerwise metric and subspace},
	booktitle = {{ICML}},
	author = {Lee, Yoonho and Choi, Seungjin},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{chollet_measure_2019,
	title = {On the measure of intelligence},
	journal = {arXiv preprint arXiv:1911.01547},
	author = {Chollet, Francois},
	year = {2019},
}

@inproceedings{passos_flexible_2012,
	title = {Flexible modeling of latent task structures in multitask learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Passos, Alexandre and Rai, Piyush and Wainer, Jacques},
	year = {2012},
}

@inproceedings{wang_enhanced_2020,
	title = {Enhanced poet: {Open}-ended reinforcement learning through unbounded invention of learning challenges and their solutions},
	language = {en},
	booktitle = {{ICML}},
	author = {Wang, Rui and Lehman, Joel and Rawal, Aditya and Zhi, Jiale and Li, Yulun and Clune, Jeff and Stanley, Kenneth O.},
	year = {2020},
}

@article{ye_contextualizing_2021,
	title = {Contextualizing multiple tasks via learning to decompose},
	language = {en},
	journal = {arXiv preprint arXiv:2106.08112},
	author = {Ye, Han-Jia and Zhou, Da-Wei and Hong, Lanqing and Li, Zhenguo and Wei, Xiu-Shen and Zhan, De-Chuan},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{singh_parrot_2021,
	title = {Parrot: {Data}-driven behavioral priors for reinforcement learning},
	language = {en},
	booktitle = {{ICLR}},
	author = {Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
	year = {2021},
}

@article{colas_how_2018,
	title = {How many random seeds? {Statistical} power analysis in deep reinforcement learning experiments},
	shorttitle = {How many random seeds?},
	journal = {arXiv preprint arXiv:1806.08295},
	author = {Colas, Cédric and Sigaud, Olivier and Oudeyer, Pierre-Yves},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{suggala_online_2020,
	title = {Online non-convex learning: {Following} the perturbed leader is optimal},
	booktitle = {{COLT}},
	author = {Suggala, Arun Sai and Netrapalli, Praneeth},
	year = {2020},
}

@inproceedings{abernethy_optimal_2008,
	title = {Optimal strategies and minimax lower bounds for online convex games},
	language = {en},
	booktitle = {Technical {Report} {No}. {UCB}/{EECS}-2008-19},
	author = {Abernethy, Jacob and Bartlett, Peter L and Rakhlin, Alexander and Tewari, Ambuj},
	year = {2008},
}

@inproceedings{murugesan_adaptive_2016,
	title = {Adaptive smoothed online multi-task learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Murugesan, Keerthiram and Liu, Hanxiao and Carbonell, Jaime and Yang, Yiming},
	year = {2016},
}

@inproceedings{saha_online_2011,
	title = {Online learning of multiple tasks and their relationships},
	booktitle = {{AISTATS}},
	author = {Saha, Avishek and Rai, Piyush and Iii, Hal Daume and Venkatasubramanian, Suresh},
	year = {2011},
}

@inproceedings{lugosi_online_2009,
	title = {Online multi-task learning with hard constraints},
	language = {en},
	booktitle = {{COLT}},
	author = {Lugosi, Gabor and Papaspiliopoulos, Omiros and Stoltz, Gilles},
	year = {2009},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Statistics Theory},
}

@inproceedings{huang_one_2020,
	title = {One policy to control them all: {Shared} modular policies for agent-agnostic control},
	booktitle = {{ICML}},
	author = {Huang, Wenlong and Mordatch, Igor and Pathak, Deepak},
	year = {2020},
}

@inproceedings{cohen_group_2016,
	title = {Group equivariant convolutional networks},
	language = {en},
	booktitle = {{ICML}},
	author = {Cohen, Taco S and Cohen, T S and Nl, Uva},
	year = {2016},
}

@inproceedings{rothfuss_pacoh_2021,
	title = {{PACOH}: {Bayes}-optimal meta-learning with {PAC}-guarantees},
	shorttitle = {Pacoh},
	language = {en},
	booktitle = {{ICML}},
	author = {Rothfuss, Jonas and Fortuin, Vincent and Josifoski, Martin and Krause, Andreas},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, 68Q32},
}

@inproceedings{sun_return_2016,
	title = {Return of frustratingly easy domain adaptation},
	isbn = {2374-3468},
	booktitle = {{AAAI}},
	author = {Sun, Baochen and Feng, Jiashi and Saenko, Kate},
	year = {2016},
}

@inproceedings{chen_iterative_2022,
	title = {Iterative feature matching: {Toward} provable domain generalization with logarithmic environments},
	shorttitle = {Iterative feature matching},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chen, Yining and Rosenfeld, Elan and Sellke, Mark and Ma, Tengyu and Risteski, Andrej},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{guo_out--distribution_2021,
	title = {Out-of-distribution prediction with invariant risk minimization: {The} limitation and an effective fix},
	shorttitle = {Out-of-distribution prediction with invariant risk minimization},
	language = {en},
	journal = {arXiv preprint arXiv:2101.07732},
	author = {Guo, Ruocheng and Zhang, Pengchuan and Liu, Hao and Kiciman, Emre},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{zhang_can_2021,
	title = {Can subnetwork structure be the key to out-of-distribution generalization?},
	booktitle = {{ICML}},
	author = {Zhang, Dinghuai and Ahuja, Kartik and Xu, Yilun and Wang, Yisen and Courville, Aaron},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{rosenfeld_online_2022,
	title = {An online learning approach to interpolation and extrapolation in domain generalization},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Rosenfeld, Elan and Ravikumar, Pradeep and Risteski, Andrej},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory},
	pages = {2641--2657},
}

@inproceedings{zaheer_deep_2017,
	title = {Deep sets},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan and Smola, Alexander},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{khemakhem_variational_2020,
	title = {Variational autoencoders and nonlinear {ICA}: {A} unifying framework},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Khemakhem, Ilyes and Kingma, Diederik P and Monti, Ricardo Pio and Hyvärinen, Aapo},
	year = {2020},
}

@inproceedings{zhou_meta-learning_2021,
	title = {Meta-learning symmetries by reparameterization},
	language = {en},
	booktitle = {{ICLR}},
	author = {Zhou, Allan and Knowles, Tom and Finn, Chelsea},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{vapnik_complete_2019,
	title = {Complete statistical theory of learning},
	volume = {80},
	issn = {00051179},
	doi = {10.1134/S000511791911002X},
	number = {11},
	journal = {Automation \& Remote Control},
	author = {Vapnik, V. N.},
	year = {2019},
	keywords = {first selection problem, FUNCTION spaces, HILBERT functions, MATHEMATICAL models, reproducing kernel Hilbert space, second selection problem, SET functions, STATISTICAL learning, statistical learning theory, training data},
	pages = {1949--1975},
}

@article{ye_out--distribution_2021,
	title = {Out-of-distribution generalization analysis via influence function},
	language = {en},
	journal = {arXiv preprint arXiv:2101.08521},
	author = {Ye, Haotian and Xie, Chuanlong and Liu, Yue and Li, Zhenguo},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{hendrycks_pretrained_2020,
	title = {Pretrained transformers improve out-of-distribution robustness},
	booktitle = {{ACL}},
	author = {Hendrycks, Dan and Liu, Xiaoyuan and Wallace, Eric and Dziedzic, Adam and Krishnan, Rishabh and Song, Dawn},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@article{aubin_linear_2021,
	title = {Linear unit-tests for invariance discovery},
	language = {en},
	journal = {arXiv preprint arXiv:2102.10867},
	author = {Aubin, Benjamin and Słowik, Agnieszka and Arjovsky, Martin and Bottou, Leon and Lopez-Paz, David},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{huang_adarl_2021,
	title = {{AdaRL}: {What}, where, and how to adapt in transfer reinforcement learning},
	shorttitle = {Adarl},
	language = {en},
	journal = {arXiv preprint arXiv:2107.02729},
	author = {Huang, Biwei and Feng, Fan and Lu, Chaochao and Magliacane, Sara and Zhang, Kun},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{ahuja_invariant_2020,
	title = {Invariant risk minimization games},
	language = {en},
	booktitle = {{ICML}},
	author = {Ahuja, Kartik and Shanmugam, Karthikeyan and Varshney, Kush R and Dhurandhar, Amit},
	year = {2020},
}

@article{arjovsky_out_2021,
	title = {Out of distribution generalization in machine learning},
	language = {en},
	journal = {arXiv preprint arXiv:2103.02667},
	author = {Arjovsky, Martin},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{ahuja_invariance_2021,
	title = {Invariance principle meets information bottleneck for out-of-distribution generalization},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ahuja, Kartik and Caballero, Ethan and Zhang, Dinghuai and Bengio, Yoshua and Mitliagkas, Ioannis and Rish, Irina},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {3438--3450},
}

@inproceedings{ahuja_empirical_2021,
	title = {Empirical or invariant risk minimization? {A} sample complexity perspective},
	shorttitle = {Empirical or invariant risk minimization?},
	language = {en},
	booktitle = {{ICLR}},
	author = {Ahuja, Kartik and Wang, Jun and Dhurandhar, Amit and Shanmugam, Karthikeyan and Varshney, Kush R.},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{xie_risk_2020,
	title = {Risk variance penalization},
	language = {en},
	journal = {arXiv preprint arXiv:2006.07544},
	author = {Xie, Chuanlong and Ye, Haotian and Chen, Fei and Liu, Yue and Sun, Rui and Li, Zhenguo},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{sagawa_investigation_2020,
	title = {An investigation of why overparameterization exacerbates spurious correlations},
	booktitle = {{ICML}},
	author = {Sagawa, Shiori and Raghunathan, Aditi and Koh, Pang Wei and Liang, Percy},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{shimodaira_improving_2000,
	title = {Improving predictive inference under covariate shift by weighting the log-likelihood function},
	volume = {90},
	issn = {03783758},
	doi = {10.1016/S0378-3758(00)00115-4},
	language = {en},
	number = {2},
	journal = {Journal of Statistical Planning and Inference},
	author = {Shimodaira, Hidetoshi},
	year = {2000},
	pages = {227--244},
}

@article{bae_meta-learned_2021,
	title = {Meta-learned invariant risk minimization},
	language = {en},
	journal = {arXiv preprint arXiv:2103.12947},
	author = {Bae, Jun-Hyun and Choi, Inchul and Lee, Minho},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{khezeli_invariance_2021,
	title = {On invariance penalties for risk minimization},
	language = {en},
	journal = {arXiv preprint arXiv:2106.09777},
	author = {Khezeli, Kia and Blaas, Arno and Soboczenski, Frank and Chia, Nicholas and Kalantari, John},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{lu_nonlinear_2021,
	title = {Nonlinear invariant risk minimization: {A} causal approach},
	shorttitle = {Nonlinear invariant risk minimization},
	language = {en},
	journal = {arXiv preprint arXiv:2102.12353},
	author = {Lu, Chaochao and Wu, Yuhuai and Hernández-Lobato, Jośe Miguel and Schölkopf, Bernhard},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{kamath_does_2021,
	title = {Does invariant risk minimization capture invariance?},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Kamath, Pritish and Tangella, Akilesh and Sutherland, Danica J. and Srebro, Nathan},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{rosenfeld_risks_2021,
	title = {The risks of invariant risk minimization},
	language = {en},
	booktitle = {{ICLR}},
	author = {Rosenfeld, Elan and Ravikumar, Pradeep and Risteski, Andrej},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{preissl_compass_2012,
	address = {Salt Lake City, UT},
	title = {Compass: {A} scalable simulator for an architecture for cognitive computing},
	isbn = {978-1-4673-0805-2 978-1-4673-0806-9},
	shorttitle = {Compass},
	doi = {10.1109/SC.2012.34},
	language = {en},
	booktitle = {International {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
	author = {Preissl, Robert and Wong, Theodore M. and Datta, Pallab and Flickner, Myron and Singh, Raghavendra and Esser, Steven K. and Risk, William P. and Simon, Horst D. and Modha, Dharmendra S.},
	year = {2012},
	pages = {1--11},
}

@inproceedings{gulrajani_search_2021,
	title = {In search of lost domain generalization},
	booktitle = {{ICLR}},
	author = {Gulrajani, Ishaan and Lopez-Paz, David},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{krueger_out--distribution_2021,
	title = {Out-of-distribution generalization via risk extrapolation (rex)},
	language = {en},
	booktitle = {{ICML}},
	author = {Krueger, David and Caballero, Ethan and Jacobsen, Joern-Henrik and Zhang, Amy and Binas, Jonathan and Zhang, Dinghuai and Priol, Remi Le and Courville, Aaron},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{igl_generalization_2019,
	title = {Generalization in reinforcement learning with selective noise injection and information bottleneck},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Igl, Maximilian and Ciosek, Kamil and Li, Yingzhen and Tschiatschek, Sebastian and Zhang, Cheng and Devlin, Sam and Hofmann, Katja},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{lee_network_2020,
	title = {Network randomization: {A} simple technique for generalization in deep reinforcement learning},
	shorttitle = {Network randomization},
	language = {en},
	booktitle = {{ICLR}},
	author = {Lee, Kimin and Lee, Kibok and Shin, Jinwoo and Lee, Honglak},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{cobbe_leveraging_2020,
	title = {Leveraging procedural generation to benchmark reinforcement learning},
	booktitle = {{ICML}},
	author = {Cobbe, Karl and Hesse, Christopher and Hilton, Jacob and Schulman, John},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{justesen_illuminating_2018,
	title = {Illuminating generalization in deep reinforcement learning through procedural level generation},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} {Deep} {RL} {Workshop}},
	author = {Justesen, Niels and Torrado, Ruben Rodriguez and Bontrager, Philip and Khalifa, Ahmed and Togelius, Julian and Risi, Sebastian},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{roberts_principles_2021,
	title = {The principles of deep learning theory},
	language = {en},
	journal = {arXiv preprint arXiv:2106.10165},
	author = {Roberts, Daniel A. and Yaida, Sho and Hanin, Boris},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, High Energy Physics - Theory},
}

@inproceedings{ansuini_intrinsic_2019,
	title = {Intrinsic dimension of data representations in deep neural networks},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ansuini, Alessio and Laio, Alessandro and Macke, Jakob H. and Zoccolan, Davide},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{camastra_intrinsic_2016,
	title = {Intrinsic dimension estimation: {Advances} and open problems},
	volume = {328},
	issn = {00200255},
	shorttitle = {Intrinsic dimension estimation},
	doi = {10.1016/j.ins.2015.08.029},
	language = {en},
	journal = {Information Sciences},
	author = {Camastra, Francesco and Staiano, Antonino},
	year = {2016},
	pages = {26--41},
}

@inproceedings{bachman_learning_2019,
	title = {Learning representations by maximizing mutual information across views},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bachman, Philip and Hjelm, R. Devon and Buchwalter, William},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{chen_simple_2020,
	title = {A simple framework for contrastive learning of visual representations},
	booktitle = {{ICML}},
	author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{quadrianto_multitask_2010,
	title = {Multitask learning without label correspondences},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Quadrianto, Novi and Smola, Alex and Caetano, Tiberio and Vishwanathan, S V N and Petterson, James},
	year = {2010},
}

@article{zhang_survey_2021,
	title = {A survey on multi-task learning},
	language = {en},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Zhang, Yu and Yang, Qiang},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{lin_information-theoretic_1998,
	title = {An information-theoretic definition of similarity},
	language = {en},
	booktitle = {{ICML}},
	author = {Lin, Dekang},
	year = {1998},
}

@article{guo_state-temporal_2021,
	title = {State-temporal compression in reinforcement learning with the reward-restricted geodesic metric},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2021.3069005},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Guo, Shangqi and Yan, Qi and Su, Xin and Hu, Xiaolin and Chen, Feng},
	year = {2021},
	keywords = {Mathematical model, Task analysis, Measurement, Reinforcement learning, Neural networks, option, reinforcement learning (RL), reward-restricted geodesic (RRG) metric, Semi-Markov decision process (SMDP), Semiconductor device measurement, state compression, state-temporal compression, Time-domain analysis},
}

@inproceedings{mankowitz_adaptive_2016,
	title = {Adaptive skills adaptive partitions (asap)},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Mankowitz, Daniel J and Mann, Timothy A and Mannor, Shie},
	year = {2016},
}

@article{tempesta_universality_2020,
	title = {Universality classes and information-theoretic measures of complexity via group entropies},
	volume = {10},
	issn = {2045-2322},
	doi = {10.1038/s41598-020-60188-y},
	language = {en},
	number = {1},
	journal = {Scientific Reports},
	author = {Tempesta, Piergiulio and Jensen, Henrik Jeldtoft},
	year = {2020},
}

@article{rodriguez_new_2019,
	title = {A new class of entropic information measures, formal group theory and information geometry},
	volume = {475},
	issn = {1364-5021, 1471-2946},
	doi = {10.1098/rspa.2018.0633},
	language = {en},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Rodríguez, Miguel Á. and Romaniega, Álvaro and Tempesta, Piergiulio},
	year = {2019},
}

@inproceedings{creager_environment_2021,
	title = {Environment {Inference} for {Invariant} {Learning}},
	language = {en},
	booktitle = {{ICML}},
	author = {Creager, Elliot and Jacobsen, Jörn-Henrik and Zemel, Richard},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{liu_heterogeneous_2021,
	title = {Heterogeneous risk minimization},
	language = {en},
	booktitle = {{ICML}},
	author = {Liu, Jiashuo and Hu, Zheyuan and Cui, Peng and Li, Bo and Shen, Zheyan},
	year = {2021},
}

@article{bu_tightening_2020,
	title = {Tightening mutual information based bounds on generalization error},
	volume = {1},
	issn = {2641-8770},
	doi = {10.1109/JSAIT.2020.2991139},
	language = {en},
	number = {1},
	journal = {IEEE Journal on Selected Areas in Information Theory},
	author = {Bu, Yuheng and Zou, Shaofeng and Veeravalli, Venugopal V.},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {121--130},
}

@inproceedings{xu_information-theoretic_2017,
	title = {Information-theoretic analysis of generalization capability of learning algorithms},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Xu, Aolin and Raginsky, Maxim},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Information Theory},
}

@inproceedings{wu_information-theoretic_2020,
	title = {Information-theoretic analysis for transfer learning},
	language = {en},
	booktitle = {{IEEE} {International} {Symposium} on {Information} {Theory} ({ISIT})},
	author = {Wu, Xuetong and Manton, Jonathan H. and Aickelin, Uwe and Zhu, Jingge},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{jose_information-theoretic_2021,
	title = {An information-theoretic analysis of the impact of task similarity on meta-learning},
	language = {en},
	booktitle = {{IEEE} {International} {Symposium} on {Information} {Theory} ({ISIT})},
	author = {Jose, Sharu Theresa and Simeone, Osvaldo},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Information Theory, Electrical Engineering and Systems Science - Signal Processing},
}

@article{zenon_information-theoretic_2019,
	title = {An information-theoretic perspective on the costs of cognition},
	volume = {123},
	journal = {Neuropsychologia},
	author = {Zenon, Alexandre and Solopchuk, Oleg and Pezzulo, Giovanni},
	year = {2019},
	pages = {5--18},
}

@article{miyake_unity_2000,
	title = {The unity and diversity of executive functions and their contributions to complex “frontal lobe” tasks: {A} latent variable analysis},
	volume = {41},
	issn = {00100285},
	shorttitle = {The unity and diversity of executive functions and their contributions to complex “frontal lobe” tasks},
	doi = {10.1006/cogp.1999.0734},
	language = {en},
	number = {1},
	journal = {Cognitive Psychology},
	author = {Miyake, Akira and Friedman, Naomi P. and Emerson, Michael J. and Witzki, Alexander H. and Howerter, Amy and Wager, Tor D.},
	year = {2000},
	pages = {49--100},
}

@inproceedings{koh_wilds_2021,
	title = {Wilds: {A} benchmark of in-the-wild distribution shifts},
	shorttitle = {Wilds},
	language = {en},
	booktitle = {{ICML}},
	author = {Koh, Pang Wei and Sagawa, Shiori and Marklund, Henrik and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and Lee, Tony and David, Etienne and Stavness, Ian and Guo, Wei and Earnshaw, Berton A. and Haque, Imran S. and Beery, Sara and Leskovec, Jure and Kundaje, Anshul and Pierson, Emma and Levine, Sergey and Finn, Chelsea and Liang, Percy},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@article{raghuram_detecting_2020,
	title = {Detecting anomalous inputs to {DNN} classifiers by joint statistical testing at the layers},
	language = {en},
	journal = {arXiv:2007.15147 [cs, stat]},
	author = {Raghuram, Jayaram and Chandrasekaran, Varun and Jha, Somesh and Banerjee, Suman},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Cryptography and Security},
}

@inproceedings{tripuraneni_provable_2021,
	title = {Provable meta-learning of linear representations},
	booktitle = {{ICML}},
	author = {Tripuraneni, Nilesh and Jin, Chi and Jordan, Michael I.},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{veeriah_discovery_2021,
	title = {Discovery of options via meta-learned subgoals},
	language = {en},
	journal = {arXiv preprint arXiv:2102.06741},
	author = {Veeriah, Vivek and Zahavy, Tom and Hessel, Matteo and Xu, Zhongwen and Oh, Junhyuk and Kemaev, Iurii and van Hasselt, Hado and Silver, David and Singh, Satinder},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{kirsch_improving_2020,
	title = {Improving generalization in meta reinforcement learning using learned objectives},
	language = {en},
	booktitle = {{ICLR}},
	author = {Kirsch, Louis and van Steenkiste, Sjoerd and Schmidhuber, Jürgen},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, I.2.6},
}

@article{jose_information-theoretic_2021-1,
	title = {Information-theoretic generalization bounds for meta-learning and applications},
	volume = {23},
	number = {1},
	journal = {Entropy},
	author = {Jose, Sharu Theresa and Simeone, Osvaldo},
	year = {2021},
	pages = {126},
}

@inproceedings{al-shedivat_data_2021,
	title = {On data eﬃciency of meta-learning},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Al-Shedivat, Maruan and Li, Liam and Xing, Eric and Talwalkar, Ameet},
	year = {2021},
}

@article{jose_transfer_2020,
	title = {Transfer meta-learning: {Information}-theoretic bounds and information meta-risk minimization},
	shorttitle = {Transfer meta-learning},
	language = {en},
	journal = {arXiv preprint arXiv:2011.02872},
	author = {Jose, Sharu Theresa and Simeone, Osvaldo and Durisi, Giuseppe},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Information Theory, Electrical Engineering and Systems Science - Signal Processing},
}

@inproceedings{yao_automated_2020,
	title = {Automated relational meta-learning},
	booktitle = {{ICLR}},
	author = {Yao, Huaxiu and Wu, Xian and Tao, Zhiqiang and Li, Yaliang and Ding, Bolin and Li, Ruirui and Li, Zhenhui},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{goldblum_unraveling_2020,
	title = {Unraveling meta-learning: {Understanding} feature representations for few-shot tasks},
	booktitle = {{ICML}},
	author = {Goldblum, Micah and Reich, Steven and Fowl, Liam and Ni, Renkun and Cherepanova, Valeriia and Goldstein, Tom},
	year = {2020},
}

@inproceedings{fallah_convergence_2020,
	title = {On the convergence theory of gradient-based model-agnostic meta-learning algorithms},
	booktitle = {{AISTATS}},
	author = {Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
	year = {2020},
}

@inproceedings{fallah_personalized_2020,
	title = {Personalized federated learning with theoretical guarantees: {A} model-agnostic meta-learning approach},
	shorttitle = {Personalized federated learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
	pages = {3557--3568},
}

@inproceedings{du_bilinear_2021,
	title = {Bilinear classes: {A} structural framework for provable generalization in {RL}},
	shorttitle = {Bilinear classes},
	booktitle = {{ICML}},
	author = {Du, Simon S. and Kakade, Sham M. and Lee, Jason D. and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Mathematics - Optimization and Control},
}

@inproceedings{du_few-shot_2021,
	title = {Few-shot learning via learning the representation, provably},
	booktitle = {{ICLR}},
	author = {Du, Simon S. and Hu, Wei and Kakade, Sham M. and Lee, Jason D. and Lei, Qi},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@inproceedings{poole_variational_2019,
	title = {On variational bounds of mutual information},
	booktitle = {{ICML}},
	author = {Poole, Ben and Ozair, Sherjil},
	year = {2019},
}

@inproceedings{agarwal_deep_2021,
	title = {Deep reinforcement learning at the edge of the statistical precipice},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron and Bellemare, Marc G},
	year = {2021},
}

@inproceedings{cheng_club_2020,
	title = {{CLUB}: {A} contrastive log-ratio upper bound of mutual information},
	language = {en},
	booktitle = {{ICML}},
	author = {Cheng, Pengyu and Hao, Weituo and Dai, Shuyang and Liu, Jiachang and Gan, Zhe and Carin, Lawrence},
	year = {2020},
}

@inproceedings{wang_revisiting_2021,
	title = {Revisiting locally supervised learning: {An} alternative to end-to-end training},
	shorttitle = {Revisiting locally supervised learning},
	language = {en},
	booktitle = {{ICLR}},
	author = {Wang, Yulin and Ni, Zanlin and Song, Shiji and Yang, Le and Huang, Gao},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{abel_expressivity_2021,
	title = {On the expressivity of {Markov} reward},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Abel, David and Dabney, Will and Harutyunyan, Anna},
	year = {2021},
}

@inproceedings{papernot_practical_2017,
	address = {Abu Dhabi United Arab Emirates},
	title = {Practical black-box attacks against machine learning},
	isbn = {978-1-4503-4944-4},
	doi = {10.1145/3052973.3053009},
	language = {en},
	booktitle = {Proceedings of the 2017 {ACM} on {Asia} {Conference} on {Computer} and {Communications} {Security}},
	author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z. Berkay and Swami, Ananthram},
	year = {2017},
	pages = {506--519},
}

@inproceedings{goodfellow_explaining_2015,
	title = {Explaining and harnessing adversarial examples},
	booktitle = {{ICLR}},
	author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
	year = {2015},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{kurakin_adversarial_2017,
	title = {Adversarial examples in the physical world},
	language = {en},
	booktitle = {{ICLR} {Workshop}},
	author = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security},
}

@inproceedings{szegedy_intriguing_2014,
	title = {Intriguing properties of neural networks},
	booktitle = {{ICLR}},
	author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
	year = {2014},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{bubeck_universal_2021,
	title = {A universal law of robustness via isoperimetry},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bubeck, Sebastien and Sellke, Mark},
	year = {2021},
}

@inproceedings{rozen_moser_2021,
	title = {Moser flow: {Divergence}-based generative modeling on manifolds},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Rozen, Noam and Grover, Aditya and Nickel, Maximilian and Lipman, Yaron},
	year = {2021},
}

@inproceedings{pillutla_mauve_2021,
	title = {{MAUVE}: {Measuring} the gap between neural text and human text using divergence frontiers},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Pillutla, Krishna and Swayamdipta, Swabha and Zellers, Rowan and Thickstun, John and Welleck, Sean and Choi, Yejin and Harchaoui, Zaid},
	year = {2021},
	pages = {13},
}

@inproceedings{even_continuized_2021,
	title = {A continuized view on nesterov acceleration for stochastic gradient descent and randomized gossip},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Even, Mathieu and Berthier, Raphaël and Bach, Francis and Flammarion, Nicolas and Gaillard, Pierre and Hendrikx, Hadrien and Massoulié, Laurent and Taylor, Adrien},
	year = {2021},
}

@inproceedings{liang_rllib_2018,
	title = {Rllib: {Abstractions} for distributed reinforcement learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Liang, Eric and Liaw, Richard and Moritz, Philipp and Nishihara, Robert and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph E and Jordan, Michael I and Stoica, Ion},
	year = {2018},
}

@inproceedings{liu_open_2018,
	title = {Open category detection with {PAC} guarantees},
	language = {en},
	booktitle = {{ICML}},
	author = {Liu, Si and Garrepalli, Risheek and Dietterich, Thomas G and Fern, Alan and Hendrycks, Dan},
	year = {2018},
}

@inproceedings{fang_learning_2021,
	title = {Learning bounds for open-set learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Fang, Zhen and Lu, Jie and Liu, Anjin and Liu, Feng and Zhang, Guangquan},
	year = {2021},
}

@inproceedings{nguyen_deep_2015,
	address = {Boston, MA, USA},
	title = {Deep neural networks are easily fooled: {High} confidence predictions for unrecognizable images},
	isbn = {978-1-4673-6964-0},
	shorttitle = {Deep neural networks are easily fooled},
	doi = {10.1109/CVPR.2015.7298640},
	language = {en},
	booktitle = {{CVPR}},
	author = {Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
	year = {2015},
	pages = {427--436},
}

@article{li_optimol_2010,
	title = {Optimol: {Automatic} online picture collection via incremental model learning},
	volume = {88},
	issn = {0920-5691, 1573-1405},
	shorttitle = {Optimol},
	doi = {10.1007/s11263-009-0265-6},
	language = {en},
	number = {2},
	journal = {International Journal of Computer Vision},
	author = {Li, Li-Jia and Fei-Fei, Li},
	year = {2010},
	pages = {147--168},
}

@article{yang_generalized_2021,
	title = {Generalized out-of-distribution detection: {A} survey},
	shorttitle = {Generalized out-of-distribution detection},
	language = {en},
	journal = {arXiv preprint arXiv:2110.11334},
	author = {Yang, Jingkang and Zhou, Kaiyang and Li, Yixuan and Liu, Ziwei},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{farajtabar_orthogonal_2020,
	title = {Orthogonal gradient descent for continual learning},
	isbn = {2640-3498},
	booktitle = {{AISTATS}},
	author = {Farajtabar, Mehrdad and Azizan, Navid and Mott, Alex and Li, Ang},
	year = {2020},
	pages = {3762--3773},
}

@article{zeng_continual_2019,
	title = {Continual learning of context-dependent processing in neural networks},
	volume = {1},
	issn = {2522-5839},
	doi = {10.1038/s42256-019-0080-x},
	language = {en},
	number = {8},
	journal = {Nature Machine Intelligence},
	author = {Zeng, Guanxiong and Chen, Yang and Cui, Bo and Yu, Shan},
	year = {2019},
	pages = {364--372},
}

@article{diaz-rodriguez_dont_2018,
	title = {Don't forget, there is more than forgetting: {New} metrics for {Continual} {Learning}},
	journal = {arXiv preprint arXiv:1810.13166},
	author = {Díaz-Rodríguez, Natalia and Lomonaco, Vincenzo and Filliat, David and Maltoni, Davide},
	year = {2018},
}

@inproceedings{buzzega_dark_2020,
	title = {Dark experience for general continual learning: {A} strong, simple baseline},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Buzzega, Pietro and Boschini, Matteo and Porrello, Angelo and Abati, Davide and Calderara, Simone},
	year = {2020},
}

@inproceedings{ha_recurrent_2018,
	title = {Recurrent world models facilitate policy evolution},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ha, David and Schmidhuber, Jürgen},
	year = {2018},
}

@article{nachum_reinforcement_2020,
	title = {Reinforcement learning via {Fenchel}-{Rockafellar} duality},
	journal = {arXiv preprint arXiv:2001.01866},
	author = {Nachum, Ofir and Dai, Bo},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{hafner_dream_2020,
	title = {Dream to control: {Learning} behaviors by latent imagination},
	shorttitle = {Dream to control},
	language = {en},
	booktitle = {{ICLR}},
	author = {Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{richter_solving_2021,
	title = {Solving high-dimensional parabolic {PDEs} using the tensor train format},
	language = {en},
	booktitle = {{ICML}},
	author = {Richter, Lorenz and Sallandt, Leon},
	year = {2021},
}

@inproceedings{vicol_unbiased_2021,
	title = {Unbiased gradient estimation in unrolled computation graphs with persistent evolution strategies},
	language = {en},
	booktitle = {{ICML}},
	author = {Vicol, Paul and Metz, Luke and Sohl-Dickstein, Jascha},
	year = {2021},
	pages = {11},
}

@inproceedings{tian_understanding_2021,
	title = {Understanding self-supervised learning dynamics without contrastive pairs},
	language = {en},
	booktitle = {{ICML}},
	author = {Tian, Yuandong and Chen, Xinlei and Ganguli, Surya},
	year = {2021},
}

@inproceedings{grathwohl_oops_2021,
	title = {Oops {I} took a gradient: {Scalable} sampling for discrete distributions},
	language = {en},
	booktitle = {{ICML}},
	author = {Grathwohl, Will and Swersky, Kevin and Hashemi, Milad and Duvenaud, David and Maddison, Chris J},
	year = {2021},
}

@inproceedings{lu_optimal_2021,
	title = {Optimal complexity in decentralized training},
	language = {en},
	booktitle = {{ICML}},
	author = {Lu, Yucheng and Sa, Christopher De},
	year = {2021},
}

@inproceedings{andreas_neural_2016,
	address = {Las Vegas, NV, USA},
	title = {Neural module networks},
	isbn = {978-1-4673-8851-1},
	doi = {10.1109/CVPR.2016.12},
	language = {en},
	booktitle = {{CVPR}},
	author = {Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
	year = {2016},
	pages = {39--48},
}

@inproceedings{farinhas_sparse_2022,
	title = {Sparse communication via mixed distributions},
	booktitle = {{ICLR}},
	author = {Farinhas, António and Aziz, Wilker and Niculae, Vlad and Martins, André F T},
	year = {2022},
}

@inproceedings{vaze_open-set_2022,
	title = {Open-set recognition: {A} good closed-set classifier is all you need},
	shorttitle = {Open-set recognition},
	language = {en},
	booktitle = {{ICLR}},
	author = {Vaze, Sagar and Han, Kai and Vedaldi, Andrea and Zisserman, Andrew},
	year = {2022},
}

@article{mitchell_algorithmic_2021,
	title = {Algorithmic fairness: {Choices}, assumptions, and definitions},
	volume = {8},
	issn = {2326-8298, 2326-831X},
	shorttitle = {Algorithmic fairness},
	doi = {10.1146/annurev-statistics-042720-125902},
	language = {en},
	number = {1},
	journal = {Annual Review of Statistics and Its Application},
	author = {Mitchell, Shira and Potash, Eric and Barocas, Solon and D'Amour, Alexander and Lum, Kristian},
	year = {2021},
	pages = {141--163},
}

@inproceedings{sagawa_extending_2022,
	title = {Extending the wilds benchmark for unsupervised adaptation},
	booktitle = {{ICLR}},
	author = {Sagawa, Shiori and Koh, Pang Wei and Lee, Tony and Gao, Irena and Xie, Sang Michael and Shen, Kendrick and Kumar, Ananya and Hu, Weihua and Yasunaga, Michihiro and Marklund, Henrik and Beery, Sara and David, Etienne and Stavness, Ian and Guo, Wei and Leskovec, Jure and Saenko, Kate and Hashimoto, Tatsunori and Levine, Sergey and Finn, Chelsea and Liang, Percy},
	year = {2022},
}

@inproceedings{eysenbach_information_2022,
	title = {The information geometry of unsupervised reinforcement learning},
	language = {en},
	booktitle = {{ICLR}},
	author = {Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
	year = {2022},
}

@inproceedings{madaan_representational_2022,
	title = {Representational continuity for unsupervised continual learning},
	language = {en},
	booktitle = {{ICLR}},
	author = {Madaan, Divyam and Yoon, Jaehong and Li, Yuanchun and Liu, Yunxin and Hwang, Sung Ju},
	year = {2022},
}

@inproceedings{raileanu_decoupling_2021,
	title = {Decoupling value and policy for generalization in reinforcement learning},
	booktitle = {{ICML}},
	author = {Raileanu, Roberta and Fergus, Rob},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{mai_online_2022,
	title = {Online continual learning in image classification: {An} empirical survey},
	volume = {469},
	issn = {0925-2312},
	shorttitle = {Online continual learning in image classification},
	doi = {10.1016/j.neucom.2021.10.021},
	language = {en},
	journal = {Neurocomputing},
	author = {Mai, Zheda and Li, Ruiwen and Jeong, Jihwan and Quispe, David and Kim, Hyunwoo and Sanner, Scott},
	year = {2022},
	keywords = {Catastrophic forgetting, Continual learning, Incremental learning, Lifelong learning, Online learning},
	pages = {28--51},
}

@inproceedings{hsu_re-evaluating_2018,
	title = {Re-evaluating continual learning scenarios: {A} categorization and case for strong baselines},
	shorttitle = {Re-evaluating continual learning scenarios},
	language = {en},
	booktitle = {Continual {Learning} {Workshop}, 32nd {Conference} on {Neural} {Information} {Processing} {Systems} ({NeurIPS} 2018)},
	author = {Hsu, Yen-Chang and Liu, Yen-Cheng and Ramasamy, Anita and Kira, Zsolt},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{derakhshani_kernel_2021,
	title = {Kernel continual learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Derakhshani, Mohammad Mahdi and Zhen, Xiantong and Shao, Ling and Snoek, Cees G M},
	year = {2021},
	pages = {11},
}

@inproceedings{mouli_asymmetry_2022,
	title = {Asymmetry learning for counterfactually-invariant classification in {OOD} tasks},
	language = {en},
	author = {Mouli, S. Chandra and Ribeiro, Bruno},
	year = {2022},
}

@article{shwartz-ziv_information_2022,
	title = {Information flow in deep neural networks},
	language = {en},
	journal = {arXiv preprint arXiv:2202.06749},
	author = {Shwartz-Ziv, Ravid},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@article{shwartz-ziv_opening_2017,
	title = {Opening the black box of deep neural networks via information},
	language = {en},
	journal = {arXiv preprint arXiv:1703.00810},
	author = {Shwartz-Ziv, Ravid and Tishby, Naftali},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@article{devroye_nonuniform_2006,
	title = {Nonuniform random variate generation},
	volume = {13},
	journal = {Handbooks in operations research and management science},
	author = {Devroye, Luc},
	year = {2006},
	pages = {83--121},
}

@article{samvelyan_minihack_2021,
	title = {Minihack the planet: {A} sandbox for open-ended reinforcement learning research},
	shorttitle = {Minihack the planet},
	language = {en},
	journal = {arXiv preprint arXiv:2109.13202},
	author = {Samvelyan, Mikayel and Kirk, Robert and Kurin, Vitaly and Parker-Holder, Jack and Jiang, Minqi and Hambro, Eric and Petroni, Fabio and Küttler, Heinrich and Grefenstette, Edward and Rocktäschel, Tim},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{greff_binding_2020,
	title = {On the binding problem in artificial neural networks},
	language = {en},
	journal = {arXiv preprint arXiv:2012.05208},
	author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, Jürgen},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, I.2.6},
}

@article{jiang_transferability_2022,
	title = {Transferability in deep learning: {A} survey},
	shorttitle = {Transferability in deep learning},
	language = {en},
	journal = {arXiv preprint arXiv:2201.05867},
	author = {Jiang, Junguang and Shu, Yang and Wang, Jianmin and Long, Mingsheng},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@article{he_automl_2021,
	title = {{AutoML}: {A} survey of the state-of-the-art},
	volume = {212},
	issn = {09507051},
	shorttitle = {{AutoML}},
	doi = {10.1016/j.knosys.2020.106622},
	language = {en},
	journal = {Knowledge-Based Systems},
	author = {He, Xin and Zhao, Kaiyong and Chu, Xiaowen},
	year = {2021},
	pages = {106622},
}

@inproceedings{ledell_h2o_2020,
	title = {{H2O} automl: {Scalable} automatic machine learning},
	booktitle = {7th {ICML} {Workshop} on {Automated} {Machine} {Learning}},
	author = {LeDell, E and Poirier, S},
	year = {2020},
}

@article{balaji_benchmarking_2018,
	title = {Benchmarking automatic machine learning frameworks},
	journal = {arXiv preprint arXiv:1808.06492},
	author = {Balaji, Adithya and Allen, Alexander},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{zhang_fundamental_2022,
	title = {On the fundamental difficulty in invariance learning for domain generalization},
	author = {Zhang, Tianren and Chen, Feng},
	year = {2022},
}

@inproceedings{lee_learning_2021,
	title = {Learning debiased representation via disentangled feature augmentation},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lee, Jungsoo and Kim, Eungyeup and Lee, Juyoung and Lee, Jihyeon and Choo, Jaegul},
	year = {2021},
}

@inproceedings{zhang_generalized_2018,
	title = {Generalized cross entropy loss for training deep neural networks with noisy labels},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhang, Zhilu and Sabuncu, Mert},
	year = {2018},
	pages = {8792--8802},
}

@inproceedings{blalock_what_2020,
	title = {What is the state of neural network pruning?},
	language = {en},
	booktitle = {Machine {Learning} and {Systems}},
	author = {Blalock, Davis and Ortiz, Jose Javier Gonzalez and Frankle, Jonathan and Guttag, John},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{zhou_deconstructing_2019,
	title = {Deconstructing lottery tickets: {Zeros}, signs, and the supermask},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhou, Hattie and Lan, Janice and Liu, Rosanne and Yosinski, Jason},
	year = {2019},
}

@inproceedings{csordas_are_2022,
	title = {Are neural nets modular? {Inspecting} functional modularity through differentiable weight masks},
	shorttitle = {Are neural nets modular?},
	language = {en},
	booktitle = {{ICLR}},
	author = {Csordás, Róbert and van Steenkiste, Sjoerd and Schmidhuber, Jürgen},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{ahmed_systematic_2021,
	title = {Systematic generalisation with group invariant predictions},
	language = {en},
	booktitle = {{ICLR}},
	author = {Ahmed, Faruk and Bengio, Yoshua and van Seijen, Harm and Courville, Aaron},
	year = {2021},
}

@article{jin_domain_2020,
	title = {Domain extrapolation via regret minimization},
	journal = {arXiv preprint arXiv:2006.03908},
	author = {Jin, Wengong and Barzilay, Regina and Jaakkola, Tommi},
	year = {2020},
}

@inproceedings{finn_one-shot_2017,
	title = {One-shot visual imitation learning via meta-learning},
	isbn = {2640-3498},
	booktitle = {{CoRL}},
	author = {Finn, Chelsea and Yu, Tianhe and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
	year = {2017},
	pages = {357--368},
}

@article{hornik_multilayer_1989,
	title = {Multilayer feedforward networks are universal approximators},
	volume = {2},
	number = {5},
	journal = {Neural networks},
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	year = {1989},
	pages = {359--366},
}

@article{funahashi_approximate_1989,
	title = {On the approximate realization of continuous mappings by neural networks},
	volume = {2},
	issn = {08936080},
	doi = {10.1016/0893-6080(89)90003-8},
	language = {en},
	number = {3},
	journal = {Neural Networks},
	author = {Funahashi, Ken-Ichi},
	year = {1989},
	pages = {183--192},
}

@article{cybenko_approximation_1989,
	title = {Approximation by superpositions of a sigmoidal function},
	volume = {2},
	number = {4},
	journal = {Mathematics of control, signals and systems},
	author = {Cybenko, George},
	year = {1989},
	pages = {303--314},
}

@article{hornik_universal_1990,
	title = {Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks},
	volume = {3},
	issn = {08936080},
	doi = {10.1016/0893-6080(90)90005-6},
	language = {en},
	number = {5},
	journal = {Neural Networks},
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	year = {1990},
	pages = {551--560},
}

@article{gao_transfering_2022,
	title = {Transfering hierarchical structure with dual meta imitation learning},
	journal = {arXiv preprint arXiv:2201.11981},
	author = {Gao, Chongkai and Jiang, Yizhou and Chen, Feng},
	year = {2022},
}

@article{li_learning_2022,
	title = {Learning invariable semantical representation from language for extensible policy generalization},
	language = {en},
	journal = {arXiv preprint arXiv:2202.00466},
	author = {Li, Yihan and Ren, Jinsheng and Xu, Tianrun and Zhang, Tianren and Gao, Haichuan and Chen, Feng},
	year = {2022},
}

@article{fujimoto_why_2022,
	title = {Why should {I} trust you, bellman? {The} bellman error is a poor replacement for value error},
	shorttitle = {Why should i trust you, bellman?},
	language = {en},
	journal = {arXiv preprint arXiv:2201.12417},
	author = {Fujimoto, Scott and Meger, David and Precup, Doina and Nachum, Ofir and Gu, Shixiang Shane},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{reid_can_2022,
	title = {Can wikipedia help offline reinforcement learning?},
	language = {en},
	journal = {arXiv preprint arXiv:2201.12122},
	author = {Reid, Machel and Yamada, Yutaro and Gu, Shixiang Shane},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{chen_decision_2021,
	title = {Decision transformer: {Reinforcement} learning via sequence modeling},
	shorttitle = {Decision transformer},
	language = {en},
	journal = {arXiv preprint arXiv:2106.01345},
	author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{zhang_when_2019,
	title = {When unseen domain generalization is unnecessary? {Rethinking} data augmentation},
	shorttitle = {When unseen domain generalization is unnecessary?},
	language = {en},
	journal = {arXiv preprint arXiv:1906.03347},
	author = {Zhang, Ling and Wang, Xiaosong and Yang, Dong and Sanford, Thomas and Harmon, Stephanie and Turkbey, Baris and Roth, Holger and Myronenko, Andriy and Xu, Daguang and Xu, Ziyue},
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
}

@inproceedings{zhang_mixup_2018,
	title = {Mixup: {Beyond} empirical risk minimization},
	shorttitle = {Mixup},
	language = {en},
	booktitle = {{ICLR}},
	author = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and Lopez-Paz, David},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{miller_accuracy_2021,
	title = {Accuracy on the line: {On} the strong correlation  between out-of-distribution and in-distribution generalization},
	language = {en},
	booktitle = {{ICML}},
	author = {Miller, John and Taori, Rohan and Raghunathan, Aditi and Sagawa, Shiori and Koh, Pang Wei and Shankar, Vaishaal and Liang, Percy and Carmon, Yair and Schmidt, Ludwig},
	year = {2021},
}

@inproceedings{cortes_discriminative_2021,
	title = {A discriminative technique for multiple-source adaptation},
	language = {en},
	booktitle = {{ICML}},
	author = {Cortes, Corinna and Mohri, Mehryar and Suresh, Ananda Theertha and Zhang, Ningshan},
	year = {2021},
}

@inproceedings{hu_does_2018,
	title = {Does distributionally robust supervised learning give robust classifiers?},
	language = {en},
	booktitle = {{ICML}},
	author = {Hu, Weihua and Niu, Gang and Sato, Issei and Sugiyama, Masashi},
	year = {2018},
}

@article{ehrenfeucht_general_1989,
	title = {A general lower bound on the number of examples needed for learning},
	volume = {82},
	issn = {08905401},
	doi = {10.1016/0890-5401(89)90002-3},
	language = {en},
	number = {3},
	journal = {Information and Computation},
	author = {Ehrenfeucht, Andrzej and Haussler, David and Kearns, Michael and Valiant, Leslie},
	year = {1989},
	pages = {247--261},
}

@article{hoeffding_probability_1963,
	title = {Probability inequalities for sums of bounded random variables},
	volume = {58},
	number = {301},
	journal = {Journal of the American Statistical Association},
	author = {Hoeffding, Wassily},
	year = {1963},
	pages = {13--30},
}

@article{hoffman_multiple-source_2017,
	title = {Multiple-source adaptation for regression problems},
	journal = {arXiv preprint arXiv:1711.05037},
	author = {Hoffman, Judy and Mohri, Mehryar and Zhang, Ningshan},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@article{lyu_barycentric-alignment_2021,
	title = {Barycentric-alignment and invertibility for domain generalization},
	language = {en},
	journal = {arXiv preprint arXiv:2109.01902},
	author = {Lyu, Boyang and Nguyen, Thuan and Ishwar, Prakash and Scheutz, Matthias and Aeron, Shuchin},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{mansour_theory_2021,
	title = {A theory of multiple-source adaptation with limited target labeled data},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Mansour, Yishay and Mohri, Mehryar and Ro, Jae and Suresh, Ananda Theertha and Wu, Ke},
	year = {2021},
}

@article{geisa_towards_2021,
	title = {Towards a theory of out-of-distribution learning},
	language = {en},
	journal = {arXiv preprint arXiv:2109.14501},
	author = {Geisa, Ali and Mehta, Ronak and Helm, Hayden S. and Dey, Jayanta and Eaton, Eric and Dick, Jeffery and Priebe, Carey E. and Vogelstein, Joshua T.},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{kifer_detecting_2004,
	title = {Detecting change in data streams},
	volume = {4},
	booktitle = {{VLDB}},
	author = {Kifer, Daniel and Ben-David, Shai and Gehrke, Johannes},
	year = {2004},
	pages = {180--191},
}

@article{xu_why_2021,
	title = {Why stable learning works? {A} theory of covariate shift generalization},
	shorttitle = {Why stable learning works?},
	language = {en},
	journal = {arXiv preprint arXiv:2111.02355},
	author = {Xu, Renzhe and Cui, Peng and Shen, Zheyan and Zhang, Xingxuan and Zhang, Tong},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{dranker_irmwhen_2021,
	title = {{IRM}—when it works and when it doesn’t: {A} test case of natural language inference},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dranker, Yana and He, He and Belinkov, Yonatan},
	year = {2021},
}

@article{zhao_fundamental_2021,
	title = {Fundamental limits and tradeoffs in invariant representation learning},
	language = {en},
	journal = {arXiv preprint arXiv:2012.10713},
	author = {Zhao, Han and Dan, Chen and Aragam, Bryon and Jaakkola, Tommi S. and Gordon, Geoffrey J. and Ravikumar, Pradeep},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{ajakan_domain-adversarial_2014,
	title = {Domain-adversarial neural networks},
	language = {en},
	journal = {arXiv preprint arXiv:1412.4446},
	author = {Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, François and Marchand, Mario},
	year = {2014},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{tachet_domain_2020,
	title = {Domain adaptation with conditional distribution matching and generalized label shift},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Tachet, Remi and Zhao, Han and Wang, Yu-Xiang and Gordon, Geoff},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{long_transfer_2014,
	address = {Columbus, OH, USA},
	title = {Transfer joint matching for unsupervised domain adaptation},
	isbn = {978-1-4799-5118-5},
	doi = {10.1109/CVPR.2014.183},
	language = {en},
	booktitle = {{CVPR}},
	author = {Long, Mingsheng and Wang, Jianmin and Ding, Guiguang and Sun, Jiaguang and Yu, Philip S.},
	year = {2014},
	pages = {1410--1417},
}

@inproceedings{wang_bridging_2021,
	title = {Bridging multi-task learning and meta-learning: {Towards} efficient training and effective adaptation},
	shorttitle = {Bridging multi-task learning and meta-learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Wang, Haoxiang and Zhao, Han and Li, Bo},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{ben-david_hardness_2012,
	title = {On the hardness of domain adaptation and the utility of unlabeled target samples},
	booktitle = {{COLT}},
	author = {Ben-David, Shai and Urner, Ruth},
	year = {2012},
	pages = {139--153},
}

@inproceedings{courty_joint_2017,
	title = {Joint distribution optimal transportation for domain adaptation},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Courty, Nicolas and Flamary, Rémi and Habrard, Amaury and Rakotomamonjy, Alain},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{ganin_unsupervised_2015,
	title = {Unsupervised domain adaptation by backpropagation},
	language = {en},
	booktitle = {{ICML}},
	author = {Ganin, Yaroslav and Lempitsky, Victor},
	year = {2015},
}

@inproceedings{mansour_domain_2009,
	title = {Domain adaptation: {Learning} bounds and algorithms},
	shorttitle = {Domain adaptation},
	booktitle = {{COLT}},
	author = {Mansour, Yishay and Mohri, Mehryar and Rostamizadeh, Afshin},
	year = {2009},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{blanchard_domain_2021,
	title = {Domain generalization by marginal transfer learning},
	language = {en},
	journal = {Journal of machine learning research},
	author = {Blanchard, Gilles and Deshmukh, Aniket Anand and Dogan, Urun and Lee, Gyemin and Scott, Clayton},
	year = {2021},
	keywords = {Statistics - Machine Learning},
}

@inproceedings{piratla_efficient_2020,
	title = {Efficient domain generalization via common-specific low-rank decomposition},
	language = {en},
	booktitle = {{ICML}},
	author = {Piratla, Vihari and Netrapalli, Praneeth and Sarawagi, Sunita},
	year = {2020},
}

@inproceedings{zhao_adversarial_2018,
	title = {Adversarial multiple source domain adaptation},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhao, Han and Zhang, Shanghang and Wu, Guanhang and Costeira, Joao P and Moura, Jose M F and Gordon, Geoffrey J},
	year = {2018},
}

@inproceedings{xu_deep_2018,
	address = {Salt Lake City, UT},
	title = {Deep cocktail network: {Multi}-source unsupervised domain adaptation with category shift},
	isbn = {978-1-5386-6420-9},
	shorttitle = {Deep cocktail network},
	doi = {10.1109/CVPR.2018.00417},
	language = {en},
	booktitle = {{CVPR}},
	author = {Xu, Ruijia and Chen, Ziliang and Zuo, Wangmeng and Yan, Junjie and Lin, Liang},
	year = {2018},
	pages = {3964--3973},
}

@inproceedings{phung_learning_2021,
	title = {On learning domain-invariant representations for transfer learning with multiple sources},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Phung, Trung and Le, Trung and Vuong, Long and Tran, Toan and Tran, Anh and Bui, Hung and Phung, Dinh},
	year = {2021},
}

@inproceedings{mansour_domain_2008,
	title = {Domain adaptation with multiple sources},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Mansour, Yishay and Mohri, Mehryar and Rostamizadeh, Afshin},
	year = {2008},
}

@inproceedings{le_lamda_2021,
	title = {Lamda: {Label} matching deep domain adaptation},
	language = {en},
	booktitle = {{ICML}},
	author = {Le, Trung and Nguyen, Tuan and Ho, Nhat and Bui, Hung and Phung, Dinh},
	year = {2021},
	pages = {12},
}

@article{ben-david_domain_2014,
	title = {Domain adaptation–can quantity compensate for quality?},
	volume = {70},
	issn = {1012-2443, 1573-7470},
	doi = {10.1007/s10472-013-9371-9},
	language = {en},
	number = {3},
	journal = {Annals of Mathematics and Artificial Intelligence},
	author = {Ben-David, Shai and Urner, Ruth},
	year = {2014},
	pages = {185--202},
}

@inproceedings{bartlett_learning_1996,
	address = {Desenzano del Garda, Italy},
	title = {Learning changing concepts by exploiting the structure of change},
	isbn = {978-0-89791-811-4},
	doi = {10.1145/238061.238080},
	language = {en},
	booktitle = {{COLT}},
	author = {Bartlett, Peter L. and Ben-David, Shai and Kulkarni, Sanjeev R.},
	year = {1996},
	pages = {131--139},
}

@article{ben-david_learnability_2019,
	title = {Learnability can be undecidable},
	volume = {1},
	issn = {2522-5839},
	doi = {10.1038/s42256-018-0002-3},
	language = {en},
	number = {1},
	journal = {Nature Machine Intelligence},
	author = {Ben-David, Shai and Hrubeš, Pavel and Moran, Shay and Shpilka, Amir and Yehudayoff, Amir},
	year = {2019},
	pages = {44--48},
}

@inproceedings{johansson_support_2019,
	title = {Support and invertibility in domain-invariant representations},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Johansson, Fredrik D and Sontag, David and Ranganath, Rajesh},
	year = {2019},
}

@article{zhang_understanding_2021,
	title = {Understanding deep learning (still) requires rethinking generalization},
	volume = {64},
	issn = {0001-0782, 1557-7317},
	doi = {10.1145/3446776},
	language = {en},
	number = {3},
	journal = {Communications of the ACM},
	author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	year = {2021},
	pages = {107--115},
}

@inproceedings{cha_swad_2021,
	title = {Swad: {Domain} generalization by seeking flat minima},
	shorttitle = {Swad},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Cha, Junbum and Chun, Sanghyuk and Lee, Kyungjae and Cho, Han-Cheol and Park, Seunghyun and Lee, Yunsung and Park, Sungrae},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{zhao_domain_2020,
	title = {Domain generalization via entropy regularization},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhao, Shanshan and Gong, Mingming and Liu, Tongliang and Fu, Huan and Tao, Dacheng},
	year = {2020},
}

@inproceedings{zhang_learning_2021,
	title = {Learning invariant representations for reinforcement learning without reconstruction},
	language = {en},
	booktitle = {{ICLR}},
	author = {Zhang, Amy and McAllister, Rowan and Calandra, Roberto and Gal, Yarin and Levine, Sergey},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{volpi_generalizing_2018,
	title = {Generalizing to unseen domains via adversarial data augmentation},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Volpi, Riccardo and Namkoong, Hongseok and Sener, Ozan and Duchi, John C and Murino, Vittorio and Savarese, Silvio},
	year = {2018},
}

@inproceedings{robey_model-based_2021,
	title = {Model-based domain generalization},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Robey, Alexander and Pappas, George J and Hassani, Hamed},
	year = {2021},
}

@article{kirk_survey_2022,
	title = {A survey of generalisation in deep reinforcement learning},
	language = {en},
	journal = {arXiv preprint arXiv:2111.09794},
	author = {Kirk, Robert and Zhang, Amy and Grefenstette, Edward and Rocktäschel, Tim},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{ben-david_impossibility_2010,
	title = {Impossibility theorems for domain adaptation},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Ben-David, Shai and Luu, Teresa and Lu, Tyler and Pal, David},
	year = {2010},
}

@inproceedings{bartlett_learning_1992,
	title = {Learning with a slowly changing distribution},
	booktitle = {Proceedings of the fifth annual workshop on {Computational} learning theory},
	author = {Bartlett, Peter L.},
	year = {1992},
	pages = {243--252},
}

@inproceedings{janzing_causal_2019,
	title = {Causal regularization},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Janzing, Dominik},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, G.3, 62J02},
}

@inproceedings{mansour_theory_2021-1,
	title = {A theory of multiple-source adaptation with limited target labeled data},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Mansour, Yishay and Mohri, Mehryar and Ro, Jae and Suresh, Ananda Theertha and Wu, Ke},
	year = {2021},
}

@inproceedings{konstantinov_sample_2020,
	title = {On the sample complexity of adversarial multi-source {PAC} learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Konstantinov, Nikola and Frantar, Elias and Alistarh, Dan and Lampert, Christoph H},
	year = {2020},
	pages = {10},
}

@inproceedings{blum_collaborative_2017,
	title = {Collaborative {PAC} learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Blum, Avrim and Haghtalab, Nika and Procaccia, Ariel D and Qiao, Mingda},
	year = {2017},
}

@inproceedings{garg_learn_2021,
	title = {Learn to expect the unexpected: {Probably} approximately correct domain generalization},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Garg, Vikas K and Kalai, Adam Tauman and Ligett, Katrina and Wu, Zhiwei Steven},
	year = {2021},
	pages = {3574--3582},
}

@inproceedings{zhou_learning_2020,
	title = {Learning to generate novel domains for domain generalization},
	language = {en},
	booktitle = {{ECCV}},
	author = {Zhou, Kaiyang and Yang, Yongxin and Hospedales, Timothy and Xiang, Tao},
	year = {2020},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{sokolic_generalization_2017,
	title = {Generalization error of invariant classifiers},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Sokolic, Jure and Giryes, Raja and Sapiro, Guillermo and Rodrigues, Miguel R D},
	year = {2017},
}

@article{allen-zhu_feature_2021,
	title = {Feature purification: {How} adversarial training performs robust deep learning},
	shorttitle = {Feature purification},
	language = {en},
	journal = {arXiv preprint arXiv:2005.10190},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
}

@inproceedings{allen-zhu_backward_2023,
	title = {Backward feature correction: {How} deep learning performs deep learning},
	shorttitle = {Backward feature correction},
	language = {en},
	booktitle = {Conference on {Learning} {Theory}},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control, Computer Science - Data Structures and Algorithms},
}

@inproceedings{xu_what_2020,
	title = {What can neural networks reason about?},
	language = {en},
	booktitle = {{ICLR}},
	author = {Xu, Keyulu and Li, Jingling and Zhang, Mozhi and Du, Simon S. and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{zhang_is_2021,
	title = {Is reinforcement learning more difficult than bandits? {A} near-optimal algorithm escaping the curse of horizon},
	shorttitle = {Is reinforcement learning more difficult than bandits?},
	language = {en},
	booktitle = {{COLT}},
	author = {Zhang, Zihan and Ji, Xiangyang and Du, Simon S.},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{munkhdalai_meta_2017,
	title = {Meta networks},
	isbn = {2640-3498},
	booktitle = {{ICML}},
	author = {Munkhdalai, Tsendsuren and Yu, Hong},
	year = {2017},
	pages = {2554--2563},
}

@inproceedings{hanneke_value_2019,
	title = {On the value of target data in transfer learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Hanneke, Steve and Kpotufe, Samory},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hanneke_no-free-lunch_2020,
	title = {A no-free-lunch theorem for multitask learning},
	journal = {arXiv preprint arXiv:2006.15785},
	author = {Hanneke, Steve and Kpotufe, Samory},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Statistics Theory},
}

@inproceedings{haghifam_towards_2021,
	title = {Towards a unified information-theoretic framework for generalization},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Haghifam, Mahdi and Dziugaite, Gintare Karolina and Roy, Daniel M and Moran, Shay},
	year = {2021},
}

@inproceedings{zhang_quantifying_2021,
	title = {Quantifying and improving transferability in domain generalization},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhang, Guojun and Zhao, Han and Yu, Yaoliang and Poupart, Pascal},
	year = {2021},
}

@inproceedings{zhu_understanding_2021,
	title = {Understanding the generalization benefit of model invariance from a data perspective},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhu, Sicheng and An, Bang and Huang, Furong},
	year = {2021},
}

@inproceedings{wald_calibration_2021,
	title = {On calibration and out-of-domain generalization},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wald, Yoav and Feder, Amir and Greenfeld, Daniel and Shalit, Uri},
	year = {2021},
	pages = {2215--2227},
}

@inproceedings{neyshabur_role_2019,
	title = {The role of over-parametrization in generalization of neural networks},
	language = {en},
	booktitle = {{ICLR}},
	author = {Neyshabur, Behnam and Li, Zhiyuan and Bhojanapalli, Srinadh},
	year = {2019},
}

@article{albuquerque_generalizing_2019,
	title = {Generalizing to unseen domains via distribution matching},
	language = {en},
	journal = {arXiv preprint arXiv:1911.00804},
	author = {Albuquerque, Isabela and Monteiro, João and Darvishi, Mohammad and Falk, Tiago H. and Mitliagkas, Ioannis},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{anonymous_task_2021,
	title = {Task relatedness-based generalization bounds for meta learning},
	language = {en},
	author = {Anonymous},
	year = {2021},
}

@inproceedings{zhao_learning_2019,
	title = {On learning invariant representations for domain adaptation},
	isbn = {2640-3498},
	booktitle = {{ICML}},
	author = {Zhao, Han and Des Combes, Remi Tachet and Zhang, Kun and Gordon, Geoffrey},
	year = {2019},
	pages = {7523--7532},
}

@inproceedings{wu_domain_2019,
	title = {Domain adaptation with asymmetrically-relaxed distribution alignment},
	language = {en},
	booktitle = {{ICML}},
	author = {Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary C},
	year = {2019},
}

@inproceedings{claassen_learning_2013,
	title = {Learning sparse causal models is not {NP}-hard},
	language = {en},
	booktitle = {{UAI}},
	author = {Claassen, Tom and Mooij, Joris M and Heskes, Tom},
	year = {2013},
}

@article{chickering_large-sample_2004,
	title = {Large-sample learning of {Bayesian} networks is {NP}-hard},
	volume = {5},
	journal = {Journal of Machine Learning Research},
	author = {Chickering, Max and Heckerman, David and Meek, Chris},
	year = {2004},
}

@article{tiwary_hardness_2008,
	title = {On the hardness of computing intersection, union and minkowski sum of polytopes},
	volume = {40},
	issn = {0179-5376, 1432-0444},
	doi = {10.1007/s00454-008-9097-3},
	language = {en},
	number = {3},
	journal = {Discrete \& Computational Geometry},
	author = {Tiwary, Hans Raj},
	year = {2008},
	pages = {469--479},
}

@article{mahajan_planar_2012,
	title = {The planar k-means problem is {NP}-hard},
	volume = {442},
	journal = {Theoretical Computer Science},
	author = {Mahajan, Meena and Nimbhorkar, Prajakta and Varadarajan, Kasturi},
	year = {2012},
	pages = {13--21},
}

@inproceedings{baldi_autoencoders_2012,
	title = {Autoencoders, unsupervised learning, and deep architectures},
	booktitle = {{ICML} workshop on unsupervised and transfer learning},
	author = {Baldi, Pierre},
	year = {2012},
	pages = {37--49},
}

@inproceedings{he_bag_2019,
	title = {Bag of tricks for image classification with convolutional neural networks},
	booktitle = {{CVPR}},
	author = {He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{janner_offline_2021,
	title = {Offline reinforcement learning as one big sequence modeling problem},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Janner, Michael and Li, Qiyang and Levine, Sergey},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{deshmukh_generalization_2019,
	title = {A generalization error bound for multi-class domain generalization},
	journal = {arXiv preprint arXiv:1905.10392},
	author = {Deshmukh, Aniket Anand and Lei, Yunwen and Sharma, Srinagesh and Dogan, Urun and Cutler, James W. and Scott, Clayton},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{saito_semi-supervised_2019,
	address = {Seoul, Korea (South)},
	title = {Semi-supervised domain adaptation via minimax entropy},
	isbn = {978-1-72814-803-8},
	doi = {10.1109/ICCV.2019.00814},
	language = {en},
	booktitle = {{ICCV}},
	author = {Saito, Kuniaki and Kim, Donghyun and Sclaroff, Stan and Darrell, Trevor and Saenko, Kate},
	year = {2019},
	pages = {8049--8057},
}

@article{berga_disentanglement_2020,
	title = {Disentanglement of color and shape representations for continual learning},
	language = {en},
	journal = {arXiv preprint arXiv:2007.06356},
	author = {Berga, David and Masana, Marc and Van de Weijer, Joost},
	year = {2020},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{denton_unsupervised_2017,
	title = {Unsupervised learning of disentangled representations from video},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Denton, Emily L},
	year = {2017},
}

@article{strouse_deterministic_2016,
	title = {The deterministic information bottleneck},
	language = {en},
	journal = {arXiv preprint arXiv:1604.00268},
	author = {Strouse, D. J. and Schwab, David J.},
	year = {2016},
	keywords = {Statistics - Machine Learning, Quantitative Biology - Neurons and Cognition, Computer Science - Information Theory, Condensed Matter - Statistical Mechanics, Quantitative Biology - Quantitative Methods},
}

@article{ji_properties_2021,
	title = {Properties of minimizing entropy},
	journal = {arXiv preprint arXiv:2112.03143},
	author = {Ji, Xu and Nehale-Ezzine, Lena and Korablyov, Maksym},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{vedantam_empirical_2021,
	title = {An empirical investigation of domain generalization with empirical risk minimizers},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Vedantam, Ramakrishna and Lopez-Paz, David and Schwab, David J},
	year = {2021},
}

@inproceedings{hu_domain_2021,
	title = {Domain generalization via multidomain discriminant analysis},
	booktitle = {{UAI}},
	author = {Hu, Shoubo and Zhang, Kun and Chen, Zhitang and Chan, Laiwan},
	year = {2021},
}

@article{sicilia_domain_2021,
	title = {Domain adversarial neural networks for domain generalization: {When} it works and how to improve},
	shorttitle = {Domain adversarial neural networks for domain generalization},
	language = {en},
	journal = {arXiv preprint arXiv:2102.03924},
	author = {Sicilia, Anthony and Zhao, Xingchen and Hwang, Seong Jae},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{ginart_making_2019,
	title = {Making {AI} forget you: {Data} deletion in machine learning},
	shorttitle = {Making ai forget you},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ginart, Antonio and Guan, Melody Y. and Valiant, Gregory and Zou, James},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{wang_generalizing_2021,
	title = {Generalizing to unseen domains: {A} survey on domain generalization},
	shorttitle = {Generalizing to unseen domains},
	language = {en},
	journal = {arXiv preprint arXiv:2103.03097},
	author = {Wang, Jindong and Lan, Cuiling and Liu, Chang and Ouyang, Yidong and Zeng, Wenjun and Qin, Tao},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{abrahamsen_training_2021,
	title = {Training neural networks is \${\textbackslash}exists{\textbackslash}mathbb {R}\$-complete},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Abrahamsen, Mikkel and Kleist, Linda and Miltzow, Tillmann},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computational Complexity, Computer Science - Neural and Evolutionary Computing, Computer Science - Data Structures and Algorithms},
}

@article{lesort_understanding_2021,
	title = {Understanding continual learning settings with data distribution drift analysis},
	language = {en},
	journal = {arXiv preprint arXiv:2104.01678},
	author = {Lesort, Timothée and Caccia, Massimo and Rish, Irina},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{brophy_machine_2021,
	title = {Machine unlearning for random forests},
	language = {en},
	booktitle = {{ICML}},
	author = {Brophy, Jonathan and Lowd, Daniel},
	year = {2021},
}

@article{kirsch_unpacking_2020,
	title = {Unpacking information bottlenecks: {Unifying} information-theoretic objectives in deep learning},
	shorttitle = {Unpacking information bottlenecks},
	language = {en},
	journal = {arXiv preprint arXiv:2003.12537},
	author = {Kirsch, Andreas and Lyle, Clare and Gal, Yarin},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{tian_what_2020,
	title = {What makes for good views for contrastive learning?},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Tian, Yonglong and Sun, Chen and Poole, Ben and Krishnan, Dilip and Schmid, Cordelia and Isola, Phillip},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	pages = {6827--6839},
}

@inproceedings{cvitkovic_minimal_2019,
	title = {Minimal achievable sufficient statistic learning},
	isbn = {2640-3498},
	booktitle = {{ICML}},
	author = {Cvitkovic, Milan and Koliander, Günther},
	year = {2019},
	pages = {1465--1474},
}

@inproceedings{stooke_decoupling_2021,
	title = {Decoupling representation learning from reinforcement learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Stooke, Adam and Lee, Kimin and Abbeel, Pieter and Laskin, Michael},
	year = {2021},
}

@inproceedings{khani_feature_2020,
	title = {Feature noise induces loss discrepancy across groups},
	booktitle = {{ICML}},
	author = {Khani, Fereshte and Liang, Percy},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{shahtalebi_sand-mask_2021,
	title = {Sand-mask: {An} enhanced gradient masking strategy for the discovery of invariances in domain generalization},
	shorttitle = {Sand-mask},
	language = {en},
	journal = {arXiv preprint arXiv:2106.02266},
	author = {Shahtalebi, Soroosh and Gagnon-Audet, Jean-Christophe and Laleh, Touraj and Faramarzi, Mojtaba and Ahuja, Kartik and Rish, Irina},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{zhang_adaptive_2021,
	title = {Adaptive risk minimization: {Learning} to adapt to domain shift},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhang, Marvin and Marklund, Henrik and Dhawan, Nikita and Gupta, Abhishek and Levine, Sergey and Finn, Chelsea},
	year = {2021},
	pages = {23664--23678},
}

@inproceedings{mansilla_domain_2021,
	title = {Domain generalization via gradient surgery},
	language = {en},
	booktitle = {{ICCV}},
	author = {Mansilla, Lucas and Echeveste, Rodrigo and Milone, Diego H and Ferrante, Enzo},
	year = {2021},
	pages = {9},
}

@inproceedings{zhou_domain_2021-1,
	title = {Domain generalization with mixstyle},
	language = {en},
	booktitle = {{ICLR}},
	author = {Zhou, Kaiyang and Yang, Yongxin and Qiao, Yu and Xiang, Tao},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{shi_gradient_2022,
	title = {Gradient matching for domain generalization},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Shi, Yuge and Seely, Jeffrey and Torr, Philip H. S. and Siddharth, N. and Hannun, Awni and Usunier, Nicolas and Synnaeve, Gabriel},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{tishby_deep_2015,
	title = {Deep learning and the information bottleneck principle},
	language = {en},
	journal = {arXiv preprint arXiv:1503.02406},
	author = {Tishby, Naftali and Zaslavsky, Noga},
	year = {2015},
	keywords = {Computer Science - Machine Learning},
}

@article{tishby_information_2000,
	title = {The information bottleneck method},
	journal = {arXiv:physics/0004057},
	author = {Tishby, Naftali and Pereira, Fernando C. and Bialek, William},
	year = {2000},
	keywords = {Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks, Nonlinear Sciences - Adaptation and Self-Organizing Systems, Physics - Data Analysis, Statistics and Probability},
}

@inproceedings{bartlett_regal_2009,
	title = {Regal: {A} regularization based algorithm for reinforcement learning in weakly communicating {MDPs}},
	booktitle = {{UAI}},
	author = {Bartlett, Peter L and Tewari, Ambuj},
	year = {2009},
}

@inproceedings{dosovitskiy_image_2021,
	title = {An image is worth 16x16 words: {Transformers} for image recognition at scale},
	shorttitle = {An image is worth 16x16 words},
	language = {en},
	booktitle = {{ICLR}},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{panareda_busto_open_2020,
	title = {Open set domain adaptation for image and action recognition},
	volume = {42},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2018.2880750},
	number = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Panareda Busto, Pau and Iqbal, Ahsan and Gall, Juergen},
	year = {2020},
	keywords = {Protocols, Training, Feature extraction, Task analysis, action recognition, Domain adaptation, Face recognition, Image recognition, open set recognition, Videos},
	pages = {413--429},
}

@inproceedings{fu_diagnosing_2019,
	title = {Diagnosing bottlenecks in deep {Q}-learning algorithms},
	language = {en},
	booktitle = {{ICML}},
	author = {Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
	year = {2019},
}

@article{wang_provably_2020,
	title = {Provably efficient causal reinforcement learning with confounded observational data},
	language = {en},
	journal = {arXiv preprint arXiv:2006.12311},
	author = {Wang, Lingxiao and Yang, Zhuoran and Wang, Zhaoran},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{zhao_inherent_2022,
	title = {Inherent tradeoffs in learning fair representations},
	volume = {23},
	number = {57},
	journal = {Journal of Machine Learning Research},
	author = {Zhao, Han and Gordon, Geoffrey J.},
	year = {2022},
	pages = {1--26},
}

@article{liu_pac_2022,
	title = {{PAC} guarantees and effective algorithms for detecting novel categories},
	volume = {23},
	number = {44},
	journal = {Journal of Machine Learning Research},
	author = {Liu, Si and Garrepalli, Risheek and Hendrycks, Dan and Fern, Alan and Mondal, Debashis and Dietterich, Thomas G.},
	year = {2022},
	pages = {1--47},
}

@inproceedings{du_provably_2019,
	title = {Provably efficient {RL} with rich observations via latent state decoding},
	language = {en},
	booktitle = {{ICML}},
	author = {Du, Simon S and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh and Dudík, Miroslav and Langford, John},
	year = {2019},
}

@inproceedings{peng_domain_2019,
	title = {Domain agnostic learning with disentangled representations},
	booktitle = {{ICML}},
	author = {Peng, Xingchao and Huang, Zijun and Sun, Ximeng and Saenko, Kate},
	year = {2019},
}

@inproceedings{efroni_provable_2022,
	title = {Provable {RL} with exogenous distractors via multistep inverse dynamics},
	booktitle = {{ICLR}},
	author = {Efroni, Yonathan and Misra, Dipendra and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{liu_large-scale_2019,
	address = {Long Beach, CA, USA},
	title = {Large-scale long-tailed recognition in an open world},
	isbn = {978-1-72813-293-8},
	doi = {10.1109/CVPR.2019.00264},
	language = {en},
	booktitle = {{CVPR}},
	author = {Liu, Ziwei and Miao, Zhongqi and Zhan, Xiaohang and Wang, Jiayun and Gong, Boqing and Yu, Stella X.},
	year = {2019},
	pages = {2532--2541},
}

@inproceedings{hsu_generalized_2020,
	address = {Seattle, WA, USA},
	title = {Generalized odin: {Detecting} out-of-distribution image without learning from out-of-distribution data},
	isbn = {978-1-72817-168-5},
	shorttitle = {Generalized odin},
	doi = {10.1109/CVPR42600.2020.01096},
	language = {en},
	booktitle = {{CVPR}},
	author = {Hsu, Yen-Chang and Shen, Yilin and Jin, Hongxia and Kira, Zsolt},
	year = {2020},
	pages = {10948--10957},
}

@inproceedings{yi_improved_2021,
	title = {Improved {OOD} generalization via adversarial training and pre-training},
	language = {en},
	booktitle = {{ICML}},
	author = {Yi, Mingyang and Hou, Lu and Sun, Jiacheng and Shang, Lifeng and Jiang, Xin and Liu, Qun and Ma, Zhi-Ming},
	year = {2021},
}

@inproceedings{busto_open_2017,
	address = {Venice},
	title = {Open set domain adaptation},
	isbn = {978-1-5386-1032-9},
	doi = {10.1109/ICCV.2017.88},
	language = {en},
	booktitle = {{ICCV}},
	author = {Busto, Pau Panareda and Gall, Juergen},
	year = {2017},
	pages = {754--763},
}

@inproceedings{liu_open_2020,
	address = {Seattle, WA, USA},
	title = {Open compound domain adaptation},
	isbn = {978-1-72817-168-5},
	doi = {10.1109/CVPR42600.2020.01242},
	language = {en},
	booktitle = {{CVPR}},
	author = {Liu, Ziwei and Miao, Zhongqi and Pan, Xingang and Zhan, Xiaohang and Lin, Dahua and Yu, Stella X. and Gong, Boqing},
	year = {2020},
	pages = {12403--12412},
}

@inproceedings{shu_open_2021,
	address = {Nashville, TN, USA},
	title = {Open domain generalization with domain-augmented meta-learning},
	isbn = {978-1-66544-509-2},
	doi = {10.1109/CVPR46437.2021.00950},
	language = {en},
	booktitle = {{CVPR}},
	author = {Shu, Yang and Cao, Zhangjie and Wang, Chenyu and Wang, Jianmin and Long, Mingsheng},
	year = {2021},
	pages = {9619--9628},
}

@inproceedings{yang_semantically_2021,
	address = {Montreal, QC, Canada},
	title = {Semantically coherent out-of-distribution detection},
	isbn = {978-1-66542-812-5},
	doi = {10.1109/ICCV48922.2021.00819},
	language = {en},
	booktitle = {{ICCV}},
	author = {Yang, Jingkang and Wang, Haoqi and Feng, Litong and Yan, Xiaopeng and Zheng, Huabin and Zhang, Wayne and Liu, Ziwei},
	year = {2021},
	pages = {8281--8289},
}

@article{ming_impact_2021,
	title = {On the impact of spurious correlation for out-of-distribution detection},
	language = {en},
	journal = {arXiv preprint arXiv:2109.05642},
	author = {Ming, Yifei and Yin, Hang and Li, Yixuan},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{sutton_quest_2022,
	title = {The quest for a common model of the intelligent decision maker},
	language = {en},
	journal = {arXiv preprint arXiv:2202.13252},
	author = {Sutton, Richard S.},
	year = {2022},
	keywords = {Computer Science - Artificial Intelligence},
}

@inproceedings{chen_understanding_2022,
	title = {Understanding domain randomization for sim-to-real transfer},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Chen, Xiaoyu and Hu, Jiachen and Jin, Chi and Li, Lihong and Wang, Liwei},
	year = {2022},
}

@inproceedings{fruit_exploration-exploitation_2017,
	title = {Exploration-exploitation in {MDPs} with options},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics}},
	author = {Fruit, Ronan and Lazaric, Alessandro},
	year = {2017},
	pages = {576--584},
}

@inproceedings{fruit_regret_2017,
	title = {Regret minimization in {MDPs} with options without prior knowledge},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro and Brunskill, Emma},
	year = {2017},
}

@inproceedings{azar_minimax_2017,
	title = {Minimax regret bounds for reinforcement learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, Rémi},
	year = {2017},
}

@article{levine_end--end_2016,
	title = {End-to-end training of deep visuomotor policies},
	volume = {17},
	language = {en},
	number = {39},
	journal = {Journal of Machine Learning Research},
	author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
	year = {2016},
	pages = {1--40},
}

@inproceedings{wiles_fine-grained_2022,
	title = {A fine-grained analysis on distribution shift},
	language = {en},
	booktitle = {{ICLR}},
	author = {Wiles, Olivia and Gowal, Sven and Stimberg, Florian and Rebuffi, Sylvestre-Alvise and Ktena, Ira and Dvijotham, Krishnamurthy and Cemgil, Taylan},
	year = {2022},
}

@article{shorten_survey_2019,
	title = {A survey on image data augmentation for deep learning},
	volume = {6},
	issn = {2196-1115},
	doi = {10.1186/s40537-019-0197-0},
	language = {en},
	number = {1},
	journal = {Journal of Big Data},
	author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
	year = {2019},
	pages = {60},
}

@inproceedings{goel_model_2021,
	title = {Model patching: {Closing} the subgroup performance gap with data augmentation},
	shorttitle = {Model patching},
	language = {en},
	booktitle = {{ICLR}},
	author = {Goel, Karan and Gu, Albert and Li, Yixuan and Ré, Christopher},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{cubuk_autoaugment_2019,
	address = {Long Beach, CA, USA},
	title = {Autoaugment: {Learning} augmentation strategies from data},
	isbn = {978-1-72813-293-8},
	shorttitle = {Autoaugment},
	doi = {10.1109/CVPR.2019.00020},
	language = {en},
	booktitle = {{CVPR}},
	author = {Cubuk, Ekin D. and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V.},
	year = {2019},
	pages = {113--123},
}

@inproceedings{cubuk_randaugment_2020,
	address = {Seattle, WA, USA},
	title = {Randaugment: {Practical} automated data augmentation with a reduced search space},
	isbn = {978-1-72819-360-1},
	shorttitle = {Randaugment},
	doi = {10.1109/CVPRW50498.2020.00359},
	language = {en},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	author = {Cubuk, Ekin D. and Zoph, Barret and Shlens, Jonathon and Le, Quoc V.},
	year = {2020},
	pages = {3008--3017},
}

@inproceedings{hendrycks_augmix_2020,
	title = {Augmix: {A} simple data processing method to improve robustness and uncertainty},
	shorttitle = {Augmix},
	booktitle = {{ICLR}},
	author = {Hendrycks, Dan and Mu, Norman and Cubuk, Ekin D. and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{zhang_towards_2021,
	title = {Towards certifying l-infinity robustness using neural networks with l-inf-dist neurons},
	isbn = {2640-3498},
	booktitle = {{ICML}},
	author = {Zhang, Bohang and Cai, Tianle and Lu, Zhou and He, Di and Wang, Liwei},
	year = {2021},
	pages = {12368--12379},
}

@inproceedings{jiang_abstraction_2015,
	title = {Abstraction selection in model-based reinforcement learning},
	language = {en},
	booktitle = {{ICML}},
	author = {Jiang, Nan and Kulesza, Alex and Singh, Satinder},
	year = {2015},
}

@inproceedings{glorot_understanding_2010,
	title = {Understanding the difficulty of training deep feedforward neural networks},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Glorot, Xavier and Bengio, Yoshua},
	year = {2010},
}

@inproceedings{hendrycks_using_2019,
	title = {Using pre-training can improve model robustness and uncertainty},
	language = {en},
	booktitle = {{ICML}},
	author = {Hendrycks, Dan and Lee, Kimin and Mazeika, Mantas},
	year = {2019},
}

@inproceedings{abbasi-yadkori_politex_2019,
	title = {Politex: {Regret} bounds for policy iteration using expert prediction},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Abbasi-Yadkori, Yasin and Bartlett, Peter L and Bhatia, Kush and Lazic, Nevena and Szepesvári, Csaba and Weisz, Gellért},
	year = {2019},
	pages = {3692--3702},
}

@inproceedings{hao_adaptive_2021,
	title = {Adaptive approximate policy iteration},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Hao, Botao and Lazic, Nevena and Abbasi-Yadkori, Yasin and Joulani, Pooria and Szepesvari, Csaba},
	year = {2021},
}

@inproceedings{wei_learning_2021,
	title = {Learning infinite-horizon average-reward {MDPs} with linear function approximation},
	language = {en},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics}},
	author = {Wei, Chen-Yu and Jafarnia-Jahromi, Mehdi and Luo, Haipeng and Jain, Rahul},
	year = {2021},
	pages = {3007--3015},
}

@inproceedings{liu_neural_2019,
	title = {Neural trust region/proximal policy optimization attains globally optimal policy},
	booktitle = {Advances in neural information processing systems},
	author = {Liu, Boyi and Cai, Qi and Yang, Zhuoran and Wang, Zhaoran},
	year = {2019},
}

@inproceedings{kim_selfreg_2021,
	address = {Montreal, QC, Canada},
	title = {{SelfReg}: {Self}-supervised contrastive regularization for domain generalization},
	isbn = {978-1-66542-812-5},
	shorttitle = {Selfreg},
	doi = {10.1109/ICCV48922.2021.00948},
	language = {en},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Kim, Daehee and Yoo, Youngjun and Park, Seunghyun and Kim, Jinkyu and Lee, Jaekoo},
	year = {2021},
	pages = {9599--9608},
}

@article{rosenfeld_domain-adjusted_2022,
	title = {Domain-adjusted regression or: {ERM} may already learn features sufficient for out-of-distribution generalization},
	shorttitle = {Domain-adjusted regression or},
	journal = {arXiv preprint arXiv:2202.06856},
	author = {Rosenfeld, Elan and Ravikumar, Pradeep and Risteski, Andrej},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{chatterjee_generalization_2022,
	title = {On the generalization mystery in deep learning},
	language = {en},
	journal = {arXiv preprint arXiv:2203.10036},
	author = {Chatterjee, Satrajit and Zielinski, Piotr},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@phdthesis{abel_theory_2022,
	type = {Ph.{D}. thesis},
	title = {A theory of abstraction in reinforcement learning},
	language = {en},
	school = {Brown University},
	author = {Abel, David},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{li_deeper_2017,
	address = {Venice},
	title = {Deeper, broader and artier domain generalization},
	isbn = {978-1-5386-1032-9},
	doi = {10.1109/ICCV.2017.591},
	language = {en},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M.},
	year = {2017},
	pages = {5543--5551},
}

@article{ramsauer_hopfield_2021,
	title = {Hopfield networks is all you need},
	language = {en},
	journal = {arXiv preprint arXiv:2008.02217},
	author = {Ramsauer, Hubert and Schäfl, Bernhard and Lehner, Johannes and Seidl, Philipp and Widrich, Michael and Adler, Thomas and Gruber, Lukas and Holzleitner, Markus and Pavlović, Milena and Sandve, Geir Kjetil and Greiff, Victor and Kreil, David and Kopp, Michael and Klambauer, Günter and Brandstetter, Johannes and Hochreiter, Sepp},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computation and Language},
}

@inproceedings{bansal_for_2022,
	title = {For self-supervised learning, rationality implies generalization, provably},
	booktitle = {{ICLR}},
	author = {Bansal, Yamini and Kaplun, Gal and Barak, Boaz},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{schott_visual_2022,
	title = {Visual representation learning does not generalize strongly within the same domain},
	language = {en},
	booktitle = {{ICLR}},
	author = {Schott, Lukas and von Kügelgen, Julius and Träuble, Frederik and Gehler, Peter and Russell, Chris and Bethge, Matthias and Schölkopf, Bernhard and Locatello, Francesco and Brendel, Wieland},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{jaderberg_spatial_2015,
	title = {Spatial transformer networks},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew},
	year = {2015},
}

@inproceedings{lu_invariant_2022,
	title = {Invariant causal representation learning for out-of-distribution generalization},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Lu, Chaochao and Wu, Yuhuai and Hernández-Lobato, Jose Miguel and Schölkopf, Bernhard},
	year = {2022},
}

@inproceedings{abel_near_2016,
	title = {Near optimal behavior via approximate state abstraction},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Abel, David and Hershkowitz, D Ellis and Littman, Michael L},
	year = {2016},
}

@inproceedings{sun_test-time_2020,
	title = {Test-time training with self-supervision for generalization under distribution shifts},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Sun, Yu and Wang, Xiaolong and Liu, Zhuang and Miller, John and Efros, Alexei A and Hardt, Moritz},
	year = {2020},
}

@inproceedings{konobeev_distribution-dependent_2021,
	title = {A distribution-dependent analysis of meta learning},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Konobeev, Mikhail and Kuzborskij, Ilja and Szepesvári, Csaba},
	year = {2021},
	pages = {5697--5706},
}

@inproceedings{taori_measuring_2020,
	title = {Measuring robustness to natural distribution shifts in image classification},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Taori, Rohan and Dave, Achal and Shankar, Vaishaal and Carlini, Nicholas and Recht, Benjamin and Schmidt, Ludwig},
	year = {2020},
	pages = {18583--18599},
}

@inproceedings{wu_generalization_2020,
	title = {On the generalization effects of linear transformations in data augmentation},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Wu, Sen and Zhang, Hongyang R and Valiant, Gregory and Re, Christopher},
	year = {2020},
	pages = {10410--10420},
}

@inproceedings{dao_kernel_2019,
	title = {A kernel theory of modern data augmentation},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Dao, Tri and Gu, Albert and Ratner, Alexander J and Smith, Virginia and Sa, Christopher De and Re, Christopher},
	year = {2019},
	pages = {1528--1537},
}

@inproceedings{zhang_adversarial_2020,
	title = {Adversarial autoaugment},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Zhang, Xinyu and Wang, Qiang and Zhang, Jian and Zhong, Zhao},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{he_data_2019,
	title = {Data augmentation revisited: {Rethinking} the distribution gap between clean and augmented data},
	shorttitle = {Data augmentation revisited},
	language = {en},
	journal = {arXiv preprint arXiv:1909.09148},
	author = {He, Zhuoxun and Xie, Lingxi and Chen, Xin and Zhang, Ya and Wang, Yanfeng and Tian, Qi},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{yun_cutmix_2019,
	address = {Seoul, Korea (South)},
	title = {Cutmix: {Regularization} strategy to train strong classifiers with localizable features},
	isbn = {978-1-72814-803-8},
	shorttitle = {Cutmix},
	doi = {10.1109/ICCV.2019.00612},
	language = {en},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Yun, Sangdoo and Han, Dongyoon and Chun, Sanghyuk and Oh, Seong Joon and Yoo, Youngjoon and Choe, Junsuk},
	year = {2019},
	pages = {6022--6031},
}

@inproceedings{verma_manifold_2019,
	title = {Manifold mixup: {Better} representations by interpolating hidden states},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Verma, Vikas and Lamb, Alex and Beckham, Christopher and Najafi, Amir and Mitliagkas, Ioannis and Lopez-Paz, David and Bengio, Yoshua},
	year = {2019},
	pages = {6438--6447},
}

@inproceedings{devries_improved_2017,
	title = {Improved regularization of convolutional neural networks with cutout},
	booktitle = {{arXiv} preprint {arXiv}:1708.04552},
	author = {DeVries, Terrance and Taylor, Graham W.},
	year = {2017},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{zhong_random_2020,
	title = {Random erasing data augmentation},
	volume = {34},
	doi = {10.1609/aaai.v34i07.7000},
	language = {en},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Zhong, Zhun and Zheng, Liang and Kang, Guoliang and Li, Shaozi and Yang, Yi},
	year = {2020},
	pages = {13001--13008},
}

@article{hernandez-garcia_data_2020,
	title = {Data augmentation instead of explicit regularization},
	language = {en},
	journal = {arXiv preprint arXiv:1806.03852},
	author = {Hernández-García, Alex and König, Peter},
	year = {2020},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{chen_group-theoretic_2020,
	title = {A group-theoretic framework for data augmentation},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chen, Shuxiao and Dobriban, Edgar and Lee, Jane H},
	year = {2020},
	pages = {21321--21333},
}

@inproceedings{xie_unsupervised_2020,
	title = {Unsupervised data augmentation for consistency training},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Xie, Qizhe and Dai, Zihang and Hovy, Eduard and Luong, Minh-Thang and Le, Quoc V},
	year = {2020},
	pages = {6256--6268},
}

@inproceedings{sinha_negative_2021,
	title = {Negative data augmentation},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Sinha, Abhishek and Ayush, Kumar and Song, Jiaming and Uzkent, Burak and Jin, Hongxia and Ermon, Stefano},
	year = {2021},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{ilse_selecting_2021,
	title = {Selecting data augmentation for simulating interventions},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Ilse, Maximilian and Tomczak, Jakub M and Forre, Patrick},
	year = {2021},
	pages = {4555--4562},
}

@inproceedings{chen_novelty_2021,
	title = {Novelty detection via contrastive learning with negative data augmentation},
	language = {en},
	booktitle = {International {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Chen, Chengwei and Xie, Yuan and Lin, Shaohui and Qiao, Ruizhi and Zhou, Jian and Tan, Xin and Zhang, Yi and Ma, Lizhuang},
	year = {2021},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	pages = {606--614},
}

@inproceedings{lin_network_2014,
	title = {Network in network},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
	year = {2014},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{kumar_fine-tuning_2022,
	title = {Fine-tuning can distort pretrained features and underperform out-of-distribution},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Kumar, Ananya and Raghunathan, Aditi and Jones, Robbie and Ma, Tengyu and Liang, Percy},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{reiss_panda_2021,
	address = {Nashville, TN, USA},
	title = {Panda: {Adapting} pretrained features for anomaly detection and segmentation},
	isbn = {978-1-66544-509-2},
	shorttitle = {Panda},
	doi = {10.1109/CVPR46437.2021.00283},
	language = {en},
	booktitle = {2021 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Reiss, Tal and Cohen, Niv and Bergman, Liron and Hoshen, Yedid},
	year = {2021},
	pages = {2805--2813},
}

@inproceedings{cha_domain_2022,
	title = {Domain generalization by mutual-information regularization with pre-trained models},
	language = {en},
	booktitle = {European {Conference} on {Computer} {Vision}},
	author = {Cha, Junbum and Lee, Kyungjae and Park, Sungrae and Chun, Sanghyuk},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	pages = {440--457},
}

@inproceedings{tripuraneni_theory_2020,
	title = {On the theory of transfer learning: {The} importance of task diversity},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Tripuraneni, Nilesh and Jordan, Michael I and Jin, Chi},
	year = {2020},
	pages = {7852--7862},
}

@inproceedings{zhang_side-tuning_2020,
	title = {Side-tuning: {A} baseline for network adaptation via additive side networks},
	shorttitle = {Side-tuning},
	language = {en},
	booktitle = {European {Conference} on {Computer} {Vision}},
	author = {Zhang, Jeffrey O. and Sax, Alexander and Zamir, Amir and Guibas, Leonidas and Malik, Jitendra},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Computer Science - Robotics},
	pages = {698--714},
}

@inproceedings{stojanov_domain_2021,
	title = {Domain adaptation with invariant representation learning: {What} transformations to learn?},
	volume = {34},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Stojanov, Petar and Li, Zijian and Gong, Mingming and Cai, Ruichu and Carbonell, Jaime and Zhang, Kun},
	editor = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P. S. and Vaughan, J. Wortman},
	year = {2021},
	pages = {24791--24803},
}

@article{selvaraju_grad-cam_2019,
	title = {Grad-{CAM}: {Visual} explanations from deep networks via gradient-based localization},
	volume = {128},
	issn = {0920-5691, 1573-1405},
	shorttitle = {Grad-cam},
	doi = {10.1007/s11263-019-01228-7},
	language = {en},
	number = {2},
	journal = {International Journal of Computer Vision},
	author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	pages = {336--359},
}

@inproceedings{lundberg_unified_2017,
	title = {A unified approach to interpreting model predictions},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lundberg, Scott M and Lee, Su-In},
	year = {2017},
	pages = {4765--4774},
}

@book{vapnik_nature_1999,
	title = {The nature of statistical learning theory},
	isbn = {0-387-98780-0},
	author = {Vapnik, Vladimir},
	year = {1999},
}

@inproceedings{shankar_image_2021,
	address = {Montreal, QC, Canada},
	title = {Do image classifiers generalize across time?},
	isbn = {978-1-66542-812-5},
	doi = {10.1109/ICCV48922.2021.00952},
	language = {en},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Shankar, Vaishaal and Dave, Achal and Roelofs, Rebecca and Ramanan, Deva and Recht, Benjamin and Schmidt, Ludwig},
	year = {2021},
	pages = {9641--9649},
}

@inproceedings{real_youtube-boundingboxes_2017,
	address = {Honolulu, HI},
	title = {Youtube-boundingboxes: {A} large high-precision human-annotated data set for object detection in video},
	isbn = {978-1-5386-0457-1},
	shorttitle = {Youtube-boundingboxes},
	doi = {10.1109/CVPR.2017.789},
	language = {en},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Real, Esteban and Shlens, Jonathon and Mazzocchi, Stefano and Pan, Xin and Vanhoucke, Vincent},
	year = {2017},
	pages = {7464--7473},
}

@article{brown_mathematics_1993,
	title = {The mathematics of statistical machine translation: {Parameter} estimation},
	volume = {19},
	language = {en},
	number = {2},
	journal = {Computational Linguistics},
	author = {Brown, Peter E and Pietra, Vincent J Della and Pietra, Stephen A Della and Mercer, Robert L},
	year = {1993},
	pages = {263--311},
}

@inproceedings{spitkovsky_viterbi_2010,
	title = {Viterbi training improves unsupervised dependency parsing},
	language = {en},
	booktitle = {Proceedings of the {Fourteenth} {Conference} on {Computational} {Natural} {Language} {Learning}},
	author = {Spitkovsky, Valentin I and Alshawi, Hiyan and Jurafsky, Daniel and Manning, Christopher D},
	year = {2010},
	pages = {9--17},
}

@inproceedings{charles_pointnet_2017,
	address = {Honolulu, HI},
	title = {{PointNet}: {Deep} learning on point sets for {3D} classification and segmentation},
	isbn = {978-1-5386-0457-1},
	shorttitle = {Pointnet},
	doi = {10.1109/CVPR.2017.16},
	language = {en},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Charles, R. Qi and Su, Hao and Kaichun, Mo and Guibas, Leonidas J.},
	year = {2017},
	pages = {77--85},
}

@inproceedings{allen-zhu_feature_2021-1,
	title = {Feature purification: {How} adversarial training performs robust deep learning},
	shorttitle = {Feature purification},
	doi = {10.1109/FOCS52979.2021.00098},
	booktitle = {2021 {IEEE} 62nd {Annual} {Symposium} on {Foundations} of {Computer} {Science} ({FOCS})},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
	year = {2021},
	keywords = {Deep learning, Training, Neural networks, Complexity theory, Knowledge engineering, Perturbation methods, Purification},
	pages = {977--988},
}

@inproceedings{liu_learning_2021,
	title = {Learning causal semantic representation for out-of-distribution prediction},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Liu, Chang and Sun, Xinwei and Wang, Jindong and Tang, Haoyue and Li, Tao and Qin, Tao and Chen, Wei and Liu, Tie-Yan},
	year = {2021},
	pages = {6155--6170},
}

@inproceedings{wang_provable_2022,
	title = {Provable domain generalization via invariant-feature subspace recovery},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Wang, Haoxiang and Si, Haozhe and Li, Bo and Zhao, Han},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {23018--23033},
}

@inproceedings{ji_implicit_2019,
	title = {The implicit bias of gradient descent on nonseparable data},
	language = {en},
	booktitle = {32nd {Annual} {Conference} on {Learning} {Theory}},
	author = {Ji, Ziwei and Telgarsky, Matus},
	year = {2019},
}

@article{ji_risk_2019,
	title = {Risk and parameter convergence of logistic regression},
	abstract = {Gradient descent, when applied to the task of logistic regression, outputs iterates which are biased to follow a unique ray deﬁned by the data. The direction of this ray is the maximum margin predictor of a maximal linearly separable subset of the data; the gradient descent iterates converge to this ray in direction at the rate O(ln ln t/ln t). The ray does not pass through the origin in general, and its oﬀset is the bounded global optimum of the risk over the remaining data; gradient descent recovers this oﬀset at a rate O((ln t)2/√t).},
	language = {en},
	journal = {arXiv preprint arXiv:1803.07300},
	author = {Ji, Ziwei and Telgarsky, Matus},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@article{soudry_implicit_2018,
	title = {The implicit bias of gradient descent on separable data},
	volume = {19},
	number = {1},
	journal = {The Journal of Machine Learning Research},
	author = {Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
	year = {2018},
	pages = {2822--2878},
}

@article{nagarajan_generalization_2019,
	title = {Generalization in deep networks: the role of distance from initialization},
	shorttitle = {Generalization in deep networks},
	language = {en},
	journal = {arXiv preprint arXiv:1901.01672},
	author = {Nagarajan, Vaishnavh and Kolter, J. Zico},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{allen-zhu_learning_2019,
	title = {Learning and generalization in overparameterized neural networks, going beyond two layers},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
	year = {2019},
	pages = {6155--6166},
}

@article{allen-zhu_forward_2021,
	title = {Forward super-resolution: {How} can {GANs} learn hierarchical generative models for real-world distributions},
	shorttitle = {Forward super-resolution},
	language = {en},
	journal = {arXiv preprint arXiv:2106.02619},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control, Computer Science - Data Structures and Algorithms},
}

@inproceedings{dittadi_transfer_2021,
	title = {On the transfer of disentangled representations in realistic settings},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Dittadi, Andrea and Träuble, Frederik and Locatello, Francesco and Wüthrich, Manuel and Agrawal, Vaibhav and Winther, Ole and Bauer, Stefan and Schölkopf, Bernhard},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{trauble_disentangled_2021,
	title = {On disentangled representations learned from correlated data},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Träuble, Frederik and Creager, Elliot and Kilbertus, Niki and Locatello, Francesco and Dittadi, Andrea and Goyal, Anirudh and Schölkopf, Bernhard and Bauer, Stefan},
	year = {2021},
	pages = {10401--10412},
}

@article{tan_class-imbalanced_2020,
	title = {Class-imbalanced domain adaptation: {An} empirical odyssey},
	shorttitle = {Class-imbalanced domain adaptation},
	language = {en},
	journal = {arXiv preprint arXiv:1910.10320},
	author = {Tan, Shuhan and Peng, Xingchao and Saenko, Kate},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{haochen_provable_2021,
	title = {Provable guarantees for self-supervised deep learning with spectral contrastive loss},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {HaoChen, Jeff Z and Gaidon, Adrien and Wei, Colin and Ma, Tengyu},
	year = {2021},
	pages = {5000--5011},
}

@inproceedings{wang_pico_2022,
	title = {{PiCO}: {Contrastive} label disambiguation for partial label learning},
	shorttitle = {Pico},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Wang, Haobo and Xiao, Ruixuan and Li, Yixuan and Feng, Lei and Niu, Gang and Chen, Gang and Zhao, Junbo},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@article{widmer_tracking_1997,
	title = {Tracking context changes through meta-learning},
	volume = {27},
	number = {3},
	journal = {Machine learning},
	author = {Widmer, Gerhard},
	year = {1997},
	pages = {259--286},
}

@inproceedings{kubat_adapting_1995,
	title = {Adapting to drift in continuous domains},
	booktitle = {European conference on machine learning},
	author = {Kubat, Miroslav and Widmer, Gerhard},
	year = {1995},
	pages = {307--310},
}

@article{widmer_learning_1996,
	title = {Learning in the presence of concept drift and hidden contexts},
	volume = {23},
	number = {1},
	journal = {Machine learning},
	author = {Widmer, Gerhard and Kubat, Miroslav},
	year = {1996},
	pages = {69--101},
}

@inproceedings{beygelzimer_contextual_2011,
	title = {Contextual bandit algorithms with supervised learning guarantees},
	booktitle = {Proceedings of the {Fourteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	author = {Beygelzimer, Alina and Langford, John and Li, Lihong and Reyzin, Lev and Schapire, Robert},
	year = {2011},
	pages = {19--26},
}

@inproceedings{vorburger_entropy-based_2006,
	title = {Entropy-based concept shift detection},
	doi = {10.1109/ICDM.2006.66},
	booktitle = {Sixth {International} {Conference} on {Data} {Mining} ({ICDM}'06)},
	author = {Vorburger, Peter and Bernstein, Abraham},
	year = {2006},
	keywords = {Switches, Noise measurement, Biomedical monitoring, Data mining, Entropy, Informatics, Multimedia computing, Streaming media, Wearable computers, Wearable sensors},
	pages = {1113--1118},
}

@inproceedings{granitzer_analysis_2008,
	title = {Analysis of machine learning techniques for context extraction},
	doi = {10.1109/ICDIM.2008.4746809},
	booktitle = {2008 {Third} {International} {Conference} on {Digital} {Information} {Management}},
	author = {Granitzer, Michael and Kroll, Mark and Seifert, Christin and Rath, Andreas S. and Weber, Nicolas and Dietzel, Olivia and Lindstaedt, Stefanie},
	year = {2008},
	keywords = {Machine learning, Support vector machines, Learning systems, Machine learning algorithms, Context modeling, Information retrieval, Knowledge management, Mutual information, Pattern matching, Support vector machine classification},
	pages = {233--240},
}

@article{tsymbal_problem_2004,
	title = {The problem of concept drift: {Definitions} and related work},
	volume = {106},
	number = {2},
	journal = {Computer Science Department, Trinity College Dublin},
	author = {Tsymbal, Alexey},
	year = {2004},
}

@inproceedings{bao_analytic-dpm_2021,
	title = {Analytic-{DPM}: {An} analytic estimate of the optimal reverse variance in diffusion probabilistic models},
	shorttitle = {Analytic-dpm},
	language = {en},
	author = {Bao, Fan and Li, Chongxuan and Zhu, Jun and Zhang, Bo},
	year = {2021},
}

@incollection{jordan_view_1998,
	address = {Dordrecht},
	title = {A view of the {EM} algorithm that justifies incremental, sparse, and other variants},
	isbn = {978-94-010-6104-9 978-94-011-5014-9},
	language = {en},
	booktitle = {Learning in {Graphical} {Models}},
	author = {Neal, Radford M. and Hinton, Geoffrey E.},
	editor = {Jordan, Michael I.},
	year = {1998},
	doi = {10.1007/978-94-011-5014-9_12},
	pages = {355--368},
}

@article{helmbold_tracking_1994,
	title = {Tracking drifting concepts by minimizing disagreements},
	volume = {14},
	issn = {0885-6125, 1573-0565},
	doi = {10.1007/BF00993161},
	language = {en},
	number = {1},
	journal = {Machine Learning},
	author = {Helmbold, David P. and Long, Philip M.},
	year = {1994},
	pages = {27--45},
}

@inproceedings{flennerhag_bootstrapped_2022,
	title = {Bootstrapped meta-learning},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Flennerhag, Sebastian and Schroecker, Yannick and Zahavy, Tom and van Hasselt, Hado},
	year = {2022},
}

@inproceedings{carlini_poisoning_2022,
	title = {Poisoning and backdooring contrastive learning},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Carlini, Nicholas and Terzis, Andreas},
	year = {2022},
}

@book{shalev-shwartz_understanding_2014,
	address = {Cambridge},
	title = {Understanding machine learning: {From} theory to algorithms},
	isbn = {978-1-107-29801-9},
	shorttitle = {Understanding machine learning},
	language = {en},
	author = {Shalev-Shwartz, Shai and Ben-David, Shai},
	year = {2014},
	doi = {10.1017/CBO9781107298019},
}

@article{redko_survey_2020,
	title = {A survey on domain adaptation theory: {Learning} bounds and theoretical guarantees},
	shorttitle = {A survey on domain adaptation theory},
	language = {en},
	journal = {arXiv preprint arXiv:2004.11829},
	author = {Redko, Ievgen and Morvant, Emilie and Habrard, Amaury and Sebban, Marc and Bennani, Younès},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{robinson_can_2021,
	title = {Can contrastive learning avoid shortcut solutions?},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Robinson, Joshua and Sun, Li and Yu, Ke and Batmanghelich, Kayhan and Jegelka, Stefanie and Sra, Suvrit},
	year = {2021},
	pages = {4974--4986},
}

@inproceedings{liu_towards_2019,
	title = {Towards understanding the importance of shortcut connections in residual networks},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Liu, Tianyi and Chen, Minshuo and Zhou, Mo and Du, Simon S and Zhou, Enlu and Zhao, Tuo},
	year = {2019},
	pages = {7890--7900},
}

@inproceedings{wen_toward_2021,
	title = {Toward understanding the feature learning process of self-supervised contrastive learning},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Wen, Zixin and Li, Yuanzhi},
	year = {2021},
	pages = {11112--11122},
}

@inproceedings{iwasawa_test-time_2021,
	title = {Test-time classifier adjustment module for model-agnostic domain generalization},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Iwasawa, Yusuke and Matsuo, Yutaka},
	year = {2021},
}

@inproceedings{levy_large-scale_2020,
	title = {Large-scale methods for distributionally robust optimization},
	abstract = {We propose and analyze algorithms for distributionally robust optimization of convex losses with conditional value at risk (CVaR) and χ2 divergence uncertainty sets. We prove that our algorithms require a number of gradient evaluations independent of training set size and number of parameters, making them suitable for large-scale applications. For χ2 uncertainty sets these are the ﬁrst such guarantees in the literature, and for CVaR our guarantees scale linearly in the uncertainty level rather than quadratically as in previous work. We also provide lower bounds proving the worst-case optimality of our algorithms for CVaR and a penalized version of the χ2 problem. Our primary technical contributions are novel bounds on the bias of batch robust risk estimation and the variance of a multilevel Monte Carlo gradient estimator due to Blanchet and Glynn [8]. Experiments on MNIST and ImageNet conﬁrm the theoretical scaling of our algorithms, which are 9–36 times more efﬁcient than full-batch methods.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Levy, Daniel and Carmon, Yair and Duchi, John C and Sidford, Aaron},
	year = {2020},
	pages = {8847--8860},
}

@article{rahimian_distributionally_2019-1,
	title = {Distributionally robust optimization: {A} review},
	shorttitle = {Distributionally robust optimization},
	abstract = {The concepts of risk-aversion, chance-constrained optimization, and robust optimization have developed signiﬁcantly over the last decade. Statistical learning community has also witnessed a rapid theoretical and applied growth by relying on these concepts. A modeling framework, called distributionally robust optimization (DRO), has recently received signiﬁcant attention in both the operations research and statistical learning communities. This paper surveys main concepts and contributions to DRO, and its relationships with robust optimization, risk-aversion, chance-constrained optimization, and function regularization.},
	language = {en},
	journal = {arXiv preprint arXiv:1908.05659},
	author = {Rahimian, Hamed and Mehrotra, Sanjay},
	year = {2019},
arXiv:1908.05659 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@article{zhou_domain_2021-2,
	title = {Domain adaptive ensemble learning},
	volume = {30},
	issn = {1941-0042},
	doi = {10.1109/TIP.2021.3112012},
	abstract = {The problem of generalizing deep neural networks from multiple source domains to a target one is studied under two settings: When unlabeled target data is available, it is a multi-source unsupervised domain adaptation (UDA) problem, otherwise a domain generalization (DG) problem. We propose a unified framework termed domain adaptive ensemble learning (DAEL) to address both problems. A DAEL model is composed of a CNN feature extractor shared across domains and multiple classifier heads each trained to specialize in a particular source domain. Each such classifier is an expert to its own domain but a non-expert to others. DAEL aims to learn these experts collaboratively so that when forming an ensemble, they can leverage complementary information from each other to be more effective for an unseen target domain. To this end, each source domain is used in turn as a pseudo-target-domain with its own expert providing supervisory signal to the ensemble of non-experts learned from the other sources. To deal with unlabeled target data under the UDA setting where real expert does not exist, DAEL uses pseudo labels to supervise the ensemble learning. Extensive experiments on three multi-source UDA datasets and two DG datasets show that DAEL improves the state of the art on both problems, often by significant margins.},
	journal = {IEEE Transactions on Image Processing},
	author = {Zhou, Kaiyang and Yang, Yongxin and Qiao, Yu and Xiang, Tao},
	year = {2021},
	keywords = {Adaptation models, Training, Feature extraction, Neural networks, Domain adaptation, Collaboration, collaborative ensemble learning, Computational modeling, domain generalization, Head},
	pages = {8008--8018},
}

@article{khurana_sita_2021,
	title = {{SITA}: {Single} image test-time adaptation},
	shorttitle = {Sita},
	language = {en},
	journal = {arXiv preprint arXiv:2112.02355},
	author = {Khurana, Ansh and Paul, Sujoy and Rai, Piyush and Biswas, Soma and Aggarwal, Gaurav},
	year = {2021},
arXiv:2112.02355 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{niu_efficient_2022,
	title = {Efficient test-time model adaptation without forgetting},
	language = {en},
	journal = {arXiv preprint arXiv:2204.02610},
	author = {Niu, Shuaicheng and Wu, Jiaxiang and Zhang, Yifan and Chen, Yaofo and Zheng, Shijian and Zhao, Peilin and Tan, Mingkui},
	year = {2022},
arXiv:2204.02610 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{wang_tent_2021,
	title = {Tent: {Fully} test-time adaptation by entropy minimization},
	shorttitle = {Tent},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Wang, Dequan and Shelhamer, Evan and Liu, Shaoteng and Olshausen, Bruno and Darrell, Trevor},
	year = {2021},
arXiv:2006.10726 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{liu_ttt_2021,
	title = {{TTT}++: {When} does self-supervised test-time training fail or thrive?},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	year = {2021},
	pages = {21808--21820},
}

@article{andrychowicz_learning_2020,
	title = {Learning dexterous in-hand manipulation},
	volume = {39},
	issn = {0278-3649, 1741-3176},
	doi = {10.1177/0278364919887447},
	language = {en},
	number = {1},
	journal = {The International Journal of Robotics Research},
	author = {Andrychowicz, Marcin and Baker, Bowen and Chociej, Maciek and Józefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and Schneider, Jonas and Sidor, Szymon and Tobin, Josh and Welinder, Peter and Weng, Lilian and Zaremba, Wojciech},
	year = {2020},
	pages = {3--20},
}

@inproceedings{peng_sim--real_2018,
	title = {Sim-to-real transfer of robotic control with dynamics randomization},
	doi = {10.1109/ICRA.2018.8460528},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
	year = {2018},
	keywords = {Adaptation models, Data models, Training, Task analysis, Trajectory, Robots, Robustness},
	pages = {3803--3810},
}

@inproceedings{li_reinforcement_2021,
	title = {Reinforcement learning for robust parameterized locomotion control of bipedal robots},
	doi = {10.1109/ICRA48506.2021.9560769},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Li, Zhongyu and Cheng, Xuxin and Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and Berseth, Glen and Sreenath, Koushil},
	year = {2021},
	keywords = {Training, Learning systems, Automation, Conferences, Legged locomotion, System dynamics, Target tracking},
	pages = {2811--2817},
}

@inproceedings{gao_loss_2022,
	title = {Loss function learning for domain generalization by implicit gradient},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Gao, Boyan and Gouk, Henry and Yang, Yongxin and Hospedales, Timothy},
	year = {2022},
}

@inproceedings{weber_certifying_2022,
	title = {Certifying out-of-domain generalization for blackbox functions},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Weber, Maurice and Li, Linyi and Wang, Boxin and Zhao, Zhikuan and Li, Bo and Zhang, Ce},
	year = {2022},
}

@inproceedings{rame_fishr_2022,
	title = {Fishr: {Invariant} gradient variances for out-of-distribution generalization},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Rame, Alexandre and Dancette, Corentin and Cord, Matthieu},
	year = {2022},
	pages = {18347--18377},
}

@inproceedings{wang_augmax_2021,
	title = {{AugMax}: {Adversarial} composition of random augmentations for robust training},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wang, Haotao and Xiao, Chaowei and Kossaifi, Jean and Yu, Zhiding and Anandkumar, Anima and Wang, Zhangyang},
	year = {2021},
	pages = {237--250},
}

@article{schmidhuber_deep_2021,
	title = {Deep learning: {Our} miraculous year 1990-1991},
	journal = {arXiv preprint arXiv:2005.05744},
	author = {Schmidhuber, Juergen},
	year = {2021},
}

@inproceedings{whitehill_whose_2009,
	title = {Whose vote should count more: {Optimal} integration of labels from labelers of unknown expertise},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Whitehill, Jacob and Wu, Ting-fan and Bergsma, Jacob and Movellan, Javier R and Ruvolo, Paul L},
	year = {2009},
	pages = {2035--2043},
}

@article{elsken_neural_2019,
	title = {Neural architecture search: {A} survey},
	volume = {20},
	number = {55},
	journal = {Journal of Machine Learning Research},
	author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
	year = {2019},
	pages = {1--21},
}

@inproceedings{liu_progressive_2018,
	title = {Progressive neural architecture search},
	booktitle = {Proceedings of the {European} conference on computer vision ({ECCV})},
	author = {Liu, Chenxi and Zoph, Barret and Neumann, Maxim and Shlens, Jonathon and Hua, Wei and Li, Li-Jia and Fei-Fei, Li and Yuille, Alan and Huang, Jonathan and Murphy, Kevin},
	year = {2018},
	pages = {19--34},
}

@inproceedings{liu_darts_2019,
	title = {{DARTS}: {Differentiable} architecture search},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Liu, Hanxiao and Simonyan, Karen and Yang, Yiming},
	year = {2019},
}

@inproceedings{zoph_learning_2018,
	title = {Learning transferable architectures for scalable image recognition},
	booktitle = {Proceedings of the {IEEE} conference on computer vision and pattern recognition},
	author = {Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V.},
	year = {2018},
	pages = {8697--8710},
}

@inproceedings{pham_efficient_2018,
	title = {Efficient neural architecture search via parameters sharing},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Pham, Hieu and Guan, Melody and Zoph, Barret and Le, Quoc and Dean, Jeff},
	year = {2018},
	pages = {4095--4104},
}

@inproceedings{zoph_neural_2017,
	title = {Neural architecture search with reinforcement learning},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Zoph, Barret and Le, Quoc V.},
	year = {2017},
}

@inproceedings{veit_conditional_2017,
	address = {Honolulu, HI},
	title = {Conditional similarity networks},
	isbn = {978-1-5386-0457-1},
	doi = {10.1109/CVPR.2017.193},
	language = {en},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Veit, Andreas and Belongie, Serge and Karaletsos, Theofanis},
	year = {2017},
	pages = {1781--1789},
}

@inproceedings{amid_multiview_2015,
	title = {Multiview triplet embedding: {Learning} attributes in multiple maps},
	language = {en},
	booktitle = {{ICML}},
	author = {Amid, Ehsan and Ukkonen, Antti},
	year = {2015},
}

@inproceedings{nigam_towards_2019,
	address = {Seoul, Korea (South)},
	title = {Towards latent attribute discovery from triplet similarities},
	isbn = {978-1-72814-803-8},
	doi = {10.1109/ICCV.2019.00049},
	language = {en},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Nigam, Ishan and Tokmakov, Pavel and Ramanan, Deva},
	year = {2019},
	pages = {402--410},
}

@inproceedings{choi_quac_2018,
	title = {{QuAC}: {Question} answering in context},
	booktitle = {{EMNLP}},
	author = {Choi, Eunsol and He, He and Iyyer, Mohit and Yatskar, Mark and Yih, Wen-tau and Choi, Yejin and Liang, Percy and Zettlemoyer, Luke},
	year = {2018},
	pages = {2174--2184},
}

@inproceedings{chen_semantic_2015,
	title = {Semantic image segmentation with deep convolutional nets and fully connected {CRFs}},
	booktitle = {{ICLR}},
	author = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
	year = {2015},
}

@article{shotton_textonboost_2009,
	title = {Textonboost for image understanding: {Multi}-class object recognition and segmentation by jointly modeling texture, layout, and context},
	volume = {81},
	number = {1},
	journal = {International journal of computer vision},
	author = {Shotton, Jamie and Winn, John and Rother, Carsten and Criminisi, Antonio},
	year = {2009},
	pages = {2--23},
}

@inproceedings{zhao_modulation_2018,
	title = {A modulation module for multi-task learning with applications in image retrieval},
	booktitle = {Proceedings of the {European} {Conference} on {Computer} {Vision} ({ECCV})},
	author = {Zhao, Xiangyun and Li, Haoxiang and Shen, Xiaohui and Liang, Xiaodan and Wu, Ying},
	year = {2018},
	pages = {401--416},
}

@inproceedings{nie_dc-bert_2020,
	title = {{DC}-{BERT}: {Decoupling} question and document for efficient contextual encoding},
	booktitle = {Proceedings of the 43rd international {ACM} {SIGIR} conference on research and development in information retrieval},
	author = {Nie, Ping and Zhang, Yuyu and Geng, Xiubo and Ramamurthy, Arun and Song, Le and Jiang, Daxin},
	year = {2020},
	pages = {1829--1832},
}

@inproceedings{le_hierarchical_2020,
	title = {Hierarchical conditional relation networks for video question answering},
	booktitle = {Proceedings of the {IEEE}/{CVF} conference on computer vision and pattern recognition ({CVPR})},
	author = {Le, Thao Minh and Le, Vuong and Venkatesh, Svetha and Tran, Truyen},
	year = {2020},
	pages = {9972--9981},
}

@article{vo_harnessing_2017,
	series = {Deep {Learning} for {Computer} {Vision}},
	title = {Harnessing noisy {Web} images for deep representation},
	volume = {164},
	issn = {1077-3142},
	doi = {10.1016/j.cviu.2017.01.009},
	language = {en},
	journal = {Computer Vision and Image Understanding},
	author = {Vo, Phong D. and Ginsca, Alexandru and Le Borgne, Hervé and Popescu, Adrian},
	year = {2017},
	keywords = {Representation learning, Deep learning, Domain adaptation, Convolutional networks, Noisy data, Semi-supervised learning},
	pages = {68--81},
}

@inproceedings{krause_unreasonable_2016,
	address = {Cham},
	title = {The unreasonable effectiveness of noisy data for fine-grained recognition},
	isbn = {978-3-319-46487-9},
	doi = {10.1007/978-3-319-46487-9_19},
	language = {en},
	booktitle = {{ECCV}},
	author = {Krause, Jonathan and Sapp, Benjamin and Howard, Andrew and Zhou, Howard and Toshev, Alexander and Duerig, Tom and Philbin, James and Fei-Fei, Li},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	year = {2016},
	keywords = {Fine-grained Recognition, Ground-truth Training Set, Label Noise, Learning Activity Data, Stanford Dogs},
	pages = {301--320},
}

@incollection{pazzani_content-based_2007,
	title = {Content-based recommendation systems},
	booktitle = {The adaptive web},
	author = {Pazzani, Michael J. and Billsus, Daniel},
	year = {2007},
	pages = {325--341},
}

@article{shen_towards_2021,
	title = {Towards out-of-distribution generalization: {A} survey},
	shorttitle = {Towards out-of-distribution generalization},
	language = {en},
	journal = {arXiv preprint arXiv:2108.13624},
	author = {Shen, Zheyan and Liu, Jiashuo and He, Yue and Zhang, Xingxuan and Xu, Renzhe and Yu, Han and Cui, Peng},
	year = {2021},
arXiv:2108.13624 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{ye_ood-bench_2021,
	title = {Ood-bench: {Benchmarking} and understanding out-of-distribution generalization datasets and algorithms},
	journal = {arXiv preprint arXiv:2106.03721},
	author = {Ye, Nanyang and Li, Kaican and Hong, Lanqing and Bai, Haoyue and Chen, Yiting and Zhou, Fengwei and Li, Zhenguo},
	year = {2021},
}

@inproceedings{li_uncertainty_2022,
	title = {Uncertainty modeling for out-of-distribution generalization},
	abstract = {Though remarkable progress has been achieved in various vision tasks, deep neural networks still suffer obvious performance degradation when tested in out-ofdistribution scenarios. We argue that the feature statistics (mean and standard deviation), which carry the domain characteristics of the training data, can be properly manipulated to improve the generalization ability of deep learning models. Common methods often consider the feature statistics as deterministic values measured from the learned features and do not explicitly consider the uncertain statistics discrepancy caused by potential domain shifts during testing. In this paper, we improve the network generalization ability by modeling the uncertainty of domain shifts with synthesized feature statistics during training. Speciﬁcally, we hypothesize that the feature statistic, after considering the potential uncertainties, follows a multivariate Gaussian distribution. Hence, each feature statistic is no longer a deterministic value, but a probabilistic point with diverse distribution possibilities. With the uncertain feature statistics, the models can be trained to alleviate the domain perturbations and achieve better robustness against potential domain shifts. Our method can be readily integrated into networks without additional parameters. Extensive experiments demonstrate that our proposed method consistently improves the network generalization ability on multiple vision tasks, including image classiﬁcation, semantic segmentation, and instance retrieval. The code can be available at https://github.com/lixiaotong97/DSU.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Li, Xiaotong and Dai, Yongxing and Ge, Yixiao and Liu, Jun and Shan, Ying and Duan, Ling-Yu},
	year = {2022},
arXiv:2202.03958 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{zhang_towards_2022,
	title = {Towards principled disentanglement for domain generalization},
	language = {en},
	booktitle = {{CVPR}},
	author = {Zhang, Hanlin and Zhang, Yi-Fan and Liu, Weiyang and Weller, Adrian and Scholkopf, Bernhard and Xing, Eric P},
	year = {2022},
	pages = {11},
}

@inproceedings{brock_large_2019-1,
	title = {Large scale {GAN} training for high fidelity natural image synthesis},
	abstract = {Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities speciﬁc to such scale. We ﬁnd that applying orthogonal regularization to the generator renders it amenable to a simple “truncation trick,” allowing ﬁne control over the trade-off between sample ﬁdelity and variety by reducing the variance of the Generator’s input. Our modiﬁcations lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128×128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.5 and Fre´chet Inception Distance (FID) of 7.4, improving over the previous best IS of 52.52 and FID of 18.65.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
	year = {2019},
arXiv:1809.11096 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{ramesh_zero-shot_2021,
	title = {Zero-shot text-to-image generation},
	abstract = {Text-to-image generation has traditionally focused on ﬁnding better modeling assumptions for training on a ﬁxed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufﬁcient data and scale, our approach is competitive with previous domain-speciﬁc models when evaluated in a zero-shot fashion.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
	year = {2021},
arXiv:2102.12092 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	pages = {8821--8831},
}

@inproceedings{mouli_bias_2022,
	title = {Bias challenges in counterfactual data augmentation},
	abstract = {Deep learning models tend not to be out-ofdistribution robust primarily due to their reliance on spurious features to solve the task. Counterfactual data augmentations provide a general way of (approximately) achieving representations that are counterfactual-invariant to spurious features, a requirement for out-of-distribution (OOD) robustness. In this work, we show that counterfactual data augmentations may not achieve the desired counterfactual-invariance if the augmentation is performed by a context-guessing machine, an abstract machine that guesses the most-likely context of a given input. We theoretically analyze the invariance imposed by such counterfactual data augmentations and describe an exemplar NLP task where counterfactual data augmentation by a context-guessing machine does not lead to robust OOD classifiers.},
	language = {en},
	booktitle = {{UAI} 2022 {Workshop} on {Causal} {Representation} {Learning}},
	author = {Mouli, S Chandra and Zhou, Yangze and Ribeiro, Bruno},
	year = {2022},
}

@inproceedings{zhou_sparse_2022,
	title = {Sparse invariant risk minimization},
	abstract = {Invariant Risk Minimization (IRM) is an emerging invariant feature extracting technique to help generalization with distributional shift. However, we find that there exists a basic and intractable contradiction between the model trainability and generalization ability in IRM. On one hand, recent studies on deep learning theory indicate the importance of large-sized or even overparameterized neural networks to make the model easy to train. On the other hand, unlike empirical risk minimization that can be benefited from overparameterization, our empirical and theoretical analyses show that the generalization ability of IRM is much easier to be demolished by overfitting caused by overparameterization. In this paper, we propose a simple yet effective paradigm named Sparse Invariant Risk Minimization (SparseIRM) to address this contradiction. Our key idea is to employ a global sparsity constraint as a defense to prevent spurious features from leaking in during the whole IRM process. Compared with sparisfy-after-training prototype by prior work which can discard invariant features, the global sparsity constraint limits the budget for feature selection and enforces SparseIRM to select the invariant features. We illustrate the benefit of SparseIRM through a theoretical analysis on a simple linear case. Empirically we demonstrate the power of SparseIRM through various datasets and models and surpass state-of-the-art methods with a gap up to 29\%.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhou, Xiao and Lin, Yong and Zhang, Weizhong and Zhang, Tong},
	year = {2022},
	pages = {27222--27244},
}

@inproceedings{chen_pareto_2022,
	title = {Pareto invariant risk minimization},
	abstract = {Despite the success of invariant risk minimization (IRM) in tackling the Out-of-Distribution generalization problem, IRM can compromise the optimality when applied in practice. The practical variants of IRM, e.g., IRMv1, have been shown to have signiﬁcant gaps with IRM and thus could fail to capture the invariance even in simple problems. Moreover, the optimization procedure in IRMv1 involves two intrinsically conﬂicting objectives, and often requires careful tuning for the objective weights. To remedy the above issues, we reformulate IRM as a multi-objective optimization problem, and propose a new optimization scheme for IRM, called PAreto Invariant Risk Minimization (PAIR). PAIR can adaptively adjust the optimization direction under the objective conﬂicts. Furthermore, we show PAIR can empower the practical IRM variants to overcome the barriers with the original IRM when provided with proper guidance. We conduct experiments with ColoredMNIST to conﬁrm our theory and the effectiveness of PAIR.},
	language = {en},
	booktitle = {{ICML} {Workshop} on {Principles} of {Distribution} {Shift}},
	author = {Chen, Yongqiang and Zhou, Kaiwen and Bian, Yatao and Xie, Binghui and Ma, Kaili and Zhang, Yonggang and Yang, Han and Han, Bo and Cheng, James},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{alet_noether_2021,
	title = {Noether networks: {Meta}-learning useful conserved quantities},
	shorttitle = {Noether networks},
	abstract = {Progress in machine learning (ML) stems from a combination of data availability, computational resources, and an appropriate encoding of inductive biases. Useful biases often exploit symmetries in the prediction problem, such as convolutional networks relying on translation equivariance. Automatically discovering these useful symmetries holds the potential to greatly improve the performance of ML systems, but still remains a challenge. In this work, we focus on sequential prediction problems and take inspiration from Noether’s theorem to reduce the problem of ﬁnding inductive biases to meta-learning useful conserved quantities. We propose Noether Networks: a new type of architecture where a meta-learned conservation loss is optimized inside the prediction function. We show, theoretically and experimentally, that Noether Networks improve prediction quality, providing a general framework for discovering inductive biases in sequential problems.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Alet, Ferran and Doblar, Dylan and Zhou, Allan and Tenenbaum, Joshua and Kawaguchi, Kenji and Finn, Chelsea},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	pages = {16384--16397},
}

@inproceedings{yao_meta-learning_2021,
	title = {Meta-learning with an adaptive task scheduler},
	abstract = {To benefit the learning of a new task, meta-learning has been proposed to transfer a well-generalized meta-model learned from various meta-training tasks. Existing meta-learning algorithms randomly sample meta-training tasks with a uniform probability, under the assumption that tasks are of equal importance. However, it is likely that tasks are detrimental with noise or imbalanced given a limited number of meta-training tasks. To prevent the meta-model from being corrupted by such detrimental tasks or dominated by tasks in the majority, in this paper, we propose an adaptive task scheduler (ATS) for the meta-training process. In ATS, for the ﬁrst time, we design a neural scheduler to decide which meta-training tasks to use next by predicting the probability being sampled for each candidate task, and train the scheduler to optimize the generalization capacity of the metamodel to unseen tasks. We identify two meta-model-related factors as the input of the neural scheduler, which characterize the difﬁculty of a candidate task to the meta-model. Theoretically, we show that a scheduler taking the two factors into account improves the meta-training loss and also the optimization landscape. Under the setting of meta-learning with noise and limited budgets, ATS improves the performance on both miniImageNet and a real-world drug discovery benchmark by up to 13\% and 18\%, respectively, compared to state-of-the-art task schedulers.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Yao, Huaxiu and Wang, Yu and Wei, Ying and Zhao, Peilin and Mahdavi, Mehrdad and Lian, Defu and Finn, Chelsea},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
	pages = {7497--7509},
}

@inproceedings{zhang_lookahead_2019,
	title = {Lookahead optimizer: \$k\$ steps forward, 1 step back},
	abstract = {The vast majority of successful deep neural networks are trained using variants of stochastic gradient descent (SGD) algorithms. Recent attempts to improve SGD can be broadly categorized into two approaches: (1) adaptive learning rate schemes, such as AdaGrad and Adam, and (2) accelerated schemes, such as heavy-ball and Nesterov momentum. In this paper, we propose a new optimization algorithm, Lookahead, that is orthogonal to these previous approaches and iteratively updates two sets of weights. Intuitively, the algorithm chooses a search direction by looking ahead at the sequence of “fast weights" generated by another optimizer. We show that Lookahead improves the learning stability and lowers the variance of its inner optimizer with negligible computation and memory cost. We empirically demonstrate Lookahead can signiﬁcantly improve the performance of SGD and Adam, even with their default hyperparameter settings on ImageNet, CIFAR10/100, neural machine translation, and Penn Treebank.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhang, Michael and Lucas, James},
	year = {2019},
	pages = {9593--9604},
}

@inproceedings{nesterov_method_1983,
	title = {A method for solving the convex programming problem with convergence rate {O} (1/k{\textasciicircum} 2)},
	volume = {269},
	booktitle = {Dokl. akad. nauk {Sssr}},
	author = {Nesterov, Yurii E.},
	year = {1983},
	pages = {543--547},
}

@article{polyak_methods_1964,
	title = {Some methods of speeding up the convergence of iteration methods},
	volume = {4},
	issn = {00415553},
	doi = {10.1016/0041-5553(64)90137-5},
	language = {en},
	number = {5},
	journal = {USSR Computational Mathematics and Mathematical Physics},
	author = {Polyak, B.T.},
	year = {1964},
	pages = {1--17},
}

@article{duchi_adaptive_2011,
	title = {Adaptive subgradient methods for online learning and stochastic optimization},
	volume = {12},
	number = {7},
	journal = {Journal of machine learning research},
	author = {Duchi, John and Hazan, Elad and Singer, Yoram},
	year = {2011},
	pages = {2121--2159},
}

@article{tieleman_rmsprop_2012,
	title = {{RmsProp}: {Divide} the gradient by a running average of its recent magnitude},
	journal = {COURSERA: Neural networks for machine learning},
	author = {Tieleman, Tijmen and Hinton, Geoffrey},
	year = {2012},
}

@article{zeiler_adadelta_2012,
	title = {{ADADELTA}: {An} adaptive learning rate method},
	shorttitle = {{ADADELTA}},
	abstract = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only ﬁrst order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classiﬁcation task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
	language = {en},
	journal = {arXiv preprint arXiv:1212.5701},
	author = {Zeiler, Matthew D.},
	year = {2012},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{reddi_convergence_2018,
	title = {On the convergence of adam and beyond},
	abstract = {Several recently proposed stochastic optimization methods that have been successfully used in training deep networks such as RMSPROP, ADAM, ADADELTA, NADAM are based on using gradient updates scaled by square roots of exponential moving averages of squared past gradients. In many applications, e.g. learning with large output spaces, it has been empirically observed that these algorithms fail to converge to an optimal solution (or a critical point in nonconvex settings). We show that one cause for such failures is the exponential moving average used in the algorithms. We provide an explicit example of a simple convex optimization setting where ADAM does not converge to the optimal solution, and describe the precise problems with the previous analysis of ADAM algorithm. Our analysis suggests that the convergence issues can be ﬁxed by endowing such algorithms with “long-term memory” of past gradients, and propose new variants of the ADAM algorithm which not only ﬁx the convergence issues but often also lead to improved empirical performance.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Reddi, Sashank J. and Kale, Satyen and Kumar, Sanjiv},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@article{robbins_stochastic_1951,
	title = {A stochastic approximation method},
	journal = {The annals of mathematical statistics},
	author = {Robbins, Herbert and Monro, Sutton},
	year = {1951},
	pages = {400--407},
}

@inproceedings{zaheer_adaptive_2018,
	title = {Adaptive methods for nonconvex optimization},
	abstract = {Adaptive gradient methods that rely on scaling gradients down by the square root of exponential moving averages of past squared gradients, such RMSPROP, ADAM, ADADELTA have found wide application in optimizing the nonconvex problems that arise in deep learning. However, it has been recently demonstrated that such methods can fail to converge even in simple convex optimization settings. In this work, we provide a new analysis of such methods applied to nonconvex stochastic optimization problems, characterizing the effect of increasing minibatch size. Our analysis shows that under this scenario such methods do converge to stationarity up to the statistical limit of variance in the stochastic gradients (scaled by a constant factor). In particular, our result implies that increasing minibatch sizes enables convergence, thus providing a way to circumvent the nonconvergence issues. Furthermore, we provide a new adaptive optimization algorithm, YOGI, which controls the increase in effective learning rate, leading to even better performance with similar theoretical guarantees on convergence. Extensive experiments show that YOGI with very little hyperparameter tuning outperforms methods such as ADAM in several challenging machine learning tasks.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zaheer, Manzil and Reddi, Sashank and Sachan, Devendra and Kale, Satyen and Kumar, Sanjiv},
	year = {2018},
	pages = {9815--9825},
}

@inproceedings{karimireddy_scaffold_2020,
	title = {{SCAFFOLD}: {Stochastic} controlled averaging for federated learning},
	abstract = {Federated Averaging (FEDAVG) has emerged as the algorithm of choice for federated learning due to its simplicity and low communication cost. However, in spite of recent research efforts, its performance is not fully understood. We obtain tight convergence rates for FEDAVG and prove that it suffers from ‘client-drift’ when the data is heterogeneous (non-iid), resulting in unstable and slow convergence.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank J and Stich, Sebastian U and Suresh, Ananda Theertha},
	year = {2020},
	pages = {5132--5143},
}

@inproceedings{dinh_personalized_2020,
	title = {Personalized federated learning with moreau envelopes},
	abstract = {Federated learning (FL) is a decentralized and privacy-preserving machine learning technique in which a group of clients collaborate with a server to learn a global model without sharing clients’ data. One challenge associated with FL is statistical diversity among clients, which restricts the global model from delivering good performance on each client’s task. To address this, we propose an algorithm for personalized FL (pFedMe) using Moreau envelopes as clients’ regularized loss functions, which help decouple personalized model optimization from the global model learning in a bi-level problem stylized for personalized FL. Theoretically, we show that pFedMe’s convergence rate is state-of-the-art: achieving quadratic speedup for strongly convex and sublinear speedup of order 2/3 for smooth nonconvex objectives. Experimentally, we verify that pFedMe excels at empirical performance compared with the vanilla FedAvg and Per-FedAvg, a meta-learning based personalized FL algorithm.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dinh, Canh T and Tran, Nguyen H and Nguyen, Tuan Dung},
	year = {2020},
	pages = {21394--21405},
}

@article{zhao_federated_2022,
	title = {Federated learning with non-iid data},
	doi = {10.48550/arXiv.1806.00582},
	abstract = {Federated learning enables resource-constrained edge compute devices, such as mobile phones and IoT devices, to learn a shared model for prediction, while keeping the training data local. This decentralized approach to train models provides privacy, security, regulatory and economic beneﬁts. In this work, we focus on the statistical challenge of federated learning when local data is non-IID. We ﬁrst show that the accuracy of federated learning reduces signiﬁcantly, by up to {\textasciitilde}55\% for neural networks trained for highly skewed non-IID data, where each client device trains only on a single class of data. We further show that this accuracy reduction can be explained by the weight divergence, which can be quantiﬁed by the earth mover’s distance (EMD) between the distribution over classes on each device and the population distribution. As a solution, we propose a strategy to improve training on non-IID data by creating a small subset of data which is globally shared between all the edge devices. Experiments show that accuracy can be increased by {\textasciitilde}30\% for the CIFAR-10 dataset with only 5\% globally shared data.},
	language = {en},
	journal = {arXiv preprint arXiv.1806.00582},
	author = {Zhao, Yue and Li, Meng and Lai, Liangzhen and Suda, Naveen and Civin, Damon and Chandra, Vikas},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{bagdasaryan_how_nodate,
	title = {How to backdoor federated learning},
	abstract = {Federated models are created by aggregating model updates submitted by participants. To protect conﬁdentiality of the training data, the aggregator by design has no visibility into how these updates are generated. We show that this makes federated learning vulnerable to a model-poisoning attack that is signiﬁcantly more powerful than poisoning attacks that target only the training data. A single or multiple malicious participants can use model replacement to introduce backdoor functionality into the joint model, e.g., modify an image classiﬁer so that it assigns an attacker-chosen label to images with certain features, or force a word predictor to complete certain sentences with an attackerchosen word. We evaluate model replacement under di↵erent assumptions for the standard federated-learning tasks and show that it greatly outperforms training-data poisoning. Federated learning employs secure aggregation to protect conﬁdentiality of participants’ local models and thus cannot detect anomalies in participants’ contributions to the joint model. To demonstrate that anomaly detection would not have been e↵ective in any case, we also develop and evaluate a generic constrain-and-scale technique that incorporates the evasion of defenses into the attacker’s loss function during training.},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Bagdasaryan, Eugene and Veit, Andreas and Hua, Yiqing and Estrin, Deborah and Shmatikov, Vitaly},
	pages = {2938--2948},
}

@inproceedings{reddi_adaptive_2021,
	title = {Adaptive federated optimization},
	abstract = {Federated learning is a distributed machine learning paradigm in which a large number of clients coordinate with a central server to learn a model without sharing their own training data. Standard federated optimization methods such as Federated Averaging (FEDAVG) are often difﬁcult to tune and exhibit unfavorable convergence behavior. In non-federated settings, adaptive optimization methods have had notable success in combating such issues. In this work, we propose federated versions of adaptive optimizers, including ADAGRAD, ADAM, and YOGI, and analyze their convergence in the presence of heterogeneous data for general nonconvex settings. Our results highlight the interplay between client heterogeneity and communication efﬁciency. We also perform extensive experiments on these methods and show that the use of adaptive optimizers can signiﬁcantly improve the performance of federated learning.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Reddi, Sashank and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Konečný, Jakub and Kumar, Sanjiv and McMahan, H. Brendan},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing, Mathematics - Optimization and Control},
}

@article{hsu_measuring_2019,
	title = {Measuring the effects of non-identical data distribution for federated visual classification},
	abstract = {Federated Learning enables visual models to be trained in a privacy-preserving way using real-world data from mobile devices. Given their distributed nature, the statistics of the data across these devices is likely to differ signiﬁcantly. In this work, we look at the effect such non-identical data distributions has on visual classiﬁcation via Federated Learning. We propose a way to synthesize datasets with a continuous range of identicalness and provide performance measures for the Federated Averaging algorithm. We show that performance degrades as distributions differ more, and propose a mitigation strategy via server momentum. Experiments on CIFAR-10 demonstrate improved classiﬁcation performance over a range of non-identicalness, with classiﬁcation accuracy improved from 30.1\% to 76.9\% in the most skewed settings.},
	language = {en},
	journal = {arXiv preprint arXiv:1909.06335},
	author = {Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{yurochkin_bayesian_2019,
	title = {Bayesian nonparametric federated learning of neural networks},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Yurochkin, Mikhail and Agarwal, Mayank and Ghosh, Soumya and Greenewald, Kristjan and Hoang, Trong Nghia and Khazaeni, Yasaman},
	year = {2019},
	pages = {7252--7261},
}

@inproceedings{dennis_heterogeneity_2021,
	title = {Heterogeneity for the win: {One}-shot federated clustering},
	abstract = {In this work, we explore the unique challenges—and opportunities—of unsupervised federated learning (FL). We develop and analyze a one-shot federated clustering scheme, k-FED, based on the widely-used Lloyd’s method for k-means clustering. In contrast to many supervised problems, we show that the issue of statistical heterogeneity in federated networks can in fact beneﬁt our analysis. We analyse k-FED under a center separation assumption and compare it to the best known requirements of its centralized counterpart. Our analysis shows that in heterogeneous regimes where the number of clusters per device pk1q is smaller than the tot?al number of clusters over the network k, pk1 ď kq, we can use heterogeneity to our advantage—signiﬁcantly weakening the cluster separation requirements for k-FED. From a practical viewpoint, k-FED also has many desirable properties: it requires only one round of communication, can run asynchronously, and can handle partial participation or node/network failures. We motivate our analysis with experiments on common FL benchmarks, and highlight the practical utility of one-shot clustering through usecases in personalized FL and device sampling.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Dennis, Don Kurian and Li, Tian and Smith, Virginia},
	year = {2021},
	pages = {2611--2620},
}

@inproceedings{yun_minibatch_2022,
	title = {Minibatch vs local {SGD} with shuffling: {Tight} convergence bounds and beyond},
	abstract = {In distributed learning, local SGD (also known as federated averaging) and its simple baseline minibatch SGD are widely studied optimization methods. Most existing analyses of these methods assume independent and unbiased gradient estimates obtained via with-replacement sampling. In contrast, we study shufﬂingbased variants: minibatch and local Random Reshufﬂing, which draw stochastic gradients without replacement and are thus closer to practice. For smooth functions satisfying the Polyak-Łojasiewicz condition, we obtain convergence bounds (in the large epoch regime) which show that these shufﬂing-based variants converge faster than their with-replacement counterparts. Moreover, we prove matching lower bounds showing that our convergence analysis is tight. Finally, we propose an algorithmic modiﬁcation called synchronized shufﬂing that leads to convergence rates faster than our lower bounds in near-homogeneous settings.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Yun, Chulhee and Rajput, Shashank and Sra, Suvrit},
	year = {2022},
}

@inproceedings{yoon_federated_2021,
	title = {Federated continual learning with weighted inter-client transfer},
	abstract = {There has been a surge of interest in continual learning and federated learning, both of which are important in deep neural networks in realworld scenarios. Yet little research has been done regarding the scenario where each client learns on a sequence of tasks from a private local data stream. This problem of federated continual learning poses new challenges to continual learning, such as utilizing knowledge from other clients, while preventing interference from irrelevant knowledge. To resolve these issues, we propose a novel federated continual learning framework, Federated Weighted Inter-client Transfer (FedWeIT), which decomposes the network weights into global federated parameters and sparse task-speciﬁc parameters, and each client receives selective knowledge from other clients by taking a weighted combination of their task-speciﬁc parameters. FedWeIT minimizes interference between incompatible tasks, and also allows positive knowledge transfer across clients during learning. We validate our FedWeIT against existing federated learning and continual learning methods under varying degrees of task similarity across clients, and our model signiﬁcantly outperforms them with a large reduction in the communication cost. Code is available at https://github.com/wyjeong/FedWeIT.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Yoon, Jaehong and Jeong, Wonyong and Lee, Giwoong and Yang, Eunho and Hwang, Sung Ju},
	year = {2021},
	pages = {12073--12086},
}

@inproceedings{shoham_overcoming_2019,
	title = {Overcoming forgetting in federated learning on non-iid data},
	abstract = {We tackle the problem of Federated Learning in the non i.i.d. case, in which local models drift apart, inhibiting learning. Building on an analogy with Lifelong Learning, we adapt a solution for catastrophic forgetting to Federated Learning. We add a penalty term to the loss function, compelling all local models to converge to a shared optimum. We show that this can be done efﬁciently for communication (adding no further privacy risks), scaling with the number of nodes in the distributed setting. Our experiments show that this method is superior to competing ones for image recognition on the MNIST dataset.},
	language = {en},
	booktitle = {{NeurIPS} 2019 {Workshop} on {Federated} {Learning} for {Data} {Privacy} and {Confidentiality}},
	author = {Shoham, Neta and Avidor, Tomer and Keren, Aviv and Israel, Nadav and Benditkis, Daniel and Mor-Yosef, Liron and Zeitak, Itai},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Cryptography and Security},
}

@article{guo_towards_2022,
	title = {Towards federated learning on time-evolving heterogeneous data},
	abstract = {Federated Learning (FL) is an emerging learning paradigm that preserves privacy by ensuring client data locality on edge devices. The optimization of FL is challenging in practice due to the diversity and heterogeneity of the learning system. Despite recent research efforts on improving the optimization of heterogeneous data, the impact of time-evolving heterogeneous data in real-world scenarios, such as changing client data or intermittent clients joining or leaving during training, has not been well studied. In this work, we propose Continual Federated Learning (CFL), a ﬂexible framework, to capture the time-evolving heterogeneity of FL. CFL covers complex and realistic scenarios—which are challenging to evaluate in previous FL formulations—by extracting the information of past local datasets and approximating the local objective functions. Theoretically, we demonstrate that CFL methods achieve a faster convergence rate than FedAvg in time-evolving scenarios, with the beneﬁt being dependent on approximation quality. In a series of experiments, we show that the numerical ﬁndings match the convergence analysis, and CFL methods signiﬁcantly outperform the other SOTA FL baselines.},
	language = {en},
	journal = {arXiv preprint arXiv:2112.13246},
	author = {Guo, Yongxin and Lin, Tao and Tang, Xiaoying},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{balakrishnan_diverse_2022,
	title = {Diverse client selection for federated learning via submodular maximization},
	abstract = {In every communication round of federated learning, a random subset of clients communicate their model updates back to the server which then aggregates them all. The optimal size of this subset is not known and several studies have shown that typically random selection does not perform very well in terms of convergence, learning efﬁciency and fairness. We, in this paper, propose to select a small diverse subset of clients, namely those carrying representative gradient information, and we transmit only these updates to the server. Our aim is for updating via only a subset to approximate updating via aggregating all client information. We achieve this by choosing a subset that maximizes a submodular facility location function deﬁned over gradient space. We introduce “federated averaging with diverse client selection (DivFL)”. We provide a thorough analysis of its convergence in the heterogeneous setting and apply it both to synthetic and to real datasets. Empirical results show several beneﬁts of our approach, including improved learning efﬁciency, faster convergence, and more uniform (i.e., fair) performance across clients. We further show a communication-efﬁcient version of DivFL that can still outperform baselines on the above metrics.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Balakrishnan, Ravikumar and Li, Tian and Zhou, Tianyi and Himayat, Nageen and Smith, Virginia and Bilmes, Jeffrey},
	year = {2022},
}

@inproceedings{chen_bridging_2022,
	title = {On bridging generic and personalized federated learning for image classification},
	abstract = {Federated learning is promising for its capability to collaboratively train models with multiple clients without accessing their data, but vulnerable when clients’ data distributions diverge from each other. This divergence further leads to a dilemma: “Should we prioritize the learned model’s generic performance (for future use at the server) or its personalized performance (for each client)?” These two, seemingly competing goals have divided the community to focus on one or the other, yet in this paper we show that it is possible to approach both at the same time. Concretely, we propose a novel federated learning framework that explicitly decouples a model’s dual duties with two prediction tasks. On the one hand, we introduce a family of losses that are robust to non-identical class distributions, enabling clients to train a generic predictor with a consistent objective across them. On the other hand, we formulate the personalized predictor as a lightweight adaptive module that is learned to minimize each client’s empirical risk on top of the generic predictor. With this two-loss, two-predictor framework which we name Federated Robust Decoupling (FED-ROD), the learned model can simultaneously achieve state-ofthe-art generic and personalized performance, essentially bridging the two tasks.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Chen, Hong-You and Chao, Wei-Lun},
	year = {2022},
}

@inproceedings{guo_hybrid_2022,
	title = {Hybrid local sgd for federated learning with heterogeneous communications},
	abstract = {Communication is a key bottleneck in federated learning where a large number of edge devices collaboratively learn a model under the orchestration of a central server without sharing their own training data. While local SGD has been proposed to reduce the number of FL rounds and become the algorithm of choice for FL, its total communication cost is still prohibitive when each device needs to communicate with the remote server repeatedly for many times over bandwidthlimited networks. In light of both device-to-device (D2D) and device-to-server (D2S) cooperation opportunities in modern communication networks, this paper proposes a new federated optimization algorithm dubbed hybrid local SGD (HLSGD) in FL settings where devices are grouped into a set of disjoint clusters with high D2D communication bandwidth. HL-SGD subsumes previous proposed algorithms such as local SGD and gossip SGD and enables us to strike the best balance between model accuracy and runtime. We analyze the convergence of HL-SGD in the presence of heterogeneous data for general nonconvex settings. We also perform extensive experiments and show that the use of hybrid model aggregation via D2D and D2S communications in HL-SGD can largely speed up the training time of federated learning.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Guo, Yuanxiong and Hu, Rui and Gong, Yanmin and Sun, Ying},
	year = {2022},
}

@inproceedings{karimireddy_byzantine-robust_2022,
	title = {Byzantine-robust learning on heterogeneous datasets via bucketing},
	abstract = {In Byzantine robust distributed or federated learning, a central server wants to train a machine learning model over data distributed across multiple workers. However, a fraction of these workers may deviate from the prescribed algorithm and send arbitrary messages. While this problem has received significant attention recently, most current defenses assume that the workers have identical data. For realistic cases when the data across workers are heterogeneous (non-iid), we design new attacks which circumvent current defenses, leading to significant loss of performance. We then propose a simple bucketing scheme that adapts existing robust algorithms to heterogeneous datasets at a negligible computational cost. We also theoretically and experimentally validate our approach, showing that combining bucketing with existing robust algorithms is effective against challenging attacks. Our work is the ﬁrst to establish guaranteed convergence for the non-iid Byzantine robust problem under realistic assumptions.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Karimireddy, Sai Praneeth and He, Lie and Jaggi, Martin},
	year = {2022},
}

@article{wang_field_2021,
	title = {A field guide to federated optimization},
	journal = {arXiv preprint arXiv:2107.06917},
	author = {Wang, Jianyu and Charles, Zachary and Xu, Zheng and Joshi, Gauri and McMahan, H. Brendan and Al-Shedivat, Maruan and Andrew, Galen and Avestimehr, Salman and Daly, Katharine and Data, Deepesh},
	year = {2021},
}

@inproceedings{yang_anarchic_2022,
	title = {Anarchic federated learning},
	abstract = {Present-day federated learning (FL) systems deployed over edge networks consists of a large number of workers with high degrees of heterogeneity in data and/or computing capabilities, which call for ﬂexible worker participation in terms of timing, effort, data heterogeneity, etc. To satisfy the need for ﬂexible worker participation, we consider a new FL paradigm called “Anarchic Federated Learning” (AFL) in this paper. In stark contrast to conventional FL models, each worker in AFL has the freedom to choose i) when to participate in FL, and ii) the number of local steps to perform in each round based on its current situation (e.g., battery level, communication channels, privacy concerns). However, such chaotic worker behaviors in AFL impose many new open questions in algorithm design. In particular, it remains unclear whether one could develop convergent AFL training algorithms, and if yes, under what conditions and how fast the achievable convergence speed is. Toward this end, we propose two Anarchic Federated Averaging (AFA) algorithms with two-sided learning rates for both cross-device and cross-silo settings, which are named AFA-CD and AFA-CS, respectively. Somewhat surprisingly, we show that, under mild anarchic assumptions, both AFL algorithms achieve the best known convergence rate as the state-of-the-art algorithms for conventional FL. Moreover, they retain the highly desirable linear speedup effect with respect of both the number of workers and local steps in the new AFL paradigm. We validate the proposed algorithms with extensive experiments on real-world datasets.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Yang, Haibo and Zhang, Xin and Khanduri, Prashant and Liu, Jia},
	year = {2022},
}

@inproceedings{marfoq_personalized_2022,
	title = {Personalized federated learning through local memorization},
	abstract = {Federated learning allows clients to collaboratively learn statistical models while keeping their data local. Federated learning was originally used to train a unique global model to be served to all clients, but this approach might be sub-optimal when clients’ local data distributions are heterogeneous. In order to tackle this limitation, recent personalized federated learning methods train a separate model for each client while still leveraging the knowledge available at other clients. In this work, we exploit the ability of deep neural networks to extract high quality vectorial representations (embeddings) from non-tabular data, e.g., images and text, to propose a personalization mechanism based on local memorization. Personalization is obtained by interpolating a collectively trained global model with a local k-nearest neighbors (kNN) model based on the shared representation provided by the global model. We provide generalization bounds for the proposed approach in the case of binary classification, and we show on a suite of federated datasets that this approach achieves significantly higher accuracy and fairness than state-of-the-art methods.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Marfoq, Othmane and Neglia, Giovanni and Kameni, Laetitia and Vidal, Richard},
	year = {2022},
}

@inproceedings{lubana_orchestra_2022,
	title = {Orchestra: {Unsupervised} federated learning via globally consistent clustering},
	abstract = {Federated learning is generally used in tasks where labels are readily available (e.g., next word prediction). Relaxing this constraint requires design of unsupervised learning techniques that can support desirable properties for federated training: robustness to statistical/systems heterogeneity, scalability with number of participants, and communication efficiency. Prior work on this topic has focused on directly extending centralized self-supervised learning techniques, which are not designed to have the properties listed above. To address this situation, we propose Orchestra, a novel unsupervised federated learning technique that exploits the federation’s hierarchy to orchestrate a distributed clustering task and enforce a globally consistent partitioning of clients’ data into discriminable clusters. We show the algorithmic pipeline in Orchestra guarantees good generalization performance under a linear probe, allowing it to outperform alternative techniques in a broad range of conditions, including variation in heterogeneity, number of clients, participation ratio, and local epochs.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Lubana, Ekdeep Singh and Tang, Chi Ian and Kawsar, Fahim and Dick, Robert P and Mathur, Akhil},
	year = {2022},
}

@inproceedings{hafner_deep_2022,
	title = {Deep hierarchical planning from pixels},
	abstract = {Intelligent agents need to select long sequences of actions to solve complex tasks. While humans easily break down tasks into subgoals and reach them through millions of muscle commands, current artiﬁcial intelligence is limited to tasks with horizons of a few hundred decisions, despite large compute budgets. Research on hierarchical reinforcement learning aims to overcome this limitation but has proven to be challenging, current methods rely on manually speciﬁed goal spaces or subtasks, and no general solution exists. We introduce Director, a practical method for learning hierarchical behaviors directly from pixels by planning inside the latent space of a learned world model. The high-level policy maximizes task and exploration rewards by selecting latent goals and the low-level policy learns to achieve the goals. Despite operating in latent space, the decisions are interpretable because the world model can decode goals into images for visualization. Director outperforms exploration methods on tasks with sparse rewards, including 3D maze traversal with a quadruped robot from an egocentric camera and proprioception, without access to the global position or top-down view that was used by prior work. Director also learns successful behaviors across a wide range of environments, including visual control, Atari games, and DMLab levels.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Hafner, Danijar and Lee, Kuang-Huei and Fischer, Ian and Abbeel, Pieter},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@article{wei_data-dependent_2020,
	title = {Data-dependent sample complexity of deep neural networks via lipschitz augmentation},
	abstract = {Existing Rademacher complexity bounds for neural networks rely only on norm control of the weight matrices and depend exponentially on depth via a product of the matrix norms. Lower bounds show that this exponential dependence on depth is unavoidable when no additional properties of the training data are considered. We suspect that this conundrum comes from the fact that these bounds depend on the training data only through the margin. In practice, many data-dependent techniques such as Batchnorm improve the generalization performance. For feedforward neural nets as well as RNNs, we obtain tighter Rademacher complexity bounds by considering additional data-dependent properties of the network: the norms of the hidden layers of the network, and the norms of the Jacobians of each layer with respect to all previous layers. Our bounds scale polynomially in depth when these empirical quantities are small, as is usually the case in practice. To obtain these bounds, we develop general tools for augmenting a sequence of functions to make their composition Lipschitz and then covering the augmented functions. Inspired by our theory, we directly regularize the network’s Jacobians during training and empirically demonstrate that this improves test performance.},
	language = {en},
	journal = {arXiv preprint arXiv:1905.03684},
	author = {Wei, Colin and Ma, Tengyu},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{wei_improved_2021,
	title = {Improved sample complexities for deep networks and robust classification via an all-layer margin},
	abstract = {For linear classifiers, the relationship between (normalized) output margin and generalization is captured in a clear and simple bound – a large output margin implies good generalization. Unfortunately, for deep models, this relationship is less clear: existing analyses of the output margin give complicated bounds which sometimes depend exponentially on depth. In this work, we propose to instead analyze a new notion of margin, which we call the “alllayer margin.” Our analysis reveals that the all-layer margin has a clear and direct relationship with generalization for deep models. This enables the following concrete applications of the all-layer margin: 1) by analyzing the all-layer margin, we obtain tighter generalization bounds for neural nets which depend on Jacobian and hidden layer norms and remove the exponential dependency on depth 2) our neural net results easily translate to the adversarially robust setting, giving the ﬁrst direct analysis of robust test error for deep networks, and 3) we present a theoretically inspired training algorithm for increasing the all-layer margin. Our algorithm improves both clean and adversarially robust test performance over strong baselines in practice.},
	language = {en},
	journal = {arXiv preprint arXiv:1910.04284},
	author = {Wei, Colin and Ma, Tengyu},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{deng_discovering_2022,
	title = {Discovering and explaining the representation bottleneck of {DNNs}},
	abstract = {This paper explores the bottleneck of feature representations of deep neural networks (DNNs), from the perspective of the complexity of interactions between input variables encoded in DNNs. To this end, we focus on the multi-order interaction between input variables, where the order represents the complexity of interactions. We discover that a DNN is more likely to encode both too simple interactions and too complex interactions, but usually fails to learn interactions of intermediate complexity. Such a phenomenon is widely shared by different DNNs for different tasks. This phenomenon indicates a cognition gap between DNNs and human beings, and we call it a representation bottleneck. We theoretically prove the underlying reason for the representation bottleneck. Furthermore, we propose a loss to encourage/penalize the learning of interactions of speciﬁc complexities, and analyze the representation capacities of interactions of different complexities.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Deng, Huiqi and Ren, Qihan and Zhang, Hao and Zhang, Quanshi},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{manias_concept_2021,
	title = {Concept drift detection in federated networked systems},
	doi = {10.1109/GLOBECOM46510.2021.9685083},
	abstract = {As next-generation networks materialize, increasing levels of intelligence are required. Federated Learning has been identiﬁed as a key enabling technology of intelligent and distributed networks; however, it is prone to concept drift as with any machine learning application. Concept drift directly affects the model’s performance and can result in severe consequences considering the critical and emergency services provided by modern networks. To mitigate the adverse effects of drift, this paper proposes a concept drift detection system leveraging the federated learning updates provided at each iteration of the federated training process. Using dimensionality reduction and clustering techniques, a framework that isolates the system’s drifted nodes is presented through experiments using an Intelligent Transportation System as a use case. The presented work demonstrates that the proposed framework is able to detect drifted nodes in a variety of non-iid scenarios at different stages of drift and different levels of system exposure.},
	language = {en},
	booktitle = {2021 {IEEE} {Global} {Communications} {Conference} ({GLOBECOM})},
	author = {Manias, Dimitrios Michael and Shaer, Ibrahim and Yang, Li and Shami, Abdallah},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Networking and Internet Architecture},
	pages = {1--6},
}

@inproceedings{canonaco_adaptive_2021,
	title = {Adaptive federated learning in presence of concept drift},
	doi = {10.1109/IJCNN52387.2021.9533710},
	abstract = {Federated Learning (FL) is a promising research area in the machine learning field. Techniques and solutions belonging to this area operate in distributed scenarios, comprising a server and pervasively distributed clients, aiming at learning a single central model without sending (possibly sensitive) data from the clients to the server. Such an approach allows mitigating the privacy concerns that are nowadays perceived as relevant in distributed machine learning solutions leveraging data belonging to different users or companies. The literature in the field of FL is wide and many state-of-the-art solutions are available. Unfortunately, all these solutions assume (implicitly or explicitly) that the process generating the data is stationary (hence not changing its statistical behavior over time); an assumption that rarely holds in real-world conditions where concept drift occurs due to, e.g., seasonality or periodicity effects, faults in sensors or actuators or changes in the users' behaviour. In this paper, we introduce, for the first time in the literature, a novel FL algorithm called Adaptive-FedAVG, able to operate with nonstationary data generating processes affected by concept drifts. Following a passive approach, Adaptive-FedAVG is able to increase the accuracy in stationary conditions and promptly react to concept drift by adapting the learning rate to increase the plasticity of the learning phase. A wide experimental campaign shows the effectiveness of the proposed Adaptive-FedAVG algorithm by comparing it with a state-of-the-art FL algorithm present in the literature both in stationary and non-stationary conditions.},
	booktitle = {2021 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Canonaco, Giuseppe and Bergamasco, Alex and Mongelluzzo, Alessio and Roveri, Manuel},
	year = {2021},
	keywords = {Machine learning, Distributed databases, Neural networks, Actuators, Collaborative work, Companies, Data privacy},
	pages = {1--7},
}

@inproceedings{chen_asynchronous_2021,
	title = {Asynchronous federated learning for sensor data with concept drift},
	doi = {10.1109/BigData52589.2021.9671924},
	abstract = {Federated learning (FL) involves multiple distributed devices jointly training a shared model without any of the participants having to reveal their local data to a centralized server. Most of previous FL approaches assume that data on devices are fixed and stationary during the training process. However, this assumption is unrealistic because these devices usually have varying sampling rates and different system configurations. In addition, the underlying distribution of the device data can change dynamically over time, which is known as concept drift. Concept drift makes the learning process complicated because of the inconsistency between existing and upcoming data. Traditional concept drift handling techniques such as chunk based and ensemble learning-based methods are not suitable in the federated learning frameworks due to the heterogeneity of local devices. We propose a novel approach, FedConD, to detect and deal with the concept drift on local devices and minimize the effect on the performance of models in asynchronous FL. The drift detection strategy is based on an adaptive mechanism which uses the historical performance of the local models. The drift adaptation is realized by adjusting the regularization parameter of objective function on each local device. Additionally, we design a communication strategy on the server side to select local updates in a prudent fashion and speed up model convergence. Experimental evaluations on three evolving data streams and two image datasets show that FedConD detects and handles concept drift, and also reduces the overall communication cost compared to other baseline methods.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Chen, Yujing and Chai, Zheng and Cheng, Yue and Rangwala, Huzefa},
	year = {2021},
	keywords = {Adaptation models, federated learning, Training, Streaming media, Collaborative work, asynchronous learning, Big Data, communication-efficient, con-cept drift, Costs, Performance evaluation},
	pages = {4822--4831},
}

@article{casado_concept_2022,
	title = {Concept drift detection and adaptation for federated and continual learning},
	volume = {81},
	issn = {1573-7721},
	doi = {10.1007/s11042-021-11219-x},
	abstract = {Smart devices, such as smartphones, wearables, robots, and others, can collect vast amounts of data from their environment. This data is suitable for training machine learning models, which can significantly improve their behavior, and therefore, the user experience. Federated learning is a young and popular framework that allows multiple distributed devices to train deep learning models collaboratively while preserving data privacy. Nevertheless, this approach may not be optimal for scenarios where data distribution is non-identical among the participants or changes over time, causing what is known as concept drift. Little research has yet been done in this field, but this kind of situation is quite frequent in real life and poses new challenges to both continual and federated learning. Therefore, in this work, we present a new method, called Concept-Drift-Aware Federated Averaging (CDA-FedAvg). Our proposal is an extension of the most popular federated algorithm, Federated Averaging (FedAvg), enhancing it for continual adaptation under concept drift. We empirically demonstrate the weaknesses of regular FedAvg and prove that CDA-FedAvg outperforms it in this type of scenario.},
	language = {en},
	number = {3},
	journal = {Multimedia Tools and Applications},
	author = {Casado, Fernando E. and Lema, Dylan and Criado, Marcos F. and Iglesias, Roberto and Regueiro, Carlos V. and Barro, Senén},
	year = {2022},
	keywords = {Catastrophic forgetting, Continual learning, Concept drift, Federated Averaging, Federated learning, Nonstationarity, Rehearsal},
	pages = {3397--3419},
}

@article{jiang_improving_2019,
	title = {Improving federated learning personalization via model agnostic meta learning},
	abstract = {Federated Learning (FL) refers to learning a high quality global model based on decentralized data storage, without ever copying the raw data. A natural scenario arises with data created on mobile phones by the activity of their users. Given the typical data heterogeneity in such situations, it is natural to ask how can the global model be personalized for every such device, individually. In this work, we point out that the setting of Model Agnostic Meta Learning (MAML), where one optimizes for a fast, gradient-based, few-shot adaptation to a heterogeneous distribution of tasks, has a number of similarities with the objective of personalization for FL. We present FL as a natural source of practical applications for MAML algorithms, and make the following observations. 1) The popular FL algorithm, Federated Averaging (McMahan et al., 2017), can be interpreted as a meta learning algorithm. 2) Careful ﬁne-tuning can yield a global model with higher accuracy, which is at the same time easier to personalize. However, solely optimizing for the global model accuracy yields a weaker personalization result. 3) A model trained using a standard datacenter optimization method is much harder to personalize, compared to one trained using Federated Averaging, supporting the ﬁrst claim. These results raise new questions for FL, MAML, and broader ML research.},
	language = {en},
	journal = {arXiv preprint arXiv:1909.12488},
	author = {Jiang, Yihan and Konečný, Jakub and Rush, Keith and Kannan, Sreeram},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{hanzely_lower_2020,
	title = {Lower bounds and optimal algorithms for personalized federated learning},
	abstract = {In this work, we consider the optimization formulation of personalized federated learning recently introduced by [19] which was shown to give an alternative explanation to the workings of local SGD methods. Our ﬁrst contribution is establishing the ﬁrst lower bounds for this formulation, for both the communication complexity and the local oracle complexity. Our second contribution is the design of several optimal methods matching these lower bounds in almost all regimes. These are the ﬁrst provably optimal methods for personalized federated learning. Our optimal methods include an accelerated variant of FedProx, and an accelerated variancereduced version of FedAvg/Local SGD. We demonstrate the practical superiority of our methods through extensive numerical experiments.},
	language = {en},
	author = {Hanzely, Filip and Horváth, Samuel and Hanzely, Slavomír and Richtárik, Peter},
	year = {2020},
	pages = {2304--2315},
}

@inproceedings{caldarola_cluster-driven_2021,
	address = {Nashville, TN, USA},
	title = {Cluster-driven graph federated learning over multiple domains},
	isbn = {978-1-66544-899-4},
	doi = {10.1109/CVPRW53098.2021.00309},
	abstract = {Federated Learning (FL) deals with learning a central model (i.e. the server) in privacy-constrained scenarios, where data are stored on multiple devices (i.e. the clients). The central model has no direct access to the data, but only to the updates of the parameters computed locally by each client. This raises a problem, known as statistical heterogeneity, because the clients may have different data distributions (i.e. domains). This is only partly alleviated by clustering the clients. Clustering may reduce heterogeneity by identifying the domains, but it deprives each cluster model of the data and supervision of others.},
	language = {en},
	booktitle = {2021 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	author = {Caldarola, Debora and Mancini, Massimiliano and Galasso, Fabio and Ciccone, Marco and Rodola, Emanuele and Caputo, Barbara},
	year = {2021},
	pages = {2743--2752},
}

@inproceedings{ghosh_efficient_2020,
	title = {An efficient framework for clustered federated learning},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ghosh, Avishek and Chung, Jichan and Yin, Dong and Ramchandran, Kannan},
	year = {2020},
	pages = {19586--19597},
}

@article{deng_adaptive_2020,
	title = {Adaptive personalized federated learning},
	abstract = {Investigation of the degree of personalization in federated learning algorithms has shown that only maximizing the performance of the global model will conﬁne the capacity of the local models to personalize. In this paper, we advocate an adaptive personalized federated learning (APFL) algorithm, where each client will train their local models while contributing to the global model. We derive the generalization bound of mixture of local and global models, and ﬁnd the optimal mixing parameter. We also propose a communication-eﬃcient optimization method to collaboratively learn the personalized models and analyze its convergence in both smooth strongly convex and nonconvex settings. The extensive experiments demonstrate the eﬀectiveness of our personalization schema, as well as the correctness of established generalization theories.},
	language = {en},
	journal = {arXiv preprint arXiv:2003.13461},
	author = {Deng, Yuyang and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing},
}

@article{tan_towards_2022,
	title = {Towards personalized federated learning},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2022.3160699},
	abstract = {In parallel with the rapid adoption of artificial intelligence (AI) empowered by advances in AI research, there has been growing awareness and concerns of data privacy. Recent significant developments in the data regulation landscape have prompted a seismic shift in interest toward privacy-preserving AI. This has contributed to the popularity of Federated Learning (FL), the leading paradigm for the training of machine learning models on data silos in a privacy-preserving manner. In this survey, we explore the domain of personalized FL (PFL) to address the fundamental challenges of FL on heterogeneous data, a universal characteristic inherent in all real-world datasets. We analyze the key motivations for PFL and present a unique taxonomy of PFL techniques categorized according to the key challenges and personalization strategies in PFL. We highlight their key ideas, challenges, opportunities, and envision promising future trajectories of research toward a new PFL architectural design, realistic PFL benchmarking, and trustworthy PFL approaches.},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Tan, Alysa Ziying and Yu, Han and Cui, Lizhen and Yang, Qiang},
	year = {2022},
	keywords = {Adaptation models, Data models, Servers, Training, Collaborative work, Data privacy, Edge computing, Faces, federated learning (FL), non-IID data, personalized FL (PFL), privacy preservation, statistical heterogeneity.},
	pages = {1--17},
}

@article{mansour_three_2020,
	title = {Three approaches for personalization with applications to federated learning},
	abstract = {The standard objective in machine learning is to train a single model for all users. However, in many learning scenarios, such as cloud computing and federated learning, it is possible to learn a personalized model per user. In this work, we present a systematic learning-theoretic study of personalization. We propose and analyze three approaches: user clustering, data interpolation, and model interpolation. For all three approaches, we provide learning-theoretic guarantees and efﬁcient algorithms for which we also demonstrate the performance empirically. All of our algorithms are model-agnostic and work for any hypothesis class.},
	language = {en},
	journal = {arXiv preprint arXiv:2002.10619},
	author = {Mansour, Yishay and Mohri, Mehryar and Ro, Jae and Suresh, Ananda Theertha},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{jothimurugesan_federated_2022,
	title = {Federated learning under distributed concept drift},
	abstract = {Federated Learning (FL) under distributed concept drift is a largely unexplored area. Although concept drift is itself a well-studied phenomenon, it poses particular challenges for FL, because drifts arise staggered in time and space (across clients). Our work is the ﬁrst to explicitly study data heterogeneity in both dimensions. We ﬁrst demonstrate that prior solutions to drift adaptation, with their single global model, are ill-suited to staggered drifts, necessitating multi-model solutions. We identify the problem of drift adaptation as a time-varying clustering problem, and we propose two new clustering algorithms for reacting to drifts based on local drift detection and hierarchical clustering. Empirical evaluation shows that our solutions achieve signiﬁcantly higher accuracy than existing baselines, and are comparable to an idealized algorithm with oracle knowledge of the ground-truth clustering of clients to concepts at each time step.},
	language = {en},
	journal = {arXiv preprint arXiv:2206.00799},
	author = {Jothimurugesan, Ellango and Hsieh, Kevin and Wang, Jianyu and Joshi, Gauri and Gibbons, Phillip B.},
	year = {2022},
	keywords = {Computer Science - Machine Learning, I.2.6},
}

@inproceedings{tahmasbi_driftsurf_2021,
	title = {{DriftSurf}: {Stable}-state / reactive-state learning under concept drift},
	abstract = {When learning from streaming data, a change in the data distribution, also known as concept drift, can render a previously-learned model inaccurate and require training a new model. We present an adaptive learning algorithm that extends previous drift-detection-based methods by incorporating drift detection into a broader stable-state/reactivestate process. The advantage of our approach is that we can use aggressive drift detection in the stable state to achieve a high detection rate, but mitigate the false positive rate of standalone drift detection via a reactive state that reacts quickly to true drifts while eliminating most false positives. The algorithm is generic in its base learner and can be applied across a variety of supervised learning problems. Our theoretical analysis shows that the risk of the algorithm is (i) statistically better than standalone drift detection and (ii) competitive to an algorithm with oracle knowledge of when (abrupt) drifts occur. Experiments on synthetic and real datasets with concept drifts confrm our theoretical analysis.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Tahmasbi, Ashraf and Jothimurugesan, Ellango and Tirthapura, Srikanta and Gibbons, Phillip B},
	year = {2021},
	pages = {10054--10064},
}

@inproceedings{bach_paired_2008,
	title = {Paired learners for concept drift},
	doi = {10.1109/ICDM.2008.119},
	abstract = {To cope with concept drift, we paired a stable online learner with a reactive one. A stable learner predicts based on all of its experience, whereas are active learner predicts based on its experience over a short, recent window of time. The method of paired learning uses differences in accuracy between the two learners over this window to determine when to replace the current stable learner, since the stable learner performs worse than does there active learner when the target concept changes. While the method uses the reactive learner as an indicator of drift, it uses the stable learner to predict, since the stable learner performs better than does the reactive learner when acquiring target concept. Experimental results support these assertions. We evaluated the method by making direct comparisons to dynamic weighted majority, accuracy weighted ensemble, and streaming ensemble algorithm (SEA) using two synthetic problems, the Stagger concepts and the SEA concepts, and three real-world data sets: meeting scheduling, electricity prediction, and malware detection. Results suggest that, on these problems, paired learners outperformed or performed comparably to methods more costly in time and space.},
	booktitle = {2008 {Eighth} {IEEE} {International} {Conference} on {Data} {Mining}},
	author = {Bach, Stephen H. and Maloof, Marcus A.},
	year = {2008},
	keywords = {Computer science, Data mining, Algorithm design and analysis, concept drift, Dynamic scheduling, Heuristic algorithms, online learning, Scheduling algorithm, Stability, time-changing data streams, USA Councils},
	pages = {23--32},
}

@article{zhao_handling_2020,
	title = {Handling concept drift via model reuse},
	volume = {109},
	issn = {0885-6125, 1573-0565},
	doi = {10.1007/s10994-019-05835-w},
	abstract = {In many real-world applications, data are often collected in the form of a stream, and thus the distribution usually changes in nature, which is referred to as concept drift in the literature. We propose a novel and effective approach to handle concept drift via model reuse, that is, reusing models trained on previous data to tackle the changes. Each model is associated with a weight representing its reusability towards current data, and the weight is adaptively adjusted according to the performance of the model. We provide both generalization and regret analysis to justify the superiority of our approach. Experimental results also validate its efﬁcacy on both synthetic and real-world datasets.},
	language = {en},
	number = {3},
	journal = {Machine Learning},
	author = {Zhao, Peng and Cai, Le-Wen and Zhou, Zhi-Hua},
	year = {2020},
	pages = {533--568},
}

@inproceedings{harel_concept_2014,
	title = {Concept drift detection through resampling},
	abstract = {Detecting changes in data-streams is an important part of enhancing learning quality in dynamic environments. We devise a procedure for detecting concept drifts in data-streams that relies on analyzing the empirical loss of learning algorithms. Our method is based on obtaining statistics from the loss distribution by reusing the data multiple times via resampling. We present theoretical guarantees for the proposed procedure based on the stability of the underlying learning algorithms. Experimental results show that the method has high recall and precision, and performs well in the presence of noise.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Harel, Maayan and Crammer, Koby and El-Yaniv, Ran and Mannor, Shie},
	year = {2014},
	pages = {1009--1017},
}

@article{peng_imitation_2022,
	title = {An imitation learning framework for generating multi-modal trajectories from unstructured demonstrations},
	volume = {500},
	journal = {Neurocomputing},
	author = {Peng, Jian-Wei and Hu, Min-Chun and Chu, Wei-Ta},
	year = {2022},
	pages = {712--723},
}

@article{ke_imitation_2020,
	title = {Imitation learning as \$f\$-divergence minimization},
	abstract = {We address the problem of imitation learning with multimodal demonstrations. Instead of attempting to learn all modes, we argue that in many tasks it is suﬃcient to imitate any one of them. We show that the state-of-the-art methods such as GAIL and behavior cloning, due to their choice of loss function, often incorrectly interpolate between such modes. Our key insight is to minimize the right divergence between the learner and the expert state-action distributions, namely the reverse KL divergence or I-projection. We propose a general imitation learning framework for estimating and minimizing any f -Divergence. By plugging in diﬀerent divergences, we are able to recover existing algorithms such as Behavior Cloning (Kullback-Leibler), GAIL (Jensen Shannon) and DAgger (Total Variation). Empirical results show that our approximate I-projection technique is able to imitate multi-modal behaviors more reliably than GAIL and behavior cloning.},
	language = {en},
	journal = {arXiv preprint arXiv:1905.12888},
	author = {Ke, Liyiming and Choudhury, Sanjiban and Barnes, Matt and Sun, Wen and Lee, Gilwoo and Srinivasa, Siddhartha},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Robotics, Computer Science - Information Theory},
}

@inproceedings{sharma_directed-info_2019,
	title = {Directed-info {GAIL}: {Learning} hierarchical policies from unsegmented demonstrations using directed information},
	shorttitle = {Directed-info gail},
	abstract = {The use of imitation learning to learn a single policy for a complex task that has multiple modes or hierarchical structure can be challenging. In fact, previous work has shown that when the modes are known, learning separate policies for each mode or sub-task can greatly improve the performance of imitation learning. In this work, we discover the interaction between sub-tasks from their resulting stateaction trajectory sequences using a directed graphical model. We propose a new algorithm based on the generative adversarial imitation learning framework which automatically learns sub-task policies from unsegmented demonstrations. Our approach maximizes the directed information ﬂow in the graphical model between sub-task latent variables and their generated trajectories. We also show how our approach connects with the existing Options framework, which is commonly used to learn hierarchical policies.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Sharma, Arjun and Sharma, Mohit and Rhinehart, Nicholas and Kitani, Kris M.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{fu_learning_2018,
	title = {Learning robust rewards with adversarial inverse reinforcement learning},
	abstract = {Reinforcement learning provides a powerful and general framework for decision making and control, but its application in practice is often hindered by the need for extensive feature and reward engineering. Deep reinforcement learning methods can remove the need for explicit engineering of policy or value features, but still require a manually speciﬁed reward function. Inverse reinforcement learning holds the promise of automatic reward acquisition, but has proven exceptionally difﬁcult to apply to large, high-dimensional problems with unknown dynamics. In this work, we propose AIRL, a practical and scalable inverse reinforcement learning algorithm based on an adversarial reward learning formulation. We demonstrate that AIRL is able to recover reward functions that are robust to changes in dynamics, enabling us to learn policies even under signiﬁcant variation in the environment seen during training. Our experiments show that AIRL greatly outperforms prior methods in these transfer settings.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Fu, Justin and Luo, Katie and Levine, Sergey},
	year = {2018},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{hausman_multi-modal_2017,
	title = {Multi-modal imitation learning from unstructured demonstrations using generative adversarial nets},
	booktitle = {Advances in neural information processing systems},
	author = {Hausman, Karol and Chebotar, Yevgen and Schaal, Stefan and Sukhatme, Gaurav and Lim, Joseph J.},
	year = {2017},
}

@inproceedings{li_infogail_2017,
	title = {{InfoGAIL}: {Interpretable} imitation learning from visual demonstrations},
	abstract = {The goal of imitation learning is to mimic expert behavior without access to an explicit reward signal. Expert demonstrations provided by humans, however, often show signiﬁcant variability due to latent factors that are typically not explicitly modeled. In this paper, we propose a new algorithm that can infer the latent structure of expert demonstrations in an unsupervised way. Our method, built on top of Generative Adversarial Imitation Learning, can not only imitate complex behaviors, but also learn interpretable and meaningful representations of complex behavioral data, including visual demonstrations. In the driving domain, we show that a model learned from human demonstrations is able to both accurately reproduce a variety of behaviors and accurately anticipate human actions using raw visual inputs. Compared with various baselines, our method can better capture the latent structure underlying expert demonstrations, often recovering semantically meaningful factors of variation in the data.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Li, Yunzhu and Song, Jiaming and Ermon, Stefano},
	year = {2017},
}

@article{osa_algorithmic_2018,
	title = {An algorithmic perspective on imitation learning},
	volume = {7},
	number = {1-2},
	journal = {Foundations and Trends® in Robotics},
	author = {Osa, Takayuki and Pajarinen, Joni and Neumann, Gerhard and Bagnell, J. Andrew and Abbeel, Pieter and Peters, Jan},
	year = {2018},
	pages = {1--179},
}

@article{lee_diversify_2022,
	title = {Diversify and disambiguate: {Learning} from underspecified data},
	shorttitle = {Diversify and disambiguate},
	abstract = {Many datasets are underspecified : there exist multiple equally viable solutions to a given task. Underspeciﬁcation can be problematic for methods that learn a single hypothesis, because diﬀerent functions that achieve low training loss can focus on diﬀerent predictive features and thus produce widely varying predictions on out-of-distribution data. We propose DivDis, a simple two-stage framework that ﬁrst learns a diverse collection of hypotheses for a task by leveraging unlabeled data from the test distribution. We then disambiguate by selecting one of the discovered hypotheses using minimal additional supervision, in the form of additional labels or inspection of function visualization. We demonstrate the ability of DivDis to ﬁnd hypotheses that use robust features in image classiﬁcation and natural language processing problems with underspeciﬁcation.},
	language = {en},
	journal = {arXiv preprint arXiv:2202.03418},
	author = {Lee, Yoonho and Yao, Huaxiu and Finn, Chelsea},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{yao_improving_2022,
	title = {Improving out-of-distribution robustness via selective augmentation},
	abstract = {Machine learning algorithms typically assume that training and test examples are drawn from the same distribution. However, distribution shift is a common problem in real-world applications and can cause models to perform dramatically worse at test time. In this paper, we specifically consider the problems of subpopulation shifts (e.g., imbalanced data) and domain shifts. While prior works often seek to explicitly regularize internal representations or predictors of the model to be domain invariant, we instead aim to learn invariant predictors without restricting the model's internal representations or predictors. This leads to a simple mixup-based technique which learns invariant predictors via selective augmentation called LISA. LISA selectively interpolates samples either with the same labels but different domains or with the same domain but different labels. Empirically, we study the effectiveness of LISA on nine benchmarks ranging from subpopulation shifts to domain shifts, and we find that LISA consistently outperforms other state-of-the-art methods and leads to more invariant predictors. We further analyze a linear setting and theoretically show how LISA leads to a smaller worst-group error.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Yao, Huaxiu and Wang, Yu and Li, Sai and Zhang, Linjun and Liang, Weixin and Zou, James and Finn, Chelsea},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@article{haochen_beyond_2022,
	title = {Beyond separability: {Analyzing} the linear transferability of contrastive representations to related subpopulations},
	shorttitle = {Beyond separability},
	abstract = {Contrastive learning is a highly effective method for learning representations from unlabeled data. Recent works show that contrastive representations can transfer across domains, leading to simple state-of-the-art algorithms for unsupervised domain adaptation. In particular, a linear classiﬁer trained to separate the representations on the source domain can also predict classes on the target domain accurately, even though the representations of the two domains are far from each other. We refer to this phenomenon as linear transferability. This paper analyzes when and why contrastive representations exhibit linear transferability in a general unsupervised domain adaptation setting. We prove that linear transferability can occur when data from the same class in different domains (e.g., photo dogs and cartoon dogs) are more related with each other than data from different classes in different domains (e.g., photo dogs and cartoon cats) are. Our analyses are in a realistic regime where the source and target domains can have unbounded density ratios and be weakly related, and they have distant representations across domains.},
	language = {en},
	journal = {arXiv preprint arXiv:2204.02683},
	author = {HaoChen, Jeff Z. and Wei, Colin and Kumar, Ananya and Ma, Tengyu},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{shen_connect_2022,
	title = {Connect, not collapse: {Explaining} contrastive learning for unsupervised domain adaptation},
	volume = {19847-19878},
	shorttitle = {Connect, not collapse},
	abstract = {We consider unsupervised domain adaptation (UDA), where labeled data from a source domain (e.g., photographs ) and unlabeled data from a target domain (e.g., sketches) are used to learn a classiﬁer for the target domain. Conventional UDA methods (e.g., domain adversarial training) learn domain-invariant features to improve generalization to the target domain. In this paper, we show that contrastive pre-training, which learns features on unlabeled source and target data and then ﬁne-tunes on labeled source data, is competitive with strong UDA methods. However, we ﬁnd that contrastive pre-training does not learn domain-invariant features, diverging from conventional UDA intuitions. We show theoretically that contrastive pre-training can learn features that vary subtantially across domains but still generalize to the target domain, by disentangling domain and class information. Our results suggest that domain invariance is not necessary for UDA . We empirically validate our theory on benchmark vision datasets.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Shen, Kendrick and Jones, Robbie and Kumar, Ananya and Xie, Sang Michael and HaoChen, Jeff Z. and Ma, Tengyu and Liang, Percy},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{ma_principles_2022,
	title = {On the principles of parsimony and self-consistency for the emergence of intelligence},
	abstract = {Ten years into the revival of deep networks and artiﬁcial intelligence, we propose a theoretical framework that sheds light on understanding deep networks within a bigger picture of Intelligence in general. We introduce two fundamental principles, Parsimony and Self-consistency, that we believe to be cornerstones for the emergence of Intelligence, artiﬁcial or natural. While these two principles have rich classical roots, we argue that they can be stated anew in entirely measurable and computable ways. More speciﬁcally, the two principles lead to an effective and efﬁcient computational framework, compressive closed-loop transcription, that uniﬁes and explains the evolution of modern deep networks and many artiﬁcial intelligence practices. While we mainly use modeling of visual data as an example, we believe the two principles will unify understanding of broad families of autonomous intelligent systems and provide a framework for understanding the brain.},
	language = {en},
	journal = {arXiv preprint arXiv:2207.04630},
	author = {Ma, Yi and Tsao, Doris and Shum, Heung-Yeung},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, I.2, Mathematics - Optimization and Control, Computer Science - Information Theory},
}

@inproceedings{zhou_deep_2022,
	title = {Do deep networks transfer invariances across classes?},
	abstract = {To generalize well, classifiers must learn to be invariant to nuisance transformations that do not alter an input’s class. Many problems have “class-agnostic” nuisance transformations that apply similarly to all classes, such as lighting and background changes for image classiﬁcation. Neural networks can learn these invariances given sufﬁcient data, but many real-world datasets are heavily class imbalanced and contain only a few examples for most of the classes. We therefore pose the question: how well do neural networks transfer class-agnostic invariances learned from the large classes to the small ones? Through careful experimentation, we observe that invariance to class-agnostic transformations is still heavily dependent on class size, with the networks being much less invariant on smaller classes. This result holds even when using data balancing techniques, and suggests poor invariance transfer across classes. Our results provide one explanation for why classiﬁers generalize poorly on unbalanced and long-tailed distributions. Based on this analysis, we show how a generative approach for learning the nuisance transformations can help transfer invariances across classes and improve performance on a set of imbalanced image classiﬁcation benchmarks. Source code for our experiments is available at https://github.com/AllanYangZhou/ generative-invariance-transfer.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Zhou, Allan and Tajwar, Fahim and Robey, Alexander and Knowles, Tom and Pappas, George J. and Hassani, Hamed and Finn, Chelsea},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{mehra_certifying_2022,
	title = {On certifying and improving generalization to unseen domains},
	abstract = {Domain Generalization (DG) aims to learn models whose performance remains high on unseen domains encountered at test-time by using data from multiple related source domains. Many existing DG algorithms reduce the divergence between source distributions in a representation space to potentially align the unseen domain close to the sources. This is motivated by the analysis that explains generalization to unseen domains using distributional distance (such as the Wasserstein distance) to the sources. However, due to the openness of the DG objective, it is challenging to evaluate DG algorithms comprehensively using a few benchmark datasets. In particular, we demonstrate that the accuracy of the models trained with DG methods varies signiﬁcantly across unseen domains, generated from popular benchmark datasets. This highlights that the performance of DG methods on a few benchmark datasets may not be representative of their performance on unseen domains in the wild. To overcome this roadblock, we propose a universal certiﬁcation framework based on distributionally robust optimization (DRO) that can efﬁciently certify the worst-case performance of any DG method. This enables a data-independent evaluation of a DG method complementary to the empirical evaluations on benchmark datasets. Furthermore, we propose a training algorithm that can be used with any DG method to provably improve their certiﬁed performance. Our empirical evaluation demonstrates the effectiveness of our method at signiﬁcantly improving the worst-case loss (i.e., reducing the risk of failure of these models in the wild) without incurring a signiﬁcant performance drop on benchmark datasets.},
	language = {en},
	journal = {arXiv preprint arXiv:2206.12364},
	author = {Mehra, Akshay and Kailkhura, Bhavya and Chen, Pin-Yu and Hamm, Jihun},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{ghosh_offline_2022,
	title = {Offline {RL} policies should be trained to be adaptive},
	abstract = {Offine RL algorithms must account for the fact that the dataset they are provided may leave many facets of the environment unknown. The most common way to approach this challenge is to employ pessimistic or conservative methods, which avoid behaviors that are too dissimilar from those in the training dataset. However, relying exclusively on conservatism has drawbacks: performance is sensitive to the exact degree of conservatism, and conservative objectives can recover highly suboptimal policies. In this work, we propose that ofﬂine RL methods should instead be adaptive in the presence of uncertainty. We show that acting optimally in ofﬂine RL in a Bayesian sense involves solving an implicit POMDP. As a result, optimal policies for ofﬂine RL must be adaptive, depending not just on the current state but rather all the transitions seen so far during evaluation. We present a model-free algorithm for approximating this optimal adaptive policy, and demonstrate the efﬁcacy of learning such adaptive policies in ofﬂine RL benchmarks.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Ghosh, Dibya and Ajay, Anurag and Agrawal, Pulkit and Levine, Sergey},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {7513--7530},
}

@article{geirhos_shortcut_2020,
	title = {Shortcut learning in deep neural networks},
	volume = {2},
	issn = {2522-5839},
	doi = {10.1038/s42256-020-00257-z},
	abstract = {Deep learning has triggered the current rise of artiﬁcial intelligence and is the workhorse of today’s machine intelligence. Numerous success stories have rapidly spread all over science, industry and society, but its limitations have only recently come into focus. In this perspective we seek to distil how many of deep learning’s problem can be seen as different symptoms of the same underlying problem: shortcut learning. Shortcuts are decision rules that perform well on standard benchmarks but fail to transfer to more challenging testing conditions, such as real-world scenarios. Related issues are known in Comparative Psychology, Education and Linguistics, suggesting that shortcut learning may be a common characteristic of learning systems, biological and artiﬁcial alike. Based on these observations, we develop a set of recommendations for model interpretation and benchmarking, highlighting recent advances in machine learning to improve robustness and transferability from the lab to real-world applications.},
	language = {en},
	number = {11},
	journal = {Nature Machine Intelligence},
	author = {Geirhos, Robert and Jacobsen, Jörn-Henrik and Michaelis, Claudio and Zemel, Richard and Brendel, Wieland and Bethge, Matthias and Wichmann, Felix A.},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Neurons and Cognition},
	pages = {665--673},
}

@article{madan_when_2022,
	title = {When and how convolutional neural networks generalize to out-of-distribution category–viewpoint combinations},
	volume = {4},
	issn = {2522-5839},
	doi = {10.1038/s42256-021-00437-5},
	language = {en},
	number = {2},
	journal = {Nature Machine Intelligence},
	author = {Madan, Spandan and Henry, Timothy and Dozier, Jamell and Ho, Helen and Bhandari, Nishchal and Sasaki, Tomotake and Durand, Frédo and Pfister, Hanspeter and Boix, Xavier},
	year = {2022},
	pages = {146--153},
}

@article{madan_what_2022,
	title = {What makes domain generalization hard?},
	abstract = {While several methodologies have been proposed for the daunting task of domain generalization, understanding what makes this task challenging has received little attention. Here we present SemanticDG (Semantic Domain Generalization): a benchmark with 15 photo-realistic domains with the same geometry, scene layout and camera parameters as the popular 3D ScanNet dataset, but with controlled domain shifts in lighting, materials, and viewpoints. Using this benchmark, we investigate the impact of each of these semantic shifts on generalization independently. Visual recognition models easily generalize to novel lighting, but struggle with distribution shifts in materials and viewpoints. Inspired by human vision, we hypothesize that scene context can serve as a bridge to help models generalize across material and viewpoint domain shifts and propose a context-aware vision transformer along with a contrastive loss over material and viewpoint changes to address these domain shifts. Our approach (dubbed as CDCNet) outperforms existing domain generalization methods by over an 18\% margin. As a critical benchmark, we also conduct psychophysics experiments and ﬁnd that humans generalize equally well across lighting, materials and viewpoints. The benchmark and computational model introduced here help understand the challenges associated with generalization across domains and provide initial steps towards extrapolation to semantic distribution shifts. We include all data and source code in the supplement, and will make it publicly available upon publication.},
	language = {en},
	journal = {arXiv preprint arXiv:2206.07802},
	author = {Madan, Spandan and You, Li and Zhang, Mengmi and Pfister, Hanspeter and Kreiman, Gabriel},
	year = {2022},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Graphics},
}

@article{wang_causal_2022,
	title = {Causal balancing for domain generalization},
	abstract = {While machine learning models rapidly advance the state-of-the-art on various real-world tasks, out-of-domain (OOD) generalization remains a challenging problem given the vulnerability of these models to spurious correlations. While current domain generalization methods usually focus on enforcing certain invariance properties across different domains by new loss function designs, we propose a balanced mini-batch sampling strategy to reduce the domain-speciﬁc spurious correlations in the observed training distributions. More speciﬁcally, we propose a two-phased method that 1) identiﬁes the source of spurious correlations, and 2) builds balanced mini-batches free from spurious correlations by matching on the identiﬁed source. We provide an identiﬁability guarantee of the source of spuriousness and show that our proposed approach provably samples from a balanced, spurious-free distribution over all training environments. Experiments are conducted on three computer vision datasets with documented spurious correlations, demonstrating empirically that our balanced mini-batch sampling strategy improves the performance of four different established domain generalization model baselines compared to the random mini-batch sampling strategy.},
	language = {en},
	journal = {arXiv preprint arXiv:2206.05263},
	author = {Wang, Xinyi and Saxon, Michael and Li, Jiachen and Zhang, Hongyang and Zhang, Kun and Wang, William Yang},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{galstyan_failure_2022,
	title = {Failure modes of domain generalization algorithms},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Galstyan, Tigran and Harutyunyan, Hrayr and Khachatrian, Hrant and Steeg, Greg Ver and Galstyan, Aram},
	year = {2022},
	pages = {19077--19086},
}

@inproceedings{sun_deep_2016,
	title = {Deep coral: {Correlation} alignment for deep domain adaptation},
	booktitle = {European conference on computer vision},
	author = {Sun, Baochen and Saenko, Kate},
	year = {2016},
	pages = {443--450},
}

@article{liu_category-stitch_2022,
	title = {Category-stitch learning for union domain generalization},
	issn = {1551-6857, 1551-6865},
	doi = {10.1145/3524136},
	abstract = {Domain generalization aims to generalize the network trained on multiple domains to unknown but related domains. Under the assumption that diferent domains share the same classes, previous works can build relationships across domains. However, in realistic scenarios, the change of domains is always followed by the change of categories, which raises a diiculty for collecting suicient aligned categories across domains. Bearing this in mind, this paper introduces union domain generalization as a new domain generalization scenario, in which the label space varies across domains, and the categories in unknown domains belong to the union of all given domain categories. The absence of categories in given domains is the main obstacle to aligning diferent domain distributions and obtaining domain-invariant information. To address this problem, we propose category-stitch learning (CSL), which aims to jointly learn the domain-invariant information and complete missing categories in all domains through an improved variational autoencoder and generators. The domain-invariant information extraction and sample generation cross-promote each other to better generalizability. Additionally, we decouple category and domain information and propose explicitly regularizing the semantic information by the classiication loss with transferred samples. Thus our method can breakthrough the category limit and generate samples of missing categories in each domain. Extensive experiments and visualizations are conducted on MNIST, VLCS, PACS, Oice-Home, and DomainNet datasets to demonstrate the efectiveness of our proposed method. CCS Concepts: · Computing methodologies → Transfer learning.},
	language = {en},
	journal = {ACM Transactions on Multimedia Computing, Communications, and Applications},
	author = {Liu, Yajing and Xiong, Zhiwei and Li, Ya and Lu, Yuning and Tian, Xinmei and Zha, Zheng-Jun},
	year = {2022},
}

@inproceedings{huang_two_2022,
	title = {The two dimensions of worst-case training and their integrated effect for out-of-domain generalization},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Huang, Zeyi and Wang, Haohan and Huang, Dong and Lee, Yong Jae and Xing, Eric P.},
	year = {2022},
	pages = {9631--9641},
}

@inproceedings{garg_leveraging_2022,
	title = {Leveraging unlabeled data to predict out-of-distribution performance},
	abstract = {Real-world machine learning deployments are characterized by mismatches between the source (training) and target (test) distributions that may cause performance drops. In this work, we investigate methods for predicting the target domain accuracy using only labeled source data and unlabeled target data. We propose Average Thresholded Conﬁdence (ATC), a practical method that learns a threshold on the model’s conﬁdence, predicting accuracy as the fraction of unlabeled examples for which model conﬁdence exceeds that threshold. ATC outperforms previous methods across several model architectures, types of distribution shifts (e.g., due to synthetic corruptions, dataset reproduction, or novel subpopulations), and datasets (WILDS, ImageNet, BREEDS, CIFAR, and MNIST). In our experiments, ATC estimates target performance 2–4ˆ more accurately than prior methods. We also explore the theoretical foundations of the problem, proving that, in general, identifying the accuracy is just as hard as identifying the optimal predictor and thus, the efﬁcacy of any method rests upon (perhaps unstated) assumptions on the nature of the shift. Finally, analyzing our method on some toy distributions, we provide insights concerning when it works.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Garg, Saurabh and Balakrishnan, Sivaraman and Lipton, Zachary C. and Neyshabur, Behnam and Sedghi, Hanie},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{federici_information-theoretic_2021,
	title = {An information-theoretic approach to distribution shifts},
	abstract = {Safely deploying machine learning models to the real world is often a challenging process. Models trained with data obtained from a speciﬁc geographic location tend to fail when queried with data obtained elsewhere, agents trained in a simulation can struggle to adapt when deployed in the real world or novel environments, and neural networks that are ﬁt to a subset of the population might carry some selection bias into their decision process. In this work, we describe the problem of data shift from a novel information-theoretic perspective by (i) identifying and describing the different sources of error, (ii) comparing some of the most promising objectives explored in the recent domain generalization and fair classiﬁcation literature. From our theoretical analysis and empirical evaluation, we conclude that the model selection procedure needs to be guided by careful considerations regarding the observed data, the factors used for correction, and the structure of the data-generating process.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Federici, Marco and Tomioka, Ryota and Forré, Patrick},
	year = {2021},
	pages = {17628--17641},
}

@inproceedings{ethayarajh_understanding_2022,
	title = {Understanding dataset difficulty with \${\textbackslash}mathcal\{v\}\$-usable information},
	abstract = {Estimating the diffi
culty of a dataset typically involves comparing state-of-the-art models to humans; the bigger the performance gap, the harder the dataset is said to be. However, this comparison provides little understanding of how difﬁcult each instance in a given distribution is, or what attributes make the dataset difﬁcult for a given model. To address these questions, we frame dataset difﬁculty—w.r.t. a model V—as the lack of V-usable information (Xu et al., 2019), where a lower value indicates a more difﬁcult dataset for V. We further introduce pointwise V-information (PVI) for measuring the difﬁculty of individual instances w.r.t. a given distribution. While standard evaluation metrics typically only compare different models for the same dataset, V-usable information and PVI also permit the converse: for a given model V, we can compare different datasets, as well as different instances/slices of the same dataset. Furthermore, our framework allows for the interpretability of different input attributes via transformations of the input, which we use to discover annotation artefacts in widely-used NLP benchmarks.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Ethayarajh, Kawin and Choi, Yejin and Swayamdipta, Swabha},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{jacobsen_excessive_2019,
	title = {Excessive invariance causes adversarial vulnerability},
	abstract = {Despite their impressive performance, deep neural networks exhibit striking failures on out-of-distribution inputs. One core idea of adversarial example research is to reveal neural network errors under such distribution shifts. We decompose these errors into two complementary sources: sensitivity and invariance. We show deep networks are not only too sensitive to task-irrelevant changes of their input, as is well-known from -adversarial examples, but are also too invariant to a wide range of task-relevant changes, thus making vast regions in input space vulnerable to adversarial attacks. We show such excessive invariance occurs across various tasks and architecture types. On MNIST and ImageNet one can manipulate the class-speciﬁc content of almost any image without changing the hidden activations. We identify an insufﬁciency of the standard cross-entropy loss as a reason for these failures. Further, we extend this objective based on an informationtheoretic analysis so it encourages the model to consider all task-dependent features in its decision. This provides the ﬁrst approach tailored explicitly to overcome excessive invariance and resulting vulnerabilities.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Jacobsen, Jörn-Henrik and Behrmann, Jens and Zemel, Richard and Bethge, Matthias},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{hu_near-optimal_2021,
	title = {Near-optimal representation learning for linear bandits and linear {RL}},
	abstract = {This paper studies representation learning for multi-task linear bandits and multi-task episodic RL with linear value function approximation. We ﬁrst consider the setting where we play M linear bandits with dimension d concurrently, and these bandits share a common k-dimensional linear representation so that k d and k M . We propose a sample-efﬁcient algorithm, MTLROtoFaUchLi,ewvehiOc˜h(Mlev√erdakgTes +thed√shkaMredTr)epreregsreent,tawtiiothn Tniﬁbceainntglythiemnpuromvbees ruopfotnotthale sbtaespesl.inOeuOr˜r(eMgrdet√sTig)achieved by solving each task independently. We further develop a lower bound that shows our regret is near-optimal when d {\textgreater} M . Furthermore, we extend the algorithm and analysis to multi-task episodic RL with linear value function approximation under low inherent Bellman error (Zanette et al., 2020a). To the best of our knowledge, this is the ﬁrst theoretical result that characterize the beneﬁts of multi-task representation learning for exploration in RL with function approximation.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Hu, Jiachen and Chen, Xiaoyu and Jin, Chi and Li, Lihong and Wang, Liwei},
	year = {2021},
	pages = {4349--4358},
}

@inproceedings{yang_reinforcement_2020,
	title = {Reinforcement learning in feature space: {Matrix} bandit, kernels, and regret bound},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Yang, Lin F and Wang, Mengdi},
	year = {2020},
	pages = {10746--10756},
}

@inproceedings{yang_impact_2021,
	title = {Impact of representation learning in linear bandits},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Yang, Jiaqi and Hu, Wei and Lee, Jason D. and Du, Simon S.},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{wang_benign_2021,
	title = {Benign overfitting in multiclass classification: {All} roads lead to interpolation},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wang, Ke and Muthukumar, Vidya and Thrampoulidis, Christos},
	year = {2021},
	pages = {24164--24179},
}

@article{fan_minedojo_2022,
	title = {Minedojo: {Building} open-ended embodied agents with internet-scale knowledge},
	shorttitle = {Minedojo},
	abstract = {Autonomous agents have made great strides in specialist domains like Atari games and Go. However, they typically learn tabula rasa in isolated environments with limited and manually conceived objectives, thus failing to generalize across a wide spectrum of tasks and capabilities. Inspired by how humans continually learn and adapt in the open world, we advocate a trinity of ingredients for building generalist agents: 1) an environment that supports a multitude of tasks and goals, 2) a large-scale database of multimodal knowledge, and 3) a ﬂexible and scalable agent architecture. We introduce MINEDOJO, a new framework built on the popular Minecraft game that features a simulation suite with thousands of diverse open-ended tasks and an internet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and forum discussions. Using MINEDOJO’s data, we propose a novel agent learning algorithm that leverages large pre-trained video-language models as a learned reward function. Our agent is able to solve a variety of open-ended tasks speciﬁed in free-form language without any manually designed dense shaping reward. We open-source the simulation suite and knowledge bases (https://minedojo.org) to promote research towards the goal of generally capable embodied agents.},
	language = {en},
	journal = {arXiv preprint arXiv:2206.08853},
	author = {Fan, Linxi and Wang, Guanzhi and Jiang, Yunfan and Mandlekar, Ajay and Yang, Yuncong and Zhu, Haoyi and Tang, Andrew and Huang, De-An and Zhu, Yuke and Anandkumar, Anima},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
}

@inproceedings{cai_theory_2021-1,
	title = {A theory of label propagation for subpopulation shift},
	abstract = {One of the central problems in machine learning is domain adaptation. Unlike past theoretical work, we consider a new model for subpopulation shift in the input or representation space. In this work, we propose a provably effective framework for domain adaptation based on label propagation. In our analysis, we use a simple but realistic expansion assumption, proposed in Wei et al. (2021). Using a teacher classiﬁer trained on the source domain, our algorithm not only propagates to the target domain but also improves upon the teacher. By leveraging existing generalization bounds, we also obtain end-to-end ﬁnite-sample guarantees on the entire algorithm. In addition, we extend our theoretical framework to a more general setting of source-to-target transfer based on a third unlabeled dataset, which can be easily applied in various learning scenarios. Inspired by our theory, we adapt consistency-based semi-supervised learning methods to domain adaptation settings and gain signiﬁcant improvements.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Cai, Tianle and Gao, Ruiqi and Lee, Jason D and Lei, Qi},
	year = {2021},
	pages = {1170--1182},
}

@inproceedings{fort_exploring_2021,
	title = {Exploring the limits of out-of-distribution detection},
	volume = {34},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Fort, Stanislav and Ren, Jie and Lakshminarayanan, Balaji},
	year = {2021},
	pages = {7068--7081},
}

@article{dar_farewell_2021,
	title = {A farewell to the bias-variance tradeoff? {An} overview of the theory of overparameterized machine learning},
	shorttitle = {A farewell to the bias-variance tradeoff?},
	abstract = {The rapid recent progress in machine learning (ML) has raised a number of scientiﬁc questions that challenge the longstanding dogma of the ﬁeld. One of the most important riddles is the good empirical generalization of overparameterized models. Overparameterized models are excessively complex with respect to the size of the training dataset, which results in them perfectly ﬁtting (i.e., interpolating) the training data, which is usually noisy. Such interpolation of noisy data is traditionally associated with detrimental overﬁtting, and yet a wide range of interpolating models – from simple linear models to deep neural networks – have recently been observed to generalize extremely well on fresh test data. Indeed, the recently discovered double descent phenomenon has revealed that highly overparameterized models often improve over the best underparameterized model in test performance.},
	language = {en},
	journal = {arXiv preprint arXiv:2109.02355},
	author = {Dar, Yehuda and Muthukumar, Vidya and Baraniuk, Richard G.},
	year = {2021},
arXiv:2109.02355 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{chen_isolating_2018,
	title = {Isolating sources of disentanglement in {VAEs}},
	abstract = {We decompose the evidence lower bound to show the existence of a term measuring the total correlation between latent variables. We use this to motivate the β-TCVAE (Total Correlation Variational Autoencoder) algorithm, a reﬁnement and plug-in replacement of the β-VAE for learning disentangled representations, requiring no additional hyperparameters during training. We further propose a principled classiﬁer-free measure of disentanglement called the mutual information gap (MIG). We perform extensive quantitative and qualitative experiments, in both restricted and non-restricted settings, and show a strong relation between total correlation and disentanglement, when the model is trained using our framework.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chen, Ricky T Q and Li, Xuechen and Grosse, Roger and Duvenaud, David},
	year = {2018},
	pages = {11},
}

@inproceedings{do_theory_2020,
	title = {Theory and evaluation metrics for learning disentangled representations},
	abstract = {We make two theoretical contributions to disentanglement learning by (a) deﬁning precise semantics of disentangled representations, and (b) establishing robust metrics for evaluation. First, we characterize the concept “disentangled representations” used in supervised and unsupervised methods along three dimensions–informativeness, separability and interpretability–which can be expressed and quantiﬁed explicitly using information-theoretic constructs. This helps explain the behaviors of several well-known disentanglement learning models. We then propose robust metrics for measuring informativeness, separability, and interpretability. Through a comprehensive suite of experiments, we show that our metrics correctly characterize the representations learned by different methods and are consistent with qualitative (visual) results. Thus, the metrics allow disentanglement learning methods to be compared on a fair ground. We also empirically uncovered new interesting properties of VAE-based methods and interpreted them with our formulation. These ﬁndings are promising and hopefully will encourage the design of more theoretically driven models for learning disentangled representations1.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Do, Kien and Tran, Truyen},
	year = {2020},
arXiv:1908.09961 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{anselmi_invariance_2016,
	title = {On invariance and selectivity in representation learning},
	volume = {5},
	number = {2},
	journal = {Information and Inference: A Journal of the IMA},
	author = {Anselmi, Fabio and Rosasco, Lorenzo and Poggio, Tomaso},
	year = {2016},
	pages = {134--158},
}

@article{eppe_intelligent_2022,
	title = {Intelligent problem-solving as integrated hierarchical reinforcement learning},
	volume = {4},
	issn = {2522-5839},
	doi = {10.1038/s42256-021-00433-9},
	language = {en},
	number = {1},
	journal = {Nature Machine Intelligence},
	author = {Eppe, Manfred and Gumbsch, Christian and Kerzel, Matthias and Nguyen, Phuong D. H. and Butz, Martin V. and Wermter, Stefan},
	year = {2022},
	pages = {11--20},
}

@inproceedings{nam_reducing_2021,
	title = {Reducing domain gap by reducing style bias},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Nam, Hyeonseob and Lee, HyunJae and Park, Jongchan and Yoon, Wonjun and Yoo, Donggeun},
	year = {2021},
	pages = {8690--8699},
}

@inproceedings{schneider_improving_2020,
	title = {Improving robustness against common corruptions by covariate shift adaptation},
	abstract = {Today’s state-of-the-art machine vision models are vulnerable to image corruptions like blurring or compression artefacts, limiting their performance in many realworld applications. We here argue that popular benchmarks to measure model robustness against common corruptions (like ImageNet-C) underestimate model robustness in many (but not all) application scenarios. The key insight is that in many scenarios, multiple unlabeled examples of the corruptions are available and can be used for unsupervised online adaptation. Replacing the activation statistics estimated by batch normalization on the training set with the statistics of the corrupted images consistently improves the robustness across 25 different popular computer vision models. Using the corrected statistics, ResNet-50 reaches 62.2\% mCE on ImageNet-C compared to 76.7\% without adaptation. With the more robust DeepAugment+AugMix model, we improve the state of the art achieved by a ResNet50 model up to date from 53.6\% mCE to 45.4\% mCE. Even adapting to a single sample improves robustness for the ResNet-50 and AugMix models, and 32 samples are sufﬁcient to improve the current state of the art for a ResNet50 architecture. We argue that results with adapted statistics should be included whenever reporting scores in corruption benchmarks and other out-of-distribution generalization settings.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Schneider, Steffen and Bringmann, Oliver and Rusak, Evgenia and Brendel, Wieland and Eck, Luisa and Bethge, Matthias},
	year = {2020},
	pages = {11539--11551},
}

@inproceedings{oren_distributionally_2019,
	title = {Distributionally robust language modeling},
	abstract = {Language models are generally trained on data spanning a wide range of topics (e.g., news, reviews, ﬁction), but they might be applied to an a priori unknown target distribution (e.g., restaurant reviews). In this paper, we ﬁrst show that training on text outside the test distribution can degrade test performance when using standard maximum likelihood (MLE) training. To remedy this without the knowledge of the test distribution, we propose an approach which trains a model that performs well over a wide range of potential test distributions. In particular, we derive a new distributionally robust optimization (DRO) procedure which minimizes the loss of the model over the worst-case mixture of topics with sufﬁcient overlap with the training distribution. Our approach, called topic conditional value at risk (topic CVaR), obtains a 5.5 point perplexity reduction over MLE when the language models are trained on a mixture of Yelp reviews and news and tested only on reviews.},
	language = {en},
	booktitle = {{EMNLP}},
	author = {Oren, Yonatan and Sagawa, Shiori and Hashimoto, Tatsunori B. and Liang, Percy},
	year = {2019},
arXiv:1909.02060 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
	pages = {4226--4236},
}

@article{duchi_distributionally_2019,
	title = {Distributionally robust losses against mixture covariate shifts},
	abstract = {Modern large-scale datasets are often collected over heterogeneous subpopulations, such as multiple demographic groups or multiple text corpora. Minimizing average loss over such datasets fails to guarantee uniformly low losses across all subpopulations. We propose a convex procedure that controls the worst-case performance over all subpopulations of a certain size. Our procedure comes with ﬁnite-sample optimality guarantees on the worst oﬀ subpopulation, and converges at the standard nonparametric rate. Empirically, we observe on lexical similarity and recidivism prediction tasks that our worst-case procedure learns models that do well against unseen subpopulations.},
	language = {en},
	author = {Duchi, John C and Hashimoto, Tatsunori and Namkoong, Hongseok},
	year = {2019},
}

@article{ben-tal_robust_2013,
	title = {Robust solutions of optimization problems affected by uncertain probabilities},
	volume = {59},
	issn = {0025-1909, 1526-5501},
	doi = {10.1287/mnsc.1120.1641},
	language = {en},
	number = {2},
	journal = {Management Science},
	author = {Ben-Tal, Aharon and den Hertog, Dick and De Waegenaere, Anja and Melenberg, Bertrand and Rennen, Gijs},
	year = {2013},
	pages = {341--357},
}

@article{duchi_statistics_2016,
	title = {Statistics of robust optimization: {A} generalized empirical likelihood approach},
	shorttitle = {Statistics of robust optimization},
	abstract = {We study statistical inference and distributionally robust solution methods for stochastic optimization problems, focusing on conﬁdence intervals for optimal values and solutions that achieve exact coverage asymptotically. We develop a generalized empirical likelihood framework—based on distributional uncertainty sets constructed from nonparametric f -divergence balls—for Hadamard diﬀerentiable functionals, and in particular, stochastic optimization problems. As consequences of this theory, we provide a principled method for choosing the size of distributional uncertainty regions to provide one- and two-sided conﬁdence intervals that achieve exact coverage. We also give an asymptotic expansion for our distributionally robust formulation, showing how robustiﬁcation regularizes problems by their variance. Finally, we show that optimizers of the distributionally robust formulations we study enjoy (essentially) the same consistency properties as those in classical sample average approximations. Our general approach applies to quickly mixing stationary sequences, including geometrically ergodic Harris recurrent Markov chains.},
	language = {en},
	journal = {arXiv preprint arXiv:1610.03425},
	author = {Duchi, John and Glynn, Peter and Namkoong, Hongseok},
	year = {2016},
arXiv:1610.03425 [stat]},
	keywords = {Statistics - Machine Learning},
}

@incollection{quinonero-candela_covariate_2008,
	title = {Covariate shift by kernel mean matching},
	isbn = {978-0-262-17005-5},
	language = {en},
	booktitle = {Dataset {Shift} in {Machine} {Learning}},
	author = {Gretton, Arthur and Smola, Alex and Huang, Jiayuan and Schmittfull, Marcel and Borgwardt, Karsten and Schölkopf, Bernhard},
	editor = {Quiñonero-Candela, Joaquin and Sugiyama, Masashi and Schwaighofer, Anton and Lawrence, Neil D.},
	year = {2008},
	doi = {10.7551/mitpress/9780262170055.003.0008},
	pages = {131--160},
}

@inproceedings{gong_domain_2016,
	title = {Domain adaptation with conditional transferable components},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Gong, Mingming and Zhang, Kun and Liu, Tongliang and Tao, Dacheng and Glymour, Clark and Scholkopf, Bernhard},
	year = {2016},
	pages = {2839--2848},
}

@article{fei_towards_2022,
	title = {Towards artificial general intelligence via a multimodal foundation model},
	volume = {13},
	issn = {2041-1723},
	doi = {10.1038/s41467-022-30761-2},
	abstract = {The fundamental goal of artificial intelligence (AI) is to mimic the core cognitive activities of human. Despite tremendous success in the AI research, most of existing methods have only single-cognitive ability. To overcome this limitation and take a solid step towards artificial general intelligence (AGI), we develop a foundation model pre-trained with huge multimodal data, which can be quickly adapted for various downstream cognitive tasks. To achieve this goal, we propose to pre-train our foundation model by self-supervised learning with weak semantic correlation data crawled from the Internet and show that promising results can be obtained on a wide range of downstream tasks. Particularly, with the developed model-interpretability tools, we demonstrate that strong imagination ability is now possessed by our foundation model. We believe that our work makes a transformative stride towards AGI, from our common practice of “weak or narrow AI” to that of “strong or generalized AI”.},
	language = {en},
	number = {1},
	journal = {Nature Communications},
	author = {Fei, Nanyi and Lu, Zhiwu and Gao, Yizhao and Yang, Guoxing and Huo, Yuqi and Wen, Jingyuan and Lu, Haoyu and Song, Ruihua and Gao, Xin and Xiang, Tao and Sun, Hao and Wen, Ji-Rong},
	year = {2022},
	pages = {3094},
}

@article{song_learning_2022,
	title = {Learning from noisy labels with deep neural networks: {A} survey},
	issn = {2162-2388},
	shorttitle = {Learning from noisy labels with deep neural networks},
	doi = {10.1109/TNNLS.2022.3152527},
	abstract = {Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 62 state-of-the-art robust training methods, all of which are categorized into five groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we perform an in-depth analysis of noise rate estimation and summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies.},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Song, Hwanjun and Kim, Minseok and Park, Dongmin and Shin, Yooju and Lee, Jae-Gil},
	year = {2022},
	keywords = {Data models, deep learning, Training data, Deep learning, Training, Task analysis, Noise measurement, Classification, label noise, noisy label, robust deep learning, robust optimization, survey., Taxonomy},
	pages = {1--19},
}

@article{kolter_dynamic_2007,
	title = {Dynamic weighted majority: {An} ensemble method for drifting concepts},
	volume = {8},
	journal = {The Journal of Machine Learning Research},
	author = {Kolter, J. Zico and Maloof, Marcus A.},
	year = {2007},
	pages = {2755--2790},
}

@article{brzezinski_reacting_2014,
	title = {Reacting to different types of concept drift: {The} accuracy updated ensemble algorithm},
	volume = {25},
	issn = {2162-2388},
	shorttitle = {Reacting to different types of concept drift},
	doi = {10.1109/TNNLS.2013.2251352},
	abstract = {Data stream mining has been receiving increased attention due to its presence in a wide range of applications, such as sensor networks, banking, and telecommunication. One of the most important challenges in learning from data streams is reacting to concept drift, i.e., unforeseen changes of the stream's underlying data distribution. Several classification algorithms that cope with concept drift have been put forward, however, most of them specialize in one type of change. In this paper, we propose a new data stream classifier, called the Accuracy Updated Ensemble (AUE2), which aims at reacting equally well to different types of drift. AUE2 combines accuracy-based weighting mechanisms known from block-based ensembles with the incremental nature of Hoeffding Trees. The proposed algorithm is experimentally compared with 11 state-of-the-art stream methods, including single classifiers, block-based and online ensembles, and hybrid approaches in different drift scenarios. Out of all the compared algorithms, AUE2 provided best average classification accuracy while proving to be less memory consuming than other ensemble approaches. Experimental results show that AUE2 can be considered suitable for scenarios, involving many types of drift as well as static environments.},
	number = {1},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Brzezinski, Dariusz and Stefanowski, Jerzy},
	year = {2014},
	keywords = {Concept drift, data stream mining, ensemble classifier, nonstationary environments},
	pages = {81--94},
}

@article{elwell_incremental_2011,
	title = {Incremental learning of concept drift in nonstationary environments},
	volume = {22},
	issn = {1941-0093},
	doi = {10.1109/TNN.2011.2160459},
	abstract = {We introduce an ensemble of classifiers-based approach for incremental learning of concept drift, characterized by nonstationary environments (NSEs), where the underlying data distributions change over time. The proposed algorithm, named Learn++.NSE, learns from consecutive batches of data without making any assumptions on the nature or rate of drift; it can learn from such environments that experience constant or variable rate of drift, addition or deletion of concept classes, as well as cyclical drift. The algorithm learns incrementally, as other members of the Learn++ family of algorithms, that is, without requiring access to previously seen data. Learn++.NSE trains one new classifier for each batch of data it receives, and combines these classifiers using a dynamically weighted majority voting. The novelty of the approach is in determining the voting weights, based on each classifier's time-adjusted accuracy on current and past environments. This approach allows the algorithm to recognize, and act accordingly, to the changes in underlying data distributions, as well as to a possible reoccurrence of an earlier distribution. We evaluate the algorithm on several synthetic datasets designed to simulate a variety of nonstationary environments, as well as a real-world weather prediction dataset. Comparisons with several other approaches are also included. Results indicate that Learn++.NSE can track the changing environments very closely, regardless of the type of concept drift. To allow future use, comparison and benchmarking by interested researchers, we also release our data used in this paper.},
	number = {10},
	journal = {IEEE Transactions on Neural Networks},
	author = {Elwell, Ryan and Polikar, Robi},
	year = {2011},
	keywords = {Machine learning, Training, Concept drift, Algorithm design and analysis, Heuristic algorithms, Humans, incremental learning, Knowledge based systems, learning in nonstationary environments, multiple classifier systems, Tuning},
	pages = {1517--1531},
}

@article{sun_concept_2018,
	title = {Concept drift adaptation by exploiting historical knowledge},
	volume = {29},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2017.2775225},
	abstract = {Incremental learning with concept drift has often been tackled by ensemble methods, where models built in the past can be retrained to attain new models for the current data. Two design questions need to be addressed in developing ensemble methods for incremental learning with concept drift, i.e., which historical (i.e., previously trained) models should be preserved and how to utilize them. A novel ensemble learning method, namely, Diversity and Transfer-based Ensemble Learning (D℡), is proposed in this paper. Given newly arrived data, D℡ uses each preserved historical model as an initial model and further trains it with the new data via transfer learning. Furthermore, D℡ preserves a diverse set of historical models, rather than a set of historical models that are merely accurate in terms of classification accuracy. Empirical studies on 15 synthetic data streams and 5 real-world data streams (all with concept drifts) demonstrate that D℡ can handle concept drift more effectively than 4 other state-of-the-art methods.},
	number = {10},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Sun, Yu and Tang, Ke and Zhu, Zexuan and Yao, Xin},
	year = {2018},
	keywords = {Adaptation models, Data models, Training data, Training, Learning systems, transfer learning, Computational modeling, Concept drift, data stream mining, incremental learning, ensemble learning},
	pages = {4822--4832},
}

@inproceedings{zhang_rich_2022,
	title = {Rich feature construction for the optimization-generalization dilemma},
	abstract = {There often is a dilemma between ease of optimization and robust out-of-distribution (OoD) generalization. For instance, many OoD methods rely on penalty terms whose optimization is challenging. They are either too strong to optimize reliably or too weak to achieve their goals. We propose to initialize the networks with a rich representation containing a palette of potentially useful features, ready to be used by even simple models. On the one hand, a rich representation provides a good initialization for the optimizer. On the other hand, it also provides an inductive bias that helps OoD generalization. Such a representation is constructed with the Rich Feature Construction (RFC) algorithm, also called the Bonsai algorithm,1 which consists of a succession of training episodes. During discovery episodes, we craft a multi-objective optimization criterion and its associated datasets in a manner that prevents the network from using the features constructed in the previous iterations. During synthesis episodes, we use knowledge distillation to force the network to simultaneously represent all the previously discovered features.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhang, Jianyu and Lopez-Paz, David and Bottou, Léon},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {26397--26411},
}

@inproceedings{kumar_understanding_2020,
	title = {Understanding self-training for gradual domain adaptation},
	abstract = {Machine learning systems must adapt to data distributions that evolve over time, in applications ranging from sensor networks and self-driving car perception modules to brain-machine interfaces. Traditional domain adaptation is only guaranteed to work when the distribution shift is small; empirical methods combine several heuristics for larger shifts but can be dataset speciﬁc. To adapt to larger shifts we consider gradual domain adaptation, where the goal is to adapt an initial classiﬁer trained on a source domain given only unlabeled data that shifts gradually in distribution towards a target domain. We prove the ﬁrst non-vacuous upper bound on the error of self-training with gradual shifts, under settings where directly adapting to the target domain can result in unbounded error. The theoretical analysis leads to algorithmic insights, highlighting that regularization and label sharpening are essential even when we have inﬁnite data. Leveraging the gradual shift structure leads to higher accuracies on a rotating MNIST dataset, a forest Cover Type dataset, and a realistic Portraits dataset.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Kumar, Ananya and Ma, Tengyu and Liang, Percy},
	year = {2020},
	pages = {5468--5479},
}

@inproceedings{xie_-n-out_2021,
	title = {In-n-out: {Pre}-training and self-training using auxiliary information for out-of-distribution robustness},
	shorttitle = {In-n-out},
	abstract = {Consider a prediction setting with few in-distribution labeled examples and many unlabeled examples both in- and out-of-distribution (OOD). The goal is to learn a model which performs well both in-distribution and OOD. In these settings, auxiliary information is often cheaply available for every input. How should we best leverage this auxiliary information for the prediction task? Empirically across three image and time-series datasets, and theoretically in a multi-task linear regression setting, we show that (i) using auxiliary information as input features improves in-distribution error but can hurt OOD error; but (ii) using auxiliary information as outputs of auxiliary pre-training tasks improves OOD error. To get the best of both worlds, we introduce In-N-Out, which ﬁrst trains a model with auxiliary inputs and uses it to pseudolabel all the in-distribution inputs, then pre-trains a model on OOD auxiliary outputs and ﬁne-tunes this model with the pseudolabels (self-training). We show both theoretically and empirically that In-N-Out outperforms auxiliary inputs or outputs alone on both in-distribution and OOD error.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Xie, Sang Michael and Kumar, Ananya and Jones, Robbie and Khani, Fereshte and Ma, Tengyu and Liang, Percy},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{glasgow_max-margin_2022,
	title = {Max-margin works while large margin fails: {Generalization} without uniform convergence},
	shorttitle = {Max-margin works while large margin fails},
	abstract = {A major challenge in modern machine learning is theoretically understanding the generalization properties of overparameterized models. Many existing tools rely on uniform convergence (UC), a property that, when it holds, guarantees that the test loss will be close to the training loss, uniformly over a class of candidate models. Nagarajan and Kolter (2019b) show that in certain simple linear and neural-network settings, any uniform convergence bound will be vacuous, leaving open the question of how to prove generalization in settings where UC fails. Our main contribution is proving novel generalization bounds in two such settings, one linear, and one non-linear. We study the linear classiﬁcation setting of Nagarajan and Kolter (2019b), and a quadratic ground truth function learned via a two-layer neural network in the non-linear regime. We prove a new type of margin bound showing that above a certain signal-to-noise threshold, any near-max-margin classiﬁer will achieve almost no test loss in these two settings. Our results show that near-max-margin is important: while any model that achieves at least a (1 − )-fraction of the max-margin generalizes well, a classiﬁer achieving half of the max-margin may fail terribly. We additionally strengthen the UC impossibility results of Nagarajan and Kolter (2019b), proving that one-sided UC bounds and classical margin bounds will fail on near-max-margin classiﬁers. Our analysis provides insight on why memorization can coexist with generalization: we show that in this challenging regime where generalization occurs but UC fails, near-max-margin classiﬁers simultaneously contain some generalizable components and some overﬁtting components that memorize the data. The presence of the overﬁtting components is enough to preclude UC, but the near-extremal margin guarantees that suﬃcient generalizable components are present.},
	language = {en},
	journal = {arXiv preprint arXiv:2206.07892},
	author = {Glasgow, Margalit and Wei, Colin and Wootters, Mary and Ma, Tengyu},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@article{gama_survey_2014,
	title = {A survey on concept drift adaptation},
	volume = {46},
	issn = {0360-0300, 1557-7341},
	doi = {10.1145/2523813},
	abstract = {Concept drift primarily refers to an online supervised learning scenario when the relation between the input data and the target variable changes over time. Assuming a general knowledge of supervised learning in this article, we characterize adaptive learning processes; categorize existing strategies for handling concept drift; overview the most representative, distinct, and popular techniques and algorithms; discuss evaluation methodology of adaptive algorithms; and present a set of illustrative applications. The survey covers the different facets of concept drift in an integrated way to reflect on the existing scattered state of the art. Thus, it aims at providing a comprehensive introduction to the concept drift adaptation for researchers, industry analysts, and practitioners.},
	language = {en},
	number = {4},
	journal = {ACM Computing Surveys},
	author = {Gama, João and Žliobaitė, Indrė and Bifet, Albert and Pechenizkiy, Mykola and Bouchachia, Abdelhamid},
	year = {2014},
	pages = {1--37},
}

@inproceedings{he_identity_2016,
	title = {Identity mappings in deep residual networks},
	booktitle = {European conference on computer vision},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year = {2016},
	pages = {630--645},
}

@inproceedings{yang_free_2021,
	title = {Free lunch for few-shot learning: {Distribution} calibration},
	shorttitle = {Free lunch for few-shot learning},
	abstract = {Learning from a limited number of samples is challenging since the learned model can easily become overfitted based on the biased distribution formed by only a few training examples. In this paper, we calibrate the distribution of these few-sample classes by transferring statistics from the classes with sufficient examples, then an adequate number of examples can be sampled from the calibrated distribution to expand the inputs to the classifier. We assume every dimension in the feature representation follows a Gaussian distribution so that the mean and the variance of the distribution can borrow from that of similar classes whose statistics are better estimated with an adequate number of samples. Our method can be built on top of off-the-shelf pretrained feature extractors and classification models without extra parameters. We show that a simple logistic regression classifier trained using the features sampled from our calibrated distribution can outperform the state-of-the-art accuracy on two datasets ({\textasciitilde}5\% improvement on miniImageNet compared to the next best). The visualization of these generated features demonstrates that our calibrated distribution is an accurate estimation.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Yang, Shuo and Liu, Lu and Xu, Min},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{luo_no_2021,
	title = {No fear of heterogeneity: {Classifier} calibration for federated learning with non-iid data},
	abstract = {A central challenge in training classification models in the real-world federated system is learning with non-IID data. To cope with this, most of the existing works involve enforcing regularization in local optimization or improving the model aggregation scheme at the server. Other works also share public datasets or synthesized samples to supplement the training of under-represented classes or introduce a certain level of personalization. Though effective, they lack a deep understanding of how the data heterogeneity affects each layer of a deep classification model. In this paper, we bridge this gap by performing an experimental analysis of the representations learned by different layers. Our observations are surprising: (1) there exists a greater bias in the classifier than other layers, and (2) the classification performance can be significantly improved by post-calibrating the classifier after federated training. Motivated by the above findings, we propose a novel and simple algorithm called Classifier Calibration with Virtual Representations (CCVR), which adjusts the classifier using virtual representations sampled from an approximated gaussian mixture model. Experimental results demonstrate that CCVR achieves state-of-the-art performance on popular federated learning benchmarks including CIFAR-10, CIFAR-100, and CINIC-10. We hope that our simple yet effective method can shed some light on the future research of federated learning with non-IID data.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Luo, Mi and Chen, Fei and Hu, Dapeng and Zhang, Yifan and Liang, Jian and Feng, Jiashi},
	year = {2021},
	pages = {5972--5984},
}

@inproceedings{moyer_invariant_2018,
	title = {Invariant representations without adversarial training},
	abstract = {Representations of data that are invariant to changes in speciﬁed factors are useful for a wide range of problems: removing potential biases in prediction problems, controlling the effects of covariates, and disentangling meaningful factors of variation. Unfortunately, learning representations that exhibit invariance to arbitrary nuisance factors yet remain useful for other tasks is challenging. Existing approaches cast the trade-off between task performance and invariance in an adversarial way, using an iterative minimax optimization. We show that adversarial training is unnecessary and sometimes counter-productive; we instead cast invariant representation learning as a single information-theoretic objective that can be directly optimized. We demonstrate that this approach matches or exceeds performance of state-of-the-art adversarial approaches for learning fair representations and for generative modeling with controllable transformations.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Moyer, Daniel and Gao, Shuyang and Brekelmans, Rob and Galstyan, Aram and Steeg, Greg Ver},
	year = {2018},
	pages = {9102--9111},
}

@inproceedings{xie_disturblabel_2016,
	address = {Las Vegas, NV, USA},
	title = {Disturblabel: {Regularizing} {CNN} on the loss layer},
	isbn = {978-1-4673-8851-1},
	shorttitle = {Disturblabel},
	doi = {10.1109/CVPR.2016.514},
	abstract = {During a long period of time we are combating overﬁtting in the CNN training process with model regularization, including weight decay, model averaging, data augmentation, etc. In this paper, we present DisturbLabel, an extremely simple algorithm which randomly replaces a part of labels as incorrect values in each iteration. Although it seems weird to intentionally generate incorrect training labels, we show that DisturbLabel prevents the network training from over-ﬁtting by implicitly averaging over exponentially many networks which are trained with different label sets. To the best of our knowledge, DisturbLabel serves as the ﬁrst work which adds noises on the loss layer. Meanwhile, DisturbLabel cooperates well with Dropout to provide complementary regularization functions. Experiments demonstrate competitive recognition results on several popular image recognition datasets.},
	language = {en},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Xie, Lingxi and Wang, Jingdong and Wei, Zhen and Wang, Meng and Tian, Qi},
	year = {2016},
	pages = {4753--4762},
}

@inproceedings{upchurch_deep_2017,
	address = {Honolulu, HI},
	title = {Deep feature interpolation for image content changes},
	isbn = {978-1-5386-0457-1},
	doi = {10.1109/CVPR.2017.645},
	abstract = {We propose Deep Feature Interpolation (DFI), a new datadriven baseline for automatic high-resolution image transformation. As the name suggests, DFI relies only on simple linear interpolation of deep convolutional features from pre-trained convnets. We show that despite its simplicity, DFI can perform high-level semantic transformations like “make older/younger”, “make bespectacled”, “add smile”, among others, surprisingly well—sometimes even matching or outperforming the state-of-the-art. This is particularly unexpected as DFI requires no specialized network architecture or even any deep network to be trained for these tasks. DFI therefore can be used as a new baseline to evaluate more complex algorithms and provides a practical answer to the question of which image transformation tasks are still challenging after the advent of deep learning.},
	language = {en},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Upchurch, Paul and Gardner, Jacob and Pleiss, Geoff and Pless, Robert and Snavely, Noah and Bala, Kavita and Weinberger, Kilian},
	year = {2017},
	pages = {6090--6099},
}

@inproceedings{yu_information-theoretic_2021,
	address = {Montreal, Canada},
	title = {Information-theoretic methods in deep neural networks: {Recent} advances and emerging opportunities},
	isbn = {978-0-9992411-9-6},
	shorttitle = {Information-theoretic methods in deep neural networks},
	doi = {10.24963/ijcai.2021/633},
	abstract = {We present a review on the recent advances and emerging opportunities around the theme of analyzing deep neural networks (DNNs) with information-theoretic methods. We ﬁrst discuss popular information-theoretic quantities and their estimators. We then introduce recent developments on information-theoretic learning principles (e.g., loss functions, regularizers and objectives) and their parameterization with DNNs. We ﬁnally brieﬂy review current usages of informationtheoretic concepts in a few modern machine learning problems and list a few emerging opportunities.},
	language = {en},
	booktitle = {Proceedings of the {Thirtieth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Yu, Shujian and Sanchez Giraldo, Luis and Principe, Jose},
	year = {2021},
	pages = {4669--4678},
}

@article{gastaldi_shake-shake_2017,
	title = {Shake-shake regularization},
	abstract = {The method introduced in this paper aims at helping deep learning practitioners faced with an overﬁt problem. The idea is to replace, in a multi-branch network, the standard summation of parallel branches with a stochastic afﬁne combination. Applied to 3-branch residual networks, shake-shake regularization improves on the best single shot published results on CIFAR-10 and CIFAR100 by reaching test errors of 2.86\% and 15.85\%. Experiments on architectures without skip connections or Batch Normalization show encouraging results and open the door to a large set of applications. Code is available at https://github.com/xgastaldi/shake-shake.},
	language = {en},
	journal = {arXiv preprint arXiv:1705.07485},
	author = {Gastaldi, Xavier},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{wang_implicit_2019,
	title = {Implicit semantic data augmentation for deep networks},
	abstract = {In this paper, we propose a novel implicit semantic data augmentation (ISDA) approach to complement traditional augmentation techniques like ﬂipping, translation or rotation. Our work is motivated by the intriguing property that deep networks are surprisingly good at linearizing features, such that certain directions in the deep feature space correspond to meaningful semantic transformations, e.g., adding sunglasses or changing backgrounds. As a consequence, translating training samples along many semantic directions in the feature space can effectively augment the dataset to improve generalization. To implement this idea effectively and efﬁciently, we ﬁrst perform an online estimate of the covariance matrix of deep features for each class, which captures the intra-class semantic variations. Then random vectors are drawn from a zero-mean normal distribution with the estimated covariance to augment the training data in that class. Importantly, instead of augmenting the samples explicitly, we can directly minimize an upper bound of the expected cross-entropy (CE) loss on the augmented training set, leading to a highly efﬁcient algorithm. In fact, we show that the proposed ISDA amounts to minimizing a novel robust CE loss, which adds negligible extra computational cost to a normal training procedure. Although being simple, ISDA consistently improves the generalization performance of popular deep models (ResNets and DenseNets) on a variety of datasets, e.g., CIFAR-10, CIFAR-100 and ImageNet. Code for reproducing our results is available at https://github.com/blackfeatherwang/ISDA-for-Deep-Networks.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wang, Yulin and Pan, Xuran and Song, Shiji and Zhang, Hong and Huang, Gao and Wu, Cheng},
	year = {2019},
	pages = {12614--12623},
}

@inproceedings{ainsworth_git_2023,
	title = {Git re-basin: {Merging} models modulo permutation symmetries},
	shorttitle = {Git re-basin},
	abstract = {The success of deep learning is thanks to our ability to solve certain massive non-convex optimization problems with relative ease. Despite non-convex optimization being NP-hard, simple algorithms – often variants of stochastic gradient descent – exhibit surprising effectiveness in ﬁtting large neural networks in practice. We argue that neural network loss landscapes contain (nearly) a single basin, after accounting for all possible permutation symmetries of hidden units. We introduce three algorithms to permute the units of one model to bring them into alignment with units of a reference model. This transformation produces a functionally equivalent set of weights that lie in an approximately convex basin near the reference model. Experimentally, we demonstrate the single basin phenomenon across a variety of model architectures and datasets, including the ﬁrst (to our knowledge) demonstration of zero-barrier linear mode connectivity between independently trained ResNet models on CIFAR-10 and CIFAR-100. Additionally, we identify intriguing phenomena relating model width and training time to mode connectivity across a variety of models and datasets. Finally, we discuss shortcomings of a single basin theory, including a counterexample to the linear mode connectivity hypothesis.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Ainsworth, Samuel K. and Hayase, Jonathan and Srinivasa, Siddhartha},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{caron_deep_nodate,
	title = {Deep clustering for unsupervised learning of visual features},
	abstract = {Clustering is a class of unsupervised learning methods that has been extensively applied and studied in computer vision. Little work has been done to adapt it to the end-to-end training of visual features on large-scale datasets. In this work, we present DeepCluster, a clustering method that jointly learns the parameters of a neural network and the cluster assignments of the resulting features. DeepCluster iteratively groups the features with a standard clustering algorithm, kmeans, and uses the subsequent assignments as supervision to update the weights of the network. We apply DeepCluster to the unsupervised training of convolutional neural networks on large datasets like ImageNet and YFCC100M. The resulting model outperforms the current state of the art by a signiﬁcant margin on all the standard benchmarks.},
	language = {en},
	author = {Caron, Mathilde and Bojanowski, Piotr and Joulin, Armand and Douze, Matthijs},
	pages = {18},
}

@inproceedings{caron_unsupervised_2020,
	title = {Unsupervised learning of visual features by contrasting cluster assignments},
	abstract = {Unsupervised image representations have signiﬁcantly reduced the gap with supervised pretraining, notably with the recent achievements of contrastive learning methods. These contrastive methods typically work online and rely on a large number of explicit pairwise feature comparisons, which is computationally challenging. In this paper, we propose an online algorithm, SwAV, that takes advantage of contrastive methods without requiring to compute pairwise comparisons. Speciﬁcally, our method simultaneously clusters the data while enforcing consistency between cluster assignments produced for different augmentations (or “views”) of the same image, instead of comparing features directly as in contrastive learning. Simply put, we use a “swapped” prediction mechanism where we predict the code of a view from the representation of another view. Our method can be trained with large and small batches and can scale to unlimited amounts of data. Compared to previous contrastive methods, our method is more memory efﬁcient since it does not require a large memory bank or a special momentum network. In addition, we also propose a new data augmentation strategy, multi-crop, that uses a mix of views with different resolutions in place of two full-resolution views, without increasing the memory or compute requirements. We validate our ﬁndings by achieving 75.3\% top-1 accuracy on ImageNet with ResNet-50, as well as surpassing supervised pretraining on all the considered transfer tasks.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Caron, Mathilde and Goyal, Priya and Misra, Ishan and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
	year = {2020},
}

@inproceedings{caron_deep_2018,
	title = {Deep clustering for unsupervised learning of visual features},
	booktitle = {Proceedings of the {European} conference on computer vision ({ECCV})},
	author = {Caron, Mathilde and Bojanowski, Piotr and Joulin, Armand and Douze, Matthijs},
	year = {2018},
	pages = {132--149},
}

@inproceedings{madry_towards_2018,
	title = {Towards deep learning models resistant to adversarial attacks},
	abstract = {Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at https://github.com/MadryLab/mnist\_challenge and https://github.com/MadryLab/cifar10\_challenge.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{azulay_why_2019,
	title = {Why do deep convolutional networks generalize so poorly to small image transformations?},
	volume = {20},
	abstract = {Convolutional Neural Networks (CNNs) are commonly assumed to be invariant to small image transformations: either because of the convolutional architecture or because they were trained using data augmentation. Recently, several authors have shown that this is not the case: small translations or rescalings of the input image can drastically change the network’s prediction. In this paper, we quantify this phenomena and ask why neither the convolutional architecture nor data augmentation are suﬃcient to achieve the desired invariance. Speciﬁcally, we show that the convolutional architecture does not give invariance since architectures ignore the classical sampling theorem, and data augmentation does not give invariance because the CNNs learn to be invariant to transformations only for images that are very similar to typical images from the training set. We discuss two possible solutions to this problem: (1) antialiasing the intermediate representations and (2) increasing data augmentation and show that they provide only a partial solution at best. Taken together, our results indicate that the problem of insuring invariance to small image transformations in neural networks while preserving high accuracy remains unsolved.},
	language = {en},
	number = {184},
	journal = {Journal of Machine Learning Research},
	author = {Azulay, Aharon and Weiss, Yair},
	year = {2019},
	pages = {1--25},
}

@article{zagoruyko_wide_2017,
	title = {Wide residual networks},
	abstract = {Deep residual networks were shown to be able to scale up to thousands of layers and still have improving performance. However, each fraction of a percent of improved accuracy costs nearly doubling the number of layers, and so training very deep residual networks has a problem of diminishing feature reuse, which makes these networks very slow to train. To tackle these problems, in this paper we conduct a detailed experimental study on the architecture of ResNet blocks, based on which we propose a novel architecture where we decrease depth and increase width of residual networks. We call the resulting network structures wide residual networks (WRNs) and show that these are far superior over their commonly used thin and very deep counterparts. For example, we demonstrate that even a simple 16-layer-deep wide residual network outperforms in accuracy and efﬁciency all previous deep residual networks, including thousand-layerdeep networks, achieving new state-of-the-art results on CIFAR, SVHN, COCO, and signiﬁcant improvements on ImageNet. Our code and models are available at https: //github.com/szagoruyko/wide-residual-networks.},
	language = {en},
	journal = {arXiv preprint arXiv:1605.07146},
	author = {Zagoruyko, Sergey and Komodakis, Nikos},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@article{wu_learnability_2019,
	title = {Learnability for the information bottleneck},
	volume = {21},
	issn = {1099-4300},
	doi = {10.3390/e21100924},
	abstract = {The Information Bottleneck (IB) method provides an insightful and principled approach for balancing compression and prediction for representation learning. The IB objective     I ( X ; Z ) - β I ( Y ; Z )     employs a Lagrange multiplier    β    to tune this trade-off. However, in practice, not only is    β    chosen empirically without theoretical guidance, there is also a lack of theoretical understanding between    β   , learnability, the intrinsic nature of the dataset and model capacity. In this paper, we show that if    β    is improperly chosen, learning cannot happen—the trivial representation     P ( Z {\textbar} X ) = P ( Z )     becomes the global minimum of the IB objective. We show how this can be avoided, by identifying a sharp phase transition between the unlearnable and the learnable which arises as    β    is varied. This phase transition defines the concept of IB-Learnability. We prove several sufficient conditions for IB-Learnability, which provides theoretical guidance for choosing a good    β   . We further show that IB-learnability is determined by the largest confident, typical and imbalanced subset of the examples (the conspicuous subset), and discuss its relation with model capacity. We give practical algorithms to estimate the minimum    β    for a given dataset. We also empirically demonstrate our theoretical conditions with analyses of synthetic datasets, MNIST and CIFAR10.},
	language = {en},
	number = {10},
	journal = {Entropy},
	author = {Wu, Tailin and Fischer, Ian and Chuang, Isaac L. and Tegmark, Max},
	year = {2019},
	pages = {924},
}

@inproceedings{sutskever_importance_2013,
	title = {On the importance of initialization and momentum in deep learning},
	abstract = {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We ﬁnd that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
	year = {2013},
	pages = {1139--1147},
}

@inproceedings{du_learning_2020,
	title = {Learning to learn with variational information bottleneck for domain generalization},
	booktitle = {European {Conference} on {Computer} {Vision}},
	author = {Du, Yingjun and Xu, Jun and Xiong, Huan and Qiu, Qiang and Zhen, Xiantong and Snoek, Cees GM and Shao, Ling},
	year = {2020},
	pages = {200--216},
}

@inproceedings{lee_compressive_2021,
	title = {Compressive visual representations},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lee, Kuang-Huei and Arnab, Anurag and Guadarrama, Sergio and Canny, John and Fischer, Ian},
	year = {2021},
	pages = {19538--19552},
}

@article{fischer_conditional_2020,
	title = {The conditional entropy bottleneck},
	volume = {22},
	number = {9},
	journal = {Entropy},
	author = {Fischer, Ian},
	year = {2020},
	pages = {999},
}

@article{zhai_understanding_2022,
	title = {Understanding why generalized reweighting does not improve over {ERM}},
	abstract = {Empirical risk minimization (ERM) is known to be non-robust in practice to distributional shift where the training and the test distributions are different. A suite of approaches, such as importance weighting, and variants of distributionally robust optimization (DRO), have been proposed to solve this problem. But a line of recent work has empirically shown that these approaches do not signiﬁcantly improve over ERM in real applications with distribution shift. The goal of this work is to obtain a comprehensive theoretical understanding of this intriguing phenomenon. We ﬁrst posit the class of Generalized Reweighting (GRW) algorithms, as a broad category of approaches that iteratively update model parameters based on iterative reweighting of the training samples. We show that when overparameterized models are trained under GRW, the resulting models are close to that obtained by ERM. We also show that adding small regularization which does not greatly affect the empirical training accuracy does not help. Together, our results show that a broad category of what we term GRW approaches are not able to achieve distributionally robust generalization. Our work thus has the following sobering takeaway: to make progress towards distributionally robust generalization, we either have to develop non-GRW approaches, or perhaps devise novel classiﬁcation/regression loss functions that are adapted to the class of GRW approaches.},
	language = {en},
	journal = {arXiv preprint arXiv:2201.12293},
	author = {Zhai, Runtian and Dan, Chen and Kolter, Zico and Ravikumar, Pradeep},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{korshunova_closer_2021,
	title = {A closer look at the adversarial robustness of information bottleneck models},
	abstract = {We study the adversarial robustness of information bottleneck models for classiﬁcation. Previous works showed that the robustness of models trained with information bottlenecks can improve upon adversarial training. Our evaluation under a diverse range of white-box l∞ attacks suggests that information bottlenecks alone are not a strong defense strategy, and that previous results were likely inﬂuenced by gradient obfuscation.},
	language = {en},
	journal = {arXiv preprint arXiv:2107.05712},
	author = {Korshunova, Iryna and Stutz, David and Alemi, Alexander A. and Wiles, Olivia and Gowal, Sven},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{dubois_lossy_2021,
	title = {Lossy compression for lossless prediction},
	abstract = {Most data is automatically collected and only ever “seen” by algorithms. Yet, data compressors preserve perceptual ﬁdelity rather than just the information needed by algorithms performing downstream tasks. In this paper, we characterize the bit-rate required to ensure high performance on all predictive tasks that are invariant under a set of transformations, such as data augmentations. Based on our theory, we design unsupervised objectives for training neural compressors. Using these objectives, we train a generic image compressor that achieves substantial rate savings (more than 1000× on ImageNet) compared to JPEG on 8 datasets, without decreasing downstream classiﬁcation performance.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dubois, Yann and Ullrich, Karen and Bloem-Reddy, Benjamin and Maddison, Chris J},
	year = {2021},
	pages = {14014--14028},
}

@inproceedings{yin_fourier_2019,
	title = {A fourier perspective on model robustness in computer vision},
	abstract = {Achieving robustness to distributional shift is a longstanding and challenging goal of computer vision. Data augmentation is a commonly used approach for improving robustness, however robustness gains are typically not uniform across corruption types. Indeed increasing performance in the presence of random noise is often met with reduced performance on other corruptions such as contrast change. Understanding when and why these sorts of trade-offs occur is a crucial step towards mitigating them. Towards this end, we investigate recently observed tradeoffs caused by Gaussian data augmentation and adversarial training. We ﬁnd that both methods improve robustness to corruptions that are concentrated in the high frequency domain while reducing robustness to corruptions that are concentrated in the low frequency domain. This suggests that one way to mitigate these trade-offs via data augmentation is to use a more diverse set of augmentations. Towards this end we observe that AutoAugment [6], a recently proposed data augmentation policy optimized for clean accuracy, achieves state-of-the-art robustness on the CIFAR-10-C [17] benchmark.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Yin, Dong and Lopes, Raphael Gontijo and Shlens, Jon and Cubuk, Ekin Dogus and Gilmer, Justin},
	year = {2019},
	pages = {13255--13265},
}

@inproceedings{zhang_theoretically_2019,
	title = {Theoretically principled trade-off between robustness and accuracy},
	abstract = {We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classiﬁcation) error and boundary error, and provide a differentiable upper bound using the theory of classiﬁcation-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of {\textasciitilde}2,000 submissions, surpassing the runner-up approach by 11.41\% in terms of mean `2 perturbation distance.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric P and Ghaoui, Laurent El and Jordan, Michael I},
	year = {2019},
	pages = {7472--7482},
}

@inproceedings{wang_denoised_2022,
	title = {Denoised {MDPs}: {Learning} world models better than the world itself},
	shorttitle = {Denoised mdps},
	abstract = {The ability to separate signal from noise, and reason with clean abstractions, is critical to intelligence. With this ability, humans can efficiently perform real world tasks without considering all possible nuisance factors.How can artificial agents do the same? What kind of information can agents safely discard as noises? In this work, we categorize information out in the wild into four types based on controllability and relation with reward, and formulate useful information as that which is both controllable and reward-relevant. This framework clarifies the kinds information removed by various prior work on representation learning in reinforcement learning (RL), and leads to our proposed approach of learning a Denoised MDP that explicitly factors out certain noise distractors. Extensive experiments on variants of DeepMind Control Suite and RoboDesk demonstrate superior performance of our denoised world model over using raw observations alone, and over prior works, across policy optimization control tasks as well as the non-control task of joint position regression.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Wang, Tongzhou and Du, Simon S. and Torralba, Antonio and Isola, Phillip and Zhang, Amy and Tian, Yuandong},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
	pages = {22591--22612},
}

@inproceedings{wang_learning_2022,
	title = {On the learning and learnability of quasimetrics},
	abstract = {Our world is full of asymmetries. Gravity and wind can make reaching a place easier than coming back. Social artifacts such as genealogy charts and citation graphs are inherently directed. In reinforcement learning and control, optimal goal-reaching strategies are rarely reversible (symmetrical). Distance functions supported on these asymmetrical structures are called quasimetrics. Despite their common appearance, little research has been done on the learning of quasimetrics. Our theoretical analysis reveals that a common class of learning algorithms, including unconstrained multilayer perceptrons (MLPs), provably fails to learn a quasimetric consistent with training data. In contrast, our proposed Poisson Quasimetric Embedding (PQE) is the ﬁrst quasimetric learning formulation that both is learnable with gradient-based optimization and enjoys strong performance guarantees. Experiments on random graphs, social graphs, and ofﬂine Q-learning demonstrate its effectiveness over many common baselines.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Wang, Tongzhou and Isola, Phillip},
	year = {2022},
	pages = {57},
}

@inproceedings{zimmermann_contrastive_2021,
	title = {Contrastive learning inverts the data generating process},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zimmermann, Roland S and Sharma, Yash and Schneider, Steffen and Bethge, Matthias and Brendel, Wieland},
	year = {2021},
	pages = {12979--12990},
}

@inproceedings{wang_understanding_2020,
	title = {Understanding contrastive representation learning through alignment and uniformity on the hypersphere},
	abstract = {Contrastive representation learning has been outstandingly successful in practice. In this work, we identify two key properties related to the contrastive loss: (1) alignment (closeness) of features from positive pairs, and (2) uniformity of the induced distribution of the (normalized) features on the hypersphere. We prove that, asymptotically, the contrastive loss optimizes these properties, and analyze their positive effects on downstream tasks. Empirically, we introduce an optimizable metric to quantify each property. Extensive experiments on standard vision and language datasets conﬁrm the strong agreement between both metrics and downstream task performance. Directly optimizing for these two metrics leads to representations with comparable or better performance at downstream tasks than contrastive learning. Project Page: ssnl.github.io/hypersphere. Code: github.com/SsnL/align uniform. Alignment: Similar samples have similar features.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Wang, Tongzhou and Isola, Phillip},
	year = {2020},
	pages = {9929--9939},
}

@inproceedings{touvron_training_2021,
	title = {Training data-efficient image transformers \& distillation through attention},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and Jégou, Hervé},
	year = {2021},
	pages = {10347--10357},
}

@inproceedings{kolesnikov_big_2020,
	title = {Big transfer (bit): {General} visual representation learning},
	booktitle = {European conference on computer vision},
	author = {Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
	year = {2020},
	pages = {491--507},
}

@inproceedings{naseer_intriguing_2021,
	title = {Intriguing properties of vision transformers},
	abstract = {Vision transformers (ViT) have demonstrated impressive performance across numerous machine vision tasks. These models are based on multi-head self-attention mechanisms that can ﬂexibly attend to a sequence of image patches to encode contextual cues. An important question is how such ﬂexibility (in attending image-wide context conditioned on a given patch) can facilitate handling nuisances in natural images e.g., severe occlusions, domain shifts, spatial permutations, adversarial and natural perturbations. We systematically study this question via an extensive set of experiments encompassing three ViT families and provide comparisons with a high-performing convolutional neural network (CNN). We show and analyze the following intriguing properties of ViT: (a) Transformers are highly robust to severe occlusions, perturbations and domain shifts, e.g., retain as high as 60\% top-1 accuracy on ImageNet even after randomly occluding 80\% of the image content. (b) The robustness towards occlusions is not due to texture bias, instead we show that ViTs are signiﬁcantly less biased towards local textures, compared to CNNs. When properly trained to encode shape-based features, ViTs demonstrate shape recognition capability comparable to that of human visual system, previously unmatched in the literature. (c) Using ViTs to encode shape representation leads to an interesting consequence of accurate semantic segmentation without pixel-level supervision. (d) Off-the-shelf features from a single ViT model can be combined to create a feature ensemble, leading to high accuracy rates across a range of classiﬁcation datasets in both traditional and few-shot learning paradigms. We show effective features of ViTs are due to ﬂexible and dynamic receptive ﬁelds possible via self-attention mechanisms. Code: https://git.io/Js15X.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Naseer, Muzammal and Ranasinghe, Kanchana and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan},
	year = {2021},
	pages = {23296--23308},
}

@article{shao_adversarial_2021,
	title = {On the adversarial robustness of vision transformers},
	abstract = {Following the success in advancing natural language processing and understanding, transformers are expected to bring revolutionary changes to computer vision. This work provides the ﬁrst and comprehensive study on the robustness of vision transformers (ViTs) against adversarial perturbations. Tested on various whitebox and transfer attack settings, we ﬁnd that ViTs possess better adversarial robustness when compared with convolutional neural networks (CNNs). This observation also holds for certiﬁed robustness. We summarize the following main observations contributing to the improved robustness of ViTs: 1) Features learned by ViTs contain less low-level information and are more generalizable, which contributes to superior robustness against adversarial perturbations. 2) Introducing convolutional or tokens-to-token blocks for learning low-level features in ViTs can improve classiﬁcation accuracy but at the cost of adversarial robustness. 3) Increasing the proportion of transformers in the model structure (when the model consists of both transformer and CNN blocks) leads to better robustness. But for a pure transformer model, simply increasing the size or adding layers cannot guarantee a similar effect. 4) Pre-training on larger datasets does not signiﬁcantly improve adversarial robustness though it is critical for training ViTs. 5) Adversarial training is also applicable to ViT for training robust models. Furthermore, feature visualization and frequency analysis are conducted for explanation. The results show that ViTs are less sensitive to high-frequency perturbations than CNNs and there is a high correlation between how well the model learns low-level features and its robustness against different frequency-based perturbations.},
	language = {en},
	journal = {arXiv preprint arXiv:2103.15670},
	author = {Shao, Rulin and Shi, Zhouxing and Yi, Jinfeng and Chen, Pin-Yu and Hsieh, Cho-Jui},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{mahmood_robustness_2021,
	address = {Montreal, QC, Canada},
	title = {On the robustness of vision transformers to adversarial examples},
	isbn = {978-1-66542-812-5},
	doi = {10.1109/ICCV48922.2021.00774},
	abstract = {Recent advances in attention-based networks have shown that Vision Transformers can achieve state-of-the-art or near state-of-the-art results on many image classiﬁcation tasks. This puts transformers in the unique position of being a promising alternative to traditional convolutional neural networks (CNNs). While CNNs have been carefully studied with respect to adversarial attacks, the same cannot be said of Vision Transformers. In this paper, we study the robustness of Vision Transformers to adversarial examples. Our analyses of transformer security is divided into three parts. First, we test the transformer under standard whitebox and black-box attacks. Second, we study the transferability of adversarial examples between CNNs and transformers. We show that adversarial examples do not readily transfer between CNNs and transformers. Based on this ﬁnding, we analyze the security of a simple ensemble defense of CNNs and transformers. By creating a new attack, the self-attention blended gradient attack, we show that such an ensemble is not secure under a white-box adversary. However, under a black-box adversary, we show that an ensemble can achieve unprecedented robustness without sacriﬁcing clean accuracy. Our analysis for this work is done using six types of white-box attacks and two types of black-box attacks. Our study encompasses multiple Vision Transformers, Big Transfer Models and CNN architectures trained on CIFAR-10, CIFAR-100 and ImageNet.},
	language = {en},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Mahmood, Kaleel and Mahmood, Rigel and van Dijk, Marten},
	year = {2021},
	pages = {7818--7827},
}

@inproceedings{shi_robustness_2020,
	title = {Robustness verification for transformers},
	abstract = {Robustness veriﬁcation that aims to formally certify the prediction behavior of neural networks has become an important tool for understanding model behavior and obtaining safety guarantees. However, previous methods can usually only handle neural networks with relatively simple architectures. In this paper, we consider the robustness veriﬁcation problem for Transformers. Transformers have complex self-attention layers that pose many challenges for veriﬁcation, including cross-nonlinearity and cross-position dependency, which have not been discussed in previous works. We resolve these challenges and develop the ﬁrst robustness veriﬁcation algorithm for Transformers. The certiﬁed robustness bounds computed by our method are signiﬁcantly tighter than those by naive Interval Bound Propagation. These bounds also shed light on interpreting Transformers as they consistently reﬂect the importance of different words in sentiment analysis.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Shi, Zhouxing and Zhang, Huan and Chang, Kai-Wei and Huang, Minlie and Hsieh, Cho-Jui},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{bhojanapalli_understanding_2021,
	address = {Montreal, QC, Canada},
	title = {Understanding robustness of transformers for image classification},
	isbn = {978-1-66542-812-5},
	doi = {10.1109/ICCV48922.2021.01007},
	abstract = {Deep Convolutional Neural Networks (CNNs) have long been the architecture of choice for computer vision tasks. Recently, Transformer-based architectures like Vision Transformer (ViT) have matched or even surpassed ResNets for image classification. However, details of the Transformer architecture ±such as the use of non-overlapping patches± lead one to wonder whether these networks are as robust. In this paper, we perform an extensive study of a variety of different measures of robustness of ViT models and compare the findings to ResNet baselines. We investigate robustness to input perturbations as well as robustness to model perturbations. We find that when pre-trained with a sufficient amount of data, ViT models are at least as robust as the ResNet counterparts on a broad range of perturbations. We also find that Transformers are robust to the removal of almost any single layer, and that while activations from later layers are highly correlated with each other, they nevertheless play an important role in classification.},
	language = {en},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Bhojanapalli, Srinadh and Chakrabarti, Ayan and Glasner, Daniel and Li, Daliang and Unterthiner, Thomas and Veit, Andreas},
	year = {2021},
	pages = {10211--10221},
}

@inproceedings{paul_vision_2022,
	title = {Vision transformers are robust learners},
	volume = {36},
	isbn = {2374-3468},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Paul, Sayak and Chen, Pin-Yu},
	year = {2022},
	pages = {2071--2081},
}

@inproceedings{mao_towards_2022,
	title = {Towards robust vision transformer},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Mao, Xiaofeng and Qi, Gege and Chen, Yuefeng and Li, Xiaodan and Duan, Ranjie and Ye, Shaokai and He, Yuan and Xue, Hui},
	year = {2022},
	pages = {12042--12051},
}

@article{chen_improved_2020,
	title = {Improved baselines with momentum contrastive learning},
	language = {en},
	journal = {arXiv preprint arXiv:2003.04297},
	author = {Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
	year = {2020},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{fischer_ceb_2020,
	title = {{CEB} improves model robustness},
	volume = {22},
	issn = {1099-4300},
	doi = {10.3390/e22101081},
	abstract = {We demonstrate that the Conditional Entropy Bottleneck (CEB) can improve model robustness. CEB is an easy strategy to implement and works in tandem with data augmentation procedures. We report results of a large scale adversarial robustness study on CIFAR-10, as well as the ImageNet-C Common Corruptions Benchmark, ImageNet-A, and PGD attacks.},
	language = {en},
	number = {10},
	journal = {Entropy},
	author = {Fischer, Ian and Alemi, Alexander A.},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {1081},
}

@article{gao_back_2022,
	title = {Back to the source: {Diffusion}-driven test-time adaptation},
	shorttitle = {Back to the source},
	abstract = {Test-time adaptation harnesses test inputs to improve the accuracy of a model trained on source data when tested on shifted target data. Existing methods update the source model by (re-)training on each target domain. While effective, re-training is sensitive to the amount and order of the data and the hyperparameters for optimization. We instead update the target data, by projecting all test inputs toward the source domain with a generative diffusion model. Our diffusion-driven adaptation method, DDA, shares its models for classiﬁcation and generation across all domains. Both models are trained on the source domain, then ﬁxed during testing. We augment diffusion with image guidance and self-ensembling to automatically decide how much to adapt. Input adaptation by DDA is more robust than prior model adaptation approaches across a variety of corruptions, architectures, and data regimes on the ImageNet-C benchmark. With its input-wise updates, DDA succeeds where model adaptation degrades on too little data in small batches, dependent data in non-uniform order, or mixed data with multiple corruptions.},
	language = {en},
	journal = {arXiv preprint arXiv:2207.03442},
	author = {Gao, Jin and Zhang, Jialing and Liu, Xihui and Darrell, Trevor and Shelhamer, Evan and Wang, Dequan},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{luo_understanding_2022,
	title = {Understanding diffusion models: {A} unified perspective},
	shorttitle = {Understanding diffusion models},
	abstract = {Diffusion models have shown incredible capabilities as generative models; indeed, they power the current state-of-the-art models on text-conditioned image generation such as Imagen and DALL-E 2. In this work we review, demystify, and unify the understanding of diffusion models across both variational and score-based perspectives. We first derive Variational Diffusion Models (VDM) as a special case of a Markovian Hierarchical Variational Autoencoder, where three key assumptions enable tractable computation and scalable optimization of the ELBO. We then prove that optimizing a VDM boils down to learning a neural network to predict one of three potential objectives: the original source input from any arbitrary noisification of it, the original source noise from any arbitrarily noisified input, or the score function of a noisified input at any arbitrary noise level. We then dive deeper into what it means to learn the score function, and connect the variational perspective of a diffusion model explicitly with the Score-based Generative Modeling perspective through Tweedie's Formula. Lastly, we cover how to learn a conditional distribution using diffusion models via guidance.},
	language = {en},
	journal = {arXiv preprint arXiv:2208.11970},
	author = {Luo, Calvin},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{chen_intriguing_2021,
	title = {Intriguing properties of contrastive losses},
	abstract = {We study three intriguing properties of contrastive learning. First, we generalize the standard contrastive loss to a broader family of losses, and we ﬁnd that various instantiations of the generalized loss perform similarly under the presence of a multi-layer non-linear projection head. Second, we study if instance-based contrastive learning (with a global image representation) can learn well on images with multiple objects present. We ﬁnd that meaningful hierarchical local features can be learned despite the fact that these objectives operate on global instancelevel features. Finally, we study the phenomenon of feature suppression among competing features shared across augmented views, such as “color distribution” vs “object class”. We construct datasets with explicit and controllable competing features, and show that, for contrastive learning, a few bits of easy-to-learn shared features can suppress, and even fully prevent, the learning of other sets of competing features. In scenarios where there are multiple objects in an image, the dominant object would suppress the learning of smaller objects. Existing contrastive learning methods critically rely on data augmentation to favor certain sets of features over others, and could suffer from learning saturation for scenarios where existing augmentations cannot fully address the feature suppression. This poses open challenges to existing contrastive learning techniques 1.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chen, Ting and Luo, Calvin and Li, Lala},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	pages = {11834--11845},
}

@inproceedings{zhao_maximum-entropy_2020,
	title = {Maximum-entropy adversarial data augmentation for improved generalization and robustness},
	abstract = {Adversarial data augmentation has shown promise for training robust deep neural networks against unforeseen data shifts or corruptions. However, it is difﬁcult to deﬁne heuristics to generate effective ﬁctitious target distributions containing “hard” adversarial perturbations that are largely different from the source distribution. In this paper, we propose a novel and effective regularization term for adversarial data augmentation. We theoretically derive it from the information bottleneck principle, which results in a maximum-entropy formulation. Intuitively, this regularization term encourages perturbing the underlying source distribution to enlarge predictive uncertainty of the current model, so that the generated “hard” adversarial perturbations can improve the model robustness during training. Experimental results on three standard benchmarks demonstrate that our method consistently outperforms the existing state of the art by a statistically signiﬁcant margin. Our code is available at https://github.com/garyzhao/ME-ADA.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhao, Long and Liu, Ting and Peng, Xi and Metaxas, Dimitris},
	year = {2020},
	pages = {14435--14447},
}

@inproceedings{huang_speedaccuracy_2017,
	address = {Honolulu, HI},
	title = {Speed/accuracy trade-offs for modern convolutional object detectors},
	isbn = {978-1-5386-0457-1},
	doi = {10.1109/CVPR.2017.351},
	abstract = {The goal of this paper is to serve as a guide for selecting a detection architecture that achieves the right speed/memory/accuracy balance for a given application and platform. To this end, we investigate various ways to trade accuracy for speed and memory usage in modern convolutional object detection systems. A number of successful systems have been proposed in recent years, but apples-toapples comparisons are difﬁcult due to different base feature extractors (e.g., VGG, Residual Networks), different default image resolutions, as well as different hardware and software platforms. We present a uniﬁed implementation of the Faster R-CNN [30], R-FCN [6] and SSD [25] systems, which we view as “meta-architectures” and trace out the speed/accuracy trade-off curve created by using alternative feature extractors and varying other critical parameters such as image size within each of these meta-architectures. On one extreme end of this spectrum where speed and memory are critical, we present a detector that achieves real time speeds and can be deployed on a mobile device. On the opposite end in which accuracy is critical, we present a detector that achieves state-of-the-art performance measured on the COCO detection task.},
	language = {en},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Huang, Jonathan and Rathod, Vivek and Sun, Chen and Zhu, Menglong and Korattikara, Anoop and Fathi, Alireza and Fischer, Ian and Wojna, Zbigniew and Song, Yang and Guadarrama, Sergio and Murphy, Kevin},
	year = {2017},
	pages = {3296--3297},
}

@inproceedings{wortsman_model_2022,
	title = {Model soups: {Averaging} weights of multiple fine-tuned models improves accuracy without increasing inference time},
	shorttitle = {Model soups},
	abstract = {The conventional recipe for maximizing model accuracy is to (1) train multiple models with various hyperparameters and (2) pick the individual model which performs best on a held-out validation set, discarding the remainder. In this paper, we revisit the second step of this procedure in the context of ﬁne-tuning large pre-trained models, where ﬁne-tuned models often appear to lie in a single low error basin. We show that averaging the weights of multiple models ﬁnetuned with different hyperparameter conﬁgurations often improves accuracy and robustness. Unlike a conventional ensemble, we may average many models without incurring any additional inference or memory costs—we call the results “model soups.” When ﬁne-tuning large pre-trained models such as CLIP, ALIGN, and a ViT-G pretrained on JFT, our soup recipe provides signiﬁcant improvements over the best model in a hyperparameter sweep on ImageNet. The resulting ViT-G model, which attains 90.94\% top-1 accuracy on ImageNet, achieved a new state of the art. Furthermore, we show that the model soup approach extends to multiple image classiﬁcation and natural language processing tasks, improves out-of-distribution performance, and improves zero-shot performance on new downstream tasks. Finally, we analytically relate the performance similarity of weight-averaging and logitensembling to ﬂatness of the loss and conﬁdence of the predictions, and validate this relation empirically. Code is available at https://github. com/mlfoundations/model-soups.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Yitzhak and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S. and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and Schmidt, Ludwig},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
	pages = {23965--23998},
}

@inproceedings{tomczak_vae_2018,
	title = {{VAE} with a {VampPrior}},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics}},
	author = {Tomczak, Jakub and Welling, Max},
	year = {2018},
	pages = {1214--1223},
}

@inproceedings{alemi_fixing_2018,
	title = {Fixing a broken {ELBO}},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Alemi, Alexander and Poole, Ben and Fischer, Ian and Dillon, Joshua and Saurous, Rif A. and Murphy, Kevin},
	year = {2018},
	pages = {159--168},
}

@article{zhang_adjacency_2022,
	title = {Adjacency constraint for efficient hierarchical reinforcement learning},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2022.3192418},
	abstract = {Goal-conditioned Hierarchical Reinforcement Learning (HRL) is a promising approach for scaling up reinforcement learning (RL) techniques. However, it often suffers from training inefficiency as the action space of the high-level, i.e., the goal space, is large. Searching in a large goal space poses difficulty for both high-level subgoal generation and low-level policy learning. In this paper, we show that this problem can be effectively alleviated by restricting the high-level action space from the whole goal space to a \$k\$-step adjacent region of the current state using an adjacency constraint. We theoretically prove that in a deterministic Markov Decision Process (MDP), the proposed adjacency constraint preserves the optimal hierarchical policy, while in a stochastic MDP the adjacency constraint induces a bounded state-value suboptimality determined by the MDP’s transition structure. We further show that this constraint can be practically implemented by training an adjacency network that can discriminate between adjacent and non-adjacent subgoals. Experimental results on discrete and continuous control tasks including challenging simulated robot locomotion and manipulation tasks show that incorporating the adjacency constraint significantly boosts the performance of state-of-the-art goal-conditioned HRL approaches.},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Zhang, Tianren and Guo, Shangqi and Tan, Tian and Hu, Xiaolin and Chen, Feng},
	year = {2022},
	keywords = {Training, Task analysis, Games, Reinforcement learning, reinforcement learning (RL), adjacency constraint, goal-conditioning, Hierarchical reinforcement learning (HRL), Markov processes, Postal services, Random variables, subgoal generation},
	pages = {1--15},
}

@inproceedings{parascandolo_learning_2021,
	title = {Learning explanations that are hard to vary},
	abstract = {In this paper, we investigate the principle that good explanations are hard to vary in the context of deep learning. We show that averaging gradients across examples – akin to a logical OR (\_) of patterns – can favor memorization and ‘patchwork’ solutions that sew together different strategies, instead of identifying invariances. To inspect this, we ﬁrst formalize a notion of consistency for minima of the loss surface, which measures to what extent a minimum appears only when examples are pooled. We then propose and experimentally validate a simple alternative algorithm based on a logical AND ({\textasciicircum}), that focuses on invariances and prevents memorization in a set of real-world tasks. Finally, using a synthetic dataset with a clear distinction between invariant and spurious mechanisms, we dissect learning signals and compare this approach to well-established regularizers.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Parascandolo, Giambattista and Neitz, Alexander and Orvieto, Antonio and Gresele, Luigi and Schölkopf, Bernhard},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{zhou_model_2022,
	title = {Model agnostic sample reweighting for out-of-distribution learning},
	abstract = {Distributionally robust optimization (DRO) and invariant risk minimization (IRM) are two popular methods proposed to improve out-of-distribution (OOD) generalization performance of machine learning models. While effective for small models, it has been observed that these methods can be vulnerable to overfitting with large overparameterized models. This work proposes a principled method, Model Agnostic samPLe rEweighting (MAPLE), to effectively address OOD problem, especially in overparameterized scenarios. Our key idea is to find an effective reweighting of the training samples so that the standard empirical risk minimization training of a large model on the weighted training data leads to superior OOD generalization performance. The overfitting issue is addressed by considering a bilevel formulation to search for the sample reweighting, in which the generalization complexity depends on the search space of sample weights instead of the model size. We present theoretical analysis in linear case to prove the insensitivity of MAPLE to model size, and empirically verify its superiority in surpassing state-of-the-art methods by a large margin. Code is available at https: //github.com/x-zho14/MAPLE.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhou, Xiao and Lin, Yong and Pi, Renjie and Zhang, Weizhong and Xu, Renzhe and Cui, Peng and Zhang, Tong},
	year = {2022},
	pages = {27203--27221},
}

@inproceedings{bai_nas-ood_2021,
	title = {Nas-ood: {Neural} architecture search for out-of-distribution generalization},
	abstract = {Recent advances on Out-of-Distribution (OoD) generalization reveal the robustness of deep learning models against distribution shifts. However, existing works focus on OoD algorithms, such as invariant risk minimization, domain generalization, or stable learning, without considering the influence of deep model architectures on OoD generalization, which may lead to sub-optimal performance. Neural Architecture Search (NAS) methods search for architecture based on its performance on the training data, which may result in poor generalization for OoD tasks. In this work, we propose robust Neural Architecture Search for OoD generalization (NAS-OoD), which optimizes the architecture with respect to its performance on generated OoD data by gradient descent. Specifically, a data generator is learned to synthesize OoD data by maximizing losses computed by different neural architectures, while the goal for architecture search is to find the optimal architecture parameters that minimize the synthetic OoD data losses. The data generator and the neural architecture are jointly optimized in an end-to-end manner, and the minimax training process effectively discovers robust architectures that generalize well for different distribution shifts. Extensive experimental results show that NAS-OoD achieves superior performance on various OoD generalization benchmarks with deep models having a much fewer number of parameters. In addition, on a real industry dataset, the proposed NAS-OoD method reduces the error rate by more than 70\% compared with the state-of-the-art method, demonstrating the proposed method’s practicality for real applications.},
	author = {Bai, Haoyue and Zhou, Fengwei and Hong, Lanqing and Ye, Nanyang},
	year = {2021},
	pages = {8300--8309},
}

@inproceedings{pang_robustness_2022,
	title = {Robustness and accuracy could be reconcilable by (proper) definition},
	abstract = {The trade-off between robustness and accuracy has been widely studied in the adversarial literature. Although still controversial, the prevailing view is that this trade-off is inherent, either empirically or theoretically. Thus, we dig for the origin of this trade-off in adversarial training and ﬁnd that it may stem from the improperly deﬁned robust error, which imposes an inductive bias of local invariance — an overcorrection towards smoothness. Given this, we advocate employing local equivariance to describe the ideal behavior of a robust model, leading to a self-consistent robust error named SCORE. By deﬁnition, SCORE facilitates the reconciliation between robustness and accuracy, while still handling the worst-case uncertainty via robust optimization. By simply substituting KL divergence with variants of distance metrics, SCORE can be efﬁciently minimized. Empirically, our models achieve top-rank performance on RobustBench under AutoAttack. Besides, SCORE provides instructive insights for explaining the overﬁtting phenomenon and semantic input gradients observed on robust models.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Pang, Tianyu and Lin, Min and Yang, Xiao and Zhu, Jun and Yan, Shuicheng},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Cryptography and Security},
	pages = {17258--17277},
}

@article{recht_cifar-10_2018,
	title = {Do cifar-10 classifiers generalize to cifar-10?},
	abstract = {Machine learning is currently dominated by largely experimental work focused on improvements in a few key tasks. However, the impressive accuracy numbers of the best performing models are questionable because the same test sets have been used to select these models for multiple years now. To understand the danger of overﬁtting, we measure the accuracy of CIFAR-10 classiﬁers by creating a new test set of truly unseen images. Although we ensure that the new test set is as close to the original data distribution as possible, we ﬁnd a large drop in accuracy (4\% to 10\%) for a broad range of deep learning models. Yet, more recent models with higher original accuracy show a smaller drop and better overall performance, indicating that this drop is likely not due to overﬁtting based on adaptivity. Instead, we view our results as evidence that current accuracy numbers are brittle and susceptible to even minute natural variations in the data distribution.},
	language = {en},
	journal = {arXiv preprint arXiv:1806.00451},
	author = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{sohn_fixmatch_2020,
	title = {{FixMatch}: {Simplifying} semi-supervised learning with consistency and confidence},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Sohn, Kihyuk and Berthelot, David and Li, Chun-Liang and Zhang, Zizhao and Carlini, Nicholas and Cubuk, Ekin D and Kurakin, Alex and Zhang, Han and Raffel, Colin},
	year = {2020},
	pages = {596--608},
}

@inproceedings{ye_mastering_2021,
	title = {Mastering atari games with limited data},
	abstract = {Reinforcement learning has achieved great success in many applications. However, sample efﬁciency remains a key challenge, with prominent methods requiring millions (or even billions) of environment steps to train. Recently, there has been signiﬁcant progress in sample efﬁcient image-based RL algorithms; however, consistent human-level performance on the Atari game benchmark remains an elusive goal. We propose a sample efﬁcient model-based visual RL algorithm built on MuZero, which we name EfﬁcientZero. Our method achieves 190.4\% mean human performance and 116.0\% median performance on the Atari 100k benchmark with only two hours of real-time game experience and outperforms the state SAC in some tasks on the DMControl 100k benchmark. This is the ﬁrst time an algorithm achieves super-human performance on Atari games with such little data. EfﬁcientZero’s performance is also close to DQN’s performance at 200 million frames while we consume 500 times less data. EfﬁcientZero’s low sample complexity and high performance can bring RL closer to real-world applicability. We implement our algorithm in an easy-to-understand manner and it is available at https://github.com/YeWR/EfficientZero. We hope it will accelerate the research of MCTS-based RL algorithms in the wider community.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
	year = {2021},
	pages = {25476--25488},
}

@article{kapturowski_human-level_2022,
	title = {Human-level {Atari} 200x faster},
	abstract = {The task of building general agents that perform well over a wide range of tasks has been an important goal in reinforcement learning since its inception. The problem has been subject of research of a large body of work, with performance frequently measured by observing scores over the wide range of environments contained in the Atari 57 benchmark. Agent57 was the first agent to surpass the human benchmark on all 57 games, but this came at the cost of poor data-efficiency, requiring nearly 80 billion frames of experience to achieve. Taking Agent57 as a starting point, we employ a diverse set of strategies to achieve a 200-fold reduction of experience needed to out perform the human baseline. We investigate a range of instabilities and bottlenecks we encountered while reducing the data regime, and propose effective solutions to build a more robust and efficient agent. We also demonstrate competitive performance with high-performing methods such as Muesli and MuZero. The four key components to our approach are (1) an approximate trust region method which enables stable bootstrapping from the online network, (2) a normalisation scheme for the loss and priorities which improves robustness when learning a set of value functions with a wide range of scales, (3) an improved architecture employing techniques from NFNets in order to leverage deeper networks without the need for normalization layers, and (4) a policy distillation method which serves to smooth out the instantaneous greedy policy overtime.},
	language = {en},
	journal = {arXiv preprint arXiv:2209.07550},
	author = {Kapturowski, Steven and Campos, Víctor and Jiang, Ray and Rakićević, Nemanja and van Hasselt, Hado and Blundell, Charles and Badia, Adrià Puigdomènech},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{tian_elf_2019,
	title = {{ELF} {OpenGo}: {An} analysis and open reimplementation of {AlphaZero}},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, C Lawrence},
	year = {2019},
	pages = {6244--6253},
}

@inproceedings{ruan_optimal_2022,
	title = {Optimal representations for covariate shift},
	abstract = {Machine learning systems often experience a distribution shift between training and testing. In this paper, we introduce a simple variational objective whose optima are exactly the set of all representations on which risk minimizers are guaranteed to be robust to any distribution shift that preserves the Bayes predictor, e.g., covariate shifts. Our objective has two components. First, a representation must remain discriminative for the task, i.e., some predictor must be able to simultaneously minimize the source and target risk. Second, the representation’s marginal support needs to be the same across source and target. We make this practical by designing self-supervised objectives that only use unlabelled data and augmentations to train robust representations. Our objectives give insights into the robustness of CLIP, and further improve CLIP’s representations to achieve SOTA results on DomainBed.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Ruan, Yangjun and Dubois, Yann and Maddison, Chris J.},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Information Theory},
}

@article{chevalley_invariant_2022,
	title = {Invariant causal mechanisms through distribution matching},
	abstract = {Learning representations that capture the underlying data generating process is a key problem for data efﬁcient and robust use of neural networks. One key property for robustness which the learned representation should capture and which recently received a lot of attention is described by the notion of invariance. In this work we provide a causal perspective and new algorithm for learning invariant representations. Empirically we show that this algorithm works well on a diverse set of tasks and in particular we observe state-of-the-art performance on domain generalization, where we are able to signiﬁcantly boost the score of existing models.},
	language = {en},
	journal = {arXiv preprint arXiv:2206.11646},
	author = {Chevalley, Mathieu and Bunne, Charlotte and Krause, Andreas and Bauer, Stefan},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{yan_improve_2020,
	title = {Improve unsupervised domain adaptation with mixup training},
	abstract = {Unsupervised domain adaptation studies the problem of utilizing a relevant source domain with abundant labels to build predictive modeling for an unannotated target domain. Recent work observe that the popular adversarial approach of learning domain-invariant features is insufﬁcient to achieve desirable target domain performance and thus introduce additional training constraints, e.g. cluster assumption. However, these approaches impose the constraints on source and target domains individually, ignoring the important interplay between them. In this work, we propose to enforce training constraints across domains using mixup formulation to directly address the generalization performance for target data. In order to tackle potentially huge domain discrepancy, we further propose a feature-level consistency regularizer to facilitate the inter-domain constraint. When adding intra-domain mixup and domain adversarial learning, our general framework signiﬁcantly improves state-of-the-art performance on several important tasks from both image classiﬁcation and human activity recognition.},
	language = {en},
	journal = {arXiv preprint arXiv:2001.00677},
	author = {Yan, Shen and Song, Huan and Li, Nanxiang and Zou, Lincan and Ren, Liu},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{xu_learning_2021,
	title = {Learning representations that support robust transfer of predictors},
	abstract = {Ensuring generalization to unseen environments remains a challenge. Domain shift can lead to substantially degraded performance unless shifts are wellexercised within the available training environments. We introduce a simple robust estimation criterion – transfer risk – that is speciﬁcally geared towards optimizing transfer to new environments. Eﬀectively, the criterion amounts to ﬁnding a representation that minimizes the risk of applying any optimal predictor trained on one environment to another. The transfer risk essentially decomposes into two terms, a direct transfer term and a weighted gradientmatching term arising from the optimality of per-environment predictors. Although inspired by IRM, we show that transfer risk serves as a better outof-distribution generalization criterion, both theoretically and empirically. We further demonstrate the impact of optimizing such transfer risk on two controlled settings, each representing a diﬀerent pattern of environment shift, as well as on two real-world datasets. Experimentally, the approach outperforms baselines across various out-of-distribution generalization tasks. Code is available at https://github.com/Newbeeer/TRM.},
	language = {en},
	journal = {arXiv preprint arXiv:2110.09940},
	author = {Xu, Yilun and Jaakkola, Tommi},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@article{fawzi_discovering_2022,
	title = {Discovering faster matrix multiplication algorithms with reinforcement learning},
	volume = {610},
	copyright = {2022 The Author(s)},
	issn = {1476-4687},
	doi = {10.1038/s41586-022-05172-4},
	abstract = {A reinforcement learning approach based on AlphaZero is used to discover efficient and provably correct algorithms for matrix multiplication, finding faster algorithms for a variety of matrix sizes.},
	language = {en},
	number = {7930},
	journal = {Nature},
	author = {Fawzi, Alhussein and Balog, Matej and Huang, Aja and Hubert, Thomas and Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and R. Ruiz, Francisco J. and Schrittwieser, Julian and Swirszcz, Grzegorz and Silver, David and Hassabis, Demis and Kohli, Pushmeet},
	year = {2022},
	pages = {47--53},
}

@article{liu_auto-lambda_2022,
	title = {Auto-lambda: {Disentangling} dynamic task relationships},
	shorttitle = {Auto-lambda},
	abstract = {Understanding the structure of multiple related tasks allows for multi-task learning to improve the generalisation ability of one or all of them. However, it usually requires training each pairwise combination of tasks together in order to capture task relationships, at an extremely high computational cost. In this work, we learn task relationships via an automated weighting framework, named Auto-λ. Unlike previous methods where task relationships are assumed to be ﬁxed, Auto-λ is a gradient-based meta learning framework which explores continuous, dynamic task relationships via task-speciﬁc weightings, and can optimise any choice of combination of tasks through the formulation of a meta-loss; where the validation loss automatically inﬂuences task weightings throughout training. We apply the proposed framework to both multi-task and auxiliary learning problems in computer vision and robotics, and show that Auto-λ achieves state-of-the-art performance, even when compared to optimisation strategies designed speciﬁcally for each problem and data domain. Finally, we observe that Auto-λ can discover interesting learning behaviors, leading to new insights in multi-task learning. Code is available at https://github.com/lorenmt/auto-lambda.},
	language = {en},
	journal = {Transactions on Machine Learning Research},
	author = {Liu, Shikun and James, Stephen and Davison, Andrew J. and Johns, Edward},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{li_dada_2020,
	title = {{DADA}: {Differentiable} automatic data augmentation},
	shorttitle = {{DADA}},
	abstract = {Data augmentation (DA) techniques aim to increase data variability, and thus train deep networks with better generalisation. The pioneering AutoAugment automated the search for optimal DA policies with reinforcement learning. However, AutoAugment is extremely computationally expensive, limiting its wide applicability. Followup works such as Population Based Augmentation (PBA) and Fast AutoAugment improved eﬃciency, but their optimization speed remains a bottleneck. In this paper, we propose Diﬀerentiable Automatic Data Augmentation (DADA) which dramatically reduces the cost. DADA relaxes the discrete DA policy selection to a diﬀerentiable optimization problem via Gumbel-Softmax. In addition, we introduce an unbiased gradient estimator, RELAX, leading to an eﬃcient and eﬀective one-pass optimization strategy to learn an eﬃcient and accurate DA policy. We conduct extensive experiments on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets. Furthermore, we demonstrate the value of Auto DA in pre-training for downstream detection problems. Results show our DADA is at least one order of magnitude faster than the state-of-theart while achieving very comparable accuracy. The code is available at https://github.com/VDIGPKU/DADA.},
	language = {en},
	journal = {arXiv preprint arXiv:2003.03780},
	author = {Li, Yonggang and Hu, Guosheng and Wang, Yongtao and Hospedales, Timothy and Robertson, Neil M. and Yang, Yongxin},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{zhou_omni-scale_2019,
	address = {Seoul, Korea (South)},
	title = {Omni-scale feature learning for person re-identification},
	isbn = {978-1-72814-803-8},
	doi = {10.1109/ICCV.2019.00380},
	abstract = {As an instance-level recognition problem, person reidentiﬁcation (ReID) relies on discriminative features, which not only capture different spatial scales but also encapsulate an arbitrary combination of multiple scales. We callse features of both homogeneous and heterogeneous scales omni-scale features. In this paper, a novel deep ReID CNN is designed, termed Omni-Scale Network (OSNet), for omni-scale feature learning. This is achieved by designing a residual block composed of multiple convolutional feature streams, each detecting features at a certain scale. Importantly, a novel uniﬁed aggregation gate is introduced to dynamically fuse multiscale features with input-dependent channel-wise weights. To efﬁciently learn spatial-channel correlations and avoid overﬁtting, the building block uses both pointwise and depthwise convolutions. By stacking such blocks layerby-layer, our OSNet is extremely lightweight and can be trained from scratch on existing ReID benchmarks. Despite its small model size, our OSNet achieves state-ofthe-art performance on six person-ReID datasets. Code and models are available at: https://github.com/ KaiyangZhou/deep-person-reid.},
	language = {en},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Zhou, Kaiyang and Yang, Yongxin and Cavallaro, Andrea and Xiang, Tao},
	year = {2019},
	pages = {3701--3711},
}

@inproceedings{schaul_prioritized_2016,
	title = {Prioritized experience replay},
	abstract = {Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efﬁciently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new stateof-the-art, outperforming DQN with uniform replay on 41 out of 49 games.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	year = {2016},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{khosla_supervised_2020,
	title = {Supervised contrastive learning},
	volume = {33},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
	year = {2020},
	pages = {18661--18673},
}

@inproceedings{arpit_ensemble_2022,
	title = {Ensemble of averages: {Improving} model selection and boosting performance in domain generalization},
	shorttitle = {Ensemble of averages},
	abstract = {In Domain Generalization (DG) settings, models trained independently on a given set of training domains have notoriously chaotic performance on distribution shifted test domains, and stochasticity in optimization (e.g. seed) plays a big role. This makes deep learning models unreliable in real world settings. We ﬁrst show that this chaotic behavior exists even along the training optimization trajectory of a single model, and propose a simple model averaging protocol that both signiﬁcantly boosts domain generalization and diminishes the impact of stochasticity by improving the rank correlation between the in-domain validation accuracy and out-domain test accuracy, which is crucial for reliable early stopping. Taking advantage of our observation, we show that instead of ensembling unaveraged models (that is typical in practice), ensembling moving average models (EoA) from independent runs further boosts performance. We theoretically explain the boost in performance of ensembling and model averaging by adapting the well known Bias-Variance trade-off to the domain generalization setting. On the DomainBed benchmark, when using a pre-trained ResNet-50, this ensemble of averages achieves an average of 68.0\%, beating vanilla ERM (w/o averaging/ensembling) by ∼ 4\%, and when using a pre-trained RegNetY-16GF, achieves an average of 76.6\%, beating vanilla ERM by 6\%. Our code is available at https://github.com/salesforce/ ensemble-of-averages.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Arpit, Devansh and Wang, Huan and Zhou, Yingbo and Xiong, Caiming},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{lan_generalization_2022,
	title = {On the generalization of representations in reinforcement learning},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Lan, Charline Le and Tu, Stephen and Oberman, Adam},
	year = {2022},
	pages = {4132--4157},
}

@inproceedings{chen_generalization_2020,
	title = {On generalization bounds of a family of recurrent neural networks},
	abstract = {Recurrent Neural Networks (RNNs) have been widely applied to sequential data analysis. Due to their complicated modeling structures, however, the theory behind is still largely missing. To connect theory and practice, we study the generalization properties of vanilla RNNs as well as their variants, including Minimal Gated Unit (MGU), Long Short Term Memory (LSTM), and Convolutional (Conv) RNNs. Speciﬁcally, our theory is established under the PAC-Learning framework. The generalization bound is presented in terms of the spectral norms of the weight matrices and the total number of parameters. We also establish reﬁned generalization bounds with additional norm assumptions, and draw a comparison among these bounds. We remark: (1) Our generalization bound for vanilla RNNs is signiﬁcantly tighter than the best of existing results; (2) We are not aware of any other generalization bounds for MGU and LSTM RNNs in the exiting literature; (3) We demonstrate the advantages of these variants in generalization.},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Chen, Minshuo and Li, Xingguo and Zhao, Tuo},
	year = {2020},
	pages = {1233--1243},
}

@inproceedings{steinke_reasoning_2020,
	title = {Reasoning about generalization via conditional mutual information},
	abstract = {We provide an information-theoretic framework for studying the generalization properties of machine learning algorithms. Our framework ties together existing approaches, including uniform convergence bounds and recent methods for adaptive data analysis. Speciﬁcally, we use Conditional Mutual Information (CMI) to quantify how well the input (i.e., the training data) can be recognized given the output (i.e., the trained model) of the algorithm. We show that bounds on CMI can be obtained from VC dimension, compression schemes, differential privacy, and other methods. We then show that bounded CMI implies various forms of generalization.},
	language = {en},
	booktitle = {{COLT}},
	author = {Steinke, Thomas and Zakynthinou, Lydia},
	year = {2020},
	pages = {3437--3452},
}

@inproceedings{chu_dna_2022,
	title = {{DNA}: {Domain} generalization with diversified neural averaging},
	abstract = {The inaccessibility of the target domain data causes domain generalization (DG) methods prone to forget target discriminative features, and challenges the pervasive theme in existing literature in pursuing a single classifier with an ideal joint risk. In contrast, this paper investigates model misspecification and attempts to bridge DG with classifier ensemble theoretically and methodologically. By introducing a pruned Jensen-Shannon (PJS) loss, we show that the target square-root risk w.r.t. the PJS loss of the ρ-ensemble (the averaged classifier weighted by a quasi-posterior ρ) is bounded by the averaged source square-root risk of the Gibbs classifiers. We derive a tighter bound by enforcing a positive principled diversity measure of the classifiers. We give a PAC-Bayes upper bound on the target square-root risk of the ρ-ensemble. Methodologically, we propose a diversified neural averaging (DNA) method for DG, which optimizes the proposed PAC-Bayes bound approximately. The DNA method samples Gibbs classifiers transversely and longitudinally by simultaneously considering the dropout variational family and optimization trajectory. The ρ-ensemble is approximated by averaging the longitudinal weights in a single run with dropout shut down, ensuring a fast ensemble with low computational overhead. Empirically, the proposed DNA method achieves the state-of-the-art classification performance on standard DG benchmark datasets.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Chu, Xu and Jin, Yujie and Zhu, Wenwu and Wang, Yasha and Wang, Xin and Zhang, Shanghang and Mei, Hong},
	year = {2022},
	pages = {4010--4034},
}

@inproceedings{leibe_discriminative_2016,
	address = {Cham},
	title = {A discriminative feature learning approach for deep face recognition},
	volume = {9911},
	isbn = {978-3-319-46477-0 978-3-319-46478-7},
	doi = {10.1007/978-3-319-46478-7_31},
	abstract = {Convolutional neural networks (CNNs) have been widely used in computer vision community, significantly improving the stateof-the-art. In most of the available CNNs, the softmax loss function is used as the supervision signal to train the deep model. In order to enhance the discriminative power of the deeply learned features, this paper proposes a new supervision signal, called center loss, for face recognition task. Specifically, the center loss simultaneously learns a center for deep features of each class and penalizes the distances between the deep features and their corresponding class centers. More importantly, we prove that the proposed center loss function is trainable and easy to optimize in the CNNs. With the joint supervision of softmax loss and center loss, we can train a robust CNNs to obtain the deep features with the two key learning objectives, inter-class dispension and intra-class compactness as much as possible, which are very essential to face recognition. It is encouraging to see that our CNNs (with such joint supervision) achieve the state-of-the-art accuracy on several important face recognition benchmarks, Labeled Faces in the Wild (LFW), YouTube Faces (YTF), and MegaFace Challenge. Especially, our new approach achieves the best results on MegaFace (the largest public domain face benchmark) under the protocol of small training set (contains under 500000 images and under 20000 persons), significantly improving the previous results and setting new state-of-the-art for both face recognition and face verification tasks.},
	language = {en},
	booktitle = {European {Conference} on {Computer} {Vision}},
	author = {Wen, Yandong and Zhang, Kaipeng and Li, Zhifeng and Qiao, Yu},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	year = {2016},
	pages = {499--515},
}

@inproceedings{galstyan_robust_2020,
	title = {Robust classification under class-dependent domain shift},
	abstract = {Investigation of machine learning algorithms robust to changes between the training and test distributions is an active area of research. In this paper we explore a special type of dataset shift which we call class-dependent domain shift. It is characterized by the following features: the input data causally depends on the label, the shift in the data is fully explained by a known variable, the variable which controls the shift can depend on the label, there is no shift in the label distribution. We deﬁne a simple optimization problem with an information theoretic constraint and attempt to solve it with neural networks. Experiments on a toy dataset demonstrate the proposed method is able to learn robust classiﬁers which generalize well to unseen domains.},
	language = {en},
	booktitle = {{ICML} 2020 {Workshop} on {Uncertainty} and {Robustness} in {Deep} {Learning}},
	author = {Galstyan, Tigran and Khachatrian, Hrant and Steeg, Greg Ver and Galstyan, Aram},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{jaiswal_discovery_2019,
	title = {Discovery and separation of features for invariant representation learning},
	abstract = {Supervised machine learning models often associate irrelevant nuisance factors with the prediction target, which hurts generalization. We propose a framework for training robust neural networks that induces invariance to nuisances through learning to discover and separate predictive and nuisance factors of data. We present an information theoretic formulation of our approach, from which we derive training objectives and its connections with previous methods. Empirical results on a wide array of datasets show that the proposed framework achieves state-of-the-art performance, without requiring nuisance annotations during training.},
	language = {en},
	journal = {arXiv preprint arXiv:1912.00646},
	author = {Jaiswal, Ayush and Brekelmans, Rob and Moyer, Daniel and Steeg, Greg Ver and AbdAlmageed, Wael and Natarajan, Premkumar},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{greenfeld_robust_2020,
	title = {Robust learning with the {Hilbert}-{Schmidt} independence criterion},
	abstract = {We investigate the use of a non-parametric independence measure, the Hilbert-Schmidt Independence Criterion (HSIC), as a loss-function for learning robust regression and classiﬁcation models. This loss-function encourages learning models where the distribution of the residuals between the label and the model prediction is statistically independent of the distribution of the instances themselves. This loss-function was ﬁrst proposed by Mooij et al. (2009) in the context of learning causal graphs. We adapt it to the task of learning for unsupervised covariate shift: learning on a source domain without access to any instances or labels from the unknown target domain, but with the assumption that p(y{\textbar}x) (the conditional probability of labels given instances) remains the same in the target domain. We show that the proposed loss is expected to give rise to models that generalize well on a class of target domains characterised by the complexity of their description within a reproducing kernel Hilbert space. Experiments on unsupervised covariate shift tasks demonstrate that models learned with the proposed loss-function outperform models learned with standard loss functions, achieving state-ofthe-art results on a challenging cell-microscopy unsupervised covariate shift task.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Greenfeld, Daniel and Shalit, Uri},
	year = {2020},
	pages = {3759--3768},
}

@inproceedings{lee_dhrl_2022,
	title = {{DHRL}: {A} graph-based approach for long-horizon and sparse hierarchical reinforcement learning},
	shorttitle = {Dhrl},
	abstract = {Hierarchical Reinforcement Learning (HRL) has made notable progress in complex control tasks by leveraging temporal abstraction. However, previous HRL algorithms often suffer from serious data inefﬁciency as environments get large. The extended components, i.e., goal space and length of episodes, impose a burden on either one or both high-level and low-level policies since both levels share the total horizon of the episode. In this paper, we present a method of Decoupling Horizons Using a Graph in Hierarchical Reinforcement Learning (DHRL) which can alleviate this problem by decoupling the horizons of high-level and low-level policies and bridging the gap between the length of both horizons using a graph. DHRL provides a freely stretchable high-level action interval, which facilitates longer temporal abstraction and faster training in complex tasks. Our method outperforms state-of-the-art HRL algorithms in typical HRL environments. Moreover, DHRL achieves long and complex locomotion and manipulation tasks.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lee, Seungjae and Kim, Jigang and Jang, Inkyu and Kim, H. Jin},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{kim_landmark-guided_2021,
	title = {Landmark-guided subgoal generation in hierarchical reinforcement learning},
	volume = {34},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kim, Junsu and Seo, Younggyo and Shin, Jinwoo},
	year = {2021},
	pages = {28336--28349},
}

@article{balestriero_learning_2021,
	title = {Learning in high dimension always amounts to extrapolation},
	abstract = {The notion of interpolation and extrapolation is fundamental in various ﬁelds from deep learning to function approximation. Interpolation occurs for a sample x whenever this sample falls inside or on the boundary of the given dataset’s convex hull. Extrapolation occurs when x falls outside of that convex hull. One fundamental (mis)conception is that state-of-the-art algorithms work so well because of their ability to correctly interpolate training data. A second (mis)conception is that interpolation happens throughout tasks and datasets, in fact, many intuitions and theories rely on that assumption. We empirically and theoretically argue against those two points and demonstrate that on any high-dimensional ({\textgreater}100) dataset, interpolation almost surely never happens. Those results challenge the validity of our current interpolation/extrapolation definition as an indicator of generalization performances.},
	language = {en},
	journal = {arXiv preprint arXiv:2110.09485},
	author = {Balestriero, Randall and Pesenti, Jerome and LeCun, Yann},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{zhao_what_2021,
	title = {What makes instance discrimination good for transfer learning?},
	abstract = {Contrastive visual pretraining based on the instance discrimination pretext task has made signiﬁcant progress. Notably, recent work on unsupervised pretraining has shown to surpass the supervised counterpart for ﬁnetuning downstream applications such as object detection and segmentation. It comes as a surprise that image annotations would be better left unused for transfer learning. In this work, we investigate the following problems: What makes instance discrimination pretraining good for transfer learning? What knowledge is actually learned and transferred from these models? From this understanding of instance discrimination, how can we better exploit human annotation labels for pretraining? Our ﬁndings are threefold. First, what truly matters for the transfer is low-level and mid-level representations, not high-level representations. Second, the intra-category invariance enforced by the traditional supervised model weakens transferability by increasing task misalignment. Finally, supervised pretraining can be strengthened by following an exemplar-based approach without explicit constraints among the instances within the same category.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Zhao, Nanxuan and Wu, Zhirong and Lau, Rynson W. H. and Lin, Stephen},
	year = {2021},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{wortsman_robust_2022,
	address = {New Orleans, LA, USA},
	title = {Robust fine-tuning of zero-shot models},
	isbn = {978-1-66546-946-3},
	doi = {10.1109/CVPR52688.2022.00780},
	abstract = {Large pre-trained models such as CLIP or ALIGN offer consistent accuracy across a range of data distributions when performing zero-shot inference (i.e., without fine-tuning on a specific dataset). Although existing fine-tuning methods substantially improve accuracy on a given target distribution, they often reduce robustness to distribution shifts. We address this tension by introducing a simple and effective method for improving robustness while fine-tuning: ensembling the weights of the zero-shot and fine-tuned models (WiSE-FT). Compared to standard fine-tuning, WiSE-FT provides large accuracy improvements under distribution shift, while preserving high accuracy on the target distribution. On ImageNet and five derived distribution shifts, WiSE-FT improves accuracy under distribution shift by 4 to 6 percentage points (pp) over prior work while increasing ImageNet accuracy by 1.6 pp. WiSE-FT achieves similarly large robustness gains (2 to 23 pp) on a diverse set of six further distribution shifts, and accuracy gains of 0.8 to 3.3 pp compared to standard fine-tuning on commonly used transfer learning datasets. These improvements come at no additional computational cost during fine-tuning or inference.},
	language = {en},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Lopes, Raphael Gontijo and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and Schmidt, Ludwig},
	year = {2022},
	pages = {7949--7961},
}

@inproceedings{peng_causality-driven_2022,
	title = {Causality-driven hierarchical structure discovery for reinforcement learning},
	abstract = {Hierarchical reinforcement learning (HRL) effectively improve agents’ exploration efﬁciency on tasks with sparse reward, with the guide of high-quality hierarchical structures (e.g., subgoals or options). However, how to automatically discover highquality hierarchical structures is still a great challenge. Previous HRL methods can hardly discover the hierarchical structures in complex environments due to the low exploration efﬁciency by exploiting the randomness-driven exploration paradigm. To address this issue, we propose CDHRL, a causality-driven hierarchical reinforcement learning framework, leveraging a causality-driven discovery instead of a randomness-driven exploration to effectively build high-quality hierarchical structures in complicated environments. The key insight is that the causalities among environment variables are naturally ﬁt for modeling reachable subgoals and their dependencies and can perfectly guide to build high-quality hierarchical structures. The results in two complex environments, 2D-Minecraft and Eden, show that CDHRL signiﬁcantly boosts exploration efﬁciency with the causality-driven paradigm.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Peng, Shaohui and Hu, Xing and Zhang, Rui and Tang, Ke and Guo, Jiaming and Yi, Qi and Chen, Ruizhi and Zhang, Xishan and Du, Zidong and Li, Ling and Guo, Qi and Chen, Yunji},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{kumar_conservative_2020,
	title = {Conservative {Q}-learning for offline reinforcement learning},
	abstract = {Effectively leveraging large, previously collected datasets in reinforcement learning (RL) is a key challenge for large-scale real-world applications. Ofﬂine RL algorithms promise to learn effective policies from previously-collected, static datasets without further interaction. However, in practice, ofﬂine RL presents a major challenge, and standard off-policy RL methods can fail due to overestimation of values induced by the distributional shift between the dataset and the learned policy, especially when training on complex and multi-modal data distributions. In this paper, we propose conservative Q-learning (CQL), which aims to address these limitations by learning a conservative Q-function such that the expected value of a policy under this Q-function lower-bounds its true value. We theoretically show that CQL produces a lower bound on the value of the current policy and that it can be incorporated into a policy learning procedure with theoretical improvement guarantees. In practice, CQL augments the standard Bellman error objective with a simple Q-value regularizer which is straightforward to implement on top of existing deep Q-learning and actor-critic implementations. On both discrete and continuous control domains, we show that CQL substantially outperforms existing ofﬂine RL methods, often learning policies that attain 2-5 times higher ﬁnal return, especially when learning from complex and multi-modal data distributions.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {1179--1191},
}

@inproceedings{xu_fourier-based_2021,
	address = {Nashville, TN, USA},
	title = {A fourier-based framework for domain generalization},
	isbn = {978-1-66544-509-2},
	doi = {10.1109/CVPR46437.2021.01415},
	abstract = {Modern deep neural networks suffer from performance degradation when evaluated on testing data under different distributions from training data. Domain generalization aims at tackling this problem by learning transferable knowledge from multiple source domains in order to generalize to unseen target domains. This paper introduces a novel Fourier-based perspective for domain generalization. The main assumption is that the Fourier phase information contains high-level semantics and is not easily affected by domain shifts. To force the model to capture phase information, we develop a novel Fourier-based data augmentation strategy called amplitude mix which linearly interpolates between the amplitude spectrums of two images. A dual-formed consistency loss called co-teacher regularization is further introduced between the predictions induced from original and augmented images. Extensive experiments on three benchmarks have demonstrated that the proposed method is able to achieve state-of-the-arts performance for domain generalization.},
	language = {en},
	booktitle = {2021 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Xu, Qinwei and Zhang, Ruipeng and Zhang, Ya and Wang, Yanfeng and Tian, Qi},
	year = {2021},
	pages = {14378--14387},
}

@inproceedings{lv_causality_2022,
	address = {New Orleans, LA, USA},
	title = {Causality inspired representation learning for domain generalization},
	isbn = {978-1-66546-946-3},
	doi = {10.1109/CVPR52688.2022.00788},
	language = {en},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Lv, Fangrui and Liang, Jian and Li, Shuang and Zang, Bin and Liu, Chi Harold and Wang, Ziteng and Liu, Di},
	year = {2022},
	pages = {8036--8046},
}

@inproceedings{bayasi_boosternet_2022,
	address = {New Orleans, LA, USA},
	title = {{BoosterNet}: {Improving} domain generalization of deep neural nets using culpability-ranked features},
	isbn = {978-1-66546-946-3},
	shorttitle = {Boosternet},
	doi = {10.1109/CVPR52688.2022.00062},
	abstract = {Deep learning (DL) models trained to minimize empirical risk on a single domain often fail to generalize when applied to other domains. Model failures due to poor generalizability are quite common in practice and may prove quite perilous in mission-critical applications, e.g., diagnostic imaging where real-world data often exhibits pronounced variability. Such limitations have led to increased interest in domain generalization (DG) approaches that improve the ability of models learned from a single or multiple source domains to generalize to out-of-distribution (OOD) test domains. In this work, we propose BoosterNet, a lean add-on network that can be simply appended to any arbitrary core network to improve its generalization capability without requiring any changes in its architecture or training procedure. Specifically, using a novel measure of feature culpability, BoosterNet is trained episodically on the most and least culpable data features extracted from critical units in the core network based on their contribution towards class-specific prediction errors, which have shown to improve generalization. At inference time, corresponding test image features are extracted from the closest classspecific units, determined by smart gating via a Siamese network, and fed to BoosterNet for improved generalization. We evaluate the performance of BoosterNet within two very different classification problems, digits and skin lesions, and demonstrate a marked improvement in model generalization to OOD test domains compared to SOTA.},
	language = {en},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Bayasi, Nourhan and Hamarneh, Ghassan and Garbi, Rafeef},
	year = {2022},
	pages = {528--538},
}

@inproceedings{kornblith_better_2019,
	address = {Long Beach, CA, USA},
	title = {Do better {ImageNet} models transfer better?},
	isbn = {978-1-72813-293-8},
	doi = {10.1109/CVPR.2019.00277},
	abstract = {Transfer learning is a cornerstone of computer vision, yet little work has been done to evaluate the relationship between architecture and transfer. An implicit hypothesis in modern computer vision research is that models that perform better on ImageNet necessarily perform better on other vision tasks. However, this hypothesis has never been systematically tested. Here, we compare the performance of 16 classiﬁcation networks on 12 image classiﬁcation datasets. We ﬁnd that, when networks are used as ﬁxed feature extractors or ﬁne-tuned, there is a strong correlation between ImageNet accuracy and transfer accuracy (r = 0.99 and 0.96, respectively). In the former setting, we ﬁnd that this relationship is very sensitive to the way in which networks are trained on ImageNet; many common forms of regularization slightly improve ImageNet accuracy but yield penultimate layer features that are much worse for transfer learning. Additionally, we ﬁnd that, on two small ﬁne-grained image classiﬁcation datasets, pretraining on ImageNet provides minimal beneﬁts, indicating the learned features from ImageNet do not transfer well to ﬁne-grained tasks. Together, our results show that ImageNet architectures generalize well across datasets, but ImageNet features are less general than previously suggested.},
	language = {en},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Kornblith, Simon and Shlens, Jonathon and Le, Quoc V.},
	year = {2019},
	pages = {2656--2666},
}

@inproceedings{gomez_reversible_2017,
	title = {The reversible residual network: {Backpropagation} without storing activations},
	shorttitle = {The reversible residual network},
	abstract = {Deep residual networks (ResNets) have signiﬁcantly pushed forward the state-ofthe-art on image classiﬁcation, increasing in performance as networks grow both deeper and wider. However, memory consumption becomes a bottleneck, as one needs to store the activations in order to calculate gradients using backpropagation. We present the Reversible Residual Network (RevNet), a variant of ResNets where each layer’s activations can be reconstructed exactly from the next layer’s. Therefore, the activations for most layers need not be stored in memory during backpropagation. We demonstrate the effectiveness of RevNets on CIFAR-10, CIFAR-100, and ImageNet, establishing nearly identical classiﬁcation accuracy to equally-sized ResNets, even though the activation storage requirements are independent of depth.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Gomez, Aidan N. and Ren, Mengye and Urtasun, Raquel and Grosse, Roger B.},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	pages = {2214--2224},
}

@inproceedings{esmaeili_structured_2019,
	title = {Structured disentangled representations},
	abstract = {Deep latent-variable models learn representations of high-dimensional data in an unsupervised manner. A number of recent efforts have focused on learning representations that disentangle statistically independent axes of variation by introducing modiﬁcations to the standard objective function. These approaches generally assume a simple diagonal Gaussian prior and as a result are not able to reliably disentangle discrete factors of variation. We propose a two-level hierarchical objective to control relative degree of statistical independence between blocks of variables and individual variables within blocks. We derive this objective as a generalization of the evidence lower bound, which allows us to explicitly represent the trade-offs between mutual information between data and representation, KL divergence between representation and prior, and coverage of the support of the empirical data distribution. Experiments on a variety of datasets demonstrate that our objective can not only disentangle discrete variables, but that doing so also improves disentanglement of other variables and, importantly, generalization even to unseen combinations of factors.},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Esmaeili, Babak and Wu, Hao and Jain, Sarthak and Bozkurt, Alican and Siddharth, N and Paige, Brooks and Brooks, Dana H},
	year = {2019},
	pages = {2525--2534},
}

@inproceedings{locatello_fairness_2019,
	title = {On the fairness of disentangled representations},
	abstract = {Recently there has been a signiﬁcant interest in learning disentangled representations, as they promise increased interpretability, generalization to unseen scenarios and faster learning on downstream tasks. In this paper, we investigate the usefulness of different notions of disentanglement for improving the fairness of downstream prediction tasks based on representations. We consider the setting where the goal is to predict a target variable based on the learned representation of high-dimensional observations (such as images) that depend on both the target variable and an unobserved sensitive variable. We show that in this setting both the optimal and empirical predictions can be unfair, even if the target variable and the sensitive variable are independent. Analyzing the representations of more than 12 600 trained state-ofthe-art disentangled models, we observe that several disentanglement scores are consistently correlated with increased fairness, suggesting that disentanglement may be a useful property to encourage fairness when sensitive variables are not observed.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Locatello, Francesco and Abbati, Gabriele and Rainforth, Thomas and Bauer, Stefan and Schölkopf, Bernhard and Bachem, Olivier},
	year = {2019},
	pages = {14584--14597},
}

@inproceedings{steenbrugge_improving_2018,
	title = {Improving generalization for abstract reasoning tasks using disentangled feature representations},
	abstract = {In this work we explore the generalization characteristics of unsupervised representation learning by leveraging disentangled VAE’s to learn a useful latent space on a set of relational reasoning problems derived from Raven Progressive Matrices. We show that the latent representations, learned by unsupervised training using the right objective function, signiﬁcantly outperform the same architectures trained with purely supervised learning, especially when it comes to generalization.},
	language = {en},
	booktitle = {{NeurIPS} 2018 {Workshop} on {Relational} {Representation} {Learning}},
	author = {Steenbrugge, Xander and Leroux, Sam and Verbelen, Tim and Dhoedt, Bart},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{locatello_weakly-supervised_2020,
	title = {Weakly-supervised disentanglement without compromises},
	abstract = {Intelligent agents should be able to learn useful representations by observing changes in their environment. We model such observations as pairs of non-i.i.d. images sharing at least one of the underlying factors of variation. First, we theoretically show that only knowing how many factors have changed, but not which ones, is sufﬁcient to learn disentangled representations. Second, we provide practical algorithms that learn disentangled representations from pairs of images without requiring annotation of groups, individual factors, or the number of factors that have changed. Third, we perform a large-scale empirical study and show that such pairs of observations are sufﬁcient to reliably learn disentangled representations on several benchmark data sets. Finally, we evaluate our learned representations and ﬁnd that they are simultaneously useful on a diverse suite of tasks, including generalization under covariate shifts, fairness, and abstract reasoning. Overall, our results demonstrate that weak supervision enables learning of useful disentangled representations in realistic scenarios.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Locatello, Francesco and Poole, Ben and Rätsch, Gunnar and Schölkopf, Bernhard and Bachem, Olivier and Tschannen, Michael},
	year = {2020},
	pages = {6348--6359},
}

@inproceedings{shu_weakly_2020,
	title = {Weakly supervised disentanglement with guarantees},
	abstract = {Learning disentangled representations that correspond to factors of variation in real-world data is critical to interpretable and human-controllable machine learning. Recently, concerns about the viability of learning disentangled representations in a purely unsupervised manner has spurred a shift toward the incorporation of weak supervision. However, there is currently no formalism that identiﬁes when and how weak supervision will guarantee disentanglement. To address this issue, we provide a theoretical framework to assist in analyzing the disentanglement guarantees (or lack thereof) conferred by weak supervision when coupled with learning algorithms based on distribution matching. We empirically verify the guarantees and limitations of several weak supervision methods (restricted labeling, match-pairing, and rank-pairing), demonstrating the predictive power and usefulness of our theoretical framework.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Shu, Rui and Chen, Yining and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{shi_normalized_2000,
	title = {Normalized cuts and image segmentation},
	volume = {22},
	abstract = {ÐWe propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images, as well as motion sequences, and found the results to be very encouraging.},
	language = {en},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Shi, Jianbo and Malik, Jitendra},
	year = {2000},
	pages = {888--905},
}

@inproceedings{kirichenko_why_2020,
	title = {Why normalizing flows fail to detect out-of-distribution data},
	abstract = {Detecting out-of-distribution (OOD) data is crucial for robust machine learning systems. Normalizing ﬂows are ﬂexible deep generative models that often surprisingly fail to distinguish between in- and out-of-distribution data: a ﬂow trained on pictures of clothing assigns higher likelihood to handwritten digits. We investigate why normalizing ﬂows perform poorly for OOD detection. We demonstrate that ﬂows learn local pixel correlations and generic image-to-latentspace transformations which are not speciﬁc to the target image dataset. We show that by modifying the architecture of ﬂow coupling layers we can bias the ﬂow towards learning the semantic structure of the target data, improving OOD detection. Our investigation reveals that properties that enable ﬂows to generate high-ﬁdelity images can have a detrimental eﬀect on OOD detection.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kirichenko, Polina and Izmailov, Pavel and Wilson, Andrew Gordon},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {20578--20589},
}

@article{kirichenko_last_2022,
	title = {Last layer re-training is sufficient for robustness to spurious correlations},
	abstract = {Neural network classiﬁers can largely rely on simple spurious features, such as backgrounds, to make predictions. However, even in these cases, we show that they still often learn core features associated with the desired attributes of the data, contrary to recent ﬁndings. Inspired by this insight, we demonstrate that simple last layer retraining can match or outperform state-of-the-art approaches on spurious correlation benchmarks, but with profoundly lower complexity and computational expenses. Moreover, we show that last layer retraining on large ImageNet-trained models can also signiﬁcantly reduce reliance on background and texture information, improving robustness to covariate shift, after only minutes of training on a single GPU.},
	language = {en},
	journal = {arXiv preprint arXiv:2204.02937},
	author = {Kirichenko, Polina and Izmailov, Pavel and Wilson, Andrew Gordon},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{izmailov_feature_2022,
	title = {On feature learning in the presence of spurious correlations},
	abstract = {Deep classiﬁers are known to rely on spurious features — patterns which are correlated with the target on the training data but not inherently relevant to the learning problem, such as the image backgrounds when classifying the foregrounds. In this paper we evaluate the amount of information about the core (non-spurious) features that can be decoded from the representations learned by standard empirical risk minimization (ERM) and specialized group robustness training. Following recent work on Deep Feature Reweighting (DFR), we evaluate the feature representations by re-training the last layer of the model on a held-out set where the spurious correlation is broken. On multiple vision and NLP problems, we show that the features learned by simple ERM are highly competitive with the features learned by specialized group robustness methods targeted at reducing the effect of spurious correlations. Moreover, we show that the quality of learned feature representations is greatly affected by the design decisions beyond the training method, such as the model architecture and pre-training strategy. On the other hand, we ﬁnd that strong regularization is not necessary for learning high quality feature representations. Finally, using insights from our analysis, we signiﬁcantly improve upon the best results reported in the literature on the popular Waterbirds, CelebA hair color prediction and WILDS-FMOW problems, achieving 97\%, 92\% and 50\% worst-group accuracies, respectively.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Izmailov, Pavel and Kirichenko, Polina and Gruver, Nate and Wilson, Andrew Gordon},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{von_luxburg_tutorial_2007,
	title = {A tutorial on spectral clustering},
	abstract = {In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved eﬃciently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the ﬁrst glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe diﬀerent graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several diﬀerent approaches. Advantages and disadvantages of the diﬀerent spectral clustering algorithms are discussed.},
	language = {en},
	journal = {arXiv preprint arXiv:0711.0189},
	author = {von Luxburg, Ulrike},
	year = {2007},
	keywords = {Computer Science - Machine Learning, Computer Science - Data Structures and Algorithms},
}

@article{hagen_new_1992,
	title = {New spectral methods for ratio cut partitioning and clustering},
	volume = {11},
	issn = {02780070},
	doi = {10.1109/43.159993},
	language = {en},
	number = {9},
	journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Hagen, L. and Kahng, A.B.},
	year = {1992},
	pages = {1074--1085},
}

@inproceedings{ng_spectral_2001,
	title = {On spectral clustering: {Analysis} and an algorithm},
	volume = {14},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ng, Andrew and Jordan, Michael and Weiss, Yair},
	year = {2001},
}

@article{stoer_simple_1997,
	title = {A simple min-cut algorithm},
	volume = {44},
	number = {4},
	journal = {Journal of the ACM (JACM)},
	author = {Stoer, Mechthild and Wagner, Frank},
	year = {1997},
	pages = {585--591},
}

@inproceedings{chua_how_2021,
	title = {How fine-tuning allows for effective meta-learning},
	abstract = {Representation learning has served as a key tool for meta-learning, enabling rapid learning of new tasks. Recent works like MAML learn task-speciﬁc representations by ﬁnding an initial representation requiring minimal per-task adaptation (i.e. a ﬁne-tuning-based objective). We present a theoretical framework for analyzing a MAML-like algorithm, assuming all available tasks require approximately the same representation. We then provide risk bounds on predictors found by ﬁnetuning via gradient descent, demonstrating that the method provably leverages the shared structure. We illustrate these bounds in the logistic regression and neural network settings. In contrast, we establish settings where learning one representation for all tasks (i.e. using a “frozen representation” objective) fails. Notably, any such algorithm cannot outperform directly learning the target task with no other information, in the worst case. This separation underscores the beneﬁt of ﬁne-tuning-based over “frozen representation” objectives in few-shot learning.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chua, Kurtland and Lei, Qi and Lee, Jason D},
	year = {2021},
	pages = {8871--8884},
}

@article{balestriero_effects_2022,
	title = {The effects of regularization and data augmentation are class dependent},
	abstract = {Regularization is a fundamental technique to prevent over-ﬁtting and to improve generalization performances by constraining a model’s complexity. Current Deep Networks heavily rely on regularizers such as Data-Augmentation (DA) or weight-decay, and employ structural risk minimization, i.e. cross-validation, to select the optimal regularization hyper-parameters. In this study, we demonstrate that techniques such as DA or weight decay produce a model with a reduced complexity that is unfair across classes. The optimal amount of DA or weight decay found from cross-validation leads to disastrous model performances on some classes e.g. on Imagenet with a resnet50, the “barn spider” classiﬁcation test accuracy falls from 68\% to 46\% only by introducing random crop DA during training. Even more surprising, such performance drop also appears when introducing uninformative regularization techniques such as weight decay. Those results demonstrate that our search for ever increasing generalization performance -averaged over all classes and samples- has left us with models and regularizers that silently sacriﬁce performances on some classes. This scenario can become dangerous when deploying a model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on INaturalist sees its performances fall from 70\% to 30\% on class \#8889 when introducing random crop DA during the Imagenet pre-training phase. Those results demonstrate that designing novel regularizers without class-dependent bias remains an open research question.},
	language = {en},
	journal = {arXiv preprint arXiv:2204.03632},
	author = {Balestriero, Randall and Bottou, Leon and LeCun, Yann},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{allen-zhu_towards_2023,
	title = {Towards understanding ensemble, knowledge distillation and self-distillation in deep learning},
	abstract = {We formally study how ensemble of deep learning models can improve test accuracy, and how the superior performance of ensemble can be distilled into a single model using knowledge distillation. We consider the challenging case where the ensemble is simply an average of the outputs of a few independently trained neural networks with the same architecture, trained using the same algorithm on the same data set, and they only diﬀer by the random seeds used in the initialization.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
}

@article{nagarajan_explaining_2021,
	title = {Explaining generalization in deep learning: {Progress} and fundamental limits},
	shorttitle = {Explaining generalization in deep learning},
	abstract = {This dissertation studies a fundamental open challenge in deep learning theory: why do deep networks generalize well even while being overparameterized, unregularized and fitting the training data to zero error? In the first part of the thesis, we will empirically study how training deep networks via stochastic gradient descent implicitly controls the networks' capacity. Subsequently, to show how this leads to better generalization, we will derive \{{\textbackslash}em data-dependent\} \{{\textbackslash}em uniform-convergence-based\} generalization bounds with improved dependencies on the parameter count. Uniform convergence has in fact been the most widely used tool in deep learning literature, thanks to its simplicity and generality. Given its popularity, in this thesis, we will also take a step back to identify the fundamental limits of uniform convergence as a tool to explain generalization. In particular, we will show that in some example overparameterized settings, \{{\textbackslash}em any\} uniform convergence bound will provide only a vacuous generalization bound. With this realization in mind, in the last part of the thesis, we will change course and introduce an \{{\textbackslash}em empirical\} technique to estimate generalization using unlabeled data. Our technique does not rely on any notion of uniform-convergece-based complexity and is remarkably precise. We will theoretically show why our technique enjoys such precision. We will conclude by discussing how future work could explore novel ways to incorporate distributional assumptions in generalization bounds (such as in the form of unlabeled data) and explore other tools to derive bounds, perhaps by modifying uniform convergence or by developing completely new tools altogether.},
	language = {en},
	journal = {arXiv preprint arXiv:2110.08922},
	author = {Nagarajan, Vaishnavh},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{wenzel_assaying_2022,
	title = {Assaying out-of-distribution generalization in transfer learning},
	abstract = {Since out-of-distribution generalization is a generally ill-posed problem, various proxy targets (e.g., calibration, adversarial robustness, algorithmic corruptions, invariance across shifts) were studied across different research programs resulting in different recommendations. While sharing the same aspirational goal, these approaches have never been tested under the same experimental conditions on real data. In this paper, we take a uniﬁed view of previous work, highlighting message discrepancies that we address empirically, and providing recommendations on how to measure the robustness of a model and how to improve it. To this end, we collect 172 publicly available dataset pairs for training and out-of-distribution evaluation of accuracy, calibration error, adversarial attacks, environment invariance, and synthetic corruptions. We ﬁne-tune over 31k networks, from nine different architectures in the many- and few-shot setting. Our ﬁndings conﬁrm that in- and out-of-distribution accuracies tend to increase jointly, but show that their relation is largely dataset-dependent, and in general more nuanced and more complex than posited by previous, smaller scale studies1.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wenzel, Florian and Dittadi, Andrea and Gehler, Peter Vincent and Simon-Gabriel, Carl-Johann and Horn, Max and Zietlow, Dominik and Kernert, David and Russell, Chris and Brox, Thomas and Schiele, Bernt and Schölkopf, Bernhard and Locatello, Francesco},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{gelada_deepmdp_2019,
	title = {{DeepMDP}: {Learning} continuous latent space models for representation learning},
	abstract = {Many reinforcement learning (RL) tasks provide the agent with high-dimensional observations that can be simpliﬁed into low-dimensional continuous states. To formalize this process, we introduce the concept of a DeepMDP, a parameterized latent space model that is trained via the minimization of two tractable latent space losses: prediction of rewards and prediction of the distribution over next latent states. We show that the optimization of these objectives guarantees (1) the quality of the embedding function as a representation of the state space and (2) the quality of the DeepMDP as a model of the environment. Our theoretical ﬁndings are substantiated by the experimental result that a trained DeepMDP recovers the latent structure underlying high-dimensional observations on a synthetic environment. Finally, we show that learning a DeepMDP as an auxiliary task in the Atari 2600 domain leads to large performance improvements over model-free RL.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Gelada, Carles and Kumar, Saurabh and Buckman, Jacob and Nachum, Oﬁr and Bellemare, Marc G},
	year = {2019},
	pages = {2170--2179},
}

@article{lake_building_2017,
	title = {Building machines that learn and think like people},
	volume = {40},
	journal = {Behavioral and brain sciences},
	author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
	year = {2017},
}

@inproceedings{huang_self-challenging_2020,
	title = {Self-challenging improves cross-domain generalization},
	booktitle = {European {Conference} on {Computer} {Vision}},
	author = {Huang, Zeyi and Wang, Haohan and Xing, Eric P. and Huang, Dong},
	year = {2020},
	pages = {124--140},
}

@inproceedings{islam_discrete_2022,
	title = {Discrete factorial representations as an abstraction for goal conditioned reinforcement learning},
	abstract = {The multiple steps described above can be summarized by zq = q(ze, L, G), where L is the codebook size, G the number of factors per vector, and q(·) the whole discretization process. We train the representations for both the state and goal observations with this discretization bottleneck applied to the continuous representations resulting from the self-supervised training. The number of factors G is a hyper-parameter. In our experiments, we explored different values: G = 1, 2, 4, 8, 16, and found that G = 16 worked the best. Discretizing with more factors slightly increases computation but reduces the number of model parameters due to the codebook embeddings being reused across the different factors.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Islam, Riashat and Zang, Hongyu and Goyal, Anirudh and Lamb, Alex and Kawaguchi, Kenji and Li, Xin and Laroche, Romain and Bengio, Yoshua and Combes, Remi Tachet Des},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{jahanian_generative_2022,
	title = {Generative models as a data source for multiview representation learning},
	abstract = {Generative models are now capable of producing highly realistic images that look nearly indistinguishable from the data on which they are trained. This raises the question: if we have good enough generative models, do we still need datasets? We investigate this question in the setting of learning general-purpose visual representations from a black-box generative model rather than directly from data. Given an off-the-shelf image generator without any access to its training data, we train representations from the samples output by this generator. We compare several representation learning methods that can be applied to this setting, using the latent space of the generator to generate multiple “views” of the same semantic content. We show that for contrastive methods, this multiview data can naturally be used to identify positive pairs (nearby in latent space) and negative pairs (far apart in latent space). We ﬁnd that the resulting representations rival or even outperform those learned directly from real data, but that good performance requires care in the sampling strategy applied and the training method. Generative models can be viewed as a compressed and organized copy of a dataset, and we envision a future where more and more “model zoos” proliferate while datasets become increasingly unwieldy, missing, or private. This paper suggests several techniques for dealing with visual representation learning in such a future. Code is available on our project page https://ali-design.github.io/GenRep/.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Jahanian, Ali and Puig, Xavier and Tian, Yonglong and Isola, Phillip},
	year = {2022},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{wu_understanding_2020,
	title = {Understanding and improving information transfer in multi-task learning},
	abstract = {We investigate multi-task learning approaches that use a shared feature representation for all tasks. To better understand the transfer of task information, we study an architecture with a shared module for all tasks and a separate output module for each task. We study the theory of this setting on linear and ReLU-activated models. Our key observation is that whether or not tasks’ data are well-aligned can signiﬁcantly affect the performance of multi-task learning. We show that misalignment between task data can cause negative transfer (or hurt performance) and provide sufﬁcient conditions for positive transfer. Inspired by the theoretical insights, we show that aligning tasks’ embedding layers leads to performance gains for multi-task training and transfer learning on the GLUE benchmark and sentiment analysis tasks; for example, we obtain a 2.35\% GLUE score average improvement on 5 GLUE tasks over BERTLARGE using our alignment method. We also design an SVD-based task reweighting scheme and show that it improves the robustness of multi-task training on a multi-label image dataset.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Wu, Sen and Zhang, Hongyang R. and Ré, Christopher},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@book{mclachlan_em_2007,
	title = {The {EM} algorithm and extensions},
	isbn = {0-470-19160-0},
	author = {McLachlan, Geoffrey J. and Krishnan, Thriyambakam},
	year = {2007},
}

@article{muthen_latent_1989,
	title = {Latent variable modeling in heterogeneous populations},
	volume = {54},
	number = {4},
	journal = {Psychometrika},
	author = {Muthén, Bengt O.},
	year = {1989},
	pages = {557--585},
}

@article{muthen_beyond_2002,
	title = {Beyond {SEM}: {General} latent variable modeling},
	volume = {29},
	number = {1},
	journal = {Behaviormetrika},
	author = {Muthén, Bengt O.},
	year = {2002},
	pages = {81--117},
}

@book{skrondal_generalized_2004,
	title = {Generalized latent variable modeling: {Multilevel}, longitudinal, and structural equation models},
	isbn = {0-429-20549-X},
	author = {Skrondal, Anders and Rabe-Hesketh, Sophia},
	year = {2004},
}

@article{kaur_modeling_2022,
	title = {Modeling the data-generating process is necessary for out-of-distribution generalization},
	abstract = {Recent empirical studies on domain generalization (DG) have shown that DG algorithms that perform well on some distribution shifts fail on others, and no state-of-the-art DG algorithm performs consistently well on all shifts. Moreover, real-world data often has multiple distribution shifts over different attributes; hence we introduce multi-attribute distribution shift datasets and ﬁnd that the accuracy of existing DG algorithms falls even further. To explain these results, we provide a formal characterization of generalization under multi-attribute shifts using a canonical causal graph. Based on the relationship between spurious attributes and the classiﬁcation label, we obtain realizations of the canonical causal graph that characterize common distribution shifts and show that each shift entails different independence constraints over observed variables. As a result, we prove that any algorithm based on a single, ﬁxed constraint cannot work well across all shifts, providing theoretical evidence for mixed empirical results on DG algorithms. Based on this insight, we develop Causally Adaptive Constraint Minimization (CACM), an algorithm that uses knowledge about the data-generating process to adaptively identify and apply the correct independence constraints for regularization. Results on fully synthetic, MNIST, small NORB, and Waterbirds datasets, covering binary and multi-valued attributes and labels, show that adaptive dataset-dependent constraints lead to the highest accuracy on unseen domains whereas incorrect constraints fail to do so. Our results demonstrate the importance of modeling the causal relationships inherent in the data-generating process.},
	language = {en},
	journal = {arXiv preprint arXiv:2206.07837},
	author = {Kaur, Jivat Neet and Kiciman, Emre and Sharma, Amit},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{fang_is_2022,
	title = {Is out-of-distribution detection learnable?},
	abstract = {Supervised learning aims to train a classiﬁer under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms. To study the generalization of OOD detection, in this paper, we investigate the probably approximately correct (PAC) learning theory of OOD detection, which is proposed by researchers as an open problem. First, we ﬁnd a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we ﬁnd that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufﬁcient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we also offer theoretical supports for several representative OOD detection works based on our OOD theory.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Fang, Zhen and Li, Yixuan and Lu, Jie and Dong, Jiahua and Han, Bo and Liu, Feng},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{venkateswara_deep_2017,
	title = {Deep hashing network for unsupervised domain adaptation},
	booktitle = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Venkateswara, Hemanth and Eusebio, Jose and Chakraborty, Shayok and Panchanathan, Sethuraman},
	year = {2017},
	pages = {5018--5027},
}

@inproceedings{liu_self-supervised_2022,
	title = {Self-supervised learning is more robust to dataset imbalance},
	abstract = {Self-supervised learning (SSL) is a scalable way to learn general visual representations since it learns without labels. However, large-scale unlabeled datasets in the wild often have long-tailed label distributions, where we know little about the behavior of SSL. In this work, we systematically investigate self-supervised learning under dataset imbalance. First, we ﬁnd out via extensive experiments that oﬀ-the-shelf selfsupervised representations are already more robust to class imbalance than supervised representations. The performance gap between balanced and imbalanced pre-training with SSL is signiﬁcantly smaller than the gap with supervised learning, across sample sizes, for both in-domain and, especially, out-ofdomain evaluation. Second, towards understanding the robustness of SSL, we hypothesize that SSL learns richer features from frequent data: it may learn label-irrelevant-but-transferable features that help classify the rare classes and downstream tasks. In contrast, supervised learning has no incentive to learn features irrelevant to the labels from frequent examples. We validate this hypothesis with semi-synthetic experiments and theoretical analyses on a simpliﬁed setting. Third, inspired by the theoretical insights, we devise a re-weighted regularization technique that consistently improves the SSL representation quality on imbalanced datasets with several evaluation criteria, closing the small gap between balanced and imbalanced datasets with the same number of examples.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Liu, Hong and HaoChen, Jeff Z. and Gaidon, Adrien and Ma, Tengyu},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{haochen_theoretical_2023,
	title = {A theoretical study of inductive biases in contrastive learning},
	abstract = {Understanding self-supervised learning is important but challenging. Previous theoretical works study the role of pretraining losses, and view neural networks as general black boxes. However, the recent work of Saunshi et al. (2022) argues that the model architecture — a component largely ignored by previous works —also has signiﬁcant inﬂuences on the downstream performance of self-supervised learning. In this work, we provide the ﬁrst theoretical analysis of self-supervised learning that incorporates the effect of inductive biases originating from the model class. In particular, we focus on contrastive learning — a popular self-supervised learning method that is widely used in the vision domain. We show that when the model has limited capacity, contrastive representations would recover certain special clustering structures that are compatible with the model architecture, but ignore many other clustering structures in the data distribution. As a result, our theory can capture the more realistic setting where contrastive representations have much lower dimensionality than the number of clusters in the data distribution. We instantiate our theory on several synthetic data distributions, and provide empirical evidence to support the theory.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {HaoChen, Jeff Z. and Ma, Tengyu},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{liu_soft_2022,
	title = {Soft augmentation for image classification},
	abstract = {Modern neural networks are over-parameterized and thus rely on strong regularization such as data augmentation and weight decay to reduce overﬁtting and improve generalization. The dominant form of data augmentation applies invariant transforms, where the learning target of a sample is invariant to the transform applied to that sample. We draw inspiration from human visual classiﬁcation studies and propose generalizing augmentation with invariant transforms to soft augmentation where the learning target softens non-linearly as a function of the degree of the transform applied to the sample: e.g., more aggressive image crop augmentations produce less conﬁdent learning targets. We demonstrate that soft targets allow for more aggressive data augmentation, offer more robust performance boosts, work with other augmentation policies, and interestingly, produce better calibrated models (since they are trained to be less conﬁdent on aggressively cropped/occluded examples). Combined with existing aggressive augmentation strategies, soft target 1) doubles the top-1 accuracy boost across Cifar-10, Cifar-100, ImageNet-1K, and ImageNet-V2, 2) improves model occlusion performance by up to 4×, and 3) halves the expected calibration error (ECE). Finally, we show that soft augmentation generalizes to self-supervised classiﬁcation tasks.},
	language = {en},
	journal = {arXiv preprint arXiv:2211.04625},
	author = {Liu, Yang and Yan, Shen and Leal-Taixé, Laura and Hays, James and Ramanan, Deva},
	year = {2022},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{min_curious_2021,
	title = {The curious case of adversarially robust models: {More} data can help, double descend, or hurt generalization},
	abstract = {Adversarial training has shown its ability in producing models that are robust to perturbations on the input data, but usually at the expense of a decrease in the standard accuracy. To mitigate this issue, it is commonly believed that more training data will eventually help such adversarially robust models generalize better on the benign/unperturbed test data. In this paper, however, we challenge this conventional belief and show that more training data can hurt the generalization of adversarially robust models in classiﬁcation problems. We ﬁrst investigate the Gaussian mixture classiﬁcation with a linear loss and identify three regimes based on the strength of the adversary. In the weak adversary regime, more data improves the generalization of adversarially robust models. In the medium adversary regime, with more training data, the generalization loss exhibits a double descent curve, which implies the existence of an intermediate stage where more training data hurts the generalization. In the strong adversary regime, more data almost immediately causes the generalization error to increase. Then we analyze a two-dimensional classiﬁcation problem with a 0-1 loss. We prove that more data always hurts generalization of adversarially trained models with large perturbations. Empirical studies conﬁrm our theoretical results.},
	language = {en},
	booktitle = {{UAI}},
	author = {Min, Yifei and Chen, Lin and Karbasi, Amin},
	year = {2021},
	pages = {129--139},
}

@inproceedings{tsipras_robustness_2019,
	title = {Robustness may be at odds with accuracy},
	abstract = {We show that there may exist an inherent tension between the goal of adversarial robustness and that of standard generalization. Speciﬁcally, training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. We demonstrate that this trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists in a fairly simple and natural setting. These ﬁndings also corroborate a similar phenomenon observed empirically in more complex settings. Further, we argue that this phenomenon is a consequence of robust classiﬁers learning fundamentally different feature representations than standard classiﬁers. These differences, in particular, seem to result in unexpected beneﬁts: the representations learned by robust models tend to align better with salient data characteristics and human perception.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Ma, Aleksander},
	year = {2019},
}

@article{fawzi_analysis_2018,
	title = {Analysis of classifiers’ robustness to adversarial perturbations},
	volume = {107},
	issn = {1573-0565},
	doi = {10.1007/s10994-017-5663-3},
	abstract = {The goal of this paper is to analyze the intriguing instability of classifiers to adversarial perturbations (Szegedy et al., in: International conference on learning representations (ICLR), 2014). We provide a theoretical framework for analyzing the robustness of classifiers to adversarial perturbations, and show fundamental upper bounds on the robustness of classifiers. Specifically, we establish a general upper bound on the robustness of classifiers to adversarial perturbations, and then illustrate the obtained upper bound on two practical classes of classifiers, namely the linear and quadratic classifiers. In both cases, our upper bound depends on a distinguishability measure that captures the notion of difficulty of the classification task. Our results for both classes imply that in tasks involving small distinguishability, no classifier in the considered set will be robust to adversarial perturbations, even if a good accuracy is achieved. Our theoretical framework moreover suggests that the phenomenon of adversarial instability is due to the low flexibility of classifiers, compared to the difficulty of the classification task (captured mathematically by the distinguishability measure). We further show the existence of a clear distinction between the robustness of a classifier to random noise and its robustness to adversarial perturbations. Specifically, the former is shown to be larger than the latter by a factor that is proportional to \$\${\textbackslash}sqrt\{d\}\$\$(with d being the signal dimension) for linear classifiers. This result gives a theoretical explanation for the discrepancy between the two robustness properties in high dimensional problems, which was empirically observed by Szegedy et al. in the context of neural networks. We finally show experimental results on controlled and real-world data that confirm the theoretical analysis and extend its spirit to more complex classification schemes.},
	language = {en},
	number = {3},
	journal = {Machine Learning},
	author = {Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
	year = {2018},
	keywords = {Adversarial examples, Classification robustness, Deep networks, Instability, Random noise},
	pages = {481--508},
}

@article{teney_id_2022,
	title = {{ID} and {OOD} performance are sometimes inversely correlated on real-world datasets},
	abstract = {Context. Several studies have empirically compared in-distribution (ID) and outof-distribution (OOD) performance of various models. They report frequent positive correlations on benchmarks in computer vision and NLP. Surprisingly, they never observe inverse correlations suggesting necessary trade-offs. This matters to determine whether ID performance can serve as a proxy for OOD generalization.},
	language = {en},
	journal = {arXiv preprint arXiv:2209.00613},
	author = {Teney, Damien and Lin, Yong and Oh, Seong Joon and Abbasnejad, Ehsan},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{yi_improved_2021-1,
	title = {Improved {OOD} generalization via adversarial training and pre-training},
	abstract = {Recently, learning a model that generalizes well on out-of-distribution (OOD) data has attracted great attention in the machine learning community. In this paper, after deﬁning OOD generalization via Wasserstein distance, we theoretically show that a model robust to input perturbation generalizes well on OOD data. Inspired by previous ﬁndings that adversarial training helps improve input-robustness, we theoretically show that adversarially trained models have converged excess risk on OOD data, and empirically verify it on both image classiﬁcation and natural language understanding tasks. Besides, in the paradigm of ﬁrst pre-training and then ﬁne-tuning, we theoretically show that a pre-trained model that is more robust to input perturbation provides a better initialization for generalization on downstream OOD data. Empirically, after ﬁne-tuning, this betterinitialized model from adversarial pre-training also has better OOD generalization.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Yi, Mingyang and Hou, Lu and Sun, Jiacheng and Shang, Lifeng and Jiang, Xin and Liu, Qun and Ma, Zhi-Ming},
	year = {2021},
	pages = {11987--11997},
}

@inproceedings{jia_scaling_2021,
	title = {Scaling up visual and vision-language representation learning with noisy text supervision},
	abstract = {Pre-trained representations are becoming crucial for many NLP and perception tasks. While representation learning in NLP has transitioned to training on raw text without human annotations, visual and vision-language representations still rely heavily on curated training datasets that are expensive or require expert knowledge. For vision applications, representations are mostly learned using datasets with explicit class labels such as ImageNet or OpenImages. For vision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all involve a non-trivial data collection (and cleaning) process. This costly curation process limits the size of datasets and hence hinders the scaling of trained models. In this paper, we leverage a noisy dataset of over one billion image alt-text pairs, obtained without expensive ﬁltering or post-processing steps in the Conceptual Captions dataset. A simple dual-encoder architecture learns to align visual and language representations of the image and text pairs using a contrastive loss. We show that the scale of our corpus can make up for its noise and leads to state-of-the-art representations even with such a simple learning scheme. Our visual representation achieves strong performance when transferred to classiﬁcation tasks such as ImageNet and VTAB. The aligned visual and language representations enables zero-shot image classiﬁcation and also set new state-of-the-art results on Flickr30K and MSCOCO image-text retrieval benchmarks, even when compared with more sophisticated crossattention models. The representations also enable cross-modality search with complex text and text + image queries.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc V. and Sung, Yunhsuan and Li, Zhen and Duerig, Tom},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
	pages = {4904--4916},
}

@article{pham_combined_2022,
	title = {Combined scaling for open-vocabulary image classification},
	language = {en},
	journal = {arXiv preprint arXiv:2111.10050},
	author = {Pham, Hieu and Dai, Zihang and Ghiasi, Golnaz and Kawaguchi, Kenji and Liu, Hanxiao and Yu, Adams Wei and Yu, Jiahui and Chen, Yi-Ting and Luong, Minh-Thang and Wu, Yonghui and Tan, Mingxing and Le, Quoc V.},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
}

@inproceedings{li_blip_2022,
	title = {{BLIP}: {Bootstrapping} language-image pre-training for  unified vision-language understanding and generation},
	abstract = {Vision-Language Pre-training (VLP) has advanced the performance for many vision-language tasks. However, most existing pre-trained models only excel in either understanding-based tasks or generation-based tasks. Furthermore, performance improvement has been largely achieved by scaling up the dataset with noisy image-text pairs collected from the web, which is a suboptimal source of supervision. In this paper, we propose BLIP, a new VLP framework which transfers flexibly to both vision-language understanding and generation tasks. BLIP effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. We achieve state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval (+2.7\% in average recall@1), image captioning (+2.8\% in CIDEr), and VQA (+1.6\% in VQA score). BLIP also demonstrates strong generalization ability when directly transferred to video-language tasks in a zero-shot manner. Code and models are available at https://github. com/salesforce/BLIP.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
	year = {2022},
	pages = {12888--12900},
}

@inproceedings{kim_conditional_2021,
	title = {Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech},
	abstract = {Several recent end-to-end text-to-speech (TTS) models enabling single-stage training and parallel sampling have been proposed, but their sample quality does not match that of two-stage TTS systems. In this work, we present a parallel endto-end TTS method that generates more natural sounding audio than current two-stage models. Our method adopts variational inference augmented with normalizing ﬂows and an adversarial training process, which improves the expressive power of generative modeling. We also propose a stochastic duration predictor to synthesize speech with diverse rhythms from input text. With the uncertainty modeling over latent variables and the stochastic duration predictor, our method expresses the natural one-to-many relationship in which a text input can be spoken in multiple ways with different pitches and rhythms. A subjective human evaluation (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our method outperforms the best publicly available TTS systems and achieves a MOS comparable to ground truth.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
	year = {2021},
	pages = {5530--5540},
}

@article{rame_diverse_2023,
	title = {Diverse weight averaging for out-of-distribution generalization},
	abstract = {Standard neural networks struggle to generalize under distribution shifts in computer vision. Fortunately, combining multiple networks can consistently improve out-of-distribution generalization. In particular, weight averaging (WA) strategies were shown to perform best on the competitive DomainBed benchmark; they directly average the weights of multiple networks despite their nonlinearities. In this paper, we propose Diverse Weight Averaging (DiWA), a new WA strategy whose main motivation is to increase the functional diversity across averaged models. To this end, DiWA averages weights obtained from several independent training runs: indeed, models obtained from different runs are more diverse than those collected along a single run thanks to differences in hyperparameters and training procedures. We motivate the need for diversity by a new bias-variance-covariancelocality decomposition of the expected error, exploiting similarities between WA and standard functional ensembling. Moreover, this decomposition highlights that WA succeeds when the variance term dominates, which we show occurs when the marginal distribution changes at test time. Experimentally, DiWA consistently improves the state of the art on DomainBed without inference overhead.},
	language = {en},
	journal = {arXiv preprint arXiv:2205.09739},
	author = {Ramé, Alexandre and Kirchmeyer, Matthieu and Rahier, Thibaud and Rakotomamonjy, Alain and Gallinari, Patrick and Cord, Matthieu},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{akyurek_what_2023,
	title = {What learning algorithm is in-context learning? {Investigations} with linear models},
	shorttitle = {What learning algorithm is in-context learning?},
	abstract = {Neural sequence models, especially transformers, exhibit a remarkable capacity for in-context learning. They can construct new predictors from sequences of labeled examples (x, f (x)) presented in the input without further parameter updates. We investigate the hypothesis that transformer-based in-context learners implement standard learning algorithms implicitly, by encoding smaller models in their activations, and updating these implicit models as new examples appear in the context. Using linear regression as a prototypical problem, we offer three sources of evidence for this hypothesis. First, we prove by construction that transformers can implement learning algorithms for linear models based on gradient descent and closed-form ridge regression. Second, we show that trained in-context learners closely match the predictors computed by gradient descent, ridge regression, and exact least-squares regression, transitioning between different predictors as transformer depth and dataset noise vary, and converging to Bayesian estimators for large widths and depths. Third, we present preliminary evidence that in-context learners share algorithmic features with these predictors: learners’ late layers non-linearly encode weight vectors and moment matrices. These results suggest that in-context learning is understandable in algorithmic terms, and that (at least in the linear case) learners may rediscover standard estimation algorithms. Code and reference implementations are released at this https link.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Akyürek, Ekin and Schuurmans, Dale and Andreas, Jacob and Ma, Tengyu and Zhou, Denny},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{idnani_dont_2023,
	title = {Don’t forget the nullspace! {Nullspace} occupancy as a mechanism for out of distribution failure},
	abstract = {Out of distribution (OoD) generalization has received considerable interest in recent years. In this work, we identify a particular failure mode of OoD generalization for discriminative classifiers that is based on test data (from a new domain) lying in the nullspace of features learnt from source data. We demonstrate the existence of this failure mode across multiple networks trained across RotatedMNIST, PACS, TerraIncognita, DomainNet and ImageNet-R datasets. We then study different choices for characterizing the feature space and show that projecting intermediate representations onto the span of directions that obtain maximum training accuracy provides consistent improvements in OoD performance. Finally, we show that such nullspace behavior also provides an insight into neural networks trained on poisoned data. We hope our work galvanizes interest in the relationship between the nullspace occupancy failure mode and generalization.},
	language = {en},
	author = {Idnani, Daksh and Madan, Vivek and Goyal, Naman and Schwab, David J. and Vedantam, Shanmukha Ramakrishna},
	year = {2023},
}

@inproceedings{li_sparse_2023,
	title = {Sparse mixture-of-experts are domain generalizable learners},
	abstract = {Human visual perception can easily generalize to out-of-distributed visual data, which is far beyond the capability of modern machine learning models. Domain generalization (DG) aims to close this gap, with existing DG methods mainly focusing on the loss function design. In this paper, we propose to explore an orthogonal direction, i.e., the design of the backbone architecture. It is motivated by an empirical finding that transformer-based models trained with empirical risk minimization (ERM) outperform CNN-based models employing state-of-the-art (SOTA) DG algorithms on multiple DG datasets. We develop a formal framework to characterize a network's robustness to distribution shifts by studying its architecture's alignment with the correlations in the dataset. This analysis guides us to propose a novel DG model built upon vision transformers, namely {\textbackslash}emph\{Generalizable Mixture-of-Experts (GMoE)\}. Extensive experiments on DomainBed demonstrate that GMoE trained with ERM outperforms SOTA DG baselines by a large margin. Moreover, GMoE is complementary to existing DG methods and its performance is substantially improved when trained with DG algorithms.},
	language = {en},
	author = {Li, Bo and Shen, Yifei and Yang, Jingkang and Wang, Yezhen and Ren, Jiawei and Che, Tong and Zhang, Jun and Liu, Ziwei},
	year = {2023},
}

@inproceedings{wang_learning_2019,
	title = {Learning robust global representations by penalizing local predictive power},
	abstract = {Despite their well-documented predictive power on i.i.d. data, convolutional neural networks have been demonstrated to rely more on high-frequency (textural) patterns that humans deem superﬁcial than on low-frequency patterns that agree better with intuitions about what constitutes category membership. This paper proposes a method for training robust convolutional networks by penalizing the predictive power of the local representations learned by earlier layers. Intuitively, our networks are forced to discard predictive signals such as color and texture that can be gleaned from local receptive ﬁelds and to rely instead on the global structure of the image. Across a battery of synthetic and benchmark domain adaptation tasks, our method confers improved generalization. To evaluate cross-domain transfer, we introduce ImageNet-Sketch, a new dataset consisting of sketch-like images and matching the ImageNet classiﬁcation validation set in categories and scale.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wang, Haohan and Ge, Songwei and Xing, Eric P. and Lipton, Zachary C.},
	year = {2019},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {10506--10518},
}

@inproceedings{barbu_objectnet_2019,
	title = {{ObjectNet}: {A} large-scale bias-controlled dataset for pushing the limits of object recognition models},
	abstract = {We collect a large real-world test set, ObjectNet, for object recognition with controls where object backgrounds, rotations, and imaging viewpoints are random. Most scientiﬁc experiments have controls, confounds which are removed from the data, to ensure that subjects cannot perform a task by exploiting trivial correlations in the data. Historically, large machine learning and computer vision datasets have lacked such controls. This has resulted in models that must be ﬁne-tuned for new datasets and perform better on datasets than in real-world applications. When tested on ObjectNet, object detectors show a 40-45\% drop in performance, with respect to their performance on other benchmarks, due to the controls for biases. Controls make ObjectNet robust to ﬁne-tuning showing only small performance increases. We develop a highly automated platform that enables gathering datasets with controls by crowdsourcing image capturing and annotation. ObjectNet is the same size as the ImageNet test set (50,000 images), and by design does not come paired with a training set in order to encourage generalization. The dataset is both easier than ImageNet – objects are largely centered and unoccluded – and harder, due to the controls. Although we focus on object recognition here, data with controls can be gathered at scale using automated tools throughout machine learning to generate datasets that exercise models in new ways thus providing valuable feedback to researchers. This work opens up new avenues for research in generalizable, robust, and more human-like computer vision and in creating datasets where results are predictive of real-world performance.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Barbu, Andrei and Mayo, David and Alverio, Julian and Luo, William and Wang, Christopher and Gutfreund, Dan and Tenenbaum, Josh and Katz, Boris},
	year = {2019},
	pages = {9448--9458},
}

@inproceedings{greydanus_hamiltonian_2019,
	title = {Hamiltonian neural networks},
	abstract = {Even though neural networks enjoy widespread use, they still struggle to learn the basic laws of physics. How might we endow them with better inductive biases? In this paper, we draw inspiration from Hamiltonian mechanics to train models that learn and respect exact conservation laws in an unsupervised manner. We evaluate our models on problems where conservation of energy is important, including the two-body problem and pixel observations of a pendulum. Our model trains faster and generalizes better than a regular neural network. An interesting side effect is that our model is perfectly reversible in time.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Greydanus, Sam and Dzamba, Misko and Yosinski, Jason},
	year = {2019},
	pages = {15353--15363},
}

@inproceedings{jacobsen_i-revnet_2018,
	title = {i-{RevNet}: {Deep} invertible networks},
	shorttitle = {I-revnet},
	abstract = {It is widely believed that the success of deep convolutional networks is based on progressively discarding uninformative variability about the input with respect to the problem at hand. This is supported empirically by the difficulty of recovering images from their hidden representations, in most commonly used network architectures. In this paper we show via a one-to-one mapping that this loss of information is not a necessary condition to learn representations that generalize well on complicated problems, such as ImageNet. Via a cascade of homeomorphic layers, we build the i-RevNet, a network that can be fully inverted up to the ﬁnal projection onto the classes, i.e. no information is discarded. Building an invertible architecture is difﬁcult, for one, because the local inversion is ill-conditioned, we overcome this by providing an explicit inverse. An analysis of i-RevNets learned representations suggests an alternative explanation for the success of deep networks by a progressive contraction and linear separation with depth. To shed light on the nature of the model learned by the i-RevNet we reconstruct linear interpolations between natural image representations.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Jacobsen, Jörn-Henrik and Smeulders, Arnold and Oyallon, Edouard},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{chang_reversible_2018,
	title = {Reversible architectures for arbitrarily deep residual neural networks},
	volume = {32},
	isbn = {2374-3468},
	booktitle = {Proceedings of the {AAAI} conference on artificial intelligence},
	author = {Chang, Bo and Meng, Lili and Haber, Eldad and Ruthotto, Lars and Begert, David and Holtham, Elliot},
	year = {2018},
	pages = {2811--2818},
}

@inproceedings{dosovitskiy_inverting_2016,
	address = {Las Vegas, NV, USA},
	title = {Inverting visual representations with convolutional networks},
	isbn = {978-1-4673-8851-1},
	doi = {10.1109/CVPR.2016.522},
	abstract = {Feature representations, both hand-designed and learned ones, are often hard to analyze and interpret, even when they are extracted from visual data. We propose a new approach to study image representations by inverting them with an up-convolutional neural network. We apply the method to shallow representations (HOG, SIFT, LBP), as well as to deep networks. For shallow representations our approach provides signiﬁcantly better reconstructions than existing methods, revealing that there is surprisingly rich information contained in these features. Inverting a deep network trained on ImageNet provides several insights into the properties of the feature representation learned by the network. Most strikingly, the colors and the rough contours of an image can be reconstructed from activations in higher network layers and even from the predicted class probabilities.},
	language = {en},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Dosovitskiy, Alexey and Brox, Thomas},
	year = {2016},
	pages = {4829--4837},
}

@inproceedings{mahendran_understanding_2015,
	address = {Boston, MA, USA},
	title = {Understanding deep image representations by inverting them},
	isbn = {978-1-4673-6964-0},
	doi = {10.1109/CVPR.2015.7299155},
	abstract = {Image representations, from SIFT and Bag of Visual Words to Convolutional Neural Networks (CNNs), are a crucial component of almost any image understanding system. Nevertheless, our understanding of them remains limited. In this paper we conduct a direct analysis of the visual information contained in representations by asking the following question: given an encoding of an image, to which extent is it possible to reconstruct the image itself? To answer this question we contribute a general framework to invert representations. We show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. We then use this technique to study the inverse of recent state-of-theart CNN image representations for the ﬁrst time. Among our ﬁndings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance.},
	language = {en},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Mahendran, Aravindh and Vedaldi, Andrea},
	year = {2015},
	pages = {5188--5196},
}

@inproceedings{saito_maximum_2018,
	address = {Salt Lake City, UT, USA},
	title = {Maximum classifier discrepancy for unsupervised domain adaptation},
	isbn = {978-1-5386-6420-9},
	doi = {10.1109/CVPR.2018.00392},
	abstract = {In this work, we present a method for unsupervised domain adaptation. Many adversarial learning methods train domain classiﬁer networks to distinguish the features as either a source or target and train a feature generator network to mimic the discriminator. Two problems exist with these methods. First, the domain classiﬁer only tries to distinguish the features as a source or target and thus does not consider task-speciﬁc decision boundaries between classes. Therefore, a trained generator can generate ambiguous features near class boundaries. Second, these methods aim to completely match the feature distributions between different domains, which is difﬁcult because of each domain’s characteristics.},
	language = {en},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Saito, Kuniaki and Watanabe, Kohei and Ushiku, Yoshitaka and Harada, Tatsuya},
	year = {2018},
	pages = {3723--3732},
}

@inproceedings{xie_self-training_2020,
	address = {Seattle, WA, USA},
	title = {Self-training with noisy student improves imagenet classification},
	isbn = {978-1-72817-168-5},
	doi = {10.1109/CVPR42600.2020.01070},
	abstract = {We present a simple self-training method that achieves 88.4\% top-1 accuracy on ImageNet, which is 2.0\% better than the state-of-the-art model that requires 3.5B weakly labeled Instagram images. On robustness test sets, it improves ImageNet-A top-1 accuracy from 61.0\% to 83.7\%, reduces ImageNet-C mean corruption error from 45.7 to 28.3, and reduces ImageNet-P mean ﬂip rate from 27.8 to 12.2.},
	language = {en},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V.},
	year = {2020},
	pages = {10684--10695},
}

@inproceedings{zoph_rethinking_2020,
	title = {Rethinking pre-training and self-training},
	volume = {33},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zoph, Barret and Ghiasi, Golnaz and Lin, Tsung-Yi and Cui, Yin and Liu, Hanxiao and Cubuk, Ekin Dogus and Le, Quoc},
	year = {2020},
	pages = {3833--3845},
}

@inproceedings{tolstikhin_mlp-mixer_2021,
	title = {{MLP}-mixer: {An} all-{MLP} architecture for vision},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Tolstikhin, Ilya and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Steiner, Andreas and Keysers, Daniel and Uszkoreit, Jakob and Lucic, Mario and Dosovitskiy, Alexey},
	year = {2021},
	pages = {24261--24272},
}

@article{massart_risk_2006,
	title = {Risk bounds for statistical learning},
	volume = {34},
	number = {5},
	journal = {The Annals of Statistics},
	author = {Massart, Pascal and Nédélec, Élodie},
	year = {2006},
	pages = {2326--2366},
}

@inproceedings{keskar_large-batch_2017,
	title = {On large-batch training for deep learning: {Generalization} gap and sharp minima},
	shorttitle = {On large-batch training for deep learning},
	abstract = {The stochastic gradient descent (SGD) method and its variants are algorithms of choice for many Deep Learning tasks. These methods operate in a small-batch regime wherein a fraction of the training data, say 32–512 data points, is sampled to compute an approximation to the gradient. It has been observed in practice that when using a larger batch there is a degradation in the quality of the model, as measured by its ability to generalize. We investigate the cause for this generalization drop in the large-batch regime and present numerical evidence that supports the view that large-batch methods tend to converge to sharp minimizers of the training and testing functions—and as is well known, sharp minima lead to poorer generalization. In contrast, small-batch methods consistently converge to ﬂat minimizers, and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation. We discuss several strategies to attempt to help large-batch methods eliminate this generalization gap.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
}

@inproceedings{garipov_loss_2018,
	title = {Loss surfaces, mode connectivity, and fast ensembling of {DNNs}},
	abstract = {The loss functions of deep neural networks are complex and their geometric properties are not well understood. We show that the optima of these complex loss functions are in fact connected by simple curves over which training and test accuracy are nearly constant. We introduce a training procedure to discover these high-accuracy pathways between modes. Inspired by this new geometric insight, we also propose a new ensembling method entitled Fast Geometric Ensembling (FGE). Using FGE we can train high-performing ensembles in the time required to train a single model. We achieve improved performance compared to the recent state-of-the-art Snapshot Ensembles, on CIFAR-10, CIFAR-100, and ImageNet.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
	year = {2018},
	pages = {8803--8812},
}

@inproceedings{izmailov_averaging_2018,
	title = {Averaging weights leads to wider optima and better generalization},
	abstract = {Deep neural networks are typically trained by optimizing a loss function with an SGD variant, in conjunction with a decaying learning rate, until convergence. We show that simple averaging of multiple points along the trajectory of SGD, with a cyclical or constant learning rate, leads to better generalization than conventional training. We also show that this Stochastic Weight Averaging (SWA) procedure ﬁnds much ﬂatter solutions than SGD, and approximates the recent Fast Geometric Ensembling (FGE) approach with a single model. Using SWA we achieve notable improvement in test accuracy over conventional SGD training on a range of state-of-the-art residual networks, PyramidNets, DenseNets, and ShakeShake networks on CIFAR-10, CIFAR-100, and ImageNet. In short, SWA is extremely easy to implement, improves generalization, and has almost no computational overhead.},
	language = {en},
	booktitle = {{UAI}},
	author = {Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	pages = {876--885},
}

@inproceedings{foret_sharpness-aware_2021,
	title = {Sharpness-aware minimization for efficiently improving generalization},
	abstract = {In today’s heavily overparameterized models, the value of the training loss provides few guarantees on model generalization ability. Indeed, optimizing only the training loss value, as is commonly done, can easily lead to suboptimal model quality. Motivated by prior work connecting the geometry of the loss landscape and generalization, we introduce a novel, effective procedure for instead simultaneously minimizing loss value and loss sharpness. In particular, our procedure, Sharpness-Aware Minimization (SAM), seeks parameters that lie in neighborhoods having uniformly low loss; this formulation results in a minmax optimization problem on which gradient descent can be performed efﬁciently. We present empirical results showing that SAM improves model generalization across a variety of benchmark datasets (e.g., CIFAR-\{10, 100\}, ImageNet, ﬁnetuning tasks) and models, yielding novel state-of-the-art performance for several. Additionally, we ﬁnd that SAM natively provides robustness to label noise on par with that provided by state-of-the-art procedures that speciﬁcally target learning with noisy labels. We open source our code at https: //github.com/google-research/sam.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{dziugaite_computing_2017-1,
	title = {Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data},
	abstract = {One of the deﬁning properties of deep learning is that models are chosen to have many more parameters than available training data. In light of this capacity for overﬁtting, it is remarkable that simple algorithms like SGD reliably return solutions with low test error. One roadblock to explaining these phenomena in terms of implicit regularization, structural properties of the solution, and/or easiness of the data is that many learning bounds are quantitatively vacuous when applied to networks learned by SGD in this “deep learning” regime. Logically, in order to explain generalization, we need nonvacuous bounds. We return to an idea by Langford and Caruana (2001), who used PAC-Bayes bounds to compute nonvacuous numerical bounds on generalization error for stochastic two-layer two-hidden-unit neural networks via a sensitivity analysis. By optimizing the PAC-Bayes bound directly, we are able to extend their approach and obtain nonvacuous generalization bounds for deep stochastic neural network classiﬁers with millions of parameters trained on only tens of thousands of examples. We connect our ﬁndings to recent and old work on ﬂat minima and MDL-based explanations of generalization.},
	language = {en},
	booktitle = {{UAI}},
	author = {Dziugaite, Gintare Karolina and Roy, Daniel M.},
	year = {2017},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{shao_theory_2022,
	title = {A theory of {PAC} learnability under transformation invariances},
	abstract = {Transformation invariances are present in many real-world problems. For example, image classification is usually invariant to rotation and color transformation: a rotated car in a different color is still identiﬁed as a car. Data augmentation, which adds the transformed data into the training set and trains a model on the augmented data, is one commonly used technique to build these invariances into the learning process. However, it is unclear how data augmentation performs theoretically and what the optimal algorithm is in presence of transformation invariances. In this paper, we study PAC learnability under transformation invariances in three settings according to different levels of realizability: (i) A hypothesis ﬁts the augmented data; (ii) A hypothesis ﬁts only the original data and the transformed data lying in the support of the data distribution; (iii) Agnostic case. One interesting observation is that distinguishing between the original data and the transformed data is necessary to achieve optimal accuracy in setting (ii) and (iii), which implies that any algorithm not differentiating between the original and transformed data (including data augmentation) is not optimal. Furthermore, this type of algorithms can even “harm” the accuracy. In setting (i), although it is unnecessary to distinguish between the two data sets, data augmentation still does not perform optimally. Due to such a difference, we propose two combinatorial measures characterizing the optimal sample complexity in setting (i) and (ii)(iii) and provide the optimal algorithms.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Shao, Han and Montasser, Omar and Blum, Avrim},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{ma_image_2023,
	title = {Image as set of points},
	abstract = {What is an image, and how to extract latent features? Convolutional Networks (ConvNets) consider an image as organized pixels in a rectangular shape and extract features via convolutional operation in a local region; Vision Transformers (ViTs) treat an image as a sequence of patches and extract features via attention mechanism in a global range. In this work, we introduce a straightforward and promising paradigm for visual representation, which is called Context Clusters. Context clusters (CoCs) view an image as a set of unorganized points and extract features via a simplified clustering algorithm. In detail, each point includes the raw feature (e.g., color) and positional information (e.g., coordinates), and a simplified clustering algorithm is employed to group and extract deep features hierarchically. Our CoCs are convolution- and attention-free, only relying on clustering algorithm for spatial interaction. Owing to the simple design, we show CoCs endow gratifying interpretability via the visualization of the clustering process. Our CoCs aim at providing a new perspective on image and visual representation, which may enjoy broad applications in different domains and exhibit profound insights. Even though we are not targeting SOTA performance, COCs still achieve comparable or even better performance than ConvNets or ViTs on several benchmarks.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Ma, Xu and Zhou, Yuqian and Wang, Huan and Qin, Can and Sun, Bin and Liu, Chang and Fu, Yun},
	year = {2023},
}

@inproceedings{shah_pitfalls_2020,
	title = {The pitfalls of simplicity bias in neural networks},
	abstract = {Several works have proposed Simplicity Bias (SB)—the tendency of standard training procedures such as Stochastic Gradient Descent (SGD) to ﬁnd simple models—to justify why neural networks generalize well [1, 49, 74]. However, the precise notion of simplicity remains vague. Furthermore, previous settings [67, 24] that use SB to justify why neural networks generalize well do not simultaneously capture the non-robustness of neural networks—a widely observed phenomenon in practice [71, 36]. We attempt to reconcile SB and the superior standard generalization of neural networks with the non-robustness observed in practice by introducing piecewise-linear and image-based datasets, which (a) incorporate a precise notion of simplicity, (b) comprise multiple predictive features with varying levels of simplicity, and (c) capture the non-robustness of neural networks trained on real data. Through theoretical analysis and targeted experiments on these datasets, we make four observations: (i) SB of SGD and variants can be extreme: neural networks can exclusively rely on the simplest feature and remain invariant to all predictive complex features. (ii) The extreme aspect of SB could explain why seemingly benign distribution shifts and small adversarial perturbations signiﬁcantly degrade model performance. (iii) Contrary to conventional wisdom, SB can also hurt generalization on the same data distribution, as SB persists even when the simplest feature has less predictive power than the more complex features.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Shah, Harshay and Tamuly, Kaustav and Raghunathan, Aditi},
	year = {2020},
}

@inproceedings{kalimeris_sgd_2019,
	title = {{SGD} on neural networks learns functions of increasing complexity},
	abstract = {We perform an experimental study of the dynamics of Stochastic Gradient Descent (SGD) in learning deep neural networks for several real and synthetic classiﬁcation tasks. We show that in the initial epochs, almost all of the performance improvement of the classiﬁer obtained by SGD can be explained by a linear classiﬁer. More generally, we give evidence for the hypothesis that, as iterations progress, SGD learns functions of increasing complexity. This hypothesis can be helpful in explaining why SGD-learned classiﬁers tend to generalize well even in the overparameterized regime. We also show that the linear classiﬁer learned in the initial stages is “retained” throughout the execution even if training is continued to the point of zero training error, and complement this with a theoretical result in a simpliﬁed model. Key to our work is a new measure of how well one classiﬁer explains the performance of another, based on conditional mutual information.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Kalimeris, Dimitris and Kaplun, Gal and Nakkiran, Preetum and Edelman, Benjamin and Yang, Tristan and Barak, Boaz and Zhang, Haofeng},
	year = {2019},
	pages = {3491--3501},
}

@inproceedings{teney_evading_2022,
	address = {New Orleans, LA, USA},
	title = {Evading the simplicity bias: {Training} a diverse set of models discovers solutions with superior {OOD} generalization},
	isbn = {978-1-66546-946-3},
	shorttitle = {Evading the simplicity bias},
	doi = {10.1109/CVPR52688.2022.01626},
	abstract = {Neural networks trained with SGD were recently shown to rely preferentially on linearly-predictive features and can ignore complex, equally-predictive ones. This simplicity bias can explain their lack of robustness out of distribution (OOD). The more complex the task to learn, the more likely it is that statistical artifacts (i.e. selection biases, spurious correlations) are simpler than the mechanisms to learn.},
	language = {en},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Teney, Damien and Abbasnejad, Ehsan and Lucey, Simon and Van den Hengel, Anton},
	year = {2022},
	pages = {16740--16751},
}

@inproceedings{lyu_gradient_2021,
	title = {Gradient descent on two-layer nets: {Margin} maximization and simplicity bias},
	abstract = {The generalization mystery of overparametrized deep nets has motivated efforts to understand how gradient descent (GD) converges to low-loss solutions that generalize well. Real-life neural networks are initialized from small random values and trained with cross-entropy loss for classiﬁcation (unlike the "lazy" or "NTK" regime of training where analysis was more successful), and a recent sequence of results (Lyu and Li, 2020; Chizat and Bach, 2020; Ji and Telgarsky, 2020a) provide theoretical evidence that GD may converge to the "max-margin" solution with zero loss, which presumably generalizes well. However, the global optimality of margin is proved only in some settings where neural nets are inﬁnitely or exponentially wide. The current paper is able to establish this global optimality for two-layer Leaky ReLU nets trained with gradient ﬂow on linearly separable and symmetric data, regardless of the width. The analysis also gives some theoretical justiﬁcation for recent empirical ﬁndings (Kalimeris et al., 2019) on the so-called simplicity bias of GD towards linear or other "simple" classes of solutions, especially early in training. On the pessimistic side, the paper suggests that such results are fragile. A simple data manipulation can make gradient ﬂow converge to a linear classiﬁer with suboptimal margin.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lyu, Kaifeng and Wang, Runzhe and Li, Zhiyuan and Arora, Sanjeev},
	year = {2021},
	pages = {12978--12991},
}

@inproceedings{nam_learning_2020,
	title = {Learning from failure: {Training} debiased classifier from biased classifier},
	abstract = {Neural networks often learn to make predictions that overly rely on spurious correlation existing in the dataset, which causes the model to be biased. While previous work tackles this issue by using explicit labeling on the spuriously correlated attributes or presuming a particular bias type, we instead utilize a cheaper, yet generic form of human knowledge, which can be widely applicable to various types of bias. We ﬁrst observe that neural networks learn to rely on the spurious correlation only when it is “easier” to learn than the desired knowledge, and such reliance is most prominent during the early phase of training. Based on the observations, we propose a failure-based debiasing scheme by training a pair of neural networks simultaneously. Our main idea is twofold; (a) we intentionally train the ﬁrst network to be biased by repeatedly amplifying its “prejudice”, and (b) we debias the training of the second network by focusing on samples that go against the prejudice of the biased network in (a). Extensive experiments demonstrate that our method signiﬁcantly improves the training of network against various types of biases in both synthetic and real-world datasets. Surprisingly, our framework even occasionally outperforms the debiasing methods requiring explicit supervision of the spuriously correlated attributes.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Nam, Junhyun and Cha, Hyuntak and Ahn, Sungsoo and Lee, Jaeho and Shin, Jinwoo},
	year = {2020},
	pages = {20673--20684},
}

@inproceedings{hu_surprising_2020,
	title = {The surprising simplicity of the early-time learning dynamics of neural networks},
	abstract = {Modern neural networks are often regarded as complex black-box functions whose behavior is difﬁcult to understand owing to their nonlinear dependence on the data and the nonconvexity in their loss landscapes. In this work, we show that these common perceptions can be completely false in the early phase of learning. In particular, we formally prove that, for a class of well-behaved input distributions, the early-time learning dynamics of a two-layer fully-connected neural network can be mimicked by training a simple linear model on the inputs. We additionally argue that this surprising simplicity can persist in networks with more layers and with convolutional architecture, which we verify empirically. Key to our analysis is to bound the spectral norm of the difference between the Neural Tangent Kernel (NTK) at initialization and an afﬁne transform of the data kernel; however, unlike many previous results utilizing the NTK, we do not require the network to have disproportionately large width, and the network is allowed to escape the kernel regime later in training.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Hu, Wei and Xiao, Lechao and Adlam, Ben and Pennington, Jeffrey},
	year = {2020},
	pages = {17116--17128},
}

@inproceedings{liu_flow_2022,
	title = {Flow straight and fast: {Learning} to generate and transfer data with rectified flow},
	shorttitle = {Flow straight and fast},
	abstract = {We present rectiﬁed ﬂow, a surprisingly simple approach to learning (neural) ordinary differential equation (ODE) models to transport between two empirically observed distributions π0 and π1, hence providing a uniﬁed solution to generative modeling and domain transfer, among various other tasks involving distribution transport. The idea of rectiﬁed ﬂow is to learn the ODE to follow the straight paths connecting the points drawn from π0 and π1 as much as possible. This is achieved by solving a straightforward nonlinear least squares optimization problem, which can be easily scaled to large models without introducing extra parameters beyond standard supervised learning. The straight paths are special and preferred because they are the shortest paths between two points, and can be simulated exactly without time discretization and hence yield computationally efﬁcient models. We show that the procedure of learning a rectiﬁed ﬂow from data, called rectiﬁcation, turns an arbitrary coupling of π0 and π1 to a new deterministic coupling with provably non-increasing convex transport costs. In addition, recursively applying rectiﬁcation allows us to obtain a sequence of ﬂows with increasingly straight paths, which can be simulated accurately with coarse time discretization in the inference phase. In empirical studies, we show that rectiﬁed ﬂow performs superbly on image generation, image-to-image translation, and domain adaptation. In particular, on image generation and translation, our method yields nearly straight ﬂows that give high quality results even with a single Euler discretization step.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{zhao_egsde_2022,
	title = {{EGSDE}: {Unpaired} image-to-image translation via energy-guided stochastic differential equations},
	shorttitle = {Egsde},
	abstract = {Score-based diffusion models (SBDMs) have achieved the SOTA FID results in unpaired image-to-image translation (I2I). However, we notice that existing methods totally ignore the training data in the source domain, leading to sub-optimal solutions for unpaired I2I. To this end, we propose energy-guided stochastic differential equations (EGSDE) that employs an energy function pretrained on both the source and target domains to guide the inference process of a pretrained SDE for realistic and faithful unpaired I2I. Building upon two feature extractors, we carefully design the energy function such that it encourages the transferred image to preserve the domain-independent features and discard domain-speciﬁc ones. Further, we provide an alternative explanation of the EGSDE as a product of experts, where each of the three experts (corresponding to the SDE and two feature extractors) solely contributes to faithfulness or realism. Empirically, we compare EGSDE to a large family of baselines on three widely-adopted unpaired I2I tasks under four metrics. EGSDE not only consistently outperforms existing SBDMs-based methods in almost all settings but also achieves the SOTA realism results without harming the faithful performance. Furthermore, EGSDE allows for ﬂexible trade-offs between realism and faithfulness and we improve the realism results further (e.g., FID of 51.04 in Cat → Dog and FID of 50.43 in Wild → Dog on AFHQ) by tuning hyper-parameters. The code is available at https://github.com/ML-GSAI/EGSDE.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhao, Min and Bao, Fan and Li, Chongxuan and Zhu, Jun},
	year = {2022},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{su_dual_2023,
	title = {Dual diffusion implicit bridges for image-to-image translation},
	abstract = {Common image-to-image translation methods rely on joint training over data from both source and target domains. The training process requires concurrent access to both datasets, which hinders data separation and privacy protection; and existing models cannot be easily adapted for translation of new domain pairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation method based on diffusion models, that circumvents training on domain pairs. Image translation with DDIBs relies on two diffusion models trained independently on each domain, and is a two-step process: DDIBs first obtain latent encodings for source images with the source diffusion model, and then decode such encodings using the target model to construct target images. Both steps are defined via ordinary differential equations (ODEs), thus the process is cycle consistent only up to discretization errors of the ODE solvers. Theoretically, we interpret DDIBs as concatenation of source to latent, and latent to target Schro¨dinger Bridges, a form of entropy-regularized optimal transport, to explain the efficacy of the method. Experimentally, we apply DDIBs on synthetic and high-resolution image datasets, to demonstrate their utility in a wide variety of translation tasks and their inherent optimal transport properties.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Su, Xuan and Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
	year = {2023},
}

@article{li_towards_2021,
	title = {Towards an understanding of benign overfitting in neural networks},
	journal = {arXiv preprint arXiv:2106.03212},
	author = {Li, Zhu and Zhou, Zhi-Hua and Gretton, Arthur},
	year = {2021},
}

@inproceedings{shamir_implicit_2022,
	title = {The implicit bias of benign overfitting},
	abstract = {The phenomenon of benign overﬁtting, where a predictor perfectly ﬁts noisy training data while attaining low expected loss, has received much attention in recent years, but still remains not fully understood beyond simple linear regression setups. In this paper, we show that for regression, benign overﬁtting is “biased” towards certain types of problems, in the sense that its existence on one learning problem precludes its existence on other learning problems. On the negative side, we use this to argue that one should not expect benign overﬁtting to occur in general, for several natural extensions of the plain linear regression problems studied so far. We then turn to classiﬁcation problems, and show that the situation there is much more favorable. Speciﬁcally, we consider a model where an arbitrary input distribution of some ﬁxed dimension k is concatenated with a high-dimensional distribution, and prove that the max-margin predictor (to which gradientbased methods are known to converge in direction) is asymptotically biased towards minimizing the expected squared hinge loss w.r.t. the k-dimensional distribution. This allows us to reduce the question of benign overﬁtting in classiﬁcation to the simpler question of whether this loss is a good surrogate for the misclassiﬁcation error, and use it to show benign overﬁtting in some new settings.},
	language = {en},
	booktitle = {{COLT}},
	author = {Shamir, Ohad},
	year = {2022},
	pages = {448--478},
}

@inproceedings{frei_benign_2022,
	title = {Benign overfitting without linearity: {Neural} network classifiers trained by gradient descent for noisy linear data},
	abstract = {Benign overfitting, the phenomenon where interpolating models generalize well in the presence of noisy data, was first observed in neural network models trained with gradient descent. To better understand this empirical observation, we consider the generalization error of two-layer neural networks trained to interpolation by gradient descent on the logistic loss following random initialization. We assume the data comes from well-separated class-conditional log-concave distributions and allow for a constant fraction of the training labels to be corrupted by an adversary. We show that in this setting, neural networks exhibit benign overfitting: they can be driven to zero training error, perfectly fitting any noisy training labels, and simultaneously achieve minimax optimal test error. In contrast to previous work on benign overfitting that require linear or kernel-based predictors, our analysis holds in a setting where both the model and learning dynamics are fundamentally nonlinear.},
	language = {en},
	booktitle = {Conference on {Learning} {Theory}},
	author = {Frei, Spencer and Chatterji, Niladri S and Bartlett, Peter L},
	year = {2022},
	pages = {2668--2703},
}

@article{bartlett_benign_2020,
	title = {Benign overfitting in linear regression},
	volume = {117},
	number = {48},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Bartlett, Peter L. and Long, Philip M. and Lugosi, Gábor and Tsigler, Alexander},
	year = {2020},
	pages = {30063--30070},
}

@article{cao_benign_2022,
	title = {Benign overfitting in two-layer convolutional neural networks},
	journal = {arXiv preprint arXiv:2202.06526},
	author = {Cao, Yuan and Chen, Zixiang and Belkin, Mikhail and Gu, Quanquan},
	year = {2022},
}

@inproceedings{djolonga_robustness_2021,
	address = {Nashville, TN, USA},
	title = {On robustness and transferability of convolutional neural networks},
	isbn = {978-1-66544-509-2},
	doi = {10.1109/CVPR46437.2021.01619},
	abstract = {Modern deep convolutional networks (CNNs) are often criticized for not generalizing under distributional shifts. However, several recent breakthroughs in transfer learning suggest that these networks can cope with severe distribution shifts and successfully adapt to new tasks from a few training examples. In this work we study the interplay between outof-distribution and transfer performance of modern image classiﬁcation CNNs for the ﬁrst time and investigate the impact of the pre-training data size, the model scale, and the data preprocessing pipeline. We ﬁnd that increasing both the training set and model sizes signiﬁcantly improve the distributional shift robustness. Furthermore, we show that, perhaps surprisingly, simple changes in the preprocessing such as modifying the image resolution can signiﬁcantly mitigate robustness issues in some cases. Finally, we outline the shortcomings of existing robustness evaluation datasets and introduce a synthetic dataset SI-SCORE we use for a systematic analysis across factors of variation common in visual data such as object size and position.},
	language = {en},
	booktitle = {2021 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Djolonga, Josip and Yung, Jessica and Tschannen, Michael and Romijnders, Rob and Beyer, Lucas and Kolesnikov, Alexander and Puigcerver, Joan and Minderer, Matthias and D'Amour, Alexander and Moldovan, Dan and Gelly, Sylvain and Houlsby, Neil and Zhai, Xiaohua and Lucic, Mario},
	year = {2021},
	pages = {16453--16463},
}

@inproceedings{ahn_as_2022,
	title = {Do as {I} can, not as {I} say: {Grounding} language in robotic affordances},
	shorttitle = {Do as i can, not as i say},
	abstract = {Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a signiﬁcant weakness of language models is that they lack real-world experience, which makes it difﬁcult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model’s “hands and eyes,” while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project’s website, the video, and open sourced code in a tabletop domain can be found at say-can.github.io.},
	language = {en},
	booktitle = {{CoRL}},
	author = {Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Ho, Daniel and Hsu, Jasmine and Ibarz, Julian and Ichter, Brian and Irpan, Alex and Jang, Eric and Ruano, Rosario Jauregui and Jeffrey, Kyle and Jesmonth, Sally and Joshi, Nikhil J. and Julian, Ryan and Kalashnikov, Dmitry and Kuang, Yuheng and Lee, Kuang-Huei and Levine, Sergey and Lu, Yao and Luu, Linda and Parada, Carolina and Pastor, Peter and Quiambao, Jornell and Rao, Kanishka and Rettinghouse, Jarek and Reyes, Diego and Sermanet, Pierre and Sievers, Nicolas and Tan, Clayton and Toshev, Alexander and Vanhoucke, Vincent and Xia, Fei and Xiao, Ted and Xu, Peng and Xu, Sichun and Yan, Mengyuan and Zeng, Andy},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics, Computer Science - Computation and Language},
}

@article{driess_palm-e_2023,
	title = {{PALM}-{E}: {An} embodied multimodal language model},
	shorttitle = {Palm-e},
	abstract = {Large language models have been demonstrated to perform complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multi-modal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pretrained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model beneﬁts from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model, PaLM-E-562B with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.},
	language = {en},
	journal = {arXiv preprint arXiv: 2303.03378},
	author = {Driess, Danny and Xia, Fei and Sajjadi, Mehdi S. M. and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and Huang, Wenlong and Chebotar, Yevgen and Sermanet, Pierre and Duckworth, Daniel and Levine, Sergey and Vanhoucke, Vincent and Hausman, Karol and Toussaint, Marc and Greff, Klaus and Zeng, Andy and Mordatch, Igor and Florence, Pete},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@article{bommasani_opportunities_2022,
	title = {On the opportunities and risks of foundation models},
	abstract = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
	language = {en},
	journal = {arXiv preprint arXiv:2108.07258},
	author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
}

@article{zhou_learning_2022,
	title = {Learning to prompt for vision-language models},
	volume = {130},
	issn = {0920-5691, 1573-1405},
	doi = {10.1007/s11263-022-01653-1},
	abstract = {Large pre-trained vision-language models like CLIP have shown great potential in learning representations that are transferable across a wide range of downstream tasks. Different from the traditional representation learning that is based mostly on discretized labels, vision-language pre-training aligns images and texts in a common feature space, which allows zero-shot transfer to a downstream task via prompting, i.e., classification weights are synthesized from natural language describing classes of interest. In this work, we show that a major challenge for deploying such models in practice is prompt engineering, which requires domain expertise and is extremely time-consuming -- one needs to spend a significant amount of time on words tuning since a slight change in wording could have a huge impact on performance. Inspired by recent advances in prompt learning research in natural language processing (NLP), we propose Context Optimization (CoOp), a simple approach specifically for adapting CLIP-like vision-language models for downstream image recognition. Concretely, CoOp models a prompt's context words with learnable vectors while the entire pre-trained parameters are kept fixed. To handle different image recognition tasks, we provide two implementations of CoOp: unified context and class-specific context. Through extensive experiments on 11 datasets, we demonstrate that CoOp requires as few as one or two shots to beat hand-crafted prompts with a decent margin and is able to gain significant improvements over prompt engineering with more shots, e.g., with 16 shots the average gain is around 15\% (with the highest reaching over 45\%). Despite being a learning-based approach, CoOp achieves superb domain generalization performance compared with the zero-shot model using hand-crafted prompts.},
	language = {en},
	number = {9},
	journal = {International Journal of Computer Vision},
	author = {Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	pages = {2337--2348},
}

@inproceedings{zhou_conditional_2022,
	address = {New Orleans, LA, USA},
	title = {Conditional prompt learning for vision-language models},
	isbn = {978-1-66546-946-3},
	doi = {10.1109/CVPR52688.2022.01631},
	abstract = {With the rise of powerful pre-trained vision-language models like CLIP, it becomes essential to investigate ways to adapt these models to downstream datasets. A recently proposed method named Context Optimization (CoOp) introduces the concept of prompt learning—a recent trend in NLP—to the vision domain for adapting pre-trained visionlanguage models. Specifically, CoOp turns context words in a prompt into a set of learnable vectors and, with only a few labeled images for learning, can achieve huge improvements over intensively-tuned manual prompts. In our study we identify a critical problem of CoOp: the learned context is not generalizable to wider unseen classes within the same dataset, suggesting that CoOp overfits base classes observed during training. To address the problem, we propose Conditional Context Optimization (CoCoOp), which extends CoOp by further learning a lightweight neural network to generate for each image an input-conditional token (vector). Compared to CoOp’s static prompts, our dynamic prompts adapt to each instance and are thus less sensitive to class shift. Extensive experiments show that CoCoOp generalizes much better than CoOp to unseen classes, even showing promising transferability beyond a single dataset; and yields stronger domain generalization performance as well. Code is available at https://github.com/ KaiyangZhou/CoOp.},
	language = {en},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
	year = {2022},
	pages = {16795--16804},
}

@inproceedings{ju_robust_2022,
	title = {Robust fine-tuning of deep neural networks with hessian-based generalization guarantees},
	abstract = {We consider transfer learning approaches that finetune a pretrained deep neural network on a target task. We investigate generalization properties of fine-tuning to understand the problem of overfitting, which often happens in practice. Previous works have shown that constraining the distance from the initialization of fine-tuning improves generalization. Using a PAC-Bayesian analysis, we observe that besides distance from initialization, Hessians affect generalization through the noise stability of deep neural networks against noise injections. Motivated by the observation, we develop Hessian distance-based generalization bounds for a wide range of fine-tuning methods. Next, we investigate the robustness of fine-tuning with noisy labels. We design an algorithm that incorporates consistent losses and distance-based regularization for fine-tuning. Additionally, we prove a generalization error bound of our algorithm under class conditional independent noise in the training dataset labels. We perform a detailed empirical study of our algorithm on various noisy environments and architectures. For example, on six image classification tasks whose training labels are generated with programmatic labeling, we show a 3.26\% accuracy improvement over prior methods. Meanwhile, the Hessian distance measure of the fine-tuned network using our algorithm decreases by six times more than existing approaches.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Ju, Haotian and Li, Dongyue and Zhang, Hongyang R},
	year = {2022},
}

@article{ren_delving_2022,
	title = {Delving into the openness of {CLIP}},
	abstract = {Contrastive Language-Image Pre-training (CLIP) has demonstrated great potential in realizing open-vocabulary visual recognition in a matching style, due to its holistic use of natural language supervision that covers unconstrained real-world visual concepts. However, it is, in turn, also difficult to evaluate and analyze the openness of CLIP-like models, since they are in theory open to any vocabulary but the actual accuracy varies. To address the insufficiency of conventional studies on openness, we resort to an incremental perspective and define the extensibility, which essentially approximates the model's ability to deal with new visual concepts, by evaluating openness through vocabulary expansions. Our evaluation based on extensibility shows that CLIP-like models are hardly truly open and their performance degrades as the vocabulary expands to different degrees. Further analysis reveals that the over-estimation of openness is not because CLIP-like models fail to capture the general similarity of image and text features of novel visual concepts, but because of the confusion among competing text features, that is, they are not stable with respect to the vocabulary. In light of this, we propose to improve the openness of CLIP in the feature space by enforcing the distinguishability of text features. Our method retrieves relevant texts from the pre-training corpus to enhance prompts for inference, which boosts the extensibility and stability of CLIP even without fine-tuning.},
	language = {en},
	journal = {arXiv preprint arXiv:2206.01986},
	author = {Ren, Shuhuai and Li, Lei and Ren, Xuancheng and Zhao, Guangxiang and Sun, Xu},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
}

@article{ding_dont_2022,
	title = {Don't stop learning: {Towards} continual learning for the {CLIP} model},
	shorttitle = {Don't stop learning},
	abstract = {The Contrastive Language-Image Pre-training (CLIP) Model is a recently proposed large-scale pre-train model which attracts increasing attention in the computer vision community. Beneﬁting from its gigantic image-text training set, the CLIP model has learned outstanding capabilities in zeroshot learning and image-text matching. To boost the recognition performance of CLIP on some target visual concepts, it is often desirable to further update the CLIP model by ﬁne-tuning some classes-of-interest on extra training data. This operation, however, raises an important concern: will the update hurt the zeroshot learning or image-text matching capability of the CLIP, i.e., the catastrophic forgetting issue? If yes, could existing continual learning algorithms be adapted to alleviate the risk of catastrophic forgetting? To answer these questions, this work conducts a systemic study on the continual learning issue of the CLIP model. We construct evaluation protocols to measure the impact of ﬁne-tuning updates and explore different ways to upgrade existing continual learning methods to mitigate the forgetting issue of the CLIP model. Our study reveals the particular challenges of CLIP continual learning problem and lays a foundation for further researches. Moreover, we propose a new algorithm, dubbed Learning without Forgetting via Replayed Vocabulary (VR-LwF), which shows exact effectiveness for alleviating the forgetting issue of the CLIP model.},
	language = {en},
	journal = {arXiv preprint arXiv:2207.09248},
	author = {Ding, Yuxuan and Liu, Lingqiao and Tian, Chunna and Yang, Jingyuan and Ding, Haoxuan},
	year = {2022},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{novack_chils_2023,
	title = {Chils: {Zero}-shot image classification with hierarchical label sets},
	shorttitle = {Chils},
	abstract = {Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot classiﬁcation through their ability generate embeddings for each class based on their (natural language) names. Prior work has focused on improving the accuracy of these models through prompt engineering or by incorporating a small amount of labeled downstream data (via ﬁnetuning). However, there has been little focus on improving the richness of the class names themselves, which can pose issues when class labels are coarselydeﬁned and uninformative. We propose Classiﬁcation with Hierarchical Label Sets (or CHiLS), an alternative strategy for zero-shot classiﬁcation speciﬁcally designed for datasets with implicit semantic hierarchies. CHiLS proceeds in three steps: (i) for each class, produce a set of subclasses, using either existing label hierarchies or by querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though these subclasses were the labels of interest; (iii) map the predicted subclass back to its parent to produce the ﬁnal prediction. Across numerous datasets with underlying hierarchical structure, CHiLS leads to improved accuracy in situations both with and without ground-truth hierarchical information. CHiLS is simple to implement within existing CLIP pipelines and requires no additional training cost. Code is available at: https://github.com/acmi-lab/CHILS.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Novack, Zachary and Garg, Saurabh and McAuley, Julian and Lipton, Zachary C.},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{santurkar_is_2023,
	title = {Is a caption worth a thousand images? {A} controlled study for representation learning},
	shorttitle = {Is a caption worth a thousand images?},
	abstract = {The development of CLIP [RKH+21] has sparked a debate on whether language supervision can result in vision models with more transferable representations than traditional imageonly methods. Our work studies this question through a carefully controlled comparison of two approaches in terms of their ability to learn representations that generalize to downstream classiﬁcation tasks. We ﬁnd that when the pre-training dataset meets certain criteria—it is sufﬁciently large and contains descriptive captions with low variability—image-only methods do not match CLIP’s transfer performance, even when they are trained with more image data. However, contrary to what one might expect, there are practical settings in which these criteria are not met, wherein added supervision through captions is actually detrimental. Motivated by our ﬁndings, we devise simple prescriptions to enable CLIP to better leverage the language information present in existing pre-training datasets.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Santurkar, Shibani and Dubois, Yann and Taori, Rohan and Liang, Percy and Hashimoto, Tatsunori},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{fang_data_2022,
	title = {Data determines distributional robustness in contrastive language-image pre-training ({CLIP})},
	abstract = {Contrastively trained language-image models such as CLIP, ALIGN, and BASIC have demonstrated unprecedented robustness to multiple challenging natural distribution shifts. Since these language-image models differ from previous training approaches in several ways, an important question is what causes the large robustness gains. We answer this question via a systematic experimental investigation. Concretely, we study ﬁve different possible causes for the robustness gains: (i) the training set size, (ii) the training distribution, (iii) language supervision at training time, (iv) language supervision at test time, and (v) the contrastive loss function. Our experiments show that the more diverse training distribution is the main cause for the robustness gains, with the other factors contributing little to no robustness. Beyond our experimental results, we also introduce ImageNet-Captions, a version of ImageNet with original text annotations from Flickr, to enable further controlled experiments of language-image training.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Fang, Alex and Ilharco, Gabriel and Wortsman, Mitchell and Wan, Yuhao and Shankar, Vaishaal and Dave, Achal and Schmidt, Ludwig},
	year = {2022},
	pages = {6216--6234},
}

@inproceedings{gupta_cross_2016,
	address = {Las Vegas, NV, USA},
	title = {Cross modal distillation for supervision transfer},
	isbn = {978-1-4673-8851-1},
	doi = {10.1109/CVPR.2016.309},
	abstract = {In this work we propose a technique that transfers supervision between images from different modalities. We use learned representations from a large labeled modality as supervisory signal for training representations for a new unlabeled paired modality. Our method enables learning of rich representations for unlabeled modalities and can be used as a pre-training procedure for new modalities with limited labeled data. We transfer supervision from labeled RGB images to unlabeled depth and optical ﬂow images and demonstrate large improvements for both these cross modal supervision transfers.},
	language = {en},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Gupta, Saurabh and Hoffman, Judy and Malik, Jitendra},
	year = {2016},
	pages = {2827--2836},
}

@article{geng_multimodal_2022,
	title = {Multimodal masked autoencoders learn transferable representations},
	abstract = {Building scalable models to learn from diverse, multimodal data remains an open challenge. For vision-language data, the dominant approaches are based on contrastive learning objectives that train a separate encoder for each modality. While effective, contrastive learning approaches introduce sampling bias depending on the data augmentations used, which can degrade performance on downstream tasks. Moreover, these methods are limited to paired image-text data, and cannot leverage widely-available unpaired data. In this paper, we investigate whether a large multimodal model trained purely via masked token prediction, without using modality-specific encoders or contrastive learning, can learn transferable representations for downstream tasks. We propose a simple and scalable network architecture, the Multimodal Masked Autoencoder (M3AE), which learns a unified encoder for both vision and language data via masked token prediction. We provide an empirical study of M3AE trained on a large-scale image-text dataset, and find that M3AE is able to learn generalizable representations that transfer well to downstream tasks. Surprisingly, we find that M3AE benefits from a higher text mask ratio (50-90\%), in contrast to BERT whose standard masking ratio is 15\%, due to the joint training of two data modalities. We also provide qualitative analysis showing that the learned representation incorporates meaningful information from both image and language. Lastly, we demonstrate the scalability of M3AE with larger model size and training time, and its flexibility to train on both paired image-text data as well as unpaired data.},
	language = {en},
	journal = {arXiv preprint arXiv:2205.14204},
	author = {Geng, Xinyang and Liu, Hao and Lee, Lisa and Schuurmans, Dale and Levine, Sergey and Abbeel, Pieter},
	year = {2022},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{shalev-shwartz_learnability_2010,
	title = {Learnability, stability and uniform convergence},
	volume = {11},
	journal = {The Journal of Machine Learning Research},
	author = {Shalev-Shwartz, Shai and Shamir, Ohad and Srebro, Nathan and Sridharan, Karthik},
	year = {2010},
	pages = {2635--2670},
}

@inproceedings{pezeshki_gradient_2021,
	title = {Gradient starvation: {A} learning proclivity in neural networks},
	abstract = {We identify and formalize a fundamental gradient descent phenomenon leading to a learning proclivity in over-parameterized neural networks. Gradient Starvation arises when cross-entropy loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This work provides a theoretical explanation for the emergence of such feature imbalances in neural networks. Using tools from Dynamical Systems theory, we identify simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. Based on our proposed formalism, we develop guarantees for a novel but simple regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation. We illustrate our ﬁndings with simple and realworld out-of-distribution (OOD) generalization experiments.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Pezeshki, Mohammad and Kaba, Sékou-Oumar and Bengio, Yoshua and Courville, Aaron and Precup, Doina and Lajoie, Guillaume},
	year = {2021},
	pages = {1256--1272},
}

@inproceedings{chen_crossvit_2021,
	address = {Montreal, QC, Canada},
	title = {{CrossViT}: {Cross}-attention multi-scale vision transformer for image classification},
	isbn = {978-1-66542-812-5},
	shorttitle = {Crossvit},
	doi = {10.1109/ICCV48922.2021.00041},
	abstract = {The recently developed vision transformer (ViT) has achieved promising results on image classification compared to convolutional neural networks. Inspired by this, in this paper, we study how to learn multi-scale feature representations in transformer models for image classification. To this end, we propose a dual-branch transformer to combine image patches (i.e., tokens in a transformer) of different sizes to produce stronger image features. Our approach processes small-patch and large-patch tokens with two separate branches of different computational complexity and these tokens are then fused purely by attention multiple times to complement each other. Furthermore, to reduce computation, we develop a simple yet effective token fusion module based on cross attention, which uses a single token for each branch as a query to exchange information with other branches. Our proposed cross-attention only requires linear time for both computational and memory complexity instead of quadratic time otherwise. Extensive experiments demonstrate that our approach performs better than or on par with several concurrent works on vision transformer, in addition to efficient CNN models. For example, on the ImageNet1K dataset, with some architectural changes, our approach outperforms the recent DeiT by a large margin of 2\% with a small to moderate increase in FLOPs and model parameters. Our source codes and models are available at https://github.com/IBM/CrossViT.},
	language = {en},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Chen, Chun-Fu Richard and Fan, Quanfu and Panda, Rameswar},
	year = {2021},
	pages = {347--356},
}

@inproceedings{liu_swin_2021,
	address = {Montreal, QC, Canada},
	title = {Swin transformer: {Hierarchical} vision transformer using shifted windows},
	isbn = {978-1-66542-812-5},
	shorttitle = {Swin transformer},
	doi = {10.1109/ICCV48922.2021.00986},
	abstract = {This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with Shifted windows. The shifted windowing scheme brings greater efﬁciency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the ﬂexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classiﬁcation (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO testdev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-theart by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneﬁcial for all-MLP architectures. The code and models are publicly available at https://github. com/microsoft/Swin-Transformer.},
	language = {en},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
	year = {2021},
	pages = {9992--10002},
}

@inproceedings{rogozhnikov_einops_2022,
	title = {Einops: {Clear} and reliable tensor manipulations with {Einstein}-like notation},
	shorttitle = {Einops},
	abstract = {Tensor computations underlie modern scientific computing and deep learning. A number of tensor frameworks emerged varying in execution model, hardware support, memory management, model definition, etc. However, tensor operations in all frameworks follow the same paradigm. Recent neural network architectures demonstrate demand for higher expressiveness of tensor operations. The current paradigm is not suited to write readable, reliable, or easy-to-modify code for multidimensional tensor manipulations. Moreover, some commonly used operations do not provide sufficient checks and can break a tensor structure. These mistakes are elusive as no tools or tests can detect them. Independently, API discrepancies complicate code transfer between frameworks. We propose einops notation: a uniform and generic way to manipulate tensor structure, that significantly improves code readability and flexibility by focusing on the structure of input and output tensors. We implement einops notation in a Python package that efficiently supports multiple widely used frameworks and provides framework-independent minimalist API for tensor manipulations.},
	language = {en},
	author = {Rogozhnikov, Alex},
	year = {2022},
}

@inproceedings{huang_arbitrary_2017,
	address = {Venice},
	title = {Arbitrary style transfer in real-time with adaptive instance normalization},
	isbn = {978-1-5386-1032-9},
	doi = {10.1109/ICCV.2017.167},
	abstract = {Gatys et al. recently introduced a neural algorithm that renders a content image in the style of another image, achieving so-called style transfer. However, their framework requires a slow iterative optimization process, which limits its practical application. Fast approximations with feed-forward neural networks have been proposed to speed up neural style transfer. Unfortunately, the speed improvement comes at a cost: the network is usually tied to a ﬁxed set of styles and cannot adapt to arbitrary new styles. In this paper, we present a simple yet effective approach that for the ﬁrst time enables arbitrary style transfer in real-time. At the heart of our method is a novel adaptive instance normalization (AdaIN) layer that aligns the mean and variance of the content features with those of the style features. Our method achieves speed comparable to the fastest existing approach, without the restriction to a pre-deﬁned set of styles. In addition, our approach allows ﬂexible user controls such as content-style trade-off, style interpolation, color \& spatial controls, all using a single feed-forward neural network.},
	language = {en},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Huang, Xun and Belongie, Serge},
	year = {2017},
	pages = {1510--1519},
}

@inproceedings{chen_bag_2023,
	title = {Bag of tricks for out-of-distribution generalization},
	abstract = {Recently, out-of-distribution (OOD) generalization has attracted attention to the robustness and generalization ability of deep learning based models, and accordingly, many strategies have been made to address different aspects related to this issue. However, most existing algorithms for OOD generalization are complicated and specifically designed for certain dataset. To alleviate this problem, nicochallenge-2022 provides NICO++, a large-scale dataset with diverse context information. In this paper, based on systematic analysis of different schemes on NICO++ dataset, we propose a simple but effective learning framework via coupling bag of tricks, including multi-objective framework design, data augmentations, training and inference strategies. Our algorithm is memory-efficient and easily-equipped, without complicated modules and does not require for large pre-trained models. It achieves an excellent performance with Top-1 accuracy of 88.16\% on public test set and 75.65\% on private test set, and ranks 1st in domain generalization task of nicochallenge-2022.},
	language = {en},
	booktitle = {European {Conference} on {Computer} {Vision}},
	author = {Chen, Zining and Wang, Weiqiu and Zhao, Zhicheng and Men, Aidong and Chen, Hong},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{openai_gpt-4_2023,
	title = {{GPT}-4 technical report},
	abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformerbased model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4’s performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
	language = {en},
	journal = {arXiv preprint arXiv:2303.08774},
	author = {OpenAI},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{kumar_how_2022,
	title = {How to fine-tune vision models with {SGD}},
	abstract = {SGD (with momentum) and AdamW are the two most used optimizers for ﬁnetuning large neural networks in computer vision. When the two methods perform the same, SGD is preferable because it uses less memory (12 bytes/parameter) than AdamW (16 bytes/parameter). However, on a suite of downstream tasks, especially those with distribution shifts, we show that ﬁne-tuning with AdamW performs substantially better than SGD on modern Vision Transformer and ConvNeXt models. We ﬁnd that large gaps in performance between SGD and AdamW occur when the ﬁne-tuning gradients in the ﬁrst “embedding” layer are much larger than in the rest of the model. Our analysis suggests an easy ﬁx that works consistently across datasets and models: merely freezing the embedding layer (less than 1\% of the parameters) leads to SGD performing competitively with AdamW while using less memory. Our insights result in state-of-the-art accuracies on ﬁve popular distribution shift benchmarks: WILDS-FMoW, WILDSCamelyon, Living-17, Waterbirds, and DomainNet.},
	language = {en},
	journal = {arXiv preprint arXiv:2211.09359},
	author = {Kumar, Ananya and Shen, Ruoqi and Bubeck, Sébastien and Gunasekar, Suriya},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{tu_maxvit_2022,
	title = {{MaxViT}: {Multi}-axis vision transformer},
	shorttitle = {Maxvit},
	abstract = {Transformers have recently gained signiﬁcant attention in the computer vision community. However, the lack of scalability of selfattention mechanisms with respect to image size has limited their wide adoption in state-of-the-art vision backbones. In this paper we introduce an eﬃcient and scalable attention model we call multi-axis attention, which consists of two aspects: blocked local and dilated global attention. These design choices allow global-local spatial interactions on arbitrary input resolutions with only linear complexity. We also present a new architectural element by eﬀectively blending our proposed attention model with convolutions, and accordingly propose a simple hierarchical vision backbone, dubbed MaxViT, by simply repeating the basic building block over multiple stages. Notably, MaxViT is able to “see” globally throughout the entire network, even in earlier, high-resolution stages. We demonstrate the eﬀectiveness of our model on a broad spectrum of vision tasks. On image classiﬁcation, MaxViT achieves state-of-the-art performance under various settings: without extra data, MaxViT attains 86.5\% ImageNet-1K top-1 accuracy; with ImageNet-21K pre-training, our model achieves 88.7\% top-1 accuracy. For downstream tasks, MaxViT as a backbone delivers favorable performance on object detection as well as visual aesthetic assessment. We also show that our proposed model expresses strong generative modeling capability on ImageNet, demonstrating the superior potential of MaxViT blocks as a universal vision module. The source code and trained models will be available at https://github.com/google-research/maxvit.},
	language = {en},
	booktitle = {{ECCV}},
	author = {Tu, Zhengzhong and Talebi, Hossein and Zhang, Han and Yang, Feng and Milanfar, Peyman and Bovik, Alan and Li, Yinxiao},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{loshchilov_decoupled_2019,
	title = {Decoupled weight decay regularization},
	abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at https://github.com/loshchil/AdamW-and-SGDW},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Loshchilov, Ilya and Hutter, Frank},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
}

@inproceedings{park_relational_2019,
	address = {Long Beach, CA, USA},
	title = {Relational knowledge distillation},
	isbn = {978-1-72813-293-8},
	doi = {10.1109/CVPR.2019.00409},
	abstract = {Knowledge distillation aims at transferring knowledge acquired in one model (a teacher) to another model (a student) that is typically smaller. Previous approaches can be expressed as a form of training the student to mimic output activations of individual data examples represented by the teacher. We introduce a novel approach, dubbed relational knowledge distillation (RKD), that transfers mutual relations of data examples instead. For concrete realizations of RKD, we propose distance-wise and angle-wise distillation losses that penalize structural differences in relations. Experiments conducted on different tasks show that the proposed method improves educated student models with a signiﬁcant margin. In particular for metric learning, it allows students to outperform their teachers’ performance, achieving the state of the arts on standard benchmark datasets.},
	language = {en},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Park, Wonpyo and Kim, Dongju and Lu, Yan and Cho, Minsu},
	year = {2019},
	pages = {3962--3971},
}

@article{gou_knowledge_2021,
	title = {Knowledge distillation: {A} survey},
	volume = {129},
	issn = {0920-5691, 1573-1405},
	shorttitle = {Knowledge distillation},
	doi = {10.1007/s11263-021-01453-z},
	abstract = {In recent years, deep neural networks have been successful in both industry and academia, especially for computer vision tasks. The great success of deep learning is mainly due to its scalability to encode large-scale data and to maneuver billions of model parameters. However, it is a challenge to deploy these cumbersome deep models on devices with limited resources, e.g., mobile phones and embedded devices, not only because of the high computational complexity but also the large storage requirements. To this end, a variety of model compression and acceleration techniques have been developed. As a representative type of model compression and acceleration, knowledge distillation eﬀectively learns a small student model from a large teacher model. It has received rapid increasing attention from the community. This paper provides a comprehensive survey of knowledge distillation from the perspectives of knowledge categories, training schemes, teacher-student architecture, distillation algorithms, performance comparison and applications. Furthermore, challenges in knowledge distillation are brieﬂy reviewed and comments on future research are discussed and forwarded.},
	language = {en},
	number = {6},
	journal = {International Journal of Computer Vision},
	author = {Gou, Jianping and Yu, Baosheng and Maybank, Stephen John and Tao, Dacheng},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {1789--1819},
}

@inproceedings{tian_contrastive_2020,
	title = {Contrastive representation distillation},
	abstract = {Often we wish to transfer representational knowledge from one neural network to another. Examples include distilling a large network into a smaller one, transferring knowledge from one sensory modality to a second, or ensembling a collection of models into a single estimator. Knowledge distillation, the standard approach to these problems, minimizes the KL divergence between the probabilistic outputs of a teacher and student network. We demonstrate that this objective ignores important structural knowledge of the teacher network. This motivates an alternative objective by which we train a student to capture signiﬁcantly more information in the teacher’s representation of the data. We formulate this objective as contrastive learning. Experiments demonstrate that our resulting new objective outperforms knowledge distillation and other cutting-edge distillers on a variety of knowledge transfer tasks, including single model compression, ensemble distillation, and cross-modal transfer. Our method sets a new state-of-the-art in many transfer tasks, and sometimes even outperforms the teacher network when combined with knowledge distillation.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{zhang_be_2019,
	address = {Seoul, Korea (South)},
	title = {Be your own teacher: {Improve} the performance of convolutional neural networks via self distillation},
	isbn = {978-1-72814-803-8},
	shorttitle = {Be your own teacher},
	doi = {10.1109/ICCV.2019.00381},
	abstract = {Convolutional neural networks have been widely deployed in various application scenarios. In order to extend the applications’ boundaries to some accuracy-crucial domains, researchers have been investigating approaches to boost accuracy through either deeper or wider network structures, which brings with them the exponential increment of the computational and storage cost, delaying the responding time.},
	language = {en},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Zhang, Linfeng and Song, Jiebo and Gao, Anni and Chen, Jingwei and Bao, Chenglong and Ma, Kaisheng},
	year = {2019},
	pages = {3712--3721},
}

@inproceedings{romero_fitnets_2015,
	title = {{FitNets}: {Hints} for thin deep nets},
	shorttitle = {Fitnets},
	abstract = {While depth tends to improve network performances, it also makes gradient-based training more difﬁcult since deeper networks tend to be more non-linear. The recently proposed knowledge distillation approach is aimed at obtaining small and fast-to-execute models, and it has shown that a student network could imitate the soft output of a larger teacher network or ensemble of networks. In this paper, we extend this idea to allow the training of a student that is deeper and thinner than the teacher, using not only the outputs but also the intermediate representations learned by the teacher as hints to improve the training process and ﬁnal performance of the student. Because the student intermediate hidden layer will generally be smaller than the teacher’s intermediate hidden layer, additional parameters are introduced to map the student hidden layer to the prediction of the teacher hidden layer. This allows one to train deeper students that can generalize better or run faster, a trade-off that is controlled by the chosen student capacity. For example, on CIFAR-10, a deep student network with almost 10.4 times less parameters outperforms a larger, state-of-the-art teacher network.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
	year = {2015},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{liu_convnet_2022,
	title = {A {ConvNet} for the 2020s},
	language = {en},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
	year = {2022},
	pages = {11976--11986},
}

@article{zador_catalyzing_2023,
	title = {Catalyzing next-generation artificial intelligence through {NeuroAI}},
	volume = {14},
	copyright = {2023 The Author(s)},
	issn = {2041-1723},
	doi = {10.1038/s41467-023-37180-x},
	abstract = {Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities – inherited from over 500 million years of evolution – that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI.},
	language = {en},
	number = {1},
	journal = {Nature Communications},
	author = {Zador, Anthony and Escola, Sean and Richards, Blake and Ölveczky, Bence and Bengio, Yoshua and Boahen, Kwabena and Botvinick, Matthew and Chklovskii, Dmitri and Churchland, Anne and Clopath, Claudia and DiCarlo, James and Ganguli, Surya and Hawkins, Jeff and Körding, Konrad and Koulakov, Alexei and LeCun, Yann and Lillicrap, Timothy and Marblestone, Adam and Olshausen, Bruno and Pouget, Alexandre and Savin, Cristina and Sejnowski, Terrence and Simoncelli, Eero and Solla, Sara and Sussillo, David and Tolias, Andreas S. and Tsao, Doris},
	year = {2023},
	keywords = {Computer science, Neuroscience},
	pages = {1597},
}

@article{baek_agreement---line_2022,
	title = {Agreement-on-the-line: {Predicting} the performance of neural networks under distribution shift},
	shorttitle = {Agreement-on-the-line},
	abstract = {Recently, Miller et al. [56] showed that a model’s in-distribution (ID) accuracy has a strong linear correlation with its out-of-distribution (OOD) accuracy on several OOD benchmarks — a phenomenon they dubbed “accuracy-on-the-line”. While a useful tool for model selection (i.e., the model most likely to perform the best OOD is the one with highest ID accuracy), this fact does not help estimate the actual OOD performance of models without access to a labeled OOD validation set. In this paper, we show a similar but surprising phenomenon also holds for the agreement between pairs of neural network classiﬁers: whenever accuracyon-the-line holds, we observe that the OOD agreement between the predictions of any two pairs of neural networks (with potentially different architectures) also observes a strong linear correlation with their ID agreement. Furthermore, we observe that the slope and bias of OOD vs ID agreement closely matches that of OOD vs ID accuracy. This phenomenon, which we call agreement-on-the-line, has important practical applications: without any labeled data, we can predict the OOD accuracy of classiﬁers, since OOD agreement can be estimated with just unlabeled data. Our prediction algorithm outperforms previous methods both in shifts where agreement-on-the-line holds and, surprisingly, when accuracy is not on the line. This phenomenon also provides new insights into deep neural networks: unlike accuracy-on-the-line, agreement-on-the-line appears to only hold for neural network classiﬁers.},
	language = {en},
	journal = {arXiv preprint arXiv:2206.13089},
	author = {Baek, Christina and Jiang, Yiding and Raghunathan, Aditi and Kolter, Zico},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{saunshi_understanding_2022,
	title = {Understanding contrastive learning requires incorporating inductive biases},
	abstract = {Contrastive learning is a popular form of selfsupervised learning that encourages augmentations (views) of the same input to have more similar representations compared to augmentations of different inputs. Recent attempts to theoretically explain the success of contrastive learning on downstream classiﬁcation tasks prove guarantees depending on properties of augmentations and the value of contrastive loss of representations. We demonstrate that such analyses, that ignore inductive biases of the function class and training algorithm, cannot adequately explain the success of contrastive learning, even provably leading to vacuous guarantees in some settings. Extensive experiments on image and text domains highlight the ubiquity of this problem – different function classes and algorithms behave very differently on downstream tasks, despite having the same augmentations and contrastive losses. Theoretical analysis is presented for the class of linear representations, where incorporating inductive biases of the function class allows contrastive learning to work with less stringent conditions compared to prior analyses.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Saunshi, Nikunj and Ash, Jordan T and Goel, Surbhi and Misra, Dipendra and Zhang, Cyril and Arora, Sanjeev and Kakade, Sham and Krishnamurthy, Akshay},
	year = {2022},
	pages = {19250--19286},
}

@inproceedings{liu_what_2023,
	title = {What contrastive learning learns beyond class-wise features?},
	abstract = {In recent years, contrastive learning has achieved the performance that is comparable to supervised learning in representation learning. However, the transferability of different contrastive learning methods to downstream tasks often varies greatly. In this paper, we study the downstream generalization ability of two contrastive learning methods: SimCLR and Spectral Contrastive Learning (Spectral CL). We find that beyond class-wise features, contrastive learning also learns two types of features, which we call shared features and subclass features, which play an important role in model transferability. SimCLR learns more shared and subclass features than Spectral CL, resulting in better transferability. We theoretically and experimentally reveal the mechanism by which SimCLR can learn more diverse features than Spectral CL. Therefore, we propose a method called High-pass Spectral CL to improve the transferability and generalization of Spectral CL, which achieves better performance than SimCLR and Spectral CL.},
	language = {en},
	author = {Liu, Xingyuming and Wang, Yifei and Wang, Yisen},
	year = {2023},
}

@inproceedings{mehta_you_2022,
	title = {You only need a good embeddings extractor to fix spurious correlations},
	abstract = {Spurious correlations in training data often lead to robustness issues since models learn to use them as shortcuts. For example, when predicting whether an object is a cow, a model might learn to rely on its green background, so it would do poorly on a cow on a sandy background A standard dataset for measuring state-of-the-art on methods mitigating this problem is Waterbirds. The best method (Group Distributionally Robust Optimization - GroupDRO) currently achieves 89\% worst group accuracy and standard training from scratch on raw images only gets 72\%. GroupDRO requires training a model in an endto-end manner with subgroup labels. In this paper, we show that we can achieve up to 90\% accuracy without using any sub-group information in the training set by simply using embeddings from a large pretrained vision model extractor and training a linear classifier on top of it. With experiments on a wide range of pre-trained models and pretraining datasets, we show that the capacity of the pre-training model and the size of the pre-training dataset matters. Our experiments reveal that high capacity vision transformers perform better compared to high capacity convolutional neural networks, and larger pre-training dataset leads to better worst-group accuracy on the spurious correlation dataset.},
	language = {en},
	booktitle = {{ECCV} 2022 workshop on {Responsible} {Computer} {Vision} ({RCV})},
	author = {Mehta, Raghav and Albiero, Vítor and Chen, Li and Evtimov, Ivan and Glaser, Tamar and Li, Zhiheng and Hassner, Tal},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{chen_project_2023,
	title = {Project and probe: {Sample}-efficient domain adaptation by interpolating orthogonal features},
	shorttitle = {Project and probe},
	abstract = {Conventional approaches to robustness try to learn a model based on causal features. However, identifying maximally robust or causal features may be difficult in some scenarios, and in others, non-causal "shortcut" features may actually be more predictive. We propose a lightweight, sample-efficient approach that learns a diverse set of features and adapts to a target distribution by interpolating these features with a small target dataset. Our approach, Project and Probe (Pro\${\textasciicircum}2\$), first learns a linear projection that maps a pre-trained embedding onto orthogonal directions while being predictive of labels in the source dataset. The goal of this step is to learn a variety of predictive features, so that at least some of them remain useful after distribution shift. Pro\${\textasciicircum}2\$ then learns a linear classifier on top of these projected features using a small target dataset. We theoretically show that Pro\${\textasciicircum}2\$ learns a projection matrix that is optimal for classification in an information-theoretic sense, resulting in better generalization due to a favorable bias-variance tradeoff. Our experiments on four datasets, with multiple distribution shift settings for each, show that Pro\${\textasciicircum}2\$ improves performance by 5-15\% when given limited target data compared to prior methods such as standard linear probing.},
	language = {en},
	journal = {arXiv preprint arXiv:2302.05441},
	author = {Chen, Annie S. and Lee, Yoonho and Setlur, Amrith and Levine, Sergey and Finn, Chelsea},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{abnar_exploring_2021,
	title = {Exploring the limits of large scale pre-training},
	abstract = {Recent developments in large-scale machine learning suggest that by scaling up data, model size and training time properly, one might observe that improvements in pre-training would transfer favorably to most downstream tasks. In this work, we systematically study this phenomena and establish that, as we increase the upstream accuracy, the performance of downstream tasks saturates. In particular, we investigate more than 4800 experiments on Vision Transformers, MLP-Mixers and ResNets with number of parameters ranging from ten million to ten billion, trained on the largest scale of available image data (JFT, ImageNet21K) and evaluated on more than 20 downstream image recognition tasks. We propose a model for downstream performance that reﬂects the saturation phenomena and captures the nonlinear relationship in performance of upstream and downstream tasks. Delving deeper to understand the reasons that give rise to these phenomena, we show that the saturation behavior we observe is closely related to the way that representations evolve through the layers of the models. We showcase an even more extreme scenario where performance on upstream and downstream are at odds with each other. That is, to have a better downstream performance, we need to hurt upstream accuracy.},
	language = {en},
	journal = {arXiv preprint arXiv:2110.02095},
	author = {Abnar, Samira and Dehghani, Mostafa and Neyshabur, Behnam and Sedghi, Hanie},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{tripuraneni_overparameterization_2021,
	title = {Overparameterization improves robustness to covariate shift in high dimensions},
	abstract = {A signiﬁcant obstacle in the development of robust machine learning models is covariate shift, a form of distribution shift that occurs when the input distributions of the training and test sets differ while the conditional label distributions remain the same. Despite the prevalence of covariate shift in real-world applications, a theoretical understanding in the context of modern machine learning has remained lacking. In this work, we examine the exact high-dimensional asymptotics of random feature regression under covariate shift and present a precise characterization of the limiting test error, bias, and variance in this setting. Our results motivate a natural partial order over covariate shifts that provides a sufﬁcient condition for determining when the shift will harm (or even help) test performance. We ﬁnd that overparameterized models exhibit enhanced robustness to covariate shift, providing one of the ﬁrst theoretical explanations for this ubiquitous empirical phenomenon. Additionally, our analysis reveals an exact linear relationship between the in-distribution and out-of-distribution generalization performance, offering an explanation for this surprising recent observation.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Tripuraneni, Nilesh and Adlam, Ben and Pennington, Jeffrey},
	year = {2021},
	pages = {13883--13897},
}

@article{liu_empirical_2022,
	title = {An empirical study on distribution shift robustness from the perspective of pre-training and data augmentation},
	abstract = {The performance of machine learning models under distribution shift has been the focus of the community in recent years. Most of current methods have been proposed to improve the robustness to distribution shift from the algorithmic perspective, i.e., designing better training algorithms to help the generalization in shifted test distributions. This paper studies the distribution shift problem from the perspective of pre-training and data augmentation, two important factors in the practice of deep learning that have not been systematically investigated by existing work. By evaluating seven pre-trained models, including ResNets [1] and ViT’s [2] with self-supervision and supervision mode, on ﬁve important distributionshift datasets, from WILDS [3] and DomainBed [4] benchmarks, with ﬁve different learning algorithms, we provide the ﬁrst comprehensive empirical study focusing on pre-training and data augmentation. With our empirical result obtained from 1,330 models, we provide the following main observations: 1) ERM combined with data augmentation can achieve state-of-the-art performance if we choose a proper pre-trained model respecting the data property; 2) specialized algorithms further improve the robustness on top of ERM when handling a speciﬁc type of distribution shift, e.g., GroupDRO [5] for spurious correlation and CORAL [6] for large-scale out-of-distribution data; 3) Comparing different pre-training modes, architectures and data sizes, we provide novel observations about pre-training on distribution shift, which sheds light on designing or selecting pre-training strategy for different kinds of distribution shifts. In summary, our empirical study provides a comprehensive baseline for a wide range of pre-training models ﬁne-tuned with data augmentation, which potentially inspires research exploiting the power of pre-training and data augmentation in the future of distribution shift study.},
	language = {en},
	journal = {arXiv preprint arXiv:2205.12753},
	author = {Liu, Ziquan and Xu, Yi and Xu, Yuanhong and Qian, Qi and Li, Hao and Jin, Rong and Ji, Xiangyang and Chan, Antoni B.},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{tripuraneni_covariate_2021,
	title = {Covariate shift in high-dimensional random feature regression},
	abstract = {A signiﬁcant obstacle in the development of robust machine learning models is covariate shift, a form of distribution shift that occurs when the input distributions of the training and test sets differ while the conditional label distributions remain the same. Despite the prevalence of covariate shift in real-world applications, a theoretical understanding in the context of modern machine learning has remained lacking. In this work, we examine the exact high-dimensional asymptotics of random feature regression under covariate shift and present a precise characterization of the limiting test error, bias, and variance in this setting. Our results motivate a natural partial order over covariate shifts that provides a sufﬁcient condition for determining when the shift will harm (or even help) test performance. We ﬁnd that overparameterized models exhibit enhanced robustness to covariate shift, providing one of the ﬁrst theoretical explanations for this intriguing phenomenon. Additionally, our analysis reveals an exact linear relationship between in-distribution and out-of-distribution generalization performance, offering an explanation for this surprising recent empirical observation.},
	language = {en},
	journal = {arXiv preprint arXiv:2111.08234},
	author = {Tripuraneni, Nilesh and Adlam, Ben and Pennington, Jeffrey},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{fridovich-keil_models_2022,
	title = {Models out of line: {A} fourier lens on distribution shift robustness},
	volume = {35},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Fridovich-Keil, Sara and Bartoldson, Brian and Diffenderfer, James and Kailkhura, Bhavya and Bremer, Timo},
	year = {2022},
	pages = {11175--11188},
}

@inproceedings{trivedi_closer_2023,
	title = {A closer look at model adaptation using feature distortion and simplicity bias},
	abstract = {Advances in the expressivity of pretrained models have increased interest in the design of adaptation protocols which enable safe and effective transfer learning. Going beyond conventional linear probing (LP) and ﬁne tuning (FT) strategies, protocols that can effectively control feature distortion, i.e., the failure to update features orthogonal to the in-distribution, have been found to achieve improved outof-distribution generalization (OOD). In order to limit this distortion, the LP+FT protocol, which ﬁrst learns a linear probe and then uses this initialization for subsequent FT, was proposed. However, in this paper, we ﬁnd when adaptation protocols (LP, FT, LP+FT) are also evaluated on a variety of safety objectives (e.g., calibration, robustness, etc.), a complementary perspective to feature distortion is helpful to explain protocol behavior. To this end, we study the susceptibility of protocols to simplicity bias (SB), i.e. the well-known propensity of deep neural networks to rely upon simple features, as SB has recently been shown to underlie several problems in robust generalization. Using a synthetic dataset, we demonstrate the susceptibility of existing protocols to SB. Given the strong effectiveness of LP+FT, we then propose modiﬁed linear probes that help mitigate SB, and lead to better initializations for subsequent FT. We verify the effectiveness of the proposed LP+FT variants for decreasing SB in a controlled setting, and their ability to improve OOD generalization and safety on three adaptation datasets.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Trivedi, Puja and Koutra, Danai and Thiagarajan, Jayaraman J.},
	year = {2023},
	keywords = {Computer Science - Machine Learning},
}

@article{entezari_role_2023,
	title = {The role of pre-training data in transfer learning},
	abstract = {The transfer learning paradigm of model pre-training and subsequent ﬁne-tuning produces highaccuracy models. While most studies recommend scaling the pre-training size to beneﬁt most from transfer learning, a question remains: what data and method should be used for pre-training? We investigate the impact of pre-training data distribution on the few-shot and full ﬁne-tuning performance using 3 pre-training methods (supervised, contrastive language-image and image-image), 7 pre-training datasets, and 9 downstream datasets. Through extensive controlled experiments, we ﬁnd that the choice of the pre-training data source is essential for the few-shot transfer, but its role decreases as more data is made available for ﬁne-tuning. Additionally, we explore the role of data curation and examine the trade-oﬀs between label noise and the size of the pre-training dataset. We ﬁnd that using 2000× more pre-training data from LAION can match the performance of supervised ImageNet pre-training. Furthermore, we investigate the eﬀect of pre-training methods, comparing language-image contrastive vs. image-image contrastive, and ﬁnd that the latter leads to better downstream accuracy12.},
	language = {en},
	journal = {arXiv preprint arXiv:2302.13602},
	author = {Entezari, Rahim and Wortsman, Mitchell and Saukh, Olga and Shariatnia, M. Moein and Sedghi, Hanie and Schmidt, Ludwig},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{simchowitz_statistical_2023,
	title = {Statistical learning under heterogenous distribution shift},
	abstract = {This paper studies the prediction of a target z from a pair of random variables (x, y), where the ground-truth predictor is additive E[z {\textbar} x, y] = f (x) + g (y). We study the performance of empirical risk minimization (ERM) over functions f + g, f ∈ F and g ∈ G, ﬁt on a given training distribution, but evaluated on a test distribution which exhibits covariate shift. We show that, when the class F is “simpler" than G (measured, e.g., in terms of its metric entropy), our predictor is more resilient to heterogenous covariate shifts in which the shift in x is much greater than that in y. These results rely on a novel Hölder style inequality for the Dudley integral which may be of independent interest. Moreover, we corroborate our theoretical ﬁndings with experiments demonstrating improved resilience to shifts in “simpler” features across numerous domains.},
	language = {en},
	journal = {arXiv preprint arXiv:2302.13934},
	author = {Simchowitz, Max and Ajay, Anurag and Agrawal, Pulkit and Krishnamurthy, Akshay},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{shi_effective_2023,
	title = {Effective robustness against natural distribution shifts for models with different training data},
	abstract = {Eﬀective robustness” measures the extra out-of-distribution (OOD) robustness beyond what can be predicted from the in-distribution (ID) performance. Existing eﬀective robustness evaluations typically use a single test set such as ImageNet to evaluate ID accuracy. This becomes problematic when evaluating models trained on diﬀerent data distributions, e.g., comparing models trained on ImageNet vs. zero-shot language-image pre-trained models trained on LAION. In this paper, we propose a new eﬀective robustness evaluation metric to compare the eﬀective robustness of models trained on diﬀerent data distributions. To do this we control for the accuracy on multiple ID test sets that cover the training distributions for all the evaluated models. Our new evaluation metric provides a better estimate of the eﬀectiveness robustness and explains the surprising eﬀective robustness gains of zero-shot CLIP-like models exhibited when considering only one ID dataset, while the gains diminish under our evaluation.},
	language = {en},
	journal = {arXiv preprint arXiv:2302.01381},
	author = {Shi, Zhouxing and Carlini, Nicholas and Balashankar, Ananth and Schmidt, Ludwig and Hsieh, Cho-Jui and Beutel, Alex and Qin, Yao},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{lee_demystifying_2023,
	title = {Demystifying disagreement-on-the-line in high dimensions},
	abstract = {Evaluating the performance of machine learning models under distribution shift is challenging, especially when we only have unlabeled data from the shifted (target) domain, along with labeled data from the original (source) domain. Recent work suggests that the notion of disagreement, the degree to which two models trained with diﬀerent randomness diﬀer on the same input, is a key to tackle this problem. Experimentally, disagreement and prediction error have been shown to be strongly connected, which has been used to estimate model performance. Experiments have led to the discovery of the disagreement-on-the-line phenomenon, whereby the classiﬁcation error under the target domain is often a linear function of the classiﬁcation error under the source domain; and whenever this property holds, disagreement under the source and target domain follow the same linear relation. In this work, we develop a theoretical foundation for analyzing disagreement in high-dimensional random features regression; and study under what conditions the disagreement-on-the-line phenomenon occurs in our setting. Experiments on CIFAR-10-C, Tiny ImageNet-C, and Camelyon17 are consistent with our theory and support the universality of the theoretical ﬁndings.},
	language = {en},
	journal = {arXiv preprint arXiv:2301.13371},
	author = {Lee, Donghwan and Moniri, Behrad and Huang, Xinmeng and Dobriban, Edgar and Hassani, Hamed},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{zhang_why_2020,
	title = {Why gradient clipping accelerates training: {A} theoretical justification for adaptivity},
	shorttitle = {Why gradient clipping accelerates training},
	abstract = {We provide a theoretical explanation for the effectiveness of gradient clipping in training deep neural networks. The key ingredient is a new smoothness condition derived from practical neural network training examples. We observe that gradient smoothness, a concept central to the analysis of ﬁrst-order optimization algorithms that is often assumed to be a constant, demonstrates signiﬁcant variability along the training trajectory of deep neural networks. Further, this smoothness positively correlates with the gradient norm, and contrary to standard assumptions in the literature, it can grow with the norm of the gradient. These empirical observations limit the applicability of existing theoretical analyses of algorithms that rely on a ﬁxed bound on smoothness. These observations motivate us to introduce a novel relaxation of gradient smoothness that is weaker than the commonly used Lipschitz smoothness assumption. Under the new condition, we prove that two popular methods, namely, gradient clipping and normalized gradient, converge arbitrarily faster than gradient descent with ﬁxed stepsize. We further explain why such adaptively scaled gradient methods can accelerate empirical convergence and verify our results empirically in popular neural network training settings.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Zhang, Jingzhao and He, Tianxing and Sra, Suvrit and Jadbabaie, Ali},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
}

@article{galindo_understanding_nodate,
	title = {Understanding {CLIP} robustness},
	abstract = {Neural networks show a lack of robustness under adverse conditions, such as dealing with new datasets/distributions and adversarial perturbations. Some works in the literature, based on experiments with Resnet models trained on Imagenet, elect possible culprits such as the vulnerability to high frequency disturbances and dependence on non-robust features. Contrastive Language-Image Pre-training (CLIP) has been proposed as a new learning procedure which has improved robustness to new distributions but low robustness to adversarial examples. Therefore, CLIP presents an ideal opportunity for measuring how robust features and frequency sensitivity are associated with robustness to data shift. In this sense, we measure the vulnerability of CLIP model to high frequency perturbations, and perform image generation and inpainting tasks for assessment of robust features. In the performed experiments, the CLIP model is shown to be more robust to higher frequency perturbations and less robust to lower frequency perturbations, indicating a higher dependence on features with lower frequency. Finally, the images generated by CLIP were of low quality, indicating a lack of robust features.},
	language = {en},
	author = {Galindo, Yuri and Faria, Fabio A},
}

@inproceedings{adebayo_post_2022,
	title = {Post hoc explanations may be ineffective for detecting unknown spurious correlation},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Adebayo, Julius and Muelly, Michael and Abelson, Harold and Kim, Been},
	year = {2022},
}

@inproceedings{makar_causally_2022,
	title = {Causally motivated shortcut removal using auxiliary labels},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Makar, Maggie and Packer, Ben and Moldovan, Dan and Blalock, Davis and Halpern, Yoni and D’Amour, Alexander},
	year = {2022},
}

@article{plumb_finding_2022,
	title = {Finding and fixing spurious patterns with explanations},
	abstract = {Image classiﬁers often use spurious patterns, such as “relying on the presence of a person to detect a tennis racket,” which do not generalize. In this work, we present an end-toend pipeline for identifying and mitigating spurious patterns for such models, under the assumption that we have access to pixel-wise object-annotations. We start by identifying patterns such as “the model’s prediction for tennis racket changes 63\% of the time if we hide the people.” Then, if a pattern is spurious, we mitigate it via a novel form of data augmentation. We demonstrate that our method identiﬁes a diverse set of spurious patterns and that it mitigates them by producing a model that is both more accurate on a distribution where the spurious pattern is not helpful and more robust to distribution shift.},
	language = {en},
	journal = {arXiv preprint arXiv:2106.02112},
	author = {Plumb, Gregory and Ribeiro, Marco Tulio and Talwalkar, Ameet},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{zhang_correct-n-contrast_2022,
	title = {Correct-n-contrast: {A} contrastive approach for improving robustness to spurious correlations},
	shorttitle = {Correct-n-contrast},
	abstract = {Spurious correlations pose a major challenge for robust machine learning. Models trained with empirical risk minimization (ERM) may learn to rely on correlations between class labels and spurious attributes, leading to poor performance on data groups without these correlations. This is particularly challenging to address when spurious attribute labels are unavailable. To improve worst-group performance on spuriously correlated data without training attribute labels, we propose Correct-n-Contrast (CnC), a contrastive approach to directly learn representations robust to spurious correlations. As ERM models can be good spurious attribute predictors, CnC works by (1) using a trained ERM model’s outputs to identify samples with the same class but dissimilar spurious features, and (2) training a robust model with contrastive learning to learn similar representations for same-class samples. To support CnC, we introduce new connections between worst-group error and a representation alignment loss that CnC aims to minimize. We empirically observe that worst-group error closely tracks with alignment loss, and prove that the alignment loss over a class helps upper-bound the class’s worst-group vs. average error gap. On popular benchmarks, CnC reduces alignment loss drastically, and achieves state-of-the-art worst-group accuracy by 3.6\% average absolute lift. CnC is also competitive with oracle methods that require group labels.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhang, Michael and Sohoni, Nimit S. and Zhang, Hongyang R. and Finn, Chelsea and Ré, Christopher},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
	pages = {26484--26516},
}

@inproceedings{liu_avoiding_2023,
	title = {Avoiding spurious correlations via logit correction},
	abstract = {Empirical studies suggest that machine learning models trained with empirical risk minimization (ERM) often rely on attributes that may be spuriously correlated with the class labels. Such models typically lead to poor performance during inference for data lacking such correlations. In this work, we explicitly consider a situation where potential spurious correlations are present in the majority of training data. In contrast with existing approaches, which use the ERM model outputs to detect the samples without spurious correlations and either heuristically upweight or upsample those samples, we propose the logit correction (LC) loss, a simple yet effective improvement on the softmax cross-entropy loss, to correct the sample logit. We demonstrate that minimizing the LC loss is equivalent to maximizing the group-balanced accuracy, so the proposed LC could mitigate the negative impacts of spurious correlations. Our extensive experimental results further reveal that the proposed LC loss outperforms state-of-the-art solutions on multiple popular benchmarks by a large margin, an average 5.5{\textbackslash}\% absolute improvement, without access to spurious attribute labels. LC is also competitive with oracle methods that make use of the attribute labels. Code is available at https://github.com/shengliu66/LC.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Liu, Sheng and Zhang, Xu and Sekhar, Nitesh and Wu, Yue and Singhal, Prateek and Fernandez-Granda, Carlos},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language, Electrical Engineering and Systems Science - Image and Video Processing},
}

@inproceedings{nguyen_avoiding_2021,
	title = {Avoiding spurious correlations: {Bridging} theory and practice},
	shorttitle = {Avoiding spurious correlations},
	abstract = {Distribution shifts in the wild jeopardize the performance of machine learning models as they tend to pick up spurious correlations during training. Recent work (Nagarajan et al., 2020) has characterized two specific failure modes of out-of-distribution (OOD) generalization, and we extend this theoretical framework by interpreting existing algorithms as solutions to these failure modes. We then evaluate them on different image classification datasets, and in the process surface two issues that are central to existing robustness techniques. For the algorithms that require access to group information, we demonstrate how the existing annotations included in standard OOD benchmarks are unable to fully capture the spurious correlations present. For methods that don't rely on group annotations during training, the validation set they utilize for model selection carries assumptions that are not realistic in real-world settings. This leads us to explore how the choice of distribution shifts represented by validation data would affect the effectiveness of different OOD robustness algorithms.},
	language = {en},
	author = {Nguyen, Thao and Nagarajan, Vaishnavh and Sedghi, Hanie and Neyshabur, Behnam},
	year = {2021},
}

@inproceedings{liu_just_2021,
	title = {Just train twice: {Improving} group robustness without training group information},
	shorttitle = {Just train twice},
	abstract = {Standard training via empirical risk minimization (ERM) can produce models that achieve high accuracy on average but low accuracy on certain groups, especially in the presence of spurious correlations between the input and label. Prior approaches that achieve high worst-group accuracy, like group distributionally robust optimization (group DRO) require expensive group annotations for each training point, whereas approaches that do not use such group annotations typically achieve unsatisfactory worst-group accuracy. In this paper, we propose a simple two-stage approach, JTT, that ﬁrst trains a standard ERM model for several epochs, and then trains a second model that upweights the training examples that the ﬁrst model misclassiﬁed. Intuitively, this upweights examples from groups on which standard ERM models perform poorly, leading to improved worst-group performance. Averaged over four image classiﬁcation and natural language processing tasks with spurious correlations, JTT closes 75\% of the gap in worst-group accuracy between standard ERM and group DRO, while only requiring group annotations on a small validation set in order to tune hyperparameters.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Liu, Evan Zheran and Haghgoo, Behzad and Chen, Annie S. and Raghunathan, Aditi and Koh, Pang Wei and Sagawa, Shiori and Liang, Percy and Finn, Chelsea},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	pages = {6781--6792},
}

@inproceedings{tang_long-tailed_2020,
	title = {Long-tailed classification by keeping the good and removing the bad momentum causal effect},
	abstract = {As the class size grows, maintaining a balanced dataset across many classes is challenging because the data are long-tailed in nature; it is even impossible when the sample-of-interest co-exists with each other in one collectable unit, e.g., multiple visual instances in one image. Therefore, long-tailed classiﬁcation is the key to deep learning at scale. However, existing methods are mainly based on reweighting/re-sampling heuristics that lack a fundamental theory. In this paper, we establish a causal inference framework, which not only unravels the whys of previous methods, but also derives a new principled solution. Speciﬁcally, our theory shows that the SGD momentum is essentially a confounder in long-tailed classiﬁcation. On one hand, it has a harmful causal effect that misleads the tail prediction biased towards the head. On the other hand, its induced mediation also beneﬁts the representation learning and head prediction. Our framework elegantly disentangles the paradoxical effects of the momentum, by pursuing the direct causal effect caused by an input sample. In particular, we use causal intervention in training, and counterfactual reasoning in inference, to remove the “bad” while keep the “good”. We achieve new state-of-the-arts on three long-tailed visual recognition benchmarks1: Long-tailed CIFAR-10/-100, ImageNet-LT for image classiﬁcation and LVIS for instance segmentation.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Tang, Kaihua and Huang, Jianqiang and Zhang, Hanwang},
	year = {2020},
	pages = {1513--1524},
}

@inproceedings{jiang_assessing_2022,
	title = {Assessing generalization of {SGD} via disagreement},
	abstract = {We empirically show that the test error of deep networks can be estimated by training the same architecture on the same training set but with two different runs of Stochastic Gradient Descent (SGD), and then measuring the disagreement rate between the two networks on unlabeled test data. This builds on — and is a stronger version of — the observation in Nakkiran \& Bansal (2020), which requires the runs to be on separate training sets. We further theoretically show that this peculiar phenomenon arises from the well-calibrated nature of ensembles of SGD-trained models. This ﬁnding not only provides a simple empirical measure to directly predict the test error using unlabeled test data, but also establishes a new conceptual connection between generalization and calibration.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Jiang, Yiding and Nagarajan, Vaishnavh and Baek, Christina and Kolter, J. Zico},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{nakkiran_distributional_2020,
	title = {Distributional generalization: {A} new kind of generalization},
	shorttitle = {Distributional generalization},
	abstract = {We introduce a new notion of generalization— Distributional Generalization—which roughly states that outputs of a classiﬁer at train and test time are close as distributions, as opposed to close in just their average error. For example, if we mislabel 30\% of dogs as cats in the train set of CIFAR-10, then a ResNet trained to interpolation will in fact mislabel roughly 30\% of dogs as cats on the test set as well, while leaving other classes unaffected. This behavior is not captured by classical generalization, which would only consider the average error and not the distribution of errors over the input domain. Our formal conjectures, which are much more general than this example, characterize the form of distributional generalization that can be expected in terms of problem parameters: model architecture, training procedure, number of samples, and data distribution. We give empirical evidence for these conjectures across a variety of domains in machine learning, including neural networks, kernel machines, and decision trees. Our results thus advance our empirical understanding of interpolating classiﬁers.},
	language = {en},
	journal = {arXiv preprint arXiv:2009.08092},
	author = {Nakkiran, Preetum and Bansal, Yamini},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Statistics Theory},
}

@article{zhou_-device_2022,
	title = {On-device domain generalization},
	abstract = {We present a systematic study of domain generalization (DG) for tiny neural networks. This problem is critical to on-device machine learning applications but has been overlooked in the literature where research has been merely focused on large models. Tiny neural networks have much fewer parameters and lower complexity and therefore should not be trained the same way as their large counterparts for DG applications. By conducting extensive experiments, we ﬁnd that knowledge distillation (KD), a wellknown technique for model compression, is much better for tackling the on-device DG problem than conventional DG methods. Another interesting observation is that the teacher-student gap on out-of-distribution data is bigger than that on in-distribution data, which highlights the capacity mismatch issue as well as the shortcoming of KD. We further propose a method called out-of-distribution knowledge distillation (OKD) where the idea is to teach the student how the teacher handles out-of-distribution data synthesized via disruptive data augmentation. Without adding any extra parameter to the model—hence keeping the deployment cost unchanged—OKD signiﬁcantly improves DG performance for tiny neural networks in a variety of ondevice DG scenarios for image and speech applications. We also contribute a scalable approach for synthesizing visual domain shifts, along with a new suite of DG datasets to complement existing testbeds.},
	language = {en},
	journal = {arXiv preprint arXiv:2209.07521},
	author = {Zhou, Kaiyang and Zhang, Yuanhan and Zang, Yuhang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{sanh_distilbert_2020,
	title = {Distilbert, a distilled version of bert: {Smaller}, faster, cheaper and lighter},
	shorttitle = {Distilbert, a distilled version of bert},
	abstract = {As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-theedge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller generalpurpose language representation model, called DistilBERT, which can then be ﬁnetuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-speciﬁc models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40\%, while retaining 97\% of its language understanding capabilities and being 60\% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.},
	language = {en},
	journal = {arXiv preprint arXiv:1910.01108},
	author = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
	year = {2020},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{du_algorithmic_2018,
	title = {Algorithmic regularization in learning deep homogeneous models: {Layers} are automatically balanced},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Du, Simon S and Hu, Wei and Lee, Jason D},
	year = {2018},
	pages = {382--393},
}

@article{hastie_surprises_2020,
	title = {Surprises in high-dimensional ridgeless least squares interpolation},
	abstract = {Interpolators—estimators that achieve zero training error—have attracted growing attention in machine learning, mainly because state-of-the art neural networks appear to be models of this type. In this paper, we study minimum 2 norm (“ridgeless”) interpolation in high-dimensional least squares regression. We consider two diﬀerent models for the feature distribution: a linear model, where the feature vectors xi ∈ Rp are obtained by applying a linear transform to a vector of i.i.d. entries, xi = Σ1/2zi (with zi ∈ Rp); and a nonlinear model, where the feature vectors are obtained by passing the input through a random one-layer neural network, xi = ϕ(W zi) (with zi ∈ Rd, W ∈ Rp×d a matrix of i.i.d. entries, and ϕ an activation function acting componentwise on W zi). We recover—in a precise quantitative way—several phenomena that have been observed in large-scale neural networks and kernel machines, including the “double descent” behavior of the prediction risk, and the potential beneﬁts of overparametrization.},
	language = {en},
	journal = {arXiv preprint arXiv:1903.08560},
	author = {Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J.},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Statistics Theory},
}

@article{zhang_are_2022,
	title = {Are all layers created equal?},
	volume = {23},
	number = {67},
	journal = {Journal of Machine Learning Research},
	author = {Zhang, Chiyuan and Bengio, Samy and Singer, Yoram},
	year = {2022},
	pages = {1--28},
}

@inproceedings{neyshabur_what_2020,
	title = {What is being transferred in transfer learning?},
	abstract = {One desired capability for machines is the ability to transfer their knowledge of one domain to another where data is (usually) scarce. Despite ample adaptation of transfer learning in various deep learning applications, we yet do not understand what enables a successful transfer and which part of the network is responsible for that. In this paper, we provide new tools and analyses to address these fundamental questions. Through a series of analyses on transferring to block-shufﬂed images, we separate the effect of feature reuse from learning low-level statistics of data and show that some beneﬁt of transfer learning comes from the latter. We present that when training from pre-trained weights, the model stays in the same basin in the loss landscape and different instances of such model are similar in feature space and close in parameter space.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan},
	year = {2020},
	pages = {512--523},
}

@inproceedings{chizat_lazy_2019,
	title = {On lazy training in differentiable programming},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chizat, Lenaic and Oyallon, Edouard and Bach, Francis},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
	pages = {2933--2943},
}

@inproceedings{chatterji_intriguing_2020,
	title = {The intriguing role of module criticality in the generalization of deep networks},
	abstract = {We study the phenomenon that some modules of deep neural networks (DNNs) are more critical than others. Meaning that rewinding their parameter values back to initialization, while keeping other modules ﬁxed at the trained parameters, results in a large drop in the network’s performance. Our analysis reveals interesting properties of the loss landscape which leads us to propose a complexity measure, called module criticality, based on the shape of the valleys that connect the initial and ﬁnal values of the module parameters. We formulate how generalization relates to the module criticality, and show that this measure is able to explain the superior generalization performance of some architectures over others, whereas, earlier measures fail to do so.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Chatterji, Niladri S. and Neyshabur, Behnam and Sedghi, Hanie},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{agarwal_minimax_2022,
	title = {Minimax regret optimization for robust machine learning under distribution shift},
	abstract = {In this paper, we consider learning scenarios where the learned model is evaluated under an unknown test distribution which potentially differs from the training distribution (i.e. distribution shift). The learner has access to a family of weight functions such that the test distribution is a reweighting of the training distribution under one of these functions, a setting typically studied under the name of Distributionally Robust Optimization (DRO). We consider the problem of deriving regret bounds in the classical learning theory setting, and require that the resulting regret bounds hold uniformly for all potential test distributions. We show that the DRO formulation does not guarantee uniformly small regret under distribution shift. We instead propose an alternative method called Minimax Regret Optimization (MRO), and show that under suitable conditions this method achieves uniformly low regret across all test distributions. We also adapt our technique to have stronger guarantees when the test distributions are heterogeneous in their similarity to the training data. Given the widespead optimization of worst case risks in current approaches to robust machine learning, we believe that MRO can be a strong alternative to address distribution shift scenarios.},
	language = {en},
	booktitle = {{COLT}},
	author = {Agarwal, Alekh and Zhang, Tong},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {2704--2729},
}

@article{liu_exploring_2023,
	title = {Exploring target representations for masked autoencoders},
	abstract = {Masked autoencoders have become popular training paradigms for self-supervised visual representation learning. These models randomly mask a portion of the input and reconstruct the masked portion according to assigned target representations. In this paper, we show that a careful choice of the target representation is unnecessary for learning good visual representation since different targets tend to derive similarly behaved models. Driven by this observation, we propose a multi-stage masked distillation pipeline and use a randomly initialized model as the teacher, enabling us to effectively train high-capacity models without any effort to carefully design the target representation. On various downstream tasks of classiﬁcation, transfer learning, object detection, and semantic segmentation, the proposed method to perform masked knowledge distillation with bootstrapped teachers (dBOT) outperforms previous self-supervised methods by nontrivial margins. We hope our ﬁndings, as well as the proposed method, could motivate people to rethink the roles of target representations in pre-training masked autoencoders. The code and pre-trained models are publicly available at https://github.com/liuxingbin/dbot.},
	language = {en},
	journal = {arXiv preprint arXiv:2209.03917},
	author = {Liu, Xingbin and Zhou, Jinghao and Kong, Tao and Lin, Xianming and Ji, Rongrong},
	year = {2023},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{gunasekar_characterizing_2018,
	title = {Characterizing implicit bias in terms of optimization geometry},
	abstract = {We study the implicit bias of generic optimization methods—mirror descent, natural gradient descent, and steepest descent with respect to different potentials and norms—when optimizing underdetermined linear regression or separable linear classiﬁcation problems. We explore the question of whether the speciﬁc global minimum (among the many possible global minima) reached by an algorithm can be characterized in terms of the potential or norm of the optimization geometry, and independently of hyperparameter choices such as step–size and momentum.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
	year = {2018},
	pages = {1827--1836},
}

@inproceedings{belkin_overfitting_2018,
	title = {Overfitting or perfect fitting? {Risk} bounds for classification and regression rules that interpolate},
	abstract = {Many modern machine learning models are trained to achieve zero or near-zero training error in order to obtain near-optimal (but non-zero) test error. This phenomenon of strong generalization performance for “overﬁtted” / interpolated classiﬁers appears to be ubiquitous in high-dimensional data, having been observed in deep networks, kernel machines, boosting and random forests. Their performance is consistently robust even when the data contain large amounts of label noise.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Belkin, Mikhail and Hsu, Daniel J and Mitra, Partha},
	year = {2018},
	pages = {2306--2317},
}

@article{shah_generalization_2020,
	title = {On generalization of adaptive methods for over-parameterized linear regression},
	abstract = {Over-parameterization and adaptive methods have played a crucial role in the success of deep learning in the last decade. The widespread use of over-parameterization has forced us to rethink generalization by bringing forth new phenomena, such as implicit regularization of optimization algorithms and double descent with training progression. A series of recent works have started to shed light on these areas in the quest to understand – why do neural networks generalize well? The setting of over-parameterized linear regression has provided key insights into understanding this mysterious behavior of neural networks.},
	language = {en},
	journal = {arXiv preprint arXiv:2011.14066},
	author = {Shah, Vatsal and Basu, Soumya and Kyrillidis, Anastasios and Sanghavi, Sujay},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{gunasekar_implicit_2017,
	title = {Implicit regularization in matrix factorization},
	abstract = {We study implicit regularization when optimizing an underdetermined quadratic objective over a matrix X with gradient descent on a factorization of X. We conjecture and provide empirical and theoretical evidence that with small enough step sizes and initialization close enough to the origin, gradient descent on a full dimensional factorization converges to the minimum nuclear norm solution.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Gunasekar, Suriya and Woodworth, Blake and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nathan},
	year = {2017},
	pages = {6151--6159},
}

@inproceedings{wilson_marginal_2017,
	title = {The marginal value of adaptive gradient methods in machine learning},
	abstract = {Adaptive optimization methods, which perform local optimization with a metric constructed from the history of iterates, are becoming increasingly popular for training deep neural networks. Examples include AdaGrad, RMSProp, and Adam. We show that for simple overparameterized problems, adaptive methods often ﬁnd drastically different solutions than gradient descent (GD) or stochastic gradient descent (SGD). We construct an illustrative binary classiﬁcation problem where the data is linearly separable, GD and SGD achieve zero test error, and AdaGrad, Adam, and RMSProp attain test errors arbitrarily close to half. We additionally study the empirical generalization capability of adaptive methods on several stateof-the-art deep learning models. We observe that the solutions found by adaptive methods generalize worse (often signiﬁcantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
	year = {2017},
	pages = {4148--4158},
}

@inproceedings{haochen_shape_2021,
	title = {Shape matters: {Understanding} the implicit bias of the noise covariance},
	abstract = {The noise in stochastic gradient descent (SGD) provides a crucial implicit regularization effect for training overparameterized models. Prior theoretical work largely focuses on spherical Gaussian noise, whereas empirical studies demonstrate the phenomenon that parameter-dependent noise —induced by mini-batches or label perturbation — is far more effective than Gaussian noise. This paper theoretically characterizes this phenomenon on a quadratically-parameterized model introduced by Vaskevicius et al. and Woodworth et al. We show that in an over-parameterized setting, SGD with label noise recovers the sparse ground-truth with an arbitrary initialization, whereas SGD with Gaussian noise or gradient descent overﬁts to dense solutions with large norms. Our analysis reveals that parameter-dependent noise introduces a bias towards local minima with smaller noise variance, whereas spherical Gaussian noise does not.},
	language = {en},
	booktitle = {Conference on {Learning} {Theory}},
	author = {HaoChen, Jeff Z and Wei, Colin and Lee, Jason D and Ma, Tengyu},
	year = {2021},
	pages = {2315--2357},
}

@inproceedings{li_what_2022,
	title = {What happens after sgd reaches zero loss? --{A} mathematical framework},
	shorttitle = {What happens after sgd reaches zero loss?},
	abstract = {Understanding the implicit bias of Stochastic Gradient Descent (SGD) is one of the key challenges in deep learning, especially for overparametrized models, where the local minimizers of the loss function L can form a manifold. Intuitively, with a sufﬁciently small learning rate η, SGD tracks Gradient Descent (GD) until it gets close to such manifold, where the gradient noise prevents further convergence. In such regime, Blanc et al. (2020) proved that SGD with label noise locally decreases a regularizer-like term, the sharpness of loss, tr[∇2L]. The current paper gives a general framework for such analysis by adapting ideas from Katzenberger (1991). It allows in principle a complete characterization for the regularization effect of SGD around such manifold—i.e., the ”implicit bias”—using a stochastic differential equation (SDE) describing the limiting dynamics of the parameters, which is determined jointly by the loss function and the noise covariance. This yields some new results: (1) a global analysis of the implicit bias valid for η−2 steps, in contrast to the local analysis of Blanc et al. (2020) that is only valid for η−1.6 steps and (2) allowing arbitrary noise covariance. As an application, we show with arbitrary large initialization, label noise SGD can always escape the kernel regime and only requires O(κ ln d) samples for learning a κ-sparse overparametrized linear model in Rd (Woodworth et al., 2020), while GD initialized in the kernel regime requires Ω(d) samples. This upper bound is minimax optimal and improves the previous O(κ2) upper bound (HaoChen et al., 2020).},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Li, Zhiyuan and Wang, Tianhao and Arora, Sanjeev},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{gunasekar_implicit_2018,
	title = {Implicit bias of gradient descent on linear convolutional networks},
	abstract = {We show that gradient descent on full width linear convolutional networks of depth L converges to a linear predictor related to the 2/L bridge penalty in the frequency domain. This is in contrast to fully connected linear networks, where regardless of depth, gradient descent converges to the 2 maximum margin solution.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
	year = {2018},
	pages = {9482--9491},
}

@article{jin_implicit_2023,
	title = {Implicit bias of gradient descent for mean squared error regression with two-layer wide neural networks},
	abstract = {We investigate gradient descent training of wide neural networks and the corresponding implicit bias in function space. For univariate regression, we show that the solution of training a width-n shallow ReLU network is within n−1/2 of the function which ﬁts the training data and whose diﬀerence from the initial function has the smallest 2-norm of the second derivative weighted by a curvature penalty that depends on the probability distribution that is used to initialize the network parameters. We compute the curvature penalty function explicitly for various common initialization procedures. For instance, asymmetric initialization with a uniform distribution yields a constant curvature penalty, and thence the solution function is the natural cubic spline interpolation of the training data. For stochastic gradient descent we obtain the same implicit bias result. We obtain a similar result for diﬀerent activation functions. For multivariate regression we show an analogous result, whereby the second derivative is replaced by the Radon transform of a fractional Laplacian. For initialization schemes that yield a constant penalty function, the solutions are polyharmonic splines. Moreover, we show that the training trajectories are captured by trajectories of smoothing splines with decreasing regularization strength.},
	language = {en},
	journal = {arXiv preprint arXiv:2006.07356},
	author = {Jin, Hui and Montúfar, Guido},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, I.2.6, G.3, 68Q32, 68T05},
}

@inproceedings{subramonian_group_nodate,
	title = {Group excess risk bound of overparameterized linear regression with constant-stepsize sgd},
	booktitle = {Workshop on {Trustworthy} and {Socially} {Responsible} {Machine} {Learning}, {NeurIPS} 2022},
	author = {Subramonian, Arjun and Sagun, Levent and Chang, Kai-Wei and Sun, Yizhou},
}

@inproceedings{fan_theoretical_2020,
	title = {A theoretical analysis of deep {Q}-learning},
	abstract = {Despite the great empirical success of deep reinforcement learning, its theoretical foundation is less well understood. In this work, we make the first attempt to theoretically understand the deep Q-network (DQN) algorithm (Mnih et al., 2015) from both algorithmic and statistical perspectives. In specific, we focus on a slight simplification of DQN that fully captures its key features. Under mild assumptions, we establish the algorithmic and statistical rates of convergence for the action-value functions of the iterative policy sequence obtained by DQN. In particular, the statistical error characterizes the bias and variance that arise from approximating the action-value function using deep neural network, while the algorithmic error converges to zero at a geometric rate. As a byproduct, our analysis provides justifications for the techniques of experience replay and target network, which are crucial to the empirical success of DQN. Furthermore, as a simple extension of DQN, we propose the Minimax-DQN algorithm for zero-sum Markov game with two players. Borrowing the analysis of DQN, we also quantify the difference between the policies obtained by Minimax-DQN and the Nash equilibrium of the Markov game in terms of both the algorithmic and statistical rates of convergence.},
	language = {en},
	author = {Fan, Jianqing and Wang, Zhaoran and Xie, Yuchen and Yang, Zhuoran},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
	pages = {486--489},
}

@inproceedings{zhang_type_2020,
	title = {A type of generalization error induced by initialization in deep neural networks},
	isbn = {2640-3498},
	booktitle = {Mathematical and {Scientific} {Machine} {Learning}},
	author = {Zhang, Yaoyu and Xu, Zhi-Qin John and Luo, Tao and Ma, Zheng},
	year = {2020},
	pages = {144--164},
}

@inproceedings{lee_finite_2020,
	title = {Finite versus infinite neural networks: an empirical study},
	volume = {33},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lee, Jaehoon and Schoenholz, Samuel and Pennington, Jeffrey and Adlam, Ben and Xiao, Lechao and Novak, Roman and Sohl-Dickstein, Jascha},
	year = {2020},
	pages = {15156--15172},
}

@article{xu_training_2019,
	title = {Training behavior of deep neural network in frequency domain},
	abstract = {Why deep neural networks (DNNs) capable of overﬁtting often generalize well in practice is a mystery [24]. To ﬁnd a potential mechanism, we focus on the study of implicit biases underlying the training process of DNNs. In this work, for both real and synthetic datasets, we empirically ﬁnd that a DNN with common settings ﬁrst quickly captures the dominant low-frequency components, and then relatively slowly captures the high-frequency ones. We call this phenomenon Frequency Principle (F-Principle). The F-Principle can be observed over DNNs of various structures, activation functions, and training algorithms in our experiments. We also illustrate how the F-Principle helps understand the eﬀect of early-stopping as well as the generalization of DNNs. This FPrinciple potentially provides insight into a general principle underlying DNN optimization and generalization.},
	language = {en},
	journal = {arXiv preprint arXiv:1807.01251},
	author = {Xu, Zhi-Qin John and Zhang, Yaoyu and Xiao, Yanyang},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Information Theory, I.2.6, Mathematics - Statistics Theory, 62-07},
}

@inproceedings{dherin_why_2022,
	title = {Why neural networks find simple solutions: {The} many regularizers of geometric complexity},
	volume = {35},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dherin, Benoit and Munn, Michael and Rosca, Mihaela and Barrett, David},
	year = {2022},
	pages = {2333--2349},
}

@inproceedings{bowman_spectral_2022,
	title = {Spectral bias outside the training set for deep networks in the kernel regime},
	volume = {35},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bowman, Benjamin and Montufar, Guido F.},
	year = {2022},
	pages = {30362--30377},
}

@inproceedings{zou_benefits_2021,
	title = {The benefits of implicit regularization from {SGD} in least squares problems},
	volume = {34},
	booktitle = {Advances in neural information processing systems},
	author = {Zou, Difan and Wu, Jingfeng and Braverman, Vladimir and Gu, Quanquan and Foster, Dean P. and Kakade, Sham},
	year = {2021},
	pages = {5456--5468},
}

@inproceedings{wu_last_2022,
	title = {Last iterate risk bounds of {SGD} with decaying stepsize for overparameterized linear regression},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Wu, Jingfeng and Zou, Difan and Braverman, Vladimir and Gu, Quanquan and Kakade, Sham},
	year = {2022},
	pages = {24280--24314},
}

@inproceedings{zou_benign_2021,
	title = {Benign overfitting of constant-stepsize {SGD} for linear regression},
	isbn = {2640-3498},
	booktitle = {Conference on {Learning} {Theory}},
	author = {Zou, Difan and Wu, Jingfeng and Braverman, Vladimir and Gu, Quanquan and Kakade, Sham},
	year = {2021},
	pages = {4633--4635},
}

@inproceedings{shachaf_theoretical_2021,
	title = {A theoretical analysis of fine-tuning with linear teachers},
	abstract = {Fine-tuning is a common practice in deep learning, achieving excellent generalization results on downstream tasks using relatively little training data. Although widely used in practice, it is lacking strong theoretical understanding. Here we analyze the sample complexity of this scheme for regression with linear teachers in several architectures. Intuitively, the success of ﬁne-tuning depends on the similarity between the source tasks and the target task, however measuring this similarity is non trivial. We show that generalization is related to a measure that considers the relation between the source task, target task and covariance structure of the target data. In the setting of linear regression, we show that under realistic settings a substantial sample complexity reduction is plausible when the above measure is low. For deep linear regression, we present a novel result regarding the inductive bias of gradient-based training when the network is initialized with pretrained weights. Using this result we show that the similarity measure for this setting is also affected by the depth of the network. We further present results on shallow ReLU models, and analyze the dependence of sample complexity on source and target tasks in this setting.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Shachaf, Gal and Brutzkus, Alon and Globerson, Amir},
	year = {2021},
	pages = {15382--15394},
}

@inproceedings{asano_augmented_2023,
	title = {The augmented image prior: {Distilling} 1000 classes by extrapolating from a single image},
	shorttitle = {The augmented image prior},
	abstract = {What can neural networks learn about the visual world when provided with only a single image as input? While any image obviously cannot contain the multitudes of all existing objects, scenes and lighting conditions – within the space of all 2563·224·224 possible 224-sized square images, it might still provide a strong prior for natural images. To analyze this “augmented image prior” hypothesis, we develop a simple framework for training neural networks from scratch using a single image and augmentations using knowledge distillation from a supervised pretrained teacher. With this, we ﬁnd the answer to the above question to be: ‘surprisingly, a lot’. In quantitative terms, we ﬁnd accuracies of 94\%/74\% on CIFAR-10/100, 69\% on ImageNet, and by extending this method to video and audio, 51\% on Kinetics-400 and 84\% on SpeechCommands. In extensive analyses spanning 13 datasets, we disentangle the effect of augmentations, choice of data and network architectures and also provide qualitative evaluations that include lucid “panda neurons” in networks that have never even seen one.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Asano, Yuki M. and Saeed, Aaqib},
	year = {2023},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{lv_improving_2023,
	title = {Improving generalization with domain convex game},
	abstract = {Domain generalization (DG) tends to alleviate the poor generalization capability of deep neural networks by learning model with multiple source domains. A classical solution to DG is domain augmentation, the common belief of which is that diversifying source domains will be conducive to the out-of-distribution generalization. However, these claims are understood intuitively, rather than mathematically. Our explorations empirically reveal that the correlation between model generalization and the diversity of domains may be not strictly positive, which limits the effectiveness of domain augmentation. This work therefore aim to guarantee and further enhance the validity of this strand. To this end, we propose a new perspective on DG that recasts it as a convex game between domains. We first encourage each diversified domain to enhance model generalization by elaborately designing a regularization term based on supermodularity. Meanwhile, a sample filter is constructed to eliminate low-quality samples, thereby avoiding the impact of potentially harmful information. Our framework presents a new avenue for the formal analysis of DG, heuristic analysis and extensive experiments demonstrate the rationality and effectiveness.},
	language = {en},
	booktitle = {{CVPR}},
	author = {Lv, Fangrui and Liang, Jian and Li, Shuang and Zhang, Jinming and Liu, Di},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{yousefzadeh_deep_2021,
	title = {Deep learning generalization and the convex hull of training sets},
	abstract = {We study the generalization of deep learning models in relation to the convex hull of their training sets. A trained image classiﬁer basically partitions its domain via decision boundaries and assigns a class to each of those partitions. The location of decision boundaries inside the convex hull of training set can be investigated in relation to the training samples. However, our analysis shows that in standard image classiﬁcation datasets, all testing images are considerably outside that convex hull, in the pixel space, in the wavelet space, and in the internal representations learned by deep networks. Therefore, the performance of a trained model partially depends on how its decision boundaries are extended outside the convex hull of its training data. From this perspective which is not studied before, over-parameterization of deep learning models may be considered a necessity for shaping the extension of decision boundaries. At the same time, over-parameterization should be accompanied by a speciﬁc training regime, in order to yield a model that not only ﬁts the training set, but also its decision boundaries extend desirably outside the convex hull. To illustrate this, we investigate the decision boundaries of a neural network, with various degrees of parameters, inside and outside the convex hull of its training set. Moreover, we use a polynomial decision boundary to study the necessity of over-parameterization and the inﬂuence of training regime in shaping its extensions outside the convex hull of training set.},
	language = {en},
	journal = {arXiv preprint arXiv:2101.09849},
	author = {Yousefzadeh, Roozbeh},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Mathematics - Differential Geometry},
}

@article{yousefzadeh_what_2022,
	title = {To what extent should we trust {AI} models when they extrapolate?},
	abstract = {Many applications affecting human lives rely on models that have come to be known under the umbrella of machine learning and artificial intelligence. These AI models are usually complicated mathematical functions that map from an input space to an output space. Stakeholders are interested to know the rationales behind models' decisions and functional behavior. We study this functional behavior in relation to the data used to create the models. On this topic, scholars have often assumed that models do not extrapolate, i.e., they learn from their training samples and process new input by interpolation. This assumption is questionable: we show that models extrapolate frequently; the extent of extrapolation varies and can be socially consequential. We demonstrate that extrapolation happens for a substantial portion of datasets more than one would consider reasonable. How can we trust models if we do not know whether they are extrapolating? Given a model trained to recommend clinical procedures for patients, can we trust the recommendation when the model considers a patient older or younger than all the samples in the training set? If the training set is mostly Whites, to what extent can we trust its recommendations about Black and Hispanic patients? Which dimension (race, gender, or age) does extrapolation happen? Even if a model is trained on people of all races, it still may extrapolate in significant ways related to race. The leading question is, to what extent can we trust AI models when they process inputs that fall outside their training set? This paper investigates several social applications of AI, showing how models extrapolate without notice. We also look at different sub-spaces of extrapolation for specific individuals subject to AI models and report how these extrapolations can be interpreted, not mathematically, but from a humanistic point of view.},
	language = {en},
	journal = {arXiv preprint arXiv:2201.11260},
	author = {Yousefzadeh, Roozbeh and Cao, Xuenan},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Mathematics - Optimization and Control},
}

@article{agarwala_geometry_2021,
	title = {Geometry and generalization: {Eigenvalues} as predictors of where a network will fail to generalize},
	shorttitle = {Geometry and generalization},
	abstract = {We study the deformation of the input space by a trained autoencoder via the Jacobians of the trained weight matrices. In doing so, we prove bounds for the mean squared errors for points in the input space, under assumptions regarding the orthogonality of the eigenvectors. We also show that the trace and the product of the eigenvalues of the Jacobian matrices is a good predictor of the MSE on test points. This is a dataset independent means of testing an autoencoder’s ability to generalize on new input. Namely, no knowledge of the dataset on which the network was trained is needed, only the parameters of the trained model.},
	language = {en},
	journal = {arXiv preprint arXiv:2107.06386},
	author = {Agarwala, Susama and Dees, Benjamin and Gearhart, Andrew and Lowman, Corey},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Mathematics - Differential Geometry},
}

@inproceedings{wu_direction_2021,
	title = {Direction matters: {On} the implicit bias of stochastic gradient descent with moderate learning rate},
	shorttitle = {Direction matters},
	abstract = {Understanding the algorithmic bias of stochastic gradient descent (SGD) is one of the key challenges in modern machine learning and deep learning theory. Most of the existing works, however, focus on very small or even inﬁnitesimal learning rate regime, and fail to cover practical scenarios where the learning rate is moderate and annealing. In this paper, we make an initial attempt to characterize the particular regularization effect of SGD in the moderate learning rate regime by studying its behavior for optimizing an overparameterized linear regression problem. In this case, SGD and GD are known to converge to the unique minimum-norm solution; however, with the moderate and annealing learning rate, we show that they exhibit different directional bias: SGD converges along the large eigenvalue directions of the data matrix, while GD goes after the small eigenvalue directions. Furthermore, we show that such directional bias does matter when early stopping is adopted, where the SGD output is nearly optimal but the GD output is suboptimal. Finally, our theory explains several folk arts in practice used for SGD hyperparameter tuning, such as (1) linearly scaling the initial learning rate with batch size; and (2) overrunning SGD with high learning rate even when the loss stops decreasing.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Wu, Jingfeng and Zou, Difan and Braverman, Vladimir and Gu, Quanquan},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{samvelyan_starcraft_2019,
	title = {The starcraft multi-agent challenge},
	abstract = {In the last few years, deep multi-agent reinforcement learning (RL) has become a highly active area of research. A particularly challenging class of problems in this area is partially observable, cooperative, multi-agent learning, in which teams of agents must learn to coordinate their behaviour while conditioning only on their private observations. This is an attractive research area since such problems are relevant to a large number of real-world systems and are also more amenable to evaluation than general-sum problems.},
	language = {en},
	booktitle = {Workshop on {Deep} {Reinforcement} {Learning} at the 33rd {Conference} on {Neural} {Information} {Processing} {Systems}},
	author = {Samvelyan, Mikayel and Rashid, Tabish and de Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim G. J. and Hung, Chia-Man and Torr, Philip H. S. and Foerster, Jakob and Whiteson, Shimon},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Multiagent Systems},
}

@article{zeng_glm-130b_2022,
	title = {{GLM}-{130B}: {An} open bilingual pre-trained model},
	shorttitle = {{GLM}-{130B}},
	abstract = {We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters. It is an attempt to open-source a 100B-scale model at least as good as GPT-3 and unveil how models of such a scale can be successfully pre-trained. Over the course of this effort, we face numerous unexpected technical and engineering challenges, particularly on loss spikes and disconvergence. In this paper, we introduce the training process of GLM-130B including its design choices, training strategies for both efﬁciency and stability, and engineering efforts. The resultant GLM-130B model offers signiﬁcant outperformance over GPT-3 175B on a wide range of popular English benchmarks while the performance advantage is not observed in OPT-175B and BLOOM-176B. It also consistently and signiﬁcantly outperforms ERNIE TITAN 3.0 260B—the largest Chinese language model—across related benchmarks. Finally, we leverage a unique scaling property of GLM-130B to reach INT4 quantization, without quantization aware training and with almost no performance loss, making it the ﬁrst among 100B-scale models. More importantly, the property allows its effective inference on 4×RTX 3090 (24G) or 8×RTX 2080 Ti (11G) GPUs, the most ever affordable GPUs required for using 100B-scale models. The GLM-130B model weights are publicly accessible and its code, training logs, related toolkit, and lessons learned are open-sourced at https://github.com/THUDM/GLM-130B.},
	language = {en},
	journal = {arXiv preprint arXiv:2210.02414},
	author = {Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and Tam, Weng Lam and Ma, Zixuan and Xue, Yufei and Zhai, Jidong and Chen, Wenguang and Zhang, Peng and Dong, Yuxiao and Tang, Jie},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{dong_first_2023,
	title = {First steps toward understanding the extrapolation of nonlinear models to unseen domains},
	abstract = {Real-world machine learning applications often involve deploying neural networks to domains that are not seen in the training time. Hence, we need to understand the extrapolation of nonlinear models—under what conditions on the distributions and function class, models can be guaranteed to extrapolate to new test distributions. The question is very challenging because even two-layer neural networks cannot be guaranteed to extrapolate outside the support of the training distribution without further assumptions on the domain shift. This paper makes some initial steps toward analyzing the extrapolation of nonlinear models for structured domain shift. We primarily consider settings where the marginal distribution of each coordinate of the data (or subset of coordinates) does not shift signiﬁcantly across the training and test distributions, but the joint distribution may have a much bigger shift. We prove that the family of nonlinear models of the form f (x) = fi(xi), where fi is an arbitrary function on the subset of features xi, can extrapolate to unseen distributions, if the covariance of the features is well-conditioned. To the best of our knowledge, this is the ﬁrst result that goes beyond linear models and the bounded density ratio assumption, even though the assumptions on the distribution shift and function class are stylized.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Dong, Kefan and Ma, Tengyu},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{gudibande_false_2023,
	title = {The false promise of imitating proprietary {LLMs}},
	abstract = {An emerging method to cheaply improve a weaker language model is to finetune it on outputs from a stronger model, such as a proprietary system like ChatGPT (e.g., Alpaca, Self-Instruct, and others). This approach looks to cheaply imitate the proprietary model’s capabilities using a weaker open-source model. In this work, we critically analyze this approach. We first finetune a series of LMs that imitate ChatGPT using varying base model sizes (1.5B–13B), data sources, and imitation data amounts (0.3M–150M tokens). We then evaluate the models using crowd raters and canonical NLP benchmarks. Initially, we were surprised by the output quality of our imitation models—they appear far better at following instructions, and crowd workers rate their outputs as competitive with ChatGPT. However, when conducting more targeted automatic evaluations, we find that imitation models close little to none of the gap from the base LM to ChatGPT on tasks that are not heavily supported in the imitation data. We show that these performance discrepancies may slip past human raters because imitation models are adept at mimicking ChatGPT’s style but not its factuality. Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs. In turn, we argue that the highest leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.},
	language = {en},
	journal = {arXiv preprint arXiv:2305.15717},
	author = {Gudibande, Arnav and Wallace, Eric and Snell, Charlie and Geng, Xinyang and Liu, Hao and Abbeel, Pieter and Levine, Sergey and Song, Dawn},
	year = {2023},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{gandelsman_test-time_2022,
	title = {Test-time training with masked autoencoders},
	abstract = {Test-time training adapts to a new test distribution on the fly by optimizing a model for each test input using self-supervision. In this paper, we use masked autoencoders for this one-sample learning problem. Empirically, our simple method improves generalization on many visual benchmarks for distribution shifts. Theoretically, we characterize this improvement in terms of the bias-variance trade-off.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Gandelsman, Yossi and Sun, Yu and Chen, Xinlei and Efros, Alexei A},
	year = {2022},
}

@inproceedings{niu_towards_2023,
	title = {Towards stable test-time adaptation in dynamic wild world},
	abstract = {Test-time adaptation (TTA) has shown to be effective at tackling distribution shifts between training and testing data by adapting a given model on test samples. However, the online model updating of TTA may be unstable and this is often a key obstacle preventing existing TTA methods from being deployed in the real world. Speciﬁcally, TTA may fail to improve or even harm the model performance when test data have: 1) mixed distribution shifts, 2) small batch sizes, and 3) online imbalanced label distribution shifts, which are quite common in practice. In this paper, we investigate the unstable reasons and ﬁnd that the batch norm layer is a crucial factor hindering TTA stability. Conversely, TTA can perform more stably with batch-agnostic norm layers, i.e., group or layer norm. However, we observe that TTA with group and layer norms does not always succeed and still suffers many failure cases. By digging into the failure cases, we ﬁnd that certain noisy test samples with large gradients may disturb the model adaption and result in collapsed trivial solutions, i.e., assigning the same class label for all samples. To address the above collapse issue, we propose a sharpness-aware and reliable entropy minimization method, called SAR, for further stabilizing TTA from two aspects: 1) remove partial noisy samples with large gradients, 2) encourage model weights to go to a ﬂat minimum so that the model is robust to the remaining noisy samples. Promising results demonstrate that SAR performs more stably over prior methods and is computationally efﬁcient under the above wild test scenarios. The source code is available at https://github.com/mr-eggplant/SAR.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Niu, Shuaicheng and Wu, Jiaxiang and Zhang, Yifan and Wen, Zhiquan and Chen, Yaofo and Zhao, Peilin and Tan, Mingkui},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{mao_context-aware_2022,
	title = {Context-aware robust fine-tuning},
	abstract = {Contrastive Language-Image Pre-trained (CLIP) models have zero-shot ability of classifying an image belonging to “[CLASS]” by using similarity between the image and the prompt sentence “a [CONTEXT] of [CLASS]”. Based on exhaustive text cues in “[CONTEXT]”, CLIP model is aware of diﬀerent contexts, e.g. background, style, viewpoint, and exhibits unprecedented robustness against a wide range of distribution shifts. However, recent works ﬁnd further ﬁne-tuning of CLIP models improves accuracy but sacriﬁces the robustness on downstream tasks. We conduct an empirical investigation to show ﬁne-tuning will corrupt the context-aware ability of pre-trained CLIP features. To solve this problem, we propose Context-Aware Robust Fine-tuning (CAR-FT). CAR-FT regularizes the model during ﬁne-tuning to capture the context information. Speciﬁcally, we use zero-shot prompt weights to get the context distribution contained in the image. By minimizing the Kullback-Leibler Divergence (KLD) between context distributions induced by original/ﬁne-tuned CLIP models, CAR-FT makes the context-aware ability of CLIP inherited into downstream tasks, and achieves both higher In-Distribution (ID) and Out-Of-Distribution (OOD) accuracy. The experimental results show CAR-FT achieves superior robustness on ﬁve OOD test datasets of ImageNet, and meanwhile brings accuracy gains on nine downstream tasks. Additionally, CAR-FT surpasses previous Domain Generalization (DG) methods and gets 78.5\% averaged accuracy on DomainBed benchmark, building the new state-of-the-art.},
	language = {en},
	journal = {arXiv preprint arXiv:2211.16175},
	author = {Mao, Xiaofeng and Chen, Yuefeng and Jia, Xiaojun and Zhang, Rong and Xue, Hui and Li, Zhao},
	year = {2022},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{dai_coatnet_2021,
	title = {Coatnet: marrying convolution and attention for all data sizes},
	abstract = {Transformers have attracted increasing interests in computer vision, but they still fall behind state-of-the-art convolutional networks. In this work, we show that while Transformers tend to have larger model capacity, their generalization can be worse than convolutional networks due to the lack of the right inductive bias. To effectively combine the strengths from both architectures, we present CoAtNets (pronounced “coat” nets), a family of hybrid models built from two key insights: (1) depthwise Convolution and self-Attention can be naturally uniﬁed via simple relative attention; (2) vertically stacking convolution layers and attention layers in a principled way is surprisingly effective in improving generalization, capacity and efﬁciency. Experiments show that our CoAtNets achieve state-of-the-art performance under different resource constraints across various datasets: Without extra data, CoAtNet achieves 86.0\% ImageNet top-1 accuracy; When pre-trained with 13M images from ImageNet-21K, our CoAtNet achieves 88.56\% top-1 accuracy, matching ViT-huge pre-trained with 300M images from JFT-300M while using 23x less data; Notably, when we further scale up CoAtNet with JFT-3B, it achieves 90.88\% top-1 accuracy on ImageNet, establishing a new state-of-the-art result.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan, Mingxing},
	year = {2021},
	pages = {3965--3977},
}

@article{domingos_every_2020,
	title = {Every model learned by gradient descent is approximately a kernel machine},
	abstract = {Deep learning’s successes are often attributed to its ability to automatically discover new representations of the data, rather than relying on handcrafted features like other learning methods. We show, however, that deep networks learned by the standard gradient descent algorithm are in fact mathematically approximately equivalent to kernel machines, a learning method that simply memorizes the data and uses it directly for prediction via a similarity function (the kernel). This greatly enhances the interpretability of deep network weights, by elucidating that they are eﬀectively a superposition of the training examples. The network architecture incorporates knowledge of the target function into the kernel. This improved understanding should lead to better learning algorithms.},
	language = {en},
	journal = {arXiv preprint arXiv:2012.00152},
	author = {Domingos, Pedro},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing, I.2.6, I.5.1},
}

@inproceedings{hardt_identity_2017,
	title = {Identity matters in deep learning},
	abstract = {An emerging design principle in deep learning is that each layer of a deep artiﬁcial neural network should be able to easily express the identity transformation. This idea not only motivated various normalization techniques, such as batch normalization, but was also key to the immense success of residual networks.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Hardt, Moritz and Ma, Tengyu},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{arora_exact_2019,
	title = {On exact computation with an infinitely wide neural net},
	abstract = {How well does a classic deep net architecture like AlexNet or VGG19 classify on a standard dataset such as CIFAR-10 when its “width”— namely, number of channels in convolutional layers, and number of nodes in fully-connected internal layers —is allowed to increase to inﬁnity? Such questions have come to the forefront in the quest to theoretically understand deep learning and its mysteries about optimization and generalization. They also connect deep learning to notions such as Gaussian processes and kernels. A recent paper [Jacot et al., 2018] introduced the Neural Tangent Kernel (NTK) which captures the behavior of fully-connected deep nets in the inﬁnite width limit trained by gradient descent; this object was implicit in some other recent papers. An attraction of such ideas is that a pure kernel-based method is used to capture the power of a fully-trained deep net of inﬁnite width.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
	year = {2019},
	pages = {8139--8148},
}

@inproceedings{chen_memory_2022,
	title = {Memory bounds for continual learning},
	abstract = {Continual learning, or lifelong learning, is a formidable current challenge to machine learning. It requires the learner to solve a sequence of k diﬀerent learning tasks, one after the other, while retaining its aptitude for earlier tasks; the continual learner should scale better than the obvious solution of developing and maintaining a separate learner for each of the k tasks. We embark on a complexity-theoretic study of continual learning in the PAC framework. We make novel uses of communication complexity to establish that any continual learner, even an improper one, needs memory that grows linearly with k, strongly suggesting that the problem is intractable. When logarithmically many passes over the learning tasks are allowed, we provide an algorithm based on multiplicative weights update whose memory requirement scales well; we also establish that improper learning is necessary for such performance. We conjecture that these results may lead to new promising approaches to continual learning.},
	language = {en},
	booktitle = {{FOCS}},
	author = {Chen, Xi and Papadimitriou, Christos and Peng, Binghui},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Data Structures and Algorithms},
	pages = {519--530},
}

@inproceedings{lei_near-optimal_2021,
	title = {Near-optimal linear regression under distribution shift},
	abstract = {Transfer learning is essential when sufﬁcient data comes from the source domain, with scarce labeled data from the target domain. We develop estimators that achieve minimax linear risk for linear regression problems under distribution shift. Our algorithms cover different transfer learning settings including covariate shift and model shift. We also consider when data are generated from either linear or general nonlinear models. We show that linear minimax estimators are within an absolute constant of the minimax risk even among nonlinear estimators for various source/target distributions.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Lei, Qi and Hu, Wei and Lee, Jason D.},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {6164--6174},
}

@inproceedings{wei_more_2022,
	title = {More than a toy: {Random} matrix models predict how real-world neural representations generalize},
	shorttitle = {More than a toy},
	abstract = {Of theories for why large-scale machine learning models generalize despite being vastly overparameterized, which of their assumptions are needed to capture the qualitative phenomena of generalization in the real world? On one hand, we ﬁnd that most theoretical analyses fall short of capturing these qualitative phenomena even for kernel regression, when applied to kernels derived from large-scale neural networks (e.g., ResNet-50) and real data (e.g., CIFAR-100). On the other hand, we ﬁnd that the classical GCV estimator (Craven and Wahba, 1978) accurately predicts generalization risk even in such overparameterized settings. To bolster this empirical ﬁnding, we prove that the GCV estimator converges to the generalization risk whenever a local random matrix law holds. Finally, we apply this random matrix theory lens to explain why pretrained representations generalize better as well as what factors govern scaling laws for kernel regression. Our ﬁndings suggest that random matrix theory, rather than just being a toy model, may be central to understanding the properties of neural representations in practice.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Wei, Alexander and Hu, Wei and Steinhardt, Jacob},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {23549--23588},
}

@inproceedings{bietti_inductive_2019,
	title = {On the inductive bias of neural tangent kernels},
	abstract = {State-of-the-art neural networks are heavily over-parameterized, making the optimization algorithm a crucial ingredient for learning predictive models with good generalization properties. A recent line of work has shown that in a certain overparameterized regime, the learning dynamics of gradient descent are governed by a certain kernel obtained at initialization, called the neural tangent kernel. We study the inductive bias of learning in such a regime by analyzing this kernel and the corresponding function space (RKHS). In particular, we study smoothness, approximation, and stability properties of functions with ﬁnite norm, including stability to image deformations in the case of convolutional networks, and compare to other known kernels for similar architectures.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bietti, Alberto and Mairal, Julien},
	year = {2019},
	pages = {12873--12884},
}

@inproceedings{mei_learning_2021,
	title = {Learning with invariances in random features and kernel models},
	abstract = {A number of machine learning tasks entail a high degree of invariance: the data distribution does not change if we act on the data with a certain group of transformations. For instance, labels of images are invariant under translations of the images. Certain neural network architectures —for instance, convolutional networks—are believed to owe their success to the fact that they exploit such invariance properties. With the objective of quantifying the gain achieved by invariant architectures, we introduce two classes of models: invariant random features and invariant kernel methods. The latter includes, as a special case, the neural tangent kernel for convolutional networks with global average pooling. We consider uniform covariates distributions on the sphere and hypercube and a general invariant target function. We characterize the test error of invariant methods in a high-dimensional regime in which the sample size and number of hidden units scale as polynomials in the dimension, for a class of groups that we call ‘degeneracy α’, with α ≤ 1. We show that exploiting invariance in the architecture saves a dα factor (d stands for the dimension) in sample size and number of hidden units to achieve the same test error as for unstructured architectures. Finally, we show that output symmetrization of an unstructured kernel estimator does not give a signiﬁcant statistical improvement; on the other hand, data augmentation with an unstructured kernel estimator is equivalent to an invariant kernel estimator and enjoys the same improvement in statistical efﬁciency.},
	language = {en},
	booktitle = {Conference on {Learning} {Theory}},
	author = {Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
	year = {2021},
	pages = {3351--3418},
}

@article{lu_deep_2021,
	title = {Deep network approximation for smooth functions},
	volume = {53},
	issn = {0036-1410, 1095-7154},
	doi = {10.1137/20M134695X},
	abstract = {This paper establishes the (nearly) optimal approximation error characterization of deep rectiﬁed linear unit (ReLU) networks for smooth functions in terms of both width and depth simultaneously. To that end, we ﬁrst prove that multivariate polynomials can be approximated by deep ReLU networks of width O(N ) and depth O(L) with an approximation error O(N −L). Through local Taylor expansions and their deep ReLU network approximations, we show that deep ReLU networks of width O(N ln N ) and depth O(L ln L) can approximate f ∈ Cs([0, 1]d) with a nearly optimal approximation error O( f Cs([0,1]d)N −2s dL−2s d). Our estimate is non-asymptotic in the sense that it is valid for arbitrary width and depth speciﬁed by N ∈ N+ and L ∈ N+, respectively.},
	language = {en},
	number = {5},
	journal = {SIAM Journal on Mathematical Analysis},
	author = {Lu, Jianfeng and Shen, Zuowei and Yang, Haizhao and Zhang, Shijun},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Numerical Analysis},
	pages = {5465--5506},
}

@inproceedings{liu_linearity_2020,
	title = {On the linearity of large non-linear models: {When} and why the tangent kernel is constant},
	abstract = {The goal of this work is to shed light on the remarkable phenomenon of “transition to linearity” of certain neural networks as their width approaches inﬁnity. We show that the “transition to linearity” of the model and, equivalently, constancy of the (neural) tangent kernel (NTK) result from the scaling properties of the norm of the Hessian matrix of the network as a function of the network width. We present a general framework for understanding the constancy of the tangent kernel via Hessian scaling applicable to the standard classes of neural networks. Our analysis provides a new perspective on the phenomenon of constant tangent kernel, which is different from the widely accepted “lazy training”. Furthermore, we show that the “transition to linearity” is not a general property of wide neural networks and does not hold when the last layer of the network is non-linear. It is also not necessary for successful optimization by gradient descent.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Liu, Chaoyue and Zhu, Libin and Belkin, Mikhail},
	year = {2020},
	pages = {15954--15964},
}

@inproceedings{hu_lora_2022,
	title = {{LoRA}: {Low}-rank adaptation of large language models},
	shorttitle = {Lora},
	abstract = {An important paradigm of natural language processing consists of large-scale pretraining on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full ﬁne-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example – deploying independent instances of ﬁne-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pretrained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B ﬁne-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than ﬁnetuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deﬁciency in language model adaptation, which sheds light on the efﬁcacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{nacson_stochastic_2019,
	title = {Stochastic gradient descent on separable data: {Exact} convergence with a fixed learning rate},
	abstract = {Stochastic Gradient Descent (SGD) is a central tool in machine learning. We prove that SGD converges to zero loss, even with a ﬁxed (nonvanishing) learning rate — in the special case of homogeneous linear classiﬁers with smooth monotone loss functions, optimized on linearly separable data. Previous works assumed either a vanishing learning rate, iterate averaging, or loss assumptions that do not hold for monotone loss functions used for classiﬁcation, such as the logistic loss. We prove our result on a ﬁxed dataset, both for sampling with or without replacement. Furthermore, for logistic loss (and similar exponentially-tailed losses), we prove that with SGD the weight vector converges in direction to the L2 max margin vector as O(1/ log(t)) for almost all separable datasets, and the loss converges as O(1/t) — similarly to gradient descent. Lastly, we examine the case of a ﬁxed learning rate proportional to the minibatch size. We prove that in this case, the asymptotic convergence rate of SGD (with replacement) does not depend on the minibatch size in terms of epochs, if the support vectors span the data. These results may suggest an explanation to similar behaviors observed in deep networks, when trained with SGD.},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Nacson, Mor Shpigel and Srebro, Nathan and Soudry, Daniel},
	year = {2019},
	pages = {3051--3059},
}

@inproceedings{goyal_finetune_2023,
	title = {Finetune like you pretrain: {Improved} finetuning of zero-shot vision models},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Goyal, Sachin and Kumar, Ananya and Garg, Sankalp and Kolter, Zico and Raghunathan, Aditi},
	year = {2023},
	pages = {19338--19347},
}

@inproceedings{chizat_implicit_2020,
	title = {Implicit bias of gradient descent for wide two-layer neural networks trained with the logistic loss},
	abstract = {Neural networks trained to minimize the logistic (a.k.a. cross-entropy) loss with gradient-based methods are observed to perform well in many supervised classiﬁcation tasks. Towards understanding this phenomenon, we analyze the training and generalization behavior of inﬁnitely wide two-layer neural networks with homogeneous activations. We show that the limits of the gradient ﬂow on exponentially tailed losses can be fully characterized as a max-margin classiﬁer in a certain nonHilbertian space of functions. In presence of hidden low-dimensional structures, the resulting margin is independent of the ambiant dimension, which leads to strong generalization bounds. In contrast, training only the output layer implicitly solves a kernel support vector machine, which a priori does not enjoy such an adaptivity. Our analysis of training is non-quantitative in terms of running time but we prove computational guarantees in simpliﬁed settings by showing equivalences with online mirror descent. Finally, numerical experiments suggest that our analysis describes well the practical behavior of two-layer neural networks with ReLU activations and conﬁrm the statistical beneﬁts of this implicit bias.},
	language = {en},
	booktitle = {Conference on {Learning} {Theory}},
	author = {Chizat, Lenaıc and Chizat, Lenaic and Fr, Universite-Paris-Saclay},
	year = {2020},
}

@article{montanari_generalization_2023,
	title = {The generalization error of max-margin linear classifiers: {Benign} overfitting and high dimensional asymptotics in the overparametrized regime},
	shorttitle = {The generalization error of max-margin linear classifiers},
	abstract = {Modern machine learning classiﬁers often exhibit vanishing classiﬁcation error on the training set. They achieve this by learning nonlinear representations of the inputs that maps the data into linearly separable classes.},
	language = {en},
	journal = {arXiv preprint arXiv:1911.01544},
	author = {Montanari, Andrea and Ruan, Feng and Sohn, Youngtak and Yan, Jun},
	year = {2023},
	keywords = {Statistics - Machine Learning, Mathematics - Statistics Theory},
}

@inproceedings{ghosal_contextual_2023,
	title = {Contextual reliability: {When} different features matter in different contexts},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Ghosal, Gaurav Rohit and Setlur, Amrith and Brown, Daniel S. and Dragan, Anca and Raghunathan, Aditi},
	year = {2023},
}

@article{chatterji_finite-sample_nodate,
	title = {Finite-sample analysis of interpolating linear classifiers in the overparameterized regime},
	volume = {22},
	abstract = {We prove bounds on the population risk of the maximum margin algorithm for two-class linear classiﬁcation. For linearly separable training data, the maximum margin algorithm has been shown in previous work to be equivalent to a limit of training with logistic loss using gradient descent, as the training error is driven to zero. We analyze this algorithm applied to random data including misclassiﬁcation noise. Our assumptions on the clean data include the case in which the class-conditional distributions are standard normal distributions. The misclassiﬁcation noise may be chosen by an adversary, subject to a limit on the fraction of corrupted labels. Our bounds show that, with suﬃcient overparameterization, the maximum margin algorithm trained on noisy data can achieve nearly optimal population risk.},
	language = {en},
	number = {129},
	journal = {Journal of Machine Learning Research},
	author = {Chatterji, Niladri S},
	pages = {1--30},
}

@inproceedings{tan_efficientnet_2019,
	title = {{EfficientNet}: {Rethinking} model scaling for convolutional neural networks},
	shorttitle = {Efficientnet},
	abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a ﬁxed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefﬁcient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Tan, Mingxing and Le, Quoc V.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	pages = {6105--6114},
}

@inproceedings{ma_over-parametrization_2023,
	title = {Over-parametrization via lifting for low-rank matrix sensing: {Conversion} of spurious solutions to strict saddle points},
	abstract = {This paper studies the role of overparametrization in solving non-convex optimization problems. The focus is on the important class of low-rank matrix sensing, where we propose an inﬁnite hierarchy of non-convex problems via the lifting technique and the Burer-Monteiro factorization. This contrasts with the existing over-parametrization technique where the search rank is limited by the dimension of the matrix and it does not allow a rich over-parametrization of an arbitrary degree. We show that although the spurious solutions of the problem remain stationary points through the hierarchy, they will be transformed into strict saddle points (under some technical conditions) and can be escaped via local search methods. This is the ﬁrst result in the literature showing that over-parametrization creates a negative curvature for escaping spurious solutions. We also derive a bound on how much over-parametrization is requited to enable the elimination of spurious solutions.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Ma, Ziye and Molybog, Igor and Lavaei, Javad and Sojoudi, Somayeh},
	year = {2023},
}

@inproceedings{xue_which_2023,
	title = {Which features are learnt by contrastive learning? {On} the role of simplicity bias in class collapse and feature suppression},
	shorttitle = {Which features are learnt by contrastive learning?},
	abstract = {Contrastive learning (CL) has emerged as a powerful technique for representation learning, with or without label supervision. However, supervised CL is prone to collapsing representations of subclasses within a class by not capturing all their features, and unsupervised CL may suppress harder class-relevant features by focusing on learning easy class-irrelevant features; both signiﬁcantly compromise representation quality. Yet, there is no theoretical understanding of class collapse or feature suppression at test time. We provide the ﬁrst uniﬁed theoretically rigorous framework to determine which features are learnt by CL. Our analysis indicate that, perhaps surprisingly, bias of (stochastic) gradient descent towards ﬁnding simpler solutions is a key factor in collapsing subclass representations and suppressing harder class-relevant features. Moreover, we present increasing embedding dimensionality and improving the quality of data augmentations as two theoretically motivated solutions to feature suppression. We also provide the ﬁrst theoretical explanation for why employing supervised and unsupervised CL together yields higher-quality representations, even when using commonly-used stochastic gradient methods.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Xue, Yihao and Joshi, Siddharth and Gan, Eric and Chen, Pin-Yu and Mirzasoleiman, Baharan},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{ye_power_2023,
	title = {On the power of pre-training for generalization in {RL}: {Provable} benefits and hardness},
	shorttitle = {On the power of pre-training for generalization in rl},
	abstract = {Generalization in Reinforcement Learning (RL) aims to train an agent during training that generalizes to the target environment. In this work, we ﬁrst point out that RL generalization is fundamentally diﬀerent from the generalization in supervised learning, and ﬁne-tuning on the target environment is necessary for good test performance. Therefore, we seek to answer the following question: how much can we expect pre-training over training environments to be helpful for eﬃcient and eﬀective ﬁne-tuning? On one hand, we give a surprising result showing that asymptotically, the improvement from pre-training is at most a constant factor. On the other hand, we show that pre-training can be indeed helpful in the nonasymptotic regime by designing a policy collection-elimination (PCE) algorithm and proving a distribution-dependent regret bound that is independent of the state-action space. We hope our theoretical results can provide insight towards understanding pre-training and generalization in RL.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Ye, Haotian and Chen, Xiaoyu and Wang, Liwei and Du, Simon S.},
	year = {2023},
	keywords = {Computer Science - Machine Learning},
}

@article{zou_understanding_2021,
	title = {Understanding the generalization of {Adam} in learning neural networks with proper regularization},
	abstract = {Adaptive gradient methods such as Adam have gained increasing popularity in deep learning optimization. However, it has been observed that compared with (stochastic) gradient descent, Adam can converge to a diﬀerent solution with a signiﬁcantly worse test error in many deep learning applications such as image classiﬁcation, even with a ﬁne-tuned regularization. In this paper, we provide a theoretical explanation for this phenomenon: we show that in the nonconvex setting of learning over-parameterized two-layer convolutional neural networks starting from the same random initialization, for a class of data distributions (inspired from image data), Adam and gradient descent (GD) can converge to diﬀerent global solutions of the training objective with provably diﬀerent generalization errors, even with weight decay regularization. In contrast, we show that if the training objective is convex, and the weight decay regularization is employed, any optimization algorithms including Adam and GD will converge to the same solution if the training is successful. This suggests that the inferior generalization performance of Adam is fundamentally tied to the nonconvex landscape of deep learning optimization.},
	language = {en},
	journal = {arXiv preprint arXiv:2108.11371},
	author = {Zou, Difan and Cao, Yuan and Li, Yuanzhi and Gu, Quanquan},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@article{bousmalis_robocat_2023,
	title = {{RoboCat}: {A} self-improving foundation agent for robotic manipulation},
	shorttitle = {Robocat},
	abstract = {The ability to leverage heterogeneous robotic experience from different robots and tasks to quickly master novel skills and embodiments has the potential to transform robot learning. Inspired by recent advances in foundation models for vision and language, we propose a foundation agent for robotic manipulation. This agent, named RoboCat, is a visual goal-conditioned decision transformer capable of consuming multi-embodiment action-labelled visual experience. This data spans a large repertoire of motor control skills from simulated and real robotic arms with varying sets of observations and actions. With RoboCat, we demonstrate the ability to generalise to new tasks and robots, both zero-shot as well as through adaptation using only 100--1000 examples for the target task. We also show how a trained model itself can be used to generate data for subsequent training iterations, thus providing a basic building block for an autonomous improvement loop. We investigate the agent's capabilities, with large-scale evaluations both in simulation and on three different real robot embodiments. We find that as we grow and diversify its training data, RoboCat not only shows signs of cross-task transfer, but also becomes more efficient at adapting to new tasks.},
	language = {en},
	journal = {arXiv preprint arXiv:2306.11706},
	author = {Bousmalis, Konstantinos and Vezzani, Giulia and Rao, Dushyant and Devin, Coline and Lee, Alex X. and Bauza, Maria and Davchev, Todor and Zhou, Yuxiang and Gupta, Agrim and Raju, Akhil and Laurens, Antoine and Fantacci, Claudio and Dalibard, Valentin and Zambelli, Martina and Martins, Murilo and Pevceviciute, Rugile and Blokzijl, Michiel and Denil, Misha and Batchelor, Nathan and Lampe, Thomas and Parisotto, Emilio and Żołna, Konrad and Reed, Scott and Colmenarejo, Sergio Gómez and Scholz, Jon and Abdolmaleki, Abbas and Groth, Oliver and Regli, Jean-Baptiste and Sushkov, Oleg and Rothörl, Tom and Chen, José Enrique and Aytar, Yusuf and Barker, Dave and Ortiz, Joy and Riedmiller, Martin and Springenberg, Jost Tobias and Hadsell, Raia and Nori, Francesco and Heess, Nicolas},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics},
}

@inproceedings{mao_understanding_2023,
	title = {Understanding zero-shot adversarial robustness for large-scale models},
	abstract = {Pretrained large-scale vision-language models like CLIP have exhibited strong generalization over unseen tasks. Yet imperceptible adversarial perturbations can signiﬁcantly reduce CLIP’s performance on new tasks. In this work, we identify and explore the problem of adapting large-scale models for zero-shot adversarial robustness. We ﬁrst identify two key factors during model adaption—training losses and adaptation methods—that affect the model’s zero-shot adversarial robustness. We then propose a text-guided contrastive adversarial training loss, which aligns the text embeddings and the adversarial visual features with contrastive learning on a small set of training data. We apply this training loss to two adaption methods, model ﬁnetuning and visual prompt tuning. We ﬁnd that visual prompt tuning is more effective in the absence of texts, while ﬁnetuning wins in the existence of text guidance. Overall, our approach signiﬁcantly improves the zero-shot adversarial robustness over CLIP, seeing an average improvement of 31 points over ImageNet and 15 zero-shot datasets. Our code and model is available at github.com/cvlab-columbia/ZSRobust4FoundationModel.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Mao, Chengzhi and Geng, Scott and Yang, Junfeng and Wang, Xin and Vondrick, Carl},
	year = {2023},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{dehghani_scaling_2023,
	title = {Scaling vision transformers to 22 billion parameters},
	abstract = {The scaling of Transformers has driven breakthrough capabilities for language models. At present, the largest large language models (LLMs) contain upwards of 100B parameters. Vision Transformers (ViT) have introduced the same architecture to image and video modelling, but these have not yet been successfully scaled to nearly the same degree; the largest dense ViT contains 4B parameters (Chen et al., 2022). We present a recipe for highly eﬃcient and stable training of a 22B-parameter ViT (ViT-22B) and perform a wide variety of experiments on the resulting model. When evaluated on downstream tasks (often with a lightweight linear model on frozen features), ViT-22B demonstrates increasing performance with scale. We further observe other interesting beneﬁts of scale, including an improved tradeoﬀ between fairness and performance, state-of-the-art alignment to human visual perception in terms of shape/texture bias, and improved robustness. ViT-22B demonstrates the potential for “LLM-like” scaling in vision, and provides key steps towards getting there.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and Jenatton, Rodolphe and Beyer, Lucas and Tschannen, Michael and Arnab, Anurag and Wang, Xiao and Riquelme, Carlos and Minderer, Matthias and Puigcerver, Joan and Evci, Utku and Kumar, Manoj and van Steenkiste, Sjoerd and Elsayed, Gamaleldin F. and Mahendran, Aravindh and Yu, Fisher and Oliver, Avital and Huot, Fantine and Bastings, Jasmijn and Collier, Mark Patrick and Gritsenko, Alexey and Birodkar, Vighnesh and Vasconcelos, Cristina and Tay, Yi and Mensink, Thomas and Kolesnikov, Alexander and Pavetić, Filip and Tran, Dustin and Kipf, Thomas and Lučić, Mario and Zhai, Xiaohua and Keysers, Daniel and Harmsen, Jeremiah and Houlsby, Neil},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{villani_any_2023,
	title = {Any deep {ReLU} network is shallow},
	abstract = {We constructively prove that every deep ReLU network can be rewritten as a functionally identical three-layer network with weights valued in the extended reals. Based on this proof, we provide an algorithm that, given a deep ReLU network, finds the explicit weights of the corresponding shallow network. The resulting shallow network is transparent and used to generate explanations of the model’s behaviour.},
	language = {en},
	journal = {arXiv preprint arXiv:2306.11827},
	author = {Villani, Mattia Jacopo and Schoots, Nandi},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{santurkar_whose_2023,
	title = {Whose opinions do language models reflect?},
	abstract = {Language models (LMs) are increasingly being used in open-ended contexts, where the opinions reﬂected by LMs in response to subjective queries can have a profound impact, both on user satisfaction, as well as shaping the views of society at large. In this work, we put forth a quantitative framework to investigate the opinions reﬂected by LMs – by leveraging high-quality public opinion polls and their associated human responses. Using this framework, we create OpinionQA, a new dataset for evaluating the alignment of LM opinions with those of 60 US demographic groups over topics ranging from abortion to automation. Across topics, we ﬁnd substantial misalignment between the views reﬂected by current LMs and those of US demographic groups: on par with the Democrat-Republican divide on climate change. Notably, this misalignment persists even after explicitly steering the LMs towards particular demographic groups. Our analysis not only conﬁrms prior observations about the left-leaning tendencies of some human feedback-tuned LMs, but also surfaces groups whose opinions are poorly reﬂected by current LMs (e.g., 65+ and widowed individuals). Our code and data are available at https://github.com/tatsu-lab/opinions\_qa.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
}

@inproceedings{zhou_ods_2023,
	title = {Ods: {Test}-time adaptation in the presence of open-world data shift},
	abstract = {Test-time adaptation (TTA) adapts a source model to the distribution shift in testing data without using any source data. There have been plenty of algorithms concentrated on covariate shift in the last decade, i.e., Dt(X), the distribution of the test data is different from the source data. Nonetheless, in real application scenarios, it is necessary to consider the inﬂuence of label distribution shift, i.e., both Dt(X) and Dt(Y ) are shifted, which has not been sufﬁciently explored yet. To remedy this, we study a new problem setup, namely, TTA with Open-world Data Shift (AODS). The goal of AODS is simultaneously adapting a model to covariate and label distribution shifts in the test phase. In this paper, we ﬁrst analyze the relationship between classiﬁcation error and distribution shifts. Motivated by this, we hence propose a new framework, namely ODS, which decouples the mixed distribution shift and then addresses covariate and label distribution shifts accordingly. We conduct experiments on multiple benchmarks with different types of shifts, and the results demonstrate the superior performance of our method against the state of the arts. Moreover, ODS is suitable for many TTA algorithms.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhou, Zhi and Guo, Lan-Zhe and Jia, Lin-Han and Zhang, Ding-Chu and Li, Yu-Feng},
	year = {2023},
}

@inproceedings{dubois_evaluating_2023,
	title = {Evaluating self-supervised learning via risk decomposition},
	abstract = {Self-supervised learning (SSL) pipelines differ in many design choices such as the architecture, augmentations, or pretraining data. Yet SSL is typically evaluated using a single metric: linear probing on ImageNet. This does not provide much insight into why or when a model is better, now how to improve it. To address this, we propose an SSL risk decomposition, which generalizes the classical supervised approximation-estimation decomposition by considering errors arising from the representation learning step. Our decomposition consists of four error components: approximation, representation usability, probe generalization, and encoder generalization. We provide efficient estimators for each component and use them to analyze the effect of 30 design choices on 169 SSL vision models evaluated on ImageNet. Our analysis gives valuable insights for designing and using SSL models. For example, it highlights the main sources of error and shows how to improve SSL in specific settings (full- vs few-shot) by trading off error components. All results and pretrained models are at https://github.com/YannDubs/SSL-Risk-Decomposition.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Dubois, Yann and Hashimoto, Tatsunori and Liang, Percy},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{shen_cross-modal_2023,
	title = {Cross-modal fine-tuning: {Align} then refine},
	shorttitle = {Cross-modal fine-tuning},
	abstract = {Fine-tuning large-scale pretrained models has led to tremendous progress in well-studied modalities such as vision and NLP. However, similar gains have not been observed in many other modalities due to a lack of relevant pretrained models. In this work, we propose ORCA, a general cross-modal ﬁne-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities. ORCA adapts to a target task via an align-then-reﬁne workﬂow: given the target input, ORCA ﬁrst learns an embedding network that aligns the embedded feature distribution with the pretraining modality. The pretrained model is then ﬁne-tuned on the embedded data to exploit the knowledge shared across modalities. Through extensive experiments, we show that ORCA obtains state-of-the-art results on 3 benchmarks containing over 60 datasets from 12 modalities, outperforming a wide range of hand-designed, AutoML, general-purpose, and task-speciﬁc methods. We highlight the importance of data alignment via a series of ablation studies and demonstrate ORCA’s utility in data-limited regimes.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Shen, Junhong and Li, Liam and Dery, Lucio M. and Staten, Corey and Khodak, Mikhail and Neubig, Graham and Talwalkar, Ameet},
	year = {2023},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{trockman_mimetic_2023,
	title = {Mimetic initialization of self-attention layers},
	abstract = {It is notoriously difﬁcult to train Transformers on small datasets; typically, large pre-trained models are instead used as the starting point. We explore the weights of such pre-trained Transformers (particularly for vision) to attempt to ﬁnd reasons for this discrepancy. Surprisingly, we ﬁnd that simply initializing the weights of self-attention layers so that they “look” more like their pre-trained counterparts allows us to train vanilla Transformers faster and to higher ﬁnal accuracies, particularly on vision tasks such as CIFAR-10 and ImageNet classiﬁcation, where we see gains in accuracy of over 5\% and 4\%, respectively. Our initialization scheme is closed form, learning-free, and very simple: we set the product of the query and key weights to be approximately the identity, and the product of the value and projection weights to approximately the negative identity. As this mimics the patterns we saw in pre-trained Transformers, we call the technique mimetic initialization.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Trockman, Asher and Kolter, J. Zico},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{feng_towards_2023,
	title = {Towards revealing the mystery behind chain of thought: {A} theoretical perspective},
	shorttitle = {Towards revealing the mystery behind chain of thought},
	abstract = {Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the expressivity of LLMs with CoT in solving fundamental mathematical and decision-making problems. We start by giving an impossibility result showing that bounded-depth Transformers are unable to directly produce correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of constant size suffice to solve both tasks by generating CoT derivations using a commonly-used math language format. Moreover, we show LLMs with CoT are capable of solving a general class of decision-making problems known as Dynamic Programming, thus justifying its power in tackling complex real-world tasks. Finally, extensive experiments on four tasks show that, while Transformers always fail to predict the answers directly, they can consistently learn to generate correct solutions step-by-step given sufficient CoT demonstrations.},
	language = {en},
	journal = {arXiv preprint arXiv:2305.15408},
	author = {Feng, Guhao and Zhang, Bohang and Gu, Yuntian and Ye, Haotian and He, Di and Wang, Liwei},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computational Complexity, Computer Science - Computation and Language},
}

@inproceedings{choromanski_rethinking_2021,
	title = {Rethinking attention with performers},
	abstract = {We introduce Performers, Transformer architectures which can estimate regular (softmax) full-rank-attention Transformers with provable accuracy, but using only linear (as opposed to quadratic) space and time complexity, without relying on any priors such as sparsity or low-rankness. To approximate softmax attentionkernels, Performers use a novel Fast Attention Via positive Orthogonal Random features approach (FAVOR+), which may be of independent interest for scalable kernel methods. FAVOR+ can also be used to efﬁciently model kernelizable attention mechanisms beyond softmax. This representational power is crucial to accurately compare softmax with other kernels for the ﬁrst time on large-scale tasks, beyond the reach of regular Transformers, and investigate optimal attention-kernels. Performers are linear architectures fully compatible with regular Transformers and with strong theoretical guarantees: unbiased or nearly-unbiased estimation of the attention matrix, uniform convergence and low estimation variance. We tested Performers on a rich set of tasks stretching from pixel-prediction through text models to protein sequence modeling. We demonstrate competitive results with other examined efﬁcient sparse and dense attention methods, showcasing effectiveness of the novel attention-learning paradigm leveraged by Performers.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and Belanger, David and Colwell, Lucy and Weller, Adrian},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
}

@article{dong_survey_2023,
	title = {A survey on in-context learning},
	abstract = {With the increasing ability of large language models (LLMs), in-context learning (ICL) has become a new paradigm for natural language processing (NLP), where LLMs make predictions only based on contexts augmented with a few examples. It has been a new trend to explore ICL to evaluate and extrapolate the ability of LLMs. In this paper, we aim to survey and summarize the progress and challenges of ICL. We first present a formal definition of ICL and clarify its correlation to related studies. Then, we organize and discuss advanced techniques, including training strategies, demonstration designing strategies, as well as related analysis. Finally, we discuss the challenges of ICL and provide potential directions for further research. We hope that our work can encourage more research on uncovering how ICL works and improving ICL.},
	language = {en},
	journal = {arXiv preprint arXiv:2301.00234},
	author = {Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Li, Lei and Sui, Zhifang},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{huh_low-rank_2023,
	title = {The low-rank simplicity bias in deep networks},
	abstract = {Modern deep neural networks are highly over-parameterized compared to the data on which they are trained, yet they often generalize remarkably well. A ﬂurry of recent work has asked: why do deep networks not overﬁt to their training data? In this work, we make a series of empirical observations that investigate and extend the hypothesis that deeper networks are inductively biased to ﬁnd solutions with lower eﬀective rank embeddings. We conjecture that this bias exists because the volume of functions that maps to low eﬀective rank embedding increases with depth. We show empirically that our claim holds true on ﬁnite width linear and non-linear models on practical learning paradigms and show that on natural data, these are often the solutions that generalize well. We then show that the simplicity bias exists at both initialization and after training and is resilient to hyper-parameters and learning methods. We further demonstrate how linear over-parameterization of deep non-linear models can be used to induce low-rank bias, improving generalization performance on CIFAR and ImageNet without changing the modeling capacity.},
	language = {en},
	journal = {Transactions on Machine Learning Research},
	author = {Huh, Minyoung and Mobahi, Hossein and Zhang, Richard and Cheung, Brian and Agrawal, Pulkit and Isola, Phillip},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{agarwal_evaluating_2021,
	title = {Evaluating {CLIP}: {Towards} characterization of broader capabilities and downstream implications},
	shorttitle = {Evaluating clip},
	abstract = {Recently, there have been breakthroughs in computer vision (“CV”) models that are more generalizable with the advent of models such as CLIP [17] and ALIGN[13]. In this paper, we analyze CLIP and highlight some of the challenges such models pose. CLIP reduces the need for task speciﬁc training data, potentially opening up many niche tasks to automation. CLIP also allows its users to ﬂexibly specify image classiﬁcation classes in natural language, which we ﬁnd can shift how biases manifest. Additionally, through some preliminary probes we ﬁnd that CLIP can inherit biases found in prior computer vision systems. Given the wide and unpredictable domain of uses for such models, this raises questions regarding what sufﬁciently safe behaviour for such systems may look like. These results add evidence to the growing body of work calling for a change in the notion of a ‘better’ model–to move beyond simply looking at higher accuracy at task-oriented capability evaluations, and towards a broader ‘better’ that takes into account deployment-critical features such as different use contexts, and people who interact with the model when thinking about model deployment.},
	language = {en},
	journal = {arXiv preprint arXiv:2108.02818},
	author = {Agarwal, Sandhini and Krueger, Gretchen and Clark, Jack and Radford, Alec and Kim, Jong Wook and Brundage, Miles},
	year = {2021},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computers and Society},
}

@inproceedings{shu_clipood_2023,
	title = {{CLIPood}: {Generalizing} {CLIP} to out-of-distributions},
	abstract = {Out-of-distribution (OOD) generalization, where the model needs to handle distribution shifts from training, is a major challenge of machine learning. Contrastive language-image pre-training (CLIP) models have shown impressive zero-shot ability, but the further adaptation of CLIP on downstream tasks undesirably degrades OOD performances. This paper aims at generalizing CLIP to out-ofdistribution test data on downstream tasks. We propose CLIPood, a fine-tuning method that can adapt CLIP models to OOD situations where both domain shifts and open classes may occur on the unseen test data. To exploit the semantic relations between classes from the text modality, CLIPood introduces a new training objective, margin metric softmax (MMS), with class adaptive margins for fine-tuning. To incorporate both pre-trained zeroshot model and fine-tuned task-adaptive model, CLIPood leverages a new optimization strategy, Beta moving average (BMA), to maintain a temporal ensemble weighted by Beta distribution. Experiments on diverse datasets with different OOD scenarios show that CLIPood consistently outperforms existing generalization techniques.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Shu, Yang and Guo, Xingzhuo and Wu, Jialong and Wang, Ximei and Wang, Jianmin and Long, Mingsheng},
	year = {2023},
}

@inproceedings{xie_explanation_2022,
	title = {An explanation of in-context learning as implicit {Bayesian} inference},
	abstract = {Large language models (LMs) such as GPT-3 have the surprising ability to do in-context learning, where the model learns to do a downstream task simply by conditioning on a prompt consisting of input-output examples. The LM learns from these examples without being explicitly pretrained to learn. Thus, it is unclear what enables in-context learning. In this paper, we study how in-context learning can emerge when pretraining documents have long-range coherence. Here, the LM must infer a latent document-level concept to generate coherent next tokens during pretraining. At test time, in-context learning occurs when the LM also infers a shared latent concept between examples in a prompt. We prove when this occurs despite a distribution mismatch between prompts and pretraining data in a setting where the pretraining distribution is a mixture of HMMs. In contrast to messy large-scale datasets used to train LMs capable of in-context learning, we generate a small-scale synthetic dataset (GINC) where Transformers and LSTMs both exhibit in-context learning1. Beyond the theory, experiments on GINC exhibit large-scale real-world phenomena including improved in-context performance with model scaling (despite the same pretraining loss), sensitivity to example order, and instances where zero-shot is better than few-shot in-context learning.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{wang_closer_2023,
	title = {A closer look at self-supervised lightweight vision transformers},
	abstract = {Self-supervised learning on large-scale Vision Transformers (ViTs) as pre-training methods has achieved promising downstream performance. Yet, how much these pre-training paradigms promote lightweight ViTs’ performance is considerably less studied. In this work, we develop and benchmark several self-supervised pre-training methods on image classiﬁcation tasks and some downstream dense prediction tasks. We surprisingly ﬁnd that if proper pre-training is adopted, even vanilla lightweight ViTs show comparable performance to previous SOTA networks with delicate architecture design. It breaks the recently popular conception that vanilla ViTs are not suitable for vision tasks in lightweight regimes. We also point out some defects of such pre-training, e.g., failing to beneﬁt from large-scale pre-training data and showing inferior performance on data-insufﬁcient downstream tasks. Furthermore, we analyze and clearly show the effect of such pre-training by analyzing the properties of the layer representation and attention maps for related models. Finally, based on the above analyses, a distillation strategy during pre-training is developed, which leads to further downstream performance improvement for MAE-based pre-training. Code is available at https://github.com/wangsr126/mae-lite.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Wang, Shaoru and Gao, Jin and Li, Zeming and Zhang, Xiaoqin and Hu, Weiming},
	year = {2023},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{li_blip-2_2023,
	title = {{BLIP}-2: {Bootstrapping} language-image pre-training with frozen image encoders and large language models},
	shorttitle = {Blip-2},
	abstract = {The cost of vision-and-language pre-training has become increasingly prohibitive due to end-toend training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various visionlanguage tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7\% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model’s emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
	year = {2023},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{fang_eva_2023,
	title = {Eva: {Exploring} the limits of masked visual representation learning at scale},
	abstract = {We launch EVA, a vision-centric foundation model to Explore the limits of Visual representation at scAle using only publicly accessible data. EVA is a vanilla ViT pretrained to reconstruct the masked out image-text aligned vision features conditioned on visible image patches. Via this pretext task, we can efficiently scale up EVA to one billion parameters, and sets new records on a broad range of representative vision downstream tasks, such as image recognition, video action recognition, object detection, instance segmentation and semantic segmentation without heavy supervised training. Moreover, we observe quantitative changes in scaling EVA result in qualitative changes in transfer learning performance that are not present in other models. For instance, EVA takes a great leap in the challenging large vocabulary instance segmentation task: our model achieves almost the same state-of-the-art performance on LVIS dataset with over a thousand categories and COCO dataset with only eighty categories. Beyond a pure vision encoder, EVA can also serve as a vision-centric, multi-modal pivot to connect images and text. We find initializing the vision tower of a giant CLIP from EVA can greatly stabilize the training and outperform the training from scratch counterpart with much fewer samples and less compute, providing a new direction for scaling up and accelerating the costly training of multi-modal foundation models.},
	language = {en},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
	year = {2023},
	pages = {19358--19369},
}

@article{sun_eva-clip_2023,
	title = {{EVA}-{CLIP}: {Improved} training techniques for {CLIP} at scale},
	shorttitle = {{EVA}-{CLIP}},
	abstract = {Contrastive language-image pre-training, CLIP for short, has gained increasing attention for its potential in various scenarios. In this paper, we propose EVA-CLIP, a series of models that significantly improve the efficiency and effectiveness of CLIP training. Our approach incorporates new techniques for representation learning, optimization, and augmentation, enabling EVA-CLIP to achieve superior performance compared to previous CLIP models with the same number of parameters but significantly smaller training costs. Notably, our largest 5.0B-parameter EVA-02-CLIP-E/14+ with only 9 billion seen samples achieves 82.0\% zero-shot top-1 accuracy on ImageNet-1K val. A smaller EVA-02CLIP-L/14+ with only 430 million parameters and 6 billion seen samples achieves 80.4\% zero-shot top-1 accuracy on ImageNet-1K val. To facilitate open access and open research, we release the complete suite of EVA-CLIP to the community.},
	language = {en},
	journal = {arXiv preprint arXiv:2303.15389},
	author = {Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue},
	year = {2023},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{alayrac__2022,
	title = {🦩 {Flamingo}: {A} visual language model for few-shot learning},
	abstract = {Building models that can be rapidly adapted to novel tasks using only a handful of annotated examples is an open challenge for multimodal machine learning research. We introduce Flamingo, a family of Visual Language Models (VLM) with this ability. We propose key architectural innovations to: (i) bridge powerful pretrained vision-only and language-only models, (ii) handle sequences of arbitrarily interleaved visual and textual data, and (iii) seamlessly ingest images or videos as inputs. Thanks to their flexibility, Flamingo models can be trained on large-scale multimodal web corpora containing arbitrarily interleaved text and images, which is key to endow them with in-context few-shot learning capabilities. We perform a thorough evaluation of our models, exploring and measuring their ability to rapidly adapt to a variety of image and video tasks. These include open-ended tasks such as visual question-answering, where the model is prompted with a question which it has to answer; captioning tasks, which evaluate the ability to describe a scene or an event; and close-ended tasks such as multiple-choice visual question-answering. For tasks lying anywhere on this spectrum, a single Flamingo model can achieve a new state of the art with few-shot learning, simply by prompting the model with task-specific examples. On numerous benchmarks, Flamingo outperforms models fine-tuned on thousands of times more task-specific data.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina and Monteiro, Marianne and Menick, Jacob and Borgeaud, Sebastian and Brock, Andrew and Nematzadeh, Aida and Sharifzadeh, Sahand and Binkowski, Mikolaj and Barreira, Ricardo and Vinyals, Oriol and Zisserman, Andrew and Simonyan, Karen},
	year = {2022},
	pages = {23716--23736},
}

@inproceedings{chan_data_2022,
	title = {Data distributional properties drive emergent in-context learning in transformers},
	abstract = {Large transformer-based models are able to perform in-context few-shot learning, without being explicitly trained for it. This observation raises the question: what aspects of the training regime lead to this emergent behavior? Here, we show that this behavior is driven by the distributions of the training data itself. In-context learning emerges when the training data exhibits particular distributional properties such as burstiness (items appear in clusters rather than being uniformly distributed over time) and having large numbers of rarely occurring classes. In-context learning also emerges more strongly when item meanings or interpretations are dynamic rather than fixed. These properties are exemplified by natural language, but are also inherent to naturalistic data in a wide range of other domains. They also depart significantly from the uniform, i.i.d. training distributions typically used for standard supervised learning. In our initial experiments, we found that in-context learning traded off against more conventional weight-based learning, and models were unable to achieve both simultaneously. However, our later experiments uncovered that the two modes of learning could co-exist in a single model when it was trained on data following a skewed Zipfian distribution -- another common property of naturalistic data, including language. In further experiments, we found that naturalistic data distributions were only able to elicit in-context learning in transformers, and not in recurrent models. In sum, our findings indicate how the transformer architecture works together with particular properties of the training data to drive the intriguing emergent in-context learning behaviour of large language models, and how future work might encourage both in-context and in-weights learning in domains beyond language.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chan, Stephanie C. Y. and Santoro, Adam and Lampinen, Andrew K. and Wang, Jane X. and Singh, Aaditya and Richemond, Pierre H. and McClelland, Jay and Hill, Felix},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	pages = {18878--18891},
}

@article{schaeffer_are_2023,
	title = {Are emergent abilities of large language models a mirage?},
	abstract = {Recent work claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. What makes emergent abilities intriguing is two-fold: their sharpness, transitioning seemingly instantaneously from not present to present, and their unpredictability, appearing at seemingly unforeseeable model scales. Here, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing ﬁxed model outputs, emergent abilities appear due the researcher’s choice of metric rather than due to fundamental changes in model behavior with scale. Speciﬁcally, nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, continuous, predictable changes in model performance. We present our alternative explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and conﬁrm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities, (2) make, test and conﬁrm two predictions about metric choices in a metaanalysis of emergent abilities on BIG-Bench; and (3) show how to choose metrics to produce never-before-seen seemingly emergent abilities in multiple vision tasks across diverse deep networks. Via all three analyses, we provide evidence that alleged emergent abilities evaporate with different metrics or with better statistics, and may not be a fundamental property of scaling AI models.},
	language = {en},
	journal = {arXiv preprint arXiv:2304.15004},
	author = {Schaeffer, Rylan and Miranda, Brando and Koyejo, Sanmi},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{you_large_2020,
	title = {Large batch optimization for deep learning: {Training} {BERT} in 76 minutes},
	shorttitle = {Large batch optimization for deep learning},
	abstract = {Training large deep neural networks on massive datasets is computationally very challenging. There has been recent surge in interest in using large batch stochastic optimization methods to tackle this issue. The most prominent algorithm in this line of research is LARS, which by employing layerwise adaptive learning rates trains RESNET on ImageNet in a few minutes. However, LARS performs poorly for attention models like BERT, indicating that its performance gains are not consistent across tasks. In this paper, we ﬁrst study a principled layerwise adaptation strategy to accelerate training of deep neural networks using large mini-batches. Using this strategy, we develop a new layerwise adaptive large batch optimization technique called LAMB; we then provide convergence analysis of LAMB as well as LARS, showing convergence to a stationary point in general nonconvex settings. Our empirical results demonstrate the superior performance of LAMB across various tasks such as BERT and RESNET-50 training with very little hyperparameter tuning. In particular, for BERT training, our optimizer enables use of very large batch sizes of 32868 without any degradation of performance. By increasing the batch size to the memory limit of a TPUv3 Pod, BERT training time can be reduced from 3 days to just 76 minutes (Table 1). The LAMB implementation is available online1.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {You, Yang and Li, Jing and Reddi, Sashank and Hseu, Jonathan and Kumar, Sanjiv and Bhojanapalli, Srinadh and Song, Xiaodan and Demmel, James and Keutzer, Kurt and Hsieh, Cho-Jui},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{wang_minilm_2020,
	title = {{MiniLM}: {Deep} self-attention distillation for task-agnostic compression of pre-trained transformers},
	abstract = {Pre-trained language models (e.g., BERT [12] and its variants) have achieved remarkable success in varieties of NLP tasks. However, these models usually consist of hundreds of millions of parameters which brings challenges for ﬁnetuning and online serving in real-life applications due to latency and capacity constraints. In this work, we present a simple and effective approach to compress large Transformer [42] based pre-trained models, termed as deep self-attention distillation. The small model (student) is trained by deeply mimicking the selfattention module, which plays a vital role in Transformer networks, of the large model (teacher). Speciﬁcally, we propose distilling the self-attention module of the last Transformer layer of the teacher, which is effective and ﬂexible for the student. Furthermore, we introduce the scaled dot-product between values in the self-attention module as the new deep self-attention knowledge, in addition to the attention distributions (i.e., the scaled dot-product of queries and keys) that have been used in existing works. Moreover, we show that introducing a teacher assistant [26] also helps the distillation of large pre-trained Transformer models. Experimental results demonstrate that our monolingual model2 outperforms stateof-the-art baselines in different parameter size of student models. In particular, it retains more than 99\% accuracy on SQuAD 2.0 and several GLUE benchmark tasks using 50\% of the Transformer parameters and computations of the teacher model. We also obtain competitive results in applying deep self-attention distillation to multilingual pre-trained models.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wang, Wenhui and Wei, Furu and Dong, Li and Yang, Nan and Zhou, Ming},
	year = {2020},
	pages = {5776--5788},
}

@inproceedings{jiao_tinybert_2020,
	title = {{TinyBERT}: {Distilling} {BERT} for natural language understanding},
	shorttitle = {{TinyBERT}},
	abstract = {Language model pre-training, such as BERT, has signiﬁcantly improved the performances of many natural language processing tasks. However, pre-trained language models are usually computationally expensive, so it is difﬁcult to efﬁciently execute them on resourcerestricted devices. To accelerate inference and reduce model size while maintaining accuracy, we ﬁrst propose a novel Transformer distillation method that is specially designed for knowledge distillation (KD) of the Transformer-based models. By leveraging this new KD method, the plenty of knowledge encoded in a large “teacher” BERT can be effectively transferred to a small “student” TinyBERT. Then, we introduce a new two-stage learning framework for TinyBERT, which performs Transformer distillation at both the pretraining and task-speciﬁc learning stages. This framework ensures that TinyBERT can capture the general-domain as well as the task-speciﬁc knowledge in BERT.},
	language = {en},
	booktitle = {{EMNLP}},
	author = {Jiao, Xiaoqi and Yin, Yichun and Shang, Lifeng and Jiang, Xin and Chen, Xiao and Li, Linlin and Wang, Fang and Liu, Qun},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{wu_tinyvit_2022,
	title = {{TinyViT}: {Fast} pretraining distillation for small vision transformers},
	shorttitle = {{TinyViT}},
	abstract = {Vision transformer (ViT) recently has drawn great attention in computer vision due to its remarkable model capability. However, most prevailing ViT models suffer from huge number of parameters, restricting their applicability on devices with limited resources. To alleviate this issue, we propose TinyViT, a new family of tiny and efficient small vision transformers pretrained on large-scale datasets with our proposed fast distillation framework. The central idea is to transfer knowledge from large pretrained models to small ones, while enabling small models to get the dividends of massive pretraining data. More specifically, we apply distillation during pretraining for knowledge transfer. The logits of large teacher models are sparsified and stored in disk in advance to save the memory cost and computation overheads. The tiny student transformers are automatically scaled down from a large pretrained model with computation and parameter constraints. Comprehensive experiments demonstrate the efficacy of TinyViT. It achieves a top-1 accuracy of 84.8\% on ImageNet-1k with only 21M parameters, being comparable to SwinB pretrained on ImageNet-21k while using 4.2 times fewer parameters. Moreover, increasing image resolutions, TinyViT can reach 86.5\% accuracy, being slightly better than Swin-L while using only 11\% parameters. Last but not the least, we demonstrate a good transfer ability of TinyViT on various downstream tasks. Code and models are available at here.},
	language = {en},
	booktitle = {European {Conference} on {Computer} {Vision}},
	author = {Wu, Kan and Zhang, Jinnian and Peng, Houwen and Liu, Mengchen and Xiao, Bin and Fu, Jianlong and Yuan, Lu},
	year = {2022},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{liang_code_2023,
	title = {Code as policies: {Language} model programs for embodied control},
	shorttitle = {Code as policies},
	abstract = {Large language models (LLMs) trained on code completion have been shown to be capable of synthesizing simple Python programs from docstrings [1]. We find that these code-writing LLMs can be re-purposed to write robot policy code, given natural language commands. Specifically, policy code can express functions or feedback loops that process perception outputs (e.g.,from object detectors [2], [3]) and parameterize control primitive APIs. When provided as input several example language commands (formatted as comments) followed by corresponding policy code (via few-shot prompting), LLMs can take in new commands and autonomously re-compose API calls to generate new policy code respectively. By chaining classic logic structures and referencing third-party libraries (e.g., NumPy, Shapely) to perform arithmetic, LLMs used in this way can write robot policies that (i) exhibit spatial-geometric reasoning, (ii) generalize to new instructions, and (iii) prescribe precise values (e.g., velocities) to ambiguous descriptions ("faster") depending on context (i.e., behavioral commonsense). This paper presents code as policies: a robot-centric formulation of language model generated programs (LMPs) that can represent reactive policies (e.g., impedance controllers), as well as waypoint-based policies (vision-based pick and place, trajectory-based control), demonstrated across multiple real robot platforms. Central to our approach is prompting hierarchical code-gen (recursively defining undefined functions), which can write more complex code and also improves state-of-the-art to solve 39.8\% of problems on the HumanEval [1] benchmark. Code and videos are available at https://code-as-policies.github.io},
	language = {en},
	booktitle = {{ICRA}},
	author = {Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
	year = {2023},
	keywords = {Computer Science - Robotics},
}

@inproceedings{chen_multi-layer_2023,
	title = {Multi-layer neural networks as trainable ladders of hilbert spaces},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Chen, Zhengdao},
	year = {2023},
}

@inproceedings{woodworth_kernel_2020,
	title = {Kernel and rich regimes in overparametrized models},
	abstract = {A recent line of work studies overparametrized neural networks in the “kernel regime,” i.e., when during training the network behaves as a kernelized linear predictor, and thus, training with gradient descent has the eﬀect of ﬁnding the corresponding minimum RKHS norm solution. This stands in contrast to other studies which demonstrate how gradient descent on overparametrized networks can induce rich implicit biases that are not RKHS norms. Building on an observation by Chizat et al. (2019), we show how the scale of the initialization controls the transition between the “kernel” (aka lazy) and “rich” (aka active) regimes and aﬀects generalization properties in multilayer homogeneous models. We provide a complete and detailed analysis for a family of simple depth-D linear networks that exhibit an interesting and meaningful transition between the kernel and rich regimes, and highlight an interesting role for the width of the models. We further demonstrate this transition empirically for matrix factorization and multilayer non-linear networks.},
	language = {en},
	booktitle = {Conference on {Learning} {Theory}},
	author = {Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
	year = {2020},
}

@inproceedings{shi_theoretical_2022,
	title = {A theoretical analysis on feature learning in neural networks: {Emergence} from inputs and advantage over fixed features},
	shorttitle = {A theoretical analysis on feature learning in neural networks},
	abstract = {An important characteristic of neural networks is their ability to learn representations of the input data with effective features for prediction, which is believed to be a key factor to their superior empirical performance. To better understand the source and beneﬁt of feature learning in neural networks, we consider learning problems motivated by practical data, where the labels are determined by a set of class relevant patterns and the inputs are generated from these along with some background patterns. We prove that neural networks trained by gradient descent can succeed on these problems. The success relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efﬁciently by exploiting the data (in particular, the structure of the input distribution). In contrast, no linear models on data-independent features of polynomial sizes can learn to as good errors. Furthermore, if the speciﬁc input structure is removed, then no polynomial algorithm in the Statistical Query model can learn even weakly. These results provide theoretical evidence showing that feature learning in neural networks depends strongly on the input structure and leads to the superior performance. Our preliminary experimental results on synthetic and real data also provide positive support.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Shi, Zhenmei and Wei, Junyi and Liang, Yingyu},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{li_theoretical_2023,
	title = {A theoretical understanding of shallow vision transformers: learning, generalization, and sample complexity},
	shorttitle = {A theoretical understanding of shallow vision transformers},
	abstract = {Vision Transformers (ViTs) with self-attention modules have recently achieved great empirical success in many vision tasks. Due to non-convex interactions across layers, however, the theoretical learning and generalization analysis is mostly elusive. Based on a data model characterizing both label-relevant and label-irrelevant tokens, this paper provides the ﬁrst theoretical analysis of training a shallow ViT, i.e., one self-attention layer followed by a two-layer perceptron, for a classiﬁcation task. We characterize the sample complexity to achieve a zero generalization error. Our sample complexity bound is positively correlated with the inverse of the fraction of label-relevant tokens, the token noise level, and the initial model error. We also prove that a training process using stochastic gradient descent (SGD) leads to a sparse attention map, which is a formal veriﬁcation of the general intuition about the success of attention. Moreover, this paper indicates that a proper token sparsiﬁcation can improve the test performance by removing label-irrelevant and/or noisy tokens, including spurious correlations. Empirical experiments on synthetic data and CIFAR-10 dataset justify our theoretical results and generalize to deeper ViTs.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Li, Hongkang and Wang, Meng and Liu, Sijia and Chen, Pin-yu},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{oymak_role_2023,
	title = {On the role of attention in prompt-tuning},
	abstract = {Prompt-tuning is an emerging strategy to adapt large language models (LLM) to downstream tasks by learning a (soft-)prompt parameter from data. Despite its success in LLMs, there is limited theoretical understanding of the power of prompt-tuning and the role of the attention mechanism in prompting. In this work, we explore prompt-tuning for one-layer attention architectures and study contextual mixture-models where each input token belongs to a context-relevant or -irrelevant set. We isolate the role of prompttuning through a self-contained prompt-attention model. Our contributions are as follows: (1) We show that softmax-prompt-attention is provably more expressive than softmax-self-attention and linear-prompt-attention under our contextual data model. (2) We analyze the initial trajectory of gradient descent and show that it learns the prompt and prediction head with near-optimal sample complexity and demonstrate how the prompt can provably attend to sparse context-relevant tokens. (3) Assuming a known prompt but an unknown prediction head, we characterize the exact finite sample performance of prompt-attention which reveals the fundamental performance limits and the precise benefit of the context information. We also provide experiments that verify our theoretical insights on real datasets and demonstrate how prompt-tuning enables the model to attend to context-relevant information.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Oymak, Samet and Rawat, Ankit Singh and Soltanolkotabi, Mahdi and Thrampoulidis, Christos},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{wang_images_2023,
	title = {Images speak in images: {A} generalist painter for in-context visual learning},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	author = {Wang, Xinlong and Wang, Wen and Cao, Yue and Shen, Chunhua and Huang, Tiejun},
	year = {2023},
	pages = {6830--6839},
}

@inproceedings{moayeri_explicit_2022,
	title = {Explicit tradeoffs between adversarial and natural distributional robustness},
	abstract = {Several existing works study either adversarial or natural distributional robustness of deep neural networks separately. In practice, however, models need to enjoy both types of robustness to ensure reliability. In this work, we bridge this gap and show that in fact, explicit tradeoffs exist between adversarial and natural distributional robustness. We ﬁrst consider a simple linear regression setting on Gaussian data with disjoint sets of core and spurious features. In this setting, through theoretical and empirical analysis, we show that (i) adversarial training with 1 and 2 norms increases the model reliance on spurious features; (ii) For ∞ adversarial training, spurious reliance only occurs when the scale of the spurious features is larger than that of the core features; (iii) adversarial training can have an unintended consequence in reducing distributional robustness, speciﬁcally when spurious correlations are changed in the new test domain. Next, we present extensive empirical evidence, using a test suite of twenty adversarially trained models evaluated on ﬁve benchmark datasets (ObjectNet, RIVAL10, Salient ImageNet-1M, ImageNet-9, Waterbirds), that adversarially trained classiﬁers rely on backgrounds more than their standardly trained counterparts, validating our theoretical results. We also show that spurious correlations in training data (when preserved in the test domain) can improve adversarial robustness, revealing that previous claims that adversarial vulnerability is rooted in spurious correlations are incomplete.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Moayeri, Mazda and Banihashem, Kiarash and Feizi, Soheil},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	pages = {38761--38774},
}

@inproceedings{loshchilov_sgdr_2017,
	title = {{SGDR}: {Stochastic} gradient descent with warm restarts},
	shorttitle = {Sgdr},
	abstract = {Restart techniques are common in gradient-free optimization to deal with multimodal functions. Partial warm restarts are also gaining popularity in gradient-based optimization to improve the rate of convergence in accelerated gradient schemes to deal with ill-conditioned functions. In this paper, we propose a simple warm restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks. We empirically study its performance on the CIFAR-10 and CIFAR-100 datasets, where we demonstrate new state-of-the-art results at 3.14\% and 16.21\%, respectively. We also demonstrate its advantages on a dataset of EEG recordings and on a downsampled version of the ImageNet dataset. Our source code is available at https://github.com/loshchil/SGDR},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Loshchilov, Ilya and Hutter, Frank},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
}

@inproceedings{garg_what_2022,
	title = {What can transformers learn in-context? {A} case study of simple function classes},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Garg, Shivam and Tsipras, Dimitris and Liang, Percy and Valiant, Gregory},
	year = {2022},
	pages = {30583--30598},
}

@article{ahuja_-context_2023,
	title = {In-context learning through the {Bayesian} prism},
	abstract = {In-context learning is one of the surprising and useful features of large language models. How it works is an active area of research. Recently, stylized meta-learning-like setups have been devised that train these models on a sequence of input-output pairs (x, f (x)) from a function class using the language modeling loss and observe generalization to unseen functions from the same class. One of the main discoveries in this line of research has been that for several problems such as linear regression, trained transformers learn algorithms for learning functions in context. However, the inductive biases of these models resulting in this behavior are not clearly understood. A model with unlimited training data and compute is a Bayesian predictor: it learns the pretraining distribution. It has been shown that high-capacity transformers mimic the Bayesian predictor for linear regression. In this paper, we show empirical evidence of transformers exhibiting the behavior of this ideal learner across different linear and non-linear function classes. We also extend the previous setups to work in the multitask setting and verify that transformers can do in-context learning in this setup as well and the Bayesian perspective sheds light on this setting also. Finally, via the example of learning Fourier series, we study the inductive bias for in-context learning. We find that in-context learning may or may not have simplicity bias depending on the pretraining data distribution.},
	language = {en},
	journal = {arXiv preprint arXiv:2306.04891},
	author = {Ahuja, Kabir and Panwar, Madhur and Goyal, Navin},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{kirsch_general-purpose_2022,
	title = {General-purpose in-context learning by meta-learning transformers},
	booktitle = {Sixth {Workshop} on {Meta}-{Learning} at the {Conference} on {Neural} {Information} {Processing} {Systems}},
	author = {Kirsch, Louis and Harrison, James and Sohl-Dickstein, Jascha and Metz, Luke},
	year = {2022},
}

@article{hahn_theory_2023,
	title = {A theory of emergent in-context learning as implicit structure induction},
	abstract = {Scaling large language models (LLMs) leads to an emergent capacity to learn in-context from example demonstrations. Despite progress, theoretical understanding of this phenomenon remains limited. We argue that in-context learning relies on recombination of compositional operations found in natural language data. We derive an information-theoretic bound showing how in-context learning abilities arise from generic next-token prediction when the pretraining distribution has sufﬁcient amounts of compositional structure, under linguistically motivated assumptions. A second bound provides a theoretical justiﬁcation for the empirical success of prompting LMs to output intermediate steps towards an answer. To validate theoretical predictions, we introduce a controlled setup for inducing in-context learning; unlike previous approaches, it accounts for the compositional nature of language. Trained transformer LMs can perform in-context learning for a range of tasks, in a manner consistent with the theoretical results. Mirroring real-world LMs in a miniature setup, in-context learning emerges when scaling parameters and data, and LMs perform better when prompted to output intermediate steps. Probing shows that in-context learning is supported by a representation of the input’s compositional structure. Taken together, these results provide a step towards theoretical understanding of emergent behavior in large language models.},
	language = {en},
	journal = {arXiv preprint arXiv:2303.07971},
	author = {Hahn, Michael and Goyal, Navin},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{von_oswald_transformers_2023,
	title = {Transformers learn in-context by gradient descent},
	abstract = {At present, the mechanisms of in-context learning in Transformers are not well understood and remain mostly an intuition. In this paper, we suggest that training Transformers on auto-regressive objectives is closely related to gradient-based metalearning formulations. We start by providing a simple weight construction that shows the equivalence of data transformations induced by 1) a single linear self-attention layer and by 2) gradientdescent (GD) on a regression loss. Motivated by that construction, we show empirically that when training self-attention-only Transformers on simple regression tasks either the models learned by GD and Transformers show great similarity or, remarkably, the weights found by optimization match the construction. Thus we show how trained Transformers become mesa-optimizers i.e. learn models by gradient descent in their forward pass. This allows us, at least in the domain of regression problems, to mechanistically understand the inner workings of in-context learning in optimized Transformers. Building on this insight, we furthermore identify how Transformers surpass the performance of plain gradient descent by learning an iterative curvature correction and learn linear models on deep data representations to solve non-linear regression tasks. Finally, we discuss intriguing parallels to a mechanism identified to be crucial for in-context learning termed induction-head (Olsson et al., 2022) and show how it could be understood as a specific case of in-context learning by gradient descent learning within Transformers.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, João and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{olsson_-context_2022,
	title = {In-context learning and induction heads},
	language = {en},
	journal = {arXiv preprint arXiv:2209.11895},
	author = {Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Johnston, Scott and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
	year = {2022},
}

@inproceedings{pan_what_2023,
	title = {What in-context learning "learns" in-context: {Disentangling} task recognition and task learning},
	shorttitle = {What in-context learning "learns" in-context},
	abstract = {Large language models (LLMs) exploit in-context learning (ICL) to solve tasks with only a few demonstrations, but its mechanisms are not yet well-understood. Some works suggest that LLMs only recall already learned concepts from pre-training, while others hint that ICL performs implicit learning over demonstrations. We characterize two ways through which ICL leverages demonstrations. Task recognition (TR) captures the extent to which LLMs can recognize a task through demonstrations -- even without ground-truth labels -- and apply their pre-trained priors, whereas task learning (TL) is the ability to capture new input-label mappings unseen in pre-training. Using a wide range of classification datasets and three LLM families (GPT-3, LLaMA and OPT), we design controlled experiments to disentangle the roles of TR and TL in ICL. We show that (1) models can achieve non-trivial performance with only TR, and TR does not further improve with larger models or more demonstrations; (2) LLMs acquire TL as the model scales, and TL's performance consistently improves with more demonstrations in context. Our findings unravel two different forces behind ICL and we advocate for discriminating them in future ICL research due to their distinct nature.},
	language = {en},
	booktitle = {{ACL}},
	author = {Pan, Jane and Gao, Tianyu and Chen, Howard and Chen, Danqi},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{si_measuring_2023,
	title = {Measuring inductive biases of in-context learning with underspecified demonstrations},
	abstract = {In-context learning (ICL) is an important paradigm for adapting large language models (LLMs) to new tasks, but the generalization behavior of ICL remains poorly understood. We investigate the inductive biases of ICL from the perspective of feature bias: which feature ICL is more likely to use given a set of underspecified demonstrations in which two features are equally predictive of the labels. First, we characterize the feature biases of GPT-3 models by constructing underspecified demonstrations from a range of NLP datasets and feature combinations. We find that LLMs exhibit clear feature biases - for example, demonstrating a strong bias to predict labels according to sentiment rather than shallow lexical features, like punctuation. Second, we evaluate the effect of different interventions that are designed to impose an inductive bias in favor of a particular feature, such as adding a natural language instruction or using semantically relevant label words. We find that, while many interventions can influence the learner to prefer a particular feature, it can be difficult to overcome strong prior biases. Overall, our results provide a broader picture of the types of features that ICL may be more likely to exploit and how to impose inductive biases that are better aligned with the intended task.},
	language = {en},
	booktitle = {{ACL}},
	author = {Si, Chenglei and Friedman, Dan and Joshi, Nitish and Feng, Shi and Chen, Danqi and He, He},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{ni_recurrent_2022,
	title = {Recurrent model-free {RL} can be a strong baseline for many {POMDPs}},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Ni, Tianwei and Eysenbach, Benjamin and Salakhutdinov, Ruslan},
	year = {2022},
	pages = {16691--16723},
}

@inproceedings{shao_is_2020,
	title = {Is normalization indispensable for training deep neural networks?},
	abstract = {Normalization operations are widely used to train deep neural networks, and they can improve both convergence and generalization in most tasks. The theories for normalization’s effectiveness and new forms of normalization have always been hot topics in research. To better understand normalization, one question can be whether normalization is indispensable for training deep neural networks? In this paper, we analyze what would happen when normalization layers are removed from the networks, and show how to train deep neural networks without normalization layers and without performance degradation. Our proposed method can achieve the same or even slightly better performance in a variety of tasks: image classiﬁcation in ImageNet, object detection and segmentation in MS-COCO, video classiﬁcation in Kinetics, and machine translation in WMT English-German, etc. Our study may help better understand the role of normalization layers and can be a competitive alternative to normalization layers. Codes are available at https://github.com/ hukkai/rescaling.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Shao, Jie and Hu, Kai and Wang, Changhu and Xue, Xiangyang and Raj, Bhiksha},
	year = {2020},
	pages = {13434--13444},
}

@inproceedings{bjorck_understanding_2018,
	title = {Understanding batch normalization},
	abstract = {Batch normalization (BN) is a technique to normalize activations in intermediate layers of deep neural networks. Its tendency to improve accuracy and speed up training have established BN as a favorite technique in deep learning. Yet, despite its enormous success, there remains little consensus on the exact reason and mechanism behind these improvements. In this paper we take a step towards a better understanding of BN, following an empirical approach. We conduct several experiments, and show that BN primarily enables training with larger learning rates, which is the cause for faster convergence and better generalization. For networks without BN we demonstrate how large gradient updates can result in diverging loss and activations growing uncontrollably with network depth, which limits possible learning rates. BN avoids this problem by constantly correcting activations to be zero-mean and of unit standard deviation, which enables larger gradient steps, yields faster convergence and may help bypass sharp local minima. We further show various ways in which gradients and activations of deep unnormalized networks are ill-behaved. We contrast our results against recent ﬁndings in random matrix theory, shedding new light on classical initialization schemes and their consequences.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bjorck, Nils and Gomes, Carla P and Selman, Bart and Weinberger, Kilian Q},
	year = {2018},
}

@inproceedings{luo_towards_2019,
	title = {Towards understanding regularization in batch normalization},
	abstract = {Batch Normalization (BN) improves both convergence and generalization in training neural networks. This work understands these phenomena theoretically. We analyze BN by using a basic block of neural networks, consisting of a kernel layer, a BN layer, and a nonlinear activation function. This basic network helps us understand the impacts of BN in three aspects. First, by viewing BN as an implicit regularizer, BN can be decomposed into population normalization (PN) and gamma decay as an explicit regularization. Second, learning dynamics of BN and the regularization show that training converged with large maximum and effective learning rate. Third, generalization of BN is explored by using statistical mechanics. Experiments demonstrate that BN in convolutional neural networks share the same traits of regularization as the above analyses.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Luo, Ping and Wang, Xinjiang and Shao, Wenqi and Peng, Zhanglin},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Systems and Control},
}

@inproceedings{santurkar_how_2018,
	title = {How does batch normalization help optimization?},
	abstract = {Batch Normalization (BatchNorm) is a widely adopted technique that enables faster and more stable training of deep neural networks (DNNs). Despite its pervasiveness, the exact reasons for BatchNorm’s effectiveness are still poorly understood. The popular belief is that this effectiveness stems from controlling the change of the layers’ input distributions during training to reduce the so-called “internal covariate shift”. In this work, we demonstrate that such distributional stability of layer inputs has little to do with the success of BatchNorm. Instead, we uncover a more fundamental impact of BatchNorm on the training process: it makes the optimization landscape signiﬁcantly smoother. This smoothness induces a more predictive and stable behavior of the gradients, allowing for faster training.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Ma, Aleksander},
	year = {2018},
}

@inproceedings{lobacheva_periodic_2021,
	title = {On the periodic behavior of neural network training with batch normalization and weight decay},
	abstract = {Training neural networks with batch normalization and weight decay has become a common practice in recent years. In this work, we show that their combined use may result in a surprising periodic behavior of optimization dynamics: the training process regularly exhibits destabilizations that, however, do not lead to complete divergence but cause a new period of training. We rigorously investigate the mechanism underlying the discovered periodic behavior from both empirical and theoretical points of view and analyze the conditions in which it occurs in practice. We also demonstrate that periodic behavior can be regarded as a generalization of two previously opposing perspectives on training with batch normalization and weight decay, namely the equilibrium presumption and the instability presumption.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lobacheva, Ekaterina and Kodryan, Maxim and Chirkova, Nadezhda and Malinin, Andrey and Vetrov, Dmitry},
	year = {2021},
	pages = {21545--21556},
}

@inproceedings{yang_mean_2019,
	title = {A mean field theory of batch normalization},
	abstract = {We develop a mean ﬁeld theory for batch normalization in fully-connected feedforward neural networks. In so doing, we provide a precise characterization of signal propagation and gradient backpropagation in wide batch-normalized networks at initialization. Our theory shows that gradient signals grow exponentially in depth and that these exploding gradients cannot be eliminated by tuning the initial weight variances or by adjusting the nonlinear activation function. Indeed, batch normalization itself is the cause of gradient explosion. As a result, vanilla batch-normalized networks without skip connections are not trainable at large depths for common initialization schemes, a prediction that we verify with a variety of empirical simulations. While gradient explosion cannot be eliminated, it can be reduced by tuning the network close to the linear regime, which improves the trainability of deep batch-normalized networks without residual connections. Finally, we investigate the learning dynamics of batch-normalized networks and observe that after a single step of optimization the networks achieve a relatively stable equilibrium in which gradients have dramatically smaller dynamic range. Our theory leverages Laplace, Fourier, and Gegenbauer transforms and we derive new identities that may be of independent interest.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Yang, Greg and Pennington, Jeffrey and Rao, Vinay and Sohl-Dickstein, Jascha and Schoenholz, Samuel S.},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks, Computer Science - Neural and Evolutionary Computing, Mathematics - Dynamical Systems},
}

@inproceedings{dukler_optimization_2020,
	title = {Optimization theory for {ReLU} neural networks trained with normalization layers},
	isbn = {2640-3498},
	booktitle = {International conference on machine learning},
	author = {Dukler, Yonatan and Gu, Quanquan and Montúfar, Guido},
	year = {2020},
	pages = {2751--2760},
}

@inproceedings{yang_change_2023,
	title = {Change is hard: {A} closer look at subpopulation shift},
	shorttitle = {Change is hard},
	abstract = {Machine learning models often perform poorly on subgroups that are underrepresented in the training data. Yet, little is understood on the variation in mechanisms that cause subpopulation shifts, and how algorithms generalize across such diverse shifts at scale. In this work, we provide a ﬁne-grained analysis of subpopulation shift. We ﬁrst propose a uniﬁed framework that dissects and explains common shifts in subgroups. We then establish a comprehensive benchmark of 20 stateof-the-art algorithms evaluated on 12 real-world datasets in vision, language, and healthcare domains. With results obtained from training over 10,000 models, we reveal intriguing observations for future progress in this space. First, existing algorithms only improve subgroup robustness over certain types of shifts but not others. Moreover, while current algorithms rely on group-annotated validation data for model selection, we ﬁnd that a simple selection criterion based on worst-class accuracy is surprisingly effective even without any group information. Finally, unlike existing works that solely aim to improve worst-group accuracy (WGA), we demonstrate the fundamental tradeoff between WGA and other important metrics, highlighting the need to carefully choose testing metrics. Code and data are available at: https: //github.com/YyzHarry/SubpopBench.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Yang, Yuzhe and Zhang, Haoran and Katabi, Dina and Ghassemi, Marzyeh},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{novak_neural_2020,
	title = {Neural tangents: {Fast} and easy infinite neural networks in {Python}},
	shorttitle = {Neural tangents},
	abstract = {NEURAL TANGENTS is a library designed to enable research into inﬁnite-width neural networks. It provides a high-level API for specifying complex and hierarchical neural network architectures. These networks can then be trained and evaluated either at ﬁnite-width as usual or in their inﬁnite-width limit. Inﬁnite-width networks can be trained analytically using exact Bayesian inference or using gradient descent via the Neural Tangent Kernel. Additionally, NEURAL TANGENTS provides tools to study gradient descent training dynamics of wide but ﬁnite networks in either function space or weight space.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Novak, Roman and Xiao, Lechao and Hron, Jiri and Lee, Jaehoon and Alemi, Alexander A. and Sohl-Dickstein, Jascha and Schoenholz, Samuel S.},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{abbe_generalization_2023,
	title = {Generalization on the unseen, logic reasoning and degree curriculum},
	abstract = {This paper considers the learning of logical (Boolean) functions with focus on the generalization on the unseen (GOTU) setting, a strong case of out-of-distribution generalization. This is motivated by the fact that the rich combinatorial nature of data in certain reasoning tasks (e.g., arithmetic/logic) makes representative data sampling challenging, and learning successfully under GOTU gives a first vignette of an ‘extrapolating’ or ‘reasoning’ learner. We then study how different network architectures trained by (S)GD perform under GOTU and provide both theoretical and experimental evidence that for a class of network models including instances of Transformers, random features models, and diagonal linear networks, a min-degree-interpolator is learned on the unseen. We also provide evidence that other instances with larger learning rates or mean-field networks reach leaky min-degree solutions. These findings lead to two implications: (1) we provide an explanation to the length generalization problem (e.g., Anil et al. 2022); (2) we introduce a curriculum learning algorithm called Degree-Curriculum that learns monomials more efficiently by incrementing supports.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Abbe, Emmanuel and Bengio, Samy and Lotfi, Aryo and Rizk, Kevin},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{singh_revisiting_2022,
	address = {New Orleans, LA, USA},
	title = {Revisiting weakly supervised pre-training of visual perception models},
	isbn = {978-1-66546-946-3},
	doi = {10.1109/CVPR52688.2022.00088},
	abstract = {Model pre-training is a cornerstone of modern visual recognition systems. Although fully supervised pre-training on datasets like ImageNet is still the de-facto standard, recent studies suggest that large-scale weakly supervised pretraining can outperform fully supervised approaches. This paper revisits weakly-supervised pre-training of models using hashtag supervision with modern versions of residual networks and the largest-ever dataset of images and corresponding hashtags. We study the performance of the resulting models in various transfer-learning settings including zero-shot transfer. We also compare our models with those obtained via large-scale self-supervised learning. We find our weakly-supervised models to be very competitive across all settings, and find they substantially outperform their self-supervised counterparts. We also include an investigation into whether our models learned potentially troubling associations or stereotypes. Overall, our results provide a compelling argument for the use of weakly supervised learning in the development of visual recognition systems. Our models, Supervised Weakly through hashtAGs (SWAG), are available publicly.},
	language = {en},
	booktitle = {{IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Singh, Mannat and Gustafson, Laura and Adcock, Aaron and De Freitas Reis, Vinicius and Gedik, Bugra and Kosaraju, Raj Prateek and Mahajan, Dhruv and Girshick, Ross and Dollar, Piotr and Van Der Maaten, Laurens},
	year = {2022},
	pages = {794--804},
}

@misc{huang_voxposer_2023,
	title = {Voxposer: {Composable} 3d value maps for robotic manipulation with language models},
	shorttitle = {Voxposer},
	abstract = {Large language models (LLMs) are shown to possess a wealth of actionable knowledge that can be extracted for robot manipulation in the form of reasoning and planning. Despite the progress, most still rely on pre-defined motion primitives to carry out the physical interactions with the environment, which remains a major bottleneck. In this work, we aim to synthesize robot trajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a large variety of manipulation tasks given an open-set of instructions and an open-set of objects. We achieve this by first observing that LLMs excel at inferring affordances and constraints given a free-form language instruction. More importantly, by leveraging their code-writing capabilities, they can interact with a visual-language model (VLM) to compose 3D value maps to ground the knowledge into the observation space of the agent. The composed value maps are then used in a model-based planning framework to zero-shot synthesize closed-loop robot trajectories with robustness to dynamic perturbations. We further demonstrate how the proposed framework can benefit from online experiences by efficiently learning a dynamics model for scenes that involve contact-rich interactions. We present a largescale study of the proposed method in both simulated and real-robot environments, showcasing the ability to perform a large variety of everyday manipulation tasks specified in free-form natural language. Project website: voxposer.github.io.},
	language = {en},
	author = {Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics, Computer Science - Computation and Language},
}

@inproceedings{malach_quantifying_2021,
	title = {Quantifying the benefit of using differentiable learning over tangent kernels},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Malach, Eran and Kamath, Pritish and Abbe, Emmanuel and Srebro, Nathan},
	year = {2021},
}

@inproceedings{yu_distribution_2023,
	title = {Distribution shift inversion for out-of-distribution prediction},
	abstract = {Machine learning society has witnessed the emergence of a myriad of Out-of-Distribution (OoD) algorithms, which address the distribution shift between the training and the testing distribution by searching for a unified predictor or invariant feature representation. However, the task of directly mitigating the distribution shift in the unseen testing set is rarely investigated, due to the unavailability of the testing distribution during the training phase and thus the impossibility of training a distribution translator mapping between the training and testing distribution. In this paper, we explore how to bypass the requirement of testing distribution for distribution translator training and make the distribution translation useful for OoD prediction. We propose a portable Distribution Shift Inversion (DSI) algorithm, in which, before being fed into the prediction model, the OoD testing samples are first linearly combined with additional Gaussian noise and then transferred back towards the training distribution using a diffusion model trained only on the source distribution. Theoretical analysis reveals the feasibility of our method. Experimental results, on both multiple-domain generalization datasets and single-domain generalization datasets, show that our method provides a general performance gain when plugged into a wide range of commonly used OoD algorithms. Our code is available at https://github.com/yu-rp/Distribution-Shift-Iverson.},
	language = {en},
	booktitle = {{CVPR}},
	author = {Yu, Runpeng and Liu, Songhua and Yang, Xingyi and Wang, Xinchao},
	year = {2023},
}

@inproceedings{kornblith_similarity_2019,
	title = {Similarity of neural network representations revisited},
	abstract = {Recent work has sought to understand the behavior of neural networks by comparing representations between layers and between different trained models. We examine methods for comparing neural network representations based on canonical correlation analysis (CCA). We show that CCA belongs to a family of statistics for measuring multivariate similarity, but that neither CCA nor any other statistic that is invariant to invertible linear transformation can measure meaningful similarities between representations of higher dimension than the number of data points. We introduce a similarity index that measures the relationship between representational similarity matrices and does not suffer from this limitation. This similarity index is equivalent to centered kernel alignment (CKA) and is also closely connected to CCA. Unlike CCA, CKA can reliably identify correspondences between representations in networks trained from different initializations.},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
	year = {2019},
	pages = {3519--3529},
}

@inproceedings{yuan_power_2023,
	title = {On the power of foundation models},
	abstract = {With inﬁnitely many high-quality data points, inﬁnite computational power, an inﬁnitely large foundation model with a perfect training algorithm and guaranteed zero generalization error on the pretext task, can the model be used for everything? This question cannot be answered by the existing theory of representation, optimization or generalization, because the issues they mainly investigate are assumed to be nonexistent here. In this paper, we show that category theory provides powerful machinery to answer this question. We have proved three results. The ﬁrst one limits the power of prompt-based learning, saying that the model can solve a downstream task with prompts if and only if the task is representable. The second one says ﬁne tuning does not have this limit, as a foundation model with the minimum required power (up to symmetry) can theoretically solve downstream tasks for the category deﬁned by pretext task, with ﬁne tuning and enough resources. Our ﬁnal result can be seen as a new type of generalization theorem, showing that the foundation model can generate unseen objects from the target category (e.g., images) using the structural information from the source category (e.g., texts). Along the way, we provide a categorical framework for supervised and self-supervised learning, which might be of independent interest.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Yuan, Yang},
	year = {2023},
}

@inproceedings{torralba_unbiased_2011,
	title = {Unbiased look at dataset bias},
	doi = {10.1109/CVPR.2011.5995347},
	abstract = {Datasets are an integral part of contemporary object recognition research. They have been the chief reason for the considerable progress in the field, not just as source of large amounts of training data, but also as means of measuring and comparing performance of competing algorithms. At the same time, datasets have often been blamed for narrowing the focus of object recognition research, reducing it to a single benchmark performance number. Indeed, some datasets, that started out as data capture efforts aimed at representing the visual world, have become closed worlds unto themselves (e.g. the Corel world, the Caltech-101 world, the PASCAL VOC world). With the focus on beating the latest benchmark numbers on the latest dataset, have we perhaps lost sight of the original purpose? The goal of this paper is to take stock of the current state of recognition datasets. We present a comparison study using a set of popular datasets, evaluated based on a number of criteria including: relative data bias, cross-dataset generalization, effects of closed-world assumption, and sample value. The experimental results, some rather surprising, suggest directions that can improve dataset collection as well as algorithm evaluation protocols. But more broadly, the hope is to stimulate discussion in the community regarding this very important, but largely neglected issue.},
	booktitle = {{CVPR}},
	author = {Torralba, Antonio and Efros, Alexei A.},
	year = {2011},
	keywords = {Support vector machines, Training, Visualization, Communities, Internet, Object recognition, Testing},
	pages = {1521--1528},
}

@article{sutton_bitter_2019,
	title = {The bitter lesson},
	journal = {Incomplete Ideas (blog)},
	author = {Sutton, Richard},
	year = {2019},
}

@inproceedings{wen_mechanism_2022,
	title = {The mechanism of prediction head in non-contrastive self-supervised learning},
	abstract = {The surprising discovery of the BYOL method shows the negative samples can be replaced by adding a prediction head to the neural network. It is mysterious why even when there exist trivial collapsed global optimal solutions, neural networks trained by (stochastic) gradient descent can still learn competitive representations. In this work, we present our empirical and theoretical discoveries on non-contrastive self-supervised learning. Empirically, we ﬁnd that when the prediction head is initialized as an identity matrix with only its off-diagonal entries being trainable, the network can learn competitive representations even though the trivial optima still exist in the training objective. Theoretically, we characterized the substitution effect and acceleration effect of the trainable, but identity-initialized prediction head. The substitution effect happens when learning the stronger features in some neurons can substitute for learning these features in other neurons through updating the prediction head. And the acceleration effect happens when the substituted features can accelerate the learning of other weaker features to prevent them from being ignored. These two effects enable the neural networks to learn diversiﬁed features rather than focus only on learning the strongest features, which is likely the cause of the dimensional collapse phenomenon. To the best of our knowledge, this is also the ﬁrst end-to-end optimization guarantee for non-contrastive methods using nonlinear neural networks with a trainable prediction head and normalization.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wen, Zixin and Li, Yuanzhi},
	year = {2022},
	pages = {24794--24809},
}

@inproceedings{chen_towards_2023,
	title = {Towards understanding feature learning in out-of-distribution generalization},
	abstract = {A common explanation for the failure of out-of-distribution (OOD) generalization is that the model trained with empirical risk minimization (ERM) learns spurious features instead of the desired invariant features. However, several recent studies challenged this explanation and found that deep networks may have already learned sufﬁciently good features for OOD generalization. The debate extends to the in-distribution and OOD performance correlations along with training or ﬁne-tuning neural nets across a variety of OOD generalization tasks. To understand these seemingly contradicting phenomena, we conduct a theoretical investigation and ﬁnd that ERM essentially learns both spurious features and invariant features. On the other hand, the quality of learned features during ERM pre-training signiﬁcantly affects the ﬁnal OOD performance, as OOD objectives rarely learn new features. Failing to capture all the underlying useful features during pre-training will further limit the ﬁnal OOD performance. To remedy the issue, we propose Feature Augmented Training (FAT), to enforce the model to learn all useful features by retaining the already learned features and augmenting new ones by multiple rounds. In each round, the retention and augmentation operations are performed on different subsets of the training data that capture distinct features. Extensive experiments show that FAT effectively learns richer features and consistently improves the OOD performance when applied to various objectives.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chen, Yongqiang and Huang, Wei and Zhou, Kaiwen and Bian, Yatao and Han, Bo and Cheng, James},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{zhang_learning_2023,
	title = {Learning useful representations for shifting tasks and distributions},
	abstract = {Does the dominant approach to learn representations (as a side effect of optimizing an expected cost for a single training distribution) remain a good approach when we are dealing with multiple distributions? Our thesis is that such scenarios are better served by representations that are richer than those obtained with a single optimization episode. We support this thesis with simple theoretical arguments and with experiments utilizing an apparently naïve ensembling technique: concatenating the representations obtained from multiple training episodes using the same data, model, algorithm, and hyper-parameters, but different random seeds. These independently trained networks perform similarly. Yet, in a number of scenarios involving new distributions, the concatenated representation performs substantially better than an equivalently sized network trained with a single training run. This proves that the representations constructed by multiple training episodes are in fact different. Although their concatenation carries little additional information about the training task under the training distribution, it becomes substantially more informative when tasks or distributions change. Meanwhile, a single training episode is unlikely to yield such a redundant representation because the optimization process has no reason to accumulate features that do not incrementally improve the training performance.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhang, Jianyu and Bottou, Léon},
	year = {2023},
}

@inproceedings{chidambaram_provably_2023,
	title = {Provably learning diverse features in multi-view data with midpoint mixup},
	abstract = {Mixup is a data augmentation technique that relies on training using random convex combinations of data points and their labels. In recent years, Mixup has become a standard primitive used in the training of state-of-the-art image classification models due to its demonstrated benefits over empirical risk minimization with regards to generalization and robustness. In this work, we try to explain some of this success from a feature learning perspective. We focus our attention on classification problems in which each class may have multiple associated features (or views) that can be used to predict the class correctly. Our main theoretical results demonstrate that, for a non-trivial class of data distributions with two features per class, training a 2-layer convolutional network using empirical risk minimization can lead to learning only one feature for almost all classes while training with a specific instantiation of Mixup succeeds in learning both features for every class. We also show empirically that these theoretical insights extend to the practical settings of image benchmarks modified to have multiple features.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Chidambaram, Muthu and Wang, Xiang and Wu, Chenwei and Ge, Rong},
	year = {2023},
}

@inproceedings{goyal_test-time_2022,
	title = {Test-time adaptation via conjugate pseudo-labels},
	abstract = {Test-time adaptation (TTA) refers to adapting neural networks to distribution shifts, with access to only the unlabeled test samples from the new domain at test-time. Prior TTA methods optimize over unsupervised objectives such as the entropy of model predictions in TENT [50], but it is unclear what exactly makes a good TTA loss. In this paper, we start by presenting a surprising phenomenon: if we attempt to meta-learn the “best” possible TTA loss over a wide class of functions, then we recover a function that is remarkably similar to (a temperature-scaled version of) the softmax-entropy employed by TENT. This only holds, however, if the classifier we are adapting is trained via cross-entropy loss; if the classifier is trained via squared loss, a different “best” TTA loss emerges. To explain this phenomenon, we analyze test-time adaptation through the lens of the training losses’s convex conjugate. We show that under natural conditions, this (unsupervised) conjugate function can be viewed as a good local approximation to the original supervised loss and indeed, it recovers the “best” losses found by meta-learning. This leads to a generic recipe that can be used to find a good TTA loss for any given supervised training loss function of a general class. Empirically, our approach consistently dominates other TTA alternatives over a wide range of domain adaptation benchmarks. Our approach is particularly of interest when applied to classifiers trained with novel loss functions, e.g., the recently-proposed PolyLoss [25] function, where it differs substantially from (and outperforms) an entropy-based loss. Further, we show that our conjugate based approach can also be interpreted as a kind of self-training using a very specific soft label, which we refer to as the conjugate pseudo-label. Overall, our method provides a broad framework for better understanding and improving test-time adaptation. Code is available at https://github.com/locuslab/ tta\_conjugate.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Goyal, Sachin and Sun, Mingjie and Raghunathan, Aditi and Kolter, Zico},
	year = {2022},
	pages = {6204--6218},
}

@inproceedings{geirhos_generalisation_2018,
	title = {Generalisation in humans and deep neural networks},
	abstract = {We compare the robustness of humans and current convolutional deep neural networks (DNNs) on object recognition under twelve different types of image degradations. First, using three well known DNNs (ResNet-152, VGG-19, GoogLeNet) we ﬁnd the human visual system to be more robust to nearly all of the tested image manipulations, and we observe progressively diverging classiﬁcation error-patterns between humans and DNNs when the signal gets weaker. Secondly, we show that DNNs trained directly on distorted images consistently surpass human performance on the exact distortion types they were trained on, yet they display extremely poor generalisation abilities when tested on other distortion types. For example, training on salt-and-pepper noise does not imply robustness on uniform white noise and vice versa. Thus, changes in the noise distribution between training and testing constitutes a crucial challenge to deep learning vision systems that can be systematically addressed in a lifelong machine learning approach. Our new dataset consisting of 83K carefully measured human psychophysical trials provide a useful reference for lifelong robustness against image degradations set by the human visual system.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Geirhos, Robert and Temme, Carlos R M and Rauber, Jonas and Schütt, Heiko H and Bethge, Matthias and Wichmann, Felix A},
	year = {2018},
	pages = {7549--7561},
}

@inproceedings{karp_local_2021,
	title = {Local signal adaptivity: {Provable} feature learning in neural networks beyond kernels},
	abstract = {Neural networks have been shown to outperform kernel methods in practice (including neural tangent kernels). Most theoretical explanations of this performance gap focus on learning a complex hypothesis class; in some cases, it is unclear whether this hypothesis class captures realistic data. In this work, we propose a related, but alternative, explanation for this performance gap in the image classiﬁcation setting, based on ﬁnding a sparse signal in the presence of noise. Speciﬁcally, we prove that, for a simple data distribution with sparse signal amidst high-variance noise, a simple convolutional neural network trained using stochastic gradient descent simultaneously learns to threshold out the noise and ﬁnd the signal. On the other hand, the corresponding neural tangent kernel, with a ﬁxed set of predetermined features, is unable to adapt to the signal in this manner. We supplement our theoretical results by demonstrating this phenomenon empirically: in CIFAR-10 and MNIST images with various backgrounds, as the background noise increases in intensity, a CNN’s performance stays relatively robust, whereas its corresponding neural tangent kernel sees a notable drop in performance. We therefore propose the local signal adaptivity (LSA) phenomenon as one explanation for the superiority of neural networks over kernel methods.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Karp, Stefani and Winston, Ezra and Li, Yuanzhi and Singh, Aarti},
	year = {2021},
	pages = {24883--24897},
}

@inproceedings{daniely_learning_2020,
	title = {Learning parities with neural networks},
	abstract = {In recent years we see a rapidly growing line of research which shows learnability of various models via common neural network algorithms. Yet, besides a very few outliers, these results show learnability of models that can be learned using linear methods. Namely, such results show that learning neural-networks with gradientdescent is competitive with learning a linear classiﬁer on top of a data-independent representation of the examples. This leaves much to be desired, as neural networks are far more successful than linear methods. Furthermore, on the more conceptual level, linear models don’t seem to capture the “deepness" of deep networks. In this paper we make a step towards showing leanability of models that are inherently non-linear. We show that under certain distributions, sparse parities are learnable via gradient decent on depth-two network. On the other hand, under the same distributions, these parities cannot be learned efﬁciently by linear methods.},
	language = {en},
	author = {Daniely, Amit and Malach, Eran},
	year = {2020},
	pages = {20356--20365},
}

@article{yu_coca_2022,
	title = {Coca: {Contrastive} captioners are image-text foundation models},
	shorttitle = {Coca},
	abstract = {Exploring large-scale pretrained foundation models is of signiﬁcant interest in computer vision because these models can be quickly transferred to many downstream tasks. This paper presents Contrastive Captioner (CoCa), a minimalist design to pretrain an image-text encoder-decoder foundation model jointly with contrastive loss and captioning loss, thereby subsuming model capabilities from contrastive approaches like CLIP and generative methods like SimVLM. In contrast to standard encoder-decoder transformers where all decoder layers attend to encoder outputs, CoCa omits cross-attention in the ﬁrst half of decoder layers to encode unimodal text representations, and cascades the remaining decoder layers which cross-attend to the image encoder for multimodal image-text representations. We apply a contrastive loss between unimodal image and text embeddings, in addition to a captioning loss on the multimodal decoder outputs which predicts text tokens autoregressively. By sharing the same computational graph, the two training objectives are computed efﬁciently with minimal overhead. CoCa is pretrained end-to-end and from scratch on both web-scale alt-text data and annotated images by treating all labels simply as text, seamlessly unifying natural language supervision for representation learning. Empirically, CoCa achieves state-of-theart performance with zero-shot transfer or minimal task-speciﬁc adaptation on a broad range of downstream tasks, spanning visual recognition (ImageNet, Kinetics400/600/700, Moments-in-Time), crossmodal retrieval (MSCOCO, Flickr30K, MSR-VTT), multimodal understanding (VQA, SNLI-VE, NLVR2), and image captioning (MSCOCO, NoCaps). Notably on ImageNet classiﬁcation, CoCa obtains 86.3\% zero-shot top-1 accuracy, 90.6\% with a frozen encoder and learned classiﬁcation head, and new state-of-the-art 91.0\% top-1 accuracy on ImageNet with a ﬁnetuned encoder.},
	language = {en},
	journal = {arXiv preprint arXiv:2205.01917},
	author = {Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Multimedia},
}

@inproceedings{lee_surgical_2023,
	title = {Surgical fine-tuning improves adaptation to distribution shifts},
	abstract = {A common approach to transfer learning under distribution shift is to fine-tune the last few layers of a pre-trained model, preserving learned features while also adapting to the new task. This paper shows that in such settings, selectively fine-tuning a subset of layers (which we term surgical fine-tuning) matches or outperforms commonly used fine-tuning approaches. Moreover, the type of distribution shift influences which subset is more effective to tune: for example, for image corruptions, fine-tuning only the first few layers works best. We validate our findings systematically across seven real-world data tasks spanning three types of distribution shifts. Theoretically, we prove that for two-layer neural networks in an idealized setting, first-layer tuning can outperform fine-tuning all layers. Intuitively, fine-tuning more parameters on a small target dataset can cause information learned during pre-training to be forgotten, and the relevant information depends on the type of shift.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Lee, Yoonho and Chen, Annie S and Tajwar, Fahim and Kumar, Ananya and Yao, Huaxiu and Liang, Percy and Finn, Chelsea},
	year = {2023},
}

@article{varma_explaining_2023,
	title = {Explaining grokking through circuit efficiency},
	abstract = {One of the most surprising puzzles in neural network generalisation is grokking: a network with perfect training accuracy but poor generalisation will, upon further training, transition to perfect generalisation. We propose that grokking occurs when the task admits a generalising solution and a memorising solution, where the generalising solution is slower to learn but more efficient, producing larger logits with the same parameter norm. We hypothesise that memorising circuits become more inefficient with larger training datasets while generalising circuits do not, suggesting there is a critical dataset size at which memorisation and generalisation are equally efficient. We make and confirm four novel predictions about grokking, providing significant evidence in favour of our explanation. Most strikingly, we demonstrate two novel and surprising behaviours: ungrokking, in which a network regresses from perfect to low test accuracy, and semi-grokking, in which a network shows delayed generalisation to partial rather than perfect test accuracy.},
	language = {en},
	journal = {arXiv preprint arXiv:2309.02390},
	author = {Varma, Vikrant and Shah, Rohin and Kenton, Zachary and Kramár, János and Kumar, Ramana},
	year = {2023},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{seleznova_analyzing_2021,
	title = {Analyzing finite neural networks: {Can} we trust neural tangent kernel theory?},
	abstract = {Neural Tangent Kernel (NTK) theory is widely used to study the dynamics of inﬁnitely-wide deep neural networks (DNNs) under gradient descent. But do the results for inﬁnitely-wide networks give us hints about the behavior of real ﬁnite-width ones? In this paper, we study empirically when NTK theory is valid in practice for fully-connected ReLU and sigmoid DNNs. We ﬁnd out that whether a network is in the NTK regime depends on the hyperparameters of random initialization and the network’s depth. In particular, NTK theory does not explain the behavior of sufﬁciently deep networks initialized so that their gradients explode as they propagate through the network’s layers: the kernel is random at initialization and changes signiﬁcantly during training in this case, contrary to NTK theory. On the other hand, in the case of vanishing gradients, DNNs are in the the NTK regime but become untrainable rapidly with depth. We also describe a framework to study generalization properties of DNNs, in particular the variance of network’s output function, by means of NTK theory and discuss its limits.},
	language = {en},
	booktitle = {2nd {Annual} {Conference} on {Mathematical} and {Scientific} {Machine} {Learning}},
	author = {Seleznova, Mariia},
	year = {2021},
}

@inproceedings{salman_provably_2019,
	title = {Provably robust deep learning via adversarially trained smoothed classifiers},
	abstract = {Recent works have shown the effectiveness of randomized smoothing as a scalable technique for building neural network-based classiﬁers that are provably robust to 2-norm adversarial perturbations. In this paper, we employ adversarial training to improve the performance of randomized smoothing. We design an adapted attack for smoothed classiﬁers, and we show how this attack can be used in an adversarial training setting to boost the provable robustness of smoothed classiﬁers. We demonstrate through extensive experimentation that our method consistently outperforms all existing provably 2-robust classiﬁers by a signiﬁcant margin on ImageNet and CIFAR-10, establishing the state-of-the-art for provable 2-defenses. Moreover, we ﬁnd that pre-training and semi-supervised learning boost adversarially trained smoothed classiﬁers even further. Our code and trained models are available at http://github.com/Hadisalman/smoothing-adversarial2.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Salman, Hadi and Yang, Greg and Li, Jerry and Zhang, Pengchuan and Zhang, Huan and Razenshteyn, Ilya and Bubeck, Sébastien},
	year = {2019},
}

@inproceedings{wei_chain--thought_2022,
	title = {Chain-of-thought prompting elicits reasoning in large language models},
	abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—signiﬁcantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufﬁciently large language models via a simple method called chain-ofthought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even ﬁnetuned GPT-3 with a veriﬁer.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H and Le, Quoc V and Zhou, Denny},
	year = {2022},
	pages = {24824--24837},
}

@article{wei_emergent_2022,
	title = {Emergent abilities of large language models},
	journal = {Transactions on Machine Learning Research},
	author = {Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald},
	year = {2022},
}

@inproceedings{ouyang_training_2022,
	title = {Training language models to follow instructions with human feedback},
	abstract = {Making language models bigger does not inherently make them better at following a user’s intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through a language model API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
	year = {2022},
	pages = {27730--27744},
}

@article{yang_dawn_2023,
	title = {The dawn of {LMMs}: {Preliminary} explorations with {GPT}-{4V}(ision)},
	shorttitle = {The dawn of lmms},
	abstract = {Large multimodal models (LMMs) extend large language models (LLMs) with multi-sensory skills, such as visual understanding, to achieve stronger generic intelligence. In this paper, we analyze the latest model, GPT-4V(ision)1, to deepen the understanding of LMMs. The analysis focuses on the intriguing tasks that GPT-4V can perform, containing test samples to probe the quality and genericity of GPT-4V’s capabilities, its supported inputs and working modes, and the effective ways to prompt the model. In our approach to exploring GPT-4V, we curate and organize a collection of carefully designed qualitative samples spanning a variety of domains and tasks. Observations from these samples demonstrate that GPT-4V’s unprecedented ability in processing arbitrarily interleaved multimodal inputs and the genericity of its capabilities together make GPT-4V a powerful multimodal generalist system. Furthermore, GPT-4V’s unique capability of understanding visual markers drawn on input images can give rise to new human-computer interaction methods such as visual referring prompting. We conclude the report with in-depth discussions on the emerging application scenarios and the future research directions for GPT-4V-based systems. We hope that this preliminary exploration will inspire future research on the next-generation multimodal task formulation, new ways to exploit and enhance LMMs to solve real-world problems, and gaining better understanding of multimodal foundation models.},
	language = {en},
	journal = {arXiv preprint arXiv:2309.17421},
	author = {Yang, Zhengyuan and Li, Linjie and Lin, Kevin and Wang, Jianfeng and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
	year = {2023},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
}

@inproceedings{liu_towards_2022,
	title = {Towards understanding grokking: {An} effective theory of representation learning},
	abstract = {We aim to understand grokking, a phenomenon where models generalize long after overfitting their training set. We present both a microscopic analysis anchored by an effective theory and a macroscopic analysis of phase diagrams describing learning performance across hyperparameters. We find that generalization originates from structured representations whose training dynamics and dependence on training set size can be predicted by our effective theory in a toy setting. We observe empirically the presence of four learning phases: comprehension, grokking, memorization, and confusion. We find representation learning to occur only in a “Goldilocks zone” (including comprehension and grokking) between memorization and confusion. We find on transformers the grokking phase stays closer to the memorization phase (compared to the comprehension phase), leading to delayed generalization. The Goldilocks phase is reminiscent of “intelligence from starvation” in Darwinian evolution, where resource limitations drive discovery of more efficient solutions. This study not only provides intuitive explanations of the origin of grokking, but also highlights the usefulness of physics-inspired tools, e.g., effective theories and phase diagrams, for understanding deep learning.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Liu, Ziming and Kitouni, Ouail and Nolte, Niklas and Michaud, Eric J and Tegmark, Max and Williams, Mike},
	year = {2022},
	pages = {34651--34663},
}

@article{power_grokking_2022,
	title = {Grokking: {Generalization} beyond overfitting on small algorithmic datasets},
	shorttitle = {Grokking},
	abstract = {In this paper we propose to study generalization of neural networks on small algorithmically generated datasets. In this setting, questions about data efﬁciency, memorization, generalization, and speed of learning can be studied in great detail. In some situations we show that neural networks learn through a process of “grokking” a pattern in the data, improving generalization performance from random chance level to perfect generalization, and that this improvement in generalization can happen well past the point of overﬁtting. We also study generalization as a function of dataset size and ﬁnd that smaller datasets require increasing amounts of optimization for generalization. We argue that these datasets provide a fertile ground for studying a poorly understood aspect of deep learning: generalization of overparametrized neural networks beyond memorization of the ﬁnite training dataset.},
	language = {en},
	journal = {arXiv preprint arXiv:2201.02177},
	author = {Power, Alethea and Burda, Yuri and Edwards, Harri and Babuschkin, Igor and Misra, Vedant},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@article{touvron_llama_2023,
	title = {Llama 2: {Open} foundation and fine-tuned chat models},
	shorttitle = {Llama 2},
	abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closedsource models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
	language = {en},
	journal = {arXiv preprint arXiv:2307.09288},
	author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{kirk_survey_2023,
	title = {A survey of zero-shot generalisation in deep reinforcement learning},
	volume = {76},
	issn = {1076-9757},
	doi = {10.1613/jair.1.14174},
	abstract = {The study of zero-shot generalisation (ZSG) in deep Reinforcement Learning (RL) aims to produce RL algorithms whose policies generalise well to novel unseen situations at deployment time, avoiding overﬁtting to their training environments. Tackling this is vital if we are to deploy reinforcement learning algorithms in real world scenarios, where the environment will be diverse, dynamic and unpredictable. This survey is an overview of this nascent ﬁeld. We rely on a unifying formalism and terminology for discussing diﬀerent ZSG problems, building upon previous works. We go on to categorise existing benchmarks for ZSG, as well as current methods for tackling these problems. Finally, we provide a critical discussion of the current state of the ﬁeld, including recommendations for future work. Among other conclusions, we argue that taking a purely procedural content generation approach to benchmark design is not conducive to progress in ZSG, we suggest fast online adaptation and tackling RL-speciﬁc problems as some areas for future work on methods for ZSG, and we recommend building benchmarks in underexplored problem settings such as oﬄine RL ZSG and reward-function variation.},
	language = {en},
	journal = {Journal of Artificial Intelligence Research},
	author = {Kirk, Robert and Zhang, Amy and Grefenstette, Edward and Rocktäschel, Tim},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {201--264},
}

@inproceedings{zheng_weakly_2021,
	address = {Montreal, QC, Canada},
	title = {Weakly supervised contrastive learning},
	isbn = {978-1-66542-812-5},
	doi = {10.1109/ICCV48922.2021.00989},
	abstract = {Unsupervised visual representation learning has gained much attention from the computer vision community because of the recent achievement of contrastive learning. Most of the existing contrastive learning frameworks adopt the instance discrimination as the pretext task, which treating every single instance as a different class. However, such method will inevitably cause class collision problems, which hurts the quality of the learned representation. Motivated by this observation, we introduced a weakly supervised contrastive learning framework (WCL) to tackle this issue. Specifically, our proposed framework is based on two projection heads, one of which will perform the regular instance discrimination task. The other head will use a graphbased method to explore similar samples and generate a weak label, then perform a supervised contrastive learning task based on the weak label to pull the similar images closer. We further introduced a K-Nearest Neighbor based multi-crop strategy to expand the number of positive samples. Extensive experimental results demonstrate WCL improves the quality of self-supervised representations across different datasets. Notably, we get a new state-of-the-art result for semi-supervised learning. With only 1\% and 10\% labeled examples, WCL achieves 65\% and 72\% ImageNet Top-1 Accuracy using ResNet50, which is even higher than SimCLRv2 with ResNet101.},
	language = {en},
	booktitle = {2021 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Zheng, Mingkai and Wang, Fei and You, Shan and Qian, Chen and Zhang, Changshui and Wang, Xiaogang and Xu, Chang},
	year = {2021},
	pages = {10022--10031},
}

@misc{ash_investigating_2021,
	title = {Investigating the role of negatives in contrastive representation learning},
	abstract = {Noise contrastive learning is a popular technique for unsupervised representation learning. In this approach, a representation is obtained via reduction to supervised learning, where given a notion of semantic similarity, the learner tries to distinguish a similar (positive) example from a collection of random (negative) examples. The success of modern contrastive learning pipelines relies on many parameters such as the choice of data augmentation, the number of negative examples, and the batch size; however, there is limited understanding as to how these parameters interact and aﬀect downstream performance. We focus on disambiguating the role of one of these parameters: the number of negative examples. Theoretically, we show the existence of a collision-coverage trade-oﬀ suggesting that the optimal number of negative examples should scale with the number of underlying concepts in the data. Empirically, we scrutinize the role of the number of negatives in both NLP and vision tasks. In the NLP task, we ﬁnd that the results broadly agree with our theory, while our vision experiments are murkier with performance sometimes even being insensitive to the number of negatives. We discuss plausible explanations for this behavior and suggest future directions to better align theory and practice.},
	language = {en},
	author = {Ash, Jordan T. and Goel, Surbhi and Krishnamurthy, Akshay and Misra, Dipendra},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
}

@misc{tamkin_feature_2022,
	title = {Feature dropout: {Revisiting} the role of augmentations in contrastive learning},
	shorttitle = {Feature dropout},
	abstract = {What role do augmentations play in contrastive learning? Recent work suggests that good augmentations are label-preserving with respect to a speciﬁc downstream task. We complicate this picture by showing that label-destroying augmentations can be useful in the foundation model setting, where the goal is to learn diverse, general-purpose representations for multiple downstream tasks. We perform contrastive learning experiments on a range of image and audio datasets with multiple downstream tasks (e.g. for digits superimposed on photographs, predicting the class of one vs. the other). We ﬁnd that Viewmaker Networks, a recently proposed model for learning augmentations for contrastive learning, produce label-destroying augmentations that stochastically destroy features needed for different downstream tasks. These augmentations are interpretable (e.g. altering shapes, digits, or letters added to images) and surprisingly often result in better performance compared to expert-designed augmentations, despite not preserving label information. To support our empirical results, we theoretically analyze a simple contrastive learning setting with a linear model. In this setting, label-destroying augmentations are crucial for preventing one set of features from suppressing the learning of features useful for another downstream task. Our results highlight the need for analyzing the interaction between multiple downstream tasks when trying to explain the success of foundation models.},
	language = {en},
	author = {Tamkin, Alex and Glasgow, Margalit and He, Xiluo and Goodman, Noah},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
}

@inproceedings{laurent_deep_2018,
	title = {Deep linear networks with arbitrary loss: {All} local minima are global},
	abstract = {We consider deep linear networks with arbitrary convex differentiable loss. We provide a short and elementary proof of the fact that all local minima are global minima if the hidden layers are either 1) at least as wide as the input layer, or 2) at least as wide as the output layer. This result is the strongest possible in the following sense: If the loss is convex and Lipschitz but not differentiable then deep linear networks can have sub-optimal local minima.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Laurent, Thomas},
	year = {2018},
	pages = {2902--2907},
}

@inproceedings{wang_hidden_2022,
	title = {The hidden convex optimization landscape of regularized two-layer relu networks: {An} exact characterization of optimal solutions},
	shorttitle = {The hidden convex optimization landscape of regularized two-layer relu networks},
	abstract = {We prove that finding all globally optimal two-layer ReLU neural networks can be performed by solving a convex optimization program with cone constraints. Our analysis is novel, characterizes all optimal solutions, and does not leverage duality-based analysis which was recently used to lift neural network training into convex spaces. Given the set of solutions of our convex optimization program, we show how to construct exactly the entire set of optimal neural networks. We provide a detailed characterization of this optimal set and its invariant transformations. As additional consequences of our convex perspective, (i) we establish that Clarke stationary points found by stochastic gradient descent correspond to the global optimum of a subsampled convex problem (ii) we provide a polynomial-time algorithm for checking if a neural network is a global minimum of the training loss (iii) we provide an explicit construction of a continuous path between any neural network and the global minimum of its sublevel set and (iv) characterize the minimal size of the hidden layer so that the neural network optimization landscape has no spurious valleys. Overall, we provide a rich framework for studying the landscape of neural network training loss through convexity.},
	language = {en},
	author = {Wang, Yifei and Lacotte, Jonathan and Pilanci, Mert},
	year = {2022},
}

@article{marks_geometry_2023,
	title = {The geometry of truth: {Emergent} linear structure in large language model representations of true/false datasets},
	shorttitle = {The geometry of truth},
	abstract = {Large Language Models (LLMs) have impressive capabilities, but are also prone to outputting falsehoods. Recent work has developed techniques for inferring whether a LLM is telling the truth by training probes on the LLM’s internal activations. However, this line of work is controversial, with some authors pointing out failures of these probes to generalize in basic ways, among other conceptual issues. In this work, we curate high-quality datasets of true/false statements and use them to study in detail the structure of LLM representations of truth, drawing on three lines of evidence: 1. Visualizations of LLM true/false statement representations, which reveal clear linear structure. 2. Transfer experiments in which probes trained on one dataset generalize to different datasets. 3. Causal evidence obtained by surgically intervening in a LLM’s forward pass, causing it to treat false statements as true and vice versa. Overall, we present evidence that language models linearly represent the truth or falsehood of factual statements. We also introduce a novel technique, mass-mean probing, which generalizes better and is more causally implicated in model outputs than other probing techniques.},
	language = {en},
	journal = {arXiv preprint arXiv:2310.06824},
	author = {Marks, Samuel and Tegmark, Max},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence},
}

@inproceedings{gurnee_language_2024,
	title = {Language models represent space and time},
	abstract = {The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a coherent model of the data generating process—a world model. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual “space neurons” and “time neurons” that reliably encode spatial and temporal coordinates. Our analysis demonstrates that modern LLMs acquire structured knowledge about fundamental dimensions such as space and time, supporting the view that they learn not merely superficial statistics, but literal world models.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Gurnee, Wes and Tegmark, Max},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{hendrycks_overview_2023,
	title = {An overview of catastrophic {AI} risks},
	abstract = {Rapid advancements in artificial intelligence (AI) have sparked growing concerns among experts, policymakers, and world leaders regarding the potential for increasingly advanced AI systems to pose catastrophic risks. Although numerous risks have been detailed separately, there is a pressing need for a systematic discussion and illustration of the potential dangers to better inform efforts to mitigate them. This paper provides an overview of the main sources of catastrophic AI risks, which we organize into four categories: malicious use, in which individuals or groups intentionally use AIs to cause harm; AI race, in which competitive environments compel actors to deploy unsafe AIs or cede control to AIs; organizational risks, highlighting how human factors and complex systems can increase the chances of catastrophic accidents; and rogue AIs, describing the inherent difficulty in controlling agents far more intelligent than humans. For each category of risk, we describe specific hazards, present illustrative stories, envision ideal scenarios, and propose practical suggestions for mitigating these dangers. Our goal is to foster a comprehensive understanding of these risks and inspire collective and proactive efforts to ensure that AIs are developed and deployed in a safe manner. Ultimately, we hope this will allow us to realize the benefits of this powerful technology while minimizing the potential for catastrophic outcomes.},
	language = {en},
	journal = {arXiv preprint arXiv:2306.12001},
	author = {Hendrycks, Dan and Mazeika, Mantas and Woodside, Thomas},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
}

@article{nanda_emergent_2023,
	title = {Emergent linear representations in world models of self-supervised sequence models},
	abstract = {How do sequence models represent their decision-making process? Prior work suggests that Othello-playing neural network learned nonlinear models of the board state (Li et al., 2023). In this work, we provide evidence of a closely related linear representation of the board. In particular, we show that probing for "my colour" vs. "opponent's colour" may be a simple yet powerful way to interpret the model's internal state. This precise understanding of the internal representations allows us to control the model's behaviour with simple vector arithmetic. Linear representations enable significant interpretability progress, which we demonstrate with further exploration of how the world model is computed.},
	language = {en},
	journal = {arXiv preprint arXiv:2309.00941},
	author = {Nanda, Neel and Lee, Andrew and Wattenberg, Martin},
	year = {2023},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{mikolov_linguistic_2013,
	title = {Linguistic regularities in continuous space word representations},
	booktitle = {Proceedings of the 2013 conference of the north american chapter of the association for computational linguistics: {Human} language technologies},
	author = {Mikolov, Tomáš and Yih, Wen-tau and Zweig, Geoffrey},
	year = {2013},
	pages = {746--751},
}

@inproceedings{li_emergent_2023,
	title = {Emergent world representations: {Exploring} a sequence model trained on a synthetic task},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Li, Kenneth and Hopkins, Aspen K and Bau, David},
	year = {2023},
}

@inproceedings{collins_maml_2022,
	title = {{MAML} and {ANIL} provably learn representations},
	abstract = {Recent empirical evidence has driven conventional wisdom to believe that gradient-based metalearning (GBML) methods perform well at fewshot learning because they learn an expressive data representation that is shared across tasks. However, the mechanics of GBML have remained largely mysterious from a theoretical perspective. In this paper, we prove that two well-known GBML methods, MAML and ANIL, as well as their ﬁrst-order approximations, are capable of learning common representation among a set of given tasks. Speciﬁcally, in the well-known multitask linear representation learning setting, they are able to recover the ground-truth representation at an exponentially fast rate. Moreover, our analysis illuminates that the driving force causing MAML and ANIL to recover the underlying representation is that they adapt the ﬁnal layer of their model, which harnesses the underlying task diversity to improve the representation in all directions of interest. To the best of our knowledge, these are the ﬁrst results to show that MAML and/or ANIL learn expressive representations and to rigorously explain why they do so.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Collins, Liam and Mokhtari, Aryan and Oh, Sewoong and Shakkottai, Sanjay},
	year = {2022},
	pages = {4238--4310},
}

@inproceedings{merullo_linearly_2022,
	title = {Linearly mapping from image to text space},
	abstract = {The extent to which text-only language models (LMs) learn to represent the physical, non-linguistic world is an open question. Prior work has shown that pretrained LMs can be taught to ``understand'' visual inputs when the models' parameters are updated on image captioning tasks. We test a stronger hypothesis: that the conceptual representations learned by text-only models are functionally equivalent (up to a linear transformation) to those learned by models trained on vision tasks. Specifically, we show that the image representations from vision models can be transferred as continuous prompts to frozen LMs by training only a single linear projection. Using these to prompt the LM achieves competitive performance on captioning and visual question answering tasks compared to models that tune both the image encoder and text decoder (such as the MAGMA model). We compare three image encoders with increasing amounts of linguistic supervision seen during pretraining: BEIT (no linguistic information), NF-ResNET (lexical category information), and CLIP (full natural language descriptions). We find that all three encoders perform equally well at transferring visual property information to the language model (e.g., whether an animal is large or small), but that image encoders pretrained with linguistic supervision more saliently encode category information (e.g., distinguishing hippo vs.{\textbackslash} elephant) and thus perform significantly better on benchmark language-and-vision tasks. Our results indicate that LMs encode conceptual information structurally similarly to vision-based models, even those that are solely trained on images.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Merullo, Jack and Castricato, Louis and Eickhoff, Carsten and Pavlick, Ellie},
	year = {2022},
}

@inproceedings{chen_generative_2020,
	title = {Generative pretraining from pixels},
	abstract = {Inspired by progress in unsupervised representation learning for natural language, we examine whether similar models can learn useful representations for images. We train a sequence Transformer to auto-regressively predict pixels, without incorporating knowledge of the 2D input structure. Despite training on low-resolution ImageNet without labels, we ﬁnd that a GPT-2 scale model learns strong image representations as measured by linear probing, ﬁne-tuning, and low-data classiﬁcation. On CIFAR-10, we achieve 96.3\% accuracy with a linear probe, outperforming a supervised Wide ResNet, and 99.0\% accuracy with full ﬁne-tuning, matching the top supervised pretrained models. We are also competitive with self-supervised benchmarks on ImageNet when substituting pixels for a VQVAE encoding, achieving 69.0\% top-1 accuracy on a linear probe of our features.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeff and Jun, Heewoo and Luan, David and Sutskever, Ilya},
	year = {2020},
	pages = {1691--1703},
}

@inproceedings{negrea_defense_2020,
	title = {In defense of uniform convergence: {Generalization} via derandomization with an application to interpolating predictors},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Negrea, Jeffrey and Dziugaite, Gintare Karolina and Roy, Daniel},
	year = {2020},
	pages = {7263--7272},
}

@article{belinkov_probing_2022,
	title = {Probing classifiers: {Promises}, shortcomings, and advances},
	volume = {48},
	issn = {0891-2017, 1530-9312},
	shorttitle = {Probing classifiers},
	doi = {10.1162/coli_a_00422},
	abstract = {Abstract
            Probing classifiers have emerged as one of the prominent methodologies for interpreting and analyzing deep neural network models of natural language processing. The basic idea is simple—a classifier is trained to predict some linguistic property from a model’s representations—and has been used to examine a wide variety of models and properties. However, recent studies have demonstrated various methodological limitations of this approach. This squib critically reviews the probing classifiers framework, highlighting their promises, shortcomings, and advances.},
	language = {en},
	number = {1},
	journal = {Computational Linguistics},
	author = {Belinkov, Yonatan},
	year = {2022},
	pages = {207--219},
}

@article{zong_fool_2023,
	title = {Fool your (vision and) language model with embarrassingly simple permutations},
	abstract = {Large language and vision-language models are rapidly being deployed in practice thanks to their impressive capabilities in instruction following, in-context learning, and so on. This raises an urgent need to carefully analyse their robustness so that stakeholders can understand if and when such models are trustworthy enough to be relied upon in any given application. In this paper, we highlight a specific vulnerability in popular models, namely permutation sensitivity in multiple-choice question answering (MCQA). Specifically, we show empirically that popular models are vulnerable to adversarial permutation in answer sets for multiple-choice prompting, which is surprising as models should ideally be as invariant to prompt permutation as humans are. These vulnerabilities persist across various model sizes, and exist in very recent language and vision-language models. Code is available at https://github.com/ys-zong/FoolyourVLLMs.},
	language = {en},
	journal = {arXiv preprint arXiv:2310.01651},
	author = {Zong, Yongshuo and Yu, Tingyang and Zhao, Bingchen and Chavhan, Ruchika and Hospedales, Timothy},
	year = {2023},
	keywords = {Computer Science - Machine Learning},
}

@article{lake_human-like_2023,
	title = {Human-like systematic generalization through a meta-learning neural network},
	issn = {0028-0836, 1476-4687},
	doi = {10.1038/s41586-023-06668-3},
	abstract = {The power of human language and thought arises from systematic compositionality—the algebraic ability to understand and produce novel combinations from known components. Fodor and Pylyshyn famously argued that artificial neural networks lack this capacity and are therefore not viable models of the mind. Neural networks have advanced considerably in the years since, yet the systematicity challenge persists. Here we successfully address Fodor and Pylyshyn’s challenge by providing evidence that neural networks can achieve human-like systematicity when optimized for their compositional skills. To do so, we introduce the meta-learning for compositionality (MLC) approach for guiding training through a dynamic stream of compositional tasks. To compare humans and machines, we conducted human behavioural experiments using an instruction learning paradigm. After considering seven different models, we found that, in contrast to perfectly systematic but rigid probabilistic symbolic models, and perfectly flexible but unsystematic neural networks, only MLC achieves both the systematicity and flexibility needed for human-like generalization. MLC also advances the compositional skills of machine learning systems in several systematic generalization benchmarks. Our results show how a standard neural network architecture, optimized for its compositional skills, can mimic human systematic generalization in a head-to-head comparison.},
	language = {en},
	journal = {Nature},
	author = {Lake, Brenden M. and Baroni, Marco},
	year = {2023},
}

@article{kaplan_scaling_2020,
	title = {Scaling laws for neural language models},
	abstract = {We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overﬁtting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a ﬁxed compute budget. Larger models are signiﬁcantly more sampleefﬁcient, such that optimally compute-efﬁcient training involves training very large models on a relatively modest amount of data and stopping signiﬁcantly before convergence.},
	language = {en},
	journal = {arXiv preprint arXiv:2001.08361},
	author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{biderman_pythia_2023,
	title = {Pythia: {A} suite for analyzing large language models across training and scaling},
	volume = {2397-2430},
	abstract = {How do large language models (LLMs) develop and evolve over the course of training? How do these patterns change as models scale? To answer these questions, we introduce Pythia, a suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters. We provide public access to 154 checkpoints for each one of the 16 models, alongside tools to download and reconstruct their exact training dataloaders for further study. We intend Pythia to facilitate research in many areas, and we present several case studies including novel results in memorization, term frequency effects on few-shot performance, and reducing gender bias. We demonstrate that this highly controlled setup can be used to yield novel insights toward LLMs and their training dynamics. Trained models, analysis code, training code, and training data can be found at https: //github.com/EleutherAI/pythia.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin and Bradley, Herbie and O'Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and Skowron, Aviya and Sutawika, Lintang},
	year = {2023},
}

@article{schick_its_2021,
	title = {It's not just size that matters: {Small} language models are also few-shot learners},
	shorttitle = {It's not just size that matters},
	abstract = {When scaled to hundreds of billions of parameters, pretrained language models such as GPT-3 (Brown et al., 2020) achieve remarkable few-shot performance. However, enormous amounts of compute are required for training and applying such big models, resulting in a large carbon footprint and making it difficult for researchers and practitioners to use them. We show that performance similar to GPT-3 can be obtained with language models that are much "greener" in that their parameter count is several orders of magnitude smaller. This is achieved by converting textual inputs into cloze questions that contain a task description, combined with gradient-based optimization; exploiting unlabeled data gives further improvements. We identify key factors required for successful natural language understanding with small language models.},
	language = {en},
	journal = {arXiv preprint arXiv:2009.07118},
	author = {Schick, Timo and Schütze, Hinrich},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{wang_learning_2022-1,
	address = {New Orleans, LA, USA},
	title = {Learning to prompt for continual learning},
	isbn = {978-1-66546-946-3},
	doi = {10.1109/CVPR52688.2022.00024},
	abstract = {The mainstream paradigm behind continual learning has been to adapt the model parameters to non-stationary data distributions, where catastrophic forgetting is the central challenge. Typical methods rely on a rehearsal buffer or known task identity at test time to retrieve learned knowledge and address forgetting, while this work presents a new paradigm for continual learning that aims to train a more succinct memory system without accessing task identity at test time. Our method learns to dynamically prompt (L2P) a pre-trained model to learn tasks sequentially under different task transitions. In our proposed framework, prompts are small learnable parameters, which are maintained in a memory space. The objective is to optimize prompts to instruct the model prediction and explicitly manage task-invariant and task-speciﬁc knowledge while maintaining model plasticity. We conduct comprehensive experiments under popular image classiﬁcation benchmarks with different challenging continual learning settings, where L2P consistently outperforms prior state-ofthe-art methods. Surprisingly, L2P achieves competitive results against rehearsal-based methods even without a rehearsal buffer and is directly applicable to challenging taskagnostic continual learning. Source code is available at https://github.com/google- research/l2p.},
	language = {en},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Wang, Zifeng and Zhang, Zizhao and Lee, Chen-Yu and Zhang, Han and Sun, Ruoxi and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and Pfister, Tomas},
	year = {2022},
	pages = {139--149},
}

@article{jiang_transferability_2022-1,
	title = {Transferability in deep learning: {A} survey},
	shorttitle = {Transferability in deep learning},
	abstract = {The success of deep learning algorithms generally depends on large-scale data, while humans appear to have inherent ability of knowledge transfer, by recognizing and applying relevant knowledge from previous learning experiences when encountering and solving unseen tasks. Such an ability to acquire and reuse knowledge is known as transferability in deep learning. It has formed the long-term quest towards making deep learning as data-eﬃcient as human learning, and has been motivating fruitful design of more powerful deep learning algorithms. We present this survey to connect diﬀerent isolated areas in deep learning with their relation to transferability, and to provide a uniﬁed and complete view to investigating transferability through the whole lifecycle of deep learning. The survey elaborates the fundamental goals and challenges in parallel with the core principles and methods, covering recent cornerstones in deep architectures, pre-training, task adaptation and domain adaptation. This highlights unanswered questions on the appropriate objectives for learning transferable knowledge and for adapting the knowledge to new tasks and domains, avoiding catastrophic forgetting and negative transfer. Finally, we implement a benchmark and an open-source library, enabling a fair evaluation of deep learning methods in terms of transferability.},
	language = {en},
	journal = {arXiv preprint arXiv:2201.05867},
	author = {Jiang, Junguang and Shu, Yang and Wang, Jianmin and Long, Mingsheng},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@article{ngo_alignment_2023,
	title = {The alignment problem from a deep learning perspective},
	abstract = {In coming decades, artiﬁcial general intelligence (AGI) may surpass human capabilities at many critical tasks. We argue that, without substantial effort to prevent it, AGIs could learn to pursue goals that conﬂict (i.e., are misaligned) with human interests. If trained like today’s most capable models, AGIs could learn to act deceptively to receive higher reward, learn internally-represented goals which generalize beyond their ﬁnetuning distributions, and pursue those goals using power-seeking strategies. We review emerging evidence for these properties. AGIs with these properties would be difﬁcult to align and may appear aligned even when they are not. We outline how the deployment of misaligned AGIs might irreversibly undermine human control over the world, and brieﬂy review research directions aimed at preventing this outcome.},
	language = {en},
	journal = {arXiv preprint arXiv:2209.00626},
	author = {Ngo, Richard and Chan, Lawrence and Mindermann, Sören},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{malladi_fine-tuning_2023,
	title = {Fine-tuning language models with just forward passes},
	abstract = {Fine-tuning language models (LMs) has yielded success on diverse downstream tasks, but as LMs grow in size, backpropagation requires a prohibitively large amount of memory. Zeroth-order (ZO) methods can in principle estimate gradients using only two forward passes but are theorized to be catastrophically slow for optimizing large models. In this work, we propose a memory-efficient zerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operate in-place, thereby fine-tuning LMs with the same memory footprint as inference. For example, with a single A100 80GB GPU, MeZO can train a 30-billion parameter model, whereas fine-tuning with backpropagation can train only a 2.7B LM with the same budget. We conduct comprehensive experiments across model types (masked and autoregressive LMs), model scales (up to 66B), and downstream tasks (classification, multiple-choice, and generation). Our results demonstrate that (1) MeZO significantly outperforms in-context learning and linear probing; (2) MeZO achieves comparable performance to fine-tuning with backpropagation across multiple tasks, with up to 12x memory reduction; (3) MeZO is compatible with both full-parameter and parameter-efficient tuning techniques such as LoRA and prefix tuning; (4) MeZO can effectively optimize non-differentiable objectives (e.g., maximizing accuracy or F1). We support our empirical findings with theoretical insights, highlighting how adequate pre-training and task prompts enable MeZO to fine-tune huge models, despite classical ZO analyses suggesting otherwise.},
	language = {en},
	journal = {arXiv preprint arXiv:2305.17333},
	author = {Malladi, Sadhika and Gao, Tianyu and Nichani, Eshaan and Damian, Alex and Lee, Jason D. and Chen, Danqi and Arora, Sanjeev},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{panigrahi_task-specific_2023,
	title = {Task-specific skill localization in fine-tuned language models},
	abstract = {Pre-trained language models can be fine-tuned to solve diverse NLP tasks, including in few-shot settings. Thus fine-tuning allows the model to quickly pick up task-specific “skills,” but there has been limited study of where these newlylearnt skills reside inside the massive model. This paper introduces the term skill localization for this problem and proposes a solution. Given the downstream task and a model fine-tuned on that task, a simple optimization is used to identify a very small subset of parameters (∼ 0.01\% of model parameters) responsible for ({\textgreater} 95\%) of the model’s performance, in the sense that grafting the fine-tuned values for just this tiny subset onto the pre-trained model gives a performance almost as well as the fine-tuned model. While reminiscent of recent works on parameter-efficient fine-tuning, the novel aspects here are that: (i) No further re-training is needed on the subset (unlike, say, with lottery tickets). (ii) Notable improvements are seen over vanilla fine-tuning with respect to calibration of predictions in-distribution (40-90\% error reduction) as well as the quality of predictions out-of-distribution (OOD). In models trained on multiple tasks, a stronger notion of skill localization is observed, where the sparse regions corresponding to different tasks are almost disjoint, and their overlap (when it happens) is a proxy for task similarity. Experiments suggest that localization via grafting can assist certain forms of continual learning. Our code is available at Skill-Localization-by-grafting1.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Panigrahi, Abhishek and Saunshi, Nikunj and Zhao, Haoyu and Arora, Sanjeev},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{he_towards_2022,
	title = {Towards a unified view of parameter-efficient transfer learning},
	abstract = {Fine-tuning large pre-trained language models on downstream tasks has become the de-facto learning paradigm in NLP. However, conventional approaches fine-tune all the parameters of the pre-trained model, which becomes prohibitive as the model size and the number of tasks grow. Recent work has proposed a variety of parameter-efficient transfer learning methods that only fine-tune a small number of (extra) parameters to attain strong performance. While effective, the critical ingredients for success and the connections among the various methods are poorly understood. In this paper, we break down the design of state-of-the-art parameter-efficient transfer learning methods and present a unified framework that establishes connections between them. Specifically, we re-frame them as modifications to specific hidden states in pre-trained models, and define a set of design dimensions along which different methods vary, such as the function to compute the modification and the position to apply the modification. Through comprehensive empirical studies across machine translation, text summarization, language understanding, and text classification benchmarks, we utilize the unified view to identify important design choices in previous methods. Furthermore, our unified framework enables the transfer of design elements across different approaches, and as a result we are able to instantiate new parameter-efficient fine-tuning methods that tune less parameters than previous methods while being more effective, achieving comparable results to fine-tuning all parameters on all four tasks.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {He, Junxian and Zhou, Chunting and Ma, Xuezhe and Berg-Kirkpatrick, Taylor and Neubig, Graham},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@article{jiang_latent_2023,
	title = {A latent space theory for emergent abilities in large language models},
	abstract = {Languages are not created randomly but rather to communicate information. There is a strong association between languages and their underlying meanings, resulting in a sparse joint distribution that is heavily peaked according to their correlations. Moreover, these peak values happen to match with the marginal distribution of languages due to the sparsity. With the advent of LLMs trained on big data and large models, we can now precisely assess the marginal distribution of languages, providing a convenient means of exploring the sparse structures in the joint distribution for effective inferences. In this paper, we categorize languages as either unambiguous or ε-ambiguous and present quantitative results to demonstrate that the emergent abilities of LLMs, such as language understanding, in-context learning, chain-of-thought prompting, and effective instruction fine-tuning, can all be attributed to Bayesian inference on the sparse joint distribution of languages.},
	language = {en},
	journal = {arXiv preprint arXiv:2304.09960},
	author = {Jiang, Hui},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{ge_provable_2023,
	title = {On the provable advantage of unsupervised pretraining},
	abstract = {Unsupervised pretraining, which learns a useful representation using a large amount of unlabeled data to facilitate the learning of downstream tasks, is a critical component of modern large-scale machine learning systems. Despite its tremendous empirical success, the rigorous theoretical understanding of why unsupervised pretraining generally helps remains rather limited—most existing results are restricted to particular methods or approaches for unsupervised pretraining with specialized structural assumptions. This paper studies a generic framework, where the unsupervised representation learning task is speciﬁed by an abstract class of latent variable models Φ and the downstream task is speciﬁed by a class of prediction functions Ψ. We consider a natural approach of using Maximum Likelihood Estimation (MLE) for unsupervised pretraining and Empirical Risk Minimization (ERM) for learning downstream tasks. We prove that, under a mild “informative” condition, our algorithm achieves an excess risk of O˜( CΦ/m + CΨ/n) for downstream tasks, where CΦ, CΨ are complexity measures of function classes Φ, Ψ, and m, n are the number of unlabeled and labeled data respectively. Comparing to the baseline of O˜( CΦ◦Ψ/n) achieved by performing supervised learning using only the labeled data, our result rigorously shows the beneﬁt of unsupervised pretraining when m ≫ n and CΦ◦Ψ {\textgreater} CΨ. This paper further shows that our generic framework covers a wide range of approaches for unsupervised pretraining, including factor models, Gaussian mixture models, and contrastive learning.},
	language = {en},
	journal = {arXiv preprint arXiv:2303.01566},
	author = {Ge, Jiawei and Tang, Shange and Fan, Jianqing and Jin, Chi},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Statistics Theory},
}

@article{zhang_inductive_2021,
	title = {On the inductive bias of masked language modeling: {From} statistical to syntactic dependencies},
	shorttitle = {On the inductive bias of masked language modeling},
	abstract = {We study how masking and predicting tokens in an unsupervised fashion can give rise to linguistic structures and downstream performance gains. Recent theories have suggested that pretrained language models acquire useful inductive biases through masks that implicitly act as cloze reductions. While appealing, we show that the success of the random masking strategy used in practice cannot be explained by such cloze-like masks alone. We construct cloze-like masks using task-speciﬁc lexicons for three different classiﬁcation datasets and show that the majority of pretrained performance gains come from generic masks that are not associated with the lexicon. To explain the empirical success of these generic masks, we demonstrate a correspondence between the masked language model (MLM) objective and existing methods for learning statistical dependencies in graphical models. Using this, we derive a method for extracting these learned statistical dependencies in MLMs and show that these dependencies encode useful inductive biases in the form of syntactic structures. In an unsupervised parsing evaluation, simply forming a minimum spanning tree on the implied statistical dependence structure outperforms a classic method for unsupervised parsing (58.74 vs. 55.91 UUAS).},
	language = {en},
	journal = {arXiv preprint arXiv:2104.05694},
	author = {Zhang, Tianyi and Hashimoto, Tatsunori},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{saunshi_mathematical_2021,
	title = {A mathematical exploration of why language models help solve downstream tasks},
	abstract = {Autoregressive language models, pretrained using large text corpora to do well on next word prediction, have been successful at solving many downstream tasks, even with zero-shot usage. However, there is little theoretical understanding of this success. This paper initiates a mathematical study of this phenomenon for the downstream task of text classiﬁcation by considering the following questions: (1) What is the intuitive connection between the pretraining task of next word prediction and text classiﬁcation? (2) How can we mathematically formalize this connection and quantify the beneﬁt of language modeling? For (1), we hypothesize, and verify empirically, that classiﬁcation tasks of interest can be reformulated as sentence completion tasks, thus making language modeling a meaningful pretraining task. With a mathematical formalization of this hypothesis, we make progress towards (2) and show that language models that are -optimal in c√ross-entropy (log-perplexity) learn features that can linearly solve such classiﬁcation tasks with O( ) error, thus demonstrating that doing well on language modeling can be beneﬁcial for downstream tasks. We experimentally verify various assumptions and theoretical ﬁndings, and also use insights from the analysis to design a new objective function that performs well on some classiﬁcation tasks.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Saunshi, Nikunj and Malladi, Sadhika and Arora, Sanjeev},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{wei_why_2021,
	title = {Why do pretrained language models help in downstream tasks? {An} analysis of head and prompt tuning},
	volume = {34},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wei, Colin and Xie, Sang Michael and Ma, Tengyu},
	year = {2021},
	pages = {16158--16170},
}

@inproceedings{malladi_kernel-based_2023,
	title = {A kernel-based view of language model fine-tuning},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Malladi, Sadhika and Wettig, Alexander and Yu, Dingli and Chen, Danqi and Arora, Sanjeev},
	year = {2023},
	pages = {23610--23641},
}

@article{zhang_what_2023,
	title = {What and how does in-context learning learn? {Bayesian} model averaging, parameterization, and generalization},
	shorttitle = {What and how does in-context learning learn?},
	abstract = {In this paper, we conduct a comprehensive study of In-Context Learning (ICL) by addressing several open questions: (a) What type of ICL estimator is learned by large language models? (b) What is a proper performance metric for ICL and what is the error rate? (c) How does the transformer architecture enable ICL? To answer these questions, we adopt a Bayesian view and formulate ICL as a problem of predicting the response corresponding to the current covariate, given a number of examples drawn from a latent variable model. To answer (a), we show that, without updating the neural network parameters, ICL implicitly implements the Bayesian model averaging algorithm, which is proven to be approximately parameterized by the attention mechanism. For (b), we analyze the ICL performance from an online learning perspective and establish a O(1/T ) regret bound for perfectly pretrained ICL, where T is the number of examples in the prompt. To answer (c), we show that, in addition to encoding Bayesian model averaging via attention, the transformer architecture also enables a ﬁne-grained statistical analysis of pretraining under realistic assumptions. In particular, we prove that the error of pretrained model is bounded by a sum of an approximation error and a generalization error, where the former decays to zero exponentially as the depth grows, and the latter decays to zero sublinearly with the number of tokens in the pretraining dataset. Our results provide a uniﬁed understanding of the transformer and its ICL ability with bounds on ICL regret, approximation, and generalization, which deepens our knowledge of these essential aspects of modern language models.},
	language = {en},
	journal = {arXiv preprint arXiv:2305.19420},
	author = {Zhang, Yufeng and Zhang, Fengzhuo and Yang, Zhuoran and Wang, Zhaoran},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{zhang_analysis_2023,
	title = {An analysis of attention via the lens of exchangeability and latent variable models},
	abstract = {With the attention mechanism, transformers achieve signiﬁcant empirical successes in natural language processing and computer vision. Despite the intuitive understanding that transformers perform relational inference (or “inductive reasoning”) over long sequences to produce desirable representations, we lack a rigorous theory on how the attention mechanism achieves it. In particular, several intriguing questions remain open: (a) What makes a desirable representation? (b) How does the attention mechanism infer the desirable representation within the forward pass? (c) How does a pretraining procedure learn to infer the desirable representation through the backward pass? We aim to answer the three questions via the lens of exchangeability. Specifically, we observe that, as is the case in BERT and ViT, input tokens are often exchangeable since they already include positional encodings. The notion of exchangeability induces a latent variable model that is invariant to input sizes, which enables our theoretical analysis.},
	language = {en},
	journal = {arXiv preprint arXiv:2212.14852},
	author = {Zhang, Yufeng and Liu, Boyi and Cai, Qi and Wang, Lingxiao and Wang, Zhaoran},
	year = {2023},
	keywords = {Computer Science - Machine Learning},
}

@article{esser_representation_2023,
	title = {Representation learning dynamics of self-supervised models},
	abstract = {Self-Supervised Learning (SSL) is an important paradigm for learning representations from unlabelled data, and SSL with neural networks has been highly successful in practice. However current theoretical analysis of SSL is mostly restricted to generalisation error bounds. In contrast, learning dynamics often provide a precise characterisation of the behaviour of neural networks based models but, so far, are mainly known in supervised settings. In this paper, we study the learning dynamics of SSL models, specifically representations obtained by minimising contrastive and non-contrastive losses. We show that a na¨ive extension of the dymanics of multivariate regression to SSL leads to learning trivial scalar representations that demonstrates dimension collapse in SSL. Consequently, we formulate SSL objectives with orthogonality constraints on the weights, and derive the exact (network width independent) learning dynamics of the SSL models trained using gradient descent on the Grassmannian manifold. We also argue that the infinite width approximation of SSL models significantly deviate from the neural tangent kernel approximations of supervised models. We numerically illustrate the validity of our theoretical findings, and discuss how the presented results provide a framework for further theoretical analysis of contrastive and non-contrastive SSL.},
	language = {en},
	journal = {arXiv preprint arXiv:2309.02011},
	author = {Esser, Pascal and Mukherjee, Satyaki and Ghoshdastidar, Debarghya},
	year = {2023},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{lee_predicting_2021,
	title = {Predicting what you already know helps: {Provable} self-supervised learning},
	volume = {34},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lee, Jason D. and Lei, Qi and Saunshi, Nikunj and Zhuo, Jiacheng},
	year = {2021},
	pages = {309--323},
}

@inproceedings{lester_power_2021,
	title = {The power of scale for parameter-efficient prompt tuning},
	abstract = {In this work, we explore "prompt tuning", a simple yet effective mechanism for learning "soft prompts" to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signal from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3's "few-shot" learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method "closes the gap" and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant in that large models are costly to share and serve, and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed "prefix tuning" of Li and Liang (2021), and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer, as compared to full model tuning.},
	language = {en},
	booktitle = {{EMNLP}},
	author = {Lester, Brian and Al-Rfou, Rami and Constant, Noah},
	year = {2021},
	keywords = {Computer Science - Computation and Language},
}

@article{liu_gpt_2023,
	title = {{GPT} understands, too},
	issn = {26666510},
	doi = {10.1016/j.aiopen.2023.08.012},
	language = {en},
	journal = {AI Open},
	author = {Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
	year = {2023},
	pages = {S2666651023000141},
}

@article{li_prefix-tuning_2021,
	title = {Prefix-tuning: {Optimizing} continuous prompts for generation},
	shorttitle = {Prefix-tuning},
	abstract = {Fine-tuning is the de facto way to leverage large pretrained language models to perform downstream tasks. However, it modiﬁes all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose preﬁx-tuning, a lightweight alternative to ﬁne-tuning for natural language generation tasks, which keeps language model parameters frozen, but optimizes a small continuous task-speciﬁc vector (called the preﬁx). Preﬁx-tuning draws inspiration from prompting, allowing subsequent tokens to attend to this preﬁx as if it were “virtual tokens”. We apply preﬁx-tuning to GPT-2 for table-to-text generation and to BART for summarization. We ﬁnd that by learning only 0.1\% of the parameters, preﬁx-tuning obtains comparable performance in the full data setting, outperforms ﬁne-tuning in low-data settings, and extrapolates better to examples with topics unseen during training.},
	language = {en},
	journal = {arXiv preprint arXiv:2101.00190},
	author = {Li, Xiang Lisa and Liang, Percy},
	year = {2021},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{ridnik_imagenet-21k_2021,
	title = {{ImageNet}-21k pretraining for the masses},
	abstract = {ImageNet-1K serves as the primary dataset for pretraining deep learning models for computer vision tasks. ImageNet-21K dataset, which is bigger and more diverse, is used less frequently for pretraining, mainly due to its complexity, low accessibility, and underestimation of its added value. This paper aims to close this gap, and make high-quality efficient pretraining on ImageNet-21K available for everyone. Via a dedicated preprocessing stage, utilization of WordNet hierarchical structure, and a novel training scheme called semantic softmax, we show that various models significantly benefit from ImageNet-21K pretraining on numerous datasets and tasks, including small mobile-oriented models. We also show that we outperform previous ImageNet-21K pretraining schemes for prominent new models like ViT and Mixer. Our proposed pretraining pipeline is efficient, accessible, and leads to SoTA reproducible results, from a publicly available dataset. The training code and pretrained models are available at: https://github.com/Alibaba-MIIL/ImageNet21K},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ridnik, Tal and Ben-Baruch, Emanuel and Noy, Asaf and Zelnik-Manor, Lihi},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{huang_modality_2022,
	title = {Modality competition: {What} makes joint training of multi-modal network fail in deep learning? (provably)},
	abstract = {Despite the remarkable success of deep multimodal learning in practice, it has not been wellexplained in theory. Recently, it has been observed that the best uni-modal network outperforms the jointly trained multi-modal network , which is counter-intuitive since multiple signals generally bring more information (Wang et al., 2020). This work provides a theoretical explanation for the emergence of such performance gap in neural networks for the prevalent joint training framework. Based on a simplified data distribution that captures the realistic property of multimodal data, we prove that for the multi-modal late-fusion network with (smoothed) ReLU activation trained jointly by gradient descent, different modalities will compete with each other. The encoder networks will learn only a subset of modalities. We refer to this phenomenon as modality competition. The losing modalities, which fail to be discovered, are the origins where the suboptimality of joint training comes from. Experimentally, we illustrate that modality competition matches the intrinsic behavior of late-fusion joint training.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Huang, Yu and Lin, Junyang},
	year = {2022},
}

@article{yadlowsky_pretraining_2023,
	title = {Pretraining data mixtures enable narrow model selection capabilities in transformer models},
	abstract = {Transformer models, notably large language models (LLMs), have the remarkable ability to perform in-context learning (ICL) – to perform new tasks when prompted with unseen inputoutput examples without any explicit model training. In this work, we study how effectively transformers can bridge between their pretraining data mixture, comprised of multiple distinct task families, to identify and learn new tasks in-context which are both inside and outside the pretraining distribution. Building on previous work, we investigate this question in a controlled setting, where we study transformer models trained on sequences of (x, f (x)) pairs rather than natural language. Our empirical results show transformers demonstrate near-optimal unsupervised model selection capabilities, in their ability to first in-context identify different task families and in-context learn within them when the task families are well-represented in their pretraining data. However when presented with tasks or functions which are out-of-domain of their pretraining data, we demonstrate various failure modes of transformers and degradation of their generalization for even simple extrapolation tasks. Together our results highlight that the impressive ICL abilities of high-capacity sequence models may be more closely tied to the coverage of their pretraining data mixtures than inductive biases that create fundamental generalization capabilities.},
	language = {en},
	journal = {arXiv preprint arXiv:2311.00871},
	author = {Yadlowsky, Steve and Doshi, Lyric and Tripuraneni, Nilesh},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{pratt_what_2023,
	title = {What does a platypus look like? {Generating} customized prompts for zero-shot image classification},
	abstract = {Open-vocabulary models are a promising new paradigm for image classiﬁcation. Unlike traditional classiﬁcation models, open-vocabulary models classify among any arbitrary set of categories speciﬁed with natural language during inference. This natural language, called “prompts”, typically consists of a set of hand-written templates (e.g., “a photo of a \{\}”) which are completed with each of the category names. This work introduces a simple method to generate higher accuracy prompts, without relying on any explicit knowledge of the task domain and with far fewer hand-constructed sentences. To achieve this, we combine open-vocabulary models with large language models (LLMs) to create Customized Prompts via Language models (CuPL, pronounced “couple”). In particular, we leverage the knowledge contained in LLMs in order to generate many descriptive sentences that contain important discriminating characteristics of the image categories. This allows the model to place a greater importance on these regions in the image when making predictions. We ﬁnd that this straightforward and general approach improves accuracy on a range of zero-shot image classiﬁcation benchmarks, including over one percentage point gain on ImageNet. Finally, this simple baseline requires no additional training and remains completely zero-shot. Code available at https://github.com/sarahpratt/CuPL.},
	language = {en},
	booktitle = {Proceedings of the {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision}},
	author = {Pratt, Sarah and Covert, Ian and Liu, Rosanne and Farhadi, Ali},
	year = {2023},
	pages = {15691--15701},
}

@inproceedings{novack_chils_2023-1,
	title = {{CHiLS}: {Zero}-shot image classification with hierarchical label sets},
	abstract = {Open vocabulary models (e.g. CLIP) have shown strong performance on zero-shot classification through their ability generate embeddings for each class based on their (natural language) names. Prior work has focused on improving the accuracy of these models through prompt engineering or by incorporating a small amount of labeled downstream data (via finetuning). However, there has been little focus on improving the richness of the class names themselves, which can pose issues when class labels are coarsely-defined and are uninformative. We propose Classification with Hierarchical Label Sets (or CHiLS), an alternative strategy for zero-shot classification specifically designed for datasets with implicit semantic hierarchies. CHiLS proceeds in three steps: (i) for each class, produce a set of subclasses, using either existing label hierarchies or by querying GPT-3; (ii) perform the standard zero-shot CLIP procedure as though these subclasses were the labels of interest; (iii) map the predicted subclass back to its parent to produce the final prediction. Across numerous datasets with underlying hierarchical structure, CHiLS leads to improved accuracy in situations both with and without ground-truth hierarchical information. CHiLS is simple to implement within existing zero-shot pipelines and requires no additional training cost. Code is available at: https://github.com/ acmi-lab/CHILS.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Novack, Zachary and McAuley, Julian and Lipton, Zachary and Garg, Saurabh},
	year = {2023},
	pages = {26342--26362},
}

@inproceedings{zheng_revisiting_2023,
	title = {Revisiting discriminative vs. generative classifiers: {Theory} and implications},
	shorttitle = {Revisiting discriminative vs. generative classifiers},
	abstract = {A large-scale deep model pre-trained on massive labeled or unlabeled data transfers well to downstream tasks. Linear evaluation freezes parameters in the pre-trained model and trains a linear classifier separately, which is efficient and attractive for transfer. However, little work has investigated the classifier in linear evaluation except for the default logistic regression. Inspired by the statistical efficiency of naïve Bayes, the paper revisits the classical topic on discriminative vs. generative classifiers (Ng \& Jordan, 2001). Theoretically, the paper considers the surrogate loss instead of the zero-one loss in analyses and generalizes the classical results from binary cases to multiclass ones. We show that, under mild assumptions, multiclass naïve Bayes requires O(log n) samples to approach its asymptotic error while the corresponding multiclass logistic regression requires O(n) samples, where n is the feature dimension. To establish it, we present a multiclass H-consistency bound framework and an explicit bound for logistic loss, which are of independent interests. Simulation results on a mixture of Gaussian validate our theoretical findings. Experiments on various pre-trained deep vision models show that naïve Bayes consistently converges faster as the number of data increases. Besides, naïve Bayes shows promise in few-shot cases and we observe the “two regimes” phenomenon in pretrained supervised models. Our code is available at https://github.com/ML-GSAI/Revisiting-Dis-vsGen-Classifiers.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zheng, Chenyu and Wu, Guoqiang and Bao, Fan and Cao, Yue and Li, Chongxuan and Zhu, Jun},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{tosh_contrastive_2021,
	title = {Contrastive learning, multi-view redundancy, and linear models},
	isbn = {2640-3498},
	booktitle = {Algorithmic {Learning} {Theory}},
	author = {Tosh, Christopher and Krishnamurthy, Akshay and Hsu, Daniel},
	year = {2021},
	pages = {1179--1206},
}

@article{yuan_florence_2021,
	title = {Florence: {A} new foundation model for computer vision},
	shorttitle = {Florence},
	abstract = {Automated visual understanding of our diverse and open world demands computer vision models to generalize well with minimal customization for speciﬁc tasks, similar to human vision. Computer vision foundation models, which are trained on diverse, large-scale dataset and can be adapted to a wide range of downstream tasks, are critical for this mission to solve real-world computer vision applications. While existing vision foundation models such as CLIP (Radford et al., 2021), ALIGN (Jia et al., 2021), and Wu Dao 2.0 (Wud) focus mainly on mapping images and textual representations to a cross-modal shared representation, we introduce a new computer vision foundation model, Florence, to expand the representations from coarse (scene) to ﬁne (object), from static (images) to dynamic (videos), and from RGB to multiple modalities (caption, depth). By incorporating universal visual-language representations from Web-scale image-text data, our Florence model can be easily adapted for various computer vision tasks, such as classiﬁcation, retrieval, object detection, VQA, image caption, video retrieval and action recognition. Moreover, Florence demonstrates outstanding performance in many types of transfer learning: fully sampled ﬁne-tuning, linear probing, few-shot transfer and zero-shot transfer for novel images and objects. All of these properties are critical for our vision foundation model to serve general purpose vision tasks. Florence achieves new state-of-the-art results in majority of 44 representative benchmarks, e.g. ImageNet-1K zero-shot classiﬁcation with top-1 accuracy of 83.74 and the top-5 accuracy of 97.18, 62.4 mAP on COCO ﬁne tuning, 80.36 on VQA, and 87.8 on Kinetics-600.},
	language = {en},
	journal = {arXiv preprint arXiv:2111.11432},
	author = {Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and Liu, Ce and Liu, Mengchen and Liu, Zicheng and Lu, Yumao and Shi, Yu and Wang, Lijuan and Wang, Jianfeng and Xiao, Bin and Xiao, Zhen and Yang, Jianwei and Zeng, Michael and Zhou, Luowei and Zhang, Pengchuan},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{arpit_closer_2017,
	title = {A closer look at memorization in deep networks},
	abstract = {We examine the role of memorization in deep learning, drawing connections to capacity, generalization, and adversarial robustness. While deep networks are capable of memorizing noise data, our results suggest that they tend to prioritize learning simple patterns ﬁrst. In our experiments, we expose qualitative differences in gradient-based optimization of deep neural networks (DNNs) on noise vs. real data. We also demonstrate that for appropriately tuned explicit regularization (e.g., dropout) we can degrade DNN training performance on noise datasets without compromising generalization on real data. Our analysis suggests that the notions of effective capacity which are dataset independent are unlikely to explain the generalization performance of deep networks when trained with gradient based methods because training data itself plays an important role in determining the degree of memorization.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Arpit, Devansh and Jastrzebski, Stanisław and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and Lacoste-Julien, Simon},
	year = {2017},
	pages = {233--242},
}

@article{tarzanagh_transformers_2023,
	title = {Transformers as support vector machines},
	abstract = {Since its inception in “Attention Is All You Need”, the transformer architecture has led to revolutionary advancements in natural language processing. The attention layer within the transformer admits a sequence of input tokens X and makes them interact through pairwise similarities computed as softmax(XQK⊤ X⊤), where (K, Q) are the trainable key-query parameters. In this work, we establish a formal equivalence between the optimization geometry of self-attention and a hard-margin SVM problem that separates optimal input tokens from non-optimal tokens using linear constraints on the outer-products of token pairs. This formalism builds on [TLZO23] and allows us to characterize the implicit bias of 1-layer transformers optimized with gradient descent, as follows. (1) Optimizing the attention layer, parameterized by (K, Q), with vanishing regularization, converges in direction to an SVM solution minimizing the nuclear norm of the combined parameter W := KQ⊤. Instead, directly parameterizing by W minimizes a Frobenius norm SVM objective. We characterize this convergence, highlighting that it can occur in locally-optimal directions rather than global ones. (2) Complementing this, for W-parameterization, we prove the local/global directional convergence of gradient descent under suitable geometric conditions. Importantly, we show that over-parameterization catalyzes global convergence by ensuring the feasibility of the SVM problem and by guaranteeing a benign optimization landscape devoid of stationary points. (3) While our theory applies primarily to linear prediction heads, we propose a more general SVM equivalence that predicts the implicit bias of 1-layer transformers with nonlinear heads/MLPs. Our findings apply to general datasets, trivially extend to cross-attention layer, and their practical validity is verified via thorough numerical experiments. We also introduce open problems and future research directions. We believe these findings inspire a new perspective, interpreting multilayer transformers as a hierarchy of SVMs that separates and selects optimal tokens.},
	language = {en},
	journal = {arXiv preprint arXiv:2308.16898},
	author = {Tarzanagh, Davoud Ataee and Li, Yingcong and Thrampoulidis, Christos and Oymak, Samet},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Mathematics - Optimization and Control},
}

@article{deora_optimization_2023,
	title = {On the optimization and generalization of multi-head attention},
	abstract = {The training and generalization dynamics of the Transformer’s core mechanism, namely the Attention mechanism, remain under-explored. Besides, existing analyses primarily focus on singlehead attention. Inspired by the demonstrated benefits of overparameterization when training fullyconnected networks, we investigate the potential optimization and generalization advantages of using multiple attention heads. Towards this goal, we derive convergence and generalization guarantees for gradient-descent training of a single-layer multi-head self-attention model, under a suitable realizability condition on the data. We then establish primitive conditions on the initialization that ensure realizability holds. Finally, we demonstrate that these conditions are satisfied for a simple tokenized-mixture model. We expect the analysis can be extended to various data-model and architecture variations.},
	language = {en},
	journal = {arXiv preprint arXiv:2310.12680},
	author = {Deora, Puneesh and Ghaderi, Rouzbeh and Taheri, Hossein and Thrampoulidis, Christos},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
}

@inproceedings{richensrobust,
  title={Robust agents learn causal world models},
  author={Richens, Jonathan and Everitt, Tom},
  booktitle={ICLR},
  year= {2024}
}


@inproceedings{garg_leveraging_2022-1,
	title = {Leveraging unlabeled data to predict out-of-distribution performance},
	abstract = {Real-world machine learning deployments are characterized by mismatches between the source (training) and target (test) distributions that may cause performance drops. In this work, we investigate methods for predicting the target domain accuracy using only labeled source data and unlabeled target data. We propose Average Thresholded Conﬁdence (ATC), a practical method that learns a threshold on the model’s conﬁdence, predicting accuracy as the fraction of unlabeled examples for which model conﬁdence exceeds that threshold. ATC outperforms previous methods across several model architectures, types of distribution shifts (e.g., due to synthetic corruptions, dataset reproduction, or novel subpopulations), and datasets (WILDS, ImageNet, BREEDS, CIFAR, and MNIST). In our experiments, ATC estimates target performance 2–4ˆ more accurately than prior methods. We also explore the theoretical foundations of the problem, proving that, in general, identifying the accuracy is just as hard as identifying the optimal predictor and thus, the efﬁcacy of any method rests upon (perhaps unstated) assumptions on the nature of the shift. Finally, analyzing our method on some toy distributions, we provide insights concerning when it works1.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Garg, Saurabh and Balakrishnan, Sivaraman and Lipton, Zachary C. and Neyshabur, Behnam and Sedghi, Hanie},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{lu_are_2023,
	title = {Are emergent abilities in large language models just in-context learning?},
	abstract = {Large language models have exhibited emergent abilities, demonstrating exceptional performance across diverse tasks for which they were not explicitly trained, including those that require complex reasoning abilities. The emergence of such abilities carries profound implications for the future direction of research in NLP, especially as the deployment of such models becomes more prevalent. However, one key challenge is that the evaluation of these abilities is often confounded by competencies that arise in models through alternative prompting techniques, such as in-context learning and instruction following, which also emerge as the models are scaled up. In this study, we provide the first comprehensive examination of these emergent abilities while accounting for various potentially biasing factors that can influence the evaluation of models. We conduct rigorous tests on a set of 18 models, encompassing a parameter range from 60 million to 175 billion parameters, across a comprehensive set of 22 tasks. Through an extensive series of over 1,000 experiments, we provide compelling evidence that emergent abilities can primarily be ascribed to in-context learning. We find no evidence for the emergence of reasoning abilities, thus providing valuable insights into the underlying mechanisms driving the observed abilities and thus alleviating safety concerns regarding their use.},
	language = {en},
	journal = {arXiv preprint arXiv:2309.01809},
	author = {Lu, Sheng and Bigoulaeva, Irina and Sachdeva, Rachneet and Madabushi, Harish Tayyar and Gurevych, Iryna},
	year = {2023},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{noauthor_mechanistic_2023,
	title = {The mechanistic basis of data dependence and abrupt learning in an in-context classification task},
	abstract = {Transformer models exhibit in-context learning: the ability to accurately predict the response to a novel query based on illustrative examples in the input sequence, which contrasts with traditional in-weights learning of query-output relationships. What aspects of the training data distribution and architecture favor in-context vs in-weights learning? Recent work has shown that specific distributional properties inherent in language, such as burstiness, large dictionaries and skewed rank-frequency distributions, control the trade-off or simultaneous appearance of these two forms of learning. We first show that these results are recapitulated in a minimal attention-only network trained on a simplified dataset. In-context learning (ICL) is driven by the abrupt emergence of an induction head, which subsequently competes with in-weights learning. By identifying progress measures that precede in-context learning and targeted experiments, we construct a two-parameter model of an induction head which emulates the full data distributional dependencies displayed by the attention-based network. A phenomenological model of induction head formation traces its abrupt emergence to the sequential learning of three nested logits enabled by an intrinsic curriculum. We propose that the sharp transitions in attention-based networks arise due to a specific chain of multi-layer operations necessary to achieve ICL, which is implemented by nested nonlinearities sequentially learned during training.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	year = {2023},
}

@article{wang_interpretability_2022,
	title = {Interpretability in the wild: {A} circuit for indirect object identification in {GPT}-2 small},
	shorttitle = {Interpretability in the wild},
	abstract = {Research in mechanistic interpretability seeks to explain behaviors of machine learning (ML) models in terms of their internal components. However, most previous work either focuses on simple behaviors in small models or describes complicated behaviors in larger models with broad strokes. In this work, we bridge this gap by presenting an explanation for how GPT-2 small performs a natural language task called indirect object identiﬁcation (IOI). Our explanation encompasses 26 attention heads grouped into 7 main classes, which we discovered using a combination of interpretability approaches relying on causal interventions. To our knowledge, this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior “in the wild” in a language model. We evaluate the reliability of our explanation using three quantitative criteria–faithfulness, completeness and minimality. Though these criteria support our explanation, they also point to remaining gaps in our understanding. Our work provides evidence that a mechanistic understanding of large ML models is feasible, pointing toward opportunities to scale our understanding to both larger models and more complex tasks. Code for all experiments is available at https://github.com/redwoodresearch/Easy-Transformer.},
	language = {en},
	journal = {arXiv preprint arXiv:2211.00593},
	author = {Wang, Kevin and Variengien, Alexandre and Conmy, Arthur and Shlegeris, Buck and Steinhardt, Jacob},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{nanda_progress_2023,
	title = {Progress measures for grokking via mechanistic interpretability},
	abstract = {Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, or training steps. One approach to understanding emergence is to find continuous progress measures that underlie the seemingly discontinuous qualitative changes. We argue that progress measures can be found via mechanistic interpretability: reverseengineering learned behaviors into their individual components. As a case study, we investigate the recently-discovered phenomenon of “grokking” exhibited by small transformers trained on modular addition tasks. We fully reverse engineer the algorithm learned by these networks, which uses discrete Fourier transforms and trigonometric identities to convert addition to rotation about a circle. We confirm the algorithm by analyzing the activations and weights and by performing ablations in Fourier space. Based on this understanding, we define progress measures that allow us to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup. Our results show that grokking, rather than being a sudden shift, arises from the gradual amplification of structured mechanisms encoded in the weights, followed by the later removal of memorizing components.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Nanda, Neel and Chan, Lawrence and Lieberum, Tom and Smith, Jess and Steinhardt, Jacob},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{barak_hidden_2022,
	title = {Hidden progress in deep learning: {SGD} learns parities near the computational limit},
	volume = {35},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Barak, Boaz and Edelman, Benjamin and Goel, Surbhi and Kakade, Sham and Malach, Eran and Zhang, Cyril},
	year = {2022},
	pages = {21750--21764},
}

@inproceedings{mayilvahanan_does_2024,
	title = {Does {CLIP}'s generalization performance mainly stem from high train-test similarity?},
	abstract = {Foundation models like CLIP are trained on hundreds of millions of samples and effortlessly generalize to new tasks and inputs. Out of the box, CLIP shows stellar zero-shot and few-shot capabilities on a wide range of out-of-distribution (OOD) benchmarks, which prior works attribute mainly to today’s large and comprehensive training dataset (like LAION). However, it is questionable how meaningful terms like out-of-distribution generalization are for CLIP as it seems likely that web-scale datasets like LAION simply contain many samples that are similar to common OOD benchmarks originally designed for ImageNet. To test this hypothesis, we retrain CLIP on pruned LAION splits that replicate ImageNet’s train-test similarity with respect to common OOD benchmarks. While we observe a performance drop on some benchmarks, surprisingly, CLIP’s overall performance remains high. This shows that high train-test similarity is insufficient to explain CLIP’s OOD performance, and other properties of the training data must drive CLIP to learn more generalizable representations. Additionally, by pruning data points that are dissimilar to the OOD benchmarks, we uncover a 100M split of LAION (¼ of its original size) on which CLIP can be trained to match its original OOD performance.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Mayilvahanan, Prasanna and Wiedemer, Thaddäus and Rusak, Evgenia and Bethge, Matthias and Brendel, Wieland},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{trager_linear_2023,
	title = {Linear spaces of meanings: {Compositional} structures in vision-language models},
	shorttitle = {Linear spaces of meanings},
	abstract = {We investigate compositional structures in data embeddings from pre-trained vision-language models (VLMs). Traditionally, compositionality has been associated with algebraic operations on embeddings of words from a preexisting vocabulary. In contrast, we seek to approximate representations from an encoder as combinations of a smaller set of vectors in the embedding space. These vectors can be seen as “ideal words” for generating concepts directly within the embedding space of the model. We ﬁrst present a framework for understanding compositional structures from a geometric perspective. We then explain what these compositional structures entail probabilistically in the case of VLM embeddings, providing intuitions for why they arise in practice. Finally, we empirically explore these structures in CLIP’s embeddings and we evaluate their usefulness for solving different vision-language tasks such as classiﬁcation, debiasing, and retrieval. Our results show that simple linear algebraic operations on embedding vectors can be used as compositional and interpretable methods for regulating the behavior of VLMs.},
	language = {en},
	journal = {arXiv preprint arXiv:2302.14383},
	author = {Trager, Matthew and Perera, Pramuditha and Zancato, Luca and Achille, Alessandro and Bhatia, Parminder and Soatto, Stefano},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
}

@inproceedings{wolff_independent_2023,
	title = {An independent compositional subspace hypothesis for {CLIP}’s representations},
	booktitle = {{ICLR} 2023 {Workshop} on {Mathematical} and {Empirical} {Understanding} of {Foundation} {Models}},
	author = {Wolff, Max and Brendel, Wieland and Wolff, Stuart},
	year = {2023},
}

@inproceedings{noauthor_clip_2023,
	title = {{CLIP} exhibits improved compositional generalization through representation disentanglement},
	abstract = {Vision-language models (VLMs), such as CLIP, have shown promising Out-of-Distribution (OoD) generalization under various flavors of distribution shifts. Recent studies attempted to investigate the leading cause of this property. In this work, we target the same goal, but focus on a certain type of distribution shift, in which test images contain unseen compositions of attribute-object pairs, but with the objects and attributes being individually seen during training. The models are expected to classify those images into the composition classes, i.e. attribute-object pairs, and also into object classes by ignoring attributes. We carefully designed an authentic image test dataset consisting of attributes for objects that are unlikely encountered in the CLIP training data. We found that the compositions diversity in the training data, as measured by normalized mutual information between objects and attributes, has a significant effect on the improvement of compositional generalization in the CLIP models. We found that image/text representation disentanglement with respect to the composition constituents also plays a key role in the improved generalization of these models. We notice that larger training datasets could potentially trigger emergence of such a disentanglement, as the compositions are typically more diverse in such datasets. We validate this hypothesis through different representation disentanglement metrics, including Z-Diff, and explicitness scores for various CLIPs. Our findings reveal a correlation between better OoD performance and higher scores in these disentanglement metrics, suggesting that improved disentanglement potentially contributes to enhanced compositional OoD generalization in VLMs.},
	language = {en},
	year = {2023},
}

@article{bai_sequential_2023,
	title = {Sequential modeling enables scalable learning for large vision models},
	abstract = {We introduce a novel sequential modeling approach which enables learning a Large Vision Model (LVM) without making use of any linguistic data. To do this, we define a common format, “visual sentences”, in which we can represent raw images and videos as well as annotated data sources such as semantic segmentations and depth reconstructions without needing any meta-knowledge beyond the pixels. Once this wide variety of visual data (comprising 420 billion tokens) is represented as sequences, the model can be trained to minimize a cross-entropy loss for next token prediction. By training across various scales of model architecture and data diversity, we provide empirical evidence that our models scale effectively. Many different vision tasks can be solved by designing suitable visual prompts at test time.},
	language = {en},
	journal = {arXiv preprint arXiv:2312.00785},
	author = {Bai, Yutong and Geng, Xinyang and Mangalam, Karttikeya and Bar, Amir and Yuille, Alan and Darrell, Trevor and Malik, Jitendra and Efros, Alexei A.},
	year = {2023},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{xuhong_explicit_2018,
	title = {Explicit inductive bias for transfer learning with convolutional networks},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Xuhong, L. I. and Grandvalet, Yves and Davoine, Franck},
	year = {2018},
	pages = {2825--2834},
}

@misc{li_self-conditioned_2023,
	title = {Self-conditioned image generation via generating representations},
	abstract = {This paper presents Representation-Conditioned image Generation (RCG), a simple yet effective image generation framework which sets a new benchmark in classunconditional image generation. RCG does not condition on any human annotations. Instead, it conditions on a self-supervised representation distribution which is mapped from the image distribution using a pre-trained encoder. During generation, RCG samples from such representation distribution using a representation diffusion model (RDM), and employs a pixel generator to craft image pixels conditioned on the sampled representation. Such a design provides substantial guidance during the generative process, resulting in high-quality image generation. Tested on ImageNet 256×256, RCG achieves a Frechet Inception Distance (FID) of 3.31 and an Inception Score (IS) of 253.4. These results not only significantly improve the state-of-the-art of class-unconditional image generation but also rival the current leading methods in classconditional image generation, bridging the long-standing performance gap between these two tasks. Code is available at https://github.com/LTH14/rcg.},
	language = {en},
	author = {Li, Tianhong and Katabi, Dina and He, Kaiming},
	year = {2023},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{dong_clip_2022,
	title = {{CLIP} itself is a strong fine-tuner: {Achieving} 85.7\% and 88.0\% top-1 accuracy with {ViT}-{B} and {ViT}-{L} on {ImageNet}},
	shorttitle = {Clip itself is a strong fine-tuner},
	abstract = {Recent studies have shown that CLIP has achieved remarkable success in performing zero-shot inference while its ﬁne-tuning performance is not satisfactory. In this paper, we identify that ﬁne-tuning performance is signiﬁcantly impacted by hyper-parameter choices. We examine various key hyper-parameters and empirically evaluate their impact in ﬁne-tuning CLIP for classiﬁcation tasks through a comprehensive study. We ﬁnd that the ﬁne-tuning performance of CLIP is substantially underestimated. Equipped with hyper-parameter reﬁnement, we demonstrate CLIP itself is better or at least competitive in ﬁne-tuning compared with large-scale supervised pre-training approaches or latest works that use CLIP as prediction targets in Masked Image Modeling. Speciﬁcally, CLIP ViT-Base/16 and CLIP ViT-Large/14 can achieve 85.7\%, 88.0\% ﬁnetuning Top1 accuracy on the ImageNet-1K dataset . These observations challenge the conventional conclusion that CLIP is not suitable for ﬁne-tuning, and motivate us to rethink recently proposed improvements based on CLIP. We will release our code publicly at https://github.com/LightDXY/ FT-CLIP.},
	language = {en},
	journal = {arXiv preprint arXiv:2212.06138},
	author = {Dong, Xiaoyi and Bao, Jianmin and Zhang, Ting and Chen, Dongdong and Gu, Shuyang and Zhang, Weiming and Yuan, Lu and Chen, Dong and Wen, Fang and Yu, Nenghai},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{firoozi_foundation_2023,
	title = {Foundation models in robotics: {Applications}, challenges, and the future},
	shorttitle = {Foundation models in robotics},
	abstract = {We survey applications of pretrained foundation models in robotics. Traditional deep learning models in robotics are trained on small datasets tailored for speciﬁc tasks, which limits their adaptability across diverse applications. In contrast, foundation models pretrained on internet-scale data appear to have superior generalization capabilities, and in some instances display an emergent ability to ﬁnd zero-shot solutions to problems that are not present in the training data. Foundation models may hold the potential to enhance various components of the robot autonomy stack, from perception to decision-making and control. For example, large language models can generate code or provide common sense reasoning, while vision-language models enable open-vocabulary visual recognition. However, signiﬁcant open research challenges remain, particularly around the scarcity of robot-relevant training data, safety guarantees and uncertainty quantiﬁcation, and real-time execution. In this survey, we study recent papers that have used or built foundation models to solve robotics problems. We explore how foundation models contribute to improving robot capabilities in the domains of perception, decision-making, and control. We discuss the challenges hindering the adoption of foundation models in robot autonomy and provide opportunities and potential pathways for future advancements. The GitHub project corresponding to this paper1 can be found here.},
	language = {en},
	journal = {arXiv preprint arXiv:2312.07843},
	author = {Firoozi, Roya and Tucker, Johnathan and Tian, Stephen and Majumdar, Anirudha and Sun, Jiankai and Liu, Weiyu and Zhu, Yuke and Song, Shuran and Kapoor, Ashish and Hausman, Karol and Ichter, Brian and Driess, Danny and Wu, Jiajun and Lu, Cewu and Schwager, Mac},
	year = {2023},
	keywords = {Computer Science - Robotics},
}

@inproceedings{darcet_vision_2024,
	title = {Vision transformers need registers},
	abstract = {Transformers have recently emerged as a powerful tool for learning visual representations. In this paper, we identify and characterize artifacts in feature maps of both supervised and self-supervised ViT networks. The artifacts correspond to high-norm tokens appearing during inference primarily in low-informative background areas of images, that are repurposed for internal computations. We propose a simple yet effective solution based on providing additional tokens to the input sequence of the Vision Transformer to fill that role. We show that this solution fixes that problem entirely for both supervised and self-supervised models, sets a new state of the art for self-supervised visual models on dense visual prediction tasks, enables object discovery methods with larger models, and most importantly leads to smoother feature maps and attention maps for downstream visual processing.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Darcet, Timothée and Oquab, Maxime and Mairal, Julien and Bojanowski, Piotr},
	year = {2024},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{sandler_mobilenetv2_2018,
	title = {{MobileNetV2}: {Inverted} residuals and linear bottlenecks},
	booktitle = {Proceedings of the {IEEE} conference on computer vision and pattern recognition},
	author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
	year = {2018},
	pages = {4510--4520},
}

@article{andreassen_evolution_2021,
	title = {The evolution of out-of-distribution robustness throughout fine-tuning},
	abstract = {Although machine learning models typically experience a drop in performance on out-of-distribution data, accuracies on in- versus out-of-distribution data are widely observed to follow a single linear trend when evaluated across a testbed of models. Models that are more accurate on the out-of-distribution data relative to this baseline exhibit “effective robustness” and are exceedingly rare. Identifying such models, and understanding their properties, is key to improving out-of-distribution performance. We conduct a thorough empirical investigation of effective robustness during ﬁne-tuning and surprisingly ﬁnd that models pre-trained on larger datasets exhibit effective robustness during training that vanishes at convergence. We study how properties of the data inﬂuence effective robustness, and we show that it increases with the larger size, more diversity, and higher example difﬁculty of the dataset. We also ﬁnd that models that display effective robustness are able to correctly classify 10\% of the examples that no other current testbed model gets correct. Finally, we discuss several strategies for scaling effective robustness to the high-accuracy regime to improve the out-of-distribution accuracy of state-of-the-art models.},
	language = {en},
	journal = {arXiv preprint arXiv:2106.15831},
	author = {Andreassen, Anders and Bahri, Yasaman and Neyshabur, Behnam and Roelofs, Rebecca},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{mania_why_2021,
	title = {Why do classifier accuracies show linear trends under distribution shift?},
	abstract = {Recent studies of generalization in deep learning have observed a puzzling trend: accuracies of models on one data distribution are approximately linear functions of the accuracies on another distribution. We explain this trend under an intuitive assumption on model similarity, which was veriﬁed empirically in prior work. More precisely, we assume the probability that two models agree in their predictions is higher than what we can infer from their accuracy levels alone. Then, we show that a linear trend must occur when evaluating models on two distributions unless the size of the distribution shift is large. This work emphasizes the value of understanding model similarity, which can have an impact on the generalization and robustness of classiﬁcation models.},
	language = {en},
	journal = {arXiv:2012.15483},
	author = {Mania, Horia and Sra, Suvrit},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{li_seenn_2023,
	title = {{SEENN}: {Towards} temporal spiking early-exit neural networks},
	shorttitle = {Seenn},
	abstract = {Spiking Neural Networks (SNNs) have recently become more popular as a biologically plausible substitute for traditional Artificial Neural Networks (ANNs). SNNs are cost-efficient and deployment-friendly because they process input in both spatial and temporal manner using binary spikes. However, we observe that the information capacity in SNNs is affected by the number of timesteps, leading to an accuracyefficiency tradeoff. In this work, we study a fine-grained adjustment of the number of timesteps in SNNs. Specifically, we treat the number of timesteps as a variable conditioned on different input samples to reduce redundant timesteps for certain data. We call our method Spiking Early-Exit Neural Networks (SEENNs). To determine the appropriate number of timesteps, we propose SEENN-I which uses a confidence score thresholding to filter out the uncertain predictions, and SEENN-II which determines the number of timesteps by reinforcement learning. Moreover, we demonstrate that SEENN is compatible with both the directly trained SNN and the ANN-SNN conversion. By dynamically adjusting the number of timesteps, our SEENN achieves a remarkable reduction in the average number of timesteps during inference. For example, our SEENN-II ResNet-19 can achieve 96.1\% accuracy with an average of 1.08 timesteps on the CIFAR-10 test dataset. Code is shared at https://github.com/Intelligent-Computing-Lab-Yale/SEENN.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Li, Yuhang and Geller, Tamar and Kim, Youngeun and Panda, Priyadarshini},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{entezari_role_2022,
	title = {The role of permutation invariance in linear mode connectivity of neural networks},
	abstract = {In this paper, we conjecture that if the permutation invariance of neural networks is taken into account, SGD solutions will likely have no barrier in the linear interpolation between them. Although it is a bold conjecture, we show how extensive empirical attempts fall short of refuting it. We further provide a preliminary theoretical result to support our conjecture. Our conjecture has implications for lottery ticket hypothesis, distributed training and ensemble methods.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Entezari, Rahim and Sedghi, Hanie and Saukh, Olga and Neyshabur, Behnam},
	year = {2022},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{frankle_linear_2020,
	title = {Linear mode connectivity and the lottery ticket hypothesis},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel and Carbin, Michael},
	year = {2020},
	pages = {3259--3269},
}

@inproceedings{liu_visual_2023,
	title = {Visual instruction tuning},
	abstract = {Instruction tuning large language models (LLMs) using machine-generated instruction-following data has been shown to improve zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. We present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and an LLM for generalpurpose visual and language understanding. To facilitate future research on visual instruction following, we construct two evaluation benchmarks with diverse and challenging application-oriented tasks. Our experiments show that LLaVA demonstrates impressive multimodal chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1\% relative score compared with GPT-4 on a synthetic multimodal instruction-following dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53\%. We make GPT-4 generated visual instruction tuning data, our model, and code publicly available.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
}

@inproceedings{huang_importance_2021,
	title = {On the importance of gradients for detecting distributional shifts in the wild},
	abstract = {Detecting out-of-distribution (OOD) data has become a critical component in ensuring the safe deployment of machine learning models in the real world. Existing OOD detection approaches primarily rely on the output or feature space for deriving OOD scores, while largely overlooking information from the gradient space. In this paper, we present GradNorm, a simple and effective approach for detecting OOD inputs by utilizing information extracted from the gradient space. GradNorm directly employs the vector norm of gradients, backpropagated from the KL divergence between the softmax output and a uniform probability distribution. Our key idea is that the magnitude of gradients is higher for indistribution (ID) data than that for OOD data, making it informative for OOD detection. GradNorm demonstrates superior performance, reducing the average FPR95 by up to 16.33\% compared to the previous best method. Code and data available: https://github.com/deeplearning-wisc/gradnorm\_ood.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Huang, Rui and Geng, Andrew and Li, Yixuan},
	year = {2021},
}

@article{hubinger_sleeper_2024,
	title = {Sleeper agents: {Training} deceptive {LLMs} that persist through safety training},
	shorttitle = {Sleeper agents},
	abstract = {Humans are capable of strategically deceptive behavior: behaving helpfully in most situations, but then behaving very differently in order to pursue alternative objectives when given the opportunity. If an AI system learned such a deceptive strategy, could we detect it and remove it using current state-of-the-art safety training techniques? To study this question, we construct proof-of-concept examples of deceptive behavior in large language models (LLMs). For example, we train models that write secure code when the prompt states that the year is 2023, but insert exploitable code when the stated year is 2024. We find that such backdoored behavior can be made persistent, so that it is not removed by standard safety training techniques, including supervised fine-tuning, reinforcement learning, and adversarial training (eliciting unsafe behavior and then training to remove it). The backdoored behavior is most persistent in the largest models and in models trained to produce chain-of-thought reasoning about deceiving the training process, with the persistence remaining even when the chain-of-thought is distilled away. Furthermore, rather than removing backdoors, we find that adversarial training can teach models to better recognize their backdoor triggers, effectively hiding the unsafe behavior. Our results suggest that, once a model exhibits deceptive behavior, standard techniques could fail to remove such deception and create a false impression of safety.},
	language = {en},
	journal = {arXiv preprint arXiv:2401.05566},
	author = {Hubinger, Evan and Denison, Carson and Mu, Jesse and Lambert, Mike and Tong, Meg and MacDiarmid, Monte and Lanham, Tamera and Ziegler, Daniel M. and Maxwell, Tim and Cheng, Newton and Jermyn, Adam and Askell, Amanda and Radhakrishnan, Ansh and Anil, Cem and Duvenaud, David and Ganguli, Deep and Barez, Fazl and Clark, Jack and Ndousse, Kamal and Sachan, Kshitij and Sellitto, Michael and Sharma, Mrinank and DasSarma, Nova and Grosse, Roger and Kravec, Shauna and Bai, Yuntao and Witten, Zachary and Favaro, Marina and Brauner, Jan and Karnofsky, Holden and Christiano, Paul and Bowman, Samuel R. and Graham, Logan and Kaplan, Jared and Mindermann, Sören and Greenblatt, Ryan and Shlegeris, Buck and Schiefer, Nicholas and Perez, Ethan},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Cryptography and Security, Computer Science - Software Engineering},
}

@inproceedings{gandelsman_interpreting_2024,
	title = {Interpreting {CLIP}'s image representation via text-based decomposition},
	abstract = {We investigate the CLIP image encoder by analyzing how individual model components affect the final representation. We decompose the image representation as a sum across individual image patches, model layers, and attention heads, and use CLIP's text representation to interpret the summands. Interpreting the attention heads, we characterize each head's role by automatically finding text representations that span its output space, which reveals property-specific roles for many heads (e.g. location or shape). Next, interpreting the image patches, we uncover an emergent spatial localization within CLIP. Finally, we use this understanding to remove spurious features from CLIP and to create a strong zero-shot image segmenter. Our results indicate that a scalable understanding of transformer models is attainable and can be used to repair and improve models.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Gandelsman, Yossi and Efros, Alexei A. and Steinhardt, Jacob},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{srivastava_beyond_2023,
	title = {Beyond the imitation game: {Quantifying} and extrapolating the capabilities of language models},
	shorttitle = {Beyond the imitation game},
	abstract = {Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit "breakthrough" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting.},
	language = {en},
	journal = {arXiv preprint arXiv:2206.04615},
	author = {Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R. and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adrià and Kluska, Agnieszka and Lewkowycz, Aitor and Agarwal, Akshat and Power, Alethea and Ray, Alex and Warstadt, Alex and Kocurek, Alexander W. and Safaya, Ali and Tazarv, Ali and Xiang, Alice and Parrish, Alicia and Nie, Allen and Hussain, Aman and Askell, Amanda and Dsouza, Amanda and Slone, Ambrose and Rahane, Ameet and Iyer, Anantharaman S. and Andreassen, Anders and Madotto, Andrea and Santilli, Andrea and Stuhlmüller, Andreas and Dai, Andrew and La, Andrew and Lampinen, Andrew and Zou, Andy and Jiang, Angela and Chen, Angelica and Vuong, Anh and Gupta, Animesh and Gottardi, Anna and Norelli, Antonio and Venkatesh, Anu and Gholamidavoodi, Arash and Tabassum, Arfa and Menezes, Arul and Kirubarajan, Arun and Mullokandov, Asher and Sabharwal, Ashish and Herrick, Austin and Efrat, Avia and Erdem, Aykut and Karakaş, Ayla and Roberts, B. Ryan and Loe, Bao Sheng and Zoph, Barret and Bojanowski, Bartłomiej and Özyurt, Batuhan and Hedayatnia, Behnam and Neyshabur, Behnam and Inden, Benjamin and Stein, Benno and Ekmekci, Berk and Lin, Bill Yuchen and Howald, Blake and Orinion, Bryan and Diao, Cameron and Dour, Cameron and Stinson, Catherine and Argueta, Cedrick and Ramírez, César Ferri and Singh, Chandan and Rathkopf, Charles and Meng, Chenlin and Baral, Chitta and Wu, Chiyu and Callison-Burch, Chris and Waites, Chris and Voigt, Christian and Manning, Christopher D. and Potts, Christopher and Ramirez, Cindy and Rivera, Clara E. and Siro, Clemencia and Raffel, Colin and Ashcraft, Courtney and Garbacea, Cristina and Sileo, Damien and Garrette, Dan and Hendrycks, Dan and Kilman, Dan and Roth, Dan and Freeman, Daniel and Khashabi, Daniel and Levy, Daniel and González, Daniel Moseguí and Perszyk, Danielle and Hernandez, Danny and Chen, Danqi and Ippolito, Daphne and Gilboa, Dar and Dohan, David and Drakard, David and Jurgens, David and Datta, Debajyoti and Ganguli, Deep and Emelin, Denis and Kleyko, Denis and Yuret, Deniz and Chen, Derek and Tam, Derek and Hupkes, Dieuwke and Misra, Diganta and Buzan, Dilyar and Mollo, Dimitri Coelho and Yang, Diyi and Lee, Dong-Ho and Schrader, Dylan and Shutova, Ekaterina and Cubuk, Ekin Dogus and Segal, Elad and Hagerman, Eleanor and Barnes, Elizabeth and Donoway, Elizabeth and Pavlick, Ellie and Rodola, Emanuele and Lam, Emma and Chu, Eric and Tang, Eric and Erdem, Erkut and Chang, Ernie and Chi, Ethan A. and Dyer, Ethan and Jerzak, Ethan and Kim, Ethan and Manyasi, Eunice Engefu and Zheltonozhskii, Evgenii and Xia, Fanyue and Siar, Fatemeh and Martínez-Plumed, Fernando and Happé, Francesca and Chollet, Francois and Rong, Frieda and Mishra, Gaurav and Winata, Genta Indra and de Melo, Gerard and Kruszewski, Germán and Parascandolo, Giambattista and Mariani, Giorgio and Wang, Gloria and Jaimovitch-López, Gonzalo and Betz, Gregor and Gur-Ari, Guy and Galijasevic, Hana and Kim, Hannah and Rashkin, Hannah and Hajishirzi, Hannaneh and Mehta, Harsh and Bogar, Hayden and Shevlin, Henry and Schütze, Hinrich and Yakura, Hiromu and Zhang, Hongming and Wong, Hugh Mee and Ng, Ian and Noble, Isaac and Jumelet, Jaap and Geissinger, Jack and Kernion, Jackson and Hilton, Jacob and Lee, Jaehoon and Fisac, Jaime Fernández and Simon, James B. and Koppel, James and Zheng, James and Zou, James and Kocoń, Jan and Thompson, Jana and Wingfield, Janelle and Kaplan, Jared and Radom, Jarema and Sohl-Dickstein, Jascha and Phang, Jason and Wei, Jason and Yosinski, Jason and Novikova, Jekaterina and Bosscher, Jelle and Marsh, Jennifer and Kim, Jeremy and Taal, Jeroen and Engel, Jesse and Alabi, Jesujoba and Xu, Jiacheng and Song, Jiaming and Tang, Jillian and Waweru, Joan and Burden, John and Miller, John and Balis, John U. and Batchelder, Jonathan and Berant, Jonathan and Frohberg, Jörg and Rozen, Jos and Hernandez-Orallo, Jose and Boudeman, Joseph and Guerr, Joseph and Jones, Joseph and Tenenbaum, Joshua B. and Rule, Joshua S. and Chua, Joyce and Kanclerz, Kamil and Livescu, Karen and Krauth, Karl and Gopalakrishnan, Karthik and Ignatyeva, Katerina and Markert, Katja and Dhole, Kaustubh D. and Gimpel, Kevin and Omondi, Kevin and Mathewson, Kory and Chiafullo, Kristen and Shkaruta, Ksenia and Shridhar, Kumar and McDonell, Kyle and Richardson, Kyle and Reynolds, Laria and Gao, Leo and Zhang, Li and Dugan, Liam and Qin, Lianhui and Contreras-Ochando, Lidia and Morency, Louis-Philippe and Moschella, Luca and Lam, Lucas and Noble, Lucy and Schmidt, Ludwig and He, Luheng and Colón, Luis Oliveros and Metz, Luke and Şenel, Lütfi Kerem and Bosma, Maarten and Sap, Maarten and ter Hoeve, Maartje and Farooqi, Maheen and Faruqui, Manaal and Mazeika, Mantas and Baturan, Marco and Marelli, Marco and Maru, Marco and Quintana, Maria Jose Ramírez and Tolkiehn, Marie and Giulianelli, Mario and Lewis, Martha and Potthast, Martin and Leavitt, Matthew L. and Hagen, Matthias and Schubert, Mátyás and Baitemirova, Medina Orduna and Arnaud, Melody and McElrath, Melvin and Yee, Michael A. and Cohen, Michael and Gu, Michael and Ivanitskiy, Michael and Starritt, Michael and Strube, Michael and Swędrowski, Michał and Bevilacqua, Michele and Yasunaga, Michihiro and Kale, Mihir and Cain, Mike and Xu, Mimee and Suzgun, Mirac and Walker, Mitch and Tiwari, Mo and Bansal, Mohit and Aminnaseri, Moin and Geva, Mor and Gheini, Mozhdeh and T, Mukund Varma and Peng, Nanyun and Chi, Nathan A. and Lee, Nayeon and Krakover, Neta Gur-Ari and Cameron, Nicholas and Roberts, Nicholas and Doiron, Nick and Martinez, Nicole and Nangia, Nikita and Deckers, Niklas and Muennighoff, Niklas and Keskar, Nitish Shirish and Iyer, Niveditha S. and Constant, Noah and Fiedel, Noah and Wen, Nuan and Zhang, Oliver and Agha, Omar and Elbaghdadi, Omar and Levy, Omer and Evans, Owain and Casares, Pablo Antonio Moreno and Doshi, Parth and Fung, Pascale and Liang, Paul Pu and Vicol, Paul and Alipoormolabashi, Pegah and Liao, Peiyuan and Liang, Percy and Chang, Peter and Eckersley, Peter and Htut, Phu Mon and Hwang, Pinyu and Miłkowski, Piotr and Patil, Piyush and Pezeshkpour, Pouya and Oli, Priti and Mei, Qiaozhu and Lyu, Qing and Chen, Qinlang and Banjade, Rabin and Rudolph, Rachel Etta and Gabriel, Raefer and Habacker, Rahel and Risco, Ramon and Millière, Raphaël and Garg, Rhythm and Barnes, Richard and Saurous, Rif A. and Arakawa, Riku and Raymaekers, Robbe and Frank, Robert and Sikand, Rohan and Novak, Roman and Sitelew, Roman and LeBras, Ronan and Liu, Rosanne and Jacobs, Rowan and Zhang, Rui and Salakhutdinov, Ruslan and Chi, Ryan and Lee, Ryan and Stovall, Ryan and Teehan, Ryan and Yang, Rylan and Singh, Sahib and Mohammad, Saif M. and Anand, Sajant and Dillavou, Sam and Shleifer, Sam and Wiseman, Sam and Gruetter, Samuel and Bowman, Samuel R. and Schoenholz, Samuel S. and Han, Sanghyun and Kwatra, Sanjeev and Rous, Sarah A. and Ghazarian, Sarik and Ghosh, Sayan and Casey, Sean and Bischoff, Sebastian and Gehrmann, Sebastian and Schuster, Sebastian and Sadeghi, Sepideh and Hamdan, Shadi and Zhou, Sharon and Srivastava, Shashank and Shi, Sherry and Singh, Shikhar and Asaadi, Shima and Gu, Shixiang Shane and Pachchigar, Shubh and Toshniwal, Shubham and Upadhyay, Shyam and Shyamolima and Debnath and Shakeri, Siamak and Thormeyer, Simon and Melzi, Simone and Reddy, Siva and Makini, Sneha Priscilla and Lee, Soo-Hwan and Torene, Spencer and Hatwar, Sriharsha and Dehaene, Stanislas and Divic, Stefan and Ermon, Stefano and Biderman, Stella and Lin, Stephanie and Prasad, Stephen and Piantadosi, Steven T. and Shieber, Stuart M. and Misherghi, Summer and Kiritchenko, Svetlana and Mishra, Swaroop and Linzen, Tal and Schuster, Tal and Li, Tao and Yu, Tao and Ali, Tariq and Hashimoto, Tatsu and Wu, Te-Lin and Desbordes, Théo and Rothschild, Theodore and Phan, Thomas and Wang, Tianle and Nkinyili, Tiberius and Schick, Timo and Kornev, Timofei and Tunduny, Titus and Gerstenberg, Tobias and Chang, Trenton and Neeraj, Trishala and Khot, Tushar and Shultz, Tyler and Shaham, Uri and Misra, Vedant and Demberg, Vera and Nyamai, Victoria and Raunak, Vikas and Ramasesh, Vinay and Prabhu, Vinay Uday and Padmakumar, Vishakh and Srikumar, Vivek and Fedus, William and Saunders, William and Zhang, William and Vossen, Wout and Ren, Xiang and Tong, Xiaoyu and Zhao, Xinran and Wu, Xinyi and Shen, Xudong and Yaghoobzadeh, Yadollah and Lakretz, Yair and Song, Yangqiu and Bahri, Yasaman and Choi, Yejin and Yang, Yichi and Hao, Yiding and Chen, Yifu and Belinkov, Yonatan and Hou, Yu and Hou, Yufang and Bai, Yuntao and Seid, Zachary and Zhao, Zhuoye and Wang, Zijian and Wang, Zijie J. and Wang, Zirui and Wu, Ziyi},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
}

@article{li_task_2023,
	title = {Task contamination: {Language} models may not be few-shot anymore},
	shorttitle = {Task contamination},
	abstract = {Large language models (LLMs) offer impressive performance in various zero-shot and few-shot tasks. However, their success in zero-shot and few-shot settings may be affected by task contamination, a potential limitation that has not been thoroughly examined. This paper investigates how zero-shot and few-shot performance of LLMs has changed chronologically over time. Utilizing GPT-3 series models and several other recent open-sourced LLMs, and controlling for dataset difficulty, we find that on datasets released before the LLM training data creation date, LLMs perform surprisingly better than on datasets released after. This strongly indicates that, for many LLMs, there exists task contamination on zeroshot and few-shot evaluation for datasets released prior to the LLMs’ training data creation date. Additionally, we utilize training data inspection, task example extraction, and a membership inference attack, which reveal further evidence of task contamination. Importantly, we find that for classification tasks with no possibility of task contamination, LLMs rarely demonstrate statistically significant improvements over simple majority baselines, in both zero and few-shot settings.},
	language = {en},
	journal = {arXiv preprint arXiv:2312.16337},
	author = {Li, Changmao and Flanigan, Jeffrey},
	year = {2023},
	keywords = {Computer Science - Computation and Language, I.2.7},
}

@article{wang_robustness_2023,
	title = {On the robustness of chatgpt: {An} adversarial and out-of-distribution perspective},
	shorttitle = {On the robustness of chatgpt},
	abstract = {ChatGPT is a recent chatbot service released by OpenAI and is receiving increasing attention over the past few months. While evaluations of various aspects of ChatGPT have been done, its robustness, i.e., the performance to unexpected inputs, is still unclear to the public. Robustness is of particular concern in responsible AI, especially for safety-critical applications. In this paper, we conduct a thorough evaluation of the robustness of ChatGPT from the adversarial and out-of-distribution (OOD) perspective. To do so, we employ the AdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart review and DDXPlus medical diagnosis datasets for OOD evaluation. We select several popular foundation models as baselines. Results show that ChatGPT shows consistent advantages on most adversarial and OOD classification and translation tasks. However, the absolute performance is far from perfection, which suggests that adversarial and OOD robustness remains a significant threat to foundation models. Moreover, ChatGPT shows astounding performance in understanding dialogue-related texts and we find that it tends to provide informal suggestions for medical tasks instead of definitive answers. Finally, we present in-depth discussions of possible research directions.},
	language = {en},
	journal = {arXiv preprint arXiv:2302.12095},
	author = {Wang, Jindong and Hu, Xixu and Hou, Wenxin and Chen, Hao and Zheng, Runkai and Wang, Yidong and Yang, Linyi and Huang, Haojun and Ye, Wei and Geng, Xiubo and Jiao, Binxin and Zhang, Yue and Xie, Xing},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{liu_evaluating_2023,
	title = {Evaluating the logical reasoning ability of chatgpt and gpt-4},
	abstract = {Harnessing logical reasoning ability is a comprehensive natural language understanding endeavor. With the release of Generative Pretrained Transformer 4 (GPT-4), highlighted as "advanced" at reasoning tasks, we are eager to learn the GPT-4 performance on various logical reasoning tasks. This report analyses multiple logical reasoning datasets, with popular benchmarks like LogiQA and ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice reading comprehension and natural language inference tasks with benchmarks requiring logical reasoning. We further construct a logical reasoning out-ofdistribution dataset to investigate the robustness of ChatGPT and GPT-4. We also make a performance comparison between ChatGPT and GPT-4. Experiment results show that ChatGPT performs signiﬁcantly better than the RoBERTa ﬁne-tuning method on most logical reasoning benchmarks. With early access to the GPT-4 API we are able to conduct intense experiments on the GPT-4 model. The results show GPT-4 yields even higher performance on most logical reasoning datasets. Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known datasets like LogiQA and ReClor. However, the performance drops signiﬁcantly when handling newly released and out-of-distribution datasets. Logical reasoning remains challenging for ChatGPT and GPT-4, especially on outof-distribution and natural language inference datasets. We release the prompt-style logical reasoning datasets as a benchmark suite and name it LogiEval.},
	language = {en},
	journal = {arXiv preprint arXiv:2304.03439},
	author = {Liu, Hanmeng and Ning, Ruoxi and Teng, Zhiyang and Liu, Jian and Zhou, Qiji and Zhang, Yue},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{noauthor_fine-tuning_2024,
	title = {Fine-tuning aligned language models compromises safety, even when users do not intend to!},
	abstract = {Optimizing large language models (LLMs) for downstream use cases often involves the customization of pre-trained LLMs through further fine-tuning. Meta's open-source release of Llama models and OpenAI's APIs for fine-tuning GPT-3.5 Turbo on customized datasets accelerate this trend. But, what are the safety costs associated with such customized fine-tuning? While existing safety alignment techniques restrict harmful behaviors of LLMs at inference time, they do not cover safety risks when fine-tuning privileges are extended to end-users. Our red teaming studies find that the safety alignment of LLMs can be compromised by fine-tuning with only a few adversarially designed training examples. For instance, we jailbreak GPT-3.5 Turbo's safety guardrails by fine-tuning it on only 10 such examples at a cost of less than \$0.20 via OpenAI's APIs, making the model responsive to nearly any harmful instructions. Disconcertingly, our research also reveals that, even without malicious intent, simply fine-tuning with benign and commonly used datasets can also inadvertently degrade the safety alignment of LLMs, though to a lesser extent. These findings suggest that fine-tuning aligned LLMs introduces new safety risks that current safety infrastructures fall short of addressing --- even if a model's initial safety alignment is impeccable, how can it be maintained after customized fine-tuning? We outline and critically analyze potential mitigations and advocate for further research efforts toward reinforcing safety protocols for the customized fine-tuning of aligned LLMs. (This paper contains red-teaming data and model-generated content that can be offensive in nature.)},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	year = {2024},
}

@inproceedings{noauthor_relu_2023,
	title = {Relu strikes back: {Exploiting} activation sparsity in large language models},
	shorttitle = {Relu strikes back},
	abstract = {Large Language Models (LLMs) with billions of parameters have drastically transformed AI applications. However, their demanding computation during inference has raised significant challenges for deployment on resource-constrained devices. Despite recent trends favoring alternative activation functions such as GELU or SiLU, known for increased computation, this study strongly advocates for reinstating ReLU activation in LLMs. We demonstrate that using the ReLU activation function has a negligible impact on convergence and performance while significantly reducing computation and weight transfer. This reduction is particularly valuable during the memory-bound inference step, where efficiency is paramount. Exploring sparsity patterns in ReLU-based LLMs, we unveil the reutilization of activated neurons for generating new tokens and leveraging these insights, we propose practical strategies to substantially reduce LLM inference computation up to three times, using ReLU activations with minimal performance trade-offs.},
	language = {en},
	month = oct,
	year = {2023},
}

@article{ramesh_hierarchical_2022,
	title = {Hierarchical text-conditional image generation with clip latents},
	abstract = {Contrastive models like CLIP have been shown to learn robust representations of images that capture both semantics and style. To leverage these representations for image generation, we propose a two-stage model: a prior that generates a CLIP image embedding given a text caption, and a decoder that generates an image conditioned on the image embedding. We show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity. Our decoders conditioned on image representations can also produce variations of an image that preserve both its semantics and style, while varying the non-essential details absent from the image representation. Moreover, the joint embedding space of CLIP enables language-guided image manipulations in a zero-shot fashion. We use diffusion models for the decoder and experiment with both autoregressive and diffusion models for the prior, ﬁnding that the latter are computationally more efﬁcient and produce higher-quality samples.},
	language = {en},
	journal = {arXiv preprint arXiv:2204.06125},
	author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
	year = {2022},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{olshausen_emergence_1996,
	title = {Emergence of simple-cell receptive field properties by learning a sparse code for natural images},
	volume = {381},
	number = {6583},
	journal = {Nature},
	author = {Olshausen, Bruno A. and Field, David J.},
	year = {1996},
	pages = {607--609},
}

@article{quiroga_invariant_2005,
	title = {Invariant visual representation by single neurons in the human brain},
	volume = {435},
	issn = {0028-0836, 1476-4687},
	doi = {10.1038/nature03687},
	language = {en},
	number = {7045},
	journal = {Nature},
	author = {Quiroga, R. Quian and Reddy, L. and Kreiman, G. and Koch, C. and Fried, I.},
	year = {2005},
	pages = {1102--1107},
}

@article{antonello_predictive_2023,
	title = {Predictive coding or just feature discovery? {An} alternative account of why language models fit brain data},
	issn = {2641-4368},
	shorttitle = {Predictive coding or just feature discovery?},
	doi = {10.1162/nol_a_00087},
	abstract = {Many recent studies have shown that representations drawn from neural network language models are extremely effective at predicting brain responses to natural language. But why do these models work so well? One proposed explanation is that language models and brains are similar because they have the same objective: to predict upcoming words before they are perceived. This explanation is attractive because it lends support to the popular theory of predictive coding. We provide several analyses that cast doubt on this claim. First, we show that the ability to predict future words does not uniquely (or even best) explain why some representations are a better match to the brain than others. Second, we show that within a language model, representations that are best at predicting future words are strictly worse brain models than other representations. Finally, we argue in favor of an alternative explanation for the success of language models in neuroscience: These models are effective at predicting brain responses because they generally capture a wide variety of linguistic phenomena.},
	journal = {Neurobiology of Language},
	author = {Antonello, Richard and Huth, Alexander},
	year = {2023},
	pages = {1--16},
}

@misc{luo_empirical_2023,
	title = {An empirical study of catastrophic forgetting in large language models during continual fine-tuning},
	abstract = {Catastrophic forgetting (CF) is a phenomenon that occurs in machine learning when a model forgets previously learned information as it learns new information. As large language models (LLMs) have shown excellent performance, it is interesting to uncover whether CF exists in the continual fine-tuning of LLMs. In this study, we empirically evaluate the forgetting phenomenon in LLMs’ knowledge, from the perspectives of domain knowledge, reasoning, and reading comprehension. The experiments demonstrate that catastrophic forgetting is generally observed in LLMs ranging from 1b to 7b. Furthermore, as the scale increases, the severity of forgetting also intensifies. Comparing the decoder-only model BLOOMZ with the encoder-decoder model mT0, BLOOMZ suffers less forgetting and maintains more knowledge. We also observe that LLMs can mitigate language bias (e.g. gender bias) during continual fine-tuning. Moreover, we find that ALPACA can maintain more knowledge and capacity compared with LLAMA during the continual fine-tuning, which implies that general instruction tuning can help mitigate the forgetting phenomenon of LLMs in the further fine-tuning process.},
	language = {en},
	author = {Luo, Yun and Yang, Zhen and Meng, Fandong and Li, Yafu and Zhou, Jie and Zhang, Yue},
	month = aug,
	year = {2023},
	keywords = {Computer Science - Computation and Language},
}

@misc{rauker_toward_2023,
	title = {Toward transparent {AI}: {A} survey on interpreting the inner structures of deep neural networks},
	shorttitle = {Toward transparent ai},
	abstract = {The last decade of machine learning has seen drastic increases in scale and capabilities. Deep neural networks (DNNs) are increasingly being deployed in the real world. However, they are difficult to analyze, raising concerns about using them without a rigorous understanding of how they function. Effective tools for interpreting them will be important for building more trustworthy AI by helping to identify problems, fix bugs, and improve basic understanding. In particular, “inner” interpretability techniques, which focus on explaining the internal components of DNNs, are well-suited for developing a mechanistic understanding, guiding manual modifications, and reverse engineering solutions.},
	language = {en},
	author = {Räuker, Tilman and Ho, Anson and Casper, Stephen and Hadfield-Menell, Dylan},
	month = aug,
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
}

@inproceedings{yu_rethinking_2024,
	title = {Rethinking the evaluation protocol of domain generalization},
	abstract = {Domain generalization aims to solve the challenge of Out-of-Distribution (OOD) generalization by leveraging common knowledge learned from multiple training domains to generalize to unseen test domains. To accurately evaluate the OOD generalization ability, it is necessary to ensure that test data information is unavailable. However, the current domain generalization protocol may still have potential test data information leakage. This paper examines the potential risks of test data information leakage in two aspects of the current protocol: pretraining on ImageNet and oracle model selection. We propose that training from scratch and using multiple test domains would result in a more precise evaluation of OOD generalization ability. We also rerun the algorithms with the modified protocol and introduce a new leaderboard to encourage future research in domain generalization with a fairer comparison.},
	language = {en},
	booktitle = {{CVPR}},
	author = {Yu, Han and Zhang, Xingxuan and Xu, Renzhe and Liu, Jiashuo and He, Yue and Cui, Peng},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{elhage_toy_2022,
	title = {Toy models of superposition},
	journal = {arXiv preprint arXiv:2209.10652},
	author = {Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol},
	year = {2022},
}

@inproceedings{udandarao_visual_2024,
	title = {Visual data-type understanding does not emerge from scaling vision-language models},
	abstract = {Recent advances in the development of vision-language models (VLMs) are yielding remarkable success in recognizing visual semantic content, including impressive instances of compositional image understanding. Here, we introduce the novel task of Visual Data-Type Identification, a basic perceptual skill with implications for data curation (e.g., noisy data-removal from large datasets, domains pecific retrieval) and autonomous vision (e.g., distinguishing changing weather conditions from camera lens staining). We develop two datasets consisting of animal images altered across a diverse set of 27 visual data-types, spanning four broad categories. An extensive zero-shot evaluation of 39 VLMs, ranging from 100M to 80B parameters, shows a nuanced performance landscape. While VLMs are reasonably good at identifying certain stylistic data-types, such as cartoons and sketches, they struggle with simpler data-types arising from basic manipulations like image rotations or additive noise. Our findings reveal that (i) model scaling alone yields marginal gains for contrastively-trained models like CLIP, and (ii) there is a pronounced drop in performance for the largest auto-regressively trained VLMs like OpenFlamingo. This finding points to a blind spot in current frontier VLMs: they excel in recognizing semantic content but fail to acquire an understanding of visual data-types through scaling. By analyzing the pre-training distributions of these models and incorporating data-type information into the captions during fine-tuning, we achieve a significant enhancement in performance. By exploring this previously uncharted task, we aim to set the stage for further advancing VLMs to equip them with visual data-type understanding. We will make our code available online upon publication.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Udandarao, Vishaal and Burg, Max F. and Albanie, Samuel and Bethge, Matthias},
	year = {2024},
}

@misc{bhalla_interpreting_2024,
	title = {Interpreting {CLIP} with sparse linear concept embeddings (splice)},
	abstract = {CLIP embeddings have demonstrated remarkable performance across a wide range of computer vision tasks. However, these high-dimensional, dense vector representations are not easily interpretable, restricting their usefulness in downstream applications that require transparency. In this work, we empirically show that CLIP’s latent space is highly structured, and consequently that CLIP representations can be decomposed into their underlying semantic components. We leverage this understanding to propose a novel method, Sparse Linear Concept Embeddings (SpLiCE ), for transforming CLIP representations into sparse linear combinations of humaninterpretable concepts. Distinct from previous work, SpLiCE does not require concept labels and can be applied post hoc. Through extensive experimentation with multiple real-world datasets, we validate that the representations output by SpLiCE can explain and even replace traditional dense CLIP representations, maintaining equivalent downstream performance while significantly improving their interpretability. We also demonstrate several use cases of SpLiCE representations including detecting spurious correlations, model editing, and quantifying semantic shifts in datasets. Code is provided at https: //github.com/AI4LIFE-GROUP/SpLiCE.},
	language = {en},
	author = {Bhalla, Usha and Oesterling, Alex and Srinivas, Suraj and Calmon, Flavio P. and Lakkaraju, Himabindu},
	month = feb,
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{rolls_neuronal_2011,
	title = {The neuronal encoding of information in the brain},
	volume = {95},
	issn = {03010082},
	doi = {10.1016/j.pneurobio.2011.08.002},
	language = {en},
	number = {3},
	journal = {Progress in Neurobiology},
	author = {Rolls, Edmund T. and Treves, Alessandro},
	year = {2011},
	pages = {448--490},
}

@inproceedings{illing_local_2021,
	title = {Local plasticity rules can learn deep representations using self-supervised contrastive predictions},
	volume = {34},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Illing, Bernd and Ventura, Jean and Bellec, Guillaume and Gerstner, Wulfram},
	year = {2021},
	pages = {30365--30379},
}

@inproceedings{jiang_spatio-temporal_2024,
	title = {Spatio-temporal approximation: {A} training-free {SNN} conversion for transformers},
	abstract = {Spiking neural networks (SNNs) are energy-efficient and hold great potential for large-scale inference. Since training SNNs from scratch is costly and has limited performance, converting pretrained artificial neural networks (ANNs) to SNNs is an attractive approach that retains robust performance without additional training data and resources. However, while existing conversion methods work well on convolution networks, emerging Transformer models introduce unique mechanisms like self-attention and test-time normalization, leading to non-causal nonlinear interactions unachievable by current SNNs. To address this, we approximate these operations in both temporal and spatial dimensions, thereby providing the first SNN conversion pipeline for Transformers. We propose Universal Group Operators to approximate non-linear operations spatially and a Temporal-Corrective Self-Attention Layer that approximates spike multiplications at inference through an estimation-correction approach. Our algorithm is implemented on a pretrained ViT-B/32 from CLIP, inheriting its zero-shot classification capabilities, while improving control over conversion losses. To our knowledge, this is the first direct training-free conversion of a pretrained Transformer to a purely event-driven SNN, promising for neuromorphic hardware deployment. Codes are available at https://github.com/ViviaHu/STA.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Jiang, Yizhou and Hu, Kunlin and Zhang, Tianren and Gao, Haichuan and Liu, Yuqian and Fang, Ying and Chen, Feng},
	year = {2024},
}

@inproceedings{yao_tree_2023,
	title = {Tree of thoughts: {Deliberate} problem solving with large language models},
	volume = {36},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
	year = {2023},
}

@inproceedings{hafner_mastering_2021,
	title = {Mastering atari with discrete world models},
	abstract = {Intelligent agents need to generalize from past experience to achieve goals in complex environments. World models facilitate such generalization and allow learning behaviors from imagined outcomes to increase sample-efficiency. While learning world models from image inputs has recently become feasible for some tasks, modeling Atari games accurately enough to derive successful behaviors has remained an open challenge for many years. We introduce DreamerV2, a reinforcement learning agent that learns behaviors purely from predictions in the compact latent space of a powerful world model. The world model uses discrete representations and is trained separately from the policy. DreamerV2 constitutes the first agent that achieves human-level performance on the Atari benchmark of 55 tasks by learning behaviors inside a separately trained world model. With the same computational budget and wall-clock time, Dreamer V2 reaches 200M frames and surpasses the final performance of the top single-GPU agents IQN and Rainbow. DreamerV2 is also applicable to tasks with continuous actions, where it learns an accurate world model of a complex humanoid robot and solves stand-up and walking from only pixel inputs.},
	language = {en},
	author = {Hafner, Danijar and Lillicrap, Timothy P. and Norouzi, Mohammad and Ba, Jimmy},
	year = {2021},
}

@article{bubeck_sparks_2023,
	title = {Sparks of artificial general intelligence: {Early} experiments with {GPT}-4},
	shorttitle = {Sparks of artificial general intelligence},
	abstract = {Artiﬁcial intelligence (AI) researchers have been developing and reﬁning large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4 [Ope23], was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT4 is part of a new cohort of LLMs (along with ChatGPT and Google’s PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and diﬃcult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4’s performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4’s capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artiﬁcial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reﬂections on societal inﬂuences of the recent technological leap and future research directions.},
	language = {en},
	journal = {arXiv preprint arXiv:2303.12712},
	author = {Bubeck, Sébastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and Nori, Harsha and Palangi, Hamid and Ribeiro, Marco Tulio and Zhang, Yi},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{noauthor_video_nodate,
	title = {Video generation models as world simulators},
	abstract = {We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.},
	language = {en-US},
}

@article{ji_survey_2023,
	title = {Survey of hallucination in natural language generation},
	volume = {55},
	issn = {0360-0300, 1557-7341},
	doi = {10.1145/3571730},
	abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before.
            In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.},
	language = {en},
	number = {12},
	journal = {ACM Computing Surveys},
	author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
	year = {2023},
	pages = {1--38},
}

@article{rawte_survey_2023,
	title = {A survey of hallucination in large foundation models},
	abstract = {Hallucination in a foundation model (FM) refers to the generation of content that strays from factual reality or includes fabricated information. This survey paper provides an extensive overview of recent efforts that aim to identify, elucidate, and tackle the problem of hallucination, with a particular focus on “Large” Foundation Models (LFMs). The paper classifies various types of hallucination phenomena that are specific to LFMs and establishes evaluation criteria for assessing the extent of hallucination. It also examines existing strategies for mitigating hallucination in LFMs and discusses potential directions for future research in this area. Essentially, the paper offers a comprehensive examination of the challenges and solutions related to hallucination in LFMs.},
	language = {en},
	journal = {arXiv preprint arXiv:2309.05922},
	author = {Rawte, Vipula and Sheth, Amit and Das, Amitava},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval},
}

@article{zhang_sirens_2023,
	title = {Siren's song in the {AI} ocean: {A} survey on hallucination in large language models},
	shorttitle = {Siren's song in the ai ocean},
	abstract = {While large language models (LLMs) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibit hallucinations: LLMs occasionally generate content that diverges from the user input, contradicts previously generated context, or misaligns with established world knowledge. This phenomenon poses a substantial challenge to the reliability of LLMs in real-world scenarios. In this paper, we survey recent efforts on the detection, explanation, and mitigation of hallucination, with an emphasis on the unique challenges posed by LLMs. We present taxonomies of the LLM hallucination phenomena and evaluation benchmarks, analyze existing approaches aiming at mitigating LLM hallucination, and discuss potential directions for future research.},
	language = {en},
	journal = {arXiv preprint arXiv:2309.01219},
	author = {Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and Wang, Longyue and Luu, Anh Tuan and Bi, Wei and Shi, Freda and Shi, Shuming},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
}

@inproceedings{yuan_revisiting_2024,
	title = {Revisiting out-of-distribution robustness in {NLP}: {Benchmark}, analysis, and {LLMs} evaluations},
	abstract = {This paper reexamines the research on out-of-distribution (OOD) robustness in the field of NLP. We find that the distribution shift settings in previous studies commonly lack adequate challenges, hindering the accurate evaluation of OOD robustness. To address these issues, we propose a benchmark construction protocol that ensures clear differentiation and challenging distribution shifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution robustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we conduct a series of experiments on pretrained language models for analysis and evaluation of OOD robustness. First, for vanilla fine-tuning, we examine the relationship between in-distribution (ID) and OOD performance. We identify three typical types that unveil the inner learning mechanism, which could potentially facilitate the forecasting of OOD robustness, correlating with the advancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and find that, despite exhibiting some effectiveness in specific cases, they do not offer significant improvement compared to vanilla fine-tuning. Further, we evaluate 5 LLMs with various adaptation paradigms and find that when sufficient ID data is available, fine-tuning domain-specific models outperform LLMs on ID examples significantly. However, in the case of OOD instances, prioritizing LLMs with in-context learning yields better results. We identify that both fine-tuned small models and LLMs face challenges in effectively addressing downstream tasks. The code is public at https://github.com/lifan-yuan/OOD\_NLP.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Yuan, Lifan and Chen, Yangyi and Cui, Ganqu and Gao, Hongcheng and Zou, Fangyuan and Cheng, Xingyi and Ji, Heng and Liu, Zhiyuan and Sun, Maosong},
	year = {2024},
}

@article{barack_two_2021,
	title = {Two views on the cognitive brain},
	volume = {22},
	issn = {1471-003X, 1471-0048},
	doi = {10.1038/s41583-021-00448-6},
	abstract = {Cognition can be defined as computation over meaningful representations in the brain to produce adaptive behaviour. There are two views on the relationship between cognition and the brain that are largely implicit in the literature. The Sherringtonian view seeks to explain cognition as the result of operations on signals performed at nodes in a network and passed between them that are implemented by specific neurons and their connections in circuits in the brain. The contrasting Hopfieldian view explains cognition as the result of transformations between or movement within representational spaces that are implemented by neural populations. Thus, the Hopfieldian view relegates details regarding the identity of and connections between specific neurons to the status of secondary explainers. Only the Hopfieldian approach has the representational and computational resources needed to develop novel neurofunctional objects that can serve as primary explainers of cognition.},
	language = {en},
	number = {6},
	journal = {Nature Reviews Neuroscience},
	author = {Barack, David L. and Krakauer, John W.},
	year = {2021},
	pages = {359--371},
}

@inproceedings{netanyahu_learning_2023,
	title = {Learning to extrapolate: {A} transductive approach},
	shorttitle = {Learning to extrapolate},
	abstract = {Machine learning systems, especially with overparameterized deep neural networks, can generalize to novel test instances drawn from the same distribution as the training data. However, they fare poorly when evaluated on out-of-support test points. In this work, we tackle the problem of developing machine learning systems that retain the power of overparameterized function approximators while enabling extrapolation to out-of-support test points when possible. This is accomplished by noting that under certain conditions, a “transductive” reparameterization can convert an out-of-support extrapolation problem into a problem of within-support combinatorial generalization. We propose a simple strategy based on bilinear embeddings to enable this type of combinatorial generalization, thereby addressing the out-of-support extrapolation problem under certain conditions. We instantiate a simple, practical algorithm applicable to various supervised learning and imitation learning tasks.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Netanyahu, Aviv and Gupta, Abhishek and Simchowitz, Max and Zhang, Kaiqing and Agrawal, Pulkit},
	year = {2023},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{wiedemer_provable_2024,
	title = {Provable compositional generalization for object-centric learning},
	abstract = {Learning representations that generalize to novel compositions of known concepts is crucial for bridging the gap between human and machine perception. One prominent effort is learning object-centric representations, which are widely conjectured to enable compositional generalization. Yet, it remains unclear when this conjecture will be true, as a principled theoretical or empirical understanding of compositional generalization is lacking. In this work, we investigate when compositional generalization is guaranteed for object-centric representations through the lens of identifiability theory. We show that autoencoders that satisfy structural assumptions on the decoder and enforce encoder-decoder consistency will learn object-centric representations that provably generalize compositionally. We validate our theoretical result and highlight the practical relevance of our assumptions through experiments on synthetic image data.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Wiedemer, Thaddäus and Brady, Jack and Panfilov, Alexander and Juhos, Attila and Bethge, Matthias and Brendel, Wieland},
	year = {2024},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{jiang_joint_2024,
	title = {On the joint interaction of models, data, and features},
	abstract = {Learning features from data is one of the defining characteristics of deep learning, but our theoretical understanding of the role features play in deep learning is still rudimentary. To address this gap, we introduce a new tool, the interaction tensor, for empirically analyzing the interaction between data and model through features. With the interaction tensor, we make several key observations about how features are distributed in data and how models with different random seeds learn different features. Based on these observations, we propose a conceptual framework for feature learning. Under this framework, the expected accuracy for a single hypothesis and agreement for a pair of hypotheses can both be derived in closed-form. We demonstrate that the proposed framework can explain empirically observed phenomena, including the recently discovered Generalization Disagreement Equality (GDE) that allows for estimating the generalization error with only unlabeled data. Further, our theory also provides explicit construction of natural data distributions that break the GDE. Thus, we believe this work provides valuable new insight into our understanding of feature learning.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Jiang, Yiding and Baek, Christina and Kolter, J. Zico},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{gao_fast_2023,
	title = {Fast counterfactual inference for history-based reinforcement learning},
	volume = {37},
	isbn = {2374-3468},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Gao, Haichuan and Zhang, Tianren and Yang, Zhile and Guo, Yuqing and Ren, Jinsheng and Guo, Shangqi and Chen, Feng},
	year = {2023},
	pages = {7613--7623},
}

@inproceedings{wen_sharpness_2024,
	title = {Sharpness minimization algorithms do not only minimize sharpness to achieve better generalization},
	abstract = {Despite extensive studies, the underlying reason as to why overparameterized neural networks can generalize remains elusive. Existing theory shows that common stochastic optimizers prefer flatter minimizers of the training loss, and thus a natural potential explanation is that flatness implies generalization. This work critically examines this explanation. Through theoretical and empirical investigation, we identify the following three scenarios for two-layer ReLU networks: (1) flatness provably implies generalization; (2) there exist non-generalizing flattest models and sharpness minimization algorithms fail to generalize poorly, and (3) perhaps most strikingly, there exist non-generalizing flattest models, but sharpness minimization algorithms still generalize. Our results suggest that the relationship between sharpness and generalization subtly depends on the data distributions and the model architectures and sharpness minimization algorithms do not only minimize sharpness to achieve better generalization. This calls for the search for other explanations for the generalization of over-parameterized neural networks.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wen, Kaiyue and Li, Zhiyuan},
	year = {2024},
}

@misc{min_metaicl_2022,
	title = {{MetaICL}: {Learning} to {Learn} {In} {Context}},
	shorttitle = {{MetaICL}},
	abstract = {We introduce MetaICL (Meta-training for InContext Learning), a new meta-training framework for few-shot learning where a pretrained language model is tuned to do in-context learning on a large set of training tasks. This metatraining enables the model to more effectively learn a new task in context at test time, by simply conditioning on a few training examples with no parameter updates or task-speciﬁc templates. We experiment on a large, diverse collection of tasks consisting of 142 NLP datasets including classiﬁcation, question answering, natural language inference, paraphrase detection and more, across seven different metatraining/target splits. MetaICL outperforms a range of baselines including in-context learning without meta-training and multi-task learning followed by zero-shot transfer. We ﬁnd that the gains are particularly signiﬁcant for target tasks that have domain shifts from the meta-training tasks, and that using a diverse set of the meta-training tasks is key to improvements. We also show that MetaICL approaches (and sometimes beats) the performance of models fully ﬁnetuned on the target task, and outperforms much bigger models with nearly 8x parameters. Finally, we show that MetaICL is complementary to human-written instructions, and the best performance can be achieved by combining both approaches.},
	language = {en},
	author = {Min, Sewon and Lewis, Mike and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
	year = {2022},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{zhong_clock_2023,
	title = {The clock and the pizza: {Two} stories in mechanistic explanation of neural networks},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Zhong, Ziqian and Liu, Ziming and Tegmark, Max and Andreas, Jacob},
	year = {2023},
}

@article{goh_multimodal_2021,
	title = {Multimodal neurons in artificial neural networks},
	volume = {6},
	issn = {2476-0757},
	doi = {10.23915/distill.00030},
	abstract = {We report the existence of multimodal neurons in artificial neural networks, similar to those found in the human brain.},
	language = {en},
	number = {3},
	journal = {Distill},
	author = {Goh, Gabriel and Cammarata, Nick and Voss, Chelsea and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Radford, Alec and Olah, Chris},
	month = mar,
	year = {2021},
	pages = {e30},
}

@article{radhakrishnan_mechanism_2024,
	title = {Mechanism for feature learning in neural networks and backpropagation-free machine learning models},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.adi5639},
	abstract = {Understanding how neural networks learn features, or relevant patterns in data, for prediction is necessary for their reliable use in technological and scientific applications. In this work, we presented a unifying mathematical mechanism, known as Average Gradient Outer Product (AGOP), that characterized feature learning in neural networks. We provided empirical evidence that AGOP captured features learned by various neural network architectures, including transformer-based language models, convolutional networks, multi-layer perceptrons, and recurrent neural networks. Moreover, we demonstrated that AGOP, which is backpropagation-free, enabled feature learning in machine learning models, such as kernel machines, that apriori could not identify task-specific features. Overall, we established a fundamental mechanism that captured feature learning in neural networks and enabled feature learning in general machine learning models.},
	language = {en},
	journal = {Science},
	author = {Radhakrishnan, Adityanarayanan and Beaglehole, Daniel and Pandit, Parthe and Belkin, Mikhail},
	year = {2024},
	pages = {science.adi5639},
}

@article{papyan_prevalence_2020,
	title = {Prevalence of neural collapse during the terminal phase of deep learning training},
	volume = {117},
	number = {40},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Papyan, Vardan and Han, X. Y. and Donoho, David L.},
	year = {2020},
	pages = {24652--24663},
}

@inproceedings{wortsman_small-scale_2024,
	title = {Small-scale proxies for large-scale {Transformer} training instabilities},
	abstract = {Teams that have trained large Transformer-based models have reported training instabilities at large scale that did not appear when training with the same hyperparameters at smaller scales. Although the causes of such instabilities are of scientific interest, the amount of resources required to reproduce them has made investigation difficult. In this work, we seek ways to reproduce and study training stability and instability at smaller scales. First, we focus on two sources of training instability described in previous work: the growth of logits in attention layers (Dehghani et al., 2023) and divergence of the output logits from the log probabilities (Chowdhery et al., 2022). By measuring the relationship between learning rate and loss across scales, we show that these instabilities also appear in small models when training at high learning rates, and that mitigations previously employed at large scales are equally effective in this regime. This prompts us to investigate the extent to which other known optimizer and model interventions influence the sensitivity of the final loss to changes in the learning rate. To this end, we study methods such as warm-up, weight decay, and the \${\textbackslash}mu\$Param (Yang et al., 2022), and combine techniques to train small models that achieve similar losses across orders of magnitude of learning rate variation. Finally, to conclude our exploration we study two cases where instabilities can be predicted before they emerge by examining the scaling behavior of model activation and gradient norms.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Wortsman, Mitchell and Liu, Peter J. and Xiao, Lechao and Everett, Katie and Alemi, Alex and Adlam, Ben and Co-Reyes, John D. and Gur, Izzeddin and Kumar, Abhishek and Novak, Roman and Pennington, Jeffrey and Sohl-dickstein, Jascha and Xu, Kelvin and Lee, Jaehoon and Gilmer, Justin and Kornblith, Simon},
	year = {2024},
	keywords = {Computer Science - Machine Learning},
}

@article{ranadive_special_2023,
	title = {On the special role of class-selective neurons in early training},
	issn = {2835-8856},
	abstract = {It is commonly observed that deep networks trained for classification exhibit class-selective neurons in their early and intermediate layers. Intriguingly, recent studies have shown that these class-selective neurons can be ablated without deteriorating network function. But if class-selective neurons are not necessary, why do they exist? We attempt to answer this question in a series of experiments on ResNet-50s trained on ImageNet. We first show that class-selective neurons emerge during the first few epochs of training, before receding rapidly but not completely; this suggests that class-selective neurons found in trained networks are in fact vestigial remains of early training. With single-neuron ablation experiments, we then show that class-selective neurons are important for network function in this early phase of training. We also observe that the network is close to a linear regime in this early phase; we thus speculate that class-selective neurons appear early in training as quasi-linear shortcut solutions to the classification task. Finally, in causal experiments where we regularize against class selectivity at different points in training, we show that the presence of class-selective neurons early in training is critical to the successful training of the network; in contrast, class-selective neurons can be suppressed later in training with little effect on final accuracy. It remains to be understood by which mechanism the presence of class-selective neurons in the early phase of training contributes to the successful training of networks.},
	language = {en},
	journal = {Transactions on Machine Learning Research},
	author = {Ranadive, Omkar and Thakurdesai, Nikhil and Morcos, Ari S. and Leavitt, Matthew L. and Deny, Stephane},
	year = {2023},
}

@inproceedings{puli_dont_2023,
	title = {Don’t blame dataset shift! {Shortcut} learning due to gradients and cross entropy},
	abstract = {Common explanations for shortcut learning assume that the shortcut improves prediction under the training distribution but not in the test distribution. Thus, models trained via the typical gradient-based optimization of cross-entropy, which we call default-ERM, utilize the shortcut. However, even when the stable feature determines the label in the training distribution and the shortcut does not provide any additional information, like in perception tasks, default-ERM still exhibits shortcut learning. Why are such solutions preferred when the loss for default-ERM can be driven to zero using the stable feature alone? By studying a linear perception task, we show that default-ERM’s preference for maximizing the margin leads to models that depend more on the shortcut than the stable feature, even without overparameterization. This insight suggests that default-ERM’s implicit inductive bias towards max-margin is unsuitable for perception tasks. Instead, we develop an inductive bias toward uniform margins and show that this bias guarantees dependence only on the perfect stable feature in the linear perception task. We develop loss functions that encourage uniform-margin solutions, called margin control (MARG-CTRL). MARG-CTRL mitigates shortcut learning on a variety of vision and language tasks, showing that better inductive biases can remove the need for expensive two-stage shortcut-mitigating methods in perception tasks.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Puli, Aahlad and Zhang, Lily and Wald, Yoav and Ranganath, Rajesh},
	year = {2023},
}

@article{zhai_investigating_2023,
	title = {Investigating the catastrophic forgetting in multimodal large language models},
	journal = {arXiv preprint arXiv:2309.10313},
	author = {Zhai, Yuexiang and Tong, Shengbang and Li, Xiao and Cai, Mu and Qu, Qing and Lee, Yong Jae and Ma, Yi},
	year = {2023},
}

@inproceedings{bachmann_pitfalls_2024,
	title = {The pitfalls of next-token prediction},
	abstract = {Can a mere next-token predictor faithfully model human intelligence? We crystallize this intuitive concern, which is fragmented in the literature. As a starting point, we argue that the two often-conflated phases of next-token prediction -- autoregressive inference and teacher-forced training -- must be treated distinctly. The popular criticism that errors can compound during autoregressive inference, crucially assumes that teacher-forcing has learned an accurate next-token predictor. This assumption sidesteps a more deep-rooted problem we expose: in certain classes of tasks, teacher-forcing can simply fail to learn an accurate next-token predictor in the first place. We describe a general mechanism of how teacher-forcing can fail, and design a minimal planning task where both the Transformer and the Mamba architecture empirically fail in that manner -- remarkably, despite the task being straightforward to learn. We provide preliminary evidence that this failure can be resolved when training to predict multiple tokens in advance. We hope this finding can ground future debates and inspire explorations beyond the next-token prediction paradigm. We make our code available under https://github.com/gregorbachmann/Next-Token-Failures},
	language = {en},
	booktitle = {{ICML}},
	author = {Bachmann, Gregor and Nagarajan, Vaishnavh},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{thrampoulidis_implicit_2024,
	title = {Implicit bias of next-token prediction},
	abstract = {Next-token prediction (NTP), the go-to training paradigm in training large language models, involves predicting the next token in a sequence. Departing from traditional one-hot classification, in NTP, multiple tokens with varying frequencies follow each given context. This work frames NTP training as cross-entropy minimization over distinct contexts, each associated with a sparse empirical probability vector across a finite vocabulary. It then addresses the following question: do gradient-based optimizers exhibit a bias towards solutions with specific structure as the NTP training loss reaches its lower bound (entropy)? Specifically, for linear NTP models trained using gradient descent (GD), we make the following contributions: Firstly, we determine NTP-separability conditions on the data, under which GD can attain its lower bound. We also demonstrate that these conditions hold under overparameterization. Secondly, we establish that the parameters of GD projected onto an appropriate data subspace converge to the unique solution of a system of linear equations, which requires the logits’ difference of in-support tokens to be equal to the log-ratio of their respective probabilities. Meanwhile, on the orthogonal subspace, the parameters diverge and converge in the direction of the solution of a max-margin quadratic program, minimizing the Euclidean norm of parameters satisfying the NTP-separability conditions. Akin to prior research on implicit bias of one-hot classification, our work opens exciting avenues for future research that can lead to better understanding optimization, generalization and robustness principles of models trained with NTP.},
	language = {en},
	author = {Thrampoulidis, Christos},
	month = feb,
	year = {2024},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{shi_how_2022,
	title = {How robust are pre-trained models to distribution shift?},
	abstract = {The vulnerability of machine learning models to spurious correlations has mostly been discussed in the context of supervised learning (SL). However, there is a lack of insight on how spurious correlations affect the performance of popular selfsupervised learning (SSL) and auto-encoder based models (AE). In this work, we shed light on this by evaluating the performance of these models on both real world and synthetic distribution shift datasets. Following observations that the linear head itself can be susceptible to spurious correlations, we develop a novel evaluation scheme with the linear head trained on out-of-distribution (OOD) data, to isolate the performance of the pretrained models from a potential bias of the linear head used for evaluation. With this new methodology, we show that SSL models are consistently more robust to distribution shifts and thus better at OOD generalisation than AE and SL models.},
	language = {en},
	booktitle = {{ICML} 2022 {Workshop} on {Spurious} {Correlations}, {Invariance}, and {Stability}},
	author = {Shi, Yuge and Daunhawer, Imant and Vogt, Julia E and Torr, Philip H S and Sanyal, Amartya},
	year = {2022},
}

@inproceedings{tian_trainable_2023,
	address = {Vancouver, BC, Canada},
	title = {Trainable projected gradient method for robust fine-tuning},
	isbn = {9798350301298},
	doi = {10.1109/CVPR52729.2023.00757},
	abstract = {Recent studies on transfer learning have shown that selectively ﬁne-tuning a subset of layers or customizing different learning rates for each layer can greatly improve robustness to out-of-distribution (OOD) data and retain generalization capability in the pre-trained models. However, most of these methods employ manually crafted heuristics or expensive hyper-parameter searches, which prevent them from scaling up to large datasets and neural networks. To solve this problem, we propose Trainable Projected Gradient Method (TPGM) to automatically learn the constraint imposed for each layer for a ﬁne-grained ﬁne-tuning regularization. This is motivated by formulating ﬁne-tuning as a bi-level constrained optimization problem. Speciﬁcally, TPGM maintains a set of projection radii, i.e., distance constraints between the ﬁne-tuned model and the pretrained model, for each layer, and enforces them through weight projections. To learn the constraints, we propose a bi-level optimization to automatically learn the best set of projection radii in an end-to-end manner. Theoretically, we show that the bi-level optimization formulation is the key to learning different constraints for each layer. Empirically, with little hyper-parameter search cost, TPGM outperforms existing ﬁne-tuning methods in OOD performance while matching the best in-distribution (ID) performance. For example, when ﬁne-tuned on DomainNetReal and ImageNet, compared to vanilla ﬁne-tuning, TPGM shows 22\% and 10\% relative OOD improvement respectively on their sketch counterparts. Code is available at https://github.com/PotatoTian/TPGM .},
	language = {en},
	booktitle = {2023 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Tian, Junjiao and Dai, Xiaoliang and Ma, Chih-Yao and He, Zecheng and Liu, Yen-Cheng and Kira, Zsolt},
	year = {2023},
	pages = {7836--7845},
}

@article{liu_decades_2024,
	title = {A decade's battle on dataset bias: {Are} we there yet?},
	shorttitle = {A decade's battle on dataset bias},
	abstract = {We revisit the “dataset classification” experiment suggested by Torralba and Efros a decade ago [51], in the new era with largescale, diverse, and hopefully less biased datasets as well as more capable neural network architectures. Surprisingly, we observe that modern neural networks can achieve excellent accuracy in classifying which dataset an image is from: e.g., we report 84.7\% accuracy on held-out validation data for the three-way classification problem consisting of the YFCC, CC, and DataComp datasets. Our further experiments show that such a dataset classifier could learn semantic features that are generalizable and transferable, which cannot be simply explained by memorization. We hope our discovery will inspire the community to rethink the issue involving dataset bias and model capabilities.},
	language = {en},
	journal = {arXiv preprint arXiv:2403.08632},
	author = {Liu, Zhuang and He, Kaiming},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{xu_initializing_2024,
	title = {Initializing models with larger ones},
	abstract = {Weight initialization plays an important role in neural network training. Widely used initialization methods are proposed and evaluated for networks that are trained from scratch. However, the growing number of pretrained models now offers new opportunities for tackling this classical problem of weight initialization. In this work, we introduce weight selection, a method for initializing smaller models by selecting a subset of weights from a pretrained larger model. This enables the transfer of knowledge from pretrained weights to smaller models. Our experiments demonstrate that weight selection can significantly enhance the performance of small models and reduce their training time. Notably, it can also be used together with knowledge distillation. Weight selection offers a new approach to leverage the power of pretrained models in resource-constrained settings, and we hope it can be a useful tool for training small models in the large-model era. Code is available at https://github.com/OscarXZQ/weight-selection.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Xu, Zhiqiu and Chen, Yanjie and Vishniakov, Kirill and Yin, Yida and Shen, Zhiqiang and Darrell, Trevor and Liu, Lingjie and Liu, Zhuang},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@misc{vishniakov_convnet_2023,
	title = {Convnet vs transformer, supervised vs clip: {Beyond} imagenet accuracy},
	shorttitle = {Convnet vs transformer, supervised vs clip},
	abstract = {Modern computer vision offers a great variety of models to practitioners, and selecting a model from multiple options for specific applications can be challenging. Conventionally, competing model architectures and training protocols are compared by their classification accuracy on ImageNet. However, this single metric does not fully capture performance nuances critical for specialized tasks. In this work, we conduct an in-depth comparative analysis of model behaviors beyond ImageNet accuracy, for both ConvNet and Vision Transformer architectures, each across supervised and CLIP training paradigms. Although our selected models have similar ImageNet accuracies and compute requirements, we find that they differ in many other aspects: types of mistakes, output calibration, transferability, and feature invariance, among others. This diversity in model characteristics, not captured by traditional metrics, highlights the need for more nuanced analysis when choosing among different models. Our code is available at github.com/kirill-vish/Beyond-INet.},
	language = {en},
	author = {Vishniakov, Kirill and Shen, Zhiqiang and Liu, Zhuang},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{leavitt_selectivity_2021,
	title = {Selectivity considered harmful: {Evaluating} the causal impact of class selectivity in {DNNs}},
	abstract = {The properties of individual neurons are often analyzed in order to understand the biological and artiﬁcial neural networks in which they’re embedded. Class selectivity—typically deﬁned as how different a neuron’s responses are across different classes of stimuli or data samples—is commonly used for this purpose. However, it remains an open question whether it is necessary and/or sufﬁcient for deep neural networks (DNNs) to learn class selectivity in individual units. We investigated the causal impact of class selectivity on network function by directly regularizing for or against class selectivity. Using this regularizer to reduce class selectivity across units in convolutional neural networks increased test accuracy by over 2\% in ResNet18 and 1\% in ResNet50 trained on Tiny ImageNet. For ResNet20 trained on CIFAR10 we could reduce class selectivity by a factor of 2.5 with no impact on test accuracy, and reduce it nearly to zero with only a small (∼2\%) drop in test accuracy. In contrast, regularizing to increase class selectivity signiﬁcantly decreased test accuracy across all models and datasets. These results indicate that class selectivity in individual units is neither sufﬁcient nor strictly necessary, and can even impair DNN performance. They also encourage caution when focusing on the properties of single units as representative of the mechanisms by which DNNs function.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Leavitt, Matthew L and Morcos, Ari S},
	year = {2021},
}

@misc{leavitt_linking_2021,
	title = {Linking average- and worst-case perturbation robustness via class selectivity and dimensionality},
	abstract = {Representational sparsity is known to affect robustness to input perturbations in deep neural networks (DNNs), but less is known about how the semantic content of representations affects robustness. Class selectivity—the variability of a unit’s responses across data classes or dimensions—is one way of quantifying the sparsity of semantic representations. Given recent evidence that class selectivity may not be necessary for, and in some cases can impair generalization, we investigate whether it also confers robustness (or vulnerability) to perturbations of input data. We found that networks regularized to have lower levels of class selectivity were more robust to average-case (naturalistic) perturbations, while networks with higher class selectivity are more vulnerable. In contrast, class selectivity increases robustness to multiple types of worst-case (i.e. white box adversarial) perturbations, suggesting that while decreasing class selectivity is helpful for average-case perturbations, it is harmful for worst-case perturbations. To explain this difference, we studied the dimensionality of the networks’ representations: we found that the dimensionality of early-layer representations is inversely proportional to a network’s class selectivity, and that adversarial samples cause a larger increase in early-layer dimensionality than corrupted samples. Furthermore, the input-unit gradient is more variable across samples and units in high-selectivity networks compared to low-selectivity networks. These results lead to the conclusion that units participate more consistently in low-selectivity regimes compared to high-selectivity regimes, effectively creating a larger attack surface and hence vulnerability to worst-case perturbations.},
	language = {en},
	author = {Leavitt, Matthew L. and Morcos, Ari},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@misc{maennel_gradient_2018,
	title = {Gradient descent quantizes {ReLU} network features},
	abstract = {Deep neural networks are often trained in the over-parametrized regime (i.e. with far more parameters than training examples), and understanding why the training converges to solutions that generalize remains an open problem Zhang et al. [2017].},
	language = {en},
	author = {Maennel, Hartmut and Bousquet, Olivier and Gelly, Sylvain},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{min_early_2024,
	title = {Early neuron alignment in two-layer {ReLU} networks with small initialization},
	abstract = {This paper studies the problem of training a two-layer ReLU network for binary classification using gradient flow with small initialization. We consider a training dataset with well-separated input vectors: Any pair of input data with the same label are positively correlated, and any pair with different labels are negatively correlated. Our analysis shows that, during the early phase of training, neurons in the first layer try to align with either the positive data or the negative data, depending on its corresponding weight on the second layer. A careful analysis of the neurons' directional dynamics allows us to provide an \${\textbackslash}mathcal\{O\}({\textbackslash}frac\{{\textbackslash}log n\}\{{\textbackslash}sqrt\{{\textbackslash}mu\}\})\$ upper bound on the time it takes for all neurons to achieve good alignment with the input data, where \$n\$ is the number of data points and \${\textbackslash}mu\$ measures how well the data are separated. After the early alignment phase, the loss converges to zero at a \${\textbackslash}mathcal\{O\}({\textbackslash}frac\{1\}\{t\})\$ rate, and the weight matrix on the first layer is approximately low-rank. Numerical experiments on the MNIST dataset illustrate our theoretical findings.},
	language = {en},
	author = {Min, Hancheng and Mallada, Enrique and Vidal, René},
	year = {2024},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{boursier_gradient_2022,
	title = {Gradient flow dynamics of shallow relu networks for square loss and orthogonal inputs},
	volume = {35},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Boursier, Etienne and Pillaud-Vivien, Loucas and Flammarion, Nicolas},
	year = {2022},
	pages = {20105--20118},
}

@inproceedings{phuong_inductive_2021,
	title = {The inductive bias of {ReLU} networks on orthogonally separable data},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Phuong, Mary and Lampert, Christoph H.},
	year = {2021},
}

@inproceedings{wang_understanding_2023,
	title = {Understanding multi-phase optimization dynamics and rich nonlinear behaviors of {ReLU} networks},
	abstract = {The training process of ReLU neural networks often exhibits complicated nonlinear phenomena. The nonlinearity of models and non-convexity of loss pose significant challenges for theoretical analysis. Therefore, most previous theoretical works on the optimization dynamics of neural networks focus either on local analysis (like the end of training) or approximate linear models (like Neural Tangent Kernel). In this work, we conduct a complete theoretical characterization of the training process of a two-layer ReLU network trained by Gradient Flow on a linearly separable data. In this specific setting, our analysis captures the whole optimization process starting from random initialization to final convergence. Despite the relatively simple model and data that we studied, we reveal four different phases from the whole training process showing a general simplifying-to-complicating learning trend. Specific nonlinear behaviors can also be precisely identified and captured theoretically, such as initial condensation, saddle-to-plateau dynamics, plateau escape, changes of activation patterns, learning with increasing complexity, etc.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Wang, Mingze and Ma, Chao},
	year = {2023},
}

@misc{boursier_early_2024,
	title = {Early alignment in two-layer networks training is a two-edged sword},
	abstract = {Training neural networks with first order optimisation methods is at the core of the empirical success of deep learning. The scale of initialisation is a crucial factor, as small initialisations are generally associated to a feature learning regime, for which gradient descent is implicitly biased towards simple solutions. This work provides a general and quantitative description of the early alignment phase, originally introduced by Maennel et al. (2018). For small initialisation and one hidden ReLU layer networks, the early stage of the training dynamics leads to an alignment of the neurons towards key directions. This alignment induces a sparse representation of the network, which is directly related to the implicit bias of gradient flow at convergence. This sparsity inducing alignment however comes at the expense of difficulties in minimising the training objective: we also provide a simple data example for which overparameterised networks fail to converge towards global minima and only converge to a spurious stationary point instead.},
	language = {en},
	author = {Boursier, Etienne and Flammarion, Nicolas},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{liu_bad_2020,
	title = {Bad global minima exist and {SGD} can reach them},
	abstract = {Several works have aimed to explain why overparameterized neural networks generalize well when trained by Stochastic Gradient Descent (SGD). The consensus explanation that has emerged credits the randomized nature of SGD for the bias of the training process towards low-complexity models and, thus, for implicit regularization. We take a careful look at this explanation in the context of image classiﬁcation with common deep neural network architectures. We ﬁnd that if we do not regularize explicitly, then SGD can be easily made to converge to poorlygeneralizing, high-complexity models: all it takes is to ﬁrst train on a random labeling on the data, before switching to properly training with the correct labels. In contrast, we ﬁnd that in the presence of explicit regularization, pretraining with random labels has no detrimental effect on SGD. We believe that our results give evidence that explicit regularization plays a far more important role in the success of overparameterized neural networks than what has been understood until now. Speciﬁcally, by penalizing complicated models independently of their ﬁt to the data, regularization affects training dynamics also far away from optima, making simple models that ﬁt the data well discoverable by local methods, such as SGD.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Liu, Shengchao and Papailiopoulos, Dimitris and Achlioptas, Dimitris},
	year = {2020},
	pages = {8543--8552},
}

@inproceedings{dai_instructblip_2023,
	title = {Instructblip: {Towards} general-purpose vision-language models with instruction tuning},
	abstract = {Large-scale pre-training and instruction tuning have been successful at creating general-purpose language models with broad competence. However, building general-purpose vision-language models is challenging due to the rich input distributions and task diversity resulting from the additional visual input. Although vision-language pretraining has been widely studied, vision-language instruction tuning remains under-explored. In this paper, we conduct a systematic and comprehensive study on vision-language instruction tuning based on the pretrained BLIP-2 models. We gather 26 publicly available datasets, covering a wide variety of tasks and capabilities, and transform them into instruction tuning format. Additionally, we introduce an instruction-aware Query Transformer, which extracts informative features tailored to the given instruction. Trained on 13 held-in datasets, InstructBLIP attains state-of-the-art zero-shot performance across all 13 held-out datasets, substantially outperforming BLIP-2 and larger Flamingo models. Our models also lead to state-of-the-art performance when finetuned on individual downstream tasks (e.g., 90.7\% accuracy on ScienceQA questions with image contexts). Furthermore, we qualitatively demonstrate the advantages of InstructBLIP over concurrent multimodal models. All InstructBLIP models are open-source.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dai, Wenliang and Li, Junnan and Li, Dongxu and Tiong, Anthony Meng Huat and Zhao, Junqi and Wang, Weisheng and Li, Boyang and Fung, Pascale and Hoi, Steven},
	year = {2023},
}

@article{gu_mamba_2023,
	title = {Mamba: {Linear}-time sequence modeling with selective state spaces},
	journal = {arXiv preprint arXiv:2312.00752},
	author = {Gu, Albert and Dao, Tri},
	year = {2023},
}

@misc{tong_eyes_2024,
	title = {Eyes wide shut? {Exploring} the visual shortcomings of multimodal {LLMs}},
	shorttitle = {Eyes wide shut?},
	abstract = {Is vision good enough for language? Recent advancements in multimodal models primarily stem from the powerful reasoning abilities of large language models (LLMs). However, the visual component typically depends only on the instance-level contrastive language-image pre-training (CLIP). Our research reveals that the visual capabilities in recent multimodal LLMs (MLLMs) still exhibit systematic shortcomings. To understand the roots of these errors, we explore the gap between the visual embedding space of CLIP and vision-only self-supervised learning. We identify ''CLIP-blind pairs'' - images that CLIP perceives as similar despite their clear visual differences. With these pairs, we construct the Multimodal Visual Patterns (MMVP) benchmark. MMVP exposes areas where state-of-the-art systems, including GPT-4V, struggle with straightforward questions across nine basic visual patterns, often providing incorrect answers and hallucinated explanations. We further evaluate various CLIP-based vision-and-language models and found a notable correlation between visual patterns that challenge CLIP models and those problematic for multimodal LLMs. As an initial effort to address these issues, we propose a Mixture of Features (MoF) approach, demonstrating that integrating vision self-supervised learning features with MLLMs can significantly enhance their visual grounding capabilities. Together, our research suggests visual representation learning remains an open challenge, and accurate visual grounding is crucial for future successful multimodal systems.},
	language = {en},
	author = {Tong, Shengbang and Liu, Zhuang and Zhai, Yuexiang and Ma, Yi and LeCun, Yann and Xie, Saining},
	year = {2024},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{verma_mysterious_2024,
	title = {Mysterious projections: {Multimodal} {LLMs} gain domain-specific visual capabilities without richer cross-modal projections},
	shorttitle = {Mysterious projections},
	abstract = {Multimodal large language models (MLLMs) like LLaVA and GPT-4(V) enable general-purpose conversations about images with the language modality. As off-the-shelf MLLMs may have limited capabilities on images from domains like dermatology and agriculture, they must be fine-tuned to unlock domain-specific applications. The prevalent architecture of current open-source MLLMs comprises two major modules: an image-language (cross-modal) projection network and a large language model. It is desirable to understand the roles of these two modules in modeling domain-specific visual attributes to inform the design of future models and streamline the interpretability efforts on the current models. To this end, via experiments on 4 datasets and under 2 fine-tuning settings, we find that as the MLLM is fine-tuned, it indeed gains domain-specific visual capabilities, but the updates do not lead to the projection extracting relevant domain-specific visual attributes. Our results indicate that the domain-specific visual attributes are modeled by the LLM, even when only the projection is fine-tuned. Through this study, we offer a potential reinterpretation of the role of cross-modal projections in MLLM architectures. Projection webpage: https://claws-lab.github.io/projection-in-MLLMs/},
	language = {en},
	journal = {arXiv preprint arXiv:2402.16832},
	author = {Verma, Gaurav and Choi, Minje and Sharma, Kartik and Watson-Daniels, Jamelle and Oh, Sejoon and Kumar, Srijan},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
}

@article{zhao_galore_2024,
	title = {Galore: {Memory}-efficient {LLM} training by gradient low-rank projection},
	shorttitle = {Galore},
	abstract = {Training Large Language Models (LLMs) presents significant memory challenges, predominantly due to the growing size of weights and optimizer states. Common memory-reduction approaches, such as low-rank adaptation (LoRA), add a trainable low-rank matrix to the frozen pre-trained weight in each layer, reducing trainable parameters and optimizer states. However, such approaches typically underperform training with full-rank weights in both pre-training and fine-tuning stages since they limit the parameter search to a low-rank subspace and alter the training dynamics, and further, may require full-rank warm start. In this work, we propose Gradient Low-Rank Projection (GaLore), a training strategy that allows full-parameter learning but is more memoryefficient than common low-rank adaptation methods such as LoRA. Our approach reduces memory usage by up to 65.5\% in optimizer states while maintaining both efficiency and performance for pre-training on LLaMA 1B and 7B architectures with C4 dataset with up to 19.7B tokens, and on fine-tuning RoBERTa on GLUE tasks. Our 8-bit GaLore further reduces optimizer memory by up to 82.5\% and total training memory by 63.3\%, compared to a BF16 baseline. Notably, we demonstrate, for the first time, the feasibility of pre-training a 7B model on consumer GPUs with 24GB memory (e.g., NVIDIA RTX 4090) without model parallel, checkpointing, or offloading strategies.},
	language = {en},
	journal = {arXiv preprint arXiv:2403.03507},
	author = {Zhao, Jiawei and Zhang, Zhenyu and Chen, Beidi and Wang, Zhangyang and Anandkumar, Anima and Tian, Yuandong},
	year = {2024},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{morcos_importance_2018,
	title = {On the importance of single directions for generalization},
	abstract = {Despite their ability to memorize large datasets, deep neural networks often achieve good generalization performance. However, the differences between the learned solutions of networks which generalize and those which do not remain unclear. Additionally, the tuning properties of single directions (deﬁned as the activation of a single unit or some linear combination of units in response to some input) have been highlighted, but their importance has not been evaluated. Here, we connect these lines of inquiry to demonstrate that a network’s reliance on single directions is a good predictor of its generalization performance, across networks trained on datasets with different fractions of corrupted labels, across ensembles of networks trained on datasets with unmodiﬁed labels, across different hyperparameters, and over the course of training. While dropout only regularizes this quantity up to a point, batch normalization implicitly discourages single direction reliance, in part by decreasing the class selectivity of individual units. Finally, we ﬁnd that class selectivity is a poor predictor of task importance, suggesting not only that networks which generalize well minimize their dependence on individual units by reducing their selectivity, but also that individually selective units may not be necessary for strong network performance.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Morcos, Ari S. and Barrett, David G. T. and Rabinowitz, Neil C. and Botvinick, Matthew},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@article{olah_zoom_2020,
	title = {Zoom {In}: {An} {Introduction} to {Circuits}},
	volume = {5},
	issn = {2476-0757},
	shorttitle = {Zoom {In}},
	doi = {10.23915/distill.00024.001},
	abstract = {By studying the connections between neurons, we can find meaningful algorithms in the weights of neural networks.},
	language = {en},
	number = {3},
	journal = {Distill},
	author = {Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
	year = {2020},
	pages = {e00024.001},
}

@misc{choi_autoft_2024,
	title = {{AutoFT}: {Learning} an objective for robust fine-tuning},
	shorttitle = {Autoft},
	abstract = {Foundation models encode rich representations that can be adapted to downstream tasks by finetuning. However, fine-tuning a model on one data distribution often degrades performance under distribution shifts. Current approaches to robust fine-tuning use hand-crafted regularization techniques to constrain the fine-tuning process towards the pretrained model. Yet, it is hard to specify how to adapt relevant characteristics of the foundation model during fine-tuning, as this depends on how the pre-training, fine-tuning, and test data distributions relate to each other. We propose AUTOFT, a data-driven approach for robust fine-tuning. Given a task, AUTOFT searches for a fine-tuning procedure that enhances out-ofdistribution (OOD) generalization. Specifically, AUTOFT uses bi-level optimization to search for an objective function and hyperparameters that maximize post-adaptation performance on a small OOD validation set. We evaluate AUTOFT on nine natural distribution shifts. Our experiments show that AUTOFT significantly improves generalization to OOD inputs, outperforming existing robust fine-tuning methods. Notably, AUTOFT achieves a new state-of-the-art on the WILDS iWildCam and FMoW benchmarks, outperforming the previous best methods by 6.0\% and 1.5\%, respectively.},
	language = {en},
	author = {Choi, Caroline and Lee, Yoonho and Chen, Annie and Zhou, Allan and Raghunathan, Aditi and Finn, Chelsea},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@misc{tian_visual_2024,
	title = {Visual autoregressive modeling: {Scalable} image generation via next-scale prediction},
	shorttitle = {Visual autoregressive modeling},
	abstract = {We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine “next-scale prediction” or “next-resolution prediction”, diverging from the standard raster-scan “next-token prediction”. This simple, intuitive methodology allows autoregressive (AR) transformers to learn visual distributions fast and can generalize well: VAR, for the first time, makes GPT-style AR models surpass diffusion transformers in image generation. On ImageNet 256×256 benchmark, VAR significantly improve AR baseline by improving Fréchet inception distance (FID) from 18.65 to 1.80, inception score (IS) from 80.4 to 356.4, with 20× faster inference speed. It is also empirically verified that VAR outperforms the Diffusion Transformer (DiT) in multiple dimensions including image quality, inference speed, data efficiency, and scalability. Scaling up VAR models exhibits clear power-law scaling laws similar to those observed in LLMs, with linear correlation coefficients near −0.998 as solid evidence. VAR further showcases zero-shot generalization ability in downstream tasks including image in-painting, out-painting, and editing. These results suggest VAR has initially emulated the two important properties of LLMs: Scaling Laws and zero-shot generalization. We have released all models and codes to promote the exploration of AR/VAR models for visual generation and unified learning.},
	language = {en},
	author = {Tian, Keyu and Jiang, Yi and Yuan, Zehuan and Peng, Bingyue and Wang, Liwei},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{sun_clip_2023,
	title = {{CLIP} as {RNN}: {Segment} countless visual concepts without training endeavor},
	shorttitle = {Clip as rnn},
	abstract = {VOC, COCO Object, and Pascal Context.},
	language = {en},
	journal = {arXiv preprint arXiv:2312.07661},
	author = {Sun, Shuyang and Li, Runjia and Torr, Philip and Gu, Xiuye and Li, Siyang},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language, Computer Science - Multimedia},
}

@article{zhang_llama-adapter_2023,
	title = {{LLaMA}-adapter: {Efficient} fine-tuning of language models with zero-init attention},
	shorttitle = {Llama-adapter},
	abstract = {We present LLaMA-Adapter, a lightweight adaption method to efficiently finetune LLaMA into an instruction-following model. Using 52K self-instruct demonstrations, LLaMA-Adapter only introduces 1.2M learnable parameters upon the frozen LLaMA 7B model, and costs less than one hour for fine-tuning on 8 A100 GPUs. Specifically, we adopt a set of learnable adaption prompts, and prepend them to the word tokens at higher transformer layers. Then, a zero-initialized attention mechanism with zero gating is proposed, which adaptively injects the new instructional cues into LLaMA, while effectively preserves its pre-trained knowledge. With our efficient training, LLaMA-Adapter can generate high-quality responses, comparable to Alpaca with fully fine-tuned 7B parameters. Besides language commands, our approach can be simply extended to multi-modal instructions for learning image-conditioned LLaMA model, which achieves superior reasoning performance on ScienceQA and COCO Caption benchmarks. Furthermore, we also evaluate the zero-initialized attention mechanism for fine-tuning other pre-trained models (ViT, RoBERTa) on traditional vision and language tasks, demonstrating the superior generalization capacity of our approach. Code is released at https://github.com/OpenGVLab/LLaMA-Adapter.},
	language = {en},
	journal = {arXiv preprint arXiv:2303.16199},
	author = {Zhang, Renrui and Han, Jiaming and Liu, Chris and Gao, Peng and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Qiao, Yu},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language, Computer Science - Multimedia},
}

@inproceedings{heusel_gans_2017,
	title = {{GANs} trained by a two time-scale update rule converge to a local {Nash} equilibrium},
	volume = {30},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
	year = {2017},
}

@article{liu_improved_2023,
	title = {Improved baselines with visual instruction tuning},
	language = {en},
	journal = {arXiv preprint arXiv:2310.03744},
	author = {Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
}

@article{allen-zhu_physics_2023,
	title = {Physics of language models: {Part} 3.2, knowledge manipulation},
	shorttitle = {Physics of language models},
	abstract = {Language models can store vast amounts of factual knowledge, but their ability to use this knowledge for logical reasoning remains questionable. This paper explores a language model's ability to manipulate its stored knowledge during inference. We focus on four manipulation types: retrieval (e.g., "What is person A's attribute X"), classification (e.g., "Is A's attribute X even or odd?"), comparison (e.g., "Is A greater than B in attribute X?") and inverse search (e.g., "Which person's attribute X equals T?") We observe that pre-trained language models like GPT2/3/4 excel in knowledge retrieval but struggle with simple classification or comparison tasks unless Chain of Thoughts (CoTs) are employed during both training and inference. They also perform poorly in inverse knowledge search, irrespective of the prompts. Our primary contribution is a synthetic dataset for a controlled experiment that confirms these inherent weaknesses: a language model cannot efficiently manipulate knowledge from pre-training data, even when such knowledge is perfectly stored and fully extractable in the models, and despite adequate instruct fine-tuning.},
	language = {en},
	journal = {arXiv preprint arXiv:2309.14402},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{allen-zhu_physics_2023-1,
	title = {Physics of language models: {Part} 3.1, knowledge storage and extraction},
	shorttitle = {Physics of language models},
	abstract = {Large language models (LLMs) can store a vast amount of world knowledge, often extractable via question-answering (e.g., “What is Abraham Lincoln’s birthday?”). However, do they answer such questions based on exposure to similar questions during training (i.e., cheating), or by genuinely learning to extract knowledge from sources like Wikipedia? In this paper, we investigate this issue using a controlled biography dataset. We find a strong correlation between the model’s ability to extract knowledge and various diversity measures of the training data. Essentially, for knowledge to be reliably extracted, it must be sufficiently augmented (e.g., through paraphrasing, sentence shuffling) during pretraining. Without such augmentation, knowledge may be memorized but not extractable, leading to 0\% accuracy, regardless of subsequent instruction fine-tuning.},
	language = {en},
	journal = {arXiv preprint arXiv:2309.14316},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{allen-zhu_physics_2023-2,
	title = {Physics of language models: {Part} 1, context-free grammar},
	shorttitle = {Physics of language models},
	abstract = {We design controlled experiments to study how generative language models, like GPT, learn context-free grammars (CFGs) — diverse language systems with a tree-like structure capturing many aspects of natural languages, programs, and logics. CFGs are as hard as pushdown automata, and can be ambiguous so that verifying if a string satisfies the rules requires dynamic programming. We construct synthetic data and demonstrate that even for difficult (long and ambiguous) CFGs, pre-trained transformers can learn to generate sentences with near-perfect accuracy and impressive diversity.},
	language = {en},
	journal = {arXiv preprint arXiv:2305.13673},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{oquab_dinov2_2023,
	title = {{DINOv2}: {Learning} robust visual features without supervision},
	journal = {Transactions on Machine Learning Research},
	author = {Oquab, Maxime and Darcet, Timothée and Moutakanni, Théo and Vo, Huy V. and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and HAZIZA, Daniel and Massa, Francisco and El-Nouby, Alaaeldin},
	year = {2023},
}

@inproceedings{zhou_ibot_2022,
	title = {{iBOT}: {Image} {BERT} pre-training with online tokenizer},
	shorttitle = {{iBOT}},
	abstract = {The success of language Transformers is primarily attributed to the pretext task of masked language modeling (MLM) (Devlin et al., 2019), where texts are ﬁrst tokenized into semantically meaningful pieces. In this work, we study masked image modeling (MIM) and indicate the advantages and challenges of using a semantically meaningful visual tokenizer. We present a self-supervised framework iBOT that can perform masked prediction with an online tokenizer. Speciﬁcally, we perform self-distillation on masked patch tokens and take the teacher network as the online tokenizer, along with self-distillation on the class token to acquire visual semantics. The online tokenizer is jointly learnable with the MIM objective and dispenses with a multi-stage training pipeline where the tokenizer needs to be pretrained beforehand. We show the prominence of iBOT by achieving an 82.3\% linear probing accuracy and an 87.8\% ﬁne-tuning accuracy evaluated on ImageNet1K. Beyond the state-of-the-art image classiﬁcation results, we underline emerging local semantic patterns, which helps the models to obtain strong robustness against common corruptions and achieve leading results on dense downstream tasks, e.g., object detection, instance segmentation, and semantic segmentation. The code and models are publicly available at https://github.com/bytedance/ibot.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Zhou, Jinghao and Wei, Chen and Wang, Huiyu and Shen, Wei and Xie, Cihang and Yuille, Alan and Kong, Tao},
	year = {2022},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{reed_generalist_2022,
	title = {A generalist agent},
	journal = {Transactions on Machine Learning Research},
	author = {Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias},
	year = {2022},
}

@inproceedings{zhou_object_2015,
	title = {Object detectors emerge in deep scene cnns},
	abstract = {With the success of new computational architectures for visual processing, such as convolutional neural networks (CNN) and access to image databases with millions of labeled examples (e.g., ImageNet, Places), the state of the art in computer vision is advancing rapidly. One important factor for continued progress is to understand the representations that are learned by the inner layers of these deep architectures. Here we show that object detectors emerge from training CNNs to perform scene classiﬁcation. As scenes are composed of objects, the CNN for scene classiﬁcation automatically discovers meaningful objects detectors, representative of the learned scene categories. With object detectors emerging as a result of learning to recognize scenes, our work demonstrates that the same network can perform both scene recognition and object localization in a single forward-pass, without ever having been explicitly taught the notion of objects.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
	year = {2015},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@article{radford_learning_2017,
	title = {Learning to generate reviews and discovering sentiment},
	abstract = {We explore the properties of byte-level recurrent language models. When given sufﬁcient amounts of capacity, training data, and compute time, the representations learned by these models include disentangled features corresponding to high-level concepts. Speciﬁcally, we ﬁnd a single unit which performs sentiment analysis. These representations, learned in an unsupervised manner, achieve state of the art on the binary subset of the Stanford Sentiment Treebank. They are also very data efﬁcient. When using only a handful of labeled examples, our approach matches the performance of strong baselines trained on full datasets. We also demonstrate the sentiment unit has a direct inﬂuence on the generative process of the model. Simply ﬁxing its value to be positive or negative generates samples with the corresponding positive or negative sentiment.},
	language = {en},
	journal = {arXiv:1704.01444},
	author = {Radford, Alec and Jozefowicz, Rafal and Sutskever, Ilya},
	year = {2017},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computation and Language},
}

@article{olah_building_2018,
	title = {The building blocks of interpretability},
	volume = {3},
	issn = {2476-0757},
	doi = {10.23915/distill.00010},
	abstract = {Interpretability techniques are normally studied in isolation. We explore the powerful interfaces that arise when you combine them -- and the rich structure of this combinatorial space.},
	language = {en},
	number = {3},
	journal = {Distill},
	author = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
	year = {2018},
	pages = {e10},
}

@article{chen_fast_2015,
	title = {Fast low-rank estimation by projected gradient descent: {General} statistical and algorithmic guarantees},
	shorttitle = {Fast low-rank estimation by projected gradient descent},
	abstract = {Optimization problems with rank constraints arise in many applications, including matrix regression, structured PCA, matrix completion and matrix decomposition problems. An attractive heuristic for solving such problems is to factorize the low-rank matrix, and to run projected gradient descent on the nonconvex factorized optimization problem. The goal of this problem is to provide a general theoretical framework for understanding when such methods work well, and to characterize the nature of the resulting ﬁxed point. We provide a simple set of conditions under which projected gradient descent, when given a suitable initialization, converges geometrically to a statistically useful solution. Our results are applicable even when the initial solution is outside any region of local convexity, and even when the problem is globally concave. Working in a non-asymptotic framework, we show that our conditions are satisﬁed for a wide range of concrete models, including matrix regression, structured PCA, matrix completion with real and quantized observations, matrix decomposition, and graph clustering problems. Simulation results show excellent agreement with the theoretical predictions.},
	language = {en},
	journal = {arXiv preprint arXiv:1509.03025},
	author = {Chen, Yudong and Wainwright, Martin J.},
	year = {2015},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Statistics Theory},
}

@article{chen_non-convex_2019,
	title = {Non-convex projected gradient descent for generalized low-rank tensor regression},
	volume = {20},
	number = {5},
	journal = {Journal of Machine Learning Research},
	author = {Chen, Han and Raskutti, Garvesh and Yuan, Ming},
	year = {2019},
	pages = {1--37},
}

@inproceedings{kumar_calibrated_2022,
	title = {Calibrated ensembles can mitigate accuracy tradeoffs under distribution shift},
	isbn = {2640-3498},
	booktitle = {Uncertainty in {Artificial} {Intelligence}},
	author = {Kumar, Ananya and Ma, Tengyu and Liang, Percy and Raghunathan, Aditi},
	year = {2022},
	pages = {1041--1051},
}

@article{ma_understanding_2023,
	title = {Understanding the robustness difference between stochastic gradient descent and adaptive gradient methods},
	journal = {Transactions on Machine Learning Research},
	author = {Ma, Avery and Pan, Yangchen and Farahmand, Amir-massoud},
	year = {2023},
}

@inproceedings{cohen_certified_2019,
	title = {Certified adversarial robustness via randomized smoothing},
	isbn = {2640-3498},
	booktitle = {international conference on machine learning},
	author = {Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
	year = {2019},
	pages = {1310--1320},
}

@inproceedings{tramer_ensemble_2018,
	title = {Ensemble adversarial training: {Attacks} and defenses},
	shorttitle = {Ensemble adversarial training},
	abstract = {Adversarial examples are perturbed inputs designed to fool machine learning models. Adversarial training injects such examples into training data to increase robustness. To scale this technique to large datasets, perturbations are crafted using fast single-step methods that maximize a linear approximation of the model’s loss. We show that this form of adversarial training converges to a degenerate global minimum, wherein small curvature artifacts near the data points obfuscate a linear approximation of the loss. The model thus learns to generate weak perturbations, rather than defend against strong ones. As a result, we ﬁnd that adversarial training remains vulnerable to black-box attacks, where we transfer perturbations computed on undefended models, as well as to a powerful novel single-step attack that escapes the non-smooth vicinity of the input data via a small random step.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Tramèr, Florian and Kurakin, Alexey and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Cryptography and Security},
}

@inproceedings{eykholt_robust_2018,
	address = {Salt Lake City, UT, USA},
	title = {Robust physical-world attacks on deep learning visual classification},
	isbn = {978-1-5386-6420-9},
	doi = {10.1109/CVPR.2018.00175},
	abstract = {Recent studies show that the state-of-the-art deep neural networks (DNNs) are vulnerable to adversarial examples, resulting from small-magnitude perturbations added to the input. Given that that emerging physical systems are using DNNs in safety-critical situations, adversarial examples could mislead these systems and cause dangerous situations. Therefore, understanding adversarial examples in the physical world is an important step towards developing resilient learning algorithms. We propose a general attack algorithm, Robust Physical Perturbations (RP2), to generate robust visual adversarial perturbations under different physical conditions. Using the real-world case of road sign classiﬁcation, we show that adversarial examples generated using RP2 achieve high targeted misclassiﬁcation rates against standard-architecture road sign classiﬁers in the physical world under various environmental conditions, including viewpoints. Due to the current lack of a standardized testing method, we propose a two-stage evaluation methodology for robust physical adversarial examples consisting of lab and ﬁeld tests. Using this methodology, we evaluate the efﬁcacy of physical adversarial manipulations on real objects. With a perturbation in the form of only black and white stickers, we attack a real stop sign, causing targeted misclassiﬁcation in 100\% of the images obtained in lab settings, and in 84.8\% of the captured video frames obtained on a moving vehicle (ﬁeld test) for the target classiﬁer.},
	language = {en},
	booktitle = {{CVPR}},
	author = {Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Xiao, Chaowei and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},
	year = {2018},
	pages = {1625--1634},
}

@article{damour_underspecification_2022,
	title = {Underspecification presents challenges for credibility in modern machine learning},
	volume = {23},
	number = {226},
	journal = {Journal of Machine Learning Research},
	author = {D'Amour, Alexander and Heller, Katherine and Moldovan, Dan and Adlam, Ben and Alipanahi, Babak and Beutel, Alex and Chen, Christina and Deaton, Jonathan and Eisenstein, Jacob and Hoffman, Matthew D.},
	year = {2022},
	pages = {1--61},
}

@inproceedings{zhai_sigmoid_2023,
	address = {Paris, France},
	title = {Sigmoid loss for language image pre-training},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350307184},
	doi = {10.1109/ICCV51070.2023.01100},
	abstract = {We propose a simple pairwise sigmoid loss for imagetext pre-training. Unlike standard contrastive learning with softmax normalization, the sigmoid loss operates solely on image-text pairs and does not require a global view of the pairwise similarities for normalization. The sigmoid loss simultaneously allows further scaling up the batch size, while also performing better at smaller batch sizes. With only four TPUv4 chips, we can train a Base CLIP model at 4 k batch size and a Large LiT model at 20 k batch size, the latter achieves 84.5\% ImageNet zero-shot accuracy in two days. This disentanglement of the batch size from the loss further allows us to study the impact of examples vs pairs and negative to positive ratio. Finally, we push the batch size to the extreme, up to one million, and ﬁnd that the beneﬁts of growing batch size quickly diminish, with a more reasonable batch size of 32 k being sufﬁcient. We hope our research motivates further explorations in improving the quality and efﬁciency of language-image pre-training.},
	language = {en},
	booktitle = {{ICCV}},
	author = {Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
	year = {2023},
	pages = {11941--11952},
}

@misc{karamcheti_prismatic_2024,
	title = {Prismatic {VLMs}: {Investigating} the design space of visually-conditioned language models},
	shorttitle = {Prismatic vlms},
	abstract = {Visually-conditioned language models (VLMs) have seen growing adoption in applications such as visual dialogue, scene understanding, and robotic task planning; adoption that has fueled a wealth of new models such as LLaVa, InstructBLIP, and PaLI-3. Despite the volume of new releases, key design decisions around image preprocessing, architecture, and optimization are underexplored, making it challenging to understand what factors account for model performance – a challenge further complicated by the lack of objective, consistent evaluations. To address these gaps, we first compile a suite of standardized evaluations spanning visual question answering, object localization from language, and targeted challenge sets that probe properties such as hallucination; evaluations that provide calibrated, finegrained insight into a VLM’s capabilities. Second, we rigorously investigate VLMs along key design axes, including pretrained visual representations and quantifying the tradeoffs of using base vs. instruct-tuned language models, amongst others. We couple our analysis with three resource contributions: (1) a unified framework for evaluating VLMs, (2) optimized, flexible code for VLM training, and (3) checkpoints for all models, including a family of VLMs at the 7-13B scale that strictly outperform InstructBLIP and LLaVa v1.5, the state-of-the-art in open-source VLMs.},
	language = {en},
	author = {Karamcheti, Siddharth and Nair, Suraj and Balakrishna, Ashwin and Liang, Percy and Kollar, Thomas and Sadigh, Dorsa},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Computation and Language},
}

@inproceedings{bao_beit_2022,
	title = {Beit: {BERT} pre-training of image transformers},
	shorttitle = {Beit},
	abstract = {We introduce a self-supervised vision representation model BEIT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT [DCLT19] developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Speciﬁcally, each image has two views in our pre-training, i.e., image patches (such as 16×16 pixels), and visual tokens (i.e., discrete tokens). We ﬁrst “tokenize” the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEIT, we directly ﬁne-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classiﬁcation and semantic segmentation show that our model achieves competitive results with previous pre-training methods.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{wang_image_2023,
	title = {Image as a foreign language: {Beit} pretraining for vision and vision-language tasks},
	booktitle = {{CVPR}},
	author = {Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit},
	year = {2023},
	pages = {19175--19186},
}

@book{horn_matrix_2012,
	title = {Matrix analysis},
	isbn = {1-139-78888-4},
	author = {Horn, Roger A. and Johnson, Charles R.},
	year = {2012},
}

@inproceedings{qi_fine-tuning_2024,
	title = {Fine-tuning aligned language models compromises safety, even when users do not intend to!},
	abstract = {Optimizing large language models (LLMs) for downstream use cases often involves the customization of pre-trained LLMs through further fine-tuning. Meta's open-source release of Llama models and OpenAI's APIs for fine-tuning GPT-3.5 Turbo on customized datasets accelerate this trend. But, what are the safety costs associated with such customized fine-tuning? While existing safety alignment techniques restrict harmful behaviors of LLMs at inference time, they do not cover safety risks when fine-tuning privileges are extended to end-users. Our red teaming studies find that the safety alignment of LLMs can be compromised by fine-tuning with only a few adversarially designed training examples. For instance, we jailbreak GPT-3.5 Turbo's safety guardrails by fine-tuning it on only 10 such examples at a cost of less than \$0.20 via OpenAI's APIs, making the model responsive to nearly any harmful instructions. Disconcertingly, our research also reveals that, even without malicious intent, simply fine-tuning with benign and commonly used datasets can also inadvertently degrade the safety alignment of LLMs, though to a lesser extent. These findings suggest that fine-tuning aligned LLMs introduces new safety risks that current safety infrastructures fall short of addressing --- even if a model's initial safety alignment is impeccable, how can it be maintained after customized fine-tuning? We outline and critically analyze potential mitigations and advocate for further research efforts toward reinforcing safety protocols for the customized fine-tuning of aligned LLMs. (This paper contains red-teaming data and model-generated content that can be offensive in nature.)},
	language = {en},
	booktitle = {{ICLR}},
	author = {Qi, Xiangyu and Zeng, Yi and Xie, Tinghao and Chen, Pin-Yu and Jia, Ruoxi and Mittal, Prateek and Henderson, Peter},
	year = {2024},
}

@article{pfau_lets_2024,
	title = {Let's think dot by dot: {Hidden} computation in transformer language models},
	shorttitle = {Let's think dot by dot},
	abstract = {Chain-of-thought responses from language models improve performance across most benchmarks. However, it remains unclear to what extent these performance gains can be attributed to human-like task decomposition or simply the greater computation that additional tokens allow. We show that transformers can use meaningless filler tokens (e.g., '......') in place of a chain of thought to solve two hard algorithmic tasks they could not solve when responding without intermediate tokens. However, we find empirically that learning to use filler tokens is difficult and requires specific, dense supervision to converge. We also provide a theoretical characterization of the class of problems where filler tokens are useful in terms of the quantifier depth of a first-order formula. For problems satisfying this characterization, chain-of-thought tokens need not provide information about the intermediate computational steps involved in multi-token computations. In summary, our results show that additional tokens can provide computational benefits independent of token choice. The fact that intermediate tokens can act as filler tokens raises concerns about large language models engaging in unauditable, hidden computations that are increasingly detached from the observed chain-of-thought tokens.},
	language = {en},
	journal = {arXiv preprint arXiv:2404.15758},
	author = {Pfau, Jacob and Merrill, William and Bowman, Samuel R.},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, I.2.6},
}

@inproceedings{huh_platonic_2024,
	title = {The {Platonic} representation hypothesis},
	abstract = {We argue that representations in AI models, particularly deep networks, are converging. First, we survey many examples of convergence in the literature: over time and across multiple domains, the ways by which different neural networks represent data are becoming more aligned. Next, we demonstrate convergence across data modalities: as vision models and language models get larger, they measure distance between datapoints in a more and more alike way. We hypothesize that this convergence is driving toward a shared statistical model of reality, akin to Plato's concept of an ideal reality. We term such a representation the platonic representation and discuss several possible selective pressures toward it. Finally, we discuss the implications of these trends, their limitations, and counterexamples to our analysis.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Huh, Minyoung and Cheung, Brian and Wang, Tongzhou and Isola, Phillip},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@article{naik_reward_2024,
	title = {Reward centering},
	abstract = {We show that discounted methods for solving continuing reinforcement learning problems can perform significantly better if they center their rewards by subtracting out the rewards’ empirical average. The improvement is substantial at commonly used discount factors and increases further as the discount factor approaches one. In addition, we show that if a problem’s rewards are shifted by a constant, then standard methods perform much worse, whereas methods with reward centering are unaffected. Estimating the average reward is straightforward in the on-policy setting; we propose a slightly more sophisticated method for the off-policy setting. Reward centering is a very general idea, so we expect almost every reinforcementlearning algorithm to benefit by the addition of reward centering.},
	journal = {arXiv preprint arXiv:2405.09999},
	author = {Naik, Abhishek and Wan, Yi and Tomar, Manan and Sutton, Richard S.},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{sundararajan_axiomatic_2017,
	title = {Axiomatic attribution for deep networks},
	isbn = {2640-3498},
	booktitle = {{ICML}},
	author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	year = {2017},
	pages = {3319--3328},
}

@article{wang_cogvlm_2024,
	title = {{CogVLM}: {Visual} expert for pretrained language models},
	shorttitle = {Cogvlm},
	abstract = {We introduce CogVLM, a powerful open-source visual language foundation model. Different from the popular shallow alignment method which maps image features into the input space of language model, CogVLM bridges the gap between the frozen pretrained language model and image encoder by a trainable visual expert module in the attention and FFN layers. As a result, CogVLM enables deep fusion of vision language features without sacrificing any performance on NLP tasks. CogVLM-17B achieves state-of-the-art performance on 10 classic cross-modal benchmarks, including NoCaps, Flicker30k captioning, RefCOCO, RefCOCO+, RefCOCOg, Visual7W, GQA, ScienceQA, VizWiz VQA and TDIUC, and ranks the 2nd on VQAv2, OKVQA, TextVQA, COCO captioning, etc., surpassing or matching PaLI-X 55B. Codes and checkpoints are available at https://github.com/THUDM/CogVLM.},
	language = {en},
	journal = {arXiv preprint arXiv:2311.03079},
	author = {Wang, Weihan and Lv, Qingsong and Yu, Wenmeng and Hong, Wenyi and Qi, Ji and Wang, Yan and Ji, Junhui and Yang, Zhuoyi and Zhao, Lei and Song, Xixuan and Xu, Jiazheng and Xu, Bin and Li, Juanzi and Dong, Yuxiao and Ding, Ming and Tang, Jie},
	year = {2024},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{engels_not_2024,
	title = {Not all language model features are linear},
	abstract = {Recent work has proposed the linear representation hypothesis: that language models perform computation by manipulating one-dimensional representations of concepts (“features”) in activation space. In contrast, we explore whether some language model representations may be inherently multi-dimensional. We begin by developing a rigorous definition of irreducible multi-dimensional features based on whether they can be decomposed into either independent or non-co-occurring lower-dimensional features. Motivated by these definitions, we design a scalable method that uses sparse autoencoders to automatically find multi-dimensional features in GPT-2 and Mistral 7B. These auto-discovered features include strikingly interpretable examples, e.g. circular features representing days of the week and months of the year. We identify tasks where these exact circles are used to solve computational problems involving modular arithmetic in days of the week and months of the year. Finally, we provide evidence that these circular features are indeed the fundamental unit of computation in these tasks with intervention experiments on Mistral 7B and Llama 3 8B, and we find further circular representations by breaking down the hidden states for these tasks into interpretable components.},
	language = {en},
	journal = {arXiv preprint arXiv:2405.14860},
	author = {Engels, Joshua and Liao, Isaac and Michaud, Eric J. and Gurnee, Wes and Tegmark, Max},
	year = {2024},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{deng_robust_2023,
	title = {Robust learning with progressive data expansion against spurious correlation},
	volume = {36},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Deng, Yihe and Yang, Yu and Mirzasoleiman, Baharan and Gu, Quanquan},
	year = {2023},
}

@inproceedings{chen_understanding_2023,
	title = {Understanding and improving feature learning for out-of-distribution generalization},
	abstract = {A common explanation for the failure of out-of-distribution (OOD) generalization is that the model trained with empirical risk minimization (ERM) learns spurious features instead of invariant features. However, several recent studies challenged this explanation and found that deep networks may have already learned sufficiently good features for OOD generalization. Despite the contradictions at first glance, we theoretically show that ERM essentially learns both spurious and invariant features, while ERM tends to learn spurious features faster if the spurious correlation is stronger. Moreover, when fed the ERM learned features to the OOD objectives, the invariant feature learning quality significantly affects the final OOD performance, as OOD objectives rarely learn new features. Therefore, ERM feature learning can be a bottleneck to OOD generalization. To alleviate the reliance, we propose Feature Augmented Training (FeAT), to enforce the model to learn richer features ready for OOD generalization. FeAT iteratively augments the model to learn new features while retaining the already learned features. In each round, the retention and augmentation operations are performed on different subsets of the training data that capture distinct features. Extensive experiments show that FeAT effectively learns richer features thus boosting the performance of various OOD objectives1.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Chen, Yongqiang and Huang, Wei and Zhou, Kaiwen and Bian, Yatao and Han, Bo and Cheng, James},
	year = {2023},
}

@article{gould_successor_2023,
	title = {Successor heads: {Recurring}, interpretable attention heads in the wild},
	shorttitle = {Successor heads},
	abstract = {In this work we present successor heads: attention heads that increment tokens with a natural ordering, such as numbers, months, and days. For example, successor heads increment ‘Monday’ into ‘Tuesday’. We explain the successor head behavior with an approach rooted in mechanistic interpretability, the field that aims to explain how models complete tasks in human-understandable terms. Existing research in this area has struggled to find recurring, mechanistically interpretable language model components beyond small toy models. Further, existing results have led to very little insight to explain the internals of larger models that are used in practice. In this paper, we analyze the behavior of successor heads in large language models (LLMs) and find that they implement abstract representations that are common to different architectures. They form in LLMs with as few as 31 million parameters, and at least as many as 12 billion parameters, such as GPT-2, Pythia, and Llama-2. We find a set of ‘mod 10’ features1 that underlie how successor heads increment in LLMs across different architectures and sizes. We perform vector arithmetic with these features to edit head behavior and provide insights into numeric representations within LLMs. Finally, we study the behavior of successor heads on models’ training data, finding that successor heads are important for the model getting low loss on examples of succession in this dataset. Finally, we interpret some of the other tasks these polysemantic heads perform and discuss the implications of our findings.},
	language = {en},
	journal = {arXiv preprint arXiv:2312.09230},
	author = {Gould, Rhys and Ong, Euan and Ogden, George and Conmy, Arthur},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{heinzerling_monotonic_2024,
	title = {Monotonic representation of numeric properties in language models},
	abstract = {Language models (LMs) can express factual knowledge involving numeric properties such as Karl Popper was born in 1902. However, how this information is encoded in the model's internal representations is not understood well. Here, we introduce a simple method for finding and editing representations of numeric properties such as an entity's birth year. Empirically, we find low-dimensional subspaces that encode numeric properties monotonically, in an interpretable and editable fashion. When editing representations along directions in these subspaces, LM output changes accordingly. For example, by patching activations along a "birthyear" direction we can make the LM express an increasingly late birthyear: Karl Popper was born in 1929, Karl Popper was born in 1957, Karl Popper was born in 1968. Property-encoding directions exist across several numeric properties in all models under consideration, suggesting the possibility that monotonic representation of numeric properties consistently emerges during LM pretraining. Code: https://github.com/bheinzerling/numeric-property-repr},
	language = {en},
	journal = {arXiv preprint arXiv:2403.10381},
	author = {Heinzerling, Benjamin and Inui, Kentaro},
	year = {2024},
	keywords = {Computer Science - Computation and Language},
}

@article{park_linear_2023,
	title = {The linear representation hypothesis and the geometry of large language models},
	abstract = {Informally, the ‘linear representation hypothesis’ is the idea that high-level concepts are represented linearly as directions in some representation space. In this paper, we address two closely related questions: What does “linear representation” actually mean? And, how do we make sense of geometric notions (e.g., cosine similarity or projection) in the representation space? To answer these, we use the language of counterfactuals to give two formalizations of “linear representation”, one in the output (word) representation space, and one in the input (sentence) space. We then prove these connect to linear probing and model steering, respectively. To make sense of geometric notions, we use the formalization to identify a particular (non-Euclidean) inner product that respects language structure in a sense we make precise. Using this causal inner product, we show how to unify all notions of linear representation. In particular, this allows the construction of probes and steering vectors using counterfactual pairs. Experiments with LLaMA-2 demonstrate the existence of linear representations of concepts, the connection to interpretation and control, and the fundamental role of the choice of inner product. Code is available at github.com/KihoPark/linear\_rep\_geometry.},
	language = {en},
	journal = {arXiv preprint arXiv:2311.03658},
	author = {Park, Kiho and Choe, Yo Joong and Veitch, Victor},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{gloeckle_better_2024,
	title = {Better \& faster large language models via multi-token prediction},
	abstract = {Large language models such as GPT and Llama are trained with a next-token prediction loss. In this work, we suggest that training language models to predict multiple future tokens at once results in higher sample efficiency. More specifically, at each position in the training corpus, we ask the model to predict the following n tokens using n independent output heads, operating on top of a shared model trunk. Considering multi-token prediction as an auxiliary training task, we measure improved downstream capabilities with no overhead in training time for both code and natural language models. The method is increasingly useful for larger model sizes, and keeps its appeal when training for multiple epochs. Gains are especially pronounced on generative benchmarks like coding, where our models consistently outperform strong baselines by several percentage points. Our 13B parameter models solves 12 \% more problems on HumanEval and 17 \% more on MBPP than comparable next-token models. Experiments on small algorithmic tasks demonstrate that multi-token prediction is favorable for the development of induction heads and algorithmic reasoning capabilities. As an additional benefit, models trained with 4-token prediction are up to 3 times faster at inference, even with large batch sizes.},
	language = {en},
	journal = {arXiv preprint arXiv:2404.19737},
	author = {Gloeckle, Fabian and Idrissi, Badr Youbi and Rozière, Baptiste and Lopez-Paz, David and Synnaeve, Gabriel},
	year = {2024},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{bender_dangers_2021,
	address = {Virtual Event Canada},
	title = {On the dangers of stochastic parrots: {Can} language models be too big?},
	isbn = {978-1-4503-8309-7},
	shorttitle = {On the dangers of stochastic parrots},
	doi = {10.1145/3442188.3445922},
	abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
	language = {en},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
	year = {2021},
	pages = {610--623},
}

@article{radford_improving_nodate,
	title = {Improving language understanding by generative pre-training},
	abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
	language = {en},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{he_masked_2022,
	title = {Masked autoencoders are scalable vision learners},
	booktitle = {Proceedings of the {IEEE}/{CVF} conference on computer vision and pattern recognition ({CVPR})},
	author = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Dollár, Piotr and Girshick, Ross},
	year = {2022},
	pages = {16000--16009},
}

@article{gao_scaling_nodate,
	title = {Scaling and evaluating sparse autoencoders},
	language = {en},
	author = {Gao, Leo and Goh, Gabriel and Sutskever, Ilya},
}

@article{harun_what_2024,
	title = {What variables affect out-of-distribution generalization in pretrained models?},
	abstract = {Embeddings produced by pre-trained deep neural networks (DNNs) are widely used; however, their efficacy for downstream tasks can vary widely. We study the factors influencing out-of-distribution (OOD) generalization of pre-trained DNN embeddings through the lens of the tunnel effect hypothesis, which suggests deeper DNN layers compress representations and hinder OOD performance. Contrary to earlier work, we find the tunnel effect is not universal. Based on 10,584 linear probes, we study the conditions that mitigate the tunnel effect by varying DNN architecture, training dataset, image resolution, and augmentations. We quantify each variable’s impact using a novel SHAP analysis. Our results emphasize the danger of generalizing findings from toy datasets to broader contexts.},
	language = {en},
	journal = {arXiv preprint arXiv:2405.15018},
	author = {Harun, Md Yousuf and Lee, Kyungbok and Gallardo, Jhair and Krishnan, Giri and Kanan, Christopher},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{masarczyk_tunnel_2023,
	title = {The tunnel effect: {Building} data representations in deep neural networks},
	volume = {36},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Masarczyk, Wojciech and Ostaszewski, Mateusz and Imani, Ehsan and Pascanu, Razvan and Miłoś, Piotr and Trzcinski, Tomasz},
	year = {2023},
}

@inproceedings{song_position_2024,
	title = {Position: {Leverage} foundational models for black-box optimization},
	shorttitle = {Position},
	abstract = {Undeniably, Large Language Models (LLMs) have stirred an extraordinary wave of innovation in the machine learning research domain, resulting in substantial impact across diverse fields such as reinforcement learning, robotics, and computer vision. Their incorporation has been rapid and transformative, marking a significant paradigm shift in the field of machine learning research. However, the field of experimental design, grounded on black-box optimization, has been much less affected by such a paradigm shift, even though integrating LLMs with optimization presents a unique landscape ripe for exploration. In this position paper, we frame the field of blackbox optimization around sequence-based foundation models and organize their relationship with previous literature. We discuss the most promising ways foundational language models can revolutionize optimization, which include harnessing the vast wealth of information encapsulated in free-form text to enrich task comprehension, utilizing highly flexible sequence models such as Transformers to engineer superior optimization strategies, and enhancing performance prediction over previously unseen search spaces.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Song, Xingyou and Tian, Yingtao and Lange, Robert Tjarko and Lee, Chansoo and Tang, Yujin and Chen, Yutian},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{schlarmann_robust_2024,
	title = {Robust {CLIP}: {Unsupervised} adversarial fine-tuning of vision embeddings for robust large vision-language models},
	shorttitle = {Robust clip},
	abstract = {Multi-modal foundation models like OpenFlamingo, LLaVA, and GPT-4 are increasingly used for various real-world tasks. Prior work has shown that these models are highly vulnerable to adversarial attacks on the vision modality. These attacks can be leveraged to spread fake information or defraud users, and thus pose a significant risk, which makes the robustness of large multi-modal foundation models a pressing problem. The CLIP model, or one of its variants, is used as a frozen vision encoder in many large vision-language models (LVLMs), e.g. LLaVA and OpenFlamingo. We propose an unsupervised adversarial fine-tuning scheme to obtain a robust CLIP vision encoder, which yields robustness on all vision down-stream tasks (LVLMs, zero-shot classification) that rely on CLIP. In particular, we show that stealth-attacks on users of LVLMs by a malicious third party providing manipulated images are no longer possible once one replaces the original CLIP model with our robust one. No retraining or fine-tuning of the down-stream LVLMs is required. The code and robust models are available at https://github.com/chs20/RobustVLM},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Schlarmann, Christian and Singh, Naman Deep and Croce, Francesco and Hein, Matthias},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{theis_what_2024,
	title = {What makes an image realistic?},
	abstract = {The last decade has seen tremendous progress in our ability to generate realistic-looking data, be it images, text, audio, or video. Here, we discuss the closely related problem of quantifying realism, that is, designing functions that can reliably tell realistic data from unrealistic data. This problem turns out to be signiﬁcantly harder to solve and remains poorly understood, despite its prevalence in machine learning and recent breakthroughs in generative AI. Drawing on insights from algorithmic information theory, we discuss why this problem is challenging, why a good generative model alone is insufﬁcient to solve it, and what a good solution would look like. In particular, we introduce the notion of a universal critic, which unlike adversarial critics does not require adversarial training. While universal critics are not immediately practical, they can serve both as a North Star for guiding practical implementations and as a tool for analyzing existing attempts to capture realism.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Theis, Lucas},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{wang_can_2024,
	title = {Can language models serve as text-based world simulators?},
	abstract = {Virtual environments play a key role in benchmarking advances in complex planning and decision-making tasks but are expensive and complicated to build by hand. Can current language models themselves serve as world simulators, correctly predicting how actions change different world states, thus bypassing the need for extensive manual coding? Our goal is to answer this question in the context of text-based simulators. Our approach is to build and use a new benchmark, called BYTESIZED32-State-Prediction, containing a dataset of text game state transitions and accompanying game tasks. We use this to directly quantify, for the first time, how well LLMs can serve as text-based world simulators. We test GPT-4 on this dataset and find that, despite its impressive performance, it is still an unreliable world simulator without further innovations. This work thus contributes both new insights into current LLM’s capabilities and weaknesses, as well as a novel benchmark to track future progress as new models appear.},
	language = {en},
	booktitle = {{ACL}},
	author = {Wang, Ruoyao and Todd, Graham and Xiao, Ziang and Yuan, Xingdi and Côté, Marc-Alexandre and Clark, Peter and Jansen, Peter},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{wang_bytesized32_2023,
	title = {Bytesized32: {A} corpus and challenge task for generating task-specific world models expressed as text games},
	shorttitle = {Bytesized32},
	abstract = {In this work, we investigate the capacity of language models to generate explicit, interpretable, and interactive world models of scientific and common-sense reasoning tasks. We operationalize this as a task of generating text games, expressed as hundreds of lines of Python code. To facilitate this task, we introduce ByteSized32 (Code: github.com/cognitiveailab/BYTESIZED32), a corpus of 32 reasoning-focused text games totaling 20k lines of Python code. We empirically demonstrate that GPT-4 can use these games as templates for single-shot in-context learning, successfully producing runnable games on unseen topics in 28\% of cases. When allowed to self-reflect on program errors, game runnability substantially increases to 57\%. While evaluating simulation fidelity is labor-intensive, we introduce a suite of automated metrics to assess game fidelity, technical validity, adherence to task specifications, and winnability, showing a high degree of agreement with expert human ratings. We pose this as a challenge task to spur further development at the juncture of world modeling and code generation.},
	language = {en},
	booktitle = {{EMNLP}},
	author = {Wang, Ruoyao and Todd, Graham and Yuan, Eric and Xiao, Ziang and Côté, Marc-Alexandre and Jansen, Peter},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{schulhoff_prompt_2024,
	title = {The prompt report: {A} systematic survey of prompting techniques},
	shorttitle = {The prompt report},
	abstract = {Generative Artificial Intelligence (GenAI) systems are being increasingly deployed across all parts of industry and research settings. Developers and end users interact with these systems through the use of prompting or prompt engineering. While prompting is a widespread and highly researched concept, there exists conflicting terminology and a poor ontological understanding of what constitutes a prompt due to the area’s nascency. This paper establishes a structured understanding of prompts, by assembling a taxonomy of prompting techniques and analyzing their use. We present a comprehensive vocabulary of 33 vocabulary terms, a taxonomy of 58 text-only prompting techniques, and 40 techniques for other modalities. We further present a meta-analysis of the entire literature on natural language prefix-prompting.},
	language = {en},
	journal = {arXiv preprint arXiv:2406.06608},
	author = {Schulhoff, Sander and Ilie, Michael and Balepur, Nishant and Kahadze, Konstantine and Liu, Amanda and Si, Chenglei and Li, Yinheng and Gupta, Aayush and Han, HyoJung and Schulhoff, Sevien and Dulepet, Pranav Sandeep and Vidyadhara, Saurav and Ki, Dayeon and Agrawal, Sweta and Pham, Chau and Kroiz, Gerson and Li, Feileen and Tao, Hudson and Srivastava, Ashay and Da Costa, Hevander and Gupta, Saloni and Rogers, Megan L. and Goncearenco, Inna and Sarli, Giuseppe and Galynker, Igor and Peskoff, Denis and Carpuat, Marine and White, Jules and Anadkat, Shyamal and Hoyle, Alexander and Resnik, Philip},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{yang_feature_2021,
	title = {Feature learning in infinite-width neural networks},
	abstract = {As its width tends to inﬁnity, a deep neural network’s behavior under gradient descent can become simpliﬁed and predictable (e.g. given by the Neural Tangent Kernel (NTK)), if it is parametrized appropriately (e.g. the NTK parametrization). However, we show that the standard and NTK parametrizations of a neural network do not admit inﬁnite-width limits that can learn features, which is crucial for pretraining and transfer learning such as with BERT. We propose simple modiﬁcations to the standard parametrization to allow for feature learning in the limit. Using the Tensor Programs technique, we derive explicit formulas for such limits. On Word2Vec and few-shot learning on Omniglot via MAML, two canonical tasks that rely crucially on feature learning, we compute these limits exactly. We ﬁnd that they outperform both NTK baselines and ﬁnite-width networks, with the latter approaching the inﬁnite-width feature learning performance as width increases. See arXiv:2011.14522 for the full version of this paper.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Yang, Greg and Hu, Edward J.},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks, Computer Science - Neural and Evolutionary Computing},
}

@article{scialom_fine-tuned_2022,
	title = {Fine-tuned language models are continual learners},
	abstract = {Recent work on large language models relies on the intuition that most natural language processing tasks can be described via natural language instructions. Language models trained on these instructions show strong zero-shot performance on several standard datasets. However, these models even though impressive still perform poorly on a wide range of tasks outside of their respective training and evaluation sets. To address this limitation, we argue that a model should be able to keep extending its knowledge and abilities, without forgetting previous skills. In spite of the limited success of Continual Learning we show that Language Models can be continual learners. We empirically investigate the reason for this success and conclude that Continual Learning emerges from self-supervision pre-training. Our resulting model Continual-T0 (CT0) is able to learn diverse new tasks, while still maintaining good performance on previous tasks, spanning remarkably through 70 datasets in total. Finally, we show that CT0 is able to combine instructions in ways it was never trained for, demonstrating some compositionality.},
	language = {en},
	journal = {arXiv preprint arXiv:2205.12393},
	author = {Scialom, Thomas and Chakrabarty, Tuhin and Muresan, Smaranda},
	year = {2022},
	keywords = {Computer Science - Computation and Language},
}

@article{shi_continual_2024,
	title = {Continual learning of large language models: {A} comprehensive survey},
	shorttitle = {Continual learning of large language models},
	language = {en},
	journal = {arXiv preprint arXiv:2404.16789},
	author = {Shi, Haizhou and Xu, Zihao and Wang, Hengyi and Qin, Weiyi and Wang, Wenyuan and Wang, Yibin and Wang, Hao},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{luo_empirical_2024,
	title = {An empirical study of catastrophic forgetting in large language models during continual fine-tuning},
	abstract = {Catastrophic forgetting (CF) is a phenomenon that occurs in machine learning when a model forgets previously learned information while acquiring new knowledge. As large language models (LLMs) have demonstrated remarkable performance, it is intriguing to investigate whether CF exists during the continual instruction tuning of LLMs. This study empirically evaluates the forgetting phenomenon in LLMs’ knowledge during continual instruction tuning from the perspectives of domain knowledge, reasoning, and reading comprehension. The experiments reveal that catastrophic forgetting is generally observed in LLMs ranging from 1b to 7b parameters. Moreover, as the model scale increases, the severity of forgetting intensifies. Comparing the decoder-only model BLOOMZ with the encoder-decoder model mT0, BLOOMZ exhibits less forgetting and retains more knowledge. Interestingly, we also observe that LLMs can mitigate language biases, such as gender bias, during continual fine-tuning. Furthermore, our findings indicate that ALPACA maintains more knowledge and capacity compared to LLAMA during continual fine-tuning, suggesting that general instruction tuning can help alleviate the forgetting phenomenon in LLMs during subsequent fine-tuning processes.},
	language = {en},
	author = {Luo, Yun and Yang, Zhen and Meng, Fandong and Li, Yafu and Zhou, Jie and Zhang, Yue},
	year = {2024},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{wu_how_2024,
	title = {How many pretraining tasks are needed for in-context learning of linear regression?},
	abstract = {Transformers pretrained on diverse tasks exhibit remarkable in-context learning (ICL) capabilities, enabling them to solve unseen tasks solely based on input contexts without adjusting model parameters. In this paper, we study ICL in one of its simplest setups: pretraining a linearly parameterized single-layer linear attention model for linear regression with a Gaussian prior. We establish a statistical task complexity bound for the attention model pretraining, showing that effective pretraining only requires a small number of independent tasks. Furthermore, we prove that the pretrained model closely matches the Bayes optimal algorithm, i.e., optimally tuned ridge regression, by achieving nearly Bayes optimal risk on unseen tasks under a fixed context length. These theoretical findings complement prior experimental research and shed light on the statistical foundations of ICL.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Wu, Jingfeng and Zou, Difan and Chen, Zixiang and Braverman, Vladimir and Gu, Quanquan and Bartlett, Peter L.},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{chen_comprehensive_2022,
	title = {A comprehensive and modularized statistical framework for gradient norm equality in deep neural networks},
	volume = {44},
	issn = {0162-8828, 2160-9292, 1939-3539},
	doi = {10.1109/TPAMI.2020.3010201},
	abstract = {The rapid development of deep neural networks (DNNs) in recent years can be attributed to the various techniques that address gradient explosion and vanishing. In order to understand the principle behind these techniques and develop new methods, plenty of metrics have been proposed to identify networks that are free of gradient explosion and vanishing. However, due to the diversity of network components and complex serial-parallel hybrid connections in modern DNNs, the evaluation of existing metrics usually requires strong assumptions, complex statistical analysis, or has limited application ﬁelds, which constraints their spread in the community. In this paper, inspired by the Gradient Norm Equality and dynamical isometry, we ﬁrst propose a novel metric called Block Dynamical Isometry, which measures the change of gradient norm in individual block. Because our Block Dynamical Isometry is norm-based, its evaluation needs weaker assumptions compared with the original dynamical isometry. To mitigate the challenging derivation, we propose a highly modularized statistical framework based on free probability. Our framework includes several key theorems to handle complex serial-parallel hybrid connections and a library to cover the diversity of network components. Besides, several sufﬁcient prerequisites are provided. Powered by our metric and framework, we analyze extensive initialization, normalization, and network structures. We ﬁnd that Gradient Norm Equality is a universal philosophy behind them. Then, we improve some existing methods based on our analysis, including an activation function selection strategy for initialization techniques, a new conﬁguration for weight normalization, and a depth-aware way to derive coefﬁcients in SeLU. Moreover, we propose a novel normalization technique named second moment normalization, which is theoretically 30\% faster than batch normalization without accuracy loss. Last but not least, our conclusions and methods are evidenced by extensive experiments on multiple models over CIFAR10 and ImageNet.},
	language = {en},
	number = {1},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Chen, Zhaodong and Deng, Lei and Wang, Bangyan and Li, Guoqi and Xie, Yuan},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {13--31},
}

@inproceedings{ahn_transformers_2023,
	title = {Transformers learn to implement preconditioned gradient descent for in-context learning},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ahn, Kwangjun and Cheng, Xiang and Daneshmand, Hadi and Sra, Suvrit},
	year = {2023},
}

@article{zhang_trained_2023,
	title = {Trained {Transformers} {Learn} {Linear} {Models} {In}-{Context}},
	abstract = {Attention-based neural networks such as transformers have demonstrated a remarkable ability to exhibit in-context learning (ICL): Given a short prompt sequence of tokens from an unseen task, they can formulate relevant per-token and next-token predictions without any parameter updates. By embedding a sequence of labeled training data and unlabeled test data as a prompt, this allows for transformers to behave like supervised learning algorithms. Indeed, recent work has shown that when training transformer architectures over random instances of linear regression problems, these models’ predictions mimic those of ordinary least squares.},
	language = {en},
	journal = {arXiv preprint arXiv:2306.09927},
	author = {Zhang, Ruiqi and Frei, Spencer and Bartlett, Peter L.},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{collins_provable_2024,
	title = {Provable multi-task representation learning by two-layer {ReLU} neural networks},
	abstract = {An increasingly popular machine learning paradigm is to pretrain a neural network (NN) on many tasks offline, then adapt it to downstream tasks, often by re-training only the last linear layer of the network. This approach yields strong downstream performance in a variety of contexts, demonstrating that multitask pretraining leads to effective feature learning. Although several recent theoretical studies have shown that shallow NNs learn meaningful features when either (i) they are trained on a single task or (ii) they are linear, very little is known about the closer-to-practice case of nonlinear NNs trained on multiple tasks. In this work, we present the first results proving that feature learning occurs during training with a nonlinear model on multiple tasks. Our key insight is that multi-task pretraining induces a pseudocontrastive loss that favors representations that align points that typically have the same label across tasks. Using this observation, we show that when the tasks are binary classification tasks with labels depending on the projection of the data onto an r-dimensional subspace within the d ≫ rdimensional input space, a simple gradient-based multitask learning algorithm on a two-layer ReLU NN recovers this projection, allowing for generalization to downstream tasks with sample and neuron complexity independent of d. In contrast, we show that with high probability over the draw of a single task, training on this single task cannot guarantee to learn all r ground-truth features.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Collins, Liam and Hassani, Hamed and Soltanolkotabi, Mahdi and Mokhtari, Aryan and Shakkottai, Sanjay},
	year = {2024},
}

@article{schmidhuber_discovering_1997,
	title = {Discovering neural nets with low {Kolmogorov} complexity and high generalization capability},
	volume = {10},
	number = {5},
	journal = {Neural Networks},
	author = {Schmidhuber, Jürgen},
	year = {1997},
	pages = {857--873},
}

@inproceedings{goldblum_position_2024,
	title = {Position: {The} no free lunch theorem, {Kolmogorov} complexity, and the role of inductive biases in machine learning},
	abstract = {No free lunch theorems for supervised learning state that no learner can solve all problems or that all learners achieve exactly the same accuracy on average over a uniform distribution on learning problems. Accordingly, these theorems are often referenced in support of the notion that individual problems require specially tailored inductive biases. While virtually all uniformly sampled datasets have high complexity, real-world problems disproportionately generate low-complexity data, and we argue that neural network models share this same preference, formalized using Kolmogorov complexity. Notably, we show that architectures designed for a particular domain, such as computer vision, can compress datasets on a variety of seemingly unrelated domains. Our experiments show that pre-trained and even randomly initialized language models prefer to generate lowcomplexity sequences. Whereas no free lunch theorems seemingly indicate that individual problems require specialized learners, we explain how tasks that often require human intervention such as picking an appropriately sized model when labeled data is scarce or plentiful can be automated into a single learning algorithm. These observations justify the trend in deep learning of unifying seemingly disparate problems with an increasingly small set of machine learning models.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Goldblum, Micah and Finzi, Marc and Rowan, Keefer and Wilson, Andrew Gordon},
	year = {2024},
}

@inproceedings{chiang_loss_2023,
	title = {Loss landscapes are all you need: {Neural} network generalization can be explained without the implicit bias of gradient descent},
	booktitle = {The {Eleventh} {International} {Conference} on {Learning} {Representations}},
	author = {Chiang, Ping-yeh and Ni, Renkun and Miller, David Yu and Bansal, Arpit and Geiping, Jonas and Goldblum, Micah and Goldstein, Tom},
	year = {2023},
}

@inproceedings{reizinger_position_2024,
	title = {Position: {Understanding} {LLMs} requires more than statistical generalization},
	shorttitle = {Position},
	abstract = {The last decade has seen blossoming research in deep learning theory attempting to answer, “Why does deep learning generalize?" A powerful shift in perspective precipitated this progress: the study of overparametrized models in the interpolation regime. In this paper, we argue that another perspective shift is due, since some of the desirable qualities of LLMs are not a consequence of good statistical generalization and require a separate theoretical explanation. Our core argument relies on the observation that AR probabilistic models are inherently non-identifiable: models zero or near-zero KL divergence apart—thus, equivalent test loss—can exhibit markedly different behaviors. We support our position with mathematical examples and empirical observations, illustrating why non-identifiability has practical relevance through three case studies: (1) the nonidentifiability of zero-shot rule extrapolation; (2) the approximate non-identifiability of in-context learning; and (3) the non-identifiability of finetunability. We review promising research directions focusing on LLM-relevant generalization measures, transferability, and inductive biases.},
	language = {en},
	booktitle = {{ICML}},
	author = {Reizinger, Patrik and Ujváry, Szilvia and Mészáros, Anna and Kerekes, Anna and Brendel, Wieland and Huszár, Ferenc},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{liu_same_2023,
	title = {Same pre-training loss, better downstream: {Implicit} bias matters for language models},
	abstract = {Language modeling on large-scale datasets improves performance of various downstream tasks. The validation pre-training loss is often used as the evaluation metric for language models since the pre-training loss tends to be well-correlated with downstream performance (which is itself hard to evaluate comprehensively). Contrary to the conventional wisdom, this paper shows that 1) pre-training loss cannot fully explain downstream performance and 2) flatness of the model is wellcorrelated with downstream performance where pre-training loss is not. We identify three ways to produce models with the same pre-training loss but different downstream performance: continue pretraining after convergence, increasing the model size, and changing the pre-training algorithms. These experiments demonstrate the existence of implicit bias of pre-training algorithms—among models with the same minimal pre-training loss, they implicitly prefer more transferable ones. Toward understanding this implicit bias, we prove that SGD with standard mini-batch noise implicitly prefers flatter minima of pre-training loss in language models, and empirically observe a strong correlation between flatness (measured by trace of Hessian) and downstream performance among models with the same pre-training loss. We also prove in a synthetic language setting that among models with the minimal pre-training loss, the flattest model transfers to downstream tasks.},
	language = {en},
	booktitle = {{ICML}},
	author = {Liu, Hong and Xie, Sang Michael and Li, Zhiyuan and Ma, Tengyu},
	year = {2023},
}

@inproceedings{zang_overcoming_2024,
	title = {Overcoming the pitfalls of vision-language model finetuning for {OOD} generalization},
	abstract = {Existing vision-language models exhibit strong generalization on a variety of visual domains and tasks. However, such models mainly perform zero-shot recognition in a closed-set manner, and thus struggle to handle open-domain visual concepts by design. There are recent finetuning methods, such as prompt learning, that not only study the discrimination between in-distribution (ID) and out-ofdistribution (OOD) samples, but also show some improvements in both ID and OOD accuracies. In this paper, we first demonstrate that vision-language models, after long enough finetuning but without proper regularization, tend to overfit the known classes in the given dataset, with degraded performance on unknown classes. Then we propose a novel approach OGEN to address this pitfall, with the main focus on improving the OOD GENeralization of finetuned models. Specifically, a class-conditional feature generator is introduced to synthesize OOD features using just the class name of any unknown class. Such synthesized features will provide useful knowledge about unknowns and help regularize the decision boundary between ID and OOD data when optimized jointly. Equally important is our adaptive self-distillation mechanism to regularize our feature generation model during joint optimization, i.e., adaptively transferring knowledge between model states to further prevent overfitting. Experiments validate that our method yields convincing gains in OOD generalization performance in different settings. Code: https://github.com/apple/ml-ogen.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Zang, Yuhang and Goh, Hanlin and Susskind, Josh and Huang, Chen},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{allen-zhu_physics_2024,
	title = {Physics of language models: {Part} 3.3, knowledge capacity scaling laws},
	shorttitle = {Physics of language models},
	abstract = {Scaling laws describe the relationship between the size of language models and their capabilities. Unlike prior studies that evaluate a model’s capability via loss or benchmarks, we estimate the number of knowledge bits a model stores. We focus on factual knowledge represented as tuples, such as (USA, capital, Washington D.C.) from a Wikipedia page. Through multiple controlled datasets, we establish that language models can and only can store 2 bits of knowledge per parameter, even when quantized to int8, and such knowledge can be flexibly extracted for downstream applications. Consequently, a 7B model can store 14B bits of knowledge, surpassing the English Wikipedia and textbooks combined based on our estimation. More broadly, we present 12 results on how (1) training duration, (2) model architecture, (3) quantization, (4) sparsity constraints such as MoE, and (5) data signal-to-noise ratio affect a model’s knowledge storage capacity. Notable insights include: • The GPT-2 architecture, with rotary embedding, matches or even surpasses LLaMA/Mistral architectures in knowledge storage, particularly over shorter training durations. This arises because LLaMA/Mistral uses GatedMLP, which is less stable and harder to train. • Prepending training data with domain names (e.g., wikipedia.org) significantly increases a model’s knowledge capacity. Language models can autonomously identify and prioritize domains rich in knowledge, optimizing their storage capacity.},
	language = {en},
	journal = {arXiv preprint arXiv:2404.05405},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{casper_open_2023,
	title = {Open problems and fundamental limitations of reinforcement learning from human feedback},
	abstract = {Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune stateof-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-layered approach to the development of safer AI systems.},
	journal = {arXiv preprint arXiv:2307.15217},
	author = {Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, Jérémy and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and Wang, Tony and Marks, Samuel and Segerie, Charbel-Raphaël and Carroll, Micah and Peng, Andi and Christoffersen, Phillip and Damani, Mehul and Slocum, Stewart and Anwar, Usman and Siththaranjan, Anand and Nadeau, Max and Michaud, Eric J. and Pfau, Jacob and Krasheninnikov, Dmitrii and Chen, Xin and Langosco, Lauro and Hase, Peter and Bıyık, Erdem and Dragan, Anca and Krueger, David and Sadigh, Dorsa and Hadfield-Menell, Dylan},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{korbak_pretraining_2023,
	title = {Pretraining language models with human preferences},
	abstract = {Language models (LMs) are pretrained to imitate internet text, including content that would violate human preferences if generated by an LM: falsehoods, offensive comments, personally identifiable information, low-quality or buggy code, and more. Here, we explore alternative objectives for pretraining LMs in a way that also guides them to generate text aligned with human preferences. We benchmark five objectives for pretraining with human feedback across three tasks and study how they affect the trade-off between alignment and capabilities of pretrained LMs. We find a Paretooptimal and simple approach among those we explored: conditional training, or learning distribution over tokens conditional on their human preference scores given by a reward model. Conditional training reduces the rate of undesirable content by up to an order of magnitude, both when generating without a prompt and with an adversariallychosen prompt. Moreover, conditional training maintains the downstream task performance of standard LM pretraining, both before and after task-specific finetuning. Pretraining with human feedback results in much better preference satisfaction than standard LM pretraining followed by finetuning with feedback, i.e., learning and then unlearning undesirable behavior. Our results suggest that we should move beyond imitation learning when pretraining LMs and incorporate human preferences from the start of training.},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Korbak, Tomasz and Shi, Kejian and Chen, Angelica and Bhalerao, Rasika and Buckley, Christopher L and Phang, Jason and Bowman, Samuel R and Perez, Ethan},
	year = {2023},
}

@inproceedings{dubois_alpacafarm_2023,
	title = {Alpacafarm: {A} simulation framework for methods that learn from human feedback},
	abstract = {Large language models (LLMs) such as ChatGPT have seen widespread adoption due to their ability to follow user instructions well. Developing these LLMs involves a complex yet poorly understood workflow requiring training with human feedback. Replicating and understanding this instruction-following process faces three major challenges: the high cost of data collection, the lack of trustworthy evaluation, and the absence of reference method implementations. We address these challenges with AlpacaFarm, a simulator that enables research and development for learning from feedback at a low cost. First, we design LLM prompts to simulate human feedback that are 45x cheaper than crowd-workers and display high agreement with humans. Second, we propose an automatic evaluation and validate it against human instructions obtained on real-world interactions. Third, we contribute reference implementations for several methods (PPO, best-of-n, expert iteration, and more) that learn from pairwise feedback. Finally, as an end-to-end validation of AlpacaFarm, we train and evaluate eleven models on 10k pairs of real human feedback and show that the rankings of models trained in AlpacaFarm match the rankings of models trained on human data. As a demonstration of the research possible in AlpacaFarm, we find that methods that use a reward model can substantially improve over supervised fine-tuning and that our reference PPO implementation leads to a +10\% improvement in win-rate against Davinci003. We release AlpacaFarm at https://github.com/tatsu-lab/alpaca\_farm.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dubois, Yann and Li, Xuechen and Taori, Rohan and Zhang, Tianyi and Gulrajani, Ishaan},
	year = {2023},
}

@inproceedings{lovelace_latent_2023,
	title = {Latent diffusion for language generation},
	abstract = {Diffusion models have achieved great success in modeling continuous data modalities such as images, audio, and video, but have seen limited use in discrete domains such as language. Recent attempts to adapt diffusion to language have presented diffusion as an alternative to existing pretrained language models. We view diffusion and existing language models as complementary. We demonstrate that encoder-decoder language models can be utilized to efficiently learn high-quality language autoencoders. We then demonstrate that continuous diffusion models can be learned in the latent space of the language autoencoder, enabling us to sample continuous latent representations that can be decoded into natural language with the pretrained decoder. We validate the effectiveness of our approach for unconditional, class-conditional, and sequence-to-sequence language generation. We demonstrate across multiple diverse data sets that our latent language diffusion models are significantly more effective than previous diffusion language models. Our code is available at https://github.com/justinlovelace/ latent-diffusion-for-language.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lovelace, Justin and Kishore, Varsha and Wan, Chao and Shekhtman, Eliot and Weinberger, Kilian Q},
	year = {2023},
}

@article{wang_interactive_2023,
	title = {Interactive natural language processing},
	abstract = {Interactive Natural Language Processing (iNLP) has emerged as a novel paradigm within the ﬁeld of NLP, aimed at addressing limitations in existing frameworks while aligning with the ultimate goals of artiﬁcial intelligence. This paradigm considers language models as agents capable of observing, acting, and receiving feedback iteratively from external entities.},
	journal = {arXiv preprint arXiv:2305.13246},
	author = {Wang, Zekun and Zhang, Ge and Yang, Kexin and Shi, Ning and Zhou, Wangchunshu and Hao, Shaochun and Xiong, Guangzheng and Li, Yizhi and Sim, Mong Yuan and Chen, Xiuying and Zhu, Qingqing and Yang, Zhenzhu and Nik, Adam and Liu, Qi and Lin, Chenghua and Wang, Shi and Liu, Ruibo and Chen, Wenhu and Xu, Ke and Liu, Dayiheng and Guo, Yike and Fu, Jie},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{tan_connecting_2019,
	title = {Connecting the dots between {MLE} and {RL} for sequence prediction},
	abstract = {Sequence prediction models can be learned from example sequences with a variety of training algorithms. Maximum likelihood learning is simple and efﬁcient, yet can suffer from compounding error at test time. Reinforcement learning such as policy gradient addresses the issue but can have prohibitively poor exploration efﬁciency. A rich set of other algorithms such as RAML, SPG, and data noising, have also been developed from different perspectives. This paper establishes a formal connection between these algorithms. We present a generalized entropy regularized policy optimization formulation, and show that the apparently distinct algorithms can all be reformulated as special instances of the framework, with the only difference being the conﬁgurations of a reward function and a couple of hyperparameters. The uniﬁed interpretation offers a systematic view of the varying properties of exploration and learning efﬁciency. Besides, inspired from the framework, we present a new algorithm that dynamically interpolates among the family of algorithms for scheduled sequence model learning. Experiments on machine translation, text summarization, and game imitation learning demonstrate the superiority of the proposed algorithm.},
	language = {en},
	journal = {arXiv preprint arXiv:1811.09740},
	author = {Tan, Bowen and Hu, Zhiting and Yang, Zichao and Salakhutdinov, Ruslan and Xing, Eric},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{pfrommer_transport_2024,
	title = {Transport of algebraic structure to latent embeddings},
	abstract = {Machine learning often aims to produce latent embeddings of inputs which lie in a larger, abstract mathematical space. For example, in the field of 3D modeling, subsets of Euclidean space can be embedded as vectors using implicit neural representations. Such subsets also have a natural algebraic structure including operations (e.g., union) and corresponding laws (e.g., associativity). How can we learn to “union” two sets using only their latent embeddings while respecting associativity? We propose a general procedure for parameterizing latent space operations that are provably consistent with the laws on the input space. This is achieved by learning a bijection from the latent space to a carefully designed mirrored algebra which is constructed on Euclidean space in accordance with desired laws. We evaluate these structural transport nets for a range of mirrored algebras against baselines that operate directly on the latent space. Our experiments provide strong evidence that respecting the underlying algebraic structure of the input space is key for learning accurate and self-consistent operations.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Pfrommer, Samuel and Anderson, Brendon G. and Sojoudi, Somayeh},
	year = {2024},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{li_mechanics_2024,
	title = {Mechanics of next token prediction with self-attention},
	abstract = {Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: What does a single self-attention layer learn from next-token prediction? We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: (1) Hard retrieval: Given input sequence, self-attention precisely selects the high-priority input tokens associated with the last input token. (2) Soft composition: It then creates a convex combination of the high-priority tokens from which the next token can be sampled. Under suitable conditions, we rigorously characterize these mechanics through a directed graph over tokens extracted from the training data. We prove that gradient descent implicitly discovers the strongly-connected components (SCC) of this graph and self-attention learns to retrieve the tokens that belong to the highest-priority SCC available in the context window. Our theory relies on decomposing the model weights into a directional component and a finite component that correspond to hard retrieval and soft composition steps respectively. This also formalizes a related implicit bias formula conjectured in [Tarzanagh et al. 2023]. We hope that these findings shed light on how self-attention processes sequential data and pave the path toward demystifying more complex architectures.},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Li, Yingcong and Huang, Yixiao and Ildiz, M. Emrullah and Rawat, Ankit Singh and Oymak, Samet},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Mathematics - Optimization and Control},
}

@inproceedings{bennett_compression_2022,
	title = {Compression, the {Fermi} paradox and artificial super-intelligence},
	volume = {13154},
	abstract = {The following brieﬂy discusses possible diﬃculties in communication with and control of an AGI (artiﬁcial general intelligence), building upon an explanation of The Fermi Paradox and preceding work on symbol emergence and artiﬁcial general intelligence. The latter suggests that to infer what someone means, an agent constructs a rationale for the observed behaviour of others. Communication then requires two agents labour under similar compulsions and have similar experiences (construct similar solutions to similar tasks). Any non-human intelligence may construct solutions such that any rationale for their behaviour (and thus the meaning of their signals) is outside the scope of what a human is inclined to notice or comprehend. Further, the more compressed a signal, the closer it will appear to random noise. Another intelligence may possess the ability to compress information to the extent that, to us, their signals would appear indistinguishable from noise (an explanation for The Fermi Paradox). To facilitate predictive accuracy an AGI would tend to more compressed representations of the world, making any rationale for their behaviour more diﬃcult to comprehend for the same reason. Communication with and control of an AGI may subsequently necessitate not only human-like compulsions and experiences, but imposed cognitive impairment.},
	booktitle = {Conference on {Artificial} {General} {Intelligence}},
	author = {Bennett, Michael Timothy},
	year = {2022},
	doi = {10.1007/978-3-030-93758-4_5},
	keywords = {Computer Science - Artificial Intelligence},
	pages = {41--44},
}

@inproceedings{fortuin_bayesian_2022,
	title = {Bayesian neural network priors revisited},
	abstract = {Isotropic Gaussian priors are the de facto standard for modern Bayesian neural network inference. However, it is unclear whether these priors accurately reﬂect our true beliefs about the weight distributions or give optimal performance. To ﬁnd better priors, we study summary statistics of neural network weights in networks trained using stochastic gradient descent (SGD). We ﬁnd that convolutional neural network (CNN) and ResNet weights display strong spatial correlations, while fully connected networks (FCNNs) display heavy-tailed weight distributions. We show that building these observations into priors can lead to improved performance on a variety of image classiﬁcation datasets. Surprisingly, these priors mitigate the cold posterior effect in FCNNs, but slightly increase the cold posterior effect in ResNets.},
	language = {en},
	author = {Fortuin, Vincent and Garriga-Alonso, Adrià and Ober, Sebastian W. and Wenzel, Florian and Rätsch, Gunnar and Turner, Richard E. and van der Wilk, Mark and Aitchison, Laurence},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{izmailov_what_nodate,
	title = {What are {Bayesian} neural network posteriors really like?},
	abstract = {The posterior over Bayesian neural network (BNN) parameters is extremely high-dimensional and non-convex. For computational reasons, researchers approximate this posterior using inexpensive mini-batch methods such as meanﬁeld variational inference or stochastic-gradient Markov chain Monte Carlo (SGMCMC). To investigate foundational questions in Bayesian deep learning, we instead use full-batch Hamiltonian Monte Carlo (HMC) on modern architectures. We show that (1) BNNs can achieve signiﬁcant performance gains over standard training and deep ensembles; (2) a single long HMC chain can provide a comparable representation of the posterior to multiple shorter chains; (3) in contrast to recent studies, we ﬁnd posterior tempering is not needed for near-optimal performance, with little evidence for a “cold posterior” effect, which we show is largely an artifact of data augmentation; (4) BMA performance is robust to the choice of prior scale, and relatively similar for diagonal Gaussian, mixture of Gaussian, and logistic priors; (5) Bayesian neural networks show surprisingly poor generalization under domain shift; (6) while cheaper alternatives such as deep ensembles and SGMCMC can provide good generalization, their predictive distributions are distinct from HMC. Notably, deep ensemble predictive distributions are similarly close to HMC as standard SGLD, and closer than standard variational inference.},
	language = {en},
	author = {Izmailov, Pavel and Vikram, Sharad and Hoffman, Matthew D and Wilson, Andrew Gordon},
}

@article{wenzel_how_2020,
	title = {How good is the {Bayes} posterior in deep neural networks really?},
	abstract = {During the past ﬁve years the Bayesian deep learning community has developed increasingly accurate and efﬁcient approximate inference procedures that allow for Bayesian inference in deep neural networks. However, despite this algorithmic progress and the promise of improved uncertainty quantiﬁcation and sample efﬁciency there are—as of early 2020—no publicized deployments of Bayesian neural networks in industrial practice. In this work we cast doubt on the current understanding of Bayes posteriors in popular deep neural networks: we demonstrate through careful MCMC sampling that the posterior predictive induced by the Bayes posterior yields systematically worse predictions compared to simpler methods including point estimates obtained from SGD. Furthermore, we demonstrate that predictive performance is improved signiﬁcantly through the use of a “cold posterior” that overcounts evidence. Such cold posteriors sharply deviate from the Bayesian paradigm but are commonly used as heuristic in Bayesian deep learning papers. We put forward several hypotheses that could explain cold posteriors and evaluate the hypotheses through experiments. Our work questions the goal of accurate posterior approximations in Bayesian deep learning: If the true Bayes posterior is poor, what is the use of more accurate approximations? Instead, we argue that it is timely to focus on understanding the origin of the improved performance of cold posteriors.},
	language = {en},
	journal = {arXiv preprint arXiv:2002.02405},
	author = {Wenzel, Florian and Roth, Kevin and Veeling, Bastiaan S. and Świątkowski, Jakub and Tran, Linh and Mandt, Stephan and Snoek, Jasper and Salimans, Tim and Jenatton, Rodolphe and Nowozin, Sebastian},
	year = {2020},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Computation},
}

@article{shwartz-ziv_pre-train_2022,
	title = {Pre-train your loss: {Easy} {Bayesian} transfer learning with informative priors},
	shorttitle = {Pre-train your loss},
	abstract = {Deep learning is increasingly moving towards a transfer learning paradigm whereby large foundation models are ﬁne-tuned on downstream tasks, starting from an initialization learned on the source task. But an initialization contains relatively little information about the source task. Instead, we show that we can learn highly informative posteriors from the source task, through supervised or self-supervised approaches, which then serve as the basis for priors that modify the whole loss surface on the downstream task. This simple modular approach enables signiﬁcant performance gains and more data-eﬃcient learning on a variety of downstream classiﬁcation and segmentation tasks, serving as a drop-in replacement for standard pre-training strategies. These highly informative priors also can be saved for future use, similar to pre-trained weights, and stand in contrast to the zero-mean isotropic uninformative priors that are typically used in Bayesian deep learning.},
	language = {en},
	journal = {arXiv preprint arXiv:2205.10279},
	author = {Shwartz-Ziv, Ravid and Goldblum, Micah and Souri, Hossein and Kapoor, Sanyam and Zhu, Chen and LeCun, Yann and Wilson, Andrew Gordon},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{qi_visual_2024,
	title = {Visual adversarial examples jailbreak aligned large language models},
	volume = {38},
	isbn = {2374-3468},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Qi, Xiangyu and Huang, Kaixuan and Panda, Ashwinee and Henderson, Peter and Wang, Mengdi and Mittal, Prateek},
	year = {2024},
	pages = {21527--21536},
}

@inproceedings{jiang_low-resource_2023,
	address = {Toronto, Canada},
	title = {“{Low}-resource” text classification: {A} parameter-free classification method with compressors},
	shorttitle = {“{Low}-resource” text classification},
	doi = {10.18653/v1/2023.findings-acl.426},
	abstract = {Deep neural networks (DNNs) are often used for text classification due to their high accuracy. However, DNNs can be computationally intensive, requiring millions of parameters and large amounts of labeled data, which can make them expensive to use, to optimize, and to transfer to out-of-distribution (OOD) cases in practice. In this paper, we propose a non-parametric alternative to DNNs that’s easy, lightweight, and universal in text classification: a combination of a simple compressor like gzip with a k-nearest-neighbor classifier. Without any training parameters, our method achieves results that are competitive with non-pretrained deep learning methods on six in-distribution datasets. It even outperforms BERT on all five OOD datasets, including four low-resource languages. Our method also excels in the few-shot setting, where labeled data are too scarce to train DNNs effectively. Code is available at https://github.com/bazingagin/npc\_gzip.},
	language = {en},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2023},
	author = {Jiang, Zhiying and Yang, Matthew and Tsirlin, Mikhail and Tang, Raphael and Dai, Yiqin and Lin, Jimmy},
	year = {2023},
	pages = {6810--6828},
}

@inproceedings{lotfi_pac-bayes_2022,
	title = {{PAC}-{Bayes} compression bounds so tight that they can explain generalization},
	abstract = {While there has been progress in developing non-vacuous generalization bounds for deep neural networks, these bounds tend to be uninformative about why deep learning works. In this paper, we develop a compression approach based on quantizing neural network parameters in a linear subspace, profoundly improving on previous results to provide state-of-the-art generalization bounds on a variety of tasks, including transfer learning. We use these tight bounds to better understand the role of model size, equivariance, and the implicit biases of optimization, for generalization in deep learning. Notably, we find large models can be compressed to a much greater extent than previously known, encapsulating Occam’s razor. We also argue for data-independent bounds in explaining generalization.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lotfi, Sanae and Finzi, Marc and Kapoor, Sanyam and Potapczynski, Andres and Goldblum, Micah and Wilson, Andrew Gordon},
	year = {2022},
}

@inproceedings{zhou_emergence_2024,
	title = {On the emergence of cross-task linearity in pretraining-finetuning paradigm},
	abstract = {The pretraining-finetuning paradigm has become the prevailing trend in modern deep learning. In this work, we discover an intriguing linear phenomenon in models that are initialized from a common pretrained checkpoint and finetuned on different tasks1, termed as Cross-Task Linearity (CTL). Specifically, we show that if we linearly interpolate the weights of two finetuned models, the features in the weight-interpolated model are often approximately equal to the linear interpolation of features in two finetuned models at each layer. We provide comprehensive empirical evidence supporting that CTL consistently occurs for finetuned models that start from the same pretrained checkpoint. We conjecture that in the pretraining-finetuning paradigm, neural networks approximately function as linear maps, mapping from the parameter space to the feature space. Based on this viewpoint, our study unveils novel insights into explaining model merging/editing, particularly by translating operations from the parameter space to the feature space. Furthermore, we delve deeper into the root cause for the emergence of CTL, highlighting the role of pretraining. We released our source code at https://github.com/zzp1012/ Cross-Task-Linearity.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhou, Zhanpeng and Chen, Zijun and Chen, Yilan and Zhang, Bo and Yan, Junchi},
	year = {2024},
}

@inproceedings{andriushchenko_sgd_2023,
	title = {{SGD} with large step sizes learns sparse features},
	isbn = {2640-3498},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Andriushchenko, Maksym and Varre, Aditya Vardhan and Pillaud-Vivien, Loucas and Flammarion, Nicolas},
	year = {2023},
	pages = {903--925},
}

@inproceedings{niu_test-time_2024,
	title = {Test-time model adaptation with only forward passes},
	abstract = {Test-time adaptation has proven effective in adapting a given trained model to unseen test samples with potential distribution shifts. However, in real-world scenarios, models are usually deployed on resource-limited devices, e.g., FPGAs, and are often quantized and hard-coded with nonmodifiable parameters for acceleration. In light of this, existing methods are often infeasible since they heavily depend on computation-intensive backpropagation for model updating that may be not supported. To address this, we propose a testtime Forward-Optimization Adaptation (FOA) method. In FOA, we seek to solely learn a newly added prompt (as model’s input) via a derivativefree covariance matrix adaptation evolution strategy. To make this strategy work stably under our online unsupervised setting, we devise a novel fitness function by measuring test-training statistic discrepancy and model prediction entropy. Moreover, we design an activation shifting scheme that directly tunes the model activations for shifted test samples, making them align with the source training domain, thereby further enhancing adaptation performance. Without using any backpropagation and altering model weights, FOA runs on quantized 8-bit ViT outperforms gradient-based TENT on full-precision 32-bit ViT, while achieving an up to 24-fold memory reduction on ImageNet-C. Code: https://github.com/mr-eggplant/FOA.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Niu, Shuaicheng and Miao, Chunyan and Chen, Guohao and Wu, Pengcheng and Zhao, Peilin},
	year = {2024},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{shi_lca---line_2024,
	title = {{LCA}-on-the-line: benchmarking out-of-distribution  generalization with class taxonomies},
	abstract = {We tackle the challenge of predicting models’ Out-of-Distribution (OOD) performance using indistribution (ID) measurements without requiring OOD data. Existing evaluations with “Effective robustness”, which use ID accuracy as an indicator of OOD accuracy, encounter limitations when models are trained with diverse supervision and distributions, such as class labels (Vision Models, VMs, on ImageNet) and textual descriptions (Visual-Language Models, VLMs, on LAION). VLMs often generalize better to OOD data than VMs despite having similar or lower ID performance. To improve the prediction of models’ OOD performance from ID measurements, we introduce the Lowest Common Ancestor (LCA)on-the-Line framework. This approach revisits the established concept of LCA distance, which measures the hierarchical distance between labels and predictions within a predefined class hierarchy, such as WordNet. We assess 75 models using ImageNet as the ID dataset and five significantly shifted OOD variants, uncovering a strong linear correlation between ID LCA distance and OOD top-1 accuracy. Our method provides a compelling alternative for understanding why VLMs tend to generalize better. Additionally, we propose a technique to construct a taxonomic hierarchy on any dataset using K-means clustering, demonstrating that LCA distance is robust to the constructed taxonomic hierarchy. Moreover, we demonstrate that aligning model predictions with class taxonomies, through soft labels or prompt engineering, can enhance model generalization. Open source code in our Project Page.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Shi, Jia and Gare, Gautam and Tian, Jinjin and Chai, Siqi and Lin, Zhiqiu and Vasudevan, Arun and Feng, Di and Ferroni, Francesco and Kong, Shu},
	year = {2024},
}

@article{hughes_position_nodate,
	title = {Position: {Open}-{Endedness} is {Essential} for {Artificial} {Superhuman} {Intelligence}},
	abstract = {In recent years there has been a tremendous surge in the general capabilities of AI systems, mainly fuelled by training foundation models on internetscale data. Nevertheless, the creation of openended, ever self-improving AI remains elusive. In this position paper, we argue that the ingredients are now in place to achieve openendedness in AI systems with respect to a human observer. Furthermore, we claim that such open-endedness is an essential property of any artificial superhuman intelligence (ASI). We begin by providing a concrete formal definition of open-endedness through the lens of novelty and learnability. We then illustrate a path towards ASI via open-ended systems built on top of foundation models, capable of making novel, humanrelevant discoveries. We conclude by examining the safety implications of generally-capable openended AI. We expect that open-ended foundation models will prove to be an increasingly fertile and safety-critical area of research in the near future.},
	language = {en},
	author = {Hughes, Edward and Dennis, Michael and Parker-Holder, Jack and Behbahani, Feryal and Mavalankar, Aditi and Shi, Yuge and Schaul, Tom and Rocktäschel, Tim},
}

@article{papadopoulos_arrows_2024,
	title = {Arrows of time for large language models},
	abstract = {We study the probabilistic modeling performed by Autoregressive Large Language Models (LLMs) through the angle of time directionality, addressing a question first raised in (Shannon, 1951). For large enough models, we empirically find a time asymmetry in their ability to learn natural language: a difference in the average log-perplexity when trying to predict the next token versus when trying to predict the previous one. This difference is at the same time subtle and very consistent across various modalities (language, model size, training time, ...). Theoretically, this is surprising: from an information-theoretic point of view, there should be no such difference. We provide a theoretical framework to explain how such an asymmetry can appear from sparsity and computational complexity considerations, and outline a number of perspectives opened by our results.},
	language = {en},
	journal = {arXiv preprint arXiv:2401.17505},
	author = {Papadopoulos, Vassilis and Wenger, Jérémie and Hongler, Clément},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{avidan_deit_2022,
	address = {Cham},
	title = {{DeiT} {III}: {Revenge} of the {ViT}},
	volume = {13684},
	isbn = {978-3-031-20052-6 978-3-031-20053-3},
	shorttitle = {{DeiT} {III}},
	abstract = {A Vision Transformer (ViT) is a simple neural architecture amenable to serve several computer vision tasks. It has limited built-in architectural priors, in contrast to more recent architectures that incorporate priors either about the input data or of specific tasks. Recent works show that ViTs benefit from selfsupervised pre-training, in particular BerT-like pre-training like BeiT.},
	language = {en},
	booktitle = {{ECCV}},
	author = {Touvron, Hugo and Cord, Matthieu and Jégou, Hervé},
	editor = {Avidan, Shai and Brostow, Gabriel and Cissé, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
	year = {2022},
	doi = {10.1007/978-3-031-20053-3_30},
	pages = {516--533},
}

@misc{scherlis_polysemanticity_2023,
	title = {Polysemanticity and capacity in neural networks},
	abstract = {Individual neurons in neural networks often represent a mixture of unrelated features. This phenomenon, called polysemanticity, can make interpreting neural networks more difficult and so we aim to understand its causes. We propose doing so through the lens of feature capacity, which is the fractional dimension each feature consumes in the embedding space. We show that in a toy model the optimal capacity allocation tends to monosemantically represent the most important features, polysemantically represent less important features (in proportion to their impact on the loss), and entirely ignore the least important features. Polysemanticity is more prevalent when the inputs have higher kurtosis or sparsity and more prevalent in some architectures than others. Given an optimal allocation of capacity, we go on to study the geometry of the embedding space. We find a block-semi-orthogonal structure, with differing block sizes in different models, highlighting the impact of model architecture on the interpretability of its neurons.},
	language = {en},
	author = {Scherlis, Adam and Sachan, Kshitij and Jermyn, Adam S. and Benton, Joe and Shlegeris, Buck},
	month = jul,
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
}

@article{teney_neural_2024,
	title = {Neural redshift: {Random} networks are not random functions},
	shorttitle = {Neural redshift},
	abstract = {Our understanding of the generalization capabilities of neural networks (NNs) is still incomplete. Prevailing explanations are based on implicit biases of gradient descent (GD) but they cannot account for the capabilities of models from gradient-free methods [9] nor the simplicity bias recently observed in untrained networks [29]. This paper seeks other sources of generalization in NNs.},
	language = {en},
	journal = {arXiv preprint arXiv:2403.02241},
	author = {Teney, Damien and Nicolicioiu, Armand and Hartmann, Valentin and Abbasnejad, Ehsan},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{springer_sharpness-aware_2024,
	title = {Sharpness-aware minimization enhances feature quality via balanced learning},
	abstract = {Sharpness-Aware Minimization (SAM) has emerged as a promising alternative optimizer to stochastic gradient descent (SGD). The originally-proposed motivation behind SAM was to bias neural networks towards flatter minima that are believed to generalize better. However, recent studies have shown conflicting evidence on the relationship between flatness and generalization, suggesting that flatness does fully explain SAM’s success. Sidestepping this debate, we identify an orthogonal effect of SAM that is beneficial out-of-distribution: we argue that SAM implicitly balances the quality of diverse features. SAM achieves this effect by adaptively suppressing well-learned features which gives remaining features opportunity to be learned. We show that this mechanism is beneficial in datasets that contain redundant or spurious features where SGD falls for the simplicity bias and would not otherwise learn all available features. Our insights are supported by experiments on real data: we demonstrate that SAM improves the quality of features in datasets containing redundant or spurious features, including CelebA, Waterbirds, CIFAR-MNIST, and DomainBed.},
	language = {en},
	booktitle = {{ICLR}},
	author = {Springer, Jacob Mitchell and Nagarajan, Vaishnavh and Raghunathan, Aditi},
	year = {2024},
}

@article{zhu_minigpt-4_2023,
	title = {Minigpt-4: {Enhancing} vision-language understanding with advanced large language models},
	shorttitle = {Minigpt-4},
	abstract = {The recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images. These features are rarely observed in previous visionlanguage models. However, the technical details behind GPT-4 continue to remain undisclosed. We believe that the enhanced multi-modal generation capabilities of GPT-4 stem from the utilization of sophisticated large language models (LLM). To examine this phenomenon, we present MiniGPT-4, which aligns a frozen visual encoder with a frozen advanced LLM, Vicuna, using one projection layer. Our work, for the first time, uncovers that properly aligning the visual features with an advanced large language model can possess numerous advanced multi-modal abilities demonstrated by GPT-4, such as detailed image description generation and website creation from hand-drawn drafts. Furthermore, we also observe other emerging capabilities in MiniGPT-4, including writing stories and poems inspired by given images, teaching users how to cook based on food photos, and so on. In our experiment, we found that the model trained on short image caption pairs could produce unnatural language outputs (e.g., repetition and fragmentation). To address this problem, we curate a detailed image description dataset in the second stage to finetune the model, which consequently improves the model’s generation reliability and overall usability. Our code, pre-trained model, and collected dataset are available at https://minigpt-4.github.io/.},
	language = {en},
	journal = {arXiv preprint arXiv:2304.10592},
	author = {Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
	year = {2023},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{dingle_inputoutput_2018,
	title = {Input–output maps are strongly biased towards simple outputs},
	volume = {9},
	number = {1},
	journal = {Nature Communications},
	author = {Dingle, Kamaludin and Camargo, Chico Q. and Louis, Ard A.},
	year = {2018},
}

@inproceedings{zhou_non-vacuous_2019,
	title = {Non-vacuous generalization bounds at the {ImageNet} scale: {A} {PAC}-{Bayesian} compression approach},
	shorttitle = {Non-vacuous generalization bounds at the imagenet scale},
	abstract = {Modern neural networks are highly overparameterized, with capacity to substantially overﬁt to training data. Nevertheless, these networks often generalize well in practice. It has also been observed that trained networks can often be “compressed” to much smaller representations. The purpose of this paper is to connect these two empirical observations. Our main technical result is a generalization bound for compressed networks based on the compressed size that, combined with off-theshelf compression algorithms, leads to state-of-the-art generalization guarantees. In particular, we provide the ﬁrst non-vacuous generalization guarantees for realistic architectures applied to the ImageNet classiﬁcation problem. Additionally, we show that compressibility of models that tend to overﬁt is limited. Empirical results show that an increase in overﬁtting increases the number of bits required to describe a trained network.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Zhou, Wenda and Veitch, Victor and Austern, Morgane and Adams, Ryan P. and Orbanz, Peter},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{tian_fast_2023,
	title = {Fast trainable projection for robust fine-tuning},
	abstract = {Robust fine-tuning aims to achieve competitive in-distribution (ID) performance while maintaining the out-of-distribution (OOD) robustness of a pre-trained model when transferring it to a downstream task. Recently, projected gradient descent has been successfully used in robust fine-tuning by constraining the deviation from the initialization of the fine-tuned model explicitly through projection. However, algorithmically, two limitations prevent this method from being adopted more widely, scalability and efficiency. In this paper, we propose a new projection-based fine-tuning algorithm, Fast Trainable Projection (FTP) for computationally efficient learning of per-layer projection constraints, resulting in an average 35\% speedup on our benchmarks compared to prior works. FTP can be combined with existing optimizers such as AdamW, and be used in a plug-and-play fashion. Finally, we show that FTP is a special instance of hyper-optimizers that tune the hyper-parameters of optimizers in a learnable manner through nested differentiation. Empirically, we show superior robustness on OOD datasets, including domain shifts and natural corruptions, across four different vision tasks with five different pre-trained models. Additionally, we demonstrate that FTP is broadly applicable and beneficial to other learning scenarios such as low-label and continual learning settings thanks to its easy adaptability. The code will be available at https://github.com/GT-RIPL/FTP.git.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Tian, Junjiao and Liu, Yen-Cheng and Smith, James Seale and Kira, Zsolt},
	year = {2023},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{lu_ai_2024,
	title = {The {AI} scientist: {Towards} fully automated open-ended scientific discovery},
	shorttitle = {The ai scientist},
	abstract = {One of the grand challenges of artificial general intelligence is developing agents capable of conducting scientific research and discovering new knowledge. While frontier models have already been used as aids to human scientists, e.g. for brainstorming ideas, writing code, or prediction tasks, they still conduct only a small part of the scientific process. This paper presents the first comprehensive framework for fully automatic scientific discovery, enabling frontier large language models to perform research independently and communicate their findings. We introduce The AI Scientist, which generates novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing a full scientific paper, and then runs a simulated review process for evaluation. In principle, this process can be repeated to iteratively develop ideas in an open-ended fashion, acting like the human scientific community. We demonstrate its versatility by applying it to three distinct subfields of machine learning: diffusion modeling, transformer-based language modeling, and learning dynamics. Each idea is implemented and developed into a full paper at a cost of less than \$15 per paper. To evaluate the generated papers, we design and validate an automated reviewer, which we show achieves near-human performance in evaluating paper scores. The AI Scientist can produce papers that exceed the acceptance threshold at a top machine learning conference as judged by our automated reviewer. This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world's most challenging problems. Our code is open-sourced at https://github.com/SakanaAI/AI-Scientist},
	language = {en},
	journal = {arXiv preprint arXiv:2408.06292},
	author = {Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{golovneva_reverse_2024,
	title = {Reverse training to nurse the reversal curse},
	abstract = {Large language models (LLMs) have a surprising failure: when trained on “A has a feature B”, they do not generalize to “B is a feature of A”, which is termed the Reversal Curse. Even when training with trillions of tokens this issue still appears due to Zipf’s law – hence even if we train on the entire internet. This work proposes an alternative training scheme, called reverse training, whereby all words are used twice, doubling the amount of available tokens. The LLM is trained in both forward and reverse directions by reversing training strings while preserving (i.e., not reversing) chosen substrings, such as entities. We show that data-matched reverse-trained models provide superior performance to standard models on standard tasks, and compute-matched reverse-trained models provide far superior performance on reversal tasks, helping resolve the reversal curse issue.},
	language = {en},
	journal = {arXiv preprint arXiv:2403.13799},
	author = {Golovneva, Olga and Allen-Zhu, Zeyuan and Weston, Jason and Sukhbaatar, Sainbayar},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{lou_discrete_2024,
	title = {Discrete diffusion modeling by estimating the ratios of the data distribution},
	abstract = {Despite their groundbreaking performance for many generative modeling tasks, diffusion models have fallen short on discrete data domains such as natural language. Crucially, standard diffusion models rely on the well-established theory of score matching, but efforts to generalize this to discrete structures have not yielded the same empirical gains. In this work, we bridge this gap by proposing score entropy, a novel loss that naturally extends score matching to discrete spaces, integrates seamlessly to build discrete diffusion models, and significantly boosts performance. Experimentally, we test our Score Entropy Discrete Diffusion models (SEDD) on standard language modeling tasks. For comparable model sizes, SEDD beats existing language diffusion paradigms (reducing perplexity by 25-75\%) and is competitive with autoregressive models, in particular outperforming GPT-2. Furthermore, compared to autoregressive mdoels, SEDD generates faithful text without requiring distribution annealing techniques like temperature scaling (around 68× better generative perplexity than un-annealed GPT-2), can trade compute and quality (similar quality with 32× fewer network evaluations), and enables controllable infilling (matching nucleus sampling quality while enabling other strategies besides left to right prompting).},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Lou, Aaron and Meng, Chenlin and Ermon, Stefano},
	year = {2024},
}

@inproceedings{khan_debating_2024,
	title = {Debating with more persuasive {LLMs} leads to more truthful answers},
	abstract = {Common methods for aligning large language models (LLMs) with desired behaviour heavily rely on human-labelled data. However, as models grow increasingly sophisticated, they will surpass human expertise, and the role of human evaluation will evolve into non-experts overseeing experts. In anticipation of this, we ask: can weaker models assess the correctness of stronger models? We investigate this question in an analogous setting, where stronger models (experts) possess the necessary information to answer questions and weaker models (non-experts) lack this information but are otherwise as capable. The method we evaluate is debate, where two LLM experts each argue for a different answer, and a non-expert selects the answer. On the QuALITY comprehension task, we find that debate consistently helps both non-expert models and humans answer questions, achieving 76\% and 88\% accuracy respectively (naive baselines obtain 48\% and 60\%). Furthermore, optimising expert debaters for persuasiveness in an unsupervised manner improves non-expert ability to identify the truth in debates. Our results provide encouraging empirical evidence for the viability of aligning models with debate in the absence of ground truth.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Khan, Akbir and Hughes, John and Valentine, Dan and Ruis, Laura and Sachan, Kshitij and Radhakrishnan, Ansh and Grefenstette, Edward and Bowman, Samuel R. and Rocktäschel, Tim and Perez, Ethan},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{carlini_stealing_2024,
	title = {Stealing part of a production language model},
	abstract = {We introduce the ﬁrst model-stealing attack that extracts precise, nontrivial information from black-box production language models like OpenAI’s ChatGPT or Google’s PaLM-2. Speciﬁcally, our attack recovers the embedding projection layer (up to symmetries) of a transformer model, given typical API access. For under \$20 USD, our attack extracts the entire projection matrix of OpenAI’s ada and babbage language models. We thereby conﬁrm, for the ﬁrst time, that these black-box models have a hidden dimension of 1024 and 2048, respectively. We also recover the exact hidden dimension size of the gpt-3.5-turbo model, and estimate it would cost under \$2,000 in queries to recover the entire projection matrix. We conclude with potential defenses and mitigations, and discuss the implications of possible future work that could extend our attack.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Carlini, Nicholas and Paleka, Daniel},
	year = {2024},
}

@inproceedings{attias_information_2024,
	title = {Information complexity of stochastic convex optimization: {Applications} to generalization, memorization, and tracing},
	abstract = {In this work, we investigate the interplay between memorization and learning in the context of stochastic convex optimization (SCO). We define memorization via the information a learning algorithm reveals about its training data points. We then quantify this information using the framework of conditional mutual information (CMI) proposed by Steinke and Zakynthinou [SZ20]. Our main result is a precise characterization of the tradeoff between the accuracy of a learning algorithm and its CMI, answering an open question posed by Livni [Liv23]. We show that, in the L2 Lipschitz–bounded setting and under strong convexity, every learner with an excess error ε has CMI bounded below by Ω(1/ε2) and Ω(1/ε), respectively. We further demonstrate the essential role of memorization in learning problems in SCO by designing an adversary capable of accurately identifying a significant fraction of the training samples in specific SCO problems. Finally, we enumerate several implications of our results, such as a limitation of generalization bounds based on CMI and the incompressibility of samples in SCO problems.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Attias, Idan and Dziugaite, Gintare Karolina and Haghifam, Mahdi and Livni, Roi and Roy, Daniel M},
	year = {2024},
}

@inproceedings{esser_scaling_2024,
	title = {Scaling rectified flow transformers for high-resolution image synthesis},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and Müller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and Podell, Dustin and Dockhorn, Tim and English, Zion and Rombach, Robin},
	year = {2024},
}

@inproceedings{bruce_genie_2024,
	title = {Genie: {Generative} interactive environments},
	shorttitle = {Genie},
	abstract = {We introduce Genie, the first generative interactive environment trained in an unsupervised manner from unlabelled Internet videos. The model can be prompted to generate an endless variety of actioncontrollable virtual worlds described through text, synthetic images, photographs, and even sketches. At 11B parameters, Genie can be considered a foundation world model. It is comprised of a spatiotemporal video tokenizer, an autoregressive dynamics model, and a simple and scalable latent action model. Genie enables users to act in the generated environments on a frame-by-frame basis despite training without any ground-truth action labels or other domain-specific requirements typically found in the world model literature. Further the resulting learned latent action space facilitates training agents to imitate behaviors from unseen videos, opening the path for training generalist agents of the future.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Bruce, Jake and Dennis, Michael and Edwards, Ashley and Parker-Holder, Jack and Shi, Yuge and Hughes, Edward and Lai, Matthew and Mavalankar, Aditi and Steigerwald, Richie and Apps, Chris and Aytar, Yusuf and Bechtle, Sarah and Behbahani, Feryal and Chan, Stephanie and Heess, Nicolas and Gonzalez, Lucy and Osindero, Simon and Ozair, Sherjil and Reed, Scott and Zhang, Jingwei and Zolna, Konrad and Clune, Jeff and de Freitas, Nando and Singh, Satinder and Rocktäschel, Tim},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{tramer_position_2024,
	title = {Position: {Considerations} for differentially private learning  with large-scale public pretraining},
	abstract = {The performance of differentially private machine learning can be boosted significantly by leveraging the transfer learning capabilities of nonprivate models pretrained on large public datasets. We critically review this approach. We primarily question whether the use of large Web-scraped datasets should be viewed as differential-privacypreserving. We further scrutinize whether existing machine learning benchmarks are appropriate for measuring the ability of pretrained models to generalize to sensitive domains. Finally, we observe that reliance on large pretrained models may lose other forms of privacy, requiring data to be outsourced to a more compute-powerful third party.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Tramèr, Florian and Kamath, Gautam and Carlini, Nicholas},
	year = {2024},
}

@inproceedings{kondratyuk_videopoet_2024,
	title = {Videopoet: {A} large language model for zero-shot video generation},
	abstract = {We present VideoPoet, a model for synthesizing high-quality videos from a large variety of conditioning signals. VideoPoet employs a decoderonly transformer architecture that processes multimodal inputs – including images, videos, text, and audio. The training protocol follows that of Large Language Models (LLMs), consisting of two stages: pretraining and task-speciﬁc adaptation. During pretraining, VideoPoet incorporates a mixture of multimodal generative objectives within an autoregressive Transformer framework. The pretrained LLM serves as a foundation that is adapted to a range of video generation tasks. We present results demonstrating the model’s stateof-the-art capabilities in zero-shot video generation, speciﬁcally highlighting the generation of high-ﬁdelity motions. Project page: https:// sites.research.google/videopoet/.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Kondratyuk, Dan and Yu, Lijun and Gu, Xiuye and Lezama, José and Huang, Jonathan and Schindler, Grant and Hornung, Rachel and Birodkar, Vighnesh and Yan, Jimmy and Chiu, Ming-Chang and Somandepalli, Krishna and Akbari, Hassan and Alon, Yair and Cheng, Yong and Dillon, Josh and Gupta, Agrim and Hahn, Meera and Hauth, Anja and Hendon, David and Martinez, Alonso and Minnen, David and Sirotenko, Mikhail and Sohn, Kihyuk and Yang, Xuan and Adam, Hartwig and Yang, Ming-Hsuan and Essa, Irfan and Wang, Huisheng and Ross, David A and Seybold, Bryan and Jiang, Lu},
	year = {2024},
}

@inproceedings{zhao_position_2024,
	title = {Position: {Measure} dataset diversity, don't just claim it},
	shorttitle = {Position},
	abstract = {Machine learning (ML) datasets, often perceived as neutral, inherently encapsulate abstract and disputed social constructs. Dataset curators frequently employ value-laden terms such as diversity, bias, and quality to characterize datasets. Despite their prevalence, these terms lack clear definitions and validation. Our research explores the implications of this issue by analyzing “diversity” across 135 image and text datasets. Drawing from social sciences, we apply principles from measurement theory to identify considerations and offer recommendations for conceptualizing, operationalizing, and evaluating diversity in datasets. Our findings have broader implications for ML research, advocating for a more nuanced and precise approach to handling value-laden properties in dataset construction.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhao, Dora and Andrews, Jerone T. A. and Papakyriakopoulos, Orestis and Xiang, Alice},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Computers and Society},
}

@inproceedings{zhao_probabilistic_2024,
	title = {Probabilistic inference in language models  via twisted sequential monte carlo},
	abstract = {Numerous capability and safety techniques of Large Language Models (LLMs), including RLHF, automated red-teaming, prompt engineering, and infilling, can be cast as sampling from an unnormalized target distribution defined by a given reward or potential function over the full sequence. In this work, we leverage the rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic inference problems. In particular, we use learned twist functions to estimate the expected future value of the potential at each timestep, which enables us to focus inference-time computation on promising partial sequences. We propose a novel contrastive method for learning the twist functions, and establish connections with the rich literature of soft reinforcement learning. As a complementary application of our twisted SMC framework, we present methods for evaluating the accuracy of language model inference techniques using novel bidirectional SMC bounds on the log partition function. These bounds can be used to estimate the KL divergence between the inference and target distributions in both directions. We apply our inference evaluation techniques to show that twisted SMC is effective for sampling undesirable outputs from a pretrained model (a useful component of harmlessness training and automated red-teaming), generating reviews with varied sentiment, and performing infilling tasks.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhao, Stephen and Brekelmans, Rob and Makhzani, Alireza and Grosse, Roger},
	year = {2024},
}

@inproceedings{zhang_feature_2024,
	title = {Feature contamination: {Neural} networks learn uncorrelated features and fail to generalize},
	shorttitle = {Feature contamination},
	abstract = {Learning representations that generalize under distribution shifts is critical for building robust machine learning models. However, despite significant efforts in recent years, algorithmic advances in this direction have been limited. In this work, we seek to understand the fundamental difficulty of out-of-distribution generalization with deep neural networks. We first empirically show that perhaps surprisingly, even allowing a neural network to explicitly fit the representations obtained from a teacher network that can generalize out-of-distribution is insufficient for the generalization of the student network. Then, by a theoretical study of two-layer ReLU networks optimized by stochastic gradient descent (SGD) under a structured feature model, we identify a fundamental yet unexplored feature learning proclivity of neural networks, feature contamination: neural networks can learn uncorrelated features together with predictive features, resulting in generalization failure under distribution shifts. Notably, this mechanism essentially differs from the prevailing narrative in the literature that attributes the generalization failure to spurious correlations. Overall, our results offer new insights into the non-linear feature learning dynamics of neural networks and highlight the necessity of considering inductive biases in out-of-distribution generalization.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhang, Tianren and Zhao, Chujie and Chen, Guanyu and Jiang, Yizhou and Chen, Feng},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@article{petersen_mathematical_2024,
	title = {Mathematical theory of deep learning},
	abstract = {This book provides an introduction to the mathematical analysis of deep learning. It covers fundamental results in approximation theory, optimization theory, and statistical learning theory, which are the three main pillars of deep neural network theory. Serving as a guide for students and researchers in mathematics and related fields, the book aims to equip readers with foundational knowledge on the topic. It prioritizes simplicity over generality, and presents rigorous yet accessible results to help build an understanding of the essential mathematical concepts underpinning deep learning.},
	language = {en},
	journal = {arXiv preprint arXiv:2407.18384},
	author = {Petersen, Philipp and Zech, Jakob},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Mathematics - History and Overview},
}

@inproceedings{kim_transformers_2024,
	title = {Transformers learn nonlinear features in context: {Nonconvex} mean-field dynamics on the attention landscape},
	shorttitle = {Transformers learn nonlinear features in context},
	abstract = {Large language models based on the Transformer architecture have demonstrated impressive capabilities to learn in context. However, existing theoretical studies on how this phenomenon arises are limited to the dynamics of a single layer of attention trained on linear regression tasks. In this paper, we study the optimization of a Transformer consisting of a fully connected layer followed by a linear attention layer. The MLP acts as a common nonlinear representation or feature map, greatly enhancing the power of in-context learning. We prove in the mean-field and two-timescale limit that the infinite-dimensional loss landscape for the distribution of parameters, while highly nonconvex, becomes quite benign. We also analyze the second-order stability of mean-field dynamics and show that Wasserstein gradient flow almost always avoids saddle points. Furthermore, we establish novel methods for obtaining concrete improvement rates both away from and near critical points. This represents the first saddle point analysis of mean-field dynamics in general and the techniques are of independent interest.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Kim, Juno and Suzuki, Taiji},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{rosenfeld_elephant_2018,
	title = {The elephant in the room},
	abstract = {We showcase a family of common failures of state-of-the art object detectors. These are obtained by replacing image sub-regions by another sub-image that contains a trained object. We call this “object transplanting”. Modifying an image in this manner is shown to have a non-local impact on object detection. Slight changes in object position can affect its identity according to an object detector as well as that of other objects in the image. We provide some analysis and suggest possible reasons for the reported phenomena.},
	language = {en},
	journal = {arXiv preprint arXiv:1808.03305},
	author = {Rosenfeld, Amir and Zemel, Richard and Tsotsos, John K.},
	year = {2018},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@article{zelikman_star_2022,
	title = {Star: bootstrapping reasoning with reasoning},
	shorttitle = {Star},
	abstract = {Generating step-by-step "chain-of-thought" rationales improves language model performance on complex reasoning tasks like mathematics or commonsense question-answering. However, inducing language model rationale generation currently requires either constructing massive rationale datasets or sacriﬁcing accuracy by using only few-shot inference. We propose a technique to iteratively leverage a small number of rationale examples and a large dataset without rationales, to bootstrap the ability to perform successively more complex reasoning. This technique, the "Self-Taught Reasoner" (STaR), relies on a simple loop: generate rationales to answer many questions, prompted with a few rationale examples; if the generated answers are wrong, try again to generate a rationale given the correct answer; ﬁnetune on all the rationales that ultimately yielded correct answers; repeat. We show that STaR signiﬁcantly improves performance on multiple datasets compared to a model ﬁne-tuned to directly predict ﬁnal answers, and performs comparably to ﬁnetuning a 30× larger state-of-the-art language model on CommensenseQA. Thus, STaR lets a model improve itself by learning from its own generated reasoning.},
	language = {en},
	journal = {arXiv preprint arXiv:2203.14465},
	author = {Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah D.},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{zelikman_quiet-star_2024,
	title = {Quiet-star: {Language} models can teach themselves to think before speaking},
	shorttitle = {Quiet-star},
	abstract = {When writing and talking, people sometimes pause to think. Although reasoning-focused works have often framed reasoning as a method of answering questions or completing agentic tasks, reasoning is implicit in almost all written text. For example, this applies to the steps not stated between the lines of a proof or to the theory of mind underlying a conversation. In the Self-Taught Reasoner (STaR, Zelikman et al. 2022), useful thinking is learned by inferring rationales from few-shot examples in question-answering and learning from those that lead to a correct answer. This is a highly constrained setting – ideally, a language model could instead learn to infer unstated rationales in arbitrary text. We present Quiet-STaR, a generalization of STaR in which LMs learn to generate rationales at each token to explain future text, improving their predictions. We address key challenges, including 1) the computational cost of generating continuations, 2) the fact that the LM does not initially know how to generate or use internal thoughts, and 3) the need to predict beyond individual next tokens. To resolve these, we propose a tokenwise parallel sampling algorithm, using learnable tokens indicating a thought’s start and end, and an extended teacher-forcing technique. Encouragingly, generated rationales disproportionately help model difficult-to-predict tokens and improve the LM’s ability to directly answer difficult questions. In particular, after continued pretraining of an LM on a corpus of internet text with Quiet-STaR, we find zero-shot improvements on GSM8K (5.9\%→10.9\%) and CommonsenseQA (36.3\%→47.2\%) and observe a perplexity improvement of difficult tokens in natural text. Crucially, these improvements require no fine-tuning on these tasks. Quiet-STaR marks a step towards LMs that can learn to reason in a more general and scalable way.},
	language = {en},
	journal = {arXiv preprint arXiv:2403.09629},
	author = {Zelikman, Eric and Harik, Georges and Shao, Yijia and Jayasiri, Varuna and Haber, Nick and Goodman, Noah D.},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{berglund_reversal_2024,
	title = {The reversal curse: {LLMs} trained on ``a is b" fail to learn ``b is a"},
	shorttitle = {The reversal curse},
	abstract = {We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form "A is B", it will not automatically generalize to the reverse direction "B is A". This is the Reversal Curse. For instance, if a model is trained on "Valentina Tereshkova was the first woman to travel to space", it will not automatically be able to answer the question, "Who was the first woman to travel to space?". Moreover, the likelihood of the correct answer ("Valentina Tershkova") will not be higher than for a random name. Thus, models do not generalize a prevalent pattern in their training set: if "A is B" occurs, "B is A" is more likely to occur. It is worth noting, however, that if "A is B" appears in-context, models can deduce the reverse relationship. We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as "Uriah Hawthorne is the composer of Abyssal Melodies" and showing that they fail to correctly answer "Who composed Abyssal Melodies?". The Reversal Curse is robust across model sizes and model families and is not alleviated by data augmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about real-world celebrities, such as "Who is Tom Cruise's mother? [A: Mary Lee Pfeiffer]" and the reverse "Who is Mary Lee Pfeiffer's son?". GPT-4 correctly answers questions like the former 79\% of the time, compared to 33\% for the latter. Code available at: https://github.com/lukasberglund/reversal\_curse.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Berglund, Lukas and Tong, Meg and Kaufmann, Max and Balesni, Mikita and Stickland, Asa Cooper and Korbak, Tomasz and Evans, Owain},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{magar_data_2022,
	title = {Data contamination: {From} memorization to exploitation},
	shorttitle = {Data contamination},
	abstract = {Pretrained language models are typically trained on massive web-based datasets, which are often “contaminated” with downstream test sets. It is not clear to what extent models exploit the contaminated data for downstream tasks. We present a principled method to study this question. We pretrain BERT models on joint corpora of Wikipedia and labeled downstream datasets, and ﬁne-tune them on the relevant task. Comparing performance between samples seen and unseen during pretraining enables us to deﬁne and quantify levels of memorization and exploitation. Experiments with two models and three downstream tasks show that exploitation exists in some cases, but in others the models memorize the contaminated data, but do not exploit it. We show that these two measures are affected by different factors such as the number of duplications of the contaminated data and the model size. Our results highlight the importance of analyzing massive web-scale datasets to verify that progress in NLP is obtained by better language understanding and not better data exploitation.},
	language = {en},
	booktitle = {{ACL}},
	author = {Magar, Inbal and Schwartz, Roy},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@article{wu_reasoning_2023,
	title = {Reasoning or reciting? {Exploring} the capabilities and limitations of language models through counterfactual tasks},
	shorttitle = {Reasoning or reciting?},
	abstract = {The impressive performance of recent language models across a wide range of tasks suggests that they possess a degree of abstract reasoning skills. Are these skills general and transferable, or specialized to specific tasks seen during pretraining? To disentangle these effects, we propose an evaluation framework based on "counterfactual" task variants that deviate from the default assumptions underlying standard tasks. Across a suite of 11 tasks, we observe nontrivial performance on the counterfactual variants, but nevertheless find that performance substantially and consistently degrades compared to the default conditions. This suggests that while current LMs may possess abstract task-solving skills to an extent, they often also rely on narrow, non-transferable procedures for task-solving. These results motivate a more careful interpretation of language model performance that teases apart these aspects of behavior.},
	language = {en},
	journal = {arXiv preprint arXiv:2307.02477},
	author = {Wu, Zhaofeng and Qiu, Linlu and Ross, Alexis and Akyürek, Ekin and Chen, Boyuan and Wang, Bailin and Kim, Najoung and Andreas, Jacob and Kim, Yoon},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{huang_compression_2024,
	title = {Compression represents intelligence linearly},
	abstract = {There is a belief that learning to compress well will lead to intelligence. Recently, language modeling has been shown to be equivalent to compression, which offers a compelling rationale for the success of large language models (LLMs): the development of more advanced language models is essentially enhancing compression which facilitates intelligence. Despite such appealing discussions, little empirical evidence is present for the interplay between compression and intelligence. In this work, we examine their relationship in the context of LLMs, treating LLMs as data compressors. Given the abstract concept of "intelligence", we adopt the average downstream benchmark scores as a surrogate, specifically targeting intelligence related to knowledge and commonsense, coding, and mathematical reasoning. Across 12 benchmarks, our study brings together 31 public LLMs that originate from diverse organizations. Remarkably, we find that LLMs' intelligence -- reflected by average benchmark scores -- almost linearly correlates with their ability to compress external text corpora. These results provide concrete evidence supporting the belief that superior compression indicates greater intelligence. Furthermore, our findings suggest that compression efficiency, as an unsupervised metric derived from raw text corpora, serves as a reliable evaluation measure that is linearly associated with the model capabilities. We open-source our compression datasets as well as our data collection pipelines to facilitate future researchers to assess compression properly.},
	language = {en},
	booktitle = {{COLM}},
	author = {Huang, Yuzhen and Zhang, Jinghan and Shan, Zifei and He, Junxian},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Theory},
}

@article{liu_kan_2024,
	title = {{KAN} 2.0: {Kolmogorov}-{Arnold} networks meet science},
	shorttitle = {Kan 2.0},
	abstract = {A major challenge of AI + Science lies in their inherent incompatibility: today’s AI is primarily based on connectionism, while science depends on symbolism. To bridge the two worlds, we propose a framework to seamlessly synergize Kolmogorov-Arnold Networks (KANs) and science. The framework highlights KANs’ usage for three aspects of scientific discovery: identifying relevant features, revealing modular structures, and discovering symbolic formulas. The synergy is bidirectional: science to KAN (incorporating scientific knowledge into KANs), and KAN to science (extracting scientific insights from KANs). We highlight major new functionalities in pykan: (1) MultKAN: KANs with multiplication nodes. (2) kanpiler: a KAN compiler that compiles symbolic formulas into KANs. (3) tree converter: convert KANs (or any neural networks) to tree graphs. Based on these tools, we demonstrate KANs’ capability to discover various types of physical laws, including conserved quantities, Lagrangians, symmetries, and constitutive laws.},
	language = {en},
	journal = {arXiv preprint arXiv:2408.10205},
	author = {Liu, Ziming and Ma, Pingchuan and Wang, Yixuan and Matusik, Wojciech and Tegmark, Max},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Physics - Data Analysis, Statistics and Probability, Physics - Computational Physics},
}

@article{liu_kan_2024-1,
	title = {{KAN}: {Kolmogorov}-{Arnold} networks},
	shorttitle = {Kan},
	abstract = {Inspired by the Kolmogorov-Arnold representation theorem, we propose KolmogorovArnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs). While MLPs have fixed activation functions on nodes (“neurons”), KANs have learnable activation functions on edges (“weights”). KANs have no linear weights at all – every weight parameter is replaced by a univariate function parametrized as a spline. We show that this seemingly simple change makes KANs outperform MLPs in terms of accuracy and interpretability, on small-scale AI + Science tasks. For accuracy, smaller KANs can achieve comparable or better accuracy than larger MLPs in function fitting tasks. Theoretically and empirically, KANs possess faster neural scaling laws than MLPs. For interpretability, KANs can be intuitively visualized and can easily interact with human users. Through two examples in mathematics and physics, KANs are shown to be useful “collaborators” helping scientists (re)discover mathematical and physical laws. In summary, KANs are promising alternatives for MLPs, opening opportunities for further improving today’s deep learning models which rely heavily on MLPs.},
	language = {en},
	journal = {arXiv preprint arXiv:2404.19756},
	author = {Liu, Ziming and Wang, Yixuan and Vaidya, Sachin and Ruehle, Fabian and Halverson, James and Soljačić, Marin and Hou, Thomas Y. and Tegmark, Max},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Condensed Matter - Disordered Systems and Neural Networks},
}

@article{ye_physics_2024,
	title = {Physics of language models: {Part} 2.1, grade-school math and the hidden reasoning process},
	shorttitle = {Physics of language models},
	abstract = {Recent advances in language models have demonstrated their capability to solve mathematical reasoning problems, achieving near-perfect accuracy on grade-school level math benchmarks like GSM8K. In this paper, we formally study how language models solve these problems. We design a series of controlled experiments to address several fundamental questions: (1) Can language models truly develop reasoning skills, or do they simply memorize templates? (2) What is the model’s hidden (mental) reasoning process? (3) Do models solve math questions using skills similar to or different from humans? (4) Do models trained on GSM8K-like datasets develop reasoning skills beyond those necessary for solving GSM8K problems? (5) What mental process causes models to make reasoning mistakes? (6) How large or deep must a model be to effectively solve GSM8K-level math questions? Our study uncovers many hidden mechanisms by which language models solve mathematical questions, providing insights that extend beyond current understandings of LLMs.},
	language = {en},
	journal = {arXiv preprint arXiv:2407.20311},
	author = {Ye, Tian and Xu, Zicheng and Li, Yuanzhi and Allen-Zhu, Zeyuan},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{von_kugelgen_self-supervised_2021,
	title = {Self-supervised learning with data augmentations provably isolates content from style},
	volume = {34},
	booktitle = {Advances in neural information processing systems},
	author = {Von Kügelgen, Julius and Sharma, Yash and Gresele, Luigi and Brendel, Wieland and Schölkopf, Bernhard and Besserve, Michel and Locatello, Francesco},
	year = {2021},
	pages = {16451--16467},
}

@article{grunwald_minimum_2019,
	title = {Minimum description length revisited},
	volume = {11},
	issn = {2661-3352, 2661-3344},
	doi = {10.1142/S2661335219300018},
	abstract = {This is an up-to-date introduction to and overview of the Minimum Description Length (MDL) Principle, a theory of inductive inference that can be applied to general problems in statistics, machine learning and pattern recognition. While MDL was originally based on data compression ideas, this introduction can be read without any knowledge thereof. It takes into account all major developments since 2007, the last time an extensive overview was written. These include new methods for model selection and averaging and hypothesis testing, as well as the ﬁrst completely general deﬁnition of MDL estimators. Incorporating these developments, MDL can be seen as a powerful extension of both penalized likelihood and Bayesian approaches, in which penalization functions and prior distributions are replaced by more general luckiness functions, average-case methodology is replaced by a more robust worst-case approach, and in which methods classically viewed as highly distinct, such as AIC vs BIC and cross-validation vs Bayes can, to a large extent, be viewed from a uniﬁed perspective.},
	language = {en},
	number = {01},
	journal = {International Journal of Mathematics for Industry},
	author = {Grünwald, Peter and Roos, Teemu},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Information Theory, Statistics - Methodology},
	pages = {1930001},
}

@article{shwartz_ziv_compress_2024,
	title = {To compress or not to compress—self-supervised learning and information theory: {A} review},
	volume = {26},
	number = {3},
	journal = {Entropy},
	author = {Shwartz Ziv, Ravid and LeCun, Yann},
	year = {2024},
	pages = {252},
}

@inproceedings{chughtai_toy_2023,
	title = {A toy model of universality: {Reverse} engineering how networks learn group operations},
	abstract = {Universality is a key hypothesis in mechanistic interpretability – that different models learn similar features and circuits when trained on similar tasks. In this work, we study the universality hypothesis by examining how small neural networks learn to implement group composition. We present a novel algorithm by which neural networks may implement composition for any finite group via mathematical representation theory. We then show that networks consistently learn this algorithm by reverse engineering model logits and weights, and confirm our understanding using ablations. By studying networks of differing architectures trained on various groups, we find mixed evidence for universality: using our algorithm, we can completely characterize the family of circuits and features that networks learn on this task, but for a given network the precise circuits learned – as well as the order they develop – are arbitrary.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Chughtai, Bilal and Chan, Lawrence and Nanda, Neel},
	year = {2023},
}

@inproceedings{lyu_finite-sample_2022,
	title = {On finite-sample identifiability of contrastive learning-based nonlinear independent component analysis},
	abstract = {Nonlinear independent component analysis (nICA) aims at recovering statistically independent latent components that are mixed by unknown nonlinear functions. Central to nICA is the identifiability of the latent components, which had been elusive until very recently. Specifically, Hyva¨rinen et al. have shown that the nonlinearly mixed latent components are identifiable (up to often inconsequential ambiguities) under a generalized contrastive learning (GCL) formulation, given that the latent components are independent conditioned on a certain auxiliary variable. The GCL-based identifiability of nICA is elegant, and establishes interesting connections between nICA and popular unsupervised/self-supervised learning paradigms in representation learning, causal learning, and factor disentanglement. However, existing identifiability analyses of nICA all build upon an unlimited sample assumption and the use of ideal universal function learners—which creates a non-negligible gap between theory and practice. Closing the gap is a nontrivial challenge, as there is a lack of established “textbook” routine for finite sample analysis of such unsupervised problems. This work puts forth a finite-sample identifiability analysis of GCL-based nICA. Our analytical framework judiciously combines the properties of the GCL loss function, statistical generalization analysis, and numerical differentiation. Our framework also takes the learning function’s approximation error into consideration, and reveals an intuitive trade-off between the complexity and expressiveness of the employed function learner. Numerical experiments are used to validate the theorems.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Lyu, Qi and Fu, Xiao},
	year = {2022},
}

@inproceedings{ahuja_towards_2022,
	title = {Towards efficient representation identification in supervised learning},
	isbn = {2640-3498},
	booktitle = {Conference on {Causal} {Learning} and {Reasoning}},
	author = {Ahuja, Kartik and Mahajan, Divyat and Syrgkanis, Vasilis and Mitliagkas, Ioannis},
	year = {2022},
	pages = {19--43},
}

@inproceedings{morwani_feature_2024,
	title = {Feature emergence via margin maximization: {Case} studies in algebraic tasks},
	abstract = {Understanding the internal representations learned by neural networks is a cornerstone challenge in the science of machine learning. While there have been significant recent strides in some cases towards understanding how neural networks implement specific target functions, this paper explores a complementary question – why do networks arrive at particular computational strategies? Our inquiry focuses on the algebraic learning tasks of modular addition, sparse parities, and finite group operations. Our primary theoretical findings analytically characterize the features learned by stylized neural networks for these algebraic tasks. Notably, our main technique demonstrates how the principle of margin maximization alone can be used to fully specify the features learned by the network. Specifically, we prove that the trained networks utilize Fourier features to perform modular addition and employ features corresponding to irreducible group-theoretic representations to perform compositions in general groups, aligning closely with the empirical observations of Nanda et al. (2023) and Chughtai et al. (2023). More generally, we hope our techniques can help to foster a deeper understanding of why neural networks adopt specific computational strategies.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Morwani, Depen and Edelman, Benjamin L and Oncescu, Costin-Andrei and Zhao, Rosie and Kakade, Sham},
	year = {2024},
}

@article{ibrahim_occams_2024,
	title = {Occam's {Razor} for self supervised learning: {What} is sufficient to learn good representations?},
	shorttitle = {Occam's razor for self supervised learning},
	abstract = {Deep Learning is often depicted as a trio of data-architecture-loss. Yet, recent Self Supervised Learning (SSL) solutions have introduced numerous additional design choices, e.g., a projector network, positive views, or teacher-student networks. These additions pose two challenges. First, they limit the impact of theoretical studies that often fail to incorporate all those intertwined designs. Second, they slow-down the deployment of SSL methods to new domains as numerous hyperparameters need to be carefully tuned. In this study, we bring forward the surprising observation that–at least for pretraining datasets of up to a few hundred thousands samples–the additional designs introduced by SSL do not contribute to the quality of the learned representations. That finding not only provides legitimacy to existing theoretical studies, but also simplifies the practitioner’s path to SSL deployment in numerous small and medium scale settings. Our finding answers a long-lasting question: the often-experienced sensitivity to training settings and hyper-parameters encountered in SSL come from their design, rather than the absence of supervised guidance.},
	language = {en},
	journal = {arXiv preprint arXiv:2406.10743},
	author = {Ibrahim, Mark and Klindt, David and Balestriero, Randall},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@misc{tsai_self-supervised_2021,
	title = {Self-supervised learning from a multi-view perspective},
	abstract = {As a subset of unsupervised representation learning, self-supervised representation learning adopts self-deﬁned signals as supervision and uses the learned representation for downstream tasks, such as object detection and image captioning. Many proposed approaches for self-supervised learning follow naturally a multi-view perspective, where the input (e.g., original images) and the self-supervised signals (e.g., augmented images) can be seen as two redundant views of the data. Building from this multi-view perspective, this paper provides an information-theoretical framework to better understand the properties that encourage successful self-supervised learning. Speciﬁcally, we demonstrate that self-supervised learned representations can extract task-relevant information and discard task-irrelevant information. Our theoretical framework paves the way to a larger space of self-supervised learning objective design. In particular, we propose a composite objective that bridges the gap between prior contrastive and predictive learning objectives, and introduce an additional objective term to discard task-irrelevant information. To verify our analysis, we conduct controlled experiments to evaluate the impact of the composite objectives. We also explore our framework’s empirical generalization beyond the multi-view perspective, where the cross-view redundancy may not be clearly observed.},
	language = {en},
	author = {Tsai, Yao-Hung Hubert and Wu, Yue and Salakhutdinov, Ruslan and Morency, Louis-Philippe},
	month = mar,
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{fini_self-supervised_2022,
	address = {New Orleans, LA, USA},
	title = {Self-supervised models are continual learners},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66546-946-3},
	doi = {10.1109/CVPR52688.2022.00940},
	abstract = {Self-supervised models have been shown to produce comparable or better visual representations than their supervised counterparts when trained offline on unlabeled data at scale. However, their efficacy is catastrophically reduced in a Continual Learning (CL) scenario where data is presented to the model sequentially. In this paper, we show that self-supervised loss functions can be seamlessly converted into distillation mechanisms for CL by adding a predictor network that maps the current state of the representations to their past state. This enables us to devise a framework for Continual self-supervised visual representation Learning that (i) significantly improves the quality of the learned representations, (ii) is compatible with several state-of-the-art self-supervised objectives, and (iii) needs little to no hyperparameter tuning. We demonstrate the effectiveness of our approach empirically by training six popular self-supervised models in various CL settings. Code: github.com/DonkeyShot21/cassle.},
	language = {en},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Fini, Enrico and Da Costa, Victor G. Turrisi and Alameda-Pineda, Xavier and Ricci, Elisa and Alahari, Karteek and Mairal, Julien},
	year = {2022},
	pages = {9611--9620},
}

@inproceedings{ahuja_interventional_2023,
	title = {Interventional causal representation learning},
	abstract = {Causal representation learning seeks to extract high-level latent factors from low-level sensory data. Most existing methods rely on observational data and structural assumptions (e.g., conditional independence) to identify the latent factors. However, interventional data is prevalent across applications. Can interventional data facilitate causal representation learning? We explore this question in this paper. The key observation is that interventional data often carries geometric signatures of the latent factors’ support (i.e. what values each latent can possibly take). For example, when the latent factors are causally connected, interventions can break the dependency between the intervened latents’ support and their ancestors’. Leveraging this fact, we prove that the latent causal factors can be identified up to permutation and scaling given data from perfect do interventions. Moreover, we can achieve block affine identification, namely the estimated latent factors are only entangled with a few other latents if we have access to data from imperfect interventions. These results highlight the unique power of interventional data in causal representation learning; they can enable provable identification of latent factors without any assumptions about their distributions or dependency structure.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Ahuja, Kartik and Mahajan, Divyat and Wang, Yixin and Bengio, Yoshua},
	year = {2023},
}

@article{yu_survey_2024,
	title = {A survey on evaluation of out-of-distribution generalization},
	journal = {arXiv preprint arXiv:2403.01874},
	author = {Yu, Han and Liu, Jiashuo and Zhang, Xingxuan and Wu, Jiayun and Cui, Peng},
	year = {2024},
}

@inproceedings{von_kugelgen_nonparametric_2023,
	title = {Nonparametric identifiability of causal representations from unknown interventions},
	volume = {36},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {von Kügelgen, Julius and Besserve, Michel and Wendong, Liang and Gresele, Luigi and Kekić, Armin and Bareinboim, Elias and Blei, David and Schölkopf, Bernhard},
	year = {2023},
}

@inproceedings{sablayrolles_spreading_2019,
	title = {Spreading vectors for similarity search},
	abstract = {Discretizing multi-dimensional data distributions is a fundamental step of modern indexing methods. State-of-the-art techniques learn parameters of quantizers on training data for optimal performance, thus adapting quantizers to the data. In this work, we propose to reverse this paradigm and adapt the data to the quantizer: we train a neural net which last layer forms a ﬁxed parameter-free quantizer, such as pre-deﬁned points of a hyper-sphere. As a proxy objective, we design and train a neural network that favors uniformity in the spherical latent space, while preserving the neighborhood structure after the mapping. We propose a new regularizer derived from the Kozachenko–Leonenko differential entropy estimator to enforce uniformity and combine it with a locality-aware triplet loss. Experiments show that our end-to-end approach outperforms most learned quantization methods, and is competitive with the state of the art on widely adopted benchmarks. Furthermore, we show that training without the quantization step results in almost no difference in accuracy, but yields a generic catalyzer that can be applied with any subsequent quantizer. The code is available online1.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Sablayrolles, Alexandre and Douze, Matthijs and Schmid, Cordelia and Jégou, Hervé},
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{ren_rejuvenating_2023,
	title = {Rejuvenating image-{GPT} as strong visual representation learners},
	booktitle = {Forty-first {International} {Conference} on {Machine} {Learning}},
	author = {Ren, Sucheng and Wang, Zeyu and Zhu, Hongru and Xiao, Junfei and Yuille, Alan and Xie, Cihang},
	year = {2023},
}

@inproceedings{razavi_generating_2019,
	title = {Generating diverse high-fidelity images with {VQ}-{VAE}-2},
	abstract = {We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE) models for large scale image generation. To this end, we scale and enhance the autoregressive priors used in VQ-VAE to generate synthetic samples of much higher coherence and ﬁdelity than possible before. We use simple feed-forward encoder and decoder networks, making our model an attractive candidate for applications where the encoding and/or decoding speed is critical. Additionally, VQ-VAE requires sampling an autoregressive model only in the compressed latent space, which is an order of magnitude faster than sampling in the pixel space, especially for large images. We demonstrate that a multi-scale hierarchical organization of VQ-VAE, augmented with powerful priors over the latent codes, is able to generate samples with quality that rivals that of state of the art Generative Adversarial Networks on multifaceted datasets such as ImageNet, while not suffering from GAN’s known shortcomings such as mode collapse and lack of diversity.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Razavi, Ali},
	year = {2019},
}

@article{zhang_transformer-based_2024,
	title = {Transformer-based models are not yet perfect at learning to emulate structural recursion},
	abstract = {This paper investigates the ability of transformer-based models to learn structural recursion from examples. Recursion is a universal concept in both natural and formal languages. Structural recursion is central to the programming language and formal mathematics tasks where symbolic tools currently excel beyond neural models, such as inferring semantic relations between datatypes and emulating program behavior. We introduce a general framework that nicely connects the abstract concepts of structural recursion in the programming language domain to concrete sequence modeling problems and learned models’ behavior. The framework includes a representation that captures the general syntax of structural recursion, coupled with two different frameworks for understanding their semantics—one that is more natural from a programming languages perspective and one that helps bridge that perspective with a mechanistic understanding of the underlying transformer architecture.},
	language = {en},
	journal = {arXiv preprint arXiv:2401.12947},
	author = {Zhang, Dylan and Tigges, Curt and Zhang, Zory and Biderman, Stella and Raginsky, Maxim and Ringer, Talia},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Formal Languages and Automata Theory, Computer Science - Logic in Computer Science, Computer Science - Programming Languages},
}

@inproceedings{child_very_2021,
	title = {Very deep {VAEs} generalize autoregressive models and can outperform them on images},
	abstract = {We present a hierarchical VAE that, for the first time, generates samples quickly \${\textbackslash}textit\{and\}\$ outperforms the PixelCNN in log-likelihood on all natural image benchmarks. We begin by observing that, in theory, VAEs can actually represent autoregressive models, as well as faster, better models if they exist, when made sufficiently deep. Despite this, autoregressive models have historically outperformed VAEs in log-likelihood. We test if insufficient depth explains why by scaling a VAE to greater stochastic depth than previously explored and evaluating it CIFAR-10, ImageNet, and FFHQ. In comparison to the PixelCNN, these very deep VAEs achieve higher likelihoods, use fewer parameters, generate samples thousands of times faster, and are more easily applied to high-resolution images. Qualitative studies suggest this is because the VAE learns efficient hierarchical visual representations. We release our source code and models at https://github.com/openai/vdvae.},
	language = {en},
	author = {Child, Rewon},
	year = {2021},
}

@article{doersch_tutorial_2021,
	title = {Tutorial on variational autoencoders},
	abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits [1, 2], faces [1, 3, 4], house numbers [5, 6], CIFAR images [6], physical models of scenes [4], segmentation [7], and predicting the future from static images [8]. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
	language = {en},
	journal = {arXiv preprint arXiv:1606.05908},
	author = {Doersch, Carl},
	year = {2021},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{kipf_variational_2016,
	title = {Variational graph auto-encoders},
	abstract = {We introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets.},
	language = {en},
	journal = {arXiv preprint arXiv:1611.07308},
	author = {Kipf, Thomas N. and Welling, Max},
	year = {2016},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{mirzadeh_gsm-symbolic_2024,
	title = {{GSM}-symbolic: {Understanding} the limitations of mathematical reasoning in large language models},
	shorttitle = {Gsm-symbolic},
	abstract = {Recent advancements in Large Language Models (LLMs) have sparked interest in their formal reasoning capabilities, particularly in mathematics. The GSM8K benchmark is widely used to assess the mathematical reasoning of models on grade-school-level questions. While the performance of LLMs on GSM8K has significantly improved in recent years, it remains unclear whether their mathematical reasoning capabilities have genuinely advanced, raising questions about the reliability of the reported metrics. To address these concerns, we conduct a largescale study on several state-of-the-art open and closed models. To overcome the limitations of existing evaluations, we introduce GSM-Symbolic, an improved benchmark created from symbolic templates that allow for the generation of a diverse set of questions. GSM-Symbolic enables more controllable evaluations, providing key insights and more reliable metrics for measuring the reasoning capabilities of models.Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically, the performance of all models declines when only the numerical values in the question are altered in the GSM-Symbolic benchmark. Furthermore, we investigate the fragility of mathematical reasoning in these models and demonstrate that their performance significantly deteriorates as the number of clauses in a question increases. We hypothesize that this decline is due to the fact that current LLMs are not capable of genuine logical reasoning; instead, they attempt to replicate the reasoning steps observed in their training data. When we add a single clause that appears relevant to the question, we observe significant performance drops (up to 65\%) across all state-of-the-art models, even though the added clause does not contribute to the reasoning chain needed to reach the final answer. Overall, our work provides a more nuanced understanding of LLMs’ capabilities and limitations in mathematical reasoning.},
	language = {en},
	journal = {arXiv preprint arXiv:2410.05229},
	author = {Mirzadeh, Iman and Alizadeh, Keivan and Shahrokhi, Hooman and Tuzel, Oncel and Bengio, Samy and Farajtabar, Mehrdad},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{zhang_interpreting_2024,
	title = {Interpreting and improving large language models in arithmetic calculation},
	abstract = {Large language models (LLMs) have demonstrated remarkable potential across numerous applications and have shown an emergent ability to tackle complex reasoning tasks, such as mathematical computations. However, even for the simplest arithmetic calculations, the intrinsic mechanisms behind LLMs remain mysterious, making it challenging to ensure reliability. In this work, we delve into uncovering a specific mechanism by which LLMs execute calculations. Through comprehensive experiments, we find that LLMs frequently involve a small fraction ({\textless} 5\%) of attention heads, which play a pivotal role in focusing on operands and operators during calculation processes. Subsequently, the information from these operands is processed through multi-layer perceptrons (MLPs), progressively leading to the final solution. These pivotal heads/MLPs, though identified on a specific dataset, exhibit transferability across different datasets and even distinct tasks. This insight prompted us to investigate the potential benefits of selectively fine-tuning these essential heads/MLPs to boost the LLMs’ computational performance. We empirically find that such precise tuning can yield notable enhancements on mathematical prowess, without compromising the performance on non-mathematical tasks. Our work serves as a preliminary exploration into the arithmetic calculation abilities inherent in LLMs, laying a solid foundation to reveal more intricate mathematical tasks.},
	language = {en},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Zhang, Wei and Wan, Chaoqun and Zhang, Yonggang and Cheung, Yiu-ming and Tian, Xinmei and Shen, Xu and Ye, Jieping},
	year = {2024},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{connor_variational_2021,
	title = {Variational autoencoder with learned latent structure},
	language = {en},
	booktitle = {{AISTATS}},
	author = {Connor, Marissa and Canal, Gregory and Rozell, Christopher},
	year = {2021},
}

@inproceedings{he_variational_2018,
	title = {Variational autoencoders with jointly optimized latent dependency structure},
	booktitle = {International conference on learning representations},
	author = {He, Jiawei and Gong, Yu and Marino, Joseph and Mori, Greg and Lehrmann, Andreas},
	year = {2018},
}

@article{teh_energy-based_2003,
	title = {Energy-based models for sparse overcomplete representations},
	volume = {4},
	abstract = {We present a new way of extending independent components analysis (ICA) to overcomplete representations. In contrast to the causal generative extensions of ICA which maintain marginal independence of sources, we deﬁne features as deterministic (linear) functions of the inputs. This assumption results in marginal dependencies among the features, but conditional independence of the features given the inputs. By assigning energies to the features a probability distribution over the input states is deﬁned through the Boltzmann distribution. Free parameters of this model are trained using the contrastive divergence objective (Hinton, 2002). When the number of features is equal to the number of input dimensions this energy-based model reduces to noiseless ICA and we show experimentally that the proposed learning algorithm is able to perform blind source separation on speech data. In additional experiments we train overcomplete energy-based models to extract features from various standard data-sets containing speech, natural images, hand-written digits and faces.},
	language = {en},
	journal = {Journal of Machine Learning Research},
	author = {Teh, Yee Whye and Welling, Max and Osindero, Simon and Hinton, Geoffrey E},
	year = {2003},
	pages = {1235--1260},
}

@inproceedings{du_implicit_2019,
	title = {Implicit generation and modeling with energy based models},
	abstract = {Energy based models (EBMs) are appealing due to their generality and simplicity in likelihood modeling, but have been traditionally difﬁcult to train. We present techniques to scale MCMC based EBM training on continuous neural networks, and we show its success on the high-dimensional data domains of ImageNet32x32, ImageNet128x128, CIFAR-10, and robotic hand trajectories, achieving better samples than other likelihood models and nearing the performance of contemporary GAN approaches, while covering all modes of the data. We highlight some unique capabilities of implicit generation such as compositionality and corrupt image reconstruction and inpainting. Finally, we show that EBMs are useful models across a wide variety of tasks, achieving state-of-the-art out-of-distribution classiﬁcation, adversarially robust classiﬁcation, state-of-the-art continual online class learning, and coherent long term predicted trajectory rollouts.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Du, Yilun and Mordatch, Igor},
	year = {2019},
}

@article{merrill_parallelism_2023,
	title = {The parallelism tradeoff: {Limitations} of log-precision transformers},
	volume = {11},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Merrill, William and Sabharwal, Ashish},
	year = {2023},
	pages = {531--545},
}

@article{feng_rethinking_2023,
	title = {Rethinking model-based, policy-based, and value-based reinforcement learning via the lens of representation complexity},
	abstract = {Reinforcement Learning (RL) encompasses diverse paradigms, including model-based RL, policy-based RL, and value-based RL, each tailored to approximate the model, optimal policy, and optimal value function, respectively. This work investigates the potential hierarchy of representation complexity — the complexity of functions to be represented — among these RL paradigms. We first demonstrate that, for a broad class of Markov decision processes (MDPs), the model can be represented by constant-depth circuits with polynomial size or Multi-Layer Perceptrons (MLPs) with constant layers and polynomial hidden dimension. However, the representation of the optimal policy and optimal value proves to be NP-complete and unattainable by constant-layer MLPs with polynomial size. This demonstrates a significant representation complexity gap between model-based RL and model-free RL, which includes policy-based RL and value-based RL. To further explore the representation complexity hierarchy between policy-based RL and value-based RL, we introduce another general class of MDPs where both the model and optimal policy can be represented by constant-depth circuits with polynomial size or constant-layer MLPs with polynomial size. In contrast, representing the optimal value is P-complete and intractable via a constant-layer MLP with polynomial hidden dimension. This accentuates the intricate representation complexity associated with value-based RL compared to policy-based RL. In summary, we unveil a potential representation complexity hierarchy within RL — representing the model emerges as the easiest task, followed by the optimal policy, while representing the optimal value function presents the most intricate challenge.},
	language = {en},
	journal = {arXiv preprint arXiv:2312.17248},
	author = {Feng, Guhao and Zhong, Han},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computational Complexity, Computer Science - Data Structures and Algorithms},
}

@inproceedings{sonderby_ladder_2016,
	title = {Ladder variational autoencoders},
	abstract = {Variational autoencoders are powerful models for unsupervised learning. However deep models with several layers of dependent stochastic variables are difﬁcult to train which limits the improvements obtained using these highly expressive models. We propose a new inference model, the Ladder Variational Autoencoder, that recursively corrects the generative distribution by a data dependent approximate likelihood in a process resembling the recently proposed Ladder Network. We show that this model provides state of the art predictive log-likelihood and tighter log-likelihood lower bound compared to the purely bottom-up inference in layered Variational Autoencoders and other generative models. We provide a detailed analysis of the learned hierarchical latent representation and show that our new inference model is qualitatively different and utilizes a deeper more distributed hierarchy of latent variables. Finally, we observe that batch-normalization and deterministic warm-up (gradually turning on the KL-term) are crucial for training variational models with many stochastic layers.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Sønderby, Casper Kaae and Raiko, Tapani and Maaløe, Lars and Sønderby, Søren Kaae and Winther, Ole},
	year = {2016},
}

@article{lampinen_learned_2024,
	title = {Learned feature representations are biased by complexity, learning order, position, and more},
	journal = {arXiv preprint arXiv:2405.05847},
	author = {Lampinen, Andrew Kyle and Chan, Stephanie CY and Hermann, Katherine},
	year = {2024},
}

@article{chen_variational_2016,
	title = {Variational lossy autoencoder},
	journal = {arXiv preprint arXiv:1611.02731},
	author = {Chen, Xi and Kingma, Diederik P. and Salimans, Tim and Duan, Yan and Dhariwal, Prafulla and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
	year = {2016},
}

@inproceedings{figurnov_implicit_2018,
	title = {Implicit reparameterization gradients},
	abstract = {By providing a simple and efﬁcient way of computing low-variance gradients of continuous random variables, the reparameterization trick has become the technique of choice for training a variety of latent variable models. However, it is not applicable to a number of important continuous distributions. We introduce an alternative approach to computing reparameterization gradients based on implicit differentiation and demonstrate its broader applicability by applying it to Gamma, Beta, Dirichlet, and von Mises distributions, which cannot be used with the classic reparameterization trick. Our experiments show that the proposed approach is faster and more accurate than the existing gradient estimators for these distributions.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Figurnov, Mikhail and Mohamed, Shakir and Mnih, Andriy},
	year = {2018},
}

@inproceedings{yang_large_2024,
	title = {Large language models as optimizers},
	abstract = {Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We ﬁrst showcase OPRO on linear regression and traveling salesman problems, then move on to our main application in prompt optimization, where the goal is to ﬁnd instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8\% on GSM8K, and by up to 50\% on Big-Bench Hard tasks. Code at https://github.com/google-deepmind/opro.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Yang, Chengrun and Wang, Xuezhi and Lu, Yifeng and Liu, Hanxiao},
	year = {2024},
}

@inproceedings{sun_autohint_2023,
	title = {Autohint: {Automatic} prompt optimization with hint generation},
	shorttitle = {Autohint},
	abstract = {This paper presents AutoHint, a novel framework for automatic prompt engineering and optimization for Large Language Models (LLM). While LLMs have demonstrated remarkable ability in achieving high-quality annotation in various tasks, the key to applying this ability to specific tasks lies in developing high-quality prompts. Thus we propose a framework to inherit the merits of both zero-shot learning and few-shot learning by incorporating enriched instructions derived from input-output demonstrations to optimize original prompt. We refer to the enrichment as the Hint and propose a framework to automatically generate the hint from labeled data. More concretely, starting from an initial prompt, our method first instructs a LLM to deduce new hints for selected samples from incorrect predictions, and then summarizes from per-sample hints and adds the results back to the initial prompt to form a new, enriched instruction. The proposed method is evaluated on the BIG-Bench Instruction Induction dataset for both zero-shot and few-shot prompts, where experiments demonstrate that our method is able to significantly boost accuracy for multiple tasks.},
	language = {en},
	booktitle = {{KDD}},
	author = {Sun, Hong and Li, Xue and Xu, Yinchuan and Homma, Youkow and Cao, Qi and Wu, Min and Jiao, Jian and Charles, Denis},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{rafailov_direct_2023,
	title = {Direct preference optimization: {Your} language model is secretly a reward model},
	abstract = {While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difﬁcult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and ﬁne-tune the unsupervised LM to align with these preferences, often with reinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, ﬁrst ﬁtting a reward model that reﬂects the human preferences, and then ﬁne-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper, we leverage a mapping between reward functions and optimal policies to show that this constrained reward maximization problem can be optimized exactly with a single stage of policy training, essentially solving a classiﬁcation problem on the human preference data. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant, and computationally lightweight, eliminating the need for ﬁtting a reward model, sampling from the LM during ﬁne-tuning, or performing signiﬁcant hyperparameter tuning. Our experiments show that DPO can ﬁne-tune LMs to align with human preferences as well as or better than existing methods. Notably, ﬁne-tuning with DPO exceeds RLHF’s ability to control sentiment of generations and improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
	year = {2023},
}

@article{zhao_m3pl_2024,
	title = {M\${\textasciicircum}3\${PL}: {Identifying} and exploiting view bias of prompt learning},
	issn = {2835-8856},
	shorttitle = {M\${\textasciicircum}3\$pl},
	abstract = {Prompt learning is an effective means of fine-tuning multi-modal foundation models such as CLIP. Despite existing success, the inner mechanism of multi-modal prompt learning has not been well understood. In this work, we identify an inductive bias of multi-modal prompt learning, which we refer to as view bias, that the learned prompts may extract only a partial subset of useful features (views) and ignore others. This bias can undermine the model's generalization ability, particularly under distribution shifts. We further observe that independently trained prompts have distinct view biases, contrary to the existing belief that they may converge to similar local optima due to having the same cross-modal representation matching objective. Based on our observations, we propose Multi-modal Matching Multi-Prompt Learning (M\${\textasciicircum}3\$PL), which incorporates multiple paired prompts and a cross-modal contrastive regularizer that facilitates the prompt pairs to encapsulate a broader spectrum of views. Extensive experiments show that M\${\textasciicircum}3\$PL effectively boosts the model's generalization capability, achieving state-of-the-art performance under various distribution shifts.},
	language = {en},
	journal = {Transactions on Machine Learning Research},
	author = {Zhao, Chujie and Zhang, Tianren and Chen, Guanyu and Jiang, Yizhou and Chen, Feng},
	year = {2024},
}

@book{odonnell_analysis_2021,
  title={Analysis of boolean functions},
  author={O'Donnell, Ryan},
  year={2014},
  publisher={Cambridge University Press}
}

@article{bhattamishra_simplicity_2023,
	title = {Simplicity bias in transformers and their ability to learn sparse boolean functions},
	abstract = {Despite the widespread success of Transformers on NLP tasks, recent works have found that they struggle to model several formal languages when compared to recurrent models. This raises the question of why Transformers perform well in practice and whether they have any properties that enable them to generalize better than recurrent models. In this work, we conduct an extensive empirical study on Boolean functions to demonstrate the following: (i) Random Transformers are relatively more biased towards functions of low sensitivity. (ii) When trained on Boolean functions, both Transformers and LSTMs prioritize learning functions of low sensitivity, with Transformers ultimately converging to functions of lower sensitivity. (iii) On sparse Boolean functions which have low sensitivity, we find that Transformers generalize near perfectly even in the presence of noisy labels whereas LSTMs overfit and achieve poor generalization accuracy. Overall, our results provide strong quantifiable evidence that suggests differences in the inductive biases of Transformers and recurrent models which may help explain Transformer’s effective generalization performance despite relatively limited expressiveness.},
	language = {en},
	journal = {arXiv preprint arXiv:2211.12316},
	author = {Bhattamishra, Satwik and Patel, Arkil and Kanade, Varun and Blunsom, Phil},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@article{liu_grokking_2023,
	title = {Grokking as compression: {A} nonlinear complexity perspective},
	shorttitle = {Grokking as compression},
	abstract = {We attribute grokking, the phenomenon where generalization is much delayed after memorization, to compression. We define linear mapping number (LMN) to measure network complexity, which is a generalized version of linear region number for ReLU networks. LMN can nicely characterize neural network compression before generalization. Although L2 norm has been popular to characterize model complexity, we argue in favor of LMN for a number of reasons: (1) LMN can be naturally interpreted as information/computation, while L2 cannot. (2) In the compression phase, LMN has nice linear relations with test losses, while L2 is correlated with test losses in a complicated nonlinear way. (3) LMN also reveals an intriguing phenomenon of the XOR network switching between two generalization solutions, while L2 does not. Besides explaning grokking, we argue that LMN is a promising candidate as the neural network version of the Kolmogorov complexity, since it explicitly considers local or conditioned linear computations aligned with the nature of modern artificial neural networks.},
	language = {en},
	journal = {arXiv preprint arXiv:2310.05918},
	author = {Liu, Ziming and Zhong, Ziqian and Tegmark, Max},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}


@inproceedings{abbe_sgd_2023,
	title = {{SGD} learning on neural networks: {Leap} complexity and saddle-to-saddle dynamics},
	isbn = {2640-3498},
	booktitle = {The {Thirty} {Sixth} {Annual} {Conference} on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Abbe, Emmanuel and Adsera, Enric Boix and Misiakiewicz, Theodor},
	year = {2023},
	pages = {2552--2623},
	file = {Abbe - SGD learning on neural networks leap complexity a.pdf:C\:\\Users\\admin\\Zotero\\storage\\NYE4VUDB\\Abbe - SGD learning on neural networks leap complexity a.pdf:application/pdf},
}


@article{liu_transformers_2023,
	title = {Transformers learn shortcuts to automata},
	abstract = {Algorithmic reasoning requires capabilities which are most naturally understood through recurrent models of computation, like the Turing machine. However, Transformer models, while lacking recurrence, are able to perform such reasoning using far fewer layers than the number of reasoning steps. This raises the question: what solutions are learned by these shallow and non-recurrent models? We show that a low-depth Transformer can represent the computations of any ﬁnite-state automaton (thus, any bounded-memory algorithm), by hierarchically reparameterizing its recurrent dynamics. Our theoretical results characterize shortcut solutions, whereby a Transformer with o(T ) layers can exactly replicate the computation of an automaton on an input sequence of length T . We ﬁnd that polynomial-sized O(log T )-depth solutions always exist; furthermore, O(1)-depth simulators are surprisingly common, and can be understood using tools from Krohn-Rhodes theory and circuit complexity. Empirically, we ﬁnd that Transformers converge to shortcut solutions with standard training, across a wide variety of automata. We further investigate the brittleness of these solutions and propose potential mitigations.},
	language = {en},
	journal = {arXiv preprint arXiv:2210.10749},
	author = {Liu, Bingbin and Ash, Jordan T. and Goel, Surbhi and Krishnamurthy, Akshay and Zhang, Cyril},
	year = {2023},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Formal Languages and Automata Theory},
}

@article{garrido_learning_2024,
	title = {Learning and leveraging world models in visual representation learning},
	abstract = {Joint-Embedding Predictive Architecture (JEPA) has emerged as a promising self-supervised approach that learns by leveraging a world model. While previously limited to predicting missing parts of an input, we explore how to generalize the JEPA prediction task to a broader set of corruptions. We introduce Image World Models, an approach that goes beyond masked image modeling and learns to predict the effect of global photometric transformations in latent space. We study the recipe of learning performant IWMs and show that it relies on three key aspects: conditioning, prediction difficulty, and capacity. Additionally, we show that the predictive world model learned by IWM can be adapted through finetuning to solve diverse tasks; a fine-tuned IWM world model matches or surpasses the performance of previous self-supervised methods. Finally, we show that learning with an IWM allows one to control the abstraction level of the learned representations, learning invariant representations such as contrastive methods, or equivariant representations such as masked image modelling.},
	language = {en},
	journal = {arXiv preprint arXiv:2403.00504},
	author = {Garrido, Quentin and Assran, Mahmoud and Ballas, Nicolas and Bardes, Adrien and Najman, Laurent and LeCun, Yann},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{li_counterfactual_2023,
	title = {Counterfactual reasoning: {Testing} language models' understanding of hypothetical scenarios},
	shorttitle = {Counterfactual reasoning},
	abstract = {Current pre-trained language models have enabled remarkable improvements in downstream tasks, but it remains difficult to distinguish effects of statistical correlation from more systematic logical reasoning grounded on the understanding of real world. We tease these factors apart by leveraging counterfactual conditionals, which force language models to predict unusual consequences based on hypothetical propositions. We introduce a set of tests from psycholinguistic experiments, as well as larger-scale controlled datasets, to probe counterfactual predictions from five pre-trained language models. We find that models are consistently able to override real-world knowledge in counterfactual scenarios, and that this effect is more robust in case of stronger baseline world knowledge -- however, we also find that for most models this effect appears largely to be driven by simple lexical cues. When we mitigate effects of both world knowledge and lexical cues to test knowledge of linguistic nuances of counterfactuals, we find that only GPT-3 shows sensitivity to these nuances, though this sensitivity is also non-trivially impacted by lexical associative factors.},
	language = {en},
	journal = {arXiv preprint arXiv:2305.16572},
	author = {Li, Jiaxuan and Yu, Lang and Ettinger, Allyson},
	year = {2023},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{khemakhem_ice-beem_2020,
	title = {Ice-beem: {Identifiable} conditional energy-based deep models based on nonlinear {ICA}},
	abstract = {We consider the identiﬁability theory of probabilistic models and establish sufﬁcient conditions under which the representations learned by a very broad family of conditional energy-based models are unique in function space, up to a simple transformation. In our model family, the energy function is the dot-product between two feature extractors, one for the dependent variable, and one for the conditioning variable. We show that under mild conditions, the features are unique up to scaling and permutation. Our results extend recent developments in nonlinear ICA, and in fact, they lead to an important generalization of ICA models. In particular, we show that our model can be used for the estimation of the components in the framework of Independently Modulated Component Analysis (IMCA), a new generalization of nonlinear ICA that relaxes the independence assumption. A thorough empirical study shows that representations learned by our model from real-world image datasets are identiﬁable, and improve performance in transfer learning and semi-supervised learning tasks.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Khemakhem, Ilyes and Monti, Ricardo P and Kingma, Diederik P and Hyvärinen, Aapo},
	year = {2020},
}

@inproceedings{lu_expressive_2017,
	title = {The expressive power of neural networks: {A} view from the width},
	abstract = {The expressive power of neural networks is important for understanding deep learning. Most existing works consider this problem from the view of the depth of a network. In this paper, we study how width affects the expressiveness of neural networks. Classical results state that depth-bounded (e.g. depth-2) networks with suitable activation functions are universal approximators. We show a universal approximation theorem for width-bounded ReLU networks: width-(n + 4) ReLU networks, where n is the input dimension, are universal approximators. Moreover, except for a measure zero set, all functions cannot be approximated by width-n ReLU networks, which exhibits a phase transition. Several recent works demonstrate the beneﬁts of depth by proving the depth-efﬁciency of neural networks. That is, there are classes of deep networks which cannot be realized by any shallow network whose size is no more than an exponential bound. Here we pose the dual question on the width-efﬁciency of ReLU networks: Are there wide networks that cannot be realized by narrow networks whose size is not substantially larger? We show that there exist classes of wide networks which cannot be realized by any narrow network whose depth is no more than a polynomial bound. On the other hand, we demonstrate by extensive experiments that narrow networks whose size exceed the polynomial bound by a constant factor can approximate wide and shallow network with high accuracy. Our results provide more comprehensive evidence that depth may be more effective than width for the expressiveness of ReLU networks.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Lu, Zhou and Pu, Hongming and Wang, Feicheng and Hu, Zhiqiang and Wang, Liwei},
	year = {2017},
}

@inproceedings{safran_depth-width_2017,
	title = {Depth-width tradeoffs in approximating natural functions with neural networks},
	abstract = {We provide several new depth-based separation results for feed-forward neural networks, proving that various types of simple and natural functions can be better approximated using deeper networks than shallower ones, even if the shallower networks are much larger. This includes indicators of balls and ellipses; non-linear functions which are radial with respect to the L1 norm; and smooth non-linear functions. We also show that these gaps can be observed experimentally: Increasing the depth indeed allows better learning than increasing width, when training neural networks to learn an indicator of a unit ball.},
	language = {en},
	booktitle = {{ICML}},
	author = {Safran, Itay and Shamir, Ohad},
	year = {2017},
}

@inproceedings{nguyen_wide_2021,
	title = {Do wide and deep networks learn the same things? {Uncovering} how neural network representations vary with width and depth},
	shorttitle = {Do wide and deep networks learn the same things?},
	abstract = {A key factor in the success of deep neural networks is the ability to scale models to improve performance by varying the architecture depth and width. This simple property of neural network design has resulted in highly effective architectures for a variety of tasks. Nevertheless, there is limited understanding of effects of depth and width on the learned representations. In this paper, we study this fundamental question. We begin by investigating how varying depth and width affects model hidden representations, ﬁnding a characteristic block structure in the hidden representations of larger capacity (wider or deeper) models. We demonstrate that this block structure arises when model capacity is large relative to the size of the training set, and is indicative of the underlying layers preserving and propagating the dominant principal component of their representations. This discovery has important ramiﬁcations for features learned by different models, namely, representations outside the block structure are often similar across architectures with varying widths and depths, but the block structure is unique to each model. We analyze the output predictions of different model architectures, ﬁnding that even when the overall accuracy is similar, wide and deep models exhibit distinctive error patterns and variations across classes.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Nguyen, Thao and Raghu, Maithra and Kornblith, Simon},
	year = {2021},
	keywords = {Computer Science - Machine Learning},
}

@article{fan_quasi-equivalence_2022,
	title = {Quasi-equivalence of width and depth of neural networks},
	abstract = {While classic studies proved that wide networks allow universal approximation, recent research and successes of deep learning demonstrate the power of deep networks. Based on a symmetric consideration, we investigate if the design of artiﬁcial neural networks should have a directional preference, and what the mechanism of interaction is between the width and depth of a network. Inspired by the De Morgan law, we address this fundamental question by establishing a quasi-equivalence between the width and depth of ReLU networks in two aspects. First, we formulate two transforms for mapping an arbitrary ReLU network to a wide network and a deep network respectively for either regression or classiﬁcation so that the essentially same capability of the original network can be implemented. Then, we replace the mainstream artiﬁcial neuron type with a quadratic counterpart, and utilize the factorization and continued fraction representations of the same polynomial function to construct a wide network and a deep network, respectively. Based on our ﬁndings, a deep network has a wide equivalent, and vice versa, subject to an arbitrarily small error.},
	language = {en},
	journal = {arXiv preprint arXiv:2002.02515},
	author = {Fan, Feng-Lei and Lai, Rongjie and Wang, Ge},
	year = {2022},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{lorens_invertible_1964,
	title = {Invertible boolean functions},
	volume = {EC-13},
	issn = {0367-7508},
	doi = {10.1109/PGEC.1964.263724},
	abstract = {A Boolean function has an inverse when every output is the result of one and only one input. There are 2n! Boolean functions of n variables which have an inverse. Equivalence classes of these functions are sets of equivalent functions in the sense that they are identical under a group operation on the input and output variables. This paper counts through five variables the number of equivalence classes of invertible Boolean functions under the group operation of complementation, permutation, and complementation and permutation, linear transformations and affine transformations. Lower bounds are given which experimentally give an asymptotic approximation. A representative function is given of each of the 52 classes of invertible Boolean functions of three variables under complementation and permutation. These are divided into three types of classes, 21 self-inverting functions, three functions have an inverse in the same class and 14 pairs of functions, each function of the pair in a different class. The four representative functions under the affine transformation are self-invertible.},
	number = {5},
	journal = {IEEE Transactions on Electronic Computers},
	author = {Lorens, C. S.},
	year = {1964},
	keywords = {Books, Boolean functions, Input variables},
	pages = {529--541},
}

@incollection{mansour_learning_1994,
	title = {Learning {Boolean} functions via the {Fourier} transform},
	booktitle = {Theoretical advances in neural computation and learning},
	author = {Mansour, Yishay},
	year = {1994},
	pages = {391--424},
}

@inproceedings{tamar_value_2016,
	title = {Value iteration networks},
	abstract = {We introduce the value iteration network (VIN): a fully differentiable neural network with a ‘planning module’ embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Tamar, Aviv and Levine, Sergey and Abbeel, Pieter and Wu, Yi and Thomas, Garrett},
	year = {2016},
}

@article{kang_how_2024,
	title = {How far is video generation from world model: {A} physical law perspective},
	shorttitle = {How far is video generation from world model},
	abstract = {OpenAI’s Sora highlights the potential of video generation for developing world models that adhere to fundamental physical laws. However, the ability of video generation models to discover such laws purely from visual data without human priors can be questioned. A world model learning the true law should give predictions robust to nuances and correctly extrapolate on unseen scenarios. In this work, we evaluate across three key scenarios: in-distribution, out-of-distribution, and combinatorial generalization. We developed a 2D simulation testbed for object movement and collisions to generate videos deterministically governed by one or more classical mechanics laws. This provides an unlimited supply of data for largescale experimentation and enables quantitative evaluation of whether the generated videos adhere to physical laws. We trained diffusion-based video generation models to predict object movements based on initial frames. Our scaling experiments show perfect generalization within the distribution, measurable scaling behavior for combinatorial generalization, but failure in out-of-distribution scenarios. Further experiments reveal two key insights about the generalization mechanisms of these models: (1) the models fail to abstract general physical rules and instead exhibit “case-based” generalization behavior, i.e., mimicking the closest training example; (2) when generalizing to new cases, models are observed to prioritize different factors when referencing training data: color {\textgreater} size {\textgreater} velocity {\textgreater} shape. Our study suggests that scaling alone is insufficient for video generation models to uncover fundamental physical laws, despite its role in Sora’s broader success.},
	language = {en},
	journal = {arXiv preprint arXiv:2411.02385},
	author = {Kang, Bingyi and Yue, Yang and Lu, Rui and Lin, Zhijie and Zhao, Yang and Wang, Kaixin and Huang, Gao and Feng, Jiashi},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{dong_fan_2024,
	title = {{FAN}: {Fourier} analysis networks},
	shorttitle = {Fan},
	abstract = {Despite the remarkable success achieved by neural networks, particularly those represented by MLP and Transformer, we reveal that they exhibit potential flaws in the modeling and reasoning of periodicity, i.e., they tend to memorize the periodic data rather than genuinely understanding the underlying principles of periodicity. However, periodicity is a crucial trait in various forms of reasoning and generalization, underpinning predictability across natural and engineered systems through recurring patterns in observations. In this paper, we propose FAN, a novel network architecture based on Fourier Analysis, which empowers the ability to efficiently model and reason about periodic phenomena. By introducing Fourier Series, the periodicity is naturally integrated into the structure and computational processes of the neural network, thus achieving a more accurate expression and prediction of periodic patterns. As a promising substitute to multi-layer perceptron (MLP), FAN can seamlessly replace MLP in various models with fewer parameters and FLOPs. Through extensive experiments, we demonstrate the effectiveness of FAN in modeling and reasoning about periodic functions, and the superiority and generalizability of FAN across a range of real-world tasks, including symbolic formula representation, time series forecasting, and language modeling.},
	language = {en},
	journal = {arXiv preprint arXiv:2410.02675},
	author = {Dong, Yihong and Li, Ge and Tao, Yongding and Jiang, Xue and Zhang, Kechi and Li, Jia and Su, Jing and Zhang, Jun and Xu, Jingjing},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{dodge_documenting_2021,
	title = {Documenting large webtext corpora: {A} case study on the colossal clean crawled corpus},
	shorttitle = {Documenting large webtext corpora},
	abstract = {Large language models have led to remarkable progress on many NLP tasks, and researchers are turning to ever-larger text corpora to train them. Some of the largest corpora available are made by scraping signiﬁcant portions of the internet, and are frequently introduced with only minimal documentation. In this work we provide some of the ﬁrst documentation for the Colossal Clean Crawled Corpus (C4; Raffel et al., 2020), a dataset created by applying a set of ﬁlters to a single snapshot of Common Crawl. We begin by investigating where the data came from, and ﬁnd a signiﬁcant amount of text from unexpected sources like patents and US military websites. Then we explore the content of the text itself, and ﬁnd machine-generated text (e.g., from machine translation systems) and evaluation examples from other benchmark NLP datasets. To understand the impact of the ﬁlters applied to create this dataset, we evaluate the text that was removed, and show that blocklist ﬁltering disproportionately removes text from and about minority individuals. Finally, we conclude with some recommendations for how to created and document web-scale datasets from a scrape of the internet.},
	language = {en},
	booktitle = {{EMNLP}},
	author = {Dodge, Jesse and Sap, Maarten and Marasović, Ana and Agnew, William and Ilharco, Gabriel and Groeneveld, Dirk and Mitchell, Margaret and Gardner, Matt},
	year = {2021},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{kumar_scaling_2024,
	title = {Scaling laws for precision},
	abstract = {Low precision training and inference affect both the quality and cost of language models, but current scaling laws do not account for this. In this work, we devise “precision-aware” scaling laws for both training and inference. We propose that training in lower precision reduces the model’s effective parameter count, allowing us to predict the additional loss incurred from training in low precision and post-train quantization. For inference, we find that the degradation introduced by post-training quantization increases as models are trained on more data, eventually making additional pretraining data actively harmful. For training, our scaling laws allow us to predict the loss of a model with different parts in different precisions, and suggest that training larger models in lower precision may be compute optimal. We unify the scaling laws for post and pretraining quantization to arrive at a single functional form that predicts degradation from training and inference in varied precisions. We fit on over 465 pretraining runs and validate our predictions on model sizes up to 1.7B parameters trained on up to 26B tokens.},
	language = {en},
	journal = {arXiv preprint arXiv:2411.04330},
	author = {Kumar, Tanishq and Ankner, Zachary and Spector, Benjamin F. and Bordelon, Blake and Muennighoff, Niklas and Paul, Mansheej and Pehlevan, Cengiz and Ré, Christopher and Raghunathan, Aditi},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@article{pearl_causal_2009,
	title = {Causal inference in statistics: {An} overview},
	volume = {3},
	issn = {1935-7516},
	shorttitle = {Causal inference in statistics},
	doi = {10.1214/09-SS057},
	abstract = {This review presents empirical researchers with recent advances in causal inference, and stresses the paradigmatic shifts that must be undertaken in moving from traditional statistical analysis to causal analysis of multivariate data. Special emphasis is placed on the assumptions that underly all causal inferences, the languages used in formulating those assumptions, the conditional nature of all causal and counterfactual claims, and the methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and unifies other approaches to causation, and provides a coherent mathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: (1) queries about the effects of potential interventions, (also called “causal effects” or “policy evaluation”) (2) queries about probabilities of counterfactuals, (including assessment of “regret,” “attribution” or “causes of effects”) and (3) queries about direct and indirect effects (also known as “mediation”). Finally, the paper defines the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both.},
	number = {none},
	journal = {Statistics Surveys},
	author = {Pearl, Judea},
	month = jan,
	year = {2009},
	keywords = {causal effects, causes of effects, confounding, counterfactuals, graphical methods, mediation, policy evaluation, potential-outcome, structural equation models},
	pages = {96--146},
}

@article{chowdhery_palm_2022,
	title = {{PaLM}: {Scaling} language modeling with pathways},
	shorttitle = {Palm},
	abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-speciﬁc training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).},
	language = {en},
	journal = {arXiv preprint arXiv:2204.02311},
	author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
	year = {2022},
	keywords = {Computer Science - Computation and Language},
}

@article{gendron_large_2024,
	title = {Large language models are not strong abstract reasoners},
	doi = {10.48550/arXiv.2305.19555},
	abstract = {Large Language Models have shown tremendous performance on a large variety of natural language processing tasks, ranging from text comprehension to common sense reasoning. However, the mechanisms responsible for this success remain opaque, and it is unclear whether LLMs can achieve human-like cognitive capabilities or whether these models are still fundamentally circumscribed. Abstract reasoning is a fundamental task for cognition, consisting of finding and applying a general pattern from few data. Evaluating deep neural architectures on this task could give insight into their potential limitations regarding reasoning and their broad generalisation abilities, yet this is currently an under-explored area. In this paper, we introduce a new benchmark for evaluating language models beyond memorization on abstract reasoning tasks. We perform extensive evaluations of state-of-the-art LLMs, showing that they currently achieve very limited performance in contrast with other natural language tasks, even when applying techniques that have been shown to improve performance on other NLP tasks. We argue that guiding LLM generation to follow causal paths could help improve the generalisation and reasoning abilities of LLMs.},
	journal = {arXiv preprint arXiv:2305.19555},
	author = {Gendron, Gaël and Bao, Qiming and Witbrock, Michael and Dobbie, Gillian},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@article{liu_evaluating_2023-1,
	title = {Evaluating the logical reasoning ability of {ChatGPT} and {GPT}-4},
	abstract = {Harnessing logical reasoning ability is a comprehensive natural language understanding endeavor. With the release of Generative Pretrained Transformer 4 (GPT-4), highlighted as "advanced" at reasoning tasks, we are eager to learn the GPT-4 performance on various logical reasoning tasks. This report analyses multiple logical reasoning datasets, with popular benchmarks like LogiQA and ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice reading comprehension and natural language inference tasks with benchmarks requiring logical reasoning. We further construct a logical reasoning out-ofdistribution dataset to investigate the robustness of ChatGPT and GPT-4. We also make a performance comparison between ChatGPT and GPT-4. Experiment results show that ChatGPT performs signiﬁcantly better than the RoBERTa ﬁne-tuning method on most logical reasoning benchmarks. With early access to the GPT-4 API we are able to conduct intense experiments on the GPT-4 model. The results show GPT-4 yields even higher performance on most logical reasoning datasets. Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known datasets like LogiQA and ReClor. However, the performance drops signiﬁcantly when handling newly released and out-of-distribution datasets. Logical reasoning remains challenging for ChatGPT and GPT-4, especially on outof-distribution and natural language inference datasets. We release the prompt-style logical reasoning datasets as a benchmark suite and name it LogiEval.},
	language = {en},
	journal = {arXiv preprint arXiv:2304.03439},
	author = {Liu, Hanmeng and Ning, Ruoxi and Teng, Zhiyang and Liu, Jian and Zhou, Qiji and Zhang, Yue},
	year = {2023},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{xu_are_2024,
	title = {Are large language models really good logical reasoners? {A} comprehensive evaluation and beyond},
	shorttitle = {Are large language models really good logical reasoners?},
	doi = {10.48550/arXiv.2306.09841},
	journal = {arXiv preprint arXiv:2306.09841},
	author = {Xu, Fangzhi and Lin, Qika and Han, Jiawei and Zhao, Tianzhe and Liu, Jun and Cambria, Erik},
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{li_counterfactual_2023-1,
	title = {Counterfactual reasoning: {Testing} language models' understanding of hypothetical scenarios},
	shorttitle = {Counterfactual reasoning},
	abstract = {Current pre-trained language models have enabled remarkable improvements in downstream tasks, but it remains difficult to distinguish effects of statistical correlation from more systematic logical reasoning grounded on the understanding of real world. We tease these factors apart by leveraging counterfactual conditionals, which force language models to predict unusual consequences based on hypothetical propositions. We introduce a set of tests from psycholinguistic experiments, as well as larger-scale controlled datasets, to probe counterfactual predictions from five pre-trained language models. We find that models are consistently able to override real-world knowledge in counterfactual scenarios, and that this effect is more robust in case of stronger baseline world knowledge -- however, we also find that for most models this effect appears largely to be driven by simple lexical cues. When we mitigate effects of both world knowledge and lexical cues to test knowledge of linguistic nuances of counterfactuals, we find that only GPT-3 shows sensitivity to these nuances, though this sensitivity is also non-trivially impacted by lexical associative factors.},
	language = {en},
	booktitle = {{ACL}},
	author = {Li, Jiaxuan and Yu, Lang and Ettinger, Allyson},
	year = {2023},
	keywords = {Computer Science - Computation and Language},
}

@article{nezhurina_alice_2024,
	title = {Alice in wonderland: {Simple} tasks showing complete reasoning breakdown in state-of-the-art large language models},
	shorttitle = {Alice in wonderland},
	abstract = {Large Language Models (LLMs) like closed weights ones GPT-3.5/4, Claude, Gemini or open weights ones like LLaMa 2/3, Mistral, Mixtral, and more recent ones Dbrx or Command R+ are often described as being instances of foundation models - that is, models that transfer strongly across various tasks and conditions in few-show or zero-shot manner, while exhibiting scaling laws that predict function improvement when increasing the pre-training scale. These claims of excelling in different functions and tasks rely on measurements taken across various sets of standardized benchmarks showing high scores for such models. We demonstrate here a dramatic breakdown of function and reasoning capabilities of state-of-the-art models trained at the largest available scales which claim strong function, using a simple, short, conventional common sense problem (AIW problem) formulated in concise natural language, easily solvable by humans. The breakdown is dramatic, as models show strong fluctuations across even slight problem variations that should not affect problem solving, also expressing strong overconfidence in the wrong solutions, often backed up by plausible sounding explanation-like confabulations. Various standard interventions in an attempt to get the right solution, like various type of enhanced prompting, or urging the models to reconsider the wrong solutions again by multi step re-evaluation, fail. We take these initial observations to the scientific and technological community to stimulate urgent re-assessment of the claimed capabilities of current generation of LLMs. Such re-assessment also requires common action to create standardized benchmarks that would allow proper detection of such basic reasoning deficits that obviously manage to remain undiscovered by current state-of-the-art evaluation procedures and benchmarks1.},
	language = {en},
	journal = {arXiv preprint arXiv:2406.02061},
	author = {Nezhurina, Marianna and Cipolina-Kun, Lucia and Cherti, Mehdi and Jitsev, Jenia},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{feng_how_2024,
	title = {How numerical precision affects mathematical reasoning capabilities of {LLMs}},
	abstract = {Despite the remarkable success of Transformerbased Large Language Models (LLMs) across various domains, understanding and enhancing their mathematical capabilities remains a significant challenge. In this paper, we conduct a rigorous theoretical analysis of LLMs’ mathematical abilities, with a specific focus on their arithmetic performances. We identify numerical precision as a key factor that influences their effectiveness in mathematical tasks. Our results show that Transformers operating with low numerical precision fail to address arithmetic tasks, such as iterated addition and integer multiplication, unless the model size grows super-polynomially with respect to the input length. In contrast, Transformers with standard numerical precision can efficiently handle these tasks with significantly smaller model sizes. We further support our theoretical findings through empirical experiments that explore the impact of varying numerical precision on arithmetic tasks, providing valuable insights for improving the mathematical reasoning capabilities of LLMs.},
	language = {en},
	journal = {arXiv preprint arXiv:2410.13857},
	author = {Feng, Guhao and Yang, Kai and Gu, Yuntian and Ai, Xinyue and Luo, Shengjie and Sun, Jiacheng and He, Di and Li, Zhenguo and Wang, Liwei},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{li_chain_2024,
	title = {Chain of thought empowers transformers to solve inherently serial problems},
	abstract = {Instructing the model to generate a sequence of intermediate steps, a.k.a., a chain of thought (CoT), is a highly effective method to improve the accuracy of large language models (LLMs) on arithmetics and symbolic reasoning tasks. However, the mechanism behind CoT remains unclear. This work provides a theoretical understanding of the power of CoT for decoder-only transformers through the lens of expressiveness. Conceptually, CoT empowers the model with the ability to perform inherently serial computation, which is otherwise lacking in transformers, especially when depth is low. Given input length n, previous works have shown that constant-depth transformers with ﬁnite precision poly(n) embedding size can only solve problems in TC0 without CoT. We ﬁrst show an even tighter expressiveness upper bound for constant-depth transformers with constant-bit precision, which can only solve problems in AC0, a proper subset of TC0. However, with T steps of CoT, constant-depth transformers using constant-bit precision and O(log n) embedding size can solve any problem solvable by boolean circuits of size T . Empirically, enabling CoT dramatically improves the accuracy for tasks that are hard for parallel computation, including the composition of permutation groups, iterated squaring, and circuit value problems, especially for low-depth transformers.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Li, Zhiyuan and Zhou, Denny and Liu, Hong and Ma, Tengyu},
	year = {2024},
}

@misc{saengkyongam_identifying_2024,
	title = {Identifying {Representations} for {Intervention} {Extrapolation}},
	abstract = {The premise of identifiable and causal representation learning is to improve the current representation learning paradigm in terms of generalizability or robustness. Despite recent progress in questions of identifiability, more theoretical results demonstrating concrete advantages of these methods for downstream tasks are needed. In this paper, we consider the task of intervention extrapolation: predicting how interventions affect an outcome, even when those interventions are not observed at training time, and show that identifiable representations can provide an effective solution to this task even if the interventions affect the outcome non-linearly. Our setup includes an outcome variable Y , observed features X, which are generated as a non-linear transformation of latent features Z, and exogenous action variables A, which influence Z. The objective of intervention extrapolation is then to predict how interventions on A that lie outside the training support of A affect Y . Here, extrapolation becomes possible if the effect of A on Z is linear and the residual when regressing Z on A has full support. As Z is latent, we combine the task of intervention extrapolation with identifiable representation learning, which we call Rep4Ex: we aim to map the observed features X into a subspace that allows for non-linear extrapolation in A. We show that the hidden representation is identifiable up to an affine transformation in Z-space, which, we prove, is sufficient for intervention extrapolation. The identifiability is characterized by a novel constraint describing the linearity assumption of A on Z. Based on this insight, we propose a flexible method that enforces the linear invariance constraint and can be combined with any type of autoencoder. We validate our theoretical findings through a series of synthetic experiments and show that our approach can indeed succeed in predicting the effects of unseen interventions.},
	language = {en},
	author = {Saengkyongam, Sorawit and Rosenfeld, Elan and Ravikumar, Pradeep and Pfister, Niklas and Peters, Jonas},
	month = mar,
	year = {2024},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{nisan_degree_1992,
	address = {Victoria, British Columbia, Canada},
	title = {On the degree of {Boolean} functions as real polynomials},
	isbn = {978-0-89791-511-3},
	doi = {10.1145/129712.129757},
	abstract = {Every boolean function may be represented as a real polynomial. In this paper we characterize the degree of this polynomial in terms of certain combinatorial properties of the boolean function.},
	language = {en},
	booktitle = {Proceedings of the twenty-fourth annual {ACM} symposium on {Theory} of computing  - {STOC} '92},
	author = {Nisan, Noam and Szegedy, Mario},
	year = {1992},
	pages = {462--467},
}

@book{stankovic_representations_2022,
	title = {Representations of multiple-valued logic functions},
	isbn = {3-031-79852-X},
	author = {Stankovic, Radomir S. and Astola, Jaakko and Moraga, Claudio},
	year = {2022},
}

@inproceedings{oymak_overparameterized_2019,
	title = {Overparameterized nonlinear learning: {Gradient} descent takes the shortest path?},
	abstract = {Many modern learning tasks involve ﬁtting nonlinear models which are trained in an overparameterized regime where the parameters of the model exceed the size of the training dataset. Due to this overparameterization, the training loss may have inﬁnitely many global minima and it is critical to understand the properties of the solutions found by ﬁrst-order optimization schemes such as (stochastic) gradient descent starting from different initializations. In this paper we demonstrate that when the loss has certain properties over a minimally small neighborhood of the initial point, ﬁrst order methods such as (stochastic) gradient descent have a few intriguing properties: (1) the iterates converge at a geometric rate to a global optima even when the loss is nonconvex, (2) among all global optima of the loss the iterates converge to one with a near minimal distance to the initial point, (3) the iterates take a near direct route from the initial point to this global optimum. As part of our proof technique, we introduce a new potential function which captures the tradeoff between the loss function and the distance to the initial point as the iterations progress. The utility of our general theory is demonstrated for a variety of problem domains spanning low-rank matrix recovery to shallow neural network training.},
	language = {en},
	booktitle = {{ICML}},
	author = {Oymak, Samet and Soltanolkotabi, Mahdi},
	year = {2019},
}

@article{xue_which_nodate,
	title = {Which {Features} are {Learnt} by {Contrastive} {Learning}? {On} the {Role} of {Simplicity} {Bias} in {Class} {Collapse} and {Feature} {Suppression}},
	abstract = {Contrastive learning (CL) has emerged as a powerful technique for representation learning, with or without label supervision. However, supervised CL is prone to collapsing representations of subclasses within a class by not capturing all their features, and unsupervised CL may suppress harder class-relevant features by focusing on learning easy class-irrelevant features; both significantly compromise representation quality. Yet, there is no theoretical understanding of class collapse or feature suppression at test time. We provide the first unified theoretically rigorous framework to determine which features are learnt by CL. Our analysis indicate that, perhaps surprisingly, bias of (stochastic) gradient descent towards finding simpler solutions is a key factor in collapsing subclass representations and suppressing harder classrelevant features. Moreover, we present increasing embedding dimensionality and improving the quality of data augmentations as two theoretically motivated solutions to feature suppression. We also provide the first theoretical explanation for why employing supervised and unsupervised CL together yields higher-quality representations, even when using commonly-used stochastic gradient methods.},
	language = {en},
	author = {Xue, Yihao and Joshi, Siddharth and Gan, Eric and Chen, Pin-Yu and Mirzasoleiman, Baharan},
}

@inproceedings{bakhtin_phyre_2019,
	title = {{PHYRE}: {A} new benchmark for physical reasoning},
	abstract = {Understanding and reasoning about physics is an important ability of intelligent agents. We develop the PHYRE benchmark for physical reasoning that contains a set of simple classical mechanics puzzles in a 2D physical environment. The benchmark is designed to encourage the development of learning algorithms that are sample-efﬁcient and generalize well across puzzles. We test several modern learning algorithms on PHYRE and ﬁnd that these algorithms fall short in solving the puzzles efﬁciently. We expect that PHYRE will encourage the development of novel sample-efﬁcient agents that learn efﬁcient but useful models of physics. For code and to play PHYRE for yourself, please visit https://player.phyre.ai.},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Bakhtin, Anton},
	year = {2019},
}

@article{snell_predicting_2024,
	title = {Predicting emergent capabilities by finetuning},
	doi = {10.48550/arXiv.2411.16035},
	abstract = {A fundamental open challenge in modern LLM scaling is the lack of understanding around emergent capabilities. In particular, language model pretraining loss is known to be highly predictable as a function of compute. However, downstream capabilities are far less predictable—sometimes even exhibiting emergent jumps—which makes it challenging to anticipate the capabilities of future models. In this work, we first pose the task of emergence prediction: given access to current LLMs that have random fewshot accuracy on a task, can we predict whether future models (GPT-N+1) will have non-trivial accuracy on that task? We then discover a simple insight for this problem: finetuning LLMs on a given task can shift the point in scaling at which emergence occurs towards less capable models. To operationalize this insight, we can finetune LLMs with varying amounts of data and fit a parametric function that predicts when emergence will occur (i.e., “emergence laws”). We validate this approach using four standard NLP benchmarks where large-scale open-source LLMs already demonstrate emergence (MMLU, GSM8K, CommonsenseQA, and CoLA). Using only small-scale LLMs, we find that, in some cases, we can accurately predict whether models trained with up to 4x more compute have emerged. Finally, we present a case study of two realistic uses for emergence prediction.},
	language = {en},
	journal = {arXiv preprint arXiv:2411.16035},
	author = {Snell, Charlie and Wallace, Eric and Klein, Dan and Levine, Sergey},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{shi_large_2023,
	title = {Large language models can be easily distracted by irrelevant context},
	language = {en},
	booktitle = {{ICML}},
	author = {Shi, Freda and Chen, Xinyun and Misra, Kanishka and Scales, Nathan and Dohan, David and Chi, Ed and Scharli, Nathanael and Zhou, Denny},
	year = {2023},
}

@article{ye_differential_2024,
	title = {Differential transformer},
	doi = {10.48550/arXiv.2410.05258},
	abstract = {Transformer tends to overallocate attention to irrelevant context. In this work, we introduce DIFF Transformer, which amplifies attention to the relevant context while canceling noise. Specifically, the differential attention mechanism calculates attention scores as the difference between two separate softmax attention maps. The subtraction cancels noise, promoting the emergence of sparse attention patterns. Experimental results on language modeling show that DIFF Transformer outperforms Transformer in various settings of scaling up model size and training tokens. More intriguingly, it offers notable advantages in practical applications, such as long-context modeling, key information retrieval, hallucination mitigation, in-context learning, and reduction of activation outliers. By being less distracted by irrelevant context, DIFF Transformer can mitigate hallucination in question answering and text summarization. For in-context learning, DIFF Transformer not only enhances accuracy but is also more robust to order permutation, which was considered as a chronic robustness issue. The results position DIFF Transformer as a highly effective and promising architecture to advance large language models.},
	language = {en},
	journal = {arXiv preprint arXiv:2410.05258},
	author = {Ye, Tianzhu and Dong, Li and Xia, Yuqing and Sun, Yutao and Zhu, Yi and Huang, Gao and Wei, Furu},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
}

@inproceedings{meng_locating_2022,
	title = {Locating and editing factual associations in {GPT}},
	language = {en},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
	year = {2022},
}

@article{wang_can_2024-1,
	title = {Can in-context learning really generalize to out-of-distribution tasks?},
	doi = {10.48550/arXiv.2410.09695},
	abstract = {In this work, we explore the mechanism of in-context learning (ICL) on out-ofdistribution (OOD) tasks that were not encountered during training. To achieve this, we conduct synthetic experiments where the objective is to learn OOD mathematical functions through ICL using a GPT-2 model. We reveal that Transformers may struggle to learn OOD task functions through ICL. Specifically, ICL performance resembles implementing a function within the pretraining hypothesis space and optimizing it with gradient descent based on the in-context examples. Additionally, we investigate ICL’s well-documented ability to learn unseen abstract labels in context. We demonstrate that such ability only manifests in the scenarios without distributional shifts and, therefore, may not serve as evidence of new-tasklearning ability. Furthermore, we assess ICL’s performance on OOD tasks when the model is pretrained on multiple tasks. Both empirical and theoretical analyses demonstrate the existence of the low-test-error preference of ICL, where it tends to implement the pretraining function that yields low test error in the testing context. We validate this through numerical experiments. This new theoretical result, combined with our empirical findings, elucidates the mechanism of ICL in addressing OOD tasks.},
	language = {en},
	journal = {arXiv preprint arXiv:2410.09695},
	author = {Wang, Qixun and Wang, Yifei and Wang, Yisen and Ying, Xianghua},
	year = {2024},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}

@inproceedings{yadlowsky_can_2023,
	title = {Can transformer models generalize via in-context learning beyond pretraining data?},
	abstract = {Transformer models, notably large language models (LLMs), have the remarkable ability to perform in-context learning (ICL) -- to perform new tasks when prompted with unseen input-output examples without any explicit model training. In this work, we study how effectively transformers can generalize beyond their pretraining data mixture, comprised of one or multiple function classes, to identify and learn new functions in-context which are outside the pretraining distribution. To investigate this question in a controlled setting, we focus on the transformers ability to in-context learn functions from simulated data. While these models do well at generalizing to new functions withing the pretrained function class, when presented with tasks or functions which are out-of-distribution from their pretraining data, we demonstrate various failure modes of transformers. Together our results suggest that the impressive ICL abilities of high-capacity transformer models may be more closely tied to the coverage of their pretraining data mixtures than inductive biases that create fundamental generalization capabilities.},
	language = {en},
	author = {Yadlowsky, Steve and Doshi, Lyric and Tripuraneni, Nilesh},
	year = {2023},
}

@inproceedings{ibarz_generalist_2022,
	title = {A generalist neural algorithmic learner},
	abstract = {The cornerstone of neural algorithmic reasoning is the ability to solve algorithmic tasks, especially in a way that generalises out of distribution. While recent years have seen a surge in methodological improvements in this area, they mostly focused on building specialist models. Specialist models are capable of learning to neurally execute either only one algorithm or a collection of algorithms with identical control-flow backbone. Here, instead, we focus on constructing a generalist neural algorithmic learner—a single graph neural network processor capable of learning to execute a wide range of algorithms, such as sorting, searching, dynamic programming, path-finding and geometry. We leverage the CLRS benchmark to empirically show that, much like recent successes in the domain of perception, generalist algorithmic learners can be built by "incorporating" knowledge. That is, it is possible to effectively learn algorithms in a multi-task manner, so long as we can learn to execute them well in a single-task regime. Motivated by this, we present a series of improvements to the input representation, training regime and processor architecture over CLRS, improving average single-task performance by over 20\% from prior art. We then conduct a thorough ablation of multi-task learners leveraging these improvements. Our results demonstrate a generalist learner that effectively incorporates knowledge captured by specialist models.},
	language = {en},
	booktitle = {Proceedings of the {First} {Learning} on {Graphs} {Conference} ({LoG} 2022)},
	author = {Ibarz, Borja and Kurin, Vitaly and Papamakarios, George and Nikiforou, Kyriacos and Bennani, Mehdi and Csordás, Róbert and Dudzik, Andrew and Bošnjak, Matko and Vitvitskyi, Alex and Rubanova, Yulia and Deac, Andreea and Bevilacqua, Beatrice and Ganin, Yaroslav and Blundell, Charles and Velicˇkovic, Petar},
	year = {2022},
}

@inproceedings{ziyin_neural_2020,
	title = {Neural networks fail to learn periodic functions and how to fix it},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Ziyin, Liu and Hartwig, Tilman and Ueda, Masahito},
	year = {2020}
}

@misc{ziyin_formation_2024,
	title = {Formation of representations in neural networks},
	doi = {10.48550/arXiv.2410.03006},
	abstract = {Understanding neural representations will help open the black box of neural networks and advance our scientific understanding of modern AI systems. However, how complex, structured, and transferable representations emerge in modern neural networks has remained a mystery. Building on previous results, we propose the Canonical Representation Hypothesis (CRH), which posits a set of six alignment relations to universally govern the formation of representations in most hidden layers of a neural network. Under the CRH, the latent representations (R), weights (W), and neuron gradients (G) become mutually aligned during training. This alignment implies that neural networks naturally learn compact representations, where neurons and weights are invariant to task-irrelevant transformations. We then show that the breaking of CRH leads to the emergence of reciprocal power-law relations between R, W, and G, which we refer to as the Polynomial Alignment Hypothesis (PAH). We present a minimal-assumption theory demonstrating that the balance between gradient noise and regularization is crucial for the emergence the canonical representation. The CRH and PAH lead to an exciting possibility of unifying major key deep learning phenomena, including neural collapse and the neural feature ansatz, in a single framework.},
	language = {en},
	author = {Ziyin, Liu and Chuang, Isaac and Galanti, Tomer and Poggio, Tomaso},
	month = oct,
	year = {2024},
	keywords = {Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks},
}

@article{livni_computational_nodate,
	title = {On the {Computational} {Efficiency} of {Training} {Neural} {Networks}},
	abstract = {It is well-known that neural networks are computationally hard to train. On the other hand, in practice, modern day neural networks are trained efﬁciently using SGD and a variety of tricks that include different activation functions (e.g. ReLU), over-speciﬁcation (i.e., train networks which are larger than needed), and regularization. In this paper we revisit the computational complexity of training neural networks from a modern perspective. We provide both positive and negative results, some of them yield new provably efﬁcient and practical algorithms for training certain types of neural networks.},
	language = {en},
	author = {Livni, Roi and Shalev-Shwartz, Shai and Shamir, Ohad},
}

@misc{peebles_scalable_2023,
	title = {Scalable {Diffusion} {Models} with {Transformers}},
	doi = {10.48550/arXiv.2212.09748},
	abstract = {We explore a new class of diffusion models based on the transformer architecture. We train latent diffusion models of images, replacing the commonly-used U-Net backbone with a transformer that operates on latent patches. We analyze the scalability of our Diffusion Transformers (DiTs) through the lens of forward pass complexity as measured by Gﬂops. We ﬁnd that DiTs with higher Gﬂops—through increased transformer depth/width or increased number of input tokens—consistently have lower FID. In addition to possessing good scalability properties, our largest DiT-XL/2 models outperform all prior diffusion models on the classconditional ImageNet 512×512 and 256×256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter.},
	language = {en},
	author = {Peebles, William and Xie, Saining},
	month = mar,
	year = {2023},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
}

@inproceedings{haley_extrapolation_1992,
	title = {Extrapolation limitations of multilayer feedforward neural networks},
	volume = {4},
	doi = {10.1109/IJCNN.1992.227294},
	abstract = {The limitations of backpropagation used as a function extrapolator were investigated. Four common functions were used to investigate the network's extrapolation capability. The purpose of the experiment was to determine whether neural networks are capable of extrapolation and, if so, to determine the range for which networks can extrapolate. The authors show that neural networks cannot extrapolate and offer an explanation to support this result.{\textless}{\textgreater}},
	booktitle = {[{Proceedings} 1992] {IJCNN} {International} {Joint} {Conference} on {Neural} {Networks}},
	author = {Haley, P.J. and Soloway, D.},
	year = {1992},
	keywords = {Neural networks, Testing, Backpropagation, Extrapolation, Feedforward neural networks, Joining processes, Multi-layer neural network, NASA, Protection, Stock markets},
	pages = {25--30 vol.4},
}

@article{barnard_extrapolation_1992,
	title = {Extrapolation and interpolation in neural network classifiers},
	volume = {12},
	issn = {1941-000X},
	doi = {10.1109/37.158898},
	abstract = {Multilayer perceptrons have recently been shown by M.A. Kramer and J.A. Leonard (1990, 1991) to give anomalous behavior in a diagnosis application. It is shown that this unsatisfactory behavior indicates a mismatch of application and technique, rather than any deficiency in the multilayer perceptron. It is further argued that this mismatch is indicative of the differences between applications that require interpolation and those which require extrapolation in addition. Simulation results to indicate a satisfactory performance of multilayer perceptrons in suitable applications are presented.{\textless}{\textgreater}},
	number = {5},
	journal = {IEEE Control Systems Magazine},
	author = {Barnard, E. and Wessels, L.F.A.},
	month = oct,
	year = {1992},
	keywords = {Interpolation, Neural networks, Extrapolation, Multi-layer neural network, Control systems, Fault diagnosis, Intelligent networks, Monitoring, Multilayer perceptrons, Transfer functions},
	pages = {50--53},
}
