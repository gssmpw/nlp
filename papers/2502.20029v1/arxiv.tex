\documentclass[journal,onecolumn,web]{ieeecolor}
\usepackage{generic}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts,dsfont,mathrsfs}
% \usepackage{algorithmicx}
\usepackage[ruled,boxed]{algorithm2e}
\usepackage{graphicx}
% \usepackage{textcomp}
\usepackage{subfigure}
% \usepackage{algorithm}
% \usepackage[ruled]{algorithm2e}
% \usepackage{array,colortbl,booktabs}
\usepackage{multirow}
\usepackage{cases}
\usepackage{float}
\usepackage{setspace}
\usepackage{slashbox}
% \usepackage{amscd,dsfont,texdraw,verbatim,multicol}
\usepackage{boxedminipage}
\usepackage{pdfsync}
\usepackage{empheq}
\usepackage{xcolor}
\definecolor{mycyan}{HTML}{0070C0}
\usepackage[colorlinks,linkcolor=mycyan,anchorcolor=black,citecolor=mycyan,urlcolor=mycyan]{hyperref}

%% $\boldsymbol{x}$ \mathfrak{h}


% \usepackage[numbers,sort,compress]{natbib}
% \usepackage[square, comma, sort&compress, numbers]{natbib}


 %\DeclareUnicodeCharacter{0221E}{$ \infty $}
% \usepackage{xcolor}
% \usepackage[active,tightpage]{preview}
% \PreviewEnvironment{tikzpicture}
% \setlength\PreviewBorder{5mm}%
% \usetikzlibrary{decorations.pathmorphing} % for snake lines
% \usetikzlibrary{matrix} % for block alignment
% % \usetikzlibrary{arrows} % for arrow heads
% \usetikzlibrary{calc} % for manimulation of coordinates
% \usetikzlibrary{shapes,arrows,chains}
\newcommand{\bassume}{ \begin{assume} \begin{rm} }
\newcommand{\eassume}{ \end{rm} \hfill $\triangleleft$ \end{assume} }
\newcommand{\bcondition}{ \begin{condition} \begin{rm} }
\newcommand{\econdition}{ \end{rm}  \end{condition} }
\newcommand{\bremark}{ \begin{remark} \begin{rm} }
\newcommand{\eremark}{ \end{rm} \hfill $\triangleleft$ \end{remark} }
\newcommand{\btheorem}{ \begin{theorem} \begin{rm} }
\newcommand{\etheorem}{ \end{rm} \hfill $\triangleleft$ \end{theorem} }
\newcommand{\blemma}{ \begin{lemma} \begin{rm} }
\newcommand{\elemma}{ \end{rm} \hfill $\triangleleft$ \end{lemma} }
\newcommand{\bcorollary}{ \begin{corollary} \begin{rm} }
\newcommand{\ecorollary}{ \end{rm}  \end{corollary} }
\newcommand{\bdefinition}{ \begin{definition}\begin{rm} }
\newcommand{\edefinition}{ \end{rm} \hfill $\triangleleft$ \end{definition} }
\newcommand{\bproposition}{ \begin{proposition} \begin{rm} }
\newcommand{\eproposition}{ \end{rm}  \end{proposition} }
\newcommand{\bexample}{ \begin{example} \begin{rm} }
\newcommand{\eexample}{ \end{rm} \hfill $\triangleleft$ \end{example} }
\newcommand{\bproblem}{ \bf Problem \begin{rm} }
\newcommand{\eproblem}{ \end{rm} \hfill $\triangleleft$ \end{problem} }
\newcommand{\bproof}{ \textit{Proof:} \begin{rm} }
\newcommand{\eproof}{ \end{rm} \hfill $\square$}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


\newtheorem{theorem}{\it Theorem}
\newtheorem{lemma}{\it Lemma}
\newtheorem{definition}{\it Definition}
\newtheorem{remark}{\it Remark}
\newtheorem{corollary}{\it Corollary}
\newtheorem{proposition}{\it Proposition}
\newtheorem{example}{\it Example}
\newtheorem{assume}{\it Assumption}
\newtheorem{condition}{\it Condition}
\newtheorem{problem}{\it Problem}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\markboth{\journalname, VOL. XX, NO. XX, XXXX 2017}
{Author \MakeLowercase{\textit{et al.}}: }
\begin{document}
\title{Robust Mean Field Social Control: A Unified Reinforcement Learning Framework}
\author{
 Zhenhui Xu, Jiayu Chen, Bing-Chang Wang, Yuhu Wu, and Tielong Shen
% \thanks{This paragraph of the first footnote will contain the date on
% which you submitted your paper for review. It will also contain support
% information, including sponsor and financial support acknowledgment. For
% example, ``This work was supported in part by the U.S. Department of
% Commerce under Grant BS123456.'' }
% \thanks{The next few paragraphs should contain
% the authors' current affiliations, including current address and e-mail. For
% example, F. A. Author is with the National Institute of Standards and
% Technology, Boulder, CO 80305 USA (e-mail: author@boulder.nist.gov). }
\thanks{Zhenhui Xu and Jiayu Chen are with the Department of Systems and Control Engineering at the Institute of Science Tokyo, Tokyo, 152-8552, Japan. (e-mail: xuzhenhui@eagle.sophia.ac.jp;jiayuc@mail.ustc.edu.cn).}
\thanks{Bing-Chang Wang is with the School of Control Science and Engineering, Shandong University, Jinan, 250061, China. (e-mail: bcwang@sdu.edu.cn)}
\thanks{Yuhu Wu and Tielong Shen are with the School of Control Science and Engineering, Dalian University of Technology, Dalian, 116024, China (e-mail: wuyuhu@dlut.edu.cn;tetu-sin@sophia.ac.jp).}}


\maketitle

\begin{abstract}
This paper studies linear quadratic Gaussian robust mean field social control problems in the presence of multiplicative noise. We aim to compute asymptotic decentralized strategies without requiring full prior knowledge of agentsâ€™ dynamics. The primary challenges lie in solving an indefinite stochastic algebraic Riccati equation for feedback gains, and an indefinite algebraic Riccati equation for feedforward gains. To overcome these challenges, we first propose a unified dual-loop iterative framework that simultaneously handles both indefinite Riccati-type equations, and provide rigorous convergence proofs for both outer-loop and inner-loop iterations. Second, recognizing that biases may arise in iterative processes due to estimation and modeling errors, we analyze the robustness of the proposed algorithm by using the small-disturbance input-to-state stability technique. This ensures convergence to a neighborhood of the optimal solution, even in the existence of disturbances. Finally, to address the limitation of requiring precise knowledge of agents' dynamics, we employ the integral reinforcement learning technique to develop a data-driven method within the dual-loop iterative framework. A numerical example is provided to demonstrate the effectiveness of the proposed algorithm.
\end{abstract}
\begin{IEEEkeywords}
Robust mean field social control, indefinite SARE, data-driven control, reinforcement learning, robustness
\end{IEEEkeywords}

\section{Introduction}
\label{sec:introduction}
Mean field game (MFG) theory, introduced independently by Lasry and Lions \cite{lasry2007mean} and Huang, Caines,and Malham{\'e} \cite{huang2007large}, provides a powerful framework for analyzing stochastic differential games involving a large number of interacting agents. In an MFG setting, each agent seeks to optimize its own cost functional while being influenced by a mean field term that represents the aggregate effect of all agents. This approach effectively decouples individual interactions, leading to a mean field equilibrium characterized by tractable forward-backward equations: the Kolmogorov-Fokker-Planck equation describes the evolution of the mean field distribution, and the Hamilton-Jacobi-Bellman equation governs the value function for each agent \cite{cousin2011mean,bensoussan2013mean,carmona2018probabilistic}. Mean field social control (MFSC) extends the MFG framework by shifting the focus from individual optimization to collective optimization. Specifically, the goal is to design decentralized strategies that minimize a common social cost, typically defined as the sum or average of all agents' costs. Approaches to finding the social optimum fall into two categories: the person-by-person optimization approach \cite{bauso2016opinion,huang2016linear,wang2017social} and the direct approach \cite{huang2021linear2,wang2020indefinite,wang2020mean}. The former transforms the social optimization problem into a non-cooperative game, allowing the use of MFG theory to find the social optimum. In contrast, the direct approach starts by solving a cooperative game involving all agents simultaneously. The resulting system of coupled equations is then analyzed in the limit as the number of agents approaches infinity. Due to their strengths, MFG and MFSC methodologies have been applied in various fields, including financial regulation \cite{wang2023decentralized,wang2019mean}, epidemic control \cite{aurell2022optimal,uz2023reinforcement} , traffic control \cite{chevalier2015micro,tanaka2020linearly}, and energy management \cite{bagagiolo2014mean,bauso2017dynamic}. However, in many decision-making scenarios, agents face uncertainties from the environment, which disrupt the ideal conditions used in the analysis of mean field equilibria and social optima. 


To address this issue, robust MFG and MFSC have gained considerable attention for their ability to provide strategies resilient to model mismatches and external disturbances. Notable progress has been made, particularly in the linear quadratic Gaussian (LQG) setting, due to its analytical tractability and broad applicability. Most existing research focuses on uncertainty in the drift term of agents' dynamics, where agents may be affected by a common fluctuating factor, such as taxation, subsidy, or interest rate\cite{huang2017robust,huang2013mean,tembine2013robust,moon2016linear,huang2017robust,wang2017social,wang2020social,liang2022robust}. Here, the uncertainty is treated as an adversarial agent and is computed as a state function that forms part of the solution. In particular, \cite{wang2017social} and \cite{wang2020social} studied robust MFSC with additive noise, formulating robust social optimization problems as two team-zero-sum games involving both control and disturbance inputs for all agents. The goal is to attenuate the effect of disturbances on the social cost by rejecting $L_2$-gain from the disturbance to the cost functional-related evaluation signal for each agent. This leads to asymptotic decentralized strategies derived from Riccati-type equations with indefinite quadratic terms, where the indefinite term arises due to the presence of disturbances. In \cite{liang2022robust}, this analysis was extended to systems with multiplicative noise, a more realistic model where noise intensity depends on the system state and inputs. By utilizing the direct approach, the social optimum was determined by low-dimensional indefinite stochastic Riccati-type equations and ordinary differential equations (ODEs), which represent the LQG counterpart of forward-backward equations in more general cases.

As a result, solving indefinite Riccati-type equations is essential for establishing mean field equilibria and social optima in LQG robust MFG and MFSC problems. This topic has been actively studied in the context of linear quadratic $H_{\infty}$ optimal control problems for single-agent systems \cite{bacsar2008h,zhou1996robust}. Specifically, in the continuous-time infinite-horizon setting, the algebraic Riccati equation (ARE) with an indefinite quadratic term is associated with deterministic systems and stochastic systems with additive noise, while the indefinite stochastic algebraic Riccati equation (SARE) arises in stochastic systems with multiplicative noise. 

Among numerical methods, iterative approaches are particularly favored for solving these types of indefinite Riccati equations due to their low computational complexity. For the indefinite ARE, an iterative process proposed in \cite{lanzon2008computing} transforms the problem into solving a sequence of $H_2$-type AREs with negative semidefinite quadratic terms. The global convergence of this method has also been rigorously proven. Furthermore, to eliminate the need for an explicit dynamical model in the iterative procedure, integral reinforcement learning (IRL) (\!\!\cite{vamvoudakis2010online,modares2014optimal,song2016off}), a specialized branch of reinforcement learning  (\!\!\cite{sutton2018reinforcement}), has been employed, as demonstrated in \cite{vrabie2011adaptive,wu2013simultaneous,liu2019new}. In \cite{vrabie2011adaptive}, the authors provided equivalent formulations of iterative algorithm from \cite{lanzon2008computing}. Each stabilizing solution of the proposed sequence of nonlinear matrix equations was approximated using the policy iteration (PI) algorithm (\!\!\cite{kleinman1968iterative}), resulting in a dual-loop iteration process with an inner loop for control updates and an outer loop for disturbance updates. However, no rigorous convergence analysis has been conducted for the entire process. In \cite{wu2013simultaneous}, single-loop iterative algorithms were proposed using the value iteration method, where control and disturbance inputs are updated simultaneously. Local convergence was established by constructing a Newtonâ€™s sequence for the fixed point equation \cite{rall1974note}. In \cite{liu2019new}, the authors further introduced a checkable criterion for algorithm initialization based on Kantorovich's theorem based on \cite{wu2013simultaneous}. Additionally, convergence property of the algorithm is rigorously proved by the mathematical induction principle, under additional conditions.
%  to eliminate the need for an explicit dynamical model in solving iterative equations, as demonstrated in \cite{vrabie2011adaptive} with a dual-loop algorithm and in \cite{liu2019new} with single-loop algorithm.
% In \cite{vrabie2011adaptive}, each solution of these nonlinear matrix equations has been approximated by using the policy iteration (PI) algorithm (\!\!\cite{kleinman1968iterative}), resulting in dual-loop iteration process. 
However, to the best of our knowledge, numerical methods for solving the indefinite SARE, particularly for the state- and input-perturbed SARE, are relatively scarce. Relevant results may be found in \cite{dragan2011computation}, where the stabilizing solution of an indefinite SARE is approximated through a sequence of SAREs with a negative semidefinite quadratic term, referred to as $H_2$-type SAREs. On the other hand, for solving an $H_2$-type SARE with a positive state weighting matrix, \cite{li2022stochastic} proposed a PI method and further employed the IRL technique to partially eliminate the requirement for an exact dynamical model. Inspired by this work, \cite{xu2024mean} extended the approach to a fully model-free version and relaxed the state  weighting matrix to be positive semidefinite. 

\vspace{-0.3cm}
\subsection{Motivation and contributions}
Although recent advances in robust MFG and MFSC have yielded significant theoretical insights, most existing research has concentrated on characterizing robust mean field equilibria and social optima. However, practical engineering applications require efficient methods for computing these solutions, particularly when agentsâ€™ dynamics are partially or completely unknown. This gap between theoretical frameworks and practical implementation motivates the present study. 


In this paper, we investigate the continuous-time LQG robust MFSC problem in the presence of multiplicative noise. Incorporating such noise into stochastic dynamics describes a broader class of real-world systems whose diffusion coefficients vary based on the state and control inputs. This introduces significant challenges in developing model-based and data-driven numerical methods for computing the asymptotic decentralized strategies. 
Utilizing the direct approach \cite{liang2022robust}, we reduce the task of finding the strategies to solving three key equations: an indefinite SARE, an indefinite ARE, and an ordinary differential equation (ODE). However, obtaining stabilizing solutions of these indefinite Riccati-type equations presents challenges unmet by existing methodologies. 

To address these difficulties, we propose a novel unified robust dual-loop iterative framework capable of simultaneously handling the indefinite SARE and ARE. The robustness property of iterative processes is defined in terms of small-disturbance input-to-state stability (ISS), as introduced in recent work \cite{pang2021robust,cui2024robust}. This ensures that the iterative procedures remain stable and converge near the optimal solution, even in the presence of small estimation and modeling errors. Building on this framework, we further develop a data-driven algorithm to approximate the asymptotic decentralized strategies without requiring full knowledge of the underlying system dynamics. 

Our approach tackles four key technical hurdles: 1). Applying the PI algorithm to the $H_2$-type SARE framework proposed in \cite{dragan2011computation} is intractable. To overcome this, we construct a new sequence of $H_2$-type SAREs in the outer loop and rigorously establish the convergence result. Moreover, unlike traditional PI methods that rely on positive (semi-)definite state weighting matrices for convergence, our equations may involve indefinite state weighting matrices. To bridge this gap, we develop a novel convergence analysis tailored to indefinite state weighting matrices, broadening the applicability of the PI algorithm. 2). Beyond disturbances in agentsâ€™ dynamics, biases arise in iterative processes due to estimation and modeling errors. To address this issue, we model these inexact iterations as discrete-time systems and treat errors as external disturbances. Using the small-disturbance ISS framework, we prove that both inner-loop and outer-loop iterative processes remain stable and convergent, even with small disturbances. Additionally, we establish the global linear convergence of the inner loop and ensure its independence from parameters of the outer loop. 3). While the robust MFSC problem involves both indefinite SARE and ARE, no existing unified framework addresses these equations simultaneously. We employ spectral techniques for Lyapunov-type operators to unify the stability and detectability conditions for both stochastic and deterministic cases. This provides a solid theoretical foundation for our unified solution methodology. 4). Transitioning to a data-driven approach for approximating the mean field social optimum strategies is difficult, particularly for the indefinite ARE. First, such ARE includes constant terms that explicitly depend on the system parameters, making it difficult to eliminate reliance on a dynamical model from the iterative equation. To solve this, we apply an equation transformation that removes these direct parameter dependencies while ensuring convergence. Second, multiplicative noise complicates the direct application of IRL techniques to the agents' trajectories. This hinders the development of data-driven iterative equations. To overcome this, we perform a system transformation to eliminate the multiplicative noise and leverages variations in the agentsâ€™ trajectories. Moreover, we determine stabilizing initial conditions through a combination of system identification and linear matrix inequality (LMI) techniques. Notably, the same dataset supports both iterative and identification procedures.
 
 

Our main contributions are summarized as follows: (\romannumeral 1) A novel unified dual-loop iterative framework is proposed for solving both indefinite SARE and ARE, with guaranteed convergence. (\romannumeral 2) Robustness analyses of both outer-loop and inner-loop iterations are conducted using the small-disturbance ISS technique, ensuring the convergence in the presence of disturbances. (\romannumeral 3) A novel data-driven algorithm is developed to approximate the mean field social optimum strategies without requiring full prior knowledge of agents' dynamics.

\vspace{-0.3cm}
\subsection{Organization and Notations}
This paper is organized as follows. Section \ref{sec2} describes the problem formulation and presents basic results for robust MFSC. In section \ref{sec:main result1}, a dual-loop iterative framework for solving indefinite Riccati-type equations is introduced, along with rigorous proofs of convergence. Section \ref{sec:main result2} provides theoretical analyses of the robustness properties for both iterative processes. In Section \ref{sec:main result3}, the proposed framework is applied to solve the robust MFSC problem, and a data-driven method is developed. Section \ref{sec:simulation} presents a simulation example to demonstrate the effectiveness of the proposed approach. Finally, Section \ref{sec:conclusion} concludes the paper.
 
% $\|\cdot\|_2$ and $\|\cdot\|_F$ represent the spectral norm and the Frobenius norm of a matrix, respectively.
A list of notations is presented as follows. For a family of $\mathbb{R}^n$-valued random variables $\{x(\tau),\tau\geq0\}$, $\sigma(x(\tau),\tau\leq t)$ is the $\sigma$-algebra generated by these random variables. For a matrix $A\in\mathbb{R}^{m\times n}$, $\mathrm{vec}(A)$ denotes the $mn$-dimensional vector obtained by stacking the columns of $A$ sequentially. Similarly, for a symmetric matrix $P\in\mathbb{S}^n$, $\mathrm{vecm}(P)$ denotes the vectorization with only its upper triangular part, defined as $[p_{11},p_{12},\cdots,p_{1n},p_{22},p_{23},\cdots,p_{nn}]^{\mathrm{T}}\in\mathbb{R}^{\frac{n(n+1)}{2}}$. The matrix $E_j$ is an $n\times n$ matrix with with its $j$-th diagonal element equal to one, while all the other entries are zero. For a family of $\mathbb{R}^n$-valued random variables $\{x(\tau),\tau\geq0\}$ and $\mathbb{R}^m$-valued random variables $\{y(\tau),\tau\geq0\}$, and a given time interval $T>0$, we define $\mathrm{vecv}(x)$ as the vector $[x_1^2,x_1x_2,\cdots,x_1x_n,x_2^2,\cdots,x_{n-1}x_n,x_n^2]\in\mathbb{R}^{\frac{1}{2}n(n+1)}$. The increment in the expected value of this vectorization is denoted by $\delta_{x}=\mathbb{E}[\mathrm{vecv}(x(t+T))-\mathrm{vecv}(x(t))]$. Moreover, we define $\delta_{xx}=\mathbb{E}[x(t+T)\otimes x(t+T)-x(t)\otimes x(t)]$ $I_x^t = \mathbb{E}\int_t^{t+T}\mathrm{vecv}(x(\tau))\mathrm{d}\tau$, $I_{xx}^t=\mathbb{E}\int_t^{t+T}x(\tau)\otimes x(\tau)\mathrm{d}\tau$, $I_{xy}^t = \mathbb{E}\int_t^{t+T}x(\tau)\times y(\tau)\mathrm{d}\tau$.

\section{Problem formulation}\label{sec2}
Consider a population of $N$ agents, denoted by $\mathcal{A}=\{\mathcal{A}_1,\cdots,\mathcal{A}_N\}$, where $\mathcal{A}_i$ represents the $i$-th agent. The state process $x_i(t)\in\mathbb{R}^n$ of $\mathcal{A}_i$ evolves according to the following stochastic differential equation (SDE)
\begin{equation}\label{sys1}
\left\{\begin{aligned}
&\mathrm{d}x_i(t)=\left[Ax_i(t)+Bu_i(t)+Gv_i(t)\right]\mathrm{d}t +\left[Cx_i(t)\!+\!Du_i(t)\right]\mathrm{d}w_i(t),\\
&x_i(0) =x_{i0}, 
\end{aligned}\right.
\end{equation}
where $u_i\in\mathbb{R}^{m_1}$, and $v_i\in\mathbb{R}^{m_2}$ represent the control input and external disturbance for $\mathcal{A}_i$, respectively. $\{w_i(t),1\leq i\leq N\}$ are a sequence of independent one-dimensional Brownian motions defined on a complete filtered probability space $(\Omega,\mathcal{F},\{\mathcal{F}_t\}_{t\geq0},\mathbb{P})$. The initial states $\{x_{i0},1\leq i\leq N\}$ are mutually independent and have the same expectation ({\sl i.e., $\mathbb{E}[x_{i0}]=\bar{x}_0 \in\mathbb{R}^n$}) and a finite second moment ({\sl i.e., ${\max_{1\leq i\leq N}}\mathbb{E}[\|x_{i0}\|^2]<c_0$, with $c_0<\infty$ a constant independent of $N$}). These initial states are also independent of $\{w_i(t),1\leq i\leq N\}$. The matrices $A,B,G,C,D$ are constant with compatible dimensions.



For each individual agent, the performance is typically evaluated using the following quadratic cost functional 
$$\mathbb{E} \int_0^{\infty}\left(\|x_i(\tau)-\Gamma x_{(N)}(\tau)\|_Q^2+\|u_i(\tau)\|_{R}^2\right)\mathrm{d}\tau,$$
where $x_{(N)}\!\!=\!\!(1/N)\sum_{\!j=1}^{\!N}\!x_j$ denotes the average state of the population. $Q\!\!\geq\!\!0$, $R\!\!>\!\!0$, and $\Gamma\!\!\in\!\!\mathbb{R}^{n\times n}$ are weighting matrices.  

However, the presence of the external unknown disturbance $v_i$ degrades the performance. To reduce the sensitivity of the cost function to this disturbance, an $L_2$-gain condition
\begin{equation*} 
\frac{\mathbb{E}\int_0^{\infty}\left(\|x_i(\tau)-\Gamma x_{(N)}(\tau)\|_Q^2+\|u_i(\tau)\|_{R}^2 \right)\mathrm{d}\tau}{\mathbb{E}\int_0^{\infty}\|v_i(\tau)\|^2 \mathrm{d}\tau}\leq\gamma^2,
\end{equation*}
is introduced by restricting $v_i(t)$ to the space of all $\mathcal{F}_t^i$-progressively measurable processes with values in $\mathbb{R}^{m_2}$ satisfying $\mathbb{E}\int_0^{\infty}\|v_i(\tau)\|^2\mathrm{d}\tau<\infty$, where $\mathcal{F}_t^i = \sigma(x_i(s),s\leq t)$, $t\geq0$. The constant $\gamma>0$ represents the desired disturbance attenuation level. Obviously, this condition ensures that the gain from the disturbance to the evaluated signal $z=[(x_i-\Gamma x_{(N)})^{\mathrm{T}}Q^{\frac{1}{2}},
u_i^{\mathrm{T}}R^{\frac{1}{2}}]^{\mathrm{T}}$ is bounded by $\gamma$ in expectation. Hence, robust control for each agent can be reduced to find an admissible control strategy that makes the disturbance attenuation level $\gamma$ as small as possible.

Following the $H_{\infty}$ design fashion, we define the social cost functional for the population of $N$ agents by 
\begin{equation}\label{Jsoc}  
J_{\text{soc}}(\mathbf{u},\mathbf{v})=\sum\nolimits_{j=1}^{N}J_i(\mathbf{u},\mathbf{v}),
\end{equation}
with the individual cost function $J_i(\mathbf{u},\mathbf{v})$ given by
\begin{equation}
\begin{aligned}
J_i(\mathbf{u},\!\mathbf{v})\!=\!\mathbb{E}\!\!\int_0^{\infty}\!\!\Big(\|x_i\!-\!\Gamma x_{(N)}\|_Q^2\!+\!\|u_i\|_{R}^2\!-\!\gamma^2\|v_i\|^2\Big)\mathrm{d}\tau,
\end{aligned}
\end{equation}
where $\mathbf{u}=(u_1,\cdots,u_N)$ and $\mathbf{v}=(v_1,\cdots,v_N)$. 

  

This robust social optimization problem can be formulated as a two-team zero-sum differential games, where the control team $\mathbf{u}$ seeks to minimize the social cost, while the disturbance team $\mathbf{v}$ desires to maximize it. The solution corresponds to saddle point $(\mathbf{u}^*,\mathbf{v}^*)$ satisfying
\begin{equation}
J_{\text{soc}}(\mathbf{u}^*,\mathbf{v}^*)\!=\!\mathop{\inf_{\mathbf{u}}\sup_{\mathbf{v}}}J_{\text{soc}}(\mathbf{u},\mathbf{v})\!=\!\sup_{\mathbf{v}}\inf_{\mathbf{u}}J_{\text{soc}}(\mathbf{u},\mathbf{v}).
\end{equation}



Depending on the different information structures available to the agents, their admissible strategies can be either centralized, denoted by $({\bf u},{\bf v})\in\mathcal{U}_{c}^u\times\mathcal{U}_{c}^v$, or decentralized, denoted by $({\bf u},{\bf v})\in\mathcal{U}_{d}^u\times\mathcal{U}_{d}^v$. The precise definitions of these admissible sets are standard and can be founded in \cite{wang2020indefinite,liang2022robust}. Within the set of admissible decentralized strategies, we introduce the concept of the mean field social optimum.
\begin{definition} 
A set of decentralized strategies $(\!{\bf u}^{o}\!,\!{\bf v}^{o}\!)\!\in\! \mathcal{U}_{d}^u\! \times\! \mathcal{U}_{d}^{v}$ is called an mean field social optimum if it has asymptotic robust social optimality, {\sl i.e., 
\begin{equation*}
\begin{aligned}
\left|\frac{1}{N}J_{\mathrm{soc}}({\bf u}^o,{\bf v}^o)-\frac{1}{N}\inf_{{\bf u}\in \mathcal{U}_{c}^u}\sup_{{\bf v}\in\mathcal{U}_{c}^v}J_{\mathrm{soc}}({\bf u},{\bf v})\right|=o(1).
\end{aligned}
\end{equation*}}
\end{definition}

Using the direct approach from \cite{liang2022robust}, we have that the closed-loop decentralized strategies $({\bf u}^o,{\bf v}^o)$ given by
\begin{numcases}{}
{u}^{o}_i(t)= -K_px_i(t)-(K_s-K_p)\bar{x}(t),~~1\leq i\leq N,\label{uo}\\
{v}^{o}_i(t)=L_px_i(t)+(L_s-L_p)\bar{x}(t),~~1\leq i\leq N,\label{do}
\end{numcases}
with the closed-loop mean field dynamics
\begin{equation}\label{xbar}
\dot{\bar{x}}(t) \!=\! \left(A\!-\!BK_s+\!GL_s\right)\!\bar{x}(t),~\bar{x}(0)\!=\!\bar{x}_0, 
\end{equation}
constitute a mean field social optimum. Here, the gain matrices $K_p$, $K_s$, $L_p$, and $L_s$ are defined as 
\begin{equation}\label{gain_op}
\left\{\begin{aligned}
&K_p \triangleq \Upsilon^{-1}(B^{\mathrm{T}}P+D^{\mathrm{T}}PC),~~K_s \triangleq  \Upsilon^{-1}B^{\mathrm{T}}S,\\
&L_p \triangleq  \frac{1}{\gamma^2}G^{\mathrm{T}}P,~~{L}_s \triangleq  \frac{1}{\gamma^2}G^{\mathrm{T}}S,
\end{aligned}\right.
\end{equation}
with $\Upsilon\triangleq R+D^{\mathrm{T}}PD$. $P$ and $S$ are the unique positive semidefinite stabilizing solutions to the following equations
\begin{equation}\label{are1}
\begin{aligned}
\!\!\!\!\!&A^{\mathrm{T}}\!P\!+\!P\!A\!+\!C^{\mathrm{T}}\!PC\!+\!Q\!+\!\frac{1}{\gamma^2}\!PGG^{\mathrm{T}}\!P\!-\!(P\!B\!+\!C^{\mathrm{T}}\!PD)\Upsilon^{-1}\!(B^{\!\mathrm{T}}P+D^{\mathrm{T}}PC)=0,
\end{aligned}
\end{equation}
\begin{equation}\label{are3}
\begin{aligned}
A_s^{\mathrm{T}}S+SA_s+Q_s+\frac{1}{\gamma^2}SGG^{\mathrm{T}}S-SB\Upsilon^{-1}B^{\mathrm{T}}S=0,
\end{aligned}
\end{equation}
where $A_s=A-B\Upsilon^{-1}D^{\mathrm{T}}PC$, $Q_{\Gamma}=-\Gamma^{\mathrm{T}}Q\Gamma+\Gamma^{\mathrm{T}}Q+Q\Gamma$ and $Q_s=Q-Q_{\Gamma}+(C-D\Upsilon^{-1}D^{\mathrm{T}}PC)^{\mathrm{T}}P(C-D\Upsilon^{-1}D^{\mathrm{T}}PC)+C^{\mathrm{T}}PD\Upsilon^{-1}R\Upsilon^{-1}D^{\mathrm{T}}PC\geq0$.  


However, in practical applications, the exact parameters of the agentsâ€™ dynamics ({\sl i.e., $A,B,G,C,D$}) may not be precisely known. Solving these indefinite Riccati-type equations under such uncertainties poses significant challenges. Therefore, our main goal is to develop an iterative method that does not rely on an exact dynamical model and offers guaranteed convergence and robustness. 

% especially in presence of disturbances and limited prior knowledge of the agents' dynamics ({\sl i.e., matrices $A,B,G,C,D$}), which becomes a bottleneck in practical applications. To overcome this challenge, our main goal is to develop an iterative method that does not rely on an exact dynamical model and has guaranteed convergence and robustness.
  
\section{A unified iterative framework for solving indefinite Riccati-type equations}\label{sec:main result1}
In this section, we present a unified dual-loop iterative framework for solving both the SARE and the ARE with indefinite quadratic terms. In the outer-loop iteration, a sequence of $H_2$-type (S)AREs is introduced, whose solutions converge to the stabilizing solution of the indefinite (S)ARE. In the inner-loop iteration, each outer-loop solution is further approached by solving a sequence of linear matrix equations. 

\vspace{-0.3cm}
\subsection{Unified formulation of useful concepts and operators}
To facilitate the development of an algorithm that can be applied to both stochastic and deterministic cases, we express the parameters of the SARE and ARE in a unified form and consider the generalized Riccati equation 
\begin{equation}\label{GARE0}
\begin{aligned}
 0=&\mathds{A}^{\mathrm{T}}\mathds{X}_i\!+\!\mathds{X}_i\mathds{A}\!+\!\mathds{C}_i^{\mathrm{T}}\mathds{X}_i\mathds{C}_i\!+\!\mathds{Q}+\mathds{X}_i\mathds{G}\mathds{W}^{-1}\mathds{G}^{\mathrm{T}}\mathds{X}_i-(\mathds{X}_i \mathds{B}+\mathds{C}_i^{\mathrm{T}} \mathds{X}_i\mathds{D}_i)\mathds{R}_i ^{-1}(\mathds{B}^{\mathrm{T}} \mathds{X}_i+\mathds{D}_i^{\mathrm{T}} \mathds{X}_i\mathds{C}_i),
\end{aligned}
\end{equation}
where 
\begin{equation*}
\mathds{C}_i=i\mathds{C},~~\mathds{D}_i=i\mathds{D},~~\mathds{R}_i = \mathds{R}+\mathds{D}_i^{\mathrm{T}} \mathds{X}_i\mathds{D}_i,~~i\in\{0,1\},
\end{equation*}
and other involved constant matrices are $\mathds{A}\in\mathbb{R}^{n\times n}$, $\mathds{C}\in\mathbb{R}^{n\times n}$, $\mathds{B}\in\mathbb{R}^{n\times m_1}$, $\mathds{D}\in\mathbb{R}^{n\times m_1}$, and $\mathds{G}\in\mathbb{R}^{n\times m_2}$. The symmetric matrices $\mathds{R}\in\mathbb{S}^{m_1}$ and $\mathds{W}\in\mathbb{S}^{m_2}$ are positive definite. Here, $\mathds{X}_i\in\mathbb{S}^n$ is the positive semidefinite stabilizing solution that we seek.

Equation (\ref{GARE0}) encompasses Riccati-type equations commonly encountered in optimal control for both stochastic and deterministic systems. The dynamics of these systems can be described by  
\begin{subequations}{}\label{sys_s}
\begin{empheq}[left={\left\{\begin{aligned}},right={\end{aligned}\right.}]{align}
&\mathrm{d}\boldsymbol{x}=\left(\mathds{A}\boldsymbol{x}-\mathds{B}\boldsymbol{u}+\mathds{G}\boldsymbol{v}\right)\mathrm{d}t+\left(\mathds{C}_i\boldsymbol{x}+\mathds{D}_i\boldsymbol{u}\right)\mathrm{d}\boldsymbol{w},\label{sys_s1}\\
&\boldsymbol{y}=\mathds{H}\boldsymbol{x}, \label{sys_s2}
\end{empheq}
\end{subequations}
where $\boldsymbol{w}(t)$ is a one-dimensional standard Brownian motion, and $\mathds{H}$ is the output matrix. 
To streamline our notation, we define the system (\ref{sys_s1}) as $\mathcal{S}_i\triangleq[\mathds{A},\mathds{B},\mathds{G}|\mathds{C}_i,\mathds{D}_i]$.
 


For all $i\in\{0,1 \}$ we define the Lyapunov-type operator $\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]}:\mathbb{S}^n\mapsto\mathbb{S}^n$ as 
\begin{equation}\label{opt:Lyapunov}
 \begin{aligned}
\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]}(X)\!\triangleq&(\mathds{A}\!-\!\mathds{B}\mathds{K}\!+\!\mathds{G}\mathds{L})^{\mathrm{T}}X\!+\!X(\mathds{A}\!-\!\mathds{B}\mathds{K}\!+\!\mathds{G}\mathds{L})+(\mathds{C}_i-\mathds{D}_i\mathds{K})^{\mathrm{T}}X(\mathds{C}_i-\mathds{D}_i\mathds{K}),
\end{aligned} 
\end{equation}
with spectrum 
\begin{equation*}
\sigma(\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]})\!=\!\{\lambda\in\mathbb{C}:\!\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]}(X)\!=\!\lambda X, X\!\in\!\mathbb{S}^n,X\!\neq\!0\}.
\end{equation*}

\begin{remark}
The adjoint operator $\mathscr{L}^*_{[\mathds{K},\mathds{L},\mathcal{S}_i]}$ is given by
\begin{equation*} 
 \begin{aligned}
\!\!\!\!\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]}^*(X)\!=&(\mathds{A}\!-\!\mathds{B}\mathds{K}\!+\!\mathds{G}\mathds{L})X\!+\!X(\mathds{A}\!-\!\mathds{B}\mathds{K}\!+\!\mathds{G}\mathds{L})^{\mathrm{T}}+(\mathds{C}_i-\mathds{D}_i\mathds{K})X(\mathds{C}_i-\mathds{D}_i\mathds{K})^{\mathrm{T}},
\end{aligned} 
\end{equation*}
This operator is commonly used to analyze asymptotic mean square stability of It\^{o} differential systems via its spectrum \cite{willems1976feedback,zhang2004stabilizability}. Since all the coefficient matrices considered here are real, we have that the spectrum of $\mathcal{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]}$ is identical to that of $\mathcal{L}^*_{[\mathds{K},\mathds{L},\mathcal{S}_i]}$, {\sl i.e., $\sigma(\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]})=\sigma(\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]}^*)$}. Consequently, we will consistently use $\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]}$ to characterize stability and stabilizability.
\end{remark}


\begin{proposition}[\cite{zhang2004stabilizability}]\label{propo:stability_SDE}
The closed-loop system
\begin{equation}\label{sys:SDE}
\mathrm{d}\boldsymbol{x}=(\mathds{A}-\mathds{B}\mathds{K}+\mathds{G}\mathds{L})\boldsymbol{x}\mathrm{d}t+(\mathds{C}_i-\mathds{D}_i\mathds{K})\boldsymbol{x}\mathrm{d}\boldsymbol{w}
\end{equation}
is asymptotically mean square stable, {\sl i.e., $$\lim_{t\rightarrow\infty} \mathbb{E}\left[\boldsymbol{x}(t)\boldsymbol{x}(t)^{\mathrm{T}}\right]=0,$$} if and only if the spectrum of $\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]}$ lies entirely in the open left half-plane $\mathbb{C}^-$.
\end{proposition}

Note that when $i=0$, the stochastic terms vanish, and the closed-loop system (\ref{sys:SDE}) can be reduced to 
\begin{equation}\label{sys:ODE}
\mathrm{d}\boldsymbol{x}=\mathds{A}_c\boldsymbol{x}\mathrm{d}t,\quad \mathds{A}_c=\mathds{A}-\mathds{B}\mathds{K}+\mathds{G}\mathds{L}.
\end{equation}
\begin{proposition}[\cite{chen1984linear}]\label{propo:stability_ODE}
For the closed-loop system (\ref{sys:ODE}), we called the equilibrium of it is asymptotically stable, {\sl i.e., $\lim_{t\rightarrow\infty} \boldsymbol{x}(t)=0,$} if and only if $\sigma(\mathds{A}_c)\triangleq\{\tilde{\lambda}\in\mathbb{C}: \mathds{A}_cx=\tilde{\lambda}x, x\in\mathbb{C}^n, x\neq0\}\subset\mathbb{C}^-$.
\end{proposition}

The next proposition establishes an equivalence between the asymptotic stability of system (\ref{sys:ODE}) and the fact that the operator $\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_0]}$ possesses a Hurwitz spectrum.
\begin{proposition}\label{propo:stabilization}
$\sigma(\mathds{A}_c)\!\subset\!\mathbb{C}^-$ if and only if $\sigma(\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_0]})\!\subset\!\mathbb{C}^-$.
\end{proposition}

\bproof
The spectrum of $\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_0]}$ is given by 
\begin{equation*}
\mathds{A}_c^{\mathrm{T}}X+X\mathds{A}_c=\lambda X,\quad X\in\mathbb{S}^{n}.
\end{equation*}
Using the Kronecker product, this can be transformed into
\begin{equation*}
\left(I_n\otimes \mathds{A}_c^{\mathrm{T}}+\mathds{A}_c^{\mathrm{T}}\otimes I_n\right)\mathrm{vec}(X)=\lambda \mathrm{vec}(X),
\end{equation*}
which implies
\begin{equation*} 
\sigma(\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_0]})=\{\tilde{\lambda}_j+\tilde{\lambda}_k|~\tilde{\lambda}_j,\tilde{\lambda}_k\in\sigma(\mathds{A}_c),j,k=1,\cdots,n\}.
\end{equation*} 
Thus, it can be immediately concluded that $\sigma(\mathds{A}_c)\subset\mathbb{C}^-$ if and only if $\sigma(\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_0]})\subset\mathbb{C}^-$.
\eproof

Therefore, in both cases, we can analyze stability by means of spectral criterion as follows.  
\begin{proposition}\label{propo:stabilizability}
For any $i\in\{0,1\}$, the system $\mathcal{S}_i$ is stabilizable if and only if there exists $(\mathds{K},\mathds{L})\in\mathbb{R}^{m_1\times n}\times \mathbb{R}^{m_2\times n}$ such that $\sigma(\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]})\!\subset\!\mathbb{C}^-$.
\end{proposition}


The proof follows directly from Propositions \ref{propo:stability_SDE} and \ref{propo:stability_ODE}. Notably, if $\mathds{G}=0$, the gain matrix $\mathds{L}$ vanishes, making Proposition \ref{propo:stabilization} reduce to \cite[Theorem 1]{zhang2004stabilizability}, where the necessary and sufficient condition for stabilizability can be expressed as $\sigma(\mathds{L}_{[\mathds{K},\mathbf{0},\mathcal{S}_i]})\subset\mathbb{C}^-$.

\begin{remark}
In the context of stochastic systems, stochastic detectability is the dual concept to stochastic stabilizability (in the mean square sense), as defined in \cite{chen2004stochastic}. Specifically, system (\ref{sys_s}) or $[\mathds{A},\mathds{H},0|\mathds{C}_i,0]$ (simplified as  $[\mathds{A},\mathds{H}|\mathds{C}_i]$) is stochastically detectable if the dual system $[\mathds{A}^{\mathrm{T}},\mathds{H}^{\mathrm{T}},0|\mathds{C}_i^{\mathrm{T}},0]$ is stabilizable for $i=1$. When $i=0$, the concept of stochastic detectability aligns with the standard notion of detectability in deterministic systems, as detailed in \cite{chen1984linear}. For simplicity, in the following we refer to stochastic detectability and deterministic detectability together as detectability.
\end{remark}

\begin{remark}
As stated in \cite{zhang2005spectral,kucera1972contribution}, detectability ensures that all unobservable modes of the system are stable. In other words, any unobservable internal dynamics do not lead to the system unstable. Combined with the spectrum method, this property provides a sufficient condition for detectability, which will be established in Proposition \ref{propo:detectable_sufficient}. The proof  directly follows from \cite[Propostiton 1]{zhang2005spectral} and Proposition \ref{propo:stability_ODE}.

Moreover, the concept of mean square detectability introduced in \cite{fragoso1998new} corresponds with our definition when $\Gamma(X)=\mathds{C}^{\mathrm{T}}X\mathds{C}$ for the stochastic case and $\Gamma(X)=0$ for the deterministic case, as indicated in equation (3.1) of \cite{fragoso1998new}. From \cite[Lemma 3.2]{fragoso1998new} and Proposition \ref{propo:stability_ODE}, we propose Proposition \ref{propo:detectable_necessary}, which, together with Proposition \ref{propo:detectable_sufficient}, plays important role in our analyses.
\end{remark}
 
 
\begin{proposition} \label{propo:detectable_sufficient}
For any $i\!\in\!\{0,\!1\}$, if $[\mathds{A},\!\mathds{H}|\mathds{C}_i]$ is detectable, then there does not exist a nonzero $X\in\mathbb{S}^n$ satisfying 
\begin{equation}\label{pro4eq1}
\left\{\begin{aligned}
&\mathscr{L}_{[\mathbf{0},\mathbf{0},\mathcal{S}_i]}(X)=\lambda X, \quad Re(\lambda)\geq0,\\
&\mathds{H}X=0.
\end{aligned}\right.
\end{equation}
\end{proposition}


 

 
\begin{proposition}\label{propo:detectable_necessary}
Consider the Lyapunov equation
\begin{equation}\label{lem_eq1}
\mathscr{L}_{[\mathbf{0},\mathbf{0},\mathcal{S}_i]}(X)+ \mathds{H}^{\mathrm{T}}\mathds{H}=0.
\end{equation}
For any $i\!\in\!\{0,\!1\}$, if $[\mathds{A},\!\mathds{H}|\mathds{C}_i]$ is detectable, then the spectrum of $\mathscr{L}_{[\mathbf{0},\mathbf{0},\mathcal{S}_i]}$ belongs to $\mathbb{C}^-$ if and only if equation (\ref{lem_eq1}) has a unique solution $X\geq0$.
\end{proposition}






Let $\mathcal{U}_i\triangleq\{\mathds{R},\mathds{B},\mathds{C}_i,\mathds{D}_i\}$ and $\mathcal{V} \triangleq \{\mathds{W},\mathds{G}\}$, and we define the following operators
\begin{align}
&\mathscr{K}^1_{\mathcal{U}_i}(X) \triangleq(\mathds{R}+\mathds{D}_i^{\mathrm{T}}X\mathds{D}_i)^{-1}\!\!\left(\mathds{B}^{\mathrm{T}}\!X\!+\!\mathds{D}_i^{\mathrm{T}}\!X\mathds{C}_i\right),\\
&\mathscr{K}^2_{\mathcal{V}}(X)\triangleq\mathds{W}^{-1}\mathds{G}^{\mathrm{T}} X.
\end{align}
Using the defined operators, equation (\ref{GARE0}) can be rewritten as
\begin{subequations}{}\label{are_operator}
\begin{empheq}[left={\left\{\begin{aligned}},right={\end{aligned}\right.}]{align}
&\mathscr{L}_{[\mathds{K}_i,\mathds{L}_i,\mathcal{S}_i]}(\mathds{X}_i)+\mathds{Q}-\|\mathds{L}_i\|_{\mathds{W}}^2+\|\mathds{K}_i\|_{\mathds{R}}^{2}=0,\label{are_operator1}\\
&\mathds{K}_i=\!\mathscr{K}_{\mathcal{U}_i}^1(\mathds{X}_i),\label{are_operator3}\\
&\mathds{L}_i =\mathscr{K}_{\mathcal{V}}^2(\mathds{X}_i).\label{are_operator2}
\end{empheq}
\end{subequations}
We replace $\mathds{L}_i$ of the above equation with a constant matrix $\boldsymbol{L}_i$ to obtain the following $H_2$-type (S)ARE
\begin{subequations}\label{general:oueter-loop}
\begin{empheq}[left={\left\{\begin{aligned}},right={\end{aligned}\right.}]{align}
&\mathscr{L}_{[\mathds{K}_{\boldsymbol{L}_i},\boldsymbol{L}_i,\mathcal{S}_i]}(\mathds{X}_{\boldsymbol{L}_i})+ \mathds{Q} -\|\boldsymbol{L}_i\|_{\mathds{W}}^2+\|\mathds{K}_{\boldsymbol{L}_i}\|_{\mathds{R}}^2=0,\label{general:oueter-loop1}\\
&\mathds{K}_{\boldsymbol{L}_i} = \mathscr{K}_{\mathcal{U}_i}^1(\mathds{X}_{\boldsymbol{L}_i}). \label{general:oueter-loop2}
\end{empheq}
\end{subequations}
Next, we further relax $\mathds{K}_{\boldsymbol{L}_i}$ to a constant matrix $\boldsymbol{K}_i$ to obtain the Lyapunov equation
\begin{equation}\label{general:inner-loop}
\mathscr{L}_{[\boldsymbol{K}_i,\boldsymbol{L}_i,\mathcal{S}_i]}(\mathds{X}_{\boldsymbol{K}_i})+ \mathds{Q} -\|\boldsymbol{L}_i\|_{\mathds{W}}^2+\|\boldsymbol{K}_i\|_{\mathds{R}}^2=0.
\end{equation}
 \begin{figure}[H]
\centering
\includegraphics[scale=0.4]{digram3_2}
\centering
\caption{Structures of different equations: (left) Indefinite (S)ARE; (middle) $H_2$-type (S)ARE; (right) Lyapunov equation.}\label{f:digram1}
\end{figure}
As illustrated in Fig. \ref{f:digram1}, the transformation from equation (\ref{are_operator}) to equation (\ref{general:inner-loop}) involves opening the closed loops in sequence. The resulting two equations provide the basis for the subsequent iterative procedures by introducing new loops with specific logic. Throughout the remainder of the dual-loop iterative framework content, all analyses and results hold for all $i\in\{0,1\}$. For brevity, explicit references to this condition are omitted in following discussions.


 

% Without loss of generality, we assume that there exists a unique positive semidefinite solution $\mathds{X}_i$ of equation (\ref{are_operator}) such that $\mathscr{L}_{[\mathds{K}_i,\mathds{L}_i,\mathcal{S}_i]}\subset\mathbb{C}^-$ and $\mathds{R}_i>0$. Define the admissible set $\mathcal{W}\! :=\! \{\mathds{L}\in\mathbb{R}^{m_2\times n}|$ $\mathds{X}_i^{\boldsymbol{v}}\geq0,~\sigma(\mathscr{L}_{[\mathds{K}_i^{\boldsymbol{v}},\mathds{L},\mathcal{S}_i]})\subset \mathbb{C}^-\}$ and $\mathcal{H}:=\{\mathrm{Tr}(\mathds{X}_i^{\boldsymbol{k}})-\mathrm{Tr}(\mathds{X}_i)|\mathds{L}\in\mathcal{W}\}$. For any $h\in\mathcal{H}$, define the set $\mathcal{G}_{h}:=\{\mathds{L}\in\mathcal{W}|\mathrm{Tr}(\mathds{X}_i^{\boldsymbol{v}}-\mathds{X}_i)\leq h\}$.

% Furthermore, for a given $\mathds{L}\in\mathcal{G}_{h}$, define the sets $\mathcal{Z}(\mathds{L})=\{\mathds{K}\in\mathbb{R}^{m_1\times n}|\mathds{X}_i^{\boldsymbol{k}}\geq0,~\sigma(\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]})\subset\mathbb{C}^-\}$, $\mathcal{N}(\mathds{L}) = \{\mathrm{Tr}(\mathds{X}_i^{\boldsymbol{k}})-\mathrm{Tr}(\mathds{X}_i^{\boldsymbol{v}})|\mathds{K}\in\mathcal{Z}(\mathds{L})\}$, and $\mathcal{D}_{\delta}(\mathds{L})=\{\mathds{K}\in\mathcal{Z}(\mathds{L})|\mathrm{Tr}(\mathds{X}_i^{\boldsymbol{k}}-\mathds{X}_i^{\boldsymbol{v}})\leq {\delta}\}$, where $\delta\in\mathcal{N}(\mathds{L})$.


% It is easy to see that $\mathds{L}_i\in\mathcal{G}_0\subset\mathcal{W}$ and $\mathds{K}_i\in\mathcal{D}_{0}(\mathds{L}_i)\subset\mathcal{Z}(\mathds{L}_i)$. In Appendix \ref{Auxiliary results}. we derive several useful results based on these formulations.
 


% \begin{remark}
%  We define the set of stabilizing $\mathds{L}$ as $\mathcal{W}\! =\! \{\mathds{L}\in\mathbb{R}^{m_2\times n}|$ $\sigma(\mathscr{L}_{[\mathds{K}_i^{\boldsymbol{v}},\mathds{L},\mathcal{S}_i]})\subset \mathbb{C}^-,i=1,2\}$, and define $\mathcal{D}_{\delta}=\{\mathds{L}\in\mathcal{W}|0\leq\mathrm{Tr}(\mathds{X}_i-\mathds{X}_i^{\boldsymbol{v}})\leq\delta\}$. The set of stabilizing $\mathds{K}$ for a given $\mathds{L}$ is defined as $\widetilde{\mathcal{W}}(\mathds{L}) \!=\! \{\mathds{K}\!\in\!\mathbb{R}^{m_1\times n}|$ $\sigma(\mathscr{L}_{[\mathds{K},\mathds{L},\mathcal{S}_i]})\!\subset\!\mathbb{C}^-\}$. For a given $\mathds{L}\in \mathcal{D}_{\delta}$, define $\widetilde{D}_{\tilde{\delta}}(\mathds{L})=\{\mathds{K}\in\widetilde{W}(\mathds{L})|0\leq\mathrm{Tr}(\mathds{X}_i^{\boldsymbol{k}}-\mathds{X}_i^{\boldsymbol{v}})\leq\tilde{\delta}\}$. In Appendix \ref{Auxiliary results}. we derive several useful results based on these formulations.
% \end{remark}
\vspace{-0.3cm}
\subsection{Introduction of outer-loop iteration}
For the $H_2$-type Riccati equation (\ref{general:oueter-loop}), we define the admissible set of $\boldsymbol{L}_i$ as 
\begin{align*}
\mathcal{W}\triangleq\{&\boldsymbol{L}_i\!\in\!\mathbb{R}^{m_2\times n}|\text{Eq. \eqref{general:oueter-loop} has a unique stabilizing solution}\\
&\text{ such that $0\!\leq\!\mathds{X}_{\boldsymbol{L}_i}\leq\mathds{X}_i$ and $\sigma(\mathscr{L}_{[\mathds{K}_{\boldsymbol{L}_i},\boldsymbol{L}_i,\mathcal{S}_i]})\!\subset\!\mathbb{C}^-$}\}.
\end{align*}
\begin{lemma}\label{lem:used in Theorem1}
Let $\mathds{L}_{\boldsymbol{L}_i}\!=\!\mathscr{K}_{\mathcal{V}}^2(\mathds{X}_{\boldsymbol{L}_i})$. If $\boldsymbol{L}_i\in\mathcal{W}$, then the spectrum of $\mathscr{L}_{[\mathds{K}_i,\mathds{L}_{\boldsymbol{L}_i},\mathcal{S}_i]}$ lies in $\mathbb{C}^{-}$.
\end{lemma}

\bproof
By using the operator $\mathscr{L}_{[\mathds{K}_i,\mathds{L}_{\boldsymbol{L}_i},\mathcal{S}_i]}$ and completing the squares, we can rewrite equations (\ref{are_operator1}) and \eqref{general:oueter-loop1} as  
\begin{equation}\label{eq:lem1_xi}
\begin{aligned}
\mathscr{L}_{[\mathds{K}_i,\mathds{L}_{\boldsymbol{L}_i},\mathcal{S}_i]}(\mathds{X}_i)\!+\!\|\mathds{L}_i-\mathds{L}_{\boldsymbol{L}_i}\|_{\mathds{W}}^2+\boldsymbol{Q}_i=0,
\end{aligned}
\end{equation}
and 
\begin{equation}\label{eq:lem1_xik}
\begin{aligned}
\!\!\!\!\!\mathscr{L}_{[\mathds{K}_i,\mathds{L}_{\boldsymbol{L}_i},\mathcal{S}_i]}(\mathds{X}_{\boldsymbol{L}_i})\!-\!\|\mathds{L}_{\boldsymbol{L}_i}\!-\!\boldsymbol{L}_i\|_{\mathds{W}}^2\!-\!\|\mathds{K}_i\!-\!\mathds{K}_{\boldsymbol{L}_i}\|_{\!\boldsymbol{R}_{i}}^2\!+\!\boldsymbol{Q}_i\!=\!0,
\end{aligned}
\end{equation}
respectively. Here, $\boldsymbol{R}_{i}=\mathds{R}+\mathds{D}_i^{\mathrm{T}}\mathds{X}_{\boldsymbol{L}_i}\mathds{D}_i$ and $\boldsymbol{Q}_i=\mathds{Q}-\|\mathds{L}_{\boldsymbol{L}_i}\|_{\mathds{W}}^2+\|\mathds{K}_i\|_{\mathds{R}}^2$.

Subtracting equation \eqref{eq:lem1_xik} from equation \eqref{eq:lem1_xi} yields
\begin{equation}\label{eq:lem1_Deltaxik}
\begin{aligned}
\mathscr{L}_{[\mathds{K}_i,\mathds{L}_{\boldsymbol{L}_i},\mathcal{S}_i]}(\mathds{X}_i-\mathds{X}_{\boldsymbol{L}_i})+\tilde{\boldsymbol{H}_i}^{\mathrm{T}}\tilde{\boldsymbol{H}_i}=0,
\end{aligned}
\end{equation}
where $\tilde{\boldsymbol{H}_i}=[\tilde{\boldsymbol{H}}_i^1,\tilde{\boldsymbol{H}}_i^2,\tilde{\boldsymbol{H}}_i^3]^{\mathrm{T}}$, $\tilde{\boldsymbol{H}}_i^1=(\mathds{L}_i-\mathds{L}_{\boldsymbol{L}_i})^{\!\mathrm{T}}\mathds{W}^{\frac{1}{2}}$, $\tilde{\boldsymbol{H}}_i^2=(\mathds{L}_{\boldsymbol{L}_i}-\boldsymbol{L}_i)^{\!\mathrm{T}}\mathds{W}^{\frac{1}{2}}$, and $\tilde{\boldsymbol{H}}_i^3=(\mathds{K}_i-\mathds{K}_{\boldsymbol{L}_i})^{\!\mathrm{T}}\!\boldsymbol{R}_{i}^{\frac{1}{2}}$.

Define $\tilde{\boldsymbol{A}_i}\triangleq\mathds{A}-\mathds{B}\mathds{K}_i+\mathds{G}\mathds{L}_{\boldsymbol{L}_i}$ and $\tilde{\mathds{C}}_i\triangleq\mathds{C}_i-\mathds{D}_i\mathds{K}_i$. By selecting $\tilde{K} = [-\mathds{G}\mathds{W}^{-\frac{1}{2}},0,0]^{\mathrm{T}}$, one has
\begin{equation*}
\begin{aligned}
\left(\tilde{\boldsymbol{A}_i}^{\!\!\mathrm{T}}\!\!\!-\!\!\tilde{\boldsymbol{H}_i}^{\!\!\mathrm{T}}\!\tilde{K}\right)^{\!\!\mathrm{T}}\!\!\!X\!\!+\!\!X\left(\tilde{\boldsymbol{A}_i}^{\!\!\mathrm{T}}\!\!-\!\!\tilde{\boldsymbol{H}_i}^{\!\!\mathrm{T}}\!\tilde{K}\right)\!\!+\!\tilde{\mathds{C}}_iX\tilde{\mathds{C}}_i^{\!\mathrm{T}}\!=\mathscr{L}_{[\mathds{K}_i,\mathds{L}_i,\mathcal{S}_i]}^*(X),
\end{aligned}
\end{equation*}
Since $\sigma(\mathscr{L}_{[\mathds{K}_i,\mathds{L}_i,\mathcal{S}_i]})\!\subset\!\mathbb{C}^-$, it follows that $[\tilde{\boldsymbol{A}_i},\!\tilde{\boldsymbol{H}_i}|\tilde{\mathds{C}}_i]$ is detectable. Furthermore, by using $\mathds{X}_{\boldsymbol{L}_i}\!\leq \!\mathds{X}_i$ and Proposition \ref{propo:detectable_necessary}, we conclude that $\sigma(\mathscr{L}_{[\mathds{K}_i,\mathds{L}_{\boldsymbol{L}_i},\mathcal{S}_i]})\subset\mathbb{C}^-$.
\eproof
 
To approximate $\mathds{X}_i$, we design an iterative process based on equation \eqref{general:oueter-loop}. In the $k$-th iteration, $\boldsymbol{L}_i$ is replaced by the approximation from the previous iteration $\mathds{L}_i^{k-1}$, leading to the following equation
\begin{subequations}{}\label{outer_eq}
\begin{empheq}[left={\left\{\begin{aligned}},right={\end{aligned}\right.}]{align}
&{\mathscr{L}}_{[\mathds{K}_i^{k},\mathds{L}_i^{k-1},\mathcal{S}_i]}(\mathds{X}_i^{k}) \!+\! \mathds{Q}\!-\!\|\mathds{L}_i^{k-1}\|_{\mathds{W}}^{2}\!+\!\|{\mathds{K}_i^{k}}\|_{\mathds{R}}^2\!=\!0,\label{outer_eq:xik+1}\\
&\mathds{K}_i^{k}=\mathscr{K}_{\mathcal{U}_i}^1(\mathds{X}_i^{k}),\label{outer_eq:kik+1}
\end{empheq}
\end{subequations}
and $\mathds{L}_i^{k}$ is solved by
\begin{equation}\label{outer_eq2}
~~\mathds{L}_i^{k}=\mathscr{K}_{\mathcal{V}}^2(\mathds{X}_i^{k}),~~k=1,2,\cdots.
\end{equation}

\begin{figure}[!htb]
\centering
\includegraphics[scale=0.37]{digram8_3_1}
\centering
\caption{Schematic diagram of the outer-loop iteration.}\label{f:diag2}
\end{figure}

As illustrated in Fig. \ref{f:diag2}, the iterative scheme introduces a new closed-loop structure with a one-step delay compared to equation \eqref{general:oueter-loop}. Specifically, $\mathds{X}_i^k$ is updated using $\mathds{L}_i^{k-1}$, and then $\mathds{L}_i^{k}$ is updated using $\mathds{X}_i^{k}$. This update mechanism generates stepwise sequences for both $\mathds{X}_i$ and $\mathds{L}_i$. The following properties hold for this procedure.
% For notational simplicity, denote $\mathds{Q}_i^k \!\triangleq\! \mathds{Q}\!-\!\|\mathds{L}_i^k\|_{\mathds{W}}^2$, $\mathds{R}_i^k \!\triangleq\!\mathds{R}\!+\!\mathds{D}_i^{\mathrm{T}}\mathds{X}_i^k\mathds{D}_i$. 
\begin{lemma}\label{lemma:W}
If $\mathds{L}_i^{k-1}\in\mathcal{W}$, then $\mathds{L}_i^k\in\mathcal{W}$, that is $0\leq\mathds{X}_i^{k+1}\leq\mathds{X}_i$ and $\sigma(\mathscr{L}_{[\mathds{K}_i^{k+1},\mathds{L}_i^k,\mathcal{S}_i]})\subset\mathbb{C}^-$. Moreover, we have $\mathds{X}_i^{k}\leq\mathds{X}_i^{k+1}$.
\end{lemma}

\bproof
At iteration $k+1$, equation (\ref{outer_eq:xik+1}) can be expressed as
\begin{equation*}
\begin{aligned}
{\mathscr{L}}_{[\mathds{K}_i^{k+1},\mathds{L}_i^{k},\mathcal{S}_i]}(\mathds{X}_i^{k+1}) + \mathds{Q}_i^{k} \!+\! \|{\mathds{K}_i^{k+1}}\|_{\mathds{R}}^2=0,
\end{aligned}
\end{equation*}
where $\mathds{Q}_i^k = \mathds{Q}\!-\!\|\mathds{L}_i^k\|_{\mathds{W}}^2$. By utilizing the operator $\mathscr{L}_{[\mathds{K}_i^{k},\mathds{L}_i^{k},\mathcal{S}_i]}$ and completing the squares, we rewrite the above equation as 
\begin{equation}\label{th1eq4}
\begin{aligned}
{\mathscr{L}}_{[\mathds{K}_i^{k},\mathds{L}_i^{k},\mathcal{S}_i]}(\mathds{X}_i^{k+1}) +\mathds{Q}_i^{k}-\|{\tilde{\mathds{K}}_i^{k}}\|^{2}_{\mathds{R}_i^{k+1}} +\|\mathds{K}_i^{k}\|_{\mathds{R}}^2=0,
\end{aligned}
\end{equation}
where $\tilde{\mathds{K}}_i^k=\mathds{K}_i^{k+1}-\mathds{K}_i^k$ and $\mathds{R}_i^{k+1} =\mathds{R}\!+\!\mathds{D}_i^{\mathrm{T}}\mathds{X}_i^{k+1}\mathds{D}_i$.

Similarly, by using $\mathscr{L}_{[\mathds{K}_i^{k},\mathds{L}_i^{k},\mathcal{S}_i]}$, equation (\ref{outer_eq:xik+1}) becomes
\begin{equation}\label{th1eq5}
\begin{aligned}
{\mathscr{L}}_{[\mathds{K}_i^{k},\mathds{L}_i^{k},\mathcal{S}_i]}(\mathds{X}_i^{k}) + \mathds{Q}_i^{k} -\|\tilde{\mathds{L}}_i^{k-1}\|_{\mathds{W}}^2+\|\mathds{K}_i^{k}\|_{\mathds{R}}^2=0,
\end{aligned}
\end{equation}
where $\tilde{\mathds{L}}_i^{k-1} =\mathds{L}_i^{k}-\mathds{L}_i^{k-1}$.

Subtracting equation (\ref{th1eq5}) from equation (\ref{th1eq4}) yields
\begin{equation}\label{th1eq6}
\begin{aligned}
&{\mathscr{L}}_{[\mathds{K}_i^{k},\mathds{L}_i^{k},\mathcal{S}_i]}(\tilde{\mathds{X}}_i^{k})+\|\tilde{\mathds{L}}_i^{k-1}\|_{\mathds{W}}^2-\|\tilde{\mathds{K}}_i^{k}\|^2_{\mathds{R}_i^{k+1}}=0,
\end{aligned}
\end{equation} 
where $\tilde{\mathds{X}}_i^k = \mathds{X}_i^{k+1}-\mathds{X}_i^k$.

Letting $\mathds{C}_i^k \triangleq \mathds{C}_i-\mathds{D}_i\mathds{K}_i^k$ and  $\mathcal{U}_i^k\triangleq\{\mathds{R}_i^k,\mathds{B},\mathds{C}_i^k,\mathds{D}_i\}$, we can derive an identity for $\tilde{\mathds{K}}_i^k$ as follows
\begin{align}
\tilde{\mathds{K}}_i^{k} =\mathscr{K}_{\mathcal{U}_i^{k}}^1(\tilde{\mathds{X}}_i^{k}).\label{ktilde}
\end{align}
% Based on this equation and using the definition $\mathds{C}_i^k=\mathds{C}_i-\mathds{D}_i\mathds{K}_i^k$, we can derive
% \begin{equation}
% \begin{aligned}
% \tilde{\mathds{K}}_i^k=(\mathds{R}_i^{k+1})^{-1}(\mathds{B}\tilde{\mathds{X}}_i^{k}+\mathds{D}_i^{\mathrm{T}}\tilde{\mathds{X}}_i^{k}\mathds{C}_i^k).
% \end{aligned}
% \end{equation}
Using the expression for $\tilde{\mathds{K}}_i^k$ from equation (\ref{ktilde}), we then rewrite $\mathscr{L}_{[\mathds{K}_i^k,\mathds{L}_i^k,\mathcal{S}_i]}(\tilde{\mathds{X}}_i^k)$ as 
\begin{equation}
\begin{aligned}
\!\!\!\!\!\mathscr{L}_{[\mathds{K}_i^{k},\mathds{L}_i^{k},\mathcal{S}_i]}(\tilde{\mathds{X}}_i^{k})\!\!=\!\!\mathscr{L}_{[\tilde{\mathds{K}}_i^{k},0,\mathcal{S}_i^{k}]}(\tilde{\mathds{X}}_i^{k})\!\!+\!\!\|\tilde{\mathds{K}}_i^{k}\|_{\mathds{R}_i^{k+1}}^2\!\!+\!\!\|\tilde{\mathds{K}}_i^{k}\|_{\mathds{R}_i^{k}}^2,
\end{aligned} 
\end{equation}
where $\mathcal{S}_i^k = [\mathds{A}_i^k,\mathds{B},0|\mathds{C}_i^k,\mathds{D}_i]$ and $\mathds{A}_i^k = \mathds{A}-\mathds{B}\mathds{K}_i^k+\mathds{G}\mathds{L}_i^k$.


Using the above identities, equation (\ref{th1eq6}) can be transformed into a standard $H_2$-type (S)ARE for $\tilde{\mathds{X}}_i^k$ 
\begin{equation}\label{th1eq7}
% \begin{empheq}[left={\left\{\begin{aligned}},right={\end{aligned}\right.}]{align}
\mathscr{L}_{[\tilde{\mathds{K}}_i^{k},0,\mathcal{S}_i^{k}]}(\tilde{\mathds{X}}_i^{k})\!+\!\|\tilde{\mathds{L}}_i^{k-1}\|_{\mathds{W}}^2\!+\!\|\tilde{K}_{i}^{k}\|_{\mathds{R}_i^{k}}^2 \!=\! 0,
% \end{empheq}
\end{equation}
where $\mathcal{S}_i^k = [\mathds{A}_i^k,\mathds{B},0|\mathds{C}_i^k,\mathds{D}_i]$ and $\mathcal{U}_i^k = \{\mathds{R}_i^k,\mathds{B},\mathds{C}_i^k,\mathds{D}_i\}$.

Next, we will verify the following conditions hold.
\begin{enumerate}
	\item[(${\bf\mathrm{\alpha_1}}$)] $\mathcal{S}_i^{k}$ is stabilizable;
	\item[(${\bf\mathrm{\beta_1}}$)] $\mathcal{O}_i^{k}\triangleq[\mathds{A}_i^{k},\mathds{H}_i^{k}|\mathds{C}_i^{k}]$ is detectable, where $\mathds{H}_i^k  \!= \!\mathds{W}^{\frac{1}{2}}\tilde{\mathds{L}}_{i}^{k-1}$.  
\end{enumerate}


{\bf Verification of (${\bf\mathrm{\alpha_1}}$)}:  Starting with $K=\mathds{K}_i-\mathds{K}_{i}^{k}$, we have 
\begin{equation*}
\begin{aligned}
&\mathscr{L}_{[K,0,\mathcal{S}_i^{k}]}(X)=\mathscr{L}_{[\mathds{K}_i,\mathds{L}_i^{k},\mathcal{S}_i]}(X).
\end{aligned}
\end{equation*}
Since $\mathds{L}_{i}^{k-1}\!\!\in\!\!\mathcal{W}$, it follows from Lemma \ref{lem:used in Theorem1} that $\sigma(\mathscr{L}_{[\mathds{K}_i,\mathds{L}_i^{k},\mathcal{S}_i]}\!\subset\!\mathbb{C}^-$. Therefore, by Proposition \ref{propo:stabilization}$, \mathcal{S}_i^{k}$ is stabilizable.



{\bf Verification of (${\bf\mathrm{\beta_1}}$)}: Let $\widetilde{K} = (\mathds{G}\mathds{W}^{-\frac{1}{2}})^{\mathrm{T}}$, we have 
\begin{equation*}
\begin{aligned}
((\mathds{A}_i^{k})^{\mathrm{T}}-(\mathds{H}_i^{k-1})^{\mathrm{T}}\widetilde{K})^{\mathrm{T}}X+X((\mathds{A}_i^{k})^{\mathrm{T}}-(\mathds{H}_i^{k-1})^{\mathrm{T}}\widetilde{K})+\mathds{C}_i^{k}X(\mathds{C}_i^{k})^{\mathrm{T}}=\mathscr{L}_{[\mathds{K}_i^{k},\mathds{L}_i^{k-1},\mathcal{S}_i]}^*(X)\subset\mathbb{C}^-,
\end{aligned}
\end{equation*}
which confirms that $\mathcal{O}_i^k$ is detectable.

Since $\mathcal{S}_i^k$ is stabilizable and $\mathcal{O}_i^k$ is detectable, according to \cite[Theorem 4.1]{zhang2008generalized} and \cite[Theorem 3]{kucera1972contribution}, there exists a unique stabilizing solution $\tilde{\mathds{X}}_i^{k}\geq0$ to equation (\ref{th1eq7}). This implies $\mathds{X}_i^{k+1}\geq\mathds{X}_i^{k}\geq0$ and the spectrum $\sigma(\mathscr{L}_{[\mathds{K}_i^{k+1},\mathds{L}_i^{k},\mathcal{S}_i]})\subset \mathbb{C}^{-}$.


 
To establish the upper bound $\mathds{X}_i^{k+1}\leq\mathds{X}_i$. we consider equations (\ref{are_operator1}) and (\ref{th1eq4}). By applying these equations, it gives
\begin{equation*} 
\begin{aligned}
\mathscr{L}_{[\mathds{K}_i,\mathds{L}_i^{k},\mathcal{S}_i]}(\Delta\mathds{X}_i^{k+1}) +\|\Delta\mathds{L}_i^{k}\|_{\mathds{W}}^2+\|\Delta\mathds{K}_i^{k+1}\|_{\mathds{R}_i^{k}}^2=0,
\end{aligned}
\end{equation*} 
where $\Delta \mathds{X}_i^{k+1}= \mathds{X}_i-\mathds{X}_i^{k+1}$, $\Delta\mathds{L}_i^k=\mathds{L}_i-\mathds{L}_i^k$, and $\Delta\mathds{K}_i^{k+1}=\mathds{K}_i-\mathds{K}_i^{k+1}$.

By Lemma \ref{lem:used in Theorem1}, $\mathds{L}_i^{k-1}\in\mathcal{W}$ implies $\sigma(\mathscr{L}_{[\mathds{K}_i,\mathds{L}_i^{k},\mathcal{S}_i]})\subset\mathbb{C}^-$. Combing with the facts $\mathds{W},\mathds{R}_i^{k}>0$, it follows from \cite[Theorem 3.2.3]{sun2020stochastic} that $\Delta \mathds{X}_i^{k+1}\geq0$, {\sl i.e., $\mathds{X}_i^{k+1}\leq\mathds{X}_i$}.  
\eproof

 To initiate the iterative procedure, an admissible gain matrix $\mathds{L}_i^0\in\mathcal{W}$ is given in the following result.  
\begin{assume}\label{assume:3-1}
The system $\mathcal{S}_i$ is stabilizable when $\mathds{G}=0$ and $\mathcal{O}_i\triangleq[\mathds{A},\mathds{Q}^{\frac{1}{2}}|\mathds{C}_i]$ is detectable.
\end{assume}
% These conditions are standard in control theory...
\begin{lemma}\label{lem:ouer_loop_k=1}
Let $\mathds{X}_i^{0}=0$ and $\mathds{L}_i^0 \!=\! \mathscr{K}_{\mathcal{V}}^2(\mathds{X}_i^0)$. If Assumption \ref{assume:3-1} holds, then $\mathds{L}_i^0\in\mathcal{W}$.
\end{lemma}

\bproof
Since $\mathds{X}_i^0=0$ gives $\mathds{L}_i^0=0$. Equation (\ref{outer_eq}) at $k=1$ can be reduced to 
\begin{subequations}\label{th1eq1}
\begin{empheq}[left={\left\{\begin{aligned}},right={\end{aligned}\right.}]{align}
&\mathscr{L}_{[\mathds{K}_i^1,0,\mathcal{S}_i]}(\mathds{X}_i^1)+\mathds{Q}+\|\mathds{K}_i^1\|_{\mathds{R}}^2=0,\\
&\mathds{K}_i^{1}=\mathscr{K}_{\mathcal{U}_i}^1(\mathds{X}_i^1).
\end{empheq}
\end{subequations}
Under Assumption \ref{assume:3-1}, it gives that equation \eqref{th1eq1} has a unique stabilizing solution $\mathds{X}_i^1\geq 0$ such that $\sigma(\mathscr{L}_{[\mathds{K}_i^1,0,\mathcal{S}_i]})\subset\mathbb{C}^{-}$.  

We rewrite equation (\ref{are_operator}) as 
\begin{equation}\label{th1eq1-3}
\begin{aligned}
&\mathscr{L}_{[\mathds{K}_i,0,\mathcal{S}_i]}(\mathds{X}_i)\!+\tilde{\mathds{H}}_i^{\mathrm{T}}\tilde{\mathds{H}}_i=\!0,
\end{aligned}
\end{equation}
where $\tilde{\mathds{H}}_i = [
\mathds{Q}^{\frac{1}{2}},\mathds{L}_i^{\mathrm{T}}\mathds{W}^{\frac{1}{2}},\mathds{K}_i^{\mathrm{T}}\mathds{R}^{\frac{1}{2}}]^{\mathrm{T}}$.
The detectability of $[{\mathds{A}}_i-\mathds{B}\mathds{K}_i,\tilde{\mathds{H}}_i|\tilde{\mathds{C}}_i]$ can be confirmed by choosing $\tilde{K}=[0,0,-\mathds{G}\mathds{W}^{-\frac{1}{2}}]^{\mathrm{T}}$. By using Proposition \ref{propo:detectable_necessary} and $\mathds{X}_i\geq0$, we have that $\mathscr{L}_{[\mathds{K}_i,0,\mathcal{S}_i]}\subset\mathbb{C}^-$.
  
Subtracting equation (\ref{th1eq1}) from equation (\ref{are_operator}) yields 
\begin{equation}\label{th1eq2}
\begin{aligned}
\mathscr{L}_{[\mathds{K}_i,0,\mathcal{S}_i]}(\Delta\mathds{X}_i^1)+ \|\mathds{L}_i\|_{\mathds{W}}^2+\|\Delta\mathds{K}_i^1\|^2_{\mathds{R}_i^1}=0.
\end{aligned}
\end{equation}
Since $\sigma(\mathscr{L}_{[\mathds{K}_i,0,\mathcal{S}_i]})\subset\mathbb{C}^-$ and $\mathds{W},\mathds{R}_i^1>0$, we have that $\Delta\mathds{X}_i^1\geq0$, {\sl i.e, $\mathds{X}_i^1\leq\mathds{X}_i$.} Hence, $\mathds{L}_i^0\in\mathcal{W}$.
\eproof

% The above lemmas confirm that starting from $\mathds{L}_i^{0}=0$, the sequence $\{\mathds{L}_i^k\}_{k=0}^{\infty}$ remains within $\mathcal{W}$. Additionally, the sequence $\{\mathds{X}_i^k\}_{k=0}^{\infty}$ is monotonically non-decreasing and bounded above by $\mathds{X}_i$. The convergence result of the outer-loop iteration is concluded in Theorem \ref{thm:convergence-outer-loop}

% The entire outer-loop iteration can be visualized as shown in Fig. \ref{f:diag1}, where..., and 
% \begin{figure}[!htb]
% \centering
% \includegraphics[scale=0.35]{digram6}
% \centering
% \caption{Structure of the outer-loop iteration.}\label{f:diag1}
% \end{figure}

 \begin{theorem}\label{thm:convergence-outer-loop}
Let the sequences $\{\mathds{X}_{i}^k\}_{k=1}^{\infty}$, $\{\mathds{L}_i^{k}\}_{k=1}^{\infty}$, and $\{\mathds{K}_i^{k}\}_{k=1}^{\infty}$ be generated by recursively solving (\ref{outer_eq}) and (\ref{outer_eq2}) with the initial condition $\mathds{L}_i^0=0$. If Assumption \ref{assume:3-1} holds, then $\lim\limits_{k\rightarrow\infty}\mathds{X}_i^{k}=\mathds{X}_i$, $\lim\limits_{k\rightarrow\infty}\mathds{L}_i^{k}=\mathds{L}_i$, and $\lim\limits_{k\rightarrow\infty}\mathds{K}_i^{k}=\mathds{K}_i$.
\end{theorem}

\bproof
From Lemmas \ref{lemma:W} and \ref{lem:ouer_loop_k=1}, we have established that the sequence $\{\mathds{X}_i^k\}_1^{\infty}$ is monotonically increasing and bounded above by $\mathds{X}_i$. Since $\mathds{X}_i$ satisfies equation (\ref{outer_eq}), taking the limit as $k\rightarrow\infty$ yields $\lim_{k\rightarrow\infty}\mathds{X}_{i}^{k} = \mathds{X}_i$. Consequently, we also have $\lim_{k\rightarrow\infty}\mathds{L}_i^{k} =\mathds{L}_i$ by equation (\ref{outer_eq2}) and $\lim_{k\rightarrow\infty}\mathds{K}_i^{k} =\mathds{K}_i$ by equation (\ref{outer_eq:kik+1}), completing the proof.
\eproof

\begin{remark}
The stabilizability and detectability conditions in Assumption \ref{assume:3-1} are standard in optimal control theory (see \cite{zhang2008generalized,kucera1972contribution}) and are commonly used in MFSC problems (see \cite{wang2020indefinite,wang2020social}). Under these conditions, Theorem \ref{thm:convergence-outer-loop} ensures the convergence result of the outer-loop iteration for both deterministic and the stochastic cases. 

Notably, when $i\!=\!0$, the proposed iterative method is equivalent to the one in \cite{lanzon2008computing}. However, for $i\!=\!1$, our iterative equations fundamentally differ from those proposed in \cite{dragan2011computation} and cannot be transformed into their framework. Specifically, in \cite{dragan2011computation}, the control gain $\mathds{K}_i^k$ is updated as
\begin{equation*}
\mathds{K}_i^k = (I+(\mathds{R}_i^k)^{-1}\mathds{D}_i^{\mathrm{T}}\mathds{X}_i^k\mathds{D}_i)^{-1}(\mathds{R}_i^{k})^{-1}(\mathds{B}^{\mathrm{T}}\mathds{X}_i^k+\mathds{D}_i^{\mathrm{T}}\mathds{X}_i^k\mathds{C}_i),
\end{equation*}
which is distinctly different from our proposed update mechanism (\ref{outer_eq:kik+1}).
\end{remark}
%   \begin{figure}[!htb]
% \centering
% \includegraphics[scale=0.34]{digram8_2}
% \centering
% \caption{Schematic Diagrams of the Iterative Procedures: (left) Outer-loop iteration; (right) Inner-loop iteration.}\label{f:diag2}
% \end{figure}
 \vspace{-0.3cm}
\subsection{Introduction of inner-loop iteration}
\begin{figure}[!htb]
\centering
\includegraphics[scale=0.36]{digram8_4}
\centering
\caption{Schematic diagram of the inner-loop iteration.}\label{f:diag2-2}
\end{figure}
To effectively solve the stabilizing solution $\mathds{X}_i^k$ of equation (\ref{outer_eq}), we introduce an inner-loop iteration based on equation (\ref{general:inner-loop}), as illustrated in Fig. \ref{f:diag2-2}. During the $(k,j)$-th inner-loop iteration, $\boldsymbol{L}_i$ is replaced by $\mathds{L}_i^{k-1}$ from the previous outer loop, while $\boldsymbol{K}_i$ is replaced by the approximation from the previous inner-loop step. As a result, the $j$-th approximation of $\mathds{X}_i^{k}$ can be obtained by solving the following Lyapunov equation
\begin{equation}\label{inner_PE}
\!\!\mathscr{L}_{[\mathds{K}_i^{(k,j-1)},\mathds{L}_i^{k-1},\mathcal{S}_i]}(\mathds{X}_i^{(k,j)})\!+\mathds{Q}_i^{k-1}+\!\|{\mathds{K}_i^{(k,j-1)}}\|_{\mathds{R}}^{2}=0. 
\end{equation}
Subsequently, $\mathds{K}_i^{(k,j)}$ is updated by using
\begin{equation}\label{inner_PI}
\mathds{K}_i^{(k,j)}=\mathscr{K}_{\mathcal{U}_i}^1(\mathds{X}_i^{(k,j)}), ~~j=1,2,\cdots.
\end{equation}
\begin{remark}
The inner-loop iteration described above is known as the PI algorithm. This algorithm was originally introduced in \cite{kleinman1968iterative} for deterministic systems and later extended to stochastic systems with multiplicative noise in \cite{li2022stochastic}. Traditional convergence analyses of the PI algorithms rely on the assumption that the state weighting matrix is positive (semi-)definite. However, in our context, when $k>1$, the updates of $ \mathds{L}_i^{k}$ may cause $\mathds{Q}_i^{k}=\mathds{Q}-\|\mathds{L}_i^{k}\|_{\mathds{W}}^2$ to be indefinite. Thus, the sufficient conditions for the existing convergence results are no longer applicable. To address this issue, we establish a new convergence result of the PI algorithm that remains valid even when the state weighting matrix is indefinite.
\end{remark}

For notational simplicity, denote $\mathds{R}_i^{(k,j)}\!\triangleq\!\mathds{R}\!+\!\mathds{D}_i^{\mathrm{T}}\mathds{X}_i^{(k,j)}\mathds{D}_i$, $\mathds{A}_i^{(k,j)}\!\triangleq\!\mathds{A}\!-\!\mathds{B}\mathds{K}_i^{(k,j)}\!+\!\mathds{G}\mathds{L}_i^{k-1}$, $\mathds{C}_i^{(k,j)}\!\triangleq\!\mathds{C}_i\!-\!\mathds{D}_i\mathds{K}_i^{(k,j)}$, $\Delta\mathds{X}_i^{(k,j)}\!\triangleq\!\mathds{X}_i^{(k,j)}\!-\!\mathds{X}_i^k$, $\Delta\mathds{K}_i^{(k,j)}\!\triangleq\!\mathds{K}_i^{(k,j)}\!-\!\mathds{K}_i^{k}$, $\tilde{X}_i^{(k,j)}\!\triangleq\!\mathds{X}_i^{(k,j)}\!-\!\mathds{X}_i^{k(k,j+1)}$, and $\tilde{K}_i^{(k,j)}\!\triangleq\!\mathds{K}_i^{(k,j)}\!-\!\mathds{K}_i^{k(k,j+1)}$. 

Define the admissible set of $\boldsymbol{K}_i$ for a given $\boldsymbol{L}_i\in\mathcal{W}$ as
\begin{equation*}
\begin{aligned}
\mathcal{Z}(\boldsymbol{L}_i)\!\triangleq\! \{&\boldsymbol{K}_i\!\in\!\mathbb{R}^{m_1\times n}|\sigma(\mathscr{L}_{[\boldsymbol{K}_i,\boldsymbol{L}_i,\mathcal{S}_i]})\subset\mathbb{C}^{-}\}.
\end{aligned}
\end{equation*}
\begin{theorem}\label{thm:convregence-inner-loop}
 Suppose there exists a $\mathds{K}_i^{(k,0)}\in\mathcal{Z}(\mathds{L}_i^{k-1})$. Let the sequences $\{\mathds{X}_i^{(k,j)}\}_{j=1}^{\infty}$ and $\{\mathds{K}_i^{(k,j)}\}_{j=1}^{\infty}$ be generated by iteratively solving equations (\ref{inner_PE}) and (\ref{inner_PI}). If the conditions of Theorem \ref{thm:convergence-outer-loop} are satisfied, then for any $k\in\mathbb{N}_+$, the following properties hold for all $j\in\mathbb{N}_+:$
 \begin{enumerate}
 	\item $\mathds{X}_i^{(k,j)}\geq \mathds{X}_i^{(k,j+1)}\geq \mathds{X}_i^{k}$;
 	\item $\mathds{K}_i^{(k,j-1)}\in\mathcal{Z}(\mathds{L}_i^{k-1})$;
 	\item $\lim_{j\rightarrow\infty}\mathds{X}_i^{(k,j)}=\mathds{X}_i^{k}$ and $\lim_{j\rightarrow\infty}\mathds{K}_i^{(k,j)}=\mathds{K}_i^{k}$.
 \end{enumerate}
\end{theorem}

\bproof
We will prove property 2) and the inequality $\mathds{X}_i^{(k,j)}\!\geq\!\mathds{X}_i^{k}$ for all $j\!\geq\!1$ by induction on $j$, and subsequently establish the monotonic decreasing property of the sequence $\{\mathds{X}_i^{(k,j)}\}_{j=1}^{\infty}$.

Assume that for some $q\geq1$, property 2) holds for $j=q$, we will show that the inequality $\mathds{X}_i^{(k,q+1)}\geq \mathds{X}_i^{k}$ holds, and property 2) also holds for $j=q+1$.

 
At iteration $j=q$, equation (\ref{inner_PE}) becomes
\begin{equation}\label{th2eq2}
\begin{aligned}
\mathscr{L}_{[\mathds{K}_i^{(k,q-1)},\mathds{L}_i^{k-1},\mathcal{S}_i]}(\mathds{X}_i^{(k,q)})+\mathcal{Q}_i^{(k,q)}=0.
\end{aligned}
\end{equation}
where $\mathcal{Q}_i^{(k,q)}=\mathds{Q}_i^{k-1}+\|\mathds{K}_{i}^{(k,q-1)}\|_{\mathds{R}}^{2}$.

Recalling equation (\ref{outer_eq:xik+1}), we can rewrite it as
\begin{equation}\label{th2eq1}
\begin{aligned}
\mathscr{L}_{[\mathds{K}_i^{(k,q-1)},\mathds{L}_i^{k-1},\mathcal{S}_i]}(\mathds{X}_i^k)
\!-\!\|\Delta\mathds{K}_i^{(k,q-1)}\|_{\mathds{R}_i^k}^2\!+\!\mathcal{Q}_i^{(k,q)}\!=\!0,
\end{aligned}
\end{equation}


Subtracting (\ref{th2eq1}) from (\ref{th2eq2}) yields
\begin{equation}\label{mathscrL}
\begin{aligned}
\mathscr{L}_{[\mathds{K}_i^{(k,q-1)},\mathds{L}_i^{k-1},\mathcal{S}_i]}(\Delta\mathds{X}_i^{(k,q)})+\|\Delta\mathds{K}_i^{(k,q-1)}\|_{\mathds{R}_i^k}^2\!=\!0,
\end{aligned}
\end{equation}
which implies that $\Delta\mathds{X}_i^{(k,q)}\geq 0$ by using $\mathds{R}_i^k>0$ and the induction assumption $\mathds{K}_i^{(k,q-1)}\in\mathcal{Z}(\mathds{L}_i^{k-1})$. 

We can transform the above equation into  
\begin{equation}
\begin{aligned}
  \mathscr{L}_{[\mathds{K}_i^{(k,q)},\mathds{L}_i^{k-1},\mathcal{S}_i]}(\Delta\mathds{X}_i^{(k,q)})+\left(\mathds{H}_i^{(k,q)}\right)^{2}=0,
\end{aligned}
\end{equation}
where $\mathds{H}_i^{(k,q)}\! =\!\sqrt{\|\Delta\mathds{K}_i^{(k,q)}\|_{\mathds{R}^k_i}^2\!+\!\|\tilde{\mathds{K}}_i^{(k,q)}\|_{\mathds{R}_i^{(k,q)}}^2}$ is positive semidefinite.

To show $\mathds{K}_i^{(k,q)}\!\in\!\mathcal{Z}(\mathds{L}_i^{k-1})$, it suffices to demonstrate that $\mathcal{O}_i^{(k,q)}\!\triangleq\![\mathds{A}_i^{(k,q)},\mathds{H}_i^{(k,q)}|\mathds{C}_i^{(k,q)}]$ is detectable. Suppose, for contradiction, that is not detectable. Then, by Proposition \ref{propo:detectable_sufficient}, there exists a nonzero symmetric matrix $X$ such that 
\begin{equation}
\left\{\begin{aligned}
&\mathscr{L}_{[\mathds{K}_{i}^{(k,q)},\mathds{L}_{i}^{k-1},\mathcal{S}_i]}(X)=\lambda X,~Re(\lambda)\geq0,\\
&\mathds{H}_{i}^{(k,q)}X=0.
\end{aligned}\right.
\end{equation} 
Since $\mathds{R}_{i}^{k},\mathds{R}_{i}^{(k,q)}>0$, the condition $\mathds{H}_i^{(k,q)}X=0$ implies $\mathds{K}_{i}^{(k,q)}X=\mathds{K}_i^{(k,q-1)}X$. This leads to
\begin{equation*}
\begin{aligned}
&\mathscr{L}_{[\mathds{K}_{i}^{(k,q)},\mathds{L}_{i}^{k-1},\mathcal{S}_i]}(X)\\
=&\mathscr{L}_{[\mathds{K}_{i}^{(k,q-1)},\mathds{L}_i^{k-1},\mathcal{S}_{i}]}(X)=\lambda X,~Re(\lambda)\geq0,
\end{aligned}
\end{equation*}
which contradicts the fact $\sigma(\mathscr{L}_{[\mathds{K}_{i}^{(k,q-1)},\mathds{L}_i^{k-1},\mathcal{S}_{i}]})\!\subset\!\mathbb{C}^-$. Therefore, $\mathcal{O}_i^{(k,q)}$ is detectable. It follows from $\Delta\mathds{X}_{i}^{(k,q)}\!\geq\!0$ and Proposition \ref{propo:detectable_necessary} that $\sigma(\mathscr{L}_{[\mathds{K}_{i}^{(k,q)},\mathds{L}_{i}^{k-1},\mathcal{S}_i]})\subset\mathbb{C}^-$, thereby $\mathds{K}_i^{(k,q)}\in\mathcal{Z}(\mathds{L}_i^{k-1})$.

Substituting $q$ with $q+1$ in equation (\ref{mathscrL}) yields
\begin{equation*} 
\begin{aligned}
\mathscr{L}_{[\mathds{K}_i^{(k,q)},\mathds{L}_i^{k-1},\mathcal{S}_i]}(\Delta\mathds{X}_i^{(k,q+1)})+\|\Delta\mathds{K}_i^{(k,q)}\|_{\mathds{R}_i^k}^2\!=\!0,
\end{aligned}
\end{equation*}
which implies that $\Delta\mathds{X}_i^{(k,q+1)}\geq0$, {\sl i.e., $\mathds{X}_i^{(k,q+1)}\geq \mathds{X}_i^k$}. 


Since $\mathds{K}_i^{(k,0)}$ satisfies $\sigma(\mathscr{L}_{[\mathds{K}_i^{(k,0)},\mathds{L}_i^{k-1},\mathcal{S}_i]})\subset\mathbb{C}^-$, the induction hypothesis holds for the base case $j=1$. 

Therefore, property 2) and inequality $X_{i}^{(k,j)}\geq X_{i}^{k}$ are confirmed for all $j\in\mathbb{N}_+$.

Next, we show that the sequence $\{\mathds{X}_{i}^{(k,j)}\}_{j=1}^{\infty}$ is monotonically decreasing. From equations (\ref{inner_PE}) and (\ref{inner_PI}), we have
\begin{equation}\label{eq:0924-1}
\begin{aligned}
\mathscr{L}_{[\mathds{K}_{i}^{(k,j)},\mathds{L}_{i}^{k-1},\mathcal{S}_{i}]}(\tilde{\mathds{X}}_{i}^{(k,j)})+\|\tilde{\mathds{K}}_{i}^{(k,j-1)}\|_{\mathds{R}_{i}^{(k,j)}}^{2}=0.
\end{aligned}
\end{equation}
Since $\mathscr{L}_{[\mathds{K}_{i}^{(k,j)},\mathds{L}_{i}^{k},\mathcal{S}_{i}]}\subset \mathbb{C}^-$ has been established for all $j\in\mathbb{N}_+$, equation (\ref{eq:0924-1}) implies $\mathds{X}_{i}^{(k,j)}\geq \mathds{X}_{i}^{(k,j+1)}$ for all $j\in\mathbb{N}_+$. Therefore, the sequence $\{\mathds{X}_i^{(k,j)}\}_{j=1}^{\infty}$ is monotonically deceasing and bound below by $\mathds{X}_{i}^{k}$. 

Since $\mathds{X}_i^k$ and $\mathds{K}_i^k$ satisfy equations (\ref{inner_PE}) and (\ref{inner_PI}), the monotone convergence theorem ensures that the sequence $\{\mathds{X}_i^{(k,j)}\}_{j=1}^{\infty}$ converges to $\mathds{X}_i^k$, and consequently, $\{\mathds{K}_i^{(k,j)}\}_{j=1}^{\infty}$ converges to $\mathds{K}_i^k$.
\eproof
% \begin{remark}
%  From the Theorems \ref{thm:convergence-outer-loop} and \ref{thm:convregence-inner-loop}, it is straightforward to observe that every element of the sequence $\{\mathds{L}_i^k\}_{k=0}^{\infty}$, generated by the outer-loop iteration, always lies in $\mathcal{D}_{\delta}$. Similarly, all elements of the sequence $\{\mathds{K}_i^{(k,j)}\}_{j=0}^{\infty}$, generated by the inner-loop iteration, always belong to $\widetilde{\mathcal{D}}_{\tilde{\delta}}(\mathds{L}_i^{k-1})$. Moreover, $\mathds{L}_i\in \mathcal{D}_{0}$ and $\mathds{K}_i^k\in\widetilde{\mathcal{D}}_{0}(\mathds{L}_i^{k-1})$ for all $k\in\mathbb{N}_+$. 
% \end{remark}





 
\section{Robustness Analysis for the Dual-Loop Algorithm}\label{sec:main result2}
% In the previous section, we introduce the outer-loop and inner-loop iterations, respectively, and analyze the convergence result of them under ideal conditions. We now turn our attention to the practical implementation of the entire iterative procedure. The focus is on its performance under a finite number of iterations and in the presence of external disturbances.
In the previous section, we introduced the outer-loop and inner-loop iterations and analyzed their convergence properties under ideal conditions. In this section, we examine the performance of the dual-loop algorithm when only a finite number of iterations is executed and assess their robustness in the presence of external disturbances. 

For the subsequent analysis, we define the sets $\mathcal{D}_{\zeta}\triangleq \{\boldsymbol{L}_i\in\mathcal{W}|\mathrm{Tr}(\mathds{X}_i-\mathds{X}_{\boldsymbol{L}_i})\leq\zeta\}$ and $\mathcal{G}_{\rho}(\boldsymbol{L}_i)\triangleq \{\boldsymbol{K}_i\in\mathcal{Z}(\boldsymbol{L}_i)|\mathrm{Tr}(\mathds{X}_{\boldsymbol{K}_i}-\mathds{X}_{\boldsymbol{L}_i})\leq\rho\}$, and conclude some auxiliary results in Appendix \ref{Auxiliary results} based on these formulations. 

% It is noted that $(\mathds{L}_i,\mathds{K}_i)\in\mathcal{D}_0\times\mathcal{G}_0(\mathds{L}_i)$. Moreover, $\{\mathds{L}_i^k\}_{k=1}^{\infty}$ and  $\{\mathds{K}_i^{(k,j)}\}_{j=1}^{\infty}$ are convergent sequences within $\mathcal{D}_{\delta}$ and within $\mathcal{G}_{\rho}(\mathds{L}_i^{k-1})$, respectively, for some $\delta,\rho>0$.


The theorems below demonstrate the algorithmâ€™s linear convergence rate. Detailed proofs of these theorems are provided in Appendices \ref{thmpf:rate-outer-loop} and \ref{thmpf:rate-inner-loop}. 
 
\begin{theorem}\label{thm:rate-outer-loop}
For any $\zeta>0$ and any $\mathds{L}_i^{k-1}\in\mathcal{D}_{\zeta}$, there exists a $\alpha(\zeta)\in(0,1)$ such that 
\begin{equation}\label{eq:resul_thm_rate-outer-loop}
\mathrm{Tr}\left(\Delta\mathds{X}_i^{k+1}\right)\leq \alpha \mathrm{Tr}\left(\Delta\mathds{X}_i^k\right).
\end{equation}
\end{theorem}
  


\begin{theorem}\label{thm:rate-inner-loop}
For any $\rho>0$ and any $\mathds{K}_i^{(k,j-1)}\in {\mathcal{G}}_{{\rho}}(\mathds{L}_i^{k-1})$, there exists a $\tilde{\alpha} \in(0,1)$ such that 
\begin{equation}\label{eq:resul_thm_rate-inner-loop}
\mathrm{Tr}\left(\Delta\mathds{X}_i^{(k,j+1)}\right)\leq \tilde{\alpha}\mathrm{Tr}\left(\Delta\mathds{X}_i^{(k,j)}\right).
\end{equation}
\end{theorem}
\begin{remark}
Theorem \ref{thm:rate-outer-loop} guarantees that the sequence $\{\mathds{X}_i^k\}_1^{\infty}$ converges linearly to the stabilizing solution $\mathds{X}_i$. Each $\mathds{X}_i^k$ is further approximated by the inner-loop iteration, which also exhibits linear convergence as established in Theorem \ref{thm:rate-inner-loop}. Notably, the convergence rate of the inner-loop iteration is independent of $\mathds{L}_i^{k-1}$, ensuring that the number of inner-loop iterations does not increase with each outer-loop iterations. Moreover, both theorems provide the bounds $\|\tilde{\mathds{X}}_i^{k}\|\leq(1+\alpha)\alpha^{k-1}\zeta$ and $\|\tilde{\mathds{X}}_i^{(k,j)}\|\leq(1+\tilde{\alpha})\tilde{\alpha}^{j-1}\rho$, with similar bounds for $\tilde{\mathds{L}}_i^k$ and $\tilde{\mathds{K}}_i^{(k,j)}$. Consequently, a convergence criterion $\xi(k,j)$ can be applied in practice to achieve the desired approximation with a finite number of steps for both loops of the algorithm, as detailed in the following algorithm.
% For deterministic systems, the locally quadratic convergence rate of PI algorithm has been established in \cite{pang2021robust}, while the stochastic case is analyzed in Theorem \ref{thm:quadratic-rate-inner-loop}.
\end{remark}
\begin{remark}
While the convergence criterion in Algorithm \ref{Alg_1} allows to approximate the true solution within a finite number of steps, it also introduces estimation errors. Since each approximation serves as the input for the subsequent iteration, biases may accumulate throughout the iterative process. Additionally, these biases may be further compounded by model mismatches and measurement errors inherent in the data-driven methods. Therefore, it is necessary to analyze the robustness of the iterative processes against these external disturbances.
\end{remark}
\begin{algorithm}
 % \KwData{this text}
  % A continuous driving cycle;}
  Initialization: $k \leftarrow1$ ,~$j \leftarrow1$, ~ $\mathds{L}_i^0\leftarrow 0$\; 
 \While{$\|\tilde{\mathds{L}}_i^{k-1}\|\geq\xi$ or $k=1$}{
 $\mathds{K}_i^{(k,0)}$ such that $\mathscr{L}_{[\mathds{K}_i^{(k,0)},\mathds{L}_i^{k-1},\mathcal{S}_i]}\subset\mathbb{C}^-$\;
 \While{$\|\tilde{\mathds{K}}_i^{(k,j-1)}\|\geq\xi$ or $j=1$}{
Solve $\mathds{X}_i^{(k,j)}$ from (\ref{inner_PE})\;
Update $\mathds{K}_i^{(k,j)}$ by (\ref{inner_PI})\;
$j\leftarrow j+1$ \;
 }
 $\mathds{X}_i^{k}\leftarrow \mathds{X}_i^{(k,j)}$\;
 Update $\mathds{L}_i^k$ by (\ref{outer_eq2})\;
  $k\leftarrow k+1$\;
  $j\leftarrow 1$\;
 }
 % \KwResult{} $~~~~v^*(t) \leftarrow S(v(t_k),v(t_{k+1})),~~\forall t \in [t(k),t(k+1)),~~k=0,1,2,...,M.$
 \caption{Dual-loop Iterative Algorithm}\label{Alg_1}
\end{algorithm}
 % between the final approximation and the exact solution
% "Implementing a convergence criterion in the outlined procedure introduces an estimation error between the final approximation and the true solution. Since each approximation feeds into the subsequent iteration, these errors can accumulate over time, leading to biases in the iterative process. This issue is further compounded by model mismatches and inherent errors in data-driven methods. Therefore, it is crucial to analyze the robustness of the iterative process against external disturbances to ensure reliable performance.

Consider the outer-loop iteration at $k\geq1$. A disturbance $\delta\mathds{L}_i^k$ may arise, introducing a bias in $\mathds{L}_i^{k}$ as follows  
\begin{equation}
\hat{\mathds{L}}_i^{k} = \mathds{L}_i^k+\delta \mathds{L}_i^{k}, \quad\mathds{L}_i^{k}=\mathcal{K}_{\mathcal{V}}^2(\hat{\mathds{X}}_i^k).
\end{equation}
This bias leads to an inexact model for the $(k+1)$-th outer-loop iteration, described by
\begin{subequations}\label{hat_outer_eq}
\begin{empheq}[left={\left\{\begin{aligned}},right={\end{aligned}\right.}]{align}
&{\mathscr{L}}_{[{\mathds{K}}_i^{k+1},\hat{\mathds{L}}_i^{k},\mathcal{S}_i]}(\hat{\mathds{X}}_i^{k+1}) \!+\! \mathds{Q}_i^k \!+\! \|{{\mathds{K}}_i^{k+1}}\|_{\mathds{R}}^2=0, \\
&\mathds{K}_i^{k+1}=\mathcal{K}_{\mathcal{U}_i}^1(\hat{\mathds{X}}_i^{k+1}),
\end{empheq}
\end{subequations}
where $\hat{\mathds{Q}}_i^k=\mathds{Q}-\|\hat{\mathds{L}}_i^{k}\|_{\mathds{W}}^2$. The ``hat'' notation differentiates the exact solution from \eqref{general:oueter-loop} and the inexact one in (\ref{hat_outer_eq}).

Similarly, in the inner-loop iteration at $j\geq1$, a disturbance $\delta\mathds{K}_i^{(k,j)}$ is introduced 
\begin{equation}
\hat{\mathds{K}}_i^{(k,j)}=\mathds{K}_i^{(k,j)}+\delta\mathds{K}_i^{(k,j)}, \quad\mathds{K}_i^{(k,j)}=\mathscr{K}_{\mathcal{U}_i}^1(\hat{\mathds{X}}_i^{(k,j)})
\end{equation} 
This results in inexact iterative equation for the $(j+1)$-th step
\begin{equation}\label{inexact:inner-loop}
\mathcal{L}_{[\hat{\mathds{K}}_i^{(k,j)},\hat{\mathds{L}}_i^{k-1},\mathcal{S}_i]}(\hat{\mathds{X}}_i^{(k,j+1)})+\hat{\mathds{Q}}_i^{k-1}+\|\hat{\mathds{K}}_i^{(k,j)}\|_{\mathds{R}}^2=0.
\end{equation}
% with $\hat{\mathds{Q}}_i^{k-1}:=\mathds{Q}_i-\|\hat{\mathds{L}}_i^{k-1}\|_{\mathds{W}}^2$.

\begin{remark}
As illustrated in Fig. \ref{f:diag9}, the inexact iterative equation (\ref{hat_outer_eq}) can be viewed as a discrete-time nonlinear system, where $\mathds{X}_i^k$ is the state and $\delta \mathds{L}_i^{k}$ serves as the disturbance input. Similarly, the inexact policy evaluation (\ref{inexact:inner-loop}) can be represented as a discrete-time linear system, where $\hat{\mathds{X}}_i^{(k,j)}$ is the state and $\delta \mathds{K}_i^{(k,j)}$ acts as the disturbance input. In the absence of disturbances, Theorems \ref{thm:rate-outer-loop} and \ref{thm:rate-inner-loop} guarantee that these systems are exponentially stable, and the states $\hat{\mathds{X}}_i^{k}$ and $\hat{\mathds{X}}_i^{(k,j)}$ converges to the equiliria $\mathds{X}_i$ and $\mathds{X}_i^{k}$, respectively. 
\begin{figure}[!htb]
\centering
\includegraphics[scale=0.4]{digram9_3}
\centering
\caption{Schematic diagrams of the inexact iterative procedures: (left) Inexact outer-loop iteration; (right) Inexact inner-loop iteration.}\label{f:diag9}
\end{figure}
\end{remark}

The following theorems demonstrate the robustness of both systems to small disturbances, ensuring stability in the presence of $\delta\mathds{L}_i^{k}$ and $\delta\mathds{K}_i^{(k,j)}$. Their proofs are provided in Appendices \ref{thmpf:robust-outer-loop} and \ref{thmpf:robust-inner-loop}.
\begin{theorem}\label{thm:robust-outer-loop}
Suppose the conditions of Theorem \ref{thm:convergence-outer-loop} hold and let $\hat{\mathds{X}}_i^0=0$ and $\hat{\mathds{L}}_i^0=0$. For any $\zeta>0$, there exists a constant $\varepsilon(\zeta)>0$ such that if the disturbance sequence $\delta \mathds{L}_i \triangleq\{\delta \mathds{L}_i^{k}\}_{k=1}^{\infty}$ satisfies $\|\delta\mathds{L}_i\|_{\infty}<\varepsilon(\zeta)$, then there exist a $\mathcal{K}\mathscr{L}$-function $\kappa(\cdot,\cdot)$ and a $\mathcal{K}$-function $\ell(\cdot)$ such that
\begin{equation}
\|\mathds{X}_i-\hat{\mathds{X}}_i^{k+1}\|_F\leq \kappa(\|{\mathds{X}}_i-\hat{\mathds{X}}_i^1\|_F,k)+\ell(\|\delta\mathds{L}_i\|_{\infty}),
\end{equation}
for all $k\in\mathbb{N}_+$, where $\|\delta \mathds{L}_i\|_{\infty}=\sup_{k\in\mathbb{N}_+}\|\delta \mathds{L}_i^k\|_F$. 
\end{theorem}







 
\begin{theorem}\label{thm:robust-inner-loop}
Suppose the conditions of Theorem \ref{thm:robust-outer-loop} hold. For any $\rho>0$, where there exists a constant $\tilde{\varepsilon}(\rho)>0$ such that if the disturbance sequence $\delta\mathds{K}_i^k\triangleq\{\delta\mathds{K}_i^{(k,j)}\}_{j=1}^{\infty}$ satisfies $\|\delta\mathds{K}_i^k\|_{\infty}<\tilde{\varepsilon}(\rho)$, then there exist a $\mathcal{K}\mathscr{L}$-function $\mu(\cdot,\cdot)$ and a $\mathcal{K}$-function $\gamma(\cdot)$ such that
\begin{equation}
\!\!\!\!\|\hat{\mathds{X}}_i^{(k,j)}-\mathds{X}_i^{k}\|_F\leq\mu(\|\hat{\mathds{X}}_i^{(k,1)}-\mathds{X}_i^{k}\|_F,j)+\gamma(\|\delta \mathds{K}_i^k\|_{\infty}) 
\end{equation}
for all $j\in\mathbb{N}_+$, where $\|\delta\mathds{K}_i^k\|_{\infty}=\sup_{j\in\mathbb{N}_+}$.
\end{theorem}
\begin{remark}
These results ensure that the systems are robust in the sense of small-disturbance ISS (\!\!\cite{pang2021robust}). In practice, when errors occur during the execution of the algorithm, the limit of the approximation error is upper bounded by the magnitude of the disturbances. As a result, the  approximation errors will eventually converge to a small neighborhood around zero, as long as the disturbances remain small.
\end{remark}



 \section{Data-driven Implementation of the Iterative Framework for Robust MFSC}\label{sec:main result3}
Based on the proposed iterative framework, we develop a data-driven method to find the decentralized control strategy (\ref{uo}) and the decentralized disturbance strategy (\ref{do}) that achieve the asymptotic robust social optimality for the game described by (\ref{sys1}) and (\ref{Jsoc}).

We begin by applying Algorithm \ref{Alg_1} to determine $(P,\!K_p,\!L_p)$. In the inner loop, the $(k,j)$-th approximations of $P$ and $K_p$ are solved by 
\begin{align}
&\mathscr{L}_{[K_p^{(k,j-1)},L_p^{k-1},\mathcal{S}_p]}(P^{(k,j)})\!+\!Q^{k-1}\!+\!\|K_p^{(k,j-1)}\|_R^2\!=\!0,\label{MFP:iteration-inner-loop-1}\\
&K^{(k,j)}_p =\mathscr{K}_{\mathcal{U}_p}^1(P^{(k,j)}),\label{MFP:iteration-inner-loop-2}
\end{align}
where $\mathcal{S}_p=[A,B,G|C,D]$, $\mathcal{U}_p=\{R,B,C,D\}$, $\mathcal{V}_p=\{\gamma^2I,G\}$, and $Q^k\!=\!Q\!-\!\gamma^2\|L_p^k\|^2$. Subsequently, the $k$-th outer-loop approximation of $L_p$ is updated by
\begin{equation}\label{MFP:iteration-outer-loop-2}
L^k_p=\mathscr{K}_{\mathcal{V}_p}^2(P^k). 
\end{equation}


Then, we utilize Algorithm \ref{Alg_1} to approximate $(S,K_s,L_s)$. The $(k,j)$-th inner-loop iteration becomes
\begin{align}
& \mathscr{L}_{[K_s^{(k,j-1)},L_s^{k-1},\mathcal{S}_s]}(S^{(k,j)})\!+\!Q_s^{k-1}\!+\!\|K_s^{(k,j-1)}\|_{\Upsilon}^{2}=0,\label{MFS:iteration-inner-loop-1}\\
&K_s^{(k,j)} =\mathscr{K}_{\mathcal{U}_s}^1(S^{(k,j)}),\label{MFS:iteration-inner-loop-2}
\end{align}
and the $k$-th outer-loop iteration is 
\begin{equation}\label{MFS:iteration-outer-loop-1}
L_s^k=\mathscr{K}_{\mathcal{V}_p}^2(S^k),
\end{equation}
where $\mathcal{S}_{s} \!=\![A_s,B,G|0,0]$, $\mathcal{U}_s\!=\!\{\Upsilon,B,0,0\}$, and $Q^k_s \!=\! Q_s\!-\gamma^2\|L_s^k\|^2$.  

\begin{assume}\label{assume:MF1_stabob}
The system $\mathcal{S}_p$ is stabilizable when $G=0$, and $[A,Q^{\frac{1}{2}}|C]$ and $[A,Q^{\frac{1}{2}}(I-\Gamma)|0]$ are detectable.
\end{assume}
% \begin{assume}\label{assume:MF2_ob}
% The pair $[A,Q^{\frac{1}{2}}(I-\Gamma)]$, is detectable.
% \end{assume}

These conditions are standard and commonly used in MFSC problems \cite{wang2020indefinite,huang2019linear2}. Under Assumption \ref{assume:MF1_stabob} and the initial conditions $L_p\!=\!L_s\!=\!0$, the convergence and robustness results of the above iterative procedures follow with Theorems \ref{thm:convergence-outer-loop}-\ref{thm:robust-inner-loop}. 
\begin{remark}\label{remk:10}
However, there are difficulties for the development of data-driven algorithm. First, the matrix $Q_s$ contain terms involving the system parameters $C$ and $D$. This explicit dependence hinders the complete removal of dynamical model from the iterative equations. Second, the discrepancy between $A_s$ and the state matrix $A$, combined with the multiplicative noise in the agents' dynamics (\ref{sys1}), makes it difficult to directly apply the IRL technique to equations (\ref{MFS:iteration-inner-loop-1}) and (\ref{MFS:iteration-inner-loop-2}) based on trajectories along system (\ref{sys1}). Finally, finding initial conditions $K_p^{(k,0)},K_s^{(k,0)}$ for both inner-loop iterations is challenging without prior information of the dynamics.
\end{remark}
\vspace{-0.2cm}
 \subsection{Data-driven approximation of gain matrices for $(u_i^o,v_i^o)$}
To overcome the first hurdle, let $\Pi^{(k,j)}\triangleq S^{(k,j)}-P$, $K_{\pi}^{(k,j)} \triangleq K_s^{(k,j)}-\Upsilon^{-1}B^{\mathrm{T}}P$, and $L^{k}_{\pi}\triangleq L_s^k-L_p$. By using these variables and equation (\ref{are1}), equations (\ref{MFS:iteration-inner-loop-1})-(\ref{MFS:iteration-outer-loop-1}) can be transformed into
\begin{align}
&\mathscr{L}_{[K_{\pi}^{(k,j-1)},L^{k-1}_{\pi},\mathcal{S}_{\pi}]}(\Pi^{(k,j)})\!+\!Q_{\Gamma}^{k-1}\!+\!\|K_{\pi}^{(k,j-1)}\|_{\Upsilon}^2\!=\!0,\label{MFPi:iteration-inner-loop-11}\\
&{K}_{\pi}^{(k,j)} = \mathscr{K}^1_{\mathcal{U}_s}(\Pi^{(k,j)}),\label{MFPi:iteration-inner-loop-12}\\
&{L}_{\pi}^k=\mathscr{K}^2_{\mathcal{V}_p}(\Pi^k), \label{MFPi:iteration-outer-loop-22}
\end{align}
respectively. Here, $\mathcal{S}_{\pi}=[A-BK_p+GL_p,B,G|0,0]$ and $Q_{\Gamma}^k=-Q_{\Gamma}-\gamma^2\|{L}_{\pi}^{k}\|^2$.
\begin{remark}
Since the equivalence between this iterative procedure and the one described by
(\ref{MFS:iteration-inner-loop-1})-(\ref{MFS:iteration-outer-loop-1}) can be easily verified, the convergence and robustness of the proposed iteration are guaranteed under the initial condition ${L}_{\pi}^0\!=\!-L_p$. As a result, the generated sequences satisfies that $\lim_{k\rightarrow\infty}\lim_{j\rightarrow\infty}\Pi^{(k,j)}\!=\!S\!-\!P\!\triangleq\!\Pi$, $\lim_{k\rightarrow\infty}\lim_{j\rightarrow\infty}K_{\pi}^{(k,j)}\!=\!K_s\!-\!K_p\!\triangleq\!K_{\pi}$, and $\lim_{k\rightarrow\infty}L_{\pi}^k\!=\!L_{s}\!-\!L_p\!\triangleq\!L_{\pi}$. It is worth noting that, compared to equation (\ref{MFS:iteration-inner-loop-1}), the explicit dependence on the system parameters is eliminated in equation (\ref{MFPi:iteration-inner-loop-11}).
\end{remark}

% Since it is straight to show the equivalence result between this iterative procedure and the iterative procedure (\ref{MFS:iteration-inner-loop-1})-(\ref{MFS:iteration-outer-loop-1}). The convergence and robustness of this iterative process are guaranteed under the condition ${L}_{\pi}^0=-L$. The generated sequence converges to $\Pi\triangleq S-P$, which satisfies the equation
% \begin{equation}\label{are2}
% \begin{aligned}
% &A_{\pi}^{\mathrm{T}}\Pi\!+\!\Pi A_{\pi}\!-\!Q_{\Gamma}\!+\!\frac{1}{\gamma^2}\Pi GG^{\mathrm{T}}\!\Pi\!-\!\Pi B\Upsilon^{-1}B^{\mathrm{T}}\Pi\!=\!0.
% \end{aligned}
% \end{equation}
% Note that despite the indefiniteness of $Q_{\Gamma}$ and $\Pi$, the dual-loop iteration remains effective.
% \end{remark}
 
 
To develop a data-driven method, we select a fixed agent $\mathcal{A}_{\mathds{L}}$, $\mathds{L}\in\{1,2,\cdots,N\}$, to collect data. The agent's exploratory control and disturbance strategies are designed as
\begin{align}
&u_{\mathds{L}}(t) \!=\! -K_{exp}x_{\mathds{L}}(t)+\xi^1(t),~ \xi^1(t)\!=\!\sigma_1\sum_{j=1}^{n_l}\sin(\omega_jt),\\
&v_{\mathds{L}}(t) \!=\! L_{exp}x_{\mathds{L}}(t)+\xi^2(t),~ \xi^2(t)\!=\!\sigma_2\sum_{j=1}^{n_l}\sin(\upsilon_jt),
\end{align}
where $\xi^1(t)$ and $\xi^2(t)$ are the sum of sine waves typically used as exploratory noise in IRL algorithms \cite{jiang2012computational,xu2024mean}. 

To address the second issue in Remark \ref{remk:10}, define new variables as follows
\begin{equation}\label{Exuv:eq}
\bar{x}_{\mathds{L}}(t)\!=\!\mathbb{E}[x_{\mathds{L}}(t)],~\bar{u}_{\mathds{L}}(t)\!=\!\mathbb{E}[u_{\mathds{L}}(t)],~\bar{v}_{\mathds{L}}(t)\!=\!\mathbb{E}[v_{\mathds{L}}(t)].
\end{equation}
By using (\ref{sys_s}), the dynamics of $\bar{x}_{\mathds{L}}$ are given by
\begin{equation}\label{sys:xL}
\mathrm{d}\bar{x}_{\mathds{L}}=(A\bar{x}_{\mathds{L}}(t)+Bu_{\mathds{L}}+Gv_{\mathds{L}})\mathrm{d}t.
\end{equation}
Additionally, introduce the following integrals and differences
\begin{equation}\label{Eint:eq}
\begin{aligned}
\!\!\!\!&\bar{\delta}_{{x}_{\mathds{L}}}^t\!=\!\mathbb{E}[\delta_{{x}_{\mathds{L}}}^t],\bar{I}_{x_{\mathds{L}}x_{\mathds{L}}}^t\!=\!\mathbb{E}[I_{x_{\mathds{L}}x_{\mathds{L}}}^t],\bar{I}_{x_{\mathds{L}}u_{\mathds{L}}}^{t}\!=\!\mathbb{E}[I_{x_{\mathds{L}}u_{\mathds{L}}}^{t}],\\
\!\!\!\!&\bar{I}_{{u}_{\mathds{L}}}^t\!=\!\mathbb{E}[I_{{u}_{\mathds{L}}}^t],\bar{I}_{x_{\mathds{L}}v_{\mathds{L}}}^t\!=\!\mathbb{E}[I_{x_{\mathds{L}}v_{\mathds{L}}}^t],\delta^t_{\bar{x}_{\mathds{L}}},I^t_{\bar{x}_{\mathds{L}}\bar{x}_{\mathds{L}}},I^t_{\bar{x}_{\mathds{L}}\bar{u}_{\mathds{L}}},I^t_{\bar{x}_{\mathds{L}}\bar{v}_{\mathds{L}}}.
\end{aligned}
\end{equation}

 Let $t_1$ and $t_l$ be the initial and terminal times of data collection phase, with the time instants $t_k=t_1+(k-1)T_s$ for $1\leq k\leq l$, where $T_s$ is the sampling time. During this phase, we obtain the following data-based matrices: $\bar{\Delta}_{(\cdot)}=\left[\bar{\delta}_{(\cdot)}^{t_1},\bar{\delta}_{(\cdot)}^{t_2},\cdots,\bar{\delta}_{(\cdot)}^{t_l}\right]^{\mathrm{T}}$, $\bar{\mathcal{I}}_{(\cdot)}=\left[\bar{I}_{(\cdot)}^{t_1},\bar{I}_{(\cdot)}^{t_2},\cdots,\bar{I}_{(\cdot)}^{t_l}\right]^{\mathrm{T}}$, $\Delta_{(\cdot)}=\left[{\delta}_{(\cdot)}^{t_1},{\delta}_{(\cdot)}^{t_2},\cdots,{\delta}_{(\cdot)}^{t_l}\right]^{\mathrm{T}}$, and $\mathcal{I}_{(\cdot)}=\left[{I}_{(\cdot)}^{t_1},{I}_{(\cdot)}^{t_2},\cdots,{I}_{(\cdot)}^{t_l}\right]^{\mathrm{T}}$, where the subscript $(\cdot)$ can be replaced with corresponding variables defined above.
 
 
\begin{assume}\label{assume:rank1}
There exists $l_1>0$ such that for all $l\geq l_1$, we have
\begin{equation}\label{A:rank1}
\begin{aligned}
&\mathrm{rank}\left(\left[\bar{\mathcal{I}}_{x_{\mathds{L}}x_{\mathds{L}}},\bar{\mathcal{I}}_{x_{\mathds{L}}u_{\mathds{L}}},\bar{\mathcal{I}}_{x_{\mathds{L}}v_{\mathds{L}}},\bar{\mathcal{I}}_{{u}_{\mathds{L}}}\right]\right) \\
= &\frac{1}{2}n(n+1)+n(m_1+m_2)+\frac{1}{2}m_1(m_1+1).
\end{aligned}
\end{equation}
\end{assume}
\begin{assume}\label{assume:rank2}
There exists $l_2>0$ such that for all $l\geq l_2$, we have
\begin{equation}\label{A:rank2}
\begin{aligned}
\mathrm{rank}\left(\left[\mathcal{I}_{\bar{x}_{\mathds{L}}\bar{x}_i},\mathcal{I}_{\bar{x}_{\mathds{L}}\bar{u}_{\mathds{L}}},\mathcal{I}_{\bar{x}_{\mathds{L}}\bar{v}_{\mathds{L}}}\right]\right) \!=\! \frac{1}{2}n(n\!+\!1)\!+\!n(m_1\!+\!m_2).
\end{aligned}
\end{equation}
\end{assume}
 
By using the data-based matrices and the IRL technique (\!\!\cite{xu2024mean}), based on equations (\ref{MFP:iteration-inner-loop-1})-(\ref{MFP:iteration-outer-loop-2}) and system (\ref{sys1}), the $(k,j)$-th approximations of $(P,K_p,L_p)$ are determined by
\begin{equation}\label{eq:MFK-data-iteration}
\begin{aligned}
\left[\begin{array}{c}
\mathrm{vecm}({P}^{(k,j)})\\
\mathrm{col}\!\left(\!M^{(k,j)}\!\right)\\
\mathrm{col}\!\left(\!L_p^{(k,j)}\!\right)\\
\mathrm{vecm}({\Lambda}_p^{(k,j)})
\end{array}\right] \!\!\! =\!\!\!\left(\!\!\left(\!\Psi_p^{(k,j-1)}\!\right)^{\!\!\mathrm{T}}\!\!\Psi_p^{(k,j-1)}\!\!\right)^{\!\!-1}\!\!\!\left(\!\Psi_p^{(k,j-1)}\!\right)^{\!\!\mathrm{T}}\!\!\Xi_p^{(k,j-1)} 
\end{aligned}
\end{equation}
and $K_p^{(k,j)}\!=\!(R\!+\!{\Lambda}_p^{(k,j)})^{-1}M^{(k,j)}$. Here, $\Psi_p^{(k,j-1)}\!=\![\bar{\Delta}_{{x}_{\mathds{L}}},\!\psi_1,\!\psi_2,\!\psi_3]$, $\psi_1\!=\!-2\bar{\mathcal{I}}_{x_{\mathds{L}}u_{\mathds{L}}}\!-\!2\bar{\mathcal{I}}_{x_{\mathds{L}}x_{\mathds{L}}}(I\!\!\otimes \!\!(K_p^{(k,j-1)})^{\!\mathrm{T}})$, $\psi_2$ 
$\! =\! -{2}{\gamma^2}\bar{\mathcal{I}}_{x_{\mathds{L}}v_{\mathds{L}}}\!+\!{2}{\gamma^2}\!\bar{\mathcal{I}}_{x_{\mathds{L}}x_{\mathds{L}}}(I\!\otimes \!(L_p^{k-1})^{\mathrm{T}})$, $\psi_3 \!=\! -\bar{\mathcal{I}}_{{u}_{\mathds{L}}}\!+\!\bar{\mathcal{I}}_{x_{\mathds{L}}x_{\mathds{L}}}\mathds{K}_p^{(k,j-1)}$, $\mathds{K}_p^{(k,j-1)}\!=\![\kappa_{11}^{(k,j-1)},\!\cdots,\!\kappa_{1m}^{(k,j-1)},\!\kappa_{22}^{(k,j-1)},$ 
$\!\cdots,$ $\!\kappa_{(m-1)m}^{(k,j-1)},\!\kappa_{mm}^{(k,j-1)}]\!\in\!\mathbb{R}^{n^2\times\! \frac{m}{2}(m+1)}$, $\kappa_{ij}^{(k,j-1)}\!=\![K_p^{(k,j-1)}]_i^{\mathrm{T}}\!\otimes\! [K_p^{(k,j-1)}]_j^{\mathrm{T}}$, $[K_p^{(k,j-1)}]_i$ is the $i$-th row of $K_p^{(k,j-1)}$, and $\Xi_p^{(k,j-1)}\!=\bar{\mathcal{I}}_{x_{\mathds{L}}x_{\mathds{L}}}\mathrm{vec}(\!-Q^{k-1}\!-\!\|K_p^{(k,j-1)}\|_R^2)$. 
 

Similarly, based on equations (\ref{MFPi:iteration-inner-loop-11})-(\ref{MFPi:iteration-outer-loop-22}) and system (\ref{sys:xL}), the $(k,j)$-th approximations of $(\Pi,K_{\pi},{L}_{\pi})$ are obtained by solving
\begin{equation}\label{eq:MFKbar-data-iteration}
\begin{aligned}
\left[\begin{array}{c}
\mathrm{vecm}({\Pi}^{(k,j)}) \\
\mathrm{col}\!\left(\!{K}_{\pi}^{(k,j)}\!\right) \\
\mathrm{col}\!\left(\!{L}_{\pi}^{(k,j)}\!\right) 
\end{array}\right] \!\!=\!\!\left(\!\!\left(\!\Psi_{\pi}^{(k,j-1)}\!\right)^{\!\!\mathrm{T}}\!\!\Psi_2^{(k,j-1)}\!\!\right)^{-1}\!\!\!\left(\!\Psi_{\pi}^{(k,j-1)}\!\right)^{\!\!\mathrm{T}}\!\!\Xi_{\pi}^{(k,j-1)}\!,
\end{aligned}
\end{equation}
where $\Psi_{\pi}^{(k,j-1)}=[\Delta_{{\bar{x}}_{\mathds{L}}},\psi_4,\psi_5]$, $\psi_4\!=\!-2\mathcal{I}_{\bar{x}_{\mathds{L}}\bar{u}_{\mathds{L}}}(I\otimes \Upsilon)\!-\!2\mathcal{I}_{\bar{x}_{\mathds{L}}\bar{x}_{\mathds{L}}}(I\otimes (K\!+\!{K}_{\pi}^{(k,j-1)})^{\mathrm{T}}\Upsilon)$, $\psi_5\! = \!-{2}{\gamma^2}\mathcal{I}_{\bar{x}_i\bar{v}_i}\!+\!{2}{\gamma^2}\mathcal{I}_{\bar{x}_{\mathds{L}}\bar{x}_{\mathds{L}}}(I\otimes (L\!+\!{L}_{\pi}^{k-1})^{\mathrm{T}})$, $\Xi_{\pi}^{(k,j-1)}\!=\!\mathcal{I}_{\bar{x}_{\mathds{L}}\bar{x}_{\mathds{L}}}\mathrm{vec}(-Q_{\Gamma}^{k-1}\!-\!\|{K}_{\pi}^{(k,j-1)}\|_{\Upsilon}^2)$.


The proof of equivalence between the data-driven iterative equations and the model-based iterative equations is similar to those presented in \cite{xu2024mean} and will not be provided here.
 
In practice, we estimate the quantities in (\ref{Exuv:eq}) and (\ref{Eint:eq}) using a finite number of trajectory samples as follows.
\begin{equation}\label{hat:E}
\begin{aligned}
\!\!\!\!\!\!&\hat{\bar{x}}_{\mathds{L}}={x}_{\mathds{L}}^{(N_s)},\hat{\bar{u}}_{\mathds{L}}={u}_{\mathds{L}}^{(N_s)},\hat{\bar{v}}_{\mathds{L}}={v}_{\mathds{L}}^{(N_s)},\hat{\bar{\delta}}_{{x}_{\mathds{L}}}^t=({\delta}_{{x}_{\mathds{L}}}^t)^{(N_s)},\\
\!\!\!\!\!\!&\hat{\bar{I}}_{x_{\mathds{L}}x_{\mathds{L}}}^t\! =\!({{I}}_{x_{\mathds{L}}x_{\mathds{L}}}^t)^{(N_s)},\hat{\bar{I}}_{x_{\mathds{L}}u_{\mathds{L}}}^{t}\!=\!({{I}}_{x_{\mathds{L}}u_{\mathds{L}}}^{t})^{(N_s)},\hat{\bar{I}}_{{u}_{\mathds{L}}}^t \!=\!({I}_{{u}_{\mathds{L}}}^t)^{(N_s)},\\
\!\!\!\!\!\!&\hat{\bar{I}}_{x_{\mathds{L}}v_{\mathds{L}}}^t =({{I}}_{x_{\mathds{L}}v_{\mathds{L}}}^t)^{(N_s)},~\delta^t_{\hat{\bar{x}}_{\mathds{L}}},~I^t_{\hat{\bar{x}}_{\mathds{L}}\hat{\bar{x}}_{\mathds{L}}},~I^t_{\hat{\bar{x}}_{\mathds{L}}\hat{\bar{u}}_{\mathds{L}}},~I^t_{\hat{\bar{x}}_{\mathds{L}}\hat{\bar{v}}_{\mathds{L}}},
\end{aligned}
\end{equation} 
% \begin{equation}\label{hat:E}
% \begin{aligned}
% &\hat{\bar{x}}_{\mathds{L}}=\frac{1}{N_s}\sum_{j=1}^{N_s}\bar{x}_{\mathds{L}}^j,~\hat{\bar{u}}_{\mathds{L}}=\frac{1}{N_s}\sum_{j=1}^{N_s}\bar{u}_{\mathds{L}}^j,~\hat{\bar{v}}_{\mathds{L}}=\frac{1}{N_s}\sum_{j=1}^{N_s}\bar{v}_{\mathds{L}}^j,\\
% &\hat{\bar{\delta}}_{{x}_{\mathds{L}}}^t=\frac{1}{N_s}\sum_{j=1}^{N_s}(\bar{\delta}_{{x}_{\mathds{L}}}^t)^j,~\hat{\bar{I}}_{x_{\mathds{L}}x_{\mathds{L}}}^t = \frac{1}{N_s}\sum_{j=1}^{N_s}({\bar{I}}_{x_{\mathds{L}}x_{\mathds{L}}}^t)^j,\\
% &\hat{\bar{I}}_{x_{\mathds{L}}u_{\mathds{L}}}^{t}= \frac{1}{N_s}\sum_{j=1}^{N_s}({\bar{I}}_{x_{\mathds{L}}u_{\mathds{L}}}^{t})^j,~
% \hat{\bar{I}}_{{u}_{\mathds{L}}}^t = \frac{1}{N_s}\sum_{j=1}^{N_s}(\bar{I}_{{u}_{\mathds{L}}}^t)^j,\\
% &\hat{\bar{I}}_{x_{\mathds{L}}v_{\mathds{L}}}^t = \frac{1}{N_s}\sum_{j=1}^{N_s}({\bar{I}}_{x_{\mathds{L}}v_{\mathds{L}}}^t)^j,~\delta^t_{\hat{\bar{x}}_{\mathds{L}}},~I^t_{\hat{\bar{x}}_{\mathds{L}}\hat{\bar{x}}_{\mathds{L}}},~I^t_{\hat{\bar{x}}_{\mathds{L}}\hat{\bar{u}}_{\mathds{L}}},~I^t_{\hat{\bar{x}}_{\mathds{L}}\hat{\bar{v}}_{\mathds{L}}},
% \end{aligned}
% \end{equation}
where $(\cdot)^{(N_s)}=\frac{1}{N_s}\sum_{j=1}^{N_s}(\cdot)^j$, $N_s$ is the number of samples and the superscript $j$ represents the $j$-th sample. By the law of large numbers, as $N_s\rightarrow\infty$, these estimates converge to their true values.



Substituting the approximations from (\ref{hat:E}) into (\ref{eq:MFK-data-iteration}) and (\ref{eq:MFKbar-data-iteration}), the undetermined parameters are solved by
\begin{equation*}
\begin{aligned}
\left[\begin{array}{c}
{\mathrm{vecm}(\hat{P}^{(k,j)})}\\
\mathrm{col}\!\left(\!\hat{M}^{(k,j)}\!\right)\\
\mathrm{col}\!\left(\!\hat{L}^{(k,j)}_p\!\right)\\
\mathrm{vecm}(\hat{\Lambda}^{(k,j)}_p)
\end{array}\right] \!\!=\!\!\left(\!\!\left(\!\hat{\Psi}_p^{(k,j-1)}\!\right)^{\!\!\mathrm{T}}\!\!\hat{\Psi}_p^{(k,j-1)}\!\!\right)^{\!\!-1}\!\!\!\!\!\left(\!\hat{\Psi}_p^{(k,j-1)}\!\right)^{\!\!\mathrm{T}}\!\!\hat{\Xi}_p^{(k,j-1)}\!,
\end{aligned}
\end{equation*}
% and 
\begin{equation*}
\begin{aligned}
\left[\begin{array}{c}
\mathrm{vecm}(\hat{{\Pi}}^{(k,j)})\\
\mathrm{col}\!\left(\!\hat{{K}}_{\pi}^{(k,j)}\!\right)\\
\mathrm{col}\!\left(\!\hat{{L}}_{\pi}^{(k,j)}\!\right)
\end{array}\right] \!\!=\!\!\left(\!\!\left(\!\hat{\Psi}_{\pi}^{(k,j-1)}\!\right)^{\!\!\mathrm{T}}\!\!\hat{\Psi}_{\pi}^{(k,j-1)}\!\!\right)^{\!\!-1}\!\!\!\!\!\left(\!\hat{\Psi}_{\pi}^{(k,j-1)}\!\right)^{\!\!\mathrm{T}}\!\!\hat{\Xi}_{\pi}^{(k,j-1)}\!.
\end{aligned}
\end{equation*}
Here, the hats on the right-hand side denote approximated data-based quantities, while the hats on the left-hand side represent the corresponding estimated results.

Bias introduced through expectation estimation and the application of convergence criteria generates disturbances. Robustness analysis demonstrates that as long as these disturbances remain small, the approximation errors of the unknown parameters will converge to a small neighborhood around zero.
 
\vspace{-0.3cm}
\subsection{Computation of initial stabilizers and mean field state}
To find the initial stabilizing gain matrices, which are necessary to start each inner-loop iteration, we introduce a quadratic function for $\bar{x}_{\mathds{L}}$
\begin{equation*}
V(\bar{x}_{\mathds{L}})=\bar{x}_{\mathds{L}}^{\mathrm{T}}E_i\bar{x}_{\mathds{L}}
\end{equation*}
with the time derivative being
\begin{equation*}
\begin{aligned}
\!\!\!\!\!\!\dot{V}(t)\!=\!2\Big(&\bar{x}_{\mathds{L}}(t)^{\mathrm{T}}\mathrm{vec}(A_i)e_i^{\mathrm{T}}\bar{x}_{\mathds{L}}(t)\!+\!\bar{u}_{\mathds{L}}(t)^{\mathrm{T}}\mathrm{vec}(B_i)e_i^{\mathrm{T}}\bar{x}_{\mathds{L}}(t)+\!\bar{v}_i(t)^{\mathrm{T}}\mathrm{vec}(G_i)e_{i}^{\mathrm{T}}\bar{x}_{\mathds{L}}(t)\Big)\mathrm{d}t,
\end{aligned}
\end{equation*}
where $A_i,B_i,G_i$ denote the $i$-th rows of their respective matrices.
Integrating the above equation over the interval $[t,t+T]$ and using the Kronecker product representation yield
\begin{equation}
\begin{aligned}
& 2\!\! \left[\begin{array}{c}
\!I_{\bar{x}_{\mathds{L}}\bar{x}_{\mathds{L}}}^t\!\\
\!I_{\bar{x}_{\mathds{L}}\bar{u}_{\mathds{L}}}^t\!\\
\!I_{\bar{x}_{\mathds{L}}\bar{v}_{\mathds{L}}}^t\!
\end{array}\right]^{\mathrm{T}}\!\!\left[\begin{array}{ccc}
\!e_i\!\otimes\! I\!&\!0\!&\!0\!\\
\!0\!&\!e_i\!\otimes \!I\!&\!\!\\
\!0\!&\!0\!&\!e_i\!\otimes \!I\!
\end{array}\right]\!\!\left[\begin{array}{c}
\!\mathrm{vec}(A_i)\!\\
\!\mathrm{vec}(B_i)\!\\
\!\mathrm{vec}(G_i)\!
\end{array}\right]=(\delta_{\bar{x}_{\mathds{L}}\bar{x}_{\mathds{L}}}^t)^{\mathrm{T}}\mathrm{vec}(E_i),
\end{aligned}
\end{equation}
where $E_i=e_ie_i^{\mathrm{T}}$. Using the data-based matrices, the unknown system parameters can be determined by
\begin{equation}
\begin{aligned}
&\left[\begin{array}{c}
\!\mathrm{vec}(A_i)\!\\
\!\mathrm{vec}(B_i)\!\\
\!\mathrm{vec}(G_i)\!
\end{array}\right]=(\Phi_1^{\mathrm{T}}\Phi_1)^{-1})(\Phi_1\chi_1),
\end{aligned}
\end{equation}
 % where
\begin{equation}\label{dssd}
\left\{\begin{aligned}
 &\Phi_1 =2\left[\mathcal{I}_{\bar{x}_{\mathds{L}}\bar{x}_{\mathds{L}}}(e_i\!\otimes\! I),\mathcal{I}_{\bar{x}_{\mathds{L}}\bar{u}_{\mathds{L}}}(e_i\!\otimes\! I),\mathcal{I}_{\bar{x}_{\mathds{L}}\bar{v}_{\mathds{L}}}(e_i\!\otimes\! I)\right],\\
&\chi_1 = \Delta_{\bar{x}_{\mathds{L}}\bar{x}_{\mathds{L}}}\mathrm{vec}(E_i).
\end{aligned}\right.
\end{equation}

In practice, using (\ref{hat:E}) to compute (\ref{dssd}), and the estimations of the system parameters are given by
\begin{equation}
\begin{aligned}
&\left[\begin{array}{c}
\!\mathrm{vec}(\hat{A}_i)\!\\
\!\mathrm{vec}(\hat{B}_i)\!\\
\!\mathrm{vec}(\hat{G}_i)\!
\end{array}\right]=(\hat{\Phi}_1^{\mathrm{T}}\hat{\Phi}_1)^{-1})(\hat{\Phi}_1\hat{\chi}_1).
\end{aligned}
\end{equation}


% With the identified system matrices, the lienar matrix inequalities (LMIs) in can be solved for an initial stabilizer for each inner-loop itartion. The addmissibility of the obtained stabilizer is guaranteed by Theorem , which is proved in Appendix


% \begin{theorem}

% There exists $\varepsilon>0,\mu>0$, and $N_s^*(\varepsilon,\mu)>0$ such that for any $N_s>N_s^*(\varepsilon,\mu)$, the following LMIs
% \begin{subequations}
% \begin{align}
% \left[\begin{array}{cc}
% \!\!\!\hat{A}^{k-1}\!W\!+\!W\!(\hat{A}^{k-1})^{\!\mathrm{T}}\!+\!BV\!+\!V^{\mathrm{T}}\! {B}^{\mathrm{T}}&\!\! {C}W\!+\!DV\!\!\\
% \!\!\!WC^{\mathrm{T}}\!+\!V^{\mathrm{T}}\!D&\!\!-W\!\!\!
% \end{array}\right] \!<\! -\epsilon I \label{aa}\\
% \left[\begin{array}{cc}
% \!\!\!\hat{A}^{k-1}\!W\!+\!W\!(\hat{A}^{k-1})^{\!\mathrm{T}}\!+\!BV\!+\!V^{\mathrm{T}}\! {B}^{\mathrm{T}}&\!\! {C}W\!+\!DV\!\!\\
% \!\!\!WC^{\mathrm{T}}\!+\!V^{\mathrm{T}}\!D&\!\!-W\!\!\!
% \end{array}\right] \!<\! -\epsilon I \label{bb}
% \end{align}
% \end{subequations}
% have a solution and $K=VW^{-1}$ is a stablizer for a given $V^{k-1}$ almost surely.


% \end{theorem}

According to \cite{zhou1996robust,rami2000linear}, provided that the number of samples is sufficiently large, we can compute the stabilizing gains $\hat{K}_p^{(k,0)}=-YX^{-1}$ and $\hat{K}_{\pi}^{(k,0)}=-VW^{-1}$ for two iteration procedures by solving the following LMIs
\begin{equation}\label{eq:LMI1}
\!\!\!\!\!\left[\begin{array}{cc}
\!\!\!\hat{A}^{k-1}\!X\!+\!X\!(\hat{A}^{k-1})^{\!\mathrm{T}}\!+\!\hat{B}Y\!+\!Y^{\mathrm{T}}\! \hat{B}^{\mathrm{T}}&\!\! {C}X\!+\!DY\!\!\\
\!\!\!XC^{\mathrm{T}}\!+\!Y^{\mathrm{T}}\!D&\!\!-X\!\!\!
\end{array}\right] \!<\! -\epsilon I,
\end{equation}
% and
\begin{equation}\label{eq:LMI2}
\left[\begin{array}{cc}
\!\!\!\hat{A}_{\pi}^{k-1}\!W\!+\!W\!(\hat{A}_{\pi}^{k-1})^{\!\mathrm{T}}\!+\!\hat{B}V\!+\!V^{\mathrm{T}}\! \hat {B}^{\mathrm{T}}&\!\! 0\!\!\\
\!\!\!0\!&  -W\!\!\!
\end{array}\right] \!<\! -\epsilon I,
\end{equation}
respectively, where $\hat{A}^{k-1} = \hat{A}+\hat{G}\hat{L}_p^{k-1}$, $\hat{A}_{\pi}^{k-1} =\hat{A}-\hat{B}\hat{K}_p+G\hat{L}_p+G\hat{{L}}_{\pi}^{k-1}$, and $\epsilon>0$.

Finally, to compute the mean field state $\bar{x}(t)$, we set the disturbance input to zero, and the control input to 
\begin{equation}
u_\mathds{L}=-(\hat{K}_p+\hat{K}_{\pi})x_{\mathds{L}},
\end{equation}
where $\hat{K}_p$ and $\hat{K}_{\pi}$ are obtained from the iterative procedure. From (\ref{sys1}), the state dynamics evolve as
\begin{equation}
\mathrm{d}{x}_{\mathds{L}}\! =\! (A\!-\!B(\hat{K}_p\!+\!\hat{K}_{\pi}){x}_{\mathds{L}})\mathrm{d}t\!+\!(C\!-\!D(\hat{K}_p\!+\!\hat{K}_{\pi})){x}_{\mathds{L}}\mathrm{d}w_{\mathds{L}}.
\end{equation}
Then, the mean field approximation $\bar{x}$ can be computed as
\begin{equation}
\hat{\bar{x}}(t)\!=\!\frac{1}{N_s}\sum\nolimits_{j=1}^{N_s}\!{x}_{\mathds{L}}^j(t),~~t\geq0,
\end{equation}
where $x_{\mathds{L}}^j$ represents the $j$-th state sample of $\mathcal{A}_{\mathds{L}}$.
\section{Numerical example}\label{sec:simulation}
In this section, we present a numerical simulation to validate the effectiveness of the proposed algorithm. The large-scale population consists of $500$ agents, with the following system parameters
\begin{equation} \label{sys:simulation}
\begin{aligned}
&A=\left[\begin{array}{cc}
0.3&0.7\\
-0.9&0.5
\end{array}\right],~B= \left[\begin{array}{c}
0.2\\
0
\end{array}\right],~G=\left[\!\begin{array}{c}
0.1\\
0
\end{array}\right],~C=\left[\begin{array}{cc}
0.01&0.03\\
0.05&0.02
\end{array}\right],~D=\left[\!\begin{array}{cc}
0.05\\
0.05
\end{array}\!\right],
\end{aligned}
\end{equation}
where $x_i\in\mathbb{R}^2$, $u_i,v_i\in\mathbb{R}$, and $w_i$ is a standard one-dimensional Brownian motion. The initial state $x_i(0)$ is uniformly distributed on $[-4,0]\times[0,4]\subset\mathbb{R}^2$ with $Ex_i(0)=[-2,2]^{\mathrm{T}}$. 

The coefficients of the cost function (\ref{Jsoc}) are 
\begin{equation*}
\begin{aligned}
\!\!\!\!\!\!Q=\left[\begin{array}{cc}
10&0\\
0&10
\end{array}\right], \Gamma=\left[\begin{array}{cc}
0.9&0\\
0&0.9
\end{array}\right], R=1.25, \gamma = 2.
\end{aligned}
\end{equation*}
 

The data-driven method to derive decentralized strategies is implemented by begin collecting measurements from a selected agent $\mathcal{A}_{\mathds{L}}$. The control and disturbance inputs for this agent are designed as
\begin{equation}\label{u12}
\begin{aligned}
&K_{exp}=[6,-3],~~\xi^1(t)=5\sum_{j=1}^{100}\sin(w_jt),\\
&L_{exp}=[0,0],~~\xi^2(t)=10\sum_{j=1}^{100}\!\sin(\upsilon_jt),
\end{aligned}
\end{equation}
where $w_j\in[-100,100]$ and $\upsilon_j\in[-300,300]$ are randomly selected. The other parameters are set as follows: $T_s=0.001$ [sec], $T=0.1$ [sec], $[t_1,t_l]=[0,14]\text{~[sec]}$, and the convergence criterion $\varepsilon=10^{-5}$. The scalar on the right-hand side of the LMIs (\ref{eq:LMI1}) and (\ref{eq:LMI2}) are set to $\epsilon=5$.

The rank conditions (\ref{A:rank1}) and (\ref{A:rank2}) are verified using sample paths from the system (\ref{sys:simulation}) with (\ref{u12}) at the end of the data collection phase. The first iterative process then starts with the estimation of system parameters and stabilizing control inputs. Under the convergence criterion $\varepsilon$, the inner-loop iterations converge, and the final values are used to update $\{\hat{P}^k,\hat{L}^k,\hat{K}^k,\hat{\Lambda}^k\}$. The results of the outer-loop iterations are shown in Fig. \ref{f:rf1} (a)-(d), demonstrating convergence at the $4$-th iteration based on $\varepsilon=10^{-5}$. The second iterative process is then applied to obtain the sequences $\{\hat{\Pi}^k,\hat{L}_{\pi}^k,\hat{K}^k_{\pi}\}$, which also converge at the $4$-th iteration, as illustrated in Fig. \ref{f:rf1} (e)-(g). 

\begin{figure*}[!htb]
\centering
\includegraphics[scale=0.4]{rf1_1}
\centering
\caption{Determined parameters of the data-driven method.}\label{f:rf1}
\end{figure*}
\begin{figure*}[!htb]
\centering
\includegraphics[scale=0.4]{rf1_2}
\centering
\caption{State trajectories of the population with $(\hat{u}_i^o,\hat{v}_i^o)$.}\label{f:rf2}
\end{figure*}

\begin{table*}[!htb]
\begin{center}
  \begin{tabular}{|@{\  \hspace*{3mm}}l||*{7}{c|}}\hline
\multicolumn{1}{|@{}l||}{\backslashbox[0pt][l]{Iteration}{Errors}}
&\makebox[4em]{$\frac{\|\hat{P}^k-P^k\|}{\|P^k\|}$}&\makebox[4em]{$\frac{\|\hat{L}_p^k-L_p^k\|}{\|L_p^k\|}$}
&\makebox[4em]{$\frac{\|\hat{K}^k_p-K^k_p\|}{\|K^k_p\|}$}&\makebox[4em]{$\frac{\|\hat{\Lambda_p}^k-\Lambda_p^k\|}{\|\Lambda_p^k\|}$}&\makebox[4em]{$\frac{\|\hat{\Pi}^k-\Pi^k\|}{\|\Pi^k\|}$}&\makebox[4em]{$\frac{\|\hat{L}_{\pi}^k-{L}_{\pi}^k\|}{\|{L}_{\pi}^k\|}$}&\makebox[4em]{$\frac{\|\hat{K}_{\pi}^k-{K}_{\pi}^k\|}{\|{K}_{\pi}^k\|}$}\\\hline\hline
$k=1$ &$0.0023$& $0.0085$ & $0.0088$& $0.0107$& $0.0091$&$0.0129$&$0.0099$\\\hline
$k=2$ &$0.0047$& $0.0096$ & $0.0073$&$0.0044$&$0.0168$&$0.0172$&$0.0175$\\\hline
$k=3$ &$0.0050$& $0.0104$ &$0.0069$&$0.0040$&$0.0168$&$0.0173$&$0.0175$\\\hline
$k=4$ &$0.0050$& $0.0104$ &$0.0069$&$0.0040$&$0.0168$&$0.0173$&$0.0175$\\\hline
\end{tabular}
\end{center}
\caption{ Estimation errors of the data-driven method.}\label{e1tab1}
\end{table*}

To verify the robustness of the data-driven method, we compare the results with one from the model-based dual-loop algorithm, denoted by $\{P^k,L^k,K^k,\Lambda^k,\Pi^k,L_{\pi}^k,K_{\pi}^k\}$ and summarize the estimation errors in Table. \ref{e1tab1}. Note that both model-based dual-loop iterations are convergent at $4$-th iteration under the convergence criterion $\varepsilon=10^{-5}$. The small error values indicate that the approximations from the data-driven method closely match the model-based results. It demonstrates that despite minor disturbances introduced by the data-driven estimations, the inner-loop still converges to values within a small range of the true values. Furthermore, the convergence of the outer-loop iterations under a given convergence criterion highlights the uniform convergence of the overall iterative processes.
 
Then, the control strategy $\hat{u}_{\mathds{L}}=-(\hat{K}+\hat{K}_{\pi})x_{\mathds{L}}$ and the disturbance strategy $\hat{v}_{\mathds{L}}=(\hat{L}+\hat{L}_{\pi})x_{\mathds{L}}$ applied to drive $\mathcal{A}_{\mathds{L}}$. The approximated mean field state trajectories are obtained by averaging the state sample paths, as shown in Fig. \ref{f:rf1} (h).  

Finally, the mean field social optimum are approximated as 
\begin{numcases}{}
\hat{u}_i^o = -\hat{K}x_i(t)-\hat{K}_{\pi}\hat{\bar{x}}(t),\\
\hat{v}_i^o = \hat{L}x_i(t)+\hat{L}_{\pi}\hat{\bar{x}}(t),~1\leq i\leq500,
\end{numcases}
and are used across the population. The resulting the state trajectories, shown in Fig. \ref{f:rf2}. It can be seen that the average state trajectories of the population are closely match the approximated mean field state trajectories, thereby verifying the consistency condition. 

\section{Conclusion} \label{sec:conclusion}
In the LQG setting, the solution of robust MFSC problem is reduced to solving indefinite Riccati-type equations that govern the gain matrices and an ordinal differential equation that describes the evolution of the mean field state. This reduction enables us to compute the robust social optimum strategies by developing a data-driven method. Notably, the proposed dual-loop framework is robust against disturbances encountered during the iterative process, and the uniform convergence of the overall algorithm is rigorously proven. Moreover, this framework is not only applicable for achieving the asymptotic robust social optimality, but also for solving other robust control or $H_{\infty}$ control problems that involve these types of Riccati equations as part of the optimal solution.
 
\appendices  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed
% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)

\section{Auxiliary results}\label{Auxiliary results}
\begin{lemma}[\cite{cui2024robust,wang1986trace}]\label{thm3:lem1}
Let $X$ and $Y$ be symmetric matrices of compatible dimensions. If $X\geq0$, then the following results hold: 1). $\lambda_{\max}(X)=\|X\|_2$; 2). $\lambda_{\min}(Y)\mathrm{Tr}(X)\leq \mathrm{Tr}(XY)\leq \lambda_{\max}(Y)\mathrm{Tr}(X)$; 3). $\|X\|_F\leq \mathrm{Tr}(X)\leq\sqrt{n}\|X\|_F,\|X\|_2\leq \mathrm{Tr}(X)\leq n \|X\|_2$.
\end{lemma}

\begin{lemma}\label{thm3:lem2}
The function $\mathds{X}_{\boldsymbol{L}_i}(\boldsymbol{L}_i)$ is continuous for any $\!\boldsymbol{L}_i\!\in\!\mathcal{W}$.
\end{lemma}

\bproof
Define the function $\mathcal{F}_i:\mathds{R}^{m_2\times n}\times \mathbb{S}^n\mapsto\mathbb{S}^n$ by the left-hand side of equation~\eqref{general:oueter-loop}, which can be written as
\begin{equation*}
\mathcal{F}_i =\mathcal{F}_i^1(\boldsymbol{L}_i,\mathds{X}_{\boldsymbol{L}_i})+\mathcal{F}_i^2(\mathds{X}_{\boldsymbol{L}_i})+\mathds{Q}-\|\boldsymbol{L}_i\|_{\mathds{W}}^2,
\end{equation*}
where 
\begin{equation*}
\left\{\begin{aligned}
&\mathcal{F}_i^1\!=\! (\mathds{A}\!+\!\mathds{G}\boldsymbol{L}_i)^{\!\mathrm{T}}\mathds{X}_{\boldsymbol{L}_i}\!+\!\mathds{X}_{\boldsymbol{L}_i}\!(\mathds{A}\!+\!\mathds{G}\boldsymbol{L}_i)\!+\!\mathds{C}_i^{\mathrm{T}}\!\mathds{X}_{\boldsymbol{L}_i}\mathds{C}_i,\\
&\mathcal{F}_i^2 \!= \!-(\mathds{X}_{\boldsymbol{L}_i} \mathds{B}\!+\!\mathds{C}_i^{\mathrm{T}} \mathds{X}_{\boldsymbol{L}_i}\mathds{D}_i)\boldsymbol{R}_i^{-1} (\mathds{B}^{\mathrm{T}}\!\mathds{X}_{\boldsymbol{L}_i}\!+\!\mathds{D}_i^{\mathrm{T}}\mathds{X}_{\boldsymbol{L}_i}\mathds{C}_i).
\end{aligned}\right.
\end{equation*}
By using the Kronecker product, the derivative of $\mathrm{vec}(\mathcal{F}_i^{1})$ with respect to $\mathrm{vec}(\mathds{X}_{\boldsymbol{L}_i})$ can be expressed as
\begin{equation}\label{fi1}
\!\!\!\!\frac{\partial \mathrm{vec}(\mathcal{F}_i^1)}{\partial \mathrm{vec}(\mathds{X}_{\boldsymbol{L}_i})}\!\!=\!\!\left(\! (\mathds{A}\!+\!\mathds{G}\boldsymbol{L}_i) \!\otimes \!I\!+\!I\!\otimes\!(\mathds{A}\!+\!\mathds{G}\boldsymbol{L}_i)\!+\!\mathds{C}_i\!\otimes\!\mathds{C}_i \right)^{\!\mathrm{T}}\!\!.
\end{equation}
By using the matrix inverse derivative identity and equation~\eqref{general:oueter-loop2}, the differential of $\mathcal{F}_i^2$ can be computed by
\begin{equation*}
\begin{aligned}
\!\!\!\!\!\!\mathrm{d}\mathcal{F}_i^2 \!=\! &-(\mathrm{d} \mathds{X}_{\boldsymbol{L}_i}\!\mathds{B}\!+\!\mathds{C}_i^{\mathrm{T}}\!\mathrm{d}\mathds{X}_{\boldsymbol{L}_i}\!\mathds{D}_i)\mathds{K}_{\boldsymbol{L}_i}\!+\!(\mathds{K}_{\boldsymbol{L}_i})^{\!\mathrm{T}}\!\mathds{D}_i^{\mathrm{T}}\!\mathrm{d}\mathds{X}_{\boldsymbol{L}_i}\!\mathds{D}_i\mathds{K}_{\boldsymbol{L}_i}-(\mathds{K}_{\boldsymbol{L}_i})^{\mathrm{T}}\!( \mathds{B}^{\mathrm{T}}\!\mathrm{d}\mathds{X}_{\boldsymbol{L}_i}\!+\!\mathds{D}_i^{\mathrm{T}}\!\mathrm{d}\mathds{X}_{\boldsymbol{L}_i}\!\mathds{C}_i).
\end{aligned}
\end{equation*}
Vectorizing $\mathrm{d}\mathcal{F}_i^2$ to express it in terms of $\mathrm{d}\mathrm{vec}(\mathds{X}_{\boldsymbol{L}_i})$ yields
\begin{equation}\label{fi2}
\begin{aligned}
\!\!\!\!\frac{\mathrm{d}\mathrm{vec}(\mathcal{F}_i^2)}{\mathrm{d}\mathrm{vec}(\mathds{X}_{\boldsymbol{L}_i})} &\!\!=\! \!-\!\Big((\mathds{B}\mathds{K}_{\boldsymbol{L}_i})\!\otimes\!I\!\!+\!\!I\!\otimes\!(\mathds{B}\mathds{K}_{\boldsymbol{L}_i})\!\!+\!\!(\mathds{D}_i \mathds{K}_{\boldsymbol{L}_i})\!\otimes\!\mathds{C}_i+\!\mathds{C}_i\!\otimes\!(\mathds{D}_i \mathds{K}_{\boldsymbol{L}_i})\!-\!(\mathds{D}_i \mathds{K}_{\boldsymbol{L}_i})\!\otimes\!(\mathds{D}_i \mathds{K}_{\boldsymbol{L}_i}) \Big)^{\mathrm{T}}.
\end{aligned}
\end{equation}
Putting results (\ref{fi1}) and (\ref{fi2}) together, we can obtain the Jacobian matrix $\frac{\partial\mathrm{vec}(\mathcal{F}_i)}{\partial \mathrm{vec}(\mathds{X}_{\boldsymbol{L}_i})}$ satisfies the  equation $\frac{\partial \mathrm{vec}(\mathcal{F}_i)}{\partial \mathrm{vec}(\mathds{X}_{\boldsymbol{L}_i})}= \mathds{M}_i$, where $\mathds{M}_i= ((\mathds{A}+\mathds{G}\boldsymbol{L}_i-\mathds{B}\mathds{K}_{\boldsymbol{L}_i})\otimes I+I\otimes (\mathds{A}+\mathds{G}\boldsymbol{L}_i-\mathds{B}\mathds{K}_{\boldsymbol{L}_i})+(\mathds{C}_i-\mathds{D}_i\mathds{K}_{\boldsymbol{L}_i})\otimes (\mathds{C}_i-\mathds{D}_i\mathds{K}_{\boldsymbol{L}_i}))^{\mathrm{T}}$.
 

Since $\boldsymbol{L}_i\in\mathcal{W}$, we have $\sigma(\mathscr{L}_{[\mathds{K}_{\boldsymbol{L}_i},\boldsymbol{L}_i,\mathcal{S}_i]})\subset \mathbb{C}^-$, which implies that the matrix $\mathds{M}_i$ is Hurwitz. Consequently, the Jacobian matrix $\frac{\partial \mathrm{vec}(\mathcal{F}_i)}{\partial \mathrm{vec}(\mathds{X}_{\boldsymbol{L}_i})}$ is invertible. 

By the implicit function theorem \cite{krantz2002implicit}, there exists a continuously differentiable function $\mathds{X}_{\boldsymbol{L}_i}(\boldsymbol{L}_i)$ such that $\mathcal{F}_i(\boldsymbol{L}_i,\mathds{X}_{\boldsymbol{L}_i}(\boldsymbol{L}_i))=0$. Therefore, $\mathds{X}_{\boldsymbol{L}_i}$ is continuous with respect to $\boldsymbol{L}_i$ for any $\boldsymbol{L}_i\in\mathcal{W}$.
\eproof

\begin{lemma}\label{thm3:lem3}
1). For any $\zeta\geq0$, the set $\mathcal{D}_{\zeta}$ is compact. 2). For any $\rho\geq0$ and any fixed matrix $\boldsymbol{L}_i\in\mathcal{W}$, the set ${\mathcal{G}}_{{\rho}}(\boldsymbol{L}_i)$ is compact.
\end{lemma} 

\bproof
We can easily verify that each set is both closed and bounded. Therefore, by the Heine-Borel theorem (\!\!\cite[Theorem 2.41]{rudin1964principles}), $\mathcal{D}_{\zeta}$ and ${\mathcal{G}}_{{\rho}}(\boldsymbol{L}_i)$ are compact.
\eproof

% \begin{lemma}\label{thm3:lem3-1}
%  For any $\rho\geq0$, the set ${\mathcal{G}}_{{\rho}}(\boldsymbol{L}_i)$ is compact.
% \end{lemma}
% \bproof
% Utilizing equation~\eqref{general:inner-loop} and Lemma \ref{thm3:lem3}, it is straightforward to verify that the set ${\mathcal{G}}_{{h}}(\boldsymbol{L}_i)$ is both bounded and closed. Hence, by \cite[Theorem 2.41]{rudin1964principles}, $\mathcal{G}_{\rho}(\boldsymbol{L}_i)$ is compact.
% \eproof
  
% \begin{lemma}[\cite{sun2020stochastic}]\label{thm3:lem4-1}
% The spectrum of $\mathscr{L}_{[\boldsymbol{K}_i,\boldsymbol{L}_i,\mathcal{S}_i]}$ lies within $\mathbb{C}^-$ if and only if there exists a $\boldsymbol{X}>0$ such that
% \begin{equation}\label{lem:Lyafun}
% \mathscr{L}_{[\boldsymbol{K}_i,\boldsymbol{L}_i,\mathcal{S}_i]}(\boldsymbol{X})<0.
% \end{equation}
% \end{lemma}
 

\begin{lemma}\label{thm3:lem4}
Let $\zeta\geq0$ and $\rho\geq0$. For all matrices $\boldsymbol{L}_i\in\mathcal{D}_{\zeta}$ and $\boldsymbol{K}_i\in{\mathcal{G}}_{\rho}(\boldsymbol{L}_i)$, consider the solution $\{\Phi(t),t\geq0\}$ to the matrix SDE
\begin{equation}\label{X_i(t):V}
\!\!\!\!\!\!\left\{\begin{aligned}
\!\!\!&\mathrm{d}\Phi \! =\! (\mathds{A}\!-\!\mathds{B}\boldsymbol{K}_i\!+\!\mathds{G}\boldsymbol{L}_i)\Phi\mathrm{d}t\!+\!(\mathds{C}_i\!-\!\mathds{D}_i\boldsymbol{K}_i)\Phi\mathrm{d}{\boldsymbol{w}},\\
&\Phi(0)=I.
\end{aligned}\right.
\end{equation}
Define 
\begin{equation}\label{eq:mathdsP}
\mathds{P}=\mathbb{E}\left[\int_{0}^{\infty}\Phi(t)\Phi(t)^{\mathrm{T}}\mathrm{d}t\right].
\end{equation}
Then there exists $\overline{b},\underline{b}>0$ such that 
\begin{equation}
\underline{b}\leq \lambda_{\min}(\mathds{P}) \leq \mathrm{Tr}(\mathds{P}) \leq \overline{b}.
\end{equation}  
\end{lemma}

\bproof 
Define $S(t) = \mathbb{E}\left[\Phi(t)\Phi(t)^{\mathrm{T}}\right]$. By applying It\^{o}'s formula to $\Phi(t)\Phi(t)^{\mathrm{T}}$, one has
\begin{equation}\label{eq:ds}
\frac{{\mathrm{d}}S(t)}{{\mathrm{d}t}}=\mathscr{L}_{[\boldsymbol{K}_i,\boldsymbol{L}_i,\mathcal{S}_i]}^*(S(t)),
\end{equation}
which satisfies that $S(0)=I$ and $S(\infty)=\lim_{t\rightarrow\infty}S(t)=0$. 

Since $\mathds{P}=\int_0^{\infty}S(\tau)\mathrm{d}\tau$, integrating both sides of equation~\eqref{eq:ds} over $[0,\infty)$ and taking the transpose gives
% \begin{equation}\label{dsdt2}
% \int_0^{\infty}\frac{\mathrm{d}}{\mathrm{d}t}S(t)\mathrm{d}t = S(\infty)-S(0)=-I.
% \end{equation}
% Substituting (\ref{eq:ds}) into (\ref{dsdt2}) yields
\begin{equation} \label{sys:P}
\mathscr{L}_{[\boldsymbol{K}_i,\boldsymbol{L}_i,\mathcal{S}_i]}(\mathds{P}) +I=0.
\end{equation}
	By $\sigma(\mathscr{L}_{[\boldsymbol{K}_i,\boldsymbol{L}_i,\mathcal{S}_i]})\subset\mathbb{C}^-$ and \cite[Theorem 3.2.3]{sun2020stochastic}, $\mathds{P}$ is positive definite solution to equation (\ref{sys:P}).


Furthermore, by the compactness of $\mathcal{D}_{\zeta}$ and ${G}_{{\rho}}(\boldsymbol{L}_i)$ (Lemmas \ref{thm3:lem3}) and the continuity of the map $(\boldsymbol{L}_i,\boldsymbol{K}_i)\mapsto \mathds{P}$, there exist uniform constants $\underline{b},\overline{b}>0$ (independent of $\boldsymbol{L}_i$ and $\boldsymbol{K}_i$) such that $\underline{b}\leq \lambda_{\min}(\mathds{P}) \leq \mathrm{Tr}(\mathds{P}) \leq \overline{b}$ hold for all $\boldsymbol{L}_i\in\mathcal{D}_{\zeta}$ and $\boldsymbol{K}_i\in {G}_{\rho}(\boldsymbol{L}_i)$. 
\eproof
 \vspace{-0.3cm}
\section{Proof of Theorem \ref{thm:rate-outer-loop}}\label{thmpf:rate-outer-loop}
We begin by showing that for any $\zeta>0$ and any $\mathds{L}_i^{k-1}\in\mathcal{D}_{\zeta}$, there exists a $a(\zeta)>0$ such that 
\begin{equation}\label{a(delta)}
\|\Delta\mathds{X}_i^k\|_F\leq a(\zeta)\|\Xi_i^k\|_F,
\end{equation}
where $\Xi_i^k = \|\tilde{\mathds{L}}_i^{k-1}\|_{\mathds{W}}^2$.
 
To establish this, we first apply (\ref{GARE0}) and (\ref{outer_eq}) to obtain
\begin{equation*}
\begin{aligned}
&\mathscr{L}_{[\mathds{K}_i,\mathds{L}_i,\mathcal{S}_i]}(\Delta\mathds{X}_i^k)\!-\!\|\Delta\mathds{L}_i^k\|_{\mathds{W}}^2+ \Xi_i^k\!+\!\|\Delta\mathds{K}_i^{k}\|^2_{\mathds{R}_i^{k}}=0.
\end{aligned}
\end{equation*}
By using the facts that $(\mathds{L}_i,\mathds{K}_i)\in\mathcal{D}_0\times {\mathcal{G}}_{0}(\mathds{L}_i)$ and $\mathds{W}>0$, and Lemmas \ref{thm3:lem1} and \ref{thm3:lem4}, the above equation yields 
\begin{equation}\label{0928-2}
\mathrm{Tr}(\Delta\mathds{X}_i^k)\leq \overline{b}\mathrm{Tr}(\Xi_i^k)+\overline{b}\mathrm{Tr}\left(\|\Delta\mathds{K}_i^k\|^2_{\mathds{R}_i^k}\right).
\end{equation}
Proceeding similarly to the derivation of \eqref{ktilde}, we have
\begin{equation*} 
\begin{aligned}
\Delta\mathds{K}_i^k=\mathds{R}_i^{-1}(\mathds{B}^{\mathrm{T}}\Delta\mathds{X}_i^k+\mathds{D}_i^{\mathrm{T}}\Delta\mathds{X}_i^k\mathds{C}_i^k),
\end{aligned}
\end{equation*}
which then gives $\mathrm{Tr}\left(\|\Delta\mathds{K}_i^k\|_{\mathds{R}_i^k}^2\right)\leq \beta_1^k \|\Delta \mathds{X}_i^k\|_2\mathrm{Tr}(\Delta\mathds{X}_i^k)$, where $\beta_1^k =\|\mathds{R}_i^{-1}\|_2^2\|\mathds{R}_i^{k}\|_2\left(\|\mathds{B}\|_2+\|\mathds{C}_i^k\|_2\|\mathds{D}_i\|_2\right)^2$. Since $\mathds{R}_i^{k}$ and $\mathds{C}_i^k$ are continuous with respect to $\mathds{X}_i^{k}$, and $\mathds{X}_i^{k}$ is continuous in $\mathds{L}_i^{k-1}\in\mathcal{D}_{\zeta}$ (Lemma \ref{thm3:lem2}), while $\mathcal{D}_{\zeta}$ is compact (Lemma \ref{thm3:lem3}), it follows that there exist a $b_1>0$ such that $\beta_1^k \leq b_1$ for all $\mathds{L}_i^{k-1}\in\mathcal{D}_{\zeta}$. Consequently, equation (\ref{0928-2}) becoming 
\begin{equation}\label{ineq:DeltaX_1^k}
\mathrm{Tr}(\Delta \mathds{X}_i^k)\leq\overline{b}\mathrm{Tr}(\Xi_i^k)+\overline{b} b_1\|\Delta\mathds{X}_i^k\|_2\mathrm{Tr}(\Delta\mathds{X}_i^k).
\end{equation}
Let $\eta = \frac{1}{2\overline{b}b_1}$. If $\|\Delta \mathds{X}_i^k\|_2\leq \eta $, one has
\begin{equation}\label{ineq1:Xi_i^k}
\|\Delta \mathds{X}_i^k\|_F\leq 2\overline{b} \mathrm{Tr}(\Xi_i^k)\leq 2\overline{b}\sqrt{n}\|\Xi_i^k\|_F.
\end{equation}
If $\|\Delta \mathds{X}_i^k\|_2\geq\eta$, since $\mathcal{D}_{\zeta}$ is compact, the subset $\mathcal{D}_{\zeta}\cap\{\mathds{L}_i^{k-1}\in\mathcal{W}|\|\Delta\mathds{X}_i^k\|_2\geq \eta \}$ is also compact. Next we prove $\Xi_i^k\neq0$ by contradiction method. Suppose otherwise, $\Xi_i^k=0$ implies $\mathds{L}_i^k=\mathds{L}_i^{k-1}$ due to $\mathds{W}>0$. It follows from equations (\ref{outer_eq}) and (\ref{outer_eq2}) that $\mathds{X}_i^{k}\geq0$ is the solution of equation (\ref{are_operator}). Thus, $\mathds{X}_i^k=\mathds{X}_i$ is  followed with the uniqueness of the solution to (\ref{are_operator}), which results in $\Delta \mathds{X}_i^k=0$. It contradicts with the condition that $\|\Delta \mathds{X}_i^k\|_2\geq\eta$. Therefore, we have $\Xi_i^k\neq0$, leading to $\|\Xi_i^k\|_F\neq0$. According to the extreme value theorem \cite{rudin1964principles}, it is immediately concluded that there exists $\epsilon(\zeta)>0$ such that $\|\Xi_i^k\|_F\geq \epsilon(\zeta)$. Thus,
 \begin{equation}\label{ineq2:Xi_i^k}
 \|\Delta \mathds{X}_i^k\|_F\leq \mathrm{Tr}(\Delta \mathds{X}_i^k)\leq \frac{\zeta}{\epsilon(\zeta)}\|\Xi_i^k\|_F.
 \end{equation}
Putting both cases together, if we set $a(\zeta)\!=\!\max(2\overline{b}\sqrt{n},\frac{\zeta}{\epsilon(\zeta)})$, then (\ref{ineq1:Xi_i^k}) and (\ref{ineq2:Xi_i^k}) together imply $\|\Delta\mathds{X}_i^k\|_F\!\leq\!a(\zeta)\|\Xi_i^k\|_F$.
  
Finally, using (\ref{th1eq7}), we have
\begin{equation}\label{0915-1}
\mathscr{L}_{[{\mathds{K}}_i^{k+1},\mathds{L}_i^{k},\mathcal{S}_i]}(\tilde{\mathds{X}}_i^{k})+\Xi_i^{k}+\|\tilde{\mathds{K}}_i^k\|_{\mathds{R}_i^k}^2=0.
\end{equation}
By Lemma \ref{lemma:W} and $\mathds{L}_i^{k-1}\in\mathcal{D}_{\zeta}\subseteq\mathcal{W}$, it follows that the spectrum $\sigma(\mathscr{L}_{[\mathds{K}_i^{k+1},\mathds{L}_i^{k},\mathcal{S}_i]})\subset\mathbb{C}^{-}$. Then, applying Lemmas \ref{thm3:lem1} and \ref{thm3:lem4} once again leads to
\begin{equation}\label{ineq:Xi_k-1}
\mathrm{Tr}(\tilde{\mathds{X}}_i^{k})\geq {\underline{b}}\|\Xi_i^{k}\|_F.
\end{equation}
From  equations (\ref{a(delta)}) and (\ref{ineq:Xi_k-1}), we obtain
\begin{equation}\label{92}
\begin{aligned}
\mathrm{Tr}(\Delta\mathds{X}_i^{k+1})\leq \left(1-\frac{\underline{b}}{\sqrt{n}a(\zeta)}\right)\mathrm{Tr}(\Delta\mathds{X}_i^{k}).
\end{aligned}
\end{equation}
By setting $\alpha(\zeta) = 1- \frac{\underline{b}}{\sqrt{n}a(\zeta)}$, we conclude that (\ref{eq:resul_thm_rate-outer-loop}) is satisfied. Moreover, since $a(\zeta)\geq 2\overline{b}\sqrt{n}$ and $0<\underline{b}/\overline{b}<1$, one has $\frac{\underline{b}}{\sqrt{n}a(\zeta)}\in(0,1)$, which implies $\alpha(\zeta)\in(0,1)$. \hfill $\square$
\vspace{-0.3cm}
\section{Proof of Theorem \ref{thm:rate-inner-loop}}\label{thmpf:rate-inner-loop}

By using $\mathscr{L}_{[\mathds{K}_i^k,\mathds{L}_i^{k-1},\mathcal{S}_i]}$ and completing the squares, we can write equation (\ref{inner_PE}) as 
\begin{equation*} 
\begin{aligned}
&\mathscr{L}_{[\mathds{K}_i^k,\mathds{L}_i^{k-1},\mathcal{S}_i]}\!(\mathds{X}_i^{(k,j)})\!\!+\!\!\Xi_i^{(k,j)}\!\!-\!\|\!\Delta\!\mathds{K}_i^{(k,j)}\!\|_{\mathds{R}_i^{(k,j)}}\!\!+\!\!\mathds{Q}_i^{k-1}\!\!+\!\!\|\!\mathds{K}_i^k\!\|_{\mathds{R}}^2\!=\!0,
\end{aligned}
\end{equation*}
where $\Xi_i^{(k,j)}=\|\tilde{\mathds{K}}_i^{(k,j-1)}\|_{\mathds{R}_i^{(k,j)}}^2$. \\
Subtracting equation (\ref{are_operator1}) from the above equation yields
\begin{equation}\label{eq1} 
\mathscr{L}_{[\mathds{K}_i^k,\mathds{L}_i^{k-1},\mathcal{S}_i]}(\Delta\mathds{X}_i^{(k,j)})\!+\!\Xi_i^{(k,j)}\!-\!\|\Delta\mathds{K}_i^{(k,j)}\|_{\mathds{R}_i^{(k,j)}}^2=0.
\end{equation}
By applying Lemmas \ref{thm3:lem1} and \ref{thm3:lem4} and $\mathds{R}_i^{(k,j)}>0$, equation (\ref{eq1}) implies
\begin{equation*}
\mathrm{Tr}\left(\Delta\mathds{X}_i^{(k,j)}\right) \leq \overline{b}\|\Xi_i^{(k,j)}\|_F.
\end{equation*}
On the other hand, since $\mathds{K}_i^{(k,j-1)}\in\mathcal{G}_{\rho}(\mathds{L}_i^{k-1})\subseteq\mathcal{Z}(\mathds{L}_i^{k-1})$ gives rise to $\mathds{K}_i^{(k,j)}\in\mathcal{Z}(\mathds{L}_i^{k-1})$, we can call (\ref{eq:0924-1}) to obtain
\begin{equation*}
\mathrm{Tr}\left(\tilde{\mathds{X}}_i^{(k,j)}\right)\geq \underline{b}\|\Xi_i^{(k,j)}\|_F.
\end{equation*}
Hence,
\begin{equation*}
\begin{aligned}
\mathrm{Tr}(\Delta\mathds{X}_i^{(k,j+1)})\leq(1-\underline{b}/\overline{b})\mathrm{Tr}(\Delta\mathds{X}_i^{(k,j)}).
\end{aligned}
\end{equation*}
By setting $\tilde{\alpha}=1-\underline{b}/\overline{b}\in(0,1)$, the proof is complete.\hfill $\square$

 

% \section{Proof of Theorem \ref{thm:quadratic-rate-inner-loop}}\label{thmpf:quadratic-rate-inner-loop}
 
% Since $\mathds{K}_i^{(k,j-1)}\!\in\!\mathcal{D}_{\tilde{\delta}}(\mathds{L}_i^{k-1})$, we have $\sigma(\mathscr{L}_{[\mathds{K}_i^{(k,j-1)},\mathds{L}_i^{k-1},\mathcal{S}_i]})$ $\subset\mathbb{C}^-$.

% Using the Kronecker product, equation (\ref{mathscrL}) can be rewritten as
% \begin{equation}\label{eq1:th4mpf}
% \begin{aligned}
% \!\!\!\!\!\!\!\mathcal{M}_i^{(k,j-1)}\mathrm{vec}(\mathds{X}_i^{k,j+1}\!-\!\mathds{X}_i^k)\!=\!-\mathrm{vec}(\|\mathds{K}_i^{(k,j)}\!-\!\mathds{K}_i^{k}\|_{\mathds{R}_i^k}^2),
% \end{aligned}
% \end{equation}
% where $\Delta \mathds{X}_i^{(k,j+1)} = \mathds{X}_i^{(k,j+1)}-\mathds{X}_i^k$, and 
% \begin{equation*}
% \begin{aligned}
% &\mathcal{M}_i^{(k,j)} = \left(I_n\otimes\mathds{A}_i^{(k,j)}+ \mathds{A}_i^{(k,j)}\otimes I_n+ \mathds{C}_i^{(k,j)} \otimes \mathds{C}_i^{(k,j)}\right)^{\mathrm{T}}.
% % &\mathds{A}_{i}^{(k,j)}= \mathds{A}-\mathds{B}\mathds{K}_i^{(k,j)}+\mathds{G}\mathds{L}_i^{k-1},\quad\mathds{C}_i^{(k,j)}=\mathds{C}_i-\mathds{D}_i\mathds{K}_i^{(k,j)}.
% \end{aligned}
% \end{equation*}
% Using (\ref{inner_PI}), we have
% \begin{equation}\label{eq:0917-2}
% \begin{aligned}
% \|\mathds{K}_i^{(k,j)}-\mathds{K}_i^{k}\|_{\mathds{R}_i^k}^2=\ell_1(\Delta \mathds{X}_i^{(k,j)})+\ell_2(\Delta \mathds{X}_i^{(k,j)}),
% \end{aligned}
% \end{equation}
% where
% \begin{equation*}
% \left\{\begin{aligned}
% \ell_1 &\! =\! \mathcal{K}(\Delta \mathds{X}_i^{(k,j)})^{\!\mathrm{T}}\!(\mathds{R}_i^{(k,j)})^{\!-1}\!\mathcal{K}(\Delta \mathds{X}_i^{(k,j)})\!+\!\mathcal{K}(\mathds{X}_i^{(k,j)})^{\!\mathrm{T}}\\
% &\times(\mathds{R}_i^{k})^{\!-1}\!\mathds{D}^{\mathrm{T}}\Delta \mathds{X}_i^{(k,j)}\mathds{D}\!(\mathds{R}_i^{(k,j)})^{\!-1}\!\mathds{D}^{\mathrm{T}}\Delta \mathds{X}_i^{(k,j)}\mathds{D}\\
% &\times(\mathds{R}_i^{(k,j)})^{\!-1}\!\mathcal{K}(\mathds{X}_i^{(k,j)})+\mathcal{K}(\mathds{X}_i^{(k,j)})^{\mathrm{T}}(\mathds{R}_i^{k})^{\!-1}\!\mathds{D}^{\mathrm{T}}\\
% &\times \Delta \mathds{X}_i^{(k,j)}\mathds{D}(\mathds{R}_i^{(k,j)})^{\!-1}\!\mathcal{K}(\Delta \mathds{X}_i^{(k,j)})+\mathcal{K}(\Delta \mathds{X}_i^{(k,j)})^{\mathrm{T}}\\
% &\times(\mathds{R}_i^{k})^{\!-1}\!\mathds{D}^{\mathrm{T}}\Delta X_i^{(k,j)}\mathds{D}(\mathds{R}_i^{(k,j)})^{\!-1}\!\mathcal{K}(\mathds{X}_i^{(k,j)}),\\
% \ell_2 &\!= \!\mathcal{K}(\Delta \mathds{X}_i^{(k,j)})^{\!\mathrm{T}}\!(\mathds{R}_i^{k})^{\!-1}\!\mathds{D}^{\!\mathrm{T}}\!\Delta\!\mathds{X}_i^{(k,j)}\!\mathds{D} (\mathds{R}_i^{(k,j)})^{\!-1}\!\mathcal{K}(\Delta \mathds{X}_i^{(k,j)}),\\
% \!\!\!\!\!\!\mathcal{K}&(X) = (\mathds{B}^{\mathrm{T}}X+\mathds{D}_i^{\mathrm{T}}X\mathds{C}_i).
% \end{aligned}\right.
% \end{equation*}

% Substituting (\ref{eq:0917-2}) into (\ref{eq1:th4mpf}) and taking norm of both sides to derive
% \begin{equation}\label{eq:0917-3}
% \begin{aligned}
% \!\!\!\|\Delta \mathds{X}_i^{(k,j+1)}\| \!\leq \!\|(\mathcal{M}_i^{(k,j)})^{-1}\| \left(\|\ell_1 \|_F\!+\!\|\ell_2 \|_F\right),
% \end{aligned}
% \end{equation}
% where
% \begin{equation*}
% \left\{\begin{aligned}
% &\|\ell_1\|_F\leq \|\mathds{R}^{-1}\|_F(\|\mathds{B}\|_F+\|\mathds{C}_i\|_F\|\mathds{D}_i\|_F)^2 \\
% &~~~~~~~~~~~~\times(1+\|\mathds{R}^{-1}\|\|\mathds{D}_i\|_F^2\|\mathds{X}_i^{(k,j)}\|_F)^2\|\Delta \mathds{X}_i^{(k,j)}\|_F^2,\\
% &\|\ell_2\|_F\!\leq\!\tilde{\delta}\|\mathds{R}^{-1}\!\|_F^2\|\!D_i\!\|_F^2(\|\mathds{B}\|_F\!+\!\|\mathds{C}_i\|_F\!\|\mathds{D}_i\|_F)^2\!\|\!\Delta\!\mathds{X}_i^{(k,j)}\!\|_F^2.
% \end{aligned}\right.
% \end{equation*}


% Since $\mathcal{M}_i^{(k,j)}$ and $\mathds{X}_i^{(k,j)}$ are continuous in $\mathds{K}_i^{(k,j-1)}\in\widetilde{\mathcal{D}}_{\tilde{\delta}}(\mathds{L}_i^{k-1})$ and the sets ${\mathcal{D}}_{{\delta}}(\mathds{L}_i^{k-1})$ and $\widetilde{\mathcal{D}}_{\tilde{\delta}}(\mathds{L}_i^{k-1})$ are compact. It follows from continuity of matrix norm and matrix inverse that there exists $d_2,d_3>0$ such that $\|(\mathcal{M}_i^{(k,j)})^{-1}\|_2\leq d_2$, $\|\mathds{X}_i^{(k,j)}\|_F^2\leq d_3$ for all $\mathds{K}_i^{(k,j-1)}\in\widetilde{\mathcal{D}}_{\tilde{\delta}}(\mathds{L}_i^{k-1})$ and $\mathds{L}_i^{k-1}\in\mathcal{D}_{\delta}$.




% Thus, it follows from (\ref{eq:0917-3}) that
% \begin{equation*}
% \begin{aligned}
% \|\Delta X_i^{(k,j+1)}\|\leq \zeta(\tilde{\delta})\|\Delta X_i^{(k,j)}\|_F^2,
% \end{aligned}
% \end{equation*}
% where $\zeta(\tilde{\delta}) \!=\!  d_2\|\mathds{R}^{\!-1}\|_F(\|\mathds{B}\|_F\!+\!\|\mathds{C}_i\|_F\|\!\mathds{D}_i\|_F)^{\!2}(1\!+\!d_3\|\mathds{R}^{\!-1}\|$ $\|\mathds{D}_i\|_F^2)$   $+d_2\tilde{\delta}\|\mathds{R}^{-1}\|_F^2\|\mathds{D}_i\|_F^2(\|\mathds{B}\|_F\!+\!\|\mathds{C}_i\|_F\|\mathds{D}_i\|_F)^2$.  \hfill$\square$

\section{Proof of Theorem \ref{thm:robust-outer-loop}}\label{thmpf:robust-outer-loop}
Before proving Theorem \ref{thm:robust-outer-loop}, we establish an important intermediate result.
\begin{lemma}\label{lem:invariant set}
For any $\zeta>0$, let $\hat{\mathds{L}}_i^{k-1}\in\mathcal{D}_{\zeta}$ and $\hat{\mathds{L}}_i^{k} =\mathds{L}_i^{k}+\delta \mathds{L}_i^{k} $. Then there exists a $\varepsilon(\zeta)>0$ such that $\hat{\mathds{L}}_i^{k}\in\mathcal{D}_{\zeta}$ for all $\|\delta \mathds{L}_i^{k}\|_F\leq\varepsilon(\zeta)$.
\end{lemma}
\bproof
Since $\hat{\mathds{L}}_i^{k-1}\in\mathcal{D}_{\zeta}\subseteq\mathcal{W}$, it follows from Lemma \ref{lemma:W} that $\mathds{L}_i^{k}\in\mathcal{W}$. We will show that $\hat{\mathds{L}}^k_i\in\mathcal{D}_{\zeta}$. By (\ref{hat_outer_eq}), one has
\begin{equation*} 
\begin{aligned}
\mathscr{L}_{[\mathds{K}_{i}^{k+1},\hat{\mathds{L}}_i^k,\mathcal{S}_i]}(\hat{\mathds{X}}_i^{k+1}\!-\!\hat{\mathds{X}}_i^k)\!+\!\|\tilde{\mathds{K}}_i^{k}\|_{\mathds{R}}^2\!+\!\hat{\Xi}_i^{k}\!-\!\|\delta\mathds{L}_i^{k}\|_{\mathds{W}}^2\!=\!0,
\end{aligned}
\end{equation*}
where $\hat{\Xi}_i^k=\|\mathds{L}_i^{k}-\hat{\mathds{L}}_i^{k-1}\|_{\mathds{W}}^2$.


Assume $\hat{\mathds{L}}_{i}^{k}\in\mathcal{W}$. Then, following a similar derivation as from (\ref{0915-1}) to (\ref{ineq:Xi_k-1}), we obtain from the above equation that
\begin{equation}
\begin{aligned}
\mathrm{Tr}(\hat{\mathds{X}}_i^{k+1}-\hat{\mathds{X}}_i^{k})\geq \underline{b}\|\hat{\Xi}_i^k\|_F-\overline{b}b_2\|\delta \mathds{L}_i^k\|_F^2,
\end{aligned}
\end{equation}
where $b_2=\|\mathds{W}\|_2$. Since $\hat{\mathds{L}}_i^{k-1}\in\mathcal{D}_{\zeta}$, we can get
\begin{equation*}
\|\mathds{X}_i-\hat{\mathds{X}}_i^k\|_F\leq a(\zeta)\|\hat{\Xi}_i^k\|_F,
\end{equation*}
where $a(\zeta)=\max(2\bar{b}\sqrt{n},\frac{\zeta}{\epsilon(\zeta)})$. It follows that 
\begin{subequations} 
 \begin{empheq}[left={\begin{aligned}},right={\end{aligned}}]{align}
\mathrm{Tr}(\mathds{X}_i\!-\!\hat{\mathds{X}}_i^{k+1})&\!\leq\! \alpha(\zeta)\mathrm{Tr}(\mathds{X}_i-\hat{\mathds{X}}_i^{k})+\overline{b}b_2\!\|\delta \mathds{L}_i^k\|_F^2\label{eq:0916-1}\\
&\!\leq\! (1\!-\!{\underline{b}}/(\sqrt{n}a(\zeta)))\zeta+\overline{b}b_2\|\delta \mathds{L}_i^k\|_F^2.
\end{empheq}
\end{subequations}
% \begin{equation}
% \begin{aligned}
% \mathrm{Tr}(\mathds{X}_i\!-\!\hat{\mathds{X}}_i^{k+1})&\!\leq\! \alpha(\delta)\mathrm{Tr}(\mathds{X}_i-\hat{\mathds{X}}_i^{k})+\overline{b}b_1\!\|\Delta \mathds{L}_i^k\|_F^2\\
% &\!\leq\! \left(1\!-\!\frac{\underline{b}}{\sqrt{n}a(\delta)}\right)\delta+\overline{b}b_1\|\Delta \mathds{L}_i^k\|_F^2.
% \end{aligned}
% \end{equation}

By setting $\varepsilon(\zeta)= (\frac{\underline{b}\zeta}{\sqrt{n}\overline{b}b_2a(\zeta)})^{\frac{1}{2}}$, we ensure that $\mathrm{Tr}(\mathds{X}_i-\hat{\mathds{X}}_i^{k+1})\leq \zeta$ whenever $\|\delta \mathds{L}_i^k\|_F\leq \varepsilon(\zeta)$. Hence, $\hat{\mathds{L}}_i^{k}\in\mathcal{D}_{\zeta}$.
 
Next, we confirm that $\hat{\mathds{L}}_i^k\in\mathcal{W}$. Suppose, for contradiction, that $\hat{\mathds{L}}_i^k\notin\mathcal{W}$. From the above derivation, it follows that $\mathcal{W}$ contains all $\boldsymbol{L}_i\in\mathbb{R}^{m_2\times n}$ satisfying $\|\boldsymbol{L}_i-\mathds{L}_i^{k}\|_F\leq\varepsilon(\zeta)$. As a result, $\|\delta \mathds{L}_i^{k}\|_F\geq\varepsilon(\zeta)$, contradicting our assumption that $\|\delta\mathds{L}_i^{k}\|_F\leq\varepsilon(\zeta)$. Therefore, $\hat{\mathds{L}}_i^k\in\mathcal{W}$. 
\eproof



% \subsection*{Proof of Theorem \ref{thm:robust-outer-loop}}
% \bproof[Proof of Theorem \ref{thm:robust-outer-loop}]
\textbf{Proof of Theorem \ref{thm:robust-outer-loop}}. Given that $\hat{\mathds{L}}_i^0=0$ and  $\hat{\mathds{X}}_i^0=0$, and knowing that the system $\mathcal{S}_i$ is stabilizable when $\mathds{G}=0$ and $\mathcal{O}_i$ is detectable, Theorem \ref{thm:convergence-outer-loop} implies $\hat{\mathds{L}}_i^0\in\mathcal{D}_{\zeta}$. 

By Lemma \ref{lem:invariant set}, there exists $\varepsilon(\zeta)>0$ such that if $\|\delta \mathds{L}\|_{\infty}\leq \varepsilon(\zeta)$, then $\hat{\mathds{L}}_i^k\in\mathcal{D}_{\zeta}$ for any $k\in\mathbb{N}_+$. 

We now apply equation (\ref{eq:0916-1}) iteratively, starting from $k=1$. This yields
\begin{equation*}
\begin{aligned}
\mathrm{Tr}(\mathds{X}_i\!-\!\hat{\mathds{X}}_i^{k+1})\leq\alpha^{k}\mathrm{Tr}(\mathds{X}_i\!-\!\hat{\mathds{X}}_i^1)\!+\! \frac{\overline{b}b_2}{\underline{b}}\sqrt{n}a \|\delta \mathds{L}_i^k\|_{\infty}^2,
\end{aligned}
\end{equation*}
which implies $\|\mathds{X}_i\!-\!\hat{\mathds{X}}_i^{k+1}\|_F\!\leq\!\alpha^{k}\sqrt{n}\|\mathds{X}_i-\hat{\mathds{X}}_i^1\|_F \!+\! \frac{\overline{b}b_2}{\underline{b}}\sqrt{n}a\|\delta \mathds{L}_i\|_{\infty}^2$. Hence, $\!\kappa(\|\mathds{X}-\hat{\mathds{X}}_i^1\|_2,k)\!\triangleq\!\alpha^{k}\sqrt{n}\|\mathds{X}_i-\hat{\mathds{X}}_i^1\|_F$ is a $\mathcal{K}\mathscr{L}$-function, and $\ell(\|\delta \mathds{L}_i\|_{\infty})\triangleq \frac{\overline{b}b_2}{\underline{b}}\sqrt{n}a\|\delta \mathds{L}_i\|_{\infty}^2$ is a $\mathcal{K}$-function.  \hfill $\square$
% \eproof

\section{Proof of Theorem \ref{thm:robust-inner-loop}}\label{thmpf:robust-inner-loop}

\begin{lemma}\label{lem:set-inner-loop}
Given $\hat{\mathds{L}}_i^{k-1}\in\mathcal{D}_{\zeta}$. For any $\rho>0$, let $\hat{\mathds{K}}_i^{(k,j-1)}\in{\mathcal{G}}_{\rho}(\hat{\mathds{L}}_i^{k-1})$ and $\hat{\mathds{K}}_i^{(k,j)} = \mathds{K}_i^{(k,j)}+\delta \mathds{K}_i^{(k,j)}$. There exists a $\tilde{\varepsilon}(\rho)>0$ such that $\hat{\mathds{K}}_i^{(k,j)}\in\mathcal{G}_{\rho}(\hat{\mathds{L}}_i^{k-1})$ for all $\|\delta\mathds{K}_i^{(k,j)}\|_F\leq\tilde{\varepsilon}(\rho)$.
\end{lemma}

\bproof
Since $\hat{\mathds{K}}_i^{(k,j-1)}\in{\mathcal{G}}_{\rho}(\hat{\mathds{L}}_i^{k-1})\subseteq{\mathcal{Z}}(\hat{\mathds{L}}_i^{k-1})$, it follows from Theorem \ref{thm:convregence-inner-loop} that ${\mathds{K}}_i^{(k,j)}\in{\mathcal{Z}}(\hat{\mathds{L}}_i^{k-1})$. Assume $\hat{\mathds{K}}_{i}^{(k,j)}\in\mathcal{Z}(\hat{\mathds{L}}_i^{k-1})$. Then, from equation (\ref{inexact:inner-loop}), one has
\begin{equation*}
\begin{aligned}
\!\!\!\mathscr{L}_{[\hat{\mathds{K}}_i^{(k,j)},\hat{\mathds{L}}_i^{k-1},\mathcal{S}_i]}(\hat{\mathds{X}}_i^{(k,j)}\!\!-\!\!\hat{\mathds{X}}_i^{(k,j+1)})\!+\!\hat{\Xi}_i^{(k,j)}\!\!-\!\!\|\delta \mathds{K}_i^{(k,j)}\|^2_{\hat{\mathds{R}}_i^{(k,j)}}\!=\!0,
\end{aligned}
\end{equation*}
where $\hat{\Xi}_i^{(k,j)}=\|\mathds{K}_i^{(k,j)}-\hat{\mathds{K}}_i^{(k,j-1)}\|^2_{\hat{\mathds{R}}_i^{(k,j)}}$ and $\hat{\mathds{R}}_i^{(k,j)} = \mathds{R}+\mathds{D}^{\mathrm{T}}\hat{\mathds{X}}_i^{(k,j)}\mathds{D}$. This implies
\begin{equation*}
\mathrm{Tr}\left(\hat{\mathds{X}}_i^{(k,j)}-\hat{\mathds{X}}_i^{(k,j+1)}\right)\geq \underline{b}\|\hat{\Xi}_i^{(k,j)}\|_F-\overline{b}b_3\|\delta \mathds{K}_i^{(k,j)}\|_F^2,
\end{equation*}
where $b_3\geq\|\hat{\mathds{R}}_i^{(k,j)}\|_2$. As a result, we can derive
\begin{equation}\label{itereq11}
\begin{aligned}
\!\!\!\!\!\!\mathrm{Tr}(\hat{\mathds{X}}_i^{(k,j+1)}\!-\!\hat{\mathds{X}}_i^{k})\!\leq\! \tilde{\alpha}\mathrm{Tr}(\hat{\mathds{X}}_i^{(k,j)}\!-\!\hat{\mathds{X}}_i^{k})\!+\!\overline{b}b_3\|\delta \mathds{K}_i^{(k,j)}\|_F^2.
\end{aligned}
\end{equation}
Since $\hat{\mathds{K}}_i^{(k,j-1)}\in {\mathcal{G}}_{\rho}(\hat{\mathds{L}}_i^{k-1})$ and $\tilde{\alpha}=1- \underline{b}/\overline{b}$, it follows from (\ref{itereq11}) that
\begin{equation*}
\begin{aligned}
\|\hat{\mathds{X}}_i^{(k,j+1)}-\hat{\mathds{X}}_i^{k}\|_F\leq(1- \underline{b}/\overline{b})\rho+\overline{b}b_3\|\delta \mathds{K}_i^{(k,j)}\|_F^2.
\end{aligned}
\end{equation*}
By letting $\tilde{\varepsilon}(\rho)=(\frac{\rho\underline{b}}{\overline{b}^2b_3})^{\frac{1}{2}}$, we ensure that $\mathrm{Tr}(\hat{\mathds{X}}_i^{(k,j+1)}-\hat{\mathds{X}}_i^k)\leq \rho$ whenever $\|\delta \mathds{K}_i^{(k,j)}\|_F\leq\tilde{\varepsilon}(\rho)$, which implies $\hat{\mathds{K}}_i^{(k,j)}\in{\mathcal{G}}_{\rho}(\hat{\mathds{L}}_i^{k-1})$.

Next, we confirm that $\hat{\mathds{K}}_i^{(k,j)}\in{\mathcal{Z}}(\hat{\mathds{L}}_i^{k-1})$. Suppose, for contradiction, that $\hat{\mathds{K}}_i^{(k,j)}\notin {\mathcal{Z}}(\hat{\mathds{L}}_i^{k-1})$. From the above derivation, $ {\mathcal{Z}}(\hat{\mathds{L}}_i^{k-1})$ contains all $\boldsymbol{K}_i\in\mathbb{R}^{m_1\times n}$  such that $\|\boldsymbol{K}_i-\mathds{K}_i^{(k,j)}\|\leq \tilde{\varepsilon}(\rho)$, it follows that $\|\delta \mathds{K}_i^{(k,j)}\|\geq\tilde{\varepsilon}(\rho)$. This contradicts our assumption that $\|\delta \mathds{K}_i^{(k,j)}\|\leq \tilde{\varepsilon}(\rho)$. Thus, $\mathds{K}_i^{(k,j)}\in{\mathcal{Z}}(\hat{\mathds{L}}_i^{k-1})$.
\eproof


{\bf Proof of Theorem \ref{thm:robust-inner-loop}}. Since $\hat{\mathds{K}}_i^{(k,0)}\in\mathcal{G}_{\rho}(\hat{\mathds{L}}_i^{k-1})$, it follows from Lemma \ref{lem:set-inner-loop} that there exists $\tilde{\varepsilon}(\rho)>0$ such that $\hat{\mathds{K}}_i^{(k,j)}\in\mathcal{G}_{\rho}(\hat{\mathds{L}}_i^{k-1})$ for all $\|\mathds{K}_i^k\|_{\infty}\leq\tilde{\varepsilon}(\rho)$ and $k\in\mathbb{N}_+$.

Thus, we repeat (\ref{itereq11}) from $k=1$ to derive
\begin{equation*}
\mathrm{Tr}(\hat{\mathds{X}}_i^{(k,j+1)}\!-\!\hat{\mathds{X}}_i^{k})\leq \tilde{\alpha}^{k}\mathrm{Tr}(\hat{\mathds{X}}_i^{(k,1)}\!-\!\hat{\mathds{X}}_i^{k}) + \frac{\overline{b}^2}{\underline{b}}b_2\|\delta\mathds{K}_i^k\|_{\infty}^2,
\end{equation*}
which gives
\begin{equation*}
\|\hat{\mathds{X}}_i^{(k,j+1)}\!-\!\hat{\mathds{X}}_i^{k}\|_F\leq \sqrt{n}\tilde{\alpha}^{k}\|\hat{\mathds{X}}_i^{(k,1)}\!-\!\hat{\mathds{X}}_i^{k}\|_2 \!+\! \frac{\overline{b}^2}{\underline{b}}b_3\|\delta\mathds{K}_i^k\|_{\infty}^2.
\end{equation*}

Thus $\mu(\|\hat{\mathds{X}}_i^{(k,j)}\!-\!\hat{\mathds{X}}_i^{k}\|_2,j)\!\triangleq\!\sqrt{n}\tilde{\alpha}^{k}\|\hat{\mathds{X}}_i^{(k,1)}\!-\!\hat{\mathds{X}}_i^{k}\|_2 $ is a $\mathscr{KL}$-function and $\gamma(\|\delta\mathds{K}_i^l\|_{\infty})\!\triangleq\!\frac{\overline{b}^2}{\underline{b}}b_3\|\delta\mathds{K}_i^k\|_{\infty}^2$ is a $\mathscr{K}$-function.\hfill $\square$

% Hence, the proof is complete.
 


%

%% use section* for acknowledgment
%\section*{Acknowledgment}
%
%
%The authors would like to thank...


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
% \ifCLASSOPTIONcaptionsoff
%   \newpage
% \fi


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
 \bibliographystyle{IEEEtran}
% % argument is your BibTeX string definitions and bibliography database(s)
 \bibliography{arxiv.bib}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)


% biography section
%
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bio/Xu}}]{
% Zhenhui Xu received the Ph.D. in mechanical engineering from Sophia University, Tokyo, Japan, in 2021. From April 2021 to August 2023, she served as a Postdoctoral Fellow in the Department of Engineering and Applied Sciences at Sophia University. Currently, she holds the position of specially appointed assistant professor in the Department of Systems and Control Engineering at the Institute of Science Tokyo. Her research interests include optimal control theory and applications in automotive systems, reinforcement learning, and mean field games.}
% \end{IEEEbiography}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bio/Chen}}]{
% Jiayu Chen received the Ph.D degree in control theory and technology from the University of Science and Technology of China in 2019. Currently, he serves as a Postdoctoral Fellow in the Department of Systems and Control Engineering at the Institute of Science Tokyo. His research interests include multi-agent system, networked control, learning-based control, and optimal control theory and applications in transportation systems.}
% \end{IEEEbiography}



% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bio/Wang}}]{
%  Bing-Chang Wang received the Ph.D. degree in system theory from the Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, China, in 2011. From September 2011 to August 2012, he was with the Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada, as a Post-Doctoral Fellow. From September 2012 to September 2013, he was with the School of Electrical Engineering and Computer Science, University of Newcastle, Callaghan, NSW, Australia, as a Research Academic. Since October 2013, he has been with the School of Control Science and Engineering, Shandong University, Jinan, China, where he is currently a Professor. His current research interests include mean field games, stochastic control, multiagent systems, and reinforcement learning.}
% \end{IEEEbiography}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bio/Wu}}]{
% Yuhu Wu received his Ph.D. degree in mathematics from the Harbin Institute of Technology, Harbin, China, in 2012. Since 2012, he has held an Assistant Professor position with the Harbin University of Science and Technology, Harbin. He held a Postdoctoral Research position with Sophia University, Tokyo, Japan, from 2012 to 2015. In 2015, he joined the School of Control Science and Engineering, Dalian University of Technology, Dalian, China, where he is currently a Full Professor. His research interests are related to optimization, nonlinear control theory, and control applications to Boolean networks, automotive powertrain systems, and unmanned aerial vehicles.}
% \end{IEEEbiography}


% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bio/Shen}}]{
% Tielong Shen received the PhD degree from Sophia University, Tokyo, Japan in 1992. From April 1992, he has been a faculty member of the Chair of Control Engineering in Department of Mechanical Engineering, Sophia University, where he currently serves as full Professor. Since 2005, he is also served concurrently ``Luojia Xuezhe'' Chair Professor of Wuhan University, and ``Tang Aoqing'' Chair Professor of Jilin university, China. His research interests include control theory and applications in automotive systems, power systems, and mechanical systems. }
% \end{IEEEbiography}
% \vspace{-1cm}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bio/Xu}}]{
% Zhenhui Xu received the Ph.D. in mechanical engineering from Sophia University, Tokyo, Japan, in 2021. Currently, she holds the position of specially appointed assistant professor in the Department of Systems and Control Engineering at the Institute of Science Tokyo. Her research interests include optimal control theory and applications in automotive systems, reinforcement learning, and mean field games.}
% \end{IEEEbiography}
% \vspace{-0.5cm}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bio/Chen}}]{
% Jiayu Chen received the Ph.D degree in control theory and technology from the University of Science and Technology of China in 2019. Currently, he serves as a Postdoctoral Fellow in the Department of Systems and Control Engineering at the Institute of Science Tokyo. His research interests include multi-agent system, networked control, learning-based control, and optimal control theory and applications in transportation systems.}
% \end{IEEEbiography}
% \vspace{-0.5cm}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bio/Wang}}]{
%  Bing-Chang Wang received the Ph.D. degree in system theory from the Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, China, in 2011. Since October 2013, he has been with the School of Control Science and Engineering, Shandong University, Jinan, China, where he is currently a Professor. His current research interests include mean field games, stochastic control, multiagent systems, and reinforcement learning.}
% \end{IEEEbiography}
% \vspace{-0.5cm}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bio/Wu}}]{
% Yuhu Wu received his Ph.D. degree in mathematics from the Harbin Institute of Technology, Harbin, China, in 2012. Since 2012, he has held an Assistant Professor position with the Harbin University of Science and Technology, Harbin. In 2015, he joined the School of Control Science and Engineering, Dalian University of Technology, Dalian, China, where he is currently a Full Professor. His research interests are related to optimization, nonlinear control theory, and control applications to Boolean networks, automotive powertrain systems, and unmanned aerial vehicles.}
% \end{IEEEbiography}
% \vspace{-0.5cm}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{bio/Shen}}]{
% Tielong Shen received the PhD degree from Sophia University, Tokyo, Japan in 1992. From April 1992, he has been a faculty member of the Chair of Control Engineering in Department of Mechanical Engineering, Sophia University, where he currently serves as full Professor. Since 2005, he is also served concurrently ``Luojia Xuezhe'' Chair Professor of Wuhan University, and ``Tang Aoqing'' Chair Professor of Jilin university, China. His research interests include control theory and applications in automotive systems, power systems, and mechanical systems. }
% \end{IEEEbiography}


% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

%\begin{IEEEbiographynophoto}{Jane Doe}
%Biography text here.
% \end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
% \enlargethispage{-5in}

 
\end{document}
