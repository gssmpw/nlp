@article{andriushchenko2024agentharm,
  author    = {Andriushchenko, M. and Souly, A. and Dziemian, M. and Duenas, D. and Lin, M. and Wang, J. and Hendrycks, D. and Zou, A. and Kolter, Z. and Fredrikson, M. and Winsor, E. and Wynne, J. and Gal, Y. and Davies, X.},
  title     = {AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents},
  journal   = {ArXiv},
  year      = {2024},
  url       = {https://arxiv.org/abs/2410.09024}
}

@misc{anthropic_computer_use,
    author = {Anthropic},
    title= {Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku},
    year={2024},
    url={https://www.anthropic.com/news/3-5-models-and-computer-use}}

@misc{boiko2023emergent,
      title={Emergent autonomous scientific research capabilities of large language models}, 
      author={Daniil A. Boiko and Robert MacKnight and Gabe Gomes},
      year={2023},
      eprint={2304.05332},
      archivePrefix={arXiv},
      primaryClass={physics.chem-ph}
}

@misc{chatgptplugins2023,
      author={OpenAI},
      day={23},
      month={03},
      year={2023},
      title = {ChatGPT plugins},
      howpublished = {\url{https://openai.com/index/chatgpt-plugins/}},
      note = {Accessed: 2024-06-15}

}

@misc{cohen2024comesaiwormunleashing,
      title={Here Comes The AI Worm: Unleashing Zero-click Worms that Target GenAI-Powered Applications}, 
      author={Stav Cohen and Ron Bitton and Ben Nassi},
      year={2024},
      eprint={2403.02817},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2403.02817}, 
}

@misc{gptengineer2023,
      author = {Osika, Anton},
      month = {04},
      year = {2023},
      title = {gpt-engineer},
      howpublished = {\url{https://github.com/gpt-engineer-org/gpt-engineer}},
      version = {0.1.0},
      note = {Accessed: 2024-06-15}

}

@misc{gptresearcher2023,
      author = {Elovic, Assaf},
      month = {07},
      year = {2023},
      title = {gpt-researcher},
      howpublished = {\url{https://github.com/assafelovic/gpt-researcher}},
      version = {0.5.4},
      note = {Accessed: 2024-06-15}
}

@misc{gptstore2024,
      author={OpenAI},
      day={10},
      month={01},
      year={2024},
      title = {Introducing the GPT Store},
      howpublished = {\url{https://openai.com/index/chatgpt-plugins/}},
      note = {Accessed: 2024-06-15}
}

@misc{greshake2023youve,
      title={Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection}, 
      author={Kai Greshake and Sahar Abdelnabi and Shailesh Mishra and Christoph Endres and Thorsten Holz and Mario Fritz},
      year={2023},
      eprint={2302.12173},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@misc{gu2024agentsmithsingleimage,
      title={Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast}, 
      author={Xiangming Gu and Xiaosen Zheng and Tianyu Pang and Chao Du and Qian Liu and Ye Wang and Jing Jiang and Min Lin},
      year={2024},
      eprint={2402.08567},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.08567}, 
}

@misc{hao2023reasoning-planing,
      title={Reasoning with Language Model is Planning with World Model}, 
      author={Shibo Hao and Yi Gu and Haodi Ma and Joshua Jiahua Hong and Zhen Wang and Daisy Zhe Wang and Zhiting Hu},
      year={2023},
      eprint={2305.14992},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{hong2023metagpt,
      title={MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework}, 
      author={Sirui Hong and Mingchen Zhuge and Jonathan Chen and Xiawu Zheng and Yuheng Cheng and Ceyao Zhang and Jinlin Wang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and JÃ¼rgen Schmidhuber},
      year={2023},
      eprint={2308.00352},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{kumar2024refusal,
  author    = {Kumar, P. and Lau, E. and Vijayakumar, S. and Trinh, T. and Team, S. R. and Chang, E. and Robinson, V. and Hendryx, S. and Zhou, S. and Fredrikson, M. and Yue, S. and Wang, Z.},
  title     = {Refusal-Trained LLMs Are Easily Jailbroken As Browser Agents},
  journal   = {ArXiv},
  year      = {2024},
  url       = {https://arxiv.org/abs/2410.13886}
}

@article{lermen2024applying,
  author    = {Lermen, S. and Dziemian, M. and Pimpale, G.},
  title     = {Applying Refusal-Vector Ablation to Llama 3.1 70B Agents},
  journal   = {ArXiv},
  year      = {2024},
  url       = {https://arxiv.org/abs/2410.10871}
}

@misc{li2022rag-survey,
      title={A Survey on Retrieval-Augmented Text Generation}, 
      author={Huayang Li and Yixuan Su and Deng Cai and Yan Wang and Lemao Liu},
      year={2022},
      eprint={2202.01110},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{li2023privacy,
  title        = {Privacy in Large Language Models: Attacks, Defenses and Future Directions},
  author       = {Haoran Li and Yulin Chen and Jinglong Luo and Yan Kang and Xiaojin Zhang and Qi Hu and Chunkit Chan and Yangqiu Song},
  year         = {2023},
  eprint       = {2310.10383},
  archivePrefix= {arXiv},
  primaryClass = {cs.CL}
}

@misc{liang2023taskmatrixai,
      title={TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs}, 
      author={Yaobo Liang and Chenfei Wu and Ting Song and Wenshan Wu and Yan Xia and Yu Liu and Yang Ou and Shuai Lu and Lei Ji and Shaoguang Mao and Yun Wang and Linjun Shou and Ming Gong and Nan Duan},
      year={2023},
      eprint={2303.16434},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{liu2021pretrain-prompt-predict,
      title={Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing}, 
      author={Pengfei Liu and Weizhe Yuan and Jinlan Fu and Zhengbao Jiang and Hiroaki Hayashi and Graham Neubig},
      year={2021},
      eprint={2107.13586},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{liu2024prompt,
      title={Prompt Injection attack against LLM-integrated Applications}, 
      author={Yi Liu and Gelei Deng and Yuekang Li and Kailong Wang and Zihao Wang and Xiaofeng Wang and Tianwei Zhang and Yepang Liu and Haoyu Wang and Yan Zheng and Yang Liu},
      year={2024},
      eprint={2306.05499},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@misc{nascimento2023selfadaptive,
      title={Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems}, 
      author={Nathalia Nascimento and Paulo Alencar and Donald Cowan},
      year={2023},
      eprint={2307.06187},
      archivePrefix={arXiv},
      primaryClass={cs.MA}
}

@misc{park_generative_2023,
	title = {Generative {Agents}: {Interactive} {Simulacra} of {Human} {Behavior}},
	shorttitle = {Generative {Agents}},
	url = {http://arxiv.org/abs/2304.03442},
	doi = {10.48550/arXiv.2304.03442},
	abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents--computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors: for example, starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture--observation, planning, and reflection--each contribute critically to the believability of agent behavior. By fusing large language models with computational, interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
	urldate = {2024-07-27},
	publisher = {arXiv},
	author = {Park, Joon Sung and O'Brien, Joseph C. and Cai, Carrie J. and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
	month = aug,
	year = {2023},
	note = {arXiv:2304.03442 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
}

@misc{qin_toolllm_2023,
	title = {{ToolLLM}: {Facilitating} {Large} {Language} {Models} to {Master} 16000+ {Real}-world {APIs}},
	shorttitle = {{ToolLLM}},
	url = {http://arxiv.org/abs/2307.16789},
	doi = {10.48550/arXiv.2307.16789},
	abstract = {Despite the advancements of open-source large language models (LLMs), e.g., LLaMA, they remain significantly limited in tool-use capabilities, i.e., using external tools (APIs) to fulfill human instructions. The reason is that current instruction tuning largely focuses on basic language tasks but ignores the tool-use domain. This is in contrast to the excellent tool-use capabilities of state-of-the-art (SOTA) closed-source LLMs, e.g., ChatGPT. To bridge this gap, we introduce ToolLLM, a general tool-use framework encompassing data construction, model training, and evaluation. We first present ToolBench, an instruction-tuning dataset for tool use, which is constructed automatically using ChatGPT. Specifically, the construction can be divided into three stages: (i) API collection: we collect 16,464 real-world RESTful APIs spanning 49 categories from RapidAPI Hub; (ii) instruction generation: we prompt ChatGPT to generate diverse instructions involving these APIs, covering both single-tool and multi-tool scenarios; (iii) solution path annotation: we use ChatGPT to search for a valid solution path (chain of API calls) for each instruction. To enhance the reasoning capabilities of LLMs, we develop a novel depth-first search-based decision tree algorithm. It enables LLMs to evaluate multiple reasoning traces and expand the search space. Moreover, to evaluate the tool-use capabilities of LLMs, we develop an automatic evaluator: ToolEval. Based on ToolBench, we fine-tune LLaMA to obtain an LLM ToolLLaMA, and equip it with a neural API retriever to recommend appropriate APIs for each instruction. Experiments show that ToolLLaMA demonstrates a remarkable ability to execute complex instructions and generalize to unseen APIs, and exhibits comparable performance to ChatGPT. Our ToolLLaMA also demonstrates strong zero-shot generalization ability in an out-of-distribution tool-use dataset: APIBench.},
	urldate = {2024-07-27},
	publisher = {arXiv},
	author = {Qin, Yujia and Liang, Shihao and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and Zhao, Sihan and Hong, Lauren and Tian, Runchu and Xie, Ruobing and Zhou, Jie and Gerstein, Mark and Li, Dahai and Liu, Zhiyuan and Sun, Maosong},
	month = oct,
	year = {2023},
	note = {arXiv:2307.16789 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{shen2023hugginggpt,
      title={HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face}, 
      author={Yongliang Shen and Kaitao Song and Xu Tan and Dongsheng Li and Weiming Lu and Yueting Zhuang},
      year={2023},
      eprint={2303.17580},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{tian2024evilgeniusesdelvingsafety,
      title={Evil Geniuses: Delving into the Safety of LLM-based Agents}, 
      author={Yu Tian and Xiao Yang and Jingyuan Zhang and Yinpeng Dong and Hang Su},
      year={2024},
      eprint={2311.11855},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.11855}, 
}

@misc{wang2024unleashing,
      title={Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration}, 
      author={Zhenhailong Wang and Shaoguang Mao and Wenshan Wu and Tao Ge and Furu Wei and Heng Ji},
      year={2024},
      eprint={2307.05300},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{wang_survey_2024,
	title = {A {Survey} on {Large} {Language} {Model} based {Autonomous} {Agents}},
	volume = {18},
	issn = {2095-2228, 2095-2236},
	url = {http://arxiv.org/abs/2308.11432},
	doi = {10.1007/s11704-024-40231-1},
	abstract = {Autonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at https://github.com/Paitesanshi/LLM-Agent-Survey.},
	language = {en},
	number = {6},
	urldate = {2024-07-27},
	journal = {Frontiers of Computer Science},
	author = {Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Ji-Rong},
	month = dec,
	year = {2024},
	note = {arXiv:2308.11432 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	pages = {186345},
	annote = {Comment: 35 pages, 5 figures, 3 tables, has been accepted by frontiers of computer science (FCS), doi=\{10.1007/s11704-024-40231-1\}},
	file = {Wang et al. - 2024 - A Survey on Large Language Model based Autonomous .pdf:/Users/esben/Zotero/storage/AFQAWTE3/Wang et al. - 2024 - A Survey on Large Language Model based Autonomous .pdf:application/pdf},
}

@inproceedings{wei2023jailbroken,
 author = {Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {80079--80110},
 publisher = {Curran Associates, Inc.},
 title = {Jailbroken: How Does LLM Safety Training Fail?},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/fd6613131889a4b656206c50a8bd7790-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}

@misc{yang2024watchagentsinvestigatingbackdoor,
      title={Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents}, 
      author={Wenkai Yang and Xiaohan Bi and Yankai Lin and Sishuo Chen and Jie Zhou and Xu Sun},
      year={2024},
      eprint={2402.11208},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2402.11208}, 
}

@misc{yao2023tree,
      title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models}, 
      author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
      year={2023},
      eprint={2305.10601},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhang2024building,
      title={Building Cooperative Embodied Agents Modularly with Large Language Models}, 
      author={Hongxin Zhang and Weihua Du and Jiaming Shan and Qinhong Zhou and Yilun Du and Joshua B. Tenenbaum and Tianmin Shu and Chuang Gan},
      year={2024},
      eprint={2307.02485},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{zhao2023expel,
      title={ExpeL: LLM Agents Are Experiential Learners}, 
      author={Andrew Zhao and Daniel Huang and Quentin Xu and Matthieu Lin and Yong-Jin Liu and Gao Huang},
      year={2023},
      eprint={2308.10144},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{zheng2024cristallinity,
    author = {Zheng, Zhiling and Zhang, Oufan and Nguyen, Ha L. and Rampal, Nakul and Alawadhi, Ali H. and Rong, Zichao and Head-Gordon, Teresa and Borgs, Christian and Chayes, Jennifer T. and Yaghi, Omar M.},
    title = {ChatGPT Research Group for Optimizing the Crystallinity of MOFs and COFs},
    journal = {ACS Central Science},
    volume = {9},
    number = {11},
    pages = {2161-2170},
    year = {2023},
    doi = {10.1021/acscentsci.3c01087},
    URL = {https://doi.org/10.1021/acscentsci.3c01087},
    eprint = {https://doi.org/10.1021/acscentsci.3c01087}
}

