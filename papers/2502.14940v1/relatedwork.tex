\section{Related Work}
\paragraph{Semantic 3D city models.}
In addition to offering geometric and visual insights into topographic features, semantic 3D city models provide comprehensive information about structures, taxonomies, and aggregations at the scale of cities, regions, and even complete countries. % \cite{Groeger2012}.
For the representation and management of city models, the standard CityGML is used internationally, which has been issued by the \gls{OGC} \cite{Kolbe2009,Groeger2012,kolbeOGCCityGeography2021}.
CityGML enables the modeling of urban objects
with their 3D geometry, appearance, topology, and semantics at four different \glspl{LOD}.
The data model of CityGML 3.0 is based on the ISO 191xx series of geographic information standards, and CityGML datasets can be encoded using the \gls{GML} \cite{Kutzner2020}.
%Its semantic model is based on the ISO 19100 standards family framework for modeling geographic features.
% CityGML, an \gls{OGC} standard since 2008 \cite{Groger2008,Kolbe2009}, facilitates the representation of buildings at various semantic \gls{LOD}.
%The implementation takes the form of an application schema for \gls{GML}, utilizing \gls{XML}.

\paragraph{Synthetic generation of semantic city models.}
With Random3Dcity, Biljecki \textit{et al.} \cite{BiljeckiRandom3Dcity} introduce a method for the procedural generation of randomized semantic city models at various \gls{LOD} levels.
Their approach utilizes a set of pre-defined architectural modeling rules guiding its stochastic nature.
Such rules govern aspects like the permissible positioning of facade elements such as doors or windows.

\paragraph{Reconstruction of semantic 3D building models.}
The considerable potential for applying detailed \gls{LOD}3 models across diverse domains, coupled with their scarcity, has motivated a significant number of studies to explore the reconstruction of such models.
Investigations involve leveraging various data sources, such as optical images, oblique \gls{ALS} point clouds, and \gls{MLS} measurements, as well as employing diverse approaches, including formal grammar approaches and Bayesian networks \cite{ripperda_rekonstruktion_2010,helmutMayerLoD3,wysocki2023scan2lod3}.
Within their pipeline for reconstructing underpasses in semantic \gls{LOD}2 city models from co-registered \gls{MLS} point clouds, Wysocki \textit{et al.} introduce the concept of 2D conflict maps. 
Their probabilistic approach relies on an occupancy grid implemented as an octree structure, with voxel sizes reflecting the combined uncertainty of the \gls{MLS} measurements and the semantic city model.
%\olafworries{
This concept has been further developed by \cite{Wysocki_Conflict_Map,wysocki2023scan2lod3,hoegner2022automatic}, thereby substantiating its effectiveness.
%}
%\olafworries{
The pivotal advantage of the previously mentioned methods over mesh-based approaches is the usage of 3D semantic building models as priors, which has proven to maintain the model watertightness as well as higher 3D reconstruction accuracy, reaching up to around $50\%$ when compared to the mesh-based Poisson reconstruction~\cite{wysocki2023scan2lod3}. 
Nevertheless, despite generally yielding commendable results, the challenge of incompleteness remains unsolved.
%}
%To identify conflicts, a ray-casting approach is employed. 
%Wysocki \textit{et al.} \cite{Wysocki_Conflict_Map}
%extract a 2D conflict map as a texture, while Yahya \cite{Yahya2023}, in contrast, directly incorporates conflict information within the 3D domain.

% \paragraph{Synthetic generation of semantic city models}
% %The scarcity of \gls{LOD}3 building models poses a challenge in utilizing real \gls{LOD}3 buildings as a source for training data.
% With Random3Dcity, Biljecki \textit{et al.} introduce an application for the procedural generation of randomized semantic city models.
% %Originally intended to create datasets for testing CityGML \cite{Kolbe2021} functionalities,
% Their software can be deployed for generating random CityGML datasets at various \gls{LOD} levels according to a set of pre-defined rules \cite{BiljeckiRandom3Dcity}.

%\olafworries{"Traditional Image inpainting" - remove this paragraph totally and put your sentence under "Deep-learning-based image inpainting" - it saves much space}
%\olafworries{I think it's still okay, just start that "In contrast to traditional methods... deep learning methods use..."}
%\olafworries{Otherwise, we'd need to elaborate more on traditional methods here}
%\paragraph{Traditional Image inpainting}
%Traditional inpainting methods such as the Method by telea \cite{Telea2004} and Inpainting based on the Navier-Stokes equations \cite{Bertalmio2001} methods often rely on solving \gls{PDE}.
% Utilizing the Fast Marching Method \cite{Sethian1999} as its foundation, the inpainting method by Telea \cite{Telea2004} analyzes pixels in the neighborhood of a missing area to predict the pixels in the gap.
% Solving pixel-wise \gls{PDE}s ensures newly generated pixel values to be consistent with their surroundings.
% Inpainting based on the Navier-Stokes \gls{PDE}s \cite{Bertalmio2001} conceptualizes an image as a dynamic fluid system.
% \gls{PDE}s are leveraged to direct the flow of information into the missing regions, akin to the natural filling of empty spaces by fluids.
\paragraph{Deep-learning-based image inpainting.}
% Besides traditional image inpainting methods that often rely on solving \gls{PDE}s \cite{Telea2004,Bertalmio2001}, recent advancements in the dynamic research domain of image inpainting provide an opportunity to address the challenge of incomplete 2D conflict maps. 
Besides traditional image inpainting methods, which typically rely on solving \gls{PDE}s \cite{Telea2004,Bertalmio2001}, and yield unsatisfactory results when applied to facade images \cite{fritzsche2022inpainting}. 
Recent advancements in deep-learning-based image inpainting suggest potential methodologies for addressing the challenge of incomplete 2D conflict maps. 
Large mask inpainting (LaMa) \cite{Suvorov2021}, configured as a Generative Adversarial Network (GAN), employs Fast Fourier Convolution operators \cite{Chi2020FFC} to overcome the limitation of restricted receptive fields, thereby enabling expansive coverage across the entire image.

% Large mask inpainting (LaMa) \cite{Suvorov2021} is configured as a Generative Adversarial Network (GAN) following a structure similar to a feed-forward ResNet inpainting network.
% To overcome the constraint of a restricted receptive field, LaMa employs Fast Fourier Convolution operators \cite{Chi2020FFC}, enabling an expansive coverage across the entire image size.

% \gls{DM}s such as \gls{SD} \cite{Rombach_2022_CVPR} represent powerful methods for various applications including image inpainting.
% %By leveraging a mapping into a latent feature space, Rombach \textit{et al.} significantly reduce the required computational resources for the deployment of \gls{DM}s.
% \gls{SD} demonstrates remarkable flexibility by utilizing conditioning mechanisms and cross-attention layers in the architecture to integrate additional information.
% Incorporating five specialized input channels combined with a dedicated training procedure enables its application for image inpainting tasks.
% %Notably, unlike many inpainting strategies, 
% The \gls{SD} model requires the provision of a text prompt for image inpainting.

\gls{DM}s have emerged as powerful tools for various generative applications in the last years. 
Notably, \gls{SD} \cite{Rombach_2022_CVPR} demonstrates remarkable flexibility with its capability to handle open-ended text conditioning. When supplemented with additional image and mask inputs, the \gls{SD} framework can be further extended to solve image inpainting tasks, guided by relevant text prompts. 
To our knowledge, no method deploying diffusion models for inpainting facade conflict maps has been published yet.

To tailor pre-trained \gls{SD} models for domain-specific applications, a variety of personalization ({\em i.e.,} customization) techniques \cite{gal2022textual,kumari2022customdiffusion,Wei_2023_ICCV} are developed. These methods generally utilize small-scale datasets to fine-tune the pre-trained \gls{SD} pipeline for specialized domains. In particular, Dreambooth \cite{Ruiz2023} stands out as a robust personalization approach, incorporating a prior-preservation loss and LoRA~\cite{hu2022lora}-based fine-tuning. 
%This method is further proven to be effective for the inpainting variant of \gls{SD} \cite{von-platen-etal-2022-diffusers}. 
% Dreambooth \cite{Ruiz2023} is a method designed for the personalization of large text-to-image diffusion models.
% It facilitates subject-driven fine-tuning, enabling the network to generate a range of new examples for a learned instance of an object type.
% A unique identifier, linked to the specific instance, is employed in the text-prompt to reference the learned instance during inference.
% %A significant advantage of Dreambooth is the small number of training samples.
% Besides text-to-image applications, Dreambooth can also be applied to the image inpainting variant of \gls{SD} \cite{von-platen-etal-2022-diffusers}.