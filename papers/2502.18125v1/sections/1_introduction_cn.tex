\section{Introduction}
\begin{CJK}{UTF8}{gkai}  
随着各行业的信息化进程，大量结构化知识以表格形式存储。这些结构化的知识往往是与下游任务密切相关的领域特定信息，与大模型在预训练数据中学到的通用知识形成互补，从而增强大模型对下游推理任务的支持能力。

大语言模型凭借其强大的语言能力和丰富的知识储备，被作为one-/fewshot-learner被应用在表格任务中~\cite{?}。目前，将大语言模型应用于表格任务的主要方法分为两大类：基于序列化的方法（serialize-based）和基于SQL的方法（SQL-based）。基于序列化的方法通过将结构化知识转化为文本句子输入，引导大模型理解序列化后的文本并进行推理和问答。例如，~\cite{?}通过Table-to-Text模型或大语言模型将表格解析为自然语言字符串，并与任务指令一起输入推理模型。然而，表格序列化会破坏其原有的结构关系，尤其在面对长表格时，可能导致严重的知识遗忘，进而在推理时缺乏逻辑关联。基于SQL的方法通过text-to-SQL模型，首先根据任务要求从表格中抽取相关知识，然后结合大模型的通用知识进行回答。虽然SQL查询在推理时充分考虑了表格数据的结构关系，但在处理缺失或不完整的稀疏表格时，大模型往往无法结合完整的上下文信息进行推理。如图\ref{fig:toy_example}中，直接对包含不完整的Miller的党派信息的单元格建模会得到错误的语义，而大语言模型结合表格结构和自身知识库能够轻松推理出Miller属于民主党派。因此，\textbf{结构关系}和\textbf{数据稀疏性}是大语言模型利用结构化知识时需要特别关注的两个关键特性，这与其擅长处理的非结构化文本输入有显著不同~\cite{?}。借助图的结构化特性对表格知识进行建模，并通过图神经网络进行学习~\cite{?}，尽管这一方法能够有效捕捉结构化知识中的依赖关系，但传统的图神经网络通常基于图级、节点级或边级的目标（如图分类、节点分类、边预测等任务）进行训练，难以满足自然语言描述的表格任务的指令化需求。这种方法容易与下游任务的实际需求脱节，导致模型关注到表格中次要的信息。

% 表格数据中的稀疏性表现在1）missing/incomplete的单元格数据，2）事实性知识缺少人工标注。
% 表格数据中特殊的结构关系表现在1）同一行/列的单元格数据中存在着相同的语义，2）顺序不变性，3）层级依赖。
为了让大模型更有效地利用结构化知识，我们提出了一种全新的大模型超图表格学习框架。在充分利用表格数据的结构特征并处理稀疏性问题的基础上，将知识转移到下游任务中。不同于传统图中的一条边只能连接两个节点，超图中的超边可以连接任意数量的节点，且这些节点之间的连接是无序的。超图能从三个方面建模知识的结构化特性。第一，超边能建模语义一致性，如表格中同一行或列中的单元格数据通常属于同一语义类别，这种特性有助于模型识别和推理出隐含的语义关联。如图\ref{fig:toy_example}中，绿色高亮的列展示了候选人的政治党派。第二，图的非序列结构表示了行列的顺序不变性。与自然语言中交换词序可能导致语义变化不同，交换表格中的行或列顺序（如图\ref{fig:toy_example}中将Moss和Mcfall两行对调）不会影响表格的整体语义。第三，超图中的超边能够建模结构化知识中的多元高阶依赖关系，例如表头和标题之间或嵌套的行或列之间的依赖(图\ref{fig:toy_example}中蓝色所示)。对于数据稀疏性问题，通过在超图上应用超图神经网络进行高阶信息传递，可以对缺失或不完整的知识进行预测或者补充。另外，我们将对下游任务的提示描述加入到超图神经网络的信息传递中，使得到的知识表示是与下游任务紧密相关的。总的来说，我们提出了一种全新的大模型超图表格事实推理框架Hypergraph-enhanced LLM Generation Framework (\name)。首先，利用大语言模型显式增强稀疏单元格，并通过增强后的单元格构建表格的超图。随后，我们设计了一种全新的超图神经网络，用于结合任务提示学习超图中的结构化知识，并与大语言模型进行联合训练。我们的贡献总结如下：

\begin{itemize}
    \item 我们提出了\name框架，利用超图建模结构化知识中的语义一致性，顺序不变性和多元高阶依赖关系，提升大模型在结构化数据上的理解和推理能力。
    \item 我们提出了一个新的超图神经网络来结合下游任务提示学习超图中的结构化知识，拓展大语言模型在结构化数据任务上的能力边界。
    \item 在多种结构化数据的下游任务上进行了大量的实验，验证了我们提出的\name框架的有效性。
\end{itemize}



\end{CJK}