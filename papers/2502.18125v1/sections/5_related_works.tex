\vspace{-0.05in}
\section{Related Works}
% structured knowledge + llms
% 1) serialized methods 
% 2) sql-based queries
Large Language Models (LLMs) excel in a broad spectrum of natural language tasks but face challenges when processing structured knowledge, such as tabular data~\cite{zhao-etal-2023-investigating}. Prior efforts to enhance LLMs' capabilities in handling structured knowledge can be broadly categorized into two main approaches: serialization-based methods~\cite{min2024exploring,hegselmann2023tabllm,jaitly2023towards} and operation-based methods~\cite{li2023sheetcopilot,ye2023decomposers,jiang-etal-2023-structgpt,wang2024chainoftable,lu2023chameleon}. 
Serialization-based methods convert structured data into a linear sequence of tokens, similar to how unstructured textual data is formatted for input into LLMs. TableLlama~\cite{zhang2024tablellama}, a pioneering approach to enhancing LLMs' performance on tabular data, is fine-tuned on the proposed TableInstruct dataset, which comprises serialized tables and task-specific instructions for several representative tabular tasks. %Similarly, GraphWiz~\cite{chen2024graphwiz} is trained on serialized graph data to improve performance on complex graphs, where the edges between nodes are explicitly enumerated. 
However, when dealing with highly complex tables or graphs, inquiry-relevant knowledge may be overlooked within the excessively long serialized token sequences~\cite{zhang2023ho,li2024snapkv}. 
The second category of methods resort to one or a series of operations such as SQL queries to help LLMs reason over structured data~\cite{li2023sheetcopilot,ye2023decomposers,jiang-etal-2023-structgpt,wang2024chainoftable,lu2023chameleon}. For example, Chain-of-Table~\cite{wang2024chainoftable} iteratively samples operations to select specific portions of the table that are tailored to the inquiry. Dater~\cite{ye2023decomposers} transforms the sub-questions generated by CodeX~\cite{chen2021evaluating} into SQL queries, enabling step-by-step multi-hop reasoning. Although these operation-based methods effectively locate the inquiry-relevant knowledge from structured data, they struggle when the target cell or neighboring cells contain missing or incomplete information.

%As messages propagate through the structures in Graph Neural Networks (GNNs), they naturally present themselves as a promising solution for enhancing the capabilities of Large Language Models. 
As messages propagate through the structures in Graph Neural Networks (GNNs), efforts have been made to integrate GNNs with LLMs to address structured knowledge more effectively~\cite{10.1145/3589334.3645627,ren2024survey,chai2023graphllm,tian2024graph,liu2024git}. For example, ~\citet{chai2023graphllm} uses a transformer module to encode the structured knowledge in graphs as the prefix of inputs to the LLMs.
Additionally, graphs serve as powerful tools for representing tabular data~\cite{chen2024hytrel,jin2024hgt}. HGT~\cite{jin2024hgt} explicitly models tables as graphs by connecting various components within the tables to enhance LLM capabilities. %Although effective, constructing this type of heterogeneous graph requires manual annotation of various table components, and the relevance of headers to the cells tends to diminish as the table length increases, thereby harming the hierarchical dependencies. 
Furthermore, HYTREL~\cite{chen2024hytrel} is particularly relevant to our \name as it also empolys hypergraphs to represent tabular data, but it overlooks incorporating the semantics of task within prompts during message propagation. Existing works, while effective, primarily focus on utilizing LLMs rather than improving their inherent capabilities with model-agnostic modules. To the best of our knowledge, we are the first to leverage hypergraphs to enhance the capabilities of LLMs in handling structured knowledge.

