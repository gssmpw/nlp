[
  {
    "index": 0,
    "papers": [
      {
        "key": "hessel-etal-2023-androids",
        "author": "Hessel, Jack and Marasovi\u0107, Ana and Hwang, Jena D. and Lee, Lillian and Da, Jeff and Zellers, Rowan and Mankoff, Robert and Choi, Yejin",
        "title": "Do Androids Laugh at Electric Sheep? Humor ``Understanding'' Benchmarks from The New Yorker Caption Contest"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "zhang2024humor",
        "author": "Zhang, Jifan and Jain, Lalit and Guo, Yang and Chen, Jiayi and Zhou, Kuan Lok and Suresh, Siddharth and Wagenmaker, Andrew and Sievert, Scott and Rogers, Timothy and Jamieson, Kevin and others",
        "title": "Humor in AI: Massive Scale Crowd-Sourced Preferences and Benchmarks for Cartoon Captioning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "Binsted2006",
        "author": "Kim Binsted and others",
        "title": "Computational Humor: An Implemented Model of Puns"
      },
      {
        "key": "Apte1988",
        "author": "Surender Apte",
        "title": "Humor and Laughter: An Anthropological Approach"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "JentzschKersting2023",
        "author": "Sophie Jentzsch and Kristian Kersting",
        "title": "ChatGPT is fun, but it is not funny! Humor is still challenging Large Language Models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "Zhong2023",
        "author": "Shanshan Zhong and Zhongzhan Huang and Shanghua Gao and Wushao Wen and Liang Lin and Marinka Zitnik and Pan Zhou",
        "title": "Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "Baluja2025",
        "author": "Ashwin Baluja",
        "title": "Text Is Not All You Need: Multimodal Prompting Helps LLMs Understand Humor"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "Horvitz2024",
        "author": "Zachary Horvitz and others",
        "title": "Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "Mirowski2024",
        "author": "Piotr W. Mirowski and others",
        "title": "A Robot Walks into a Bar: Can Language Models Serve as Creativity Support Tools for Comedy?"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "NYPost2024",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "LastLaugh2024",
        "author": "Robison, Greg",
        "title": "The Last Laugh: Exploring the Role of Humor as a Benchmark for Large Language Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "zhang2024humor",
        "author": "Zhang, Jifan and Jain, Lalit and Guo, Yang and Chen, Jiayi and Zhou, Kuan Lok and Suresh, Siddharth and Wagenmaker, Andrew and Sievert, Scott and Rogers, Timothy and Jamieson, Kevin and others",
        "title": "Humor in AI: Massive Scale Crowd-Sourced Preferences and Benchmarks for Cartoon Captioning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "Mankoff2008",
        "author": "Robert Mankoff",
        "title": "The New Yorker Cartoon Caption Contest"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "hessel-etal-2023-androids",
        "author": "Hessel, Jack and Marasovi\u0107, Ana and Hwang, Jena D. and Lee, Lillian and Da, Jeff and Zellers, Rowan and Mankoff, Robert and Choi, Yejin",
        "title": "Do Androids Laugh at Electric Sheep? Humor ``Understanding'' Benchmarks from The New Yorker Caption Contest"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "wei2021finetuned",
        "author": "Wei, Jason and Bosma, Maarten and Zhao, Vincent and others",
        "title": "Finetuned Language Models are Zero-Shot Learners"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "schulman2017proximal",
        "author": "Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg",
        "title": "Proximal Policy Optimization Algorithms"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "rafailov2023direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea",
        "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "guo2024grpo",
        "author": "Guo, Daya and Zhu, Qihao and Yang, Dejian and Song, Junxiao",
        "title": "Group Relative Policy Optimization for Aligning Large Language Models"
      }
    ]
  }
]