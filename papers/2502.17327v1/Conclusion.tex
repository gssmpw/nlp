\section{Conclusion, Limitations and Future Work}\label{sec:conclusion}

We have presented \algoname, a generative model that synthesizes diverse characters with distinct motion dynamics using a skeletal structure as input.
It uses a 
transformer-based denoising network, integrating graph information
at key points in the pipeline.
Our evaluation shows a highly informative latent space and notable generalization, even for characters with few or no training samples. 

One limitation of our method stems from imperfections in the input data. Despite our cleaning procedure, certain data artifacts remain unresolved. 
Another limitation is that our data augmentation process is computationally expensive with $O(J^2)$ complexity.


In the future, we plan to use \algoname for skeletal retargeting, multi-character interaction, editing, and various control modalities such as text-based and music-driven animation.
Another potential direction is editing
animations by simply modifying joint labels in the text descriptions.
Finally, future work could further explore DIFT features
in the motion domain.

