%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

%\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper
\documentclass[journal]{IEEEtran}
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
				                                         % you want to use the \thanks command

\newcommand{\todo}[1]{\textcolor{red}{\textbf{TODO: }#1}}
\newcommand\CPP{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\relsize{-3}{\textbf{++}}}}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\DeclareMathOperator*{\minimize}{minimize}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{gensymb}
\usepackage{xcolor}
\usepackage{color}		
\usepackage{multirow}		
\usepackage{array}										
\usepackage{colortbl}
\usepackage{siunitx}
\usepackage[english]{babel}
\usepackage{mathtools}
\usepackage[hidelinks]{hyperref} 
\usepackage{blindtext}
\usepackage[ruled, linesnumbered]{algorithm2e}
\usepackage{pifont}% http://ctan.org/pkg/pifont

%\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{
Generalizable and Fast Surrogates:\\Model Predictive Control of Articulated Soft \\Robots using Physics-Informed Neural Networks
}

%\author{Anonymous%
\author{Tim-Lukas Habich, Aran Mohammad, Simon F. G. Ehlers, Martin Bensch, Thomas Seel, and Moritz Schappler%
\thanks{All authors are with the Leibniz University Hannover, Institute of Mechatronic Systems, 30823 Garbsen, Germany
	(corresponding author: Tim-Lukas Habich, e-mail: \href{mailto:habich@imes.uni-hannover.de}{habich@imes.uni-hannover.de}).}%
\thanks{This work was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) -- 433586601 and INST 187/742-1 FUGG.}%
}

\newif\ifcopyright
	\copyrighttrue
\definecolor{imesorange}{rgb}{0.902,0.478,0.157} 
\definecolor{imesblue}{rgb}{0,0.31,0.6}
\definecolor{imesgreen}{rgb}{0.78,0.82,0.09}
\newcommand{\mm}[1]{\boldsymbol{#1}}
\newcommand{\quot}[1]{``#1"}
\newcommand{\cmark}{\textcolor{green}{\textbf{\ding{51}}}}%
\newcommand{\xmark}{\textcolor{red}{\textbf{\ding{55}}}}%
\newcommand{\redbf}[1]{\textcolor{red}{\textbf{#1}}}
\newcommand{\orangebf}[1]{\textcolor{imesorange}{\textbf{#1}}}
\newcommand{\orange}[1]{\textcolor{imesorange}{#1}}
\newcommand{\bluebf}[1]{\textcolor{imesblue}{\textbf{#1}}}
\newcommand{\greenbf}[1]{\textcolor{imesgreen}{\textbf{#1}}}
\newcommand{\m}[5]{{}_{\mathrm{#2}}^{\mathrm{#3}}{\mm{#1}}^{\mathrm{#4}}_{\mathrm{#5}}} 
\newcommand{\sk}[5]{{}_{\mathrm{#2}}^{\mathrm{#3}}{#1}^{\mathrm{#4}}_{\mathrm{#5}}} 
\newcommand{\inkscape}[3]{
	\begin{figure}[#3]
		\centering
		\resizebox{\linewidth}{!}{\input{images/#1.pdf_tex}}
		\caption{#2} \label{fig:#1}
	\end{figure}
}
\newcommand{\inkscapescale}[4]{
	\begin{figure}[#3]
		\centering
		\resizebox{#4\linewidth}{!}{\input{images/#1.pdf_tex}}
		\caption{#2} \label{fig:#1}
\end{figure}}
\newcommand{\e}[2]{\begin{equation} #1 \label {eq:#2} \end{equation}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\ind}[1]{\mathrm{#1}}
\newcommand{\R}{\mathbb{R}}
\usepackage[mathscr]{euscript}
\newcommand{\fra}[1]{{\mathscr{F}}_{#1}}
\newcommand{\tJac}[1]{\mm J_{\mathcal{T}#1}}
\newcommand{\transpose}{^\mathrm{T}}
\definecolor{Gray}{gray}{0.85}
\newcommand{\cgray}{\cellcolor{Gray}}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
\newcolumntype{N}{@{}m{0pt}@{}}
%Algorithm
\makeatletter
\newcommand{\removelatexerror}{\let\@latex@error\@gobble}
\makeatother

\hyphenation{Vero-Black-Plus}
\hyphenation{mini-mal-ly}
\hyphenation{Mc-Kibben}
\begin{document}
\ifcopyright
\thispagestyle{empty}
\pagestyle{empty}
{\LARGE IEEE Copyright Notice}
\newline
\fboxrule=0.4pt \fboxsep=3pt

\fbox{\begin{minipage}{1.1\linewidth}  % <-- hier Kastenbreiter der Kopfzeile ändern
		This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.  
		
\end{minipage}}
\else
\fi
\graphicspath{{./images/}}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
Soft robots can revolutionize several applications with high demands on dexterity and safety.
When operating these systems, real-time estimation and control require fast and accurate models.
However, prediction with first-principles~(FP) models is slow, and learned black-box models have poor generalizability.
Physics-informed machine learning offers excellent advantages here, but it is currently limited to simple, often simulated systems without considering changes after training.
We propose physics-informed neural networks~(PINNs) for articulated soft robots (ASRs) with a focus on data efficiency.
The amount of expensive real-world training data is reduced to a minimum -- one dataset in one system domain.
Two hours of data in different domains are used for a comparison against two gold-standard approaches:
In contrast to a recurrent neural network, the PINN provides a high generalizability.
The prediction speed of an accurate FP~model is improved with the PINN by up to a factor of 466 at slightly reduced accuracy.
This enables nonlinear model predictive control (MPC) of the pneumatic ASR.
In nine dynamic MPC experiments, an average joint-tracking error of 1.3° is achieved.
\end{abstract}
\begin{IEEEkeywords}
	Modeling, control, and learning for soft robots, physics-informed machine learning, model learning for control, optimization and optimal control
\end{IEEEkeywords}
\section{Introduction}
Building soft robots has been an emerging research field for several years. 
In contrast to conventional rigid robots, they are made of significantly softer materials. 
The resulting compliance makes them suitable robot candidates for intrinsically safe interaction with humans, as less damage is caused in the event of a collision~\cite{Rus.2015}. 
Modeling and controlling such rubber-like robots is challenging mainly due to complex geometries, material nonlinearities, and air compressibility in case of pneumatic actuation~\cite{Xavier.2022}.
Therefore, handcrafted models built with conventional first-principles approaches lack accuracy. 
Even if the accuracy is high due to advanced modeling/identification techniques:
\textit{Prediction with first-principles models is slow} due to numerical integration with small time steps.
This prevents the application of these models in real-time estimation and control.

In contrast, \textit{learning-based modeling} only requires input-output data of the system, and learning dynamics is possible with large time steps. 
Therefore, high prediction speeds with learned forward models are possible and enable such real-time applications.
However, \textit{huge amounts of real-world data} is necessary.
The recording is not only expensive and time-consuming, but there is another central problem:
\textit{Learned models only show good performance within the seen data space} (interpolation). 
For changing domains after training (extrapolation), there is usually poor generalization for such black-box approaches~\cite{Nelles.2020}. 
Combining the advantages of both modeling worlds in a \textit{hybrid strategy} (and omitting the disadvantages), as sketched in Fig.~\ref{fig:cover}(a), is a widespread goal in various research fields.
\inkscapescale{cover}{(a)~The objective of this work is to solve the tradeoff between model accuracy/generalizability and prediction speed in the field of soft robotics by using physics-informed machine learning (ML). (b)~During training, data from \textit{one} training domain is available. Trained surrogate models extrapolate for changed system dynamics in \orange{unseen test domains}. We consider changing the payload and the orientation of the robot base as possible modifications during operation.}{tbp}{1}

Within soft robotics, hybrid approaches incorporating both physical knowledge and machine learning are a highly promising line of research~\cite{DellaSantina.2023} and an unexplored area~\cite{GeorgeThuruthel.2018,Laschi.2023}. 
This work focuses on such an approach by using physics-informed neural networks~\cite{Raissi.2019}. 
As an emerging strategy, PINNs have been used in a wide variety of applications to solve ordinary differential equations~(ODEs), e.g., for modeling nonlinear structural systems, and partial differential equations~(PDEs) such as Navier-Stokes equations~\cite{Cuomo.14.01.2022}. 
In this article, we use PINNs to provide fast and accurate surrogate models of articulated soft robots.
One central requirement is the generalization to unseen dynamics, which were not present when recording training data, such as an additional mass or a changed base orientation, illustrated in Fig.~\ref{fig:cover}(b).
As a real-time application, we choose nonlinear MPC (NMPC), which places high demands not only on prediction accuracy but also on prediction speed due to online optimization. 

The remainder of this article is organized as follows: 
After an overview of related work and our contributions (Sec.~\ref{relatedwork}), preliminaries are introduced (Sec.~\ref{preliminaries}). 
State-space modeling of the soft robot using first principles and PINNs is presented (Sec.~\ref{main_pinn}), followed by the architecture for NMPC.
In Sec.~\ref{experiments}, the identification and learning results are shown, and all models are compared regarding prediction speed and accuracy.
Also, control experiments are presented.
The article ends with conclusions, including future work directions (Sec.~\ref{conclusions}). 
\section{Related Work}\label{relatedwork}
The state of the art for black-box learning is summarized, followed by an overview of hybrid-learning directions with a focus on physics-informed ML for (soft) robots. 
Our contributions and claims complete this section.
\subsection{Black-Box Learning}
Within soft robotics, data-driven approaches for control are still in their infancy~\cite{Wang.2021b}, with much progress having been made in recent years. 
In~\cite{Braganza.2007}, \textit{feedforward neural networks} (NNs) were first applied to feedforward control of soft extensible continuum manipulators. 
Many works also use feedforward NNs for MPC, e.g., of a soft actuator with one degree of freedom (DoF)~\cite{Gillespie.2018}, a soft continuum joint~\cite{Cheney.2024}, and a six-DoF soft robot~\cite{Hyatt.2019,Hyatt.2020}.
In~\cite{Habich.2023}, Gaussian processes are trained to realize learning-based position and stiffness feedforward control of a soft actuator.

Nonlinear material behavior and friction cause hysteresis effects that can be captured using \textit{recurrent neural networks}~\cite{Lipton.29.05.2015}. 
These are used in~\cite{Thuruthel.2017} to learn the direct dynamics of a soft manipulator with a nonlinear autoregressive exogenous model. 
Only an open-loop predictive control policy was implemented, which was further developed in~\cite{Thuruthel.2019} for closed-loop control.
Data-driven MPC was successfully realized for a single actuator by using long short-term memory (LSTM) units~\cite{Luong.2021} and for the ASR from Fig.~\ref{fig:cover}(b) via gated recurrent units (GRUs)~\cite{Schafke.2024}.

Recording real-world data requires a lot of effort, and trained networks only achieve \textit{good accuracy within the seen data space}.
In case of system changes, training must be repeated with new data due to\textit{ poor extrapolation}. 
In addition, convergence is more difficult for high-dimensional NNs required to model multi-DoF robots. 
For this reason, the prediction of the entire state vector was not possible with the chosen network architecture and the existing data in~\cite{Hyatt.2019}.
Thus, only the velocity at the next time step was learned. 
Data-driven control of a soft robot using the Koopman operator is realized in~\cite{Bruder.2021}, and, more recently, a data-efficient method based on neural ODEs~\cite{Chen.2018} was used to model a soft manipulator~\cite{Kasaei.2023}. 
However, the authors do not use physical knowledge, which results in poor generalization.

For \textit{different payloads}, reinforcement learning using an LSTM network as a forward-dynamics model was conducted in~\cite{Centurelli.2022}.
However, even for only $\nu{=}1$ varying model parameter (payload), different real-world datasets with variable payload conditions are necessary as training data.
We do not believe that such black-box approaches are scalable for real-world applications, i.e., $\nu{>}1$: 
For the minimum requirement of two levels per model parameter (e.g., minimum and maximum payload), $2^{\nu}$~datasets are already required.
This implies that for variations of several parameters, a time-consuming and expensive data acquisition is necessary.
In addition, some parameters require finer variations and, therefore, more than two levels due to poor interpolation.  
%However, the authors conclude that with such NNs, no hysteresis effects can be learned. These occur strongly with soft robots because of the nonlinear material behavior and also due to joint friction within ASRs. 
%State-space models of nonlinear systems can be transformed into recurrent neural networks (RNNs) and vice versa \cite{Schussler.2019}. 
 \subsection{Directions of Hybrid Learning}
The problems above can be solved using hybrid approaches by applying \textit{physical knowledge in combination with black-box learning}. 
Within the pioneering work of Nguyen-Tuong and Peters for rigid robots~\cite{NguyenTuong.2010}, knowledge of the parametric dynamics model is incorporated into the nonparametric Gaussian process via mean or kernel function. 
%Unlike NNs, the prediction time of GPs scales linearly in the number of training examples. 
Finite-element models have been used to analyze soft robotic segments, thus generating vast amounts of (simulated) training data for feedforward NNs~\cite{Runge.2017}. 
%However, this requires a highly accurate simulation, which depends to a large extent on material parameters and manufacturing tolerances that are difficult to determine. 
External loads such as gravity or contact forces are not taken into account. 

\textit{Residual/Error learning} of physical models using data is one main direction of hybrid learning.
This has been done for a soft continuum joint~\cite{Johnson.2021}, a soft parallel robot~\cite{Huang.2024}, and soft continuum robots~\cite{Reinhart.2017, Gao.2024, Lou.2024, Jiahao.2024}. 
The main requirement for these approaches is that \textit{the physical model must be efficiently evaluated} during real-time control or estimation, which is often not the case for accurate models of soft robots.
Another possible disadvantage is the need for real experimental data from all domains.
This indicates, due to poor extrapolation, that a new error model must be learned if the system changes after training. 
Consequently, the authors of~\cite{Lou.2024} collect training data in several domains (different payloads between $\SI{0}{\gram}$ and~$\SI{300}{\gram}$) in order to ensure generalization within this data region (interpolation).
However, we argue that trained models should extrapolate across the available training data and that data acquisition for every possible system change is not practical.
In line with this, it was recently concluded that the \textit{generalization beyond bounded training data and the handling of novel dynamical events} should be examined in future work~\cite{Gao.2024}.
Also, the authors of~\cite{Huang.2024} declare robust control with learned models in changing environments as future work.
%A sufficiently accurate model is generally required so that error learning does not become too complex and may not converge for multi-DoF systems. 
%Further, constant joint stiffnesses and damping are assumed in~\cite{Johnson.2021}. This is not true for antagonistic actuators with nonlinear material behavior and joint angle limits~\cite{Vanderborght.2013}. Learning those latent, nonlinear quantities would be more useful. This must be done unsupervised, since \textit{no measured data} for damping or stiffness are available.

Alternatively to error learning, \textit{prior knowledge for constraining NN training} results in less data required. 
This was realized in~\cite{NEUMANN.2013} using extreme learning machines with only one hidden layer. 
Due to the simple network structure, linear constraints, such as the monotonic behavior of the drives or physical restrictions of the soft robot, can be taken into account using quadratic optimization. 
In~\cite{Tariverdi.2021}, a soft manipulator was discretized according to continuum-mechanics principles, and recurren neural networks (RNNs) were trained for each node, taking applied forces and moments for every node as inputs. 
The authors conclude that the supervised learning used might not entirely respect underlying physics, and \textit{trained models are not applicable to changing dynamics without retraining}.

The aforementioned problems are countered by \textit{physics-informed machine learning}~\cite{Karniadakis.2021}, also known as scientific machine learning~\cite{Cuomo.14.01.2022}. 
This is done by including physical knowledge into the training process so that \textit{trained regressors will be aware of governing physical laws}. %Existing NN approaches can be extended to PINNs~\cite{Raissi.2019}, allowing resulting models to plausibly predict outside seen data.
Regarding modeling and control of dynamical systems, physics-informed ML is an alternative approach compared to classical gray-box modeling: 
Instead of (or in addition to) identifying parameters of white-box models consisting of simplified modeling assumptions, physics-informed ML comes from the black-box side without modeling simplifications and is equipped with additional constraints such as symmetries, causal relationships, or conservation laws~\cite{Nghiem.2023}.
Underlying ODEs/PDEs can act as learning bias during the training process, limiting the high-dimensional search space and, therefore, the necessary amount of real data while still maintaining a high generalization. 
This is beneficial since real-world experiments are expensive, and \textit{the training data will rarely represent all possible system conditions during inference}.
Besides high generalizability despite less data, trained surrogate models are considerably faster to evaluate since they do not rely on fine spatiotemporal discretization required for numerical integration of conventional ODEs/PDEs. 
This significantly speeds up the solution of hard optimization problems, such as during nonlinear MPC, which is outlined in a recent overview~\cite{Nghiem.2023} as one of the main opportunities for physics-informed~ML.

%The unsupervised learning of latent nonlinear state variables such as stiffness and damping is also possible, although no measured data for these quantities are available. This is realized by the differential equations encoded in the network~\cite{Zhang.2020,Raissi.2020}.
\subsection{Physics-Informed Machine Learning in (Soft) Robotics}
For rigid systems, physics-inspired networks using Lagrangian and Hamiltonian mechanics were proposed~\cite{Lutter.2019,Lutter.05.10.2021}. 
Mass matrix, centrifugal, Coriolis, gravitational, and frictional forces as well as (potential and kinetic) energies are learned unsupervised by minimizing the ODE residual. 
In~\cite{Nicodemus.2022}, PINNs are employed for the nonlinear MPC of a simulated rigid robot with two degrees of freedom (DoF).

Within soft robotics, hybrid RNNs using responses from the physical model as additional inputs for state observation of one-DoF soft actuators (McKibben actuator and soft finger) are utilized in~\cite{Sun.2022}. 
A physics-informed simulation model is trained from finite-element (FE) data and is used as \textit{efficient-to-evaluate surrogate model} within MPC in~\cite{Lahariya.2022}. 
A simulated one-DoF soft finger is considered, and the authors identify the transfer to physical prototypes and extension to multi-DoF tasks as a future research direction. 
Similarly, PINNs are trained as fast surrogate models of soft robotic fingers in~\cite{Wang.2024,Beaber.2024}.
To enable fast prediction of Cosserat rod statics, PINNs are trained for one simulated tendon-driven segment of a continuum robot~\cite{Bensch.2024}.
A real one-segment tendon-driven soft robot was modeled in~\cite{Liu.2024} using Lagrangian neural networks with measurement data. 
Since the network is trained with offline-recorded data, the generalization to changes of the system dynamics would be poor.

The authors of~\cite{Yoon.2024} propose a kinematics-informed neural network for pneumatic and tendon-driven soft robots with one segment. 
The generalization ability is examined for motor commands, which are unseen during network training. 
Although this is already an important study, generalization to changed systems would be even more crucial. 
Learning system dynamics instead of pure kinematics would also be advantageous for optimal control, which is realized in~\cite{Chhatoi.2023} for an ASR using differential dynamic programming. 
Thereby, forward dynamics are simulated via inversion of the inertia matrix and they declare the realization of MPC as future work. 
For our robot, forward simulation via inversion of the inertia matrix and numerical integration of the \textit{stiff ODE} is very time-consuming. 
Therefore, a fast and accurate surrogate model is necessary for MPC. 

In~\cite{Mendenhall.2024}, experimental data is extended with simulated FE data of \textit{out-of-distribution} (unseen) loading/deformation cases to train a PINN of a single-bellows actuator. 
The main motivation here is to build a fast surrogate of a computationally expensive FE model.
Although the NN is 435 times faster compared to the FEM, one simulation still takes ${>}\SI{20}{\second}$ for the parallel actuator consisting of five bellows. 
This computation time further increases for soft robots with more bellows making it unsuitable for real-time applications. 
Also, only statics are modeled to predict deformations.

Most similar to our proposed approach,~\cite{Wang.2024c} formulate a physics-informed LSTM network with a \textit{variable system property as model input}. 
This allows the training of the model for unseen system properties, which are not present when recording training data. 
However, it is only applied to a simple one-DoF mass-spring-damper system.
Control is also not considered.

\subsection{Contributions}
Laschi et al.~\cite{Laschi.2023} conclude that\textit{ traditional modeling techniques must be incorporated into existing learning strategies} for novel advancements in the soft-robotics field.
Recently, Falotico et al.~\cite{Falotico.2024} also declare the integration of physical principles into machine-learning approaches as a perspective for solving current issues in terms of accuracy and computational efficiency, \textit{explicitly mentioning PINNs}.  
Related soft-robotics work only considers simple (often simulated) actuators and not PINNs for control (PINCs)~\cite{Antonelo.2024}, which are specifically designed for real-time MPC.
To the best of our knowledge, no published work considers PINNs for fast MPC of -- either real nor multi-DoF -- soft robotic systems.
Dynamics changes after training are also predominantly neglected.

Our work \textit{contributes} to this field: 
\textbf{1)}~A first-principles model of our ASR is derived and identified, which is very accurate, but the forward simulation requires significant computing time. 
This justifies the need for an alternative model approach with low computational cost during inference.
\textbf{2)}~For the first time, the original form of physics-informed neural networks -- introduced by Raissi et al.~\cite{Raissi.2019} and formulated for state-space modeling in~\cite{Antonelo.2024,Krauss.2024} -- is applied to a real multi-DoF soft robot.
This is especially relevant for model-based estimation/control, where \textit{models with low computational cost and high accuracy even for changed dynamics} are required.
\textbf{3)}~Generalizability is achieved by extending existing work on PINNs for control~\cite{Antonelo.2024,Krauss.2024} to consider system changes after training.
We perform a systematic hyperparameter optimization (HPO) during the PINN training, which is often neglected due to excessive training times of several days.
\textbf{4)}~Two hours of experimental data of the soft robot are used for evaluation, whereby the dynamics of the robot are changed. 
The proposed model is compared against the gold standard of both modeling worlds, namely a hyperparameter-optimized RNN, and an identified FP model, regarding prediction speed and accuracy.
\textbf{5)}~For the first time, learning-based MPC with PINNs is realized for multi-DoF soft robots and validated in several dynamic real-world experiments, including comparison with a baseline controller.
\textbf{6)}~The whole codebase for learning and control is published as open source\footnote{\label{foot:pinn}After acceptance, the link to the public repository will be placed here.} for possible applications beyond soft robotics. 
All datasets are also available to enable reproducibility.

In sum, we make \textit{three claims}: 
First, our surrogate model outperforms an accurate physics-driven model in terms of prediction speed by orders of magnitude with only slightly reduced accuracy.
Second, by incorporating physical knowledge during training, the PINN achieves higher prediction accuracies and generalization to out-of-distribution data compared to a recurrent neural network.
Throughout this article, all models receive data from only one domain during training/identification and are tested in unseen test domains, as depicted in Fig.~\ref{fig:cover}(b).
Third, accurate learning-based nonlinear MPC with PINNs is enabled for different soft-robot dynamics without the need of retraining the system model or retuning the controller.
This is intended to represent one practical scenario with high demands on prediction speed and accuracy. 
All claims are proven experimentally.

\section{Preliminaries}\label{preliminaries}
This section covers the basics of RNNs and PINNs. 
The method used for optimizing their hyperparameters is also briefly described.
\subsection{Recurrent Neural Networks}\label{rnns}
%the LSTM~\cite{Hochreiter.1997}
In contrast to utilizing physical knowledge, forward dynamics can be trained with black-box approaches on existing training data.
In this work, data-driven state-space modeling is performed using recurrent neural networks as the gold standard for time-series learning. 
RNNs can simulate dynamical systems by incorporating information from previous time steps. 
They can represent state-space models~\cite{Schussler.2019} and are promising for learning long-term dependencies, such as hysteresis. 
The predicted states
\e{[\mm{h}(T_\ind{s}),\hat{\mm{x}}(T_\ind{s})]=\mm{f}_\mathrm{RNN}(\mm{h}_0,\mm{x}_0,\mm{u}_0)}{RNN}
for one step with sample time $T_\ind{s}$ can be computed given hidden state $\mm{h}_0{=}\mm{h}(0)$, initial state $\mm{x}_0{=}\mm{x}(0)$, and input $\mm{u}_0{=}\mm{u}(0)$ at time\footnote{For better comparison, the continuous notation with time $t$ is used throughout the article for all models, although the implementation of RNNs is discrete.} $t{=}0$. 
Gated recurrent units (GRUs)~\cite{Cho.2014} are well suited for time-series learning due to the ability to prevent vanishing and exploding gradients during backpropagation. 
In this work, such an RNN is utilized as the reference method for a purely data-driven approach with its standard implementation, which is described in the following.

During simulation with known initial values $\mm{x}_0$ and $\mm{u}_0$, the hidden state is initialized to $\mm{h}_0{=}\mm{0}$ and then recursively passed for each time step in the same way as the predicted state $\hat{\mm{x}}(T_\ind{s})$ for a given input trajectory $\mm{u}(t) \forall t$.
This behavior is imitated during batch-wise training, whereby gradients of $\hat{\mm{x}}$ and $\mm{h}$ are detached for each new batch.
Note that we use the current state $\mm{x}_0$ as network input due to the MPC context of this work.
%For the sake of completeness, the domain $\mm{d}$ is also passed to the network as input. 
%As already mentioned, the domain is not varied during training in this work and thus will not affect the prediction.

%\begin{align} \label{eq:GRU}
%	\begin{split}
%		\boldsymbol{r}_k &= \boldsymbol{\sigma} (\boldsymbol{W}_{xr} \boldsymbol{x}_{k}+\boldsymbol{b}_{xr}+\boldsymbol{W}_{hr}\boldsymbol{h}_{k-1}+\boldsymbol{b}_{hr}), \\ 
%		\boldsymbol{z}_k &= \boldsymbol{\sigma} (\boldsymbol{W}_{xz} \boldsymbol{x}_{k}+\boldsymbol{b}_{xz}+\boldsymbol{W}_{hz}\boldsymbol{h}_{k-1}+\boldsymbol{b}_{hz}), \\
%		\boldsymbol{n}_k &= \boldsymbol{\tanh} (\boldsymbol{W}_{xn} \boldsymbol{x}_{k} + \boldsymbol{b}_{xn} + \boldsymbol{r}_k \odot (\boldsymbol{W}_{hn} \boldsymbol{h}_{k-1} + \boldsymbol{b}_{hn})), \\
%		\boldsymbol{h}_k &= (1- \boldsymbol{z}_k) \odot \boldsymbol{n}_k + \boldsymbol{z}_k \odot \boldsymbol{h}_{k-1}.
%	\end{split}
%\end{align}
%The hidden state $\boldsymbol{h}_k$ is computed for every time step $k$ by the reset gate $\boldsymbol{r}_k$, update gate $\boldsymbol{z}_k$ and the hidden-state candidate~$\boldsymbol{n}_k$ incorporating the input $\boldsymbol{x}_{k}$ and the hidden state $\boldsymbol{h}_{k-1}$ from previous time step. The trainable weights and biases are represented by $\boldsymbol{W}_\diamond$ and $\boldsymbol{b}_\diamond$, while $\odot$ describes the element-wise multiplication and $\boldsymbol{\sigma}$ the element-wise sigmoid activation.

\subsection{Physics-Informed Neural Networks}
Purely black-box models require a large amount of experimental data, which is very expensive (e.g., costs for staff and maintenance of the system) to acquire in the real world. 
Usually, the available data only describe a few operating points, and trained regressors, therefore, only perform well within these data regions. 
PINNs~\cite{Raissi.2019} provide an excellent opportunity in this \textit{small data regime} to incorporate existing domain knowledge and thus regularize the training process by additional physics-based loss terms. 
Here, the basic idea is that the loss function for optimizing the network weights does not only consist of a data loss $\mc{L}_\ind{d}$ as in RNNs but also takes into account additional knowledge using physics~$\mc{L}_\ind{p}$ and initial-condition/boundary $\mc{L}_0$ losses. 
The additional losses are evaluated on a finite set of \textit{sampled collocation points} in the entire input space and do not require additional real datasets. 
This leads to encoding physical knowledge into the NNs to achieve broad generalizability.

Based on this idea, Antonelo et al.~\cite{Antonelo.2024} reformulate such PINN for control to enable simulations with variable, long-range time horizons.
These PINCs are designed for fast MPC of dynamical systems with state-space models from first principles
\e{\hat{\dot{\mm{x}}}(t)=\mm{f}_\ind{FP}(\mm{x}(t),\mm{u}(t))}{FP_SSM}
with states $\mm{x}(t)$ and inputs $\mm{u}(t)$. 
This is done by the use of several NN inputs such as the time $t$, initial state $\mm{x}_0$, and control action $\mm{u}_0$. 
Prediction for indefinitely long horizons is realized by recursively feeding back the output of the PINN 
\e{\hat{\mm{x}}(T_\ind{s})=\mm{f}_\ind{PINN}(T_\ind{s},\mm{x}_0,\mm{u}_0)\approx{{\mm{x}}}(T_\ind{s})}{antonelo_pinn} 
as initial value $\mm{x}_0$ at the subsequent time step with new input~$\mm{u}_0$. 
The latter is considered constant within each time interval $t{\in}[0,T_\ind{s})$ (zero-order hold assumption). 
Therefore, the NN is only trained for small time steps, and forecasting is done via \textit{self-loop prediction}, which is similar to RNNs.  

The physics loss is determined by means of collocation points evaluated with (\ref{eq:antonelo_pinn}) and compared with (\ref{eq:FP_SSM}) using automatic differentiation $\frac{\partial \hat{\mm{x}}}{\partial t}$.
In addition, the initial condition 
\e{\mm{x}_0=\mm{f}_\ind{PINN}(0,\mm{x}_0,\mm{u}_0)}{b} 
is learned using an initial-condition loss. 
In fact, no real data was used for training a surrogate model to solve the ODEs of two benchmark systems (Van-der-Pol oscillator and four-tank system) in~\cite{Antonelo.2024}.
Their main motivation is the development of an efficient-to-evaluate model instead of the time-consuming numerical integration of (\ref{eq:FP_SSM}). 
This is due to the fact that PINNs are trained to directly compute $\hat{\mm{x}}(T_\ind{s})$, cf. (\ref{eq:antonelo_pinn}), while integrators such as Runge-Kutta methods require smaller step sizes due to instabilities. 

The high prediction speed is accompanied by a considerably increased training effort of several days compared to RNNs.
Especially for dynamical systems with several states, the PINC training is very time-consuming.
To counter this, the domain-decoupled PINN (DD-PINN) was proposed in~\cite{Krauss.2024}, which approximates the solution
\e{\hat{\mm{x}}(T_\ind{s})=\mm{f}_\ind{PINN}(T_\ind{s},\mm{x}_0,\mm{u}_0)=\mm{x}_0+\mm{a}(\mm{\alpha}(\mm{x}_0,\mm{u}_0),T_\ind{s})}{DD-PINN-Pred}
with an ansatz function
\begin{multline}\label{eq:Ansatz_DD-PINN}
\mm{a}(\mm{\alpha},t){=}\sum_{i=1}^{n_\ind{a}} \mm{\alpha}_{1i}{\odot}\big(\exp{({-}\mm{\alpha}_{4i}t)}{\odot}\sin{(\mm{\alpha}_{2i}t{+}\mm{\alpha}_{3i})}\\
{-}\sin{(\mm{\alpha}_{3i})} \big)
\end{multline}
using Hadamard product~(${\odot}$) and element-wise functions $\exp{(\cdot)}$ and $\sin{(\cdot)}$. 
Therefore, a sum of damped harmonic oscillations is assumed as the solution, whereas $\mm{a}(\mm{\alpha},0){\equiv}0$ applies.
In constrast to the PINC~(\ref{eq:antonelo_pinn}), only the ansatz vector
\e{\mm{\alpha}=[\mm{\alpha}_1\transpose,\mm{\alpha}_2\transpose,\mm{\alpha}_3\transpose,\mm{\alpha}_4\transpose]\transpose\in\R^{4\ind{dim}(\mm{x})n_\ind{a}}}{Ansatz_params}
is predicted by the feedforward NN.
Each $\mm{\alpha}_j{=}[\mm{\alpha}_{j1}\transpose,\hdots,\mm{\alpha}_{j n_\ind{a}}\transpose]\transpose$ consists of $n_\ind{a}$ vectors of length $\ind{dim}(\mm{x})$.
The main advantage is that the training converges much faster~\cite{Krauss.2024}.
On the one hand, this is because the computationally expensive automatic differentiation is avoided, as $\frac{\partial \hat{\mm{x}}}{\partial t}$ can be calculated in closed form by time differentiation of (\ref{eq:Ansatz_DD-PINN}), which results to
\begin{multline}\label{eq:Ansatz_DD-PINN_diff}
	\dot{\mm{a}}(\mm{\alpha},t){=}\sum_{i=1}^{n_\ind{a}} \mm{\alpha}_{1i}{\odot}\exp{({-}\mm{\alpha}_{4i}t)}{\odot}\big({-}\mm{\alpha}_{4i}{\odot}\sin{(\mm{\alpha}_{2i}t{+}\mm{\alpha}_{3i})}\\
	{+}\cos{(\mm{\alpha}_{2i}t{+}\mm{\alpha}_{3i})}{\odot}\mm{\alpha}_{2i} \big)
\end{multline}
with element-wise function $\cos{(\cdot)}$.
On the other hand, by decoupling the time domain $t$ from the feedforward NN and constructing the ansatz function (\ref{eq:Ansatz_DD-PINN}), it is possible that the initial condition is always maintained, and thus, $\mc{L}_0{\equiv}0$ applies.
Both PINC and DD-PINN are extended for variable domains in this work so that generalization can be achieved even when the system changes after training.

\subsection{Hyperparameter Optimization}
The hyperparameter optimization of the NNs in this work is conducted with the asynchronous successive halving algorithm~(ASHA)~\cite{Li.} to obtain optimal network architectures. 
ASHA samples within the given boundaries of the hyperparameters and starts multiple training runs based on the available computing resources. 
By monitoring the validation loss of each hyperparameter configuration (trial) during training, poorly performing configurations are stopped by choosing a reduction factor, and the resources are used for new training runs.
All trials are minimally trained until the user-defined grace period is reached.
The latter is a crucial parameter and should be chosen sufficiently large, as otherwise, good trials with slower convergence will be rejected.
In contrast, a grace period that is too long unnecessarily extends the time required for the HPO.
After a defined number of trials, the hyperparameters of the training result with the lowest validation loss are chosen as the optimal set.

\section{Hybrid Learning of ASR Models for MPC}\label{main_pinn}
After describing the soft-robot platform, a state-space model is obtained using first principles and system identification. 
Based on this, our hybrid approach is introduced and integrated into nonlinear MPC as \textit{one possible real-time application}.
\subsection{Soft-Robot Platform}\label{snake_robot}
\inkscapescale{kinematic_chain}{(a) Kinematic chain of the articulated soft robot with $n{=}5$ rotational actuators of height $h{=}\SI{53.4}{\milli\meter}$ and coordinate frames $\fra{i}$. In this work, dynamics are changed by attaching a variable mass $m_\ind{e}$ to the last segment with mass $m_5$ and by changing the base orientation $\beta_\ind{g}$ against gravity. (b)~Real robot with joint angles $q_i$ and antagonistic actuation via pneumatic pressures $p_{i1}$ and $p_{i2}$.}{tbp}{1}
The open-source soft pneumatic robot with antagonistic bellows from~\cite{Habich.2024} is used in this work with $n{=}5$ stacked actuators, which is shown in Figs.~\ref{fig:cover}(b) and~\ref{fig:kinematic_chain}. 
Antagonistically arranged cast bellows with air pressures $\mm{p}_i{=}[p_{i1},p_{i2}]\transpose$ actuate each joint $i$. 
Bellows pressures ${\mm{p}}{=}[\mm{p}_1\transpose,\dots,\mm{p}_n\transpose]\transpose$ and joint angles $\mm{q}{=}[q_1,\dots,q_n]\transpose$ are measured.
The latter is (first-order) low-pass filtered with \SI{1}{\hertz}, and joint velocities~$\dot{\mm{q}}$ are obtained online via numerical differentiation. 
Desired bellows pressures $\mm{p}_\ind{d}$ are set using external proportional valves. 

Further information regarding the semi-modular ASR can be found in the supporting video of~\cite{Habich.2024}.
The published design has been minimally optimized with regard to various points: joint-friction reduction via smaller shaft diameters, reconstruction of the frames to reduce plastic deformation, increased maximum working pressures by using thicker bellows, and larger tube diameters for faster pressure dynamics. 
The improved version is freely available\footnote{After acceptance, the link to the public repository will be placed here.}.
To further reduce friction, we removed the cable/tube guides in each actuator.

The additional end-effector mass~$m_\ind{e}$ and the base orientation~$\beta_\ind{g}$ can be varied, summarized in the \textit{domain variable}~$\mm{\delta}{=}[m_\ind{e},\beta_\ind{g}]\transpose$. 
Data $\mm{D}_\ind{t}$ with several training samples of~$[\mm{q}\transpose,\dot{\mm{q}}\transpose,\mm{p}\transpose,\mm{p}_{\ind{d}}\transpose]\transpose$ in the training domain~$\mm{\delta}_\ind{t}$ (constant additional mass and constant base orientation) is acquired for the identification/training of the FP~model (Sec.~\ref{first_princ}) and the hybrid model (Sec.~\ref{pinn_subsection}). 
\textit{Afterward}, the domain is modified, which aims to represent a change in the real system that occurs after recording training data. 
Our method is intended to generalize even for such changes that are unknown during training. 
As a general illustration of our method, $\nu{=}\ind{dim}(\mm{\delta}){=}2$ different parameters are investigated. 
This can be extended arbitrarily.

%After presenting the modular, pneumatic VSA suitable for snake-robot applications, the learning-based position and stiffness control is introduced in the following (\ref{learn_based_con}). For this purpose, the basics of Gaussian process regression are first described (\ref{pre_GP}).
%\renewcommand{\arraystretch}{1.2}
%\begin{table}[b]
%	%\vspace{1.5mm}
%	\caption{DH parameters of the snake robot}
%	\vspace{-4mm}
%	\label{tab:DH_param}
%	\begin{center}
%		\begin{tabular}{|c|c|c|c|c|}
%			%\rule{0pt}{0ex}
%			\hline
%			$i$&$\theta_i$&$d_i$&$a_i$&$\alpha_i$\\
%			\hline
%			$1$&$q_1$&$0$&$h/2$&$-\pi/2$\\
%			\hline
%			$2$&$q_2$&$0$&$h$&$\pi/2$\\
%			\hline
%			$3$&$q_3$&$0$&$h$&$-\pi/2$\\
%			\hline
%			$4$&$q_4$&$0$&$h$&$\pi/2$\\
%			\hline
%			$5$&$q_5$&$0$&$h$&$-\pi/2$\\
%			\hline
%		\end{tabular}
%	\end{center}
%	\vspace{-1.5mm}	
%\end{table} 
\subsection{First-Principles Modeling and Identification}\label{first_princ}
\subsubsection{Robot Dynamics}

Forward kinematics of the serial robot are obtained using Denavit-Hartenberg notation. 
Based on this, dynamics
%($\mm{\theta}{=}\mm{q}$, $\mm{d}{=}\mm{0}$, $\mm{a}{=}h[1,1,1,1,1/2]\transpose$, $\mm{\alpha}{=}\pi/2[-1,1,-1,1,-1]\transpose$)
%\e{\mm{\tau}_p=\Delta\mm{p}A_pr_p=\mm{M}\ddot{\mm{q}}+\mm{c}+\mm{g}+\mm{K}_\ind{d}\dot{\mm{q}}+\mm{K}_\ind{s}\mm{q}}{dyn}
\e{\overbrace{\underbrace{\mm{\tau}(\mm{p}){=}\mm{g}(\mm{q}){+}\mm{s}(\mm{q})}_{\ind{I}}{+}\mm{M}(\mm{q})\ddot{\mm{q}}{+}\mm{c}(\mm{q},\dot{\mm{q}}){+}\mm{d}(\dot{\mm{q}})}^{\ind{II}}{+}\mm{b}(\mm{q},\dot{\mm{q}})}{dyn}
%\e{\ddot{\mm{q}}=\mm{M}^{-1}(\mm{q})\bigl(\mm{K}_\mathrm{\mm{\tau}}\mm{p}-\mm{c}(\mm{q},\dot{\mm{q}})-\mm{g}(\mm{q})-\mm{D}_\mathrm{v}\dot{\mm{q}} -\mm{C}_\mathrm{s}\mm{q}\bigr)}{fdyn}
are modeled by means of Euler-Lagrange equations with gravitational~$\mm{g}$, Coriolis/centrifugal~$\mm{c}$, and inertial torques~$\mm{M}\ddot{\mm{q}}$ with mass matrix $\mm{M}$ and accelerations $\ddot{\mm{q}}$.
The latter is only necessary for offline system identification and is determined via offline low-pass filtering and (two-times) numerical differentiation of~$\mm{q}$.

To capture joint friction and the bellows behavior, (\ref{eq:dyn}) additionally contains viscous and Coulomb friction $\mm{d}{=}\mm{k}_\ind{v}{\odot}\dot{\mm{q}}{+}\mm{k}_\ind{C}{\odot}\tanh(\dot{\mm{q}}\pi/\dot{q}_\ind{C})$, and stiffness torques $\mm{s}{=}\mm{k}_\ind{s}{\odot}\mm{q}$. 
The hyperbolic tangent with threshold $\dot{q}_\ind{C}$ is used instead of the discontinuous signum function. 

For modeling the contact torques $\mm{b}{=}[b_1,\dots,b_n]\transpose$ at the compliant joint limits, we adapt the nonlinear model of contact normal force~\cite{Azad.2014}, which is an improved version of the Hunt-Crossley model~\cite{Hunt.1975}. 
This leads to
\e{b_{i}=\left\{
	\begin{array}{ll}
		+|\Delta q_i|^{3/2}k_\ind{bs}{+}\sqrt{|\Delta q_i|}\dot{q}_i k_\ind{bd} & \textrm{for}\,q_i>q_\ind{bt} \\
		-|\Delta q_i|^{3/2}k_\ind{bs}{+}\sqrt{|\Delta q_i|}\dot{q}_i k_\ind{bd} & \textrm{for}\,q_i<-q_\ind{bt} \\
		0 &  \textrm{otherwise}\\
	\end{array}
	\right.}{}
for each joint $i$ with $\Delta q_i{=}q_i{-}q_\ind{bt}$, threshold of the soft boundaries $q_\ind{bt}$, and contact parameters $\mm{k}_\ind{b}{=}[k_\ind{bs},k_\ind{bd}]\transpose$.

The left-hand side of~(\ref{eq:dyn}) consists of pressure differences $\Delta\mm{p}{=}[\Delta p_1,\dots,\Delta p_n]\transpose$ with $\Delta p_i{=}p_{i1}{-}p_{i2}$, which are mapped to joint torques~$\mm{\tau}{=}A_\ind{p}r_\ind{p}\Delta\mm{p}$ via pressure area~$A_\ind{p}{=}\SI{639.8}{\milli\meter^2}$ and lever arm~$r_\ind{p}{=}\SI{24.1}{\milli\meter}$ of each actuator. 
The simple linear actuation model is validated experimentally by coupling a torque sensor to the first actuator, which is shown in Fig.~\ref{fig:KMS_experiment}.
For an exemplary pressure trajectory, it is shown that the actuation model is valid for the whole pressure range with maximum pressure $p_\ind{max}{=}\SI{0.7}{\bar}$.
\inkscapescale{KMS_experiment}{Validation of the actuation model: (a)~Experimental setup with torque sensor attached to the first actuator. (b)~The mapping from pressures to torque with factor $A_\ind{p}r_\ind{p}$ applies for the entire pressure range.}{tbp}{1}

\subsubsection{Identification Parameters}
The dynamics equation~(\ref{eq:dyn}) consists of several unknown parameters 
\e{\mm{k}=[\mm{k}_\ind{s}\transpose,\mm{k}_\ind{v}\transpose,\mm{k}_\ind{C}\transpose,\mm{k}_\ind{b}\transpose]\transpose\in\R^{3n+2}.}{ident_params} 
All other parameters are either adopted from CAD software (actuator height, center-of-gravity positions, and entries of the inertia tensors) or measured (segment masses), whereby the bellows, sensor cables, and tubes are neglected. 
The kinematic and inertia parameters of the first $n{-}1$ actuators are equal due to the repetitive structure.

Note that due to the casting process with high reproducibility, the contact parameters $\mm{k}_\ind{b}$ are assumed to be identical for all joints.
The same simplification could be applied to the parameters $\mm{k}_\ind{s}, \mm{k}_\ind{v}$ and $\mm{k}_\ind{C}$ for all joints.
However, the tubes/cables of the last actuator have to overcome considerably higher friction than those of the first actuator.
Similarly, the tubes/cables may also influence the joint stiffness. 
Therefore, we identify different stiffness and friction parameters for each joint.

A three-step least-squares identification is conducted, whereby we choose $\dot{q}_\ind{C}{=}\SI{1}{\degree/\second}$ and ${q}_\ind{bt}{=}\SI{10}{\degree}$ heuristically. 
The identification dataset $\mm{D}_\ind{t}$ is split into three subsets: $\mm{D}_\ind{tI}$, $\mm{D}_\ind{tII}$, and $\mm{D}_\ind{tIII}$. 
Each subset is used to identify different parameters of~(\ref{eq:ident_params}). 
Such a multi-step identification is common to isolate the influence of the different static/dynamic terms and improve the identification result. 
The procedure is explained in the following.

\subsubsection{Identification of Stiffness}
The factors \mbox{$\mm{k}_\ind{s}{=}[k_{\ind{s}1}\dots,k_{\ind{s}n}]\transpose$} are identified using static data inside the soft boundaries: $\mm{D}_\ind{tI}{\subset}\mm{D}_\ind{t}$ with $|\dot{q}_i|{\leq}\dot{q}_\ind{C}{\approx}0\land|{q}_i|{\leq} q_\ind{bt}$. 
The dynamics equation simplifies to (\ref{eq:dyn})-$\ind{I}$ for these data points, as velocity- and acceleration-dependent terms are assumed to be negligible, and contact torques are zero.
This results in the parameter-linear form
\e{\mm{\tau}_{\ind{I}j}=\mm{\tau}_j-\mm{g}_j=\mm{Q}_{\ind{I}j}\mm{k}_\ind{s}}{parameter-linear-I}
for an arbitrary measurement $j$. 
Vertically stacking\footnote{Note that for each datapoint $j$, the dataset categorization ($\ind{I,\,II,\,III}$) is done separately for each actuator $i$. The rows of $\mm{Q}_\diamond$ and $\mm{\tau}_\diamond$ are therefore deleted if the conditions for the respective dataset $\mm{D}_\ind{t\diamond}$ are not fulfilled.
	This ensures that all data is used and only occurs once in all datasets.
	Such separation of the dataset neglects the coupling between the different robot segments.
	If this simplification does not apply to other systems, suitable identification trajectories must be recorded.\label{ident_I_II_III}} $\mm{\tau}_{\ind{I}j}$ and $\mm{Q}_{\ind{I}j}{=}\ind{diag}(\mm{q}_j)$ for all measurements leads to $\mm{\tau}_\ind{I}$ and $\mm{Q}_\ind{I}$, respectively. 
The latent parameters $\mm{k}_\ind{s}{=}\mm{Q}_\ind{I}^\dagger\mm{\tau}_{\ind{I}}$ are obtained by Moore-Penrose pseudo-inversion ($\dagger$).
%\begin{figure}[th] % prediction
%	\vspace{2.5mm}
%	\centering
%	\includegraphics[width=\linewidth]{ident_results}
%	\caption{bla}
%	\label{fig:ident_results}
%	\vspace{-2mm}
%\end{figure}
\subsubsection{Identification of Friction}
The friction parameters $\mm{k}_\ind{vC}{=}[k_{\ind{v}1},k_{\ind{C}1},\dots,k_{\ind{v}n},k_{\ind{C}n}]\transpose$ are identified using dynamic data inside the soft boundaries: $\mm{D}_\ind{tII}{\subset}\mm{D}_\ind{t}$ with $|\dot{q}_i|{>}\dot{q}_\ind{C}\land|{q}_i|{\leq} q_\ind{bt}$. 
The dynamics equation simplifies to~(\ref{eq:dyn})-$\ind{II}$ for these data points, which can be transformed into the parameter-linear form\footnote{$f_\ind{C}(\dot{q}){=}\tanh(\dot{q}\pi/\dot{q}_\ind{C})$}
\begin{equation}
	\label{eq:parameter-linear-II}
	\begin{split}
		\mm{\tau}_{\ind{II}j}&=\mm{\tau}_j-\mm{g}_j-\mm{s}_j-\mm{M}_j\ddot{\mm{q}}_j-\mm{c}_j \\
		& = \underbrace{\begin{bmatrix}
				\dot{q}_{1j}\quad f_\ind{C}(\dot{q}_{1j})&\mm{0}&\mm{0} \\
				\mm{0}&\ddots & \mm{0}\\
				\mm{0}&\mm{0}&\dot{q}_{nj}\quad f_\ind{C}(\dot{q}_{nj})
		\end{bmatrix}}_{\mm{Q}_{\ind{II}j}\in\R^{n\times 2n}}
		\mm{k}_\ind{vC}
	\end{split}.
\end{equation}
Thereby, the stiffness torques $\mm{s}_j$ are computed with the \textit{previously identified} parameters $\mm{k}_\ind{s}$.
Similar to above, $\mm{\tau}_\ind{II}$ and $\mm{Q}_\ind{II}$ are obtained by vertically stacking\footref{ident_I_II_III} $\mm{\tau}_{\ind{II}j}$ and $\mm{Q}_{\ind{II}j}$, respectively. 
This enables the computation of the friction parameters $\mm{k}_\ind{vC}{=}\mm{Q}_\ind{II}^\dagger\mm{\tau}_{\ind{II}}$.

\subsubsection{Identification of Contact Parameters}
The factors $\mm{k}_\ind{b}$ are identified using data outside the soft boundaries $\mm{D}_\ind{tIII}{\subset}\mm{D}_\ind{t}$ with $|{q}_i|{>}q_\ind{bt}$. 
The entire dynamics equation (\ref{eq:dyn}) applies to these data points, which can be transformed into the parameter-linear form
\begin{equation}
	\label{eq:parameter-linear-III}
	\begin{split}
		\mm{\tau}_{\ind{III}j}&=\mm{\tau}_j-\mm{g}_j-\mm{s}_j-\mm{M}_j\ddot{\mm{q}}_j-\mm{c}_j-\mm{d}_j \\
		& = \underbrace{\begin{bmatrix}
				\ind{sgn}(q_{1j})|\Delta q_{1j}|^{3/2}&\sqrt{|\Delta q_{1j}|}\dot{q}_{1j}\\
				\vdots&\vdots \\
				\ind{sgn}(q_{nj})|\Delta q_{nj}|^{3/2}&\sqrt{|\Delta q_{nj}|}\dot{q}_{nj}
		\end{bmatrix}}_{\mm{Q}_{\ind{III}j}\in\R^{n\times 2}}
		\mm{k}_\ind{b}
	\end{split}
\end{equation}
using \textit{previously identified} parameters of stiffness and friction. 
The parameters $\mm{k}_\ind{b}{=}\mm{Q}_\ind{III}^\dagger\mm{\tau}_{\ind{III}}$ are computed in analogy to above\footref{ident_I_II_III}.
%Due to relatively small inertia and Coriolis terms, (\ref{eq:dyn}) can be simplified to obtain first order dynamics
%\e{\dot{\mm{q}}=\mm{K}_\mathrm{d}^{-1}\bigl(\Delta\mm{p}A_pr_p-\mm{g}-\mm{K}_\mathrm{s}\mm{q}\bigr).}{fdyn_red}
%\e{\mm{K}_\mathrm{v}\dot{\mm{q}}+\mm{K}_\mathrm{c}\tanh{(\lambda_\ind{c}\dot{\mm{q}})}+\mm{\tau}_\mathrm{l}(\mm{q},\dot{\mm{q}})=\mm{\tau}_\ind{p}(\mm{p})-\mm{\tau}_\mathrm{g}(\mm{q})-\mm{K}_\mathrm{s}\mm{q}.}{fdyn_red}
%Note that this simplification is \textit{not required} for our hybrid method in~\ref{pinn_subsection}. For other soft robots, (\ref{eq:dyn}) can also be transformed to second order dynamics. However, for the robot platform used in this work, the mass matrix is ill-conditioned and very small time steps are required for numerical integration. The modeling error due to simplification~(\ref{eq:fdyn_red}) is negligible. 

\subsubsection{Forward Prediction}
The inverse dynamics (\ref{eq:dyn}) can be transformed into state-space form
\e{\hat{\dot{\mm{x}}}(t)=\mm{f}_{\ind{FP}\mm{\delta}}(\mm{x},\mm{u},\mm{\delta})}{state-space}
with additional domain input~$\mm{\delta}$.
We denote $\mm{x}{=}[\mm{q}\transpose,\dot{\mm{q}}\transpose]\transpose{\in}\R^{2n}$ as state of the dynamical system and $\mm{u}{=}\mm{p}_\ind{d}{\in}\R^{2n}$ as system input. 
Thereby, $\mm{p}_\ind{d}{=}\mm{p}$ is assumed.
This is valid due to the fast pressure control of the proportional valves so that the desired and measured pressures match closely with a time delay of $\SI{10}{}{-}\SI{80}{\milli\second}$.
If this simplification does not hold, the pressure dynamics could be modeled via a simple first-order system.

Conventional numerical integration of (\ref{eq:state-space}) by using explicit Euler/Runge-Kutta methods can be used to predict the evolution of the states.  
However, very small step sizes ${\leq}\SI{100}{\micro\second}$ are necessary for stable forward simulation of the system due to the stiff ODE. 
This is impractical for use in real-time nonlinear MPC not only due to the excessive computation time, which is further evaluated in Sec.~\ref{performance}.
Also, to enable online optimization during control, the prediction horizon is usually bounded to a few time steps. 
The fine discretization of the model would, therefore, lead to a very short prediction horizon, which considerably reduces the time available to solve an MPC problem.
Thus, \textit{a fast-to-evaluate surrogate model with large time steps is necessary for real-time control}.
\subsection{State-Space Modeling using PINNs}\label{pinn_subsection}
Both first-principles (Sec.~\ref{first_princ}) and data-driven modeling \mbox{(Sec.~\ref{rnns})} have disadvantages.
The former has good generalizability.
However, prediction with numerical integration is computationally expensive. 
The latter learns input-output relationships purely from real data, ignoring any physical principles. 
This leads to poor generalizability, as trained models are strongly overfitted to one (training) domain of the system.
However, numerical integration with fine discretization is not necessary, as it enables fast inference with large time steps.
We combine the advantages of both approaches in the following.
For this purpose, physics-informed neural networks provide an excellent architecture.

The original approach for state-space modeling using PINNs~(\ref{eq:antonelo_pinn}) consists of a network with three inputs: time $t$, initial state $\mm{x}_0$, and input signal $\mm{u}_0$. 
It is trained on artificially sampled collocation points, for which the ODE does not need to be solved.
Real data points can additionally be used if the first-principles model is not accurate enough.
According to~\cite{Wang.02.07.2021}, a trustworthy and reliable physics-informed model should be able to extrapolate to systems with different parameters, external forces, or boundary conditions while maintaining high accuracy.
However, both PINC~\cite{Antonelo.2024} and DD-PINN~\cite{Krauss.2024} represent the state space for one selected parameterization of the dynamical system, but not if this domain changes after training.
For example, the NNs can be trained only for \textit{one} domain (e.g., one particular mass at the end effector $m_\ind{e}$ and base orientation $\beta_\ind{g}$).
Instead, we would like to train a PINN that generalizes to \textit{all} realistic domains during inference to avoid time-consuming data acquisition and retraining. 
For this, the domain~$\mm{\delta}$ is defined as another input of the PINN, which can be any quantity of the first-principles model.

\inkscape{pinn_structures}{PINN structures with inputs in orange, feedforward network in blue with output in green. Both networks are extended by an additional domain input $\mm{\delta}$: (a)~The PINC directly predicts the state $\hat{\mm{x}}$. During training, the network requires computationally expensive automatic differentiation for each collocation point (in each training epoch) and contains an additional loss term~$\mc{L}_\ind{0}$ for the initial condition. (b)~The DD-PINN predicts the ansatz vector~$\mm{\alpha}$ of an ansatz function~$\mm{a}(\mm{\alpha},t)$. The latter can be differentiated in closed form. Also, $\mm{a}(\mm{\alpha},0){\equiv}0$ applies so that no initial-condition loss is necessary. Both drastically speed up the training time.}{tbp}

Similar to (\ref{eq:state-space}), the forward pass of the proposed PINN architecture results in
\e{\hat{\mm{x}}(t)=\mm{f}_{\ind{PINN}\mm{\delta}}(t,\mm{x}_0,\mm{u}_0,\mm{\delta}),}{pinn_forward}
which is visualized in Fig.~\ref{fig:pinn_structures} for both PINC and DD-PINN. 
The feedforward NN consists of $n_\ind{h}$~hidden layers, each with $n_\ind{n}$~neurons and hyperbolic tangent activation function. 
Whereas the feedforward part of the PINC directly predicts~$\hat{\mm{x}}(t)$, the ansatz vector $\mm{\alpha}$ (\ref{eq:Ansatz_params}) is computed within the DD-PINN, which is then used to calculate the state
\e{\hat{\mm{x}}(t)=\mm{x}_0+\mm{a}(\mm{\alpha}(\mm{x}_0,\mm{u}_0,\mm{\delta}),t).}{DD-PINN-Pred-domain}

Collocation points are sampled in $\R^{1{+}4n{+}\nu}$ with user-specified boundaries\footnote{All inputs and outputs of the NN are scaled between $-1$ and $1$ by using this user-specified minimum/maximum values. For the sake of clarity, we do not introduce new symbols for each variable since min-max scaling is straightforward and must be considered during implementation.} $\mc{T}{\subset} \R$, $\mc{X}_0{\subset} \R^{2n}$, $\mc{U}_0{\subset} \R^{2n}$ and $\mc{D}{\subset} \R^\nu$.
In this way, domains can be trained even if no real data is available for that domain. 
During prediction, the current domain $\mm{\delta}$ can then be specified.
We use latin hypercube sampling within the range ${\pm} 1$ for sampling the scaled quantities $t$, $\mm{u}_0$, and $\mm{\delta}$. 
For the scaled states~$\mm{x}_0$, we utilize a multivariate normal distribution with zero mean and standard deviation of $0.4$.
This importance sampling has the advantage that there are fewer collocation points at the broadly selected sampling boundaries, and, for example, more samples are taken to consider the high slope of the Coulomb friction term for $\dot{q}_i{\approx}0$.

%\e{\mc{L}=\eta_\ind{d}\mc{L}_\mathrm{d}+\eta_\ind{b}\mc{L}_\mathrm{b}+\eta_\ind{p}\mc{L}_\mathrm{p}}{loss}
The total (multi-objective) loss $\mc{L}$ is composed of several terms ($\mc{L}_\ind{d},\mc{L}_\ind{p}$, and $\mc{L}_\ind{0}$), whose weights ($\eta_\ind{d},\eta_\ind{p}$, and $\eta_\ind{0}$) are calculated after the first training epoch (cf. Sec.~\ref{pinn_impl}).
The mean squared error (MSE) between network \textit{prediction} and \textit{ground truth} is determined, whereby the determination of both quantities varies depending on the loss.

\subsubsection{Physics Loss $\mc{L}_\ind{p}$}
On collocation points, the residuum
\e{\mm{r}_\ind{p}=\frac{\partial\hat{\mm{x}}}{\partial t}-\mm{f}_{\ind{FP}\mm{\delta}}(\hat{\mm{x}},\mm{u}_0,\mm{\delta})}{r_physics}
is calculated with the modeled system dynamics (\ref{eq:state-space}), zero-order hold assumption for $\mm{u}_0$, and the time derivative of the predicted states $\frac{\partial\hat{\mm{x}}}{\partial t}{=}\frac{\partial}{\partial t}\mm{f}_{\ind{PINN}\mm{\delta}}$.
The latter is done by means of automatic differentiation for the PINC, and can be computed in closed form for the DD-PINN via $\frac{\partial\hat{\mm{x}}}{\partial t}{=}\dot{\mm{a}}$ using~(\ref{eq:Ansatz_DD-PINN_diff}).

\subsubsection{Initial-Condition Loss $\mc{L}_0$}
In order to train a PINN, it is essential to consider the governing initial/boundary conditions. 
For state-space modeling, this loss is defined for the initial condition $\mm{x}_0$, which must match the network output $\mm{f}_{\ind{PINN}\mm{\delta}}(0,\mm{x}_0,\mm{u}_0,\mm{\delta})$. 
The loss is also computed on the sampled collocation points with time $t$ set to zero.
For the DD-PINN, this loss is not necessary since $\mc{L}_0{\equiv}0$ due to the choice of $\mm{a}$.

\subsubsection{Data Loss $\mc{L}_\ind{d}$}
This optional loss term is determined with existing real measurement data in the training domain $\mm{\delta}_\ind{t}$.
Similar to black-box learning, the prediction $\hat{\mm{x}}(T_\ind{s}){=}\mm{f}_{\ind{PINN}\mm{\delta}}(T_\ind{s},\mm{x}_0,\mm{u}_0,\mm{\delta}_\ind{t})$ is compared to the measured ground truth $\mm{x}(T_\ind{s})$ using the specified error metric.

\subsection{Implementation}\label{pinn_impl}
\begin{figure}[t]
	\removelatexerror
	\vspace{2mm}
	\begin{algorithm}[H]
		\caption{Training of PINC or DD-PINN}\label{alg:pinn}
		{\small 
			\SetKwInOut{Input}{In}
			\SetKwInOut{Output}{Out}
			\Input{$n_\ind{e},n_\ind{s},n_\ind{p},n_0,n_\ind{b},n_\ind{a},n_{\lambda},\lambda_\ind{0},\lambda_\ind{min},\mm{X}_\ind{d},\mm{Y}_\ind{d}$}
			\Output{$\mm{w}$}
			$\mm{\eta},\lambda,\mc{L}_0\gets\{[1,1,1]\transpose,\lambda_\ind{0},0\}$\;
			\ForEach{$epoch \in [0,\dots,n_\mathrm{e}-1]$}{
				\If{$epoch\bmod n_\ind{s}=0$}{\label{1st:line:sampling}
					$\mm{X}_\ind{p}\gets$ Sample $n_\ind{p}$ points\;
					\uIf{$n_\ind{a}=0$}{
						\tcp{PINC}
						$\mm{X}_\ind{0}\gets$ Take $n_\ind{0}$ points from $\mm{X}_\ind{p}$ and set $t=0$\;
						$\mm{Y}_\ind{0}\gets\mm{x}_0$ from all samples $\mm{X}_\ind{0}$, cf. (\ref{eq:b})\;
						$\mm{X},\mm{Y}\gets$ Shuffle $[\mm{X}_\ind{d},\mm{Y}_\ind{d}],[\mm{X}_\ind{p},\mm{0}],[\mm{X}_\ind{0},\mm{Y}_\ind{0}]$\;\label{lst:line:Yp}
					}
					\Else{
						\tcp{DD-PINN}
						$\mm{X},\mm{Y}\gets$ Shuffle $[\mm{X}_\ind{d},\mm{Y}_\ind{d}],[\mm{X}_\ind{p},\mm{0}]$\;\label{2st:line:Yp}						
						}
					$\mm{D}'_\ind{t},\mm{D}'_\ind{v}\gets$ Split $\mm{X},\mm{Y}$ in batches of size $n_\ind{b}$\;
				}\label{2st:line:sampling}
				$\bar{\mc{L}}_\ind{v},\bar{\mm{\mc{L}}}_\ind{t}\gets\{0,\mm{0}\}$\;
				\ForEach{$\mm{D}'\in[\mm{D}'_\ind{t},\mm{D}'_\ind{v}]$}{
					\ForEach{$\mm{B}\in\mm{D}'$ with $b$ batches}{
						$\mc{L}_\ind{d}\gets\mathrm{MSE}(\mm{Y}_{\ind{d}\mm{B}},\hat{\mm{Y}}_{\ind{d}\mm{B}})$\;\label{lst:line:Ld}
						$\mc{L}_\ind{p}\gets\mathrm{MSE}(\mm{F}(\hat{\mm{Y}}_{\ind{p}\mm{B}},\mm{X}_{\ind{p}\mm{B}}),\frac{\partial}{\partial t}\hat{\mm{Y}}_{\ind{p}\mm{B}})$\;\label{lst:line:Lp}
						\If{$n_\ind{a}=0$}{
							$\mc{L}_\ind{0}\gets\mathrm{MSE}(\mm{Y}_{\ind{0}\mm{B}},\hat{\mm{Y}}_{\ind{0}\mm{B}})$\;\label{lst:line:Lic}
						}
						$\mc{L}\gets[\mc{L}_\ind{d},\mc{L}_\ind{p},\mc{L}_\ind{0}]\mm{\eta}$\;\label{lst:line:L_total}
						\uIf{$\mm{D}'=\mm{D}'_\ind{t}$}{
							$\bar{\mm{\mc{L}}}_\ind{t}\gets\bar{\mm{\mc{L}}}_\ind{t}+b^{-1}[\mc{L}_\ind{d},\mc{L}_\ind{p},\mc{L}_\ind{0}]\transpose$\;
							$\mm{w}\gets$ Optimize network weights with $\mc{L},\lambda$\;
						}
						\Else{$\bar{\mc{L}}_\ind{v}\gets\bar{\mc{L}}_\ind{v}+b^{-1}\mc{L}$\;}				
					\If{$epoch=0$ and last batch of $\mm{D}'_\ind{t}$}{
						\uIf{$n_\ind{a}=0$}{
							$\mm{\eta}\gets\max(\bar{\mm{\mc{L}}}_\ind{t})[1/\bar{\mc{L}}_\ind{td},1/\bar{\mc{L}}_\ind{tp},1/\bar{\mc{L}}_\ind{t0}]\transpose$\;}\label{lst:line:eta}
						\Else{
							$\mm{\eta}\gets\max(\bar{\mm{\mc{L}}}_\ind{t})[1/\bar{\mc{L}}_\ind{td},1/\bar{\mc{L}}_\ind{tp},1]\transpose$\;\label{2st:line:eta}
						}
					}}
			}
		\If{$epoch>n_\lambda$}{
		$\lambda\gets\mathrm{ReduceLROnPlateau}(\bar{\mc{L}}_\ind{v},n_{\lambda},\lambda_\ind{min})$\;\label{reducelr}}}	
		
		}
		
	\end{algorithm}
	%\vspace{-6mm}
\end{figure} 

For a comprehensive overview, the PINN training described in the previous section is provided in Algorithm~\ref{alg:pinn} as pseudo-code.
We implemented the training in PyTorch~\cite{Paszke.2019}.
Necessary inputs for training a neural network with $n_\ind{n}$~neurons and $n_\ind{h}$~hidden layers are:
\begin{itemize}
	\item $n_\ind{e}$: Number of training epochs
	\item $n_\ind{s}$: The collocation points are resampled all $n_\ind{s}$ epochs for faster convergence and to prevent overfitting
	\item $n_\ind{p}$, $n_\ind{0}$: Number of collocation/initial-condition points
	\item $n_\ind{b}$: Number of collocation, initial-condition and data points in one batch
	\item $n_\ind{a}$: Number of ansatz functions of DD-PINN ($n_\ind{a}{=}0$ implies PINC training)
	\item $n_{\lambda},\,\lambda_\ind{0},\,\lambda_\ind{min}$: The initial learning rate $\lambda_\ind{0}$ is halved when there is no improvement of the mean validation loss $\bar{\mc{L}}_\ind{v}$ after $n_{\lambda}$ epochs until $\lambda_\ind{min}$ is reached (line~\ref{reducelr})
	\item $\mm{X}_\ind{d},\,\mm{Y}_\ind{d}$: Real measurement data from $\mm{D}_\ind{t}$ (optional)
\end{itemize} 

In general, $\mm{X}_\diamond$ describes the input data with $n_\diamond$ points for the respective loss terms. 
Associated with this, $\mm{Y}_\diamond$ is the ground-truth output, which is compared to the network predictions $\hat{\mm{Y}}_\diamond$. 
A mini-batch training of a given feedforward network is conducted.
After resampling at defined intervals, all data points are split into batches such that each batch consists of points for all losses~(lines \ref{1st:line:sampling}--\ref{2st:line:sampling}). 
There is no ground truth $\mm{x}(t)$ necessary when calculating the physics loss. 
This is indicated in line~\ref{lst:line:Yp} (or~\ref{2st:line:Yp}) with $\mm{Y}_\ind{p}{=}\mm{0}$. 
With a $70/30$ split, the training dataset\footnote{We use the $\mm{D}'_\diamond$ to denote the datasets during PINN training, which are not equal to the measured dataset in the training domain $\mm{D}_\ind{t}$.} $\mm{D}'_\ind{t}$ and the validation dataset $\mm{D}'_\ind{v}$ are formed.

For each batch $\mm{B}$ of the two datasets, the losses are calculated (lines~\ref{lst:line:Ld}--\ref{lst:line:L_total}). 
The physics loss is determined with modeled dynamics $\mm{f}_{\ind{FP}\mm{\delta}}(\hat{\mm{x}},\mm{u}_0,\mm{\delta})$, which is denoted with the function $\mm{F}(\cdot,\cdot)$ for the entire batch (line~\ref{lst:line:Lp}). 
Finally, the weights of the network~$\mm{w}$ are updated via the Adam optimizer using the current training loss and the current learning rate.

At the beginning, the weighting factors $\mm{\eta}{=}[\eta_\ind{d},\eta_\ind{p},\eta_\ind{0}]\transpose$ are initialized to ones.
After the first epoch, these are adjusted using the mean losses during all training batches $\bar{\mm{\mc{L}}}_\ind{t}$ (line~\ref{lst:line:eta} or~\ref{2st:line:eta}).  
With these scaling factors, the loss weighting is done during the remaining epochs.

\subsection{Real-Time Application: Nonlinear MPC with PINNs}\label{mpc}
As one possible PINN application, a nonlinear model predictive control of the soft robot is realized. 
Since there is a high demand for prediction speed, the benefits of fast and accurate PINNs can be illustrated here.
Besides considerably improved generalizability of PINNs compared to RNNs, the simple structure of a feedforward NN is another advantage of PINNs.
MPC with RNNs requires the correct initialization of the non-measurable hidden states, which complicates their use in MPC~\cite{Schafke.2024}.

The proposed control architecture is illustrated in Fig.~\ref{fig:control_architecture}.
MPC uses the discrete model of the system to predict the behavior for a prediction horizon of $m$ time steps.
The MPC solver searches for an input trajectory to minimize a user-defined cost function within this prediction horizon.
Only the first input signal $\mm{u}^*_0$ of this optimized input trajectory $[\mm{u}^*_\ind{0},\dots,\mm{u}^*_{m{-}1}]{\in}\R^{2n{\times}m}$ is applied to the real system, and the optimization is solved again with current measured states and new desired positions $[\mm{q}_\ind{d1},\dots,\mm{q}_{\ind{d}m}]{\in}\R^{n{\times}m}$ for $m$ future time steps.
The optimization problem is formulated as

\begin{multline}\label{eq:optimization_problem}
	\minimize_{\mm{u}_0,\dots,\mm{u}_{m-1}} \enspace  \sum_{k=1}^{m-1}  \lVert \mm{q}_{\ind{d}k}-\hat{\mm{q}}_k \rVert_{\mm{Q}_\ind{s}}^{2}+
	\sum_{k=0}^{m-1} \lVert \mm{u}_{k} \rVert_{\mm{R}_\ind{s}}^{2} \\
	+ \lVert \mm{q}_{\ind{d}m}-\hat{\mm{q}}_{m} \rVert_{\mm{Q}_{\ind{t}}}^{2}
\end{multline}
subject to\footnote{For the sake of clarity, we use the index notation $\hat{\mm{x}}_k{=}[\hat{\mm{q}}_k\transpose,\hat{\dot{\mm{q}}}_k\transpose]\transpose{=}\hat{\mm{x}}(kT_\ind{s})$.} $\hat{\mm{x}}_{k+1}{=}\mm{f}_{\ind{PINN}\mm{\delta}}(T_\ind{s},\hat{\mm{x}}_k,\mm{u}_k,\mm{\delta})$, $\mm{u}_{\ind{min}} {\leq}  \mm{u}_{k} {\leq} \mm{u}_{\ind{max}}$, and $\hat{\mm{x}}_0$ obtained from measurements for each MPC cycle. 
State constraints could be defined but are not necessary for our soft robot.
Since the PINN uses scaled inputs/outputs, the entire optimization problem is formulated with scaled (unitless) quantities.
The diagonal weighting matrices for the stage costs of the states $\mm{Q}_\ind{s}$ and inputs $\mm{R}_\ind{s}$, and for the terminal cost $\mm{Q}_\ind{t}$ consist of constant diagonal entries ${Q}_\ind{s}$, ${R}_\ind{s}$, and ${Q}_\ind{t}$.
The input limits are $\mm{u}_{\text{min}}$ and $\mm{u}_{\text{max}}$, which can be obtained by min-max scaling of the system-specific limits with a pressure range of $0{-}\SI{0.7}{\bar}$.
We implemented the nonlinear MPC problem with CasADi~\cite{Andersson.2019} using the interior-point method.
\inkscape{control_architecture}{Control architecture: The nonlinear MPC uses the PINN as the dynamics model. An additional PI controller compensates for model errors.}{tbp}

Similar to the group of Killpack~\cite{Gillespie.2018,Hyatt.2019,Hyatt.2020}, we add the output~$\mm{u}_\ind{PI}$ of a standard PI controller with weighting matrices $\mm{Q}_\ind{P}$ and $\mm{Q}_\ind{I}$ to the MPC output $\mm{u}^*_0$ in order to compensate for model errors.
The PI controller with anti-windup and output saturation outputs the desired pressure differences $\Delta\mm{p}_\ind{PI}{\in}\R^{n}$ of all bellows pairs. 
This is mapped to each antagonist and agonist via 
\begin{equation}
	\begin{split}
		\mm{u}_\ind{PI}&{=}\mm{g}_\ind{PI}(\Delta \mm{p}_\ind{PI})\\
		& {=} [\Delta p_\ind{PI1},{-}\Delta p_\ind{PI1},\dots,\Delta p_{\ind{PI}n},{-}\Delta p_{\ind{PI}n}]\transpose/2.
	\end{split}
\end{equation}
Note that the same was done in~\cite{Habich.2024} without MPC by setting $\mm{u}^*_0{\equiv}\frac{p_\ind{max}}{2}[1,\dots,1]\transpose$.
We compare our work (termed \quot{PINN+NMPC+PI}) with~\cite{Habich.2024} (termed \quot{PI}) in control experiments, cf. Sec.~\ref{control_res}.

\subsection{Domain Knowledge in Practice}
This chapter ends with a brief note regarding the main requirement of our approach: the knowledge of the current domain $\mm{\delta}$.
Such a requirement is also used as a basis in comparable work.
For example, various payloads are known to the controller a priori in~\cite{Centurelli.2022}.
The model in~\cite{Wang.2024c} also receives the load as input.
For easily measurable quantities, these can be determined online in the application, e.g., measurement of the base inclination using an accelerometer.
Alternatively, unmeasurable quantities could be estimated online.
To this end, the proposed PINN architecture with the domain as input is ideally suited, especially for real-time applications, due to the high prediction speed.

\section{Experiments}\label{experiments}
After describing the pneumatic test bench~(Sec.~\ref{test_bench}), the identification and HPO results~(Sec.~\ref{ident_learning_res}) are presented.
All these optimized (first-principles, hybrid, and black-box) models are then experimentally validated~(Sec.~\ref{performance}).
The section ends with experiments on learning-based MPC using the proposed PINN~(Sec.~\ref{control_res}).

\subsection{Test Bench}\label{test_bench}
\inkscapescale{test_bench_n_Act}{Test-bench architecture: Orange color represents communication elements and blue color represents pneumatic components.}{tbp}{1}
The used test bench was presented in~\cite{Habich.2024} and is only briefly described below.
The main structure is illustrated in Fig.~\ref{fig:test_bench_n_Act}.
\subsubsection{Components}
The pneumatic system consists of a supply unit (pressure supply, shut-off valve, and filter regulator) and three-way proportional piezo valves (Festo VEAA-B-3-D2-F-V1-1R1, resolution: $\SI{5}{mbar}$) with integrated pressure control for each bellows.
Industrial compressors generate the compressed air centrally with negligible pressure fluctuations.
Each actuator is equipped with a Hall encoder (Megatron ETA25K, resolution: $0.09\degree$).
\subsubsection{Communication}
The EtherCAT protocol is used with the corresponding open-source tool EtherLab, which was modified with an external-mode patch and a shared-memory real-time interface\footnote{After acceptance, the link to the public repository will be placed here.} for Matlab/Simulink.
%\footnote{\url{https://github.com/SchapplM/etherlab-examples}}
This enables reading in or setting several values (current pressures~$\boldsymbol{p}$, joint angles~$\boldsymbol{q}$, and desired pressures~$\boldsymbol{p}_{\ind{d}}$) with a cycle time of $\SI{1}{\milli\second}$ via the EtherCAT real-time bus with input and output terminals (Beckhoff EL3702 and EL4102).
To avoid damage, an output saturation of the desired pressures~$\boldsymbol{p}_{\ind{d}}$ is implemented with limits $0{-}p_\ind{max}$.

Data can be logged, and settings can be altered during runtime with the development computer~(Dev-PC, \SI{3.6}{\giga\hertz} Intel Core i7-12700K CPU with \SI{16}{\giga\byte} RAM) using Matlab/Simulink 2018b.
The compiled model is executed on the real-time computer~(RT-PC, \SI{4.7}{\giga\hertz} Intel Core i7-12700K CPU with \SI{16}{\giga\byte} RAM).
\subsubsection{MPC Implementation}
CasADi was integrated using its fast \CPP~API for real-time control instead of using Python.
%For this, the MPC problem was compiled into a shared library and then integrated by using an S-function in~\cite{Schafke.2024}.
%However, since no multi-threading was used, the global test-bench frequency for data acquisition had to be reduced to the MPC frequency during control.
%This also means that the numerical differentiation would have to be carried out at a very low frequency ${\ll} \SI{1}{\kilo\hertz}$, which would result in an unusable noisy velocity signal.
The MPC was decoupled from the real-time system using a ROS~server.
Once the MPC problem is solved, the modified $\mm{u}^*_0$ is used. 
Therefore, no fixed MPC frequency was specified, but rather, the fastest possible frequency was set automatically depending on the choice of MPC parameters.
The trained PINN is exported from PyTorch and manually recreated in CasADi.
Due to the use of the widespread ROS framework, this implementation\footref{foot:pinn} can also be beneficial for other applications.

\subsection{Model Identification/Learning}\label{ident_learning_res}
All approaches receive an identical dataset of $\SI{15}{\minute}$ for identification/training in the training domain $\mm{\delta}_\ind{t}{=}[\SI{0}{\gram},\SI{0}{\degree}]\transpose$.
The data was logged at a frequency of $\SI{1}{\kilo\Hz}$ and then downsampled to $\SI{50}{\Hz}$.
Random pressure combinations limited to~$\SI{0.7}{\bar}$ with a linear transition of $\SI{1}{\second}$ were applied to each bellows, with each combination being held for $\SI{3}{\second}$.

\subsubsection{Parameter Identification}\label{ident_res}
With the chosen parameters ($\dot{q}_\ind{C}{=}\SI{1}{\degree/\second}$ and ${q}_\ind{bt}{=}\SI{10}{\degree}$), the datasets $\mm{D}_\ind{tI}$, $\mm{D}_\ind{tII}$, and $\mm{D}_\ind{tIII}$ comprise \SI{40}{\percent}, \SI{17}{\percent}, and \SI{43}{\percent} of all datapoints, respectively. 
Various combinations of $\dot{q}_\ind{C}$ and ${q}_\ind{bt}$ were tested, whereby the identified parameters only changed marginally.

The results are presented in Table~\ref{tab:ident_params}.
For both the stiffness~$\mm{k}_\ind{s}$ and the friction parameters~$\mm{k}_\ind{v}$ and~$\mm{k}_\ind{C}$, a trend can be seen that these increase slightly towards the distal end.
As already mentioned, this is attributed to the routing of the cables and tubes in the robot body.
The parameters shown remain unchanged after this offline identification and serve as the training foundation for the PINNs.
To illustrate the effects of the various parameters, Fig.~\ref{fig:ident_results} shows the characteristics of different positions and velocities of an exemplary joint after identification.

\begin{table}[b]
	\centering
	\caption{Identified parameters $\mm{k}$ of (\ref{eq:dyn})}
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		param.&unit& $i{=}1$&$i{=}2$&$i{=}3$&$i{=}4$&$i{=}5$ \\
		\hline
		$k_{\ind{s}i}$ &\SI{}{\newton\meter/\degree}&$0.035$&$0.034$&$0.043$&$0.035$&$0.041$\\
		\hline
		$k_{\ind{v}i}$ &\SI{}{\newton\meter\second/\degree}&$0.008$&$0.008$&$0.010$&$0.011$&$0.011$\\
		\hline
		$k_{\ind{C}i}$ &\SI{}{\newton\meter}&$0.171$&$0.214$&$0.233$&$0.204$&$0.232$\\
		\hline
		$k_\ind{bs}$ &\SI{}{\newton\meter/\degree^{3/2}}&\multicolumn{5}{c|}{$0.010$}\\
		\hline
		$k_\ind{bd}$ &\SI{}{\newton\meter\second/\degree^{3/2}}&\multicolumn{5}{c|}{$0.005$}\\
		\hline
	\end{tabular}
	\label{tab:ident_params}
\end{table}

\inkscape{ident_results}{Stiffness, damping, and contact characteristics of joint $i{=}3$ with identified parameters for a simulative variation of (a)~position~$q_3$ with a kink at the threshold of the soft boundaries ${\pm} q_\ind{bt}$ and (b)~velocity~$\dot{q}_3$. Curves illustrate the identified parameters from joint $i{=}3$, and are qualitatively similar for the other joints.}{tbp}

\subsubsection{PINC vs. DD-PINN}\label{training_res}
To first get an impression of the training, the proposed PINC and DD-PINN with domain input $\mm{\delta}$ were each trained with identical parameters ($n_\ind{s}{=}250$, $n_\ind{p}{=}\SI{100000}{}$, $n_\ind{b}{=}512$, $n_\lambda{=}50$, $\lambda_\ind{0}{=}\SI{5e{-4}}{}$, $\lambda_\ind{min}{=}\SI{5e{-5}}{}$).
Both trainings were conducted on one core with \SI{8}{\giga\byte} RAM of a computing cluster (\SI{2.6}{\giga\hertz} Intel Xeon Gold 6442Y CPU).
The PINC receives $n_\ind{0}{=}0.2n_\ind{p}$ initial-condition points.
In contrast, the DD-PINN does not require these points, as $\mc{L}_\ind{v0}{\equiv}\mc{L}_\ind{t0}{\equiv}0$ applies due to the structural property of the used ansatz function (\ref{eq:Ansatz_DD-PINN}) with $n_\ind{a}{=}50$.
A simple feedforward NN with $n_\ind{n}{=}100$ neurons and $n_\ind{h}{=}2$ hidden layers is trained.
The user-specified boundaries are set to 
\begin{equation} \label{boundaries}
	\begin{split}
		\mc{T}&=[0,\kappa T_\ind{s}], \\
		\mc{X}_0&=[-\kappa q_\ind{max},\kappa q_\ind{max}]^{n}\times[-\kappa \dot{q}_\ind{max},\kappa \dot{q}_\ind{max}]^{n},\\
		\mc{U}_0&=[0,\kappa p_\ind{max}]^{2n}\,\ind{and}\\
		\mc{D}&=[0,\kappa m_\ind{emax}]{\times}[0,\kappa \beta_{\ind{gmax}}]
	\end{split}
\end{equation}
with $q_\ind{max}{=}\SI{25}{\degree}$, $\dot{q}_\ind{max}{=}\SI{30}{\degree/\second}$, $p_\ind{max}{=}\SI{0.7}{\bar}$, $m_\ind{emax}{=}\SI{200}{\gram}$ and $\beta_{\ind{gmax}}{=}\SI{90}{\degree}$.
The limits are system-specific, and the factor $\kappa{=}1.25$ is used to train for slightly larger ranges, also done in~\cite{Nicodemus.2022}.
We chose the sample time $T_\ind{s}{=}\SI{20}{\milli\second}$, which is further discussed in Sec.~\ref{HPO_res}.

Note that no real data points ($n_\ind{d}{\equiv}0$) are used for all PINNs in this work, similar to~\cite{Antonelo.2024,Krauss.2024}. 
In our case, adding data points has no advantage due to the high accuracy of the first-principles model (cf. Sec.~\ref{pred_acc}), which is \textit{already identified with the real data} from the training domain.
Moreover, this would slow down and complicate the training even further due to the additional loss term.

The training progress for both networks is illustrated in Fig.~\ref{fig:train_time}.
It can be seen that the DD-PINN converges much faster for two main reasons.
First, no initial-condition loss needs to be minimized. 
Second, $\frac{\partial\hat{\mm{x}}}{\partial t}$ is calculated in closed form for all $n_\ind{p}$~collocation points so that no computationally expensive automatic differentiation is required. 
The latter considerably influences the average duration of one training epoch $\bar{T}_\ind{e}$, allowing it to be reduced by $\SI{41.7}{\percent}$ (PINC: $\bar{T}_\ind{e}{=}\SI{274.0}{\second}$, DD-PINN: $\bar{T}_\ind{e}{=}\SI{159.7}{\second}$).
Thus, the DD-PINN was trained for \SI{1500}{} epochs, while the PINC could only be trained for 875 epochs within the recorded training time of approx. \SI{67}{\hour}.
A systematic HPO can be enabled in a reasonable time due to this considerably faster convergence.
Therefore, the DD-PINN architecture with $n_\ind{e}{=}\SI{1500}{}$ is used for the rest of this work.
\begin{figure}[t]
	\vspace{2.5mm}
	\centering{\includegraphics[width=\linewidth]{images/train_time_pinc_ddpinn.pdf}}
	\caption{Training convergence of two PINN architectures (PINC and DD-PINN), which are adapted for our system and extended to enable additional domain input $\mm{\delta}$. The validation physics losses $\mc{L}_\ind{vp}$ and validation initial-condition loss $\mc{L}_\ind{v0}$ are plotted over training time. Both networks are trained on the same hardware with identical parameters. For the PINC, two competing loss terms must be minimized, whereby the initial-condition loss is weighted with $\eta_0$ ($\eta_\ind{p}{=}1$). The DD-PINN has a considerably improved convergence, which is indicated by the \textit{lower physics loss}. Also, the initial-condition loss from the DD-PINN ($\mc{L}_\ind{v0}{\equiv}0$) is always less than PINC's $\mc{L}_\ind{v0}$. We, therefore, use the DD-PINN in this work.}
	\label{fig:train_time}
\end{figure}
\subsubsection{Hyperparameter Optimization}\label{HPO_res}
Compared to RNNs, the training of PINNs is very time-consuming and requires considerable resources of computing hardware. 
We suspect that this is the main reason why systematic hyperparameter optimizations of PINNs are relatively rare in the state of the art.
This is in line with a recent overview~\cite{Nghiem.2023}, which declares such HPO as an open challenge.
However, since many hyperparameters significantly influence the network performance, we perform an HPO.
For this purpose, the computing cluster from the previous section was used, which allows several PINNs to be trained in parallel.

Before an HPO can be carried out, the most crucial training parameters must first be defined.
For the DD-PINN, these are $n_\ind{n}$, $n_\ind{h}$, $\lambda_0$ and $n_\ind{a}$.
All other parameters are taken from the previous section.
At this point, it must be noted that $T_\ind{s}$ is also a crucial parameter for the PINN performance.
For large sampling times $T_\ind{s}$, the prediction speed is improved, but the accuracy degrades.
The opposite is true for a small $T_\ind{s}$.
This tradeoff was already highlighted in~\cite{Zeipel.2024} for the PINC and applies analogously to the DD-PINN.
Since the physics loss also shows a tendency to decrease as $T_\ind{s}$ decreases, integration into an HPO with ASHA is not recommended. 
It would always tend towards a very small $T_\ind{s}$ without considering the prediction speed.
This parameter was therefore tuned iteratively, and a sample time $T_\ind{s}{=}\SI{20}{\milli\second}$ proved to be suitable.
The later use in the MPC was also taken into account here, as the sample times must not be too small.
Otherwise, there would be problems similar to those with the FP~model~(cf. Sec.~\ref{first_princ}).

During the HPO, 35 networks are trained simultaneously, with a total of 100 trials being examined.
As PINN training converges slowly, ASHA's grace period is set to 500 epochs with a reduction factor of 2.
To keep the computation time reasonable, only $n_\ind{e}{=}\SI{1000}{}$ epochs are trained during the HPO.
The best trial can be further trained afterward.

\inkscape{HPO_results}{Results of hyperparameter optimization with $100$ trials each: Poorly performing trials are shown in gray, the best ten in blue, and the best one in green. The validation loss $\mc{L}_\ind{v}$ is considerably reduced by systematically tuning the networks' hyperparameters. (a)~The optimization of the most important PINN parameters ($n_\mathrm{n}$, $n_\mathrm{h}$, $\lambda_0$ and $n_\mathrm{a}$) took approx. six days due to the long training times on the specified cluster hardware. (b)~The optimization of the most important RNN parameters ($n_\mathrm{n}$, $n_\mathrm{h}$, $\lambda_0$ and $r_\mathrm{d}$) took ${<}\SI{14}{\hour}$ on the specified cluster hardware with minor performance.}{tbp}

The results are visualized in Fig.~\ref{fig:HPO_results}(a).
It can be seen that the systematic HPO can considerably minimize the validation loss.
Note that with such an HPO, the limits of the hyperparameters must be adjusted iteratively so that no optimal parameters lie at their boundaries.
Otherwise, the true optimum of the parameter could be outside the limits.
This iterative process, in combination with the HPO duration of approx. six days, therefore, requires a substantial computation and time effort.

The HPO of the RNN is performed similarly, and the results are shown in Fig.~\ref{fig:HPO_results}(b).
Since RNNs converge much faster, $n_\ind{e}{=}300$, $n_\ind{\lambda}{=}10$ are chosen, and ASHA's grace period is set to 100 epochs.
The PINN-specific parameter $n_\ind{a}$ is replaced by the dropout rate $r_\ind{d}$ as an important training parameter of the RNN.
Although significantly inferior cluster hardware (\SI{2.3}{\giga\hertz} Intel Cascade Lake Xeon Gold 6230N CPU) was used, only ${<}\SI{14}{\hour}$ is required for the HPO of the RNNs.

\subsection{First Principles vs. Hybrid vs. Black Box}\label{performance}
The following experiments underline our \textit{first and second claims} regarding prediction speed and generalizability, which are illustrated in Fig.~\ref{fig:cover}(a).
As the model base, we use the identified first-principles model and the PINN and RNN (both hyperparameter-optimized) from the previous section.

\subsubsection{Prediction Speed}\label{pred_speed}
For a fair comparison of the prediction times, the physics-driven state-space model~(\ref{eq:state-space}) and the forward passes of the RNN~(\ref{eq:RNN}) and PINN~(\ref{eq:pinn_forward}) were reimplemented and mex-compiled in Matlab R2023a.
A \SI{2.5}{\giga\hertz} Intel Core i5-10300H CPU with \SI{16}{\giga\byte} of RAM running Windows was used for evaluation.
The explicit-Euler method and the Runge-Kutta fourth-order method (RK4) were used for the numerical integration of the physical model.
These are often used in the MPC as integrators due to the constant step size. 

The results for an exemplary \SI{100}{\second} trajectory of the input signals are listed in Table~\ref{tab:pred_speed}. 
The time for each prediction horizon of $T_\ind{s}{=}\SI{20}{\milli\second}$ was measured for all methods. 
The statistical data (mean, maximum, and minimum), therefore, refer to $\SI{5000}{}$ time measurements, whereby a different number of function calls $n_\ind{calls}$ are required per measurement depending on the method.

Due to the stiff ODE~(\ref{eq:state-space}), fine step sizes (Euler: \SI{20}{\micro\second}, RK4: \SI{100}{\micro\second}) are necessary for robust forward simulation of the system.
In contrast, only \textit{one} function call of the networks' forward passes is required for a horizon of $T_\ind{s}$.
This demonstrates one key advantage of using model-learning approaches.
On average, the PINN is faster than numerical integration using explicit Euler or RK4 by a factor of 466 and 378, respectively.
Due to the simpler network structure, the PINN is also slightly faster than the RNN, which is also presented in Table~\ref{tab:pred_speed}.

\begin{table}[b]
	\centering
	\caption{Computation time for predicting a horizon of $T_\ind{s}=\SI{20}{\milli\second}$. Statistics were computed for a \SI{100}{\second} input trajectory.}
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		method&mean$/\SI{}{\milli\second}$& max$/\SI{}{\milli\second}$ & min$/\SI{}{\milli\second}$ & $n_\ind{calls}$ \\
		\hline
		PINN &$\mathbf{0.04}$&$\mathbf{0.98}$ &$\mathbf{0.03}$  &$\mathbf{1}$\\
		\hline
		RNN &$0.07$&$1.22$ &$0.05$  &$\mathbf{1}$\\
		\hline
		Euler &$18.64$&$35.11$ &$17.61$  &$1000$\\
		\hline
		RK4 &$15.11$&$28.61$ &$14.30$  &$200$\\
		\hline
	\end{tabular}
	\label{tab:pred_speed}
\end{table}

With regard to a real-time nonlinear MPC, the results show that the numerical integration of the physics-driven state-space model is unsuitable.
This is mainly due to the long prediction times.
Even if we ignore this aspect, the required fine temporal discretization of the physics model and, thus, the high number of function calls is problematic.
The number of discrete time steps $m$ in the prediction horizon of the MPC influences the solution times considerably and is, therefore, usually set to a few time steps, e.g., $m{=}5$.
This would lead to very short prediction horizons (Euler: \SI{100}{\micro\second}, RK4: \SI{500}{\micro\second}), which results in difficulties such as aggressive MPC actions.
Online optimization cannot be solved in such a short time frame, as solver frequencies of $2{-}\SI{10}{\kilo\hertz}$ would be required.
\subsubsection{Generalizability}\label{pred_acc}
For all test datasets, random pressure combinations limited to $\SI{0.7}{\bar}$ with a linear transition of $\SI{1}{\second}$ were applied to each bellows.
In contrast to the training data, each combination is held for only $\SI{1}{\second}$, which leads to more dynamic motions.

\inkscape{spider_plot}{Accuracy of FP model, RNN, and PINN on twelve test datasets in different domains $\mm{\delta}{=}[m_\ind{e},\beta_\ind{g}]\transpose$ with \SI{10}{\minute} duration each. 
	The ODE of the FP model is numerically integrated with an advanced implicit solver to achieve results of the highest possible accuracy. 
	(a)~Mean absolute error (MAE) $\bar{e}_q$ between true and predicted positions averaged over all $n$ joints. 
	The PINN is only marginally inferior to the FP model, whereas the RNN has large errors due to poor generalization. 
	(b)~MAE $\bar{e}_{\dot{q}}$ between true and predicted velocities averaged over all $n$ joints. 
	PINN and RNN are only marginally less accurate than the FP model, whereby the error of the RNN increases with higher mass $m_\ind{e}$ due to poor generalization.}{tbp}

Many publications only investigate a generalization for changed input trajectories, for which this would already be sufficient.
However, we also want to investigate the generalizability to changes in system dynamics after training-data acquisition.
For this purpose, test datasets with a duration of $\SI{10}{\minute}$ for twelve different test domains $\mm{\delta}{\in}[\SI{0}{\gram},\SI{50}{\gram},\SI{100}{\gram},\SI{200}{\gram}]{\times}[\SI{0}{\degree},\SI{45}{\degree},\SI{90}{\degree}]$ were recorded. 
Note that an additional mass of $m_\ind{e}{=}\SI{200}{\gram}$ is approx. \SI{20}{\percent} of the total mass of the robot, and therefore, represents a considerable system change.
In order to also investigate possible bellows changes over time, the test datasets were recorded \textit{more than two months later} than the training dataset.
The robot continued to operate during this time, which required bellows to be replaced due to cracks.
We believe this is important because the identified parameters listed in Table~\ref{tab:ident_params} are fixed and serve as the basis for training the PINN.

The results for all test datasets are visualized in Fig.~\ref{fig:spider_plot}.
To have a first-principles baseline with the highest possible accuracy, an implicit Runge-Kutta method (Radau IIA of order five~\cite{Hairer.1996}) is used for numerical integration. 
This is more advanced than explicit Euler or RK4, and also has the advantage that no discrete step size has to be chosen/tuned.

Fig.~\ref{fig:spider_plot}(a) demonstrates the advantage of the PINN over the RNN.
The more changes are present after training, the larger the RNN error becomes: 
For $m_\ind{e}{=}\SI{200}{\gram}$ and $\beta_\ind{g}{\in}[\SI{45}{\degree},\SI{90}{\degree}]$, this position error is more than twice as large compared to the performance in the training domain~$\mm{\delta}_\ind{t}$.
In contrast, our proposed PINN consistently achieves an accuracy that is only slightly worse than the FP model, which has to be integrated with a substantial time effort.
Even in the training domain, the PINN achieves a lower position error than the RNN.

\begin{figure}[t]
	\vspace{2.5mm}
	\centering{\includegraphics[width=\linewidth]{images/val_trajectory_short.pdf}}
	\caption{Prediction results for $q_2$ and $q_5$ on test datasets in (a)--(b)~training domain $\mm{\delta}{=}\mm{\delta}_\ind{t}{=}[\SI{0}{\gram},\SI{0}{\degree}]\transpose$ and (c)--(d)~unseen test domain $\mm{\delta}{=}[\SI{100}{\gram},\SI{45}{\degree}]\transpose$. Within the unseen test domain, the dynamics of joint $i{=}2$ are mainly changed due to gravity. This is taken into account by the FP model and the PINN due to the exploited physical knowledge. During training, data in this test domain was not available. Therefore, large deviations occur with the RNN due to poor generalization.}
	\label{fig:traj_test}
\end{figure}
To elaborate further, Fig.~\ref{fig:traj_test} shows prediction results for a short excerpt of tests in two different domains. 
First, the RNN often shows poor accuracy at the beginning because the unmeasurable hidden states have to be initialized first. 
Moreover, it can be seen that the prediction of $q_2$, in particular, is worse for new domains, as this is most affected by the system change.
Such disadvantages do not exist with the PINN.

There are qualitatively similar results on the velocity level, which is shown in Fig.~\ref{fig:spider_plot}(b).
The further away from the training domain, the worse the RNN generalizes.
Since the base orientation~$\beta_\ind{g}$ only has a minor influence on the velocity, the poor generalizability of the RNN is less present.
However, the mass $m_\ind{e}$ influences the velocity.
Therefore, at higher inertia, a higher prediction error of the RNN can be seen.

\subsection{Control Results}\label{control_res}
In final control experiments with the soft robot, the \textit{third claim} is confirmed.
It should first be mentioned that all controller gains were manually tuned once in the training domain and then remained unchanged.
The PI gains are set to $\mm{Q}_\ind{P}{=}\ind{diag}(40,60,110,110,100)\SI{}{\milli\bar/\degree}$ and $\mm{Q}_\ind{I}{=}\ind{diag}(40,40,80,60,110)\SI{}{\milli\bar/(\degree\second)}$.
For the nonlinear MPC problem, a prediction horizon with $m{=}5$ steps was chosen and the unitless gains were tuned to ${Q}_\ind{s}{=}5$, ${R}_\ind{s}{=}0.7$ and ${Q}_\ind{t}{=}10$.
Automated tuning could further improve the control performance, which is not the scope of this work.
Nevertheless, the same PI controller with identical gains is used in both approaches.
Only the input signal $\mm{u}^*_0$ is different (PINN+NMPC+PI: $\mm{u}^*_0$ from online optimization, PI: $\mm{u}^*_0$ constant, cf. Sec.~\ref{mpc}).


\begin{table}[t]
	\centering
	\caption{Tracking errors and NMPC frequency for control experiments in different domains $\mm{\delta}{=}[m_\ind{e},\beta_\ind{g}]\transpose$ \\with $\SI{40}{\second}$ duration each}
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		$\beta_\ind{g}/\SI{}{\degree}$ &$m_\ind{e}/\SI{}{\gram}$&controller & $\bar{e}_q/\SI{}{\degree}$ & $f_\ind{NMPC}/\SI{}{\hertz}$ \\
		\hline
		\multirow{6}{*}{$0$} 	& \multirow{2}{*}{$0$} 		& PINN+NMPC+PI &$\mathbf{1.20}$ & $19.4$\\ \cline{3-5} 
		&                   & PI       &$1.28$ & --\\ \cline{2-5} 
		& \multirow{2}{*}{$100$} 	& PINN+NMPC+PI &$\mathbf{1.20}$ & $20.5$\\ \cline{3-5} 
		&                   & PI       &$1.25$ & --\\ \cline{2-5} 
		& \multirow{2}{*}{$200$} 	& PINN+NMPC+PI &$1.34$ & $19.3$\\ \cline{3-5} 
		&                  			& PI       &$\mathbf{1.32}$ & --\\ \hline
		\multirow{6}{*}{$45$} 	& \multirow{2}{*}{$0$} 		& PINN+NMPC+PI &$\mathbf{1.29}$ & $18.4$\\ \cline{3-5} 
		&                   		& PI       &$1.42$ & --\\ \cline{2-5} 
		& \multirow{2}{*}{$100$} 	& PINN+NMPC+PI &$\mathbf{1.12}$ & $19.6$\\ \cline{3-5} 
		&                   		& PI       &$1.26$ & --\\ \cline{2-5} 
		& \multirow{2}{*}{$200$} 	& PINN+NMPC+PI &$1.32$ & $19.2$\\ \cline{3-5} 
		&                   		& PI       &$\mathbf{1.27}$ & --\\ \hline
		\multirow{6}{*}{$90$} 	& \multirow{2}{*}{$0$} 		& PINN+NMPC+PI &$\mathbf{1.39}$ & $18.5$\\ \cline{3-5} 
		&                   		& PI       &$1.68$ & --\\ \cline{2-5} 
		& \multirow{2}{*}{$100$} 	& PINN+NMPC+PI &$\mathbf{1.28}$ & $18.8$\\ \cline{3-5} 
		&                   		& PI       &$1.47$ & --\\ \cline{2-5} 
		& \multirow{2}{*}{$200$} 	& PINN+NMPC+PI &$\mathbf{1.76}$ & $17.8$\\ \cline{3-5} 
		&                   		& PI       &$1.90$ & --\\ \hline
	\end{tabular}
	\label{tab:mpc_exp}
\end{table}

Experiments were conducted in nine domains with different desired trajectories of the positions.
For this purpose, ramp trajectories were generated, whereby both the rise time in the range $0.5{-}\SI{2}{\second}$ and the height of the plateau in the range ${\pm}\SI{18}{\degree}$ are determined randomly.
The duration of each plateau is set to \SI{1}{\second}.
The resulting trajectories correspond to dynamic movements of the robot, whereby some sections are not even feasible.

The results are presented in Table~\ref{tab:mpc_exp}.
In general, accurate trajectory tracking is realized with the nonlinear MPC, and the fast PINNs enable control frequencies $f_\ind{NMPC}$ up to \SI{20.5}{\hertz}.
It can be seen that the NMPC approach mostly achieves better tracking results due to the feedforward character.
Also, more dynamic responses are obtained by optimizing the input signals for desired references of future time steps.
On average, an improvement of \SI{7.4}{\percent} can be realized with the combination of NMPC and PI control.
It must be noted that the MPC runs with a significantly lower control frequency than the PI control ($\SI{1}{\kilo\hertz}$).
Thus, better computing hardware would increase $f_\ind{NMPC}$, which could further improve the tracking performance.
Depending on the system dynamics, this improvement can also be higher.
If state constraints were required for other systems, these could also be easily handled using the MPC framework.

Exemplary control results for one test domain are visualized in Fig.~\ref{fig:control_plot}.
It can be seen that for joint one in particular, the steep changes can only be tracked with a slight delay due to the high inertia.
In addition, for joint two in the present domain, three sections of the desired trajectory are not feasible due to gravity. 
This is illustrated in Fig.~\ref{fig:control_plot_pd} with the corresponding pressure curves, which run into saturation three times.
At these points, the solver takes longer to converge, which is the reason for the decreased control frequencies in Table~\ref{tab:mpc_exp}.

\begin{figure}[t]
	\vspace{2.5mm}
	\centering{\includegraphics[width=\linewidth]{images/control_result_90deg_0g.pdf}}
	\caption{(a)--(e) Control results for a randomly selected trajectory of all $n$~joints and $\mm{\delta}{=}[\SI{0}{\gram},\SI{90}{\degree}]\transpose$ using the proposed PINN as a model within NMPC and comparison with PI control.}
	\label{fig:control_plot}
\end{figure}

\begin{figure}[t]
	\vspace{2.5mm}
	\centering{\includegraphics[width=\linewidth]{images/control_result_90deg_0g_pd.pdf}}
	\caption{Measured pressures (a)~$p_{21}$ and (b)~$p_{22}$ during the control experiment with $\mm{\delta}{=}[\SI{0}{\gram},\SI{90}{\degree}]\transpose$ for NMPC with the PINN and PI control. The NMPC enables a more dynamic response due to the model knowledge used, which results in higher pressure amplitudes.}
	\label{fig:control_plot_pd}
\end{figure}
\section{Conclusion}\label{conclusions}
Model-based estimation and control of soft robots require forward models that generalize to several system dynamics and provide a high prediction speed for real-time applications.
However, data-hungry black-box learning and slow physics-based models cannot fulfill both requirements.
In a literature overview, we analyze the current trend of hybrid model learning and identify a research gap regarding physics-informed neural networks (PINNs) for \textit{real-world, multi-DoF soft robots in small data regimes}.
The latter is crucial: Real-world data is expensive due to the recording effort or possible maintenance/damage, and it is unrealistic that all future system conditions can be considered during training-data acquisition.

We extend two existing PINN architectures with domain knowledge and perform hybrid model learning for articulated soft robots.
In two hours of experiments, the presented model was tested in various system domains that were not known during the recording of the training data.
Core results of our work (Table~\ref{tab:pred_speed} and Fig.~\ref{fig:spider_plot}) show that the PINN outperforms an elaborately identified first-principles model and a recurrent neural network \textit{when generalizability and prediction speed are considered jointly}.
As one possible real-time application, the PINN enables nonlinear model predictive control and, thus, accurate position tracking in several system domains for dynamic references.

Future work directions arise from our work.
The method is applicable to (soft) continuum robots, where dynamical models from Cosserat rod theory are accurate but require huge computational costs.
Since the domain variables only need to appear in the dynamics equation, the PINN could be trained for other variable quantities, such as external contacts.
This could, in principle, be used for contact estimation during operation.
In general, the online estimation of unmeasurable domain variables is the main task for future research.
Regarding control, GPU approaches~\cite{Hyatt.2020,Jeon.2025} could further improve the performance, and the combination with online learning could enable adaptivity.
Beyond soft robotics, our architecture can be applied to diverse dynamical systems to provide fast and generalizable surrogate models for real-time estimation and control.

%\addtolength{\textheight}{-7.3cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgment}
We thank Mehdi Belhadj for collecting the datasets.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{IEEEtran}
\bibliography{literatur}

\end{document}
