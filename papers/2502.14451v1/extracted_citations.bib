@article{Chen2021,
author = {Nanxin Chen and Shinji Watanabe and Jesus Villalba and Piotr Zelasko and Najim Dehak},
doi = {10.1109/LSP.2020.3044547},
issn = {1070-9908},
journal = {IEEE Signal Process. Lett.},
pages = {121-125},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Non-Autoregressive Transformer for Speech Recognition}},
volume = {28},
year = {2021},
}

@article{Forney1973,
author = {G.D. Forney},
doi = {10.1109/PROC.1973.9030},
issn = {0018-9219},
issue = {3},
journal = {Proc. IEEE},
pages = {268-278},
title = {The viterbi algorithm},
volume = {61},
year = {1973},
}

@article{Jo2019,
author = {Jihyuck Jo and Han-Gyu Kim and In-Cheol Park and Bang Chul Jung and Hoyoung Yoo},
doi = {10.31209/2019.100000096},
issn = {1079-8587},
issue = {2},
journal = {Intell. Autom. Soft Comput.},
pages = {351-358},
publisher = {TSI Press},
title = {{Modified Viterbi Scoring for HMM-based Speech Recognition}},
volume = {25},
year = {2019},
}

@article{Kaneko2020,
author = {Masahiro Kaneko},
doi = {10.5715/jnlp.27.683},
issn = {1340-7619},
issue = {3},
journal = {J. Nat. Lang. Process.},
pages = {683-687},
publisher = {Association for Natural Language Processing},
title = {{Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction}},
volume = {27},
year = {2020},
}

@article{Kawara2021,
author = {Yuki Kawara and Chenhui Chu and Yuki Arase},
doi = {10.1109/TASLP.2020.3042001},
issn = {2329-9290},
journal = {IEEE/ACM Trans. Audio Speech Lang. Process.},
pages = {644-655},
title = {Preordering Encoding on Transformer for Translation},
volume = {29},
year = {2021},
}

@article{Nguyen2021,
author = {Thien Nguyen and Lam Nguyen and Phuoc Tran and Huu Nguyen},
doi = {10.1155/2021/5515407},
editor = {Dr Shahzad Sarfraz},
issn = {1099-0526},
journal = {Complexity},
pages = {1-10},
publisher = {Hindawi Limited},
title = {{Improving Transformer-Based Neural Machine Translation with Prior Alignments}},
volume = {2021},
year = {2021},
}

@article{Park2019,
author = {Dongju Park and Chang Wook Ahn},
doi = {10.3390/sym11111393},
issn = {2073-8994},
issue = {11},
journal = {Symmetry},
pages = {1-1393},
publisher = {MDPI AG},
title = {{Self-Supervised Contextual Data Augmentation for Natural Language Processing}},
volume = {11},
year = {2019},
}

@article{Pattnaik2020,
author = {Sagarika Pattnaik and Ajit Kumar Nayak and Srikanta Patnaik},
doi = {10.6109/jicce.2020.18.4.207},
issn = {22348883},
issue = {4},
journal = {J. Inf. Commun. Converg. Eng.},
pages = {207-215},
publisher = {Korea Institute of Information and Communication Engineering},
title = {{A Semi-supervised Learning of HMM to Build a POS Tagger for a Low Resourced Language}},
volume = {18},
year = {2020},
}

@article{Raj2022,
author = {Pani Prithvi Raj and Pakala Akhil Reddy and Nitin Chandrachoodan},
doi = {10.1145/3510028},
issn = {1539-9087},
issue = {3},
journal = {ACM Trans. Embed. Comput. Syst.},
keywords = {On-chip memory,Viterbi decoding,binary search trees},
pages = {1-18},
publisher = {Association for Computing Machinery},
title = {{Reduced Memory Viterbi Decoding for Hardware-accelerated Speech Recognition}},
volume = {21},
year = {2022},
}

@inproceedings{Shen2020,
author = {Tianxiao Shen and Victor Quach and Regina Barzilay and Tommi Jaakkola},
city = {Stroudsburg, PA, USA},
doi = {10.18653/v1/2020.emnlp-main.420},
booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
pages = {5186-5198},
publisher = {Association for Computational Linguistics},
title = {{Blank Language Models}},
year = {2020},
}

@inproceedings{Wang2019a,
title = {{BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model}},
author = {Alex Wang and Kyunghyun Cho},
booktitle = {Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation},
year = {2019},
publisher = {Association for Computational Linguistics},
doi = {10.18653/v1/W19-2304},
pages ={30-36},
}

@article{Wang2022,
author = {Chengyu Wang and Suyang Dai and Yipeng Wang and Fei Yang and Minghui Qiu and Kehan Chen and Wei Zhou and Jun Huang},
doi = {10.1109/TASLP.2022.3153268},
issn = {2329-9290},
journal = {IEEE/ACM Trans. Audio Speech Lang. Process.},
pages = {1207-1218},
title = {{ARoBERT: An ASR Robust Pre-Trained Language Model for Spoken Language Understanding}},
volume = {30},
year = {2022},
}

@article{Wang2023,
author = {Zihao Wang and Ming Jiang and Junli Wang},
doi = {10.1109/TBDATA.2023.3316472},
issn = {2332-7790},
journal = {IEEE Trans. Big Data},
pages = {1-12},
title = {PHAED: A Speaker-aware Parallel Hierarchical Attentive Encoder-Decoder Model for Multi-turn Dialogue Generation},
year = {2023},
}

@article{Yu2021,
author = {Shi Yu and Yuxin Chen and Hussain Zaidi},
doi = {10.3389/fams.2021.604842},
issn = {2297-4687},
journal = {Front. Appl. Math. Stat.},
publisher = {Frontiers Media S.A.},
title = {{AVA: A Financial Service Chatbot Based on Deep Bidirectional Transformers}},
volume = {7},
year = {2021},
pages = {1-33}
}

@article{Zeng2021,
author = {Changchang Zeng and Shaobo Li},
doi = {10.1155/2021/5375334},
editor = {Balakrishnan Nagaraj},
issn = {1530-8677},
journal = {Wirel. Commun. Mob. Comput.},
pages = {1-17},
publisher = {Hindawi Limited},
title = {{Analyzing the Effect of Masking Length Distribution of MLM: An Evaluation Framework and Case Study on Chinese MRC Datasets}},
volume = {2021},
year = {2021},
}

@inproceedings{attention-2017,
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
booktitle = {Advances in Neural Information Processing Systems},
issn = {10495258},
pages = {1-11},
publisher = {MIT Press},
title = {{Attention is All you Need}},
year = {2017}
}

