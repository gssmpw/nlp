[
  {
    "index": 0,
    "papers": [
      {
        "key": "attention-2017",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\\L}ukasz and Polosukhin, Illia",
        "title": "{Attention is All you Need}"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "Kawara2021",
        "author": "Yuki Kawara and Chenhui Chu and Yuki Arase",
        "title": "Preordering Encoding on Transformer for Translation"
      },
      {
        "key": "Nguyen2021",
        "author": "Thien Nguyen and Lam Nguyen and Phuoc Tran and Huu Nguyen",
        "title": "{Improving Transformer-Based Neural Machine Translation with Prior Alignments}"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "Chen2021",
        "author": "Nanxin Chen and Shinji Watanabe and Jesus Villalba and Piotr Zelasko and Najim Dehak",
        "title": "{Non-Autoregressive Transformer for Speech Recognition}"
      },
      {
        "key": "Wang2022",
        "author": "Chengyu Wang and Suyang Dai and Yipeng Wang and Fei Yang and Minghui Qiu and Kehan Chen and Wei Zhou and Jun Huang",
        "title": "{ARoBERT: An ASR Robust Pre-Trained Language Model for Spoken Language Understanding}"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "Kaneko2020",
        "author": "Masahiro Kaneko",
        "title": "{Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction}"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "Park2019",
        "author": "Dongju Park and Chang Wook Ahn",
        "title": "{Self-Supervised Contextual Data Augmentation for Natural Language Processing}"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "Yu2021",
        "author": "Shi Yu and Yuxin Chen and Hussain Zaidi",
        "title": "{AVA: A Financial Service Chatbot Based on Deep Bidirectional Transformers}"
      },
      {
        "key": "Wang2023",
        "author": "Zihao Wang and Ming Jiang and Junli Wang",
        "title": "PHAED: A Speaker-aware Parallel Hierarchical Attentive Encoder-Decoder Model for Multi-turn Dialogue Generation"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "Zeng2021",
        "author": "Changchang Zeng and Shaobo Li",
        "title": "{Analyzing the Effect of Masking Length Distribution of MLM: An Evaluation Framework and Case Study on Chinese MRC Datasets}"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "Shen2020",
        "author": "Tianxiao Shen and Victor Quach and Regina Barzilay and Tommi Jaakkola",
        "title": "{Blank Language Models}"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "Wang2019a",
        "author": "Alex Wang and Kyunghyun Cho",
        "title": "{BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model}"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "Forney1973",
        "author": "G.D. Forney",
        "title": "The viterbi algorithm"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "Jo2019",
        "author": "Jihyuck Jo and Han-Gyu Kim and In-Cheol Park and Bang Chul Jung and Hoyoung Yoo",
        "title": "{Modified Viterbi Scoring for HMM-based Speech Recognition}"
      },
      {
        "key": "Raj2022",
        "author": "Pani Prithvi Raj and Pakala Akhil Reddy and Nitin Chandrachoodan",
        "title": "{Reduced Memory Viterbi Decoding for Hardware-accelerated Speech Recognition}"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "Pattnaik2020",
        "author": "Sagarika Pattnaik and Ajit Kumar Nayak and Srikanta Patnaik",
        "title": "{A Semi-supervised Learning of HMM to Build a POS Tagger for a Low Resourced Language}"
      }
    ]
  }
]