[
  {
    "index": 0,
    "papers": [
      {
        "key": "houlsby2019parameter",
        "author": "Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain",
        "title": "Parameter-efficient transfer learning for NLP"
      },
      {
        "key": "ruckle2020adapterdrop",
        "author": "R{\\\"u}ckl{\\'e}, Andreas and Geigle, Gregor and Glockner, Max and Beck, Tilman and Pfeiffer, Jonas and Reimers, Nils and Gurevych, Iryna",
        "title": "Adapterdrop: On the efficiency of adapters in transformers"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "zaken2021bitfit",
        "author": "Zaken, Elad Ben and Ravfogel, Shauli and Goldberg, Yoav",
        "title": "Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models"
      },
      {
        "key": "lawton2023neural",
        "author": "Lawton, Neal and Kumar, Anoop and Thattai, Govind and Galstyan, Aram and Steeg, Greg Ver",
        "title": "Neural architecture search for parameter-efficient fine-tuning of large pre-trained language models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "hu2021lora",
        "author": "Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu",
        "title": "Lora: Low-rank adaptation of large language models"
      },
      {
        "key": "zhang2023adalora",
        "author": "Zhang, Qingru and Chen, Minshuo and Bukharin, Alexander and Karampatziakis, Nikos and He, Pengcheng and Cheng, Yu and Chen, Weizhu and Zhao, Tuo",
        "title": "AdaLoRA: Adaptive budget allocation for parameter-efficient fine-tuning"
      },
      {
        "key": "liu2024dora",
        "author": "Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung",
        "title": "Dora: Weight-decomposed low-rank adaptation"
      },
      {
        "key": "hao2024flora",
        "author": "Hao, Yongchang and Cao, Yanshuai and Mou, Lili",
        "title": "Flora: Low-Rank Adapters Are Secretly Gradient Compressors"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chen2023parameter",
        "author": "Chen, Jiaao and Zhang, Aston and Shi, Xingjian and Li, Mu and Smola, Alex and Yang, Diyi",
        "title": "Parameter-efficient fine-tuning design spaces"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "wallace1991jpeg",
        "author": "Wallace, Gregory K",
        "title": "The JPEG still picture compression standard"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "gao2024parameter",
        "author": "Gao, Ziqi and Wang, Qichao and Chen, Aochuan and Liu, Zijing and Wu, Bingzhe and Chen, Liang and Li, Jia",
        "title": "Parameter-Efficient Fine-Tuning with Discrete Fourier Transform"
      }
    ]
  }
]