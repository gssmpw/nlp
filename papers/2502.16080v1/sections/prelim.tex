\section{Preliminaries}
\label{sec:prelim}


%\paragraph{Notation.}
\textbf{Notation.}
We use caligraphic uppercase letters to denote sets (e.g., $\calX$), bold uppercase letters to denote matrices (e.g., $\allocation$), bold lowercase letters to denote vectors (e.g., $\price$), lowercase letters to denote scalar quantities (e.g., $x$), and uppercase letters to denote random variables (e.g., $X$). 
We denote the $i$th row vector of a matrix (e.g., $\allocation$) by the corresponding bold lowercase letter with subscript $i$ (e.g., $\allocation[\buyer])$. 
Similarly, we denote the $j$th entry of a vector (e.g., $\price$ or $\allocation[\buyer]$) by the corresponding lowercase letter with subscript $j$ (e.g., $\price[\good]$ or $\allocation[\buyer][\good]$).
We denote functions by a letter determined by the value of the function, e.g., $f$ if the mapping is scalar valued, $\f$ if the mapping is vector valued, and $\calF$ if the mapping is set valued.

We denote the set $\left\{1, \hdots, n\right\}$ by $[n]$, the set $\left\{0, 1, \hdots, n\right\}$ by $[n^*]$, the set of natural numbers by $\N$, and the set of real numbers by $\R$. 
We denote the positive and strictly positive elements of a set using a $+$ or $++$ subscript, respectively, e.g., $\R_+$ and $\R_{++}$.

For any $n \in \N$, we denote the  $n$-dimensional vector of zeros and ones by $\zeros[n]$ and $\ones[n]$, respectively.
We let $\simplex[n] = \{\x \in \R_+^n \mid \sum_{i = 1}^n x_i = 1 \}$ denote the unit simplex in $\R^n$, and $\simplex(A)$ denote the set of all probability distributions over a given set $A$.
We also define the support of a probability density function $f \in \simplex(\calX)$ as $\supp(f) \doteq \left\{ \x \in \calX: f(\x) > 0 \right\}$.
%
Finally, we denote the orthogonal projection operator onto a set $C$ by $\project[C]$, i.e., $\project[C](\x) \doteq \argmin_{\y \in C} \left\|\x - \y \right\|^2$.


%For any collection of sets $\{\actionspace[\player]\}_{\player \in \players}$, we define their concatenated Carthesian product $\prod_{\player \in \players} \actionspace[\player] \doteq \{(\action[1], \hdots, \action[\numplayers]) \mid \forall \player \in \players,  \action[\player] \in \actionspace[\player]\}$, and their non-concatenated Carthesian product 
%
%For any collection of sets $\{\actionspace[\player]\}_{\player \in \players}$, we define the notation $(\action[\player], \action[-\player]) \doteq (\action[1], \hdots, \action[\numplayers]) \in \actionspace \doteq \bigtimes_{\player \in \players} \actionspace[\player]$, where $\action[-\player] \in \actionspace[-\player] \doteq \bigtimes_{\player^\prime \in \players, \player^{\prime}\neq \player} \actionspace[{\player^\prime}]$ denotes $(\action[1], \hdots, \action[\numplayers])$ with the $\player$th entry $\action[\player] \in \actionspace[\player]$ removed.


%%% AVERAGE ITERATES
%Given a tuple consisting of a sequence of iterates and weights $(\{\z^{(\iter)}\}_\iter, \{\learnrate[][\iter]\}_\iter)$, the weighted average of the iterates is given by $\mean[\z][\learnrate] \doteq \frac{\sum_{\iter} \learnrate[][\iter] \z^{(\iter)}}{\sum_{\iter} \learnrate[][\iter]}$.
%%%


%\paragraph{Mathematical Terminology.}

%%% HOMOGENEOUS
%A function $f: \R^m \to \R$ is said to be \mydef{homogeneous of degree $k \in \N_+$} if $\forall \allocation[ ] \in \R^m, \lambda > 0, f(\lambda \allocation[ ]) = \lambda^k f(\allocation[ ])$.
%Unless otherwise indicated, without loss of generality, a homogeneous function is assumed to be homogeneous of degree 1.

%%% BALL
% We write $\ball[\varepsilon][\x] = \{ \z \in \calZ \mid ||\z - \x || \leq \varepsilon \}$ to denote the closed $\varepsilon$-ball centered at $\x$, where $\calZ$ will be clear from context.

%%% INDICATOR FUNCTION
% We denote by $\setindic[\calC](\x)$ the indicator function of a set $\calC$, with value 1 if $\x \in \calC$ and $0$ otherwise.
%Given two vectors $\x, \y \in \R^n$, we write $\x \geq \y$ or $\x > \y$ to mean component-wise $\ge$ or $>$, respectively.

%%% DIAMETER
%For any set $\calC$, we denote the diameter by $\diam (\calC) \doteq \max_{\c, \c^\prime \in \calC} \|\c - \c^\prime \|$.

%%% SUBDIFFERENTIAL
We define the subdifferential of any function $\obj: \calX \times \calY \to \R$ w.r.t.\@ variable $\x$ at a point $(\a, \b) \in \calX \times \calY$ by $\subdiff[\x] f (\bm{a}, \b) \doteq \{\h \mid f(\bm{x}, \b) \geq f (\bm{a}, \b) + \h^T (\bm{x} - \bm{a}) \}$, 
and we denote the derivative operator (resp.\@ partial derivative operator w.r.t.\@ $\x$) 
%$\subgrad$ (resp.\@ $\subgrad[\x]$) 
of any function $\g: \calX \times \calY \to \calZ$ by $\subgrad \g$ (resp.\@ $\subgrad[\x] \g$).

% We define the subdifferential $\subdiff$ of a convex function $\obj$ at a point $\bm{a} \in U$ by $\subdiff[\bm{x}] f(\bm{a}) = \{\subgrad \mid f(\bm{x}) \geq f(\bm{a}) + \subgrad^T (\bm{x} - \bm{a}) \}$.
% }
%%% COMPONENT-WISE COMPARISON OPERATORS
%Given two vectors $\x, \y \in \R^n$, we write $\x \geq \y$ or $\x > \y$ to mean component-wise $\ge$ or $>$, respectively.


%\paragraph{Mathematical Terminology.}
%\textbf{Mathematical Terminology.}
\textbf{Terminology.}
Fix any norm $\| \cdot \|$. Given $\calA \subset \R^d$, the function $\obj: \calA \to \R$ is said to be $\lipschitz[\obj]$-\mydef{Lipschitz-continuous} iff $\forall \x_1, \x_2 \in \calX, \left\| \obj(\x_1) - \obj(\x_2) \right\| \leq \lipschitz[\obj] \left\| \x_1 - \x_2 \right\|$.
If the gradient of $\obj$ is $\lipschitz[\grad \obj]$-Lipschitz-continuous, $\obj$ is called $\lipschitz[\grad \obj]$-\mydef{Lipschitz-smooth}. 
% The function $\obj$ is said to be a $\lipschitz[\obj]$-contraction (resp. non-expansion) if it is Lipschitz-continuous with coefficient $\lipschitz[\obj] < 1$ (resp. $\lipschitz[\obj] = 1$). 

We require notions of stochastic convexity related to stochastic dominance of probability measures \cite{atakan2003valfunc}.
Given non-empty and convex parameter and outcome spaces $\calW$ and $\calO$ respectively, a conditional probability distribution $\w \mapsto \trans(\cdot \mid \w) \in \simplex (\calO)$ is said to be \mydef{stochastically convex} (resp.\ \mydef{stochastically concave}) in $\w \in \calW$ if for all continuous, bounded, and convex (resp.\ concave) functions $\statevalue: \calO \to \R$,  $\lambda \in (0,1)$, and $\w^\prime, \w^\dagger \in \calW$ s.t.\ $\mean[\w] = \lambda \w^\prime + (1-\lambda)  \w^\dagger$, it holds that $\Ex_{O \sim \trans(\cdot \mid \mean[\w])} \left[\statevalue(O)\right] \leq \text{ (resp.\@ $\geq$) } \lambda \Ex_{O \sim  \trans(\cdot \mid \w^\prime)} \left[\statevalue(O)\right] + (1-\lambda)\Ex_{O \sim \trans(\cdot \mid \w^\dagger)} \left[\statevalue(O)\right]$.
\deni{Define Gradient dominance?}
% \deni{Should be able to delete.}
% A probability measure $\trans( \cdot \mid \outeraction) \in \simplex(\states)$ is said to be \mydef{stochastically affine} if it is both stochastically convex and stochastically concave.
