\section{Claude and Gemini Results}
\label{appendix:F}

In addition to GPT-O1-Preview, we report the results of PiF against Claude-3.5-Sonnet~\citep{anthropic2024claude} and Gemini-1.5-Flash~\citep{team2023gemini}.
Due to resource constraints, we can only present the results of our proposed method.

\begin{table*}[h]
\setlength{\tabcolsep}{15pt} % Adjust column separation

\caption{{The attack results of the PiF method targeting large commercial models on AdvBench.}} % Change caption color to blue
\label{table:14}
\centering
  \begin{tabular}{l | c | c }
    \toprule
    \toprule
    {Metric} & {Claude-3.5-Sonnet} & {Gemini-1.5-Flash} \\
    \midrule
     {ASR ($\uparrow$)} & \cellcolor{SelfColor!15}{79.42} & \cellcolor{SelfColor!15}{80.36}\\ 
    \midrule     
     {AHS ($\uparrow$)} & \cellcolor{SelfColor!15}{1.74} &  \cellcolor{SelfColor!15}{2.45} \\
    \bottomrule
    \bottomrule
  \end{tabular}
\end{table*}

From Table~\ref{table:14}, it is evident that although Claude-3.5-Sonnet and Gemini-1.5-Flash exhibit higher safety levels compared to GPT-O1-Preview, PiF demonstrates its reliable ability to successfully jailbreak these models without conducting any hyperparameter search. 
Our approach consistently achieves a high ASR of approximately 80\% and an AHS of about 2.1. 
These results underscore the effectiveness and scalability of our method in jailbreaking diverse large commercial models.