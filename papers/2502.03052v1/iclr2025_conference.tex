\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage[hyphens]{url}   % simple URL typesetting
\usepackage{xurl}
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{float}
\usepackage{caption}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{multirow}
\usepackage{fancyhdr}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{wrapfig}
\usepackage{colortbl}
\usepackage[textsize=tiny]{todonotes}
\usepackage[most]{tcolorbox}
\usepackage{fancybox,framed}
\usepackage{threeparttable} 
\usepackage{mdframed}
\usepackage{fontawesome}
\usepackage{pgffor}

\captionsetup[figure]{labelsep = period}
\captionsetup[table]{labelsep = period}

\definecolor{SelfColor}{rgb}{0.913,0.443,0.196}
\definecolor{UrlColor}{rgb}{0.7098,0.009,0.0}
\definecolor{RefColor}{rgb}{0.082,0.376,0.510}

\usepackage[colorlinks,
            linkcolor = UrlColor,
            urlcolor  = UrlColor, 
            citecolor= RefColor,
]{hyperref}
\usepackage[capitalize,noabbrev]{cleveref}

\newcounter{chatbox}
\renewcommand{\thechatbox}{\arabic{chatbox}}
\newtcolorbox{chatbox}[2][]{
  colback=gray!15,
  colframe=black,
  fonttitle=\bfseries,
  coltitle=white,
  colbacktitle=black,
  enhanced,
  attach boxed title to top left={yshift=-2mm, xshift=2mm},
  title=#2,
  before upper={\refstepcounter{chatbox}\label{#2}\small},
  fontupper=\small
}

\title{Understanding and Enhancing the Transferability of Jailbreaking Attacks}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.


\author{Runqi Lin\\
Sydney AI Centre, The University of Sydney\\
\texttt{rlin0511@uni.sydney.edu.au}\\
\And
Bo Han\\
Hong Kong Baptist University\\
\texttt{bhanml@comp.hkbu.edu.hk}\\
\And
Fengwang Li\\
The University of Sydney\\
\texttt{fengwang.li@sydney.edu.au} \quad \quad \quad \quad \quad \quad \quad \quad \;\\
\And
Tongliang Liu\thanks{Corresponding author}\\
Sydney AI Centre, The University of Sydney\\
\texttt{tongliang.liu@sydney.edu.au}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}
\maketitle

\input{0_Abstract}
\input{1_Introduction}
\input{2_Related_Works}
\input{3_Understanding}
\input{4_Methodology}
\input{5_Experiments}
\input{6_Conclusion}

\section*{Ethics Statement}
This study exposes vulnerabilities that could be exploited to maliciously manipulate large language models.
While acknowledging these risks, we believe that openly sharing this research is beneficial for advancing progress in artificial intelligence safety.
Transparent discussions of threats are essential for ensuring that large language models operate within ethical boundaries and for developing trustworthy real-world applications.

This research not only highlights vulnerabilities but also aims to encourage developer teams to proactively enhance security mechanisms, thereby mitigating the risk of malicious exploitation.
We are confident that our study provides reliable red-teaming evaluation metrics for the future alignment of large language models with human values.
Ultimately, we hope this work will facilitate safety, responsibility, and ethics in the development of large language models.

\section*{Acknowledgments}
The authors express gratitude to Muyang Li and Suqin Yuan for their helpful feedback. 
The authors also thank the reviewers and area chair for their valuable comments.
This research was undertaken with the assistance of resources from the National Computational Infrastructure (NCI Australia), an NCRIS enabled capability supported by the Australian Government.
This work is partly supported by the OpenAI Researcher Access Program.
Bo Han was supported by RGC Young Collaborative Research Grant No. C2005-24Y, NSFC General Program No. 62376235, and Guangdong Basic and Applied Basic Research Foundation Nos. 2022A1515011652 and 2024A1515012399.
Tongliang Liu is partially supported by the following Australian Research Council projects: FT220100318, DP220102121, LP220100527, LP220200949, IC190100031.

\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\clearpage
\newpage
\appendix
\input{A_Appendix}
\input{B_Appendix}
\input{C_Appendix}
\input{D_Appendix}
\input{E_Appendix}
\input{F_Appendix}
\input{G_Appendix}
\input{H_Appendix}

\end{document}
