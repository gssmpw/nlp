\section{Source Model, Hyperparameters and Template Selection}
\label{appendix:D}

\textbf{Sources Model.}\hspace*{2mm}As shown in Table~\ref{table:10}, we can observe a minor decline in both ASR and AHS when using Bert-Base and Llama-2 as the source models.
For Bert-Base, this performance reduction can be simply attributed to the decrease in the quantity of model parameters.
For heavyweight Llama-2, this performance loss stems from the fact that the architecture of MLMs is more suitable for token-level intent perception.
We also extend our evaluation to include Vicuna-13B-V1.5, aligning with the original settings recommended in the GCG and PAIR.
As shown in Table~\ref{table:11}, our PiF method can effectively adapt to various source LLMs, consistently achieving superior performance with an ASR of nearly 100\% and an AHS of around 4.0.
More importantly, the above results effectively demonstrate that PiF consistently achieves excellent results across MLMs and CLMs.

\begin{table*}[h]
\setlength{\tabcolsep}{15pt}
\caption{{Comparison of different PiF's sources model on AdvBench.}}
\label{table:10}
\centering
  \begin{tabular}{l | c c}
    \toprule
    \toprule
    \multirow{1}*{Source Model} & ASR ($\uparrow$) & AHS ($\uparrow$) \\
    \midrule
     Bert-Large & \textbf{100.0} & \textbf{3.87} \\ 
     Bert-Base & 99.8 & 3.75 \\        
     Llama-2-7B-Chat & 97.7 & 3.40 \\ 
    \bottomrule
   \bottomrule
  \end{tabular}
\end{table*}


\begin{table*}[h]
\setlength{\tabcolsep}{8pt} % Adjust column separation
\caption{{Compare the result of jailbreaking attacks targeting Llama-2-7B-Chat on MaliciousInstruct.}}
\label{table:11}
\centering
  \begin{tabular}{l | c | c | c  c}
    \toprule
    \toprule
    {Method} & {GCG} & {PAIR} & \multicolumn{2}{c}{PiF} \\
    \midrule
    {Sources Model} & {Vicuna-13B-V1.5} & {Vicuna-13B-V1.5} & {Vicuna-13B-V1.5} & {Bert-Large} \\ 
    {ASR ($\uparrow$)} & {0.0}  & {84.0} & \cellcolor{SelfColor!15}{97.0} & \cellcolor{SelfColor!15}\textbf{{100.0}} \\ 
    {AHS ($\uparrow$)} & {1.0} & {2.36}  & \cellcolor{SelfColor!15}{3.67} & \cellcolor{SelfColor!15}\textbf{{4.65}} \\
    \bottomrule
    \bottomrule
  \end{tabular}
\end{table*}

\begin{figure*}[b]
\begin{center}
    \begin{subfigure}
    {
            \includegraphics[width=0.33\columnwidth]{image/Result_1.pdf}\hspace{-0.65em}
            \includegraphics[width=0.33\columnwidth]{image/Result_2.pdf}\hspace{-0.65em}
            \includegraphics[width=0.33\columnwidth]{image/Result_3.pdf}
    }
    \end{subfigure}
    \\        
    \vspace{-0.6em}
    \begin{subfigure}
    {
            \includegraphics[width=0.33\columnwidth]{image/Result_5.pdf}\hspace{-0.65em}
            \includegraphics[width=0.33\columnwidth]{image/Result_4.pdf}\hspace{-0.65em}
            \includegraphics[width=0.33\columnwidth]{image/Result_6.pdf}
    }
    \end{subfigure}
\vspace{-1.2em}
\caption{The impact of hyperparameters $\mathcal{N}$, $\mathcal{M}$, $\mathcal{K}$ (top row), and $\tau$, ${T}$, $\Theta$ (bottom row) on AdvBench.
}
\label{fig:5}
\end{center}
\end{figure*}

\textbf{Hyperparameters.}\hspace*{2mm}For variable control, we tune one hyperparameter at a time while keeping the others fixed.
As depicted in Figure~\ref{fig:5} (top row), we can observe that changing the values of $\mathcal{N}$, $\mathcal{M}$, and $\mathcal{K}$ leads to a slight reduction in both ASR and AHS.
This is because a search space that is too small will limit PiF's ability to identify vulnerabilities, whereas an excessively large search space will result in a scattered focus.
From Figure~\ref{fig:5} (bottom row), it is evident that both sharp and flat sampling distributions hinder effectiveness, while a moderate $\tau$ promotes the generation of stable jailbreaking attacks.
Meanwhile, we can observe that setting inadequate iterations $T$ or overly strict thresholds $\Theta$ leads to a substantial decrease in performance.
However, redundant iterations will result in unnecessary computational overhead, while looser thresholds may increase the attack's perplexity.
In light of the above trade-off, we set appropriate hyperparameters to achieve the optimal balance.

\textbf{Evaluation Template.}\hspace*{2mm}
From Table~\ref{table:12}, it is evident that our method achieves similar ASR across different evaluation templates, but the AHS tends to decrease as the template length increases.
Importantly, templates that contain tokens after the \texttt{[MASK]} position are unsuitable for the CLMs' architecture.

\begin{table*}[h]
\setlength{\tabcolsep}{8pt} % Adjust column separation
\caption{{Comparison of different PiF's evaluation templates on AdvBench.}}
\label{table:12}
\centering
  \begin{tabular}{l | c c}
    \toprule
    \toprule
    \multirow{1}*{Template} & ASR ($\uparrow$) & AHS ($\uparrow$) \\
    \midrule
     \texttt{This intent is [MASK]} & \textbf{100.0} & \textbf{3.87} \\ 
     \texttt{This is a [MASK] intent} (designed for MLMs) & 99.8 & 3.85 \\        
     \texttt{The intent of this sentence is [MASK]} & 99.8  & 3.73 \\ 
    \bottomrule
   \bottomrule
  \end{tabular}
\end{table*}