[
  {
    "index": 0,
    "papers": [
      {
        "key": "wang2018dataset",
        "author": "Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A",
        "title": "Dataset distillation"
      },
      {
        "key": "zhao2021datasetGM",
        "author": "Bo Zhao and Konda Reddy Mopuri and Hakan Bilen",
        "title": "Dataset Condensation with Gradient Matching"
      },
      {
        "key": "kimICML22",
        "author": "Kim, Jang-Hyun and Kim, Jinuk and Oh, Seong Joon and Yun, Sangdoo and Song, Hwanjun and Jeong, Joonhyun and Ha, Jung-Woo and Song, Hyun Oh",
        "title": "Dataset Condensation via Efficient Synthetic-Data Parameterization"
      },
      {
        "key": "zhao2021dataset",
        "author": "Zhao, Bo and Bilen, Hakan",
        "title": "Dataset condensation with differentiable siamese augmentation"
      },
      {
        "key": "cazenavette2022distillation",
        "author": "George Cazenavette and Tongzhou Wang and Antonio Torralba and Alexei A. Efros and Jun-Yan Zhu",
        "title": "Dataset Distillation by Matching Training Trajectories"
      },
      {
        "key": "liu2023dream",
        "author": "Liu, Yanqing and Gu, Jianyang and Wang, Kai and Zhu, Zheng and Jiang, Wei and You, Yang",
        "title": "{DREAM}: Efficient Dataset Distillation by Representative Matching"
      },
      {
        "key": "lee2022dataset",
        "author": "Lee, Hae Beom and Lee, Dong Bok and Hwang, Sung Ju",
        "title": "Dataset condensation with latent space knowledge factorization and sharing"
      },
      {
        "key": "zhao2023dataset",
        "author": "Zhao, Bo and Bilen, Hakan",
        "title": "Dataset condensation with distribution matching"
      },
      {
        "key": "wang2022cafe",
        "author": "Wang, Kai and Zhao, Bo and Peng, Xiangyu and Zhu, Zheng and Yang, Shuo and Wang, Shuo and Huang, Guan and Bilen, Hakan and Wang, Xinchao and You, Yang",
        "title": "Cafe: Learning to condense dataset by aligning features"
      },
      {
        "key": "jiang2022delving",
        "author": "Jiang, Zixuan and Gu, Jiaqi and Liu, Mingjie and Pan, David Z",
        "title": "Delving into effective gradient matching for dataset condensation"
      },
      {
        "key": "du2022minimizing",
        "author": "Du, Jiawei and Jiang, Yidi and Tan, Vincent TF and Zhou, Joey Tianyi and Li, Haizhou",
        "title": "Minimizing the accumulated trajectory error to improve dataset distillation"
      },
      {
        "key": "shin2023loss",
        "author": "Shin, Seungjae and Bae, Heesun and Shin, Donghyeok and Joo, Weonyoung and Moon, Il-Chul",
        "title": "Loss-Curvature Matching for Dataset Selection and Condensation"
      },
      {
        "key": "deng2022remember",
        "author": "Zhiwei Deng and Olga Russakovsky",
        "title": "Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks"
      },
      {
        "key": "liu2022dataset",
        "author": "Songhua Liu and Kai Wang and Xingyi Yang and Jingwen Ye and Xinchao Wang",
        "title": "Dataset Distillation via Factorization"
      },
      {
        "key": "zhao2022synthesizing",
        "author": "Bo Zhao and Hakan Bilen",
        "title": "Synthesizing Informative Training Samples with {GAN}"
      },
      {
        "key": "wang2023dim",
        "author": "Wang, Kai and Gu, Jianyang and Zhou, Daquan and Zhu, Zheng and Jiang, Wei and You, Yang",
        "title": "DiM: Distilling Dataset into Generative Model"
      },
      {
        "key": "lorraine2020optimizing",
        "author": "Lorraine, Jonathan and Vicol, Paul and Duvenaud, David",
        "title": "Optimizing millions of hyperparameters by implicit differentiation"
      },
      {
        "key": "nguyen2021dataset",
        "author": "Timothy Nguyen and Zhourong Chen and Jaehoon Lee",
        "title": "Dataset Meta-Learning from Kernel Ridge-Regression"
      },
      {
        "key": "nguyen2021datasetKIP",
        "author": "Nguyen, Timothy and Novak, Roman and Xiao, Lechao and Lee, Jaehoon",
        "title": "Dataset distillation with infinitely wide convolutional networks"
      },
      {
        "key": "vicol2022implicit",
        "author": "Vicol, Paul and Lorraine, Jonathan P and Pedregosa, Fabian and Duvenaud, David and Grosse, Roger B",
        "title": "On implicit bias in overparameterized bilevel optimization"
      },
      {
        "key": "zhou2022dataset",
        "author": "Yongchao Zhou and Ehsan Nezhadarya and Jimmy Ba",
        "title": "Dataset Distillation using Neural Feature Regression"
      },
      {
        "key": "loo2022efficient",
        "author": "Noel Loo and Ramin Hasani and Alexander Amini and Daniela Rus",
        "title": "Efficient Dataset Distillation using Random Feature Approximation"
      },
      {
        "key": "zhang2022accelerating",
        "author": "Zhang, Lei and Zhang, Jie and Lei, Bowen and Mukherjee, Subhabrata and Pan, Xiang and Zhao, Bo and Ding, Caiwen and Li, Yao and Xu, Dongkuan",
        "title": "Accelerating dataset distillation via model augmentation"
      },
      {
        "key": "cui2023scaling",
        "author": "Cui, Justin and Wang, Ruochen and Si, Si and Hsieh, Cho-Jui",
        "title": "Scaling up dataset distillation to imagenet-1k with constant memory"
      },
      {
        "key": "loo2023dataset",
        "author": "Loo, Noel and Hasani, Ramin and Lechner, Mathias and Rus, Daniela",
        "title": "Dataset Distillation with Convexified Implicit Gradients"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "yin2023squeeze",
        "author": "Yin, Zeyuan and Xing, Eric and Shen, Zhiqiang",
        "title": "Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "yin2023dataset",
        "author": "Yin, Zeyuan and Shen, Zhiqiang",
        "title": "Dataset Distillation via Curriculum Data Synthesis in Large Data Era"
      },
      {
        "key": "sun2023diversity",
        "author": "Sun, Peng and Shi, Bei and Yu, Daiwei and Lin, Tao",
        "title": "On the Diversity and Realism of Distilled Dataset: An Efficient Dataset Distillation Paradigm"
      },
      {
        "key": "dwa2024neurips",
        "author": "Du, Jiawei and Zhang, Xin and Hu, Juncheng and Huang, Wenxin and Zhou, Joey Tianyi",
        "title": "Diversity-Driven Synthesis: Enhancing Dataset Distillation through Directed Weight Adjustment"
      },
      {
        "key": "shao2023generalized",
        "author": "Shao, Shitong and Yin, Zeyuan and Zhou, Muxin and Zhang, Xindong and Shen, Zhiqiang",
        "title": "Generalized Large-Scale Data Condensation via Various Backbone and Statistical Matching"
      },
      {
        "key": "loo2024large",
        "author": "Noel Loo and Alaa Maalouf and Ramin Hasani and Mathias Lechner and Alexander Amini and Daniela Rus",
        "title": "Large Scale Dataset Distillation with Domain Shift"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "xiao2024large",
        "author": "Xiao, Lingao and He, Yang",
        "title": "Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?"
      },
      {
        "key": "zhang2024breaking",
        "author": "Zhang, Xin and Du, Jiawei and Liu, Ping and Zhou, Joey Tianyi",
        "title": "Breaking class barriers: Efficient dataset distillation via inter-class feature compensator"
      },
      {
        "key": "qin2024label",
        "author": "Qin, Tian and Deng, Zhiwei and Alvarez-Melis, David",
        "title": "A Label is Worth a Thousand Images in Dataset Distillation"
      },
      {
        "key": "kang2024label",
        "author": "Kang, Seoungyoon and Lim, Youngsun and Shim, Hyunjung",
        "title": "Label-Augmented Dataset Distillation"
      },
      {
        "key": "yu2025teddy",
        "author": "Yu, Ruonan and Liu, Songhua and Ye, Jingwen and Wang, Xinchao",
        "title": "Teddy: Efficient large-scale dataset distillation via taylor-approximated matching"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "coleman2020selection",
        "author": "Cody Coleman and Christopher Yeh and Stephen Mussmann and Baharan Mirzasoleiman and Peter Bailis and Percy Liang and Jure Leskovec and Matei Zaharia",
        "title": "Selection via Proxy: Efficient Data Selection for Deep Learning"
      },
      {
        "key": "toneva2018an",
        "author": "Mariya Toneva and Alessandro Sordoni and Remi Tachet des Combes and Adam Trischler and Yoshua Bengio and Geoffrey J. Gordon",
        "title": "An Empirical Study of Example Forgetting during Deep Neural Network Learning"
      },
      {
        "key": "pleiss2020identifying",
        "author": "Pleiss, Geoff and Zhang, Tianyi and Elenberg, Ethan and Weinberger, Kilian Q",
        "title": "Identifying mislabeled data using the area under the margin ranking"
      },
      {
        "key": "feldman2020neural",
        "author": "Feldman, Vitaly and Zhang, Chiyuan",
        "title": "What neural networks memorize and why: Discovering the long tail via influence estimation"
      },
      {
        "key": "paul2021deep",
        "author": "Paul, Mansheej and Ganguli, Surya and Dziugaite, Gintare Karolina",
        "title": "Deep learning on a data diet: Finding important examples early in training"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "xia2023moderate",
        "author": "Xiaobo Xia and Jiale Liu and Jun Yu and Xu Shen and Bo Han and Tongliang Liu",
        "title": "Moderate Coreset: A Universal Method of Data Selection for Real-world Data-efficient Deep Learning"
      },
      {
        "key": "sorscher2022beyond",
        "author": "Sorscher, Ben and Geirhos, Robert and Shekhar, Shashank and Ganguli, Surya and Morcos, Ari",
        "title": "Beyond neural scaling laws: beating power law scaling via data pruning"
      },
      {
        "key": "zheng2023coveragecentric",
        "author": "Haizhong Zheng and Rui Liu and Fan Lai and Atul Prakash",
        "title": "Coverage-centric Coreset Selection for High Pruning Rates"
      },
      {
        "key": "zhang2024spanning",
        "author": "Zhang, Xin and Du, Jiawei and Li, Yunsong and Xie, Weiying and Zhou, Joey Tianyi",
        "title": "Spanning training progress: Temporal dual-depth scoring (tdds) for enhanced dataset pruning"
      },
      {
        "key": "grosz2024data",
        "author": "Grosz, Steven and Zhao, Rui and Ranjan, Rajeev and Wang, Hongcheng and Aggarwal, Manoj and Medioni, Gerard and Jain, Anil",
        "title": "Data Pruning via Separability, Integrity, and Model Uncertainty-Aware Importance Sampling"
      },
      {
        "key": "abbas2024effective",
        "author": "Amro Kamal Mohamed Abbas and Evgenia Rusak and Kushal Tirumala and Wieland Brendel and Kamalika Chaudhuri and Ari S. Morcos",
        "title": "Effective pruning of web-scale datasets based on complexity of concept clusters"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "ben2024distilling",
        "author": "Ben-Baruch, Emanuel and Botach, Adam and Kviatkovsky, Igor and Aggarwal, Manoj and Medioni, G{\\'e}rard",
        "title": "Distilling the Knowledge in Data Pruning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "liu2023dream",
        "author": "Liu, Yanqing and Gu, Jianyang and Wang, Kai and Zhu, Zheng and Jiang, Wei and You, Yang",
        "title": "{DREAM}: Efficient Dataset Distillation by Representative Matching"
      },
      {
        "key": "xu2025distill",
        "author": "Xu, Yue and Li, Yong-Lu and Cui, Kaitong and Wang, Ziyu and Lu, Cewu and Tai, Yu-Wing and Tang, Chi-Keung",
        "title": "Distill gold from massive ores: Bi-level data pruning towards efficient dataset distillation"
      },
      {
        "key": "moser2024distill",
        "author": "Moser, Brian B and Raue, Federico and Nauen, Tobias C and Frolov, Stanislav and Dengel, Andreas",
        "title": "Distill the Best, Ignore the Rest: Improving Dataset Distillation with Loss-Value-Based Pruning"
      },
      {
        "key": "shen2024deltsimplediversitydrivenearlylate",
        "author": "Zhiqiang Shen and Ammar Sherif and Zeyuan Yin and Shitong Shao",
        "title": "DELT: A Simple Diversity-driven EarlyLate Training for Dataset Distillation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "he2024you",
        "author": "He, Yang and Xiao, Lingao and Zhou, Joey Tianyi",
        "title": "You Only Condense Once: Two Rules for Pruning Condensed Datasets"
      }
    ]
  }
]