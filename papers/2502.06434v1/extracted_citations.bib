@inproceedings{abbas2024effective,
title={Effective pruning of web-scale datasets based on complexity of concept clusters},
author={Amro Kamal Mohamed Abbas and Evgenia Rusak and Kushal Tirumala and Wieland Brendel and Kamalika Chaudhuri and Ari S. Morcos},
booktitle=ICLR,
year={2024},
}

@article{ben2024distilling,
  title={Distilling the Knowledge in Data Pruning},
  author={Ben-Baruch, Emanuel and Botach, Adam and Kviatkovsky, Igor and Aggarwal, Manoj and Medioni, G{\'e}rard},
  journal={arXiv preprint arXiv:2403.07854},
  year={2024}
}

@inproceedings{cazenavette2022distillation,
    title={Dataset Distillation by Matching Training Trajectories},
    author={George Cazenavette and Tongzhou Wang and Antonio Torralba and Alexei A. Efros and Jun-Yan Zhu},
    booktitle=CVPR,
    year={2022}
}

@inproceedings{coleman2020selection,
    title={Selection via Proxy: Efficient Data Selection for Deep Learning},
    author={Cody Coleman and Christopher Yeh and Stephen Mussmann and Baharan Mirzasoleiman and Peter Bailis and Percy Liang and Jure Leskovec and Matei Zaharia},
    booktitle=ICLR,
    year={2020}
}

@inproceedings{cui2023scaling,
  title={Scaling up dataset distillation to imagenet-1k with constant memory},
  author={Cui, Justin and Wang, Ruochen and Si, Si and Hsieh, Cho-Jui},
  booktitle=ICML,
  pages={6565--6590},
  year={2023},
  organization={PMLR}
}

@inproceedings{deng2022remember,
  title={Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks},
  author={Zhiwei Deng and Olga Russakovsky},
  booktitle=NIPS,
  year={2022}
}

@inproceedings{du2022minimizing,
  title={Minimizing the accumulated trajectory error to improve dataset distillation},
  author={Du, Jiawei and Jiang, Yidi and Tan, Vincent TF and Zhou, Joey Tianyi and Li, Haizhou},
  booktitle=CVPR,
  year={2023}
}

@inproceedings{dwa2024neurips,
    title={Diversity-Driven Synthesis: Enhancing Dataset Distillation through Directed Weight Adjustment},
    author={Du, Jiawei and Zhang, Xin and Hu, Juncheng and Huang, Wenxin and Zhou, Joey Tianyi},
    booktitle=NIPS,
    year={2024}
}

@inproceedings{feldman2020neural,
  title={What neural networks memorize and why: Discovering the long tail via influence estimation},
  author={Feldman, Vitaly and Zhang, Chiyuan},
  booktitle=NIPS,
  pages={2881--2891},
  year={2020}
}

@inproceedings{grosz2024data,
  title={Data Pruning via Separability, Integrity, and Model Uncertainty-Aware Importance Sampling},
  author={Grosz, Steven and Zhao, Rui and Ranjan, Rajeev and Wang, Hongcheng and Aggarwal, Manoj and Medioni, Gerard and Jain, Anil},
  booktitle={International Conference on Pattern Recognition},
  pages={398--413},
  year={2024},
  organization={Springer}
}

@inproceedings{he2024you,
  title={You Only Condense Once: Two Rules for Pruning Condensed Datasets},
  author={He, Yang and Xiao, Lingao and Zhou, Joey Tianyi},
  booktitle=NIPS,
  year={2024}
}

@article{jiang2022delving,
  title={Delving into effective gradient matching for dataset condensation},
  author={Jiang, Zixuan and Gu, Jiaqi and Liu, Mingjie and Pan, David Z},
  journal={arXiv preprint arXiv:2208.00311},
  year={2022}
}

@article{kang2024label,
  title={Label-Augmented Dataset Distillation},
  author={Kang, Seoungyoon and Lim, Youngsun and Shim, Hyunjung},
  journal={arXiv preprint arXiv:2409.16239},
  year={2024}
}

@inproceedings{kimICML22,
  title = {Dataset Condensation via Efficient Synthetic-Data Parameterization},
  author = {Kim, Jang-Hyun and Kim, Jinuk and Oh, Seong Joon and Yun, Sangdoo and Song, Hwanjun and Jeong, Joonhyun and Ha, Jung-Woo and Song, Hyun Oh},
  booktitle = ICML,
  year = {2022},
  url = {https://github.com/snu-mllab/Efficient-Dataset-Condensation}
}

@article{lee2022dataset,
  title={Dataset condensation with latent space knowledge factorization and sharing},
  author={Lee, Hae Beom and Lee, Dong Bok and Hwang, Sung Ju},
  journal={arXiv preprint arXiv:2208.10494},
  year={2022}
}

@inproceedings{liu2022dataset,
  title={Dataset Distillation via Factorization},
  author={Songhua Liu and Kai Wang and Xingyi Yang and Jingwen Ye and Xinchao Wang},
  booktitle=NIPS,
  year={2022},
}

@article{liu2023dream,
  title={{DREAM}: Efficient Dataset Distillation by Representative Matching},
  author={Liu, Yanqing and Gu, Jianyang and Wang, Kai and Zhu, Zheng and Jiang, Wei and You, Yang},
  journal={arXiv preprint arXiv:2302.14416},
  year={2023}
}

@inproceedings{loo2022efficient,
  title={Efficient Dataset Distillation using Random Feature Approximation},
  author={Noel Loo and Ramin Hasani and Alexander Amini and Daniela Rus},
  booktitle=NIPS,
  year={2022}
}

@inproceedings{loo2023dataset,
  title={Dataset Distillation with Convexified Implicit Gradients},
  author={Loo, Noel and Hasani, Ramin and Lechner, Mathias and Rus, Daniela},
  booktitle=ICML,
  year={2023}
}

@inproceedings{loo2024large,
title={Large Scale Dataset Distillation with Domain Shift},
author={Noel Loo and Alaa Maalouf and Ramin Hasani and Mathias Lechner and Alexander Amini and Daniela Rus},
booktitle=ICML,
year={2024},
}

@inproceedings{lorraine2020optimizing,
  title={Optimizing millions of hyperparameters by implicit differentiation},
  author={Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1540--1552},
  year={2020}
}

@article{moser2024distill,
  title={Distill the Best, Ignore the Rest: Improving Dataset Distillation with Loss-Value-Based Pruning},
  author={Moser, Brian B and Raue, Federico and Nauen, Tobias C and Frolov, Stanislav and Dengel, Andreas},
  journal={arXiv preprint arXiv:2411.12115},
  year={2024}
}

@inproceedings{nguyen2021dataset,
  title={Dataset Meta-Learning from Kernel Ridge-Regression},
  author={Timothy Nguyen and Zhourong Chen and Jaehoon Lee},
  booktitle=ICLR,
  year={2021}
}

@inproceedings{nguyen2021datasetKIP,
  title={Dataset distillation with infinitely wide convolutional networks},
  author={Nguyen, Timothy and Novak, Roman and Xiao, Lechao and Lee, Jaehoon},
  booktitle=NIPS,
  pages={5186--5198},
  year={2021}
}

@inproceedings{paul2021deep,
  title={Deep learning on a data diet: Finding important examples early in training},
  author={Paul, Mansheej and Ganguli, Surya and Dziugaite, Gintare Karolina},
  booktitle=NIPS,
  pages={20596--20607},
  year={2021}
}

@inproceedings{pleiss2020identifying,
  title={Identifying mislabeled data using the area under the margin ranking},
  author={Pleiss, Geoff and Zhang, Tianyi and Elenberg, Ethan and Weinberger, Kilian Q},
  booktitle=NIPS,
  pages={17044--17056},
  year={2020}
}

@inproceedings{qin2024label,
  title={A Label is Worth a Thousand Images in Dataset Distillation},
  author={Qin, Tian and Deng, Zhiwei and Alvarez-Melis, David},
  booktitle=NIPS,
  year={2024}
}

@inproceedings{shao2023generalized,
  title={Generalized Large-Scale Data Condensation via Various Backbone and Statistical Matching},
  author={Shao, Shitong and Yin, Zeyuan and Zhou, Muxin and Zhang, Xindong and Shen, Zhiqiang},
  booktitle=CVPR,
  year={2024}
}

@misc{shen2024deltsimplediversitydrivenearlylate,
      title={DELT: A Simple Diversity-driven EarlyLate Training for Dataset Distillation}, 
      author={Zhiqiang Shen and Ammar Sherif and Zeyuan Yin and Shitong Shao},
      year={2024},
      eprint={2411.19946},
      archivePrefix={arXiv},
}

@inproceedings{shin2023loss,
  title={Loss-Curvature Matching for Dataset Selection and Condensation},
  author={Shin, Seungjae and Bae, Heesun and Shin, Donghyeok and Joo, Weonyoung and Moon, Il-Chul},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={8606--8628},
  year={2023}
}

@inproceedings{sorscher2022beyond,
  title={Beyond neural scaling laws: beating power law scaling via data pruning},
  author={Sorscher, Ben and Geirhos, Robert and Shekhar, Shashank and Ganguli, Surya and Morcos, Ari},
  booktitle=NIPS,
  pages={19523--19536},
  year={2022}
}

@InProceedings{sun2023diversity,
  title={On the Diversity and Realism of Distilled Dataset: An Efficient Dataset Distillation Paradigm},
  author={Sun, Peng and Shi, Bei and Yu, Daiwei and Lin, Tao},
  booktitle=CVPR,
  year={2024}
}

@inproceedings{toneva2018an,
  title={An Empirical Study of Example Forgetting during Deep Neural Network Learning},
  author={Mariya Toneva and Alessandro Sordoni and Remi Tachet des Combes and Adam Trischler and Yoshua Bengio and Geoffrey J. Gordon},
  booktitle=ICLR,
  year={2019}
}

@inproceedings{vicol2022implicit,
  title={On implicit bias in overparameterized bilevel optimization},
  author={Vicol, Paul and Lorraine, Jonathan P and Pedregosa, Fabian and Duvenaud, David and Grosse, Roger B},
  booktitle=ICML,
  pages={22234--22259},
  year={2022}
}

@article{wang2018dataset,
  title={Dataset distillation},
  author={Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A},
  journal={arXiv preprint arXiv:1811.10959},
  year={2018}
}

@inproceedings{wang2022cafe,
  title={Cafe: Learning to condense dataset by aligning features},
  author={Wang, Kai and Zhao, Bo and Peng, Xiangyu and Zhu, Zheng and Yang, Shuo and Wang, Shuo and Huang, Guan and Bilen, Hakan and Wang, Xinchao and You, Yang},
  booktitle=CVPR,
  pages={12196--12205},
  year={2022}
}

@article{wang2023dim,
  title={DiM: Distilling Dataset into Generative Model},
  author={Wang, Kai and Gu, Jianyang and Zhou, Daquan and Zhu, Zheng and Jiang, Wei and You, Yang},
  journal={arXiv preprint arXiv:2303.04707},
  year={2023}
}

@inproceedings{xia2023moderate,
  title={Moderate Coreset: A Universal Method of Data Selection for Real-world Data-efficient Deep Learning},
  author={Xiaobo Xia and Jiale Liu and Jun Yu and Xu Shen and Bo Han and Tongliang Liu},
  booktitle=ICLR,
  year={2023}
}

@inproceedings{xiao2024large,
  title={Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?},
  author={Xiao, Lingao and He, Yang},
  booktitle=nips,
  year={2024}
}

@inproceedings{xu2025distill,
  title={Distill gold from massive ores: Bi-level data pruning towards efficient dataset distillation},
  author={Xu, Yue and Li, Yong-Lu and Cui, Kaitong and Wang, Ziyu and Lu, Cewu and Tai, Yu-Wing and Tang, Chi-Keung},
  booktitle=ECCV,
  pages={240--257},
  year={2025},
  organization={Springer}
}

@article{yin2023dataset,
  title={Dataset Distillation via Curriculum Data Synthesis in Large Data Era},
  author={Yin, Zeyuan and Shen, Zhiqiang},
  journal={Transactions on Machine Learning Research},
  year={2024}
}

@inproceedings{yin2023squeeze,
 title={Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective},
  author={Yin, Zeyuan and Xing, Eric and Shen, Zhiqiang},
  booktitle=NIPS,
  year={2023},
}

@inproceedings{yu2025teddy,
  title={Teddy: Efficient large-scale dataset distillation via taylor-approximated matching},
  author={Yu, Ruonan and Liu, Songhua and Ye, Jingwen and Wang, Xinchao},
  booktitle=ECCV,
  pages={1--17},
  year={2025},
  organization={Springer}
}

@inproceedings{zhang2022accelerating,
  title={Accelerating dataset distillation via model augmentation},
  author={Zhang, Lei and Zhang, Jie and Lei, Bowen and Mukherjee, Subhabrata and Pan, Xiang and Zhao, Bo and Ding, Caiwen and Li, Yao and Xu, Dongkuan},
  booktitle=CVPR,
  year={2023}
}

@article{zhang2024breaking,
  title={Breaking class barriers: Efficient dataset distillation via inter-class feature compensator},
  author={Zhang, Xin and Du, Jiawei and Liu, Ping and Zhou, Joey Tianyi},
  journal={arXiv preprint arXiv:2408.06927},
  year={2024}
}

@inproceedings{zhang2024spanning,
  title={Spanning training progress: Temporal dual-depth scoring (tdds) for enhanced dataset pruning},
  author={Zhang, Xin and Du, Jiawei and Li, Yunsong and Xie, Weiying and Zhou, Joey Tianyi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26223--26232},
  year={2024}
}

@inproceedings{zhao2021dataset,
  title={Dataset condensation with differentiable siamese augmentation},
  author={Zhao, Bo and Bilen, Hakan},
  booktitle=ICML,
  pages={12674--12685},
  year={2021}
}

@inproceedings{zhao2021datasetGM,
    title={Dataset Condensation with Gradient Matching},
    author={Bo Zhao and Konda Reddy Mopuri and Hakan Bilen},
    booktitle=ICLR,
    year={2021}
}

@inproceedings{zhao2022synthesizing,
  title={Synthesizing Informative Training Samples with {GAN}},
  author={Bo Zhao and Hakan Bilen},
  booktitle={NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research},
  year={2022}
}

@inproceedings{zhao2023dataset,
  title={Dataset condensation with distribution matching},
  author={Zhao, Bo and Bilen, Hakan},
  booktitle=WACV,
  pages={6514--6523},
  year={2023}
}

@inproceedings{zheng2023coveragecentric,
  title={Coverage-centric Coreset Selection for High Pruning Rates},
  author={Haizhong Zheng and Rui Liu and Fan Lai and Atul Prakash},
  booktitle=ICLR,
  year={2023}
}

@inproceedings{zhou2022dataset,
  title={Dataset Distillation using Neural Feature Regression},
  author={Yongchao Zhou and Ehsan Nezhadarya and Jimmy Ba},
  booktitle=NIPS,
  year={2022}
}

