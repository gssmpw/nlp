\section{Related Work}
\subsection{Pseudo-Labeling}
Pseudo-labeling is a key component in self-training for semi-supervised learning (SSL), where model predictions on unlabeled data become pseudo-labels for subsequent training~\cite{lee2013pseudo}. Although effective, it is vulnerable to error propagation, where inaccurate pseudo-labels aggravate model biases and reduce performance~\cite{zhang2020semi}. To address this, teacher-student frameworks stabilize pseudo-labeling using an exponential moving average (EMA) of the student’s weights~\cite{tarvainen2017mean}. Methods such as~\cite{yang2022st++} refine the teacher iteratively, while~\cite{shin2024revisiting} reuses earlier teacher predictions to mitigate confirmation bias.

We address these issues by introducing a dynamic thresholding mechanism that adjusts to the model’s evolving confidence during training. Unlike~\cite{yang2022st++} and~\cite{shin2024revisiting}, which use static thresholds, our adaptive threshold improves label quality by filtering low-confidence predictions as the model learns. Fixed thresholds may discard useful uncertain labels or allow noise to propagate. Additionally, our confidence decay strategy gradually reduces the effect of noisy pseudo-labels, enabling initial exploration and later focusing on reliable regions.

\subsection{Consistency Regularization}
Consistency regularization ensures predictions remain stable under input perturbations. Early methods like Temporal Ensembling~\cite{laine2017temporal} and VAT~\cite{miyato2018virtual} promote this by comparing predictions on augmented inputs. Extensions such as T-VAT~\cite{wang2022semi} use adversarial perturbations in a teacher-student setup, while~\cite{cho2024interactive} uses two student networks to refine pseudo-labels through feedback.

These methods often rely on complex augmentations or adversarial training, increasing computational cost. In contrast, we avoid explicit consistency loss. Instead, our confidence-weighting and decay, we inherently dampen the impact of unstable predictions and achieve similar robustness without adversarial training or augmentation-heavy designs.

\subsection{Boundary Refined Semantic Segmentation}
Boundary precision is a known weakness in semantic segmentation, especially under limited supervision. In weakly-supervised semantic segmentation (WSSS), boundary-aware methods such as~\cite{zheng2024intramixintraclassmixupgeneration} \cite{chen2022class} refine coarse Class Activation Maps (CAMs) using spatial priors but often miss fine boundary details due to reliance on image-level labels, limiting their use in SSSS.

In SSSS, boundary-aware methods remain underexplored. The distinction between boundary refinement in WSSS and SSSS is significant. In WSSS, boundaries are inferred from global image-level cues, whereas SSSS requires refining noisy, pixel-level pseudo-labels that already carry structural uncertainty. This makes boundary refinement in SSSS more challenging, and addressing it requires methods like ours that explicitly target spatial inconsistencies in dense predictions. ~\cite{dong2024boundary} learning class prototypes near edges by clustering features, which improves precision but introduces additional complexity and hyperparameter sensitivity.

We propose a simpler, more efficient alternative: Sobel-based boundary detection integrated into the loss function. Sobel filters \cite{jensen2020multiobject} are fast, interpretable, and differentiable enough for training compared to other edge detectors like Canny. They offer a non-learned yet effective method to identify edges, especially valuable when pseudo-label quality is still evolving. We use them to extract edge information and generate binary boundary masks, enabling a boundary-aware loss, which guides the model to focus on spatial inconsistencies, significantly improving segmentation near edges.


\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{Fig._2_Framework.png}
\caption{Overview of the CW-BASS Framework. In Stage 1, the teacher model generates pseudo-labels with confidence scores for unlabeled data. The confidence-weighted loss and dynamic thresholding filter reliable predictions to train the student model. In Stage 2, a confidence decay strategy and boundary-aware module progressively improve segmentation accuracy near object boundaries.}
\label{Fig._2_Framework.png}
\end{figure*}