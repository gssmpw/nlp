 \begin{figure*}[ht]
    \centering
    
    % Row 1
    \begin{minipage}{0.32\textwidth}
        \includegraphics[width=\linewidth]{figs/mmlu/mmlu_pro_gpt-3.5-turbo_temp0.2_feedback.pdf}
        \label{fig:feedback_turbo_mmlu}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \includegraphics[width=\linewidth]{figs/gsm_hard/gsm_hard_gpt-3.5-turbo_temp0.2_feedback.pdf}
        \label{fig:feedback_turbo_gsm_hard}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \includegraphics[width=\linewidth]{figs/humaneval/gpt-3.5-turbo_feedback_temp0.4.pdf}
       \label{fig:feedback_turbo_humaneval}
    \end{minipage}
    \vspace{-0.7cm}
    \caption{EM@k or Pass@k graphs of Single, Dual and Diverse strategies of \texttt{RandIdeaInj} versus direct sampling on the MMLU-Pro, GSM-Hard and Humaneval using \texttt{GPT-3.5-turbo}. In the Dual strategy, \texttt{GPT-4o-mini} serves as the thinker. The Diverse method utilizes a set of four models, with  \texttt{GPT-3.5-turbo}, \texttt{GPT-4o-mini}~\cite{openai2023gpt4omini}, and \texttt{Llama-3.1-8B-Instruct}~\cite{meta_llama_8b_2024} consistently included across all datasets. The fourth model varies by dataset: \texttt{Qwen2.5-7B-Instruct}~\cite{yang2024qwen2} for MMLU-Pro, \texttt{Qwen2.5-Math-7B-Instruct}~\cite{yang2024qwen2math} for GSM-Hard, and \texttt{Qwen2.5-Coder-7B-Instruct}~\cite{hui2024qwen2} for HumanEval. In each iteration, a thinker is randomly selected from the set of four models.}
    \label{fig:feedback_turbo}
\end{figure*}