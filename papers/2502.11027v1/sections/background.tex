\vspace{-0.2cm}
\section{Background}
\vspace{-0.1cm}
\label{sec:background}
\subsection{Problem Description}
\label{sec:background_problem}
We consider sets of tasks defined by a tuple $\langle \vp, \tQ, V \rangle$ of an instruction prompt $\vp$, a distribution $\tQ$ over the question set and a verifier $V$. For a solver of the task, the \textbf{prompt} $\vp$ and a \textbf{question} $\vq$ sampled from the distribution $\tQ(\cdot)$ are given, from which the solver predicts an \textbf{answer} $\vs$. This answer is finally judged by the \textbf{verifier} $V(\vs | \vp, \vq)$, which assigns $1$ to accepted answers and $0$ to rejected answers. Specifically, we inspect the following scenarios under this framework. 

\textbf{Reason \& MATH.} In reasoning tasks and math tasks, 
the prompt $\vp$ asks the solver to choose answer $\vs$ from an answer set $\mA$ for some question $\vq \sim \tQ$, and the verifier $V$ simply checks if the answer exactly matches the hidden ground truth, which we denote by $\mH$. 
% \textbf{(2)} In a math task $\vx=\langle \vp_m, \tQ_m, V_m \rangle$, the prompt $\vp_m$ asks the solver to reason and calculate for some question $\vq_m \sim \tQ_m$. Verifier $V_m$ considers a solution $s$ to be exact match if it is equal to the ground truth $\mH_m$. 
\\
\textbf{Code Generation.} In a program synthesis task, the solver is given a prompt and object pair $\langle \vp,\vo \rangle$ in natural language with $\vo \sim \tQ$, which asks the solver to write code for some object $\vo$. The goal is to complete the code implementation of $\vo$ such that it passes all hidden tests designed to evaluate its correctness, denoted by $\mH$. These hidden tests $\mH$ are not visible to the solver under any circumstances. The verifier $V$ considers a solution $s'$ to be correct if it passes all hidden tests $\mH$. 

\subsection{Best-of-N sampling}
\label{sec:background_bon}
Best-of-N, or repeated sampling, involves sampling i.i.d. responses $[\vs]_N := [\vs_1, \vs_2,..., \vs_N] \sim \text{LLM} (\cdot| \vp, \vq)$ given prompt $\vp$ and question $\vq$ from the LLM solver. 
% For all the above task sets, the solver is allowed a total of $N$ submissions $\vs_k$, where $k = 1, \cdots, N$. 
Typically, to select a single best answer $\vs^*$ from $N$ submissions, one would use a reward model to assign scores to each individual answer. 
The reward model can be a trained heuristic \citep{zhang2024generativeverifiersrewardmodeling}, self-consistency \citep{wang2023selfconsistency} or an LLM-as-a-judge \citep{zheng2023judgingllmasajudgemtbenchchatbot}. 
Since our focus is on diversity injection, we use the ground truth reward model in our experiments where possible.
% , which is the same as our verifier: assign $1$ to accepted answers and $0$ to rejected answers. 
% The best solution $\vs^*$ is then selected based on a verifier, commonly exact math the correct answer in reason and math~\cite{wang2023math}, and the number of validation tests passed in code generation~\cite{chen2024alphamath}. 
For reasoning and math tasks, A task is considered to be solved if at least one submission exactly matches the ground truth~\cite{wang2023math}; in this case the proportion of tasks that are solved by the LLM solver with $k$ submissions is called the \textbf{EM@k rate}. 
For code generation tasks, a task is solved if at least one submission passes all hidden tests (this is equivalent to selecting the answer that passes the highest number of validation tests~\cite{chen2024alphamath}); in this case the proportion of tasks that are solved with $k$ submissions is called the \textbf{Pass@k rate}~\cite{chen2021evaluating}. More details on evaluation metrics can be found in Appendix~\ref{metrics}. 
% For reasoning and math tasks, if at least one submission matches the ground truth, the task is considered solved. 
% Given a set of tasks $\tX$, the proportion of tasks that are solved is called \textbf{EM@k rate}. 
% For code generation tasks, if at least one submission passes all the hidden tests, then the task is considered to be solved. 
% Given a set of tasks, the proportion of tasks that are solved by the LLM solver with $k$ submissions is called the \textbf{pass@k rate}~\cite{chen2021evaluating}. 