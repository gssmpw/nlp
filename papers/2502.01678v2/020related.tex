

\subsection{EEG-Based Alzheimerâ€™s Disease Detection}
\label{sub:eeg_ad_detection}

In the last two decades, EEG-based Alzheimer's disease (AD) detection has followed two main research directions: manual biomarker extraction and deep learning representation. \textbf{Biomarker Extraction:} This research direction aims to identify potential biomarkers in EEG signals of AD patients and use simple classifiers, such as Multi-Layer Perceptrons (MLP) and Support Vector Machines (SVM), to differentiate these features from normal healthy subjects. Different types of EEG features are used, including statistical features like Mean, Skewness, Kurtosis, and Standard Deviation~\cite{tzimourta2019eeg, tzimourta2019analysis, kulkarni2017extracting, kanda2014clinician, waser2013eeg, tylova2013predictive, mora2019scale}, spectral features like Phase Shift, Phase Coherence, Bispectrum, and Bicoherence~\cite{wang2017enhanced, cassani2014effects, wang2015multiple, fraga2013characterizing, tait2019network, waser2016quantifying, trambaiolli2011improving}, power features like Power Spectrum Density, Relative Band Power, Ratio of EEG Rhythm, and Energy~\cite{fahimi2017index, schmidt2013index, liu2016multiple, kanda2014clinician}, as well as complexity features like Shannon Entropy, Tsallis Entropy, and Permutation Entropy~\cite{garn2015quantitative, azami2019multiscale, tylova2018unbiased, coronel2017quantitative, al2018complexity}. The main advantage of this approach is its interpretability, which is crucial for real-world healthcare applications. \textbf{Deep Learning:} Compared to manual biomarker extraction, deep learning offers an alternative approach by automatically extracting useful representations for AD detection. Models such as Convolutional Neural Networks (CNNs)~\cite{li2022predictive, cura2022deep}, Graph Neural Networks (GNNs)~\cite{shan2022spatial, klepl2023adaptive}, and Transformers~\cite{wang2024adformer} are widely used for representation learning. Some researchers still perform manual feature extraction or transform the data before applying deep learning models. For example, the method in~\cite{ieracitano2019convolutional} converts 5-second EEG intervals into Power Spectral Density (PSD) images and uses 2D convolutional layers on the images for feature extraction. DICE-net~\cite{miltiadous2023dice} extracts relative band power and spectral coherence connectivity across five frequency bands and applies convolutional layers followed by transformers. In contrast, some studies apply deep learning methods directly to EEG data. For instance, the method in~\cite{gallego2024alzheimer} uses semi-supervised spatiotemporal representation learning with deep learning models for AD detection based on different sleep-stage EEG data. STEADYNet~\cite{kachare2024steadynet} designs low-complexity convolutional models for AD and dementia detection, focusing on fast inference times. Research in ~\cite{watanabe2024deep} using MNet that applies convolutional networks for feature extraction and concatenates with relative power spectrum for AD and other dementia detection. ADformer~\cite{wang2024adformer} uses a multi-granularity spatial-temporal transformer for AD detection and widely tests on five EEG-AD datasets.





\subsection{Self-Supervised Learning in EEG}
\label{sub:self_supervised_pretrain}

There are two main strategies for self-supervised representation learning in EEG: contrastive learning and mask-reconstruction. \textbf{Contrastive Learning:} BENDR~\cite{kostas2021bendr} follows a similar contrastive learning pipeline as Wav2Vec~\cite{baevski2020wav2vec}, but it is trained on EEG data. EEG2Vec~\cite{zhu2023eeg2vec} explores both contrastive learning and mask-reconstruction for self-supervised pre-training on EEG data. BIOT~\cite{yang2024biot} designs a transformer architecture for biomedical signal embedding and applies a self-supervised contrastive framework similar to BYOL~\cite{grill2020bootstrap}. COMET~\cite{wang2024contrast} utilizes various data levels in biomedical time series to define positive and negative pairs in contrastive learning. \textbf{Mask-Reconstruction:} Neuro-BERT~\cite{wu2024neuro} employs masked autoencoding to predict missing amplitude and phase of EEG signals during pre-training. EEG2Rep~\cite{mohammadi2024eeg2rep} combines a context encoder with a momentum target encoder to reconstruct context-level representations rather than raw data in self-supervised pre-training. LaBraM~\cite{jiang2024large}, the first large foundation model in the EEG domain, uses a neural tokenizer to reconstruct the Fourier spectrum during self-supervised pre-training. EEGPT~\cite{wangeegpt} is a foundation model for EEG representation learning that integrates reconstruction loss with an alignment loss between the encoder and momentum encoder. \textbf{Other strategies:} Recently, some work has begun exploring the potential of autoregressive pretraining for EEG, such as another work also named EEGPT~\cite{yue2024eegpt}.


