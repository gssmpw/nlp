
















\begin{table*}[ht]
    \centering
    \scriptsize
    \caption{\textbf{Ablation Study of Contrastive Learning Modules.} This table presents the ablation study of each module in self-supervised contrastive learning during the pretraining stage. The \textbf{All} is the same as the LEAD-Base model.
    }
    \vspace{2mm}
    \label{tab:contrastive_modules}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{@{}ll|cc|cc|cc|cc|cc@{}}
    \toprule

    
    \multicolumn{2}{l|}{\textbf{Datasets}} & \multicolumn{2}{c|}{\makecell{\textbf{ADFTD} \\ \textit{(53,215 Samples)}  \\ \textit{(65 Subjects)} }}
     & \multicolumn{2}{c|}{\makecell{\textbf{BrainLat}  \\ \textit{(29,788 Samples)}  \\ \textit{(67 Subjects)} }} & \multicolumn{2}{c|}{\makecell{\textbf{CNBPM}  \\ \textit{(46,336 Samples)}  \\ \textit{(126 Subjects)} }} & \multicolumn{2}{c|}{\makecell{\textbf{Cognision-ERP}  \\ \textit{(61,300 Samples)}  \\ \textit{(177 Subjects)} }} & \multicolumn{2}{c}{\makecell{\textbf{Cognision-rsEEG} \\ \textit{(32,400 Samples)}  \\ \textit{(180 Subjects)} }} \\ \midrule
    
    
    \multicolumn{12}{c}{\textbf{Sample-Level Classification}}  \\
    
    \midrule
    \multicolumn{2}{l|}{\diagbox{\textbf{Modules}}{\textbf{Metrics}}} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} \\ \midrule

    \midrule


    \multicolumn{2}{l|}{\textbf{Sample-Level Contrast}}  & \textbf{78.67\std{1.47}} & \textbf{78.55\std{1.43}}   & 70.34\std{0.43} & 70.27\std{0.40}   & 93.75\std{0.29} & 92.04\std{0.38}   & 64.87\std{0.62} & 64.67\std{0.66}   & 70.28\std{0.67} & 69.65\std{0.84} \\
    \multicolumn{2}{l|}{\textbf{Subject-Level Contrast}}  & 75.60\std{2.43} & 75.55\std{2.48}   & 75.73\std{1.53} & 75.65\std{1.53}   & \textbf{96.51\std{0.21}} & \textbf{95.55\std{0.28}}   & \textbf{69.78\std{0.46}} & \textbf{69.69\std{0.46}}   & 75.74\std{0.31} & 75.53\std{0.30} \\
    \multicolumn{2}{l|}{\textbf{All}}  & 76.64\std{0.87} & 76.64\std{0.86}   & \textbf{77.89\std{1.28}} & \textbf{77.80\std{1.34}}   & 96.51\std{0.33} & 95.53\std{0.42}   & 69.58\std{0.90} & 69.53\std{0.91}   & \textbf{76.21\std{0.39}} & \textbf{76.01\std{0.39}} \\

    \midrule
    
    \multicolumn{12}{c}{\textbf{Subject-Level Classification}}  \\

    \midrule

    \multicolumn{2}{l|}{\diagbox{\textbf{Models}}{\textbf{Metrics}}} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} \\ \midrule

    
    \multicolumn{2}{l|}{\textbf{Sample-Level Contrast}}  & \textbf{81.43\std{3.50}} & \textbf{81.36\std{3.55}}   & 82.86\std{3.50} & 82.81\std{3.55}   & 96.15\std{0.00} & 96.15\std{0.00}   & 78.33\std{2.08} & 78.31\std{2.08}   & 80.54\std{2.02} & 80.03\std{2.13} \\
    \multicolumn{2}{l|}{\textbf{Subject-Level Contrast}}  & 81.43\std{3.50} & 81.36\std{3.55}   & 87.14\std{5.35} & 87.11\std{5.36}   & \textbf{100.00\std{0.00}} & \textbf{100.00\std{0.00}}   & 82.22\std{3.33} & 82.21\std{3.33}   & 90.27\std{1.32} & 90.23\std{1.34} \\
    \multicolumn{2}{l|}{\textbf{All}}  & 80.00\std{5.35} & 79.96\std{5.36}   & \textbf{90.00\std{3.50}} & \textbf{89.98\std{3.48}}   & 100.00\std{0.00} & 100.00\std{0.00}   & \textbf{84.44\std{2.22}} & \textbf{84.42\std{2.21}}   & \textbf{91.89\std{1.71}} & \textbf{91.86\std{1.73}} \\

    
    \bottomrule
    \end{tabular}
    }
\end{table*}













