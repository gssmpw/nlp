












\begin{table*}[h]
    \centering
    \scriptsize
    \caption{\textbf{Single-Dataset Finetuning or Validation.} This table presents the results of single-dataset fine-tuning or unified fine-tuning but validated on the single dataset. Two models are named with P-11-F-1-Base and P-11-F-5-V-1-Base.
    }
    \vspace{2mm}
    \label{tab:single_dataset_finetune_validate}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{@{}ll|cc|cc|cc|cc|cc@{}}
    \toprule

    
    \multicolumn{2}{l|}{\textbf{Datasets}} & \multicolumn{2}{c|}{\makecell{\textbf{ADFTD} \\ \textit{(53,215 Samples)}  \\ \textit{(65 Subjects)} }}
     & \multicolumn{2}{c|}{\makecell{\textbf{BrainLat}  \\ \textit{(29,788 Samples)}  \\ \textit{(67 Subjects)} }} & \multicolumn{2}{c|}{\makecell{\textbf{CNBPM}  \\ \textit{(46,336 Samples)}  \\ \textit{(126 Subjects)} }} & \multicolumn{2}{c|}{\makecell{\textbf{Cognision-ERP}  \\ \textit{(61,300 Samples)}  \\ \textit{(177 Subjects)} }} & \multicolumn{2}{c}{\makecell{\textbf{Cognision-rsEEG} \\ \textit{(32,400 Samples)}  \\ \textit{(180 Subjects)} }} \\ \midrule
    
    
    \multicolumn{12}{c}{\textbf{Sample-Level Classification}}  \\
    
    \midrule
    \multicolumn{2}{l|}{\diagbox{\textbf{Models}}{\textbf{Metrics}}} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} \\ \midrule

    \midrule


    \multicolumn{2}{l|}{\textbf{P-11-F-1-Base(3.41M)}}  & \textbf{77.30\std{0.93}} & \textbf{77.28\std{0.93}}   & \textbf{78.97\std{0.53}} & \textbf{78.92\std{0.56}}   & \textbf{96.78\std{0.34}} & \textbf{95.93\std{0.44}}   & 60.72\std{0.61} & 60.59\std{0.62}   & 64.13\std{0.68} & 64.06\std{0.66} \\
    \multicolumn{2}{l|}{\textbf{P-11-F-5-V-1-Base(3.41M)}}  & 76.55\std{0.63} & 76.54\std{0.63}   & 78.45\std{0.85} & 78.39\std{0.89}   & 96.68\std{0.34} & 95.74\std{0.45}   & \textbf{70.13\std{0.55}} & \textbf{70.08\std{0.56}}   & 75.95\std{0.26} & 75.76\std{0.28} \\
    \midrule
    \multicolumn{2}{l|}{\textbf{LEAD-Base(3.41M)}}  & 76.64\std{0.87} & 76.64\std{0.86}   & 77.89\std{1.28} & 77.80\std{1.34}   & 96.51\std{0.33} & 95.53\std{0.42}   & 69.58\std{0.90} & 69.53\std{0.91}   & \textbf{76.21\std{0.39}} & \textbf{76.01\std{0.39}} \\

    \midrule
    
    \multicolumn{12}{c}{\textbf{Subject-Level Classification}}  \\

    \midrule

    \multicolumn{2}{l|}{\diagbox{\textbf{Models}}{\textbf{Metrics}}} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} & \textbf{Accuracy} & \textbf{F1 Score} \\ \midrule



    \multicolumn{2}{l|}{\textbf{P-11-F-1-Base(3.41M)}}  & 77.14\std{2.86} & 77.05\std{2.81}   & 90.00\std{3.50} & 89.98\std{3.48}   & 97.69\std{1.88} & 97.69\std{1.89}   & 65.56\std{3.33} & 65.47\std{3.32}   & 72.43\std{3.97} & 72.40\std{4.01} \\
    \multicolumn{2}{l|}{\textbf{P-11-F-5-V-1-Base(3.41M)}}  & 78.57\std{4.52} & 78.51\std{4.52}   & 87.14\std{2.86} & 87.14\std{2.84}   & 100.00\std{0.00} & 100.00\std{0.00}   & \textbf{85.00\std{2.22}} & \textbf{84.97\std{2.22}}   & 91.89\std{1.71} & 91.86\std{1.73} \\
    \midrule
    \multicolumn{2}{l|}{\textbf{LEAD-Base(3.41M)}}  & \textbf{80.00\std{5.35}} & \textbf{79.96\std{5.36}}   & \textbf{90.00\std{3.50}} & \textbf{89.98\std{3.48}}   & \textbf{100.00\std{0.00}} & \textbf{100.00\std{0.00}}   & 84.44\std{2.22} & 84.42\std{2.21}   & \textbf{91.89\std{1.71}} & \textbf{91.86\std{1.73}} \\

    
    \bottomrule
    \end{tabular}
    }
\end{table*}













