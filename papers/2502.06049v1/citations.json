[
  {
    "index": 0,
    "papers": [
      {
        "key": "DBLP:journals/corr/abs-2004-05150",
        "author": "Iz Beltagy and\nMatthew E. Peters and\nArman Cohan",
        "title": "Longformer: The Long-Document Transformer"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "DBLP:journals/corr/abs-2007-14062",
        "author": "Manzil Zaheer and\nGuru Guruganesh and\nAvinava Dubey and\nJoshua Ainslie and\nChris Alberti and\nSantiago Onta{\\~{n}}{\\'{o}}n and\nPhilip Pham and\nAnirudh Ravula and\nQifan Wang and\nLi Yang and\nAmr Ahmed",
        "title": "Big Bird: Transformers for Longer Sequences"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "DBLP:journals/corr/abs-2006-03274",
        "author": "Ankit Gupta and\nJonathan Berant",
        "title": "{GMAT:} Global Memory Augmentation for Transformers"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "DBLP:journals/corr/abs-2004-08483",
        "author": "Joshua Ainslie and\nSantiago Onta{\\~{n}}{\\'{o}}n and\nChris Alberti and\nPhilip Pham and\nAnirudh Ravula and\nSumit Sanghai",
        "title": "{ETC:} Encoding Long and Structured Data in Transformers"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "DBLP:journals/corr/abs-1901-02860",
        "author": "Zihang Dai and\nZhilin Yang and\nYiming Yang and\nJaime G. Carbonell and\nQuoc V. Le and\nRuslan Salakhutdinov",
        "title": "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bulatov2022recurrentmemorytransformer",
        "author": "Aydar Bulatov and Yuri Kuratov and Mikhail S. Burtsev",
        "title": "Recurrent Memory Transformer"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "rodkin2024associativerecurrentmemorytransformer",
        "author": "Ivan Rodkin and Yuri Kuratov and Aydar Bulatov and Mikhail Burtsev",
        "title": "Associative Recurrent Memory Transformer"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "ko2024memreasoner",
        "author": "Ko, Ching-Yun and Dai, Sihui and Das, Payel and Kollias, Georgios and Chaudhury, Subhajit and Lozano, Aurelie",
        "title": "MemReasoner: A Memory-augmented LLM Architecture for Multi-hop Reasoning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "kuratov2024babilong",
        "author": "Yuri Kuratov and Aydar Bulatov and Petr Anokhin and Ivan Rodkin and Dmitry Sorokin and Artyom Sorokin and Mikhail Burtsev",
        "title": "BABILong: Testing the Limits of LLMs with Long Context Reasoning-in-a-Haystack"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "ko2024memreasoner",
        "author": "Ko, Ching-Yun and Dai, Sihui and Das, Payel and Kollias, Georgios and Chaudhury, Subhajit and Lozano, Aurelie",
        "title": "MemReasoner: A Memory-augmented LLM Architecture for Multi-hop Reasoning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "DBLP:journals/corr/abs-2005-11401",
        "author": "Patrick S. H. Lewis and\nEthan Perez and\nAleksandra Piktus and\nFabio Petroni and\nVladimir Karpukhin and\nNaman Goyal and\nHeinrich K{\\\"{u}}ttler and\nMike Lewis and\nWen{-}tau Yih and\nTim Rockt{\\\"{a}}schel and\nSebastian Riedel and\nDouwe Kiela",
        "title": "Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "mavi2024multihopquestionanswering",
        "author": "Vaibhav Mavi and Anubhav Jangra and Adam Jatowt",
        "title": "Multi-hop Question Answering"
      }
    ]
  }
]