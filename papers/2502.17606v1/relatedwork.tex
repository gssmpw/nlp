\section{Related Work}
\vspace{0.3em}
\noindent\textbf{Workload Characterizing and Modeling.}
Early studies \cite{cao2020characterizing, dong2017optimizing, ycsb} explored workload patterns and focused on providing insights into performance and operational challenges in a corporate setting while also releasing modeled workloads (MixGraph \cite{cao2020characterizing} and YCSB \cite{ycsb}), for the research community to use and learn. However, these workload characterization and modeling studies have relied solely on manual approaches performed by human experts.  
% Benchmark tools such as the Yahoo! Cloud Serving Benchmark (YCSB) \cite{ycsb} further standardized the evaluation process, though their reliance on synthetic workloads limits real-world applicability.
More recently, automated techniques for workload modeling have emerged, leveraging machine learning to generalize across systems. While such methods have shown promise in domains like networking \cite{gan_modeling_network}, they have not been applied to LSM-KVS. 

\vspace{0.3em}
\noindent\textbf{LSM-KVS Tuning and Optimization.}
Several studies have focused on tuning and optimizing LSM-KVS to balance performance and resource utilization. While shown to be effective, existing approaches like ADOC \cite{yu2023adoc}, RTune \cite{RTune}, K2vtune \cite{lee2024k2vtune}, Dremel \cite{Dremel}, CAMAL \cite{yu2024camal}, all focus on a subset of options and workloads using ML-based or heuristic approaches. For instance, ADOC focuses on modifying only two configuration options: the block size and the available resources for background processes. While this method effectively improves performance, it does not assist beyond certain workloads (e.g., write-heavy). In contrast, ELMo-Tune-V2 produces a design that leverages LLM to surpass the subset paradigm set by the current work. Further, our design encompasses an end-to-end solution that includes workload characterization and modeling, along with real-time tuning capabilities not showcased in any current design. 

\vspace{0.3em}
\noindent\textbf{LLM for LSM-KVS Tuning.}
Emerging studies \cite{Thakkar2024can, giannankouris2024lambda, giannakouris2024demonstrating} have explored using LLM for LSM-KVS tuning. For instance, Elmo-Tune \cite{Thakkar2024can} leverages LLMs to generate tuning recommendations by synthesizing knowledge of preset workload patterns, enabling an iterative tuning loop. Meanwhile, $\lambda$-tune \cite{giannankouris2024lambda, giannakouris2024demonstrating} focuses on OLAP applications (e.g., Postgres) to optimize their configurations. Similar goals inspire our approach but differ in two key areas. Unlike both solutions, which rely on pre-trained LLMs for configuration synthesis, our methodology performs characterization and modeling of benchmarks to formulate an end-to-end solution. We diverge from the existing solutions by incorporating real-time tuning, a feature not considered by ELMo-Tune, and focusing on LSM-KVS, which faces very different workloads and more dynamic setups than OLAP applications that $\lambda$-Tune focuses upon.