\section{Introduction}
A Monolithic Architecture refers to software architectures where all of the applicationâ€™s components are deployed as a single unit \cite{newman2019monolith}. As the scale of the monolithic applications gets larger, maintaining such software becomes extremely complex while scaling and organizational issues start emerging \cite{soundcloud2024}. Due to a multitude of factors such as its modularity and its compatibility with Cloud technologies, the Microservices architectural style has proven to be effective in meeting the needs of applications deployed at large scales \cite{spotify2022,netflix2015,soundcloud2024,vayghan2019availability,vayghan2021stateful,almarimi2019apirec}. However, migrating from an established monolithic system to a more modern and more complex microservices architecture has been shown to be an extremely expensive and difficult process \cite{rosati2019migrationcost,fritzsch_2019_migrationindustry,kalske2018m2mchallenges,francesco_2018_idustrialsurvey,vayghan2018experience}. In-depth analysis of the migration pipeline \cite{faustino2022stepwise,mazzara2021casestudy} has identified the decomposition step, which consists of partitioning the monolith's component into target microservices, as the largest and most important roadblock when refactoring a monolith into microservices. 

There has been an increasing interest \cite{Abgaz2023decompsurvey,oumoussa2024decompsurvey} in automating the decomposition process to reduce its constraints and to democratize it. Decomposition approaches range from semi-automated methods \cite{gysel2016servicecutter,li2019dataflowdec} which aim to guide the developers through the process to mostly automated approaches \cite{mathai2022chgnn,jin2021fosci,kalia2021mono2micro,khaled2022hydecomp,yedida2023deeply,aldebagy2021code2vec} that generate decompositions using input representations of the monolith such as its source code or its design artifacts. 

In fact, one of the most common approaches to analyzing the monolithic applications for the task of decomposing them to microservices is the static analysis of the source code \cite{Abgaz2023decompsurvey}. However, this analysis method has often under-performed when compared with dynamic analysis for example \cite{desai2021cogcn,kalia2021mono2micro}. On the other hand, these alternative representations of the monolith often come with their own disadvantages such as low coverage in the case of dynamic analysis. While there has been some effort into combining multiple representations \cite{mathai2022chgnn,khaled2022hydecomp,qian2023gdcdvf}, most analysis techniques in microservices decomposition research has relied mainly on traditional methods (e.g. static and dynamic analysis) and explicitly defined features (e.g. cohesion, coupling). On the other hand, recent software engineering research has showcased the potential of using Large Language Models (LLMs) \cite{niu2023codeembedreview} and Representation Learning techniques \cite{guo2022unixcoder,wang2023codet5p} to enhance the performance of downstream tasks \cite{Torregrossa2023embeddingssurvey} like code summarization and code search \cite{junkai2024codesearch} through rich, high-dimensional representation vectors of source code. 



In this research, we present MonoEmbed, a Language Model based approach for decomposing monolithic applications into microservices. MonoEmbed consists of a pipeline with two main components: Analysis and Inference. The Analysis component contains the Language Model and is responsible for transforming the monolith's elements, in the form of source code fragments, into efficient embedding vectors that were optimized for the decomposition problem. We reviewed a large and diverse number of Pre-Trained Language Models (e.g. Encoders \cite{guo2021graphcodebert} , LLMs\cite{aimeta2024llama3modelcard}) and improved their performance through a Contrastive Learning based fine-tune process (i.e. by maximizing the distance between classes of different microservices while reducing the differences between classes that should be in the same microservice). By imporving the quality of these embedding vectors, we enable better microservices suggestions in the Inference component which utilizes clustering algorithms to partition the classes.

Using a large set of existing microservices applications, we train the Language Models and evaluate the quality of the embeddings they generate based on their similarity with the true partitions. We compare the performance of a large number of clustering algorithms with different models. We evaluate the performance of MonoEmbed in comparison with decomposition benchmark approaches on 8 monolithic applications. Results showcase that our approach is able to generate more cohesive and consistent decompositions. 

The main contributions of this research are:
\begin{itemize}
    \item We propose a Language Models based decomposition approach and show that it generates more consistent and cohesive results on applications with varying scales. 
    \item We evaluate 18 Pre-Trained Language Models and 4 benchmark representations to review the quality of their embedding vectors in the decomposition space.
    \item We introduce and evaluate potential fine-tuning methods and datasets for decompositions. Our Fine-Tuned LLMs outperform current models, producing robust embeddings that effectively distinguish microservice boundaries.
\end{itemize}