\subsection{RQ4: Comparison with the Decomposition Benchmarks}\label{subsec:benchmarks}
\subsubsection{Experimental Setup}
In this RQ, we evaluate the performance of our approach on monolithic applications and compare it with benchmark decomposition methods. We select 8 monolithic applications with varying numbers of classes and that have been used in decomposition problems \cite{khaled2022msextractor,kalia2021mono2micro,jin2021fosci}. We apply our approach and 6 additional benchmarks on these applications and measure 7 evaluation metrics that represent different qualities in the generated microservices. The Table \ref{tab:monoapps} shows the details of the monolithic applications

The benchmark decomposition approaches that we compare with are: \textit{Code2VecDec} \cite{aldebagy2021code2vec}, \textit{CHGNN} \cite{mathai2022chgnn}, \textit{Deeply} \cite{yedida2023deeply}, \textit{Mono2Micro} \cite{kalia2021mono2micro}, \textit{MSExtractor} \cite{khaled2022msextractor} and \textit{TopicDec} \cite{brito2021topicmodeling}. Since some of the approaches, such as \textit{TopicDec} and \textit{Mono2Micro}, generate multiple decompositions or do not have predefined hyper-parameters, We generate multiple results for the rest of the approaches by varying their potential hyper-parameters. \textit{Deeply} and \textit{Code2VecDec} are the exceptions since the former always generates a single decomposition while the latterâ€™s authors specified the recommended hyper-parameters.  We apply these approaches on all of the applications except for \textit{CHGNN} due to its requirement of manually defined input seeds. As such, we evaluate \textit{CHGNN} only on Plants \cite{monoapps2024plants}, AcmeAir \cite{monoapps2024acmeair} and DayTrader \cite{monoapps2024daytrader} for which the authors provide input data. As for \textit{MonoEmbed}, we used \textit{ME-llm2vec-340K} due to its performance in Table \ref{tab:ftscores_samples} and Affinity Propagation based on our observation in section \ref{subsec:rq3clustering}.

\begin{table}[h]
\caption{Monolithic application data.}\label{tab:monoapps}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}lllll@{}}
\toprule
Application   & \# of classes & \# of methods & \# of semantic terms & \# of unique calls \\ \midrule
Plants \cite{monoapps2024plants}    & 40            & 1109          & 607                  & 123                \\
 JPetStore \cite{monoapps2024jpetstore} & 43& 876& 231&96\\
PetClinic \cite{monoapps2024petcliniclegacy} & 60            & 987           & 475                  & 106                \\
ACMEair \cite{monoapps2024acmeair}   & 86            & 1629          & 553                  & 123                \\
 PartsMRP \cite{monoapps2024partsunlimited} & 100& 1951& 423&234\\
DayTrader \cite{monoapps2024daytrader} & 118           & 2577          & 607                  & 282                \\
 7ep-demo \cite{monoapps20247epdemo} & 119& 2702& 1048&204\\
 Roller \cite{monoapps2024roller}   & 531           & 15426         & 2632                 & 2195               \\  \bottomrule
\end{tabular}
}
\end{table}


\subsubsection{Evaluation Metrics}
The evaluation in this RQ is based on monolithic applications for which a true and correct decomposition rarely exists. As such, we utilized 6 metrics from related works and an aggregate score that measure certain qualities in the decomposition. CoHesion at the Message level (CHM)\cite{jin2021fosci,athanasopoulos2015cohesion} is commonly used to measure the structural cohesiveness of the components in the microservices. The assumption in this case is that the better the structural similarity is the better the decomposition is. CoHesion at the Domain level (CHD)\cite{jin2021fosci,athanasopoulos2015cohesion} is similar to CHM but focuses on the domain instead. Business Case Purity (BCP)\cite{kalia2021mono2micro} quantifies the cohesion from a business usecase standpoint. Inter-Call Percentage (ICP)\cite{kalia2021mono2micro} is a measurement of the coupling between the microservices. Non-Extreme Distribution (NED)\cite{desai2021cogcn} reflects the size of the microservices penalizing extremely small or large microservices. Coverage (COV) is the percentage of classes that were included in the decomposition. 



We define an aggregate score (SCORE) combining all metrics, inspired by \textit{CHGNN}'s evaluation \cite{mathai2022chgnn}. This approach addresses two challenges: Metric scales vary by application (e.g., median BCP for JPetStore is 2.6, while for PetClinic it's 0.8) and and vary between each other. For a fair comparison:
\begin{enumerate}

\item We standardize evaluation metrics for each application.
\item We combine scaled metrics using a weighted sum:
\begin{itemize}

\item CHM and CHD (to be maximized): weight = 2
\item BCP and ICP (to be minimized): weight = -2
\item NED and COV (secondary qualities): weights = -1 and 1 respectively
\end{itemize}
\end{enumerate}



A higher SCORE indicates a more balanced decomposition. In addition, this scaling allows aggregation across applications.



\begin{table}[h]



    \centering
    \caption{Scaled evaluation metrics for each decomposition approach. }
    \label{tab:monoscores}
    \resizebox{\linewidth}{!}{%

\begin{tabular}{l|lllllll}
\toprule
   Approach &     CHM$\nearrow$ &     CHD$\nearrow$ &      BCP$\searrow$ &      ICP$\searrow$ &      NED$\searrow$ &     COV$\nearrow$ &   SCORE$\nearrow$ \\
\midrule
  MonoEmbed &    \textbf{1.168} &    \textbf{1.375} &             -0.527 &              0.323 &              0.252 &    \textbf{0.818} &    \textbf{6.061} \\
 Mono2Micro & \underline{0.174} &    \uuline{0.317} &    \textbf{-1.210} & \underline{-0.719} &              0.231 &            -1.124 &    \uuline{3.485} \\
Code2VecDec &    \uuline{0.461} & \underline{0.187} &    \uuline{-0.665} &              1.144 & \underline{-0.091} & \underline{0.678} & \underline{1.107} \\
MSExtractor &             0.068 &             0.022 &              0.227 &              0.543 &              0.215 &    \textbf{0.818} &            -0.757 \\
     Deeply &            -0.782 &            -0.852 & \underline{-0.643} &    \textbf{-1.500} &              0.599 &            -1.219 &            -0.801 \\
   TopicDec &            -0.538 &            -0.368 &             -0.061 &    \uuline{-0.776} &    \uuline{-0.339} &            -1.170 &            -0.969 \\
      CHGNN &             0.014 &            -0.351 &              0.495 &             -0.375 &    \textbf{-0.613} &            -0.739 &            -1.040 \\
\bottomrule
\end{tabular}

    

    



}
\end{table}


\subsubsection{Results}


Table \ref{tab:monoscores} shows the mean scaled metric values across evaluation applications for each decomposition approach while Table \ref{tab:appscores} presents the SCORE values for each benchmark and  application. The best 3 values in each metric are in bold, double underline and simple underline. 

In Table \ref{tab:monoscores}, our approach, \textit{MonoEmbed}, achieved the best SCORE, followed by \textit{Mono2Micro} and \textit{Code2VecDec}. In fact, \textit{MonoEmbed} scored highest in CHM, CHD, and COV, with a BCP value close to the second and third models, demonstrating its ability to group cohesive classes across multiple aspects. It even surpassed \textit{CHGNN}, a dynamic analysis approach, and nearly matched \textit{Deeply}'s BCP score, a metric it optimizes. However, \textit{MonoEmbed}'s higher-than-average ICP score suggests increased inter-microservice coupling. 


As shown in Table \ref{tab:appscores}, \textit{MonoEmbed} achieved the highest scores for Plants, AcmeAir, PartUnlimited, and Roller, and second-highest for DayTrader and 7EP-Demo but had worse scores on smaller applications. While \textit{MSExtractor} and \textit{Code2VecDec} excelled with smaller applications, they struggled with the rest, suggesting that simpler methods or method-level granularities may suit smaller applications, which have more focused relationships and bounded contexts. \textit{MonoEmbed} on the other hand demonstrated more consistent performance, especially for larger applications. 

Both \textit{Code2VecDec} and \textit{MonoEmbed} use embedding models and clustering. While \textit{Code2VecDec} performed well on PetClinic, its results were inconsistent and generally lower than \textit{MonoEmbed}'s, highlighting the advantage of fine-tuned contextual EMs. However, \textit{Code2VecDec}'s performance suggests some potential in method-level embeddings. Unlike other benchmarks, \textit{MonoEmbed} does not use predefined representations. \textit{CHGNN}, \textit{Deeply}, and \textit{Mono2Micro} rely on runtime interactions, while \textit{MSExtractor} and \textit{TopicDec} use structural and semantic similarities. These approaches may excel in metrics reflecting similar qualities to their inputs. For instance, \textit{Mono2Micro} achieved low BCP and ICP scores but sacrificed coverage and microservice balance. On the other hand, \textit{MonoEmbed}'s model was trained on numerous microservices applications and learns class groupings based on real-world developer practices. This approach likely contributes to its consistent performance across metrics and applications. While all approaches use source code at some level, \textit{MonoEmbed} does not require in-depth analysis or additional input, potentially explaining further its consistency across applications.

\begin{figure*}[]
\centering
\includegraphics[width=0.9\linewidth]{img/05/fig_case_study.pdf}
\caption{A UMAP 2-dimensional projection of VoyageAI, MonoEmbed-unixcoder and MonoEmbed-llm2vec embeddings.} \label{fig:casestudy}
\end{figure*}

\begin{tcolorbox}[colback=gray!10!white, colframe=gray!90!black]
\textbf{Summary:} \textit{MonoEmbed} is able to consistently generate highly cohesive decompositions on different applications and scales while maintaining full coverage, albeit with higher microservice coupling.
\end{tcolorbox}











\begin{table}[]



    \centering
    \caption{Aggregate scores on each monolithic application.}
    \label{tab:appscores}
    \resizebox{\linewidth}{!}{%
    

    \begin{tabular}{l|lllllll}
\toprule
   Application &       MonoEmbed &         Mono2Micro &        Code2VecDec &        MSExtractor &          Deeply &       TopicDec &  CHGNN \\
\midrule
        Plants &  \textbf{5.986} &             -0.998 &  \underline{0.740} &     \uuline{2.238} &         -10.799 &         -2.791 & -2.359 \\
     JPetStore &          -5.177 &     \uuline{1.668} & \underline{-2.369} &     \textbf{2.339} &          -5.069 &         -3.609 &      - \\
     PetClinic &          -2.069 &             -3.099 &     \textbf{1.209} &  \underline{0.534} &         -10.010 & \uuline{0.892} &      - \\
       AcmeAir &  \textbf{8.521} &     \uuline{4.187} &  \underline{1.999} &             -2.192 &          -1.113 &          0.277 &  0.576 \\
PartsUnlimited & \textbf{14.530} & \underline{-0.661} &             -2.443 &             -1.901 &          -2.789 & \uuline{0.160} &      - \\
     DayTrader & \uuline{11.170} &  \underline{8.606} &              4.382 &             -1.582 & \textbf{20.272} &         -5.415 & -1.336 \\
      7EP-Demo &  \uuline{1.395} &     \textbf{6.038} &             -7.743 & \underline{-0.447} &          -0.659 &         -1.138 &      - \\
        Roller & \textbf{14.129} &  \underline{5.433} &    \uuline{13.082} &             -5.042 &           3.759 &          3.870 &      - \\
\midrule
          Mean &  \textbf{6.061} &     \uuline{3.485} &  \underline{1.107} &             -0.757 &          -0.801 &         -0.969 & -1.040 \\
\bottomrule
\end{tabular}



    
    



}
\end{table}