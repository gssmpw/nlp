%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{graphicx} % for including graphics
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{booktabs}
\usepackage{bm}

\title{\LARGE \bf
HiFAR: Multi-Stage Curriculum Learning for \underline{Hi}gh-Dynamics Humanoid \underline{Fa}ll \underline{R}ecovery
}
\author{Penghui Chen$^{1}$, Yushi Wang$^{1}$, Changsheng Luo$^{1}$, Wenhan Cai$^{2}$, and Mingguo Zhao$^{1}$% <-this % stops a space
\thanks{*This research was supported by STI 2030—Major Projects grant number 2021ZD0201402 and Beijing Natural Science Foundation(L243004).}% <-this % stops a space
\thanks{$^{1}$Department of Automation, Tsinghua University, Beijing 100084, China
 }%
\thanks{$^{2}$Booster Robotics Technology Co., Ltd, Beijing, China}
        % {\tt\small b.d.researcher@ieee.org}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Humanoid robots encounter considerable difficulties in autonomously recovering from falls, especially within dynamic and unstructured environments. Conventional control methodologies are often inadequate in addressing the complexities associated with high-dimensional dynamics and the contact-rich nature of fall recovery. Meanwhile, reinforcement learning techniques are hindered by issues related to sparse rewards, intricate collision scenarios, and discrepancies between simulation and real-world applications. In this study, we introduce a multi-stage curriculum learning framework, termed HiFAR. This framework employs a staged learning approach that progressively incorporates increasingly complex and high-dimensional recovery tasks, thereby facilitating the robot's acquisition of efficient and stable fall recovery strategies. Furthermore, it enables the robot to adapt its policy to effectively manage real-world fall incidents. We assess the efficacy of the proposed method using a real humanoid robot, showcasing its capability to autonomously recover from a diverse range of falls with high success rates, rapid recovery times, robustness, and generalization. 

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction} 

As robots become increasingly integrated into human-centric spaces, ensuring their resilience and adaptability is essential. Given that falls are inevitable in dynamic environments, the autonomous fall recovery capability of humanoid robots is crucial for real-world deployment.

The need for rapid fall recovery in humanoid robots is driven by the dynamic and unpredictable nature of real-world environments. Quick recovery from falls minimizes downtime and potential damage, enhancing the robot's operational efficiency and safety. For instance, in competitive environments like RoboCup \cite{robocup}, quick and efficient fall recovery is crucial to maintain performance. 

Early solutions for fall recovery relied on finite state machines (FSMs) to trigger preprogrammed actions upon detecting fall indicators \cite{kanehiro2003first}, \cite{stuckler2006getting}. While computationally lightweight—enabling real-time execution on early humanoids like Honda's ASIMO \cite{sakagami2002intelligent}, their brittleness became evident in unstructured environments. 

The need for real-time adaptation in dynamic environments spurred the adoption of optimization-based methods, particularly for maintaining bipedal stability under external perturbations. A seminal advancement in this domain is the Capture Point theory \cite{pratt2006capture}, which formulates push recovery as a problem of regulating the robot’s zero-moment point (ZMP) within its support polygon. By solving convex optimization problems, methods like Model Predictive Control (MPC) \cite{katayama2023model} enabled humanoids to recover balance through step adjustment and torso reorientation. In the context of robot fall recovery, optimization-based methods, such as Whole-Body Control (WBC) \cite{moro2019whole}, have proven effective in online optimization of the robot’s fall trajectory \cite{cai2023self}. However, unmodeled actuator dynamics lead to trajectory tracking errors, and computational latency becomes intractable for multi-contact scenarios.

Model-based control approaches, while effective for stable locomotion, struggle to address the high-dimensional dynamics and contact-rich nature of fall recovery due to their reliance on precise system modeling and computational latency. Reinforcement learning (RL) has been proven effective in humanoid locomotion \cite{kumar2022adapting} and emerges as a solution for fall recovery by enabling robots to learn recovery policies through environment interaction rather than explicit physics modeling. Recent advances in RL have shown success in developing long-horizon behaviors \cite{haarnoja2024learning}, whole-body control \cite{cheng2024expressive}, and contact-rich tasks \cite{zhang2024whole}, \cite{dao2024sim}, making it a promising approach for fall recovery.

Various approaches have been proposed to solve fall recovery with reinforcement learning, including predefined trajectories \cite{haarnoja2024learning}, \cite{zhuang2025embrace}, symmetric behaviors \cite{gaspard2024frasa}, key state initialization(KSI) \cite{yang2023learning}, and task stage division \cite{huang2025learning}. However, these methods have limitations in adaptability to different fall scenarios or robustness to external disturbances.

Autonomous fall recovery in dynamic environments is a critical challenge for humanoid robots. 
This work aims to develop a robust policy that enables a fallen humanoid robot to autonomously recover and stand up across various fall scenarios, including supine, prone, and lateral falls. 
To systematically evaluate the proposed fall recovery policy, we employ the following criteria:
\begin{itemize}
        \item \textbf{Success Rate}: The percentage of successful recovery trials.
        \item \textbf{Recovery Time}: The time required to recover from a fall.
        \item \textbf{Robustness}: The ability to recover from falls under external disturbances and uncertainties.
        \item \textbf{Generalization}: The ability to recover from falls under different initial states and environmental conditions.
\end{itemize}

To address these challenges, we introduce a multi-stage curriculum learning framework that progressively refines the fall recovery policy by increasing task dimensionality and complexity. In the initial stage, the policy is trained in a low-dimensional setting to establish fundamental recovery behaviors. Subsequently, the second stage extends to a high-dimensional deployment scenario, incorporating additional constraints and variability. Each stage integrates tailored optimization techniques to enhance policy robustness and stability.

Our key contributions include:  
\begin{itemize}
        \item We introduce a stage division strategy and curriculum setting to break down the complex high-dimensional fall recovery task into simpler low-dimensional tasks and gradually increase the task complexity to facilitate the learning process.
        \item We employ KSI and reward shaping to guide the learning process and accelerate the convergence of a stable fall recovery policy. Furthermore, we introduce dimensionality expansion through supplementary actuated joints, enabling the policy to generalize robustly across diverse fall scenarios.
        \item We conduct comprehensive experimental validation on the real humanoid robot Booster T1, which illustrates the versatility and robustness of the proposed approach. Real robot experiment videos are available on our project page\footnote{https://hi-far.github.io/}.
\end{itemize}

\section{Related Works}

\subsection{Learning Real-world Humanoid Fall Recovery} 
Tuomas Haarnoja \textit{et al.} trained a DRL agent with predefined keyframes on a kidsize humanoid\cite{haarnoja2024learning}. However, forcing the robot to follow certain trajectories limited the fall recovery behaviors. 

FRASA \cite{gaspard2024frasa} integrates fall recovery and stand-up strategies for the Sigmaban humanoid \cite{allali2019rhoban} into a unified framework but simplifies the problem to a planar scenario and enforces symmetric behaviors, which limits the agent's capabilities. 

By using a KSI method, Chuanyu Yang \textit{et al.} proposed a DRL framework that can learn versatile fall recovery policies for different humanoid and quadruped robots in simulated environments. However, this framework has only been validated on the real Jueying Pro quadruped robot \cite{yang2023learning}. 

Ziwen Zhuang \textit{et al.} achieved humanoid standing through mobile manipulation guided by high-level motion commands, yet their approach lacks autonomous recovery capabilities. \cite{zhuang2025embrace}. 

Furthermore, Tao Huang \textit{et al.} proposed the HoST \cite{huang2025learning} method to train fall recovery by segmenting long-horizon motions into multiple short-horizon sub-tasks. However, this explicit segmentation may limit the agent's adaptability to diverse fall scenarios, such as prone and lateral falls.

HumanUp \cite{he2025learning} also utilizes a two-stage curriculum learning framework to train humanoid robot stand-up. However, their second stage is a tracking task of a slowed-down trajectory discovered in the first stage, which limits the agent's recovery speed and adaptability to different fall scenarios. 

\subsection{Multi-Stage Curriculum Learning}
Multi-Stage Curriculum Learning (MSCL) represents a training methodology that incrementally escalates the complexity of learning tasks by introducing supplementary constraints or objectives at each phase \cite{bengio2009curriculum}. 
Empirical evidence suggests that multi-stage learning and curriculum learning enhances the sample efficiency and generalization capabilities of reinforcement learning agent \cite{wang2024multi}, \cite{chen2024u}, particularly within complex and high-dimensional environments such as fall recovery training \cite{tao2022learning}. 

\subsection{State Initialization}
Reference state initialization (RSI) \cite{peng2018deepmimic} samples the initial state of the agent from the reference motion at the start of each episode. KSI \cite{yang2023learning} initializes the agent's state to a predefined key state, while do not require a reference motion sequence.

RSI leverages the rich and informative state distribution of reference motion to guide the agent during training. KSI contributes to the stabilization of the learning process and enhances the convergence of the policy by offering the agent multiple consistent starting points.

\subsection{Reinforcement Learning Framework}

Many open-source reinforcement learning frameworks are available for humanoid robots, such as Legged Gym and Humanoid Gym \cite{gu2024humanoid}. 
We leverage Booster Gym \cite{BoosterGym} as the foundational codebase to implement our methods. It incorporates pre-configured settings and techniques for sim-to-real transfer, along with a comprehensive toolchain supporting policy evaluation across multiple simulators and real-world deployment. This framework collectively reduces engineering overhead while accelerating the development of our methods.

\begin{figure*}[ht]
        \centering
        \includegraphics[width=\textwidth]{figures/roadmap.png}
        \caption{\textbf{Framework overview}. HiFAR offers a multi-stage curriculum learning framework designed for autonomous fall recovery in humanoid robots. The initial training phase emphasizes the development of a fall recovery policy within a low-dimensional task environment. The subsequent training phase tackles the intricacies associated with formulating a deployable fall recovery policy in a higher-dimensional task setting. 
 }
        \label{fig:roadmap_figure}
\end{figure*}

\section{Methods}

\subsection{Framework and Curriculum Setup}

The high-dimensional nature of the fall recovery task, coupled with the complexities of collisions and contacts, as well as the sparse reward structure, presents significant challenges in \textbf{the development of an effective fall recovery policy}. The variability of fall scenarios encountered in real-world applications, along with hardware constraints and the discrepancies between simulated environments and actual conditions, further complicate the learning and implementation of such policies, thereby hindering \textbf{the training of a deployable fall recovery strategy}. Consequently, the direct application of single-stage reinforcement learning to develop an autonomous and robust fall recovery policy proves to be problematic.

To mitigate these challenges, we propose a multi-stage curriculum learning framework, referred to as HiFAR, as illustrated in Fig. \ref{fig:roadmap_figure}. This framework incrementally introduces the agent to increasingly complex and high-dimensional recovery tasks. The multi-stage curriculum learning framework is divided into two distinct stages:

The initial stage concentrates on \textbf{the development of a basic fall recovery policy}. In this phase, the task is constrained to two-dimensional fall scenarios (\textit{e.g.}, supine and prone falls), with control limited to joints operating within the $(x, z)$ plane (the joints highlighted in yellow in Fig. \ref{fig:target_state}(A)). This design choice is based on the observation that humanoid robots can effectively recover from these standard positions using predominantly planar movements. By constraining the policy's exploration space, this configuration reduces the risk of self-collision during training. The agent is trained to recover from simple falls by utilizing an extended range of motion and higher torque capacities. Techniques such as KSI and reward shaping are employed to facilitate the learning process.

The subsequent stage focuses on \textbf{the training of a deployable fall recovery policy}. This phase expands the task to encompass three-dimensional fall scenarios, such as cross-leg falls. To handle diverse real-world falls, we include lateral hip roll joints (orange in Fig. \ref{fig:target_state}(A)) in the action space and introduce further randomizations in terrain and robot state. Realistic constraints on joint positions, torque, and velocity ensure practical training.

The curriculum across the two stages includes the following components:
\begin{itemize}
        \item \textbf{Task Dimension}: The initial stage is centered on a two-dimensional task, whereas the subsequent stage progresses to a three-dimensional task.
        \item \textbf{Task Constraints}: The first stage is characterized by lenient constraints that promote exploration, in contrast to the second stage, which imposes stringent constraints and introduces complex perturbations.
        \item \textbf{Task Complexity}: The initial stage is concerned with straightforward fall scenarios, while the second stage incorporates a greater variety of randomized fall scenarios.
\end{itemize}

By first mastering simpler tasks, the agent is better prepared to tackle more complex challenges, ultimately resulting in more efficient and stable strategies for fall recovery.

\subsection{Training Setup}
The agent is trained in a simulated environment using the Booster Gym framework \cite{BoosterGym}. The target state of fall recovery is the robot standing up with a stable posture, defined by target CoM height, DoF positions, and torso orientation, as shown in Fig. \ref{fig:target_state}(B).

\begin{figure}[h!]
        \centering
        \includegraphics[width=\columnwidth]{figures/joints_and_targets.png}
        \caption{\textbf{Booster T1}. (A) Controlled joints. (B) Target Standing State. }
        \label{fig:target_state}
\end{figure}

The agent has proprioceptive observations, including the robot's orientation, angular velocity, joint positions, velocities, and action. The action space consists of the target joint position of controlled joints. We use the Proximal Policy Optimization (PPO) algorithm \cite{schulman2017proximal} and RMA network architecture \cite{kumar2022adapting} to train the agent. 

We achieve cross-stage network expansion by integrating zero-initialized fully-connected layers into both input and output layers of the pre-existing network, thereby enabling the second stage to possess expanded action decision spaces and enhanced environmental perception dimensions while preserving knowledge transfer from the initial training phase.

Instead of forcing symmetric actions like FRASA\cite{gaspard2024frasa}, we use a mirror loss term to encourage the agent to learn symmetric recovery strategies while allowing for asymmetry when necessary, which is more realistic and generalizable to real-world scenarios.

\subsection{Keference State Initialization}

As illustrated in Figure \ref{fig:roadmap_figure}, we have selected six critical states—comprising three prone keyframes and three supine keyframes—from established handcrafted fall recovery motions. These motions are specifically designed to facilitate recovery from both supine and prone falls and have demonstrated efficacy in practical applications. The identified key states are used to initialize the agent’s state at the beginning of each episode, ensuring a consistent starting point for the learning process. This approach stabilizes the training process and improves policy convergence.

\subsection{Reward Design}

Table \ref{table:reward_function} outlines the reward function components, designed to encourage prompt and stable fall recovery. Each component is weighted by a coefficient $\omega_i$ to balance competing objectives, with adjustments across learning stages for task alignment.

Survival, base height, standing, orientation, and DoF reference terms facilitate recovery and upright stability. Conversely, torque, DoF velocity/acceleration, root acceleration, action rate, DoF limits, torque fatigue, power, and hip roll terms penalize undesirable actions, promoting smooth, efficient recovery.

\begin{table}[h!]
        \footnotesize
        \renewcommand{\arraystretch}{1.6}
        \centering
        \caption{Components of the Reward Function}
        \label{table:reward_function}
        \begin{tabular}{l l}
        \toprule
        \textbf{Reward terms} & \textbf{Formulas} \\ \midrule
 Survival & \( R_{\text{survival}} = \bm{1} \) \\ \hline
 Base Height & \( R_{\text{base height}} = \exp\left( -\sigma(h_{\text{base}} - h_{\text{des}})^2 \right) \) \\ \hline
 Standing & \( R_{\text{stand}} = \bm{1}_\text{standing} \) \\ \hline
 Orientation & \( R_{\text{orientation}} = \| \bm{g}_{x,y} \|^2 \) \\ \hline
 DoF Reference & \( R_{\text{dof pos ref}} = \| \bm{q}_{\text{ref}} - \bm{q} \|^2 \) \\ \hline
Torques & \( R_{\text{torques}} = \| \bm{\tau} \|^2 \) \\ \hline
 DoF Velocities & \( R_{\text{dof vel}} = \| \dot{\bm{q}} \|^2 \) \\ \hline
 DoF Accelerations & \( R_{\text{dof acc}} = \| \ddot{\bm{q}} \|^2 \) \\ \hline
 Root Accelerations & \( R_{\text{root acc}} = \| \bm{a} \|^2 \) \\ \hline
 Action Rate & \( R_{\text{action rate}} =  \|\dot{\bm{a}_t}\|^2+\|\ddot{\bm{a}_t}\|^2 \) \\ \hline
 DoF Position Limits & \( R_{\text{dof pos limits}} = \|\bm{1}_\text{out of bound}\| \) \\ \hline
 Torque Fatigue & \( R_{\text{torque fatigue}} = \| \bm{\tau} \oslash \bm{\tau}_{\text{limit}} \|^2 \) \\ \hline
 Power & \( R_{\text{power}} = \| \bm{\tau} \odot \dot{\bm{q}} \| \) \\ \hline
 Hip Roll & \( R_{\text{hip roll}} = ( q_{\text{hip roll}} - q_{\text{ref}} )^2 \) \\ \bottomrule
        \end{tabular}
\end{table}
        
\subsection{Domain Randomization}
We apply domain randomization techniques, including randomized push forces and torques, within the simulation environment to improve the robustness and generalizability of the learned policy. The randomized parameters are detailed in Table \ref{table:domain_randomization}:

\begin{table}[ht]
        \footnotesize
        \renewcommand{\arraystretch}{1.6}
        \centering
        \caption{Domain Randomization Parameters}
        \label{table:domain_randomization}
        \begin{tabular}{l l l l}
        \toprule
        \textbf{Parameter} & \textbf{Range} & \textbf{Operation} & \textbf{Distribution} \\ \midrule
 DoF position & [0., 0.05] & Additive & Gaussian \\ \hline
 Base XY Position & [-1., 1.] & Additive & Uniform \\ \hline
 Base Linear Velocity & [0., 0.1] & Additive & Gaussian \\ \hline
 Joint Stiffness & [0.95, 1.05] & Scaling & Uniform \\ \hline
 Joint Damping & [0.95, 1.05] & Scaling & Uniform \\ \hline
 Terrain Friction & [0.1, 2.0] & Additive & Uniform \\ \hline
 Terrain Compliance & [0.5, 1.5] & Additive & Uniform \\ \hline
 Terrain Restitution & [0.1, 0.9] & Additive & Uniform \\ \hline
 Torso CoM Position & [-0.1, 0.1] & Additive & Uniform \\ \hline
 Torso Mass & [0.8, 1.2] & Scaling & Uniform \\ \hline
 Other CoM Position & [-0.005, 0.005] & Additive & Uniform \\ \hline
 Other Mass & [0.98, 1.02] & Scaling & Uniform \\ \bottomrule
        \end{tabular}
\end{table}

Additionally, Booster Gym \cite{BoosterGym} facilitates the modeling of control delays within the simulation, thereby increasing the realism of the training process and enhancing the applicability of the learned policy to real-world scenarios.

\section{Results and Analysis}

\subsection{Training Analysis}
We analyze the agent’s learning curve with KSI. As shown in Fig. \ref{fig:train_stand}, the standing reward curve exhibits four step-like increases, indicating that the agent progressively learns to recover from falls and stand up at each key state.
The integration of KSI with selected key states stabilizes the learning process and enhances policy convergence.
\begin{figure}[h]
        \centering
        \includegraphics[width=\columnwidth]{figures/train_stand.png}
        \caption{\textbf{Training Analysis}. Standing reward function curve and agent behavior during training.}
        \label{fig:train_stand}
\end{figure}

\subsection{Simulation Experiments}

\subsubsection{Simulation Settings}

We evaluate our policy in the Webots simulator based on success rate, recovery time, and robustness. The simulation environment is designed to replicate real-world conditions, including the robot model and control system.

Before deploying the policy on the physical robot, we conduct a series of simulation experiments to assess its effectiveness in fall recovery. The standard experimental setup includes supine and prone fall scenarios, with a torso mass of 11.7 kg, a friction coefficient of 1.0, and no external disturbances. Each experiment is repeated 10 times under identical conditions to measure the recovery success rate.

\subsubsection{Standard Supine and Prone Recovery Experiments}
Snapshots of the simulation experiments are presented in Fig. \ref{fig:webots}. In both prone and supine scenarios, our policy successfully enables the robot to recover from falls and stand upright with a stable posture, achieving a 100\% success rate.
The rapid variations in the torso pitch curve highlight the robot's highly dynamic movements.

\begin{figure*}[h!]
        \centering
        \includegraphics[width=\textwidth]{figures/sim.png}
        \caption{\textbf{Snapshots of simulation experiments and the curve of the torso pitch}. (A) Prone fall recovery. (B) Supine fall recovery.}
        \label{fig:webots}
\end{figure*}

\subsubsection{Disturbance Experiments}
In this experiment, we apply a random push force to the robot at 0.8s after the recovery process starts and lasts 200ms. 

In the planar force experiment, the perturbation force is applied forward along the robot’s torso direction during recovery from the prone position and backward during recovery from the supine position. The recovery success rate under different perturbation forces is presented in Table \ref{table:force_experiment}.

\begin{table}[h!]
        \footnotesize
        \renewcommand{\arraystretch}{1.6}
        \centering
        \caption{Success Rate of Planar Force Experiments}
        \label{table:force_experiment}
        \begin{tabular}{c c c c c c c}
        \toprule
 \textbf{Force} & \textbf{50N} & \textbf{100N} & \textbf{150N} & \textbf{200N} & \textbf{250N} & \textbf{300N} \\ \midrule
 Prone & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $80\%$ & $0\%$  \\ \hline
 Supine & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $60\%$ \\ \bottomrule
 \end{tabular}
\end{table}

In the lateral force experiment, the perturbation force is applied leftward along the robot’s torso direction during recovery from both prone and supine positions. The recovery success rate under different perturbation forces is shown in Table \ref{table:lateral_force_experiment}.

\begin{table}[h!]
        \footnotesize
        \renewcommand{\arraystretch}{1.6}
        \centering
        \caption{Success Rate of Lateral Force Experiments}
        \label{table:lateral_force_experiment}
        \begin{tabular}{c c c c c c}
        \toprule
\textbf{Force} & \textbf{50N} & \textbf{100N} & \textbf{150N} & \textbf{200N} & \textbf{250N} \\ \midrule
 Prone & $100\%$ & $100\%$ & $100\%$ & $90\%$ & $10\%$ \\ \hline
 Supine & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $0\%$ \\ \bottomrule
 \end{tabular}
\end{table}

The results demonstrate the strong robustness of our policy against perturbations in various directions.

\subsubsection{Load Experiments}

We simulate the mass inaccuracy of the real robot by modifying its mass in simulation. The success rate of the recovery process under different mass perturbations is shown in Table \ref{table:load_experiment}.

\begin{table}[h!]
        \footnotesize
        \renewcommand{\arraystretch}{1.6}
        \centering
        \caption{Success Rate of Load Experiments}
        \label{table:load_experiment}
        \begin{tabular}{c c c c c}
        \toprule
 \textbf{Extra Torso Mass}  & \textbf{+2.4kg} & \textbf{5.9kg} & \textbf{+9.4kg} & \textbf{+11.7kg} \\ \midrule
 Prone & $100\%$ & $100\%$ & $100\%$ & $100\%$ \\ \hline
 Supine & $100\%$ & $100\%$ & $100\%$ & $0\%$ \\ \bottomrule
 \end{tabular}
\end{table}

With up to $80\%$ extra torso mass, the robot can still recover from prone and supine falls with a $100\%$ success rate, demonstrating the strong robustness of our policy against mass perturbations.

\subsubsection{Friction Experiments}

In real-world scenarios, the robot may fall on terrains with varying friction coefficients. To evaluate its ability to recover from falls under different surface conditions, we conduct experiments with various friction coefficients. The recovery success rate for each friction setting is presented in Table \ref{table:friction_experiment}.

\begin{table}[h!]
        \footnotesize
        \renewcommand{\arraystretch}{1.6}
        \centering
        \caption{Success Rate of Friction Experiments}
        \label{table:friction_experiment}
        \begin{tabular}{c c c c c c}
        \toprule
 \textbf{Friction Coefficient}  & \textbf{0.8} & \textbf{0.6} & \textbf{0.4} & \textbf{0.2} & \textbf{0.1} \\ \midrule
 Prone & $100\%$ & $100\%$ & $100\%$ & $90\%$ & $0\%$ \\ \hline
 Supine & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $90\%$ \\ \bottomrule
 \end{tabular}
\end{table}

The high recovery success rate at friction coefficients as low as 0.2 demonstrates the robustness of our policy and its applicability to real-world terrains with low friction.

\subsubsection{Torque Limits Experiments}

In real-world conditions, motors may be unable to generate the desired torque due to operational constraints. To assess the robot’s ability to recover from falls under varying torque limitations, we conduct experiments with different torque limits. The success rate of the recovery process under different torque limits is shown in Table \ref{table:torque_experiment}.

\begin{table}[h!]
        \footnotesize
        \renewcommand{\arraystretch}{1.6}
        \centering
        \caption{Success Rate of Torque Limit Experiments}
        \label{table:torque_experiment}
        \begin{tabular}{c c c }
        \toprule
 \textbf{Torque Limit Percentage} & $\bm{85\%}$ & $\bm{75\%}$ \\ \midrule
 Prone & $100\%$ & $100\%$ \\ \hline
 Supine & $100\%$ & $60\%$ \\ \bottomrule
 \end{tabular}
\end{table}

The high recovery success rate at an 85\% torque limit demonstrates that the robot can reliably recover from falls despite actuator wear and degradation.

\section{Real-world Experiments and Analysis}
\subsection{Hardware Platform}

We validate our policy on the real humanoid robot Booster T1, which is a 118cm tall humanoid robot with 23 DoFs. The robot is equipped with a set of sensors, including IMUs, and joint encoders to provide feedback for the control system. On-board computations are performed using a Nvidia AGX Orin GPU and 14-core high-performance CPU. 

% \vspace{-0.2cm}

\begin{figure*}[t!]
        \centering
        \includegraphics[width=0.9\textwidth]{figures/result_1_a.jpg}
        \caption{\textbf{Fall recovery behaviors on a real robot}. (A) High-dynamics fall recovery from the prone position. (B) High-dynamics fall recovery from the supine position. }
        \label{fig:result_1}
\end{figure*}

\begin{figure*}[t!]
        \centering
        \includegraphics[width=0.9\textwidth]{figures/result_23_a.jpg}
        \caption{\textbf{Fall recovery under different scenarios}. (A) Random initial state. (A1) lateral positioning, (A2) apart leg posture, (A3) seated position, and (A4) crossed leg posture. (B)Environmental complexity. (B1-2) sloped surfaces, (B3-4) obstacles, and (B5-6) outdoor environments.}
        \label{fig:result_23}
\end{figure*}

\subsection{Experimental Setup}
\subsubsection{Supine and Prone Recovery Experiments} 
Initially placed in either a supine or prone position, the robot executes the policy to restore itself to an upright posture. We record the success rate and recovery time for each trial.

\subsubsection{Random Initial State Experiments} 
Initialized in various fall conditions, including lateral falls, crossed-leg falls, and sitting positions, the robot's ability to recover from diverse initial states is assessed.

\subsubsection{Environmental Complexity Experiments}
Recovery performance is evaluated in complex scenarios, such as standing up from a slope, recovering with obstacles (e.g., a ball) between its legs, and operating in outdoor environments.

\subsubsection{Load and Disturbance Experiments} 
The robot’s recovery ability is tested under additional loads and subjected to strong external forces, such as pushes or impacts, to evaluate its robustness and stability.

\subsection{Results and Analysis}

\begin{figure*}[t!]
        \centering
        \includegraphics[width=0.9\textwidth]{figures/result_4_a.jpg}
        \caption{\textbf{Fall recovery under load and disturbance}. (A) 5kg load. (B) Push. (C) Impact.}
        \label{fig:result_4}
\end{figure*}

\subsubsection{Supine and Prone Recovery Experiments}

The performance of our policy is shown in Figure \ref{fig:result_1}. Our policy demonstrates high-dynamics recovery behaviors on the real robot, closely matching its performance in the simulation environment. This consistency validates the sim-to-real transferability of our method.

To evaluate recovery performance, we conducted 20 supine and 20 prone fall recovery trials on the real robot. The average recovery time and success rates are summarized in Table \ref{table:recovery_time_success_rate}. Our method achieves rapid and reliable fall recovery with a 100\% success rate, demonstrating its robustness in real-world deployment.

\begin{table}[h!]
        \footnotesize
        \renewcommand{\arraystretch}{1.6}
        \centering
        \caption{Average Time and Success Rate of Supine and Prone Recovery Experiments}
        \label{table:recovery_time_success_rate}
        \begin{tabular}{c c c}
        \toprule
         & \textbf{Supine} & \textbf{Prone} \\ \midrule
 Average Time (s) & $2.711\pm0.319$ & $2.875\pm0.474$ \\ \hline
 Success Rate & $100\%$ & $100\%$ \\ \bottomrule
        \end{tabular}
\end{table}

\subsubsection{Random Initial State and Environmental Complexity Experiments}

To assess generalization, we initialize the robot in various random states, as illustrated in Figure \ref{fig:result_23}(A). The robot successfully recovers from all scenarios, demonstrating the adaptability of our policy.

Further, we test the robot in complex environments, including standing up from a slope, navigating obstacles between its legs, and recovering in outdoor conditions (Figure \ref{fig:result_23}(B)). The robot consistently executes versatile recovery behaviors across diverse environmental conditions, showcasing the generalizability of our approach.


\subsubsection{Load and Disturbance Experiments}

We evaluate recovery performance under additional physical constraints. Figure \ref{fig:result_4}(A) illustrates the robot with a 5 kg load attached during recovery. The robot successfully stands up while maintaining stability, demonstrating its ability to handle additional payloads.

Furthermore, we introduce external disturbances by applying push forces (Figure \ref{fig:result_4}(B)) and impact (Figure \ref{fig:result_4}(C)) during recovery. The robot reacts by adopting a safe sitting posture to mitigate impact before immediately executing high-dynamic recovery to a standing stance. These results confirm the robustness of our policy in handling strong disturbances autonomously.

\subsubsection{Various Behaviors}

\textbf{Push and Fall Recovery}: The robot uses ankle and hip strategies for minor perturbations and recovery steps for stronger pushes. If falling, it transitions to a safe posture before recovering.
\textbf{Walking after Recovery}: After standing up, the robot stabilizes in a standard stance, enabling a seamless transition into locomotion, demonstrating the practicality of our approach.

\section{Conclusions}

We introduce a multi-stage curriculum learning approach for autonomous humanoid fall recovery. Our method progressively increases task complexity, starting with basic recovery skills and advancing to complex scenarios while addressing sim-to-real challenges.

Simulation and real-world experiments confirm our method’s high success rate, fast recovery, robustness, and generalization across diverse falls and disturbances. The approach enables versatile recovery behaviors in varied environments.

This method offers a robust solution for humanoid fall recovery and can extend to other adaptive robotics applications. 
Future work will aim to enhance the policy's adaptability to a wider range of scenarios, particularly in environments where space or speed constraints affect the robot's stand-up ability.

\section*{Acknowledgment}
We thank Booster Robotics for T1 hardware and support. 

% A conclusion section is not required. Although a conclusion may review the main points of the paper, do not replicate the abstract as the conclusion. A conclusion might elaborate on the importance of the work or suggest applications and extensions. 


% \section{PROCEDURE FOR PAPER SUBMISSION}

% \subsection{Selecting a Template (Heading 2)}

% First, confirm that you have the correct template for your paper size. This template has been tailored for output on the US-letter paper size. 
% It may be used for A4 paper size if the paper size setting is suitably modified.

% \subsection{Maintaining the Integrity of the Specifications}

% The template is used to format your paper and style the text. All margins, column widths, line spaces, and text fonts are prescribed; please do not alter them. You may note peculiarities. For example, the head margin in this template measures proportionately more than is customary. This measurement and others are deliberate, using specifications that anticipate your paper as one part of the entire proceedings, and not as an independent document. Please do not revise any of the current designations

% \section{MATH}

% Before you begin to format your paper, first write and save the content as a separate text file. Keep your text and graphic files separate until after the text has been formatted and styled. Do not use hard tabs, and limit use of hard returns to only one return at the end of a paragraph. Do not add any kind of pagination anywhere in the paper. Do not number text heads-the template will do that for you.

% Finally, complete content and organizational editing before formatting. Please take note of the following items when proofreading spelling and grammar:

% \subsection{Abbreviations and Acronyms} Define abbreviations and acronyms the first time they are used in the text, even after they have been defined in the abstract. Abbreviations such as IEEE, SI, MKS, CGS, sc, dc, and rms do not have to be defined. Do not use abbreviations in the title or heads unless they are unavoidable.

% \subsection{Units}

% \begin{itemize}

% \item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as 3.5-inch disk drive.
% \item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
% \item Do not mix complete spellings and abbreviations of units: Wb/m2 or webers per square meter, not webers/m2.  Spell out units when they appear in text: . . . a few henries, not . . . a few H.
% \item Use a zero before decimal points: 0.25, not .25. Use cm3, not cc. (bullet list)

% \end{itemize}


% \subsection{Equations}

% The equations are an exception to the prescribed specifications of this template. You will need to determine whether or not your equation should be typed using either the Times New Roman or the Symbol font (please no other font). To create multileveled equations, it may be necessary to treat the equation as a graphic and insert it into the text after your paper is styled. Number equations consecutively. Equation numbers, within parentheses, are to position flush right, as in (1), using a right tab stop. To make your equations more compact, you may use the solidus ( / ), the exp function, or appropriate exponents. Italicize Roman symbols for quantities and variables, but not Greek symbols. Use a long dash rather than a hyphen for a minus sign. Punctuate equations with commas or periods when they are part of a sentence, as in

% $$
% \alpha + \beta = \chi \eqno{(1)}
% $$

% Note that the equation is centered using a center tab stop. Be sure that the symbols in your equation have been defined before or immediately following the equation. Use (1), not Eq. (1) or equation (1), except at the beginning of a sentence: Equation (1) is . . .

% \subsection{Some Common Mistakes}
% \begin{itemize}


% \item The word data is plural, not singular.
% \item The subscript for the permeability of vacuum ?0, and other common scientific constants, is zero with subscript formatting, not a lowercase letter o.
% \item In American English, commas, semi-/colons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
% \item A graph within a graph is an inset, not an insert. The word alternatively is preferred to the word alternately (unless you really mean something that alternates).
% \item Do not use the word essentially to mean approximately or effectively.
% \item In your paper title, if the words that uses can accurately replace the word using, capitalize the u; if not, keep using lower-cased.
% \item Be aware of the different meanings of the homophones affect and effect, complement and compliment, discreet and discrete, principal and principle.
% \item Do not confuse imply and infer.
% \item The prefix non is not a word; it should be joined to the word it modifies, usually without a hyphen.
% \item There is no period after the et in the Latin abbreviation et al..
% \item The abbreviation i.e. means that is, and the abbreviation e.g. means for example.

% \end{itemize}


% \section{USING THE TEMPLATE}

% Use this sample document as your LaTeX source file to create your document. Save this file as {\bf root.tex}. You have to make sure to use the cls file that came with this distribution. If you use a different style file, you cannot expect to get required margins. Note also that when you are creating your out PDF file, the source file is only part of the equation. {\it Your \TeX\ $\rightarrow$ PDF filter determines the output file size. Even if you make all the specifications to output a letter file in the source - if your filter is set to produce A4, you will only get A4 output. }

% It is impossible to account for all possible situation, one would encounter using \TeX. If you are using multiple \TeX\ files you must make sure that the ``MAIN`` source file is called root.tex - this is particularly important if your conference is using PaperPlaza's built in \TeX\ to PDF conversion tool.

% \subsection{Headings, etc}

% Text heads organize the topics on a relational, hierarchical basis. For example, the paper title is the primary text head because all subsequent material relates and elaborates on this one topic. If there are two or more sub-topics, the next level head (uppercase Roman numerals) should be used and, conversely, if there are not at least two sub-topics, then no subheads should be introduced. Styles named Heading 1, Heading 2, Heading 3, and Heading 4 are prescribed.

% \subsection{Figures and Tables}

% Positioning Figures and Tables: Place figures and tables at the top and bottom of columns. Avoid placing them in the middle of columns. Large figures and tables may span across both columns. Figure captions should be below the figures; table heads should appear above the tables. Insert figures and tables after they are cited in the text. Use the abbreviation Fig. 1, even at the beginning of a sentence.

% \begin{table}[h]
% \caption{An Example of a Table}
% \label{table_example}
% \begin{center}
% \begin{tabular}{|c||c|}
% \hline
% One & Two\\
% \hline
% Three & Four\\
% \hline
% \end{tabular}
% \end{center}
% \end{table}


%    \begin{figure}[thpb]
%       \centering
%       \framebox{\parbox{3in}{We suggest that you use a text box to insert a graphic (which is ideally a 300 dpi TIFF or EPS file, with all fonts embedded) because, in an document, this method is somewhat more stable than directly inserting a picture.
% }}
%       %\includegraphics[scale=1.0]{figurefile}
%       \caption{Inductance of oscillation winding on amorphous
%        magnetic core versus DC bias magnetic field}
%       \label{figurelabel}
%    \end{figure}
   

% Figure Labels: Use 8 point Times New Roman for Figure labels. Use words rather than symbols or abbreviations when writing Figure axis labels to avoid confusing the reader. As an example, write the quantity Magnetization, or Magnetization, M, not just M. If including units in the label, present them within parentheses. Do not label axes only with units. In the example, write Magnetization (A/m) or Magnetization {A[m(1)]}, not just A/m. Do not label axes with a ratio of quantities and units. For example, write Temperature (K), not Temperature/K.


% \addtolength{\textheight}{-10cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section*{APPENDIX}

% Appendixes should appear before the acknowledgment.

% The preferred spelling of the word acknowledgment in America is without an e after the g. Avoid the stilted expression, One of us (R. B. G.) thanks . . .  Instead, try R. B. G. thanks. Put sponsor acknowledgments in the unnumbered footnote on the first page.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,reference}


\end{document}

