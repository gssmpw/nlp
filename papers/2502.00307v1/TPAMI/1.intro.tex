\section{Introduction}\label{sec:intro}


\IEEEPARstart{A} diffusion probabilistic model~\cite{sohl2015deep,ho2020denoising,song2020score,song2020denoising}, also known as a diffusion model, is a generative model that consists \sqq{of} (1) a forward diffusion process that gradually adds noise to a data distribution until it becomes a simple latent distribution (\textit{e.g.}, Gaussian), and (2) a reverse process that \sqq{begins with} a random sample in the latent distribution \sqq{and employs} a learned network to revert the diffusion process, \sqq{thereby generating} a data point in the original distribution. 
%
Among all the variants of the diffusion model, the denoising diffusion probabilistic model (DDPM)~\cite{ho2020denoising} offers the advantage of a simple training procedure by exploring an explicit connection between the diffusion model and denoising score matching.
%
Recent studies have demonstrated the compelling performance of DDPM in high-fidelity image synthesis~\cite{ho2020denoising, nichol2021improved, dhariwal2021diffusion}. % which is comparable with or even surpasses the state-of-the-art GAN-based models~\cite{brock2018large, karras2020training}.

Despite its rapid development, there are relatively few studies on applying the diffusion model to conditional generation, which is \sqq{a key requirement} for many real-world applications, such as the well-known image-to-image (I2I) task~\cite{isola2017image} that translate a source image of one style into another target image of \sqq{a different} style.
%
Unlike unconditional generation, conditional generation \sqq{necessitates constraining} synthesized result with an input sample in the source domain as the \revise{content guidance}. 
%
Therefore, to handle an I2I task using DDPM, existing methods~\cite{sasaki2021unit,saharia2021palette,choi2021ilvr,liu2021more,wang2022pretraining} inject the information from an input source sample into every single denoising step in the reverse process (see \cref{fig:method}a).
%
In this way, each denoising step explicitly relies on its previous step, making it inefficient to learn the step-wise injection.

\input{figures/fig_method/fig.tex}

% \input{figures/fig_teaser/fig.tex}

In this work\sqq{,} we investigate a more efficient approach to applying DDPM to I2I tasks by endowing a pre-trained DDPM with a translator, \sqq{which we name} {\em Diffusion Model Translator} (\method).
%
First, we provide a \textit{theoretical} proof that given two diffusion processes on two different image domains involved in an I2I task, it is feasible to accomplish the I2I task by shifting a distribution from one process to \sqq{another} at a particular timestep with appropriate reparameterization.
%
Based on this theoretical justification, we develop a new efficient DDPM pipeline, as illustrated in \cref{fig:method}b.
%
Assuming that a DDPM has been prepared for one image domain $y_0$, we use it to decode the latent that is shifted from another domain $x_0$.
%
To accomplish the domain shift, we apply the same forward diffusion process onto $x_0$ and $y_0$ until a pre-defined timestep $t$, and then employ a neural network to translate $x_t$ to $y_t$ as a typical I2I problem.

There are two major advantages \sqq{to} our approach.
%
First, the training of \method is independent of DDPM and can be executed very efficiently.
%
Second, \method can benefit from using all the previous techniques in the I2I field (\textit{e.g.}, such as Pix2Pix~\cite{isola2017image}, TSIT~\cite{jiang2020tsit}, SPADE~\cite{park2019SPADE}, and SEAN~\cite{Zhu_2020_CVPR}), for a better performance.
%
Furthermore, regarding the choice of the timestep $t$ to perform domain transfer, we propose a practical strategy to automatically select an appropriate timestep for a given data distribution.

To empirically validate the \revise{efficacy} of our method, we conducted evaluation on four I2I tasks: image stylization, image colorization, segmentation to image, and sketch to image.
%
Both qualitative and quantitative results demonstrate the superiority of our method over existing diffusion-based alternatives as well as the GAN-based counterparts of \method.

% In this paper, we propose a simple yet efficient module named \textit{diffusion model translator} (\method), to accomplish the I2I task with DDPM.
%
% Different from existing methods that rely on input reference for each refinement step, we introduce a translation mapping which bridges the pre-trained DDPM and the input reference.
%
% Our method shifts the latent diffusion distribution at one single intermediate step as the constraint of the generation, which makes it possible for the well-prepared DDPM applicable to the I2I task without any retraining.


% As shown in \cref{fig:method}b, our method starts from the given reference and the desired output.
% %
% First, it gradually applies the forward diffusion process onto both of the reference and the output until the pre-selected timestep.
% %
% Then it learns the translation mapping between the reference and the output with noise, following the same way as a simple I2I task.
% %
% Different from previous methods which inject the input reference at each step of denoising sampling, our \method model is capable of introducing more effective constraint by the learned translation mapping.
% %
% More importantly, we prove that it is feasible to transfer only the latent distribution at some intermediate step to accomplish the I2I task.
% %
% This observation is far beyond trivial, since the reference information is regarded to act as the constraint for each iteration of denoising step~\cite{sasaki2021unit,saharia2021palette,choi2021ilvr,wang2022pretraining}, and then our \method model does not need thousands of reverse steps which is time consuming.
% %
% Some results are shown in \cref{fig:teaser}.


% Our main contributions are summarized as follows.
% %
% First we prove the feasibility of training a simple \method module that can bridge the input reference and the pre-trained DDPM by injecting the reference information at some specific timestep.
% %
% Second, we fully study the effect of the timestep $t$ used for the training process, and propose a simple method to determine an adequate timestep before training.
% %
% Third, we conduct comprehensive experiments to demonstrate the efficiency and effectiveness of our proposed method (as well as the simple strategy for timestep $t$ determination) on a wide range of datasets.
