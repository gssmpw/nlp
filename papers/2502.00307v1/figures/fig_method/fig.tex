\begin{figure*}[t]
\centering
%\setlength\tabcolsep{2pt}
%\begin{tabular}{cc}
%\begin{minipage}[t]{0.55\linewidth}\includegraphics[width=1\linewidth]{figures/fig_method/method_palette.pdf}\end{minipage} &
%\begin{minipage}[t]{0.45\linewidth}\includegraphics[width=1\linewidth]{figures/fig_method/method_dmt.pdf}\end{minipage} \\
%(a) Our proposed \method & (b) Palette
%\end{tabular}
\includegraphics[width=1.\textwidth]{figures/fig_method/method_dmt.pdf}
\vspace{-15pt}
\caption{
    \textbf{Conceptual comparison} between (a) existing methods~\cite{saharia2021palette,choi2021ilvr,liu2021more} and (b) our \method.
    %
    $\{x_t\}_{t=0}^T$ represent different states of the \revise{input from the source domain}, while $y_T \to y_0$ stands for the denoising process of DDPM.
    %
    Here, $T$ denotes the total number of noise-adding steps in the diffusion process.
    %
    Instead of using the \revise{information $f_t(x)$ from the source domain} (which can be the original or noisy image) for an iterative refinement at \textit{each} denoising step $t,t=0,1,\cdots,T$, \method accomplishes the I2I task efficiently by learning an efficient translation module at just one \textit{preset} timestep and fully reusing the pre-trained DDPM.
    %
    How to select an appropriate translation timestep is discussed in \cref{subsec:Optimal}.
}
\label{fig:method}
\vspace{-10pt}
\end{figure*}
