\section{Background and Related Work}
Counterfactual explanations can be generated using a variety of methods, which are broadly classified into optimization-based and generative approaches. Op-timization-based methods aim to optimize an objective function subject to certain constraints \cite{poyiadzi2020face,ustun2019actionable,joshi2019towards,mothilal2020explaining,karimi2020model}. These methods focus on minimizing a distance function, with one key constraint ensuring that the resulting counterfactual satisfies the desired class prediction. Within this category, optimization techniques can be further divided into gradient-based and non-gradient-based approaches. Discrete non-gradient methods, such as constraint satisfaction problem solvers (SATs), form a subclass that often fail to account for traditional desiderata in counterfactual explanations, such as incorporating a realism loss \cite{barzekar2023achievable,rasouli2024care,salimi2023towards}.

 An advantage of optimization-based methods is having great flexibility in constructing custom distance functions and additional constraints. However, this flexibility also results in the need to construct a new optimization search space for each task. It is often unclear which distance function is optimal since the difficulty of adjusting a feature is a personal matter. Furthermore, these methods may lack assurance that the generated explanations are realistic. To address this issue, reconstruction loss from auto-encoders or outputs from GAN discriminators can be incorporated as additional constraints in gradient-based methods \cite{joshi2019towards,van2021interpretable}. 
 
 Despite their benefits, these methods suffer from slow generation speeds, as multiple optimization steps are required to generate each candidate explanation. To accelerate the process, techniques such as leveraging class prototypes—abstract representations of samples belonging to a specific class in the latent space—can guide the optimization path more effectively \cite{van2021interpretable}. Yang et al.~\cite{yang2022mace} achieve a speedup by identifying the most relevant features, focusing on the nearest samples that match the desired target class.

Generative models, such as GANs \cite{nemirovsky_2022_countergan,vanlooveren_2021_conditional,singla_2021_explaining}, inherently adhere to the data manifold and offer rapid inference speeds due to their one-shot generation capability, as they require training only once for the entire data space. However, a key limitation of existing GAN approaches is their assumption of a fixed set of mutable features, necessitating retraining when a different combination of features is considered. This restricts user flexibility in choosing which features to modify and which to keep immutable. Nemirovsky et al.~\cite{nemirovsky_2022_countergan} tackled this issue by introducing a method to respect immutable features during counterfactual generation. Specifically, their approach searches for counterfactual examples while automatically reverting any changes made to features marked as immutable, ensuring these features remain unaltered. However, the set of immutable features remains fixed, and users are still unable to dynamically select which features to keep unaltered. 

FCEGAN addresses this limitation by introducing a \textit{counterfactual template} that allows users to specify which features are mutable. This template serves as an additional input to the counterfactual generator, enabling users to dynamically control which features can be altered. FCEGAN incorporates techniques from the Conditional Tabular GAN (CTGAN) \cite{xu_modeling_2019}, including training-by-sampling \cite{engelmann_conditional_2021,zhao_ctab-gan_2021}, and the Wasserstein GAN \cite{arjovsky_towards_2017,arjovsky_wasserstein_2017} with gradient penalty (WGAN-GP) \cite{gulrajani_improvedwgan_2017}, to generate diverse and realistic synthetic tabular data \cite{xu_modeling_2019}. These methods effectively mitigate mode collapse \cite{srivastava2017veegan}, which can otherwise compromise the diversity of the generated counterfactual explanations.

In black-box scenarios, where the underlying model's architecture and parameters are inaccessible, a promising solution is to leverage a dataset of the model's historical predictions. These datasets inherently capture the relationships between specific input features and the corresponding outputs. For instance, Nemirovsky et al.\cite{nemirovsky_2022_countergan} utilize this idea by weighting samples based on the model's previously assigned scores. This strategy enables the generation of counterfactuals that align with the model's prior behavior, even in the absence of direct access to its internal workings.

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.95\linewidth]{architecture.png}
    \caption{\textbf{FCEGAN Architecture}. The users' original features \(x_{og}\), concatenated with their (undesired) predictions, are input to the model. Normally the user would select which features are set mutable in the counterfactual template. During training, counterfactual templates \( x_{tmp} \) are generated by randomly setting a fraction of features as mutable, along with specifying a desired target \( y_{desired} \), which is especially important in multi-class settings. The original instance \( x_{og} \) and counterfactual template \( x_{tmp} \) are fed into the flexible counterfactual generator, which outputs the predicted counterfactuals \( x_{cf} \). To ensure realism, a combination of two discriminator losses is used: \( L_{D_{og}} \), comparing \( x_{cf} \) with the original instance \( x_{og} \), and \( L_{D_{cf}} \), comparing \( x_{cf} \) with real counterfactuals from the desired class \( x_{desired} \). To limit divergence, a divergence loss \( L_{div} \) is applied, computed separately for mutable and immutable features. An optional classifier loss \( L_{clas} \) can guide the generator to produce valid counterfactuals aligned with the desired target.}
    \label{fig:architecture}
\end{figure}