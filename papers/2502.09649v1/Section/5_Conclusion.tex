


\section{Conclusion}
\label{Conclusion}
%在这项工作中，我们引入了 Imit Diff，a fine-grained semanstic guided diffusion transformer imitation learning framework with dual res fusion. Imit Diff 的 core contribution 在于巧妙地利用了 vision foundation models 的先验知识，将原本难以对齐的 high-level 语义监督转化为了与视觉观测同模态的细粒度语义遮罩，并采用了合适的方式将其注入到双分辨率融合模块提取的多尺度视觉信息中。基于 consistency policy 的 DiT action head 有效减少了 diffusion transformer 的 denoise 时间 in robot control。在具有复杂场景和 visual distraction 的 fine manipulation 中，Imit Diff 表现出了很高的准确性和鲁棒性。额外地，我们征明了 Imit Diff 在 zero-shot everyday tasks 中的泛化性。

In this work, we present Imit Diff, a fine-grained semantic-guided diffusion transformer imitation learning framework featuring dual res fusion. The core contribution of Imit Diff lies in its innovative utilization of prior knowledge from vision foundation models. It transforms traditionally challenging-to-align high-level semantic supervision into fine-grained semantic masks that share the same modality as visual observations. This pixel-level semanstic information is then effectively integrated into the multi-scale visual information extracted by the dual res fusion module. Furthermore, the DiT action head, based on a consistency policy, significantly reduces the denoising time of the diffusion transformer in robot control tasks. Imit Diff demonstrates high accuracy and robustness in fine manipulation tasks, even in complex scenes with visual distractions. Additionally, we showcase the generalization capability of Imit Diff through its performance in zero-shot everyday tasks.

% 尽管我们开发出了一种有效的 visuomotor imitation learning policy，这项工作仍然存在一些问题。我们建立的 open vocabulary vision foundation models pipeline 在 4060 Ti GPU 上达到了 15-20 FPS。未来可以考虑接入 SAM2 或 Efficient Track Anything 等更为先进和轻量化的 module。另外，尽管提供了更高效的推理，consistency policy 的训练需要更多的计算资源，并且两个模型的顺序训练会造成不稳定。基于 flow matching 的 diffusion methods remain for future exploration。
\textbf{Limitations. }Although we have developed an effective visuomotor imitation learning policy, several limitations remain in this work. The open vocabulary vision foundation models pipeline achieves 15-20 FPS on a 4060 Ti GPU, which leaves room for optimization. Future work could explore integrating more advanced and lightweight modules, such as SAM2 \citep{ravi2024sam} or Efficient Track Anything \citep{xiong2024efficient}, to enhance computational efficiency. Additionally, while the consistency policy improves inference efficiency, its training demands substantial computational resources which introduces instability into training process. Diffusion models based on flow matching may remain for future exploration \citep{lipman2022flow}.