\section{Experiments}
\label{Experiments}

% We present experiments to evaluate Imit Diff's performance on fine manipulation tasks。我们设计了四个真实世界的任务来验证 Imit Diff 在复杂场景和 visual distractions 的表现。消融实验证明了 policy 每个组件的有效性。额外地，我们进行了 visual distraction 和 appearance / category generalization 的 zero-shot 实验来证明 Imit Diff 受益于注入了细粒度显式语义信息的双视觉增强框架。

We present experiments to evaluate the performance of Imit Diff on fine manipulation tasks. Four real-world tasks are designed to assess Imit Diff's effectiveness in complex scenes with visual distractions. Ablation experiments highlight the contribution of each component of the policy. Furthermore, zero-shot experiments on visual distraction and appearance / category generalization are conducted to demonstrate that Imit Diff benefits from the dual visual enhancement framework, which injects fine-grained explicit semantic information.

\subsection{Environment Setup}

% Imit Diff is evaluated across 4 real-world tasks on Airbot Play 6-DoF robot arms, including a teacher and a gripper for demonstration and inference. We use simple RGB web cameras to obtain real-world visual observations from global view and wrist view. Our real-world setup and everyday objects used in our tasks are shown in Figure 5.

\textbf{Robot Setup:} Imit Diff is evaluated across 4 real-world tasks on Airbot Play 6-DoF robot arms, including a teacher and a gripper for demonstration and inference. We use simple RGB web cameras to obtain real-world visual observations from global view and wrist view. Our real-world setup and everyday objects used in our tasks are shown in Figure \ref{fig:robot_setup}.

%For the four tasks，我们使用 8xA100 with 80 GB of VRAM for 所有实验的训练。We use a desktop containing a single 4060 Ti GPU with 16 GB of VRAM for inference. A brief overview of trainning setup is shown in Table I.

\textbf{Traning and Inference Setup: }For the four tasks, we use 8 $\times$ A100 with 80 GB of VRAM for training all experiments. We use a desktop containing a single 4060 Ti GPU with 16 GB of VRAM for inference.

% 插入robot setup图
% 
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Figure/robot_setup.pdf} 
    \caption{\textbf{Our robot setup and everyday objects.} We use Airbot Play 6-DoF robot arms including a gripper and a teacher to demonstrate and inference. We aloso employ diverse everyday objects for our manipulation tasks and visual distraction. Two USB cameras are used to capture global and wrist view visual observations.}
    \label{fig:robot_setup}
\end{figure}

%插入 illustrations of all tasks 图
% 
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\textwidth]{Figure/illustrations_of_all_tasks.pdf} 
    % Illustrations of all taksk. We evaluate Imit Diff and baseline methods on four real-world tasks。Stack Blocks: (1) grasp the red block, (2) place the red block on the green one, (3) grasp the blue block and place it on the green one。Cover Glue: (1) grasp the white lid, (2) insert the white lid on the red glue。Jujube Place: (1) grasp the jujube, (2) place jujube in the bowl。Drawer Place: (1) Open the drawer, (2) place the red block into the drawer。
    \caption{\textbf{Illustrations of all tasks.} We evaluate Imit Diff and baseline methods on four real-world tasks. \textbf{Stack Blocks: }(1) grasp the red block, (2) place the red block on the green one, (3) grasp the blue block and place it on the green one. \textbf{Cover Glue: }(1) grasp the white lid, (2) insert the white lid onto the red glue. \textbf{Jujube Place: }(1) grasp the jujube, (2) place jujube in the bowl. \textbf{Drawer Place: }(1) Open the drawer, (2)  place the red block into the drawer.}
    \label{fig:illustrations_of_all_tasks}
\end{figure}

\subsection{Tasks and Metrics}

%我们设计了四种包含不同 manipulation 属性和任务要求的现实世界精细任务。Figure 5 shows illustrations of all tasks。我们在后续段落中详细解释了每个任务的具体内容以及我们设计该任务的原因。For all 4 real-world tasks，we collect demonstrations using Airbot Play teleoperation。我们总共采集了 100 组 demonstrations for each task with 50 组 no visual distraction，30 组 easy visual distraction 和 20 组 hard visual distraction。不同程度 visual distraction 的 difficulty 在 Figure 6 中展示。我们在 Table I 中总结了 Imit Diff 的任务 setup。

\textbf{Tasks Setup: }We design four real-world tasks with varying manipulation properties and task requirements. Figure \ref{fig:illustrations_of_all_tasks} illustrates all tasks and we provide detailed explanations of each task's specific content and the rationale behind our design in the following paragraphs. For all four tasks, we collect 100 demonstrations per task using Airbot Play teleoperation: 50 sets with no visual distraction, 30 sets with easy visual distraction, and 20 sets with hard visual distraction. The different levels of visual distraction are illustrated in Figure \ref{fig:visual_distraction}. A summary of the task setup for Imit Diff is provided in Table \ref{tab:task_summary}.

%1) Stack blocks in order。The Airbot Play Arm 按照顺序把三个不同颜色的积木搭在一起。两次堆叠都需要细粒度的对齐信息来保证三块积木都不滑落。我们设计这个任务来 evaluate Imit Diff 在 stack 类 manipulation 和 long horizon task 上的 performance。

\begin{enumerate}

\item \textbf{Stack blocks in order (Stack Blocks).} In this task, the Airbot Play Arm is required to stack three blocks of different colors in a specific order. The stacking operations demand precise alignment to ensure that the blocks do not fall off. This task is designed to assess Imit Diff's performance on stack manipulation and long-horizon tasks, where fine-grained visual information is crucial for maintaining stability during the manipulation process.

%2) Cover white lid on red glue。In this task，the Airbot Play Arm 需要首先抓取 white lid 然后把它盖在 red glue 上。我们设计这个任务来 evaluate Imit Diff 在 insert 类 manipulation 的 performance。

\item \textbf{Cover white lid on red glue (Cover Glue).} In this task, the Airbot Play Arm is required to first grab the white lid and then place it onto the red glue. This task is designed to evaluate Imit Diff's performance in insertion-based manipulation, where precise alignment and control are essential for successfully completing the task.

%3) Place jujube in bowl. In this task，the Airbot Play Arm 需要抓取枣子并把它放到碗里。枣子对抓取位置有细粒度要求，这个任务 evaluate 了 Imit Diff 在 place & grasp 类 manipulation 上的performance。

\item \textbf{Place jujube in bowl (Jujube Place).} In this task, the Airbot Play Arm is required to grab a jujube and place it in a bowl. The task has fine-grained requirements for the grasping position of the jujube to ensure proper placement. This task evaluates Imit Diff's performance in place-and-grasp manipulation, where precision in both the grasping and placement stages is critical.

%4) Place block in drawer。The Airbot Play Arm 首先打开抽屉，然后夹取方块并把它放置在抽屉里。我们通过任务来评价 Imit Diff 在操作铰链类 manipulation fine 任务上的 performance。

\item \textbf{Place block in drawer (Drawer Place). }In this task, the Airbot Play Arm is required to first open the drawer, then grab the block and place it inside. This task is designed to evaluate Imit Diff's performance on fine manipulation tasks involving the operation of hinges.

\end{enumerate}

% For each trained policy, we report average success rates on the policy checkpoint (selected using action mean-squared error). For success rates, we average over 25 trials per situation. Starting positions are rondomized between trials for each task。

\textbf{Metrics: }For each trained policy, we report average success rates on the policy checkpoint (selected using action mean-squared error). For success rates, we average over 25 trials per situation. Starting positions are rondomized between trials for each task.

\begin{table}[t]
\centering
\renewcommand{\arraystretch}{1.2}
\tabcolsep=0.035\linewidth
%我们为每个任务采集了 100 组 demonstrations，并以 32 的 action horizon 进行训练。机器人的感知和动作使用 6DoF arm 和 gripper 的关节空间位姿。
\caption{\textbf{A summary of task setup}, including \textbf{Stack Blocks}, \textbf{Cover Glue}, \textbf{Jujube Place} and \textbf{Drawer Place} four real-world tasks with different types of manipulation attributes. We collected 100 demonstrations for each task and trained the model with an action horizon of 32. The robot's perception and actions are based on the joint space poses of the 6DoF arm and gripper.}
\label{tab:task_summary}
\begin{tabular*}{\linewidth}{@{}ccccc@{}}
\toprule[1.2pt]
\multicolumn{5}{c}{\textbf{Real Robot Experiment (4 Tasks)}} \\ \midrule
\textbf{Task} & \textbf{Mani} & \textbf{ActH} & \textbf{\#Demo} & \textbf{Robo Perc} \\ \hline
Stack Blocks                     &     Stack           &   32   & 100     &      Joint     \\
Cover Glue                           &      Insert          &   32   &   100   &     Joint      \\
Jujube Place                &       Grasp \& Place         &   32   &    100  &     Joint      \\
Drawer Place                  &           Hingle     &   32   &   100   &     Joint      \\ 
\bottomrule[1.2pt]
\end{tabular*}
\end{table}

% % 插入 illustrations of all tasks 图
% % 
% \begin{figure*}[htbp]
%     \centering
%     \includegraphics[width=0.85\textwidth]{Figure/illustrations_of_all_tasks.pdf} 
%     % Illustrations of all taksk. We evaluate Imit Diff and baseline methods on four real-world tasks。Stack Blocks: (1) grasp the red block, (2) place the red block on the green one, (3) grasp the blue block and place it on the green one。Cover Glue: (1) grasp the white lid, (2) insert the white lid on the red glue。Jujube Place: (1) grasp the jujube, (2) place jujube in the bowl。Drawer Place: (1) Open the drawer, (2) place the red block into the drawer。
%     \caption{\textbf{Illustrations of all tasks.} We evaluate Imit Diff and baseline methods on four real-world tasks. \textbf{Stack Blocks: }(1) grasp the red block, (2) place the red block on the green one, (3) grasp the blue block and place it on the green one. \textbf{Cover Glue: }(1) grasp the white lid, (2) insert the white lid onto the red glue. \textbf{Jujube Place: }(1) grasp the jujube, (2) place jujube in the bowl. \textbf{Drawer Place: }(1) Open the drawer, (2)  place the red block into the drawer.}
%     \label{fig:illustrations_of_all_tasks}
% \end{figure*}


%插入 visual distraction图

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\textwidth]{Figure/visual_distraction.pdf} 
    %illustrations of visual distractions level. Imit Diff can adeptly handle diverse real-world visual scenarios from no distraction to hard distraction.
    \caption{\textbf{Illustrations of visual distractions level. }Imit Diff can adeptly handle diverse real-world visual scenarios from no distraction to hard distraction.}
    \label{fig:visual_distraction}
\end{figure*}

\begin{table*}[t]
\centering
\renewcommand{\arraystretch}{1.2}
\tabcolsep=0.02\linewidth
% Main results for real robot experiments on Imit Diff and baselines. Each task is evaluated with 25 trials. 因为多尺度细粒度的视觉特征和显式的语义掩码注入，Imit Diff 对任务物体有强烈的 knowaware，outperforms 其他 baseline 方法。
\caption{\textbf{Main Results for Real Robot Experiments on Imit Diff and Baselines. }Each task is evaluated with 25 trials. Due to the integration of multi-scale fine-grained visual features and explicit semantic mask injection, Imit Diff demonstrates a strong knowaware of task objects and consistently outperforms other baseline methods in all evaluated tasks.}
\label{tab:real_world_experiment}
\begin{tabular*}{\textwidth}{@{}c|ccc|ccc|ccc|ccc@{}} 
\toprule[1.2pt]
\multirow{2}{*}{\makecell{\textbf{Algorithm / Task}}} & \multicolumn{3}{c|}{\textbf{Stack Blocks}} & \multicolumn{3}{c|}{\textbf{Cover Glue}} & \multicolumn{3}{c|}{\textbf{Jujube Place}} & \multicolumn{3}{c}{\textbf{Drawer Place}} \\ 
\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13}
 & {Clean} & {Easy} & {Hard} & {Clean} & {Easy} & {Hard} & {Clean} & {Easy} & {Hard} & {Clean} & {Easy} & {Hard} \\ \midrule
\textbf{Imit Diff}                    & \textbf{0.80}   & \textbf{0.80}     & \textbf{0.72}    & \textbf{0.96}   & \textbf{0.96}     & \textbf{0.88}      & \textbf{0.96}   & \textbf{0.96}     & \textbf{0.92}    & \textbf{0.88}   & \textbf{0.88}     & \textbf{0.84}      \\
DP (transformer)                       & 0.44   & 0.20     & 0      & 0.32   & 0.16     & 0      & 0.48   & 0.20     & 0      & 0.56   & 0.32     & 0      \\
DP (U-Net)                     & 0.40   & 0.20    & 0      & 0.32   & 0.24     & 0      & 0.52   & 0.20    & 0      & 0.56   & 0.32     & 0      \\
ACT                     & 0.60   & 0.32     & 0      & 0.76   & 0.44     & 0      & 0.64   & 0.40     & 0      & 0.76   & 0.52     & 0      \\ 
\bottomrule[1.2pt]
\end{tabular*}
\end{table*}

\begin{table*}[t]
\centering
\renewcommand{\arraystretch}{1.4}
\tabcolsep=0.018\linewidth
% Ablation study on components of Imit Diff.
%我们选择 Drawer Place 作为消融实验任务。Multi Scale 代表了是否构建 FPN 提取并融合高分辨率视觉特征图的多尺度信息。Model-Base 代表了模型的预训练权重。这里 CLIP-Pretrained 表示低分辨率编码器为 CLIP-Pretrained ViT-B，高分辨率编码器为 LAION-Pretrained ConvNext-B。DINO-Pretrained 表示低分辨率编码器为 DINO-Pretrained ViT-B，高分辨率编码器为 ConvNext-B。
\caption{\textbf{Ablation study on components of Imit Diff. }We choose Cover Glue as the task for the ablation experiments. The term Multi-Scale indicates whether an FPN (Feature Pyramid Network) is used to extract and fuse multi-scale information from high res visual feature maps. Model-Base refers to the pretrained weights used in the model. Specifically, CLIP-Pretrained means that the low res encoder is a CLIP-Pretrained ViT-B \citep{caron2021emerging}, while the high res encoder is a LAION-Pretrained ConvNext-B. On the other hand, DINO-Pretrained means the low res encoder is a DINO-Pretrained ViT-B, and the high res encoder is ConvNext-B.}
\label{tab:ablation}
\begin{tabular*}{\linewidth}{@{}ccccccccc@{}} 
\toprule[1.2pt]
\textbf{Low Res} & \textbf{High Res} & \textbf{Multi Scale} & \textbf{Semanstic Mask} & \textbf{Model-Base} & \textbf{No Distraction} & \textbf{Easy Distraction} & \textbf{Hard Distraction} \\ \hline
      \checkmark         &          \checkmark        &   \checkmark   &   \checkmark  &     CLIP-Pretrained       &       \textbf{0.96}       &   \textbf{0.96}    & \textbf{0.88}      \\
       \checkmark        &       \checkmark           &      &    \checkmark  &     CLIP-Pretrained       &      0.56          &   0.56   &   0.40   \\
        \checkmark       &        \checkmark          &   \checkmark   &      &      CLIP-Pretrained      &       0.88         &  0.60    &   0.12   \\
        \checkmark       &                  &      &  \checkmark    &     CLIP-Pretrained       &      0.32          &   0.32   &   0.24   \\ 
        \checkmark       &        \checkmark          &   \checkmark   &  \checkmark    &     DINO-Pretrained       &       0.96         &   0.92   & 0.88     \\ 
\bottomrule[1.2pt]
\end{tabular*}
\end{table*}



\subsection{Baselines and Experiment Results}

% We benchmark Imit Diff against 先进的 imitation learning polices that have shown significant success in complex robot tasks。具体来说，我们使用 Action Chunking Transformer (ACT) 作为 auto-regression 和 CVAE 类 baseline model，使用 Diffusion Policy (DP) 代表 diffusion 类 baseline model。对于 ACT，我们保持与 original implementations 相同的 setup，使用分辨率为 480x640 的图像作为原始输入。对于 DP，我们为 global camera view 和 wrist camera view 分别分配一个独立的 CLIP-pretrained ViT-B encoder 并微调它们，来保持与 Imit Diff vision encoder 公平的参数量。我们 evaluate DP based on both U-Net and transformer architecture, and for DiT we simply 不适用 feature aggregation，保持和 Imit Diff 中类似的完整的 token sequence conditioning。 

% % 插入illustrations of all tasks图
% % 
% \begin{figure*}[htbp]
%     \centering
%     \includegraphics[width=\textwidth]{Figure/illustrations_of_all_tasks.pdf} 
%     \caption{}
%     \label{fig:illustrations_of_all_tasks}
% \end{figure*}


\textbf{Baselines: }We benchmark Imit Diff against state-of-the-art imitation learning policies that have demonstrated significant success in complex robot tasks. Specifically, we use Action Chunking Transformer (ACT) as the baseline model for auto-regression and CVAE, and Diffusion Policy (DP) as the baseline model for diffusion. We use the same action prediction horizon for ACT, DP, and Imit Diff. For ACT, we retain the original setup, using images with a resolution of 480$\times$640 (compared to 448$\times$448 for high res and 224$\times$224 for low res in Imit Diff) as the input. For DP, we assign separate CLIP-pretrained ViT-B encoders for both global camera view and wrist camera view, fine-tuning them to ensure the parameter size is consistent with the Imit Diff vision encoder. We evaluate DP based on both U-Net and transformer architectures. For DiT, we omit feature aggregation and maintain full token sequence conditioning, similar to the setup in Imit Diff. We also note that, on the 4060 Ti GPU, the 100-step DDPM variant of DP has an unaffordable inference time per forward pass. Thus we choose the faster and more realistic DDiM, which uses 16 steps for policy inference.

%我们对四个现实世界任务在如图 6 所示的三种不同程度的视觉干扰上进行实验。实验结果如表 II 所示，Imit Diff significantly outperforms 其他三种 baseline models，尤其是在复杂的场景和强烈的视觉干扰下。这是因为，受益于 Dual Res Fusion Module described in Section 3.2，Imit Diff 具有提取多尺度的细粒度视觉特征的能力。As 在 Section 3.1 中的描述，Imit Diff 从 pixel-level Semanstic Injection 中学习到了任务物体的鲜明 knowaware。这使得 Imit Diff 能够很好地处理复杂场景中地视觉信息，并屏蔽无关杂物的干扰。
\textbf{Experiment Results: }We conduct experiments on four real-world tasks with three different levels of visual distraction as shown in Figure \ref{fig:visual_distraction}. The experimental results are summarized in Table \ref{tab:real_world_experiment}. Imit Diff significantly outperforms the three baseline models, particularly in complex scenes with strong visual distraction.This improvement is attributed to the Dual Res Fusion Module described in Section \ref{Dual Res Fusion}, which enables Imit Diff to extract multi-scale, fine-grained visual features. Additionally, as discussed in Section \ref{Semanstic Injection}, Imit Diff learns distinct task object knowaware through pixel-level Semanstic Injection,  allowing it to effectively handle visual information in complex scenes and mitigate distraction from irrelevant clutter.



%我们选择 Drawer Place 作为 ablation study 的参考实验。实验结果如表 III 所示，ablation study 证明了 Imit Diff 中各组件的有效性。我们使用了包括 CLIP 和 DINO 在内的两种不同预训练权重模型取得了较好的结果。这证明了Imit Diff 框架的可迁移性。We also 统计了不同去噪框架的推理时间，noting that 由于 vision foundation models inference 对 CUDA 的占用，EDM 耗时 1.6s，consistency on DiT action head (Sec 3.3) 耗时 0.15s。

\subsection{Ablation Study}

We choose Cover Glue as the reference task for the ablation study. The experimental results are presented in Table \ref{tab:ablation}. The ablation study demonstrates the effectiveness of each component in Imit Diff. We utilize two different pretrained weight models, CLIP and DINO, to achieve the same effective performance, highlighting the transferability of the Imit Diff framework. Additionally, we measured the inference time of different denoising frameworks. We note that due to the occupancy of CUDA by vision foundation models' inference, EDM takes 1.6s, while the consistency mechanism in the DiT action head (Section \ref{Consistency Policy with DiT Architecture}) reduces inference time to 0.15s.



\subsection{Zero-shot Generalization Experiment}

% 我们在 Drawer Place 任务上采集了 100 组没有视觉干扰的数据。我们希望验证 Imit Diff 在 zero-shot 情况下对 visual distraction 的鲁棒性。TABLE IV 展示了 Imit Diff 对比其他 baseline 方法在 visual distraction zero-shot 情况下的鲁棒性。 
\textbf{Distraction Zero-shot Experiment.} We collected 100 episodes of data without visual distraction for the Drawer Place task. The goal is to evaluate the robustness of Imit Diff to visual distraction in a zero-shot setting. Table \ref{tab:distracion_zero_shot} presents the comparison of Imit Diff with other baseline methods, demonstrating its superior robustness in handling visual distraction in the zero-shot case.

% 类似于之前 distraction zero-shot experiment，我们在 Drawer Place 任务上采集了 100 组没有视觉干扰的数据，并改变任务物体的 appearance and category as shown in Figure 7. 实验结果展示在 Table V 中，Imit Diff 依靠 vision foundation models 获取的显式细粒度语义观测和双分辨率视觉增强框架，获得了更优秀的object appearance and category 泛化能力。
\textbf{Appearance \& Category Generalization Zero-shot Experiment. }Similar to the zero-shot visual distraction experiment, we collected 100 episodes of data without visual distraction for the Drawer Place task. this time we altered the appearance and category of the task objects, as shown in Figure \ref{fig:category_generalization}. The experimental results are presented in Table \ref{tab:category_zero_shot}. Imit Diff leverages the explicit fine-grained semantic observations provided by the vision foundation models and the dual res visual enhancement framework, enabling it to achieve superior object appearance and category generalization capabilities.

% 插入 category generalization 图
% 
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.4\textwidth]{Figure/category_generalization.pdf} 
    \caption{\textbf{Objects appearance and category generalizartion of Drawer Place.}}
    \label{fig:category_generalization}
\end{figure}

\begin{table}[t]
\centering
\renewcommand{\arraystretch}{1.2}
\tabcolsep=0.018\linewidth
% We arrange over 10 trials per situation。Imit Diff outperforms baseline models under visual distraction. We note that ACT performs better than DP models due to the z style trained with CVAE.
\caption{\textbf{Visual Distraction Zero-shot. }We arrange over 10 trials per situation. Imit Diff outperforms baseline models under visual distraction. We note that ACT performs better than DP models due to the $z$ style trained with CVAE.}
\label{tab:distracion_zero_shot}
\begin{tabular*}{\linewidth}{@{}cccc@{}}
\toprule[1.2pt]
\textbf{Algorithm / Task} & \textbf{No Distraction} & \textbf{Easy Distraction} & \textbf{Hard Distraction} \\ \hline
Imit diff                     &        \textbf{0.9}        &  \textbf{0.9}    &   \textbf{0.7}   \\
ACT                           &         0.8       &   0.3   &   0   \\
DP (transfomer)                &         0.6       &   0   &   0  \\
DP (U-net)                     &          0.6      &    0  &   0   \\ 

\bottomrule[1.2pt]
\end{tabular*}
\end{table}

\begin{table}[t]
\centering
\renewcommand{\arraystretch}{1.2}
\tabcolsep=0.018\linewidth
% 我们改变 Drawer Place 中 task objects 的 appearance 和 category。其中，Appearance Grasp 和 Category Grasp 代表改变抓取物体的 appearance 和 category。Appearance Drawer 表示改变 drawer 的 appearance。
\caption{\textbf{Appearance \& Category Generalizaion Zero-shot. }We modify the appearance and category of task objects in the Drawer Place environment. Specifically, Appear Grasp and Category Grasp refer to altering the appearance and category of the object to be grasped. Appear Drawer denotes changing the appearance of the drawer.}
\label{tab:category_zero_shot}
\begin{tabular*}{\linewidth}{@{}cccc@{}}
\toprule[1.2pt]
\textbf{Algorithm / Task} & \textbf{Appear Grasp} & \textbf{Category Grasp} & \textbf{Appear Drawer} \\ \hline
Imit diff                     &        \textbf{0.8}        &  \textbf{0.7}    &   \textbf{1.0}   \\
ACT                           &         0.5       &   0.3   &   0.8   \\
DP (transfomer)                &         0.5       &   0.3   &   0.6  \\
DP (U-net)                     &          0.5      &    0.2  &   0.6   \\ 

\bottomrule[1.2pt]
\end{tabular*}
\end{table}