\section{Introduction}

\ac{BFT} consensus protocols enable distributed systems that can tolerate arbitrary failures, making them a critical component for blockchain systems that distribute trust among participants that validate transactions and maintain the ledger.
Therefore, to reduce reliance on a few participants and bolster security, scaling BFT protocols beyond their traditional capacity~\cite{pbft, zyzzyva} has become crucial.

Numerous studies have tackled the scalability challenges using various optimization strategies effective under specific favorable conditions~\cite{sbft, algorand, tendermint, kauri, mirbft}.
However, in adverse scenarios, these optimizations become less effective or even defunct, necessitating a switch~\cite{Abstract, adapt} to a more resilient but less effective protocol, like PBFT~\cite{pbft}, to make progress.
It is, however, non-trivial to detect whether or not the operating conditions are favorable or adversarial.
Existing work utilizes inefficient techniques based on randomness~\cite{algorand, kauri, mytumbler} or predefined assignments~\cite{mirbft}, requiring repeated trial-and-error to find a working system configuration.
These systems often ignore the actual operating conditions, such as the latency between replicas and prior misbehavior, resulting in poor performance.
Many systems~\cite{bft-smart,local1,local2,local3,local4} that consider the operating conditions rely only on local measurements to select a system configuration.
This is problematic because local measurements across the replicas may be inconsistent, making it challenging to make global configuration decisions.
Similarly, there is a lack of transparency and trust if a single replica, e.g., the leader, can make such decisions based only on its local measurements since it is impossible to verify that the decision was based on actual measurements.

This paper advocates for a holistic, measurement-based approach to accurately identify the current operating conditions, promoting aggressive use of efficient protocols and reducing fallback to less efficient ones.
We accomplish this through a shared append-only log of measurements.

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{images/OptiLog.pdf}
  \caption{\sysname's component architecture.}
  \Description{Diagram showing the architecture of \sysname, including the sensor application, sensors and monitors.}
  \label{fig:arch}
\end{figure}

We describe \sysname, an integrated shared log for recording various metrics and computing efficient system configurations from these metrics.
\sysname extends a generic \ac{RSM} with sensors and monitors to capture and evaluate different metrics.
Individual replicas instrumented with sensors record measurements in the log, and corresponding monitors at replicas collate these measurements to derive \textit{efficient configurations}.
\sysname enables replicas to make consistent configuration decisions based on the same information.
The log also provides transparency, allowing all replicas to verify decisions and recognize faulty behaviors.
\cref{fig:arch} illustrates \sysname's architecture; see \cref{sec:optiblogarch} for a detailed description.

Moreover, some optimization techniques can be costly to (deterministically) evaluate for large configuration sizes.
Thus, \sysname allows heuristic optimization techniques to be used, where the resulting non-deterministic configurations are logged, such that the replicas can consistently determine a global ranking of configurations.
\sysname also supports collaborative optimization techniques where the search space is partitioned and distributed across the \ac{RSM} replicas.

To showcase \sysname's effectiveness, we focus on BFT systems~\cite{kauri, omniledger, byzcoin} that organize their RSM replicas in a tree topology for improved scalability.
A tree topology reduces communication overhead by limiting interactions to parent and child replicas.
However, this structure is vulnerable to failures, which can fragment the network.
To counter this, tree-based protocols require fallback and reconfiguration mechanisms.
Kauri~\cite{kauri}, for example, builds multiple randomized trees to prevent targeted attacks, switching to a new tree when failures occur.
However, this approach can cause considerable delays in reaching consensus due to the number of reconfigurations needed to find a working tree.
Moreover, blindly constructing trees based on randomness can result in latency-imbalanced trees that degrade the RSM's performance.
Ideally, trees should be constructed with reliable replicas at the core and less reliable ones at the leaves.

Our second contribution, \optitree, is a novel RSM optimization strategy that leverages \sysname to collect metrics based on historical system behavior and performance.
\optitree is a heuristic tree selection algorithm designed to create low-latency trees while excluding faulty replicas from the tree's core.
Each replica uses simulated annealing~\cite{simulatedannealing} to search for a low-latency tree.
Since simulated annealing is non-deterministic, the resulting trees are recorded in the log.
From this logged data, replicas can deterministically select the tree with the lowest cumulative latency.
\optitree can reconfigure the RSM until a working tree is found, while recording the measurements in the log.
This approach is guaranteed to find a working tree within at most 2\f reconfigurations for certain tree configurations, where \f is the maximum number of faulty replicas.

The main contributions of this paper are:
%\vspace{-0.1cm}
\begin{enumerate}
  \item \sysname, a logging framework for systematic metrics collection and configuration optimization for RSMs.
  \item \sysname enables RSM optimizations to compute heuristic configurations while maintaining accountability.
  \item \optitree uses \sysname to generate low-latency working trees with linear reconfigurations.
\end{enumerate}
