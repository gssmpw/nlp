\begin{table}[!t]\centering
    \scriptsize
    %
    \caption{Configurations of our ViT models and associated pretraining costs. GPU-hours describes the number of GPU-hours required to pretrain each model for $500$ epochs on an H100 GPU.}
    \label{tab:size_cost}
    % \setlength{\tabcolsep}{2pt}
    % \resizebox{\linewidth}{!}{\begin{tabular}{lccccc}
    {\begin{tabular}{lccccc}
       architecture & blocks & dim & heads & params & GPU-hours \\
         \toprule
         ViT-Nano & 4 & 128 & 8 & 0.8M & 200 \\
         % ViT-Tiny \cite{touvron2022deit} & 12 & 192 & 3 & 5.3M & 259 \\
         % ViT-Base \cite{dosovitskiy2021an} & 12 & 768 & 12 & 85M & 573 \\
         ViT-Tiny & 12 & 192 & 3 & 5.3M & 259 \\
         ViT-Base & 12 & 768 & 12 & 85.0M & 573 \\
    \end{tabular}}
\end{table}
