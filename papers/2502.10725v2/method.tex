\section{Methods}

% Method
% (1) split: split into propositions
% (2) parse: extract core tokens
% (3) represent: build a hierarchical net
% (4) merge: merge representations

\begin{table*}[h!]
\centering
\small 
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{@{}>{\raggedright\arraybackslash}p{2.5cm}>{\raggedright\arraybackslash}p{2.8cm}>{\raggedright\arraybackslash}p{9cm}@{}}
\toprule
\textbf{Clause Type} & \textbf{Primary Rule} & \textbf{Example} \\ \midrule
Conjunct & token.dep\_ == \texttt{conj} & I am singing and \textbf{playing} a guitar. -> (I am singing, I be playing a guitar) \\
\midrule
Clausal Complement & token.dep\_ == \texttt{ccomp} & She thinks this \textbf{is} a good idea. -> (she thinks \texttt{identifier\_ccomp}, this is a good idea) \\
\midrule
Adnominal Clause & token.dep\_ ==  \texttt{acl} & A cat \textbf{sitting} on sand looks up at the camera. -> (a cat looks up at the camera, cat be sitting on sand) \\
\midrule
Prepositional Complement & token.dep\_ == \texttt{pcomp} & He goes to school by \textbf{taking} a bus. -> (he goes to school by \texttt{identifier\_pcomp}, he be taking a bus) \\
\midrule
Adverbial Clause & token.dep\_ == \texttt{advcl} & Although it is \textbf{raining}, we will go to a garden. -> (we will go to a garden, it is raining) \\
\midrule
Open Clausal Complement & token.dep\_ == \texttt{xcomp} & He is going to \textbf{swim}. -> (he is going to \texttt{xcomp\_identifier}, he swim) \\
\midrule
Subject Clause & token.dep\_ == \texttt{csubj} & \textbf{Adding} aspirin to the water could kill the plant. -> (\texttt{identifier\_csubj} could kill the plant, adding aspirin to the water) \\
\midrule
Relative Clause & token.dep\_ == \texttt{relcl} & They like the person who \textbf{lives} in the street. -> (They like the person, person lives in the street) \\ 
\bottomrule
\end{tabular}
\caption{Splitting rules for a \texttt{Prop2} sentence according to its clause types. The condition \texttt{token.pos\_ in (\texttt{VERB},\texttt{AUX})} is also required for all rules. We omit it to improve the clarity of the table. The examples follow the format: Input Sentence -> (Main Proposition, Subordinate Proposition). The bold text in an example is the extracted verb token for the subordinate clause. Note that \texttt{identifier\_ccomp}, \texttt{identifier\_pcomp}, \texttt{xcomp\_identifier} and \texttt{identifier\_csubj} serve as placeholders for the relevant clauses.  
} 
\label{tab:splitting_rules_cs2v}
\end{table*}

The PropNet model comprises four key components: splitting, parsing, representing, and merging. Specifically, the splitting and parsing processes  correspond to activities occurring in short-term memory, whereas the representing and merging processes align with those in long-term memory. Subsequently, we introduce a method for comparing two sentence representations, which generates a difference vector as output.

The following symbols are used to represent different types of sentences based on the number of verbs they contain:

\begin{itemize}
    \item \texttt{Prop0}: Sentences with 0 verbs, e.g., ``A ball on the ground.''
    \item \texttt{Prop1}: Sentences with 1 verb, e.g., ``A boy is playing football.''
    \item \texttt{Prop2}: Sentences with 2 verbs, e.g., ``A boy is playing football and a girl is dancing.''
    \item \texttt{Prop3+}: Sentences with more than 2 verbs, e.g., ``A man is sitting in a chair, wearing a cloak, and holding a stick.''
\end{itemize}

Here the term "verb" encompasses linking verbs. For instance, in the sentences "a boy is in a park" or "a girl is happy," the word "is" is treated as a verb, and both sentences are categorized as \texttt{Prop1}. In the rest of this work, a proposition refers to a \texttt{Prop1} or \texttt{Prop0} sentence.


We introduce the following notations to classify sentence pairs based on sentence types:

\begin{itemize}
    \item \texttt{P1-} denotes the set of pairs where both sentences are \texttt{Prop0} or \texttt{Prop1}.
    \item \texttt{P2} represents the set of pairs that contain at least one \texttt{Prop2}, excluding pairs with any \texttt{Prop3}. For instance, a \texttt{Prop1} and a \texttt{Prop2} sentence, or two \texttt{Prop2} sentences. 
    \item \texttt{P3+} indicates the set of pairs that includes at least one \texttt{Prop3} sentence.
\end{itemize}

\subsection{Splitting}

\begin{figure*}[h!]
  \includegraphics[width=1\textwidth]{split_and_merge_cs_plus3v.png}
  \caption{Splitting a \texttt{Prop3+} sentence and merging its proposition representations by backtracking. At each splitting step, the method for splitting \texttt{Prop2} is called. The extracted proposition invokes the representation component to build a hierarchical network. During the upward traversal, the same strategies for merging \texttt{P2}---denoted by green, grey, and purple arrows---are employed to integrate all networks into a unified network. Note that \texttt{identifier\_advcl} is a placeholder for an adverbial clause.}
  \label{fig:split_and_merge_cs_plus3v}
\end{figure*}


For \texttt{Prop0} and \texttt{Prop1}, splitting is unnecessary. At this stage, the input sentence itself serves as the output proposition. For \texttt{Prop2}, split the input sentence into two \texttt{Prop1} propositions, a main proposition (main clause) and a subordinate proposition (subordinate clause). Table~\ref{tab:splitting_rules_cs2v} presents the splitting rules for different clause types. These rules extract the verb token of the subordinate clause. Then the subordinate clause is generated by iterating over the verb token's subtree provided by spaCy parsing tool \footnote{For more details, see the spaCy documentation: \url{https://spacy.io/usage/linguistic-features/\#pos-tagging}}. For instance, in the \texttt{Prop2} sentence ``She thinks this is a good idea'', the splitting rules identify ``is'' as the verb token for the subordinate clause. The token ``is'' owns a subtree ``this is a good idea'' by dependency parsing. 

% We set clause identifiers to record relations between propositions. In the above example, the main clause becomes ``She thinks \texttt{identifier\_ccomp}'' where \texttt{identifier\_ccomp} points to ``this is a good idea''. The recorded relations are crucial for merging proposition representations into a unified network.

The generated subordinate clause is then replaced by a clause identifier in the input sentence for five clause types \texttt{Clausal Complement}, \texttt{Prepositional Complement}, \texttt{Open Clausal Complement}, \texttt{Subject Clause} and \texttt{Adverbial Clause}. Their identifiers are notated as \texttt{identifier\_ccomp}, \texttt{identifier\_pcomp}, \texttt{xcomp\_identifier}, \texttt{identifier\_csubj} and \texttt{identifier\_advcl}, respectively. For other clause types, the subordinate clause is replaced by an empty string. When the replacement is completed, the rest of the input sentence becomes the main proposition. Table~\ref{tab:splitting_rules_cs2v} presents examples for each clause type. Note that \texttt{identifier\_advcl} is applied only when the clause is preceded by the word ``to'' that indicates the purpose of an action. Figure~\ref{fig:split_and_merge_cs_plus3v} provides an example for this specific situation. 

Clause identifiers are crucial for merging proposition representations into a unified network. In the above example, the main proposition is ``She thinks \texttt{identifier\_ccomp}'' where \texttt{identifier\_ccomp} would point to ``this is a good idea'' in the merging phase.

If the subordinate clause is non-finite, the subject of the main clause is spliced to it, forming a complete subordinate proposition. For instance, in ``she wants to dance'', the subordinate proposition ``she dance'' uses the subject of the main proposition ``she wants xcomp\_identifier''. If the subordinate clause is finite, no subject insertion is required since the clause already contains its own subject. The splitting rules for relative clause type are more intricate and are detailed in Appendix~\ref{app:propnet_relative_clause}.

Situation becomes significantly more complex for \texttt{Prop3+}. We employ a backtracking algorithm to decompose the input sentence into \texttt{Prop1} propositions by constructing a binary tree, as shown in Figure~\ref{fig:split_and_merge_cs_plus3v}. The splitting method for \texttt{Prop2} is invoked during each splitting step to extract a subordinate proposition \texttt{Prop1}, serving as the leaf node of the binary tree. Then the leaf node invokes the representation component to construct a hierarchical network, which is explained in Section~\ref{method:represent}.





\subsection{Parsing}
\label{method:parse}

\begin{table*}[h!]
	\footnotesize
	\centering 
    \small 
    \renewcommand{\arraystretch}{1.5}
	{
		\begin{tabular}{p{0.08\textwidth}|p{0.28\textwidth}|p{0.30\textwidth}|p{0.22\textwidth}}
			\toprule 
			\textbf{Dimension} & \textbf{Explanation} & \textbf{Primary Rule} & \textbf{Example}\\
            
			\midrule
			Action & An action described by the verb in a proposition. & token.pos\_ is \texttt{VERB} & The man is \textbf{riding} a horse. \\
            
			Subject * & An entity or concept that performs the action. & token.dep\_ is \texttt{nsubj} & The \textbf{man} is riding a horse. \\
            
            Object * & An entity or concept that receives the action. & token.dep\_ in (\texttt{dobj}, \texttt{nsubjpass}) & The man is riding a \textbf{horse}. \\		
            \midrule
            
            Where *	&The place where the action occurs, or the time when it occurs.	& preposition of token in ``on'', ``in'', ``inside'', ``outside'', ``at'', \ldots)	&The polar bear is sliding on the \textbf{snow}.	\\
            
            Aux\_Obj *	&The instrument or tool that is used to perform the action. Or indirect object which is the recipient, beneficiary, or target of an action.  	& preposition of token in (``with'', ``by'', ``about'', ``as'', \ldots)	&A person is cutting mushrooms with a \textbf{knife}.		\\	
            
            Goal *	&The intended outcome or objective that the subject aims to achieve by performing the action.	& preposition of token in (``into'', ``to'', ``onto'', ``towards'',\ldots)	&A man pours oil into a \textbf{pot}.\\
            
            Reason *	&The cause or motivation behind the action.	& preposition of token in (``for'', ``due'')	&The teacher praised her for her excellent \textbf{work}.		\\
            
            Source *	&The origin or starting point from which the action arises. 	&preposition of token in (``from'')	&She learned the news from her \textbf{friend}.		\\	
            \midrule
            
            Attribute	&The appearance, state, nature, or features of an entity or a concept.	&token.dep\_ in (\texttt{amod}, \texttt{nmod}, \texttt{compound}) 	&A \textbf{young} girl is using sign language.		\\														
            Part\_of	&One entity is a component or piece of another larger entity.	& An entity token of another entity token; token.dep\_ is \texttt{poss}	& Two men are packing suitcases into the trunk of a \textbf{car}.		\\															
			\bottomrule
		\end{tabular}
	}
    \caption{ Dimensions of parsing a \texttt{Prop1}/\texttt{Prop0} sentence. Dimensions \texttt{Attribute} and \texttt{Part\_of} are designed for an entity or concept. Others are related to the action in a proposition. Primary rules of extracting tokens are explained with examples. Note that token.pos\_ and token.dep\_ are the POS tagging and dependency parsing results from spaCy. The bold text in an example is the extracted token for its dimension. Dimensions marked with a ``*'' also follow this parsing rule \texttt{token.pos\_ in (\texttt{NOUN}, \texttt{PRON}, \texttt{PROPN}, \texttt{NUM})} which is omited in the table for brevity.
    % The primary rules to extract corresponding token of each dimension are listed. 
	} \label{tab:parsing_rules}	
\end{table*}


This phase extracts key tokens from a proposition with respect to specific dimensions. The intuition of designing these dimensions is that we require they can describe the meaning of a single action that happens in the real world, which is the key to understand the meaning of a complex sentence consisting of a series of actions. Therefore, eight critical dimensions related to the verb of a proposition are considered: \texttt{Action}, \texttt{Subject}, \texttt{Object}, \texttt{Where}, \texttt{Auxiliary\_Object}, \texttt{Goal}, \texttt{Reason}, \texttt{Source}. The extracted words under each dimension are either describing a physical entity like ``car'' or an abstractive concept like ``brand''. For these words, two additional dimensions \texttt{Attribute} and \texttt{Part\_of} are considered for the descriptions of them. Explanations for these dimensions and extracting primary rules \footnote{Because of the variety of language, even a \texttt{Prop1} sentence can have an extremely flexible structure. Therefore, minor rules are handcrafted for extraction which can be seen in the codes.} with examples are listed in Table~\ref{tab:parsing_rules}. The prepositions used by primary rules in the table are omitted for brevity. See Appendix~\ref{app:propnet_parse} for a detailed list of these prepositions. Extraction is implemented by resorting to spaCy part-of-speech tagging and dependency parsing tools \footnote{For more details, see the spaCy documentation: \url{https://spacy.io/usage/linguistic-features/\#pos-tagging}}.  

 
\subsection{Representing}
\label{method:represent}


\begin{figure*}[h!]
  \includegraphics[width=1\textwidth]{ss_repr_v2.pdf}
  \center
  \caption{(a) Six-level hierarchical structure of PropNet. (b) An example of representing the sentence ``A young man is playing an instrument in the garden''. Evolutionary nodes, developmental nodes, instance nodes and stamp nodes are labeled as red, orange, green and grey colors respectively.}
  \label{fig:ss1}
\end{figure*}

As brain's long-term memory stores information as a hierarchical network \citep{Collins1969RetrievalTF, Anderson1974RetrievalOP, Kintsch1974TheRO}, PropNet represents a proposition using a six-level hierarchical network. Figure~\ref{fig:ss1} (b) provides an example of how the sentence ``A young man is playing an instrument in the garden'' is represented. The network comprises three types of nodes: evolutionary nodes, developmental nodes and instance nodes which are represented as red, orange and green colors, respectively. In designing the network, we incorporate ideas similar to Nature Design and Nurture Beliefs , which are outlined in \citep{Yang2024AutomaticEO}. Evolutionary nodes correspond to Nature Design, which reflects human nature and is derived from heredity. They are denoted with a prefix ``\#'', like \texttt{\#action}. Each dimension in the parsing phase has a corresponding evolutionary node. Developmental nodes correspond to Nurture Beliefs, which are learned from experience, and are named with a prefix ``\_'', such as \texttt{\_young}. Each word in a sentence corresponds to a developmental node. 

An evolutionary node cannot directly establish a connection with a developmental node. This connection is fulfilled by an instance node. Each evolutionary node points to at least one instance node. Each instance node can point to only one developmental node. They have the following three types:

\begin{itemize}
    \item Entity instance nodes are linked to developmental nodes whose lexical content has a hypernym ``physical entity'', a relationship that can be ascertained using WordNet \citep{miller1995wordnet}. Entity instance nodes are denoted as \texttt{ins\_entity\_id}; for instance, \texttt{ins\_entity\_17}, which is linked to \texttt{\_man}.
    \item Concept instance nodes are linked to developmental nodes whose lexical content is not ``physical entity'', such as adjectives, pronouns, and numbers. These nodes are denoted as \texttt{ins\_concept\_id}; for example, \texttt{ins\_concept\_29}, which is connected to \texttt{\_young}.
    \item Action instance nodes are linked to developmental nodes that contain verbal lexical content and are labeled as \texttt{ins\_action\_id}. As an example, \texttt{ins\_action\_15} refers to \texttt{\_play}.
\end{itemize}


Figure~\ref{fig:ss1} (a) provides a more lucid depiction of the six-level hierarchical structure of PropNet. An action instance node functions as the root and triggers \texttt{\#action}. It also points to a developmental node \texttt{\_play}. This action instance node is unique because there is only one verb in a proposition. Edges from \texttt{\#action} connect evolutionary nodes \texttt{\#subject}, \texttt{\#object}, \texttt{\#where}, \texttt{\#aux\_obj}, \texttt{\#goal}, \texttt{\#source}, and \texttt{\#reason}, each of which corresponds to a parsing dimension described in Section~\ref{method:parse}. These nodes will establish connections with instance nodes that are created for the words parsed from each dimension. For example, \texttt{\#subject} points to \texttt{ins\_entity\_17}, which has a link with \texttt{\_man}. At level 4, these instance nodes activate two evolutionary nodes, \texttt{\#attr} and \texttt{\#part\_of}, which align with the parsing dimensions \texttt{Attribute} and \texttt{Part\_of} respectively. Similarly, \texttt{\#attr} and \texttt{\#part\_of} establish links with instance nodes created for the words parsed under \texttt{Attribute} and \texttt{Part\_of}. For instance, \texttt{ins\_entity\_17} points to \texttt{\#attr} and \texttt{\#attr} points to \texttt{\_young}.


\begin{table*}[h!]
\centering
\small
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{@{}p{2.5cm}p{6cm}p{6cm}@{}}
\toprule
\textbf{Strategy} & \textbf{Rule} & \textbf{Example} \\ \midrule
Merge Subjects & Merge the instance nodes with the same subject into a single instance node. & A \textbf{cat} sitting on sand looks up at the camera. $\rightarrow$ (a \textbf{cat} looks up at the camera, \textbf{cat} be sitting on sand) [Merge instance nodes of \textbf{cat}] \\

Link Clause Identifier to Action Stamp Node (ASN) & Establish links between the instance node of \texttt{identifier\_ccomp}, \texttt{identifier\_pcomp}, \texttt{xcomp\_identifier}, \texttt{identifier\_advcl} and \texttt{identifier\_csubj} in the MAIN and the ASN in the SUB. (MAIN: main proposition; SUB: subordinate proposition) & She thinks this is a good idea. $\rightarrow$ (she thinks identifier\_ccomp, this is a good idea) [Link the instance node of \textbf{identifier\_ccomp} to the ASN invoked by \textbf{is}] \\
Link Action Stamp Nodes (ASNs) by Time Node & 

\begin{itemize}[leftmargin=*,nosep,after=\strut]
    \item \textbf{MAIN Before SUB}: Link the ASN of MAIN to \texttt{\#time\_before}, and then link \texttt{\#time\_before} to the ASN of SUB;
    \item \textbf{MAIN After SUB}: Link the ASN of SUB to \texttt{\#time\_before}, and then link \texttt{\#time\_before} to the ASN of MAIN;
    \item \textbf{MAIN and SUB Occur Simultaneously}: Link \texttt{\#time\_same} to the ASNs of MAIN and SUB.
\end{itemize} &

The boy washes his hands before he has lunch. $\rightarrow$ (the boy washes his hands, he has lunch) [ASN invoked by \textbf{wash} -> \texttt{\#time\_before} -> ASN invoked by \textbf{has}] \\ \bottomrule
\end{tabular}
\caption{Merging Strategies for A \texttt{Prop2} Sentence}
\label{tab:merge_2v_cs}
\end{table*}


If during the parsing phase, no words are associated with a dimension, its corresponding evolutionary node will invoke an instance node that points to a default developmental node, \texttt{\_unknown}. This ensures the network remains complete even when some information is missing. In Figure~\ref{fig:ss1} (b), only \texttt{\#subject}, \texttt{\#object} and \texttt{\#where} have valid instance nodes, which point to \texttt{\_man}, \texttt{\_instrument} and \texttt{\_garden}, correspondingly. All other evolutionary nodes pointed to by \texttt{\#action}  are connected to instance nodes that point to \texttt{\_unknown}, which is marked by a purple box in the figure.


There's a fourth type of nodes, called stamp nodes, which can be distinguished by their grey color in Figure~\ref{fig:ss1} (b). The primary role of stamp nodes is to distinguish different parts of the network representing a complex sentence that consists of several propositions. An action stamp node is activated by an action instance node and named as \texttt{stamp\_action\_id}. It points to all entity or concept instance nodes associated with that action, thereby grouping them together and differentiating them from the entity or concept instance nodes of other actions. 

An entity stamp node is triggered by an entity instance node and named as \texttt{stamp\_entity\_id}. It points to all entity or concept instance nodes that describe the corresponding entity instance node. As shown by the blue box in the figure, \texttt{stamp\_entity\_32} points to \texttt{ins\_concept\_29}, aggregating the modifier ``young'' to the entity ``man''. 





\subsection{Merging}

When the main proposition and the subordinate proposition of a \texttt{Prop2} sentence are represented separately, we need to combine them to convey a complete and coherent meaning. We put forward three merging strategies, which are enumerated in Table~\ref{tab:merge_2v_cs}. If the subordinate proposition is a relative clause, a different merging strategy is adopted, which is presented in Appendix~\ref{app:propnet_relative_clause}. 

For a \texttt{Prop3+} sentence, the merging process corresponds to the upward backtracking process of splitting, illustrated in Figure~\ref{fig:split_and_merge_cs_plus3v}. The same strategies are applied as for \texttt{Prop2}. Appendix~\ref{app:propnet_cases} demonstrates the merging result of the sentence example in Figure~\ref{fig:split_and_merge_cs_plus3v}.



\subsection{Comparison of Two Sentence Representations}
\label{sec: diff_vec}


Given the PropNets of a pair of sentences, a natural consideration is how to compare the differences between the two networks. However, since the PropNet of a complex sentence can be extensive, containing a large number of nodes and edges, directly comparing two PropNets poses a significant challenge due to computational complexity. A more viable computational approach involves comparing the disparities in the representations of the corresponding propositions between the two sentences, and then aggregating these disparities into an overall signature difference. Thus, we initially introduce the method for comparing the differences between two propositions, which is previously presented as pair type \texttt{P1-}. Next, based on this foundation, we discuss the difference-construction methods for more complex pair types \texttt{P2} and \texttt{P3+}.

\begin{figure*}[h]
  \includegraphics[width=1\textwidth]{compare_module.pdf}
  \centering
  \caption{Framework of the comparison module. This module consists of two parts: difference vector computation and CART prediction. It is exemplified by the pair ``The tall man is playing the delicate piano'' and ``The short man is playing the delicate guitar''. They differ at \texttt{\#action|\#subject|\#attr} and \texttt{\#action|\#object}, which are marked with elements 2 and 1 at the corresponding positions in the difference vector. The codes 0, 1, 2 represent ``identical'', ``similar'' and ``different'', respectively. Note that the difference vector for \texttt{P1-} is padded with 0, doubling its size, before it enters the corresponding CART model.}
  \label{fig:compare_module}
\end{figure*}

\subsubsection{Pair Type \texttt{P1-}}
\label{pair_type_p1}

The comparison dimensions are formed by the Cartesian product of \{\texttt{\#subject}, \texttt{\#object}, \texttt{\#where}, \texttt{\#aux\_obj}, \texttt{\#goal}, \texttt{\#source}, \texttt{\#reason}\} and \{$1$, \texttt{\#attr}, \texttt{\#part\_of}\}, further extended by \{\texttt{\#action}, \texttt{\#action|\#subject|\#where}, \texttt{\#action|\#object|\#where}\}. For example, the dimension \texttt{\#action|\#subject|\#attr} represents the attribute of an entity or concept that serves as the subject within the action. The reason of using the names of evolutionary nodes is this way of naming can reveals the route to locate the corresponding entity or concept instance nodes within the graph of PropNet. The explanations of all these 24 dimensions are provided in Appendix~\ref{sec:compare_dim}. 

By comparing the developmental nodes indicated by the dimensional instance nodes, we obtain a similarity code for each dimension. Concatenating these codes in sequence produces a difference vector $\mathbf{v_1}$. The similarity code primarily takes three values: 0 for identical, 1 for similar, 2 for different. A large language model (LLM) acts as the knowledge base to compute the similarity degree between two words. This strategy is word-level based, ignoring context-dependent meanings, e.g. polysemous words. Identification of the gloss that a word uses given a context is left in future work. Details on LLM prompts, additional similarity codes, and examples for each code are provided in Appendix~\ref{app:similar_code}.

Figure~\ref{fig:compare_module} illustrates how to calculate a difference vector given the representations of two sentences ``The tall man is playing the delicate piano'' and ``The short man is playing the delicate guitar''. Purple boxes identify the concept instance nodes under \texttt{\#action|\#subject|\#attr} with two different developmental nodes \texttt{\_tall} and \texttt{\_short}. Blue boxes identify the entity instance nodes under \texttt{\#action|\#object} with two different developmental nodes \texttt{\_piano} and \texttt{\_guitar}. The instance nodes of other dimensions have exactly the same developmental nodes. Since \texttt{\_tall} and \texttt{\_short} are judged as different by LLM, \texttt{\#action|\#subject|\#attr} contributes a code of 2 to the difference vector. As \texttt{\_piano} and \texttt{\_guitar} is judged as similar by LLM, \texttt{\#action|\#object} contributes a code of 1 to the difference vector. 


\subsubsection{Pair Type \texttt{P2}}
Assume the first sentence \texttt{s1} of the pair being compared can be split into two propositions, \texttt{pp1} and \texttt{pp2}. If the second sentence \texttt{s2} is \texttt{Prop0} or \texttt{Prop1}, the following alignment process is applied. If two propositions share identical subjects and actions, they are considered to have a significant overlap. This criterion can be evaluated by examining the specific elements \texttt{\#action} and \texttt{\#action|\#subject} of the difference vector. For a fair comparison, we align \texttt{s2} to the proposition that exhibits a significant overlap with it. Subsequently, we utilize the difference vector associated with this alignment. This vector is then padded with 2 until it attains a length twice that of the original, resulting in the final output $\mathbf{v_2}$. Padding with 2 implies \texttt{s2} lacks a corresponding component to compare with the other proposition of \texttt{s1}.

We illustrate the alignment process by comparing ``I like apple'' and ``She likes orange and I like banana''. ``She likes orange and I like banana'' is split into ``She likes orange'' and ``I like banana''. According to the order of appearance, we would compare ``She likes orange'' and ``I like apple'', which is not a fair comparison. By implementing the alignment process, ``I like banana'' and ``I like apple'' are compared, while ``She likes orange'' has no counterpart for comparison.

If the second sentence \texttt{s2} is \texttt{Prop2}, a similar alignment process is applied, but without padding. For example, in the pair ``I like apple and she likes pineapple'' and ``She likes orange and I like banana'', the proposition ``I like apple'' aligns with ``I like banana'', and ``she likes pineapple'' aligns with ``she likes orange''.



\subsubsection{Pair Type \texttt{P3+}}
As a \texttt{Prop3+} sentence can contain multiple propositions, we estrict our consideration to its first four propositions in the order of appearance.
Therefore, the difference vector $\mathbf{v_3}$ for \texttt{P3+} has a size that is twice the length of $\mathbf{v_2}$ for \texttt{P2}. We calculate the overlap degree as the number of overlapping words between two propositions. The alignment strategy involves iterating through all the propositions of the first and second sentences, and then choose the pair with the maximum overlap degree. After that, we remove the selected propositions from the list and continue to apply the aligning strategy to the remaining propositions until the maximum overlap degree is zero.

Let's exemplify the above process, considering the pair: ``Three men are jumping off a wall'' and ``Three young men run, jump, and kick off of a Coke machine''. The second sentence consists of three propositions: ``three young men run'', ``three young men jump'', and ``three young men kick off of a Coke machine''. After the alignment process, its proposition list is reordered to ``three young men jump'', ``three young men run'', ``three young men kick off of a Coke machine''. The first sentence is compared with ``three young men jump'', resulting a difference vector $\mathbf{v_1}$. Since ``three young men run'' and ``three young men kick off of a Coke machine''
have no counterparts, we concatenate $\mathbf{v_1}$ with two vectors of the same length as $\mathbf{v_1}$, padded with 2 to signify the two sentences are different in this part. Finally, the resulting vector is padded with 0 until it reaches the required length, indicating the two sentences are the same in this default part.
