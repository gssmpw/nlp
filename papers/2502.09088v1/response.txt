\section{Related work}
\label{sec:related_work}
Implicit Neural Representations (INRs) have been shown effective in representing 3D shapes, by letting simple coordinate-based neural networks continuously represent an occupancy grid while fitting a Signed Distance Function (SDF)**Park et al., "Deep SDF"**. Neural SDFs address known problems of voxel and mesh representations, including limited resolution or foldings. They have been adapted to fit single or multiple surfaces from medical images**Qiu et al., "Neural SDF for Multi-Surface Reconstruction"**. A clever way to learn a consistent INR across multiple shapes is the autodecoder (AutoD) principle introduced in**Groueix et al., "AtlasNet"** and used in**Kim et al., "DeepSDF"**. An AutoD conditions the INR to an additional learnable latent variable defined on a coordinate system shared over the dataset. The joint INR  becomes a conditional generative shape model. 
When trained on a population, the AutoD INR learns an implicit shape prior, with latent variables encoding variations across the population, including  changes in shape. Such shape prior was used to complete partial annotations for volume segmentation **Qiu et al., "Unsupervised Partial Annotation Completion"**. 
We extend this approach to the unsupervised detection of abnormal shapes, relying either on the reconstruction error or distances in the learned latent space. To the best of our knowledge, anomaly detection based on INRs has been studied for images**Anoosheh et al., "Deep Anomaly Detection"**, but not for global shape abnormalities.