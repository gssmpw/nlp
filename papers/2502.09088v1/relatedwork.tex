\section{Related work}
\label{sec:related_work}
Implicit Neural Representations (INRs) have been shown effective in representing 3D shapes, by letting simple coordinate-based neural networks continuously represent an occupancy grid while fitting a Signed Distance Function (SDF)~\cite{Gropp}. Neural SDFs address known problems of voxel and mesh representations, including limited resolution or foldings. They have been adapted to fit single or multiple surfaces from medical images~\cite{alblas:heart-workshop2022:atlas,AMIRANASHVILI2024}. A clever way to learn a consistent INR across multiple shapes is the autodecoder (AutoD) principle introduced in~\cite{park:cvpr2019:deepsdf} and used in \cite{AMIRANASHVILI2024}. An AutoD conditions the INR to an additional learnable latent variable defined on a coordinate system shared over the dataset. The joint INR  becomes a conditional generative shape model. 
When trained on a population, the AutoD INR learns an implicit shape prior, with latent variables encoding variations across the population, including  changes in shape. Such shape prior was used to complete partial annotations for volume segmentation \cite{AMIRANASHVILI2024}. 
We extend this approach to the unsupervised detection of abnormal shapes, relying either on the reconstruction error or distances in the learned latent space. To the best of our knowledge, anomaly detection based on INRs has been studied for images~\cite{naval:miccai2021:anomaly-images} and to detect abnormal regions in point-clouds~\cite{bergmann:wacv2023:anomaly-points}, but not for global shape abnormalities.