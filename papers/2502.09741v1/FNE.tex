

\section{Methods}

Building on insights from prior studies 
\cite{zhou2024pre} that highlight the importance of Fourier features in numerical embeddings, we propose Fourier Number Embedding. Unlike existing methods that often require digit-wise tokenization or pre-training to handle numeric tasks, FoNE directly maps numbers into compact Fourier representations.


In Section \ref{sec:fne}, we introduce FoNE, where each digit is represented with two entries in their embeddings. In Section \ref{sec:fnp}, we introduce the Fourier number loss function and Fourier number prediction, which demonstrate how we decode the last hidden states from Fourier space to number space to compute loss and make the prediction. In Section \ref{sec:inco} we show how we incorporate our method into input sequences. The complete process is shown in Figure \ref{fig:teaser1}. 



\subsection{Fourier Number Embedding (FoNE)}\label{sec:fne}
\ifdefined\isarxiv

\begin{algorithm*}[!ht]
\caption{Fourier Number Embedding (FoNE) Algorithm}\label{alg:fne_algorithm_fixed}
    \begin{algorithmic}[1]
    \Procedure{\textsc{FourierNumberEmbedding}}{$x \in \R, m \in \Z_{\geq 0}, n \in \Z_{\geq 0}, d \in \Z_{> 0}$} 
    \State{\textbf{Inputs}: Number $x$, integer digit length $m$, decimal digit length $n$, embedding dimension $d$}
    \State Initialize empty embedding vector $\text{FoNE} \gets []$
    \For{$i = -n+1 \to m$} \Comment{Loop over all scales from $10^{-n+1}$ to $10^m$}
        \State $T_i \gets 10^i$ \Comment{Set the period for the current scale}
        \State $\phi(x, T_i) \gets (\cos(\tfrac{2\pi}{T_i} x), \sin(\tfrac{2\pi}{T_i} x))$ \Comment{Compute the circular embedding for scale $T_i$}
        \State Append $\phi(x, T_i)$ to $\text{FoNE}$ \Comment{Add the embedding for this scale to the result}
    \EndFor
    \While{$\text{Length}(\text{FoNE}) < d$} \Comment{Ensure embedding dimension matches the target}
        \State Append $0$ to $\text{FoNE}$ \Comment{Zero-pad}
    \EndWhile
    \State \Return $\text{FoNE}$ 
    \EndProcedure
    \end{algorithmic}
\end{algorithm*}
\else
\fi

We first  introduce the following circular embedding function that maps each $x \in \R$ to a point on the unit circle.
\begin{definition}[Circular embedding]\label{def:circular}
Let $T$ be a given period. We define function $\phi: \R \rightarrow \R^2$
\begin{align*}
\phi(x, T) :=  \left(\cos \left(\tfrac{2\pi}{T}x \right),\sin \left(\tfrac{2\pi}{T}x \right) \right).
\end{align*}
\end{definition}
 Let $m$ represents the number of digits before the decimal point, and $n$ represents the number of digits after the decimal point, ensuring that both integer and fractional parts of a number are accounted for in the representation. Next, we formally define the FoNE method that directly map numbers to their embedding.
\begin{definition}[Fourier Number Embedding]
Let $m$ be the integer digit length, and $n$ be the decimal digit length. We define the Fourier Number Embedding function $\FoNE: \R \rightarrow \R^{2(m+n)}$ for an input number $x$ as follows:
\begin{align*}
    \FoNE(x,m,n) := \bigl[\phi(x,T_i)\bigr]_{i=-n+1}^{m},
\end{align*}
where $T_i = 10^{i}$ for each integer $i$ in the range $-n+1$ to $m$.
\end{definition}
To align the embedding dimensions of FoNE with the model's input embedding dimension \( d \), we map the Fourier Number Embedding, which lies in \( \mathbb{R}^{2(m+n)} \), to \( \mathbb{R}^d \). This mapping can be achieved in two ways: (1) by applying a learnable linear transformation \( \mathbf{W} \in \mathbb{R}^{d \times 2(m+n)} \), or (2) by appending zeros to the embedding vector to match the dimensionality \( d \). As demonstrated in Section \ref{sec:ablation}, both approaches achieve comparable results.


Then, we introduce an elementary lemma and demonstrate why FoNE can preserve the numeracy on numbers.
\begin{lemma}[Informal version of Lemma \ref{lem:fne_preserve_numeracy:formal}]\label{lem:fne_preserve_numeracy:informal}
    Given the pair $\left(\cos\left(\tfrac{2\pi}{T}x\right), \sin\left(\tfrac{2\pi}{T}x\right)\right)$, we can recover 
    % \begin{align*}
$x \bmod T$.
    % \end{align*}
\end{lemma}
\begin{lemma}[FoNE preserves numeracy]
    Given a number's Fourier Number Embedding $\FoNE(x)$, its integer digit length $m$, and the decimal digit length $n$, by using Lemma~\ref{lem:fne_preserve_numeracy:informal}, we can recover $x \bmod 10^{i}$ for each integer $i$ in the range $-n+1$ to $m$.

\end{lemma}
A natural question that arises here is why do we need $x \bmod 10$ when we know $x \bmod 100$. Hence, next, we show the necessity of different periods.

\begin{lemma}[Necessity of different periods]
When $T$ becomes very large in a circular embedding (Definition \ref{def:circular}), the difference
$\frac{2\pi}{T} (x+1) -\frac{2\pi}{T} x$
approaches zero, causing the embedded representations of $x$ and $x+1$ to become arbitrarily close on the unit circle. Consequently, a single large $T$ cannot sufficiently distinguish adjacent values in the embedding. Hence, one must choose $T$ across a broad range of scales to ensure that the embedding remains adequately distinguishable for all values of $x$. In this paper, we choose $T$ as $10^i,~ \forall i$, so that each $T$ effectively captures one digit of $x$. 
\end{lemma}
Note that since FoNE uses the ratio between entries to represent numbers, it is unaffected by layer normalization and RMS normalization  (Lemma \ref{lem:fne_preserve_numeracy_layer_norm}), in contrast to xVal \cite{golkar2023xval}, which uses the magnitudes of entries.


To provide a clear illustration of our method, we present a detailed example demonstrating how we map number $4.17$  to its embedding.
\begin{example}
Consider $x = 4.17$. Its Fourier Number Embedding is given by
\[
[\phi(4.17,0.1), \phi(4.17,1), \phi(4.17,10)],
\]
where $\phi$ is defined in Definition \ref{def:circular}.
From these components, by using Lemma \ref{lem:fne_preserve_numeracy:informal}, we can recover
\[
[4.17 \bmod 0.1, 4.17 \bmod 1, 4.17 \bmod 10],\footnote{  For real \(x\) and positive real \(m\), \(x \bmod m\) is defined as 
   $ x - m \cdot \left\lfloor \frac{x}{m} \right\rfloor,$
  yielding a value in the range \([0, m)\)}
\]
which simplifies to $[0.07,0.17,4.17]$. If we used only $T = 10$, then $\phi(4.17,10)$ would be nearly indistinguishable from $\phi(4.18,10)$, causing the embedding to lose fine-grained information about less significant digits. However, with these chosen periods $T$, we can capture all the digits.
\end{example}


\ifdefined\isarxiv
\else
\begin{algorithm}[!ht]
\caption{Fourier Number Loss \& Prediction}
\label{alg:fourier_loss_prediction}
\begin{algorithmic}[1]

    %--------------------------------------------------
    % Digit-wise Loss
    %--------------------------------------------------
    \Function{FourierNumberLossFunction}{$h, y, i$}
        \State $y_i \gets \text{the $i$-th digit of } y$
        \State $a \gets \bigl[h[2i],h[2i+1]\bigr]$
        \State $b \gets  [\phi(0,10),
                \phi(1,10),
                \cdots,
                \phi(9,10)]^\top$
        \State $\text{logits} \gets a \cdot b$
        \State $\text{loss} \gets L_{\mathrm{CE}}(y_i,\ \text{logits})$ \State \Comment{\textit{Cross-entropy loss for digit $i$}}
        \State \Return \text{loss}
    \EndFunction

    %--------------------------------------------------
    % Digit-wise Prediction
    %--------------------------------------------------
    \Function{FourierNumberPrediction}{$h, i$}
    \State   \Comment{\textit{Prediction for digit $i$}}
        \State $\text{logits} \gets 
        \bigl[h[2i],h[2i+1]\bigr]
            \cdot
            \bigl[
                \phi(j,10)
            \bigr]_{j=0,\dots,9}$
        \State $\hat{y}_i \gets \arg\max_{j \in \{0,\dots,9\}} \text{logits}[j]$
        \State \Return $\hat{y}_i$
    \EndFunction

\end{algorithmic}
\end{algorithm}

\fi


\subsection{Decoding}\label{sec:fnp}


\ifdefined\isarxiv
\begin{algorithm}[!ht]
\caption{Fourier Number Loss \& Prediction}
\label{alg:fourier_loss_prediction}
\begin{algorithmic}[1]

    %--------------------------------------------------
    % Digit-wise Loss
    %--------------------------------------------------
    \Function{FourierNumberLossFunction}{$h, y, i$}
        \State $y_i \gets \text{the $i$-th digit of } y$
        \State $a \gets \bigl[h[2i],h[2i+1]\bigr]$
        \State $b \gets  [\phi(0,10),
                \phi(1,10),
                \cdots,
                \phi(9,10)]^\top$
        \State $\text{logits} \gets a \cdot b$
        \State $\text{loss} \gets L_{\mathrm{CE}}(y_i,\ \text{logits})$ \Comment{\textit{Cross-entropy loss for digit $i$}}
        \State \Return \text{loss}
    \EndFunction

    %--------------------------------------------------
    % Digit-wise Prediction
    %--------------------------------------------------
    \Function{FourierNumberPrediction}{$h, i$}
    \Comment{\textit{Prediction for digit $i$}}
        \State $\text{logits} \gets 
        \bigl[h[2i],h[2i+1]\bigr]
            \cdot
            \bigl[
                \phi(j,10)
            \bigr]_{j=0,\dots,9}$
        \State $\hat{y}_i \gets \arg\max_{j \in \{0,\dots,9\}} \text{logits}[j]$
        \State \Return $\hat{y}_i$
    \EndFunction

\end{algorithmic}
\end{algorithm}

\else
\fi


As each number has its own FoNE, calculating the logits for all possible numbers becomes computationally infeasible. Therefore, we introduce a novel decoding head that maps hidden states from Fourier space to number space as shown in Figure~\ref{fig:teaser1}(d). Below, we explicitly  define the loss function and prediction function for each digit and then show how to combine these to obtain the final loss and prediction.

\begin{definition}[Fourier Number Loss Function]
Let \(h \in \mathbb{R}^{d}\) denote the last-layer hidden state of the model. Let $y_i$ denote the $i$-th digit of the label number $y$. For digit $i$, we define the Fourier Number Loss Function $L_{\FoNE}$ as:
\vspace{-1.5mm}
\begin{align*}
    L_{\FoNE} (h, y, i) :=    L_{\mathrm{CE}}\!\Bigl(y_i,  (\underbrace{[
                h[2i], ~h[2i+1]
            ]}_{1 \times 2}
            \cdot
            \underbrace{\begin{bmatrix}
                \phi(0,10)\\
                \vdots\\
                \phi(9,10)
            \end{bmatrix}}_{2\times 10})
       \Bigr)
\end{align*}
\end{definition}
\vspace{-3mm}
This construction allows each digit to be treated as a separate prediction task while sharing the same underlying model representation \(h\). By taking the average of \(L_{\FoNE}(h, y, i)\) over all digit positions \(i\), we obtain the final training loss.

\begin{definition}[Fourier Number Prediction for the \(i\)-th digit]
Let \(h \in \mathbb{R}^{d}\) denote the last-layer hidden state of the model. For digit $i$, we define the Fourier Number Prediction as:
\vspace{-1mm}
\begin{align*}
 \hat{y}_i := 
    \arg\max_{j \in \{0,\dots,9\}}
    \Bigl(
        \big[   h[2i], ~h[2i+1]
            \big]
            \cdot
            \big[\phi(j,10)\big]
    \Bigr).
\end{align*}
\end{definition}
\vspace{-2mm}
\noindent
Here, \(\hat{y}_i\) is determined by the similarity between the hidden states and the circular embedding of number in $\{0,\cdots,9\}$ as illustrated in Figure \ref{fig:teaser1}(d). Once we have computed \(\hat{y}_i\) for each digit \(i\), the final prediction for the entire number can be formed by concatenating these digit-wise predictions. We defer the detailed algorithms to Appendix \ref{app:fourier_final_loss_prediction}.
%due to space limit.

\subsection{Incorporating FoNE into Input Sequences}\label{sec:inco}

The integration of Fourier Number Embedding (FoNE) into input sequences proceeds as follows, as illustrated in Figure~\ref{fig:teaser1}:

\begin{enumerate}[itemsep=-2pt,topsep=0pt,leftmargin=15pt]
    \item Extract all numbers from the input sequence to create a number list. Replace each number with the token \texttt{[Num]} and tokenize the sequence to obtain a token list.
    \item Embed the token list using standard word embedding methods.
    \item Map each number in the number list to its FoNE representation using Algorithm~\ref{alg:fne_algorithm_fixed}, as detailed in Section~\ref{sec:fne}.
    \item Add the FoNE to the word embedding of the corresponding \texttt{[Num]} token.
    \item Feed the combined embeddings into the model.
    \item Use the model's output embeddings to predict the next token in the sequence.
    \item If the predicted token is \texttt{[Num]}, decode the numerical value using the method described in Section~\ref{sec:fnp}, or compute the loss during training.
\end{enumerate}
This procedure ensures that FoNE embeddings are seamlessly integrated into the input sequence, enabling the model to leverage both numerical and contextual information effectively.
