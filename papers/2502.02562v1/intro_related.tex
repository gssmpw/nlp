\section{Introduction and Related Work}
\label{sec:intro_related}
Position encodings (PEs) \citep{pes-survey, pes-length-gen, pos-encoding-diet, kiyono-etal-2021-shape} inject information about the respective locations of tokens into transformers \citep{vaswani2017attention}. 
They are essential for good performance because vanilla attention is a set function, equivariant under permutation.
In contrast, the meaning of a sequence of tokens in general depends on its ordering. %

\pg{APEs and RPEs} Practitioners initially relied on \textit{absolute} PEs
\citep[APEs;][]{vaswani2017attention, kiyono-etal-2021-shape, WangSLJYLS21, LiuYDH20} which add or concatenate fixed, precomputed position embeddings to tokens.
These have since been replaced by \emph{relative} PEs \citep[RPEs;][]{shaw2018self, RaffelSRLNMZLL20, LiYGAOZSYKB24, ChiFRR22, PressSL22, ChiFRR23}, which add a learnable bias term that depends on the distance between tokens to the pre-softmax attention logits.
RPEs tend to generalise better than APEs over varying sequence lengths.
However, they often require explicit computation for every query-key pair. %


\pg{RoPE} To address the limitations of RPEs and APEs, researchers recently introduced \emph{rotary} position encodings \citep[RoPE;][]{su2024roformer, heo2025rotary}.
These have been widely adopted in large language models \citep[LLMs;][]{dubey2024llama,team2024gemma}.
RoPE acts on queries and keys by partitioning them into $2$-dimensional blocks, each of which is rotated by an angle proportional to the token's position in the sequence.
Whilst queries and keys are rotated separately, the angle of \emph{relative} rotation is proportional to their separation, combining the best properties of APEs and RPEs.
Mathematically, for query and key of dimensionality $d$, RoPE involves $\lfloor \frac{d}{2} \rfloor$ Givens rotations \citep{BindelDKM02} acting on disjoint 2D subspaces.


Besides providing strong empirical gains, two attractive properties have driven the enthusiastic uptake of RoPE. 
\begin{enumerate}[leftmargin=*, itemsep=-1pt, topsep=0pt]
    \item {\textbf{Separability.}}  
    RoPE transforms each query and key independently, based on its position.
    This happens once per token; 
    the PE'd tokens are not recalculated during subsequent processing like autoregressive generation.
    This makes KV-caching convenient. 
    Separability also makes RoPE compatible with linear attention, e.g.~Performers \citep{choromanski2020rethinking, katharopoulos2020transformers}.
    Here, the attention matrix is not instantiated in memory so explicit RPE mechanisms are not possible.\footnote{\emph{Implicit} relative position encoding schemes, which avoid instantiating the attention matrix in memory, have also been proposed \citep{reid2024linear,choromanski2022block,luo2021stable}.} %
    \item {\textbf{Translational invariance.}} 
    For a query-key pair at positions $(i,j)\in\mathbb{N}^2$, the relative rotation angle depends only on $i-j$. 
    This improves sequence-length generalization.
\end{enumerate}
However, RoPE is not the only position encoding algorithm with these desirable traits. 
In this paper, we propose a more general algorithm called \textbf{STRING}: \textbf{S}eparable \textbf{Tr}anslationally \textbf{In}variant Position Encodin\textbf{g}s.
STRING is based on Lie groups. 
It generalises RoPE via a unifying theoretical framework, incorporating the latter as a special case.
In fact, we later prove that STRING is the \emph{most general} PE algorithm with the properties above, amongst a broad class.

\pg{STRING for robotics}
The above features are especially important in robotics, where efficient 2D/3D token representation and sensible physical priors are key. 
To demonstrate it, we integrate STRING into Vision Transformers (ViTs), showing strong improvements for open-vocabulary object detection models and various robotics controllers. This showcases the real-world impact of our STRING.




Videos of STRING-based robotics controllers can be found here: \href{ https://sites.google.com/view/string-robotics}{ https://sites.google.com/view/string-robotics}.

\pg{Key contributions} 
\begin{enumerate}[leftmargin=*, itemsep=-1pt, topsep=0pt]
\item We introduce STRING, a new family of position encodings for multidimensional token coordinates that respect both separability and translational invariance. 
\item We rigorously analyse STRING's theoretical properties (\textbf{ Sec. \ref{sec:string_core_section}}), proving that it is more general than RoPE.
We provide computationally efficient implementations.
\item We show strong accuracy gains across varied models using Transformers with STRING, on a range of robotics and general vision tasks (see Fig. \ref{fig:aloha_double_insertion_comparison} and \textbf{Sec.  \textbf{\ref{sec:experiments}}}).
\end{enumerate}

