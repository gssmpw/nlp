\documentclass[11pt, a4paper, logo]{gdmstyle/googledeepmind}
\pdfinfoomitdate 1
\pdftrailerid{redacted}

\makeatletter
\renewcommand\bibentry[1]{\nocite{#1}{\frenchspacing\@nameuse{BR@r@#1\@extra@b@citeb}}}
\makeatother

\usepackage{blindtext}


\usepackage{microtype}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage{booktabs} %
\usepackage{enumitem}
\usepackage{tcolorbox}
\usepackage{svg}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage[sort,numbers,square]{natbib}

\usepackage{hyperref}


\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\cocoAP}[0]{$\text{AP}^\text{COCO}$}
\newcommand{\lvisAP}[0]{$\text{AP}^\text{LVIS}$}

\newcommand{\pg}[1]{{\bf #1.}}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{numprint}


\usepackage[capitalize,noabbrev]{cleveref}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{remark}[theorem]{Remark}

\usepackage[textsize=tiny]{todonotes}



\usepackage{capt-of,etoolbox}





\newif\ifarxiv

\arxivtrue

\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}


\usepackage{lastpage}




\title{Learning the RoPEs: Better 2D and 3D Position Encodings with STRING}
\keywords{Position Encoding, Transformers,  Translation Invariance, Attention}


\newcommand{\addLink}[1]{{\normalfont\href{mailto:#1}{\nolinkurl{#1}}}}
\correspondingauthor{Krzysztof Choromanski (\addLink{kchoro@google.com}) \\ $^{*}$ Equal contribution, $^{\wedge}$ Work done at Google Research, $^\dagger$ Random order, $^{\ddagger}$ Senior lead. }

\setcounter{Maxaffil}{2}  %
\author{

Connor Schenck$^{*\dagger}$\thanks{$^{*}$ Equal contribution. $^{\wedge}$ Work done at Google Research. $^\dagger$ Random order. $^{\ddagger}$ Senior lead.},
Isaac Reid$^{*\wedge \dagger 23}$,
Mithun George Jacob$^{*\dagger1}$,
Alex Bewley$^{*\dagger 1}$,
Joshua Ainslie$^{*\dagger 1}$,
David Rendleman$^{*\dagger 1}$,
Deepali Jain$^{* 1}$,
Mohit Sharma$^{* 1}$,
Avinava Dubey$^{* 3}$,
Ayzaan Wahid$^{1}$,
Sumeet Singh$^{1}$,
René Wagner$^{1}$,
Tianli Ding$^{1}$,
Chuyuan Fu$^{1}$,
Arunkumar Byravan$^{1}$,
Jake Varley$^{1}$,
Alexey Gritsenko$^{1}$,
Matthias Minderer$^{1}$,
Dmitry Kalashnikov$^{1}$,
Jonathan Tompson$^{1}$,
Vikas Sindhwani$^{1}$,
Krzysztof Choromanski$^{*\ddagger 1}$
}
\affil{$^{1}$Google DeepMind \hspace{1cm} $^{2}$University of Cambridge \hspace{1cm} $^{3}$Google Research}


\date{\today}

\begin{abstract}%
We introduce \textbf{STRING}: Separable Translationally Invariant Position Encodings. 
STRING extends Rotary Position Encodings \citep[RoPE;][]{su2024roformer}, a recently proposed and widely used algorithm in large language models, via a unifying theoretical framework. 
Importantly, STRING still provides \textbf{exact} translation invariance, including token coordinates of arbitrary dimensionality, whilst maintaining a low computational footprint. 
These properties are especially important in robotics, where efficient 3D token representation is key. 
We integrate STRING into Vision Transformers with RGB(-D) inputs (color plus optional depth), showing substantial gains, e.g. in open-vocabulary object detection and for robotics controllers.
We complement our experiments with a rigorous mathematical analysis, proving the universality of our methods. Videos of STRING-based robotics controllers can be found here: \href{ https://sites.google.com/view/string-robotics}{ https://sites.google.com/view/string-robotics}.
\end{abstract}

\begin{document}

\maketitle

\begin{figure*}[h] %
    \centering
    \includegraphics[width=\textwidth]{figures/aloha-doubleinsertion-vis-2.jpg} %
    \captionsetup{justification=centering} %
    \caption{\small{\textbf{Top:} Successful diffusion policy conditioned on a STRING-enhanced Transformer vision encoder, attempting the double-insertion task on \textrm{Aloha}-\textrm{sim}. %
    \textbf{Bottom:} Same experiment, but with a regular vision encoder for which the policy fails.
    STRING provides strong improvements for training dexterous robotics policies, outperforming previous position encoding algorithms such as RoPE.}}
    \label{fig:aloha_double_insertion_comparison}
\end{figure*} %


\input{intro_related}
\input{preliminaries}
\input{string}
\input{experiments}
\input{conclusion}

\section{Impact Statement}
The goal of this work is to contribute to the advancement of the machine learning field which may result in potential societal consequences. We acknowledge these potential risks, especially in downstream use-cases of advanced machine learning techniques and advocate for careful consideration of ethical implications in the development and deployment of these techniques. Additionally, as it is the case for all papers discussing training Transformer architectures, the corresponding carbon footprint needs to be taken into account. STRING plays a positive role here since it reduces computational costs by providing ways of fine-tuning already pre-trained architectures with a negligible set of extra trainable parameters. 



\vskip 0.2in
\bibliographystyle{plainnat}
\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Barbero et~al.(2024)Barbero, Vitvitskyi, Perivolaropoulos, Pascanu,
  and Veli{\v{c}}kovi{\'c}]{barbero2024round}
Federico Barbero, Alex Vitvitskyi, Christos Perivolaropoulos, Razvan Pascanu,
  and Petar Veli{\v{c}}kovi{\'c}.
\newblock Round and round we go! what makes rotary positional encodings useful?
\newblock \emph{arXiv preprint arXiv:2410.06205}, 2024.

\bibitem[Beyer et~al.(2024)Beyer, Steiner, Pinto, Kolesnikov, Wang, Salz,
  Neumann, Alabdulmohsin, Tschannen, Bugliarello, Unterthiner, Keysers,
  Koppula, Liu, Grycner, Gritsenko, Houlsby, Kumar, Rong, Eisenschlos, Kabra,
  Bauer, Bošnjak, Chen, Minderer, Voigtlaender, Bica, Balazevic, Puigcerver,
  Papalampidi, Henaff, Xiong, Soricut, Harmsen, and Zhai]{beyer2024paligemma}
Lucas Beyer, Andreas Steiner, André~Susano Pinto, Alexander Kolesnikov, Xiao
  Wang, Daniel Salz, Maxim Neumann, Ibrahim Alabdulmohsin, Michael Tschannen,
  Emanuele Bugliarello, Thomas Unterthiner, Daniel Keysers, Skanda Koppula,
  Fangyu Liu, Adam Grycner, Alexey Gritsenko, Neil Houlsby, Manoj Kumar, Keran
  Rong, Julian Eisenschlos, Rishabh Kabra, Matthias Bauer, Matko Bošnjak,
  Xi~Chen, Matthias Minderer, Paul Voigtlaender, Ioana Bica, Ivana Balazevic,
  Joan Puigcerver, Pinelopi Papalampidi, Olivier Henaff, Xi~Xiong, Radu
  Soricut, Jeremiah Harmsen, and Xiaohua Zhai.
\newblock {PaliGemma: A versatile 3B VLM for transfer}.
\newblock \emph{arXiv preprint arXiv:2407.07726}, 2024.

\bibitem[Bindel et~al.(2002)Bindel, Demmel, Kahan, and Marques]{BindelDKM02}
David Bindel, James Demmel, William Kahan, and Osni Marques.
\newblock On computing givens rotations reliably and efficiently.
\newblock \emph{{ACM} Trans. Math. Softw.}, 28\penalty0 (2):\penalty0 206--238,
  2002.
\newblock \doi{10.1145/567806.567809}.
\newblock URL \url{https://doi.org/10.1145/567806.567809}.

\bibitem[Calli et~al.(2015)Calli, Walsman, Singh, Srinivasa, Abbeel, and
  Dollar]{calli2015benchmarking}
Berk Calli, Aaron Walsman, Arjun Singh, Siddhartha Srinivasa, Pieter Abbeel,
  and Aaron~M Dollar.
\newblock Benchmarking in manipulation research: The ycb object and model set
  and benchmarking protocols.
\newblock \emph{arXiv preprint arXiv:1502.03143}, 2015.

\bibitem[Chen et~al.(2024)Chen, Xu, Kirmani, Ichter, Driess, Florence, Sadigh,
  Guibas, and Xia]{chen2024spatialvlm}
Boyuan Chen, Zhuo Xu, Sean Kirmani, Brian Ichter, Danny Driess, Pete Florence,
  Dorsa Sadigh, Leonidas Guibas, and Fei Xia.
\newblock Spatialvlm: Endowing vision-language models with spatial reasoning
  capabilities, 2024.
\newblock URL \url{https://arxiv.org/abs/2401.12168}.

\bibitem[Chen et~al.(2021)Chen, Tsai, Bhojanapalli, Chung, Chang, and
  Ferng]{pos-encoding-diet}
Pu{-}Chin Chen, Henry Tsai, Srinadh Bhojanapalli, Hyung~Won Chung, Yin{-}Wen
  Chang, and Chun{-}Sung Ferng.
\newblock A simple and effective positional encoding for transformers.
\newblock In Marie{-}Francine Moens, Xuanjing Huang, Lucia Specia, and
  Scott~Wen{-}tau Yih, editors, \emph{Proceedings of the 2021 Conference on
  Empirical Methods in Natural Language Processing, {EMNLP} 2021, Virtual Event
  / Punta Cana, Dominican Republic, 7-11 November, 2021}, pages 2974--2988.
  Association for Computational Linguistics, 2021.
\newblock \doi{10.18653/V1/2021.EMNLP-MAIN.236}.
\newblock URL \url{https://doi.org/10.18653/v1/2021.emnlp-main.236}.

\bibitem[Chen et~al.(2023)Chen, Wang, Changpinyo, Piergiovanni, Padlewski,
  Salz, Goodman, Grycner, Mustafa, Beyer, Kolesnikov, Puigcerver, Ding, Rong,
  Akbari, Mishra, Xue, Thapliyal, Bradbury, Kuo, Seyedhosseini, Jia, Ayan,
  Riquelme, Steiner, Angelova, Zhai, Houlsby, and Soricut]{chen2023pali}
Xi~Chen, Xiao Wang, Soravit Changpinyo, AJ~Piergiovanni, Piotr Padlewski,
  Daniel Salz, Sebastian Goodman, Adam Grycner, Basil Mustafa, Lucas Beyer,
  Alexander Kolesnikov, Joan Puigcerver, Nan Ding, Keran Rong, Hassan Akbari,
  Gaurav Mishra, Linting Xue, Ashish Thapliyal, James Bradbury, Weicheng Kuo,
  Mojtaba Seyedhosseini, Chao Jia, Burcu~Karagol Ayan, Carlos Riquelme, Andreas
  Steiner, Anelia Angelova, Xiaohua Zhai, Neil Houlsby, and Radu Soricut.
\newblock Pali: A jointly-scaled multilingual language-image model, 2023.
\newblock URL \url{https://arxiv.org/abs/2209.06794}.

\bibitem[Chi et~al.(2022)Chi, Fan, Ramadge, and Rudnicky]{ChiFRR22}
Ta{-}Chung Chi, Ting{-}Han Fan, Peter~J. Ramadge, and Alexander Rudnicky.
\newblock {KERPLE:} kernelized relative positional embedding for length
  extrapolation.
\newblock In Sanmi Koyejo, S.~Mohamed, A.~Agarwal, Danielle Belgrave, K.~Cho,
  and A.~Oh, editors, \emph{Advances in Neural Information Processing Systems
  35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS
  2022, New Orleans, LA, USA, November 28 - December 9, 2022}, 2022.

\bibitem[Chi et~al.(2023)Chi, Fan, Rudnicky, and Ramadge]{ChiFRR23}
Ta{-}Chung Chi, Ting{-}Han Fan, Alexander Rudnicky, and Peter~J. Ramadge.
\newblock Dissecting transformer length extrapolation via the lens of receptive
  field analysis.
\newblock In Anna Rogers, Jordan~L. Boyd{-}Graber, and Naoaki Okazaki, editors,
  \emph{Proceedings of the 61st Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto,
  Canada, July 9-14, 2023}, pages 13522--13537. Association for Computational
  Linguistics, 2023.
\newblock \doi{10.18653/V1/2023.ACL-LONG.756}.
\newblock URL \url{https://doi.org/10.18653/v1/2023.acl-long.756}.

\bibitem[Choromanski et~al.(2020)Choromanski, Likhosherstov, Dohan, Song, Gane,
  Sarlos, Hawkins, Davis, Mohiuddin, Kaiser, et~al.]{choromanski2020rethinking}
Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song,
  Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin,
  Lukasz Kaiser, et~al.
\newblock Rethinking attention with performers.
\newblock \emph{arXiv preprint arXiv:2009.14794}, 2020.

\bibitem[Choromanski et~al.(2022)Choromanski, Lin, Chen, Zhang, Sehanobish,
  Likhosherstov, Parker-Holder, Sarlos, Weller, and
  Weingarten]{choromanski2022block}
Krzysztof Choromanski, Han Lin, Haoxian Chen, Tianyi Zhang, Arijit Sehanobish,
  Valerii Likhosherstov, Jack Parker-Holder, Tamas Sarlos, Adrian Weller, and
  Thomas Weingarten.
\newblock From block-toeplitz matrices to differential equations on graphs:
  towards a general theory for scalable masked transformers.
\newblock In \emph{International Conference on Machine Learning}, pages
  3962--3983. PMLR, 2022.

\bibitem[Collins et~al.(2022)Collins, Goel, Deng, Luthra, Xu, Gundogdu, Zhang,
  Yago~Vicente, Dideriksen, Arora, Guillaumin, and Malik]{collins2022abo}
Jasmine Collins, Shubham Goel, Kenan Deng, Achleshwar Luthra, Leon Xu, Erhan
  Gundogdu, Xi~Zhang, Tomas~F Yago~Vicente, Thomas Dideriksen, Himanshu Arora,
  Matthieu Guillaumin, and Jitendra Malik.
\newblock Abo: Dataset and benchmarks for real-world 3d object understanding.
\newblock \emph{CVPR}, 2022.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE Conference on Computer Vision and Pattern
  Recognition}, pages 248--255, 2009.
\newblock \doi{10.1109/CVPR.2009.5206848}.

\bibitem[Diele et~al.(1998)Diele, Lopez, and Peluso]{DieleLP98}
Fasma Diele, Luciano Lopez, and R.~Peluso.
\newblock The cayley transform in the numerical solution of unitary
  differential systems.
\newblock \emph{Adv. Comput. Math.}, 8\penalty0 (4):\penalty0 317--334, 1998.
\newblock \doi{10.1023/A:1018908700358}.
\newblock URL \url{https://doi.org/10.1023/A:1018908700358}.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{dosovitskiy2020vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{ICLR}, 2021.

\bibitem[Downs et~al.(2022)Downs, Francis, Koenig, Kinman, Hickman, Reymann,
  McHugh, and Vanhoucke]{downs2022google}
Laura Downs, Anthony Francis, Nate Koenig, Brandon Kinman, Ryan Hickman, Krista
  Reymann, Thomas~B McHugh, and Vincent Vanhoucke.
\newblock Google scanned objects: A high-quality dataset of 3d scanned
  household items.
\newblock In \emph{2022 International Conference on Robotics and Automation
  (ICRA)}, pages 2553--2560. IEEE, 2022.

\bibitem[Dubey et~al.(2024)Dubey, Jauhri, Pandey, Kadian, Al-Dahle, Letman,
  Mathur, Schelten, Yang, Fan, et~al.]{dubey2024llama}
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad
  Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan,
  et~al.
\newblock The llama 3 herd of models.
\newblock \emph{arXiv preprint arXiv:2407.21783}, 2024.

\bibitem[{Gemma Team} et~al.(2024){Gemma Team}, Mesnard, Hardin, Dadashi,
  Bhupatiraju, Pathak, Sifre, Rivi{\`e}re, Kale, Love, et~al.]{team2024gemma}
{Gemma Team}, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya
  Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivi{\`e}re, Mihir~Sanjay
  Kale, Juliette Love, et~al.
\newblock Gemma: Open models based on gemini research and technology.
\newblock \emph{arXiv preprint arXiv:2403.08295}, 2024.

\bibitem[Gupta et~al.(2019)Gupta, Dollar, and Girshick]{gupta2019lvis}
Agrim Gupta, Piotr Dollar, and Ross Girshick.
\newblock Lvis: A dataset for large vocabulary instance segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 5356--5364, 2019.

\bibitem[Hall(2013)]{hall2013lie}
Brian~C Hall.
\newblock \emph{Lie groups, Lie algebras, and representations}.
\newblock Springer, 2013.

\bibitem[Hendrycks and Gimpel(2016)]{hendrycks2016}
Dan Hendrycks and Kevin Gimpel.
\newblock Bridging nonlinearities and stochastic regularizers with gaussian
  error linear units.
\newblock \emph{CoRR}, abs/1606.08415, 2016.
\newblock URL \url{http://arxiv.org/abs/1606.08415}.

\bibitem[Heo et~al.(2025)Heo, Park, Han, and Yun]{heo2025rotary}
Byeongho Heo, Song Park, Dongyoon Han, and Sangdoo Yun.
\newblock Rotary position embedding for vision transformer.
\newblock In \emph{European Conference on Computer Vision}, pages 289--305.
  Springer, 2025.

\bibitem[Hertzberg et~al.(2011)Hertzberg, Wagner, Frese, and
  Schr{\"{o}}der]{Hertzberg2011}
Christoph Hertzberg, Ren{\'{e}} Wagner, Udo Frese, and Lutz Schr{\"{o}}der.
\newblock Integrating generic sensor fusion algorithms with sound state
  representations through encapsulation of manifolds.
\newblock \emph{CoRR}, abs/1107.1119, 2011.
\newblock URL \url{http://arxiv.org/abs/1107.1119}.

\bibitem[Katharopoulos et~al.(2020)Katharopoulos, Vyas, Pappas, and
  Fleuret]{katharopoulos2020transformers}
Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and Fran{\c{c}}ois
  Fleuret.
\newblock Transformers are rnns: Fast autoregressive transformers with linear
  attention.
\newblock In \emph{International conference on machine learning}, pages
  5156--5165. PMLR, 2020.

\bibitem[Kazemnejad et~al.(2023)Kazemnejad, Padhi, Ramamurthy, Das, and
  Reddy]{pes-length-gen}
Amirhossein Kazemnejad, Inkit Padhi, Karthikeyan~Natesan Ramamurthy, Payel Das,
  and Siva Reddy.
\newblock The impact of positional encoding on length generalization in
  transformers.
\newblock In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz
  Hardt, and Sergey Levine, editors, \emph{Advances in Neural Information
  Processing Systems 36: Annual Conference on Neural Information Processing
  Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
  2023.

\bibitem[Kiyono et~al.(2021)Kiyono, Kobayashi, Suzuki, and
  Inui]{kiyono-etal-2021-shape}
Shun Kiyono, Sosuke Kobayashi, Jun Suzuki, and Kentaro Inui.
\newblock {SHAPE}: {S}hifted absolute position embedding for transformers.
\newblock In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott
  Wen-tau Yih, editors, \emph{Proceedings of the 2021 Conference on Empirical
  Methods in Natural Language Processing}, pages 3309--3321, Online and Punta
  Cana, Dominican Republic, November 2021. Association for Computational
  Linguistics.
\newblock \doi{10.18653/v1/2021.emnlp-main.266}.
\newblock URL \url{https://aclanthology.org/2021.emnlp-main.266/}.

\bibitem[Kuhn(1955)]{kuhn55}
H.W. Kuhn.
\newblock The hungarian method for the assignment problem.
\newblock \emph{Naval Research Logistics Quarterly}, 2\penalty0
  (1--2):\penalty0 83--97, 1955.

\bibitem[Li et~al.(2024)Li, You, Guruganesh, Ainslie, Onta{\~{n}}{\'{o}}n,
  Zaheer, Sanghai, Yang, Kumar, and Bhojanapalli]{LiYGAOZSYKB24}
Shanda Li, Chong You, Guru Guruganesh, Joshua Ainslie, Santiago
  Onta{\~{n}}{\'{o}}n, Manzil Zaheer, Sumit Sanghai, Yiming Yang, Sanjiv Kumar,
  and Srinadh Bhojanapalli.
\newblock Functional interpolation for relative positions improves long context
  transformers.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations, {ICLR} 2024, Vienna, Austria, May 7-11, 2024}.
  OpenReview.net, 2024.
\newblock URL \url{https://openreview.net/forum?id=rR03qFesqk}.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{Computer Vision--ECCV 2014: 13th European Conference,
  Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pages
  740--755. Springer, 2014.

\bibitem[Liu et~al.(2020)Liu, Yu, Dhillon, and Hsieh]{LiuYDH20}
Xuanqing Liu, Hsiang{-}Fu Yu, Inderjit~S. Dhillon, and Cho{-}Jui Hsieh.
\newblock Learning to encode position for transformer with continuous dynamical
  model.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020, 13-18 July 2020, Virtual Event}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 6327--6335. {PMLR},
  2020.
\newblock URL \url{http://proceedings.mlr.press/v119/liu20n.html}.

\bibitem[Luo et~al.(2021)Luo, Li, Cai, He, Peng, Zheng, Ke, Wang, and
  Liu]{luo2021stable}
Shengjie Luo, Shanda Li, Tianle Cai, Di~He, Dinglan Peng, Shuxin Zheng, Guolin
  Ke, Liwei Wang, and Tie-Yan Liu.
\newblock Stable, fast and accurate: Kernelized attention with relative
  positional encoding.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 22795--22807, 2021.

\bibitem[Matthias~Minderer(2022)]{minderer2022simple}
Austin Stone Maxim Neumann Dirk Weissenborn Alexey Dosovitskiy Aravindh
  Mahendran Anurag Arnab Mostafa Dehghani Zhuoran Shen Xiao Wang Xiaohua Zhai
  Thomas Kipf Neil~Houlsby Matthias~Minderer, Alexey~Gritsenko.
\newblock Simple open-vocabulary object detection with vision transformers.
\newblock \emph{ECCV}, 2022.

\bibitem[Ostmeier et~al.(2024)Ostmeier, Axelrod, Moseley, Chaudhari, and
  Langlotz]{ostmeier2024liere}
Sophie Ostmeier, Brian Axelrod, Michael~E Moseley, Akshay Chaudhari, and Curtis
  Langlotz.
\newblock Liere: Generalizing rotary position encodings.
\newblock \emph{arXiv preprint arXiv:2406.10322}, 2024.

\bibitem[Press et~al.(2022)Press, Smith, and Lewis]{PressSL22}
Ofir Press, Noah~A. Smith, and Mike Lewis.
\newblock Train short, test long: Attention with linear biases enables input
  length extrapolation.
\newblock In \emph{The Tenth International Conference on Learning
  Representations, {ICLR} 2022, Virtual Event, April 25-29, 2022}.
  OpenReview.net, 2022.
\newblock URL \url{https://openreview.net/forum?id=R8sQPpGCv0}.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, Krueger, and Sutskever]{radford2021clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International conference on machine learning}, pages
  8748--8763. PMLR, 2021.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{RaffelSRLNMZLL20}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{J. Mach. Learn. Res.}, 21:\penalty0 140:1--140:67, 2020.
\newblock URL \url{https://jmlr.org/papers/v21/20-074.html}.

\bibitem[Reid et~al.(2024)Reid, Dubey, Jain, Whitney, Ahmed, Ainslie, Bewley,
  Jacob, Mehta, Rendleman, et~al.]{reid2024linear}
Isaac Reid, Kumar~Avinava Dubey, Deepali Jain, Will Whitney, Amr Ahmed, Joshua
  Ainslie, Alex Bewley, Mithun Jacob, Aranyak Mehta, David Rendleman, et~al.
\newblock Linear transformer topological masking with graph random features.
\newblock \emph{arXiv preprint arXiv:2410.03462}, 2024.

\bibitem[Roziere et~al.(2023)Roziere, Gehring, Gloeckle, Sootla, Gat, Tan, Adi,
  Liu, Sauvestre, Remez, et~al.]{roziere2023code}
Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat,
  Xiaoqing~Ellen Tan, Yossi Adi, Jingyu Liu, Romain Sauvestre, Tal Remez,
  et~al.
\newblock Code llama: Open foundation models for code.
\newblock \emph{arXiv preprint arXiv:2308.12950}, 2023.

\bibitem[Rubinstein et~al.(1991)Rubinstein, Segman, and
  Zeevi]{rubinstein1991recognition}
Jacob Rubinstein, Joseph Segman, and Yehoshua Zeevi.
\newblock Recognition of distorted patterns by invariance kernels.
\newblock \emph{Pattern Recognition}, 24\penalty0 (10):\penalty0 959--967,
  1991.

\bibitem[Segman et~al.(1992)Segman, Rubinstein, and Zeevi]{segman1992canonical}
Joseph Segman, Jacob Rubinstein, and Yehoshua~Y Zeevi.
\newblock The canonical coordinates method for pattern deformation: Theoretical
  and computational considerations.
\newblock \emph{IEEE Transactions on Pattern Analysis \& Machine Intelligence},
  14\penalty0 (12):\penalty0 1171--1183, 1992.

\bibitem[Shaw et~al.(2018)Shaw, Uszkoreit, and Vaswani]{shaw2018self}
Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani.
\newblock Self-attention with relative position representations.
\newblock \emph{arXiv preprint arXiv:1803.02155}, 2018.

\bibitem[Singh et~al.(2024)Singh, Tu, and Sindhwani]{singh2024revisiting}
Sumeet Singh, Stephen Tu, and Vikas Sindhwani.
\newblock Revisiting energy based models as policies: Ranking noise contrastive
  estimation and interpolating energy models.
\newblock \emph{Transactions on Machine Learning Research}, 2024.
\newblock ISSN 2835-8856.
\newblock URL \url{https://openreview.net/forum?id=JmKAYb7I00}.

\bibitem[Su et~al.(2024)Su, Ahmed, Lu, Pan, Bo, and Liu]{su2024roformer}
Jianlin Su, Murtadha Ahmed, Yu~Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu.
\newblock Roformer: Enhanced transformer with rotary position embedding.
\newblock \emph{Neurocomputing}, 568:\penalty0 127063, 2024.

\bibitem[Tai et~al.(2019)Tai, Bailis, and Valiant]{tai2019equivariant}
Kai~Sheng Tai, Peter Bailis, and Gregory Valiant.
\newblock Equivariant transformer networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  6086--6095. PMLR, 2019.

\bibitem[Tziafas and Kasaei(2023)]{10341422}
Georgios Tziafas and Hamidreza Kasaei.
\newblock Early or late fusion matters: Efficient rgb-d fusion in vision
  transformers for 3d object recognition.
\newblock In \emph{2023 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 9558--9565, 2023.

\bibitem[Udayan et~al.(2023)Udayan, Addanki, Durgapu, Yerramreddy, and
  Kolla]{JADYK23}
J.~Divya Udayan, Veerababu Addanki, Sathvik Durgapu, Dhanvanth~Reddy
  Yerramreddy, and Dorasanaiah Kolla.
\newblock Forward kinematics simulation of {KUKA} {KR5} arc robot with robo
  analyzer.
\newblock In \emph{Proceedings of the 2023 Fifteenth International Conference
  on Contemporary Computing, IC3-2023, Noida, India, August 3-5, 2023}, pages
  294--299. {ACM}, 2023.
\newblock \doi{10.1145/3607947.3608006}.
\newblock URL \url{https://doi.org/10.1145/3607947.3608006}.

\bibitem[{Unity Technologies}(2023)]{unity}
{Unity Technologies}.
\newblock Unity, 2023.
\newblock URL \url{https://unity.com/}.
\newblock Game development platform.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna~M. Wallach,
  Rob Fergus, S.~V.~N. Vishwanathan, and Roman Garnett, editors, \emph{Advances
  in Neural Information Processing Systems 30: Annual Conference on Neural
  Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA,
  {USA}}, pages 5998--6008, 2017.

\bibitem[Wang et~al.(2021)Wang, Shang, Lioma, Jiang, Yang, Liu, and
  Simonsen]{WangSLJYLS21}
Benyou Wang, Lifeng Shang, Christina Lioma, Xin Jiang, Hao Yang, Qun Liu, and
  Jakob~Grue Simonsen.
\newblock On position embeddings in {BERT}.
\newblock In \emph{9th International Conference on Learning Representations,
  {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net, 2021.
\newblock URL \url{https://openreview.net/forum?id=onxoVA9FxMw}.

\bibitem[Xiong et~al.(2023)Xiong, Liu, Molybog, Zhang, Bhargava, Hou, Martin,
  Rungta, Sankararaman, Oguz, et~al.]{xiong2023effective}
Wenhan Xiong, Jingyu Liu, Igor Molybog, Hejia Zhang, Prajjwal Bhargava, Rui
  Hou, Louis Martin, Rashi Rungta, Karthik~Abinav Sankararaman, Barlas Oguz,
  et~al.
\newblock Effective long-context scaling of foundation models.
\newblock \emph{arXiv preprint arXiv:2309.16039}, 2023.

\bibitem[Yang et~al.(2024)Yang, Kang, Huang, Zhao, Xu, Feng, and
  Zhao]{yang2024depthv2}
Lihe Yang, Bingyi Kang, Zilong Huang, Zhen Zhao, Xiaogang Xu, Jiashi Feng, and
  Hengshuang Zhao.
\newblock Depth anything v2, 2024.
\newblock URL \url{https://arxiv.org/abs/2406.09414}.

\bibitem[Zhai et~al.(2023)Zhai, Mustafa, Kolesnikov, and
  Beyer]{zhai2023sigmoid}
Xiaohua Zhai, Basil Mustafa, Alexander Kolesnikov, and Lucas Beyer.
\newblock Sigmoid loss for language image pre-training.
\newblock \emph{arXiv preprint arXiv:2303.15343}, 2023.

\bibitem[Zhao et~al.(2023)Zhao, Feng, Feng, Qin, and Liu]{pes-survey}
Liang Zhao, Xiaocheng Feng, Xiachong Feng, Bing Qin, and Ting Liu.
\newblock Length extrapolation of transformers: {A} survey from the perspective
  of position encoding.
\newblock \emph{CoRR}, abs/2312.17044, 2023.
\newblock \doi{10.48550/ARXIV.2312.17044}.

\bibitem[Zhao et~al.(2024)Zhao, Tompson, Driess, Florence, Ghasemipour, Finn,
  and Wahid]{zhao2024aloha}
Tony~Z Zhao, Jonathan Tompson, Danny Driess, Pete Florence, Kamyar Ghasemipour,
  Chelsea Finn, and Ayzaan Wahid.
\newblock Aloha unleashed: A simple recipe for robot dexterity.
\newblock \emph{arXiv preprint arXiv:2410.13126}, 2024.

\end{thebibliography}




\section*{Contributions}
\vspace{-1mm}
\textbf{Connor Schenck} worked on the pipeline to filter the full WebLI dataset of 10 billion images down to approximately 60 million images and run the monodepth models on the RGB images to create depth images. Connor also created the codebase to train models to predict 3D bounding boxes for queried objects in a scene and generated the results for 3D detection in section \ref{sec:owlvit3d}. \\
\textbf{Isaac Reid} proposed to parameterise PEs as exponentiated learnable generators, proved Theorems 3.2-3.4, wrote Secs 1-3 of the manuscript. \\
\textbf{Mithun George Jacob} proposed and implemented Cayley-STRING. He evaluated it on WebLI-3D, ALOHA simulation, ImageNet and Places365. He also contributed to the creation of WebLI-3D, the integration of STRING into ALOHA Unleashed and the preparation of the manuscript and website. \\
\textbf{Alex Bewley} carried out the OWL-ViT 2D experiments with RoPE and STRING variants. Alex also reviewed and contributed to the design of the 3D bounding box detection model used in the experiment and helped prepare the manuscript. \\
\textbf{Joshua Ainslie} proposed investigating RoPE for robot vision with RGB/RGB-D inputs and developed the library for learnable 2D/3D RoPE in ViT/ViTD models. He set up early experiments for WebLI-3D, ImageNet, Places365, and OWL-ViT indicating promising headroom for improved position encodings. \\
\textbf{David Rendleman} contributed to WebLI-3D dataset creation, ViT training infrastructure, and evaluation of trained models in simulated ALOHA. \\
\textbf{Deepali Jain} helped set up the sim dataset for 3D detection. Ran training experiments for on-robot manipulation tasks and compared several RELM-based vision encoders for generative policies. \\
\textbf{Mohit Sharma} co-developed training, evaluation and infrastructure for Kuka real-world experiments. Setup and ran training experiments to evaluate 3D encoders on real-world tasks. Helped write the real-world Kuka evaluations section of the paper. \\
\textbf{Avinava Dubey} developed RoPE for ViT/ViTD and experimented with WebLI-3D, ImageNet and Places365. Helped with writing the paper. \\
\textbf{Ayzaan Wahid} provided code and support for running ALOHA experiments in sim and real: train codebase, support with sim experiments, support repo for real deployment. \\
\textbf{Sumeet Singh} integration support for Diffusion-$\phi$ \citep{singh2024revisiting}, multi-system and assist training. \\
\textbf{René Wagner} advised on orientation representations, proposed switching from quaternions to the two-column orientation representation used for 3D detection results, and helped prepare the manuscript. \\
\textbf{Tianli Ding} advised on datasets selection and monocular depth estimation, conducted ALOHA real-robot experiments. \\
\textbf{Chuyuan Fu} provided code and support for generating and using ALOHA sim dataset. \\
\textbf{Arunkumar Byravan} provided the sim datasets for 3D detection, Colab for loading the results and support in working with the datasets. \\
\textbf{Jake Varley} provided code and support for running Kuka experiments. \\
\textbf{Alexey Gritsenko} advised on OWL-ViT with RoPE and 3D detection experiments. \\
\textbf{Matthias Minderer} advised on the use of the Scenic codebase for OWL-ViT experiments and the inner workings of OWL-ViT architecture used in both the 2D and 3D experiments. \\
\textbf{Dmitry Kalashnikov} bimanual Kuka data infra development and support. Red-teaming infra and research contributions. \\
\textbf{Jonathan Tompson} advised on ALOHA sim and real experiments. \\
\textbf{Vikas Sindhwani} led red-teaming and out-of-distribution data collection efforts on biarm Kuka cells; supported 3d + Diffusion-$\phi$ effort. \\ 
\textbf{Krzysztof Choromanski} overall lead of the project (managing project and Team). Co-proposed Lie-algebra approach to extend RoPE embeddings. Developed and implemented Circulant-STRING and proved Theorem 3.5. Proposed Extension 1 and co-proposed Extension 2. Prepared depth modeling backbone for Diffusion-$\phi$ experiments and trained first depth Diffusion-$\phi$ policies conditioned on STRING for robotics manipulation with KUKA arms. Helped write the paper and prepare the website. \\


\input{appendix}


\end{document}
