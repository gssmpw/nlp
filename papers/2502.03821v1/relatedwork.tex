\section{Related Work}
\subsection{Personalized Dialogue Systems}
Prior research on personalized dialogue systems has focused on encoding various user-specific information within end-to-end dialogue systems to enhance response specificity. For instance, \citet{li2016persona} tackled the issue of inconsistent responses in multi-turn dialogues by developing a personalized seq2seq %\cite{luong2015addressing}
model. This model was built on the basis of resources such as the Twitter corpus and incorporated user identity information (e.g., gender, age, and country of residence) into its encoding scheme. \citet{zhang2018personalizing} constructed the PERSONA-CHAT dataset and endeavored to train a personalized dialogue agent by embedding the user profiles in a memory-augmented neural network \cite{sukhbaatar2015end} during the training process. The resultant model displayed a higher degree of fluency and consistency, approaching human levels on these evaluative metrics, while retaining distinct personality traits. \citet{zheng2020pre} introduced a pre-training based method that can utilize persona-sparse data. They then encoded speakersâ€™ personas and dialogue histories together to enrich dialogue contexts. While these studies have somewhat enhanced the ability of dialogue systems to express personalized features, they have not sufficiently explored the modeling of individual personality traits.

\begin{figure*}[t]
	\centering
	\includegraphics[width=1\textwidth]{figure/fig_method.pdf}
	\caption{Illustration of the proposed PsyPlay through three stages: Role Card Creation, Topic Extraction, and Dialogue Generation. The first stage aims to create multiple personalized roles. The second stage extracts appropriate dialogue topics for roles. The third stage prompts the roles to engage in conversation with each other based on the given topic, resulting in personality-infused dialogues.}
	\label{fig:method}
\vspace{-3mm}
\end{figure*}

\subsection{Role-Playing with LLMs}
For LLM-based role-playing, the agents are often assumed as specific characters or roles derived from novels, movies, comics, and games. The LLM is required to mimic the speaking styles of characters based on their likes and experiences in interacting with the users. For instance, \citet{shao2023character} gathered character portraits from Wikipedia and generated character-related conversations via ChatGPT; \citet{wang2023rolellm} employed GPT-4 \cite{achiam2023gpt} to create character descriptions and subsequently developed intricate prompts to guide ChatGPT in generating role-based dialogue; \citet{tu2024charactereval} established a Chinese benchmark dataset for the evaluation of role-playing quality, assessing the role-playing capability of the LLM intelligent agent across four dimensions: conversational ability, character consistency, role-playing attractiveness, and personality back-testing. Although LLMs enable swift construction of dialogue agents embodying various character traits through prompt engineering in role-playing, recent research on RPCA personalities \cite{huang2023chatgpt} indicates that RPCAs, prompted merely by names or descriptions, fail to effectively convey the intended personality traits. Moreover, in assessing role personality, some studies \cite{tu2024charactereval, huang2023chatgpt, wang2023does} adopt the approach of directly prompting the agent to complete self-assessment personality tests. However, this method, solely relying on the agent's responses, is influenced by the LLM's training data and value alignment, and thus may not accurately assess the real personality manifested by the agent in conversation with users. In this paper, we verify the reliability of role-playing by evaluating the true personality reflected in the dialogue.