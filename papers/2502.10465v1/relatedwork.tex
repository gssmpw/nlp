\section{Related Work}
\subsection{Diffusion Models}

Inspired by non-equilibrium thermodynamics, Ho et al. proposed the popular denoising diffusion probabilistic (DDPM) generative paradigm \cite{ho2020denoising}, which performed competitively compared to PGGAN \cite{guo2021pggan} on the 256x256 LSUN dataset \cite{yu2015lsun}. Since this development, a considerable amount of research has focused on diffusion models to improve architectures, accelerate sampling speeds, and explore various downstream tasks. Nichol et al.~\cite{nichol2021improved} discovered that learning the variances of the reverse process in DDPMs can significantly reduce the number of sampling steps required. Song et al.~\cite{song2020denoising} extend DDPMs through a class of non-Markovian diffusion processes into denoising diffusion implicit models (DDIMs), yielding higher-quality samples with fewer sampling steps. Subsequent work, Adaptive Diffusion Model(ADM) \cite{li2024adm}, identifies a more effective architecture and achieves state-of-the-art performance compared to other generative models with classifier guidance. Viewing DDPMs as solving differential equations on manifolds, Liu et al.~\cite{liu2022pseudo} proposed pseudo-numerical methods for diffusion models (PNDMs), further enhancing sampling efficiency and generation quality. Beyond unconditional image generation, there is a wealth of \textit{conditional} text-to-image generation literature which leverage the diffusion process. Among these, VQDiffusion, based on a VQ-VAE~\cite{van2017neural}, models the latent space with a conditional variant of DDPMs. The latent diffusion model (LDM) \cite{rombach2022high} exploits a cross-attention mechanism and latent spaces to condition diffusion models on textual inputs.



\subsection{Watermarked Diffusion Models}

%Lukas et al.~\cite{lukas2023leveraging} discussed adaptive attacks on image watermarks by exploiting weaknesses in frequency domain watermarking, including detailed strategies on how attackers can optimize these attacks to bypass watermarking protections.


% To demonstrate the generality of our watermarking method, we performed end-to-end training on both DDIM and DDPM in the same manner. 
% Hereafter, let \( a \) represent the diffusion model.



Recent research in watermarking technology has primarily focused on optimising robustness, imperceptibility, and adaptability. Existing works have provided diverse approaches to address these challenges. Wu et al.~\cite{wu2021watermarking} introduced a method for embedding watermarks into the outputs of neural networks, protecting the intellectual property of deep learning models. Their approach effectively balances image quality and watermark robustness. Liu et al.~\cite{liu2018blind} proposed a dual watermarking mechanism combining robust and fragile watermarks, achieving simultaneous copyright protection and tampering detection. Zong et al.~\cite{zong2015histogram} utilised histogram shape-based features to design a robust watermarking scheme, particularly effective against geometric attacks such as cropping and random bending. Wang et al.~\cite{wang2024template} employed a template-enhanced network to achieve watermark synchronisation under geometric attacks, improving extraction accuracy. Huang et al.~\cite{huang2023texture} leveraged texture-aware adaptive embedding strategies to optimise watermark robustness and imperceptibility, focusing on textured regions to balance these trade-offs.

Compared to these works, our study introduces a novel strategy that embeds watermarks directly into the diffusion process of generative models. Unlike traditional methods that focus solely on protecting output images, our approach ensures that the watermark is deeply integrated with the generation process, enabling traceability back to the model itself. The proposed framework demonstrates strong model-agnostic adaptability, as it can be applied to various diffusion model architectures such as DDIM and DDPM. Furthermore, experimental results reveal that our method maintains high visual quality, with negligible impact on image fidelity, while achieving robustness against multiple attacks, including compression, rotation, and blurring.

A key innovation of our work lies in its efficient encoding and decoding of watermark features using an autoencoder. This design enhances the precision of watermark extraction, even under substantial attack conditions. Additionally, we contribute to the field by introducing the Generative Watermarking Image (GWI) dataset, which provides a standardised benchmark for evaluating watermarking techniques in generative models. Unlike the template-based synchronisation approach proposed by Wang et al.~\cite{wang2024template}, our method eliminates the reliance on complex template embedding, simplifying implementation and reducing computational overhead. Moreover, by integrating watermarking into the diffusion model's training process, we extend the applicability of watermarking technologies beyond the traditional scope, establishing a robust foundation for protecting generative models.


\begin{figure*}
\centering
% Use the relevant command to insert your figure file.
% For example, with the graphicx package use
  \includegraphics[width=\textwidth]{frame.png}
% figure caption is below the figure
\caption{\small The Watermark Generator transforms an image-based watermark $w$ into a watermark feature map $w_{T}$ which serves as a branch input to the diffusion model. It is merged with the output $x_{T}$ of the forward diffusion process. The watermarked noise `$xw_T$' serves as a new input for the diffusion denoising phase, which enables embedding watermark features into the diffusion model. The trained diffusion model generates images $xw_{0}$ as usual, but they contain imperceptible watermark information. The Watermark Extractor learns to reconstruct the watermark  $w_R$ from the generated images.}
\label{fig:2}       % Give a unique label
\end{figure*}