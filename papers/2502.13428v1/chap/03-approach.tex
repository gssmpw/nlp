\section{Approach}

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=1\textwidth,page=1]{img/img-cropped.pdf}
  \caption{Overview of the MCTS process.}
  \label{fig:overview}
\end{figure*}

\subsection{Overview}

% 近期,将LLM视为agent的KBQA方法已经展现了remarkable capabilities in few-shot learning and reasoning.
% 然而, 受限于线性的决策过程, 这些方法未能充分挖掘LLM的推理潜力.
% 为了解决这个问题, 我们将MCTS引入到KBQA中, 并设计了一套适用于KBQA的打分规则, 并验证了直接提示 open-source LLM to give a reward 是可行的.
Recent KBQA methods that conceptualize LLMs as agents have demonstrated remarkable capabilities in few-shot learning and reasoning.
However, constrained by their linear decision-making processes, these methods have not fully realized the reasoning potential of LLMs.
To address this limitation, we introduce Monte Carlo Tree Search (MCTS) into KBQA and design a scoring mechanism specifically tailored for KBQA tasks.
We demonstrate that directly prompting open-source LLMs to provide rewards for intermediate steps in the MCTS process is an effective approach.
Figure \ref{fig:overview} presents an overview of the search process.

\subsection{Preliminaries}

\textbf{For KBQA}, a knowledge base (KB) is formally defined as $\mathcal{K} \in \mathcal{E} \times \mathcal{P} \times (\mathcal{E} \cup \mathcal{L} \cup \mathcal{C})$, where $\mathcal{E}$ denotes the set of entities, $\mathcal{P}$ represents the set of predicates (including relations and qualifiers), $\mathcal{C}$ denotes the set of classes (e.g., concepts), and $\mathcal{L}$ comprises the set of literal values.
Given a question $Q$ and a knowledge base $\mathcal{K}$, our goal is to generate an executable SPARQL expression that answers the question.
The semantic parsing process can be formalized as $p(\text{SPARQL} | Q, \mathcal{K})$.

\textbf{For MCTS}, a node $e=\{a, o\}$ contains an action $a$ and an observation $o$, except for the root node $e_{root}=\{Q\}$ which contains only the question.
For conciseness, we include the thought component within the action.
The state $s$ of a node $e$ is defined as the path from root node to $e$, formally represented as:

\begin{equation}
    s_e = \{e_{root}, e_1, ..., e_d\} \nonumber \\
    = \{Q, a_1, o_1, ..., a_d, o_d\}
\end{equation}

where $d$ is the depth of node $e$ in the tree. Thus, the state of a node represents the complete history of interactions along the branch.

\subsection{Monte Carlo Tree Search for KBQA}

MCTS is a tree search-based method that explores the solution space through iterative selection, expansion, evaluation, simulation and backpropagation, achieving superior performance compared to linear decision-making approaches.

\textbf{Selection}. The selection phase identifies the most promising leaf node for expansion. Starting from the root node, we employ the widely-used Upper Confidence Bounds applied to Trees (UCT) as our selection criterion. UCT effectively balances exploiting high-value nodes and exploring less-visited nodes.
We skip terminal nodes and select the node with the highest UCT value.

The formula is defined as:
\begin{equation}
    \text{UCT}(e) = \frac{w_e}{n(e)} + \sqrt{2 * \frac{\ln N(e)}{n(e)}}
\end{equation}

where $w_e$ is the total reward of node $e$, $n(e)$ is its visit count, and $N(e)$ is its parent's visit count.
The selection process is formalized as:

\begin{equation}
    e_{select} = \arg\max_{e \in E} \text{UCT}(e)
\end{equation}

where $E$ denotes the set of non-terminal nodes.

\textbf{Expansion}.
Following Interactive-KBQA \citep{Xiong-Guanming-ACL-2024-Interactive-KBQA}, we fine-tune an open-source LLM on human-annotated interaction data to serve as our action-generating agent.
% The multi-round interactive approach essentially decomposes the semantic parsing task into a step-wise action sequence comprising entity (and concept) localization, predicate finding, and SPARQL generation.
The action space is defined as \{SearchNodes, SearchGraphPatterns, ExecuteSPARQL, Done\}.
After executing each action, we obtain an observation which, together with the action, forms a new node.
Formally, the process is defined as:

\begin{equation}
    \{a_i\}_{i=1}^n = \text{Agent}(s_e)
\end{equation}

where $a_i$ represents the actions (including thought process) generated by the agent, $n$ is a hyperparameter controlling how many completions to generate for each input, and $s_e$ is the state of the selected node $e$.


\textbf{Evaluation}.
Evaluation is a crucial component that guides the search direction.
Unlike classical MCTS approaches that evaluate nodes only upon termination, we evaluate intermediate steps immediately after each node generation.

Formally, the score function is defined as:
\begin{equation}
    r(e) = \text{LLM}(\text{Prompt}_{eval}, \text{Exemplar}_{eval}, s_e)
\end{equation}

where $\text{Prompt}_{eval}$ represents the evaluation prompt consisting of task description, guidelines, and format requirements, and $\text{Exemplar}_{eval}$ denotes examples. Notably, we utilize an instruction-tuned open-source LLM without additional fine-tuning.

Based on the characteristics of the KBQA task, we design a set of rules as prompt text to score actions based on environmental feedback.
Our interactive semantic parsing approach essentially decomposes the process of finding the target SPARQL query into the collection and combination of basic elements.
For instance, we use the SearchNodes tool to locate entities and concepts, and the SearchGraphPatterns tool to find predicates and their corresponding literal value formats. The agent then combines these elements to construct SPARQL queries that express complex semantics.

Therefore, the scoring rules are designed to assess whether the state has successfully identified elements and solved sub-problems, which is fundamentally a simpler classification task.
Multiple studies \citep{Gu-Yu-ACL-2023-Pangu,Chen-Ziru-ACL-2024-Why-Tree-Search} have demonstrated that LLMs perform more accurately in discrimination tasks compared to generation tasks. 
The complete evaluation prompt and exemplars can be found in Appendix \ref{app_sec:reward_prompt}.

\textbf{Simulation and Backpropagation}.
Our approach evaluates intermediate states directly, bypassing the simulation step of traditional MCTS.
After obtaining the score, we immediately perform backpropagation.
We design a depth-based linear decay update function to prevent the search from getting trapped in local optima along branches. The function is defined as:

\begin{equation}
    w_e = w_e + r_e * (1 - \gamma * max(0, d_e - d_{exp}))
\end{equation}

where $\gamma$ is the decay coefficient, $d_e$ is the depth of the current node, and $d_{exp}$ is the expected depth. The detailed parameter settings can be found in Section \ref{sec:imp_details}.


\textbf{Termination}.
When an action generates \texttt{Done}, its branch terminates. The search process early stops after generating $k$ instances of \texttt{Done}, where $k$ is a hyperparameter that balances efficiency and performance. 
Otherwise, the search continues until reaching the maximum interaction rounds.
The impact of $k$ is analyzed in Section \ref{sec:early_stop_analysis}.
Notably, only valid terminal nodes are counted. 
A valid terminal node must have ExecuteSPARQL as its penultimate action, produce a non-empty error-free execution result, and its SPARQL query is treated as the prediction for that branch.
Finally, we vote for the most frequent execution result as the final result.

\subsection{Data Construction via Distant Supervision}

Existing KBQA datasets consist of question-SPARQL pairs but lack intermediate reasoning steps. Using our proposed method and a distant supervision paradigm, we augment these datasets with complete intermediate reasoning processes.
Implementation details are provided in Section \ref{sec:imp_details}.
Experimental results demonstrate that the extended dataset further improves model performance, as discussed in Section \ref{sec:extended_dataset_experiment}.
