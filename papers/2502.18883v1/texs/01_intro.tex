\section{Introduction}\label{sec:intro}
Extensive ML models have been developed under the assumption that training and testing data come from the same distribution (\ie \textit{closed-world assumption}). However, this assumption is often violated in practice, where deployed models may frequently encounter out-of-distribution (OOD) instances that are not seen in training ~\cite{torralba2011unbiased}. 
For instance, a model trained on high-quality code may struggle to comprehend buggy code. Adapting ML models to distribution shifts is possible but challenging and costly due to the constantly evolving data~\cite{liu2022deep}. Moreover, even if the training data is up-to-date, models will still encounter unforeseen scenarios under the open-world setting. Failure to recognize an OOD sample, and consequently to produce incorrect predictions, significantly compromises the reliability of a model. A reliable and trustworthy ML model should not only achieve high performance on samples from known distributions, \ie in-distribution (ID) data, but also accurately detect OOD samples which can then either abstain from making predictions, or potentially be forwarded to appropriate models handling other distributions or tasks.

OOD detection has been extensively studied in computer vision (CV)~\cite{yang2021generalized} and natural language processing (NLP)~\cite{li2023survey} across a range of tasks (\eg image/sentiment classification, question answering). Existing OOD detectors typically design a scoring function to derive confidence/ID scores, enabling the detection of OOD samples based on a predefined threshold. These OOD detectors serve as an auxiliary function to the original ML models and ensures a high proportion (\eg 95\%)~\cite{ming2022delving} of ID data finally retained based on the threshold. This is crucial to prevent the OOD auxiliary scoring from adversely affecting ML models' performance on their main image/language-related tasks. Current OOD detection approaches are proposed in supervised, unsupervised, and weakly-supervised regimes depending on the availability of OOD data. Supervised approaches~\cite{hendrycks2018deep} learn a classical binary classifier based on both ID and OOD data, but in practice, it is hard to assume the presence of a large dataset that captures everything different from the ID data. Unsupervised ones~\cite{mai2022self, zhou2021contrastive} only utilize ID data for training, but are likely to suffer from poor performance. Recent studies have demonstrated that weak supervision~\cite{tian2020few, majhi2021weakly, kim2023key, kim-etal-2023-pseudo} can remarkably outperform unsupervised learning methods for anomaly/OOD detection. Some weakly-supervised approaches~\cite{majhi2021weakly, kim2023key, kim-etal-2023-pseudo} generate pseudo-labeled OODs by partially corrupting ID data based on output attention mappings, while others~\cite{tian2020few} leverage a tiny collection of labeled OODs (\eg 1\% of ID data) to detect specific OOD types in the applications where access to OOD samples is limited and pseudo OOD generation is challenging~\cite{yoo2022data}. However, none of these ML approaches have been applied in the context of SE for code-related tasks.

Existing OOD detection research in SE primarily focuses on anomaly detection or software defect detection. Anomaly detection techniques~\cite{le2022log, wang2023logonline, traces2020guo, traces2021liu} are designed to detect anomalous system states (\eg failed processes, availability issues, security incidents) during system running based on \textit{monitoring data} (\eg logs, traces), but they still cannot been applied to the code context. There also exists a body of research dedicated to detecting suspicious defects in \textit{source code} (\eg vulnerability detection~\cite{sejfia2024toward, steenhoek2024dataflow, vul2024cao}, neural bug detection~\cite{ allamanis2021self, he2022distribution}). Although defective source code represents a type of distribution shifts from normal code, current defect detection techniques are not sufficient to cover a broad range of unseen scenarios considered by OOD detection.

Therefore, the goal of this work is to address the OOD detection problem in the context of SE for code-related tasks. While Transformer-based~\cite{vaswani2017attention} NL-PL (programming language) models have shown remarkable success in code understanding and generation ~\cite{guo2020graphcodebert, guo2022unixcoder, athena} by utilizing bimodal data (\ie comment and code), they often assume training and testing examples belong to the same distribution. Thus, these models may not guarantee the robustness against OOD instances in the open world (as evidenced by~\cite{hendrycks2020pretrained} for NL Transformers). For instance, a code search engine, which is trained on GitHub comment-based queries and code, is likely to fail in user questions and code answers from StackOverflow. 

In this paper, we systematically investigate the ability of pre-trained NL-PL models~\cite{guo2020graphcodebert, guo2022unixcoder, liu2023contrabert} in detecting OOD instances and the impact of OOD detection on a downstream code task (\ie code search). While NLP OOD detection techniques show promise for adaptation to NL-PL models due to the similarity between NL and PL, they can only detect textual OODs from uni-modal data. However, in the SE context for code-related tasks, distribution shifts can occur in either modality (comment or code) or both of them. An effective OOD code detector should be able to detect OOD from comments, code, or both modalities, by utilizing multi-modal NL-PL pairs. Several multi-modal approaches have been proposed for vision OOD detection~\cite{ming2022delving, esmaeilpour2022zero}, utilizing information from both images and their textual descriptions, but they are still designed to detect \textit{only} visual OODs.

% That said, I do have a few reservations regarding the particularity of OOD samples and the technical contribution

% However, I am missing whether such OOD detection model training will differ from the other NL models which basically are targeted to improve the OOD data detection accuracy. At the end of the day, such inputs are presented as vectors and whether at the level of embedding and vector inputs, it is not clear to me how the proposed approach brings technical contribution.

% Provide a in-depth discussion on the challenges for OOD code detection as compared to other domain e.g., vision. 

% More in-depth discussions are needed to highlight the challenges in OOD code detection


To overcome these challenges, we develop two types of multi-modal OOD detection models to equip NL-PL models with OOD code detection capability. The first one is unsupervised (coined as COOD), which fine-tunes the NL-PL models to closely align NL-PL representations solely from ID data~\cite{husain2019codesearchnet} based on the multi-modal contrastive learning~\cite{oord2018representation}, and then uses their prediction confidences as OOD scores. The contrastive learning objective is expected to effectively capture high-level alignment information within (NL, PL) pairs to detect OODs. To further enhance the OOD detection performance, we propose a weakly-supervised OOD detection model, COOD+, which utilizes a tiny collection of OOD samples (\eg 1\%) during model training. Current techniques in ML typically considered unsupervised contrastive learning~\cite{zhou2021contrastive} or outlier exposure~\cite{hendrycks2018deep, liu2020energy}, in conjunction with a scoring function, limiting their ability to detect OODs from just one modality. In contrast, our COOD+ integrates an improved contrastive learning module with a binary OOD rejection module in order to effectively detect OODs from NL, PL, or both modalities. OOD samples are then identified by a combination of two different scoring functions: the confidence scores produced by the contrastive learning module and the prediction probabilities of the binary OOD rejection module.

Due to the lack of evaluation benchmarks for OOD code detection, we create a new benchmark tailored for code context following the construction principles in ML~\cite{zhou2021contrastive, mai2022self}, but containing more OOD scenarios: (1) aligned (NL, PL) pairs collected from a new domain, \eg from StackOverflow rather than GitHub, (2) misaligned (NL, PL) pairs,  (3) the presence of syntactic errors in NL descriptions, and (4) buggy source code. We first evaluate the proposed models on two real-world datasets, CodeSearchNet-Java and CodeSearchNet-Python, and establish a range of unsupervised and weakly-supervised baselines for comparison. Experimental results show that both COOD and COOD+ models significantly outperform the best unsupervised and weakly-supervised baselines, respectively. Specifically, our unsupervised COOD is moderately capable of detecting OODs from three scenarios but does not perform well across all four scenarios. By integrating two modules, our COOD+ model effectively detects OODs from all scenarios simultaneously.

Furthermore, we apply our approaches to improve the robustness of existing (NL, PL) models for the code search task under the four OOD scenarios described above. By corrupting 15\% of the testing dataset with OOD examples, we demonstrate that NL-PL models actually are not robust to OOD samples. Specifically, the performance of a fine-tuned GraphCodeBERT code search model drops by around 5\% due to the presence of OODs. Subsequently, we filter the corrupted testing dataset with our COOD/COOD+, and show that our detectors successfully recover this performance loss and also improve the code search performance compared to the original testing set. In summary, the contributions of this paper are: 
 

\begin{itemize}[noitemsep, leftmargin=1.2em]  
\item A novel OOD benchmark specifically designed for code contexts, encompassing multiple OOD scenarios;

\item The first work to address OOD detection for code across four distinct scenarios;  

\item A multi-modal OOD detection framework for NL-PL pre-trained models, leveraging contrastive learning in both unsupervised and weakly-supervised settings;

\item A comprehensive evaluation showcasing the superior performance of our COOD and COOD+ frameworks in detecting OOD samples across four scenarios;

\item An online appendix providing the full codebase and experimental infrastructure of our approaches~\cite{cood-tool}. 

\end{itemize}