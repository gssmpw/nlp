% \vspace{-0.2cm}
\section{Related Work}\label{sec:related}
We review the related work on OOD detection in various fields such as computer vision (CV), natural language processing (NLP), and software engineering (SE), and then point out unique characteristics of our approach. 
% Out-of-Distribution (OOD) detection has gained prominence.

\subsection{OOD Detection in SE}
% In SE, two research directions have introduced the concept of OOD or distribution shift: anomaly detection and software defect detection. In this discussion, we primarily focus on the existing techniques in these two areas and the types of OOD data they address.

To ensure the reliability and safety of large-scale software systems, extensive work~\cite{ le2022log, yu2024deep, zhang2024metalog} has been conducted on anomaly detection to identify anomalous system state (\eg failed processes, availability issues, security incidents) during system running based on \texttt{\small monitoring data} (not in code format). Specifically, monitoring data includes logs~\cite{le2022log, wang2023logonline}, metrics (\eg response time, CPU usage)~\cite{metrics2021zervas}, traces~\cite{traces2020guo, traces2021liu}, etc. While some approaches utilize supervised learning techniques~\cite{zhang2019robust, lu2018detecting}, others employ unsupervised~\cite{farzad2020unsupervised} or semi-supervised learning~\cite{yang2021semi, Heter2023lee} due to insufficient anomaly labels. However, none of these anomaly detection techniques target code-based OOD detection, the main focus of our work. We mention this research line here since some existing OOD-related work in ML use the terms \textit{anomaly detection} and \textit{(generalized) OOD detection}  interchangeably~\cite{hendrycks2018deep}, but anomaly detection in SE has distinct characteristics as described above.

% The availability issues can manifest as performance anomalies (anomalous increase of response time), reliability anomalies (anomalous increase of error counts), traffic anomalies (anomalous increase/decrease of queries per second), etc. However, none of these anomaly detection techniques target code-based OOD detection, which is the main focus of our approach. We include this research line here since some existing OOD-related work in ML use the terms \textit{anomaly detection} and \textit{(generalized) OOD detection}  interchangeably~\cite{hendrycks2018deep}. %, but anomaly detection in SE has distinct characteristics as described above. 


Additionally, current defect detection techniques~\cite{lu2021codexglue} in SE typically identify defects by analyzing \texttt{\small source code} with code semantic features extracted. Research in vulnerability detection focuses on security-related defects, such as buffer overflows and use-after-free. Compared to conventional static tools~\cite{CodeQLtool, Checkmarxtool}, DL-based techniques~\cite{sejfia2024toward, steenhoek2024dataflow, cul2024liu, vul2024cao} utilize Graph Neural Networks (GNNs) or Transformers to learn implicit vulnerability patterns from source code. Additionally, bug detection techniques~\cite{kanade2020learning, chen2021plur, allamanis2021self, he2022distribution} also fall under the umbrella of defect detection but typically address semantically-incorrect code (\eg wrong binary operators, variable misuse) which is not necessarily security-related and probably syntactically feasible. Although our focus is also on source code, defective code is only considered as one scenario within the scope of our OOD detection problem. 

More recently, several research has explored the robustness and generalization of source code models to different OOD scenarios~\cite{hu2023codes, weyssow2023usage, hajipour2024simscood}. Hu \etal introduced a benchmark dataset to assess the performance of code models under distribution shifts~\cite{hu2023codes}, while others investigated fine-tuning strategies like low-rank adaptation~\cite{hajipour2024simscood} and continual learning~\cite{weyssow2023usage} for enhanced \textit{generalization} on OOD data. However, these studies did not specifically tackle OOD \textit{detection}, and existing unsupervised OOD detectors have shown limited effectiveness for source code data~\cite{hu2023codes}. In short, unlike prior work, our study directly aims to improve the OOD detection performance of existing code-related models, ensuring greater robustness and trustworthiness in the open world where many unseen OOD scenarios may be encountered.

\subsection{OOD Detection in CV and NLP}

In the ML community, OOD detection~\cite{hendrycksbaseline, yang2021generalized, salehiunified, li2023survey} has been extensively studied over the years, leading to a better-defined and formulated task. The primary objective of OOD detection here is to design an auxiliary ID-OOD classifier derived from neural-based visual and/or textual models based on OOD scores. Given that correctly predicted instances tend to have greater maximum softmax probabilities (MSP) than incorrectly predicted and OOD instances, MSP-based OOD scoring function~\cite{hendrycksbaseline, hein2019relu} weree initially utilized to identify OOD samples. Subsequently, energy- and distance-based scores~\cite{liu2020energy, zhou2021contrastive,sun2022knn} have also been utilized to derive OOD scores. For visual OOD data, existing techniques often aim for multi-class classification tasks (\eg image classification) and learn a $K+1$ classifier assuming that the unseen space is included in the additional class~\cite{hu2021outlier, liznerski2022exposing}. The OOD data utilized for evaluation is typically constructed from a completely different dataset (out-domain data) or by holding out a subset of classes in a categorized dataset, where one category is considered normal and the remaining categories are treated as OOD.

In the context of textual data, OOD detection techniques are applied to both classification tasks (\eg sentiment/topic classification~\cite{zhou2021contrastive, kim-etal-2023-pseudo}) and selective prediction tasks~\cite{kamath-etal-2020-selective,varshney-etal-2022-investigating, xin2021art} (\eg question answering, semantic equivalence judgments). These techniques rely on various algorithmic solutions including outlier exposure~\cite{zeng2021adversarial, hu2021outlier}, data augmentation~\cite{zheng2020aug, zhan-etal-2021-scope}, contrastive learning~\cite{zhou2021contrastive, 10.1109/TASLP.2022.3162081}, \etc. Compared to traditional neural-based language models, pre-trained Transformer-based~\cite{vaswani2017attention} models exhibit greater robustness to distributional shifts and are more effective in identifying OOD instances~\cite{hendrycks2020pretrained, xu-etal-2021-unsupervised}. Besides the out-domain data, text-based OOD detection also consider syntactic OOD data~\cite{mai2022self} due to the intrinsic characteristics of sentences. Syntactic OOD and ID data come from the same domain, but the syntactic OOD data has its word order shuffled, which allows for the measurement of OOD detectors' sensitivity to underlying syntactic information while preserving word frequency.


Some studies~\cite{sun2020real, wang2021radar} have explored the incorporation of multi-modal data into neural-based models to improve OOD detection accuracy. Recently, CLIP-based methods~\cite{fort2021exploring, ming2022delving,esmaeilpour2022zero} have emerged as a promising approach for OOD detection by leveraging vision-language bimodal data, exhibiting superior performance over uni-modal data only. The main intuition behind these approaches is to take advantage of the alignment between visual classes or concepts and their textual descriptions. For instance, Ming et al.~\cite{ming2022delving} detect visual OOD in an unsupervised manner by matching visual features with known ID concepts in the corresponding textual descriptions. 

However, these studies typically focus on detecting OOD data from at most two scenarios (\ie out-domain and shuffled-text OODs) within a \textit{single} modality. Even multi-modal approaches are often limited to detecting only visual OODs by additionally considering accompanying textual descriptions. Our proposed approach aims to effectively identify OOD samples from four distinct scenarios across \textit{two} modalities (\ie NL and PL). To achieve this, we utilize a combination of different scoring functions from two different modules: cosine similarities of a contrastive learning module and prediction probabilities of a binary OOD classifier. % Conversely, most ML OOD detectors typically consist of only one module~\cite{zhou2021contrastive, liu2020energy}.


%\shao{Add a sentence to state the limitation of existing works. ``However, existing work only consider one or two OOD scenarios''} \shao{We need to summarize the difference of this work and existing works. For example, ``In summary, while OOD detection has been widely studied in the ML community, but it remains unexplored in code-based OOD detection. Moreover, existing OOD detection methods in ML community only consider at most two scenarios, but we focus on 4 different OOD scenarios. Namely, we add two more ....''}\denys{agree, this should clearly spell out the contribution and put to rest the comments on how this is different from ML OOD papers}

%However, all existing studies for visual/textual/multi-modal OOD detection in the ML community do not address code-based OOD detection. %Given the success of multi-modal data and pre-trained language models in OOD detection, we utilize the bimodal (comment, code) pair for code-based OOD detection based on contrastive learning.  Furthermore, we identify OOD samples from four OOD scenarios, while existing work in ML only consider two.  

%in out-of-domain and syntactic NL/comment settings, but also design two more OOD scenarios: namely the syntactic OOD code (\ie buggy/defective code) to accommodate code context, and the misalignment between comment and code.

% For example, Qiu \etal ~\cite{qiu2022unsupervised} introduced an unsupervised contrastive method that employs generative adversarial networks to extract latent features from five modalities, significantly enhancing the precision of detecting abnormal driving segments. More 