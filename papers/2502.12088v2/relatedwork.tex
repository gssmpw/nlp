\section{Related Work}
The idea of processing multiple data points simultaneously originates from multi-instance learning, where models receive sets of instances and assign labels at the group level \cite{maron1997framework, dietterich1997solving, ilse2018attention}. Once datasets can be meaningfully represented by neural networks, amortized learning techniques allowing models to generalize quickly to new datasets naturally emerge \cite{ganguly2023amortized, lopez2015towards, kim2024targeted}.

A notable example is the \textit{neural statistician} framework \cite{edwards2017towards}, which employs variational autoencoders (VAEs) to learn dataset representations in an unsupervised manner. Similarly, \citet{hewitt2018variational} applied VAEs to infer generative models from few data points. The concept of learning dataset-level representations has also been explored through meta-features \cite{jomaa2021dataset2vec, kotlar2021novel, 10136150}, where models extract high-level statistics tailored for specific tasks. For instance, \citet{kotlar2021novel} learned meta-features for anomaly detection, while \citet{wu2022learning} trained models to predict dataset-level statistics such as the number of distinct values. Recently, \citet{hollmann2025accurate} employed transformers trained on synthetic datasets for missing value imputation, which we recognize as an instance of meta-statistical learning in low-sample-size settings.

Approaches of a meta-statistical nature have also been successfully applied in causal discovery \cite{lopez2015towards, lowe2022amortized, lorch2022amortized, wu2024sample}. These methods generate synthetic data with known causal structures and train neural networks to infer causal properties from a set of observations \cite{kelearning}. For example, \citet{kim2024targeted} proposed an attention-based model trained on simulated datasets to identify causal parents of target variables. Meta-statistical learning is a type of amortized learning focused on estimating statistical parameters; it builds upon and generalizes these previous works. 

\xhdr{Machine Learning for Statistical Inference}
Our work aligns with the broader research direction on neural processes \cite{garnelo2018neural, garnelo2018conditional,kim2019attentive, Gordon:2020, markou2022practical, huang2023practical, BruinsmaMRFAVBH23}. Neural processes can predict latent variables of interest from datasets \cite{chang2025amortized} by leveraging transformers \cite{pmlr-v162-nguyen22b} and Deep Sets \cite{NIPS2017_f22e4747} to enforce permutation invariance \cite{JMLR:v21:19-322}. A related approach, known as prior-fitted networks, has demonstrated that transformers can be effectively repurposed for Bayesian inference \cite{muller2022transformers} and optimization tasks \cite{pmlr-v202-muller23a}.

Additionally, there is growing interest in using trained models to assist in statistical inference \cite{angelopoulos2023predictionpoweredinference} and optimization \cite{NIPS2017_addfa9b7, NEURIPS2020_f52db9f7, NEURIPS2021_56c3b2c6, amos2023tutorialamortizedoptimization}. In particular, simulation-based inference benefits from neural simulations \cite{pmlr-v89-papamakarios19a, cranmer2020frontier} and amortized Bayesian inference \cite{gonccalves2020training, elsemueller2024sensitivity, radev2020bayesflow, avecilla2022neural, pmlr-v235-gloeckler24a}. Amortized Bayesian inference typically replaces probabilistic inference with a neural network prediction task \cite{chan2018likelihood, chen2023learning, chen2020neural}. These previous work illustrate the feasibility of learning distribution-relevant parameters via maximum likelihood using permutation-invariant dataset representations. In this work, we identify the emerging theme: translate complex statistical inference problems and into the powerful and flexible framework of supervised learning. We then undertake a study of this paradigm from the ground up and investigate parameter efficient dataset encoders like the Set Transformer \cite{lee2019set,zhang2022set}.

\xhdr{Relationship to Meta-Learning}
Meta-learning, or \textit{learning to learn}, is a paradigm focused on generalizing across tasks drawn from different distributions \cite{schmidhuber1996simple, hospedales2021meta, huisman2021survey}. Meta-learning seeks to acquire transferable meta-knowledge, enabling rapid adaptation to new tasks \cite{schmidhuber1987evolutionary, thrun1998lifelong, schmidhuber1993neural, vanschoren2019meta}. A broad range of approaches exist \cite{vinyals2016matching, santoro2016meta, finn2017model, snell2017prototypical}, some emphasizing dataset-level processing to extract useful representations \cite{mishra2017simple, ravi2017optimization, munkhdalai2017meta, shyam2017attentive}. This is particularly relevant in few-shot learning \cite{finn2017model, snell2017prototypical, wang2023few, wu2020meta, rivolli2022meta}. 
Notably, neural processes represent a class of meta-learners that use a meta-distribution over functions, adapting their prior to new datasets using observed input-output pairs \cite{garnelo2018neural, garnelo2018conditional, kim2019attentive}.
% 
Meta-statistical learning shares conceptual similarities with meta-learning, as both focus on generalization across distributions. However, while the target of meta-learning remains instance-level predictions, meta-statistical learning emphasizes distributional properties. These paradigms are complementary: insights from dataset-level analysis can directly improve generalization in meta-learning \cite{jomaa2021dataset2vec, kotlar2021novel, kobalczyk2025automatedknowledgeintegrationhumaninterpretable}.