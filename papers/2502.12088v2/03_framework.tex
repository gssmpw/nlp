\subsection{Background: Supervised Learning}
Supervised learning aims to find a function \( f: \mathcal{X} \to \mathcal{Y} \) that maps input data to output labels based on a finite dataset of observations \( \mathcal{D} = \{(x_i, y_i)\}_{i=1}^n \), where \( (x_i, y_i) \in \mathcal{X} \times \mathcal{Y} \) and \( i \in \{1, \dots, n\} \). Here, \( \mathcal{X} \) denotes the input space (e.g., \( \mathbb{R}^d \) for \( d \)-dimensional data), and \( \mathcal{Y} \) denotes the output space, which is continuous for regression or discrete for classification. The data points are assumed to be i.i.d. samples from an unknown joint distribution \( P_{X,Y} \) over \( \mathcal{X} \times \mathcal{Y} \).

The function \( f \) is modeled by a parameterized family \( \{f_\theta : \theta \in \Theta\} \), where \( \theta \) represents the parameters (e.g., weights in a neural network). The quality of \( f_\theta \) is evaluated using a loss function \( L: \mathcal{Y} \times \mathcal{Y} \to \mathbb{R} \), which measures the discrepancy between predicted and true outputs. 

\xhdr{Generalization}
The goal is to minimize the expected risk: \(R(\theta) = \mathbb{E}_{(x, y) \sim P_{X,Y}}[L(f_\theta(x), y)]\), but since \( P_{X,Y} \) is unknown, the empirical risk is minimized as a proxy. 
Generalization is achievable because machine learning algorithms perform \emph{induction}, based on assumptions about the underlying structure of the data and the expectation of how new data relate to observed ones. Typically, we expect the model to generalize \textit{in distribution}, where new instances are sampled from \( P_{X,Y} \). However, we often also care about generalization \textit{out of distribution}, where new instances are sampled from a different, but related distribution.

\subsection{Meta-Statistical Learning}
Instead of learning a mapping from individual data points to their labels, \textbf{meta-statistical learning} maps entire datasets to their labels. 
Meta-statistical learning remains within standard supervised learning with the dataset being just another modality representable by a neural network. 

\xhdr{Setup and notation}
Meta-statistical learning aims to find a function $\varphi: \Gamma \to \mathcal{Y}$ that maps input datasets to labels based on a finite meta-dataset $\mathcal{S} = \{(\mathcal{D}_i, y_i)\}_{i=1}^{M}$, where $\mathcal{D}_i \in \Gamma$ is itself a dataset $\mathcal{D}_i = \{(x_{i,j})\}_{j=1}^{n_i}$. As in standard supervised learning, $\mathcal{Y}$ denotes the output space, which is continuous for regression or discrete for classification. The meta-datapoints are assumed to be sampled i.i.d. from an unknown joint meta-distribution $P_{\Gamma,Y}$, a distribution over datasets (their data-generating distribution) and their target labels.
% 
The function $\varphi$ is modeled by a parameterized family $\{\varphi_{\theta} : \theta \in \Theta\}$ that can process entire datasets as input (e.g., a recurrent neural network, convolutional neural network, or Transformer). The quality of $\varphi_{\theta}$ is still evaluated using a loss function $L_{\Gamma}: \mathcal{Y} \times \mathcal{Y} \to \mathbb{R}$. The learning objective remains to minimize the expected risk, but taken over the meta-distribution:
\[
R(\theta) = \mathbb{E}_{(\mathcal{D}, y) \sim P_{\Gamma, Y}} \left[L_{\Gamma}\left(\varphi_{\theta}(\mathcal{D}), y\right)\right].
\]

\subsection{Structure of the Meta-Generalization Problem}

To provide additional structure to the generative process that produces a meta-datapoint \( (\mathcal{D}_i, y_i) \sim P_{\Gamma, Y} \), we decompose it into two steps: (i) sample a distribution \( P_X \), and (ii) sample a dataset \( \mathcal{D}_i \sim P_X \). This process is illustrated in \Figref{fig:fig_1_large}. The label can either be a property of the dataset itself, \( y_i = A(\mathcal{D}_i) \), or a property of the distribution, \( y_i = g(P_X) \).  When the label is a property \( A \) of the dataset, we refer to it as a \textbf{descriptive} label, such as the column-wise \texttt{average}. When the label is a property \( g \) of the distribution, we refer to it as an \textbf{inferential} label, such as determining whether the dataset was sampled from a normal distribution or estimating the mutual information between two variables.

Several generalization questions arise from this setup:

(i) \textbf{Within-distribution generalization:} The function \( \varphi_{\theta} \) should generalize across different datasets resampled from the same distribution \( P_X \). In the inferential case, where the label depends only on \( P_X \), \( \varphi_{\theta} \) should produce the same prediction for all datasets of fixed size sampled from \( P_X \). The predictions of \( \varphi_{\theta} \) should not systematically overestimate or underestimate the label. This is measured by the \textbf{variance} and the \textbf{bias} of \( \varphi_{\theta} \) as a statistical estimator of \( y = g(P_X) \).

(ii) \textbf{Length generalization:} The function \( \varphi_{\theta} \) should generalize to datasets of varying lengths. Statistical inference is harder for smaller datasets, so we expect performance to improve with larger datasets. This is measured by the \textbf{consistency} of \( \varphi_{\theta} \) as a statistical estimator of \( y = g(P_X) \).

(iii) \textbf{In-meta-distribution generalization:} Similar to standard supervised learning, \( \varphi_{\theta} \) should generalize to new meta-datapoints sampled from the same meta-distribution \( P_{\Gamma, Y} \). For example, if \( \varphi_{\theta} \) is trained to predict the standard deviation of datasets sampled from exponential distributions, it should generalize to exponential distributions with unseen rate parameters.

(iv) \textbf{Out-of-meta-distribution generalization:} Analogous to out-of-distribution generalization, \( \varphi_{\theta} \) could be expected to generalize to distributions and datasets sampled from a different meta-distribution than \( P_{\Gamma, Y} \). For instance, if \( \varphi_{\theta} \) is trained on datasets from Normal, Uniform, and Exponential distributions, it can be tested on datasets sampled from Log-normal, Cauchy, or Weibull distributions.

\subsection{Related Work}
The idea of processing multiple data points simultaneously originates from multi-instance learning, where models receive sets of instances and assign labels at the group level \cite{maron1997framework, dietterich1997solving, ilse2018attention}. Once datasets can be meaningfully represented by neural networks, amortized learning techniques allowing models to generalize quickly to new datasets naturally emerge \cite{ganguly2023amortized, lopez2015towards, kim2024targeted}.

A notable example is the \textit{neural statistician} framework \cite{edwards2017towards}, which employs variational autoencoders (VAEs) to learn dataset representations in an unsupervised manner. Similarly, \citet{hewitt2018variational} applied VAEs to infer generative models from few data points. The concept of learning dataset-level representations has also been explored through meta-features \cite{jomaa2021dataset2vec, kotlar2021novel, 10136150}, where models extract high-level statistics tailored for specific tasks. For instance, \citet{kotlar2021novel} learned meta-features for anomaly detection, while \citet{wu2022learning} trained models to predict dataset-level statistics such as the number of distinct values. Recently, \citet{hollmann2025accurate} employed transformers trained on synthetic datasets for missing value imputation, which we recognize as an instance of meta-statistical learning in low-sample-size settings.

Approaches of a meta-statistical nature have also been successfully applied in causal discovery \cite{lopez2015towards, lowe2022amortized, lorch2022amortized, wu2024sample}. These methods generate synthetic data with known causal structures and train neural networks to infer causal properties from a set of observations \cite{kelearning}. For example, \citet{kim2024targeted} proposed an attention-based model trained on simulated datasets to identify causal parents of target variables. Meta-statistical learning is a type of amortized learning focused on estimating statistical parameters; it builds upon and generalizes these previous works. 

\xhdr{Machine Learning for Statistical Inference}
Our work aligns with the broader research direction on neural processes \cite{garnelo2018neural, garnelo2018conditional,kim2019attentive, Gordon:2020, markou2022practical, huang2023practical, BruinsmaMRFAVBH23}. Neural processes can predict latent variables of interest from datasets \cite{chang2025amortized} by leveraging transformers \cite{pmlr-v162-nguyen22b} and Deep Sets \cite{NIPS2017_f22e4747} to enforce permutation invariance \cite{JMLR:v21:19-322}. A related approach, known as prior-fitted networks, has demonstrated that transformers can be effectively repurposed for Bayesian inference \cite{muller2022transformers} and optimization tasks \cite{pmlr-v202-muller23a}.

Additionally, there is growing interest in using trained models to assist in statistical inference \cite{angelopoulos2023predictionpoweredinference} and optimization \cite{NIPS2017_addfa9b7, NEURIPS2020_f52db9f7, NEURIPS2021_56c3b2c6, amos2023tutorialamortizedoptimization}. In particular, simulation-based inference benefits from neural simulations \cite{pmlr-v89-papamakarios19a, cranmer2020frontier} and amortized Bayesian inference \cite{gonccalves2020training, elsemueller2024sensitivity, radev2020bayesflow, avecilla2022neural, pmlr-v235-gloeckler24a}. Amortized Bayesian inference typically replaces probabilistic inference with a neural network prediction task \cite{chan2018likelihood, chen2023learning, chen2020neural}. These previous work illustrate the feasibility of learning distribution-relevant parameters via maximum likelihood using permutation-invariant dataset representations. In this work, we identify the emerging theme: translate complex statistical inference problems and into the powerful and flexible framework of supervised learning. We then undertake a study of this paradigm from the ground up and investigate parameter efficient dataset encoders like the Set Transformer \cite{lee2019set,zhang2022set}.

\xhdr{Relationship to Meta-Learning}
Meta-learning, or \textit{learning to learn}, is a paradigm focused on generalizing across tasks drawn from different distributions \cite{schmidhuber1996simple, hospedales2021meta, huisman2021survey}. Meta-learning seeks to acquire transferable meta-knowledge, enabling rapid adaptation to new tasks \cite{schmidhuber1987evolutionary, thrun1998lifelong, schmidhuber1993neural, vanschoren2019meta}. A broad range of approaches exist \cite{vinyals2016matching, santoro2016meta, finn2017model, snell2017prototypical}, some emphasizing dataset-level processing to extract useful representations \cite{mishra2017simple, ravi2017optimization, munkhdalai2017meta, shyam2017attentive}. This is particularly relevant in few-shot learning \cite{finn2017model, snell2017prototypical, wang2023few, wu2020meta, rivolli2022meta}. 
Notably, neural processes represent a class of meta-learners that use a meta-distribution over functions, adapting their prior to new datasets using observed input-output pairs \cite{garnelo2018neural, garnelo2018conditional, kim2019attentive}.
% 
Meta-statistical learning shares conceptual similarities with meta-learning, as both focus on generalization across distributions. However, while the target of meta-learning remains instance-level predictions, meta-statistical learning emphasizes distributional properties. These paradigms are complementary: insights from dataset-level analysis can directly improve generalization in meta-learning \cite{jomaa2021dataset2vec, kotlar2021novel, kobalczyk2025automatedknowledgeintegrationhumaninterpretable}.