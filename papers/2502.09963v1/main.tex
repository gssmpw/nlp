% CVPR 2025 Paper Template; see https://github.com/cvpr-org/author-kit

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage{cvpr}
\usepackage{algorithm}
\usepackage{algorithmic}
% \usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Import additional packages in the preamble file, before hyperref
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\todo}[1]{{\color{red}#1}}
\newcommand{\TODO}[1]{\textbf{\color{red}[TODO: #1]}}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, 
% e.g. with the file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete *.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
%\def\paperID{1666} % *** Enter the Paper ID here
%\def\confName{CVPR}
%\def\confYear{2025}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Generating on Generated: An Approach Towards Self-Evolving Diffusion Models}
% \title{RSIDiff - Approaching Recursive Self-Improvement of Diffusion Models with Synthetic Data}
%\title{Approaching Recursive Self-Improvement of Diffusion Models with Distributional Alignment}
% \title{Achieving Recursive Self-Improvement of Diffusion Models with Active Learning}

%%%%%%%%% AUTHORS - PLEASE UPDATE
% \author{Xulu Zhang\\
% PolyU\\
% CAIR, HKISI, CAS\\
% {\tt\small compxulu.zhang@connect.polyu.hk}
% % For a paper whose authors are all at the same institution,
% % omit the following lines up until the closing ``}''.
% % Additional authors and addresses can be added with ``\and'',
% % just like the second author.
% % To save space, use either the email address or home page, not both
% \and
% Xiaoyong Wei\\
% PolyU\\
% %{\tt\small secondauthor@i2.org}
% \and
% Jinlin Wu\\
% CAIR, HKISI, CAS\\
% CASIA\\
% \and
% Jiaxin Wu\\
% PolyU\\
% \and
% Zhaoxiang Zhang\\
% CASIA\\
% UCAS\\
% CAIR, HKISI, CAS\\
% \and
% Zhen Lei\\
% CASIA\\
% UCAS\\
% CAIR, HKISI, CAS\\
% \and
% Qing Li\\
% PolyU\\
% }

\author{
Xulu Zhang\textsuperscript{1,2},
Xiaoyong Wei\textsuperscript{1},
Jinlin Wu\textsuperscript{2,3},
Jiaxin Wu\textsuperscript{1},
Zhaoxiang Zhang\textsuperscript{2,3,4},
Zhen Lei\textsuperscript{2,3,4},
Qing Li\textsuperscript{1} \\
}
\twocolumn[{
\maketitle

\begin{center}
    %\vskip -0.2in
    \textsuperscript{1}The Hong Kong Polytechnic University, Hong Kong \\
    \textsuperscript{2}CAIR, HKISI, CAS, Beijing \\
    \textsuperscript{3}UCAS, Beijing \\
    \textsuperscript{4}CASIA, Beijing
    \captionsetup{type=figure}
    %
    \vspace{2pt}
    \includegraphics[width=.95\textwidth]{figures/super_figure.pdf}
    \captionof{figure}{We introduce RSIDiff, a novel approach that enhances the performance of diffusion models through recursive self-training. By iteratively refining the model with its own generated data, RSIDiff produces images of noteworthy aesthetic quality.}
    % \captionof{figure}{Images generated by our proposed method RSIDiff, a novel approach that enhances the perceptual alignment and reduces hallucinations of diffusion models through recursive self-training. }
\end{center}
}]

\begin{abstract}
\vskip -0.1in
    Recursive Self-Improvement (RSI) enables intelligence systems to autonomously refine their capabilities. This paper explores the application of RSI in text-to-image diffusion models, addressing the challenge of training collapse caused by synthetic data. We identify two key factors contributing to this collapse: the lack of perceptual alignment and the accumulation of generative hallucinations.
    %
    To mitigate these issues, we propose three strategies: (1) a prompt construction and filtering pipeline designed to facilitate the generation of perceptual aligned data, (2) a preference sampling method to identify human-preferred samples and filter out generative hallucinations, and (3) a distribution-based weighting scheme to penalize selected samples with hallucinatory errors. Our extensive experiments validate the effectiveness of these approaches.
    %
    %The source code is available at https://release\_upon\_acceptance.
    % in improving alignment with human performance
\end{abstract}

\section{Introduction}
% Recently, we have witnessed rapid advancements in generative models, like ChatGPT [] or Diffusion Models [], which significantly enhance the quality and diversity of synthetic data.
% %
% The ease of generated data has made it a convenient way to acquire large-scale datasets for training automated models [], especially in scenarios where collecting real data is expensive and human-labored [].
% %
% Beyond helping the improvement of the automatic recognition systems, another interesting question arises: 
% %
% \textit{Is this the time for us to leverage synthetic data to enhance the original generative model itself, thereby achieving recursive self-improvement (RSI)?} 

% This question has recently gained considerable attention. However, the findings may be disappointing.
% %
% Simply unbiased sampling generated data not only cannot improve the model itself but also poisons the system [].
% %
% This is attributed to the limited model expression ability and the inevitable distributional difference between real data and synthetic data, which cause the error compounding over recursive training [].
% %
% Consequently, in multiple iterations, even a small number of generated samples can amplify these errors, leading the original model to exacerbate sample artifacts [] or even cause training collapse [].

% % To solve this problem, a straightforward way is to select the most informative samples for recursive training.
% To solve this problem, biased sampling is necessary to achieve RSI.
% %
% This has been widely discussed in the field of active learning, where query strategies are designed to find the fewest helpful samples for maximum performance gain.
% %
% Applying active learning to achieve RSI shows possibility.
% %
% However, applying active learning to generative models still faces challenges.
% %
% Specifically, traditional active learning primarily focuses on discriminative models.
% %
% The data selection is often based on information entropy [] or representation degree [], which requires comparison with decision boundary or sample clustering.
% %
% In other words, these sampling strategies are bound with the target model and implemented at feature-level spaces.
% %
% In contrast, current data selection in generative models is typically conducted from an isolated high-level comparison.
% %
% Typically, pre-defined metrics are used to select samples by evaluating their quality, like text-image alignment [], image fidelity [], and aesthetics [].
% %
% Although these methods aim to minimize function expressiveness errors, they still lack a reasonable explanation to tell how far the selected sample can contribute to the models.
% %
% Some selected high-quality samples may exhibit compelling results but contribute little to the RSI.
% %
% This results in limited performance gain with extensive resource waste.
% %
% In this paper, we focus on diffusion models, a popular choice for text-to-image generation, and utilize active learning to explore the potential of RSI.

% To address this issue, we propose a sample sampling and weight redistribution scheme based on distribution measurement. Using the sample distribution generated by a pre-trained initial model as a baseline, we measure the deviation of generated samples in subsequent iterations. We employ two sampling strategies—deviation and quality filtering—to reduce sample errors and distribution shifts. Deviation serves as a dynamic adjustment factor for sample contribution during training, ultimately achieving self-improvement in text-to-image models.

% Our contributions are as follows:
% We explore the feasibility of self-improvement in text-to-image models.
% We pioneer the application of active learning concepts to enhance text-to-image models in general scenarios.
% We propose a distribution-based sample sampling and weight allocation scheme, combined with quality filtering as a query strategy.
% Extensive experiments demonstrate the feasibility of self-improvement in text-to-image models.

% Recursive Self-Improvement (RSI) is becoming an increasingly vital concept in the realm of machine learning []. By enabling models to refine their own capabilities through iterative processes, RSI facilitates a significant leap in performance and adaptability. As researchers work toward the development of large models that can surpass human intelligence, particularly in the context of Artificial General Intelligence (AGI), RSI becomes essential [].

% Simultaneously, diffusion models have demonstrated the ability to generate compelling and diverse samples, facilitating a wide range of applications, such as image generation, video synthesis, and personalization. This raises an important but overlooked question: \textit{Is now the time to leverage synthetic data to enhance diffusion models themselves, thereby achieving recursive self-improvement?}

The concept of self-evolving generative models \cite{tao2024survey} holds increasing significance within the realm of machine learning. 
%
Recently, Recursive Self-Improvement methods \cite{schmidhuber2003godel,yampolskiy2015seed,nivel2013bounded,steunebrink2016growing} have garnered substantial attention. 
%
RSI strives for superintelligence by empowering artificial general intelligence systems to autonomously enhance their own capabilities.
%
This approach has been exemplified by systems like AlphaGo \cite{silver2016mastering}, which utilize self-play to significantly improve decision-making capabilities, ultimately defeating human champions. 
%
Moreover, there has been growing interest in applying RSI to language models (LMs) \cite{zelikman2022star,gou2023critic,yuan2024self,chen2024self}. 
%
By incorporating RSI, LMs can iteratively improve their linguistic understanding, leading to more nuanced and contextually aware interactions. % and adaptability

Recently, diffusion models have emerged as a prominent area of research. 
%
By employing denoising strategies and pre-training on large-scale datasets, advanced methods, such as DALL-E 2 \cite{ramesh2022hierarchical} and Stable Diffusion \cite{rombach2022high}, have shown a remarkable capacity for generating compelling and diverse samples. 
%
However, the scarcity of reliable data and growing privacy concerns present significant challenges to the ongoing advancement of these models. 
%
% In this context, leveraging RSI to incorporate synthetic data into the enhancement of generative models becomes not just beneficial but essential.
In this context, RSI becomes a promising solution, where models could leverage synthetic data for continuous self-evolving while addressing both data availability and privacy issues.

Despite its potential, implementing RSI in diffusion models through self-training presents technical challenges. 
%Current research has started to focus on using generated data for recursive self-training.
%
The primary one is the training collapse \cite{shumailov2024ai,dohmatob2024strong,alemohammad2023self}, which frequently occurs during fine-tuning with randomly selected data.
%
This collapse results in the production of defective outputs, creating a detrimental feedback loop where poor results hinder further model refinement.
%
We also observe a similar outcome when training diffusion models with their own generated data. 
%
As illustrated in \cref{fg:domain_shift}, there is a noticeable increase in artifacts in the generated images.
% decline in the fidelity of the generated subject.
%
The diffusion model gradually loses the ability to depict fine-grained details and can only generate the rough contour of the desired dog.
%
Additionally, we notice an evident distribution shift accompanying this image degradation.

In this paper, we attribute the model collapse to the lack of \textbf{perceptual alignment} and the compounding of \textbf{generative hallucinations}. 
%
Specifically, \textbf{perceptual alignment} refers to the ability of the model to generate outputs that closely match human preferences and expectations, such as accurately depicting the style and context of a given prompt.
%to the valuable knowledge that the base model can acquire, such as the style painting skills.
%
However, due to the inherent randomness of diffusion models, the number of unsatisfactory samples generated often far exceeds that of human-preferred ones.
%
% As a result, random sampling struggles to uncover valuable outputs, ultimately failing to provide perceptual-aligned information for self-improvement.
As a result, random sampling struggles to provide perceptual-aligned information for self-improvement.
%
Conversely, \textbf{generative hallucinations} frequently exist in out-of-distribution samples, such as ``dog with five legs'' or ``human with seven fingers''. These flawed images are included in the training data through random sampling and poison the model training. This sustained accumulation eventually results in the domain shift and degraded generation quality.
%
Therefore, it is essential to explore strategies that avoid generative hallucinations in generated data while enhancing perceptual alignment to promote continuous improvement.


To address these challenges, we propose that the diffusion model needs a mechanism to control its perceptual alignment and reduce the generative hallucinations when performing RSI. 
%
To this end, we review the training process of text-to-image diffusion models and find that the quality of the text prompt and its corresponding generated image highly impact the model evolution.
%
Driven by this intuition, we introduce a mechanism focusing on both data quality and distribution to construct better prompt-(synthetic)image pairs to control the self-evolving process. 
%
For data quality, we design a pipeline for high-quality prompt construction. This process aims to provide clear, specific, and diverse prompts to improve the perceptual alignment of synthetic images. 
% highly improves the frequency of human-preferred data.
%
In addition, we introduce a preference sampling strategy aimed at selectively curating the synthetic data with fewer hallucinations and better human preference scores.
% which reduces the inclusion of generative hallucinations and identifies the samples aligned with human preferences.
%
For the data distribution, we propose a distribution-based weighting scheme to penalize the out-of-distribution samples. This minimizes the impact of potential hallucinatory errors.
%
% The framework is shown in \cref{fg:framework}.
%
The overview of the three proposed strategies are visualized in \cref{fg:framework} (a), (b), and (c), respectively. 
%
% \cref{fg:framework} (d) shows the incorporation of three strategies to the text-to-image diffusion model training. 
%
Through these methods, we aim to build a robust, effective, and controllable RSI process for diffusion models.

\textbf{Contribution.} 
%
1) We conduct a pilot study exploring the application of RSI in text-to-image diffusion models;
%
2) We propose three approaches designed to promote perceptual alignment while minimizing the impact of generative hallucinations;
%
3) We perform extensive experiments to validate the effectiveness of the proposed approaches.

\begin{figure}[t]
\centering
\centerline{\includegraphics[width=0.93\linewidth]{figures/domain_shift.pdf}}
\caption{\textbf{Degeneration in RSI.} We observe a severe domain shift and decline in image fidelity when fine-tuning diffusion models with self-generated data. The diffusion model gradually loses the ability to generate fine-grained details.}
\label{fg:domain_shift}
\vskip -0.1in
\end{figure}

\begin{figure*}[t]
\begin{center}
\centerline{\includegraphics[width=0.93\linewidth]{figures/framework.pdf}}
\caption{\textbf{Framework of RSIDiff.} (a) We crawl Prompts from user-active image synthesis website and filter them based on clarity, specificity, and diversity; (b) We employ preference sampling, which utilizes automatic metrics to identify human-preferred images; (c) We use the distribution-based weighting strategy to penalize out-of-distribution samples; and (d) We fine-tune the diffusion model with the selected samples and start a new training round.}
\label{fg:framework}
\end{center}
\vskip -0.2in
\end{figure*}


\section{Related Work}
\subsection{Recursive Self-Improvement}
RSI was first introduced to solve harder problems through iterative refinement \cite{schmidhuber2003godel}.
%
A significant sub-area is the use of synthetic data for self-retraining, which has gained much discussion about its associated challenges.
%
For instance, \cite{shumailov2024ai} demonstrates that iterative training of models like OPT-125M \cite{zhang2022opt} with synthetic text can lead to severe distribution shifts.
%
Similarly, \cite{dohmatob2024strong} has found that even a small number of synthetic samples can cause significant large model collapse during training.
%
Meanwhile, \cite{alemohammad2023self} reports substantial degradation in the quality of generated samples when using synthetic images to train StyleGAN2 \cite{karras2020analyzing} and DDPM models \cite{ho2020denoising}.

Despite these challenges, recent work by Meta \cite{yuan2024self} has proven the feasibility of RSI with synthetic data. They propose a self-rewarding model that utilizes large language models (LLMs) to generate responses and corresponding rewards based on a generated prompt set. These sample pairs are then used for Direct Preference Optimization (DPO) \cite{rafailov2024direct}.
%
While these studies have effectively highlighted the challenges in RSI using synthetic data, they have not specifically discussed state-of-the-art (SoTA) text-to-image models.
%
In contrast, this paper aims to address these gaps by focusing on the application of RSI to SoTA diffusion models and providing practical solutions.

% 除了使用合成数据训练自己，目前还有其他的自我提升的策略，这些方法主要使用了
In addition to using synthetic data, there has been other exploration of self-improvement strategies. 
%
These methods primarily utilize self-critique mechanisms \cite{madaan2024self,chen2023teaching,welleckgenerating,han2024small,miao2023selfcheck}, where the model refines its response based on its own feedback. 
%
However, these dialogue-based methods cannot be directly applied in the context of text-to-image models.

\subsection{Human Preference Alignment}
In recent advancements of text-to-image models, a primary focus has been on enhancing alignment with human preferences. 
%
This typically requires extensive pre-training on high-quality image-text pairs \cite{betker2023improving,esser2024scaling}.
%
Another research branch focuses on fine-tuning pre-trained models to yield better results.
%
For example, \cite{dai2023emu} fine-tunes SDXL \cite{podell2023sdxl} with 2,000 high-quality samples, which are filtered from a 1.1 billion dataset.
%
Additionally, some methods leverage reinforcement learning during the tuning phase. 
%
For example, DDPO \cite{black2023training} and DPOK \cite{fan2024reinforcement} have trained a reward model to guide the optimization, while Diffusion-DPO \cite{wallace2024diffusion} and D3PO \cite{yang2024using} propose the implicit reward functions to fine-tune diffusion models directly on the preference dataset.
%
However, there remains limited exploration into the potential of using self-generated data for further improvement.

Meanwhile, a variety of human preference datasets and evaluation metrics have been developed. Pic-a-pic dataset \cite{kirstain2023pick} features 583,747 image pairs for binary comparison, and the HPD v2 dataset \cite{wu2023human} includes 798,090 human preference choices across 433,760 image pairs. 
%
The evaluation metrics for assessing human preferences are also advanced significantly, including PickScore \cite{kirstain2023pick}, Human Preference Score (HPS) \cite{wu2023humanhps}, HPS v2 \cite{wu2023human}, and image rewards \cite{xu2024imagereward}. 
%
These together provide a robust framework for evaluating how well generated content aligns with human expectations.


\begin{algorithm}[tb]
   \caption{RSIDiff Procedure}
   \label{alg:rsidiff_procedure}
\begin{algorithmic}
   \STATE {\bfseries Input:} Base model $\mathcal{G}_0$, prompt set $\mathcal{P}=\left \{ \mathcal{P}_0, \mathcal{P}_1, ...,\mathcal{P}_r \right \}$, total training round $r$.
   \STATE Initialize current training round $i=0$.
   \REPEAT
   \STATE Generate synthetic dataset $\mathcal{D}_i$ using prompt set $\mathcal{P}_i$ with the diffusion model $\mathcal{G}_i$.
   \STATE Apply preference sampling to obtain the synthetic training set $\mathcal{S}_i$ from dataset $\mathcal{D}_i$.
   \STATE Calculate the sample weights $\mathcal{W}_i$ of training set $\mathcal{S}_i$.
   \STATE Fine-tune the model $\mathcal{G}_i$ with weighted training set $(\mathcal{W}_i\circ\mathcal{S}_i,\mathcal{P}_i)$ and get the updated model $\mathcal{G}_{i+1}$.
   \STATE Update current training round $i=i+1$.
   \UNTIL{Round $i$ reaches the total training round $r$.}
\end{algorithmic}
\end{algorithm}

\section{Method}

\subsection{Problem Definition}
Given a base model $\mathcal{G}_0$, RSI aims to enhance the performance of target models through iterative refinement.
%
At each round $i$, the model generates a set of synthetic data $\mathcal{D}_i$ based on the current prompt set $\mathcal{P}_i$. This generated data serves as the primary input for the subsequent training phase within the RSI loop.
%
The fine-tuning process can be formulated as follows:
%
\begin{equation}
    \theta_{i+1}=f(\theta_i, \mathcal{D}_i, \mathcal{P}_i),
\end{equation}
where $\theta_i$ denotes the target model parameters at round $i$, and $f$ is a function that updates the model based on the received data and associated loss feedback.

In this paper, we focus on the RSI of diffusion models. The diffusion process consists of two main steps: a noise-adding step in the forward process and a denoising step in the reverse process. During the forward process, Gaussian noise is incrementally added to the input data $x_0$, resulting in a noisy latent representation given by

\begin{equation}
    x_t=\sqrt{\alpha_t} x_{t-1}+\sqrt{1-\alpha_t}\epsilon_t, 
\end{equation}
where $\alpha_t$ controls the variance of the added noise $\epsilon_t$. The reverse process, denoted as $\hat{x_{\theta}}(x_{t}, t, c)$, aims to denoise the noisy latent $x_t$ based on the current timestep $t$ and the prompt condition $c$.

Consequently, the update function $f$ can be written as:

\begin{equation}
\label{eq:update}
    f(\theta, \mathcal{D}, \mathcal{P}) = \min_\theta\frac{1}{|\mathcal{D}|}\sum_{x_0 \in \mathcal{D}, c \in \mathcal{P}} \mathbb{E}\left [ \lambda_{t}||\hat{x_{\theta}}(x_{t}, t, c)- x_0) ||^ {2} \right ]
\end{equation}
where $\lambda_{t}$ is a time-dependent weighting factor. The goal is to minimize the difference between the denoised output and the original data, thereby refining the model's capability with synthetic data.

\begin{figure}[t]
\begin{center}
\centerline{\includegraphics[width=0.98\linewidth]{figures/prompt_sample.pdf}}
\caption{Examples generated by SD v1.4 with a simple prompt (left) and our filtered prompt (right). The latter produces a more visually appealing image.}
\label{fg:prompt_samples}
\end{center}
\vskip -0.2in
\end{figure}

\subsection{Better Prompts}
Recently, text-to-image models have shown significant improvements when trained with highly descriptive image captions \cite{betker2023improving,esser2024scaling}. 
%
In the context of RSI, the prompts used for synthetic image generation not only guide the model in producing images but also serve as captions in subsequent training iterations.
%
Additionally, due to the random nature of diffusion models, well-designed prompts can significantly increase the likelihood of generating outputs that align with human preferences. 
%
As illustrated in \cref{fg:prompt_samples}, we compare generations from two types of prompts and carefully crafted prompts yield visually appealing results.

To acquire such high-quality prompts, we utilize a dataset of 172k prompts collected from the Lexica website, where users share preferred synthetic images and corresponding prompts. 
%
% This ensures the underlying preferences of synthetic data with the collected prompts.
%
To further optimize the efficacy of these prompts, we propose a structured filtering approach that focuses on \textbf{clarity}, \textbf{specificity}, and \textbf{diversity}. 

\textbf{Clarity} reduces ambiguity in the prompts to ensure better embedding representations in the model. We achieve this by designing instructions to ask Llama 3 \cite{dubey2024llama} for filtering.

\textbf{Specificity} includes detailed attributes and contexts that accurately represent the desired image, which is also implemented through Llama 3 filtering.

\textbf{Diversity} guarantees a wide range of scenarios in the prompts to promote a comprehensive learning procedure. We implement this by using K-means clustering \cite{ahmed2020k} to categorize prompt embeddings into distinct groups. Prompts that are closest to the cluster centers are selected.

Through this human-aligned prompt construction process and quality-oriented filtering strategy, we extract 40k prompts that significantly improve the perceptual alignment of synthetic images and benefit the following methods. 


\subsection{Preference Sampling}
Recent research has shown that using random sampling methods can lead to model collapse.
%
In this paper, we explain this phenomenon by analyzing the two impacts from generated samples: \textbf{perceptual alignment} and \textbf{generative hallucinations}. 
%
\textbf{Perceptual alignment} provides the human-preferred information exhibited in the generated samples that enhances the model's abilities.
%
In contrast, \textbf{generative hallucinations} are negative information arising from defective data that hinder model training.
%
As we have discussed, random sampling fails to find valuable samples for model optimization while simultaneously introducing generative hallucinations. 
%
This leads to the accumulation of errors through iterative training processes and causes severe distribution shifts and overall performance degradation.
%

To address these challenges, this paper proposes a preference sampling strategy to identify preferred data and filter out flawed samples.
% Since more and more text-to-image methods target user experience, 
%
Specifically, we employ automated metrics to evaluate the preference of the synthetic data. These metrics encompass various aspects, including the alignment between text prompts and corresponding generated images \cite{radford2021learning}, aesthetic quality \cite{schuhmann2022laion}, and overall human preference scores \cite{wu2023human}. 
%
This samples a training subset $\mathcal{S}_i$ from the generated data $\mathcal{D}_i$ at round $i$. The \cref{eq:update} will be updated as follows:

\begin{equation}
    f(\theta, \mathcal{S}, \mathcal{P}) = \min_\theta\frac{1}{|\mathcal{S}|}\sum_{x_0 \in \mathcal{S}, c \in \mathcal{P}} \mathbb{E}\left [ \lambda_{t}||\hat{x_{\theta}}(x_{t}, t, c)- x_0) ||^ {2} \right ]
\end{equation}

This ensures that the filtered dataset exhibits a strong alignment with human preferences and minimizes undesired generative hallucinations.
% This sampling strategy not only reduces generative hallucinations in the generated samples by removing low-quality data but also provides a clear direction for model optimization.

\subsection{Distribution-based Sample Weight}
While preference sampling selects the generated data that aligns well with human preferences, hallucinations may still exist. 
%
To maintain continuous improvement, it is important to evaluate the contribution of each sample to model optimization. 
%
As mentioned in \cref{fg:domain_shift}, we observe that the accumulation of out-of-distribution hallucinations can lead to significant domain shifts.
%
To address this issue, we propose a distribution-based weighting scheme to assess the potential errors in the selected samples.
%
This scheme uses the samples $\mathcal{D}_0$ generated by the base model $\mathcal{G}_0$ as references to evaluate the distribution shift of selected samples $\mathcal{S}_i$.
%
In this scheme, samples that are located within the main distribution will be assigned a weight of 1, while weights will decrease for samples that are away from the main distribution.
%
The weight $w_s$ for each sample $s \in \mathcal{S}_i$ can be formulated as follows:

\begin{equation}
    w_{s}=\left\{\begin{array}{ll}
    1 & \text { if } d\left(s, \mathcal{D}_{0}\right) \leq \beta \\
    \exp \left(-\frac{d\left(s, \mathcal{D}_{0}\right)-\beta}{\sigma^{2}}\right) & \text { if } d\left(s, \mathcal{D}_{0}\right)>\beta
    \end{array}\right.
\end{equation}
where $d\left(s, \mathcal{D}_{0}\right)$ is a distance metric quantifying how far the sample $s$ is from the main distribution, $\beta$ is a predefined threshold distance, beyond which the weight begins to decrease,
$\sigma$ is a hyperparameter that controls the rate of decay for the weights of out-of-distribution samples.

The parameter update function can be written as follows:

\begin{equation}
    f(\theta, \mathcal{S}, \mathcal{P}) = \min_\theta\frac{1}{|\mathcal{S}|}\sum_{x_0 \in \mathcal{S}, c \in \mathcal{P}} \mathbb{E}\left [w_{x_0} \lambda_{t}||\hat{x_{\theta}}(x_{t}, t, c)- x_0) ||^ {2} \right ]
\end{equation}

With this weighting strategy, the in-distribution samples contribute optimally to model training while the others are penalized.
%
After a round of fine-tuning, we can evaluate the model and start a new training round. The overall framework is illustrated in \cref{fg:framework} and depicted in \cref{alg:rsidiff_procedure}.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.26\linewidth]{figures/precision_legend_only.pdf}
    \subfloat[HPS test dataset.]{\includegraphics[width=0.48\linewidth]{figures/comparison_dataset1.png}}
    \subfloat[PartiPrompts dataset.]{\includegraphics[width=0.48\linewidth]{figures/comparison_dataset2.png}}
    \caption{\textbf{Quantitative Results.} Performance comparison with the base model and SFT method across two datasets and 4 evaluation metrics. The results show that RSIDiff significantly outperforms the base model and achieves consistent improvements.}
    \label{fg:precision}
\end{figure}

% \begin{table}[t]
%   \centering
%   \begin{small}
%   \begin{tabular}{lccc}
%     \toprule
%     Evaluation Perspective  & win (\%) & tie (\%) & lose (\%) \\
%     \midrule
%     Visual Appeal & 32.7 & 52.6 & 14.7 \\
%     Text Faithfulness & 34.8 & 64.9 & 10.3\\
%     \bottomrule
%   \end{tabular}
%   \caption{\textbf{Uer Study.} Results of the user study comparing RSIDiff in the 6th round to the base model across two evaluation perspectives. The terms ``win'', ``tie'', and ``lose'' denote the samples generated by RSIDiff are preferred, regarded as equal, and less favored compared to the base model, respectively.}
%   \label{tb:user_study}
%   \end{small}
% \end{table}

\begin{table}[t]
  \centering
  \begin{small}
  \begin{tabular}{lccc}
    \toprule
    Compared Method  & Visual Appeal & Text Faithfulness \\
    \midrule
    Base Model & 69.0\% & 77.2\% \\
    SFT & 59.8\% & 64.9\% \\
    \bottomrule
  \end{tabular}
  \caption{\textbf{User Study.} The percentage of user preference on RSIDiff (6th round) compared to the base model and SFT method.}
  \label{tb:user_study}
  \end{small}
\end{table}

\begin{figure*}[t]
\begin{center}
\centerline{\includegraphics[width=0.94\linewidth]{figures/sd_samples.pdf}}
\caption{\textbf{Qualitative Results.} Examples generated by the base model (SD v1.4), SFT method, and RSIDiff at 6th round. The results illustrate RSIDiff's superior performance in several areas: effective centering of concepts (1st row), generation of intricate details (2nd row), better alignment with text prompts (3rd row), and enhanced understanding of artistic styles (4th row).}
\label{fg:sd_samples}
\end{center}
\vskip -0.2in
\end{figure*}

\vskip -0.1in
\section{Experiments}
\subsection{Experimental Setting}
\textbf{Datasets.} 
We conduct experiments using two representative datasets: PartiPrompts \cite{yu2022scaling} and HPS test \cite{wu2023human}.
%
The PartiPrompts dataset consists of 1,633 prompts that cover a variety of categories and challenges.%, providing a diverse testing ground for our models.
%
The HPS test dataset includes 3,200 prompts designed to evaluate four key aspects of text-to-image models: Animation, Concept Art, Painting, and Photo. For each prompt, we generate 10 images, resulting in a total of 4,8330 images per round.

\textbf{Evaluation Metrics.} We utilize four metrics: 
%
1) \textit{Text-alignment} evaluates how well the generated images correspond to textual descriptions. We implement it by measuring the similarity between the CLIP image features and the corresponding text features.
%
2) \textit{HPS v2} \cite{wu2023human} is an upgraded version of the human preference scorer \cite{wu2023humanhps}. In this paper, we utilize version 2.1.
%
3) \textit{PickScore} \cite{kirstain2023pick} is a CLIP-based preference scorer trained on the Pic-a-pic dataset \cite{kirstain2023pick}.
%
4) \textit{ImageReward} \cite{xu2024imagereward} is another preference scoring function.
% that evaluates the model's alignment with human preferences  to predict human preferences
% 5) \textit{Aesthetic} assesses the aesthetic quality of the generated images. , which is trained on a large human preference dataset using CLIP architecture

\textbf{Hyperparameters.}
We use Stable Diffusion 1.4 \cite{rombach2022high} as the base model for self-improvement. In each training round, we generate images with 5k prompts and select 300 samples as the training set. The model is fine-tuned with batch size of 12 and learning rate of $1e^{-6}$ over 30 epochs. This process is recursively applied for a total of 8 rounds.

For the distribution-based weighting scheme, the parameters $\beta$ and $\sigma^2$ are set to 35 and 2, respectively. We employ the Variational Autoencoder (VAE) from SD v1.4 as the image encoder to calculate the mean value of distances between the selected samples and the reference dataset $\mathcal{D}_0$.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/ablation/legend_only.png}
    \subfloat[Evaluation on HPS test dataset.]{\includegraphics[width=0.93\linewidth]{figures/ablation/ablation_dataset1.png}} \\
    \subfloat[Evaluation on PartiPrompts dataset.]{\includegraphics[width=0.93\linewidth]{figures/ablation/ablation_dataset2.png}}
    \caption{\textbf{Ablation studies.} We compare RSIDiff with four configurations on the HPS test and PartiPrompts datasets. The results demonstrate that RSIDiff achieves superior recursive improvement while removing any individual strategy significantly degrades performance.}
    \label{fg:ablation}
\end{figure*}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/sample_num_legend_only.png}
    \includegraphics[width=0.96\linewidth]{figures/sample_num.png}
    \caption{\textbf{Impact of sample size.} We select 100, 300, 1000, and 2000 samples from 5,000 synthetic data per training round and test the impact of sample size on the HPS test dataset.}
    \label{fg:sample_num}
    \vskip -0.1in
\end{figure}


\subsection{Results}

% \begin{figure}[t]
% \begin{center}
% \centerline{\includegraphics[width=0.95\linewidth]{figures/comparison.png}}
% \caption{\textbf{Quantitative Results.} Performance comparison of RSIDiff and the base model across two datasets and 4 evaluation metrics. The results demonstrate that RSIDiff significantly outperforms the base model and achieves consistent improvements.}
% \label{fg:comparison_w_base}
% \end{center}
% \end{figure}


\textbf{Quantitative Results.}
We first validate the effectiveness of our proposed method by comparing it against the base model and supervised fine-tuning (SFT) method. 
%
For the SFT method, we fine-tune the diffusion model for 500 epochs using 5,000 synthetic data samples. Note that these data are generated by our filtered prompts, which have largely enhanced the aesthetic quality compared to poorly designed prompts. 
%
The results are illustrated in \cref{fg:precision}, where a training round of 0 reflects the performance of the baseline model.
%
It is clear that our method outperforms the base model and SFT method on all evaluation tests.
This demonstrates the effectiveness of RSIDiff.
%, achieving significant improvements through recursive training with synthetic data. 
%
Notably, the model achieves its highest performance in the 6th training round, surpassing the base model by 7.0\% and 181.6\% on the HPS v2.1 and ImageReward metrics of the HPS test dataset. 
%The ImageReward score also shows a considerable increase, exceeding the base model by xxx\% on the HPS test and xxx\% on PartiPrompts in the 7th round.
Additionally, RSIDiff demonstrates superior performance compared to the SFT method, with advantages becoming evident after the 4th training round. 
%
Remarkably, this improvement is achieved using only 1,200 samples, significantly fewer than the scale of the SFT training set.
%
% Another interesting finding is that, although RSIDiff is not specifically designed to enhance alignment, our method still achieves consistent improvements in text alignment. This suggests that RSIDiff positively impacts the model's ability to align generated images with their corresponding textual descriptions.

However, it is worth noting that the performance gained is not infinite. After the 6th round, we begin to see a decline on performance, suggesting that errors within the generated data start to adversely affect the model’s performance. This highlights the need for ongoing refinement and error management to sustain the benefits of self-improvement.


\textbf{User Study.}
We conduct a user study comprising two comparison tasks to evaluate the performance of RSIDiff. Participants are presented with two images generated by the same prompt with RSIDiff and the compared method. They are asked to evaluate the samples based on two key perspectives: Visual Appeal and Text Faithfulness.
%
This evaluation process yielded a total of 4,800 responses from 8 participants. The results are summarized in \cref{tb:user_study}.
%
It is clear that RSIDiff significantly improves both metrics.
%
Particularly, it outperforms the base model in Visual Appeal by 69.0\% and shows a substantial improvement by 59.8\% over the SFT method.
%
% In terms of Text Faithfulness, RSIDiff won 32.7\% of the comparisons, while only 14.7\% were considered losses. 
% %
% For Visual Appeal, RSIDiff achieved a win rate of 34.8\%, with 64.9\% ties and 10.3\% losses.
%
These findings suggest that RSIDiff enhances the base model by maintaining fidelity to the text and improving the overall visual quality of the generated images.

\textbf{Qualitative Results.} The qualitative results demonstrate that RSIDiff outperforms the base model, as illustrated in \cref{fg:sd_samples}. We highlight the key areas of improvement:
1) \textit{Concept Centering:} The first row shows RSIDiff produces well-crafted images rather than wrongly cropped photographs. 
%
2) \textit{Detail Rendering:} Our model generates intricate details, such as subtle facial features, as shown in the second row.
%
3) \textit{Text Alignment:} The third row illustrates that RSIDiff achieves superior alignment with the text prompts, like the successful generation of space suits, and a lonely astronaut.
%
4) \textit{Stylistic Understanding:} The fourth row highlights our method’s improved ability to understand painting styles, resulting in more aesthetically pleasing paintings.
%
Overall, these qualitative results underscore the effectiveness of RSIDiff in producing human-preferred images.



\subsection{Ablation Studies}
To validate the effectiveness of our proposed methods, we conduct ablation studies on both the HPS test dataset and the PartiPrompts dataset. 
%
We assess the impact of prompts by creating another prompt set with CLIP-based templates, such as ``a photo of [concept].''
%
We incorporate noun classes from the ImageNet dataset \cite{deng2009imagenet} to fill the [concept].
%
As illustrated in \cref{fg:ablation}, we visualize the impact of the three proposed methods alongside a setting without any proposed strategy.
%
Our results reveal that RSIDiff achieves the best recursive improvement compared to the other four settings. 
%
And we observe a noticeable performance drop when removing individual methods from RSIDiff.
%
Moreover, the results show a significant decline compared to the base model when no strategies are applied.
%
This indicates the importance of our proposed methods in mitigating generative hallucinations and enhancing the preference.

We next examine how the number of selected samples per training round affects performance. We compare four configurations: 100, 300 (default), 1000, and 2000. \cref{fg:sample_num} shows the results on the HPS test dataset.
%
Obviously, the 300-sample configuration significantly outperforms the 100-sample option by incorporating a larger number of valuable samples into the training process. 
%
However, the performance trends are less consistent when selecting 1000 or 2000 samples.
While these configurations exhibit superior performance in the early rounds, their improvement slows after round 3, even with a decline in PickScore.
%
This indicates that an excess of loosely selected samples may exacerbate the accumulation of generative hallucinations, potentially leading to an earlier happen of model collapse.



\begin{figure}[t]
\begin{center}
\centerline{\includegraphics[width=0.99\linewidth]{figures/sd3_samples.pdf}}
\caption{\textbf{Comparison with SD3.} We show the effectiveness of RSIDiff on SD3 in generating rational images (1st row), improving the detail in hand rendering (2nd row), depicting clear separation between hair and headdress (3rd row), and facilitating coherent interactions between the bichon and motorcycle (4th row).}
\label{fg:sd3_samples}
\end{center}
\vskip -0.2in
\end{figure}

\subsection{RSIDiff on SD3}
% use human-selected preferred data, and tested by human
In this section, we evaluate the performance of RSIDiff by using the Stable Diffusion 3 medium (SD3) model \cite{esser2024scaling} as the base model.
%
During each preference sampling phase, we generate 13,000 images to create the synthetic data pool. After automated filtering with multiple metrics, we conduct an additional manual selection process to further filter the samples, ultimately obtaining 1,000 high-quality images. This ensures a more accurate alignment with human preferences. We optimize the LoRA \cite{hu2021lora} weights of SD3 with a learning rate of $1e^{-6}$ for 2,000 steps. We repeat this process for a total of 3 rounds.

Figure \ref{fg:sd3_samples} illustrates the comparison of generated images between the base model and RSIDiff. Our method corrects flaws present in the generated images. For example, RSIDiff demonstrates physically plausible generation, enhanced detail in hand rendering, clear separation between the character and the background, and more coherent interaction between subjects. These results validate our method for improving visual quality and adherence to user expectations.

\section{Conclusion}
This paper presents a study on the self-evolving text-to-image diffusion models. We highlight the degeneration issue when using self-generated data for self-training and attribute the problem to the lack of perceptual alignment and accumulation of generative hallucinations. To address this challenge, we introduce three key strategies: a prompt construction pipeline to enhance perceptual alignment, a preference sampling approach to prioritize human-aligned outputs while filtering out defective samples, and a distribution-based weighting mechanism to mitigate the effects of hallucinatory data. Our results show that RSIDiff significantly improves human preferences and model robustness. This work lays the groundwork for future research into enhancing diffusion models through RSI techniques.


% \begin{table*}[t]
% \caption{The percentage of user preference on our proposed method (Uncertainty + Balance) compared to Round 1 (DreamBooth) and Oracle feedback (Human + Balance).}
% \label{tb:compare_w_base}
% \begin{center}
% \begin{small}
% % \begin{sc}
% \begin{tabular}{l|cccc|cccc}
% \bottomrule
% &  \multicolumn{4}{c}{HPS test dataset}  &  \multicolumn{4}{c}{PartiPrompts} \\ \cline{2-5} \cline{6-9} 
% ~ & HPS v2.1  & Pick-a-pic & ImageReward & Text-alignment & HPS v2.1  & Pick-a-pic & ImageReward & Text-alignment  \\ \hline
%         Base Model & 24.26  & 20.71  & 0.1418  & 0.3247  & 24.93  & 21.20  & 0.1826  & 0.3125  \\
%         R1 & 24.88  & 20.83  & 0.2606  & 0.3269  & 25.27  & 21.24  & 0.2423  & 0.3142  \\ 
%         R2 & 25.22  & 20.88  & 0.2917  & 0.3296  & 25.42  & 21.28  & 0.2764  & 0.3142  \\ 
%         R3 & 25.14  & 20.83  & 0.2413  & 0.3276  & 25.63  & 21.30  & 0.3193  & 0.3154  \\ 
%         R4 & 25.42  & 20.84  & 0.3200  & 0.3276  & 25.83  & 21.32  & 0.3337  & 0.3152  \\ 
%         R5 & 25.65  & 20.90  & 0.3570  & 0.3306  & 25.90  & 21.31  & 0.3776  & 0.3162  \\
%         R6 & 25.96  & 20.91  & 0.3993  & 0.3289  & 26.00  & 21.33  & 0.3552  & 0.3162  \\
%         R7 & 25.78  & 20.88  & 0.4171  & 0.3298  & 25.93  & 21.29  & 0.3622  & 0.3157  \\
%         R8 & 25.79  & 20.87  & 0.3462  & 0.3291  & 25.98  & 21.30  & 0.3782  & 0.3162  \\
% \toprule
% \end{tabular}
% % \end{sc}
% \end{small}
% \end{center}
% \end{table*}

{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{cvpr}
}

% WARNING: do not forget to delete the supplementary pages from your submission 
% \input{sec/X_suppl}

% \newpage

\section{Supplementary Materials}
To provide a more comprehensive understanding of the method, we have included additional details in the following sections. The source code can be accessed at https://open\_upon\_acceptance.


\subsection{Prompt Set Examples}
This section presents partial prompt samples for generating human-aligned images, as shown in \cref{tb:prompt}. Our prompt set demonstrates key qualities: clarity, specificity, and diversity.

\subsection{More Ablation Studies}
In this section, we conduct an ablation study to analyze the impact of the hyperparameters $\beta$ and $\sigma$ as defined in Eq. (4). The parameter $\beta$ determines whether samples are in-distribution or out-of-distribution, while $\sigma$ influences the penalization weight assigned to out-of-distribution samples. Results are shown in \cref{fg:beta_ablation} and \cref{fg:sigma_ablation}. It is clear that model performance varies on these parameters, which indicates the importance of the distribution-based weighting scheme. Based on overall results, we set $\beta$ and $\sigma^2$ to 35 and 2, respectively. 


\subsection{Additional Results}
We provide more qualitative results to show the effectiveness of RSIDiff.
\cref{fg:supp_iter} illustrates how RSIDiff improves human preference as training progresses.
\cref{fg:supp_sd_samples} shows the superior performance of RSIDiff through the comparison with base model and SFT method.
\cref{fg:supp_sd3_1}, \cref{fg:supp_sd3_2}, and \cref{fg:supp_sd3_3} show that RSIDiff is able to boost the SD3 model across multiple aspects.


\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{|c|p{15cm}|}
        \hline
        No. & Prompt \\ \hline
        1&Red panda in a spacesuit in space having an epiphany nebula in the background, trending on artstation, highly detailed \\\hline
        2 &  A samoyed dog seated on a rock in a jungle, mist, tropical trees, vines, birds, sunset, fluffy clouds, warm colors, beautiful lighting, digital art, intricate details, trending on artstation\\\hline
        %2&A street view of a cyberpunk city, fantasy, elegant, digital painting, artstation, concept art, matte, sharp focus, illustration, art by josan gonzalez\\\hline
        3&Digital art, fantasy portrait of a cat in a lounge chair wearing sunglasses, by james jean, by ross tran, ultra detailed, character design, concept art, trending on artstation\\\hline
         % 2& A fantastical transparent small turquoise spirit horse made of water and foam and algae, splashing water, wave, translucent, ethereal, noble, radiant, hyperalism, scottish folklore, digital painting, art station, concept art, smooth, 8 k frostbite 3 engine, ultra detailed, art by artgerm and greg rutkowski and magali Villeneuve \\\hline
         4& Illustration of a short curly orange hair man as a portrait, smooth, reflects, masterpiece artwork, ultra detailed, artgerm, style by karl marx, digital art, trending on artstation, behance, deviantart \\\hline
         5& Fennec fox, pink, palm trees, furry, cute, disney zootopia, concept art, aviator sunglasses, synthwave style, artstation, detailed, award winning, dramatic lighting, miami vice, oil on canvas\\\hline
         6&Digital art of a cute penguin sitting on a chair wearing sunglasses at night, detailed, trending on artstation, digital art, award winning art, detailed digital art, painting\\\hline
         % 5& Long shot of a very cute owl chick nesting in a futuristic mug, esao andrews, humorous illustration, hyperrealistic, big depth of field, warm colors, night scenery, low light, 3 d octane render, 4 k, concept art, hyperdetailed, hyperrealistic, trending on artstation\\\hline
         %7&Close up of a cute crocheted elephant, concept art, illustrated, highly detailed, high quality, bright colors, optimistic \\\hline
         % 8&Professional ominous concept art portrait of a robot character with a flat metallic mandala face by artgerm and greg rutkowski. an intricate, elegant, highly detailed digital painting, concept art, smooth, sharp focus, illustration, in the style of simon stalenhag, wayne barlowe, and igor kieryluk \\\hline
         7&A dog in an astronaut suit, 3d, sci-fi fantasy, intricate, elegant, highly detailed, lifelike, photorealistic, digital painting, artstation, illustration, concept art, sharp focus, art in the style of Shigenori Soejima \\\hline
         8&Portrait of a vampire woman staring into a mirror, realistic, 8 k, extremely detailed, cgi, trending on artstation, hyper - realistic render, 4 k hd wallpaper, premium prints available, by greg rutkowski\\\hline
        9&A medieval brick castle surrounded by dozens of planets in a green field at noon, matte oil painting, cumulus clouds, impact craters, fantasy, concept art, clear, crisp, sharp, extremely detailed, wallpaper\\\hline
        % 
        % 12&Universe in a grain of sand, masterpiece, dyson sphere, scifi, unique environment, high quality, 4 k, high detail, trending on artstation, art by gordon freeman, albert voidstar\\\hline
        % 
        % 
        % 15&Beautiful portrait of a female officer wearing a fancy naval uniform, art by wlop and artgerm, science fiction, intricate detail, blonde hair, space background, trending on artstation, sharp focus, illustration, caustics, octane render, radiant light, 4 k\\\hline
        % 
        % 17& Hand drawn cute gnomes face in autumn disguise holding pumpkin, detailed face, concept art, low angle, high detail, warm lighting, volumetric, godrays, vivid, beautiful, trending on artstation, by jordan grimmer, huge scene, grass, art greg rutkowski\\\hline
        % 18&An achingly beautiful print of roman ruins in the middle of Yosemite valley by Raphael, Hopper, and Rene Magritte. detailed, romantic, enchanting, trending on artstation\\\hline
        % 19&Concept art of cute candy characters, oil painting by jama jurabaev, extremely detailed, brush hard, artstation, for aaa game, high quality, brush stroke \\\hline
        % 20&A highly detailed matte painting of a beautiful beach with golden shimmering sands by Studio Ghibli, Mokoto Shinkai, by Artgerm, volumetric lighting, octane render, 4K resolution, trending on artstation\\\hline
    \end{tabular}
    \caption{\textbf{Sample Prompts from the Prompt Set.} This table displays several prompts included in our prompt set, which are selected based on three key aspects: clarity, specificity, and diversity.}
    \label{tb:prompt}
\end{table*}


\begin{figure*}[t]
    \centering
    \includegraphics[width=0.4\linewidth]{figures/supp_legend_only.png}
    \subfloat[Evaluation on HPS test dataset.]{\includegraphics[width=0.93\linewidth]{figures/supp_ablation_beta1.png}} \\
    \subfloat[Evaluation on PartiPrompts dataset.]{\includegraphics[width=0.93\linewidth]{figures/supp_ablation_beta2.png}}
    \caption{\textbf{Ablation Study of $\beta$.} We assess the effects of $\beta$ under four different metrics on the HPS test and PartiPrompts datasets. Higher values of $\beta$ correspond to a more permissive determination of in-distribution samples. We set $\beta$ as 35 based on the overall performance.}
    \label{fg:beta_ablation}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.4\linewidth]{figures/supp_sigma_legend_only.png}
    \subfloat[Evaluation on HPS test dataset.]{\includegraphics[width=0.93\linewidth]{figures/supp_ablation_sigma1.png}} \\
    \subfloat[Evaluation on PartiPrompts dataset.]{\includegraphics[width=0.93\linewidth]{figures/supp_ablation_sigma2.png}}
    \caption{\textbf{Ablation Study of $\sigma^2$.} We assess the effects of $\sigma^2$ under four different metrics on the HPS test and PartiPrompts datasets. Smaller values of $\sigma^2$ correspond to a higher penalization on out-of-distribution samples. We set $\sigma^2$ as 2.0 based on the overall performance.}
    \label{fg:sigma_ablation}
\end{figure*}




\begin{figure*}[t]
\begin{center}
\centerline{\includegraphics[width=0.98\linewidth]{figures/supp_iter.pdf}}
\caption{\textbf{Examples Generated in Rounds.} We show examples generated from rounds 1 to 6, alongside outputs from the base model (SD v1.4). The images illustrate a gradual enhancement in visual quality.}
\label{fg:supp_iter}
\end{center}
\end{figure*}

\begin{figure*}[t]
\begin{center}
\centerline{\includegraphics[width=0.9\linewidth]{figures/supp_sd_samples.pdf}}
\caption{\textbf{Qualitative Results.} Examples generated by the base model (SD v1.4), SFT method, and RSIDiff. The results illustrate RSIDiff's superior performance in several areas: generation of intricate details, effective centering of concepts, human-aligned aesthetic understanding, and better alignment with text prompts.}
\label{fg:supp_sd_samples}
\end{center}
\end{figure*}


\begin{figure*}[t]
\begin{center}
\centerline{\includegraphics[width=0.75\linewidth]{figures/supp_sd3_1.pdf}}
\caption{\textbf{Examples Generated by SD3 and RSIDiff.} This comparison highlights that our method RSIDiff enhances the base model by achieving more coherent interactions between subjects.}
\label{fg:supp_sd3_1}
\end{center}
\end{figure*}

\begin{figure*}[t]
\begin{center}
\centerline{\includegraphics[width=0.75\linewidth]{figures/supp_sd3_2.pdf}}
\caption{\textbf{Examples Generated by SD3 and RSIDiff.} This comparison highlights that our method RSIDiff enhances the base model by improving
the detail in hands and feet rendering.}
\label{fg:supp_sd3_2}
\end{center}
\end{figure*}

\begin{figure*}[t]
\begin{center}
\centerline{\includegraphics[width=0.75\linewidth]{figures/supp_sd3_3.pdf}}
\caption{\textbf{Examples Generated by SD3 and RSIDiff.} This comparison highlights that our method RSIDiff enhances the base model by generating physically plausible subjects.}
\label{fg:supp_sd3_3}
\end{center}
\end{figure*}

\end{document}
