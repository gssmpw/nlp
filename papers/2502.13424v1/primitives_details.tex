\section{Details of Section~\ref{sec:primitives} -- Algorithms and Analysis of Building Blocks}
\label{sec:prim_details}

In this section, we include the remaining details of our building blocks (Section~\ref{sec:primitives}). Theorems are restated for easy reference. First, let us introduce the following combinatorial object, to be used later.

\begin{definition}[Strong selector]
\label{def:strong-selector}
    A family $\mathcal{F}$ of subsets of $[n]$ of size at most $k$ each is called an \emph{$(n,k)$ strong selector} if for every non-empty subset $S \in [n]$ such that $|S| \leq k$, for every element $a \in S$, there exists a set $F \in \mathcal{F}$ such that $|F \cap S| = \{a\}$.
\end{definition}

Note that there are known constructions of $(n,\Delta)$ strong selectors of length at most $O(\Delta^2 \log n)$~\cite{5967914}. Next, we show how to use an $(n,\Delta)$ strong selector to perform a local broadcast.

\subsection{Local broadcast}
\label{sec:local-broadcast}

%One can perform local broadcast routine based on strong selectors. 
Our local broadcast routine is non-adaptive. That is, each node 
%will have a prepared-in-advance 
has a predefined schedule 
%determining 
specifying in which rounds beeps and in which rounds listens. 

\parhead{Assumptions} % \pga{The nodes IDs come from range $[1,n^c]$.} 
The nodes know the total number of nodes $n$, parameter $c$,
 %\mm{[[the range has been defined above, do we need to recall it?]]} 
the maximum degree $\Delta$ of the graph and have access to a global clock. Additionally, we assume that each node $v$ knows its neighborhood $N(v)$. (In Subsection~\ref{sub:neighbourhood} we will show how all nodes can learn their neighborhoods in $O(\Delta^2 \log^2 n)$ beeping rounds.)

\localbroadcastthm*
\remove{
\begin{theorem}
\label{th:local_broadcast}
\mm{Consider a Beeping Network where each node $v$ knows $n$, $\Delta$, and $N(v)$.}
    Assume that every message $m_v$ of each node $v$ has length at most $k$ for some $k>0$. Then, there is a deterministic distributed local broadcast algorithm that works in $O(k\Delta^2 \log^2 n)$ beeping rounds.
\end{theorem}
}

\begin{proof}
Consider an $(n^c,\Delta)$ strong selector $\mathcal{F}=\{S_1,S_2,\dots, S_L\}$ of length $L=O(\Delta^2 \log n)$, known to all nodes. Our local broadcast schedule will take $L$ rounds. At any round $i$, nodes $v \in S_i$ that have bit 1 (indicating to transmit) send a beep while all the other nodes are silent.

Consider any receiver $r$. Consider the set $N(r)$ of neighbors of $r$. Note that $|N(r)| \leq \Delta$. From the definition of a $(n^c,\Delta)$ strong selector $\mathcal{F}$, for every $v \in N(r)$ there exists an index $i$ such that $S_i \cap N(r) = \{v\}$. Therefore, for every pair of transmitters $v$ and receiver $r$ that are adjacent to each other, there exists a round $i$ such that $v$ is the only transmitting neighbor of $r$.

%Here we will assume that each node knows its neighborhood. In Subsection~\ref{sub:neighbourhood} we will show how all the nodes can learn their neighborhoods in $O(\Delta^2 \log^2 n)$ beeping rounds.

Since every node $v$ knows its neighborhood $N(v)$ and the sets $S_i$ for all $i$, node $v$ also knows for each neighbor $u \in N(v)$ at what round $t$ neighbor $u$ is the only neighbor transmitting. If at round $t$ node $v$ hears a beep, it means that $u$ transmitted bit 1. If at round $t$ node $v$ hears silence, it means that $u$ transmitted bit 0.

Therefore, after $L$ rounds the algorithm will go through the entire strong selector $\mathcal{F}$ and each node will learn a bit of information from each of its neighbors.

The procedure can be repeated $B$ times to broadcast messages of at most $B$ bits.
Hence, the claim follows.
%
\end{proof}


\subsection{Learning neighborhood}
\label{sub:neighbourhood}


Now we show how all the nodes can learn their neighborhoods in $O(\Delta^2 \log^2 n)$ beeping rounds. The following procedure will be non-adaptive. 

\parhead{Assumptions} %\pga{The nodes IDs come from range $[1,n^c]$.} 
The nodes know the total number of nodes $n$ and parameter $c$.
% \pga{the range of possible IDs $[1,n^c]$ for some constant $c \geq 1$}
% and have access to a global clock.

\learningneighthm*
\remove{
\begin{theorem}
\label{th:learning_neighbourhood}
\mm{Consider a Beeping Network where each node $v$ knows $n$.}
    There is a deterministic distributed learning neighborhood algorithm that works in $O(\Delta^2 \log^2 n)$ beeping rounds.
\end{theorem}
}

\begin{proof}
The nodes will beep according to a strong selector $\mF$ as in the previous subsection. This time, however, for each set $S_i \in \mF$ there will be $2\log n$ beeping rounds instead of $1$ round. First, nodes $v \in S_1$ will transmit for $2\log n$ rounds, then nodes $v \in S_2$ will transmit for $2\log n$ rounds and so on.

In each block of $2\log n$ rounds corresponding to a set $S_i$ for some $i$, each node $v \in S_i$ will encode its ID in the following way. For each bit in its ID, if the bit is 1, then the node listens for 1 round and then beeps. If the bit is 0, then the node beeps once and then listens for 1 round. The process is repeated for each bit in the ID.

After all $2\log n$ beeping rounds corresponding to a set $S_i$ for some $i$ pass, each node $v$ can look at the string of beeps and silences that it heard during the block. If there were beeps in both rounds $2k$ and $2k+1$ for some $k$, then there were multiple neighbors transmitting in the block and $v$ will ignore this block. Otherwise, the string of beeps encodes the ID of the only transmitting neighbor $u$. 
% node $v$ will assume that this string of bits is an ID of a node $u$. If the ID of $u$ is such that $u \in S_i$, then $u$ was the only neighbor of $v$ transmitting in the block. 
% \pga{[We may need to transmit 01 for each bit 1 and 10 for each bit 0 to really make this unambiguous.]} 
In particular, $u$ can be added to the list of neighbors of $v$. 
% On the other hand, if $u \notin S_i$, then that means that multiple neighbors of $v$ were overlapping their beeps during the block corresponding to $S_i$ and $u$ should not be added to the list of neighbors of $v$.

% \pga{According to the definition of strong selector $\mF$,} 
After all $L$ blocks of transmissions pass, each node $v$ heard from each $u \in N(v)$ in a block such that $u$ was the only transmitting neighbor. Therefore, each $u \in N(v)$ was added to the list of neighbors of $v$. No other nodes were added to the list of neighbors of $v$. Thus, $v$ knows its neighborhood from now on and the claim follows.
\end{proof}

\subsection{Cluster gathering}
\label{sec:gathering}

% \noindent \textbf{Aggregating information via overlapping Steiner trees.} 

\noindent \textbf{Assumptions.} %\pga{The nodes IDs come from range $[1,n^c]$.} 
Thanks to running cluster gathering inside the network decomposition algorithm, we will have access to additional structures. During the working of the network decomposition algorithm, each cluster $C$ will have a Steiner tree $S$ associated with it. All nodes $v \in C$ will be regular nodes in the Steiner tree $S$, while there may be some additional nodes $u \notin C$ that are Steiner nodes in $S$. All Steiner trees will have depth at most $O(\log^2 n)$, i.e., the diameter of the Steiner tree $S$ will be the same as the weak-diameter of the cluster $C$ that corresponds to $S$. Each node and each edge will be in at most $O(\log n)$ Steiner trees. Each Steiner tree $S$ will have a fixed root node $r$.
Given that our cluster gathering algorithm uses the local broadcast algorithm defined above, the previous assumptions also~apply.

% We can develop a cluster gathering algorithm where all nodes in all clusters work in parallel, resulting in only $O(local\_broadcast\cdot \log^4 n)$ beeping rounds.

\noindent \textbf{Effect and efficiency.} Given the above assumptions, we can develop an algorithm that gathers and aggregates limited information (each node passes at most $O(\log n)$ bits for each Steiner tree it is in) from all nodes in a cluster $C$ to the root $r$ of the corresponding Steiner tree $S$, with all clusters working in parallel. Additionally, the root $r$ can broadcast $O(\log n)$ bits to all nodes in $C$. The algorithm will work in $O(\Delta^2 \cdot \log^6 n)$ beeping rounds.

\noindent \textbf{Utilization.} The gathering algorithm will be used throughout the network decomposition algorithm but may be of independent use, especially since the network decomposition algorithm may output the Steiner trees it was using as well as the decomposition. Therefore, any algorithm using our network decomposition algorithm will have access to the appropriate Steiner trees to use for %gathering 
collecting information using our cluster gathering algorithm.

\clustergatherthm*
\remove{
\begin{theorem}
\label{th:cluster_gathering}
\mm{Consider a Beeping Network where each node $v$ knows $n$, $\Delta$, and $N(v)$.}
    There is a deterministic distributed cluster gathering algorithm that works in $O(\Delta^2 \log^4 n)$ beeping rounds.
\end{theorem}
}

%\noindent \textbf{Algorithm description.} 
\begin{proof}
The algorithm will utilize the local broadcast subroutine at each step. When we say "transmit", we mean to use local broadcast subroutine, unless specified otherwise. Each node $v \in C$ broadcasts its $O(\log n)$ bits (e.g., a number less than $n$) in parallel using the local broadcast subroutine $O(\log n)$ times. At each step, the parent $p$ of $v$ in the corresponding Steiner tree will listen for the message from $v$ as well as messages from its other children. Whenever $p$ receive messages from some of its children, $p$ prepares its own message (e.g., sum of numbers provided by its children in the current step, assuming that the sum is smaller than $n$) of $O(\log n)$ bits. The process will repeat until the root $r$ receives all the messages, which will last the number of steps equal to the depth of the Steiner tree, $O(\log^2 n)$. Note that node $p$ may receive messages from its children in multiple steps; in that case in each step $t$ node $p$ transmits the aggregate of messages it received at $t$, thus transmitting multiple times.

Similarly, one can broadcast a message from $r$ to all the nodes $v\in C$ in $O(\log^2 n)$ steps. The entire algorithm takes $O(\log^2 n)$ steps, which is $O(t_{local\_broadcast} \cdot \log^2 n)$ beeping rounds and the claim follows.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Network Decomposition}
\label{sec:decomposition}


% \subsection{Network decomposition from~\cite{ghaffari2021improved}}


In this section, we present how to adapt the network decomposition algorithm of Ghaffari et al.~\cite{ghaffari2021improved} to the beeping model. The only changes are in the way that nodes communicate. The original algorithm was %made
designed for the \congest model, where communication was straightforward. 
Instead, for the beeping model, we have to carefully implement all the concurrent communication, so that the algorithm remains efficient.
%
First, let us recall the result from~\cite{ghaffari2021improved}. 

% \noindent\textbf{Notations:} $b$ is the length of identifiers, $n$ is the number of nodes in graph $G$.

\begin{theorem}\cite{ghaffari2021improved}
    There is a deterministic distributed algorithm that computes a $(\log n, \log^2 n)$ network decomposition in $O(\log^5 n)$ \congest rounds.
\end{theorem}

We adapt the above result to the beeping model and obtain the next theorem.

\networkdecompthm*
\remove{
\begin{theorem}
\label{thm:local-decomposition}
    There is a deterministic distributed algorithm that computes a $(\log n, \log^2 n)$ network decomposition in $O(\Delta^2 \log^8 n)$ beeping rounds.
\end{theorem}
}

The algorithm works as follows. In preprocessing, each node learns its neighborhood, so that we will be able to use local broadcast routine.
%freely. 
This part can take up to $O(\Delta^2 \log^2 n)$ beeping rounds (see Theorem~\ref{th:learning_neighbourhood}). Next, we perform the network decomposition algorithm from~\cite{ghaffari2021improved} with all the communication carefully replaced, as shown 
%in Section~\ref{sec:rundown} 
below. This completes our network decomposition algorithm.

% \dk{In order to combine our Local Broadcast with the tools in~\cite{ghaffari2021improved}, detailed check of these tools need to be done to assure, among others, that they rely on Local Broadcast (not the general \congest model rules).
% We provide the relevant parts in Section~\ref{sec:Ghaffari-verbatim}.}



%\subsubsection{Summary of messages}
\label{sec:rundown}

% Let $local\_broadcast$ denote the number of beeping rounds to perform a local broadcast in the beeping model, i.e., make sure that for every node $v$ all neighbors of $v$ receive a message from $v$ \pga{of length at most $\log n$. According to Theorem~\ref{th:local_broadcast}, such local broadcast lasts $O(\Delta^2 \log^2 n$ beeping rounds.}

\paragraph{Summary of messages:}
We need to carefully replace all the communication from~\cite{ghaffari2021improved} with routines that work in the beeping model. We will use our local broadcast and cluster gathering routines from Section~\ref{sec:primitives}.

% Below we present a list of messages transmitted in \pga{the original algorithm for the \congest model~\cite{ghaffari2021improved} and how to implement this information transmission in the beeping model. The original algorithm can be viewed in Subsection~\ref{sec:ghaffari}. In the list below we count the messages done per \emph{step}. There will be at most $O(\log^2 n)$ steps in the algorithm.}

Below, we present a list of messages transmitted in %Subsection~\ref{sec:Ghaffari-verbatim} in 
a step and how to implement this information %transmission 
propagation in the beeping model (for convenience, we attach the network decomposition algorithm from~\cite{ghaffari2021improved} in Section~\ref{sec:Ghaffari-verbatim}):
\begin{enumerate}
    \item \textbf{Before proposals.} A node $v$ needs to check which clusters are adjacent to it and what are the parameters of these clusters (id, level). Every node $u$ can broadcast the parameters of the cluster $u$ is in, which is at most $O(\log n)$ bits. This is done once per step, %. This used to cost
    at a cost of $O(1)$ \congest rounds per step. In the beeping model, it can be done via a local broadcast with messages of length at most $O(\log n)$ bits. According to Theorem~\ref{th:local_broadcast}, it will cost $O(\Delta^2 \log^2 n)$ beeping rounds per step.
    \item \textbf{Proposals.} Proposals to join a cluster can be transmitted to all neighbors if the target cluster (or the target node) is specified in the message. Other receivers may ignore the message. This part used to cost $O(1)$ \congest rounds per step. 
    % In beeping model, this can be done in $O(local\_broadcast)$ rounds per step.
    In the beeping model, it can be done via a local broadcast, where the message specifies the IDs of both, sender and receiver, meaning messages of length at most $O(\log n)$ bits. According to Theorem~\ref{th:local_broadcast}, it will cost $O(\Delta^2 \log^2 n)$ beeping rounds per step.
    \item \textbf{Gathering proposals.} The leader of each cluster should learn the total number of proposals and the total number of tokens in the cluster. This part was done in $O(\log^3 n)$ \congest rounds. %of \congest model. 
    Note that the algorithm keeps the Steiner tree of $O(\log^2 n)$ diameter for each cluster, such that each node (and therefore each edge) is in at most $O(\log n)$ Steiner trees. Additionally, each node that participates in this cluster gathering  can add the numbers of proposals/tokens it receives from other nodes and then transmit the sums instead of relaying each message separately; these sums can never exceed the total number of nodes $n$, so this guarantees that each node only transmits $O(\log n)$ bits per Steiner tree it is in. Therefore, we can use the cluster gathering algorithm. According to Theorem~\ref{th:cluster_gathering}, this takes at most $O(\Delta^2 \log^6 n)$ beeping rounds.
    % given a $O(\log^2 n)$ diameter Steiner tree such that each node (and therefore each edge) is in at most $O(\log n)$ Steiner trees. 
    % This can be done in $O(\log^3 n)$ rounds of \congest model, since a message from a leaf to the root can collide with at most $O(\log^3 n)$ different messages. In beeping model, we can use the 
    % this can be done in $O(local\_broadcast \cdot \log^3 n)$ rounds per step. \pga{There should be an additional factor of $O(\log n)$ due to the length of the messages passed. Also, how do we determine, which message (from which Steiner tree) to transmit first?}
    \item \textbf{Responding to proposals.} Each node informs all its neighbors either that all the proposals were accepted or that all the proposing nodes should be killed. This part used to cost $O(1)$ \congest rounds per step. In the beeping model, the same can be done in a local broadcast, with $O(1)$ bit messages. According to Theorem~\ref{th:local_broadcast}, it will cost $O(\Delta^2 \log n)$ beeping rounds.
    \item \textbf{Stalling.} If a cluster decides to stall, all nodes neighboring the cluster should be informed about it. This \mm{part} used to cost $O(1)$ \congest rounds per step. In the beeping model, \mm{the same} can be done in a local broadcast with $O(1)$ bit messages. According to Theorem~\ref{th:local_broadcast}, it will cost $O(\Delta^2 \log n)$ beeping rounds.
\end{enumerate}

In the procedure described above, there is a total of $O(\Delta^2 \cdot \log^6 n)$ beeping rounds required per step. There are up to $O(\log n)$ steps per phase and up to $O(\log n)$ phases in the algorithm, which results in $O(\Delta^2 \cdot \log^8 n)$ beeping rounds for the entire algorithm. Note that only the means of communication changed. Therefore, the correctness of the algorithm is unaffected. This completes the proof of Theorem~\ref{thm:local-decomposition}.

% \pga{[TODO: We don't know whether we hear a single signal or multiple signals!]}

% \pga{[Solution 2: Have a preprocessing phase where all nodes learn their neighborhood. This can be done in $O(\Delta^2 \log^2 n)$ beeping rounds.]}

% \pga{Solution 1: Let $n$ be the number of nodes in the network. Consider $(n^2,\Delta)$ strong selector $\mathcal{F}$. Consider a node $v$ with id equal $id(v)$ that attempts to transmits a message $m$ with the first $\log n$ bits equal to $\hat{m}$. Let $id(v,m)$ be the concatenation of $id(v)$ and $\hat{m}$. Every $id(v,m)$ corresponds to exactly one element of the universum $U=[n^2]$. A node $v$ with a message $m$ will "transmit" (bit 0 is encoded as silence, while bit 1 is encoded as a beep) a bit in round $t$ if $t$-th set of $\mathcal{F}$ contains $id(v,m)$. 
% % [TODO: We need a single bit, i.e., 1 or 0. We can encode a single bit in two rounds: code 10 (i.e., transmission and then silence) corresponds to bit 0, while code 01 (silence followed by transmission) corresponds to bit 1.]

% The strong selector ensures that each node-message pair successfully transmits a bit to any neighbor.

% Intuitively, we copied each node $n$ times (id of a node is concatenated with one of $n$ different beginnings of a message on $\log n$ bits), but only at most one copy can transmit at any round. A transmission from node $u$ to node $v$ can overlap with at most $\Delta - 1$ other neighbors of $v$. The strong selector $\mathcal{F}$ guarantees that for every listener $v$ that has at most $\Delta$ neighbors $N(v)$, for each $u\in N(v)$ there is at least one set $S \in \mathcal{F}$ such that $S \cap N(v) = {u}$. }

% \pga{[COMMENT: Do we assume that a node knows its neighbors? If yes, the following paragraph is trivial. Otherwise, we may need a linear program. Problem with a linear program: Nodes that transmit 0 are silent. We can run a single local broadcast routine to learn our neighbors.]

% Furthermore, after every set of $\mathcal{F}$ was used, every listener $v$ can determine which round was the round with exactly one neighbor transmitting and which rounds had multiple neighbors transmitting.

% Let $f_v^i$ denote feedback that node $v$ receives at round $i$, i.e., $f_v^i=0$ if node $v$ heard silence in round $i$ and $f_v^i=1$ if node $v$ heard at least one beep in round $i$. After all $L$ rounds, each node $v$ determines the rounds with a unique transmitter based on the feedback $f_v^i$ it received at round $i$ for all $1 \leq i \leq L$ and the knowledge of what every set $S_i \in \mathcal{F}$ contains. Let $x_u=1$ if $u$ is beeping and $x_u=0$ otherwise. The linear program consists of $nL$ equations, one for each pair node-round $(v,i)$:

% \[ \sum_{u \in N(v)} x_u = 0 \text{ iff } f_v^i=0\]
% \[ \sum_{u \in N(v)} x_u \geq 1 \text{ iff } f_v^i=1\]

% }


% \subsection{Possible outputs}
% \pga{
% Besides the $(C,D)$ network decomposition, the algorithm above computes a few other structures that can be %helpful.
% \mm{useful and are of independent interest.}
% One such structure is a Steiner tree of depth $O(D)$ for each cluster. Additionally, a root of each Steiner tree can serve as a leader for the corresponding cluster\footnote{Note, the leader may be outside of the cluster it is serving.}. During the construction of the Steiner trees, any aggregate information (i.e., information that can be aggregated without increasing the size of messages beyond $O(\log n)$ bits, e.g., the number of descendants) can be gathered in each node in the Steiner tree without changing the asymptotic cost of the operation. During the gathering proposals stage the leader can broadcast $O(1)$ bits to its entire clusters without changing the asymptotic cost of the operation.
% }

% \pga{TODO: A separate algorithm for gathering information in multiple Steiner trees simultaneously. We use Lemmas/Theorems from Ghaffari's paper, so that we know that the Steiner trees have the right properties and there are only $\log n$ overlaps. Then, we can use THIS algorithm to describe gathering proposals part, as well as provide this algorithm as a separate primitive. This algorithm should be described before gathering proposals, perhaps before network decomposition section.}

%\section{Missing details from Section~\ref{}}
%\section{Details from Section~\ref{sec:decomposition}: Efficient Network Decomposition in Beeping Networks}


% \textcolor{green}{---------------------------------???????????}

% \dk{In order to prove Theorem~\ref{thm:local-decomposition}, we need to make sure that the network decomposition algorithm in~\cite{ghaffari2021improved} can indeed be implemented using only beeps.}
% indeed uses Local Broadcast as communication tool.}
\subsection{GGR network decomposition algorithm}
\label{sec:Ghaffari-verbatim}

\noindent\textbf{Notation:} $b$ is the length of identifiers, $n$ is the number of nodes in graph $G$.

The remainder of this subsection, which is important from perspective of assurance that our Local Broadcast could be combined with the tools in~\cite{ghaffari2021improved}, is cited from~\cite{ghaffari2021improved} verbatim.

\noindent\textbf{Construction  outline:}   The  construction  has  $2(b+\log n) =O(\log n)$ phases. Each phase has $28(b+\log n) =O(\log n)$ steps.  Initially, all nodes of $G$ are \emph{living}, during the construction some living nodes \emph{die}. Each living node is  part  of  exactly  one  cluster.   Initially,  there  is  one cluster $C_v$ for each vertex $v\in V(G)$ and we define the identifier $id(C)$ of $C$ as the unique identifier of $v$ and use $id_i(C)$  to  denote  the $i$-th  least  significant  bit  of  $id(C)$. From now on, we talk only about identifiers of clusters and do not think of vertices as having identifiers, though they will still use them for simple symmetry breaking tasks.   Also,  at  the  beginning,  the  Steiner  tree $T_{C_v}$ of a cluster $C_v$ contains just one node, namely $v$ itself, as a  terminal  node.   Clusters  will  grow  or  shrink  during the iterations, while their Steiner trees collecting their vertices can only grow.  When a cluster does not contain any nodes, it does not participate in the algorithm anymore.

\noindent\textbf{Parameters of each cluster:} Each cluster $C$ keeps two other parameters besides its identifier $id(C)$ to make its decisions:  its number of tokens $t(C)$ and its level $lev(C)$.The number of tokens can change in each step -- more precisely it is incremented by one whenever a new vertex joins $C$, while it does not decrease when a vertex leaves $C$.  The number of tokens only decreases when $C$ actively deletes nodes.  We define $t_i(C)$ as the number of tokens of $C$ at the beginning of the $i$-th phase and set $t_1(C) = 1$. Each  cluster  starts  in  level  $0$.   The  level  of  each cluster does not change within a phase $i$ and can only increment by one between two phases; it is bounded by $b$.  We denote with $lev_i(C)$ the level of $C$ during phase $i$.   Moreover,  for  the  purpose  of  the  analysis,  we  keep track  of  the  potential  $\Phi(C)$  of  a  cluster $C$ defined  as $\Phi_i(C) = 3i - 2lev_i(C) + id_{lev_i(C)+1}(C)$.  The potential of each cluster stays the same within a phase.

\noindent\textbf{Description  of  a  step:} In each step, first, each node $v$ of each cluster $C$ checks whether it is adjacent to a  cluster $C'$ such that  $lev(C')<lev(C)$. If  so, then $v$ proposes  to  an arbitrary  neighboring  cluster $C'$ among the neighbors with the smallest level $lev(C')$ and if there is a choice, it prefers to join clusters with $id_{lev(C')+1}(C') = 1$.  Otherwise, if there is a neighboring cluster $C'$ with $lev(C') = lev(C)$ and $id_{lev(C')+1}(C') = 1$, while  $id_{lev(C)+1}(C)  =  0$,  then $v$ proposes  to  arbitrary such cluster.

Second, each cluster $C$ collects the number of proposals  it  received.   Once  the  cluster  has  collected  the number  of  proposals,  it  does  the  following.   If  there are $p$ proposing nodes,  then they join $C$ if and only if $p \geq t(C)/(28(b+ \log n))$.  The denominator is equal to the number of steps. If $C$ accepts these proposals, then $C$ receives $p$ new tokens, one from each newly joined node. On the other hand, if $C$ does not accept the proposals as their number is not sufficiently large, then $C$ decides to kill all those proposing nodes.  These nodes are then removed from $G$.  Cluster $C$ pays $p \cdot 14(b+ \log n)$ tokens for this, i.e., it pays $14(b+ \log n)$ tokens for every vertex that it deletes.  These tokens are forever gone.  Then the cluster does not participate in growing anymore,  until the end of the phase and throughout that time we call that cluster \emph{stalling}.  The cluster tells that it is stalling to neighboring nodes so that they do not propose to it. At the end of the phase, each stalling cluster increments its level by one.

If the cluster is in level $b-1$ and goes to the last level $b$, it will not grow anymore during the whole algorithm, and  we  say  that  it  has finished.    Other  neighboring clusters can still eat its vertices (by this we mean that vertices of the finished clusters may still propose to join other clusters). 

Whenever  a  node $u$ joins  a  cluster $C$ via  a  vertex $v\in C$, we add $u$ to the Steiner tree $T_C$ as a new terminal node and connect it via an edge $uv$.  Whenever a node $u\in C$ is deleted or eaten by a different cluster, it stays in the Steiner tree $T_C$ but is changed to a non-terminal node.


