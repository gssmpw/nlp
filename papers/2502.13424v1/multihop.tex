%\section{Multi-hop Bounds}
%\vspace*{-3.1ex}
\section{Multi-hop \mam{Simulation}}

% - lower bound of $\Omega(\Delta)$ for Learning neighborhood based on Davies lower bound (Lemma 14 in Davies' paper); write it down!

% - algorithm for multihop Learning neighborhood via flooding (repeated use of Local Broadcast); we can also compute the shortest paths to each node within k hops.


% \dk{!!!! POTENTIAL NOTATION CLASH - $k$ denoted size of messages in previous section(s) while here denotes $k$-hop distance !!!!}

\dk{We generalize the 
%local communication 
\mam{simulation}
at distance $1$ to the following {\em $B$-bit $h$-hop simulation} problem: each node has messages, potentially different, of size at most $B$ \mam{bits} addressed to any other node, and it needs to deliver them to all destination nodes \mam{within} distance at most $h$ \mam{hops}. 
If each node has only a single message of size at most $B$ \mam{bits} to be delivered to all nodes \mam{within} distance at most $h$ \mam{hops}, then we call this restricted version {\em $B$-bit $h$-hop Local Broadcast}.
Note also that we do not require messages addressed to nodes of distance larger than $h$ to be delivered.}
%
Below we generalize the lower bound for single-hop simulation %by Davies
in~\cite{davies2023optimal} 
to multi-hop simulation and multi-hop local broadcast.

\begin{theorem}\label{thm:multihoplb}
    There 
    %exists 
    is
    an adversarial network of size $\Theta(\Delta^h)$ such that any $B$-bit $h$-hop simulation algorithm requires $\Omega(B\Delta^{h+1})$ beeping rounds to succeed with probability more than $2^{-\frac{1}{2}\cdot B(\Delta-1)^{h-2}(\Delta/2)^3} = 2^{-\Theta\left(B\Delta^{h+1}\right)}$.

    There exists an adversarial network of size $\Theta(\Delta^h)$ such that any $B$-bit $h$-hop Local Broadcast requires $\Omega(B\Delta^{h})$ beeping rounds to succeed with probability more than $2^{-\frac{1}{2}\cdot B(\Delta-1)^{h-2}(\Delta/2)^2} = 2^{-\Theta\left(B\Delta^{h}\right)}$.
\end{theorem}
\begin{proof}
    \noindent\textbf{Problem instance.}
    \mamr{We describe the construction of the adversarial network and input set of messages used to prove our lower bound as follows (refer to Figures~\ref{fig:multihop_graph} and~\ref{fig:multihop_graph2}).}
    Consider a full bipartite graph $K_{\Delta/2,\Delta/2}$, with one part called $T$ and the other $R$. We 
    %will 
    focus on transmissions going towards nodes in $R$, hence nodes in $R$ will be called receivers, while nodes in $T = T_1$ will be called the first \mamr{of $h$ layers}~of~transmitters. 
    
    % Let us ignore for a moment $R$ and its links. 
    Each node in $T_1$ will be a root of an $(h-1)$-depth tree of transmitters. We create a second layer of transmitters $T_2$ composed of $(\Delta/2)^2$ nodes. Each node in $T_1$ \mamr{(already connected to each node in $R$)} will also be connected to different $\Delta/2$ nodes in $T_2$.
    % , thus each node in $T$ has degree $\Delta/2 + \Delta/2 = \Delta$. 
    %Every
    \mamr{For subsequent layers of transmitters, that is each} layer $T_i$, for $3 \leq i \leq h$, will be composed of $(\Delta/2)^2 (\Delta-1)^{i-2}$ nodes. Each node in layer $T_{i-1}$, for $3 \leq i \leq h$, will be connected to different $\Delta-1$ nodes in layer~$T_i$. 
    %\pga{See Figure~\ref{fig:multihop_graph}.}
    % Thus, nodes in layer $T_{i-1}$ for $3 \leq i \leq k-2$ have degree $1 + \Delta-1 = \Delta$. Finally, nodes in layer $T_{k-1}$ have degree $1$.
%
    \begin{figure}[t]
        \centering
        \includegraphics[width=0.5\linewidth]{multihop_graph2.pdf}
        \caption{An illustration of the structure of the graph. The graph is partitioned into vertical layers $T_h$, \dots, $T_1$, $R$. \pga{The graph is branching out heavily, so we show only a path} from an arbitrary node in $T_1$ layer to an arbitrary node in $T_h$ layer, with all the edges incident to the path. The numbers between the layers denote the number of edges between the layers that are incident \pga{to the path or on} the path. Recall that layers $T_1$ and $R$ have $\Delta/2$ nodes each, while the other layers have significantly more nodes, but we only show nodes that are adjacent to the considered path.}
        \label{fig:multihop_graph}
    \end{figure}
%    
    Note that each node \mamr{in the defined network} has at most~$\Delta$~neighbors.

    %We have defined the graph we will be working on. Now we will describe the transmissions. 
    \mamr{We define now the input set of messages as follows.}
    Let each node $v \in T_{h}$ have a $B$-bit message $m_{v \rightarrow u}$ to each node $u \in R$. We choose those messages uniformly at random. We will show that just these messages cannot be relayed efficiently and we do not need any other messages in our problem instance\footnote{Alternatively we can make all the other messages known to the optimal algorithm, e.g., by setting them to be $0^B$.}.

%    \noindent\textbf{Gossiping.} Here we analyze the Gossiping algorithms.
    \noindent\textbf{\mam{Multihop Simulation.}} Here we analyze the \mam{multihop simulation} algorithms.

    There are $(\Delta/2)^2(\Delta-1)^{h-2}$ nodes in $T_h$, and each of them has $\Delta/2$ (possibly different) messages, one for each node in $R$. Therefore, there are $(\Delta/2)^3 (\Delta-1)^{h-2} \pga{=} \Theta(\Delta^{h+1})$ messages to nodes in $R$ that are passing through nodes in $T_1$.

    % Note that each node in $T_1$ will have to relay $(\Delta-1)^{k-1}\Delta/2 = \Theta(\Delta^k)$ messages to each node in $R$, i.e., $(\Delta-1)^{k-1}(\Delta/2)^2 = \Theta(\Delta^{k+1})$ messages total.
    
    % Note that each of the $\Delta/2$ nodes in $T_1$ will have to relay messages from $\frac{(\Delta/2)^2(\Delta-1)^{k-2}}{\Delta/2}$ nodes in $T_{k}$. Each node in $T_{k}$ has $\Delta/2$ (possibly different) messages, one for each node in $R$. Therefore, there are $(\Delta-1)^{k-2}(\Delta/2)^2 = \Theta(\Delta^{k})$ messages to nodes in $R$.

    Let $\mathcal{R}$ be the concatenated string of local randomness in all the nodes in $R$.
    %in $T_i$, for $1 \leq i \leq h-1$. 
    The output of any receiver $u \in R$ must depend only on $\mathcal{R}$, node IDs and the pattern of beeps and silences of nodes in $T_1$.

    There are $2^t$ possible patterns of beeps and silences in $t$ rounds. Therefore, the output of nodes in $R$ must be one of the $2^t$ possible distributions, where a distribution is over the randomness of $\mathcal{R}$. The correct output of nodes in $R$ is a string $\{0,1\}^{B(\Delta-1)^{h-2}(\Delta/2)^3}=\{0,1\}^{\Theta(B\Delta^{h+1})}$ chosen uniformly at random (since the input messages of nodes in $T_{h}$ were chosen uniformly at random). Therefore, the probability of picking the correct result is at most $2^{t-B(\Delta-1)^{h-2}(\Delta/2)^3}$,
    %. Any 
    \mamr{and any} algorithm that finishes within $t \leq \frac{1}{2}\cdot B(\Delta-1)^{h-2}(\Delta/2)^3$ rounds has at most $2^{-\frac{1}{2}\cdot B(\Delta-1)^{h-2}(\Delta/2)^3}$ probability of outputting the correct answer.
    
    \noindent\textbf{Local Broadcast.} The analysis of Local Broadcast is analogous to the analysis of \mam{multihop simulation}, except that there are $\Delta/2$ times fewer messages to transmit \mamr{(because the same message is transmitted to all nodes located within distance $h$ hops of the transmitter)}. The full analysis of Local Broadcast~is~below.

    There are $(\Delta/2)^2(\Delta-1)^{h-2}$ nodes in $T_h$ and each of them has $1$ message to nodes in $R$. Therefore, there are $(\Delta-1)^{h-2}(\Delta/2)^2 \pga{=} \Theta(\Delta^{h})$ messages to nodes in $R$ that are passing through nodes in $T_1$.

    Let $\mathcal{R}$ be the concatenated string of local randomness in all the nodes in $R$. The output of any receiver $u \in R$ must depend only on $\mathcal{R}$, node IDs, and the pattern of beeps and silences of nodes in $T_1$.

    There are $2^t$ possible patterns of beeps and silences in $t$ rounds. Therefore, the output of nodes in $R$ must be one of the $2^t$ possible distributions, where a distribution is over the randomness of $\mathcal{R}$. The correct output of nodes in $R$ is a string $\{0,1\}^{B(\Delta-1)^{h-2}(\Delta/2)^2}=\{0,1\}^{\Theta(B\Delta^{h})}$ chosen uniformly at random (since the input messages of nodes in $T_{h}$ were chosen uniformly at random). Therefore, the probability of picking the correct result is at most $2^{t-B(\Delta-1)^{h-2}(\Delta/2)^2}$,
    %. Any 
    \mamr{and any} algorithm that finishes within $t \leq \frac{1}{2}\cdot B(\Delta-1)^{h-2}(\Delta/2)^2$ rounds has at most $2^{-\frac{1}{2}\cdot B(\Delta-1)^{h-2}(\Delta/2)^2}$ probability of outputting the correct answer.
\end{proof}

    \begin{figure}[t]
        \centering
        \includegraphics[width=1\linewidth]{ctree.jpeg}
        \caption{Illustration for Theorem~\ref{thm:multihoplb}. Example of adversarial graph for $\Delta=4$ and $h=5$.}
        \label{fig:multihop_graph2}
    \end{figure}
    
\vspace*{-1.5ex}
\paragraph{Algorithm.}
%
\pga{A simple algorithm would repeatedly use a 1-hop Local Broadcast routine to flood the network with the messages until nodes at a distance $h$ received the messages. This, however, can take $\Omega(\Delta^{2h})$ rounds. Instead, we limit the flooding by only sending messages along the shortest paths to their destinations using a 1-hop simulation algorithm. The details of the algorithm as well as its analysis are presented next.}

In the beginning, 
%the
nodes use a standard protocol to disseminate their IDs up to distance $h$. They do it in $h$ subsequent epochs, each epoch $i$ of $t_i$ rounds sufficient to run our  Local Broadcast from Section~\ref{sec:primitives} (see Theorem~\ref{th:local_broadcast}) for messages of size $\Delta^i\log n$.
These messages contain different IDs learned by the node at the beginning of the current epoch.
A direct inductive argument, also using the property that there are at most $\Delta^i$ nodes at a distance at most $i$, shows that at the end of epoch $i$, each node knows the IDs of all nodes at a distance at most $i$ from it.
Additionally, each node records in which epoch $i$ it learned each known ID $v$ for the first time and from which of its neighbors $w$ -- and stores this information as a triple $(v,w,i)$.
%
The invariant for $i=h$ proves that at the end of epoch $h$, each node knows IDs of all nodes of distance at most $h$ from it. The round complexity is %clearly 
% $O(\Delta^{k}\log n \cdot \Delta^2\log^2 n)\le O(\Delta^{k+2}\log^3 n)$
$\sum_{i=1}^h \Delta^{i}\log n \cdot \Delta^2 \log n \pga{=} O(\Delta^{h+2} \log^2 n)$, and as will be seen later, it is subsumed by the round complexity of the second part of our algorithm (as the $\polylog n$ function in Theorem~\ref{thm:congest-sim} is asymptotically bigger than $\log^2 n$).

% NOT SURE IF THIS PARAGRAPH IS NEEDED:
Note that a sequence of triples $(v,w_1=v,1),\ldots,(v,w_{\ell},\ell)$,
stored at nodes $w_2,w_3,\dots,w_\ell,w_{\ell+1}=u$ respectively, represents a shortest path to node $v$ starting from the node $u$; the length of that path~is~$\ell$.

In the second part, nodes also proceed in epochs, but this time each epoch $i$ takes $t^*_i$ rounds sufficient to execute $1$-hop simulation algorithm from Section~\ref{sec:main-simulation} (see Theorem~\ref{thm:congest-sim}) for point-to-point messages of size $(B+\log n)\Delta^h$. 
Here $B$ denotes the known upper bound on the size of any input message.
In epoch $i$, every node $u$ transmits a (possibly different) message of size $(B+\log n)\Delta^h$ to each neighbor $w$. Such a message contains all the input messages of nodes within $i-1$ distance and the recipients of these messages such that $w$ is the next node on the saved shortest path to the recipient. The messages have already traveled $i-1$ hops, so their destination is at most $h-(i-1)$ hops away. More specifically, the message from node $u$
addressed to a neighbor $w$ in epoch $i$ 
contains pairs $(v,m_{z \rightarrow v})$, where $v$ is such that $(v,w,i')$ is stored at the node for some $i'\le h-(i-1)$ and $m_{z \rightarrow v}$ is a message received by the node $u$ in epoch $i-1$ (in case of $i-1=0$, it is the original message of the node addressed to $v$).
A direct inductive argument shows that at the end of each epoch $i$ a node knows at most $\Delta^i$ messages addressed to any node $v$ of distance $\ell \le h-i$ from the node. This invariant is based on the following arguments: 
\begin{itemize}
\item 
Because there is a unique neighbor $w$ of the node $u$ such that a triple $(v,w,\ell)$ is stored at the node, 
% \item 
the number of such nodes $v$ of distance at most $h-i+1$ from the node $u$ is at most $\Delta^{h-i+1}$, 
\item \pga{by the end of epoch $i-1$, node $u$ could receive messages to be relayed to $v$ from $\Delta^{i-1}$ different nodes at distance $i-1$,}
\item \pga{each message contains up to $B$-bit long original message and an ID of length $\log n$,}
\item 
hence, messages of size at most $(B+\log n)\Delta^{i-1} \cdot \Delta^{h-i+1} = (B+\log n) \Delta^h$ are being sent to each neighbor in epoch $i$, and by definition -- epoch $i$ has sufficient number of rounds to deliver them. 
\end{itemize}
The invariant for $i=h$ proves the desired property of $B$-bit $h$-hop simulation. The total number of rounds~is 
\[
O(h\cdot (B+\log n)\Delta^h \cdot \Delta^2\polylog n) 
%\le
\subseteq
O(h\cdot B\Delta^{h+2} \polylog n) 
\ ,
\]
where factor $h$ comes from the number of epochs, each sending at most $\Delta$ point-to-point messages of size at most $(B+\log n)\Delta^h$ to neighbors (by the invariant) using the $1$-hop simulation protocol with overhead $O(\Delta^2 \polylog n)$ (by Theorem~\ref{thm:congest-sim}).
Hence we proved the following.


\begin{theorem}\label{thm:multihopub}
There is a distributed deterministic algorithm solving the $B$-bit $h$-hop simulation problem \mam{in a beeping network} in $O(h\cdot B\Delta^{h+2}\polylog n)$ rounds.
\end{theorem}

