\newcommand{\myboldmath}{}%\boldmath doesn't work with latex
\newcommand{\defn}[1]{{\textit{\textbf{\myboldmath #1}}}}

\vspace*{-1.5ex}
\section{Model, Notation, and Problems}
\label{sec:model}

\vspace*{-1ex}
We consider a communication network formed by $n$ devices with communication and computation capabilities, called \defn{nodes}. 
Each node has a unique \defn{ID}
% \pga{. Depending on the problem, we assume that the IDs come from the range $[1,n]$ or $[1,n^c]$} 
from the range $[1,n^c]$
for some constant $c \geq 1$.\footnote{The availability of identifiers is essential in order to break symmetry in deterministic protocols, as pointed out in previous works on deterministic protocols in the Beeping model~\cite{beauquier2018fast,dufoulon2018beeping}.}
Nodes communicate by sending \defn{messages} among them. 
A message is composed of a binary sequence containing the source node ID, the destination node ID (if applicable), and the specific information to be sent. 
If the destination node receives the message from the source node, we say that the message was \defn{delivered}.
Each pair of nodes that are able to communicate directly (i.e., without relaying communication through other nodes) are said to be connected by a communication \defn{link} and are called \defn{neighbors}.
We assume that links are \defn{symmetric}, i.e., messages can be sent in both directions (delivery is restricted to the communication models specified below).
The network topology defined by the communication links is modeled with an undirected graph $G=(V,E)$ where $V$ is the set of nodes and $E$ is the set of links. 
\mam{If $E$ is such that for every pair of nodes $u,v\in V$ there is a path of links connecting $u$ and $v$ we say that the network is \defn{connected}.}
For each node $v\in V$, the set of neighbors of $v$ is called its \defn{neighborhood}, denoted as $N(v)$.
We assume that time is slotted in \defn{rounds} of communication. All nodes start running protocols simultaneously, i.e., the network is \defn{synchronous}.
We assume that computations take negligible time with respect to communication.
Thus, we measure algorithm performance in rounds.

\vspace*{-2ex}
\subsection{Communication Models}

\vspace*{-0.95ex}
\parhead{Beeping Networks~\cite{cornejo2010deploying}}
%\paragraph{Beeping Networks~\cite{cornejo2010deploying}:}
In this model, 
in each round each node can either \defn{beep} (send a signal) or \defn{listen} (do not send any signal). 
By doing so, nodes obtain the following \defn{communication channel feedback}. 
In any given round, a listening node \defn{hears} either \defn{silence} (no neighbor beeps) or \defn{noise} (one or more neighbors beep).
A listening node that hears noise cannot distinguish between a single beep and multiple beeps. 

Network protocols may use the channel feedback
(i.e. the temporal sequence of strings from \{``silence'',``noise''\})
to make decisions adaptively.
However, delivering messages is not straightforward because it requires sending (and receiving) the whole binary sequence of the message (according to some beeping schedule, possibly changing adaptively during the communication), somehow encoded with beeps. In that sense, protocols for Beeping Networks can be seen as radio network coding to cope with the communication restrictions (as in~\cite{efremenko2018interactive} to cope with noise). 

\vspace*{-2ex}
\begin{figure}[th]
\centering
\begin{subfigure}[htbp]{0.3\textwidth}
\centering
\vspace*{-2ex}
\includegraphics[scale=0.12]{BN1.jpg}
\caption{All nodes listen. All nodes hear silence.}
\label{subfig:network}
\end{subfigure}
\hspace{0.1in}
\begin{subfigure}[htbp]{0.3\textwidth}
\centering
\includegraphics[scale=0.12]{BN2.jpg}
\caption{Node $a$ beeps, $\{b,c,d,e,f\}$ listen. $\{b,c,d\}$ hear noise. $\{e,f\}$ hear silence.}
\label{subfig:1beep}
\end{subfigure}
\hspace{0.1in}
\begin{subfigure}[htbp]{0.3\textwidth}
\centering
\vspace*{-0.2ex}
\includegraphics[scale=0.12]{BN3.jpg}
\caption{Nodes $\{a,b\}$ beep, $\{c,d,e,f\}$ listen. $\{c,d\}$ hear noise. $\{e,f\}$ hear silence.}
\label{subfig:2beep}
\end{subfigure}
\vspace*{-1.5ex}
\caption{Beeping Network communication model example.}
\vspace*{-1.5ex}
\label{fig:BNmodel}
\end{figure}

\remove{%%%%%%%  START  REMOVE  %%%%%%%%
\parhead{Radio Networks with Collision Detection~\cite{chlamtac1985broadcasting}}
%\paragraph{Radio Networks with Collision Detection~\cite{chlamtac1985broadcasting}:}
In this model, 
in each round each node can either \defn{transmit} (send a message) or \defn{receive} (do not send any message). 
By doing so, nodes obtain the following \defn{communication channel feedback}. 
In any given round a receiving node \defn{receives} either \defn{silence} (no neighbor transmits), or a \defn{successful transmission} (one neighbor transmits), or a \defn{collision} (two or more neighbors transmit).

Note, that having three states the channel feedback of this model is richer, potentially allowing protocols that adapt more effectively. Moreover, the length of the messages transmitted is not restricted, reducing the problem of message delivery to avoiding collisions. 

}%%%%%%%  END  REMOVE  %%%%%%%%%%%%%%%%%

\parhead{\congest Networks~\cite{peleg2000distributed}}
%\paragraph{\congest Networks~\cite{peleg2000distributed}:}
In this model, 
in each round each node can send a (possibly different) message of $O(\log n)$ bits to each neighbor independently. All nodes receive the messages sent by their neighbors. That is, there are no collisions. In the \defn{\congest Broadcast} version of this model, each node can only broadcast the same message to all its neighbors in each round.

\vspace*{-1ex}
\subsection{Problems Studied}

Our main research question in this work is how to efficiently simulate a round of communication of a \congest Network protocol in a Beeping Network. 
We also study several distributed computing problems (of independent interest) in the context of Beeping Networks, and applications of our simulator that improve efficiency with respect to known solutions for Beeping Networks.

Before specifying the problems studied, we define the following notation for any Beeping Network with topology graph $G=(V,E)$.
%
A \defn{cluster} of nodes $C$ is a subset of nodes in $V$ (i.e. $C\in V$)~\footnote{Note that a cluster does not need to be connected.}.
%
We say that clusters $C_1$ and $C_2$ are \defn{neighboring clusters} if and only if there exist vertices $v_1 \in C_1$ and $v_2 \in C_2$ such that $\{v_1,v_2\} \in E$.
%
We say that a subgraph $G'$ of graph $G$ has a \defn{weak-diameter} $D$ if each vertex in $G'$ is at most $D$ distance away from every other vertex in $G$ (the original graph).\footnote{In contrast with the regular diameter, where each vertex in $G'$ is at most $D$ distance away from every other vertex in $G'$.
%(in the \emph{subgraph}).
}
%
An \defn{independent set} is a set of nodes $S\subseteq V$ such that $\forall u,v \in S : \{u,v\}\notin E$.
A \defn{maximal independent set (MIS)} is an independent set that is not a subset of any other independent set. 

The definitions of all problems studied follow. 
%\textcolor{green}{[[should we require stopping???]]} 

\parhead{Local Broadcast} 
%\paragraph{Local Broadcast:} 
Given a Beeping Network with topology graph $G=(V,E)$, where each node $v\in V$ holds a message $m_v$, this problem is solved once $m_v$ is delivered to every node in $N(v)$. 

\parhead{Learning Neighborhood} 
%\paragraph{Learning Neighborhood:} 
Given a Beeping Network with topology graph $G=(V,E)$, the learning neighborhood problem is solved once every node $v\in V$ knows \mam{the ID of every node $u\in N(v)$.} 

\parhead{Cluster Gathering}
%\paragraph{Cluster Gathering:}
Given a Beeping Network with topology graph $G=(V,E)$, where 
each node $v\in V$ holds some data $d_v$, 
the set of nodes is partitioned in $k\geq 1$ \defn{clusters} as $\{C_1,C_2,\dots,C_k\}$, and 
for each cluster $C_i$, $i\in[k]$, there is a designated \defn{leader} node $l_{C_i}\in C_i$ and a Steiner tree of depth at most $O(\log^2 n)$ that spans the cluster $C_i$,
the cluster gathering problem is solved once all leaders have received the data of all nodes in their cluster. That is, for each $i\in [k]$, $l_i$ knows $d_v$, for all $v\in C_i$.

\parhead{Network Decomposition} 
%\paragraph{Network Decomposition:} 
Given a Beeping Network with topology graph $G=(V,E)$ and parameter integers $C$ and $D$,
the $(C,D)$-network decomposition problem is to find a partition of $V$ into clusters $\{C_1,C_2,\dots\}$ such that each cluster has weak-diameter at most $O(D)$, and each cluster can be assigned a color so that, 
for every pair of neighboring clusters $C_i,C_j$, 
the color of $C_i$ and $C_j$ are different,
and the number of colors used is in $O(C)$.

\parhead{\congest Simulation}
%\paragraph{\congest Simulation:}
Given a Beeping Network with topology graph $G=(V,E)$, where each node $u\in V$ may hold a message $m_{u,v}$ of $O(\log n)$ bits that must be delivered to node $v\in N(u)$, the \congest simulation problem is solved once for every $u\in V$ and $v\in N(u)$, 
$m_{u,v}$ and the ID of $u$ has been delivered~to~$v$.

\parhead{Maximal Independent Set}
%\paragraph{Maximal Independent Set:}
Given a Beeping Network with topology graph $G=(V,E)$, 
The Maximal Independent Set problem is solved when, for some such set,
 $S\subseteq V$, every node $v\in S$, $v$  knows that it is~in~$S$.


\remove{
\section{Model and notation}
\label{sec:model}

% \pga{Prepare citations

% Setting: Graph

% Communication: Beeping

% Problem definitions: MIS, broadcast, local broadcast, gathering.}

% \subsection{}

% \subsection{Network}
We consider a communication network represented by an undirected graph $G=(V,E)$ with $n$ nodes. Nodes represent devices, and edges represent pairs of devices that can 
%hear \mm{[[hear not defined]]} each other. 
communicate directly.
Each node has a unique ID from the range $[1,n^c]$ for some constant $c>1$.
Time is divided into synchronous rounds of communication, and algorithm performance is measured in rounds.

\subsection{Communication models in networks}

\parhead{Beeping Networks}
%We study the beeping model. Time is divided into synchronous rounds.
% \pga{[COMMENT: find a better place to mention synchronous rounds]} 
In the beeping model, in each round, each node can either \emph{listen} or \emph{beep} (send a signal). A node $v$ that listens may \emph{hear} either \emph{silence} or \emph{noise}. Silence is heard in a round if all neighbors of $v$ are listening. Noise is heard by $v$ if $v$ listens and at least one neighbor of $v$ beeps. A listening node cannot distinguish between a single beep and multiple beeps from different neighbors in the same round. A node that beeps cannot listen in the same round. A node may interpret the channel feedback it receives 
%(string of silence and noise) 
(a temporal sequence of strings from \{``silence'',``noise''\})
and change its behavior accordingly.

Note that in the beeping model, transmitting and receiving messages is not explicit. Each message can be represented as a binary sequence containing the source \pga{ID}, the destination ID (if applicable), and the content string. Learning such sequence requires beeping by the message source (according to some beeping schedule, possibly changing adaptively during the communication) and the receiver has to interpret the sequence of beeps heard during the communication to extract the right message and its sender ID from this sequence. 

\parhead{Radio Networks with collision detection}
%
In the Radio Networks with collision detection model, presented in~\cite{chlamtac1985broadcasting}, a message transmitted by node $u$ is received by node $v$ in a round $r$ if $\{u,v\}\in E$, $u$ is transmitting, $v$ is not transmitting, and for any other node $u'\neq u$, such that $\{u',v\}\in E$, $u'$ is not transmitting in round $r$. If $u$ and $u'$ transmit in the same round, we say that a \emph{collision} occurs at $v$. Nodes are able to distinguish collisions from the background noise present in the communication channel when no node transmits.

% The beeps do not carry any message themselves;

% Nodes in the graph can communicate with \emph{beeps} -- signals that 

\parhead{\congest Networks}
%We translate algorithms that work in the \congest model to the beeping model. 
In the \congest model, in each round, every node can exchange (transmit and receive simultaneously) $O(\log n)$ bits with each neighbor independently. All pairs of nodes can communicate simultaneously and there are no collisions.

% \dk{\congest model.}

\subsection{Studied problems}

We study several problems, including graph problems (e.g., MIS) and tools (e.g.,  the problem of network decomposition), as well as auxiliary problems of learning neighborhood, local broadcast, cluster gathering and distributed simulation of \congest round in the beeping model. Ultimately, our solutions are designed for the beeping model, which is more demanding (due to limited communication and channel feedback) than the \congest model.  
% All the nodes will work concurrently


\noindent\textbf{Learning neighborhood.} A \emph{learning neighborhood} problem is the problem of finding all neighbors for all nodes in the graph. 
% At the end of the algorithm, each node can decipher IDs of all of its neighbors.
This can be done based on the feedback on the channel a node was receiving during the algorithm.

\noindent\textbf{Local broadcast.} A \emph{local broadcast} routine is an algorithm that all nodes in the graph perform concurrently. The input is some message $m_v$ at each node $v$. At the end of the local broadcast, for each node $v$, the contents of message $m_v$ are known to all neighbors of $v$.

% \noindent\textbf{Local broadcast.} A \emph{local broadcast} problem is a problem where each node $v$ has an input message $m_v$. 
% % The goal is, for each node $v$, 
% At the end of local broadcast, for each node $v$, the contents of message $m_v$ are known to all neighbors of $v$.

\noindent 
{\bf Distributed simulation of any \congest round in the beeping model.}
Suppose every node has a possibly different message of logarithmic size to deliver to each of its neighbors. 
The goal is that each neighbor receives such a message, in the sense that it learns and stores a binary sequence consisting of neighbor ID and the message. 

%\noindent
%{\bf Maximal Independent Set (MIS) and other graph problems.} ????????  TBA  ?????????????


\parhead{Maximal Independent Set}
Given a graph $G=(V,E)$, an \emph{independent set} is a set of nodes $S\subseteq V$ such that each pair of nodes in $S$ is not adjacent, that is, $\forall u,v \in S : \{u,v\}\notin E$.
A \emph{maximal} independent set (MIS) is an independent set that is not a subset of any other independent set. 
Given a network with topology represented by a graph $G=(V,E)$, the Maximal Independent Set problem is the problem of identifying the nodes in a maximal independent set $S\subseteq V$.


Before we describe the Network Decomposition problem -- a key tool in solving several graph problems in the \congest model -- we introduce some notation. 

\begin{definition}[Weak-diameter]
We say that a subgraph $G'$ of some graph $G$ has a \emph{weak-diameter} $D$ if each vertex in $G'$ is at most $D$ distance away from every other vertex in the \emph{original graph} $G$. Compare it to the regular diameter, where each vertex in $G'$ is at most $D$ distance away from every other vertex in the \emph{subgraph} $G$.
\end{definition}

% \pga{COMMENT: Is it known that partition requires disjoint sets that sum to the whole?}

\begin{definition}[neighboring clusters]
    We say that clusters $c_1$ and $c_2$ in graph $G=(V,E)$ are neighbors iff there exist vertices $v_1 \in c_1$ and $v_2 \in c_2$ such that $(v_1,v_2) \in E$.
\end{definition}

% \noindent\textbf{Local broadcast.} In local broadcast problem, each node may have up to $1$ bit of information to transmit. The goal is to have each node $v$ transmit its bit of information to all its neighbors.

\noindent\textbf{Network decomposition.} 
% \begin{definition}[network decomposition]    
A $(C,D)$ network decomposition of a graph $G=(V,E)$ is a partition of graph $G$ into clusters\footnote{Note, a cluster does not have to be connected.} $c_1,c_2,\dots$ such that each cluster has weak-diameter at most $O(D)$ and the clusters can be colored in at most $O(C)$ colors such that any two neighboring clusters have different~colors.
% \end{definition}

The problem of network decomposition that we solve below is the problem of finding a $(C,D)$ network decomposition for a given graph $G$ and parameters $C,D$.

\noindent\textbf{Cluster gathering.}
% In the \emph{cluster gathering} problem, a graph is partitioned into clusters of weak-diameter at most $O(\log^2 n)$. Every node $v$ has a message 
In short, in the \emph{cluster gathering} problem, a graph is partitioned into clusters. 
% Each cluster $C$ has a designated leader $l_C$.\footnote{The leader $l_C$ may be outside of the cluster $C$, but it should be at most $O(\log^2 n)$ distance away from the furthest node in $C$.} 
Every node $v$ in a cluster $C$ has data $d_v$. The task is to gather all the data from nodes $v \in C$ into the designated leader $l_C$ of cluster $C$, for all clusters $C$.

Specific assumptions and discussion of the cluster gathering problem can be found in Section~\ref{sec:gathering}.

% In the \emph{cluster gathering} problem, a graph is partitioned into clusters of weak-diameter at most $O(\log^2 n)$. Each cluster $C$ has a designated leader $l_C$.\footnote{The leader $l_C$ may be outside of the cluster $C$, but it should be at most $O(\log^2 n)$ distance away from the furthest node in $C$.} Every node $v$ in a cluster $C$ has data $d_v$. The task is to gather all the data from nodes $v \in C$ into the leader $l_C$, for all clusters $C$.

% We consider cluster gathering with the following additional assumptions. Each cluster $C$ will have a Steiner tree $S$ associated with it. All nodes $v \in C$ will be regular nodes in the Steiner tree $S$, while there may be some additional nodes $u \notin C$ that are Steiner nodes in $S$. All Steiner trees will have depth at most $O(\log^2 n)$, i.e., the diameter of the Steiner tree $S$ will be the same as the weak-diameter of the cluster $C$ that corresponds to $S$. Each node and each edge will be in at most $O(\log n)$ Steiner trees. Each Steiner tree $S$ will have a fixed root node $r$ that will act as the leader $l_C$ of cluster $C$ corresponding to $S$. Finally, we will assume that any subset of data from nodes in the same cluster can be aggregated into a message of at most $O(\log n)$ bits.\footnote{In particular, we use cluster gathering to determine the number of nodes with a certain property within each cluster. However, the algorithm may have other uses, hence the more general description.}

% The gathering algorithm will be used throughout the network decomposition algorithm, but may be of independent use, especially since the network decomposition algorithm may output the Steiner trees it was using as well as the decomposition. Therefore, any algorithm using our network decomposition algorithm will have access to the appropriate Steiner trees to use for gathering information using our gathering algorithm.
}