\section{Preliminaries}

In this paper, random variables and their realizations are denoted in the upper and lower case, respectively. Sets and vectors are written in bold. For a set $\mathbf{X}$, its power set is denoted as $\mathbb{P}(\mathbf{X})$.

\subsection{Multi-objective Bayesian optimization}\label{subsec:prelim_mobo}
Multi-objective Bayesian optimization simultaneously minimizes (or, maximizes) a set of black-box objectives $f_1, \dots, f_m: \mathbf{X} \rightarrow \mathbb{R}$ with minimal function evaluations. Due to potential conflicts between objectives, it aims to find trade-off solutions, known as Pareto optima:

\begin{definition}[Pareto optimality]
    A point $x \in \mathbf{X}$ is called \textit{Pareto-optimal} if there is no other $x' \in \mathbf{X}$ such that $f_i(x) \geq f_i(x')$ for all $1\leq i \leq m$, and $f_i(x) > f_i(x')$ for at least one $1\leq i \leq m$. The set of Pareto-optimal points in $\mathbf{X}$ is called \textit{Pareto set}, denoted $\mathcal{P}_s$. The \textit{Pareto front} is the image of the Pareto set under the objective functions, given by $\mathcal{P}_f = \{ \mathbf{f}(x) = (f_1(x),\dots,f_m(x)) \ | \ x \in \mathcal{P}_s \}$.
\end{definition}

At each iteration of a \textsc{mobo} algorithm, prior data is used to fit a \textit{surrogate model} of the objectives, for which Gaussian processes \cite{gps} are predominantly used. Based on the surrogates, an approximation $\tilde{\mathcal{P}}_f$ of the Pareto front is computed. The next point/batch to be evaluated is determined by maximizing the \textit{acquisition function}, which estimates the utility of evaluating the objectives at a given point/batch. The most commonly used acquisition function is the hypervolume indicator $\mathcal{H}$ \citep{dgemo_hypervolume}. The larger the hypervolume, the better $\tilde{\mathcal{P}}_f$  approximates the true Pareto front. To determine how much the hypervolume would increase if a batch of samples $\mathbf{B} \subseteq \mathbf{X}$ was added to the current approximation, hypervolume improvement is used:
\begin{equation}
    \text{HVI}(\mathbf{f}(\mathbf{B}), \tilde{\mathcal{P}}_f)= \mathcal{H} (\tilde{\mathcal{P}}_f \cup \mathbf{f}(\mathbf{B})) - \mathcal{H}(\tilde{\mathcal{P}}_f).
\end{equation}

Since \textsc{dgemo} \citep{dgemo} is the relevant \textsc{mobo} algorithm for our work, we briefly describe its batch selection strategy. It considers hypervolume improvement as well as sample diversity in the input space. To this end, the so called diversity regions $\mathcal{R}_1,\dots,\mathcal{R}_K$ are constructed by using the current Pareto front approximation to group the optimal points based on their performance properties in the input space. Formally, a batch is chosen as follows:
\begin{align}\label{eq:mo_cbo.dgemo_batch_selection}
    \mathbf{B} = &\underset{\mathbf{B} \subseteq \mathbf{X}, |\mathbf{B}| = B}{\text{arg max }} \text{HVI}(\mathbf{f}(\mathbf{B}), \tilde{\mathcal{P}}_f) \notag \\
    & \hspace{0.7cm} \text{ s.t. } \underset{1 \leq k \leq K}{\text{max}} \delta_k(\mathbf{B}) - \underset{1 \leq k \leq K}{\text{min}} \delta_k(\mathbf{B}) \leq 1,
\end{align}
where $B$ denotes the batch size and the functions $\delta_{k}(\cdot)$ are defined as the number of elements from $\mathbf{B}$ that belong to $\mathcal{R}_k$. For the complete selection algorithm, we refer to \citet{dgemo}.

\subsection{Causality}
\paragraph{Graph notation} A graph $\mathcal{G} = (\mathbf{V}, \mathbf{E})$ is defined by a finite vertex set $\mathbf{V}$ and an edge set $\mathbf{E} \subseteq \mathbf{V} \times \mathbf{V}$, containing ordered pairs of distinct vertices. The subgraph of $\mathcal{G}$ restricted to $\mathbf{V}' \subseteq \mathbf{V}$ is given by $\mathcal{G}[\mathbf{V}'] = ( \mathbf{V}', \mathbf{E}[\mathbf{V}'])$, where $\mathbf{E}[\mathbf{V}'] = \{(i,j) \in \mathbf{E} \ | \ i,j \in \mathbf{V}'\}$. 
For $V \in \mathbf{V}$, the set of its parents, ancestors and descendants in $\mathcal{G}$ is denoted as $\text{pa}(V)_{\mathcal{G}}$, $\text{an}(V)_{\mathcal{G}}$, and $\text{de}(V)_{\mathcal{G}}$, respectively. 
Here, no vertex is a parent, an ancestor, or a descendant of itself. 
Conversely, with a capital letter, this notation is extended to include the argument in the result, i.e., $\text{Pa}(V)_{\mathcal{G}} = \text{pa}(V)_{\mathcal{G}} \cup \{ V \}$. 
Moreover, we define these relations for sets of variables $\mathbf{V}' \subseteq \mathbf{V}$, i.e., $\text{pa}(\mathbf{V}')_{\mathcal{G}} = \bigcup_{V \in \mathbf{V'}} \text{pa}(V)_{\mathcal{G}}$ and $\text{Pa}(\mathbf{V}')_{\mathcal{G}} = \bigcup_{V \in \mathbf{V'}} \text{Pa}(V)_{\mathcal{G}}$. 
Equivalent conventions apply to the ancestor and descendant relationships.


\paragraph{Structural causal models} Let $\langle \mathbf{V}, \mathbf{U}, \mathbf{F}, P(\textbf{U}) \rangle$ be a structural causal model (\textsc{scm}) \cite{Pearl_00} and $\mathcal{G}$ its associated acyclic graph that encodes the underlying causal mechanisms. 
Specifically, $\mathbf{U}$ is a set of independent exogenous random variables distributed according to the probability distribution $P(\mathbf{U})$, $\mathbf{V}$ is a set of endogenous random variables, and $\mathbf{F} = \{f_V\}_{V \in \mathbf{V}}$ is a set of deterministic functions such that $V = f_V(\text{pa}(V)_{\mathcal{G}}, \mathbf{U}^V)$, where $\mathbf{U}^{V} \subseteq \mathbf{U}$ is the set of exogenous variables affecting $V \in \mathbf{V}$. The set $\mathbf{U}^V \cap \mathbf{U}^W$ consists of unobserved confounders between $V,W \in \mathbf{V}$, which are the exogenous variables influencing both $V$ and $W$. Within $\mathbf{V}$ there are three different types of variables to be distinguished: non-manipulative variables $\mathbf{C}$ that cannot be modified, treatment variables $\mathbf{X}$ which can be set to specific values, and output variables $\mathbf{Y} = \{Y_1,\dots,Y_m\}$ which represent the outcome of interest. We consider only real-valued \textsc{scm}s, where all endogenous variables have continuous domains. 
For $\mathbf{X}_s \subseteq \mathbf{X}$, $\text{CC}(\mathbf{X}_s)_{\mathcal{G}}$ refers to the c-component of $\mathcal{G}$ \citep{do_calculus.proof_3}, which, in this context, is the maximal set of variables that includes $\mathbf{X}_s$ and is connected via unobserved confounders. The joint distribution of $\mathbf{V}$, which is determined by $P(\mathbf{U})$, is referred as \textit{observational distribution} and denoted $P(\mathbf{V})$. 

\paragraph{Interventions} A set $\mathbf{X}_s \in \mathbb{P}(\mathbf{X})$ is also called an intervention set. The interventional domain of an intervention set is given as $\mathcal{D}(\mathbf{X}_s)= \times_{X \in \mathbf{X}_s} \mathcal{D}(X)$ and determines the feasible values of $\mathbf{X}_s$. An \textit{intervention} on $\mathbf{X}_s$ involves replacing the structural equations $f_{X}$ with a constant $x$, for all $X \in \mathbf{X}_s$. This action is denoted with the do-operator $\text{do}(\mathbf{X}_s = \mathbf{x}_s)$, where the \textit{intervention value} is $\mathbf{x}_s \in \mathcal{D}(\mathbf{X}_s)$. 
The graph $\mathcal{G}_{\overline{\mathbf{X}}_s}$ represents this intervention and is obtained by removing the incoming edges into $\mathbf{X}_s$. 
The observational distribution of $\mathcal{G}_{\overline{\mathbf{X}}_s}$ is denoted as $P(\mathbf{V} | \text{do}(\mathbf{X}_s=\mathbf{x}_s))$
and called \textit{interventional distribution}. 
For $\mathbf{X}_s =\varnothing$, no intervention is performed and the observational and interventional distributions coincide. The tuple $(\mathbf{X}_s,\mathbf{x}_s)$ is referred to as an \textit{intervention set-value} pair. Given two sets $\mathbf{X}_s, \mathbf{X}_s' \subseteq \mathbf{X}$ and $\mathbf{x}_s \in \mathcal{D}(\mathbf{X}_s)$, we write by $\mathbf{x}_s[\mathbf{X}_s']$ the values of $\mathbf{x}_s$ corresponding to $\mathbf{X}_s \cap \mathbf{X}_s'$. 


\section{The \textsc{mo-cbo} 
Problem}\label{sec:mo_cbo}

In our setting, we require that the causal relationships encoded in $\mathcal{G}$ are known while the underlying parametrizations, i.e., $\mathbf{F}$ and $P(\mathbf{U})$, can be unknown. This restricted information is denoted as $\langle \mathcal{G},\mathbf{Y}, \mathbf{X}, \mathbf{C}\rangle$ and the assumption allows generalization across systems that share the same causal structure. 

A \textsc{mo-cbo} problem aims to identify intervention set-value pairs $(\mathbf{X}_s, 
\mathbf{x}_s)$ that can minimize all target variables in $\mathbf{Y}$ simultaneously. The outcomes of an intervention $\text{do}(\mathbf{X}_s=\mathbf{x}_s)$ are captured as the expected values:
\begin{equation}
\label{eq:exp_target}
    \mathbb{E}_{P(Y_i | \text{do}(\mathbf{X}_s=\mathbf{x}_s))}[Y_i] := \mu_i(\mathbf{X}_s,\mathbf{x}_s),
\end{equation}
where $P(Y_i | \text{do}(\mathbf{X}_s=\mathbf{x}_s))$ denotes the interventional distribution of $Y_i$, for all $i=1,\dots,m$.  
We write $\boldsymbol{\mu}(\mathbf{X}_s,\mathbf{x}_s) = (\mu_1(\mathbf{X}_s,\mathbf{x}_s),\dots,\mu_m(\mathbf{X}_s,\mathbf{x}_s))$ for the vector notation. Since opposing causal relationships among the variables can cause conflicting single-objective optima, we consider multi-objective optimization settings, where the aim is to find Pareto-optimal solutions to establish trade-offs between the objective functions. This motivates the application of Pareto optimality to intervention set-value pairs: 


\begin{definition}[Pareto-optimal intervention set-value pair]
    Given $\mathcal{S} \subseteq \mathbb{P}(\mathbf{X})$, an intervention set-value pair $(\mathbf{X}_s, \mathbf{x}_s)$ with $\mathbf{X}_s \in \mathcal{S}$, $\mathbf{x}_s \in \mathcal{D}(\mathbf{X}_s)$ is called \textit{Pareto-optimal for $\mathcal{S}$}, if there is no other intervention set-value pair $(\mathbf{X}_s', \mathbf{x}_s')$ with $\mathbf{X}_s' \in \mathcal{S}$, $\mathbf{x}_s' \in \mathcal{D}(\mathbf{X}_s')$ such that $\mu_i(\mathbf{X}_s', \mathbf{x}_s') \leq \mu_i(\mathbf{X}_s, \mathbf{x}_s)$ for all $1 \leq i \leq m$, and $\mu_i(\mathbf{X}_s', \mathbf{x}_s') < \mu_i(\mathbf{X}_s, \mathbf{x}_s)$ for at least one $1 \leq i \leq m$.
\end{definition}

\begin{definition}[Causal Pareto front]
    The space of all Pareto-optimal intervention set-value pairs for a given $\mathcal{S} \subseteq \mathbb{P}(\mathbf{X})$ is called the \textit{causal Pareto set for $\mathcal{S}$}, denoted $\mathcal{P}^{\mathsf{c}}_s(\mathcal{S})$. The corresponding \textit{causal Pareto front for $\mathcal{S}$}, denoted $\mathcal{P}^{\mathsf{c} }_f(\mathcal{S})$, is the $m$-dimensional image of the causal Pareto set under the objectives $\mu_i$, $1 \leq i \leq m$.
\end{definition}

We define \textsc{mo-cbo} problems as identifying the causal Pareto front $\mathcal{P}_f^{\mathsf{c}}(\mathbb{P}(\mathbf{X}))$ over the set of all intervention sets, and we refer to $\mathcal{P}_f^{\mathsf{c}}(\mathbb{P}(\mathbf{X}))$ simply as the causal Pareto front. 

\subsection{Decomposition of \textsc{mo-cbo} Problems}
To navigate the discovery of Pareto-optimal intervention set-value pairs, we aim to simplify the search space.  

\begin{definition}[Local \textsc{mo-cbo} problem]\label{def:local_mocbo_problem}
    Let $\textbf{X}_s \in \mathbb{P}(\mathbf{X})$ be an intervention set. Then, the multi-objective optimization problem defined by the objective functions $\mu_i(\mathbf{X}_s,\ \cdot \ ): \mathcal{D}(\mathbf{X}_s) \rightarrow \mathbb{R}$, $\mathbf{x}_s \mapsto \mu_i(\mathbf{X}_s,\mathbf{x}_s)$, $1 \leq i \leq m$, is called the \textit{local \textsc{mo-cbo} problem w.r.t. $\mathbf{X}_s$}.
\end{definition}

\noindent
For the local \textsc{mo-cbo} problem w.r.t. $\mathbf{X}_s \in \mathbb{P}(\mathbf{X})$, its Pareto set shall be denoted as $\mathcal{P}_s^{\mathsf{l}} (\mathbf{X}_s)$ and the associated Pareto front as $\mathcal{P}_f^{\mathsf{l}}(\mathbf{X}_s)$. Each local \textsc{mo-cbo} problem corresponds to a standard multi-objective optimization task, solvable with existing methods. The following proposition decomposes \textsc{mo-cbo} problems into such local problems. The proof is given in \cref{appendix:mo_cbo_decomposition}.

\begin{proposition}\label{prop:mo_cbo.decomposition}
Given $\langle \mathcal{G}, \mathbf{Y},\mathbf{X}, \mathbf{C} \rangle$, let $\mathcal{S} \subseteq \mathbb{P}(\mathbf{X})$ be a non-empty collection of intervention sets. Then, it holds
\begin{equation}
    \mathcal{P}_f^{\mathsf{c}}(\mathcal{S}) \subseteq \bigcup_{s=1}^{|\mathcal{S}|} \mathcal{P}_f^{\mathsf{l}}(\mathbf{X}_s).
\end{equation}
\end{proposition}

\noindent
Therefore, discovering the causal Pareto front requires to identify Pareto-optimal solutions of the local \textsc{mo-cbo} problems with respect to all intervention sets $\mathbf{X}_s \in \mathbb{P}(\mathbf{X})$.