\begin{algorithm}[!t]
\small
   \caption{Training Procedure}
   \label{alg:training}
   \SetKwInOut{Require}{Require}
   \KwIn{Training set $D_{tr}=\{V_i,T_i\}^M$, Video learner $f_\theta$.}  
   \Require{GWA Params $\theta_{\texttt{GWA}}$ update at each epoch with $l$ step length. CLIP Params $\theta_{\texttt{CLIP}}$. Batch size of training samples $B$. Learning rate $\alpha,\beta,\delta$.}
   \KwOut{The final GWA learner $f_{\theta_{\texttt{GWA}}}$.}
   \BlankLine
   Initialize $\theta, \theta_{\texttt{GWA}} \gets \theta_{\texttt{CLIP}}; \text{Step}=0; t=0$\\
   \While{not coverged}{
   $\text{Step} \gets \text{Step}+1$ \\
   Construct batch of tasks $\mathcal{T}_i=\{\mathcal{S},\mathcal{Q}\}$ by sampling $\mathcal{S},\mathcal{Q} \gets \{V_a,T_a\}^B, \{V_b,T_b\}^B \subseteq D_{tr}$\\
   \ForAll {$\mathcal{T}_i$}{
   \textcolor{iccvblue}{\tcp{meta training}}
   Evaluate $\nabla_\theta \mathcal{L}_{\mathcal{T}_i}^{\mathcal{S}}(\theta)$ \wrt Eq.~\eqref{eq:spt} \\
   Compute adapted parameters with gradient decent: $\theta'_i = \theta-\alpha \nabla_{\theta} \mathcal{L}_{\mathcal{T}_i}^{\mathcal{S}}(\theta)$ \wrt Eq.~\eqref{eq:spt_update}\\
   }
   \textcolor{iccvblue}{\tcp{meta testing}}
   Evaluate $\nabla_{\theta'_i} \mathcal{L}_{\mathcal{T}_i}^{\mathcal{Q}}(\theta'_i)$ \wrt Eq.~\eqref{eq:qry}\\
   \textcolor{iccvblue}{\tcp{meta-optimization}}
   Update $\theta$ \wrt Eq.~\eqref{eq:FOMAML} \\
   \textcolor{iccvblue}{\tcp{Gaussian Weight Average}}
   \If{$\text{mod}(\text{Step}, l)==0$}{
   $t \gets t+1; \theta_t \gets \theta$ \\
   Update $\theta_{\texttt{GWA}}$ \wrt Eq.~\eqref{eq:GWA}\\
   }
   }
\end{algorithm}
   