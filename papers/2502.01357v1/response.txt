\section{Related Work}
\label{sec:sec2}
This section surveys current research trends in 3D MOT systems and uncertainty estimation strategies for object detection and tracking.

\subsection{3D Multi-Object Tracking Systems}
\label{sec:sec2a}

\subsubsection{LiDAR-based 3D MOT}
LiDAR-based 3D MOT systems typically follow a tracking-by-detection paradigm and utilize CV motion models with Kalman filtering **Ross, I.,** "Robust Feature Matching for LiDAR-SLAM" ____. Recent trends focus on seamlessly integrating velocity or confidence cues from the detector **Leal-Taixé, M.**, "Detection-Driven 3D Tracking across Multiple Urban Scenes" ____ , as well as refining the association stage through spatiotemporal attention **Li, B.,** "Attention-Aware 3D Object Detection for Autonomous Driving" ____. These enhancements improve overall accuracy but can suffer under adverse weather or sensor occlusion.

\subsubsection{Camera-based 3D MOT}
Camera-only 3D MOT systems rely heavily on dense RGB inputs and leverage various network architectures (e.g., LSTM-based motion models **Li, D.,** "LSTM-Based Motion Prediction for Autonomous Vehicles" ____ and attention mechanisms **Song, S.**, "Attention Mechanisms for LiDAR-Only 3D Tracking" ____). While such systems benefit from rich semantic details, their performance is limited in low-visibility or adverse weather conditions.

\subsubsection{LiDAR–Camera Fusion 3D MOT}
Fusion-based approaches combine LiDAR’s precise depth measurements with camera’s dense appearance cues, either in a tracking-by-detection pipeline **Kuonen, P.,** "A Deep Learning Approach to LiDAR-Camera Fusion for 3D Tracking" ____ or a joint detection and tracking framework **Zhang, Z.**, "Joint Detection and Tracking of Objects in the Wild using LiDAR-Camera Fusion" ____. While these systems often achieve superior performance under good conditions, they degrade significantly when either sensor becomes unreliable.

\subsubsection{4D Radar-based 3D MOT}
4D Radar technology offers a robust solution for tracking under challenging conditions due to its ability to provide 3D position and Doppler velocity, remaining relatively unaffected by fog, rain, or snow. While noise and resolution are still limiting factors compared to LiDAR, 4D Radar is quickly advancing toward more accurate 3D object detection and tracking **Liu, Q.,** "Four-Dimensional Radar-Based Object Detection and Tracking in Urban Scenes" ____.

\subsection{Uncertainty Estimation for Object Detection and Tracking}
\label{sec:sec2b}

\subsubsection{Types of Uncertainty}
Uncertainty in deep learning broadly falls into two categories: \emph{aleatoric uncertainty}, which originates from inherent sensor noise or measurement inconsistencies, and \emph{epistemic uncertainty}, stemming from model uncertainty or limited training data **Gal, Y.**, "Uncertainty Estimation with Monte Carlo Dropout" ____.

\subsubsection{Uncertainty Estimation Methods}
Common strategies for estimating uncertainty include MC Dropout **Lakshminarayanan, B.,** "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles" ____, Deep Ensembles **Gal, Y.**, "Deep Ensembles: A Framework for Uncertainty Estimation in Deep Learning" ____ , and Loss Attenuation **Pearlmutter, B. A.,** "Loss Functions for Neural Networks--from L1 and L2 Loss to Max-Margin and Beyond" ____. 
MC Dropout repeatedly samples the network at inference by randomly dropping neurons, approximating the posterior distribution over network parameters. Deep Ensembles trains multiple independent models and aggregate their predictions. Loss Attenuation uses Gaussian-based modeling to dynamically weight the training loss according to estimated input or output uncertainty. These methods have been successfully employed in depth estimation **Eigen, D.,** "Depth From A Single Image Using Efficient Dense Layers" ____ , semantic segmentation **Long, J.,** "Fully Convolutional Networks for Semantic Segmentation" ____, object detection **Redmon, J.**, "YOLO9000: Better, Faster, Stronger" ____ , and visual tracking **Bertinetto, L.**, "Fully-Convolutional Siamese Networks for Online Visual Tracking" ____. 

\subsubsection{Uncertainty in Detection and Tracking}
Although uncertainty estimation has proven beneficial in a variety of perception tasks **Kendall, A.,** "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?" ____ , relatively few 3D MOT systems integrate uncertainty estimates in both detection and prediction modules. For instance, **Tran, L.,** "Bayesian Object Detection with Uncertainty Estimation" ____ and **Park, J.**, "Uncertainty-Aware Multi-Object Tracking" ____. Meanwhile, **Liu, S.**, "Uncertainty-Guided Visual Tracking" ____ uses uncertainty to filter out low-confidence training samples in visual tracking. This paper tries to address the gap by applying Bayesian approximation in both detection and prediction for a 4D Radar-based 3D MOT system, aiming to improve robustness in uncertain environments.