\section{Discussion}
\label{sec:discussion}

We discuss our findings in four parts: the first, about the potential for AEDTs and strategy use, such as referrals to circumvent automation to exacerbate social inequity; next, the implications this has for auditing such systems; third, the role of AEDTs (now and in the future) in holding employers accountable for problematic practices; and finally, directions for future AEDT policies that center workers' needs and experiences. 

\subsection{Exacerbating Social Inequity}
A major finding from this work was the role of individual attributes like socioeconomic status and strategy use, such as referrals in  job market outcomes. In the context of automated employment decision tools (AEDTs), this calls attention to the continued potential for more applicants to gain an advantage by using referrals and other methods to circumvent automated processes altogether. This is a major risk of automation --- that it will result in inequity based not just on the automated evaluations themselves, but in who is subject to them. This will be an important area for future research to continue studying. 

Our findings on socioeconomic differences in hiring outcomes extend current literature that employers factor class-based differences into hiring processes~\cite{adnin2022hiring}. We saw participants in our study achieve greater job success based on annual household income, despite not finding any significant differences in strategy use across all demographic lines, including race, gender, and income. One possible explanation for this phenomenon --- in which financially-privileged applicants report the same knowledge of hiring processes and even strategy use, but still see success at higher rates --- has been discussed in a qualitative investigation into how class differences shape computer science students' experiences and tactics in hiring~\cite{chua2021playing}. That research found that applicants across socioeconomic backgrounds used social connections to secure job offers, had access to connections at companies, displayed similar knowledge of employers' expectations, and faced similar emotional burdens. However, crucially, upper-middle-class participants in that study were more at ease crossing social hierarchy lines than their working- and middle-class counterparts~\cite{chua2021playing}. This manifested in differences in use of specific strategies, including cold-emailing professionals and setting up informal conversations about job opportunities, which ultimately led to referrals that circumvented official hiring pipelines. 
Working- and middle-class job seekers only relied on their closest connections and felt uncomfortable reaching outside that circle for fear of burdening others, whereas upper- and upper-middle-class job seekers felt comfortable using the same strategies to a much greater degree. Perhaps our data's indication of income as important for job market success, while strategy use and awareness of systems had insignificant impact, could be explained by magnitude: differences in people's scale of connections and willingness to use them. 

The impact of social privilege was striking in our findings, suggesting that current hiring practices exacerbate social inequality. Rather than finding that applicant success was driven by factors within their control, we instead found that applicants with greater access to referrals, who were thereby able to evade more automation than their peers, such as resume screeners, and those coming from higher socioeconomic backgrounds, were the ones who received job offers at higher rates. In contrast, more egalitarian strategies available to a wider range of applicants, like free online assessment practice, were not associated with higher levels of job success. Procedural fairness perceptions and willingness to be evaluated by AEDTs were lower among those who received more referrals, which may be explained by those privileged applicants who are able to obtain referrals both knowing about this alternative route to a job offer, and also knowing that many of their peers do not have access to it. Hiring processes that circumvent automation based on personal contacts, such as referrals and informal networks, violate key social justice dimensions, such as \textit{distribution} where the benefits and burdens of AEDTs are not equitably shared, and \textit{enablement} where all people do not have the ability to reach their full potential~\cite{dombrowski2016social}. In contrast to AEDTs that claim to be ``bias-free'' or ``bias-mitigating,'' our results suggest that automated hiring processes continue to perpetuate dominant social inequalities in hiring outcomes, and, newly, in what groups are required to interact with automated hiring tools.

\subsection{Implications for AEDT Auditing}

Speaking to differing perspectives on whether using connections is appropriate, our results also showed that applicants who received referrals had lower ratings of procedural fairness in hiring processes across evaluation types and automation levels. We saw this effect despite the potential for outcome favorability bias~\cite{wang2020factors} (applicants might bias towards thinking the strategies they use are \textit{more} fair). This might be a result of referral-using applicants seeing the system as more gameable, negatively impacting their perceptions of its fairness~\cite{armstrong2023navigating, chua2021playing, leclercq2020gamification}. Meanwhile, applicants without referrals may be unaware that this process exists, or that it can be used to circumvent large parts of the standard application pipeline. Of course, the system is --- and has always been --- gameable in this way. The use of referrals in technology jobs predates any AEDTs. In an ideal world, AEDT use would neither continue nor exacerbate previous human-system biases. Instead, we should re-evaluate current recruiting practices and insist on changes to these systems that provide improvements over prior processes. 

There are important implications for auditing practices towards achieving this outcome. Given the centrality of processes outside any AEDT, algorithm audits cannot stop at analyzing the algorithmic system alone. Instead, they should be done (as other research has recently argued~\cite{lam2023STA}), in the full sociotechnical context in which these tools are used. When applicants circumvent resume screening through referrals or other methods to jump to securing interviews, they gain an advantage that is not captured when auditing the AEDT in isolation. Instead, audits should extend to the entire hiring pipeline at companies using AEDTs (not to mention those which do not). These audits, as we also expressed above, must take into consideration a range of user attributes. Current hiring auditing laws and mandates tend to look at only gender and race~\cite{locallaw144}, but there may be additional and intersectional factors that impact experiences with AEDTs, including income, sexual orientation, age, and disability. 

\subsection{Accountability}
As they currently stand, AEDTs provide employers with two significant benefits: increased efficiency and accountability-avoidance. The first is straightforward; AEDTs allow employers to scale their hiring process and screen many more applicants with smaller HR departments. The latter is significantly more pernicious. As other scholars have also described, the use of AEDTs shifts accountability away from employers and onto the third-party systems they contract~\cite{sanchez2020does, ajunwa2019paradox, wilson2021building}. 

In traditional hiring practices with human decision-makers, the responsibility (or perhaps blame) for unfair hiring decisions could be traced to an individual or team. In contrast, AEDTs allow employers to claim ignorance and instead point the blame at AEDT developers~\cite{wright2024null, groves2024auditing}.  Additionally, across the board, participants reported not knowing how their data was used and not receiving feedback from prospective employers throughout the hiring process. These issues requires swift response from policymakers, such as that seen in New York City, whose recent Local Law 144 (LL144) mandates that employers using AEDTs publicly release a ``bias audit'' document regarding the tools they use~\cite{locallaw144}. 

And yet, there are limitations with such legislation. Most notably, employers are responsible for finding and paying the third-party auditors and publishing the audit results (beyond a few minimal required statistics), giving them out-sized control over these audits' findings~\cite{wright2024null, groves2024auditing}. Moreover, the audits themselves are not auditable! Details on what analysis was conducted on what data, and with what precise results, is not mandated by LL144. Additionally, there may be referrals and informal hiring practices that allow applicants to skip automated hiring processes altogether. Only examining AEDTs ignores the range of potential biases in the hiring pipeline as a whole. Legislation should consider more sociotechnical auditing approaches, looking beyond tool performance to the context in which these tools are used~\cite{lam2023STA}. As it stands, this kind of legislation runs the risk of perpetuating problematic practices and helping employers avoid true accountability. 

Instead of providing avenues for employers to show off their ``bias-free'' practices in a brief, vague document, we need policies aimed at convincingly demonstrating that workers are being treated fairly and lawfully, as well as avenues for recourse and worker-targeted resources for navigating AEDTs when there is (or is suspected to be) foul play. This brings us to our final discussion point, about developing policies that benefit workers, not just employers. 

\subsection{Worker-Centric Policies}
Our findings show that both referral use and the presence of automation breed distrust and perceptions of unfairness in applicants. These, along with the limitations of current legislation outlined above, speak to the need for more human-centered tools and policies. Specifically, in the workplace context, we name this angle \textit{worker-centric}. 

Current practices are completely divorced from workers' desires and their best interests. These are not unreasonable stakeholders --- consistent with prior work~\cite{lee2018understanding, zhang2022examining, gonzalez2022allying}, our participants were quite accepting of automated decisions for more technical scenarios, and relatively tolerant of it when guaranteed a human review of all automated rejection. As it stands, however, since employers are willing to tolerate some false negatives (qualified candidates who do not advance in their process) as opposed to false positives (unqualified candidates who do advance), they and third-party companies have designed AEDTs with the goal of minimizing false positives~\cite{friedrich1993primary}, in direct opposition to job seekers' preferences as studied in this paper and others~~\cite{morse2021ends, roulin2014interviewers}. 

Auditing policies like those focusing on ``equity'' in AEDT scoring or selection rates do not address these important dimensions of fairness during the intermediate steps of the process~\cite{locallaw144}. Legal mandates could help ensure applicants are treated fairly, and simultaneously increase their trust in these processes. In doing so, they would require employers to share in some part of the cost of AEDT use, instead of only relishing the benefits at the expense of job seekers. 

Outside the job market itself, another worker-centered effort could be undertaken by career services groups at universities  to create venues for young job seekers to meet mentors and alumni to bridge socioeconomic divides and work to demystify hidden curricula~\cite{nakai2023uncovering}.

\subsection{Limitations and Future Work}
We note a few key limitations that also provide opportunities for future study in this direction. First, our results are limited in their generalizability by the participant pool we surveyed. This means that our sample may not be reflective of all computing students (those enrolled in other types of institutions or in other geographical regions, in particular), or of all job seekers (especially those who are more senior in the workforce). We did control for whether applicants were finished with their job search; however, since participants took the survey in the fall,  some participants may have received later job offers, which we were not able to capture, introducing inaccuracy into our measure of hiring outcome success. We also did not collect age data from participants, which may also be an important factor in hiring outcomes. We encourage future research to investigate AEDT awareness, perceptions, and experiences with more granularity and in a wider range of settings with regard to location, career stage, age, and other attributes.

Second, our survey questions did not include the gamut of all AEDTs. We selected the specific evaluation methods and applicant strategies in our survey based on prior literature~\cite{armstrong2023navigating}, but may have left out important ones. Moreover, in a space changing as quickly as this one, the systems and strategies used, or people's perceptions about them, may change considerably in the coming years. We encourage future work to continue deepening our understandings of the topics we discussed, and to continue to broaden the research space as needed. 

Finally, while participants in our study reported trusting human evaluation more than AI-involved evaluation processes, we find it important to note that this does not mean human-only processes are free of issues. Indeed AEDT biases have been shown to mirror existing human biases~\cite{caliskan2017semantics}, and also sometimes stem from biases in their training data, which are human-made decisions~\cite{ajunwa2019auditing}. It is possible that our participants inflated their reported judgements of human evaluators in response to the idea of AI review posed in other questions. Future work should continue to study the reality of applicants' experiences navigating human review as well as AEDTs. 