\section{Background}
\label{sec:background}

We review previous research related to automated employment decision tools (AEDTs) as a whole, as well as work on how AEDTs impact various stakeholders' perceptions and applicant career-seeking. 

\subsection{Automated Employment Decision Tools}
Throughout the hiring process, recruiters increasingly rely on AEDTs to identify open positions and manage applicants, check and score resumes, evaluate technical skills, and even automate video interviews~\cite{bogen2018help, sanchez2020does}. The development of such technologies is an active area of research. For instance, prior work has built resume scanning tools using natural language processing~\cite{sanyal2017resume, harsha2022automated, bharadwaj2022resume} and by matching keywords in job descriptions to resumes~\cite{dhende2018candidate, satheesh2020resume} to assess candidates. Additionally, researchers have investigated how to use AI to screen applicants using automated video interviews where applicants record a video of themselves answering questions in a fixed amount of time. Researchers have then used AI to assess personality traits and evaluate job ``fit,'' through a variety of verbal and nonverbal behaviors, such as word choice, fluency, pronunciation, inflection, facial expressions, posture, and eye movements ~\cite{chen2016automated, naim2016automated, hickman2022automated}. However, other scholars have critiqued these methods, expressing concerns about their ethics and validity~\cite{roemmich2023values, rhea2022resume}. 

Such critiques are often connected to a research angle focused on algorithmic fairness. Prior research has shown that AI can learn implicit bias similar to humans, measured by word and image associations~\cite{caliskan2017semantics}. In the context of hiring, researchers have shown that AEDTs can not only be biased, but that they may do so in violation of anti-discrimination laws~\cite{ajunwa2019auditing, sanchez2020does, raghavan2020mitigating}. In one highly-publicized example, Amazon stopped using their resume reviewing AEDT after machine-learning specialists discovered it scored resumes lower when they mentioned the word ``woman'' or the names of historically women's colleges~\cite{dastin2018amazon}. Work has found gender bias in other systems as well, for example showing that some automated systems rate women's resumes lower than men's even when controlling for similar levels of experience and job-relevant traits~\cite{parasurama2022gendered, chen2018investigating}. In addition to gender bias, previous auditing work has found biases in such systems along the lines of race~\cite{ajunwa2019auditing}, disability status~\cite{buyl2022tackling}, and age~\cite{farber2017factors} among other factors. 

As new legislation like New York City's Local Law 144, which mandates employers publish the results of a bias audit for any AEDT they use, is enacted, there is a growing need to understand the perceptions and experiences of job seekers themselves, who otherwise have limited input in the hiring processes to which they are subjected. Recent work has found that current legislation is missing key definitions and auditing standards, does not prevent companies from using biased AEDTs, and gives employers an inappropriately high degree of discretion on who conducts the audits and what results are published from them~\cite{groves2024auditing, wright2024null}. Given this context, there is a crucial need for applicants' own perspectives to inform audits and policy. Our study contributes to this literature by providing insights into applicants' perceptions about AEDTs' procedural fairness, their willingness to be evaluated by AEDTs, and the formal and informal strategies they use to navigate the automated hiring landscape.


\subsection{Perceptions of Algorithmic Fairness}

It is imperative to understand not only bias within automated systems, but also people's perceptions of algorithmic fairness, which directly impact trust~\cite{woodruff2018qualitative, lee2018understanding}. One approach to understanding user perceptions of fairness in algorithmic decision-making is through \textit{procedural fairness}, which refers to an evaluation of the process by which a decision is made as opposed to its outcome~\cite{lee2019procedural, schoeffer2021appropriate}. Procedural fairness stands in contrast to other kinds of fairness perceptions of automated systems, including those focusing on outcomes (distributive fairness), interactions (interpersonal fairness), and  explanations (informational fairness)~\cite{colquitt2012organizational, schoeffer2021appropriate}. When comparing types of fairness perceptions, procedural fairness has been shown to be a robust predictor of overall fairness evaluations and heavily relied on by users to judge the fairness of AI systems~\cite{thibaut1975procedural, morse2021ends, glikson2020human}. Components that impact procedural fairness perceptions include the perceived consistency, competency, and benevolence of the decision-maker~\cite{lee2019procedural, morse2021ends, leventhal1980should, tyler2003procedural}. Additionally, how much voice individuals have over the decision process, such as the ability to provide feedback or overturn a flawed decision, can impact procedural fairness and system trust~\cite{lee2019procedural, morse2021ends, lind1990voice, folger1977distributive, jeung2023correct}. In this work, we measure people's perceptions of AEDTs' procedural fairness, building on existing literature in the space by investigating its relationship to participants' willingness to be evaluated by such AEDTs.

Numerous factors have been shown to impact people's perceptions of algorithmic fairness, such as the task being automated~\cite{lee2018understanding, zhang2022examining}, whether the system's decision is in the user's favor~\cite{wang2020factors}, and the amount of human oversight~\cite{lee2017algorithmic, gonzalez2022allying}. For tasks that require more human skills, such as hiring or work performance evaluations, people view algorithmic decision-makers as less fair, effective, and trustworthy than mechanical skills, like work assignment or scheduling~\cite{lee2018understanding}. Previous qualitative work on computing students' perceptions of automated hiring found that applicants felt human recruiters could assess skills that automated processes could not, and that this limited their ability to demonstrate the full extent of their skills when being automatically evaluated~\cite{armstrong2023navigating}. In general, entirely algorithmic decisions are perceived as less fair than decisions made by humans~\cite{lee2017algorithmic, gonzalez2022allying}. Human decision-making may also lead applicants to report more positive experiences with hiring due to the potential for social recognition, applicants' sense of being acknowledged and appreciated by another person~\cite{lee2018understanding, armstrong2023navigating}. Despite the current automated hiring landscape, applicants often attribute success in the hiring process to social recognition and connections~\cite{armstrong2023navigating, chua2021playing}. However, there is currently limited work on applicants' perceptions of fairness and their desire to be evaluated by automated versus non-automated systems as it exists in relation to other attributes like social connections.


\subsection{Career-Seeking Amid Automation}
Young job seekers' experiences with an increasingly automated landscape are important for their future success; insufficient support and negative experiences at this stage can impact career-seeking and transitions from school into the workforce~\cite{bock2013women, giannakos2017understanding, jones1986socialization, begel2008novice}. Perceptions and experiences in automated hiring may influence applicants' desire to apply for certain positions and sense of belonging in the field. Past work found that perceptions of algorithmic fairness impacted user trust with implications for tool use~\cite{woodruff2018qualitative}. 
When trust is lost, qualified applicants may be dissuaded from applying through automated hiring process with limited transparency \cite{van2021job}. This may be especially true of applicants coming from underrepresented backgrounds---the same applicants who are often most negatively impacted by biased AEDTs---whose decisions about whether to stay in the field are heavily influenced by environmental factors, presence of feedback, and presentation of information~\cite{bock2013women, giannakos2017understanding, metaxa2018gender}.
Prior work has found a disconnect between employers' and applicants' hiring process priorities~\cite{friedrich1993primary}, but as human resources professionals begin to utilize AEDTs, there is some research to suggest that even some HR workers have concerns about data accuracy and ceding control to automated decision-making systems~\cite{li2021algorithmic}. 

Given job seekers' concerns, they must develop new strategies to navigate automation. Qualitative research interviewing job-seekers has revealed the importance of referrals in circumventing automation and securing job offers, and that they often attribute their hiring successes to knowing how to ``play the hiring game''~\cite{armstrong2023navigating, chua2021playing}. Students from different socioeconomic backgrounds have reported different experiences with hiring processes even when they have access to the same resources, with applicants from working and middle-class backgrounds feeling like they need to earn social credit before relying on social connections~\cite{chua2021playing}. Consequently, automated hiring experiences and knowledge of strategies may not only impact applicants desire to stay in the computing field~\cite{olson2014opportunities}, but also their ability to receive job offers. Further work is needed to assess applicants' experiences and perceptions of fairness in relation to socioeconomic status and resource access in the context of automated hiring processes. We expand on prior qualitative work by providing a quantitative survey investigation, examining how referrals and other strategies impact people's perceptions of procedural fairness, desire to be evaluated by AEDTs, and job-seeking success. 