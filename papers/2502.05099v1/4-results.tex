\section{Findings}
\label{sec:results}

We proposed these hypotheses and statistically analyzed survey responses to answer each research question:

\begin{enumerate}
\item[RQ1:] How do young job seekers' perceptions of AEDTs' procedural fairness and their own willingness to be evaluated by different AEDT hiring processes change as the level of automation and type of evaluation change?
\item[\textit{H1:}] \textit{As the level of automation in hiring scenarios increases, and as the technical nature of the evaluation type increases, perceptions of fairness will decrease.}
\item[ ] Prior work has shown that perceptions of fairness increase for more mechanical tasks~\cite{lee2018understanding, zhang2022examining} and when a human decision maker is included~\cite{gonzalez2022allying}, which we hypothesized will also hold in our study, in regards to participants' reported procedural fairness evaluations of different AEDTs and willingness to be evaluated by them.
\end{enumerate}

\begin{enumerate}
\item[RQ2:] Do perceptions of AEDTs' procedural fairness and willingness to be evaluated by AEDTs change based on applicants' use of strategies to be successful in the hiring process?
\item[\textit{H2:}] \textit{Participants with greater use of strategies will report lower perceptions of fairness.}
\item[ ] We suspected that applicants who have more resource access and greater awareness of AEDTs might view the system as less meritocratic and more game-able, and thus distrust their fairness ~\cite{leclercq2020gamification, leutner2023game}.
\end{enumerate}

\begin{enumerate}
 \item[RQ3:] How do awareness about AEDTs, strategies to navigate automation, and demographic attributes (like gender, race, and income) relate to job market outcomes?
\item[\textit{H3:}] \textit{Participants with higher AEDT-awareness and higher reported strategy use will obtain more job offers.}
\item[ ] We hypothesized that applicants with more experience and awareness of automated systems would be better at navigating automated hiring systems and therefore see more positive job outcomes based on prior work showing applicants attribute their successes to awareness of how to play the ``game'' in hiring~\cite{armstrong2023navigating, chua2021playing}.
\end{enumerate}

We found evidence to support the first and second hypotheses. Participants largely did not consider automated processes fair or want to be evaluated by them, and they rated greater automation (less human involvement) and automation of less technical evaluations (i.e., interviews as opposed to coding assessments) lower across on both measures.
When looking at the relationship between perceptions of fairness and strategy use, the use of strategies like referrals, as well as awareness of some AEDTs was associated with lower fairness ratings. 
We found partial evidence supporting the third hypothesis; use of referrals was the only strategy associated with job market success. The other major predictor of job success was family household income. 


\subsection{Participants' Perceptions of the Hiring Process}

We begin by answering RQ1: how do young job seekers' perceptions of AEDT procedural fairness and willingness change as a result of automation level and evaluation type?

In the first part of the survey, participants rated the procedural fairness and their own willingness to be evaluated by different hiring scenarios on a 5-point Likert scale. Each scenario, as described in Section~\ref{sec:methods}, had an \textbf{evaluation type} (online coding assessment, resume, or interview) and \textbf{automation level} (human-only, human-AI, AI with human review of rejections, AI with human review of acceptances, and AI-only). Participants rated both (1) how \textit{fair} they found the hiring process in the scenario, and also (2) their \textit{willingness} to be evaluated that way themselves. We found that participants' ratings of procedural fairness were generally similar to their own willingness to be evaluated by these methods, but that the  willingness measure was usually slightly lower (confirmed with a paired t-test comparing all ratings of (1) to ratings of (2) ($t(6718) = 23.27$, $p < 0.001$)).

\subsubsection{Evaluation Type} Comparing participant perceptions of fairness in the three evaluation types (online coding assessment, resume, and interview), we found that participants rated the use of automation (all decision-makers except ``human-only'') as less fair in less technical evaluation types than more technical ones. Automation was perceived as most fair for a coding assessment evaluation and least fair for a behavioral interview evaluation (see Figure ~\ref{fig:scenarios}). We conducted an ANOVA for the effects of evaluation type ($F(2) = 238.15$, $p < 0.001$) and automation level ($F(4) = 518.93$, $p < 0.001$) on procedural fairness perceptions, finding significant effects for each, as well as their interaction ($F(8) = 51.19$, $p < 0.001$). We also conducted an ANOVA for the effects of evaluation type ($F(2) = 267.07$, $p < 0.001$), automation level ($F(4) = 521.17$, $p < 0.001$), and their interaction ($F(8) = 68.37$, $p < 0.001$) on participants' own willingness to be evaluated in this way, with consistent results of the significant effects.
We did not find any significant effects of race, gender, or household income on procedural fairness or willingness perceptions.

Several participants verbalized the idea that less technical evaluation types should not be automated in their responses to an open-ended question in which we asked for their thoughts on this part of the survey. One participant explained, ``[A] resume is much harder to quantify via an algorithm than piece of code.'' Another explained, ``resumes are much more nuanced than coding assessments, as applicants can have different strengths and weaknesses which can qualify them differently.''
The idea that the use of automation in hiring processes leads them to be ``gamed'' and therefore less fair caused participants to bristle.
One wrote, ``Much more than resumes and coding assignments, automating the actual interview removes the human aspect of jobs and turns it into a game. Not only could interviewees cheat the system, exploit bugs, and cause chaos, but turning human interaction into a soulless computer guessing game makes the interview much less about how much an employer likes a candidate but how much the candidate can understand the algorithm judging it.''

\begin{figure}
\centering
  \includegraphics[width = 0.74\textwidth]{figures/scenarios.png}
  \includegraphics[width = 0.24\textwidth]{figures/legend.png}
  \Description[Bar chart comparing fairness ratings for a range of evaluation types and automation levels.]{Bar chart where human-only evaluation is preferred over AI, especially for interview assessments.}
  \caption{Participants' \textit{procedural fairness} and \textit{willingness} perceptions for different evaluation types and levels of automation were rated on a Likert scale (1: process seems very unfair / unwilling to be evaluated this way --- 5: seems very fair / willing to be evaluated this way). Notably, both measures performed similarly with participants. Responses reflected that some human involvement was always preferred, and AI-only review was least-preferred across evaluation types. However, there was a greater tolerance for AI involvement in more technical evaluations (i.e., in coding assessments compared to interviews). Bars represent 95\% confidence intervals.} 
  \label{fig:scenarios}
\end{figure}

\subsubsection{Automation Level} 
Regarding automation levels (human-only, human-AI, AI with human review of rejections, AI with human review of acceptances, and AI-only), fairness and willingness ratings were higher for lower levels of automation across evaluation types (see Figure ~\ref{fig:scenarios}). Participants found the scenarios more fair when there was a human in the loop, and the AI-only conditions always ranked lowest. Summarizing this perspective in an AI-only interview scenario, one participant wrote, ``This is the worst so far, human interaction can't be replaced with a machine. Personally, I've taken an automated interview and it felt wrong.''

Within the human-AI combination decision-makers, participants preferred a human evaluator to review AI decisions for rejections (checking for false negatives) over acceptances (checking for false positives) (Figure ~\ref{fig:scenarios}). A one-sided paired t-test confirmed this finding as statistically significant for both the fairness ($M= 0.48$, $CI= 0.43$, $t(1343)=15.92$, $p < 0.001$) and willingness ($M= 0.43$, $CI= 0.37$, $t(1343)=13.37$, $p < 0.001$) measures.

This aligned with our hypotheses about job applicants' priorities; as one participant expressed, ``an algorithm rejecting a deserving applicant is a lot worse than advancing an undeserving applicant.''
Overall, participants perceived human evaluators as a guardrail against AI, which they perceived as potentially more biased. One participant summarized: ``I think that there should be some aspect of human review, whether or not the applicant passes doesn't really matter, I think there should just be some sort of fail-safe.''

\begin{table}
\begin{tabular}{lr} \hline
\textbf{Strategy Use} & \textbf{Percentage} \\ \hline                    
    \hspace{2mm}Used online resources              & 81\% \\ 
    \hspace{2mm}Practiced for online coding assessment              & 69\% \\ 
    \hspace{2mm}Talked with people who had recently applied              & 63\% \\ 
    \hspace{2mm}Used referrals              & 57\% \\ 
    \hspace{2mm}Used application materials and descriptions              & 57\% \\ 
    \hspace{2mm}Had friends who worked at companies                      & 51\% \\
    \hspace{2mm}Mass-applied to companies (more than 20)                 & 50\% \\ 
    \hspace{2mm}Used career services through university                  & 45\% \\
    \hspace{2mm}Modified resumes using keywords from the job description & 42\% \\
    \hspace{2mm}Connected with recruiter through company                 & 34\% \\         
    \hspace{2mm}Put resume through a resume scanner                      & 26\% \\       
    \hspace{2mm}Had family members who worked at companies               & 19\% \\              
    \hspace{2mm}Connected with recruiter outside of company              & 12\% \\ \hline
\end{tabular}
\caption{\label{tab:strategies} Most participants used a variety of strategies to navigate automated hiring processes, especially  online resources, practice for online coding assessments, and talking with others who had recently applied.}
\end{table}

\subsection{Strategy Use}

In these results, we answer research questions RQ2 (Do perceptions of AEDTs' fairness and willingness to be evaluated by AEDTs change based on applicants' use of strategies to be successful in the hiring process?) and RQ3 (How do awareness about AEDTs, strategies to navigate automation, and demographic attributes like gender, race, and income relate to job market outcomes?).

\subsubsection{Descriptive Results}
Participants reported differences in strategy use (e.g., online coding assessment practice or modifying resumes for scanners), visualized in Table~\ref{tab:strategies}. While many applicants added keywords from the job description to their resume (42\%), fewer applicants had put their resume through a resume scanner to see how it was processed (26\%). A more commonly-used strategy than either was the use of LeetCode or another coding assessment practice tool (69\%). 
Mass-applying, which we define as applying to more than 20 jobs, was another strategy exactly half of participants reported using. 33\% of participants applied to more than 50 jobs. Overall, participants' number of applications ranged from zero to 600 ($mean = 45$, $median = 17$). Number of company applications are visualized in Figure~\ref{fig:numCompanies}. When applying, 57\% reported receiving at least one referral; applicants reported receiving referrals for an average of 12\% of their job applications, though this was skewed by some on the much higher end ($mean = 12\%$, $median = 3\%$) (Figure \ref{fig:referral}). 

Participants reported learning about the hiring process through many different channels, including online resources (81\%), others who had recently applied (63\%), application materials and descriptions (57\%), friends who worked at companies (51\%), career services through their universities (45\%), company recruiters (34\%), family members who worked at companies (19\%), and recruiters outside of companies (12\%). 
In terms of awareness of these systems, most applicants knew AEDTs existed: 95\% had heard of online coding assessments, 88\% had for automated resume readers, and 87\% for automated video interviews. Most also reported personal experience with these systems: 63\% of participants reported having experience with online coding assessments, 53\% for automated video interviews, 47\% for resume readers, and 38\% for applicant tracking systems. We found less familiarity with automated resume readers and applicant tracking systems, perhaps because these are often not explicitly mentioned as automated in the application process~\cite{schumann2020we, wilson2021building}. Additionally, many participants reported not know how their data was used in the hiring process (77\%) and not receiving feedback throughout the process (83\%).

 \subsubsection{Strategy Use and Participant Perceptions}
Next, we compare participants' perceptions of procedural fairness and their willingness to be evaluated by AEDTs, as these relate to the various strategies participants used. (For a complete list of these strategies, see Table~\ref{tab:strategies}). 
Using a linear model predicting participants' average perceived fairness and willingness ratings from awareness of and use of different strategies (as well as participant demographics), we found that participants who reported \textit{using referrals} (Fairness: $F(200) = -2.478$, $p = 0.014$; Willingness: $F(200) = -2.312$, $p = 0.022$), and who were \textit{aware of online coding assessment tools} like LeetCode (Fairness: $F(200) = -2.349$, $p = 0.020$; Willingness: $F(200) = -2.356$, $p = 0.019$) reported lower perceived fairness and lower evaluation willingness, while \textit{awareness of automated video interviews} was actually associated with higher fairness and willingness scores (Fairness: $F(200) = 2.113$, $p = 0.036$; Willingness: $F(426) = 2.608$, $p = 0.010$).

Two other attributes (participants who reported using online resources in their application process and believed they knew how their data were used) had inconsistent effects on fairness and willingness. The remaining strategies did not  show significant effects on either fairness or willingness, which included modifying resumes with keywords, changing layouts for resume scanners, testing resumes with scanners, practicing for online coding assessments with tools like LeetCode, mass-applying to companies, using career services, or access to contacts within companies. We also did not find significant effects due to any demographic variables, including race, gender, or household income. For the full statistical test results see Appendix Tables~\ref{tab:fairStats} and ~\ref{tab:evalStats}.

\subsubsection{Strategy Use and Job Outcomes}

\begin{figure}
\centering
\begin{minipage}{.45\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{figures/numCompanies.png}
  \Description[Histogram of number of jobs participants applied to]{Histogram with long tail showing most participants applied to <15 jobs but many applied to 50 or more}
  \captionof{figure}{Participants reported applying to 0 to 600 jobs, with 50\% applying to more than 20.}
  \label{fig:numCompanies}
\end{minipage}%
\hspace{0.05\textwidth}
\begin{minipage}{.45\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{figures/referrals.png}
  \Description[Histogram of percent of applications that used referrals]{Histogram long tail shows hat most participants used <5 referrals but many had 20 or more.}
  \captionof{figure}{Participants used referrals in anywhere from 0\% to 100\% of applications, with over half of participants having at least one referral.}
  \label{fig:referral}
\end{minipage}
\end{figure}

Finally, we investigated the effect of awareness of AEDTs and strategy use on job outcomes. We defined job success as receiving one or more job offers, and fit a regression to predict job success from strategy use, awareness of AEDTs, gender, race, and income.  We found little evidence to suggest many measures of strategy use (i.e., modifying resumes with keywords, checking resumes with scanners, practicing LeetCode, mass-applying to companies, or talking with recent applicants) impact job outcomes. While using at least one referral was not significant, having a higher percentage of jobs applied to with a referral did have significant effects on hiring outcomes ($F(128)=2.063$, $p < 0.041$). 

The other major factor we identified that related to job outcome success was family income. Even after controlling for strategy use, participants who reported higher family income had more success securing employment ($F(128)=2.530$, $p = 0.013$) (Figure~\ref{fig:jobOffers}). For the full test results see Appendix Table ~\ref{tab:jobStats}.
Several mechanisms might explain this effect. For instance, students from more affluent backgrounds may have more internship experience due to their ability to accept unpaid positions, or their family connections to industry may carry more weight. As one participant succinctly described, ``My father [gave] me a hiring QR code which I used to apply for the job and then was hired after a meeting.''

\begin{figure}
    \centering
    \includegraphics[width = 0.9\textwidth]{figures/hiringOutcome.png}
    \Description[Stacked bar chart of hiring outcome by annual household income]{Stacked bar chart showing that most applicants without job offers came from families making under 200k per year; rates of 1+ job offers skew slightly higher.}
    \caption{Participants reporting higher annual household incomes were also more likely to receive one or more job offers.}
    \label{fig:jobOffers}
\end{figure}