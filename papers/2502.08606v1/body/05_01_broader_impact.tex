\section*{Impact Statement}
\label{sec:impact-statement}

This work shows how to apply the framework of scaling laws to the distillation setting,
investigating distillation as a viable alternative to the overtraining paradigm for producing 
capable language models.
The work explains when distillation \emph{should} and \emph{should not} be performed, from a compute efficiency perspective, compared to supervised learning.
There are a number of benefits to this:
\begin{enumerate}
    \item As compute-optimal recipes for distillation are now known, there is greater opportunity for producing powerful models with lower inference costs.
    Lowering inference costs lower the largest component of language model training carbon footprint.
    \item When combined with other known scaling laws, there is a larger space of models for which we know compute-optimal configurations. 
    To produce models with a given capability, the compute, hardware and climate costs have now been reduced compared to before, as the optimal recipe is known.
    \item Our distillation scaling law lowers compute usage through removing unnecessary experimentation over various hyperparameters and distillation settings. We now understand that the primary driver of student cross-entropy is teacher cross-entropy, and so teacher size and tokens can be discarded as axes to search over.
    \item Small powerful models democratize the study of models with significant capabilities, enabling the involvement of a greater number of perspectives to study
    model capabilities and safety aspects.
\end{enumerate}
There are however, potential negative consequences:
\begin{enumerate}
    \item Using distillation as part of a training pipeline introduces new sources of bias. Teacher models may contain bias from their pretraining data. Even if a student is distilled on data that is unbiased, the bias of the teacher will be inherited by the student.
    \item Small powerful language models are more efficient during inference, reducing the amount of resources needed for bad actors to achieve their goals, such as generating targeted misinformation at scale.
\end{enumerate}
