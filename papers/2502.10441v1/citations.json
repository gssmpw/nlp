[
  {
    "index": 0,
    "papers": [
      {
        "key": "christiano2017deep",
        "author": "Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario",
        "title": "Deep reinforcement learning from human preferences"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "ziegler2019fine",
        "author": "Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey",
        "title": "Fine-tuning language models from human preferences"
      },
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "perez2022red",
        "author": "Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey",
        "title": "Red Teaming Language Models with Language Models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "rafailov2024direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "ethayarajh2024kto",
        "author": "Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe",
        "title": "Kto: Model alignment as prospect theoretic optimization"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "bai2022constitutional",
        "author": "Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others",
        "title": "Constitutional ai: Harmlessness from ai feedback"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "bai2022constitutional",
        "author": "Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others",
        "title": "Constitutional ai: Harmlessness from ai feedback"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "anthropic2024claude",
        "author": "Anthropic",
        "title": "Claude's Constitution"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "huang2024collective",
        "author": "Huang, Saffron and Siddarth, Divya and Lovitt, Liane and Liao, Thomas I and Durmus, Esin and Tamkin, Alex and Ganguli, Deep",
        "title": "Collective Constitutional AI: Aligning a Language Model with Public Input"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "mu2024rule",
        "author": "Tong Mu and Alec Helyar and Johannes Heidecke and Joshua Achiam and Andrea Vallone and Ian D Kivlichan and Molly Lin and Alex Beutel and John Schulman and Lilian Weng",
        "title": "Rule Based Rewards for Fine-Grained {LLM} Safety"
      },
      {
        "key": "dong2023steerlmattributeconditionedsft",
        "author": "Dong, Yi and Wang, Zhilin and Sreedhar, Makesh Narsimhan and Wu, Xianchao and Kuchaiev, Oleksii",
        "title": "Steerlm: Attribute conditioned sft as an (user-steerable) alternative to rlhf"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "davis2023affordances",
        "author": "Davis, Jenny L",
        "title": "\u2018Affordances\u2019 for Machine Learning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "obiValueImprintTechnique2024",
        "author": "Obi, Ike and Pant, Rohan and Agrawal, Srishti Shekhar and Ghazanfar, Maham and Basiletti, Aaron",
        "title": "Value Imprint: A Technique for Auditing the Human Values Embedded in RLHF Datasets"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "klingefjord2024humanvaluesalignai",
        "author": "Klingefjord, Oliver and Lowe, Ryan and Edelman, Joe",
        "title": "What are human values, and how do we align AI to them?"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "findeis2024inverse",
        "author": "Findeis, Arduin and Kaufmann, Timo and H{\\\"u}llermeier, Eyke and Albanie, Samuel and Mullins, Robert",
        "title": "Inverse Constitutional AI: Compressing Preferences into Principles"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "sorensen2024roadmap",
        "author": "Sorensen, Taylor and Moore, Jared and Fisher, Jillian and Gordon, Mitchell and Mireshghallah, Niloofar and Rytting, Christopher Michael and Ye, Andre and Jiang, Liwei and Lu, Ximing and Dziri, Nouha and others",
        "title": "A roadmap to pluralistic alignment"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "sorensenValueKaleidoscopeEngaging2024",
        "author": "Sorensen, Taylor and Jiang, Liwei and Hwang, Jena D. and Levine, Sydney and Pyatkin, Valentina and West, Peter and Dziri, Nouha and Lu, Ximing and Rao, Kavel and Bhagavatula, Chandra and Sap, Maarten and Tasioulas, John and Choi, Yejin",
        "title": "Value {{Kaleidoscope}}: {{Engaging AI}} with {{Pluralistic Human Values}}, {{Rights}}, and {{Duties}}"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "kirkprism",
        "author": "Kirk, Hannah Rose and Whitefield, Alexander and R{\\\"o}ttger, Paul and Bean, Andrew Michael and Margatina, Katerina and Mosquera, Rafael and Ciro, Juan Manuel and Bartolo, Max and Williams, Adina and He, He and others",
        "title": "The PRISM Alignment Dataset: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "feng2024modular",
        "author": "Feng, Shangbin and Sorensen, Taylor and Liu, Yuhan and Fisher, Jillian and Park, Chan Young and Choi, Yejin and Tsvetkov, Yulia",
        "title": "Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "klassen2024pluralistic",
        "author": "Klassen, Toryn Q and Alamdari, Parand A and McIlraith, Sheila A",
        "title": "Pluralistic Alignment Over Time"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "conitzer2024position",
        "author": "Conitzer, Vincent and Freedman, Rachel and Heitzig, Jobst and Holliday, Wesley H and Jacobs, Bob M and Lambert, Nathan and Moss{\\'e}, Milan and Pacuit, Eric and Russell, Stuart and Schoelkopf, Hailey and others",
        "title": "Position: Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "sandri-etal-2023-dont",
        "author": "Sandri, Marta  and\nLeonardelli, Elisa  and\nTonelli, Sara  and\nJezek, Elisabetta",
        "title": "Why Don`t You Do It Right? Analysing Annotators' Disagreement in Subjective Tasks"
      },
      {
        "key": "wang2024aligninglanguagemodelshuman",
        "author": "Wang, Jiashuo and Wang, Haozhao and Sun, Shichao and Li, Wenjie",
        "title": "Aligning language models with human preferences via a bayesian approach"
      },
      {
        "key": "Cabitza_2023",
        "author": "Cabitza, Federico and Campagner, Andrea and Basile, Valerio",
        "title": "Toward a Perspectivist Turn in Ground Truthing for Predictive Computing"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "plank-2022-problem",
        "author": "Plank, Barbara",
        "title": "The {\\textquotedblleft}Problem{\\textquotedblright} of Human Label Variation: On Ground Truth in Data, Modeling and Evaluation"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "zhang2024divergingpreferencesannotatorsdisagree",
        "author": "Zhang, Michael JQ and Wang, Zhilin and Hwang, Jena D and Dong, Yi and Delalleau, Olivier and Choi, Yejin and Choi, Eunsol and Ren, Xiang and Pyatkin, Valentina",
        "title": "Diverging Preferences: When do Annotators Disagree and do Models Know?"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "feffer2023moralmachinetyrannymajority",
        "author": "Feffer, Michael and Heidari, Hoda and Lipton, Zachary C",
        "title": "Moral machine or tyranny of the majority?"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "paun-etal-2018-comparing",
        "author": "Paun, Silviu  and\nCarpenter, Bob  and\nChamberlain, Jon  and\nHovy, Dirk  and\nKruschwitz, Udo  and\nPoesio, Massimo",
        "title": "Comparing {B}ayesian Models of Annotation"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "davani-etal-2022-dealing",
        "author": "Mostafazadeh Davani, Aida  and\nD{\\'i}az, Mark  and\nPrabhakaran, Vinodkumar",
        "title": "Dealing with Disagreements: Looking Beyond the Majority Vote in Subjective Annotations"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "liu2024aligning",
        "author": "Liu, Yinhong and Zhou, Han and Guo, Zhijiang and Shareghi, Ehsan and Vulic, Ivan and Korhonen, Anna and Collier, Nigel",
        "title": "Aligning with human judgement: The role of pairwise preference in large language model evaluators"
      },
      {
        "key": "wu2023stylesubstanceevaluationbiases",
        "author": "Wu, Minghao and Aji, Alham Fikri",
        "title": "Style over substance: Evaluation biases for large language models"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "li2024decompose",
        "author": "Li, Minzhi and Liu, Zhengyuan and Deng, Shumin and Joty, Shafiq and Chen, Nancy F and Kan, Min-Yen",
        "title": "Decompose and Aggregate: A Step-by-Step Interpretable Evaluation Framework"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "caputo2024alignment",
        "author": "Caputo, Nicholas",
        "title": "Alignment as Jurisprudence"
      },
      {
        "key": "abiri2024public",
        "author": "Abiri, Gilad",
        "title": "Public Constitutional AI"
      },
      {
        "key": "nay2024law",
        "author": "John J. Nay",
        "title": "Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "caputo2024alignment",
        "author": "Caputo, Nicholas",
        "title": "Alignment as Jurisprudence"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "abiri2024public",
        "author": "Abiri, Gilad",
        "title": "Public Constitutional AI"
      }
    ]
  }
]