\section{Method}

\subsection{Proofs}

In the proofs we use the simplified notations ${ \mathbf{x}}:=({ \bm{\theta}},{ \mathbf{p}})$, ${ \mathbf{y}}:={ \mathbf{s}}$, $f({ \mathbf{x}},{ \mathbf{y}}):=G({ \bm{\theta}},{ \mathbf{p}},{ \mathbf{s}})$, ${ \mathbf{y}}^*({ \mathbf{x}}):=\arg\max_{ \mathbf{y}} f({ \mathbf{x}},{ \mathbf{y}})$ and $g({ \mathbf{x}}):=f({ \mathbf{x}},{ \mathbf{y}}^*({ \mathbf{x}})).$ 

\subsubsection{proof of lemma \ref{lemma1}}

First we introduce some lemmas from previous literature.

\begin{lemma} 
\label{lemma2}
(Lemma 1.2.3, Theorem 2.1.8 and Theorem 2.1.10 in \cite{nesterov2013introductory})
\begin{itemize}
    \item Suppose a function \( h \) is \( L_h \)-gradient-Lipschitz and has a unique maximizer \( { \mathbf{x}}^* \). Then, for any \( { \mathbf{x}} \), we have:
    \[
    \frac{1}{2L_h} \|\nabla h({ \mathbf{x}})\|_2^2 \leq h({ \mathbf{x}}^*) - h({ \mathbf{x}}) \leq \frac{L_h}{2} \|{ \mathbf{x}} - { \mathbf{x}}^*\|_2^2. \tag{15}
    \]
    
    \item Suppose a function \( h \) is \( \tau_h \)-strongly concave and has a unique maximizer \( { \mathbf{x}}^* \). Then, for any \( { \mathbf{x}} \), we have:
    \[
    \frac{\tau_h}{2} \|{ \mathbf{x}} - { \mathbf{x}}^*\|_2^2 \leq h({ \mathbf{x}}^*) - h({ \mathbf{x}}) \leq \frac{1}{2\tau_h} \|\nabla h({ \mathbf{x}})\|_2^2. \tag{16}
    \]
\end{itemize}
\end{lemma}

From lemma \ref{lemma2} and the definition of $\epsilon$-stationary point (in definition \ref{definition1}) we can get the following lemma.

\begin{lemma}
\label{lemma3}
    Suppose assumption \ref{assumption1} holds and $({ \mathbf{x}}_\epsilon,{ \mathbf{y}}_\epsilon)$ is an $\epsilon$-stationary point of $\min_{ \mathbf{x}}\max_{ \mathbf{y}} f({ \mathbf{x}},{ \mathbf{y}})$, let $({ \bm{\theta}}_\epsilon,{ \mathbf{p}}_\epsilon)={ \mathbf{x}}_\epsilon$ we have
    $$F({ \bm{\theta}}_\epsilon,{ \mathbf{s}}_\epsilon)-\min_{ \mathbf{s}} F({ \bm{\theta}}_\epsilon,{ \mathbf{s}}) \leq O(\frac{\epsilon^2}{\lambda^2}).$$
\end{lemma}

\begin{proof}
    $$F({ \bm{\theta}}_\epsilon,{ \mathbf{s}}_\epsilon)-\min_{ \mathbf{s}} F({ \bm{\theta}}_\epsilon,{ \mathbf{s}}) \leq \frac{1}{\tau}\|\nabla_{ \mathbf{s}} F({ \bm{\theta}}_\epsilon,{ \mathbf{s}}_\epsilon)\|^2=\frac{1}{\lambda^2\tau}\|\nabla_{ \mathbf{y}} f({ \mathbf{x}}_\epsilon,{ \mathbf{y}}_\epsilon)\|^2\leq O(\frac{\epsilon^2}{\lambda^2}),$$
    here the first inequality is from Lemma \ref{lemma2} applied to $-F$ and the second inequality from definition \ref{definition1}.
\end{proof}

The following is a rephrase of theorem 2 in \cite{LuMei24}.

\begin{proof} (proof of lemma \ref{lemma1})
    By Lemma \ref{lemma3} and the value of $\lambda$ we have $$F({ \bm{\theta}}_\epsilon,{ \mathbf{s}}_\epsilon)-\min_{ \mathbf{s}} F({ \bm{\theta}}_\epsilon,{ \mathbf{s}}) \leq O(\epsilon^4).$$

    Therefore, by Theorem 2 in \cite{LuMei24} we have $\mathbb{E}[\|\nabla F({ \bm{\theta}},{ \mathbf{p}}^*({ \bm{\theta}}))\|]\leq O(\epsilon)$ and Lemma \ref{lemma1} is proven.
\end{proof}

\subsubsection{proof of theorem \ref{theorem1}}

Based on Lemma \ref{lemma1}, it suffices to prove that the algorithm \ref{bi_minimax_ZOFO} outputs an $\epsilon$-stationary point of $\min_{ \mathbf{x}}\max_{ \mathbf{y}} f({ \mathbf{x}},{ \mathbf{y}})$. In this section we will prove this conclusion.

First we introduce the smoothed function of $f$, which will be useful in the proof. 

\begin{lemma}
\label{lemma5}
    (Lemma C.2 in \cite{zhang2024dpzero})
        Let \( { \mathbf{u}} \) be uniformly sampled from the Euclidean sphere \( \sqrt{d}\mathbb{{ \mathbf{s}}}^{d-1} \) and \( { \mathbf{v}} \) be uniformly sampled from the Euclidean ball \( \sqrt{d}\mathbb{B}^d = \{ { \mathbf{x}} \in \mathbb{R}^d \mid \|{ \mathbf{x}}\| \leq \sqrt{d} \} \). For any function \( f({ \mathbf{x}}) : \mathbb{R}^d \to \mathbb{R} \) and \( \alpha > 0 \), we define its zeroth-order gradient estimator as:

\[
\hat{\nabla} f_\alpha({ \mathbf{x}}) = \frac{f({ \mathbf{x}} + \alpha { \mathbf{u}}) - f({ \mathbf{x}} - \alpha { \mathbf{u}})}{2 \alpha} { \mathbf{u}},
\]
and the smoothed function as:
\[
f_\alpha({ \mathbf{x}}) = \mathbb{E}_{ \mathbf{v}}[f({ \mathbf{x}} + \alpha { \mathbf{v}})].
\]

The following properties hold:

\begin{itemize}
    \item[(i)] \( f_\alpha({ \mathbf{x}}) \) is differentiable and \( \mathbb{E}_{ \mathbf{u}}[\hat{\nabla} f_\alpha({ \mathbf{x}})] = \nabla f_\alpha({ \mathbf{x}}) \).
    
    \item[(ii)] If \( f({ \mathbf{x}}) \) is \(\ell\)-smooth, then we have that:
    \[
    \|\nabla f({ \mathbf{x}}) - \nabla f_\alpha({ \mathbf{x}})\| \leq \frac{\ell}{2} \alpha d^{3/2}.
    \]
\end{itemize}
\end{lemma}

If we use $f({ \mathbf{x}},{ \mathbf{y}};\xi)$ to denote a forward evaluation with random samples $\xi$ and let batch size $B=|\xi|$, then $f({ \mathbf{x}},\cdot;\xi)$ is a function from $\mathbb{R}^d$ to $\mathbb{R}$ and $\ell$-smooth. The above lemma can be used on $f({ \mathbf{x}},\cdot)$ and $f({ \mathbf{x}},\cdot;\xi)$. We can define its smoothed function $f_\alpha({ \mathbf{x}},\cdot;\xi)$ and has the properties above.

\begin{lemma}
\label{lemma6}
    If assumption \ref{assumption1} holds, for $f_\alpha$ defined in Lemma \ref{lemma5}, $\nabla_{ \mathbf{x}} f_\alpha({ \mathbf{x}},{ \mathbf{y}})$ is $\ell$-continuous on ${ \mathbf{y}}$, i.e.
    $$\|\nabla_{ \mathbf{x}} f_\alpha({ \mathbf{x}},{ \mathbf{y}}_1)-\nabla_{ \mathbf{x}} f_\alpha({ \mathbf{x}},{ \mathbf{y}}_2)\|\leq \ell \|{ \mathbf{y}}_1-{ \mathbf{y}}_2\|,$$
    for any ${ \mathbf{x}}\in\mathbb{R}^d,{ \mathbf{y}}_1,{ \mathbf{y}}_2\in\mathbb{R}^{d'}$.
\end{lemma}

\begin{proof}
    \begin{align*}
        & \|\nabla_{ \mathbf{x}} f_\alpha({ \mathbf{x}},{ \mathbf{y}}_1)-\nabla_{ \mathbf{x}} f_\alpha({ \mathbf{x}},{ \mathbf{y}}_2)\| \\
        = & \|\mathbb{E}_{ \mathbf{v}} [ f({ \mathbf{x}}+\alpha { \mathbf{v}},{ \mathbf{y}}_1) ]-\mathbb{E}_{ \mathbf{v}} [ f({ \mathbf{x}}+\alpha { \mathbf{v}},{ \mathbf{y}}_2) ]\| \\
        \leq & \mathbb{E}_{ \mathbf{v}}\|f({ \mathbf{x}}+\alpha { \mathbf{v}},{ \mathbf{y}}_1)-f({ \mathbf{x}}+\alpha { \mathbf{v}},{ \mathbf{y}}_2)\| \\
        \leq & \ell\|{ \mathbf{y}}_1-{ \mathbf{y}}_2\|.
    \end{align*}
    Here the first inequality is from the convexity of norm and the second inequality is from the $\ell$-smoothness of $f$.
\end{proof}

We first give the iteration complexity of the inner loop of Algorithm \ref{bi_minimax_ZOFO}. Using the simplified notations we can write the update step in the inner loop as ${ \mathbf{y}}^k_{t+1}={ \mathbf{y}}^k_t+\eta \nabla_{ \mathbf{y}} f({ \mathbf{x}}^k,{ \mathbf{y}}^k_t;\xi_t).$ We use $B_1, B_2$ to denote the batch size for the inner loop and outer loop, respectively. But finally we will prove that they are in fact of the same order.

\begin{lemma}
\label{lemma7}
    In Algorithm \ref{bi_minimax_ZOFO}, by setting $\eta=1/2\ell$, $T=O(\kappa\log(\frac{1}{\epsilon}))$ and $B_1=O(\epsilon^{-2})$ we have $$\mathbb{E}[\|{ \mathbf{y}}^k_{T}-{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2]\leq \epsilon^2$$ in outer loop $k$.
\end{lemma}

\begin{proof}
    \begin{align*}
        & \|{ \mathbf{y}}^k_{t+1}-{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2 \\
        = & \|{ \mathbf{y}}^k_t+\eta \nabla_{ \mathbf{y}} f({ \mathbf{x}}^k,{ \mathbf{y}}^k_t;\xi_t) - { \mathbf{y}}^*({ \mathbf{x}}^k)\|^2 \\
        = & \|{ \mathbf{y}}^k_t-{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2+2\eta\langle \nabla_{ \mathbf{y}} f({ \mathbf{x}}^k,{ \mathbf{y}}^k_t;\xi_t), { \mathbf{y}}^k_t-{ \mathbf{y}}^*({ \mathbf{x}}^k)\rangle +\eta^2 \|\nabla_{ \mathbf{y}} f({ \mathbf{x}}^k,{ \mathbf{y}}^k_t;\xi_t)\|^2.
    \end{align*}

    Now taking expectations on both sides we have
    \begin{align*}
        & \mathbb{E}[\|{ \mathbf{y}}^k_{t+1}-{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2] \\
        \leq & \mathbb{E}[\|{ \mathbf{y}}^k_t-{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2]+2\eta\mathbb{E}[\langle \nabla_{ \mathbf{y}} f({ \mathbf{x}}^k,{ \mathbf{y}}^k_t), { \mathbf{y}}^k_t-{ \mathbf{y}}^*({ \mathbf{x}}^k)\rangle] +\eta^2 (\mathbb{E}[\|\nabla_{ \mathbf{y}} f({ \mathbf{x}}^k,{ \mathbf{y}}^k_t)\|^2]+\frac{\sigma^2}{B_1}) \\
        \leq & \mathbb{E}[\|{ \mathbf{y}}^k_t-{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2] - 2\eta \mathbb{E}[f({ \mathbf{x}}^k,{ \mathbf{y}}^*({ \mathbf{x}}^k))-f({ \mathbf{x}}^k,{ \mathbf{y}}^k_t)]+2\ell \eta^2\mathbb{E}[f({ \mathbf{x}}^k,{ \mathbf{y}}^*({ \mathbf{x}}^k))-f({ \mathbf{x}}^k,{ \mathbf{y}}^k_t)]+\frac{\eta^2\sigma^2}{B_1} \\
        = & \mathbb{E}[\|{ \mathbf{y}}^k_t-{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2] - \frac{1}{2\ell} \mathbb{E}[f({ \mathbf{x}}^k,{ \mathbf{y}}^*({ \mathbf{x}}^k))-f({ \mathbf{x}}^k,{ \mathbf{y}}^k_t)]+\frac{\sigma^2}{4\ell^2B_1} \\
        \leq & \mathbb{E}[\|{ \mathbf{y}}^k_t-{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2] - \frac{\tau}{4\ell}\mathbb{E}[\|{ \mathbf{y}}^k_t-{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2] +\frac{\sigma^2}{4\ell^2B_1}.
    \end{align*}

    The first inequality is from Assumption \ref{assumption1}, second and last inequalities from Lemma \ref{lemma2} and the equation is from the value of $\eta$.

    In order for $\mathbb{E}[\|{ \mathbf{y}}^k_{T}-{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2]\leq \epsilon^2$ we need $T=O(\kappa\log(\frac{1}{\epsilon}))$ and $B_1=O(\epsilon^{-2}).$
\end{proof}

The following lemma is from Theorem 1 in \cite{MalladiGNDL0A23Mezo}.

\begin{lemma}
\label{lemma9}
If Assumption \ref{assumption2} holds, there exists a constant $\gamma={ \bm{\theta}}(r)$ such that 
$$\mathbb{E}[\hat{\nabla}_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1};\xi)^T H({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\hat{\nabla}_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1};\xi)]\leq \ell\gamma \mathbb{E}[\|\nabla_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1};\xi)\|^2].$$
\end{lemma}

Finally, we give the proof for Theorem \ref{theorem1}. In this part we assume both ${ \bm{\theta}}$ and ${ \mathbf{p}}$ updates with zeroth order gradient for the convenience of analysis and this does not change the order of the total complexity.

\begin{proof} (\textbf{proof of Theorem \ref{theorem1}}) 

    From Assumption \ref{assumption2}, taking expectation conditioning on ${ \mathbf{x}}^k$ and ${ \mathbf{y}}^{k+1}$ we have
    \begin{align*}
        \mathbb{E}[g({ \mathbf{x}}^{k+1})] \leq & g({ \mathbf{x}}^k)-\zeta\langle \nabla_{ \mathbf{x}} g({ \mathbf{x}}^k),\mathbb{E}[\hat{\nabla}_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1};\xi)]\rangle\\
        &  + \frac{\zeta^2}{2} \mathbb{E}[\hat{\nabla}_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1};\xi)^T H({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\hat{\nabla}_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1};\xi)] \\
        \leq & g({ \mathbf{x}}^k)-\zeta\langle \nabla_{ \mathbf{x}} g({ \mathbf{x}}^k),\nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\rangle + \frac{\zeta^2}{2}\ell\gamma \mathbb{E}[\|\nabla_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1};\xi)\|^2] 
    \end{align*}

    Let us bound the inner product term:
    \begin{align*}
        & -\zeta\langle \nabla_{ \mathbf{x}} g({ \mathbf{x}}^k),\nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\rangle \\
        \leq & -\zeta\langle \nabla_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^*({ \mathbf{x}}^k))- \nabla_{ \mathbf{x}} f_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^*({ \mathbf{x}}^k))+\nabla_{ \mathbf{x}} f_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^*({ \mathbf{x}}^k)) \\
        & -\nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})+\nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1}), \nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\rangle \\
        \leq & \frac{1}{\ell\gamma}\|\nabla_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^*({ \mathbf{x}}^k))- \nabla_{ \mathbf{x}} f_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^*({ \mathbf{x}}^k))\|^2+\frac{\zeta^2\ell\gamma}{4}\|\nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2 \\
        & + \frac{1}{\ell\gamma}\|\nabla_{ \mathbf{x}} f_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^*({ \mathbf{x}}^k))- \nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2+\frac{\zeta^2\ell\gamma}{4}\|\nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2 \\
        & -\zeta\langle \nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1}), \nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\rangle \\
        \leq & \frac{\alpha^2 \ell^2 d^3}{4\ell\gamma}+\frac{\ell^2}{\ell\gamma}\|{ \mathbf{y}}^*({ \mathbf{x}}^k)-{ \mathbf{y}}^{k+1}\|^2+\frac{\zeta^2\ell\gamma}{2}\|\nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2 \\
        & -\zeta\langle \nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1}), \nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\rangle.
    \end{align*}
    Here the last inequality is from Lemma \ref{lemma5} and Lemma \ref{lemma6}.

    Now back to the original inequality, taking expectations over all the randomness in the algorithm we have 
    \begin{align*}
        & \zeta(1-\frac{\zeta\ell\gamma}{2})\mathbb{E}[\|\nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2] \\
        \leq & \mathbb{E}[g({ \mathbf{x}}^{k})-g({ \mathbf{x}}^{k+1})] + \frac{\ell}{\gamma}\mathbb{E}[\|{ \mathbf{y}}^*({ \mathbf{x}}^k)-{ \mathbf{y}}^{k+1}\|^2] + \frac{\zeta^2\ell\gamma}{2}\mathbb{E}[\|\nabla_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1};\xi)\|^2]+\frac{\alpha^2 \ell d^3}{4\gamma} \\
        \leq & \mathbb{E}[g({ \mathbf{x}}^{k})-g({ \mathbf{x}}^{k+1})] + \frac{\ell}{\gamma}\mathbb{E}[\|{ \mathbf{y}}^*({ \mathbf{x}}^k)-{ \mathbf{y}}^{k+1}\|^2] + \frac{\zeta^2\ell\gamma}{2}\mathbb{E}[\|\nabla_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2]+\frac{\zeta^2\ell\gamma\sigma^2}{2B_2}+\frac{\alpha^2 \ell d^3}{4\gamma},
    \end{align*}
    where the last inequality is from Assumption \ref{assumption1}.

    On the other hand, from Lemma \ref{lemma5}, by letting $\zeta=\frac{1}{2\ell\gamma}$ we have
    \begin{align*}
        & \mathbb{E}[\|\nabla_xf({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2] \\
        \leq & 2\mathbb{E}[\|\nabla_xf_\alpha({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2]+\frac{\alpha^2\ell^2(d+d')^3}{2} \\
        \leq & \frac{16}{3}\ell\gamma\mathbb{E}[g({ \mathbf{x}}^{k})-g({ \mathbf{x}}^{k+1})]+\frac{16}{3}\ell^2\mathbb{E}[\|{ \mathbf{y}}^*({ \mathbf{x}}^k)-{ \mathbf{y}}^{k+1}\|^2]\\
        & +\frac{2}{3}\mathbb{E}[\|\nabla_{ \mathbf{x}} f({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2]+\frac{2\sigma^2}{3B_2}+\frac{11}{6}\alpha^2\ell^2(d+d')^3 \\
        \Rightarrow & \mathbb{E}[\|\nabla_xf({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2] \leq 16\ell\gamma\mathbb{E}[g({ \mathbf{x}}^{k})-g({ \mathbf{x}}^{k+1})]+16\ell^2\mathbb{E}[\|{ \mathbf{y}}^*({ \mathbf{x}}^k)-{ \mathbf{y}}^{k+1}\|^2]\\
        & +\frac{2\sigma^2}{B_2}+\frac{11}{2}\alpha^2\ell^2(d+d')^3.
    \end{align*}


    Taking summation of $k$ from $1$ to $K$ we have
    \begin{align*}
        & \frac{1}{K}\sum_{k=1}^{K+1}\mathbb{E}[\|\nabla_xf({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2] \\
        \leq & \frac{16\ell\gamma}{K}\mathbb{E}[g({ \mathbf{x}}^{1})-g({ \mathbf{x}}^{K+1})]+\frac{16\ell^2}{K}\sum_{k=1}^K\mathbb{E}[\|{ \mathbf{y}}^*({ \mathbf{x}}^k)-{ \mathbf{y}}^{k+1}\|^2]+\frac{2\sigma^2}{B_2}+\frac{11}{2}\alpha^2\ell^2(d+d')^3 \\
        \leq & \frac{16\ell\gamma}{K}\mathbb{E}[g({ \mathbf{x}}^{1})-\min_{ \mathbf{x}} g({ \mathbf{x}})]+\frac{16\ell^2}{K}\sum_{k=1}^K\mathbb{E}[\|{ \mathbf{y}}^*({ \mathbf{x}}^k)-{ \mathbf{y}}^{k+1}\|^2]+\frac{2\sigma^2}{B_2}+\frac{11}{2}\alpha^2\ell^2(d+d')^3.
    \end{align*}

    Thus, by setting parameters as in Theorem \ref{theorem1} we have $\min_k\mathbb{E}[\|\nabla_xf({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2]\leq \epsilon^2.$

    On the other hand, since
    $$\mathbb{E}[\|\nabla_xf({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2]=\mathbb{E}[\|\nabla_xf({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})-\nabla_{ \mathbf{y}} f({ \mathbf{x}}^k,{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2]\leq\ell^2\mathbb{E}[\|{ \mathbf{y}}^{k+1}-{ \mathbf{y}}^*({ \mathbf{x}}^k)\|^2],$$
    similar to Lemma \ref{lemma7} we have $\mathbb{E}[\|\nabla_xf({ \mathbf{x}}^k,{ \mathbf{y}}^{k+1})\|^2]\leq \epsilon^2$ by setting $T=O(\kappa\log(\frac{\kappa}{\epsilon}))$ and $B_1=O(\epsilon^{-2}).$
\end{proof}


\section{Experimental Setup}\label{app:experiment}
{To recall the proposed Algorithm \ref{bi_minimax_ZOFO}, we present a pipeline of the proposed Algorithm \ref{bi_minimax_ZOFO} in figure \ref{fig:pipeline}.}


\subsection{Single-Task experiments}\label{app:single-task-exp}
Following MeZO~\citep{MalladiGNDL0A23Mezo}, we evaluate our approach on a range of classification and multiple-choice tasks. In this setting, training and testing are conducted on the same task.

\subsubsection{Tasks}
We use the following tasks for evaluating the fine-tuning capabilities of Bilevel-ZOFO in a single-task setting.
\paragraph{BoolQ~\citep{clark2019boolq}:} A yes/no question-answering task where each question is paired with a paragraph that contains the answer.

\paragraph{CB~\citep{wang2019superglue-cb}:} The CommitmentBank task involves determining whether a given sentence in context entails, contradicts, or is neutral to a premise.

\paragraph{COPA~\citep{roemmele2011copa}:} The Choice of Plausible Alternatives (COPA) task requires selecting the most plausible cause or effect from two alternatives for a given premise.

\paragraph{ReCoRD:~\citep{zhang2018record}} The Reading Comprehension with Commonsense Reasoning Dataset (ReCoRD) is a cloze-style task where models must predict masked-out entities in text based on the surrounding context.

\paragraph{RTE~\citep{wang2018gluesst2}:} The Recognizing Textual Entailment (RTE) task involves determining whether a given hypothesis is entailed by a provided premise.

\paragraph{SST2~\citep{wang2018gluesst2}:} The Stanford Sentiment Treebank (SST-2) task focuses on binary sentiment classification of sentences as positive or negative.

\paragraph{WiC~\citep{pilehvar2018wic}:} The Word-in-Context (WiC) task involves determining whether the same word is used in the same sense in two different sentences.

\paragraph{WinoGrande~\citep{sakaguchi2021winogrande}:} A commonsense reasoning task where the goal is to resolve pronoun references in ambiguous sentences by identifying the correct antecedent.

\paragraph{WSC~\citep{levesque2012wsc}:} The Winograd Schema Challenge (WSC) tests a model's ability to resolve pronoun references in sentences, requiring commonsense reasoning.

\paragraph{SQuAD~\citep{rajpurkar2016squad}:} The Stanford Question Answering Dataset (SQuAD) is a reading comprehension task where models must answer questions based on a given passage of text.

\subsubsection{PEFT Variants} 
We utilize three PEFT techniques—prompt-tuning~\citep{LesterAC21PromptTuning}, prefix-tuning~\citep{LiL20PrefixTuning}, and LoRA~\citep{HuSWALWWC22LORA}—for lower-level training to evaluate bilevel-ZOFO across various conditions and resource constraints.

\begin{enumerate} 
\item \textbf{LoRA:} For all single-task LoRA experiments, we set $r=8$ and $\alpha=16$. 
\item \textbf{Prefix Tuning:} We use 5 prefix tokens across all experiments. 
\item \textbf{Prompt Tuning:} We configure 10 soft prompt tokens for every experiment. \end{enumerate}

\subsubsection{Hyperparameter Search}\label{app:single-hyperparameters}
Given resource limitations, we focus on sweeping only the learning rate as the key hyperparameter. For MeZO and first-order PEFT experiments, we explore learning rates from the set $\{1e-2, 1e-3, 1e-4, 1e-5, 1e-6\}$. For Bilevel-ZOFO, we sweep both the upper-level and lower-level learning rates: $\text{lr}_{\text{upper}} \in \{1e-4, 1e-5, 1e-6\}$ and $\text{lr}_{\text{lower}} \in \{1e-2, 1e-3, 1e-4, 1e-5\}$. We perform all experiments in tables \ref{tab:single-task-opt} and \ref{tab:single-task-llama2-7b} using three random seeds and report the average and standard deviation.  We also set $\epsilon=1e-3$, following MeZO~\cite{MalladiGNDL0A23Mezo}.

\subsubsection{Training}\label{app:sigle-task-training}

All experiments used a batch size of 8 and were conducted in bfloat16 precision on a single A6000 Ada 48GB GPU. MeZO was run for 10,000 steps, while FO and Bilevel-ZOFO methods were run for 5,000 steps. Our implementation builds upon MeZO’s codebase, and memory profiling as well as latency calculations are based on their framework.

For each task, 1000 examples are randomly sampled for training, 500 for validation, and 1000 for testing. For bilevel-ZOFO, the training set is split into upper-level and lower-level subsets with a 1:2 ratio. During each lower-level update, only the PEFT parameters are optimized, while in the upper-level step, the entire model is fine-tuned using zeroth-order gradient approximation. We set $\lambda=10000$ and perform 20 lower-level updates between each upper-level update for all bilevel-ZOFO experiments.

All experiments use the Adam optimizer~\citep{AdamKingmaB14},including baselines and both lower-level and upper-level optimizers. No weight decay was applied, and the models were trained with a constant learning rate schedule. Batch size is set to $16$ for all experiments. We load all models in bfloat16. We find the best performing model based on validation loss and report test results from that checkpoint. We report the test accuracy or F1-score based on the test dataset being imbalanced or not.

We fix the memory budget of each step across bilevel-ZOFO and the baselines. We train zeroth-order methods for 10,000 steps, and bilevel-ZOFO and first-order methods for 5000 steps. We use A6000ada 48GPUs in our experiments. We load all models in bfloat16.

Figure~\ref{fig:low_source_increases} compares the number of parameters tuned by first-order PEFT methods that are used in our experiments.

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.65\linewidth]{figures/params-3.png}
    \caption{Number of additional parameters PEFT methods introduced to each model.}
    \label{fig:low_source_increases}
\end{figure}



\subsection{Results}\label{app:appendix-results}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/loss_curve_copa_bilevel.png}
    \caption{Training loss for the lower-level objective of the bilevel framework with Lora as the PEFT model.}
    \label{fig:loss_curve}
\end{figure}

{ Figure \ref{fig:loss_curve} presents the training loss for the lower-level objective of the bilevel framework with Lora as the PEFT model. As shown, consistent with the guarantees provided by our theoretical analysis, Bilevel-ZOFO converges. }


Table~\ref{tab:single-task-opt} presents the test metrics when applying bilevel-ZOFO and baselines to fine-tune OPT-1.3B~\citep{OPT} on a downstream task. 

\begin{table}[ht!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{llcccccccccc} \toprule
Trainer & Mode & BoolQ & CB & Copa & ReCoRD & RTE & SST2 & WIC & WinoGrande & WSC & Average \\ \midrule
\multirow{5}{*}{MeZO} 
& ft & $0.6927 \pm 0.0660$ & $0.7767 \pm 0.1162$ & $0.7000 \pm 0.0289$ & $0.6980 \pm 0.0053$ & $0.6587 \pm 0.0271$ & $0.8214 \pm 0.0042$ & $0.5543 \pm 0.0146$ & $0.5480 \pm 0.0108$ & $0.5054 \pm 0.0056$ & $0.6617 \pm 0.0321$ \\ 
& lora & $0.6860 \pm 0.0012$ & $0.7607 \pm 0.0515$ & $0.7200 \pm 0.0058$ & $0.7083 \pm 0.0049$ & $0.6755 \pm 0.0110$ & $0.8501 \pm 0.0067$ & $0.5549 \pm 0.0057$ & $0.5607 \pm 0.0050$ & $0.5570 \pm 0.0000$ & $0.6748 \pm 0.0102$ \\ 
& prefix & $0.6573 \pm 0.0379$ & $0.7945 \pm 0.0309$ & $0.7033 \pm 0.0208$ & $0.7047 \pm 0.0010$ & $0.6972 \pm 0.0055$ & $0.8218 \pm 0.0127$ & $0.5622 \pm 0.0127$ & $0.5370 \pm 0.0137$ & $0.5105 \pm 0.1313$ & $0.6654 \pm 0.0285$ \\ 
& prompt & $0.6260 \pm 0.0056$ & $0.5821 \pm 0.0179$ & $0.7067 \pm 0.0058$ & $0.7070 \pm 0.0053$ & $0.5415 \pm 0.0063$ & $0.7463 \pm 0.0218$ & $0.5574 \pm 0.0048$ & $0.5556 \pm 0.0038$ & $0.4654 \pm 0.0618$ & $0.6098 \pm 0.0159$ \\ \cmidrule{2-12} 
& average & $0.6655$ & $0.7285$ & $0.7075$ & $0.7045$ & $0.6432$ & $0.8099$ & $0.5572$ & $0.5503$ & $0.5096$ & $0.6529 \pm 0.0217$ \\ \midrule
\multirow{4}{*}{FO} 
& lora & $0.7403 \pm 0.0055$ & $0.8512 \pm 0.0412$ & $0.7500 \pm 0.0058$ & $0.7206 \pm 0.0035$ & $0.7292 \pm 0.0165$ & $0.9258 \pm 0.0032$ & $0.6463 \pm 0.0276$ & $0.5806 \pm 0.0055$ & $0.6474 \pm 0.0200$ & $0.7324 \pm 0.0143$ \\ 
& prefix & $0.7300 \pm 0.0035$ & $0.8571 \pm 0.0644$ & $0.7167 \pm 0.0115$ & $0.7093 \pm 0.0032$ & $0.7136 \pm 0.0110$ & $0.8133 \pm 0.0050$ & $0.5387 \pm 0.0050$ & $0.5980 \pm 0.0029$ & $0.5705 \pm 0.0294$ & $0.6941 \pm 0.0141$ \\ 
& prompt & $0.7150 \pm 0.0156$ & $0.7142 \pm 0.0714$ & $0.7466 \pm 0.0115$ & $0.7163 \pm 0.0063$ & $0.6936 \pm 0.0185$ & $0.8016 \pm 0.0779$ & $0.5386 \pm 0.0197$ & $0.5980 \pm 0.0090$ & $0.5062 \pm 0.0434$ & $0.6700 \pm 0.0306$ \\ \cmidrule{2-12} 
& average & $0.7284$ & $0.8075$ & $0.7378$ & $0.7154$ & $0.7121$ & $0.8470$ & $0.5745$ & $0.5922$ & $0.5747$ & $0.6982 \pm 0.0197$ \\ \midrule
\multirow{4}{*}{Ours} 
& lora & $0.7433 \pm 0.0191$ & $0.9167 \pm 0.0103$ & $0.7400 \pm 0.0200$ & $0.7183 \pm 0.0031$ & $0.7401 \pm 0.0108$ & $0.9331 \pm 0.0020$ & $0.6447 \pm 0.0218$ & $0.5903 \pm 0.0058$ & $0.6428 \pm 0.0855$ & $0.7410 \pm 0.0209$ \\ 
& prefix & $0.7340 \pm 0.0095$ & $0.8690 \pm 0.0206$ & $0.7267 \pm 0.0153$ & $0.7140 \pm 0.0044$ & $0.7304 \pm 0.0091$ & $0.8550 \pm 0.0178$ & $0.6317 \pm 0.0282$ & $0.5710 \pm 0.0130$ & $0.5810 \pm 0.0338$ & $0.7125 \pm 0.0179$ \\ 
& prompt & $0.7367 \pm 0.0850$ & $0.7679 \pm 0.0644$ & $0.7633 \pm 0.0058$ & $0.7257 \pm 0.0153$ & $0.6867 \pm 0.0208$ & $0.8335 \pm 0.0779$ & $0.6267 \pm 0.0462$ & $0.5900 \pm 0.0173$ & $0.5133 \pm 0.1493$ & $0.6938 \pm 0.0536$ \\ \cmidrule{2-12} 
& average & $0.7380$ & $0.8512$ & $0.7433$ & $0.7193$ & $0.7191$ & $0.8739$ & $0.6344$ & $0.5838$ & $0.5790$ & $0.7158 \pm 0.0308$ \\ \midrule
\bottomrule
\end{tabular}
}
\caption{Single-Task Experiments on OPT-1.3B with 1000 samples. Values correspond to mean across three random seeds. FO: First-Order. FT: full-model fine-tuning.}
\label{tab:single-task-opt}
\end{table}


Table~\ref{tab:single-task-llama2-7b} demonstrates the results for fine-tuning Llama2-7b~\citep{Llama2} on various classification and open-ended generation tasks.

\begin{table}
\centering
\scalebox{0.8}{
\begin{tabular}{llllllll}
\toprule
Trainer & Mode & BoolQ & ReCoRD & SQuAD & SST2 & Average \\
\midrule
\multirow{4}{*}{MeZO} & ft & 0.7915 ± 0.0516 & 0.7890 ± 0.0001 & 0.7737 ± 0.1634 & 0.8646 ± 0.0216 & 0.8047 \\
& lora & 0.8020 ± 0.0014 & 0.7970 ± 0.0001 & 0.7412 ± 0.0013 & 0.8529 ± 0.0117 & 0.7983 \\
& prefix & 0.7830 ± 0.0131 & 0.7905 ± 0.0007 & 0.7093 ± 0.0207 & 0.8364 ± 0.0010 & 0.7798 \\
& prompt & 0.7787 ± 0.0049 & 0.7935 ± 0.0007 & 0.7014 ± 0.0451 & 0.8246 ± 0.0216 & 0.7746 \\ \midrule
\multirow{3}{*}{FO} & lora & 0.8420 ± 0.0104 & 0.7920 ± 0.0053 & 0.8197 ± 0.0043 & 0.9557 ± 0.0007 & 0.8524\\
& prefix & 0.7783 ± 0.0021 & 0.8013 ± 0.0012 & 0.7946 ± 0.0419 & 0.9243 ± 0.0053 & 0.8246 \\
& prompt & 0.8083 ± 0.0142 & 0.8023 ± 0.0074 & 0.7805 ± 0.0633 & 0.9284 ± 0.0072 & 0.8299 \\ \midrule
\multirow{3}{*}{Ours} & lora & 0.8473 ± 0.0025 & 0.8290 ± 0.0044 & 0.8160 ± 0.0041 & 0.9629 ± 0.0053 & \cellcolor[HTML]{C0C0C0} 0.8638  \\
& prefix & 0.8193 ± 0.0127 & 0.8067 ± 0.0065 & 0.8090 ± 0.0302 & 0.9382 ± 0.0064 & \cellcolor[HTML]{C0C0C0} 0.8433 \\
& prompt & 0.8145 ± 0.0012 & 0.8108 ± 0.0065 & 0.7960 ± 0.0028 & 0.9222 ± 0.0039 & \cellcolor[HTML]{C0C0C0}0.8359 \\ 
\bottomrule
\end{tabular}
}
\caption{Single-Task Experiments on Llama2-7B with 1000 samples. Values correspond to mean and std across three random seeds. FO: First-Order. FT: full-model fine-tuning}
\label{tab:single-task-llama2-7b}
\end{table}

\subsection{ Memory Profiling and Wall Clock Time Analysis}\label{sec:mem-profiling}
{
Figure \ref{fig:memory-profiling} demonstrates the memory profiling of Bilevel-ZOFO, MeZO and First-order prefix tuning on four different tasks. Memory consumption of MeZO and first-order PEFT methods varies across tasks, with one occasionally surpassing the other. Each lower-level update in our method matches that of the corresponding PEFT method. Similarly, each upper-level update requires the greater memory usage between MeZO and PEFT under comparable settings. As a result, the total memory requirement of our method corresponds to the maximum memory usage of the PEFT and MeZO experiments. Nonetheless, as demonstrated in Table \ref{tab:single-task-opt}, our method outperforms both PEFT and MeZO on average. 

We also present a wall-clock time analysis of bilevel-ZOFO compared to the baseline. As shown in Table \ref{tab:wall_clock_time}, similar to MeZO~\cite{MalladiGNDL0A23Mezo}, we observe that zeroth-order steps exhibit higher latency compared to first-order steps. The results indicate that our bilevel-ZOFO achieves comparable delays to the FO-PEFT method while significantly reducing step duration compared to MeZO. Moreover, as highlighted in Table \ref{tab:single-task-opt-main}, bilevel-ZOFO outperforms both methods on average.
}

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figures/memory-consumption.png}
    \caption{Memory consumption of MeZO and first-order PEFT methods varies across tasks, with one occasionally surpassing the other. Our Bilevel-ZOFO method demonstrates comparable memory usage to both baselines. Values correspond to memory usage for fine-tuning OPT1.3b~\cite{OPT} on each task using a batch size of 8 and on a singel A6000ada 48GB GPU.}
    \label{fig:memory-profiling}
\end{figure}

\begin{table}
    \centering
    \caption{Wallclock time per step of different training methods when finetuning OPT1.3b. The values are measured on a single A6000ada 48GB GPU. The wallclock time is averaged over 3 different runs that produced the values of Table \ref{tab:single-task-opt-main}. We use a batch size of 8 for all experiments.}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Task} & \textbf{MeZO} & \textbf{FO Prefix-Tuning} & \textbf{Bilevel-ZOFO (Prefix)} \\
        \midrule
        Copa & 0.299 & 0.127 & 0.135 \\
        MultiRC & 0.622 & 0.474 & 0.502 \\
        WSC & 0.278 & 0.120 & 0.164 \\
        \bottomrule
    \end{tabular}
    \label{tab:wall_clock_time}
\end{table}


\subsection{Sensitivity Analysis}\label{sec:sensitivity-analysis}
In this section, we provide experimental results that prove Bilevel-ZOFO mitigates the sensitivity of MeZO to hard prompts. First, similar to Table 5 of the MeZO~\cite{MalladiGNDL0A23Mezo} paper, we experiment with different choices of hard prompts for both MeZO and our Bilevel-ZOFO. Table~\ref{tab:prompt_sensitivity_comparison-app} shows the results for tuning Opt 1.3b on SST2 and COPA. We can see that our method effectively mitigates the sensitivity of MeZO to hard prompts. The difference between the results with and without a simple hard prompt in our experiment is much less than MeZO's


\begin{table}
\centering
\begin{tabular}{llccc}
\hline
\textbf{Method}         & \textbf{Experiment} & \textbf{With Prompt (\%)} & \textbf{Without Prompt (\%)} & \textbf{Difference} \\ \hline
\multirow{2}{*}{MeZO}   & SST-2               & 89.6                      & 51.9                        & -38.6               \\ 
                        & COPA                & 70.0                      & 54.8                        & -15.2               \\ \hline
\multirow{2}{*}{Bilevel-ZOFO} & SST-2         & 93.3                      & 92.9                        & \textbf{-0.4}                \\ 
                        & COPA                & 76.66                     & 73.6                        & \textbf{-3.06}               \\ \hline
\end{tabular}
\caption{Prompt Sensitivity Comparison for MeZO and Bilevel-ZOFO. Bilevel-ZOFO effectively mitigates the sensitivity of MeZO to hard prompts.}
\label{tab:prompt_sensitivity_comparison-app}
\end{table}

To also validate that the improved results are not because of tuning more parameters, we conducted an experiment on COPA using OPT1.3B  and compared Bilevel-ZOFO to a two-stage pipeline that tunes the same number of parameters. First, we performed first-order prompt tuning for a fixed number of steps (same as the number of lower-level updates in bilevel-ZOFO), followed by additional tuning using ZO for the same number of iterations as the upper level updates in bilevel-ZOFO (\textbf{A two-stage pipeline}). As shown in Table~\ref{tab:two-stage-comparison}, even with extensive hyperparameter tuning, the second stage does not improve the results achieved after the first stage and is highly likely to decrease performance. Our method, however, improves performance when using the same number of steps in the upper and lower levels, respectively. The bilevel structure makes the trained prompts dynamically optimal for the full ZO fine-tuning and reaches an accuracy of 76.66.

The observed performance drop after the second stage is indeed counter-intuitive at first glance. However, it is a limitation of MeZO as it approximates gradients. While further fine-tuning intuitively should improve performance, the inherent noise in gradient approximation can lead to suboptimal updates. This observation is consistent with the fact that MeZO typically requires a significant number of iterations to converge. This is a key contribution of our work: Our approach addresses MeZO's challenges, such as sensitivity to hard prompts and long convergence times, while outperforming both MeZO and PEFT and maintaining similar memory efficiency. The intuition behind why our method is effective in enhancing both MeZO's full-model tuning and PEFT is in the nested bilevel structure. This structure encodes more information (as reflected in the training method) from the prompt tuning stage than only treating it as a first stage, thereby providing better guidance for MeZO. In contrast, our bilevel method effectively addresses the issues of MeZO and demonstrates improved performance over both MeZO and the PEFT baseline, even with the same number of ZO iterations.
See ~\cite{shirkavand2024efficient} for a more detailed analysis of why a bilevel-method is better than a two-staged pipeline.


\begin{table}
\centering
\begin{tabular}{llc}
\hline
\textbf{Method}         & \textbf{Experiment (COPA)} & \textbf{Accuracy (\%)} \\ \hline
\multirow{4}{*}{Two-Stage Pipeline}   & After Stage 1              & 74.33                                   \\ 
                        & After Stage 2 (lr $0.001$)               & 51.66                         \\ 
                        & After Stage 2 (lr $0.0001$)               & 70.33                          \\ 
                        & After Stage 2 (lr $0.00001$)               & 72.66                      \\ 
                        & After Stage 2 (lr $0.000001$)               & 74.33                         \\ \hline
Bilevel-ZOFO &   -      & \textbf{76.66}  \\ \hline
\end{tabular}
\caption{Comparison of Bilevel-ZOFO with a two-staged pipeline.}
\label{tab:two-stage-comparison}
\end{table}

The training loss curves for both stages of a two-stage approach and our bilevel framework are provided in Figure~\ref{fig:two-stage-loss-comparison}. When running MeZO in the second stage, the training loss exhibits oscillations and does not show improvement within 500–1000 iterations. This behavior is consistent with findings in the original MeZO~\cite{MalladiGNDL0A23Mezo} paper, which notes that MeZO typically requires much longer to converge—on the order of 100k iterations. The oscillatory behavior observed within the shorter training duration is not surprising due to gradient approximation errors.


\begin{figure}
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/first-stage.png} 
        \caption{First-Stage PEFT}
        \label{fig:first-stage}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth} 
        \centering
        \includegraphics[width=\linewidth]{figures/second-stage.png}
        \caption{Second-Stage MeZO}
        \label{fig:second-stage}
    \end{subfigure}
        \begin{subfigure}[b]{0.5\textwidth} 
        \centering
        \includegraphics[width=\linewidth]{figures/bilevel-stage.png}
        \caption{Bilevel}
        \label{fig:bilevel-stage}
    \end{subfigure}
    \caption{The training loss curves for both stages of a two-stage approach (a and b) and our bilevel framework (c).}
    \label{fig:two-stage-loss-comparison}
\end{figure}



\subsection{Multi-task experiments}\label{app:multi-task-exp}
In this section we explain the experimental details of mutil-task experiments.

\subsubsection{Meta-Tasks}
Following the methodology of \citet{MinLZH22MetaICL}, we evaluate the performance of bilevel-ZOFO as a fast and efficient meta-learning algorithm. We perform experiments using four of the distinct meta-learning settings outlined in MetaICL~\citep{MinLZH22MetaICL}: classification-to-classification, non-classification-to-classification, QA-to-QA, and non-QA-to-QA. Each of these \emph{meta-learning tasks} includes a set of training sub-tasks and a different set of test sub-tasks. The sub-tasks are sourced from CROSSFIT~\citep{YeLR21CrossfitFewShot} and UNIFIEDQA~\citep{KhashabiMKSTCH20}, comprising a total of 142 unique sub-tasks. These sub-tasks cover a variety of problems, including text classification, question answering, and natural language understanding, all in English.  Table \ref{tab:meta-learning-tasks} shows the number of tasks in each training and testing meta-learning setting and the total number of examples in each training task.

\begin{table}[ht]
\centering
\begin{tabular}{ccccc}
\hline
\textbf{Meta-train Setting} & \textbf{\# tasks} & \textbf{\# examples} & \textbf{Target Setting} & \textbf{\# tasks} \\ 
\hline
Classification & 43 & 384,022 & \multirow{2}{*}{Classification} & \multirow{2}{*}{20} \\\cmidrule{1-3}
Non-Classification & 37 & 368,768 &  &  \\
\hline
QA & 37 & 486,143 & \multirow{2}{*}{QA} & \multirow{2}{*}{22} \\\cmidrule{1-3}
Non-QA & 33 & 521,342 &  &  \\
\hline
\end{tabular}
\caption{Details of four different meta-learning settings. Each row indicates meta-training/target tasks for each setting. There is no overlap between the training and test tasks.}
\label{tab:meta-learning-tasks}
\end{table}

See Tables 14 and 15 of MetaICL~\citep{MinLZH22MetaICL} for a list of all sub-tasks. 

\subsubsection{Baselines}
We use GPT2-Large~\cite{radford2019gpt2} as the base model for these experiments.We compare our method against several baseline approaches:
\begin{itemize}
    \item \textbf{MetaICL}~\citep{MinLZH22MetaICL}: A method for meta-learning with in-context learning. MetaICL tunes all the parameters of the base model using the first-order method. In both training and testing, the model is given $k$ demonstration examples, ${(a_1,b_1), \dots, (a_k,b_k)}$, where $b_i$ represents either classification labels or possible answers in question-answering tasks, along with one test example $(a,b)$. The input is formed by concatenating the demonstration examples $a_1,b_1, \dots, a_k,b_k,a$. The model then computes the conditional probability of each label, and the label with the highest probability is selected as the prediction.
    \item \textbf{Zero-shot}: This method uses the pretrained language model (LM) without any tuning, performing zero-shot inference without any demonstration examples.
    \item \textbf{In-context Learning (ICL)}: This method uses the pretrained LM with in-context learning by conditioning on a concatenation of $k$ demonstration examples and 1 actual test sample similar to MetaICL.
\end{itemize}

We sample 768 examples from each training sub-task. We use these samples to train MetaICL in their original setting for 30,000 steps. This includes learning rate of $1e-5$, batch size of $1$ on $8$ GPUs, 8-bit Adam optimizer and fp16 half precision. See MetaICL\citep{MinLZH22MetaICL} for full details.  To train our method, we split the training dataset of each sub-task to two subsets, 256 samples as the development dataset for upper-level updates and 512 samples for lower-level training. For each outer iteration of our method, we randomly sample a subset of 5 training tasks. We perform 10 lower-level updates between each pair of upper-level updates. To keep bilevel-ZOFO as lightweight as possible, unlike MetaICL, we do not include demonstration examples in the inputs. Since bilevel-ZOFO uses significantly less memory and has much faster updates compared to MetaICL, theoretically we are able to train it for many more iterations within the same total training duration as MetaICL. However, due to resource constraints, we only train bilevel-ZOFO for 50,000 iterations. Similar to ~\cite{MalladiGNDL0A23Mezo}, we did not observe a plateau in performance for bilevel-ZOFO, indicating that further training can yield additional improvements. We use Adam optimizer and a learning rate of $1e-6$ for both upper and lower-level training. We employ a batch size of $4$ and train on a single rtx6000ada GPU.

For both ICL and MetaICL, during the testing phase the model is given $k=4$ demonstration examples for each test data point. We don't use demonstration examples in test samples for bilevel-ZOFO evaluation. We evaluate the zero-shot capabilities of our method as well as the performance of the final model LoRA-tuned for 10 additional iterations on $4$ demonstration samples from each class of each test sub-task. Similar to \cite{MinLZH22MetaICL}, we report \textbf{Macro-averaged F1} as the evaluation metric.
