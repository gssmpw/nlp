\begin{figure}[!t] 
    \centering
    \includegraphics[width=0.7\linewidth]{figures/Optimization_pipeline.pdf}
    \caption{Bilevel ZOFO optimizes LLM fine-tuning by solving a bilevel problem using a penalty-based minimax approach, combining zeroth-order gradient estimation for LLM updates and first-order methods for PEFT parameters.}
    \label{fig:pipeline}
\end{figure}

\section{Bilevel model and Zeroth-order-first-order method }
In this section, we present our bilevel model and the zeroth-order-first-order method for solving it. Let { $\mathbf{p}$} represent the parameters of the PEFT model, and { $\bm{\theta}$} represent the parameters of the pretrained base model. Given a single downstream task, such as classification, we aim to solve the following optimization problem:

\begin{equation}\label{single}
\min_{{ \bm{\theta}}\in \mathbb{R}^d} F({ \bm{\theta}}, { \mathbf{p}};\mathfrak{D}_f),
\end{equation}

where ${ \mathbf{p}}\in \mathbb{R}^{d'}$ and $F({ \bm{\theta}}, { \mathbf{p}};\mathcal{B}): = \frac{1}{|\mathcal{B}|} \sum_{x\in \mathcal{B}}F({ \bm{\theta}}, { \mathbf{p}};x)$ is a loss function given a dataset $\mathcal{B}$. 


When ${ \mathbf{p}}$ corresponds to the embeddings of the hard prompt (as shown in Table 13 in the appendix of \cite{MalladiGNDL0A23Mezo}), the model above reduces to classical fine-tuning on a single downstream task. In model \eqref{single}, the parameters of the PEFT model, ${ \mathbf{p}}$, are fixed.

To enhance generalization ability, we split the dataset into two parts: one for tuning the PEFT model (denoted as $\mathfrak{D}_{ \mathbf{p}}$) and another for fine-tuning the LLM (denoted as $\mathfrak{D}_f$). To maximize performance on downstream tasks, we need the optimal PEFT model parameters that are best suited for the current LLM base model. To achieve this, ${ \mathbf{p}}$ should satisfy the following condition:
 \[
{ \mathbf{p}(\bm{\theta})} \in \argmin_{{ \mathbf{p}}\in \mathbb{R}^{d'}} F({ \bm{\theta}}, { \mathbf{p}};\mathfrak{D}_{ \mathbf{p}}).
\]
This condition reveals that as the parameters $\theta$ of the LLM change, the parameters ${ \mathbf{p}}$ in the PEFT model should also be updated accordingly. Therefore, instead of solving \eqref{single}, our true objective becomes:
\begin{equation}\label{bi}
\begin{split}
\min_{{ \bm{\theta}}\in \mathbb{R}^d} &F({ \bm{\theta}}, { \mathbf{p}(\bm{\theta})};\mathfrak{D}_f)\\
{\rm { \mathbf{s}}.t.\ }& { \mathbf{p}(\bm{\theta})} \in \argmin_{{ \mathbf{s}}\in \mathbb{R}^{d'}} F({ \bm{\theta}}, { \mathbf{{ \mathbf{s}}}};\mathfrak{D}_{ \mathbf{p}}).
\end{split}
\end{equation}
In this way, we find the optimal pair of parameters for both the PEFT model and the LLM base model to achieve the best performance on downstream tasks.

To solve the bilevel optimization problem \eqref{bi}, classical bilevel methods (as discussed in related work) view \eqref{bi} as a single-level problem $\min_{ \bm{\theta}} F({ \bm{\theta}}, { \mathbf{p}(\bm{\theta})})$. Since ${ \mathbf{p}(\bm{\theta})}$ is the minimizer of another optimization problem, these methods typically require computing the Hessian-vector product (matrix multiplication of $\nabla_{{ \bm{\theta}} { \mathbf{p}}} F({ \bm{\theta}}, { \mathbf{p}})$ and some vector $v$) multiple times to estimate the gradient of $F({ \bm{\theta}}, { \mathbf{p}(\mathbf{{ \bm{\theta}}})})$ with respect to ${ \bm{\theta}}$. However, for large language models (LLMs), this approach is computationally prohibitive because the number of parameters in ${ \bm{\theta}}$ is too large.

To reduce the computational cost, following \citet{LuMei24}, we consider using a penalty method for the bilevel problem \eqref{bi}. Specifically, \eqref{bi} is equivalent to the following constrained optimization problem:
\begin{equation}\label{bi_constraint}
\begin{split}
\min_{\bm{\theta} \in \mathbb{R}^d , \bm{\mathbf{p}} \in \mathbb{R}^{d'}} &F({ \bm{\theta}}, { \mathbf{p}};\mathfrak{D}_f)\\
{\rm { \mathbf{s}}.t.\ }& F({ \bm{\theta}}, { \mathbf{p}};\mathfrak{D}_{ \mathbf{p}}) - \inf_{ \mathbf{{ \mathbf{s}}}}F({ \bm{\theta}}, { \mathbf{{ \mathbf{s}}}};\mathfrak{D}_{ \mathbf{p}})\le 0.
\end{split}
\end{equation}
By penalizing the constraint, we obtain the following penalized problem:

\begin{equation}\label{bi_penalized}
  \min_{\substack{\bm{\theta} \in \mathbb{R}^d \\ \bm{\mathbf{p}} \in \mathbb{R}^{d'}}} \!\! F({ \bm{\theta}}, { \mathbf{p}(\bm{\theta})};\mathfrak{D}_f) + \lambda(F({ \bm{\theta}}, { \mathbf{p}};\mathfrak{D}_{ \mathbf{p}}) - \!\!
  \inf_{{ \mathbf{s}}\in\mathbb{R}^{d'}} F({ \bm{\theta}}, { \mathbf{{ \mathbf{s}}}};\mathfrak{D}_{ \mathbf{p}})),
\end{equation}

where $\lambda>0$. As $\lambda$ increases, the solution to the penalized problem approaches the solution to \eqref{bi_constraint}, and thus the solution to \eqref{bi} (see Lemma \ref{lemma1} for an explicit relationship between the stationary points of \eqref{bi_penalized} and those of the original problem \eqref{bi}).
 Note that the penalized problem \eqref{bi_penalized} is equivalent to the following minimax problem:
\begin{multline}
\label{equation5}
\min_{{ \bm{\theta}}\in \mathbb{R}^d,{ \mathbf{p}}\in\mathbb{R}^{d'}} 
\max_{{ \mathbf{s}}\in\mathbb{R}^{d'}} 
G_\lambda({ \bm{\theta}},{ \mathbf{p}},{ \mathbf{s}}):= \\
F({ \bm{\theta}}, { \mathbf{p}(\bm{\theta})};\mathfrak{D}_f)
+ \lambda \big( F({ \bm{\theta}}, { \mathbf{p}};\mathfrak{D}_{ \mathbf{p}})
- F({ \bm{\theta}}, { \mathbf{s}};\mathfrak{D}_{ \mathbf{p}}) \big).
\end{multline}

In this way, we can solve the bilevel problem as a minimax problem. The basic minimax algorithm works as follows: at iteration $k$, we first solve the maximization problem $\max_{ \mathbf{{ \mathbf{s}}}}G_\lambda({ \bm{\theta}}^k, { \mathbf{p}}^k, { \mathbf{s}})$ with $({ \bm{\theta}}^k, { \mathbf{p}}^k)$ fixed. For example, we can update ${ \mathbf{s}}^k$ using an inner loop with stochastic gradient descent (SGD). Let ${ \mathbf{s}}^{k+1}$ be the result of this inner loop. Then, in the outer loop, we update $({ \bm{\theta}}^k, { \mathbf{p}}^k)$ by solving $\min_{{ \bm{\theta}}, { \mathbf{p}}} G_\lambda({ \bm{\theta}}, { \mathbf{p}}, { \mathbf{s}}^{k+1})$ with ${ \mathbf{s}}^{k+1}$ fixed. Again, SGD can be used to update ${ \bm{\theta}}^k$ and ${ \mathbf{p}}^k$. The conceptual algorithm is presented in Algorithm~\ref{minimax_algorithm}.

\begin{algorithm}[!ht]
\caption{ Bilevel first-order  method}\label{minimax_algorithm}
\begin{algorithmic}[1]
\STATE{Input: $\eta>0$, $\zeta>0$, ${ \mathbf{s}}^0={ \mathbf{s}}^{k}$, $K,T\in \mathbb{N}_+$, $\lambda\ge 0$. }
\FOR{k=0,\dots,K}
\FOR{$t=0,\dots,T-1$.}
\STATE{Let ${ \mathbf{s}}^k_{t+1}={ \mathbf{s}}^k_{t} - \eta \nabla_{ \mathbf{{ \mathbf{s}}}}G_{\lambda_k}({ \bm{\theta}}^k,{ \mathbf{p}}^k,{ \mathbf{s}}^k_t)$.}
\STATE{Output ${ \mathbf{s}}^{k+1}={ \mathbf{s}}^k_{T}$.}
\ENDFOR
\STATE{Let ${ \bm{\theta}}^{k+1}={ \bm{\theta}}^k - \zeta \nabla_{ \bm{\theta}} G_{\lambda_k}({ \bm{\theta}}^k,{ \mathbf{p}}^k,{ \mathbf{s}}^k)$ and ${ \mathbf{p}}^{k+1}= { \mathbf{p}}^k - \zeta \nabla_{ \mathbf{p}} G_{\lambda}({ \bm{\theta}}^k,{ \mathbf{p}}^k,{ \mathbf{s}}^k) .$}
\ENDFOR
\end{algorithmic}
\end{algorithm}

However, note that
\begin{multline}\label{grad}
  \nabla_{ \bm{\theta}} G_{\lambda_k}({ \bm{\theta}}^k,{ \mathbf{p}}^k,{ \mathbf{s}}^k) =  
  \nabla_{{ \bm{\theta}}} F({ \bm{\theta}}^k, { \mathbf{p}}^k;\mathfrak{D}_f) + \\
  \lambda_k(   \nabla_{{ \bm{\theta}}}F({ \bm{\theta}}, { \mathbf{p}}^k;\mathfrak{D}_{ \mathbf{p}}) + 
  \nabla_{{ \bm{\theta}}}F({ \bm{\theta}}^k, { \mathbf{s}}^k;\mathfrak{D}_{ \mathbf{p}})),
\end{multline}
requires calculating the gradient with respect to ${ \bm{\theta}}$, i.e, $\nabla_{{ \bm{\theta}}} F({ \bm{\theta}}^k, { \mathbf{p}}^k;\mathfrak{D}_f)$. Given the large scale of ${ \bm{\theta}}$ in LLMs, this is computationally expensive. To avoid this, we use zeroth-order (ZO) information to approximate the gradient $\nabla_{ \bm{\theta}} G$. Following \cite{MalladiGNDL0A23Mezo, ZhangLHLZZCLY0W24Zobench, GuoLZLY24}, we employ the Simultaneous Perturbation Stochastic Approximation (SPSA) as a classical zeroth-order gradient estimator. Specifically, at each iteration $k$, we sample ${ \mathbf{z}}^k \sim N(0, I_d)$, where $d$ is the dimension of ${ \bm{\theta}}$. We then approximate the gradient $\nabla_{\bm{\theta}}F$ as follows:
\begin{multline}\label{ZO_grad}
  \hat{\nabla}_{{ \bm{\theta}}} F({ \bm{\theta}}^k, { \mathbf{p}}^k;x) := \\
  \frac{F({ \bm{\theta}}^k + \epsilon { \mathbf{z}}^k, { \mathbf{p}}^k;x) - F({ \bm{\theta}}^k - \epsilon { \mathbf{z}}^k, { \mathbf{p}}^k;x)}{2\epsilon}{ \mathbf{z}}^k.
\end{multline}


As opposed to the number of LLM parameters ${ \bm{\theta}}$, the number of PEFT parameters ${ \mathbf{p}}$ is very small. So it is feasible to compute the exact gradient with respect to ${ \mathbf{p}}$. Thus, we calculate $\nabla_{ \mathbf{p}} F({ \bm{\theta}}, { \mathbf{p}}; \mathcal{B})$ exactly.

Additionally, in each iteration $k$ and inner iteration $t$ of Algorithm \ref{minimax_algorithm}, we sample a mini-batch $\mathcal{B}$ of size $B$. We use $\hat{\nabla}_{{ \bm{\theta}}} F({ \bm{\theta}}^k, { \mathbf{p}}^k;\mathcal{B}) $
to substitude $\nabla_{{ \bm{\theta}}} F({ \bm{\theta}}^k, { \mathbf{p}}^k;\mathcal{D}_f)$ and $\nabla_{{ \bm{\theta}}} F({ \bm{\theta}}^k, { \mathbf{p}}^k;\mathcal{D}_p)$in \eqref{grad}. We also use mini-batches when calculating the gradients with respect to the PEFT parameters ${ \mathbf{s}}$ and ${ \mathbf{p}}$. 

This approach leads to the final algorithm (Algorithm \ref{bi_minimax_ZOFO} and Figure \ref{fig:pipeline}) for fine-tuning LLMs using the bilevel model \eqref{bi}. We refer to this method as the Bilevel Zeroth-Order-First-Order (Bilevel ZOFO) method.

\begin{algorithm}[!ht]
\caption{Bilevel Zeroth-order-first-order Method (Bilevel ZOFO)}
\label{bi_minimax_ZOFO}
\begin{algorithmic}[1]
\STATE{Input: $\eta>0$, $\zeta>0$, batchsize $B$, ${ \mathbf{s}}^0={ \mathbf{s}}^{k}$, $K,T\in \mathbb{N}_+$, $\lambda>0$.} 
\FOR{k=0,\dots,K}
\FOR{t=0,\dots,T-1}
\STATE{Sample a batch $\mathcal{B}^k_{t,{ \mathbf{p}}}$ from $\mathfrak{D}_{ \mathbf{p}}$. }
\STATE{Let ${ \mathbf{s}}^k_{t+1}={ \mathbf{s}}^k_{t} - \eta \nabla_{ \mathbf{{ \mathbf{s}}}}F({ \bm{\theta}}^k, { \mathbf{s}}^k_t;\mathcal{B}^k_{t,{ \mathbf{p}}})$}
\STATE{Output ${ \mathbf{s}}^{k+1}={ \mathbf{s}}^k_{T}$.}
\ENDFOR
\STATE{Sample a batch $\{\mathcal{B}^k_f\}$ from $\mathfrak{D}_f$ and $\{\mathcal{B}^k_{ \mathbf{p}}\}$ from $\mathfrak{D}_{ \mathbf{p}}$. }
\STATE{For $x\in \mathcal{B}^k_{ \mathbf{p}}\cup \mathcal{B}^k_f$, calculate $\hat \nabla_{{ \bm{\theta}}} F({ \bm{\theta}}^k, { \mathbf{p}}^k;x)$ following \eqref{ZO_grad}. }
\STATE{Let

{\small
\begin{multline}\label{outer_update_ZO_p}
    { \mathbf{p}}^{k+1} = { \mathbf{p}}^k - \zeta (\nabla_{{ \mathbf{p}}} F({ \bm{\theta}}^k, { \mathbf{p}}^k;\mathcal{B}^k_f) + \\ 
    \lambda_k( \nabla_{{ \mathbf{p}}}F({ \bm{\theta}}^k, { \mathbf{p}}^k;\mathcal{B}^k_{ \mathbf{p}})))
\end{multline}

\begin{multline}\label{outer_update_ZO_theta}
    { \bm{\theta}}^{k+1} = { \bm{\theta}}^k - \zeta(\hat \nabla_{{ \bm{\theta}}} F({ \bm{\theta}}^k, { \mathbf{p}}^{k}; \mathcal{B}^k_f) + \\ 
    \lambda_k(\hat  \nabla_{{ \bm{\theta}}}F({ \bm{\theta}}^k, { \mathbf{p}}^{k};\mathcal{B}^k_{ \mathbf{p}}) -  \hat{\nabla}_{{ \bm{\theta}}}F({ \bm{\theta}}^k, { \mathbf{s}}^{k+1};\mathcal{B}^k_{ \mathbf{p}})))
\end{multline}
}}
\ENDFOR
\end{algorithmic}
\end{algorithm}


