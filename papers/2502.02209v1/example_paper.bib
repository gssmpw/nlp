@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@InProceedings{pmlr-v89-ali19a,
  title = 	 {A Continuous-Time View of Early Stopping for Least Squares Regression},
  author =       {Ali, Alnur and Kolter, J. Zico and Tibshirani, Ryan J.},
  booktitle = 	 {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1370--1378},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--18 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v89/ali19a/ali19a.pdf},
  url = 	 {https://proceedings.mlr.press/v89/ali19a.html},
}

@misc{https://doi.org/10.48550/arxiv.2206.05794,
  doi = {10.48550/ARXIV.2206.05794},
  
  url = {https://arxiv.org/abs/2206.05794},
  
  author = {Galanti, Tomer and Siegel, Zachary S. and Gupte, Aparna and Poggio, Tomaso},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@ARTICLE{726791,
  author={LeCun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  doi={10.1109/5.726791}}


@article{
doi:10.1073/pnas.1907369117,
author = {Tomaso Poggio  and Andrzej Banburski  and Qianli Liao },
title = {Theoretical issues in deep networks},
journal = {Proceedings of the National Academy of Sciences},
volume = {117},
number = {48},
pages = {30039-30045},
year = {2020},
doi = {10.1073/pnas.1907369117},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1907369117},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1907369117},
}

@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International conference on machine learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@article{daniely2019generalization,
  title={Generalization bounds for neural networks via approximate description length},
  author={Daniely, Amit and Granot, Elad},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@inproceedings{NEURIPS2022_42049206,
 author = {Graf, Florian and Zeng, Sebastian and Rieck, Bastian and Niethammer, Marc and Kwitt, Roland},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {10164--10178},
 publisher = {Curran Associates, Inc.},
 title = {On Measuring Excess Capacity in Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/420492060687ca7448398c4c3fa10366-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@book{ECCV2022,
    editor = {Shai Avidan and Gabriel Brostow and Moustapha Ciss√© and Giovanni Maria Farinella and Tal Hassner},
    title = {Computer Vision -- ECCV 2022},
    year = {2022},
    publisher = {Springer},
    doi = {10.1007/978-3-031-19769-7}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Attention is All you Need},
 volume = {30},
 year = {2017}
}


@inproceedings{chefer2021transformer,
  title={Transformer interpretability beyond attention visualization},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={782--791},
  year={2021}
}
@inproceedings{chefer2021generic,
  title={Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={397--406},
  year={2021}
}
@inproceedings{ali2022xai,
  title={XAI for transformers: Better explanations through conservative propagation},
  author={Ali, Ameen and Schnake, Thomas and Eberle, Oliver and Montavon, Gr{\'e}goire and M{\"u}ller, Klaus-Robert and Wolf, Lior},
  booktitle={International Conference on Machine Learning},
  pages={435--451},
  year={2022},
  organization={PMLR}
}

@InProceedings{shrikumar2016not,
  title = 	 {Learning Important Features Through Propagating Activation Differences},
  author =       {Avanti Shrikumar and Peyton Greenside and Anshul Kundaje},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {3145--3153},
  year = 	 {2017},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
}
@article{galanti2024norm,
  title={Norm-based Generalization Bounds for Sparse Neural Networks},
  author={Galanti, Tomer and Xu, Mengjia and Galanti, Liane and Poggio, Tomaso},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{chen2019generalization,
  title={On generalization bounds of a family of recurrent neural networks},
  author={Chen, Minshuo and Li, Xingguo and Zhao, Tuo},
  journal={arXiv preprint arXiv:1910.12947},
  year={2019}
}
@inproceedings{tu2019understanding,
  title={Understanding generalization in recurrent neural networks},
  author={Tu, Zhuozhuo and He, Fengxiang and Tao, Dacheng},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@article{liu2024generalization,
  title={From generalization analysis to optimization designs for state space models},
  author={Liu, Fusheng and Li, Qianxiao},
  journal={arXiv preprint arXiv:2405.02670},
  year={2024}
}
@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}
@inproceedings{nam2020relative,
  title={Relative attributing propagation: Interpreting the comparative contributions of individual units in deep neural networks},
  author={Nam, Woo-Jeoung and Gur, Shir and Choi, Jaesik and Wolf, Lior and Lee, Seong-Whan},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={03},
  pages={2501--2508},
  year={2020}
}
@article{bach2015pixel,
  title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
  author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
  journal={PloS one},
  volume={10},
  number={7},
  pages={e0130140},
  year={2015},
  publisher={Public Library of Science}
}
@inproceedings{guo2023improving,
  title={Improving robustness of vision transformers by reducing sensitivity to patch corruptions},
  author={Guo, Yong and Stutz, David and Schiele, Bernt},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4108--4118},
  year={2023}
}
@inproceedings{gur2021visualization,
  title={Visualization of supervised and self-supervised neural networks via attribution guided factorization},
  author={Gur, Shir and Ali, Ameen and Wolf, Lior},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={13},
  pages={11545--11554},
  year={2021}
}
@inproceedings{iwana2019explaining,
  title={Explaining convolutional neural networks using softmax gradient layer-wise relevance propagation},
  author={Iwana, Brian Kenji and Kuroki, Ryohei and Uchida, Seiichi},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)},
  pages={4176--4185},
  year={2019},
  organization={IEEE}
}
@inproceedings{gu2019understanding,
  title={Understanding individual decisions of cnns via contrastive backpropagation},
  author={Gu, Jindong and Yang, Yinchong and Tresp, Volker},
  booktitle={Computer Vision--ACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2--6, 2018, Revised Selected Papers, Part III 14},
  pages={119--134},
  year={2019},
  organization={Springer}
}
@inproceedings{shrikumar2017learning,
  title={Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  booktitle={International conference on machine learning},
  pages={3145--3153},
  year={2017},
  organization={PMLR}
}
@article{smilkov2017smoothgrad,
  title={Smoothgrad: removing noise by adding noise},
  author={Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:1706.03825},
  year={2017}
}
@inproceedings{trauger2024sequence,
  title={Sequence length independent norm-based generalization bounds for transformers},
  author={Trauger, Jacob and Tewari, Ambuj},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1405--1413},
  year={2024},
  organization={PMLR}
}
@article{srinivas2019full,
  title={Full-gradient representation for neural network visualization},
  author={Srinivas, Suraj and Fleuret, Fran{\c{c}}ois},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@inproceedings{ru2023token,
  title={Token contrast for weakly-supervised semantic segmentation},
  author={Ru, Lixiang and Zheng, Heliang and Zhan, Yibing and Du, Bo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3093--3102},
  year={2023}
}
@inproceedings{sundararajan2017axiomatic,
  title={Axiomatic attribution for deep networks},
  author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
  booktitle={International conference on machine learning},
  pages={3319--3328},
  year={2017},
  organization={PMLR}
}

@inproceedings{fong2017interpretable,
  title={Interpretable explanations of black boxes by meaningful perturbation},
  author={Fong, Ruth C and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3429--3437},
  year={2017}
}
@inproceedings{jain2019attention,
  title={Attention is not Explanation},
  author={Jain, Sarthak and Wallace, Byron C},
  booktitle={Proceedings of NAACL-HLT},
  pages={3543--3556},
  year={2019}
}

@inproceedings{abnar2020quantifying,
  title={Quantifying Attention Flow in Transformers},
  author={Abnar, Samira and Zuidema, Willem},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={4190--4197},
  year={2020}
}
@article{ali2023centered,
  title={Centered Self-Attention Layers},
  author={Ali, Ameen and Galanti, Tomer and Wolf, Lior},
  journal={arXiv preprint arXiv:2306.01610},
  year={2023}
}
@inproceedings{
guo2023contranorm,
title={ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond},
author={Xiaojun Guo and Yifei Wang and Tianqi Du and Yisen Wang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}
@inproceedings{chen-etal-2023-alleviating,
    title = "Alleviating Over-smoothing for Unsupervised Sentence Representation",
    author = "Chen, Nuo  and
      Shou, Linjun  and
      Pei, Jian  and
      Gong, Ming  and
      Cao, Bowen  and
      Chang, Jianhui  and
      Li, Jia  and
      Jiang, Daxin",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    pages = "3552--3566",
}
@inproceedings{chen2020measuring,
  title={Measuring and relieving the over-smoothing problem for graph neural networks from the topological view},
  author={Chen, Deli and Lin, Yankai and Li, Wei and Li, Peng and Zhou, Jie and Sun, Xu},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={3438--3445},
  year={2020}
}
@inproceedings{kulikov-etal-2022-characterizing,
    title = "Characterizing and addressing the issue of oversmoothing in neural autoregressive sequence modeling",
    author = "Kulikov, Ilia  and
      Eremeev, Maksim  and
      Cho, Kyunghyun",
    booktitle = "Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = nov,
    year = "2022",
    address = "Online only",
    publisher = "Association for Computational Linguistics",
    pages = "1115--1124",
}
@article{rusch2023survey,
  title={A survey on oversmoothing in graph neural networks},
  author={Rusch, T Konstantin and Bronstein, Michael M and Mishra, Siddhartha},
  journal={arXiv preprint arXiv:2303.10993},
  year={2023}
}
@article{wu2022non,
  title={A non-asymptotic analysis of oversmoothing in graph neural networks},
  author={Wu, Xinyi and Chen, Zhengdao and Wang, William and Jadbabaie, Ali},
  journal={arXiv preprint arXiv:2212.10701},
  year={2022}
}
@article{gong2021vision,
  title={Vision transformers with patch diversification},
  author={Gong, Chengyue and Wang, Dilin and Li, Meng and Chandra, Vikas and Liu, Qiang},
  journal={arXiv preprint arXiv:2104.12753},
  year={2021}
}
@article{wang2022anti,
  title={Anti-oversmoothing in deep vision transformers via the fourier domain analysis: From theory to practice},
  author={Wang, Peihao and Zheng, Wenqing and Chen, Tianlong and Wang, Zhangyang},
  journal={arXiv preprint arXiv:2203.05962},
  year={2022}
}
@article{xie2023residual,
  title={ResiDual: Transformer with Dual Residual Connections},
  author={Xie, Shufang and Zhang, Huishuai and Guo, Junliang and Tan, Xu and Bian, Jiang and Awadalla, Hany Hassan and Menezes, Arul and Qin, Tao and Yan, Rui},
  journal={arXiv preprint arXiv:2304.14802},
  year={2023}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{nguyen2024mitigating,
  title={Mitigating Over-smoothing in Transformers via Regularized Nonlocal Functionals},
  author={Nguyen, Tam and Nguyen, Tan and Baraniuk, Richard},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{dovonon2024setting,
  title={Setting the Record Straight on Transformer Oversmoothing},
  author={Dovonon, Gb{\`e}tondji JS and Bronstein, Michael M and Kusner, Matt J},
  journal={arXiv preprint arXiv:2401.04301},
  year={2024}
}
@inproceedings{arras-etal-2017-explaining,
    title = "Explaining Recurrent Neural Network Predictions in Sentiment Analysis",
    author = {Arras, Leila  and
      Montavon, Gr{\'e}goire  and
      M{\"u}ller, Klaus-Robert  and
      Samek, Wojciech},
    booktitle = "Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    year = "2017",
    pages = "159--168",

}
@inproceedings{yuan2021explaining,
  title={Explaining information flow inside vision transformers using markov chain},
  author={Yuan, Tingyi and Li, Xuhong and Xiong, Haoyi and Cao, Hui and Dou, Dejing},
  booktitle={eXplainable AI approaches for debugging and diagnosis.},
  year={2021}
}
@article{guillaumin2014imagenet,
  title={Imagenet auto-annotation with segmentation propagation},
  author={Guillaumin, Matthieu and K{\"u}ttel, Daniel and Ferrari, Vittorio},
  journal={International Journal of Computer Vision},
  volume={110},
  pages={328--348},
  year={2014},
  publisher={Springer}
}
@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@article{mambaPoint,
  title={PointMamba: A Simple State Space Model for Point Cloud Analysis},
  author={Liang, Dingkang and Zhou, Xin and Wang, Xinyu and Zhu, Xingkui and Xu, Wei and Zou, Zhikang and Ye, Xiaoqing and Bai, Xiang},
  journal={arXiv preprint arXiv:2402.10739},
  year={2024}
}


@article{mambaGraph1,
  title={Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective State Spaces},
  author={Wang, Chloe and Tsepa, Oleksii and Ma, Jun and Wang, Bo},
  journal={arXiv preprint arXiv:2402.00789},
  year={2024}
}

@article{mambaGraph2,
  title={Graph Mamba: Towards Learning on Graphs with State Space Models},
  author={Behrouz, Ali and Hashemi, Farnoosh},
  journal={arXiv preprint arXiv:2402.08678},
  year={2024}
}


mambaViT1
mambaViT1
mambaMedical
@article{mambaMedical1,
  title={Semi-Mamba-UNet: Pixel-Level Contrastive Cross-Supervised Visual Mamba-based UNet for Semi-Supervised Medical Image Segmentation},
  author={Wang, Ziyang and Ma, Chao},
  journal={arXiv preprint arXiv:2402.07245},
  year={2024}
}

@article{mambaMedical2,
  title={Mamba-unet: Unet-like pure visual mamba for medical image segmentation},
  author={Wang, Ziyang and Zheng, Jian-Qing and Zhang, Yichi and Cui, Ge and Li, Lei},
  journal={arXiv preprint arXiv:2402.05079},
  year={2024}
}

@article{mambaMedical8,
  title={nnMamba: 3D Biomedical Image Segmentation, Classification and Landmark Detection with State Space Model},
  author={Gong, Haifan and Kang, Luoyao and Wang, Yitao and Wan, Xiang and Li, Haofeng},
  journal={arXiv preprint arXiv:2402.03526},
  year={2024}
}

@article{mambaMedical3,
  title={Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining},
  author={Liu, Jiarun and Yang, Hao and Zhou, Hong-Yu and Xi, Yan and Yu, Lequan and Yu, Yizhou and Liang, Yong and Shi, Guangming and Zhang, Shaoting and Zheng, Hairong and others},
  journal={arXiv preprint arXiv:2402.03302},
  year={2024}
}

@article{mambaMedical4,
  title={Vm-unet: Vision mamba unet for medical image segmentation},
  author={Ruan, Jiacheng and Xiang, Suncheng},
  journal={arXiv preprint arXiv:2402.02491},
  year={2024}
}

@article{lv2024decision,
  title={Decision Mamba: A Multi-Grained State Space Model with Self-Evolution Regularization for Offline RL},
  author={Lv, Qi and Deng, Xiang and Chen, Gongwei and Wang, Michael Yu and Nie, Liqiang},
  journal={arXiv preprint arXiv:2406.05427},
  year={2024}
}

@article{mambaMedical5,
  title={Segmamba: Long-range sequential modeling mamba for 3d medical image segmentation},
  author={Xing, Zhaohu and Ye, Tian and Yang, Yijun and Liu, Guang and Zhu, Lei},
  journal={arXiv preprint arXiv:2401.13560},
  year={2024}
}

@article{mambaMedical7,
  title={U-mamba: Enhancing long-range dependency for biomedical image segmentation},
  author={Ma, Jun and Li, Feifei and Wang, Bo},
  journal={arXiv preprint arXiv:2401.04722},
  year={2024}
}


@article{mambaND,
  title={Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data},
  author={Li, Shufan and Singh, Harkanwar and Grover, Aditya},
  journal={arXiv preprint arXiv:2402.05892},
  year={2024}
}


@inproceedings{li2025videomamba,
  title={Videomamba: State space model for efficient video understanding},
  author={Li, Kunchang and Li, Xinhao and Wang, Yi and He, Yinan and Wang, Yali and Wang, Limin and Qiao, Yu},
  booktitle={European Conference on Computer Vision},
  pages={237--255},
  year={2025},
  organization={Springer}
}


@article{chen2024video,
  title={Video mamba suite: State space model as a versatile alternative for video understanding},
  author={Chen, Guo and Huang, Yifei and Xu, Jilan and Pei, Baoqi and Chen, Zhe and Li, Zhiqi and Wang, Jiahao and Li, Kunchang and Lu, Tong and Wang, Limin},
  journal={arXiv preprint arXiv:2403.09626},
  year={2024}
}

@article{mambamoe1,
  title={BlackMamba: Mixture of Experts for State-Space Models},
  author={Anthony, Quentin and Tokpanov, Yury and Glorioso, Paolo and Millidge, Beren},
  journal={arXiv preprint arXiv:2402.01771},
  year={2024}
}

@article{mambamoe2,
  title={Moe-mamba: Efficient selective state space models with mixture of experts},
  author={Pi{\'o}ro, Maciej and Ciebiera, Kamil and Kr{\'o}l, Krystian and Ludziejewski, Jan and Jaszczur, Sebastian},
  journal={arXiv preprint arXiv:2401.04081},
  year={2024}
}

@article{wang2024mambabyte,
  title={MambaByte: Token-free Selective State Space Model},
  author={Wang, Junxiong and Gangavarapu, Tushaar and Yan, Jing Nathan and Rush, Alexander M},
  journal={arXiv preprint arXiv:2401.13660},
  year={2024}
}

@article{mambaViT1,
  title={Vmamba: Visual state space model},
  author={Liu, Yue and Tian, Yunjie and Zhao, Yuzhong and Yu, Hongtian and Xie, Lingxi and Wang, Yaowei and Ye, Qixiang and Liu, Yunfan},
  journal={arXiv preprint arXiv:2401.10166},
  year={2024}
}

@article{mambaViT2,
  title={Vision mamba: Efficient visual representation learning with bidirectional state space model},
  author={Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong and Liu, Wenyu and Wang, Xinggang},
  journal={arXiv preprint arXiv:2401.09417},
  year={2024}
}

@article{ahamed2024mambatab,
  title={MambaTab: A Simple Yet Effective Approach for Handling Tabular Data},
  author={Ahamed, Md Atik and Cheng, Qiang},
  journal={arXiv preprint arXiv:2401.08867},
  year={2024}
}

@article{gu2023mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}

@article{gu2021combining,
  title={Combining recurrent, convolutional, and continuous-time models with linear state space layers},
  author={Gu, Albert and Johnson, Isys and Goel, Karan and Saab, Khaled and Dao, Tri and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={572--585},
  year={2021}
}

@article{scan1,
  title={Prefix sums and their applications},
  author={Blelloch, Guy E},
  year={1990},
  publisher={School of Computer Science, Carnegie Mellon University Pittsburgh, PA, USA}
}
@article{blelloch1990prefix,
  title={Prefix sums and their applications},
  author={Blelloch, Guy E},
  year={1990},
journal={Technical Report},
  publisher={School of Computer Science, Carnegie Mellon University Pittsburgh, PA, USA}
}

@article{scan2,
  title={Parallelizing linear recurrent neural nets over sequence length},
  author={Martin, Eric and Cundy, Chris},
  journal={arXiv preprint arXiv:1709.04057},
  year={2017}
}
@article{lutati2023focus,
  title={Focus Your Attention (with Adaptive IIR Filters)},
  author={Lutati, Shahar and Zimerman, Itamar and Wolf, Lior},
  journal={arXiv preprint arXiv:2305.14952},
  year={2023}
}

@inproceedings{david2022decision,
  title={Decision S4: Efficient Sequence-Based RL via State Spaces Layers},
  author={David, Shmuel Bar and Zimerman, Itamar and Nachmani, Eliya and Wolf, Lior},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{lu2024structured,
  title={Structured state space models for in-context reinforcement learning},
  author={Lu, Chris and Schroecker, Yannick and Gu, Albert and Parisotto, Emilio and Foerster, Jakob and Singh, Satinder and Behbahani, Feryal},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{gu2021efficiently,
  title={Efficiently modeling long sequences with structured state spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2111.00396},
  year={2021}
}

@article{mehta2022long,
  title={Long range language modeling via gated state spaces},
  author={Mehta, Harsh and Gupta, Ankit and Cutkosky, Ashok and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2206.13947},
  year={2022}
}

@article{fu2022hungry, title={Hungry hungry hippos: Towards language modeling with state space models}, author={Fu, Daniel Y and Dao, Tri and Saab, Khaled K and Thomas, Armin W and Rudra, Atri and R{\'e}, Christopher}, journal={arXiv preprint arXiv:2212.14052}, year={2022} }

@inproceedings{goel2022s,
  title={It‚Äôs raw! audio generation with state-space models},
  author={Goel, Karan and Gu, Albert and Donahue, Chris and R{\'e}, Christopher},
  booktitle={International Conference on Machine Learning},
  pages={7616--7633},
  year={2022},
  organization={PMLR}
}


@article{baron20232,
  title={2-D SSM: A General Spatial Layer for Visual Transformers},
  author={Baron, Ethan and Zimerman, Itamar and Wolf, Lior},
  journal={arXiv preprint arXiv:2306.06635},
  year={2023}
}


@article{nguyen2022s4nd,
  title={S4nd: Modeling images and videos as multidimensional signals with state spaces},
  author={Nguyen, Eric and Goel, Karan and Gu, Albert and Downs, Gordon and Shah, Preey and Dao, Tri and Baccus, Stephen and R{\'e}, Christopher},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={2846--2861},
  year={2022}
}

@article{yan2023diffusion,
  title={Diffusion models without attention},
  author={Yan, Jing Nathan and Gu, Jiatao and Rush, Alexander M},
  journal={arXiv preprint arXiv:2311.18257},
  year={2023}
}

@inproceedings{wang2023selective,
  title={Selective structured state-spaces for long-form video understanding},
  author={Wang, Jue and Zhu, Wentao and Wang, Pichao and Yu, Xiang and Liu, Linda and Omar, Mohamed and Hamid, Raffay},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6387--6397},
  year={2023}
}

@inproceedings{saon2023diagonal,
  title={Diagonal state space augmented transformers for speech recognition},
  author={Saon, George and Gupta, Ankit and Cui, Xiaodong},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}



@article{chefer2022optimizing,
  title={Optimizing relevance maps of vision transformers improves robustness},
  author={Chefer, Hila and Schwartz, Idan and Wolf, Lior},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={33618--33632},
  year={2022}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}
@inbook{fullgrad,
author = {Srinivas, Suraj and Fleuret, Fran\c{c}ois},
title = {Full-gradient representation for neural network visualization},
year = {2019},
publisher = {Curran Associates Inc.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {371},
numpages = {10}
}
@article{montavon2017explaining,
  title={Explaining nonlinear classification decisions with deep taylor decomposition},
  author={Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  journal={Pattern recognition},
  volume={65},
  pages={211--222},
  year={2017},
  publisher={Elsevier}
}

@article{poli2023hyena,
  title={Hyena hierarchy: Towards larger convolutional language models},
  author={Poli, Michael and Massaroli, Stefano and Nguyen, Eric and Fu, Daniel Y and Dao, Tri and Baccus, Stephen and Bengio, Yoshua and Ermon, Stefano and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2302.10866},
  year={2023}
}



@article{gao2020pile,
  title={The pile: An 800gb dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}


@article{peng2023rwkv,
  title={RWKV: Reinventing RNNs for the Transformer Era},
  author={Peng, Bo and Alcaide, Eric and Anthony, Quentin and Albalak, Alon and Arcadinho, Samuel and Cao, Huanqi and Cheng, Xin and Chung, Michael and Grella, Matteo and GV, Kranthi Kiran and others},
  journal={arXiv preprint arXiv:2305.13048},
  year={2023}
}


@article{fan2023rmt,
  title={Rmt: Retentive networks meet vision transformers},
  author={Fan, Qihang and Huang, Huaibo and Chen, Mingrui and Liu, Hongmin and He, Ran},
  journal={arXiv preprint arXiv:2309.11523},
  year={2023}
}

@article{zimerman2023multi,
  title={Multi-Dimensional Hyena for Spatial Inductive Bias},
  author={Zimerman, Itamar and Wolf, Lior},
  journal={arXiv preprint arXiv:2309.13600},
  year={2023}
}

@article{ma2022mega,
  title={Mega: moving average equipped gated attention},
  author={Ma, Xuezhe and Zhou, Chunting and Kong, Xiang and He, Junxian and Gui, Liangke and Neubig, Graham and May, Jonathan and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2209.10655},
  year={2022}
}

@inproceedings{hua2022transformer,
  title={Transformer quality in linear time},
  author={Hua, Weizhe and Dai, Zihang and Liu, Hanxiao and Le, Quoc},
  booktitle={International Conference on Machine Learning},
  pages={9099--9117},
  year={2022},
  organization={PMLR}
}

@article{zimerman2023converting,
  title={Converting Transformers to Polynomial Form for Secure Inference Over Homomorphic Encryption},
  author={Zimerman, Itamar and Baruch, Moran and Drucker, Nir and Ezov, Gilad and Soceanu, Omri and Wolf, Lior},
  journal={arXiv preprint arXiv:2311.08610},
  year={2023}
}

@article{smith2022simplified,
  title={Simplified state space layers for sequence modeling},
  author={Smith, Jimmy TH and Warrington, Andrew and Linderman, Scott W},
  journal={arXiv preprint arXiv:2208.04933},
  year={2022}
}
@article{lu2021soft,
  title={Soft: Softmax-free transformer with linear complexity},
  author={Lu, Jiachen and Yao, Jinghan and Zhang, Junge and Zhu, Xiatian and Xu, Hang and Gao, Weiguo and Xu, Chunjing and Xiang, Tao and Zhang, Li},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={21297--21309},
  year={2021}
}

@article{wortsman2023replacing,
  title={Replacing softmax with relu in vision transformers},
  author={Wortsman, Mitchell and Lee, Jaehoon and Gilmer, Justin and Kornblith, Simon},
  journal={arXiv preprint arXiv:2309.08586},
  year={2023}
}

@article{dss,
  title={Diagonal state spaces are as effective as structured state spaces},
  author={Gupta, Ankit and Gu, Albert and Berant, Jonathan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={22982--22994},
  year={2022}
}

@article{gss,
  title={Long range language modeling via gated state spaces},
  author={Mehta, Harsh and Gupta, Ankit and Cutkosky, Ashok and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2206.13947},
  year={2022}
}

@article{shazeer2020glu,
  title={Glu variants improve transformer},
  author={Shazeer, Noam},
  journal={arXiv preprint arXiv:2002.05202},
  year={2020}
}

@article{MAMABICL1,
  title={Is Mamba Capable of In-Context Learning?},
  author={Grazzi, Riccardo and Siems, Julien and Schrodi, Simon and Brox, Thomas and Hutter, Frank},
  journal={arXiv preprint arXiv:2402.03170},
  year={2024}
}

@article{MAMABAICL2,
  title={Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks},
  author={Park, Jongho and Park, Jaeseung and Xiong, Zheyang and Lee, Nayoung and Cho, Jaewoong and Oymak, Samet and Lee, Kangwook and Papailiopoulos, Dimitris},
  journal={arXiv preprint arXiv:2402.04248},
  year={2024}
}

@article{zimerman2023long,
  title={On the long range abilities of transformers},
  author={Zimerman, Itamar and Wolf, Lior},
  journal={arXiv preprint arXiv:2311.16620},
  year={2023}
}

@article{farooq2021global,
  title={Global interaction modelling in vision transformer via super tokens},
  author={Farooq, Ammarah and Awais, Muhammad and Ahmed, Sara and Kittler, Josef},
  journal={arXiv preprint arXiv:2111.13156},
  year={2021}
}

@inproceedings{hatamizadeh2023global,
  title={Global context vision transformers},
  author={Hatamizadeh, Ali and Yin, Hongxu and Heinrich, Greg and Kautz, Jan and Molchanov, Pavlo},
  booktitle={International Conference on Machine Learning},
  pages={12633--12646},
  year={2023},
  organization={PMLR}
}
@article{ali2024hidden,
  title={The hidden attention of mamba models},
  author={Ali, Ameen and Zimerman, Itamar and Wolf, Lior},
  journal={arXiv preprint arXiv:2403.01590},
  year={2024}
}
@article{gupta2022simplifying, title={Simplifying and understanding state space models with diagonal linear rnns}, author={Gupta, Ankit and Mehta, Harsh and Berant, Jonathan}, journal={arXiv preprint arXiv:2212.00768}, year={2022} }

@article{romero2021ckconv,
  title={Ckconv: Continuous kernel convolution for sequential data},
  author={Romero, David W and Kuzina, Anna and Bekkers, Erik J and Tomczak, Jakub M and Hoogendoorn, Mark},
  journal={arXiv preprint arXiv:2102.02611},
  year={2021}
}


@article{pioro2024moe,
  title={Moe-mamba: Efficient selective state space models with mixture of experts},
  author={Pi{\'o}ro, Maciej and Ciebiera, Kamil and Kr{\'o}l, Krystian and Ludziejewski, Jan and Jaszczur, Sebastian},
  journal={arXiv preprint arXiv:2401.04081},
  year={2024}
}

@article{MS1,
  title={A Survey on Vision Mamba: Models, Applications and Challenges},
  author={Xu, Rui and Yang, Shu and Wang, Yihui and Du, Bo and Chen, Hao},
  journal={arXiv preprint arXiv:2404.18861},
  year={2024}
}

@article{MS2,
  title={Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges},
  author={Patro, Badri Narayana and Agneeswaran, Vijay Srinivas},
  journal={arXiv preprint arXiv:2404.16112},
  year={2024}
}

@article{MS3,
  title={A Survey on Visual Mamba},
  author={Zhang, Hanwei and Zhu, Ying and Wang, Dan and Zhang, Lijun and Chen, Tianxiang and Ye, Zi},
  journal={arXiv preprint arXiv:2404.15956},
  year={2024}
}

@article{qin2024hgrn2,
  title={HGRN2: Gated Linear RNNs with State Expansion},
  author={Qin, Zhen and Yang, Songlin and Sun, Weixuan and Shen, Xuyang and Li, Dong and Sun, Weigao and Zhong, Yiran},
  journal={arXiv preprint arXiv:2404.07904},
  year={2024}
}

@article{sun2023retentive,
  title={Retentive network: A successor to transformer for large language models},
  author={Sun, Yutao and Dong, Li and Huang, Shaohan and Ma, Shuming and Xia, Yuqing and Xue, Jilong and Wang, Jianyong and Wei, Furu},
  journal={arXiv preprint arXiv:2307.08621},
  year={2023}
}

@article{duan2024vision,
  title={Vision-rwkv: Efficient and scalable visual perception with rwkv-like architectures},
  author={Duan, Yuchen and Wang, Weiyun and Chen, Zhe and Zhu, Xizhou and Lu, Lewei and Lu, Tong and Qiao, Yu and Li, Hongsheng and Dai, Jifeng and Wang, Wenhai},
  journal={arXiv preprint arXiv:2403.02308},
  year={2024}
}

@inproceedings{zimerman2024multi,
  title={Multi-dimensional hyena for spatial inductive bias},
  author={Zimerman, Itamar and Wolf, Lior},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={973--981},
  year={2024},
  organization={PMLR}
}

@article{spravil2024hyenapixel,
  title={HyenaPixel: Global Image Context with Convolutions},
  author={Spravil, Julian and Houben, Sebastian and Behnke, Sven},
  journal={arXiv preprint arXiv:2402.19305},
  year={2024}
}


@article{attanasio2022entropy,
  title={Entropy-based attention regularization frees unintended bias mitigation from lists},
  author={Attanasio, Giuseppe and Nozza, Debora and Hovy, Dirk and Baralis, Elena},
  journal={arXiv preprint arXiv:2203.09192},
  year={2022}
}

@article{li2018multi,
  title={Multi-head attention with disagreement regularization},
  author={Li, Jian and Tu, Zhaopeng and Yang, Baosong and Lyu, Michael R and Zhang, Tong},
  journal={arXiv preprint arXiv:1810.10183},
  year={2018}
}

@article{bonaldi2023weigh,
  title={Weigh your own words: Improving hate speech counter narrative generation via attention regularization},
  author={Bonaldi, Helena and Attanasio, Giuseppe and Nozza, Debora and Guerini, Marco},
  journal={arXiv preprint arXiv:2309.02311},
  year={2023}
}



@inproceedings{hatamizadeh2023global,
  title={Global context vision transformers},
  author={Hatamizadeh, Ali and Yin, Hongxu and Heinrich, Greg and Kautz, Jan and Molchanov, Pavlo},
  booktitle={International Conference on Machine Learning},
  pages={12633--12646},
  year={2023},
  organization={PMLR}
}


@article{romero2021ckconv,
  title={Ckconv: Continuous kernel convolution for sequential data},
  author={Romero, David W and Kuzina, Anna and Bekkers, Erik J and Tomczak, Jakub M and Hoogendoorn, Mark},
  journal={arXiv preprint arXiv:2102.02611},
  year={2021}
}

@article{lieber2024jamba,
  title={Jamba: A hybrid transformer-mamba language model},
  author={Lieber, Opher and Lenz, Barak and Bata, Hofit and Cohen, Gal and Osin, Jhonathan and Dalmedigos, Itay and Safahi, Erez and Meirom, Shaked and Belinkov, Yonatan and Shalev-Shwartz, Shai and others},
  journal={arXiv preprint arXiv:2403.19887},
  year={2024}
}

@article{de2024griffin,
  title={Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models},
  author={De, Soham and Smith, Samuel L and Fernando, Anushan and Botev, Aleksandar and Cristian-Muraru, George and Gu, Albert and Haroun, Ruba and Berrada, Leonard and Chen, Yutian and Srinivasan, Srivatsan and others},
  journal={arXiv preprint arXiv:2402.19427},
  year={2024}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@article{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}

@article{yang2023gated,
  title={Gated linear attention transformers with hardware-efficient training},
  author={Yang, Songlin and Wang, Bailin and Shen, Yikang and Panda, Rameswar and Kim, Yoon},
  journal={arXiv preprint arXiv:2312.06635},
  year={2023}
}

@article{katsch2023gateloop,
  title={Gateloop: Fully data-controlled linear recurrence for sequence modeling},
  author={Katsch, Tobias},
  journal={arXiv preprint arXiv:2311.01927},
  year={2023}
}



@inproceedings{orvieto2023resurrecting,
  title={Resurrecting recurrent neural networks for long sequences},
  author={Orvieto, Antonio and Smith, Samuel L and Gu, Albert and Fernando, Anushan and Gulcehre, Caglar and Pascanu, Razvan and De, Soham},
  booktitle={International Conference on Machine Learning},
  pages={26670--26698},
  year={2023},
  organization={PMLR}
}

@inproceedings{biderman2023pythia,
  title={Pythia: A suite for analyzing large language models across training and scaling},
  author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin Gregory and Bradley, Herbie and O‚ÄôBrien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
  booktitle={International Conference on Machine Learning},
  pages={2397--2430},
  year={2023},
  organization={PMLR}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}


@article{poli2024mechanistic,
  title={Mechanistic Design and Scaling of Hybrid Architectures},
  author={Poli, Michael and Thomas, Armin W and Nguyen, Eric and Ponnusamy, Pragaash and Deiseroth, Bj{\"o}rn and Kersting, Kristian and Suzuki, Taiji and Hie, Brian and Ermon, Stefano and R{\'e}, Christopher and others},
  journal={arXiv preprint arXiv:2403.17844},
  year={2024}
}

@article{wang2022pretraining,
  title={Pretraining without attention},
  author={Wang, Junxiong and Yan, Jing Nathan and Gu, Albert and Rush, Alexander M},
  journal={arXiv preprint arXiv:2212.10544},
  year={2022}
}

@article{qin2024hierarchically,
  title={Hierarchically gated recurrent neural network for sequence modeling},
  author={Qin, Zhen and Yang, Songlin and Zhong, Yiran},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{zhai2021attention,
  title={An attention free transformer},
  author={Zhai, Shuangfei and Talbott, Walter and Srivastava, Nitish and Huang, Chen and Goh, Hanlin and Zhang, Ruixiang and Susskind, Josh},
  journal={arXiv preprint arXiv:2105.14103},
  year={2021}
}


@article{peng2024eagle,
  title={Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence},
  author={Peng, Bo and Goldstein, Daniel and Anthony, Quentin and Albalak, Alon and Alcaide, Eric and Biderman, Stella and Cheah, Eugene and Ferdinan, Teddy and Hou, Haowen and Kazienko, Przemys{\l}aw and others},
  journal={arXiv preprint arXiv:2404.05892},
  year={2024}
}


@article{merrill2024illusion,
  title={The illusion of state in state-space models},
  author={Merrill, William and Petty, Jackson and Sabharwal, Ashish},
  journal={arXiv preprint arXiv:2404.08819},
  year={2024}
}

@article{cirone2024theoretical,
  title={Theoretical Foundations of Deep Selective State-Space Models},
  author={Cirone, Nicola Muca and Orvieto, Antonio and Walker, Benjamin and Salvi, Cristopher and Lyons, Terry},
  journal={arXiv preprint arXiv:2402.19047},
  year={2024}
}

@article{jelassi2024repeat,
  title={Repeat after me: Transformers are better than state space models at copying},
  author={Jelassi, Samy and Brandfonbrener, David and Kakade, Sham M and Malach, Eran},
  journal={arXiv preprint arXiv:2402.01032},
  year={2024}
}

@article{wang2024state,
  title={State-space models with layer-wise nonlinearity are universal approximators with exponential decaying memory},
  author={Wang, Shida and Xue, Beichen},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

% papers cited in the "vacuous bound?" section
@ARTICLE{2017arXiv170608498B,
   author = {{Bartlett}, P. and {Foster}, D.~J. and {Telgarsky}, M.},
    title = "{Spectrally-normalized margin bounds for neural networks}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1706.08498},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
     year = 2017,
    month = jun,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170608498B},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{jiang2019fantastic,
  title={Fantastic generalization measures and where to find them},
  author={Jiang, Yiding and Neyshabur, Behnam and Mobahi, Hossein and Krishnan, Dilip and Bengio, Samy},
  journal={arXiv preprint arXiv:1912.02178},
  year={2019}
}
@article{xu2023dynamics,
  title={Dynamics in Deep Classifiers Trained with the Square Loss: Normalization, Low Rank, Neural Collapse, and Generalization Bounds},
  author={Xu, Mengjia and Rangamani, Akshay and Liao, Qianli and Galanti, Tomer and Poggio, Tomaso},
  journal={Research},
  volume={6},
  pages={0024},
  year={2023},
  publisher={AAAS}
}
@book{AntBartlett2002,
author = {Anthony, M. and Bartlett, P.},
  title={Neural Network Learning - Theoretical Foundations},
publisher = {Cambridge University Press},
  year={2002}
}

@InProceedings{10.1007/978-3-319-46379-7_1,
author="Maurer, Andreas",
editor="Ortner, Ronald
and Simon, Hans Ulrich
and Zilles, Sandra",
title="A Vector-Contraction Inequality for Rademacher Complexities",
booktitle="Algorithmic Learning Theory",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="3--17",
abstract="The contraction inequality for Rademacher averages is extended to Lipschitz functions with vector-valued domains, and it is also shown that in the bounding expression the Rademacher variables can be replaced by arbitrary iid symmetric and sub-gaussian variables. Example applications are given for multi-category learning, K-means clustering and learning-to-learn.",
isbn="978-3-319-46379-7"
}



@book{MohriRostamizadehTalwalkar18,
  origdate = {2012},
  pagetotal = {504},
  publisher = {MIT Press},
  referencetype = {book},
  series = {Adaptive Computation and Machine Learning},
  edition = {2nd},
  address = {Cambridge, MA},
  author = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  title = {Foundations of Machine Learning},
  year = {2018}
}
@article{truong2022rademacher,
  title={On Rademacher Complexity-based Generalization Bounds for Deep Learning},
  author={Truong, Lan V},
  journal={arXiv preprint arXiv:2208.04284},
  year={2022}
}


@article{wei2019data,
  title={Data-dependent sample complexity of deep neural networks via lipschitz augmentation},
  author={Wei, Colin and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@article{ho2020denoising,
    title={Denoising Diffusion Probabilistic Models},
    author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
    year={2020},
    journal={arXiv preprint arxiv:2006.11239}
}

@article{JMLR:v8:tewari07a,
  author  = {Ambuj Tewari and Peter L. Bartlett},
  title   = {On the Consistency of Multiclass Classification Methods},
  journal = {Journal of Machine Learning Research},
  year    = {2007},
  volume  = {8},
  number  = {36},
  pages   = {1007--1025},
  url     = {http://jmlr.org/papers/v8/tewari07a.html}
}

@article{10.5555/1005332.1044701,
author = {Zhang, Tong},
title = {Statistical Analysis of Some Multi-Category Large Margin Classification Methods},
year = {2004},
issue_date = {12/1/2004},
publisher = {JMLR.org},
volume = {5},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = {dec},
pages = {1225‚Äì1251},
numpages = {27}
}

@article{Boucheron2010,
author = {St√©phane Boucheron, Olivier Bousquet, G√°bor Lugosi},
journal = {ESAIM: Probability and Statistics},
keywords = {Pattern recognition; statistical learning theory; concentration inequalities; empirical processes; model selection.; concentration inequalities; model selection},
language = {eng},
month = {3},
pages = {323-375},
publisher = {EDP Sciences},
title = {Theory of Classification: a Survey of Some Recent Advances},
url = {http://eudml.org/doc/104340},
volume = {9},
year = {2010},
}

@book{DBLP:books/daglib/0035704,
  author    = {St{\'{e}}phane Boucheron and
               G{\'{a}}bor Lugosi and
               Pascal Massart},
  title     = {Concentration Inequalities - {A} Nonasymptotic Theory of Independence},
  publisher = {Oxford University Press},
  year      = {2013},
  url       = {https://doi.org/10.1093/acprof:oso/9780199535255.001.0001},
  doi       = {10.1093/acprof:oso/9780199535255.001.0001},
  isbn      = {978-0-19-953525-5},
  timestamp = {Mon, 16 Sep 2019 14:43:12 +0200},
  biburl    = {https://dblp.org/rec/books/daglib/0035704.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{https://doi.org/10.48550/arxiv.1806.05159,
  doi = {10.48550/ARXIV.1806.05159},
  
  url = {https://arxiv.org/abs/1806.05159},
  
  author = {Li, Xingguo and Lu, Junwei and Wang, Zhaoran and Haupt, Jarvis and Zhao, Tuo},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {On Tighter Generalization Bound for Deep Neural Networks: CNNs, ResNets, and Beyond},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{ledent, 
title={Norm-Based Generalisation Bounds for Deep Multi-Class Convolutional Neural Networks}, 
volume={35}, 
url={https://ojs.aaai.org/index.php/AAAI/article/view/17007}, DOI={10.1609/aaai.v35i9.17007}, 
number={9}, 
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
author={Ledent, Antoine and Mustafa, Waleed and Lei, Yunwen and Kloft, Marius}, 
year={2021}, 
month={May}, 
pages={8279-8287}
}



@article{JMLR:v20:17-612,
  author  = {Peter L. Bartlett and Nick Harvey and Christopher Liaw and Abbas Mehrabian},
  title   = {Nearly-tight VC-dimension and Pseudodimension Bounds for Piecewise Linear Neural Networks},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {63},
  pages   = {1--17},
  url     = {http://jmlr.org/papers/v20/17-612.html}
}

@article{Poggio2022,
  title={Foundations of Deep Learning: Compositional Sparsity of Computable Functions},
  author={Poggio, T.},
  journal={CBMM memo 138},
  year={2022}
}



@misc{https://doi.org/10.48550/arxiv.1412.6614,
  doi = {10.48550/ARXIV.1412.6614},
  
  url = {https://arxiv.org/abs/1412.6614},
  
  author = {Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{10.5555/3298483.3298577,
author = {Mhaskar, Hrushikesh and Liao, Qianli and Poggio, Tomaso},
title = {When and Why Are Deep Networks Better than Shallow Ones?},
year = {2017},
publisher = {AAAI Press},
booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
pages = {2343‚Äì2349},
numpages = {7},
location = {San Francisco, California, USA},
series = {AAAI'17}
}

@book{Vapnik1998,
  author = {Vapnik, Vladimir N.},
  publisher = {Wiley-Interscience},
  title = {Statistical Learning Theory},
  year = {1998}
}
@inproceedings{ledent2021norm,
  title={Norm-based generalisation bounds for deep multi-class convolutional neural networks},
  author={Ledent, Antoine and Mustafa, Waleed and Lei, Yunwen and Kloft, Marius},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={9},
  pages={8279--8287},
  year={2021}
}
@article{long2019generalization,
  title={Generalization bounds for deep convolutional neural networks},
  author={Long, Philip M and Sedghi, Hanie},
  journal={arXiv preprint arXiv:1905.12600},
  year={2019}
}
@inproceedings{golowich2018size,
  title={Size-independent sample complexity of neural networks},
  author={Golowich, Noah and Rakhlin, Alexander and Shamir, Ohad},
  booktitle={Conference On Learning Theory},
  pages={297--299},
  year={2018},
  organization={PMLR}
}

@inproceedings{
zhou2018nonvacuous,
title={Non-vacuous Generalization Bounds at the ImageNet Scale: a {PAC}-Bayesian Compression Approach},
author={Wenda Zhou and Victor Veitch and Morgane Austern and Ryan P. Adams and Peter Orbanz},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=BJgqqsAct7},
}

@inproceedings{hellstrom,
 author = {Hellstr\"{o}m, Fredrik and Durisi, Giuseppe},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {10108--10121},
 publisher = {Curran Associates, Inc.},
 title = {A New Family of Generalization Bounds Using Samplewise Evaluated CMI},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/41b6674c28a9b93ec8d22a53ca25bc3b-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@inproceedings{DR17,
  author       = {Gintare Karolina Dziugaite and
                  Daniel M. Roy},
  title        = {Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural
                  Networks with Many More Parameters than Training Data},
  booktitle    = {Proceedings of the Thirty-Third Conference on Uncertainty in Artificial
                  Intelligence, {UAI} 2017, Sydney, Australia, August 11-15, 2017},
  publisher    = {{AUAI} Press},
  year         = {2017},
  url          = {http://auai.org/uai2017/proceedings/papers/173.pdf},
  biburl       = {https://dblp.org/rec/conf/uai/DziugaiteR17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{cao2019generalization,
  title={Generalization bounds of stochastic gradient descent for wide and deep neural networks},
  author={Cao, Yuan and Gu, Quanquan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@InProceedings{pmlr-v162-biggs22a,
  title = 	 {Non-Vacuous Generalisation Bounds for Shallow Neural Networks},
  author =       {Biggs, Felix and Guedj, Benjamin},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {1963--1981},
  year = 	 {2022},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  url = 	 {https://proceedings.mlr.press/v162/biggs22a.html},
}

@misc{https://doi.org/10.48550/arxiv.1910.01487,
  doi = {10.48550/ARXIV.1910.01487},
  
  url = {https://arxiv.org/abs/1910.01487},
  
  author = {Lin, Shan and Zhang, Jingwei},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Generalization Bounds for Convolutional Neural Networks},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@book{Ledoux1991ProbabilityIB,
  title={Probability in Banach spaces},
  author={Michel Ledoux and Michel Talagrand},
  year={1991},
  publisher={Springer Berlin, Heidelberg},
  numpages={480},
}


@misc{https://doi.org/10.48550/arxiv.2010.08127,
  doi = {10.48550/ARXIV.2010.08127},
  
  url = {https://arxiv.org/abs/2010.08127},
  
  author = {Nakkiran, Preetum and Neyshabur, Behnam and Sedghi, Hanie},
  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Statistics Theory (math.ST), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.1602.07868,
  doi = {10.48550/ARXIV.1602.07868},
  
  url = {https://arxiv.org/abs/1602.07868},
  
  author = {Salimans, Tim and Kingma, Diederik P.},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{NEURIPS2019_62dad6e2,
 author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
 booktitle = {Advances in Neural Information Processing Systems},
 publisher = {Curran Associates, Inc.},
 title = {Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers},
 year = {2019}
}

@article{allen2019learning,
  title={Learning and generalization in overparameterized neural networks, going beyond two layers},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{
richards2021stability,
title={Stability \& Generalisation of Gradient Descent for Shallow Neural Networks without the Neural Tangent Kernel},
author={Dominic Richards and Ilja Kuzborskij},
booktitle={Advances in Neural Information Processing Systems},
year={2021},
volume={34},
publisher = {Curran Associates Inc.},
}

@inproceedings{taigman2014deepface,
  added-at = {2014-10-02T23:51:24.000+0200},
  author = {Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
  biburl = {https://www.bibsonomy.org/bibtex/25704a9ab4c0abe0c34b34b7d564b9401/seboettg},
  booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
  interhash = {19f4a0ed09dd182d9a45466f323efa72},
  intrahash = {5704a9ab4c0abe0c34b34b7d564b9401},
  keywords = {deepface face face-recognition recognition},
  timestamp = {2014-10-02T23:51:24.000+0200},
  title = {DeepFace: Closing the Gap to Human-Level Performance in Face Verification},
  year = {2014}
}

@article{SilverHuangEtAl16nature,
  added-at = {2016-05-21T09:09:48.000+0200},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/29e987f58d895c490144693139cbc90c7/flint63},
  doi = {10.1038/nature16961},
  file = {Nature online:2016/SilverHuangEtAl16nature.pdf:PDF},
  groups = {public},
  interhash = {48430c7891aaf9fe2582faa8f5d076c1},
  intrahash = {9e987f58d895c490144693139cbc90c7},
  issn = {0028-0836},
  journal = {Nature},
  keywords = {01614 paper ai google learn algorithm},
  pages = {484--489},
  timestamp = {2018-04-16T12:03:12.000+0200},
  title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
  volume = {529},
  year = {2016}
}

@misc{arulkumaran2019alphastar,
  added-at = {2019-04-09T12:11:21.000+0200},
  author = {Arulkumaran, Kai and Cully, Antoine and Togelius, Julian},
  biburl = {https://www.bibsonomy.org/bibtex/2947150f9813e394092cc1bef6f8a933d/stuart10},
  description = {AlphaStar: An Evolutionary Computation Perspective},
  interhash = {ac94adeb96ffdc292d0f1a5bf4b72ee6},
  intrahash = {947150f9813e394092cc1bef6f8a933d},
  keywords = {game},
  note = {cite arxiv:1902.01724},
  timestamp = {2019-04-09T12:11:21.000+0200},
  title = {AlphaStar: An Evolutionary Computation Perspective},
  url = {http://arxiv.org/abs/1902.01724},
  year = 2019
}

@misc{chen2021evaluating,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{zhai2021scaling,
      title={Scaling Vision Transformers}, 
      author={Xiaohua Zhai and Alexander Kolesnikov and Neil Houlsby and Lucas Beyer},
      year={2021},
      eprint={2106.04560},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}


@article{Mhaskar:1996:NNO:1362203.1362213,
 author = {Hrushikesh N. Mhaskar},
 title = {Neural Networks for Optimal Approximation of Smooth and Analytic Functions},
 journal = {Neural Comput.},
 issue_date = {January 1996},
 volume = {8},
 number = {1},
 year = {1996},
 pages = {164--177},
 publisher = {MIT Press},
} 

@article{10.1006/jath.1998.3305,
author = {Vitaly Maiorov and Ron Meir and Joel Ratsaby},
title = {On the Approximation of Functional Classes Equipped with a Uniform Measure Using Ridge Functions},
year = {1999},
publisher = {Academic Press, Inc.},
volume = {99},
number = {1},
journal = {J. Approx. Theory},
pages = {95‚Äì111},
}

@inproceedings{
nagarajan2018deterministic,
title={Deterministic {PAC}-Bayesian generalization bounds for deep networks via generalizing noise-resilience},
author={Vaishnavh Nagarajan and Zico Kolter},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Hygn2o0qKX},
}

@misc{https://doi.org/10.48550/arxiv.1901.08584,
  doi = {10.48550/ARXIV.1901.08584},
  
  url = {https://arxiv.org/abs/1901.08584},
  
  author = {Arora, Sanjeev and Du, Simon S. and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  
  keywords = {Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{10.1006/jath.1998.3304,
author = {Vitaly Maiorov},
title = {On Best Approximation by Ridge Functions},
year = {1999},
issue_date = {July 1999},
publisher = {Academic Press, Inc.},
volume = {99},
number = {1},
journal = {J. Approx. Theory},
}

@ARTICLE{Maiorov99lowerbounds,
    author = {Vitaly Maiorov and Allan Pinkus},
    title = {Lower bounds for approximation by MLP neural networks },
    journal = {NEUROCOMPUTING},
    year = {1999},
    volume = {25},
    pages = {81--91}
}


@misc{https://doi.org/10.48550/arxiv.1710.11278,
  doi = {10.48550/ARXIV.1710.11278},
  
  url = {https://arxiv.org/abs/1710.11278},
  
  author = {Hanin, Boris and Sellke, Mark},
  
  keywords = {Machine Learning (stat.ML), Computational Complexity (cs.CC), Machine Learning (cs.LG), Combinatorics (math.CO), Statistics Theory (math.ST), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {Approximating Continuous Functions by ReLU Nets of Minimal Width},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{
lotfi2022pacbayes,
title={{PAC}-Bayes Compression Bounds So Tight That They Can Explain Generalization},
author={Sanae Lotfi and Marc Anton Finzi and Sanyam Kapoor and Andres Potapczynski and Micah Goldblum and Andrew Gordon Wilson},
booktitle={Advances in Neural Information Processing Systems},
year={2022},
volume={35},
publisher = {Curran Associates Inc.},
}

@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 volume = {33},
 year = {2020}
}

@inproceedings{devlin-etal-2019-bert,
    title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author = {Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina},
    booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
    month = {jun},
    year = {2019},
    publisher = {Association for Computational Linguistics},
}

@misc{https://doi.org/10.48550/arxiv.1904.01367,
  doi = {10.48550/ARXIV.1904.01367},
  
  url = {https://arxiv.org/abs/1904.01367},
  
  author = {He, Fengxiang and Liu, Tongliang and Tao, Dacheng},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Why ResNet Works? Residuals Generalize},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{he2016residual,
  added-at = {2021-05-01T22:31:00.000+0200},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  biburl = {https://www.bibsonomy.org/bibtex/2f08d8f1a1881a5c9ee27060e40ada500/nosebrain},
  booktitle = {Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition},
  doi = {10.1109/CVPR.2016.90},
  interhash = {d2fe72bcc2c02bacc9fae990ec4d4927},
  intrahash = {f08d8f1a1881a5c9ee27060e40ada500},
  issn = {1063-6919},
  keywords = {image recognition resnet},
  location = {Las Vegas, NV, USA},
  month = jun,
  pages = {770--778},
  publisher = {IEEE},
  series = {CVPR '16},
  timestamp = {2021-05-01T22:31:00.000+0200},
  title = {{Deep Residual Learning for Image Recognition}},
  url = {http://ieeexplore.ieee.org/document/7780459},
  year = 2016
}

@misc{https://doi.org/10.48550/arxiv.1608.03983,
  doi = {10.48550/ARXIV.1608.03983},
  
  url = {https://arxiv.org/abs/1608.03983},
  
  author = {Loshchilov, Ilya and Hutter, Frank},
  
  keywords = {Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Optimization and Control (math.OC), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {SGDR: Stochastic Gradient Descent with Warm Restarts},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{10.5555/3295222.3295372,
author = {Bartlett, Peter L. and Foster, Dylan J. and Telgarsky, Matus},
title = {Spectrally-Normalized Margin Bounds for Neural Networks},
year = {2017},
publisher = {Curran Associates Inc.},
booktitle = {Advances in Neural Information Processing Systems},
volume={30},
}


@article{bartlett2017spectrally,
  title={Spectrally-normalized margin bounds for neural networks},
  author={Bartlett, Peter L and Foster, Dylan J and Telgarsky, Matus J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{https://doi.org/10.48550/arxiv.1709.01953,
  title={Implicit Regularization in Deep Learning},
  author={Behnam Neyshabur},
  journal={ArXiv},
  year={2017},
  volume={abs/1709.01953}
}


@article{beck2024xlstm,
  title={xLSTM: Extended Long Short-Term Memory},
  author={Beck, Maximilian and P{\"o}ppel, Korbinian and Spanring, Markus and Auer, Andreas and Prudnikova, Oleksandra and Kopp, Michael and Klambauer, G{\"u}nter and Brandstetter, Johannes and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:2405.04517},
  year={2024}
}

@book{feller1991introduction,
  title={An introduction to probability theory and its applications, Volume 2},
  author={Feller, William},
  volume={81},
  year={1991},
  publisher={John Wiley \& Sons}
}

@InProceedings{pmlr-v80-gunasekar18a,
  title = 	 {Characterizing Implicit Bias in Terms of Optimization Geometry},
  author =       {Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1832--1841},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/gunasekar18a/gunasekar18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/gunasekar18a.html},
}

@article{ramapuram2024theory,
  title={Theory, analysis, and best practices for sigmoid self-attention},
  author={Ramapuram, Jason and Danieli, Federico and Dhekane, Eeshan and Weers, Floris and Busbridge, Dan and Ablin, Pierre and Likhomanenko, Tatiana and Digani, Jagrit and Gu, Zijin and Shidani, Amitis and others},
  journal={arXiv preprint arXiv:2409.04431},
  year={2024}
}


@inproceedings{Bartlett2001RademacherAG,
  title={Rademacher and Gaussian Complexities: Risk Bounds and Structural Results},
  author={Peter L. Bartlett and Shahar Mendelson},
  booktitle={J. Mach. Learn. Res.},
  year={2001}
}

@inproceedings{NEURIPS2018_03c6b069,
 author = {Du, Simon S and Wang, Yining and Zhai, Xiyu and Balakrishnan, Sivaraman and Salakhutdinov, Russ R and Singh, Aarti},
 booktitle = {Advances in Neural Information Processing Systems},
 publisher = {Curran Associates, Inc.},
 title = {How Many Samples are Needed to Estimate a Convolutional Neural Network?},
 volume = {31},
 year = {2018}
}

@article{mambaRL1,
  title={Decision mamba: Reinforcement learning via sequence modeling with selective state spaces},
  author={Ota, Toshihiro},
  journal={arXiv preprint arXiv:2403.19925},
  year={2024}
}

@inproceedings{Dai2024IsMC,
  title={Is Mamba Compatible with Trajectory Optimization in Offline Reinforcement Learning?},
  author={Yang Dai and Oubo Ma and Longfei Zhang and Xingxing Liang and Shengchao Hu and Mengzhu Wang and Shouling Ji and Jincai Huang and Li Shen},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:269922242}
}

@article{Ota2024DecisionMR,
  title={Decision Mamba: Reinforcement Learning via Sequence Modeling with Selective State Spaces},
  author={Toshihiro Ota},
  journal={ArXiv},
  year={2024},
  volume={abs/2403.19925},
  url={https://api.semanticscholar.org/CorpusID:268793600}
}


@misc{lecun-mnisthandwrittendigit-2010,
  author = {LeCun, Yann and Cortes, Corinna},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  year = {2010},
}

@inproceedings{neyshabur2015norm,
  title={Norm-based capacity control in neural networks},
  author={Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
  booktitle={Conference on learning theory},
  pages={1376--1401},
  year={2015},
  organization={PMLR}
}


@inproceedings{
Long2020Generalization,
title={Generalization bounds for deep convolutional neural networks},
author={Philip M. Long and Hanie Sedghi},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=r1e_FpNFDr}
}

@article{Harvey2017NearlytightVB,
  title={Nearly-tight VC-dimension bounds for piecewise linear neural networks},
  author={Nick Harvey and Christopher Liaw and Abbas Mehrabian},
  journal={ArXiv},
  year={2017},
  volume={abs/1703.02930}
}



@inproceedings{timor2023implicit,
  title={Implicit regularization towards rank minimization in relu networks},
  author={Timor, Nadav and Vardi, Gal and Shamir, Ohad},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={1429--1459},
  year={2023},
  organization={PMLR}
}

@inproceedings{
le2022training,
title={Training invariances and the low-rank phenomenon: beyond linear networks},
author={Thien Le and Stefanie Jegelka},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=XEW8CQgArno}
}



@Article{Cybenko1989,
author={George Cybenko},
title="Approximation by superpositions of a sigmoidal function",
journal="Mathematics of Control, Signals and Systems",
year="1989",
volume="2",
number="4",
pages="303--314",
}

@article{Hornik1991ApproximationCO,
  title={Approximation capabilities of multilayer feedforward networks},
  author={Kurt Hornik},
  journal={Neural Networks},
  year={1991},
  volume={4},
  pages={251-257}
}

@inproceedings{
@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}




@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{galanti2022sgd,
  title={SGD and weight decay provably induce a low-rank bias in neural networks},
  author={Galanti, Tomer and Siegel, Zachary S and Gupte, Aparna and Poggio, Tomaso},
  journal={arXiv preprint arXiv:2206.05794},
  year={2022}
}

@article{li2018tighter,
  title={On tighter generalization bound for deep neural networks: Cnns, resnets, and beyond},
  author={Li, Xingguo and Lu, Junwei and Wang, Zhaoran and Haupt, Jarvis and Zhao, Tuo},
  journal={arXiv preprint arXiv:1806.05159},
  year={2018}
}



@inproceedings{ali2019continuous,
  title={A continuous-time view of early stopping for least squares regression},
  author={Ali, Alnur and Kolter, J Zico and Tibshirani, Ryan J},
  booktitle={The 22nd international conference on artificial intelligence and statistics},
  pages={1370--1378},
  year={2019},
  organization={PMLR}
}

@article{Belkin2021FitWF,
  title={Fit without fear: remarkable mathematical phenomena of deep learning through the prism of interpolation},
  author={Mikhail Belkin},
  journal={Acta Numerica},
  year={2021},
  volume={30},
  pages={203 - 248}
}

@inproceedings{
zhang2017understanding,
title={Understanding deep learning requires rethinking generalization},
author={Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=Sy8gdB9xx}
}

@inproceedings{NIPS2017_10ce03a1,
 author = {Neyshabur, Behnam and Bhojanapalli, Srinadh and Mcallester, David and Srebro, Nati},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 publisher = {Curran Associates, Inc.},
 title = {Exploring Generalization in Deep Learning},
 volume = {30},
 year = {2017}
}

@InProceedings{pmlr-v80-arora18b,
  title = 	 {Stronger Generalization Bounds for Deep Nets via a Compression Approach},
  author =       {Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang, Yi},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {254--263},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/arora18b/arora18b.pdf},
  url = 	 {https://proceedings.mlr.press/v80/arora18b.html},
}


@article{Neyshabur2018APA,
  title={A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks},
  author={Behnam Neyshabur and Srinadh Bhojanapalli and David A. McAllester and Nathan Srebro},
  journal={ArXiv},
  year={2018},
  volume={abs/1707.09564}
}

@article{Neyshabur2019TowardsUT,
  title={Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks},
  author={Behnam Neyshabur and Zhiyuan Li and Srinadh Bhojanapalli and Yann LeCun and Nathan Srebro},
  journal={ArXiv},
  year={2019},
  volume={abs/1805.12076}
}

@article{bartlett2002rademacher,
  title={Rademacher and Gaussian complexities: Risk bounds and structural results},
  author={Bartlett, Peter L and Mendelson, Shahar},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Nov},
  pages={463--482},
  year={2002}
}

@book{Shalev-Shwartz2014,
title = {Understanding Machine Learning: From Theory to Algorithms},
author = {Shalev-Shwartz, Shai and Ben-David, S. },
year={2014},
publisher = {Cambridge eBooks}
}

@book{Mohri:2012:FML:2371238,
  address = {Cambridge, MA},
  author = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  edition = 2,
  isbn = {978-0-262-03940-6},
  origdate = {2012},
  publisher = {MIT Press},
  timestamp = {2019-03-23T19:47:18.000+0100},
  title = {Foundations of Machine Learning},
  year = 2018
}

@book{mohri2018foundations,
  title={Foundations of machine learning},
  author={Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year={2018},
  publisher={MIT press}
}

@inproceedings{
Jiang2020Fantastic,
title={Fantastic Generalization Measures and Where to Find Them},
author={Yiding Jiang and Behnam Neyshabur and Hossein Mobahi and Dilip Krishnan and Samy Bengio},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SJgIPJBFvH}
}


@article{allen2019can,
  title={Can sgd learn recurrent neural networks with provable generalization?},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{cohen2022implicit,
  title={On the implicit bias of gradient descent for temporal extrapolation},
  author={Cohen-Karlik, Edo and David, Avichai Ben and Cohen, Nadav and Globerson, Amir},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={10966--10981},
  year={2022},
  organization={PMLR}
}

@article{cohen2022learning,
  title={Learning Low Dimensional State Spaces with Overparameterized Recurrent Neural Nets},
  author={Cohen-Karlik, Edo and Menuhin-Gruman, Itamar and Giryes, Raja and Cohen, Nadav and Globerson, Amir},
  journal={arXiv preprint arXiv:2210.14064},
  year={2022}
}

@inproceedings{emami2021implicit,
  title={Implicit bias of linear rnns},
  author={Emami, Melikasadat and Sahraee-Ardakan, Mojtaba and Pandit, Parthe and Rangan, Sundeep and Fletcher, Alyson K},
  booktitle={International Conference on Machine Learning},
  pages={2982--2992},
  year={2021},
  organization={PMLR}
}

@article{hardt2018gradient,
  title={Gradient descent learns linear dynamical systems},
  author={Hardt, Moritz and Ma, Tengyu and Recht, Benjamin},
  journal={Journal of Machine Learning Research},
  volume={19},
  number={29},
  pages={1--44},
  year={2018}
}

@inproceedings{
baron2024a,
title={A 2-Dimensional State Space Layer for Spatial Inductive Bias},
author={Ethan Baron and Itamar Zimerman and Lior Wolf},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=BGkqypmGvm}
}

@article{gu2022train,
  title={How to train your hippo: State space models with generalized orthogonal basis projections},
  author={Gu, Albert and Johnson, Isys and Timalsina, Aman and Rudra, Atri and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2206.12037},
  year={2022}
}

@inproceedings{siegelmann1992computational,
  title={On the computational power of neural nets},
  author={Siegelmann, Hava T and Sontag, Eduardo D},
  booktitle={Proceedings of the fifth annual workshop on Computational learning theory},
  pages={440--449},
  year={1992}
}

@inproceedings{cohen2016expressive,
  title={On the expressive power of deep learning: A tensor analysis},
  author={Cohen, Nadav and Sharir, Or and Shashua, Amnon},
  booktitle={Conference on learning theory},
  pages={698--728},
  year={2016},
  organization={PMLR}
}

@article{levine2020limits,
  title={Limits to depth efficiencies of self-attention},
  author={Levine, Yoav and Wies, Noam and Sharir, Or and Bata, Hofit and Shashua, Amnon},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={22640--22651},
  year={2020}
}

@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier}
}

@article{song2023expressibility,
  title={The Expressibility of Polynomial based Attention Scheme},
  author={Song, Zhao and Xu, Guangyi and Yin, Junze},
  journal={arXiv preprint arXiv:2310.20051},
  year={2023}
}

@article{kim2023polynomial,
  title={Polynomial-based Self-Attention for Table Representation learning},
  author={Kim, Jayoung and Shin, Yehjin and Park, Noseong},
  journal={arXiv preprint arXiv:2312.07753},
  year={2023}
}

@article{chrysos2021deep,
  title={Deep polynomial neural networks},
  author={Chrysos, Grigorios G and Moschoglou, Stylianos and Bouritsas, Giorgos and Deng, Jiankang and Panagakis, Yannis and Zafeiriou, Stefanos},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={8},
  pages={4021--4034},
  year={2021},
  publisher={IEEE}
}

@article{waleffe2024empirical,
  title={An Empirical Study of Mamba-based Language Models},
  author={Waleffe, Roger and Byeon, Wonmin and Riach, Duncan and Norick, Brandon and Korthikanti, Vijay and Dao, Tri and Gu, Albert and Hatamizadeh, Ali and Singh, Sudhakar and Narayanan, Deepak and others},
  journal={arXiv preprint arXiv:2406.07887},
  year={2024}
}

@article{kileel2019expressive,
  title={On the expressive power of deep polynomial neural networks},
  author={Kileel, Joe and Trager, Matthew and Bruna, Joan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{zuo2024falcon,
  title={Falcon mamba: The first competitive attention-free 7b language model},
  author={Zuo, Jingwei and Velikanov, Maksim and Rhaiem, Dhia Eddine and Chahed, Ilyas and Belkada, Younes and Kunsch, Guillaume and Hacid, Hakim},
  journal={arXiv preprint arXiv:2410.05355},
  year={2024}
}


@inproceedings{shen2024scaling,
  title={Scaling Laws for Linear Complexity Language Models},
  author={Shen, Xuyang and Li, Dong and Leng, Ruitao and Qin, Zhen and Sun, Weigao and Zhong, Yiran},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={16377--16426},
  year={2024}
}

@article{qin2023transnormerllm,
  title={Transnormerllm: A faster and better large language model with improved transnormer},
  author={Qin, Zhen and Li, Dong and Sun, Weigao and Sun, Weixuan and Shen, Xuyang and Han, Xiaodong and Wei, Yunshen and Lv, Baohong and Luo, Xiao and Qiao, Yu and others},
  year={2023}
}


@article{li2025minimax,
  title={Minimax-01: Scaling foundation models with lightning attention},
  author={Li, Aonian and Gong, Bangwei and Yang, Bo and Shan, Boji and Liu, Chang and Zhu, Cheng and Zhang, Chunhao and Guo, Congchao and Chen, Da and Li, Dong and others},
  journal={arXiv preprint arXiv:2501.08313},
  year={2025}
}

@article{zhang2024secure,
  title={Secure Transformer Inference Made Non-interactive},
  author={Zhang, Jiawen and Liu, Jian and Yang, Xinpeng and Wang, Yinghao and Chen, Kejia and Hou, Xiaoyang and Ren, Kui and Yang, Xiaohu},
  journal={Cryptology ePrint Archive},
  year={2024}
}

@article{sarrof2024expressive,
  title={The Expressive Capacity of State Space Models: A Formal Language Perspective},
  author={Sarrof, Yash and Veitsman, Yana and Hahn, Michael},
  journal={arXiv preprint arXiv:2405.17394},
  year={2024}
}