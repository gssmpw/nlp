\section{Related Work}
\paragraph{Emotional Dialog Systems} In order to create an agent or dialog system simulating the way that human beings express themselves, many studies was trying to find a way to make an emotional dialog system as emotion is the basic representation of human beings. \citet{zhou2018emotional} and \citet{2019Generating} proposed a way of \textbf{Emotion Embedding} to make the model "has" the emotion, where, models were forced to install a module to generate emotions. %Considering the model and the module as a whole, it still means that some specific parameters dominate the generation of emotions.

\paragraph{Instruct tuning based emotional control} In the domain of emotional control and generation, a significant body of work has focused on leveraging fine-tuning techniques for LLMs. \citet{chen2023soulchat} and \citet{chen2024cause} explored fine-tuning approaches to cultivate empathetic behavior in LLMs, specifically for applications within psychological counseling and emotional support domains. Furthermore, \citet{zheng2023buildingemotionalsupportchatbots} proposed a specialized dataset and demonstrated how fine-tuning the Llama model could be used to create emotionally intelligent chatbots designed for empathetic interaction. However, althrough instruct-tuning models have relatively good performance, they are often inflexible and struggle to adapt to a wide range of applications and model architectures\cite{ghosh2024closer}. Some methods depend on predefined emotion categories or assume a fixed set of emotional expressions, limiting their ability to adjust to real-world, dynamic situations \cite{liu2024emollms}.
% For emotion control and emotion generation, most work focuses on prompting and fine-tuning models. \cite{li2024enhancing} and \cite{li2023good} propsed ways to prompt the LLMs to generate emotional responses. \cite{chen2023soulchat} and \cite{chen2024cause} proposed ways to fine-tune the model in order to let the LLMs generate empathetic responses in  psychological counseling related fields. \cite{zheng2023buildingemotionalsupportchatbots} also proposed a dataset and fine-tune Llama to build a emotional chatbot.


\paragraph{In-context Vectors and Function Vectors} \citet{liu2024incontextvectorsmakingcontext} proposes the concept of In-context vector(ICV). ICV is added during forward propagation and used as a condensed contextual prompt. 
% It has the concepts of compactness and controllability. 
However, ICV only focuses on the last token position during extraction and lacks global significance. 
% At the same time, ICV is extracted by decoding the input-output pair \((x, y)\) through a large model. The extraction method focuses on the process of context learning, rather than using the large model itself to extract different language styles for the same task, which is different from the focus of our work. We pay more attention to the difference in activation values between different layers of the model itself when encountering the same problem and expressing different emotions, thereby extracting the emotion vector.
Similarly, \citet{todd2024functionvectorslargelanguage} proposes the Function Vector(FV). The FV they extracted pays more attention to the output of the attention head with the best average indirect effect, and then replaces the attention head at the corresponding position in the forward propagation to achieve improved performance of the model on specific tasks. The process of observing and extracting FV is relatively complicated. At the same time, since FV focuses on the process of causal analysis, it is difficult to apply to tasks such as emotions that require high generalization.\citet{ilharco2023editingmodelstaskarithmetic} also proposes a similar concept of task vector, but they need to fine-tune the model when extracting task vector, which is also a bit cumbersome compared to our method of directly using prompt to extract.

% \paragraph{Function Vectors} \cite{todd2024functionvectorslargelanguage} proposes the Function Vector(FV). The FV they extracted pays more attention to the output of the attention head with the best average indirect effect, and then replaces the attention head at the corresponding position in the forward propagation to achieve improved performance of the model on specific tasks. The process of observing and extracting FV is relatively complicated. At the same time, since FV focuses on the process of causal analysis, it is more suitable for tasks with clear directions, and it is difficult to apply to tasks such as emotions that require high generalization.\cite{ilharco2023editingmodelstaskarithmetic} also proposes a similar concept of task vector, but they need to fine-tune the model when extracting task vector, which is also a bit cumbersome compared to our method of directly using prompt to extract.