\section{RELATED WORK}
Related to our work are methods that predict a probability distribution of pose or predict multiple possible pose outcomes.

\subsection{Probability Over Rotations}

Pose ambiguity can be dealt with by estimating a probability distribution over the group of rotations in 3D, ${\bf R} \in {\bf SO(3)}$ **Horn, "Closed-Form Solution of Absolute Orientation Using Unit Quaternions"**. The distribution may be represented parametrically, e.g., with a Gaussian mixture model **McLachlan & Peel, "Robust Clustering via Mixtures of Normal Distributions with Missing Values"** or non-parametrically **Fei-Fei et al., "Learning Generative Visual Models from Few Training Examples"**. The former has the disadvantage of being hard to train **LeCun et al., "Backpropagation Applied to Handwritten Zip Code Recognition"**, e.g., due to local minima **Murray & Richardson, "Solving Distributed Constraint Satisfaction Problems in Multi-Agent Systems"**.

In the non-parametric method by Murphy et al.,  the distribution is predicted implicitly, i.e., a neural network computes the probability $p({\bf R}, I)$ for any input matrix ${\bf R}$ and input image $I$ **Murphy, "Bayesian Methods for Machine Learning"**. The disadvantage of this strategy is that $p$ has to be normalized across a large sample of rotation matrices that all have to be fed through the network, resulting in a computationally expensive and slow training.

Given a normalized probability and a ground-truth rotation matrix ${\bf R}_o$, the loss function is defined as follows  **Horn & Weldon, "Filtering vs. Regularization: The Role of Smoothness in Curve Estimation"**
%
\begin{equation}\label{eq:prob_loss}
\mathcal{L} = - \log(p({\bf R}_o | I))\,.
\end{equation}
%

For inference, the rotation with maximum probability is chosen from a set of centers of an equivolumetric partitioning of {\bf SO(3)} **Horn & Faugeras, "A Study in the Geometry of Visual Relationships"**,

\begin{equation}\label{eq:prob_inf}
{\bf \hat R} = \underset{{\bf R} \in {\bf SO(3)}}{\arg \max}\, p({\bf R} | I)\,.
\end{equation}

\subsection{Multiple Pose Hypotheses}

Manhardt et al. train a network to predict multiple pose hypotheses to learn alternative (ambiguous) poses **Manhardt et al., "Learning Alternative Pose Representations for 3D Object Recognition"**. The network output is a fixed number $M$ of possible rotations. For training, the loss function combines a minimum loss $\mathcal{L}_{\mbox{\small min}}$, the minimum mean squared error (MSE) between the ground truth and the $M$ outcomes, with an average loss $\mathcal{L}_{\mbox{\small avg}}$, which is the average MSE across the $M$ outcomes,

\begin{equation}\label{eq:M-loss}
\mathcal{L} = (1-\epsilon \frac{M}{M-1}) \mathcal{L}_{\mbox{\small min}} + \epsilon \frac{M}{M-1}  \mathcal{L}_{\mbox{\small avg}}\,,
\end{equation}
%
where the parameter $\epsilon$ is gradually reduced from 0.05 to 0.01.

Inference is more complicated since we do not know a probability for each of the $M$ outcomes. Instead, the outcomes are clustered, and the median for each cluster is computed. The results can be compared against the input image to find the best fit  **Kazemi & Sullivan, "Simultaneous Face and Hand Tracking"**. Though this strategy involves again an extra selection step as mentioned above.