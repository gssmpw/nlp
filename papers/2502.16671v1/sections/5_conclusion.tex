
\section{Conclusion}

Our \data\ benchmark highlights the crucial need for video LLMs to move beyond linguistic bias by integrating deeper non-verbal understanding for socially intelligent AI. By proposing mime understanding as a novel evaluation setting, we introduce a challenging yet valuable benchmark that requires models to interpret human gestures, emotional dynamics, and social interactions without explicit spoken dialogue. Our comprehensive analysis presents new research directions toward advancing the next generation of verbal and nonverbal socially intelligent foundation models.