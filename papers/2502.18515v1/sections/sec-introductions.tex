\section{Introduction}

Smart contracts, self-executing agreements with terms directly written into code, have emerged as a cornerstone of blockchain technology \cite{nath2014web,ray2023web3}. Their ability to automate transactions and eliminate intermediaries has led to widespread adoption in various sectors, including finance, supply chain management, and healthcare \cite{zheng2018blockchain,karanjai2021conditional,kaleem2021event}. However, the increasing complexity of smart contracts has given rise to a growing concern: security vulnerabilities\cite{vacca2021systematic}. These vulnerabilities, often stemming from coding errors or design flaws, can be exploited by malicious actors, leading to significant financial losses and damage to the reputation of blockchain projects. 

The financial implications of smart contract vulnerabilities are substantial. Reports indicate that cumulative losses from attacks against Ethereum smart contracts alone have exceeded USD 3.1 billion as of 2023~\cite{li2023smart}. In the DeFi space, an estimated \$9.04 billion has been stolen due to vulnerabilities~\cite{wronka2023financial}. Notable incidents like the DAO hack of 2016, resulting in a \$55 million loss~\cite{popper2016hacking}, and the Poly Network hack in 2021, where over \$600 million was stolen~\cite{polyhack}, underscore the critical need for robust security measures. 

Traditional security auditing methods, while essential, often face limitations in terms of accuracy and scalability. This has spurred the exploration of automated techniques for vulnerability detection \cite{10.1145/3238147.3238177,wang2020contractward}and repair, with Large Language Models (LLMs) emerging as a promising solution \cite{joshi2023repair}. LLMs, trained on vast datasets of code, can learn to understand and generate code that adheres to specific programming paradigms and best practices. However, most of the the tools available for smart contracts are very language-specific, mostly relying on Solidity as the language of choice, as well as often sometimes requiring compiled bytecode for scanning for other languages\cite{song2024empirical}.

Apart from Solidity~\cite{dannen2017solidity}, Move~\cite{blackshear2019move} has gained significant traction lately due to its strong focus on security. Its cutting-edge features,
including a custom data type for secure operations and robust access controls via Move modules, and unique memory safety features~\cite{blackshear2022move} have been
particularly noteworthy. Moreover, the Move Prover, a native security framework, provides an additional layer of
protection \cite{dill2022fast}. Notably, several prominent blockchain platforms, such as Starcoin~\cite{starcoin}, Aptos~\cite{devaptos}, and Sui~\cite{blackshear2024sui}, have already adopted Move.

However, despite its promising architecture, the real-world security performance of Move modules remains largely
untested. Unlike Solidity-based smart contracts, which have been extensively studied through empirical research
and surveys, there is a scarcity of research focused specifically on Move modules. Although some methodologies
have been proposed for identifying defects in Move modules or conducting formal verification \cite{keilty2022model,park2024securing}, and empirical analysis\cite{song2024empirical}, a significant knowledge gap persists. Specifically, large-scale investigations into the frequency of defects
in real-world Move modules and identifying potential vulnerabilities and repairing them are lacking, highlighting the need for further research in this area.

This paper proposes a novel framework for detecting and repairing vulnerabilities in smart contracts, focusing on the Solidity and Move languages from a programming language perspective. Our hypothesis relies on understanding the code and preventing known bad practices and unsafe code from being written before even compilation to prevent vulnerability. Our approach leverages the power of a multi-LLM agent system, combining the strengths of explanation and repair models. Our framework, \sln{}, leverages a multi-agent LLM framework to understand, critique, and repair code based on previously learned vulnerabilities as well as propose patches to repair them. 
%
By integrating an LLM specialized in code explanation with another focused on code repair, we aim to improve the accuracy and efficiency of the vulnerability remediation process.

We try to answer the following research questions in this paper, related to software engineering using AI agents and in the landscape of complex smart contract reasoning.
\begin{itemize}
    \item \textbf{RQ1:} Do the present state-of-the-art LLMs can explain a Smart Contract code correctly?
    \item \textbf{RQ2:} Can they detect and explain bad coding practices or specific mistakes leading to bugs or vulnerabilities in a smart contract code?
    \item \textbf{RQ3:} Can we encode programming language-specific knowledge to train the LLMs to understand unsafe and buggy codes in detail enough to repair them?
    \item \textbf{RQ4:} Does the proposed post-training framework be generalized to a larger set of pre-trained LLMs?
\end{itemize}

The key contributions of this paper are as follows:
\begin{enumerate}
    \item We introduce \sln{}, a multi-agent LLM code detection and repair framework that can analyze and repair codes based on coding concepts instead of just using the vast amount of codes for pre-training.
    \item We propose a method that can encompass programming language-specific paradigms for smart contracts, both for established language like Solidity and low resource language like Move, without the need for significantly large pertaining dataset. 
    \item We give a detailed recipe for how this can be scaled for other languages and give a comprehensive evaluation of \sln{}'s efficacy for other pre trained LLMs.
    \item We introduce, implement, and evaluate our framework on generalized pre trained LLMs to show the efficacy of our framework. We evaluate the performance of our framework and various LLMs on a diverse set of vulnerabilities in Solidity and Move smart contracts.
    \item We provide a detailed analysis of the results, identifying the strengths and weaknesses of different approaches and highlighting the challenges in automated code repair.
\end{enumerate}
