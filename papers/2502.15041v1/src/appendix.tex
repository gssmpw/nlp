\appendix
% \section*{Appendix}
% \addcontentsline{toc}{section}{Appendix}

\subsection{Node Embeddings} \label{app:a}

Our key requirement is to
    feed structural features into the neural networks directly. CapsGNN
    uses a GCN~\cite{Kipf:LCLR17} architecture to obtain node
    embeddings. The GCN is a widely used  architecture,
    which has the capability to work directly on graph data and captures its
    structural information. It is adapted from standard convolutional neural networks (CNN) to graphs.

     A graph with $N$ nodes is represented as a data structure
     containing nodes $V=\{v_1,\cdots,v_N\}$, node
     features $\textbf{X}\in R^{N\times d}$ (where $d$ is the dimension for the node embeddings), and edges
     between nodes encoded as an adjacency matrix $\textbf{A}\in \{0, 1\}^{N \times N}.$ This data structure is provided as input to a GCN with  $L$ convolution layers. At each layer $l$, the convolution operation is applied to each node and its neighbors, or more precisely to the neighbors that can be reached within $l$ steps. Then, the representation of each node at  layer $l$ is obtained by transforming the result of the convolution operation at that layer through an activation function. The  representation at the last layer $L$ is used to obtain the final  embeddings of the nodes in the graph. The dimensionality of the node embeddings is a hyper-parameter that needs to be fine-tuned.
    Formally, the node embeddings at layer $l+1$ are obtained as follows:
    % \begin{equation}
    %     H^{l+1} = f\left(\Tilde{\textbf{D}}^{-\frac{1}{2}}\Tilde{\textbf{A}}\Tilde{\textbf{D}}^{-\frac{1}{2}}\textbf{H}^{l}\textbf{W}^{l}\right)
    % \end{equation}

       \begin{equation}
        H^{l+1} = f\left({\textbf{D}}^{-\frac{1}{2}}{\textbf{A}}{\textbf{D}}^{-\frac{1}{2}}\textbf{H}^{l}\textbf{W}^{l}\right)
    \end{equation}
    \noindent
    where \(f\left(\cdot\right)\) denotes the activation function; \(H^{l}\) represents the node features at layer $l, H^{0} = \textbf{X}$; % \in {R}^{N \times d}$ , where \(N\) is the number of nodes in the graph and \(d\) is the dimension of the node embeddings;
    \(\textbf{W}^{l}\) is a trainable weight matrix at layer \(l\); \({\textbf{A}}=\textbf{A} + \textbf{I}\), where \(\textbf{I}\) is the identity matrix; % and \(\textbf{A}\) is the adjacency matrix of the graph;
    \(\textbf{D}\) is the diagonal node degree matrix of \({\textbf{A}}\). The normalized Laplacian matrix defined as \({\textbf{D}}^{-\frac{1}{2}}{\textbf{A}}{\textbf{D}}^{-\frac{1}{2}}\)  helps avoid exploding/vanishing gradients in this deep neural network model.


\subsection{Experimental Setup} \label{app:b}

\textit{Experimental Environment.} Traditional ML models are trained and tested on a Linux server equipped with 48 Intel Xeon(R) E5-2650 cores and 256GB of RAM. For each ML model, we apply a grid search to identify the optimal hyperparameters from a set of predefined candidates. Detailed hyperparameter configurations for each model on different datasets will be provided in the following section. The DL models are trained and tested on a Linux GPU server with 28 Intel(R) Xeon(R) Gold-6132 cores, 512GB of RAM, and a Tesla T4 GPU.

\textit{Evaluation Metrics.}  After running the trained model on a given test dataset, the prediction results can be statistically described in a \textit{confusion matrix} as shown in Table
\ref{tab:confusion_matrix}. To evaluate the models on the GooglePlay-Only dataset, we use three key metrics derived from the confusion matrix: precision, recall, and F1 score. The precision, recall, and F1 score reported in this dataset specifically refer to the \textbf{performance on malicious apps}. Precision (PR) is calculated as \(TP/(TP + FP)\), recall is calculated as \(TP/(TP + FN)\), and F1 score is calculated as \(2 * (Precision * Recall)/(Precision + Recall)\). For publicly available datasets, we follow the same evaluation metrics as used in the original works.


\begin{table}[h]
\caption{Confusion Matrix}
\begin{center}
\begin{tabular}{|c|c|c|c|}
  \hline
  & \multicolumn{3}{c|}{Predict class}\\
  \hline
  \multirow{5}{*}{\begin{tabular}{@{}c@{}}Actual \\ class \end{tabular}} &  & Malicious & Benign\\
  \cline{2-4}
  & \multirow{2}{*}{Malicious} & True Positive & False Negative  \\
  & & (TP) & (FN) \\
  \cline{2-4}
  & \multirow{2}{*}{Bengin} & False Positive & True Negative \\
  & & (FP) & (TN) \\
  \hline
\end{tabular}
\end{center}
\label{tab:confusion_matrix}
\end{table}



\subsection{Evaluation Metrics in Details} \label{app:c}

Figure~\ref{fig:evaluation_result} only shows
F1-scores from the ML approach and DL approach. More evaluation details including the
precision and recall can be found in
Table~\ref{tab:best_ml_result} and
Table~\ref{tab:capsgnn_result}. These tables also provide validation
F1-score during model train stage. For traditional ML models we only
show the best results among the four selected models; in our case Random
Forest (RF) gives the best result.


% \begin{table}[!htb]
\begin{table}[h]
    \caption{RF Results}
    \label{tab:best_ml_result}
    \centering
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{l*{4}c}
    \toprule[1.6pt]
    % \multirow{2}{*}{$_{Window}$ \space \textbackslash \space $^{EVAL.}$} & \multirow{2}{*}{Precision} & \multirow{2}{*}{Recall} & \multirow{2}{*}{F1} &  \multirow{2}{*}{Validation\_F1} \\
    % &  &  &  &  \\
    \multicolumn{1}{c|}{\multirow{3}{*}{$_{Window}$ \space \textbackslash \space $^{EVAL.}$}} & \multicolumn{3}{c|}{Test} & Validation \\
    \cline{2-5}
    \multicolumn{1}{c|}{} & \multicolumn{1}{c}{\multirow{2}{*}{Precision}} & \multicolumn{1}{c}{\multirow{2}{*}{Recall}} & \multicolumn{1}{c|}{\multirow{2}{*}{F1}} & \multirow{2}{*}{F1} \\
    \multicolumn{1}{c|}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c|}{} \\
    \midrule
     Window-3 & 1.000000 & 0.876667 & 0.934281 & 0.8244 \\
     Window-4 & 0.932624 & 0.876667 & 0.903780 & 0.8472 \\
     Window-5 & 0.927039 & 0.720000 & 0.810507 & 0.8575 \\
     Window-6 & 0.768456 & 0.763333 & 0.765886 & 0.8688 \\
     Window-7 & 0.776699 & 0.800000 & 0.788177 & 0.8739 \\
     Window-8 & 0.735043 & 0.860000 & 0.792627 & 0.8695 \\
     Window-9 & 0.748521 & 0.843333 & 0.793103 & 0.8826 \\
     Window-10 & 0.758017 & 0.866667 & 0.808709 & 0.8681 \\
     Window-11 & 0.813380 & 0.770000 & 0.791096 & 0.8696 \\
     Window-12 & 0.733333 & 0.806667 & 0.768254 & 0.8641 \\
     Window-13 & 0.695167 & 0.623333 & 0.657293 & 0.8454 \\
     Window-14 & 0.700272 & 0.856667 & 0.770615 & 0.8490 \\
     Window-15 & 0.639344 & 0.650000 & 0.644628 & 0.8401 \\
     Window-16 & 0.774603 & 0.813333 & 0.793496 & 0.8264 \\
     Window-17 & 0.460317 & 0.676667 & 0.547908 & 0.8304 \\
     Window-18 & 0.575000 & 0.153333 & 0.242105 & 0.7909 \\
     Window-19 & 0.370370 & 0.100000 & 0.157480 & 0.7669 \\
     Window-20 & 0.994764 & 0.633333 & 0.773931 & 0.7874 \\
     Window-21 & 0.965665 & 0.750000 & 0.844278 & 0.7881 \\
     Window-22 & 0.351211 & 0.735507 & 0.475410 & 0.7684\\
    \bottomrule[1.6pt]
    \end{tabular}
    }
  \end{table}

\begin{table}[h]
    \caption{CapsGNN Results}
    \label{tab:capsgnn_result}
    \centering
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{l*{4}c}
    \toprule[1.6pt]
    % \multirow{2}{*}{$_{Window}$ \space \textbackslash \space $^{EVAL.}$} & \multirow{2}{*}{Precision} & \multirow{2}{*}{Recall} & \multirow{2}{*}{F1} &  \multirow{2}{*}{Validation\_F1} \\
    % &  &  &  &  \\
    \multicolumn{1}{c|}{\multirow{3}{*}{$_{Window}$ \space \textbackslash \space $^{EVAL.}$}} & \multicolumn{3}{c|}{Test} & Validation \\
    \cline{2-5}
    \multicolumn{1}{c|}{} & \multicolumn{1}{c}{\multirow{2}{*}{Precision}} & \multicolumn{1}{c}{\multirow{2}{*}{Recall}} & \multicolumn{1}{c|}{\multirow{2}{*}{F1}} & \multirow{2}{*}{F1} \\
    \multicolumn{1}{c|}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c|}{} \\
    \midrule
     Window-3 & 0.985185 & 0.886667 & 0.933333 & 0.9242 \\
     Window-4 & 0.914676 & 0.893333 & 0.903879 & 0.9364 \\
     Window-5 & 0.907950 & 0.723333 & 0.805195 & 0.8828 \\
     Window-6 & 0.770833 & 0.740000 & 0.755102 & 0.8025 \\
     Window-7 & 0.902439 & 0.740000 & 0.813187 & 0.7830 \\
     Window-8 & 0.932584 & 0.830000 & 0.878307 & 0.8510 \\
     Window-9 & 0.987013 & 0.760000 & 0.858757 & 0.8989 \\
     Window-10 & 0.975510 & 0.796667 & 0.877064 & 0.9037 \\
     Window-11 & 0.897338 & 0.786667 & 0.838366 & 0.8824 \\
     Window-12 & 0.912863 & 0.733333 & 0.813309 & 0.8205 \\
     Window-13 & 0.865385 & 0.600000 & 0.708661 & 0.8564 \\
     Window-14 & 0.835664 & 0.796667 & 0.815700 & 0.7667 \\
     Window-15 & 0.830435 & 0.638796 & 0.722117 & 0.8539 \\
     Window-16 & 0.845324 & 0.783333 & 0.813149 & 0.8000 \\
     Window-17 & 0.584507 & 0.553333 & 0.568493 & 0.8761 \\
     Window-18 & 0.534118 & 0.772109 & 0.631433 & 0.5673 \\
     Window-19 & 0.768456 & 0.776271 & 0.772344 & 0.6476 \\
     Window-20 & 0.843220 & 0.663333 & 0.742537 & 0.8488 \\
     Window-21 & 0.889313 & 0.779264 & 0.830660 & 0.7782 \\
     Window-22 & 0.866667 & 0.616788 & 0.720682 & 0.8552 \\
    \bottomrule[1.6pt]
    \end{tabular}
    }
  \end{table}

  
  % \begin{table}[h]
  %   \caption{RF Results after removing "problematic" aps}
  %   \label{tab:ml_result_2020}
  %   \centering
  %   \resizebox{\columnwidth}{!}{
  %   \begin{tabular}{l*{4}c}
  %   \toprule[1.6pt]
  %   % \multirow{2}{*}{$_{Window}$ \space \textbackslash \space $^{EVAL.}$} & \multirow{2}{*}{Precision} & \multirow{2}{*}{Recall} & \multirow{2}{*}{F1} &  \multirow{2}{*}{Validation\_F1} \\
  %   % &  &  &  &  \\
  %   % \multicolumn{1}{c|}{\multirow{3}{*}{$_{Window}$ \space \textbackslash \space $^{EVAL.}$}} & \multicolumn{3}{c|}{Test} & Validation \\
  %   % \cline{2-5}
  %   % \multicolumn{1}{c|}{} & \multicolumn{1}{c}{\multirow{2}{*}{Precision}} & \multicolumn{1}{c}{\multirow{2}{*}{Recall}} & \multicolumn{1}{c|}{\multirow{2}{*}{F1}} & \multirow{2}{*}{F1} \\
  %   % \multicolumn{1}{c|}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c|}{} \\
  %   % \midrule
  %   ... & ... & ... & ... & ... \\ 
  %   Window-17 & 0.817460 & 0.686667 & 0.746377 & 0.8435 \\
  %   Window-18 & 0.750000 & 0.531250 & 0.621951 & 0.8150 \\
  %   Window-19 & 0.898182 & 0.823333 & 0.859130 & 0.8550 \\
  %   %... & ... & ... & ... & ... \\
  %   \bottomrule[1.6pt]
  %   \end{tabular}
  %   }
  % \end{table}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
