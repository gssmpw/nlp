\begin{abstract}
Large language models'
significant advances in capabilities
are accompanied by significant increases in inference costs.
\emph{Model routing} is a simple technique for reducing inference cost,
wherein one maintains a pool of candidate LLMs,
and learns to route each prompt to the smallest feasible LLM.
Existing works focus on learning a router for a \emph{fixed} pool of
LLMs.
In this paper, we consider the problem of \emph{dynamic} routing, 
where \emph{new, previously unobserved} LLMs are available at test time.
We propose a new approach to this problem that relies on representing each LLM as a \emph{feature vector}, derived based on predictions on a set of representative prompts.
Based on this, we detail two effective strategies, relying on \emph{cluster-based} routing and a \emph{learned cluster map} respectively.
We prove that these strategies are estimates of a theoretically optimal routing rule, and provide an excess risk bound to quantify their errors.
Experiments on a range of public benchmarks show the effectiveness of the proposed strategies in routing amongst more than 30 unseen LLMs.
\end{abstract}


