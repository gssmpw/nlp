\textbf{Model fusion}
Model routing may be contrast to model \emph{fusion}, 
where the primary goal is to leverage multiple models to improve \emph{quality}, 
potentially at the expense of \emph{efficiency}.
This can involve
invoking multiple models prior to generating an output~\citep{Ravaut:2022,Jiang:2023,Guha:2024,Wang:2024,Hu:2024b},
or producing a single fused model~\citep{Singh:2020}.


\textbf{Mixture of experts (MoE).}\
Classically, MoE models focused on learning parameters for independent models, along with a suitable routing rule~\citep{Jacobs:1991,Jordan:1993}.
These have proven an plausible alternative to model specialisation~\citep{Jang:2023,Douillard:2024}.
Such models are typically of the same size; thus, cost considerations do not factor into the router design.
More recently, MoEs have focussed on \emph{sub}-models within a single larger model, e.g., a Transformer~\citep{Fedus:2022,Zhou:2022}.


\textbf{Early-exiting.}\
Early-exiting enables adaptive computation within a \emph{single} neural model,
by allowing computation to terminate at some intermediate layer~\citep{TeeMcDKun2016,ScaScaBac2020,Zhou:2020}. 
Often, the termination decision is based on a simple model confidence (akin to simple model cascading),
but learning approaches have also been considered~\citep{XinNogYu2020,SchFisGup2022}.


\textbf{Speculative decoding.}\
Speculative decoding is another technique that leverages two models to speed up inference, by using the smaller model to draft tokens and having the larger model verify them~\citep{Stern:2018,chen2023accelerating,leviathan2023fast,Tran-Thien_2023,Sun:2023,Zhou:2024,Cai:2024b,Li:2024,Li:2024b}.
Recent
works have studied approaches to combine
speculative decoding
with
early-exits~\citep{Elhoushi_2024} 
and
cascades~\citep{Narasimhan:2024}.

\setlength{\tabcolsep}{0.2em} %
\renewcommand{\arraystretch}{1.2}  %

\begin{table}[!t]
    \begin{centering}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{>{\raggedright}p{3cm}>{\centering}m{1.5cm}>{\centering}m{4cm}>{\centering}m{1.5cm}>{\centering}m{2cm}>{\centering}m{1.5cm}>{\centering}m{3cm}}
    \toprule 
    Routing approach & Candidate LLMs & Training signals & Works without task labels & Adaptive computation & Unseen models at test time & Reference\tabularnewline
    \midrule
    Smoothie  & Any & Query embeddings. No label required. & \boldcheck &  \crossmark &  \crossmark & \citet{GuhCheCho2024}\tabularnewline
    Cascading with token-level features  & 2 & Pointwise evaluation. & \boldcheck & \boldcheck &  \crossmark & \citet{GupNarJit2024}\tabularnewline
    Summon the titans  & 2 & Annotations from a teacher model. & \boldcheck & \boldcheck  &  \crossmark & \citet{Rawat:2021} \tabularnewline
    RouteLLM  & 2 & Pairwise comparison metrics. & \boldcheck & \boldcheck  &  \crossmark & \citet{OngAlmWu2024}\tabularnewline
    K-NN router & Any & Pointwise evaluation, query embeddings.  & \boldcheck & \boldcheck  &  \crossmark & \citet{HuBieLi2024}\tabularnewline
    GraphRouter & Any &  Task information &  \crossmark & \boldcheck  & \boldcheck  & \citet{Feng:2024}\tabularnewline
    \midrule 
    Our proposal & Any & Pointwise evaluation, query clusters & \boldcheck & \boldcheck  & \boldcheck & This work\tabularnewline
    \bottomrule
    \end{tabular}
    }
    \par\end{centering}
    \caption{A qualitative comparison of recently proposed query routing approaches.
    Adaptive computation refers to the ability to trade quality for a
    reduced inference cost. 
    }
\end{table}
