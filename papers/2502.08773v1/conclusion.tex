We present principled strategies for routing amongst multiple unseen test-time LLMs,
without having to retrain the router. 
Central to our approach is a \emph{prediction correctness} LLM representation,
with accompanying cluster-based routing strategies.
Our proposal is computationally efficient, and able to deliver a good quality-cost trade-off as shown in experiments involving $>30$ unseen LLMs on EmbedLLM.
An interesting future direction is to 
enhance routing robustness to query distribution shifts. 
Such a routing system  will further reduce the need for frequent router retraining.

