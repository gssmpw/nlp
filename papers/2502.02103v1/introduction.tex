\section{Introduction}
\label{sec:introduction}

Neural networks have transformed machine learning through their ability to learn complex, hierarchical representations, traditionally interpreted through intensity-based representations where larger activation values signify stronger feature presence. This interpretation, originating from the McCulloch-Pitts neuron \cite{mcculloch1943logical} and Rosenblatt's perceptron \cite{rosenblatt1958perceptron}, underlies modern deep learning \cite{lecun2015deep}. However, our theoretical understanding of neural networks' internal mechanisms remains limited \cite{lipton2018mythos, montavon2018methods}, particularly regarding how they represent and process features.

In our prior work \cite{oursland2024interpreting}, we argued that networks may naturally learn distance-based representations, where smaller activations indicate proximity to learned prototypes. This reinterpretation challenges the traditional intensity-based paradigm and provides a statistical foundation rooted in principles like the Mahalanobis distance \cite{mahalanobis1936generalized, mclachlan2019mahalanobis}. Empirical evidence supports this theory. In our work \cite{oursland2024neural}, we demonstrated that distance-based metrics play a crucial role in how networks learn and utilize features, suggesting the need to rethink the fundamental nature of representations.

\textbf{Core Questions.} This paper investigates: (1) whether neural networks naturally prefer distance-based or intensity-based representations, (2) how architectural choices shape these representational biases, and (3) what geometric and statistical principles underlie these preferences.

\textbf{Contributions.} We examine neural network behavior through distance and intensity representations via: (1) A theoretical framework formalizing the distinction between these representations, (2) empirical analysis of six architectural variants, revealing mechanisms behind dead node creation and geometric performance limitations, and (3) introduction of OffsetL2, a novel architecture validating our framework through strong, stable performance.

The remainder of this paper reviews related work (Section \ref{sec:related_work}), establishes theoretical foundations (Section \ref{sec:background}), presents our experimental design (Section \ref{sec:exp_design}) and findings (Section \ref{sec:results}), and discusses implications (Section \ref{sec:discussion}).