In this section, we discuss extensions to the $\pname$ protocol and implications of our design decisions.




\parhead{Full Serializability}
\emph{Full} serializability requires that no local action can interleave between two CRT actions within a rollup batch, in addition to the relative ordering already required by \emph{weak} serializability. We can easily modify the $\gsc$ contract to support full serializability as follows. If $\action$ is ready to declare a session as inactive, then, before returning, it triggers a new $\textproc{finishSession}$ on the other $\gsc$. This ensures that both GSCs mark the current session as inactive, which was not the case in \cref{alg:gsc-single-trigger}. Further, we require that \emph{all} rollup transactions (including local ones) use $\startsession$ as their entrypoint. Then $\startsession$ can revert any transaction that attempts to execute during an ongoing CRT session. 


Unlike L1 protocols with fine-grained state locks~\cite{fal-tccsci-23}, our approach locks the entire rollup state during the CRT session, simplifying implementation. Transactions in the batch can still access the full state outside the CRT session. However, this requires routing all transactions through the $\gsc$, making it not backwards-compatible with existing applications.




\parhead{Distinct Executors}
For ease of exposition, we have described $\pname$ under a shared Executor operating both rollups. However, $\pname$ can easily be adapted to support \emph{distinct}, possibly \emph{distrusting} Executors $E_1$ and $E_2$. Upon listening to a trigger call emitted by $\gsc_1$, $E_1$ sends the triggered action information to $E_2$, who proceeds to execute a matching $\action$. $E_1$ can set proper timeouts so that he does not wait an indefinite amount of time for $E_2$ (and vice-versa). Since $E_1$ and $E_2$ need to communicate back and forth to execute CRTs, the network latency becomes the bottleneck during off-chain execution. Nevertheless, this drawback is not specific to $\pname$ but inherent to the distinct Executors setup.




\parhead{Implications on rollup finality}
Recall from \cref{sec:liveness-chain-crt} that the end-to-end latency of $\pname$ is $4$ rounds. In Ethereum, one round lasts $13$ minutes, so rollups using $\pname$ achieve finality after $4 \times 13 = 52$ minutes; this might seem much longer than the single round ($13$ minutes) required by existing zk-rollups for finality. However, most zk-rollups currently submit new state roots to L1 at intervals in the order of \emph{hours}, since SNARK proof generation is the bottleneck. Thus, both the $4\times$ latency and the $\vsm{}$ state locking introduced by $\pname$ do not affect existing rollups' finality and throughput, since the $\vsm{}$s were already not utilized during that time for any new state updates. Similarly, the increased proving time incurred by our SNARK-based implementation is also dominated by the SNARK validity proof generation time required by existing zk-rollups.

Note that the discussion above is about L1 \emph{finality}, which does not place any trust on the Executor. Today, applications may also be interested in instant confirmation of rollup transactions~\cite{zksync-instant-confirmations}. Since the Executor needs to be trusted for such faster confirmations, $\pname$ preserves the underlying zk-rollups' instant confirmation guarantees.






