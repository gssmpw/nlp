\section{Feature Matching}
\label{sec:Hybrid-Feature-Tracking}
Traditional VIO feature matching methods are typically classified into two categories: optical flow-based \cite{qin-tro-2018_VINS-Mono,geneva2020openvins} and descriptor matching-based \cite{leutenegger-ijrr-2015-OKVIS,campos2021orb-slam3}. Optical flow-based methods, such as KLT\cite{Lucas_Kanade_1981_KLT,opencv_library}, often exhibit continuous drift, which limits VIO accuracy. Conversely, descriptor-based methods may suffer from a lack of long-term tracking capability. To address these limitations, the community has recently proposed some joint tracking solutions, such as \cite{zong2017improved,zhong2023improved,bang2017camera}, etc. However, some\cite{zong2017improved,zhong2023improved} of these methods simply combine two features by just using feature extraction points of ORB for optical flow tracking, or like\cite{bang2017camera}, just running two matching methods separately and then selecting the better one. These algorithms could not fully leverage the advantages of both methods, which limits the upper bound of feature matching. So we introduce a novel hybrid feature matching scheme which tightly integrates optical flow and descriptor methods. As illustrated in \cref{fig:Feature—Tracking}, features can be tracked using both optical flow and descriptor, aiming to achieve a balanced trade-off between track length and accuracy.

%Traditional methods for feature matching in Visual-Inertial Odometry (VIO) can be broadly categorized into two types: optical flow-based approaches and descriptor matching-based methods. Optical flow-based methods, such as KLT (Lucas-Kanade Tracker), are known for their tendency to suffer from continuous drift, thus limiting the overall accuracy of VIO systems (Qin et al., 2018; Geneva et al., 2020). On the other hand, descriptor-based methods, like ORB-SLAM3 (Leutenegger et al., 2015; Campos et al., 2021), may face challenges in maintaining long-term tracking capabilities.


%To mitigate these shortcomings, recent efforts in the research community have explored hybrid solutions that combine both optical flow and descriptor matching techniques (Zong et al., 2017; Zhong et al., 2023; Bang et al., 2017). However, some of these hybrid methods simply concatenate features or independently apply different matching algorithms without fully leveraging the strengths of each method. This approach often limits the potential upper bound of feature matching performance.

%In response, this paper introduces a novel hybrid feature matching scheme that integrates optical flow and descriptor methods more closely. This integrated approach, illustrated in Figure 1, aims to achieve a balanced trade-off between track length and accuracy in feature tracking.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{pictures/Feature_Tracking.drawio.pdf}
    \caption{Hybrid Feature Matching Approach}
    \label{fig:Feature—Tracking}
\end{figure}
Specifically, as outlined in \cref{alg:feature-matching}, for each frame of image, we first perform feature detection and description. Subsequently, during the feature matching process, tracks with established triangulation can be projected onto the current frame as priors for matching. The initial pose of the current frame is derived from IMU propagation. Leveraging these priors, descriptor-based matching is performed, followed by a ratio test to validate good matches. This is similar to ORB-SLAM\cite{murartal-tro-2015-ORB-SLAM}, with the distinction that we only utilize feature tracks within the current sliding window.

For feature tracks unable to be triangulated or have failed matches through projection, they transition to the second stage of matching, utilizing either 2D priors or optical flow priors. All these features will first undergo optical flow \cite{Lucas_Kanade_1981_KLT} from the previous frame to the current frame. These matches serve as priors for descriptor matching. Here we use ORB features for matching. With optical flow priors, ORB matching only requires KNN matching within a very small window (set to a radius of 10 pixels) and undergoes a ratio test (threshold set to 0.7). ORB points that fail to match still utilize the optical flow matching result for the current frame, with the descriptor retained, thus preventing interruptions in feature tracking due to descriptor matching failures and ensuring longer track lengths. If the number of tracks in the current frame falls below a certain threshold (set to 150), new tracks will be generated, awaiting subsequent feature matching.

It is important to note that while our method employs ORB as an example, it can be substituted with any descriptor-based method.
In \cref{sec:Experimental_Results}, we quantified the effectiveness of this matching strategy on public datasets, including matching accuracy indicators and VIO trajectory accuracy indicators.

\begin{algorithm}[h]
\DontPrintSemicolon
\SetKwInput{KwInput}{Input}                % Set the Input
\SetKwInput{KwOutput}{Output}              % Set the Output
\KwInput{Images, 3D Points, Poses}
\KwOutput{Matched Features}

\SetKwFunction{FMain}{}    % 先定义 \FMain
\SetKwProg{Fn}{Function}{:}{\KwRet}        % 定义函数风格
\SetKwProg{FnMain}{HybMatching}{:}{\KwRet} % 定义主函数风格
\FnMain{\FMain}{
    
    \tcc{Max 150 kpts per-frame, pyramid level 1}
    
    ORBFeatureDetect();
    
    ComputeORBDescriptor();
    
    \tcc{Descriptor matching by prior}
    
    \For{feature track $f_k$}{
        \If{$f_k$ IsTriangulated}{
            \tcc{Similar with \cite{murartal-tro-2015-ORB-SLAM}}  
            MatchWith3DProjection(); 
        }
        \Else{
            MatchWith2DPrior();
        }
    }
    Ransac(); \tcc{Remove outliers}
    \If{count(track) < 150}{
        AddNewTracks();
    }
    \KwRet{all\_matches} % 明确返回值
}
\Fn{\FMain MatchWith2DPrior{}}{
    
    \tcc{OpticalFlow as prior, from previous frame to current}
    OpticalFlow();
    
    \tcc{Search in a 10x10 pixels window by OpticalFlow's prior}
    SearchInArea(10);
    
    RatioTest(0.7);
    
    \tcc{When match failed, add OpticalFlow's result as supplement}
    AddFlowToMatches();
    
    Ransac();
}
\caption{Hybrid Feature Matching}
\label{alg:feature-matching}
\end{algorithm}