\section{State Initialization}
\label{sec:Initialization}
\begin{figure*}[h]
 \centering % avoid the use of \begin{center}...\end{center} and use \centering instead (more compact)
 \includegraphics[width=\textwidth]{pictures/Visual_Gyro_SFM.drawio.pdf}
 \caption{Pipeline of Visual Gyroscope tightly coupled SFM (VG-SFM)}
 \label{fig:VG-SFM}
\end{figure*}


% \begin{figure*}[htbp]
%     \centering
%     \begin{tikzpicture}[node distance=2cm, >=latex,font=\large]
%         % Nodes
%         \node (preprocess) [process, xshift=1.4cm] {Preprocess};
%         \node (images) [below of=imagebox, yshift=0.5cm] {Images}; % 放置在矩形框内
%         \node (feature) [right of=images, xshift=1cm, align=center] {Feature\\Matching};
%         \node (gyroscope) [below of=images, yshift=0.5cm] {Gyroscope};
%         \node (integration) [right of=gyroscope, xshift=1cm] {Integration};
%         \node (twoview) [process, right of=preprocess, xshift=4.6cm] {Two View Reconstruction};
%         \node (twopoint) [below of=twoview, yshift=-0.2cm, align=center] {2-Point Pose Estimation,\\Points Triangulation};
%         \node (nouse) [left of=twopoint, xshift=-1cm] {};
%         \node (pnp) [process, right of=twoview, xshift=2.3cm] {PnP};
%         \node (vgpnp) [below of=pnp, yshift=-0.2cm] {VG-PnP};
%         \node (ba) [process, right of=pnp, xshift=1.2cm] {BA};
%         \node (vgba) [below of=ba, yshift=-0.2cm] {VG-BA};

%         \node[fit=(images), draw, inner sep=0.2cm] (imagesbox)  at (images){};
%         \node[fit=(feature), draw, inner sep=0.2cm] (featurebox) at (feature) {};
%         \node[fit=(integration), draw, inner sep=0.2cm] (integrationbox) at (integration) {};
%         \node[fit=(gyroscope), draw, inner sep=0.2cm] (gyroscopebox) at (gyroscope) {};
%         \node[fit=(twopoint), draw, inner sep=0.2cm] (twopointbox) at (twopoint) {};
%         \node[fit=(vgpnp), draw, inner sep=0.2cm] (vgpnpbox) at (vgpnp) {};
%         \node[fit=(vgba), draw, inner sep=0.2cm] (vgbabox) at (vgba) {};
        
%         % Arrows
%         \draw [->] (imagesbox) -- (featurebox);
%         \draw [->] (gyroscopebox) -- (integrationbox);
%         \draw [->] (twopointbox) -- (vgpnpbox);
%         \draw [->] (vgpnpbox) -- (vgbabox);
%         \draw [arrow] (featurebox) -| ($(nouse.west)!0.5!(nouse.south west)$);
%         \draw [arrow] (integrationbox) -| ($(nouse.west)!0.5!(nouse.south west)$);
%         \draw [->] ($(nouse.west)!0.5!(nouse.south west)$) -- (twopointbox);

%          % Vertical dashed line
%         \draw[dashed] ($(preprocess.east) + (3.0cm,0)$) -- ($(preprocess.east) + (3.0cm,-4cm)$);
%         \draw[dashed] ($(twoview.east) + (0.8cm,0)$) -- ($(twoview.east) + (0.8cm,-4cm)$);
%         \draw[dashed] ($(pnp.east) + (1.1cm,0)$) -- ($(pnp.east) + (1.1cm,-4cm)$);

%     \end{tikzpicture}
%     \caption{Pipeline of Visual Gyroscope tightly coupled SfM (VG-SfM)}
%  \label{fig:VG-SFM}
% \end{figure*}

\begin{figure}[h]
 \centering % avoid the use of \begin{center}...\end{center} and use \centering instead (more compact)
 \includegraphics[width=\columnwidth]{pictures/VG-BA-Factor-Graph.drawio.pdf}
 \caption{Factor Graph of VG-BA}
 \label{fig:VG-BA-F}
\end{figure}

A high-quality initialization can significantly accelerate the convergence speed of the filter. We employ two initialization methods depending on the motion states, namely static and motion.
To determine the current state, we consider the average displacement of sparse features and the standard deviation of acceleration and angular velocity. If both the average displacement and standard deviation are below specific thresholds, we perform static initialization similar to OpenVINS \cite{geneva2020openvins}; otherwise, we proceed with motion initialization.

\subsection{Motion Initialization}
We design a new VI initialization method to robustly handle the fast VIO motion initialization problem. In this case, we need to solve the problem based on very few observations, typically using only 4 image frames and related IMU data.
Given the limited number of image observations, traditional SfM solutions become highly fragile and prone to erroneous or failed solutions.

We revisit the problem of visual IMU initialization. There are a large number of parameters that need to be estimated, and visual observations alone are not sufficient. Although the IMU is noisy, the gyroscope can often provide relatively accurate initial orientation, which is irrelevant to the scene. This is also helpful for visual SfM. However, the state of the accelerometer is very difficult to estimate. So we need to wait for some parameters to be stable, and then initialize the accelerometer-related parameters, such as scale, velocity and gravity. Based on these studies, we designed a new pipeline of VI initialization. As shown in \cref{fig:teaser}, the core idea is to first tightly couple with the gyroscope and then loosely couple with the accelerometer, and finally optimize all parameters together. 
The pipeline consists of VG-SfM, VA-Align and VI-BA.  Especially for VG-SfM, rotation from the gyroscope's integration is tightly used in the whole process of SfM, which significantly increases the robustness and accuracy of SfM.
\subsection{VG-SfM}
VG-SfM is a tightly coupled method that integrates visual and gyroscope data. In scenarios with short time intervals and minimal parallax, visual measurements may lack stability. Conversely, the gyroscope provides high-precision rotation information, even in the absence of correct bias. Leveraging this, we utilize the rotation information obtained from gyroscope integration as a vital prior and constraint for visual SfM, resulting in a more stable SfM solution. Refer to \cref{fig:VG-SFM} for an illustration.
\begin{enumerate}
    \item \textbf{Preprocess}: We use visual and inertial data for system initialization. Upon capturing images, we initially perform feature tracking with \cite{Lucas_Kanade_1981_KLT} . Subsequently, we integrate the angular velocity data from the gyroscope \cite{forster2017manifold-preintergration}.  Before two-view reconstruction, we select two frames with the maximal parallax as keyframes from the initial frames.
    \item \textbf{Two View Reconstruction}: Traditional visual SfM requires 5-point correspondences \cite{fivepoint2004nister} to estimate relative pose, which is accurate in most case but can be unreliable in scenarios with limited parallax. However, in the context of VIO, we can obtain initial rotation information from the gyroscope. Despite potential noise and long-term drift in gyroscope data, it remains accurate and robust over short time intervals. Therefore, we opt to directly utilize gyroscope rotation instead of relying solely on visual cues. With the rotation known, the translation parameters to be estimated reduce to just 2 DoF (excluding scale), rendering the problem linear and amenable to robust solutions. This simplification facilitates the identification of inliers and determination of optimal parameters using \textbf{2-Point-RANSAC} \cite{Kneip_Chli_Siegwart_2010}. Subsequently, initial pose computation enables triangulation of 3D points, facilitating solution of other frames based on these points.
    \item \textbf{VG-PnP}: Given a sufficient number of 3D points and corresponding 2D features, we employ Perspective-n-Point (PnP) to determine the pose of each frame. Also, we utilize gyroscope's rotation measurements to improve the robustness of visual PnP, a method we term VG-PnP, which tightly integrates visual and gyroscope data. The problem can be formulated as follows:
    \begin{equation}\label{eq:vg_pnp}
        {\arg\min_{\textbf{R}_k,\textbf{t}_k}} ( {C_I}_{k}(\bm{\gamma}) + {C_V}_{k}),
    \end{equation}
where ${C_I}_{k}(\bm{\gamma})$ represents the pre-integration term of IMU for frame $k$, utilizing gyroscope measurements to constrain rotation. ${C_V}_k$ is the visual term from image frame $k$, using 3D-2D measurements to constrain 6DoF pose. For frames within the sliding window excluding the two initialized frames, we consider the minor camera motion during the initialization process. We use the position of the initialized neighboring frame as the initial position and accumulate the pre-integrated rotation from the initialized neighboring frame to the current frame as the initial rotation. Subsequently, we apply the Levenberg-Marquardt method to minimize \cref{eq:vg_pnp}, thereby obtaining the pose for each uninitialized frame.

        \item \textbf{VG-BA}: Upon calculating the initial values of 3D points and camera poses, we proceed to perform VG-BA, , a bundle adjustment tightly coupling visual and gyroscope data. The initial value of gyroscope's bias is set to zero. VG-BA comprises two components, where both residuals are combined and optimized to minimize the total cost, formulated as:
          \begin{equation}
      \label{VG-BA}
      \begin{aligned}
{\arg\min_{\textbf{X}_l,\textbf{R}_k,\textbf{t}_k,\textbf{b}_g}} ( C_I(\bm{\gamma}) + C_V),
      \end{aligned}
    \end{equation}
    where $C_I(\gamma)$ is defined in \cref{eq:gyro_cost}, and $C_V$ is defined in \cref{eq:cost_camera}. $\textbf{X}_l, \textbf{R}_k, \textbf{t}_k, \textbf{b}_g$ represent the states to be estimated. $\textbf{X}_l$ denotes the $l^{th}$ 3D point, $\textbf{R}_k$ and $\textbf{t}_k$ denote the pose of frame $k$, and $\textbf{b}_g$ represents the bias of gyroscope. It is important to note that the pose of the first frame needs to be fixed. Further details of the factor graph can be found in \cref{fig:VG-BA-F}.
    After VG-SfM, we obtain the pose of each frame. In order to align them with IMU data, we transform them into body frame. 
 \end{enumerate}
    \subsection{VA-Align} Following a similar approach to \cite{qin-tro-2018_VINS-Mono}, we initially define the initial state vector for visual inertial alignment as:
    
  \begin{equation} \label{eq:init_state}
    \textbf{X}_{init} = [{\textbf{v}}_{I_0}, ... , {\textbf{v}}_{I_n}, s, \textbf{g}^{c_0}],
  \end{equation}
  where ${\textbf{v}}_{I_k}$ represents the velocity in the body frame $k$, $s$ is the scale factor between visual SfM and IMU, and $\textbf{g}^{c_0}$ is the gravity vector in frame $c_0$.  
    By defining the state as in \cref{eq:init_state}, we can rewrite the \cref{eq:preintergration} as:
        \begin{equation}
      \label{eq:VI-Align-integration}
      \begin{aligned}
        \bm{\alpha}^{I_k}_{I_{k+1}} &= \textbf{R}^{I_k}_{c_0}(s(\textbf{p}^{c_0}_{I_{k+1}} - \textbf{p}^{c_0}_{I_{k}})) + \frac{1}{2}\bm{g}^{c_0}\Delta t_k^2 - \textbf{R}^{c_0}_{I_k}\textbf{v}_{I_k}\Delta t_k)\\
        \bm{\beta}^{I_k}_{I_{k+1}} &= {\textbf{R}^{I_k}_{c_0}}({\textbf{R}^{c_0}_{I_{k+1}}}\textbf{v}_{I_{k+1}} 
        + \textbf{g}^{c_0}{\Delta}{t_k} 
        - {\textbf{R}^{c_0}_{I_k}}v_{I_k}).
      \end{aligned}
    \end{equation}
   We combine \cref{eq:VI-Align-integration} and \cref{eq:preintergration} and solve for the initial state $X_{init}$, following the methodology outlined in \cite{qin-tro-2018_VINS-Mono}.
   %TODO BA function
    \subsection{VI-BA} Once all the initial states are estimated, we perform an overall bundle adjustment to further improve the accuracy. Unlike traditional VI-BA methods with fixed weights, we have developed a scheme to adjust the weights of the visual and IMU term based on disparity. It has been observed that when the disparity is small, the residuals of $C_{total}$  are primarily influenced by $C_I$ alone, while the the degrees of freedom of the 4KF IMU are excessively high. As a result, the optimization of VI-BA tends to minimize IMU errors rather than overall errors. Below are the revised formulas:
    \begin{equation}
    \begin{aligned}
        C_{total} &= w(P) *C_V + C_I\\
        w(P) &= \frac{w_{max}}{1+e^{(P-P_{min})}} + w_{min},
    \end{aligned}
    \end{equation}
    where $w(P)$ represents a sigmoid-like weighting function used to to balance the weights of the visual and IMU term. $P$ denotes the average parallax of the two frames with the largest parallax in SfM. $w_{max}, w_{min}$ are the maximal (approximative maximal) and minimal values of the weighting function, respectively. In this work, we set $(w_{max}, w_{min})$ to $(e^4, 1)$. $P_{min}$ is the threshold representing the minimum parallax range within which BA can work effectively. In this work, we set it to 20 pixels.

    During the bundle adjustment process, we fix the position and yaw of the first frame because these 4 degrees of freedom are unobservable.
    