%% the only exception to this rule is the \firstsection command
\firstsection{Introduction}

%% \section{Introduction} %for journal use above \firstsection{..} instead
Visual Inertial Odometry (VIO) is a pivotal technology that integrates image and Inertial Measurement Unit (IMU) measurements to estimate the 6 degrees of freedom (6DoF) motion of a camera. Widely adopted in Augmented Reality/Virtual Reality (AR/VR) systems and autonomous navigation, VIO stands out for its utilization of low-cost and compact camera and IMU sensors. The performance of VIO systems heavily relies on visual inertial initialization and feature matching. Moreover, the robustness and low latency of initialization are critical for Extended Reality (XR) applications, while developers expect accurate camera tracking within milliseconds of launching VIO, regardless of the use case.

The initialization of VIO involves estimating initial variables such as gravity, velocity, and biases of gyroscope and accelerometer for sensors with calibrated intrinsic and extrinsic parameters. Accurate initialization of VIO algorithms is crucial for providing consistent and accurate motion tracking. 
    As shown in \cref{tab:algorithms}, early methods \cite{Dong-Si_initialization, martinelli2014closed} attempted to directly solve all initial variables by constructing a set of equations incorporating visual and IMU observations. Although these algorithms have low computational complexity, they lack robustness and are susceptible to outliers. 
    In recent years, some methods (e.g., \cite{qin-tro-2018_VINS-Mono,campos2020inertial,zuniga2021analytical,campos2019fast, Qin_Shen_2017}) have adopted a loosely coupled approach. They primarily rely on visual Structure from Motion (SfM) to reconstruct the initial structure and align it with IMU pre-integration\cite{forster2017manifold-preintergration}. Consequently, the quality of initialization highly depends on visual SfM. However, in cases of low parallax or small fragments, it becomes challenging to solve the problem robustly. 
    To address the robustness issue in VIO initialization, \cite{Rotation-Translation-Decoupled} proposed a rotation and translation decoupled method. This method first estimates rotation-related parameters and then employs a linear global translation constraint to solve other states without reconstructing 3D points, thereby increasing the success rate of initialization with considerable accuracy. However, this pose-only method is unable to fully exploit nonlinearities in the initialization problems, which limits the accuracy. 
    Furthermore, currently available consumer-grade IMU sensors can provide relatively accurate rotational measurements even without calibrated biases. These measurements can directly offer good initial rotation values for VIO system initialization, significantly simplifying the problem. However, previous algorithms have not fully utilized such characteristics. 


\begin{table*}[htbp]
  \caption{Comparison of our method with previous VIO initialization approaches. "Gyr" denotes gyroscope and "Acc" denotes accelerometer. 
  "Decoupled R\&T 2D" refers to rotation and translation decoupling with  2d visual information, while "Decoupled R\&T 3D" refers to the same, but with 3D information.
Our method comprehensively leverages visual, IMU and 3D information. In contrast, existing VI tightly-coupled methods suffer from instability due to crude fusion of visual and IMU data; VI loosely-coupled methods do not integrate IMU data into the visual SfM process; Decoupled R\&T  2D methods neglect the use of 3D information to mitigate system errors. These shortcomings in existing methods significantly affect the accuracy, robustness and success rate of VIO initialization.}
  \centering
  
    % \begin{tabular}{c|c|c|c|c|c}
    % \toprule
    % \textbf{Algorithms}& \textbf{VI Coupling Mode} & \textbf{Visual SFM} & \textbf{Two View Reconstruction}& \textbf{Estimate IMU Bias}
    % & \textbf{VI-BA \& 3D Map} \\
    % \midrule
    % Closed-form \cite{martinelli2014closed} & Gyro \& Acc Tight & No & No & No
    % & \textbf{Yes} \\
    % VINS-Mono \cite{qin-tro-2018_VINS-Mono} & Gyro \& Acc Loose & Yes & 5-point Ransac & \textbf{Gyro} & \textbf{Yes} \\
    % Inertial-only \cite{campos2020inertial} & Gyro \& Acc Loose & Yes & 4-point \& 8-point Ransac & Gyro \& Acc  & \textbf{Yes} \\
    % DRT-t \cite{Rotation-Translation-Decoupled}  & Gyro \& Acc Tight & No & No &\textbf{Gyro}  & No \\
    % DRT-l \cite{Rotation-Translation-Decoupled}  & \textbf{Gyro Tight, Acc Loose} & No & No & \textbf{Gyro} & No \\
    % Ours  & \textbf{Gyro Tight, Acc Loose} & \textbf{VG-SFM} & \textbf{2-point Ransac w/ Gyro} & \textbf{Gyro}  & \textbf{Yes} \\
    % \end{tabular}

    \begin{tabular}{cccccccc}
    \toprule
    \textbf{VI Coupling Type} & \textbf{Algorithms} & \textbf{Visual Init}& \textbf{Visual SfM} & \textbf{VI-BA}  & \textbf{Bias Init}& \textbf{Robustness} & \textbf{Accuracy} \\
    \midrule
    Tightly coupled& Closed-form \cite{martinelli2014closed,geneva2020openvins} & - & - & \checkmark  &-& $\star\star$ & $\star\star$ \\
    \midrule
    \multirow{2}{*}{Loosely coupled} & Inertial-Only \cite{campos2020inertial} & 4-point/8-point& \checkmark & \checkmark  &Gyr \& Acc& $\star\star\star$  & $\star\star$ \\
    & VINS-Mono \cite{qin-tro-2018_VINS-Mono}& 5-point& \checkmark & \checkmark  &Gyr& $\star\star\star$ & $\star\star\star$ \\
    \midrule
    \multirow{2}{*}{Decoupled R\&T 2D}& DRT-t \cite{Rotation-Translation-Decoupled} & - & - & -  &Gyr& $\star\star\star\star$ & $\star\star\star$ \\
     & DRT-l \cite{Rotation-Translation-Decoupled}& - & - & -  &Gyr& $\star\star\star\star$ & $\star\star\star\star$ \\
    \midrule
    \textbf{Decoupled R\&T 3D}& XR-VIO& \textbf{2-point w/ Gyr}& \textbf{VG-SfM} & \textbf{\checkmark}  &Gyr& $\star\star\star\star\star$ & $\star\star\star\star\star$ \\
    \bottomrule
    \end{tabular}

  \label{tab:algorithms}
\end{table*}%
Conventional methods of VIO or visual SLAM typically utilize popular optical flow-based methods \cite{Lucas_Kanade_1981_KLT} or descriptors-based methods, such as BRIEF\cite{calonder2010brief}, ORB\cite{rublee2011orb}, and BRISK\cite{BRISK},  to match keypoint features and estimate the state. However, each of these techniques has its respective drawbacks: optical flow-based methods tend to drift after long feature tracking, while descriptor-based methods often encounter tracking failures, both resulting in inaccurate state estimation. To address these challenges, some studies have explored the utilization of geometric constraints, such as planarity or depth information. Additionally, other approaches have leveraged deep learning techniques, such as LoFTR\cite{sun2021loftr} and SuperGlue\cite{sarlin2020superglue}, to learn feature representations and matching strategies that are robust to textureless regions or repetitive patterns. Nevertheless, for XR and mobile applications, he complexity of visual features significantly increase the computational load. 

% \begin{table*}[h]
%   \centering
%     \begin{tabular}{c|c|c|c|c|c}
%     \toprule
%     \textbf{Algorithms}& \textbf{VI Coupling Mode} & \textbf{Visual SFM} & \textbf{Two View Reconstruction}& \textbf{Estimate IMU Bias}
%     & \textbf{VI-BA \& 3D Map} \\
%     \midrule
%     Closed-form \cite{martinelli2014closed} & Gyro \& Acc Tight & No & No & No
%     & \textbf{Yes} \\
%     VINS-Mono \cite{qin-tro-2018_VINS-Mono} & Gyro \& Acc Loose & Yes & Visual & \textbf{Gyro} & \textbf{Yes} \\
%     Inertial-only \cite{campos2020inertial} & Gyro \& Acc Loose & Yes & Visual & Gyro \& Acc  & \textbf{Yes} \\
%     DRT-t \cite{Rotation-Translation-Decoupled}  & Gyro \& Acc Tight & No & No &\textbf{Gyro}  & No \\
%     DRT-l \cite{Rotation-Translation-Decoupled}  & \textbf{Gyro Tight, Acc Loose} & No & No & \textbf{Gyro} & No \\
%     Ours  & \textbf{Gyro Tight, Acc Loose} & \textbf{VG-SFM} & \textbf{Visual \& Gyro} & \textbf{Gyro}  & \textbf{Yes} \\
%     \end{tabular}%
%   \label{tab:algorithms}%
% \end{table*}%
In this article, we aim to explore the limits of visual inertial initialization. Through a novel visual inertial fusion process, we significantly improve the success rate and accuracy of initialization. Even in short fragments with small parallax, our proposed initialization method can be completed quickly and stably. 
Additionally, we explore various feature matching solutions to achieve superior matching results by combining existing algorithms suitable for mobile platforms. 
By elucidating these advancements, this paper seeks to contribute to the development of more dependable and efficient VIO systems for XR, enabling immersive and realistic user experiences.

Our main contributions can be summarized as follows:
\begin{itemize}
\item \textbf{Fast VI Initialization}: We propose a rapid and precise VI initialization method, which robustly estimates the initial state of VIO using only four image frames. This robust estimation enables users to freely use mobile devices for AR experiences. In the EuRoC \cite{Burri25012016-EuRoC} benchmark evaluation, our algorithm achieves the state-of-the-art results compared to other similar algorithms.

\item \textbf{Hybrid Feature Matching}: We introduce a hybrid feature matching method, which tightly integrates two traditional feature matching schemes: optical flow and descriptor matching. By leveraging the advantages of both approaches, features can be tracked more stably and accurately. This results in longer track length and reduced feature drift, leading to more accurate state estimation of VIO.

\item \textbf{High-Precision VIO}: We develop a complete VIO system. With the improvements in initialization and feature matching, our entire system demonstrates outstanding accuracy and robustness. This system achieves state-of-the-art performance on open-source datasets compared to other feature matching-based VIO methods.
\end{itemize}