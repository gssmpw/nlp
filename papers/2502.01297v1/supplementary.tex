% $Id: template.tex 11 2007-04-03 22:25:53Z jpeltier $

%\documentclass{vgtc}                          % final (conference style)
\documentclass[review,journal]{abbrv_journal/vgtc} % review
%\documentclass[widereview]{vgtc}             % wide-spaced review
%\documentclass[preprint]{vgtc}               % preprint
%\documentclass[electronic]{vgtc}             % electronic version

%% Uncomment one of the lines above depending on where your paper is
%% in the conference process. ``review'' and ``widereview'' are for review
%% submission, ``preprint'' is for pre-publication, and the final version
%% doesn't use a specific qualifier. Further, ``electronic'' includes
%% hyperreferences for more convenient online viewing.

%% Please use one of the ``review'' options in combination with the
%% assigned online id (see below) ONLY if your paper uses a double blind
%% review process. Some conferences, like IEEE Vis and InfoVis, have NOT
%% in the past.

%% Figures should be in CMYK or Grey scale format, otherwise, colour
%% shifting may occur during the printing process.

%% These few lines make a distinction between latex and pdflatex calls and they
%% bring in essential packages for graphics and font handling.
%% Note that due to the \DeclareGraphicsExtensions{} call it is no longer necessary
%% to provide the the path and extension of a graphics file:
%% \includegraphics{diamondrule} is completely sufficient.
%%
\ifpdf%                                % if we use pdflatex
  \pdfoutput=1\relax                   % create PDFs from pdfLaTeX
  \pdfcompresslevel=9                  % PDF Compression
  \pdfoptionpdfminorversion=7          % create PDF 1.7
  \ExecuteOptions{pdftex}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.pdf,.png,.jpg,.jpeg} % for pdflatex we expect .pdf, .png, or .jpg files
\else%                                 % else we use pure latex
  \ExecuteOptions{dvips}
  \usepackage{graphicx}                % allow us to embed graphics files
  \DeclareGraphicsExtensions{.eps}     % for pure latex we expect eps files
\fi%

\renewcommand{\figurename}{Fig.}

%% it is recomended to use ``\autoref{sec:bla}'' instead of ``Fig.~\ref{sec:bla}''
\graphicspath{{figures/}{pictures/}{images/}{./}} % where to search for the images

\usepackage{microtype}                 % use micro-typography (slightly more compact, better to read)
\PassOptionsToPackage{warn}{textcomp}  % to address font issues with \textrightarrow
\usepackage{textcomp}                  % use better special symbols
\usepackage{mathptmx}                  % use matching math font
\usepackage{times}                     % we use Times as the main font
\renewcommand*\ttdefault{txtt}         % a nicer typewriter font
\usepackage{cite}                      % needed to automatically sort the references
\usepackage{tabu}                      % only used for the table example
\usepackage{booktabs}                  % only used for the table example
\usepackage{bm}
\usepackage{algorithm}
% \usepackage{algorithmic}
\usepackage[algo2e,linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{makecell}
\usepackage{amsmath,amssymb}
\usepackage{multirow}
\usepackage{float}
%% We encourage the use of mathptmx for consistent usage of times font
%% throughout the proceedings. However, if you encounter conflicts
%% with other math-related packages, you may want to disable it.


%% If you are submitting a paper to a conference for review with a double
%% blind reviewing process, please replace the value ``0'' below with your
%% OnlineID. Otherwise, you may safely leave it at ``0''.
\onlineid{1234}

%% declare the category of your paper, only shown in review mode
\vgtccategory{Research}
\vgtcpapertype{algorithm/technique}
%% allow for this line if you want the electronic option to work properly
% \vgtcinsertpkg

%% In preprint mode you may define your own headline.
%\preprinttext{To appear in an IEEE VGTC sponsored conference.}

%% Paper title.

% \title{High-precision Visual Inertial Odometry with Fast Initialization for Mobile AR}
\title{XR-VIO: High-precision Visual Inertial Odometry with Fast Initialization for XR Applications
Supplementary Document
}
%% This is how authors are specified in the conference style

%% Author and Affiliation (single author).
%%\author{Roy G. Biv\thanks{e-mail: roy.g.biv@aol.com}}
%%\affiliation{\scriptsize Allied Widgets Research}

%% Author and Affiliation (multiple authors with single affiliations).
%%\author{Roy G. Biv\thanks{e-mail: roy.g.biv@aol.com} %
%%\and Ed Grimley\thanks{e-mail:ed.grimley@aol.com} %
%%\and Martha Stewart\thanks{e-mail:martha.stewart@marthastewart.com}}
%%\affiliation{\scriptsize Martha Stewart Enterprises \\ Microsoft Research}

%% Author and Affiliation (multiple authors with multiple affiliations)
% \author{Paper ID:1280}
%\author{Roy G. Biv\thanks{e-mail: roy.g.biv@aol.com}\\ %
%        \scriptsize Starbucks Research %
%\and Ed Grimley\thanks{e-mail: ed.grimley@aol.com}\\ %
%     \scriptsize Grimley Widgets, Inc. %
%\and Martha Stewart\thanks{e-mail: martha.stewart@marthastewart.com}\\ %
%     \parbox{1.4in}{\scriptsize \centering Martha Stewart Enterprises \\ Microsoft Research}}

%% A teaser figure can be included as follows, but is not recommended since
%% the space is now taken up by a full width abstract.
%\teaser{
%  \includegraphics[width=1.5in]{sample.eps}
%  \caption{Lookit! Lookit!}
%}

%% Abstract section.
% \input{sections/0_abstract}
%% ACM Computing Classification System (CCS).
%% See <http://www.acm.org/about/class> for details.
%% We recommend the 2012 system <http://www.acm.org/about/class/class/2012>
%% For the 2012 system use the ``\CCScatTwelve'' which command takes four arguments.
%% The 1998 system <http://www.acm.org/about/class/class/2012> is still possible
%% For the 1998 system use the ``\CCScat'' which command takes four arguments.
%% In both cases the last two arguments (1998) or last three (2012) can be empty.

\CCScatlist{
  \CCScatTwelve{VIO}{SLAM}{Initialization}{AR};
}

% A teaser figure can be included as follows


%\CCScatlist{
  %\CCScat{H.5.2}{User Interfaces}{User Interfaces}{Graphical user interfaces (GUI)}{};
  %\CCScat{H.5.m}{Information Interfaces and Presentation}{Miscellaneous}{}{}
%}

%% Copyright space is enabled by default as required by guidelines.
%% It is disabled by the 'review' option or via the following command:
% \nocopyrightspace

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% START OF THE PAPER %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\firstsection{Introduction}
\maketitle

This is the supplementary document that our main paper refers to. It contains some additional implement details and additional experiment results.

\section{Additional Experiments}

In Sec. 6, we conducted comprehensive experiments on our initialization method and feature tracking approach, comparing them with numerous state-of-the-art (SOTA) algorithms to demonstrate the effectiveness of our proposed method. To further emphasize the advantages of our algorithm, we provide additional experimental results and comparisons in this supplementary material. 

\subsection{Initialization Evaluation}
In Sect. 6.3, we conducted a comprehensive evaluation of our initialization algorithm compared to several SOTA algorithms, including Closed-form \cite{martinelli2014closed}, Vins-Mono \cite{qin-tro-2018_VINS-Mono}, Inertial-only \cite{campos2020inertial}, and DRT \cite{Rotation-Translation-Decoupled}. As presented in Tab. 2 in the main text, we compared the accuracy metrics of our initialization method under two configurations: 4-keyframe (4KF) and 5-keyframe (5KF). Our results demonstrated a high initialization success rate with very few initial frames, outperforming SOTA algorithms in terms of accuracy metrics. However, existing methods typically initialize using a 10-keyframe (10KF) configuration. To provide a more comprehensive and fair comparison, we extended our evaluations to include the 10KF configuration. Under this setting, each sequence was segmented into 1137 fragments at intervals of 1.2 seconds, with keyframes uniformly selected at intervals of 0.1 seconds for all methods.

\Cref{tab:Init_Compare2_sup} and  \cref{fig:Init_Error_10KF_CDF_sup} present a detailed overview of the accuracy metrics and corresponding cumulative distribution functions (CDF) of various initialization methods. Notably, our algorithm maintains superiority over existing approaches under the widely adopted 10KF configuration, demonstrating superior performance across all metrics compared to current initialization methods.

Furthermore, it's important to highlight that the DRT method, including DRT-l and DRT-r, does not employ a joint optimization algorithm like VI-BA. To ensure a fair comparison, we conducted additional experiments by disabling VI-BA in the XR-VIO initialization pipeline and compared the results of VA-Align (referred to as XR-VIO w/o VI-BA) with those of the DRT algorithm.

As illustrated in \cref{fig:Init_Error_CDF_sup} and \cref{tab:Init_Compare_sup}, the accuracy metrics of XR-VIO w/o VI-BA are slightly lower than those of XR-VIO, but significantly higher than those of the DRT algorithm. This result highlights the innovativeness and practical value of our VG-SfM approach, confirming its effectiveness even in scenarios where VI-BA is disabled.



\begin{table}[htbp]
    \centering
    \begin{tabular}{ccccc}
    \toprule
         Algorithms &  Scale(\%)$\downarrow$&  ATE(m)$\downarrow$&  Gravity(°)$\downarrow$&Success(\%)$\uparrow$\\
         \midrule
         Closed-form \cite{martinelli2014closed} & 12.55 & 0.031 & 1.70 & 32.36  \\
         Inertial-only \cite{campos2020inertial} & 20.12 &  0.062& 9.77 & 41.86 \\
         Vins-Mono \cite{qin-tro-2018_VINS-Mono} & 19.78 & 0.053 & 1.72 & 58.51 \\
         DRT-l \cite{Rotation-Translation-Decoupled} & 30.42 & 0.070 & 2.22 & 76.18 \\
         DRT-t \cite{Rotation-Translation-Decoupled} & 27.08 & 0.067 & 2.36 & 75.99 \\
         XR-VIO&  \textbf{11.99}&  \textbf{0.027}&  \textbf{1.48}&\textbf{83.97} \\
         \bottomrule
    \end{tabular}
    \caption{10KF Initialization Evaluation on EuRoC. Bold font indicates the best result. We compare these methods under the configuration: 10KF, including scale, ATE, gravity, and success rate.}
    \label{tab:Init_Compare2_sup}
\end{table}

\begin{figure}[!h]
    \centering
    \includegraphics[width=1\linewidth,height=0.032\linewidth]{pictures/labels.png}
    10KF
    \includegraphics[width=1\linewidth,height=0.3\linewidth]{pictures/Figure_3_new.png}
    \caption{Cumulative distribution of initialization with 10KF. Scale error, ATE and gravity RMSE are shown in 3 columns. }
    \label{fig:Init_Error_10KF_CDF_sup}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=1\linewidth,height=0.05\linewidth]{pictures/linear_labels.png}
    4KF
    \centering
    \includegraphics[width=1\linewidth,height=0.3\linewidth]{pictures/linear_4kf.png}
    5KF
    \includegraphics[width=1\linewidth,height=0.3\linewidth]{pictures/linear_5kf.png}
    10KF
    \includegraphics[width=1\linewidth,height=0.3\linewidth]{pictures/linear_10kf.png}
    \caption{Cumulative distribution of initialization with different keyframes: 4KF, 5KF, and 10KF. Scale error, ATE and gravity RMSE are shown in 3 columns. }
    \label{fig:Init_Error_CDF_sup}
\end{figure}

\begin{table*}[t]
    \centering
    \begin{tabular}{c|cccc|cccc}
    \toprule
 & \multicolumn{4}{c}{4KF} &\multicolumn{4}{c}{5KF}\\
          \midrule
         &  Scale(\%)$\downarrow$&  ATE(m)$\downarrow$&  Gravity(°)$\downarrow$&Success(\%)$\uparrow$& Scale(\%)$\downarrow$& ATE(m)$\downarrow$& Gravity(°)$\downarrow$& Success(\%)$\uparrow$\\
         % \hline
         DRT-l&  41.79&  0.041&  3.50&76.94 & 34.57& 0.039& 2.64&85.79\\
         DRT-t&  61.54&  0.059&  3.97&\textbf{86.56} & 50.46& 0.059& 3.37& \underline{86.24}\\
         XR-VIO w/o VI-BA &  \underline{30.68}&  \underline{0.028}&  \underline{2.37}&\underline{83.98} & \underline{28.34}& \underline{0.032}& \underline{2.14}&\textbf{87.15}\\
         XR-VIO&  \textbf{26.88}&  \textbf{0.026}&  \textbf{2.26}&\underline{83.98} & \textbf{22.71}& \textbf{0.027}& \textbf{1.99}&\textbf{87.15}\\
         \bottomrule
    \end{tabular}
    \caption{Initialization Evaluation on EuRoC. Bold font indicates the best result, underline indicates the second best result. We compare these methods under 2 different configuration: 4KF and 5KF, both including scale, ATE, gravity, and success rate.}
    \label{tab:Init_Compare_sup}
\end{table*}

\subsection{Trajectory Evaluation}
In Sec. 6.5, we  conducted a comparison of trajectory accuracy between OKVIS \cite{leutenegger-ijrr-2015-OKVIS}, VINS-Mono \cite{qin-tro-2018_VINS-Mono}, VINS-Fusion \cite{qin2019a_VINS_Fusion_Local}, OpenVINS \cite{geneva2020openvins}, HybVIO \cite{hybvio} and our XR-VIO algorithm on the Euroc \cite{Burri25012016-EuRoC} and ZJU-Sensetime \cite{jinyu2019survey} datasets. The overall accuracy of the XR-VIO algorithm surpassed these SOTA algorithms on both datasets. However, Euroc and ZJU-Sensetime datasets do not provide metrics for Apple ARKit \footnote{\url{https://developer.apple.com/documentation/arkit/}} and Google ARCore \footnote{\url{https://developers.google.com/ar/}},  two leading commercial AR software solutions with substantial influence in the XR field. To further compare with ARKit and ARCore, we utilized the ADVIO dataset ~\cite{cortes2018advio}.

\begin{table}[h]
  \centering
    \begin{tabular}{cccccc}
    \toprule
         Dataset & ARKit & ARCore & XR-VIO \\
    \midrule
    advio-01 & 2.466 & 8.294 & \textbf{2.039} \\
    advio-02 & 2.594 & \textbf{1.473} & 2.387 \\
    advio-03 & \textbf{1.293} & 2.694 & 1.488 \\
    advio-04 & 5.186 & 24.67 & \textbf{2.827} \\
    advio-05 & 1.631 & \textbf{1.027} & 1.213 \\
    advio-06 & 4.093 & 1.758 & \textbf{1.499} \\
    advio-07 & 3.511 & 7.867 & \textbf{0.581} \\
    advio-08 & \textbf{1.318} & 7.018 & 1.540 \\
    advio-09 & 2.971 & \textbf{2.071} & 3.072\\
    advio-10 & 1.850 & \textbf{0.990} & 2.097 \\
    advio-11 & 2.782 & 2.822 & \textbf{2.677} \\
    advio-12 & 1.850 & 2.975 &  \textbf{1.719}\\
    advio-13 & 1.270 & 3.717 & \textbf{0.850} \\
    advio-14 & \textbf{1.500} & 5.825 & 4.990 \\
    advio-15 & 0.917 & 1.215 & \textbf{0.903} \\
    advio-16 & 1.219 & 3.069 & \textbf{0.576} \\
    advio-17 & 1.771 & 1.586 & \textbf{0.765} \\
    advio-18 & 0.695 & 1.509 & \textbf{0.589} \\
    advio-19 & 0.994 & \textbf{0.890} & 2.008 \\
    advio-20 & \textbf{9.445} & 12.77 & 12.931 \\
    advio-21 & 17.00 & 12.86 & \textbf{11.363} \\
    advio-22 & \textbf{4.752} & 5.198 & 6.467 \\
    advio-23 & -     & 4.660 & \textbf{4.252} \\
    \midrule
    \textbf{avg.} & 3.706 & 5.086 & \textbf{2.993} \\
    \bottomrule
    \end{tabular}%
  \caption{ATE (m) of different algorithms on the ADVIO dataset with metric of RMSE. Bold font indicates the best result in each column. ’-’ represents a failure to run on
this data.}
  \label{tab:data_sup}%
\end{table}%
\textbf{ADVIO} (Advanced Visual-Inertial Odometry) dataset is an open benchmark dataset designed for evaluating visual-inertia algorithms. It contains diverse real-world scenes, including different indoor/outdoor environments, lighting conditions, and dynamic object interferences, facilitating the assessment of robustness, accuracy, and real-time performance of various algorithms. Notably, the ADVIO dataset offers three aligned trajectories with ground truth: an ARCore trajectory captured on a Google Pixel device, an ARKit trajectory obtained from an iPhone, and Tango odometry recorded on a Google Tango tablet device.

Following the configurations outlined in Sec. 6, we executed all 23 datasets from ADVIO and compared them with ARKit and ARCore using Absolute Trajectory Error (ATE) metrics. As depicted in \cref{tab:data_sup}, out of the 23 datasets, our XR-VIO algorithm achieved the highest accuracy in 13 of them. Overall, our accuracy surpassed that of ARKit and ARCore. This experiment underscores the robustness and superiority of our XR-VIO algorithm in XR environments, particularly in pedestrian XR scenarios.



%% if specified like this the section will be committed in review mode
% \acknowledgments{
% The authors wish to thank A, B, and C. This work was supported in part by
% a grant from XYZ.}

%\bibliographystyle{abbrv}
\bibliographystyle{abbrv_journal/abbrv-doi}
%\bibliographystyle{abbrv-doi-narrow}
%\bibliographystyle{abbrv-doi-hyperref}
%\bibliographystyle{abbrv-doi-hyperref-narrow}
\newpage
\bibliography{reference/main}
\end{document}
