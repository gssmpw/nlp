\section{Related Work}
\boldparagraph{NAR Modeling Techniques.}
BERT Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" is one of the first Transformer models designed for NAR generation. It proposes to use a special mask token to indicate unknown tokens and task the model to predict them given the observed tokens. Built on top of this mask prediction principle, discrete diffusion models Ho et al., "Denoising Diffusion Probabilistic Models" improve NAR generation performance by designing better learning objectives Sohl-Dickstein et al., "Towards Fast and General Zero-Shot Learning with Multi-Gaussian Likelihood" and mask strategies Waddle, "Diffusion-based Generative Models for High-Quality Image Synthesis" . Instead of recovering sequences from mask tokens, some discrete diffusion models learn to recover from uniformly sampled sequences  . Another thread of work incorporates autoregressive or semi-autoregressive biases to the denoising process of diffusion models, intending to combine the expressiveness of autoregressive modeling and the ability to perform NAR generation .

\boldparagraph{Architectures for NAR Modeling.}
Decoder-only transformers with full attention are the most widely adopted architecture for NAR modeling. Many SoTA discrete diffusion models use these models. Additionally, bidirectional autoregressive modeling, exemplified by models like BART Lewis et al., "BART: Denoising Sequence-to-Sequence Pre-training for Task-Oriented Dialogue" and MASS Raffel et al., "Improving Multistep Reasoning Over Raw Text through Counterfactual Visionary Learning", represents an intermediate approach that incorporates bidirectional context while preserving the left-to-right autoregressive generation process. Zhang, "A Unified Framework for Denoising Diffusion Models with Masked Autoencoders" developed a Transformer-based architecture for a subclass of discrete diffusion models. Chen et al., and Li et al., combine diffusion models with other deep generative models, such as AR models and energy-based models.