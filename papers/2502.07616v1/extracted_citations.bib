@article{austin2021structured,
  title={Structured denoising diffusion models in discrete state-spaces},
  author={Austin, Jacob and Johnson, Daniel D and Ho, Jonathan and Tarlow, Daniel and Van Den Berg, Rianne},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17981--17993},
  year={2021}
}

@article{campbell2022continuous,
  title={A continuous time framework for discrete denoising models},
  author={Campbell, Andrew and Benton, Joe and De Bortoli, Valentin and Rainforth, Thomas and Deligiannidis, George and Doucet, Arnaud},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={28266--28279},
  year={2022}
}

@inproceedings{chen2024diffusion,
  title={Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion},
  author={Chen, Boyuan and Mons{\'o}, Diego Mart{\'\i} and Du, Yilun and Simchowitz, Max and Tedrake, Russ and Sitzmann, Vincent},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@inproceedings{devlin2018bert,
  author    = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  title     = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  booktitle = {Proceedings of NAACL-HLT},
  year      = {2018},
  pages     = {4171--4186},
  publisher = {Association for Computational Linguistics},
}

@inproceedings{han2023ssd,
  title={SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control},
  author={Han, Xiaochuang and Kumar, Sachin and Tsvetkov, Yulia},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={11575--11596},
  year={2023}
}

@article{lewis2020bart,
  title={BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and others},
  journal={arXiv preprint arXiv:1910.13461},
  year={2020}
}

@inproceedings{liu2025discrete,
  title={Discrete Copula Diffusion},
  author={Liu, Anji and Broadrick, Oliver and Niepert, Mathias and Van den Broeck, Guy},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}

@article{lou2023discrete,
  title={Discrete diffusion language modeling by estimating the ratios of the data distribution},
  author={Lou, Aaron and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2310.16834},
  year={2023}
}

@article{sahoo2024simple,
  title={Simple and Effective Masked Diffusion Language Models},
  author={Sahoo, Subham Sekhar and Arriola, Marianne and Schiff, Yair and Gokaslan, Aaron and Marroquin, Edgar and Chiu, Justin T and Rush, Alexander and Kuleshov, Volodymyr},
  journal={arXiv preprint arXiv:2406.07524},
  year={2024}
}

@article{shi2024simplified,
  title={Simplified and Generalized Masked Diffusion for Discrete Data},
  author={Shi, Jiaxin and Han, Kehang and Wang, Zhe and Doucet, Arnaud and Titsias, Michalis K},
  journal={arXiv preprint arXiv:2406.04329},
  year={2024}
}

@article{song2019mass,
  title={MASS: Masked Sequence to Sequence Pre-training for Language Generation},
  author={Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
  journal={arXiv e-prints},
  pages={arXiv--1905},
  year={2019}
}

@inproceedings{sun2023score,
  title={Score-based Continuous-time Discrete Diffusion Models},
  author={Sun, Haoran and Yu, Lijun and Dai, Bo and Schuurmans, Dale and Dai, Hanjun},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{warner2024smarter,
  title={Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference},
  author={Warner, Benjamin and Chaffin, Antoine and Clavi{\'e}, Benjamin and Weller, Orion and Hallstr{\"o}m, Oskar and Taghadouini, Said and Gallagher, Alexis and Biswas, Raja and Ladhak, Faisal and Aarsen, Tom and others},
  journal={arXiv preprint arXiv:2412.13663},
  year={2024}
}

@inproceedings{xu2025energy,
  title={Energy-Based Diffusion Language Models for Text Generation},
  author={Xu, Minkai and Geffner, Tomas and Kreis, Karsten and Nie, Weili and Xu, Yilun and Leskovec, Jure and Ermon, Stefano and Vahdat, Arash},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}

