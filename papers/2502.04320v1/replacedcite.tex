\section{Related Work}
\paragraph{Diffusion Model Interpretability}

A fair amount of existing work attempts to interpret diffusion models. Some works investigate diffusion models from an analytic lens ____, attempting to understand how diffusion models geometrically model the manifold of data. Other works attempt to understand how models memorize images ____. An increasing body of work attempts to repurpose the representations of diffusion models for various tasks like classification ____, segmentation ____, and even robotic control ____. However, most relevant to our work is the substantial body of methods investigating how the representations of the neural network architectures underpinning diffusion can be used to garner insight into how these models work, steer their behavior, and improve their safety. 

Numerous papers have observed that the cross attention mechanisms of UNet-based diffusion models like Stable Diffusion ____ and SDXL ____ can produce interpretable saliency maps of textual concepts ____. Cross attention maps are used in a variety of image editing tasks like producing masks that localize objects of interest to edit ____, controlling the layout of images ____, altering the appearance of an image but retaining its layout ____, and even generating synthetic data to train instruction based editing models ____. Other works observe that performing interventions on cross attention maps can improve the faithfulness of images to prompts by ensuring attributes are assigned to the correct objects ____.  Additionally, it has been observed that self-attention layers of diffusion models encode useful information about the layout of images ____. 

%


\paragraph{Zero-shot Image Segmentation}
In this work, we evaluate \tool{} on the task of zero-shot image segmentation, which is a natural way to assess the accuracy of our saliency maps and the transferability of the representations of multi-modal DiT architectures to downstream vision tasks. This task also provides a good setting to compare to a variety of other interpretability methods for various foundation model architectures like CLIP ____, DINO ____, and diffusion models.  

A variety of works train a diffusion models from scratch for the task of image segmentation ____ or attempt to fine-tune pretrained models ____. Another line of work leverages diffusion models to generate synthetic data that can be used to train segmentation models that transfer zero-shot to new classes ____. While effective, these methods are training-based and thus do not provide as much insight into the representations of existing text-to-image generation models, which is the key motivation behind \tool{}. 

A significant body of work attempts to improve the interpretability of CLIP vision transformers (ViTs) ____. The authors of ____ develop a method for generating saliency maps for ViT models, and they introduce an evaluation protocol for assessing the effectiveness of these saliency maps. This evaluation protocol centers around the ImageNet-Segmentation dataset ____, and we extend this evaluation to the PascalVOC dataset ____. They compare to a variety of zero-shot interpretability methods like GradCAM ____, Layerwise-Relevance Propagation ____, raw attentions, and the Rollout method ____. The authors of ____ demonstrate an approach to expressing image patches in terms of textual concepts. We also compare our approach to zero-shot diffusion based methods ____ and the self-attention maps of DINO ViT models ____. 

Another line of work attempts perform unsupervised segmentation without any class or text conditioning by performing clustering of the embeddings of models ____. Despite not producing class predictions, these models are often evaluated on semantic segmentation datasets by using approaches like Hungarian matching ____ to pair unlabeled segmentation predictions with the best matching ones in a multi-class semantic segmentation dataset. In contrast, \tool{} enables text conditioning so we do not compare to this family of methods. We also don't compare to models like SAM ____ as it is trained on a large scale dataset.  %