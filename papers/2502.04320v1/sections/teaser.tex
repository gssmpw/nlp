
% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\linewidth]{figures/Qualitative Cross vs Output Space Decompositions.pdf}
%     % \vspace{-0.2in}
%     \caption{\textbf{\tool{} projections in the attention output space are qualitatively better than those in the cross attention space. } Using our approach to generate contextualized concept embeddings we compare saliency maps produced by performing linear projections in the cross attention space and attention output space. The output space  saliency maps are much better localized to the appropriate image regions. }
%     \label{fig:enter-label}
% \end{figure*}


% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\linewidth]{figures/QualitativeResults.pdf}
%     \vspace{-0.2in}
%     \caption{\textbf{\tool{} can produce highly localized saliency maps for an open-set of concepts, regardless of the text prompt. } }
%     \label{fig:enter-label}
% \end{figure*}


\begin{figure}[t!]
    \centering
    \includegraphics[width=1.0\linewidth]{figures/CrownJewelDragon.png}
    \vspace{-0.25in}
    \caption{\textbf{\tool{} produces saliency maps that precisely localize the presence of textual concepts in images.}  We compare Flux raw cross attention, DAAM \cite{tang_what_2022} with SDXL, and TextSpan \cite{gandelsman_interpreting_2024} for CLIP. }
    \label{fig:teaser}
\end{figure}

