\begin{table*}[ht!]
\centering
\begin{tabular}{@{}l| p{7cm} |r| r@{}}
\textbf{Dataset} & \textbf{Description} & \textbf{Samples} & \textbf{Eval-Samples} \\
\midrule
\multicolumn{4}{l}{\textbf{Knowledge-based}} \\
\midrule
\textbf{MMLU} & Massive Multitask Language Understanding benchmark covering 57 subjects & 14,042 & 375 (x3) \\
\textbf{MMLU Pro} & Professional-level extension of MMLU with advanced questions & 12,032 & 374 (x3) \\
\textbf{GPQA} & Challenging dataset of multiple-choice questions written by domain experts in biology, physics, and chemistry & 546 & 250 (x3)\\
\midrule
\multicolumn{4}{l}{\textbf{Reasoning-based}} \\
\midrule
\textbf{StrategyQA} & Dataset of questions requiring implicit multi-hop reasoning & 2,289 & 330 (x3)\\
\textbf{MuSR} & Logic reasoning for solving murder mystery stories & 250 & 152 (x3)\\
\textbf{SQuAD 2.0} & Stanford QA Dataset with answerable and unanswerable questions & 11,873 & 373 (x3)\\
\end{tabular}
\caption{All datasets used for evaluation with a short description, number of samples in the test set, and number of samples used in this study. The datasets are divided into knowledge-based tasks and reasoning-based tasks.}
\label{tab:datasets}
\end{table*}
