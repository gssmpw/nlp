\section{Introduction}
\label{sec:intro}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\columnwidth]{pdf/DecisionProtocol.drawio-4.pdf}
    \caption{Illustration of different decision protocol families in this study.
    \vspace{-0.3cm}
    }
    \label{fig:decision_protocols}
\end{figure}

Humans are inherently social, and collaboration has been key to innovation and progress. %
We know that generating solutions together is only beneficial if we can effectively select, agree, and commit to them.
History, sociology, and psychology have long demonstrated how different decision-making processes influence collective outcomes \citep{jones_comparison_1994, list_social_2022}. 
Multi-agent systems form a parallel to human behavior by solving problems collectively via debate.
However, so far, few studies have investigated how decision-making influences \ac{LLM} collaboration and their ability to problem-solve.

Current approaches often apply decision strategies like majority voting \citep{yang_llm_2024} or consensus \citep{yin_exchange--thought_2023} indiscriminately to various tasks.
Consensus strategies refine decisions while voting approaches choose from proposed solutions.
Prior work often treats these strategies as fixed variables without considering problem-specific characteristics \citep{yin_exchange--thought_2023}.
We show that changes in decision protocols lead to markedly different results among tasks.
Thus, we argue that decision-making is central to multi-agent processes.

This study systematically quantifies the effectiveness of decision-making protocols within multi-agent debates on knowledge tasks (i.e., MMLU \citep{hendrycks_measuring_2021-1}, MLLU-Pro \citep{wang_mmlu-pro_2024}, GPQA \citep{rein_gpqa_2023}) and reasoning tasks (i.e., SQuAD 2.0 \citep{rajpurkar_know_2018}, StrategyQA \citep{geva_did_2021}, MuSR \citep{sprague_musr_2024}). 
In contrast to prior work, which varies the decision protocol concurrently to other parameters~\citep{yang_llm_2024, yin_exchange--thought_2023}, we use a consistent setup to quantify changes for which only the decision mechanism is responsible.
Specifically, we explore the impact of three consensus \citep{chen_reconcile_2024} and four voting \citep{yang_llm_2024} methods and highlight their task-specific strengths and weaknesses.
An overview of how consensus and voting decision protocols work in our setup can be seen in \Cref{fig:decision_protocols}.
Throughout our experiments, we observe that answer diversity and independent answer generation have a marked impact on decision-making. 
To reap the benefits of these factors, we propose two novel methods: \acf{AAD} and \acf{CI}.
\ac{AAD} ensures each agent independently drafts an initial solution before any interaction, promoting distinct reasoning paths. %
\ac{CI} structures agent collaboration through iterative refinement while preventing excessive communication to avoid bias towards similar answers between agents.

Our experiments show that consensus protocols perform better in knowledge tasks, improving performance by $2.8\%$, and voting protocols perform better in reasoning tasks, improving results by $13.2\%$. 
\ac{AAD} increases accuracy by about $3.3\%$, while \ac{CI} further improves effectiveness, leading to an $7.4\%$ performance boost. 
Our results underline the role of decision protocols for multi-agent experiments. 
We recommend consensus strategies for knowledge tasks and voting for reasoning tasks while generally using \ac{AAD} or \ac{CI} to improve answer diversity. 
Our investigations into the role of decision protocols are particularly relevant for high-stakes domains such as medical diagnostics and legal reasoning, where wrong decisions can have real-world negative effects. 
We release the code and data for these experiments publicly\footnote{\href{https://github.com/lkaesberg/decision-protocols}{github.com/lkaesberg/decision-protocols}}. 

\medskip
\noindent\textbf{Key Contributions:}
\begin{itemize}
    \item[ยง\ref{sec:experiment1}] A systematic comparison of decision protocols, revealing for the first time that consensus is most effective for knowledge tasks, while voting is better in reasoning tasks.
    \item[ยง\ref{sec:experiment-numagents}] An analysis of scaling differences between increasing the number of agents and extending the number of communication rounds.
    \item[ยง\ref{sec:experiment2}] The proposal of two new methods, \ac{AAD} and \ac{CI}, to enhance answer diversity in multi-agent debates by encouraging independent thinking.
\end{itemize}
