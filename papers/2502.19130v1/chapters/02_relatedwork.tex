\section{Related Work}



\noindent
\textbf{LLMs as Agents}. %
An agent differs from an LLM in that it has a defined planning behavior, can use tools, and maintains a state or memory across interactions. 
Techniques such as \acf{CoT} prompting \citep{wei_chain--thought_2023}, self-refinement \citep{madaan_self-refine_2023}, and self-consistency \citep{wang_self-consistency_2022} improve models' ability to plan, critique, and refine responses. 
Persona-based prompting \citep{jiang_personallm_2024} enables \acp{LLM} to adopt specialized roles, improving answer diversity.
A single-agent system operates as one entity with an internal state, while a multi-agent debate consists of multiple agents with a private state that persists across calls and may operate asynchronously, leading to emergent, independent behaviors \cite{du2023improvingfactualityreasoninglanguage, ZhaoHXL23a, XuYLW23a, SuzgunK24a, goldberg2024}.
In multi-agent debates, many parameter choices have to be made, such as in which turn order they communicate \citep{yin_exchange--thought_2023}, and which tools they can use \citep{yao2023reactsynergizingreasoningacting}.
Yet one choice is inevitable: How to make decisions between agents.



\noindent
\textbf{Decision-Making}. Finding collective solutions markedly impacts human decision-making \cite{jones_comparison_1994}. 
While consensus promotes shared decisions and allows everyone to contribute to the final solution, it can be time-consuming and lead to power concentration of individuals with ``vetos''. 
Conversely, voting can lead to a faster final decision because it streamlines decision-making, but is susceptible to manipulation and does not take into account all opinions.
For example, participants can vote for a less preferred but more viable alternative to block an undesired outcome, leading to outcomes that do not reflect the collective will of the group \citep{list_social_2022}.

Research in multi-agent debate has implemented various human decision protocols \citep{yin_exchange--thought_2023, chen_reconcile_2024, yang_llm_2024}. 
Exchange-of-Thought \citep{yin_exchange--thought_2023} employs a consensus-based approach, where agents iteratively refine answers through discussion in reasoning tasks, but they do not compare consensus to other decision protocols.
\citet{yang_llm_2024, 10.1145/3665332} introduce multiple voting protocols (e.g., approval voting) but do not compare the performance of these voting decision protocols across different tasks, focussing more on a comparison of how humans vote compared to \acp{LLM}.
ReConcile \citep{chen_reconcile_2024} integrates a hybrid voting and consensus approach by iteratively refining answers through confidence-weighting until consensus is reached. %
In summary, prior work focuses on a single class of decision protocols without systematic comparison, partly because many parameters change between experiments \citep{yin_exchange--thought_2023, yang_llm_2024, chen_reconcile_2024}.
This work systematically evaluates seven voting and consensus approaches on both knowledge and reasoning datasets to show task-based advantages of one protocol over another.

