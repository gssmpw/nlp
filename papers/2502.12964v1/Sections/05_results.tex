

\section{Results}\label{sec:main_results}

First, we identify whether \chk examples are consistently present across certainty metrics and across different models (Section \ref{sec:Consistently Exists}). Next, we show that \chk examples are consistently present in instruct-tuned and larger models (Section \ref{chk Persists in Instruction-Tuning and Larger Models}). Lastly, we show that \chk can not be explained as noise (Section \ref{sec:Certainty Hallucinations can not be Explain as Noise}).



\subsection{\chk Consistently Exists}\label{sec:Consistently Exists}

As shown in Figure \ref{fig:Hallucinations from miss knowledge vs. hallucinations regardless of knowledge vs. non-hallucination-knowledge classification}, 
a non-negligible amount of hallucinations occur with high certainty, demonstrating the existence of \chk. For example, for the Mistral model with the probability certainty measure on the child setting (upper-left subfigure of Figure \ref{fig:Hallucinations from miss knowledge vs. hallucinations regardless of knowledge vs. non-hallucination-knowledge classification}), approximately $20\%$ of hallucinations exceed the certainty threshold ($T^* = 0.5$).  
 This means that using $0.5$ as the certainty threshold, a significant portion of hallucinations would be classified as certain hallucinations.
 Similar patterns are found in other setups shown in the figure. 
 
 These findings highlight that high-certainty hallucinations are not rare but a common phenomenon in these models.
See Appendix \ref{appendix:Qualitative Evaluation} for a qualitative evaluation showing examples of hallucinations that exhibit high probability and low semantic entropy scores, both measures of high certainty.



\paragraph{\chk is Consistent Across Certainty Thresholds.}

The black dashed line in each subfigure represents the optimal certainty threshold (explained in Section \ref{subsec:Certainty Threshold}). Our results show that between $10\%$ and $40\%$ of hallucinations exceed this threshold, confirming the presence of certain hallucinations. The figure shows that this trend persists across a range of certainty thresholds, not just the optimal one, demonstrating that the results are robust to threshold selection.

While the correct answers (blue line) are consistently above the hallucinations (red line) across all thresholds, the certainty-correct relationship is not absolute. Many correct answer samples occur with low certainty, indicating that certainty levels vary even for correct predictions while the model knows the answer.
See Appendix~\ref{appendix-Certain HK+ Exist Additional Results} for similar results on the Gemma and Llama models. Additionally, results using a temperature of $0.5$ instead of $1$ for semantic entropy generations are provided in Appendix~\ref{appendix:Semantic Entropy results Different Temperature}. For similar results using a variation of the child setting, demonstrating the robustness of the phenomenon, refer to Appendix~\ref{appendix:Prompt Specificity}.



\paragraph{\chk is Consistent Across Certainty Metrics.}


As the figure shows, the extent of high-certainty hallucinations varies across the certainty measures (different rows).
Nevertheless, across all three measures, we effectively identify \chk examples.



\subsection{\chk Persists in Instruction-Tuning and Larger Models} \label{chk Persists in Instruction-Tuning and Larger Models}

Since instruction tuning and model size often influence model behavior, we investigate their effect on \chk to assess its persistence.

\paragraph{Instruction-Tuned Models are less Calibrated.}
Instruction-tuned models display poorer calibration between uncertainty and hallucinations, as reflected by their higher rates of high-certainty hallucinations. 
For example, for the Mistral model with the probability certainty measure on the child setting, approximately $20\%$ of hallucinations have a certainty value of $\mathbf{0.5}$ or higher. In contrast, for the Mistral-Instruct model, around $20\%$ of hallucinations have a certainty value of $\mathbf{0.9}$ or higher. These results are shown in the upper-left subfigure and the upper-third-from-the-left subfigure of Figure \ref{fig:Hallucinations from miss knowledge vs. hallucinations regardless of knowledge vs. non-hallucination-knowledge classification}.
Similar results are found with Llama and Gemma models (Appendix \ref{appendix-Certain HK+ Exist Additional Results}).

These results suggest that certainty-based methods may be less effective in these models. These findings align with prior work noticing poor calibration after instruction tuning \citep{gpt4} and underscore the need for improved detection methods tailored to instruction-tuned models.








\begin{figure}
\centering
\begin{subfigure}[b]{0.23\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/pdfs/27vs9_gemma_triviaqa_child_semantic_entropy.pdf}
 \end{subfigure}%
 \hfill
  \centering
\begin{subfigure}[b]{0.23\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/pdfs/27vs9_gemma_triviaqa_alice_semantic_entropy.pdf}
 \end{subfigure}
 \hfill
\centering
\begin{subfigure}[b]{0.23\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/pdfs/27vs9_gemma_triviaqa_child_prob.pdf}
  \caption{Gemma, Child}
  \end{subfigure}
  \hfill
  \centering
  \begin{subfigure}[b]{0.23\textwidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/pdfs/27vs9_gemma_triviaqa_alice_prob.pdf}
  \caption{Gemma, Alice-Bob}
 \end{subfigure}\\

 \caption{
Detection of \chk: Comparing Gemma-27B to Gemma-9B on TriviaQA. The results indicate that certainty levels are comparable and slightly higher for the larger model, Gemma-27B.}
 \label{fig:Hallucinations gemma}
\end{figure}


\paragraph{\chk also appears in larger models.}
Next, we conduct the same test on the larger Gemma-2-27B using TriviaQA in both settings.
The results are shown in Figure \ref{fig:Hallucinations gemma}. Evidently, the certainty levels of the Gemma-2-27B hallucinations are comparable to, and in some cases slightly higher than, those observed in Gemma-9B. This suggests that not only does this phenomenon exist in larger models, but it may also become more pronounced as model size increases. See Appendix \ref{appendix:chk Persists in Larger Models Additional Results} for similar results on the Natural Questions dataset.



\begin{table*}[t]
        \centering
        \begin{tabular}{l c cc cc cc}
        \toprule
        & & \multicolumn{2}{c}{Probability} & \multicolumn{2}{c}{Semantic Entropy} & \multicolumn{2}{c}{Probability Difference}\\ 
        \cmidrule(lr){3-4} \cmidrule(lr){5-6}\cmidrule(lr){7-8}
        Model&Dataset&\multicolumn{1}{c}{Random} & \multicolumn{1}{c}{Certain} & \multicolumn{1}{c}{Random} & \multicolumn{1}{c}{Certain}& \multicolumn{1}{c}{Random} & \multicolumn{1}{c}{Certain}\\
        \midrule 
\multirow{2}{*}{Llama}  &  TriviaQA  & 3.55 & \textbf{27.42} & 2.67 & \textbf{16.67} & 2.21 &\textbf{18.29}\\ 
 & NQ & 4.38 & \textbf{21.21} & 3.03 &  \textbf{7.14} &4.57 & \textbf{16.02}\\
\midrule
\multirow{2}{*}{Mistral}  &  TriviaQA  & 5.11 & \textbf{28.21} & 3.93 & \textbf{15.66} &  4.99 &\textbf{22.97}\\ 
 & NQ & 12.51 & \textbf{34.53} & 6.08 &  \textbf{15.14} &12.72 & \textbf{31.75}\\
\midrule  
\multirow{2}{*}{Gemma}  &  TriviaQA  & 3.46 & \textbf{22.99} & 3.39 & \textbf{14.29} & 1.83 &\textbf{17.24}\\ 
 & NQ & 5.74 & \textbf{26.52} & 3.71 &  \textbf{9.2} &5.6 & \textbf{22.11}\\
\midrule 
\multirow{2}{*}{Llama-Inst} &  TriviaQA  & 7.33 & \textbf{19.41} & 4.01 & \textbf{15.77}  & 6.58 &\textbf{18.05}\\ 
 & NQ & 7.25 & \textbf{18.08} & 4.59 &  \textbf{15.36} &6.82 & \textbf{17.34}\\
\midrule  
\multirow{2}{*}{Mistral-Inst} &  TriviaQA  & 8.03 & \textbf{36.48} & 7.26 & \textbf{19.05}& 7.24 &\textbf{34.49}\\ 
 & NQ & 11.05 & \textbf{31.46} & 11.29 &  \textbf{24.94} & 8.65 & \textbf{30.83}\\
\midrule  
\multirow{2}{*}{Gemma- Inst} &  TriviaQA  & 8.07 & \textbf{35.73} & 8.16 & \textbf{27.01} & 7.46 &\textbf{32.01}\\ 
 & NQ & 7.6 & \textbf{31.72} & 8.03 &  \textbf{25.42} &10.08 & \textbf{35.47}\\
\bottomrule
\end{tabular}
        \caption{Jaccard Similarity of \chk across different prompts. The \textit{Certain} columns shows the overall similarity of \emph{\chk} samples between prompts in the TriviaQA and NaturalQA datasets, using \emph{Probability}, \emph{Semantic entropy}, and \emph{Probability Difference} as the certainty thresholds. Results indicate high similarity, suggesting consistency across settings. All scores are statistically significant (permutation test, Random column, \(p < 0.0001\) for probability and probability difference,  \(p < 0.0007\) for semantic entropy).}
        \label{tab:jaccard}
\end{table*}





\subsection{\chk Cannot Be Explained as Noise}\label{sec:Certainty Hallucinations can not be Explain as Noise}
While the existence of \chk is apparent, a potential criticism is that these samples could merely reflect noise stemming from the natural correlation between uncertainty and hallucinations, rather than constituting a distinct and consistent subset. To address this, we evaluate the similarity of \chk examples across two distinct contexts: the Alice-Bob and Child settings. 

Hallucination and non-hallucination classifications 
differ significantly between these settings, with overall Jaccard similarity between their hallucinations ranging from 30\% to 50\%. Thus, finding consistent \chk samples across these diverse settings will suggest they are not artifacts of the uncertainty-hallucination correlation but instead represent a robust phenomenon.

We quantify this consistency using the Jaccard similarity of \chk across settings and validate its uniqueness with a permutation test on $10$K randomly sampled subsets of hallucination samples of equivalent size. The results confirm that \chk similarity between context settings exceeds random expectations, as can be seen in Table \ref{tab:jaccard}, using probabilities, semantic entropy, and probability difference certainty metrics. 
Appendix \ref{sec:appendix-Jaccard Similarity Additional Results} provides additional analyses, including results for only shared hallucination examples between the settings that further demonstrate the uniqueness of \chk.



