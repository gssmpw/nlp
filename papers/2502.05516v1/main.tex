% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%

\input{packages}
\input{macros}

\begin{document}
%
\title{Evaluating Differential Privacy on Correlated Datasets Using Pointwise Maximal Leakage}
%
\titlerunning{Evaluating DP on Correlated Datasets Using PML}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Sara~Saeidian \and Tobias~J.~Oechtering \and Mikael~Skoglund}
%
\authorrunning{S.~Saeidian et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{KTH Royal Institute of Technology, 100 44 Stockholm, Sweden\\
\email{\{saeidian,oech,skoglund\}@kth.se}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Data-driven advancements significantly contribute to societal progress, yet they also pose substantial risks to privacy. In this landscape, \emph{differential privacy} (DP) has become a cornerstone in privacy preservation efforts. However, the adequacy of DP in scenarios involving correlated datasets has sometimes been questioned and multiple studies have hinted at potential vulnerabilities. In this work, we delve into the nuances of applying DP to correlated datasets by leveraging the concept of \emph{pointwise maximal leakage} (PML) for a quantitative assessment of information leakage. Our investigation reveals that DP's guarantees can be arbitrarily weak for correlated databases when assessed through the lens of PML. More precisely, we prove the existence of a pure DP mechanism with PML levels arbitrarily close to that of a mechanism which releases individual entries from a database without any perturbation. By shedding light on the limitations of DP on correlated datasets, our work aims to foster a deeper understanding of subtle privacy risks and highlight the need for the development of more effective privacy-preserving mechanisms tailored to diverse scenarios.


\keywords{Pointwise maximal leakage  \and Differential privacy \and Correlated data.}
\end{abstract}
%
%
%
\section{Introduction}
\label{sec:intro}
\input{sections/intro}

\section{Preliminaries}
\label{sec:background}
\input{sections/background}

\section{Privacy for Correlated Databases: PML vs. DP}
\label{sec:main}
\input{sections/dp_pml}

\section{Conclusions}
\label{sec:discussion}
\input{sections/discussion}


\begin{credits}
\subsubsection{\ackname} This work has been supported by the Swedish Research Council (VR) under the grant 2023-04787 and Digital Futures center within the collaborative project DataLEASH. 


\subsubsection{\discintname}
The authors have no competing interests to declare that are
relevant to the content of this article.
\end{credits}
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{main}
%

\end{document}
