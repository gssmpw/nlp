\section{Case Studies }\label{sec:casestudies}
\subsection{Case Study I: Prime+iProbe and Flush+iReload Covert Channels with SMC}\label{subsec:case1}

In this case study, we exploit the SMC behavior on x86 processors to create a high bandwidth and low error rate covert channel utilizing Prime+Probe and Flush+Reload techniques. 

\noindent\textbf{Prime+iProbe.} We adopt the Prime+Probe approach to create our Prime+iProbe covert channel. First, the sender and the receiver agree on an L1i cache set to transmit the bits. Next, the sender fetches an instruction cache line from either the lower level cache (L2 or L3) or memory into the L1i cache set by executing an instruction if the transmitted bit is '1'. Otherwise, the sender performs a dummy function for a certain amount of time to send '0'. The receiver allocates a contiguous memory region and creates an eviction set with eight cache lines for the pre-determined set number by filling them with \textit{nop} instructions. During the prime phase, one \textit{nop} instruction is executed to place the cache lines into the L1i cache. In the probe phase, the receiver leverages one of the SMC primitives described in Section~\ref{sec:SMCAttack} to create the SMC conflict and measure the time for each cache line. If at least one of the cache lines produces a low execution time value, the sender transmits a '1' because the sender evicted one cache line belonging to the receiver, and no SMC conflict occurred for the evicted cache line. Otherwise, all cache lines will create SMC conflicts, leading to high \textit{rdtsc} timings. 

There are three parameters affecting the error rate and bandwidth: 1) \textit{The duration of dummy operations ($\tau_{d}$)} determines the length of the '0' bit. This duration should be long enough to ensure the receiver can observe the no-activity region in the cache set. 2) \textit{The number of loads ($N_l$)} for a single '1' bit transmission is crucial as the receiver may not be able to detect consecutive '1's. We prefer creating more than one load for a single bit to increase the chance of detecting consecutive '1's. 3) \textit{the waiting time between prime and probe phases ($\tau_{w}$)} is crucial to observe the activities in the L1i cache. If the receiver has a low waiting time in between, the probability of missing the L1i cache eviction caused by the sender increases gradually. In the meantime, more frequent pipeline flushes lead to slower sender time, eventually hurting the bandwidth. 

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{Sections/Figures/covert_channel.jpg}
    \Description{SMC timings measured by the receiver using Prime and LMS attack (blue line) and the automatically assigned bit values (red digits). The peaks for the 0s and 1s can be distinguished. This experiment is conducted in the Tiger Lake microarchitecture.}
    \caption{SMC timings measured by the receiver using Prime and LMS attack (blue line) and the automatically assigned bit values (red digits). The peaks for the 0s and 1s can be distinguished. This experiment is conducted in the Tiger Lake microarchitecture.}
    \label{fig:covert}
    
\end{figure}

\noindent\textbf{Evaluation.} Our test setup is based on the Intel Cascade Lake microarchitecture with a 32 KB instruction cache, 64 cache sets, and 8-way associativity. 
The duration of dummy operations for a single 0 bit is chosen as an empty for loop with $\tau_{d} = 10,000$ iterations. This duration leads to four samples per one '0', as shown in Figure~\ref{fig:covert}. 
Next, we determined that $N_l = 10$ loads create four consecutive low timings for the receiver. 
Finally, $\tau_{w} = 1,000$ iterations of an empty for loop is decided as the final value for the waiting time. This amount of waiting time is sufficient to detect the majority of load operations. As shown in Figure~\ref{fig:covert}, 0s and 1s can easily be transmitted between sender and receiver. The high time difference between low and high peaks also leads to a lower error rate in our covert channel, as shown in Table~\ref{tab:covert}. We achieve up to 189 Kbit/s with the Prime+iFlush covert channel, having only a 0.3\% error rate.

\begin{table}[h]
\small
\centering
\caption{SMC-based covert channels on instruction cache based on Flush+Reload and Prime+Probe attacks. The covert channels are created on the Intel Cascade Lake architecture. App. means applicability of the attack.}
\setlength{\tabcolsep}{5pt}
\scalebox{0.95}{
\begin{tabular}{l|c|c|c}
\textbf{Covert Channel} & \textbf{App.} & \textbf{Bit Rate (Kbit/s)} & \textbf{Error Rate (\%)} \\\hline
Prime+iFlush & $\checkmark$ & 188.9 & 0.3 \\\hline
Prime+iFlushopt & $\checkmark$ & 183.2 & 0.6 \\\hline
Prime+iLock & $\checkmark$ & 134.2 & 1.4 \\\hline
Prime+iPrefetch & $\checkmark$ & 120.1 & 1.2 \\\hline
Prime+iStore & $\checkmark$ & 123.2 & 0.6 \\\hline
Prime+iClwb & $\checkmark$ & 133.5 & 0.4 \\\hline
Flush+iFlush & $\checkmark$ & 660.2 & 0.9 \\\hline
Flush+iFlushopt & $\checkmark$ & 670.3 & 0.8\\\hline
Flush+iLock & $\times$ & N/A & N/A \\\hline
Flush+iPrefetch & $\checkmark$ & 452.7 & 0.4\\\hline
Prime+iStore & $\times$ & N/A & N/A \\\hline
FLush+iClwb & $\checkmark$ & 203.6 & 1.8\\\hline

\end{tabular}
}
\label{tab:covert}
%\vspace{-5mm}
\end{table}

\noindent\textbf{Flush+iReload.} We implement Flush+iReload covert channels based on the Flush+Reload technique. We create a shared code page filled with \textit{nop} instructions between two processes with read and execute permissions similar to a shared library structure in OS. This setup is similar to Flush+Reload attack scenarios in which the deduplication mechanism merges the same read-only code pages in the memory~\cite{irazoqui2014wait}. The sender executes an instruction in the shared code page to $N_l = 10$ times to send a single '1' bit. For the '0' bit, the sender executes an empty for loop with $\tau_d = 10,000$. The receiver executes SMC-creating instructions except \texttt{store} and \texttt{lock} as the code page has no write permission. 
As there is only one cache line used to transmit the bits, we can achieve a faster transmission rate with Flush+iReload channels.

\noindent\textbf{Evaluation.} We compare the covert channel bandwidth with various SMC-based covert channels as given in Table~\ref{tab:covert}. The Prime+iFlush side-channel achieves the highest bandwidth with 188.9 Kbit/s while creating a low error rate among Prime+iProbe techniques. Similarly, Prime+iFlushopt achieves a high bandwidth and low error rate. Prime+iLock leads to a higher error rate and lower bandwidth compared to flush-based SMC since the lock instruction creates a higher time difference, as given in Figure~\ref{fig:CPUcycleTime_cascade}, which results in spending more time probing the cache lines. 

Both Flush+iFlush and Flush+iFlushopt channels achieve around 660 Kbit/s transmission rate with less than 1\% error rate. The Flush+iPrefetch technique is comparably slower than flush-based covert channels since the \texttt{prefetch} instruction requires the \texttt{clflush} instruction to be executed before the cache line is brought into the L1i cache in order to create an SMC conflict. 
Finally, the \texttt{clwb} instruction requires more repetitions from the sender process to create distinguishable 0s and 1s. We tripled the number of executions and empty for loop size in the sender process to increase the signal-to-noise ratio, resulting in around 200 Kbit/s transmission rate. We also evaluated the Prime+iLock covert channel on the AMD Ryzen 5 microarchitecture. We observed that the covert channel is more noisy than on Intel Cascade Lake. One of the reasons is that we utilized the \textit{rdtsc} instruction to measure the time of executing lock and store instructions, which has 21 cycles resolution in our setup. Hence, the time difference between SMC and non-SMC behavior is less distinctive, leading to a bandwidth of 98.2 Kbit/s with a 2.5\% error rate.

\subsection{Case Study II: RSA Key Recovery}\label{subsec:case2}

In this case study, we describe how Prime+iProbe attacks can be utilized to perform an end-to-end side-channel attack. The experiments were performed on the Intel Tiger Lake microarchitecture to show that our attack is feasible in different microarchitectures.

\noindent\textbf{Step 1: Vulnerable Library Detection} In this part, we explore how the Prime+iStore attack can detect the targeted cryptographic library as well as its version. 
We assume that the victim uses one of the most popular libraries (OpenSSL or Libgcrypt) for the RSA decryption task while the attacker aims to identify the correct library and version. 

In the offline phase, we randomly selected 14 library versions from Libgcrypt and 20 versions from OpenSSL. 
We monitor all L1i cache sets in order, starting from set 0. We collect 100 Prime+iStore timings from each set, resulting in 6400 samples from 64 sets.
Next, we convert the timings to hit and miss based on the threshold (100 cycles for Tiger Lake). 
The number of activities in each set is summed up, and 64 activity values are created for each measurement. For each library version, we collected 8 measurements with varying decryption keys, resulting in 272 measurements in total. This dataset is used to train a k-th nearest neighbor (kNN) machine learning model. The model is trained with cross-validation, three closest neighbors, and Euclidean distance parameters, which achieved 100\% accuracy during the cross-validation process.

In the online phase, the attacker aims to detect the correct library version with only one measurement. We collected two measurements for each library and converted them to activity traces. The resulting feature vectors are then classified with the pre-trained model. We achieved 97\% accuracy in detecting the correct library. Note that there are slight differences between close library versions, making it more challenging to detect the correct library. However, the memory offsets for different functions used by each library differ, which creates a distinct fingerprint for each library. 

\begin{figure}[t]
    \centering
    {
    \includegraphics[width=\linewidth]{Sections/Figures/SMC_RSA_bits.jpg}
    }
    \caption{Low timing values indicate that there is a multiplication activity as one of the cache lines is evicted from the L1i cache. The experiment is performed on Intel Tiger Lake with the Prime+iStore attack.}
    \Description{Low timing values indicate that there is a multiplication activity as one of the cache lines is evicted from the L1i cache. The experiment is performed on Intel Tiger Lake with the Prime+iStore attack.}
    \label{fig:RSA_bits}
\end{figure}

\noindent\textbf{Step 2: Multiplication Set Detection.}  It is crucial for an adversary to detect the L1i cache set used for multiplications. For this purpose, we profiled the Libgcrypt 1.5.1 RSA implementation. In the offline phase, we collect measurements consisting of 20,000 samples from each set with the Prime+IStore technique. 
The number of activities (cache misses) in each cache set is recorded to create the feature vector as depicted in Figure~\ref{fig:RSA_bits}. We collected 500 measurements from cache sets used for the multiplication operation and 500 more measurements from other cache sets. The dataset is divided into training (80\%) and test (20\%) datasets to train a binary classification kNN model. %The kNN model is trained for  to distinguish between the target set and other sets with the same parameters as the previous scenario. 
In the online phase, the attacker collects measurements from different sets and aims to detect the cache set used for multiplication. The kNN model can detect the correct set with a 96\% success rate. We further collected measurements from older versions of Libgcrypt, and the success rate remains the same. 

\begin{figure}[t]
    \centering
    {
    \includegraphics[width=\linewidth]{Sections/Figures/Traces_vs_Success_Rate.jpg}
    }
    \caption{The number of traces required to achieve 70\% key recovery rate for Flush, Store, Lock and Clwb-based SMC attacks on Intel Tiger Lake.}
    \Description{A graph showing the number of traces required to achieve a 70\% key recovery rate for Flush, Store, Lock, and Clwb-based SMC attacks on Intel Tiger Lake.}
    \label{fig:RSA_success_rate}
\end{figure}

\noindent\textbf{Step 3: RSA Key Recovery.} This step is implemented with several Prime+iProbe attacks to demonstrate the 2048-bit RSA decryption key recovery from the Libgcrypt 1.5.1 library by profiling multiplication operations. 

Our key recovery attack consists of several steps. In the first step, we decide the amount of time needed to be placed between the Prime and Probe steps. We identify both the slow-down amount on the RSA decryption process and the number of multiplication operations detected by the attack with different wait times. When the wait time is high, the RSA decryption process runs faster, limiting the attack's resolution and missing several multiplication function calls. If the wait time is very low, the RSA decryption runs very slowly, and multiplication function calls are less likely to be detected, leading to a smaller number of activities. We determined that an empty \textit{for} loop with 700 iterations between the Prime and Probe phases fulfilled our requirements. The time difference between multiplication operations increased by five times while one Prime+iProbe sample collection takes around 7000 cycles. 
We expect to have three Prime+iProbe samples without any activity if there are two multiplications consecutively ('11'). The number of no-activity samples is increased by 2 for each 0 bit between two consecutive multiplications. Hence, our attack can be performed on the RSA decryption process with a sufficient resolution. 


In the second step, we collect Prime+iProbe samples while running the decryption process. When the multiplication function (\textit{mul\_n}) is called, at least one attacker-controlled cache line is evicted from the profiled cache set. When this cache line is invalidated with one of the SMC techniques, it takes less time to execute the specific operation since SMC conflict does not occur on that line. We collect multiple traces to recover a large portion of the 2048-bit RSA decryption key. As shown in Figure~\ref{fig:RSA_success_rate}, a single trace is successful in leaking 63\% of the RSA key when the Prime+iFlush attack is performed. As stated in previous works~\cite{yarom2014flush+,inci2015seriously}, recovering at least 70\% of the decryption bits is sufficient for attackers to leak the entire RSA decryption key. With the increasing number of traces, an attacker can reach up to 70\% secret key recovery while the number of required traces changes depending on the attack type. We observed that the Prime+iFlush attack only needs 10 traces to recover 70\% of the bits. Similarly, the Prime+iStore attack needs around 13 traces to recover 70\% of the bits correctly. On the other hand, Prime+iLock requires 20 traces to leak 70\% of the bits. We noticed that the relatively poor performance of the Prime+iLock attack is due to the high number of missed multiplication activities compared to other attacks. 
We also noticed that the \texttt{clwb} instruction takes a longer time, leading to more noisy samples as the time between prime and probe stages increases in parallel. 
Note that our attack does not assume that there is a shared memory page between the attacker and victim, which leads to a higher noise amount compared to Flush+Reload attacks. More interestingly, our Prime+Probe attack does not increase the last-level cache miss counters significantly, making it difficult for the current performance counter-based defense mechanisms to detect our attack as discussed in Section~\ref{sec:dynamic_detection}.



\subsection{Case Study III: OpenSSL SRP Single Trace Attack}\label{subsec:case3}
In this section, we leverage the Prime+iProbe attack to leak a secret key with only a single trace collected from the Secure Remote Password (SRP) protocol in OpenSSL. OpenSSL SRP protocol is used for secure password-based authentication between a client and server without transmitting the actual password, enhancing security against eavesdropping and replay attacks~\cite{wu1998secure,taylor2007using}. 

Both client and server compute a shared key to authenticate each other without sharing a password. In the registration phase, first, a publicly known group $G$ of prime order $p$ and a generator $g$ are created. Then, a hash function is used to compute a group related parameter $k=H(g\,||\,p)$. A verifier is calculated by the server v = $g^x\,mod\,p$ where $x = H(salt\,||\, H(client\_id\,||\,pwd))$. $pwd$ belongs to the client and the server does not have access to the $pwd$. Hence, the server keeps the password in the form $(client\_id,\,v,\,salt)$. In the login phase, the client generates a random number $a$ uniformly chosen from $(1,p-1)$, computes $A=g^a \,mod\,p$ and sends it to the server. Then, the server generates a secret random number $b$ chosen from $(1, p-1)$, computes $B=kv + g^b\,mod \,p$ and sends both the salt and $B$ to the client. Finally, the client recovers the verifier $v = g^x\,mod\,p$. If the secret exponent $b$ can be recovered by an attacker, a malicious server can be generated to authenticate the clients and access confidential information from the clients. Since $b$ is secret and randomly chosen for each authentication, an attacker needs to leak $b$ with a single trace, which is the target in our attack.
\begin{lstlisting}[caption={Implementation of the \texttt{SRP\_Calc\_server\_key} function in OpenSSL v1.1.1w SRP library.}, label=lst:SRP_library, language=Python, basicstyle=\ttfamily\scriptsize, basewidth={.48em}, backgroundcolor=\color{white}]
def SRP_Calc_server_key(A, v, u, b, N):
    BIGNUM *tmp = NULL, *S = NULL;
    BN_CTX *bn_ctx;
    
    # S = (Av^u)^b mod N
    BN_mod_exp(tmp, v, u, N, bn_ctx)
    BN_mod_mul(tmp, A, tmp, N, bn_ctx)
    
    S = BN_new();
    BN_mod_exp(S, tmp, b, N, bn_ctx) 
    
    return S; 
\end{lstlisting}

Even though the client implementation was exploited to leak passwords~\cite{de2021parasite} and then patched by setting the constant time flag within the client key generation function \texttt{SRP\_Calc\_client\_key}, the server-side key generation \texttt{SRP\_Calc\_server\_key} still remains unprotected against timing attacks as given in Listing~\ref{lst:SRP_library}. The omission of \texttt{BN\_\allowbreak FLG\_\allowbreak CONSTTIME} flag allows attackers to leak the server's private key exponent bits (\textit{b} in the Listing~\ref{lst:SRP_library}).

In the \texttt{SRP\_Calc\_server\_key} function, modular exponentiation is executed using the \texttt{BN\_mod\_exp\_mont} function to compute the server's shared secret key, $S=(A*v^u)^b\,mod\, N$. The algorithm processes the bits of the secret exponent \textit{p} (the binary representation of \textit{b}) from the most significant bit (MSB) to the least significant bit (LSB), using sliding window exponentiation. The square operation (\texttt{bn\_mul\_mont\_fixed\_top (r, r, r, mont, ctx)}) is executed if the \texttt{BN\_is\_bit\_set} function returns 0 (Line 3 and Line 12 in Listing~\ref{lst:BN_mod_exp_mont}). Conversely, if the bit is '1', the algorithm accumulates a window of bits with a maximum size of 6, \texttt{wvalue}, to reduce the number of multiplications while executing consecutive square operations for the number of bits in the window before the multiplication. Hence, the number of bits in each window leads to a variable timing from Line 9 to Line 20 in Listing~\ref{lst:BN_mod_exp_mont}. Our attack relies on the elapsed time between each execution of the jump instruction associated with the infinite loop in Line 2 since the operations (squares and multiplications) based on the secret (\textit{p}) bits lead to varying time differences. 
\begin{lstlisting}[caption={The implementation of the \texttt{BN\_mod\_exp\_mont} function in \texttt{/crypto/bn/bn\_exp.c}} OpenSSL-1.1.1w. The code has been modified as a Python-like syntax to save space., label=lst:BN_mod_exp_mont, language=Python, basicstyle=\ttfamily\scriptsize, basewidth={.48em}, backgroundcolor=\color{white}]
def BN_mod_exp_mont(rr, a, p, m, ctx, in_mont):
    while True:
        if not BN_is_bit_set(p, wstart):
        # Square
            if not bn_mul_mont_fixed_top(r, r, r, mont, ctx): 
            wstart -= 1
            continue
        # Window 
        for i in range(1, window):
            if wstart - i < 0:
                break
            if BN_is_bit_set(p, wstart - i):
                wvalue <<= (i - wend)
                wvalue |= 1
                wend = i
        # Square
        for _ in range(wend + 1):
            if not bn_mul_mont_fixed_top(r, r, r, mont, ctx): 
        # Multiply
        if not bn_mul_mont_fixed_top(r, r, val[wvalue >> 1], mont, ctx):
\end{lstlisting}


\noindent\textbf{Experiment Setup.} Our experiments were performed on an Intel Tiger Lake microarchitecture running Ubuntu 22.04 with 16GB RAM. We utilized OpenSSL 1.1.1w (up-to-date) to ensure our findings are relevant to current implementations. 

\noindent\textbf{Results.} Our attack relies on the Prime+iStore attack. Since the server calculates the shared key only once for each client, our purpose is to leak as many bits as we can in one trace and then recover the remaining bits as explained in~\cite{de2021parasite,yarom2014flush+,inci2015seriously}. The address of the "jump" instruction associated with the infinite for loop is determined through the disassembled version of the \texttt{libcrypto.so} binary to monitor the specific instruction cache set. Next, an authentication request to the server is sent to calculate the shared key. We assume that the server process and the attacker share the same physical core as described in Section~\ref{sec:Threat Model}. In the meantime, the attacker starts executing the Prime+IStore attack. 

The server's secret key ($b$) size is determined by the group size. While a larger group size provides better security, the incurred performance overhead increases in parallel. We tested our attack with four different group sizes: 1024, 2048, 4096, and 6144.
We manually set static values for the client's public ephemeral value (\textit{A}), username, password, and salt while the server's private keys (\textit{b}) are generated randomly.

The time difference between each iteration is 500-600 cycles for back-to-back square operations when two consecutive bits are "00" with a group size of 1024. When the Prime+IStore attack runs in parallel, the time difference increases to 2000 cycles due to frequent core resource flushes. This performance degradation enables the attacker to collect at least one sample between each square. When a sliding window operation is executed, the multiplication takes 6000 cycles and each additional bit in the window takes 2000 cycles. Hence, our attack has sufficient resolution to detect activities in each iteration even with the smallest group size. However, it is not possible to know which array entry is accessed for the window multiplication, leading to unknown bits in each window. If the window size is 6, the middle four bits "1XXXX1" are unknown. Based on our experiments, the randomly generated keys have around 45\% unknown bits that cannot be leaked through the instruction cache channel. Still, an attacker can perform dictionary search and mathematical algorithms to leak the entire key~\cite{inci2015seriously,de2021parasite}. 

In total, 100 random keys (\textit{b}) were created for each group/key size. Each secret key is profiled only once and the success rate of each single-trace key recovery attack is recorded. Interestingly, the time difference between consecutive square operations and square+multiply instances increases when the group size becomes larger. It means that higher group sizes give better resolution for the attacker. For instance, there is a 20,000-25,000 cycle difference between each square when the group size is set to 6,144, which is much larger than the size of 1,024, leading to longer traces for an attacker to extract the key. Hence, the attacker adjusts the key extraction process based on the time difference distribution between the activities. There are seven patterns that need to be distinguished based on the time differences: "0", "1", "11", "1X1", "1XX1", "1XXX1", "1XXXX1". The time difference increases for each pattern as more operations are involved, leading to more samples without any activity between each cache miss as shown in Figure~\ref{fig:SRP}.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{Sections/Figures/trace_6144_prime_istore.jpg}
    
    \caption{The cache activity monitored by the Prime+IStore attack during the secret exponent computation with the 6144 group size. "X" bits represent the unknown bits in the window multiplicand.}
    \Description{The cache activity monitored by the Prime+IStore attack during the secret exponent computation with the 6144 group size. "X" bits represent the unknown bits in the window multiplicand.}
    \label{fig:SRP}
    
\end{figure}

\begin{table}[h]
\small
\centering
\caption{Leakage rates obtained with Mastik~\cite{yarom2016mastik} and Prime+IStore attacks for different group sizes in the SRP\_Calc\_Server\_Key function for the OpenSSL-1.1.1w implementation.}
\setlength{\tabcolsep}{5pt}
%\scalebox{0.9}{
\begin{tabular}{l|c|c|c|c|}
\cline{2-5}
& \multicolumn{4}{c|}{\textbf{Group Size (bits)}} \\
\cline{2-5}
%\hline
& \textbf{1024} & \textbf{2048} & \textbf{4096} & \textbf{6144} \\\hline\hline
\multicolumn{1}{|l|}{\textbf{Prime+IStore}} & 65\% & 73\% & 83\% & 90\% \\\hline
\multicolumn{1}{|l|}{\textbf{Mastik (PnP)}} & 22\% & 31\% &  37\% & 48\%  \\\hline
\end{tabular}
%}
\label{tab:SRP_leak}
\end{table}

An attacker can leak up to 90\% of the possible bits in a given secret exponent with the Prime+IStore attack, which is calculated over 100 keys. The highest leakage rates are achieved on the largest group size as the time difference between each pattern increases significantly, leading to less noisy traces. The lowest leakage rate is 65\% for the key size of 1024 as given in Table~\ref{tab:SRP_leak}. We also compare the Prime+IStore attack with the Prime+Probe (PnP) attack from the Mastik tool. The PnP attack is noisier compared to our attack because L1i cache hits and misses cannot be reliably distinguished, as shown in Figure~\ref{fig:CPUcycleTime_cascade}. Hence, we selected a threshold for the miss/hit classification by matching the expected number of cache misses to the actual cache misses obtained from reverse engineering. Moreover, the number of outliers is much higher compared to the Prime+IStore attack. As a result, PnP can leak up to 48\% of the possible bits, which is considerably lower than our attack. Our results show that with the Prime+IStore technique a single trace attack can be performed with high accuracy.

\begin{table*}[t]
\centering
\caption{Comparative analysis of SMC-ISpectre Attack Vulnerability across diverse Microarchitectures through various strategies. An $\times$ indicates unsupported instructions. Secrets leaked without SMC behavior are marked with $\LEFTcircle$, while successful SMC-ISpectre attacks are denoted by $\CIRCLE$.}
%\seonghun{AMD Ryzen SMC on flush flushopt need to be checked by the counters}
\setlength{\tabcolsep}{7pt}
\scalebox{0.65}{
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c}
%\hline
\textbf{}            & \textbf{Westmere EP} & \textbf{Sandy Bridge} & \textbf{Ivy Bridge} &\textbf{Broadwell}  & \textbf{Ice Lake} &\textbf{Cascade Lake}&\textbf{Comet Lake}& \textbf{AMD Ryzen 5} &\textbf{AMD EPYC 7232P}&\textbf{Tiger Lake}\\ \hline
\textbf{Load}        & $\LEFTcircle$ & $\LEFTcircle$ & $\LEFTcircle$ & $\LEFTcircle$ & $\LEFTcircle$ & $\LEFTcircle$& $\LEFTcircle$ & $\LEFTcircle$ & $\LEFTcircle$& $\LEFTcircle$\\ \hline
\textbf{Flush}       & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$ &  $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$ &$\LEFTcircle$& $\CIRCLE$\\ \hline
\textbf{FlushOPT}    & $\CIRCLE$ & $\CIRCLE$ & $\times$ & $\times$  & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$ & $\LEFTcircle$& $\CIRCLE$\\ \hline
\textbf{Store}       & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$  & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$& $\CIRCLE$& $\CIRCLE$\\ \hline
\textbf{Lock}     & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$  & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$ & $\CIRCLE$& $\CIRCLE$& $\CIRCLE$\\ \hline
\textbf{Prefetch}    & $\Circle$ & $\Circle$ & $\Circle$ & $\CIRCLE$  & $\Circle$ & $\CIRCLE$ & $\CIRCLE$ &$\LEFTcircle$& $\LEFTcircle$& $\Circle$ \\ \hline
\textbf{PrefetchNTA} & $\Circle$ & $\Circle$ & $\Circle$ & $\Circle$  & $\Circle$ & $\LEFTcircle$ & $\LEFTcircle$ &$\LEFTcircle$& $\LEFTcircle$ & $\Circle$ \\ \hline
\textbf{Execute}     & $\Circle$ & $\Circle$ & $\Circle$ & $\Circle$  & $\Circle$ & $\Circle$ & $\Circle$ & $\Circle$ & $\Circle$& $\Circle$\\ \hline
\textbf{Clwb}     & $\times$ & $\times$ & $\times$ & $\times$  &$\times$ & $\CIRCLE$ & $\Circle$ & $\Circle$ & $\LEFTcircle$ & $\CIRCLE$ \\ \hline
\end{tabular}
}
\label{table:Spectre_attacks}
\end{table*}

\subsection{Case Study IV: ISpectre Attack}\label{subsec:case4}
In this section, we leverage Flush+iReload attacks in the context of the Spectre v1. 
We exploit the Pattern History Table (PHT)~\cite{canella2019systematic}, which predicts the outcome of conditional branch instructions.
The original Spectre v1 variant is designed to leak information from the data cache by accessing out-of-bound array elements and encoding the secret value to different memory pages.
However, \texttt{ISpectre} attack exploits an indirect \texttt{call} instruction based on the value of the shared oracle code page array, which not only aims to access unauthorized memory but also aims to execute the code located at an address that is determined speculatively by the branch prediction unit as given in Listing~\ref{lst:conditional_assembly}.
Since we leak the secret from the L1i cache sets, traditional shared cache-focused defenses are insufficient~\cite{ren2021see} against ISpectre.

\noindent\textbf{Experiment Setup.} \texttt{ISpectre} experiments are conducted on various microarchitectures as shown in Table~\ref{table:Spectre_attacks}. In total, we test 8 Intel and 2 AMD microarchitectures to evaluate our attack. All experiments are conducted on the Ubuntu 20.04.6 LTS operating system with default configuration. All microarchitectures (microcode code 0x5003707 in Intel Cascade Lake) are patched with their vendors' latest Spectre defense mechanisms.



\noindent\textbf{ISpectre.} In the \texttt{ISpectre} attack, the branch instruction in the \texttt{victim\_function} is mistrained with in-bound values and the indirect function call is executed by accessing \texttt{oracle\_code\_page} with the predefined offset size (notsecret[index] $\times$ cache line size).  
Next, the adversary supplies an out-of-bound \texttt{index} value, leading to the execution of an out-of-bound memory location with the predefined offset.
Once the victim function executes the instruction in this memory region, the cache line is speculatively brought to the L1i cache.
This behavior acts as the encoding of the secret into an instruction cache line.
Next, the attacker performs the Flush+iReload profiling on all the instruction cache lines in the \texttt{oracle\_code\_page} and measures the execution time.
If the execution time is higher than a threshold, the secret character is already encoded into that offset in the \texttt{oracle\_code\_page}, which was brought to the L1i cache.



\begin{lstlisting}[language=C, caption={C Code snippet for the victim function executing an indirect branch instruction}, label=lst:conditional_assembly,basicstyle=\ttfamily\scriptsize, basewidth={.48em}, backgroundcolor=\color{white}]
asm volatile( "call *%0\n" 
: : "c"(oracle_code_page + notsecret[index] * CACHE_LINE_SIZE):"rax");}
\end{lstlisting}

\noindent\textbf{Evaluation.} 
Our attack can exploit \texttt{flush}, \texttt{flushopt}, \texttt{store}, \texttt{lock}, and \texttt{prefetch} instructions to create SMC conflict and distinguish the execution time between L1i cache hit and DRAM access on various x86 microarchitectures as given in Table~\ref{table:Spectre_attacks}. 
The attacker measures the time it takes to execute each cache line associated with the secret byte and distinguishes the correct secret.
Even though \texttt{load}, \texttt{prefetchnta}, and \texttt{execute} instructions do not create an SMC conflict, \texttt{load} can still leak secret characters, which is illustrated with a half circle in Table~\ref{table:Spectre_attacks}. 
Both \texttt{lock} and \texttt{store} instructions are successful at leaking the secret bytes in all x86 microarchitectures. 
As the \texttt{clwb} instruction is not available in older generations of Intel microarchitectures, it is not suitable for the Spectre attacks. 
The \texttt{flush} operations are also successful at leaking the secret bytes except for the AMD EPYC 7232P microarchitecture, in which the flush instructions have no effect on the SMC conflicts.

The highest leakage rate is 3161 B/s with the \texttt{lock} instruction as given in Table~\ref{tab:spec_leak}. We also achieve up to 3109 B/s leakage rate with the Flush+iFlushopt attack with an average success rate of 98.37\%. Furthermore, the \texttt{Flush+iFlushopt} attack reveals secret bytes with 4105.84 B/s on AMD Ryzen 5. This performance surpasses TLB-Evict+Prefetch attack~\cite{lipp2022amd}, which recovers 96.7\% rate at 58.98 B/s, and outperforms Lipp et al.~\cite{lipp2020take} of 0.66B/s on the same AMD microarchitecture.
Notably, non-SMC Spectre attacks are also feasible to leak secret bytes in the L1i cache. 

\begin{table}[h]
\small
\centering
\caption{Spectre-v1 leakage rates for Flush+iReload attacks. The leakage rates are given in B/s. The experiments are conducted on Intel Cascade Lake and AMD Ryzen 5 processors.}
\setlength{\tabcolsep}{5pt}
\scalebox{0.9}{
\begin{tabular}{l|c|c|c|c|c|c}
\textbf{Processor} & \textbf{Flush} & \textbf{Flushopt} & \textbf{Store} & \textbf{Lock} & \textbf{Prefetch} & \textbf{Clwb} \\\hline
\textbf{Intel CL} & 1513 & 3109 & 2039 & 3161 & 1556 & 
 2974 \\\hline
\textbf{AMD Ryzen} & 4045 & 4105 & 1382 & 2168 & N/A & N/A \\\hline
\end{tabular}
}
\label{tab:spec_leak}

\end{table}
