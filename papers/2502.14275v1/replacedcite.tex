\section{Related Work}
\begin{figure*}[!ht]
    \centering
    \vspace{-1em}
    \resizebox{\textwidth}{!}{
        \includegraphics[width=\textwidth]{figures/dataset_pipeline.pdf}
    }
    % \includegraphics[0.5\textwidth]{figures/dataset_pipeline.pdf}
    \caption{Pipeline for the \mkj dataset construction.}
    \label{fig:pipeline}
    \vspace{-1em}
\end{figure*}


\paragraph{Benchmarks} Most works that study the factuality of LLMs use existing question-answering (QA) benchmarks such as WebQuestions____, TriviaQA____, LC-QuAD____, Natural Questions____, and EntityQuestions____. 
There are also new QA benchmarks assessing LLMs' long-tail knowledge factuality____. 
For medical QA datasets, ____ build MMedBench, a multilingual medical multi-choice QA benchmark with rationales, which involves the aggregation of various medical multi-choice QA datasets from multiple languages____. 
There are also some benchmarks involving more challenging medical questions such as the clinical topics datasets of MMLU____ and MedMCQA____. However, these datasets mostly contain multi-hop or indirect relationship questions, assessing more about skilled reasoning abilities of LLMs.
Compared with these benchmarks, \mkj{} focuses on fundamental evaluation by one-hop direct medical knowledge judgments and contributes to the growing body of work on LLM evaluation by systematically leveraging knowledge graphs.
% to assess LLMs' inherent medical expertise.




\paragraph{LLMs in Medicine}
To apply LLMs on different tasks in general medical and healthcare contexts, some approaches are adopted such as prompt engineering____ and fine-tuning LLMs with domain-specific data____.
There are also some work integrating medical knowledge graphs to assist LLMs on tasks such as medical question answering____ and diagnosis prediction____.
While existing efforts have focused on enhancing LLMs' performances across diverse tasks, a fundamental assessment of their capabilities to internalize and apply medical knowledge remains relatively limited. To address this gap, we introduce the \mkj dataset.
% However, these works focus more on improving the performances across various tasks and a fundamental assessment of LLMs' capabilities to internalize medical knowledge remains somewhat limited. To this end, we propose \mkj.