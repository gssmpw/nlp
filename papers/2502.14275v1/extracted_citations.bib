@article{afshar2024role,
  title={On the role of the UMLS in supporting diagnosis generation proposed by Large Language Models},
  author={Afshar, Majid and Gao, Yanjun and Gupta, Deepak and Croxford, Emma and Demner-Fushman, Dina},
  journal={Journal of Biomedical Informatics},
  volume={157},
  pages={104707},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{berant2013semantic,
  title={Semantic parsing on freebase from question-answer pairs},
  author={Berant, Jonathan and Chou, Andrew and Frostig, Roy and Liang, Percy},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1533--1544},
  year={2013}
}

@inproceedings{blinov2022rumedbench,
  title={RuMedBench: A Russian Medical Language Understanding Benchmark},
  author={Blinov, Pavel and Reshetnikova, Arina and Nesterov, Aleksandr and Zubkova, Galina and Kokh, Vladimir},
  booktitle={International Conference on Artificial Intelligence in Medicine},
  pages={383--392},
  year={2022}
}

@misc{chen2023meditron70b,
      title={MEDITRON-70B: Scaling Medical Pretraining for Large Language Models}, 
      author={Zeming Chen and Alejandro Hernández-Cano and Angelika Romanou and Antoine Bonnet and Kyle Matoba and Francesco Salvi and Matteo Pagliardini and Simin Fan and Andreas Köpf and Amirkeivan Mohtashami and Alexandre Sallinen and Alireza Sakhaeirad and Vinitra Swamy and Igor Krawczuk and Deniz Bayazit and Axel Marmet and Syrielle Montariol and Mary-Anne Hartley and Martin Jaggi and Antoine Bosselut},
      year={2023},
      eprint={2311.16079},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{chen2024cod,
  title={CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis},
  author={Chen, Junying and Gui, Chi and Gao, Anningzhe and Ji, Ke and Wang, Xidong and Wan, Xiang and Wang, Benyou},
  journal={arXiv preprint arXiv:2407.13301},
  year={2024}
}

@inproceedings{dubey2019lc,
  title={Lc-quad 2.0: A large dataset for complex question answering over wikidata and dbpedia},
  author={Dubey, Mohnish and Banerjee, Debayan and Abdelkawi, Abdelrahman and Lehmann, Jens},
  booktitle={The Semantic Web--ISWC 2019: 18th International Semantic Web Conference, Auckland, New Zealand, October 26--30, 2019, Proceedings, Part II 18},
  pages={69--78},
  year={2019},
  organization={Springer}
}

@article{gao2023leveraging,
  title={Leveraging a medical knowledge graph into large language models for diagnosis prediction},
  author={Gao, Yanjun and Li, Ruizhe and Caskey, John and Dligach, Dmitriy and Miller, Timothy and Churpek, Matthew M and Afshar, Majid},
  journal={arXiv preprint arXiv:2308.14321},
  year={2023}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{jin2021disease,
  title={What disease does this patient have? a large-scale open domain question answering dataset from medical exams},
  author={Jin, Di and Pan, Eileen and Oufattole, Nassim and Weng, Wei-Hung and Fang, Hanyi and Szolovits, Peter},
  journal={Applied Sciences},
  volume={11},
  number={14},
  pages={6421},
  year={2021},
  publisher={MDPI}
}

@inproceedings{joshi2017triviaqa,
  title={TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension},
  author={Joshi, Mandar and Choi, Eunsol and Weld, Daniel S and Zettlemoyer, Luke},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1601--1611},
  year={2017}
}

@article{kasai2023evaluating,
  title={Evaluating gpt-4 and chatgpt on japanese medical licensing examinations},
  author={Kasai, Jungo and Kasai, Yuhei and Sakaguchi, Keisuke and Yamada, Yutaro and Radev, Dragomir},
  journal={arXiv preprint arXiv:2303.18027},
  year={2023}
}

@article{kumar2024automatic,
  title={Automatic question-answer generation for long-tail knowledge},
  author={Kumar, Rohan and Kim, Youngmin and Ravi, Sunitha and Sun, Haitian and Faloutsos, Christos and Salakhutdinov, Ruslan and Yoon, Minji},
  journal={arXiv preprint arXiv:2403.01382},
  year={2024}
}

@article{kwiatkowski2019natural,
  title={Natural questions: a benchmark for question answering research},
  author={Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={453--466},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{labrak-etal-2022-frenchmedmcqa,
    title = "{F}rench{M}ed{MCQA}: A {F}rench Multiple-Choice Question Answering Dataset for Medical domain",
    author = "Labrak, Yanis  and
      Bazoge, Adrien  and
      Dufour, Richard  and
      Daille, Beatrice  and
      Gourraud, Pierre-Antoine  and
      Morin, Emmanuel  and
      Rouvier, Mickael",
    editor = "Lavelli, Alberto  and
      Holderness, Eben  and
      Jimeno Yepes, Antonio  and
      Minard, Anne-Lyse  and
      Pustejovsky, James  and
      Rinaldi, Fabio",
    booktitle = "Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.louhi-1.5/",
    doi = "10.18653/v1/2022.louhi-1.5",
    pages = "41--46",
    abstract = "This paper introduces FrenchMedMCQA, the first publicly available Multiple-Choice Question Answering (MCQA) dataset in French for medical domain. It is composed of 3,105 questions taken from real exams of the French medical specialization diploma in pharmacy, mixing single and multiple answers. Each instance of the dataset contains an identifier, a question, five possible answers and their manual correction(s). We also propose first baseline models to automatically process this MCQA task in order to report on the current performances and to highlight the difficulty of the task. A detailed analysis of the results showed that it is necessary to have representations adapted to the medical domain or to the MCQA task: in our case, English specialized models yielded better results than generic French ones, even though FrenchMedMCQA is in French. Corpus, models and tools are available online."
}

@inproceedings{malaviya-etal-2024-expertqa,
    title = "{E}xpert{QA}: Expert-Curated Questions and Attributed Answers",
    author = "Malaviya, Chaitanya  and
      Lee, Subin  and
      Chen, Sihao  and
      Sieber, Elizabeth  and
      Yatskar, Mark  and
      Roth, Dan",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.167",
    doi = "10.18653/v1/2024.naacl-long.167",
    pages = "3025--3045",
    abstract = "As language models are adopted by a more sophisticated and diverse set of users, the importance of guaranteeing that they provide factually correct information supported by verifiable sources is critical across fields of study. This is especially the case for high-stakes fields, such as medicine and law, where the risk of propagating false information is high and can lead to undesirable societal consequences. Previous work studying attribution and factuality has not focused on analyzing these characteristics of language model outputs in domain-specific scenarios. In this work, we conduct human evaluation of responses from a few representative systems along various axes of attribution and factuality, by bringing domain experts in the loop. Specifically, we collect expert-curated questions from 484 participants across 32 fields of study, and then ask the same experts to evaluate generated responses to their own questions. In addition, we ask experts to improve upon responses from language models. The output of our analysis is ExpertQA, a high-quality long-form QA dataset with 2177 questions spanning 32 fields, along with verified answers and attributions for claims in the answers.",
}

@inproceedings{mallen2023not,
  title={When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories},
  author={Mallen, Alex and Asai, Akari and Zhong, Victor and Das, Rajarshi and Khashabi, Daniel and Hajishirzi, Hannaneh},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9802--9822},
  year={2023}
}

@inproceedings{pal2022medmcqa,
  title={Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering},
  author={Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},
  booktitle={Conference on health, inference, and learning},
  pages={248--260},
  year={2022},
  organization={PMLR}
}

@article{qiu2024towards,
  title={Towards building multilingual language model for medicine},
  author={Qiu, Pengcheng and Wu, Chaoyi and Zhang, Xiaoman and Lin, Weixiong and Wang, Haicheng and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={8384},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{sciavolino2021simple,
  title={Simple Entity-Centric Questions Challenge Dense Retrievers},
  author={Sciavolino, Christopher and Zhong, Zexuan and Lee, Jinhyuk and Chen, Danqi},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={6138--6148},
  year={2021}
}

@article{shi2024ehragent,
  title={Ehragent: Code empowers large language models for complex tabular reasoning on electronic health records},
  author={Shi, Wenqi and Xu, Ran and Zhuang, Yuchen and Yu, Yue and Zhang, Jieyu and Wu, Hang and Zhu, Yuanda and Ho, Joyce and Yang, Carl and Wang, May D},
  journal={arXiv preprint arXiv:2401.07128},
  year={2024}
}

@article{shi2024mgh,
  title={Mgh radiology llama: A llama 3 70b model for radiology},
  author={Shi, Yucheng and Shu, Peng and Liu, Zhengliang and Wu, Zihao and Li, Quanzheng and Li, Xiang},
  journal={arXiv preprint arXiv:2408.11848},
  year={2024}
}

@article{singhal2025toward,
  title={Toward expert-level medical question answering with large language models},
  author={Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Amin, Mohamed and Hou, Le and Clark, Kevin and Pfohl, Stephen R and Cole-Lewis, Heather and others},
  journal={Nature Medicine},
  pages={1--8},
  year={2025},
  publisher={Nature Publishing Group US New York}
}

@inproceedings{trivedi2017lc,
  title={Lc-quad: A corpus for complex question answering over knowledge graphs},
  author={Trivedi, Priyansh and Maheshwari, Gaurav and Dubey, Mohnish and Lehmann, Jens},
  booktitle={The Semantic Web--ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21-25, 2017, Proceedings, Part II 16},
  pages={210--218},
  year={2017},
  organization={Springer}
}

@inproceedings{vilares-gomez-rodriguez-2019-head,
    title = "{HEAD}-{QA}: A Healthcare Dataset for Complex Reasoning",
    author = "Vilares, David  and
      G{\'o}mez-Rodr{\'i}guez, Carlos",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1092/",
    doi = "10.18653/v1/P19-1092",
    pages = "960--966",
    abstract = "We present HEAD-QA, a multi-choice question answering testbed to encourage research on complex reasoning. The questions come from exams to access a specialized position in the Spanish healthcare system, and are challenging even for highly specialized humans. We then consider monolingual (Spanish) and cross-lingual (to English) experiments with information retrieval and neural techniques. We show that: (i) HEAD-QA challenges current methods, and (ii) the results lag well behind human performance, demonstrating its usefulness as a benchmark for future work."
}

@article{xie2024me,
  title={Me-LLaMA: Foundation Large Language Models for Medical Applications},
  author={Xie, Qianqian and Chen, Qingyu and Chen, Aokun and Peng, Cheng and Hu, Yan and Lin, Fongci and Peng, Xueqing and Huang, Jimin and Zhang, Jeffrey and Keloth, Vipina and others},
  journal={Research square},
  pages={rs--3},
  year={2024}
}

@article{xiong2023doctorglm,
  title={Doctorglm: Fine-tuning your chinese doctor is not a herculean task},
  author={Xiong, Honglin and Wang, Sheng and Zhu, Yitao and Zhao, Zihao and Liu, Yuxiao and Huang, Linlin and Wang, Qian and Shen, Dinggang},
  journal={arXiv preprint arXiv:2304.01097},
  year={2023}
}

@inproceedings{xu2023baize,
  title={Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data},
  author={Xu, Canwen and Guo, Daya and Duan, Nan and McAuley, Julian},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={6268--6278},
  year={2023}
}

@article{yang2024kg,
  title={Kg-rank: Enhancing large language models for medical qa with knowledge graphs and ranking techniques},
  author={Yang, Rui and Liu, Haoran and Zeng, Qingcheng and Ke, Yu He and Li, Wanxin and Cheng, Lechao and Chen, Qingyu and Caverlee, James and Matsuo, Yutaka and Li, Irene},
  journal={arXiv preprint arXiv:2403.05881},
  year={2024}
}

@article{yasunaga2022deep,
  title={Deep bidirectional language-knowledge graph pretraining},
  author={Yasunaga, Michihiro and Bosselut, Antoine and Ren, Hongyu and Zhang, Xikun and Manning, Christopher D and Liang, Percy S and Leskovec, Jure},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={37309--37323},
  year={2022}
}

@article{zhao2024helene,
  title={HELENE: Hessian Layer-wise Clipping and Gradient Annealing for Accelerating Fine-tuning LLM with Zeroth-order Optimization},
  author={Zhao, Huaqin and Li, Jiaxi and Pan, Yi and Liang, Shizhe and Yang, Xiaofeng and Liu, Wei and Li, Xiang and Dou, Fei and Liu, Tianming and Lu, Jin},
  journal={arXiv preprint arXiv:2411.10696},
  year={2024}
}

