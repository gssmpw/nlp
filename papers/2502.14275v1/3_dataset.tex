
\section{Dataset Construction}
\label{sec:dataset}


\subsection{Overview}
% \todo{Statistics about the \mkj dataset.}
The objective of \mkj dataset is to provide a structured and controlled environment for evaluating LLMs on fundamental, one-hop medical knowledge. We use the following three-step construction pipeline, which yields $3,000$ rigorously curated and standardized questions:

\begin{enumerate}[left=0pt,topsep=0pt,partopsep=0pt,parsep=0pt,itemsep=0pt]
    \item \textbf{Triplet Extraction.} We systematically retrieve medical knowledge triplets $(s, p, o)$ from the UMLS, then apply filtering steps to remove substandard or repetitive entries.
    \item \textbf{Template Design.} We assess the evaluation as a binary classification task, which involves constructing predicate-specific templates that map each triplet into a well-defined judgment statement (either "True" or "False").
    \item \textbf{Entity Substitution.} We populate the templates with entities of the same semantic types to generate both positive and negative samples for creating balanced binary judgments.
\end{enumerate}

% We present the construction methodology of the \mkj dataset, which comprises 3,000 rigorously curated and standardized questions.
% \begin{enumerate}
%     \item Firstly, we begin with the systematic extraction of medical knowledge triplets from UMLS, followed by filtering procedures to eliminate redundant or substandard entries.
    
%     \item Secondly, to facilitate direct assessment of LLMs' medical knowledge, we structure our evaluation framework as a binary classification task. This involves the careful development of predicate-specific templates that align with the extracted triplets.
    
%     \item Lastly, we operate systematic entity substitution within these templates to generate well-formed binary judgment questions.
% \end{enumerate}


\subsection{Triplets collection}
\label{sec:data_collect}
Let $\mathcal{G}=\{\mathcal{V}, \mathcal{E}\}$ represent the medical knowledge graph derived from UMLS, where $\mathcal{V}$ is the set of vertices (i.e., medical concepts or entities), and $\mathcal{E}$ is the set of predicates (relations) among those concepts.

Concretely, UMLS contains over 3.8 million concepts $|\mathcal{V}|$ and more than 78 million relations $|\mathcal{E}|$. Since directly using all possible triples is infeasible, we filter and refine relavent samples as follows:

1. \textbf{Preliminary Question Set.} We begin with a set of multi-hop medical QA benchmarks $\mathcal{Q}_{ori}$, such a LiveQA~\cite{abacha2017overview} and ExpertQA~\cite{malaviya-etal-2024-expertqa}. Each question $Q\in \mathcal{Q}_{ori}$ is a natural-language query. It provides a diverse set of real-world medical problems and serve as a basis for identifying the most relevant and valuable UMLS knowledge components.

2. \textbf{Keyword Extraction.} For each $Q$, we prompt an LLM (e.g. \gptfour~\cite{openai2023gpt4} ) to recognize specialized medical named entities. Let 
\begin{equation*}
\mathcal{K}(Q)=\{k_1,\dots,k_n\}
\end{equation*}
be the extracted set of medical keywords from $Q$.

3. \textbf{Graph Matching.} For each keyword $k\in\mathcal{K}(Q)$, we query the UMLS API\footnote{https://documentation.uts.nlm.nih.gov/rest/home.html} to acquire associated links 
\begin{equation*}
\ell=(v_1, e, v_2),
\end{equation*}
where $v_1, v_2\in \mathcal{V}$ and $e\in \mathcal{E}$. Denote the multiset of all such links retrieved across all $Q \in \mathcal{Q}_{ori}$ by $\mathcal{L}$.

4. \textbf{Deduplication \& Filtering.} We deduplicate entries and incorrect artifacts from $\mathcal{L}$. This process yields a high-quality subset:
\begin{equation*}
\mathcal{T}=\{ (s,p,o) \mid s,o \in \mathcal{V}, p\in \mathcal{E} \},
\end{equation*}
where each element $(s,p,o)$ corresponds to a verified medical subject-predicate-object triplet.

5. \textbf{Knowledge Base Construction.} Finally, each triplet $(s,p,o)$ is converted into a short  ``fact'' in natural language (e.g., ``s is a contraindicated drug for o''), which forms a knowledge base $\mathcal{D}$. This textual representation serves as the source for subsequent experiments in later sections.
% We extract the triplets from UMLS (Unified Medical Language System), which is a comprehensive repository of health and biomedical vocabularies. The core component of UMLS, Metathesaurus, contains over 3.8 million concepts and more than 78 million relations, which constitutes large-scale knowledge graphs.
% Here we define the knowledge graphs as $\mathcal{G} = \{\mathcal{V}, \mathcal{E}\}$, where $\mathcal{V}$ and $\mathcal{E}$ denote the set of concepts and predicates respectively.

% Therefore, UMLS is a suitable foundational knowledge source for extracting high-quality medical knowledge triplets. 
% In practice, we begin with questions in established multi-hop medical question-answering (QA) datasets, such as LiveQA~\cite{abacha2017overview} and ExpertQA~\cite{malaviya-etal-2024-expertqa}, which provide a diverse set of real-world medical problems and serve as a basis for identifying the most relevant and valuable UMLS knowledge components.

% To start with, given a question $Q$, we apply a medical name entity recognition prompt $P_\text{MedNER}$ to LLMs (we use \gptfour~\cite{openai2023gpt4} here) to extract relevant medical keywords $K_Q$ within $Q$. 
% Then we match the keywords $K_Q$ in knowledge graphs $\mathcal{G}$ using the UMLS API to acquire associated links $L$ composed of subject $v_1$, predicate $e$, and object $v_2$ as $L=(v_1, e, v_2)$ where $v_1, v_2 \in \mathcal{V}$ and $e \in \mathcal{E}$.

% After that, we deduplicate and filter the collected links $L$ to acquire high-quality triplets $T=(s, p, o)$ where $s$, $p$, $o$ indicate subject, predicate and object respectively, and organize them into a knowledge base $D$ by transformation into sentences.
% Additionally, by drawing on UMLS, a comprehensive and authoritative medical knowledge source, the stored triplets are more likely to be of high quality and ensuring reliability.




\subsection{Template construction}
\label{sec:data_temp}
To facilitate direct assessment of LLMs' medical knowledge, we frame our evaluation as a binary classification task, converting extracted triplets $\mathcal{T}$ into binary judgment questions.

Central to this transformation is our template-based approach, where we develop a specific template for each predicate type $p$ in the triplet $(s, p, o)$, which enables us to consistently frame the medical knowledge contained in each triplet as a well-structured binary judgment question, and facilitates standardized precise evaluation.

Specifically, we identify about 200 unique predicates among the collected triplets $\mathcal{T}$. Then we leverage LLMs to generate and human experts to check the templates tailored to the unique predicates present in the triplets $\mathcal{T}$.

\subsection{Question generation with templates}
\label{sec:data_sub}
Having predicate-specific templates, we proceed to generate binary judgment questions by applying these templates to the UMLS triplets $\mathcal{T}$. 
This process involves substituting the entities from each triplet into the corresponding placeholders in the template to form complete and meaningful judgments. The judgments involve positive judgments that their statements hold, as well as negative judgments that their statements do not hold.

For positive judgment samples, they are generated by simply replacing the placeholders in the templates with the original entities present in the triplet. 

However, for negative judgment samples, we need to construct statements that do not hold. In practice, we substitute the object placeholder with other entities that do not satisfy the given relationship with the subject in the triplet. It is essential to ensure that the substituted entities belong to the same semantic type as the original object to maintain logical coherence.
To achieve this, we collect $N_i$ entities within the same semantic type $i$ as the object in the original triplet. We then randomly shuffle this list and select $k$ candidate entities (where $k \ll N_i$) and fill in the placeholder to create $k$ negative ones (here we set $k=3$). 
% Here we choose $k=3$ and construct 1 positive judgment as well as 3 negative judgments for each triplet.
% We guarantee $k \ll N_i$ to minimize the error rate in constructing negative samples.

While negative samples are generated by randomly sampling objects from the same semantic type, there remains a nonzero yet small probability that the resulting statement $(s,p,o_{\text{neg}})$ might actually reflect a valid relation. 
To solve this issue, we perform post-hoc checks against our curated knowledge base $\mathcal{D}$. In the rare case where $(s,p,o_{\text{neg}})$ is present in $\mathcal{D}$, we exclude that instance and resample. In practice, we find this probability to be negligible (below 1\%), which is partially due to the large amount of entities within the same semantic type as shown in Appendix~\ref{app:data_detail}, ensuring that nearly all sampled negative statements are indeed invalid relationships.

The resulting set of binary judgment questions forms the \mkj{} dataset, providing resource for evaluating the medical knowledge within LLMs. Using templates to guide question generation, we enable robust and interpretable assessments across a wide range of aspects of medical knowledge. More information about the dataset can be fonud in Appendix~\ref{app:data_detail}.


