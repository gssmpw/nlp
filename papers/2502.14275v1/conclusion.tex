\section{Conclusion}
We introduce the Medical Knowledge Judgment (\mkj) dataset which is designed to assess the ability of LLMs to internalize medical and healthcare factual knowledge by extracting and formulating medical knowledge triplets into one-hop direct judgment questions.
Our experiments on the \mkj dataset and subsequent analysis indicate that LLMs still face challenges in retaining factual medical knowledge, with notable variations in performance across different semantic categories, especially when dealing with rare medical conditions.
In the meanwhile, most LLMs exhibit poor calibration status with mixed overconfidence and underconfidence patterns.
To address these issues, we investigate retrieval-augmented generation, and demonstrate its effectiveness in enhancing factual accuracy and reducing uncertainty in medical decision-making. 


% Our experimentation on the \mkj dataset and analysis reveal that LLMs still struggle with factual medical knowledge retention, exhibiting significant performance variance across different semantic categories, particularly for rare medical conditions. 
% Furthermore, LLMs show poor calibration, often being overconfident in incorrect answers. 
% To mitigate these issues, we explore retrieval-augmented generation, demonstrating its effectiveness in improving factual accuracy and reducing uncertainty in medical decision-making.

% Our experimentation and analysis show that current LLMs have notable limitations in representing factual knowledge in medical and healthcare, particularly for the questions about sign and symptom.
% Though RAG is an promising approach to alleviate the problem, there is still a considerable gap before LLMs can be directly applied to the medical and healthcare fields in practice.
