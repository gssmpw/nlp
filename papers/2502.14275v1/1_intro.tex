\section{Introduction}
Large language models (LLMs) such as GPT-4~\cite{openai2023gpt4} and Llama3~\cite{dubey2024llama} have demonstrated remarkable generative capabilities, achieving state-of-the-art performance in various NLP tasks.
However, their ability to accurately recall and apply domain-specific knowledge remains a major challenge, particularly in high-stakes fields such as healthcare~\cite{li2022neural, bi2024decoding, yang2023large, liu2023evaluating, yan2023multimodal}. LLMs are prone to hallucinations-generating plausible but incorrect content~\cite{ji2023survey, bang2023multitask, zhang2023siren}-which raises concerns about their factual reliability~\cite{chen2023hallucination, li-etal-2024-dawn}. 
These domain-specific knowledge gaps often lead to contradictions, misinformation, and overconfident yet incorrect predictions, making them unsuitable for direct deployment in clinical decision-making. 

\input{tables/overview}

To evaluate \textit{``how knowledgeable are LLM in medicine and healthcare''}, existing benchmarks typically frame the task as a question-answering (QA) challenge, often involving clinical questions that require multi-step reasoning, indirect relationships, or external retrieval~\cite{pal2022medmcqa, malaviya-etal-2024-expertqa}. 
However, evaluating LLMs' core medical knowledge requires a direct and controlled framework-one that can systematically quantify what LLMs ``know'' without the confounding effects of reasoning or retrieval augmentation. 
Fundamental knowledge evaluation is not merely an auxiliary task-it is a prerequisite for trustworthy and effective medical foundation models~\cite{zhang2024generalist, moor2023foundation}. By ensuring that LLMs possess a solid factual foundation, we pave the way for more reliable reasoning, clinical applications, and ultimately, safer deployment in real-world healthcare settings.

To address this gap, we introduce the Medical Knowledge Judgment Dataset (\mkj), designed to systematically evaluate LLMs' inherent factual medical knowledge through one-hop binary judgment tasks. 
We construct \mkj through a systematic process of extracting knowledge triplets from Unified Medical Language System (UMLS) and transforming them into carefully templated judgment questions. 
We focus on one-hop relation and remove triplets with multi-hop nodes or multiple relationships, which ensures single and indisputable answer~\cite{weimeasuring, sun2024head}. Some examples are provided in Figure~\ref{fig:overview}.
% following methodological insights from SimpleQA~\cite{weimeasuring} and Head-to-Tail~\cite{sun2024head}. 

The UMLS serves as the ideal foundation for our dataset due to its unparalleled comprehensiveness and reliability in the medical domain. 
First, UMLS is a rigorously curated and widely trusted biomedical resource, integrating over 3.8 million concepts and 78 million relationships from authoritative medical terminologies. This ensures that the knowledge assessed in our dataset is clinically validated and standardized. 
Second, its knowledge graph (KG) structure provides an explicit, structured representation of medical knowledge, enabling precise fact-based evaluation while minimizing ambiguity and inconsistencies often found in alternative sources~\citep{abacha2017overview, malaviya-etal-2024-expertqa}. 
By leveraging UMLS as a gold-standard knowledge base, our dataset ensures high factual reliability, broad medical coverage, and systematic evaluation of LLMs’ medical expertise.

% The \mkj dataset contributes to the growing body of work on LLM evaluation by systematically leveraging medical knowledge graphs to assess LLMs' medical expertise.
To comprehensively examine LLMs’ capabilities in medical knowledge retention, we focus on four specific research questions:

\begin{itemize}[left=0pt, topsep=0pt, itemsep=0pt, partopsep=0pt,parsep=0pt]
    \item \textbf{RQ1} To what extent can LLMs accurately perform medical judgments?
    \item \textbf{RQ2} How well are LLMs calibrated in medical and healthcare contexts?
    \item \textbf{RQ3} What are the underlying reasons behind LLMs’ failure to retain certain critical medical knowledge?
    \item \textbf{RQ4} What strategies can enhance the response accuracy of LLMs?
\end{itemize}

We groups the questions into three progressive categories: Biomedical Entities (foundational concepts), Pathological Conditions (phenomena), and Clinical Practice (applications) with detailed information in Appendix~\ref{app:data_detail}. Through comprehensive analysis on \mkj, we find that LLMs, especially open-source LLMs, still struggle with basic factual medical knowledge retention as illustrated in Figure~\ref{fig:overview}. 
Our further investigation in later sections reveals critical challenges: poor calibration with frequent overconfidence in incorrect predictions as shown in Figure~\ref{fig:calibration_curves}, and notably degraded performance when handling rare medical conditions as in Figure~\ref{fig:acc_and_freq}. To address these limitations, we implement retrieval-augmented generation, which substantially improves factual accuracy in medical contexts displayed in Table~\ref{tab:sparse_dense_rag}.



% With a logical progression, we group the questions into three categories: from Biomedical Entities (fundamentals) to Pathological Conditions (phenomena), and then Clinical Practice (application), on which our experiment reveals that LLMs still struggle with factual medical knowledge retention as demonstrated in Figure~\ref{fig:overview}, and show a descending trend with three groups of questions.

% Through comprehensive experimentation and analysis of LLMs on \mkj, it is found that current LLMs remain considerably distant from achieving satisfactory performances (e.g. >90\%) as demonstrated in Figure~\ref{fig:overview}. 

% \jiaxi{Categories and corresponding semantic types to be added in the appendix.}
% 1. (covering fundamental medical components such as anatomical structures and biochemical substances)
% 2. (focusing on diseases, disorders, and their associated symptoms and manifestations)
% 3. (encompassing therapeutic procedures, treatment guidelines, and medical interventions)

% Our further analysis reveals that LLMs exhibit poor calibration level on the \mkj dataset, often being overconfident in incorrect answers. LLMs are also found to have significant performance variance across different semantic categories, particularly for rare medical conditions. To mitigate these issues, we explore retrieval-augmented generation, demonstrating its effectiveness in improving factual accuracy and reducing uncertainty in medical decision-making.


% % Original words
% First, our analysis shows that current LLMs struggle to achieve high accuracies on the MKJ benchmark, indicating a noticeable gap in their medical knowledge representation. 
% Second, our calibration analysis reveals a concerning pattern of miscalibration in the domains of medicine and healthcare, where LLMs' confidence scores show significant discrepancy with their actual performance accuracies, exhibiting both over-confidence and under-confidence patterns.
% Third, our analysis reveals that the performance degradation is particularly pronounced for questions involving rare medical conditions, which suggests that insufficient coverage of such uncommon topics in the models' pretraining corpora may be a key contributing factor to their suboptimal performances.
% Third, through further investigation, we identify that the performance degradation is particularly pronounced for rare medical conditions, suggesting insufficient coverage of these topics in the models' pretraining corpora. 
% Fourth, to mitigate these limitations, we explore the integration of Retrieval-Augmented Generation (RAG) as a potential solution. By leveraging the collected comprehensive UMLS knowledge graph triplets as a document corpus, we demonstrate significant improvements in model performance. 

% To sum up, our main contributions are as follows:
% (1) We introduce \mkj, a dataset designed to evaluate LLMs’ inherent factual knowledge in medical and healthcare domains. 
% (2) To answer the RQs, we conduct extensive experiments and find current LLMs struggle to do accurate judgments and tend to be over-confident with their predictions. We analyze the underlying reasons and improve the performances with the technique of RAG. 



% \todo{Kai's comments: (1) why evaluating knowledgeable are LLMs in healthcare is important --> understand how LLM utilizes the inherent knowledge to solve the real-world or practical clinical questions (how and if the knowledge is utilized during medical reasoning). 
% (2) refine the post-training strategies to add more knowledge and estimate if there is forgetting issue.}
