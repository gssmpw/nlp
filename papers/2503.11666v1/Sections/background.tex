This section gives an overview of the relevant techniques used in our work.
\subsection{Python-based verification}
Python is a widely-used, high-level programming language employed across various industries. Its extensive standard library and ecosystem support a multitude of existing libraries. To support the functionalities from SystemVerilog and \ac{UVM}, \ac{Cocotb} \cite{cocotb} is introduced as an open-source Python-based verification environment. It provides synchronous logic, connects the \ac{DUV} and Python testbench using \ac{GPI}. \\Building upon \ac{Cocotb}, \ac{PyUVM} is a Python library that implements \ac{UVM} 1.2 IEEE specification in Python using its high-level language features \cite{salmei_themperek}. As shown in Fig. \ref{pyuvmbfm}, the testbench software is the \ac{PyUVM} testbench, the proxy is implemented in \ac{Cocotb}, where \ac{Cocotb} connects Python to simulators through \ac{VPI} and \ac{VHPI}. Hence, both Python and the \ac{DUV}, which runs in the simulator, share the same proxy interface. The transactions from the testbench are called using Python coroutines such as driver and monitors \ac{BFMs}, which also ensures the \ac{DUV} is not busy.
\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{Figures/pyuvmbfm.pdf} 
	\caption{Proxy-driven PyUVM testbench}
	\label{pyuvmbfm}
\end{figure}
PyVSC \cite{Ballance} is a Python library that enables constrained randomization and functional coverage,
similar to SystemVerilog. Python does not have in-built support for coverage constructs.
Hence, PyVSC has been used in conjunction with PyUVM to enable these features in this research
work.
\subsection{Machine Learning}
Supervised \ac{ML} is used to obtain trained models to make predictions, which are further utilized for the \ac{ML}-optimized simulation regression. Table \ref{analogy} shows the analogy used in our work for \ac{ML} modeling.

\begin{table}[htbp]
	\setcellgapes{0.5pt}
	\makegapedcells
	\renewcommand{\arraystretch}{1.3}
	\caption{ML modeling terms and their analogy in our work}
	\label{analogy}
	\footnotesize
	\centering
	\resizebox{\columnwidth}{!}
	{
\begin{tabular}{lll}
	\hline
	\textbf{ML componets}                                            & \textbf{Definition}                                                                                    & \textbf{Analogy in our work}                                                  \\ \hline
	Dataset                                                          & Data used for training/testing ML models                                                               & \begin{tabular}[c]{@{}l@{}}I/P and coverbin status \\ (hit/miss)\end{tabular} \\ \hline
	\begin{tabular}[c]{@{}l@{}}Independent \\ variables\end{tabular} & \begin{tabular}[c]{@{}l@{}}Features extracted from dataset and \\ used for O/P prediction\end{tabular} & O/P coverbin                                                                  \\ \hline
	\begin{tabular}[c]{@{}l@{}}Dependent \\ variables\end{tabular}   & O/P values/labels to be predicted                                                                      & I/P stimuli                                                                   \\ \hline
\end{tabular}%
	}
	\vspace{-0.4cm}
\end{table}



\subsection{Performance metrics}
\label{pm}
To evaluate the proposed methodology, three performance metrics \ref{eq:optimization_runs}, \ref{eq:optimization_runtime}, and \ref{eq:coverage_regain} have been defined, referred from \cite{gadde2024improvingsimulationregressionefficiency}.
\begin{equation}
	\scriptsize\textit{Optimization in test runs (x)} = \frac{\textit{Number of test runs in original regression}}{\textit{Number of test runs in ML-optimized regression}}
	\label{eq:optimization_runs}
\end{equation}
\begin{equation}
	\scriptsize\textit{Optimization in run-time (x)} = \frac{\textit{Simulation run-time of original regression}}{\textit{Simulation run-time of ML-optimized regression}}
	\label{eq:optimization_runtime}
\end{equation}
\begin{equation}
	\scriptsize\textit{Coverage regain (\%)} = \frac{\textit{Coverage of ML-optimized regression}}{\textit{Coverage of original regression}} 
	\label{eq:coverage_regain}
\end{equation}