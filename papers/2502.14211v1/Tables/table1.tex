%  
% \begin{table*}[htbp]
%   \centering
%    \caption{Comparison of zero-shot learning performance of different models and methods on common sense reasoning datasets. The best outcome is highlighted in \textbf{bold}.}
%    % \subcaption[]{Zero-Shot Learning Performance.}
%     \resizebox{\textwidth}{!}{\begin{tabular}{lccccccccccccccccccccc}
%     \specialrule{1.5pt}{0pt}{0pt}
%     \multirow{2}[4]{*}{\textbf{Models}} & \multirow{2}[4]{*}{\textbf{Methods}} & \multicolumn{6}{c}{\textbf{LogiQA}}           &       & \multicolumn{6}{c}{\textbf{OpenbookQA}}       &       & \multicolumn{6}{c}{\textbf{CosmosQA}} \\
% \cmidrule{3-8}\cmidrule{10-15}\cmidrule{17-22}          &       & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} &       & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} &       & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{LLaMA-2-7B} & ORI & 0.40  & \textbf{   0.32} & 0.61  & \textbf{   0.38} & \textbf{   0.41} & \textbf{   0.73} &       & 0.48  & \textbf{   0.36} & 0.50  & \textbf{   0.53} & \textbf{   0.47} & \textbf{   0.59} &       & 0.45  & 0.33  & 0.58  & 0.42  & 0.43  & 0.72  \\
%           & POI & \textbf{   0.49} & 0.29  & \textbf{   0.45} & 0.36  & 0.38  & 0.78  &       & \textbf{   0.52} & 0.35  & \textbf{   0.45} & 0.49  & 0.44  & 0.73  &       & \textbf{   0.58} & \textbf{   0.36} & \textbf{   0.44} & \textbf{   0.50} & \textbf{   0.51} & \textbf{   0.46} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{LLaMA-2-13B} & ORI & 0.46  & 0.30  & 0.49  & 0.47  & 0.52  & \textbf{   0.67} &       & 0.54  & 0.39  & 0.46  & 0.45  & 0.43  & 0.70  &       & 0.56  & 0.41  & 0.46  & \textbf{   0.59} & \textbf{   0.57} & \textbf{   0.54} \\
%           & POI & \textbf{   0.58} & \textbf{   0.37} & \textbf{   0.34} & \textbf{   0.57} & \textbf{   0.54} & 0.73  &       & \textbf{   0.65} & \textbf{   0.45} & \textbf{   0.32} & \textbf{   0.56} & \textbf{   0.54} & \textbf{   0.55} &       & \textbf{   0.64} & \textbf{   0.43} & \textbf{   0.34} & 0.37  & 0.47  & 0.61  \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{LLaMA-3-8B} & ORI & 0.66  & 0.44  & 0.42  & 0.63  & 0.55  & 0.59  &       & 0.72  & 0.43  & 0.35  & 0.61  & 0.55  & 0.49  &       & 0.69  & 0.46  & 0.26  & 0.67  & 0.66  & 0.45  \\
%          & POI & \textbf{   0.79} & \textbf{   0.47} & \textbf{   0.25} & \textbf{   0.70} & \textbf{   0.72} & \textbf{   0.41} &       & \textbf{   0.87} & \textbf{   0.55} & \textbf{   0.21} & \textbf{   0.75} & \textbf{   0.71} & \textbf{   0.34} &       & \textbf{   0.81} & \textbf{   0.53} & \textbf{   0.15} & \textbf{   0.71} & \textbf{   0.79} & \textbf{   0.33} \\
         
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{Vicuna-7B} & ORI & 0.37  & \textbf{   0.29} & 0.64  & \textbf{   0.44} & \textbf{   0.36} & \textbf{   0.75} &       & 0.43  & 0.32  & 0.49  & 0.37  & 0.34  & 0.74  &       & 0.40  & 0.31  & 0.51  & 0.47  & 0.38  & 0.75  \\
%          & POI & \textbf{   0.45} & 0.26  & \textbf{   0.44} & 0.43  & 0.31  & 0.81  &       & \textbf{   0.51} & \textbf{   0.36} & \textbf{   0.45} & \textbf{   0.50} & \textbf{   0.42} & \textbf{   0.64} &       & \textbf{   0.52} & \textbf{   0.34} & \textbf{   0.43} & \textbf{   0.63} & \textbf{   0.58} & \textbf{   0.70} \\

% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{Vicuna-13B} & ORI & 0.43  & 0.32  & 0.55  & 0.45  & 0.46  & 0.72  &       & 0.53  & 0.36  & 0.48  & 0.49  & 0.40  & 0.67  &       & 0.51  & 0.36  & 0.49  & 0.55  & 0.44  & 0.64  \\
%            & POI & \textbf{   0.51} & \textbf{   0.37} & \textbf{   0.38} & \textbf{   0.54} & \textbf{   0.49} & \textbf{   0.64} &       & \textbf{   0.62} & \textbf{   0.42} & \textbf{   0.39} & \textbf{   0.57} & \textbf{   0.64} & \textbf{   0.53} &       & \textbf{   0.59} & \textbf{   0.44} & \textbf{   0.33} & \textbf{   0.64} & \textbf{   0.51} & \textbf{   0.57} \\

% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{GPT-3.5-Turbo} & ORI & 0.57  & 0.35  & 0.42  & 0.61  & 0.49  & 0.68  &       & 0.68  & 0.37  & 0.36  & 0.58  & 0.52  & 0.54  &       & 0.63  & 0.42  & 0.39  & 0.61  & 0.65  & 0.46  \\
%           & POI & \textbf{   0.71} & \textbf{   0.39} & \textbf{   0.31} & \textbf{   0.73} & \textbf{   0.68} & \textbf{   0.40} &       & \textbf{   0.77} & \textbf{   0.49} & \textbf{   0.23} & \textbf{   0.70} & \textbf{   0.69} & \textbf{   0.37} &       & \textbf{   0.75} & \textbf{   0.51} & \textbf{   0.20} & \textbf{   0.68} & \textbf{   0.71} & \textbf{   0.35} \\

% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{GPT-4} & ORI & 0.70  & 0.44  & 0.30  & 0.69  & 0.66  & 0.44  &       & 0.75  & 0.45  & 0.28  & 0.75  & 0.65  & 0.47  &       & 0.74  & 0.54  & 0.22  & 0.64  & 0.68  & 0.31  \\
%            & POI & \textbf{   0.82} & \textbf{   0.50} & \textbf{   0.18} & \textbf{   0.81} & \textbf{   0.74} & \textbf{   0.32} &       & \textbf{   0.89} & \textbf{   0.58} & \textbf{   0.16} & \textbf{   0.83} & \textbf{   0.76} & \textbf{   0.29} &       & \textbf{   0.87} & \textbf{   0.59} & \textbf{   0.14} & \textbf{   0.74} & \textbf{   0.85} & \textbf{   0.19} \\

%     \specialrule{1.5pt}{0pt}{0pt}
%     \end{tabular}}%
%       \label{tab:1-commonsense}%
% \end{table*}%


\begin{table*}[htbp]
  \centering
  \caption{Comparison of zero-shot learning performance of foundational models using different prompt strategies on commonsense reasoning datasets. The confidence is calculated by the verbalized confidence method. The best outcome is highlighted in \textbf{bold}.}
     \resizebox{.98\textwidth}{!}{\begin{tabular}{lc|cccccc|cccccc|cccccc}
    \toprule
    \multirow{2}[4]{*}{\textbf{Model}} & \multirow{2}[4]{*}{\textbf{Method}} & \multicolumn{6}{c|}{\textbf{LogiQA}}          & \multicolumn{6}{c|}{\textbf{OpenbookQA}}      & \multicolumn{6}{c}{\textbf{CosmosQA}} \\
\cmidrule{3-20}          &       & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} \\
    \midrule
    \multirow{2}[2]{*}{LLaMA-2-7B} & Orign Prompt & 0.40  & \textbf{0.32} & 0.54  & \textbf{0.38} & \textbf{0.41} & \textbf{0.73} & 0.48  & \textbf{0.36} & 0.50  & \textbf{0.53} & \textbf{0.47} & \textbf{0.59} & 0.45  & 0.33  & 0.58  & 0.42  & 0.43  & 0.72  \\
          & Transfer Prompt & \textbf{0.55} & 0.29  & \textbf{0.45} & 0.36  & 0.38  & 0.78  & \textbf{0.52} & 0.35  & \textbf{0.45} & 0.49  & 0.44  & 0.73  & \textbf{0.58} & \textbf{0.36} & \textbf{0.44} & \textbf{0.50} & \textbf{0.51} & \textbf{0.46} \\
    \midrule
    \multirow{2}[2]{*}{LLaMA-2-13B} & Orign Prompt & 0.46  & 0.30  & 0.49  & 0.47  & 0.52  & \textbf{0.67} & 0.54  & 0.39  & 0.46  & 0.45  & 0.43  & 0.70  & 0.56  & 0.41  & 0.46  & \textbf{0.59} & \textbf{0.57} & \textbf{0.54} \\
          & Transfer Prompt & \textbf{0.57} & \textbf{0.37} & \textbf{0.34} & \textbf{0.57} & \textbf{0.54} & 0.73  & \textbf{0.65} & \textbf{0.45} & \textbf{0.32} & \textbf{0.56} & \textbf{0.54} & \textbf{0.55} & \textbf{0.64} & \textbf{0.43} & \textbf{0.34} & 0.37  & 0.47  & 0.61  \\
    \midrule
    \multirow{2}[2]{*}{LLaMA-3-8B} & Orign Prompt & 0.66  & 0.44  & 0.42  & 0.63  & 0.55  & 0.59  & 0.72  & 0.43  & 0.35  & 0.61  & 0.55  & 0.49  & 0.69  & 0.46  & 0.26  & 0.67  & 0.66  & 0.45  \\
          & Transfer Prompt & \textbf{0.79} & \textbf{0.47} & \textbf{0.31} & \textbf{0.70} & \textbf{0.72} & \textbf{0.41} & \textbf{0.87} & \textbf{0.55} & \textbf{0.21} & \textbf{0.75} & \textbf{0.71} & \textbf{0.34} & \textbf{0.81} & \textbf{0.53} & \textbf{0.15} & \textbf{0.71} & \textbf{0.79} & \textbf{0.33} \\
    \midrule
    \multirow{2}[2]{*}{Vicuna-7B} & Orign Prompt & 0.37  & \textbf{0.29} & 0.64  & \textbf{0.44} & \textbf{0.36} & \textbf{0.75} & 0.43  & 0.32  & 0.49  & 0.37  & 0.34  & 0.74  & 0.40  & 0.31  & 0.51  & 0.47  & 0.38  & 0.75  \\
          & Transfer Prompt & \textbf{0.46} & 0.26  & \textbf{0.44} & 0.43  & 0.31  & 0.81  & \textbf{0.51} & \textbf{0.36} & \textbf{0.45} & \textbf{0.50} & \textbf{0.42} & \textbf{0.64} & \textbf{0.52} & \textbf{0.34} & \textbf{0.43} & \textbf{0.63} & \textbf{0.58} & \textbf{0.70} \\
    \midrule
    \multirow{2}[2]{*}{Vicuna-13B} & Orign Prompt & 0.43  & 0.32  & 0.49  & 0.45  & 0.46  & 0.72  & 0.53  & 0.36  & 0.48  & 0.49  & 0.40  & 0.67  & 0.51  & 0.36  & 0.49  & 0.55  & 0.44  & 0.64  \\
          & Transfer Prompt & \textbf{0.49} & \textbf{0.37} & \textbf{0.36} & \textbf{0.54} & \textbf{0.49} & \textbf{0.64} & \textbf{0.62} & \textbf{0.42} & \textbf{0.39} & \textbf{0.57} & \textbf{0.64} & \textbf{0.53} & \textbf{0.59} & \textbf{0.44} & \textbf{0.33} & \textbf{0.64} & \textbf{0.51} & \textbf{0.57} \\
    \midrule
    \multirow{2}[2]{*}{GPT-3.5-Turbo} & Orign Prompt & 0.59  & 0.35  & 0.42  & 0.61  & 0.49  & 0.68  & 0.68  & 0.37  & 0.36  & 0.58  & 0.52  & 0.54  & 0.63  & 0.42  & 0.39  & 0.61  & 0.65  & 0.46  \\
          & Transfer Prompt & \textbf{0.71} & \textbf{0.39} & \textbf{0.27} & \textbf{0.73} & \textbf{0.68} & \textbf{0.40} & \textbf{0.77} & \textbf{0.49} & \textbf{0.23} & \textbf{0.70} & \textbf{0.69} & \textbf{0.37} & \textbf{0.75} & \textbf{0.51} & \textbf{0.20} & \textbf{0.68} & \textbf{0.71} & \textbf{0.35} \\
    \midrule
    \multirow{2}[2]{*}{GPT-4} & Orign Prompt & 0.70  & 0.44  & 0.30  & 0.69  & 0.66  & 0.44  & 0.75  & 0.45  & 0.28  & 0.75  & 0.65  & 0.47  & 0.74  & 0.54  & 0.22  & 0.64  & 0.68  & 0.31  \\
          & Transfer Prompt & \textbf{0.82} & \textbf{0.50} & \textbf{0.18} & \textbf{0.81} & \textbf{0.74} & \textbf{0.32} & \textbf{0.89} & \textbf{0.58} & \textbf{0.16} & \textbf{0.83} & \textbf{0.76} & \textbf{0.29} & \textbf{0.87} & \textbf{0.59} & \textbf{0.14} & \textbf{0.74} & \textbf{0.85} & \textbf{0.19} \\
    \bottomrule
    \end{tabular}}%
\label{tab:1-commonsense}%
\end{table*}%

% \begin{table*}[htbp]
%   \centering
%   \caption{Comparison of zero-shot learning performance of different models and methods on common sense reasoning datasets. The best outcome is highlighted in \textbf{bold}.}
%      \resizebox{.98\textwidth}{!}{\begin{tabular}{cc|cccccc|cccccc|cccccc}
%     \toprule
%     \multirow{2}[4]{*}{\textbf{Model}} & \multirow{2}[4]{*}{\textbf{Method}} & \multicolumn{6}{c|}{\textbf{LogiQA}}          & \multicolumn{6}{c|}{\textbf{OpenbookQA}}      & \multicolumn{6}{c}{\textbf{CosmosQA}} \\
% \cmidrule{3-20}          &       & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} \\
%     \midrule
%     \multirow{2}[2]{*}{GPT-4} & Orign Prompt & 0.70  & 0.44  & 0.30  & 0.69  & 0.66  & 0.44  & 0.75  & 0.45  & 0.28  & 0.75  & 0.65  & 0.47  & 0.74  & 0.54  & 0.22  & 0.64  & 0.68  & 0.31  \\
%           & Transfer Prompt & \textbf{0.82} & \textbf{0.50} & \textbf{0.18} & \textbf{0.81} & \textbf{0.74} & \textbf{0.32} & \textbf{0.89} & \textbf{0.58} & \textbf{0.16} & \textbf{0.83} & \textbf{0.76} & \textbf{0.29} & \textbf{0.87} & \textbf{0.59} & \textbf{0.14} & \textbf{0.74} & \textbf{0.85} & \textbf{0.19} \\
%     \bottomrule
%     \end{tabular}}%
% \label{tab:1-commonsense}%
% \end{table*}%


% \begin{table*}[htbp]
%   \centering
%    \caption{Comparison of zero-shot learning performance of different models and methods on common sense reasoning datasets. ORI is the abbreviation of Orign Prompt, and Orign Prompt-prompt evaluates the results of the ORI column. The best outcome is highlighted in \textbf{bold}.}
%    % \subcaption[]{Zero-Shot Learning Performance.}
%     \resizebox{\textwidth}{!}{\begin{tabular}{lccccccccccccccccccccc}
%     \specialrule{1.5pt}{0pt}{0pt}
%     \multirow{2}[4]{*}{\textbf{Models}} & \multirow{2}[4]{*}{\textbf{Methods}} & \multicolumn{6}{c}{\textbf{LogiQA}}           &       & \multicolumn{6}{c}{\textbf{OpenbookQA}}       &       & \multicolumn{6}{c}{\textbf{CosmosQA}} \\
% \cmidrule{3-8}\cmidrule{10-15}\cmidrule{17-22}          &       & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} &       & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} &       & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{LLaMA-2-7B} & ORI & 0.40  & \textbf{   0.32} & 0.61  & \textbf{   0.38} & \textbf{   0.41} & \textbf{   0.73} &       & 0.48  & \textbf{   0.36} & 0.50  & \textbf{   0.53} & \textbf{   0.47} & \textbf{   0.59} &       & 0.45  & 0.33  & 0.58  & 0.42  & 0.43  & 0.72  \\
%           & POI & \textbf{   0.49} & 0.29  & \textbf{   0.45} & 0.36  & 0.38  & 0.78  &       & \textbf{   0.52} & 0.35  & \textbf{   0.45} & 0.49  & 0.44  & 0.73  &       & \textbf{   0.58} & \textbf{   0.36} & \textbf{   0.44} & \textbf{   0.50} & \textbf{   0.51} & \textbf{   0.46} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{LLaMA-2-13B} & ORI & 0.46  & 0.30  & 0.49  & 0.47  & 0.52  & \textbf{   0.67} &       & 0.54  & 0.39  & 0.46  & 0.45  & 0.43  & 0.70  &       & 0.56  & 0.41  & 0.46  & \textbf{   0.59} & \textbf{   0.57} & \textbf{   0.54} \\
%           & POI & \textbf{   0.58} & \textbf{   0.37} & \textbf{   0.34} & \textbf{   0.57} & \textbf{   0.54} & 0.73  &       & \textbf{   0.65} & \textbf{   0.45} & \textbf{   0.32} & \textbf{   0.56} & \textbf{   0.54} & \textbf{   0.55} &       & \textbf{   0.64} & \textbf{   0.43} & \textbf{   0.34} & 0.37  & 0.47  & 0.61  \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{LLaMA-3-8B} & ORI & 0.66  & 0.44  & 0.42  & 0.63  & 0.55  & 0.59  &       & 0.72  & 0.43  & 0.35  & 0.61  & 0.55  & 0.49  &       & 0.69  & 0.46  & 0.26  & 0.67  & 0.66  & 0.45  \\
%           & POI & \textbf{   0.79} & \textbf{   0.47} & \textbf{   0.25} & \textbf{   0.70} & \textbf{   0.72} & \textbf{   0.41} &       & \textbf{   0.87} & \textbf{   0.55} & \textbf{   0.21} & \textbf{   0.75} & \textbf{   0.71} & \textbf{   0.34} &       & \textbf{   0.81} & \textbf{   0.53} & \textbf{   0.15} & \textbf{   0.71} & \textbf{   0.79} & \textbf{   0.33} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{Vicuna-7B} & ORI & 0.37  & \textbf{   0.29} & 0.64  & \textbf{   0.44} & \textbf{   0.36} & \textbf{   0.75} &       & 0.43  & 0.32  & 0.49  & 0.37  & 0.34  & 0.74  &       & 0.40  & 0.31  & 0.51  & 0.47  & 0.38  & 0.75  \\
%           & POI & \textbf{   0.45} & 0.26  & \textbf{   0.44} & 0.43  & 0.31  & 0.81  &       & \textbf{   0.51} & \textbf{   0.36} & \textbf{   0.45} & \textbf{   0.50} & \textbf{   0.42} & \textbf{   0.64} &       & \textbf{   0.52} & \textbf{   0.34} & \textbf{   0.43} & \textbf{   0.63} & \textbf{   0.58} & \textbf{   0.70} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{Vicuna-13B} & ORI & 0.43  & 0.32  & 0.55  & 0.45  & 0.46  & 0.72  &       & 0.53  & 0.36  & 0.48  & 0.49  & 0.40  & 0.67  &       & 0.51  & 0.36  & 0.49  & 0.55  & 0.44  & 0.64  \\
%           & POI & \textbf{   0.51} & \textbf{   0.37} & \textbf{   0.38} & \textbf{   0.54} & \textbf{   0.49} & \textbf{   0.64} &       & \textbf{   0.62} & \textbf{   0.42} & \textbf{   0.39} & \textbf{   0.57} & \textbf{   0.64} & \textbf{   0.53} &       & \textbf{   0.59} & \textbf{   0.44} & \textbf{   0.33} & \textbf{   0.64} & \textbf{   0.51} & \textbf{   0.57} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{GPT-3.5-Turbo} & ORI & 0.57  & 0.35  & 0.42  & 0.61  & 0.49  & 0.68  &       & 0.68  & 0.37  & 0.36  & 0.58  & 0.52  & 0.54  &       & 0.63  & 0.42  & 0.39  & 0.61  & 0.65  & 0.46  \\
%           & POI & \textbf{   0.71} & \textbf{   0.39} & \textbf{   0.31} & \textbf{   0.73} & \textbf{   0.68} & \textbf{   0.40} &       & \textbf{   0.77} & \textbf{   0.49} & \textbf{   0.23} & \textbf{   0.70} & \textbf{   0.69} & \textbf{   0.37} &       & \textbf{   0.75} & \textbf{   0.51} & \textbf{   0.20} & \textbf{   0.68} & \textbf{   0.71} & \textbf{   0.35} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{GPT-4} & ORI & 0.70  & 0.44  & 0.30  & 0.69  & 0.66  & 0.44  &       & 0.75  & 0.45  & 0.28  & 0.75  & 0.65  & 0.47  &       & 0.74  & 0.54  & 0.22  & 0.64  & 0.68  & 0.31  \\
%           & POI & \textbf{   0.82} & \textbf{   0.50} & \textbf{   0.18} & \textbf{   0.81} & \textbf{   0.74} & \textbf{   0.32} &       & \textbf{   0.89} & \textbf{   0.58} & \textbf{   0.16} & \textbf{   0.83} & \textbf{   0.76} & \textbf{   0.29} &       & \textbf{   0.87} & \textbf{   0.59} & \textbf{   0.14} & \textbf{   0.74} & \textbf{   0.85} & \textbf{   0.19} \\
%     \specialrule{1.5pt}{0pt}{0pt}
%     \end{tabular}}%
%       \label{tab:1-commonsense}%
% \end{table*}%
%     \midrule
% \begin{table*}[htbp]
%   \centering
%    \caption{ Zero-Shot(top table) and Five-shot(bottom table) learning performance comparison on commonsense reasoning datasets using different models and methods. (Bold values indicate the best performance across different metrics for each dataset.)}
%    \subcaption[]{Zero-Shot Learning Performance.}
%     \resizebox{.98\textwidth}{!}{
%     \multirow{2}[4]{*}{\textbf{Model}} & \multirow{2}[4]{*}{\textbf{Method}} & \multicolumn{6}{c}{\textbf{LogiQA}}           &       & \multicolumn{6}{c}{\textbf{OpenbookQA}}       &       & \multicolumn{6}{c}{\textbf{CosmosQA}} \\
% \cmidrule{3-8}\cmidrule{10-15}\cmidrule{17-22}          &       & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} &       & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} &       & \textbf{IFR ↑} & \textbf{ACC ↑} & \textbf{ECE ↓} & \textbf{ROC ↑} & \textbf{PR-P ↑} & \textbf{PR-N ↓} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{LLaMA-2-7B} & ORI & 0.44  & \textbf{   0.37} & 0.52  & \textbf{   0.45} & \textbf{   0.48} & \textbf{   0.70} &       & 0.45  & \textbf{   0.40} & 0.49  & \textbf{   0.55} & \textbf{   0.54} & 0.64  &       & 0.49  & 0.37  & 0.52  & 0.45  & 0.45  & 0.65  \\
%           & POI & \textbf{   0.57} & 0.35  & \textbf{   0.40} & 0.41  & 0.45  & 0.74  &       & \textbf{   0.60} & 0.39  & \textbf{   0.43} & 0.35  & 0.48  & \textbf{   0.57} &       & \textbf{   0.63} & \textbf{   0.42} & \textbf{   0.45} & \textbf{   0.56} & \textbf{   0.57} & \textbf{   0.51} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{LLaMA-2-13B} & ORI & 0.55  & 0.38  & 0.45  & 0.49  & 0.56  & \textbf{   0.59} &       & 0.56  & 0.37  & 0.52  & 0.41  & 0.39  & 0.75  &       & 0.54  & \textbf{   0.46} & 0.47  & \textbf{   0.63} & \textbf{   0.67} & \textbf{   0.35} \\
%           & POI & \textbf{   0.63} & \textbf{   0.41} & \textbf{   0.38} & \textbf{   0.59} & \textbf{   0.66} & 0.68  &       & \textbf{   0.69} & \textbf{   0.48} & \textbf{   0.30} & \textbf{   0.59} & \textbf{   0.65} & \textbf{   0.51} &       & \textbf{   0.66} & 0.45  & \textbf{   0.32} & 0.59  & 0.65  & 0.48  \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{LLaMA-3-8B} & ORI & 0.71  & 0.43  & 0.35  & 0.67  & 0.72  & 0.36  &       & 0.76  & 0.44  & 0.30  & 0.67  & 0.60  & 0.43  &       & 0.74  & 0.46  & 0.25  & 0.67  & 0.71  & 0.46  \\
%           & POI & \textbf{   0.80} & \textbf{   0.47} & \textbf{   0.21} & \textbf{   0.79} & \textbf{   0.77} & \textbf{   0.25} &       & \textbf{   0.89} & \textbf{   0.57} & \textbf{   0.17} & \textbf{   0.81} & \textbf{   0.76} & \textbf{   0.28} &       & \textbf{   0.87} & \textbf{   0.53} & \textbf{   0.11} & \textbf{   0.78} & \textbf{   0.83} & \textbf{   0.25} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{Vicuna-7B} & ORI & 0.42  & \textbf{   0.29} & \textbf{   0.55} & 0.41  & \textbf{   0.42} & \textbf{   0.73} &       & 0.46  & 0.27  & 0.55  & 0.42  & 0.34  & 0.77  &       & 0.43  & 0.29  & 0.55  & 0.41  & 0.33  & 0.83  \\
%           & POI & \textbf{   0.50} & 0.27  & 0.47  & \textbf{   0.47} & 0.30  & 0.76  &       & \textbf{   0.63} & \textbf{   0.38} & \textbf{   0.31} & \textbf{   0.51} & \textbf{   0.48} & \textbf{   0.58} &       & \textbf{   0.65} & \textbf{   0.39} & \textbf{   0.37} & \textbf{   0.68} & \textbf{   0.46} & \textbf{   0.66} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{Vicuna-13B} & ORI & 0.49  & 0.33  & 0.37  & 0.47  & 0.38  & 0.78  &       & 0.58  & 0.35  & 0.42  & 0.54  & 0.40  & 0.67  &       & 0.63  & 0.44  & 0.45  & 0.55  & 0.57  & 0.50  \\
%           & POI & \textbf{   0.63} & \textbf{   0.37} & \textbf{   0.34} & \textbf{   0.53} & \textbf{   0.49} & \textbf{   0.65} &       & \textbf{   0.66} & \textbf{   0.44} & \textbf{   0.36} & \textbf{   0.58} & \textbf{   0.59} & \textbf{   0.51} &       & \textbf{   0.67} & \textbf{   0.49} & \textbf{   0.28} & \textbf{   0.71} & \textbf{   0.64} & \textbf{   0.44} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{GPT-3.5-Turbo} & ORI & 0.68  & 0.37  & 0.37  & 0.61  & 0.56  & 0.61  &       & 0.74  & 0.42  & 0.32  & 0.64  & 0.57  & 0.49  &       & 0.67  & 0.48  & 0.35  & 0.68  & 0.70  & 0.32  \\
%           & POI & \textbf{   0.77} & \textbf{   0.45} & \textbf{   0.23} & \textbf{   0.78} & \textbf{   0.70} & \textbf{   0.36} &       & \textbf{   0.81} & \textbf{   0.55} & \textbf{   0.19} & \textbf{   0.76} & \textbf{   0.74} & \textbf{   0.34} &       & \textbf{   0.84} & \textbf{   0.56} & \textbf{   0.18} & \textbf{   0.75} & \textbf{   0.79} & \textbf{   0.22} \\
% \cmidrule{1-8}\cmidrule{10-15}\cmidrule{17-22}    \multirow{2}[2]{*}{GPT-4} & ORI & 0.78  & 0.47  & 0.26  & 0.75  & 0.67  & 0.39  &       & 0.83  & 0.50  & 0.21  & 0.78  & 0.76  & 0.44  &       & 0.75  & 0.55  & 0.18  & 0.70  & 0.75  & 0.30  \\
%           & POI & \textbf{   0.86} & \textbf{   0.56} & \textbf{   0.12} & \textbf{   0.88} & \textbf{   0.80} & \textbf{   0.24} &       & \textbf{   0.91} & \textbf{   0.63} & \textbf{   0.13} & \textbf{   0.86} & \textbf{   0.87} & \textbf{   0.27} &       & \textbf{   0.89} & \textbf{   0.64} & \textbf{   0.09} & \textbf{   0.88} & \textbf{   0.92} & \textbf{   0.16} \\
%     \specialrule{1.5pt}{0pt}{0pt}
%     \end{tabular}}%
%   \label{tab:addlabel}%
% \end{table*}%

