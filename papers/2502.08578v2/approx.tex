We first derive a family of upper bounds on the approximation ratio of the coordinate-wise median mechanism in $\lqnorm$ for each value of $q\in[1,\infty)$ (note that the approximation guarantee for $\lqnorm[\infty]$ can be easily obtained by taking the limit of approximation results for $q\to\infty$). We then conclude this section with examples that demonstrate tightness of our upper bound guarantees for each value of $q\in\reals_{\ge 1}\cup\{\infty\}$
and unlimited dimension $d$. Specifically, these examples provide a family of lower bounds $\LB(q,d)$ for each value of $q$ and $d$, which converge to our upper bound $\UB(q)$ at a rate $\LB(q,d)\ge\UB(q)-O(\frac{1}{d})$.  

To derive the upper bounds $\UB(q)$ on the approximation ratio, we write a natural optimization problem over the set of $n$ points $\locs=(\loci)_{i=1}^n$ for a fixed positions of the facility $\facility\in\reals^d$ and the constraint that $\locs$ have a given coordinate-wise median $\median\in\reals^d$. Specifically, we encode the approximation ratio as a linear objective $\SC(\locs,\facility)-\lambda\cdot\SC(\locs,\median)$ for a constant 
$\lambda\in(0,1)$ that captures the inverse of the approximation 
ratio $1/\alpha$ of the coordinate-wise median mechanism $\median(\locs)$.
Our goal is to find $\lambda(q)>0$ such that the minimum of this optimization problem is at least $0$.

We normalize the parameters $(\facility,\median)$ of our optimization problem by applying simple translation, scaling, and reflection transformations of space $\reals^d$ so that: (i) $\median=\vect{0}=(0,\ldots,0)$; (ii) optimal facility $\facility=(f_1,\ldots,f_d)$ has all positive coordinates $f_j> 0$ (if $f_j=0$ we simply let $f_j=\eps$ for arbitrary small $\eps>0$ with only a negligible increase to the value of our optimization formulation); (iii) $\qnorm{\facility}=1$. We also assume that the total number of points $n$ is even, as we can duplicate all points in our instance without changing the locations of $\facility$ and $\median$. 
Our objective function $\SC(\locs,\facility)-\lambda\cdot\SC(\locs,\median)$ can be conveniently separated into $\sum_{i\in[n]}g(\loci)$, where $
g(\loci)\eqdef \qnorm{\loci-\facility}-\lambda\cdot\qnorm{\loci}$. To capture the constraint that $\median$ is a median of the set $\locs$, we define the \emph{signature} $\sigma(\loc)\in\{-1,1\}^d$ of a point $\loc=(p_1,\ldots,p_d)\in\reals^d$, where $\sigma(\loc)\eqdef(\sign(p_1),\ldots,\sign(p_d))$.    
The sign function $\sign(p_{j})=1$ if $p_{j}>0$ and $\sign(p_{j})=-1$ if $p_{j}<0$; when $p_{j}=0$, the sign can take either value $1$ or $-1$ (in the former case we write $p_{j}=0^+$ , and in the latter case we write $p_{j}=0^-$). Hence, our optimization problem can be succinctly written as follows.
\begin{align}
 \label{eq:main}
 \min\limits_{\locs}& \sum_{i\in[n]} g(\loci), &\quad %\text{where }
 where~ g(\loci)\eqdef\qnorm{\loci-\facility}-\lambda\cdot\qnorm{\loci} \nonumber\\
 \text{s.t.}&  \sum_{i\in [n]}\sigma(\loci) = \vect{0}, & 
\end{align}
We first observe that \eqref{eq:main} indeed achieves minimum (not an infinum) at a certain configuration of points $\locs=(\loci[1],\ldots,\loci[n])$ for each fixed value of $\lambda=\lambda(q)\in(0,1)$.
\begin{claim}
    \label{cl:compact set}
    The optimization problem~\eqref{eq:main} attains minimum.
\end{claim}
\begin{proof}
Consider a closed ball $B_R(\zerovec)\subset{\R^d}$ centered at $\zerovec$ with radius $R=\frac{2n}{1-\lambda}$. The continuous function $\sum_{i\in[n]}g(\loci)$ attains minimum on a compact set $\left\{\locs\in B_R(\zerovec)^n ~\mid~\sum_{i\in[n]}\sigma(\loci)=\vect{0}\right\}$.
Note that by triangle inequality $g(\loc)\ge\qnorm{\loc}-
\qnorm{\facility}-\lambda\cdot\qnorm{\loc}=(1-
\lambda)\cdot\qnorm{\loc}-\qnorm{\facility}\ge -1$ for any 
$\loc\in\reals^d$. By setting $\locs=
(\vect{0},\ldots,\vect{0})$ we get the value of 
$n\cdot\qnorm{\facility}=n$ in \eqref{eq:main}. Now, if any of the points $\loc\in\locs$ is outside of $B_R(\zerovec)$, then $g(\loc)> 2n-1$ and $\sum_{i\in[n]}g(\loci)> 2n-1 + (-1)\cdot (n-1)=n$, i.e., any $\locs$ outside of our compact set achieves larger value than $\locs=(\zerovec,\ldots,\zerovec)$. 
\end{proof}

To solve~\eqref{eq:main}, we first explore the local properties of the optimal solution. Namely, we fix signatures of all locations $\loc\in\locs$ and focus on a local optimization of $g(\loc)$ for a single location $\loc$ with a fixed signature $\sigma(\loc)=\sigma^o\in\{-1,1\}^d$. 
I.e., we find $\loc=\argmin\limits_{\vl:\sigma(\vl)=\sigma^o} g(\vl)$. 

\subsection{Optimization on individual points}
\label{sec:upper_local}
For a fixed signature $\sigma^o$ of $\loc$ we define 
$S(\loc)$ and $\overline{S}(\loc)$ as
$$
S\eqdef\{j\in [d]\ \vert \sigma_{j}^{o}=1\}
\quad\quad
\overline{S}\eqdef\{j\in [d]\ \vert \sigma_j^o=-1\}
$$
the sets of respectively positive and negative coordinates in $\loc$. Therefore, we need to minimize $g(\loc)$ for a $\loc\in\reals^d$ with  $p_j\in[0^+,\infty)$ when $j\in S=S(\loc)$ and $p_j\in(-\infty,0^-]$ when $j\in\overline{S}=\overline{S}(\loc)$. 

We begin by making a simple observation that the optimal $\loc$ may not have $p_j\notin[0^+,f_j)$ for each coordinate $j$. Namely,
\begin{claim}
    \label{cl:coordinate-wise condition}
    We have $p_j\in[f_j,+\infty)$ for each $j\in S$.
\end{claim}
\begin{proof}
If there exists a coordinate $j$ with $p_j\in[0^+,f_j)$, we can change $p_j$ to $f_j$. This does not affect the signature $\sigma(\loc)$. At the same time, it decreases $|p_j-f_j|$ making $\qnorm{\loc-\facility}$ smaller, and it increases $p_j$ making the value of $\qnorm{\loc}$ larger. I.e., $g(\loc)$ decreases, which means that $\loc$ was not optimal.
\end{proof}

We next explore local optimum conditions of $g(\loc)$, which allow us to explicitly find the values of each coordinate $p_j$, when $S\ne\emptyset$ and also narrow down the set of candidate locations for the case of $S=\emptyset$. The explicit form of optimal $\loc$ with given sets of positive and negative coordinates is summarized in the next Lemma~\ref{lm:local optimal condition}. We first define a non negative number $c(\loc)$ as  
    \be
    \label{eq:constant_c}
    c\eqdef
    \lambda^\frac{1}{q-1}\cdot\frac{\qnorm{\loc-\facility}}{\qnorm{\loc}} 
    \ee  
\begin{lemma}[Optimal $\loc$ with given signature $\sigma^o$]
    \label{lm:local optimal condition}
    %For each $\loc\in \locs$, there are two cases
    If
     \begin{enumerate}[label=(\roman*)]
        \item $S(\loc)\ne\emptyset$. Then $\frac{p_j-f_j}{p_j} = c$ for $j\in S$,  $p_j=0^-$ for $j\in \overline{S}$;
        \item$S(\loc)=\emptyset$. Then $\exists\ T\subseteq [d]$ such that $\frac{-p_j+f_j}{-p_j}=c$ for $j\in T$, $p_j=0^-$ for $j\notin T$.
    \end{enumerate}
    % The constant $c$ in either case is given by the formula
    % any coordinate of $\loc$ satisfies either (i) $S\neq\emptyset$, $\frac{p_j-f_j}{p_j} = c$ for $\forall j\in S$, where $c=\lambda^\frac{1}{q-1}\cdot\frac{\qnorm{\loc-\facility}}{\qnorm{\loc}}^{(*)}$ and $p_j=0^-$ for $\forall j\in \overline{S}$ or (ii) $S=\emptyset$, $\exists\ T\subseteq [d], \frac{-p_j+f_j}{-p_j}=c$ for $\forall i\in T$, with $c$ also given by (*), and  $p_j=0$ for $\forall i\in \overline{T}$.
\end{lemma}
\begin{proof}
% We write local optimum conditions of $g(\loc)$ separately for each of the coordinates $p_j$.
We distinguish the optimum solution $\loc$ with the variable $\vl$ in the optimization problem for $g(\vl)$. It is important to note that the function $g(\vl)=\qnorm{\vl-\facility}-\lambda\cdot\qnorm{\vl}$ is differentiable in $l_j$ when $l_j\notin \{0,f_j\}$. Hence, for every coordinate $p_j\notin\{0,f_j\}$ of the optimum  we have $
\frac{\partial}{\partial l_j}g(\vl)\big\vert_{\vl=\loc}=0
$. I.e., 
\begin{equation*}
%\label{eq:derivative_g}
    \left\{
    \begin{aligned}
    &\frac{\partial}{\partial l_j}g(\vl)\big\vert_{\vl=\loc}=\frac{(p_j-f_j)^{q-1}}{\qnorm{\loc-\facility}^{q-1}}-\lambda\cdot\frac{p_j^{q-1}}{\qnorm{\loc}^{q-1}}=0,\ &p_j>f_j\\
    &\frac{\partial}{\partial l_j}g(\vl)\big\vert_{\vl=\loc}=-\frac{(-p_j+f_j)^{q-1}}{\qnorm{\loc-\facility}^{q-1}}+\lambda\cdot\frac{(-p_j)^{q-1}}{\qnorm{\loc}^{q-1}}=0,\  &p_j< 0
    \end{aligned}
    \right.
\end{equation*}
Thus, for $c$ defined as in~\eqref{eq:constant_c} we get 
\begin{equation}
\label{eq:equation_for_c}
    \left\{
    \begin{aligned}
    &c = \frac{p_j-f_j}{p_j},\ &\text{when }p_j\in (f_j,+\infty)\\
    &c = \frac{f_j-p_j}{-p_j},\  &\text{when }p_j\in (-\infty,0)
    \end{aligned}
    \right.
\end{equation}
Furthermore, if $p_j=f_j$, the function $g(\vl)$ has the right-hand partial derivative $\frac{\partial}{\partial_{+}l_j}g(\vl)$ at $\vl=\loc$. As $\loc$ is the local minimum, $\frac{\partial}{\partial_+ l_j}g(\vl)\big\vert_{\vl=\loc}=\frac{(p_j-f_j)^{q-1}}{\qnorm{\loc-\facility}^{q-1}}-\lambda\cdot\frac{p_j^{q-1}}{\qnorm{\loc}^{q-1}}\ge 0$ when $p_j=f_j$, i.e., 
$
\frac{p_j-f_j}{p_j}\ge
\lambda^{\frac{1}{q-1}}\cdot\frac{\qnorm{\loc-\facility}}{\qnorm{\loc}}
$. As $c=\frac{\qnorm{\loc-\facility}}{\qnorm{\loc}}\ge 0$ and $p_j=f_j$, we get that $0=\frac{p_j-f_j}{p_j}\ge c\ge 0$. This means that $c=0$ and that \eqref{eq:equation_for_c} holds for a larger range of $p_j\in[f_j,+\infty)$.
% $\lambda^\frac{1}{q-1}\cdot\frac{\qnorm{\loc-\facility}}{\qnorm{\loc}}=c \le \frac{p_j-f_j}{p_j}=0$. By definition $c\ge 0$, thus we get $c=0=\frac{p_j-f_j}{p_j}$ when $p_j=f_j$. In other words, we can extend the range of $p_j$ in \eqref{eq:equation_for_c} to $p_j\in[f_j,+\infty)$.

Next, observe that $c = \frac{p_j-f_j}{p_j}<1$ in \eqref{eq:equation_for_c} when $p_j\in [f_j,\infty)$ (as $f_j>0$), and that $c=\frac{-p_j+f_j}{-p_j}>1$ when $p_j\in (-\infty, 0)$ for the same 
constant $c=\lambda^\frac{1}{q-1}\cdot\frac{\qnorm{\loc-\facility}}{\qnorm{\loc}}$. Hence, $\loc$ cannot 
simultaneously have coordinates $p_j\in[f_j,\infty)$ and $p_i\in(-\infty,0)$ for $i,j\in[d]$. I.e., when $S(\loc)\ne\emptyset$, we have $c<1$, which means that $p_j=0^-$ for any $j\in\overline{S}$ and $c=\frac{p_j-f_j}{p_j}$ for any $j\in S$. This concludes the proof for the 
case (i). On the other hand, when $S(\loc)=\emptyset$, then equation \eqref{eq:equation_for_c} gives us (ii) for $T\eqdef\{j\in [d] ~|~p_j < 0\}$.
\end{proof}

Lemma~\ref{lm:local optimal condition}, while describing the optimal point $\loc\in\reals^d$ with given signature $\sigma(\loc)$ (equivalently, with given sets $S(\loc)$ and $\overline{S}(\loc)$), still does not explain the relation between this signature and the respective value of $g(\loc)$ in the global optimization problem~\eqref{eq:main}. We express $g(\loc)$ for the optimal point $\loc$ as the function of $\energy[S]$ (and $\energyc[S]$) given by\footnote{We generally use the notation $\energy[X]\eqdef\sum_{j\in X}{f_j}^q$ for any set $X\subseteq[d]$.} 
\[
\energy[S]\eqdef\sum_{j\in S}{f_j}^q\quad\quad
\energyc[S] \eqdef\sum_{j\in \overline{S}}f_j^q=1-\energy[S]
\]
% $\energy[S]\eqdef\sum_{j\in S}{f_j}^q$ and 
% $\energyc[S] \eqdef\sum_{j\in \overline{S}}f_j^q=1-\energy[S]$ 
% (we generally use notation $\energy[X]\eqdef\sum_{j\in X}{f_j}^q$ for any set $X\subseteq[d]$) 
in the next Lemma~\ref{lm:expression for local optimum}, which is essential for handling the main optimization problem~\eqref{eq:main}.  
% Next, given the description of the optimal point $\loc\in\locs$ with a fixed 
% signature $\sigma(\loc)=\sigma^o$ in Lemma~\ref{lm:local optimal condition} we can conveniently express $g(\loc)$ as a function of sets 
% $S$,$\overline{S}$ for the signature $\sigma^o=\sigma(\loc)$ and 
% $\facility$. Specifically, we express $g(\loc)$ as a function of 
% $\energy[S]\eqdef\sum_{j\in S}{f_j}^q$ and 
% $\energyc[S] \eqdef\sum_{j\in \overline{S}}f_j^q=1-\energy[S]$ 
% (we generally use notation $\energy[X]\eqdef\sum_{j\in X}{f_j}^q$ for any set $X\subseteq[d]$).
\begin{lemma}[Expression of $g(\loc)$ as a function of $\Delta_{_S}$]
    \label{lm:expression for local optimum}
    For an optimal $\loc$ with 
    given sets of positive $S$ and negative $\overline{S}$ coordinates, if 
    \begin{enumerate}[label=(\roman*)]
        \item $S(\loc)\ne\emptyset$, then 
        $g(\loc)=\Big(1-\lambda^{q/(q-1)}\Big)^{(q-1)/q}\cdot\ecsq-\lambda\cdot\esq$.
        \item $S(\loc)=\emptyset$, then 
        $g(\loc)\geq\Big(1-\lambda^{q/(q-1)}\Big)^{(q-1)/q}$.
    \end{enumerate}
\end{lemma}
\begin{proof}[Proof sketch]
The proof for the most part is elementary algebraic manipulations. We only present key steps and defer detailed derivations to Appendix~\ref{sec:appendix}.
When $S(\loc)\neq\emptyset$, according to Lemma~\ref{lm:local optimal condition}, $p_j=f_j/(1-c)$ for $j\in S$. Then $g(\loc)=\qnorm{\loci-\facility}-\lambda\cdot\qnorm{\loci}$ is
\begin{align}
\label{eq:g(p)}
g(\loc)=\left(\left(\frac{c}{1-c}\right)^q\cdot\esq+\ecsq\right)^{1/q}-\lambda\cdot\frac{1}{1-c}\cdot\ecsq.
\end{align}
Using that $c=\lambda^{1/(q-1)}\cdot\qnorm{\loc-\facility}/\qnorm{\loc}$, we obtain the following equations that allow us to replace terms dependent on $c$ in \eqref{eq:g(p)}:
\begin{align*}
&\frac{c}{1-c}=\left(\frac{\energyc}{\energy}\right)^{1/q}\cdot\left(\frac{\lambda}{1-\lambda^{q/(q-1)}}\right)^{1/q},\quad\text{and}\quad\frac{1}{1-c}=\frac{c}{1-c}+1.
\end{align*}

% \begin{align*}
% \text{Then,}\quad g(\loc)&=\left(\left(\frac{c}{1-c}\right)^q\cdot\energy+\energyc\right)^{1/q}-\lambda\cdot\frac{1}{1-c}\cdot\ecsq\\
% &=\left(1-\lambda^{q/(q-1)}\right)^{(q-1)/q}\cdot\ecsq-\lambda\cdot\esq.
% \end{align*}
\[
\text{Then,}\quad g(\loc)=\left(\left(\frac{c}{1-c}\right)^q\cdot\energy+\energyc\right)^{1/q}-\lambda\cdot\frac{1}{1-c}\cdot\ecsq
=\left(1-\lambda^{q/(q-1)}\right)^{(q-1)/q}\cdot\ecsq-\lambda\cdot\esq.
\]
This concludes the proof for the case $S(\loc)\ne\emptyset$. When $S(\loc)=\emptyset$ and $T=\{j~|~p_j< 0^-\}\neq\emptyset$, we obtain similar expression of $g(\loc)$ for a fixed set $T$: 
\begin{align*}
g(\loc)=
        \left(1-\lambda^{q/(q-1)}\right)^{(q-1)/q}\cdot(1-\energyT)^{1/q}+\lambda\cdot\etq.
\end{align*}
We want to understand what is the minimum of the above expression for $g(\loc)$ over 
all possible $T\subseteq[d]$, $T\ne\emptyset$ (when $T=\emptyset$, $g(\loc)=1$). Let 
$x\eqdef\energyT$, then $x\in[0,1]$ and $g(\loc)=t(x)\eqdef\left(1-\lambda^{q/(q-1)}\right)^{(q-1)/q}\cdot(1-x)^{1/q}+\lambda\cdot x^{1/q}$. Note that when 
$T\ne\emptyset$, we have $c>1$ in Lemma~\ref{lm:local optimal condition}, which 
implies that $\energyT\le\lambda^{q/(q-1)}$. Furthermore, as $t(x)$ is a positive 
linear combination of concave functions $x^{1/q}$ and $(1-x)^{1/q}$, the function 
$t(x)$ is concave on $x\in[0,\lambda^{q/(q-1)}]$ and, thus, achieves its minimum at 
the end points $x=0$, or $x=\lambda^{q/(q-1)}$. I.e., $t(0)=\left(1-\lambda^{q/(q-1)}\right)^{(q-1)/q}< 1=t(\lambda^{q/(q-1)})$ is the minimum value. Interestingly, we 
cannot achieve $x=\energyT=0$ for a nonempty $T$ and, on the other hand, when $T=\emptyset$ the point $\loc=\zerovec$ is not a local optimum (in this case $g(\zerovec)=1>\left(1-\lambda^{q/(q-1)}\right)^{(q-1)/q}$). We still get the desired lower bound on $g(\loc)\ge\left(1-\lambda^{q/(q-1)}\right)^{(q-1)/q}$ for the case $S(\loc)=\emptyset$.
\end{proof}

\subsection{Upper Bounds on Approximation Ratios}
\label{sec:upper_global}
We finally derive the family of upper bounds $\UB(q)$ on the approximation ratios $\alpha(q)$ of the median mechanism in $\lqnorm(\reals^{d})$.
\begin{theorem}
    \label{thm:UB}
    The median mechanism in the normed vector space $\lqnorm(\reals^{d})$ with $q\in\reals_{\ge 1}$ of arbitrary dimension $d\in\nats_{\ge 1}$ has
    approximation ratio $\alpha(q)\le\UB(q)$, where $\UB(q)$ is an increasing function in $q$ with $\UB(1)=1$ and $\UB(q)\to 3$ when $q\to\infty$.
    For $q=2$, $\UB(2)=\sqrt{6\sqrt{3}-8}\approx 1.55$.
\end{theorem}
\begin{proof} We now consider our main optimization problem~\eqref{eq:main}.
Lemma~\ref{lm:expression for local optimum} shows that, for any location $\loci\in\locs$, $g(\loci)$ can be expressed\footnote{In case $\energy[S(\loci)]=0$, we only have a lower bound on $g(\loci)$, which is without any loss of generality when dimension $d\to\infty$.} as a function of $\energy[S(\loci)]$ and $\energy[\overline{S}(\loci)]=1-\energy[S(\loci)]$. 
The constraints $\sum_{i\in [n]}\sigma(\loci) = \vect{0}$ of~\eqref{eq:main} is still unwieldy. On the other hand, it implies that
% \begin{multline}
%     \label{eq:relaxed_median_constraint}
%     \sum\limits_{i\in[n]}\energy[S(\loci)]=
%     \sum_{i\in[n]}\sum_{j:p_{i,j}\ge 0^+}f_j^q
%     \\
%     =\sum_{j\in[d]}f_j^q\cdot\sum_{i:p_{i,j}\ge 0^+}1
%     =\frac{n}{2}\cdot\sum_{j\in[d]}f_j^q=\frac{n}{2}.
% \end{multline}
\begin{equation}
    \label{eq:relaxed_median_constraint}
    \sum\limits_{i\in[n]}\energy[S(\loci)]=
    \sum_{i\in[n]}\sum_{j:p_{i,j}\ge 0^+}f_j^q
    =\sum_{j\in[d]}f_j^q\cdot\sum_{i:p_{i,j}\ge 0^+}1
    =\frac{n}{2}\cdot\sum_{j\in[d]}f_j^q=\frac{n}{2}.
\end{equation}
We simply relax the constraint in \eqref{eq:main} to \eqref{eq:relaxed_median_constraint} and solve the corresponding minimization problem (recall that we are interested in finding the largest possible $\lambda<1$ such that \eqref{eq:main} is at least $0$). To further simplify the presentation of the relaxed optimization problem, we let $x_i\eqdef\energy[S(\loci)]\in[0,1]$, $1-x_i=\energy[\overline{S}(\loci)]$, and define $\delta=\delta(\lambda)\eqdef\left(1-\lambda^{q/(q-1)}\right)^{(q-1)/q}/\lambda=\left(\lambda^{-q/(q-1)}-1\right)^{(q-1)/q}$, which is a decreasing function of $\lambda$.
Then the objective function of \eqref{eq:main} can be rewritten as $\sum_{i\in[n]}h(x_i)$, where $h(x_i)\eqdef \lambda\cdot\left(\delta\cdot(1-x_i)^{1/q}-x_i^{1/q}\right)$. The relaxed problem in $\vx=(x_i)_{i\in[n]}$ is as follows
\begin{align}
 \label{eq:relaxed main}
 \min\limits_{\vx}& \sum_{i\in[n]} h(x_i), &&\quad
 where~ h(x_i)\eqdef \lambda\cdot\left(\delta\cdot(1-x_i)^{1/q}- x_i^{1/q}\right)\nonumber\\
 \text{s.t.}&  \sum_{i\in [n]}x_i = \frac{n}{2},
 &&\quad\quad \forall i\in[n]~x_i\in[0,1]
\end{align}
Note that we are only interested in $\lambda$ such that $\delta(\lambda)\ge 1$ (otherwise, \eqref{eq:relaxed main} is negative for $(x_i=1/2)_{i\in[n]}$). Next, to solve \eqref{eq:relaxed main}, we explore convexity/concavity of $h(\cdot)$ on the interval $x\in[0,1]$.
\begin{claim}
    \label{cl:property of h(x)}
    The function $h(x)$ is convex in $x$ on $[0,z]$ and concave in $x$ on $[z,1]$, where $z\eqdef\delta^{-q/(2q-1)}/\left(\delta^{-q/(2q-1)}+1\right)\le 1/2$.
\end{claim}
\begin{proof}
We take second-order derivative of $h(x)$:
\begin{align*}
    \frac{\partial^2}{\partial x^2}h(x)=\lambda\cdot\frac{q-1}{q^2}\cdot\left(x^{-(2q-1)/q}-\delta\cdot(1-x)^{-(2q-1)/q}\right).
\end{align*}
The function $\frac{\partial^2}{\partial x^2}h(x)$ goes from $+\infty$ to $-\infty$ when $x$ goes from $0$ to $1$. The only real root of $\frac{\partial^2}{\partial x^2}h(x)$ on $x\in[0,1]$ is 
\[
z=\delta^{-q/(2q-1)}/\left(\delta^{-q/(2q-1)}+1\right).
\] 
As $\delta\ge 1$, we have $z\le\frac{1}{2}$.
Thus, $\frac{\partial^2}{\partial x^2}h(x)\ge 0$
for $x\in[0,z]$ implying that $h(x)$ is convex on $[0,z]$, and $\frac{\partial^2}{\partial x^2}h(x)\le 0$
for $x\in[z,1]$ implying that $h(x)$ is concave on $[z,1]$.
\end{proof}
Given Claim~\ref{cl:property of h(x)}, we can succinctly describe local minima of~\eqref{eq:relaxed main}.
\begin{lemma}[Possible Solutions to~\eqref{eq:relaxed main}]
    \label{optimal value of x_i}
    $\exists a\in[0,z],b\in[z,1)$, such that
    $\forall i\in[n]~x_i\in\{a, b, 1\}$ in the optimal solution to \eqref{eq:relaxed main}. Moreover, $\vert\{i\in[n]~\vert~ x_i=b\}\vert\le 1$. 
\end{lemma}
\begin{proof}
First, we show that $\exists a\in[0,z]$ such that each $x_i=a$ if $x_i\in[0,z]$. Assume towards a contradiction that $0\le x_1 < x_2\le z$ in \eqref{eq:relaxed main}. As $h(\cdot)$ is convex on $[0,z]$, we could replace $x_1$ and $x_2$ with $x_1+\eps$ and $x_2-\eps$ without violating the constraint $\sum_{i\in[n]}x_i=n/2$ and reduce $h(x_1)+h(x_2)>h(x_1+\eps)+h(x_2-\eps)$.

Next, we show that there could be at most one $x_i\in(z,1)$ in the optimum solution to \eqref{eq:relaxed main}. We assume that $z<x_1\leq x_2<1$ towards a contradiction. Then we could decrease $h(x_1)+h(x_2)>h(x_1-\eps)+h(x_2+\eps)$ by moving $x_1$ and $x_2$ to $x_1-\eps$ and $x_2+\eps$ without violating the constraint $\sum_{i\in[n]}x_i=n/2$.
\end{proof}
Lemma~\ref{optimal value of x_i} allow us to reduce the space of optimization~\eqref{eq:relaxed main} to only three parameters $a,b,$ and the number of points $|\{i: x_i=a\}|$. Moreover, since we may duplicate the locations of optimal solution $\locs$ without changing the objectives and violating the constraints in~\eqref{eq:main} and~\eqref{eq:relaxed main}, we can assume that the minimum in~\eqref{eq:main} and~\eqref{eq:relaxed main} is attained when the number of points $n$ goes to infinity. Now, when $n\to+\infty$ we can ignore the effect of a single point\footnote{Formally, for any $\lambda\in(0,1)$ such that~\eqref{eq:relaxed main} is strictly smaller than $0$ for $n=n_0$ points, we let $n=100\cdot n_0$ and construct a feasible solution $\vx$ to \eqref{eq:relaxed main}, such that all $x_i\in\{a,1\}$ and $\sum_{i\in[n]}h(x_i)<0$.} $x_i=b$ in~\eqref{eq:relaxed main}, which reduces the number of parameter down to $2$ ($a$, $|\{i: x_i=a\}|$). As we have the constraint $\sum_{i=1}^n x_i = n/2$, the number $|\{i: x_i=a\}|$ and $|\{i: x_i=1\}|$ must be respectively $\frac{n}{2(1-a)}$ and $\frac{1-2a}{2(1-a)}\cdot n$. 
I.e., there is only one parameter $a$ to optimize in~\eqref{eq:relaxed main}. Recall that we need to find $\lambda$ (which defines $\delta(\lambda)$) such that   $\sum_{i\in[n]}h(x_i)\ge 0$ for any feasible $\vx$
in~\eqref{eq:relaxed main}.
Equivalently, we need to find $\lambda$ such that
\begin{align}
    \label{eq: optimization over a}   &\min_{a\in[0,z]}\left[\frac{n}{2(1-a)}\cdot h(a) + \frac{1-2a}{2(1-a)}\cdot n\cdot h(1)\right]&\\
    &=\min_{a\in[0,z]}\left[\frac{n}{2(1-a)}\cdot\lambda\cdot\left(\delta\cdot(1-a)^{1/q}-a^{1/q}-1+2\cdot a\right)\right]\ge 0,\nonumber
\end{align}
Thus, we need to minimize $u(a)\eqdef\delta\cdot(1-a)^{1/q}-a^{1/q}-1+2\cdot a$.
Let $a^*\eqdef \argmin\limits_{a\in[0,z]} u(a)$. We observe that 
% \Jianhao{i modified the proof of lemma 4 and changed the form of equation (8).}
\begin{lemma}
    \label{lm:optimal solution for a}
    If $u(a^*)=0$, then $a^*$ is optimal $\Rightarrow u'(a^*)=0$.
\end{lemma}
The proof of Lemma~\ref{lm:optimal solution for a} is straightforward (we simply verify that if $u(a^*)=0$, $a\in\{0,z\}$ are not optimal, and that $u'(a)=0$ has a unique solution on $(0,z)$) and we defer it to Appendix. 

The final step in the proof of Theorem~\ref{thm:UB} is to find $\lambda^*$ such that the minimum of \eqref{eq:relaxed main} and respectively \eqref{eq: optimization over a} is equal to $0$.
As \eqref{eq:relaxed main} is a relaxation of \eqref{eq:main} with a smaller or equal value, we immediately would get that \eqref{eq:main} has value at least $0$ for $\lambda=\lambda^*$, which translates into $1/\lambda^*$ approximation guarantee for the coordinate-wise median mechanism. By Lemma~\ref{lm:optimal solution for a}, the optimal $\lambda^*$ and $a^*$ must satisfy equations $u(a^*)=0$ and $u'(a^*)=0$. Then by denoting $\delta^*=\delta(\lambda^*)$, we get the following system of equations on $\lambda^*$ and $a^*$
\begin{equation}
\label{eq:upper bound}
\left\{
    \begin{aligned}
    &\delta^*\cdot(1-a^*)^{\frac{1}{q}}-{(a^*)}^{\frac{1}{q}}-1+2\cdot a^*=0\\
    &\frac{1}{q}\cdot\left(-\delta^*\cdot(1-a^*)^{\frac{1-q}{q}}-(a^*)^{\frac{1-q}{q}}\right)+2=0.
    \end{aligned}
    \right.
\end{equation}
After multiplying by $1-a^*$ the second equation in \eqref{eq:upper bound}, we get
\begin{equation}
\label{eq:inequality of a}
    \frac{1}{q}\cdot\left(-\delta^*\cdot(1-a^*)^{\frac{1}{q}}+(a^*)^{\frac{1}{q}}-(a^*)^{\frac{1-q}{q}}\right)+2-2a^*=0.
\end{equation}
The first equation in \eqref{eq:upper bound} gives us $\delta^*\cdot(1-a^*)^{1/q}-{(a^*)}^{1/q}=1-2\cdot a^*$. By plugging it in \eqref{eq:inequality of a} we get
\begin{align}
    \label{eq:optimal a^*}
    2\cdot\left(1-\frac{1}{q}\right)\cdot a^*+\frac{1}{q}\cdot (a^*)^{\frac{1-q}{q}}-2+\frac{1}{q}=0.
\end{align}
We now obtain $\lambda^*(q)$ through the following steps:
\begin{enumerate}[label=(\roman*)]
        \item find $a^*$ from equation~\eqref{eq:optimal a^*}.
        \item set $\delta^*=\left((a^*)^{1/q}+1-2\cdot a^*\right)/(1-a^*)^{1/q}$ from the first line of~\eqref{eq:upper bound}.
        \item calculate $\lambda^*$ by inverting function $\delta(\lambda)=\left(\lambda^{-\frac{q}{q-1}}-1\right)^{\frac{q-1}{q}}$ at $\delta=\delta^*$:
        \[
        \lambda^*=\left(1+(\delta^*)^{\frac{q}{q-1}}\right)^{-\frac{q-1}{q}}.
        \]
\end{enumerate}
We can numerically calculate $a^*(q)$ for each $q\ge 1$ and then get $\UB(q)=1/\lambda^*(q)$ (see figure~\ref{fig:UB(q)}).
\begin{figure}[htb] 
		\centering
		\includegraphics[width=5.0in]{UB_20.png}
		\caption{UB(q)}
\label{fig:UB(q)}		
\end{figure}

Furthermore, for $q=2$ and $q\to+\infty$ we can find algebraic expressions for $a^*$ and thus get precise values of $\UB(q)$. In particular, for $q=2$ the equation \eqref{eq:optimal a^*} becomes $a^*+\frac{1}{2}\cdot (a^*)^ {-1/2}-\frac{3}{2}=0$, which gives $a^*=1-\frac{\sqrt{3}}{2}$. By following steps (ii) and (iii) we get $\UB(2)=1/\lambda^*=\sqrt{6\sqrt{3}-8}$.
When $q\rightarrow\infty$, in step (i) one can get $a=\frac{1+o(1)}{2q}$. Then by (ii) we get $\delta^*\rightarrow (a^*)^{1/q}+1\rightarrow 2$ and by (iii) $\lambda^*\rightarrow 1/(1+\delta^*)\rightarrow 1/3$. I.e., we get that median mechanism is a $3$-approximation under $\lqnorm[\infty]$ norm.
\end{proof}

\subsection{Lower Bounds on Approximation Ratios}
\label{sec:lower_global}
In this section, we show that the upper bound $\UB(q)$ is essentially tight by constructing a series of instances for each norm $\lqnorm$ with $q\ge 1$ and each dimension $d\in\nats_{\ge 1}$ such that coordinate-wise median achieves $\LB(q,d)=\UB(q)\cdot\left(1-O(\frac{1}{d})\right)$ approximation. For a given $q$ and $d$ our instance is as follows.

The optimal facility location is at $\facility=(1,1,\cdots,1)\in\reals^d$ and the median $\m=(0,0,\cdots,0)\in\reals^d$. We shall use parameters $a^*,\lambda^*$ given by \eqref{eq:optimal a^*}. We also define parameter $c^*$ (analog of $c$ from Section~\ref{sec:upper_local}) as
\begin{align*}
        c^*\eqdef\frac{\left(\frac{1-a^*}{a^*}\cdot\frac{(\lambda^*)^{q/(q-1)}}{1-(\lambda^*)^{q/(q-1)}}\right)^{1/q}}{1+\left(\frac{1-a^*}{a^*}\cdot\frac{(\lambda^*)^{q/(q-1)}}{1-(\lambda^*)^{q/(q-1)}}\right)^{1/q}}.
\end{align*}        
The number of points $n$ is a very large integer. There are only two types of points $\loc\in\reals^d$ in $\locs$.
\begin{description}
        \item[Type I.] $\flr{a^*\cdot d}$ coordinates are $1/(1-c^*)$ and the rest are $0$.        
        \item[Type II.] $\loc=(1,1,\cdots,1)$ the same as $\facility$.
\end{description}
The numbers\footnote{Obviously, both of these numbers must be integers, but as $n$ can be arbitrary large, we will simply ignore the dependency on $n$ and the fact that $\frac{n}{2-2a^*}$ may be non integer.} of Type I and II points are respectively $\frac{n}{2-2a^*}$ and $n\cdot\frac{1-2a^*}{2-2a^*}$. 
The strictly positive coordinates of Type I points are uniformly distributed across all $d$ coordinates.
Then the social costs of the median mechanism $\SC(\locs,\median)$ and the optimum $\SC(\locs,\facility)$ are respectively
\begin{align*}
    &\sum_{\loc\in\locs} \qnorm{\m-\loc}=\frac{1}{1-c^*}\cdot\flr{a^*\cdot d}^{1/q}\cdot\frac{n}{2-2a^*}+d^{1/q}\cdot\frac{1-2a^*}{2-2a^*}\cdot n,\\
    &\sum_{\loc\in\locs} \qnorm{\facility-\loc}=\left(\left(\frac{c^*}{1-c^*}\right)^q\cdot \flr{a^*\cdot d}+(d-\flr{a^*\cdot d})\right)^\frac{1}{q}\cdot\frac{n}{1-2a^*}.
\end{align*}
We note that when $d\rightarrow\infty$, the approximation ratio for our instance is approaching $\UB(q)=1/\lambda^*$, as the difference between $\flr{a^*\cdot d}$ and $a^*\cdot d$ is negligible: 
\begin{align*}
    \frac{\sum_{\loc\in\locs} \qnorm{\m-\loc}}{\sum_{\loc\in\locs} \qnorm{\facility-\loc}}
    \underset{d\to+\infty}{\longrightarrow}
    \frac{\frac{1}{1-c^*}\cdot (a^*)^{1/q}+1-2a^*}{\left(\left(\frac{c^*}{1-c^*}\right)^q\cdot a^* +1-a^*\right)^{1/q}}=1/\lambda^*.
\end{align*}
For a given $d$ we get the following lower bound on the approximation ratio
\begin{align*}
    &\frac{\sum_{\loc\in\locs} \qnorm{\m-\loc}}{\sum_{\loc\in\locs} \qnorm{\facility-\loc}}=\frac{\frac{1}{1-c^*}\cdot\flr{a^*\cdot d}^{1/q}+d^{1/q}\cdot(1-2a^*))}{\left(\left(\frac{c^*}{1-c^*}\right)^q\cdot \flr{a^*\cdot d}+(d-\flr{a^*\cdot d})\right)^{1/q}}\\
    &\leq \frac{\frac{1}{1-c^*}\cdot(a^*\cdot d)^{1/q}+d^{1/q}\cdot(1-2a^*))}{\left(\left(\frac{c^*}{1-c^*}\right)^q\cdot (a^*\cdot d-1)+(d-a^*\cdot d)\right)^{1/q}}\\
    &\leq \frac{\frac{1}{1-c^*}\cdot(a^*\cdot d)^{1/q}+d^{1/q}\cdot(1-2a^*))}{\left(\left(\frac{c^*}{1-c^*}\right)^q\cdot (a^*\cdot d)+(d-a^*\cdot d)\right)^{1/q}}\cdot\frac{1}{(1-O(\frac{1}{d}))^{1/q}}\\
    &\leq \frac{1}{\lambda^*\cdot(1-O(\frac{1}{d}))}.
\end{align*}
%\Jianhao{the case of $q=\infty$}
For the important special case of $\lqnorm[\infty](\reals^d)$, our instance consists of the following two types of points.
\begin{description}
        \item[Type I.] One coordinate is $2$ and all remaining coordinates are $0$.        
        \item[Type II.] $\loc=(1,1,\cdots,1)$ the same as $\facility$.
\end{description}
There are $\frac{d}{2d-1}\cdot n$ points of Type I and $\frac{d-1}{2d-1}\cdot n$ points of Type II. The non zero coordinate of Type I points are distributed uniformly over $[d]$.  The approximation ratio of the median mechanism is
\begin{align*}
    \frac{\sum_{\loc\in\locs} \qnorm[\infty]{\m-\loc}}{\sum_{\loc\in\locs} \qnorm[\infty]{\facility-\loc}}
    = \frac{2\cdot\frac{d}{2d-1}\cdot n+1\cdot\frac{d-1}{2d-1}\cdot n}{1\cdot\frac{d}{2d-1}\cdot n}=3-\frac{1}{d}\underset{d\to+\infty}{\longrightarrow}
    3.
\end{align*}

In summary, we obtain the following result
% The first equality holds because when $d\rightarrow\infty$, the consequence of replacing $\flr{a^*\cdot d}$ with $a^*\cdot d$ in the formula is negligible. 
%In this section, we derive our lower bounds $\LB(q,d)$ of the median mechanism.
\begin{theorem}
    \label{thm:LB}
   For $\lqnorm(\reals^d)$ with any $q\ge 1$ and $d\in\nats_{\ge 1}$, the 
   approximation ratio of the median mechanism is at most $\LB(q,d)=(1-O(\frac{1}{d}))\cdot\UB(q)$.
   I.e., the upper bound $\UB(q)$ is tight for $d\rightarrow\infty$.
\end{theorem}