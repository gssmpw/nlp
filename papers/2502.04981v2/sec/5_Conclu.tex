\section{Conclusion}
In this paper, we propose \ourmethod{}, an vision-centric automated pipeline for open-ended semantic occupancy annotation that integrates differentiable Gaussian splatting guided by vision-language models.
To facilitate scene understanding, we leverage VLMs and build an efficient and comprehensive scene representation for occupancy annotation. \ourmethod{} integrates vision-language attention with visual foundation models, effectively handles dynamic objects over time, and enhances both spatiotemporal consistency and geometric detail. 
Our framework achieves state-of-the-art performance on open-ended semantic occupancy annotation and performs favorably against other automated annotation pipeline, without using any human annotations.

