\section{Experiments}
\label{sec:exp}
\noindent\textbf{Datasets.} {\YuiR Following existing studies~\cite{liu2023hybrid,zhoustrengthened,liu2020learning,mccreesh2017partitioning,solnon2015complexity,hoffmann2017between},} we use four benchmark graph collections, namely biochemicalReactions (\textsf{BI}), images-CVIU11 (\textsf{CV}), images-PR15 (\textsf{PR}) and LV (\textsf{LV}), in the experiments. All datasets are collected from http://liris.cnrs.fr/csolnon/SIP.html and come from real-world applications in various domains, {\Yui as shown in Table~\ref{tab:my_label}}. Specifically, \textsf{BI} contains 136 unlabeled bipartite graphs, each of which corresponds to a biochemical reaction network. \textsf{CV} contains 44 pattern graphs and 146 target graphs, which are generated from segmented images. \textsf{PR} contains 24 pattern graphs and 1 target graph, which are also from segmented images. \textsf{LV} contains 112 graphs generated from biological networks. 
%
{\YuiR All graphs have up to thousands of vertices. We note that (1) solving our problem on two graphs with beyond 10K vertices is challenging based on the worst-case time complexity of $O^*((|V_G|+1)^{|V_Q|})$, (2) the largest graph used in previous studies~\cite{liu2023hybrid,zhoustrengthened,liu2020learning,mccreesh2017partitioning} has 6,771 vertices, which is also covered (in LV) by our experiments, and (3) finding the largest common subgraph between two graphs with thousands of vertices has found many real applications~\cite{ehrlich2011maximum}.}
%
{\Yui Following existing studies~\cite{liu2023hybrid,zhoustrengthened,liu2020learning,mccreesh2017partitioning,solnon2015complexity,hoffmann2017between}}, for \textsf{BI} and \textsf{LV}, we generate and test the problem instances (i.e., $Q$ and $G$) by pairing any two distinct graphs; and for \textsf{CV} and \textsf{PR} {\revision which consist of two types of graphs, namely pattern graphs and target graphs}, we test all those problem instances with one graph $Q$ from pattern graphs and the other $G$ from target graphs.

\begin{table*}[]
    \centering
    \caption{\Yui Datasets used in the experiments (``\# of solved instances'' refers to the number of instances solved by algorithms within 1,800 seconds and ``Achieved speedups'' refers to the percentage of the solved instances that \texttt{RRSplit} runs at least 5$\times$/10$\times$/100$\times$ faster than \texttt{McSplitDAL})}
    \vspace{-0.15in}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
        \multirow{2}{*}{Dataset} & \multirow{2}{*}{Domain} & \multirow{2}{*}{\# of graphs} & \multirow{2}{*}{\# of instances} & \multirow{2}{*}{\# of vertices} & \multicolumn{2}{c|}{\# of solved instances} & \multicolumn{3}{c|}{Achieved speedups} \\
        \cline{6-10}
        & & & & & \texttt{RRSplit} & \texttt{McSplitDAL} & 5$\times$ & 10$\times$ & 100$\times$\\
        \hline
        \textsf{BI} & Biochemical & 136 & 9,180 & 9$\sim$ 386 & 7,730 & 4,696 & 91.3\% & 84.4\% & 69.7\% \\
        \textsf{CV} & Segmented images & 190 & 6,424 & 22$\sim$ 5,972 & 1,351 & 1,291& 76.5\% & 48.6\% & 0.2\% \\
        \textsf{PR} & Segmented images & 25& 24& 4$\sim$ 4,838  & 24 & 24 & 91.7\% & 91.7\% & 58.3\% \\
        \textsf{LV} & Synthetic & 112 & 6,216& 10$\sim$ 6,671 & 1,059 & 883 & 68.0\% & 54.7\% & 38.3\%\\
        \hline
    \end{tabular}
    
    \label{tab:my_label}
\end{table*}

\begin{table*}[]
    \centering
    \caption{\YuiR Comparison of running time on all datasets (statistics of achieved speedups in Figure~\ref{fig:all_datasets_T})}
    \vspace{-0.15in}
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        \multirow{2}{*}{Dataset} & \multicolumn{3}{c|}{\texttt{RRSplit} runs faster} & \multicolumn{3}{c|}{\texttt{McSplitDAL} runs faster} \\
        \cline{2-7}
        & \% of instances & Avg. speedup & Max. speedup & \% of instances & Avg. speedup & Max. speedup\\
        \hline
        BI& 99.43\% & 3.3$\times 10^4$ & $10^6$ & 0.5\% & 24.81 & 872.37 \\
        CV& 92.15\% & 10.92 & 161 & 7.84\% & 4.96 & 38.97 \\
        PR& 95.83\% & 139.39 & 234 & 4.17\% & 1.23 & 1.23 \\
        LV& 93.48\% & 1.2$\times 10^4$ & $10^6$ & 6.51\% & 24.23 & 652.13 \\
        \hline
    \end{tabular}
    
    \label{tab:results}
\end{table*}

\smallskip
\noindent\textbf{Algorithms.} We compare the newly proposed algorithm \texttt{RRSplit} with \texttt{McSplitDAL}~\cite{liu2023hybrid}. To be specific, \texttt{McSplitDAL} is one variant of \texttt{McSplit} as introduced in Section~\ref{sec:sota}, which follows the framework of \texttt{McSplit} (i.e., Algorithm~\ref{alg:mcsplit}) and introduces some learning-based techniques for optimizing the policies of selecting vertices at line 6, line 8 and line 10 of Algorithm~\ref{alg:mcsplit}. To our best knowledge, \texttt{McSplitDAL} is the state-of-the-art algorithm and runs significantly faster than previous solutions, including \texttt{McSplitLL}~\cite{zhoustrengthened} and \texttt{McSplitRL}~\cite{liu2023hybrid}. Besides these, in order to study the effectiveness of different reductions employed in our algorithm \texttt{RRSplit}, we evaluate three variants of  \texttt{RRSplit} --  
{\YuiR \texttt{RRSplit-VE}, \texttt{RRSplit-MB}, and \texttt{RRSplit-UB}, respectively obtained by turning off vertex-equivalence based reductions, maximality based reductions,  and  vertex-equivalence based upper bound}. 
%namely \texttt{RRSplit-MR} and \texttt{RRSplit-VER},


\smallskip
\noindent\textbf{Implementation and metrics.} All algorithms are implemented in C++ and compiled with -O3 optimization. All experiments run on a Linux machine with a 2.10GHz Intel CPU and 128GB memory. Note that, for the implementation of \texttt{McSplitDAL}, we directly use the source code from the authors of~\cite{liu2023hybrid}. We record and compare the total running times of the algorithms on different problem instances (note that the measured running time excludes the I/O time of reading graphs from the disk). We set the running time limit (INF) as 1,800 seconds by default. Our data and code are available at https://github.com/KaiqiangYu/SIGMOD25-MCSS. 

\subsection{Comparison among algorithms}

\begin{figure}[]
		\subfigure[\textsf{BI}]{
			\includegraphics[width=4.0cm]{figure/BI_TDS.pdf}
		}
		\subfigure[\textsf{CV}]{
			\includegraphics[width=4.0cm]{figure/ICVIU11_TDS.pdf}
		}
		\subfigure[\textsf{PR}]{
			\includegraphics[width=4.0cm]{figure/PR15_TDS.pdf}
		}	
		\subfigure[\textsf{LV}]{
			\includegraphics[width=4.0cm]{figure/LV_TDS.pdf}
		}
        \vspace{-0.15in}
	\caption{Running time on all datasets. {\Yui For those problem instances locating at the right side of dash line `- .' with orange color (resp. `- -' with green color),  \texttt{RRSplit} achieves at least 100$\times$ (resp. 10$\times$) speedup compared with \texttt{McSplitDAL}.}}
	\label{fig:all_datasets_T}
\end{figure}

\noindent\textbf{All datasets (running time)}. We compare our algorithm \texttt{RRSplit} with the baseline \texttt{McSplitDAL} on all graph collections. {\YuiR Following some existing works~\cite{mccreesh2016clique}}, we report the running times of the algorithms on various problem instances in Figure~\ref{fig:all_datasets_T}. 
%
%
Specifically, each dot in the scatter figures represents a problem instance, with the $x$-axis (resp. $y$-axis) corresponding to the running time of \texttt{RRSplit} (resp. \texttt{McSplitDAL}) {\chengC on the instance}. Hence, for those problem instances with small values on $x$-axis and large values on $y$-axis (which thus locate on the top left region of the figures), \texttt{RRSplit} performs better than \texttt{McSplitDAL}.
%In particular, for those problem instances locating at the right side of dash line `- .' {\Yui with orange color} (resp. `- -' with green color),  \texttt{RRSplit} achieves at least 100$\times$ (resp. 10$\times$) speedup compared with \texttt{McSplitDAL}. 
We mark the running time as INF if the problem instance cannot be solved within the default time limit.
%
{\YuiR Besides, we also provide some statistics in Table~\ref{tab:my_label} and Table~\ref{tab:results}.}
%
We observe that (1) \texttt{RRSplit} outperforms \texttt{McSplitDAL} by achieving around one to {\Yui four} orders of magnitude speedup {\YuiR (in average)} on the majority {\YuiR (above 92\%)} of the tested problem instances and (2) \texttt{McSplitDAL} cannot handle all problem instances within the time limit. 
% This fact demonstrates the efficiency of our algorithm \texttt{RRSplit}. 
We do note that \texttt{McSplitDAL} runs slightly faster on a few {\YuiR (below 8\%)} problem instances in \textsf{CV} and \textsf{LV}. {\YuiR Some possible reasons are as follows. 
First, our \texttt{RRSplit} introduces some extra time costs for conducting the proposed reductions as well as computing the upper bound. Second, the heuristic polices adopted in \texttt{RRSplit} and \texttt{McSplitDAL} for branching may have different behaviors. 
%
In specific, on these problem instances, the heuristic policies may help \texttt{McSplitDAL} to find a large common subgraph quickly so as to prune more unpromising branches {\revision via the upper-bound based reduction} (note that they are based on reinforcement learning {\cheng and the behaviors of the learned policy is} based on the explored branches during the running time). } 

%{\cheng One possible reason could be that} their learned heuristic policies can help to find a large common subgraph quickly so as to prune more unpromising branches {\cheng on these datasets}. 


\begin{figure}[]
		\subfigure[\textsf{BI}]{
			\includegraphics[width=4.0cm]{figure/BI_Branch_TDS.pdf}
		}
		\subfigure[\textsf{CV}]{
			\includegraphics[width=4.0cm]{figure/ICVIU11_Branch_TDS.pdf}
		}
		\subfigure[\textsf{PR}]{
			\includegraphics[width=4.0cm]{figure/PR15_Branch_TDS.pdf}
		}	
		\subfigure[\textsf{LV}]{
			\includegraphics[width=4.0cm]{figure/LV_Branch_TDS.pdf}
		}
        \vspace{-0.15in}
	\caption{Number of formed branches on all datasets}
	\label{fig:all_datasets_BT}
\end{figure}

\smallskip
\noindent\textbf{All datasets (number of formed branches)}. We report the number of branches formed by the algorithms on different problem instances in Figure~\ref{fig:all_datasets_BT}. Similarly, each dot in the scatter figures represents a problem instance, with the $x$-axis (resp. $y$-axis) corresponding to the number of branches formed by \texttt{RRSplit} (resp. \texttt{McSplitDAL}) {\chengC on the instance}. We have the following observations. First, the number of branches formed by \texttt{RRSplit} is significantly {\chengC smaller} than that formed by \texttt{McSplitDAL}, e.g., the former is around 10\% - 0.01\% of the latter on the most of problem instances. This shows the effectiveness of our proposed maximality-based reductions and vertex-equivalence-based reductions.
%, and is also compatible with the theoretical results.
Second, the distribution of the number of formed branches in Figure~\ref{fig:all_datasets_BT} is consistent with that of the running time in Figure~\ref{fig:all_datasets_T}. This indicates the achieved speedups on the running time \laks{can be traced} to our newly-designed reductions.

\begin{figure}[]
		\subfigure[\textsf{BI}]{
			\includegraphics[width=4.0cm]{figure/BI_CDF.pdf}
		}
		\subfigure[\textsf{CV}]{
			\includegraphics[width=4.0cm]{figure/ICVIU11_CDF.pdf}
		}
		\subfigure[\textsf{PR}]{
			\includegraphics[width=4.0cm]{figure/PR15_CDF.pdf}
		}	
		\subfigure[\textsf{LV}]{
			\includegraphics[width=4.0cm]{figure/LV_CDF.pdf}
		}
        \vspace{-0.2in}
	\caption{Comparison by varying time limits}
	\label{fig:all_vary_T}
\end{figure}

\begin{figure}[]
		\subfigure[\textsf{BI}]{
			\includegraphics[width=4.0cm]{figure/BI_Branch_CDF.pdf}
		}
		\subfigure[\textsf{CV}]{
			\includegraphics[width=4.0cm]{figure/ICVIU11_Branch_CDF.pdf}
		}
		\subfigure[\textsf{PR}]{
			\includegraphics[width=4.0cm]{figure/PR15_Branch_CDF.pdf}
		}	
		\subfigure[\textsf{LV}]{
			\includegraphics[width=4.0cm]{figure/LV_Branch_CDF.pdf}
		}
        \vspace{-0.2in}
	\caption{Comparison by varying the limit of number of formed branches}
	\label{fig:all_vary_B}
\end{figure}

\smallskip
\noindent\textbf{Varying time limits}. We report the number of solved problem instances in Figure~\ref{fig:all_vary_T} as the time limit is varied. Clearly, all algorithms solve more problem instances as the time limit increases. We observe that \texttt{RRSplit} solves more problem instances than \texttt{McSplitDAL} within the same time limit. In particular, \texttt{RRSplit} with a time limit of 1 second even solves more problem instances than \texttt{McSplitDAL} with a time limit of 10 seconds in all graph collections {\cheng except for} \textsf{CV}; and on \texttt{PR}, \texttt{RRSplit} solves all problem instances within the time limit of 10 seconds. This further demonstrates the superiority of our algorithm \texttt{RRSplit} over the baseline \texttt{McSplitDAL}. 

\smallskip
\noindent\textbf{Varying the limits of number of formed branches}. We report the number of solved problem instances in Figure~\ref{fig:all_vary_B} as the limit on  number of formed branches is varied. We note that the more branches are allowed to be formed, the more instances will be solved. We observe that (1) \texttt{RRSplit} solves more problem instances than \texttt{McSplitDAL} within the same limit of the number of formed branches and (2) the results in Figure~\ref{fig:all_vary_B} show  similar tendencies as those in Figure~\ref{fig:all_vary_T} in general. This further {\cheng explains} the practical superiority of the newly proposed reductions.


\begin{figure}[]
		\subfigure[\textsf{Running time (BI)}]{
			\includegraphics[width=4.0cm]{figure/BI_SIM.pdf}
		}	
		\subfigure[\textsf{Running time (LV)}]{
			\includegraphics[width=4.0cm]{figure/LV_SIM.pdf}
		}
        \subfigure[\textsf{\# of branches (BI)}]{
			\includegraphics[width=4.0cm]{figure/BI_SIMB.pdf}
		}	
		\subfigure[\textsf{\# of branches (LV)}]{
			\includegraphics[width=4.0cm]{figure/LV_SIMB.pdf}
		}
        \vspace{-0.2in}
	\caption{Comparison by varying similarities}
	\label{fig:all_vary_S}
\end{figure}

\smallskip
\noindent\textbf{Varying the similarities of  input graphs}. We define the similarity of  input graphs $Q$ and $G$, $Sim(Q,G)$, as follows.
\begin{equation}
\label{eq:sim}
    Sim(Q,G)=\frac{|S^*|}{\min\{|V_Q|,|V_G|\}},
\end{equation}
where $S^*$ is the maximum common subgraph between $Q$ and $G$. Clearly, $Sim(Q,G)$ varies from 0 to 1, and the larger the value of $Sim(Q,G)$, the higher the similarity between $Q$ and $G$. We test different problem instances as the similarity varies from 0.5 to 1 on \textsf{BI} and \textsf{LV}, and report the average running time in Figures~\ref{fig:all_vary_S}(a)-(b) and the average number of formed branches in Figures~\ref{fig:all_vary_S}(c)-(d). {\Yui The results on \textsf{CV} and \textsf{PR} show similar trends, complete details of which appear in the 
\ifx \CR\undefined
Appendix. 
\else
technical report~\cite{TR}. 
\fi
}  We can see that \texttt{RRSplit} consistently outperforms \texttt{McSplitDAL} {\chengC in} various settings, e.g., \texttt{RRSplit} runs several orders of magnitude faster and forms fewer branches than \texttt{McSplitDAL}. This demonstrates that our designed reductions are effective for pruning the redundant branches on problem instances with various similarities. Besides, we observe that both \texttt{RRSplit} and \texttt{McSplitDAL} have the running time and the number of formed branches first increase and then decrease as the similarity grows. {\revision The possible reasons are as follows. (1) The maximum common subgraphs become larger as the similarity increases according to Equation~(\ref{eq:sim}) and typically more common subgraphs will be explored for finding a large maximum common subgraph. Therefore, the running time firstly increases; (2) the upper-bound based reduction {\chengE performs} better as the similarity grows. {\chengE For example, in the setting of} $Sim(Q,G)=1$, the algorithm can be terminated directly once a common subgraph with $\min\{|V_Q|,|V_G|\}$ vertices is found. Therefore, the running time then decreases.}

%Possible reasons include (1) the number of common subgraphs (i.e., search space) first increases and then decreases as the similarity grows and/or (2) the proposed reductions performs better on those problem instances with the similarity {\cheng close to} 0.5 or 1.   


\begin{figure}[]
		\subfigure[\textsf{\Yui Varying time limits (BI)}]{
			\includegraphics[width=4.0cm]{figure/BI_RT.pdf}
		}	
		\subfigure[\textsf{\Yui Varying time limits (LV)}]{
			\includegraphics[width=4.0cm]{figure/LV_RT.pdf}
		}
        \subfigure[\textsf{\Yui Varying limit of \#branches (BI)}]{
			\includegraphics[width=4.0cm]{figure/BI_BT.pdf}
		}	
		\subfigure[\textsf{\Yui Varying limit of \#branches (LV)}]{
			\includegraphics[width=4.0cm]{figure/LV_BT.pdf}
		}
        \vspace{-0.15in}
	\caption{Comparison among various reductions}
	\label{fig:all_vary_R}
\end{figure}

{\revision
\smallskip
\noindent\textbf{Scalability test.} We test the scalability of our \texttt{RRSplit} on two large datasets, i.e., \textsf{Twitter} and \textsf{DBLP}, which are collected from different domains (http://konect.cc/). Here, \textsf{Twitter} is a social network with 465,017 vertices and 833,540 edges, and \textsf{DBLP} is a collaboration network with 317,080 vertices and 1,049,866 edges. Following existing studies~\cite{arai2023gup,jin2023circinus,sun2023efficient}, we generate the problem instances (i.e., $Q$ and $G$) as follows. Let \textsf{Twitter} or \textsf{DBLP} be the graph $G$. We first extract a set of graphs $Q$ from $G$. Specifically, we conduct a random walk on $G$ and extract a subgraph induced by the visited vertices. By varying the size of the extracted graph $Q$ (among $\{20,30,40,50,60\}$), we extract 5 sets and each of them contains 100 different graphs $Q$.
%
Then, we generate different problems by pairing the graph $G$ (i.e., \textsf{Twitter} or \textsf{DBLP}) with different graphs $Q$ in the set. In summary, for each dataset, we have 500 different problem instances. 

We compare our \texttt{RRSplit} with \texttt{McSplitDAL} by varying the size of $Q$, and report the average running time in Figure~\ref{fig:scalability_test}. We observe that our \texttt{RRSplit} outperforms \texttt{McSplitDAL} significantly.
% , which demonstrates the scalability of the proposed method. 
Besides, \texttt{McSplitDAL} cannot handle almost all the problem instances within the time and/or space limit (INF/OOM). This is because the implementation of \texttt{McSplitDAL} highly relies on the adjacent matrix of $Q$ and $G$, which introduces huge space and time costs when $G$ is very large. Finally, we observe that \texttt{RRSplit} has the running time increase as the size of $Q$ grows. This is also consistent with the theoretical analysis.
}

\begin{figure}[]
		\subfigure[\textsf{Running time (Twitter)}]{
			\includegraphics[width=4.0cm]{figure/TW_S.pdf}
		}	
		\subfigure[\textsf{Running time (DBLP)}]{
			\includegraphics[width=4.0cm]{figure/DBLP_S.pdf}
		}
        \vspace{-0.2in}
	\caption{\revision Scalability test on large datasets}
	\label{fig:scalability_test}
\end{figure}

\subsection{Ablation studies}

We study the effects of various reductions on reducing the redundant computations. In specific, we compare \texttt{RRSplit} with three variants, namely \texttt{RRSplit-VE}: the full version without vertex-equivalence based reductions, \texttt{RRSplit-MB}: the full version without maximality based reductions and \texttt{RRSplit-UB}: the full version without the vertex-equivalence based upper bound, on \textsf{BI} and \textsf{LV}. We report the number of solved problem instances in Figure~\ref{fig:all_vary_R}(a,b) for varying the time limit and in Figure~\ref{fig:all_vary_R}(c,d) for varying the limit of number of formed branches. {\Yui The results on \textsf{CV} and \textsf{PR} show similar clues, which we put in the 
\ifx \CR\undefined
Appendix. 
\else
technical report~\cite{TR}. 
\fi
First, we can see that all four algorithms perform better than the baseline \texttt{McSplitDAL}, among which \texttt{RRSplit} performs the best. This demonstrates the effectiveness of vertex-equivalence-based reductions, maximality-based reductions and vertex-equivalence-based upper bound. Second, \texttt{RRSplit-VE} and \texttt{RRSplit-MB} {\chengB achieve} comparable performance and {\chengB both} contribute to the improvements. Specifically, we note that \texttt{RRSplit-VE} runs slightly faster than \texttt{RRSplit-MB} on \textsf{BI} while \texttt{RRSplit-MB} runs slightly faster than \texttt{RRSplit-VE} on \textsf{LV}. }  {\revision This is possibly because graphs in \textsf{BI} are relatively small biochemical networks where two vertices are more likely to be structural equivalent and thus the vertex-equivalence based reductions outperform other reductions, while graphs in \texttt{LV} are synthetic networks. }