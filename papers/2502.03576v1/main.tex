% These are the instructions for authors for IJCAI-25.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai25.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai25}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[switch]{lineno}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% From previous version
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathtools}
%\usepackage{stmaryrd}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{bm}
\usepackage[bb=dsserif]{mathalpha} %fixes \mathbb{1}
\usepackage [mathscr] {eucal}
\usepackage{float}
\usepackage{xcolor}
\usepackage[colorinlistoftodos]{todonotes}  % required for comment macro
\usepackage{color}                          % required for comment macro
\usepackage{totcount}                       % required for comment macro
\usepackage{tikz}
\usetikzlibrary{intersections}
\usetikzlibrary{patterns} % Load the patterns library
\usetikzlibrary{patterns.meta}

% Colors
\newcommand{\pill}[1]{\textbf{#1}}
\definecolor{Red}{RGB}{210, 0 , 30}
\definecolor{Blue}{RGB}{0, 30, 210}
\definecolor{Green}{RGB}{15, 210, 15}
\definecolor{Cyan}{RGB}{0, 190, 180}
\definecolor{Beryl}{RGB}{80, 170, 200}
\definecolor{Cerulean}{RGB}{42, 82, 190}
\definecolor{Azure}{RGB}{0, 127, 255}
\definecolor{Indigo}{RGB}{70, 0, 130}
\definecolor{Navy}{RGB}{0, 0, 128}
\definecolor{Sapphire}{RGB}{15, 82, 186}
\definecolor{Turquoise}{RGB}{64, 200, 210}
\definecolor{Ultramarine}{RGB}{20, 10, 150}
\definecolor{Bordeaux}{RGB}{120, 0, 5}

% Comments
\reversemarginpar
\newtotcounter{notecount}
\newcommand{\notewarning}{%
\ifnum\totvalue{notecount}>0%
 \vspace{1ex}
\begin{center}
 \begin{tikzpicture}[baseline=(A.south)]
    \node (A) [] at (0,0){};
    \node [rounded corners=1pt,rectangle, draw=red, fill=red!20,text=black](B) at (0.1ex,0ex){
        \Large \raggedright {\bf Warning:} There are still some notes left!
    };
 \end{tikzpicture}
\end{center}
 \vspace{1ex}
\fi
}
\makeatletter
\def\myaddcontentsline#1#2#3{%
  \addtocontents{#1}{\protect\contentsline{#2}{#3}{Section \thesubsection\ at p. \thepage}{}}}
\renewcommand{\@todonotes@addElementToListOfTodos}{%
    \if@todonotes@colorinlistoftodos%
        \myaddcontentsline{tdo}{todo}{{%
            \colorbox{\@todonotes@currentbackgroundcolor}%
                {\textcolor{\@todonotes@currentbackgroundcolor}{o}}%
            \ \@todonotes@caption}}%
    \else%
        \myaddcontentsline{tdo}{todo}{{\@todonotes@caption}}%
   \fi}%
\newcommand*\mylistoftodos{%
  \begingroup
       \setbox\@tempboxa\hbox{Section 9.9 at p. 99}%
       \renewcommand*\@tocrmarg{\the\wd\@tempboxa}%
       \renewcommand*\@pnumwidth{\the\wd\@tempboxa}%
       \listoftodos%
  \endgroup
}
\makeatother
\definecolor{lightgreen}{rgb}{0.86, 0.93, 0.78}
\definecolor{bordergreen}{rgb}{0.55, 0.76, 0.74}
\definecolor{lightblue}{rgb}{0.70, 0.90, 0.99}
\definecolor{borderblue}{rgb}{0.01, 0.66, 0.96}
\definecolor{lightamber}{rgb}{1, 0.93, 0.70}
\definecolor{borderamber}{rgb}{1, 0.76, 0.03}

\newcommand{\damien}[1]{\stepcounter{notecount}\todo[caption={},inline,bordercolor=bordergreen,linecolor=bordergreen,color=lightgreen]{\footnotesize{Damien:} #1}{}}
\newcommand{\damiens}[1]{\stepcounter{notecount}\todo[caption={},bordercolor=bordergreen,linecolor=bordergreen,color=lightgreen, fancyline]{\footnotesize{Damien:} #1}{}}

% Commands

\DeclareMathOperator*{\argmin}{\arg\!\min}

\newcommand\restr[2]{{% we make the whole thing an ordinary symbol
  \left.\kern-\nulldelimiterspace % automatically resize the bar with \right
  #1 % the function
  \littletaller % pretend it's a little taller at normal size
  \right|_{#2} % this is the delimiter
  }}

\newcommand{\littletaller}{\mathchoice{\vphantom{\big|}}{}{}{}}



%%%%%%%%%%%%%%%%%%%%%%%%

% Comment out this line in the camera-ready submission
%\linenumbers

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{assumption}{Assumption}
\newtheorem{axiom}{Axiom}
\newtheorem{example}{Example}
\newtheorem*{remark}{Remark}

\newtheorem{rthm}{Theorem}
\newenvironment{reptheorem}[1]
  {\renewcommand\therthm{\ref*{#1}}\rthm}
  {\endrthm}

\newtheorem{rlem}{Lemma}
\newenvironment{replemma}[1]
  {\renewcommand\therlem{\ref*{#1}}\rlem}
  {\endrlem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.


% PDF Info Is REQUIRED.

% Please leave this \pdfinfo block untouched both for the submission and
% Camera Ready Copy. Do not include Title and Author information in the pdfinfo section
\pdfinfo{
/TemplateVersion (IJCAI.2025.0)
}



\title{Clone-Resistant Weights in Metric Spaces:\\ A Framework for Handling Redundancy Bias}


\author{
Damien Berriaud
\And
Roger Wattenhofer\\
\affiliations
 ETH Z\"urich\\
\emails
\{dberriaud, wattenhofer\}@ethz.ch
}



\begin{document}


\maketitle

\begin{abstract}
    We are given a set of elements in a metric space. The distribution of the elements is arbitrary, possibly adversarial. Can we weigh the elements  
    in a way that is resistant to such
    (adversarial) manipulations?
    This problem arises in various contexts. For instance, the elements could represent data points,
    requiring robust domain adaptation. 
    Alternatively, they might represent tasks to be aggregated into a benchmark; or questions about personal political opinions in voting advice applications.
    This article introduces a theoretical framework for dealing with such problems. We propose \textit{clone-proof representation functions} as a solution concept. 
    These functions distribute importance across elements of a set such that similar objects (``clones'') share (some of) their weights, thus avoiding a potential bias introduced by their multiplicity.
    Our framework extends the maximum uncertainty principle to accommodate general metric spaces and includes a set of axioms --- symmetry, continuity, and clone-proofness --- that guide the construction of representation functions.
    Finally, we address the existence of representation functions satisfying our axioms in the significant case of Euclidean spaces and propose a general method for their construction.
\end{abstract}




\section{Introduction}






Morpheus: ``You take the \textcolor{Blue}{\pill{blue}} pill and the story ends. You wake up in your bed and believe whatever you want to believe. 
You take the \textcolor{Red}{\pill{red}} pill, you stay in Wonderland and I show you how deep the rabbit hole goes.''
Before Neo can make his choice, Morpheus continues: ``Or you can take this \textcolor{Indigo}{\pill{indigo}} pill, and wake up with \$100 in your pocket. Or this \textcolor{Navy}{\pill{navy}} pill
%, and you wake up 
-- with a different hair color.''
Why would Morpheus present these insignificant shades of blue? 
Neo already feels manipulated, but Morpheus continues excitedly and adds 
%even 
more pills colored in \textcolor{Bordeaux}{\pill{bordeaux}}, \textcolor{Cyan}{\pill{cyan}}, and \textcolor{Green}{\pill{green}}?!






\begin{figure}[!tbh]
    \centering
    \begin{tikzpicture}[scale=5]

\definecolor{PaperBlue}{HTML}{1f77b4}
\definecolor{PaperOrange}{HTML}{ff7f0e}
\definecolor{PaperGreen}{HTML}{2ca02c}
\definecolor{PaperRed}{HTML}{d62728}
\definecolor{PaperGrey}{HTML}{7f7f7f}
\definecolor{PaperYellow}{HTML}{ffdd00}

% Draw the equilateral triangle (simplex)
\coordinate (R) at (1, 0); % Red
\coordinate (G) at (0, 0); % Green
\coordinate (B) at (0.5, {sqrt(3)/2}); % Blue

% Draw triangle
\fill[PaperOrange, opacity=0.05] (R) -- (G) -- (B) -- cycle;

% Draw and fill the arcs' intersections with the triangle
% Centered at R
\begin{scope}
    \clip (R) -- (G) -- (B) -- cycle; % Restrict to the triangle
    \fill[PaperRed, opacity=0.1] (0.7, 0) arc[start angle=180, end angle=120, radius=0.3];
\end{scope}
\fill[PaperRed, opacity=0.1] (1, 0) -- (0.85, 0.2598) -- (0.7, 0) -- cycle;


% Centered at G
\begin{scope}
    \clip (R) -- (G) -- (B) -- cycle; % Restrict to the triangle
    \fill[PaperGreen, opacity=0.1] (0.3, 0) arc[start angle=0, end angle=60, radius=0.3];
\end{scope}
\fill[PaperGreen, opacity=0.1] (0, 0) -- (0.15, 0.2598) -- (0.3, 0) -- cycle;

% Centered at B
\begin{scope}
    \clip (R) -- (G) -- (B) -- cycle; % Restrict to the triangle
    \fill[PaperBlue, opacity=0.1] (0.5 - 0.15, {sqrt(3)/2 - 0.259}) arc[start angle=-120, end angle=-60, radius=0.3];
\end{scope}
\fill[PaperBlue, opacity=0.1] (0.5, {sqrt(3)/2}) -- (0.35, {sqrt(3)/2 - 0.259}) -- (0.65, {sqrt(3)/2 - 0.259}) -- cycle;

% Draw dashed arcs
\draw[dashed, PaperRed] (0.7, 0) arc[start angle=180, end angle=120, radius=0.3];
\draw[dashed, PaperGreen] (0.3, 0) arc[start angle=0, end angle=60, radius=0.3];
\draw[dashed, PaperBlue] (0.5 - 0.15, {sqrt(3)/2 - 0.259}) arc[start angle=-120, end angle=-60, radius=0.3];

% Normalize
\newcommand{\plotcolor}[4]{
    % #1 = name, #2 = R, #3 = G, #4 = B
    \pgfmathsetmacro{\Sum}{#2 + #3 + #4}
    \pgfmathsetmacro{\RNorm}{#2 / \Sum}
    \pgfmathsetmacro{\GNorm}{#3 / \Sum}
    \pgfmathsetmacro{\BNorm}{#4 / \Sum}
    \pgfmathsetmacro{\x}{\RNorm * 1 + \GNorm * 0 + \BNorm * 0.5}
    \pgfmathsetmacro{\y}{\RNorm * 0 + \GNorm * 0 + \BNorm * sqrt(3)/2}
    \fill[#1] (\x, \y) circle (0.01) node[below right] {#1};
}

% Plot all the colors
\plotcolor{Red}{210}{0}{30}
\plotcolor{Bordeaux}{120}{10}{3}
\plotcolor{Blue}{10}{30}{210}
\plotcolor{Cyan}{0}{190}{180}
\plotcolor{Indigo}{70}{0}{170}
\plotcolor{Navy}{0}{0}{128}
\plotcolor{Green}{5}{120}{3}

\end{tikzpicture}

    \caption{Which weight should we give to each individual point?
    By symmetry, one would expect 
    the areas in \textcolor{Blue}{blue}, \textcolor{Red}{red} and \textcolor{Green}{green} to sum up to the same value, even though they contain different numbers of points. 
    How to deal with the addition of \textcolor{Cyan}{cyan} though?
    }
    \label{fig:intro_RGB_triangle}
\end{figure}

Is there an objective way to make a choice without being bamboozled 
(see Figure~\ref{fig:intro_RGB_triangle})?
This problem is at the heart of machine learning as well as various other areas, e.g., distributed systems or social choice. Let us first discuss some application examples:



(i) In machine learning, one may want to tackle class imbalance in multi-label classification problems, e.g., by giving weights to the individual contribution of each sample to the loss.
More generally, reweighing a loss function
according to a clone-proof representation
can be thought of as a distribution-agnostic importance sampling technique. As such, it could be beneficial whenever the most informative samples become increasingly difficult to obtain,
either because of the \emph{computational cost} associated with computing the associated true label, e.g., for protein folding \cite{jumper_highly_2021}, Graph Neural Networks-based SAT solvers \cite{wang_neuroback_2024}, climate modeling \cite{eyring_pushing_2024};
%,kochkov_neural_2024
or simply because of their \emph{relative rarity}, e.g., for rare disease diagnosis in medical image analysis \cite{banerjee_machine_2023},
%,li_role_2024}
fraud detection in financial systems \cite{motie_financial_2024}, low-resources languages in Natural Language Processing \cite{hedderich_survey_2021}.
%,magueresse_low-resource_2020}.

(ii) Benchmarking theory presents another natural context. 
Consider a composite benchmark consisting of different tasks; however, it quickly becomes apparent that many tasks are quite similar. Perhaps they should share some of their weight?
Recent research has proposed to revisit benchmarking practices through the lens of social choice theory \cite{colombo_what_2022,rofin_votenrank_2023,zhang_inherent_2024}.
%tatiana_how_2021,
While this approach enables a more accurate aggregation of individual tasks' performance into a final score, we argue that benchmarking diverges from traditional voting scenarios in a key way: anonymity, or the equal treatment of votes, is not inherently required. Instead, the benchmark's outcome should
%must 
remain unaffected by the inclusion of numerous highly similar tasks, as this could unfairly favor models that perform well on the original task over those excelling in other areas. 
Weighing tasks with a clone-proof representation offers a solution to this problem. 

(iii) Finally, clone-proof representations offer a novel set of tools to mitigate Sybil attacks in distributed systems. While reputation mechanisms are designed to promote cooperation, significant research has focused on preventing adversaries from exploiting these systems by creating fake identities that mutually reinforce one another \cite{resnick_sybilproof_2009,seuken_sybil-proof_2014,stannat_achieving_2021}.
%seuken_sybil-proofness_2011,cheng_sybilproof_2005,
Similarly, researchers have sought to design mechanisms that incentivize information diffusion within social networks without encouraging the creation of fraudulent identities \cite{babaioff_bitcoin_2016,chen_sybil-proof_2023,zhang_sybil-proof_2020}. In both scenarios, clone-proof representations could help regulate the influence of Sybils once detected, effectively shifting the challenge to identifying these artificially generated identities.







\paragraph{Contribution \& Outline}

This work proposes a mathematical framework for handling redundancy in a metric space. 
Specifically, we tackle the problem of determining the relative importance of elements in a finite set such that close-by elements, or ``clones,'' share some of their weight.
To extend the well-understood case of discrete metrics, where elements are either similar or equally dissimilar, we introduce in Section~\ref{sec:axioms} the concept of representation function and propose a set of axioms that such functions should satisfy in general metric spaces. 
These properties can be broadly categorized into three key principles: symmetry, continuity, and clone-proofness.
Building on these foundations, we address in Section~\ref{sec:local_voting} the challenges of constructing functions that adhere to these axioms.
For the specific case of Euclidean spaces, we resolve the question of existence and construct, in Theorems~\ref{thm:local_vote_rep_func} and~\ref{thm:cont_convex_combi_gr}, a family of desirable representation functions.
We finally explore in Section~\ref{sec:discu} possible extensions of our construction to more general spaces and discuss the computational hurdles associated with its evaluation.







\section{Related Work}

 
Our work intersects with several bodies of literature; we focus hereafter on 
three of the most relevant topics.



\paragraph{Benchmark Aggregation and Measuring Task Similarity.}

In a recent line of work \cite{colombo_what_2022,himmi_towards_2023,rofin_votenrank_2023,tatiana_how_2021,zhang_inherent_2024}, multi-tasks benchmarking practices have been scrutinized through the lenses of social choice theory. In particular, these works question the usage of the arithmetical mean to aggregate scores of different tasks in popular benchmarks \cite{koh_wilds_2021,wang_superglue_2020}
%wang_glue_2019,
and investigate different aggregates such as the Pythagorean means \cite{tatiana_how_2021}, the Bradley-Terry model \cite{peyrard_better_2021}, or other classical voting rules \cite{colombo_what_2022,himmi_towards_2023,rofin_votenrank_2023}.

Contrary to usual voting scenarios where the equal treatment of voters is of utmost importance, there is apriori no requirement to treat each task equally in benchmark aggregation scenarios, and we may want to consider voting schemes with different weights, e.g., chosen arbitrarily by the benchmark creator.
These weights may however carry more information than arbitrary preference. In \cite{balduzzi_re-evaluating_2018}, researchers proposed to model the evaluation of agents on different tasks through a zero-sum meta-game played between an ``agent'' and a ``task'' player, each choosing a probability distribution over the corresponding set. Scores on different tasks are then aggregated with a weighted average, where the weights correspond to the probability of playing each task in the entropy-maximizing Nash Equilibrium. One of the desirable properties of this technique is that it is invariant under the addition of \emph{exact} copies of agents, a property which has been studied under the appellation \emph{false-name-proofness} in social choice theory \cite{conitzer_using_2010,nehama_manipulation-resistant_2022,todo_characterizing_2009}. Note however that this property is very brittle and only applies to purely adversarial scenarios, as we lose all guarantees whenever a vanishingly small amount of noise is added to one of the copies. 
Our work aims exactly at extending this property to near-copies, thus ensuring it remains usable in real-world scenarios. Calculating the weights for different tasks using the representation function introduced in this work ensures an automatic scaling of the benchmark, i.e., the evaluation always benefits from adding new although slightly redundant tasks.


 
Importantly, our framework assumes that practitioners provide a suitable distance metric, as its selection lies beyond the scope of this work.
Identifying an appropriate distance metric between tasks or datasets is a critical prerequisite for applying our approach effectively. 
Fortunately, this challenge has been extensively explored 
%in prior works 
\cite{alvarez-melis_geometric_2020,gretton_kernel_2012,liu_wasserstein_2022}, particularly within the transfer learning literature \cite{achille_task2vec_2019,peng_domain2vec_2020}. 
This existing body of research complements our work and provides valuable guidance for practitioners seeking to use our framework for benchmark aggregation.








\paragraph{Domain Adaptation and Samples Reweighting.}

In traditional learning setups, training and testing data are assumed to follow the same distribution. \emph{Domain adaptation} \cite{wang_deep_2018}, however, addresses scenarios where this assumption is violated, such as in the presence of class imbalance or label noise \cite{torralba_unbiased_2011}.

One approach to handle biases in training datasets involves assigning weights to individual samples and minimizing a weighted loss. Classical algorithms, such as AdaBoost \cite{freund_decision-theoretic_1997}, hard-negative mining \cite{chang_active_2018},
%,malisiewicz_ensemble_2011,lin_focal_2018
self-paced learning \cite{jiang_self-paced_2015}, adapt these weights dynamically during training based on the observed training loss. In contrast, the \emph{meta-learning} framework \cite{jamal_rethinking_2020,ren_learning_2019,shu_meta-weight-net_2019}
%
iteratively optimizes the weighting 
%weights 
to minimize loss on a small, unbiased validation dataset. Diverging from these methods, we consider a one-shot scenario, where the sample weighting is determined a priori and remains fixed.


In the context of imbalanced classification and long-tailed datasets, reweighting techniques have been explored extensively \cite{cao_learning_2019,dong_class_2017,gebru_fine-grained_2017}. These methods typically assign weights inversely proportional to the number of instances in each class. Recent approaches, such as those proposed in \cite{cui_class-balanced_2019}, go further by accounting for data overlap. They suggest weighting samples based on the effective number of samples, under the intuition that the marginal benefit of adding a new sample diminishes as the sample count grows. Specifically, they expand each data point to include its surrounding neighborhood and define the informativeness of a sample as the additional coverage %volume
it contributes compared to the scenario where the sample is excluded.
Our theoretical framework, in particular the locality axiom (see Axiom~\ref{axi:alpha_clone_locality}) and the volume-based construction 
%parametrized by $\alpha$ 
(see Section~\ref{sec:local_voting}), draws a close parallel to their total volume of sampled data, but extends this intuition beyond simple classification problems.


More generally, reweighting is a key technique in addressing \emph{covariate shift} within domain adaptation. Covariate shift occurs when the input distribution differs between training and evaluation datasets, i.e., $P_{train}(x) \neq P_{test}(x)$, but the conditional distribution $P_{train}(y \vert x) = P_{test}(y \vert x)$ remains consistent. Originating in importance sampling -- a technique commonly used to reduce variance in Monte Carlo estimation -- different methods \cite{y_covariate_2019} tackle covariate shift by reweighting samples with the ratio $P_{test} (x) / P_{train}(x).$ Approaches such as \emph{Kernel Density Estimation} \cite{hardle_nonparametric_2004} approximate these distributions using Gaussian kernels but suffer from the curse of dimensionality. Alternatively, \emph{Kernel Mean Matching} \cite{gretton_covariate_2009} minimizes the discrepancy between training and test distributions by aligning their means in a reproducing kernel Hilbert space, effectively estimating $P_{test} (x) / P_{train}(x) $ directly.
In contrast to these statistical methods, our approach does not rely on assumptions about the stochasticity of the sampling process. Instead, we adopt an axiomatic framework that provides robustness guarantees even when samples are adversarially selected. This makes our method more resilient to challenges like dataset poisoning \cite{carlini_poisoning_2024}.







\paragraph{Metric Learning and Hierarchical clustering.}

Metric learning and clustering techniques adopt fundamentally opposing philosophies. On the one hand, metric learning generally assumes access to ground-truth labels of similarity, e.g., whether points belong to the same class, and seeks to derive a distance metric, often within the class of generalized Mahalanobis metrics, that best separates dissimilar points while bringing similar ones closer \cite{ghojogh_spectral_2022}. 
On the other hand, clustering assumes some ground truth distance metric and aims to recover a notion of class by grouping similar points into clusters.
Our framework aligns more closely with clustering techniques through its shared starting assumption -- the availability of an informative distance metric. However, it diverges in its objective, focusing instead on the implications of similarity for 
%achieving 
unbiased weighting of 
%the 
data points.


Still, clustering techniques may represent a useful step toward this goal: one could first group points into clusters, assign clusters equal weights, and then share these weights uniformly within each cluster.
Such ``hard'' clusters may however lack the smooth properties we aim for. These limitations can be mitigated by adopting hierarchical clustering techniques, where points can belong to multiple clusters arranged in a tree structure (dendrogram) \cite{murtagh_algorithms_2017,ran_comprehensive_2023}. This approach enables contributions across different scales, akin to the role of the probability distribution $\nu$  in Theorem~\ref{thm:cont_convex_combi_gr}.

One may even consider more flexible structures, such as \emph{Fuzzy Hierarchical Clustering (FHC)} or \emph{Overlapping Hierarchical Clustering (OHC)}. 
FHC \cite{varshney_pifhc_2022} 
%varshney_improved_2020,
allows points to have partial membership in several clusters at once, with the sum of memberships normalized across clusters. 
OHC \cite{berthold_overlapping_2020}, on the other hand, constructs directed acyclic graphs of clusters (quasi-dendrograms) instead of traditional trees, enabling a soft merging process. This approach allows points to have full membership in multiple clusters simultaneously, letting clusters overlap without the need for fuzzy memberships.

In any case, transitioning from clusters of points to individual weights becomes a non-trivial task for ``soft'' clusters. In this work, we move away from the concept of clusters and allow for non-transitive similarity relations.





\section{Representation Functions and Desirable Axioms}\label{sec:axioms}


In this section, we formally introduce representation functions and propose a set of axioms that we consider essential for generalizing the well-understood case of discrete metrics.
Notations are introduced as they appear, a summary is however provided in Appendix~\ref{sec:def}.



Consider a metric space $(E,d)$, that is a set $E$ equipped with a notion of distance in the form of an operator $d:E\times E \mapsto \mathbb{R}_{\geq 0}$ satisfying \emph{separability}, \emph{symmetry} and \emph{triangular inequality}. 
We now formally define the object of interest of this work, called \emph{representation functions of $(E, d)$}.

\begin{definition}[Representation functions of $(E, d)$]
    A representation function of $(E, d)$ is a function $f$ that maps finite sets of $E$ to probability distributions over their elements, i.e.,
    \begin{equation*}
        \begin{aligned}
            f: S \in \mathcal{P}(E) &\mapsto p_S \in \Delta(S),
        \end{aligned}
    \end{equation*}
    where $\mathcal{P}(E)$
    denotes the set containing all finite subsets of $E$ (outside the empty set),
    and $\Delta(S) = \big\{\ p_S : S \mapsto [0,1] \mid \sum_{x \in S} p
    _S(x) =1 \big\}$ denotes the 
    %finite dimensional 
    simplex over the elements of $S.$ 
    We moreover refer to the probability distribution $f(S): S \mapsto [0,1]$ as the representation of $S.$
\end{definition}


Note that this definition encompasses the \emph{uniform distribution} as a particular case of representation function.
Indeed, consider the discrete metric space $(E,\rho)$, where $\rho(x,y)$ is equal to one if $x \neq y$ and zero otherwise. Then the maximum entropy principle compels us to use the \emph{uniform representation function} $\mathcal{U} : S \in \mathcal{P}(E) \mapsto \mathbb{1}_S(\cdot) / |S| \in \Delta(S).$

Drawing inspiration from the properties of this particular representation function, we next introduce a few axioms 
%that we would want a representation function $f$ to verify from an application perspective
that we argue are desirable for a general metric space $(E,d)$ and representation function $f$ thereof.
%from an application perspective.
The first desirable property that the uniform representation $\mathcal{U}$ verifies is rather simple: it ensures that all elements of a finite set are represented with positive probability. This means that it never hurts to add new elements to a set as the support of the probability distribution given by the representation function only increases.

\begin{axiom}[Positivity]\label{axi:pos}
Every element of a finite set is represented with positive probability, i.e.,
for all finite subset $S \in  \mathcal{P}(E)$ and element $x$ in  $S$, we have $f(S)(x) >0.$
\end{axiom}

The second property of $\mathcal{U}$ that we would want to extend to a generic $f$ is that of symmetry: 
when the distance is uninformative and some elements are isomorphic, they receive similar weights. In particular, if all elements of a finite subset $S$ are equidistant, then $f(S)$ should be uniform over $S.$
%the uniform probability over $S.$


\begin{axiom}[Symmetry]\label{axi:sym}
    Elements of a set that are symmetric with respect to the metric are equally represented, i.e., 
    for all finite subset $ S \in  \mathcal{P}(E)$ and self-isometry $\sigma_S: S \mapsto S$, it holds for all $x \in S$ that $f(S)(x) = f(S)(\sigma_S(x)). $
\end{axiom}

Importantly, we consider in the above definition that the permutation $\sigma_S$ preserves the distance on $S$, but need not be extendable to a full isometry on $E.$ Moreover, determining the automorphism group of a set $S$ is an instance of the \emph{graph automorphism problem}, which is known to be 
%in the complexity class NP and
solvable in quasi-polynomial time \cite{helfgott_graph_2017}, but is neither known to be in P nor to be NP-complete. 
Luckily, two symmetric elements $x$ and $\sigma_S(x)$ possess the same multi-set of distances $\{\{d(x,y)\}\}_{y\in S}$ and 
we only need to make sure that similar multi-sets lead to similar representations.





Finally, the third property that $\mathcal{U}$ trivially satisfies is that of continuity, since the topology induced by the metric $\rho$ is the discrete one. In order to define a notion of continuity for general metric spaces $(E,d)$, we let $d(y,X) = \min_{x\in X} d(x,y)$ denote the distance from an individual element $y$ in $E$ to a finite subset $X$ in $\mathcal{P}(E).$ We then equip the domain $\mathcal{P}(E)$ of a representation function $f$ with the natural metric associated with $d$, that is the \emph{Hausdorff distance} $d_H(X,Y) = \max\big\{ \max_{x\in X} d(x,Y), \max_{b\in Y} d(X,y) \big\}$ where $X, Y$ are two finite subsets of $E.$ 
Finally, we denote by $\pi_X$ the canonical projection on a finite subset $X$, that is the map $\pi_X: y\in E \mapsto \argmin_{x \in X} d(x,y)$, and let $\underline{d}(X) = \min_{x \neq x' \in X} d(x,x')$ be the minimal distance between two distinct elements of $X.$
The following result characterizes neighborhoods in the metric space $(\mathcal{P}(E), d_H).$



\begin{lemma}\label{lem:conv_hausdorff}
    Let $X$ be a finite subset of $individualE$ and let $\delta$ satisfy $\underline{d}(X) / 2 > \delta >0.$ 
     A finite subset $Y \in \mathcal{P}(E)$ is at distance $d_H(X,Y) \leq \delta$ if and only if the canonical projection $\restr{\pi_X}{Y}$ is the unique surjective map $\pi: Y \mapsto X$ such that $\max_{y \in Y} d(y,\pi(y)) \leq \delta.$ 
    
\end{lemma}

The proof of Lemma~\ref{lem:conv_hausdorff} is included in Appendix~\ref{sec:metric_cont&axioms_disc}. 
Interestingly, the surjectivity means that, in small enough neighborhoods of a fixed finite subset $X$, there are only sets of cardinality greater or equal to that of $X$. Moreover, the projection $\pi = \restr{\pi_X}{Y}$ offers a neat way to identify which elements of a neighboring set $Y$ correspond to some element $x$ of $X$: we then refer to each $\pi^{-1}(x) = \{ y\in Y \mid \pi(y) =x \}$ as a \emph{class of clones} since all $y, y'$ in $\pi^{-1}(x)$ are at distance at most $2\delta$ by the triangle inequality.
Assuming additivity over each class of clones, we are then able to collapse some of the dimensions of the codomain $\Delta(Y)$ and identify it with $\Delta(X).$ 
Note that such an homeomorphism was apriori not clearly identifiable since the two simplices would be of different dimensions whenever $\vert Y \vert > \vert X \vert.$
With this intuition, we then define \emph{class continuity} as follows. 


\begin{axiom}[Class Continuity]\label{axi:class_cont}
Representation is class-wise continuous, i.e.,
for a finite subset $X\in \mathcal{P}(E)$ and $\epsilon>0$, there exists $\delta>0$ such that, for each finite subset $Y \in \mathcal{P}(E)$ satisfying $d_H(X,Y) \leq \delta$, we have $\max_{x\in X} \big\vert f(X)(x) - \sum_{y \in \pi^{-1}(x)} f(Y)(y) \big\vert \leq \epsilon$,
where $\pi = \restr{\pi_X}{Y}$ denotes the canonical projection on $X.$
\end{axiom}

We show in Appendix~\ref{sec:metric_cont&axioms_disc} that this formulation corresponds to the classical definition of continuity between two carefully chosen metric spaces. Note moreover that Axiom~\ref{axi:class_cont} ensures a form of \emph{cloneproofness}, i.e., robustness of representation under the addition of clones. Intuitively, when a set $Y$ contains many $\delta$-clones, we can find a set $X$ of smaller size in its $\delta$-Hausdorff neighborhood: Axiom~\ref{axi:class_cont} then ensures that $X$ and $Y$ have ``similar representations'' when summing probabilities locally over the redundancies in $Y.$

However, we argue that this definition of continuity, although intuitive, is perhaps not desirable from an application standpoint. Indeed, we show hereafter that a representation function $f$ satisfying Axioms~\ref{axi:sym} and~\ref{axi:class_cont} may give very different individual representations to points in nearby sets.

\smallskip

\begin{example}[Diverging individual representations.]
    


Let $f$ be a representation function on the three-dimensional Euclidean space $(\mathbb{R}^3, d_2)$ satisfying both Axioms~\ref{axi:sym} and~\ref{axi:class_cont}, and define the parametric family $S_{\alpha,\beta, \gamma} = \big\{o, u_\alpha, v^+_{\beta,\gamma}, v^-_{\beta,\gamma} \big\}$, where $o=(0,0,0)$, $u_\alpha = (1,\alpha, 0)$, $v^+_{\beta,\gamma} = (1,-\beta, \gamma)$ and $v^-_{\beta,\gamma} = v^+_{\beta,-\gamma}.$ Figure~\ref{fig:visualization_param_families} summarizes our construction.


On one hand, consider the set $S_{\alpha, \alpha, \gamma}$, where $\alpha>0$ is fixed and $\gamma>0$ is much smaller than $\alpha.$
Since $S_{\alpha, \alpha, \gamma}$ converges to the set $S_{\alpha} = \{o, u_\alpha, u_{-\alpha} \}$ in the Hausdorff sense when $\gamma$ goes to zero, Axiom~\ref{axi:class_cont} implies $\lim_{\gamma\to 0} f(S_{\alpha, \alpha, \gamma})(u_\alpha) = f(S_{\alpha})(u_\alpha).$
Moreover, $S_{\alpha}$ converges in turn to the symmetric set $S_0 = \{x, u_0\}$, 
%when $\alpha$ goes to zero,
and Axioms~\ref{axi:sym} and~\ref{axi:class_cont} together imply that $\lim_{\alpha\to 0} f(S_\alpha)(u_\alpha) = f(S_0)(y_0) /2 = 1/4.$ 
Combining these two results, we  get $$\lim_{\alpha\to 0} \lim_{\gamma\to 0} f(S_{\alpha, \alpha, \gamma})(u_\alpha) =1/4.$$

On the other hand, consider the set $S_{\alpha, \alpha/2, \sqrt{3} \alpha/ 2 }.$ Note that the points $u_\alpha$, $v^+_\alpha$ and $v^-_\alpha$ form an equilateral triangle centered in $u_0$
%$(1,0,0)$
and orthogonal to the origin, hence by Axiom~\ref{axi:sym} they must receive similar representation. 
As $S_{\alpha, \alpha/2, \sqrt{3} \alpha/ 2 }$ also converges to the symmetric $S_0$ when $\alpha$ goes to zero, Axioms~\ref{axi:sym} and~\ref{axi:class_cont} finally imply $$\lim_{\alpha\to 0} f \big(S_{\alpha, \alpha/2, \sqrt{3} \alpha/ 2 }\big) (u_\alpha) = 1/6.$$

We hence constructed two sets of similar cardinality and arbitrary close whose individual representations differ. %Figure~\ref{fig:visualization_param_families} summarizes our construction.

\end{example}
%\smallskip




\begin{figure}[!tbh]
     \centering
     \begin{subfigure}[t]{0.24\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/power_two_family-cropped.pdf}
         \caption{$S_{\alpha, \alpha, \gamma}$ for $1 \gg \alpha \gg \gamma >0.$}
         \label{fig:visualization_power_two}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.175\textwidth}
         \centering
        \includegraphics[width=\textwidth]{Figures/equilateral_family-cropped.pdf}
        \caption{$S_{\alpha, \alpha/2, \sqrt{3} \alpha/ 2 }$ for $1\gg \alpha>0$}
        \label{fig:visualization_equilateral}
     \end{subfigure}
     
        \caption{Visualization of the divergence of individual representations under Axioms~\ref{axi:sym} and~\ref{axi:class_cont}. The edges in%Figure
        ~\ref{fig:visualization_power_two} highlight the symmetries of $S_{\alpha, \alpha, \gamma}$ in the limit $\gamma \to 0$; the equilateral triangle in%Figure
        ~\ref{fig:visualization_equilateral} displays the symmetry of $S_{\alpha, \alpha/2, \sqrt{3} \alpha/ 2 }.$}
        \label{fig:visualization_param_families}
\end{figure}



The consequences of this interaction between Axioms~\ref{axi:sym} and~\ref{axi:class_cont} are perhaps better understood from a \emph{fairness} perspective. Imagine for example an online lottery where participants can register for free by providing personal parameters that are difficult to forge, i.e., whose values may only be be slightly modified. 
In this scenario, \emph{cloneproofness} means ensuring that a malevolent attacker cannot gain from registering to the lottery many times, i.e., keeping the lottery fair for players without the  capacity or the envy to forge many fake identities.
However, it may still happen that two individuals, e.g., two siblings, have similar personal parameters and cannot be distinguished from a behavioral perspective from two malevolent clones. In their misfortune, the two siblings would at least hope that they share the price equitably: the above example shows that using a representation function satisfying Axioms~\ref{axi:sym} and~\ref{axi:class_cont} would not ensure such \emph{clone fairness}, a property formalized in the following axiom.
This can be thought of as a continuous extension of Axiom~\ref{axi:sym} since perfect clones at distance precisely zero would always be isomorphic with one another, and thus have equal representations.



\begin{axiom}[Uniform Clone Fairness]\label{axi:clone_fair_uni}
Representation is fair among $\delta$-clones, i.e.,
for all $\epsilon>0$, there exists $\delta>0$ such that, for all finite subset $S\in \mathcal{P}(E)$ and $x,y$ in $S$ satisfying $d(x,y)\leq \delta$, it holds that $\vert f(S)(x) - f(S)(y) \vert \leq \epsilon.$
\end{axiom}



Given this incompatibility, we propose to replace Axiom~\ref{axi:class_cont} with two slightly weaker axioms that are however compatible with the clone fairness in Axiom~\ref{axi:clone_fair_uni}.
Because Axiom~\ref{axi:class_cont} considers sets of different cardinality, it collapses high-dimensional simplices into smaller ones, and only looks at the continuity of representation between different classes of clones. In so doing, it loses track of individual representation which end up locally diverging. A simple solution to this issue is then to restrict the requirements of Axiom~\ref{axi:class_cont} to sets of similar cardinality.
%Note that $\restr{\pi_X}{Y}$ is then bijective for $\delta$ small enough 
Note that any surjective map $\pi:Y\mapsto X$ becomes bijective in such a case, and this applies in particular to $\restr{\pi_X}{Y}$ when $\delta$ is small enough in Lemma~\ref{lem:conv_hausdorff}.


\begin{axiom}[Individual Continuity]\label{axi:indiv_cont}
Representation is element-wise continuous, i.e.,
for a finite subset $X\in \mathcal{P}(E)$ and $\epsilon>0$, there exists $\delta>0$ such that, for all subset $Y\in\mathcal{P}(E)$ with $|Y| =|X|$ and $d_H(X,Y) \leq \delta$, we have 
$\max_{x\in X} \vert f(X)(x) - f(Y)(\pi^{-1}(x)) \vert \leq \epsilon$, where $\pi = \restr{\pi_X}{Y}$ denotes the canonical projection on $X.$
\end{axiom}


Note that Axiom~\ref{axi:indiv_cont},  unlike Axiom~\ref{axi:class_cont}, does not address the addition of clones. To account for this, we introduce a second weakening of Axiom~\ref{axi:class_cont}, essentially requiring continuity of representation everywhere except in the vicinity of the newly added clone. This relaxation allows for greater flexibility in how the mass is redistributed locally.



\begin{axiom}[$\alpha$-Locality under Addition of Clones]\label{axi:alpha_clone_locality}
The addition of a clone only changes the representation locally, i.e.,
for a finite subset $S \in \mathcal{P}(E)$ and $\epsilon >0$, there exists $\delta>0$ such that for each element $x \in S$ and $\delta$-clone $x'$ satisfying $d(x,x') \leq \delta$, we have for all $z\in S$ such that $d(x,z)\geq \alpha$ that $\vert f(S)(z) - f(S\cup\{x'\})(z) \vert \leq \epsilon.$
\end{axiom}

Though similar in formulation,
%Although their formulation are very close,
note that Axiom~\ref{axi:clone_fair_uni} cannot be derived from Axiom~\ref{axi:indiv_cont} by simply plugging in $Y =X$, since the restricted projection $\restr{\pi_X}{X}$ is always the identity.
Moreover, Axioms~\ref{axi:clone_fair_uni} and~\ref{axi:alpha_clone_locality} provide orthogonal restrictions in the presence of clones: the former dictates how to shift weights around the recently introduced clone, while the latter ensures weights do not change away from it.
We further discuss the relationship between these axioms in Appendix~\ref{sec:metric_cont&axioms_disc}.

\smallbreak

We finally denote by $\mathcal{R}_\alpha(E,d) $ the set of representation functions on $(E,d)$ satisfying Axioms~\ref{axi:pos}, \ref{axi:sym}, \ref{axi:clone_fair_uni}, \ref{axi:indiv_cont} and~\ref{axi:alpha_clone_locality} with parameter $\alpha>0.$ 
The burning question is now this: does $\mathcal{R}_\alpha(E,d)$ have any elements at all?



\section{Local Voting Approach}\label{sec:local_voting}


To construct representation functions that satisfy our axioms, the first step is to identify invariant objects under clones' addition: we argue that
the open balls of the topology, that is the $B_r (x) := \{y \in E \mid d(x,y) < r \}$ for some element $x \in E$ and radius $r>0$, are natural invariants for our problem. Indeed, they are stable under the addition of clones, in the sense that for some \emph{$\delta$-clones} $x,y$ in  $E$ satisfying $d(x,y) \leq \delta$, the triangle inequality ensures that $B_r(x) \subseteq B_r(x) \cup B_r(y) \subseteq B_{r+\delta}(x).$ 
If we then equip our space with a measure $\mu$ defined on the open balls of the space\footnote{I.e., on the Borel $\sigma$-algebra.} 
and associate with each finite subset $X\subseteq E$ its neighborhood $B_r(X):= \bigcup_{x\in X} B_r(x)$, we obtain a map invariant under clone addition. Indeed, for each neighboring  finite set $Y \subseteq B_\delta(X)$ with $r>\delta>0$, we have $\mu\big(B_{r- \delta}(X)\big) \leq \mu\big(B_r(Y)\big) \leq \mu\big(B_{r+ \delta}(X)\big)$ and the map $X\in \mathcal{P}(E) \mapsto \mu\big(B_r(X)\big)$ is continuous with respect to the Hausdorff distance.\footnote{At least when $\mu$ is locally finite.}

Note however that further requirements are needed to satisfy the symmetry in Axiom~\ref{axi:sym}, essentially regarding the homogeneity and the isotropy of the underlying measure space.
For this reason, we focus on Euclidean spaces $(\mathbb{R}^n, d_2)$ for the remainder of the section.
We will discuss in Section~\ref{sec:discu} how to adapt our approach to more general metric spaces.


Based on the above invariant, we construct a representation function as a local voting scheme. For a fixed $r>0$ and finite subset $S \subseteq \mathbb{R}^n$, we consider each element of $B_r(S)$ as a voter that approves only of the candidates in $S$ close to him, and as such spreads his voting power equally among them. 
Formally, we define the grade that each voter $z$ in $B_r(S)$ attributes to a candidate $x$ in $S$ as follows
\begin{equation*}
    g_{r,S,x} (z) = \frac{\mathbb{1}_{B_r(x)}(z) }{\sum_{y \in S} \mathbb{1}_{B_r(y)}(z)} .
\end{equation*}


We then aggregate the ballots with the Lebesgue measure $\mu$ and finally define the representation function $g_r$, for each finite subset $S \subseteq \mathbb{R}^n$, as follows
\begin{equation*}
    g_r(S) : x \in S \mapsto  \int_{B_r(S)} \frac{g_{r,S,x}}{\mu\big(B_r(S)\big)} \:d\mu.
\end{equation*}

As illustrated in Figure~\ref{fig:illustration_g_r_depth_cells},  the representation function $g_r$ computes a weighted average of the inverse depth of each cell, with the depth defined as the number of intersecting balls forming the cell and the weights based on the cell's size.




\begin{figure}[!tbh]
    \centering
    \begin{tikzpicture}[scale=1.3]

        % Define colors for the balls
        \definecolor{PaperBlue}{HTML}{1f77b4}
        \definecolor{PaperOrange}{HTML}{ff7f0e}
        \definecolor{PaperGreen}{HTML}{2ca02c}
        \definecolor{PaperRed}{HTML}{d62728}

        % Define and label the points
        \coordinate (X) at (0,0);        
        \coordinate (W) at (-0.5,0.1); 
        \coordinate (Y) at (1.0,0.7);   
        \coordinate (Z) at (1.7,-0.3);  
        \fill[PaperBlue] (X) circle (1pt) node[above] {$x$};
        \fill[PaperOrange] (W) circle (1pt) node[below left] {$w$};
        \fill[PaperGreen] (Y) circle (1pt) node[right] {$y$};
        \fill[PaperRed] (Z) circle (1pt) node[above right] {$z$};

        % Draw the blue ball
        
        \fill[PaperBlue, opacity=0.09] (X) circle (1.5cm);

        % Define paths for the other balls
        \path[name path=Wcircle] (W) circle (1.5cm);
        \path[name path=Ycircle] (Y) circle (1.5cm);
        \path[name path=Zcircle] (Z) circle (1.5cm);
        \path[name path=Xcircle] (X) circle (1.5cm);

        % Fill and draw other balls
        \draw[thin, dotted, PaperOrange] (W) circle (1.5cm);
        \fill[PaperOrange, opacity=0.06] (W) circle (1.5cm);
        \draw[thin, dotted, PaperGreen] (Y) circle (1.5cm);
        \fill[PaperGreen, opacity=0.06] (Y) circle (1.5cm);
        \draw[thin, dotted, PaperRed] (Z) circle (1.5cm);
        \fill[PaperRed, opacity=0.06] (Z) circle (1.5cm);

        % Highlight intersections with thick edges
        \begin{scope}
            \path[name intersections={of=Xcircle and Wcircle, by={XWa, XWb}}];
            \draw[ PaperOrange] (XWa) arc[start angle=429.1, end angle=269, radius=1.5cm];
            
            \path[name intersections={of=Xcircle and Ycircle, by={XYa, XYb}}];
            \draw[PaperGreen] (XYa) arc[start angle=149, end angle=281, radius=1.5cm];
        
            \path[name intersections={of=Xcircle and Zcircle, by={XZa, XZb}}];
            \draw[ PaperRed] (XZa) arc[start angle=115, end angle=224.5, radius=1.5cm];
        \end{scope}

        \draw[PaperBlue] (X) circle (1.5cm); 


        % Add labels for intersections
        \node at (-0.8,-0.6) { $\frac{1}{2}$};  
        \node at (0,0.8) { $\frac{1}{3}$}; 
        \node at (0.6,-0.1) {$\frac{1}{4}$};   
        \node at (0.44,-0.87) {$\frac{1}{3}$};
        \node at (0.3,-1.31) { $1$};  
        \node at (0.8,-1.0) {$\frac{1}{2}$};  
        \node at (1.2,-0.05) { $\frac{1}{3}$};  
        \node at (0.75,1.13) {$\frac{1}{2}$}; 
        %\node at (0,1.8) { $g_r(S)(x) \simeq 0.19$};
        \node at (-1.2,1.8) { $g_r(S)(x) \simeq 0.19$};
        %\node at (-1.5,-1.5) { $g_r(S)(x) \simeq 0.19$};

    \end{tikzpicture}
    \caption{
    Computation of $g_r(S)(x)$ in the two-dimensional Euclidean space $(\mathbb{R}^2, d_2)$, where the set $S = \{w,x,y,z\}$ contains four elements. 
    A cell $A_r(U)$ is uniquely defined by the subset $U\subseteq S$ as the possibly empty intersection of the balls around each element in $U$ and the complement of the balls of each element of $S$ absent from $U.$ 
    For each subset $U$ containing $x$, the grading function $g_{r,S,x}$ is constant on the cell $A_r(U)$ and equal to the inverse depth of the cell, i.e., $g_{r,S,x}(z) = 1 / U$ for all $z$ in $A_r(U).$
   The weight of $x$ in $S$
   %, i.e., $g_r(S)(x)$, 
   is then equal to the weighted average of $g_{r,S,x}$ on the ball centered in $x$, where the weight of each cell corresponds to its area normalized by the total area of the balls' union. 
   %weights correspond to the cells' area normalized by the total area of the balls' union. 
   We estimated the value $g_r(S)(x) \simeq 0.19$ via Monte Carlo sampling methods.
    }
    \label{fig:illustration_g_r_depth_cells}
\end{figure}




We next show that this class of representation functions satisfies the desirable axioms we introduced in Section~\ref{sec:axioms}.

\begin{theorem}\label{thm:local_vote_rep_func}
For $r>0$, the representation function $g_r$ is well-defined and belongs in $\mathcal{R}_{2r}(\mathbb{R}^n, d_2).$
\end{theorem}

The detailed proof of Theorem~\ref{thm:local_vote_rep_func} is included in Appendix~\ref{sec:proof}, and we provide here a sketch of the proof.
As depicted in Figure~\ref{fig:illustration_g_r_depth_cells}, the weight $g_r(S)(x)$ is in fact a weighted average of positive elements, hence it is positive and Axiom~\ref{axi:pos} trivially holds.
%The proof of the symmetry in Axiom~\ref{axi:sym} 
Showing that $g_r$ is symmetric (Axiom~\ref{axi:sym})
is also relatively straightforward after observing the following two properties of Euclidean spaces: first, the fact that one can uplift any self-isometry $\sigma_S$ on a finite subset $S$ to an isometry on the entire space $\mathbb{R}^n$, c.f. Appendix~\ref{sec:self-iso_eucli}; second, the fact that the Lebesgue measure is invariant under \emph{translations}, \emph{rotations} and \emph{reflections}, which generate the group of Euclidean isometries \cite{gallian_contemporary_2020}.
The most challenging aspect of the proof is verifying that $g_r$ satisfies Axioms~\ref{axi:clone_fair_uni}, \ref{axi:indiv_cont} and~\ref{axi:alpha_clone_locality}.
While these proofs are technically intricate, they fortunately follow a similar structure. We illustrate our approach by focusing on the simpler case of Axiom~\ref{axi:clone_fair_uni} below. 
In order to bound the difference of representation function $\vert g_r(S)(x) - g_r(S)(y)\vert$, we first show that the grading functions  $g_{r,S,x}$ and $g_{r,S,y}$ are equal outside of a thin spherical shell parametrized by $\delta$, the distance between the neighboring elements $x$ and $y$ (c.f. Figure~\ref{fig:ball_inclusion}).
This allows us to obtain a difference of Lebesgue measure $\mu(B_{r}(x)) - \mu(B_{r-\delta}(x))$, which we then bound in terms of $\delta$ by taking the limit of this difference as $\delta$ approaches zero (c.f. Figure~\ref{fig:minkowski_content}). 
The formalization of this argument relies 
%To formalize this intuitive explanation, we rely 
on tools from \emph{geometric measure theory}, particularly the $n-1$-dimensional Minkowski content. 
These arguments are illustrated in Figure~\ref{fig:illustration_proof_thm1}.



\begin{figure}[!tbh]
    \centering
    \begin{subfigure}[t]{0.48\columnwidth}
        \centering
        \begin{tikzpicture}[scale = 0.8]
        
            % Define colors for the balls
            \definecolor{PaperBlue}{HTML}{1f77b4}
            \definecolor{PaperRed}{HTML}{d62728}
            
            % Define points
            \coordinate (x) at (0,0); % Point x
            \coordinate (y) at (0.5,0); % Point y at distance delta from x
            
            % Draw circles
            \draw[thick, PaperBlue] (x) circle (2); 
            \draw[ PaperBlue, dashed] (x) circle (1.5); 
            \draw[thick, PaperRed] (y) circle (2); 
            \fill[PaperBlue, opacity =0.1] (x) circle (1.5);
          
            \draw[<->, thin] (0,-0.4) -- (0.5, -0.4) node[midway, below] {\(\delta\)};
            \draw[thin, dotted] (0,-0.4) -- (x);
            \draw[thin, dotted] (0.5,-0.4) -- (y);
            
    
            % Draw points and labels
            \fill[PaperBlue] (x) circle (2pt) node[above left] {\(x\)};
            \fill[PaperRed] (y) circle (2pt) node[above right] {\(y\)};
    
            % Add colored labels 
            \node[PaperBlue] at (-1.8, -1.8) { $B_r(x)$};  
            \node[PaperRed] at (2.3,1.8) { $B_r(y)$};
            \node[PaperBlue] at (0,1.) { $B_{r-\delta}(x)$};
        \end{tikzpicture}
        \caption{The ball $B_{r-\delta}(x)$ belongs in the intersection of $B_r(x)$ and $B_r(y)$, hence $x$ and $y$ receive the same grade
        from every voter on $B_{r-\delta}(x).$
        %, i.e.,  $g_{r,S,x}(z) = g_{r,S,y}(z)$ for each voter $z$ in  $B_{r-\delta}(x)$.
        }
        \label{fig:ball_inclusion}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\columnwidth}
         \centering
         \begin{tikzpicture}[scale=0.8]
            % Define colors
            \definecolor{PaperBlue}{HTML}{1f77b4}
            \definecolor{PaperHatch}{HTML}{d3d3d3}
            \definecolor{PaperOrange}{HTML}{ff7f0e}
            \definecolor{PaperGreen}{HTML}{2ca02c}
            \definecolor{PaperRed}{HTML}{d62728}
            
            % Define points
            \coordinate (x) at (0,0); % Center point x

            \fill[PaperGreen, opacity =0.1] (x) circle (2); % Outer circle filled with hatch
            
            % Remove the inner circle's region (fill it white)
            \fill[white] (x) circle (1.495); % Inner circle made white, erasing that region
            
            % Draw the outer circle
            \draw[PaperBlue] (x) circle (2); % Circle with radius r
            
            % Draw the inner circle
            \draw[PaperBlue,  dashed] (x) circle (1.5); % Circle with radius r - delta

            
            % Draw the arrow indicating delta
            \draw[>-<, thin, black] (-1, 1) -- (-1.47, 1.47);
            \draw[thin, black] (-0.9, 0.9) -- (-1.6, 1.6);
            \node at (-1.87, 1.5) {\(\delta\)};
            
            % Draw point x
            \fill[PaperBlue] (x) circle (2pt) node[below] {$x$};
            
            % Add labels
            \node[PaperBlue] at (-1.8, -1.8) {$B_r(x)$};  
            \node[PaperBlue] at (0,1.) { $B_{r-\delta}(x)$};
            \node[PaperGreen] at (1.2, -1.2) { $\Delta$};
            %\node at (1.7, -1.7) { $V^n(\Delta) \simeq \delta \cdot S^n_r$};
        \end{tikzpicture}
         \caption{
         The $n$\textsuperscript{th}-dimensional volume of the green set $\mu(\Delta)$ can be approximated as $\delta$ times $S^{n-1}_r$, the $n-1$\textsuperscript{th}-dimensional surface of a ball of radius $r.$
         }
         \label{fig:minkowski_content}
     \end{subfigure}
     
    \caption{Key steps in demonstrating that $g_r$ satisfies Axiom~\ref{axi:clone_fair_uni}.
    %, \ref{axi:indiv_cont} and~\ref{axi:alpha_clone_locality}.
    }
    \label{fig:illustration_proof_thm1}
\end{figure}




Since $\mathcal{R}_\alpha(E,d)$ is monotonically increasing in positive $\alpha$,
%Since $\mathcal{R}_\alpha(E,d) \subseteq \mathcal{R}_{\alpha'}(E,d)$ for all $\alpha' \geq \alpha >0$,
Theorem~\ref{thm:local_vote_rep_func} actually ensures that the whole collection $\{ g_r\}_{\alpha/2 \geq r>0}$ belongs in $\mathcal{R}_\alpha(\mathbb{R}^n,d_2).$ 
Moreover, it is relatively straightforward to see that $\mathcal{R}_\alpha(\mathbb{R}^n,d_2)$ is a convex set and, as such, contains all finite convex combinations of $\{ g_r\}_{\alpha/2 \geq r>0}.$
Since the representation functions $g_r$ are well-behaved, we generalize this result as follows.
%in the following Theorem~\ref{thm:convexity}.

\begin{theorem}\label{thm:cont_convex_combi_gr}
    Let $\nu$ be a probability density function over $[0,\alpha/2].$
    Then the representation function $f_\nu : S \in \mathcal{P}\big(\mathbb{R}^n \big) \mapsto \int_0^{\alpha/2} \nu(r) g_r(S) ~dr$ belongs in $\mathcal{R}_\alpha(\mathbb{R}^n,d_2).$
\end{theorem}
The detailed proof of Theorem~\ref{thm:cont_convex_combi_gr}, provided in Appendix~\ref{sec:proof}, relies on inequalities derived for the proof of Theorem~\ref{thm:local_vote_rep_func}.









\section{Discussion}\label{sec:discu}

We gather in this section different remarks on our results as well as possible extensions of our work.


\paragraph{Extension to Perfect Clones.}

The framework we considered until now only allows for $\delta$-clones with $\delta>0$, but not perfect clones, i.e., with $\delta =0.$  The appropriate analytical tool to handle this is to consider a \emph{pseudo-metric space} $(E,d)$ instead of a metric one, where the pseudo-metric $d$ verifies \emph{non-negativity}, \emph{symmetry}, \emph{triangle inequality} like a full-fledged metric, but only verifies \emph{identity} instead of \emph{separability}. 
%(c.f. Section~\ref{sec:def}). 
This exactly means that two different elements $x\neq y$ in $E$ may be perfect clones, i.e., $d(x,y) =0.$ 

Most of the axioms we introduced directly extend to a pseudo-metric space $(E,d)$; however, the surjectivity in Lemma~\ref{lem:conv_hausdorff} breaks, and with it Axioms~\ref{axi:class_cont} and~\ref{axi:indiv_cont}. 
To circumvent this issue, we rely on the equivalence relationship induced by the vanishing of the pseudo-metric, i.e., we define the \emph{metric identification} as $x\sim y$ if and only if $d(x,y) =0$, and write $[x]$ for the equivalence class of $x$ in $E.$ 
Letting $E^* = E / {\mathrel{\sim}}$ denote the quotient space of $E$ by the equivalence relation $\sim$, and defining $d^* : ([x], [y]) \in E^*\times E^* \mapsto d(x,y) $, we then refer to $(E^*, d^*)$ as the metric space induced by the pseudo-metric space $(E,d).$ 
In order to adapt Axiom~\ref{axi:indiv_cont} to a pseudo-metric space, we simply ask that its requirements be verified after we collapse all perfect clones. 
%This means that 
In other words, there must exists a representation function $f^*$ of $(E^*,d^*)$ verifying Axiom~\ref{axi:indiv_cont} such that $f^* (X / {\mathrel{\sim}})([x]) = \sum_{x' \in [x] \cap X} f(X)(x')$ holds for all choices of $X$ and $x\in X.$
We refer the interested reader to Appendix~\ref{sec:metric_id} for more details.

Note that a similar extension is possible for Axiom~\ref{axi:class_cont}. As argued in Section~\ref{sec:axioms} however, representation functions satisfying both this extension and Axiom~\ref{axi:sym} would treat $\delta$-clones and perfect clones differently since the latter are always isomorphic but the former not,
thus violating Axiom~\ref{axi:clone_fair_uni}.




\paragraph{Extension beyond Euclidean spaces.}

While the solution proposed in Section~\ref{sec:local_voting} is restricted to Euclidean spaces, similar ideas could be applied in more general metric spaces. Using a Radon measure $\mu$, one could define the representation functions $g_r$ in full generality and show similarly as in Theorem~\ref{thm:local_vote_rep_func} that Axioms~\ref{axi:pos}, \ref{axi:clone_fair_uni}, \ref{axi:indiv_cont} and~\ref{axi:alpha_clone_locality} hold. The real challenge however is to satisfy Axiom~\ref{axi:sym}. 

Indeed, our proof relies on two convenient properties of Euclidean spaces: first, the uplifting of self-isometry $\sigma_S$ to the entire space; second the invariance of the Lebesgue measure under translations, rotations and reflections. 
What can be done without these properties?
The first problem could be entirely shunned by arguing that only full-fledged isometries should be considered in the definition of Axiom~\ref{axi:sym}. The second issue is however tougher to ward off. 
To extend invariance by translation beyond vector spaces, one should consider \emph{uniformly distributed measures}, i.e., measures that give the same weight to all balls of the same radius. However, such measures turn out to be very rigid objects and are uniquely defined up to a multiplicative constant in most metric spaces.

\begin{lemma}[From \cite{christensen_measures_1970}]\label{lem:unif_measure}
%\cite{christensen_measures_1970}.
Let  $(E,d)$ be a locally compact metric space. There exists a Radon measure $\mu$ defined on the Borel $\sigma$-algebra of $E$ that is uniformly distributed, i.e., it verifies $0 < \mu(B_r(x)) = \mu(B_r(y)) < \infty $ for all $r>0$ and $x,y$ in $E.$ 
Moreover, this measure is unique up to a multiplicative constant if $E$ is separable.
\end{lemma}

As a particular example, this essentially implies that the Lebesgue measure is the only Borel measure invariant by translation on $\mathbb{R}^n$. This comes as an awful news since this indicates that our approach is doomed even in the simple case of $\mathbb{R}^n$ endowed with the $L^1$ distance $d_1(x,y) = \sum_{i=1}^n \vert x_i - y_i \vert$, as explained in Figure~\ref{fig:l1_balls_intersection}.

\begin{figure}[!tbh]
    \centering
    \begin{tikzpicture}[scale=0.95]

        % Define Paper colors
        \definecolor{PaperBlue}{HTML}{1f77b4}
        \definecolor{PaperOrange}{HTML}{ff7f0e}
        \definecolor{PaperGreen}{HTML}{2ca02c}
        \definecolor{PaperRed}{HTML}{d62728}
        \definecolor{PaperPurple}{HTML}{9467bd}
        \definecolor{PaperBrown}{HTML}{8c564b}
        \definecolor{PaperPink}{HTML}{e377c2}
        \definecolor{PaperGray}{HTML}{7f7f7f}
        \definecolor{PaperOlive}{HTML}{bcbd22}
        \definecolor{PaperCyan}{HTML}{17becf}
        
        % Define the points
        \coordinate (A) at (0,0);
        \coordinate (B) at (2,0);
        \coordinate (C) at (-1,1);

        % Draw the L1 balls centered at A, B, and C
        \draw[ PaperRed, rotate around={45:(A)}] (A) ++(-1,-1) rectangle ++(2,2);
        \fill[PaperRed, opacity=0.07, rotate around={45:(A)}] (A) ++(-1,-1) rectangle ++(2,2);
        \draw[ PaperBlue, rotate around={45:(B)}] (B) ++(-1,-1) rectangle ++(2,2);
        \fill[PaperBlue, opacity=0.07, rotate around={45:(B)}] (B) ++(-1,-1) rectangle ++(2,2);
        \draw[ PaperGreen, rotate around={45:(C)}] (C) ++(-1,-1) rectangle ++(2,2);
        \fill[PaperGreen, opacity=0.07, rotate around={45:(C)}] (C) ++(-1,-1) rectangle ++(2,2);

        % Add dashed L1 ball of radius 2
        \draw[dashed, rotate around={45:(A)}] (A) ++(-1.414,-1.414) rectangle ++(2.828,2.828);

        % Draw the axes
        \draw[->, dotted] (-2.8,0) -- (3.8,0) ;% node[right] {$x$};
        \draw[->, dotted] (0,-2.2) -- (0,2.6) ; %node[above] {$y$};



        \fill[PaperRed] (A) circle (1pt) node[above right] {$x$};
        \fill[PaperBlue] (B) circle (1pt) node[below right] {$y$};
        \fill[PaperGreen] (C) circle (1pt) node[above left] {$z$};


        
    \end{tikzpicture}
    \caption{The representation function $g_r$ does not satisfy Axiom~\ref{axi:sym} in $(\mathbb{R}^2, d_1).$ As illustrated by the dashed $L^1$ ball centered in $x$, points $y$ and $z$ are indeed at the same distance of $x$, thus belong in a common isometry class in $S=\{x,y,z\}$ and should receive similar representation under Axiom~\ref{axi:sym}. Note however that the Lebesgue measure, i.e., the area, of the intersection between the red and the green ball differs from that of the intersection between the red and the blue ball, hence $g_r(S)(y) \neq g_r(S)(z).$ }
    \label{fig:l1_balls_intersection}
\end{figure}

Such metric spaces thus require developing techniques different from the one introduced in this work. 
\emph{Topologically independent} representation functions would provide an elegant solution to this issue, i.e., functions that do not rely on the topological properties of $(E,d)$, but rather solely depend on the distance matrices associated with each finite set.

\begin{axiom}[Topological Invariance]\label{axi:topo_inv}
Representation only depends on the distance matrix associated with each finite set, i.e., 
there exists a family $(h_n)_{n\geq1}$ with $h_n: \mathbb{R}^{n\times n} \mapsto \Delta(n)$ such that, for all $S \in \mathcal{P}(E)$ of cardinality $\vert S\vert =n$, we have $f(S) = h_n(M(S))$, where $M = (d(x,y))_{x,y \in S} \in \mathbb{R}^{n\times n}$ denotes the distance matrix associated to $S$ and $d$, unique up to permutations.
\end{axiom}

Identifying representation functions within $\mathcal{R}_\alpha(E,d)$ that 
%also
adhere to Axiom~\ref{axi:topo_inv} is a promising direction for future works.





\paragraph{Computability}

Our focus thus far has been on identifying representation functions with theoretically desirable properties. However, from a practical standpoint, such tools are of little utility if they cannot be computed efficiently. This concern is encapsulated in the following principle.

\begin{axiom}[Exact Computability]\label{axi:comput} The representation of any given subset is efficiently computable, i.e.,
for any subset $S\in \mathcal{P}(E)$, the probability distribution $f(S)$ can be exactly computed in time polynomially bounded by the cardinality $\vert S\vert$ of the subset, and the dimension $n$ of the space if $E = \mathbb{R}^n.$
\end{axiom}

It is worth noting that the representation functions introduced in Section~\ref{sec:local_voting} are unlikely to meet this criterion.
For example, computing $g_r(S)(x)$ would a priori involve averaging $g_{r,S, x}$ over as many as $O\big(2^{\vert S\vert}\big)$ disjoint cells, making the approach computationally infeasible. 
Additionally, even the simpler task of calculating the volume $\mu\big( B_r(S))$ of the union of Euclidean balls becomes increasingly challenging in higher dimensions (see \cite{cazals_computing_2011} for the case $n=3$). While hardness results for this specific problem are not readily available, related problems, such as computing the exact volume of the union of general axis-aligned boxes, are known to be \#P-hard \cite{bringmann_approximating_2010}. 

In practice, as often occurs, we may want to relax Axiom~\ref{axi:comput} and settle for approximate evaluations of $g_r(S)$. Monte-Carlo-based methods \cite{bringmann_approximating_2010,mitchell_fast_2018} could potentially be adapted to our framework and enable us to efficiently estimate $g_r(S)$ within an $\epsilon$ factor with high probability, where $\epsilon \propto 1 /\sqrt{k}$ typically decreases quadratically with the number of samples $k.$





\newpage




\bibliographystyle{named}
\bibliography{Cloneproofness}


\newpage
\appendix

\section{Preliminaries \& Notations}\label{sec:def}

In this section, we provide an overview of the notations used throughout the paper and introduce the key tools necessary for our demonstrations.

%In this section, we summarize the notations used throughout the paper, and introduce the most important tools used for our demonstrations.

\paragraph{Metric spaces and Hausdorff norm.}

Let $E$ be a set and let $d: E\times E \mapsto \mathbb{R}_{\geq0}$ be a metric on $E$, that is an operator satisfying for all $x,y,z \in E$
\begin{enumerate}
    \item (\emph{Non-negativity}) $d(x,y) \geq 0$ ;
    %for all $x,y \in E$;
    \item (\emph{Symmetry}) $d(x,y) = d(y,x)$;
    %for all $x,y \in E$;
    \item (\emph{Triangle inequality}) $d(x,z) \leq d(x,y) + d(y,z)$ ;
    %for all $x,y,z \in E$;
    \item (\emph{Separability}) $d(x,y) =0 \iff x =y.$ 
    %$d(x,x) =0$ for all $x\in E.$ %, but $d(x,y) = 0$ does not necessarily imply that $x = y$.
\end{enumerate}

For $n \in \mathbb{N}$, let $\mathcal{P}_n(E) := \{ S \subseteq E \mid n = \vert S \vert \}$ denote the powerset of subsets of $E$ of cardinality $n$; we further denote by $\mathcal{P}(E) := \bigcup_{n\geq1} \mathcal{P}_n(E)$ the set of finite subsets of $E.$ In particular,  $\mathcal{P}(E)$ does not contain the empty-set.

\smallskip
We equip $\mathcal{P}(E)$ with the \emph{Hausdorff distance} $d_H$, defined for two finite subsets $X, Y$ in $\mathcal{P}(E)$ as 
$$d_H(X,Y) := \max\big\{ \max_{x\in X} d(x,Y), \max_{b\in Y} d(X,y) \big\}.$$  

A metric space is finally defined as an ordered pair where the first element is a set and the second is a metric on this set; $(E,d)$ and $(\mathcal{P}(E), d_H)$ constitute the two most prominent examples of metric spaces in this work.





\paragraph{Isometries and self-isometries.}

In the metric space $(E,d)$, an isometry is defined as a map $\sigma: E \mapsto E$ that preserves distances, i.e., that verifies for all $x,y$ in $E$, 
$$d(\sigma(x),\sigma(y)) = d(x,y).$$ 


For $X \in \mathcal{P}(E)$ a finite subset of $E$, we moreover refer to an isometry in the subspace induced by $X$ as a \emph{self-isometry on $X$}, i.e., a permutation $\sigma_X: X\mapsto X$ such that $d(\sigma_X(x),\sigma_X(y)) = d(x,y)$ for all $x,y$ in $X.$

\smallskip
While restricting an isometry $\sigma$ to a subset $X \subseteq E$ gives a self-isometry on $X$, note that the converse may not hold in general. We however show in Appendix~\ref{sec:self-iso_eucli} that it holds in the particular case of Euclidean spaces and that a self-isometry $\sigma_X$ on $X \subseteq E$ may then be extended to a full-fledged isometry $\sigma$ on the entire space $E.$


\paragraph{Projection.}

For $X$ a finite subset of $E$, we let $\underline{d}(X)$ denote  the \emph{inner diameter of $X$}, defined as $$\underline{d}(X) := \min_{x \neq x' \in X} d(x,x').$$
Moreover, we define the \emph{canonical projection on $X$} as the operator $\pi_X : E \mapsto \mathcal{P}(X)$ verifying $\pi_X(y) =\argmin_{x \in X} d(x,y)$ for all $y$ in $E.$ 

\smallskip
In particular, note that the codomain of $\pi_X$ is $\mathcal{P}(X)$, since the minimum may be achieved in multiple points simultaneously. Lemma~\ref{lem:conv_hausdorff} shows however that this does not happen when the domain of $\pi_X$ is restricted to finite sets $Y$ close enough to $X$; we denote the restricted operator as $\restr{\pi_X}{Y}.$
In such cases, we may associate each singleton $\{x\} $ in $\mathcal{P}(X)$ to the corresponding element $x \in X$ and recover the formulation in the main body.



\paragraph{Topology.}

In a metric space $(E,d)$, we denote by $B_r(x)$ the open ball of radius $r>0$ centered in $x \in E$, that is the set $B_r(x) := \{y \in E \mid d(x,y) < r\}.$ When $X$ is a set of points in $E$, we extend this definition and write $B_r(X) := \bigcup_{x\in X} B_r(x)$ for the union of the open balls of radius $r>0$ centered at each element of $X.$

\smallbreak
A set $X\subseteq E$ is then said to be \emph{open} if it contains a ball of positive size centered in each of its elements, i.e., for all $x \in X$, there exists $r>0$ such that $B_r(x) \subseteq X.$ 
On the contrary, we say that a set $X$ is \emph{closed} when its complement $X^c = E \setminus X$ is open. 
We next define the \emph{closure} $\overline{X}$ of a set $X$ as the smallest closed set that contains $X$, and its \emph{interior} $\mathring{X}$ as the largest open set contained within $X$.


\paragraph{Hausdorff measure.}

A \emph{$\sigma$-algebra on $E$} is a non-empty collection of subsets of $E$ closed under complement, countable union and countable intersections. In particular, the \emph{Borel $\sigma$-algebra} $\Sigma$ is the smallest $\sigma$-algebra by set inclusion containing all open sets of $E.$

We refer to the ordered pair $(E, \Sigma)$ as a \emph{measurable space}, and define a \emph{measure} as a function $\mu : \Sigma \mapsto \mathbb{R}\cup\{ \pm \infty \}$ that verifies 
\begin{enumerate}
    \item \emph{Non-negativity:} $\mu(X) \geq 0$ for all $X\in \Sigma$;
    \item  $\mu(\emptyset) =0$;
    \item \emph{Countable additivity:} $\mu\big ( \bigcup_{k\in\mathbb{N}} X_k \big) = \sum_{k\in\mathbb{N}} \mu(X_k)$ for all countable collection $\{X_k\}_{k\in\mathbb{N}}$ of pairwise disjoint sets in $\Sigma.$
\end{enumerate}

The \emph{Hausdorff measure} is particularly important, we recall its definition hereafter.
For $U$ a subset of $E$, we first define the \emph{diameter of $U$} as 
$$\operatorname{diam}(U) = \sup \{ d(x,y) \mid x,y, \in U \}.$$
We moreover adopt the convention $\operatorname{diam}(\emptyset)=0.$
For two positive real number $\delta$ and  $m$, as well as a subset $X \in \Sigma$, we further write
\begin{equation*}
\begin{aligned}
    \mathcal{H}^m_\delta(X) = \inf \Bigg\{ \sum_{k\in\mathbb{N}} \operatorname{diam}(U_k)^m \mid &X\subseteq \bigcup_{k\in\mathbb{N}} U_k, \\
    &\operatorname{diam}(U_k)<\delta \Bigg\},
\end{aligned}
\end{equation*}
where the infimum is taken over countable collections $\{U_k\}_{k\in\mathbb{N}}$ that cover $X$ with sets of diameter smaller than $\delta.$
The \emph{$m$-dimensional Hausdorff measure} is then finally defined as 
$$ \mathcal{H}^m(X) = 2^{-m} \alpha_m \cdot  \lim_{\delta \to 0}  \mathcal{H}^m_\delta(X) ,$$
where $\alpha(m) = \frac{\pi^{m/2}}{\Gamma(m/2+1)} $ denotes the volume of the unit $m$-ball, and $\Gamma$ represents Euler's gamma function. 

When $m$ is an integer, the scaling $2^{-m} \alpha_m$ ensures that the $m$-dimensional Hausdorff measure coincides with the classical Lebesgue measure on the Borel sets of an $m$-dimensional Euclidean space.

\smallbreak
For an Euclidean space $(E,d) = (\mathbb{R}^n, d_2) $, we can therefore write the $n-1$-dimensional surface of a ball of radius $r>0$  as 
$$ S^{n-1}_r = \mathcal{H}^{n-1} \big(B_r(x) \big),$$
where $x$ may be any point in $E$ since the Lebesgue measure, hence also the Hausdorff measure, are invariant by translation.
Denoting by $V^n_r$ the $n$-dimensional volume of a ball of radius $r>0$, we moreover have $V^n_r = \alpha(n) r^n $ as well as the relation $S^{n-1}_r = \frac{n}{r} V^n_r. $



\paragraph{Geometric measure theory.}

For two subsets $X,Y$ of $E = \mathbb{R}^n$, we define the \emph{Minkowski sum $X+Y$} as follows, i.e., $X+Y = \{ x+y \mid x \in X, y \in Y\}.$

\smallbreak
Let $o = (0,\dots,0)$ denote the origin and let $m$ be an integer verifying $0\leq m \leq n.$ We next define the \emph{$m$-dimensional Minkowski content of $X$} as
$$\mathcal{M}^{*m} (X) = \limsup_{\delta \to 0} \frac{ \mu\big( X + B_\delta(o) \big)}{\alpha(n-m) \delta^{n-m}},$$
where $\mu$ denotes the $m$-dimensional Lebesgue measure, and $X + B_\delta(o))$ is a Minkowski sum.
The \emph{$m$-dimensional lower Minkowski content } $\mathcal{M}_*^{m} (X)$ is similarly defined by replacing the $\sup$ by an $\inf$ in the definition of  $\mathcal{M}^{*m} (X).$

When the upper and lower $m$-dimensional Minkowski contents are equal, we call their common value $\mathcal{M}^{m} (X)$ the \emph{ $m$-dimensional Minkowski content of $X.$}

In particular for $m=n-1$, we have $\alpha(1)=2$ and we get
$$\mathcal{M}^{n-1} (X)  = \lim_{\delta \to 0} \frac{ \mu \big( X + B_\delta(o) \big)}{2\delta}.$$

A set $X$ is said to be \emph{$m$- rectifiable} if and only if there exists a Lipschitz function mapping some bounded subset of $\mathbb{R}^m$ onto $X.$ 
\smallbreak
With these definitions in place, we can now present a fundamental result in geometric measure theory that establishes a connection between the Minkowski content of well-behaved sets and their Hausdorff measure.

\begin{theorem}[From \cite{federer_geometric_1996}, Thm 3.2.39]
    If $X$ is a closed $m$-rectifiable set of $\mathbb{R}^n$, then 
    $\mathcal{M}^{m} (X) = \mathcal{H}^m(X).$
\end{theorem}




\section{Definition of Continuity in Terms of Metric and Discussion of the Axioms}\label{sec:metric_cont&axioms_disc}

In this section, we prove the Lemmas discussed in Section~\ref{sec:axioms}, and provide a more thorough discussion of the relationships between the different Axioms. 

We open this section with a short proof of Lemma~\ref{lem:conv_hausdorff} characterizing neighborhoods in $(\mathcal{P}(E), d_H).$


\begin{replemma}{lem:conv_hausdorff}
     Let $X$ be a finite subset of $E$ and $\delta$ satisfy $\underline{d}(X) /2 >\delta>0.$ 
     %For $\delta$ such that $\max_{x,x' \in X} d(x,x') >\delta>0$, 
     A finite subset $Y \in \mathcal{P}(E)$ is at distance $d_H(X,Y) \leq \delta$ if and only if the canonical projection $\restr{\pi_X}{Y}$ is the unique surjective map $\pi: Y \mapsto X$ such that $\max_{y \in Y} d(y,\pi(y)) \leq \delta$ holds.
\end{replemma}
\begin{proof}
Let $X$ be a finite subset in $\mathcal{P}(E)$ and let $\delta$ satisfy $\max_{x,x' \in X} d(x,x') / 2 >\delta>0.$

\smallskip
We first show the converse $\impliedby.$ Consider a finite subset $Y$ such that $\pi = \restr{\pi_X}{Y}$ is surjective and verifies $d(y,\pi(y)) \leq \delta.$
We directly have $d(X,y) \leq d(\pi(y), y) \leq \delta$ for all $y\in Y.$
Moreover for $x\in X$, the set $\pi^{-1}(x)$ is non-empty by surjectivity of $\pi$, and we similarly get $d(x,Y) \leq \min_{y \in \pi^{-1}(x)} d(\pi(y), y) \leq \delta.$
Taking the maximum over $Y$ and $X$ respectively, we finally establish that $\max_{y \in Y} d(X,y) \leq \delta$ and $\max_{x \in X} d(x,Y) \leq \delta$, which, combined with the definition of the Hausdorff norm, gives the desired result $d_H(X,Y) \leq \delta.$

\smallskip
We now turn to the direction $\implies.$ Let $Y$ be a finite subset in  $\mathcal{P}(E)$ that verifies $d_H(X,Y) \leq \delta.$ 
We first show that $\pi = \restr{\pi_X}{Y}$ is well-defined and surjective. 
Indeed, consider $x$ in $X$ and let $y$ be the element of $Y$ closest to $x.$ We then directly get $d(x,y) = d(x,Y) \leq d_H(X,Y) \leq \delta < \max_{z,z' \in X} d(z,z') /2.$
Moreover, let $x'$ be an element of $X$ different from $x.$
%Now suppose that $\pi(y)$ is different from $x.$ 
By triangle inequality, we get
$d(y, x') \geq d(x, x') - d(x,y) \geq \max_{z,z' \in X} d(z,z') - \delta  >  \delta.$
Since we know that $d(y,X) \leq d_(X,Y) \leq \delta$, there must be one element in $X$ at distance $\delta$ of $y$: this can only be $x$, i.e., $\pi(y) =x$, hence $\pi$ is well-defined and surjective.

Moreover, any other choice of $\pi(y) = x' \neq x$ will break the property $\max_{y\in Y} d(y, \pi(y))$, and $\restr{\pi_X}{Y}$ is the only choice.


% As a concluding remark, note that when the domain and codomain of $\pi$ are of the same cardinality, i.e., when $\vert Y\vert = \vert X\vert$, surjectivity directly implies bijectivity.
    
\end{proof}


We next show that Axiom~\ref{axi:class_cont} is simply an instance of the definition of continuity between two metric spaces.
For $S$ a finite subset of $E$, recall that we denote by $\Delta(S) := \big\{p_S : S \mapsto [0,1] \mid \sum_{x\in S} p_S(x) =1 \big\}$ the set of probability distributions over the elements of $S.$ We further define $\Delta_{\mathcal{P}}(E) := \bigcup_{S\in \mathcal{P}(E)} \Delta(S)$ to be the set of probability distributions over all finite subsets of $E.$
For two finite subsets $X,Y$ of $E$ with $\vert X \vert \leq \vert Y \vert$ and respective probability distributions $p_X$ in $\Delta(X)$ and $p_Y$ in $\Delta(Y)$, we then define the map $d_\Delta : \Delta_{\mathcal{P}}(E) \times \Delta_{\mathcal{P}}(E) \mapsto \mathbb{R}_{\geq 0}$ as follows:


\begin{equation*}
\begin{aligned}
    d_\Delta(p_X, p_Y) 
    &= \min_{\substack{\pi:Y\mapsto X \\ \pi \text{ surjective}}} \max \bigg\{ \max_{ y \in Y} d(y, \pi(y)), \\
    &\: \sum_{x \in X}  \Big \vert p_X(x) - \sum_{y \in \pi^{-1}(x)} p_Y(y) \Big| \bigg\} \\
    &= d_\Delta(p_Y, p_X).
\end{aligned}
\end{equation*}



%We next show that $\Delta_{\mathcal{P}}(E)$ equipped with $d_\Delta$ is a metric space.
\begin{lemma}
     The map $d_\Delta$ constitutes a metric on $\Delta_{\mathcal{P}}(E).$
\end{lemma}
\begin{proof} 
% The symmetry and reflexivity of $\sim_d$ are directly implied by the symmetry and the indistinguishability of pseudo-metric $d$; there only remains to verify that $\sim_d$ is transitive.
% We verify the four Axioms of a metric, i.e., non-negativity, distinguishability, symmetry, and triangle inequality.

Note that \emph{symmetry} and \emph{non-negativity} clearly hold by definition. We hence focus on \emph{separability} and \emph{triangle inequality.}

\begin{itemize}
    \item \emph{Separability.} Let $X,Y$ be two finite subsets of $E$ satisfying $\vert X \vert \leq \vert Y \vert$, and let $p_X, p_Y$ be probability distribution on the respective sets.
    
    \smallskip
    On one hand, we verify that $d_\Delta(p_X, p_X)=0$: indeed, the choice $\pi =\text{Id}$ renders both  terms of $d_\Delta(p_X, p_X)$ null since $d$ and $\Vert\cdot \Vert_1$ both satisfy distinguishability.

    \smallskip
    On the other hand, suppose that $d_\Delta(p_X, p_Y)=0$, and let $\pi: Y \mapsto X$ be the surjective map achieving the minimum. Since the first term is null and $d$ verifies distinguishability, we directly get that $X = Y.$ Since the second term is moreover null, we moreover obtain $p_X =p_Y$, and $d_\Delta$ also verifies distinguishability.

    
    \item \emph{Triangle inequality.}
Let $X,Y,Z$ be three sets in $\mathcal{P}(E)$ satisfying $\vert X \vert \leq \vert Y \vert \leq \vert Z \vert$, and $p_X, p_Y, p_Z$ be probability distribution on the respective sets. Let $\pi_Y : Z \mapsto Y$ and $\pi_X: Y \mapsto X$ be the two surjective maps that achieve the minimum in $d_\Delta(p_Z,p_Y)$ and in $d_\Delta(p_Y,p_X)$ respectively; we then denote by $\pi$ the surjective map $\pi_X \circ \pi_Y : Z \mapsto X.$

\begin{equation*}
    \begin{aligned}
        &d_\Delta(p_X, p_Z) \\
        &\stackrel{(a)}{\leq} \max \bigg\{ \max_{ z \in Z} d(z, \pi(z)), \\
        &\: \sum_{x \in X}  \Big \vert p_X(x) - \sum_{z \in \pi^{-1}(x)} p_Z(z) \Big\vert \bigg\} ,\\ 
        &\stackrel{(b)}{\leq} \max \bigg\{ \max_{ z \in Z} d(z, \pi_Y(z)) + d(\pi_Y(z),  \pi(z)), \\
        &\sum_{x \in X}  \Big \vert p_X(x) - \sum_{y \in \pi_X^{-1}(x)} p_Y(y) \Big\vert \\
        &+ \sum_{y \in \pi_X^{-1}(x)}  \Big \vert  p_Y(y) - \sum_{z \in \pi_Y^{-1}(y)} p_Z(z) \Big\vert \bigg\} ,\\ 
        &\stackrel{(c)}{\leq} \max \bigg\{ \max_{ z \in Z} d(z, \pi_Y(z)) + \max_{ y \in Y}d(y,  \pi_X(y)), \\
        &\sum_{x \in X}  \Big \vert p_X(x) - \sum_{y \in \pi_X^{-1}(x)} p_Y(y) \Big\vert \\
        &+  \sum_{y \in Y} \Big \vert  p_Y(y) - \sum_{z \in \pi_Y^{-1}(y)} p_Z(z) \Big\vert \bigg\} ,\\ 
        &\stackrel{(d)}{\leq} d_\Delta(p_X, p_Y) + d_\Delta(p_Y, p_Z)  .
    \end{aligned}
\end{equation*}
Inequality $(a)$ follows from the minimum in the definition of $d_\Delta(p_X, p_Z) $ being smaller than with the particular choice $\pi = \pi_X \circ \pi_Y$; 
inequality $(b)$ use the triangular inequality, as well as the partition $\pi^{-1}(x) = \bigcup_{y \in \pi_X^{-1}(x)} \pi_Y^{-1}(y).$
Inequality $(c)$ holds by taking the maximum over $Y$ in the first term and summing over the whole set $Y$ instead of simply $\pi^{-1}(x)$ in the second term;
inequality $(d)$ finally uses the inequality $\max\{a+b, u+v\} \leq \max \{a,u\} + \max \{b,v\}$, as well as the definitions of $\pi_Y$ and $\pi_X.$

\end{itemize}
    
\end{proof}

Combining these results, we finally characterize the representation functions that satisfy Axiom~\ref{axi:class_cont}.

\begin{lemma}
    A representation function $f$ 
    %on $(E,d)$ 
    satisfying Axiom~\ref{axi:class_cont} is precisely a continuous map from $(\mathcal{P}(E), d_H)$ to $(\Delta_{\mathcal{P}}(E), d_\Delta).$
\end{lemma}
\begin{proof}
Note that a representation function $f$ is indeed a map from $\mathcal{P}(E)$ to $\Delta_{\mathcal{P}}(E)$, we hereafter focus on the relationship between Axiom~\ref{axi:class_cont} and continuity between metric spaces.

\smallbreak
We first prove the direction $\implies.$ Consider an arbitrary small $\epsilon>0$ and a finite subset $X$ in $\mathcal{P}(E).$ By Axiom~\ref{axi:class_cont} and Lemma~\ref{lem:conv_hausdorff}, there exists $\delta >0$ small enough such that  $\max_{x\in X} \big\vert f(X)(x) - \sum_{y \in \pi^{-1}(x)} f(Y)(y) \big\vert \leq \epsilon / \vert X \vert$ holds for all finite subset $Y$ satisfying $d_H(X,Y) \leq \delta$, where the canonical projection $\pi = \restr{\pi_X}{Y}$ is surjective.
%, with $\pi:Y \mapsto X$ a surjective map given by Lemma~\ref{lem:conv_hausdorff}.
For all such subset $Y$, we then get
\begin{equation*}
\begin{aligned}
    d_\Delta(f(X), f(Y)) 
        &\leq \max \bigg\{ \max_{ y \in Y} d(y, \pi(y)), \\
        &\: \sum_{x \in X}  \Big \vert f(X)(x) - \sum_{y \in \pi^{-1}(x)} f(Y)(y) \Big\vert \bigg\}.
\end{aligned}
\end{equation*}
Note that the first term is bounded by $\delta \leq \epsilon$ by definition of $Y$ and $\pi.$
Moreover, as shown above, each of the $\vert X \vert$ terms of the sum is bounded by $\epsilon / \vert X \vert$ . We hence conclude that $d_\Delta(f(X), f(Y)) \leq \epsilon$, and $f$ is indeed a continuous map between the two metric spaces $(\mathcal{P}(E), d_H)$ and $(\Delta_{\mathcal{P}}(E), d_\Delta).$

\smallbreak
We next turn to the direction $\impliedby.$ Consider a finite subset $X$ in $\mathcal{P}(E)$ and an arbitrary $\epsilon$ such that $\underline{d}(X) /2 > \epsilon>0.$
By definition of continuity, there exists $\delta >0$ such that for all subsets $Y$ in $\mathcal{P}(E)$ satisfying $d_H(X,Y) \leq \delta$, it holds that $d_\Delta(f(X), f(Y)) \leq \epsilon.$ Let $\pi$ be the minimizer in $d_\Delta(f(X), f(Y))$; since $\pi:Y \mapsto X$ is a surjective map satisfying $d(y, \pi(y)) \leq \epsilon$ for all $y \in Y$, Lemma~\ref{lem:conv_hausdorff} implies that $\pi = \restr{\pi_X}{Y}.$ 
We then directly get Axiom~\ref{axi:class_cont}, i.e.,
$$\max_{x \in X} \Big\vert f(X)(x) - \sum_{y \in \pi^{-1}(x)} f(Y)(y) \Big\vert \leq d_\Delta(f(X), f(Y)) \leq \epsilon.$$
    
\end{proof}



We conclude this section with a discussion of Axioms~\ref{axi:class_cont}, \ref{axi:clone_fair_uni}, \ref{axi:indiv_cont} and~\ref{axi:alpha_clone_locality}.
First, note that the formulation of Axiom~\ref{axi:clone_fair_uni} stands out from the three others because it inverses the quantifiers for $X$ and $\delta$, in the spirit of uniform continuity. Note that this detail is of great importance as the non-uniform equivalent of Axiom~\ref{axi:clone_fair_uni} would always be trivially satisfied for a given finite subset $X$ by choosing $\delta$ strictly smaller than $\underline{d}(X).$ Even in the case of perfect clones in a pseudo-metric space (c.f. Section~\ref{sec:discu} ), this weaker form of Axiom~\ref{axi:clone_fair_uni} would not be interesting since perfect clones, being in the same isomorphism class, would already obtain the exact same representation under Axiom~\ref{axi:sym}.

One could however wonder whether stronger uniform versions of the remaining axioms could be considered. We argue this is not easily done for Axioms~\ref{axi:class_cont} and~\ref{axi:indiv_cont}. Indeed, both are defined in terms of the canonical projection $\restr{\pi_X}{Y}$, which is only necessarily surjective for a value of $\delta$ smaller than $\underline{d}(X) /2$, i.e.,  that depends on the choice of the underlying finite subset $X$ (c.f. Lemma~\ref{lem:conv_hausdorff}). Note moreover that surjectivity is vital: for each element $x$ in $X$ and $\delta > \underline{d}(X) /2 $, we can find a choice of $Y$ such that $x$ is not in the codomain of $\restr{\pi_X}{Y}$, and $x$ should receive representation smaller than $\epsilon.$ This is of course a contradiction.
Furthermore, switching to different surjective maps is not an alternative: what about symmetric cases, e.g., $X = \{(0,0), (1,1)\}$ and $Y = \{(0,1), (1,0) \}$ in $\mathbb{R}^2$? One would then have to consider multiple maps simultaneously, each with contradictory constraints.

The same issue does not occur for Axiom~\ref{axi:alpha_clone_locality} however, since it compares the representation of the same element $z$ in two different nearby sets. One could then strengthen Axiom~\ref{axi:alpha_clone_locality} by asking for $\delta$ to be independent of the underlying subset $X.$
%, see Axiom~\ref{axi:uni_alpha_clone_locality}.

\begin{axiom}[Uniform $\alpha$-Locality under Addition of Clones]\label{axi:uni_alpha_clone_locality}
The addition of a clone only changes the representation locally, i.e.,
for each $\epsilon >0$, there exists $\delta>0$ such that for all finite subset $S \in \mathcal{P}(E)$, element $x \in S$ and $\delta$-clone $x'$ satisfying $d(x,x') \leq \delta$, we have for all $z\in S$ such that $d(x,z)\geq \alpha$ that $\vert f(S)(z) - f(S\cup\{x'\})(z) \vert \leq \epsilon.$
\end{axiom}

Another possible direction to strengthen Axiom~\ref{axi:alpha_clone_locality} would be to require the same to hold also for $\epsilon = 0.$
%, see Axiom~\ref{axi:strict_alpha_clone_locality}.



\begin{axiom}[Strict $\alpha$-Locality under Addition of Clones]\label{axi:strict_alpha_clone_locality}
The addition of a clone only changes the representation locally, i.e.,
for a finite subset $S \in \mathcal{P}(E)$, there exists $\delta>0$ such that, for each element $x \in S$ and $\delta$-clone $x'$ satisfying $d(x,x') \leq \delta$, we have for all $z\in S$ such that $d(x,z)\geq \alpha$ that $f(S)(z) = f(S\cup\{x'\})(z).$
\end{axiom}

Note that the family of representation function $g_r$ we introduced in Section~\ref{sec:local_voting} verifies neither of these strengthenings.











\section{Proofs of the Main Results}\label{sec:proof}

This section gathers the proofs of Theorems~\ref{thm:local_vote_rep_func} and~\ref{thm:cont_convex_combi_gr}. Most of the technical tools required for the demonstrations are introduced in Appendix~\ref{sec:def}. Before delving into the proof of Theorem~\ref{thm:local_vote_rep_func}, let us first recall its formulation.

\begin{reptheorem}{thm:local_vote_rep_func}
For $r>0$, the representation function $g_r$ is well-defined and belongs in $\mathcal{R}_{2r}(\mathbb{R}^n, d_2).$
\end{reptheorem}

\begin{proof}
     Let $r>0$ be a positive radius, we first verify that $g_r$ is a well-defined representation function. 
    Let $S$ be a finite subset of $\mathbb{R}^n$, and $x$ be an element of $S$, we show that $ g_{r,S,x}$ is measurable with respect to the Lebesgue measure $\mu$. 
    Indeed, consider the following partition of its domain
    \begin{equation*}
        \begin{aligned}
            B_r(S) 
            &= \bigcup_{U \subseteq S} A_r(U),
        \end{aligned}
    \end{equation*}
    where $A_r(U) = \bigcap_{u\in U} B_r(u) \bigcap_{v \in S\setminus U} \big( B_r(S) \setminus B_r(v) \big)$ belongs in the Borel $\sigma$-algebra for all choice of $U \subseteq S$. 
    Note that this partition is finite since there are at most $2^{\vert S \vert }$ choices for the subset $U.$ 

    Moreover,  $g_{r,S,x}$ is null on $B_r(S)  \setminus B_r(x)$ and, for all $U \subseteq S$ with $x\in U$ and all $y$ in $A_r(U)$, we have $g_{r,S,x}(y) = \frac{1}{\vert U \vert}.$ Using the above partition, we rewrite 
    \begin{equation}\label{equ:grade_simple_f}
        g_{r,S,x}: y \in B_r(S) \mapsto \sum_{ \{x\} \subseteq U \subseteq S } \frac{\mathbb{1}_{A_r(U)}(y) } { \vert U \vert},
    \end{equation}
     and recognize a simple non-negative function. As such,  $g_{r,S,x}$ is both measurable and integrable, and $g_r(S)$ is well-defined. 
     Moreover, we verify that $g_r(S)$ is normalized.
    \begin{equation*}
        \begin{aligned}
            \sum_{x\in S} g_r(S)(x)
            &= \sum_{x\in S} \int_{B_r(S)} \frac{g_{r,S,x}}{\mu(B_r(S))} \:d\mu ,\\
            &= \int_{B_r(S)} \frac{1}{\mu(B_r(S))}    \sum_{x\in S} \frac{ \mathbb{1}_{B_r(x)}(y) }{\sum_{z \in S} \mathbb{1}_{B_r(z)}(y) }\: d\mu(y), \\
            &= \int_{B_r(S)} \frac{ 1}{\mu(B_r(S))} \: d\mu =1.
        \end{aligned}
    \end{equation*}
    %where $(a)$ uses Fubini's theorem since $g_{r,S,x}$ is integrable.
    
    Since $g_r(S)$ is also non-negative, it is a probability distribution over $S$, hence $g_r$ is indeed a well-defined representation function over $\mathcal{P}(\mathbb{R}^n)$.

    \medskip
     \textbf{Axiom~\ref{axi:pos}.} Let $S$ be a finite subset of $\mathbb{R}^n$, and $x$ be an element of $S.$ Using the expression of $g_{r,S,x}$ in Equation~\eqref{equ:grade_simple_f}, we get for each $y$ in $B_r(x)$ that $g_{r,S,x}(y) \geq \frac{1}{\vert S\vert}.$ Since $\mu\big(B_r(S)\big) \leq \vert S \vert \cdot \mu\big(B_r(x)\big) $ by countable additivity and uniformity of $\mu$, we finally obtain
     %\damien{Is invariance by translation clearer?}
     \begin{equation}\label{equ:proof_gr_pos}
         \begin{aligned}
             g_r(S)(x) 
             &\stackrel{(a)}{=} \int_{B_r(x)} \frac{g_{r,S,x}}{\mu\big(B_r(S)\big)} \:d\mu, \\
             &\geq \frac{1}{\vert S \vert} \int_{B_r(x)} \frac{1}{\mu\big(B_r(S)\big)} \:d\mu, \\
             &= \frac{1}{\vert S \vert} \frac{\mu\big(B_r(x)\big)}{\mu\big(B_r(S)\big)} \geq \frac{1}{\vert S \vert^2}.
         \end{aligned}
     \end{equation}
     Equality $(a)$ holds since  $g_{r,S,x}$ is null on $B_r(S)  \setminus B_r(x).$
      Hence we have $g_r(S)(x) >0$ for all $x \in S$, and Axiom~\ref{axi:pos} holds.
    
    \medskip
    \textbf{Axiom~\ref{axi:sym}.} Let $S\subset \mathbb{R}^n$ be a finite subset,  $\sigma_S :S \mapsto S$ be a self-isometry on $S$, and $x$ be an element of $S.$ 
    Since $g_{r,S,x}$ is a simple function, we deduce from Equation~\eqref{equ:grade_simple_f} the following, i.e., 
    \begin{equation*}
        \begin{aligned}
            g_r(S)(\sigma(x))
            &= \frac{1}{\mu\big(B_r(S)\big)} \sum_{\{\sigma(x)\} \subseteq U \subseteq S} \frac{\mu\big(A_r(U)\big) } { \vert U \vert},\\
            &\stackrel{(a)}{=}  \frac{1}{\mu\big(B_r(S)\big)} \sum_{\{x\} \subseteq V \subseteq S } \frac{\mu\big(A_r(\sigma_S(V))\big) } { \vert \sigma_S(V) \vert },\\
            &\stackrel{(b)}{=}  \frac{1}{\mu\big(B_r(S)\big)} \sum_{ \{x\} \subseteq V \subseteq S} \frac{\mu\big(T\circ L(A_r(V))\big) } { \vert V \vert},\\
            &\stackrel{(c)}{=}  \frac{1}{\mu\big(B_r(S)\big)} \sum_{\{x\} \subseteq V \subseteq S} \frac{\mu\big(A_r(V))\big) } { \vert V \vert },\\
            &= g_r(S)(x).
        \end{aligned} 
    \end{equation*}
    Equality $(a)$ holds by writing $V = \sigma_S^{-1}(U) = \{ \sigma_S^{-1}(u) \mid u \in U\}$ and noting that $V$ contains $ \{x\}$.
    Equality $(b)$ uses that $\vert \sigma_S(V) \vert = \vert V \vert $ and the decomposition of the isometry $\sigma_S$ as a linear transformation $L: x\mapsto Qx$ and a translation $T:x \mapsto x + t$, where $Q$ and $t$ are the orthogonal matrix and the vector of Lemma~\ref{lem:isometry_rigid_transformation}. Using that $T\circ L$ is an isometry on $\mathbb{R}^n$, we then rewrite $A_r(\sigma_S(V)) = T\circ L (A_r(V)).$
    
    Finally, Equality $(c)$ follows from the invariance of the Lebesgue measure by translation $\mu\big( T\circ L (A_r(V))\big)= \mu\big( L (A_r(V))\big)$, as well as its behavior under linear transformation $\mu\big( L (A_r(V))\big) = \vert \text{det}(Q)\vert \cdot \mu\big( A_r(V)\big) = \mu\big( A_r(V)\big) $, where we used that $Q$ is orthogonal.
    Hence Axiom~\ref{axi:sym} holds.
    

    \medskip
    Since the proofs of Axioms~\ref{axi:clone_fair_uni}, \ref{axi:indiv_cont} and~\ref{axi:alpha_clone_locality} use similar techniques, we first introduce the necessary tools in the more complex case of Axiom~\ref{axi:indiv_cont}, and later use similar arguments to show Axiom~~\ref{axi:alpha_clone_locality} and then~\ref{axi:clone_fair_uni}.


    \medskip 
    \textbf{Axiom~\ref{axi:indiv_cont}.}
     Let $X$ be a finite subset of $\mathbb{R}^n$, and let $\delta$ satisfy $\min\{r, \underline{d}(X) /2\} > \delta > 0.$
    Consider a subset $Y$ of $\mathbb{R}^n$ satisfying $\vert X \vert = \vert Y \vert$ and $d_H(X,Y) \leq \delta.$ 
    Note that Lemma~\ref{lem:conv_hausdorff} ensures that $\pi= \restr{\pi_X}{Y}$ the cardinal projection on $X$ is bijective and verifies $d(y, \pi(y)) \leq \delta$ for all $y$ in $Y.$ 
    
     For $U$ a subset of $X$, we denote by $\partial A_r(U)$ the boundary of $A_r(U).$ We moreover associate with $A_r(U)$ its ``thick interior'' $A_r^{-\delta}(U) = \big\{ x \in S \mid d(x, \partial A_r(U)) > \delta \big\} $, as well as its ``thick closure'' $A_r^{+\delta}(U) = \big\{ x \in \mathbb{R}^n \mid d(x, A_r(U)) \leq \delta \big\}.$ Note that these definitions allow to obtain the ``thick boundary'' of $A_r(U)$ by set difference, i.e., $ \partial A_r(U) + \overline{B}_\delta(o) = A_r^{+\delta}(U) \setminus A_r^{-\delta}(U) .$

     \smallskip
     We next show that $A_r^{-\delta}(U) \subseteq  A_r(\pi(U))$; let $z$ be an element of $A_r^{-\delta}(U).$
     \begin{itemize}
         \item  Let $u$ be an element of $U$ and let $z'$ be the projection of $z$ on the boundary of $B_r(u).$ Note in particular that $z$ belongs to the segment $[z',u].$
        This implies that $d(z,u) = d(z',u) - d(z,z') < r -\delta$ by definition of $A_r^{-\delta}(U).$ By triangle inequality, we then get $d(z,\pi(u)) \leq d(z,u) + d(u,\pi(u)) \leq \delta.$  Note that this holds for all choices of $u$ in $U$, hence also for all $\pi(u)$ in $ \pi(U).$ 

        \item Now let $v$ be an element of $X\setminus U$ and let $z'$ be the projection of $z$ on the boundary of $B_r(v).$ Note this time that $z'$ belongs in the segment $[z,v]$ and we similarly obtain $d(z,v) = d(z',z) + d(z',v) > r+\delta > r-\delta$ using the definition of  $A_r^{-\delta}(U).$ The triangle inequality again gives $d(z,\pi(v)) \geq  d(z,v) - d(v,\pi(v)) \geq \delta$ for all $\pi(v) \in Y \setminus \pi(U).$ 
     \end{itemize}
     Together, this implies that $z$ lies in  $A_r(\pi(U))$ and we conclude that $A_r^{-\delta}(U) \subseteq  A_r(\pi(U)).$
     
    \smallskip
    Since $A_r^{-\delta}(U)$ is also a subset of $A_{r}(U)$,
    Equation~\eqref{equ:grade_simple_f} implies, for all $x$ in $X$ and $z$ in $A_r^{-\delta}(U)$, that $g_{r,X,x}(z) = \mathbb{1}_U(z) /  \vert U \vert  = g_{r,Y,\pi(x)}(z).$
    Since this holds for all choices of $U \subseteq X$, we finally get that $g_{r,X,x}  = g_{r,Y,\pi(x)}$ on $A_r^{-\delta,X} := \bigcup_{U \subseteq X} A_r^{-\delta}(U).$

    \smallskip
    We now bound the difference of representation between $x$ in $X$ and $\pi(x)$ in $Y$ using the partition of $B_r(X \cup Y)$ induced by $A_r^{-\delta,X}.$

    \begin{equation}\label{equ:bound_rep_diff_X&Y}
        \begin{aligned}
            &\big\vert g_r(X)(x) - g_r(Y)(\pi(x)) \big\vert \\
            &= \bigg\vert \int_{B_r(X)} \frac{g_{r,X,x}} {\mu\big(B_r(X)\big)} d\mu  - \int_{B_r(Y)} \frac{g_{r,Y,\pi(x)}} {\mu\big(B_r(Y)\big)} d\mu \bigg\vert ,\\
            &\stackrel{(a)}{\leq} \bigg \vert \frac{\mu\big(B_r(X)\big)}{\mu\big(B_r(Y)\big)} -  1 \bigg\vert \cdot \bigg 
             \vert\int_{A_r^{-\delta,X}} \frac{g_{r,X,x}} {\mu\big(B_r(X)\big)} d\mu \bigg\vert \\
            &+  \int_{ B_r( X\cup Y )\setminus A_r^{-\delta,X}} \frac{1} {\mu\big(B_r(x)\big)}  d\mu , \\
            &\stackrel{(b)}{\leq}   \frac{\mu\big(B_{r + \delta}(X)\big) - \mu\big(B_{r}(X)\big)} {\mu\big(B_r(\pi(x))\big)}  
            +  \frac{ \mu\big(B_{r + \delta}( X )\big) -   \mu\big(A_r^{-\delta,X}\big)}{\mu\big(B_r(x)\big)} ,\\
            &\stackrel{(c)}{\leq} \frac{2}{V_r^n} \sum_{U \subseteq X} \mu\big(A_{r}^{+\delta}(U)\big) -  \mu\big(A_{r}^{ - \delta}(U)\big) .\\
        \end{aligned}
    \end{equation}

    Inequality $(a)$ follows from the functional equality $g_{r,X,x}  = g_{r,Y,\pi(x)}$ on $A_r^{-\delta,X}$ and the fact that the two functions have their image in $[0,1]$ otherwise; it also uses that both $\mu\big(B_r(X)\big)$ and $\mu\big(B_r(Y)\big)$ are greater than $\mu\big(B_r(x)\big).$
    We establish inequality $(b)$ by noting that $B_r(\pi(x)) \subseteq B_r(Y) \subseteq B_{r+\delta}(X)$ and that the integral in the first term is bounded by one.
    Finally, inequality $(c)$ holds by writing $V_r^n$ for the volume of the $n$-dimensional Euclidean ball of radius $r$,
    and using the inclusion $B_{r+\delta}(X) \subseteq \bigcup_{U\subseteq X} A_r^{+\delta}(U)$ in combination with Boole's inequality and the definition of $A_r^{-\delta,X}.$
    
    \smallbreak
     For $U\subseteq X$, remark that the boundary $ \partial A_{r}(U)$  is covered by the countable union of smooth $n-1$ manifolds $\bigcup_{x\in X} \partial B_{r}(x)$, hence it is $n-1$ rectifiable. 
    By \cite[Theorem 3.2.39]{federer_geometric_1996}, the Minkovski content of the boundary $ \mathcal{M}^{n-1}\big(\partial A_{r}(U)\big)$ exists and is equal to its $n-1$ dimensional Hausdorff measure $ \mathcal{H}^{n-1}\big(\partial A_{r}(U) \big)$, i.e.,

    \begin{equation*}
    \begin{aligned}
        \mathcal{M}^{n-1}\big(\partial A_{r}(U) \big)
         &=\lim_{\delta \to 0} \frac{ \mu\big(\partial A_{r}(U) + B_\delta(o)\big)  }{2 \delta} ,\\
         &\stackrel{(a)}{=}\lim_{\delta \to 0} \frac{ \mu\big(A_r^{+\delta}(U)\big)  - \mu\big( A_r^{-\delta}(U) \big)}{2 \delta} ,\\
         &= \mathcal{H}^{n-1} \big(\partial A_{r}(U)\big) .
    \end{aligned}
    \end{equation*}
    Equality $(a)$ follows from the definitions of the sets $A_r^{+\delta}(U)$ and $A_r^{-\delta}(U)$ leading to the set equality $ \partial A_r(U) + \overline{B}_\delta(o) = A_r^{+\delta}(U) \setminus A_r^{-\delta}(U) .$

    \smallskip
     We can hence take $\delta >0$ small enough so as to satisfy, for all subsets $U\subseteq X$, 
    \begin{equation}\label{equ:cont_bound_diff_with_Hausdorff}
        \mu\big(A_r^{+\delta}(U)\big)  - \mu\big( A_r^{-\delta}(U) \big) \leq 4 \delta \mathcal{H}^{n-1}(\partial A_{r}(U)).
    \end{equation}

    With such a choice of $\delta$, Equation~\eqref{equ:bound_rep_diff_X&Y} then becomes, i.e.,
    \begin{equation}\label{equ:proof_cont_final}
        \begin{aligned}
            \big\vert g_r(X)(x) - g_r(Y)(\pi(x)) \big\vert
            &\leq  \frac{8 \delta}{ V^n_r}   \sum_{ U \subseteq X}  \mathcal{H}^{n-1} (\partial A_{r}(U) ) ,\\
            &\stackrel{(a)}{\leq}  \frac{16 \delta}{ V^n_r}   \sum_{ x\in X}  \mathcal{H}^{n-1} (\partial B_{r}(x) ) , \\
             &\stackrel{(b)}{=} \frac{16  \delta \vert X \vert n }{ r}.
        \end{aligned}
    \end{equation}
    Inequality $(a)$ follows from the set equality $\bigcup_{U\subseteq X} \partial A_{r}(U) = \bigcup_{x\subseteq X} \partial B_{r}(x),$ as well as by noting that each component of the boundary $\partial A_{r}(U)$  is counted at most twice over all subsets $U\subseteq X$.
    Equality $(b)$ uses the relation between the surface and the volume of an $n$-dimensional sphere of radius $r$, i.e.,
    $\mathcal{H}^{n-1} \big(\partial B_{r}(x) \big)= S^{n-1}_r = \frac{n}{r} V^n_r .$

    \smallskip
    For a fixed radius $r > 0$ and an arbitrary $\epsilon > 0$, we can finally choose $\delta \leq \epsilon r / \big( 16 \vert X \vert n \big)$ small enough, and Axiom~\ref{axi:indiv_cont} holds.



    
 


    \medskip
    \textbf{Axiom~\ref{axi:alpha_clone_locality}.} 
    Let $S\subseteq \mathbb{R}^n$ be a finite subset, $x$ be an element of $S$ and $x' \in \mathbb{R}^n \setminus S$ be a $\delta$-clone of $x$, where $\delta$ verifies $\min\{r, \underline{d}(S)/2\} > \delta >0.$ We moreover denote by $S'$ the union $S \cup \{x'\}.$

    \smallskip
    The proof follows the same structure as that of Axiom~\ref{axi:indiv_cont}: for $y$ an element of $S$ such that $d(x,y) \geq 2r$, we first show that $ g_{r,S,y}$ and $g_{r,S',y}$ are equal on a carefully chosen set.
    Indeed for $z$ an element of $B_{r - \delta}(y)$, the triangle inequality gives $d(z,x') \geq d(x,y) - d(x,x') - d(x',y) > 2r - \delta - (r- \delta) = r $, and we obtain that $ g_{r,S,y}(z) = g_{r,S',y}(z).$ 

    \smallskip
    We then bound the difference of representation between $S$ and $S'$ in a similar fashion as in Equation~\eqref{equ:bound_rep_diff_X&Y}.
    \begin{equation*}%\label{eq:bound_rep_diff_local_simple}
        \begin{aligned}
             &\big\vert g_r(S)(y) - g_r(S')(y) \big\vert \\
             &\stackrel{(a)}{\leq}  \bigg(\frac{\mu\big(B_r(S')\big)}{\mu\big(B_r(S)\big)} -  1 \bigg) \cdot \bigg\vert  \int_{B_{r - \delta}(y)} \frac{g_{r,S',y}} {\mu\big(B_r(S')\big)} d\mu \bigg\vert \\
             &+  \int_{B_r(y)\setminus B_{r - \delta}(y)} \frac{1} {\mu\big(B_r(S)\big)}  d\mu ,\\
             &\stackrel{(b)}{\leq}   \frac{\mu\big(B_{r + \delta}(S)\big) - \mu\big(B_r(S)\big)}{\mu\big(B_r(y)\big)}  + \frac{ \mu\big(B_r(y)\big) - \mu\big(B_{r - \delta}(y)\big)}{\mu\big(B_r(y)\big)} ,\\
             &\stackrel{(c)}{\leq} \frac{4 \delta}{  V^n_r} \Big(S_r^{n-1} + \sum_{U\subseteq S} \mathcal{H}^{n-1}(\partial A_{r}(U)) \Big) .
             %\stackrel{(d)}{\leq} \frac{2\delta (2 \vert X \vert +1) n }{ r}.
        \end{aligned}
    \end{equation*}
    Inequalities $(a)$ and $(b)$ follow from similar arguments as Equation~\eqref{equ:bound_rep_diff_X&Y}$(a)$ and $(b)$ respectively; inequality $(c)$ holds for $\delta$ small enough by combining the arguments of Equation~\eqref{equ:bound_rep_diff_X&Y}$(c)$ and Equation~\eqref{equ:cont_bound_diff_with_Hausdorff}.
    
    \smallskip
    A similar double-counting argument as in Equation~\eqref{equ:proof_cont_final}$(a)$ 
    %and the equality $V^n_r = \frac{r}{n} S^{n-1}_r$ 
    finally gives 
    \begin{equation}\label{equ:proof_clone_loc_final}
        \big\vert g_r(S)(y) - g_r(S')(y) \big\vert 
        \leq \frac{4\delta (2 \vert S \vert +1) n }{ r} \leq \epsilon,
    \end{equation}
    where the last inequality holds for an arbitrary $\epsilon>0$ and a choice of $\delta \leq  \epsilon  r / \big( 4n (2 \vert S \vert + 1)  \big) $ small enough. Hence Axiom~\ref{axi:alpha_clone_locality} holds with $\alpha = 2r.$

    

    \medskip
    \textbf{Axiom~\ref{axi:clone_fair_uni}.} 
    Let $\delta$ be a positive number satisfying $r> \delta >0$, and $S$ be a finite subset of $\mathbb{R}^n.$ We moreover let $x,y$ be two elements of $S$ such that $d(x,y) \leq \delta.$

    \smallskip
    Similarly as for the proof of Axiom~\ref{axi:indiv_cont}, we first show that $B_{r-\delta}(x) \subset B_{r}(x) \cap B_r(y).$ Indeed, for $z$ an element of $B_{r-\delta}(x)$, the triangle inequality gives $d(z,y) \leq d(z,x) + d(x,y) < r -\delta + \delta = r.$ Equation~\eqref{equ:grade_simple_f} then implies the functional equality $g_{r,S,x} = g_{r,S,y}$  on $B_{r-\delta}(x).$

    \smallskip
    We then bound the difference of representation between $x$ and $y$ in a similar fashion as in Equation~\eqref{equ:bound_rep_diff_X&Y}.
    \begin{equation}\label{equ:bound_clone_fair}
        \begin{aligned}
             \big\vert g_r(S)(x) - g_r(S)(y) \big\vert
             %&= \bigg\vert \int_{B_r(z)} \frac{g_{r,S,z}} {\mu\big(B_r(X)\big)} - \frac{g_{r,S',z}} {\mu\big(B_r(X')\big)} d\mu \bigg\vert ,\\
             &\stackrel{(a)}{\leq}   \int_{B_r(x)\setminus B_{r - \delta}(x)} \frac{1} {\mu\big(B_r(S)\big)}  d\mu ,\\
             &\stackrel{(b)}{\leq}  \frac{ \mu\big(B_r(x)\big) - \mu\big(B_{r - \delta}(x)\big)}{\mu\big(B_r(x)\big)}  \\
             &\stackrel{(c)}{\leq} \frac{4 \delta S_r^{n-1}}{  V^n_r} = \frac{4 \delta n}{r},
        \end{aligned}
    \end{equation}
    where inequality $(a)$ and $(b)$ use similar arguments as for Equation~\eqref{equ:bound_rep_diff_X&Y}$(a)$ and $(b)$ respectively; inequality $(c)$ follows from combining the arguments of Equations~\eqref{equ:cont_bound_diff_with_Hausdorff} and~\eqref{equ:proof_cont_final}. 
    In particular, note that 
    $ \mu\big(B_{r}(x)\big) - \mu\big(B_{r -\delta}(x)\big) \leq \mu\big(B_{r+\delta}(x)\big) - \mu\big(B_{r -\delta}(x)\big) \leq 4 \delta S_r^{n-1} $
    holds for a value of $\delta$ small enough but independent of $S$ since the Lebesgue measure is invariant by translation.
    
    \smallskip
    Then for an arbitrary $\epsilon>0$, a choice of $\delta \leq  \epsilon  r / (4n) $ small enough ensures that Axiom~\ref{axi:clone_fair_uni} holds.
    

    
   \medskip \textbf{Conclusion.} 
   Since $g_r$ is a representation function on $(\mathbb{R}^n, d_2)$ satisfying Axioms~\ref{axi:pos}, \ref{axi:sym}, \ref{axi:clone_fair_uni}, \ref{axi:indiv_cont} and \ref{axi:alpha_clone_locality} with $\alpha =2r$, we conclude that $g_r$ belongs in $\mathcal{R}_{2r}(\mathbb{R}^n,d_2).$

\end{proof}
    

We now recall the formulation of Theorem~\ref{thm:cont_convex_combi_gr} before attacking its demonstration.




\begin{reptheorem}{thm:cont_convex_combi_gr}
    Let $\nu$ be a probability density function over $[0,\alpha/2].$
    Then the representation function $f_\nu : S \in \mathcal{P}\big(\mathbb{R}^n \big) \mapsto \int_0^{\alpha/2} \nu(r) g_r(S) ~dr$ belongs in $\mathcal{R}_\alpha(\mathbb{R}^n,d_2).$
\end{reptheorem}

\begin{proof}
Let $\nu$ be a probability density function over $[0,\alpha/2]$, that is a non-negative Lebesgue-integrable function satisfying $\int_0^{\alpha/2} \nu(r) dr =1$. Let $S$ be a finite subset of $\mathbb{R}^n$ and $x$ be an element of $S.$

\smallskip
First, note that $r \mapsto g_r(S)(x)$ is a non-negative step function over $\mathbb{R}_{>0}$, hence  $r \mapsto \nu(r) \cdot g_r(S)(x)$ is Lebesgue-integrable and $f_\nu(S)(x)$ is non-negative. Moreover, we have 
\begin{equation*}
\begin{aligned}
    \sum_{x \in X} f_\nu(S)(x) 
    &=  \int_{(0,\alpha/2]} \nu(r) \sum_{x \in X} g_r(S)(x) ~dr ,\\
    &\stackrel{(a)}{=}  \int_{(0,\alpha/2]} \nu(r) ~dr =1 ,
\end{aligned}
\end{equation*}
where equality $(a)$ uses that $g_r$ is a representation function.
This ensures that $f_\nu$ is  also a representation function of $(\mathbb{R}^n, d_2).$
 
\smallskip

We now verify that Axioms~\ref{axi:pos}, \ref{axi:sym}, \ref{axi:clone_fair_uni}, \ref{axi:indiv_cont} and \ref{axi:alpha_clone_locality} are implied for $f_\nu$ from the fact that $g_r$ belongs in $\mathcal{R}_\alpha(\mathbb{R}^n,d_2)$ for all $\alpha/2\geq r>0.$
On the one hand, Axiom~\ref{axi:pos} is directly implied from Equation~\eqref{equ:proof_gr_pos}, i.e,
\begin{equation*}
\begin{aligned}
    f_\nu(S)(x) 
    &=  \int_{(0,\alpha/2]} \nu(r)  g_r(S)(x) ~dr , \\
    &\geq \int_{(0,\alpha/2]} \frac{\nu(r)}{|S|^2}  dr , \\
    &= \frac{1}{|S|^2} >0.
\end{aligned}
\end{equation*}
%We similarly get that Axiom~\ref{axi:sym} holds for $f_\nu$: for an isometry $\sigma:S\mapsto S$, we have 
Furthermore, for an isometry $\sigma_S : S\mapsto S$, we have
\begin{equation*}
\begin{aligned}
    f_\nu(S)(\sigma_S(x)) 
    &=  \int_{(0,\alpha/2]} \nu(r)  g_r(S)(\sigma_S(x)) ~dr , \\
    &\stackrel{(a)}{=} \int_{(0,\alpha/2]} \nu(r)  g_r(S)(x) ~dr , \\
    &= f_\nu(S)(x),
\end{aligned}
\end{equation*}
where equality $(a)$ uses that Axiom~\ref{axi:sym} holds for $g_r$, hence it also holds for $f_\nu.$
\smallbreak
On the other hand, Axioms~\ref{axi:clone_fair_uni}, \ref{axi:indiv_cont} and~\ref{axi:alpha_clone_locality} require a little more work; we hereafter focus on Axiom~\ref{axi:indiv_cont}.
%Let $C$ be a positive constant in $(0,\alpha/2)$, let $\delta>0$ be strictly smaller than $C$,
Let $C$ be a positive constant in $(0, \alpha/2)$, and $X$ be a finite subset of $\mathbb{R}^n.$ For a constant $\delta$ satisfying $ \min\{C, \underline{d}(X) /2 \}> \delta >0$ and a finite subset $Y \in \mathcal{P}(\mathbb{R}^n)$ satisfying $d_H(X,Y) \leq \delta$ and $\vert Y \vert = \vert X \vert$,  Lemma ~\ref{lem:conv_hausdorff} ensures that the canonical projection $\pi = \restr{\pi_X}{Y}$ is bijective and verifies $\max_{y \in Y} d(y, \pi(y)) \leq \delta.$
The following then holds, i.e.,
\begin{equation*}
    \begin{aligned}
        &\big\vert f_\nu(X)(x) - f_\nu(Y)(\sigma(x)) \big\vert \\
        &\stackrel{(a)}{\leq} \int_{(0,\alpha/2]} \nu(r) \big\vert g_r(X)(x) - g_r(Y)(\pi(x)) \big\vert dr,\\
        &\stackrel{(b)}{\leq} \int_0^C \nu(r)  dr + \int_{C}^{\alpha/2} \nu(r) \frac{16  \delta \vert X \vert n }{ r} dr,\\
        &\stackrel{(c)}{\leq} \mathcal{V}(C) + \frac{16  \delta \vert X \vert n }{ C}.
    \end{aligned}
\end{equation*}
Inequality $(a)$ uses the non-negativity of $\nu$ and the triangle inequality;
inequality $(b)$ holds for $\delta$ small enough by bounding the difference $\big\vert g_r(X)(x) - g_r(Y)(\sigma(x)) \big\vert $ by one in the first term, and using Equation~\eqref{equ:proof_cont_final} for the second term. Inequality $(c)$ is finally obtained by rewriting $\mathcal{V}(\cdot)$ for the cumulative distribution associated with the density $\nu(\cdot)$, and noting that $r\mapsto \frac{16  \delta \vert X \vert n }{ r}$ is decreasing on $[C,\alpha/2]$.

\smallskip
Now fix $\epsilon>0$; by continuity of $\mathcal{V}$, there exists $C>0$ such that $\mathcal{V}(C) = \epsilon /2$. Then for $0<\delta \leq \epsilon C /(32   \vert X \vert n ) $ small enough, we get $\big\vert f_\nu(X)(x) - f_\nu(Y)(\sigma(x)) \big\vert \leq \epsilon$ and Axiom~\ref{axi:indiv_cont} holds for $f_\nu.$

\medskip
Similar arguments combined with Equations~\eqref{equ:proof_clone_loc_final} and~\eqref{equ:bound_clone_fair} respectively show that Axioms~\ref{axi:alpha_clone_locality} and~\ref{axi:clone_fair_uni} hold for $f_\nu.$
We then conclude that $f_\nu$ belongs in $\mathcal{R}_\alpha(\mathbb{R}^n,d_2).$


\end{proof}



\section{Self-Isometries in Euclidean Space}\label{sec:self-iso_eucli}

In this section, we show that a self-isometry $\sigma_S$ on a finite subset $S \subseteq \mathbb{R}^n$ can be uplifted to a full-fledged isometry on $\mathbb{R}^n$, that is a rigid transformation.



\begin{lemma}
\label{lem:isometry_rigid_transformation}
Let $S=\{x_1, \dots, x_m\}$ be a finite subset of the Euclidean space $\mathbb{R}^n$ and  $\sigma_S:S\mapsto S$ be a self-isometry on $S.$
 There then exists an $n\times n$-orthogonal matrix $Q$ and an $n$-dimensional vector $t$ such that, for all $i\in[m]$, we have $\sigma(x_i) = Q x_i + t.$
\end{lemma}
\begin{proof}
For an index $2 \leq i \leq m$, we define $y_i = x_{i} - x_1$ and $z_i = \sigma(x_{i})  - \sigma(x_1).$ 
We then concatenate the $y_i$ (resp. $z_i$) and define the $n\times(m-1)$ matrix $Y = [y_2, \dots, y_{n}]$ (resp. $Z = [z_2, \dots, z_{m}]$).
For $i,j \in [m-1]$, note that the following holds:
\begin{equation*}
    \begin{aligned}
        (Y^\top Y)_{i,j} 
        &= y_{i+1} \cdot y_{j+1} ,\\
        &= \frac{1}{2} \Big(\Vert y_{i+1} + y_{j+1}\Vert^2 - \Vert y_{i+1} \Vert^2 - \Vert y_{j+1} \Vert^2 \Big),\\
        &= \frac{1}{2} \Big( d(x_{i+1}, x_{j+1})^2 - d(x_{i+1}, x_1)^2 \\
        &- d(x_{j+1}, x_1)^2 \Big),  \\
        &\stackrel{(a)}{=} \frac{1}{2} \Big( d\big(\sigma(x_{i+1}), \sigma(x_{j+1})\big)^2 - d\big(\sigma(x_{i+1}), \sigma(x_1)\big)^2 \\
        &- d\big(\sigma(x_{j+1}),\sigma( x_1)\big)^2 \Big) ,\\
        &= z_{i+1} \cdot z_{j+1} = (Z^\top Z)_{i,j}.
    \end{aligned}
\end{equation*}
Equality $(a)$ holds since $\sigma$ is an isometry on $S$.

\smallbreak
By \cite[Theorem 3.7.11]{horn_matrix_2012}, there exists an orthogonal $n\times n$ matrix $Q$ such that $Z=Q Y$, and we obtain for all $i \in[m]$ that $\sigma(x_{i}) = Q (x_{i} - x_1) +  \sigma(x_1)$ (the case $i=1$ holds trivially). 
Rewriting $t =  \sigma(x_1) - Q x_1 $ gives the desired result.

\end{proof}

Note moreover that the Euclidean group $E(n)$, i.e., the group of isometries in Euclidean space,  is exactly the semi-direct product of the orthogonal group $O(n)$ extended by the translational group $T(n).$ In other words, Lemma~\ref{lem:isometry_rigid_transformation} ensures that all self-isometries $\sigma_S: S \mapsto S$ on a finite subset $S \in \mathbb{R}^n$ can be extended to a full-fledged isometry $\sigma:\mathbb{R}^n \mapsto \mathbb{R}^n.$ 





\section{Pseudo-metric and Metric Identification}\label{sec:metric_id}

In this section, we expand on the discussion in Section~\ref{sec:discu} regarding the extension of our framework to perfect clones.

Let $(E,d)$ be a pseudo-metric space, that is an ordered pair where $E$ is a set and $d: E\times E \mapsto \mathbb{R}_{\geq0}$ is a pseudo-metric on $E$ satisfying, for all $x,y,z \in E$, i.e.,
\begin{enumerate}
    \item (\emph{Non-negativity}) $d(x,y) \geq 0$ ,
    \item (\emph{Symmetry}) $d(x,y) = d(y,x)$,
    \item (\emph{Triangle inequality}) $d(x,z) \leq d(x,y) + d(y,z)$ ;
    \item (\emph{Identity}) $d(x,x) =0 .$ 
\end{enumerate}

We next show that the pseudo-metric $d$ implicitly defines an equivalence relation $\sim$ on $E$, which we refer to as the \emph{metric identification.} We denote by $[x] = \{ y \in E \mid x\sim y\}$ the equivalence class of $x$ in $E.$

\begin{lemma}[Metric Identification in $(E,d)$]\label{lem:equiv_rel_E}
The binary relation defined for all $x,y \in E$ by $x\sim y$ if and only if $d(x,y) =0$ is an equivalence relation.
Moreover, for all $x\sim y$ and $z$ in $E$, we have $d(x,z) = d(y,z).$
\end{lemma}
\begin{proof}
The symmetry and reflexivity of $\sim$ are directly implied by the symmetry and the identity of the pseudo-metric $d$; there only remains to verify that $\sim$ is transitive.

\smallbreak
Let $x,y$ be elements of $E$ such that $x \sim y$, i.e., $d(x,y)= d(y,x) =0$, and let $z$ be in $E.$
By triangle inequality, we have on one hand $d(x,z) \leq d(x,y) + d(y,z) = d(y,z).$ 
On the other hand, we also have $d(y,z) \leq d(y,x) + d(x,z) = d(x,z)$, hence we indeed get $d(x,z) = d(y,z).$ 

\smallbreak
Applying this to $z \in E$ such that $y\sim z$ finally implies $d(x,z) =0$, i.e., $x\sim z$, and we verify that $\sim$ is transitive.
\end{proof}



We next consider the \emph{quotient space} of $E$ by the equivalence relation $\sim$, that is the set $E^* = E / {\mathrel{\sim}}$ of all equivalence classes induced by $\sim$ on $E.$ We may now define the metric $d^* : ([x], [y]) \in E^*\times E^* \mapsto d(x,y) $, and refer to the metric space $(E^*,d^*)$ as the metric space induced by the pseudo-metric space $(E,d).$

For a finite subset $X \subseteq E$, we similarly define the quotient $X^* = X / {\mathrel{\sim}} =  \{ [x] \mid x\in X \}$, and define $\mathcal{P}(E)^*$ to be the set containing all sets $X^*$ , i.e., $\mathcal{P}(E)^* = \{ X / {\mathrel{\sim}} \mid X \in \mathcal{P}(E) \}.$
We may then equip $\mathcal{P}(E)^*$ with the Hausdorff metric $d_H^*$ associated to the metric $d^*.$

\smallbreak
For representation functions $f$ operating on a pseudo-metric space $(E,d)$, we adapt our requirement and demand that Axiom~\ref{axi:indiv_cont} is respected after we collapse all perfect clones. This intuition is formalized as follows.


\begin{axiom}[Individual Continuity for Pseudo-metric Spaces] \label{axi:indiv_cont_pseudo}
There exists a representation function $f^*$ of $(E^*,d^*)$ verifying Axiom~\ref{axi:indiv_cont} that is equal to $f$ after collapsing perfect clones, i.e., it holds for all $X \in \mathcal{P}(E)$ and $x \in X$ that $f^*(X^*)([x]) = \sum_{x' \in [x] \cap X} f(X)(x').$
\end{axiom}



In other words, Axiom~\ref{axi:indiv_cont_pseudo} demands the following: for a finite subset $X\in \mathcal{P}(E)$ and a positive $\epsilon$, there exists $\delta>0$ such that, for all finite subset $Y\in \mathcal{P}(E)$ verifying
$\vert Y^* \vert = \vert X^* \vert$ 
%$\vert Y / {\mathrel{\sim}} \vert = \vert X / {\mathrel{\sim}} \vert$
and $d_H(X,Y) \leq \delta$, it holds that 
$$\max_{x\in X} \Bigg\vert \sum_{x' \in [x] \cap X} f(X)(x') - \sum_{y \in \pi^{-1}([x]) \cap Y} f(Y)(y) \Bigg\vert \leq \epsilon ,$$
where $\pi = \restr{\pi_{X^*}}{Y^*}$ denotes the canonical projection on $X^*$ restricted to $Y^*.$








\end{document}
