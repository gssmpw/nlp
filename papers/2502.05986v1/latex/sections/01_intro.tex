\section{Introduction}
\label{sec:intro}

Recently there has been a growing interest in leveraging large language models (LLMs) to solve complex multi-agent tasks \cite{guo2024largelanguagemodelbased,tran2025multiagentcollaborationmechanismssurvey}, such as improving factuality and reasoning, \cite{du2023improvingfactualityreasoninglanguage, liang-etal-2024-encouraging} simulating software development teams \cite{hong2024metagpt, qian-etal-2024-chatdev, liu2024a}, and human interactions \cite{10.1145/3586183.3606763}. A key requirement for succeeding at such cooperative tasks is the agent's ability to communicate effectively.

\begin{figure}[t]
\centering
  \includegraphics[width=\columnwidth]{latex/figures/agent_monitoring_intro_v2.pdf}
  \caption{\textbf{An overview of our approach}. We propose to improve multi-agent collaboration by monitoring agent communication and applying interventions to the environment in case rogue agents are detected.}
  \label{fig:intro}
\end{figure}

However, establishing effective communication is a major challenge for current LLMs, which often ignore critical information in the communication \cite{liu-etal-2024-lost, levy-etal-2024-task}, become distracted by irrelevant messages \cite{shi2023large, amayuelas-etal-2024-multiagent}, and introduce hallucinations \cite{xiao-wang-2021-hallucination, zhang2023sirenssongaiocean, jiang2024surveylargelanguagemodel, lin2024maoframeworkprocessmodel, Huang_2025}.
Such failures introduce noise to the  communication, which can be amplified as LLM responses are generated for many steps \cite{zhang2024how, ivgi2024from, yoran-etal-2024-assistantbench, jimenez2024swebench}. Consequently, a single agent can cause an entire system failure.

To improve multi-agent collaboration, recent works have proposed introducing changes to the communication protocol \cite{guo2024embodiedllmagentslearn, mehta-etal-2024-improving}, augmenting the communication with agent beliefs \cite{li-etal-2023-theory}, and adding specific modules for reasoning and grounding \cite{agashe2023evaluating, hong2024metagpt}.
While these approaches often yield improvements in the overall task performance, they do not prevent cases where one \textit{rogue agent} introduces noise to the communication and drags the system into failure \cite{darcy2024margmultiagentreviewgeneration, hong2024metagpt}.


In this work, we propose to improve multi-agent collaboration through live monitoring and interventions in agent communication. Specifically, we hypothesize that many failures can be detected and prevented early on --- before the agent becomes non-functional and the task fails --- based on the state of the agent and how it observes the environment (see Fig.~\ref{fig:intro} for an illustration). 
This approach is widely used in industrial systems, such as intrusion detection software and critical manufacturing processes \cite{STAVROPOULOS2013421, 10.1145/3411763.3451774, manpaper, Woods02092023, cyber}, and is also observed in natural systems such as the human immune system, which monitors faulty behavior and prevents infections from spreading throughout the body. 


To test this hypothesis, we present a monitor and intervention framework (\S\ref{sec:method}). To monitor an agent's state, we employ simple classifiers that detect rogue agents based on intrinsic signals of uncertainty, such as the prediction's entropy during action selection. This monitor then triggers an intervention mechanism, which prevents the communication from being distorted and the agents from failing at the task. 
Specifically, we experiment with simple interventions of restarting certain parts of the communication or the entire environment.

To evaluate our approach, we create a modular collaborative environment, called \ourenv{}, which allows analyzing different agent communication protocols at varying task-complexity levels (\S\ref{sec:env}). \ourenv{} is inspired by the well-known game of \emph{Guess Who},\footnote{\url{https://en.wikipedia.org/wiki/Guess_Who}} where players (here agents) collaborate to identify a culprit among a group of suspects based on their appearance properties.

Next (\S\ref{sec:experimental_setting}), we conduct experiments with \llama{} \cite{grattafiori2024llama3herdmodels}, \qwen{} \cite{qwen2025qwen25technicalreport}, and \gpt{} \cite{openai2024gpt4technicalreport} on two variants of \ourenv{} and the \govsim{} environment \cite{piatti2024cooperate}, where agents should consume resources in a cooperative and sustainable manner. Notably, these environments cover symmetric and asymmetric agents, structured and free-form communication protocols, and varying levels of task complexities.
Our results (\S\ref{sec:results}) show that, across all settings, monitoring rogue agents leads to substantial improvements in multi-agent collaboration. Specifically, we observe gains of up to 20\%.
Finally, we conduct ablations and qualitative analysis (\S\ref{sec:analysis}), showing that strong monitors and interventions are needed to improve performance, and that our monitors are effective at identifying a range of \emph{rogue} agents, including when agents hallucinate information in the communication channel.


To summarize, our work makes the following contributions: (a) we propose the notion of live monitoring and interventions to prevent failures due to rogue agents in multi-agent systems, (b) we introduce \ourenv{}, a modular environment for studying collaborative multi-agent systems where agents are either symmetrical/asymmetrical, (c) we show that our approach leads to substantial performance gains on \ourenv{} and \govsim{} across models and complexity levels, and (d) we show that improvements are due to strong monitors and interventions.






