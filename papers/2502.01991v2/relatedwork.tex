\section{Related Works}
% The rise of social media has drastically transformed public discourse, particularly on contentious topics \cite{barbera2024distract,islam2023weakly,islam2023analysis,islam2022understanding,puri2020social,ahmed2019framing,bode2018participation,mundt2018scaling,sharma2017analyzing,smith2013role}, by providing a platform that can both inform \cite{brynielsson2018informing,bhanot2012use,chou2009social} and mislead \cite{rocha2021impact,treen2020online,wu2019misinformation,moravec2018fake} on a massive scale. This transformation has been vividly illustrated during the COVID-19 pandemic, which sparked a global infodemic \cite{tagliabue2020pandemic}. \citet{ferrara2020characterizing} studied the narratives fueled with conspiracy theories and COVID-19 misinformation on the global news sentiment, on hate speech and social bot interference, and on multimodal Chinese propaganda. \citet{wang2023understanding} developed a codebook to characterize the various types of COVID-19 misinformation images related to the virus, from false medical advice to conspiracy theories and analyzed how COVID-19 misinformation images are used on social media.

% Social media platforms have become battlefields where moral perspectives clash, underscoring the necessity for a nuanced analysis of how moral beliefs shape public opinion and individual positions in vaccine debates \cite{beiro2023moral, weinzierl2022hesitancy, islam2022understanding, rossen2019accepters, amin2017association}. MFT \cite{haidt2007morality,haidt2004intuitive} suggests a theoretical framework for analyzing the moral perspective, containing six basic moral foundations (Table \ref{tab:moral_foundations}). \citet{weinzierl2022hesitancy} identified vaccine hesitancy profiles in COVID-19 discussions by analyzing the  underlying MFs. \citet{islam2022understanding} analyzed COVID-19 vaccine campaigns on Facebook by predicting MF and themes. \citet{beiro2023moral} employed the MFT to assess the moral narratives around vaccination debate on Facebook.
% %

% Recently, \citet{roy2021identifying} introduced a framework for analyzing moral sentiment called morality frames building on and extending MFT. \citet{pacheco2022holistic} adapted this morality frame formalism that identifies moral roles associated with moral foundation expressions in the text. 
% \citet{pacheco2022holistic,roy2021identifying} used annotated data to train a relational classifier using a declarative framework for specifying deep relational models called DRaiL \cite{pacheco-goldwasser-2021-modeling}. One limitation of these works is their dependency on labeled datasets annotated by humans. 
% In contrast, we rely on LLMs inference to generate labels and explanations for morality frames in this paper.

% Recent studies show that LLMs can perform tasks with just a few examples in-context \cite{chowdhery2023palm,le2022bloom,kojima2022large,brown2020language}. A variety of prior work has
% explored task instructions as a part of few-shot prompt \cite{mishra2022cross} and can benefit from explicitly decomposing problems into multiple steps \cite{mishra2022reframing}. Other recent work has shown that LLMs can benefit from examples that decompose the reasoning process (can be seen as an explanation) leading to an answer \cite{wei2022chain}. \citet{lampinen2022can} provided explanations after the answer in the prompt for few-shot settings. 


% In recent times, researchers have been exploring assistive possibilities of LLMs in several tasks \cite{kolla2024llm,lin2024rambler,xu2024jamplate,kim2024exploring}. \citet{kolla2024llm} examined the feasibility of using LLMs for online moderation, i.e.,
% identifying rule violations on Reddit. \citet{lin2024rambler} proposed LLM-assisted macro revisions. However, researchers have evaluated the performance of LLMs as annotators in various NLP tasks \cite{ding2023gpt,wang2021want}. \citet{mei2024wavcaps} have demonstrated that LLMs can serve effectively as an assistive tool for annotation tasks. \citet{gilardi2023chatgpt,huang2023chatgpt} have investigated LLM's ability to independently perform annotations, showcasing its potential to enhance both the efficiency and accuracy of these processes. 

% In contrast to previous works, our work explores the few-shot prompting with explanations capacity of LLMs to assist annotators in complex psycholinguistic tasks, specifically within the context of identifying morality frames in vaccination debates on social media. Utilizing a two-step method, we first generate labels and explanations via few-shot prompting with LLMs, followed by a human evaluation phase that includes a "think-aloud" tool to provide judgments and collect feedback. 

% Our study explores the integration of LLMs into the human annotation process, focusing on the identification of morality frames within the context of the COVID-19 vaccine debate on social media. We propose a collaborative framework that combines the strengths of AI-generated outputs (including explanations) with human expertise, creating a more efficient and reliable annotation process. 

The rise of social media has drastically transformed public discourse, particularly on contentious topics \cite{barbera2024distract,islam2024post,islam2023weakly,islam2023analysis,islam2022understanding,puri2020social,mundt2018scaling,sharma2017analyzing,smith2013role}, by providing a platform that can both inform \cite{brynielsson2018informing,bhanot2012use,chou2009social} and mislead \cite{rocha2021impact,treen2020online,wu2019misinformation,moravec2018fake} on a massive scale. This transformation has been vividly illustrated during the COVID-19 pandemic, which sparked a global infodemic \cite{tagliabue2020pandemic}. \citet{ferrara2020characterizing} studied the narratives fueled with conspiracy theories and COVID-19 misinformation on the global news sentiment, on hate speech and social bot interference, and on multimodal Chinese propaganda. \citet{wang2023understanding} developed a codebook to characterize the various types of COVID-19 misinformation images related to the virus, from false medical advice to conspiracy theories and analyzed how COVID-19 misinformation images are used on social media.

Social media platforms have become battlefields where moral perspectives clash, underscoring the necessity for a nuanced analysis of how moral beliefs shape public opinion and individual positions in vaccine debates \cite{beiro2023moral, weinzierl2022hesitancy, islam2022understanding, rossen2019accepters, amin2017association}. MFT \cite{haidt2007morality,haidt2004intuitive} suggests a theoretical framework for analyzing the moral perspective, containing six basic moral foundations (Table \ref{tab:moral_foundations}). \citet{weinzierl2022hesitancy} identified vaccine hesitancy profiles in COVID-19 discussions by analyzing the  underlying MFs. \citet{islam2022understanding} analyzed COVID-19 vaccine campaigns on Facebook by predicting MF and themes. \citet{beiro2023moral} employed the MFT to assess the moral narratives around vaccination debate on Facebook.
%

Recently, \citet{roy2021identifying} introduced a framework for analyzing moral sentiment called morality frames building on and extending MFT. \citet{pacheco2022holistic} adapted this morality frame formalism that identifies moral roles associated with moral foundation expressions in the text. 
\citet{pacheco2022holistic,roy2021identifying} used annotated data to train a relational classifier using a declarative framework for specifying deep relational models called DRaiL \cite{pacheco-goldwasser-2021-modeling}. One limitation of these works is their dependency on labeled datasets annotated by humans. 
In contrast, we rely on LLMs inference to generate labels and explanations for morality frames in this paper.

Recent studies show that LLMs can perform tasks with just a few examples in-context \cite{chowdhery2023palm,le2022bloom,kojima2022large,brown2020language}. A variety of prior work has
explored task instructions as a part of few-shot prompt \cite{mishra2022cross} and can benefit from explicitly decomposing problems into multiple steps \cite{mishra2022reframing}. Other recent work has shown that LLMs can benefit from examples that decompose the reasoning process (can be seen as an explanation) leading to an answer \cite{wei2022chain}. \citet{lampinen2022can} provided explanations after the answer in the prompt for few-shot settings. 


In recent times, researchers have been exploring assistive possibilities of LLMs in several tasks \cite{kolla2024llm,lin2024rambler,xu2024jamplate,kim2024exploring}. \citet{kolla2024llm} examined the feasibility of using LLMs for online moderation, i.e.,
identifying rule violations on Reddit. \citet{lin2024rambler} proposed LLM-assisted macro revisions. However, researchers have evaluated the performance of LLMs as annotators in various NLP tasks \cite{ding2023gpt,wang2021want}. \citet{mei2024wavcaps} have demonstrated that LLMs can serve effectively as an assistive tool for annotation tasks. \citet{gilardi2023chatgpt,huang2023chatgpt} have investigated LLM's ability to independently perform annotations, showcasing its potential to enhance both the efficiency and accuracy of these processes. 

In contrast to previous works, our work explores the few-shot prompting with explanations capacity of LLMs to assist annotators in complex psycholinguistic tasks, specifically within the context of identifying morality frames in vaccination debates on social media. Utilizing a two-step method, we first generate labels and explanations via few-shot prompting with LLMs, followed by a human evaluation phase that includes a "think-aloud" tool to provide judgments and collect feedback. 

% Our study explores the integration of LLMs into the human annotation process, focusing on the identification of morality frames within the context of the COVID-19 vaccine debate on social media. We propose a collaborative framework that combines the strengths of AI-generated outputs (including explanations) with human expertise, creating a more efficient and reliable annotation process. 
% \begin{figure*}
% \centering
% \begin{subfigure}{1\textwidth}
%   \centering
%   \includegraphics[width=\textwidth]{mturk_task.png}
%   \caption{Task interface in general.}
%   \label{tsk}
% \end{subfigure}
% \begin{subfigure}{1\textwidth}
%   \centering
%   \includegraphics[width=\textwidth]{correct_task.png}
%   \caption{Task interface (annotators agree with LLMs generated moral foundation and role).}
%   \label{cor_tsk}
% \end{subfigure}
% \begin{subfigure}{1\textwidth}
%   \centering
%   \includegraphics[width=\textwidth]{wrong_task.png}
%   \caption{Task interface (error in moral foundation and role).}
%   \label{wrg_tsk}
% \end{subfigure}
% \caption{Task interface for assessing LLMs generated morality frames. }
% \label{task_mturk}
% \end{figure*}
%