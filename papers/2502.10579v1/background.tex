% \vspace{-0.1in}
\section{Background}

An evolving graph consists of a series of snapshots $G_0$, $G_1$ $\cdots$ $G_n$ of a graph captured over time. 
In evolving graph analytics, we are interested in solving a query over a specific time window during which the graph is evolving. Multiple snapshots of the graph at different points in time during the time window are available, and solving a query over a time window requires computing its results for all the snapshots within that window. Evolving graph analytics is motivated by a user's need to observe trends in a graph property. A naive approach for evaluating a query over all snapshots, shown in Figure~\ref{fig:evolving_approaches}(a), simply evaluates a query from scratch on each snapshot. To overcome  the obvious inefficiency of this approach, the following \emph{incremental approaches} have been proposed: the KickStarter-based  streaming approach; and the Common Graph deletion-free approach.

% \vspace{-0.1in}
\subsection{KickStarter-based Incremental Approach}

Without loss in generality, we assume that all vertices are present in all snapshots and the changes from one snapshot to the next are represented in the form of additions and deletions of the edges applied to an earlier snapshot that produces the next snapshot. The batches of edges, including additions and deletions, are denoted as $\delta_1, \delta_2 \cdots \delta_n$ in Figure~\ref{fig:evolving_approaches}(b). The KickStarter-based~\cite{kickstarter} incremental approach evaluates the query of the first snapshot $G_0$ from scratch and then incrementally processes $\delta_1$ through $\delta_n$ in turn to obtain query results for $G_1$ through $G_n$ as shown in Figure~\ref{fig:evolving_approaches}(b).

\begin{figure}[!h]
    %\vspace{0.05in}
    \centering
    \includegraphics[width=0.8\columnwidth]{diagrams/naive_technique.pdf}

    \vspace{0.05in}
    (a) \textsf{Naive Technique}: Full Computation (\textbf{Full}) on each snapshot of the graph ($G_0$, $G_1$, ..., $G_n$) and independently calculate the results for each snapshot from scratch.
    \vspace{0.15in}
    
    \includegraphics[width=0.7\columnwidth]{diagrams/incremental_technique.pdf}

    \vspace{0.05in}
    (b) \textsf{Kickstarter-based Incremental}: Full Computation (\textbf{Full}) on the first snapshot of the graph ($G_0$), and Incrementally (\textbf{Inc}) apply the delta batches ($\delta_1$, $\delta_2$, ..., $\delta_n$) to find the results for each snapshot in ($G_0 \rightarrow G_1 \rightarrow \cdots G_n$).
    \vspace{0.1in}

    \includegraphics[width=0.6\columnwidth]{diagrams/commongraph_technique.pdf}

    \vspace{0.05in}
    (c) \textsf{Deletion-Free Common Graph}: Full Computation (\textbf{Full}) on the Common Graph and Incrementally (\textbf{Inc}) add the delta batches ($\Delta_0$, $\Delta_1$, ..., $\Delta_n$) to the Common Graph to find the results for each snapshot of the graph ($G_0$, $G_1$, ..., $G_n$).
    \vspace{-0.05in}
    
    \caption{Strategies for Evolving Graph Query Evaluation.}
    \label{fig:evolving_approaches}
    \vspace{-0.25in}
\end{figure}

% \vspace{-0.1in}
\subsection{The Common Graph Deletion-Free Approach}
While the KickStarter-based approach avoids redundant computation in the naive approach, it still needs to pay the high cost of evaluation associated with processing edge deletions. Past work on JetStream~\cite{jetstream} has shown that incremental processing for an edge deletion operation is significantly more expensive than the edge addition operation for monotonic graph queries. Therefore, the Common Graph approach was recently proposed to avoid both redundant computation and expensive handling of deletions (see Figure~\ref{fig:evolving_approaches}(c)). Common Graph is the subgraph that is shared by all the snapshots under consideration. Therefore, solving the query on it, and then streaming different batches of edge additions enables incrementally computing the query on each snapshot without having to explicitly deal with edge deletions. 

\emph{Common Graph} is the subgraph that is common to all snapshots of the evolving graph. Therefore, each snapshot can be obtained by simply adding an appropriate subset of edges to the Common Graph, that is, no edge deletions are required to convert the Common Graph to any snapshot. After computing the query on this Common Graph, by adding the missing edges for a snapshot and incrementally updating the query results in response to the additions, the query results for the snapshot are obtained. This is called the \emph{direct hop} approach. %If multiple snapshots require many common edges to be added to obtain them from the Common Graph, then we can also carry out the additions in stages to share incremental subcomputations among subsets of snapshots. This approach is called the \emph{work sharing} approach.

Figure~\ref{fig:commongraph} shows the Common Graph $G_{C}$ for three snapshots $G_i$, $G_{i+1}$, and $G_{i+2}$. We add $\Delta_{+}^{i}$ and remove $\Delta_{-}^{i}$ edges to incrementally derive $G_{i+1}$ from $G_i$. Similarly, we can derive $G_{i+2}$ from $G_{i+1}$ by respectively adding and deleting the delta batches of edges. The \emph{Common Graph} for the three snapshots, $G_{C}$, is also shown. \emph{Direct hop} approach adds different subsets of edges to the Common Graph to derive the three snapshots as shown in the figure.  For example, to derive $G_i$ we should combine three batches of edges ($\Delta_{-}^{i}$, $\Delta_{-}^{i+1}$, and $\Delta_{-}^{i+2}$) and apply them once to $G_{C}$. The main strength of the \emph{direct hop} workflow is that we can add all the addition delta batches independently and find all the snapshots in parallel. The main limitation of the \emph{direct hop} is the redundant addition operations. For example, to derive $G_i$ and $G_{i+1}$ we must add $\Delta_{-}^{i+1}$ and $\Delta_{-}^{i+2}$ twice to $G_C$. Therefore \emph{work sharing} was proposed to further reduce redundant additions. 

\iffalse
\begin{figure}[!t]
%\vspace{-0.2in}
    \centering
    \includegraphics[width=0.8\columnwidth]{diagrams/Time_Increase_with_Size.pdf}
    \vspace{-0.15in}
    \caption{Incremental SSSP execution time for a RMAT graph with increasing size on a 75K batch of edge additions.}
    \label{fig:incremental_time}
\vspace{-0.15in}
\end{figure}
\fi

Though Common Graph provides significant speedups over KickStarter-based method~\cite{CommonGraph}, its scalability is limited. 
%To illustrate this effect, we use an RMAT~\cite{rmat,pa_rmat} graph with parameters (a=0.57, b=0.19, c=0.19, d=0.05) which yields a power-law graph. Our RMAT graph contains 5 million vertices and comes in four different versions, with the number of edges equalling 12.5, 25, 50, and 100 million. Our goal is to examine the time required for the incremental processing of edge additions as we increase the size of the graph. We used a batch of 75K additions for this experiment and conducted it on RisGraph~\cite{risgraph} using the Single Source Shortest Path algorithm. As shown in the Figure~\ref{fig:incremental_time}, the time required for incremental additions increases as the size of the RMAT graph expands. 
Therefore, we argue that to further optimize performance, it is essential to \textbf{eliminate wasteful work on analyzing UVV vertices and traversing incoming edges of UVV vertices in the Common Graph}. In subsequent sections, we demonstrate how to identify UVVs and exploit them to improve scalability. 





\iffalse
\begin{figure}[!t]
    \centering
    \includegraphics[width=0.8
    \columnwidth]{diagrams/Normalized.pdf}
    \caption{Showing the normalized number of edge additions and edge deletions for the \emph{streaming}, \emph{direct hop}, and \emph{work sharing} scenarios applied to the TTW graph.}
    \label{fig:addition_number}
    \vspace{-0.15in}
\end{figure}
\fi

\begin{figure}[!t]
%\vspace{0.1in}
    \centering
    \includegraphics[width=0.9\linewidth]{diagrams/commongraph.pdf}
    \vspace{-0.15in}
    \caption{Common Graph $G_{C}$ of snapshots $G_i$, $G_{i+1}$, $G_{i+2}$.}
    \label{fig:commongraph}
    \vspace{-0.1in}
\end{figure}