% \vspace{-0.15in}
\section{Introduction}
% \vspace{-0.05in}

Graph analytics are employed in many domains to uncover insights from connected data. There has been much work resulting in scalable graph analytics systems for GPUs, multicore servers, and  clusters~\cite{pregel, graphlab, powergraph, galois, ligra, coral, gridgraph, graphchi, cusha, cusha2, tigr, gunrock, pingali, saday}. Most real-world graphs change dynamically over time~\cite{sakr-21}. Therefore, recently there has been a great deal of interest in analytics over changing graphs~\cite{kickstarter,graphbolt,risgraph,CommonGraph,tegra,evog-taco,chronos}. Efficient dynamic graph processing has diverse applications, including social network analysis for community detection and influence propagation~\cite{aggarwal2014, giatsidis2011d}, personalized recommendation systems~\cite{amatriain2015recommender, koren2009matrix}, and telecommunication networks for traffic management and fault detection~\cite{nguyen2018survey, li2017survey}. It is also crucial in financial networks for fraud detection and risk assessment~\cite{akoglu2015graph, kumar2016edge}, biological networks like gene regulatory networks~\cite{liu2018dynamic, zhang2012inferring}, and transportation networks for traffic flow optimization~\cite{wang2016dynamic, zheng2013u}. In e-commerce, it aids in customer interaction analysis and supply chain management~\cite{yan2017survey, ngai2012information}, while in cybersecurity, it enhances intrusion detection and network defense~\cite{ahmed2016survey, garcia2014empirical}. Additionally, smart cities benefit from urban planning and resource management applications~\cite{batty2012smart, neirotti2014current}, and healthcare uses include epidemic tracking and patient monitoring~\cite{he2016dynamic, rumsfeld2016big}. These applications underscore the importance of dynamic graph processing.

%Recent approaches to analyzing evolving graphs employ incremental techniques to optimize computation. Let $G_i$ and $G_{i+1}$ represent two versions (snapshots) of an evolving graph such that $G_{i+1}$ is obtained by applying a batch of updates in form of edge additions and deletions to $G_i$. Given query solution on graph $G_i$, incremental techniques are used in \cite{kickstarter,graphbolt,risgraph,tegra} to efficiently compute query results for $G_{i+1}$. Incremental techniques are motivated by the observation that there is a significant overlap between one version of the graph ($G_i$) and its subsequent updated version ($G_{i+1}$). Thus, instead of performing query evaluation on both versions from scratch, incremental algorithms are employed -- given the results of a query on $G_i$, an incremental algorithm updates these results to obtain the results of the same query on $G_{i+1}$. A general incremental algorithm that supports both edge additions and deletions was first proposed in KickStarter~\cite{kickstarter} and then further extended and optimized by Graphbolt~\cite{graphbolt} and RisGraph~\cite{risgraph} respectively.

As a graph continues to evolve, a sequence of snapshots is captured which grows in length over time. An \emph{evolving graph query} is aimed at analyzing the evolution of a graph property (e.g., shortest paths) over a time window. That is, an evolving graph query typically requires a graph query to be solved over a sequence of snapshots $G_0, G_{1}, \ldots, G_{n}$. By selecting the time window, the user requests query evaluation for all snapshots within a time window to observe trends in query results (e.g., changes in shortest paths). As the duration of the time window for query evaluation increases, so do the number of snapshots that must be analyzed and hence the cost of query evaluation rises. Thus, efficiently evaluating a query over many snapshots is an important open problem.

\vspace{0.05in}
\noindent
\textbf{Existing Approaches.~} To reduce the high cost of query evaluation over a large number of snapshots, existing approaches such as Tegra~\cite{tegra} and CommonGraph~\cite{CommonGraph} leverage incremental algorithms. A general incremental algorithm that supports both edge additions and deletions was first proposed in KickStarter~\cite{kickstarter} and then further extended and optimized by Graphbolt~\cite{graphbolt} and RisGraph~\cite{risgraph} respectively. While both Tegra and CommonGraph employ incremental algorithms, there is a major difference. Tegra explicitly processes both additions and deletions using incremental algorithms developed in KickStarter~\cite{kickstarter} and Graphbolt~\cite{graphbolt}. In contrast, CommonGraph~\cite{CommonGraph} converts edge deletions between snapshots into edge additions between a common graph and each snapshot, thus trading expensive deletions processing for relatively inexpensive additions processing. The common graph is first used to evaluate a query. Starting from the common graph and query results computed for it, edge additions are processed to incrementally compute query results for each snapshot. 

%Despite the above recent advances, query evaluation over an evolving graph remains expensive due to the large irregular graph over which evaluations are carried out. Iterative evaluation over large graphs incurs significant overhead due to the movement of the graph data across the memory hierarchy. This overhead is exacerbated by the iterative nature of graph analytics. Thus, in spite of advances due to incremental algorithms, efficient processing of large and irregular graphs remains a major challenge for evolving graph analytics.

%We carried out a study that shows that due to the gradually changing nature of evolving graphs, when a vertex-specific query (e.g., SSSP) is evaluated over a sequence of \textcolor{red}{25 to 100} snapshots, for \textcolor{red}{over 50\% to 90\% of vertices} the query results remain unchanged across all snapshots. 

\vspace{0.05in}
\noindent
\textbf{Our Insight: UVVs.~} We develop a new insight and a novel algorithm to take advantage of the insight to substantially optimize query evaluation across multiple snapshots. 

Our key insight originates from the gradually changing nature of an evolving graph. From the results of a study presented in Figure~\ref{motivation1}, we observe that, \textbf{given a vertex-specific query (e.g., SSSP), the query results for 53.2\% to 99.8\% of vertices remain unchanged across  25 to 100 consecutive snapshots.} Therefore the \emph{unchanged vertex values} (UVVs) can be computed once, and then minimal analysis can be performed for each snapshot to obtain the results for the remaining vertices in that snapshot. Moreover, the incremental computation can be performed over a much \emph{smaller graph} obtained by eliminating the incoming edges of all vertices with unchanged values -- since no updates need to be applied to their values, the incoming edges play no role in the incremental computation for any snapshot.

 
\begin{figure}[!t]
    \centering
    \includegraphics[width=0.9\linewidth]{diagrams/data2.pdf}
    \vspace{-0.175in}
    \caption{Given series of 100 snapshots obtained by performing 100K edge updates (50\% deletions and 50\% additions) from one snapshot to the next, the above plot gives the percentage of vertex property values that remain unchanged across 25, 50, 75, and 100 snapshots for 4 input graphs and 5 benchmarks. 100K edges represent between 0.14\% of edges in LJ to 0.025\% for Wen.}
    \label{motivation1}
    \vspace{-0.175in}
\end{figure}

\vspace{0.05in}
\noindent
\textbf{Our Solution.~}
To take advantage of the above insight, and resulting opportunities for optimizing evaluation of an evolving graph query, we need to address the following key challenge. Given a vertex-specific query $Q$ and a sequence of snapshots, we must \textbf{identify vertices with unchanged vertex values} (UVVs). To address this challenge, we develop a novel \textbf{intersection-union analysis} to compute lower and upper bounds of a vertex value across all snapshots. When the bounds are found to be equal, we can \textbf{safely} conclude that the vertex value found remains the same across all the provided snapshots. Therefore, the rest of our query evaluation is limited to computing values across snapshots for vertices whose bounds were not equal. Our approach is applicable to path-based monotonic algorithms. A path-based monotonic algorithm incrementally explores or constructs paths within a graph while ensuring that the computed metric along each path (e.g., distance, cost) adheres to a monotonic property, such as non-increasing or non-decreasing values. As the algorithm progresses, it extends partial paths in such a way that the solution's quality improves or remains constant, ensuring convergence to an optimal or sub-optimal solution without regressing to a worse state.

We further optimize evaluation of query $Q$ by \emph{concurrently} performing incremental computations for all snapshots over a significantly smaller graph that we refer to as the $Q$-Relevant SubGraph ($QRS$). The smaller graph is obtained by eliminating the incoming edges of all vertices with unchanged values.


Our experiments with several benchmarks and graphs for 64 snapshots show that we need to carry out per snapshot incremental analysis for under 42\% vertices on a graph with under 32\% of edges. When we incrementally evaluate the query on each snapshot using $QRS$, the cost of evaluation is lowered. 
Our approach delivers speedups of up to 12.23$\times$ over the state-of-the-art RisGraph implementation of the KickStarter-based incremental algorithm for 64 snapshots.

% \vspace{0.05in}
% \noindent
% \textcolor{red}{\textbf{Applications: } Evolving graphs have diverse applications across various domains, including social networks, biological systems, transportation networks, and epidemiology. In social networks, evolving graphs capture the dynamic nature of relationships and interactions between individuals, enabling insights into community structures, influence propagation, and trend prediction. In biological systems, evolving graphs model dynamic interactions between molecules, genes, or proteins over time, aiding in the understanding of complex biological processes such as gene regulation, protein-protein interactions, and disease pathways.  Moreover, evolving graphs are instrumental in modeling transportation networks, where they facilitate urban planning, traffic management, and infrastructure development by analyzing changes in network topology and traffic flow dynamics.  In epidemiology, evolving graphs derived from contact tracing data help track the spread of infectious diseases, identify high-risk individuals or communities, and inform targeted interventions such as quarantine measures and vaccination campaigns, thus contributing to disease control and public health efforts.}

% \textcolor{red}{Most of the above applications can easily fit into the UVVs application because we do not have a big change from one version to another version of the graph, so we have many unchanged values among different versions of the graph, which makes it suitable for UVVs exploration. One example of an evolving graph that changes slowly over time could be a transportation network in a city. In this evolving graph, nodes represent locations such as intersections or landmarks, and edges represent roads or transportation links between these locations. As the city evolves and develops, the transportation network also undergoes changes, albeit slowly. Initially, the transportation network may start with a simple configuration, with a few main roads connecting key areas of the city. Over time, as the city grows, new nodes (intersections) and edges (roads) may be added to the network to accommodate increased traffic flow and urban expansion. For instance, new residential areas may lead to the addition of residential streets, while commercial developments may result in the construction of new highways or arterial roads. These changes to the transportation network occur gradually and may take years or even decades to manifest fully. Therefore, it is a good application to explore using the UVVs approach.}

%we present an approach that substantially optimizes the state-of-the-art Common Graph method by replacing incremental computations over the large Common Graph \todo{should it be over a large common graph? thanks, done, rajiv} with incremental computations over a dramatically smaller subgraph of the Common Graph. Our key insight comes from the data presented in Figure~\ref{motivation1}. \textbf{Given a query Q, we observe that query results for over \textcolor{red}{50\% to 90\% of vertices remain the same across  25 to 100} snapshots. } This points to the existence of a significantly smaller subgraph of the Common Graph,  that is sufficient for incrementally computing the results of Q for all the snapshots \todo{maybe this could be elaborated more to be more intuitive?}. We refer to the smaller graph for query Q as its \textbf{Query Relevant Subgraph} or QRS for query Q. However, for a given query Q and a series of snapshots, identifying the QRS from the Common Graph is a challenge. 

%To solve the above problem we propose the novel use of all snapshots intersection and union graphs to identify lower and upper bounds on query results for each vertex across all snapshots. \textbf{When the bounds for a vertex match \todo{maybe more explicit on what "match" means here}, we can conclude that the query result for the vertex remains unchanged across all snapshots.} Therefore, incremental evaluations will not alter their values for any of the snapshots. Consequently all incoming edges of these vertices can be eliminated producing a much smaller QRS for the given query Q from the Common Graph of the snapshots under consideration. By streaming the missing edges for each snapshot into the small QRS, we can incrementally obtain the precise results for each snapshot, while reducing the cost. In addition, we simultaneously perform the incremental computations for the snapshots for further speedups. Our experiments show that the evaluation of a query using the QRG achieves speedups ranging from \textcolor{red}{a$\times$ to b$\times$} over query evaluation using the Common Graph.

\vspace{0.05in}
\noindent
The key contributions of this paper are as follows:
\begin{itemize}[leftmargin=*, topsep=1pt]
\setlength{\itemsep}{0.5pt}
\setlength{\parskip}{0.5pt}
    \item
    \textsf{\it Identifying Unchanged Vertex Values:} We 
    develop a novel \emph{intersection-union analysis} for identifying unchanged vertex values by bounding vertex values across all snapshots. 
    
    \item
    \textsf{\it Reduced Graph for Incremental Computation:} We identify a significantly smaller $Q$-Relevant Subgraph ($QRS$) over which incremental computations are performed.
    
    \item
    \textsf{\it Concurrent Incremental Evaluation for All Snapshots:} We build a system that simultaneously performs incremental computations for all snapshots further reducing the cost. 

    \item 
    \textsf{\it Experimental Evaluation:} We demonstrate our approach by applying it to evaluation of queries across 64 snapshots of five input graphs and five monotonic algorithms.  
\end{itemize}