\section{Adversarial Objects}\label{sec:method}
%
%
Given a solid reference object $\Omega \subset \mathbb{R}^3$ and its moments of mass $m_0 \in \mathbb{R}_{>0}$, $m_1 \in \mathbb{R}^3$, and $m_2 \in \mathbb{R}^{3x3}$, we optimize a material distribution (consisting of Young's modulus $Y$, Poisson's ratio $\nu$, mass density $\rho$, and material occupancy $\alpha$) to maximally change the trajectories after simulation:
%max ∫_Ω ‖ q_adv(t=1) - q_ref(t=1) ‖² dV
%subject to:
%Y(x) ∈ [Y_min, Y_max] ∀ x ∈ Ω (1)
%ν(x) ∈ [ν_min, ν_max] ∀ x ∈ Ω (2)
%ρ(x) ∈ [0,ρ_max] ∀ x ∈ Ω (3)
%ρ(x) > ρ_min ∀ x ∈ ∂Ω (4)
%∫_Ω ρ(x) dV = m₀ (5)
%∫_Ω x ρ(x) dV = m₁ (6)
%∫_Ω ((x⋅x)I - xxᵀ )ρ(x) dV = m₂ (7)
\begin{gather}
\underset{Y,\ \nu,\ \rho,\ \alpha}{\mathrm{argmax}} \quad  \int_\Omega || q_\text{adv}(t_\text{end}) -  q_\text{ref}(t_\text{end}) ||^2 dV  \label{eq:continuous} \\
\text{s.t.}\quad                    Y(x) \in [Y_\text{min}, Y_\text{max}]\quad \forall x \in \Omega  \tag{\ref{eq:continuous}a} \\
\phantom{\text{s.t.}}\quad   \nu(x) \in [\nu_\text{min}, \nu_\text{max}] \quad \forall x \in \Omega   \tag{\ref{eq:continuous}b} \\
\phantom{\text{s.t.}}\quad   \rho(x) \in [\rho_\text{min}, \rho_\text{max}] \quad \forall x \in \Omega  \tag{\ref{eq:continuous}c} \\
\phantom{\text{s.t.}}\quad   \alpha(x) \in \{0, 1\} \quad \forall x \in \Omega\strut^\mathrm{o} \tag{\ref{eq:continuous}d} \\
\phantom{\text{s.t.}}\quad   \alpha(x) = 1 \quad \forall x \in \partial \Omega  \tag{\ref{eq:continuous}e} \\
\phantom{\text{s.t.}}\quad   \int_\Omega \rho(x)\alpha(x) dV = m_0 \tag{\ref{eq:continuous}f} \\
\phantom{\text{s.t.}}\quad   \int_\Omega x \rho(x)\alpha(x) dV = m_1 \tag{\ref{eq:continuous}g} \\
\phantom{\text{s.t.}}\quad   \int_\Omega ((x \cdot x)I - xx^T) \rho(x)\alpha(x) dV = m_2, \tag{\ref{eq:continuous}h}
\end{gather}
where $q_\text{ref}$ is the simulation result of the reference object, $q_\text{adv}$ is the simulation result of the adversarial object, $q(t_\text{end})$ represents the final state of the simulation. \revision{We delegate detailed discussion the physical meaning of material parameters (e.g. \citet{materials-strength-book})}. Looking at the constraints, Eq. \ref{eq:continuous}(a-c) ensure that material parameters stay within a specified range of perceptually stiff materials. Eq. \ref{eq:continuous}(d-e) allow changing the internal geometry of the object while ensuring that the boundary of the domain remains the same (same collision geometry). And Eq. \ref{eq:continuous}(f-h) ensure that the moments of the object are the same (same behavior if reduced to RBD).
\revision{
Together, the constraints enforce our notion of ``imperceptible perturbation" to the rigid body simulator - the object is made of only highly stiff materials (such that one may reasonably choose to simulate with rigid body techniques - see Supplemental D), the object has the same external geometry to the reference (so that it experiences identical contacts), and it has identical moments of mass (meaning identical response to the reference in rigid body simulation due to the reduced degrees of freedom).
}

Typically, a rigid body simulator takes as input the boundary of the domain $\partial \Omega$ as, e.g., a triangle mesh and the moments as parameters. We choose to discretize our problem by tetrahedralizing the interior of the input mesh and treating $Y$, $\nu$, $\rho$, and $\alpha$ as per-tetrahedron quantities:
%max  ∑ᵢ Vᵢ ‖qᵢ_ref(t=1) - q_advᵢ(t=1)‖²
%subject to:
%Yᵢ ∈ [Y_min,Y_max] ∀ i
%ᵢ ∈ [ν_min,ν_max] ∀ i
%ρᵢ ∈ [0,ρ_max] ∀ i
%ρᵢ > ρ_min ∀ i ∈ ∂Ω
%Σᵢ Vᵢ ρᵢ = m₀
%Σᵢ ρᵢ ∫ᵢ x dV = m₁
%Σᵢ ρᵢ ∫ᵢ ((x⋅x) I - xxᵀ) dV = m₂
\begin{gather}
\underset{Y,\ \nu,\ \rho,\ \alpha}{\mathrm{argmax}} \quad  \sum_i V_i || q_i^\text{adv}(t_\text{end}) -  q_i^\text{ref}(t_\text{end}) ||^2  \label{eq:discrete} \\
\text{s.t.}\quad                    Y_i \in [Y_\text{min}, Y_\text{max}]\quad \forall i  \tag{\ref{eq:discrete}a} \\
\phantom{\text{s.t.}}\quad   \nu_i \in [\nu_\text{min}, \nu_\text{max}] \quad \forall i   \tag{\ref{eq:discrete}b} \\
\phantom{\text{s.t.}}\quad   \rho_i \in [\rho_\text{min}, \rho_\text{max}] \quad \forall i  \tag{\ref{eq:discrete}c} \\
\phantom{\text{s.t.}}\quad   \alpha_i \in \{0, 1\} \quad \forall i \in \Omega\strut^\mathrm{o} \tag{\ref{eq:discrete}d} \\
\phantom{\text{s.t.}}\quad   \alpha_i = 1 \quad \forall i \in \partial \Omega  \tag{\ref{eq:discrete}e} \\
\phantom{\text{s.t.}}\quad   \sum_i V_i \rho_i \alpha_i = m_0 \tag{\ref{eq:discrete}f} \\
\phantom{\text{s.t.}}\quad   \sum_i \rho_i \alpha_i \int_i x dV = m_1 \tag{\ref{eq:discrete}g} \\
\phantom{\text{s.t.}}\quad   \sum_i \rho_i \alpha_i \int_i ((x \cdot x)I - xx^T) dV = m_2, \tag{\ref{eq:discrete}h}
\end{gather}
where $i$ refers to an individual tetrahedron in $\Omega$ (now represented with a tetrahedral mesh: $V$, $T$).
\begin{figure*}[t]
 \centering
 \includegraphics[width=\linewidth]{figures/star-corner}
 \vspace{-0.7cm}
 \caption{We simulate a star colliding off of the ground and a wall in a rigid body simulator (left). From it, we construct an adversarial object (middle) that has identical surface geometries and first three moments of mass, and simulate it in a deformable simulator (middle). On the right, we show the difference in trajectories. Note that the angular difference means separation will grow over time and the effect can cascade through subsequent contacts.} 
 \label{fig:base-example}
\end{figure*}

\subsection{Dealing with the Constraints}
While the objective function in Eq. \ref{eq:discrete} is very simple, dealing with its constraints requires some care.

\subsubsection{Material Constraints}
The box constraints from Eq. \ref{eq:discrete}(a-c) are used to ensure that the adversarial object is made up of physically reasonable, perceptually rigid materials by setting an allowable range of Young's moduli, Poisson's ratio, and density.

While the material occupancy constraint from Eq \ref{eq:discrete}(d) is a discrete value of either 0 or 1, we follow the SIMP approach of treating it as a continuous variable between $[\alpha_\text{min}, 1]$ where the optimization drives it towards those endpoints, and then snapping it to the discrete values as a postprocessing step. This allows elements ranging from fully occupied to unoccupied, while not running into the simulation errors that would arise from 0 occupancy elements \cite{Mlejnek1992SomeAO}. To satisfy the boundary occupancy constraint from Eq. \ref{eq:discrete}(e), we simply set the values of $\alpha$ corresponding to boundary elements to $1$, and reduce the $\alpha$ degrees of freedom to the interior elements.

We satisfy these constraints by parameterizing the materials with new per element variables $\theta_{\{Y, \nu, \rho, \alpha\}}$:
\begin{equation}
\label{eq:parameterization}
\begin{split}
	x &= f_\text{param}(\theta, x_\text{min}, x_\text{max}) \\ &= \frac{1}{2} \tanh\left(\theta \right)(x_\text{max} - x_\text{min}) +  \frac{1}{2}(x_\text{max} + x_\text{min}),
\end{split}
\end{equation}
where $x$ is a stand-in for a material parameter, $\theta$ is its corresponding parameterized variable, and $x_\text{min}$ and $x_\text{max}$ are its minimum and maximum value. 
Now any value of $\theta$ will correspond to a material parameter in the allowable range, and thus implicitly satisfying the constraints while using an unconstrained optimization over $\theta$ (see Fig \ref{fig:didactic-example}). 

\subsubsection{Moments of Mass Constraints}
Finding a physically plausible occupancy and mass density distribution over the object that satisfies the mass moments constraints from Eq. \ref{eq:discrete}(f-h) is straightforward, and there are likely many such distributions for given target moments given the very large number of degrees of freedom compared to the number of constraints. 

We can compute the mass moments exactly via quadrature rule, using the per element volume vector $A$, mass densities $\rho = f_\text{param}(\theta_\rho)$, and material occupancies $\alpha = f_\text{param}(\theta_\alpha)$.  Since the mass densities and material occupancies are constant per element, this ultimately means that we can construct a moments of mass operator $S(V, T) \in \mathbb{R}^{10\ \times\ |T|}$  that acts on the per element (effective) density to compute the mass moments with the quadrature rule. Each row in $S$ corresponds to a different moment. Then, the adversarial object's moments are found as a matrix-vector multiplication:
\begin{equation}
\label{eq:moment-construction}
	M_{adv} = S (\alpha \odot \rho),
\end{equation}
where $\odot$ refers to the Hadamard product (and $\alpha \odot \rho$ is the effective density). %This formulation means we only have to construct $S$ once per object. 
We choose to enforce Eq. \ref{eq:discrete}(f-h) via soft constraint.

\subsection{Final Optimization Problem}
%
\begin{figure*}[t]
	\centering
	\includegraphics[width=\linewidth]{figures/didactic}
	\vspace{-0.7cm}
	\caption{Our differentiable physics simulator allows us to construct adversarial objects using a first order optimization method.}
	\label{fig:didactic-example}
\end{figure*}
Using the parameterization scheme and soft constraint formulation for the moments of mass, we simplify the optimization problem in Eq. \ref{eq:discrete}:
\begin{equation}
\label{eq:total-cost}
\begin{split}
	 \underset{\theta_Y, \theta_\nu, \theta_\rho, \theta_\alpha}{\mathrm{argmin}} &\  -|| q_\text{adv}(t_\text{end}) - q_\text{ref}(t_\text{end}) ||_M^2\ + \\% \beta \ || M_\text{ref} - M_\text{adv} ||^2,
	 \ &\  \beta \ || M_\text{ref} - M_\text{adv} ||^2,
\end{split}
\end{equation}
which we can be solved using a standard first-order descent method - we choose ADAM \cite{adam} (see Fig \ref{fig:didactic-example}). We determine $\beta$ experimentally. 
\revision{
While the use of soft constraint means the mass moments of the adversarial object are not guaranteed to exactly match those of the reference, appropriate choice of the coefficient $\beta$ results in very low error (see Table \ref{table:moments-comparison}), such that rigid body trajectory differences will be negligible on the timescales of interest.
}

\subsection{Forward Simulation}
%
Due to the increased stability and the ability to take larger timesteps, implicit integrators are commonly used for elastodynamics simulation. We use BDF-2 due to it's superior damping performance in comparison to implicit Euler \cite{bdf2-book}.% (see \citet{bdf2-book}), which we find is especially significant through contact.

Using one of the standard techniques in simulation, we pose each dynamic step as the solution to a non-linear optimization problem where forces (including contact) are described as gradients of continuous potential energy functions (see e.g. \cite{ipc, implicit-newton}). Our hyperelastic constitutive model is the stable Neohookean energy from \citet{dynamic-deformables}, and our contact forces are from the smoothly clamped barrier energy in \citet{ipc}.
The ``energy'' in each time step is fully differentiable, but to compute the solution we may require many Newton iterations with line-search. For an explicit formulation, see Supplemental (A).

It is now clear how the material parameters are incorporated; the mass matrix $M$ must account for the densities and occupancies, and the hyperelastic strain energy $E_\Psi$ must account for the Young's modulus, Poisson's ratio, and occupancies. Following the topology optimization literature, we raise $\alpha$ to the power of 3 when it is used to scale the stiffnesses in $E_\Psi$ in order to promote occupancy sparsity \cite{topology-opt-reference}.

From the total energy of the system, we can can analytically calculate its gradient and Hessian (which we project to be positive definite), and run a Newton solve to convergence at each timestep until the end of the simulation.

\subsection{Simulation Gradients}
%While it is theoretically possible to simply use automatic differentiation to compute all of our gradients, it is incurs an enormous performance cost due differentiating through the iterative Newton solve. 
Our optimization problem is now well posed, but simply backpropagating through the nested loops over timestep and Newton iterations is untenable. 
Like much of the inverse design community, we instead leverage the Adjoint Method (summarized in \cite{mcnamara2004fluid}), which is used to differentiate through constrained optimization problems of the form:
\begin{equation}
\begin{split}
	\mathop{\text{argmin}}_\theta & \text{ } f(q, \theta) \\
	\text{s.t.} & \text{ }g(q, \theta) = 0,
\end{split}
\end{equation}
where $q$ is the state, $\theta$ is the design parameters to optimize, $f(q, \theta)$ is the cost function, $g(q,\theta)$ is the constraint. In inverse physics problems, $g$ is typically a constraint requiring that $q$ and $\theta$ are physically valid. 
Then, the gradient can be calculated as:
\begin{equation}
\label{eq:adjoint-equation}
\frac{d f}{d \theta} = \frac{\partial f}{\partial \theta} - \left(\frac{\partial f}{\partial q} \left(\frac{\partial g}{\partial q}\right)^{-1} \right) \frac{\partial g}{\partial \theta}.
\end{equation}

By using the Adjoint method to provide the derivatives for each timestep, we can avoid the massive performance hit of using auto-differentiation through Newton solves while still taking advantage of the convenience afforded by auto-differentiation frameworks \cite{gradsim}. The optimization problem from the forward simulation is implicitly in the form of the adjoint problem:
$$ q_{t+1} = argmin_q \ E(q, \theta) \ \text{ s.t. }\ G(q, \theta) = 0, $$ 
where $E$ is the minimization objective and $G$ its gradient ($\frac{\partial E}{\partial q_{t+1}}$). See Supplemental (B) for implementation details.

\subsubsection{Gradient Smoothing}
One of the limitations of nodal/element based topology optimization is the existence of the so-called non-physical ``checkerboard patterns'' where the optimized material occupancies are allocated such that patches are connected only at the element corners due to mesh/grid connectivity. One of the standard approaches to avoiding this is by using gradient smoothing, which is generally referred to in topology optimization as applying a ``filter function'' \cite{top-opt-filters}. In topology optimization, the design domain is usually discretized as a regular grid, and the filter functions are typically hat functions centered at each element. 

As we encounter irregular meshes, we instead use a more geometrically motivated mesh Laplacian based smoothing proposed by \citet{alec-blurring}. %, which both accounts for the irregular elements, but also for the fact that two points on a mesh that might be Euclideanly close may not be geodesically close due to mesh geometry.
The standard cotangent Laplacian $L$ acts on vertex valued functions while our occupancy is per element. So, we instead first construct the false barycentric subdivision of the mesh so that the original elements have corresponding vertices. We can then apply Laplacian blurring using this subdivided mesh, and use a matrix $N = [0\ I]$, to transfer per element values to the barycenter vertices. Thus, we blur a per element input $\delta$ as:
\begin{equation}
\label{eq:gradient-blurring}
	\hat{\delta} = N^T (\tilde{M} - \gamma \tilde{L})^{-1} N A\  \delta, 
\end{equation}
where $\tilde{L}$ is the subdivided mesh Laplacian, and $\tilde{M}$ a modified mass matrix for the subdivided mesh, with the barycenter vertices having an area of the original mesh elements and all other vertices having area of 0 (see Fig. \ref{fig:smooth-function}). This smoothing operator is also conservative - it will preserve the volume weighted integral of the input function.

We apply this smoothing method on the gradient of the material occupancies ($\theta_\alpha$) to avoid the aforementioned checkerboarding artifacts (see Fig. \ref{fig:topology-opt-checkerboard}). The smoothing matrix from Eq. \ref{eq:gradient-blurring} is of size $| T | \times | T|$, while the $\theta_\alpha$ is of size $| T |_\text{interior}$, so we use selection matrices to apply it. 
\begin{figure}[t]
	\includegraphics[width=\linewidth]{figures/blur-function}
	\vspace{-0.7cm}
	\caption{Our geometrically motivated smoothing operator from Eq. \ref{eq:gradient-blurring} is used to smooth an element defined function on an irregular mesh.}
	\label{fig:smooth-function}
\end{figure}

\subsection{Postprocessing}
In SIMP, raising $\alpha$ to the power of 3 will drive the occupancies towards extremes by penalizing intermediary values - the effective volume is proportional to $\alpha$ but the effective stiffness is less than proportional (see \citet{topology-opt-reference} for a derivation and in depth discussion). 
However, this is not enough to guarantee no intermediate occupancy values. Therefore, as a post-processing step after the materials are determined, we sharpen the occupancies by rounding $\alpha$ so that its elements are either 0 or 1.
We then have an optimization to ensure the mass moments constraint is still satisfied:
\begin{equation}
	\underset{\theta_\rho}{\mathrm{argmin}} \text{    } || M_\text{ref} - M_\text{adv} ||^2,
\end{equation}
which we solve by running gradient descent starting with our previously found $\theta_\rho$.
\begin{figure}[t]
	\includegraphics[width=\linewidth]{figures/cube-blur}
	\vspace{-0.7cm}
	\caption{Using our geometrically motivated smoothing operator on the material occupancy gradients of this adversarial cube, we can avoid the checkerboarding artifacts that otherwise appear.}
	\label{fig:topology-opt-checkerboard}
\end{figure}
