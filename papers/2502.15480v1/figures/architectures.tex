\begin{figure*}
    \centering
    \includegraphics[scale=1.0]{figures/images/Architecture.pdf}
    \caption{
    Overview of the neural models to compute the BRDF $f(x, l, v)$. Approaches based on a parametric model employ an MLP to predict the parameters for the respective model. A sigmoid or softplus output nonlinearity is used, depending on the range of the parameters. Methods based on a single MLP compute the BRDF value directly from the position and the view and light direction. Additive models split the reflection into a diffuse and a specular component. While the \emph{separate} architecture uses independent MLPs for both, the \emph{shared} architecture uses a common MLP with two separate heads.
    For all \emph{purely} neural approaches, the Rusinkiewicz angles \cite{rusinkiewicz1998new} are used to parametrize the directions. Moreover, we employ an intrinsic approach \cite{KoestlerIntrinsicNeuralFields22} to encode the position directly on the mesh as well as positional encoding for the angles. See \cref{sec:angleAndEncoding} for details on the angles and the encoding.
    }
    \label{fig:architectures}
\end{figure*}