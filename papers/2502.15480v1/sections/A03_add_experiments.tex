\section{Additional Experimental Results}
\label{sec:supp:add_experimental_results}

In this section, we present several additional results. \cref{sec:supp:quantitative_reciprocity} and \cref{sec:supp:arch_changes_view_light_exps} give further results and details for the experiments on the reciprocity approach and the number of layers for the directions from 
\iftoggle{arxiv}{\cref{sec:analysis_brdf_models}}{Sec.~6.2}
in the main text. In \cref{sec:supp:exps_angle_param}, we analyze the influence of the angle parametrization on the reconstruction quality. \cref{sec:supp:changes_nerfactor} justifies our changes to the NeRFactor architecture, which is the basis of our additive separate architecture.
\cref{sec:supp:failure_cases} gives insight to failure cases for the purely neural additive approaches that we observed occasionally.
While \cref{sec:supp:qualitative_diffuse_specular} presents a qualitative analysis of the diffuse and specular parts of the models based on a split of the reflectance
\cref{sec:supp:spat_var_recon_brdf} uses the albedo maps to analyze how well the models can represent the spatially uniform BRDFs of the semi-synthetic dataset.
Finally, \cref{sec:supp:additional_experiments_comp} provides additional qualitative and quantitative results for both datasets, comparing the various neural BRDF approaches.


\subsection{Quantitative Results for the Reciprocity Approaches}
\label{sec:supp:quantitative_reciprocity}

\input{tables/supp_changes_quantitative_reci}

As shown in 
\iftoggle{arxiv}{\cref{sec:analysis_brdf_models}}{Sec.~6.2}
in the main text, the random input swap of view and light direction applied during training, as described in LitNerf \cite{Sarkar23LitNerf}, can reduce the RMSE of the reciprocity constraint. However, this strategy does not provide a guarantee that the reciprocity is actually fulfilled. In contrast, our input mapping, as proposed in
\iftoggle{arxiv}{\cref{sec:reciMapping}}{Sec.~4.3},
ensures that the reciprocity constraint is exactly fulfilled by construction.
In \cref{tab:changes_quantitative_reci}, we analyze the effect of both strategies on the reconstruction quality by comparing against the results without any reciprocity strategy. Overall, we observe only a minimal difference with a minor tendency for slightly worse results as a trade-off for the fulfilled reciprocity.
One exception is the single MLP architecture, where, for the real-world examples, the random input swap seems to have a more noticeable advantage over our strategy.


\subsection{Architecture Changes Experiments: Number of Layers for View/Light Direction}
\label{sec:supp:arch_changes_view_light_exps}

In
\iftoggle{arxiv}{\cref{sec:analysis_brdf_models}}{Sec.~6.2}
in the main text, we analyzed the influence of the number of layers (NOL) for the directions on the reconstruction quality. In the following, we provide detailed architectural changes for the different models.

\begin{itemize}
    \item For the single MLP architecture, we feed the directions in at layer 4 instead of 1, decreasing the NOL for the directions from 6 to 3.
    \item For the additive separate architecture, we reduce the NOL of the specular MLP from 4 to 2. Also, we remove the input skip.
    \item For the additive shared architecture, we reduce the NOL of the shared MLP from 5 to 3 while increasing the NOL of the diffuse and specular MLPs (and therefore NOL for the directions) by 2, respectively.
\end{itemize}


\subsection{Influence of the Angle Parametrization}
\label{sec:supp:exps_angle_param}

\input{tables/supp_changes_view_light}

Following previous work \cite{Zhang2021NeRFactor, sztrajman2021neural}, we use the Rusinkiewicz angles \cite{rusinkiewicz1998new} to parametrize the directions as inputs for the MLPs; see \cref{sec:supp:angle_definitions} for a review and discussion. As noted by Rusinkiewicz, this parametrization aligns the specular peaks better with the coordinate axes, which benefits learning highly specular materials. The results in \cref{tab:changes_quantitative_view_light} confirm that using the view-light angles as parametrization for purely neural BRDF models reduces the reconstruction quality compared to the Rusinkiewicz angles. Moreover, we see that, indeed, this effect is more prominent for the MERL-based semi-synthetic dataset, which contains more highly specular materials.


\subsection{Changes from the NeRFactor Architecture}
\label{sec:supp:changes_nerfactor}

\input{tables/supp_changes_nerfactor}
\input{figures/supp_cow_nerfactor}

While our additive separate architecture is based on NeRFactor \cite{Zhang2021NeRFactor}, we made two changes, which improved the results for our data significantly. In this section, we present the comparison to justify these adjustments.

As a first change, we remove the albedo clamping. The original work empirically constrains the diffuse reflection (\ie the albedo) to $[0.03, 0.8]$. Since we work in linear space, we transform these values from sRGB to linear space, which yields the range $[0.0023, 0.6038]$. The results in \cref{tab:supp:changes_quantitative_nerfactor} show that we obtain significantly worse results for the semi-synthetic MERL-based data. The reason lies in the metallic materials contained in this dataset. Metals show almost no subsurface scattering due to the free electrons \cite{akenine2019realTimeRendering}. As demonstrated in \cref{sec:supp:qualitative_diffuse_specular} and visible in particular in \cref{fig:supp_diff_spec_synth_2}, all models replicate this behavior and show almost no diffuse contribution. However, the lower bound on the diffuse part imposed by the albedo clamping prohibits a negligible contribution of the albedo, and we observe a dark gray base color for the diffuse renderings. This leads to the decrease in construction quality. While we see slight improvements with the albedo clamping for non-metal materials and the real-world data, we still decided to remove it due to the significant performance decrease for metallic materials.

As a second change, we use an RGB specular term instead of a scalar one. While the original work assumes, that all color information can be handeled by the albedo network, we find, that for certain materials, a colored specular part is necessary for good reconstructions. The most extreme example we observed is the cow object from the DiLiGenT-MV dataset \cite{Li2020DiLiGentMVDataset} as shown in \cref{fig:supp:nerfactor_cow_scalar_spec}. We can clearly see, that an approach with a scalar specular term yields an inaccurate glow effect that is not observed for models with an RGB specular term (\cf
the rendering for the additive separate architecture in
\iftoggle{arxiv}{\cref{fig:evaluation_renderings}}{Fig.~3}
in the main text and \cref{fig:supp_diff_spec_real} in the appendix).
While the effect is less prominent for other materials, \cref{tab:supp:changes_quantitative_nerfactor} confirms that a scalar specular term instead of an RGB one yields systematically worse results for both datasets. Recall that we observe a similar effect on the cow for the FMBRDF model \cite{ichikawa2023fresnel}, which also employs a scalar specular term; \cf
\iftoggle{arxiv}{\cref{sec:comparison_brdf_models}}{Sec.~6.1}
in the main text.

\subsection{Failure Cases}
\label{sec:supp:failure_cases}

\input{figures/supp_failure_softplus}

Although all methods show quite stable convergence with the chosen parameters, we observed occasional issues with very shiny materials for the additive purely neural models that employ a softplus output nonlinearity. \cref{fig:supp:failure_softplus} shows a failure example for the additive shared architecture. As described in \cref{sec:supp:softplusScaling}, scaling the output of the softplus function solves this issue.



\subsection{Qualitative Results Diffuse and Specular Split}
\label{sec:supp:qualitative_diffuse_specular}

\input{figures/supp_renderings_diffuse_spec_real}
\input{figures/supp_renderings_diffuse_spec_synth_1}
\input{figures/supp_renderings_diffuse_spec_synth_2}

In \cref{fig:supp_diff_spec_real,fig:supp_diff_spec_synth_1,fig:supp_diff_spec_synth_2}, we present a quantitative analysis of the diffuse and the specular component of all models that split the BRDF into those two contributions. Overall, the methods mostly show a reasonable split. For the purely neural methods, we notice a tendency to represent a larger fraction of the appearance by the specular part, leading to darker diffuse parts. Our enhancements introduced in \iftoggle{arxiv}{\cref{sec:enhancingAddSplit}}{Sec.~4.4}
and in particular the regularizers discussed in \iftoggle{arxiv}{\cref{sec:enhancingAddSplit}}{Sec.~4.4} and \cref{sec:supp:regularizers_enhanced} seem to improve on the disentanglement of diffuse and specular components. \cref{fig:supp_diff_spec_synth_2} reveals that all models can represent the behavior of metallic objects, where almost no subsurface scattering is present, and indeed predict almost no albedo component.


\subsection{Spatial Variation of the Reconstructed BRDFs}
\label{sec:supp:spat_var_recon_brdf}

\input{figures/supp_renderings_diffuse_flat}

As described in the main text, the MERL BRDFs are uniform over the respective meshes for the semi-synthetic dataset. To assess how well the models can capture this spatial uniformity, we render the albedo without the cosine term for all models, that employ an additive split. The results for five materials in \cref{fig:supp:renderings_diffuse_flat} reveal very little spatial variation of the albedos, which indicates that all models are able to capture the spatial uniformity quite well.



\subsection{Additional Comparison Results}
\label{sec:supp:additional_experiments_comp}

We report quantitative results for the individual objects of the DiLiGenT-MV dataset in \cref{tab:supp:diligent_quantitative} and qualitative results for both datasets in \cref{fig:supp:renderings_real,fig:supp:renderings_synth_1,fig:supp:renderings_synth_2,fig:supp:renderings_synth_3,fig:supp:renderings_synth_4,fig:supp:renderings_synth_5,fig:supp:renderings_synth_6}.

\paragraph{Real-World Data}
The quantitative evaluation on the individual objects in \cref{tab:supp:diligent_quantitative} confirms that for the DiLiGenT-MV dataset \cite{Li2020DiLiGentMVDataset}, the difference between the approaches based on parametric models and purely neural methods is quite small. We even observe that for individual objects like the bear, some parametric approaches perform slightly better than the purely neural approaches -- in particular, better than approaches with more layers for the directions (\eg Single MLP). This behavior can also be observed qualitatively in \cref{fig:supp:renderings_real}. The reason might be the noise in the real-world data, to which the purely neural methods seem to be slightly more sensitive. The fact that neural approaches with fewer layers for the directions (\eg Additive shared) yield better results supports this claim, in particular in light of the analysis of the number of layers for the directions presented in
\iftoggle{arxiv}{\cref{sec:analysis_brdf_models}}{Sec.~6.2}.

Moreover, \cref{fig:supp:renderings_real} reveals that all methods show errors in similar regions - recesses in particular. We hypothesize un-modelled interreflections as a potential reason. Due to the indicator function in the rendering equation for our scenario
(\iftoggle{arxiv}{\cref{eq:rendering_single_dir_light}}{Eq.~(9)} in the main paper),
shadows in the recesses will be completely black in our renderings. That is, however, a simplification because, in reality, some light reflected off the near surfaces will reach the shaded regions in the recesses. Therefore, larger errors for the image-based metrics in those parts of the mesh are expected.

Finally, \cref{tab:supp:diligent_quantitative} confirms that for the novel additive strategy, which we proposed in
\iftoggle{arxiv}{\cref{sec:enhancingAddSplit}}{Sec.~4.4},
we observe consistent improvements in the extended vanilla additive models.

\paragraph{Semi-Synthetic Data}
\cref{fig:supp:renderings_synth_1,fig:supp:renderings_synth_2,fig:supp:renderings_synth_3,fig:supp:renderings_synth_4,fig:supp:renderings_synth_5,fig:supp:renderings_synth_6} show a systematic advantage of purely neural methods for the challenging materials of the MERL dataset. The error maps reveal that in particular the specular peaks are much better represented, often showing a significant improvement over the parametric methods. While the difference is smaller for more diffuse materials, we still see an advantage of the purely neural methods.

\input{tables/supp_quantitative_diligent}
\input{figures/supp_renderings_real}
\input{figures/supp_renderings_synth_1}
\input{figures/supp_renderings_synth_2}
\input{figures/supp_renderings_synth_3}
\input{figures/supp_renderings_synth_4}
\input{figures/supp_renderings_synth_5}
\input{figures/supp_renderings_synth_6}
