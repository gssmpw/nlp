\section{Related Work}
BRDF modeling has been studied extensively, and various approaches have been proposed. Comprehensive overviews can be found in \cite{montes2012overviewBRDFModels} and \cite{Guarnera2016BRDFRepresentationAcquisition}. 

\paragraph{Phenomenological and Physically-Based BRDF Models}
Classical works explicitly model the interaction between light and matter by parametric equations, often employing a split into a diffuse component like the Lambertian reflection \cite{Lamber1760} and a specular component. The Phong and the Blinn-Phong models \cite{Phong75,Blinn77} are popular phenomenological approaches for the specular part, despite their physical incorrectness. Several modifications have been proposed, making them, \eg, energy conserving and anisotropic \cite{lafortune1994using,Ashikhmin00AnAnisotropicPhongBRDFModel}.

Most physically-based models for the specular part are microfacet models, introduced by Torrance and Sparrow \cite{torrance1967theory}. They use statistically distributed small mirror-like microfacets in combination with the Fresnel reflection law.
Several extensions to the microfacet model have been presented
\cite{CookTorranceT82,trowbridge1975average,walter2007microfacet,smith1967geometrical,schlick1994inexpensive,Holzschuch17ATwoScaleMicrofacetReflectanceModel}, among those, the popular Disney BRDF \cite{burley2012physically} and the Oren-Nayar model that generalizes diffuse reflection by Lambertian microfacets \cite{Oren94OrenNayar}.
Recently,  Ichikawa \etal addressed shortcomings in the latter model and proposed an approach based on Fresnel reflectance and transmission that also models polarimetric behavior \cite{ichikawa2023fresnel}.

\paragraph{Neural Approaches Based on Parametric Models}
Several neural reflectance methods rely on the extensive research on parametric and physical BRDF models. The idea is to compute the parameters of those models with spatial MLPs for a given input location and to compute the reflectance using the model with the predicted parameters.

The well-established microfacet BRDF \cite{torrance1967theory, walter2007microfacet,CookTorranceT82} has been successfully applied to neural scene reconstruction, where a spatial neural network jointly parametrizes the scene geometry and the parameters for the reflection model \cite{bi2020neuralReflectanceFields,srinivasan2021nerv,Boss2021NERD,Zhang22IRON}. Trained on multi-view images, this allows for novel view synthesis and other downstream tasks like re-lighting or the extraction of 3D assets. Other works employ the microfacet model for material estimation from a single flash image based on U-Nets \cite{Deschaintre2018SingleImageSVBRDFCaptureDeepNN,Henzler2021GenerativeModellingBRDFFlashIms} and in combination with Generative Adversarial Networks to create a generative reflectance model for material reconstruction \cite{Guo2020MaterialGAN}.

The Disney BRDF \cite{burley2012physically} is another parametric model that has been used successfully to design neural reflectance methods. Zhang \etal combine it with a neural SDF for joint estimation of scene geometry and appearance \cite{Zhang21PhySG}. Also, it is used in the scene model proposed by Zhang \etal which includes indirect illumination \cite{Zhang2022ModellingIndirIlluminationInvRendering}. Brahimi \etal employ it for scene reconstruction based on volumetric rendering \cite{Brahimi24SuperVol} and for uncalibrated point-light photometric stereo \cite{brahimi24SparseViewsNearLight}.




\paragraph{Purely Neural Models}
In contrast, purely neural methods do not depend on parametric models but use MLPs to predict the BRDF values directly. 
Two main approaches can be distinguished: While some works use a single MLP to compute the complete BRDF value, others rely on an additive split into a diffuse and a specular part.

Sztrajman \etal \cite{sztrajman2021neural} use a single neural network to represent a non-spatially-varying BRDF, which they train on the MERL data \cite{matusik2003MERL}. By using a variational-autoencoder, they compress their neural BRDFs into a latent space.
Hu \etal \cite{hu2020deepbrdf} employ an autoencoder to compress the MERL BRDFs directly.
Zhang \etal \cite{Zhang2021NeRFactor} use a neural BRDF based on an additive split with a specular component pre-trained on the MERL data \cite{matusik2003MERL} for neural scene reconstruction under unknown lighting conditions. They demonstrate a slight advantage of their purely neural approach over a microfacet BRDF-based neural model.
Sarka \etal \cite{Sarkar23LitNerf} employ several MLPs to compute an additive split as well as terms for indirect illumination to obtain highly realistic reconstructions of human heads. 
Among the other methods,
they are the only ones who aim to ensure the reciprocity of the BRDF.
Zheng \etal \cite{Zeng23RelightingNeRFsWithShadowAndHighlightHints} use a single MLP to model the reflectance for volume rendering based scene reconstruction. In contrast to previous methods, they do not model effects like interreflection and Lambert's cosine law explicitly but have the neural network learn them, which they facilitate by additional \emph{light transport hints} predicted by separate networks.

\paragraph{Neural Methods in Computer Graphics}

Neural approaches have also been explored in computer graphics to model highly complex materials.
Fan \etal \cite{Fan2022NeuralLayeredBRDF} propose learned operations in a latent space to model the layering of multiple materials.
Rainer \etal \cite{rainer2019neuralBTFCompression,rainer2020unifiedNeuralEncodingOfBTFs} and Rodriguez-Pardo \etal\cite{rodriguez2023neubtf} employ autoencoders to compress Bidirectional Texture Functions (BTFs) into a latent space, enabling fast test-time encodings.
Kuznetsov \etal extend an MLP decoder for BTFs by a generalization of classic mipmap pyramids and curvature awareness \cite{Kuznetsov21NeuMIP,kuznetsov2022renderingNeuralMaterialsOnCurvedSurfaces}.
Tg \etal have investigated neural approaches to model the subsurface scattering in translucent objects \cite{tg2024neuralSSS,TG23NeuralBSSRDF}.

