@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}

@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  year={2023}
}

@inproceedings{jaegle2021perceiver,
  title={Perceiver: General perception with iterative attention},
  author={Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle={International conference on machine learning},
  pages={4651--4664},
  year={2021},
  organization={PMLR}
}

@article{zhang2023text,
  title={Text-to-image Diffusion Model in Generative AI: A Survey},
  author={Zhang, Chenshuang and Zhang, Chaoning and Zhang, Mengchun and Kweon, In So},
  journal={arXiv preprint arXiv:2303.07909},
  year={2023}
}

@inproceedings{zhou2021transfill,
  title={Transfill: Reference-guided image inpainting by merging multiple color and spatial transformations},
  author={Zhou, Yuqian and Barnes, Connelly and Shechtman, Eli and Amirghodsi, Sohrab},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2266--2276},
  year={2021}
}

@article{zhao2022geofill,
  title={Geofill: Reference-based image inpainting of scenes with complex geometry},
  author={Zhao, Yunhan and Barnes, Connelly and Zhou, Yuqian and Shechtman, Eli and Amirghodsi, Sohrab and Fowlkes, Charless},
  journal={arXiv preprint arXiv:2201.08131},
  year={2022}
}

@article{zhao20223dfill,
  title={3DFill: Reference-guided Image Inpainting by Self-supervised 3D Image Alignment},
  author={Zhao, Liang and Zhao, Xinyuan and Ma, Hailong and Zhang, Xinyu and Zeng, Long},
  journal={arXiv preprint arXiv:2211.04831},
  year={2022}
}

@inproceedings{zeng2020high,
  title={High-resolution image inpainting with iterative confidence feedback and guided upsampling},
  author={Zeng, Yu and Lin, Zhe and Yang, Jimei and Zhang, Jianming and Shechtman, Eli and Lu, Huchuan},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XIX 16},
  pages={1--17},
  year={2020},
  organization={Springer}
}

@inproceedings{liu2023zero,
  title={Zero-1-to-3: Zero-shot One Image to 3D Object},
  author={Liu, Ruoshi and Wu, Rundi and Van Hoorick, Basile and Tokmakov, Pavel and Zakharov, Sergey and Vondrick, Carl},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  year={2023}
}

@article{deitke2022objaverse,
  title={Objaverse: A Universe of Annotated 3D Objects},
  author={Deitke, Matt and Schwenk, Dustin and Salvador, Jordi and Weihs, Luca and Michel, Oscar and VanderBilt, Eli and Schmidt, Ludwig and Ehsani, Kiana and Kembhavi, Aniruddha and Farhadi, Ali},
  journal={arXiv preprint arXiv:2212.08051},
  year={2022}
}

@article{zhao2021large,
  title={Large scale image completion via co-modulated generative adversarial networks},
  author={Zhao, Shengyu and Cui, Jonathan and Sheng, Yilun and Dong, Yue and Liang, Xiao and Chang, Eric I and Xu, Yan},
  journal={arXiv preprint arXiv:2103.10428},
  year={2021}
}

@inproceedings{li2022mat,
  title={Mat: Mask-aware transformer for large hole image inpainting},
  author={Li, Wenbo and Lin, Zhe and Zhou, Kun and Qi, Lu and Wang, Yi and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10758--10768},
  year={2022}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{ding2021cogview,
  title={Cogview: Mastering text-to-image generation via transformers},
  author={Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and Zheng, Wendi and Zhou, Chang and Yin, Da and Lin, Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={19822--19835},
  year={2021}
}

@inproceedings{wu2022nuwa,
  title={N{\"u}wa: Visual synthesis pre-training for neural visual world creation},
  author={Wu, Chenfei and Liang, Jian and Ji, Lei and Yang, Fan and Fang, Yuejian and Jiang, Daxin and Duan, Nan},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XVI},
  pages={720--736},
  year={2022},
  organization={Springer}
}

@article{yu2022scaling,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  journal={arXiv preprint arXiv:2206.10789},
  year={2022}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}

@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

@article{ruiz2022dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  journal={arXiv preprint arXiv:2208.12242},
  year={2022}
}

@article{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01618},
  year={2022}
}

@article{chang2023muse,
  title={Muse: Text-To-Image Generation via Masked Generative Transformers},
  author={Chang, Huiwen and Zhang, Han and Barber, Jarred and Maschinot, AJ and Lezama, Jose and Jiang, Lu and Yang, Ming-Hsuan and Murphy, Kevin and Freeman, William T and Rubinstein, Michael and others},
  journal={arXiv preprint arXiv:2301.00704},
  year={2023}
}

@article{mokady2022null,
  title={Null-text Inversion for Editing Real Images using Guided Diffusion Models},
  author={Mokady, Ron and Hertz, Amir and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2211.09794},
  year={2022}
}

@article{bar2023multidiffusion,
  title={MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation},
  author={Bar-Tal, Omer and Yariv, Lior and Lipman, Yaron and Dekel, Tali},
  journal={arXiv preprint arXiv:2302.08113},
  volume={2},
  year={2023}
}

@inproceedings{yang2023paint,
  title={Paint by example: Exemplar-based image editing with diffusion models},
  author={Yang, Binxin and Gu, Shuyang and Zhang, Bo and Zhang, Ting and Chen, Xuejin and Sun, Xiaoyan and Chen, Dong and Wen, Fang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18381--18391},
  year={2023}
}

@inproceedings{poole2023dreamfusion,
  title={Dreamfusion: Text-to-3d using 2d diffusion},
  author={Poole, Ben and Jain, Ajay and Barron, Jonathan T and Mildenhall, Ben},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@inproceedings{schuhmann2022laion,
 author = {Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and Schramowski, Patrick and Kundurthy, Srivatsa and Crowson, Katherine and Schmidt, Ludwig and Kaczmarczyk, Robert and Jitsev, Jenia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {25278--25294},
 publisher = {Curran Associates, Inc.},
 title = {LAION-5B: An open large-scale dataset for training next generation image-text models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/a1859debfb3b59d094f3504d5ebb6c25-Paper-Datasets_and_Benchmarks.pdf},
 volume = {35},
 year = {2022}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{mou2023t2i,
  title={T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models},
  author={Mou, Chong and Wang, Xintao and Xie, Liangbin and Zhang, Jian and Qi, Zhongang and Shan, Ying and Qie, Xiaohu},
  journal={arXiv preprint arXiv:2302.08453},
  year={2023}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{bar2022visual,
  title={Visual prompting via image inpainting},
  author={Bar, Amir and Gandelsman, Yossi and Darrell, Trevor and Globerson, Amir and Efros, Alexei},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25005--25017},
  year={2022}
}

@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXIII},
  pages={709--727},
  year={2022},
  organization={Springer}
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021}
}

@article{yu2021vector,
  title={Vector-quantized image modeling with improved VQGAN},
  author={Yu, Jiahui and Li, Xin and Koh, Jing Yu and Zhang, Han and Pang, Ruoming and Qin, James and Ku, Alexander and Xu, Yuanzhong and Baldridge, Jason and Wu, Yonghui},
  journal={arXiv preprint arXiv:2110.04627},
  year={2021}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{ma2023unified,
  title={Unified Multi-Modal Latent Diffusion for Joint Subject and Text Conditional Image Generation},
  author={Ma, Yiyang and Yang, Huan and Wang, Wenjing and Fu, Jianlong and Liu, Jiaying},
  journal={arXiv preprint arXiv:2303.09319},
  year={2023}
}

@inproceedings{avrahami2022blended,
  title={Blended diffusion for text-driven editing of natural images},
  author={Avrahami, Omri and Lischinski, Dani and Fried, Ohad},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18208--18218},
  year={2022}
}

@article{hertz2022prompt,
  title={Prompt-to-prompt image editing with cross attention control},
  author={Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01626},
  year={2022}
}

@article{li2023gligen,
  title={GLIGEN: Open-Set Grounded Text-to-Image Generation},
  author={Li, Yuheng and Liu, Haotian and Wu, Qingyang and Mu, Fangzhou and Yang, Jianwei and Gao, Jianfeng and Li, Chunyuan and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2301.07093},
  year={2023}
}

@article{couairon2022diffedit,
  title={Diffedit: Diffusion-based semantic image editing with mask guidance},
  author={Couairon, Guillaume and Verbeek, Jakob and Schwenk, Holger and Cord, Matthieu},
  journal={arXiv preprint arXiv:2210.11427},
  year={2022}
}

@article{voynov2022sketch,
  title={Sketch-Guided Text-to-Image Diffusion Models},
  author={Voynov, Andrey and Aberman, Kfir and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2211.13752},
  year={2022}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@article{liu2021gpt,
  title={GPT understands, too},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2103.10385},
  year={2021}
}

@article{liu2021p,
  title={P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks},
  author={Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng Lam and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2110.07602},
  year={2021}
}

@article{ge2022domain,
  title={Domain adaptation via prompt learning},
  author={Ge, Chunjiang and Huang, Rui and Xie, Mixue and Lai, Zihang and Song, Shiji and Li, Shuang and Huang, Gao},
  journal={arXiv preprint arXiv:2202.06687},
  year={2022}
}


@article{yao2021cpt,
  title={Cpt: Colorful prompt tuning for pre-trained vision-language models},
  author={Yao, Yuan and Zhang, Ao and Zhang, Zhengyan and Liu, Zhiyuan and Chua, Tat-Seng and Sun, Maosong},
  journal={arXiv preprint arXiv:2109.11797},
  year={2021}
}

@article{liao2023rethinking,
  title={Rethinking Visual Prompt Learning as Masked Visual Token Modeling},
  author={Liao, Ning and Shi, Bowen and Cao, Min and Zhang, Xiaopeng and Tian, Qi and Yan, Junchi},
  journal={arXiv preprint arXiv:2303.04998},
  year={2023}
}

@article{sohn2022visual,
  title={Visual Prompt Tuning for Generative Transfer Learning},
  author={Sohn, Kihyuk and Hao, Yuan and Lezama, Jos{\'e} and Polania, Luisa and Chang, Huiwen and Zhang, Han and Essa, Irfan and Jiang, Lu},
  journal={arXiv preprint arXiv:2210.00990},
  year={2022}
}

@article{bahng2022visual,
  title={Visual prompting: Modifying pixel space to adapt pre-trained models},
  author={Bahng, Hyojin and Jahanian, Ali and Sankaranarayanan, Swami and Isola, Phillip},
  journal={arXiv preprint arXiv:2203.17274},
  year={2022}
}

@inproceedings{bertalmio2000image,
  title={Image inpainting},
  author={Bertalmio, Marcelo and Sapiro, Guillermo and Caselles, Vincent and Ballester, Coloma},
  booktitle={Proceedings of the 27th annual conference on Computer graphics and interactive techniques},
  pages={417--424},
  year={2000}
}

@article{hays2007scene,
  title={Scene completion using millions of photographs},
  author={Hays, James and Efros, Alexei A},
  journal={ACM Transactions on Graphics (ToG)},
  volume={26},
  number={3},
  pages={4--es},
  year={2007},
  publisher={ACM New York, NY, USA}
}

@inproceedings{criminisi2003object,
  title={Object removal by exemplar-based inpainting},
  author={Criminisi, Antonio and Perez, Patrick and Toyama, Kentaro},
  booktitle={2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.},
  volume={2},
  pages={II--II},
  year={2003},
  organization={IEEE}
}

@inproceedings{suvorov2022resolution,
  title={Resolution-robust large mask inpainting with fourier convolutions},
  author={Suvorov, Roman and Logacheva, Elizaveta and Mashikhin, Anton and Remizova, Anastasia and Ashukha, Arsenii and Silvestrov, Aleksei and Kong, Naejin and Goka, Harshith and Park, Kiwoong and Lempitsky, Victor},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={2149--2159},
  year={2022}
}

@inproceedings{dong2022incremental,
  title={Incremental transformer structure enhanced image inpainting with masking positional encoding},
  author={Dong, Qiaole and Cao, Chenjie and Fu, Yanwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11358--11368},
  year={2022}
}

@inproceedings{oh2019onion,
  title={Onion-peel networks for deep video completion},
  author={Oh, Seoung Wug and Lee, Sungho and Lee, Joon-Young and Kim, Seon Joo},
  booktitle={proceedings of the IEEE/cvf international conference on computer vision},
  pages={4403--4412},
  year={2019}
}

@article{zhang2023makes,
  title={What Makes Good Examples for Visual In-Context Learning?},
  author={Zhang, Yuanhan and Zhou, Kaiyang and Liu, Ziwei},
  journal={arXiv preprint arXiv:2301.13670},
  year={2023}
}

@article{wang2022images,
  title={Images Speak in Images: A Generalist Painter for In-Context Visual Learning},
  author={Wang, Xinlong and Wang, Wen and Cao, Yue and Shen, Chunhua and Huang, Tiejun},
  journal={arXiv preprint arXiv:2212.02499},
  year={2022}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International Conference on Machine Learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@article{tang2022quadtree,
  title={Quadtree attention for vision transformers},
  author={Tang, Shitao and Zhang, Jiahui and Zhu, Siyu and Tan, Ping},
  journal={arXiv preprint arXiv:2201.02767},
  year={2022}
}

@inproceedings{chen2021learning,
  title={Learning continuous image representation with local implicit image function},
  author={Chen, Yinbo and Liu, Sifei and Wang, Xiaolong},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8628--8638},
  year={2021}
}

@inproceedings{lu2021masa,
  title={Masa-sr: Matching acceleration and spatial adaptation for reference-based image super-resolution},
  author={Lu, Liying and Li, Wenbo and Tao, Xin and Lu, Jiangbo and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6368--6377},
  year={2021}
}

@article{zhou2017places,
  title={Places: A 10 million image database for scene recognition},
  author={Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={6},
  pages={1452--1464},
  year={2017},
  publisher={IEEE}
}

@inproceedings{cheng2022inout,
  title={InOut: diverse image outpainting via GAN inversion},
  author={Cheng, Yen-Chi and Lin, Chieh Hubert and Lee, Hsin-Ying and Ren, Jian and Tulyakov, Sergey and Yang, Ming-Hsuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11431--11440},
  year={2022}
}

@inproceedings{li2018megadepth,
  title={Megadepth: Learning single-view depth prediction from internet photos},
  author={Li, Zhengqi and Snavely, Noah},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2041--2050},
  year={2018}
}

@inproceedings{schops2017multi,
  title={A multi-view stereo benchmark with high-resolution images and multi-camera videos},
  author={Schops, Thomas and Schonberger, Johannes L and Galliani, Silvano and Sattler, Torsten and Schindler, Konrad and Pollefeys, Marc and Geiger, Andreas},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3260--3269},
  year={2017}
}

@inproceedings{agustsson2017ntire,
  title={Ntire 2017 challenge on single image super-resolution: Dataset and study},
  author={Agustsson, Eirikur and Timofte, Radu},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={126--135},
  year={2017}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14},
  pages={694--711},
  year={2016},
  organization={Springer}
}

@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

@article{qin2020u2,
  title={U2-Net: Going deeper with nested U-structure for salient object detection},
  author={Qin, Xuebin and Zhang, Zichen and Huang, Chenyang and Dehghan, Masood and Zaiane, Osmar R and Jagersand, Martin},
  journal={Pattern recognition},
  volume={106},
  pages={107404},
  year={2020},
  publisher={Elsevier}
}

@article{elfwing2018sigmoid,
  title={Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  author={Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  journal={Neural Networks},
  volume={107},
  pages={3--11},
  year={2018},
  publisher={Elsevier}
}

@article{fahim2021single,
  title={Single-View 3D reconstruction: A Survey of deep learning methods},
  author={Fahim, George and Amin, Khalid and Zarif, Sameh},
  journal={Computers \& Graphics},
  volume={94},
  pages={164--190},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{wang2018pixel2mesh,
  title={Pixel2mesh: Generating 3d mesh models from single rgb images},
  author={Wang, Nanyang and Zhang, Yinda and Li, Zhuwen and Fu, Yanwei and Liu, Wei and Jiang, Yu-Gang},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={52--67},
  year={2018}
}

@article{chen2019learning,
  title={Learning to predict 3d objects with an interpolation-based differentiable renderer},
  author={Chen, Wenzheng and Ling, Huan and Gao, Jun and Smith, Edward and Lehtinen, Jaakko and Jacobson, Alec and Fidler, Sanja},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{liu2019soft,
  title={Soft rasterizer: A differentiable renderer for image-based 3d reasoning},
  author={Liu, Shichen and Li, Tianye and Chen, Weikai and Li, Hao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7708--7717},
  year={2019}
}

@article{chan2023generative,
  title={Generative novel view synthesis with 3d-aware diffusion models},
  author={Chan, Eric R and Nagano, Koki and Chan, Matthew A and Bergman, Alexander W and Park, Jeong Joon and Levy, Axel and Aittala, Miika and De Mello, Shalini and Karras, Tero and Wetzstein, Gordon},
  journal={arXiv preprint arXiv:2304.02602},
  year={2023}
}

@inproceedings{wu2017marrnet,
  title={Marrnet: 3d shape reconstruction via 2.5 d sketches},
  author={Wu, Jiajun and Wang, Yifan and Xue, Tianfan and Sun, Xingyuan and Freeman, Bill and Tenenbaum, Josh},
  booktitle={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{xu2019disn,
  title={Disn: Deep implicit surface network for high-quality single-view 3d reconstruction},
  author={Xu, Qiangeng and Wang, Weiyue and Ceylan, Duygu and Mech, Radomir and Neumann, Ulrich},
  booktitle={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{niklaus20193d,
  title={3d ken burns effect from a single image},
  author={Niklaus, Simon and Mai, Long and Yang, Jimei and Liu, Feng},
  journal={ACM Transactions on Graphics (ToG)},
  volume={38},
  number={6},
  pages={1--15},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{shih20203d,
  title={3d photography using context-aware layered depth inpainting},
  author={Shih, Meng-Li and Su, Shih-Yang and Kopf, Johannes and Huang, Jia-Bin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8028--8038},
  year={2020}
}

@inproceedings{rombach2021geometry,
  title={Geometry-free view synthesis: Transformers and no 3d priors},
  author={Rombach, Robin and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14356--14366},
  year={2021}
}

@article{schwarz2020graf,
  title={Graf: Generative radiance fields for 3d-aware image synthesis},
  author={Schwarz, Katja and Liao, Yiyi and Niemeyer, Michael and Geiger, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20154--20166},
  year={2020}
}

@inproceedings{niemeyer2021giraffe,
  title={Giraffe: Representing scenes as compositional generative neural feature fields},
  author={Niemeyer, Michael and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11453--11464},
  year={2021}
}

@inproceedings{lin2023magic3d,
  title={Magic3d: High-resolution text-to-3d content creation},
  author={Lin, Chen-Hsuan and Gao, Jun and Tang, Luming and Takikawa, Towaki and Zeng, Xiaohui and Huang, Xun and Kreis, Karsten and Fidler, Sanja and Liu, Ming-Yu and Lin, Tsung-Yi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={300--309},
  year={2023}
}

@article{qian2023magic123,
  title={Magic123: One image to high-quality 3d object generation using both 2d and 3d diffusion priors},
  author={Qian, Guocheng and Mai, Jinjie and Hamdi, Abdullah and Ren, Jian and Siarohin, Aliaksandr and Li, Bing and Lee, Hsin-Ying and Skorokhodov, Ivan and Wonka, Peter and Tulyakov, Sergey and others},
  journal={arXiv preprint arXiv:2306.17843},
  year={2023}
}

@inproceedings{wang2023score,
  title={Score jacobian chaining: Lifting pretrained 2d diffusion models for 3d generation},
  author={Wang, Haochen and Du, Xiaodan and Li, Jiahao and Yeh, Raymond A and Shakhnarovich, Greg},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12619--12629},
  year={2023}
}

@article{tang2023make,
  title={Make-it-3d: High-fidelity 3d creation from a single image with diffusion prior},
  author={Tang, Junshu and Wang, Tengfei and Zhang, Bo and Zhang, Ting and Yi, Ran and Ma, Lizhuang and Chen, Dong},
  journal={arXiv preprint arXiv:2303.14184},
  year={2023}
}

@article{liu2023syncdreamer,
  title={SyncDreamer: Generating Multiview-consistent Images from a Single-view Image},
  author={Liu, Yuan and Lin, Cheng and Zeng, Zijiao and Long, Xiaoxiao and Liu, Lingjie and Komura, Taku and Wang, Wenping},
  journal={arXiv preprint arXiv:2309.03453},
  year={2023}
}

@article{van2016conditional,
  title={Conditional image generation with pixelcnn decoders},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{salimans2017pixelcnn++,
  title={Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications},
  author={Salimans, Tim and Karpathy, Andrej and Chen, Xi and Kingma, Diederik P},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017}
}

@inproceedings{yu2018generative,
  title={Generative image inpainting with contextual attention},
  author={Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5505--5514},
  year={2018}
}

@inproceedings{downs2022google,
  title={Google scanned objects: A high-quality dataset of 3d scanned household items},
  author={Downs, Laura and Francis, Anthony and Koenig, Nate and Kinman, Brandon and Hickman, Ryan and Reymann, Krista and McHugh, Thomas B and Vanhoucke, Vincent},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)},
  pages={2553--2560},
  year={2022},
  organization={IEEE}
}

@article{podell2023sdxl,
  title={Sdxl: Improving latent diffusion models for high-resolution image synthesis},
  author={Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and M{\"u}ller, Jonas and Penna, Joe and Rombach, Robin},
  journal={arXiv preprint arXiv:2307.01952},
  year={2023}
}

@inproceedings{
podell2024sdxl,
title={{SDXL}: Improving Latent Diffusion Models for High-Resolution Image Synthesis},
author={Dustin Podell and Zion English and Kyle Lacey and Andreas Blattmann and Tim Dockhorn and Jonas M{\"u}ller and Joe Penna and Robin Rombach},
booktitle={International Conference on Learning Representations (ICLR)},
year={2024},
}

@inproceedings{cao2024leftrefill,
  title={LeftRefill: Filling Right Canvas based on Left Reference through Generalized Text-to-Image Diffusion Model},
  author={Cao, Chenjie and Cai, Yunuo and Dong, Qiaole and Wang, Yikai and Fu, Yanwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7705--7715},
  year={2024}
}

@misc{flux2024,
    author={Black Forest Labs},
    title={FLUX},
    year={2024},
    howpublished={\url{https://github.com/black-forest-labs/flux}},
}

@misc{iclight2024,
  author = {Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
  title  = {IC-Light GitHub Page},
  year   = {2024},
}

@InProceedings{
ke2023repurposing,
title={Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation},
author={Bingxin Ke and Anton Obukhov and Shengyu Huang and Nando Metzger and Rodrigo Caye Daudt and Konrad Schindler},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2024}
}

@inproceedings{yang2024depth,
  title={Depth anything: Unleashing the power of large-scale unlabeled data},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10371--10381},
  year={2024}
}

@inproceedings{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4015--4026},
  year={2023}
}

@article{shi2024seededit,
  title={SeedEdit: Align Image Re-Generation to Image Editing},
  author={Shi, Yichun and Wang, Peng and Huang, Weilin},
  journal={arXiv preprint arXiv:2411.06686},
  year={2024}
}

@inproceedings{zhao2023unleashing,
  title={Unleashing text-to-image diffusion models for visual perception},
  author={Zhao, Wenliang and Rao, Yongming and Liu, Zuyan and Liu, Benlin and Zhou, Jie and Lu, Jiwen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5729--5739},
  year={2023}
}

@article{rout2024semantic,
  title={Semantic image inversion and editing using rectified stochastic differential equations},
  author={Rout, Litu and Chen, Yujia and Ruiz, Nataniel and Caramanis, Constantine and Shakkottai, Sanjay and Chu, Wen-Sheng},
  journal={arXiv preprint arXiv:2410.10792},
  year={2024}
}

@article{dalva2024fluxspace,
  title={FluxSpace: Disentangled Semantic Editing in Rectified Flow Transformers},
  author={Dalva, Yusuf and Venkatesh, Kavana and Yanardag, Pinar},
  journal={arXiv preprint arXiv:2412.09611},
  year={2024}
}

@article{wang2024exploiting,
  title={Exploiting diffusion prior for real-world image super-resolution},
  author={Wang, Jianyi and Yue, Zongsheng and Zhou, Shangchen and Chan, Kelvin CK and Loy, Chen Change},
  journal={International Journal of Computer Vision},
  pages={1--21},
  year={2024},
  publisher={Springer}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@inproceedings{wang2018esrgan,
  title={Esrgan: Enhanced super-resolution generative adversarial networks},
  author={Wang, Xintao and Yu, Ke and Wu, Shixiang and Gu, Jinjin and Liu, Yihao and Dong, Chao and Qiao, Yu and Change Loy, Chen},
  booktitle={Proceedings of the European conference on computer vision (ECCV) workshops},
  pages={0--0},
  year={2018}
}

@inproceedings{lim2017enhanced,
  title={Enhanced deep residual networks for single image super-resolution},
  author={Lim, Bee and Son, Sanghyun and Kim, Heewon and Nah, Seungjun and Mu Lee, Kyoung},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={136--144},
  year={2017}
}

@article{liu2022flow,
  title={Flow straight and fast: Learning to generate and transfer data with rectified flow},
  author={Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
  journal={arXiv preprint arXiv:2209.03003},
  year={2022}
}

@inproceedings{esser2024scaling,
  title={Scaling rectified flow transformers for high-resolution image synthesis},
  author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{ye2023ip,
  title={Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models},
  author={Ye, Hu and Zhang, Jun and Liu, Sibo and Han, Xiao and Yang, Wei},
  journal={arXiv preprint arXiv:2308.06721},
  year={2023}
}

@misc{alimamacontrolnet2024,
    author={AlimamaCreative Team},
    title={Alimama FLUX ControlNet },
    year={2024},
    howpublished={\url{https://github.com/alimama-creative/FLUX-Controlnet-Inpainting}},
}

@misc{fluxfill2024,
    author={Black Forest Labs},
    title={FLUX.Fill},
    year={2024},
    howpublished={\url{https://huggingface.co/black-forest-labs/FLUX.1-Fill-dev}},
}

@article{hong2024cogvlm2,
  title={Cogvlm2: Visual language models for image and video understanding},
  author={Hong, Wenyi and Wang, Weihan and Ding, Ming and Yu, Wenmeng and Lv, Qingsong and Wang, Yan and Cheng, Yean and Huang, Shiyu and Ji, Junhui and Xue, Zhao and others},
  journal={arXiv preprint arXiv:2408.16500},
  year={2024}
}

@article{tang2024realfill,
  title={Realfill: Reference-driven generation for authentic image completion},
  author={Tang, Luming and Ruiz, Nataniel and Chu, Qinghao and Li, Yuanzhen and Holynski, Aleksander and Jacobs, David E and Hariharan, Bharath and Pritch, Yael and Wadhwa, Neal and Aberman, Kfir and others},
  journal={ACM Transactions on Graphics (TOG)},
  volume={43},
  number={4},
  pages={1--12},
  year={2024},
  publisher={ACM New York, NY, USA}
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{tian2024visual,
  title={Visual autoregressive modeling: Scalable image generation via next-scale prediction},
  author={Tian, Keyu and Jiang, Yi and Yuan, Zehuan and Peng, Bingyue and Wang, Liwei},
  journal={arXiv preprint arXiv:2404.02905},
  year={2024}
}

@article{meng2021sdedit,
  title={Sdedit: Guided image synthesis and editing with stochastic differential equations},
  author={Meng, Chenlin and He, Yutong and Song, Yang and Song, Jiaming and Wu, Jiajun and Zhu, Jun-Yan and Ermon, Stefano},
  journal={arXiv preprint arXiv:2108.01073},
  year={2021}
}


@inproceedings{parmar2023zero,
  title={Zero-shot image-to-image translation},
  author={Parmar, Gaurav and Kumar Singh, Krishna and Zhang, Richard and Li, Yijun and Lu, Jingwan and Zhu, Jun-Yan},
  booktitle={ACM SIGGRAPH 2023 Conference Proceedings},
  pages={1--11},
  year={2023}
}

@article{kulikov2024flowedit,
  title={FlowEdit: Inversion-Free Text-Based Editing Using Pre-Trained Flow Models},
  author={Kulikov, Vladimir and Kleiner, Matan and Huberman-Spiegelglas, Inbar and Michaeli, Tomer},
  journal={arXiv preprint arXiv:2412.08629},
  year={2024}
}

@article{huang2023region,
  title={Region-aware diffusion for zero-shot text-driven image editing},
  author={Huang, Nisha and Tang, Fan and Dong, Weiming and Lee, Tong-Yee and Xu, Changsheng},
  journal={arXiv preprint arXiv:2302.11797},
  year={2023}
}

@article{wang2024taming,
  title={Taming rectified flow for inversion and editing},
  author={Wang, Jiangshan and Pu, Junfu and Qi, Zhongang and Guo, Jiayi and Ma, Yue and Huang, Nisha and Chen, Yuxin and Li, Xiu and Shan, Ying},
  journal={arXiv preprint arXiv:2411.04746},
  year={2024}
}

@inproceedings{li2024zone,
  title={Zone: Zero-shot instruction-guided local editing},
  author={Li, Shanglin and Zeng, Bohan and Feng, Yutang and Gao, Sicheng and Liu, Xiuhui and Liu, Jiaming and Li, Lin and Tang, Xu and Hu, Yao and Liu, Jianzhuang and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6254--6263},
  year={2024}
}

@inproceedings{mokady2023null,
  title={Null-text inversion for editing real images using guided diffusion models},
  author={Mokady, Ron and Hertz, Amir and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6038--6047},
  year={2023}
}

@inproceedings{brooks2023instructpix2pix,
  title={Instructpix2pix: Learning to follow image editing instructions},
  author={Brooks, Tim and Holynski, Aleksander and Efros, Alexei A},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18392--18402},
  year={2023}
}

@inproceedings{sheynin2024emu,
  title={Emu edit: Precise image editing via recognition and generation tasks},
  author={Sheynin, Shelly and Polyak, Adam and Singer, Uriel and Kirstain, Yuval and Zohar, Amit and Ashual, Oron and Parikh, Devi and Taigman, Yaniv},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8871--8879},
  year={2024}
}

@inproceedings{zhang2024hive,
  title={Hive: Harnessing human feedback for instructional visual editing},
  author={Zhang, Shu and Yang, Xinyi and Feng, Yihao and Qin, Can and Chen, Chia-Chih and Yu, Ning and Chen, Zeyuan and Wang, Huan and Savarese, Silvio and Ermon, Stefano and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9026--9036},
  year={2024}
}

@article{zhang2024magicbrush,
  title={Magicbrush: A manually annotated dataset for instruction-guided image editing},
  author={Zhang, Kai and Mo, Lingbo and Chen, Wenhu and Sun, Huan and Su, Yu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{betker2023improving,
  title={Improving image generation with better captions},
  author={Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuang, Juntang and Lee, Joyce and Guo, Yufei and others},
  journal={Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf},
  volume={2},
  number={3},
  pages={8},
  year={2023}
}

@article{su2024roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

@misc{ren2024grounded,
      title={Grounded SAM: Assembling Open-World Models for Diverse Visual Tasks}, 
      author={Tianhe Ren and Shilong Liu and Ailing Zeng and Jing Lin and Kunchang Li and He Cao and Jiayu Chen and Xinyu Huang and Yukang Chen and Feng Yan and Zhaoyang Zeng and Hao Zhang and Feng Li and Jie Yang and Hongyang Li and Qing Jiang and Lei Zhang},
      year={2024},
      eprint={2401.14159},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{tan2024ominicontrol,
  title={Ominicontrol: Minimal and universal control for diffusion transformer},
  author={Tan, Zhenxiong and Liu, Songhua and Yang, Xingyi and Xue, Qiaochu and Wang, Xinchao},
  journal={arXiv preprint arXiv:2411.15098},
  volume={3},
  year={2024}
}