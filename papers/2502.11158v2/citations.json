[
  {
    "index": 0,
    "papers": [
      {
        "key": "sohl2015deep",
        "author": "Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya",
        "title": "Deep unsupervised learning using nonequilibrium thermodynamics"
      },
      {
        "key": "ho2020denoising",
        "author": "Ho, Jonathan and Jain, Ajay and Abbeel, Pieter",
        "title": "Denoising diffusion probabilistic models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "rombach2022high",
        "author": "Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\\\"o}rn",
        "title": "High-resolution image synthesis with latent diffusion models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "peebles2023scalable",
        "author": "Peebles, William and Xie, Saining",
        "title": "Scalable diffusion models with transformers"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "flux2024",
        "author": "Black Forest Labs",
        "title": "FLUX"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "esser2024scaling",
        "author": "Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\\\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others",
        "title": "Scaling rectified flow transformers for high-resolution image synthesis"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "liu2022flow",
        "author": "Liu, Xingchao and Gong, Chengyue and Liu, Qiang",
        "title": "Flow straight and fast: Learning to generate and transfer data with rectified flow"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "van2017neural",
        "author": "Van Den Oord, Aaron and Vinyals, Oriol and others",
        "title": "Neural discrete representation learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "esser2021taming",
        "author": "Esser, Patrick and Rombach, Robin and Ommer, Bjorn",
        "title": "Taming transformers for high-resolution image synthesis"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "tian2024visual",
        "author": "Tian, Keyu and Jiang, Yi and Yuan, Zehuan and Peng, Bingyue and Wang, Liwei",
        "title": "Visual autoregressive modeling: Scalable image generation via next-scale prediction"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "gal2022image",
        "author": "Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel",
        "title": "An image is worth one word: Personalizing text-to-image generation using textual inversion"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "voynov2022sketch",
        "author": "Voynov, Andrey and Aberman, Kfir and Cohen-Or, Daniel",
        "title": "Sketch-Guided Text-to-Image Diffusion Models"
      },
      {
        "key": "li2023gligen",
        "author": "Li, Yuheng and Liu, Haotian and Wu, Qingyang and Mu, Fangzhou and Yang, Jianwei and Gao, Jianfeng and Li, Chunyuan and Lee, Yong Jae",
        "title": "GLIGEN: Open-Set Grounded Text-to-Image Generation"
      },
      {
        "key": "ma2023unified",
        "author": "Ma, Yiyang and Yang, Huan and Wang, Wenjing and Fu, Jianlong and Liu, Jiaying",
        "title": "Unified Multi-Modal Latent Diffusion for Joint Subject and Text Conditional Image Generation"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "ruiz2022dreambooth",
        "author": "Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir",
        "title": "Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zhang2023adding",
        "author": "Zhang, Lvmin and Agrawala, Maneesh",
        "title": "Adding conditional control to text-to-image diffusion models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "mou2023t2i",
        "author": "Mou, Chong and Wang, Xintao and Xie, Liangbin and Zhang, Jian and Qi, Zhongang and Shan, Ying and Qie, Xiaohu",
        "title": "T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "houlsby2019parameter",
        "author": "Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain",
        "title": "Parameter-efficient transfer learning for NLP"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "podell2024sdxl",
        "author": "Dustin Podell and Zion English and Kyle Lacey and Andreas Blattmann and Tim Dockhorn and Jonas M{\\\"u}ller and Joe Penna and Robin Rombach",
        "title": "{SDXL}: Improving Latent Diffusion Models for High-Resolution Image Synthesis"
      },
      {
        "key": "esser2024scaling",
        "author": "Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\\\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others",
        "title": "Scaling rectified flow transformers for high-resolution image synthesis"
      },
      {
        "key": "flux2024",
        "author": "Black Forest Labs",
        "title": "FLUX"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "gal2022image",
        "author": "Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel",
        "title": "An image is worth one word: Personalizing text-to-image generation using textual inversion"
      },
      {
        "key": "mokady2022null",
        "author": "Mokady, Ron and Hertz, Amir and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel",
        "title": "Null-text Inversion for Editing Real Images using Guided Diffusion Models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "lester2021power",
        "author": "Lester, Brian and Al-Rfou, Rami and Constant, Noah",
        "title": "The power of scale for parameter-efficient prompt tuning"
      },
      {
        "key": "liu2021gpt",
        "author": "Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie",
        "title": "GPT understands, too"
      },
      {
        "key": "liu2021p",
        "author": "Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng Lam and Du, Zhengxiao and Yang, Zhilin and Tang, Jie",
        "title": "P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "liu2023pre",
        "author": "Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham",
        "title": "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      },
      {
        "key": "ge2022domain",
        "author": "Ge, Chunjiang and Huang, Rui and Xie, Mixue and Lai, Zihang and Song, Shiji and Li, Shuang and Huang, Gao",
        "title": "Domain adaptation via prompt learning"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "jia2022visual",
        "author": "Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam",
        "title": "Visual prompt tuning"
      },
      {
        "key": "liao2023rethinking",
        "author": "Liao, Ning and Shi, Bowen and Cao, Min and Zhang, Xiaopeng and Tian, Qi and Yan, Junchi",
        "title": "Rethinking Visual Prompt Learning as Masked Visual Token Modeling"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "sohn2022visual",
        "author": "Sohn, Kihyuk and Hao, Yuan and Lezama, Jos{\\'e} and Polania, Luisa and Chang, Huiwen and Zhang, Han and Essa, Irfan and Jiang, Lu",
        "title": "Visual Prompt Tuning for Generative Transfer Learning"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "sohn2022visual",
        "author": "Sohn, Kihyuk and Hao, Yuan and Lezama, Jos{\\'e} and Polania, Luisa and Chang, Huiwen and Zhang, Han and Essa, Irfan and Jiang, Lu",
        "title": "Visual Prompt Tuning for Generative Transfer Learning"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "hu2021lora",
        "author": "Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu",
        "title": "Lora: Low-rank adaptation of large language models"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "tang2024realfill",
        "author": "Tang, Luming and Ruiz, Nataniel and Chu, Qinghao and Li, Yuanzhen and Holynski, Aleksander and Jacobs, David E and Hariharan, Bharath and Pritch, Yael and Wadhwa, Neal and Aberman, Kfir and others",
        "title": "Realfill: Reference-driven generation for authentic image completion"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "bertalmio2000image",
        "author": "Bertalmio, Marcelo and Sapiro, Guillermo and Caselles, Vincent and Ballester, Coloma",
        "title": "Image inpainting"
      },
      {
        "key": "criminisi2003object",
        "author": "Criminisi, Antonio and Perez, Patrick and Toyama, Kentaro",
        "title": "Object removal by exemplar-based inpainting"
      },
      {
        "key": "hays2007scene",
        "author": "Hays, James and Efros, Alexei A",
        "title": "Scene completion using millions of photographs"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "zeng2020high",
        "author": "Zeng, Yu and Lin, Zhe and Yang, Jimei and Zhang, Jianming and Shechtman, Eli and Lu, Huchuan",
        "title": "High-resolution image inpainting with iterative confidence feedback and guided upsampling"
      },
      {
        "key": "zhao2021large",
        "author": "Zhao, Shengyu and Cui, Jonathan and Sheng, Yilun and Dong, Yue and Liang, Xiao and Chang, Eric I and Xu, Yan",
        "title": "Large scale image completion via co-modulated generative adversarial networks"
      },
      {
        "key": "li2022mat",
        "author": "Li, Wenbo and Lin, Zhe and Zhou, Kun and Qi, Lu and Wang, Yi and Jia, Jiaya",
        "title": "Mat: Mask-aware transformer for large hole image inpainting"
      },
      {
        "key": "suvorov2022resolution",
        "author": "Suvorov, Roman and Logacheva, Elizaveta and Mashikhin, Anton and Remizova, Anastasia and Ashukha, Arsenii and Silvestrov, Aleksei and Kong, Naejin and Goka, Harshith and Park, Kiwoong and Lempitsky, Victor",
        "title": "Resolution-robust large mask inpainting with fourier convolutions"
      },
      {
        "key": "dong2022incremental",
        "author": "Dong, Qiaole and Cao, Chenjie and Fu, Yanwei",
        "title": "Incremental transformer structure enhanced image inpainting with masking positional encoding"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "tang2024realfill",
        "author": "Tang, Luming and Ruiz, Nataniel and Chu, Qinghao and Li, Yuanzhen and Holynski, Aleksander and Jacobs, David E and Hariharan, Bharath and Pritch, Yael and Wadhwa, Neal and Aberman, Kfir and others",
        "title": "Realfill: Reference-driven generation for authentic image completion"
      },
      {
        "key": "oh2019onion",
        "author": "Oh, Seoung Wug and Lee, Sungho and Lee, Joon-Young and Kim, Seon Joo",
        "title": "Onion-peel networks for deep video completion"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "zhou2021transfill",
        "author": "Zhou, Yuqian and Barnes, Connelly and Shechtman, Eli and Amirghodsi, Sohrab",
        "title": "Transfill: Reference-guided image inpainting by merging multiple color and spatial transformations"
      },
      {
        "key": "zhao2022geofill",
        "author": "Zhao, Yunhan and Barnes, Connelly and Zhou, Yuqian and Shechtman, Eli and Amirghodsi, Sohrab and Fowlkes, Charless",
        "title": "Geofill: Reference-based image inpainting of scenes with complex geometry"
      },
      {
        "key": "zhao20223dfill",
        "author": "Zhao, Liang and Zhao, Xinyuan and Ma, Hailong and Zhang, Xinyu and Zeng, Long",
        "title": "3DFill: Reference-guided Image Inpainting by Self-supervised 3D Image Alignment"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "meng2021sdedit",
        "author": "Meng, Chenlin and He, Yutong and Song, Yang and Song, Jiaming and Wu, Jiajun and Zhu, Jun-Yan and Ermon, Stefano",
        "title": "Sdedit: Guided image synthesis and editing with stochastic differential equations"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "hertz2022prompt",
        "author": "Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel",
        "title": "Prompt-to-prompt image editing with cross attention control"
      },
      {
        "key": "mokady2023null",
        "author": "Mokady, Ron and Hertz, Amir and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel",
        "title": "Null-text inversion for editing real images using guided diffusion models"
      },
      {
        "key": "parmar2023zero",
        "author": "Parmar, Gaurav and Kumar Singh, Krishna and Zhang, Richard and Li, Yijun and Lu, Jingwan and Zhu, Jun-Yan",
        "title": "Zero-shot image-to-image translation"
      },
      {
        "key": "dalva2024fluxspace",
        "author": "Dalva, Yusuf and Venkatesh, Kavana and Yanardag, Pinar",
        "title": "FluxSpace: Disentangled Semantic Editing in Rectified Flow Transformers"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "avrahami2022blended",
        "author": "Avrahami, Omri and Lischinski, Dani and Fried, Ohad",
        "title": "Blended diffusion for text-driven editing of natural images"
      },
      {
        "key": "couairon2022diffedit",
        "author": "Couairon, Guillaume and Verbeek, Jakob and Schwenk, Holger and Cord, Matthieu",
        "title": "Diffedit: Diffusion-based semantic image editing with mask guidance"
      },
      {
        "key": "huang2023region",
        "author": "Huang, Nisha and Tang, Fan and Dong, Weiming and Lee, Tong-Yee and Xu, Changsheng",
        "title": "Region-aware diffusion for zero-shot text-driven image editing"
      },
      {
        "key": "li2024zone",
        "author": "Li, Shanglin and Zeng, Bohan and Feng, Yutang and Gao, Sicheng and Liu, Xiuhui and Liu, Jiaming and Li, Lin and Tang, Xu and Hu, Yao and Liu, Jianzhuang and others",
        "title": "Zone: Zero-shot instruction-guided local editing"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "rout2024semantic",
        "author": "Rout, Litu and Chen, Yujia and Ruiz, Nataniel and Caramanis, Constantine and Shakkottai, Sanjay and Chu, Wen-Sheng",
        "title": "Semantic image inversion and editing using rectified stochastic differential equations"
      },
      {
        "key": "wang2024taming",
        "author": "Wang, Jiangshan and Pu, Junfu and Qi, Zhongang and Guo, Jiayi and Ma, Yue and Huang, Nisha and Chen, Yuxin and Li, Xiu and Shan, Ying",
        "title": "Taming rectified flow for inversion and editing"
      },
      {
        "key": "kulikov2024flowedit",
        "author": "Kulikov, Vladimir and Kleiner, Matan and Huberman-Spiegelglas, Inbar and Michaeli, Tomer",
        "title": "FlowEdit: Inversion-Free Text-Based Editing Using Pre-Trained Flow Models"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "brooks2023instructpix2pix",
        "author": "Brooks, Tim and Holynski, Aleksander and Efros, Alexei A",
        "title": "Instructpix2pix: Learning to follow image editing instructions"
      },
      {
        "key": "sheynin2024emu",
        "author": "Sheynin, Shelly and Polyak, Adam and Singer, Uriel and Kirstain, Yuval and Zohar, Amit and Ashual, Oron and Parikh, Devi and Taigman, Yaniv",
        "title": "Emu edit: Precise image editing via recognition and generation tasks"
      },
      {
        "key": "zhang2024hive",
        "author": "Zhang, Shu and Yang, Xinyi and Feng, Yihao and Qin, Can and Chen, Chia-Chih and Yu, Ning and Chen, Zeyuan and Wang, Huan and Savarese, Silvio and Ermon, Stefano and others",
        "title": "Hive: Harnessing human feedback for instructional visual editing"
      },
      {
        "key": "zhang2024magicbrush",
        "author": "Zhang, Kai and Mo, Lingbo and Chen, Wenhu and Sun, Huan and Su, Yu",
        "title": "Magicbrush: A manually annotated dataset for instruction-guided image editing"
      },
      {
        "key": "shi2024seededit",
        "author": "Shi, Yichun and Wang, Peng and Huang, Weilin",
        "title": "SeedEdit: Align Image Re-Generation to Image Editing"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "flux2024",
        "author": "Black Forest Labs",
        "title": "FLUX"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "liu2022flow",
        "author": "Liu, Xingchao and Gong, Chengyue and Liu, Qiang",
        "title": "Flow straight and fast: Learning to generate and transfer data with rectified flow"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "esser2024scaling",
        "author": "Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\\\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others",
        "title": "Scaling rectified flow transformers for high-resolution image synthesis"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "peebles2023scalable",
        "author": "Peebles, William and Xie, Saining",
        "title": "Scalable diffusion models with transformers"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "radford2021learning",
        "author": "Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others",
        "title": "Learning transferable visual models from natural language supervision"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "raffel2020exploring",
        "author": "Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J",
        "title": "Exploring the limits of transfer learning with a unified text-to-text transformer"
      }
    ]
  },
  {
    "index": 40,
    "papers": [
      {
        "key": "fluxfill2024",
        "author": "Black Forest Labs",
        "title": "FLUX.Fill"
      }
    ]
  },
  {
    "index": 41,
    "papers": [
      {
        "key": "flux2024",
        "author": "Black Forest Labs",
        "title": "FLUX"
      }
    ]
  },
  {
    "index": 42,
    "papers": [
      {
        "key": "rombach2022high",
        "author": "Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\\\"o}rn",
        "title": "High-resolution image synthesis with latent diffusion models"
      }
    ]
  },
  {
    "index": 43,
    "papers": [
      {
        "key": "esser2024scaling",
        "author": "Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\\\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others",
        "title": "Scaling rectified flow transformers for high-resolution image synthesis"
      },
      {
        "key": "ramesh2021zero",
        "author": "Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya",
        "title": "Zero-shot text-to-image generation"
      },
      {
        "key": "saharia2022photorealistic",
        "author": "Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others",
        "title": "Photorealistic text-to-image diffusion models with deep language understanding"
      }
    ]
  },
  {
    "index": 44,
    "papers": [
      {
        "key": "hu2021lora",
        "author": "Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu",
        "title": "Lora: Low-rank adaptation of large language models"
      }
    ]
  }
]