%!TEX encoding = UTF-8 Unicode
% !TEX spellcheck = en_US

\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024
\usepackage{pgfplots}  
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
%\usepackage{url}
\usepackage{hyperref}
\usepackage[noend]{algpseudocode}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

%%% Cedric %%%
\graphicspath{{figs/}}
%\usepackage{lmodern,textcomp}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\bibliographystyle{IEEEtran}

\newcommand{\ve}[1]{ {\mathbf{#1}} }
\def\RR{\mathbb{R}}
\def\bal#1{\begin{align}#1\end{align}}

\newcommand{\ds}{\ensuremath{\mathrm{s}}}
\newcommand{\dt}{\ensuremath{\mathrm{t}}}
\newcommand{\bX}{\ensuremath{\textbf{X}}}
\def\ys{\ve{y}^{\ds}}
\def\yt{\ve{y}^{\dt}}
\def\ya{\ve{y}^{\alpha}}

\def\defequal{\stackrel{\mbox{\footnotesize def}}{=}}
\newtheorem{definition}{\textbf{Definition}}
\newtheorem{theorem}{Theorem}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\C}{\ensuremath{\mathbb{C}}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\ba}{\ensuremath{\boldsymbol{a}}}

\newcommand{\bY}{\ensuremath{\textbf{Y}}}
\newcommand{\bx}{\ensuremath{\textbf{x}}}
\newcommand{\bnx}{\bar{\ensuremath{\textbf{x}}}}
\newcommand{\Proba}{\ensuremath{\mathbb{P}}}
\DeclareMathOperator*{\argmin}{argmin}
\newcommand{\OT}{\text{OT}}

\newcommand{\ced}[1]{\textcolor{cyan}{#1}}


%%% Elsa %%%
\newcommand{\modif}[1]{\color{orange} #1} %  Modifications Elsa
\newcommand{\com}[1]{\color{blue} #1} % Commentaires Elsa

%%% David %%%
\newcommand{\dav}[1]{\color{magenta} #1} % Commentaires Elsa


%\def\mypath{/Users/cfevotte/Dropbox/RESOURCES/bib_files}
%\def\mypath{/Users/cfevotte/ownCloud\ -\ cloud.irit.fr/bib_files}

\def\mypath{'/Users/cfevotte/ownCloud - cloud.irit.fr/bib_files'}

\begin{document}
\sloppy

\title{Audio signal interpolation using optimal transportation of spectrograms\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured for https://ieeexplore.ieee.org  and
%should not be used}
\thanks{This work is supported by ANITI under the French ANR Cluster IA programme. Part of this work was conducted while Marien Renaud was a MSc intern student at IRIT.}
}

\author{\IEEEauthorblockN{David Valdivia}
\IEEEauthorblockA{\textit{IRIT, Universit\'e de Toulouse} \\
%\textit{name of organization (of Aff.)}\\
%City, Country \\
%email address or ORCID
}
\and
\IEEEauthorblockN{Marien Renaud}
\IEEEauthorblockA{\textit{IMB, Universit\'e de Bordeaux} \\
}
\and
\IEEEauthorblockN{Elsa Cazelles, C\'edric F\'evotte}
\IEEEauthorblockA{\textit{IRIT, CNRS, Universit\'e de Toulouse}}
}

\maketitle

\begin{abstract}
We present a novel approach for generating an artificial audio signal that interpolates between given source and target sounds. Our approach relies on the computation of Wasserstein barycenters of the source and target spectrograms, followed by phase reconstruction and inversion. In contrast with previous works, our new method considers the spectrograms globally and does not operate on a temporal frame-to-frame basis. An other contribution is to endow the transportation cost matrix with a specific structure that prohibits remote displacements of energy along the time axis, and for which optimal transport is made possible by leveraging the unbalanced transport framework. The proposed cost matrix makes sense from the audio perspective and also allows to reduce the computation load. Results with synthetic musical notes and real environmental sounds illustrate the potential of our novel approach. 
\end{abstract}

\begin{IEEEkeywords}
Optimal transport, time-frequency analysis, audio interpolation.
\end{IEEEkeywords}

\section{Introduction}

We consider the problem of generating artificial sounds that interpolate between given source and target signals. Though we consider audio signals in this paper (for creative and editing purposes), the methodology proposed in this paper is not limited to this class of signals. Given two temporal signals $\ys \in \RR^{L}$ (source) and $\yt \in \RR^{L}$ (target) we wish to generate an interpolant $\ya \in \RR^{L}$ (for any $\alpha \in [0,1]$) such that $\ve{y}^{0}=\ys $ and $\ve{y}^{1} =\yt$. To achieve this task, a baseline option is to compute the Euclidean barycenter of $\ys$ and $\yt$ with weights $(1-\alpha,\alpha)$ given by
\bal{
\ve{y}^{\alpha} &= \argmin_{\ve{y}} \ (1- \alpha) \, \| \ve{y} - \ve{y}^{\rm s} \|^{2}_{2}  + \alpha \, \| \ve{y} - \ve{y}^{\rm t} \|^{2}_{2} \label{eq:eucbar} \\
 & = (1-\alpha) \, \ve{y}^{\rm s} + \alpha \, \ve{y}^{\rm t} \label{eq:eucbar2}.
}
As shown by \eqref{eq:eucbar2}, the Euclidean barycenter is just a weighted average of the source and target signals. The objective of this paper is to explore an alternative option based on {\em optimal transport} (OT), that can produce truly hybrid sounds. In the proposed setting, the normalized time-frequency (t-f) distributions of the source and target signals are interpreted as discrete probability distributions supported by the t-f grid. We then propose to compute a Wasserstein barycenter \cite{Agueh2011}, also called an interpolant, of these t-f distributions. The resulting t-f barycenter may then be inverted using suitable t-f grid reassignment and phase reconstruction to obtain a temporal interpolant. We also propose to endow the transportation cost matrix with a specific structure that prohibits remote displacements of energy along the time axis, and for which optimal transport is made possible by leveraging the unbalanced transport framework. The proposed cost matrix makes sense from the audio perspective and also allows to reduce the computation load.

To the best of our knowledge, \cite{Henderson2019} is the first prior work to consider optimal transport of spectra for audio interpolation. The setting in \cite{Henderson2019} is however more restricted than ours because the authors consider the frames of the spectrogram individually (frame-to-frame OT). Furthermore, the source and target t-f  distributions result from a specific pitch-based processing of the spectrograms, which exploits the harmonic nature of tonal musical signals. Peak frequencies are identified in the source and target spectra using t-f reassignment \cite{Auger2013}. Those peak frequencies and their energy (integrated over a selected neighborhood) lay ground to the OT procedure. This approach is well suited to pitched sounds. An other prior work in audio interpolation with OT is \cite{Roma2020}. In this work, a nonnegative matrix factorization (NMF) of the source and target spectrograms is first computed \cite{Smaragdis2014}. Simplifying a little, an interpolated spectrogram is then constructed by multiplying the temporal activations of the target spectrogram with a dictionary of interpolated spectra. The latter are obtained by interpolating the source and target spectral dictionaries obtained by NMF, using the OT procedure of \cite{Henderson2019}. In contrast with the approach of \cite{Henderson2019,Roma2020}, we consider the spectrogram {\em globally}, meaning that transportation of energy is possible over neighboring time frames. Furthermore, we do not resort to any pre-processing and work directly on the raw spectrograms. This allows to work with a wider range of sounds, and in particular wide-band signals. Other technical differences related to the support of the interpolated distribution and to phase reconstruction will be discussed next.

While OT has been considered in many image processing problems, it has been less popularized in audio signal processing settings and this paper is also a step in that direction. Besides \cite{Henderson2019,Roma2020} that consider audio interpolation, other applicative examples of OT in audio signal processing are music transcription \cite{Flamary2016,Elvander2017} and audio classification \cite{Dessein2018,Cazelles2021}. The methods derived in this paper are non-supervised (the source and target signals are the only two inputs). Supervised learning-based approaches have also been considered for audio interpolation, see, e.g., \cite{Engel2019}. These approaches can produce spectacular results but rely on the intensive training of generative networks.\footnote{Audio interpolation may also refer to the tasks of filling missing gaps in a corrupted signal \cite{Godsill1998,Adler2012} or synthesizing virtual 3D sounds \cite{Radke2002}. Such tasks are not considered here but could benefit from our results in future work.}

{The paper is organized as follows. Section \ref{sec:preliminaries} introduces notations and elements of OT. We then present a first interpolation method based on Wasserstein barycenters in Section \ref{sec:method}. Some limitations of this baseline method are remedied by our second method, that relies on unbalanced OT and a structured cost matrix, as described in Section~\ref{sec:uot}. Finally, we report experiments with synthetic musical notes and real environmental sounds in Section \ref{sec:experiments}, before concluding in Section \ref{sec:conclusion}.}


%present our interpolation method in Section \ref{sec:method}, based on unbalanced OT and structured cost matrix. 




\section{Preliminaries}\label{sec:preliminaries}

\subsection{Notations}

We denote by $\bX^{\ds}$, $\bX^{\dt} \in \RR_{+}^{M \times N}$ the spectrograms of the source and target signals. They are equal to the magnitude of a short-time Fourier transform (STFT) of $\ve{y}^{\ds}$ and $\ve{y}^{\dt}$. The values of $M$ (number of frequency bins) and $N$ (number of time frames) are dictated by the length of the chosen STFT analysis window and hop size. Dropping the superscripts $\ds$ and $\dt$ for conciseness, the coefficients of the spectrogram $\bX$ are denoted by $X_{mn} \in \RR_{+}$, with $(m,n) \in \{1,\ldots, M\} \times \{1,\ldots, N\} $. The t-f couples $(m,n)$ index t-f points of the form $\omega_{mn} = (f_{m}, t_{n})$ with $f_{m} = \frac{m-1}{M} \frac{f_{s}}{2} $ and $t_{n} = (n-1)\frac{H}{f_{s}}$, where $f_{s}$ and $H$ denote the sampling frequency (Hz) and hop size (in samples).

Let us define by $\ve{x}^{\ds}$ and $\ve{x}^{\dt}$ the vectorized versions of $\bX^{\ds}$ and $\bX^{\dt}$. The vectorization underlies an arbitrary one-to-one mapping between the t-f grid $(m,n) \in \{1,\ldots, M\} \times \{1,\ldots, N\} $ and a point $i \in \{1,\dots,I\}$, with $I = MN$, such that $x^{\ds}_{i} =  X^{\ds}_{mn}$ and $x^{\dt}_{i} =  X^{\dt}_{mn}$. We will sometimes use the shorthand $\omega_{i} = \omega_{mn} $. 
%
%Let us define an arbitrary one-to-one mapping between the t-f grid $(m,n) \in \{1,\ldots, M\} \times \{1,\ldots, N\} $ and a point $i \in \{1,\dots,I\}$, with $I = MN$. Let us then define by $\ve{x}^{\ds}$ and $\ve{x}^{\dt}$ the vectorized versions of $\bX^{\ds}$ and $\bX^{\dt}$, with entries $x^{\ds}_{i} =  X^{\ds}_{mn}$ and $x^{\dt}_{i} =  X^{\dt}_{mn}$. Similarly, we will sometimes use the shorthand $\omega_{i} = \omega_{mn} $. 
%
We assume that the spectrograms have been normalized (globally), so that $\sum_{i} x^{\ds}_{i} = \sum_{i} x^{\dt}_{i} =1 $. 

\subsection{Optimal transport and Wasserstein barycenters} \label{sec:OT}

Equipped with these notations and conventions, we may view the source and target spectrograms $\bX^{\ds}$ and $\bX^{\dt}$ as discrete probability distributions $\mu^{\ds}$ and $\mu^{\dt}$ supported by the t-f points $\omega_{i}\in\R^2$, i.e.,
\begin{equation}\label{eq:tf_distribution}
\mu = \sum_{m=1}^M\sum_{n=1}^N X_{mn} \delta_{\omega_{mn}} = \sum_{i=1}^I x_{i} \delta_{\omega_{i}}
\end{equation}
where we dropped the superscripts $\ds$ or $\dt$, and where $\delta$ is the Dirac delta function. Using OT terminology, the coefficients $X_{mn}$ or $x_i$ will sometimes be referred to as ``mass".


\begin{definition} \label{Definition_1}
%Let $\mu^{\ds} = \sum_{m=1}^M{a^{\ds}_m \delta_{\omega_m}}$ and $\mu^{\dt} = \sum_{m=1}^M{a^{\dt}_m \delta_{\omega_m}}$ be two discrete probability distributions. 
The optimal transport distance, or 2-Wasserstein distance, between distributions $\mu^{\ds}$ and $\mu^{\dt}$ is given by $\sqrt{\OT \left( \mu^{\ds},\mu^{\dt} \right)}$, with
\begin{equation}
\label{eq:wass}
\OT \left( \mu^{\ds},\mu^{\dt} \right) = \min_{\textbf{P} \in \Pi(\bx^{\ds},\bx^{\dt})}{\langle \textbf{C},\textbf{P} \rangle },
\end{equation}
where $\Pi(\bx^{\ds},\bx^{\dt}):=\{ \textbf{P} \in \R^{I\times I}_{+} | \textbf{P} \textbf{1}_{I} = \bx^{\ds}, \textbf{P}^{\top}\textbf{1}_I = \bx^{\dt} \}$ is the set of transport plans $\ve{P}$ with marginals $\bx^{\ds}$ and $\bx^{\dt}$ ($\textbf{1}_I$ denotes the vector in $\R^I$ with all entries equal to one), and $\textbf{C}$ is the transportation cost matrix defined entry-wise by $C_{ii'} = \Vert\omega_i-\omega_{i'}\Vert^2$.
%\begin{itemize}
%\item $\textbf{a}^{\ds}$ : source distribution ($\textbf{a}^{\ds}$ can be identified with $\mu^{\ds}$)
%\item $\textbf{a}^{\dt}$ : the target distribution ($\textbf{a}^{\dt}$ can be identified with $\mu^{\dt}$)
%\item $\Pi_{\textbf{a}^{\ds},\textbf{a}^{\dt}} = \{ \textbf{P} \in \R^{M\times M}_{+} | \textbf{P}\textbf{1} = \textbf{a}^{\ds}, \textbf{P}^{T}\textbf{1} = \textbf{a}^{\dt} \}$
%\item $\textbf{C}$ the cost matrix, if $c$ is the cost  function, $C_{i,j} = c(x_i,x_j)$
%\end{itemize}
\end{definition}

%The definition of Wasserstein barycenters naturally follows from \eqref{eq:eucbar} and \eqref{eq:wass}.
\begin{definition}
The Wasserstein barycenter of coefficient $\alpha \in [0,1]$ between the two distributions $\mu^{\ds}$ and $\mu^{\dt}$ is defined by
\begin{equation}
\label{eq:wbar}
\mu^{\alpha} \in \argmin_{\nu} \ (1-\alpha)\, \OT\left(\mu^{\ds}, \nu \right)^2 + \alpha \, \OT\left(\mu^{\dt},\nu\right)^2. 
\end{equation}
\end{definition}
It can easily be shown with the triangular inequality that $\mu^{\alpha}$ is explicit in terms of an optimal plan $\ve{P}^\star\in\Pi(\bx^{\ds},\bx^{\dt})$ in \eqref{eq:wass}  \cite{peyre2019computational}, and is given by 
\begin{equation}
\label{eq:explicit_bar}
\mu^{\alpha} = \sum_{i,i'=1}^I P^{\star}_{ii'} \, \delta_{(1-\alpha)\omega_i+\alpha \omega_{i'}}.
\end{equation}
Note that $\ve{P}^\star$ is independent of $\alpha$.
%and that only the support of $\mu^{\alpha}$ depends on $\alpha$.


\section{Signal interpolation using time-frequency Wasserstein barycenters} \label{sec:method}


When $\mu^{\ds}$ and $\mu^{\dt}$ are the t-f distributions \eqref{eq:tf_distribution} of the source and target signals, the distribution $\mu^{\alpha}$ given by \eqref{eq:explicit_bar} defines a t-f barycenter that one might wish to invert back into the time domain in order to reconstruct an audio interpolant $\ve{y}^{\alpha}$ of $\ve{y}^{\ds}$ and $\ve{y}^{\dt}$. This simple and yet novel idea raises practical issues regarding the t-f support of $\mu^{\alpha}$ and phase reconstruction, as discussed next.

\subsection{Time-frequency reassignment} As indicated by \eqref{eq:explicit_bar}, the support of $\mu^{\alpha}$ is the set of t-f points $\omega_{ii'}^{\alpha} := (1-\alpha) \omega_{i} + \alpha \omega_{i'}$, $(i, i') \in \{ 1, \ldots, I \}^{2}$.
%$\Omega = \{ (1-\alpha) \omega_{i} + \alpha \omega_{i'}, (i, i') \in \{ 1, \ldots, I \}^{2} \}$. 
Equivalently, given $\alpha \in [0,1]$, the support of $\mu^{\alpha}$ is given by the $(MN)^{2}$ t-f points $\{ \left( (1-\alpha) f_{m} + \alpha f_{m'},(1-\alpha) t_{n} + \alpha t_{n'}   \right)\}_{mm'nn'}$.  As such, $\mu^{\alpha}$ is not supported by the same t-f grid than $\mu^{\ds}$ and $\mu^{\dt}$, it instead is spread over many more t-f points which form an irregular grid. In this paper, we choose to reconstruct a native-grid spectrogram $\ve{X}^{\alpha} \in \RR_{+}^{M \times N} $ from $\mu^{\alpha}$ by reassigning the mass $P^{\star}_{ii'}$ supported by $\omega_{ii'}^{\alpha}$ to the closest native t-f point $\omega_{j^{\star}}$, such that $j^{\star} = \argmin_{j} \| \omega_{j} - \omega_{ii'}^{\alpha} \| $.

\subsection{Phase reconstruction} Given the barycentric spectrogram $\ve{X}^{\alpha} $ reconstructed in the previous step, we use the classical Griffin and Lim phase reconstruction algorithm \cite{Griffin1983} and overlap-add inverse STFT to reconstruct a temporal signal $\ve{y}^{\alpha}$.


\subsection{Discussion}

%The bottleneck of the baseline approach presented in this section is twofold.
{The baseline approach presented at the beginning of this section presents some limitations that we now discuss. Firstly, the computation of $\ve{P}^{\star}$ in \eqref{eq:wass} might be too computationally intensive even for small-size problems corresponding to few seconds of audio. A standard remedy is to consider entropy-regularized OT, which can be solved more efficiently using the Sinkhorn algorithm \cite{Cuturi13}. Unfortunately, we found out that this solution is not desirable for spectrogram interpolation, as the entropy term tends to spread the mass of the optimal plan too smoothly, cutting out time-frequency details. Secondly, even for short audio signals, we found preferable to prevent the mass from moving to anywhere on the t-f support. As such, we propose in the next section a structured cost matrix that favors mass displacement along the frequency axis while controlling the permissible displacement over neighboring time frames. We then leverage the unbalanced OT framework to efficiently compute the corresponding optimal transport plan.}

%such as a few seconds of audio recorded at standard sampling frequency $f_{s} = 44.1$~kHz \cite{peyre2019computational}.
%in any direction within the spectrograms, regardless of their frequency content.

\section{Signal interpolation using unbalanced optimal transport and a structured cost matrix} \label{sec:uot}

\subsection{Structured cost matrix}\label{sec:cost_matrix}

{In order to produce audio results that sound more natural}, we propose to prevent remote time displacements of mass by introducing the cost matrix $\bar{\ve{C}} \in \RR_+^{I \times I}$ with coefficients
%For our audio interpolation task, we seek to prevent from remote displacements of the mass between the spectrograms, in order to maintain a consistent audio rendering. Therefore, we introduce the cost matrix $\bar{\ve{C}} \in \RR_+^{I \times I}$ with coefficients given by
%Therefore we define the cost matrix $\textbf{C}$ for $(i,i')\in\{1,\ldots,I\}^2$ and associated $(m,n)$ and $(m',n')$ in $\{1,\ldots,M\}\times\{1,\ldots,N\}$ as
\begin{equation}
    \label{eq:costC}
    \bar{C}_{ii'} = \left\{
    \begin{array}{ll}
        (f_m - f_{m'})^2 +
        (t_{n} - t_{n'})^2  & \mbox{if } |n - n'|\leq p, \\
        +\infty & \mbox{otherwise},
    \end{array}
\right.
\end{equation}
where $(f_m,t_n)$ (resp. $(f_{m'},t_{n'})$) is the t-f point mapped with $i$ (resp. $i'$). In contrast with the standard $\ell_2^2$ cost matrix $\ve{C}$ introduced in Section~\ref{sec:OT}, $\bar{\ve{C}}$ now explicitly forbids mass displacements of time range larger than $p$ frames. As our experiments will show, the user-defined parameter $p$ plays a significant role.\footnote{In practice, we use dimensionless time and frequency variables and simply set $C_{ii'} = (m-m')^2 + (n-n')^2$, and likewise for $\bar{C}_{ii'}$.} Note that when $p=0$, the cost matrix $\bar{\ve{C}}$ only allows frequency displacements in matching frames $n=n'$ (mass cannot spill over adjacent frames). This is close to the frame-to-frame setting of \cite{Henderson2019}, with the exception that in our case the spectrograms are still considered as a whole distribution (and normalized globally) as opposed to every frame being normalized like in \cite{Henderson2019}.



%in the structured cost matrix \eqref{eq:costC}, only frequency displacements are allowed, still, \eqref{eq:UOT_bar} is not equivalent to a frame-by-frame interpolation.



\subsection{Unbalanced OT and spectrogram interpolants}

%, which was originally designed to compare unnormalized distributions of different total mass,

As the proposed structured cost matrix \eqref{eq:costC} proscribes certain displacement of mass, the OT problem \eqref{eq:wass} using $\bar{\ve{C}}$ might not have a solution verifying the marginals constraint \cite{peyre2019computational}. We therefore consider unbalanced OT \cite{chizat2018unbalanced,liero2018optimal} which relaxes the conservation of mass constraints in problem \eqref{eq:wass}:
\begin{align}
\text{UOT}_\beta \left( \mu^{\ds},\mu^{\dt} \right) = \min_{\textbf{P} \in \R_+^{I\times I}}{\langle\textbf{C},\textbf{P} \rangle } &+ \beta \ \text{KL}(\textbf{P}\mathbf{1}_I, \bx^{\ds}) \nonumber\\
&+ \beta \ \text{KL}(\textbf{P}^T \mathbf{1}_I, \bx^{\dt}),
\label{eq:unbalanced_wass}
\end{align}
where $\text{KL}$ is the Kullback-Leibler divergence between nonnegative numbers, and $\beta\in\R_+$ is a parameter that controls the trade-off between mass transportation and mass creation/loss. For a large $\beta$, one recovers the OT problem \eqref{eq:wass}, whereas a small $\beta$ will encourage displacements of mass between points that are close in the t-f grid, promoting a local consistency of frequency content between the source and target spectrograms.

Following \eqref{eq:explicit_bar}, we reconstruct a t-f interpolant from an optimal solution $\ve{P}^{\beta}\in\R_+^{I\times I}$ of \eqref{eq:unbalanced_wass}:
\begin{equation}\label{eq:UOT_bar}
    \mu^{\alpha}_\beta = \sum_{i,i'=1}^I P^{\beta}_{ii'} \, \delta_{(1-\alpha)\omega_i+\alpha \omega_{i'}}.
\end{equation}
An audio interpolant $\ve{y}^{\alpha}$ is then reconstructed from $\mu^{\alpha}_\beta$ as in Section \ref{sec:method}.

%Note that for $p=0$ in the structured cost matrix \eqref{eq:costC}, only frequency displacements are allowed, still, \eqref{eq:UOT_bar} is not equivalent to a frame-by-frame interpolation.




\section{Experiments}\label{sec:experiments}

\subsection{Implementation details and experimental setting}

The interpolant \eqref{eq:explicit_bar} requires to solve the OT problem \eqref{eq:wass}, for which we used the POT toolbox \cite{flamary2021pot}. The interpolant \eqref{eq:UOT_bar} requires to solve the UOT problem \eqref{eq:unbalanced_wass}, for which we use the majorization-minimization (MM) algorithm introduced in \cite{chapel2021unbalanced}. We implemented a dedicated version of the MM algorithm that leverages the particular structure of $\bar{\ve{C}}$ in \eqref{eq:costC}. Indeed, we may only consider indices $ii'$ with finite entries $\bar{C}_{ii'}$, because $P_{ii'}^\beta= 0$ whenever $\bar{C}_{ii'}= +\infty$. This allows for an efficient implementation that can run with audio signals of up to a few seconds with standard sampling frequencies.

In the following, we presents results with synthetic musical notes and real environmental sounds. For comparison with OT and readability of the spectrograms, we use short audio signals of duration 1 second sampled at $f_s=$16kHz. The spectrograms are computed with a Hann window of duration 40ms with overlap 50\%. Audio samples and code are available online.\footnote{\url{https://davidvaldiviad.github.io/audio-signal-interpolation-ot/}}

%In our experiments, we compute the interpolants \eqref{eq:explicit_bar} and \eqref{eq:UOT_bar} by respectively solving the OT problem \eqref{eq:wass} and the UOT problem \eqref{eq:unbalanced_wass}. The OT plan is computed using the POT toolbox \cite{flamary2021pot}. We solve the UOT problem with a majorization-minimization algorithm based on multiplicative updates and proposed in \cite{chapel2021unbalanced}. We additionally leverage the structure of $\bar{\ve{C}}$ in \eqref{eq:costC} by only considering indices $ii'$ with finite entries $\bar{C}_{ii'}$, allowing fast implementation for long audios with high sampling frequency.

%In the following, we illustrate our method on synthetic musical notes and textured sounds. Musical notes are generated using the music production software Ableton Live. The audio signals are all 1 second long and sampled at 16kHz. The t-f distributions are obtained with a Hann analysis window of 40ms and an overlap of 50\%. {\modif The results can be heard at \url{}.}

\subsection{Interpolating musical notes}

Our first experiment consists in interpolating two versions of the same sequence C3-G3 played either with a piano (source) or a guitar (target). The two input signals were generated with the music production software Ableton Live. We set the interpolation parameter to $\alpha=0.5$. For the UOT-based method, we set the hyperparameter to $\beta=1$ and the time-limiting parameter to $p=0$. Results are shown in Fig. \ref{fig:melodies-interpolation}.

We observe that the structure of $\bar{\ve{C}}$ has a decisive influence on the nature of the interpolants. Since OT is {\em constrained} to move all the mass from the source to the target, some mass is spread along the time axis. This produces a continuous audio signal in which the temporal structure of the source and target signals is lost, see Fig. \ref{fig:melodies-interpolation}(c). On the other hand, by limiting the mass displacement on the time axis, UOT is able to produce an interpolant that preserves the dynamics of the input signals as seen in Fig. \ref{fig:melodies-interpolation}(d). This results in the same sequence C3-G3 played by a hybrid instrument (in between a guitar and a piano), as can be gathered from the online audio samples.


%We observe that the time-limiting parameter has a decisive influence on the quality of the interpolants. As OT \textit{has to} move all the mass from the source to the target, some mass is spread along the time axis. This produces a continuous audio signal, losing the rhythm of the original melody, see Fig. \ref{fig:melodies-interpolation}(c). On the other hand, by limiting the displacement on the time axis, UOT manages to produce interpolants that keep the dynamics of the input signals as seen in Fig. \ref{fig:melodies-interpolation}(d). The resulting audio produces the same melody C3-G3 played by a hybrid instrument between a guitar and a piano.

\begin{figure}[t]
\footnotesize
  \centering
  \begin{tabular}{c} 
    \begin{tikzpicture}
      \begin{axis}[
        width=0.8\columnwidth,
        height=0.25\columnwidth,
        % xlabel={Time (s)},
        ylabel={Frequency (kHz)},
        scale only axis,
        title={(a) Piano (source)},
        xtick={0,0.2,0.4,0.6,0.8,1},
        ytick={0,2,4,6,8},
        xmin=0, xmax=1,
        ymin=0, ymax=8,
        xlabel near ticks,
        ylabel near ticks,
        tick label style={font=\scriptsize},
        label style={font=\scriptsize},
      ]
        \addplot graphics[xmin=-0.02,xmax=1.01,ymin=-0.2,ymax=8.2] {figs/case-2-source.png};
      \end{axis}
    \end{tikzpicture}
    \\
    \begin{tikzpicture}
      \begin{axis}[
        width=0.8\columnwidth,
        height=0.25\columnwidth,
        % xlabel={Time (s)},
        ylabel={Frequency (kHz)},
        scale only axis,
        title={(b) Guitar (target)},
        xtick={0,0.2,0.4,0.6,0.8,1},
        ytick={0,2,4,6,8},
        xmin=0, xmax=1,
        ymin=0, ymax=8,
        xlabel near ticks,
        ylabel near ticks,
        tick label style={font=\scriptsize},
        label style={font=\scriptsize},
      ]
        \addplot graphics[xmin=-0.02,xmax=1.01,ymin=-0.2,ymax=8.2] {figs/case-2-target.png};
      \end{axis}
    \end{tikzpicture}
    \\
    \begin{tikzpicture}
      \begin{axis}[
        width=0.8\columnwidth,
        height=0.25\columnwidth,
        % xlabel={Time (s)},
        ylabel={Frequency (kHz)},
        scale only axis,
        title={(c) OT interpolation},
        xtick={0,0.2,0.4,0.6,0.8,1},
        ytick={0,2,4,6,8},
        xmin=0, xmax=1,
        ymin=0, ymax=8,
        xlabel near ticks,
        ylabel near ticks,
        tick label style={font=\scriptsize},
        label style={font=\scriptsize},
      ]
        \addplot graphics[xmin=-0.02,xmax=1.01,ymin=-0.2,ymax=8.2] {figs/case-2-emd-interpolation.png};
      \end{axis}
    \end{tikzpicture}
    \\
    \begin{tikzpicture}
      \begin{axis}[
        width=0.8\columnwidth,
        height=0.25\columnwidth,
        xlabel={Time (s)},
        ylabel={Frequency (kHz)},
        scale only axis,
        title={(d) UOT interpolation ($p=0$)},
        xtick={0,0.2,0.4,0.6,0.8,1},
        ytick={0,2,4,6,8},
        xmin=0, xmax=1,
        ymin=0, ymax=8,
        xlabel near ticks,
        ylabel near ticks,
        tick label style={font=\scriptsize},
        label style={font=\scriptsize},
      ]
        \addplot graphics[xmin=-0.02,xmax=1.01,ymin=-0.2,ymax=8.2] {figs/case-2-uot-interpolation.png};
      \end{axis}
    \end{tikzpicture}
  \end{tabular}
\caption{Interpolation between two versions of the same sequence of notes C3-G3 played on a piano and a guitar, using $\alpha=0.5$.}
  
  %\caption{Interpolation between a melody C3-G3 played on (a) piano (source) and (b) guitar (target) for $\alpha=0.5$. (c) OT interpolant and (d) UOT interpolant with regularization parameter $\beta=1$ and time-limiting parameter $p=0$.}
  \label{fig:melodies-interpolation}
\end{figure}

\subsection{Interpolating environmental sounds}

We now consider environmental sounds that have a more {\em textured} structure as opposed to mostly harmonic. The source is the chirp of a cicada and the target is a sample of flowing water. The cicada's chirp is characterized by strong high-frequency energy and by a clear rhythmic pattern, whereas the water flow is continuous and essentially wide-band.


%We consider here textured sounds. The source is the chirp of a cicada and the target is the sound of a flow of water. A cicada's chirp is characterized by strong high frequency energy and by a clear rhythmic pattern, whereas a water flow is continuous and has a {\modif darker sound}.

We set $\alpha=0.5$ and $\beta=1$ like in previous section, but we now explore various values of the time-limiting parameter $p$, see Fig.~\ref{fig:texture-interpolation}. Fig.~\ref{fig:texture-interpolation}(c) and Fig.~\ref{fig:texture-interpolation}(d) show that OT and UOT with $p=0$ capture essential characteristics of the input signals: the temporal structure induced by the cicada's chirp and wide-band energy content. However, Fig.~\ref{fig:texture-interpolation}(c) shows that the temporal structure of the OT interpolant is not as sharp, again because of the conservation of mass constraint. Increasing the value of $p$ for the UOT interpolant has a significant impact, see Figs.~\ref{fig:texture-interpolation}(e-f): larger values of $p$ allow for increasing temporal transportation (i.e., along the temporal axis). The perceptual impact of the value of $p$ can be assessed by listening to the audio samples available online.

%Figs.~\ref{fig:texture-interpolation}(c-f) show interpolants computed with OT and UOT with different time-limiting parameters $p$. The interpolation parameter is fixed at $\alpha=0.5$. Notice that for OT (Fig.~\ref{fig:texture-interpolation}(c)) and UOT with $p=0$ (Fig.~\ref{fig:texture-interpolation}(d)), the interpolants manage to capture essential characteristics of the input signals : the rhythm induced by the cicada's chirp and the wide-band spread energy content. However, the rhythm of the OT interpolant (Fig.~\ref{fig:texture-interpolation}(c)) is a {\modif bit blurred due to the conservation of mass constraint.}

%Increasing the time-limiting parameter $p$ for UOT interpolants has a critical impact, see Figs.~\ref{fig:texture-interpolation}(e-f). Large values of $p$ allow for more horizontal (ie. in time) transport. %while the regularization parameter $\beta$ spreads the mass in all directions.

\begin{figure}[t]
\footnotesize
  \centering
  \begin{tabular}{c} 
    \begin{tikzpicture}
      \begin{axis}[
        width=0.8\columnwidth,
        height=0.25\columnwidth,
        % xlabel={Time (s)},
        ylabel={Frequency (kHz)},
        scale only axis,
        title={(a) Cicada's chirp (source)},
        xtick={0,0.2,0.4,0.6,0.8,1},
        ytick={0,2,4,6,8},
        xmin=0, xmax=1,
        ymin=0, ymax=8,
        xlabel near ticks,
        ylabel near ticks,
        tick label style={font=\scriptsize},
        label style={font=\scriptsize},
      ]
        \addplot graphics[xmin=-0.02,xmax=1.01,ymin=-0.2,ymax=8.2] {figs/case-3-source.png};
      \end{axis}
    \end{tikzpicture}
    \\
    \begin{tikzpicture}
      \begin{axis}[
        width=0.8\columnwidth,
        height=0.25\columnwidth,
        % xlabel={Time (s)},
        ylabel={Frequency (kHz)},
        scale only axis,
        title={(b) Flowing water (target)},
        xtick={0,0.2,0.4,0.6,0.8,1},
        ytick={0,2,4,6,8},
        xmin=0, xmax=1,
        ymin=0, ymax=8,
        xlabel near ticks,
        ylabel near ticks,
        tick label style={font=\scriptsize},
        label style={font=\scriptsize},
      ]
        \addplot graphics[xmin=-0.02,xmax=1.01,ymin=-0.2,ymax=8.2] {figs/case-3-target.png};
      \end{axis}
    \end{tikzpicture}
    \\
    \begin{tikzpicture}
      \begin{axis}[
        width=0.8\columnwidth,
        height=0.25\columnwidth,
        % xlabel={Time (s)},
        ylabel={Frequency (kHz)},
        scale only axis,
        title={(c) OT interpolation},
        xtick={0,0.2,0.4,0.6,0.8,1},
        ytick={0,2,4,6,8},
        xmin=0, xmax=1,
        ymin=0, ymax=8,
        xlabel near ticks,
        ylabel near ticks,
        tick label style={font=\scriptsize},
        label style={font=\scriptsize},
      ]
        \addplot graphics[xmin=-0.02,xmax=1.01,ymin=-0.2,ymax=8.2] {figs/case-3-interpolation-emd.png};
      \end{axis}
    \end{tikzpicture}
    \\
    \begin{tikzpicture}
      \begin{axis}[
        width=0.8\columnwidth,
        height=0.25\columnwidth,
        % xlabel={Time (s)},
        ylabel={Frequency (kHz)},
        scale only axis,
        title={(d) UOT interpolation ($p=0$)},
        xtick={0,0.2,0.4,0.6,0.8,1},
        ytick={0,2,4,6,8},
        xmin=0, xmax=1,
        ymin=0, ymax=8,
        xlabel near ticks,
        ylabel near ticks,
        tick label style={font=\scriptsize},
        label style={font=\scriptsize},
      ]
        \addplot graphics[xmin=-0.02,xmax=1.01,ymin=-0.2,ymax=8.2] {figs/case-3-interpolation-p-0.png};
      \end{axis}
    \end{tikzpicture}
    \\
    \begin{tikzpicture}
      \begin{axis}[
        width=0.8\columnwidth,
        height=0.25\columnwidth,
        % xlabel={Time (s)},
        ylabel={Frequency (kHz)},
        scale only axis,
        title={(e) UOT interpolation ($p=5$)},
        xtick={0,0.2,0.4,0.6,0.8,1},
        ytick={0,2,4,6,8},
        xmin=0, xmax=1,
        ymin=0, ymax=8,
        xlabel near ticks,
        ylabel near ticks,
        tick label style={font=\scriptsize},
        label style={font=\scriptsize},
      ]
        \addplot graphics[xmin=-0.02,xmax=1.01,ymin=-0.2,ymax=8.2] {figs/case-3-interpolation-p-5.png};
      \end{axis}
    \end{tikzpicture}
    \\
    \begin{tikzpicture}
      \begin{axis}[
        width=0.8\columnwidth,
        height=0.25\columnwidth,
        xlabel={Time (s)},
        ylabel={Frequency (kHz)},
        scale only axis,
        title={(f) UOT interpolation ($p=+\infty$)},
        xtick={0,0.2,0.4,0.6,0.8,1},
        ytick={0,2,4,6,8},
        xmin=0, xmax=1,
        ymin=0, ymax=8,
        xlabel near ticks,
        ylabel near ticks,
        tick label style={font=\scriptsize},
        label style={font=\scriptsize},
      ]
        \addplot graphics[xmin=-0.02,xmax=1.01,ymin=-0.2,ymax=8.2] {figs/case-3-interpolation-p-100.png};
      \end{axis}
    \end{tikzpicture}
  \end{tabular}

\caption{Interpolation between a cicada's chirp and flowing water, using $\alpha=0.5$. Various values of the time-limiting parameter $p$ are considered. In subplot (f) we use $p=+\infty$ as a shorthand for using $\bar{\ve{C}}= \ve{C}$ (the time limit is lifted).}
  

  %\caption{Interpolation between texture sounds : (a) cicada's chirp (source) and (b) flow of water (target) for $\alpha=0.5$. We display (c) OT interpolant and UOT interpolants for regularization parameter $\beta=1$ and time-limiting parameter (d) $p=0$, (e) $p=5$ and (f) $p=+\infty$, for which $\bar{\ve{C}}= \ve{C}$.}
  \label{fig:texture-interpolation}
\end{figure}


\section{Discussion}\label{sec:conclusion}

In our opinion, our work opens promising research directions regarding the optimal transportation of spectrograms for signal processing applications. In this paper we have resorted to a t-f grid reassignment followed by standard phase retrieval to proceed to the temporal reconstruction of the interpolants. An exciting research direction would be to design inversion methods that circumvent the reassignment and work directly in the irregular grid. Another direction would be to design t-f interpolants that are constrained to be supported by the native grid. A third direction would be to leverage the phase of the source and target signals to produce better estimates of the phase of the interpolant. This latter direction in particular may further improve audio quality. 


\clearpage

% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Agueh2011}
M.~Agueh and G.~Carlier, ``Barycenters in the {W}asserstein space,'' \emph{SIAM
  Journal on Mathematical Analysis}, vol.~43, no.~2, pp. 904--924, 2011.

\bibitem{Henderson2019}
T.~Henderson and J.~Solomon, ``Audio transport: a generalized portamento via
  optimal transport,'' in \emph{Proc. International Conference on Digital Audio
  Effects (DAFx)}, 2019.

\bibitem{Auger2013}
F.~Auger, P.~Flandrin, Y.-T. Lin, S.~McLaughlin, S.~Meignen, T.~Oberlin, and
  H.-T. Wu, ``Time-frequency reassignment and synchrosqueezing: {A}n
  overview,'' \emph{IEEE Signal Processing Magazine}, vol.~30, no.~6, pp.
  32--41, 2013.

\bibitem{Roma2020}
G.~Roma, O.~Green, and P.~A. Tremblay, ``Audio morphing using matrix
  decomposition and optimal transport,'' in \emph{Proc. International
  Conference on Digital Audio Effects (DaFx)}, 2020.

\bibitem{Smaragdis2014}
P.~Smaragdis, C.~F{\'e}votte, G.~Mysore, N.~Mohammadiha, and M.~Hoffman,
  ``Static and dynamic source separation using nonnegative factorizations: {A}
  unified view,'' \emph{IEEE Signal Processing Magazine}, vol.~31, no.~3, pp.
  66--75, 2014.

\bibitem{Flamary2016}
R.~Flamary, C.~F\'evotte, N.~Courty, and V.~Emiya, ``Optimal spectral
  transportation with application to music transcription,'' in \emph{Advances
  in Neural Information Processing Systems (NIPS)}, 2016.

\bibitem{Elvander2017}
F.~Elvander, S.~I. Adalbj{\"o}rnsson, J.~Karlsson, and A.~Jakobsson, ``Using
  optimal transport for estimating inharmonic pitch signals,'' in
  \emph{Proc.~IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}, 2017, pp. 331--335.

\bibitem{Dessein2018}
A.~Dessein, N.~Papadakis, and J.-L. Rouas, ``Regularized optimal transport and
  the rot mover's distance,'' \emph{The Journal of Machine Learning Research},
  vol.~19, no.~1, pp. 590--642, 2018.

\bibitem{Cazelles2021}
E.~Cazelles, A.~Robert, and F.~Tobar, ``The {W}asserstein-fourier distance for
  stationary time series,'' \emph{IEEE Transactions on Signal Processing},
  vol.~69, pp. 709--721, 2021.

\bibitem{Engel2019}
J.~Engel, K.~K. Agrawal, S.~Chen, I.~Gulrajani, C.~Donahue, and A.~Roberts,
  ``Gansynth: {A}dversarial neural audio synthesis,'' in \emph{Proc.
  International Conference on Learning Representations (ICLR)}, 2019.

\bibitem{Godsill1998}
S.~J. Godsill and P.~J. Rayner, \emph{Digital audio restoration}.\hskip 1em
  plus 0.5em minus 0.4em\relax Springer, 1998.

\bibitem{Adler2012}
A.~Adler, V.~Emiya, M.~G. Jafari, M.~Elad, R.~Gribonval, and M.~D. Plumbley,
  ``Audio inpainting,'' \emph{IEEE Transactions on Audio, Speech, and Language
  Processing}, vol.~20, no.~3, pp. 922--932, 2012.

\bibitem{Radke2002}
R.~J. Radke and S.~Rickard, ``Audio interpolation for virtual audio
  synthesis,'' \emph{Journal of the Audio Engineering Society}, 2002.

\bibitem{peyre2019computational}
G.~Peyr{\'e} and M.~Cuturi, ``Computational optimal transport: With
  applications to data science,'' \emph{Foundations and Trends{\textregistered}
  in Machine Learning}, vol.~11, no. 5-6, pp. 355--607, 2019.

\bibitem{Griffin1983}
D.~Griffin and J.~Lim, ``Signal estimation from modified short-time {F}ourier
  transform,'' in \emph{Proc.~IEEE International Conference on Acoustics,
  Speech, and Signal Processing (ICASSP)}, vol.~8, 1983, pp. 804--807.

\bibitem{Cuturi13}
M.~Cuturi, ``Sinkhorn distances: Lightspeed computation of optimal transport,''
  in \emph{Advances in Neural Information Processing Systems}, vol.~26, 2013.

\bibitem{chizat2018unbalanced}
L.~Chizat, G.~Peyr{\'e}, B.~Schmitzer, and F.-X. Vialard, ``Unbalanced optimal
  transport: Dynamic and kantorovich formulations,'' \emph{Journal of
  Functional Analysis}, vol. 274, no.~11, pp. 3090--3123, 2018.

\bibitem{liero2018optimal}
M.~Liero, A.~Mielke, and G.~Savar{\'e}, ``Optimal entropy-transport problems
  and a new hellinger--kantorovich distance between positive measures,''
  \emph{Inventiones mathematicae}, vol. 211, no.~3, pp. 969--1117, 2018.

\bibitem{flamary2021pot}
R.~Flamary, N.~Courty, A.~Gramfort, M.~Z. Alaya, A.~Boisbunon, S.~Chambon,
  L.~Chapel, A.~Corenflos, K.~Fatras, N.~Fournier, L.~Gautheron, N.~T. Gayraud,
  H.~Janati, A.~Rakotomamonjy, I.~Redko, A.~Rolet, A.~Schutz, V.~Seguy, D.~J.
  Sutherland, R.~Tavenard, A.~Tong, and T.~Vayer, ``{POT}: Python optimal
  transport,'' \emph{Journal of Machine Learning Research}, vol.~22, no.~78,
  pp. 1--8, 2021.

\bibitem{chapel2021unbalanced}
L.~Chapel, R.~Flamary, H.~Wu, C.~F{\'e}votte, and G.~Gasso, ``Unbalanced
  optimal transport through non-negative penalized linear regression,''
  \emph{Advances in Neural Information Processing Systems (NeurIPS)}, vol.~34,
  pp. 23\,270--23\,282, 2021.

\end{thebibliography}



\end{document}








