\section{Experimental Evaluation}
\label{sec:exp}

%\subsection{Experimental Setup}
\label{sec:setup}

\noindent{\bf [Setup]} We implemented our algorithms in Python 3.9. The evaluation was conducted on a server Intel(R) Xeon(R) Gold 6242R CPU 3.10GHz (80 CPUs), with 512GB RAM.
Our code is publicly available: \url{https://github.com/boniolp/kGraph}

\begin{figure*}[tb]
 \centering
\includegraphics[width=0.97\linewidth]{figures/experiments.pdf}

 \caption{\rev{Experimental comparison of $k$-Graph versus the baselines on the UCR archive. In (a), the mean values are represented as a white square. The horizontal red dotted line represents the best mean.}}
 \vspace{-0.3cm}
 \label{fig:experiments_effectiveness_figures}

\end{figure*}

%\subsection{Experimental Configuration}
\label{sec:configuration_data_baseline}
\noindent{\bf [Datasets]} We conducted an experimental evaluation utilizing real datasets from the UCR-Archive~\cite{Dau2018TheUT} to assess the classification performance of various methods. While our proposed approach is versatile and can be evaluated on variable-length time series, the baseline methods do not share this flexibility. Therefore, out of the initial 128 datasets, we excluded 15 containing variable-length time series. Our comparative analysis involves assessing our proposed approach against the baselines on a subset of 113 real-time series datasets.
Table~\ref{tab:dataset_statistics} summarizes the characteristics of the adopted datasets, 
which represent several different scenarios. 


\begin{table}[tb]
\centering
\scalebox{0.92}{
\begin{tabular}{r|r|r|r|r}
\hline
\multicolumn{1}{l}{Dataset Type} & \multicolumn{1}{l}{\# Dataset} & \multicolumn{1}{l}{Avg. \# TS} & \multicolumn{1}{l}{Avg. Length} & \multicolumn{1}{l}{Avg. Classes} \\
\hline
AUDIO & 1 & 2110.00 & 1024.00 & 39.00 \\
DEVICE & 11 & 2428.18 & 809.27 & 3.55 \\
ECG & 7 & 2313.71 & 513.29 & 14.14 \\
EOG & 2 & 724.00 & 1250.00 & 12.00 \\
EPG & 2 & 288.50 & 601.00 & 3.00 \\
H.DYN. & 3 & 312.00 & 2000.00 & 52.00 \\
IMAGE & 31 & 1713.81 & 338.45 & 10.61 \\
MOTION & 6 & 343.83 & 899.00 & 3.83 \\
OTHER & 1 & 204.00 & 201.00 & 18.00 \\
SENSOR & 14 & 2213.64 & 348.79 & 3.07 \\
SIMUL. & 9 & 1566.33 & 255.44 & 3.89 \\
SOUND & 11 & 1982.27 & 308.18 & 6.91 \\
SPECTRO & 12 & 448.17 & 980.75 & 3.42 \\
TRAFFIC & 1 & 365.00 & 24.00 & 2.00 \\
\hline
\end{tabular}
}
\caption{UCR-Archive Dataset category Statistics}
\label{tab:dataset_statistics}
\vspace{-0.3cm}
\end{table}


\noindent{\bf [Baselines]} 
In our experimental evaluation, we consider the 15 state-of-the-art (SOTA) algorithm from each category: 
\begin{itemize}[noitemsep, topsep=1pt, parsep=1pt, partopsep=1pt, leftmargin=0.5cm]

    \item \textbf{Traditional Clustering:} We include the $k$-Means algorithm, which uses the Euclidean distance as a similarity measure. \paulJournal{We also include eight additional traditional clustering approaches for completeness which are Mean-Shift~\cite{1000236} (M.Sh. in Table~\ref{tab:effectiveness_category}), Gaussian Mixture~\cite{10.5555/1953048.2078195} (G.M. in Table~\ref{tab:effectiveness_category}), BIRCH~\cite{10.1145/233269.233324}, MiniBatch-$k$-Means~\cite{10.5555/1953048.2078195}, OPTICS~\cite{10.1145/304182.304187}, HDBSCAN~\cite{10.1007/978-3-642-37456-2_14}, DBSCAN~\cite{10.5555/3001460.3001507} and Agglomerative Clustering with a average linkage~\cite{10.5555/1953048.2078195} (Aggl. in Table~\ref{tab:effectiveness_category}). For all these baselines, we use their corresponding scikit-learn~\cite{10.5555/1953048.2078195} implementation, and we select their default parameters.}
    
    \item \textbf{Raw-based Approaches:} We select the $k$-Shape algorithm~\cite{10.1145/2949741.2949758}. This algorithm identifies the most discriminative sub-shapes of the time series to form the final cluster. \rev{In addition, we adopt SomTimeS, an algorithm that uses a self-organizing map (SOM) framework to align and compare time series with Dynamic Time Warping (DTW) as the distance measure. It enhances computational efficiency through a pruning strategy that reduces the number of DTW calculations during training.}

    \item \paulJournal{\textbf{Symbolic Approaches:} We select the Symbolic Pattern Forest algorithm (SPF)~\cite{ijcai2019-406}. The approach checks if some randomly selected symbolic patterns exist in the time series to partition the dataset. This partition process is executed multiple times, and the ensemble combines the partitions to generate the final partition.}
    
    \item \textbf{Features-based Approaches:} We choose Time2Feat~\cite{bonifati2022time2feat} (T2F in Table~\ref{tab:effectiveness_category}). This approach extracts and selects the best features from the time series, providing a fully interpretable and effective solution.

    \item \textbf{Deep Learning Approaches:} We opt for two baselines. First, the Deep Temporal Clustering (DTC) algorithm~\cite{DTCAlgorithm}. DTC uses feature representation extracted from the Deep Auto-Encoder and the Kullback-Leibler (KL) divergence objective for self-labeling of the dataset. \paulJournal{The second baseline considered is the Reservoir Model Space~\cite{bianchi2020reservoir} (called Reservoir in the rest of the paper and Res. in Table~\ref{tab:effectiveness_category}). Reservoir Computing (RC) is a family of Recurrent Neural Network (RNN) models whose recurrent part is generated randomly and then kept fixed. The representation learned with Reservoir is then fed into a traditional clustering.}

\end{itemize}


\noindent{\bf [Metrics]} We compare $k$-Graph against state-of-the-art approaches using metrics that assess how well clusters align with predefined or expected data structures by comparing them with external information like labels.
We focus on four metrics: the Adjusted Rand Index (ARI)~\cite{steinley2004properties}, Adjusted Mutual Information (AMI), Normalized Mutual Information (NMI), and Rand Index (RI).


\rev{The Adjusted Rand Index (ARI), derived from the Rand Index (RI), measures the similarity between two clusterings by counting pairs of data points in the same or different clusters. Unlike the RI, the ARI accounts for expected similarity due to chance, which is crucial for accurate results, especially in imbalanced datasets. This correction provides a more reliable measure of clustering performance, with a scale from -0.5 to 1. A value of 1 indicates perfect agreement, 0 suggests chance-level agreement and negative values indicate disagreement. By considering class balance, the ARI offers a more robust assessment of clustering similarity compared to the RI}. To enhance evaluation robustness, we also use Adjusted Mutual Information (AMI) and Normalized Mutual Information (NMI). Mutual Information (MI) measures the mutual dependence between two clusterings, but cluster sizes and numbers can influence it. NMI normalizes MI to a scale from 0 (no mutual information) to 1 (perfect correlation). AMI further adjusts MI for chance, providing a normalized measure that is useful for comparing clustering results across datasets with varying cluster sizes.




\subsection{Accuracy Evaluation}

\begin{figure}[tb]
 \centering
\includegraphics[width=\linewidth]{figures/pairwise_comp.pdf}

 \caption{Pairwise comparisons (ARI) of the top performing methods, namely, $k$-Graph, $k$-Shape, SPF, and BIRCH.}
\vspace{-0.3cm}
 \label{fig:pairwise_comp}
\end{figure}


\etitle{Presentation} Table~\ref{tab:effectiveness_category} showcases the performance of $k$-Graph compared to state-of-the-art approaches, expressed in terms of Adjusted Rand Index (ARI). The datasets are categorized as introduced in Section~\ref{sec:configuration_data_baseline}.
\paulJournal{We also include the average ARI, NMI, AMI, and RI (for the entire UCR-Archive), as well as the number of wins and the average rank (for each measure).}
The results demonstrate $k$-Graph's superior performance across various dataset types, achieving the best performance in 5 out of 13 cases and the second-best results in 2 out of 8 cases. 
Moreover, we observe that $k$-Graph outperforms the baselines on average across the entire UCR-Archive for all measures. We also note that $k$-Graph has the best average rank for AMI and ARI and is second best for RI and ARI. Finally, $k$-Graph has the most significant number of wins (i.e., number of times $k$-Graph has the best performance) for ARI, AMI, and NMI, and the second largest number of wins for RI. Figure~\ref{fig:experiments_effectiveness_figures}(a) presents ARI, AMI, NMI, and RI across all datasets, demonstrating $k$-Graph's overall improvement compared to other approaches. Figure~\ref{fig:experiments_effectiveness_figures}(b) shows the critical difference diagram using a pairwise Wilcoxon sign rank test, with methods ranked along the horizontal axis.
Figure~\ref{fig:pairwise_comp} compares $k$-Graph's ARI with top-performing methods ($k$-Shape, SPF, and BIRCH). Each point represents a dataset's performance between two methods, with the green area indicating superior performance for y-axis methods and the white area for x-axis methods. Dotted lines mark 0.1 performance difference intervals, with points outside these bands indicating significant performance differences. The average distance from the identity line indicates the magnitude of performance differences between methods.



\begin{table*}[]
\scalebox{0.79}{
\begin{tabular}{r|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}
\hline
\textbf{}                             &\textbf{$k$-Graph}& $k$-Shape    & SPF            & BIRCH          & G.M.           & MB-$k$-M.   & $k$-Means   & SomTimes & T2F & DTC & OPTICS & Reservoir & Aggl. & HDBSC. & M.Sh. & DBSC. \\ \hline
\multicolumn{17}{c}{{\it Averaged ARI per category of the UCR-Archive datasets}} \\ \hline
\multicolumn{1}{r|}{\textbf{AUDIO}}   & 0.226          & 0.223          & 0.262          & \textbf{0.392} & {\ul 0.386}    & 0.329          & 0.343       & 0.074 & 0.118 & 0.320 & 0.000 & 0.000 & -0.000 & 0.012 & -0.000 & 0.000 \\
\multicolumn{1}{r|}{\textbf{DEVICE}}  & 0.101          & 0.072          & 0.080          & 0.063          & {\ul 0.108}    & 0.094          & 0.058       & \textbf{0.117} & 0.083 & 0.058 & 0.007 & 0.016 & 0.003 & 0.015 & 0.000 & 0.001 \\
\multicolumn{1}{r|}{\textbf{ECG}}     & {\ul 0.315}    & \textbf{0.363} & 0.248          & 0.285          & 0.279          & 0.243          & 0.251       & 0.224 & 0.166 & 0.190 & 0.112 & 0.082 & 0.051 & 0.011 & 0.000 & 0.000 \\
\multicolumn{1}{r|}{\textbf{EOG}}     & 0.129          & 0.152          & 0.126          & 0.156          & \textbf{0.188} & 0.163          & {\ul 0.170} & 0.146 & 0.139 & 0.139 & 0.000 & 0.065 & 0.000 & 0.021 & 0.000 & 0.000 \\
\multicolumn{1}{r|}{\textbf{EPG}}     & 0.445          & 0.035          & 0.416          & \textbf{1.000} & \textbf{1.000} & \textbf{1.000} & 0.182       & \textbf{1.000} & 0.538 & 0.109 & {\ul 0.772} & 0.759 & \textbf{1.000} & \textbf{1.000} & 0.000 & 0.000 \\
\multicolumn{1}{r|}{\textbf{H.DYN.}}  & \textbf{0.373} & 0.037          & {\ul 0.235}    & 0.109          & 0.092          & 0.087          & 0.043       & 0.066 & 0.048 & -0.000 & 0.001 & 0.000 & 0.018 & 0.005 & 0.000 & 0.000 \\
\multicolumn{1}{r|}{\textbf{IMAGE}}   & 0.290          & {\ul 0.297}    & 0.292          & \textbf{0.299} & 0.283          & 0.249          & 0.259       & 0.238 & 0.191 & 0.176 & 0.157 & 0.105 & 0.024 & 0.064 & 0.014 & -0.000 \\
\multicolumn{1}{r|}{\textbf{MOTION}}  & \textbf{0.170} & 0.154          & {\ul 0.156}    & 0.155          & 0.123          & 0.138          & 0.141       & 0.124 & 0.090 & 0.139 & 0.048 & 0.033 & 0.034 & 0.050 & 0.000 & 0.000 \\
\multicolumn{1}{r|}{\textbf{OTHER}}   & \textbf{0.945} & 0.414          & 0.308          & {\ul 0.713}    & 0.627          & 0.668          & 0.708       & 0.212 & 0.478 & 0.295 & 0.242 & 0.000 & 0.705 & 0.056 & 0.000 & 0.000 \\
\multicolumn{1}{r|}{\textbf{SENSOR}}  & \textbf{0.352} & 0.283          & {\ul 0.337}    & 0.224          & 0.238          & 0.215          & 0.234       & 0.226 & 0.191 & 0.174 & 0.166 & 0.074 & 0.097 & 0.093 & 0.001 & -0.005 \\
\multicolumn{1}{r|}{\textbf{SIM.}}    & {\ul 0.403}    & 0.353          & 0.376          & 0.315          & 0.351          & 0.274          & 0.261       & 0.292 & \textbf{0.418} & 0.209 & 0.110 & 0.113 & 0.070 & 0.034 & 0.000 & 0.000 \\
\multicolumn{1}{r|}{\textbf{SOUND}}   & \textbf{0.044} & 0.035          & {\ul 0.041}    & 0.004          & 0.011          & 0.010          & 0.016       & 0.031 & 0.028 & 0.000 & 0.000 & 0.016 & 0.001 & 0.000 & 0.000 & 0.000 \\
\multicolumn{1}{r|}{\textbf{SPECTRO}} & 0.208          & 0.167          & \textbf{0.234} & 0.133          & 0.130          & 0.172          & {\ul 0.212} & 0.170 & 0.171 & 0.063 & 0.157 & -0.001 & 0.020 & 0.054 & 0.000 & 0.000 \\
\multicolumn{1}{r|}{\textbf{TRAFFIC}} & 0.492          & 0.676          & 0.136          & 0.461          & {\ul 0.749}    & \textbf{0.757} & 0.047       & 0.260 & -0.018 & 0.054 & 0.000 & 0.000 & 0.008 & 0.098 & 0.008 & 0.000 \\ \hline
\multicolumn{17}{c}{{\it Averaged Accuracy for each dataset of UCR-Archive}} \\ \hline
\multicolumn{1}{r|}{\textbf{RI}}      & \textbf{0.729} & 0.702          & {\ul 0.721}    & 0.697          & 0.707          & 0.700          & 0.695       & 0.688 & 0.693 & 0.630 & 0.438 & 0.467 & 0.411 & 0.464 & 0.314 & 0.317 \\
\multicolumn{1}{r|}{\textbf{ARI}}     & \textbf{0.275} & 0.237          & {\ul 0.252}    & 0.238          & 0.239          & 0.223          & 0.208       & 0.209 & 0.181 & 0.145 & 0.124 & 0.075 & 0.061 & 0.069 & 0.004 & -0.001 \\
\multicolumn{1}{r|}{\textbf{AMI}}     & \textbf{0.315} & 0.291          & 0.291          & 0.296          & {\ul 0.293}    & 0.278          & 0.256       & 0.264 & 0.230 & 0.204 & 0.161 & 0.098 & 0.093 & 0.119 & 0.005 & 0.001 \\
\multicolumn{1}{r|}{\textbf{NMI}}     & \textbf{0.335} & 0.312          & 0.312          & {\ul 0.320}    & 0.317          & 0.302          & 0.282       & 0.284 & 0.259 & 0.217 & 0.165 & 0.102 & 0.118 & 0.133 & 0.006 & 0.001 \\ \hline
\multicolumn{17}{c}{{\it Number of win on the UCR-Archive}} \\ \hline
\multicolumn{1}{r|}{\textbf{RI}}      & {\ul 22} &	8  &	\textbf{26} &	8  &	4  &	4 &	6 &	5 &	8 &	4 &	2 &	1 &	1 &	2 &	0 &	1  \\
\multicolumn{1}{r|}{\textbf{ARI}}     & \textbf{25} &	11 &	{\ul 17} &	9  &	5  &	7 &	8 &	6 &	8 &	4 &	3 &	1 &	0 &	2 &	0 &	0 \\
\multicolumn{1}{r|}{\textbf{AMI}}     & \textbf{21} &	11 &	12 &	{\ul 13} &	12 &	1 &	7 &	4 &	7 &	3 &	7 &	4 &	0 &	3 &	1 &	0 \\
\multicolumn{1}{r|}{\textbf{NMI}}     & \textbf{21} &	12 &	12 &	{\ul 13} &	11 &	1 &	6 &	4 &	7 &	3 &	7 &	4 &	0 &	4 &	1 &	0 \\
\hline
\end{tabular}}
\caption{\rev{Effectiveness (ARI, RI, AMI, and NMI) per category of the UCR-Archive, the average (of measures) across all UCR-Archive, and the number of wins (i.e., the number of time methods achieved best accuracy) on the UCR-Archive. In bold, the best value per dataset type. The underlined represents the second best result.}}
\label{tab:effectiveness_category}
\vspace{-0.4cm}
\end{table*}

\etitle{Discussion} The results indicate an enhancement in accuracy with the implementation of $k$-Graph. 
This improvement is evident when evaluating performance across different dataset types and considering the overall average across all datasets. 
Nevertheless, we observe in Figure~\ref{fig:experiments_effectiveness_figures}(b) that, across all datasets of the UCR-Archive taken individually, $k$-Graph outperforms the baselines for NMI and AMI, albeit not significantly. For ARI and RI, SPF is slightly above $k$-Graph.
\paulJournal{It is also important to note that some of the traditional baselines demonstrate strong performances (across all measures) although these approaches were specifically proposed for time series. Nevertheless, among the top performing methods (ranked first or second in Figure~\ref{fig:experiments_effectiveness_figures}(a)), 3 approaches on 4 have been proposed for time series clustering.} \rev{Moreover, we observe that $k$-Graph performance is lower than the baselines for the TRAFFIC category. The latter is composed of one dataset (Chinatown) that contains very short time series (24 data points). As k-Graph relies on extracting meaningful subsequences, such dataset with very short time series is particularly hard to handle. Consequently, we can empirically observe a potential limitation of k-Graph for very short time series.}


Furthermore, the comparison illustrated in Figure~\ref{fig:pairwise_comp} with $k$-Shape provides intriguing insights. It unveils scenarios where $k$-Graph outperforms $k$-Shape, SPF, BIRCH, and vice versa, highlighting each approach's distinctive strengths and weaknesses when applied to diverse datasets. 
The latter emphasizes two key points: (i) the importance of an adaptable and robust approach like $k$-Graph that meets the objectives outlined in the initial challenge across various datasets, and (ii) the complementary nature of $k$-Graph, $k$-Shape, and BIRCH, suggesting potential synergies for improved accuracy.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/noise_exp.pdf}
    \caption{\rev{Number of win (ratio) versus Noise (ratio) in the UCR-Archive}}
    \vspace{-0.3cm}
    \label{fig:noise_exp}
\end{figure}

\rev{We investigate the performance differences between $k$-Graph and the four best-performing baselines by assessing the impact of noise on accuracy. The noise level of datasets in the UCR-Archive is measured by the average noise ratio, defined as the ratio of the average difference between consecutive points to the maximum amplitude of the time series. We calculate the number of wins (i.e., instances where a method achieves the best ARI score) for datasets within predefined noise ratio intervals. As shown in Figure~\ref{fig:noise_exp}, the proportion of $k$-Graph wins increases with the noise ratio, reaching 68\% for time series with a noise ratio above 0.28. Overall, Figure~\ref{fig:noise_exp} indicates that $k$-Graph's efficiency is unaffected by noise and is more robust than the baselines.}


\subsection{Execution Time Evaluation}

\begin{figure}[tb]
 \centering
\includegraphics[width=0.9\linewidth]{figures/exec_time_exp.pdf}
\vspace{-0.2cm}
 \caption{Execution time computed on all datasets of the UCR-Archive.}
\vspace{-0.3cm}
 \label{fig:exec_time}
\end{figure}

\etitle{Presentation} We compare our method's execution time against other approaches, all configured for a multi-core CPU setup. To ensure consistency, we focus on methods with pure Python implementations, including Time2Feat, $k$-Shape, and DTC, \rev{but also include $k$-Means (implemented in C) for a comprehensive evaluation.} Figure~\ref{fig:exec_time} shows that $k$-Graph, $k$-Shape, and DTC have similar execution times, differing by about 10 seconds. Time2Feat is the slowest, taking 50 seconds longer, \rev{while $k$-Means is the fastest, likely due to its C implementation.}
\etitle{Discussion} The observed results indicate that extracting numerous graphs does not compromise the algorithm's efficiency, as it maintains competitive performance compared to widely adopted methods, \dt{as required by the first challenge. However, it is noteworthy that $k$-Means, employing a straightforward solution, outperforms other approaches regarding speed.}






\subsection{Parameter Influence}

\begin{figure}[tb]
 \centering
\includegraphics[width=\linewidth]{figures/parameter_influence.pdf}

 \caption{Influence of $k$-Graph parameters on (a) accuracy and (b) execution time (green hover the default values of these parameters).}
 \label{fig:param_infl}
\vspace{-0.3cm}
\end{figure}

\etitle{Presentation} As introduced in Section \ref{sec:proposed}, $k$-Graph has three main parameters: Number of Lengths ($M$) for randomly selected subsequence lengths, Sample ($smpl$) to reduce subsequences in PCA training, and Rate Maximum Length ($rml$) for the upper limit of subsequence length selection. Figure \ref{fig:param_infl} demonstrates parameter impacts across UCR Datasets, showing effectiveness (ARI) in column (a) and efficiency (seconds) in column (b). The rows show variations in $M$ (eight values), $smpl$ (five values), and $rml$ (five values) parameters respectively. For consistency, default values of $M=30$, $smpl=10$, and $rml=0.4$ are maintained when not studied.

\begin{figure}[tb]
 \centering
\includegraphics[width=\linewidth]{figures/interpretability.pdf}

 \caption{$k$-Graph interpretability for the Trace dataset from the UCR-Archive. The highlighted nodes are the most representative and exclusive subsequences identified by $k$-Graph for each cluster.}
\label{fig:interpretability}
\vspace{-0.3cm}
\end{figure}

\etitle{Discussion} The experimentation with the parameter M reveals that increasing the number of lengths positively impacts accuracy until it reaches a plateau at around $M=30$ lengths. Beyond this point, the accuracy shows little improvement. Correspondingly, as the lengths increase, the time required by the algorithm also increases, demonstrating a trade-off between accuracy and computational efficiency. A favorable balance between execution time and performance is achieved with approximately 30 different lengths. Examining the $smpl$ parameter indicates that reducing the number of subsequences minimally impacts performance until around 10. However, it significantly affects the algorithm's execution time. As we decrease the number of subsequences, the time performance improves. Achieving a good balance involves reducing the number of subsequences by 10 times. Finally, the analysis of the $rml$ parameter shows that adopting 40\%(0.4) of the length of the shortest series in the dataset as the maximum subsequence length is the optimal solution. This choice provides similar execution times while demonstrating superior performance in terms of effectiveness.


\subsection{$k$-Graph Interpretability}


\etitle{Presentation} In this section, we explore how $k$-Graph enhances the interpretability of clustering results compared to $k$-Shape. While $k$-Shape and $k$-Graph differ in interpretability---$k$-Graph offers a graph-based, subsequence-based interpretation, whereas $k$-Shape provides centroids of the same size as the dataset's time series---we still present $k$-Shape's centroids to highlight the interpretability advantage of $k$-Graph. Figure~\ref{fig:interpretability} provides visual insights using the Trace dataset from the UCR-Archive, which contains simulated time series representing various instrument failures in nuclear power plants (four classes). 
In this figure, we observe the graph $\mathcal{G}_{\bar{\ell}}$ for the optimal length $\bar{\ell}=36$, along with the most representative and exclusive nodes for each cluster ($\bar{N}_{C_1}=N^{(1)}$, $\bar{N}_{C_2}=N^{(2)}$, $\bar{N}_{C_3}=N^{(3)}$, $\bar{N}_{C_4}=N^{(4)}$).
The colored nodes in Figure~\ref{fig:interpretability}  represent those with an exclusivity above 0.9 (i.e., the $\gamma$-graphoids with $\gamma=0.9$). 

\begin{figure*}[tb]
 \centering
\includegraphics[width=\linewidth]{figures/interpretation_practice.pdf}
\vspace{-0.3cm}
 \caption{\paulJournal{Interpretability of $k$-Graph clustering applied to the CBF dataset.}}
\vspace{-0.3cm}
\label{fig:interpretability_practice}
\end{figure*}

\begin{figure}[tb]
 \centering
\includegraphics[width=\linewidth]{figures/examples_interpretability.pdf}
\vspace{-0.4cm}
 \caption{\rev{Comparisons of $k$-Graph and $k$-Shape interpretability for each cluster obtained on three UCR-Archive datasets. (*.1) centroids (in red) computed using $k$-Shape.  (*.2) most representative and exclusive node $\bar{\mathcal{N}}$.}}
\vspace{-0.5cm}
\label{fig:interpretability_ex}
\end{figure}

\etitle{Discussion} In Figure~\ref{fig:interpretability}, most nodes represent subsequences from all clusters (i.e., grey nodes), but some, like Node $ N^{(2)} $, show high representativity and exclusivity. This figure highlights $k$-Graph's interpretability capabilities, showing that its clustering partition aligns with the labels of the Trace dataset. The graphoids effectively identify the discriminant features of clusters 2, 3, and 4. Notably, Node $ N^{(4)} $ has $ |N^{(4)}|_{C_4}=1 $ and $ Pr_{C_4}(N^{(4)})=1 $, indicating it is crossed only by time series from cluster 1.

For cluster 1, the distinctive characteristic is the absence of discriminative patterns, as indicated by Node $ N^{(1)} $ with $ |N^{(1)}|_{C_1}=1 $ and $ Pr_{C_1}(N^{(1)})=0.33 $. While this node is highly representative, its low exclusivity suggests that cluster 1 lacks specific patterns, which aligns with the unique nature of class 1 in the Trace dataset. This ability to detect clusters without discriminant subsequences highlights $k$-Graph's robustness in handling diverse data structures. The representativity and exclusivity measures are crucial for users to evaluate the validity of identified nodes, providing a mechanism to filter out potential misinterpretations and ensuring that the clustering results are both meaningful and actionable.


\subsection{Interpretability in Practice}

\paulJournal{
Even though the graph can be important for the user to interact and explore the clustering result, the graph is not necessary for interpreting the clustering partition. In practice, we only need to return the most ``important" nodes (i.e., with the highest representativity and exclusivity).}

\paulJournal{
Figure~\ref{fig:interpretability_practice} depicts the $k$-Graph output on the CBF datasets (illustrated in Figure~\ref{fig:interpretability_practice}(a)).
$k$-Graph can automatically select the most representative and exclusive node for each cluster (illustrated in Figure~\ref{fig:interpretability_practice}(b)).
Each node is associated with its corresponding exclusivity ($Pr_{C_i}(N)$) and representativity ($|N|_{C_i}$) values.
These values give a direct interpretation of the clustering. For example, the high representativity ($|\bar{N_1}|_{C_1}=0.96$) and high exclusivity ($Pr_{C_1}(\bar{N_1})=0.78$) of $\bar{N_1}$ imply the following interpretation: {\it "A time series belongs to cluster 1 if and only if a subsequence of this time series is similar to $\bar{N_1}$"}. We can see indeed in Figure~\ref{fig:interpretability_practice}(a) that a subsequence of $T_1$ (called $S_1$) is similar to $\bar{N_1}$. 

On the contrary, the high representativity ($|\bar{N_3}|_{C_3}=0.96$) and medium exclusivity ($Pr_{C_3}(\bar{N_3})=0.60$) of $\bar{N_3}$ imply the following interpretation: {\it "A time series belongs to cluster 3 if a subsequence of this time series is similar to $\bar{N_3}$. However, a time series $T$ containing a subsequence similar to similar to $\bar{N_3}$ does not necessarily mean that T belongs to cluster 3"}. Figure~\ref{fig:interpretability_practice}(a) confirms that a subsequence of $T_2$ and $T_3$ (called $S'_2$ and $S_3$ respectively) are similar to $\bar{N_3}$. However, $T_2$ belongs to cluster 2, and $T_3$ belongs to cluster 3. 

In general, $k$-Graph helps us to understand that the CBF dataset is composed of (i) time series with a rapid increase followed by a slow decrease (class 1 matched by cluster 1), (ii) time series with a slow increase followed by a rapid decrease (class 2 matched by cluster 2), and (iii) time series that do not contains rapid increase or decrease, and that contain a flat subsequence (class 3 matched by cluster 3).
}

\subsection{Interpretability Examples}

\etitle{Presentation}
\paul{In Figure~\ref{fig:interpretability_ex}, we provide comparisons between $k$-Shape's and $k$-Graph's interpretability on three additional datasets of the UCR-Archive: (a) Coffee dataset with two classes, (b) DodgerLoopWeekend datasets with two classes, (c) 
FreezerRegularTrain datasets with two classes.
For $k$-Shape, interpretability is driven by inspecting the centroids of each cluster.
For $k$-Graph, we provide the most representative and exclusive nodes (due to lack of space, we omit plotting the corresponding graphs) for each cluster obtained with $k$-Graph.}


\etitle{Discussion} Figure~\ref{fig:interpretability_ex} highlights the most representative nodes for each cluster in four UCR-Archive datasets. In all cases, $k$-Graph provides clustering consistent with the labels. For DodgerLoopWeekend
(Figure~\ref{fig:interpretability_ex}(b.2)),
the nodes clearly correspond to class-specific patterns. 

In contrast, the Coffee and FreezerRegularTrain datasets (Figure~\ref{fig:interpretability_ex}(a) and (c)) present more subtle patterns. In the Coffee dataset, the nodes reveal that class differences lie in the relative heights of two central peaks. 

For FreezerRegularTrain, despite similar time series, $k$-Graph identifies nodes that highlight subtle differences in the initial increase, with cluster 2 showing a more abrupt rise and longer plateau. These nodes are highly representative and exclusive for their clusters ($|\bar{N_1}|_{C_1}=0.88$, $|\bar{N_2}|_{C_2}=0.98$ and $Pr_{C_1}(\bar{N_1})=0.98$, $Pr_{C_2}(\bar{N_2})=0.89$), aligning with discriminative features noted in the UCR-Archive~\cite{Dau2018TheUT}. These examples demonstrate the effectiveness of $k$-Graph in identifying relevant patterns for complex tasks.

\paul{Unlike $k$-Graph, the centroids computed with $k$-Shape often lack sufficient information to distinguish between classes. 
In examples, such as Coffee, DodgerLoopWeekend, and FreezerRegularTrain, distinguishing between classes is challenging. Additional comparisons on UCR-Archive datasets are available in our GitHub repository. This analysis suggests that $k$-Graph offers improved interpretability over previous solutions.} 




