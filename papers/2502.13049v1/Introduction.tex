\section{Introduction}
\label{sec:intro}
Massive collections of time series are becoming a reality in virtually every scientific and social domain~\cite{Palpanas2019,MAHDAVINEJAD2018161}. 
Thus, there is a significant need for multiple relevant applications for proposing methods that can efficiently analyze them~\cite{DBLP:journals/dagstuhl-reports/BagnallCPZ19}. 
Examples of fields that involve data series are finance, environmental sciences, astrophysics, neuroscience, engineering, multimedia, etc.~\cite{fulfillingtheneed,DBLP:journals/dagstuhl-reports/BagnallCPZ19}. 
Once collected, the major analysis tasks on  time series include pattern matching (or similarity search)~\cite{c19-isip-Palpanas-isaxfamily, DBLP:journals/tkde/PengFP21, seanet}, classification~\cite{DBLP:journals/datamine/YeK11,DBLP:conf/cikm/SchaferL17, DBLP:journals/datamine/TanPW20, inceptionTime}, clustering~\cite{DBLP:conf/sdm/UlanovaBK15,DBLP:journals/sigmod/PaparrizosG16,DBLP:conf/ijcai/Li0Z19}, anomaly detection~\cite{benchref,Series2GraphPaper,DBLP:conf/edbt/Gao0B20,normajournal,DBLP:journals/pvldb/BoniolPPF21} and motif discovery~\cite{DBLP:journals/tkde/ZhuMK21}.


Time series clustering poses a pivotal and complex challenge in data science, garnering substantial attention with many proposed algorithms in recent years. Traditional approaches hinge on distance measures, exemplified by $k$-Means clustering utilizing Euclidean or Dynamic Time Warping (DTW) distances, and the widely adopted $k$-Shape algorithm~\cite{DBLP:journals/sigmod/PaparrizosG16} serves as a prominent baseline method.
However, recent studies underscore the efficacy of feature-based methods, where clustering operates on extracted time series features, showcasing robust performance in accuracy and execution time~\cite{bonifati2022time2feat}. 
Despite their success, these methods grapple with noteworthy limitations: (i) susceptibility to noisy time series, which can compromise clustering performance, and (ii) a need for more interpretability in most solutions, hindering a comprehensive understanding of the outcomes. The last limitation is a challenging problem, especially when the important features to discover are typical subsequences that could be a grouping criterion for a given cluster. Therefore, identifying such subsequences and providing an interpretable representation of the clustering partitions to the user is essential to enhance the usage and maximize the understanding and trust of unsupervised clustering in time series applications. Unfortunately, none of the existing methods allow a straightforward solution for this problem.

This paper introduces $k$-Graph, a novel graph-based \rev{univariate time series } clustering method that aims to overcome the shortcomings of existing approaches and the problems mentioned above. \rev{To the best of our knowledge, $k$-Graph is the first approach proposing a graph-based representation of the time series for the purpose of clustering. Overall, }
$k$-Graph is based on a four-step process: The first step involves \textbf{Graph Embedding} where several graphs are computed leveraging an adapted Series2Graph algorithm~\cite{Series2GraphPaper}. Each graph encapsulates groups of similar subsequences within a dataset, with nodes representing these groups and edges carrying weights based on sequence occurrences. Moving forward, in the \textbf{Graph Clustering} phase, features are extracted for time series using the graph nodes and edges. The $k$-Means algorithm is then applied for clustering based on these features. Next, spectral clustering is deployed in \textbf{Consensus Clustering} to establish consensus across the multiple partitions obtained in the previous step. This step yields the final labels assigned by $k$-Graph. Lastly, the most relevant graph is selected in \textbf{Interpretability Computation}, and graphoids are computed to enhance interpretability \paulJournal{(examples of graphoids for the Trace dataset~\cite{Dau2018TheUT} are depicted in Figure~\ref{fig:intro})}. This step contributes to a more profound understanding of the clustering outcomes.

\begin{figure}[tb]
 \centering
\includegraphics[width=\linewidth]{figures/fig_intro.pdf}
 \caption{$k$-Graph resulting graph $\mathcal{G}$ when applied on the Trace dataset~\cite{Dau2018TheUT}}
 \vspace{-0.3cm}
 \label{fig:intro}
\end{figure}

Our contributions are as follows:
\begin{enumerate}
    \item We provide a new problem formulation for graph embedding for time series clustering (Section~\ref{sec:Probdef}). We formalize the concept of interpretability regarding clustering with graph representation of time series and how to measure it.
    \item We propose a novel graph embedding method for \rev{univariate time series } clustering. The latter can be used on time series of variable length and provides through the graph an interpretable interface for the user to dive into the time series datasets and extract meaningful patterns that compose the different clusters (Section~\ref{sec:proposed}).
    \item We demonstrate that our proposed approach is at least equalling and outperforming under certain scenarios, the current state-of-the-art clustering methods for time series, and being of the same order of magnitude regarding execution time (Section~\ref{sec:exp}).
    \item In addition to being as accurate and as expensive to compute, we demonstrate through multiple examples on real world datasets the interpretability power of $k$-Graph, and the usefulness of the graph for knowledge discovery tasks (Section~\ref{sec:exp}).
    \item We provide an open-source implementation of our approach (\url{https://github.com/boniolp/kGraph}). 
\end{enumerate}

We conclude by discussing the implications of our work and exploring future directions to enhance the accuracy, execution time, and interpretability of our proposed method (Section~\ref{sec:conclusions}). 
