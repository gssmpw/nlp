[
  {
    "index": 0,
    "papers": [
      {
        "key": "wei2022emergent",
        "author": "Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others",
        "title": "Emergent abilities of large language models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "wang2021simvlm",
        "author": "Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan",
        "title": "Simvlm: Simple visual language model pretraining with weak supervision"
      },
      {
        "key": "ju2022prompting",
        "author": "Ju, Chen and Han, Tengda and Zheng, Kunhao and Zhang, Ya and Xie, Weidi",
        "title": "Prompting visual-language models for efficient video understanding"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "dang2023clip",
        "author": "Dang, Xuzhe and Edelkamp, Stefan and Ribault, Nicolas",
        "title": "CLIP-Motion: Learning reward functions for robotic actions using consecutive observations"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chen2024vision",
        "author": "Chen, William and Mees, Oier and Kumar, Aviral and Levine, Sergey",
        "title": "Vision-language models provide promptable representations for reinforcement learning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "sumers2023distilling",
        "author": "Sumers, Theodore and Marino, Kenneth and Ahuja, Arun and Fergus, Rob and Dasgupta, Ishita",
        "title": "Distilling internet-scale vision-language models into embodied agents"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "fu2024furl",
        "author": "Fu, Yuwei and Zhang, Haichao and Wu, Di and Xu, Wei and Boulet, Benoit",
        "title": "FuRL: Visual-Language Models as Fuzzy Rewards for Reinforcement Learning"
      },
      {
        "key": "rocamonde2023vision",
        "author": "Rocamonde, Juan and Montesinos, Victoriano and Nava, Elvis and Perez, Ethan and Lindner, David",
        "title": "Vision-language models are zero-shot reward models for reinforcement learning"
      },
      {
        "key": "wang2024rl",
        "author": "Wang, Yufei and Sun, Zhanyi and Zhang, Jesse and Xian, Zhou and Biyik, Erdem and Held, David and Erickson, Zackory",
        "title": "Rl-vlm-f: Reinforcement learning from vision language foundation model feedback"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "cui2022can",
        "author": "Cui, Yuchen and Niekum, Scott and Gupta, Abhinav and Kumar, Vikash and Rajeswaran, Aravind",
        "title": "Can foundation models perform zero-shot task specification for robot manipulation?"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "mahmoudieh2022zero",
        "author": "Mahmoudieh, Parsa and Pathak, Deepak and Darrell, Trevor",
        "title": "Zero-shot reward specification via grounded natural language"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "sontakke2024roboclip",
        "author": "Sontakke, Sumedh and Zhang, Jesse and Arnold, S{\\'e}b and Pertsch, Karl and B{\\i}y{\\i}k, Erdem and Sadigh, Dorsa and Finn, Chelsea and Itti, Laurent",
        "title": "Roboclip: One demonstration is enough to learn robot policies"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "mguni2021ligs",
        "author": "Mguni, David Henry and Jafferjee, Taher and Wang, Jianhong and Slumbers, Oliver and Perez-Nieves, Nicolas and Tong, Feifei and Yang, Li and Zhu, Jiangcheng and Yang, Yaodong and Wang, Jun",
        "title": "Ligs: Learnable intrinsic-reward generation selection for multi-agent learning"
      },
      {
        "key": "ma2022elign",
        "author": "Ma, Zixian and Wang, Rose and Li, Fei-Fei and Bernstein, Michael and Krishna, Ranjay",
        "title": "Elign: Expectation alignment as a multi-agent intrinsic reward"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "csimcsek2006intrinsic",
        "author": "Simsek, Ozgur and Barto, Andrew G",
        "title": "An intrinsic reward mechanism for efficient exploration"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "ng1999policy",
        "author": "Ng, Andrew Y and Harada, Daishi and Russell, Stuart",
        "title": "Policy invariance under reward transformations: Theory and application to reward shaping"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "devlin2012dynamic",
        "author": "Devlin, Sam Michael and Kudenko, Daniel",
        "title": "Dynamic potential-based reward shaping"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "grzes2017reward",
        "author": "Grzes, Marek",
        "title": "Reward shaping in episodic reinforcement learning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "chen2022knowledge",
        "author": "Chen, Min and Pu, Zhiqiang and Pan, Yi and Yi, Jianqiang",
        "title": "Knowledge transfer from situation evaluation to multi-agent reinforcement learning"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "zhang2023multiexperience",
        "author": "Zhang, Tianle and Liu, Zhen and Yi, Jianqiang and Wu, Shiguang and Pu, Zhiqiang and Zhao, Yanjie",
        "title": "Multiexperience-Assisted Efficient Multiagent Reinforcement Learning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "samvelyan2019starcraft",
        "author": "Samvelyan, Mikayel and Rashid, Tabish and De Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon",
        "title": "The starcraft multi-agent challenge"
      }
    ]
  }
]