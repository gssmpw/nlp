@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@inproceedings{xu2018multi,
  title={Multi-vehicle flocking control with deep deterministic policy gradient method},
  author={Xu, Zhao and Lyu, Yang and Pan, Quan and Hu, Jinwen and Zhao, Chunhui and Liu, Shuai},
  booktitle={2018 IEEE 14th International Conference on Control and Automation (ICCA)},
  pages={306--311},
  year={2018},
  organization={IEEE}
}

@techreport{yang2004multiagent,
  title={Multiagent reinforcement learning for multi-robot systems: A survey},
  author={Yang, Erfu and Gu, Dongbing},
  year={2004},
  institution={tech. rep}
}

@inproceedings{liu2023lazy,
  title={Lazy agents: a new perspective on solving sparse reward problem in multi-agent reinforcement learning},
  author={Liu, Boyin and Pu, Zhiqiang and Pan, Yi and Yi, Jianqiang and Liang, Yanyan and Zhang, Du},
  booktitle={International Conference on Machine Learning},
  pages={21937--21950},
  year={2023},
  organization={PMLR}
}

@article{zhu2018human,
  title={Human-like autonomous car-following model with deep reinforcement learning},
  author={Zhu, Meixin and Wang, Xuesong and Wang, Yinhai},
  journal={Transportation research part C: emerging technologies},
  volume={97},
  pages={348--368},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{dossa2019human,
  title={A human-like agent based on a hybrid of reinforcement and imitation learning},
  author={Dossa, Rousslan Fernand Julien and Lian, Xinyu and Nomoto, Hirokazu and Matsubara, Takashi and Uehara, Kuniaki},
  booktitle={2019 international joint conference on neural networks (IJCNN)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}

@inproceedings{kurach2020google,
  title={Google research football: A novel reinforcement learning environment},
  author={Kurach, Karol and Raichuk, Anton and Sta{\'n}czyk, Piotr and Zaj{\k{a}}c, Micha{\l} and Bachem, Olivier and Espeholt, Lasse and Riquelme, Carlos and Vincent, Damien and Michalski, Marcin and Bousquet, Olivier and others},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={4501--4510},
  year={2020}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={1--35},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@incollection{csikszentmihalyi2015intrinsic,
  title={Intrinsic rewards and emergent motivation},
  author={Csikszentmihalyi, Mihaly},
  booktitle={The hidden costs of reward},
  pages={205--216},
  year={2015},
  publisher={Psychology Press}
}

@inproceedings{xiao2023chain,
  title={Chain-of-Experts: When LLMs Meet Complex Operations Research Problems},
  author={Xiao, Ziyang and Zhang, Dongxiang and Wu, Yangjun and Xu, Lilin and Wang, Yuan Jessica and Han, Xiongwei and Fu, Xiaojin and Zhong, Tao and Zeng, Jia and Song, Mingli and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{qian2023communicative,
  title={Communicative agents for software development},
  author={Qian, Chen and Cong, Xin and Yang, Cheng and Chen, Weize and Su, Yusheng and Xu, Juyuan and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2307.07924},
  year={2023}
}

@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{adeniji2023language,
  title={Language reward modulation for pretraining reinforcement learning},
  author={Adeniji, Ademi and Xie, Amber and Sferrazza, Carmelo and Seo, Younggyo and James, Stephen and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2308.12270},
  year={2023}
}

@article{rocamonde2023vision,
  title={Vision-language models are zero-shot reward models for reinforcement learning},
  author={Rocamonde, Juan and Montesinos, Victoriano and Nava, Elvis and Perez, Ethan and Lindner, David},
  journal={arXiv preprint arXiv:2310.12921},
  year={2023}
}

@article{baumli2023vision,
  title={Vision-Language Models as a Source of Rewards},
  author={Baumli, Kate and Baveja, Satinder and Behbahani, Feryal and Chan, Harris and Comanici, Gheorghe and Flennerhag, Sebastian and Gazeau, Maxime and Holsheimer, Kristian and Horgan, Dan and Laskin, Michael and others},
  journal={arXiv preprint arXiv:2312.09187},
  year={2023}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@article{wang2021simvlm,
  title={Simvlm: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={arXiv preprint arXiv:2108.10904},
  year={2021}
}

@inproceedings{ju2022prompting,
  title={Prompting visual-language models for efficient video understanding},
  author={Ju, Chen and Han, Tengda and Zheng, Kunhao and Zhang, Ya and Xie, Weidi},
  booktitle={European Conference on Computer Vision},
  pages={105--124},
  year={2022},
  organization={Springer}
}

@article{fu2024furl,
  title={FuRL: Visual-Language Models as Fuzzy Rewards for Reinforcement Learning},
  author={Fu, Yuwei and Zhang, Haichao and Wu, Di and Xu, Wei and Boulet, Benoit},
  journal={arXiv preprint arXiv:2406.00645},
  year={2024}
}

@article{wang2024rl,
  title={Rl-vlm-f: Reinforcement learning from vision language foundation model feedback},
  author={Wang, Yufei and Sun, Zhanyi and Zhang, Jesse and Xian, Zhou and Biyik, Erdem and Held, David and Erickson, Zackory},
  journal={arXiv preprint arXiv:2402.03681},
  year={2024}
}

@article{dang2023clip,
  title={CLIP-Motion: Learning reward functions for robotic actions using consecutive observations},
  author={Dang, Xuzhe and Edelkamp, Stefan and Ribault, Nicolas},
  journal={arXiv preprint arXiv:2311.03485},
  year={2023}
}

@article{chen2024vision,
  title={Vision-language models provide promptable representations for reinforcement learning},
  author={Chen, William and Mees, Oier and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2402.02651},
  year={2024}
}

@article{sontakke2024roboclip,
  title={Roboclip: One demonstration is enough to learn robot policies},
  author={Sontakke, Sumedh and Zhang, Jesse and Arnold, S{\'e}b and Pertsch, Karl and B{\i}y{\i}k, Erdem and Sadigh, Dorsa and Finn, Chelsea and Itti, Laurent},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{sumers2023distilling,
  title={Distilling internet-scale vision-language models into embodied agents},
  author={Sumers, Theodore and Marino, Kenneth and Ahuja, Arun and Fergus, Rob and Dasgupta, Ishita},
  journal={arXiv preprint arXiv:2301.12507},
  year={2023}
}

@inproceedings{cui2022can,
  title={Can foundation models perform zero-shot task specification for robot manipulation?},
  author={Cui, Yuchen and Niekum, Scott and Gupta, Abhinav and Kumar, Vikash and Rajeswaran, Aravind},
  booktitle={Learning for dynamics and control conference},
  pages={893--905},
  year={2022},
  organization={PMLR}
}

@inproceedings{mahmoudieh2022zero,
  title={Zero-shot reward specification via grounded natural language},
  author={Mahmoudieh, Parsa and Pathak, Deepak and Darrell, Trevor},
  booktitle={International Conference on Machine Learning},
  pages={14743--14752},
  year={2022},
  organization={PMLR}
}

@article{puterman1990markov,
  title={Markov decision processes},
  author={Puterman, Martin L},
  journal={Handbooks in Operations Research and Management Science},
  volume={2},
  pages={331--434},
  year={1990},
  publisher={Elsevier}
}

@article{zhang2024vision,
  title={Vision-language models for vision tasks: A survey},
  author={Zhang, Jingyi and Huang, Jiaxing and Jin, Sheng and Lu, Shijian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{csimcsek2006intrinsic,
  title={An intrinsic reward mechanism for efficient exploration},
  author={Simsek, Ozgur and Barto, Andrew G},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={833--840},
  year={2006}
}

@article{mguni2021ligs,
  title={Ligs: Learnable intrinsic-reward generation selection for multi-agent learning},
  author={Mguni, David Henry and Jafferjee, Taher and Wang, Jianhong and Slumbers, Oliver and Perez-Nieves, Nicolas and Tong, Feifei and Yang, Li and Zhu, Jiangcheng and Yang, Yaodong and Wang, Jun},
  journal={arXiv preprint arXiv:2112.02618},
  year={2021}
}

@inproceedings{badnava2023new,
  title={A new potential-based reward shaping for reinforcement learning agent},
  author={Badnava, Babak and Esmaeili, Mona and Mozayani, Nasser and Zarkesh-Ha, Payman},
  booktitle={2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC)},
  pages={01--06},
  year={2023},
  organization={IEEE}
}

@inproceedings{wierstra2008episodic,
  title={Episodic reinforcement learning by logistic reward-weighted regression},
  author={Wierstra, Daan and Schaul, Tom and Peters, Jan and Schmidhuber, Juergen},
  booktitle={International Conference on Artificial Neural Networks},
  pages={407--416},
  year={2008},
  organization={Springer}
}

@inproceedings{chen2022knowledge,
  title={Knowledge transfer from situation evaluation to multi-agent reinforcement learning},
  author={Chen, Min and Pu, Zhiqiang and Pan, Yi and Yi, Jianqiang},
  booktitle={International Conference on Neural Information Processing},
  pages={3--14},
  year={2022},
  organization={Springer}
}

@article{zhang2023multiexperience,
  title={Multiexperience-Assisted Efficient Multiagent Reinforcement Learning},
  author={Zhang, Tianle and Liu, Zhen and Yi, Jianqiang and Wu, Shiguang and Pu, Zhiqiang and Zhao, Yanjie},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}

@article{harrop2014performance,
  title={Performance indicators that predict success in an English professional League One soccer team},
  author={Harrop, Kerys and Nevill, Alan},
  journal={International Journal of Performance Analysis in Sport},
  volume={14},
  number={3},
  pages={907--920},
  year={2014},
  publisher={Taylor \& Francis}
}

@article{simon1955behavioral,
  title={A behavioral model of rational choice},
  author={Simon, Herbert A},
  journal={The quarterly journal of economics},
  pages={99--118},
  year={1955},
  publisher={JSTOR}
}

@article{yu2022surprising,
  title={The surprising effectiveness of ppo in cooperative multi-agent games},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24611--24624},
  year={2022}
}

@inproceedings{kuba2022trust,
  title={Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning},
  author={Kuba, JG and Chen, R and Wen, M and Wen, Y and Sun, F and Wang, J and Yang, Y},
  booktitle={ICLR 2022-10th International Conference on Learning Representations},
  pages={1046},
  year={2022},
  organization={The International Conference on Learning Representations (ICLR)}
}

@article{de2020independent,
  title={Is independent learning all you need in the starcraft multi-agent challenge?},
  author={De Witt, Christian Schroeder and Gupta, Tarun and Makoviichuk, Denys and Makoviychuk, Viktor and Torr, Philip HS and Sun, Mingfei and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2011.09533},
  year={2020}
}

@inproceedings{bolander2018better,
  title={Better eager than lazy? How agent types impact the successfulness of implicit coordination},
  author={Bolander, Thomas and Engesser, Thorsten and Mattm{\"u}ller, Robert and Nebel, Bernhard},
  booktitle={Sixteenth International Conference on Principles of Knowledge Representation and Reasoning},
  year={2018}
}

@article{gu2023safe,
  title={Safe multi-agent reinforcement learning for multi-robot control},
  author={Gu, Shangding and Kuba, Jakub Grudzien and Chen, Yuanpei and Du, Yali and Yang, Long and Knoll, Alois and Yang, Yaodong},
  journal={Artificial Intelligence},
  volume={319},
  pages={103905},
  year={2023},
  publisher={Elsevier}
}

@article{abi2024scaling,
  title={Scaling instructable agents across many simulated worlds},
  author={Abi Raad, Maria and Ahuja, Arun and Barros, Catarina and Besse, Frederic and Bolt, Andrew and Bolton, Adrian and Brownfield, Bethanie and Buttimore, Gavin and Cant, Max and Chakera, Sarah and others},
  journal={arXiv e-prints},
  pages={arXiv--2404},
  year={2024}
}

@article{samvelyan2019starcraft,
  title={The starcraft multi-agent challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and De Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1902.04043},
  year={2019}
}

@article{ma2022elign,
  title={Elign: Expectation alignment as a multi-agent intrinsic reward},
  author={Ma, Zixian and Wang, Rose and Li, Fei-Fei and Bernstein, Michael and Krishna, Ranjay},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8304--8317},
  year={2022}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={Icml},
  volume={99},
  pages={278--287},
  year={1999}
}

@inproceedings{wiewiora2003principled,
  title={Principled methods for advising reinforcement learning agents},
  author={Wiewiora, Eric and Cottrell, Garrison W and Elkan, Charles},
  booktitle={Proceedings of the 20th international conference on machine learning (ICML-03)},
  pages={792--799},
  year={2003}
}

@inproceedings{devlin2012dynamic,
  title={Dynamic potential-based reward shaping},
  author={Devlin, Sam Michael and Kudenko, Daniel},
  booktitle={11th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2012)},
  pages={433--440},
  year={2012},
  organization={IFAAMAS}
}

@inproceedings{grzes2017reward,
  title={Reward shaping in episodic reinforcement learning},
  author={Grzes, Marek},
  booktitle={Sixteenth International Conference on Autonomous Agents and Multiagent Systems},
  pages={565–-573},
  year={2017},
  organization={ACM}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}