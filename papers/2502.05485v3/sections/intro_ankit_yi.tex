\section{Introduction}


%%%%%% Hierarchical Action Model Story

\ankit{Large action models are looking promising for open world manipulation -- Talk about RTs, Octo, OpenVLA -- what large action models promise}

\ankit{Limitations in building large action models -- requires lots of data -- sim2real hasn't worked with them either -- they are also not very precise as compared to smaller skill specific models like RVT-2 -- huge compute requirements, latency issues}

\ankit{However, we have able to utilize internet scale data to create VLMs -- therefore can be we do something that allows us to use all this advancement to deliver open-world manipulation capabilities}

\ankit{Our proposal -- A hierarchical design that allows for much flexibility -- communication via an informed trajectory -- decouples the perception + semantic understanding from low level actions }

\ankit{We study an instantiation of this idea and show -- results -- highlight how we can use low-cost data / sim data -- highlight latency advantages}

\ankit{Contrast our work with others including RT-Trajectory}

\ankit{Summarize Contributions - General Hierarchical Design -- Explore the advantages and design choices for this design - Do experiments comparing stuff}

%%%%%% Cheap Data Story

\yi{I think maybe we can focus the story on cheap data and expensive data? A draft as below.}

Title \#1: Divide and Conquer: A Two-Part Framework for Data-Efficient and Generalizable Robotic Learning

\yi{maybe RoboDC: Data-Efficient and Generalizable Robotic Learning in a Divide and Conquer way}

Title \#2: Maximizing Generalization with Minimal Teleoperation Data: A Dual-Module Approach

Title \#3: Leveraging Inexpensive Data for Precision and Generalization in Robotic Skill Acquisition

Recent advances in robotic learning have seen VLA frameworks (cite RT-1, RT-2, RT-X, OpenVLA) achieve remarkable success, demonstrating strong generalization capabilities. However, a significant limitation of these VLA-style models are their reliance on large amounts of teleoperation data—typically hundreds of demonstrations—to learn new skills. 
\caelan{Express in terms of reported human hours and/or monetary cost, e.g. Google collected 18 months of data with a large team of human contractors for RT-1}
Despite various efforts to streamline this data collection process (cite ALOHA, AR2D2, UMI), these methods often still require access to real-world environments, special requirements and even the involvement of professional operators, which restricts the scalability of data collection compared to fields like computer vision or natural language processing, where tasks can be easily outsourced to large-scale annotators.

In contrast, behavior cloning methods such as RVT and 3DDA have shown that new skills can be learned with much smaller datasets—on the order of tens of demonstrations. \caelan{``In contrast'' - RT-1 is a BC approach} \caelan{RVT as published isn't really a high-frequency BC approach (waypoints)}
\yi{maybe we can also talk about some RL method which can learn do sim2real?} However, these approaches suffer from poor generalization and a lack of semantic understanding, limiting their ability to handle diverse or unseen tasks.
\caelan{Low task diversity in practice}

In this paper, we propose a novel framework that addresses the shortcomings of both approaches by dividing the problem into two parts. The first part, a high-level module, leverages large amounts of inexpensive data and is responsible for perception, language understanding, and planning. 
The second part, a shallow execution head, uses a limited amount of expensive data to perform accurate and robust actions based on high-level instructions. This combination allows our system to achieve strong generalization with minimal expensive data, similar to OpenVLA, while retaining the precision and robustness of behavior cloning methods.
\caelan{Define inexpensive and expensive}

\textbf{The main contributions of this paper are as follows:}
\begin{itemize}
    \item We propose a framework that strategically separates data into inexpensive and expensive sources, demonstrating that this approach reduces the need for costly teleoperation data while maintaining competitive performance.
    \item We show that our framework achieves the strong generalization ability of OpenVLA while retaining the accuracy and robustness of behavior cloning methods.
    \item We demonstrate that our method can also benefit from simulated data—another source of inexpensive data—by successfully transferring skills learned in simulation to real-world tasks.
\end{itemize}

\caelan{Needs more specifies (e.g. the trajectory prediction process)}