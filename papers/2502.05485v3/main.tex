
\documentclass{article} % For LaTeX2e
%\usepackage{iclr2025_conference,times} camera ready
\usepackage{arxiv,times} % arxiv without "published as a ..." left header
\PassOptionsToPackage{numbers, compress}{natbib}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
\usepackage{enumitem}

\usepackage{booktabs}
\usepackage{pifont}
\usepackage{graphicx}
\usepackage{dsfont}
\usepackage{wrapfig}
\usepackage{mdframed}
\usepackage{cleveref}
\usepackage{multirow} % Add this in the preamble

\definecolor{customRed}{RGB}{190,110,113}
\definecolor{darkBlue}{RGB}{10,50,220}
\hypersetup{
	colorlinks=true,
	linkcolor=cyan,
	filecolor=magenta,      
	urlcolor=cyan,
	%citecolor=orange,
    citecolor=customRed,
}

\newcommand{\cmark}{\ding{51}} % Check mark
\newcommand{\xmark}{\ding{55}} % Cross mark

\title{
% Hybrid Simulation and Real Hierarchical \\ Policy Learning for Robot Manipulation
\method: Hierarchical Action Models for Open-World Robot Manipulation
}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

% rememeber to remove raymond in the camera-ready version
\iclrfinalcopy
\author{
    Yi Li$^{\star\ddag 1, 2}$, Yuquan Deng$^{\star 2}$, Jesse Zhang$^{\star 1, 3}$, Joel Jang$^{1, 2}$, Marius Memmel$^{2}$, Raymond Yu$^{2}$ \\ \textbf{ Caelan Garrett$^{1}$, Fabio Ramos$^{1}$, Dieter Fox$^{1,2}$, Anqi Li$^{\dag 1}$, Abhishek Gupta$^{\dag 1,2}$, Ankit Goyal$^{\dag 1}$} \\
$^{1}$NVIDIA \ $^{2}$University of Washington \ $^{3}$University of Southern California
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand{\method}{HAMSTER}
\newcommand{\methodlong}{\textbf{H}ierarchical \textbf{A}ction \textbf{M}odels with \textbf{S}epara\textbf{TE}d Path \textbf{R}epresentations}
\newcommand{\targetdata}{\mathcal{D}_T}
\newcommand{\vlmdata}{\mathcal{D}_\text{off}}

\newcommand{\caelan}[1]{\textcolor{blue}{(Caelan: #1)}}
\newcommand{\yi}[1]{\textcolor{purple}{(Yi: #1)}}
\newcommand{\ankit}[1]{\textcolor{red}{(Ankit: #1)}}
\newcommand{\anqi}[1]{\textcolor{orange}{(Anqi: #1)}}
\newcommand{\ag}[1]{\textcolor{cyan}{(AG: #1)}}
\newcommand{\jz}[1]{\textcolor{green}{(JZ: #1)}}
% \newcommand{\rpm}{\tiny \raisebox{.2ex}{$\scriptstyle\pm~$}}
% \newcommand{\rpmh}{\huge \raisebox{.2ex}{$\scriptstyle\pm~$}}
% \newcommand{\rpmx}{\small \raisebox{.2ex}{$\scriptstyle\pm~$}}

%\newcommand{\caelan}[1]{}
%\newcommand{\yi}[1]{}
%\newcommand{\ankit}[1]{}
%\newcommand{\anqi}[1]{}
%\newcommand{\ag}[1]{}
%\newcommand{\jz}[1]{}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
\input{sections/abstract}
\end{abstract}

{\let\thefootnote\relax\footnotetext{$^\star$ co-first authors $^\ddag$ project lead $^\dag$ equal advising}}
\input{sections/intro_camera_ready}
% \input{sections/intro_ag}
\input{sections/related_work_al}
\input{sections/prelim}
\input{sections/method}
\input{sections/experiments}
\vspace{-2mm}
\section{Conclusion and Limitations}
\vspace{-2mm}
In summary, \method\ studies the potential of hierarchical VLA models, achieving robust generalization in robotic manipulation. It consists of a finetuned VLM that accurately predicts 2D paths for robotic manipulation and a low-level policy that learns to generate actions using the 2D paths. This two-step architecture enables visual generalization and semantic reasoning across considerable domain shifts, while enabling data-efficient specialist policies, like ones conditioned on 3D inputs, to perform low-level action execution.


This work represents an initial step towards developing versatile, hierarchical VLA methods, with numerous opportunities for future improvement and expansion. The proposed work only generates points in 2D space, without making native 3D predictions. This prevents the VLM from having true spatial 3D understanding. Moreover, the interface of just using 2D paths is a bandwidth limited one, which cannot communicate nuances such as force or rotation. In the future, investigating learnable intermediate interfaces is a promising direction. Moreover, training these VLMs directly from large-scale human video datasets would also be promising. 

\section*{Acknowledgements}
We thank Wentao Yuan for generously providing the Robopoint dataset. We also acknowledge Entong Su and Yunchu Zhang for their assistance in setting up the robot environment. We are grateful for the support from the Army Research Lab through sponsored research, as well as the Amazon Science Hub for Yi and Marius. We also thank Animesh Garg for many helpful discussions. Finally, we extend our gratitude to Yao Lu, Hongxu Yin, Ligeng Zhu, Borys Tymchenko, and Zhijian Liu from NVIDIAâ€™s VILA group for their valuable support throughout this work.

% \newpage
\setcitestyle{
  sort,
  numbers,
  square,
}
\bibliography{iclr2025_conference}
\bibliographystyle{iclr2024_conference}

\newpage
\input{sections/appendix}

\end{document}
