We introduce \RealEdit, a large-scale dataset of human-edit images sourced from Reddit. We capture the original image, edit instruction and up to 5 output images for each post. We notice significant distributional differences in the edits requested and image subjects when compared to existing synthetic datasets used to train editing models. Given this, we propose three contributions of our dataset. First, we evaluate 6 state of the art editing models on our dataset, showing that they fail to cater to human requests. Second, we fine-tune InstructPix2Pix~\cite{brooks2023instructpix2pix} on our data to create a model that performs real-world edits successfully. We evaluate this on automated metrics as well as humans and find we outrank existing models (some quick result to show this quantitatively). Third, we examine the use of our data in deepfake detection and find that we are able to improve F1 by X\%.
% We introduce a large-scale dataset of human-edited images, where each data point consists of an original image, a corresponding textual instruction, and the resulting edited image. By comparing this dataset to commonly used synthetic data, we uncover significant differences between the data that users find valuable and the synthetic data typically used to train image generation models. We utilize the dataset in three key ways. Firstly, we evaluate state-of-the-art models on human-centered tasks and capture their inability to extrapolate on real world examples. Secondly, we fine-tune our own state-of-the-art image editing model using InstuctPix2Pix pipeline and deploy it on Reddit. Thirdly, we assess the ability of leading deepfake detection algorithms (such as Universal Fake Detect) to detect human-edited images, revealing their difficulty in accurately identifying these edits.

