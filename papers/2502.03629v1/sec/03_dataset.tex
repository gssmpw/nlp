\section{\RealEdit}
\label{sec:realedit}

We introduce \RealEdit: a high-quality large-scale dataset for text-guided image editing. \RealEdit dataset includes 48K training data points and 9K test data points, each featuring an \textit{original image}, an \textit{editing instruction}, and one to five \textit{human-edited output images}. Altogether, we are publishing a total of 151K images. \RealEdit is the first large-scale image editing dataset wherein real-world users both submit and complete the requests (Table \ref{tab:dataset_comparison}).

\input{tables/image_editing_datasets}

\begin{figure*}[!h]
    \centering
    \includegraphics[width=\textwidth]{figs/data_figure.pdf}
    \caption{\textbf{Dataset curation pipeline.} We source data from r/estoration and r/PhotoshopRequest. From the posts, we extract input images and edit instructions. The instructions are processed using a VLM to isolate the editing task. From the comments, we collect up to 5 human-edited outputs per post.}
    \label{fig:data_pipeline}
    \vspace{-2mm}
\end{figure*}

\subsection{Dataset creation pipeline}
The extensive and structured nature of Reddit makes it an ideal source for creating diverse large-scale datasets rooted in real-world content. We leverage this by developing a data collection pipeline with three key steps: (1) collecting raw post and comment data from the subreddits of interest, (2) processing and organizing the data, and (3) manual verification to ensure safe and high-quality outputs (Figure~\ref{fig:data_pipeline}).
\noindent\textbf{Step 1: Subreddit selection.}
We build a diverse image editing dataset from two key subreddits to cover a wide range of tasks. The main source, \href{https://www.reddit.com/r/PhotoshopRequest/}{r/PhotoshopRequest}, provides 261K posts and 1.1M comments on tasks ranging from object removal and background changes, to creative edits.
Additionally, we source requests from \href{https://www.reddit.com/r/estoration/}{r/estoration} for their sentimental value to users.
This subreddit contributes 20K posts and 126K comments focused on restoring old photos, including repairing creases, colorizing black-and-white images, and enhancing clarity.
We exclude larger communities like \href{https://www.reddit.com/r/photoshopbattles/}{r/photoshopbattles} due to their emphasis on humor and less specific editing needs. The dataset consists of original image URLs sourced from posts, edit instructions, and edited image URLs taken from the comments. The images we collected were posted between 2012 and 2021 which implies low likelihood of AI-generated content. 

% This selection ensures that our dataset reflects a broad spectrum of practical image-editing tasks, while excluding smaller or highly specialized subreddits to maintain diversity and scale.

% We curated data from two prominent subreddits, each catering to distinct image-editing tasks. The first subreddit, \href{https://www.reddit.com/r/PhotoshopRequest/}{r/PhotoshopRequest} has over 1.2 million members and offers a wide variety of tasks, such as removing objects or people from images, altering backgrounds, and even creating humorous or whimsical edits (Fig. \ref{fig:PR_2_samples}). This subreddit formed the backbone of our dataset and we source 261,000 posts and 1.102 million comments from this community.

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[height=3.5cm]{figs/PR_2_samples.png}
%     \caption{Examples of r/PhotoshopRequest posts.}
%     \label{fig:PR_2_samples}
% \end{figure}

% We diversified our dataset with images editing requests from \href{https://www.reddit.com/r/estoration/}{r/estoration}. With approximately 200,000 members, this community is dedicated to restoring old images. Requests submitted here often hold deep sentimental value for users, as the images are frequently of their ancestors or personal childhood memories. We crawled 20,000 posts and 126,000 comments from this community. Typical tasks include repairing creases, removing discoloration, and improving image clarity.

% % \begin{figure}[htbp]
% %     \centering
% %     \includegraphics[totalheight=6cm]{figs/restoration_example.png}
% %     \caption{A typical post on r/estoration.}
% %     \label{fig:restoration_example}
% % \end{figure}

% By selecting these two subreddits, we ensured that the dataset captured a broad spectrum of common and practical image-editing tasks. We also considered other image-editing communities, most notably \href{https://www.reddit.com/r/photoshopbattles/}{r/photoshopbattles}, which boasts a huge user base of over 20 million. However, we chose to exclude it due to its primary focus on humorous content. While humor is an important aspect of online communities, the actual edits in this subreddit are not specific enough and do not accurately represent the typical editing needs of most individuals. Our dataset still covers this niche with some humorous content sourced from r/PhotoshopRequests. We acknowledge that there are other subreddits that could contribute to the image editing dataset, but they tend to either be highly specialized or have relatively small user bases, limiting the diversity and scale needed for a robust dataset.




\noindent\textbf{Step 2: Instruction refinement and caption generation.}
One challenge in collecting web-crawled data is that user-provided instructions may be noisy, often including personal anecdotes or task-irrelevant details
(\textit{e.g., ``This photo was taken of my Mother and me at my Grandmother’s wake. I would love to get this framed for my Mom’s birthday next month. I love the photo, but the person who took it put filters all over it. I was wondering if someone could make it look more natural.''}). We use GPT-4o~\cite{openai2023gpt4} to summarize the text to only the key editing requirements. The pipeline refines the noisy instruction above into the following: ``Restore image damage and enhance clarity''.

For the \RealEdit test set, we generated captions for both input and edited images using vision-language models to support evaluation on caption-based metrics. Implementation details are provided in the Appendix.

% For building the \RealEdit test set, we additionally add captions for both the input and the edited images, in order to facilitate evaluation metrics that operate on the input or target output captions. 
% % specifically for the test split in order to facilitate evaluation for models that require captions.
% The input image caption is generated using LLaVA-Next~\cite{liu2024llavanext}, conditioned on the processed instruction. This instruction-aware captioning is particularly useful for subtle edits, as it ensures the LLaVA-Next model to focus on specific areas of the image that might otherwise be overlooked.
% For the edited images, we combined the input caption with the editing instructions and used GPT-4o~\cite{openai2023gpt4} to generate a caption that summarizes both the original content and the modifications made. 

% \begin{figure*}[htbp]
%     \centering
%     \includegraphics[width=\textwidth]{figs/instruction-aware-vlm.png}
%     \caption{Conditioning the VLM on the editing instruction improves caption quality.}
%     \label{fig:instruction-aware-vlm}
% \end{figure*}

% \begin{figure*}[htbp]
%     \centering
%     \includegraphics[width=\textwidth]{figs/output_caption.png}
%     \caption{Captions for edited images are produced by feeding the edit instruction and original image caption to GPT-4o.}
%     \label{fig:output_caption}
% \end{figure*}


\noindent\textbf{Step 3: Data verification and final composition.}
After generating the dataset, we conducted a rigorous multi-stage verification process to ensure data quality. All images were screened for inappropriate content using the opennsfw2\cite{bhky_opennsfw2} network, filtering out those flagged as explicit.  Additionally, \RealEdit test set was manually reviewed by two annotators evaluating the following criteria:
(1) appropriateness of the input image, (2) applicability of the instruction, and (3) correctness of the output image. Approximately 78\% of the data points were agreed upon as high quality and included in the final test set for \RealEdit.



% Through the manual review process, approximately 78\% of the images were agreed upon by two independent annotators as high-quality and were included in the final test set for \RealEdit.


% \begin{figure*}[htbp]
%     \centering
%     \includegraphics[width=\textwidth]{figs/template_data_pipeline.pdf}
%     \caption{Template of data collection pipeline}
%     \label{fig:template_data_pipeline}
% \end{figure*}


