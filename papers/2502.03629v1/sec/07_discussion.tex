\section{Discussion}

\paragraph{Privacy and ethics.}
To protect user privacy, individuals can opt out of having their images in the dataset by removing the photos from Reddit. Since our dataset contains image URLs rather than image files, images deleted from the web are automatically removed. Additionally, we provide a form where individuals can request their data to be removed from the dataset. Although this evolving dataset may introduce challenges for quantitative validation, ensuring user privacy remains our top priority. 

Our work has positive social impacts, such as reducing the need for professional editing software and skills, and enabling higher-quality restorations of family photographs. However, we recognize the risks of malicious exploitation and strongly oppose any harmful, offensive, or derogatory use of our model or data. We plan to further pursue the development of fake image detection tools.

\paragraph{Conclusion.}
We propose \RealEdit, a dataset of 57K input - instruction - outputs data points where all instructions and edits are performed by humans. We analyze the distribution of real-world editing requests and fine-tune InstructPix2Pix~\cite{brooks2023instructpix2pix} to create a SOTA image editing model on these tasks. Lastly we explore \ours’s potential in facilitating deepfake detection.
%\paragraph{Future directions.} Future work may explore the effect of different model architecture on the model performance and ability to handle diverse \RealEdit data. We plan to expand the dataset over time with newly collected examples. 
% \subsection{Conclusion}
% % We propose dataset.
% We propose \RealEdit, a dataset of 57K input - instruction - outputs data points where all instructions and edits are performed by humans.  
% % We reveal what kind of requests are valuable


% % We should follow this taxonomy in the future, when developing synthetic data.
% We taxonomize edit requests by operation and subject, and determine that the distribution of tasks in current editing datasets do not reflect human desiderata.

% % We have a sota model.
% We develop a SOTA editing model by finetuning InstructPix2Pix~\cite{brooks2023instructpix2pix} on the \textsc{RealEdit}   dataset. We achieve competitive performance on standard automated metrics (L1- and L2-pixel distance, DINO, CLIP-I and CLIP-T) and outperform current SOTA models on automated metrics that specifically measure task completion (VQAScore, VIEScore, TIFA) as well as human evaluations.




% We have intergrated new eval: TIFA, VQA, elo ratings.

% We see that data is also valuable from deep fake detection standpoint. 



% \label{sec:conclusion}



% In this paper we explore the reasons why diffusion based editing is so far behind diffusion based generation. Generation models like DALL-E or Midjourney have shown great results.  We are really good at embedding models. Why can't we do edits?
% First of all we sure we can't do edits well because we took real human data and saw it for ourselves. 

% This dataset aims to reduce the model drawbacks due to the following reasons:

% \textbf{Synthetic data.} This is a large scale \textit{real} human data. Inputs are pictures taken or selected by real people and outputs are edited by amateur photo editors on two subreddits.

% \textbf{Image content.} Users care most about editing images containing people, as these tend to have more personal relevance to them. 

% % The input image of the caption used as an example is bkdisu.jpeg, index is 39218
% \textbf{Artifical captions.} We collected human request in their natural form. We noticed that people tend to have extraneous contextual information that does not contribute to describing the edit to be performed (\textit{e.g. ``This photo was taken of my Mother and me at my Grandmother’s wake. I would love to get this framed for my Mom’s birthday next month. I love the photo, but the person who took it put filters all over it. I was wondering if someone could make it look more natural.''}). We converted such instructions with a lot of noise into those that are more direct.

% \textbf{Tasks choices.} The editing tasks in out dataset differed greatly from other datasets in both the actual tasks and the subjects of the edits. 

% \textbf{Task density.} overwhelmingly users care about adding and removing objects into images. While this task exists, it doesn't receive enough attention. 

% By fine-tuning instruct pix-2-pix on our training data, we can see it what performance we can see due to adding real data. 

% By benchmarking real human edits, we can see what kind of metrics we need to achieve to approach results made by professionals. This is a minimum sufficient result. 


% clearly ability to look up data improves edits on human sets. 



% \subsection{Limitations and Future Work}
% Data limitations:
% Sometimes reddit users do what isnt asked, like purposefully being funny or not following the prompt (remove all people instead of just the specified person)

% biases of reddit  (western, leftist, male)

% Model limitations:
% can handle prompts with too many instructions
% text doesnt get generated well
% remove blur



% test set leakage 

% \input{tables/aesthetic_scores}
