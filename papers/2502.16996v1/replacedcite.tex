\section{Related Work}
\subsection{Image \& Video Style Transfer}

NST research has progressed from online image-optimization techniques ____, to offline model-optimization methods capable of reproducing one style per trained network ____, and arbitrary-style-per-model approaches ____ that can reproduce any given referenced style image on an input photograph ____. Early work on arbitrary style transfer, \textit{AdaIN} ____, used an adaptive instance normalization layer that aligns the mean and variance of the content features with the respective mean and variance of style features. Other work suggested patch-based techniques ____, while neural flows ____ and vector quantization ____ have also been exploited for arbitrary stylisation. Recently, the success of attention mechanisms ____ in computer vision has resulted in multiple attention-based methods ____, as well as diffusion model-based methods ____ for artistic style transfer. Among these attention-based approaches, \textit{RAST} ____, a system inspired by image restoration shows enhanced structure preservation, a desirable quality in a game setting. Our approach utilises \textit{RAST} (which uses \textit{SANet} ____ as a backbone) in a distillation framework that is also based on style-attentional networks (\textit{SANet}).

% \subsection{Video Style Transfer}

Temporal incoherence is the main challenge that arises when stylising videos compared to images. Methods have resorted to optic flow data to improve temporal stability ____. Multiple-style-per-network models ____ and arbitrary-style-per-network models ____ have been proposed, while depth-aware and structure-preserving video style transfer ____ attempts to retain depth and global structure of the stylised video frames. Image style transfer approaches have been extended to work for videos with additional temporal loss training ____, and unified frameworks for joint image and video style transfer techniques have been developed ____. Diffusion-based methods for stylised video generation have also emerged ____.


\subsection{Style Transfer for 3D Computer Games}

Whilst image and video NST methods can be applied at the end of the rendering pipeline to achieve real-time computer game stylisation, this is essentially a post-processing effect that interprets the rendered frames as single images and does not prevent undesired artifacts and flickering issues. Multi-style artistic style transfer for games has been shown in work by Unity ____ -- this utilises the method of Ghiasi~\etal \shortcite{ghiasi2017exploring} to stylise each intercepted final rendered image. Any G-buffer or 3D data is ignored while the produced stylisations are inconsistent and the post-process effects are diminished, as the stylisation network is used as a final `filter'. Other approaches have demonstrated improved stylisation quality when G-buffer data is taken into account during training ____. Style transfer specifically tailored for computer games has only been recently proposed ____. Here, NST is injected into the rendering pipeline before the post-process stage but is only capable of reproducing one style image per trained network. Yet, arbitrary style transfer could offer a significant advantage to developers and artists, as well as enable users to upload any artwork of their choice to stylise the game scenes.


\subsection{Knowledge Distillation}
Pioneered by Hinton~\etal \shortcite{hinton2015distilling}, knowledge distillation has been a widely adopted technique for training compressed models. This aims to create smaller and faster models that retain quality and performance. Recently, methods have leveraged this technique for the task of style transfer, demonstrating improved performance ____. Wang~\etal \shortcite{chen2023collaborative} show that training a smaller encoder to replace the large \textit{VGG-19} ____ that is typically utilised in encoder-decoder-based neural style transfer results in ultra-resolution outputs that were hard to achieve before due to memory constraints. High-quality arbitrary style transfer for images is also achieved by designing a network composed of a content encoder, a style encoder and a decoder based on CNNs, and employing symmetric knowledge distillation ____. The method by Chen~\etal \shortcite{chen2020optical} -- also based on a simple CNN architecture -- achieves fast video style transfer without relying on optic flow information during inference, but is only capable of reproducing one style per trained network.