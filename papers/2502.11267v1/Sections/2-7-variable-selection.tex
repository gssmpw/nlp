There are lots of variables in a system could impact user's performance. 
\citet{kulesza2012tell} suggested that the more users understand the underlying system, the more effectively they can control it. 

\steven{\citet{lee2024clarify} introduces a system that allows non-expert users to train and correct models by directly interact with model using natural languages. In each iteration, the system will use similarity score between user description and image and display images above a threshold. The system will also provide 0-1 score indicating how well description separates the error cases from the correct prediction. Basically using metrics to guide user.
It does not mentioned about the sample size selection.}

\steven{[Data Instance:] In active learning, the goal is to minimize the amount of interaction required by users by querying the most important information~\cite{bernard2018vial}. [This can be used to justify why we increase to 50, to ensure the diversity. We cannot deploy algorithms to find most representative data sample because of the technical limitation of Google App Script]}

\steven{[Data Instance:] \citet{vermetten2022analyzing} investigated how the number of sample size affects the reliability of algorithm comparisons in iterative optimization. The study found that small sample sizes lead to high variability in performance estimates and larger sample sizes could decrease the impact of outliers. The performance could loss due to small samples and increasing sample size consistently improves reliability. }

\steven{\citet{purohit2018ranking} suggested capping the maximum number of annotation tasks assigned per unit of time to manage workload effectively to mitigate annotator burnout.}

\steven{\citet{pandey2022modeling} mentioned annotator can develop a mental representation of a concept by seeing a sufficient number of examples.}

\steven{\citet{wang2016human} limited users to verify the top-50 in each round, where users did binary classification on whether image was match or not.}

\steven{[explanation]\citet{kulesza2015principles} presents a system that explains the reason behind each prediction for users to better understand the system's logic to tailor the system toward their needs. In the system, users will modify feature weights within the model. n our LLM-powered system, users need to use natural language to guide the system. However, this can be more challenging because large models are less responsive to prompt variations compared to smaller models~\cite{zhuo2024prosa}.}

\steven{The more users understand the underlying system, the more effectively they can control it~\cite{kulesza2012tell}.}

\steven{\citet{teso2023leveraging} discusses a general framework for incorporating explanations into interactive machine learning. Users can get a better understanding of the machine's logic by observing the machine's explanations. [In LLM system, the explanation is the supporting argument for selecting a label.] Once understanding the bugs and limitation, users could modify the algorithm to correct flaws~\cite{kulesza2015principles}. [In our case, user cannot directly modify LLMs but only provide natural language to guide them. Also, subjective tasks does not have universal correct answers, where users need to provide their own standards to steer LLMs. ] }

\steven{[Task Difficulty:] 
A task being too difficult can frustrate users~\cite{zheng2022virtual}, particularly when exceeding their skill level, and a task being to easy can lead to boredom~\cite{zhang2021personalized}.
  These study focused on the impacts of difficulty on users' performance on a pre-defined task. However, in our study, our work prioritizes the dynamics of human-LLM interaction, emphasizing how effective humans could guide LLMs to align with their standard. In this context, the difficulty level of the task itself is less critical, as our primary objective is to assess the effectiveness of human guidance, regardless of the inherent complexity of the task.}


\steven{[task type:]\citet{cayir2016study} found the complexity and definition of a task significantly influence user performance. }

\steven{[task type:] \citet{hettiachchi2022survey} discusses different task assignment methods, including the modeling of worker performance and the impact of task heterogeneity on assignment strategies.
\citet{zhen2021crowdsourcing} provides a detailed exploration of task assignment challenges, task types, and their effects on worker performance and task outcomes. 
}