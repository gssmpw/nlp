\documentclass[compsoc,conference,a4paper,10pt,times]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
% \usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{bmpsize}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{booktabs}

\usepackage{enumitem}
\usepackage{threeparttable}
\usepackage{multirow}

\usepackage{siunitx} % Use this package for alignment and number formatting
\sisetup{
  group-separator={\,},
  detect-all,
  input-ignore={,},
  input-decimal-markers={.},
  table-align-text-post=false
}

\usepackage[
 backend=biber
,style=ieee
,minbibnames=1
,maxbibnames=5
,maxcitenames=1
,mincitenames=1
,eprint=true
,doi=true
,isbn=false
,url=true
]{biblatex}
\bibliography{ref} 
\AtBeginBibliography{\footnotesize}

\DeclareSourcemap{
  \maps{
    \map{
      \step[fieldset=month, null]
      \step[fieldset=address, null]
      \step[fieldset=location, null]
      \step[fieldset=publisher, null]
      \step[fieldset=url, null]
      \step[fieldset=isbn, null]
      \step[fieldset=series, null]
      \step[fieldset=editor, null]
    %   \step[fieldset=number, null]
    }
  }
}

% \newcommand{\ap}[1]{\textcolor{red}{#1}}
% \renewcommand{\ap}[1]{#1}

% \newcommand{\ys}[1]{\textcolor{blue}{#1}}
% \renewcommand{\ys}[1]{#1}

% \usepackage[
% hidelinks,
%   colorlinks=true,
% %   allcolors=black,
%   % linkcolor=black,
%   % citecolor=blue,
%   % pdfstartview=Fit,
%   % breaklinks=true
%   urlcolor=black
% ]{hyperref}

\usepackage{cleveref}
%\Crefname{equation}{Eq.}{Eqs.}
\Crefname{figure}{Fig.}{Figs.}
%\Crefname{tabular}{Tab.}{Tabs.}

\usepackage{lipsum}


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


\usepackage{flushend}

\begin{document}

\title{Binary VPN Traffic Detection Using Wavelet Features and Machine Learning}

\author{
    \IEEEauthorblockN{Yasameen Sajid Razooqi\IEEEauthorrefmark{1} and Adrian Pekar\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}\IEEEauthorrefmark{3}
    }
    \IEEEauthorblockA{
        \IEEEauthorrefmark{1}Department of Networked Systems and Services, Faculty of Electrical Engineering and Informatics,\\ Budapest University of Technology and Economics, M\H{u}egyetem rkp. 3., H-1111 Budapest, Hungary.\\
        \IEEEauthorrefmark{2}HUN-REN-BME Information Systems Research Group, Magyar Tud\'{o}sok krt. 2, 1117 Budapest, Hungary.\\
        \IEEEauthorrefmark{3}CUJO LLC, Budapest, Hungary.\\
        Email: rsajid@hit.bme.hu, apekar@hit.bme.hu
    }
}

\maketitle

\begin{abstract}
Encrypted traffic classification faces growing challenges as encryption renders traditional deep packet inspection ineffective. This study addresses binary VPN detection, distinguishing VPN-encrypted from non-VPN traffic using wavelet transform-based features across multiple machine learning models. We analyze the impact of wavelet decomposition levels and dataset filtering on classification performance. Our results demonstrate that Random Forest (RF) achieves superior performance with an F1-score of 99\%, maintaining robust accuracy even after significant dataset filtering. Neural Networks (NN) show comparable effectiveness with an F1-score of 98\% when trained on wavelet level 12, while Support Vector Machines (SVM) exhibit notable sensitivity to dataset reduction, with F1-scores dropping from 90\% to 85\% after filtering. Comparing wavelet decomposition at levels 5 and 12, we observe improved classification performance at level 12, particularly for variable traffic types, though the marginal gains may not justify the additional computational overhead. These findings establish RF as the most reliable model for VPN traffic classification while highlighting key performance tradeoffs in feature extraction and preprocessing.
\end{abstract}

\begin{IEEEkeywords}
Encrypted traffic classification, VPN detection, wavelet transform, 
% machine learning, network security, feature extraction, 
network traffic analysis
\end{IEEEkeywords}

\section{Introduction}

The widespread adoption of network encryption poses a challenge for traffic classification, as traditional deep packet inspection and port-based methods are no longer effective~\cite{CiscoVNI2017,Statista2020}. VPNs are among the most commonly used encryption tools, with nearly one-third of internet users employing VPN services to protect their online activity~\cite{GlobalWebIndex2020}. While this enhances privacy and security, it also complicates traffic analysis for network management, intrusion detection, and policy enforcement.

Recent research has explored machine learning (ML) for encrypted traffic classification. The approaches in this field can be broadly categorized into three main groups. First, traditional feature-based methods have shown promise, with techniques like Sample Entropy Fingerprint and TCP characteristics heuristics achieving high accuracy in VPN detection~\cite{9353766,hanlon2024detecting}. Second, deep learning approaches have emerged as powerful tools, with innovations like FlowPics for visual representation of flow features~\cite{10724208} and advanced architectures combining CNN with attention mechanisms~\cite{Chai2024,Seydali2024}. The third category explores novel modeling paradigms, including multi-task learning with DistilBERT~\cite{Park2024} and text-to-text transformation using large language models~\cite{Luo2024}.

Notably, \citeauthor{10044382}~\cite{10044382} introduced an ML framework that combines wavelet-based features with uncertainty quantification for application-level classification across VPN and non-VPN traffic. However, the related but distinct problem of binary VPN detection---determining whether traffic is VPN-encrypted regardless of application---has received less attention. While wavelet transforms have proven effective in network anomaly detection~\cite{4023145,4198844}, their potential for binary VPN classification remains unexplored.

In this work, we focus on \textit{binary VPN detection} and re-evaluate the effectiveness of \textit{wavelet transform-based features} for distinguishing VPN from non-VPN traffic. We assess the performance of multiple ML models, including Random Forest (RF), Neural Networks (NN), and Support Vector Machines (SVM), and analyze the impact of dataset filtering, a common preprocessing step that significantly affects classification performance and data distribution. Unlike prior work that primarily targets application classification, our analysis provides insights into the robustness of different ML models under specific data processing variations: wavelet decomposition depth (levels 5 and 12) and flow-length filtering.

Our results show that RF achieves the highest accuracy, reaching 99\% with wavelet level 12 and maintaining strong performance (98\%) even after dataset filtering. NNs also perform well, with accuracy dropping slightly from 98\% to 96\% after filtering. SVMs experience the most significant decline, with accuracy decreasing from 90\% to 85\% (wavelet level 12) and 88\% to 83\% (wavelet level 5) after filtering. Detailed misclassification analysis of the best-performing RF model reveals that Chat traffic exhibits the highest error rate, with frequent confusion between VPN and non-VPN traffic, even after filtering. In contrast, VoIP traffic is classified with perfect accuracy, showing no misclassification in either VPN or non-VPN scenarios. While deeper wavelet decomposition (level 12 versus level 5) improves classification accuracy, particularly for variable traffic types, the modest performance gains may not justify the additional computational overhead. These findings emphasize the importance of using robust models like RF for VPN detection, especially when dataset size is limited.

The remainder of this paper is structured as follows: 
\Cref{sec:WF} provides background on wavelet-based feature extraction. 
\Cref{sec:method} describes our methodology, including dataset preprocessing and model selection. 
\Cref{sec:res} presents and analyzes our results. 
\Cref{sec:discussion} discusses key findings and their implications. 
\Cref{sec:comparison} provides a comparative analysis between our findings and those of \citeauthor{10044382}~\cite{10044382}. 
Finally, \Cref{sec:conc} concludes this paper and outlines future research directions.

\section{Wavelet Transform}
\label{sec:WF}

Wavelet transform is a powerful mathematical tool for analyzing non-stationary signals by decomposing them into components of varying frequency and localization in time. Unlike Fourier transforms, which provide only frequency-domain representation, wavelet transforms preserve both time and frequency information, making them particularly suited for analyzing complex and transient signals such as network traffic~\cite{Ahad2016}. This section outlines the fundamentals of wavelet features, their general applications, and their specific use in the analysis of IP flows for VPN detection.

\subsection{Wavelet Transform Fundamentals}

\subsubsection{Types of Wavelet Transforms}

Several variations of wavelet transforms exist, each optimized for specific applications:
\begin{itemize}
    \item \textbf{Continuous Wavelet Transform (CWT):} Provides a detailed time-frequency representation of signals by continuously scaling and shifting the wavelet function, making it ideal for analyzing non-stationary signals with high precision.
    
    \item \textbf{Discrete Wavelet Transform (DWT):} Operates on discrete scales and positions, enabling efficient computation and perfect reconstruction of signals. It is particularly suited for tasks such as signal compression and noise reduction.
    
    \item \textbf{Wavelet Packet Transform (PWT):} Extends DWT by further decomposing both approximation and detail coefficients, offering a finer resolution for signals with intricate frequency components~\cite{RuizdelaHermosaGonzlezCarrato2014}.
\end{itemize}

Among these, DWT is preferred for its balance between analytical capability and computational efficiency.

\subsubsection{Discrete Wavelet Transform Fundamentals}

DWT decomposes a signal into two sets of coefficients: 
\textbf{approximation coefficients}, which capture the low-frequency components, and 
\textbf{detail coefficients}, which represent the high-frequency components of the signal~\cite{91217}.

\begin{itemize}
    \item \textbf{Approximation coefficients (\(A_j\))} are computed as follows:

            \begin{equation}
                    A_j[k] = \sum_{n} x[n] \cdot g(2k - n),
                    \label{eq:Approximation}
            \end{equation}

            where \(x[n]\) is the input signal, \(g[n]\) represents the low-pass filter coefficients, and \(2k\) is the downsampling factor.    

    \item \textbf{Detail coefficients (\(D_j\))} are computed as:

            \begin{equation}
                D_j[k] = \sum_{n} x[n] \cdot h(2k - n),
                \label{eq:Detail}
            \end{equation}

            where \(h[n]\) represents the high-pass filter coefficients.
\end{itemize}

Both approximation and detail coefficients are used to compute the wavelet-based features. To simplify the notation in feature calculations, we introduce a general notation \(C_j[k]\), where \(C_j[k]\) represents either \(A_J[k]\) (approximation coefficient at the final level) or \(D_j[k]\) (detail coefficients at intermediate levels). 

\subsubsection{Wavelet Transform Metrics}
\label{subsec:metrics}

To analyze the coefficients \(C_j[k]\) obtained from DWT, we compute several key metrics that characterize different aspects of the signal.

\begin{enumerate}
    \item \textbf{Relative Wavelet Energy Vector (\(E_j\))} represents the energy distribution across different decomposition levels:

    \begin{equation}
           E_j = \frac{\sum_{k} C_j[k]^2}{\sum_{j}\sum_{k} C_j[k]^2} \times 100\%.
           \label{eq:energy}
    \end{equation}

    Here, \(\sum_{k} C_j[k]^2\) represents the energy of the coefficients at level \(j\), while \(\sum_{j}\sum_{k} C_j[k]^2\) represents the total energy across all levels~\cite{Amin2015}. Since this metric reflects the relative energy distribution, it satisfies the constraint \(\sum_j E_j = 100\%\).

    \item \textbf{Absolute Mean of Coefficients:}
    The absolute mean (\(M_j\)) at level \(j\) quantifies the average magnitude of wavelet coefficients~\cite{753747}:

    \begin{equation}
          M_j = \frac{1}{N_j} \sum_{k} |C_j[k]|.
          \label{eq:mean}
    \end{equation}

    Here, \(N_j\) represents the number of coefficients at level \(j\), and \(|C_j[k]|\) is the absolute value of each coefficient.

    \item \textbf{Standard Deviation of Coefficients:}
    The standard deviation (\(\sigma_j\)) at level \(j\) measures the spread of coefficients~\cite{7566534}:

    \begin{equation}
          \sigma_j = \sqrt{\frac{1}{N_j} \sum_{k} \left(C_j[k] - \bar{C}_j\right)^2}.
          \label{eq:std}
    \end{equation}

    where the mean \(\bar{C}_j\) is given by:

     \begin{equation}
           \bar{C}_j = \frac{1}{N_j} \sum_{k} C_j[k].
     \end{equation}

    \item \textbf{Shannon Entropy:}
    The Shannon entropy (\(H_j\)) at level \(j\) quantifies the information content of the wavelet coefficients~\cite{Uyar2008}:

    \begin{equation}
          H_j = -\sum_{k} P_j[k] \log_2 P_j[k].
          \label{eq:shannon}
    \end{equation}

    The probability distribution \(P_j[k]\) is defined as:

    \begin{equation}
          P_j[k] = \frac{|C_j[k]|}{\sum_{k} |C_j[k]|},
    \end{equation}

    with the constraint:

    \begin{equation}
        \sum_k P_j[k] = 1.
    \end{equation}
\end{enumerate}

\subsection{Wavelet Features in IP Flows}
\label{subsec:ip_flows}

IP flows consist of sequences of packets sharing common attributes (e.g., source/destination IP addresses and ports, and protocols) within a specific time window. Wavelet-based analysis is applied to numerical sequences derived from flow attributes such as packet size.

\subsubsection{Decomposition Process}

The DWT decomposes these sequences into detail coefficients (\(D_j\)) and approximation coefficients (\(A_j\)) over multiple decomposition levels (\(J\)). The optimal number of decomposition levels is determined as:

\begin{equation}
     J = \lfloor \log_2(n) \rfloor,
      \label{eq:level}
\end{equation}

where \(n\) is the length of the sequence.


\subsubsection{Feature Vector Construction}

For each decomposition level, wavelet features are computed to create comprehensive feature vectors for classification. These include:

\begin{itemize}
    \item \textbf{Energy Features:} Raw energy values (\(E_j\)) at each decomposition level.
    \item \textbf{Statistical Features:} 
        \begin{itemize}
            \item Absolute mean (\(M_j\)).
            \item Standard deviation (\(\sigma_j\)).
            \item Shannon entropy (\(H_j\)).
        \end{itemize}
\end{itemize}

\begin{table*}[]
    \centering
    \caption{Comparison of Flow Counts with Different Active Timeouts}
    \begin{tabular}{lrrrrrrrrrrr}
        \toprule
         & \multicolumn{3}{c}{Complete Flows} & & \multicolumn{5}{c}{Act. Timeout 41} & \multicolumn{1}{c}{Act. Timeout 4.96} \\
        \cmidrule(r){2-5} \cmidrule(r){6-10} \cmidrule(r){11-11} \\
        Category & non-VPN & VPN & $\sum$ & Tab. 3~\cite{10044382} & non-VPN & VPN & $\sum$ & Filtered & Reduction (\%) & Sec.~IV.A~\cite{10044382} \\
        \midrule
        Chat & 1244 & 57 & 1301 & 1301 & 5928 & 5751 & 11679 & 10259 & 12.16 & 10498 \\
        Com. \& Cont. & 13591 & 8 & 13599 & 13599 & 15961 & 1624 & 17585 & 1470 & 91.64 & 1675 \\
        File Transfer & 16420 & 10 & 16430 & 16430 & 17588 & 378 & 17966 & 805 & 95.52 & 851 \\
        Streaming & 1759 & 5 & 1764 & 1764 & 3334 & 160 & 3494 & 1841 & 47.31 & 1827 \\
        VoIP & 318 & 299 & 617 & 617 & 786 & 437 & 1223 & 242 & 80.21 & 243 \\
        \bottomrule
    \end{tabular}
\label{tbl:DS}
\end{table*}

\section{Methodology}
\label{sec:method}

This section describes our approach to VPN traffic classification. We first present the dataset and our flow metering process, followed by  feature extraction 
methodology for the wavelet-based features. We then detail the machine learning models employed and the evaluation metrics used to assess their performance.

\subsection{Dataset Description}
\label{sec:DS}

We use the VPN/non-VPN Network Application Traffic (VNAT)~\cite{10044382} dataset for our classification task. The dataset comprises 165 pcap files (82 VPN and 83 non-VPN traffic traces) with a total size of 36.1 GB. All network traffic was captured using \texttt{tcpdump} and stored in PCAP format, encompassing both VPN-encrypted and unencrypted flows across 33,711 connections and approximately 272 hours of capture time.

The dataset covers traffic from 10 applications categorized into 5 main groups: Streaming, VoIP, Chat, Command \& Control, and File Transfer. These categories exhibit notable variations in their distribution across different metrics. For instance, while File Transfer represents 90\% of the dataset's volume, it accounts for only 40\% of connections and 5\% of the total capture time. Conversely, Command \& Control traffic, despite comprising merely 2\% of the dataset's size, represents 40\% of all connections and 47\% of the total capture duration.

\subsection{Flow Processing and Analysis}

We utilized NFStream~\cite{Aouini2022}, a flexible network data analysis framework, to process the dataset's PCAP files. While VNAT provides both traffic traces in PCAP format and pre-extracted statistical summaries in HDF (h5) format, we chose NFStream for its ability to seamlessly integrate plugins, particularly for calculating the Wavelet Features discussed in \Cref{sec:WF}.

To ensure consistency with the methodology described in~\cite{10044382}, we extracted flow records under two conditions: first, without applying any flow timeout to capture complete flow records, and second, with an active timeout of 41 seconds, approximating the original study’s segmentation of flows into 40.96-second intervals. In the latter case, packets were assigned to 0.01-second time bins, and intervals containing fewer than 20 packets were discarded.

\Cref{tbl:DS} presents the comparative flow counts, revealing that while complete flow counts match exactly with the original study, the application of timeout parameters leads to notable variations across traffic categories:
\begin{itemize}
\item \textbf{Chat}: 1301 complete flows in both studies; our timeout yielded 10259 flows versus original 10498 (12.16\% reduction after filtering)
\item \textbf{Command \& Control}: 13599 complete flows; timeout processing produced 1470 flows versus 1675 (91.64\% reduction after filtering)
\item \textbf{File Transfer}: 16430 complete flows; resulted in 805 flows versus 851 (95.52\% reduction after filtering)
\item \textbf{Streaming}: 1764 complete flows; yielded 1841 flows versus 1827 (47.31\% reduction after filtering)
\item \textbf{VoIP}: 617 complete flows; produced 242 flows versus 243 (80.21\% reduction after filtering)
\end{itemize}

These substantial differences in flow counts, despite similar filtering criteria, demonstrate the sensitivity of flow segmentation techniques to minor timing parameter variations (41s vs. 40.96s), as NFStream only supports integer timeout values for performance optimization. 
 
The reduction in flow counts is particularly pronounced in Command \& Control (91.64\%), File Transfer (95.52\%), and VoIP (80.21\%) traffic. This dramatic reduction highlights the effect of flow segmentation on dataset composition and raises potential concerns regarding class imbalance, as we will discuss in \Cref{sec:discussion}.

Beyond differences in flow segmentation, we identified two key methodological variations that distinguish our processing from the original VNAT dataset. First, NFStream processes only the first fragment (offset zero) of fragmented IP packets, as it requires flow headers for proper stream reconstruction. This means that while our flow segmentation remains comparable, NFStream does not reconstruct fragmented packets to obtain their true size, whereas the original study performed full reassembly. This methodological difference primarily affects large UDP-based transmissions where fragmentation occurs more frequently.

Second, we observed discrepancies in how transport layer sizes were computed. The original study inconsistently applied UDP header exclusions while including TCP headers in size calculations. NFStream, in contrast, consistently accounts for TCP and UDP payload size differences, ensuring uniformity in flow size calculations. While these differences do not directly impact the extracted features, they affect dataset comparability and highlight the sensitivity of flow statistics to implementation details.

\subsection{Feature Extraction}

For our classification task, we extract wavelet-based features to capture the temporal characteristics of packet size distributions in network flows. We apply DWT to transport-layer packet size sequences in both forward and backward directions. Following \cite{10044382}, we remove flows with fewer than 20 packets. Our choice of decomposition level J=5 is supported by the packet count distribution in our filtered dataset, as shown in \Cref{tbl:PC}. With the 25th percentile at 56 packets, J=5 (scale of $2^{5} = 32$ via \Cref{eq:level}) ensures effective capture of packet variations across the majority of flows. We also evaluate J=12 to enable direct comparison with \cite{10044382}, though at this level (scale of $2^{12} = 4096$), the decomposition scale significantly exceeds typical flow lengths in their dataset. The highly skewed distribution (mean $=2,599$, median $=63$) indicates that while some flows contain up to 857,900 packets, such extensive flows are rare outliers. This distribution suggests that while J=12 might capture finer-grained variations in exceptionally long flows, it might provide diminishing returns for typical traffic patterns.

\begin{table}[h]
    \centering
    \caption{Packet Count Statistics Before and After Filtering}
    \label{tab:packet_stats}
    \begin{tabular}{lcc}
        \hline
        \textbf{Statistic} & \textbf{Before Filtering} & \textbf{After Filtering} \\
        \hline
        Count & 51947 & 14617 \\
        Mean & 733.50 & 2599.00 \\
        Standard Deviation & 12444.49 & 23357.13 \\
        Minimum & 1 & 20 \\
        25th Percentile & 2 & 56 \\
        Median & 2 & 63 \\
        75th Percentile & 36 & 73 \\
        Maximum & 857900 & 857900 \\
        \hline
    \end{tabular}
\label{tbl:PC}    
\end{table}

From each decomposition, we compute four key wavelet-based metrics using both the approximation coefficients \Cref{eq:Approximation} and detail coefficients \Cref{eq:Detail}: relative wavelet energy~\Cref{eq:energy}, absolute mean~\Cref{eq:mean}, standard deviation~\Cref{eq:std}, and Shannon entropy~\Cref{eq:shannon}. These metrics quantify the distribution of energy across frequency components, capturing structural properties of packet sequences.

At each decomposition level \(j\), these four metrics are computed separately for the corresponding detail coefficients \(D_j\). Additionally, at the final decomposition level \(J\), they are also computed for the approximation coefficients \(A_J\), leading to \( 4J \) features from the \(J\) sets of detail coefficients and \( 4 \) features from the final approximation coefficients.

Since we extract these features separately for both the forward and backward packet sequences, the total number of wavelet-based features is given by \(F_{wavelet} = 8J + 8\), where \(8J\) accounts for the features extracted from all \(J\) levels of detail coefficients, while the additional \(8\) corresponds to the features from the final approximation coefficients. This results in 48 features for \(J=5\) and 104 features for \(J=12\), ensuring a balance between feature diversity and computational efficiency.

\begin{table}[!htp]
    \centering
    \caption{Performance Comparison of Machine Learning Models}
    \label{tbl:performance}
    \begin{tabular}{lccc}
        \toprule
        Model & Precision \% & Recall \% & F1-score \% \\
        \midrule
        RF12  & 99 & 99 & 99 \\
        RF12\_filtered  & 98 & 98 & 98 \\
        RF5  & 99 & 99 & 99 \\
        RF5\_filtered  & 98 & 98 & 98 \\
        NN12  & 99 & 98 & 98 \\
        NN12\_filtered & 96 & 96 & 96 \\
        NN5  & 93 & 93 & 93 \\
        NN5\_filtered  & 93 & 93 & 93 \\
        SVM12  & 90 & 90 & 90 \\
        SVM12\_filtered  & 85 & 85 & 85 \\
        SVM5  & 88 & 88 & 88 \\
        SVM5\_filtered  & 83 & 83 & 83 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Classification Models}

To classify VPN and non-VPN traffic, we employ three machine learning models: RF, NN, and SVM. Each model is evaluated on both full and filtered datasets, with an 80/20 train-test split and fixed random seed to ensure reproducibility.

\subsubsection{Random Forest} RF is implemented as an ensemble-based classifier, leveraging decision tree aggregation to improve generalization. It is well-suited for high-dimensional feature spaces and has been widely used in network traffic classification due to its robustness and interpretability. Default hyperparameters were used, as preliminary evaluation showed competitive performance across the dataset without requiring extensive optimization.

\subsubsection{Neural Networks}

NN model consists of three fully connected layers: an input layer with 64 neurons, a hidden layer with 32 neurons using ReLU activation, and an output layer with a sigmoid activation function for binary classification. The model is trained using the Adam optimizer with binary cross-entropy loss for 20 epochs. 

\subsubsection{Support Vector Machine}

SVM is trained using a linear kernel and optimized with \texttt{LinearSVC}, configured with a maximum iteration limit of 10,000 to ensure convergence. We apply feature scaling prior to training to stabilize optimization.

The chosen model configurations demonstrated strong classification performance across the dataset without requiring extensive hyperparameter tuning. Given their efficiency and stability, they provide the groundwork for future research employing hyperparameter optimization and alternative models.

\begin{figure}[!htp]
    \centering
    \includegraphics[width=1\linewidth]{fig/test_accuracy_plot.png}
    \caption{Accuracy Comparison of ML Models with and without Filtering.}
    \label{fig:barchart_acurracy}
\end{figure}

\subsection{Performance Metrics}

We evaluate model performance using standard classification metrics: accuracy, precision, recall, and F1-score. Additionally, we analyze confusion matrices and misclassified samples to assess model behavior across different traffic categories. Misclassification patterns provide insights into category-specific classification challenges and help identify traffic types that are particularly difficult to distinguish under VPN obfuscation.

Beyond classification metrics, we investigate the effect of filtering on model performance. Since filtering reduces dataset size by discarding flows with fewer than 20 packets, it may introduce biases or reduce model generalizability.The impact of filtering on different models will be discussed in \Cref{sec:res}.

\begin{figure*}[]
     \centering
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{fig/confusion_matrix_RF12.png}
         \caption{RF12}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{fig/confusion_matrix_RF12_filtered.png}
         \caption{RF12\_filtered}
     \end{subfigure}\\
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{fig/confusion_matrix_RF5.png}
         \caption{RF5}
     \end{subfigure}
     \hfill
    \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=0.7\textwidth]{fig/confusion_matrix_RF5_filtered.png}
         \caption{RF5\_filtered}
     \end{subfigure}
      \caption{Confusion Matrices for RF with 5 and 12 Wavelet Decomposition Levels}
        \label{fig:CM}
\end{figure*}

\begin{figure*}[]
     \centering
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{fig/RF12.png}
         \caption{RF12}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{fig/RF12_filtered.png}
         \caption{RF12\_filtered}
     \end{subfigure}\\
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{fig/RF5.png}
         \caption{RF5}
     \end{subfigure}
     \hfill
    \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{fig/RF5_filtered.png}
         \caption{RF5\_filtered}
     \end{subfigure}
     \caption{Distribution of Misclassified Samples Across Different Traffic Categories for RF 12 levels}
     \label{fig:Misclassification}
\end{figure*}

\section{Results}
\label{sec:res}

\Cref{tbl:performance} summarizes our experimental results. For visual comparison, we provide the accuracy scores separately as bar plots in \Cref{fig:barchart_acurracy}. Models are denoted with suffixes `5' or `12' indicating the wavelet decomposition levels used for feature extraction, while the suffix `\_filtered' identifies models trained on datasets where, following the methodology in~\cite{10044382}, flows with fewer than 20 packets were removed.

From \Cref{tbl:performance}, we observe that RF maintains consistently high F1-scores of 99\% at both decomposition levels, with only a minor decrease to 98\% after filtering. NNs exhibit sensitivity to decomposition levels, with NN12 achieving an F1-score of 98\%, slightly decreasing to 96\% after filtering, while NN5 remains stable at 93\% across both filtered and unfiltered scenarios. SVMs show the most significant impact from filtering. The F1-score for SVM12 drops from 90\% to 85\%, while SVM5 declines from 88\% to 83\% after filtering, indicating that SVM remains the most affected model by dataset reduction.

The accuracy patterns in \Cref{fig:barchart_acurracy} align with these observations, with RF maintaining stability at both decomposition levels, showing only minimal reductions from 99\% to 98\% after filtering. NN demonstrates moderate sensitivity, with NN12 accuracy decreasing from 98\% to 96\%, while NN5 remains unchanged at 93\% post-filtering. SVM exhibits the most noticeable filtering impact, with SVM12 accuracy declining from 90\% to 85\% and SVM5 dropping from 88\% to 83\%, reinforcing that SVM is the most sensitive model to dataset reduction.

Since RF achieved consistently the best performance across both 5 and 12-level decomposition configurations, we focus our detailed analysis on its confusion matrices and misclassifications.

\Cref{fig:CM} illustrates the classification performance across different RF configurations. RF12 achieves 100\% accuracy for non-VPN traffic and 97\% for VPN traffic, with minimal misclassification rates of 0\% and 3\%, respectively. The filtered version maintains strong performance, with 99\% accuracy for non-VPN and 98\% for VPN traffic, showing a slight reduction in misclassification rates. 
RF5 exhibits similar performance, achieving 100\% accuracy for non-VPN and 97\% for VPN traffic. After filtering, RF5 shows a small drop in non-VPN classification accuracy to 98\%, while VPN accuracy improved to 98\%. These results confirm RF’s robustness, with only minimal variations in misclassification rates across different wavelet levels and filtering conditions.

\Cref{fig:Misclassification} reveals category-specific classification challenges. Chat traffic presents the highest misclassification counts, with RF12 showing 46 total misclassifications (17 non-VPN, 29 VPN) before filtering, reducing to 35 (20 non-VPN, 15 VPN) after filtering. File Transfer and Command \& Control categories show marked improvement with filtering---RF12's misclassifications in File Transfer drop from 8 to 3 cases. RF5 shows similar patterns but with generally higher misclassification counts across all categories, particularly visible in the Chat and Streaming categories, reinforcing the advantage of higher decomposition levels for accurate classification.

However, these reduced misclassification counts after filtering should be interpreted with caution. As shown in \Cref{tbl:DS}, filtering dramatically reduces the available samples---up to 95.52\% in File Transfer and 91.64\% in Command \& Control categories. Thus, the lower misclassification counts primarily reflect the reduced dataset size rather than actual performance improvement. This observation aligns with the accuracy and F1-score metrics in \Cref{tbl:performance}, which show that filtering generally decreases model performance despite the apparent reduction in misclassifications.

\section{Discussion}
\label{sec:discussion}

RF outperforms NN and SVM in VPN classification across all tested conditions. RF's ensemble structure handles missing information in shorter flows effectively, while SVM degrades due to its sensitivity to feature sparsity and distribution shifts.

The superior performance of RF and NN with J=12 over J=5 highlights the benefits of finer-grained spectral features, particularly in Chat and Streaming traffic. However, RF12 shows diminishing returns over RF5, suggesting that beyond a certain threshold, deeper wavelet decomposition adds little value. Filtering disproportionately reduces File Transfer and Command \& Control traffic, exacerbating class imbalance and increasing misclassification risks, especially in underrepresented categories.

Misclassification analysis shows Chat traffic has the highest error rate, likely due to overlapping encrypted and non-encrypted patterns, while VoIP remains perfectly classified by RF, indicating distinct traffic characteristics.

Beyond accuracy, these findings highlight the importance of structured feature spaces in encrypted traffic analysis. NN models' sensitivity to dataset variations suggests benefits from pretraining or feature augmentation. Future work could explore adaptive wavelet decomposition, focusing on the most informative spectral bands to improve efficiency and scalability.

\section{Comparison with VNAT Study}
\label{sec:comparison}

\citeauthor{10044382}~\cite{10044382} introduced VNAT, focusing on uncertainty quantification and out-of-distribution (OOD) detection. While both studies use wavelet-based features, they differ in key aspects.

The primary distinction is in objectives: VNAT targets application classification using application-specific patterns, while we focus on binary VPN detection. Both studies confirm wavelet-based features' effectiveness in encrypted traffic classification.

Our approaches to flow processing differ. VNAT uses fixed 40.96-second intervals with a 20-packet minimum, while we compare expire flows with 41-second timeouts. Similarly, VNAT analyzes filtering through byte-level reductions, whereas our flow-count approach reveals disproportionate impacts on File Transfer and Command \& Control traffic, particularly affecting SVM performance.

Feature extraction methodologies are similar, but our study systematically evaluates two decomposition depths, showing that J=12 performs better than J=5, though with diminishing returns. Unlike VNAT, which combines statistical features with wavelet representations and only uses J=12, we conducted an additional experiment beyond our main wavelet-based analysis. This experiment used only carefully selected conventional features: mean, minimum, maximum, and standard deviation of inter-arrival times and packet sizes, calculated across bidirectional, forward, and backward directions. This conventional features approach achieved performance matching our wavelet-based results at both decomposition depths (J=5 and J=12).

While this finding is noteworthy, the current landscape of publicly available VPN datasets is limited. Besides ISCXVPN2016~\cite{DraperGil2016}, which has known inconsistencies~\cite{10044382}, VNAT remains the only publicly accessible dataset for VPN traffic analysis to our knowledge. This highlights a critical need for new, comprehensive VPN datasets that would enable more extensive evaluation of both conventional and wavelet-based approaches across different classification scenarios.

The studies also differ in model architecture: VNAT employs a Prototypical Network for application classification and OOD detection, while we demonstrate RF's comparable performance without specialized architectures. However, VNAT's OOD detection capability remains advantageous for handling unseen applications.

\section{Conclusion}
\label{sec:conc}

This study evaluated binary VPN traffic classification using wavelet-based features and machine learning models, focusing on the impact of wavelet decomposition levels and dataset filtering. Our results show that RF consistently achieves the highest classification accuracy, maintaining robustness across different preprocessing conditions, while SVM suffer the most from dataset reductions.
We found that deeper wavelet decompositions improve classification performance, particularly for complex traffic types, though the marginal gains may not
justify the additional computational overhead. Filtering significantly alters the dataset distribution, disproportionately affecting certain traffic categories and increasing misclassification rates.
Future research could explore adaptive wavelet decomposition techniques and hybrid models that combine structured and deep learning-based feature representations for enhanced classification accuracy and generalization. Additionally, creating a new VPN and non-VPN traffic dataset could address the limitations of existing datasets, ensuring more reliable evaluation and enhancing real-world applicability.

\section*{Data Availability}

This work utilizes the VNAT dataset~\cite{10044382} as the primary data source. While the original raw traffic traces from VNAT are not redistributed, all processed datasets derived from these traces---including extracted network flows, filtered datasets, and wavelet-based feature representations---are made available for research purposes. These datasets can be accessed at~\cite{github-repo}. 

\section*{Reproducibility}

All data and artifacts necessary to reproduce the results of this study, including analysis scripts, trained models, and performance metrics, are available at~\cite{github-repo}. The provided resources have been prepared to align with the methodologies detailed in this paper, ensuring full reproducibility of the machine learning experiments. By making these materials publicly accessible, we aim to facilitate further research and validation within the community.

\section*{Acknowledgement}

Supported by the János Bolyai Research Scholarship of the Hungarian Academy of Sciences. 
% This work was supported by Project no. 2024-1.2.6-EUREKA-2024-00009. 
Project no. 2024-1.2.6-EUREKA-2024-00009 has been implemented with the support provided by the Ministry of Culture and Innovation of Hungary from the National Research, Development and Innovation Fund, financed under the 2024-1.2.6-EUREKA funding scheme.

\printbibliography

\end{document}