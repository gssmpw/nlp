\section{Conclusions}

This work identifies critical cross and joint attention layers in diffusion models that directly influence text generation within images. Our proposed patching method is adaptable to various diffusion model architectures, regardless of the text encoder used. We demonstrate that in \SDXL, only three layers (out of 70) impact text generation, while in \DeepFloyd and SD3, only a single layer is responsible for the generated text (out of 22 and 24, respectively).
Fine-tuning these localized layers using LoRA significantly improves the quality of the generated text of a base model without affecting its remaining generative capabilities. This selective targeting approach also increases the efficiency and precision of image-editing methods applied to text, reducing unintended modifications to non-textual visual elements.
Additionally, our method can be leveraged to create an effective safeguard against the generation of harmful or toxic text in images, further highlighting its practical utility in safer and more efficient text-to-image generation workflows.


\subsubsection*{Acknowledgments}
The project was funded by German Research Foundation (DFG) within the framework of the Weave Programme under the project titled "Protecting Creativity: On the Way to Safe Generative Models", funding number 545047250.
The project was also supported by the National Science Centre, Poland, grants no: 2023/51/B/ST6/03004 and 2022/45/B/ST6/02817, PLGrid grant no. PLG/2024/017266, and by the Warsaw University of Technology within the (IDUB) programme.




