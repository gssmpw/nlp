\section{Experiments and Results}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/results_v2.jpg}
    \caption{\textbf{Effectiveness of hallucination mitigation across datasets.} Visual comparison of generated samples with (green border) and without (red border) our proposed method. From left to right: (a) Simple Shapes dataset \citep{aithal2024understanding}, where our method prevents the generation of extra instances, adhering to the single-instance-per-region distribution; (b) MNIST dataset \citep{lecun1998gradient}, where hallucinated artifacts that distort the digits are reduced; (c) Hands dataset \citep{afifi201911k}, where hallucinations such as missing, extra, or malformed fingers are corrected, producing anatomically accurate hands. Our approach consistently enhances realism and fidelity in generated images across different datasets.}
    \label{fig:results}
    \vspace{-5pt}
\end{figure*}

\subsection{Experimental Details}

We evaluate our proposed approach on three datasets: Simple Shapes \citep{aithal2024understanding}, MNIST \citep{lecun1998gradient}, and Hands \citep{afifi201911k}, each previously used in \citet{aithal2024understanding} to interpret the causes of hallucinations in diffusion models. 
% 
\begin{itemize}
    \item \textbf{Simple Shapes:} This synthetic dataset comprises 5,000 black-and-white images, where each image is divided into three equal vertical regions designated for a triangle, square, and pentagon, respectively. 
    Each shape has a 0.5 probability of appearing in its assigned column. 
    Following \citet{aithal2024understanding}, we train an unconditional DDPM \citep{sehwag2023minimaldiffusion} on this dataset. 
    For this model, we define hallucinations as instances where multiple shapes appear within a single column region (\eg \cref{fig:results} (a)). 

    \item \textbf{MNIST:} This dataset, widely used for handwritten digit recognition, consists of 60,000 grayscale images. 
    We train a class-conditional DDPM trained with classifier-free guidance \citep{ho2022cfg}. 
    Hallucinations observed in this model manifest as artifacts that distort the digits, potentially impacting recognition (\eg \cref{fig:results} (b)). 

    \item \textbf{Hands:} We randomly sample 5,000 images from the Hands dataset, which consists of high-quality images of human hands against uniform backgrounds.
    For this dataset, we train an ADM model \citep{nichol2021improved}.
    Hallucinations in this dataset are visually prominent, often manifesting as deformations or unrealistic anomalies, such as missing, additional, or malformed fingers (\eg \cref{fig:results} (c)).
\end{itemize}

For each dataset, we generate 1,000 samples using the same initial noise vectors and employ DDIM sampling with 250 inference steps, ensuring consistency and reproducibility across all experiments. 
We evaluate these generated images of all these datasets using FID \citep{heusel2017gans}. 
Further, since hallucinations are easily identifiable in Shapes and Hands datasets we report the percentage of hallucinated images directly. 
However, in MNIST due to the subjective difficulty in identifying hallucinated artifacts in handwritten digits, we instead report the classification accuracy.  

\subsection{Implementation Details}

Our implementation uses the following empirically determined hyperparameters unless otherwise specified. 
All models are trained with $T=1000$ timesteps. 
We focus on optimizing the temperature parameter, $\hat{\tau}$, between timesteps $T_1 = 0.92T$ and $T_2=0.6T$, corresponding to the interval where \citet{aithal2024understanding} detect hallucinations via high-variance intermediate outputs.
A scaling factor $\gamma=2$ is used to optimize $\hat{\tau}$ in the range of $[-2 , 2]$, effectively mapping the temperature parameter to the interval $[0.01, 100]$.
We use the Adam optimizer \citep{kingma2014adam} with a learning rate $\eta=0.01$ and run the optimization for $N=10$ iterations, applying early stopping when the gradient norm drops below $\delta=0.001$.

We periodically reinitialize $\hat{\tau}$ at intervals of $\lambda = 0.04T$, and masked perturbations are introduced just before each of the first three reinitializations: \ie $L = \{ T_1 - \lambda k + 1 ; k \in \{0,1,2\}\}$. We avoid further perturbations beyond this point, as they impede the model’s ability to recover meaningful features from the perturbation.  
The threshold for masking is set at $\beta = \mu_s + 1.5 \sigma_s$, where $\mu_s$ and $\sigma_s$ denote the mean and standard deviation of anomaly scores derived from the training samples.  

\subsection{Results and Discussion}

As outlined in the introduction, our work is the first, to the best of our knowledge, to propose a method for mitigating hallucinations that occur organically in unconditional generative models. 
Consequently, we evaluate the effectiveness of our approach by comparing it to a standard diffusion model without temperature scaling, which serves as our baseline. 
These results are summarized in \cref{tab:quant_results}, and visual examples are depicted in \cref{fig:results}.
Our method demonstrates substantial improvements in FID scores across all datasets: 12.1\% in Shapes, 25.6\% in MNIST, and 20.8\% in Hands. 
Additionally, the percentage of hallucinated images decreases by 6.7\% in the Shapes dataset and 12.9\% in Hands dataset, while classification accuracy  in MNIST improves by 2.3\%. 


\begin{table}[tbp]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|cc|cc|cc}
        \toprule
        \multirow{2}{*}{Method} & \multicolumn{2}{c|}{Shapes} & \multicolumn{2}{c|}{MNIST} & \multicolumn{2}{c}{Hands} \\
        & FID$\downarrow$ & Hal.\% $\downarrow$& FID$\downarrow$ & Acc.$\uparrow$ & FID$\downarrow$ & Hal.\% $\downarrow$\\
        \midrule
        Default & 178.4 & 7.8 & 20.3 & 92.0 & 129.1 & 22.1 \\
        Ours & 156.9 & 1.1 & 15.1 & 94.3 & 102.3 & 9.2\\
        \bottomrule
    \end{tabular}
    }
    \caption{\textbf{Quantitative evaluation of our proposed method compared to the default diffusion model without temperature scaling.} Our approach demonstrates improvements across all metrics, including enhanced FID scores for all datasets, higher classification accuracy for MNIST, and a reduced percentage of hallucinated images for both Shapes and Hands datasets.}
    \label{tab:quant_results}
    \vspace{-10pt}
\end{table}


\begin{table*}[tbp]
    \centering
    \begin{minipage}{0.3\textwidth}
        \centering
        \resizebox{\linewidth}{!}{%
            \begin{tabular}{l|c}
                \toprule
                Method & FID $\downarrow$ \\
                \midrule
                Default ($\tau=1.0$) & 129.1 \\
                \midrule
                Fixed $\tau$: & \\
                \quad $\tau = 0.01$ & 127.6 \\
                \quad $\tau = 0.1$ & 127.3 \\
                \quad $\tau = 10.0$ & 128.5 \\
                \midrule
                Adaptive $\tau$ & 115.2 \\
                \quad + Periodic re-initialization & 109.0 \\
                \quad + Masked perturbation & 102.3 \\
                \bottomrule
            \end{tabular}
        }
        \caption{Effect of temperature scaling configurations and sub-components in the proposed algorithm. }
        \label{tab:temp_param}
    \end{minipage}
    \hfill
    \begin{minipage}{0.3\textwidth}
        \centering
        \resizebox{\linewidth}{!}{%
            \begin{tabular}{ccc|c}
                \toprule 
                \multicolumn{3}{c|}{Resolution} & \multirow{2}{*}{FID $\downarrow$} \\
                $8\times 8$ & $16\times 16$ & $32 \times 32$ & \\
                \midrule
                \checkmark & - & - & 127.6\\
                - & \checkmark & - & 115.8\\
                - & - & \checkmark & 110.9\\
                \checkmark & \checkmark & - & 114.3\\
                \checkmark & - & \checkmark & 109.1\\
                - & \checkmark & \checkmark & 103.4\\
                \checkmark & \checkmark & \checkmark & 102.3\\
                \bottomrule
            \end{tabular}
        }
        \caption{Impact of modifying different attention resolutions with adaptive temperature scaling.}
        \label{tab:attn_res}
    \end{minipage}
    \hfill
    \begin{minipage}{0.34\textwidth}
        \centering
        \resizebox{\linewidth}{!}{%
            \begin{tabular}{l|c|c}
                \toprule
                Feature Backbone & Noised Aug. & FID $\downarrow$ \\
                \midrule
                \multirow{2}{*}{ResNet (ImageNet)} & \texttimes & 116.3\\
                                                   & \checkmark & 115.7\\
                \midrule
                \multirow{2}{*}{Diff. UNet (Hands)} & \texttimes & 105.5 \\
                                                   & \checkmark & 102.3\\
                \bottomrule
            \end{tabular}
        }
        \caption{Effectiveness of using the diffusion model’s denoising UNet for feature extraction compared to a ResNet backbone and the impact of noise augmentation for in-distribution memory bank creation.}
        \label{tab:memory_bank_ablation}
    \end{minipage}
    \vspace{-5pt}
\end{table*}

To gain more insights through ablations, which are discussed below, we concentrate on the Hands dataset, which better reflects real-world data.
In \cref{tab:temp_param} we illustrate the performance gains achieved by progressively incorporating each sub-component of our method, beginning with the baseline (a standard diffusion model equivalent to $\tau=1.0$).
First, we analyze the impact of using fixed temperature values ($\tau \in \{0.01, 0.1, 10.0\}$), which yield modest improvements over the baseline but show relatively consistent results.
This suggests that static temperature values are inadequate to handle varying noise conditions throughout the denoising process and diverse hallucination scenarios, as also reflected in the qualitative examples illustrated in \cref{fig:temp_test}.
Introducing a dynamically adjusted temperature parameter results in a notable reduction in FID scores, underscoring the importance of adaptive temperature control.
Additional performance gains are observed with periodic re-initialization, likely because it helps the process avoid getting stuck in sub-optimal states.
Finally, our masked perturbation strategy mitigates hallucinations through targeted perturbation of anomalous regions early in the denoising process, resulting in additional improvements in FID. 
In \cref{fig:abl_tempnoise}, we depict visual examples where adaptive temperature scaling alone is insufficient. 
In such cases, while adaptive temperature tuning partially reduces hallucinated features, combining it with masked perturbation effectively alleviates these artifacts, resulting in more realistic hand images. 

Additionally, we investigate the impact of modifying different combinations of attention resolutions ($8\times8$, $16\times16$, and $32\times32$) with adaptive temperature scaling in \cref{tab:attn_res}. 
Results indicate that modifying all resolutions yields the best performance; however, higher resolutions play a more substantial role in hallucination mitigation. 
This is intuitive, as lower resolutions primarily capture global features and their dependencies, while higher resolutions focus on finer, localized details essential for relatively accurate structure and feature delineation. 
By adjusting the attention distribution at higher resolutions, the model can better suppress hallucinatory artifacts that may arise from inaccurately emphasized local features.

We also explore the effectiveness of using the denoising UNet as the feature extraction backbone, compared to a ResNet as used in prior work \citep{roth2022patchcore,kim2024tackling}. 
In this context, we evaluate FID scores for feature extraction using an ImageNet-pretrained ResNet (specifically WideResNet-50 \citep{zagoruyko2016wide}) versus the diffusion model's encoder, with and without noise-augmented images when constructing the in-distribution memory bank.
The results which are tabulated in \cref{tab:memory_bank_ablation}, indicate that the denoising UNet consistently outperforms the ResNet backbone, likely because the UNet is trained to process noisy inputs, making it more effective at extracting meaningful features in noisy images. 
Additionally, using the denoising UNet itself to extract features eliminates reliance on external models.
Furthermore, noise augmentation in the memory bank creation process enhances performance, as it better simulates intermediate denoising outputs and improves memory bank robustness.

\begin{figure}[tbp]
    \centering
    \includegraphics[width=0.65\linewidth]{figs/ablations_noisepert.jpg}
    \caption{\textbf{Effect of adaptive temperature tuning and masked perturbation.} The default diffusion model (left) commonly generates artifacts like missing or extra fingers. Adaptive temperature tuning (middle) reduces such artifacts to a certain extent, while combining it with masked perturbation (right) effectively mitigates hallucinations, producing anatomically accurate hands.}
    \label{fig:abl_tempnoise}
    \vspace{-10pt}
\end{figure}

While our method successfully mitigates hallucinations, a limitation is the increased inference time due to the dynamic optimization of the temperature parameter, a common issue among inference-time optimization methods. 
A potential solution could involve incorporating a learnable temperature parameter directly into the training process, enabling the diffusion model to adaptively scale self-attention without additional inference-time adjustments. 
This approach could significantly reduce inference time while preserving performance gains.
Furthermore, the lack of a structured, standardized method to systematically generate and detect hallucinations constrains our experiments to a limited set of data distributions. 
Future work on structured frameworks for hallucination generation and detection could broaden the evaluation scope and advance mitigation techniques across varied datasets and diffusion models.
