\section{Method}

\subsection{Preliminaries}

Diffusion models \citep{ho2020ddpm} generate high-quality images by progressively transforming random noise into coherent images through a process of iterative denoising. 
These models rely on a denoising UNet that learns to reverse a forward noise addition process, with the goal of recovering the original image. 
The denoising UNet, parameterized by $\theta$, models an approximate posterior distribution:
\begin{equation}
    p_{\theta}(x_{t-1} | x_t ) =  \mathcal{N}\left ( x_{t-1}; \mu_\theta (x_t, t), \Sigma_\theta(x_t,t) \right ).
\end{equation}
At each timestep $t$, the UNet takes the noisy input $x_t$ and predicts the noise component $\epsilon_t$ that was added, obtaining the denoised output, $x_{t-1} = x_{t} - \epsilon_t$.
This denoising process is repeated for a finite number of steps, $T$, starting from random noise ($x_T \sim \mathcal{N}(\mu, \Sigma)$), progressively generating a realistic image, $x_0$. 

The denoising UNet incorporates multiple self-attention layers \citep{vaswani2017attention} at different resolutions, which are essential for capturing spatial dependencies across various regions of the image. 
This enables the model to produce locally and globally coherent features throughout the denoising process.

Within each self-attention layer, the intermediate features are projected into Query ($Q$), Key ($K$), and Value ($V$) vectors, which are then used to compute the feature updates, $\Delta\phi$, as follows:
\begin{equation}
    \Delta\phi = A \cdot V = \text{softmax}\left(\frac{Q\cdot K^T}{\sqrt{d}} \right ) \cdot V, \label{eq:feat_update_default}
\end{equation}
where, $A$ denotes the attention matrix and $d$ is the feature dimension of $Q$. 
The $i^{th}$ row of the attention matrix represents the weighted similarity between spatial location $i$ and all spatial locations in the image, including itself, indicating the relevance of each region of the image to $i$. 


\subsection{Preliminary Observations}

Self-attention plays a crucial role, particularly in the early denoising steps of diffusion models, where the image is still dominated by noise.
During these stages, self-attention enables the model to identify and enhance relevant features while attenuating extraneous noise.
However, in certain cases, the attention mechanism may perform inversely (\ie amplifying irrelevant features or suppressing essential features), which may lead to hallucinations in the final generated image.
We illustrate examples of these two scenarios in \cref{fig:posneg_emphsupp}, where intermediate denoised predictions are shown. 
The intermediate prediction at timestep $t$ is obtained using the following formula:
\begin{equation}
    \hat{x}_0^{(t)} = \left ( x_t - \sqrt{1 - \bar{\alpha}_t} \epsilon_t \right ) / \sqrt{\bar{\alpha}_t},
\end{equation}
where, $\bar{\alpha}_t$ is the cumulative product of the noise schedule up to timestep $t$ \citep{ho2020ddpm}. 
In \cref{fig:posneg_emphsupp}, rows 1 and 3 depict affirmative attention behaviors, where relevant features are correctly emphasized or irrelevant ones are suppressed, resulting in realistic images.
In contrast, rows 2 and 4 illustrate detrimental behaviors, where incorrect emphasis or suppression of features contributes to hallucinations\footnote{We use examples from hand generation, as hallucinatory artifacts like missing/additional/malformed fingers are particularly easy to identify.}.

To investigate and potentially control these unintended behaviors, we introduce a temperature parameter, $\tau$, to modulate the sharpness of the attention distribution in the softmax normalization. 
By adjusting $\tau$, we can control the spread of attention across spatial locations, potentially reducing unwanted emphasis or suppression. 
Formally, incorporating $\tau$, modifies the feature update equation, \cref{eq:feat_update_default} as follows:
\begin{equation}
    % \vspace{-5pt}
    \Delta \phi = \text{softmax} \left ( \frac{Q \cdot K^T}{\tau \cdot \sqrt{d}}\right) \cdot V.
\end{equation}

\vspace{-10pt}
\paragraph{Effect of Temperature Scaling on Attention Distribution.}
To understand how $\tau$ affects the attention distribution, we start with the softmax function, which transforms the similarity scores between Query ($Q$) and Key ($K$) vectors into a probability distribution, thereby computing the attention weights.
Expanding the softmax function, the attention distribution is given by,
\begin{equation}
    A_{i,j} = \frac{\text{exp} \left ( \frac{Q_i \cdot K_j}{\tau \cdot \sqrt{d}} \right )}{\Sigma_m \text{exp} \left ( \frac{Q_i \cdot K_m}{\tau \cdot \sqrt{d}} \right )},
\end{equation}
where, $A_{i,j}$ represents the attention weight between spatial locations $i$ and $j$. 
The formulation reduces to the original attention distribution when $\tau=1.0$, effectively removing the temperature scaling. 

As $\tau$ decreases, the factor $1/\tau$ increases, making the exponentials more sensitive to high similarity scores. This results in a sharper distribution, where a few spatial locations receive most of the attention, and the distribution approaches a point mass as $\tau \rightarrow 0$.
Conversely, as $\tau$ increases, the exponents become less sensitive to differences in similarity scores, resulting in a more uniform attention distribution, where the model attends to a broader range of spatial locations.
This temperature scaling mechanism allows us to modulate the radius of focus in self-attention, which can help control the amplification of relevant or irrelevant features in early denoising stages. 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.65\linewidth]{figs/pos_neg_emph_supp_v2.jpg}
    \caption{\textbf{Examples of affirmative and detrimental attention behaviors in diffusion models.}  The columns $\hat{x}_0^{(t_1)}$ and $\hat{x}_0^{(t_1-\Delta_t)}$ show the intermediate denoised predictions at an early denoising step $t_1$ and a subsequent step $t_1 - \Delta_t$. The $x_0$ column depicts the final denoised image. Rows 1 and 3 illustrate affirmative emphasis and suppression, respectively, resulting in realistic denoised images,  while rows 2 and 4 show detrimental emphasis and suppression, leading to hallucinations in the generated images. }
    \label{fig:posneg_emphsupp}
    \vspace{-5pt}
\end{figure}

\paragraph{Empirical Observations on Temperature Scaling.}
Initially, we experimented with different values of $\tau$ to observe its impact on mitigating hallucinations using the same set of initial noise ($x_T$) across trials. 
For reproducibility, we used DDIM sampling \citep{song2020ddim}, which enables deterministic denoising. 
Our observations, shown in \cref{fig:temp_test}, indicate that by manually adjusting $\tau$, we could mitigate hallucinations and produce in-distribution images from initial conditions that previously led to hallucinations. 

However, as observed in \cref{fig:temp_test}, these experiments reveal that there is no single, fixed value of $\tau$ that {\it consistently} prevents hallucinations across different scenarios. 
While a specific $\tau$ may improve the outcome for one sample, it can exacerbate hallucinatory artifacts in another. 
This limitation indicates that a static temperature value cannot robustly address hallucinations universally. 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\linewidth]{figs/temp_test_v3.jpg}
    \caption{\textbf{Example generations with temperature scaled attention.} For each column, we start with the same initial noise ($x_T$), which results in hallucinations under the default setting with no temperature scaling (\ie $\tau=1.0$). Each row depicts the generated samples for different combinations of $\tau_{32}$ and $\tau_{16}$, corresponding to the resolutions at which the self-attention layers operate --- $32\times32$ and $16\times 16$, respectively. Hallucination-free generations are indicated with green borders. This figure demonstrates that adjusting $\tau$ can mitigate hallucinations, although no single temperature value provides a universal solution across all scenarios. }
    \label{fig:temp_test}
    \vspace{-8pt}
\end{figure}

\subsection{Adaptive Attention Modulation (AAM)}

Our preliminary experiments suggest that a dynamic, context-aware tuning of the temperature parameter $\tau$ is essential for robust hallucination mitigation, as manual adjustment is impractical due to its time-consuming and labor-intensive nature. 
Therefore, we propose an adaptive temperature tuning mechanism that dynamically adjusts $\tau$ during denoising to modulate the attention distribution, ensuring effective hallucination mitigation across diverse scenarios. 

\vspace{-10pt}
\paragraph{Inference-Time Optimization for Temperature Tuning.}
We implement adaptive temperature tuning through an inference-time optimization strategy, a technique successfully employed in prior work \citep{poole2022dreamfusion, burgert2022peekaboo, burgert2024diffusion, lin2023magic3d}.
By optimizing the temperature parameter $\tau$ on-the-fly, our method tailors the attention distribution's sharpness to the specific context of each denoising step.

To ensure $\tau$ stays within a practical and stable range, we optimize an intermediate variable, $\hat{\tau}$, rather than directly optimizing $\tau$. 
Specifically, we define $\tau = 10^{\gamma \cdot \tanh{(\hat{\tau}})}$, allowing $\tau$ to vary smoothly within a controlled range (\ie $\tau \in [10^{-\gamma}, 10^{\gamma}]$), preventing extreme values that could destabilize the denoising process. 
We employ an exponential transformation because we observed that meaningful changes in $\tau$ often occur across different orders of magnitude, allowing for effective scaling at varying levels. 
This formulation also permits larger adjustments when needed, particularly in the early stages of optimization, while ensuring that $\tau$ remains positive, thereby avoiding potential issues associated with negative values.

An anomaly score derived from the PatchCore anomaly detection model \citep{roth2022patchcore}, which is a training-free model,  guides the optimization.
PatchCore constructs a memory bank from features of in-distribution training samples, which is then used to detect out-of-distribution (OOD) anomalies in generated images. 

To tailor PatchCore to our setup, we introduce a few modifications. 
To better match the early denoising stages, where noise is dominant, we augment the training data of the diffusion model with noisy samples generated using the same noise schedule as when training the diffusion model. 
This prevents the anomaly detection model from falsely identifying these noise characteristics as OOD. 
Further, instead of extracting features from an ImageNet pre-trained WideResNet-50 \citep{zagoruyko2016wide}, we extract features from the diffusion model's denoising UNet. 
These features are more representative of the intermediate outputs, as they are specifically tuned to extract meaningful structures from noisy inputs.
Following \citet{roth2022patchcore}, we use mid-level features (specifically from layers 7 and 11 of the UNet encoder), as they provide a balance, being neither too generic (as shallow features might be) nor overly biased towards denoising (as deeper features could be). 

Our method dynamically tunes $\tau$ over specific denoising timesteps to adapt to the evolving structure of the image as it progresses through the generation process:
\begin{enumerate}
    \item \textbf{Initial Denoising Stage ($T \ge t > T_1$)}:
    For the earliest timesteps, the model denoises using the default temperature setting (\ie $\tau=1.0$). 
    This phase allows the model to establish foundational structures from initial random noise, ensuring that the anomaly model has structured features to analyze rather than pure randomness.

    \item \textbf{Adaptive Tuning Stage  ($T_1 \ge t > T_2$)}: 
    In this stage, high-level structure and coarse features are defined, as observed in prior work \citep{choi2022perception, park2024explaining}.
    As hallucinations are most likely to emerge during this stage, we optimize $\tau$ during this range of timesteps as the coarse structure forms.
    The optimization details are as follows: 
    \begin{itemize}
        \item The optimization is performed over $N$ iterations, with early stopping based on the gradient norm to improve computational efficiency.
        \item At each timestep $t$, $\tau$ is initialized to the optimal value from the previous step. Further to prevent being stagnant at a local minimum, $\tau$ is periodically re-initialized to the default value.
        \item The objective is to minimize the anomaly score predicted by PatchCore, ensuring that features inconsistent with in-distribution characteristics are minimized during denoising.   
    \end{itemize}

    \item \textbf{Final Denoising Stage ($T_2 \ge t > 0$)}: 
    Once the high-level structure is established, we revert to the default temperature setting for the remaining timesteps.
    Since these later steps primarily focus on refining low-level/finer details (\eg textures), hallucinations are less likely to emerge, making adaptive tuning unnecessary during this phase.
\end{enumerate}

\vspace{-10pt}
\paragraph{Masked Perturbation for Early Hallucination Suppression.}
While adaptive temperature tuning addresses most hallucinations, certain hallucinatory artifacts manifesting during the very early denoising stages (\ie during $t \in [T,T_1]$) can persist. 
Since intermediate outputs at this stage are predominantly noise, these early hallucinations cannot be effectively detected by the anomaly detection model. 
To handle these cases, we introduce a masked perturbation strategy that selectively disrupts emerging hallucinations in localized regions. 

At specific denoising timesteps $t \in L$, we compute an anomaly heatmap $h$ from PatchCore, generating a binary mask $M$ based on a threshold $\beta$. 
This binary mask highlights anomalous regions, which are selectively perturbed as follows: 
\begin{equation}
    x_{t-1} \leftarrow M \cdot \zeta + (1-M) \cdot x_{t-1}, \quad \zeta \sim \mathcal{N}(\mu, \Sigma).
\end{equation}
This operation introduces noise selectively into the anomalous regions, preventing early-stage hallucinations from persisting in subsequent steps.

The complete algorithm for adaptive temperature tuning with masked perturbation is outlined in \cref{algo:adaptive_tuning}.

\begin{algorithm} 
\caption{Adaptive Attention Modulation}
\label{algo:adaptive_tuning}
\SetKwInOut{KwInit}{Initialize}

\KwIn{Diffusion model $f_{\theta}(\cdot)$, PatchCore model $g(\cdot)$, num. of timesteps $T$, thresholds $\lambda$, $\beta$, $\delta$, num. of optimization steps $N$, learning rate $\eta$, perturbation set $L$ }

\KwOut{Generated image, $x_0$}

\KwInit {$x_T \sim \mathcal{N}(\mu, \Sigma) $} 

\For{$t = T$ \textbf{down to} $1$}{
    \If{$T_1 \ge t > T_2$ }{ \tcp{\footnotesize Adaptive Tuning Stage}
        \If{$(T_1-t) \mod \lambda = 0$}{
            \tcp{\footnotesize Periodical Re-initialization}
            $\hat{\tau} \gets 0$ \; 
        }
        \For{$n = 1$ \textbf{to} $N$}{
            \tcp{\footnotesize Optimizing $\hat{\tau}$}
            $\epsilon_t = f_\theta(x_t, \tau= 10^{\gamma \cdot \tanh(\hat{\tau})})$\;
            $\hat{x}_0^{(t)} = \left ( x_t - \sqrt{1 - \bar{\alpha}_t} \epsilon_t \right ) / \sqrt{\bar{\alpha}_t}$ \;
            $s,h = g(\hat{x}_0^{(t)})$ \;
            $\hat{\tau} \gets \hat{\tau} - \eta \cdot \nabla_{\hat{\tau}} s$ \;
            \If{$|\nabla_{\hat{\tau}} s| <  \delta$}{
                \textbf{break}
            }
        }

        $\epsilon_t = f_\theta(x_t, \tau = 10^{\gamma \cdot \tanh(\hat{\tau})})$\;
        $x_{t-1} = x_{t} - \epsilon_{t}$ \;
        $\hat{x}_0^{(t)} = \left ( x_t - \sqrt{1 - \bar{\alpha}_t} \epsilon_t \right ) / \sqrt{\bar{\alpha}_t}$ \;
        \If{$t \in L$}{
            \tcp{\footnotesize Masked Perturbation}
            $s,h = g(\hat{x}_0^{(t)})$ \;            
            $M = h > \beta$ \;
            $x_{t-1} \gets M \cdot \zeta + (1 - M) \cdot x_{t-1}$ \;
        }
    }

    \Else{
        \tcp{\footnotesize Default Temperature Setting}
        $\epsilon_t = f_\theta(x_t, \tau = 1.0)$\;
        $x_{t-1} = x_{t} - \epsilon_{t}$ \;
    }
}
\end{algorithm}