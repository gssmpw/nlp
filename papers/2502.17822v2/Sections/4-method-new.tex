\section{Methodology}
\label{sec: method}

\subsection{Augmented Proposal Generator}

 \begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{Images/Framework.pdf}
    \vspace{-8pt}
    \caption
    {
       The pipeline of our Easy-Poly method. Real-time improvements to the baseline~\cite{li2024fast} are highlighted in distinct colors.
        \textbf{\textcolor[RGB]{255, 182, 193}{Pink}} denotes \textcolor{black}{the Optimization of Fast-Poly.}
        \textbf{\textcolor[RGB]{139, 58, 98}{Purple}} denotes \textcolor{black}{the new functional modules.}
     }
     \Description{}
    \label{fig: frameworkpoly}
\end{figure*}


% \section{Optimized FocalsConv Framework for Multi-modal Object Detection}
We propose an augmented proposal generator based on FocalsConv to generate more accurate 3D proposals. It involves upgrades to \textbf{CenterPoint} and \textbf{LargeKernel3D}, incorporating advanced data augmentation techniques and refined SpConv convolution methods. To tackle real-world challenges, we implement robust optimization and exception handling mechanisms for erroneous and empty frames. This leads to significant improvements in indexing efficiency during training, evaluation, and tracking phases, and substantial enhancements in object detection performance metrics, such as mAP and NDS (please see the Table~\ref{tab:mAP}).

Our optimized FocalsConv framework enhances the CenterPoint and LargeKernel3D methods through multi-modal data augmentation. A comprehensive analysis of augmentation techniques, including \textbf{"db\_sample"}, \textbf{"flip"}, \textbf{"rotate"}, \textbf{"rescale"}, and \textbf{"translate"}, reveals that a combination of \textbf{double flip} and \textbf{rotation} significantly boosts detection accuracy, especially in crowded scenes and for small object detection. The convolution process in FocalsConv is mainly implemented via the Det3D backbone network. We integrate a multi-modal LargeKernel3D module into the existing LiDAR-based LargeKernel3D framework and introduce a novel VoxelSpecific module, derived from VoxelLocal, for efficient voxelization. In the post-processing stage, FocalsConv employs rotated NMS followed by multi-class NMS. Comparative experiments with circular NMS show that PointPillars benefits the most from this approach, while LargeKernel3D achieves optimal performance with rotated NMS, and CenterPoint shows intermediate results. Table~\ref{tab:mAP} presents the performance differences between the LargeKernel3D and CenterPoint methods in both the original FocalsConv model and our optimized version.
% We propose a comprehensive optimization framework for FocaleConv, encompassing enhancements to \textbf{CenterPoint} and \textbf{LargeKernel3D}, with a primary focus on advancing multi-modal object detection. Our approach integrates sophisticated data augmentation techniques and refined spconv convolution methods. To address challenges in real-world scenarios, we implement robust optimization and exception handling mechanisms for erroneous and empty frames. This strategy significantly improves indexing efficiency during training, evaluation, and tracking phases, resulting in substantial enhancements to object detection performance metrics, notably mAP and NDS (see Table~\ref{tab:mAP}). The incorporation of advanced data augmentation techniques serves a dual purpose: mitigating overfitting risks and bolstering the model's generalization capabilities through strategic expansion of the training dataset.


\begin{table}
\caption{Comparison of Existing 3D object detection methods Applied to the nuScenes Val Set, except for line 2 using LIDAR only, all other methods are based on multi-modal.}
\label{tab:mAP}
    % \renewcommand{\arraystretch}{0.7}
    \setlength{\tabcolsep}{0.6mm}
  \begin{tabular}{ccclccl}
    \toprule
    \textbf{Method} & \textbf{Detector} & \textbf{ Augmentation} & \textbf{mAP} & \textbf{NDS} \\
    \midrule
     FocalsConv~\cite{chen2022focal} & CenterPoint~\cite{yin2021center} &  \checkmark & 63.86 & 69.41 \\
      FocalsConv~\cite{chen2022focal} & LargeKernel3D~\cite{chen2022scaling} & $\times$  & 63.30 & 69.10 \\
    \midrule
     % Ours & CenterPoint & 2D+3D & No & 63.15 & 68.88 \\
     \textbf{Ours} & CenterPoint~\cite{yin2021center} &  \checkmark & 
        \textcolor{blue}{64.89} & 
        \textcolor{blue}{70.13} \\
       % \textbf{70.28} \\
     % \midrule
     % Ours & LargeKernel3D & 2D+3D & No & 63.56 & 69.40 \\
     % Ours & LargeKernel3D & 2D+3D & \colorbox{red}{Yes}  & 
     \textbf{Ours} & LargeKernel3D~\cite{chen2022scaling} & \checkmark  & 
        \textcolor{red}{64.96} & 
        \textcolor{red}{70.28} \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Easy-Poly Framework}

% \subsection{Overview}
This section details the design and implementation of the Easy-Poly framework, which processes outputs from an augmented proposal generator to produce robust 3D multi-object tracking (MOT) results. The framework comprises two major modules: (i) the pipeline architecture with preprocessing and lifecycle management, and (ii) advanced data association combined with dynamic motion modeling. Figure~\ref{fig: frameworkpoly} provides an overview of the system architecture.

% \subsubsection{Pipeline}
The Easy-Poly pipeline is organized into five key stages: \textbf{Pre-processing}, \textbf{Association}, \textbf{Matching}, \textbf{Estimation}, and \textbf{Life-cycle Management}. In the pre-processing stage, the output from an optimized FocalsConv model is reformatted as input for tracking. Parallel computation is employed to filter 3D detections and predict the states of existing trajectories. The main steps are as follows:
\begin{itemize}
    \item \textbf{Detection Filtering and Prediction:} Each frame is processed using a two-stage approach. First, \textbf{Score Filtering (SF)} eliminates low-confidence detections to reduce false positives. Next, \textbf{NMS} is applied to remove redundant bounding boxes, thereby balancing precision and recall. Specialized filters then predict both the time-variable motion and time-invariant states, as well as refine the confidence scores of trajectories.
    \item \textbf{Association and Matching:} Cost matrices are constructed to perform a two-stage association. Voxel mask and geometry-based metrics accelerate the matching process, after which the Hungarian algorithm~\cite{kuhn1955hungarian} determines the optimal matching between detections and existing tracklets. Unmatched detections are subsequently initialized as new tracklets.
    \item \textbf{State Update and Frame Advancement:} For matched tracklets, time-invariant states are updated using a lightweight filter, while time-variable states are refined via an Extended Kalman Filter (EKF). A confidence-count mixed life-cycle approach further refines the tracking scores. The remaining tracklets are then forwarded for processing in subsequent frames.
\end{itemize}




\subsubsection{Data Preprocessing \& Prediction}

Our framework initiates with parallel processing of 3D detections and trajectory predictions. Leveraging outputs from the optimized FocalsConv model, we implement a dual-stage filtering strategy:

\begin{itemize}
\item \textbf{Score Filtering (SF):} Eliminates low-confidence detections ($\mathrm{score} < \tau_{\mathrm{SF}}$) to reduce false positives while preserving recall
\item \textbf{NMS:} Removes redundant boxes using class-specific voxel masking and geometry-aware IoU thresholds
\end{itemize}

Concurrent trajectory prediction employs specialized filters for:
\begin{itemize}
\item Time-variant states: Motion prediction via Extended Kalman Filter
\item Time-invariant states: Appearance modeling using lightweight CNNs
\item Score refinement: Confidence-count mixed estimation
\end{itemize}

This preprocessing stage reduces computational complexity by 38\% compared to baseline methods while maintaining 97.4\% detection recall, as quantified in Section~\ref{sec:experiments}.

\subsubsection{Multi-Hypothesis Tracking with Dynamic Association}
Our novel Multi-Hypothesis Tracking (MHT) algorithm addresses association ambiguity through probabilistic reasoning:

\begin{equation}
\mathbf{M}_{\mathrm{det}}, \mathbf{M}_{\mathrm{tra}}, \mathbf{U}_{\mathrm{det}}, \mathbf{U}_{\mathrm{tra}} = \mathrm{MHT}(\mathbf{C}, \boldsymbol{\tau})
\label{eq:mht}
\end{equation}

where $\mathbf{C} \in \mathbb{R}^{N_{\mathrm{cls}} \times N_{\mathrm{det}} \times N_{\mathrm{tra}}}$ denotes the class-wise association cost matrix and $\boldsymbol{\tau}$ represents category-specific matching thresholds. The MHT implementation proceeds as:

\begin{enumerate}
\item \textbf{Hypothesis Generation:} Create association candidates using kinematic (Mahalanobis distance) and appearance (cosine similarity) metrics
\item \textbf{Probability Estimation:} Compute hypothesis likelihoods $p(\mathcal{H}_i|\mathbf{Z}_{1:t})$ via Bayesian updates
\item \textbf{Pruning:} Retain top-$k$ hypotheses based on likelihood ratios ($\alpha=0.01$)
\item \textbf{Track Update:} Fuse selected hypotheses using log-likelihood weighted averaging
\end{enumerate}

As demonstrated in Figure~\ref{fig:hypothesis_tree}, this approach maintains multiple plausible associations until sufficient evidence accumulates, reducing ID switches by 22\% in occlusion scenarios.

\subsubsection{Adaptive Kalman Filtering}
We enhance state estimation through confidence-aware Kalman updates:

\begin{equation}
\hat{\mathbf{x}}_k = \hat{\mathbf{x}}_{k|k-1} + w_k\mathbf{K}_k(\mathbf{z}_k - \mathbf{H}_k\hat{\mathbf{x}}_{k|k-1})
\label{eq:XK}
\end{equation}

where $w_k \in [0,1]$ represents the detector confidence score. The covariance update incorporates this weighting:

\begin{equation}
\mathbf{P}_k = (\mathbf{I} - w_k\mathbf{K}_k\mathbf{H}_k)\mathbf{P}_{k|k-1}(\mathbf{I} - w_k\mathbf{K}_k\mathbf{H}_k)^\top + w_k^2\mathbf{K}_k\mathbf{R}_k\mathbf{K}_k^\top
\label{eq:PK}
\end{equation}

Dynamic noise adaptation further improves robustness:

\begin{align}
\mathbf{R}_{\mathrm{new}} &= \begin{cases}
0.9\mathbf{R}, & \|\mathbf{r}\|_2 < 1.0 \\
1.1\mathbf{R}, & \|\mathbf{r}\|_2 > 5.0 \\
\mathbf{R}, & \text{otherwise}
\end{cases} \\
\mathbf{Q}_{\mathrm{new}} &= \begin{cases}
0.9\mathbf{Q}, & \|\mathbf{v}\|_2 < 1.0 \\
1.1\mathbf{Q}, & \|\mathbf{v}\|_2 > 10.0 \\
\mathbf{Q}, & \text{otherwise}
\end{cases}
\label{eq:noise_adaptation}
\end{align}

where $\mathbf{r}$ denotes measurement residuals and $\mathbf{v}$ represents estimated velocity.

\subsubsection{Life-Cycle Management}
Our improved life-cycle module introduces three key mechanisms:

\begin{itemize}
\item \textbf{Confidence-Aware Termination:} Soft termination using exponentially weighted average scores:
\begin{equation}
s_{\mathrm{avg}}^{(t)} = \alpha s_{\mathrm{det}}^{(t)} + (1-\alpha)s_{\mathrm{avg}}^{(t-1)}, \quad \alpha=0.2
\end{equation}

\item \textbf{Adaptive Age Thresholding:} Dynamic track longevity $T_{\mathrm{max}} = f(s_{\mathrm{avg}}, \sigma_{\mathrm{env}})$ based on environmental complexity

\item \textbf{Occlusion Reasoning:} Motion-guided existence probability prediction for temporarily occluded objects
\end{itemize}


% (Optional additional section for lifecycle management and parameter tuning can be included here if needed.)



% In this section, we introduce the details of the Easy-Poly, that processing the output from the augmented proposal generator to produce the results of 3D MOT. Easy-Poly's pipeline is structured into five key stages: \textbf{Pre-processing}, \textbf{Association}, \textbf{Matching}, \textbf{Estimation}, and \textbf{Life-cycle}. The process unfolds as follows:
% \begin{itemize}
% \item \textbf{Pre-processing and Prediction:} For each frame, Fast-Poly employs parallel computing processes to filter 3D detections and predict existing trajectories. SF and NMS filters are applied to the detections, while specialized filters predict the motion (time-variable), score, and time-invariant states of trajectories.
% \item \textbf{Association and Matching:} Cost matrices are constructed for two-stage association. Voxel mask and geometry-based metric accelerate NMS and matching computations. The Hungarian algorithm~\cite{kuhn1955hungarian} is then applied to determine matched pairs, unmatched detections, and unmatched tracklets.
% \item \textbf{State Update:} To optimize matrix dimensionality, time-invariant and time-variable states in matched tracklets are updated using our proposed lightweight filter and Extended Kalman Filter (EKF), respectively.  Scores are refined using a confidence-count mixed life-cycle approach.
% \item \textbf{Initialization and Termination:} Unmatched detections are initialized as new active tracklets. FP agents in  are identified through soft-termination, considering max-age and online average refined scores.
% \item \textbf{Frame Advancement:} The remaining tracklets are forwarded to downstream tasks and prepared for subsequent frame tracking.
% \end{itemize}

% % Our Easy-Poly mainly optimizes and adjusts the past work of Fast Poly, see in Figure~\ref{fig: frameworkpoly}. For example, in the preprocessing phase, we format the first frame of the result file generated by FocalsConv+ as the input data of the tracking part. Fine-tune the score filter and voxel mask to optimize the NMS process. Existing 3D detectors generate numerous low-confidence bounding boxes to ensure high recall, but applying these detections directly to update trajectories can result in severe ID switches. To tackle this issue, raw detection objects must be preprocessed to reduce false-positive matches. Before NMS, we apply SF to remove detection objects of lower confidence scores. We apply NMS to remove bboxes with high similarity, improving precision without significant loss of recall. Directly applying NMS to objects would lead to substantial computational overhead. SF can efficiently remove apparent false-positive detections, improving the inference speed of the algorithm.





% Our Easy-Poly framework significantly enhances the previous Fast-Poly work, introducing numerous optimizations and innovations, as illustrated in Figure~\ref{fig: frameworkpoly}.
% In the pre-processing stage, we utilize the output from our optimized FocalsConv model, formatting the initial frame as input for the tracking module. We fine-tuned the score filter and voxel mask to enhance performance. A two-stage optimization strategy is implemented: first, we apply \textbf{Score Filtering (SF)} to eliminate low-confidence detections, effectively reducing false positives. Subsequently, \textbf{Non-Maximum Suppression (NMS)} is applied to remove highly similar bounding boxes, improving precision without significantly compromising recall. This dual-stage approach effectively balances detection accuracy and computational efficiency, addressing critical challenges in 3D object tracking for autonomous driving applications.


% In the data association stage, we focus on the critical task of the MHT algorithm, which is a novel technique that we introduced in addition to the \textbf{Hungarian}, \textbf{Greedy} and \textbf{Mutual Nearest Neighbor (MNN)} algorithms. 

% The MHT algorithm is a data association method used in multi-target tracking to handle the uncertainty in object-to-track assignments. The key idea behind MHT is to maintain multiple hypotheses about the associations between detections and tracks, and then update and prune these hypotheses over time as new observations become available. The algorithm operates as follows:

% \begin{itemize}
% \item \textbf{Initialization:} In the first time step, each detection is considered a new track, and a hypothesis is created for each detection.
% \item \textbf{Prediction:} For each existing track, the algorithm predicts the expected location of the object in the next time step based on the object's previous state and a motion model.
% \item \textbf{Association:} The algorithm computes the cost matrix of associating each detection with each existing track. This cost can be based on various factors, such as the distance between the predicted track location and the detection, the appearance similarity, or other object-specific features.
% \item \textbf{Generation of hypotheses:} The algorithm generates new hypotheses by considering all possible combinations of associating detections with tracks. This includes hypotheses where a detection is associated with an existing track, a new track is created for a detection, or a track remains unassociated (missed detection).
% \item \textbf{Hypothesis Pruning:} The number of hypotheses can grow exponentially over time, so the algorithm needs to prune the hypothesis tree to keep the problem tractable. This is typically done by removing hypotheses with low probabilities or scores.
% \item \textbf{Hypothesis Update:} For each remaining hypothesis, the algorithm updates the state of the associated tracks based on the new detections. This may involve updating the track's position, velocity, and other state variables.
% \item \textbf{Repeat:} The process repeats from step 2 for the next time step, using the updated track states and the new set of detections.


% \end{itemize}
 

% The MHT algorithm can be summarized by the following mathematical formula:

% \begin{equation}
%     \mathbf{m}_{\mathrm{det}}, \mathbf{m}_{\mathrm{tra}}, \mathbf{u}_{\mathrm{det}}, \mathbf{u}_{\mathrm{tra}} = \mathrm{MHT}(\mathbf{C}, \boldsymbol{\tau})
%     \label{eq:mht}
% \end{equation}

% $\mathbf{C} \in \mathbb{R}^{N_{\mathrm{cls}} \times N_{\mathrm{det}} \times N_{\mathrm{tra}}}$ is the cost matrix between classes, detections, and tracks. If the cost matrix has a size of $N_{\mathrm{det}} \times N_{\mathrm{tra}}$, then $\mathbf{C} \in \mathbb{R}^{N_{\mathrm{det}} \times N_{\mathrm{tra}}}$. $\boldsymbol{\tau} \in \mathbb{R}^{N_{\mathrm{cls}}}$ is the matching threshold for each class.  $\mathbf{m}_{\mathrm{det}} \in \mathbb{N}^{|\mathbf{m}_{\mathrm{det}}|}$ is the list of matched detection indices. $\mathbf{m}_{\mathrm{tra}} \in \mathbb{N}^{|\mathbf{m}_{\mathrm{tra}}|}$ is the list of matched track indices.  $\mathbf{u}_{\mathrm{det}} \in \mathbb{N}^{|\mathbf{u}_{\mathrm{det}}|}$ is the list of unmatched detection indices. $\mathbf{u}_{\mathrm{tra}} \in \mathbb{N}^{|\mathbf{u}_{\mathrm{tra}}|}$ is the list of unmatched track indices. Equation \eqref{eq:mht} describes the main function of the MHT algorithm, which is to take the cost matrix $\mathbf{C}$ and the matching thresholds $\boldsymbol{\tau}$ as inputs, and output the lists of matched detection and track indices $\mathbf{m}_{\mathrm{det}}$ and $\mathbf{m}_{\mathrm{tra}}$, as well as the lists of unmatched detection and track indices $\mathbf{u}_{\mathrm{det}}$ and $\mathbf{u}_{\mathrm{tra}}$.

% Specifically, the MHT algorithm first solves the optimal matching between detections and tracks for each class $c \in [1, N_{\mathrm{cls}}]$ using the Hungarian algorithm on the cost matrix $\mathbf{C}[c, :, :]$, and then filters out the matches that do not satisfy the threshold $\tau_c$. Finally, it combines the matching results from all classes to obtain the final lists of matched and unmatched detections and tracks. In summary, Equation \eqref{eq:mht} describes the inputs, outputs, and internal processing of the MHT algorithm, which is the mathematical expression of this algorithm.


% % \begin{equation}
% % \mathbf{m}{\mathrm{det}}, \mathbf{m}{\mathrm{tra}}, \mathbf{u}{\mathrm{det}}, \mathbf{u}{\mathrm{tra}} = \mathrm{MHT}(\mathbf{C}, \boldsymbol{\tau})
% % \label{eq:mht}
% % \end{equation}
% % Among them, the implementation of the function is as follows:
% % For each category, find the optimal match between the detection box of the category and the tracking target:
% % \begin {align*}
% % \mathbf {m}{\mathrm{det}}^{(c)}, \mathbf{m}{\mathrm {tra}}^{(c)} &= \mathrm {solve_hungarian}(\mathbf {C}[c, :, :], \tau_c)
% % \end {align*}
% % Among them, the function uses the Hungarian algorithm to solve the optimal match and filters out matches that do not meet the conditions based on a threshold.
% % Merge the matching results of all categories:

% % \begin{align*}
% % \mathbf{m}{\mathrm{det}} &= \bigcup{c=1}^{N_{\mathrm{cls}}} \mathbf{m}{\mathrm{det}}^{(c)} \
% % \mathbf{m}{\mathrm{tra}} &= \bigcup_{c=1}^{N_{\mathrm{cls}}} \mathbf{m}_{\mathrm{tra}}^{(c)} \
% % \end{align*}

% % Calculate the index of unmatched detection boxes and tracking targets:
% % \begin {align*}
% % \mathbf {u}{\mathrm{det}} &= \mathbb{N}^{N{\mathrm{det}}} \setminus \mathbf{m}{\mathrm{det}} \
% % \mathbf{u}{\mathrm{tra}} &= \mathbb{N}^{N_{\mathrm{tra}}} \setminus \mathbf{m}_{\mathrm{tra}}
% % \end{align*}

% % In summary, the mathematical formula of the MHT algorithm can be expressed as:
% % \begin{equation}
% % \mathbf{m}{\mathrm{det}}, \mathbf{m}{\mathrm{tra}}, \mathbf{u}{\mathrm{det}}, \mathbf{u}{\mathrm{tra}} = \mathrm{MHT}(\mathbf{C}, \boldsymbol{\tau})
% % \label{eq:mht}
% % \end{equation}

 
% % Among them, \mathbf{m}{\mathrm{det}}, \mathbf{m}{\mathrm{tra}} and \mathbf{u}{\mathrm{det}}, \mathbf{u}{\mathrm{tra}}, respectively, represent the index lists of matched detection boxes and tracking targets, and respectively represent the index lists of unmatched detection boxes and tracking targets.

% The key advantage of the MHT algorithm is its ability to handle uncertainty and ambiguity in the data association problem. By maintaining multiple hypotheses, the algorithm can explore different possible associations and delay the decision-making process until more information becomes available. This can lead to more robust and accurate tracking performance, especially in challenging scenarios with occlusions, missed detections, or false alarms.


% Extensive experimental evaluations were conducted to compare the performance of the \textbf{MHT}, \textbf{Hungarian}, \textbf{Greedy}, and \textbf{MNN} algorithms. The results conclusively demonstrate that the Hungarian and MHT algorithms outperform their counterparts in the given application context. The evaluation provides a detailed comparison of the strengths and weaknesses of each algorithm, highlighting their adaptability and accuracy within the specific use case.

% In addition, threshold adjustment significantly impacts object detection and tracking performance. The \textbf{Intersection over Union (IoU)} threshold determines the trade-off between precision and recall. A higher threshold ensures more accurate detections but may miss objects with slightly lower IoU. Conversely, a lower threshold increases sensitivity, potentially detecting more objects at the risk of false positives. Through extensive experimentation, we iteratively optimize this threshold to achieve a balance between detection accuracy and false alarm rate, thereby enhancing the overall system performance in autonomous driving scenarios.

% In our motion model, we introduce the confidence score from the object detector as a weighting factor in the update steps of both Linear Kalman Filter and Extended Kalman Filter. This approach assigns higher weights to detections with greater confidence during state and covariance matrix updates. Consequently, this enhancement improves the accuracy (MOTA and AMOTA) and robustness of 3D object tracking. The modified update equation for the state estimate can be expressed as:

% \begin{equation}
% \hat{x}k = \hat{x}{k|k-1} + w_k K_k(z_k - H_k\hat{x}_{k|k-1})
% \label{eq:XK}
% \end{equation}

% where $w_k$ is the confidence score of the detection at time step $k$, and $K_k$ is the Kalman gain.

% Similarly, the covariance update is adjusted to:

% \begin{equation}
% P_k = (I - w_kK_kH_k)P_{k|k-1}(I - w_kK_kH_k)^T + w_k^2K_kR_kK_k^T
% \label{eq:PK}
% \end{equation}

% This weighted approach effectively incorporates the reliability of detections into the filtering process, leading to more accurate and robust 3D object tracking performance.

% In the life-cycle management stage, compared to the baseline Fast-Poly, Easy-Poly improve in terms of the motion model. We adjusted the wheelbase ratio and rear tire ratio parameters, finding the optimal values through grid search or Bayesian optimization, changing them from the original 0.8 and 0.5 to the latest 0.6 and 0.3. Through these adjustments, tracking performance and robustness have been improved. 

% In the part where we use \textbf{Kalman Filter} for the motion model, we have introduced new dynamic adjustments to the noise covariance, including dynamic adjustment of measurement noise covariance and dynamic adjustment of process noise covariance. These are applied to both \textbf{Linear Kalman Filter} and \textbf{Extend Kalman Filter}.
% The dynamic adjustment of measurement noise covariance is based on the magnitude of the measurement residual to dynamically adjust the measurement noise covariance R. When the measurement residual is small, the value of R is reduced; when the measurement residual is large, the value of R is increased. The specific formula is as follows:
% % \[
% % R_{new} = \begin{cases}
% % 0.9 \cdot R, & \text{if } \|res\| < 1.0 \\
% % 1.1 \cdot R, & \text{if } \|res\| > 5.0 \\
% % R, & \text{otherwise}
% % \end{cases}
% % \]

% \begin{equation}
% R_{new} = \begin{cases}
% 0.9 \cdot R, & \text{if } \|res\| < 1.0 \\
% 1.1 \cdot R, & \text{if } \|res\| > 5.0 \\
% R, & \text{otherwise}
% \end{cases}
% \label{eq:R}
% \end{equation}

% \(R_{new}\) is the adjusted measurement noise covariance, \(R\) is the original measurement noise covariance, \(\|res\|\) represents the Euclidean norm (L2 norm) of the measurement residual, \(\|res\| = \sqrt{\sum_{i=1}^n res_i^2}\), where \(res_i\) is the i-th component of the residual vector. This formula expresses the following logic:
% If the norm of the residual is less than 1.0, R is reduced by 10\%. If the norm of the residual is greater than 5.0, R is increased by 10\%. If the norm of the residual is between 1.0 and 5.0, R remains unchanged. This dynamic adjustment strategy aims to adjust the behavior of the Kalman filter based on the reliability of the measurements. When the measurement residual is small, it increases the trust in the measurement (decreases R); when the measurement residual is large, it decreases the trust in the measurement (increases R).

% The dynamic adjustment of process noise covariance is based on the current state to dynamically adjust the process noise covariance Q. For example, adjusting the value of Q based on the magnitude of velocity. Its formula is as follows:


% % \[
% % Q_{new} = \begin{cases}
% % 0.9 \cdot Q, & \text{if } \|\mathbf{v}\| < 1.0 \\
% % 1.1 \cdot Q, & \text{if } \|\mathbf{v}\| > 10.0 \\
% % Q, & \text{otherwise}
% % \end{cases}
% % \]

% \begin{equation}
% Q_{new} = \begin{cases}
% 0.9 \cdot Q, & \text{if } \|\mathbf{v}\| < 1.0 \\
% 1.1 \cdot Q, & \text{if } \|\mathbf{v}\| > 10.0 \\
% Q, & \text{otherwise}
% \end{cases}
% \label{eq:Q}
% \end{equation}


% \(Q_{new}\) is the adjusted process noise covariance, \(Q\) is the original process noise covariance, \(\mathbf{v} = [state_1, state_2]\) represents the first two components of the state vector (assumed to be velocity components), \(\|\mathbf{v}\| = \sqrt{state_1^2 + state_2^2}\) is the Euclidean norm (L2 norm) of the velocity vector.
% This formula expresses the following logic: If the norm of the velocity is less than 1.0, Q is reduced by 10\%. If the norm of the velocity is greater than 10.0, Q is increased by 10\%. If the norm of the velocity is between 1.0 and 10.0, Q remains unchanged.


% This dynamic adjustment strategy aims to adjust the Kalman filter's process model based on the current state (in this case, velocity). When the velocity is low, it decreases the process noise (reduces Q), indicating higher confidence in the system dynamics; when the velocity is high, it increases the process noise (increases Q), indicating lower confidence in the system dynamics.

% Autonomous vehicles encounter diverse environmental conditions during operation, such as urban streets, highways, and adverse weather. Dynamic adjustment of R and Q enables the Kalman filter to adapt to these varying conditions, enhancing tracking accuracy by increasing measurement uncertainty in rainy conditions and decreasing it in clear weather. Sensor performance in autonomous vehicles may fluctuate due to factors like temperature, vibration, or partial occlusion. Dynamic R adjustment compensates for these variations. Optimal noise parameters may differ for near and far target tracking, with Q allowing more precise tracking at close range and greater uncertainty at longer distances.

% In additional, we proposed increasing the maximum age parameter to 20 for all detection and tracking categories. This modification significantly extends object tracking duration while maintaining high tracking accuracy and computational efficiency. Consequently, we observed a substantial reduction in frame loss during life-cycle management, resulting in more complete and robust tracking trajectories for each object of interest.

% Examining the implementation details across stages, our Easy-Poly demonstrates comprehensive optimizations from preprocessing and data association to motion model evaluation and lifecycle management. The framework introduces innovative elements, including the MHT algorithm and dynamic adjustment of noise covariances (\textbf{measurement} and \textbf{process} noise). Our extensive experimental evaluation, encompassing comparative studies and ablation analyses, demonstrates the meticulousness and comprehensiveness of the proposed Easy-Poly approach. These experiments rigorously validate the efficacy and robustness of our method across diverse scenarios and conditions.

