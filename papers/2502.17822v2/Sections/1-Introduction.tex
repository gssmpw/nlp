\section{Introduction}
% 背景
% 已有的方法以及不足
% 为了解决什么问题，提出了什么方法，包含什么。。。
% 实现什么样的效果
% contribution
\label{sec: introduction}


\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{Images/TopFigure.pdf}
    \vspace{-8pt}
    \caption{
    Data augmentation effect of CenterPoint and LargeKernel3D in multi-modal mode. It illustrates the performance gains of FocalsConv in 3D object detection. \textbf{(a)} and \textbf{(b)} present CenterPoint results, while \textbf{(c)} and \textbf{(d)} showcase LargeKernel3D outcomes. Notably, \textbf{(a)} and \textbf{(c)} utilize the baseline FocalsConv model, whereas \textbf{(b)} and \textbf{(d)} employ our augmented proposal generator, demonstrating reduced false negatives and false positives. This comparison also highlights our augmented proposal generator's superiority over original detectors particularly in handling small objects and crowded scenes.}
     \Description{}
    \label{fig: topfig}
\end{figure*}

% Recent years have witnessed significant advancements in 3D MOT technologies. Current research trends focus on using data fusion from multiple sensors, including cameras, LiDAR, and millimeter-wave radar, to enhance tracking performance. Traditional filtering techniques and deep learning approaches are being widely employed in 3D MOT systems, contributing to their improved efficacy~\cite{pftrack,ding20233dmotformer}. 

% Most 3D MOT systems based on 3D object detection often overlook improvements to the detection process itself. Although Poly-MOT and its successor Fast-Poly employ the FocalsConv~\cite{chen2022focal} model and utilize CenterPoint~\cite{yin2021center} and LargeKernel3D~\cite{chen2022scaling} as object detectors, they lack further data augmentation and convolution optimization in multi-modal settings, leaving room for improvement in object detection results. Moreover, recent 3D MOT methods such as Poly-MOT and Fast-Poly exhibit relatively high IDS, FN, and FP values, often neglecting applications in crowded scenarios, small object detection, and adverse weather conditions, thus failing to achieve optimal tracking performance. In addition, these methods demonstrate deficiencies in pre-processing, association processes, motion module evaluation, and life-cycle management.

% We propose \textbf{Easy-Poly}, a real-time filter-based 3D MOT method for multiple object categories, built on the \textbf{tracking-by-detection (TBD)} framework. To enhance 3D object detection in the preprocessing stage, particularly for crowded scenes, small objects, and adverse weather conditions, we abandoned the \textbf{OpenPCDet}~\cite{lang2019pointpillars} framework and the less efficient \textbf{PointPillars}~\cite{lang2019pointpillars} method within FocalsConv. Instead, we focused on CenterPoint and LargeKernel3D detectors, implementing specialized data augmentation techniques for LargeKernel3D's multi-modal fusion mode. Our proposed Easy-Poly achieves significant improvements in small object detection and crowded scene analysis through multi-modal data augmentation, optimized convolution operations, and efficient indexing techniques during pre-processing, as demonstrated in Figure~\ref{fig: topfig}.

% Beyond pre-processing, we refined the motion model by adjusting parameters via grid search or Bayesian optimization, improving AMOTA and IDS values. We optimized the adaptive Kalman filter by dynamically adjusting the process noise covariance Q and the measurement noise covariance R in the dynamic motion modeling (DMM), enhancing the tracking performance in challenging weather and scenarios. Incorporating detection confidence as a weight in Linear and Extended Kalman Filters improved 3D object tracking accuracy and robustness. We introduced the dynamic track-oriented data association (DTO) module in the association stage to improve the effectiveness of the data association. In life-cycle management, we optimized tracking effectiveness and reduced failure rates by extending tracking frame counts. These enhancements address the shortcomings of previous methods such as Poly-MOT and Fast-Poly, particularly in reducing missed detections and false positives and improving tracking performance in complex weather and special scenarios.

% We conducted comprehensive multi-modal experiments on Poly-MOT, Fast-Poly, and our proposed Easy-Poly model, yielding systematic results and reliable analysis. Optimized CenterPoint and LargeKernel3D methods demonstrated significant improvements on the nuScenes dataset. For object detection, CenterPoint's mAP increased from \textbf{63.86\%} to \textbf{64.89\%} on the nuScenes validation set, while LargeKernel3D improved from \textbf{63.30\%} to \textbf{64.96\%}. In multi-object tracking, CenterPoint's AMOTA rose from \textbf{73.1\%} to \textbf{74.5\%}. LargeKernel3D excelled in \textbf{MOTA}, \textbf{AMOTA}, \textbf{AMOTP}, \textbf{FPS}, and ID switches (\textbf{IDS}). Notably, AMOTA reached \textbf{75.0\%} with \textbf{34.9} FPS, achieving 1× faster inference than the baseline. Experimental results indicate that Easy-Poly exhibits enhanced adaptability and robustness across diverse and complex road conditions and weather scenarios, positioning it as a more versatile and reliable solution for autonomous driving applications.

% \section{Introduction}
% \label{sec:intro}

Recent years have witnessed significant advancements in 3D multi-object tracking (3D MOT), largely driven by the demands of autonomous driving, robotics, and mixed reality applications. The research trend has increasingly leaned toward the fusion of multi-modal data to enhance both reliability and accuracy~\cite{pftrack,ding20233dmotformer}. 

Traditional filtering techniques have coexisted with deep learning-based approaches, each contributing to robust 3D MOT systems. Nonetheless, most existing pipelines predominantly focus on the tracking stage, devoting less attention to improving 3D object detection itself. For instance, Poly-MOT and Fast-Poly employ the FocalsConv~\cite{chen2022focal} framework together with detectors such as CenterPoint~\cite{yin2021center} and LargeKernel3D~\cite{chen2022scaling}, but they do not thoroughly explore data augmentation or convolutional optimization in multi-modal settings. Moreover, they exhibit high identity switches (IDS), false negatives (FN), and false positives (FP), reflecting suboptimal performance in crowded scenarios, small-object detection, and adverse weather. These shortcomings underscore the need for more comprehensive methods that can efficiently integrate detection improvements with advanced filtering, robust association, and effective life-cycle management.

In this work, we propose \textbf{Easy-Poly}, a real-time filter-based 3D MOT method that follows the \emph{tracking-by-detection} (TBD) paradigm, supporting multiple object categories and offering substantial improvements in complex environments. 
First, we build a \textbf{Augmented Proposal Generator} based on FocalsConv. This generator substantially elevates detection quality by incorporating refined sparse convolution operations and multi-modal data augmentation, leading to notable improvements in dense-traffic scenes and for small-object categories. Then, we introduce a carefully optimized \emph{Easy-Poly} pipeline (Figure~\ref{fig: frameworkpoly}) that orchestrates the flow of high-quality detections through pre-processing, association, matching, estimation, and life-cycle management. Specifically, we integrate \textbf{Score Filtering (SF)} and Non-Maximum Suppression (NMS) to prune low-confidence detections, apply a \textbf{Dynamic Track-Oriented (DTO)} module to handle ambiguous data association and propose a \emph{Dynamic Motion Modeling (DMM)} strategy that infuses confidence weighting into Kalman filter updates while adaptively adjusting both measurement and process noise covariances. These enhancements collectively mitigate false positives, reduce tracking failures, and boost the robustness of tracking.

Extensive experiments on the nuScenes dataset validate the efficacy of Easy-Poly, demonstrating superior detection and tracking performance compared to Poly-MOT and Fast-Poly baselines. With the augmented proposal generator, \emph{CenterPoint} achieves an mAP improvement from \textbf{63.86\%} to \textbf{64.89\%}, while \emph{LargeKernel3D} improves from \textbf{63.30\%} to \textbf{64.96\%}. Moreover, in 3D MOT, Easy-Poly raises CenterPoint’s AMOTA from \textbf{73.1\%} to \textbf{74.5\%}, and LargeKernel3D reaches \textbf{75.0\%} AMOTA at \textbf{34.9} FPS—almost doubling the inference speed of the baseline. Our framework thereby offers an efficient, versatile, and more reliable solution for real-world autonomous driving, underscoring the importance of synergistic improvements in both detection and tracking modules.

This paper makes the following key contributions:
\begin{itemize}
    \item We propose a novel \textbf{Augmented Proposal Generator} that integrates refined sparse convolution and multi-modal data augmentation, significantly improving 3D detection quality in dense-traffic and small-object scenarios.
    \item We introduce an \textbf{Easy-Poly} pipeline encompassing pre-processing, data association, and motion modeling. Notably, we design a \textbf{DTO} algorithm for robust association under ambiguous conditions and a \textbf{DMM} module that adaptively adjusts noise covariances.
    \item We incorporate \textbf{confidence-weighted Kalman filtering} and \textbf{dynamic threshold management} into life-cycle management, enhancing tracking accuracy and robustness in adverse weather and complex road conditions.
    \item Extensive experiments on nuScenes show that Easy-Poly outperforms Poly-MOT and Fast-Poly baselines in both detection (mAP, NDS) and MOT metrics (AMOTA, MOTA, FPS), validating the effectiveness and efficiency of our design.
\end{itemize}


