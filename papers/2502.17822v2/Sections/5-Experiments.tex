\section{Experiments}
\label{sec: experiments}

\begin{table*}
        % \centering
        \caption{A comparison between our proposed method with other advanced methods on the nuScenes test set.
        % This leaderboard is available at \href{https://www.nuscenes.org/tracking?externalData=all&mapData=all&modalities=Any}{nuScenes official benchmark}.
        $\ddagger$ means the GPU device.
        \textcolor{black}{The reported runtimes of all methods exclude the detection time.}
        Poly-MOT~\cite{li2023poly}, Fast-Poly~\cite{li2024fast} and Easy-Poly rely entirely on the detector input, as they do not utilize any visual or deep features \textcolor{black}{during tracking}.}
        \label{table:nu_test}
        % \renewcommand{\arraystretch}{0.7}
        \setlength{\tabcolsep}{1.6mm}
        {
        \begin{tabular}{cccc|ccc|ccc}
        \toprule
        \multicolumn{1}{c}{\textbf{Method}} & \textbf{Device} & \textbf{Detector} & \textbf{Input} & \textbf{AMOTA}$\uparrow$ & \textbf{MOTA}$\uparrow$ & \textbf{FPS}$\uparrow$ & \textbf{IDS}$\downarrow$ & \textbf{FN}$\downarrow$ & \textbf{FP}$\downarrow$ \\ \midrule
                                     EagerMOT~\cite{kim2021eagermot}               & \textbf{\text{--}}       & CenterPoint~\cite{yin2021center}\&Cascade R-CNN~\cite{cai2018cascade}         & 2D+3D       & 67.7      & 56.8     & 4    & 1156    & 24925   & 17705   \\
                                   CBMOT~\cite{benbarka2021score}     & I7-9700          & CenterPoint~\cite{yin2021center}\&CenterTrack~\cite{zhou2020tracking}          & 2D+3D         & 67.6      & 53.9      & \textcolor{red}{80.5}    & 709    & 22828   & 21604   \\
                                   % ShaSTA~\cite{sadjadpour2023shasta} & A100$\ddagger$       & CenterPoint~\cite{yin2021center}         & 3D      & 69.6      & 57.8     & 10     & 473    & 21293   & 16746   \\
                                   Minkowski~\cite{gwak2022minkowski} & TITAN$\ddagger$  & Minkowski~\cite{gwak2022minkowski}         & 3D      & 69.8      & 57.8     & 3.5    & 325    & 21200   & 19340   \\
                                   ByteTrackv2~\cite{zhang2023bytetrackv2} & \textbf{\text{--}}       & TransFusion-L~\cite{bai2022transfusion}         & 3D      & 70.1      & 58     & \textbf{\text{--}}    & 488    & 21836   & 18682   \\
                                   3DMOTFormer~\cite{ding20233dmotformer}& 2080Ti$\ddagger$       & BEVFuison~\cite{liu2023bevfusion}       & 2D+3D      & 72.5      & 60.9     & \textcolor{blue}{54.7}    & 593    & 20996   & \textcolor{blue}{17530}   \\  
                                   %CAMO-MOT~\cite{li2023camo}& 3090Ti$\ddagger$   & BEVFuison~\cite{liu2023bevfusion}\&FocalsConv~\cite{chen2022focal}   & 2D+3D      & 75.3      & \textbf{63.5}     & \textbf{\text{--}}    & 324    & 18192   & 17269   \\
                                   Poly-MOT~\cite{li2023poly}               & 9940X       & LargeKernel3D~\cite{chen2022scaling}         &2D+3D       & \textcolor{blue}{75.4}      & \textcolor{blue}{62.1}     & 3    & \textcolor{blue}{292}    & \textcolor{blue}{17956}   & 19673   \\ 
                                  Fast-Poly~\cite{li2024fast}               & 7945HX       & LargeKernel3D~\cite{chen2022scaling}         &2D+3D       & \textcolor{blue}{75.8}      & \textcolor{blue}{62.8}     & 34.2    & \textcolor{blue}{326}    & \textcolor{blue}{18415}   &  \textcolor{blue}{17098}  \\ \midrule

                                  \textbf{Easy-Poly (Ours)}               & 4090Ti$\ddagger$       & LargeKernel3D~\cite{chen2022scaling}         &2D+3D       &  \textcolor{red}{75.9}      & \textcolor{red}{63.0}     & \textcolor{blue}{34.9}    & \textcolor{red}{287}    & \textcolor{red}{17620}   &   \textcolor{red}{16718}  \\
        \bottomrule
        \end{tabular}}
        % \vspace{-1.5em}
 \end{table*}


\begin{table*}
\vspace{0.5em}
\begin{center}
\caption{
{A comparison of existing methods applied to the nuScenes val set.}}
\label{table:nu_val}
% \renewcommand{\arraystretch}{0.7}
\setlength{\tabcolsep}{2.4mm}
{
\begin{tabular}{cccccccc}
\toprule
\bf{Method} & \bf{Detector} & \bf{Input Data} & \bf{MOTA$\uparrow$} & \bf{AMOTA$\uparrow$} & \bf{AMOTP$\downarrow$} & \bf{FPS$\uparrow$} & \bf{IDS$\downarrow$}  \\ \hline
CBMOT~\cite{benbarka2021score}   & CenterPoint~\cite{yin2021center} \& CenterTrack~\cite{zhou2020tracking} & 2D + 3D & -- & 72.0 & \textbf{\textcolor{red}{48.7}}  & -- & 479   \\
EagerMOT~\cite{kim2021eagermot}  & CenterPoint~\cite{yin2021center} \& Cascade R-CNN~\cite{cai2018cascade} & 2D + 3D  & -- & 71.2   & 56.9 & 13  & 899    \\
SimpleTrack~\cite{pang2022simpletrack}  & CenterPoint~\cite{yin2021center} & 3D & 60.2 & 69.6  & 54.7 & 0.5  & 405  \\
CenterPoint~\cite{yin2021center}   & CenterPoint~\cite{yin2021center} & 3D & -- & 66.5  & 56.7 & -- & 562 \\ 
OGR3MOT~\cite{zaech2022learnable}  & CenterPoint~\cite{yin2021center} &3D & 60.2 & 69.3  & 62.7 & 12.3 & \textbf{\textcolor{blue}{262}}  \\ \hline

\textbf{Poly-MOT}~\cite{li2023poly}      & CenterPoint~\cite{yin2021center} & 3D & 61.9 & 73.1   & \textbf{\textcolor{blue}{52.1}} & 5.6 & 281   \\ 
% \textbf{Poly-MOT}~\cite{li2023poly}      & LargeKernel3D-L~\cite{chen2022scaling}  & 3D   & \textbf{\textcolor{red}{75.2}}    & 54.1   & \textbf{\textcolor{red}{252}} \\ 

\textbf{Poly-MOT}~\cite{li2023poly}      & LargeKernel3D-L~\cite{chen2022scaling}  & 3D & 54.1 & \textbf{\textcolor{red}{75.2}}    & 54.1  & 8.6 & 252 \\

\textbf{Fast-Poly}~\cite{li2024fast}      & CenterPoint~\cite{yin2021center} & 3D & \textbf{\textcolor{blue}{63.2}}  & 73.7   &  -- & \textbf{\textcolor{blue}{28.9}} & 414   \\ \hline
 
\textbf{Easy-Poly (Ours)}       & CenterPoint~\cite{yin2021center} & 2D + 3D & \textbf{\textcolor{blue}{64.4}} & \textbf{\textcolor{blue}{74.5}}   & 54.9  & \textbf{\textcolor{blue}{34.6}} & \textbf{\textcolor{blue}{272}}   \\
\textbf{Easy-Poly (Ours)}       & LargeKernel3D~\cite{chen2022scaling}  & 2D + 3D  & \textbf{\textcolor{red}{64.8}} & \textbf{\textcolor{blue}{75.0}}    & \textbf{\textcolor{blue}{53.6}}  & \textbf{\textcolor{red}{34.9}}  & \textbf{\textcolor{red}{242}} \\ \hline
% \vspace{-4.5em}
% \setlength{\abovecaptionskip}{3pt}
% \setlength{\belowcaptionskip}{3pt}
\end{tabular}}
\end{center}
\end{table*}

\subsection{Datasets}

% The nuScenes dataset~\cite{caesar2020nuscenes} consists of 850 training and 150 test sequences, capturing a wide range of driving scenarios, including challenging weather conditions and nighttime environments. Each sequence contains approximately 40 frames, with keyframes sampled at 2Hz and fully annotated. In addition to this, it provides annotations for object-level attributes such as visibility, activity, pose, and more. It includes a large volume of RGB and point-cloud data (in PCD format). The official evaluation protocol utilizes \textbf{AMOTA}, \textbf{MOTA}, and \textbf{sAMOTA}~\cite{weng20203d} as primary metrics, evaluating performance across seven object categories: Car (\textit{Car}), Bicycle (\textit{Bic}), Motorcycle (\textit{Moto}), Pedestrian (\textit{Ped}), Bus (\textit{Bus}), Trailer (\textit{Tra}), and Truck (\textit{Tru}). Given the substantial size of the complete nuScenes dataset, users often prefer the nuScenes-mini dataset. Notably, Poly-MOT, Fast-Poly, and our proposed Easy-Poly methods exclusively utilize keyframes for tracking tasks.


The nuScenes dataset~\cite{caesar2020nuscenes} consists of 850 training and 150 test sequences, capturing a wide range of driving scenarios, including challenging weather conditions and nighttime environments. Each sequence contains approximately 40 frames, with keyframes sampled at 2Hz and fully annotated. The official evaluation protocol utilizes \textbf{AMOTA}, \textbf{MOTA}, and \textbf{sAMOTA}~\cite{weng20203d} as primary metrics, evaluating performance across seven object categories: Car (\textit{Car}), Bicycle (\textit{Bic}), Motorcycle (\textit{Moto}), Pedestrian (\textit{Ped}), Bus (\textit{Bus}), Trailer (\textit{Tra}), and Truck (\textit{Tru}). Notably, Poly-MOT, Fast-Poly, and our proposed Easy-Poly methods exclusively utilize keyframes for tracking tasks.

\subsection{Implementation Details}

% Our tracking method is implemented in Python under the Nvidia 4090X GPU.  Hyperparameters are chosen based on the best AMOTA identified in the validation set. SF thresholds are category-specific and detector-specific, which are (\textit{Bic}: 0.15; are (\textit{Car}: 0.16; are (\textit{Moto}: 0.16; \textit{Bus}: 0.12; \textit{Tra}: 0.13; \textit{Tru}: 0; \textit{Ped}: 0.13) on nuScenes on Waymo. The NMS thresholds are 0.08 on all categories and datasets. We also employ Scale-NMS~\cite{huang2021bevdet} on (\textit{Bic}, \textit{Ped}) on nuScenes. With default $IoU_{bev}$ in NMS, we additionally utilize our proposed $A\text{-}gIoU_{bev}$ to describe similarity for (\textit{Bic}, \textit{Ped}, \textit{Bus}, \textit{Tru}) on nuScenes. The motion models and filters are consistent with~\cite{li2023poly}. The lightweight filter is implemented by the median filter with $l_{lw}=5$ on all datasets. The association metrics are all implemented by $A\text{-}gIoU$ on all datasets. The first association thresholds $\theta_{fm}$ are category-specific, which are (\textit{Bic, Moto, Bus}: 1.6; \textit{Car, Tru}: 1.2; \textit{Tra}: 1.16;\textit{Ped}: 1.78) on nuScenes. Voxel mask size $\theta_{vm}$ is 5\textit{m} on nuScenes.  The count-based and output file strategies are consistent with~\cite{li2023poly}. In the confidence-based part, decay rates $\sigma$ are category-specific, which are (\textit{Ped}: 0.18; \textit{Car}: 0.26; \textit{Tru, Moto}: 0.28; \textit{Tra}: 0.22; \textit{Bic,Bus}: 0.24) on nuScenes. The delete threshold $\theta_{dl}$ are (\textit{Bus}: 0.08,  \textit{Ped}: 0.1 and 0.04 for other categories) on nuScenes.

Our tracking framework is implemented in Python and executed on an Nvidia 4090X GPU. Hyperparameters are optimized based on the highest AMOTA achieved on the validation set. The following category-specific and SF thresholds are employed for nuScenes: (\textit{Bic}: 0.15; \textit{Car}: 0.16; \textit{Moto}: 0.16; \textit{Bus}: 0.12; \textit{Tra}: 0.13; \textit{Tru}: 0; \textit{Ped}: 0.13). NMS thresholds are uniformly set to 0.08 across all categories and datasets. Additionally, we implement Scale-NMS~\cite{huang2021bevdet} for (\textit{Bic}, \textit{Ped}) categories on nuScenes.
In conjunction with the default in NMS, we introduce our novel  metric to enhance similarity assessment for (\textit{Bic}, \textit{Ped}, \textit{Bus}, \textit{Tru}) categories on nuScenes. Motion models and filters are consistent with those described in~\cite{li2023poly}. A lightweight filter, implemented as a median filter with , is applied across all datasets. Association metrics universally employ  across all datasets.
Category-specific first association thresholds  for nuScenes are as follows: (\textit{Bic, Moto, Bus}: 1.6; \textit{Car, Tru}: 1.2; \textit{Tra}: 1.16; \textit{Ped}: 1.78). The voxel mask size  is set to 5\textit{m} on nuScenes. Count-based and output file strategies align with those presented in~\cite{li2023poly}.
In the confidence-based component, category-specific decay rates for nuScenes are: (\textit{Ped}: 0.18; \textit{Car}: 0.26; \textit{Tru, Moto}: 0.28; \textit{Tra}: 0.22; \textit{Bic, Bus}: 0.24). The delete thresholds  are set as follows: (\textit{Bus}: 0.08, \textit{Ped}: 0.1, and 0.04 for all other categories) on nuScenes.

In the object tracking phase of 3D MOT, Easy-Poly exhibits exceptional performance following a series of optimizations. These enhancements include pre-processing, Kalman filtering, motion modeling, and tracking cycle refinements. The integration of these techniques significantly improves the algorithm's effectiveness in complex 3D environments.

Easy-Poly exhibits exceptional performance on the test set, achieving a \textbf{75.9\%} AMOTA score, surpassing the majority of existing 3D MOT methods. As shown in Table \ref{table:nu_test}, Easy-Poly attains a remarkably low IDS count of \textbf{287} while maintaining the highest AMOTA (\textbf{75.9\%}) among all modal methods. This underscores Easy-Poly's ability to maintain stable tracking without compromising recall. Notably, Easy-Poly achieves state-of-the-art performance without relying on additional image data input. Easy-Poly significantly outperforms competing algorithms in the critical 'Car' category. With minimal computational overhead, it delivers impressive results, highlighting its potential for integration into real-world autonomous driving systems. The False Negative and False Positive metrics in Table \ref{table:nu_test} further demonstrate Easy-Poly's robust continuous tracking capability while maintaining high recall.

For validation set experiments in Table \ref{table:nu_val}, we utilize CenterPoint~\cite{yin2021center} as the detector to ensure fair comparisons. As illustrated in Table \ref{table:nu_val}, Easy-Poly significantly outperforms most deep learning-based methods in both tracking accuracy (\textbf{75.0\%} AMOTA, \textbf{64.8\%} MOTA) and computational efficiency (\textbf{34.9} FPS). Compared to the baseline FastPoly~\cite{li2024fast}, Easy-Poly achieves substantial improvements of \textbf{+1.3\%} in MOTA and \textbf{+1.6\%} in AMOTA, while operating \textbf{1.5x} faster under identical conditions. When integrated with the high-performance LargeKernel3D~\cite{chen2022scaling} detector, Easy-Poly demonstrates even more impressive detection and tracking capabilities. Furthermore, when employing the multi-camera detector \textcolor{black}{DETR3D}~\cite{DETR3D} with constrained performance, Easy-Poly exhibits robust real-time performance without compromising accuracy. Furthermore, the lower AMOTP and IDS metrics demonstrate Easy-Poly's exceptional capability in tracking small objects and maintaining performance in complex scenarios and adverse weather conditions. These results underscore the algorithm's robustness across diverse and challenging environments.
% It is noteworthy that achieving optimal AMOTA necessitates a stringent score filter threshold, which marginally reduces the latency advantage of our method. Nevertheless, Easy-Poly maintains a favorable balance between accuracy and computational efficiency.

\begin{table}
% \vspace{0.5em}
        \caption{Comparing different data association algorithms using CenterPoint and (lines 1-7) and LargeKernel3D (lines 8-11) methods on nuScenes val set. Among them, the algorithms lines 1-3 are the Fast-Poly framework and in lines 4-11 are the latest our Easy-Poly framework.}

        \label{table:nus_assoc}
        % \renewcommand{\arraystretch}{0.7}
        \setlength{\tabcolsep}{0.1mm}
        \begin{tabular}{cccccc}
        \toprule
        \multicolumn{1}{c}{\textbf{Algorithms}} & \textbf{MOTA}$\uparrow$ & \textbf{AMOTA}$\uparrow$ & \textbf{AMOTP}$\downarrow$ & \textbf{IDS}$\downarrow$ & \textbf{FN}$\downarrow$\\ 
        
        \midrule
         %  Mutual Nearest Neighbor (MNN)
         MNN  & 62.2  & 72.5 & 52.4  & 433 & 16644  \\  
         Greedy    & 62.3  & 72.7 &  53.4  & 428  & 17647 \\
         Hungarian & \textbf{\textcolor{blue}{63.2}}  & \textbf{\textcolor{blue}{73.7}} & \textbf{\textcolor{blue}{52.1}} & \textbf{\textcolor{blue}{414}}  & \textbf{\textcolor{blue}{15996}}  \\
        
        \midrule  
        % 多模态+数据增强
         %  Mutual Nearest Neighbor (MNN)
        \textbf{MNN (Ours)}  & 63.7  & 73.6 & 54.8  & 406 &  \textbf{\textcolor{red}{15873 }}\\  
        \textbf{Greedy (Ours)}    &  64.0  & 73.7  &  54.6  & 368  & 16736 \\
        \textbf{Hungarian (Ours)}  & 64.3  & 74.3 & \textbf{\textcolor{red}{54.3}} &  335 & 16892  \\

        \textbf{DTO (Ours)}   & \textbf{\textcolor{red}{64.4}}  &   \textbf{\textcolor{red}{74.5}} & 54.9 &  \textbf{\textcolor{red}{272}} & 16982  \\

        
         \midrule
         \textbf{MNN (Ours)}  & 64.1  & 73.9 & 54.0  & 370 & 15865  \\  
         \textbf{Greedy (Ours)}    & 64.5  & 74.3 & 53.7  & 307  & 16014 \\
        \textbf{Hungarian (Ours)}  & 64.7  & 74.8 & 53.9  & 291  & 15923 \\

        \textbf{DTO (Ours)}  & \textbf{\textcolor{red}{64.8}}  & \textbf{\textcolor{red}{75.0}} & \textbf{\textcolor{red}{53.6}}  & \textbf{\textcolor{red}{242}}  & \textbf{\textcolor{red}{15488}} \\

    \bottomrule
\end{tabular}
\end{table}



% \begin{table}
% \caption{The ablation study of whether or not to use Score Filter and Non-Maximum Suppression, including the Run-Time, which represents the execution time of the Pre-processing Module. We compared Poly-MOT~\cite{li2023poly} (rows 1-3) with our proposed Easy-Poly method (rows 4-6).}
% \label{table:nu_NMSsf}
% % \renewcommand{\arraystretch}{0.7}
% \setlength{\tabcolsep}{2.7mm}
% {
% \begin{tabular}{cccc}
% \toprule

% \textbf{Variable} & \textbf{AMOTA$\uparrow$} & \textbf{IDS$\downarrow$} &
% \textbf{Run-Time (s) $\downarrow$}
% \\ 
% \midrule
% NMS + SF & \textbf{\textcolor{blue}{73.1}}   & \textbf{\textcolor{blue}{281}}  & 0.055    \\
% NMS     & 71.8  & 320  & 0.093     \\
% SF       & 68.6  & 354  & \textbf{\textcolor{blue}{0.008}}     \\ 
% \midrule
% \textbf{NMS + SF (Ours)} & \textbf{\textcolor{red}{75.0}}   & \textbf{\textcolor{red}{242}}  & 0.037    \\
% \textbf{NMS (Ours)}      & 73.6   & 273  & 0.068    \\
% \textbf{SF (Ours)}       & 71.2   & 308  & \textbf{\textcolor{red}{0.008}}     \\\hline
% % \vspace{-3.2em}
% \end{tabular}}
% \end{table}



\subsection{Comparative Evaluations} 
\label{sec: Comparative}

% Our proposed method, Easy-Poly, achieves state-of-the-art performance on the nuScenes validation set, demonstrating \textbf{75.0\%} AMOTA at \textbf{34.9} FPS, surpassing existing approaches. Utilizing an identical detector, Easy-Poly outperforms Fast-Poly \cite{li2024fast} across nearly all key metrics, with notable improvements in accuracy (\textbf{+1.3\%} AMOTA, \textbf{+1.6\%} MOTA) and speed (\textbf{+6.0 FPS}). While marginally slower than CBMOT \cite{benbarka2021score} and 3DMOTFormer \cite{ding20233dmotformer}, Easy-Poly significantly exceeds their accuracy while maintaining robust real-time performance. Our open-source implementation establishes a strong baseline for 3D MOT, providing a solid foundation for future advancements in the field.

In this study, we conduct a comprehensive evaluation of the association stage, focusing on four algorithms: Hungarian, Greedy, MNN, and the novel DTO. Our extensive experiments, summarized in Table~\ref{table:nus_assoc}, reveal that the Easy-Poly consistently outperforms Fast-Poly across both CenterPoint and LargeKernel3D frameworks. Notably, LargeKernel3D demonstrates superior performance over CenterPoint, particularly in complex tracking scenarios. Among the association algorithms, Hungarian and DTO consistently yield superior results, underscoring their robustness and efficacy in diverse multi-object tracking contexts. Compared to the Hungarian algorithm, DTO not only achieves similarly excellent AMOTA values but also provides more robust and accurate tracking performance, especially in challenging scenarios involving occlusions, missed detections, or false positives. These findings highlight the critical role of algorithm selection and model optimization in advancing the state-of-the-art in 3D object tracking.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{Images/Ablation_study_line_chart_for_NMS.pdf}
    \vspace{-8pt}
    \caption
    {
      The ablation study of whether or not to use Score Filter and Non-Maximum Suppression, including the Run-Time, which represents the execution time of the Pre-processing Module. We compared Poly-MOT with our proposed Easy-Poly method.
     }
     \Description{}
    \label{fig: NMSFS}
\end{figure*}


\textcolor{black}{Table \ref{table:nu_life} demonstrates the efficacy of our proposed methods. The Fast-Poly tracklet termination strategy (line 3) significantly outperforms baseline score refinement~\cite{benbarka2021score} (line 2), yielding a \textbf{2.7\%} improvement in AMOTA and reducing FN by \textbf{2366}. This enhancement mitigates tracker vulnerabilities in mismatch scenarios, including occlusions. Further performance gains are achieved through smoother score prediction (line 4), resulting in additional improvements of \textbf{0.4\%} AMOTA, \textbf{0.1\%} MOTA, and a reduction of \textbf{926 FN}.}
Our Easy-Poly model exhibits even more substantial performance enhancements. The tracklet termination strategy (line 7) surpasses the baseline score refinement (line 6) by \textbf{2.8\%} in AMOTA while decreasing FN by \textbf{1844}. Furthermore, the integration of smoother score prediction (line 8) further boosts the tracking performance, resulting in improvements of \textbf{0.4\%} in AMOTA and \textbf{0.6\%} in MOTA, along with a reduction of \textbf{575} FN.


\begin{table}
% \vspace{0.5em}
        \caption{A comparison on distinct life-cycle modules on nuScenes val set.
        \textbf{Average} means using the online average score to delete.
        \textbf{Latest} means using the latest score to delete.
        \textbf{Max-age} means using the continuous mismatch time to delete.
        Other settings are under the best performance. Methods in lines 1-4 and lines 5-8 use Fast-Poly~\cite{li2024fast} and Our Easy-Poly.
        }
        \label{table:nu_life}
        % \renewcommand{\arraystretch}{0.7}
        \setlength{\tabcolsep}{0.1mm}
        \begin{tabular}{ccccc}
        \toprule
        \multicolumn{1}{c}{\textbf{Strategy}} & \textbf{AMOTA}$\uparrow$ & \textbf{MOTA}$\uparrow$ & \textbf{FPS}$\uparrow$ & \textbf{FN}$\downarrow$\\ \midrule
 
         Count                \& Max-age            & 73.3      & 62.9     & 23.0  & 16523    \\
         %predict:normal update:normal+delete = -100
         Confidence~\cite{benbarka2021score} \& Latest       & 70.6      & 63.2     & \textbf{\textcolor{blue}{45.8}}  & 19192   \\%predict:minus update:multi+latest
         Confidence~\cite{benbarka2021score} \& Average      & 73.3      & 63.1     & 28.3 & 16826   \\%predict:minus update:multi+average
         Confidence  \& Average      & \textbf{\textcolor{blue}{73.7}}      & \textbf{\textcolor{blue}{63.2}}     & 28.9  & \textbf{\textcolor{blue}{15900}}   \\%predict:normal update:multi+average 27.7or28.9
         \midrule
         \textbf{Count \& Max-age (Ours)}          & 74.3      & 63.8     & 34.3  & 16024    \\
         %predict:normal update:normal+delete = -100
         \textbf{Confidence~\cite{benbarka2021score} \& Latest (Ours)}        & 71.8      & 63.7     & \textbf{\textcolor{red}{50.2}}  & 17907   \\%predict:minus update:multi+latest
         \textbf{Confidence~\cite{benbarka2021score} \& Average (Ours)}       & 74.6      & 64.2     & 35.6 & 16063   \\%predict:minus update:multi+average
         \textbf{Confidence \& Average (Ours)}      & \textbf{\textcolor{red}{75.0}}      & \textbf{\textcolor{red}{64.8}}     & 36.9  & \textbf{\textcolor{red}{15488}}   \\%predict:normal update:multi+average 36.9
        \bottomrule
        \end{tabular}
    \end{table}


\subsection{Ablation Studies}

% The Sf can filter out low-score bounding boxes while NMS can remove duplicate bounding boxes with high confidence, which makes the remaining bounding boxes have superior quality. For the Poly-MOT, using SF before NMS brings inference 40\% reduction in pre-processing inference time while boosting AMOTA by 1.3\% compared with only using NMS. The Fast-Poly has better performance, using SF before NMS brings inference 50\% reduction in pre-processing inference time while boosting AMOTA by 1.4\% compared with only using NMS, as demonstrate in Table~\ref{table:nu_NMSsf}.  It is clear from the table that when only SF is used without NMS, although the running time is fast, both AMOTA and IDS values become lower and the values drop very significantly.

We optimize two-stage filtering approach that synergistically combines SF and NMS to significantly enhance bounding box quality in multi-object tracking scenarios. This novel method effectively integrates SF to eliminate low-score detections and NMS to remove high-confidence duplicates, resulting in a set of superior quality bounding boxes. Our comprehensive experimental results, presented in Figure~\ref{fig: NMSFS}, demonstrate substantial improvements in both computational efficiency and tracking accuracy across multiple state-of-the-art models. For the Poly-MOT model, our approach of applying SF before NMS yields a remarkable \textbf{40\%} reduction in pre-processing inference time while simultaneously improving AMOTA by \textbf{1.3\%} compared to using NMS alone. These results highlight the significant potential of our method in improving real-time tracking capabilities without compromising accuracy. The Easy-Poly model exhibits even more impressive performance gains, further validating the scalability and effectiveness of our approach. By applying SF before NMS, we achieve a substantial \textbf{50\%} reduction in pre-processing time coupled with a \textbf{1.4\%} improvement in AMOTA. This notable improve in both speed and accuracy underscores the robustness of our method across different model architectures. Importantly, our analysis reveals critical insight into the interplay between SF and NMS. Although using SF without NMS accelerates processing, it leads to significant degradation in both AMOTA and Identity Switches IDS metrics. This observation underscores the crucial importance of our combined SF-NMS approach in maintaining an optimal balance between processing speed and tracking accuracy. The synergistic effect of SF and NMS not only enhances the quality of bounding boxes but also optimizes the trade-off between computational efficiency and tracking performance. This balance is particularly vital in real-world applications where both speed and accuracy are paramount, such as autonomous driving and surveillance systems. 
% The consistent improvements observed across different models suggest broad applicability and potential for integration into various tracking frameworks, paving the way for more efficient and accurate tracking systems in complex, real-world environments.


% \subsection{Visualization}
