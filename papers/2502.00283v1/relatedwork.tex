\section{Literature review}
\subsection{Conceptual design}

According to previous research, product design process can be divided into four phases: analysis of problem, conceptual design, embodiment of scheme, and detailing \citep{french1985conceptual}. Among these, conceptual design, which encompasses preliminary decision-making and design concepts generation, is regarded as the key part of the design process \citep{eppinger1995product}. A few conceptual design models have been proposed to explain the stages in conceptual design. For example, \cite{goodman2016designing} outlined that conceptual design process encompasses four stages: manage (deciding what actions to take next), explore (identifying needs), create (generating ideas), and evaluate (judging and testing the design concepts). \cite{Jasmine2020} delineated the design process into several distinct phases: establishing design requirements, assessing technology availability, sketching concepts and layouts, performing analysis and making trade-offs, optimizing revisions, and developing a preliminary design. Some researchers also promoted to apply the conventional design process model to conceptual design, such as the double diamond design process \citep{DesignCouncil2019}, which includes discover, define, develop, and deliver. Building on previous frameworks and considering the integral role of Generative AI, this study defines the conceptual design process as consisting of four stages: problem definition, idea generation, idea selection and evaluation, and idea evolution. This serves as the foundation for our experiment and underpins the research findings and conclusions presented in this study.

Although conceptual design is essential for design processes, it is challenging to obtain creative design ideas of high originality and novelty based on designers' own effort. Many computer-aided conceptual design support methods and tools have been proposed to offer creativity support to designers. For example, knowledge- or heuristics-based stimulation approaches can retrieval and mapping of source knowledge into the target design domain \citep{jiang2022data}. Some studies have attempted to utilize the information in patents, research papers, or encyclopedia data to construct semantic networks \citep{luo2019computer, sarica2020technet}. By computing the semantic distances between design goals and knowledge in database, these methods could offer design stimuli or knowledge to human designers. However, these stimuli-based methods still require designers' cross-domain reasoning to complete the final design concept adapting to the current problem scenario.

\subsection{Generative AI in conceptual design}
Driven by technological advancements in machine learning, such as Generative Adversarial Networks (GANs) \citep{goodfellow2014generative}, Variational Autoencoders (VAEs) \citep{kingma2014auto}, and transformers \citep{vaswani2017attention}, various Generative AI models including GPTs \citep{radford2018improving}, BERT \citep{kenton2019bert}, and StyleGAN \citep{karras2019style} have demonstrated significant potential and powerful performance. Among these, text-to-text and text-to-image models have garnered considerable attention in the field of conceptual design \citep{wu2024integrating}, and have sparked a series of studies on how to smoothly integrate these two types of models into existing workflows \citep{mahdavi2024ai, guo2024exploring}. 

Text-to-text tools, enhanced by Large Language Models (LLMs), such as ChatGPT, Llama, and BERT, can generate natural and fluent answers to comprehend user input and provide contextual solutions in natural language. In the conceptual design domain, Generative AI-based text generation has been applied to requirement extraction \citep{shahin2024harnessing}, creative ideation \citep{suh2024luminate}, solution generation \citep{chen2024triz} and so on. For our experiments, as the experiment was carried out in May 2023 to June 2023, we specifically chose GPT-3.5 due to its robust capabilities in generating coherent and contextually relevant text outputs, which has been widely applied in Generative AI-assisted design research \citep{chen2024designfusion, chen2024llm, chen2024beyond}. 

Some text-to-image models have also been used to aid designers in early concept development by providing visual references and multimodal stimuli \citep{kwon2023understanding}. These models, such as Midjourney, DALL-E, and Stable Diffusion, promote rapid exploration and iteration through visualization, enabling designers to better express their design concepts. Among these, Midjourney stands out both commercially and in terms of model performance, which has been widely adopted in human-AI collaboration research \citep{tan2024using, wadinambiarachchi2024effects, mahdavi2024ai} due to its impressive image generation quality and user-friendly features.

Although various work has been done to develop Generative AI-based design tools and methodologies, there is still a lack of empirical evidence for the effects of Generative AI in conceptual design processes. Thus, in this study, we adapt experimental methods from traditional design research to explore the influence of two representative Generative AI models (i.e. text-to-text and text-to-image models) on different conceptual design stages, contributing new empirical evidence to the design community. 

During the human-AI collaboration, Generative AI can assist human designers by generating concepts for selection, evaluation, and iteration. Additionally, the output from Generative AI can inspire designers to develop more innovative ideas as the information can often expand designersâ€™ knowledge and exploration scope. These capabilities create unprecedented opportunities, particularly for novice designers, by significantly lowering the barriers to cross-disciplinary design and rapid visualization. Therefore, this study focuses on novice designers as research subjects to ensure more targeted research conclusions.