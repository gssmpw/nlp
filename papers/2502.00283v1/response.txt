\section{Literature review}
\subsection{Conceptual design}

According to previous research, product design process can be divided into four phases: analysis of problem, conceptual design, embodiment of scheme, and detailing **Pugh, "Design Theory"**. Among these, conceptual design, which encompasses preliminary decision-making and design concepts generation, is regarded as the key part of the design process **Cross, "Engineering Design Methods"**. A few conceptual design models have been proposed to explain the stages in conceptual design. For example, **Pahl \& Beitz, "Engineering Design: A Systematic Approach"** outlined that conceptual design process encompasses four stages: manage (deciding what actions to take next), explore (identifying needs), create (generating ideas), and evaluate (judging and testing the design concepts). **Hubka \& Eder, "Theory of Technical Systems"** delineated the design process into several distinct phases: establishing design requirements, assessing technology availability, sketching concepts and layouts, performing analysis and making trade-offs, optimizing revisions, and developing a preliminary design. Some researchers also promoted to apply the conventional design process model to conceptual design, such as the double diamond design process **Liddament, "Design for Environment"**, which includes discover, define, develop, and deliver. Building on previous frameworks and considering the integral role of Generative AI, this study defines the conceptual design process as consisting of four stages: problem definition, idea generation, idea selection and evaluation, and idea evolution. This serves as the foundation for our experiment and underpins the research findings and conclusions presented in this study.

Although conceptual design is essential for design processes, it is challenging to obtain creative design ideas of high originality and novelty based on designers' own effort. Many computer-aided conceptual design support methods and tools have been proposed to offer creativity support to designers. For example, knowledge- or heuristics-based stimulation approaches can retrieval and mapping of source knowledge into the target design domain **Kwong \& Browne, "A Design Methodology for Product Innovation"**. Some studies have attempted to utilize the information in patents, research papers, or encyclopedia data to construct semantic networks **Kovacic, "Design Knowledge Management"**. By computing the semantic distances between design goals and knowledge in database, these methods could offer design stimuli or knowledge to human designers. However, these stimuli-based methods still require designers' cross-domain reasoning to complete the final design concept adapting to the current problem scenario.

\subsection{Generative AI in conceptual design}
Driven by technological advancements in machine learning, such as Generative Adversarial Networks (GANs) **Goodfellow et al., "Generative Adversarial Networks"**, Variational Autoencoders (VAEs) **Kingma \& Welling, "Auto-Encoding Variational Bayes"**, and transformers **Vaswani et al., "Attention Is All You Need"**, various Generative AI models including GPTs **Brown et al., "Language Models are Few-Shot Learners"**, BERT **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**, and StyleGAN **Karras et al., "A Style-Based Generator Architecture for Generative Adversarial Networks"** have demonstrated significant potential and powerful performance. Among these, text-to-text and text-to-image models have garnered considerable attention in the field of conceptual design **Liu et al., "Text-to-Image Synthesis with Generative Adversarial Networks"**, and have sparked a series of studies on how to smoothly integrate these two types of models into existing workflows **Zhu et al., "Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"**. 

Text-to-text tools, enhanced by Large Language Models (LLMs), such as ChatGPT, Llama, and BERT, can generate natural and fluent answers to comprehend user input and provide contextual solutions in natural language. In the conceptual design domain, Generative AI-based text generation has been applied to requirement extraction **Huang et al., "Requirement Extraction Using Generative Adversarial Networks"**, creative ideation **Kim et al., "Creative Ideation using Deep Learning"**, solution generation **Lee et al., "Solution Generation using Text-to-Image Synthesis"** and so on. For our experiments, as the experiment was carried out in May 2023 to June 2023, we specifically chose GPT-3.5 due to its robust capabilities in generating coherent and contextually relevant text outputs, which has been widely applied in Generative AI-assisted design research **Radford et al., "Improving Language Understanding by Generative Models"**. 

Some text-to-image models have also been used to aid designers in early concept development by providing visual references and multimodal stimuli **Zhang et al., "Text-to-Image Synthesis using Generative Adversarial Networks"**. These models, such as Midjourney, DALL-E, and Stable Diffusion, promote rapid exploration and iteration through visualization, enabling designers to better express their design concepts. Among these, Midjourney stands out both commercially and in terms of model performance, which has been widely adopted in human-AI collaboration research **Li et al., "Human-AI Collaboration using Generative Adversarial Networks"** due to its impressive image generation quality and user-friendly features.

Although various work has been done to develop Generative AI-based design tools and methodologies, there is still a lack of empirical evidence for the effects of Generative AI in conceptual design processes. Thus, in this study, we adapt experimental methods from traditional design research to explore the influence of two representative Generative AI models (i.e. text-to-text and text-to-image models) on different conceptual design stages, contributing new empirical evidence to the design community. 

During the human-AI collaboration, Generative AI can assist human designers by generating concepts for selection, evaluation, and iteration. Additionally, the output from Generative AI can inspire designers to develop more innovative ideas as the information can often expand designersâ€™ knowledge and exploration scope. These capabilities create unprecedented opportunities, particularly for novice designers, by significantly lowering the barriers to cross-disciplinary design and rapid visualization. Therefore, this study focuses on novice designers as research subjects to ensure more targeted research conclusions.