%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper
% 
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{caption}

\title{\LARGE \bf
Individualised Treatment Effects Estimation with Composite Treatments and Composite Outcomes
}


\author{Vinod Kumar {Chauhan}$^{1,*}$, Lei Clifton$^{1,2}$, Gaurav Nigam$^{1,3}$ and David A. Clifton$^{1,4,\#}$% <-this % stops a space
\thanks{$^{1}$Institute of Biomedical Engineering,
	University of Oxford UK
        % {\tt\small vinod.kumar@eng.ox.ac.uk}
        }%
\thanks{$^{2}$Nuffield Department of Primary Care Health Sciences, University of Oxford UK
        % {\tt\small b.d.researcher@ieee.org}
        }%
\thanks{$^3$Nuffield Department of Medicine, University of Oxford, Oxford, UK}
\thanks{$^{4}$Oxford-Suzhou Institute of Advanced Research (OSCAR), Suzhou, China
        % {\tt\small b.d.researcher@ieee.org}
        }%
\thanks{$^{*}$Corresponding author: V.K. Chauhan (\href{mailto:vinod.kumar@eng.ox.ac.uk}{vinod.kumar@eng.ox.ac.uk}).}
\thanks{$^{\#}$This work was supported in part by the National Institute for Health Research (NIHR) Oxford Biomedical Research Centre (BRC) and in part by InnoHK Project Programme 3.2: Human Intelligence and AI Integration (HIAI) for the Prediction and Intervention of CVDs: Warning System at Hong Kong Centre for Cerebro-cardiovascular Health Engineering (COCHE).
DAC was supported by an NIHR Research Professorship, an RAEng Research Chair, the InnoHK Hong Kong Centre for Cerebro-cardiovascular Health Engineering (COCHE), the NIHR Oxford Biomedical Research Centre (BRC), and the Pandemic Sciences Institute at the University of Oxford. GN is funded by NIHR (Grant number 302607) for a doctoral research fellowship. The views expressed are those of the authors and not necessarily those of the NHS, the NIHR, the Department of Health, the InnoHK â€“ ITC, or the University of Oxford.}% <-this % stops a space
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
    % Real-world scenarios often involve multiple interventions and multiple outcomes, making it essential to understand how they collectively affect individuals.
    Estimating individualised treatment effect (ITE) -- that is the causal effect of a set of variables (also called exposures, treatments, actions, policies, or interventions), referred to as \textit{composite treatments}, on a set of outcome variables of interest, referred to as \textit{composite outcomes}, for a unit from observational data -- remains a fundamental problem in causal inference with applications across disciplines, such as healthcare, economics, education, social science, marketing, and computer science. Previous work in causal machine learning for ITE estimation is limited to simple settings, like single treatments and single outcomes. This hinders their use in complex real-world scenarios; for example, consider studying the effect of different ICU interventions, such as beta-blockers and statins for a patient admitted for heart surgery, on different outcomes of interest such as atrial fibrillation and in-hospital mortality. The limited research into composite treatments and outcomes is primarily due to data scarcity for all treatments and outcomes.
    To address the above challenges, we propose a novel and innovative hypernetwork-based approach, called \emph{H-Learner}, to solve ITE estimation under composite treatments and composite outcomes, which tackles the data scarcity issue by dynamically sharing information across treatments and outcomes. Our empirical analysis with binary and arbitrary composite treatments and outcomes demonstrates the effectiveness of the proposed approach compared to existing methods.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec_intro}
Causal inference helps to answer fundamental ``what if'' questions regarding the effect of a set of variables on a set of outcome variables of interest. For instance, one might be interested in estimating the risk of cancer for an individual if they were to quit smoking. Such questions are prevalent in science, including healthcare, economics, education, social science, marketing, and computer science. While randomised controlled trials remain the gold standard for causal effect estimation, they can be time-consuming, expensive, ethically challenging, and more importantly not suitable for individual-level causal effect estimation due to their strict inclusion criteria and small and less representative samples. By contrast, non-experimental approaches based on observational datasets (e.g., electronic health records) address many of these limitations and can complement randomised controlled trials. Recently, there has been notable progress in causal machine learning \cite{bica2021real,chauhan2024dynamic}, a discipline that integrates rigorous causal inference methodologies with state-of-the-art machine learning techniques, particularly for the analysis of observational data.

Existing research in individualised treatment effects (ITE), also referred to as conditional average treatment effects estimation or heterogeneous treatment effects estimation in the machine learning literature \cite{shalit2017estimating}, is mostly focused on simple settings considering single treatments, such as binary treatments, and single outcomes \cite{curth2021inductive,chauhan2023adversarial,hernan2023causal,chauhan2023dynamic,melnychuk2025orthogonal}. However, the real world is complex and might involve \emph{composite treatments}, i.e., multiple simultaneous treatments (often referred to as polypharmacy in clinical literature \cite{hajjar2007polypharmacy}), as well as \emph{composite outcomes}, where we aim to optimise multiple simultaneous outcomes of interest. Thus, existing methods are not always suitable for practical adoption in these multi-faceted scenarios.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{composite.pdf}
    \caption{Example: An intensive care unit patient, admitted for heart surgery, needs composite treatments to optimise composite outcomes.}
    \label{fig_problem}
\end{figure}
\textbf{Motivating example}: Suppose a patient is admitted to a hospital for heart surgery. Approximately 20--50\% of such patients are at risk of atrial fibrillation within the first seven days after surgery \cite{d2018society}, which is associated with an increased risk of heart failure, dementia, and stroke \cite{Munger2014}. During the surgery, clinicians can choose from more than ten interventions (e.g., beta-blockers, statins, and others) to manage multiple outcomes, including atrial fibrillation, mortality, and readmission to the intensive care unit, as depicted in Fig.~\ref{fig_problem}. Evaluating the combined effects of these interventions on the outcomes of interest is a complex open problem that urgently requires solutions with potentially significant impact on healthcare.

% lack of holistic view and its consequences (proof if possible), 
% We argue that the existing methods are not only limited to simple settings but they lack a discussion on a holistic approach to ITE estimation. While selecting the best treatments for a patient using ITE algorithms, lack of a holistic approach would run the same risks as using purely predictive algorithms in binary treatments. For example, in the above heart surgery example, by studying ITE only for beta-blockers and not considering causal effects for all possible options would be equivalent to using correlational machine learning for selecting those interventions, and thus is not a correct approach to solve the causal problem \cite{Prosperi2020Causal,Geloven2024,Joshi2025AI}.

The primary challenge with composite treatments and outcomes is the scarcity of data for certain treatment combinations. For instance, with $K$ binary treatments, there are $2^K$ possible treatment combinations, and in many real-world settings, it is impractical (or impossible) to obtain sufficient observations for all these combinations. This data deficiency hampers the reliable estimation of ITE for more complex treatment-outcome scenarios. Furthermore, analysing composite treatments and outcomes necessitates addressing confounding bias for each treatment component and outcome individually, compounding the challenge.

To address the above challenges in ITE estimation for complex real-world scenarios, we propose a novel and innovative approach based on a hypernetwork (a neural network that generates weights for another neural network) \cite{chauhan2024brief}, referred to as \emph{H-Learner}, to solve the problem of composite treatments and outcomes. In H-Learner, the hypernetwork is conditioned on the treatments and outcomes to generate a target learner for each specific treatment combination. Because H-Learner maps treatments to the corresponding target learners, it can tackle data scarcity by dynamically sharing information across treatments and outcomes. We provide an empirical study of H-Learner under varying treatments and outcomes, comparing its performance against existing methods.

\textbf{Contributions:} (i) We present an innovative and novel methodology, H-Learner, which leverages hypernetworks for ITE estimation under composite treatments and outcomes by sharing information across different treatment-outcome combinations; (ii) We empirically validate H-Learner against state-of-the-art approaches, showing superior or at par performance in scenarios involving varying treatments and outcomes with minimal assumptions.

% \begin{itemize}
%     % \item Our work is the first to highlight the need for a holistic approach to individualised treatment effects estimation, while considering composite treatments and outcomes, reflecting the need of complex real-world scenarios.
%     % \item To the best of our knowledge, we are the first to solve composite treatments and composite outcomes which present a complex but a practical scenario.
%     \item We present an innovative and novel approach, called HLearner, to solve composite treatments and outcomes, which can handle treatments with scarce data as well as no data. HLearner employs hypernetworks to generate unique target learners for each treatment combination, combining the best of SLearner and TLearner.
%     \item We present empirical analysis with synthetic and semi-synthetic datasets to prove the effectiveness of HLearner.
% \end{itemize}

% The rest of the paper is organised as: Section~\ref{sec_problem_def} provides a problem definition of SSB, while Section~\ref{sec_related_work} presents a brief overview of literature related to SSB. The proposed research direction and T-Net and MT-Net are discussed in Section~\ref{sec_methods}, followed by performance analysis with synthetic and semi-synthetic datasets in Section~\ref{sec_results}. Discussion on the significance of results is presented in Section~\ref{sec_discussion}, and finally, the concluding remarks are given in Section~\ref{sec_conclusion}.


\section{Related Work}
\label{sec_related_work}
In this section, we briefly review the literature on ITE estimation and hypernetworks.

\subsection{Individualised Treatment Effects Estimation}
\label{subsec_ITE}
After the pioneering work of \cite{johansson2016learning}, a wide variety of machine learning-based ITE learners have been proposed \cite{bica2021real}. These methods can be broadly categorised as: (i) representation learning or deep learning-based learners, e.g., \cite{curth2021inductive,shalit2017estimating,hassanpour2019counterfactual,hassanpour2019learning,chauhan2023adversarial,chauhan2024dynamic}, (ii) tree-based learners \cite{athey2019estimating}, and (iii) meta-learners, which are model-agnostic and can be subdivided into direct learners (S-Learner and T-Learner) \cite{kunzel2019metalearners}, and indirect learners (RA-Learner, DR-Learner, and X-Learner) \cite{kennedy2023towards,curth2021nonparametric,kunzel2019metalearners}. For a comprehensive review, please refer to \cite{Curth2024Machine}. While these frameworks have demonstrated success, they predominantly address settings with a single treatment and a single outcome.

The study of composite treatment effects has been constrained by data scarcity arising from the exponential number of treatment combinations (for $K$ binary treatments, $2^K$ combinations) and the possibility that many combinations have insufficient or no data at all. In this context, \cite{wang2019blessings} proposed an S-Learner-based approach, called deconfounder (DEC), that accommodates composite (binary and real) treatments for a single outcome. They leverage proxy variables and latent representations to capture interactions among multiple treatments and mitigate unmeasured confounding. Similarly, \cite{zou2020counterfactual} developed the variational sample re-weighting (VSR) approachâ€”an extension of S-Learnerâ€”to handle high-dimensional binary treatments (referred to as bundle treatments), using learned latent representations to de-correlate treatments from confounders. To address data scarcity, \cite{qian2021estimating} proposed a data-augmentation strategy for composite treatment and single outcome settings, whereby $K$ ITE learners generate balanced datasets for each treatment before training a standard supervised deep learning model to predict potential outcomes. However, this method requires to train multiple models and is also limited to binary composite treatments.

% There have been some on multiple simultaneous treatments, such as bundle treatments that usually abstracted as a high dimensional binary vector \cite{zou2020counterfactual}, 
% - composite treatment, terminology, existing works and limitations, table of comparison

% While our work focuses on static settings, there have been work in dynamic settings, i.e., time-series \cite{}. There are also other settings where treatments are complex, such as \cite{}. Moreover, while it could be easy to estimate composite treatments and outcomes under structural causal models which need causal structure as well as functional relationships among variables, in practice it is difficult to know the exact data-generating process \cite{}. So, our discussion is related to the potential outcomes framework \cite{} which is more appropriate for inferring treatment effects \cite{}.

% \subsection{Composite Treatments}
% \label{subsec_hypernetworks}

\subsection{Hypernetworks}
\label{subsec_hypernetworks}
Hypernetworks, or hypernets, are a class of neural networks that generate the weights of another network, known as the target (or primary) network \cite{chauhan2024brief}. Although the core idea of context-dependent weight generation originated earlier \cite{schmidhuber1992learning}, the term ``hypernetwork'' was popularised by \cite{ha2017hypernetworks}, who introduced an end-to-end training paradigm for both the hypernetwork and the target network. Hypernetworks thus provide an alternative way to train neural networks \cite{chauhan2024brief}, which consist of a primary network for performing predictions and a hypernetwork for generating the primary networkâ€™s weights. Depending on the type of conditioning (data, task identifiers, or noise), hypernetworks are respectively categorised as data-conditioned, task-conditioned, or noise-conditioned hypernetworks. They can be classified using five key design criteria based on input-output variability and architectural choices \cite{chauhan2024brief}.

When a hypernetwork is used to generate weights for multiple target networks (referred to as soft-weight sharing), it enables end-to-end information sharing across those networks. Soft-weight sharing was recently used in \cite{chauhan2024dynamic} to propose HyperITE that addresses the problem of information sharing between potential outcome functions for training ITE learners. Nevertheless, HyperITEs are limited to binary treatments and single outcomes, unlike our approach which can handle an arbitrary number of treatments and outcomes.

Hypernetworks have emerged as a powerful deep learning technique due to their flexibility, expressivity, data-adaptivity, and information sharing, and have been used across various problems in deep learning \cite{chauhan2024brief}. For example, hypernetworks have been successfully applied and have shown better results across different deep learning problems, such as uncertainty quantification \cite{deutsch2019generative,Chan2024}, hyperparameter optimisation \cite{lorraine2018stochastic}, continual learning \cite{Oswald2020Continual}, federated learning \cite{shin2024effective}, multitasking \cite{tay2021hypergrid}, embedding representations \cite{yoo2024hyper}, ensemble learning \cite{kristiadi2019predictive}, multi-objective optimisation \cite{Tuan2024}, weight pruning \cite{liu2019metapruning}, model-extraction attack \cite{yuan2024hypertheft}, unlearning \cite{rangel2024learning}, image processing \cite{Ramanarayanan_2023_ICCV,Zhou2024}, quantum computing \cite{carrasquilla2023quantum}, knowledge distillation \cite{wu2023hyperinr}, neural architecture search \cite{peng2020cream}, adversarial defence \cite{sun2017hypernetworks}, and learning partial differential equations \cite{botteghi2025hyperl}. For an overview of hypernetworks, refer to \cite{chauhan2024brief}.

% To sum up, 


\section{Background}
\label{sec_background}
% This requires considering the complex interplay of multiple possible treatments and outcomes, often referred to as composite treatments and composite outcomes. 
\textbf{Notations:} Let $\mathbf{x}_i = (x_{i1}, \dots, x_{ip})^\top$ denote the $p$-dimensional vector of pre-treatment features for patient $i$ ($i=1, \dots, N$). Let $\mathbf{t}_i = (t_{i1}, \dots, t_{iK})^\top$ be the $K$-dimensional treatment vector for patient $i$, where $t_{ik}$ represents the $k$-th component of the potentially composite treatment. Let $\mathbf{y}_i = (y_{i1}, \dots, y_{iM})^\top$ be the $M$-dimensional outcome vector for patient $i$, where $y_{im}$ is the $m$-th outcome.  $y_{im}(\mathbf{t}_i)$ denotes the potential outcome for patient $i$ on outcome $m$ if they were to receive treatment vector $\mathbf{t}$.  The observed outcome is $y_{im} = y_{im}(\mathbf{t}_i)$. The observational dataset is $\mathcal{D} = \{(\mathbf{x}_i, \mathbf{t}_i, \mathbf{y}_i)\}_{i=1}^N$.

\textbf{Potential Outcomes Framework:} Following the potential outcomes framework \cite{rubin2005causal}, we define $y_{im}(\mathbf{t}_i)$ as the potential outcome for individual $i$ on outcome $m$ if they were to receive treatment vector $\mathbf{t}_i \in \mathcal{T}$.  This represents the counterfactual outcome that would have been observed had individual $i$ received treatment $\mathbf{t}_i$, even if they actually received a different treatment.  We can then represent the vector of potential outcomes under treatment $\mathbf{t_i}$ as $\mathbf{y}_i(\mathbf{t}_i) = (y_1(\mathbf{t}_i), y_2(\mathbf{t}_i), \dots, y_M(\mathbf{t}_i))^\top$.  The fundamental problem of causal inference is that we can only observe one potential outcome vector for each individual, namely $\mathbf{y}_i = \mathbf{y}_i(\mathbf{t}_i)$, where $\mathbf{t}_i$ is the treatment vector actually received by individual $i$.  Specifically, the observed outcome for individual $i$ on outcome $m$ is $y_{im} = y_m(\mathbf{t}_i)$.

\textbf{Assumptions:} To identify and estimate ITEs for composite treatments and composite outcomes, we rely on the standard causal assumptions of (i) unconfoundedness (or conditional exchangeability), (ii) positivity (or overlap) and (iii) consistency for all individual treatments and outcomes.
% (i) \textit{Unconfoundedness (or Conditional Exchangeability):} For all $\mathbf{t}_{ik}$, $k \in \{1, \dots, K\}$ and $m \in \{1, \dots, M\}$, $\{y_{im}(\mathbf{t})\}_{i=1}^N \perp \mathbf{t}_i \mid \mathbf{x}_i$. This assumption states that, given the observed covariates $\mathbf{x}_i$, the potential outcomes under *any* treatment $\mathbf{t}$ are independent of the treatment actually received $\mathbf{t}_i$. In other words, there are no unmeasured confounders affecting both the treatment assignment and the potential outcomes. (ii) \textit{Positivity (or Overlap):} For all $\mathbf{t} \in \mathcal{T}$ and all $\mathbf{x}$ in the support of $\mathbf{x}_i$, $P(\mathbf{t}_i = \mathbf{t} \mid \mathbf{x}_i = \mathbf{x}) > 0.$ This assumption ensures that there is a non-zero probability of receiving any treatment $\mathbf{t}$ for all individuals with covariate values $\mathbf{x}$.  It requires sufficient overlap in the covariate distributions across treatment groups. (iii) \textit{Consistency:} For all $\mathbf{t} \in \mathcal{T}$, if $\mathbf{t}_i = \mathbf{t}$, then for all $m \in \{1, \dots, M\}$, $y_{im}(\mathbf{t}) = y_{im}.$ This assumption states that the potential outcome under the treatment actually received is equal to the observed outcome. It links the potential outcomes to the observed data.

\section{Methods}
\label{sec_methods}
In this section, we introduce \emph{H-Learner}, a hypernetwork-based approach to solve ITE estimation problems with composite treatment and composite outcome.

% Problem Formulation
% Identification??
% for binary setting, S-Learner is not advocated but for complex setting is the only choice.

% H-Learner
\textbf{Motivation:}
Complex real-world scenarios often entail multiple concurrent treatments (polypharmacy) and multiple outcomes of interest. Existing research on ITE estimation, however, typically focuses on single treatment and single outcome problems. In the composite treatment and composite outcome setting, the exponential number of possible treatment combinations (e.g., $2^K$ for $K$ binary treatments) leads to data scarcity, where certain treatment combinations may have limited or no samples. Such data sparsity poses a significant challenge to reliably estimating ITE.

Broadly, there are two ways to address composite treatment and composite outcome problems:  
\emph{(i) Train independent models for each treatment combination,} akin to a T-Learner \cite{kunzel2019metalearners}. While flexible, this approach can be infeasible when data are scarce for many treatment combinations.  
\emph{(ii) Train a single joint model for all treatment combinations and outcomes,} such as an S-Learner \cite{kunzel2019metalearners}. This approach can alleviate data scarcity through shared learning but may lack the flexibility needed even for simpler (binary) scenarios.  

To overcome these limitations, we utilise hypernetworks for joint training of ITE learners. Our proposed \emph{H-Learner} effectively combines the advantages of both independent and joint training: it dynamically shares information across treatments and outcomes yet learns distinct learners for each treatment-outcome combination, mitigating data scarcity.

% This also enables ITE estimation for treatments lacking any data, i.e., zero-shot learning of treatment effects \cite{nilforoshan2023zero}, as discussed below.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\linewidth]{HLearner}
    \caption{Architecture of H-Learner. It comprises two networks: (1) a hypernetwork conditioned on treatments and outcomes, and (2) a target network (ITE learner). The hypernetwork generates the target networkâ€™s weights for each treatment-outcome combination, enabling dynamic information sharing.}
    \label{fig_HLearner}
\end{figure}

\begin{figure*}[htb!]
    \begin{subfigure}{0.32\textwidth} % Adjust width as needed
        \centering
        \includegraphics[width=\textwidth]{MCMO-NC} % Or .png, .jpg, etc.
        % \caption{Description of Figure 1}
        % \label{fig:sub1}
    \end{subfigure}
    \hfill % Important for spacing between subfigures
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{MCMO-TC}
        % \caption{Description of Figure 2}
        % \label{fig:sub2}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{MCMO-YC}
        % \caption{Description of Figure 3}
        % \label{fig:sub3}
    \end{subfigure}
    \caption{Comparative study of ITE learners for arbitrary composite treatments and composite outcomes (shaded region represents one standard error over 10 repetitions).}
    \label{fig_results_continuous}
\end{figure*}

\begin{figure*}[htb!]
    \begin{subfigure}{0.32\textwidth} % Adjust width as needed
        \centering
        \includegraphics[width=\textwidth]{MCMO-NB} % Or .png, .jpg, etc.
        % \caption{Description of Figure 1}
        % \label{fig:sub1}
    \end{subfigure}
    \hfill % Important for spacing between subfigures
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{MCMO-TB}
        % \caption{Description of Figure 2}
        % \label{fig:sub2}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{MCMO-YB}
        % \caption{Description of Figure 3}
        % \label{fig:sub3}
    \end{subfigure}
    \caption{Comparative study of ITE learners for binary composite treatments and composite outcomes (shaded region represents one standard error over 10 repetitions). H-Learner does not need any assumptions about the interaction among the treatments and can handle composite outcomes but SCP needs to know the causal structure among treatments and is limited to single outcomes.}
    \label{fig_results_binary}
\end{figure*}

\textbf{Neural Architecture and Working:} 
Figure~\ref{fig_HLearner} illustrates the key components of H-Learner, which include an embedding layer, a hypernetwork, and a target network (the ITE learner). The embedding layer learns representations for each of the unique combinations of treatments and outcomes and has been implemented using a single linear layer. The embedding layer maps given causes and an effect to a meaningful representation which is equivalent to learning embeddings for words in natural language processing \cite{wang2020survey}.

The hypernetwork is a multi-layer perceptron that takes the treatment-outcome embeddings as input (i.e., \emph{task-conditioned} inputs \cite{chauhan2024brief}) and outputs the weights of the target network. The target network, in turn, receives the covariate data and predicts the potential outcomes for the specified treatment-outcome combination. Unlike conventional learners where the target networkâ€™s weights are trained directly, here they are entirely generated by the hypernetwork and thus are not themselves learned via backpropagation.

Training proceeds by feeding the treatments and outcomes into the embedding layer, whose outputs are passed to the hypernetwork. The hypernetwork produces weights for the target network, which processes the observed covariates to predict potential outcomes. We compute the prediction loss on factual observations (the data points for which the treatments and outcomes are known) and backpropagate the error. Since only the embedding layer and the hypernetwork parameters are trainable, the backpropagated gradients update those components to learn better embeddings for treatments and outcomes and improve the hypernetworkâ€™s mapping from embeddings to target-network weights. Each training epoch thus leads to dynamic information sharing across the various treatments and outcomes, benefiting low-data configurations through mechanisms similar to transfer learning and multitasking \cite{maurer2016benefit,chauhan2023hcr}.

% Since hypernetwork learns to map treatments and an outcome to weights for a learner network to predict potential outcomes corresponding to the combination of that treatments and an outcome, similar to a standard neural network trained on given which can work with new inputs, the hypernetwork can map treatments unseen during the training to generate learner networks for those treatments. Thus, helping to estimate treatment effects for new treatments, also called as zero-shot learning \cite{nilforoshan2023zero}.

Formally, we define the optimisation objective for H-Learner as:
\begin{equation}
    \label{eq_hlearner}
    \min_{\phi, \psi} f(\mathbf{x}; \theta_{\mathbf{t},\mathbf{y}} = h(e_{\mathbf{t},\mathbf{y}}=e(\mathbf{t},\mathbf{y};\psi); \phi)), \quad \forall \{\mathbf{x}, \mathbf{t},\mathbf{y}\} \in \mathcal{D},
\end{equation}
where $\phi$ and $\psi$ are the trainable parameters of the hypernetwork and the embedding layer, respectively, $e(\cdot,\cdot;\psi)$ denotes the embedding function, and $h(\cdot;\phi)$ represents the hypernetwork. The weights $\theta_{\mathbf{t},\mathbf{y}}$ for each treatment-outcome pair $(\mathbf{t},\mathbf{y})$ are generated by the hypernetwork, rather than learned directly. Consequently, H-Learner is a meta-model approach that naturally accommodates composite treatments and outcomes through dynamic weight-sharing across the treatment-outcome space.

\section{Experiments}
\label{sec_experiments}
Here, we present our experimental setup and the corresponding results.

\subsection{Experimental Setup}
\label{subsec_experimental_setup}
\textbf{Baselines:} 
For composite treatments comprising binary treatments only, we compare against DEC, SCP, S-Learner, and VSR. For composite treatments that may be binary, continuous, or categorical, we use S-Learner and xS-Learner, due to the lack of methods which could handle arbitrary treatments. With respect to composite outcomes, we apply these baselines independently for each outcome because none of them are explicitly designed to handle multiple outcomes simultaneously. Specifically, we use a multitasking version of S-Learner (still referred to as S-Learner) and repeat the learner for each outcome referred to as xS-Learner. Unless otherwise specified, our experiments involve five treatments (either all binary or one continuous and four binary) and two outcomes.

\textbf{Metric:} We employ an extension of the Precision in the Estimation of Heterogeneous Effects (PEHE) \cite{hill2011bayesian} suitable for composite treatments and outcomes. Concretely, this extension reduces to computing the mean squared error (MSE) of the estimated treatment effects overall treatment combinations and outcomes.

\textbf{Dataset:} 
Because of the ``fundamental problem of causal inference'' \cite{holland1986statistics}, not all potential outcomes are observable in real-world data, making direct validation of causal methods inherently difficult. As is common in the literature, we use synthetic datasets, where all potential outcomes are artificially generated, to evaluate our proposed methodology. Our data generation process follows \cite{chauhan2023adversarial} and is extended to accommodate multiple treatments and multiple outcomes.

\textbf{Hyperparameters:} 
We implemented SCP, VSR, and DEC using the publicly available code from \cite{qian2021estimating}, adopting their hyperparameter tuning protocols. For H-Learner, we set the learning rate to 0.005, the embedding size to 32, and used a hypernetwork with two hidden layers of 100 neurons each. All other hyperparameters, including the optimiser and batch size, are the same as those used in the baseline implementations.

\subsection{Results}
\label{subsec_results}
In this subsection, we compare H-Learner under two scenarios: (1) arbitrary composite treatments and (2) binary composite treatments.

\textbf{Arbitrary composite treatments:} Since H-Learner shares information across all treatments and outcomes, we compare it against S-Learner \cite{kunzel2019metalearners}, which employs a multitasking neural network, and xS-Learner, which considers only a single outcome at a time and therefore does not share information across outcomes. Figure~\ref{fig_results_continuous} summarises performance as we vary the number of patients, treatments, and outcomes. H-Learner consistently performs better across different data sizes and different numbers of treatments and outcomes. Notably, its advantage over the baselines becomes more pronounced when the dataset size decreases or when the number of outcomes increases. This improvement arises from H-Learnerâ€™s dynamic end-to-end information sharing across treatments and outcomes, facilitated by hypernetworks \cite{chauhan2024brief}.

\textbf{Binary composite treatments:}
Here, we restrict treatments to binary treatments and compare H-Learner against S-Learner, VSR, SCP, and DEC. Figure~\ref{fig_results_binary} shows that H-Learner typically outperforms or is on par with the baselines. Its superior performance in smaller datasets, relative to SCP, can be attributed to the way H-Learner shares information across outcomes, which other methods do not. The same mechanism also enables H-Learner to outperform the baselines when the number of outcomes is increased. Although SCP shows stronger results for certain treatments and is overall the second-best estimator, it relies on knowing the underlying causal structure among treatments -- information we provide in these experiments but which may be unavailable in practice. In contrast, H-Learner can accommodate an arbitrary number of treatments (and their interrelationships) by generating a distinct learner network for each treatment combination.

% \subsection{Ablation}
% \label{subsec_ablation}

\section{Conclusion}
\label{sec_conclusion}
In this paper, we proposed \emph{H-Learner}, a novel hypernetwork-based framework for ITE estimation under composite treatments and composite outcomes -- an important yet underexplored problem in real-world causal inference. By mapping each treatment-outcome combination to a distinct target learner, H-Learner combines the flexibility of independent models with the benefits of a joint learner capable of dynamic end-to-end information sharing. Our empirical results highlight that H-Learner not only manages data scarcity effectively but also consistently outperforms or competes with existing methods when dealing with both arbitrary and binary composite treatments, as well as multiple outcomes. Incorporating hypernetworks enables adaptive weight generation, facilitating transfer learning across complex treatment-outcome configurations and enhancing robustness in scenarios with limited data. We believe H-Learner provides a strong foundation for addressing increasingly intricate real-world causal inference tasks involving multiple treatments and outcomes.

% \section*{Acknowledgements}
% This work was supported in part by the National Institute for Health Research (NIHR) Oxford Biomedical Research Centre (BRC) and in part by InnoHK Project Programme 3.2: Human Intelligence and AI Integration (HIAI) for the Prediction and Intervention of CVDs: Warning System at Hong Kong Centre for Cerebro-cardiovascular Health Engineering (COCHE).
% DAC was supported by an NIHR Research Professorship, an RAEng Research Chair, the InnoHK Hong Kong Centre for Cerebro-cardiovascular Health Engineering (COCHE), the NIHR Oxford Biomedical Research Centre (BRC), and the Pandemic Sciences Institute at the University of Oxford. GN is funded by NIHR (Grant number 302607) for a doctoral research fellowship. 
% The views expressed are those of the authors and not necessarily those of the NHS, the NIHR, the Department of Health, the InnoHK â€“ ITC, or the University of Oxford.

% We also thank the Editor-in-Chief, Associate Editor, and reviewers for their constructive feedback, which significantly enhanced the quality of our submission, and for their expedited review, underscoring the importance of Hypernets in the field.


\section*{Statements and Declarations}
\subsection*{Competing Interests}
The authors declare that they have no competing interests.

\subsection*{Code Availability}
The finalised code, after acceptance, will be available at \url{https://github.com/jmdvinodjmd/HLearner}.

% \subsection*{Data Availability}
% Data sharing not applicable to this article as no datasets were generated or analysed during the current study.

% \subsection*{Contributions}
% V.K.C. conceptualised the study, analysed the literature and wrote the first draft. J.Z., P.L. and S.M. helped to filter out the literature and prepare Table~\ref{tab_hypernets}. D.A.C did supervision and funding acquisition. All authors reviewed and approved the final manuscript.



\bibliographystyle{plain}
\bibliography{ML4HC} 




\end{document}
