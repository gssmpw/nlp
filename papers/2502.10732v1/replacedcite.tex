\section{Related Work}
\label{sec:related}

Our work intersects with three distinct areas within the RL literature. We discuss related work in each of these domains.


\textbf{RL for Resource Allocation}\quad
RL has been widely studied for constrained resource allocation across domains. In maternal health, ____ apply RL to a restless multiarmed bandit (RMAB) problem ____ to compute patient-specific intervention probabilities. Also in an RMAB setting, ____ propose a model-based RL approach that prioritizes users via an index and allocates resources under budget constraints. In public health, ____ propose RL to optimize  extreme heat warnings under a budget on the number of possible alerts. Other works include multi-agent RL for robotic warehouse allocation ____ and exogenous MDPs for cloud resource management ____. While these methods optimize rewards effectively, they often lack interpretability---critical for deployment in sensitive domains requiring trust, transparency, and accountability.


\textbf{RL and Language Agents}\quad 
The language agents ____ paradigm developed somewhat independently of RL, with works like ReAct prompting ____ extending chain-of-thought (CoT) ____ to action settings. These works have focused on tasks such as open-ended web navigation ____, social simulations ____, and virtual assistants ____. Meanwhile, language interfaces have also be been proposed within the RL literature, including leveraging external and commonsense knowledge ____, pre-training goal-based policies ____, enhancing generalization in embodied agents ____, and aiding human-AI coordination ____. Related works include GLAM ____, TWOSOME ____, BAD ____, and TextGym ____, which use LLM finetuning techniques in RL environments with a reward function. Relevant to our work is also ____, which, inspired by open-ended settings like Minecraft, employs RL to optimize the goals of an LLM planner based on feasibility.



\textbf{Explainable RL (XRL)}\quad
Early XRL relied on methods like decision trees and concept-based explanations ____, but these struggled with scalability in dynamic environments ____. Recent advances introduced large language models (LLMs) for post-hoc explanations, such as explaining decision paths from policy trees ____ or adding language descriptions to RL policies ____. However, these approaches focus on interpreting pre-existing policies rather than enabling LLMs to generate inherently explainable decisions, with challenges in aligning explanations to human reasoning ____. By contrast, inherently (also known as intrinsically) interpretable policies  are those that have internal representation that allow explanations 
 ____. Our work sits this literature by using LLM reasoning traces as the basis for environment action selection.
 
 \rev{
    With various works acknowledging the trade-off between interpretability and performance, prioritizing interpretability appears to be crucial in practice for many critical applications ____: an approach that we subscribe to in this work. For example, in the clinical AI domain, physicians require transparency to validate recommendations and uphold ethical accountability, as mandated by regulatory frameworks (e.g., ____). High-performing black-box systems often face rejection in clinical workflows due to distrust ____.  By contrast, interpretable models allow clinicians to audit biases and adapt logic to local contexts, whereas opaque policies risk failures under real-world distribution shifts ____. Transparent reasoning facilitates iterative, clinician-driven refinement, ensuring collaborative decision aid rather than an inflexible oracle ____. Empirical surveys show clinicians favor models that enable shared decision-making, error accountability, and ethical oversight despite modest performance penalties ____â€”a critical stance in high-stakes healthcare environments where trust and adaptability outweigh narrow efficiency gains.
}