\begin{wrapfigure}[18]{r}{0.475\textwidth}
  \vspace{-0.3in}
   \begin{center}
    \makebox[0.5\textwidth][c]{
    \input{ICLR_2025/Figure_Wrappers/Legend/two_methods}
    }

    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\textwidth]{ICLR_2025/Figures/eval_generalization_rigid/eval_line_Isaac-Rigid-Sliding-Multi-v0_eval_unseen_onl3_wTAE_norect.pdf}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\textwidth]{ICLR_2025/Figures/eval_generalization_rigid/eval_line_Isaac-Rigid-Insertion-Multi-v0_eval_unseen_onl3_wT_norect.pdf}
    \end{subfigure}
  \end{center}
  \vspace{-0.15in}
    \caption{Generalization performance on rigid-sliding and rigid-insertion tasks over 10 seeds. Models are trained on one object (\textit{plus}), two objects (\textit{plus}, \textit{star}), three object (\textit{plus}, \textit{star}, \textit{pentagon}) and tested on the remaining unseen objects. Graph-based models show better generalization than the Transformer, likely due to their ability to exploit object topology.}
    \label{fig:eval_generalization}
\end{wrapfigure}
