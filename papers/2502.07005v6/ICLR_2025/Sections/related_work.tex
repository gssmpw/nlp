\paragraph{Equivariant Policies for Robotic Manipulation}

In imitation learning for robotic manipulation, equivariance has been widely applied to reduce the effort of collecting human demonstrations \citep{zeng2020transporter, huang2022equi-trans, huang2024fourier, ryu2023diffusion, yang2024equibot}. Most prior work focuses on simple pick-and-place tasks, where the policy outputs the 3D pose of the end-effector. By leveraging equivariance, these policies can generalize across different object poses, significantly reducing the number of required demonstrations (e.g., only 5 to 10 demonstrations in \citep{ryu2023diffusion}). However, 3D pose actions are insufficient for tasks that require higher dexterity or involve deformable objects. To address this limitation, Equibot \citep{yang2024equibot} designed an equivariant policy that outputs velocity vectors, achieving success in more complex tasks such as cloth folding and object wrapping. 

There has been limited work on exploiting equivariant policies in reinforcement learning, and existing approaches have largely focused on 2D spaces \citep{wang2022so2equivariant, nguyen2023equivariant}. In this work, we extend the study of equivariant policies to 3D space within a reinforcement learning setting, which, to the best of our knowledge, has not yet been explored for robotic manipulation.
\input{ICLR_2025/Figure_Wrappers/eval_ppo_3_tasks}

\paragraph{RL with GNNs}

Graph-based representations in reinforcement learning have shown great success across diverse domains, including molecular design \citep{simm2021symmetryaware}, adaptive mesh refinement \citep{freymuth2023swarm}, and multi-agent systems like traffic light control \citep{pol2022multiagent}. Among these, the most closely related work to ours is morphology reinforcement learning \citep{wang2018nervenet, huang2020smp, pmlr-v162-trabucco22b, hong2022structureaware, gupta2022metamorph}, where the robotâ€™s kinematic structure is represented as a graph, allowing actuators to be controlled through message passing. This approach enables policies to generalize across different robot topologies, particularly in locomotion tasks \citep{gupta2022metamorph}. \citet{chen2023sgrl} extend these ideas to handle 3D environments, but only with sub-equivariant policies for rotations around the gravity axis.

However, these works primarily exploit the locality of graph structures, framing the problem as multi-agent reinforcement learning on graphs \citep{Jiang2020Graph}, where each node can make decisions influenced by its neighbors. In contrast, our work focuses on the underactuated problem where only a small subset of nodes (actuators) controls a much larger set of object nodes, framing a heterogeneous graph. The interactions between the nodes are therefore much more complex to capture using homogeneous GNN models.
