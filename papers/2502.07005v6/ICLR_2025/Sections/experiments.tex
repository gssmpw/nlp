In this section, we outline the experimental setup and present the results comparing the proposed \model against other baselines.

\subsection{Experimental Setup}
\label{sec:exp_setup}

\paragraph{Task Design}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{ICLR_2025/Figures/Fig_1_full.pdf}
    \caption{Illustration of our diverse and challenging manipulation tasks, involving both rigid and deformable objects. These tasks require precise control under complex geometric constraints, coordination between multiple actuators, and handling of intricate interactions between objects and actuators. The variety of tasks highlights the need for policies that can understand the geometric structure in large observation and action spaces.
    }
    \label{fig:main_tasks}
\end{figure*}

Our task design, illustrated in Figure~\ref{fig:main_tasks}, emphasizes testing the role of geometric structure and information exchange between objects and actuators in robotic manipulation. To focus on this, we abstract away the specifics of the robot body and consider only end-effector control. We introduce two categories of tasks: rigid manipulation on diverse geometries and deformable object manipulation, all implemented in NVIDIA IsaacLab \citep{mittal2023orbit} to leverage its GPU-based parallelization capabilities\footnote{A video showcasing the tasks can be found in the supplementary material.}. 

The rigid manipulation tasks are inspired by Transporter Net \citep{zeng2020transporter}. \textbf{Rigid-Sliding} mimics using a suction gripper to slide an object across a 2D plane to a target position and orientation, with 10 distinct objects, and randomized initial and target poses. \rebuttal{Next, \textbf{Rigid-Pushing} removes the physical connection between the actuator and the object, allowing the actuator to move freely in the $x$-$y$ plane to push the object to a desired target position and orientation}. \textbf{Rigid-Insertion}, similar to the assembly kit task in Transporter Net, extends this to 3D, requiring precise alignment and insertion of objects into holes, using $8$ different objects. Additionally, we introduce a novel \textbf{Rigid-Insertion-Two-Agents} task, where two linear actuators work together to control an object, guiding it to a target randomly positioned in the upper hemisphere of the $\mathcal{S}^2$.

For deformable object manipulation, we first adopt the \textbf{Rope-Closing} task from \cite{reform}, where two actuators manipulate a deformable rope to wrap around a cylindrical object in a 2D plane, with randomized initial configurations. We then introduce a novel task, \textbf{Rope-Shaping}, which increases complexity by requiring the rope to form a specific shape (a ``W" from the LASA dataset \citep{lasa-dataset}) to a desired orientation. Finally, we introduce \textbf{Cloth-Hanging}, where four actuators control the corners of a cloth to hang it onto a hanger, with randomized starting positions and orientations in 3D space. 
% \todo{Make sth up for the exploration explaination.}

These tasks present a range of manipulation challenges, emphasizing the role of geometric structure and requiring complex exploration strategies to coordinate the agents in completing the tasks. Full task details, including reward definitions, are provided in Appendix~\ref{appx:task_details}.

\paragraph{Baselines}

We compare \model against two primary baselines: policies based on a Transformer \citep{attention} and a naive \gls{empn}. Transformers serve as a strong baseline to evaluate in our setting as it can be seen as a fully-connected GNN \citep{battaglia2018relational}, and have achieved state-of-the-art performance in other graph-based reinforcement learning problems \citep{kurin2021my, pmlr-v162-trabucco22b, gupta2022metamorph, hong2022structureaware}. In addition, for the \emph{Cloth-Hanging} task, we evaluate two additional baselines, Heterogeneous GNN (HeteroGNN) and a naive GNN to highlight the effectiveness of incorporating equivariant constraints in a large 3D space. 

Our experimental setup aims to answer the following key questions: \textbf{(1)} Can explicitly modeling heterogeneity between actuators and objects, combined with $SE(3)$ equivariance, improve performance in complex 3D tasks? \textbf{(2)} \rebuttal{How well does HEPi generalize when dealing with different geometries, resolutions in rigid tasks, and varying sample spaces in the complex 3D \emph{cloth-hanging} task?} \textbf{(3)} Attention mechanisms are often employed in GNNs to capture heterogeneity, do they offer the same benefits as explicitly modeling heterogeneity in HEPi? \textbf{(4)} Does using trust-region methods in HEPi stabilize the training process more effectively than a naive PPO?

\subsection{Results and Discussions}
\label{sec:results}
\input{ICLR_2025/Sections/results}
