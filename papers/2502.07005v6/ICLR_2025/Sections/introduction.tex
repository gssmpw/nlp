Geometric structure plays a crucial role in robotic manipulation. For instance, in insertion tasks, a robot must precisely align objects with their corresponding target placements. Understanding the geometries is therefore essential in such tasks, as each pair requires a unique alignment \citep{zeng2020transporter, tang2024automate}. Similarly, for deformable objects like cloths, whose shapes change over time, successfully completing the task requires a policy that can capture these dynamic geometric changes \citep{softgym, antonova2021dedo, robocraft}. In both scenarios, these geometric structures can be naturally represented as graphs, a widely adopted framework in robot learning \citep{wang2018nervenet, huang2020smp, ryu2023diffusion, robocraft}. In this paper, we frame manipulation problems as heterogeneous graphs. Taking the \textit{Cloth-Hanging} task as an example, depicted in Figure~\ref{fig:hepi_diagram}, the cloth and the actuators are represented as two distinct node sets, connected by a set of directed inter-edges. Each node is associated with a geometric vector representing its 3D coordinates. Yet, this representation results in high-dimensional observation and action spaces, which makes learning policies that generalize seamlessly to novel orientations, poses, and unseen geometries challenging.

To address this issue, recent works \citep{zeng2020transporter,huang2022equi-trans,huang2024fourier,ryu2023diffusion} introduced equivariance in the $SE(3)$ space as an inductive bias.
Using \glspl{empn}, they learn policies that generalize to different poses by leveraging the geometric structure of the scene.
These works learn by imitation, and most only consider simple pick-and-place tasks, where the model only has to produce a desired end-effector pose to be reached by a controller. 
An exception is the recent Equibot \citep{yang2024equibot}, where the policy outputs velocity vectors rather than static end-effector poses, enabling success in more complex and dynamic tasks like cloth folding and wrapping by imitation. 
This work investigates how to transfer these ideas from imitation to reinforcement learning. 
Unlike supervised imitation, training policies with reinforcement learning presents additional challenges, particularly due to the need for high-frequency data collection and efficient adaptation to new experiences. Large policy networks struggle in these settings, as they are unable to quickly adapt to changing data \citep{andrychowicz2021what}. To address these issues, we design a lightweight heterogenous equivariant architecture, amenable to efficient on-policy reinforcement learning.
The architecture's equivariance allows generalizing between poses and its heterogeneity enables us to include and exploit knowledge about the scene as well as the unactuated and actuated objects in it. 
For training, we find that naively using Proximal Policy Optimization (PPO) \citep{ppo}, can result in suboptimal performance, and we propose to employ a more principled trust region approach from \cite{otto2021trpl} to achieve stable convergence.  

To evaluate our approach and future advancements in this direction, we propose a novel suite of \rebuttal{seven} tasks, realized using NIVIDA IsaacLab \citep{mittal2023orbit} to utilize its GPU-based simulation engine.
% Those tasks feature complex 2D and 3D manipulations, deformable objects, and objects of varying shapes and geometries. 
They are designed to highlight the role of geometric structure in manipulation tasks, with a progressive increase in difficulty, from simple rigid-body manipulation with diverse objects to more challenging tasks involving multiple actuators and deformable objects. Our experimental results demonstrate that the proposed \emph{\model} outperforms both Transformer-based and pure \gls{empn} baselines, particularly in complex 3D manipulation tasks. HEPi's integration of equivariance and explicit heterogeneity modelling improves performance in terms of average returns, sample efficiency,  and generalization to unseen objects.

To summarize, our contributions are \textbf{i)} a novel benchmark comprising rigid insertion of varying geometries and deformable objects manipulation that is particularly well-suited for geometry aware reinforcement learning research; \textbf{ii)} \gls{hepi}, a graph-based policy that is expressive and computationally efficient while being constrained to be $SE(3)$-equivariant, perfectly suitable for solving complex 3D manipulation tasks under reinforcement learning settings; \textbf{iii)} a theoretical justification and extensive empirical analysis for our design choices.

\begin{figure*}
    \centering
    \includegraphics[width=0.95\linewidth]{ICLR_2025/Figures/Fig_2_full.pdf}
    \caption{\textbf{Left:} A \emph{Cloth-Hanging} task represented by a heterogeneous graph that comprises two disjoint node sets, objects, and actuators, connected through directed, fully-connected inter-edges. Intra-edges occur within each set (both objects and actuators) to capture relationships within clusters. Information is aggregated from objects to actuators via inter-edges. The target distance is absorbed into the feature representation rather than treated as a separate node type. \textbf{Right:} Overview of \emph{Heterogeneous Equivariant Policy (HEPi)}, consisting of multiple Equivariant Message Passing Networks (EMPNs) process the graph, and the outputs are aggregated to generate the final action.}
    \label{fig:hepi_diagram}
\end{figure*}
