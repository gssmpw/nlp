\input{ICLR_2025/Figure_Wrappers/eval_all_6_tasks}

In the main evaluations, we generate 1000 scenes per task (sampled according to Appendix~\ref{appx:task_details}) and compute the undiscounted return over 10 seeds, and report the average using Interquartile Mean (IQM) \citep{agarwal2021iqm} with 95\% confident interval. Figure \ref{fig:results_main_6_tasks} shows the \update{evaluation} curves for the \rebuttal{seven} manipulation tasks. Overall, both EMPN and HEPi outperform the Transformer in terms of sample complexity, owing to their ability to exploit symmetry.

For final performance on rigid tasks, firstly in \textit{rigid-slding-2D} and \textit{rigid-insertion-2D+z} tasks, HEPi and Transformer policies perform comparably, suggesting that the limited task complexity does not fully leverage the benefits of equivariant constraints. However, when the search space grows larger, as in the case of \textit{rigid-insertion-two-agents-3D}, Transformer struggles to find a policy that generalizes to all poses. EMPN, on the other hand, gets stuck in local optima due to its lack of expressiveness, especially in tasks requiring more exploration, such as \rebuttal{\textit{rigid-pushing-2D}}, \textit{rigid-insertion-2D+z} and \textit{rigid-insertion-two-agents-3D}. In contrast, HEPi’s explicit handling of heterogeneity allows for more effective exploration, leading to better overall performance.

In \textit{rope-closing} and \textit{rope-shaping}, simple deformable object tasks, the Transformer exhibits poor generalization, likely due to the complexity introduced by non-rigid constraints and random orientations. HEPi and EMPN perform similarly on the 2D tasks, but as tasks scale up to 3D environments, such as \textit{cloth-hanging-3D}, HEPi shows a significant advantage, outperforming both baselines. This highlights the importance of explicitly capturing heterogeneity and task geometry in manipulation. % tasks.

\input{ICLR_2025/Figure_Wrappers/eval_cloth_hanging_equiv}


\paragraph{Generalizability}

\input{ICLR_2025/Figure_Wrappers/eval_noise_res_pushing}

Figure~\ref{fig:eval_equi} compares the performance of different models on the \emph{Cloth-Hanging} task across varying sample spaces. As expected, smaller sample spaces simplify the exploration and improve performance. Heterogeneous models (HeteroGNN and HEPi) consistently achieve higher final returns than their homogeneous counterparts, demonstrating greater expressiveness. However, HeteroGNN requires more samples, whereas HEPi's use of \gls{empn} significantly improves sample efficiency by leveraging equivariant constraints in large 3D spaces.

Next, we evaluate the robustness of HEPi to noisy inputs and its ability to handle high-resolution object meshes on the \emph{Rigid-Pushing} task. GNNs naturally capture locality through message passing, allowing them to scale effectively to higher-resolution graphs without retraining \citep{li2020multipole, freymuth2023swarm}. During training, we added Gaussian noise ($\sigma=0.01$) to normalized positions and velocities to encourage diverse node representations, a common GNN regularization technique \citep{godwin2022simple}. The best HEPi agent was then evaluated with varying Gaussian noise levels applied to pre-normalized inputs (environment noise) and across low-resolution (\(\sim20\) nodes) and high-resolution (\(\sim1200\) nodes) object meshes. As shown in Figure~\ref{fig:genealizability_main} (left), HEPi maintains high performance across resolutions with only mild degradation at higher noise levels, demonstrating its scalability and robustness to noisy and diverse object representations.

Finally, we evaluate the generalization of these models to unseen objects on two rigid tasks: \emph{rigid-sliding} and \emph{rigid-insertion}. Both tasks are trained on subsets of objects—one (\textit{plus}), two (\textit{plus}, \textit{star}), and three (\textit{plus}, \textit{star}, \textit{pentagon})—and tested on the remaining objects. Figure~\ref{fig:genealizability_main} (right) shows that HEPi generalizes better than the Transformer baseline, benefiting from the ability of graph-based models to exploit object topology. In contrast, Transformers lack structure-aware embeddings and struggle with graph-structured inputs, as noted in prior work \citep{hong2022structureaware}.

\paragraph{Attention}

\input{ICLR_2025/Figure_Wrappers/eval_all_bar_6_tasks}

Attention mechanisms are widely used in graph neural networks to capture heterogeneity. In this experiment, we examine the impact of adding attention as an aggregation function in Equation~\ref{eq:mpnn} to both homogeneous and heterogeneous graph networks, framing the popular Graph Attention Network (GAT) framework \citep{gat}. However, as shown in Figure \ref{fig:eval_attention}, attention does not provide any noticeable benefit across the tasks. 

While attention helps capture some heterogeneity, particularly in tasks like \rebuttal{\textit{rigid-pushing-2D}} and \textit{rigid-insertion-two-agents-3D}, it ultimately complicates the learning process in on-policy reinforcement learning, making the optimization landscape more difficult to traverse. Additionally, adding attention significantly increases training time without improving performance, e.g., for HEPi it almost doubled.

\paragraph{Training Stability}

To investigate the impact of the TRPL method, we compare it against PPO. For a fair comparison, we perform a grid search over the \texttt{clip\_eps} parameter in PPO (Appendix~\ref{sec:appx_grid_search_ppo}). Overall, as depicted in Figure~\ref{fig:eval_trpl_ppo}, in tasks requiring high exploration such as \emph{cloth-hanging-3D}, PPO struggles to maintain conservative updates, often resulting in unstable performance. However, in tasks with a lower-dimensional action space, such as 2D environments, well-tuned PPO performs comparably to TRPL in terms of final average return, though being less sample efficient. This suggests that while PPO can be tuned to perform adequately in simpler action spaces, TRPL provides more stability and robustness, particularly in complex 3D environments that demand more effective exploration control.

