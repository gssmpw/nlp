\section{Discussion on Applicability and Limitations}
\label{appx:discussion}

\subsection{Theoretical Foundations and Motivations}
The application of Latent Diffusion Models (LDM) to time series forecasting represents a fundamental shift from traditional approaches. This section examines the theoretical foundations and practical motivations behind our framework. Traditional time series forecasting methods often struggle with three key challenges: capturing complex distributions, modeling uncertainty, and handling long-range dependencies. Our LDM-based approach addresses these challenges through its principled probabilistic framework:
\begin{equation}
p(x_{t+1:t+H}|x_{1:t}) = \int p(z)p_\theta(x_{t+1:t+H}|z,x_{1:t})dz
\end{equation}

This formulation offers several advantages. First, it naturally models the full conditional distribution of future values rather than point estimates, enabling robust uncertainty quantification. Second, the iterative denoising process allows the model to capture temporal dependencies at multiple scales. Third, the latent space representation provides an efficient mechanism for learning compressed temporal features.

The integration of vision transformations with LDM is motivated by both theoretical insights and empirical observations. Time series data, when properly transformed into visual representations, exhibits several important properties:

\begin{enumerate}
\item \textbf{Pattern Preservation}: Visual encodings preserve crucial temporal structures including periodicity, trends, and seasonality through spatial arrangements. This is formally expressed as:
\begin{equation}
d(X_1, X_2) \propto d(\mathcal{V}(X_1), \mathcal{V}(X_2))
\end{equation}
where $\mathcal{V}$ represents our vision transformation processing.

\item \textbf{Information Complementarity}: Different visual encodings capture complementary aspects of temporal dynamics:
\begin{equation}
\mathcal{I}(X;Z) \geq \mathcal{I}(X;Z_{visual}) + \mathcal{I}(X;Z_{temporal})
\end{equation}
This property ensures that no critical temporal information is lost during transformation.

\item \textbf{Transfer Learning Potential}: The visual domain enables leveraging powerful pre-trained vision models and their hierarchical feature extraction capabilities.
\end{enumerate}

\subsection{Current Limitations and Future Directions}
The primary limitation of our framework centers on the computational efficiency of the diffusion process. The iterative nature of denoising introduces significant computational overhead, expressed as $T_{\text{total}} = T_{\text{visual}} + t \cdot T_{\text{diffusion}} + T_{\text{projection}}$, which poses challenges for real-time applications and resource-constrained environments. While we have implemented several efficiency-enhancing strategies, such as gradient-free vision transformations and component freezing (including text and vision encoders), the sequential nature of the diffusion process remains a fundamental constraint. The model also exhibits sensitivity to hyperparameter choices in the diffusion schedule, as reflected in the gradient behavior $\sigma(\nabla_\theta \mathcal{L}) \propto \lambda_1\beta_t + \lambda_2\alpha_t$, though this sensitivity is primarily confined to the diffusion component.

Our framework's modular architecture provides clear pathways for future improvements. The design allows for easy replacement and enhancement of individual components, from vision transformation methods (We were able to employ more than the three strategies in the article) to temporal encoder architectures. Future research could focus on developing more efficient training algorithms and incorporating adaptive computation mechanisms while maintaining the model's predictive power. The integration of sophisticated scheduling mechanisms or alternative diffusion formulations could address current computational constraints and improve training stability. Additionally, the framework's extensibility enables adaptation to specific domain requirements and integration of emerging techniques in both visual representation learning and diffusion modeling. These potential improvements, combined with the framework's demonstrated strengths in probabilistic modeling and multi-scale feature capture, suggest promising directions for advancing time series forecasting capabilities.