\newpage
\section{Prerequisites of Latent Diffusion Models}
\label{appx:ldm_algorithm}

\subsection{Autoencoder Framework}
Latent Diffusion Models (LDMs) leverage the autoencoder architecture to facilitate efficient learning in the latent space. An autoencoder comprises two primary components: an encoder and a decoder. The encoder $\mathcal{E}$ compresses high-dimensional input data $x \in \mathbb{R}^D$ into a lower-dimensional latent representation $z \in \mathbb{R}^d$, where $d \ll D$. This compression not only reduces the computational complexity but also captures the essential features of the data. In our implementation, we utilize the pre-trained AutoencoderKL from the \textbf{\textit{stable-diffusion-v1-4}}, which has demonstrated remarkable capabilities in image compression and reconstruction. Mathematically, this process is described as:
\begin{equation}
    z = \mathcal{E}(x)
\end{equation}

\paragraph{Latent Space Scaling}
\label{latent_space_scaling}
In practice, the latent representations produced by the encoder are typically scaled by a factor $s = 0.18215$ to ensure numerical stability and optimal distribution characteristics:
\begin{equation}
    z_{scaled} = s \cdot \mathcal{E}(x)
\end{equation}
This specific scaling factor originates from the VAE design in Stable Diffusion and is derived through empirical optimization. The value is calculated to minimize the KL divergence between the scaled latent distribution and the standard normal distribution:
\begin{equation}
    s^* = \operatorname*{argmin}_{s} \mathbb{E}_{x \sim p_{data}}[D_{KL}(s \cdot \mathcal{E}(x) \| \mathcal{N}(0, 1))]
\end{equation}
where $D_{KL}$ represents the Kullback-Leibler divergence. In our framework, this scaling operation serves multiple critical purposes. It ensures numerical stability during the diffusion process by maintaining consistent value ranges while facilitating better optimization dynamics by bringing the latent distribution closer to the standard normal. This operation also maintains compatibility with the pre-trained weights while allowing for efficient processing of our visual time series representations.

The optimization process involves collecting latent representations $z = \mathcal{E}(x)$ from a large dataset, computing their empirical statistics $\mu_z$ and $\sigma_z^2$, and determining the optimal scaling factor $s$ such that $s\sigma_z \approx 1$ to match the target standard deviation. This process has been extensively validated in the context of both image generation and, in our case, time series visual representations. During decoding, the inverse scaling is applied to restore the original magnitude:
\begin{equation}
    \hat{x} = \mathcal{D}(z_{scaled}/s)
\end{equation}
The autoencoder is trained to minimize the reconstruction loss:
\begin{equation}
    \mathcal{L}_{\text{AE}} = \|\mathcal{D}(\mathcal{E}(x)) - x\|_2^2
\end{equation}
However, in the context of LDMs, the autoencoder enables operations to be performed in the compressed latent space, thereby enhancing efficiency without significant loss of information. In our implementation, we freeze the pret-rained autoencoder parameters in the LDM4TS model during training, focusing the optimization process on diffusion dynamics and temporal feature extraction. This design choice significantly reduces computational overhead while maintaining the benefits of well-learned representations from the compressed latent space.

\subsection{Foundations of Diffusion Models}
Diffusion models define a principled framework for generative modeling through gradual noise addition and removal. In our LDM4TS framework, we adapt this process specifically for time series visual representations while maintaining the fundamental probabilistic structure.

\paragraph{Forward Process}
The forward diffusion process follows a Markov chain that progressively adds Gaussian noise:
\begin{align}
    q(x_t|x_{t-1}) &= \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t\mathbf{I}) \\
    q(x_t|x_0) &= \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t}x_0, (1-\bar{\alpha}_t)\mathbf{I})
\end{align}
Here, $q(x_t|x_{t-1})$ describes the transition from step $t-1$ to $t$, where $\beta_t$ controls the noise schedule. In our implementation, we adopt a linear noise schedule with carefully tuned parameters $\beta_{start}=0.00085$ and $\beta_{end}=0.012$. The second equation gives the direct relationship between any noisy sample $x_t$ and the original data $x_0$, where $\bar{\alpha}_t = \prod_{s=1}^t (1-\beta_s)$ represents the cumulative product of noise levels.

\paragraph{Reverse Process}
The reverse process learns to gradually denoise data through:
\begin{equation}
    p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t,t), \Sigma_\theta(x_t,t))
\end{equation}
where the mean and variance are parameterized as:
\begin{align}
    \mu_\theta(x_t,t) &= \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(x_t,t)) \\
    \Sigma_\theta(x_t,t) &= \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t
\end{align}
In our framework, we modify the noise prediction network $\epsilon_\theta$ to accept additional conditioning information, transforming the reverse process into:
\begin{equation}
    p_\theta(x_{t-1}|x_t,c) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t,t,c), \Sigma_\theta(x_t,t))
\end{equation}
where $c$ represents the concatenated frequency domain embeddings and encoded textual descriptions. This modification allows the model to leverage both spectral and semantic information during the denoising process while maintaining the same variance schedule.

\paragraph{Score-based Generation}
The score function represents the gradient of the log-density:
\begin{equation}
    s_\theta(x_t,t) = \nabla_{x_t} \log p_\theta(x_t) = -\frac{\epsilon_\theta(x_t,t)}{\sqrt{1-\bar{\alpha}_t}}
\end{equation}
This formulation enables training through denoising score matching:
\begin{equation}
    \mathcal{L}_{\text{score}} = \mathbb{E}_{t,x_0,\epsilon}[\|\epsilon - \epsilon_\theta(x_t,t)\|_2^2]
\end{equation}

\paragraph{Sampling Methods}
Different sampling strategies offer various trade-offs between generation quality and computational efficiency. In our implementation, we primarily utilize DDIM for its deterministic nature and faster sampling capabilities, though both approaches are supported:
\begin{itemize}
    \item \textbf{DDPM}: Uses the full chain of $T$ steps with stochastic sampling:
    \begin{equation}
        x_{t-1} = \mu_\theta(x_t,t) + \sigma_t\epsilon, \quad \epsilon \sim \mathcal{N}(0,\mathbf{I})
    \end{equation}
    \item \textbf{DDIM}: Enables faster sampling through deterministic trajectories:
    \begin{equation}
        x_{t-1} = \sqrt{\bar{\alpha}_{t-1}}\left(\frac{x_t - \sqrt{1-\bar{\alpha}_t}\epsilon_\theta(x_t,t)}{\sqrt{\bar{\alpha}_t}}\right) + \sqrt{1-\bar{\alpha}_{t-1}}\epsilon_\theta(x_t,t)
    \end{equation}
\end{itemize}

\subsection{U-Net Architecture}
The U-Net architecture serves as the backbone for noise prediction in our framework, combining multi-view processing with skip connections specifically designed for time series visual patterns. Our implementation modifies the standard U-Net structure to better handle temporal dependencies while maintaining spatial coherence.

\paragraph{Encoder-Decoder Structure}
The architecture consists of multiple resolution levels:
\begin{itemize}
    \item \textbf{Downsampling path}: Progressive feature compression
    \begin{equation}
        h_l = \text{ResBlock}(\text{Down}(h_{l-1})), \quad l = 1,\ldots,L
    \end{equation}
    
    \item \textbf{Upsampling path}: Gradual feature reconstruction
    \begin{equation}
        h'_l = \text{ResBlock}(\text{Up}(h'_{l+1})) + h_l, \quad l = L,\ldots,1
    \end{equation}
    
    \item \textbf{Skip connections}: Feature preservation across scales
    \begin{equation}
        h'_l = h'_l + \text{Project}(h_l)
    \end{equation}
\end{itemize}

\paragraph{Feature Extraction}
Each resolution level processes features through a sequence of operations:
\begin{equation}
    F_l = \text{Conv}(\text{GroupNorm}(\text{Attention}(h_l)))
\end{equation}
These operations are augmented with timestep embeddings, which provide temporal information to guide the denoising process:
\begin{equation}
    \gamma_t = \text{MLP}(\text{SinusoidalPos}(t))
\end{equation}
In our implementation, the timestep embedding is projected through a two-layer MLP with SiLU activation, following the design choices in Stable Diffusion for consistency and stability.

\subsection{Attention Mechanisms}
Our model employs attention mechanisms to capture both local and global dependencies in the visual representations:
\paragraph{Self-Attention}
Computes interactions within a feature set through scaled dot-product attention:
\begin{equation}
    \text{Attention}(Q,K,V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V
\end{equation}
where $Q,K,V \in \mathbb{R}^{N \times d_k}$ are query, key, and value matrices.

\paragraph{Cross-Attention}
Enables conditioning through external information:
\begin{equation}
    \text{CrossAttn}(Q,K,V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V
\end{equation}
where $Q$ comes from the main branch and $K,V$ from conditioning information. Multi-head attention extends this:
\begin{equation}
    \text{MultiHead}(Q,K,V) = \text{Concat}(\text{head}_1,\ldots,\text{head}_h)W^O
\end{equation}

\subsection{Conditional Generation}
\label{appx:conditional_generation}
Our framework implements a sophisticated dual-conditioning mechanism that leverages both frequency domain features and semantic descriptions to guide the diffusion process. This multi-modal approach enables robust capture of both temporal patterns and contextual information:

\paragraph{Frequency Conditioning}
To effectively encode the rich spectral information inherent in time series data, we implement a sophisticated frequency domain transformation pipeline. This process begins with the application of a Hann window function, which is crucial for minimizing spectral leakage and enhancing frequency resolution:

\begin{equation}
    w_t = 0.5(1 - \cos(\frac{2\pi t}{L-1}))
\end{equation}
The frequency features are then systematically extracted through a carefully designed three-step process. First, we apply the window function to the input sequence:
\begin{equation}
    X_{win} = X \odot w
\end{equation}

Next, we transform the windowed signal into the frequency domain using the Fast Fourier Transform:
\begin{equation}
    X_{fft} = \text{FFT}(X_{win}) = \sum_{t=0}^{L-1} X_{win}(t) \cdot e^{-2\pi i k t / L}
\end{equation}
Finally, to preserve the complete spectral information, we concatenate the real and imaginary components of the FFT output:
\begin{equation}
    c_{freq} = \text{Concat}[X_{fft_{real}}, X_{fft_{imag}}] \in \mathbb{R}^{B \times (2DL+2)}
\end{equation}
where $L$ denotes the sequence length, $w$ represents the Hann window function, and $\odot$ indicates element-wise multiplication. The terms $X_{fft_{real}}$ and $X_{fft_{imag}}$ correspond to the real and imaginary components of the Fourier transform respectively. This comprehensive encoding strategy enables our model to capture both amplitude and phase information across multiple frequency bands, while maintaining computational efficiency through strategic dimensionality reduction.

\paragraph{Text Conditioning}
To provide semantic guidance for the diffusion process, we automatically generate descriptive prompts by extracting key characteristics from the input time series. The prompt generation function $d_{prompt}(X)$ captures the following statistical properties:
\vspace{-1em}
\begin{itemize}[leftmargin=*, itemsep=0pt]
    \item Statistical measures: minimum, maximum, and median values
    \item Temporal dynamics: overall trend direction and lag patterns
    \item Context information: prediction length and historical window size
    \item Domain knowledge: dataset-specific descriptions
\end{itemize}
\vspace{-1em}
These features are combined into a structured prompt template. A typical generated prompt follows the format:
\begin{quote}
\textit{\textcolor{gray}{"$<|start_prompt|>$Dataset description: \{description\}. Task: forecast the next \{pred\_len\} steps given the previous \{seq\_len\} steps. Input statistics: min value \{min\}, max value \{max\}, median value \{median\}, trend is \{trend\_direction\}, top-5 lags are \{lags\}.$<|<end_prompt>|>$"}}
\end{quote}

The prompts are then processed through a frozen \textit{\textbf{BERT-base-uncased}} model (110M parameters) to extract semantic features. Specifically, each prompt is first tokenized using BERT's WordPiece tokenizer with a maximum sequence length of 77 tokens:
\begin{equation}
    h_{token} = \text{BERT}(d_{prompt}(X)) \in \mathbb{R}^{B \times L_{seq} \times d_{ff}}
\end{equation}
where $L_{seq}$ is the sequence length after tokenization and $d_{ff}=768$ is BERT's hidden dimension. The token-level features are aggregated through mean pooling to obtain a sequence-level representation:
\begin{equation}
    h_{pool} = \frac{1}{L_{seq}}\sum_{i=1}^{L_{seq}} h_{token}[:,i,:] \in \mathbb{R}^{B \times d_{ff}}
\end{equation}
The pooled features are then projected to match the latent dimension through a learnable transformation:
\begin{equation}
    c_{text} = \text{TextEncoder}(X)= \text{TextProj}(h_{pool}) \in \mathbb{R}^{B \times d_{model}}
\end{equation}
where $\text{TextProj}(\cdot)$ consists of a linear layer that projects from $d_{ff}$ to $d_{model}$, followed by layer normalization and ReLU activation to enhance feature expressiveness.

The frequency and text conditions are fused through a cross-modal attention mechanism:
\begin{equation}
    c = \text{CrossAttn}(\text{MLP}([c_{\text{text}}; c_{\text{freq}}])) \in \mathbb{R}^{B \times d_{model}}
\end{equation}
where the MLP first projects the concatenated features to a higher dimension for better feature interaction, and the cross-attention layer enables dynamic feature selection based on the latent representation. This combined conditioning signal guides the diffusion process by injecting both semantic and frequency information into each denoising step through the attention blocks of the U-Net architecture.