\newpage
\section{Pseudo of LDM4TS framework}
\begin{algorithm}[H]
\caption{Training Process of LDM4TS}
\begin{algorithmic}[1]
\REQUIRE Time series data $\{\mathbf{X}, \mathbf{Y}\}$, where $\mathbf{X} \in \mathbb{R}^{B\times L\times D}$, $\mathbf{Y} \in \mathbb{R}^{B\times pred\_len\times D}$
\ENSURE Trained model parameters $\Theta$

\STATE Initialize VAE encoder $\mathcal{E}$, decoder $\mathcal{D}$, UNet $\mathcal{U}$, \hfill $\triangleright$ Model components
\STATE Initialize diffusion steps $T$, noise schedule $\{\beta_t\}_{t=1}^T$ \hfill $\triangleright$ Diffusion parameters
\STATE $\alpha_t = 1 - \beta_t$, $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$ \hfill $\triangleright$ Compute coefficients

\WHILE{not converged}
    \STATE Sample mini-batch $\{\mathbf{X}_b, \mathbf{Y}_b\}$ \hfill $\triangleright$ Get training batch
    
    \STATE // Data Preprocessing
    \STATE $means, stdev \gets \text{ComputeStats}(\mathbf{X}_b)$ \hfill $\triangleright$ Calculate statistics
    \STATE $\mathbf{X}_{norm} \gets (\mathbf{X}_b - means) / stdev$ \hfill $\triangleright$ Normalize input
    
    \STATE // Vision Transformation for Time Series
    \FOR{$i \in \{1,\ldots,D\}$}
        \STATE $\mathbf{X}_i \gets \mathbf{X}_{norm}[:,:,i]$ \hfill $\triangleright$ Extract dimension $i$ \;
        \STATE $\mathbf{I}_{seg,i} \gets \text{Segmentation}(\mathbf{X}_i)$ \hfill $\triangleright$ Time series to image \;
        \STATE $\mathbf{I}_{gaf,i} \gets \text{GramianAngularField}(\mathbf{X}_i)$ \hfill $\triangleright$ Polar encoding \;
        \STATE $\mathbf{I}_{rp,i} \gets \text{RecurrencePlot}(\mathbf{X}_i)$ \hfill $\triangleright$ Distance matrix
    \ENDFOR
    
    \STATE $\mathbf{I} \gets \text{Concat}([\mathbf{I}_{seg}, \mathbf{I}_{gaf}, \mathbf{I}_{rp}])$ \hfill $\triangleright$ Combine all views
    
    \STATE // Conditional Controls
    \STATE $\mathbf{f} \gets \text{FreqEncoder}(\text{FFT}(\mathbf{X}_{norm}))$ \hfill $\triangleright$ Extract frequency features
    \STATE $\mathbf{c} \gets \text{TextEncoder}(\text{GeneratePrompt}(\mathbf{X}_b))$ \hfill $\triangleright$ Generate text embedding
    \STATE $\mathbf{cond} \gets \text{FusionLayer}([\mathbf{f}, \mathbf{c}])$ \hfill $\triangleright$ Fuse conditions

    \STATE // Forward Diffusion Process
    \STATE $\epsilon \sim \mathcal{N}(0, \mathbf{I})$ \hfill $\triangleright$ Sample random noise
    \STATE $\mathbf{z}_t \gets \sqrt{\bar{\alpha}_t}\mathbf{z}_0 + \sqrt{1-\bar{\alpha}_t}\epsilon$ \hfill $\triangleright$ Noisy latent
    
    \STATE // Reverse Diffusion Process
    \STATE $\mathbf{z}_0 \gets (\mathbf{z}_t - \sqrt{1-\bar{\alpha}_t}\hat{\epsilon})/\sqrt{\bar{\alpha}_t}$ \hfill $\triangleright$ Denoised latent
    
    % \STATE // Latent Diffusion Process
    % \STATE $\epsilon \sim \mathcal{N}(0, \mathbf{I})$ \hfill $\triangleright$ Sample random noise
    % \STATE $\mathbf{z}_t \gets \sqrt{\bar{\alpha}_t}\mathbf{z}_0 + \sqrt{1-\bar{\alpha}_t}\epsilon$ \hfill $\triangleright$ Noisy latent
    
    % \FUNCTION{ReverseDiffusion}{$\mathbf{z}_t, \hat{\epsilon}, t$} \hfill $\triangleright$ Remove noise
    %     \RETURN $(\mathbf{z}_t - \sqrt{1-\bar{\alpha}_t}\hat{\epsilon})/\sqrt{\bar{\alpha}_t}$ \hfill $\triangleright$ Denoised latent
    % \ENDFUNCTION
    
    \STATE $\mathbf{z}_0 \gets \mathcal{E}(\mathbf{I})$ \hfill $\triangleright$ Encode to latent space
    \STATE Sample $t \sim \text{Uniform}\{1,...,T\}$ \hfill $\triangleright$ Random timestep
    \STATE $\mathbf{z}_t, \epsilon \gets \text{ForwardDiffusion}(\mathbf{z}_0, t)$ \hfill $\triangleright$ Forward process
    \STATE $\hat{\epsilon} \gets \mathcal{U}(\mathbf{z}_t, t, \mathbf{cond})$ \hfill $\triangleright$ Predict noise
    \STATE $\mathbf{z}_{rec} \gets \text{ReverseDiffusion}(\mathbf{z}_t, \hat{\epsilon}, t)$ \hfill $\triangleright$ Reverse process
    \STATE $\mathbf{I}_{rec} \gets \mathcal{D}(\mathbf{z}_{rec})$ \hfill $\triangleright$ Decode image
    
    \STATE // Feature Extraction and Fusion
    \STATE $\mathbf{h}_v \gets \text{VisionEncoder}(\mathbf{I}_{rec})$ \hfill $\triangleright$ Visual features
    \STATE $\mathbf{h}_t \gets \text{TemporalEncoder}(\text{PatchEmbed}(\mathbf{X}_{norm}))$ \hfill $\triangleright$ Temporal features
    \STATE $\alpha \gets \text{Softmax}(\text{MLP}([\mathbf{h}_v, \mathbf{h}_t]))$ \hfill $\triangleright$ Compute weights
    \STATE $\hat{\mathbf{Y}} \gets \alpha_1\text{VisionHead}(\mathbf{h}_v) + \alpha_2\text{TemporalHead}(\mathbf{h}_t)$ \hfill $\triangleright$ Fuse predictions
    
    \STATE // Optimization
    \STATE $\mathcal{L}_{diff} \gets \|\epsilon - \hat{\epsilon}\|_2^2$ \hfill $\triangleright$ Diffusion loss
    \STATE $\mathcal{L}_{pred} \gets \|\hat{\mathbf{Y}} - \mathbf{Y}_b\|_2^2$ \hfill $\triangleright$ Prediction loss
    \STATE $\mathcal{L} \gets \lambda_1\mathcal{L}_{diff} + \lambda_2\mathcal{L}_{pred}$ \hfill $\triangleright$ Total loss
    \STATE $\Theta \gets \text{Adam}(\Theta, \nabla_{\Theta}\mathcal{L})$ \hfill $\triangleright$ Update parameters
\ENDWHILE

\STATE \textbf{return} $\Theta$ \hfill $\triangleright$ Return trained model
\end{algorithmic}
\end{algorithm}