\vspace{-1em}
\section{Related Work}
\vspace{-0.2em}
\subsection{Diffusion Models for Time Series}
Diffusion models have emerged as a powerful class of generative approaches, demonstrating remarkable success across various high-dimensional data domains. Denoising Diffusion Probabilistic Models (DDPM)~\cite{ho2020denoising} employ a Markov chain to add and remove Gaussian noise, producing high-fidelity samples gradually. Score-based diffusion models~\cite{song2020score} directly estimate the score function of data distributions. Meanwhile, conditional diffusion models incorporate additional guidance signals to enhance generation quality~\cite{dhariwal2021diffusion} further.
\begin{figure*}[t]
  \centering
  \includegraphics[width=0.98\linewidth]{figure/framework.pdf}
  \caption{The framework of our proposed LDM4TS. Time series data is first transformed into complementary visual representations (SEG: Segmentation, GAF: Gramian Angular Field, RP: Recurrence Plot) that encode structural temporal patterns. A conditional latent diffusion model then reconstructs the masked images through iterative denoising guided by cross-modal conditioning (FC: frequency conditioning, TC: textual conditioning). Finally, the reconstructed images are mapped back to time series space with explicit temporal dependencies and implicit patterns.}
\vspace{-0.4cm}
\label{fig:framework}
\end{figure*}

Recent years have witnessed increasing applications of diffusion models in time series analysis~\cite{yang2024survey,lin2024diffusion}. For forecasting tasks, TimeGrad~\cite{rasul2021autoregressive} pioneers this direction by incorporating autoregressive components, while D3VAE~\cite{li2022generative} integrates variational auto-encoders with diffusion for enhanced capabilities. TSDiff~\cite{kollovieh2024predict} iteratively refines base forecasts through implicit probability densities. In parallel, conditional approaches have been explored for imputation tasks, where CSDI~\cite{tashiro2021csdi} and MIDM~\cite{wang2023observed} handle irregular time series through conditional score matching. Domain-specific designs have also emerged, such as DiffLoad~\cite{wang2023diffload} for load forecasting, WaveGrad~\cite{chen2020wavegrad} and DiffWave~\cite{kong2020diffwave} for audio synthesis, and EHRDiff~\cite{yuan2023ehrdiff} for healthcare applications. DiffSTG~\cite{wen2023diffstg} further explores spatio-temporal graph structures in diffusion models for time series.

\textit{However, these methods primarily focus on single-modality time series and lack mechanisms for modeling cross-modal temporal relationships.} Our work advances the development of latent diffusion models for TSF by incorporating multimodal information and exploiting cross-modal conditioning mechanisms, thereby substantially improving the accuracy and robustness under different forecasting scenarios.
%By modeling the temporal alignment between different modalities, our approach aims to enhance both forecasting performance and multimodal information utilization.

\subsection{Vision-enhanced Time Series Forecasting}
Vision models like ViT~\cite{dosovitskiy2020image} and MAE~\cite{he2022masked} have demonstrated remarkable success in CV through their powerful feature extraction capabilities, showing strong generalization abilities when pre-trained on large-scale datasets like ImageNet~\cite{deng2009imagenet}. Inspired by the success of vision models, researchers have begun exploring their potential in time series forecasting. 

The concept of treating time series as images has evolved from traditional approaches using Gramian Angular Fields (GAF) and Markov Transition Fields (MTF)~\cite{wang2015imaging} to more sophisticated methods. TimesNet~\cite{wu2022timesnet} introduces a novel approach by transforming temporal data into 2D matrices, enabling the use of inception blocks for multi-scale temporal pattern extraction. Building upon this idea, SparseTSF~\cite{lin2024sparsetsf} incorporates sparsity constraints to better capture periodic and trend components in time series. ViTime~\cite{yang2024vitime} demonstrates the possibility of zero-shot forecasting by treating time series as visual signals while VisionTS~\cite{chen2024visionts} shows that pre-trained visual models can directly serve as time series forecasters without domain-specific adaptation. 

\textit{However, these approaches are predominantly deterministic and lack uncertainty quantification capabilities since they are not built within generative frameworks.} Our work addresses these limitations by integrating latent diffusion models with visual representations in a unified framework. This design enables our model to effectively capture temporal dependencies while maintaining the uncertainty modeling capabilities inherent in diffusion models.

\par In summary, while existing methods have made significant progress in either cross-modal temporal pattern extraction or probabilistic generative modeling, they have yet to effectively combine these complementary strengths. Our work bridges this gap by introducing a unified framework that leverages both visual representation learning and latent diffusion processes. Using multi-view vision transformations and multi-conditional generation, our approach captures rich temporal patterns while providing well-calibrated uncertainty estimates, advancing both visual representation learning and probabilistic modeling aspects of TSF.
\vspace{-0.5em}