
\documentclass[table]{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
%\input{math_commands.tex}
\usepackage{xcolor} 
\usepackage[most]{tcolorbox}
\usepackage{soul}
\usepackage{pifont}
\usepackage{bbding}
\usepackage{wrapfig}
\usepackage{caption}
\usepackage{color,xcolor}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} 
\usepackage{multirow}
\usepackage{diagbox}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{natbib}
\usepackage{amsthm}
% \setenumerate[1]{itemsep=-0.05em,partopsep=-0.05em,parsep=0.40em,topsep=-0.05em}
% \setitemize[1]{itemsep=-0.05em,partopsep=-0.05em,parsep=0.40em,topsep=-0.05em}
% \setlist{nosep}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{tikz}
% \makeatletter
% \g@addto@macro\normalsize{%
	% \setlength\abovedisplayskip{4pt}
	% \setlength\belowdisplayskip{4pt}
	% \setlength\abovedisplayshortskip{0pt}
	% \setlength\belowdisplayshortskip{0pt}
	% }
% \makeatother

\usepackage{algorithm}
\usepackage[noend]{algorithmic}

\renewcommand{\algorithmiccomment}[1]{\blue{$\triangleright$ #1}}

\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\orange}[1]{\textcolor{orange}{#1}}

\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}
\def \S {\mathbf{S}}
\def \A {\mathbf{A}}
\def \X {\mathcal{X}}
\def \Ab {\bar{\A}}
\def \R {\mathbb{R}}
\def \Kt {\widetilde{K}}
\def \k {\mathbf{k}}
\def \W {\mathbf{W}}
\def \one {\mathbf{1}}
\def \ubf {\mathbf{u}}
\def \v {\mathbf{v}}
\def \vbf {\mathbf{v}}
\def \t {\mathbf{t}}
\def \x {\mathbf{x}}
\def \Se {\mathcal{S}}
\def \E {\mathbb{E}}
\def \Rh {\widehat{R}}
\def \p {\mathbf{p}}
\def \a {\mathbf{a}}
\def \diag {\mbox{diag}}
\def \dist {\mathrm{dist}}
\def \b {\mathbf{b}}
\def \e {\mathbf{e}}
\def \ba {\boldsymbol{\alpha}}
\def \c {\mathbf{c}}
\def \tr {\mbox{tr}}
\def \d {\mathbf{d}}
\def \dbf {\mathbf{d}}
\def \z {\mathbf{z}}
\def \s {\mathbf{s}}
\def \bh {\widehat{b}}
\def \y {\mathbf{y}}
\def \u {\mathbf{u}}
\def \M {\mathcal{M}}
\def \H {\mathcal{H}}
\def \Hbf {\mathbf{H}}
\def \g {\mathbf{g}}
\def \F {\mathcal{F}}
\def \I {\mathbb{I}}
\def \P {\mathcal{P}}
\def \Q {\mathcal{Q}}
\def \N {\mathcal{N}}
\def \V {\mathcal{V}}
\def \xh {\widehat{\x}}
\def \wh {\widehat{\w}}
\def \ah {\widehat{\alpha}}
\def \Rc {\mathcal R}
\def \Lh {\hat{L}}
\def \D {\mathcal{D}}
\def \Bh {\widehat B}
\def \B {\mathbf B}
\def \C {\mathcal{C}}
\def \U {\mathbf U}
\def \Kh {\widehat K}
\def \fh {\widehat f}
\def \yh {\widehat y}
\def \Xh {\widehat{X}}
\def \Fh {\widehat{F}}
\def \psih {\hat{\psi}}

\usepackage{hyperref}
% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
\hypersetup{colorlinks={true},linkcolor={blue},citecolor={blue}}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}
\title{Near-Optimal Online Learning for Multi-Agent Submodular Coordination: Tight Approximation and Communication Efficiency}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.
%\thanks{Corresponding Author}
\author{Qixin Zhang$^{1}$\quad Zongqi Wan$^{4}$\quad Yu Yang$^{2}$\quad Li Shen$^{3}$\quad Dacheng Tao$^{1}$\\
$^{1}$Nanyang Technological University\quad $^{2}$City University of Hong Kong\quad $^{3}$Sun Yat-sen University\\$^{4}$Institute of Computing Technology, Chinese Academy of Sciences\\
\texttt{qxzhang4-c@my.cityu.edu.hk};\quad \texttt{wanzongqi20s@ict.ac.cn};\quad\texttt{yuyang@cityu.edu.hk}\\\texttt{mathshenli@gmail.com};\quad \texttt{dacheng.tao@ntu.edu.sg}}


%\& Amelie P. Amygdale \thanks{ Use footnote for %providing further information
%about author (webpage, alternative address)---%\emph{not} for acknowledging
%funding agencies.  Funding acknowledgements go at the end of the paper.} \\Department of Computer Science\\
%Cranberry-Lemon University\\
%Pittsburgh, PA 15213, USA \\
%\texttt{\{hippo,brain,jen\}@cs.cranberry-lemon.edu} \\
%\And
%Ji Q. Ren \& Yevgeny LeNet \\
%Department of Computational Neuroscience \\
%University of the Witwatersrand \\
%Joburg, South Africa \\
%\texttt{\{robot,net\}@wits.ac.za} \\
%\AND
%Coauthor \\
%Affiliation \\
%Address \\
%\texttt{email}
%}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}
	\maketitle

\begin{abstract}
Coordinating multiple agents to collaboratively maximize submodular functions in unpredictable environments is a critical task with numerous applications in machine learning, robot planning and control. The existing approaches, such as the OSG algorithm,  are often hindered by their poor approximation guarantees and the rigid requirement for a fully connected communication graph. To address these challenges, we firstly present a $\textbf{MA-OSMA}$ algorithm, which employs the multi-linear extension to transfer the discrete submodular maximization problem into a continuous optimization, thereby allowing us to reduce the strict dependence on a complete graph through consensus techniques. Moreover, $\textbf{MA-OSMA}$ leverages a novel surrogate gradient to avoid sub-optimal stationary points. To eliminate the computationally intensive projection operations in $\textbf{MA-OSMA}$, we also introduce a projection-free $\textbf{MA-OSEA}$ algorithm, which effectively utilizes the KL divergence by mixing a uniform distribution. Theoretically, we confirm that both algorithms achieve a regret bound of $\widetilde{O}(\sqrt{\frac{C_{T}T}{1-\beta}})$ against aÂ  $(\frac{1-e^{-c}}{c})$-approximation to the best comparator in hindsight, where $C_{T}$ is the deviation of maximizer sequence, $\beta$ is the spectral gap of the network and $c$ is the joint curvature of submodular objectives. This result significantly improves the $(\frac{1}{1+c})$-approximation provided by the state-of-the-art OSG algorithm. Finally, we demonstrate the effectiveness of our proposed algorithms through simulation-based multi-target tracking.
\end{abstract}
%\doparttoc % Tell to minitoc to generate a toc for the parts
%\faketableofcontents % Run a fake tableofcontents command for the partocs
	\section{Introduction}
\input{ICLR/Introduction}
	\section{Preliminaries and Problem Formulation}
\input{ICLR/preliminaries}
\section{Multi-linear Extension and its Properties}\label{sec:multi-linear}
\input{ICLR/multi-linear_extension}
\section{Methodology}
The mirror method, a sophisticated optimization framework, utilizes the notion of Bregman divergence in lieu of  Euclidean distance for the projection step, thereby unifying a spectrum of first-order algorithms~\citep{nemirovsky1983problem}. In this section, we present two multi-agent variants of the online mirror ascent~\citep{hazan2016introduction,jadbabaie2015online,shahrampour2017distributed}, which is specifically crafted to tackle the MA-OSM problem introduced in Section~\ref{sec:Problem_Formulation}. 
\subsection{Multi-Agent Online Surrogate Mirror Ascent}
	\input{ICLR/MA-OSMA}
		\subsection{Projection-free Multi-Agent Online Surrogate Entropic Ascent}
  \input{ICLR/MA-OSEA}
  \section{Numerical Experiments}
\input{ICLR/Experiments}
\section{Conclusions and Future Work}
This paper presents two efficient algorithms for the multi-agent online submodular maximization problem. In sharp contrast with the previous OSG method, our proposed algorithms not only enjoy a tight $(\frac{1-e^{-c}}{c})$-approximation but also reduce the need for a complete communication graph. Finally, extensive empirical evaluations are performed to validate the effectiveness of our algorithms. 

In many real-world scenarios, the local information gathered by one agent is often contaminated with noise, thereby leading to imperfect assessments of the marginal gains of its own actions. To tackle this challenge, a compelling strategy is to extend our regret analysis to accommodate the estimation errors inherent in marginal evaluations, as exemplified by the work of \citet{corah2021scalable}. Furthermore, another innovative direction is to generalize Algorithms~\ref{alg:BDOMA} and \ref{alg:BDOEA} to adapt to time-varying and directed network topology~\citep{nedic2014distributed,nedic2017achieving}, as opposed to the static and undirected structure that is assumed. Lastly, the most promising direction is to design a parameter-free algorithm that eliminates the dependency on curvature of Algorithms~\ref{alg:BDOMA} and \ref{alg:BDOEA}.
\newpage
\bibliography{iclr2025_conference}\bibliographystyle{iclr2025_conference}
\newpage
\appendix
\input{ICLR/Appendix}
%You may include other additional sections here.


\end{document}
