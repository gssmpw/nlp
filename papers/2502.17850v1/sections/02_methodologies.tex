\section{Proposed Model and its Methodology}
\label{sec:methodologies}

\input{figures/block_diagram}

Figure \ref{fig:block diagram} shows the block diagram for the proposed model.  For this paper, the DRIVE Dataset has been used to test and create the outputs of the model. Three versions of the proposed model have been put to the test, each attempting to improve upon the former version in a multitude of ways. The versions are as follows:

\subsection{Fuzzy Contrast Enhancement (Version 1)}
\label{subsec:version_1}
The method for Fuzzy Contrast Enhancement is inspired by the fuzzy-based image enhancement method proposed by V\^{u}ong\ L\^e\ Minh\ Nguy\~en
\cite{FuzzyLogicImage}. The method is as follows:

\subsubsection{Import RGB Image and G-channel Extraction}
First, the image gets imported from the designated directory in an RGB format, and the G-channel of the image is extracted to reduce the size of the image.  OpenCV was used for implementing both functionalities.  Figure \ref{fig:RGB comparison} shows a comparison of the R, G, and B channels of the same image.

\input{figures/RGB_comparison}

\subsubsection{Conversion to Hue-Luminosity-Saturation (HLS) format and L-Channel Extraction}
he image is converted from RGB format into Hue-Luminosity-Saturation (HLS) color space format. The International Commission on Illumination $L^{*}a^{*}b^{*}$ color-space (CIELAB) format is more widely used in modifying the luminosity/lightness of the image due to its design putting the relative perceptual difference of the human eye into consideration. However, as only a single color channel is being used for this step, using the HLS format was more efficient, as both hue and saturation of HLS color space and $a^{*}$ and $b^{*}$ of CIELAB are static in the same color channel, and conversion from RGB to CIELAB costs more computational time in comparison to that of RGB to HLS.

\subsubsection{Fuzzy Transform of Luminosity in L Channel Image}
In this part, the luminosity ranging from 0 to 100 is fuzzified into five linguistic values (very dark, dark, medium, bright, and very bright) using the Gaussian membership function.  Figure 3 shows the graphic analysis of the membership functions in different mean luminosity.  The mathematical equations for the five linguistic memberships are as follows:

\begin{align}
    \mu_{\text{VeryDark}} =& G \left( x, \max(-20, M - 40), \frac{M}{2} \right) \notag \\
    \mu_{\text{Dark}} =& G \left( x, 0.45M, \frac{M}{4} \right) \notag \\
    \mu_{\text{Medium}} =& G \left( x, 1.1M, \frac{M}{6} \right) \notag \\
    \mu_{\text{Bright}} =& G \left( x, 2.5M - 25, \frac{100 - M}{4} \right) \notag \\
    \mu_{\text{VeryBright}} =& G \left( x, 125, \frac{100 - M}{4} \right) \notag \\
    \text{where} \quad & G(x, M, \sigma) = e^{-0.5 \left( \frac{x - M}{\sigma} \right)^2}
    \label{eq:contrast_enhancement}
\end{align}

Here, $x$ is the luminosity of the pixel, and $\sigma$ is the standard deviation of the luminosity of the entire image. $M$ is the variance-reduced mean luminosity of the whole image, and its value is calculated based on the mean luminosity of the image. Using the $M$ and $\sigma$ as input allows the membership function to generally shift around based on the overall brightness of the image itself, as the level of darkness of blood vessels compared to tissues is subjective. The Gaussian function was used as a membership function, and it is one of the most popular membership functions due to its conciseness and smoothness. The adaptive shift of the threshold via Eq. (\ref{eq:contrast_enhancement}) is visualized in Fig. \ref{fig:adaptive_thresholding}.

\input{figures/adaptive_thresholding}

Three fuzzy rules were used for this version as follows:
\begin{itemize}
    \item{IF input is Dark THEN output is Very Dark}
    \item{IF input is Medium THEN output is Medium}
    \item{IF input is Bright THEN output is Very Bright}
\end{itemize}

This process intensifies the contrast of the image, i.e., making the bright part brighter and the dark part darker.

\subsubsection{Normalization by Min-max scaling of new Luminosity}
Passing through such rules may result in luminosity values varying beyond their original range of 0 to 100 or luminosity values not varying enough. To remedy such issues, the luminosity is normalized so that the luminosity values range fully from 0 to 100 using the following equation:
\begin{equation}
    L_{\text{norm}} = \left( \frac{L - L_{\min}}{L_{\max} - L_{\min}} \right) \times 100
    \label{eq:lnorm}
\end{equation}

\subsubsection{Output and Its Limitations}
The final output image, produced after applying Fuzzy Contrast Enhancement (FCE), exhibits improved contrast, enhancing the visibility of the retinal blood vessels. However, this method alone presents some limitations in preserving finer vascular details in high-luminosity regions.

Figure \ref{fig:FCE_results} illustrates the original image compared to the enhanced output, highlighting both the improvements in vessel contrast and the areas where the method struggles to preserve fine details.

\input{figures/FCE_results}

\subsection{Post-processing}
\subsubsection{Linear blending (Version 2)}
\label{subsec:version_2}

The outputs of both methods, fuzzy and CLAHE, are linearly blended using the following equation:
\begin{equation}
    \text{output}_{\text{total}} = w_{1} \cdot \text{output}_{\text{fuzzy}} + w_{2} \cdot \text{output}_{\text{CLAHE}} - c
    \label{eq:output_total}
\end{equation}

where $w_{1}$, $w_{2}$ are the blending weights, and $c$ is a constant. In our implementation, we set $w_{1} = 0.6$, $w_{2} =  0.8$, and $c = -0.4$ based on empirical observations.

The selection of the weights and the constant was based on specific considerations. The weight of the CLAHE method is higher than that of the fuzzy method. The CLAHE method has, although not as crisp as FCE, shown better accuracy in increasing contrast between blood vessels and retinal tissues.  Ensuring accurate preprocessing of blood vessels is of paramount importance, as segmentation errors cannot be justified for marginal improvements in morphological representation. The constant was added not only to normalize the overall luminosity of the image but also to allow non-programmer personnel to edit the output luminosity with ease, as not all images share the same luminosity value.

\subsubsection{Hue adjustment for yellow output image (Version 3)}
\label{subsec:version_3}
The hue of the output of the image is finally modified so that the overall color of the image has a yellowish hue. This is because the yellowish hue performs the best in supporting doctors to better recognize distinctions within relatively low-contrast images \cite{oguraComparisonGrayscaleColorscale2017}.