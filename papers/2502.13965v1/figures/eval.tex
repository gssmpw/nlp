  % \begin{table}[]
  %   \begin{tabular}{|c|c|c|}
  %       \hline
  %       \textbf{Model} & \textbf{\# Model Weight}  & \textbf{GPUs} \\ 
  %       \hline
  %       LlaMA-3.1-8B-instruct & 16 GB & A100-80GB \\
  %       LlaMA-3.1-70B-Instruct & 140 GB & 4$\times$A100-80GB \\
  %       Falcon-180B & 360GB & 8$\times$A100-80GB \\
  %       \hline
  %   \end{tabular}
  %    \caption{Mode Size and Server Configuration}
  %    \label{tab:model_config}
  %    \end{table}

% \input{plots}
  % \begin{table}[]
  %   \begin{tabular}{|c|c|c|c|c|}
  %       \hline
  %       \textbf{Name} & \textbf{\# Scheduling Policy} & \textbf{Preempted Based} & \textbf{Chunk Prefill} & \textbf{Prefix Caching} \\ 
  %       \hline
  %       vLLM & FCFS & \xmark & \xmark & \xmark \\
  %       vLLM-Cache & FCFS & \xmark & \checkmark & \checkmark \\
  %       vLLM-MLFQ & MLFQ & \checkmark & \checkmark & \checkmark \\
  %       \hline
  %   \end{tabular}
  %    \caption{Baseline setting}
  %    \label{tab:baselne_config}
  %    \end{table}


% \begin{table}[ht!]
%     \centering
%     \resizebox{\columnwidth}{!}{ 
%         \begin{tabular}{|c|c|c|c|c|}
%             \hline
%             \textbf{Name} & \textbf{Scheduling Policy} & \textbf{Preempted Based} & \textbf{Chunk Prefill} & \textbf{Prefix Caching} \\ 
%             \hline
%             vLLM & FCFS & \xmark & \xmark & \xmark \\
%             vLLM-opt & FCFS & \xmark & \checkmark & \checkmark \\
%             vLLM-MLFQ & MLFQ & \checkmark & \checkmark & \checkmark \\
%             \hline
%         \end{tabular}
%     }
%     \caption{Baseline setting}
%     \label{tab:baselne_config}
% \end{table}




% \begin{figure*}[!htb]
%     \centering
%     \includegraphics[width=0.5\textwidth]{plots/2engine.pdf} 
%     \caption{Agent Normalized latency and p95, P99 of different load balance policy with Llama3.1-8B and Llama3.1-70B on two engine}  
%     \label{fig:two-engine}  
% \end{figure*}

% \begin{figure*}[!htb]
%     \centering
%     \begin{minipage}{\textwidth}
%         \centering
%         \includegraphics[width=0.8\textwidth]{plots/e2e_sharegpt_all_models.pdf}
%         \label{fig:sharegpt-1}
%     \end{minipage}\\[1ex]
%     \begin{minipage}{\textwidth}
%         \centering
%         \includegraphics[width=0.8\textwidth]{plots/e2e_lats_all_models.pdf}
%         \label{fig:sharegpt-2}
%     \end{minipage}\\[1ex]
%     \begin{minipage}{\textwidth}
%         \centering
%         \includegraphics[width=0.8\textwidth]{plots/e2e_bfcl_all_models.pdf}
%         \label{fig:sharegpt-3}
%     \end{minipage}
%     \caption{Agent Normalized latency of different serving systems with Llama and Falcon models on various workloads}  
%     \label{fig:e2e_workload}
% \end{figure*}



% \begin{figure*}[!htb]
%     \centering
%     \begin{subfigure}{0.33\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{plots/sharegpt_llama_8b.pdf}
%         \caption{Llama3.1-8B, 1GPU, ShareGPT}
%         \label{fig:llama3-8b-sharegpt}
%     \end{subfigure}\hfill
%     \begin{subfigure}{.33\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{plots/sharegpt_llama_70b.pdf}
%         \caption{Llama3.1-70B, 4GPU, ShareGPT}
%         \label{fig:llama3-70b-sharegpt}
%     \end{subfigure}\hfill
%     \begin{subfigure}{.33\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{plots/sharegpt_opt_175b.pdf}
%         \caption{Falcon-180B, 8GPU, ShareGPT}
%         \label{fig:falcon-180b-sharegpt}
%     \end{subfigure}
%     \vspace{-1mm}
%     \caption{Agent Normalized latency of different serving systems with Llama and Falcon models on ShareGPT}
%     \label{fig:sharegpt_comparison}
% \end{figure*}


% \begin{figure*}[!htb]
%     \centering
%     \begin{subfigure}{0.33\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{plots/sharegpt_llama_8b.pdf}
%         \caption{Llama3.1-8B, 1GPU, ShareGPT}
%         \label{fig:llama3-8b-sharegpt}
%     \end{subfigure}\hfill
%     \begin{subfigure}{.33\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{plots/sharegpt_llama_70b.pdf}
%         \caption{Llama3.1-70B, 4GPU, ShareGPT}
%         \label{fig:llama3-70b-sharegpt}
%     \end{subfigure}\hfill
%     \begin{subfigure}{.33\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{plots/sharegpt_opt_175b.pdf}
%         \caption{Falcon-180B, 8GPU, ShareGPT}
%         \label{fig:falcon-180b-sharegpt}
%     \end{subfigure}
%     \vspace{-1mm}
%     \caption{Agent Normalized latency of different serving systems with Llama and Falcon models on ShareGPT}
%     \label{fig:sharegpt_comparison}
% \end{figure*}



% \begin{figure*}[!htb]
% \begin{subfigure}{.33\textwidth}
%     \centering
%     % insert your first pdf
%     \includegraphics[width=0.67\textwidth]{plots/sharegpt_llama_8b.pdf}
%     \caption{Llama3.1-8B, 1GPU, ShareGPT}
%     \label{fig:llama3-8b-sharegpt}
% \end{subfigure}\hfill
% \vspace{-3mm}
% \begin{subfigure}{.33\textwidth}
%     \centering
%     % insert your second pdf
%     \includegraphics[width=0.67\textwidth]{plots/sharegpt_llama_70b.pdf}
%     \caption{Llama3.1-70B, 4GPU, ShareGPT}
%     \label{fig:llama3-70b-sharegpt}
% \end{subfigure}\hfill
% \begin{subfigure}{.33\textwidth}
%     \centering
%     % insert your third pdf
%     \includegraphics[width=\textwidth]{plots/sharegpt_opt_175b.pdf}
%     \caption{Falcon-180B, 8GPU, ShareGPT}
%     \label{fig:falcon-180b-sharegpt}
% \end{subfigure}
% \vspace{-5mm}
% \end{figure*}