\begin{algorithm}[!h]
   \caption{Viability Filter Online Training}
   \label{alg:online training}
\begin{algorithmic}
   \STATE Initialize success and failure buffer $D_s,D_f$ to capacity $N$, soft-update parameter $\tau$
   \STATE Initialize Viability Filter $\VF_{\theta}$ , target Viability Filter $\hat{\VF}_{\phi}$ and load Diffusion Planner $G_p$
   \STATE Initialize Humanoid Environment
   % \STATE Load Viability Function $V_\theta$ and target Viability Function $\hat{V}_\phi$ from offline checkpoints
   \FOR{$N_{E}$ episodes}
       \STATE Get planner initial conditioning signal $\rvc_0$ and $\VF$ state $s_{0}$ from environment
       \STATE Generate $N_s$ plans $P_0 \sim G_p(\rvc)$
   \FOR{each timestep $t$ in episode}
       \STATE With probability $\epsilon$, select a random plan $p_t$ where $p_t \in P_t$
       \STATE Otherwise, select $p_t = \arg\max_{p} VF_{\theta}(s_t, P_t)$
       \STATE Execute first target step from $p_t$ in the environment's control loop
       \IF{target step reached without early termination}
           \STATE assign success reward $r_s = 1$, and get $\rvc_{t+1}, s_{t+1}$
           \STATE sample new plans $P_{t+1} = G_p(\rvc_{t+1})$
           \STATE Store transition $(s_t, p_t, r_t, s_{t+1}, P_{t+1})$ in $D_s$
       \ELSIF{entered early termination}
           \STATE assign failure reward $r_f = 0$
           \STATE Store transition $(s_t, p_t, r_f, \emptyset, \emptyset)$ in $D_f$
           \STATE Terminate episode
       \ENDIF
   \ENDFOR
   \STATE Sample a random batch of transitions $(s_i, p_i, r_i, s_{i+1}, P_{i+1})$ equally from $D_s$ and $D_f$
   \STATE Set target $y_i = 
       \begin{cases} 
           r_i & \text{if $s_{i+1}$ is $\emptyset$} \\
           r_i + \gamma \max_{P_{i+1}} \hat{VF}_{\phi}(s_{i+1}, P_{i+1}) & \text{otherwise}
       \end{cases}$
   \STATE Perform a gradient descent step on $(y_i - VF_\theta(s_i, p_i))^2$ with respect to $\theta$
   \STATE Perform soft-update to target network $\phi \gets (1-\tau)\cdot\phi + \tau\cdot\theta$
   \ENDFOR
\end{algorithmic}
\end{algorithm}
