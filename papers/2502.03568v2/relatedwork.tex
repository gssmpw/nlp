\section{Related Work}
% \paragraph{Code generation and compositionality.}
LLMs to understand, generate, and improve code have been mainly developed to produce debugging information without invoking a compiler/interpreter~\cite{hou2023large,santos2023always,chen2021evaluating,widjojo2023addressing,zan2023large}.
Code generation and simulation require some degree of compositionality~\cite{mccoy2023much}, i.e., the result of complex expressions can be determined by their constituents and the rules used to combine them.
Recent works explored compositionality in terms of simple mathematical operations that LLMs can execute~\cite{frieder2023mathematical,yang2023code,yuan2023well}, and revealed how the most potent models do not achieve that~\cite{mccoy2023embers,west2023generative}.
Our work further explores the tension between memorisation and performance on complex tasks~\cite{berglund2023reversal,eldan2023s,yang2023code}, with results that illustrate how the former is at tension with the size of a model, the so-called ``inverse scaling law''~\cite{biderman2023emergent}.
% \paragraph{Code simulation.}

Before the breakthrough of closed-source LLMs~\cite{la2023arrt}, a seminal work tested LLMs on code simulation, showing how keeping track of the variables improves their capabilities~\cite{nye2021show}. Successive works explored LLMs and code simulation~\cite{chen2024language,tufano2023predicting,zhou2023algorithms}, particularly in~\cite{liu2023code}, where the authors fine-tune Transformer-based models to output the program trace of a code snippet. 
The code simulation capabilities of LLMs have been explored in several recent works: the first that identified the problem as relevant for LLMs is~\cite{la2024code}, of which this work is an extension. Other works successively extended this idea~\cite{lyu2024largelanguagemodelscode}.
Recent developments in this field go under the name of ``code reasoning'', as a model's ability to predict a variable's state at runtime~\cite{chen2024evaluating}, the output of a statement/function~\cite{gu2024cruxeval,liu2024codemind}, or their capability to handle recursion~\cite{zhang2024transformerbased}.
At the architectural level, several works studied Transformers and attention-based models regarding the operations and programming languages they interpret and execute~\cite{weiss2021thinking} and their recursive code simulation capabilities~\cite{zhang2023can}.
On a broader perspective, past work investigated the Turing-completeness of LLMs~\cite{giannou2023looped,perez2021attention,schuurmans2023memory,wei2022statistically}, and their ability to follow instructions~\cite{ouyang2022training} and policies expressed as code~\cite{liang2023code}.