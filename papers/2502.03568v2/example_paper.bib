@article{turpin2024language,
  title={Language models don't always say what they think: unfaithful explanations in chain-of-thought prompting},
  author={Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{liu2023code,
  title={Code Execution with Pre-trained Language Models},
  author={Liu, Chenxiao and Lu, Shuai and Chen, Weizhu and Jiang, Daxin and Svyatkovskiy, Alexey and Fu, Shengyu and Sundaresan, Neel and Duan, Nan},
  journal={arXiv preprint arXiv:2305.05383},
  year={2023}
}

@misc{gu2024cruxeval,
      title={CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution}, 
      author={Alex Gu and Baptiste Rozière and Hugh Leather and Armando Solar-Lezama and Gabriel Synnaeve and Sida I. Wang},
      year={2024},
      eprint={2401.03065},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@article{llama3modelcard,
  title={Llama 3 Model Card},
  author={AI@Meta},
  year={2024},
  url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}
}

@misc{wang2023selfconsistency,
      title={Self-Consistency Improves Chain of Thought Reasoning in Language Models}, 
      author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
      year={2023},
      eprint={2203.11171},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{chen2024language,
      title={Can Language Models Pretend Solvers? Logic Code Simulation with LLMs}, 
      author={Minyu Chen and Guoqiang Li and Ling-I Wu and Ruibang Liu and Yuxin Su and Xi Chang and Jianxin Xue},
      year={2024},
      eprint={2403.16097},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{liu2024codemind,
      title={CodeMind: A Framework to Challenge Large Language Models for Code Reasoning}, 
      author={Changshu Liu and Shizhuo Dylan Zhang and Ali Reza Ibrahimzada and Reyhaneh Jabbarvand},
      year={2024},
      eprint={2402.09664},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{chen2024evaluating,
      title={Evaluating Large Language Models with Runtime Behavior of Program Execution}, 
      author={Junkai Chen and Zhiyuan Pan and Xing Hu and Zhenhao Li and Ge Li and Xin Xia},
      year={2024},
      eprint={2403.16437},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{zhang2024transformerbased,
      title={Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion}, 
      author={Dylan Zhang and Curt Tigges and Zory Zhang and Stella Biderman and Maxim Raginsky and Talia Ringer},
      year={2024},
      eprint={2401.12947},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{mueller-linzen-2023-plant,
    title = "How to Plant Trees in Language Models: Data and Architectural Effects on the Emergence of Syntactic Inductive Biases",
    author = "Mueller, Aaron  and
      Linzen, Tal",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.629",
    pages = "11237--11252",
    abstract = "Accurate syntactic representations are essential for robust generalization in natural language. Recent work has found that pre-training can teach language models to rely on hierarchical syntactic features{---}as opposed to incorrect linear features{---}when performing tasks after fine-tuning. We test what aspects of pre-training are important for endowing encoder-decoder Transformers with an inductive bias that favors hierarchical syntactic generalizations. We focus on architectural features (depth, width, and number of parameters), as well as the genre and size of the pre-training corpus, diagnosing inductive biases using two syntactic transformation tasks: question formation and passivization, both in English. We find that the number of parameters alone does not explain hierarchical generalization: model depth plays greater role than model width. We also find that pre-training on simpler language, such as child-directed speech, induces a hierarchical bias using an order-of-magnitude less data than pre-training on more typical datasets based on web text or Wikipedia; this suggests that in cognitively plausible language acquisition settings, neural language models may be more data-efficient than previously thought.",
}

@article{dziri2023faith,
  title={Faith and Fate: Limits of Transformers on Compositionality},
  author={Dziri, Nouha and Lu, Ximing and Sclar, Melanie and Li, Xiang Lorraine and Jian, Liwei and Lin, Bill Yuchen and West, Peter and Bhagavatula, Chandra and Bras, Ronan Le and Hwang, Jena D and others},
  journal={arXiv preprint arXiv:2305.18654},
  year={2023}
}

@article{giannou2023looped,
  title={Looped transformers as programmable computers},
  author={Giannou, Angeliki and Rajput, Shashank and Sohn, Jy-yong and Lee, Kangwook and Lee, Jason D and Papailiopoulos, Dimitris},
  journal={arXiv preprint arXiv:2301.13196},
  year={2023}
}

@article{olsson2022context,
   title={In-context Learning and Induction Heads},
   author={Olsson, Catherine and Elhage, Nelson and Nanda, Neel and others},
   year={2022},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html}
}

@article{tufano2023predicting,
  title={Predicting Code Coverage without Execution},
  author={Tufano, Michele and Chandel, Shubham and Agarwal, Anisha and Sundaresan, Neel and Clement, Colin},
  journal={arXiv preprint arXiv:2307.13383},
  year={2023}
}

@misc{webb2023emergent,
      title={Emergent Analogical Reasoning in Large Language Models}, 
      author={Taylor Webb and Keith J. Holyoak and Hongjing Lu},
      year={2023},
      eprint={2212.09196},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@InProceedings{pmlr-v80-rabinowitz18a,
  title = 	 {Machine Theory of Mind},
  author =       {Rabinowitz, Neil and Perbet, Frank and Song, Francis and Zhang, Chiyuan and Eslami, S. M. Ali and Botvinick, Matthew},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {4218--4227},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/rabinowitz18a/rabinowitz18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/rabinowitz18a.html},
  abstract = 	 {Theory of mind (ToM) broadly refers to humans’ ability to represent the mental states of others, including their desires, beliefs, and intentions. We design a Theory of Mind neural network {–} a ToMnet {–} which uses meta-learning to build such models of the agents it encounters. The ToMnet learns a strong prior model for agents’ future behaviour, and, using only a small number of behavioural observations, can bootstrap to richer predictions about agents’ characteristics and mental states. We apply the ToMnet to agents behaving in simple gridworld environments, showing that it learns to model random, algorithmic, and deep RL agents from varied populations, and that it passes classic ToM tasks such as the "Sally-Anne" test of recognising that others can hold false beliefs about the world.}
}


@misc{lin2024graphenhanced,
      title={Graph-enhanced Large Language Models in Asynchronous Plan Reasoning}, 
      author={Fangru Lin and Emanuele La Malfa and Valentin Hofmann and Elle Michelle Yang and Anthony Cohn and Janet B. Pierrehumbert},
      year={2024},
      eprint={2402.02805},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{schuurmans2023memory,
  title={Memory augmented large language models are computationally universal},
  author={Schuurmans, Dale},
  journal={arXiv preprint arXiv:2301.04589},
  year={2023}
}

@article{biderman2023emergent,
  title={Emergent and predictable memorization in large language models},
  author={Biderman, Stella and Prashanth, USVSN Sai and Sutawika, Lintang and Schoelkopf, Hailey and Anthony, Quentin and Purohit, Shivanshu and Raf, Edward},
  journal={arXiv preprint arXiv:2304.11158},
  year={2023}
}

@inproceedings{la2022king,
	title        = {The King Is Naked: {On} the Notion of Robustness for Natural Language Processing},
	author       = {Emanuele La Malfa and Marta Kwiatkowska},
	year         = 2022,
	booktitle    = {Thirty-Sixth {AAAI} Conference on Artificial Intelligence, {AAAI} 2022, Thirty-Fourth Conference on Innovative Applications of Artificial Intelligence, {IAAI} 2022, The Twelveth Symposium on Educational Advances in Artificial Intelligence, {EAAI} 2022 Virtual Event, February 22 - March 1, 2022},
	publisher    = {{AAAI} Press},
	pages        = {11047--11057},
	url          = {https://ojs.aaai.org/index.php/AAAI/article/view/21353},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/aaai/MalfaK22.bib},
	timestamp    = {Tue, 12 Jul 2022 01:00:00 +0200}
}
@inproceedings{barnes-etal-2019-sentiment,
	title        = {Sentiment Analysis Is Not Solved! {A}ssessing and Probing Sentiment Classification},
	author       = {Barnes, Jeremy  and {\O}vrelid, Lilja  and Velldal, Erik},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {12--23},
	doi          = {10.18653/v1/W19-4802},
	url          = {https://aclanthology.org/W19-4802}
}
@article{frieder2023mathematical,
	title        = {Mathematical Capabilities of {ChatGPT}},
	author       = {Frieder, Simon and Pinchetti, Luca and Chevalier, Alexis and Griffiths, Ryan-Rhys and Salvatori, Tommaso and Lukasiewicz, Thomas and Petersen, Philipp Christian and Berner, Julius},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2301.13867},
	url          = {https://arxiv.org/abs/2301.13867}
}
@article{harris1954distributional,
	title        = {Distributional structure},
	author       = {Harris, Zellig S},
	year         = 1954,
	journal      = {Word},
	publisher    = {Taylor \& Francis},
	volume       = 10,
	number       = {2-3},
	pages        = {146--162}
}
@inproceedings{mikolov2013distributed,
	title        = {Distributed Representations of Words and Phrases and their Compositionality},
	author       = {Tom{\'{a}}s Mikolov and Ilya Sutskever and Kai Chen and Gregory S. Corrado and Jeffrey Dean},
	year         = 2013,
	booktitle    = {Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States},
	pages        = {3111--3119},
	url          = {https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/nips/MikolovSCCD13.bib},
	editor       = {Christopher J. C. Burges and L{\'{e}}on Bottou and Zoubin Ghahramani and Kilian Q. Weinberger},
	timestamp    = {Thu, 21 Jan 2021 00:00:00 +0100}
}
@inproceedings{sinha2021masked,
	title        = {Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little},
	author       = {Sinha, Koustuv  and Jia, Robin  and Hupkes, Dieuwke  and Pineau, Noëlle and Williams, Adina  and Kiela, Douwe},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Online and Punta Cana, Dominican Republic},
	pages        = {2888--2913},
	doi          = {10.18653/v1/2021.emnlp-main.230},
	url          = {https://aclanthology.org/2021.emnlp-main.230}
}
@inproceedings{hermann2013not,
	title        = {{``}Not not bad{''} is not {``}bad{''}: A distributional account of negation},
	author       = {Hermann, Karl Moritz  and Grefenstette, Edward  and Blunsom, Phil},
	year         = 2013,
	booktitle    = {Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality},
	publisher    = {Association for Computational Linguistics},
	address      = {Sofia, Bulgaria},
	pages        = {74--82},
	url          = {https://aclanthology.org/W13-3209}
}
@inproceedings{zhang2020semantics,
	title        = {Semantics-Aware {BERT} for Language Understanding},
	author       = {Zhuosheng Zhang and Yuwei Wu and Hai Zhao and Zuchao Li and Shuailiang Zhang and Xi Zhou and Xiang Zhou},
	year         = 2020,
	booktitle    = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI} 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA, February 7-12, 2020},
	publisher    = {{AAAI} Press},
	pages        = {9628--9635},
	url          = {https://aaai.org/ojs/index.php/AAAI/article/view/6510},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/aaai/0001WZLZZZ20.bib},
	timestamp    = {Fri, 04 Sep 2020 01:00:00 +0200}
}
@inproceedings{bender2020climbing,
	title        = {Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data},
	author       = {Bender, Emily M.  and Koller, Alexander},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {5185--5198},
	doi          = {10.18653/v1/2020.acl-main.463},
	url          = {https://aclanthology.org/2020.acl-main.463}
}
@inproceedings{szegedy2013intriguing,
	title        = {Intriguing properties of neural networks},
	author       = {Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian J. Goodfellow and Rob Fergus},
	year         = 2014,
	booktitle    = {2nd International Conference on Learning Representations, {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
	url          = {http://arxiv.org/abs/1312.6199},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/journals/corr/SzegedyZSBEGF13.bib},
	editor       = {Yoshua Bengio and Yann LeCun},
	timestamp    = {Thu, 25 Jul 2019 01:00:00 +0200}
}
@inproceedings{le2020adversarial,
	title        = {Adversarial Filters of Dataset Biases},
	author       = {Ronan Le Bras and Swabha Swayamdipta and Chandra Bhagavatula and Rowan Zellers and Matthew E. Peters and Ashish Sabharwal and Yejin Choi},
	year         = 2020,
	booktitle    = {Proceedings of the 37th International Conference on Machine Learning, {ICML} 2020, 13-18 July 2020, Virtual Event},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research},
	volume       = 119,
	pages        = {1078--1088},
	url          = {http://proceedings.mlr.press/v119/bras20a.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/icml/BrasSBZPSC20.bib},
	timestamp    = {Tue, 15 Dec 2020 00:00:00 +0100}
}
@inproceedings{niven2019probing,
	title        = {Probing Neural Network Comprehension of Natural Language Arguments},
	author       = {Niven, Timothy  and Kao, Hung-Yu},
	year         = 2019,
	booktitle    = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {4658--4664},
	doi          = {10.18653/v1/P19-1459},
	url          = {https://aclanthology.org/P19-1459}
}
@inproceedings{bender2021dangers,
	title        = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
	author       = {Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	pages        = {610--623}
}

@inproceedings{wang2019bert,
	title        = {{BERT} has a Mouth, and It Must Speak: {BERT} as a {M}arkov Random Field Language Model},
	author       = {Wang, Alex  and Cho, Kyunghyun},
	year         = 2019,
	booktitle    = {Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {30--36},
	doi          = {10.18653/v1/W19-2304},
	url          = {https://aclanthology.org/W19-2304}
}
@inproceedings{goyal2021exposing,
	title        = {Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings},
	author       = {Kartik Goyal and Chris Dyer and Taylor Berg{-}Kirkpatrick},
	year         = 2022,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=6PvWo1kEvlT},
	biburl       = {https://dblp.org/rec/conf/iclr/GoyalDB22.bib},
	timestamp    = {Sat, 20 Aug 2022 01:00:00 +0200}
}
@inproceedings{coenen2019visualizing,
	title        = {Visualizing and Measuring the Geometry of {BERT}},
	author       = {Emily Reif and Ann Yuan and Martin Wattenberg and Fernanda B. Vi{\'{e}}gas and Andy Coenen and Adam Pearce and Been Kim},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada},
	pages        = {8592--8600},
	url          = {https://proceedings.neurips.cc/paper/2019/hash/159c1ffe5b61b41b3c4d8f4c2150f6c4-Abstract.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/nips/ReifYWVCPK19.bib},
	editor       = {Hanna M. Wallach and Hugo Larochelle and Alina Beygelzimer and Florence d'Alch{\'{e}}{-}Buc and Emily B. Fox and Roman Garnett},
	timestamp    = {Thu, 21 Jan 2021 00:00:00 +0100}
}
@inproceedings{jawahar2019does,
	title        = {What Does {BERT} Learn about the Structure of Language?},
	author       = {Jawahar, Ganesh  and Sagot, Beno{\^\i}t  and Seddah, Djam{\'e}},
	year         = 2019,
	booktitle    = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {3651--3657},
	doi          = {10.18653/v1/P19-1356},
	url          = {https://aclanthology.org/P19-1356}
}
@article{manning2020emergent,
	title        = {Emergent linguistic structure in artificial neural networks trained by self-supervision},
	author       = {Manning, Christopher D and Clark, Kevin and Hewitt, John and Khandelwal, Urvashi and Levy, Omer},
	year         = 2020,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = 117,
	number       = 48,
	pages        = {30046--30054}
}
@inproceedings{marvin2018targeted,
	title        = {Refining Targeted Syntactic Evaluation of Language Models},
	author       = {Newman, Benjamin  and Ang, Kai-Siang  and Gong, Julia  and Hewitt, John},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {3710--3723},
	doi          = {10.18653/v1/2021.naacl-main.290},
	url          = {https://aclanthology.org/2021.naacl-main.290}
}
@inproceedings{mohebbi2021exploring,
	title        = {Exploring the Role of {BERT} Token Representations to Explain Sentence Probing Results},
	author       = {Mohebbi, Hosein  and Modarressi, Ali  and Pilehvar, Mohammad Taher},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Online and Punta Cana, Dominican Republic},
	pages        = {792--806},
	doi          = {10.18653/v1/2021.emnlp-main.61},
	url          = {https://aclanthology.org/2021.emnlp-main.61}
}
@book{chomsky2009syntactic,
	title        = {Syntactic structures},
	author       = {Chomsky, Noam},
	year         = 2009,
	publisher    = {De Gruyter Mouton}
}
@article{ettinger2020bert,
	title        = {What {BERT} Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models},
	author       = {Ettinger, Allyson},
	year         = 2020,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	address      = {Cambridge, MA},
	volume       = 8,
	pages        = {34--48},
	doi          = {10.1162/tacl_a_00298},
	url          = {https://aclanthology.org/2020.tacl-1.3}
}
@inproceedings{bolukbasi2016man,
	title        = {Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings},
	author       = {Tolga Bolukbasi and Kai{-}Wei Chang and James Y. Zou and Venkatesh Saligrama and Adam Tauman Kalai},
	year         = 2016,
	booktitle    = {Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain},
	pages        = {4349--4357},
	url          = {https://proceedings.neurips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/nips/BolukbasiCZSK16.bib},
	editor       = {Daniel D. Lee and Masashi Sugiyama and Ulrike von Luxburg and Isabelle Guyon and Roman Garnett},
	timestamp    = {Thu, 21 Jan 2021 00:00:00 +0100}
}
@inproceedings{gonen2019lipstick,
	title        = {Lipstick on a Pig: {D}ebiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them},
	author       = {Gonen, Hila  and Goldberg, Yoav},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {609--614},
	doi          = {10.18653/v1/N19-1061},
	url          = {https://aclanthology.org/N19-1061}
}
@inproceedings{liang2020towards,
	title        = {Towards Debiasing Sentence Representations},
	author       = {Liang, Paul Pu  and Li, Irene Mengze  and Zheng, Emily  and Lim, Yao Chong  and Salakhutdinov, Ruslan  and Morency, Louis-Philippe},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {5502--5515},
	doi          = {10.18653/v1/2020.acl-main.488},
	url          = {https://aclanthology.org/2020.acl-main.488}
}
@inproceedings{kim2020pre,
	title        = {Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction},
	author       = {Taeuk Kim and Jihun Choi and Daniel Edmiston and Sang{-}goo Lee},
	year         = 2020,
	booktitle    = {International Conference on Learning Representations,},
	url          = {https://openreview.net/forum?id=H1xPR3NtPB},
}
@inproceedings{dunn2021learned,
	title        = {Learned Construction Grammars Converge Across Registers Given Increased Exposure},
	author       = {Dunn, Jonathan  and Tayyar Madabushi, Harish},
	year         = 2021,
	booktitle    = {Proceedings of the 25th Conference on Computational Natural Language Learning},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {268--278},
	doi          = {10.18653/v1/2021.conll-1.21},
	url          = {https://aclanthology.org/2021.conll-1.21}
}
@inproceedings{marevcek2019balustrades,
	title        = {From Balustrades to Pierre Vinken: Looking for Syntax in Transformer Self-Attentions},
	author       = {Mare{\v{c}}ek, David  and Rosa, Rudolf},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {263--275},
	doi          = {10.18653/v1/W19-4827},
	url          = {https://aclanthology.org/W19-4827}
}
@inproceedings{shen2018straight,
	title        = {Straight to the Tree: Constituency Parsing with Neural Syntactic Distance},
	author       = {Shen, Yikang  and Lin, Zhouhan  and Jacob, Athul Paul  and Sordoni, Alessandro  and Courville, Aaron  and Bengio, Yoshua},
	year         = 2018,
	booktitle    = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Melbourne, Australia},
	pages        = {1171--1180},
	doi          = {10.18653/v1/P18-1108},
	url          = {https://aclanthology.org/P18-1108}
}
@article{dunn2017computational,
	title        = {Computational learning of construction grammars},
	author       = {Dunn, Jonathan},
	year         = 2017,
	journal      = {Language and cognition},
	publisher    = {Cambridge University Press},
	volume       = 9,
	number       = 2,
	pages        = {254--292}
}
@inproceedings{hessel2021effective,
	title        = {How effective is {BERT} without word ordering? Implications for language understanding and data privacy},
	author       = {Hessel, Jack  and Schofield, Alexandra},
	year         = 2021,
	booktitle    = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {204--211},
	doi          = {10.18653/v1/2021.acl-short.27},
	url          = {https://aclanthology.org/2021.acl-short.27}
}
@book{chomsky2006language,
	title        = {Language and mind},
	author       = {Chomsky, Noam and others},
	year         = 2006,
	publisher    = {Cambridge University Press}
}
@inproceedings{gao2019representation,
	title        = {Representation Degeneration Problem in Training Natural Language Generation Models},
	author       = {Jun Gao and Di He and Xu Tan and Tao Qin and Liwei Wang and Tie{-}Yan Liu},
	year         = 2019,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=SkEYojRqtm},
}
@inproceedings{li2020sentence,
	title        = {On the Sentence Embeddings from Pre-trained Language Models},
	author       = {Li, Bohan  and Zhou, Hao  and He, Junxian  and Wang, Mingxuan  and Yang, Yiming  and Li, Lei},
	year         = 2020,
	booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {9119--9130},
	doi          = {10.18653/v1/2020.emnlp-main.733},
	url          = {https://aclanthology.org/2020.emnlp-main.733}
}
@inproceedings{ganitkevitch2013ppdb,
	title        = {{PPDB}: The Paraphrase Database},
	author       = {Ganitkevitch, Juri  and Van Durme, Benjamin  and Callison-Burch, Chris},
	year         = 2013,
	booktitle    = {Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Atlanta, Georgia},
	pages        = {758--764},
	url          = {https://aclanthology.org/N13-1092}
}
@inproceedings{devlin2018bert,
	title        = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	author       = {Devlin, Jacob  and Chang, Ming-Wei  and Lee, Kenton  and Toutanova, Kristina},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {4171--4186},
	doi          = {10.18653/v1/N19-1423},
	url          = {https://aclanthology.org/N19-1423}
}
@inproceedings{reimers2019sentence,
	title        = {Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks},
	author       = {Reimers, Nils  and Gurevych, Iryna},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Hong Kong, China},
	pages        = {3982--3992},
	doi          = {10.18653/v1/D19-1410},
	url          = {https://aclanthology.org/D19-1410}
}
@inproceedings{ravfogel2020null,
	title        = {Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection},
	author       = {Ravfogel, Shauli  and Elazar, Yanai  and Gonen, Hila  and Twiton, Michael  and Goldberg, Yoav},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {7237--7256},
	doi          = {10.18653/v1/2020.acl-main.647},
	url          = {https://aclanthology.org/2020.acl-main.647}
}
@article{nye2021show,
  title={Show your work: Scratchpads for intermediate computation with language models},
  author={Nye, Maxwell and Andreassen, Anders Johan and Gur-Ari, Guy and Michalewski, Henryk and Austin, Jacob and Bieber, David and Dohan, David and Lewkowycz, Aitor and Bosma, Maarten and Luan, David and others},
  journal={arXiv preprint arXiv:2112.00114},
  year={2021}
}
@inproceedings{hajic2009conll,
	title        = {The {C}o{NLL}-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages},
	author       = {Haji{\v{c}}, Jan  and Ciaramita, Massimiliano  and Johansson, Richard  and Kawahara, Daisuke  and Mart{\'\i}, Maria Ant{\`o}nia  and M{\`a}rquez, Llu{\'\i}s  and Meyers, Adam  and Nivre, Joakim  and Pad{\'o}, Sebastian  and {\v{S}}t{\v{e}}p{\'a}nek, Jan  and Stra{\v{n}}{\'a}k, Pavel  and Surdeanu, Mihai  and Xue, Nianwen  and Zhang, Yi},
	year         = 2009,
	booktitle    = {Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL} 2009): Shared Task},
	publisher    = {Association for Computational Linguistics},
	address      = {Boulder, Colorado},
	pages        = {1--18},
	url          = {https://aclanthology.org/W09-1201}
}
@inproceedings{wang2020infobert,
	title        = {InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective},
	author       = {Boxin Wang and Shuohang Wang and Yu Cheng and Zhe Gan and Ruoxi Jia and Bo Li and Jingjing Liu},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=hpH98mK5Puk},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/iclr/WangWCGJLL21.bib},
	timestamp    = {Thu, 12 Aug 2021 01:00:00 +0200}
}
@inproceedings{merchant2020happens,
	title        = {What Happens To {BERT} Embeddings During Fine-tuning?},
	author       = {Merchant, Amil  and Rahimtoroghi, Elahe  and Pavlick, Ellie  and Tenney, Ian},
	year         = 2020,
	booktitle    = {Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {33--44},
	doi          = {10.18653/v1/2020.blackboxnlp-1.4},
	url          = {https://aclanthology.org/2020.blackboxnlp-1.4}
}
@inproceedings{baroni2014don,
	title        = {Don{'}t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors},
	author       = {Baroni, Marco  and Dinu, Georgiana  and Kruszewski, Germ{\'a}n},
	year         = 2014,
	booktitle    = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Baltimore, Maryland},
	pages        = {238--247},
	doi          = {10.3115/v1/P14-1023},
	url          = {https://aclanthology.org/P14-1023}
}
@inproceedings{wallace2019universal,
	title        = {Universal Adversarial Triggers for Attacking and Analyzing {NLP}},
	author       = {Wallace, Eric  and Feng, Shi  and Kandpal, Nikhil  and Gardner, Matt  and Singh, Sameer},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Hong Kong, China},
	pages        = {2153--2162},
	doi          = {10.18653/v1/D19-1221},
	url          = {https://aclanthology.org/D19-1221}
}
@inproceedings{pennington2014glove,
	title        = {{G}lo{V}e: Global Vectors for Word Representation},
	author       = {Pennington, Jeffrey  and Socher, Richard  and Manning, Christopher},
	year         = 2014,
	booktitle    = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
	publisher    = {Association for Computational Linguistics},
	address      = {Doha, Qatar},
	pages        = {1532--1543},
	doi          = {10.3115/v1/D14-1162},
	url          = {https://aclanthology.org/D14-1162}
}
@article{goldberg2019assessing,
	title        = {Assessing BERT's syntactic abilities},
	author       = {Goldberg, Yoav},
	year         = 2019,
	journal      = {ArXiv preprint},
	volume       = {abs/1901.05287},
	url          = {https://arxiv.org/abs/1901.05287}
}
@inproceedings{conneau2018you,
	title        = {What you can cram into a single {\textbackslash}{\textdollar}{\&}!{\#}* vector: Probing sentence embeddings for linguistic properties},
	author       = {Alexis Conneau and Germ{\'{a}}n Kruszewski and Guillaume Lample and Lo{\"{\i}}c Barrault and Marco Baroni},
	year         = 2018,
	booktitle    = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, {ACL} 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers},
	publisher    = {Association for Computational Linguistics},
	pages        = {2126--2136},
	doi          = {10.18653/v1/P18-1198},
	url          = {https://aclanthology.org/P18-1198/},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/acl/BaroniBLKC18.bib},
	editor       = {Iryna Gurevych and Yusuke Miyao},
	timestamp    = {Fri, 06 Aug 2021 00:40:55 +0200}
}
@inproceedings{limisiewicz2020syntax,
	title        = {Syntax Representation in Word Embeddings and Neural Networks - {A} Survey},
	author       = {Tomasz Limisiewicz and David Marecek},
	year         = 2020,
	booktitle    = {Proceedings of the 20th Conference Information Technologies - Applications and Theory {(ITAT} 2020), Hotel Tyrapol, Oravsk{\'{a}} Lesn{\'{a}}, Slovakia, September 18-22, 2020},
	publisher    = {CEUR-WS.org},
	series       = {{CEUR} Workshop Proceedings},
	volume       = 2718,
	pages        = {40--50},
	url          = {http://ceur-ws.org/Vol-2718/paper16.pdf},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/itat/LimisiewiczM20.bib},
	editor       = {Martin Holena and Tom{\'{a}}s Horv{\'{a}}th and Alica Kelemenov{\'{a}} and Frantisek Mr{\'{a}}z and Dana Pardubsk{\'{a}} and Martin Pl{\'{a}}tek and Petr Sos{\'{\i}}k},
	timestamp    = {Wed, 11 Nov 2020 16:38:41 +0100}
}
@inproceedings{alzantot2018generating,
	title        = {Generating Natural Language Adversarial Examples},
	author       = {Alzantot, Moustafa  and Sharma, Yash  and Elgohary, Ahmed  and Ho, Bo-Jhang  and Srivastava, Mani  and Chang, Kai-Wei},
	year         = 2018,
	booktitle    = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Brussels, Belgium},
	pages        = {2890--2896},
	doi          = {10.18653/v1/D18-1316},
	url          = {https://aclanthology.org/D18-1316}
}
@inproceedings{jia2019certified,
	title        = {Certified Robustness to Adversarial Word Substitutions},
	author       = {Jia, Robin  and Raghunathan, Aditi  and G{\"o}ksel, Kerem  and Liang, Percy},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Hong Kong, China},
	pages        = {4129--4142},
	doi          = {10.18653/v1/D19-1423},
	url          = {https://aclanthology.org/D19-1423}
}
@book{manning1999foundations,
	title        = {Foundations of statistical natural language processing},
	author       = {Manning, Christopher and Schutze, Hinrich},
	year         = 1999,
	publisher    = {MIT press}
}
@inproceedings{huang2019achieving,
	title        = {Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propagation},
	author       = {Huang, Po-Sen  and Stanforth, Robert  and Welbl, Johannes  and Dyer, Chris  and Yogatama, Dani  and Gowal, Sven  and Dvijotham, Krishnamurthy  and Kohli, Pushmeet},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Hong Kong, China},
	pages        = {4083--4093},
	doi          = {10.18653/v1/D19-1419},
	url          = {https://aclanthology.org/D19-1419}
}
@inproceedings{peters-etal-2018-deep,
	title        = {Deep Contextualized Word Representations},
	author       = {Peters, Matthew E.  and Neumann, Mark  and Iyyer, Mohit  and Gardner, Matt  and Clark, Christopher  and Lee, Kenton  and Zettlemoyer, Luke},
	year         = 2018,
	booktitle    = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {New Orleans, Louisiana},
	pages        = {2227--2237},
	doi          = {10.18653/v1/N18-1202},
	url          = {https://aclanthology.org/N18-1202}
}
@inproceedings{hewitt2019structural,
	title        = {{A} Structural Probe for Finding Syntax in Word Representations},
	author       = {Hewitt, John  and Manning, Christopher D.},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {4129--4138},
	doi          = {10.18653/v1/N19-1419},
	url          = {https://aclanthology.org/N19-1419}
}
@article{liu2019roberta,
	title        = {Roberta: A robustly optimized bert pretraining approach},
	author       = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	year         = 2019,
	journal      = {ArXiv preprint},
	volume       = {abs/1907.11692},
	url          = {https://arxiv.org/abs/1907.11692}
}
@article{liu2020very,
	title        = {Very deep transformers for neural machine translation},
	author       = {Liu, Xiaodong and Duh, Kevin and Liu, Liyuan and Gao, Jianfeng},
	year         = 2020,
	journal      = {ArXiv preprint},
	volume       = {abs/2008.07772},
	url          = {https://arxiv.org/abs/2008.07772}
}
@inproceedings{wang2021dcn,
	title        = {DCN V2: Improved Deep \& Cross Network and Practical Lessons for Web-scale Learning to Rank Systems},
	author       = {Wang, Ruoxi and Shivanna, Rakesh and Cheng, Derek and Jain, Sagar and Lin, Dong and Hong, Lichan and Chi, Ed},
	year         = 2021,
	booktitle    = {Proceedings of the Web Conference 2021},
	pages        = {1785--1797}
}
@article{rubenstein1965contextual,
	title        = {Contextual correlates of synonymy},
	author       = {Rubenstein, Herbert and Goodenough, John B},
	year         = 1965,
	journal      = {Communications of the ACM},
	publisher    = {ACM New York, NY, USA},
	volume       = 8,
	number       = 10,
	pages        = {627--633}
}
@inproceedings{nivre2016universal,
	title        = {{U}niversal {D}ependencies v1: A Multilingual Treebank Collection},
	author       = {Nivre, Joakim  and de Marneffe, Marie-Catherine  and Ginter, Filip  and Goldberg, Yoav  and Haji{\v{c}}, Jan  and Manning, Christopher D.  and McDonald, Ryan  and Petrov, Slav  and Pyysalo, Sampo  and Silveira, Natalia  and Tsarfaty, Reut  and Zeman, Daniel},
	year         = 2016,
	booktitle    = {Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)},
	publisher    = {European Language Resources Association (ELRA)},
	address      = {Portoro{\v{z}}, Slovenia},
	pages        = {1659--1666},
	url          = {https://aclanthology.org/L16-1262}
}
@inproceedings{mrkvsic2016counter,
	title        = {Counter-fitting Word Vectors to Linguistic Constraints},
	author       = {Mrk{\v{s}}i{\'c}, Nikola  and {\'O} S{\'e}aghdha, Diarmuid  and Thomson, Blaise  and Ga{\v{s}}i{\'c}, Milica  and Rojas-Barahona, Lina M.  and Su, Pei-Hao  and Vandyke, David  and Wen, Tsung-Hsien  and Young, Steve},
	year         = 2016,
	booktitle    = {Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {San Diego, California},
	pages        = {142--148},
	doi          = {10.18653/v1/N16-1018},
	url          = {https://aclanthology.org/N16-1018}
}
@inproceedings{socher2013recursive,
	title        = {Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank},
	author       = {Socher, Richard  and Perelygin, Alex  and Wu, Jean  and Chuang, Jason  and Manning, Christopher D.  and Ng, Andrew  and Potts, Christopher},
	year         = 2013,
	booktitle    = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Seattle, Washington, USA},
	pages        = {1631--1642},
	url          = {https://aclanthology.org/D13-1170}
}
@article{kuleshov2018adversarial,
	title        = {Adversarial examples for natural language classification problems},
	author       = {Kuleshov, Volodymyr and Thakoor, Shantanu and Lau, Tingfung and Ermon, Stefano},
	year         = 2018,
	journal      = {arxiv pre-print}
}
@article{gibson2019efficiency,
	title        = {How efficiency shapes human language},
	author       = {Gibson, Edward and Futrell, Richard and Piantadosi, Steven P and Dautriche, Isabelle and Mahowald, Kyle and Bergen, Leon and Levy, Roger},
	year         = 2019,
	journal      = {Trends in cognitive sciences},
	publisher    = {Elsevier},
	volume       = 23,
	number       = 5,
	pages        = {389--407}
}
@book{miller1998wordnet,
	title        = {WordNet: An electronic lexical database},
	author       = {Miller, George A},
	year         = 1998,
	publisher    = {MIT press}
}
@inproceedings{turian2010word,
	title        = {Word Representations: A Simple and General Method for Semi-Supervised Learning},
	author       = {Turian, Joseph  and Ratinov, Lev-Arie  and Bengio, Yoshua},
	year         = 2010,
	booktitle    = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Uppsala, Sweden},
	pages        = {384--394},
	url          = {https://aclanthology.org/P10-1040}
}
@article{floridi2020gpt,
	title        = {{GPT-3}: Its nature, scope, limits, and consequences},
	author       = {Floridi, Luciano and Chiriatti, Massimo},
	year         = 2020,
	journal      = {Minds and Machines},
	publisher    = {Springer},
	volume       = 30,
	number       = 4,
	pages        = {681--694}
}
@inproceedings{la2020assessing,
	title        = {Assessing Robustness of Text Classification through Maximal Safe Radius Computation},
	author       = {La Malfa, Emanuele  and Wu, Min  and Laurenti, Luca  and Wang, Benjie  and Hartshorn, Anthony  and Kwiatkowska, Marta},
	year         = 2020,
	booktitle    = {Findings of the Association for Computational Linguistics: EMNLP 2020},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {2949--2968},
	doi          = {10.18653/v1/2020.findings-emnlp.266},
	url          = {https://aclanthology.org/2020.findings-emnlp.266}
}
@inproceedings{kusner2015word,
	title        = {From Word Embeddings To Document Distances},
	author       = {Matt J. Kusner and Yu Sun and Nicholas I. Kolkin and Kilian Q. Weinberger},
	year         = 2015,
	booktitle    = {Proceedings of the 32nd International Conference on Machine Learning, {ICML} 2015, Lille, France, 6-11 July 2015},
	publisher    = {JMLR.org},
	series       = {{JMLR} Workshop and Conference Proceedings},
	volume       = 37,
	pages        = {957--966},
	url          = {http://proceedings.mlr.press/v37/kusnerb15.html},
}
@inproceedings{dong2021towards,
	title        = {Towards Robustness Against Natural Language Word Substitutions},
	author       = {Xinshuai Dong and Anh Tuan Luu and Rongrong Ji and Hong Liu},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=ks5nebunVn\_},
}
@article{xu2020elephant,
	title        = {Elephant in the room: An evaluation framework for assessing adversarial examples in {NLP}},
	author       = {Xu, Ying and Zhong, Xu and Yepes, Antonio Jose Jimeno and Lau, Jey Han},
	year         = 2020,
	journal      = {ArXiv preprint},
	volume       = {abs/2001.07820},
	url          = {https://arxiv.org/abs/2001.07820}
}
@inproceedings{la2021guaranteed,
	title        = {On Guaranteed Optimal Robust Explanations for {NLP} Models},
	author       = {Emanuele La Malfa and Rhiannon Michelmore and Agnieszka M. Zbrzezny and Nicola Paoletti and Marta Kwiatkowska},
	year         = 2021,
	booktitle    = {Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, {IJCAI} 2021, Virtual Event / Montreal, Canada, 19-27 August 2021},
	publisher    = {ijcai.org},
	pages        = {2658--2665},
	doi          = {10.24963/ijcai.2021/366},
	url          = {https://doi.org/10.24963/ijcai.2021/366},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/ijcai/MalfaMZPK21.bib},
	editor       = {Zhi{-}Hua Zhou},
	timestamp    = {Sun, 02 Oct 2022 16:08:04 +0200}
}
@article{goldberg2014word2vec,
	title        = {word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method},
	author       = {Goldberg, Yoav and Levy, Omer},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1402.3722}
}
@article{rogers2020primer,
	title        = {A Primer in {BERT}ology: What We Know About How {BERT} Works},
	author       = {Rogers, Anna  and Kovaleva, Olga  and Rumshisky, Anna},
	year         = 2020,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	address      = {Cambridge, MA},
	volume       = 8,
	pages        = {842--866},
	doi          = {10.1162/tacl_a_00349},
	url          = {https://aclanthology.org/2020.tacl-1.54}
}
@inproceedings{madry2017towards,
	title        = {Towards Deep Learning Models Resistant to Adversarial Attacks},
	author       = {Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
	year         = 2018,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=rJzIBfZAb},
}
@inproceedings{ribeiro2020beyond,
	title        = {Beyond Accuracy: Behavioral Testing of {NLP} Models with {C}heck{L}ist},
	author       = {Ribeiro, Marco Tulio  and Wu, Tongshuang  and Guestrin, Carlos  and Singh, Sameer},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {4902--4912},
	doi          = {10.18653/v1/2020.acl-main.442},
	url          = {https://aclanthology.org/2020.acl-main.442}
}
@inproceedings{white2021non,
	title        = {A Non-Linear Structural Probe},
	author       = {White, Jennifer C.  and Pimentel, Tiago  and Saphra, Naomi  and Cotterell, Ryan},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {132--138},
	doi          = {10.18653/v1/2021.naacl-main.12},
	url          = {https://aclanthology.org/2021.naacl-main.12}
}
@inproceedings{pimentel2020information,
	title        = {Information-Theoretic Probing for Linguistic Structure},
	author       = {Pimentel, Tiago  and Valvoda, Josef  and Maudslay, Rowan Hall  and Zmigrod, Ran  and Williams, Adina  and Cotterell, Ryan},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {4609--4622},
	doi          = {10.18653/v1/2020.acl-main.420},
	url          = {https://aclanthology.org/2020.acl-main.420}
}
@inproceedings{bauer-etal-2023-semgrex,
	title        = {Semgrex and Ssurgeon, Searching and Manipulating Dependency Graphs},
	author       = {Bauer, John  and Kiddon, Chlo{\'e}  and Yeh, Eric  and Shan, Alex  and D. Manning, Christopher},
	year         = 2023,
	booktitle    = {Proceedings of the 21st International Workshop on Treebanks and Linguistic Theories (TLT, GURT/SyntaxFest 2023)},
	publisher    = {Association for Computational Linguistics},
	address      = {Washington, D.C.},
	pages        = {67--73},
	url          = {https://aclanthology.org/2023.tlt-1.7}
}
@article{radford2019language,
	title        = {Language Models are Unsupervised Multitask Learners},
	author       = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
	year         = 2019,
	journal      = {OpenAI blog},
	volume       = 1,
	number       = 8,
	pages        = 9,
    url = {https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf}
}
@inproceedings{qi2020stanza,
	title        = {{S}tanza: A Python Natural Language Processing Toolkit for Many Human Languages},
	author       = {Qi, Peng  and Zhang, Yuhao  and Zhang, Yuhui  and Bolton, Jason  and Manning, Christopher D.},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {101--108},
	doi          = {10.18653/v1/2020.acl-demos.14},
	url          = {https://aclanthology.org/2020.acl-demos.14}
}
@inproceedings{ravichander2020probing,
	title        = {Probing the Probing Paradigm: Does Probing Accuracy Entail Task Relevance?},
	author       = {Ravichander, Abhilasha  and Belinkov, Yonatan  and Hovy, Eduard},
	year         = 2021,
	booktitle    = {Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {3363--3377},
	doi          = {10.18653/v1/2021.eacl-main.295},
	url          = {https://aclanthology.org/2021.eacl-main.295}
}
@article{belinkov2022probing,
	title        = {Probing Classifiers: Promises, Shortcomings, and Advances},
	author       = {Belinkov, Yonatan},
	year         = 2022,
	journal      = {Computational Linguistics},
	publisher    = {MIT Press},
	address      = {Cambridge, MA},
	volume       = 48,
	number       = 1,
	pages        = {207--219},
	doi          = {10.1162/coli_a_00422},
	url          = {https://aclanthology.org/2022.cl-1.7}
}
@misc{ChatGPT,
	title        = {Introducing {ChatGPT}},
	author       = {{OpenAI}},
	year         = 2023,
	url          = {https://openai.com/blog/chatgpt},
	note         = {Accessed on April 11, 2023},
	date-added   = {February 5, 2023}
}
@inproceedings{jacovi2021formalizing,
	title        = {Formalizing trust in artificial intelligence: Prerequisites, causes and goals of human trust in {AI}},
	author       = {Jacovi, Alon and Marasovi{\'c}, Ana and Miller, Tim and Goldberg, Yoav},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
	pages        = {624--635}
}
@article{wang2023chatgpt,
	title        = {Is {ChatGPT} a Good Sentiment Analyzer? {A} Preliminary Study},
	author       = {Wang, Zengzhi and Xie, Qiming and Ding, Zixiang and Feng, Yi and Xia, Rui},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.04339},
	url          = {https://arxiv.org/abs/2304.04339}
}
@article{qin2023chatgpt,
	title        = {Is {ChatGPT} a general-purpose natural language processing task solver?},
	author       = {Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.06476},
	url          = {https://arxiv.org/abs/2302.06476}
}
@article{borji2023categorical,
	title        = {A categorical archive of {ChatGPT}failures},
	author       = {Borji, Ali},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.03494},
	url          = {https://arxiv.org/abs/2302.03494}
}
@article{wang2023robustness,
	title        = {On the robustness of {ChatGPT}: An adversarial and out-of-distribution perspective},
	author       = {Wang, Jindong and Hu, Xixu and Hou, Wenxin and Chen, Hao and Zheng, Runkai and Wang, Yidong and Yang, Linyi and Huang, Haojun and Ye, Wei and Geng, Xiubo and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.12095},
	url          = {https://arxiv.org/abs/2302.12095}
}

@article{ray2023chatGPT,
title = {{ChatGPT}: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope},
journal = {Internet of Things and Cyber-Physical Systems},
volume = {3},
pages = {121-154},
year = {2023},
url = {https://www.sciencedirect.com/science/article/pii/S266734522300024X},
author = {Partha Pratim Ray},
}

@article{dai2023chataug,
	title        = {{ChatAug}: Leveraging {ChatGPT} for Text Data Augmentation},
	author       = {Dai, Haixing and Liu, Zhengliang and Liao, Wenxiong and Huang, Xiaoke and Wu, Zihao and Zhao, Lin and Liu, Wei and Liu, Ninghao and Li, Sheng and Zhu, Dajiang and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.13007},
	url          = {https://arxiv.org/abs/2302.13007}
}
@article{zhao2023survey,
	title        = {A survey of large language models},
	author       = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2303.18223},
	url          = {https://arxiv.org/abs/2303.18223}
}
@article{mahowald2023dissociating,
	title        = {Dissociating language and thought in large language models: a cognitive perspective},
	author       = {Mahowald, Kyle and Ivanova, Anna A and Blank, Idan A and Kanwisher, Nancy and Tenenbaum, Joshua B and Fedorenko, Evelina},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2301.06627},
	url          = {https://arxiv.org/abs/2301.06627}
}
@article{zhang2023one,
	title        = {One small step for generative {AI}, one giant leap for {AGI}: A complete survey on {ChatGPT} in {AIGC} era},
	author       = {Zhang, Chaoning and Zhang, Chenshuang and Li, Chenghao and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.06488},
	url          = {https://arxiv.org/abs/2304.06488}
}
@misc{barnes2021time,
	title        = {Is it time to move beyond sentence classification?},
	author       = {Barnes, Jeremy},
	year         = 2021,
    url = {https://jerbarnes.github.io/downloads/keynote_AIST2021.pdf}
}
@article{raffel2020exploring,
	title        = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
	author       = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
	year         = 2020,
	journal      = {J. Mach. Learn. Res.},
	volume       = 21,
	pages        = {140:1--140:67},
	url          = {http://jmlr.org/papers/v21/20-074.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/journals/jmlr/RaffelSRLNMZLL20.bib},
	timestamp    = {Fri, 05 Feb 2021 00:00:00 +0100}
}
@article{thoppilan2022lamda,
	title        = {Lamda: Language models for dialog applications},
	author       = {Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2201.08239},
	url          = {https://arxiv.org/abs/2201.08239}
}
@inproceedings{romera2015embarrassingly,
	title        = {An embarrassingly simple approach to zero-shot learning},
	author       = {Bernardino Romera{-}Paredes and Philip H. S. Torr},
	year         = 2015,
	booktitle    = {Proceedings of the 32nd International Conference on Machine Learning, {ICML} 2015, Lille, France, 6-11 July 2015},
	publisher    = {JMLR.org},
	series       = {{JMLR} Workshop and Conference Proceedings},
	volume       = 37,
	pages        = {2152--2161},
	url          = {http://proceedings.mlr.press/v37/romera-paredes15.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/icml/Romera-ParedesT15.bib},
	editor       = {Francis R. Bach and David M. Blei},
	timestamp    = {Wed, 29 May 2019 01:00:00 +0200}
}
@article{kojima2022large,
	title        = {Large language models are zero-shot reasoners},
	author       = {Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2205.11916},
	url          = {https://arxiv.org/abs/2205.11916}
}
@article{cao2020treatment,
	title        = {Treatment response prediction and individualized identification of first-episode drug-naive schizophrenia using brain functional connectivity},
	author       = {Cao, Bo and Cho, Raymond Y and Chen, Dachun and Xiu, Meihong and Wang, Li and Soares, Jair C and Zhang, Xiang Yang},
	year         = 2020,
	journal      = {Molecular psychiatry},
	publisher    = {Nature Publishing Group UK London},
	volume       = 25,
	number       = 4,
	pages        = {906--913}
}
@article{touvron2023llama,
	title        = {{LLaMA}: Open and Efficient Foundation Language Models},
	author       = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.13971},
	url          = {https://arxiv.org/abs/2302.13971}
}
@article{touvron2023llama2,
	title        = {{LLaMA 2}: Open Foundation and Fine-Tuned Chat Models},
	author       = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2307.09288},
	url          = {https://arxiv.org/abs/2307.09288}
}
@misc{alpaca,
	title        = {Stanford {Alpaca}: An Instruction-following {LLaMA} model},
	author       = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto},
	year         = 2023,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	url = {https://github.com/tatsu-lab/stanford_alpaca}
}
@inproceedings{darwiche2020three,
	title        = {Three Modern Roles for Logic in {AI}},
	author       = {Darwiche, Adnan},
	year         = 2020,
	booktitle    = {Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
	pages        = {229--243}
}
@article{darwiche2020reasons,
	title        = {On The Reasons Behind Decisions},
	author       = {Darwiche, Adnan and Hirth, Auguste},
	year         = 2020,
	journal      = {ArXiv preprint},
	volume       = {abs/2002.09284},
	url          = {https://arxiv.org/abs/2002.09284}
}
@inproceedings{alvarez2018towards,
	title        = {Towards Robust Interpretability with Self-Explaining Neural Networks},
	author       = {David Alvarez{-}Melis and Tommi S. Jaakkola},
	year         = 2018,
	booktitle    = {Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr{\'{e}}al, Canada},
	pages        = {7786--7795},
	url          = {https://proceedings.neurips.cc/paper/2018/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/nips/Alvarez-MelisJ18.bib},
	editor       = {Samy Bengio and Hanna M. Wallach and Hugo Larochelle and Kristen Grauman and Nicol{\`{o}} Cesa{-}Bianchi and Roman Garnett},
	timestamp    = {Thu, 21 Jan 2021 00:00:00 +0100}
}
@misc{bills2023language,
	title        = {Language models can explain neurons in language models},
	author       = {Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
	year         = 2023,
	url = {https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html}
}
@incollection{sep-compositionality,
	title        = {{Compositionality}},
	author       = {Szabó, Zoltán Gendler},
	year         = 2022,
	booktitle    = {The {Stanford} Encyclopedia of Philosophy},
	publisher    = {Metaphysics Research Lab, Stanford University},
	edition      = {{F}all 2022},
	editor       = {Edward N. Zalta and Uri Nodelman},
	howpublished = {\url{https://plato.stanford.edu/archives/fall2022/entries/compositionality/}}
}
@article{cattell1886time,
	title        = {The time it takes to see and name objects},
	author       = {Cattell, James McKeen},
	year         = 1886,
	journal      = {Mind},
	publisher    = {JSTOR},
	volume       = 11,
	number       = 41,
	pages        = {63--65}
}
@article{mcclelland1977role,
	title        = {The role of familiar units in perception of words and nonwords},
	author       = {McClelland, James L and Johnston, James C},
	year         = 1977,
	journal      = {Perception \& Psychophysics},
	publisher    = {Springer},
	volume       = 22,
	pages        = {249--261}
}
@article{liu2023we,
	title        = {We're Afraid Language Models Aren't Modeling Ambiguity},
	author       = {Liu, Alisa and Wu, Zhaofeng and Michael, Julian and Suhr, Alane and West, Peter and Koller, Alexander and Swayamdipta, Swabha and Smith, Noah A and Choi, Yejin},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.14399},
	url          = {https://arxiv.org/abs/2304.14399}
}
@inproceedings{blei2003latent,
	title        = {Latent Dirichlet Allocation},
	author       = {David M. Blei and Andrew Y. Ng and Michael I. Jordan},
	year         = 2001,
	booktitle    = {Advances in Neural Information Processing Systems 14 [Neural Information Processing Systems: Natural and Synthetic, {NIPS} 2001, December 3-8, 2001, Vancouver, British Columbia, Canada]},
	publisher    = {{MIT} Press},
	pages        = {601--608},
	url          = {https://proceedings.neurips.cc/paper/2001/hash/296472c9542ad4d4788d543508116cbc-Abstract.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/nips/BleiNJ01.bib},
	editor       = {Thomas G. Dietterich and Suzanna Becker and Zoubin Ghahramani},
	timestamp    = {Thu, 21 Jan 2021 00:00:00 +0100}
}
@article{landauer1998introduction,
	title        = {An introduction to latent semantic analysis},
	author       = {Landauer, Thomas K and Foltz, Peter W and Laham, Darrell},
	year         = 1998,
	journal      = {Discourse processes},
	publisher    = {Taylor \& Francis},
	volume       = 25,
	number       = {2-3},
	pages        = {259--284}
}
@inproceedings{brendel2017decision,
	title        = {Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models},
	author       = {Wieland Brendel and Jonas Rauber and Matthias Bethge},
	year         = 2018,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=SyZI0GWCZ},
}
@inproceedings{bassan2023towards,
	title        = {Towards Formal {XAI}: Formally Approximate Minimal Explanations of Neural Networks},
	author       = {Bassan, Shahaf and Katz, Guy},
	year         = 2023,
	booktitle    = {Tools and Algorithms for the Construction and Analysis of Systems: 29th International Conference, TACAS 2023, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2022, Paris, France, April 22--27, 2023, Proceedings, Part I},
	pages        = {187--207},
	organization = {Springer}
}
@article{wu2022verix,
	title        = {VeriX: Towards Verified Explainability of Deep Neural Networks},
	author       = {Wu, Min and Wu, Haoze and Barrett, Clark},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2212.01051},
	url          = {https://arxiv.org/abs/2212.01051}
}
@inproceedings{croce2019sparse,
	title        = {Sparse and Imperceivable Adversarial Attacks},
	author       = {Francesco Croce and Matthias Hein},
	year         = 2019,
	booktitle    = {2019 {IEEE/CVF} International Conference on Computer Vision, {ICCV} 2019, Seoul, Korea (South), October 27 - November 2, 2019},
	publisher    = {{IEEE}},
	pages        = {4723--4731},
	doi          = {10.1109/ICCV.2019.00482},
	url          = {https://doi.org/10.1109/ICCV.2019.00482},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/iccv/Croce019.bib},
	timestamp    = {Thu, 05 Mar 2020 00:00:00 +0100}
}
@article{wang2019natural,
	title        = {Natural language adversarial attack and defense in word level},
	author       = {Wang, Xiaosen and Jin, Hao and He, Kun},
	year         = 2019
}
@inproceedings{pierazzi2020intriguing,
	title        = {Intriguing properties of adversarial ml attacks in the problem space},
	author       = {Pierazzi, Fabio and Pendlebury, Feargus and Cortellazzi, Jacopo and Cavallaro, Lorenzo},
	year         = 2020,
	booktitle    = {2020 IEEE symposium on security and privacy (SP)},
	pages        = {1332--1349},
	organization = {IEEE}
}
@inproceedings{morris2020reevaluating,
	title        = {Reevaluating Adversarial Examples in Natural Language},
	author       = {Morris, John  and Lifland, Eli  and Lanchantin, Jack  and Ji, Yangfeng  and Qi, Yanjun},
	year         = 2020,
	booktitle    = {Findings of the Association for Computational Linguistics: EMNLP 2020},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {3829--3839},
	doi          = {10.18653/v1/2020.findings-emnlp.341},
	url          = {https://aclanthology.org/2020.findings-emnlp.341}
}
@inproceedings{vaswani2017attention,
	title        = {Attention is All you Need},
	author       = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	year         = 2017,
	booktitle    = {Advances in Neural Information Processing Systems 30: 2017, December 4-9, 2017, Long Beach, CA, {USA}},
	pages        = {5998--6008},
	url          = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html}
}
@inproceedings{xue2020mt5,
	title        = {m{T}5: A Massively Multilingual Pre-trained Text-to-Text Transformer},
	author       = {Xue, Linting  and Constant, Noah  and Roberts, Adam  and Kale, Mihir  and Al-Rfou, Rami  and Siddhant, Aditya  and Barua, Aditya  and Raffel, Colin},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {483--498},
	doi          = {10.18653/v1/2021.naacl-main.41},
	url          = {https://aclanthology.org/2021.naacl-main.41}
}
@article{bubeck2023sparks,
	title        = {Sparks of Artificial General Intelligence: Early experiments with {GPT-4}},
	author       = {Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2303.12712},
	url          = {https://arxiv.org/abs/2303.12712}
}
@article{kocon2023chatgpt,
	title        = {{ChatGPT}: Jack of all trades, master of none},
	author       = {Koco{\'n}, Jan and Cichecki, Igor and Kaszyca, Oliwier and Kochanek, Mateusz and Szyd{\l}o, Dominika and Baran, Joanna and Bielaniewicz, Julita and Gruza, Marcin and Janz, Arkadiusz and Kanclerz, Kamil and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.10724},
	url          = {https://arxiv.org/abs/2302.10724}
}
@article{petrov2023langauge,
	title        = {Language Model Tokenizers Introduce Unfairness Between Languages},
	author       = {Petrov, Aleksandar and La Malfa, Emanuele and Torr, Philip and Bibi, Adel},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.15425},
	url          = {https://arxiv.org/abs/2305.15425}
}
@article{frank3023experimentology,
	title        = {Experimentology: An Open Science Approach to Experimental Psychology Methods},
	author       = {Frank, Michael},
	year         = 2023,
	journal      = {github project arXiv:xxxx:xxxx}
}
@inproceedings{wiegand2010survey,
	title        = {A survey on the role of negation in sentiment analysis},
	author       = {Wiegand, Michael  and Balahur, Alexandra  and Roth, Benjamin  and Klakow, Dietrich  and Montoyo, Andr{\'e}s},
	year         = 2010,
	booktitle    = {Proceedings of the Workshop on Negation and Speculation in Natural Language Processing},
	publisher    = {University of Antwerp},
	address      = {Uppsala, Sweden},
	pages        = {60--68},
	url          = {https://aclanthology.org/W10-3111}
}
@article{laskar2023systematic,
	title        = {A Systematic Study and Comprehensive Evaluation of {ChatGPT} on Benchmark Datasets},
	author       = {Laskar, Md Tahmid Rahman and Bari, M Saiful and Rahman, Mizanur and Bhuiyan, Md Amran Hossen and Joty, Shafiq and Huang, Jimmy Xiangji},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.18486},
	url          = {https://arxiv.org/abs/2305.18486}
}
@article{wei2022chain,
	title        = {Chain of thought prompting elicits reasoning in large language models},
	author       = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2201.11903},
	url          = {https://arxiv.org/abs/2201.11903}
}
@inproceedings{hou-etal-2019-modeling,
	title        = {Modeling language learning using specialized Elo rating},
	author       = {Hou, Jue  and Maximilian, Koppatz  and Hoya Quecedo, Jos{\'e} Mar{\'\i}a  and Stoyanova, Nataliya  and Yangarber, Roman},
	year         = 2019,
	booktitle    = {Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {494--506},
	doi          = {10.18653/v1/W19-4451},
	url          = {https://aclanthology.org/W19-4451}
}
@article{liang2022holistic,
	title        = {Holistic evaluation of language models},
	author       = {Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2211.09110},
	url          = {https://arxiv.org/abs/2211.09110}
}
@article{chang2023survey,
	title        = {A Survey on Evaluation of Large Language Models},
	author       = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Zhu, Kaijie and Chen, Hao and Yang, Linyi and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2307.03109},
	url          = {https://arxiv.org/abs/2307.03109}
}
@inproceedings{kiela2021dynabench,
	title        = {Dynabench: Rethinking Benchmarking in {NLP}},
	author       = {Kiela, Douwe  and Bartolo, Max  and Nie, Yixin  and Kaushik, Divyansh  and Geiger, Atticus  and Wu, Zhengxuan  and Vidgen, Bertie  and Prasad, Grusha  and Singh, Amanpreet  and Ringshia, Pratik  and Ma, Zhiyi  and Thrush, Tristan  and Riedel, Sebastian  and Waseem, Zeerak  and Stenetorp, Pontus  and Jia, Robin  and Bansal, Mohit  and Potts, Christopher  and Williams, Adina},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {4110--4124},
	doi          = {10.18653/v1/2021.naacl-main.324},
	url          = {https://aclanthology.org/2021.naacl-main.324}
}
@article{suzgun2022challenging,
	title        = {Challenging {BIG-Bench} tasks and whether chain-of-thought can solve them},
	author       = {Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2210.09261},
	url          = {https://arxiv.org/abs/2210.09261}
}
@article{srivastava2022beyond,
	title        = {Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
	author       = {Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2206.04615},
	url          = {https://arxiv.org/abs/2206.04615}
}
@article{zhong2023agieval,
	title        = {{AGIE}val: A Human-Centric Benchmark for Evaluating Foundation Models},
	author       = {Zhong, Wanjun and Cui, Ruixiang and Guo, Yiduo and Liang, Yaobo and Lu, Shuai and Wang, Yanlin and Saied, Amin and Chen, Weizhu and Duan, Nan},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.06364},
	url          = {https://arxiv.org/abs/2304.06364}
}
@article{OpenAI2023GPT4TR,
	title        = {{GPT-4} Technical Report},
	author       = {OpenAI},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2303.08774},
	url          = {https://arxiv.org/abs/2303.08774}
}
@article{rombach2021highresolution,
	title        = {High-Resolution Image Synthesis with Latent Diffusion Models},
	author       = {Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2112.10752},
	url = {https://arxiv.org/abs/2112.10752}
}
@article{jacovi2023stop,
	title        = {Stop uploading test data in plain text: Practical strategies for mitigating data contamination by evaluation benchmarks},
	author       = {Jacovi, Alon and Caciularu, Avi and Goldman, Omer and Goldberg, Yoav},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.10160},
	url          = {https://arxiv.org/abs/2305.10160}
}
@article{mukherjee2023orca,
	title        = {Orca: Progressive learning from complex explanation traces of {GPT-4}},
	author       = {Mukherjee, Subhabrata and Mitra, Arindam and Jawahar, Ganesh and Agarwal, Sahaj and Palangi, Hamid and Awadallah, Ahmed},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2306.02707},
	url          = {https://arxiv.org/abs/2306.02707}
}
@inproceedings{chang2008importance,
	title        = {Importance of Semantic Representation: Dataless Classification},
	author       = {Chang, Ming-Wei and Ratinov, Lev-Arie and Roth, Dan and Srikumar, Vivek},
	year         = 2008,
	booktitle    = {AAAI},
	volume       = 2,
	pages        = {830--835},
    url          = {https://dl.acm.org/doi/10.5555/1620163.1620201}
}
@article{bai2022training,
	title        = {Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback},
	author       = {Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2204.05862},
	url          = {https://arxiv.org/abs/2204.05862}
}
@article{gao2020pile,
  title={The pile: An 800gb dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}
@inproceedings{min-etal-2022-rethinking,
    title = "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",
    author = "Min, Sewon  and
      Lyu, Xinxi  and
      Holtzman, Ari  and
      others",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.759"
}

@article{niu2021review,
	title        = {A review on the attention mechanism of deep learning},
	author       = {Niu, Zhaoyang and Zhong, Guoqiang and Yu, Hui},
	year         = 2021,
	journal      = {Neurocomputing},
	publisher    = {Elsevier},
	volume       = 452,
	pages        = {48--62},
        url = {https://www.sciencedirect.com/science/article/abs/pii/S092523122100477X}
}
@inproceedings{bahdanau2014neural,
	title        = {Neural Machine Translation by Jointly Learning to Align and Translate},
	author       = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
	year         = 2015,
	booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
	url          = {http://arxiv.org/abs/1409.0473},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/journals/corr/BahdanauCB14.bib},
	editor       = {Yoshua Bengio and Yann LeCun},
	timestamp    = {Fri, 29 Mar 2019 00:00:00 +0100}
}
@article{chowdhery2022palm,
	title        = {{PaLM}: Scaling Language Modeling with Pathways},
	author       = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2204.02311},
	url          = {https://arxiv.org/abs/2204.02311}
}
@article{wolf2019huggingface,
	title        = {{HuggingFace's }{T}ransformers: State-of-the-art Natural Language Processing},
	author       = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
	year         = 2019,
	journal      = {ArXiv preprint},
	volume       = {abs/1910.03771},
	url          = {https://arxiv.org/abs/1910.03771}
}
@misc{SaaS,
	title        = {What Does That Server Really Serve?},
	author       = {Richard Stallman},
	year         = 2010,
	url          = {https://www.bostonreview.net/articles/what-does-that-server-really-serve/}
}
@misc{open-free,
	title        = {Open Source Misses the Point},
	author       = {Richard Stallman},
	year         = 2022,
	url          = {https://www.gnu.org/philosophy/open-source-misses-the-point.html}
}
@article{ahia2023all,
	title        = {Do All Languages Cost the Same? {T}okenization in the Era of Commercial Language Models},
	author       = {Ahia, Orevaoghene and Kumar, Sachin and Gonen, Hila and Kasai, Jungo and Mortensen, David R and Smith, Noah A and Tsvetkov, Yulia},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.13707},
	url          = {https://arxiv.org/abs/2305.13707}
}
@article{mccoy2023much,
	title        = {How much do language models copy from their training data? {E}valuating linguistic novelty in text generation using {RAVEN}},
	author       = {McCoy, R Thomas and Smolensky, Paul and Linzen, Tal and Gao, Jianfeng and Celikyilmaz, Asli},
	year         = 2023,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	volume       = 11,
	pages        = {652--670},
        url = {https://aclanthology.org/2023.tacl-1.38}
}
@article{carlini2022quantifying,
	title        = {Quantifying Memorization Across Neural Language Models},
	author       = {Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2202.07646},
	url          = {https://arxiv.org/abs/2202.07646}
}
@inproceedings{biderman2023pythia,
	title        = {Pythia: A Suite for Analyzing Large Language Models across Training and Scaling},
	author       = {Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin Gregory and Bradley, Herbie and O’Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
	year         = 2023,
	booktitle    = {International Conference on Machine Learning},
	pages        = {2397--2430},
	organization = {PMLR},
    url          = {https://arxiv.org/pdf/2304.01373.pdf}
}
@article{zhang2023exploring,
	title        = {Exploring the {MIT} Mathematics and {EECS} Curriculum Using Large Language Models},
	author       = {Zhang, Sarah J and Florin, Samuel and Lee, Ariel N and Niknafs, Eamon and Marginean, Andrei and Wang, Annie and Tyser, Keith and Chin, Zad and Hicke, Yann and Singh, Nikhil and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2306.08997},
	url          = {https://arxiv.org/abs/2306.08997}
}
@misc{exams-mit-chatgpt,
	title        = {No, {GPT4} can’t ace {MIT}},
	author       = {Chowdhuri, Raunak and Deshmukh, Neil and Koplow, David},
	year         = 2023,
	url          = {https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864}
}
@article{burnell2023revealing,
	title        = {Revealing the structure of language model capabilities},
	author       = {Burnell, Ryan and Hao, Han and Conway, Andrew RA and Orallo, Jose Hernandez},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2306.10062},
	url          = {https://arxiv.org/abs/2306.10062}
}
@article{dao2022flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16344--16359},
  year={2022}
}
@article{zini2022explainability,
	title        = {On the explainability of natural language processing deep models},
	author       = {Zini, Julia El and Awad, Mariette},
	year         = 2022,
	journal      = {ACM Computing Surveys},
	publisher    = {ACM New York, NY},
	volume       = 55,
	number       = 5,
	pages        = {1--31},
        url = {https://dl.acm.org/doi/10.1145/3529755}
}
@article{li2023evaluating,
	title        = {Evaluating {ChatGPT}'s Information Extraction Capabilities: An Assessment of Performance, Explainability, Calibration, and Faithfulness},
	author       = {Li, Bo and Fang, Gexiang and Yang, Yang and Wang, Quansen and Ye, Wei and Zhao, Wen and Zhang, Shikun},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.11633},
	url          = {https://arxiv.org/abs/2304.11633}
}
@inproceedings{maynez-etal-2020-faithfulness,
	title        = {On Faithfulness and Factuality in Abstractive Summarization},
	author       = {Maynez, Joshua  and Narayan, Shashi  and Bohnet, Bernd  and McDonald, Ryan},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {1906--1919},
	doi          = {10.18653/v1/2020.acl-main.173},
	url          = {https://aclanthology.org/2020.acl-main.173}
}
@article{xian2018zero,
	title        = {Zero-shot Learning -- A Comprehensive Evaluation of the Good, the Bad and the Ugly},
	author       = {Xian, Yongqin and Lampert, Christoph H and Schiele, Bernt and Akata, Zeynep},
	year         = 2018,
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	publisher    = {IEEE},
	volume       = 41,
	number       = 9,
	pages        = {2251--2265},
        url = {https://www.computer.org/csdl/journal/tp/2019/09/08413121/13rRUwh80CK}
}
@article{zhou2022domain,
	title        = {Domain generalization: A survey},
	author       = {Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Xiang, Tao and Loy, Chen Change},
	year         = 2022,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	publisher    = {IEEE},
        url = {https://ieeexplore.ieee.org/document/9847099}
}
@article{aiyappa2023can,
	title        = {Can we trust the evaluation on {ChatGPT}?},
	author       = {Aiyappa, Rachith and An, Jisun and Kwak, Haewoon and Ahn, Yong-Yeol},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2303.12767},
	url          = {https://arxiv.org/abs/2303.12767}
}
@article{shen2023chatgpt,
	title        = {In {ChatGPT} we trust? {M}easuring and characterizing the reliability of {ChatGPT}},
	author       = {Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Zhang, Yang},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.08979},
	url          = {https://arxiv.org/abs/2304.08979}
}
@article{pezzelle2023dealing,
	title        = {Dealing with Semantic Underspecification in Multimodal NLP},
	author       = {Pezzelle, Sandro},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2306.05240},
	url          = {https://arxiv.org/abs/2306.05240}
}
@article{du2022measure,
	title        = {A Measure-Theoretic Characterization of Tight Language Models},
	author       = {Du, Li and Hennigen, Lucas Torroba and Pimentel, Tiago and Meister, Clara and Eisner, Jason and Cotterell, Ryan},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2212.10502},
	url          = {https://arxiv.org/abs/2212.10502}
}
@article{heron2013open,
	title        = {Open source and accessibility: advantages and limitations},
	author       = {Heron, Michael and Hanson, Vicki L and Ricketts, Ian},
	year         = 2013,
	journal      = {Journal of interaction Science},
	publisher    = {SpringerOpen},
	volume       = 1,
	number       = 1,
	pages        = {1--10},
        url          = {https://journalofinteractionscience.springeropen.com/articles/10.1186/2194-0827-1-2}
}
@book{tkacz2020wikipedia,
	title        = {Wikipedia and the Politics of Openness},
	author       = {Tkacz, Nathaniel},
	year         = 2020,
	publisher    = {University of Chicago Press},
        url          = {https://press.uchicago.edu/ucp/books/book/chicago/W/bo19085555.html}
}
@article{henkel2009champions,
	title        = {Champions of Revealing—The Role of Open Source Developers in Commercial Firms},
	author       = {Henkel, Joachim},
	year         = 2009,
	journal      = {Industrial and Corporate Change},
	publisher    = {Oxford University Press},
	volume       = 18,
	number       = 3,
	pages        = {435--471},
        url          = {https://academic.oup.com/icc/article-abstract/18/3/435/807451}
}
@article{dwivedi2023so,
	title        = {``{S}o what if {ChatGPT} wrote it?'' {M}ultidisciplinary perspectives on opportunities, challenges and implications of generative conversational {AI} for research, practice and policy},
	author       = {Dwivedi, Yogesh K and Kshetri, Nir and Hughes, Laurie and Slade, Emma Louise and Jeyaraj, Anand and Kar, Arpan Kumar and Baabdullah, Abdullah M and Koohang, Alex and Raghavan, Vishnupriya and Ahuja, Manju and others},
	year         = 2023,
	journal      = {International Journal of Information Management},
	publisher    = {Elsevier},
	volume       = 71,
	pages        = 102642,
    url          = {https://www.sciencedirect.com/science/article/pii/S0268401223000233}
}
@article{moller2023prompt,
	title        = {Is a prompt and a few samples all you need? {U}sing {GPT-4} for data augmentation in low-resource classification tasks},
	author       = {M{\o}ller, Anders Giovanni and Dalsgaard, Jacob Aarup and Pera, Arianna and Aiello, Luca Maria},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.13861},
	url          = {https://arxiv.org/abs/2304.13861}
}
@article{eldan2023tinystories,
	title        = {TinyStories: How Small Can Language Models Be and Still Speak Coherent {E}nglish?},
	author       = {Eldan, Ronen and Li, Yuanzhi},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.07759},
	url          = {https://arxiv.org/abs/2305.07759}
}
@article{liesenfeld2023opening,
	title        = {Opening up {ChatGPT}: Tracking openness, transparency, and accountability in instruction-tuned text generators},
	author       = {Liesenfeld, Andreas and Lopez, Alianda and Dingemanse, Mark},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2307.05532},
	url          = {https://arxiv.org/abs/2307.05532}
}
@article{kaddour2023challenges,
	title        = {Challenges and Applications of Large Language Models},
	author       = {Kaddour, Jean and Harris, Joshua and Mozes, Maximilian and Bradley, Herbie and Raileanu, Roberta and McHardy, Robert},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2307.10169},
	url          = {https://arxiv.org/abs/2307.10169}
}
@article{chen2023chatgpt,
	title        = {How is {ChatGPT}'s behavior changing over time?},
	author       = {Chen, Lingjiao and Zaharia, Matei and Zou, James},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2307.09009},
	url          = {https://arxiv.org/abs/2307.09009}
}
@article{izza2023delivering,
	title        = {Delivering Inflated Explanations},
	author       = {Izza, Yacine and Ignatiev, Alexey and Stuckey, Peter and Marques-Silva, Joao},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2306.15272},
	url          = {https://arxiv.org/abs/2306.15272}
}
@inproceedings{carlini2021extracting,
	title        = {Extracting Training Data from Large Language Models},
	author       = {Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
	year         = 2021,
	booktitle    = {30th USENIX Security Symposium (USENIX Security 21)},
	pages        = {2633--2650},
    url          = {https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting}
}
@inproceedings{holtzman2019curious,
	title        = {The Curious Case of Neural Text Degeneration},
	author       = {Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
	year         = 2020,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=rygGQyrFvH},
}
@article{rae2021scaling,
	title        = {Scaling language models: Methods, analysis \& insights from training {Gopher}},
	author       = {Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
	year         = 2021,
	journal      = {ArXiv preprint},
	volume       = {abs/2112.11446},
	url          = {https://arxiv.org/abs/2112.11446}
}
@inproceedings{chen2018execution,
	title        = {Execution-Guided Neural Program Synthesis},
	author       = {Xinyun Chen and Chang Liu and Dawn Song},
	year         = 2019,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=H1gfOiAqYm},
}
@article{austin2021program,
	title        = {Program synthesis with large language models},
	author       = {Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
	year         = 2021,
	journal      = {ArXiv preprint},
	volume       = {abs/2108.07732},
	url          = {https://arxiv.org/abs/2108.07732}
}
@article{virtanen2019multilingual,
	title        = {Multilingual is not enough: {BERT} for Finnish},
	author       = {Virtanen, Antti and Kanerva, Jenna and Ilo, Rami and Luoma, Jouni and Luotolahti, Juhani and Salakoski, Tapio and Ginter, Filip and Pyysalo, Sampo},
	year         = 2019,
	journal      = {ArXiv preprint},
	volume       = {abs/1912.07076},
	url          = {https://arxiv.org/abs/1912.07076}
}
@article{bang2023multitask,
	title        = {A Multitask, Multilingual, Multimodal Evaluation of {ChatGPT} on Reasoning, Hallucination, and Interactivity},
	author       = {Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.04023},
	url          = {https://arxiv.org/abs/2302.04023}
}
@article{ahuja2023mega,
	title        = {{MEGA}: Multilingual Evaluation of Generative {AI}},
	author       = {Ahuja, Kabir and Hada, Rishav and Ochieng, Millicent and Jain, Prachi and Diddee, Harshita and Maina, Samuel and Ganu, Tanuja and Segal, Sameer and Axmed, Maxamed and Bali, Kalika and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2303.12528},
	url          = {https://arxiv.org/abs/2303.12528}
}
@article{zarifhonarvar2023economics,
	title        = {Economics of {ChatGPT}: A labor market view on the occupational impact of artificial intelligence},
	author       = {Zarifhonarvar, Ali},
	year         = 2023,
	journal      = {Available at SSRN 4350925},
        url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4350925}
}
@article{alregib2022explanatory,
	title        = {Explanatory Paradigms in Neural Networks},
	author       = {AlRegib, Ghassan and Prabhushankar, Mohit},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2202.11838},
	url          = {https://arxiv.org/abs/2202.11838}
}
@article{rudin2019stop,
	title        = {Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
	author       = {Rudin, Cynthia},
	year         = 2019,
	journal      = {Nature machine intelligence},
	publisher    = {Nature Publishing Group UK London},
	volume       = 1,
	number       = 5,
	pages        = {206--215},
        url = {https://www.nature.com/articles/s42256-019-0048-x}
}
@article{feng2023towards,
	title        = {Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective},
	author       = {Feng, Guhao and Gu, Yuntian and Zhang, Bohang and Ye, Haotian and He, Di and Wang, Liwei},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.15408},
	url          = {https://arxiv.org/abs/2305.15408}
}
@inproceedings{mei2023foveate,
	title        = {Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy {AI}},
	author       = {Mei, Alex and Levy, Sharon and Wang, William Yang},
	year         = 2023,
	booktitle    = {Findings of the Association for Computational Linguistics: ACL 2023},
	pages        = {11021--11036},
        url = {https://aclanthology.org/2023.findings-acl.701}
}
@article{ohmer2023evaluating,
	title        = {Evaluating task understanding through multilingual consistency: A {ChatGPT} case study},
	author       = {Ohmer, Xenia and Bruni, Elia and Hupkes, Dieuwke},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.11662},
	url          = {https://arxiv.org/abs/2305.11662}
}
@article{bommasani2021opportunities,
	title        = {On the Opportunities and Risks of Foundation Models},
	author       = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
	year         = 2021,
	journal      = {ArXiv preprint},
	volume       = {abs/2108.07258},
	url          = {https://arxiv.org/abs/2108.07258}
}
@inproceedings{liu2022aligning,
	title        = {Aligning Generative Language Models with Human Values},
	author       = {Liu, Ruibo  and Zhang, Ge  and Feng, Xinyu  and Vosoughi, Soroush},
	year         = 2022,
	booktitle    = {Findings of the Association for Computational Linguistics: NAACL 2022},
	publisher    = {Association for Computational Linguistics},
	address      = {Seattle, United States},
	pages        = {241--252},
	doi          = {10.18653/v1/2022.findings-naacl.18},
	url          = {https://aclanthology.org/2022.findings-naacl.18}
}
@article{santurkar2023whose,
	title        = {Whose opinions do language models reflect?},
	author       = {Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2303.17548},
	url          = {https://arxiv.org/abs/2303.17548}
}
@article{ganguli2022red,
	title        = {Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned},
	author       = {Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2209.07858},
	url          = {https://arxiv.org/abs/2209.07858}
}
@article{peng2023you,
	title        = {Are You Copying My Model? {P}rotecting the Copyright of Large Language Models for {EaaS} via Backdoor Watermark},
	author       = {Peng, Wenjun and Yi, Jingwei and Wu, Fangzhao and Wu, Shangxi and Zhu, Bin and Lyu, Lingjuan and Jiao, Binxing and Xu, Tong and Sun, Guangzhong and Xie, Xing},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.10036},
	url          = {https://arxiv.org/abs/2305.10036}
}
@article{alemohammad2023self,
	title        = {Self-Consuming Generative Models Go {MAD}},
	author       = {Alemohammad, Sina and Casco-Rodriguez, Josue and Luzi, Lorenzo and Humayun, Ahmed Imtiaz and Babaei, Hossein and LeJeune, Daniel and Siahkoohi, Ali and Baraniuk, Richard G},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2307.01850},
	url          = {https://arxiv.org/abs/2307.01850}
}
@article{ignatiev2019abd,
	title        = {Abduction-Based Explanations for Machine Learning Models},
	author       = {Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao},
	year         = 2019,
	month        = {Jul.},
	journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 33,
	number       = {01},
	pages        = {1511--1519},
	doi          = {10.1609/aaai.v33i01.33011511},
	url          = {https://ojs.aaai.org/index.php/AAAI/article/view/3964}
}
@article{marques2022delivering,
	title        = {Delivering Trustworthy {AI} through Formal {XAI}},
	author       = {Marques-Silva, Joao and Ignatiev, Alexey},
	year         = 2022,
	month        = {Jun.},
	journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 36,
	number       = 11,
	pages        = {12342--12350},
	doi          = {10.1609/aaai.v36i11.21499},
	url          = {https://ojs.aaai.org/index.php/AAAI/article/view/21499}
}
@article{turpin2023language,
	title        = {Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting},
	author       = {Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel R},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.04388},
        url = {https://arxiv.org/abs/2305.04388}
}
@article{krishna2023post,
	title        = {Post hoc explanations of language models can improve language models},
	author       = {Krishna, Satyapriya and Ma, Jiaqi and Slack, Dylan and Ghandeharioun, Asma and Singh, Sameer and Lakkaraju, Himabindu},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.11426},
    url = {https://arxiv.org/abs/2305.11426}
}
@article{hendrycks2023overview,
	title        = {An Overview of Catastrophic {AI} Risks},
	author       = {Hendrycks, Dan and Mazeika, Mantas and Woodside, Thomas},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2306.12001},
    url = {https://arxiv.org/abs/2306.12001}
}
@article{schaeffer2023emergent,
	title        = {Are Emergent Abilities of Large Language Models a Mirage?},
	author       = {Rylan Schaeffer and Brando Miranda and Sanmi Koyejo},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2304.15004},
    url = {https://arxiv.org/abs/2304.15004}
}
@article{huang2023ark,
	title        = {{ArK}: Augmented Reality with Knowledge Interactive Emergent Ability},
	author       = {Qiuyuan Huang and Jae Sung Park and Abhinav Gupta and Paul Bennett and Ran Gong and Subhojit Som and Baolin Peng and Owais Khan Mohammed and Chris Pal and Yejin Choi and Jianfeng Gao},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.00970},
    url = {https://arxiv.org/abs/2305.00970}
}
@article{schaeffer2023invalid,
	title        = {Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting},
	author       = {Rylan Schaeffer and Kateryna Pistunova and Samar Khanna and Sarthak Consul and Sanmi Koyejo},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2307.10573},
    url = {https://arxiv.org/abs/2307.10573}

}
@article{singhal2023large,
	title        = {Large language models encode clinical knowledge},
	author       = {Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others},
	year         = 2023,
	journal      = {Nature},
	publisher    = {Nature Publishing Group UK London},
	pages        = {1--9}, 
        url = {https://www.nature.com/articles/s41586-023-06291-2}
}
@article{wei2022emergent,
	title        = {Emergent Abilities of Large Language Models},
	author       = {Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
	year         = 2022,
	journal      = {Transactions on Machine Learning Research},
        url = {https://arxiv.org/abs/2206.07682}
}
@article{yao2023tree,
	title        = {Tree of thoughts: Deliberate problem solving with large language models},
	author       = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.10601},
    url = {https://arxiv.org/abs/2305.10601}
}

@article{besta2023graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Podstawski, Michal and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  journal={arXiv preprint arXiv:2308.09687},
  year={2023},
  url = {https://arxiv.org/abs/2308.09687}
}


}
@misc{sarah2020davinci,
	title        = {
		{\emph{If text-davinci-001 is a rough approximate to the model reported in the NeurIPS 2020 paper, and text-davinci-002 is ~InstructGPT in the 2022 preprint, then what is just "davinci"?

		Trying to reproduce results from a time before this naming existed} [Tweet]. Twitter}
	},
	author       = {{Sarah Wiegreffe (sigmoid.social/@sarah) [@sarahwiegreffe]}},
	note          = {\url{https://twitter.com/sarahwiegreffe/status/1583617355678355456}},
	entrysubtype = {Tweet},
	eprint       = {Twitter},
	date         = {2022-10-22},
        year = {2023-01-15}
}
@article{chang2023speak,
  title={Speak, memory: An archaeology of books known to {ChatGPT/GPT-4}},
  author={Chang, Kent K and Cramer, Mackenzie and Soni, Sandeep and Bamman, David},
  journal={arXiv preprint arXiv:2305.00118},
  year={2023}
}
@misc{ycombinator2023decreased,
	title        = {Experiencing decreased performance with {ChatGPT-4}},
	author       = {{Hacker News}},
	year         = 2023,
	url          = {https://news.ycombinator.com/item?id=36633995},
	note         = {Accessed on July 31, 2023},
	date-added   = {July 31, 2023}
}
@misc{ycombinator2023dumber,
	title        = {{ChatGPT} use declines as users complain about ‘dumber’ answers},
	author       = {{Hacker News}},
	year         = 2023,
	url          = {https://news.ycombinator.com/item?id=36750200},
	note         = {Accessed on July 31, 2023},
	date-added   = {July 31, 2023}
}
@misc{openai2023decreased,
	title        = {Experiencing decreased performance with {ChatGPT-4}},
	author       = {{OpenAI Community}},
	year         = 2023,
	url          = {https://community.openai.com/t/experiencing-decreased-performance-with-chatgpt-4/234269},
	note         = {Accessed on July 31, 2023},
	date-added   = {July 31, 2023}
}
@misc{eleuther2023gptmodel,
	title        = {On the Sizes of {OpenAI} {API} Models},
	author       = {Gao, Leo},
	year         = 2023,
	url          = {https://blog.eleuther.ai/gpt3-model-sizes/},
	note         = {Accessed on July 31, 2023},
	date-added   = {July 31, 2023}
}
@misc{dean2023unicorn,
	title        = {{GPT} Unicorn: A Daily Exploration of {GPT-4}'s Image Generation Capabilities},
	author       = {Adam, Dean},
	year         = 2023,
	url          = {https://adamkdean.co.uk/posts/gpt-unicorn-a-daily-exploration-of-gpt-4s-image-generation-capabilities},
	note         = {Accessed on July 31, 2023},
	date-added   = {July 31, 2023}
}
@misc{chann2023nondeterminism,
	title        = {{Non-}determinism in {GPT}-4 is caused by Sparse {MoE}},
	author       = {Chann, Sherman},
	year         = 2023,
	url          = {https://152334h.github.io/blog/non-determinism-in-gpt-4/},
	note         = {Accessed on August 5, 2023},
	date-added   = {August 5, 2023}
}


@inproceedings{pmlr-v162-sun22e,
  title = 	 {Black-Box Tuning for Language-Model-as-a-Service},
  author =       {Sun, Tianxiang and Shao, Yunfan and Qian, Hong and Huang, Xuanjing and Qiu, Xipeng},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {20841--20855},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/sun22e/sun22e.pdf},
  url = 	 {https://proceedings.mlr.press/v162/sun22e.html},
  abstract = 	 {Extremely large pre-trained language models (PTMs) such as GPT-3 are usually released as a service. It allows users to design task-specific prompts to query the PTMs through some black-box APIs. In such a scenario, which we call Language-Model-as-a-Service (LMaaS), the gradients of PTMs are usually unavailable. Can we optimize the task prompts by only accessing the model inference APIs? This paper proposes the black-box tuning framework to optimize the continuous prompt prepended to the input text via derivative-free optimization. Instead of optimizing in the original high-dimensional prompt space, which is intractable for traditional derivative-free optimization, we perform optimization in a randomly generated subspace due to the low intrinsic dimensionality of large PTMs. The experimental results show that the black-box tuning with RoBERTa on a few labeled samples not only significantly outperforms manual prompt and GPT-3’s in-context learning, but also surpasses the gradient-based counterparts, i.e., prompt tuning and full model tuning.}
}
@article{zhao2021lmturk,
  title={{LMTurk}: Few-Shot Learners as Crowdsourcing Workers in a Language-Model-as-a-Service Framework},
  author={Zhao, Mengjie and Mi, Fei and Wang, Yasheng and Li, Minglei and Jiang, Xin and Liu, Qun and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2112.07522},
  year={2021},
  url = {https://aclanthology.org/2022.findings-naacl.51}
}


@article{ding2022delta,
  title={Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models},
  author={Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and others},
  journal={arXiv preprint arXiv:2203.06904},
  year={2022},
  url={https://arxiv.org/abs/2203.06904}
}
@article{dong2022survey,
  title={A Survey on In-context Learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022},
  url={https://arxiv.org/abs/2301.00234}
}
@inproceedings{deng2022rlprompt,
    title = "{RLP}rompt: Optimizing Discrete Text Prompts with Reinforcement Learning",
    author = "Deng, Mingkai  and
      Wang, Jianyu  and
      Hsieh, Cheng-Ping  and
      Wang, Yihan  and
      Guo, Han  and
      Shu, Tianmin  and
      Song, Meng  and
      Xing, Eric  and
      Hu, Zhiting",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.222",
    pages = "3369--3391"
}
@article{li2021prefix,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}
@misc{openai2023finetuning,
	title        = {{OpenAI} Documentation - Fine-tuning},
	author       = {{OpenAI}},
	year         = 2023,
	url          = {https://platform.openai.com/docs/guides/fine-tuning},
	note         = {Accessed on August 7, 2023},
	date-added   = {August 7, 2023}
}

@article{goldberg2016primer,
  title={A Primer on Neural Network Models for Natural Language Processing},
  author={Goldberg, Yoav},
  journal={Journal of Artificial Intelligence Research},
  volume={57},
  pages={345--420},
  year={2016},
  url={https://dl.acm.org/doi/10.5555/3176748.3176757}
}

@inproceedings{hu2021lora,
  title={{LoRA}: Low-rank Adaptation of Large Language Models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url = {https://arxiv.org/abs/2106.09685}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient Transfer Learning for {NLP}},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR},
 url = {http://proceedings.mlr.press/v97/houlsby19a/houlsby19a.pdf}
}

@article{zou2023universal,
  title={Universal and Transferable Adversarial Attacks on Aligned Language Models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023},
  url = {https://arxiv.org/abs/2307.15043}
}

@article{cohn2023dialectical,
  title={Dialectical Language Model Evaluation: an Initial Appraisal of the Commonsense Spatial Reasoning Abilities of {LLM}s},
  author={Cohn, Anthony G and Hernandez-Orallo, Jose},
  journal={arXiv preprint arXiv:2304.11164},
  year={2023},
  url = {https://arxiv.org/abs/2304.11164}
}

@article{ouyang2023llm,
  title={{LLM} is Like a Box of Chocolates: the Non-determinism of {ChatGPT} in Code Generation},
  author={Ouyang, Shuyin and Zhang, Jie M and Harman, Mark and Wang, Meng},
  journal={arXiv preprint arXiv:2308.02828},
  year={2023},
  url = {https://arxiv.org/abs/2308.02828}
}

@article{liu2023agentbench,
  title={AgentBench: Evaluating {LLM}s as Agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  journal={arXiv preprint arXiv:2308.03688},
  year={2023},
  url = {https://arxiv.org/abs/2308.03688}
}

@article{hao2023reasoning,
  title={Reasoning with Language Model is Planning with World Model},
  author={Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
  journal={arXiv preprint arXiv:2305.14992},
  year={2023},
  url={https://arxiv.org/abs/2305.14992}
}

@article{lu2023emergent,
  title={Are Emergent Abilities in Large Language Models just In-Context Learning?},
  author={Lu, Sheng and Bigoulaeva, Irina and Sachdeva, Rachneet and Madabushi, Harish Tayyar and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2309.01809},
  year={2023},
  url={https://arxiv.org/abs/2309.01809}
}

@article{gulcehre2023reinforced,
  title={Reinforced Self-Training ({ReST}) for Language Modeling},
  author={Gulcehre, Caglar and Paine, Tom Le and Srinivasan, Srivatsan and Konyushkova, Ksenia and Weerts, Lotte and Sharma, Abhishek and Siddhant, Aditya and Ahern, Alex and Wang, Miaosen and Gu, Chenjie and others},
  journal={arXiv preprint arXiv:2308.08998},
  year={2023},
  url={https://arxiv.org/abs/2308.08998}
}

@article{roziere2023code,
  title={Code {Llama}: Open Foundation Models for Code},
  author={Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023},
  url={https://arxiv.org/abs/2308.12950}
}

@article{zhang2022automatic,
  title={Automatic chain of thought prompting in large language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  journal={arXiv preprint arXiv:2210.03493},
  year={2022},
  url={https://arxiv.org/abs/2210.03493}
}
@article{jojic2023gpt,
  title={GPT is becoming a Turing machine: Here are some ways to program it},
  author={Jojic, Ana and Wang, Zhen and Jojic, Nebojsa},
  journal={arXiv preprint arXiv:2303.14310},
  year={2023}
}
@article{lieber2021jurassic,
  title={Jurassic-1: Technical details and evaluation},
  author={Lieber, Opher and Sharir, Or and Lenz, Barak and Shoham, Yoav},
  journal={White Paper. AI21 Labs},
  volume={1},
  pages={9},
  year={2021}
}
@inproceedings{gardner2018allennlp,
    title = "{A}llen{NLP}: A Deep Semantic Natural Language Processing Platform",
    author = "Gardner, Matt  and
      Grus, Joel  and
      Neumann, Mark  and
      Tafjord, Oyvind  and
      Dasigi, Pradeep  and
      Liu, Nelson F.  and
      Peters, Matthew  and
      Schmitz, Michael  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of Workshop for {NLP} Open Source Software ({NLP}-{OSS})",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-2501" 
    
}


@misc{lmaas2023sun_github,
	title        = {Language Models as a Service ({LMaaS})},
	author       = {Sun, Tianxiang and He, Zhengfu and Wu, Lingling and Zheng, Chujie and Shrivastava, Disha and Xie, Tianbao and Perez, Fábio and Ye, Jiacheng and Liu, Xiangyang },
	year         = 2023,
	url          = {https://github.com/txsun1997/LMaaS-Papers},
	note         = {Accessed on September 21, 2023},
	date-added   = {September 21, 2023}
}

@article{berglund2023reversal,
  title={The Reversal Curse: LLMs trained on" A is B" fail to learn" B is A"},
  author={Berglund, Lukas and Tong, Meg and Kaufmann, Max and Balesni, Mikita and Stickland, Asa Cooper and Korbak, Tomasz and Evans, Owain},
  journal={arXiv preprint arXiv:2309.12288},
  year={2023},
  url={https://arxiv.org/pdf/2309.12288.pdf}
}

@article{van2023mitigating,
  title={Mitigating data scarcity for large language models},
  author={Van, Hoang},
  journal={arXiv preprint arXiv:2302.01806},
  year={2023},
  url={https://arxiv.org/pdf/2302.01806.pdf}
}

@article{azaria2023internal,
  title={The Internal State of an LLM Knows When its Lying},
  author={Azaria, Amos and Mitchell, Tom},
  journal={arXiv preprint arXiv:2304.13734},
  year={2023},
  url={https://arxiv.org/pdf/2304.13734.pdf}
}

@article{mccoy2023embers,
  title={Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve},
  author={McCoy, R Thomas and Yao, Shunyu and Friedman, Dan and Hardy, Matthew and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2309.13638},
  year={2023},
  url={https://arxiv.org/pdf/2309.13638.pdf}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented Generation for Knowledge-intensive NLP Tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020},
  url={https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf}
}

@article{ippolito2022preventing,
  title={Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy},
  author={Ippolito, Daphne and Tram{\`e}r, Florian and Nasr, Milad and Zhang, Chiyuan and Jagielski, Matthew and Lee, Katherine and Choquette-Choo, Christopher A and Carlini, Nicholas},
  journal={arXiv preprint arXiv:2210.17546},
  year={2022},
  url={https://arxiv.org/pdf/2210.17546.pdf}
}

@article{petrov2023when,
  title={When do Prompting and Prefix-tuning Work? A Theory of Capabilities and Limitations},
  author={Petrov, Aleksandar and Bibi, Adel and Torr, Philip},
  journal={under submission},
  year={2023},
  url={}
}

@article{kossen2023context,
  title={In-Context Learning in Large Language Models Learns Label Relationships but Is Not Conventional Learning},
  author={Kossen, Jannik and Rainforth, Tom and Gal, Yarin},
  journal={arXiv preprint arXiv:2307.12375},
  year={2023},
  url={https://arxiv.org/pdf/2307.12375.pdf}
}
@article{mckenzie2023inverse,
  title={Inverse Scaling: When Bigger Isn't Better},
  author={McKenzie, Ian R and Lyzhov, Alexander and Pieler, Michael and Parrish, Alicia and Mueller, Aaron and Prabhu, Ameya and McLean, Euan and Kirtland, Aaron and Ross, Alexis and Liu, Alisa and others},
  journal={arXiv preprint arXiv:2306.09479},
  year={2023},
  url={https://arxiv.org/pdf/2306.09479.pdf}
}

@inproceedings{schlarmann2023adversarial,
  title={On the Adversarial Robustness of Multi-modal Foundation Models},
  author={Schlarmann, Christian and Hein, Matthias},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3677--3685},
  year={2023}, 
  url={https://openaccess.thecvf.com/content/ICCV2023W/AROW/papers/Schlarmann_On_the_Adversarial_Robustness_of_Multi-Modal_Foundation_Models_ICCVW_2023_paper.pdf}
}

@article{paranjape2023art,
  title={ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models},
  author={Paranjape, Bhargavi and Lundberg, Scott and Singh, Sameer and Hajishirzi, Hannaneh and Zettlemoyer, Luke and Ribeiro, Marco Tulio},
  journal={arXiv preprint arXiv:2303.09014},
  year={2023},
  url={https://arxiv.org/pdf/2303.09014.pdf}
}

@article{JMLR:v22:20-302,
  author  = {Jorge  Pérez and Pablo BarcelÃ³ and Javier Marinkovic},
  title   = {Attention is Turing-Complete},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {75},
  pages   = {1--35},
  url     = {http://jmlr.org/papers/v22/20-302.html}
}

@article{bhattamishra2020computational,
  title={On the Computational Power of Transformers and its Implications in Sequence Modeling},
  author={Bhattamishra, Satwik and Patel, Arkil and Goyal, Navin},
  journal={arXiv preprint arXiv:2006.09286},
  year={2020},
  url={https://arxiv.org/pdf/2006.09286.pdf}
}

@article{wei2022statistically,
  title={Statistically Meaningful Approximation: a Case Study on Approximating Turing Machines with Transformers},
  author={Wei, Colin and Chen, Yining and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={12071--12083},
  year={2022},
  url={https://proceedings.neurips.cc/paper_files/paper/2022/file/4ebf1d74f53ece08512a23309d58df89-Paper-Conference.pdf}
}

@article{zhang2023can,
  title={Can Transformers Learn to Solve Problems Recursively?},
  author={Zhang, Shizhuo Dylan and Tigges, Curt and Biderman, Stella and Raginsky, Maxim and Ringer, Talia},
  journal={arXiv preprint arXiv:2305.14699},
  year={2023}, 
  url={https://arxiv.org/pdf/2305.14699.pdf}
}

@article{la2023arrt,
  title={The ARRT of Language-Models-as-a-Service: Overview of a New Paradigm and its Challenges},
  author={La Malfa, Emanuele and Petrov, Aleksandar and Frieder, Simon and Weinhuber, Christoph and Burnell, Ryan and Cohn, Anthony G and Shadbolt, Nigel and Wooldridge, Michael},
  journal={arXiv preprint arXiv:2309.16573},
  year={2023},
  url={https://arxiv.org/pdf/2309.16573.pdf}
}

@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier},
  url={https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/notes/Sonia_Hornik.pdf}
}

@article{yun2019transformers,
  title={Are transformers universal approximators of sequence-to-sequence functions?},
  author={Yun, Chulhee and Bhojanapalli, Srinadh and Rawat, Ankit Singh and Reddi, Sashank J and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:1912.10077},
  year={2019},
  url={https://arxiv.org/pdf/1912.10077.pdf}
}

@article{eldan2023s,
  title={Who’s Harry Potter? Approximate Unlearning in LLMs},
  author={Eldan, Ronen and Russinovich, Mark},
  journal={arXiv preprint arXiv:2310.02238},
  year={2023}, 
  url={https://www.thetalkingmachines.com/sites/default/files/2023-10/2310.02238.pdf}
}

@inproceedings{weiss2021thinking,
  title={Thinking like transformers},
  author={Weiss, Gail and Goldberg, Yoav and Yahav, Eran},
  booktitle={International Conference on Machine Learning},
  pages={11080--11090},
  year={2021},
  organization={PMLR}, 
  url={https://proceedings.mlr.press/v139/weiss21a/weiss21a.pdf}
}

@article{wang2019learning,
  title={Learning deep transformer models for machine translation},
  author={Wang, Qiang and Li, Bei and Xiao, Tong and Zhu, Jingbo and Li, Changliang and Wong, Derek F and Chao, Lidia S},
  journal={arXiv preprint arXiv:1906.01787},
  year={2019},
  url={https://arxiv.org/pdf/1906.01787.pdf}
}

@article{yuan2023well,
  title={How well do Large Language Models perform in Arithmetic tasks?},
  author={Yuan, Zheng and Yuan, Hongyi and Tan, Chuanqi and Wang, Wei and Huang, Songfang},
  journal={arXiv preprint arXiv:2304.02015},
  year={2023},
  url={https://arxiv.org/pdf/2304.02015.pdf}
}

@article{dolanmov,
  title={mov is Turing-complete (2013)},
  author={Dolan, Stephen},
  journal={URl: https://drwho. virtadpt. net/files/mov. pdf. Acknowledgments www. tugraz. at}
}

@article{yang2023gpt,
  title={GPT Can Solve Mathematical Problems Without a Calculator},
  author={Yang, Zhen and Ding, Ming and Lv, Qingsong and Jiang, Zhihuan and He, Zehai and Guo, Yuyi and Bai, Jinfeng and Tang, Jie},
  journal={arXiv preprint arXiv:2309.03241},
  year={2023},
  url={https://arxiv.org/pdf/2309.03241.pdf?utm_source=pocket_saves}
}

@article{dufter2022position,
  title={Position information in transformers: An overview},
  author={Dufter, Philipp and Schmitt, Martin and Sch{\"u}tze, Hinrich},
  journal={Computational Linguistics},
  volume={48},
  number={3},
  pages={733--763},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{shi2023detecting,
  title={Detecting Pretraining Data from Large Language Models},
  author={Shi, Weijia and Ajith, Anirudh and Xia, Mengzhou and Huang, Yangsibo and Liu, Daogao and Blevins, Terra and Chen, Danqi and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2310.16789},
  year={2023},
  url={https://arxiv.org/pdf/2310.16789.pdf}
}

@article{maini2023can,
  title={Can Neural Network Memorization be Localized?},
  author={Maini, Pratyush and Mozer, Michael C and Sedghi, Hanie and Lipton, Zachary C and Kolter, J Zico and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2307.09542},
  year={2023},
  url={https://arxiv.org/pdf/2307.09542.pdf}
}

@article{searle1980minds,
  title={Minds, brains, and programs},
  author={Searle, John R},
  journal={Behavioral and brain sciences},
  volume={3},
  number={3},
  pages={417--424},
  year={1980},
  publisher={Cambridge University Press}
}

@inproceedings{la2022king,
	title        = {The King Is Naked: {On} the Notion of Robustness for Natural Language Processing},
	author       = {Emanuele La Malfa and Marta Kwiatkowska},
	year         = 2022,
	booktitle    = {Thirty-Sixth {AAAI} Conference on Artificial Intelligence, {AAAI} 2022, Thirty-Fourth Conference on Innovative Applications of Artificial Intelligence, {IAAI} 2022, The Twelveth Symposium on Educational Advances in Artificial Intelligence, {EAAI} 2022 Virtual Event, February 22 - March 1, 2022},
	publisher    = {{AAAI} Press},
	pages        = {11047--11057},
	url          = {https://ojs.aaai.org/index.php/AAAI/article/view/21353},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/aaai/MalfaK22.bib},
	timestamp    = {Tue, 12 Jul 2022 01:00:00 +0200}
}
@inproceedings{barnes-etal-2019-sentiment,
	title        = {Sentiment Analysis Is Not Solved! {A}ssessing and Probing Sentiment Classification},
	author       = {Barnes, Jeremy  and {\O}vrelid, Lilja  and Velldal, Erik},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {12--23},
	doi          = {10.18653/v1/W19-4802},
	url          = {https://aclanthology.org/W19-4802}
}
@article{harris1954distributional,
	title        = {Distributional structure},
	author       = {Harris, Zellig S},
	year         = 1954,
	journal      = {Word},
	publisher    = {Taylor \& Francis},
	volume       = 10,
	number       = {2-3},
	pages        = {146--162}
}
@inproceedings{mikolov2013distributed,
	title        = {Distributed Representations of Words and Phrases and their Compositionality},
	author       = {Tom{\'{a}}s Mikolov and Ilya Sutskever and Kai Chen and Gregory S. Corrado and Jeffrey Dean},
	year         = 2013,
	booktitle    = {Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013. Proceedings of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States},
	pages        = {3111--3119},
	url          = {https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/nips/MikolovSCCD13.bib},
	editor       = {Christopher J. C. Burges and L{\'{e}}on Bottou and Zoubin Ghahramani and Kilian Q. Weinberger},
	timestamp    = {Thu, 21 Jan 2021 00:00:00 +0100}
}
@inproceedings{sinha2021masked,
	title        = {Masked Language Modeling and the Distributional Hypothesis: Order Word Matters Pre-training for Little},
	author       = {Sinha, Koustuv  and Jia, Robin  and Hupkes, Dieuwke  and Pineau, Noëlle and Williams, Adina  and Kiela, Douwe},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Online and Punta Cana, Dominican Republic},
	pages        = {2888--2913},
	doi          = {10.18653/v1/2021.emnlp-main.230},
	url          = {https://aclanthology.org/2021.emnlp-main.230}
}
@inproceedings{hermann2013not,
	title        = {{``}Not not bad{''} is not {``}bad{''}: A distributional account of negation},
	author       = {Hermann, Karl Moritz  and Grefenstette, Edward  and Blunsom, Phil},
	year         = 2013,
	booktitle    = {Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality},
	publisher    = {Association for Computational Linguistics},
	address      = {Sofia, Bulgaria},
	pages        = {74--82},
	url          = {https://aclanthology.org/W13-3209}
}
@inproceedings{zhang2020semantics,
	title        = {Semantics-Aware {BERT} for Language Understanding},
	author       = {Zhuosheng Zhang and Yuwei Wu and Hai Zhao and Zuchao Li and Shuailiang Zhang and Xi Zhou and Xiang Zhou},
	year         = 2020,
	booktitle    = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI} 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA, February 7-12, 2020},
	publisher    = {{AAAI} Press},
	pages        = {9628--9635},
	url          = {https://aaai.org/ojs/index.php/AAAI/article/view/6510},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/aaai/0001WZLZZZ20.bib},
	timestamp    = {Fri, 04 Sep 2020 01:00:00 +0200}
}
@inproceedings{bender2020climbing,
	title        = {Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data},
	author       = {Bender, Emily M.  and Koller, Alexander},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {5185--5198},
	doi          = {10.18653/v1/2020.acl-main.463},
	url          = {https://aclanthology.org/2020.acl-main.463}
}
@inproceedings{szegedy2013intriguing,
	title        = {Intriguing properties of neural networks},
	author       = {Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian J. Goodfellow and Rob Fergus},
	year         = 2014,
	booktitle    = {2nd International Conference on Learning Representations, {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
	url          = {http://arxiv.org/abs/1312.6199},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/journals/corr/SzegedyZSBEGF13.bib},
	editor       = {Yoshua Bengio and Yann LeCun},
	timestamp    = {Thu, 25 Jul 2019 01:00:00 +0200}
}
@inproceedings{le2020adversarial,
	title        = {Adversarial Filters of Dataset Biases},
	author       = {Ronan Le Bras and Swabha Swayamdipta and Chandra Bhagavatula and Rowan Zellers and Matthew E. Peters and Ashish Sabharwal and Yejin Choi},
	year         = 2020,
	booktitle    = {Proceedings of the 37th International Conference on Machine Learning, {ICML} 2020, 13-18 July 2020, Virtual Event},
	publisher    = {{PMLR}},
	series       = {Proceedings of Machine Learning Research},
	volume       = 119,
	pages        = {1078--1088},
	url          = {http://proceedings.mlr.press/v119/bras20a.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/icml/BrasSBZPSC20.bib},
	timestamp    = {Tue, 15 Dec 2020 00:00:00 +0100}
}
@inproceedings{niven2019probing,
	title        = {Probing Neural Network Comprehension of Natural Language Arguments},
	author       = {Niven, Timothy  and Kao, Hung-Yu},
	year         = 2019,
	booktitle    = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {4658--4664},
	doi          = {10.18653/v1/P19-1459},
	url          = {https://aclanthology.org/P19-1459}
}
@inproceedings{bender2021dangers,
	title        = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
	author       = {Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	pages        = {610--623}
}
@inproceedings{chen2021evaluating,
	title        = {Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models},
	author       = {Priyan Vaithilingam and Tianyi Zhang and Elena L. Glassman},
	year         = 2022,
	booktitle    = {{CHI} '22: {CHI} Conference on Human Factors in Computing Systems - 5 May 2022, Extended Abstracts},
	publisher    = {{ACM}},
	pages        = {332:1--332:7},
	doi          = {10.1145/3491101.3519665},
	url          = {https://doi.org/10.1145/3491101.3519665},
}
@inproceedings{wang2019bert,
	title        = {{BERT} has a Mouth, and It Must Speak: {BERT} as a {M}arkov Random Field Language Model},
	author       = {Wang, Alex  and Cho, Kyunghyun},
	year         = 2019,
	booktitle    = {Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {30--36},
	doi          = {10.18653/v1/W19-2304},
	url          = {https://aclanthology.org/W19-2304}
}
@inproceedings{goyal2021exposing,
	title        = {Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings},
	author       = {Kartik Goyal and Chris Dyer and Taylor Berg{-}Kirkpatrick},
	year         = 2022,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=6PvWo1kEvlT},
	biburl       = {https://dblp.org/rec/conf/iclr/GoyalDB22.bib},
	timestamp    = {Sat, 20 Aug 2022 01:00:00 +0200}
}
@inproceedings{coenen2019visualizing,
	title        = {Visualizing and Measuring the Geometry of {BERT}},
	author       = {Emily Reif and Ann Yuan and Martin Wattenberg and Fernanda B. Vi{\'{e}}gas and Andy Coenen and Adam Pearce and Been Kim},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada},
	pages        = {8592--8600},
	url          = {https://proceedings.neurips.cc/paper/2019/hash/159c1ffe5b61b41b3c4d8f4c2150f6c4-Abstract.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/nips/ReifYWVCPK19.bib},
	editor       = {Hanna M. Wallach and Hugo Larochelle and Alina Beygelzimer and Florence d'Alch{\'{e}}{-}Buc and Emily B. Fox and Roman Garnett},
	timestamp    = {Thu, 21 Jan 2021 00:00:00 +0100}
}
@inproceedings{jawahar2019does,
	title        = {What Does {BERT} Learn about the Structure of Language?},
	author       = {Jawahar, Ganesh  and Sagot, Beno{\^\i}t  and Seddah, Djam{\'e}},
	year         = 2019,
	booktitle    = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {3651--3657},
	doi          = {10.18653/v1/P19-1356},
	url          = {https://aclanthology.org/P19-1356}
}
@article{manning2020emergent,
	title        = {Emergent linguistic structure in artificial neural networks trained by self-supervision},
	author       = {Manning, Christopher D and Clark, Kevin and Hewitt, John and Khandelwal, Urvashi and Levy, Omer},
	year         = 2020,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = 117,
	number       = 48,
	pages        = {30046--30054}
}
@inproceedings{marvin2018targeted,
	title        = {Refining Targeted Syntactic Evaluation of Language Models},
	author       = {Newman, Benjamin  and Ang, Kai-Siang  and Gong, Julia  and Hewitt, John},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {3710--3723},
	doi          = {10.18653/v1/2021.naacl-main.290},
	url          = {https://aclanthology.org/2021.naacl-main.290}
}
@inproceedings{mohebbi2021exploring,
	title        = {Exploring the Role of {BERT} Token Representations to Explain Sentence Probing Results},
	author       = {Mohebbi, Hosein  and Modarressi, Ali  and Pilehvar, Mohammad Taher},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Online and Punta Cana, Dominican Republic},
	pages        = {792--806},
	doi          = {10.18653/v1/2021.emnlp-main.61},
	url          = {https://aclanthology.org/2021.emnlp-main.61}
}
@book{chomsky2009syntactic,
	title        = {Syntactic structures},
	author       = {Chomsky, Noam},
	year         = 2009,
	publisher    = {De Gruyter Mouton}
}
@article{ettinger2020bert,
	title        = {What {BERT} Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models},
	author       = {Ettinger, Allyson},
	year         = 2020,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	address      = {Cambridge, MA},
	volume       = 8,
	pages        = {34--48},
	doi          = {10.1162/tacl_a_00298},
	url          = {https://aclanthology.org/2020.tacl-1.3}
}
@inproceedings{bolukbasi2016man,
	title        = {Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings},
	author       = {Tolga Bolukbasi and Kai{-}Wei Chang and James Y. Zou and Venkatesh Saligrama and Adam Tauman Kalai},
	year         = 2016,
	booktitle    = {Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain},
	pages        = {4349--4357},
	url          = {https://proceedings.neurips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/nips/BolukbasiCZSK16.bib},
	editor       = {Daniel D. Lee and Masashi Sugiyama and Ulrike von Luxburg and Isabelle Guyon and Roman Garnett},
	timestamp    = {Thu, 21 Jan 2021 00:00:00 +0100}
}
@inproceedings{gonen2019lipstick,
	title        = {Lipstick on a Pig: {D}ebiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them},
	author       = {Gonen, Hila  and Goldberg, Yoav},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {609--614},
	doi          = {10.18653/v1/N19-1061},
	url          = {https://aclanthology.org/N19-1061}
}
@inproceedings{liang2020towards,
	title        = {Towards Debiasing Sentence Representations},
	author       = {Liang, Paul Pu  and Li, Irene Mengze  and Zheng, Emily  and Lim, Yao Chong  and Salakhutdinov, Ruslan  and Morency, Louis-Philippe},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {5502--5515},
	doi          = {10.18653/v1/2020.acl-main.488},
	url          = {https://aclanthology.org/2020.acl-main.488}
}
@inproceedings{kim2020pre,
	title        = {Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction},
	author       = {Taeuk Kim and Jihun Choi and Daniel Edmiston and Sang{-}goo Lee},
	year         = 2020,
	booktitle    = {International Conference on Learning Representations,},
	url          = {https://openreview.net/forum?id=H1xPR3NtPB},
}
@inproceedings{dunn2021learned,
	title        = {Learned Construction Grammars Converge Across Registers Given Increased Exposure},
	author       = {Dunn, Jonathan  and Tayyar Madabushi, Harish},
	year         = 2021,
	booktitle    = {Proceedings of the 25th Conference on Computational Natural Language Learning},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {268--278},
	doi          = {10.18653/v1/2021.conll-1.21},
	url          = {https://aclanthology.org/2021.conll-1.21}
}
@inproceedings{marevcek2019balustrades,
	title        = {From Balustrades to Pierre Vinken: Looking for Syntax in Transformer Self-Attentions},
	author       = {Mare{\v{c}}ek, David  and Rosa, Rudolf},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {263--275},
	doi          = {10.18653/v1/W19-4827},
	url          = {https://aclanthology.org/W19-4827}
}
@inproceedings{shen2018straight,
	title        = {Straight to the Tree: Constituency Parsing with Neural Syntactic Distance},
	author       = {Shen, Yikang  and Lin, Zhouhan  and Jacob, Athul Paul  and Sordoni, Alessandro  and Courville, Aaron  and Bengio, Yoshua},
	year         = 2018,
	booktitle    = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Melbourne, Australia},
	pages        = {1171--1180},
	doi          = {10.18653/v1/P18-1108},
	url          = {https://aclanthology.org/P18-1108}
}
@article{dunn2017computational,
	title        = {Computational learning of construction grammars},
	author       = {Dunn, Jonathan},
	year         = 2017,
	journal      = {Language and cognition},
	publisher    = {Cambridge University Press},
	volume       = 9,
	number       = 2,
	pages        = {254--292}
}
@inproceedings{hessel2021effective,
	title        = {How effective is {BERT} without word ordering? Implications for language understanding and data privacy},
	author       = {Hessel, Jack  and Schofield, Alexandra},
	year         = 2021,
	booktitle    = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {204--211},
	doi          = {10.18653/v1/2021.acl-short.27},
	url          = {https://aclanthology.org/2021.acl-short.27}
}
@book{chomsky2006language,
	title        = {Language and mind},
	author       = {Chomsky, Noam and others},
	year         = 2006,
	publisher    = {Cambridge University Press}
}
@inproceedings{gao2019representation,
	title        = {Representation Degeneration Problem in Training Natural Language Generation Models},
	author       = {Jun Gao and Di He and Xu Tan and Tao Qin and Liwei Wang and Tie{-}Yan Liu},
	year         = 2019,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=SkEYojRqtm},
}
@inproceedings{li2020sentence,
	title        = {On the Sentence Embeddings from Pre-trained Language Models},
	author       = {Li, Bohan  and Zhou, Hao  and He, Junxian  and Wang, Mingxuan  and Yang, Yiming  and Li, Lei},
	year         = 2020,
	booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {9119--9130},
	doi          = {10.18653/v1/2020.emnlp-main.733},
	url          = {https://aclanthology.org/2020.emnlp-main.733}
}
@inproceedings{ganitkevitch2013ppdb,
	title        = {{PPDB}: The Paraphrase Database},
	author       = {Ganitkevitch, Juri  and Van Durme, Benjamin  and Callison-Burch, Chris},
	year         = 2013,
	booktitle    = {Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Atlanta, Georgia},
	pages        = {758--764},
	url          = {https://aclanthology.org/N13-1092}
}
@inproceedings{devlin2018bert,
	title        = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	author       = {Devlin, Jacob  and Chang, Ming-Wei  and Lee, Kenton  and Toutanova, Kristina},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {4171--4186},
	doi          = {10.18653/v1/N19-1423},
	url          = {https://aclanthology.org/N19-1423}
}
@inproceedings{reimers2019sentence,
	title        = {Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks},
	author       = {Reimers, Nils  and Gurevych, Iryna},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Hong Kong, China},
	pages        = {3982--3992},
	doi          = {10.18653/v1/D19-1410},
	url          = {https://aclanthology.org/D19-1410}
}
@inproceedings{ravfogel2020null,
	title        = {Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection},
	author       = {Ravfogel, Shauli  and Elazar, Yanai  and Gonen, Hila  and Twiton, Michael  and Goldberg, Yoav},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {7237--7256},
	doi          = {10.18653/v1/2020.acl-main.647},
	url          = {https://aclanthology.org/2020.acl-main.647}
}
@inproceedings{hajic2009conll,
	title        = {The {C}o{NLL}-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages},
	author       = {Haji{\v{c}}, Jan  and Ciaramita, Massimiliano  and Johansson, Richard  and Kawahara, Daisuke  and Mart{\'\i}, Maria Ant{\`o}nia  and M{\`a}rquez, Llu{\'\i}s  and Meyers, Adam  and Nivre, Joakim  and Pad{\'o}, Sebastian  and {\v{S}}t{\v{e}}p{\'a}nek, Jan  and Stra{\v{n}}{\'a}k, Pavel  and Surdeanu, Mihai  and Xue, Nianwen  and Zhang, Yi},
	year         = 2009,
	booktitle    = {Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL} 2009): Shared Task},
	publisher    = {Association for Computational Linguistics},
	address      = {Boulder, Colorado},
	pages        = {1--18},
	url          = {https://aclanthology.org/W09-1201}
}
@inproceedings{wang2020infobert,
	title        = {InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective},
	author       = {Boxin Wang and Shuohang Wang and Yu Cheng and Zhe Gan and Ruoxi Jia and Bo Li and Jingjing Liu},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=hpH98mK5Puk},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/iclr/WangWCGJLL21.bib},
	timestamp    = {Thu, 12 Aug 2021 01:00:00 +0200}
}
@inproceedings{merchant2020happens,
	title        = {What Happens To {BERT} Embeddings During Fine-tuning?},
	author       = {Merchant, Amil  and Rahimtoroghi, Elahe  and Pavlick, Ellie  and Tenney, Ian},
	year         = 2020,
	booktitle    = {Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {33--44},
	doi          = {10.18653/v1/2020.blackboxnlp-1.4},
	url          = {https://aclanthology.org/2020.blackboxnlp-1.4}
}
@inproceedings{baroni2014don,
	title        = {Don{'}t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors},
	author       = {Baroni, Marco  and Dinu, Georgiana  and Kruszewski, Germ{\'a}n},
	year         = 2014,
	booktitle    = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Baltimore, Maryland},
	pages        = {238--247},
	doi          = {10.3115/v1/P14-1023},
	url          = {https://aclanthology.org/P14-1023}
}
@inproceedings{wallace2019universal,
	title        = {Universal Adversarial Triggers for Attacking and Analyzing {NLP}},
	author       = {Wallace, Eric  and Feng, Shi  and Kandpal, Nikhil  and Gardner, Matt  and Singh, Sameer},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Hong Kong, China},
	pages        = {2153--2162},
	doi          = {10.18653/v1/D19-1221},
	url          = {https://aclanthology.org/D19-1221}
}
@inproceedings{pennington2014glove,
	title        = {{G}lo{V}e: Global Vectors for Word Representation},
	author       = {Pennington, Jeffrey  and Socher, Richard  and Manning, Christopher},
	year         = 2014,
	booktitle    = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
	publisher    = {Association for Computational Linguistics},
	address      = {Doha, Qatar},
	pages        = {1532--1543},
	doi          = {10.3115/v1/D14-1162},
	url          = {https://aclanthology.org/D14-1162}
}
@article{goldberg2019assessing,
	title        = {Assessing BERT's syntactic abilities},
	author       = {Goldberg, Yoav},
	year         = 2019,
	journal      = {ArXiv preprint},
	volume       = {abs/1901.05287},
	url          = {https://arxiv.org/abs/1901.05287}
}
@inproceedings{conneau2018you,
	title        = {What you can cram into a single {\textbackslash}{\textdollar}{\&}!{\#}* vector: Probing sentence embeddings for linguistic properties},
	author       = {Alexis Conneau and Germ{\'{a}}n Kruszewski and Guillaume Lample and Lo{\"{\i}}c Barrault and Marco Baroni},
	year         = 2018,
	booktitle    = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, {ACL} 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers},
	publisher    = {Association for Computational Linguistics},
	pages        = {2126--2136},
	doi          = {10.18653/v1/P18-1198},
	url          = {https://aclanthology.org/P18-1198/},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/acl/BaroniBLKC18.bib},
	editor       = {Iryna Gurevych and Yusuke Miyao},
	timestamp    = {Fri, 06 Aug 2021 00:40:55 +0200}
}
@inproceedings{limisiewicz2020syntax,
	title        = {Syntax Representation in Word Embeddings and Neural Networks - {A} Survey},
	author       = {Tomasz Limisiewicz and David Marecek},
	year         = 2020,
	booktitle    = {Proceedings of the 20th Conference Information Technologies - Applications and Theory {(ITAT} 2020), Hotel Tyrapol, Oravsk{\'{a}} Lesn{\'{a}}, Slovakia, September 18-22, 2020},
	publisher    = {CEUR-WS.org},
	series       = {{CEUR} Workshop Proceedings},
	volume       = 2718,
	pages        = {40--50},
	url          = {http://ceur-ws.org/Vol-2718/paper16.pdf},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/itat/LimisiewiczM20.bib},
	editor       = {Martin Holena and Tom{\'{a}}s Horv{\'{a}}th and Alica Kelemenov{\'{a}} and Frantisek Mr{\'{a}}z and Dana Pardubsk{\'{a}} and Martin Pl{\'{a}}tek and Petr Sos{\'{\i}}k},
	timestamp    = {Wed, 11 Nov 2020 16:38:41 +0100}
}
@inproceedings{alzantot2018generating,
	title        = {Generating Natural Language Adversarial Examples},
	author       = {Alzantot, Moustafa  and Sharma, Yash  and Elgohary, Ahmed  and Ho, Bo-Jhang  and Srivastava, Mani  and Chang, Kai-Wei},
	year         = 2018,
	booktitle    = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Brussels, Belgium},
	pages        = {2890--2896},
	doi          = {10.18653/v1/D18-1316},
	url          = {https://aclanthology.org/D18-1316}
}
@inproceedings{jia2019certified,
	title        = {Certified Robustness to Adversarial Word Substitutions},
	author       = {Jia, Robin  and Raghunathan, Aditi  and G{\"o}ksel, Kerem  and Liang, Percy},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Hong Kong, China},
	pages        = {4129--4142},
	doi          = {10.18653/v1/D19-1423},
	url          = {https://aclanthology.org/D19-1423}
}
@book{manning1999foundations,
	title        = {Foundations of statistical natural language processing},
	author       = {Manning, Christopher and Schutze, Hinrich},
	year         = 1999,
	publisher    = {MIT press}
}
@inproceedings{huang2019achieving,
	title        = {Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propagation},
	author       = {Huang, Po-Sen  and Stanforth, Robert  and Welbl, Johannes  and Dyer, Chris  and Yogatama, Dani  and Gowal, Sven  and Dvijotham, Krishnamurthy  and Kohli, Pushmeet},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	publisher    = {Association for Computational Linguistics},
	address      = {Hong Kong, China},
	pages        = {4083--4093},
	doi          = {10.18653/v1/D19-1419},
	url          = {https://aclanthology.org/D19-1419}
}
@inproceedings{peters-etal-2018-deep,
	title        = {Deep Contextualized Word Representations},
	author       = {Peters, Matthew E.  and Neumann, Mark  and Iyyer, Mohit  and Gardner, Matt  and Clark, Christopher  and Lee, Kenton  and Zettlemoyer, Luke},
	year         = 2018,
	booktitle    = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {New Orleans, Louisiana},
	pages        = {2227--2237},
	doi          = {10.18653/v1/N18-1202},
	url          = {https://aclanthology.org/N18-1202}
}
@inproceedings{hewitt2019structural,
	title        = {{A} Structural Probe for Finding Syntax in Word Representations},
	author       = {Hewitt, John  and Manning, Christopher D.},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Minneapolis, Minnesota},
	pages        = {4129--4138},
	doi          = {10.18653/v1/N19-1419},
	url          = {https://aclanthology.org/N19-1419}
}
@inproceedings{brown2020language,
	title        = {Language Models are Few-Shot Learners},
	author       = {Tom B. Brown and Benjamin Mann and Nick Ryder and others},
	year         = 2020,
	booktitle    = {Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual},
	url          = {https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{liu2019roberta,
	title        = {Roberta: A robustly optimized bert pretraining approach},
	author       = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	year         = 2019,
	journal      = {ArXiv preprint},
	volume       = {abs/1907.11692},
	url          = {https://arxiv.org/abs/1907.11692}
}
@article{liu2020very,
	title        = {Very deep transformers for neural machine translation},
	author       = {Liu, Xiaodong and Duh, Kevin and Liu, Liyuan and Gao, Jianfeng},
	year         = 2020,
	journal      = {ArXiv preprint},
	volume       = {abs/2008.07772},
	url          = {https://arxiv.org/abs/2008.07772}
}
@inproceedings{wang2021dcn,
	title        = {DCN V2: Improved Deep \& Cross Network and Practical Lessons for Web-scale Learning to Rank Systems},
	author       = {Wang, Ruoxi and Shivanna, Rakesh and Cheng, Derek and Jain, Sagar and Lin, Dong and Hong, Lichan and Chi, Ed},
	year         = 2021,
	booktitle    = {Proceedings of the Web Conference 2021},
	pages        = {1785--1797}
}
@article{rubenstein1965contextual,
	title        = {Contextual correlates of synonymy},
	author       = {Rubenstein, Herbert and Goodenough, John B},
	year         = 1965,
	journal      = {Communications of the ACM},
	publisher    = {ACM New York, NY, USA},
	volume       = 8,
	number       = 10,
	pages        = {627--633}
}
@inproceedings{nivre2016universal,
	title        = {{U}niversal {D}ependencies v1: A Multilingual Treebank Collection},
	author       = {Nivre, Joakim  and de Marneffe, Marie-Catherine  and Ginter, Filip  and Goldberg, Yoav  and Haji{\v{c}}, Jan  and Manning, Christopher D.  and McDonald, Ryan  and Petrov, Slav  and Pyysalo, Sampo  and Silveira, Natalia  and Tsarfaty, Reut  and Zeman, Daniel},
	year         = 2016,
	booktitle    = {Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)},
	publisher    = {European Language Resources Association (ELRA)},
	address      = {Portoro{\v{z}}, Slovenia},
	pages        = {1659--1666},
	url          = {https://aclanthology.org/L16-1262}
}
@inproceedings{mrkvsic2016counter,
	title        = {Counter-fitting Word Vectors to Linguistic Constraints},
	author       = {Mrk{\v{s}}i{\'c}, Nikola  and {\'O} S{\'e}aghdha, Diarmuid  and Thomson, Blaise  and Ga{\v{s}}i{\'c}, Milica  and Rojas-Barahona, Lina M.  and Su, Pei-Hao  and Vandyke, David  and Wen, Tsung-Hsien  and Young, Steve},
	year         = 2016,
	booktitle    = {Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {San Diego, California},
	pages        = {142--148},
	doi          = {10.18653/v1/N16-1018},
	url          = {https://aclanthology.org/N16-1018}
}
@inproceedings{socher2013recursive,
	title        = {Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank},
	author       = {Socher, Richard  and Perelygin, Alex  and Wu, Jean  and Chuang, Jason  and Manning, Christopher D.  and Ng, Andrew  and Potts, Christopher},
	year         = 2013,
	booktitle    = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Seattle, Washington, USA},
	pages        = {1631--1642},
	url          = {https://aclanthology.org/D13-1170}
}
@article{kuleshov2018adversarial,
	title        = {Adversarial examples for natural language classification problems},
	author       = {Kuleshov, Volodymyr and Thakoor, Shantanu and Lau, Tingfung and Ermon, Stefano},
	year         = 2018,
	journal      = {arxiv pre-print}
}
@article{gibson2019efficiency,
	title        = {How efficiency shapes human language},
	author       = {Gibson, Edward and Futrell, Richard and Piantadosi, Steven P and Dautriche, Isabelle and Mahowald, Kyle and Bergen, Leon and Levy, Roger},
	year         = 2019,
	journal      = {Trends in cognitive sciences},
	publisher    = {Elsevier},
	volume       = 23,
	number       = 5,
	pages        = {389--407}
}
@book{miller1998wordnet,
	title        = {WordNet: An electronic lexical database},
	author       = {Miller, George A},
	year         = 1998,
	publisher    = {MIT press}
}
@inproceedings{turian2010word,
	title        = {Word Representations: A Simple and General Method for Semi-Supervised Learning},
	author       = {Turian, Joseph  and Ratinov, Lev-Arie  and Bengio, Yoshua},
	year         = 2010,
	booktitle    = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Uppsala, Sweden},
	pages        = {384--394},
	url          = {https://aclanthology.org/P10-1040}
}
@article{floridi2020gpt,
	title        = {{GPT-3}: Its nature, scope, limits, and consequences},
	author       = {Floridi, Luciano and Chiriatti, Massimo},
	year         = 2020,
	journal      = {Minds and Machines},
	publisher    = {Springer},
	volume       = 30,
	number       = 4,
	pages        = {681--694}
}
@inproceedings{la2020assessing,
	title        = {Assessing Robustness of Text Classification through Maximal Safe Radius Computation},
	author       = {La Malfa, Emanuele  and Wu, Min  and Laurenti, Luca  and Wang, Benjie  and Hartshorn, Anthony  and Kwiatkowska, Marta},
	year         = 2020,
	booktitle    = {Findings of the Association for Computational Linguistics: EMNLP 2020},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {2949--2968},
	doi          = {10.18653/v1/2020.findings-emnlp.266},
	url          = {https://aclanthology.org/2020.findings-emnlp.266}
}
@inproceedings{kusner2015word,
	title        = {From Word Embeddings To Document Distances},
	author       = {Matt J. Kusner and Yu Sun and Nicholas I. Kolkin and Kilian Q. Weinberger},
	year         = 2015,
	booktitle    = {Proceedings of the 32nd International Conference on Machine Learning, {ICML} 2015, Lille, France, 6-11 July 2015},
	publisher    = {JMLR.org},
	series       = {{JMLR} Workshop and Conference Proceedings},
	volume       = 37,
	pages        = {957--966},
	url          = {http://proceedings.mlr.press/v37/kusnerb15.html},
}
@inproceedings{dong2021towards,
	title        = {Towards Robustness Against Natural Language Word Substitutions},
	author       = {Xinshuai Dong and Anh Tuan Luu and Rongrong Ji and Hong Liu},
	year         = 2021,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=ks5nebunVn\_},
}
@article{xu2020elephant,
	title        = {Elephant in the room: An evaluation framework for assessing adversarial examples in {NLP}},
	author       = {Xu, Ying and Zhong, Xu and Yepes, Antonio Jose Jimeno and Lau, Jey Han},
	year         = 2020,
	journal      = {ArXiv preprint},
	volume       = {abs/2001.07820},
	url          = {https://arxiv.org/abs/2001.07820}
}
@inproceedings{la2021guaranteed,
	title        = {On Guaranteed Optimal Robust Explanations for {NLP} Models},
	author       = {Emanuele La Malfa and Rhiannon Michelmore and Agnieszka M. Zbrzezny and Nicola Paoletti and Marta Kwiatkowska},
	year         = 2021,
	booktitle    = {Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, {IJCAI} 2021, Virtual Event / Montreal, Canada, 19-27 August 2021},
	publisher    = {ijcai.org},
	pages        = {2658--2665},
	doi          = {10.24963/ijcai.2021/366},
	url          = {https://doi.org/10.24963/ijcai.2021/366},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/ijcai/MalfaMZPK21.bib},
	editor       = {Zhi{-}Hua Zhou},
	timestamp    = {Sun, 02 Oct 2022 16:08:04 +0200}
}
@article{goldberg2014word2vec,
	title        = {word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method},
	author       = {Goldberg, Yoav and Levy, Omer},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1402.3722}
}
@article{rogers2020primer,
	title        = {A Primer in {BERT}ology: What We Know About How {BERT} Works},
	author       = {Rogers, Anna  and Kovaleva, Olga  and Rumshisky, Anna},
	year         = 2020,
	journal      = {Transactions of the Association for Computational Linguistics},
	publisher    = {MIT Press},
	address      = {Cambridge, MA},
	volume       = 8,
	pages        = {842--866},
	doi          = {10.1162/tacl_a_00349},
	url          = {https://aclanthology.org/2020.tacl-1.54}
}
@inproceedings{madry2017towards,
	title        = {Towards Deep Learning Models Resistant to Adversarial Attacks},
	author       = {Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
	year         = 2018,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=rJzIBfZAb},
}
@inproceedings{ribeiro2020beyond,
	title        = {Beyond Accuracy: Behavioral Testing of {NLP} Models with {C}heck{L}ist},
	author       = {Ribeiro, Marco Tulio  and Wu, Tongshuang  and Guestrin, Carlos  and Singh, Sameer},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {4902--4912},
	doi          = {10.18653/v1/2020.acl-main.442},
	url          = {https://aclanthology.org/2020.acl-main.442}
}
@inproceedings{white2021non,
	title        = {A Non-Linear Structural Probe},
	author       = {White, Jennifer C.  and Pimentel, Tiago  and Saphra, Naomi  and Cotterell, Ryan},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {132--138},
	doi          = {10.18653/v1/2021.naacl-main.12},
	url          = {https://aclanthology.org/2021.naacl-main.12}
}
@inproceedings{pimentel2020information,
	title        = {Information-Theoretic Probing for Linguistic Structure},
	author       = {Pimentel, Tiago  and Valvoda, Josef  and Maudslay, Rowan Hall  and Zmigrod, Ran  and Williams, Adina  and Cotterell, Ryan},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {4609--4622},
	doi          = {10.18653/v1/2020.acl-main.420},
	url          = {https://aclanthology.org/2020.acl-main.420}
}
@inproceedings{bauer-etal-2023-semgrex,
	title        = {Semgrex and Ssurgeon, Searching and Manipulating Dependency Graphs},
	author       = {Bauer, John  and Kiddon, Chlo{\'e}  and Yeh, Eric  and Shan, Alex  and D. Manning, Christopher},
	year         = 2023,
	booktitle    = {Proceedings of the 21st International Workshop on Treebanks and Linguistic Theories (TLT, GURT/SyntaxFest 2023)},
	publisher    = {Association for Computational Linguistics},
	address      = {Washington, D.C.},
	pages        = {67--73},
	url          = {https://aclanthology.org/2023.tlt-1.7}
}
@article{radford2019language,
	title        = {Language Models are Unsupervised Multitask Learners},
	author       = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
	year         = 2019,
	journal      = {OpenAI blog},
	volume       = 1,
	number       = 8,
	pages        = 9,
    url = {https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf}
}
@inproceedings{qi2020stanza,
	title        = {{S}tanza: A Python Natural Language Processing Toolkit for Many Human Languages},
	author       = {Qi, Peng  and Zhang, Yuhao  and Zhang, Yuhui  and Bolton, Jason  and Manning, Christopher D.},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {101--108},
	doi          = {10.18653/v1/2020.acl-demos.14},
	url          = {https://aclanthology.org/2020.acl-demos.14}
}
@inproceedings{ravichander2020probing,
	title        = {Probing the Probing Paradigm: Does Probing Accuracy Entail Task Relevance?},
	author       = {Ravichander, Abhilasha  and Belinkov, Yonatan  and Hovy, Eduard},
	year         = 2021,
	booktitle    = {Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {3363--3377},
	doi          = {10.18653/v1/2021.eacl-main.295},
	url          = {https://aclanthology.org/2021.eacl-main.295}
}
@article{belinkov2022probing,
	title        = {Probing Classifiers: Promises, Shortcomings, and Advances},
	author       = {Belinkov, Yonatan},
	year         = 2022,
	journal      = {Computational Linguistics},
	publisher    = {MIT Press},
	address      = {Cambridge, MA},
	volume       = 48,
	number       = 1,
	pages        = {207--219},
	doi          = {10.1162/coli_a_00422},
	url          = {https://aclanthology.org/2022.cl-1.7}
}
@misc{ChatGPT,
	title        = {Introducing {ChatGPT}},
	author       = {{OpenAI}},
	year         = 2023,
	url          = {https://openai.com/blog/chatgpt},
	note         = {Accessed on April 11, 2023},
	date-added   = {February 5, 2023}
}
@inproceedings{jacovi2021formalizing,
	title        = {Formalizing trust in artificial intelligence: Prerequisites, causes and goals of human trust in {AI}},
	author       = {Jacovi, Alon and Marasovi{\'c}, Ana and Miller, Tim and Goldberg, Yoav},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
	pages        = {624--635}
}
@article{wang2023chatgpt,
	title        = {Is {ChatGPT} a Good Sentiment Analyzer? {A} Preliminary Study},
	author       = {Wang, Zengzhi and Xie, Qiming and Ding, Zixiang and Feng, Yi and Xia, Rui},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.04339},
	url          = {https://arxiv.org/abs/2304.04339}
}
@article{qin2023chatgpt,
	title        = {Is {ChatGPT} a general-purpose natural language processing task solver?},
	author       = {Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.06476},
	url          = {https://arxiv.org/abs/2302.06476}
}
@article{borji2023categorical,
	title        = {A categorical archive of {ChatGPT}failures},
	author       = {Borji, Ali},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.03494},
	url          = {https://arxiv.org/abs/2302.03494}
}
@article{wang2023robustness,
	title        = {On the robustness of {ChatGPT}: An adversarial and out-of-distribution perspective},
	author       = {Wang, Jindong and Hu, Xixu and Hou, Wenxin and Chen, Hao and Zheng, Runkai and Wang, Yidong and Yang, Linyi and Huang, Haojun and Ye, Wei and Geng, Xiubo and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.12095},
	url          = {https://arxiv.org/abs/2302.12095}
}

@article{ray2023chatGPT,
title = {{ChatGPT}: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope},
journal = {Internet of Things and Cyber-Physical Systems},
volume = {3},
pages = {121-154},
year = {2023},
url = {https://www.sciencedirect.com/science/article/pii/S266734522300024X},
author = {Partha Pratim Ray},
}

@article{dai2023chataug,
	title        = {{ChatAug}: Leveraging {ChatGPT} for Text Data Augmentation},
	author       = {Dai, Haixing and Liu, Zhengliang and Liao, Wenxiong and Huang, Xiaoke and Wu, Zihao and Zhao, Lin and Liu, Wei and Liu, Ninghao and Li, Sheng and Zhu, Dajiang and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.13007},
	url          = {https://arxiv.org/abs/2302.13007}
}

@article{mahowald2023dissociating,
	title        = {Dissociating language and thought in large language models: a cognitive perspective},
	author       = {Mahowald, Kyle and Ivanova, Anna A and Blank, Idan A and Kanwisher, Nancy and Tenenbaum, Joshua B and Fedorenko, Evelina},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2301.06627},
	url          = {https://arxiv.org/abs/2301.06627}
}

@misc{barnes2021time,
	title        = {Is it time to move beyond sentence classification?},
	author       = {Barnes, Jeremy},
	year         = 2021,
    url = {https://jerbarnes.github.io/downloads/keynote_AIST2021.pdf}
}
@article{raffel2020exploring,
	title        = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
	author       = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
	year         = 2020,
	journal      = {J. Mach. Learn. Res.},
	volume       = 21,
	pages        = {140:1--140:67},
	url          = {http://jmlr.org/papers/v21/20-074.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/journals/jmlr/RaffelSRLNMZLL20.bib},
	timestamp    = {Fri, 05 Feb 2021 00:00:00 +0100}
}
@article{thoppilan2022lamda,
	title        = {Lamda: Language models for dialog applications},
	author       = {Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2201.08239},
	url          = {https://arxiv.org/abs/2201.08239}
}
@inproceedings{romera2015embarrassingly,
	title        = {An embarrassingly simple approach to zero-shot learning},
	author       = {Bernardino Romera{-}Paredes and Philip H. S. Torr},
	year         = 2015,
	booktitle    = {Proceedings of the 32nd International Conference on Machine Learning, {ICML} 2015, Lille, France, 6-11 July 2015},
	publisher    = {JMLR.org},
	series       = {{JMLR} Workshop and Conference Proceedings},
	volume       = 37,
	pages        = {2152--2161},
	url          = {http://proceedings.mlr.press/v37/romera-paredes15.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/icml/Romera-ParedesT15.bib},
	editor       = {Francis R. Bach and David M. Blei},
	timestamp    = {Wed, 29 May 2019 01:00:00 +0200}
}

@article{cao2020treatment,
	title        = {Treatment response prediction and individualized identification of first-episode drug-naive schizophrenia using brain functional connectivity},
	author       = {Cao, Bo and Cho, Raymond Y and Chen, Dachun and Xiu, Meihong and Wang, Li and Soares, Jair C and Zhang, Xiang Yang},
	year         = 2020,
	journal      = {Molecular psychiatry},
	publisher    = {Nature Publishing Group UK London},
	volume       = 25,
	number       = 4,
	pages        = {906--913}
}
@misc{alpaca,
	title        = {Stanford {Alpaca}: An Instruction-following {LLaMA} model},
	author       = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto},
	year         = 2023,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	url = {https://github.com/tatsu-lab/stanford_alpaca}
}
@inproceedings{darwiche2020three,
	title        = {Three Modern Roles for Logic in {AI}},
	author       = {Darwiche, Adnan},
	year         = 2020,
	booktitle    = {Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
	pages        = {229--243}
}
@article{darwiche2020reasons,
	title        = {On The Reasons Behind Decisions},
	author       = {Darwiche, Adnan and Hirth, Auguste},
	year         = 2020,
	journal      = {ArXiv preprint},
	volume       = {abs/2002.09284},
	url          = {https://arxiv.org/abs/2002.09284}
}
@inproceedings{alvarez2018towards,
	title        = {Towards Robust Interpretability with Self-Explaining Neural Networks},
	author       = {David Alvarez{-}Melis and Tommi S. Jaakkola},
	year         = 2018,
	booktitle    = {Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr{\'{e}}al, Canada},
	pages        = {7786--7795},
	url          = {https://proceedings.neurips.cc/paper/2018/hash/3e9f0fc9b2f89e043bc6233994dfcf76-Abstract.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/nips/Alvarez-MelisJ18.bib},
	editor       = {Samy Bengio and Hanna M. Wallach and Hugo Larochelle and Kristen Grauman and Nicol{\`{o}} Cesa{-}Bianchi and Roman Garnett},
	timestamp    = {Thu, 21 Jan 2021 00:00:00 +0100}
}
@misc{bills2023language,
	title        = {Language models can explain neurons in language models},
	author       = {Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
	year         = 2023,
	url = {https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html}
}
@incollection{sep-compositionality,
	title        = {{Compositionality}},
	author       = {Szabó, Zoltán Gendler},
	year         = 2022,
	booktitle    = {The {Stanford} Encyclopedia of Philosophy},
	publisher    = {Metaphysics Research Lab, Stanford University},
	edition      = {{F}all 2022},
	editor       = {Edward N. Zalta and Uri Nodelman},
	howpublished = {\url{https://plato.stanford.edu/archives/fall2022/entries/compositionality/}}
}
@article{cattell1886time,
	title        = {The time it takes to see and name objects},
	author       = {Cattell, James McKeen},
	year         = 1886,
	journal      = {Mind},
	publisher    = {JSTOR},
	volume       = 11,
	number       = 41,
	pages        = {63--65}
}
@article{mcclelland1977role,
	title        = {The role of familiar units in perception of words and nonwords},
	author       = {McClelland, James L and Johnston, James C},
	year         = 1977,
	journal      = {Perception \& Psychophysics},
	publisher    = {Springer},
	volume       = 22,
	pages        = {249--261}
}
@article{liu2023we,
	title        = {We're Afraid Language Models Aren't Modeling Ambiguity},
	author       = {Liu, Alisa and Wu, Zhaofeng and Michael, Julian and Suhr, Alane and West, Peter and Koller, Alexander and Swayamdipta, Swabha and Smith, Noah A and Choi, Yejin},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.14399},
	url          = {https://arxiv.org/abs/2304.14399}
}
@inproceedings{blei2003latent,
	title        = {Latent Dirichlet Allocation},
	author       = {David M. Blei and Andrew Y. Ng and Michael I. Jordan},
	year         = 2001,
	booktitle    = {Advances in Neural Information Processing Systems 14 [Neural Information Processing Systems: Natural and Synthetic, {NIPS} 2001, December 3-8, 2001, Vancouver, British Columbia, Canada]},
	publisher    = {{MIT} Press},
	pages        = {601--608},
	url          = {https://proceedings.neurips.cc/paper/2001/hash/296472c9542ad4d4788d543508116cbc-Abstract.html},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/nips/BleiNJ01.bib},
	editor       = {Thomas G. Dietterich and Suzanna Becker and Zoubin Ghahramani},
	timestamp    = {Thu, 21 Jan 2021 00:00:00 +0100}
}
@article{landauer1998introduction,
	title        = {An introduction to latent semantic analysis},
	author       = {Landauer, Thomas K and Foltz, Peter W and Laham, Darrell},
	year         = 1998,
	journal      = {Discourse processes},
	publisher    = {Taylor \& Francis},
	volume       = 25,
	number       = {2-3},
	pages        = {259--284}
}
@inproceedings{brendel2017decision,
	title        = {Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models},
	author       = {Wieland Brendel and Jonas Rauber and Matthias Bethge},
	year         = 2018,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=SyZI0GWCZ},
}
@inproceedings{bassan2023towards,
	title        = {Towards Formal {XAI}: Formally Approximate Minimal Explanations of Neural Networks},
	author       = {Bassan, Shahaf and Katz, Guy},
	year         = 2023,
	booktitle    = {Tools and Algorithms for the Construction and Analysis of Systems: 29th International Conference, TACAS 2023, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2022, Paris, France, April 22--27, 2023, Proceedings, Part I},
	pages        = {187--207},
	organization = {Springer}
}
@article{wu2022verix,
	title        = {VeriX: Towards Verified Explainability of Deep Neural Networks},
	author       = {Wu, Min and Wu, Haoze and Barrett, Clark},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2212.01051},
	url          = {https://arxiv.org/abs/2212.01051}
}
@inproceedings{croce2019sparse,
	title        = {Sparse and Imperceivable Adversarial Attacks},
	author       = {Francesco Croce and Matthias Hein},
	year         = 2019,
	booktitle    = {2019 {IEEE/CVF} International Conference on Computer Vision, {ICCV} 2019, Seoul, Korea (South), October 27 - November 2, 2019},
	publisher    = {{IEEE}},
	pages        = {4723--4731},
	doi          = {10.1109/ICCV.2019.00482},
	url          = {https://doi.org/10.1109/ICCV.2019.00482},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/conf/iccv/Croce019.bib},
	timestamp    = {Thu, 05 Mar 2020 00:00:00 +0100}
}
@article{wang2019natural,
	title        = {Natural language adversarial attack and defense in word level},
	author       = {Wang, Xiaosen and Jin, Hao and He, Kun},
	year         = 2019
}
@inproceedings{pierazzi2020intriguing,
	title        = {Intriguing properties of adversarial ml attacks in the problem space},
	author       = {Pierazzi, Fabio and Pendlebury, Feargus and Cortellazzi, Jacopo and Cavallaro, Lorenzo},
	year         = 2020,
	booktitle    = {2020 IEEE symposium on security and privacy (SP)},
	pages        = {1332--1349},
	organization = {IEEE}
}
@inproceedings{morris2020reevaluating,
	title        = {Reevaluating Adversarial Examples in Natural Language},
	author       = {Morris, John  and Lifland, Eli  and Lanchantin, Jack  and Ji, Yangfeng  and Qi, Yanjun},
	year         = 2020,
	booktitle    = {Findings of the Association for Computational Linguistics: EMNLP 2020},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {3829--3839},
	doi          = {10.18653/v1/2020.findings-emnlp.341},
	url          = {https://aclanthology.org/2020.findings-emnlp.341}
}

@inproceedings{xue2020mt5,
	title        = {m{T}5: A Massively Multilingual Pre-trained Text-to-Text Transformer},
	author       = {Xue, Linting  and Constant, Noah  and Roberts, Adam  and Kale, Mihir  and Al-Rfou, Rami  and Siddhant, Aditya  and Barua, Aditya  and Raffel, Colin},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {483--498},
	doi          = {10.18653/v1/2021.naacl-main.41},
	url          = {https://aclanthology.org/2021.naacl-main.41}
}
@article{bubeck2023sparks,
	title        = {Sparks of Artificial General Intelligence: Early experiments with {GPT-4}},
	author       = {Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2303.12712},
	url          = {https://arxiv.org/abs/2303.12712}
}
@article{kocon2023chatgpt,
	title        = {{ChatGPT}: Jack of all trades, master of none},
	author       = {Koco{\'n}, Jan and Cichecki, Igor and Kaszyca, Oliwier and Kochanek, Mateusz and Szyd{\l}o, Dominika and Baran, Joanna and Bielaniewicz, Julita and Gruza, Marcin and Janz, Arkadiusz and Kanclerz, Kamil and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.10724},
	url          = {https://arxiv.org/abs/2302.10724}
}
@article{petrov2023langauge,
	title        = {Language Model Tokenizers Introduce Unfairness Between Languages},
	author       = {Petrov, Aleksandar and La Malfa, Emanuele and Torr, Philip and Bibi, Adel},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.15425},
	url          = {https://arxiv.org/abs/2305.15425}
}
@article{frank3023experimentology,
	title        = {Experimentology: An Open Science Approach to Experimental Psychology Methods},
	author       = {Frank, Michael},
	year         = 2023,
	journal      = {github project arXiv:xxxx:xxxx}
}
@inproceedings{wiegand2010survey,
	title        = {A survey on the role of negation in sentiment analysis},
	author       = {Wiegand, Michael  and Balahur, Alexandra  and Roth, Benjamin  and Klakow, Dietrich  and Montoyo, Andr{\'e}s},
	year         = 2010,
	booktitle    = {Proceedings of the Workshop on Negation and Speculation in Natural Language Processing},
	publisher    = {University of Antwerp},
	address      = {Uppsala, Sweden},
	pages        = {60--68},
	url          = {https://aclanthology.org/W10-3111}
}
@article{laskar2023systematic,
	title        = {A Systematic Study and Comprehensive Evaluation of {ChatGPT} on Benchmark Datasets},
	author       = {Laskar, Md Tahmid Rahman and Bari, M Saiful and Rahman, Mizanur and Bhuiyan, Md Amran Hossen and Joty, Shafiq and Huang, Jimmy Xiangji},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.18486},
	url          = {https://arxiv.org/abs/2305.18486}
}

@inproceedings{hou-etal-2019-modeling,
	title        = {Modeling language learning using specialized Elo rating},
	author       = {Hou, Jue  and Maximilian, Koppatz  and Hoya Quecedo, Jos{\'e} Mar{\'\i}a  and Stoyanova, Nataliya  and Yangarber, Roman},
	year         = 2019,
	booktitle    = {Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {494--506},
	doi          = {10.18653/v1/W19-4451},
	url          = {https://aclanthology.org/W19-4451}
}
@article{liang2022holistic,
	title        = {Holistic evaluation of language models},
	author       = {Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2211.09110},
	url          = {https://arxiv.org/abs/2211.09110}
}
@article{chang2023survey,
	title        = {A Survey on Evaluation of Large Language Models},
	author       = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Zhu, Kaijie and Chen, Hao and Yang, Linyi and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2307.03109},
	url          = {https://arxiv.org/abs/2307.03109}
}
@inproceedings{kiela2021dynabench,
	title        = {Dynabench: Rethinking Benchmarking in {NLP}},
	author       = {Kiela, Douwe  and Bartolo, Max  and Nie, Yixin  and Kaushik, Divyansh  and Geiger, Atticus  and Wu, Zhengxuan  and Vidgen, Bertie  and Prasad, Grusha  and Singh, Amanpreet  and Ringshia, Pratik  and Ma, Zhiyi  and Thrush, Tristan  and Riedel, Sebastian  and Waseem, Zeerak  and Stenetorp, Pontus  and Jia, Robin  and Bansal, Mohit  and Potts, Christopher  and Williams, Adina},
	year         = 2021,
	booktitle    = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {4110--4124},
	doi          = {10.18653/v1/2021.naacl-main.324},
	url          = {https://aclanthology.org/2021.naacl-main.324}
}
@article{suzgun2022challenging,
	title        = {Challenging {BIG-Bench} tasks and whether chain-of-thought can solve them},
	author       = {Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2210.09261},
	url          = {https://arxiv.org/abs/2210.09261}
}
@article{srivastava2022beyond,
	title        = {Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
	author       = {Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2206.04615},
	url          = {https://arxiv.org/abs/2206.04615}
}
@article{zhong2023agieval,
	title        = {{AGIE}val: A Human-Centric Benchmark for Evaluating Foundation Models},
	author       = {Zhong, Wanjun and Cui, Ruixiang and Guo, Yiduo and Liang, Yaobo and Lu, Shuai and Wang, Yanlin and Saied, Amin and Chen, Weizhu and Duan, Nan},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.06364},
	url          = {https://arxiv.org/abs/2304.06364}
}

@article{rombach2021highresolution,
	title        = {High-Resolution Image Synthesis with Latent Diffusion Models},
	author       = {Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
	year         = 2021,
	journal      = {arXiv preprint arXiv:2112.10752},
	url = {https://arxiv.org/abs/2112.10752}
}
@article{jacovi2023stop,
	title        = {Stop uploading test data in plain text: Practical strategies for mitigating data contamination by evaluation benchmarks},
	author       = {Jacovi, Alon and Caciularu, Avi and Goldman, Omer and Goldberg, Yoav},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.10160},
	url          = {https://arxiv.org/abs/2305.10160}
}
@article{mukherjee2023orca,
	title        = {Orca: Progressive learning from complex explanation traces of {GPT-4}},
	author       = {Mukherjee, Subhabrata and Mitra, Arindam and Jawahar, Ganesh and Agarwal, Sahaj and Palangi, Hamid and Awadallah, Ahmed},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2306.02707},
	url          = {https://arxiv.org/abs/2306.02707}
}
@inproceedings{chang2008importance,
	title        = {Importance of Semantic Representation: Dataless Classification},
	author       = {Chang, Ming-Wei and Ratinov, Lev-Arie and Roth, Dan and Srikumar, Vivek},
	year         = 2008,
	booktitle    = {AAAI},
	volume       = 2,
	pages        = {830--835},
    url          = {https://dl.acm.org/doi/10.5555/1620163.1620201}
}
@article{bai2022training,
	title        = {Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback},
	author       = {Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2204.05862},
	url          = {https://arxiv.org/abs/2204.05862}
}
@article{kaplan2020scaling,
	title        = {Scaling laws for neural language models},
	author       = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
	year         = 2020,
	journal      = {ArXiv preprint},
	volume       = {abs/2001.08361},
	url          = {https://arxiv.org/abs/2001.08361}
}
@article{shanahan2022talking,
	title        = {Talking about large language models},
	author       = {Shanahan, Murray},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2212.03551},
	url          = {https://arxiv.org/abs/2212.03551}
}
@article{niu2021review,
	title        = {A review on the attention mechanism of deep learning},
	author       = {Niu, Zhaoyang and Zhong, Guoqiang and Yu, Hui},
	year         = 2021,
	journal      = {Neurocomputing},
	publisher    = {Elsevier},
	volume       = 452,
	pages        = {48--62},
        url = {https://www.sciencedirect.com/science/article/abs/pii/S092523122100477X}
}
@inproceedings{bahdanau2014neural,
	title        = {Neural Machine Translation by Jointly Learning to Align and Translate},
	author       = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
	year         = 2015,
	booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
	url          = {http://arxiv.org/abs/1409.0473},
	bibsource    = {dblp computer science bibliography, https://dblp.org},
	biburl       = {https://dblp.org/rec/journals/corr/BahdanauCB14.bib},
	editor       = {Yoshua Bengio and Yann LeCun},
	timestamp    = {Fri, 29 Mar 2019 00:00:00 +0100}
}
@article{chowdhery2022palm,
	title        = {{PaLM}: Scaling Language Modeling with Pathways},
	author       = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2204.02311},
	url          = {https://arxiv.org/abs/2204.02311}
}
@article{wolf2019huggingface,
	title        = {{HuggingFace's }{T}ransformers: State-of-the-art Natural Language Processing},
	author       = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
	year         = 2019,
	journal      = {ArXiv preprint},
	volume       = {abs/1910.03771},
	url          = {https://arxiv.org/abs/1910.03771}
}
@misc{SaaS,
	title        = {What Does That Server Really Serve?},
	author       = {Richard Stallman},
	year         = 2010,
	url          = {https://www.bostonreview.net/articles/what-does-that-server-really-serve/}
}
@misc{open-free,
	title        = {Open Source Misses the Point},
	author       = {Richard Stallman},
	year         = 2022,
	url          = {https://www.gnu.org/philosophy/open-source-misses-the-point.html}
}
@article{ahia2023all,
	title        = {Do All Languages Cost the Same? {T}okenization in the Era of Commercial Language Models},
	author       = {Ahia, Orevaoghene and Kumar, Sachin and Gonen, Hila and Kasai, Jungo and Mortensen, David R and Smith, Noah A and Tsvetkov, Yulia},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.13707},
	url          = {https://arxiv.org/abs/2305.13707}
}

@article{carlini2022quantifying,
	title        = {Quantifying Memorization Across Neural Language Models},
	author       = {Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2202.07646},
	url          = {https://arxiv.org/abs/2202.07646}
}
@inproceedings{biderman2023pythia,
	title        = {Pythia: A Suite for Analyzing Large Language Models across Training and Scaling},
	author       = {Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin Gregory and Bradley, Herbie and O’Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
	year         = 2023,
	booktitle    = {International Conference on Machine Learning},
	pages        = {2397--2430},
	organization = {PMLR},
    url          = {https://arxiv.org/pdf/2304.01373.pdf}
}
@article{zhang2023exploring,
	title        = {Exploring the {MIT} Mathematics and {EECS} Curriculum Using Large Language Models},
	author       = {Zhang, Sarah J and Florin, Samuel and Lee, Ariel N and Niknafs, Eamon and Marginean, Andrei and Wang, Annie and Tyser, Keith and Chin, Zad and Hicke, Yann and Singh, Nikhil and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2306.08997},
	url          = {https://arxiv.org/abs/2306.08997}
}
@misc{exams-mit-chatgpt,
	title        = {No, {GPT4} can’t ace {MIT}},
	author       = {Chowdhuri, Raunak and Deshmukh, Neil and Koplow, David},
	year         = 2023,
	url          = {https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864}
}
@article{burnell2023revealing,
	title        = {Revealing the structure of language model capabilities},
	author       = {Burnell, Ryan and Hao, Han and Conway, Andrew RA and Orallo, Jose Hernandez},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2306.10062},
	url          = {https://arxiv.org/abs/2306.10062}
}
@article{scao2022bloom,
	title        = {{BLOOM}: A {176B}-Parameter Open-Access Multilingual Language Model},
	author       = {Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2211.05100},
	url          = {https://arxiv.org/abs/2211.05100}
}
@article{zini2022explainability,
	title        = {On the explainability of natural language processing deep models},
	author       = {Zini, Julia El and Awad, Mariette},
	year         = 2022,
	journal      = {ACM Computing Surveys},
	publisher    = {ACM New York, NY},
	volume       = 55,
	number       = 5,
	pages        = {1--31},
        url = {https://dl.acm.org/doi/10.1145/3529755}
}
@article{li2023evaluating,
	title        = {Evaluating {ChatGPT}'s Information Extraction Capabilities: An Assessment of Performance, Explainability, Calibration, and Faithfulness},
	author       = {Li, Bo and Fang, Gexiang and Yang, Yang and Wang, Quansen and Ye, Wei and Zhao, Wen and Zhang, Shikun},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.11633},
	url          = {https://arxiv.org/abs/2304.11633}
}
@inproceedings{maynez-etal-2020-faithfulness,
	title        = {On Faithfulness and Factuality in Abstractive Summarization},
	author       = {Maynez, Joshua  and Narayan, Shashi  and Bohnet, Bernd  and McDonald, Ryan},
	year         = 2020,
	booktitle    = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Online},
	pages        = {1906--1919},
	doi          = {10.18653/v1/2020.acl-main.173},
	url          = {https://aclanthology.org/2020.acl-main.173}
}

@article{zhou2022domain,
	title        = {Domain generalization: A survey},
	author       = {Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Xiang, Tao and Loy, Chen Change},
	year         = 2022,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	publisher    = {IEEE},
        url = {https://ieeexplore.ieee.org/document/9847099}
}
@article{aiyappa2023can,
	title        = {Can we trust the evaluation on {ChatGPT}?},
	author       = {Aiyappa, Rachith and An, Jisun and Kwak, Haewoon and Ahn, Yong-Yeol},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2303.12767},
	url          = {https://arxiv.org/abs/2303.12767}
}
@article{shen2023chatgpt,
	title        = {In {ChatGPT} we trust? {M}easuring and characterizing the reliability of {ChatGPT}},
	author       = {Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Zhang, Yang},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.08979},
	url          = {https://arxiv.org/abs/2304.08979}
}
@article{pezzelle2023dealing,
	title        = {Dealing with Semantic Underspecification in Multimodal NLP},
	author       = {Pezzelle, Sandro},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2306.05240},
	url          = {https://arxiv.org/abs/2306.05240}
}
@article{du2022measure,
	title        = {A Measure-Theoretic Characterization of Tight Language Models},
	author       = {Du, Li and Hennigen, Lucas Torroba and Pimentel, Tiago and Meister, Clara and Eisner, Jason and Cotterell, Ryan},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2212.10502},
	url          = {https://arxiv.org/abs/2212.10502}
}
@article{heron2013open,
	title        = {Open source and accessibility: advantages and limitations},
	author       = {Heron, Michael and Hanson, Vicki L and Ricketts, Ian},
	year         = 2013,
	journal      = {Journal of interaction Science},
	publisher    = {SpringerOpen},
	volume       = 1,
	number       = 1,
	pages        = {1--10},
        url          = {https://journalofinteractionscience.springeropen.com/articles/10.1186/2194-0827-1-2}
}
@book{tkacz2020wikipedia,
	title        = {Wikipedia and the Politics of Openness},
	author       = {Tkacz, Nathaniel},
	year         = 2020,
	publisher    = {University of Chicago Press},
        url          = {https://press.uchicago.edu/ucp/books/book/chicago/W/bo19085555.html}
}
@article{henkel2009champions,
	title        = {Champions of Revealing—The Role of Open Source Developers in Commercial Firms},
	author       = {Henkel, Joachim},
	year         = 2009,
	journal      = {Industrial and Corporate Change},
	publisher    = {Oxford University Press},
	volume       = 18,
	number       = 3,
	pages        = {435--471},
        url          = {https://academic.oup.com/icc/article-abstract/18/3/435/807451}
}
@article{dwivedi2023so,
	title        = {``{S}o what if {ChatGPT} wrote it?'' {M}ultidisciplinary perspectives on opportunities, challenges and implications of generative conversational {AI} for research, practice and policy},
	author       = {Dwivedi, Yogesh K and Kshetri, Nir and Hughes, Laurie and Slade, Emma Louise and Jeyaraj, Anand and Kar, Arpan Kumar and Baabdullah, Abdullah M and Koohang, Alex and Raghavan, Vishnupriya and Ahuja, Manju and others},
	year         = 2023,
	journal      = {International Journal of Information Management},
	publisher    = {Elsevier},
	volume       = 71,
	pages        = 102642,
    url          = {https://www.sciencedirect.com/science/article/pii/S0268401223000233}
}
@article{moller2023prompt,
	title        = {Is a prompt and a few samples all you need? {U}sing {GPT-4} for data augmentation in low-resource classification tasks},
	author       = {M{\o}ller, Anders Giovanni and Dalsgaard, Jacob Aarup and Pera, Arianna and Aiello, Luca Maria},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2304.13861},
	url          = {https://arxiv.org/abs/2304.13861}
}
@article{eldan2023tinystories,
	title        = {TinyStories: How Small Can Language Models Be and Still Speak Coherent {E}nglish?},
	author       = {Eldan, Ronen and Li, Yuanzhi},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.07759},
	url          = {https://arxiv.org/abs/2305.07759}
}
@article{liesenfeld2023opening,
	title        = {Opening up {ChatGPT}: Tracking openness, transparency, and accountability in instruction-tuned text generators},
	author       = {Liesenfeld, Andreas and Lopez, Alianda and Dingemanse, Mark},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2307.05532},
	url          = {https://arxiv.org/abs/2307.05532}
}
@article{kaddour2023challenges,
	title        = {Challenges and Applications of Large Language Models},
	author       = {Kaddour, Jean and Harris, Joshua and Mozes, Maximilian and Bradley, Herbie and Raileanu, Roberta and McHardy, Robert},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2307.10169},
	url          = {https://arxiv.org/abs/2307.10169}
}
@article{chen2023chatgpt,
	title        = {How is {ChatGPT}'s behavior changing over time?},
	author       = {Chen, Lingjiao and Zaharia, Matei and Zou, James},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2307.09009},
	url          = {https://arxiv.org/abs/2307.09009}
}
@article{izza2023delivering,
	title        = {Delivering Inflated Explanations},
	author       = {Izza, Yacine and Ignatiev, Alexey and Stuckey, Peter and Marques-Silva, Joao},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2306.15272},
	url          = {https://arxiv.org/abs/2306.15272}
}
@inproceedings{carlini2021extracting,
	title        = {Extracting Training Data from Large Language Models},
	author       = {Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
	year         = 2021,
	booktitle    = {30th USENIX Security Symposium (USENIX Security 21)},
	pages        = {2633--2650},
    url          = {https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting}
}
@inproceedings{holtzman2019curious,
	title        = {The Curious Case of Neural Text Degeneration},
	author       = {Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
	year         = 2020,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=rygGQyrFvH},
}
@article{rae2021scaling,
	title        = {Scaling language models: Methods, analysis \& insights from training {Gopher}},
	author       = {Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
	year         = 2021,
	journal      = {ArXiv preprint},
	volume       = {abs/2112.11446},
	url          = {https://arxiv.org/abs/2112.11446}
}
@inproceedings{chen2018execution,
	title        = {Execution-Guided Neural Program Synthesis},
	author       = {Xinyun Chen and Chang Liu and Dawn Song},
	year         = 2019,
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=H1gfOiAqYm},
}
@article{austin2021program,
	title        = {Program synthesis with large language models},
	author       = {Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
	year         = 2021,
	journal      = {ArXiv preprint},
	volume       = {abs/2108.07732},
	url          = {https://arxiv.org/abs/2108.07732}
}
@article{virtanen2019multilingual,
	title        = {Multilingual is not enough: {BERT} for Finnish},
	author       = {Virtanen, Antti and Kanerva, Jenna and Ilo, Rami and Luoma, Jouni and Luotolahti, Juhani and Salakoski, Tapio and Ginter, Filip and Pyysalo, Sampo},
	year         = 2019,
	journal      = {ArXiv preprint},
	volume       = {abs/1912.07076},
	url          = {https://arxiv.org/abs/1912.07076}
}
@article{bang2023multitask,
	title        = {A Multitask, Multilingual, Multimodal Evaluation of {ChatGPT} on Reasoning, Hallucination, and Interactivity},
	author       = {Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2302.04023},
	url          = {https://arxiv.org/abs/2302.04023}
}
@article{ahuja2023mega,
	title        = {{MEGA}: Multilingual Evaluation of Generative {AI}},
	author       = {Ahuja, Kabir and Hada, Rishav and Ochieng, Millicent and Jain, Prachi and Diddee, Harshita and Maina, Samuel and Ganu, Tanuja and Segal, Sameer and Axmed, Maxamed and Bali, Kalika and others},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2303.12528},
	url          = {https://arxiv.org/abs/2303.12528}
}
@article{zarifhonarvar2023economics,
	title        = {Economics of {ChatGPT}: A labor market view on the occupational impact of artificial intelligence},
	author       = {Zarifhonarvar, Ali},
	year         = 2023,
	journal      = {Available at SSRN 4350925},
        url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4350925}
}
@article{alregib2022explanatory,
	title        = {Explanatory Paradigms in Neural Networks},
	author       = {AlRegib, Ghassan and Prabhushankar, Mohit},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2202.11838},
	url          = {https://arxiv.org/abs/2202.11838}
}
@article{rudin2019stop,
	title        = {Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
	author       = {Rudin, Cynthia},
	year         = 2019,
	journal      = {Nature machine intelligence},
	publisher    = {Nature Publishing Group UK London},
	volume       = 1,
	number       = 5,
	pages        = {206--215},
        url = {https://www.nature.com/articles/s42256-019-0048-x}
}
@article{feng2023towards,
	title        = {Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective},
	author       = {Feng, Guhao and Gu, Yuntian and Zhang, Bohang and Ye, Haotian and He, Di and Wang, Liwei},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.15408},
	url          = {https://arxiv.org/abs/2305.15408}
}
@inproceedings{mei2023foveate,
	title        = {Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy {AI}},
	author       = {Mei, Alex and Levy, Sharon and Wang, William Yang},
	year         = 2023,
	booktitle    = {Findings of the Association for Computational Linguistics: ACL 2023},
	pages        = {11021--11036},
        url = {https://aclanthology.org/2023.findings-acl.701}
}
@article{ohmer2023evaluating,
	title        = {Evaluating task understanding through multilingual consistency: A {ChatGPT} case study},
	author       = {Ohmer, Xenia and Bruni, Elia and Hupkes, Dieuwke},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.11662},
	url          = {https://arxiv.org/abs/2305.11662}
}
@article{bommasani2021opportunities,
	title        = {On the Opportunities and Risks of Foundation Models},
	author       = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
	year         = 2021,
	journal      = {ArXiv preprint},
	volume       = {abs/2108.07258},
	url          = {https://arxiv.org/abs/2108.07258}
}
@inproceedings{liu2022aligning,
	title        = {Aligning Generative Language Models with Human Values},
	author       = {Liu, Ruibo  and Zhang, Ge  and Feng, Xinyu  and Vosoughi, Soroush},
	year         = 2022,
	booktitle    = {Findings of the Association for Computational Linguistics: NAACL 2022},
	publisher    = {Association for Computational Linguistics},
	address      = {Seattle, United States},
	pages        = {241--252},
	doi          = {10.18653/v1/2022.findings-naacl.18},
	url          = {https://aclanthology.org/2022.findings-naacl.18}
}
@article{santurkar2023whose,
	title        = {Whose opinions do language models reflect?},
	author       = {Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2303.17548},
	url          = {https://arxiv.org/abs/2303.17548}
}
@article{ganguli2022red,
	title        = {Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned},
	author       = {Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
	year         = 2022,
	journal      = {ArXiv preprint},
	volume       = {abs/2209.07858},
	url          = {https://arxiv.org/abs/2209.07858}
}
@article{peng2023you,
	title        = {Are You Copying My Model? {P}rotecting the Copyright of Large Language Models for {EaaS} via Backdoor Watermark},
	author       = {Peng, Wenjun and Yi, Jingwei and Wu, Fangzhao and Wu, Shangxi and Zhu, Bin and Lyu, Lingjuan and Jiao, Binxing and Xu, Tong and Sun, Guangzhong and Xie, Xing},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2305.10036},
	url          = {https://arxiv.org/abs/2305.10036}
}
@article{alemohammad2023self,
	title        = {Self-Consuming Generative Models Go {MAD}},
	author       = {Alemohammad, Sina and Casco-Rodriguez, Josue and Luzi, Lorenzo and Humayun, Ahmed Imtiaz and Babaei, Hossein and LeJeune, Daniel and Siahkoohi, Ali and Baraniuk, Richard G},
	year         = 2023,
	journal      = {ArXiv preprint},
	volume       = {abs/2307.01850},
	url          = {https://arxiv.org/abs/2307.01850}
}
@article{ignatiev2019abd,
	title        = {Abduction-Based Explanations for Machine Learning Models},
	author       = {Ignatiev, Alexey and Narodytska, Nina and Marques-Silva, Joao},
	year         = 2019,
	month        = {Jul.},
	journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 33,
	number       = {01},
	pages        = {1511--1519},
	doi          = {10.1609/aaai.v33i01.33011511},
	url          = {https://ojs.aaai.org/index.php/AAAI/article/view/3964}
}
@article{marques2022delivering,
	title        = {Delivering Trustworthy {AI} through Formal {XAI}},
	author       = {Marques-Silva, Joao and Ignatiev, Alexey},
	year         = 2022,
	month        = {Jun.},
	journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = 36,
	number       = 11,
	pages        = {12342--12350},
	doi          = {10.1609/aaai.v36i11.21499},
	url          = {https://ojs.aaai.org/index.php/AAAI/article/view/21499}
}
@article{turpin2023language,
	title        = {Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting},
	author       = {Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel R},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.04388},
        url = {https://arxiv.org/abs/2305.04388}
}
@article{krishna2023post,
	title        = {Post hoc explanations of language models can improve language models},
	author       = {Krishna, Satyapriya and Ma, Jiaqi and Slack, Dylan and Ghandeharioun, Asma and Singh, Sameer and Lakkaraju, Himabindu},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.11426},
    url = {https://arxiv.org/abs/2305.11426}
}
@article{hendrycks2023overview,
	title        = {An Overview of Catastrophic {AI} Risks},
	author       = {Hendrycks, Dan and Mazeika, Mantas and Woodside, Thomas},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2306.12001},
    url = {https://arxiv.org/abs/2306.12001}
}
@article{schaeffer2023emergent,
	title        = {Are Emergent Abilities of Large Language Models a Mirage?},
	author       = {Rylan Schaeffer and Brando Miranda and Sanmi Koyejo},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2304.15004},
    url = {https://arxiv.org/abs/2304.15004}
}
@article{huang2023ark,
	title        = {{ArK}: Augmented Reality with Knowledge Interactive Emergent Ability},
	author       = {Qiuyuan Huang and Jae Sung Park and Abhinav Gupta and Paul Bennett and Ran Gong and Subhojit Som and Baolin Peng and Owais Khan Mohammed and Chris Pal and Yejin Choi and Jianfeng Gao},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.00970},
    url = {https://arxiv.org/abs/2305.00970}
}
@article{schaeffer2023invalid,
	title        = {Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting},
	author       = {Rylan Schaeffer and Kateryna Pistunova and Samar Khanna and Sarthak Consul and Sanmi Koyejo},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2307.10573},
    url = {https://arxiv.org/abs/2307.10573}

}
@article{singhal2023large,
	title        = {Large language models encode clinical knowledge},
	author       = {Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others},
	year         = 2023,
	journal      = {Nature},
	publisher    = {Nature Publishing Group UK London},
	pages        = {1--9}, 
        url = {https://www.nature.com/articles/s41586-023-06291-2}
}
@article{wei2022emergent,
	title        = {Emergent Abilities of Large Language Models},
	author       = {Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
	year         = 2022,
	journal      = {Transactions on Machine Learning Research},
        url = {https://arxiv.org/abs/2206.07682}
}
@article{yao2023tree,
	title        = {Tree of thoughts: Deliberate problem solving with large language models},
	author       = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.10601},
    url = {https://arxiv.org/abs/2305.10601}
}

@article{besta2023graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Podstawski, Michal and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  journal={arXiv preprint arXiv:2308.09687},
  year={2023},
  url = {https://arxiv.org/abs/2308.09687}
}


}
@misc{sarah2020davinci,
	title        = {
		{\emph{If text-davinci-001 is a rough approximate to the model reported in the NeurIPS 2020 paper, and text-davinci-002 is ~InstructGPT in the 2022 preprint, then what is just "davinci"?

		Trying to reproduce results from a time before this naming existed} [Tweet]. Twitter}
	},
	author       = {{Sarah Wiegreffe}},
	note          = {\url{https://twitter.com/sarahwiegreffe/status/1583617355678355456}},
	entrysubtype = {Tweet},
	eprint       = {Twitter},
	date         = {2022-10-22},
        year = {2023}
}
@article{chang2023speak,
  title={Speak, memory: An archaeology of books known to {ChatGPT/GPT-4}},
  author={Chang, Kent K and Cramer, Mackenzie and Soni, Sandeep and Bamman, David},
  journal={arXiv preprint arXiv:2305.00118},
  year={2023}
}
@misc{ycombinator2023decreased,
	title        = {Experiencing decreased performance with {ChatGPT-4}},
	author       = {{Hacker News}},
	year         = 2023,
	url          = {https://news.ycombinator.com/item?id=36633995},
	note         = {Accessed on July 31, 2023},
	date-added   = {July 31, 2023}
}
@misc{ycombinator2023dumber,
	title        = {{ChatGPT} use declines as users complain about ‘dumber’ answers},
	author       = {{Hacker News}},
	year         = 2023,
	url          = {https://news.ycombinator.com/item?id=36750200},
	note         = {Accessed on July 31, 2023},
	date-added   = {July 31, 2023}
}
@misc{openai2023decreased,
	title        = {Experiencing decreased performance with {ChatGPT-4}},
	author       = {{OpenAI Community}},
	year         = 2023,
	url          = {https://community.openai.com/t/experiencing-decreased-performance-with-chatgpt-4/234269},
	note         = {Accessed on July 31, 2023},
	date-added   = {July 31, 2023}
}
@misc{eleuther2023gptmodel,
	title        = {On the Sizes of {OpenAI} {API} Models},
	author       = {Gao, Leo},
	year         = 2023,
	url          = {https://blog.eleuther.ai/gpt3-model-sizes/},
	note         = {Accessed on July 31, 2023},
	date-added   = {July 31, 2023}
}
@misc{dean2023unicorn,
	title        = {{GPT} Unicorn: A Daily Exploration of {GPT-4}'s Image Generation Capabilities},
	author       = {Adam, Dean},
	year         = 2023,
	url          = {https://adamkdean.co.uk/posts/gpt-unicorn-a-daily-exploration-of-gpt-4s-image-generation-capabilities},
	note         = {Accessed on July 31, 2023},
	date-added   = {July 31, 2023}
}
@misc{chann2023nondeterminism,
	title        = {{Non-}determinism in {GPT}-4 is caused by Sparse {MoE}},
	author       = {Chann, Sherman},
	year         = 2023,
	url          = {https://152334h.github.io/blog/non-determinism-in-gpt-4/},
	note         = {Accessed on August 5, 2023},
	date-added   = {August 5, 2023}
}


@inproceedings{pmlr-v162-sun22e,
  title = 	 {Black-Box Tuning for Language-Model-as-a-Service},
  author =       {Sun, Tianxiang and Shao, Yunfan and Qian, Hong and Huang, Xuanjing and Qiu, Xipeng},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {20841--20855},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/sun22e/sun22e.pdf},
  url = 	 {https://proceedings.mlr.press/v162/sun22e.html},
  abstract = 	 {Extremely large pre-trained language models (PTMs) such as GPT-3 are usually released as a service. It allows users to design task-specific prompts to query the PTMs through some black-box APIs. In such a scenario, which we call Language-Model-as-a-Service (LMaaS), the gradients of PTMs are usually unavailable. Can we optimize the task prompts by only accessing the model inference APIs? This paper proposes the black-box tuning framework to optimize the continuous prompt prepended to the input text via derivative-free optimization. Instead of optimizing in the original high-dimensional prompt space, which is intractable for traditional derivative-free optimization, we perform optimization in a randomly generated subspace due to the low intrinsic dimensionality of large PTMs. The experimental results show that the black-box tuning with RoBERTa on a few labeled samples not only significantly outperforms manual prompt and GPT-3’s in-context learning, but also surpasses the gradient-based counterparts, i.e., prompt tuning and full model tuning.}
}
@article{zhao2021lmturk,
  title={{LMTurk}: Few-Shot Learners as Crowdsourcing Workers in a Language-Model-as-a-Service Framework},
  author={Zhao, Mengjie and Mi, Fei and Wang, Yasheng and Li, Minglei and Jiang, Xin and Liu, Qun and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2112.07522},
  year={2021},
  url = {https://aclanthology.org/2022.findings-naacl.51}
}


@article{ding2022delta,
  title={Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models},
  author={Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and others},
  journal={arXiv preprint arXiv:2203.06904},
  year={2022},
  url={https://arxiv.org/abs/2203.06904}
}
@article{dong2022survey,
  title={A Survey on In-context Learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022},
  url={https://arxiv.org/abs/2301.00234}
}
@inproceedings{deng2022rlprompt,
    title = "{RLP}rompt: Optimizing Discrete Text Prompts with Reinforcement Learning",
    author = "Deng, Mingkai  and
      Wang, Jianyu  and
      Hsieh, Cheng-Ping  and
      Wang, Yihan  and
      Guo, Han  and
      Shu, Tianmin  and
      Song, Meng  and
      Xing, Eric  and
      Hu, Zhiting",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.222",
    pages = "3369--3391"
}
@article{li2021prefix,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}
@misc{openai2023finetuning,
	title        = {{OpenAI} Documentation - Fine-tuning},
	author       = {{OpenAI}},
	year         = 2023,
	url          = {https://platform.openai.com/docs/guides/fine-tuning},
	note         = {Accessed on August 7, 2023},
	date-added   = {August 7, 2023}
}

@article{goldberg2016primer,
  title={A Primer on Neural Network Models for Natural Language Processing},
  author={Goldberg, Yoav},
  journal={Journal of Artificial Intelligence Research},
  volume={57},
  pages={345--420},
  year={2016},
  url={https://dl.acm.org/doi/10.5555/3176748.3176757}
}

@inproceedings{hu2021lora,
  title={{LoRA}: Low-rank Adaptation of Large Language Models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url = {https://arxiv.org/abs/2106.09685}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient Transfer Learning for {NLP}},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR},
 url = {http://proceedings.mlr.press/v97/houlsby19a/houlsby19a.pdf}
}

@article{zou2023universal,
  title={Universal and Transferable Adversarial Attacks on Aligned Language Models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023},
  url = {https://arxiv.org/abs/2307.15043}
}

@article{lanham2023measuring,
  title={Measuring Faithfulness in Chain-of-Thought Reasoning},
  author={Lanham, Tamera and Chen, Anna and Radhakrishnan, Ansh and Steiner, Benoit and Denison, Carson and Hernandez, Danny and Li, Dustin and Durmus, Esin and Hubinger, Evan and Kernion, Jackson and others},
  journal={arXiv preprint arXiv:2307.13702},
  year={2023},
  url={https://www-files.anthropic.com/production/files/measuring-faithfulness-in-chain-of-thought-reasoning.pdf}
}

@article{cohn2023dialectical,
  title={Dialectical Language Model Evaluation: an Initial Appraisal of the Commonsense Spatial Reasoning Abilities of {LLM}s},
  author={Cohn, Anthony G and Hernandez-Orallo, Jose},
  journal={arXiv preprint arXiv:2304.11164},
  year={2023},
  url = {https://arxiv.org/abs/2304.11164}
}

@article{ouyang2023llm,
  title={{LLM} is Like a Box of Chocolates: the Non-determinism of {ChatGPT} in Code Generation},
  author={Ouyang, Shuyin and Zhang, Jie M and Harman, Mark and Wang, Meng},
  journal={arXiv preprint arXiv:2308.02828},
  year={2023},
  url = {https://arxiv.org/abs/2308.02828}
}

@article{liu2023agentbench,
  title={Agent{B}ench: Evaluating {LLM}s as Agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  journal={arXiv preprint arXiv:2308.03688},
  year={2023},
  url = {https://arxiv.org/abs/2308.03688}
}
@article{lu2023emergent,
  title={Are Emergent Abilities in Large Language Models just In-Context Learning?},
  author={Lu, Sheng and Bigoulaeva, Irina and Sachdeva, Rachneet and Madabushi, Harish Tayyar and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2309.01809},
  year={2023},
  url={https://arxiv.org/abs/2309.01809}
}

@article{gulcehre2023reinforced,
  title={Reinforced Self-Training ({ReST}) for Language Modeling},
  author={Gulcehre, Caglar and Paine, Tom Le and Srinivasan, Srivatsan and Konyushkova, Ksenia and Weerts, Lotte and Sharma, Abhishek and Siddhant, Aditya and Ahern, Alex and Wang, Miaosen and Gu, Chenjie and others},
  journal={arXiv preprint arXiv:2308.08998},
  year={2023},
  url={https://arxiv.org/abs/2308.08998}
}

@article{zhang2022automatic,
  title={Automatic chain of thought prompting in large language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  journal={arXiv preprint arXiv:2210.03493},
  year={2022},
  url={https://arxiv.org/abs/2210.03493}
}

@inproceedings{gardner2018allennlp,
    title = "{A}llen{NLP}: A Deep Semantic Natural Language Processing Platform",
    author = "Gardner, Matt  and
      Grus, Joel  and
      Neumann, Mark  and
      Tafjord, Oyvind  and
      Dasigi, Pradeep  and
      Liu, Nelson F.  and
      Peters, Matthew  and
      Schmitz, Michael  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of Workshop for {NLP} Open Source Software ({NLP}-{OSS})",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-2501" 
    
}


@misc{lmaas2023sun_github,
	title        = {Language Models as a Service ({LMaaS})},
	author       = {Sun, Tianxiang and He, Zhengfu and Wu, Lingling and Zheng, Chujie and Shrivastava, Disha and Xie, Tianbao and Perez, Fábio and Ye, Jiacheng and Liu, Xiangyang },
	year         = 2023,
	url          = {https://github.com/txsun1997/LMaaS-Papers},
	note         = {Accessed on September 21, 2023},
	date-added   = {September 21, 2023}
}

@article{van2023mitigating,
  title={Mitigating data scarcity for large language models},
  author={Van, Hoang},
  journal={arXiv preprint arXiv:2302.01806},
  year={2023},
  url={https://arxiv.org/pdf/2302.01806.pdf}
}

@article{azaria2023internal,
  title={The Internal State of an {LLM} Knows When its Lying},
  author={Azaria, Amos and Mitchell, Tom},
  journal={arXiv preprint arXiv:2304.13734},
  year={2023},
  url={https://arxiv.org/pdf/2304.13734.pdf}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented Generation for Knowledge-intensive NLP Tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020},
  url={https://proceedings.neurips.cc/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf}
}

@article{ippolito2022preventing,
  title={Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy},
  author={Ippolito, Daphne and Tram{\`e}r, Florian and Nasr, Milad and Zhang, Chiyuan and Jagielski, Matthew and Lee, Katherine and Choquette-Choo, Christopher A and Carlini, Nicholas},
  journal={arXiv preprint arXiv:2210.17546},
  year={2022},
  url={https://arxiv.org/pdf/2210.17546.pdf}
}

@article{petrov2023when,
  title={When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and Limitations},
  author={Petrov, Aleksandar and Bibi, Adel and Torr, Philip},
  journal={arXiv preprint arXiv:2310.19698},
  year={2023},
  url={https://arxiv.org/abs/2310.19698}
}

@article{kossen2023context,
  title={In-Context Learning in Large Language Models Learns Label Relationships but Is Not Conventional Learning},
  author={Kossen, Jannik and Rainforth, Tom and Gal, Yarin},
  journal={arXiv preprint arXiv:2307.12375},
  year={2023},
  url={https://arxiv.org/abs/2307.12375}
}

@article{mckenzie2023inverse,
  title={Inverse Scaling: When Bigger Isn't Better},
  author={McKenzie, Ian R and Lyzhov, Alexander and Pieler, Michael and Parrish, Alicia and Mueller, Aaron and Prabhu, Ameya and McLean, Euan and Kirtland, Aaron and Ross, Alexis and Liu, Alisa and others},
  journal={arXiv preprint arXiv:2306.09479},
  year={2023},
  url={https://arxiv.org/abs/2306.09479}
}

@inproceedings{schlarmann2023adversarial,
  title={On the Adversarial Robustness of Multi-modal Foundation Models},
  author={Schlarmann, Christian and Hein, Matthias},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3677--3685},
  year={2023}, 
  url={https://openaccess.thecvf.com/content/ICCV2023W/AROW/papers/Schlarmann_On_the_Adversarial_Robustness_of_Multi-Modal_Foundation_Models_ICCVW_2023_paper.pdf}
}

@article{paranjape2023art,
  title={ART: Automatic Multi-step Reasoning and Tool-use for Large Language Models},
  author={Paranjape, Bhargavi and Lundberg, Scott and Singh, Sameer and Hajishirzi, Hannaneh and Zettlemoyer, Luke and Ribeiro, Marco Tulio},
  journal={arXiv preprint arXiv:2303.09014},
  year={2023},
  url={https://arxiv.org/pdf/2303.09014.pdf}
}

@article{maynez2020faithfulness,
  title={On Faithfulness and Factuality in Abstractive Summarization},
  author={Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan},
  journal={arXiv preprint arXiv:2005.00661},
  year={2020},
  url={https://arxiv.org/pdf/2005.00661.pdf}
}

@article{zhang2023language,
  title={How Language Model Hallucinations can Snowball},
  author={Zhang, Muru and Press, Ofir and Merrill, William and Liu, Alisa and Smith, Noah A},
  journal={arXiv preprint arXiv:2305.13534},
  year={2023},
  url={https://arxiv.org/pdf/2305.13534.pdf}
}

@article{alkaissi2023artificial,
  title={Artificial Hallucinations in {ChatGPT}: Implications in Scientific Writing},
  author={Alkaissi, Hussam and McFarlane, Samy I},
  journal={Cureus},
  volume={15},
  number={2},
  year={2023},
  publisher={Cureus},
  url={https://assets.cureus.com/uploads/editorial/pdf/138667/20230219-28928-6kcyip.pdf}
}

@article{huang2023can,
  title={Can Large Language Models Explain Themselves? A Study of {LLM}-Generated Self-Explanations},
  author={Huang, Shiyuan and Mamidanna, Siddarth and Jangam, Shreedhar and Zhou, Yilun and Gilpin, Leilani H},
  journal={arXiv preprint arXiv:2310.11207},
  year={2023},
  url={https://arxiv.org/pdf/2310.11207.pdf}
}

@article{borzunov2022petals,
  title = {Petals: Collaborative Inference and Fine-tuning of Large Models},
  author = {Borzunov, Alexander and Baranchuk, Dmitry and Dettmers, Tim and Ryabinin, Max and Belkada, Younes and Chumachenko, Artem and Samygin, Pavel and Raffel, Colin},
  journal = {arXiv preprint arXiv:2209.01188},
  year = {2022},
  url = {https://arxiv.org/abs/2209.01188}
}

@article{chao2023jailbreaking,
  title={Jailbreaking Black Box Large Language Models in Twenty Queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023},
  url={https://arxiv.org/abs/2310.08419}
}

@article{liu2023jailbreaking,
  title={Jailbreaking {ChatGPT} via prompt engineering: An empirical study},
  author={Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Liu, Yang},
  journal={arXiv preprint arXiv:2305.13860},
  year={2023},
  url={https://arxiv.org/abs/2305.13860}
}

@article{yao2023fuzzllm,
  title={{FuzzLLM:} A Novel and Universal Fuzzing Framework for Proactively Discovering Jailbreak Vulnerabilities in Large Language Models},
  author={Yao, Dongyu and Zhang, Jianshu and Harris, Ian G and Carlsson, Marcel},
  journal={arXiv preprint arXiv:2309.05274},
  year={2023},
  url={https://arxiv.org/abs/2309.05274}
}

@article{pan2023survey,
  title={Survey of Vector Database Management Systems},
  author={Pan, James Jie and Wang, Jianguo and Li, Guoliang},
  journal={arXiv preprint arXiv:2310.14021},
  year={2023},
  url={https://arxiv.org/pdf/2310.14021.pdf}
}

@article{han2023comprehensive,
  title={A Comprehensive Survey on Vector Database: Storage and Retrieval Technique, Challenge},
  author={Han, Yikun and Liu, Chunjiang and Wang, Pengfei},
  journal={arXiv preprint arXiv:2310.11703},
  year={2023},
  url={https://arxiv.org/pdf/2310.11703.pdf}
}

@article{gudibande2023false,
  title={The false promise of imitating proprietary {LLM}s},
  author={Gudibande, Arnav and Wallace, Eric and Snell, Charlie and Geng, Xinyang and Liu, Hao and Abbeel, Pieter and Levine, Sergey and Song, Dawn},
  journal={arXiv preprint arXiv:2305.15717},
  year={2023}, 
  url={https://arxiv.org/pdf/2305.15717.pdf}
}

@article{perez2021attention,
  title={Attention is turing complete},
  author={P{\'e}rez, Jorge and Barcel{\'o}, Pablo and Marinkovic, Javier},
  journal={The Journal of Machine Learning Research},
  volume={22},
  number={1},
  pages={3463--3497},
  year={2021},
  publisher={JMLRORG}
}

@article{west2023generative,
  title={The Generative AI Paradox:" What It Can Create, It May Not Understand"},
  author={West, Peter and Lu, Ximing and Dziri, Nouha and Brahman, Faeze and Li, Linjie and Hwang, Jena D and Jiang, Liwei and Fisher, Jillian and Ravichander, Abhilasha and Chandu, Khyathi and others},
  journal={arXiv preprint arXiv:2311.00059},
  year={2023}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{liang2023code,
  title={Code as policies: Language model programs for embodied control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={9493--9500},
  year={2023},
  organization={IEEE}
}

@article{widjojo2023addressing,
  title={Addressing Compiler Errors: Stack Overflow or Large Language Models?},
  author={Widjojo, Patricia and Treude, Christoph},
  journal={arXiv preprint arXiv:2307.10793},
  year={2023}
}

@inproceedings{santos2023always,
  title={Always Provide Context: The Effects of Code Context on Programming Error Message Enhancement},
  author={Santos, Eddie Antonio and Prasad, Prajish and Becker, Brett A},
  booktitle={Proceedings of the ACM Conference on Global Computing Education Vol 1},
  pages={147--153},
  year={2023}
}

@inproceedings{zan2023large,
  title={Large language models meet NL2Code: A survey},
  author={Zan, Daoguang and Chen, Bei and Zhang, Fengji and Lu, Dianjie and Wu, Bingchao and Guan, Bei and Yongji, Wang and Lou, Jian-Guang},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={7443--7464},
  year={2023}
}

@article{hou2023large,
  title={Large language models for software engineering: A systematic literature review},
  author={Hou, Xinyi and Zhao, Yanjie and Liu, Yue and Yang, Zhou and Wang, Kailong and Li, Li and Luo, Xiapu and Lo, David and Grundy, John and Wang, Haoyu},
  journal={arXiv preprint arXiv:2308.10620},
  year={2023}
}

@article{yang2023code,
  title={What do code models memorize? an empirical study on large language models of code},
  author={Yang, Zhou and Zhao, Zhipeng and Wang, Chenyu and Shi, Jieke and Kim, Dongsun and Han, DongGyun and Lo, David},
  journal={arXiv preprint arXiv:2308.09932},
  year={2023}
}

@article{zhou2023algorithms,
  title={What algorithms can transformers learn? a study in length generalization},
  author={Zhou, Hattie and Bradley, Arwen and Littwin, Etai and Razin, Noam and Saremi, Omid and Susskind, Josh and Bengio, Samy and Nakkiran, Preetum},
  journal={arXiv preprint arXiv:2310.16028},
  year={2023}
}

@article{petrov2023prompting,
  title={When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and Limitations},
  author={Petrov, Aleksandar and Torr, Philip HS and Bibi, Adel},
  journal={arXiv preprint arXiv:2310.19698},
  year={2023}
}

@article{huang2024notion,
  title={A Notion of Complexity for Theory of Mind via Discrete World Models},
  author={Huang, X Angelo and La Malfa, Emanuele and Marro, Samuele and Asperti, Andrea and Cohn, Anthony and Wooldridge, Michael},
  journal={arXiv preprint arXiv:2406.11911},
  year={2024}
}

@misc{kim2023entitytrackinglanguagemodels,
      title={Entity Tracking in Language Models}, 
      author={Najoung Kim and Sebastian Schuster},
      year={2023},
      eprint={2305.02363},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.02363}, 
}

@article{sweller1991evidence,
  title={Evidence for cognitive load theory},
  author={Sweller, John and Chandler, Paul},
  journal={Cognition and instruction},
  volume={8},
  number={4},
  pages={351--362},
  year={1991},
  publisher={Taylor \& Francis}
}

@misc{kim2023fantombenchmarkstresstestingmachine,
      title={FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions}, 
      author={Hyunwoo Kim and Melanie Sclar and Xuhui Zhou and Ronan Le Bras and Gunhee Kim and Yejin Choi and Maarten Sap},
      year={2023},
      eprint={2310.15421},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.15421}, 
}

@misc{cobbe2021trainingverifierssolvemath,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      year={2021},
      eprint={2110.14168},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.14168}, 
}

@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and et al.},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@article{la2024code,
  title={Code simulation challenges for large language models},
  author={La Malfa, Emanuele and Weinhuber, Christoph and Torre, Orazio and Lin, Fangru and Cohn, Anthony and Shadbolt, Nigel and Wooldridge, Michael},
  journal={arXiv preprint arXiv:2401.09074},
  year={2024}
}

@misc{lyu2024largelanguagemodelscode,
      title={Large Language Models as Code Executors: An Exploratory Study}, 
      author={Chenyang Lyu and Lecheng Yan and Rui Xing and Wenxi Li and Younes Samih and Tianbo Ji and Longyue Wang},
      year={2024},
      eprint={2410.06667},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.06667}, 
}