\begin{figure}
    \centering
    \subfloat[Score covariance]{
    \label{fig:computer-sc-cov-1B-3B}
    \includegraphics[width=0.3\linewidth]{./figures/mmlu/covariance/college_computer_science/cov_Llama-3.2-3B-Instruct_Llama-3.2-1B-Instruct_kde.pdf}
    }
    \hspace{1mm}
    \subfloat[Variance of the score difference]{
    \label{fig:computer-sc-var-1B-3B}
    \includegraphics[width=0.3\linewidth]{./figures/mmlu/variance/college_computer_science/var_Llama-3.2-3B-Instruct_Llama-3.2-1B-Instruct_kde.pdf}
    }
    \hspace{1mm}
    \subfloat[Estimation error vs. \# samples ]{
    \label{fig:computer-sc-err-1B-3B}
    \includegraphics[width=0.3\linewidth]{./figures/mmlu/error/college_computer_science/error_Llama-3.2-3B-Instruct_Llama-3.2-1B-Instruct.pdf}
    }
    \caption{\textbf{Comparison between \texttt{Llama-3.2-1B-Instruct} and \texttt{Llama-3.2-3B-Instruct} on multiple-choice questions from the MMLU dataset.}
    % using coupled and independent autoregressive generation.} 
    Panel (a) shows the kernel density estimate (KDE) of the covariance between the scores of the two LLMs on each question under coupled generation; the dashed line corresponds to the average value. Panel (b) shows the KDE of the variance of the difference between the scores of the LLMs on each question under coupled and independent generation; the highlighted point corresponds to the median value. Panel (c) shows the absolute error in the estimation of the expected difference between the scores of the LLMs against the number of samples; for each point on the x-axis, we perform $1{,}000$ sub-samplings and shaded areas correspond to $95\%$ confidence intervals. Across all panels, we use all questions from the knowledge area ``college computer science'' of MMLU. We obtained qualitatively similar results for other knowledge areas (refer to Appendix~\ref{app:mmlu}).}
    \label{fig:mmlu-1B-vs-3B-college-cs}
\end{figure}

% 1. brief description of experiments conducted
In this section, we evaluate several large language models from the \texttt{Llama} family under coupled and independent autoregressive generation using: (i) the benchmark dataset MMLU~\cite{hendrycks2021measuring} and (ii) pairwise comparisons between outputs of the LLMs when prompted using open-ended questions from the LMSYS Chatbot Arena platform~\cite{lmsys2023chatbot}.
%
In all our experiments, the LLMs use an implementation of the Gumbel-Max SCM~\cite{chatzi2024counterfactual} as a sampler both under coupled and independent autoregressive generation.
%
For details on hardware, datasets and models used for experiments, refer to Appendix~\ref{app:add_exp}.

\subsection{Evaluation on the MMLU dataset}\label{sec:mmlu}
%
In this section, we compare three LLMs of different sizes, namely, \texttt{Llama-3.1-8B-Instruct} and \texttt{Llama-3.2-\{1B, 3B\}-Instruct}, using the MMLU benchmark dataset~\cite{hendrycks2021measuring}, which comprise $14{,}042$ multiple choice questions covering $52$ knowledge areas.
% 
Recall that our theoretical results in Section~\ref{sec:individual} suggest that coupled autoregressive generation requires fewer samples than independent generation to reliably estimate the competitive advantage of one LLM against another in certain canonical settings. Here, our goal is to empirically investigate to what extent these results generalize to evaluations based on 
% each of the knowledge areas in 
the MMLU dataset.

% TODO: Perhaps put the system promppt in Appendix 
% -Setup: 
% -Number of choices, 
% areas we focus on here (other areas in appendix)
% -GUmbel max
% -repeat each question 10 times
% -- what is the R score 
\xhdr{Experimental setup} 
%
In our experiments, for each multiple choice question in the MMLU benchmark dataset, we provide the question itself together with the available options ($4$ for each question, indexed from A to D) as an input prompt to the LLMs. 
% 
Further, we instruct the LLMs to generate an output sequence comprising only the index of the selected option through a system prompt---refer to Appendix~\ref{app:add_exp} for the exact prompt. 
% 
To evaluate the outputs provided by each LLM, we use a binary score $R \in \{0,1\}$, which indicates whether the LLM output is the (single) correct ($R=1$) or incorrect $(R=0)$ answer of the given options.
% 
% For reproducibility, 
To obtain reliable conclusions,
we experiment with each multiple choice question $10$ times, each time using a (different) random seed to generate the Gumbel noise variables used by the sampler. 
% Gumbel-Max SCM. 
%
Due to space constraints, in what follows, we compare \texttt{Llama-3.2-1B-Instruct} and \texttt{Llama-3.2-3B-Instruct} on the knowledge area ``college computer science''. In Appendix~\ref{app:mmlu}, we provide further results on other knowledge areas and other pairs of LLMs.  

\xhdr{Results} 
%
Figures~\ref{fig:computer-sc-cov-1B-3B} and~\ref{fig:computer-sc-var-1B-3B} show that the scores of the LLMs are positively correlated under coupled generation and thus the variance of the difference in scores is lower under coupled generation than under independent, in agreement with Proposition~\ref{prop:variance}.
% 
Further, we compute the error in the estimation of the expected difference in scores resulting from using the two approaches as a function of the available sample size. To this end, we first estimate the expected score difference using $1{,}000$ samples and consider this as (a proxy of) the ground truth. Then, we compute the absolute estimation error achieved by independent and coupled generation while sub-sampling the original samples across various sample sizes.
% 
Figure~\ref{fig:computer-sc-err-1B-3B} summarizes the results, which show that, as expected from our theoretical analysis, a lower variance of the difference in scores under coupled generation leads to a reduction in the number of samples required to achieve equivalent error in the estimation of the expected difference between the scores of the LLMs.
% 
Perhaps surprisingly, we find that this reduction can, in practice, be quite large. For example, to achieve an estimation error of $\approx$$0.034$, coupled generation needs $40$\% fewer samples than independent generation. 


\begin{figure}[h]
\centering
\includegraphics[width=0.47\linewidth]{figures/lmsys/8B-8b.pdf}
%
\caption{
\textbf{Empirical win-rate of \texttt{Llama-3.1-8B-Instruct-bnb-8bit} against any other LLM on questions from the LMSYS-Chat-1M dataset.} 
%
% Empirical estimate of the win-rate  under coupled autoregressive generation as 
% given by Eq.~\ref{eq:coupled-generation-win-rates} and under independent 
% generation generation as given by  Eq.~\ref{eq:independent-generation-win-
% rates}. 
%
Each empirical win-rate is computed using 
pairwise comparisons between the outputs 
% of the LLM above and any other LLM over 
to $500$ questions with $10$ (different) random seeds under both coupled and independent generation. 
%
The error bars correspond to 95\% confidence intervals. For each pair of empirical win-rates under coupled and independent generation, we conduct a two-tailed z-test, to test the null hypothesis that the empirical win-rates are the same; (\fourstars, \threestars) indicate $p$-values ($<0.0001$, $< 0.001$). We obtain qualitatively similar results for other LLMs (refer to Appendix~\ref{app:lmsys}).
% \textbf{
% Win-rates achieved by six different LLMs from the \texttt{Llama} family on the LMSYS-Chat-1M dataset using independent and coupled autoregressive token generator.}
% The plot shows using coupled autoregressive token generator, the win-rates derived from pairwise comparisons differ sufficiently as compared with independent autoregressive generator. 
}
\label{fig:win_rate}
\end{figure}

\subsection{Evaluation on the LMSYS-Chat-1M Dataset}
% 
In this section, we compare the same three LLMs as in the previous section
% , namely, \texttt{Llama-3.1-8B-Instruct} and 
% \texttt{Llama-3.2-\{1B, 3B\}-Instruct}, 
as well as three quantized variants\footnote{Refer to Appendix~\ref{app:add_exp} for more details on the quantized variants.}, namely, \texttt{Llama-3.1-8B-Instruct-\{AWQ-INT4, bnb-4bit, bnb-8bit\}}, using pairwise comparisons between their outputs by a strong LLM, when prompted with open-ended questions from the LMSYS Chatbot Arena platform~\cite{lmsys2023chatbot}. 
%
Similarly as in the previous section, here, our goal is to investigate to what extent the theoretical results derived in Section~\ref{sec:pairwise}, which show that the win-rates under coupled and independent autoregressive generation are different in certain canonical settings, generalize.

\xhdr{Experimental setup} %
%
We experiment with $500$ questions from the LMSYS-Chat-1M dataset~\cite{zheng2024lmsys}. We provide the question itself as an input prompt to the LLMs, and instruct them to generate a concise response as an output through a system prompt.
% 
Further, similarly as elsewhere~\cite{chatzi2024prediction,li2024llms,boyeau2024autoeval,gera2024justrank,li2023generative,zheng2023judging}, we use a strong LLM, namely, \texttt{GPT-4o-2024-11-20}, as a judge. 
%
More specifically, for each question and pair of outputs provided by two different LLMs, we prompt the judge to respond which of the two outputs it prefers, but allowing the judge to declare a tie---for the exact prompts we use, refer to Appendix~\ref{app:add_exp}.
%
Given these pairwise comparisons, to evaluate the outputs provided by each LLM, we use the win-rate achieved by each LLM against each other.
%
To obtain reliable conclusions, similarly as in the previous section, we repeat each experiment $10$ times, each time using a (different) random seed to generate the Gumbel noise variables used by the Gumbel-Max SCM.
% 
% In Table~\ref{tab:ranking} and Figure~\ref{fig:win_rate}, we use \texttt{8B}, \texttt{3B}, and \texttt{1B} to refer to \texttt{Llama-3.1-8B-Instruct} and   \texttt{Llama-3.2-\{3B, 1B\}-Instruct} respectively, and \texttt{8B-bnb-8bit}, \texttt{8B-bnb-4bit}, and \texttt{8B-AWQ-INT4} to refer to \texttt{Llama-3.1-8B-Instruct-\{bnb-8bit, bnb-4bit, AWQ-INT4\}} to improve readability. 

\xhdr{Results}
%
We find that the empirical win-rate of each LLM against any other LLM is generally lower under coupled generation than under independent generation, as shown in Figure~\ref{fig:win_rate} for \texttt{Llama-3.1-8B-Instruct-bnb-8bit} and Figure~\ref{fig:lmsys-all-llms} in Appendix~\ref{app:lmsys} for other LLMs.
% 
Moreover, whenever the LLMs under comparison are \textit{sufficiently} similar, the difference between win-rates is statistically significant, suggesting that our theoretical results may generalize beyond the canonical setting discussed in Section~\ref{sec:pairwise}.
% against \texttt{Llama-3.1-8B-Instruct}, \texttt{Llama-3.1-8B-Instruct-AWQ-
% INT4} and \texttt{Llama-3.1-8B-Instruct-bnb-4bit}
%
% differs with very high statistical significance  
% under coupled and under independent autoregressive generation.
%
% % 
%
We hypothesize that this is partially due to an increase in the number of ties under coupled autoregressive generation. For example, for \texttt{Llama-3.1-8B-Instruct-bnb-8bit}, we observe a $24\%$, $11\%$, $15\%$ increase in the number of ties in the pairwise comparisons against \texttt{Llama-3.1-8B-Instruct}, \texttt{Llama-3.1-8B-Instruct-bnb-4bit}, and \texttt{Llama-3.1-8B-Instruct-AWQ-INT4}. 
%
Remarkably, the difference in empirical win-rates 
%  
leads to differences in the rankings derived from the average win-rates, as shown in Table~\ref{tab:ranking}. 
%
Under independent generation, the average win-rates achieved by \texttt{Llama-3.1-8B-Instruct} and \texttt{Llama-3.1-8B-Instruct-bnb-8bit} are statistically indistinguishable and thus they are both ranked at the top.
%
However, under coupled generation, \texttt{Llama-3.1-8B-Instruct} has a competitive advantage against \texttt{Llama-3.1-8B-Instruct-bnb-8bit}, and it is ranked at the top.
% 
% TO ADD: hypothesis test for first 2 models




\begin{table}[t]
    \centering
    \setlength{\tabcolsep}{4pt}
    \small
    \begin{tabular}{l c c c c}
    \toprule & \multicolumn{2}{c}{Coupled} &  \multicolumn{2}{c}{Independent} \\
    \cmidrule(r{1mm}){2-3} \cmidrule(l{1mm}){4-5}
    {LLM} & Rank & Avg. win-rate 
    & Rank & Avg. win-rate \\ 
    \midrule \texttt{8B} & 1 & 0.3670 $\pm$0.0020 & 1 & 0.3863 $\pm$0.0020 \\ 
    \texttt{bnb-8bit} & 2 & 0.3562 $\pm$0.0020 & 1 & 0.3825 $\pm$0.0020 \\
    \texttt{bnb-4bit} & 3 & 0.3339 $\pm$0.0020 & 3 & 0.3463 $\pm$0.0020 \\
    \texttt{AWQ-INT4} & 4 & 0.3164 $\pm$0.0019 & 4 & 0.3310 $\pm$0.0019 \\
    \texttt{3B} & 5 & 0.2787 $\pm$0.0019 & 5 & 0.2828 $\pm$0.0019 \\
    \texttt{1B} & 6 & 0.1650 $\pm$0.0015 & 6 & 0.1664 $\pm$0.0015 \\ \bottomrule
    \end{tabular}
    \caption{
    \textbf{Average win-rate and ranking of each LLM on questions from the LMSYS-Chat-1M dataset.}
    %
    To estimate the average win-rate of each LLM, along with $95\%$ confidence intervals, we use the pairwise comparisons between the outputs of all pairs of LLMs using all $500$ questions with $10$ (different) random seeds under both coupled and independent generation. 
    %
    To derive the rankings, for each LLM, we choose the lowest ranking provided by the method of~\citet{chatzi2024prediction}.}\label{tab:ranking} 
    \vspace{-5mm}
\end{table}

% \begin{table}[]
%     \caption{
%     \textbf{Average win-rate and ranking of each LLM on questions from the LMSYS-Chat-1M dataset.}
%     %
%     To estimate the average win-rate of each LLM, along with $95\%$ confidence intervals, we use the pairwise comparisons between the outputs of all pairs of LLMs using all $500$ questions with $10$ (different) random seeds under both coupled and independent generation. 
%     %
%     To derive the rankings, for each LLM, we choose the lowest ranking provided by the method of Chatzi et al.~\citep{chatzi2024prediction}.
% %
%    % To obtain the ranking of each LLM, we use the pairwise comparisons between the outputs of all pairs of LLMs, for all $500$ questions and all $10$ repetitions under coupled and independent generation, and apply the method by Chatzi et al.~\citep{chatzi2024prediction}. Together with the average win-rates we provide $95\%$ confidence intervals.
%     } 
%     \label{tab:ranking}
%     \centering
%     \begin{tabular}{lcccc}
%     \toprule & & Coupled &  &  Independent \\
%     \midrule LLM & Rank & Avg. win-rate 
%     & Rank & Avg. win-rate \\ 
%     \midrule \texttt{8B} & 1 & 0.3670 $\pm$0.0020 & 1 & 0.3863 $\pm$0.0020 \\ 
%     \texttt{bnb-8bit} & 2 & 0.3562 $\pm$0.0020 & 1 & 0.3825 $\pm$0.0020 \\
%     \texttt{bnb-4bit} & 3 & 0.3339$\pm$0.0020 & 3 & 0.3463 $\pm$0.0020 \\
%     \texttt{AWQ-INT4} & 4 & 0.3164 $\pm$0.0019 & 4 & 0.3310 $\pm$0.0019 \\
%     \texttt{3B} & 5 & 0.2787 $\pm$0.0019 & 5 & 0.2828 $\pm$0.0019 \\
%     \texttt{1B} & 6 & 0.1650 $\pm$0.0015 & 6 & 0.1664 $\pm$0.0015 \\ \bottomrule
%     \end{tabular}
% \end{table}
% %