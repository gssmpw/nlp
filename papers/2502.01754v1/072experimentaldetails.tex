\vspace{-2mm}

\xhdr{Hardware setup} Our experiments are executed on a compute server equipped with 2 $\times$ Intel Xeon Gold 5317 CPU, $1{,}024$ GB main memory, and $2$ $\times$ A100 Nvidia Tesla GPU ($80$ GB, Ampere Architecture). In each experiment a single Nvidia A100 GPU is used.


\xhdr{Datasets} 
As a benchmark dataset, we use Measuring Massive Multitask Language Understanding dataset (MMLU)~\cite{hendrycks2021measuring} consisting of $14{,}042$ questions covering $52$ diverse knowledge areas with each question offering four possible choices indexed from A to D, and a ground-truth answer. For pairwise comparison tasks, we use the first $500$ questions from the LMSYS-Chat-1M dataset~\cite{zheng2024lmsys}.

\xhdr{Models} In our experiments, we 
% evaluate popular large language models from the \texttt{Llama} family sharing 
% the same token vocabulary.  
%Specifically, we 
use \texttt{Llama-3.1-8B-Instruct}, its quantized variants \texttt{Llama-3.1-8B-Instruct-\{AWQ-INT4, bnb-4bit, bnb-8bit\}} and \texttt{Llama-3.2-\{1B, 3B\}-Instruct} models. The models are obtained from \texttt{Hugging Face}, and the quantised LLM variants \texttt{Llama-3.1-8B-Instruct-\{bnb-4bit, bnb-8bit\}} are built using the \texttt{bitsandbytes} library~\cite{bitsnbytes2024bits}.

\xhdr{Prompts} To instruct LLMs for generating output, we use the system prompt in Table~\ref{app:sys_prompt_2} for the MMLU dataset and Table~\ref{app:sys_prompt_3} for the LMSYS-Chat-1M dataset. Further, to perform pairwise comparisons of outputs of different LLMs, we use the system prompt in Table~\ref{app:sys_prompt_1}, which is adapted from~\cite{chiang2024chatbot}, to prompt the strong LLM.

\begin{table}[h]
\centering
\begin{tcolorbox}[
    colframe=white,      % Border color
    colback=gray!14,     % Background color
    boxrule=0.5mm,       % Border thickness
    arc=4mm,             % Rounded corners
    left=3mm,            % Left margin
    right=3mm,           % Right margin
    top=3mm,             % Top margin
    bottom=3mm           % Bottom margin
]
\begin{tabular}{ m{15.2cm} }
\rowcolor{gray!14} 
    \textbf{System:} Please act as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user prompt displayed below. Your job is to evaluate which assistant's answer is better. When evaluating the assistants' answers, compare both assistants' answers. You must identify and correct any mistakes or inaccurate information. Then consider if the assistant's answers are helpful, relevant, and concise. Helpful means the answer correctly responds to the prompt or follows the instructions. Note when user prompt has any ambiguity or more than one interpretation, it is more helpful and appropriate to ask for clarifications or more information from the user than providing an answer based on assumptions. Relevant means all parts of the response closely connect or are appropriate to what is being asked. Concise means the response is clear and not verbose or excessive. Then consider the creativity and novelty of the assistant's answers when needed. Finally, identify any missing important information in the assistants' answers that would be beneficial to include when responding to the user prompt. do not provide any justification or explanation for your response. You must output only one of the following choices as your final verdict: 

    \vspace{2mm}
    `A' if the response of assistant A is better
    
    \vspace{1mm}
    `B' if the response of assistant B is better
    
    \vspace{1mm}
    `Tie' if the responses are tied
\end{tabular}
\end{tcolorbox}
\vspace{-3mm}
\caption{\label{app:system_prompt}System prompt used for obtaining pairwise preferences using \texttt{GPT-4o-2024-11-20} as the judge.}
\label{app:sys_prompt_1}
\end{table}


\vspace{-3mm}

\begin{table}[h]
\centering
\begin{tcolorbox}[
    colframe=white,      % Border color
    colback=gray!14,     % Background color
    boxrule=0.5mm,       % Border thickness
    arc=4mm,             % Rounded corners
    left=3mm,            % Left margin
    right=3mm,           % Right margin
    top=3mm,             % Top margin
    bottom=3mm           % Bottom margin
]
\begin{tabular}{ m{15.2cm} }
    \rowcolor{gray!14}
    \textbf{System:} You will be given multiple choice questions. Please reply with a single character `A', `B', `C', or `D' only. DO NOT explain your reply.
\end{tabular}
\end{tcolorbox}
\vspace{-3mm}
\caption{System prompt used for the MMLU dataset.}
\label{app:sys_prompt_2}
\end{table}


\vspace{-3mm}

\begin{table}[h]
\centering
\begin{tcolorbox}[
    colframe=white,      % Border color
    colback=gray!14,     % Background color
    boxrule=0.5mm,       % Border thickness
    arc=4mm,             % Rounded corners
    left=3mm,            % Left margin
    right=3mm,           % Right margin
    top=3mm,             % Top margin
    bottom=3mm           % Bottom margin
]
\begin{tabular}{ m{15.2cm} }
    \rowcolor{gray!14}
    \textbf{System:} Keep your responses short and to the point.
\end{tabular}
\end{tcolorbox}
\vspace{-3mm}
\caption{System prompt used for the LMSYS Chatbot Arena dataset.}
\label{app:sys_prompt_3}
\end{table}




