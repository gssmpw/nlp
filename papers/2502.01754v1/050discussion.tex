In this section, we discuss several aspects of our work, which we believe are important to consider and may serve as a basis for future research. 

\xhdr{Model assumptions}
%
Our theoretical analysis of coupled autoregressive generation focuses on sampling mechanisms that satisfy counterfactual stability~\citep{oberst2019counterfactual}. Although counterfactual stability has been shown to be a desirable property for causal mechanisms in SCMs and, more specifically, for causal mechanisms used for sampling in LLMs~\citep{chatzi2024counterfactual}, counterfactual stability may not always be appropriate and should be justified by domain specific knowledge~\citep{haugh2023counterfactual}. 
%
In this context, it is also worth mentioning that the Gumbel-Max SCM is not the only SCM that satisfies counterfactual stability~\citep{lorberbom2021learning,haugh2023counterfactual}. Therefore, it would be interesting to understand the sensitivity of coupled autoregressive generation to this specific choice of SCM as well as extending our theoretical analysis to sampling mechanisms satisfying other alternative properties~\citep{vlontzos2023estimating}. 

\xhdr{Practical considerations}
Our experimental results and theoretical analysis suggest that coupled autoregressive generation is most advantageous over independent autoregressive generation whenever the LLMs under comparison are sufficiently close in terms of their next-token distributions.
%
Motivated by this observation, it would be important to identify which parts of the LLM development pipeline (\eg, the LLMs' architectures, training data, or fine-tuning process) lead, in practice, to sufficiently small changes in the next-token distributions for coupled autoregressive generation to be most beneficial.

Our causal model for coupled autoregressive generation assumes that the LLMs under comparison share the same vocabulary. However, in practice, this may not hold since models use different tokenizers---different families of tokenizers may even use different low-level representations for tokens that appear to be the same at the string level.\footnote{For example, certain tokenizers represent spaces between words with the unicode character \texttt{U+2581}, while others use \texttt{U+0120}.} 
%
One could think of naively lifting this assumption by merging the vocabularies of different LLMs, however, we empirically found that, using this strategy, different LLMs end up using different tokens (and thus noise values) to generate the same responses and thus coupled autoregressive generation provides significantly lower gains.
%
Extending our causal model for coupled autoregressive generation to LLMs with different tokenizers is an interesting, albeit challenging, direction for future work.

\xhdr{Evaluation}
%
We have conducted experiments using LLMs from the \texttt{Llama} family, namely \texttt{Llama-3.1-8B-Instruct} and \texttt{Llama-3.2-\{1B, 3B\}-Instruct}, and quantized versions thereof. It would be interesting to conduct experiments with LLMs from other families and also consider fine-tuned versions of them to understand how coupled autoregressive generation behaves in different settings. Furthermore, we have experimented with (i) a single benchmark dataset (\ie, MMLU) and (ii) a single dataset of prompts for pairwise comparisons (\ie, LMSYS Chatbot Arena), where we have used a strong LLM as a judge (\ie, \texttt{GPT-4o-2024-11-20}) and win-rate as an evaluation metric. 
%
To better understand the benefits of coupled autoregressive generation, it would be important to experiment with additional datasets, pairwise comparisons made by humans, and additional evaluation metrics based on, \eg, the Elo rating system~\cite{askell2021general,dettmers2024qlora,bai2022training,wu2023chatarena,lin2023llm} and the Bradley-Terry model~\cite{chiang2024chatbot,boyeau2024autoeval}.