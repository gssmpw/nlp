% 1. Large language models and randomization
State of the art large language models rely on randomization to respond to a prompt. As an immediate consequence, a model may respond differently to the same prompt if asked multiple times.
%
% 2. Evaluation/ranking should control for randomness
In this work, we argue that the evaluation and ranking of large language models should control for the randomization underpinning their functioning.
%
% 3. Causal model of coupled autoregressive generation 
Our starting point is the development of a causal model for coupled autoregressive generation, which allows different large language models to sample responses with the same source of randomness.
%
% 4. Theoretical properties of coupled autoregressive generation for individual task and pairwise comparison tasks
Building upon our causal model, we first show that, on evaluations based on benchmark datasets, coupled autoregressive generation leads to the same conclusions as vanilla autoregressive generation but using provably fewer samples. However, we further show that, on evaluations based on (human) pairwise comparisons, coupled and vanilla autoregressive generation can surprisingly lead to different rankings when comparing more than two models, even with an infinite amount of samples. This suggests that the apparent advantage of a model over others in existing evaluation protocols may not be genuine but rather confounded by the randomness inherent to the generation process.
% 
% 5. Experiments on several LLMs from Llama
To illustrate and complement our theoretical results, we conduct experiments with several large language models from the \texttt{Llama} family.
%
% 6. MMLU results
We find that, across multiple knowledge areas from the popular MMLU benchmark dataset, coupled autoregressive generation requires up to $40$\% fewer samples to reach the same conclusions as vanilla autoregressive generation.
%
% 7. LMSYS results
Further, using data from the LMSYS Chatbot Arena platform, we find that the win-rates derived from pairwise comparisons by a strong large language model to prompts differ under coupled and vanilla autoregressive generation.