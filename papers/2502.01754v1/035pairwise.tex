% short section summary
In this section, we focus on the evaluation and comparison of LLMs according to their level of alignment with human preferences, as elicited by pairwise comparisons between outputs of different LLMs to the same prompts.
%
Such an evaluation protocol has become particularly popular to evaluate and compare LLMs in open-ended, complex tasks in which, in contrast to benchmark datasets, there are no structured ground-truth outputs.
%
In what follows, we provably show that, perhaps surprisingly, different LLMs may compare differently under coupled autoregressive generation and under independent autoregressive generation. 

One of the standard approaches to evaluate and compare different LLMs according to their level of alignment with human pairwise preferences reduces to estimating the win-rate achieved by each LLM $m$ against any other LLM $m' \neq m$, \ie,\footnote{We believe that our theoretical results can be extended to other popular performance metrics based on the Elo rating system~\cite{askell2021general,dettmers2024qlora,bai2022training,wu2023chatarena,lin2023llm} and the Bradley-Terry model~\cite{chiang2024chatbot,boyeau2024autoeval}, as discussed in Section~\ref{sec:discussion}.}
%
\begin{align} 
\EE_{\Ub\sim P_{\Ub}, \Ub'\sim P_{\Ub}, S_q\sim P_Q} [&\one\{R_{m}(\vertarrowbox{\Ub}{}, S_q) > R_{m'}(\vertarrowbox{\Ub}{}', S_q)\}] \label{eq:independent-generation-win-rates} \\[-4ex]
&\text{\small \hspace{5mm} Independent generation} \nn
\end{align}
%
where $\one\{R_m(\ub, s_q) > R_{m'}(\ub, s_q)\} = 1 \, (0)$ means that, for prompt $s_q$ and realized sequence of noise values $\ub$, the output of $m$ is (not) preferred over the output of $m'$.\footnote{For simplicity, we assume that human preferences are deterministic and thus $R_m(\ub, s_q, z) = R_m(\ub, s_q)$. We lift this assumption in our experiments in Section~\ref{sec:experiments}.}

Here, similarly as in Eq.~\ref{eq:independent-generation-difference} in the evaluation based on benchmark datasets, we use different noise variables $\Ub$ and $\Ub'$ because, in this standard approach, each LLM generates outputs to each prompt independently (\ie, using independent autoregressive generation).
%
Conversely, under coupled autoregressive generation, the win-rate adopts the following form:
%
\begin{align} 
\EE_{\Ub\sim P_{\Ub}, S_q\sim P_Q} [&\one\{R_{m}(\vertarrowbox{\Ub}{}, S_q) > R_{m'}(\vertarrowbox{\Ub}{}, S_q)\}] \label{eq:coupled-generation-win-rates} \\[-4ex]
&\text{\small \hspace{8mm} Coupled generation} \nn
\end{align}

% discuss that we show that the two quantities can be different. briefly mention toy example with model playing against itself.
However, in contrast with the comparison of the expected difference in scores under independent and coupled autoregressive generation in the evaluation based on benchmark datasets, 
%
we cannot directly claim that Eqs.~\ref{eq:independent-generation-win-rates} and~\ref{eq:coupled-generation-win-rates} are equivalent because the win-rate is non-linear with respect to $R_{m}(\ub, s_q)$ and $R_{m'}(\ub', s_q)$. 
%
In what follows, we will further analyze the difference between win-rates in two canonical settings similar to those we used in Section~\ref{sec:individual}.

In the first canonical setting, for each prompt, the response can only be one of two given single-token sequences and one of these sequences is preferred over the other by the user.
% (\ie, achieves a positive score). 
Further, the LLMs under comparison always output one of them as a response and the sampling mechanism used by the LLMs satisfies counterfactual stability. 
%
Then, we can compute the win-rates achieved by each LLM $m$ against any other LLM $m' \neq m$ under independent and coupled autoregressive generation using the following proposition:
\begin{proposition}\label{prop:gap_win_rates_stability}
    Given a fixed prompt $s_q \sim P_{Q}$, assume that $f_{R}(s_+)>f_{R}(s_-)$ for $s_+ = s_q \circ t_+$ and $s_-=s_q \circ t_-$, where $t_+$ and $t_-$ are single-token sequences. 
    %
    Further, assume that the LLMs $m$ and $m'$ respond $t_+$ with probability $p_{m}$ and $p_{m'}$, respectively, and $t_-$ with probability $1-p_{m}$ and $1-p_{m'}$, and the sampling mechanism defined by $f_T$ and $P_{U}$ satisfies counterfactual stability. Without loss of generality, assume $p_{m'} > p_{m}$. 
    %
    Then, under
    % independent
    coupled
    autoregressive generation, we have that
    %
    \begin{equation}     \label{eq:gap_win_rates_stability_coupled}
    \begin{split}
        \EE_{\Ub\sim P_{\Ub}}[\one\{R_m(\Ub, s_q)>R_{m'}(\Ub, s_q)\}] &= 0,  \\ 
        \EE_{\Ub\sim P_{\Ub}}[\one\{R_m(\Ub, s_q)<R_{m'}(\Ub, s_q)\}] &= p_{m'} - p_{m}.
    \end{split}
    \end{equation}
    %
    Conversely, under
    % coupled
    independent
    autoregressive generation, we have that
    \begin{equation}    \label{eq:gap_win_rates_stability_independent}
    \begin{split}
        \EE_{\Ub, \Ub' \sim P_{\Ub}}[\one\{R_m(\Ub, s_q)>R_{m'}(\Ub', s_q)\}] &= p_m (1-p_{m'}), \\
        \EE_{\Ub, \Ub' \sim P_{\Ub}}[\one\{R_m(\Ub, s_q)<R_{m'}(\Ub', s_q)\}] &= p_{m'} (1-p_{m}) 
    \end{split}
    \end{equation}
\end{proposition}
%
% discuss the qualitative insights of prop 4
From the above proposition, we can readily conclude that, in general, the win-rates do differ under independent and coupled autoregressive generation. Nevertheless, we may be tempted to conclude that, for ranking LLMs, 
%
this difference appears inconsequential because, for each fixed prompt $s_q$, we have that
%
\begin{multline*}
\EE_{\Ub\sim P_{\Ub}}[\one\{R_m(\Ub, s_q)<R_{m'}(\Ub, s_q)\}] - \EE_{\Ub\sim P_{\Ub}}[\one\{R_m(\Ub, s_q)>R_{m'}(\Ub, s_q)\}] \\ 
= \EE_{\Ub, \Ub' \sim P_{\Ub}}[\one\{R_m(\Ub, s_q)<R_{m'}(\Ub', s_q)\}] - \EE_{\Ub, \Ub' \sim P_{\Ub}}[\one\{R_m(\Ub, s_q)>R_{m'}(\Ub', s_q)\}].
\end{multline*}
%
However, whenever one needs to rank more than two LLMs, the difference in win-rates can be actually consequential---the rankings derived from the win-rates can be different under independent and coupled autoregressive generation, as illustrated by the following simple example.

% explain that the difference in win-rates may lead to a difference in rankings -> example
Consider we are given three LLMs $m_1$, $m_2$, and $m_3$, and we need to rank them according to the average win-rate they achieve against each other on two input prompts $q$ and $q'$, each with a preferred single-token response out of two single-token responses.
%
Assume that the probability that each LLM outputs the preferred single-token response for $q$ and $q'$ is given by the table of the example introduced in Section~\ref{sec:intro}.
%
Under independent autoregressive generation, the average win-rates of $m_1$, $m_2$ and $m_3$ are $0.1545$, $0.15675$ and $0.16225$, respectively. Therefore, $m_3$ is ranked at the top, followed by $m_2$, and $m_1$ is ranked last. 
%
In contrast, under coupled autoregressive generation, the average win-rates of $m_1$, $m_2$ and $m_3$ are $0.0525$, $0.0225$, and $0.03$, respectively, and thus $m_1$ is ranked at the top, followed by $m_3$, and $m_2$ is ranked last.\footnote{Refer to Appendix~\ref{app:example-ranking} for the detailed calculation of the average win-rates.} Interestingly, the ranking obtained under coupled autoregressive generation aligns with the ranking obtained in Section~\ref{sec:intro} using the average accuracy of each LLM. More crucially, this case illustrates how rankings obtained using coupled and independent autoregressive generation can differ, leading to opposite conclusions regarding the LLMs' performance.

% proposition about Gumbel-max to discuss the number of ties
In the second canonical setting, for each prompt, the response can be one of any single-token sequences, and each of the sequences may provide a different level of user'{}s satisfaction (\ie, achieve a different score). 
%
Further, the LLMs under comparison always output one of them as a response and the sampling mechanism used by the LLMs is given by the Gumbel-Max SCM.
%
The following proposition shows that the number of ties between an LLM $m$ and any other \emph{sufficiently similar} LLM $m' \neq m$ are higher under coupled autoregressive generation than under independent autoregressive generation:
%
\begin{proposition}\label{prop:gumbel_ties}
    Given a fixed prompt $s_q \sim P_{Q}$, 
    assume, without loss of generality, that $f_R(s_q \circ t_1) \geq f_R(s_q \circ t_2) \geq \ldots \geq f_R(s_q \circ t_{|V|})$. 
    %
    Let $m$ be an LLM that assigns positive probability to every single-token sequence and zero probability to any other sequence. 
    %
    If the sampling mechanism defined by $f_T$ and $P_U$ is given by the Gumbel-Max SCM, then, there exists a constant $\varepsilon(m)>0$ such that, for every LLM $m'$ that assigns positive probability to every single-token sequence and zero probability to any other sequence and satisfies $d(m,m')=\sup_{s_q} \norm{f_D(s_q,m)-f_D(s_q, m')}_\infty < \varepsilon(m)$, it holds that
    %
    \begin{equation*}
    \EE_{\Ub \sim P_{\Ub}}[\one\{R_m(\Ub, s_q)=R_{m'}(\Ub, s_q)\}] > \EE_{\Ub, \Ub' \sim P_{\Ub}}[\one\{R_m(\Ub, s_q)=R_{m'}(\Ub', s_q)\}].
%         P\left(R_m(U,S_q)=R_{m'}(U, S_q)\right) > P\left(R_m(U,S_q)=R_{m'}(U', 
% S_q)\right).
    \end{equation*}
    %
\end{proposition}
%
% discuss the implications of the proposition
The above proposition implies that the win-rates under independent and coupled autoregressive generation are different and, similarly as in the first canonical setting, rankings derived from the win-rates may differ under independent and coupled autoregressive generation. We investigate this further in our experiments in Section~\ref{sec:experiments}.