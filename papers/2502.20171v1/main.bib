% Long form of conference & journal abbreviations -- especially for camera ready
@String(PAMI  = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV  = {Int. J. Comput. Vis.})
@String(CVPR  = {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV  = {Int. Conf. Comput. Vis.})
@String(ECCV  = {Eur. Conf. Comput. Vis.})
@String(NeurIPS = {Adv. Neural Inform. Process. Syst.})
@String(ICML  = {Int. Conf. Mach. Learn.})
@String(ICLR  = {Int. Conf. Learn. Represent.})
@String(ACCV  = {Asian Conf. Comput. Vis.})
@String(BMVC  = {Brit. Mach. Vis. Conf.})
@String(CVPRW = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {IEEE Int. Conf. Image Process.})
@String(ICPR  = {Int. Conf. Pattern Recog.})
@String(ICASSP=	{ICASSP})
@String(ICME  = {Int. Conf. Multimedia and Expo})
@String(JMLR  = {J. Mach. Learn. Res.})
@String(TMLR  = {Trans. Mach. Learn Res.})
@String(TOG   = {ACM Trans. Graph.})
@String(TIP   = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TCSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TMM   = {IEEE Trans. Multimedia})
@String(ACMMM = {ACM Int. Conf. Multimedia})
@String(PR    = {Pattern Recognition})

@String(MNI	  = {Nature Mach. Intell.})
@String(SPL	  = {IEEE Sign. Process. Letters})
@String(VR    = {Vis. Res.})
@String(JOV	  = {J. Vis.})
@String(TVC   = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF   = {Comput. Graph. Forum})
@String(CVM   = {Computational Visual Media})


% Short form of conference & journal abbreviations -- especially for submission version
% if desired, remove these macros in favor of the above ones
@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NeurIPS = {NeurIPS})
@String(ICML  = {ICML})
@String(ICLR  = {ICLR})
@String(ACCV  = {ACCV})
@String(BMVC  =	{BMVC})
@String(CVPRW = {CVPRW})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {ICIP})
@String(ICPR  = {ICPR})
@String(ICASSP=	{ICASSP})
@String(ICME  =	{ICME})
@String(JMLR  = {JMLR})
@String(TMLR  = {TMLR})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(PR    = {PR})

@inproceedings{de2023querying,
  title={Querying a sign language dictionary with videos using dense vector search},
  author={De Coster, Mathieu and Dambre, Joni},
  booktitle={2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@misc{van2015het,
  title={{Het Corpus VGT. Een digitaal open access corpus van videos and annotaties van Vlaamse Gebarentaal, ontwikkeld aan de Universiteit Gent i.s.m. KU Leuven}},
  howpublished={\url{www.corpusvgt.be}},
  author={Van Herreweghe, Mieke and Vermeerbergen, Myriam and Demey, Eline and De Durpel, Hannes and Nyffels, Hilde and Verstraete, Sam},
  year={2015}
}

@article{desai2024asl,
  title={ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign Language Recognition},
  author={Desai, Aashaka and Berger, Lauren and Minakov, Fyodor and Milano, Nessa and Singh, Chinmay and Pumphrey, Kriston and Ladner, Richard and Daum{\'e} III, Hal and Lu, Alex X and Caselli, Naomi and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{van2004woordenboek,
  title={Woordenboek Nederlands--Vlaamse Gebarentaal/Vlaamse Gebarentaal--Nederlands online},
  author={Van Herreweghe, Mieke and Vermeerbergen, M and De Weerdt, K and Van Mulders, Katrien},
  year={2004}
}

@article{sincan2020autsl,
  title={Autsl: A large scale multi-modal turkish sign language dataset and baseline methods},
  author={Sincan, Ozge Mercanoglu and Keles, Hacer Yalim},
  journal={IEEE access},
  volume={8},
  pages={181340--181355},
  year={2020},
  publisher={IEEE}
}

@misc{asl-signs,
    author = {Chow, Ashley and Cameron, Glenn and Sherwood, Mark and Culliton, Phil and Sepah, Sam and Dane, Sohier and Starner, Thad},
    title = {Google - Isolated Sign Language Recognition},
    publisher = {Kaggle},
    year = {2023},
    url = {https://kaggle.com/competitions/asl-signs}
}

@misc{chow2023google,
  title={Google-American Sign Language Fingerspelling Recognition},
  author={Chow, Ashley and Cameron, Glenn and Georg, Manfred and Sherwood, Mark and Culliton, Phil and Sepah, Sam and Dane, Sohier and Starner, Thad},
  year={2023}
}

@article{de2023towards,
  title={Towards the extraction of robust sign embeddings for low resource sign language recognition},
  author={De Coster, Mathieu and Rushe, Ellen and Holmes, Ruth and Ventresque, Anthony and Dambre, Joni},
  journal={arXiv preprint arXiv:2306.17558},
  year={2023}
}

@inproceedings{holmes2023scarcity,
  title={{From Scarcity to Understanding: Transfer Learning for the Extremely Low Resource Irish Sign Language}},
  author={Holmes, Ruth and Rushe, Ellen and De Coster, Mathieu and Bonnaerens, Maxim and Satoh, Shin'ichi and Sugimoto, Akihiro and Ventresque, Anthony},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2008--2017},
  year={2023}
}

@inproceedings{ko2018sign,
  title={Sign language recognition with recurrent neural network using human keypoint detection},
  author={Ko, Sang-Ki and Son, Jae Gi and Jung, Hyedong},
  booktitle={Proceedings of the 2018 conference on research in adaptive and convergent systems},
  pages={326--328},
  year={2018}
}

@inproceedings{koller2016deep,
  title={Deep sign: Hybrid CNN-HMM for continuous sign language recognition},
  author={Koller, Oscar and Zargaran, O and Ney, Hermann and Bowden, Richard},
  booktitle={Proceedings of the British Machine Vision Conference 2016},
  year={2016}
}

@InProceedings{koller2017re,
author = {Koller, Oscar and Zargaran, Sepehr and Ney, Hermann},
title = {Re-Sign: Re-Aligned End-To-End Sequence Modelling With Deep Recurrent CNN-HMMs},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@inproceedings{ye2018recognizing,
  title={Recognizing american sign language gestures from within continuous videos},
  author={Ye, Yuancheng and Tian, Yingli and Huenerfauth, Matt and Liu, Jingya},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={2064--2073},
  year={2018}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{de2020sign,
  title={Sign language recognition with transformer networks},
  author={De Coster, Mathieu and Van Herreweghe, Mieke and Dambre, Joni},
  booktitle={12th international conference on language resources and evaluation},
  pages={6018--6024},
  year={2020},
  organization={European Language Resources Association (ELRA)}
}

@inproceedings{moryossef2021evaluating,
  title={Evaluating the immediate applicability of pose estimation for sign language recognition},
  author={Moryossef, Amit and Tsochantaridis, Ioannis and Dinn, Joe and Camgoz, Necati Cihan and Bowden, Richard and Jiang, Tao and Rios, Annette and Muller, Mathias and Ebling, Sarah},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3434--3440},
  year={2021}
}

@misc{grishchenko2020mediapipe,
  title = {MediaPipe Holistic â€” Simultaneous Face, Hand and Pose Prediction, on Device},
  author = {Ivan Grishchenko and Valentin Bazarevsky},
  year = {2020},
  month = {December 10},
  note = {Posted by Research Engineers, Google Research},
}

@inproceedings{cao2017realtime,
  title={Realtime multi-person 2d pose estimation using part affinity fields},
  author={Cao, Zhe and Simon, Tomas and Wei, Shih-En and Sheikh, Yaser},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7291--7299},
  year={2017}
}

@article{fei2006one,
  title={One-shot learning of object categories},
  author={Fei-Fei, Li and Fergus, Robert and Perona, Pietro},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={28},
  number={4},
  pages={594--611},
  year={2006},
  publisher={IEEE}
}

@article{bilge2019zero,
  title={Zero-shot sign language recognition: Can textual data uncover sign languages?},
  author={Bilge, Yunus Can and Ikizler-Cinbis, Nazli and Cinbis, Ramazan Gokberk},
  journal={arXiv preprint arXiv:1907.10292},
  year={2019}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{rastgoo2021zs,
  title={Zs-slr: Zero-shot sign language recognition from rgb-d videos},
  author={Rastgoo, Razieh and Kiani, Kourosh and Escalera, Sergio},
  journal={arXiv preprint arXiv:2108.10059},
  year={2021}
}

@inproceedings{bohacek2023learning,
  title={Learning from what is already out there: few-shot sign language recognition with online dictionaries},
  author={Bohacek, Maty{\'a}{\v{s}} and Hr{\'u}z, Marek},
  booktitle={2023 IEEE 17th International Conference on Automatic Face and Gesture Recognition (FG)},
  pages={1--6},
  year={2023},
  organization={IEEE}
}

@article{wang2021cornerstone,
  title={Cornerstone network with feature extractor: a metric-based few-shot model for chinese natural sign language},
  author={Wang, Fei and Li, Chen and Zeng, Zhen and Xu, Ke and Cheng, Sirui and Liu, Yanjun and Sun, Shizhuo},
  journal={Applied Intelligence},
  volume={51},
  pages={7139--7150},
  year={2021},
  publisher={Springer}
}

@inproceedings{camgoz2020sign,
  title={Sign language transformers: Joint end-to-end sign language recognition and translation},
  author={Camgoz, Necati Cihan and Koller, Oscar and Hadfield, Simon and Bowden, Richard},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10023--10033},
  year={2020}
}

@article{caselli2017asl,
  title={ASL-LEX: A lexical database of American Sign Language},
  author={Caselli, Naomi K and Sehyr, Zed Sevcikova and Cohen-Goldberg, Ariel M and Emmorey, Karen},
  journal={Behavior research methods},
  volume={49},
  pages={784--801},
  year={2017},
  publisher={Springer}
}

@inproceedings{fink2023sign,
  title={Sign language-to-text dictionary with lightweight transformer models},
  author={Fink, Jerome and Poitier, Pierre and Andr{\'e}, Maxime and Meurice, Loup and Fr{\'e}nay, Beno{\^\i}t and Cleve, Anthony and Dumas, Bruno and Meurant, Laurence},
  booktitle={32nd International Joint Conference on Artificial Intelligence, IJCAI 2023},
  pages={5968--5976},
  year={2023},
  organization={International Joint Conferences on Artificial Intelligence}
}

@misc{popsign,
    author={{PopSign}},
    title={{American Sign Language Learning Game}},
    howpublished={\url{https://www.popsign.org/}},
    note="[Online; accessed 24 June 2024]",
    year={{n.d.}}
}

@book{battison1978lexical,
  title={Lexical borrowing in American sign language.},
  author={Battison, Robbin},
  year={1978},
  publisher={Linstok Press},
  address={Silver Spring}
}

@article{stokoe1960sign,
  title={{Sign language structure: An outline of the visual communication systems of the American deaf}},
  author={Stokoe, William},
  journal={Studies in Linguistics, Occasional Papers},
  volume={8},
  year={1960},
  address={Silver Spring},
  publisher={Linstok Press}
}

@inproceedings{de2021good,
  title={{Is ``good enough'' good enough? Ethical and responsible development of sign language technologies}},
  author={De Meulder, Maartje},
  booktitle={Proceedings of the 1st International Workshop on Automatic Translation for Signed and Spoken Languages (AT4SSL)},
  pages={12--22},
  year={2021}
}

@inproceedings{albanie2020bsl,
  title={BSL-1K: Scaling up co-articulated sign language recognition using mouthing cues},
  author={Albanie, Samuel and Varol, G{\"u}l and Momeni, Liliane and Afouras, Triantafyllos and Chung, Joon Son and Fox, Neil and Zisserman, Andrew},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XI 16},
  pages={35--53},
  year={2020},
  organization={Springer}
}


@article{bank2015alignment,
  title={Alignment of two languages: The spreading of mouthings in Sign Language of the Netherlands},
  author={Bank, Richard and Crasborn, Onno and Van Hout, Roeland},
  journal={International Journal of Bilingualism},
  volume={19},
  number={1},
  pages={40--55},
  year={2015},
  publisher={Sage Publications Sage UK: London, England}
}


@misc{mediapipemodelcard,
  title={{MediaPipe BlazePose GHUM 3D Model Card}},
  author={{Google}},
  year={2020},
  howpublished={\url{https://storage.googleapis.com/mediapipe-assets/Model Card BlazePose GHUM 3D.pdf}},
   note={[Online; accessed 24 June 2024]}
}

@article{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{mittal2021compositional,
  title={Compositional attention: Disentangling search and retrieval},
  author={Mittal, Sarthak and Raparthy, Sharath Chandra and Rish, Irina and Bengio, Yoshua and Lajoie, Guillaume},
  journal={arXiv preprint arXiv:2110.09419},
  year={2021}
}

@INPROCEEDINGS{papadimitriou2023sign,
  author={Papadimitriou, Katerina and Potamianos, Gerasimos},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Sign Language Recognition via Deformable 3D Convolutions and Modulated Graph Convolutional Networks}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  keywords={Deformable models;Solid modeling;Adaptation models;Visualization;Three-dimensional displays;Convolution;Gesture recognition;SI isolated sign language recognition;deformable 3D-CNN;ST-GCN;modulated GCN;"PIXIE"},
  doi={10.1109/ICASSP49357.2023.10096714}
}

@article{chen2022two,
  title={Two-stream network for sign language recognition and translation},
  author={Chen, Yutong and Zuo, Ronglai and Wei, Fangyun and Wu, Yu and Liu, Shujie and Mak, Brian},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17043--17056},
  year={2022}
}

@inproceedings{bragg2019sign,
  title={Sign language recognition, generation, and translation: An interdisciplinary perspective},
  author={Bragg, Danielle and Koller, Oscar and Bellard, Mary and Berke, Larwan and Boudreault, Patrick and Braffort, Annelies and Caselli, Naomi and Huenerfauth, Matt and Kacorri, Hernisa and Verhoef, Tessa and others},
  booktitle={Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility},
  
  year={2019}
}

@inproceedings{li2020word,
    title={Word-level Deep Sign Language Recognition from Video: A New Large-scale Dataset and Methods Comparison},
    author={Li, Dongxu and Rodriguez, Cristian and Yu, Xin and Li, Hongdong},
    booktitle={The IEEE Winter Conference on Applications of Computer Vision},
    pages={1459--1469},
    year={2020}
 }

@inproceedings{kezar2023sem,
  title={The Sem-Lex Benchmark: Modeling ASL Signs and Their Phonemes},
  author={Kezar, Lee and Thomason, Jesse and Caselli, Naomi and Sehyr, Zed and Pontecorvo, Elana},
  booktitle={Proceedings of the 25th International ACM SIGACCESS Conference on Computers and Accessibility},
  pages={1--10},
  year={2023}
}