\section{INTRODUCTION}
% Foundational Vision-Language Models (VLMs) have enabled robots to detect \cite{clip, segment_anything, detic} and map objects \cite{clio, conceptgraphs, hovsg, bare, ovoslam} described using natural language. Such systems are not limited to a closed set of classes, and are thus able to generalize to diverse tasks and environments. To retain this generality, existing open-vocabulary robotic vision systems avoid adapting foundational VLMs using domain specific data \cite{conceptgraphs, clio}. However, an unintended outcome of this design is that the system may not be well-suited to the robot's current task or deployment environment \cite{seal, eal_semseg, self_improving, move_to_see, interactron}.  

Foundational Vision-Language Models (VLMs) have enabled robots to detect \cite{clip, segment_anything, detic} and map objects \cite{clio, conceptgraphs, hovsg, bare, ovoslam} described using natural language. Such systems are not limited to a closed set of classes, and are thus able to generalize to diverse tasks and environments.
However, a domain shift exists between the large-scale, internet data used to train a VLM and the raw image streams collected by a robot \cite{seal}. Consequently, pre-trained VLMs are unlikely to perform optimally in robotic deployment environments \cite{seal, eal_semseg, self_improving, move_to_see, interactron}.  

% Methods for adapting a VLM to domain specific data using few \cite{coop, clip_adapter} or no \cite{upl, ueo} labelled samples provide a natural solution to this problem. However, existing approaches require the definition of a closed-set of classes, which is impractical when the robot is expected to respond to diverse natural language queries. 
% As such, existing approaches to open-vocabulary object detection rely on pre-trained VLMs that underperform in robotic deployment environments \cite{conceptgraphs, clio}.

Methods for adapting a VLM to domain specific data using few \cite{coop, clip_adapter} or no \cite{upl, ueo} labelled samples provide a natural solution to this problem. However, existing approaches require the definition of a closed-set of classes to perform adaptation. In contrast, pre-trained VLMs are often used in robotics to respond to diverse natural language queries. In this setting, it is not sufficient to improve the performance of the VLM on a closed-set of classes. Instead, methods are required that enable an adapted model to be used for open-vocabulary object detection.

% Thus, to improve open-vocabulary object detection in robotic deployment environments, we explore how a pre-trained VLM can be adapted \textit{without} pre-defining a closed-set of classes.
To overcome this limitation, we explore how a pre-trained VLM (e.g. CLIP) can be adapted for use in robotics \textit{without} pre-defining a closed-set of classes. 
We aim to leverage the fact that existing robotic vision systems \cite{conceptgraphs, clio, hovsg} perform open-vocabulary object detection in response to natural language queries (e.g. `water the plant'). Furthermore, using parameter-efficient methods such as prompt tuning \cite{coop, cocoop}, adaptation of a VLM can be performed without fine-tuning the entire model. Thus, we hypothesise that a pre-trained VLM could be quickly adapted to natural language queries as they arise (Figure \ref{domain_shift}). This avoids having to pre-define a closed-set of classes, ensuring that an adapted model can be used for open-vocabulary object detection.

\begin{figure}[!t]
\centering
\includegraphics[width=1\columnwidth]{Figures/rapid_adaptation2.png}
\caption[Domain Shift for VLMs]{Existing methods for overcoming the domain gap between captioned images and robotic data streams require the definition of a closed-set of classes. This is unrealistic for robots that detect objects in response to diverse natural language queries. In response, we explore how a pre-trained VLM could be rapidly adapted to natural language queries as they arise. 
This approach avoids having to pre-define a closed-set of classes, ensuring that an adapted model can be used for open-vocabulary object detection.
% An example of the captioned image data used to train a VLM (top) \cite{laion5b}. Such datasets contain images that are not representative of robotic deployment, where diverse tasks must be performed using an egocentric data stream.
}
\vspace{-1.5em}
\label{domain_shift}
\end{figure}

% This way, an improved model could be used to carry out the task, without needing to pre-define a closed-set of classes. 

% We hypothesise that a VLM could be quickly adapted to an open-vocabulary tasks description (e.g. water the plant). In turn, the robot could use the adapted model to carry out the task, before repeating the process as new tasks arise. 
% This way, an adapted model can be applied to open-vocabulary detection tasks that were previously unknown to the robot.

% To overcome this limitation, we explore how a pre-trained VLM can be adapted \textit{without} pre-defining a closed-set of classes. To achieve this, a robotic vision paradigm is proposed where the VLM (e.g. CLIP) is quickly adapted to open-vocabulary detection tasks as they arise (Figure \ref{hook_figure}). 
% % The goal of this approach is to retain the generality of using a pre-trained VLM \cite{clip, conceptgraphs}, while ensuring that an optimal model is applied to specific tasks \cite{seal}. 
% Given a new task related to a small set of objects (e.g. water the plant), we leverage unlabelled data collected by the robot in previous deployments to efficiently adapt the model. The robot can then use the adapted model to carry out the task, before repeating the process as new tasks arise. 
% This way, an optimised model can be used to respond to diverse natural language queries.

To this end, we propose QueryAdapter; a novel robotic vision framework for rapidly adapting a pre-trained VLM in response to a natural language query (Figure \ref{simple_method}). Given a new query, we use a Large Language Model (LLM) to generate a set of ``target classes'' required to fulfill the request. Unlabelled data collected by the robot in previous deployments is then used to align VLM features with these target classes. To improve efficiency, only the top $k$ previously observed objects for each target class are selected for adaptation. Similarly, learnable prompt tokens \cite{coop} are optimised instead of fine-tuning the entire model, allowing adaptation to be performed in a few minutes. 
As a final step, the adapted model is used to detect the target classes in the current scene, improving the retrieval of objects related to the query. 

% As a final step, the adapted model and the target classes are used to retrieve objects from the current scene that are relevant to the task. In this way, an improved model can be used to complete novel tasks without pre-defining a closed-set of relevant classes.

% The approach firstly uses an LLM to process a natural language task description, generating a set of  required to complete the task.

% Using this framework (Figure \ref{hook_figure}) an improved model can be applied to open-vocabulary detection tasks without needing to pre-define a closet-set of relevant classes

% This framework requires that adaptation be performed quickly to minimise downtime of the robot. Furthermore, as the tasks are unknown before deployment, unlabelled data collected in previous environments must be leveraged to perform adaptation.



% When implementing QueryAdapter, we find that the majority of previously observed objects are irrelevant to a given natural language query. 
A further challenge in implementing this framework is that for a specific query, very few objects will be relevant. In existing literature, objects that fall outside the classes defined for detection are termed Out-of-Distribution (OOD) \cite{ueo} or open-set objects \cite{open_vlm}. A similar problem occurs when implementing QueryAdapter, with the majority of previously observed objects being unrelated to a given natural language query. 
% Existing unsupervised learning methods perform poorly in the presence of such \textit{open-query} objects.
We refer to these as \textit{open-query} objects, and find that existing unsupervised learning methods perform poorly in this challenging setting.
% In this realistic setting, we find that existing unsupervised VLM adapters designed for image classification perform poorly \cite{ueo, upl}.
% This produces an extremely challenging OOD problem that is akin to finding a needle in a haystack \cite{ueo, open_vlm, probvlm}. 
% This produces a challenging Out-of-Distribution (OOD) problem in which existing unsupervised learning methods perform poorly \cite{ueo, upl}. 
% To overcome this, we propose a novel approach to performing adaptation using an unlabelled data stream containing many OOD objects. 
% To overcome this, we propose using the captions of previously observed objects to extract the most common classes in the dataset, and propose these as ``negative classes''. 
To overcome this, we use the captions of previously observed objects to extract the most common classes in the dataset, and propose using these as ``negative classes'' during adaptation.
The addition of these negative classes helps produce better calibrated confidence scores, improving the performance of unsupervised learning techniques based on entropy maximisation \cite{ueo}. This method ensures that the QueryAdapter framework remains effective when using data collected by the robot in previous deployments.
% Lastly, by only using objects that have high similarity with the target classes, the number of OOD objects is reduced.

% The challenge in implementing this framework is that for a specific task, only a small proportion of the previously observed objects will be relevant. This produces an extremely challenging OOD problem that is akin to finding a needle in a haystack \cite{ueo, open_vlm, probvlm}. In this realistic setting, we find that existing unsupervised VLM adapters designed for image classification perform poorly \cite{ueo, upl}. With this in mind, we propose TaskAdapter to adapt a VLM using an unlabelled data stream containing many OOD objects. The approach firstly uses an LLM to process a natural language task description, generating a set of ``target classes'' required to complete the task. Then, we use captions of previously observed objects to extract the most common classes in the dataset, and propose these as ``negative classes''. The addition of these negative classes helps produce better calibrated confidence scores during training, improving the efficacy of self-training techniques based on entropy maximisation \cite{ueo}. As a final step to improve both performance and efficiency, we perform adaptation using the top-k previously observed objects for each target class.

% these methods are not design to adapt a VLM to relatively few classes using the raw RGB streams collected by a robot. In this setting, the vast majority of previously observed objects are irrelevant, leading to a challenging OOD problem that is akin to finding a needle in a haystack. Furthermore, we find that existing methods designed for image classification require many candidate classes to produce appropriate confidence scores. 

% Then, for each relevant class, we select the top-k previously observed objects as candidates for performing adaptation. However, instead of using these candidate objects directly as pseudo-labels, we treat them as samples for training a light-weight adapter via Universal Entropy Optimisation (UEO).
% This set of objects can then be used to train a light-weight adapter network, but instead of using them directly as pseudo-labels, we treat them as samples for applying Universal Entropy Optimisation (UEO). 
% This set of objects can then be used to train a light-weight adapter network, either by using them as pseudo-labels or as samples for an unsupervised loss such as entropy minimisation. 
% Lastly, we propose a method for generating negative class labels to produce reliable confidence scores during training.

% This idea is closely related to data-efficient transfer learning of VLMs, which aims to adapt pre-trained CLIP features to optimally perform image classification in a particular domain. As it is difficult to generate labelled data for open-vocabulary concepts, these methods aim to perform adaptation with few or no labelled samples. However, modern open-vocabulary vision systems are distinct from traditional detection and classification, as they do not aim to classify each object at the time of observation. Instead, these systems maintain a generic representation of objects that can be utilised later to respond to to natural language queries. Adapting a VLM for this task produces several challenges that are not addressed in existing work designed for image classification. Firstly, image classification tends to assign a single class name to each object (i.e. chair), ignoring the potential for an object to be described in multiple ways (i.e. used for sitting, four legs and a backrest). Additionally, it is natural to use data collected by the robot in previous deployments to perform adaptation. However, when focussing on a set of 'core concepts', the vast majority of previously observed objects will be irrelevant, leading to a challenging out-of-distribution (OOD) problem.

% With these challenges in mind, we propose an approach to adapting a VLM to a set of core natural language concepts using only unlabelled data collected by the robot. Central to our system is a novel pseudo-labelling method that can assign any number of core concepts to a previously observed object. Unlike existing work, this allows us to deal with many out-of-distribution objects and diverse descriptions of the same object. We then use a light-weight adapter to align the object features with the generated pseudo-labels to enhance retrieval of core-concepts, without compromising zero-shot performance. Furthermore, as we can incrementally produce labels for new concepts and objects and efficiently re-train the adapter, the system can be used for continual robot learning.

To summarise, our work makes the following contributions: 
\begin{itemize}
    \item We propose QueryAdapter, a framework for rapidly adapting a pre-trained VLM in response to a natural language query.
    This avoids having to pre-define a closed-set of classes, ensuring that an adapted model can be used for open-vocabulary object detection.
    % This is the first approach for adapting a VLM in response to a specific query, avoiding the need to pre-define a closed-set of classes.
    % responding to task-oriented queries with an adapted VLM. Using this approach, an improved model can be used to complete novel tasks without pre-defining a closed-set of relevant classes.
    % \item A novel pseudo-labelling approach that produces a dataset for adapting a VLM to a task described using natural language.
    \item We propose the use of object captions as negative classes during adaptation, helping to produce better calibrated confidence scores for open-query objects. This ensures that QueryAdapter is effective when using the raw data collected by the robot in previous deployments. 
    \item We conduct a detailed evaluation of natural language object retrieval in real-world scenes \cite{scannet++}, demonstrating the effectiveness of our approach in adapting to challenging natural language queries. 
    % \item An approach to align object features with a core set of natural language concepts using only unlabelled data collected by the robot, leading to improved retrieval of core concepts without sacrificing zero-shot performance. 
    % \item A novel pseudo-labelling approach that can assign any number of core concepts to a previously observed object, effectively dealing with many out-of-distribution samples and diverse descriptions of the same object. 
    % \item A demonstration of the system for continual robot learning, where core-concepts and unlabelled data are incrementally made available to the robot. 
\end{itemize}