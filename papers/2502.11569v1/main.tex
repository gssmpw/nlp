\documentclass[11pt]{article}
\pdfoutput=1
\usepackage[final]{acl}

% \usepackage{subfig}
\usepackage{subcaption}

% Font packages
\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata} 
\usepackage{csquotes}
\usepackage{enumitem}

% Math packages
\usepackage{amsmath}
\usepackage{amssymb}  % Added for math symbols
\usepackage{amsthm}
\usepackage{mathtools}

% Table packages
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{tabularx}
\usepackage{tabulary}
\usepackage{adjustbox}
\usepackage{siunitx}
\usepackage{makecell}

% Graphics and color packages
\usepackage{graphicx}
\usepackage{bm}
\usepackage{xcolor}
\usepackage{xcolor,colortbl}

% TikZ and tcolorbox packages
\usepackage[most]{tcolorbox} 
\usepackage{cleveref}
\usepackage{makecell}

% Define tcolorbox styles
\newtcbtheorem[auto counter, number within=section, 
crefname={example}{Example},
Crefname={Example}{Example}]
{exmp}{Exam\smash{p}le} 
{colback=pale_red!5, colframe=DarkPurple, left=.02in, right=.02in,bottom=.02in, top=.02in}{exmp}  

\newtcbtheorem[auto counter, 
crefname={prompt}{Prompt},
Crefname={Prompt}{Prompt}]
{prompt}{Prom\smash{p}t} 
{colback=pale_red!5, colframe=DarkPurple, left=.02in, right=.02in,bottom=.02in, top=.02in}{prompt}  

% \usepackage{enumitem}
\usepackage{listings}
\lstset{
    language=Python,
    basicstyle=\ttfamily\footnotesize,
    breaklines=True,
    showstringspaces=False,
    frame=none,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{green!50!black},
    morekeywords={import, from, as, def, return, in, if, else, elif, for, while, try, except, with, class, self, True, False, None, and, or, not, is, pass},
} 










% Define colors
\definecolor{Violet}{RGB}{148,0,211}    
\definecolor{DarkPurple}{RGB}{75,0,130} 
\definecolor{lightergray}{RGB}{230,230,230}
\definecolor{DarkRed}{RGB}{130,25,0}
\definecolor{PurpleRed}{RGB}{204,0,102}
\definecolor{DarkGreen}{RGB}{30,130,30}
\definecolor{DarkBlue}{RGB}{0,0,250}
\definecolor{DarkYellow}{RGB}{255,128,0}
\definecolor{light-gray}{gray}{0.95}
\definecolor{lightgreen}{RGB}{231,255,219}
\definecolor{lightred}{RGB}{252,231,234}
\definecolor{lightyellow}{RGB}{250,253,191}
\definecolor{lightpurple}{RGB}{229,204,255}
\definecolor{lightblue}{RGB}{229,246,254}
\definecolor{value-modification}{RGB}{250, 217, 86}
\definecolor{digit-expansion}{RGB}{216, 194, 104}
\definecolor{integer-decimal-fraction}{RGB}{240, 133, 51}
\definecolor{semantic-paraphrasing}{RGB}{85, 157, 63}
\definecolor{complexity-increasing}{RGB}{58, 120, 175}
\definecolor{question-transformation}{RGB}{174, 205, 225}
\definecolor{interference-injection}{RGB}{255,204,229}
\definecolor{remove-constrain}{RGB}{204,204,255}

% Custom commands
\newcommand{\xmark}{\textcolor{red}{\ding{55}}} 
\newcommand{\cmark}{\textcolor{DarkGreen}{\ding{51}}}
\newcommand{\addmark}{\textcolor{DarkYellow}{\ding{59}}}
\newcommand{\editmark}{\textcolor{blue}{\ding{34}}}

\definecolor{pale_green}{rgb}{0.55,0.75,0.60}
\definecolor{pale_red}{rgb}{0.90,0.61,0.58}
\definecolor{pale_yellow}{rgb}{0.95,0.92,0.72}

% AIbox definition
\tcbset{
  aibox/.style={
    width=\textwidth,
    top=0pt, bottom=0pt, left=5pt, right=5pt,
    colback=white,
    colframe=black,
    colbacktitle=black,
    enhanced,
    center,
    attach boxed title to top left={yshift=-0.1in,xshift=0.15in},
    boxed title style={boxrule=0pt,colframe=white,},
  }
}
\newtcolorbox{AIbox}[2][]{aibox,title=#2,#1}

\addtocontents{toc}{\protect\setcounter{tocdepth}{-1}} 





\newcounter{testexample}
\usepackage{tcolorbox}
\usepackage{xcolor}

\def\exampletext{Definition} % If English

\NewDocumentEnvironment{testexample}{ O{} }
{
\colorlet{colexam}{red!45!black} % Global example color
\newtcolorbox[use counter=testexample]{testexamplebox}{%
    % Example Frame Start
    empty,% Empty previously set parameters
    % Removed title line: title={\exampletext: #1},% use \thetcbcounter to access the testexample counter text
    % Removed title related options
    % Removed: attach boxed title to top left,
    % Removed: minipage boxed title,
    % Removed: boxed title style={empty,size=minimal,toprule=0pt,top=4pt,left=3mm,overlay={}},
    % Removed: coltitle=colexam,fonttitle=\bfseries,
    before=\par\medskip\noindent,parbox=false,boxsep=0pt,left=3mm,right=0mm,top=5pt,breakable,pad at break=0mm,
       before upper=\csname @totalleftmargin\endcsname0pt, % Use instead of parbox=true. This ensures parskip is inherited by box.
    % Handles box when it exists on one page only
    overlay unbroken={\draw[colexam,line width=.5pt] ([xshift=-0pt]frame.north west) -- ([xshift=-0pt]frame.south west); },
    % Handles multipage box: first page
    overlay first={\draw[colexam,line width=.5pt] ([xshift=-0pt]frame.north west) -- ([xshift=-0pt]frame.south west); },
    % Handles multipage box: middle page
    overlay middle={\draw[colexam,line width=.5pt] ([xshift=-0pt]frame.north west) -- ([xshift=-0pt]frame.south west); },
    % Handles multipage box: last page
    overlay last={\draw[colexam,line width=.5pt] ([xshift=-0pt]frame.north west) -- ([xshift=-0pt]frame.south west); },%
    }
\begin{testexamplebox}}
{\end{testexamplebox}\endlist}

\newcommand{\xw}[1]{{\small\color{blue}{\bf xw:} #1}}



\title{Towards Reasoning Ability of Small Language Models}
% \title{From Large to Small: Towards Reasoning in Small and Compressed Language Models}

\author{
 \textbf{Gaurav Srivastava\textsuperscript{1}},
 \textbf{Shuxiang Cao\textsuperscript{2}},
 \textbf{Xuan Wang\textsuperscript{1}}
\\
\\
 \textsuperscript{1}Department of Computer Science, Virginia Tech, Blacksburg, VA, USA,
 \\
 \textsuperscript{2}Department of Physics, Clarendon Laboratory, University of Oxford, OX1 3PU, UK
\\
\\
 \normalsize{
        \texttt{(\href{gks@vt.edu}{gks}, \href{xuanw@vt.edu}{xuanw})@vt.edu; (\href{shuxiang.cao@physics.ox.ac.uk}{shuxiang.cao})@physics.ox.ac.uk}
     % \href{mailto:gks@vt.edu}{gks@vt.edu}
 }
}

\begin{document}
\maketitle


\begin{abstract}



Reasoning has long been viewed as an emergent property of large language models (LLMs), appearing at or above a certain scale ($\sim$100B parameters). However, recent studies challenge this assumption, showing that small language models (SLMs) can also achieve competitive reasoning performance. SLMs are increasingly favored for their efficiency and deployability. However, there is a lack of systematic study on the reasoning abilities of diverse SLMs, including those trained from scratch or derived from LLMs through quantization, pruning, and distillation. This raises a critical question: \emph{Can SLMs achieve reasoning abilities comparable to LLMs?} In this work, we systematically \textbf{survey, benchmark, and analyze} \textbf{72} SLMs from \textbf{six} model families across \textbf{14} reasoning benchmarks. For reliable evaluation, we examine \textbf{four} evaluation methods and compare \textbf{four} LLM judges against human evaluations on \textbf{800} data points. We repeat all experiments \textbf{three} times to ensure a robust performance assessment. Additionally, we analyze the impact of different prompting strategies in small models. Beyond accuracy, we also evaluate model robustness under \textbf{adversarial conditions} and \textbf{intermediate reasoning steps}. Our findings challenge the assumption that scaling is the only way to achieve strong reasoning. Instead, we foresee a future where SLMs with strong reasoning capabilities can be developed through structured training or post-training compression. They can serve as efficient alternatives to LLMs for reasoning-intensive tasks. \footnote{All model responses, evaluation results, and GPT-based judgments will be released.}

\end{abstract}


\input{sections/introduction}
\input{sections/related_works}
\input{sections/experimental-setup}
\input{sections/results}
\input{sections/conclusion}
\input{sections/limitations}

\section*{Ethics Statement}
This study evaluates small language models using standardized benchmarks and publicly available datasets, ensuring transparency and reproducibility. No private or sensitive data was used, and all models were assessed under fair conditions. We acknowledge potential biases in LLM-based evaluations and encourage further research for mitigation.

\section*{Acknowledgements}
This work was supported by the NSF NAIRR Pilot with PSC Neocortex and NCSA Delta, Cisco Research, Amazon, Schmidt Science, the Commonwealth Cyber Initiative, the Amazon–Virginia Tech Center for Efficient and Robust Machine Learning, the Sanghani Center for AI and Data Analytics at Virginia Tech, the Virginia Tech Innovation Campus, Children's National Hospital, and the Fralin Biomedical Research Institute at Virginia Tech. S. C. acknowledges support from Schmidt Science. The views, findings, conclusions, and recommendations expressed in this work are those of the authors and do not necessarily reflect the opinions of the funding agencies.

% This work is sponsored by the NSF NAIRR Pilot with PSC Neocortex and NCSA Delta, Cisco Research, Amazon, Schmidt Science, Commonwealth Cyber Initiative, Amazon + Virginia Tech Center for Efficient and Robust Machine Learning, Sanghani Center for AI and Data Analytics (Virginia Tech), Virginia Tech Innovation Campus, Children’s National Hospital and Fralin Biomedical Research Institute (Virginia Tech). S. C. acknowledges the support from Schmidt Science. Any opinions, findings, and conclusions or recommendations expressed in this work are those of the author(s) and do not necessarily reflect the views of the funding agencies.







\bibliography{custom}


\clearpage
\appendix

\input{sections/appendix}





\end{document}
