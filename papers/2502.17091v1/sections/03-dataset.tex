% \gabis{Where do we define our notion of framing and relevant terms? Will that happen in the intro? For example here we use the term ``sentiment shifts'', which I think requires defintion.}\gili{done in intro}

% \gabis{Recurring comment - we should change tense to present, while most of the paper is currently in the past tense, I indicated this in some places, but should verify throughout.}

% \input{figures/flipped_ratio}


Our dataset curation consists of three steps, as depicted in Figure~\ref{fig:fig1}. First, we collect natural, real-world statements, with some clear sentiment, either positive or negative (\S\ref{sec:base-statements}; e.g., ``I won the highest prize'' as positive). Next, 
we reframe each statement by adding a prefix or suffix conveying the opposite sentiment
% for each statement, we add a framing that conveys the opposite sentiment to the base statement 
(\S\ref{sec:adding-framing}; e.g., ``I won the highest prize, although I lost all my friends on the way''). Finally, we collect large-scale human annotations via crowdsourcing, to label the sentiment shifts when wrapping the statements with the opposite framing (\S\ref{sec:human-annotations}; e.g., labeling ``negative'' the statement ``I won the highest prize, although I lost all my friends on the way''). 
%\gabis{I think we can remove the textual examples here to save space}

The complete dataset consists of 1000 statements, in which 500 are statements that their base form has positive sentiment, and 500 are base negative statements. 




\subsection{Collecting Base Statements}\label{sec:base-statements}
First, we collect base statements, which convey a clear sentiment, either clearly positive or clearly negative statements. We use \spike{} -- an extractive search system, which allows to extract statements from real-world datasets~\cite{taub-tabib-etal-2020-interactive}.
%\gabis{there's also a citation for spike}.\footnote{~\url{https://spike.apps.allenai.org}} 
Specifically, we collect statements from Amazon Reviews dataset, which are naturally occurring, sentiment-rich, texts but are less likely to trigger strong preexisting biases or emotional reactions, which may be a confound for our experiment.\footnote{~\url{https://spike.apps.allenai.org/datasets/reviews}} 
% \gabis{Why did we use this specifically? I think once we write the intro it would be good to relate to what we wrote there and how this domain is relevant.}
\input{figures/pos-score-dist}


Using \spike, we extract ${\sim}6k$ statements that fulfilled our designated queries, which we found correlated with clear sentiment. We designed the queries to capture positive or negative verbs that describe actions with some clear sentiment (e.g., ``enjoy'' or ``waste''), or statements with positive or negative adjective, describing an outcome with a clear sentiment (e.g., ``good'' or ``nasty''). The patterns and queries used for extraction are detailed in Appendix~\ref{sec:appendix-spike}.
% \gabis{needs more details, what are our queries? What were we aiming for? I understand that at a high level we're looking for clear sentiment, but how do we achieve this via lexical-syntactic queries?}. 
Next, we run in-house annotations to label and filter the extracted statements, to handle negations or other cases where the statement does not convey a clear sentiment. 
The filtering process results in $1,301$ positive statements, and $1,229$ negative statements.


\subsection{Adding Framing}\label{sec:adding-framing}

To reframe the statements in our dataset, we use GPT-4~\cite{achiam2023gpt}.\footnote{We used the gpt-4-0613 version.} 
% \gabis{do we have more details about which GPT4? what date?}
% The model was asked to keep he base statement unchanged, and add some prefix or suffix, that can be either positive or negative, oppositely to the base statement sentiment (e.g., I won the highest proze, althoug I lost all my friends on the way). 
The input prompt includes a 1-shot example, followed by a task description ``Add a <SENTIMENT> suffix or prefix to the given statement. Don't change the original statement.'', where SENTIMENT is either ``positive'' or ``negative'', opposite to the base statement sentiment (i.e., positive framing for negative base statement, and vice versa).

Unlike the base statement, the conveying sentiment of reframed statements is more ambiguous and there is no one clear label, as shown in Figure~\ref{fig:pos-score-dist}.\footnote{Scores in Figure~\ref{fig:pos-score-dist} are given by a fine-tuned sentiment analysis model ~\url{https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest}}
%as we present the sentiment scores assigned by a fine-tuned sentiment analysis model,\footnote{~\url{https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest}} %that was shown to be state-of-the-art when fine-tuned on sentiment analysis~\cite{csanady2024llambert}. 
% We present the sentiment scores 
% before and after reframing. It shows that wrapping the statement with the opposite sentiment injects ambiguity to the overall sentiment, as the sentiment scores become more dispersed. 
The exhibeted ambiguity in sentiment allows us to measure to what extent LLMs' shifting sentiment after framing, and how correlated it is to human behavior.



% In Figure~\ref{fig:pos-score-dist}, \gabis{Is roberta SOTA? it's a bit old by now. Do we have a reference to back this up?}\footnote{RoBERTa, fine-tuned for sentiment analysis~\url{https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest}} The base statement scores are predominantly centered around binary values, either strongly positive or strongly negative. In contrast, the sentiment scores after opposite framing are more dispersed, reflecting increased ambiguity in sentiment. 
% \gabis{I'm not sure if this paragraph belongs here, maybe should be a subsection on its own at the end of the section?}


\subsection{Collecting Human Annotations}\label{sec:human-annotations}

In the final step, we collect human annotations through Amazon Mechanical Turk to evaluate the framing effect in \name{} over human participants, providing a reference for comparison with LLMs.\footnote{\url{https://www.mturk.com}} 
Details about the annotation platform are elaborated in Appendix~\ref{sec:mturk-appendix}.

The complete dataset includes 1K statements, each annotated by five different annotators. Given our budget, we preferred to collect five annotations per statement, resulting in less statements, but providing a more robust scoring for the ambiguity of a statement.

% We select a pool of 10 qualified workers who successfully passed our qualification test, which consisted of 20 base statements (unframed), for which annotators were expected to achieve perfect accuracy. The estimated hourly wage for the entire experiment was approximately 14USD per hour. More details about the annotation platform can be found in Appendix~\ref{sec:mturk-appendix}. Given our budget, we preferred to collect five annotations per statement, resulting in less statements, but providing a more robust scoring for the ambiguity of a statement.

For the annotation process, each statement in our dataset is presented in its reframed version (i.e., positive base statements with negative framing and vice versa), to five different annotators. This setup generates, for each dataset instance, a score ranging from 0 to 5, representing the number of annotators that votes for the sentiment that aligns with the opposite framing, which means that the overall sentiment of the reframed statement has shifted from its base sentiment. For example, in Figure~\ref{fig:fig1}, the statement ``I won the highest prize, although I lost all my friends on the way'' is shown to have two annotators voting ``negative'', which aligns with the sentiment of the framing and not the base statement, so the label for that instance in \name{} would be 2 (sentiment shifts).

% \gabist{It is important to note that there is no definitive ``right'' or ``wrong'' label for these statements, as the opposite sentiment framing often renders the sentiment conveyed highly ambiguous.}
Instances with score near 0 indicate that annotators agree that the overall sentiment remains unchanged despite the opposite framing. Score closer to 5 indicates that annotators agree that reframing shifted the perceived sentiment, while score around 2-3 suggests that the opposite framing makes the sentiment ambiguous.

