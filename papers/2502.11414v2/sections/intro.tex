\section{Introduction}
% Learning to Rank (LTR) with implicit user feedback (e.g., click) has attracted much research interest. On the one hand, user feedback collected from search logs not only indicates the relevance of the query-document pairs but is also easy to collect on a large scale. On the other hand, directly optimizing a ranking model with user feedback suffers from various biases 
% % (e.g., position bias \cite{ai2018unbiased,hu2019unbiased,joachims2017unbiased,luo2024unbiased,wang2018position}, trust bias \cite{agarwal2019addressing,vardasbi2020inverse}, contextual bias \cite{chen2021adapting,zhuang2021cross})
% and noise deriving from user behaviors. Consequently, substantial research on unbiased learning to rank (ULTR) has been conducted to mitigate these biases in user clicks and obtain an unbiased ranking model \cite{gupta2024unbiased}. 

% Most existing Unbiased Learning to Rank (ULTR) methods are based on the user examination hypothesis \cite{richardson2007predicting}, which assumes that a document will be clicked if and only if it is relevant and observed by users. According to this hypothesis, \citet{joachims2017unbiased} first propose the inverse propensity weighting (IPW) method to debias clicks. For simplicity, they only focus on mitigating position bias---where the observation probability decreases with the increasing position---assuming that the propensity only depends on the position. The following methods \cite{ai2018unbiased,hu2019unbiased,wang2018position} focus on estimating the propensity depending on position only as well, among which the dual learning algorithm (DLA) performs the best. DLA jointly learns an unbiased ranker and an unbiased propensity model. To estimate the propensity in more general interaction settings, where the observation probability at each position is not independent, \citet{chen2021adapting} propose the interactional observation-based model (IOBM), which leverages both the click and position information of the results list for predicting the propensity.
% position bias unbiased learning to rank with click data.
% p(click) = p(o) p(r) 
% IPW, DLA. 
Most existing unbiased learning-to-rank (ULTR) studies focus on mitigating position bias \cite{joachims2017unbiased,ai2018unbiased,luo2024unbiased,zhang2023towards} and are based on position-based click modeling \cite{richardson2007predicting}. Position-based modeling (PBM) assumes that users click a result when they examine the result and it is relevant. The observation probability (i.e., click propensity) depends on the position of the result on the search result page (SERP). Grounded on PBM, a major thread of ULTR research is to estimate the propensity of each position on the SERP and conduct inverse propensity weighting (IPW) on the click \cite{joachims2017unbiased,ai2018unbiased,luo2024unbiased}. Among them, a popular approach is the dual learning algorithm (DLA) \cite{ai2018unbiased} that adaptively learns relevance and click propensity by IPW and inverse relevance weighting simultaneously.

% The above ULTR methods assume that input features of the propensity model, e.g., positions, are bias-relevant but relevance-irrelevant. However, in the real world, the result lists are generated by the previous ranking model, which causes that positions may also imply relevance, thus the propensity model is confounded with the ranking model. \citet{zhang2023towards} propose two effective methods, gradient reversal (GradRev) and observation dropout (Drop) to alleviate the negative effects of this confounding by unlearning the relevant information in the propensity model. Further, \citet{luo2024unbiased} regard that this confounding leads to the over-estimation issue of propensity and proposes the unconfounded propensity estimation (UPE) to mitigate the issue based on a backdoor adjustment.

% propensity estimation:
%     pointwise propensity estimation
%     o r - entangled
%     depending on context embeddings 
% false negatives; PRS
% more references can be added in the cameral-ready version: yu2023feature and other related work
Despite its efficacy on synthetic click data, DLA does not perform as well on the Baidu-ULTR dataset \cite{zou2022large}, real-world large-scale click data \cite{hager2024unbiased}. There are several potential reasons for this. First, users may have more complex behaviors PBM cannot capture \cite{zou2022large}. Second, search engines have strong logging policies that rank high-relevance results to higher positions, leading to inaccurate propensity estimation from confounded relevance and observation \cite{hager2024unbiased}. Third, severe false negative issues exist in the result list. Most results are relevant but users only click one or two of them \cite{yu2023cir}.

\enlargethispage{\baselineskip}
Existing work has made efforts to address these challenges. To capture complex user behaviors, \citet{chen2021adapting} propose the Interactional Observation-Based Model (IOBM), which estimates a position's click propensity by incorporating clicks from other positions in the result list. To mitigate issues arising from strong logging policies, \citet{zhang2023towards} introduce gradient reversal (GradRev) and observation dropout (Drop) to disentangle relevance and observation. \citet{luo2024unbiased} propose an unconfounded propensity estimation (UPE) approach with backdoor adjustment. To address the false negative problem, \citet{wang2021non} argue that non-clicks with higher observation probability are more likely to be true negatives, and therefore assign higher weights to pairs formed by a click and such non-clicks. However, this approach implies that higher-position results are more likely to be true negatives, which contradicts the fact that strong logging policies tend to rank more relevant results higher. Since most of these methods are evaluated on synthetic data, their performance on real-world click data remains unclear.

% challenge existing hypothesis
% Our hypothesis
Targeting effective ULTR with real-world click data, we challenge the examination hypothesis in PBM. In our analysis of the Baidu-ULTR dataset, we find that among query sessions with clicks, only about 1.2\% involve more than two clicks, approximately two-thirds have a single click, and one-third have exactly two clicks. Given users' limited patience and the fact that a single relevant result typically satisfies their information needs, we hypothesize that users may have a non-zero probability of not clicking a relevant result, even after examining it. As the number of potentially relevant results in a list increases, users are less likely to leave the session without clicking. This behavior reflects a query-level click propensity influenced by the quality of the ranking list, which we refer to as relevance saturation bias.

Accordingly, we propose a Dual Inverse Propensity Weighting mechanism (\m) that incorporates both query-level and position-level click propensity. When the query-level propensity is larger, the ranking list of the query has a smaller inverse weight, which reduces the importance of sessions with potentially more false negatives. Hence, inaccurate contrastive learning between clicks and non-clicks will be mitigated. We theoretically prove that \m~can learn an unbiased ranking model. We compare \m~with state-of-the-art baselines, including GradRev, Drop, UPE, and IOBM, on the Baidu-ULTR dataset and demonstrate significant improvements over them. 

% For lack of real-world click data, existing ULTR methods have primarily demonstrated their effectiveness on synthetic datasets, where clicks are simulated based on specific user browsing behaviors (e.g., position-based model (PBM) \cite{craswell2008experimental}), therefore their empirical performance remains unclear in real-world click data. Moreover, most methods focus on addressing a single type of bias, particularly position bias, which is prevalent in ranking systems. 

% findings -> methods
% A recently published real-world click data, the Baidu-ULTR dataset \cite{zou2022large}, offers a valuable opportunity to investigate biases and the performance of existing ULTR methods in real-world user clicks. Previous work on the Baidu-ULTR dataset has some findings: 1) \citet{hager2024unbiased} suggests the presence of a top-heavy position bias, but observes conventional ULTR methods \cite{ai2018unbiased,hu2019unbiased,joachims2017unbiased,wang2018position}, which merely consider the position factor to address position bias, do not bring clear benefits. (2) \citet{yu2023cir,yu2023feature} discover that the false negative issue is even more severe, where non-clicked results at top ranks are potentially relevant due to the high quality of the ranking lists returned by the search engine. This contrasts with \cite{wang2021non}, which assumes that non-clicked results with lower observation probability are more likely to be relevant.

% We believe that queries with more severe false negative issue are more likely to receive clicks due to their larger number of relevant documents. We refer to this bias as user interaction bias and define a query's probability of receiving clicks as the click propensity. To characterize user selection bias, we introduce a new click hypothesis, i.e., the click probability of a document depends on not only the relevance and observation probability but also the click propensity. Further, we propose the Bi-Level Inverse Propensity Weighting (\m) method, which consists of query-level inverse click propensity and position-level inverse propensity weighting to alleviate user interaction bias and position bias, respectively. We theoretically prove that through the \m, an unbiased ranking model can be obtained. We conduct all the experiments on real-world click data, the Baidu-ULTR dataset, and demonstrate the effectiveness and necessity of the \m.

% The main contributions of this paper are summarized as follows:
% \begin{enumerate}[0]
% \item[$\bullet$] We believe that queries with more severe false negative issue have more potential to receive clicks. We refer to this bias as user selection bias and define a query's probability of receiving clicks as the click propensity.
% \item[$\bullet$] We introduce a new click hypothesis to characterize user selection bias, and then propose the Bi-Level Inverse Propensity Weighting (\m) method, which consists of query-level inverse click propensity and position-level inverse propensity weighting to mitigate user selection bias and position bias, relatively.
% \item[$\bullet$] We theoretically analyze that leveraging the \m~method can obtain an unbiased ranking model, and conduct all the experiments on real-world click data, the Baidu-ULTR dataset, to demonstrate the superiority of our \m.
% \end{enumerate}