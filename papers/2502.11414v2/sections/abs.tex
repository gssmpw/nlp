\begin{abstract}
Most existing unbiased learning-to-rank (ULTR) approaches are based on the user examination hypothesis, which assumes that users will click a result only if it is both relevant and observed (typically modeled by position). However, in real-world scenarios, users often click only one or two results after examining multiple relevant options, due to limited patience or because their information needs have already been satisfied. Motivated by this, we propose a query-level click propensity model to capture the probability that users will click on different result lists, allowing for non-zero probabilities that users may not click on an observed relevant result. We hypothesize that this propensity increases when more potentially relevant results are present, and refer to this user behavior as relevance saturation bias. Our method introduces a Dual Inverse Propensity Weighting (\m) mechanism---combining query-level and position-level IPW---to address both relevance saturation and position bias. Through theoretical derivation, we prove that \m~can learn an unbiased ranking model. Experiments on the real-world Baidu-ULTR dataset demonstrate that our approach significantly outperforms state-of-the-art ULTR baselines. The code and dataset information can be found at \url{https://github.com/Trustworthy-Information-Access/DualIPW}.

% Unbiased Learning to Rank (ULTR) has been extensively explored to mitigate various biases in user clicks and learn an unbiased ranker. Most ULTR methods are based on the user examination hypothesis, which assumes that a document will be clicked if and only if it is relevant and observed by users. However, in real-world scenarios, search engines often return high-quality ranking lists containing numerous relevant documents, leading to the false negative issue, where relevant and observed documents remain unclicked. Furthermore, we believe that queries with more severe false negative issue are more likely to receive clicks because they contain more relevant documents. We refer to this bias as user interaction bias and define a query's probability of receiving clicks as the click propensity. To characterize user interaction bias, we introduce a new click hypothesis: the click probability of a document is determined by its relevance, observation probability, and click propensity. Based on this hypothesis, we propose the Bi-Level Inverse Propensity Weighting (\m) method, consisting of query-level inverse click propensity weighting and position-level inverse propensity weighting to alleviate user interaction bias and position bias, respectively. Through theoretical analysis, we prove that our \m~can learn an unbiased ranking model. Experiments on real-world click data, the Baidu-ULTR dataset, further demonstrate the effectiveness and necessity of the \m.
\end{abstract}
\keywords{Unbiased Learning to Rank, Position Bias, Relevance Saturation Bias}