\section{Related Work}
% tracking-by-detection paradigm: SORT, DeepSORT, ByteTrack
% transformer
% tracking-by-attention paradigm: MOTR, MOTRv2, MeMOT, MeMOTR
{\bfseries Multi-Object Tracking.}
Prevailing approaches to multi-object tracking problems can be classified into two main paradigms: tracking-by-detection and tracking-by-attention. Tracking-by-detection involves two consecutive stages: using a detector to predict the bounding boxes of objects and their corresponding features, followed by an association step to match these instances across frames. SORT \cite{wojke2017simple} employs the Kalman filter for motion modeling and associates tracking instances based on the intersection-over-union (IoU) of bounding boxes. DeepSORT \cite{Wojke2018deepsort} enhances this method by integrating a deep learning-based module to extract the appearance features of objects. More recently, ByteTrack \cite{zhang2022bytetrack} treats detection boxes as bytes and associates all of them, significantly boosting the tracker's performance. Advanced techniques in BoT-SORT \cite{aharon2022botsort}, and OC-SORT \cite{cao2023observation} further refine the association and post-processing steps, achieving even better performance. On the other hand, the advent of the Transformer architecture \cite{vaswani2017attention} has driven considerable advancements in the tracking-by-attention paradigm in recent years. TrackFormer \cite{meinhardt2021trackformer} introduces tracking instances as queries during the detection step. MOTR \cite{zeng2021motr} expands on this by incorporating a query interaction module, and MOTRv2 \cite{zhang2023motrv2} further improves its performance by initializing queries using detection results from YOLOX \cite{yolox2021}. Furthermore, by integrating historical features across frames as memory, MeMOT \cite{cai2022memot}, and MeMOTR \cite{MeMOTR} noticeably improve the performance of attention-based trackers.

{\bfseries Referring Multi-Object Tracking.}
Referring multi-object tracking is an emerging challenge, whereas referring single-object tracking, or segmentation, has been studied for years and has achieved good performance results \cite{ZHAO202310, zhou2023joint, zheng2023towards, wu2022language, botach2021end}. However, due to some intrinsic limitations, referring multi-object tracking cannot be directly expanded from these approaches. Precedent methods employ various techniques to tackle this additional textual referring expression. MENDER \cite{nguyen2023type} utilizes the cross-modality fusion module to handle three distinct inputs, including features from the video frame, tracking instances, and textual captions. To further enhance performance, they further implement third-order tensor decomposition. TransRMOT \cite{wu2023referring} places the cross-attention module at the beginning of the pipeline, aggregating the textual features into the detection step. Despite the flexibility gained, training these end-to-end tracking networks entirely for diverse video distributions incurs considerable computational costs due to the demanding training process. Recently, iKUN \cite{du2024ikun} designed a plug-and-play pipeline for referring multi-object tracking problems by decoupling the task into two sub-tasks: tracking and referring. It allows the tracker network to remain frozen during training, offering flexibility in utilizing different off-the-shelf trackers. Inspired by this approach, we explore this paradigm further and facilitate the method with our memory-efficient technique during the referring task, enhancing the performance of the pipeline.