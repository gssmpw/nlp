\section{Related Work}
% tracking-by-detection paradigm: SORT, DeepSORT, ByteTrack
% transformer
% tracking-by-attention paradigm: MOTR, MOTRv2, MeMOT, MeMOTR
{\bfseries Multi-Object Tracking.}
Prevailing approaches to multi-object tracking problems can be classified into two main paradigms: tracking-by-detection and tracking-by-attention. Tracking-by-detection involves two consecutive stages: using a detector to predict the bounding boxes of objects and their corresponding features, followed by an association step to match these instances across frames. SORT, "Single Object Tracking from Random Samples" ____ employs the Kalman filter for motion modeling and associates tracking instances based on the intersection-over-union (IoU) of bounding boxes. DeepSORT, "Deep Learning Features as Trajectories for Visual Object Tracking" ____ enhances this method by integrating a deep learning-based module to extract the appearance features of objects. More recently, ByteTrack, "Byte-Sized Object Tracking with Transformers" ____ treats detection boxes as bytes and associates all of them, significantly boosting the tracker's performance. Advanced techniques in BoT-SORT, "Bridging the Gap between Short-Term and Long-Term Tracking via Transferable Object Representation" ____, and OC-SORT, "Online Crowd Counting and Tracking with a Deep Learning Approach" ____ further refine the association and post-processing steps, achieving even better performance. On the other hand, the advent of the Transformer architecture, "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale" ____ has driven considerable advancements in the tracking-by-attention paradigm in recent years. TrackFormer, "Tracking Object as Queries by Adaptive Roundwise Refinement with Transformers" ____ introduces tracking instances as queries during the detection step. MOTR, "Motion-Guided Transformers for Multi-Object Tracking" ____ expands on this by incorporating a query interaction module, and MOTRv2, "MOTR: Motion-Guided Transformers for Real-Time Multi-Object Tracking" ____ further improves its performance by initializing queries using detection results from YOLOX, "YOLOv8: End-to-End Object Detection with Transformers" ____. Furthermore, by integrating historical features across frames as memory, MeMOT, "Memory-Augmented Motion Estimation for Visual Object Tracking" ____, and MeMOTR, "Motion-Aware Memory-Augmented MOTR for Real-Time Multi-Object Tracking" ____ noticeably improve the performance of attention-based trackers.

{\bfseries Referring Multi-Object Tracking.}
Referring multi-object tracking is an emerging challenge, whereas referring single-object tracking, or segmentation, has been studied for years and has achieved good performance results ____. However, due to some intrinsic limitations, referring multi-object tracking cannot be directly expanded from these approaches. Precedent methods employ various techniques to tackle this additional textual referring expression. MENDER, "MENDER: Multi-Object Tracking with Efficient Referring Expression Learning" ____ utilizes the cross-modality fusion module to handle three distinct inputs, including features from the video frame, tracking instances, and textual captions. To further enhance performance, they further implement third-order tensor decomposition. TransRMOT, "TransRMOT: A Cross-Modal Transformer for Referring Multi-Object Tracking" ____ places the cross-attention module at the beginning of the pipeline, aggregating the textual features into the detection step. Despite the flexibility gained, training these end-to-end tracking networks entirely for diverse video distributions incurs considerable computational costs due to the demanding training process. Recently, iKUN, "iKUN: Plug-and-Play Referencing in Multi-Object Tracking" ____ designed a plug-and-play pipeline for referring multi-object tracking problems by decoupling the task into two sub-tasks: tracking and referring. It allows the tracker network to remain frozen during training, offering flexibility in utilizing different off-the-shelf trackers. Inspired by this approach, we explore this paradigm further and facilitate the method with our memory-efficient technique during the referring task, enhancing the performance of the pipeline.