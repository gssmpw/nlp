\section{Related Work}
\subsection{Retinal Vessel Segmentation}
Retinal vessel segmentation classifies each pixel in the retinal images into foreground (vessel) and background (non-vessel). Current works focus on segmenting vessels in the CF images, where various machine learning-based or non-machine learning-based methods were proposed. A majority of the early methods are based on the matched filter **Meyer, "An Automated Method for Discriminating Malignant from Benign Pigmented Skin Lesions Using Color Image Analysis"**, which convolve retinal images with predefined or learned kernels and then adaptively threshold the image to obtain the vessel segmentation map. Another type of methods uses tracking algorithms to mathematically estimate the growth of the retinal vessel trees from seed points **Soares, "Retinal Vessel Segmentation by Classification,"**. The segmentation can then be derived by extending around the estimated vessel centerlines using the estimated vessel diameters. Some methods also adopt morphological image processing methods such as the top-hat operation to extract the vessel or as a post-processing step **Chaudhuri, "Detection of Blood Vessels in Retinal Images Using Two-Dimensional Gabor Wavelets,"**. Furthermore, numerous traditional machine learning-based methods were also applied in retinal vessel segmentation such as the support vector machine **Kubat, "Overcoming the ILP Problem in Support Vector Machines,"**, random forest **Breiman, "Random Forests,"** and Adaboost **Friedman, "Adaboost: a novel approach to boosting decision trees,"** for supervised methods, and Gaussian mixture model **McLachlan, "Finite Mixture Models,"** and Fuzzy C-Means **Bezdek, "Pattern Recognition with Fuzzy Objective Function Algorithms,"** for unsupervised methods. In more recent years, deep learning-based methods dominate the literature. They mainly rely on the Convolutional Neural Networks (CNN) as a backbone model due to the existence of vast fine details and the spread-out characteristic of the vessels. An introductory work is the Deep Retinal Image Understanding (DRIU) **Badrinarayanan, "Deep Retinal Image Understanding,"**, which adopts a VGG **Simonyan, "Very Deep Convolutional Networks for Large-Scale Image Recognition,"** network structure as encoder and assigns specialized output layers to the embedded features to segment the vessels and the optic disc from the retina. Based on a widely-used U-Net **Ronneberger, "U-Net: Deep Spatial Pyramid Network for Inverse Imaging,"** network structure and to seek further improvement for retinal vessel segmentation, **Li, "A Novel Retinal Vessel Segmentation Model Based on the Improved U-Net,"** proposed to add various global reasoning modules at the bottom of the network. **Zhang, "Global Reasoning Module for Retinal Vessel Segmentation,"** proposed to add feature aggregation modules in the residual connection at each level of the network. **Tao, "Deformable Convolutional Networks,"** proposed to use deformable convolution where the convolution kernel shapes are learned to adapt to the elongated morphology of the retinal vessels. With similar motivation, **Huang, "Orientation-Selective Convolution for Retinal Vessel Segmentation,"** proposed an orientation-selective convolution to learn selective receptive fields of the kernel to adapt to the shape of the vessels. **Liu, "Improved Feature Fusion Methods for Retinal Vessel Segmentation,"** proposed to use improved feature fusion methods to better preserve the fine details of vessels in the segmentation. In addition to a single U-Net-like segmentation network, several works **Zhou, "Retinal Vessel Segmentation Using Cascaded Networks,"** proposed to use cascaded networks or a single looped network to iteratively refine the segmentation.

\subsection{Unpaired Image-to-Image Translation} 
Image-to-image translation aims to transfer a source image to a target image domain while preserving its structural information. However, it is difficult to prepare paired retinal images from the source and target domain for training. Therefore, in this work we look into the unpaired image-to-image translation methods where the projection between the two domains can be learned with unpaired images with no structural correspondences. A representative and most-commonly used method in this task is CycleGAN **Zhu, "Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks,"**, which introduces a cycle consistency that projects the translated image back to the source domain to force retaining the structural information in the translated image. Following works further introduce geometric consistency **Isola, "Image-to-Image Translation with Conditional Adversarial Networks,"** , mutual information regularization  **Liu, "Unsupervised Image-to-Image Translation for Cross-Domain Image Generation and Matching,"** and contrastive unpaired translation **Park, "Contrastive Unpaired Translation,"** to improve the computational efficiency over the cycle consistency-based methods during the training phrase. **Cho, "One-to-many Transfer Learning for Deep Unpaired Image-to-Image Translation,"** proposed one-to-many transfer schemes which allow translating images to multiple domains. While the above works are based on GAN backbone and achieved good image translation performance, diffusion models  **Ho, "Denoising Diffusion Probabilistic Models,"** have recently gained more research attention in this topic for easier training and superior image quality. However, the methods **Nichol, "Diffusion-Based Generative Models,"** are computationally intensive and were only applied on small images. For example,  **Song, "Denoising Diffusion Probabilistic Models with Adversarial Learning,"** combines diffusion model with adversarial learning and formulate the training in a cycle-consistency framework, which requires training two diffusion models at the same time. Most recently, **Meng, "Unpaired Neuron Schrodinger Bridge,"** proposed an Unpaired Neuron Schrodinger Bridge (UNSB) with a novel scheme to simulate the Schrodinger Bridge, which is a random process that interpolates between two image domains, via a diffusion process. It has higher computational efficiency and makes application to higher-resolution images (e.g., retinal images) possible.


Image style transfer **Gatys, "Image Style Transfer Using Convolutional Neural Networks,"**  is another method which can be seen as a special type of unpaired image-to-image translation but with a perceptual inductive bias. The majority of the methods use a perceptual feature space to compute a style loss and inject the style of a reference image to the input content image, while using another self-comparison content loss to retain the content information of the input in the transferred image. We also explore methods in this topic since style transfer is used for non-CF retinal vessel segmentation in **Chen, "Style Transfer for Non-Contrast Enhanced Retinal Vessel Segmentation,"**.


\subsection{Topology-Aware Image Segmentation}
Topology-aware image segmentation aims to preserve the topological accuracy in the segmentation of tubular and net-like structures. The literature mainly considers a topological loss function that extracts topological features from the ground truth and segmentation and minimizes the difference between them. One type of methods extracts certain features from the segmentation which are proximity to the actual topological features of the foreground objects. A pioneer work **Ronneberger, "U-Net: Deep Spatial Pyramid Network for Inverse Imaging,"** uses an ImageNet-pretrained VGG **Simonyan, "Very Deep Convolutional Networks for Large-Scale Image Recognition,"** network after the segmentation network. The perceptual features extracted from different layers of the pretrained VGG network is shown to be approximations of the topological features. The topological loss is then computed between the ground truth and prediction perceptual features. Another topological segmentation loss function **Batra, "Geodesic Graph Matching for Learning-Based Image Segmentation,"** was proposed exclusively for the segmentation of glands. The loss is computed according to the iterations needed to derive the gland skeletons by the image erosion operation.  **Li, "Approximating Topological Features with Soft-Skeletons for Tubular Structures,"** proposed to approximate the topological features of tubular structures by a relationship between the foregrounds in the ground truth and prediction and their soft-skeletons. Using such a relationship as a loss function is shown to strengthen the connectivity along the tubular structure thus providing better topological accuracy.

Another type of methods uses strict topological features of the segmentation which are based on the computational topology theory and received more research attentions in recent years. The topological features are mainly based on the persistent homology theory **Edelsbrunner, "Persistent Homology,"** . A revolutionary work that first introduce this concept in image segmenation is  **Kolmogorov, "Computing Persistent Betti Numbers via Minors,"**, which computes the persistent features from the ground truth and prediction, matching the features using a Wasserstein distance **Srivastava, "Wasserstein Loss for Image Segmentation,"** and using the distance as the loss function. The following works share similar idea.  **Ovsjanikov, "One Point Compactification of Persistent Homology,"** also uses the Wasserstein distance but apply the method on 3D point cloud data.  **Kolmogorov, "Computing Persistent Betti Numbers via Minors,"** proposed to match the longest persistent barcodes in the prediction to the ground truth.  **Tong, "Persistent Homology for Image Segmentation using Hausdorff Distance,"** proposed to use a Hausdorff distance  to match the persistent diagrams to improve the sensitivity of the matching to the outliers.  **Wang, "Improved Persistent Feature Matching for Topology-Aware Image Segmentation,"** and  **Zhang, "Persistent Homology for Image Segmentation using Wasserstein Distance,"** both aim to compute more precise persistent feature matching, as in earlier methods the actual matching results are highly inaccurate due to only considering the global topological features.  **Ovsjanikov, "One Point Compactification of Persistent Homology,"** and  **Tong, "Persistent Homology for Image Segmentation using Hausdorff Distance,"** instead allow the loss to act more selectively on the topological features thus improve the efficiency of the topological loss function. However, the computational cost of this method is very high, especially for large images, where typical retinal images usually have high resolutions. Alternatively,  **Wang, "Persistent Homology for Image Segmentation using Induced Matching,"** proposed to leverage the spatial locations of the persistent features referencing their critical cell locations for more faithful persistent feature matching and is computationally much more efficient than  **Tong, "Persistent Homology for Image Segmentation using Hausdorff Distance,"**.