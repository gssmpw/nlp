%!TEX root=../paper.tex

\section{Related Work}
\label{sec:relatedwork}

\subsection{LLM-based Fault Localisation}

Fault localisation aims to automatically pinpoint software bugs, often by analysing program behaviour at different granularity levels. With large language models (LLMs) now available, researchers have explored using these models for fault localisation tasks. For instance, Wu et al.~\cite{wuLargeLanguageModels2023} achieved notable results in statement-level localisation given the buggy method using ChatGPT-4, though they identified challenges in extending the modelâ€™s context handling to the class level. Addressing this issue, AutoFL~\cite{kangQuantitativeQualitativeEvaluation2024a} introduced an agent architecture that leverages the function-calling capabilities of OpenAI models, allowing LLMs to autonomously explore repositories. This approach also posits that LLMs can potentially offer explanations for root causes of bugs. Similarly, FuseFL~\cite{widyasariDemystifyingFaultyCode2024a} aimed to enhance explainability by integrating spectrum-based fault localisation results into prompts, though its scope was limited to student programming assignments.

Alongside these advancements, efforts to utilize open-source language models in fault localisation have gained traction. Yang et al.~\cite{yangLargeLanguageModels2024a} proposed a test-free FL approach by fine-tuning large, open-source language models with datasets of buggy programs, with a focus on reducing programmer input. More recently, Liu et al.~\cite{liuEmpiricalEvaluationLarge2024} conducted an empirical evaluation comparing FL performance between proprietary and open-source models on novice programming tasks. They found that while ChatGPT-3.5 and 4 outperformed other models, open-source models demonstrated complementary behaviors, successfully localizing bugs that proprietary models missed.

\subsection{Ensemble Methods}

Ensemble learning combines predictions from multiple models to enhance overall performance by leveraging the diverse strengths of individual learners. Ensembles have been applied to fault localisation, based on the observation that no single FL technique is effective across all faults. Wang et al.~\cite{wangSearchbasedFaultLocalization2011} and Xuan et al.~\cite{xuanLearningCombineMultiple2014}, combined FL outputs from multiple models to improve localisation accuracy. Sohn et al.~\cite{sohnWhyTrainselectWhen2019b} further explored ensemble learning across FL methods, demonstrating that combining diverse techniques could achieve better performance. \cosmosfl is the first ensemble technique for LLM-based FL to the best of our knowledge.

Recent works have explored the use of multiple language models in ensemble methods. Jiang et al.~\cite{jiang2023llmblender} proposed an ensemble approach that leverages the complementary strengths of various language models by ranking and fusing their outputs, a method distinct from our approach. More closely, Zhang et al.~\cite{zhangInfeREStepbyStepRegex2023} demonstrated that combining outputs from different regex generators through self-consistency decoding resulted in improved performance. Kumar Dipongkor~\cite{kumardipongkorEnsembleMethodBug2024a} applied ensemble methods to bug triaging using BERT variants, showing that a voting-based ensemble consistently outperformed a stacking-based approach (i.e., training an additional layer on top of pre-trained language models' outputs). However, both of these methods aggregate lower-level outputs, while \cosmosfl employs a voting-based ensemble at the task level by aggregating the FL scores.