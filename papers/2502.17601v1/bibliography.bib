% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }
 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkh{\"a}user" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press"  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries




@article{zou2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@misc{kukačka2017regularizationdeeplearningtaxonomy,
      title={Regularization for Deep Learning: A Taxonomy}, 
      author={Jan Kukačka and Vladimir Golkov and Daniel Cremers},
      year={2017},
      eprint={1710.10686},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1710.10686}, 
}

@article{mikolov13,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@article{meng22,
  title={Mass-editing memory in a transformer},
  author={Meng, Kevin and Sharma, Arnab Sen and Andonian, Alex and Belinkov, Yonatan and Bau, David},
  journal={arXiv preprint arXiv:2210.07229},
  year={2022}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}



@article{gurnee23,
  title={Language models represent space and time},
  author={Gurnee, Wes and Tegmark, Max},
  journal={arXiv preprint arXiv:2310.02207},
  year={2023}
}

@article{liu19named,
  title={Knowledge-augmented language model and its application to unsupervised named-entity recognition},
  author={Liu, Angli and Du, Jingfei and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1904.04458},
  year={2019}
}

@article{tenney19,
  title={What do you learn from context? probing for sentence structure in contextualized word representations},
  author={Tenney, Ian and Xia, Patrick and Chen, Berlin and Wang, Alex and Poliak, Adam and McCoy, R Thomas and Kim, Najoung and Van Durme, Benjamin and Bowman, Samuel R and Das, Dipanjan and others},
  journal={arXiv preprint arXiv:1905.06316},
  year={2019}
}

@inproceedings{hewitt19,
    title = "{A} Structural Probe for Finding Syntax in Word Representations",
    author = "Hewitt, John  and
      Manning, Christopher D.",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1419/",
    doi = "10.18653/v1/N19-1419",
    pages = "4129--4138",
    abstract = "Recent work has improved our ability to detect linguistic knowledge in word representations. However, current methods for detecting syntactic knowledge do not test whether syntax trees are represented in their entirety. In this work, we propose a structural probe, which evaluates whether syntax trees are embedded in a linear transformation of a neural network`s word representation space. The probe identifies a linear transformation under which squared L2 distance encodes the distance between words in the parse tree, and one in which squared L2 norm encodes depth in the parse tree. Using our probe, we show that such transformations exist for both ELMo and BERT but not in baselines, providing evidence that entire syntax trees are embedded implicitly in deep models' vector geometry."
}
@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{zhang24,
  title={Towards General Conceptual Model Editing via Adversarial Representation Engineering},
  author={Zhang, Yihao and Wei, Zeming and Sun, Jun and Sun, Meng},
  journal={arXiv preprint arXiv:2404.13752},
  year={2024}
}

@article{zhang2023towards,
  title={Towards best practices of activation patching in language models: Metrics and methods},
  author={Zhang, Fred and Nanda, Neel},
  journal={arXiv preprint arXiv:2309.16042},
  year={2023}
}


@article{rosati24,
  title={Representation noising effectively prevents harmful fine-tuning on LLMs},
  author={Rosati, Domenic and Wehner, Jan and Williams, Kai and Bartoszcze, {\L}ukasz and Atanasov, David and Gonzales, Robie and Majumdar, Subhabrata and Maple, Carsten and Sajjad, Hassan and Rudzicz, Frank},
  journal={arXiv preprint arXiv:2405.14577},
  year={2024}
}

@article{xiao24,
  title={Enhancing Multiple Dimensions of Trustworthiness in LLMs via Sparse Activation Control},
  author={Xiao, Yuxin and Wan, Chaoqun and Zhang, Yonggang and Wang, Wenxiao and Lin, Binbin and He, Xiaofei and Shen, Xu and Ye, Jieping},
  journal={arXiv preprint arXiv:2411.02461},
  year={2024}
}

@article{zhao24,
  title={Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering},
  author={Zhao, Yu and Devoto, Alessio and Hong, Giwon and Du, Xiaotang and Gema, Aryo Pradipta and Wang, Hongru and Wong, Kam-Fai and Minervini, Pasquale},
  journal={arXiv preprint arXiv:2410.15999},
  year={2024}
}

@article{rando24,
  title={Gradient-based jailbreak images for multimodal fusion models},
  author={Rando, Javier and Korevaar, Hannah and Brinkman, Erik and Evtimov, Ivan and Tram{\`e}r, Florian},
  journal={arXiv preprint arXiv:2410.03489},
  year={2024}
}


@article{bhattacharjee24,
  title={Towards Inference-time Category-wise Safety Steering for Large Language Models},
  author={Bhattacharjee, Amrita and Ghosh, Shaona and Rebedea, Traian and Parisien, Christopher},
  journal={arXiv preprint arXiv:2410.01174},
  year={2024}
}

@inproceedings{tas24,
  title={Words in Motion: Extracting Interpretable Control Vectors for Motion Transformers},
  author={Tas, Omer Sahin and Wagner, Royden},
  booktitle={Interpretable AI: Past, Present and Future}
}

@article{feng24,
  title={Legend: Leveraging Representation Engineering to Annotate Safety Margin for Preference Datasets},
  author={Feng, Duanyu and Qin, Bowen and Huang, Chen and Huang, Youcheng and Zhang, Zheng and Lei, Wenqiang},
  journal={arXiv preprint arXiv:2406.08124},
  year={2024}
}

@article{luo24,
  title={PaCE: Parsimonious Concept Engineering for Large Language Models},
  author={Luo, Jinqi and Ding, Tianjiao and Chan, Kwan Ho Ryan and Thaker, Darshan and Chattopadhyay, Aditya and Callison-Burch, Chris and Vidal, Ren{\'e}},
  journal={arXiv preprint arXiv:2406.04331},
  year={2024}
}

@article{zou24circuit,
  title={Improving Alignment and Robustness with Short Circuiting},
  author={Zou, Andy and Phan, Long and Wang, Justin and Duenas, Derek and Lin, Maxwell and Andriushchenko, Maksym and Wang, Rowan and Kolter, Zico and Fredrikson, Matt and Hendrycks, Dan},
  journal={arXiv preprint arXiv:2406.04313},
  year={2024}
}

@article{dong24,
  title={ConTrans: Weak-to-Strong Alignment Engineering via Concept Transplantation},
  author={Dong, Weilong and Wu, Xinwei and Jin, Renren and Xu, Shaoyang and Xiong, Deyi},
  journal={arXiv preprint arXiv:2405.13578},
  year={2024}
}

@article{zhao2024expperp,
  title={Opening the black box of large language models: Two views on holistic interpretability},
  author={Zhao, Haiyan and Yang, Fan and Lakkaraju, Himabindu and Du, Mengnan},
  journal={arXiv e-prints},
  pages={arXiv--2402},
  year={2024}
}

@article{wolf24,
  title={Tradeoffs Between Alignment and Helpfulness in Language Models},
  author={Wolf, Yotam and Wies, Noam and Shteyman, Dorin and Rothberg, Binyamin and Levine, Yoav and Shashua, Amnon},
  journal={arXiv preprint arXiv:2401.16332},
  year={2024}
}

@article{rai2024practical,
  title={A practical review of mechanistic interpretability for transformer-based language models},
  author={Rai, Daking and Zhou, Yilun and Feng, Shi and Saparov, Abulhair and Yao, Ziyu},
  journal={arXiv preprint arXiv:2407.02646},
  year={2024}
}

@misc{vgel2024representation,
  author = {VGEL.ME},
  title = {Representation Engineering: Mistral-7B an Acid Trip},
  year = {2024},
  month = {January},
  url = {https://vgel.me/posts/representation-engineering/},
  note = {Accessed: 2025-02-19}
}

@article{li24,
  title={Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation Engineering},
  author={Li, Tianlong and Zheng, Xiaoqing and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2401.06824},
  year={2024}
}

@article{liu23,
  title={Aligning large language models with human preferences through representation engineering},
  author={Liu, Wenhao and Wang, Xiaohua and Wu, Muling and Li, Tianlong and Lv, Changze and Ling, Zixuan and Zhu, Jianhao and Zhang, Cenyuan and Zheng, Xiaoqing and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2312.15997},
  year={2023}
}

@article{mayne24,
  title={Can sparse autoencoders be used to decompose and interpret steering vectors?},
  author={Mayne, Harry and Yang, Yushi and Mahdi, Adam},
  journal={arXiv preprint arXiv:2411.08790},
  year={2024}
}

@article{seyitoglu24,
  title={Extracting Unlearned Information from LLMs with Activation Steering},
  author={Seyito{\u{g}}lu, Atakan and Kuvshinov, Aleksei and Schwinn, Leo and G{\"u}nnemann, Stephan},
  journal={arXiv preprint arXiv:2411.02631},
  year={2024}
}

@article{chalnev24,
  title={Improving Steering Vectors by Targeting Sparse Autoencoder Features},
  author={Chalnev, Sviatoslav and Siu, Matthew and Conmy, Arthur},
  journal={arXiv preprint arXiv:2411.02193},
  year={2024}
}

@article{stolfo24,
  title={Improving Instruction-Following in Language Models through Activation Steering},
  author={Stolfo, Alessandro and Balachandran, Vidhisha and Yousefi, Safoora and Horvitz, Eric and Nushi, Besmira},
  journal={arXiv preprint arXiv:2410.12877},
  year={2024}
}

@article{liu2024survey,
  title={A survey of attacks on large vision-language models: Resources, advances, and future trends},
  author={Liu, Daizong and Yang, Mingyu and Qu, Xiaoye and Zhou, Pan and Cheng, Yu and Hu, Wei},
  journal={arXiv preprint arXiv:2407.07403},
  year={2024}
}

@article{yi2024jailbreak,
  title={Jailbreak attacks and defenses against large language models: A survey},
  author={Yi, Sibo and Liu, Yule and Sun, Zhen and Cong, Tianshuo and He, Xinlei and Song, Jiaxing and Xu, Ke and Li, Qi},
  journal={arXiv preprint arXiv:2407.04295},
  year={2024}
}

@inproceedings{bertino2021ai,
  title={AI for Security and Security for AI},
  author={Bertino, Elisa and Kantarcioglu, Murat and Akcora, Cuneyt Gurcan and Samtani, Sagar and Mittal, Sudip and Gupta, Maanak},
  booktitle={Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy},
  pages={333--334},
  year={2021}
}

@article{wang24,
  title={Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors},
  author={Wang, Weixuan and Yang, Jingyuan and Peng, Wei},
  journal={arXiv preprint arXiv:2410.12299},
  year={2024}
}

@article{stoher24,
  title={Activation scaling for steering and interpreting language models},
  author={Stoehr, Niklas and Du, Kevin and Sn{\ae}bjarnarson, V{\'e}steinn and West, Robert and Cotterell, Ryan and Schein, Aaron},
  journal={arXiv preprint arXiv:2410.04962},
  year={2024}
}

@article{pham24,
  title={Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective},
  author={Pham, Van-Cuong and Nguyen, Thien Huu},
  journal={arXiv preprint arXiv:2409.10053},
  year={2024}
}

@article{zhang24latent,
  title={Uncovering Latent Chain of Thought Vectors in Language Models},
  author={Zhang, Jason and Viteri, Scott},
  journal={arXiv preprint arXiv:2409.14026},
  year={2024}
}

@article{wang2024inferaligner,
  title={Inferaligner: Inference-time alignment for harmlessness through cross-model guidance},
  author={Wang, Pengyu and Zhang, Dong and Li, Linyang and Tan, Chenkun and Wang, Xinghao and Ren, Ke and Jiang, Botian and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2401.11206},
  year={2024}
}

@article{beaglehole25,
      title={Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers}, 
      author={Daniel Beaglehole and Adityanarayanan Radhakrishnan and Enric Boix-Adserà and Mikhail Belkin},
      year={2025},
      journal={arXiv preprint arXiv:2502.03708} 
}

@article{jiang2025probe,
      title={Probe-Free Low-Rank Activation Intervention}, 
      author={Chonghe Jiang and Bao Nguyen and Anthony Man-Cho So and Viet Anh Nguyen},
      year={2025},
      journal={arXiv preprint arXiv:2502.04043}
}

@article{nguyen2025,
      title={Task-driven Layerwise Additive Activation Intervention}, 
      author={Hieu Trung Nguyen and Bao Nguyen and Binh Nguyen and Viet Anh Nguyen},
      year={2025},
      journal={arXiv preprint arXiv:2502.06115},
}

@article{bereska24,
  title={Mechanistic Interpretability for AI Safety--A Review},
  author={Bereska, Leonard and Gavves, Efstratios},
  journal={arXiv preprint arXiv:2404.14082},
  year={2024}
}

@article{li2024vision,
  title={Do Vision and Language Models Share Concepts? A Vector Space Alignment Study},
  author={Li, Jiaang and Kementchedjhieva, Yova and Fierro, Constanza and S{\o}gaard, Anders},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={1232--1249},
  year={2024},
  publisher={MIT Press 255 Main Street, 9th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{kastner24,
  title={Explaining AI through mechanistic interpretability},
  author={K{\"a}stner, Lena and Crook, Barnaby},
  journal={European Journal for Philosophy of Science},
  volume={14},
  number={4},
  pages={52},
  year={2024},
  publisher={Springer}
}

@article{ngueajio25,
  title={Decoding Fake News and Hate Speech: A Survey of Explainable AI Techniques: A Survey of Explainable AI Techniques.},
  author={Ngueajio, Mikel and Aryal, Saurav and Atemkeng, Marcellin and Washington, Gloria and Rawat, Danda},
  journal={ACM Computing Surveys},
  year={2025},
  publisher={ACM New York, NY}
}


@article{liu2023icv,
  title={In-context vectors: Making in context learning more effective and controllable through latent space steering},
  author={Liu, Sheng and Ye, Haotian and Xing, Lei and Zou, James},
  journal={arXiv preprint arXiv:2311.06668},
  year={2023}
}

@article{zhuang2024vector,
  title={Vector-ICL: In-context Learning with Continuous Vector Representations},
  author={Zhuang, Yufan and Singh, Chandan and Liu, Liyuan and Shang, Jingbo and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2410.05629},
  year={2024}
}

@article{piantadosi2024concepts,
  title={Why concepts are (probably) vectors},
  author={Piantadosi, Steven T and Muller, Dyana CY and Rule, Joshua S and Kaushik, Karthikeya and Gorenstein, Mark and Leib, Elena R and Sanford, Emily},
  journal={Trends in Cognitive Sciences},
  volume={28},
  number={9},
  pages={844--856},
  year={2024},
  publisher={Elsevier}
}

@article{hendel2023context,
  title={In-context learning creates task vectors},
  author={Hendel, Roee and Geva, Mor and Globerson, Amir},
  journal={arXiv preprint arXiv:2310.15916},
  year={2023}
}
@article{devin2019plan,
  title={Plan arithmetic: Compositional plan vectors for multi-task control},
  author={Devin, Coline and Geng, Daniel and Abbeel, Pieter and Darrell, Trevor and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.14033},
  year={2019}
}


@article{bowen2024beyond,
  title={Beyond Task Vectors: Selective Task Arithmetic Based on Importance Metrics},
  author={Bowen, Tian and Songning, Lai and Jiemin, Wu and Zhihao, Shuai and Shiming, Ge and Yutao, Yue},
  journal={arXiv preprint arXiv:2411.16139},
  year={2024}
}

@article{pham2024robust,
  title={Robust Concept Erasure Using Task Vectors},
  author={Pham, Minh and Marshall, Kelly O and Hegde, Chinmay and Cohen, Niv},
  journal={arXiv preprint arXiv:2404.03631},
  year={2024}
}

@article{yang2025task,
  title={Task Vectors in In-Context Learning: Emergence, Formation, and Benefit},
  author={Yang, Liu and Lin, Ziqian and Lee, Kangwook and Papailiopoulos, Dimitris and Nowak, Robert},
  journal={arXiv preprint arXiv:2501.09240},
  year={2025}
}

@article{olsson2022context,
  title={In-context learning and induction heads},
  author={Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and others},
  journal={arXiv preprint arXiv:2209.11895},
  year={2022}
}

@inproceedings{moosavi2017universal,
  title={Universal adversarial perturbations},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1765--1773},
  year={2017}
}

@article{cao2024nothing,
  title={Nothing in excess: Mitigating the exaggerated safety for llms via safety-conscious activation steering},
  author={Cao, Zouying and Yang, Yifei and Zhao, Hai},
  journal={arXiv preprint arXiv:2408.11491},
  year={2024}
}

@article{ren2024identifying,
  title={Identifying semantic induction heads to understand in-context learning},
  author={Ren, Jie and Guo, Qipeng and Yan, Hang and Liu, Dongrui and Zhang, Quanshi and Qiu, Xipeng and Lin, Dahua},
  journal={arXiv preprint arXiv:2402.13055},
  year={2024}
}

@article{sun2024concept,
  title={Concept Bottleneck Large Language Models},
  author={Sun, Chung-En and Oikarinen, Tuomas and Ustun, Berk and Weng, Tsui-Wei},
  journal={arXiv preprint arXiv:2412.07992},
  year={2024}
}

@article{akyurek2022learning,
  title={What learning algorithm is in-context learning? investigations with linear models},
  author={Aky{\"u}rek, Ekin and Schuurmans, Dale and Andreas, Jacob and Ma, Tengyu and Zhou, Denny},
  journal={arXiv preprint arXiv:2211.15661},
  year={2022}
}

@article{agarwal2024many,
  title={Many-shot in-context learning},
  author={Agarwal, Rishabh and Singh, Avi and Zhang, Lei M and Bohnet, Bernd and Rosias, Luis and Chan, Stephanie and Zhang, Biao and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and others},
  journal={arXiv preprint arXiv:2404.11018},
  year={2024}
}

@article{zheng2024distributed,
  title={Distributed Rule Vectors is A Key Mechanism in Large Language Models' In-Context Learning},
  author={Zheng, Bowen and Ma, Ming and Lin, Zhongqiao and Yang, Tianming},
  journal={arXiv preprint arXiv:2406.16007},
  year={2024}
}

@article{liu2024gpt,
  title={GPT understands, too},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  journal={AI Open},
  volume={5},
  pages={208--215},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{panigrahi2023task,
  title={Task-specific skill localization in fine-tuned language models},
  author={Panigrahi, Abhishek and Saunshi, Nikunj and Zhao, Haoyu and Arora, Sanjeev},
  booktitle={International Conference on Machine Learning},
  pages={27011--27033},
  year={2023},
  organization={PMLR}
}

@inproceedings{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  booktitle={Extended abstracts of the 2021 CHI conference on human factors in computing systems},
  pages={1--7},
  year={2021}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{ilharco2022editing,
  title={Editing models with task arithmetic},
  author={Ilharco, Gabriel and Ribeiro, Marco Tulio and Wortsman, Mitchell and Gururangan, Suchin and Schmidt, Ludwig and Hajishirzi, Hannaneh and Farhadi, Ali},
  journal={arXiv preprint arXiv:2212.04089},
  year={2022}
}


@article{mu2024learning,
  title={Learning to compress prompts with gist tokens},
  author={Mu, Jesse and Li, Xiang and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{shao2023compositional,
  title={Compositional task representations for large language models},
  author={Shao, Nan and Cai, Zefan and Liao, Chonghua and Zheng, Yanan and Yang, Zhilin and others},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{lampinen2020transforming,
  title={Transforming task representations to perform novel tasks},
  author={Lampinen, Andrew K and McClelland, James L},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={52},
  pages={32970--32981},
  year={2020},
  publisher={National Acad Sciences}
}

@article{xie2021explanation,
  title={An explanation of in-context learning as implicit bayesian inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  journal={arXiv preprint arXiv:2111.02080},
  year={2021}
}

@article{huang2024multimodal,
  title={Multimodal task vectors enable many-shot multimodal in-context learning},
  author={Huang, Brandon and Mitra, Chancharik and Arbelle, Assaf and Karlinsky, Leonid and Darrell, Trevor and Herzig, Roei},
  journal={arXiv preprint arXiv:2406.15334},
  year={2024}
}

@article{han2024parameter,
  title={Parameter-efficient fine-tuning for large models: A comprehensive survey},
  author={Han, Zeyu and Gao, Chao and Liu, Jinyang and Zhang, Jeff and Zhang, Sai Qian},
  journal={arXiv preprint arXiv:2403.14608},
  year={2024}
}

@article{sahoo2024systematic,
  title={A systematic survey of prompt engineering in large language models: Techniques and applications},
  author={Sahoo, Pranab and Singh, Ayush Kumar and Saha, Sriparna and Jain, Vinija and Mondal, Samrat and Chadha, Aman},
  journal={arXiv preprint arXiv:2402.07927},
  year={2024}
}

@inproceedings{marvin2023prompt,
  title={Prompt engineering in large language models},
  author={Marvin, Ggaliwango and Hellen, Nakayiza and Jjingo, Daudi and Nakatumba-Nabende, Joyce},
  booktitle={International conference on data intelligence and cognitive informatics},
  pages={387--402},
  year={2023},
  organization={Springer}
}


@article{luo2024task,
  title={Task Vectors are Cross-Modal},
  author={Luo, Grace and Darrell, Trevor and Bar, Amir},
  journal={arXiv preprint arXiv:2410.22330},
  year={2024}
}

@article{rai24,
  title={A practical review of mechanistic interpretability for transformer-based language models},
  author={Rai, Daking and Zhou, Yilun and Feng, Shi and Saparov, Abulhair and Yao, Ziyu},
  journal={arXiv preprint arXiv:2407.02646},
  year={2024}
}

@article{chen24,
  title={GRATH: Gradual Self-Truthifying for Large Language Models},
  author={Chen, Weixin and Song, Dawn and Li, Bo},
  journal={arXiv preprint arXiv:2401.12292},
  year={2024}
}

@article{leong23,
  title={Self-detoxifying language models via toxification reversal},
  author={Leong, Chak Tou and Cheng, Yi and Wang, Jiashuo and Wang, Jian and Li, Wenjie},
  journal={arXiv preprint arXiv:2310.09573},
  year={2023}
}


@article{tan24,
  title={Analyzing the generalization and reliability of steering vectors},
  author={Tan, Daniel and Chanin, David and Lynch, Aengus and Kanoulas, Dimitrios and Paige, Brooks and Garriga-Alonso, Adria and Kirk, Robert},
  journal={arXiv preprint arXiv:2407.12404},
  year={2024}
}

@article{price24,
  title={Future events as backdoor triggers: Investigating temporal vulnerabilities in llms},
  author={Price, Sara and Panickssery, Arjun and Bowman, Sam and Stickland, Asa Cooper},
  journal={arXiv preprint arXiv:2407.04108},
  year={2024}
}


@article{stickland24,
  title={Steering without side effects: Improving post-deployment control of language models},
  author={Stickland, Asa Cooper and Lyzhov, Alexander and Pfau, Jacob and Mahdi, Salsabila and Bowman, Samuel R},
  journal={arXiv preprint arXiv:2406.15518},
  year={2024}
}

@misc{kaufmann2024surveyreinforcementlearninghuman,
      title={A Survey of Reinforcement Learning from Human Feedback}, 
      author={Timo Kaufmann and Paul Weng and Viktor Bengs and Eyke Hüllermeier},
      year={2024},
      eprint={2312.14925},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.14925}, 
}
@article{ghandehariom24,
  title={Who's asking? User personas and the mechanics of latent misalignment},
  author={Ghandeharioun, Asma and Yuan, Ann and Guerard, Marius and Reif, Emily and Lepori, Michael A and Dixon, Lucas},
  journal={arXiv preprint arXiv:2406.12094},
  year={2024}
}

@article{park2024iclr,
  title={Iclr: In-context learning of representations},
  author={Park, Core Francisco and Lee, Andrew and Lubana, Ekdeep Singh and Yang, Yongyi and Okawa, Maya and Nishi, Kento and Wattenberg, Martin and Tanaka, Hidenori},
  journal={arXiv preprint arXiv:2501.00070},
  year={2024}
}

@article{parkmeasuring,
  title={Measuring Effects of Steered Representation in Large Language Models},
  author={Park, Bumjin and Joung, Youngju and Kim, Yeonjea and Choi, Jaesik and others}
}

@article{rahn24,
  title={Controlling Large Language Model Agents with Entropic Activation Steering},
  author={Rahn, Nate and D'Oro, Pierluca and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2406.00244},
  year={2024}
}

@article{wang24steering,
  title={Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories},
  author={Wang, Tianlong and Jiao, Xianfeng and He, Yifan and Chen, Zhongzhi and Zhu, Yinghao and Chu, Xu and Gao, Junyi and Wang, Yasha and Ma, Liantao},
  journal={arXiv preprint arXiv:2406.00034},
  year={2024}
}

@article{lucchetti24,
  title={Activation Steering for Robust Type Prediction in CodeLLMs},
  author={Lucchetti, Francesca and Guha, Arjun},
  journal={arXiv preprint arXiv:2404.01903},
  year={2024}
}

@article{c,
  title={Extending Activation Steering to Broad Skills and Multiple Behaviours},
  author={van der Weij, Teun and Poesio, Massimo and Schoots, Nandi},
  journal={arXiv preprint arXiv:2403.05767},
  year={2024}
}

@article{qian24,
  title={Towards tracing trustworthiness dynamics: Revisiting pre-training period of large language models},
  author={Qian, Chen and Zhang, Jie and Yao, Wei and Liu, Dongrui and Yin, Zhenfei and Qiao, Yu and Liu, Yong and Shao, Jing},
  journal={arXiv preprint arXiv:2402.19465},
  year={2024}
}

@article{singh24,
  title={Mimic: Minimally modified counterfactuals in the representation space},
  author={Singh, Shashwat and Ravfogel, Shauli and Herzig, Jonathan and Aharoni, Roee and Cotterell, Ryan and Kumaraguru, Ponnurangam},
  journal={arXiv preprint arXiv:2402.09631},
  year={2024}
}

@article{lu24,
  title={Investigating Bias Representations in Llama 2 Chat via Activation Steering},
  author={Lu, Dawn and Rimsky, Nina},
  journal={arXiv preprint arXiv:2402.00402},
  year={2024}
}

@article{rutte24,
  title={A Language Model's Guide Through Latent Space},
  author={von R{\"u}tte, Dimitri and Anagnostidis, Sotiris and Bachmann, Gregor and Hofmann, Thomas},
  journal={arXiv preprint arXiv:2402.14433},
  year={2024}
}

@article{alain16,
  title={Understanding intermediate layers using linear classifier probes},
  author={Alain, Guillaume},
  journal={arXiv preprint arXiv:1610.01644},
  year={2016}
}

@article{wang2024inferaligner,
  title={Inferaligner: Inference-time alignment for harmlessness through cross-model guidance},
  author={Wang, Pengyu and Zhang, Dong and Li, Linyang and Tan, Chenkun and Wang, Xinghao and Ren, Ke and Jiang, Botian and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2401.11206},
  year={2024}
}

@article{zheng2023learn,
  title={Learn from model beyond fine-tuning: A survey},
  author={Zheng, Hongling and Shen, Li and Tang, Anke and Luo, Yong and Hu, Han and Du, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:2310.08184},
  year={2023}
}

@article{dodge2020fine,
  title={Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping},
  author={Dodge, Jesse and Ilharco, Gabriel and Schwartz, Roy and Farhadi, Ali and Hajishirzi, Hannaneh and Smith, Noah},
  journal={arXiv preprint arXiv:2002.06305},
  year={2020}
}

@inproceedings{zhai2018autoencoder,
  title={Autoencoder and its various variants},
  author={Zhai, Junhai and Zhang, Sufang and Chen, Junfen and He, Qiang},
  booktitle={2018 IEEE international conference on systems, man, and cybernetics (SMC)},
  pages={415--419},
  year={2018},
  organization={IEEE}
}

@article{berahmand2024autoencoders,
  title={Autoencoders and their applications in machine learning: a survey},
  author={Berahmand, Kamal and Daneshfar, Fatemeh and Salehi, Elaheh Sadat and Li, Yuefeng and Xu, Yue},
  journal={Artificial Intelligence Review},
  volume={57},
  number={2},
  pages={28},
  year={2024},
  publisher={Springer}
}

@article{panickssery24,
  title={Steering llama 2 via contrastive activation addition},
  author={Panickssery, Nina and Gabrieli, Nick and Schulz, Julian and Tong, Meg and Hubinger, Evan and Turner, Alexander Matt},
  journal={arXiv preprint arXiv:2312.06681},
  year={2023}
}

@article{jorgensen24,
  title={Improving activation steering in language models with mean-centring},
  author={Jorgensen, Ole and Cope, Dylan and Schoots, Nandi and Shanahan, Murray},
  journal={arXiv preprint arXiv:2312.03813},
  year={2023}
}

@article{wang24trojan,
  title={Backdoor activation attack: Attack large language models using activation steering for safety-alignment},
  author={Wang, Haoran and Shu, Kai},
  journal={arXiv preprint arXiv:2311.09433},
  year={2023}
}

@misc{mallen2024elicitinglatentknowledgequirky,
      title={Eliciting Latent Knowledge from Quirky Language Models}, 
      author={Alex Mallen and Madeline Brumley and Julia Kharchenko and Nora Belrose},
      year={2024},
      eprint={2312.01037},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.01037}, 
}
@article{park24,
  title={The linear representation hypothesis and the geometry of large language models},
  author={Park, Kiho and Choe, Yo Joong and Veitch, Victor},
  journal={arXiv preprint arXiv:2311.03658},
  year={2023}
}

@article{mattturner24,
  title={Activation addition: Steering language models without optimization},
  author={Turner, Alexander Matt and Thiergart, Lisa and Leech, Gavin and Udell, David and Vazquez, Juan J and Mini, Ulisse and MacDiarmid, Monte},
  journal={arXiv e-prints},
  pages={arXiv--2308},
  year={2023}
}

@article{subramani22,
  title={Extracting latent steering vectors from pretrained language models},
  author={Subramani, Nishant and Suresh, Nivedita and Peters, Matthew E},
  journal={arXiv preprint arXiv:2205.05124},
  year={2022}
}

@article{desantis24,
  title={Visual-TCAV: Concept-based Attribution and Saliency Maps for Post-hoc Explainability in Image Classification},
  author={De Santis, Antonio and Campi, Riccardo and Bianchi, Matteo and Brambilla, Marco},
  journal={arXiv preprint arXiv:2411.05698},
  year={2024}
}

@article{fleissner24,
  title={Decision Trees for Interpretable Clusters in Mixture Models and Deep Representations},
  author={Fleissner, Maximilian and Zarvandi, Maedeh and Ghoshdastidar, Debarghya},
  journal={arXiv preprint arXiv:2411.01576},
  year={2024}
}

@article{weij24,
      title={Extending Activation Steering to Broad Skills and Multiple Behaviours}, 
      author={Teun van der Weij and Massimo Poesio and Nandi Schoots},
      year={2024},
      journal={arXiv preprint arXiv:2403.05767} 
}

@inproceedings{schmalwasser24,
  title={Exploiting Text-Image Latent Spaces for the Description of Visual Concepts},
  author={Schmalwasser, Laines and Gawlikowski, Jakob and Denzler, Joachim and Niebling, Julia},
  booktitle={International Conference on Pattern Recognition},
  pages={109--125},
  year={2024},
  organization={Springer}
}

@article{garg24,
  title={KTCR: Improving Implicit Hate Detection with Knowledge Transfer driven Concept Refinement},
  author={Garg, Samarth and Kavuri, Vivek Hruday and Shroff, Gargi and Mishra, Rahul},
  journal={arXiv preprint arXiv:2410.15314},
  year={2024}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022}
}

@article{li2022emergent,
  title={Emergent world representations: Exploring a sequence model trained on a synthetic task},
  author={Li, Kenneth and Hopkins, Aspen K and Bau, David and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  journal={arXiv preprint arXiv:2210.13382},
  year={2022}
}

@article{crabbe2022concept,
  title={Concept activation regions: A generalized framework for concept-based explanations},
  author={Crabb{\'e}, Jonathan and van der Schaar, Mihaela},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2590--2607},
  year={2022}
}

@article{ch2023androids,
  title={Do Androids Know They're Only Dreaming of Electric Sheep?},
  author={CH-Wang, Sky and Van Durme, Benjamin and Eisner, Jason and Kedzie, Chris},
  journal={arXiv preprint arXiv:2312.17249},
  year={2023}
}

@article{chen2024inside,
  title={INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection},
  author={Chen, Chao and Liu, Kai and Chen, Ze and Gu, Yi and Wu, Yue and Tao, Mingyuan and Fu, Zhihang and Ye, Jieping},
  journal={arXiv preprint arXiv:2402.03744},
  year={2024}
}

@article{herrmann2025standards,
  title={Standards for belief representations in LLMs},
  author={Herrmann, Daniel A and Levinstein, Benjamin A},
  journal={Minds and Machines},
  volume={35},
  number={1},
  pages={1--25},
  year={2025},
  publisher={Springer}
}

@inproceedings{lillms,
  title={Do LLMs Build World Representations? Probing Through the Lens of State Abstraction},
  author={Li, Zichao and Cao, Yanshuai and Cheung, Jackie CK},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}
}
@article{huang24,
  title={LG-CAV: Train Any Concept Activation Vector with Language Guidance},
  author={Huang, Qihan and Song, Jie and Xue, Mengqi and Zhang, Haofei and Hu, Bingde and Wang, Huiqiong and Jiang, Hao and Wang, Xingen and Song, Mingli},
  journal={arXiv preprint arXiv:2410.10308},
  year={2024}
}

@inproceedings{bronzini2024unveiling,
  title={Unveiling LLMs: The evolution of latent representations in a dynamic knowledge graph},
  author={Bronzini, Marco and Nicolini, Carlo and Lepri, Bruno and Staiano, Jacopo and Passerini, Andrea},
  booktitle={First Conference on Language Modeling},
  year={2024}
}

@article{liu2024llm4gen,
  title={Llm4gen: Leveraging semantic representation of llms for text-to-image generation},
  author={Liu, Mushui and Ma, Yuhang and Zhen, Yang and Dan, Jun and Yu, Yunlong and Zhao, Zeng and Hu, Zhipeng and Liu, Bai and Fan, Changjie},
  journal={arXiv preprint arXiv:2407.00737},
  year={2024}
}

@article{jiang2024origins,
  title={On the origins of linear representations in large language models},
  author={Jiang, Yibo and Rajendran, Goutham and Ravikumar, Pradeep and Aragam, Bryon and Veitch, Victor},
  journal={arXiv preprint arXiv:2403.03867},
  year={2024}
}

@inproceedings{manigrasso2024probing,
  title={Probing LLMs for logical reasoning},
  author={Manigrasso, Francesco and Schouten, Stefan and Morra, Lia and Bloem, Peter},
  booktitle={International Conference on Neural-Symbolic Learning and Reasoning},
  pages={257--278},
  year={2024},
  organization={Springer}
}

@inproceedings{sam2024eliciting,
  title={Eliciting Black-Box Representations from LLMs through Self-Queries},
  author={Sam, Dylan and Finzi, Marc Anton},
  booktitle={ICML 2024 Next Generation of AI Safety Workshop}
}

@article{yan2024exploring,
  title={Exploring the LLM Journey from Cognition to Expression with Linear Representations},
  author={Yan, Yuzi and Li, Jialian and Zhang, Yipin and Yan, Dong},
  journal={arXiv preprint arXiv:2405.16964},
  year={2024}
}

@article{pres24,
      title={Towards Reliable Evaluation of Behavior Steering Interventions in LLMs}, 
      author={Itamar Pres and Laura Ruis and Ekdeep Singh Lubana and David Krueger},
      year={2024},
      journal={arXiv preprint arXiv2410.17245}
}

@article{sam2025predicting,
  title={Predicting the Performance of Black-box LLMs through Self-Queries},
  author={Sam, Dylan and Finzi, Marc and Kolter, J Zico},
  journal={arXiv preprint arXiv:2501.01558},
  year={2025}
}

@article{zhang2024personalization,
  title={Personalization of large language models: A survey},
  author={Zhang, Zhehao and Rossi, Ryan A and Kveton, Branislav and Shao, Yijia and Yang, Diyi and Zamani, Hamed and Dernoncourt, Franck and Barrow, Joe and Yu, Tong and Kim, Sungchul and others},
  journal={arXiv preprint arXiv:2411.00027},
  year={2024}
}

@article{rafieian2023ai,
  title={AI and personalization},
  author={Rafieian, Omid and Yoganarasimhan, Hema},
  journal={Artificial Intelligence in Marketing},
  pages={77--102},
  year={2023},
  publisher={Emerald Publishing Limited}
}

@article{zhang2023siren,
  title={Siren's song in the AI ocean: a survey on hallucination in large language models},
  author={Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
  journal={arXiv preprint arXiv:2309.01219},
  year={2023}
}

@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={arXiv preprint arXiv:2311.05232},
  year={2023}
}

@article{salvagno2023artificial,
  title={Artificial intelligence hallucinations},
  author={Salvagno, Michele and Taccone, Fabio Silvio and Gerli, Alberto Giovanni},
  journal={Critical Care},
  volume={27},
  number={1},
  pages={180},
  year={2023},
  publisher={Springer}
}

@inproceedings{brocki2019concept,
  title={Concept saliency maps to visualize relevant features in deep generative models},
  author={Brocki, Lennart and Chung, Neo Christopher},
  booktitle={2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)},
  pages={1771--1778},
  year={2019},
  organization={IEEE}
}

@article{orgad2024llms,
  title={Llms know more than they show: On the intrinsic representation of llm hallucinations},
  author={Orgad, Hadas and Toker, Michael and Gekhman, Zorik and Reichart, Roi and Szpektor, Idan and Kotek, Hadas and Belinkov, Yonatan},
  journal={arXiv preprint arXiv:2410.02707},
  year={2024}
}

@article{marks24,
  title={The geometry of truth: Emergent linear structure in large language model representations of true/false datasets},
  author={Marks, Samuel and Tegmark, Max},
  journal={arXiv preprint arXiv:2310.06824},
  year={2023}
}

@inproceedings{kim24,
  title={EQ-CBM: A Probabilistic Concept Bottleneck with Energy-based Models and Quantized Vectors},
  author={Kim, Sangwon and Ahn, Dasom and Ko, Byoung Chul and Jang, In-su and Kim, Kwang-Ju},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  pages={3432--3448},
  year={2024}
}

@article{nicolson24,
  title={TextCAVs: Debugging vision models using text},
  author={Nicolson, Angus and Gal, Yarin and Noble, J Alison},
  journal={arXiv preprint arXiv:2408.08652},
  year={2024}
}

@article{xu24,
  title={Uncovering Safety Risks in Open-source LLMs through Concept Activation Vector},
  author={Xu, Zhihao and Huang, Ruixuan and Wang, Xiting and Wu, Fangzhao and Yao, Jing and Xie, Xing},
  journal={arXiv preprint arXiv:2404.12038},
  year={2024}
}

@article{nicolson24explain,
  title={Explaining Explainability: Understanding Concept Activation Vectors},
  author={Nicolson, Angus and Schut, Lisa and Noble, J Alison and Gal, Yarin},
  journal={arXiv preprint arXiv:2404.03713},
  year={2024}
}



@article{tennenholtz24,
  title={Demystifying embedding spaces using large language models},
  author={Tennenholtz, Guy and Chow, Yinlam and Hsu, Chih-Wei and Jeong, Jihwan and Shani, Lior and Tulepbergenov, Azamat and Ramachandran, Deepak and Mladenov, Martin and Boutilier, Craig},
  journal={arXiv preprint arXiv:2310.04475},
  year={2023}
}

@article{postmus24,
  title={Steering Large Language Models using Conceptors: Improving Addition-Based Activation Engineering},
  author={Postmus, Joris and Abreu, Steven},
  journal={arXiv preprint arXiv:2410.16314},
  year={2024}
}

@article{scalena24,
  title={Multi-property steering of large language models with dynamic activation composition},
  author={Scalena, Daniel and Sarti, Gabriele and Nissim, Malvina},
  journal={arXiv preprint arXiv:2406.17563},
  year={2024}
}



@article{ferrando24halluc,
  title={Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models},
  author={Ferrando, Javier and Obeso, Oscar and Rajamanoharan, Senthooran and Nanda, Neel},
  journal={arXiv preprint arXiv:2411.14257},
  year={2024}
}

@article{kolbeinsson24,
  title={Composable interventions for language models},
  author={Kolbeinsson, Arinbjorn and O'Brien, Kyle and Huang, Tianjin and Gao, Shanghua and Liu, Shiwei and Schwarz, Jonathan Richard and Vaidya, Anurag and Mahmood, Faisal and Zitnik, Marinka and Chen, Tianlong and others},
  journal={arXiv preprint arXiv:2407.06483},
  year={2024}
}

@article{jorgensen24mean,
  title={Improving activation steering in language models with mean-centring},
  author={Jorgensen, Ole and Cope, Dylan and Schoots, Nandi and Shanahan, Murray},
  journal={arXiv preprint arXiv:2312.03813},
  year={2023}
}

@article{zhang24reef,
  title={Reef: Representation encoding fingerprints for large language models},
  author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2410.14273},
  year={2024}
}

@article{ferrando24,
  title={A primer on the inner workings of transformer-based language models},
  author={Ferrando, Javier and Sarti, Gabriele and Bisazza, Arianna and Costa-juss{\`a}, Marta R},
  journal={arXiv preprint arXiv:2405.00208},
  year={2024}
}

@article{xiao24config,
  title={Configurable foundation models: Building llms from a modular perspective},
  author={Xiao, Chaojun and Zhang, Zhengyan and Song, Chenyang and Jiang, Dazhi and Yao, Feng and Han, Xu and Wang, Xiaozhi and Wang, Shuo and Huang, Yufei and Lin, Guanyu and others},
  journal={arXiv preprint arXiv:2409.02877},
  year={2024}
}


@article{im2025unified,
  title={A Unified Understanding and Evaluation of Steering Methods},
  author={Im, Shawn and Li, Yixuan},
  journal={arXiv preprint arXiv:2502.02716},
  year={2025}
}

@article{liu24cognitive,
  title={Cognitive Dissonance: Why Do Language Model Outputs Disagree with Internal Representations of Truthfulness?},
  author={Liu, Kevin and Casper, Stephen and Hadfield-Menell, Dylan and Andreas, Jacob},
  journal={arXiv preprint arXiv:2312.03729},
  year={2023}
}

@article{choi24,
  title={Safety-aware fine-tuning of large language models},
  author={Choi, Hyeong Kyu and Du, Xuefeng and Li, Yixuan},
  journal={arXiv preprint arXiv:2410.10014},
  year={2024}
}

@article{kong24,
  title={Aligning Large Language Models with Representation Editing: A Control Perspective},
  author={Kong, Lingkai and Wang, Haorui and Mu, Wenhao and Du, Yuanqi and Zhuang, Yuchen and Zhou, Yifei and Song, Yue and Zhang, Rongzhi and Wang, Kai and Zhang, Chao},
  journal={arXiv preprint arXiv:2406.05954},
  year={2024}
}

@article{li24ranker,
  title={Quantifying multilingual performance of large language models across languages},
  author={Li, Zihao and Shi, Yucheng and Liu, Zirui and Yang, Fan and Payani, Ali and Liu, Ninghao and Du, Mengnan},
  journal={arXiv preprint arXiv:2404.11553},
  year={2024}
}

@article{marks24sparse,
  title={Sparse feature circuits: Discovering and editing interpretable causal graphs in language models},
  author={Marks, Samuel and Rager, Can and Michaud, Eric J and Belinkov, Yonatan and Bau, David and Mueller, Aaron},
  journal={arXiv preprint arXiv:2403.19647},
  year={2024}
}

@article{wu24,
  title={Reft: Representation finetuning for language models},
  author={Wu, Zhengxuan and Arora, Aryaman and Wang, Zheng and Geiger, Atticus and Jurafsky, Dan and Manning, Christopher D and Potts, Christopher},
  journal={arXiv preprint arXiv:2404.03592},
  year={2024}
}

@inproceedings{brocki19,
  title={Concept saliency maps to visualize relevant features in deep generative models},
  author={Brocki, Lennart and Chung, Neo Christopher},
  booktitle={2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)},
  pages={1771--1778},
  year={2019},
  organization={IEEE}
}

@article{nielsen22,
  title={Robust explainability: A tutorial on gradient-based attribution methods for deep neural networks},
  author={Nielsen, Ian E and Dera, Dimah and Rasool, Ghulam and Ramachandran, Ravi P and Bouaynaya, Nidhal Carla},
  journal={IEEE Signal Processing Magazine},
  volume={39},
  number={4},
  pages={73--84},
  year={2022},
  publisher={IEEE}
}

@article{bengio13,
  title={Representation learning: A review and new perspectives},
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={8},
  pages={1798--1828},
  year={2013},
  publisher={IEEE}
}

@article{wang2024probing,
  title={Probing the Emergence of Cross-lingual Alignment during LLM Training},
  author={Wang, Hetong and Minervini, Pasquale and Ponti, Edoardo M},
  journal={arXiv preprint arXiv:2406.13229},
  year={2024}
}

@article{dong23,
  title={Probing explicit and implicit gender bias through llm conditional text generation},
  author={Dong, Xiangjue and Wang, Yibo and Yu, Philip S and Caverlee, James},
  journal={arXiv preprint arXiv:2311.00306},
  year={2023}
}

@inproceedings{youssef24,
  title={Llms for generating and evaluating counterfactuals: A comprehensive study},
  author={Youssef, Paul and Seifert, Christin and Schl{\"o}tterer, J{\"o}rg and others},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={14809--14824},
  year={2024}
}

@article{cheng24,
  title={Interactive Analysis of LLMs using Meaningful Counterfactuals},
  author={Cheng, Furui and Zouhar, Vil{\'e}m and Chan, Robin Shing Moon and F{\"u}rst, Daniel and Strobelt, Hendrik and El-Assady, Mennatallah},
  journal={arXiv preprint arXiv:2405.00708},
  year={2024}
}

@article{ancona19,
  title={Gradient-based attribution methods},
  author={Ancona, Marco and Ceolini, Enea and {\"O}ztireli, Cengiz and Gross, Markus},
  journal={Explainable AI: Interpreting, explaining and visualizing deep learning},
  pages={169--191},
  year={2019},
  publisher={Springer}
}

@article{schroder23,
  title={What about the Latent Space? The Need for Latent Feature Saliency Detection in Deep Time Series Classification},
  author={Schr{\"o}der, Maresa and Zamanian, Alireza and Ahmidi, Narges},
  journal={Machine Learning and Knowledge Extraction},
  volume={5},
  number={2},
  pages={539--559},
  year={2023},
  publisher={MDPI}
}
@article{zhao24exppersp,
  title={Opening the black box of large language models: Two views on holistic interpretability},
  author={Zhao, Haiyan and Yang, Fan and Lakkaraju, Himabindu and Du, Mengnan},
  journal={arXiv e-prints},
  pages={arXiv--2402},
  year={2024}
}

@inproceedings{boldsen2022interpreting,
  title={Interpreting character embeddings with perceptual representations: The case of shape, sound, and color},
  author={Boldsen, Sidsel and Agirrezabal, Manex and Hollenstein, Nora},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={6819--6836},
  year={2022}
}

@article{yetman2025representation,
  title={Representation in large language models},
  author={Yetman, Cameron C},
  journal={arXiv preprint arXiv:2501.00885},
  year={2025}
}
@article{slobodkin2023curious,
  title={The curious case of hallucinatory unanswerablity: Finding truths in the hidden states of over-confident large language models},
  author={Slobodkin, Aviv and Goldman, Omer and Caciularu, Avi and Dagan, Ido and Ravfogel, Shauli},
  journal={arXiv preprint arXiv:2310.11877},
  year={2023}
}

@article{harding2023operationalising,
  title={Operationalising representation in natural language processing},
  author={Harding, Jacqueline},
  year={2023}
}

@article{rai24,
  title={A practical review of mechanistic interpretability for transformer-based language models},
  author={Rai, Daking and Zhou, Yilun and Feng, Shi and Saparov, Abulhair and Yao, Ziyu},
  journal={arXiv preprint arXiv:2407.02646},
  year={2024}
}

@article{goldstein2024does,
  title={Does ChatGPT Have a Mind?},
  author={Goldstein, Simon and Levinstein, Benjamin A},
  journal={arXiv preprint arXiv:2407.11015},
  year={2024}
}

@article{chalmers2025propositional,
  title={Propositional interpretability in artificial intelligence},
  author={Chalmers, David J},
  journal={arXiv preprint arXiv:2501.15740},
  year={2025}
}

@article{levinstein2024still,
  title={Still no lie detector for language models: Probing empirical and conceptual roadblocks},
  author={Levinstein, Benjamin A and Herrmann, Daniel A},
  journal={Philosophical Studies},
  pages={1--27},
  year={2024},
  publisher={Springer}
}

@article{tang2023llamas,
  title={What do llamas really think? revealing preference biases in language model representations},
  author={Tang, Raphael and Zhang, Xinyu and Lin, Jimmy and Ture, Ferhan},
  journal={arXiv preprint arXiv:2311.18812},
  year={2023}
}

@article{he2024jailbreaklens,
  title={JailbreakLens: Interpreting Jailbreak Mechanism in the Lens of Representation and Circuit},
  author={He, Zeqing and Wang, Zhibo and Chu, Zhixuan and Xu, Huiyu and Zheng, Rui and Ren, Kui and Chen, Chun},
  journal={arXiv preprint arXiv:2411.11114},
  year={2024}
}

@article{zhao24survey,
author = {Zhao, Haiyan and Chen, Hanjie and Yang, Fan and Liu, Ninghao and Deng, Huiqi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Du, Mengnan},
title = {Explainability for Large Language Models: A Survey},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3639372},
doi = {10.1145/3639372},
abstract = {Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this article, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional deep learning models.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb,
articleno = {20},
numpages = {38},
keywords = {Explainability, interpretability, large language models}
}

@article{murty20,
  title={Expbert: Representation engineering with natural language explanations},
  author={Murty, Shikhar and Koh, Pang Wei and Liang, Percy},
  journal={arXiv preprint arXiv:2005.01932},
  year={2020}
}

@article{lee24,
  title={Programming refusal with conditional activation steering},
  author={Lee, Bruce W and Padhi, Inkit and Ramamurthy, Karthikeyan Natesan and Miehling, Erik and Dognin, Pierre and Nagireddy, Manish and Dhurandhar, Amit},
  journal={arXiv preprint arXiv:2409.05907},
  year={2024}
}


@inproceedings{rosatirepresentation,
  title={Representation Noising: A Defence Mechanism Against Harmful Finetuning},
  author={Rosati, Domenic and Wehner, Jan and Williams, Kai and Bartoszcze, Lukasz and Gonzales, Robie and Majumdar, Subhabrata and Sajjad, Hassan and Rudzicz, Frank and others},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems}
}

@article{elhage2022toy,
  title={Toy models of superposition},
  author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and others},
  journal={arXiv preprint arXiv:2209.10652},
  year={2022}
}

@inproceedings{bau2020rewriting,
  title={Rewriting a deep generative model},
  author={Bau, David and Liu, Steven and Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part I 16},
  pages={351--369},
  year={2020},
  organization={Springer}
}
@article{levinstein2024still,
  title={Still no lie detector for language models: Probing empirical and conceptual roadblocks},
  author={Levinstein, Benjamin A and Herrmann, Daniel A},
  journal={Philosophical Studies},
  pages={1--27},
  year={2024},
  publisher={Springer}
}

@inproceedings{kotek2023gender,
  title={Gender bias and stereotypes in large language models},
  author={Kotek, Hadas and Dockum, Rikker and Sun, David},
  booktitle={Proceedings of the ACM collective intelligence conference},
  pages={12--24},
  year={2023}
}

@article{azaria2023internal,
  title={The internal state of an LLM knows when it's lying},
  author={Azaria, Amos and Mitchell, Tom},
  journal={arXiv preprint arXiv:2304.13734},
  year={2023}
}

@article{yin2024characterizing,
  title={Characterizing truthfulness in large language model generations with local intrinsic dimension},
  author={Yin, Fan and Srinivasa, Jayanth and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2402.18048},
  year={2024}
}


@inproceedings{hardy2023large,
  title={Large language models meet cognitive science: LLMs as tools, models, and participants},
  author={Hardy, Mathew and Sucholutsky, Ilia and Thompson, Bill and Griffiths, Tom},
  booktitle={Proceedings of the annual meeting of the cognitive science society},
  volume={45},
  number={45},
  year={2023}
}
@article{zhang2024truthx,
  title={Truthx: Alleviating hallucinations by editing large language models in truthful space},
  author={Zhang, Shaolei and Yu, Tian and Feng, Yang},
  journal={arXiv preprint arXiv:2402.17811},
  year={2024}
}

@article{viswanathan2025geometry,
  title={The Geometry of Tokens in Internal Representations of Large Language Models},
  author={Viswanathan, Karthik and Gardinazzi, Yuri and Panerai, Giada and Cazzaniga, Alberto and Biagetti, Matteo},
  journal={arXiv preprint arXiv:2501.10573},
  year={2025}
}

@article{zarlenga2022concept,
  title={Concept embedding models: Beyond the accuracy-explainability trade-off},
  author={Zarlenga, Mateo Espinosa and Barbiero, Pietro and Ciravegna, Gabriele and Marra, Giuseppe and Giannini, Francesco and Diligenti, Michelangelo and Shams, Zohreh and Precioso, Frederic and Melacci, Stefano and Weller, Adrian and others},
  journal={arXiv preprint arXiv:2209.09056},
  year={2022}
}

@article{mahinpei2021promises,
  title={Promises and pitfalls of black-box concept learning models},
  author={Mahinpei, Anita and Clark, Justin and Lage, Isaac and Doshi-Velez, Finale and Pan, Weiwei},
  journal={arXiv preprint arXiv:2106.13314},
  year={2021}
}

@inproceedings{koh2020concept,
  title={Concept bottleneck models},
  author={Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle={International conference on machine learning},
  pages={5338--5348},
  year={2020},
  organization={PMLR}
}

@article{liu2024active,
  title={Active Use of Latent Constituency Representation in both Humans and Large Language Models},
  author={Liu, Wei and Xiang, Ming and Ding, Nai},
  journal={arXiv preprint arXiv:2405.18241},
  year={2024}
}

@article{zhu2024language,
  title={Language Models Represent Beliefs of Self and Others},
  author={Zhu, Wentao and Zhang, Zhining and Wang, Yizhou},
  journal={arXiv preprint arXiv:2402.18496},
  year={2024}
}

@article{yousefi2023context,
  title={In-Context learning in large language models: A neuroscience-inspired analysis of representations},
  author={Yousefi, Safoora and Hasanbeig, Hosein and Betthauser, Leo Moreno and Saran, Akanksha and Milli{\`e}re, Rapha{\"e}l and Momennejad, Ida},
  year={2023}
}

@inproceedings{ismail2023concept,
  title={Concept bottleneck generative models},
  author={Ismail, Aya Abdelsalam and Adebayo, Julius and Bravo, Hector Corrada and Ra, Stephen and Cho, Kyunghyun},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{vargas2023foundation,
  title={Foundation Model's Embedded Representations May Detect Distribution Shift},
  author={Vargas, Max and Tsou, Adam and Engel, Andrew and Chiang, Tony},
  journal={arXiv preprint arXiv:2310.13836},
  year={2023}
}

@article{ferry2023emergence,
  title={Emergence and Function of Abstract Representations in Self-Supervised Transformers},
  author={Ferry, Quentin RV and Ching, Joshua and Kawai, Takashi},
  journal={arXiv preprint arXiv:2312.05361},
  year={2023}
}

@article{ngo2024language,
  title={What Do Language Models Hear? Probing for Auditory Representations in Language Models},
  author={Ngo, Jerry and Kim, Yoon},
  journal={arXiv preprint arXiv:2402.16998},
  year={2024}
}

@article{canby2024measuring,
  title={Measuring the reliability of causal probing methods: Tradeoffs, limitations, and the plight of nullifying interventions},
  author={Canby, Marc and Davies, Adam and Rastogi, Chirag and Hockenmaier, Julia},
  journal={arXiv preprint arXiv:2408.15510},
  year={2024}
}

@article{he2024multilevel,
  title={Multilevel interpretability of artificial neural networks: leveraging framework and methods from neuroscience},
  author={He, Zhonghao and Achterberg, Jascha and Collins, Katie and Nejad, Kevin and Akarca, Danyal and Yang, Yinzhu and Gurnee, Wes and Sucholutsky, Ilia and Tang, Yuhan and Ianov, Rebeca and others},
  journal={arXiv preprint arXiv:2408.12664},
  year={2024}
}

@article{ivanova2021probing,
  title={Probing artificial neural networks: insights from neuroscience},
  author={Ivanova, Anna A and Hewitt, John and Zaslavsky, Noga},
  journal={arXiv preprint arXiv:2104.08197},
  year={2021}
}


@article{blank2023large,
  title={What are large language models supposed to model?},
  author={Blank, Idan A},
  journal={Trends in Cognitive Sciences},
  year={2023},
  publisher={Elsevier}
}

@article{lee2023neural,
  title={From neural activations to concepts: A survey on explaining concepts in neural networks},
  author={Lee, Jae Hee and Lanza, Sergio and Wermter, Stefan},
  journal={arXiv preprint arXiv:2310.11884},
  year={2023}
}

@article{kaushal2022tokens,
  title={What do tokens know about their characters and how do they know it?},
  author={Kaushal, Ayush and Mahowald, Kyle},
  journal={arXiv preprint arXiv:2206.02608},
  year={2022}
}

@article{choudhary2022interpretation,
  title={Interpretation of black box nlp models: A survey},
  author={Choudhary, Shivani and Chatterjee, Niladri and Saha, Subir Kumar},
  journal={arXiv preprint arXiv:2203.17081},
  year={2022}
}

@inproceedings{guo2024steering,
  title={Steering large language models for cross-lingual information retrieval},
  author={Guo, Ping and Ren, Yubing and Hu, Yue and Cao, Yanan and Li, Yunpeng and Huang, Heyan},
  booktitle={Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={585--596},
  year={2024}
}

@article{kumar2022probing,
  title={Probing classifiers are unreliable for concept removal and detection},
  author={Kumar, Abhinav and Tan, Chenhao and Sharma, Amit},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17994--18008},
  year={2022}
}

@article{arps2022probing,
  title={Probing for constituency structure in neural language models},
  author={Arps, David and Samih, Younes and Kallmeyer, Laura and Sajjad, Hassan},
  journal={arXiv preprint arXiv:2204.06201},
  year={2022}
}

@inproceedings{hernandez2022ast,
  title={AST-Probe: Recovering abstract syntax trees from hidden representations of pre-trained language models},
  author={Hern{\'a}ndez L{\'o}pez, Jos{\'e} Antonio and Weyssow, Martin and Cuadrado, Jes{\'u}s S{\'a}nchez and Sahraoui, Houari},
  booktitle={Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
  pages={1--11},
  year={2022}
}

@article{troshin2022probing,
  title={Probing pretrained models of source code},
  author={Troshin, Sergey and Chirkova, Nadezhda},
  journal={arXiv preprint arXiv:2202.08975},
  year={2022}
}

@article{wang2024knowledge,
  title={Knowledge mechanisms in large language models: A survey and perspective},
  author={Wang, Mengru and Yao, Yunzhi and Xu, Ziwen and Qiao, Shuofei and Deng, Shumin and Wang, Peng and Chen, Xiang and Gu, Jia-Chen and Jiang, Yong and Xie, Pengjun and others},
  journal={arXiv preprint arXiv:2407.15017},
  year={2024}
}

@article{klabunde2023similarity,
  title={Similarity of neural network models: A survey of functional and representational measures},
  author={Klabunde, Max and Schumacher, Tobias and Strohmaier, Markus and Lemmerich, Florian},
  journal={arXiv preprint arXiv:2305.06329},
  year={2023}
}

@article{ghandeharioun2024patchscope,
  title={Patchscope: A unifying framework for inspecting hidden representations of language models},
  author={Ghandeharioun, Asma and Caciularu, Avi and Pearce, Adam and Dixon, Lucas and Geva, Mor},
  journal={arXiv preprint arXiv:2401.06102},
  year={2024}
}

@article{aghazadeh2022metaphors,
  title={Metaphors in pre-trained language models: Probing and generalization across datasets and languages},
  author={Aghazadeh, Ehsan and Fayyaz, Mohsen and Yaghoobzadeh, Yadollah},
  journal={arXiv preprint arXiv:2203.14139},
  year={2022}
}


@article{huang2023rigorously,
  title={Rigorously assessing natural language explanations of neurons},
  author={Huang, Jing and Geiger, Atticus and D'Oosterlinck, Karel and Wu, Zhengxuan and Potts, Christopher},
  journal={arXiv preprint arXiv:2309.10312},
  year={2023}
}

@article{gurnee2023finding,
  title={Finding neurons in a haystack: Case studies with sparse probing},
  author={Gurnee, Wes and Nanda, Neel and Pauly, Matthew and Harvey, Katherine and Troitskii, Dmitrii and Bertsimas, Dimitris},
  journal={arXiv preprint arXiv:2305.01610},
  year={2023}
}

@inproceedings{rauker2023toward,
  title={Toward transparent ai: A survey on interpreting the inner structures of deep neural networks},
  author={R{\"a}uker, Tilman and Ho, Anson and Casper, Stephen and Hadfield-Menell, Dylan},
  booktitle={2023 ieee conference on secure and trustworthy machine learning (satml)},
  pages={464--483},
  year={2023},
  organization={IEEE}
}

@article{mahowald2024dissociating,
  title={Dissociating language and thought in large language models},
  author={Mahowald, Kyle and Ivanova, Anna A and Blank, Idan A and Kanwisher, Nancy and Tenenbaum, Joshua B and Fedorenko, Evelina},
  journal={Trends in Cognitive Sciences},
  year={2024},
  publisher={Elsevier}
}

@article{belrose2023eliciting,
  title={Eliciting latent predictions from transformers with the tuned lens},
  author={Belrose, Nora and Furman, Zach and Smith, Logan and Halawi, Danny and Ostrovsky, Igor and McKinney, Lev and Biderman, Stella and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2303.08112},
  year={2023}
}

@article{belinkov2022probing,
  title={Probing classifiers: Promises, shortcomings, and advances},
  author={Belinkov, Yonatan},
  journal={Computational Linguistics},
  volume={48},
  number={1},
  pages={207--219},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{slobodkin2023curious,
  title={The curious case of hallucinatory unanswerablity: Finding truths in the hidden states of over-confident large language models},
  author={Slobodkin, Aviv and Goldman, Omer and Caciularu, Avi and Dagan, Ido and Ravfogel, Shauli},
  journal={arXiv preprint arXiv:2310.11877},
  year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Grokking via Mechanistic Interpretability},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{hernandez24,
  title={Inspecting and editing knowledge representations in language models},
  author={Hernandez, Evan and Li, Belinda Z and Andreas, Jacob},
  journal={arXiv preprint arXiv:2304.00740},
  year={2023}
}

@article{elazar21,
  title={Amnesic probing: Behavioral explanation with amnesic counterfactuals},
  author={Elazar, Yanai and Ravfogel, Shauli and Jacovi, Alon and Goldberg, Yoav},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={160--175},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{cunningham2023sparse,
  title={Sparse autoencoders find highly interpretable features in language models},
  author={Cunningham, Hoagy and Ewart, Aidan and Riggs, Logan and Huben, Robert and Sharkey, Lee},
  journal={arXiv preprint arXiv:2309.08600},
  year={2023}
}

@article{brinkmann2024mechanistic,
  title={A mechanistic analysis of a transformer trained on a symbolic multi-step reasoning task},
  author={Brinkmann, Jannik and Sheshadri, Abhay and Levoso, Victor and Swoboda, Paul and Bartelt, Christian},
  journal={arXiv preprint arXiv:2402.11917},
  year={2024}
}

@article{syed2023attribution,
  title={Attribution patching outperforms automated circuit discovery},
  author={Syed, Aaquib and Rager, Can and Conmy, Arthur},
  journal={arXiv preprint arXiv:2310.10348},
  year={2023}
}

@article{rai2024practical,
  title={A practical review of mechanistic interpretability for transformer-based language models},
  author={Rai, Daking and Zhou, Yilun and Feng, Shi and Saparov, Abulhair and Yao, Ziyu},
  journal={arXiv preprint arXiv:2407.02646},
  year={2024}
}

@article{conmy2023towards,
  title={Towards automated circuit discovery for mechanistic interpretability},
  author={Conmy, Arthur and Mavor-Parker, Augustine and Lynch, Aengus and Heimersheim, Stefan and Garriga-Alonso, Adri{\`a}},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={16318--16352},
  year={2023}
}

@article{heimersheim24,
  title={How to use and interpret activation patching},
  author={Heimersheim, Stefan and Nanda, Neel},
  journal={arXiv preprint arXiv:2404.15255},
  year={2024}
}

@article{yeo2024towards,
  title={Towards Faithful Natural Language Explanations: A Study Using Activation Patching in Large Language Models},
  author={Yeo, Wei Jie and Satapathy, Ranjan and Cambria, Erik},
  journal={arXiv preprint arXiv:2410.14155},
  year={2024}
}

@article{alain16,
  title={Understanding intermediate layers using linear classifier probes},
  author={Alain, Guillaume},
  journal={arXiv preprint arXiv:1610.01644},
  year={2016}
}

@article{li24momentum,
  title={In-Context Learning State Vector with Inner and Momentum Optimization},
  author={Li, Dongfang and Liu, Zhenyu and Hu, Xinshuo and Sun, Zetian and Hu, Baotian and Zhang, Min},
  journal={arXiv preprint arXiv:2404.11225},
  year={2024}
}

@article{tlaie24,
  title={Exploring and steering the moral compass of Large Language Models},
  author={Tlaie, Alejandro},
  journal={arXiv preprint arXiv:2405.17345},
  year={2024}
}

@article{cao24steering,
  title={Personalized Steering of Large Language Models: Versatile Steering Vectors Through Bi-directional Preference Optimization},
  author={Cao, Yuanpu and Zhang, Tianrong and Cao, Bochuan and Yin, Ziyi and Lin, Lu and Ma, Fenglong and Chen, Jinghui},
  journal={arXiv preprint arXiv:2406.00045},
  year={2024}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn and others},
    journal={arXiv preprint arXiv:2202.05262},
    year={2022}
}

@article{schubert2023transformer,
    title={Transformer Circuits Thread},
    author={Schubert, Ludwig and Olsson, Catherine and Ridge, Stella and Hilton, Jacob and Elhage, Nelson and Nanda, Neel},
    journal={Anthropic Blog},
    year={2023},
    url={https://transformer-circuits.pub}
}

@article{cammarata2020thread,
    title={Thread: Circuits},
    author={Cammarata, Nick and Olah, Chris and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
    journal={Distill},
    year={2020},
    doi={10.23915/distill.00024}
}

@article{olah2020zoom,
    title={Zoom In: An Introduction to Circuits},
    author={Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan},
    journal={Distill},
    volume={5},
    number={3},
    pages={e00024-001},
    year={2020}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{anthropic2022mechanistic,
    title={Mechanistic Interpretability: A Technical Introduction},
    author={Anthropic and Burns, Chris and Chen, Daniel and Damour, Sydney and Levine, Avital and Schubert, Kyle},
    journal={Anthropic Blog},
    year={2022}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}


@article{dai2023language,
    title={Language Model Behavior: A Comprehensive Survey},
    author={Dai, Shuyang and Li, Zheng and Geng, Zhitao and Ding, Ning and Zhou, Wangchunshu and Qiu, Xipeng and Tang, Jie},
    journal={arXiv preprint arXiv:2303.11504},
    year={2023}
}

@article{zhang2023survey,
    title={A Survey on Language Model Safety: Risks, Solutions, and Future Directions},
    author={Zhang, Zheng and Zhang, Hongchao and Zhao, Tianqing and Yang, Yue and Zhang, Dongxiang and Wang, Wei},
    journal={arXiv preprint arXiv:2304.10436},
    year={2023}
}

@article{kim2023causal,
    title={Causal Abstraction for Language Models},
    author={Kim, Hyunwoo and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.05697},
    year={2023}
}

@article{wang2023large,
    title={Large Language Models are Better Reasoners with Self-Verification},
    author={Wang, Yixuan and Sun, Jing and Zhang, Junjie and Xu, Hongyu},
    journal={arXiv preprint arXiv:2212.09561},
    year={2023}
}

@article{chen2023interpretable,
    title={Interpretable Neural Programming with Transformers},
    author={Chen, Xinyun and Zhou, Denny and Wang, Qian and Durrett, Greg},
    journal={Transactions on Machine Learning Research},
    year={2023}
}

@article{wu2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Wu, Jeff and Steinhardt, Jacob and Ermon, Stefano},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023core,
    title={Core Mechanisms of Cognition in Large Language Models},
    author={Anthropic and Joseph, Nicholas and Chan, Ho-Chung and Askell, Amanda and Nanda, Neel and Ndousse, Kamal and Olsson, Catherine and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11257},
    year={2023}
}

@article{chan2023mechanistic,
    title={Mechanistic Interpretability of Computation in Language Models},
    author={Chan, Ho-Chung and Nanda, Neel and Ndousse, Kamal and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.05174},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{filos2023compositional,
    title={Compositional Explanations for Large Language Models},
    author={Filos, Angelos and Zelikman, Eric and Poesia, Gabriel and Mu, Jesse and Goodman, Noah D.},
    journal={arXiv preprint arXiv:2306.05839},
    year={2023}
}

@article{elhage2023tracr,
    title={{TRACR}: Compiled Transformers as a Laboratory for Interpretability},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Interpretability Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn In-Context by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity: Understanding and Constraining Changes in Neural Network Representations},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Grokking via Mechanistic Interpretability},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Large Language Models: A Survey},
    author={Wang, Linda and Zou, Andy and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Systematic Review of Real-World Applications of Interpretable Machine Learning},
    author={Olsson, Catherine and Nanda, Neel and Elhage, Nelson and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2303.07359},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{brumley24,
  title={Comparing Bottom-Up and Top-Down Steering Approaches on In-Context Learning Tasks},
  author={Brumley, Madeline and Kwon, Joe and Krueger, David and Krasheninnikov, Dmitrii and Anwar, Usman},
  journal={arXiv preprint arXiv:2411.07213},
  year={2024}
}

@article{wang2023editing,
    title={Editing Large Language Models: Problems, Methods, and Opportunities},
    author={Wang, Yunzhi and Cai, Xiaoxue and Lin, Aishan and Liu, Qing and Ma, Tao and Yu, Dian and Wang, Hao},
    journal={arXiv preprint arXiv:2305.13172},
    year={2023}
}

@inproceedings{bender21,
  title={On the dangers of stochastic parrots: Can language models be too big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={610--623},
  year={2021}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{dai2023knowledge,
    title={Knowledge Neurons in Pretrained Transformers: An Empirical Study},
    author={Dai, Damai and Li, Yizhu and Sun, Weizhe and Dong, Li and Wei, Furu},
    journal={arXiv preprint arXiv:2104.08696},
    year={2023}
}

@article{geva2023tracr,
    title={{TRACR}: Transformer Reasoning Circuits},
    author={Geva, Mor and Schuster, Tal and Manning, Christopher D. and Berant, Jonathan},
    journal={Transactions on Machine Learning Research},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}


@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{vaswani2017attention,
    title={Attention is All You Need},
    author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
    journal={Advances in Neural Information Processing Systems},
    volume={30},
    pages={5998--6008},
    year={2017}
}

@article{devlin2019bert,
    title={{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
    journal={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics},
    pages={4171--4186},
    year={2019}
}

@article{brown2020language,
    title={Language Models are Few-Shot Learners},
    author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
    journal={Advances in Neural Information Processing Systems},
    volume={33},
    pages={1877--1901},
    year={2020}
}

@article{raffel2020exploring,
    title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
    author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
    journal={Journal of Machine Learning Research},
    volume={21},
    pages={1--67},
    year={2020}
}

@article{liu2019roberta,
    title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
    author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
    journal={arXiv preprint arXiv:1907.11692},
    year={2019}
}

@article{radford2019language,
    title={Language Models are Unsupervised Multitask Learners},
    author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
    journal={OpenAI Blog},
    volume={1},
    number={8},
    pages={9},
    year={2019}
}

@article{radfordclip,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      journal={arXiv preprint arXiv:22103.00020}
}

@article{clark2020electra,
    title={{ELECTRA}: Pre-training Text Encoders as Discriminators Rather Than Generators},
    author={Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D},
    journal={International Conference on Learning Representations},
    year={2020}
}

@article{lewis2020bart,
    title={{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
    author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke},
    journal={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
    pages={7871--7880},
    year={2020}
}

@article{yang2019xlnet,
    title={{XLNet}: Generalized Autoregressive Pretraining for Language Understanding},
    author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ and Le, Quoc V},
    journal={Advances in Neural Information Processing Systems},
    volume={32},
    year={2019}
}

@article{lan2020albert,
    title={{ALBERT}: A Lite BERT for Self-supervised Learning of Language Representations},
    author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
    journal={International Conference on Learning Representations},
    year={2020}
}

@article{dong2019unified,
    title={Unified Language Model Pre-training for Natural Language Understanding and Generation},
    author={Dong, Li and Yang, Nan and Wang, Wenhui and Wei, Furu and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Zhou, Ming and Hon, Hsiao-Wuen},
    journal={Advances in Neural Information Processing Systems},
    volume={32},
    year={2019}
}

@article{peters2018deep,
    title={Deep Contextualized Word Representations},
    author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
    journal={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics},
    pages={2227--2237},
    year={2018}
}

@article{he2020deberta,
    title={{DeBERTa}: Decoding-enhanced BERT with Disentangled Attention},
    author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
    journal={International Conference on Learning Representations},
    year={2020}
}

@article{conneau2020unsupervised,
    title={Unsupervised Cross-lingual Representation Learning at Scale},
    author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzmán, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
    journal={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
    pages={8440--8451},
    year={2020}
}

@article{zhang2020pegasus,
    title={{PEGASUS}: Pre-training with Extracted Gap-sentences for Abstractive Summarization},
    author={Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter},
    journal={International Conference on Machine Learning},
    pages={11328--11339},
    year={2020}
}

@article{sun2019ernie,
    title={{ERNIE}: Enhanced Representation through Knowledge Integration},
    author={Sun, Yu and Wang, Shuohuan and Li, Yukun and Feng, Shikun and Chen, Xuyi and Zhang, Han and Tian, Xin and Zhu, Danxiang and Tian, Hao and Wu, Hua},
    journal={arXiv preprint arXiv:1904.09223},
    year={2019}
}

@article{yang2020xlnet,
    title={{XLNet}: Generalized Autoregressive Pretraining for Language Understanding},
    author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ and Le, Quoc V},
    journal={Advances in Neural Information Processing Systems},
    volume={32},
    pages={5753--5763},
    year={2020}
}

@article{liu2020multilingual,
    title={Multilingual Denoising Pre-training for Neural Machine Translation},
    author={Liu, Yinhan and Gu, Jiatao and Goyal, Naman and Li, Xian and Edunov, Sergey and Ghazvininejad, Marjan and Lewis, Mike and Zettlemoyer, Luke},
    journal={Transactions of the Association for Computational Linguistics},
    volume={8},
    pages={726--742},
    year={2020}
}

@article{keskar2019ctrl,
    title={{CTRL}: A Conditional Transformer Language Model for Controllable Generation},
    author={Keskar, Nitish Shirish and McCann, Bryan and Varshney, Lav R and Xiong, Caiming and Socher, Richard},
    journal={arXiv preprint arXiv:1909.05858},
    year={2019}
}

@article{wang2019structbert,
    title={{StructBERT}: Incorporating Language Structures into Pre-training for Deep Language Understanding},
    author={Wang, Wei and Bi, Bin and Yan, Ming and Wu, Chen and Bao, Zuyi and Peng, Liwei and Wang, Luo},
    journal={International Conference on Learning Representations},
    year={2019}
}

@article{song2019mass,
    title={{MASS}: Masked Sequence to Sequence Pre-training for Language Generation},
    author={Song, Kaitao and Tan, Xu and Qin, Tao and Lu, Jianfeng and Liu, Tie-Yan},
    journal={International Conference on Machine Learning},
    pages={5926--5936},
    year={2019}
}
@misc{orgad2024llmsknowshowintrinsic,
      title={LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations}, 
      author={Hadas Orgad and Michael Toker and Zorik Gekhman and Roi Reichart and Idan Szpektor and Hadas Kotek and Yonatan Belinkov},
      year={2024},
      eprint={2410.02707},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.02707}, 
}
@article{chowdhery2022palm,
    title={{PaLM}: Scaling Language Modeling with Pathways},
    author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and others},
    journal={arXiv preprint arXiv:2204.02311},
    year={2022}
}

@article{hoffmann2022training,
    title={Training Compute-Optimal Large Language Models},
    author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
    journal={arXiv preprint arXiv:2203.15556},
    year={2022}
}

@article{touvron2023llama,
    title={{LLaMA}: Open and Efficient Foundation Language Models},
    author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
    journal={arXiv preprint arXiv:2302.13971},
    year={2023}
}

@article{zhang2022opt,
    title={{OPT}: Open Pre-trained Transformer Language Models},
    author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
    journal={arXiv preprint arXiv:2205.01068},
    year={2022}
}

@article{rae2021scaling,
    title={Scaling Language Models: Methods, Analysis \& Insights from Training Gopher},
    author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
    journal={arXiv preprint arXiv:2112.11446},
    year={2021}
}

@article{thoppilan2022lamda,
    title={{LaMDA}: Language Models for Dialog Applications},
    author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
    journal={arXiv preprint arXiv:2201.08239},
    year={2022}
}

@article{smith2022using,
    title={Using DeepSpeed and Megatron to Train Megatron-Turing {NLG} 530B, A Large-Scale Generative Language Model},
    author={Smith, Shaden and Patwary, Mostofa and Norick, Brandon and LeGresley, Patrick and Rajbhandari, Samyam and Casper, Jared and Liu, Zhun and Prabhumoye, Shrimai and Zerveas, George and Sundaram, Vijay and others},
    journal={arXiv preprint arXiv:2201.11990},
    year={2022}
}

@article{wei2022emergent,
    title={Emergent Abilities of Large Language Models},
    author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{bommasani2021opportunities,
    title={On the Opportunities and Risks of Foundation Models},
    author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
    journal={arXiv preprint arXiv:2108.07258},
    year={2021}
}

@article{fedus2021switch,
    title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
    author={Fedus, William and Zoph, Barret and Shazeer, Noam},
    journal={arXiv preprint arXiv:2101.03961},
    year={2021}
}

@article{du2021glam,
    title={{GLaM}: Efficient Scaling of Language Models with Mixture-of-Experts},
    author={Du, Nan and Huang, Yanping and Dai, Andrew M and Tong, Simon and Lepikhin, Dmitry and Xu, Yuanzhong and Krikun, Maxim and Zhou, Yanqi and Yu, Adams Wei and Firat, Orhan and others},
    journal={International Conference on Machine Learning},
    pages={5547--5569},
    year={2021}
}

@article{holmes2022state,
  title={State of the art and practice in AI in education},
  author={Holmes, Wayne and Tuomi, Ilkka},
  journal={European Journal of Education},
  volume={57},
  number={4},
  pages={542--570},
  year={2022},
  publisher={Wiley Online Library}
}

@article{lin2021space,
    title={Space-Efficient Language Models through Dimension Reduction},
    author={Lin, Zhuohan and Liu, Zi and Winata, Genta Indra and Cahyawijaya, Samuel and Madotto, Andrea and Bang, Yichong and Fung, Pascale},
    journal={Findings of the Association for Computational Linguistics: EMNLP 2021},
    pages={3793--3804},
    year={2021}
}

@article{wang2021language,
    title={Language Models are General-Purpose Interfaces},
    author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
    journal={arXiv preprint arXiv:2108.07679},
    year={2021}
}

@article{zhang2023palm,
    title={{PaLM} 2 Technical Report},
    author={Zhang, Rohan and Chen, Daiyi and Du, Jing and Fan, Luyu and Tao, Dacheng and others},
    journal={arXiv preprint arXiv:2305.10403},
    year={2023}
}

@article{black2022gpt,
    title={{GPT-NeoX-20B}: An Open-Source Autoregressive Language Model},
    author={Black, Sid and Gao, Leo and Wang, Phil and Leahy, Connor and Biderman, Stella},
    journal={Proceedings of the ACL Workshop on Challenges \& Perspectives in Creating Large Language Models},
    pages={95--105},
    year={2022}
}

@article{aghajanyan2022cm3,
    title={{CM3}: A Causal Masked Multimodal Model of the Internet},
    author={Aghajanyan, Armen and Huang, Bernie and Ross, Candace and Karpukhin, Vladimir and Xu, Hu and Goyal, Naman and Metcalf, Gargi and Ott, Myle},
    journal={arXiv preprint arXiv:2201.07520},
    year={2022}
}

@article{tay2022scaling,
    title={Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?},
    author={Tay, Yi and Dehghani, Mostafa and Gupta, Samira and Bahri, Dara and Metzler, Donald},
    journal={arXiv preprint arXiv:2207.10551},
    year={2022}
}

@article{anil2022palm,
    title={{PaLM}: Scaling Language Modeling with Pathways},
    author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Peter and Chen, Zhifeng and others},
    journal={arXiv preprint arXiv:2204.02311},
    year={2022}
}

@article{chowdhery2023palm,
    title={{PaLM} 2: Scaling Language Modeling with Pathways},
    author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
    journal={arXiv preprint arXiv:2305.10403},
    year={2023}
}

@article{wei2023chain,
    title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
    author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
    journal={arXiv preprint arXiv:2201.11903},
    year={2023}
}

@article{kojima2022large,
    title={Large Language Models are Zero-Shot Reasoners},
    author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={22199--22213},
    year={2022}
}

@article{zhang2023survey,
    title={A Survey of Large Language Models},
    author={Zhang, Wayne Xin and Jiang, Xiaoming and Wang, Yuwei and Luo, Zhao and Li, Chunpu and Chen, Yuxi and Xu, Zihan and Gao, Xiangru and Wang, Yihan and Zhang, Xiao and others},
    journal={arXiv preprint arXiv:2303.18223},
    year={2023}
}

@article{li2023survey,
    title={A Survey on Evaluation of Large Language Models},
    author={Li, Yupeng and Zhao, Wei and Shen, Cheng and Chen, Jianxin},
    journal={arXiv preprint arXiv:2307.03109},
    year={2023}
}

@article{huang2023large,
    title={Large Language Models Can Be Easily Distracted by Irrelevant Context},
    author={Huang, Freda and Cho, Jungwon and Goldstein, Daniel G and Paik, Pascale},
    journal={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
    pages={11089--11110},
    year={2023}
}

@article{wei2023self,
    title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
    author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
    journal={International Conference on Learning Representations},
    year={2023}
}

@article{zhang2023instruction,
    title={Instruction Tuning with {GPT-4}},
    author={Zhang, Baolin and Xu, Ningyu and Yang, Xiaozhi and Li, Lei and Zhu, Kenny and Wang, Xiang and Huang, Xuanjing and Huang, Minlie},
    journal={arXiv preprint arXiv:2304.03277},
    year={2023}
}

@article{ju2024large,
  title={How large language models encode context knowledge? a layer-wise probing study},
  author={Ju, Tianjie and Sun, Weiwei and Du, Wei and Yuan, Xinwei and Ren, Zhaochun and Liu, Gongshen},
  journal={arXiv preprint arXiv:2402.16061},
  year={2024}
}

@article{skean2024does,
  title={Does representation matter? exploring intermediate layers in large language models},
  author={Skean, Oscar and Arefin, Md Rifat and LeCun, Yann and Shwartz-Ziv, Ravid},
  journal={arXiv preprint arXiv:2412.09563},
  year={2024}
}

@article{raghu2017svcca,
  title={Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability},
  author={Raghu, Maithra and Gilmer, Justin and Yosinski, Jason and Sohl-Dickstein, Jascha},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{sun2023sora,
    title={Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models},
    author={Sun, Yifan and Ding, Xueqi and Wang, Zekun and Ding, Ming and Ren, Jie and Zhou, Hang and Li, Xin and Yang, Changqing and Lu, Huazhu and Xie, Weidi},
    journal={arXiv preprint arXiv:2402.17177},
    year={2024}
}

@article{li2024inference,
  title={Inference-time intervention: Eliciting truthful answers from a language model},
  author={Li, Kenneth and Patel, Oam and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{li2024survey,
    title={A Survey on Multimodal Large Language Models},
    author={Li, Sheng and Zhao, Xing and Ding, Yifan and Zhao, Lin},
    journal={arXiv preprint arXiv:2306.13549},
    year={2024}
}

@article{yang2024survey,
    title={A Survey on Large Language Model based Autonomous Agents},
    author={Yang, Zhiheng and Li, Chao and Fan, Hongxi and Wang, Zongjie and Zhu, Yuliang and Wang, Zihao and Li, Jianquan and Chi, Mingming and Zhao, Zhou},
    journal={arXiv preprint arXiv:2308.11432},
    year={2024}
}

@article{qin2023survey,
    title={A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
    author={Qin, Yue and Hu, Jiaxin and Li, Xuanyu and Lin, Yilun and Ma, Xiaolu and Li, Weizhu and Wen, Yinan and Wang, Hao and Liang, Weizhu and Wang, Xuming and others},
    journal={arXiv preprint arXiv:2311.05232},
    year={2023}
}

@article{wang2023survey,
    title={A Survey on Large Language Model Security: Threats, Defenses and Future Directions},
    author={Wang, Jie and Jin, Mingyu and Deng, Yifan and Zhang, Xingbo and Li, Quanquan and Yan, Ming and Zheng, Wenyuan and Yang, Tianwei},
    journal={arXiv preprint arXiv:2311.13647},
    year={2023}
}

@article{liu2023survey,
    title={A Survey of Large Language Models for Healthcare: From Data, Technology, and Applications to Accountability and Ethics},
    author={Liu, Shaoxiong and He, Xuanang and Guo, Huajie and Lin, Yiqing and Du, Yiquan and Sun, Xian and Li, Yushan and Zhou, Xiang and Gao, Ming and Li, Jing and others},
    journal={arXiv preprint arXiv:2310.05694},
    year={2023}
}

@article{chen2023survey,
    title={A Survey on Large Language Models for Software Engineering},
    author={Chen, Zibin and Zhao, Hao and Lu, Jifeng and Xie, Tianyi and Li, Quanqi and Du, Ju},
    journal={arXiv preprint arXiv:2312.15223},
    year={2023}
}

@article{csahin2024unlocking,
  title={Unlocking the black box: an in-depth review on interpretability, explainability, and reliability in deep learning},
  author={{\c{S}}AHiN, Emrullah and Arslan, Naciye Nur and {\"O}zdemir, Durmu{\c{s}}},
  journal={Neural Computing and Applications},
  pages={1--107},
  year={2024},
  publisher={Springer}
}

@article{gohel2021explainable,
  title={Explainable AI: current status and future directions},
  author={Gohel, Prashant and Singh, Priyanka and Mohanty, Manoranjan},
  journal={arXiv preprint arXiv:2107.07045},
  year={2021}
}


@article{sheu2022survey,
  title={A survey on medical explainable AI (XAI): recent progress, explainability approach, human interaction and scoring system},
  author={Sheu, Ruey-Kai and Pardeshi, Mayuresh Sunil},
  journal={Sensors},
  volume={22},
  number={20},
  pages={8068},
  year={2022},
  publisher={MDPI}
}

@article{ehsan2024explainability,
  title={Explainability pitfalls: Beyond dark patterns in explainable AI},
  author={Ehsan, Upol and Riedl, Mark O},
  journal={Patterns},
  volume={5},
  number={6},
  year={2024},
  publisher={Elsevier}
}

@article{danilevsky2020survey,
  title={A survey of the state of explainable AI for natural language processing},
  author={Danilevsky, Marina and Qian, Kun and Aharonov, Ranit and Katsis, Yannis and Kawas, Ban and Sen, Prithviraj},
  journal={arXiv preprint arXiv:2010.00711},
  year={2020}
}

@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Liu, Tianyu and others},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}


@article{liu2021makes,
  title={What Makes Good In-Context Examples for GPT-$3 $?},
  author={Liu, Jiachang and Shen, Dinghan and Zhang, Yizhe and Dolan, Bill and Carin, Lawrence and Chen, Weizhu},
  journal={arXiv preprint arXiv:2101.06804},
  year={2021}
}@inproceedings{zhao2021calibrate,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={International conference on machine learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}



@inproceedings{li2023transformers,
  title={Transformers as algorithms: Generalization and stability in in-context learning},
  author={Li, Yingcong and Ildiz, Muhammed Emrullah and Papailiopoulos, Dimitris and Oymak, Samet},
  booktitle={International Conference on Machine Learning},
  pages={19565--19594},
  year={2023},
  organization={PMLR}
}

@inproceedings{von2023transformers,
  title={Transformers learn in-context by gradient descent},
  author={Von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Jo{\~a}o and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max},
  booktitle={International Conference on Machine Learning},
  pages={35151--35174},
  year={2023},
  organization={PMLR}
}

@article{dai2022can,
  title={Why can gpt learn in-context? language models implicitly perform gradient descent as meta-optimizers},
  author={Dai, Damai and Sun, Yutao and Dong, Li and Hao, Yaru and Ma, Shuming and Sui, Zhifang and Wei, Furu},
  journal={arXiv preprint arXiv:2212.10559},
  year={2022}
}

@article{yoo2022ground,
  title={Ground-truth labels matter: A deeper look into input-label demonstrations},
  author={Yoo, Kang Min and Kim, Junyeob and Kim, Hyuhng Joon and Cho, Hyunsoo and Jo, Hwiyeol and Lee, Sang-Woo and Lee, Sang-goo and Kim, Taeuk},
  journal={arXiv preprint arXiv:2205.12685},
  year={2022}
}

@article{xie2021explanation,
  title={An explanation of in-context learning as implicit bayesian inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  journal={arXiv preprint arXiv:2111.02080},
  year={2021}
}

@article{wang2023large,
  title={Large language models are implicitly topic models: Explaining and finding good demonstrations for in-context learning},
  author={Wang, Xinyi and Zhu, Wanrong and Wang, William Yang},
  journal={arXiv preprint arXiv:2301.11916},
  pages={3},
  year={2023}
}

@article{bailey2023soft,
  title={Soft prompting might be a bug, not a feature},
  author={Bailey, Luke and Ahdritz, Gustaf and Kleiman, Anat and Swaroop, Siddharth and Doshi-Velez, Finale and Pan, Weiwei},
  year={2023}
}

@article{wu2024infoprompt,
  title={Infoprompt: Information-theoretic soft prompt tuning for natural language understanding},
  author={Wu, Junda and Yu, Tong and Wang, Rui and Song, Zhao and Zhang, Ruiyi and Zhao, Handong and Lu, Chaochao and Li, Shuai and Henao, Ricardo},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{sahoo2024systematic,
  title={A systematic survey of prompt engineering in large language models: Techniques and applications},
  author={Sahoo, Pranab and Singh, Ayush Kumar and Saha, Sriparna and Jain, Vinija and Mondal, Samrat and Chadha, Aman},
  journal={arXiv preprint arXiv:2402.07927},
  year={2024}
}

@article{wies2023learnability,
  title={The learnability of in-context learning},
  author={Wies, Noam and Levine, Yoav and Shashua, Amnon},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={36637--36651},
  year={2023}
}


@article{garg2022can,
  title={What can transformers learn in-context? a case study of simple function classes},
  author={Garg, Shivam and Tsipras, Dimitris and Liang, Percy S and Valiant, Gregory},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30583--30598},
  year={2022}
}

@article{min2022rethinking,
  title={Rethinking the role of demonstrations: What makes in-context learning work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2202.12837},
  year={2022}
}

@article{zhao2023survey,
    title={A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation},
    author={Zhao, Xiaowei and Li, Yikun and Zhang, Jiawen and Wu, Handong and Wang, Yichi and Guo, Sujuan},
    journal={arXiv preprint arXiv:2305.11391},
    year={2023}
}

@article{wei2024survey,
    title={A Survey on In-Context Learning in Natural Language Processing: Challenges, Methods, and Future Directions},
    author={Wei, Yixuan and Zhao, Yimeng and Zhang, Jifan and Wu, Yujiu and Xu, Weizhen and Li, Lei},
    journal={arXiv preprint arXiv:2401.07822},
    year={2024}
}

@article{li2024comprehensive,
    title={A Comprehensive Survey of AI-Generated Content ({AIGC}): A History of Generative AI from {GAN} to {ChatGPT}},
    author={Li, Yifan and Zhang, Jingkang and Zhang, Xiang and Li, Chang and Tong, Yongxin and Xu, Yifang and Liu, Jiawei and Xie, Weidi and Wang, Yongqi and Xie, Yao and others},
    journal={arXiv preprint arXiv:2303.04226},
    year={2024}
}

@article{wang2024survey,
    title={A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly},
    author={Wang, Bang and Xu, Jie and Wang, Yue and Sun, Yiran and Li, Fenghua and Yan, Mingwu and Xue, Minhui},
    journal={arXiv preprint arXiv:2312.02003},
    year={2024}
}

@article{chen2024survey,
    title={A Survey on Knowledge Distillation of Large Language Models},
    author={Chen, Lei and Li, Yong and Xu, Zhilin and Wu, Yonghao and Wang, Jindong and Xie, Xing},
    journal={arXiv preprint arXiv:2402.13116},
    year={2024}
}

@article{zhang2024survey,
    title={A Survey on Evaluation of Large Language Models},
    author={Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Jiang, Lemao and Liu, Yang},
    journal={arXiv preprint arXiv:2402.06797},
    year={2024}
}

@article{liu2024survey,
    title={A Survey on Large Language Model Alignment: Methods and Analysis},
    author={Liu, Zheng and Wang, Kai and Hou, Yiyang and Zhu, Yue and Wang, Shihan and Zhang, Zhiheng and Wang, Yining and Xu, Yixuan and Zhang, Yongfeng and Zhu, Xiaoyan},
    journal={arXiv preprint arXiv:2402.15121},
    year={2024}
}

@article{yang2024comprehensive,
    title={A Comprehensive Survey on Automatic Generation of Benchmark Datasets for Large Language Models},
    author={Yang, Zheng and Zhang, Xiang and Li, Chang and Xu, Yifang and Xie, Weidi and Wang, Yongqi and Xie, Yao and Zhang, Wei},
    journal={arXiv preprint arXiv:2402.11391},
    year={2024}
}

@article{wang2024comprehensive,
    title={A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models},
    author={Wang, Yue and Xu, Jie and Wang, Bang and Sun, Yiran and Li, Fenghua and Yan, Mingwu and Xue, Minhui},
    journal={arXiv preprint arXiv:2401.01313},
    year={2024}
}

@article{li2023survey,
    title={A Survey on Large Language Models: Applications, Challenges, and Solutions},
    author={Li, Yuxiao and Wang, Yafei and Liu, Jing and Wang, Tianyi and Xia, Rui and Chen, Yidong},
    journal={ACM Computing Surveys},
    year={2023}
}

@article{yang2023harnessing,
    title={Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond},
    author={Yang, Jingfeng and Zhang, Hongye and Xu, Mingxuan and Zhao, Xueqing and Qin, Yao and Wang, Yaqing and Wang, Haohan and Ding, Kaiming and others},
    journal={arXiv preprint arXiv:2304.13712},
    year={2023}
}

@article{zhao2023survey,
    title={A Survey of Large Language Models Attribution: Datasets, Methods, and Applications},
    author={Zhao, Zheng and Liu, Jing and Wang, Xinyu and Wang, Chaoyu and Liu, Yuhan and Zhang, Yijun and Wang, Qiushi and others},
    journal={arXiv preprint arXiv:2311.03731},
    year={2023}
}

@article{chen2023foundation,
    title={Foundation Models for Decision Making: Problems, Methods, and Opportunities},
    author={Chen, Sherry and Yao, Shunyu and Chen, Dian and Hager, Gregory D and Zhao, Rui},
    journal={arXiv preprint arXiv:2303.04129},
    year={2023}
}

@article{wu2023graph,
    title={Graph Neural Networks for Large Language Models: Techniques, Applications, and Future Directions},
    author={Wu, Shirui and Huang, Yuhan and Zhao, Liang and Zhang, Huaping and Xu, Chuan},
    journal={arXiv preprint arXiv:2309.11495},
    year={2023}
}

@article{dong2023survey,
    title={A Survey on Long Text Modeling with Large Language Models},
    author={Dong, Ming and Chen, Bowen and Liu, Qianqian and Li, Feng and Yuan, Yong and others},
    journal={arXiv preprint arXiv:2311.07487},
    year={2023}
}

@article{wang2023retrieval,
    title={Retrieval-Augmented Generation for Large Language Models: A Survey},
    author={Wang, Wayne Xin and Zhang, Xiang and Wen, Ji-Rong},
    journal={arXiv preprint arXiv:2312.10997},
    year={2023}
}

@article{chen2023knowledge,
    title={Knowledge Graphs Meet Large Language Models: A Survey},
    author={Chen, Yuhan and Li, Jing and Ye, Yong and Huang, Yixin},
    journal={arXiv preprint arXiv:2311.07749},
    year={2023}
}

@article{lin2019artificial,
  title={Artificial intelligence, finance, and the law},
  author={Lin, Tom CW},
  journal={Fordham L. Rev.},
  volume={88},
  pages={531},
  year={2019},
  publisher={HeinOnline}
}

@article{liu2023recent,
    title={Recent Advances in Large Language Models: A Survey},
    author={Liu, Yang and Zhong, Ming and Xu, Renren and Zhu, Jiale and Zhang, Yaqing and others},
    journal={arXiv preprint arXiv:2307.06435},
    year={2023}
}

@article{wei2023emergent,
    title={Emergent Abilities of Large Language Models: A Comprehensive Survey},
    author={Wei, Yuxiang and Wang, Zexuan and Liu, Yao and Liu, Xiangyu and Gao, Jianfeng},
    journal={arXiv preprint arXiv:2309.02784},
    year={2023}
}

@article{huang2023large,
    title={Large Language Models for Software Engineering: A Systematic Literature Review},
    author={Huang, Xinyi and Liu, Yanlin and Chen, Junjie and Xie, Tao},
    journal={arXiv preprint arXiv:2308.10620},
    year={2023}
}

@article{wang2023prompting,
    title={Prompting Frameworks for Large Language Models: A Survey},
    author={Wang, Shihan and Li, Yujia and Liu, Yixuan and Sun, Xiang},
    journal={arXiv preprint arXiv:2311.12785},
    year={2023}
}

@article{zhang2023principle,
    title={Principle-Driven Self-Alignment of Language Models from Scratch},
    author={Zhang, Zheng and Zhang, Xueyan and Chen, Yifa and Zhao, Zhou and others},
    journal={arXiv preprint arXiv:2305.03047},
    year={2023}
}

@article{li2023survey,
    title={A Survey on Language Models for Code},
    author={Li, Ziyin and Qian, Yifu and Liu, Yuhao and Liu, Chong and Jiang, Yiyang and others},
    journal={arXiv preprint arXiv:2311.07989},
    year={2023}
}

@article{wang2023towards,
    title={Towards Better Chain-of-Thought Prompting Strategies: A Survey},
    author={Wang, Zhuowei and Zhang, Xin and An, Youliang and Wang, Zhiyong and others},
    journal={arXiv preprint arXiv:2310.04959},
    year={2023}
}

@article{chen2023understanding,
    title={Understanding Large Language Models Through the Lens of Optimization},
    author={Chen, Tianyi and Liu, Jing and Zheng, Yifan and Wang, Yizhou and others},
    journal={arXiv preprint arXiv:2312.03135},
    year={2023}
}

@article{zhao2023survey,
    title={A Survey on Large Language Model based Autonomous Agents},
    author={Zhao, Zhiheng and Lin, Shuai and Xu, Yutao and Wang, Yisen},
    journal={arXiv preprint arXiv:2308.11432},
    year={2023}
}

@article{li2023trustworthy,
    title={Trustworthy Large Language Models: A Survey},
    author={Li, Yuxin and Sun, Yifan and Xue, Xiaoyu and Yang, Yupeng and others},
    journal={arXiv preprint arXiv:2310.19247},
    year={2023}
}

@article{wang2023foundation,
    title={Foundation Models for Natural Language Processing: A Survey},
    author={Wang, Yaqing and Dong, Xin Luna and Wang, Qi and Yang, Yiming},
    journal={Foundations and Trends in Information Retrieval},
    volume={17},
    number={2},
    pages={128--256},
    year={2023}
}

@article{yang2023human,
    title={Human-Like Language Models: A Survey},
    author={Yang, Kai and Wang, Yifan and Zhang, Xiang and Xu, Yifang and others},
    journal={arXiv preprint arXiv:2312.09530},
    year={2023}
}

@article{elhage2023superposition,
    title={Superposition, Memorization, and Double Descent},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2303.14186},
    year={2023}
}

@article{wang2023editing,
    title={Editing Language Models by Identifying and Updating Relevant Representations},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.12341},
    year={2023}
}

@article{meng2023locating,
    title={Locating and Editing Knowledge in Language Models},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={36},
    year={2023}
}

@article{dai2023knowledge,
    title={Knowledge Neurons: Implementing Interpretable Concept Representations in Neural Networks},
    author={Dai, Damai and Li, Lei and Ding, Ning and Huang, Xuezhe and Wei, Furu},
    journal={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
    pages={8912--8925},
    year={2023}
}


@article{wang2023causal,
    title={Causal Representation Learning for Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.14705},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity: Understanding and Manipulating Neural Network Representations},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}


@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}



@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}

@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}


@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}

@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}


@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}

@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}


@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}


@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}


@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

}

@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}

@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}

@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}


@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}


@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}



@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}



@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}


@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}


@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}

@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}



@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}


@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}

@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}


@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}


@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}


@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}



@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}


@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}

@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}

@article{wang2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
    author={Wang, Arthur and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}


@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}


@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2023representation,
    title={Representation Engineering for Text Generation},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{anthropic2023superposition,
    title={Understanding Superposition in Neural Networks},
    author={Anthropic and Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={arXiv preprint arXiv:2310.11454},
    year={2023}
}

@article{wang2023causal,
    title={Causal Scrubbing for Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.02205},
    year={2023}
}

@article{nanda2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Elhage, Nelson and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2308.08760},
    year={2023}
}


@article{anthropic2023representation,
    title={Representation Engineering: A Top-Down Approach to AI Transparency},
    author={Anthropic and Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{li2023mechanistic,
    title={Mechanistic Mode Connectivity in Neural Networks},
    author={Li, Evan and Olsson, Catherine and Askell, Amanda and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2305.18760},
    year={2023}
}

@article{zou2023representation,
    title={Representation Engineering: A Survey of Methods and Applications},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.01405},
    year={2023}
}


@article{wang2023understanding,
    title={Understanding and Manipulating Representations in Large Language Models},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14997},
    year={2023}
}

@article{nanda2023progress,
    title={Progress Measures for Representation Learning in Neural Networks},
    author={Nanda, Neel and Chan, Ho-Chung and Ndousse, Kamal and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05217},
    year={2023}
}

@article{phang2023transformers,
    title={Transformers Learn Representations by Gradient Descent},
    author={Phang, Jason and Prasad, Aaditya and Geiger, Atticus and Liang, Percy and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2212.07677},
    year={2023}
}

@article{belrose2023scoring,
    title={Scoring Representations by their Contextual Specificity},
    author={Belrose, Nicholas and Nanda, Neel and Olsson, Catherine and Askell, Amanda and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.00025},
    year={2023}
}

@article{cunningham2023causal,
    title={Causal Scrubbing: A Method for Rigorously Testing Representation Learning Hypotheses},
    author={Cunningham, Edward and Lindner, Daniel and Nanda, Neel and Olsson, Catherine},
    journal={arXiv preprint arXiv:2310.03019},
    year={2023}
}

@article{wang2023towards,
    title={Towards Understanding Grokking: An Effective Theory of Representation Learning},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.07747},
    year={2023}
}

@article{hubinger2023neurons,
    title={Neurons in Large Language Models: Dead, Polysemantic, and Interpretable},
    author={Hubinger, Evan and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2309.04658},
    year={2023}
}

@article{li2023laws,
    title={Laws of Mechanistic Abstraction in Neural Networks},
    author={Li, Evan and Askell, Amanda and Drain, Dawn and Nanda, Neel and Amodei, Dario and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Olsson, Catherine and Elhage, Nelson},
    journal={arXiv preprint arXiv:2309.06256},
    year={2023}
}

@article{wang2023interpretable,
    title={Interpretable Parts: Analyzing and Controlling Neural Networks by Finding Meaningful Directions},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2304.14999},
    year={2023}
}

@article{anthropic2023decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.11220},
    year={2023}
}

@article{meng2023mass,
    title={Mass-Editing Memory in a Transformer},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={arXiv preprint arXiv:2210.07229},
    year={2023}
}

@article{bau2020understanding,
    title={Understanding the Role of Individual Units in a Deep Neural Network},
    author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
    journal={Proceedings of the National Academy of Sciences},
    volume={117},
    number={48},
    pages={30071--30078},
    year={2020}
}

@article{elhage2022solu,
    title={{SOLU}: Mechanistic Analysis of Internal Language Model Representations},
    author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Ndousse, Kamal and Hernandez, Danny and Drain, Dawn},
    journal={Transactions on Machine Learning Research},
    year={2022}
}

@article{wang2023circuit,
    title={Circuit Analysis of Language Models: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{cammarata2021curve,
    title={Curve Detectors: A Theory of Neural Network Features},
    author={Cammarata, Nick and Goh, Gabriel and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Olah, Chris},
    journal={Distill},
    year={2021}
}

@article{meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
    journal={Advances in Neural Information Processing Systems},
    volume={35},
    pages={5260--5273},
    year={2022}
}


@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023monosemanticity,
    title={Towards Monosemantic Representations in Neural Networks},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2310.14033},
    year={2023}
}

@article{wang2023mechanistic,
    title={Mechanistic Interpretability of Neural Networks: A Survey},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2305.02430},
    year={2023}
}

@article{olsson2023interpretability,
    title={Interpretability in the Wild: A Circuit for Indirect Object Identification},
    author={Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2211.00593},
    year={2023}
}

@article{burns2023discovering,
    title={Discovering Latent Knowledge in Language Models Without Supervision},
    author={Burns, Colin and Steinhardt, Jacob and Klein, Jacob},
    journal={arXiv preprint arXiv:2212.03827},
    year={2023}
}

@article{anthropic2023tracr,
    title={{TRACR}: A Framework for Compiling Transformers into Interpretable Circuits},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2301.05062},
    year={2023}
}

@article{wang2022geometry,
    title={The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2310.06824},
    year={2022}
}

@article{dai2022knowledge,
    title={Knowledge Neurons in Pretrained Transformers},
    author={Dai, Damai and Li, Lei and Ding, Ning and Huang, Xuezhe and Wei, Furu},
    journal={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
    pages={8493--8506},
    year={2022}
}

@article{anthropic2022decomposition,
    title={Decomposing Language Models Into Understandable Components},
    author={Anthropic and Olsson, Catherine and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn and Elhage, Nelson and Joseph, Nicholas and Kernion, John and Ndousse, Kamal and Nanda, Neel and Amodei, Dario},
    journal={arXiv preprint arXiv:2210.03095},
    year={2022}
}

@article{park2023linear,
    title={Linear Representation Analysis: Understanding Neural Network Representations through Linear Models},
    author={Park, Jaeho and Kim, Jihwan and Lee, Hyunsoo and Kim, Jaewoo},
    journal={arXiv preprint arXiv:2305.08072},
    year={2023}
}

@article{marks2023geometry,
    title={The Geometry of Truth in Large Language Models},
    author={Marks, Paul and Chen, Jia and Zhao, Justin and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
    journal={arXiv preprint arXiv:2310.06824},
    year={2023}
}

@article{qiu2024spectral,
    title={Spectral Methods for Neural Network Editing},
    author={Qiu, Shuyang and Cao, Yian and Zhang, Yue and Zhao, Tong},
    journal={arXiv preprint arXiv:2401.05793},
    year={2024}
}

@article{raghu17,
  title={Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability},
  author={Raghu, Maithra and Gilmer, Justin and Yosinski, Jason and Sohl-Dickstein, Jascha},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{jorgensen2023improving,
    title={Improving Representation Engineering through Mean-Centered Activation Vectors},
    author={Jorgensen, Erik and Raghunathan, Aditi and Liang, Percy},
    journal={arXiv preprint arXiv:2310.12797},
    year={2023}
}

@article{rimsky2023steering,
    title={Contrastive Activation Addition: Efficient Concept Steering in Language Models},
    author={Rimsky, Mikhail and Kaplan, Jared and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn},
    journal={arXiv preprint arXiv:2312.01054},
    year={2023}
}

@article{stickland2024steering,
    title={Selective Vector Application for Efficient Model Steering},
    author={Stickland, Asa Cooper and Rimsky, Mikhail and Askell, Amanda and Chan, Ho-Chung},
    journal={arXiv preprint arXiv:2401.09417},
    year={2024}
}

@article{todd2023function,
    title={Function Vectors in Large Language Models},
    author={Todd, Andrew and Steinhardt, Jacob and Liang, Percy},
    journal={arXiv preprint arXiv:2310.15213},
    year={2023}
}

@article{liu2023context,
    title={Context Learning in Language Models: Mechanisms and Representations},
    author={Liu, Nelson F. and Steinhardt, Jacob and Liang, Percy},
    journal={arXiv preprint arXiv:2309.15431},
    year={2023}
}

@article{bahri24,
  title={Explaining neural scaling laws},
  author={Bahri, Yasaman and Dyer, Ethan and Kaplan, Jared and Lee, Jaehoon and Sharma, Utkarsh},
  journal={Proceedings of the National Academy of Sciences},
  volume={121},
  number={27},
  pages={e2311878121},
  year={2024},
  publisher={National Academy of Sciences}
}

@article{ball2024understanding,
    title={Understanding and Preventing Jailbreak Attacks in Large Language Models},
    author={Ball, Daniel and Thakur, Nishant and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn},
    journal={arXiv preprint arXiv:2401.05668},
    year={2024}
}

@article{arditi2024refusal,
    title={Refusal Mechanisms in Language Models: A Representation Analysis},
    author={Arditi, Eran and Chan, Ho-Chung and Askell, Amanda and Drain, Dawn},
    journal={arXiv preprint arXiv:2401.03575},
    year={2024}
}

@article{cao2024personalized,
    title={Personalized Steering of Language Model Behavior},
    author={Cao, Yian and Zhao, Tong and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2401.06811},
    year={2024}
}

@article{luo2024pace,
    title={PACE: Precision Activation Control for Efficient Language Model Editing},
    author={Luo, Zhiying and Zhang, Yue and Zhao, Tong},
    journal={arXiv preprint arXiv:2401.07896},
    year={2024}
}

@article{hu2021lora,
    title={LoRA: Low-Rank Adaptation of Large Language Models},
    author={Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Chen, Weizhu},
    journal={arXiv preprint arXiv:2106.09685},
    year={2021}
}

@article{bailey2023soft,
  title={Soft prompting might be a bug, not a feature},
  author={Bailey, Luke and Ahdritz, Gustaf and Kleiman, Anat and Swaroop, Siddharth and Doshi-Velez, Finale and Pan, Weiwei},
  year={2023}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@article{lester2022guiding,
  title={Guiding frozen language models with learned soft prompts},
  author={Lester, Brian and Constant, Noah and Al-Rfou, Rami},
  journal={Google AI Blog},
  year={2022}
}

@article{bhaila2024soft,
  title={Soft Prompting for Unlearning in Large Language Models},
  author={Bhaila, Karuna and Van, Minh-Hao and Wu, Xintao},
  journal={arXiv preprint arXiv:2406.12038},
  year={2024}
}

@article{li2021prefix,
    title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
    author={Li, Xiang Lisa and Liang, Percy},
    journal={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics},
    pages={4582--4597},
    year={2021}
}

@article{hendrycks2021unsolved,
    title={Unsolved Problems in ML Safety},
    author={Hendrycks, Dan and Carlini, Nicholas and Schulman, John and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2109.13916},
    year={2021}
}

@article{golechha2024position,
    title={Position-based Prompting for Health Domain Adaptation in Large Language Models},
    author={Golechha, Mahima and Feng, Shikun and Gunasekara, Chulaka and Dernoncourt, Franck and Basu, Prithwish},
    journal={arXiv preprint arXiv:2401.12003},
    year={2024}
}

@article{liu2024aligning,
    title={Aligning Large Language Models with Human Preferences through Representation Engineering},
    author={Liu, Xiao and Wang, Hao and Zhang, Yingfang and Zhang, Hongyi and Wang, Heng},
    journal={arXiv preprint arXiv:2401.05399},
    year={2024}
}

@article{tlaie2024exploring,
    title={Exploring Representation Engineering for Language Model Safety},
    author={Tlaie, Adam and Askell, Amanda and Chan, Ho-Chung and Drain, Dawn},
    journal={arXiv preprint arXiv:2401.06850},
    year={2024}
}

@article{vonrutte2024language,
    title={Language Model Behavior: A Comprehensive Survey},
    author={von Rutte, Dario and Wolfe, Ryan and Deng, Yue and Goodman, Noah D.},
    journal={arXiv preprint arXiv:2401.09012},
    year={2024}
}

@article{wang2024adaptive,
    title={Adaptive Representation Engineering: Towards Dynamic Model Behavior Control},
    author={Wang, Alex and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2401.08967},
    year={2024}
}

@article{zou2024improving,
    title={Improving Representation Engineering through Gradient-Based Optimization},
    author={Zou, Andy and Wang, Linda and Kolter, J. Zico and Steinhardt, Jacob},
    journal={arXiv preprint arXiv:2401.10152},
    year={2024}
}

@misc{goldowskydill2025detectingstrategicdeceptionusing,
      title={Detecting Strategic Deception Using Linear Probes}, 
      author={Nicholas Goldowsky-Dill and Bilal Chughtai and Stefan Heimersheim and Marius Hobbhahn},
      year={2025},
      eprint={2502.03407},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.03407}, 
}

@misc{greenblatt2024alignmentfakinglargelanguage,
      title={Alignment faking in large language models}, 
      author={Ryan Greenblatt and Carson Denison and Benjamin Wright and Fabien Roger and Monte MacDiarmid and Sam Marks and Johannes Treutlein and Tim Belonax and Jack Chen and David Duvenaud and Akbir Khan and Julian Michael and Sören Mindermann and Ethan Perez and Linda Petrini and Jonathan Uesato and Jared Kaplan and Buck Shlegeris and Samuel R. Bowman and Evan Hubinger},
      year={2024},
      eprint={2412.14093},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.14093}, 
}

%@misc{bronzini2024unveilingllmsevolutionlatent,
%      title={Unveiling LLMs: The Evolution of Latent Representations in a Dynamic Knowledge Graph}, 
%      author={Marco Bronzini and Carlo Nicolini and Bruno Lepri and Jacopo Staiano and Andrea Passerini},
%      year={2024},
%      eprint={2404.03623},
%      archivePrefix={arXiv},
%      primaryClass={cs.CL},
%      url={https://arxiv.org/abs/2404.03623}, 
%}

@misc{deepseekai2024deepseekv3technicalreport,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI and Aixin Liu and Bei Feng and Bing Xue and Bingxuan Wang and Bochao Wu and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Daya Guo and Dejian Yang and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Haowei Zhang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Li and Hui Qu and J. L. Cai and Jian Liang and Jianzhong Guo and Jiaqi Ni and Jiashi Li and Jiawei Wang and Jin Chen and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and Junxiao Song and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Lei Xu and Leyi Xia and Liang Zhao and Litong Wang and Liyue Zhang and Meng Li and Miaojun Wang and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Mingming Li and Ning Tian and Panpan Huang and Peiyi Wang and Peng Zhang and Qiancheng Wang and Qihao Zhu and Qinyu Chen and Qiushi Du and R. J. Chen and R. L. Jin and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and Runxin Xu and Ruoyu Zhang and Ruyi Chen and S. S. Li and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shaoqing Wu and Shengfeng Ye and Shengfeng Ye and Shirong Ma and Shiyu Wang and Shuang Zhou and Shuiping Yu and Shunfeng Zhou and Shuting Pan and T. Wang and Tao Yun and Tian Pei and Tianyu Sun and W. L. Xiao and Wangding Zeng and Wanjia Zhao and Wei An and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and X. Q. Li and Xiangyue Jin and Xianzu Wang and Xiao Bi and Xiaodong Liu and Xiaohan Wang and Xiaojin Shen and Xiaokang Chen and Xiaokang Zhang and Xiaosha Chen and Xiaotao Nie and Xiaowen Sun and Xiaoxiang Wang and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xingkai Yu and Xinnan Song and Xinxia Shan and Xinyi Zhou and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and Y. K. Li and Y. Q. Wang and Y. X. Wei and Y. X. Zhu and Yang Zhang and Yanhong Xu and Yanhong Xu and Yanping Huang and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Li and Yaohui Wang and Yi Yu and Yi Zheng and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Ying Tang and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yu Wu and Yuan Ou and Yuchen Zhu and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yukun Zha and Yunfan Xiong and Yunxian Ma and Yuting Yan and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Z. F. Wu and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhen Huang and Zhen Zhang and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhibin Gou and Zhicheng Ma and Zhigang Yan and Zhihong Shao and Zhipeng Xu and Zhiyu Wu and Zhongyu Zhang and Zhuoshu Li and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Ziyi Gao and Zizheng Pan},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}