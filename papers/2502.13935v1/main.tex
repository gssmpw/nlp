%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
%\usepackage{subfigure}
\usepackage{booktabs} % for professional tables


\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{subcaption}
\usepackage{makecell}
\usepackage{tabularx}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Continually Learning Structured Visual Representations via Network Refinement with Rerelation}

\begin{document}

\twocolumn[
\icmltitle{Continually Learning Structured Visual Representations via Network Refinement with Rerelation}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Zeki Doruk Erden}{epfl}
\icmlauthor{Boi Faltings}{epfl}
\end{icmlauthorlist}

\icmlaffiliation{epfl}{Artificial Intelligence Laboratory, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland}

\icmlcorrespondingauthor{Zeki Doruk Erden}{zeki.erden@epfl.ch}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{continual learning, vision, network refinement}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}

Current machine learning paradigm relies on continuous representations like neural networks, which iteratively adjust parameters to approximate outcomes rather than directly learning the structure of problem. This spreads information across the network, causing issues like information loss and incomprehensibility Building on prior work in environment dynamics modeling, we propose a method that learns visual space in a structured, continual manner. Our approach refines networks to capture the core structure of objects while representing significant subvariants in structure efficiently. We demonstrate this with 2D shape detection, showing incremental learning on MNIST without overwriting knowledge and creating compact, comprehensible representations. These results offer a promising step toward a transparent, continually learning alternative to traditional neural networks for visual processing.

% The current machine learning paradigm uses continuous representations like neural networks, which adjust parameters iteratively to approximate outcomes rather than directly learning the visual space's structure. This approach spreads information across the network, leading to issues like destruction of existing information and human incomprehensibility. Here, we build on prior work in environment dynamics modeling and introduce an early design of a method that learns visual space in a structured, continual way. Our approach refines networks representing visual spaces to capture the core structure of object classes minimally while hierarchically organizing observed subvariants within resource limits. We demonstrate this with a shape detection task on 2D objects, showing it can incrementally learn MNIST without overwriting knowledge and create compact, interpretable network representations. These preliminary results suggest a promising first step toward a transparent and continually learning alternative to traditional neural networks for visual information processing.

% The current machine learning paradigm relies on continuous representations, such as neural networks, which iteratively adjust parameters to approximate outcomes rather than directly learning the underlying structure of the visual space. This method disperses information across the network, resulting in challenges like a lack of continual learning capability and human incomprehensibility. In this work, we expand on prior research in environment dynamics modeling and present a learning method that is inherently continual and structured in its representation of visual space. At the core of our approach is a mechanism for refining and representing networks to capture the essential structure of a class of objects minimally, while also organizing frequently observed subvariants hierarchically within the limits of available resources. We demonstrate our method’s proof-of-concept with a basic feature representation for shape detection on planar objects, showcasing its performance in incrementally learning the MNIST dataset without disrupting existing knowledge and generating compact, human-comprehensible network representations of digits. This highlights the potential of a transparent and integrable alternative for visual information processing, offering a contrast to traditional neural networks.


\end{abstract}



\section{Introduction}
\label{sec:introduction}

% In the landscape of modern machine learning (ML), continuous representations such as neural networks (NNs) have become the standard for modeling complex systems and visual data. These models, through iterative adjustments to network parameters, approximate outcomes by dispersing information across layers. While this approach has yielded impressive results across various domains, including image recognition and natural language processing, it has also introduced a host of challenges that demand urgent attention. 

% The limitations of traditional neural networks become especially evident when considering their struggle to learn from multiple tasks sequentially without destroying past knowledge—a challenge known as continual learning. Continual learning is not just a desirable feature but a fundamental necessity for machine learning systems, as it reflects the realistic flow of information and the incremental nature of real-world learning requirements. Without this capability, AI models require frequent retraining from scratch whenever new tasks or data emerge, a process that is resource-intensive, inefficient, and impractical for scaling. Moreover, continual learning is essential for the persistent acquisition of knowledge, enabling systems to improve open-endedly over time while integrating new information from small, incremental datasets. As machine learning systems continue to evolve, addressing this shortcoming becomes critical for developing adaptable, comprehensible, and flexible systems that can thrive in the dynamic and ever-changing complexities of real-world environments. Furthermore, their heavily overparameterized and nonstructured nature has, for the better part of a decade, prioritized convenience and performance over comprehensibility—a compromise that has fundamentally limited our ability to fully trust, control, and integrate these systems.

Modern machine learning relies on neural networks to model complex systems, achieving remarkable success in areas like image recognition and NLP \cite{khan2021machine, zhao2023survey}, yet as these problems are solved, crucial shortcomings at their core start to gain attention \cite{clune2019ai,zador2019critique,marcus2018deep,lecun2022path}. Importantly, they struggle with continual learning—the ability to learn new tasks without forgetting previous ones, as essential for open-ended learning, reflecting real-world dynamics. This limitation necessitates frequent, resource-intensive retraining, making scalability impractical. Furthermore, the overparameterized, unstructured design of neural networks has prioritized performance over comprehensibility, limiting trust, control, and adaptability in complex environments. The lack of comprehensibility in AI is a critical concern as systems grow more capable. Neural networks' opaque nature makes their internal workings hard to understand, refine, or integrate with structured systems. This opacity hinders human validation, corrective adjustments, and the incorporation of explicit knowledge. Without these capabilities, using AI in critical decision-making poses risks absent in more transparent engineering domains.



An alternative exists: we can retain the power of advanced learning systems while prioritizing structure, transparency, and control by focusing research on these goals. This is essential for building adaptable, human-aligned systems suited for real-world complexities. Prior work \cite{Erden2024Modelleyen, erden2025agential_extendedabs, erden2025agential} has demonstrated the viability of frameworks that incorporate minimal, yet rich, representations of data to achieve continual learning and interoperability on simple environment dynamics modeling, offering a clear path toward systems that align more closely with human understanding. In this paper, we expand on these advancements by proposing a novel framework to apply these foundational ideas to the domain of observation spaces that can be represented as networks, in particular to visual information processing. Our approach refines these principles to create a continual and structured learning process for vision, emphasizing the capture of essential object structures while hierarchically organizing frequently observed subvariants. This method ensures that knowledge is continually learned without disrupting existing representations and creates compact, directly human-comprehensible representations. It further lays the groundwork for applying the broader framework from \cite{erden2025agential} to visual domains, supporting structured representations for modeling environment dynamics.


We demonstrate the potential of our approach with a proof-of-concept shape detection task on 2D objects. The model learns incrementally from the MNIST dataset, retaining knowledge while incorporating new information without task boundaries or replay, and generates structured, human-comprehensible representations. This showcases the potential of this type of approach as a transparent alternative to traditional neural networks, capable of learning continually by design, hence addressing key challenges in machine learning in general as well as for visual processing.


% We validate the preliminary feasibility of our approach through a proof-of-concept demonstration using a simple shape detection task on 2D objects. The model incrementally learns from the MNIST dataset, retaining previously learned knowledge while incorporating new information without prevalent constraining assumptions of existing methods like task boundaries or replay, all the while learning structured representations that are comprehensible by the human eye. This highlights the potential of our method as a transparent, integrable alternative to traditional neural network architectures, offering a solution to some of the most pressing challenges in visual learning and cognitive modeling.



\section{Related work}
\label{sec:related_work}


Two most important core limitations of current ML systems are the inability of continual learning and incomprehensibility of internal structure; problems often tackled in isolation \cite{kirkpatrick2017overcoming,rusu2016progressive,jacobson2022task,hadsell2020embracing,zhuang2020comprehensive,xu2019explainable}. Solutions proposed for these problems often don't fully resolve the fundamental limitations of NNs in this regard but aim to mitigate their effects.

% Many continual learning solutions rely on assumptions that simplify the problem (e.g. externally defined task boundaries and explicit task change information \cite{rusu2016progressive,jacobson2022task} or storage and replay of past observations \cite{buzzega2020dark}) or only bias learning towards past tasks without ensuring true continual learning \cite{kirkpatrick2017overcoming}. Same problems persist in visual problems \cite{qu2021recent}, where even with techniques that otherwise provide state of the art performance, realizing continual learning is often dependent either on replay buffers (e.g. \cite{galashov2023continually}) or externally defined task boundaries (e.g. \cite{wang2022continual}). One notable exception to this are methods that work by generating multiple experts and assigning newcoming tasks to experts via match with a generative model (\cite{erden2024directed, lee2020neural}). These methods are indeed powerful and act as operating on more relaxed constraints, however they still share the assumption of distinct tasks implicitly by their decomposition of the whole system into distinct experts. This becomes important with the assumption an available bulk of data sufficient to train the generative model of each expert at the time of their creation, which can be a reasonable assumption within the controlled training flow of offline experimentation but not necessarily true in an arbitrary continual learning flow, where an important point is for data from different tasks to be distributed across time without necessarily available as a bulk (so that the agent can \textit{continue} learning a past task or environment, in addition to not destroying existing information on that). In other words, the continual learning problem simply becomes transferred to the generative model used for task identification instead of the full system, but is still very much present. In addition to these, none of these continual learning approaches aim to tackle comprehensibility of the models at together with the continual learning problem as a problem that shares the same root cause, which brings us to the next point.

Many continual learning methods rely on simplifying assumptions, such as externally defined task boundaries and task change information \cite{rusu2016progressive, jacobson2022task}, or storing and replaying past observations \cite{buzzega2020dark}, which bias learning toward previous tasks without enabling true continual learning \cite{kirkpatrick2017overcoming}. These issues also affect visual problems \cite{qu2021recent}, where even state-of-the-art techniques depend on replay buffers \cite{galashov2023continually} or task boundaries \cite{wang2022continual}. One exception is methods generating multiple experts and assigning tasks based on a generative model \cite{erden2024directed, lee2020neural}. While powerful, these methods still assume distinct tasks by decomposing the system into experts, relying on the assumption that bulk data is available for each expert’s generative model. This assumption holds in offline experimentation but not in continual learning, where data is distributed over time and not available in bulk. Thus, the continual learning problem shifts to the generative model for task identification rather than the entire system. Additionally, none of these methods address model comprehensibility alongside continual learning, which shares the same root cause.






% Existing methods for comprehensibility of learned models, collected under the umbrella field of Explainable AI methods \cite{xu2019explainable, kashefi2023explainability} attempt to provide post-hoc explanations for the operation of neural networks, yet they fail to address the fundamental incomprehensibility of their internal structures, leaving them far from being truly engineerable. Visual processing with neural network-based methods also suffer from the same problems \cite{kashefi2023explainability}. Furthermore, the challenge of explainability is often approached independently of the continual learning problem, rather than being seen as stemming from a shared underlying issue. Even studies that consider explainability within the context of continual learning tend to either propose distinct, sequentially applicable mechanisms for each problem separately \cite{roy2022interpretable} or focus on additional explainability challenges that arise when certain continual learning methods are used \cite{rymarczyk2023icicle, cossu2024drifting}.

Current approaches to making learned models comprehensible, categorized under Explainable AI methods \cite{xu2019explainable, kashefi2023explainability} offer post-hoc explanations for neural network operations but fail to address the core incomprehensibility of their internal structures, leaving them hard to trustfully validate and engineer. Visual processing with neural networks faces the same issue \cite{kashefi2023explainability}. Moreover, comprehensibility is often treated separately from continual learning, rather than as a shared challenge. Studies that consider both tend to propose distinct mechanisms for each problem \cite{roy2022interpretable} or focus on specific explainability issues arising from certain continual learning methods \cite{rymarczyk2023icicle, cossu2024drifting}.



% These limitations are inherent to neural networks and similar methods, and addressing them within the same paradigm is either impossible or leads to excessive complexity of methodology. Recent work has proposed a different approach to learning, termed \textit{varsel mechanisms} \cite{erden2025agential, erden2025agential_extendedabs}, as an approach that learns via local variation and selection, an important principle of adaptation in biological systems as well  \cite{marc2005plausibility, gerhart2007theory}. The particular method proposed in this class, termed Modelleyen \cite{Erden2024Modelleyen, erden2025agential, erden2025agential_extendedabs}, has been shown to realize continual learning starting from the lowest levels of organization without any task boundaries, task change information, or replay buffer; as well as resulting in an inherently comprehensible internal structure as a result of learning structure in a manner that is minimally complex at each level, hence addressing the two major issues of continual learning and explainability/comprehensibility together, by addressing their common origin, that being a nonstructured representation.


These limitations are inherent to neural networks and similar methods, and attempting to address them within the same paradigm either proves impossible or leads to excessive methodological complexity. Recent work has proposed \textit{varsel mechanisms} \cite{erden2025agential, erden2025agential_extendedabs}, which learn via local variation and selection, mimicking biological adaptation \cite{marc2005plausibility, gerhart2007theory}. The method, Modelleyen \cite{Erden2024Modelleyen, erden2025agential, erden2025agential_extendedabs}, enables continual learning without task boundaries, task change information, or replay buffers, while also creating an inherently comprehensible structure by learning with minimal complexity at each level. This approach addresses both continual learning and explainability/comprehensibility by tackling their shared root cause: nonstructured representations.











\section{Method}
\label{sec:method}


\subsection{Background: Modelleyen and Varsel mechanisms}

Previous studies (\cite{Erden2024Modelleyen}, \cite{erden2025agential_extendedabs}, \cite{erden2025agential}) introduced \textit{Modelleyen} as an example of proposed \textit{varsel mechanisms}, which learn through component-level topological variation and selection to model external environments or tasks. This contrasts with methods like neural networks that rely on fine-tuning continuous parameters without explicitly learning network topology. Due to space constraints, we provide only a brief overview here; for full details, see \cite{Erden2024Modelleyen, erden2025agential_extendedabs, erden2025agential} and Section \ref{sec:my_background} for the formal learning algorithm from these papers.


The learning core of the varsel network in \textit{Modelleyen} consists of \textit{conditioning (state) variables (CSVs)}, which, along with raw observations and target predictions, form the model's building blocks, akin to neurons in neural networks. The method in \cite{Erden2024Modelleyen, erden2025agential} exhaustively connects CSVs with other state variables (representing raw observations or their discrete activation dynamics) based on observed data at each time instant, then refines these connections with further observations (see Fig. \ref{fig:csvform} in Appendix). Higher-order CSVs are formed upstream (Fig. \ref{fig:csvformupstream} in Appendix) to predict downstream CSV states when conflicts arise, enabling the representation of arbitrary logical functions. Theorem 1 in \cite{Erden2024Modelleyen} proves a strong continual learning property: a CSV's response to a past instance 
$x_0$ remains consistent even after structural modifications from new instances $x_i$, provided no negative sources formation occurs in the meantime. Although system-wide performance retention is not guaranteed due to mechanisms like suppressive connections or component removals, this still ensures local information retention and consistency, providing a potent guarantee of knowledge preservation with system-wide reflections verified experimentally \cite{erden2025agential}.

% The core components for learning in the varsel network proposed in Modelleyen are called \textit{conditioning (state) variables (CSVs)} which, together with the raw observations they take as input and targets they explain \& predict, form the building blocks of a predictive model, analogous to neurons for a neural network. The method in \cite{Erden2024Modelleyen, erden2025agential} operates on the principle of exhaustive connection formation of these CSVs with other state variables in the model (which can correspond to raw observations or their activation/deactivation dynamics, all assumed to be discrete variables) based on everything that is observed in a given time instant (hence all possibly contributing to the observed outcome), and then gradually \textit{refining} these relations with further observations of the same outcome (see Figure \ref{fig:csvform} in Appendix for an illustration). The process continues upstream with higher-order CSVs formed, predicting the state of the downstream CSVs closer to the target variables, when the connection formation-refinement cycle of one CSV results in a conflict with what is observed. This process, repeated upstream and with positive and negative sources, can represent arbitrary logical functions of any complexity. In \cite{Erden2024Modelleyen}, Theorem 1, it is shown that this learning flow comes with a strong guarantee of continual learning, in that the response of any single CSV to a past instance $x_0$ remains consistent with its response to the same instance when it was observed in the past even if the CSV has undergone structure modification in response to some new instance(s) $x_1$ in the duration between the two observations of $x_0$, as long as the CSV does not undergo a negative sources formation (a process that happens once in the lifetime of the CSV). We note for context that this guarantee does \textit{not} translate into a guarantee of system-wide perfect retention of performance, as there are other mechanism that can affect the system response (including suppressive connections and component removals based on statistical insignificance). It is, however, a guarantee of retention of the relevant information at a local level in a way that the response at local level remains consistent with the past inputs.

% Previous work validated Modelleyen's approach on environment dynamics modeling in a simple, low-dimensional finite state machine. Need for further extensions to be able to process higher-dimensional and structured observations spaces was discussed (\cite{erden2025agential}), in particular within the context of the capability of operating on networks instead of lists of state variables. Our method aims to extend this approach by providing such an extension, exemplifying how the principles underlying Modelleyen can be adapted to process visual observations, as discussed in the following subsections.

Previous work validated \textit{Modelleyen} on low-dimensional finite state machines; yet highlighted the need for extensions to handle higher-dimensional and structured observation spaces, particularly for operating on networks rather than lists of state variables \cite{erden2025agential}. Our method extends this approach, adapting \textit{Modelleyen}'s principles to process visual observations, as detailed in the following subsections.



\subsection{Continually learning structured visual representations}

% Our aim now is to extend the framework proposed in \cite{erden2025agential} to primarily operate on \textit{networks} as observations, instead of raw state variables. Graphs or networks can be used to represent many different domains, notably important ones for AI being observations with spatial and temporal properties. Our focus in this work is in vision, in particular on learning 2D shape identification, though the approach remains general for any observation that can be represented as a network. Furthermore, the method remains agnostic to the particular means of converting a 2D image into a network. We detail the particular feature representation we use for our experiments in Section \ref{sec:feature_representation}, however for this section the reader can think about a general concept of a visual feature (including edges, colors, gradients, whole objects - or, on the opposite end, raw pixels) where it is mentioned.

We aim to extend the framework from \cite{erden2025agential} to operate on \textit{networks} as observations, rather than raw state variables. Networks can represent diverse domains, particularly spatial and temporal observations relevant to AI. Our focus is on vision, specifically 2D shape identification, though the approach is generalizable to any network-representable observation provided an appropriate representational conversion is used. The method is agnostic to how a 2D image is converted into a network. We detail our experimental feature representation in Section \ref{sec:feature_representation}, but for this section, the reader can think about a generic concept of a visual feature that can refer to edges, colors, gradients, objects, or even raw pixels. We refer to this design as \textit{Modelleyen with network refinement} (\textit{MNR} for short).

\subsubsection{Representational basis}

First, let's define the basis for our representation of observations and input sources for conditioning state variables (CSVs) in this extension:

\begin{definition}
    A \textit{state network (SN)} is a directed graph $(N,E)$, where each node $N$ has an associated \textit{type}. A list of tuples of state networks and associated keys, $P=[(k_0, SN_0), (k_1, SN_1), ...]$ is called a \textit{state polynetwork (SPN).}
\end{definition}

% Node types in state networks are intended to represent distinct features (e.g. in visual space, edges or corners with certain orientations, object types, etc.) and nodes are distinct, observed instantiations of such features in the present in the current observation (e.g. in a visual input, two distinct edges with the same orientation, or two instances of the same object, would be represented as two distinct nodes of the same type - see Figure \ref{fig:assignment_source} for an example). Edges ($E$) are intended to represent the relations between the entities represented by nodes - in visual inputs this could correspond to relative positions of objects to one another (see next section), in temporal domains they can correspond to succession relations. A state polynetwork is just a collection of distinct SNs, together with a designator key, which allows us to define different types of relations and, if needed, types of features. In case of visual space, this may correspond to different feature types (shape information, color gradients, even perhaps together with abstract objects in the visual space if applicable), or different types of relations between features (such as relative positioning across different dimensions in a multi-dimensional observation spaces, as we do in the next section). Examples of an actual SPN (whose construction is detailed in the coming section) is shown on Figure \ref{fig:representation_example_vn}.

Node types in state networks 
(SNs) represent distinct features (e.g., edges, corners, or objects in visual space), with nodes being observed instances of these features in the current observation (e.g., two edges with the same orientation or two instances of the same object are distinct nodes of the same type; see Figure \ref{fig:assignment_source} for an example). Edges ($E$) represent relations between nodes, such as relative positions in visual inputs or succession in temporal domains. A state polynetwork (SPN) is a collection of distinct state networks with a designator key, enabling the definition of different feature and relation types. In visual space, this could include shape, color gradients, or abstract objects, as well as multi-dimensional relations (e.g., relative positioning). An example SPN is shown in Figure \ref{fig:representation_example_vn} (its means of construction from images is detailed in the next section).

% SPNs are going to act as the input sources for CSVs in our model, in place of the sets of state variables in \cite{Erden2024Modelleyen, erden2025agential}. Consequently, learning the model will correspond to learning proper SPN structures that captures the information that we want to represent in as a result of learning, which brings us to the question of how an SPN (representing the existing input configuration of a CSV) should be modified in response to observation of other SPNs (i.e. new observations).

SPNs will serve as input sources for CSVs in our model, replacing the sets of state variables in \cite{Erden2024Modelleyen, erden2025agential}. Learning the model involves constructing SPN structures that capture the desired information, bringing us to the question of how an SPN (representing a CSV's input configuration) should be modified in response to new SPN observations.




\subsubsection{Network refinement with rerelation}
\label{sec:netref_description}

% Refinement is the fundamental learning process in Modelleyen \cite{Erden2024Modelleyen, erden2025agential}, where two lists of state variables (acting as a sources for a CSV) are reduced to their intersection in order to represent only the subset that is \textit{required} to activate the CSV they are a source of. An analogous operation that can find the \textit{shared part} of two (or more, when applied sequentially) state polynetworks (SPNs) is required to form the basis of the learning flow at the model level (which is discussed in the next subsection).

Refinement, the core learning process in \textit{Modelleyen} \cite{Erden2024Modelleyen, erden2025agential}, reduces two lists of state variables (sources for a CSV) to their intersection, retaining only the subset necessary to activate the CSV. An analogous operation is needed to identify the \textit{shared part} of two or more state polynetworks (SPNs), forming the basis for the model-level learning flow (discussed in Sec. \ref{sec:learning_flow}).


For that purpose, we make the following definition:

\begin{definition}
    An SPN $P_0=[(k_0, SN^0_0),\ (k_1, SN^0_1),$ $...(k_N, SN^0_N)]$ is \textit{satisfied by} another SPN $P_1=[(k_0, SN^1_0), (k_1, SN^1_1), ... (k_N, SN^1_N)]$ (with the same set of keys  $K=[k_0, k_1, ... k_N]$) given a potentially partial \textit{assignment} $f: V(P_0) \nrightarrow V(P_1)$, where $N(P_i)$ is the set of all nodes across all state networks of $P_i$, if and only if the following conditions hold:
    \begin{enumerate}
        \item For $\forall n_0 \in N(P_0)$, $f(n_0)$ is defined (has a mapped node in $N(P_1)$), and
        \item For $\forall e_0=(n_0, n_1) \in E(SN^0_i)$ where $E(SN^0_i)$ is the set of all edges in state network $SN^0_i$ in $P_0$, there exists a path in $SN^1_i$ from $f(n_0)$ to $f(n_1)$.
    \end{enumerate}
\end{definition}

% Intuitively, $P_0$ is satisfied by $P_1$ given an assignment if every node in $P_0$ has an assigned target node, and every edge in $P_1$ has a path between the assigned targets of the two endpoints of the edge in the corresponding SN (i.e. the SN with the same key) in $P_1$. This means that every entity and relation represented in $P_0$ is also present in $P_1$, even if they are mediated by entities that are not present in $P_0$ (since we are looking for \textit{paths} in $P_1$, not edges, corresponding to \textit{edges} in $P_0$).

Intuitively, $P_0$ is satisfied by $P_1$ under an assignment if every node in $P_0$ has a corresponding target node in $P_1$, and every edge in $P_0$ has a path in $P_1$ connecting the assigned targets of its endpoints within the same SN. This ensures that all entities and relations in $P_0$ are present in $P_1$, even if mediated by additional entities not in $P_0$ (as paths, not direct edges, are required).



% We can now redefine our goal of "finding the intersection" of two SPNs $P_0$ and $P_1$ as "modifying (refining) $P_0$ minimally so that it becomes satisfied by $P_1$." This can be realized by a process that we call \textit{network refinement with rerelation} between a \textit{source} SPN $P_0$ and a \textit{refiner} SPN $P_1$. This process is formally described in Algorithm \ref{alg:netref}, and is founded on two subprocesses:

We can now redefine "finding the intersection" of two SPNs $P_0$ and $P_1$ as "minimally refining $P_0$ to be satisfied by $P_1$." This is achieved through \textit{network refinement with rerelation}, where $P_0$ (source) is refined by $P_1$ (refiner). The process, detailed in Algorithm \ref{alg:netref}, relies on two subprocesses:

\begin{algorithm}[tb]
\caption{Network refinement with rerelation.}

\label{alg:netref}
\textbf{Function-}\textit{RefineBy}($P_0$, $P_1$, f)

\textbf{Parameters:} $P_0$, source SPN. $P_1$, refiner SPN. $f$, a partial assignment between nodes in $P_0$ to nodes in $P_1$.

\begin{algorithmic}[1] %[1] enables line numbers
    \FOR{$SN^0_i \in P_0$}
        \FOR{$n \in nodes(SN^0_i)$}                    
            \IF{$f(n)$ not defined}
                \FOR{$(n_0, n_1) \in edges(SN^0_i, n)$}
                    \STATE RemoveWithRerelation($SN^0_i, n_0, n_1)$
                \ENDFOR
                \STATE $SN^0_i$.RemoveNode($n$)
            \ENDIF
        \ENDFOR
        
        \FOR{$(n_0, n_1) \in edges(SN^0_i)$}
            \IF{$path(f(n_0), f(n_1))$ not in $SN^1_i$}
                \STATE RemoveWithRerelation($SN^0_i, n_0, n_1)$
            \ENDIF
        \ENDFOR
    \ENDFOR

    
\end{algorithmic}

\textbf{Function-}\textit{RemoveWithRerelation}($SN$, $n_0$, $n_1$)

\begin{algorithmic}[1] %[1] enables line numbers
    \FOR{$(p,s)\ \in\ prod(P_{SN}(n_0),\  S_{SN}(n_1))$}
        \STATE $SN$.AddEdge($p$, $s$)
    \ENDFOR
    \STATE $SN$.RemoveEdge($n_0$, $n_1$)
\end{algorithmic}

\end{algorithm}


\begin{itemize}
    \item \textit{Refinement:} Nodes in $P_0$ that are missing in $P_1$, and edges in SNs of $P_0$ that don't have a path between their endpoints in the corresponding SN of $P_1$, are removed.
    \item \textit{Rerelation:} When an edge $(n_0, n_1)$ is removed (including via node removal), a new edge $(p_i, s_i)$ is created for $\forall p_i \in P(n_0), s_i \in S(n_1)$, where $P(n)$ and $S(n)$ are predecessors and successors of node $n$ respectively. (Each edge formed by rerelation is checked for the same conditions of presence as existing ones.)
\end{itemize}

Figure \ref{fig:netref} illustrates this process: the source SPN in \ref{fig:netref_source} is refined by the refiner in \ref{fig:netref_refiner}, resulting in the refined SPN in \ref{fig:netref_final}. Paths like $(A,D)$ or $(A,C)$ are preserved despite differing intermediaries. Applying this process sequentially to a source SPN across multiple refiners results in a final SPN representing commonalities across all refiners, ensuring it is satisfied by each refiner retrospectively.\footnote{The local continual learning guarantee in \textit{Modelleyen} (Theorem 1 in \cite{Erden2024Modelleyen, erden2025agential}) also applies to Algorithm \ref{alg:netref}, as nodes and paths in an SPN are analogous to state variables in the base version. Thus, the theorem's proof holds for node and path removal, with edge refinement being more constrained than path refinement.}

% An illustration of this process is provided on Figure \ref{fig:netref}. In the figure, the source SPN in \ref{fig:netref_source} is refined by the refiner SPN in \ref{fig:netref_refiner}, resulting in the refined version in \ref{fig:netref_final}. The paths that are present (like $(A,D)$ or $(A,C)$) in both networks are preserved, despite their intermediaries are not shared ($B$ and $K$, respectively). The sequential application of this process to an original source SPN over multiple refiner SPNs will result in the final state of the source SPN to represent the commonalities across all the refiners observed up to that point; and hence, by construction, the refined source will be satisfied by every refiner SPN it was refined by up to that point.\footnote{The local continual learning guarantee in Modelleyen (preservation of past activity states of a CSV, Theorem 1 in \cite{Erden2024Modelleyen, erden2025agential}) holds with Algorithm \ref{alg:netref} as well, since we can consider each node and path that is present and can be refined in an SPN as analogous to an individual source state variable in the base version of Modelleyen, and hence proof of the theorem in \cite{erden2025agential} holds with respect to the removal of nodes and paths as well (and refinement of edges is more constrained than refinement of paths).}

\begin{figure*}
     \centering
     \begin{subfigure}{0.25\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/netref_source_v2.png}
         \caption{Source SN.}
         \label{fig:netref_source}
     \end{subfigure}
     \hspace{1cm}
     \begin{subfigure}{0.25\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/netref_refiner_v2.png}
         \caption{Refiner SN.}
         \label{fig:netref_refiner}
     \end{subfigure}
     \hspace{1cm}
     \begin{subfigure}{0.25\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/netref_final_v2.png}
         \caption{Source SN after refinement.}
         \label{fig:netref_final}
     \end{subfigure}
    %\caption{Illustration of network refinement with rerelation. Highlighted edges in (c) represent edges that have been created by rerelation. Paths $(A,D)$ and $(A,C)$ are present in both networks, but are mediated by different intermediaries ($B$ and $K$ respectively), hence their intermediaries are refined and these paths are represented as new edges which were not present in the original version. Similarly for path $(Z,C)$, which is mediated by path $(Z,Y,X,C)$ in source and $(Z,L,C)$ in refiner. In contrast, edge $(A,Z)$ is not present in refiner SPN (no path from $A$ to $Z$), therefore it is removed without any relation. Edge $(A,B)$ is preserved as it is since it is present in both networks, despite the successors of $B$ differing. (Positioning of nodes are for illustration only and is irrelevant for the refinement operation.)}
    \caption{Illustration of network refinement with rerelation. In (c), highlighted edges are created through rerelation. Paths $(A,D)$ and $(A,C)$ exist in both networks but are mediated by different intermediaries (B and K respectively), leading to refined intermediaries and new edges. Similarly, path $(Z,C)$, mediated by $(Y,X)$ in the source and $(L)$ in the refiner, is refined. Edge $(A,Z)$ is removed as it lacks a corresponding path in the refiner SPN. Edge $(A,B)$ is preserved unchanged, as it appears in both networks, despite differing successors of B. (Node positions are illustrative and irrelevant to refinement.)}
    \label{fig:netref}
\end{figure*}

\textit{\textbf{Statistical Refinement}} Given the noisy experimental domain, we enhanced Algorithm \ref{alg:netref} by incorporating node/edge observation statistics. Instead of removing a node/edge upon its first absence, we remove it only if the ratio of its absences exceeds a threshold $T_{ref} \in (0,1)$. This prevents losing important features potentially missed due to noise or misassignment (see below). Being a more constrained removal condition, this maintains \textit{Modelleyen}'s continual learning guarantees.

% \paragraph{Statistical refinement} In light of the noisy nature of our experimental domain, we found that augmenting the process in Algorithm \ref{alg:netref} with the consideration of statistics of observation of nodes and edges was beneficial to learning. In particular, instead of removing a node/edge at the first observation of its absence, in our experiments we opted to remove them only if the ratio of observations they have been absent up to that point exceeds a threshold $T_{ref} \in (0,1)$. This prevents us from losing important features that may not be present in a few observed instances due to noise rather than not being important, or may not be detected due to being misassigned (see below). Making node/edge removal conditions more constrained, this does not negatively effect the continual learning guarantees of Modelleyen.

\textit{\textbf{Assignments}} A key issue in extending the base Modelleyen framework to network refinement is finding a suitable (possibly partial) node mapping $f: V(P_0) \nrightarrow V(P_1)$) between two SPNs. The only constraint is that source nodes can only map to nodes of the same type (i.e., representing the same feature). However, multiple valid mappings may exist, resulting in different post-refinement structures (see Figure \ref{fig:assignment}). To address this, we used the following approach: We create a population of alternative assignments by pairing nodes from the source and refiner SPNs based on shared node types. While this works well with a small number of nodes per type, our feature representation (Section \ref{sec:feature_representation}) often requires additional prioritization. To address this, we rank node pairs by their positional proximity in both SPNs, using the negative softmax of the distance between candidate pairs to probabilistically select the most suitable assignments. After generating the population, we calculate a \textit{mismatch score} for each assignment, representing the total number of nodes and paths in the source SPN missing from the refiner SPN. The assignment with the lowest mismatch score—requiring the least refinement—is selected.

% \paragraph{Assignments} A problem that emerges with this extension of base Modelleyen framework to network refinement is, of course, the problem of finding a proper assignment (node mapping, possibly partial) $f: V(P_0) \nrightarrow V(P_1)$ between the nodes of two SPNs. The natural constraint for such as assignment would be for each source node to be mapped only to nodes that share the same node type with them (i.e. represent the same feature). However even then, multiple such assignments can be present, leading to different post-refinement structures (see Figure \ref{fig:assignment} for an illustration). We follow a two-step approach to handle the task of generating good assignments:

%\begin{enumerate}
    % \item We generate a population of alternative assignments, with sources and targets chosen from suitable pairs in source and refiner SPNs based on shared node types. This can be sufficient in itself when there is a small number of nodes per each type, yet this is not always the case with our feature representation (Section \ref{sec:feature_representation}). Therefore, we prioritize the possible node pairs by their positional proximity in the source SPN (over the average position of all its observations until now) and in the target SPN, choosing the pairs with probability proportional to the negative softmax of the distance between a candidate assignment pair.
%    \item We create a population of alternative assignments by pairing nodes from the source and refiner SPNs based on shared node types. While this works well with a small number of nodes per type, our feature representation (Section \ref{sec:feature_representation}) often requires additional prioritization. To address this, we rank node pairs by their positional proximity in both SPNs, using the negative softmax of the distance between candidate pairs to probabilistically select the most suitable assignments.
    % \item Once such a population is generated, we compute a \textit{mismatch score} for that assignment between the two SPNs, being the total number of nodes and paths that are present in the source SPN but not in refiner SPN. We choose the assignment with the lowest mismatch score (hence, least amount of refinement that'll be made) from the population.
  %  \item After generating the population, we calculate a \textit{mismatch score} for each assignment, representing the total number of nodes and paths in the source SPN missing from the refiner SPN. The assignment with the lowest mismatch score—requiring the least refinement—is selected.
%\end{enumerate}

% We observed that this mechanism of making assignments yielded good mappings in our experiments (see Section \ref{sec:results}). However, it should also be noted that it is not infallible, and furthermore choosing the proper assignment across a population is the most computationally expensive part in our workflow. It is very likely that better solutions to this problem of finding proper assignment, or even ways to avoid needing such assignments in the first place, can be found with further inquiry into this area.

In our experiments, this assignment mechanism produced effective mappings (see Section \ref{sec:results}). However, it is not flawless, and selecting the optimal assignment from the population remains the most computationally intensive step in our workflow. Further research could likely improve this process or even eliminate the need for such assignments altogether.

\begin{figure}
     \centering
     \begin{subfigure}{0.2\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/assignment_source_v2.png}
         \caption{Source SN.}
         \label{fig:assignment_source}
     \end{subfigure}
     \hspace{1cm}
     \begin{subfigure}{0.2\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/assignment_refiner_v2.png}
         \caption{Refiner SN.}
         \label{fig:assignment_refiner}
     \end{subfigure}
     \vfill
     \begin{subfigure}{0.2\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/assignment_final_0_v2.png}
         \caption{Refinement result with $A$ assigned to $A0$.}
         \label{fig:assignment_final_0}
     \end{subfigure}
     \hspace{1cm}
      \begin{subfigure}{0.2\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/assignment_final_1_v2.png}
         \caption{Refinement result with $A$ assigned to $A1$.}
         \label{fig:assignment_final_1}
     \end{subfigure}
    \caption{A node ($A$) of a given type (red) in the refiner SPN can map to multiple nodes in the source network ($A0$ or $A1$), resulting in two post-refinement networks with no clear superior assignment.}
    \label{fig:assignment}
\end{figure}



\subsubsection{Learning flow}
\label{sec:learning_flow}


% As in \cite{Erden2024Modelleyen}, \textit{model} in our system design is formed of \textit{conditioning state variables (CSVs)}, which represent the relationship between their \textit{sources} and their \textit{targets}. In our design, the sources of a CSV is a state polynetwork (SPN) as defined above; and as in REF, a CSV can have as a target either other CSVs, or some designated target state variables. The learning flow remains mostly the same as it was used in Modelleyen in  (as before, space limitations prevent us from having a detailed description here, the reader is referred to \cite{erden2025agential} and Algorithms \ref{alg:algorithm_adaptationloop} \& \ref{alg:algorithm_csvstate} repeated from the paper in the Appendix for details), with only the following exceptions:

As in \cite{Erden2024Modelleyen}, our system design defines a \textit{model} using \textit{conditioning state variables (CSVs)}, which describe relationships between their \textit{sources} (state polynetworks, or SPNs) and \textit{targets} (other CSVs or specific target state variables). The learning flow largely follows Modelleyen's approach (see \cite{erden2025agential} and Algorithms \ref{alg:algorithm_adaptationloop} \& \ref{alg:algorithm_csvstate} in the Appendix for details), except for the following adjustments:


\begin{enumerate}
    
    % \item In \cite{Erden2024Modelleyen, erden2025agential}, upstream CSVs were constructed in a way that they do not share sources with the lower level CSVs that they condition, but rather integrate with what is effectively an \textit{and} condition. In our implementation, however, we make it so that upstream CSVs encompass their targets, being an observed \textit{subvariant} of their targets rather than separate entities. Assignments from lower-order CSVs are propagated to their upstream conditioners, hence no assignment needs to be done twice. This was done mainly to keep the learning flow and implementation simple at this stage of our work, as an \textit{and} integration of two distinct networks would require an additional definition of the connecting subnetwork in between them.

    \item Unlike \cite{Erden2024Modelleyen, erden2025agential}, where upstream CSVs integrate with lower-level CSVs via an \textit{and} condition, our implementation treats upstream CSVs as observed \textit{subvariants} of their CSV targets, with source SPNs encompassing the source SPNs of them. This allows assignments from lower-order CSVs to propagate upstream, eliminating redundant assignments and simplifying the learning flow by avoiding the need for additional subnetwork definitions.



    % \item Contrary to \cite{erden2025agential} where a common CSV is created for all targets in a given step with differentiation later if needed, we always assume a single target per CSV and consequently, create a separate CSV (with identical sources) for each target in a given step. This is a result of our previous change, made in order to make the aforementioned upstream assignment propagation possible. 

    \item Unlike \cite{erden2025agential}, which creates a common CSV for all targets in a step, we assume a single target per CSV and create separate CSVs (with identical sources) for each target. This change supports the upstream assignment propagation in previous point.


    % \item Instead of representing negative (suppressing) sources as a separate source entity within a given CSV, we externalize them into their separate CSVs. More precisely, just as a positively-conditioning (i.e. regular) CSV explains and predicts the possibility of the activity of its targets when its sources are satisfied (REF) and is formed when a state variable with an active state and no active conditioner is observed, a negatively-conditioning CSV is formed when a state variable with an inactive state and no active negative conditioner is observed. We accordingly redefine the \textit{unconditionality} flag in REF to go inactive in the first observation of an inactive state of the CSV, opening a CSV for positive and negative upstream conditioning at the same time.

    \item Instead of embedding negative (suppressing) sources within a CSV, we externalize them into separate CSVs. A negatively-conditioning CSV is formed when a state variable with an inactive state and no active negative conditioner is observed (with potentially multiple formed per target). We also redefine the \textit{unconditionality} flag to deactivate upon the first observation of an inactive state, allowing simultaneous positive and negative upstream conditioning.

    % \item Finally, instead of the more elaborate $NCC$ metric used in \cite{erden2025agential} to filter statistically insignificant conditioners of a state variable, we simply remove a conditioner $C$ of a target $T$ if $P(SS(C)|I(T)) < T_{sign}$, where $SS(C)$ and $I(T)$ are the events of sources of $C$ being satisfied and observation of the corresponding state of $T$, respectively.

    \item Instead of the complex $NCC$ metric in \cite{erden2025agential}, we filter insignificant conditioners by removing a conditioner $C$ of target $T$ if $P(SS(C)|I(T)) < T_{sign}$, where $SS(C)$ and $I(T)$ represent the satisfaction of $C$'s sources and the observation of $T$'s state, respectively.

    
\end{enumerate}

The major changes, outlined in points 1 and 2, primarily affect CSV composition without altering the core learning flow or CSV state definitions. These changes were made for implementation simplicity and will be modified in future framework developments to include multiple targets and distinct upstream networks, improving representational efficiency (see Section \ref{sec:results}).

Currently, the operational flow is computationally intensive, limiting simulations to shorter durations. At this stage, our focus is on designing and validating the learning flow rather than optimizing the algorithm or capping model complexity, though these aspects are briefly discussed in Section \ref{sec:conclusion}.

% The major changes are points 1 and 2 above, affecting the composition of a CSV. These don't affect the core learning flow and definition of CSV states and formation conditions. They are both for simplicity of implementation at this point, and will be modified with multiple targets and distinct upstream networks in future developments of the framework, which is expected to result in a better representational efficiency (see Section \ref{sec:results} below).

% We note that the operational flow in current version is computationally demanding, which allowed us to simulate learning only for a limited duration as discussed in Section \ref{sec:results}. The reader should keep in mind that at the current stage of the framework, we focus on designing a proper learning flow and validating it primarily, hence have not focused on the optimization of the algorithm or mechanisms to cap model complexity increase. Some of these aspects are discussed on Section \ref{sec:conclusion}.

% \paragraph{Prediction} When performing prediction of targets for a given observed SPN, we follow the following procedure: First, we attempt to find an assignment (using the same approach of generating a population with node mapping prioritization outlined above) that satisfies the source SPN of a given CSV. If there is no such assignment, we regard the CSV as inactive. If there is such an assignment, we compute the probability of activation of the CSV as follows: If the CSV has no positive/negative conditioners (is unconditional), then the activity probability is $p=P(I(T)|SS(C))$, as tracked over the course of learning progression. If the CSV has conditioners (is conditional), then the probability of activity is $p= (1-p^{max}_-) * p^{max}_+$ where $p^{max}_-$ and $p^{max}_+$ are the maximum among the activation probabilities of positive and negative conditioners, respectively. Intuitively speaking, this corresponds to prioritizing the most-upstream (hence most precisely matching with current observed SPN) representations that are activated when deciding on a final estimated probability of seeing activity, and with possible conflicts between simultaneously active suppressing and activating pathways resolved by multiplication of probabilities coming from the two paths.












\subsection{Feature representation for basic shape learning}
\label{sec:feature_representation}

% The process described until now is universal with respect to any observation space that can be represented as one or multiple networks. In our experiments in this paper, we wanted to demonstrate the operation of this method on a basic domain in visual processing. More specifically, we chose 2D shape identification on binary images (with MNIST as our test domain) as both the most basic visual processing task and also as a domain that is well recognized that served as the starting point of other computer vision approaches, including neural networks \cite{lecun1998gradient, cortes1995support}. Here, we describe the feature representation (converting images to networks) we use for this domain. We note that this is only demonstrative for the use of our approach in a simple context, and possible extensions to other types including other 2D features like color gradients etc., or features in a 3D space with 3D positions, can be used in future work as the domain shows the need for it.

\textit{Modelleyen with network refinement} (MNR) is applicable to any observation space representable as networks. For our experiments, we focus on demonstrating the method in a basic visual processing domain: 2D shape identification in binary images, using MNIST as the test domain. This task is foundational in computer vision and has historically served as a starting point for approaches like neural networks \cite{lecun1998gradient, cortes1995support}. Below, we detail the feature representation (image-to-network conversion) used. We note that this is only demonstrative for the use of our approach in a simple context, but future work can extend it to other types, including 2D features like color gradients or 3D features with spatial positions, as the domain requires.


% We wanted our features to be as general as possible for shape detection, in order to avoid the trap of falling into totally hand-crafted features. For that, we opted to use \textit{horizontal (x) and vertical (y) gradient orientation change points}. Our processing flow for an image is as follows: First, a given grayscale image is converted to binary with a threshold of 50\%, and then the contours of the binary image is approximated as a polygon using the OpenCV implementation of Ramer–Douglas–Peucker algorithm \cite{opencv_shape_analysis}, leaving us with corners in the image and oriented edges (CW for outer contours, CCW for inner contours) connecting those corners (Figure \ref{fig:representation_example_bcn}). Following that, we compute the sign of the gradients of each corner in x and y dimensions based on the orientation of the edge (for example, an edge facing rightwards in the image has negative gradient in x-axis).

To ensure generality in shape detection and avoid overly hand-crafted features, we use \textit{horizontal (x) and vertical (y) gradient orientation change points}. Our image processing flow involves: (1) converting a grayscale image to binary with a 50\% threshold, (2) approximating contours as polygons using OpenCV's Ramer–Douglas–Peucker algorithm \cite{opencv_shape_analysis}, yielding corners and oriented edges (CW for outer, CCW for inner contours) (Figure \ref{fig:representation_example_bcn}), and (3) computing the sign of gradients at each corner in the x and y dimensions based on edge orientation (e.g., a rightward-facing edge has a negative x-axis gradient).

%We construct our final SPN from the corners that correspond to change in gradient orientations in x or y axes. To that end, we traverse corners in a detected contour in the direction of their connection (CW or CCW). If the direction of gradient (positive or negative) in either of the x or y axes change from the predecessor-edge of a corner to its successor edge, then we create a node for this corner in our SPN (to be shared by all its networks), with the type defined by the combination of the observed change axis and direction, and the convexity of a corner. For example, the corner at the top-right of Figure \ref{fig:representation_example_bcn} represents a convex corner that displays a change from a y-gradient from positive (upwards-oriented edge) to negative (downwards-oriented edge), hence it corresponds to a node of type \textit{"convex, +y to -y"} in the final SPN (node \textit{cx\_ypos\_yneg\_0} in Fig. \ref{fig:representation_example_vn}.) This gives us the nodes of our SPN.

We build the final SPN using corners where gradient orientations change in the x or y axes. Traversing the contour in its connected direction (CW or CCW), we create a node for each corner if the gradient direction (positive or negative) changes in either axis from the predecessor to the successor edge. The node type is defined by the change axis, direction, and corner convexity. For example, the top-right corner in Figure \ref{fig:representation_example_bcn} represents a convex corner with a y-gradient change from positive to negative, resulting in a node of type \textit{"convex, +y to -y"} (node \textit{cx\_ypos\_yneg\_0} in Fig. \ref{fig:representation_example_vn}). This process defines the SPN's nodes.

% We define four types of SNs for our SPN, namely  \textit{contour}, \textit{inner}, \textit{outer}, and \textit{all.} Edges in \textit{contour} SNs are the contour connections that are present along the nodes as described in the previous paragraph, the only change being that if a corner is not used in the final SPN representation as a node (due to not representing any change in gradient orientations), its predecessor and successor are also connected with a contour edge. Edges in \textit{inner} and \textit{outer} SNs represent nodes that can be connected with a straight line in the original image without leaving inner (pixel value 1) and outer (pixel value 0) regions of the original binary image, respectively. \textit{All}-type SNs are just SNs that represent all connections in inner, outer, and contour networks, agnostic to their type - this is used to persistent represent relative positional relations between instances even in cases where what lies between them in actual images can vary.\footnote{It is in principle possible to represent the whole image with only all-type networks, however the specific representation of inner, outer, and contour networks not only potentially helps in distinguishability (by representing the specific connection types of features if they are reliably observed), but also in human comprehensibility of the learned models.} Each type of network comes with two variants, \textit{horizontal} and \textit{vertical}, in which a directed edge in one of these networks represents that the source of the edge being of positionally lower index than the target of the edge in the corresponding axis. For example, the presence of a directed edge $(n_0, n_1)$ in the network \textit{contour-horizontal} would mean that nodes $n_0$ and $n_1$ are connected by a contour edge, and that $n_0$ is towards the left of $n_1$. See Fig. \ref{fig:representation_example_vn} for an example SPN constructed in this manner.


Our SPN includes four types of SNs: \textit{contour}, \textit{inner}, \textit{outer}, and \textit{all}. \textit{Contour} SNs represent connections along the contour, linking nodes as described earlier, with edges added between predecessors and successors of skipped corners. \textit{Inner} and \textit{outer} SNs connect nodes with straight lines that stay within the inner (pixel value 1) or outer (value 0) regions of the binary image. \textit{All}-type SNs combine all connections, regardless of type, to persistently represent relative positional relationships even when their actual types can vary across images. Each network type has \textit{horizontal} and \textit{vertical} variants, where directed edges indicate positional relationships along the respective axis. For example, a directed edge $(n_0, n_1)$ in \textit{contour-horizontal} means $n_0$ is to the left of $n_1$. See Fig. \ref{fig:representation_example_vn} for an example SPN.


\begin{figure}
     \centering
     \begin{subfigure}[t]{0.2\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/representation_example_im.png}
         \caption{Original image.}
         \label{fig:representation_example_im}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.2\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/representation_example_bcn.png}
         \caption{Approximated contours and corners.}
         \label{fig:representation_example_bcn}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/representation_example_vn.png}
         \caption{Final SPN, all networks drawn together.}
         \label{fig:representation_example_vn}
     \end{subfigure}
     \caption{Example SPN construction from an image for 2D shape identification. In (c), blue, green, and black edges denote inner, outer, and contour connections, respectively. Nodes, colored by type, represent gradient change points (e.g., "cc\_xneg\_xpos\_1" indicates a concave corner with x-gradient shifting from (-) to (+)).}
    \label{fig:feature_representation}
\end{figure}

% This means of representation is generally applicable and domain-agnostic in the context of 2D shape detection, reliant only on the contours that correspond to image gradients in certain directions. However we note that it is primarily for demonstrative purpose of the operation of the design we propose, and has known limitations; including a limited expressivity, as the details of the full shape can be not represented (e.g. only three of the five corners at the bottom of the shape in Fig. \ref{fig:representation_example_bcn} are used as features in \ref{fig:representation_example_vn}). This limited expressivity is the reason behind the identification accuracy falling short of perfect detection as discussed in Section \ref{sec:results}. A more complete form would consider not only gradient sign swaps, but all changes in the orientation of the gradient, making representation more complex but more complete. Likewise, it is suitable only for shape detection on binary images only at the moment, though possible extensions to other types including other 2D features like color gradients etc. or features in a 3D space with 3D positions are possible with the similar underlying logic augmented with the needed extensions. Finally, there is always the possibility that for the context of learning with a varsel mechanism, shape detection is not best done by the logic of this representation (directly-observed change points of the contour), but with alternative type of representation altogether, be it pixel-level processing as in fully-connected NNs, fixed-size filters as in CNNs, or more advanced ones like frequency-based transformations. Some of these alternatives are discussed in the Conclusion.

\textit{Limitations and possible extensions:} This representation is broadly applicable and domain-agnostic for 2D shape detection, relying on contours matching image gradients. However, it’s mainly for demonstrating our design and has limitations, such as limited expressivity from not capturing all details of the shape but only those that represent gradient sign changes (e.g., only three of five corners are used in Fig. \ref{fig:representation_example_vn}). This affects final identification accuracy, making it fall short from a perfect performance as discussed in Section \ref{sec:results}. A more complete approach would consider all gradient orientation changes, increasing complexity but also completeness. Likewise, it currently works for shape detection, but could be extended to other 2D features or 3D spaces with similar logic. Additionally, for learning with a varsel mechanism, shape detection might benefit from alternative representations like pixel-level processing, CNN filters, or frequency-based transformations, as discussed in the Conclusion. Finally, we note that multiple feature types can be used with SPN representation, either in separate networks or within the same network, capturing positional relations between features across domains. While we don't explore this here, it’s an interesting direction for future work.







\begin{figure*}
     \centering
     \begin{subfigure}{0.75\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/my_3c_avg.png}
         \caption{MNR, $N_C=3$.}
         \label{fig:results_cl_my}
     \end{subfigure}
     \begin{subfigure}{0.75\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/nn_3c_avg.png}
         \caption{Fully connected neural network,$N_C=3$.}
         \label{fig:results_cl_nn}
     \end{subfigure}
     \begin{subfigure}{0.75\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/cnn_3c_avg.png}
         \caption{Convolutional neural network, $N_C=3$.}
         \label{fig:results_cl_cnn}
     \end{subfigure}
     \begin{subfigure}{0.75\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/my_5c_avg.png}
         \caption{MNR, $N_C=5$.}
         \label{fig:results_cl_my_5c}
     \end{subfigure}
     \begin{subfigure}{0.75\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/my_10c_avg.png}
         \caption{MNR, $N_C=10$.}
         \label{fig:results_cl_my_10c}
     \end{subfigure}
    \caption{Learning performance of MNR, fully connected, and convolutional neural networks on $N_C$-class incremental learning over 10 cycles. Accuracies reflect correct classification ratios for each class. Shaded areas denote cycles, and vertical lines separate iterations within cycles. Results are averaged over 10 (a-c) and 5 (d-e) runs. Note that class indices $i$ are randomly chosen at the start of each run and do \textit{not} necessarily correspond to digit $i$.}
    \label{fig:results_cl}
\end{figure*}


\section{Experimental setup}
\label{sec:experiment_setup}

We experiment on MNIST dataset, with the aim to (1) show continual learning performance of MNR, and contrast it with the learning progression of neural networks, and (2) investigate learned representations of classes by MNR for proper structure and comprehensibility.

% Our learning flow for MNR is as follows: At the start of each trial, we choose $N_C$ classes randomly and independently, from the 10 total classes available. During one \textit{cycle} of learning, we expose the system to $N_{samples}$ samples from each of the $N_C$ classes sequentially (single exposure followed by a single learning step, no reexposure since repeated learning steps with the same instance have further no effect on the model in MNR). Exposure to the samples from one of the $N_C$ classes is defined as one \textit{iteration} in the cycle. In other words, iteration $i$ in a cycle processes chosen class index $i$ (which is not necessarily equal to digit $i$). The training flow is the same for neural networks as well: The network is trained on a single chosen sample at a step, until convergence or reaching maximum number of epochs. To evaluate performance, we compute the per-class accuracy at the end of learning each iteration (class) in a cycle (hence $N_C$ evaluations per cycle). We train the systems with 10 such cycles, simulating a general and realistic continual flow on information with the requirement of ongoing learning without any constraining assumptions. The examples we use to demonstrate the comprehensibility of learned models are also taken from the same runs in our continual learning experiments.

Our MNR learning process involves randomly selecting $N_C$ classes from the 10 available at the start of each trial. In one \textit{cycle}, the system is exposed to $N_{sample}$ samples from each class sequentially, with one exposure and learning step per sample (no reexposure, as repeated steps have no effect in MNR). Processing samples from one class constitutes an \textit{iteration}. Neural networks follow the same flow, trained on one sample per step until convergence or max epochs. Performance is evaluated via per-class accuracy after each iteration ($N_C$ evaluations per cycle). We train for 10 such cycles, simulating a general and realistic continual flow on information with the requirement of ongoing learning without any constraining assumptions. Examples for model comprehensibility demonstrations are drawn from these experiments. We run our experiments on MNR with $N_C=3,\ 5$ and $10$, and with $N_C=3$ on NNs for comparison of behavior. Reported results are averages of 10 and 5 runs for $N_C=3$ and $5$ respectively.  Further details, including choice of parameters and computation of predictions in MNR, can be found on Appendix \ref{sec:exp_details}.


We do not provide a experimental comparison with existing continual learning methods since, as discussed in Section \ref{sec:related_work}, every proposed method we are aware of operates with significant constraining assumptions, notably either replay buffers or clear task boundaries, which MNR does not have and was designed specifically to not have. It is known that existing methods can show near-perfect retention of information using while operating under these limiting assumptions \cite{erden2024directed}, hence any partial comparison such as taking them as an upper baseline wouldn't be informative.







\section{Results and discussion}
\label{sec:results}



\subsection{Continual learning}

Figure \ref{fig:results_cl} shows learning progression of MNR for $N_C=3$, $4$, and $5$ classes; as well as that of the neural network variants for $N_C=3$ for comparison.



MNR's final performance, as expected, does not achieve perfect identification, with accuracies of ~85\%, 60\% and 50\% for $N_C=3, 5$ and $10$ respectively after 10 cycles. This stems primarily from limitations of feature representation (Section \ref{sec:feature_representation}) and while it suggests the need for improvement with better representations (see Conclusions), it is not our main focus here. To validate continual learning of our design, we focus on MNR's high retention of learned information, as shown in Figures \ref{fig:results_cl_my}, \ref{fig:results_cl_my_5c}, and \ref{fig:results_cl_my_10c}. Performance on class $i$ remains stable in later iterations ($j>i$) of the same cycle, with early accuracy persisting throughout. This contrasts sharply with neural networks: a fully connected NN (Fig. \ref{fig:results_cl_nn}) loses all information on class $j>i$ in early cycles, and even after 10 cycles, it fails to retain a stable representation, showing $>50\%$ accuracy loss. A convolutional NN performs worse, losing all information repeatedly. Continual learning is most critical in early cycles (first 3-4), as in the long run, with increasing number of cycles, the problem is equivalent to stochastic gradient descent with a slow timescale, reducing the problem to statistical learning with data abundance where NNs already excel. MNR's retention of performance is consistent across tests with 5 and 10 classes as well, albeit with lower baseline accuracies.


% We first note that the final learning performance of MNR expectedly falls short of perfect identification, with absolute accuracies at the end of 10 cycles reaching around 85\% with $N_C=3$, 60\% with $N_C=5$ and 50\% with $N_C=10$. This is due to limitations in the expressivity of the representation as discussed on Section \ref{sec:feature_representation}. The net performance not main focus here and will be improved with better representation. For validation of the continual learning property, we primarily focus on retention of what has been learned with MNR, which is considerably high in Figures \ref{fig:results_cl_my}, \ref{fig:results_cl_my_5c} and \ref{fig:results_cl_my_10c}, where it is seen that the performance obtained on class index $i$ in the $i^{th}$ iteration of a given cycle remains at high values with new classes coming at iterations $j>i$ of the same cycle, and the range of accuracy obtained early on persists throughout. This is in stark contrast to the learning behavior neural networks, for example. On Fig. \ref{fig:results_cl_nn}, a fully connected NN is seen to destroy all the information regarding class index $i$ (apparent from accuracies of previously-learned classes abruptly decaying from 1 to 0 at the next iteraton in the cycle) at iterations $j>i$ for earlier cycles, and even after 10 cycles of repeated exposure, the network cannot find a fully encompassing representation, continuing the sequences of losign-and-relearning to a significant degree (corresponding to $>50\%$ accuracy loss). A convolutional network doesn't even have this trend of partial improvement, keeping losing all information at each cycle until the end of its training duration. We note that our focus in context of continual learning is necessarily on earlier cycles in training, most importantly the first 3-4 cycles -- in the long run, with increasing number of cycles, the problem becomes equivalent to a stochastic gradient descent with only a slower timescale of convergence, hence once again becoming effectively a statistical learning problem (in which neural networks excel and continual learning issue is no longer valid). The same observation of retention of performance with MNR is valid for tests with 5 and 10 classes as well, with only the baseline net accuracy obtained in the overall task being lower.

% We would like to note that with MNR, as it is with Modelleyen \cite{erden2025agential}, even when there is performance loss, it is, by design, not due to a loss/destruction of information (unless a conditioner falls below specified significance threshold and is removed due to insignificance) but due to either over-refinement resulting in the representation no longer distinguishing, or a negative conditioning overriding the existing structure, and can be reversed rapidly when a new instance is observed accordingly.

We note that in MNR, as in Modelleyen \cite{erden2025agential}, even when there are small performance fluctuations, it is by design not due to direct destruction of existing information (unless a conditioner is removed for cumulative insignificance) but stems from over-refinement or negative conditioning.


We briefly note the factors limiting performance compared to the perfect detection achieved by neural networks. First, the representation used lacks full expressivity, capturing only gradient change points rather than all shape features (see Section \ref{sec:feature_representation}). Second, the current statistical refinement approach retains some features not present in every sample of a class, yet SPN satisfaction (Definition 3.2) requires precise matches. This leads to missed instances, especially outliers. This is rather straightforward to offset by allowing soft satisfaction of SPNs (Definition 3.2). These limitations were not the focus of this work, which prioritized validating the learning flow with a demonstrative representation, and will be addressed in future research.

% We should also give a brief discussion of the factors and limitations that lead to the performance currently falling short of the perfect detection as obtained by neural networks. First factor is the limitations of expressivity in the representation used. As discussed in Section \ref{sec:feature_representation}, the currently used representation is not completely expressive in that it does not represent every shape feature, but only gradient change points. A second factor is related to the fact that while in the current implementation the refinement is done statistically, satisfaction of SPNs (Definition 3.2) requires precise match. This allows the retention of a degree of features that are not necessarily observed in every sample in a given class, inevitably losing some instances, in particular those that are "outliers" in the parts that are not fully reliably observed but are protected by statistical refinement. This is rather straightforward to offset with allowing soft satisfactions as well. These aspects have not been in our focus in the current version of the work, where priority was on validation of the learning flow with a demonstrative feature representation, and will be addressed in future work.



\subsection{Comprehensibility of learned representations}

% Figure \ref{fig:results_spns} shows the learned source SPNs corresponding to some example digits from our experiments, at low depths (closer to the target variable, corresponding to more general representations) to those in higher depths (further away in the conditioning chain, hence more specific representations corresponding to more sparsely observed subvariants. The representations are very comprehensible to human eye, clearly representing the corresponding digits, their features and relations between them. For example, most contours of digit 2 are preserved in Figure \ref{fig:results_spns_2_ds}, and while there are considerable samples with a "hole" in the turning point on the lower left of the digit (like the example in Fig. \ref{fig:feature_representation}), the features corresponding to these holes are not represented (refined) while the part that is persistent in this turning point (namely the gradient change in vertical axis, represented by feature \textit{cx\_yneg\_ypos\_1} in \ref{fig:results_spns_2_ds}) is present. Similarly, although not as many contours are preserved in the representation of digit 5 in Fig. \ref{fig:results_spns_5_ds}, nonetheless the major features (two vertical gradient sign changes on right side, the horizontal gradient sign changes at top and bottom) are preserved together with the correct relative positional relations between them. Furthermore, while contour relations have been refined at the general representation at depth 0 in \ref{fig:results_spns_5_ds}, they are preserved at the more specific subvariants upstream, like in Fig. \ref{fig:results_spns_5_us9} which provide more details.


Figure \ref{fig:results_spns} illustrates samples of the learned SPNs, ranging from general representations at lower depths (near the target variable) to more specific ones at higher depths capturing rarer subvariants. These representations are visually intuitive, effectively depicting the digits, their features, and interrelations. For instance, most contours of digit "2" are preserved in Fig. \ref{fig:results_spns_2_ds}, though features like holes at the lower-left turning point (common in some samples like that in Fig. \ref{fig:feature_representation}) are omitted, while persistent features, such as the vertical gradient change (\textit{"cx\_yneg\_ypos\_1"}), are retained. Similarly, digit "5" in Fig. \ref{fig:results_spns_5_ds} retains key features, including vertical gradient changes on the right and horizontal changes at the top and bottom, along with correct positional relations. While general contours of "5" are refined at depth 0, they are preserved at the more specific subvariants upstream, like in Fig. \ref{fig:results_spns_5_us9} which provide more details. Some additional examples are also provided in Figure \ref{fig:results_spns_appendix} in Appendix.

\begin{figure*}
     \centering
     \begin{subfigure}{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/2_ds.png}
         \caption{Digit 2, depth 0.}
         \label{fig:results_spns_2_ds}
     \end{subfigure}
      \begin{subfigure}{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/5_ds.png}
         \caption{Digit 5, depth 0.}
         \label{fig:results_spns_5_ds}
     \end{subfigure}
     \begin{subfigure}{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/5_us9.png}
         \caption{Digit 5, depth 8.}
         \label{fig:results_spns_5_us9}
     \end{subfigure}
    %\caption{Sample source SPNs learned by the system, displayed with all SNs drawn together. Blue, black and gray edges represent inner, contour and all-type connections respectively. Depths are the conditioning distance from the target variable (i.e. number of CSVs in the conditioning path between the CSV for which the given SPN is a source of, and the target variable). Positions of nodes are the average of all the positions they have been observed within the lifetime of the CSV. See Fig. \ref{fig:results_spns_appendix} in Appendix for more examples.}
    \caption{Sample source SPNs learned by the system, shown with all SNs combined. Blue, black, and gray edges represent inner, contour, and all-type connections, respectively. Depths indicate conditioning distance from the target variable (number of CSVs in the conditioning path). Node positions reflect the average of all observed positions during the CSV's lifetime. Additional examples are in Fig. \ref{fig:results_spns_appendix} in A.2.}
    \label{fig:results_spns}
\end{figure*}

\section{Conclusions, Limitations and Future Work}
\label{sec:conclusion}

% In this work, we provided an extension of prior work on structured representations for continual learning without constraining assumptions and internal comprehensibility of learned models for processing higher-dimensional observation spaces that can be represented as networks, in particular in the context of visual space. We detailed the extension we developed, provided a candidate feature representation for its application to 2D shape identification as an initial test domain, and demonstrated its operation on that task. Although a perfect performance like those obtained by NNs was not reached, mainly due to the expressive limitation of the feature representation framework we developed, the core focus of our design was validated in that (1) continual learning without any constraining assumption was achieved, without any destruction of past information (by design) or visibly large decay in performance with future learning exposures, and (2) the learned internal representations are easily comprehensible by the human eye. Our method also serves the broader vision of being the basis of the conceived future integration of the wider framework proposed in \cite{erden2025agential} to structured visual spaces, and environment dynamics modelling \& deliberative behavior with visual observation spaces.

This work extended prior research on structured representations for continual learning, focusing on higher-dimensional observation spaces that can be represented as networks, particularly in visual domains, without constraining assumptions and ensuring model comprehensibility. To that end, we introduced the mechanism of learning via network refinement with rerelation in Modelleyen learning flow, applied it to 2D shape identification with a proposed feature representation, and demonstrated its functionality. While final performance didn’t match NNs due to limitations in feature expressivity, our core design aims were validated by (1) achieving continual learning without constraining assumptions, retaining past knowledge consistently, and (2) producing representations easily comprehensible by humans. This method also lays the groundwork for the integration of a means to process structured visual spaces into the broader framework of modeling environment dynamics and deliberative behavior in \cite{erden2025agential}.


% Feature representation in the current version is primarily for demonstrative purpose, and is a preliminary and simple one based only on gradient sign changes, specifically for 2D shape detection. This type of representation, as discussed, is known to be expressively limited; albeit it can capture most of the important features each class, some such features still remain uncaptured as evident by the final performances falling short. Alternative means of feature representations that can capture all potentially relevant details that can be considered in future work would make a long way in benefiting the expressivity of the model. These may include advanced or more detailed versions of the current edge-gradient based way of representation (which is a strong candidate as in theory all the relevant information of the shape can be extracted from edge gradients), or it may be an alternative approach, such as well-established feature identification methods from CV literature (SIFT REF) or use of pretrained NNs (such as visual foundation models)  (VTF REF) for that purpose and keeping the Modelleyen learning flow for high-level operation. Another alternative would be using frequency components or arbitrary-order changes, as well-established set of methods particularly suitable for our learning flow at higher level (REF- FREQ IN VIS). Pixel-level detection is also a possibility, hence effectively making of similar base-level analysis as NNs once the scalability issues discussed below are resolved, but this might not be very helpful in comprehensibility, likely making model more complex than needed. An intermediate representation, such as using and possibly learning fixed-size filters as is done with CNNs, could also be possible. These are all avenues for future exploration, some of whom can be applicable more widely than just 2D shape identification.

The current feature representation is a simple, demonstrative approach based on gradient sign changes, specifically designed for 2D shape detection. While it captures many key features, it is expressively limited, as evidenced by the performance shortfalls. Future work should focus on enhancing this expressivity. One option is to refine the edge-gradient-based method, which theoretically contains all the necessary shape information and hence remains a strong candidate. Alternatively, well-established computer vision methods, such as SIFT \cite{lindeberg2012scale} or pretrained neural networks like visual foundation models (\cite{oquab2023dinov2}), could be used for feature representation while retaining the MNR flow for high-level learning. Another promising direction is the use of frequency components \cite{xu2020learning}, which are especially well-suited to this learning framework. Pixel-level detection, similar to NNs, could also be considered if scalability challenges are addressed, though this might unnecessarily complicate the model and reduce its interpretability. Intermediate representations, such as fixed-size filters similar to those used in CNNs, are another possibility. These approaches could improve the model's performance and extend its applicability beyond 2D shape identification.

The current implementation of our method is computationally demanding due to redundancies  in modelling included for methodological simplicity, as optimization was not our focus at this stage. Upstream CSVs are represented as larger networks encompassing their downstream targets instead of distinct, integrated subnetworks, and each CSV is restricted to a single output, preventing shared conditioning sources. These design choices, while easy to modify, inflate computational demands. Furthermore, current learning flow processes multiple intersecting upstream paths simultaneously, which could be streamlined by handling only the "best-matching" path at each step, narrowing the upstream network being processed. Although the model in Modelleyen can grow as large as needed, operations should ideally involve only a small set of CSVs, with their combined source SPNs no more complex than the SPN representing given observation. This would cap per-step computation complexity to the size of the observation space, and our aim is to realize this degree of computational efficiency.

% The current implementation of our method is computationally demanding, as to a large extent the models developed has redundancies and repeated representations due to design choices that were made for method simplicity at this stage of the work and has not undergone revision for the reduction of their computational demands. Namely, currently (as discussed in Section \ref{sec:method} and in contrast to the original formulation of Modelleyen \cite{erden2025agential}) upstream CSVs are represented as larger networks encompassing their downstream targets instead of simply distinct subnetworks that integrate with them, and additionally a CSV is represented to be targeting only a single target, losing possibility of share of the same conditioning source across targets. These two mechanisms can be resolved within the designed framework with some rather straightforward changes, thereby reducing the computational demands. Furthermore, one limitation is that currently multiple upstream paths are processed at the same time if there is an intersection with each of them, this way of processing can be revisited to process only a single one (possibly the "best-matching" one) to cap the size of the upstream network being processed at each step to being a single upstream path only. In principle, while the model can grow unboundedly, all operations should be doable within a very small set of CSVs, whose source SPNs' combined size should not exceed the complexity of the SPN corresponding to a given observation. Our aim is to realize this per-step computation complexity.

A natural long-term extension of this work is processing more complex visual spaces, which would require hierarchical representations. While moderately simple structures (e.g., eyes or noses) can be plausibly learned using an approach similar to what is described in this work, more complex entities (e.g. whole faces) or multi-object scenes demand hierarchical organization of components. Our method is well-suited for such structured spaces, as they often involve fewer alternative assignments (e.g., unique objects). Future work will explore such extensions into hierarchical representations, and means for their unsupervised construction through the progression of learning.

% A natural extension of this work in the long term is processing more complex and composite visual spaces. For processing more complex visual spaces, one would need a form of hierarchical representations - it is plausible to think that the structure of something moderately simple like an eye or a nose can be learned and represented using the methods described here, as it is primarily based on shape detection; though the same can't be said for a face (unless one operates on low-dimension explicitly) -- for that, one would need to represent the components of a face in a hierarchical manner. Same would be said for more complex visual scenes, including multiple objects and their interrelations. The good news is that our method, arguably is even more suitable for such spaces given the representations, as they are often more structured, with lower number of alternative assignments possible (usually-unique, distinct objects). Such extensions with the consideration of how visual elements can be represented in a hierarchy, perhaps constructed over the course of the learning progression, is also going to be investigated in future work.


\input{main.bbl}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\section{Appendix}

\subsection{Figures and algorithms detailing  original design of Modelleyen}
\label{sec:my_background}

This section provides some brief background information in Modelleyen. All figures and papers are taken from \cite{erden2025agential}, the reader is referred to to there for full context and details.

Figures \ref{fig:csvform} illustrates the formation of the sources composition of a CSV, and Fig. \ref{fig:csvformupstream} illustrates the formation of upstream conditioning pathways. Algorithm \ref{alg:algorithm_adaptationloop} gives an overview of the per-step learning loop in Modelleyen, and Alg. \ref{alg:algorithm_csvstate} provides a complete view into the per-step state-computation operations of a CSV, which is the focus of learning in the algorithm. This learning flow is kept intact in our design as well, with the exception of the changes listed in Section \ref{sec:learning_flow}.


\begin{figure}
     \centering
     \begin{subfigure}[t]{0.22\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/CSV_Formation_1.png}
         \caption{}
         \label{fig:csvform_1}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.22\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/CSV_Formation_2.png}
         \caption{}
         \label{fig:csvform_2}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.22\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/CSV_Formation_3.png}
         \caption{}
         \label{fig:csvform_3}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.22\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/CSV_Formation_4.png}
         \caption{}
         \label{fig:csvform_4}
     \end{subfigure}
     %\hspace{1cm}
     \hfill
     \begin{subfigure}[t]{0.22\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/CSV_Formation_5.png}
         \caption{}
         \label{fig:csvform_5}
     \end{subfigure}
    \caption{From \cite{erden2025agential}. Sample formation of a CSV in a continual manner. The relationship to be modelled is $Y = X0\ and\ !X2$ ("!" denotes "not"). Black and orange arrows represent positive and negative sources for CSV $C0$ respctively. $Xi$ can be interpreted either as single or grouped SVs. (a) Initial state with no relation formed between $X0-3$ and $Y$. (b) $X0, X1 \rightarrow Y$ observed. Positive connections hypothesizing both $X0$ \& $X1$ are required for Y are formed. (c) $X0 \rightarrow Y$ is observed. $X1$ is deduced unnecessary for $Y$. (d) $X0, X2, X3 \rightarrow !Y$ observed. $Y$ is hypothesized to be suppressed by $X2$ and $X3$. (e) $X0, X2 \rightarrow !Y$ observed. $X3$, seen unnecessary for suppression of $Y$, refined. Correct structure learned and is stable from now on.}
    \label{fig:csvform}
\end{figure}



% fig* for single column
\begin{figure*}
     \centering
     \begin{subfigure}[t]{0.25\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/UpstreamCSV_1.png}
         \caption{}
         \label{fig:csvformupstream_1}
     \end{subfigure}
     \vline
     \begin{subfigure}[t]{0.5\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/UpstreamCSV_2.png}
         \caption{}
         \label{fig:csvformupstream_2}
     \end{subfigure}
    \caption{From \cite{erden2025agential}. Example of upstream conditioning, continuing from Figure \ref{fig:csvform}. Assume that the unconditionality flag of $C0$ is set following an observation that $(X0,\ !X2)$ did not result in its activation (see main text). (a) $X0, !X2, X4, X5 \rightarrow Y$ observed. $C0$ is observed to be active, since $XO, !X2$ led to $Y$. A new CSV $C1$ is formed \& conditions $C0$. Note that $(X4, X5)$ alone will not predict activation of $C0$ if $C0$’s sources are not also active. (b) New conditioners are also subject to the CSV processes: Here, the source $X5$ of $C1$ has been refined, and new conditioners $C2$ and $C3$ are formed. Multiple conditioners represent alternative paths: In this case, $C0$ is expected to be active when sources of either $C1$ or $C2$ is active. Any logical function can hence be incorporated in a conditioning pathway in a minimal and ongoing manner without destroying past knowledge.}
    \label{fig:csvformupstream}
\end{figure*}


\begin{algorithm}[tb]
\caption{From \cite{erden2025agential}. Pseudocode of the main Modelleyen adaptation loop; formed of state computations followed by CSV generation for unexplained SVs.}

\label{alg:algorithm_adaptationloop}
\textbf{Parameter}: $N$ Set of all target nodes\\
\textbf{Function} \textit{ProcessEnvironmentStep}(observations)
\begin{algorithmic}[1] %[1] enables line numbers
    \STATE $BSVStates \leftarrow \ observations$
    \STATE $ComputeDSVStates()$ \COMMENT{Computes DSV states by BSV events}
    \FOR{$level\ \in\ reverse(ComputationLevels)$}
        \FOR{$CSV\ \in\ SVs_in(level)$}
            \STATE $ComputeState(CSV)$
        \ENDFOR
    \ENDFOR
    \STATE $UnexplainedSVs \leftarrow [SV:\ SV.state = 1\ \AND\ NoConditionerActive(SV)]$
    \STATE $sources \leftarrow [SV:\ SV in\ [BSVs, DSVs]\ \AND\ SV.state = 1\ \AND\ isEligible(SV)]$
    \STATE $ NewCSV = CreateCSV(sources, [SV: SV\ in\ UnexplainedSVs\ \AND\ TargetEligible(SV)])$
    \STATE $ModelRefinement()$ \COMMENT{Removes CSVs with no source or target}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[tb]
\caption{From \cite{erden2025agential}. Pseudocode for CSV state computation.}

\label{alg:algorithm_csvstate}

\textbf{Function} \textit{ComputeState}($CSV$)
\begin{algorithmic}[1] %[1] enables line numbers
    \IF{$AnySourceActive()$}
        \STATE $SeparateActiveInactiveTargets()$ \COMMENT{Creates two CSVs from current one with active and inactive targets in either of them}
        \IF{$AnyTargetObserved()$}
            \STATE $State = 1$
            \STATE $PosSources \leftarrow [source:\ source\ in\ PosSources\ \AND\ source.state=1]$
            \STATE $NegSources \leftarrow [source:\ source\ in\ NegSources\ \AND\ source.state!=1]$
        \ELSIF{$AnyTargetInactive()$}
            \IF{$not(AllSourcesActive())$}
                \STATE $State = 1$
            \ELSE
                \IF{$AnyNegativeSourceActive()$}
                    \STATE $State = 0$
                    \STATE $NegSources \leftarrow [source:\ source\ in\ NegSources\ \AND\ source.State=1]$
                \ELSE
                    \STATE $State = -1$  \COMMENT{No negative source active to explain inactivity of targets}
                \ENDIF
            \ENDIF
        \ENDIF
    \ELSE
        \STATE $State = 0$ \COMMENT{Unobserved if targets are not observed}
    \ENDIF

    \IF{$State = -1$}
        \IF{$NegativeConnectionsFormed$}
            \STATE $FormNegativeConnections()$
        \ELSE
            \STATE $unconditionality = "isConditional"$ \COMMENT{-1 for }
        \ENDIF
    \ENDIF

    
\end{algorithmic}

\end{algorithm}

\subsection{Additional illustrations}

Figure \ref{fig:results_spns_appendix} presents some additional learned representations in the runs during our experiments presented in the main text.

\begin{figure*}
     \centering
     \begin{subfigure}{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/4_ds.png}
         \caption{Digit 4, depth 0.}
         \label{fig:results_spns_4_ds}
     \end{subfigure}
     \begin{subfigure}{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/7_ds.png}
         \caption{Digit 7, depth 0.}
         \label{fig:results_spns_7_ds}
     \end{subfigure}
      \begin{subfigure}{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/6_ds.png}
         \caption{Digit 6, depth 0.}
         \label{fig:results_spns_6_ds}
     \end{subfigure}
     \begin{subfigure}{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Figures/6_negfrom4.png}
         \caption{Source of a negative conditioner (suppressing connection) for digit 6, initialized from an instance of digit 4.}
         \label{fig:results_spns_6_negfrom4}
     \end{subfigure}
    \caption{Additional examples of representations of digits learned by MNR.}
    \label{fig:results_spns_appendix}
\end{figure*}

\subsection{Experimental details}
\label{sec:exp_details}

\paragraph{Sample sizes:} We use $N_{sample}=20,\ 10,\ 5$ and test set size of $50,\ 20,\ 10$ samples per class for experiments with $N_C=3,\ 5,\ 10$ respectively. Reported results are averages of 10 runs for $N_C=3$ and 5 runs for $N_C=5$. Population size for generating assignments was chosen as $10$ for both learning and prediction.

\paragraph{MNR settings:} For MNR, we choose refinement threshold $T_{ref}=0.05$, significance threshold $T_{sign}=0.05$. $\epsilon$ for polygonal approximation is $0.01L$ where $L$ is the arc length of contour being approximated.

\paragraph{Neural network settings:} Our fully connected neural network architecture is of 2 hidden layers with 128 neurons each, while the CNN architecture has a pair of convolutional (32 filters with 3x3 kernels) and max-pooling (with pool size 2x2) layer, repeated twice sequentially, followed by a dense layer of 128 neurons. All NNs use ReLU activation in hidden layers and softmax in output. We use a maximum of 100 epochs and an early stopping patience of 10 epochs. All remaining settings are Keras defaults.

\paragraph{Prediction in MNR} To predict targets for a given observed SPN, we follow this procedure: First, we attempt to find an assignment (as described in \ref{sec:netref_description}) that \textit{satisfies} the source SPN of the CSV. If no assignment is found, the CSV is considered inactive. If an assignment is found, we compute the activation probability of the CSV. If the CSV is unconditional (no positive/negative conditioners), the probability is $p = P(I(T)|SS(C))$, tracked over the learning process. If the CSV is conditional, the probability is $p = (1 - p^{max}-) \times p^{max}+$, where $p^{max}-$ and $p^{max}+$ are the maximum activation probabilities of negative and positive conditioners, respectively. Intuitively, this approach prioritizes the most-upstream representations (most closely matching the observed SPN) when calculating the final probability, resolving conflicts between activating and suppressing pathways by multiplying their probabilities.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
