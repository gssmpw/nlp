\section{Methodology} \label{sec:methodology}

When training a flow-based model, such as Shortcut model, using only the first-order term as the training loss has several limitations compared to incorporating high-order losses. (1) Firstly, relying solely on the first-order term results in a less accurate approximation of the true dynamics, as it captures only the linear component and misses important nonlinear aspects that higher-order terms can represent. This can lead to slower convergence, as the model must implicitly learn complex dynamics without explicit guidance from higher-order terms. (2) Additionally, while the first-order approach reduces model complexity and the risk of overfitting, it may also limit the model's ability to generalize effectively to unseen data, particularly when the underlying dynamics are highly nonlinear. (3) In contrast, including higher-order terms enhances the model's capacity to capture intricate patterns, improving both accuracy and generalization, albeit at the cost of increased computational complexity and potential overfitting risks.

Then, we introducing our HOMO (High-Order Matching for One-step Shortcut diffusion model). The intuition behind this design is to leverage high-order dynamics to achieve a more accurate and stable approximation of the field evolution. By incorporating higher-order losses, we aim to capture the nonlinearities and complex interactions that are often present in real-world systems. This approach not only improves the fidelity of the model but also enhances its ability to generalize across different scenarios.

\begin{definition}[HOMO Inference]
\label{def:HOMO_inference}
Let $\Delta t = 1 / 128$. 
Let $x_t$ be the current field. 
Let $t \in \mathbb{N}$ denote the time step. 
Let $u_{1,\theta_1}( \cdot )$ and $u_{2,\theta_2}( \cdot )$ denote the HOMO models to be trained. 
Let $d \in (0, 1 / 128, 1 / 64,\dots, 1 / 2, 1 )$ denote the step size. 
Then, we define the HOMO computation of the next field $x_{t + d}$ as follows: 
\begin{align*}
x_{t + d} = 
\begin{cases}
x_t + d \cdot u_1( x_t, t, d ) 
+ \frac{d^2}{2} \\
\qquad \cdot u_2(u_1 ( x_t, t, d), x_t, t, d ) & \text{if } d \geq 1 / 128, \\
x_t + \Delta t \cdot u_1( x_t, t, 0 )
+ \frac{(\Delta t)^2}{2} \\
\qquad \cdot u_2(u_1 ( x_t, t, 0), x_t, t, 0 ) & \text{if } d < 1 / 128.
\end{cases}
\end{align*}
\end{definition}

The self-consistency target is to ensure that the model's predictions are consistent across different time steps. This is crucial for maintaining the stability and accuracy of the model over long-term predictions. 

\begin{definition}[HOMO Self-Consistency Target]
\label{def:2nd_self_consistency_target}
Let $u_{1,\theta_1}$ be the networks to be trained.
Let $x_t$ be the current field and $x_{t+d}$ be defined in Definition~\ref{def:HOMO_inference}.
Let $t \in \mathbb{N}$ denote the time step. 
Let $d \in (0, 1 / 128, 1 / 64,\dots, 1 / 2, 1 )$ denote the step size.
Then, we define the Self-Consistency target as follows: 
\begin{align*}
    \dot{x}_t^{\mathrm{target}} = & ~ u_{1,\theta_1} ( x_t, t, d ) / 2 + u_{1,\theta_1}( x_{t + d}, t, d ) / 2 
\end{align*}
\end{definition}

The second-order HOMO loss is designed to optimize the model by minimizing the discrepancy between the predicted and true velocities and accelerations. This loss function ensures that the model not only captures the immediate dynamics but also the underlying trends and changes in the system. 

\begin{definition}[Second-order HOMO Loss] 
\label{def:HOMO_loss}
Let $x_t$ be the current field. 
Let $t \in \mathbb{N}$ denote the time step. 
Let $\dot{x}_t^{\mathrm{target}}$ be defined by Definition~\ref{def:2nd_self_consistency_target}.
Let $u_{1,\theta_1}( \cdot )$ and $u_{2,\theta_2}( \cdot )$ denote the HOMO models to be trained. 
Let $d \in (0, 1 / 128, 1 / 64,\dots, 1 / 2, 1 )$ denote the step size. 
Let $\dot{x}_t^\True$ and $\ddot{x}_t^\True$ be the observed (or numerically approximated) true velocity and acceleration. 
Let $\dot{x}_t^{\mathrm{pred}} := u_{1,\theta_1}(x_t, t, 2 d)$ denote the model prediction of the first-order term.
Then, we define the HOMO Loss as follows: 
\begin{align*}
L_{(\theta_1,\theta_2)} = & ~ \E[\ell_{2,1,\theta_1}(x_t, \dot{x}_t^{\True})] + \E[\ell_{2,2,\theta_2, \theta_1}(x_t, \ddot{x}_t^{\True})] \\
& ~ +
\E[ \| u_{1,\theta_1}(x_t, t, 2 d)- \dot{x}_t^{\mathrm{target}}\|^2]
\end{align*}

We define 
\begin{align*}
    \ell_{2,1,\theta_1}(x_t, \dot{x}_t^{\True}) := &~ \|  u_{1,\theta_1}(x_t, t, 2 d) - \dot{x}_t^{\True} \|^2, \\
    \ell_{2,2,\theta_2, \theta_1}(x_t, \ddot{x}_t^{\True}) := &~ \| u_{2,\theta_2}  (\dot{x}_t^{\mathrm{pred}}, x_t, t, 2 d) - \ddot{x}_t^{\True} \|^2 \\
    \ell_{\mathrm{selfc}}(x_t, \dot{x}_t^{\mathrm{target}}) := &~ \| u_{1,\theta_1}(x_t, t, 2 d)- \dot{x}_t^{\mathrm{target}}\|^2
\end{align*}
and 
\begin{align*}
    \ell_{(\theta_1, \theta_2)}(x_t, x_t^{\True}) := &~ \ell_{2,1,\theta_1}(x_t, \dot{x}_t^{\True})+\ell_{2,2,\theta_2, \theta_1}(x_t, \ddot{x}_t^{\True}) \\ + &~ \ell_{\mathrm{selfc}}(x_t, \dot{x}_t^{\mathrm{target}}).
\end{align*}
\end{definition}

\begin{remark} [Simple notations] \label{rem:simplicity_notations}
For simplicity, we denote first-order matching as M1, which implies that HOMO is optimized solely by the first-order loss $\ell_{2,1,\theta_1}(x_t, \dot{x}_t^{\True})$. Second-order matching is denoted as M2, where HOMO is optimized only by the second-order loss $\ell_{2,2,\theta_2, \theta_1}(x_t, \ddot{x}_t^{\True})$. We refer to HOMO optimized solely by the self-consistency loss as SC, denoted by $\ell_{\mathrm{selfc}}(x_t, \dot{x}_t^{\mathrm{target}})$. Combinations of M1, M2, and SC are used to indicate HOMO optimized by corresponding combinations of loss terms. For example, (M1 + M2) denotes HOMO optimized by both first-order and second-order terms, while (M1 + M2 + SC) represents HOMO optimized by the first-order, second-order, and self-consistency terms.
\end{remark}


