\section{Third-Order HOMO}\label{sec:app:3rd_homo}
This section extends HOMO to third-order dynamics and analyzes its performance on complex synthetic tasks. Section~\ref{sec:app:3rd_homo_algorithm} introduces the training and sampling algorithms incorporating third-order dynamics. Section~\ref{sec:app:trajectory_setting} compares two trajectory parameterization strategies for high-order systems. Section~\ref{sec:app:complex_dataset} describes the 2 Round Spin, 3 Round Spin, and Dot-Circle datasets designed to test complex mode transitions. Section~\ref{sec:app:euclidean_distance_loss} provides quantitative analysis through Euclidean distance metrics between generated and target distributions. Section~\ref{sec:app:3rd_self_consistency} evaluates the isolated impact of self-consistency constraints. Section~\ref{sec:app:3rd_first_order_plus_self_consistency} examines first-order dynamics coupled with self-consistency regularization. Section~\ref{sec:app:3rd_first_order_plus_second_order_plus_self_consistency} studies the combined effect of first-, second-order dynamics and self-consistency. Finally, Section~\ref{sec:app:3rd_order_homo} demonstrates full third-order HOMO with all optimization terms, analyzing trajectory linearity and mode fidelity under different trajectory settings.
\subsection{Algorithm}\label{sec:app:3rd_homo_algorithm}
Here we first introduce the training algorithm of our third-order HOMO: 
\begin{algorithm}[!ht]\caption{ Third-Order HOMO Training}
\begin{algorithmic}[1]
\While{not converged}
\State $x_0 \sim \N (0, I), x_1 \sim D, (d, t) \sim p(d, t)$
\State $\beta_t \gets \sqrt{1-\alpha_t^2}$
\State $x_t \gets \alpha_t \cdot x_0 + \beta_t \cdot x_1$ \Comment{Noise data point}
\For{first $k$ batch elements}
\State $\dot s_t^{\True} \gets \dot{\alpha_t} x_0 + \dot{\beta_t} x_1$ \Comment{First-order target}
\State $\ddot s_t^{\True} \gets \ddot{\alpha_t} x_0 + \ddot{\beta_t} x_1$ \Comment{Second-order target}
\State $\dddot s_t^{\True} \gets \dddot{\alpha_t} x_0 + \dddot{\beta_t} x_1$ \Comment{Third-order target}
\State $d \gets 0$
\EndFor
\For{other batch elements}
\State $s_t \gets u_1 ( x_t, t, d)$ \Comment{First small step of first order}
\State $\dot s_t \gets u_2 (u_1 ( x_t, t, d), x_t, t, d)$ \Comment{First small step of second order}
\State $\ddot s_t \gets u_3 (u_2(u_1(x_t, t, d), x_t, t, d), u_1(x_t, t, d), x_t, t, d)$ \Comment{First small step of third order}
\State $x_{t + d} \gets x_t + d \cdot s_t + \frac{d^2}{2} \dot s_t + \frac{d^6}{3} \ddot s_t $ \Comment{Follow ODE}
\State $s_{t + d} \gets u_1 ( x_{t + d}, t + d, d )$ \Comment{Second small step of first order}
\State $\dot s_t^{\mathrm{target}} \gets$ stopgrad $(s_t + s_{t+d}) / 2$ \Comment{Self-consistency target of first order }
\EndFor
\State $\theta \gets \nabla_\theta ( \| u_1 ( x_t, t, 2d ) - \dot s_t^{\True} \|^2$
\Statex \hspace{4.2em} $ + \| u_2 (u_1 (x_t, t, 2d), x_t, t, 2d) - \ddot s_t^{\True} \|^2$
\Statex \hspace{4.2em} $ + \| u_3 (u_2(u_1(x, t, d), x, t, d), u_1(x, t, d), x, t, d) - \dddot{s}_t^{\True} \|^2 $
\Statex \hspace{4.2em} $ + \| u_{1}(x_t, t, 2 d) - \dot{s}_t^{\mathrm{target}}\|^2$
\EndWhile
\end{algorithmic}
\end{algorithm}

Then we will discuss the sampling algorithm in third-order HOMO: 
\begin{algorithm}[!ht]\caption{Third-Order HOMO Sampling}
\begin{algorithmic}[1]
\State $x \sim \N (0, I)$
\State $d \gets 1 / M$
\State $t \gets 0$
\For{$n \in [0, \dots, M - 1]$}
\State $x \gets x + d \cdot u_1(x, t, d) + \frac{d^2}{2} \cdot u_2(u_1(x, t, d), x, t, d) + \frac{d^3}{6}\cdot u_3 (u_2(u_1(x, t, d), x, t, d), u_1(x, t, d), x, t, d)$
\State $t \gets t + d$
\EndFor
\State \textbf{return} $x$
\end{algorithmic}
\end{algorithm}

\subsection{Trajectory setting}\label{sec:app:trajectory_setting}
We have trajectory as:
\begin{align*}
    z_t = \alpha_t z_0 + \beta_t z_1
\end{align*}
In original trajectory, we choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. And new trajectory as $\alpha_t = 1 - ( 3t^2 - 2t^3 )$ and $\beta_t = 3t^2 - 2t^3$. 

\subsection{Dataset}\label{sec:app:complex_dataset}
Here, we introduce three datasets we use: 2 Round spin, 3 Round spin, and Dot-Circle datasets. In 2 Round spin dataset and 3 Round spin dataset, we both sample 600 points from Gaussian distribution with $0.3$ variance for both source distribution and target distribution. In Dot-Circle datasets, we sample 300 points from the center dot and 300 points from the outermost circle, combine them as source distribution, and then sample 600 points from 2 round spin distribution. 
\begin{figure}[!ht] 
\centering
\includegraphics[width=0.25\textwidth]{new_spiral_dataset.pdf}
\includegraphics[width=0.25\textwidth]{3round_spiral_dataset.pdf}
\includegraphics[width=0.25\textwidth]{dotpluscircle_dataset.pdf}
\caption{
The 2 Round spin dataset(\textbf{Left}), 3 Round spin dataset(\textbf{Middle}), and Dot-Circle datasets(\textbf{Right}). Our goal is to make HOMO learn a transport trajectory from distribution $\pi_0$ ({\textbf{brown}}) to distribution $\pi_1$ ({\textbf{indigo}}). 
}
\label{fig:three_complex_dataset}
\end{figure}


\subsection{Euclidean distance loss}\label{sec:app:euclidean_distance_loss}
Here, we present the Euclidean distance loss performance of four different loss terms combined under the original trajectory setting and the new trajectory setting. 


\begin{table}[!ht] 
\centering
\caption{
\textbf{Euclidean distance loss of three complex distribution datasets under new trajectory setting.} Lower values indicate more accurate distribution transfer results. Optimal values are highlighted in \textbf{Bold}. And \underline{Underlined} numbers represent the second best (second lowest) loss value for each dataset (row). 
For the qualitative results of a mixture of Gaussian experiments, please refer to Figure~\ref{fig:mixture_of_gaussian_experiment}.
}
\label{tab:euclidean_distance_complex_datasets_new}
\begin{tabular}{l|c|c|c}
\toprule
& \textbf{2 Round} & \textbf{3 Round} & \textbf{Dot-} \\
\textbf{Loss terms}  & \textbf{spin} & \textbf{spin} & \textbf{Circle} \\
\midrule
SC              & 41.265 & 48.201 & 87.407 \\
M1 + SC          & 14.926 & 18.376 & 30.027 \\
M1 + M2 + SC      & \underline{11.435} & \underline{12.422} & \underline{24.712} \\
M1 + M2 + SC + M3		& \textbf{4.701} & \textbf{9.261} & \textbf{21.968} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Only Self-Consistency Term}\label{sec:app:3rd_self_consistency}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the first line, we use the original transport trajectory setting, followed by the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In 2 Round spin datasets and 3 Round spin datasets, we sample 400 points, both source distribution and target distribution. In the Dot-Circle dataset, we sample 600 points from both source distribution and target distribution, 300 points of source points from the circle, and another 300 from the center dot. In 2-round dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $180$ training steps. In 3-round spin dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $180$ training steps. In Dot-Circle dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $180$ training steps. 
\begin{figure}[!ht]
\centering
\subfloat[(original)SC / 2 Round]
{\includegraphics[width=0.25\textwidth]{1_3_2round_spiral_output.pdf}}
\subfloat[(original)SC / 3 Round]
{\includegraphics[width=0.25\textwidth]{1_3_3round_spiral_output.pdf}}
\subfloat[(original)SC / DotPlusCircle]
{\includegraphics[width=0.25\textwidth]{1_3_dotpluscircle_output.pdf}} \\
\subfloat[(new)SC / 2 Round]
{\includegraphics[width=0.25\textwidth]{2_3_2round_spiral_output.pdf}}
\subfloat[(new)SC / 3 Round]
{\includegraphics[width=0.25\textwidth]{2_3_3round_spiral_output.pdf}}
\subfloat[(new)SC / DotPlusCircle]
{\includegraphics[width=0.25\textwidth]{2_3_dotpluscircle_output.pdf}}
\caption{
(SC )
The distributions generated by HOMO are only optimized by self-consistency loss. 
\textbf{Upper row(original trajectory setting):}
Figure (a), in 2 Round spin dataset. Figure (b), in 3 Round spin dataset. 
Figure (c), in Dot-Circle dataset. 
\textbf{Lower row(new trajectory setting):}
Figure (d), in 2 Round spin dataset. 
Figure (e), in 3 Round spin dataset. 
Figure (f), in Dot-Circle dataset. 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). 
}
\label{fig:3rd_self_consistency}
\end{figure}

\subsection{First Order Plus Self-Consistency}\label{sec:app:3rd_first_order_plus_self_consistency}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the first line, we use the original transport trajectory setting, followed by the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In 2 Round spin datasets and 3 Round spin datasets, we sample $400$ points in both source distribution and target distribution. And in the Dot-Circle dataset, we sample $600$ points from both source distribution and target distribution, $300$ points of sources points from the circle, and another $300$ from the center dot. In 2 Round dataset training, we use ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimension, $800$ batch size, $0.005$ learning rate, and $1000$ training steps. In 3 Round spin dataset training, we also use ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimension, $1000$ batch size, $0.005$ learning rate, and $2000$ training steps. And in Dot-Circle dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $10000$ training steps. 
\begin{figure}[!ht]
\centering
\subfloat[(original)(M1+SC) / 2 Round]
{\includegraphics[width=0.25\textwidth]{1_13_2round_spiral_output.pdf}}
\subfloat[(original)(M1+SC) / 3 Round]
{\includegraphics[width=0.25\textwidth]{1_13_3round_spiral_output.pdf}}
\subfloat[(original)(M1+SC) / Dot-Circle]
{\includegraphics[width=0.25\textwidth]{1_13_dotpluscircle_output.pdf}} \\
\subfloat[(new)(M1 + SC) / 2 Round]
{\includegraphics[width=0.25\textwidth]{2_13_2round_spiral_output.pdf}}
\subfloat[(new)(M1 + SC) / 3 Round]
{\includegraphics[width=0.25\textwidth]{2_13_3round_spiral_output.pdf}}
\subfloat[(new)(M1+SC) / Dot-Circle]
{\includegraphics[width=0.25\textwidth]{2_13_dotpluscircle_output.pdf}}
\caption{
(M1+SC)
The distributions generated by HOMO are only optimized by first-order loss and self-consistency loss. 
\textbf{Upper row(original trajectory setting):}
Figure (a), in 2 Round spin dataset. Figure (b), in 3 Round spin dataset. 
Figure (c), in Dot-Circle dataset. 
\textbf{Lower row(new trajectory setting):}
Figure (d), in 2 Round spin dataset. 
Figure (e), in 3 Round spin dataset. 
Figure (f), in Dot-Circle dataset. 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). 
}
\label{fig:3rd_first_order_plus_self_consistency}
\end{figure}

\subsection{First Order Plus Second Order Plus Self-Consistency}\label{sec:app:3rd_first_order_plus_second_order_plus_self_consistency}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the first line, we use the original transport trajectory setting, followed by the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In 2 Round spin datasets and 3 Round spin datasets, we sample 400 points, both source distribution and target distribution. And in the Dot-Circle dataset, we sample 600 points from both source distribution and target distribution, 300 points of source points from the circle, and another 300 from the center dot. In 2 Round dataset training, we use ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimension, $800$ batch size, $0.005$ learning rate, and $1000$ training steps. In 3 Round spin dataset training, we also use ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimension, $1000$ batch size, $0.005$ learning rate, and $2000$ training steps. And in Dot-Circle dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $10000$ training steps. 
\begin{figure}[!ht]
\centering
\subfloat[(original) (M1+M2+SC) / 2 Round]
{\includegraphics[width=0.25\textwidth]{1_123_2round_spiral_output.pdf}}
\subfloat[(original) (M1+M2+SC) / 3 Round]
{\includegraphics[width=0.25\textwidth]{1_123_3round_spiral_output.pdf}}
\subfloat[(original) (M1+M2+SC) / Dot-Circle]
{\includegraphics[width=0.25\textwidth]{1_123_dotpluscircle_output.pdf}} \\
\subfloat[(new) (M1+M2+SC) / 2 Round]
{\includegraphics[width=0.25\textwidth]{2_123_2round_spiral_output.pdf}}
\subfloat[(new) (M1+M2+SC) / 3 Round]
{\includegraphics[width=0.25\textwidth]{2_123_3round_spiral_output.pdf}}
\subfloat[(new) (M1+M2+SC) / Dot-Circle]
{\includegraphics[width=0.25\textwidth]{2_123_dotpluscircle_output.pdf}}
\caption{
(M1+M2+SC)
The distributions generated by HOMO are only optimized by first-order loss and second order loss, and self-consistency loss. 
\textbf{Upper row(original trajectory setting):}
Figure (a), in 2 Round spin dataset. Figure (b), in 3 Round spin dataset. 
Figure (c), in Dot-Circle dataset. 
\textbf{Lower row(new trajectory setting):}
Figure (d), in 2 Round spin dataset. 
Figure (e), in 3 Round spin dataset. 
Figure (f), in Dot-Circle dataset. 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). 
}
\label{fig:3rd_frist_order_plus_second_order_plus_self_consistency}
\end{figure}

\subsection{Third-Order HOMO}\label{sec:app:3rd_order_homo}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the first line, we use the original transport trajectory setting, followed by the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In 2 Round spin datasets and 3 Round spin datasets, we sample 400 points, both source distribution and target distribution. In the Dot-Circle dataset, we sample 600 points, both source distribution and target distribution, 300 points of source points from the circle, and another 300 from the center dot. In 2-round dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $1000$ training steps. In 3-round spin dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $2000$ training steps. In Dot-Circle dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $10000$ training steps. 

\begin{figure}[!ht]
\centering
\subfloat[(original) (M1+M2+M3+SC) / 2 Round]
{\includegraphics[width=0.25\textwidth]{1_1234_2round_spiral_output.pdf}}
\subfloat[(original) (M1+M2+M3+SC) / 3 Round]
{\includegraphics[width=0.25\textwidth]{1_1234_3round_spiral_output.pdf}}
\subfloat[(original) (M1+M2+M3+SC) / Dot-Circle]
{\includegraphics[width=0.25\textwidth]{1_1234_dotpluscircle_output.pdf}}\\
\subfloat[(new) (M1+M2+M3+SC) / 2 Round]
{\includegraphics[width=0.25\textwidth]{2_1234_2round_spiral_output.pdf}}
\subfloat[(new) (M1+M2+M3+SC) / 3 Round]
{\includegraphics[width=0.25\textwidth]{2_1234_3round_spiral_output.pdf}}
\subfloat[(new) (M1+M2+M3+SC) / Dot-Circle]
{\includegraphics[width=0.25\textwidth]{2_1234_dotpluscircle_output.pdf}}
\caption{
(M1+M2+M3+SC) The distributions generated by Third-Order HOMO, optimized by first-order loss and second-order loss, third-order loss and self-consistency loss. 
\textbf{Upper row(original trajectory setting):}
Figure (a), in 2 Round spin dataset. Figure (b), in 3 Round spin dataset. 
Figure (c), in Dot-Circle dataset. 
\textbf{Lower row(new trajectory setting):}
Figure (d), in 2 Round spin dataset. 
Figure (e), in 3 Round spin dataset. 
Figure (f), in Dot-Circle dataset. 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). 
}
\label{fig:3rd_order_homo}
\end{figure}
