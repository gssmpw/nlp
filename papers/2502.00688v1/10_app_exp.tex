\section{Empirical Ablation Study} \label{sec:app:empirical_ablation_study}
In Section~\ref{sec:app:dataset}, we introduce the three Gaussian mixture distribution datasets—four-mode, five-mode, and eight-mode—used in our empirical ablation study, along with their configurations for source and target modes. The subsequent subsections analyze the impact of different optimization terms. Section~\ref{sec:app:rectified_flow} evaluates the performance of HOMO optimized solely with the first-order term. Section~\ref{sec:app:second_order} examines the effect of using only the second-order term. Section~\ref{sec:app:self_consistency} assesses results when optimization is guided by the self-consistency term. Section~\ref{sec:app:first_order_plus_second_order} explores the combined effect of first- and second-order terms, while Section~\ref{sec:app:second_order_plus_self_target} investigates the combination of second-order and self-consistency terms. Through these analyses, we aim to dissect the contributions of individual and combined loss terms in achieving effective transport trajectories.
\subsection{Dataset}\label{sec:app:dataset}

Here we introduce three datasets we use: four-mode, five-mode, and eight-mode Gaussian mixture distribution datasets; each Gaussian component has a variance of $0.3$. In the four-mode Gaussian mixture distribution, four source mode(\textbf{brown}) positioned at a distance $D_0 = 5$ from the origin, and four target mode(\textbf{indigo}) positioned at a distance $D_0 = 14$ from the origin, each mode sample 200 points. In five-mode Gaussian mixture distribution, five source mode(\textbf{brown}) positioned at a distance $D_0 = 6$ from the origin, and five target mode(\textbf{indigo}) positioned at a distance $D_0 = 13$ from the origin, each mode sample 200 points. And in eight-mode Gaussian mixture distribution, eight source mode(\textbf{brown}) positioned at a distance $D_0 = 6$ from the origin, and eight target mode(\textbf{indigo}) positioned at a distance $D_0 = 13$ from the origin, each mode sample 100 points. 

\begin{figure}[!ht] 
\centering
\includegraphics[width=0.25\textwidth]{4_dataset.pdf}
\includegraphics[width=0.25\textwidth]{5_dataset.pdf}
\includegraphics[width=0.25\textwidth]{8_dataset.pdf}
\caption{
The four-mode Gaussian mixture distribution (\textbf{Left}), five-mode Gaussian mixture distribution (\textbf{Middle}), and eight-mode Gaussian mixture distribution (\textbf{Right}). Our goal is to make HOMO learn a transport trajectory from distribution $\pi_0$ ({\textbf{brown}}) to distribution $\pi_1$ ({\textbf{indigo}}). 
}
\label{fig:three_normal_dataset}
\end{figure}

\subsection{Only First Order Term}\label{sec:app:rectified_flow}

We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the target transport trajectory setting, we follow the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In the four-mode dataset, five-mode dataset, and eight-mode dataset, we all sample 100 points in each source mode and target mode. And in four-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $1000$ training steps. In five-mode dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $1000$ training steps. And in eight-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $1000$ training steps. 


\begin{figure}[!ht]
\centering
\includegraphics[width=0.25\textwidth]{4_1_output.pdf}
\includegraphics[width=0.25\textwidth]{5_1_output.pdf}
\includegraphics[width=0.25\textwidth]{8_1_output.pdf}
\caption{
(A) The distributions generated by HOMO are only optimized by first-order term in four-mode dataset (\textbf{Left}), five-mode dataset (\textbf{Middle}), and eight-mode dataset (\textbf{Right}). 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). 
}
\label{fig:1_distribution}
\end{figure}


\subsection{Only Second Order Term}\label{sec:app:second_order}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the target transport trajectory setting, we follow the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In the four-mode dataset, five-mode dataset, and eight-mode dataset, we all sample 100 points in each source mode and target mode. And in four-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $100$ training steps. In five-mode dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $100$ training steps. And in eight-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $100$ training steps. 


\begin{figure}[!ht]
\centering
\includegraphics[width=0.25\textwidth]{4_2_output.pdf}
\includegraphics[width=0.25\textwidth]{5_2_output.pdf}
\includegraphics[width=0.25\textwidth]{8_2_output.pdf}
\caption{
(B) The distributions generated by HOMO are only optimized by second-order term in the four-mode dataset (\textbf{Left}), five-mode dataset (\textbf{Middle}), and eight-mode dataset (\textbf{Right}). 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). 
}
\label{fig:2_distribution}
\end{figure}

\subsection{Only Self-Consistency Term}\label{sec:app:self_consistency}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the target transport trajectory setting, we follow the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In the four-mode dataset, five-mode dataset, and eight-mode dataset, we all sample 100 points in each source mode and target mode. And in four-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $50$ training steps. In five-mode dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $50$ training steps. And in eight-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $50$ training steps. 
\begin{figure}[!ht]
\centering
\includegraphics[width=0.25\textwidth]{4_3_output.pdf}
\includegraphics[width=0.25\textwidth]{5_3_output.pdf}
\includegraphics[width=0.25\textwidth]{8_3_output.pdf}
\caption{
(C) The distributions generated by HOMO are only optimized by self-consistency term in the four-mode dataset (\textbf{Left}), five-mode dataset (\textbf{Middle}), and eight-mode dataset (\textbf{Right}). 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). 
}
\label{fig:3_distribution}
\end{figure}

\subsection{First Order Plus Second Order}\label{sec:app:first_order_plus_second_order}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the target transport trajectory setting, we follow the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In the four-mode dataset, five-mode dataset, and eight-mode dataset, we all sample 100 points in each source mode and target mode. And in four-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $1000$ training steps. In five-mode dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $2000$ training steps. And in eight-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $2000$ training steps. 
\begin{figure}[!ht]
\centering
\includegraphics[width=0.25\textwidth]{4_12_output.pdf}
\includegraphics[width=0.25\textwidth]{5_12_output.pdf}
\includegraphics[width=0.25\textwidth]{8_12_output.pdf}
\caption{
(A + B) The distributions generated by HOMO, optimized by first-order term and second-order term in four-mode dataset (\textbf{Left}), five-mode dataset (\textbf{Middle}), and eight-mode dataset (\textbf{Right}). 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). 
}
\label{fig:12_distribution}
\end{figure}


\subsection{Second Order Plus Self-Target}\label{sec:app:second_order_plus_self_target}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the target transport trajectory setting, we follow the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In the four-mode dataset, five-mode dataset, and eight-mode dataset, we all sample 100 points in each source mode and target mode. And in four-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $100$ training steps. In five-mode dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $100$ training steps. And in eight-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $100$ training steps. 
\begin{figure}[!ht]
\centering
\includegraphics[width=0.25\textwidth]{4_23_output.pdf}
\includegraphics[width=0.25\textwidth]{5_23_output.pdf}
\includegraphics[width=0.25\textwidth]{8_23_output.pdf}
\caption{
(B + C) The distributions generated by HOMO, optimized by second-order term and self-consistency term in four-mode dataset (\textbf{Left}), five-mode dataset (\textbf{Middle}), and eight-mode dataset (\textbf{Right}). 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). 
}
\label{fig:23_distribution}
\end{figure}

\subsection{First Order Plus Self-Target}\label{sec:app:first_order_plus_self_target}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the target transport trajectory setting, we follow the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In the four-mode dataset, five-mode dataset, and eight-mode dataset, we all sample 100 points in each source mode and target mode. And in four-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $1000$ training steps. In five-mode dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $1000$ training steps. And in eight-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $1000$ training steps. 
\begin{figure}[!ht]
\centering
\includegraphics[width=0.25\textwidth]{4_13_output.pdf}
\includegraphics[width=0.25\textwidth]{5_13_output.pdf}
\includegraphics[width=0.25\textwidth]{8_13_output.pdf}
\caption{
(A + C) The distributions generated by HOMO, optimized by first-order term and self-consistency term in four-mode dataset (\textbf{Left}), five-mode dataset (\textbf{Middle}), and eight-mode dataset (\textbf{Right}). 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). 
}
\label{fig:13_distribution}
\end{figure}

\subsection{HOMO}\label{sec:app:homo}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the target transport trajectory setting, we follow the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In the four-mode dataset, five-mode dataset, and eight-mode dataset, we all sample 100 points in each source mode and target mode. And in four-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $1000$ training steps. In five-mode dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $1000$ training steps. And in eight-mode dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $1000$ training steps. 
\begin{figure}[!ht]
\centering
\includegraphics[width=0.25\textwidth]{4_123_output.pdf}
\includegraphics[width=0.25\textwidth]{5_123_output.pdf}
\includegraphics[width=0.25\textwidth]{8_123_output.pdf}
\caption{
(A + B + C) The distributions generated by HOMO in four-mode dataset (\textbf{Left}), five-mode dataset (\textbf{Middle}), and eight-mode dataset (\textbf{Right}). 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). 
}
\label{fig:123_distribution}
\end{figure}


\section{Complex Distribution Experiment}\label{sec:app:complex_distribution_experiment}
In Section~\ref{sec:app:datasets2}, we introduce the datasets used in our experiments. The analysis of results with first-order and second-order terms in Section~\ref{sec:app:first_second}, and we evaluate the performance with first-order and self-consistency terms in Section~\ref{sec:app:first_third}, assess the impact of second-order and self-consistency terms in Section~\ref{sec:app:second_third}. Finally, we present the overall results of HOMO with all loss terms combined in Section~\ref{sec:app:homo2}.

\subsection{Datasets}\label{sec:app:datasets2}
Here, we introduce four datasets we proposed: circle dataset, irregular ring dataset, spiral line dataset, and spin dataset. In the circle dataset, we sample 600 points from Gaussian distribution with $0.3$ variance for both source distribution and target distribution. In the irregular ring dataset, we sample 600 points from Gaussian distribution with $0.3$ variance for both source distribution and target distribution. In the spiral line dataset, we sample 600 points from Gaussian distribution with $0.3$ variance for both source distribution and target distribution. In the spin dataset, we sample 600 points from the Gaussian distribution with $0.3$ variance for both source distribution and target distribution. 
\begin{figure}[!ht]
\centering
\includegraphics[width=0.2\textwidth]{center_to_circle_dataset.pdf}
\includegraphics[width=0.2\textwidth]{center_to_irregular_ring_dataset.pdf}
\includegraphics[width=0.2\textwidth]{spiral_dataset.pdf}
\includegraphics[width=0.2\textwidth]{new_spiral_dataset.pdf}
\caption{
The circle dataset(\textbf{Left most}), irregular ring dataset (\textbf{Middle left}), spiral line dataset (\textbf{Middle right}), and spin dataset (\textbf{Right most}). 
Our goal is to make HOMO to learn a transport trajectory from distribution $\pi_0$ ({\textbf{brown}}) to distribution $\pi_1$ ({\textbf{indigo}}). 
}
\label{fig:datasets}
\end{figure}

\subsection{First Order Plus Second Order}\label{sec:app:first_second}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the target transport trajectory setting, we follow the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In the circle dataset, we all sample 400 points, both source distribution and target distribution. In the irregular ring dataset, we all sample 600 points, both source distribution and target distribution. In the spiral line dataset, we all sample 300 points, both source distribution and target distribution. In circle dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $1000$ training steps. In irregular ring dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $1000$ training steps. In spiral line dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $1000$ training steps. In spiral line dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $1000$ training steps. 
\begin{figure}[!ht]
\centering
\includegraphics[width=0.2\textwidth]{12_circle_output.pdf}
\includegraphics[width=0.2\textwidth]{12_irr_circle_output.pdf}
\includegraphics[width=0.2\textwidth]{12_spiral_output.pdf}
\includegraphics[width=0.2\textwidth]{12_new_spiral_output.pdf}
\caption{
(M1+M2) \textbf{HOMO results on complex datasets with two kinds of loss: first-order and second-order terms.} The distributions generated by HOMO,
in circle dataset(\textbf{Left most}), irregular ring dataset (\textbf{Middle left}), spiral line dataset (\textbf{Middle right}) and spin dataset (\textbf{Right most}).  
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). }
\label{fig:m1_m2_appendix}
\end{figure}

\subsection{First Order Plus Self-Consistency Term}\label{sec:app:first_third}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the target transport trajectory setting, we follow the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In the circle dataset, we all sample 400 points, both source distribution and target distribution. In the irregular ring dataset, we all sample 600 points, both source distribution and target distribution. In the spiral line dataset, we all sample 300 points, both source distribution and target distribution. In circle dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $1000$ training steps. In irregular ring dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $1000$ training steps. In spiral line dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $1000$ training steps. In spiral line dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $1000$ training steps. 
\begin{figure}[!ht]
\centering
\includegraphics[width=0.2\textwidth]{13_circle_output.pdf}
\includegraphics[width=0.2\textwidth]{13_irr_circle_output.pdf}
\includegraphics[width=0.2\textwidth]{13_spiral_output.pdf}
\includegraphics[width=0.2\textwidth]{13_new_spiral_output.pdf}
\caption{
(M1+SC) \textbf{HOMO results on complex datasets with two kinds of loss: first-order and self-consistency terms.} The distributions generated by HOMO,
in circle dataset(\textbf{Left most}), irregular ring dataset (\textbf{Middle left}), spiral line dataset (\textbf{Middle right}) and spin dataset (\textbf{Right most}). 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). }
\label{fig:m1_sc_appendix}
\end{figure}

\subsection{Second Order Plus Self-Consistency Term}\label{sec:app:second_third}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the target transport trajectory setting, we follow the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In the circle dataset, we all sample 400 points, both source distribution and target distribution. In the irregular ring dataset, we all sample 600 points, both source distribution and target distribution. In the spiral line dataset, we all sample 300 points, both source distribution and target distribution. And in circle dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $100$ training steps. In irregular ring dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $100$ batch size, $0.005$ learning rate, and $1000$ training steps. In spiral line dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $100$ training steps. In spiral line dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $1000$ training steps. 
\begin{figure}[!ht]
\centering
\includegraphics[width=0.2\textwidth]{23_circle_output.pdf}
\includegraphics[width=0.2\textwidth]{23_irr_circle_output.pdf}
\includegraphics[width=0.2\textwidth]{23_spiral_output.pdf}
\includegraphics[width=0.2\textwidth]{23_new_spiral_output.pdf}
\caption{
(M2+SC) \textbf{HOMO results on complex datasets with two kinds of loss: second-order and self-consistency terms.} The distributions generated by HOMO,
in circle dataset(\textbf{Left most}), irregular ring dataset (\textbf{Middle left}), spiral line dataset (\textbf{Middle right}) and spin dataset (\textbf{Right most}). 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). }
\label{fig:m2_sc_appendix}
\end{figure}

\subsection{HOMO}\label{sec:app:homo2}
We optimize models by the sum of squared error(SSE). The source distribution and target distribution are all Gaussian distributions. For the target transport trajectory setting, we follow the VP ODE framework from~\cite{rectified_flow}, which is $x_t = \alpha_t x_0 + \beta_t x_1$. We choose $\alpha_t = \exp(-\frac{1}{4} a(1-t)^2 - \frac{1}{2} b(1-t))$ and $\beta_t = \sqrt{1 - \alpha_t^2}$, with hyperparameters $a = 19.9$ and $b = 0.1$. In the circle dataset, we all sample 400 points, both source distribution and target distribution. In the irregular ring dataset, we all sample 600 points, both source distribution and target distribution. In the spiral line dataset, we all sample 300 points, both source distribution and target distribution. And in circle dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $800$ batch size, $0.005$ learning rate, and $1000$ training steps. In irregular ring dataset training, we also use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1000$ batch size, $0.005$ learning rate, and $1000$ training steps. In spiral line dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $1000$ training steps. In spiral line dataset training, we use an ODE solver and Adam optimizer, with 2 hidden layer MLP, 100 hidden dimensions, $1600$ batch size, $0.005$ learning rate, and $1000$ training steps. 
\begin{figure}[!ht]
\centering
\includegraphics[width=0.2\textwidth]{123_circle_output.pdf}
\includegraphics[width=0.2\textwidth]{123_irr_circle_output.pdf}
\includegraphics[width=0.2\textwidth]{123_spiral_output.pdf}
\includegraphics[width=0.2\textwidth]{123_new_spiral_output.pdf}
\caption{
(M1+M2+SC) \textbf{HOMO results on complex datasets with three kinds of loss: first-order, second-order, and self-consistency terms.} The distributions generated by HOMO in circle dataset(\textbf{Left most}), irregular ring dataset (\textbf{Middle left}), spiral line dataset (\textbf{Middle right}), and spin dataset (\textbf{Right most}). 
The source distribution, $\pi_0$ ({\textbf{brown}}), and the target distribution, $\pi_1$ ({\textbf{indigo}}), are shown, along with the generated distribution ({\textbf{pink}}). }
\label{fig:m1_m2_sc_appendix}
\end{figure}
