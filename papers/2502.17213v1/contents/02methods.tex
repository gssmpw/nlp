\section{Methods}

\subsection{Problem Definition}
\label{sec:pdef}
In this survey, we classify neurological diagnostic tasks into sample-level classification and event-level classification, both of which fall under the broader framework of classification problems. 
Sample-level classification involves assigning a single label to an entire signal, which typically represents a specific subject or sample (e.g., Alzheimer’s disease diagnosis). 
By comparison, event-level classification focuses on identifying and classifying distinct temporal segments within a more extended signal, thereby introducing an implicit segmentation process by associating each segment with a specific event or state (e.g., seizure detection or sleep staging).

Electrical brain signals, which capture the brain's electrical activity over time, can be modeled as multivariate time series.
Specifically, let  $\mathbf{X} \in \mathbb{R}^{C \times T}$  represent the EEG/iEEG time series, where $C$ is the number of channels, and $T$ is the number of sampling points. Each channel  $\mathbf{x}^c = \{x^c_1, x^c_2, \dots, x^c_T\}$  corresponds to the measurements from a specific source, such as an EEG electrode or a contact of an iEEG electrode.

\subsubsection{Sample-Level Classification}
In sample-level classification, the objective is to assign a single label $y \in \mathcal{Y}$ to the entire signal $\mathbf{X}$. This can be formulated as:
\[
y = \Phi_{\text{sample}}(\mathbf{X}; \boldsymbol{\theta}), \quad y \in \mathcal{Y},
\]
where $\Phi_{\text{sample}}$ represents the deep learning model parameterized by $\boldsymbol{\theta}$, and $\mathcal{Y}$ denotes the set of possible classes. Here, $\mathbf{X}$ is treated as a unified entity, capturing sample-level or subject-level characteristics.

\subsubsection{Event-Level Classification}
In event-level classification, the goal is to classify smaller temporal segments of the signal. The signal $\mathbf{X}$ is divided into $K$ segments $\mathbf{X}_1, \mathbf{X}_2, \dots, \mathbf{X}_K$, where $\mathbf{X}_k \in \mathbb{R}^{C \times T_k}$ and $T_k$ is the duration of the $k$-th segment. A classification model is applied to each segment to produce a sequence of labels $\mathbf{Y} = \{y_1, y_2, \dots, y_K\}, \, y_k \in \mathcal{Y}$:
\[
y_k = \Phi_{\text{segment}}(\mathbf{X}_k; \boldsymbol{\theta}), \quad \mathbf{Y} = \bigcup_{k=1}^K \{y_k\},
\]
where $\Phi_{\text{segment}}$ denotes the deep learning model parameterized by $\boldsymbol{\theta}$. This process associates each segment $\mathbf{X}_k$ with a specific label $y_k$, allowing the temporal localization of events within the signal.
Event-level classification captures natural temporal dependencies between consecutive segments, reflecting the continuity of events in time~\cite{chen2024con4m}.

\subsection{Signal Collection}
EEG have evolved significantly since Hans Berger first recorded EEG signals from the human scalp in 1924~\cite{berger1929elektroenkephalogramm}.
While EEG signals are typically collected non-invasively using scalp electrodes placed according to the 10-20 system~\cite{jasper1958ten},
more recent studies employ higher-density EEG electrode configurations for enhanced spatial resolution and detailed brain activity mapping.
EEG captures brain oscillations across frequency bands, each linked to specific neural states: delta (deep sleep), theta (light sleep), alpha (relaxation), beta (focus), and gamma (higher cognition)~\cite{buzsaki2004neuronal}.
Depending on the study, participants may perform tasks or rest to elicit relevant brain activity. Resting-state EEG evaluates baseline activity, while specific tasks can highlight disease-related abnormalities~\cite{jeong2004eeg}.

iEEG involves implanting electrodes either within deep and superficial brain structures via burr holes (SEEG) or on the brain’s surface by placing grids during craniotomy (ECoG).
Compared to EEG, iEEG offers excellent spatial resolution and reduced susceptibility to artifacts from scalp muscle activity and eye movements.
SEEG allows recording from deep and distributed brain regions with minimal invasiveness, while ECoG provides higher spatial resolution for cortical surface activity due to its densely packed electrode grids. 
However, iEEG can still be affected by cardiac artifacts, electrode shifts, and other forms of noise. Rigorous preprocessing techniques are essential to ensure the accuracy and reliability of EEG and iEEG signals in clinical and research applications.

\subsection{Signal Preprocessing}

\begin{table}[]
\renewcommand{\arraystretch}{1.2}
\caption{Signal Preprocessing Techniques}
\label{tab:lowlevel}
\footnotesize
\centering
\begin{tabular}{p{80pt}p{90pt}p{30pt}}
\hline
\textbf{Techniques}     & \textbf{Details}             & \textbf{Reference}             \\
\hline
\multirow{4}{80pt}{Noise Reduction \& Filtering} 
                            & FIR Filter           & ~\cite{banville2021uncovering}  \\
                            & IIR Filter           & ~\cite{oh2020deep} \\
                            & Adaptive Filters     & ~\cite{9353630}\\
                            & Manual \& Custom     & ~\cite{ay2019automated} \\
\hline
\multirow{2}{80pt}{Artifact Removal} 
                            & Blind Source Separation  & ~\cite{10023506} \\
                            & Artifact Correction  & ~\cite{MOGHADDARI2020105738} \\
\hline
\multirow{3}{80pt}{Baseline Correction \& Detrending} 
                            & Baseline Correction  & ~\cite{sun2021hybrid} \\
                            & Baseline Removal     & ~\cite{nouri2024detection} \\
                            & Detrending           & ~\cite{Seizure49} \\
\hline
\multirow{3}{80pt}{Channel Processing} 
                            & Channel Selection    & ~\cite{wen2018deep} \\
                            & Channel Mapping      & ~\cite{Kostas2021BENDR} \\
                            & Re-Referencing       & ~\cite{nouri2024detection} \\
\hline
\multirow{3}{80pt}{Normalization \& Scaling} 
                            & Z-Normalization      & ~\cite{ACHARYA2018270} \\
                            & Quantile Normalization & ~\cite{ko2022eeg} \\
                            & Scaling \& Shifting  & ~\cite{Kostas2021BENDR} \\
\hline
\multirow{4}{80pt}{Sampling Adjustment} 
                            & Downsampling         & ~\cite{mousavi2019deep} \\
                            & Resampling           & ~\cite{ZHANG2020105089} \\
                            & Interpolation        & ~\cite{SZ27} \\
                            & Imputation           & ~\cite{sharma2021dephnn} \\
\hline
\multirow{1}{80pt}{Segmentation} 
                            & Windowing            & ~\cite{seal2021deprnet} \\
\hline
\multirow{2}{80pt}{Signal Alignment \& Synchronization} 
                            & Time Synchronization & ~\cite{iwama2023two} \\
                            & Temporal Alignment   & ~\cite{iwama2023two} \\
\hline
\end{tabular}
\end{table}


EEG/iEEG signals require low-level preprocessing to address challenges such as noise and artifact removal, normalization for consistency, and segmentation into analyzable time windows.
These steps refine raw data, ensuring it accurately reflects brain activity and provides a robust foundation for analysis.
Representative methods are summarized in Table~\ref{tab:lowlevel}, with one key work per category highlighted.
%given space constraints.}

\subsubsection{Noise Reduction and Filtering}
Filtering techniques, such as Finite Impulse Response (FIR) and Infinite Impulse Response (IIR) filters, are employed to isolate specific frequency components. Advanced methods like MSEC noise reduction and wavelet transforms~\cite{ay2019automated} provide specialized solutions for effective denoising and precise data refinement.

\subsubsection{Artifact Removal} 
Artifact removal strategies include Blind Source Separation techniques, such as Independent Component Analysis (ICA), Principal Component Analysis (PCA), and Multiple Component Analysis (MCA)~\cite{9047940}, along with Artifact Correction methods, including Ocular Correction and Artifact Subspace Reconstruction. Wavelet decomposition is also commonly used mitigate artifacts.

\subsubsection{Baseline Correction and Detrending} 
Baseline correction and detrending address baseline drift caused by eye movements, breathing, and subject motion. Baseline correction standardizes power data, baseline removal reduces subject-independent noise, and detrending eliminates linear or nonlinear trends, enhancing signal reliability.

\subsubsection{Channel Processing} 
Neurological disorders often affect specific brain regions, making channel processing techniques, including selection, mapping, and re-referencing, essential for enhancing the specificity and interpretability of analyses.

\subsubsection{Normalization and Scaling}
Normalization standardizes the amplitude of raw EEG and iEEG signals, which often vary in voltage. Common methods include Z-score and quantile normalization, while linear scaling and shifting minimize spurious amplitude variations across channels.

\subsubsection{Sampling Adjustment}
Sampling adjustments optimize data for analysis while reducing computational demands. Downsampling reduces memory and processing requirements, whereas interpolation handles missing data, insufficient training samples, and pulse artifacts~\cite{Tuncer2020ANE}.

\subsubsection{Segmentation}
Segmentation divides EEG and iEEG data into smaller sections for localized information extraction and data augmentation to enhance sample diversity.
Overlap windows ensure continuity and capture transitional features, while non-overlapping segments prioritize computational efficiency and maintain distinct temporal boundaries.
% Techniques like epoching and sliding windows enhance analysis depth, though they may increase computational complexity.

\subsubsection{Signal Alignment and Synchronization}
Signal alignment ensures temporal consistency across signals from different sources, improving the reliability of findings. Fine-grained temporal alignment further corrects residual discrepancies after initial synchronization, ensuring data precision.



\subsection{Feature Extraction}

\begin{table}[t]
\renewcommand{\arraystretch}{1.2}
\caption{Feature Extraction Techniques}
\label{tab:highlevel}
\footnotesize
\centering
\begin{tabular}{p{80pt}p{90pt}p{30pt}} % 第一列和第二列设置固定宽度，自动换行
\hline
\textbf{Techniques}     & \textbf{Details}                 & \textbf{Reference}             \\
\hline
\multirow{2}{80pt}{Data Augmentation} & Oversampling                     & ~\cite{ZHANG2020105089}         \\
                                       & ELM-AE                           & ~\cite{9713847}                 \\
\hline
\multirow{2}{80pt}{Signal Decomposition \& Transformation} 
                                       & Time-Frequency Analysis          & ~\cite{PD2} \\
                                       & Empirical Decomposition          & ~\cite{zulfikar2022empirical}   \\
\hline
\multirow{3}{80pt}{Spectral \& Power Analysis}  
                                       & Power Spectrum                   & ~\cite{li2019eeg}               \\
                                       & Spectral Density                 & ~\cite{Seizure214}        \\
                                       & Partial Directed Coherence       & ~\cite{khan2021automated}       \\
\hline
\multirow{3}{80pt}{Time-Domain Features Extraction}  
                                       & Statistical Measures             & ~\cite{zhu2019multimodal}       \\
                                       & Amplitude \& Range               & ~\cite{Seizure7}    \\
                                       & Hjorth Parameters                & ~\cite{li2019depression}             \\
\hline
\multirow{2}{80pt}{Frequency-Domain Features Extraction}  
                                       & Band Power Features              & ~\cite{Seizure67}        \\
                                       & Spectral Measures                & ~\cite{tosun2021effects}        \\
\hline
\multirow{3}{80pt}{Time-Frequency Features Extraction}  
                                       & Wavelet Coefficients             & ~\cite{aslan2022deep}           \\
                                       & STFT Features                    & ~\cite{choi2019novel}           \\
                                       & Multitaper Spectral              & ~\cite{vilamala2017deep}        \\
\hline
\multirow{3}{80pt}{Other Features Extraction}  
                                       & Nonlinear Features               & ~\cite{Seizure109}        \\
                                       & Spatial Features                 & ~\cite{phang2019multi} \\
                                       & Transform-Based Features         & ~\cite{electronics11142265} \\
\hline
\multirow{2}{80pt}{Graph Analysis}                                                         & Clustering Coefficient           & ~\cite{Zhan2020EpilepsyDetection}       \\
                                       & Other Graph Metrics              & ~\cite{ho2023self}   \\
\hline
\end{tabular}
\end{table}

Feature extraction techniques reconfigure data into alternative representations by isolating key features or decomposing it into core components essential for modeling and analysis. This process effectively primes the data for more sophisticated, abstract analytical tasks.
Representative methods are summarized in Table~\ref{tab:highlevel}, with one key work per category highlighted.
%given space constraints.}

\subsubsection{Data Augmentation}
Data augmentation generates new samples to increase dataset diversity and improve classification accuracy and stability. Oversampling is commonly used to address class imbalances, while the Extreme Learning Machine Autoencoder (ELM-AE) employs autoencoders to synthesize data by reconstructing input features~\cite{9713847}.

\subsubsection{Spectral and Power Analysis}
Spectral and power analysis focuses on examining the frequency components and energy distribution of signals.
Key techniques include power spectrum calculation, frequency band energy analysis, and partial-directed coherence for evaluating signal causality.

\subsubsection{Time Domain Feature Extraction}
Time domain features, such as statistical measures, Hjorth parameters, and Zero-Crossing Rate, effectively represent signal amplitude, time scale, and complexity. These features provide valuable insights into signal distribution, intensity, and rate of change.

\subsubsection{Frequency Domain Feature Extraction}
Frequency domain features, such as band power, band energy, median frequency, spectral edge frequency, and power spectral density (PSD), provide insights into the spectral content of signals.

\subsubsection{Time-Frequency Feature Extraction}\
Time-frequency features capture both temporal and spectral information, providing a comprehensive signal representation.
Short-time Fourier Transform (STFT) analyzes frequency variations over time, while Continuous and Discrete Wavelet Transforms (CWT, DWT) offer detailed time-frequency representations.
Advanced techniques like FBSE-EWT filter banks~\cite{9096344} and Smoothed Pseudo Wigner Ville Distribution (SPWVD)~\cite{Ebrahimzadeh2013ANA} enhance analysis precision.

\subsubsection{Other Feature Extraction}
Nonlinear features, such as entropy measures, fractal dimensions, and Lyapunov exponents, capture complex patterns that linear methods may miss. Spatial features, including Common Spatial Patterns and connectivity measures like phase-locking value (PLV) and phase-lag index (PLI), represent spatial domain activities. 
Transform-based features further enhance analysis by reconstructing signals into more informative representations.

\subsubsection{Signal Decomposition and Transformation}
Signal decomposition and transformation techniques decompose complex signals to facilitate detailed analysis, such as wavelet transforms, Gabor Transform~\cite{PD2}, Fast Fourier Transform, Empirical Mode Decomposition, and Hilbert-Huang Transform.

\subsubsection{Graph Analysis}
Graph analysis evaluates connectivity between channels. Metrics like degree measure connections and node importance, while the clustering coefficient quantifies local network density, revealing network structure.


\subsection{Data Partitioning Strategies}

Building on the detailed definition of \(\mathbf{X}^{(i)} \in \mathbb{R}^{C \times T}\) in Section~\ref{sec:pdef}, where \(\mathbf{X}^{(i)}\) represents the EEG or iEEG signal of subject \(i\), we further introduce additional notations to formalize the data partitioning strategies:

\begin{itemize}
    \item \(\mathcal{P} = \{1, 2, \dots, N\}\): The set of \(N\) subjects in the dataset.
    \item \(\mathcal{X}_\text{train}, \mathcal{X}_\text{val}, \mathcal{X}_\text{test}\): The training, validation, and testing sets, respectively.
    \item \(\alpha_\text{train}, \alpha_\text{val}, \alpha_\text{text}  \in (0, 1)\): The proportion of data used for training, validation and test, and \(\alpha_\text{train} + \alpha_\text{val} + \alpha_\text{test} = 1.\)
    \item \(K^{(i)}\): The total number of temporal segments or events derived from subject \(i\)'s data.
\end{itemize}

Using these definitions, we classify data partitioning strategies into three categories: subject-specific methods, mixed-subject methods, and cross-subject methods.

\subsubsection{Subject-Specific Methods}
Subject-specific methods focus on capturing individual characteristics by partitioning each subject’s data independently into training, validation, and testing sets. Formally,
\[
\mathcal{X}_\text{train} \cup \mathcal{X}_\text{val} \cup \mathcal{X}_\text{test} = \{\mathbf{X}_k^{(i)}\}_{k=1}^{K^{(i)}},
\]
where \(i\) denotes a specific subject. This method is particularly useful in the early stages of development, as it enables rapid iteration on small datasets and captures individual patient patterns. It is commonly used in closed-loop seizure detection systems, where personalization is critical.

\subsubsection{Mixed-Subject Methods}
Mixed-subject methods leverage signals from all subjects in \(\mathcal{P}\) for training, validation, and testing, aiming to create models with broad applicability. 
The data partitioning method is as follows:
\[
\mathcal{X}_\text{set} \subset \bigcup_{i \in \mathcal{P}} \bigcup_{k=1}^{K^{(i)}} \{\mathbf{X}^{(i)}_k\}, \quad
|\mathcal{X}_\text{set}| = \alpha_\text{set} \sum_{i=1}^{N} K^{(i)},
\]
where \(\text{set} \in \{\text{train}, \text{val}, \text{test}\}\).
By pooling data across subjects, this approach maximizes training efficiency and improves the model’s robustness to inter-subject variability. However, it also introduces the risk of data leakage, as segments from the same subject may appear in different sets.

\subsubsection{Cross-Subject Methods}
Clinical applications demand models that generalize across unseen patients. Cross-subject methods explicitly enforce subject separation between training, validation, and testing by partitioning $\mathcal{P}$ into disjoint subsets:

\[
|\mathcal{P}_\text{set}| = \alpha_\text{set} |\mathcal{P}|, \quad
\mathcal{X}_\text{set} = \bigcup_{i \in \mathcal{P}_\text{set}} \bigcup_{k=1}^{K^{(i)}} \{\mathbf{X}^{(i)}_k\},\
\]
where \(\text{set} \in \{\text{train}, \text{val}, \text{test}\}\).
This ensures that models are evaluated on entirely unseen subjects. 
%Among the three approaches, cross-subject partitioning is the most clinically relevant, aligning closely with real-world deployment scenarios.

Extending subject-level partitioning strategies, dataset-level partitioning includes three approaches: \textbf{dataset-specific} (independent partitioning per dataset), \textbf{mixed-dataset} (pooling data across datasets), and \textbf{cross-dataset} (disjoint datasets for training, validation, and testing). Dataset-specific methods capture individual dataset characteristics, while mixed-dataset methods enhance robustness to inter-dataset variability. Cross-dataset partitioning is crucial for universal models, rigorously assessing generalization and closely aligning with real-world clinical deployment.

\subsection{Deep Learning Architectures}
Neurological data processing relies on several key architectures:
\textbf{Convolutional Neural Networks (CNNs)}~\cite{lecun1995convolutional} excel at extracting spatial/spectral features through hierarchical convolutions.
\textbf{Recurrent Neural Networks (RNNs)}~\cite{elman1990finding} capture temporal dependencies via recurrent connections.
\textbf{Transformers}~\cite{vaswani2017attention} model long-range spatiotemporal relationships using self-attention.
\textbf{Graph Neural Networks (GNNs)}~\cite{4700287} analyze functional connectivity in graph-structured data.
\textbf{Autoencoders (AEs)}~\cite{hinton1993autoencoders} learn compressed representations through encoder-decoder structures.
\textbf{Generative Adversarial Networks (GANs)}~\cite{goodfellow2014generative} synthesize signals through adversarial training.
\textbf{Spiking Neural Networks (SNNs)}~\cite{maass1997networks} leverage spike-based computation for temporal dynamics.


\subsection{Deep Learning Paradigms}
Deep learning applications in neurological diagnostics can be categorized into four paradigms: supervised learning, self-supervised learning, unsupervised learning, and semi-supervised learning.
Each paradigm addresses specific challenges in processing brain signals by leveraging architectures tailored to data availability and task requirements.
These paradigms will be further discussed in detail in Section~\ref{sec:app}.

\subsubsection{Supervised Learning}
Supervised learning is the dominant paradigm for neurological diagnostics tasks, training models to map signals $ \mathbf{X} \in \mathbb{R}^{C \times T} $ to labels $y \in \mathcal{Y} $.
%Common architectures include Convolutional Neural Networks (\textbf{CNNs})~\cite{lecun1995convolutional} for feature extraction,
%Recurrent Neural Networks (\textbf{RNNs})~\cite{elman1990finding} for modeling temporal dependencies,
%and \textbf{Transformers}~\cite{vaswani2017attention} for handling complex spatiotemporal relationships with attention mechanisms.

\subsubsection{Unsupervised Learning}
Unsupervised learning is essential for uncovering intrinsic data structures in signals $\mathbf{X}$, enabling representation learning without relying on labels. 
%Common architectures include Autoencoders (\textbf{AE})~\cite{hinton1993autoencoders} for encoding features and reducing dimensionality, Generative Adversarial Networks (\textbf{GANs})~\cite{goodfellow2014generative} for synthesizing realistic data in low-resource scenarios,
%and Spiking Neural Networks (\textbf{SNNs})~\cite{maass1997networks} for modeling  spatiotemporal dynamics in signals.

\subsubsection{Semi-Supervised Learning}
Semi-supervised learning combines a small set of labeled examples $\{(x_i, \hat{y}_i)\}_{i=1}^l$, where $\hat{y}_i$ denotes the provided labels, with a larger set of unlabeled examples $\{x_j\}_{j=l+1}^{l+u}$ to learn a mapping from $\mathbf{X}$ to $\mathcal{Y}$. 
%Common architectures include Graph Neural Networks (\textbf{GNNs})~\cite{4700287}, \textbf{CNNs}, and \textbf{RNNs}. 

\subsubsection{Self-Supervised Learning}
Self-supervised learning (SSL) leverages unlabeled EEG/iEEG data by constructing pretext tasks that generate pseudo-labels $\hat{y}$ from intrinsic properties of the raw signals $\mathbf{X}$. These tasks enable models to learn robust representations, which can be fine-tuned for downstream tasks.
SSL methods fall into three main categories: contrastive, predictive, and reconstruction-based learning.
\textbf{Contrastive-based methods}, such as Contrastive Predictive Coding (CPC)~\cite{banville2021uncovering} and Transformation Contrastive Learning~\cite{mohsenvand2020contrastive}, learns by maximizing similarity between related views while minimizing it between unrelated ones, capturing distinguishing signal features.
\textbf{Predictive-based learning} employs pretext tasks such as Relative Positioning and Temporal Shuffling to extract structural patterns across temporal, frequency, and spatial domains~\cite{banville2019self, oord2018representation}. By predicting transformations applied to the data, it enhances domain-specific feature learning.
\textbf{Reconstruction-based learning} trains models to reconstruct masked signal segments. Methods like Masked Autoencoders (MAE) reconstruct temporal or spectral components, learning intrinsic patterns in the process~\cite{Kostas2021BENDR, wu2022neuro2vec}.
Studies have also explored hybrid methods, which combine elements from contrastive, predictive, and reconstruction-based approaches~\cite{cai2023mbrain, banville2021uncovering}.
%\textbf{Transformers} and \textbf{CNNs} are the primary architectures used in this paradigm.