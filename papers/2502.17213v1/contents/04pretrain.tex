

%	•	CL: Contrastive Learning
%	•	CPC: Contrastive Predictive Coding
%	•	MAE: Masked Autoencoding

\section{Universal Pre-trained Models}
\label{sec:bm}

In recent years, SSL has revolutionized EEG/iEEG analysis in neurological diagnosis. Emerging methods focus on generalizable SSL frameworks that integrate heterogeneous datasets during pre-training, overcoming the limitations of task- and dataset-specific models and enabling seamless adaptation to multiple downstream tasks.
%This paradigm shift is driven by the need for more realistic and robust solutions in neurological diagnostics. These methods enable models to learn richer and more generalizable representations by leveraging multiple datasets and other physiological signals. 
%Such frameworks can adapt seamlessly to various clinical tasks, including Seizure detection, sleep stage classification, and mental health assessment, without being constrained by the specific characteristics of individual datasets. 
These innovations bring us closer to the development of universal neurodiagnostic models capable of addressing challenges across diverse clinical settings.

Table~\ref{tab:pts} summarizes pre-trained SSL frameworks for multi-task neurodiagnosis, organized by the SSL paradigms to align with their technical evolution analyzed in this section. 
While some frameworks extend to broader time-series data, such as BCI signals and motion sensor data, we focus on datasets and tasks directly relevant to neurological applications.
Below, we further explore these frameworks, examining their contributions to unified pre-training strategies, multitask adaptability, and their potential to impact real-world applications.

%\textbf{Contrastive learning} methods establish positive and negative pairings to learn robust representations by optimizing agreement between related views and reducing it between unrelated ones. This paradigm effectively captures meaningful features from EEG by promoting models to concentrate on intrinsic patterns that differentiate between similar and dissimilar data.
\subsection{Contrastive- and Predictive- Based Learning}
\paragraph{Contrastive Predictive Coding}
Early SSL approaches in EEG/iEEG analysis are largely based on the Contrastive Predictive Coding (CPC) paradigm~\cite{banville2021uncovering,cai2023mbrain}, which learns robust representations by predicting signal segments through contrastive learning. While these models employed generic architectures across neurophysiological tasks, they fail to achieve true cross-task generalization. As a result, they are trained separately on specific datasets, limiting their clinical applicability across diverse neurodiagnostic applications.
CPC variants like TS-TCC~\cite{eldele2021time} introduce a one-to-one feature transfer mechanism. This framework enables feature migration across tasks such as human activity recognition, sleep staging, and epileptic seizure detection, paving the way for broader multi-domain diagnostic generalization.


Building on the foundational principles of CPC, two distinct approaches have emerged: contrastive learning (CL) and predictive-based variants. CL retains CPC’s contrastive framework but emphasizes explicit instance-level discrimination through hand-crafted augmentations for positive/negative pairs, instead of CPC’s autoregressive future state prediction.
Predictive variants inherit CPC’s structure but replace its auto-learned latent contexts with manually defined features.

\paragraph{Contrastive-Based learning}
SeqCLR~\cite{mohsenvand2020contrastive}, inspired by SimCLR, employs contrastive learning to EEG data, enhancing similarity between augmented views of the same channel through domain-specific transformations. Adopting a mixed-dataset training approach, it unifies diverse EEG datasets for robust representation learning.
TF-C~\cite{zhang2022self} incorporates dual time-frequency contrastive learning with a cross-domain consistency loss to align embeddings across temporal and spectral representations.
It further evaluates one-to-many paradigms, highlighting the potential of cross-task feature sharing for universal neural signal models.
BIOT~\cite{yang2024biot} integrates contrastive learning, unifying multimodal biosignals (e.g., EEG, ECG) via tokenization and linear attention to learn invariant physiological patterns for cross-task generalization.

\paragraph{Predictive-Based Learning}
Jo et al.~\cite{jo2023channel} proposes a channel-aware predictive-based framework, which leverages stopped band prediction for spectral feature learning and employs temporal trend identification to capture dynamic patterns. 
By integrating mix-dataset pretraining, it enhances generalization through cross-domain feature fusion. However, the pretraining scale remains limited.

%\textbf{Masked modeling} focuses on reconstructing missing or masked portions of the signal, forcing the model to learn intrinsic patterns in the data. This paradigm is particularly effective in extracting multi-grained features across temporal and spectral dimensions.
\subsection{Reconstruction-Based Learning}
\paragraph{Masked Autoencoding}
The paradigm shift from CPC to masked reconstruction in SSL aims for higher data efficiency and scalability, inspired by cross-domain advances like masked language modeling in NLP (e.g., BERT~\cite{devlin2018bert}), with MAE's generative approach enhancing classification performance while avoiding complex negative sampling.
%This transition is further accelerated by the proven scalability and strong generalization of transformer architectures, enabling larger models and unified multitask learning frameworks.

Neuro2vec~\cite{wu2022neuro2vec} extends masked reconstruction by integrating EEG-specific spatiotemporal recovery and spectral component prediction into a unified framework, utilizing a CNN-ViT hybrid architecture for patch embedding and reconstruction. 
CRT~\cite{zhang2023self} further introduces multi-domain reconstruction through cross-domain synchronization of temporal and spectral features, replacing conventional masking with adaptive input dropping to preserve data distribution integrity, thereby improving robustness in physiological signal modeling.
Neuro-BERT~\cite{wu2024neuro} introduces Fourier Inversion Prediction (FIP), reconstructing masked signals by predicting their Fourier amplitude and phase, then applying an inverse Fourier transform. The spectral-based prediction framework inherently matches the physiological nature of EEG signals.

\paragraph{Large-Scale Continuous-Reconstruction Models}
Transformer architectures excel in neurodiagnostics due to their scalability and attention mechanisms, which adaptively capture global dependencies in irregular neural signals. BERT-style pretraining, particularly masked reconstruction, enhances neurodiagnostic classification by enforcing robust contextual learning of latent bioelectrical patterns, which is crucial for distinguishing subtle neurological signatures. Their parallelizable training and tokenized time-frequency representations pave the way for scalable foundation models, driving large-scale pretraining in neural signal analysis.

Inspired by Bert, BENDR~\cite{Kostas2021BENDR} integrates CPC with MAE-inspired reconstruction for temporal feature learning. 
Pretrained on the Temple University Hospital EEG Corpus (TUEG)—a diverse dataset containing 1.5 TB of raw clinical EEG recordings from over 10,000 subjects—BENDR represents the emergence of large-scale pretraining for neurodiagnostics, showcasing the cross-subject scalability of transformers. 
It demonstrates how foundation models can unify heterogeneous neural signal paradigms, advancing generalized and scalable EEG analysis.
CBRAMOD~\cite{wang2024cbramod} introduces a criss-cross transformer framework to explicitly model EEG’s spatial-temporal heterogeneity.
Using patch-based masked EEG reconstruction, it separately processes spatial and temporal patches through parallel attention mechanisms, preserving the structural dependencies unique to EEG.

Brant~\cite{zhang2024brant} and Brainwave~\cite{yuan2024brainwavebrainsignalfoundation}
represent a unified effort to establish foundation models for neural signal analysis. 
Brant focuses on SEEG signals, employing a masked autoencoding framework with dual Transformer
encoders to capture temporal dependencies and spatial
correlations, enabling applications such as seizure detection and signal forecasting.
Brainwave pioneers large-scale pretraining with an unprecedented multimodal corpus of over 40,000 hours of EEG and iEEG data from 16,000 subjects, marking a significant milestone in neural signal foundation models. Its pre-training strategy follows a masked modeling paradigm that randomly masks time-frequency patches of neural signals, and the model is trained to reconstruct the missing regions. To enhance generalizability across different types of neural data, Brainwave employs a shared encoder for both EEG and iEEG, coupled with modality-specific reconstruction decoders. These innovations position Brainwave as the first comprehensive foundation model capable of unifying EEG and iEEG analysis, with transformative implications for neuroscience research.
%The framework demonstrates strong performance in downstream tasks, excelling in cross-subject, cross-hospital, and cross-subtype evaluations.
\paragraph{Large-Scale Discrete-Reconstruction Models}
Vector Quantized Variational Autoencoder (VQ-VAE) is a powerful framework for learning discrete representations of continuous data by mapping inputs to a predefined codebook, which has been widely adopted in domains like speech and image processing~\cite{van2017neural}. By tokenizing raw data into discrete codes, this approach enhances cross-subject generalization while preserving interpretable spatiotemporal patterns.

LaBraM~\cite{jiang2024large} trains its discrete codebook by reconstructing both Fourier spectral magnitudes and phases of EEG segments, then pretrains with a symmetric masking task that predicts masked code indices bidirectionally.
NeuroLM~\cite{jiang2024neurolm} further extends this approach by introducing VQ Temporal-Frequency Prediction, aligning EEG tokens with textual representations through adversarial training. After tokenization, it employs multi-channel autoregressive modeling, enabling an LLM to predict the next EEG token in a manner analogous to language modeling.
EEGFormer~\cite{chen2024eegformer} focuses on reconstructing raw temporal waveforms for codebook training, followed by BERT-style masked signal reconstruction pretraining.
These methods demonstrate how VQ-based tokenization adapts to EEG modeling—whether prioritizing spectral synchrony (LaBraM), fusing time-frequency features (NeuroLM), or preserving temporal fidelity (EEGFormer).

\subsection{BrainBenchmark}
The development of universal pre-trained frameworks represents a transformative advancement in healthcare, enabling the integration of heterogeneous datasets and generalization across diverse diagnostic tasks.
To systematically evaluate and advance this field, we have established an open benchmark, currently comprising 8 models and 9 public datasets focused on neurological diagnostics, with ongoing expansions planned. 
This benchmark supports comprehensive performance evaluation, custom model integration, and dataset extensibility, fostering reproducible research and innovation. The implementation is publicly available at \href{https://github.com/ZJU-BrainNet/BrainBenchmark}{https://github.com/ZJU-BrainNet/BrainBenchmark}. 
Future work will include a detailed analysis of benchmark results to further advance universal frameworks in EEG/iEEG analysis.