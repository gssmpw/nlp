\section{Applications}
\label{sec:app}



\begin{table*}[t]
\centering
\renewcommand{\arraystretch}{1.2}
\caption{Public EEG/iEEG datasets for seizure detection, with \textbf{Seizures} indicating the number of episodes, \textbf{Length} the duration of each record, and \textbf{Size} the total duration of recording.}
\label{tab:ep}
\footnotesize
\begin{tabular}{lccccccc}
\hline
\textbf{Dataset} & \textbf{Type} &  \textbf{Subjects} &  \textbf{Seizures} & \textbf{Length} & \textbf{Size} &  \textbf{Frequency (Hz)} &  \textbf{Channels} \\ \hline
Bonn~\cite{andrzejak2001indications}             & EEG & {10}                                 & {-}       & {23.6 sec}          & {$\approx$ 3.3 hours}                           & {173.61}                   & {1}               \\
Freiburg~\cite{ihle2012epilepsiae}         & iEEG & {21}            & {87}         & {4 sec}         & {$\approx$ 504 hours }         & {256}                      & {128}               \\
Mayo-UPenn~\cite{seizure-detection}       & iEEG & {2}                                  & {48}                    & {1 sec}           & {583 min}                         & {500-5000}                 & {16-76}             \\
CHB-MIT~\cite{guttag2010chb,shoeb2009application,goldberger2000physiobank}          & EEG & {22}                                 & {198}          & {1 hour}                    & {$\approx$ 686 hours}                    & {256}                      & {23 / 24 / 26}         \\
Bern-Barcelona~\cite{andrzejak2012nonrandomness}   & iEEG & {5}                                  & {3750}              & {20 sec}               & {57 hours}                        & {512}                      & {64}                \\
Hauz Khas~\cite{hauz}        & EEG & {10}                                 & {-}       & {5.12 sec}          & {87 min}                           & {200}                      & {50}                \\
Melbourne~\cite{melbourne}        & iEEG & {3}                                  & {-}      & {10 min}             & {81.25 hours}                            & {400}                      & {184}               \\
TUSZ~\cite{shah2018temple}             & EEG & {642}                                & {3050}               & {-}              & {700 hours}                         & {250}                      & {19}                \\
SWEC-ETHZ~\cite{burrello2018oneshot,burrello2019hdc} 
        & iEEG           & 18 / 16 & 244 / 100 & 1 hour / 3 min & 2656 hours / 48 min & 512 / 1024 & 24-128 / 36-100 \\
Zenodo~\cite{stevenson2019dataset}         & EEG & {79}                                 & {1379}                  & {74 min}           & {$\approx$ 97 hours}                    & {256}                      & {21}                \\
Mayo-Clinic~\cite{Nejedly2020}      & iEEG & {25}                                 & {-}           & {3 sec}      & {50 hours}                          & {5000}                     & {1}                 \\
FNUSA~\cite{Nejedly2020}           & iEEG & {14}                                 & {-}        & {3 sec}         & {7 hours}                           & {5000}                     & {1}                 \\
Siena~\cite{detti2020eeg}            & EEG & {14}                                 & {47}                  & {145-1408 min}             & {$\approx$ 128  hours}                         & {512}                      & {27}                \\
Beirut~\cite{nasreddine2021epileptic}           & EEG & {6}                                  & {35}        & {1 sec}                       & {130 min}                          & {512}                      & {19}                \\
HUP~\cite{HUP}              & iEEG & {58}                                 & {208}                       & {300 sec}       & {$\approx$ 27 hours}                    & {500}                      & {52-232}            \\
CCEP~\cite{ds004080:1.2.4} & iEEG & {74} & {-} & {-} & {89 hours} & {2048} & {48-116} \\  \hline
\end{tabular}
\end{table*}

This section systematically reviews neurological disease diagnosis methodologies. Each subsection starts with an introduction to the disease’s background, including its characteristics, diagnostic tasks, and relevant public datasets. We will then review representative works for each disease, highlighting disease-specific features in the context of deep learning-based diagnosis, such as data types, frequency bands, brain regions, and methodological trends. 
Given their extensive research history, seizure detection and sleep staging receive dedicated sections, while other disorders are analyzed through focused comparative discussions to eliminate redundancy. Technical implementation details across studies (preprocessing pipelines, network architectures, training protocols) are systematically cataloged in supplementary tables.

\subsection{Seizure Disorder}


\subsubsection{Task Description}
Epilepsy, a neurological disorder affecting 50 million people globally, is characterized by recurrent seizures caused by abnormal brain activity. 
Seizures range from brief confusion or blanking out to severe convulsions and loss of consciousness. According to the World Health Organization (WHO), up to 70\% of epilepsy cases can be effectively treated with proper care. However, in low-income regions, limited resources and stigma often hinder access to treatment, heightening the risk of premature death\cite{WHO_epilepsy}.

Seizure detection primarily relies on standardized EEG/iEEG datasets, summarized in Table~\ref{tab:ep}. The key challenge is distinguishing seizure events from background activity, typically framed as binary classification where $y_k \in \{0, 1\}$. 
Most approaches segment long EEG sequences into smaller windows for sample-level classification, aggregating segment predictions to form event-level outcomes as $\mathbf{Y} = \bigcup_{k=1}^K \{y_k\}$~\cite{xu2023patient,peng2023wavelet2vec}. 
Another approach detects optimal cut points within continuous recordings to identify the boundaries of meaningful segments $\{\mathbf{X}_k\}_{k=1}^K$, and each segment is classified individually~\cite{Zhan2020EpilepsyDetection}. 
The final event-level prediction is obtained by combining these event-level labels $\mathbf{Y} = \bigcup_{k=1}^K \{\Phi_{\text{segment}}(\mathbf{X}_k; \boldsymbol{\theta})\}$.
%In contrast, datasets like Bonn consist of pre-segmented short EEG recordings, typically used for sample-level classification, which simplifies the problem by eliminating the need for segmentation.

More detailed classifications have also been explored, including three-class tasks, where $y_k \in \{\text{A}, \text{D}, \text{E}\}$ represents interictal (A, the period between seizures), preictal (D, the time before seizure onset), and ictal (E, seizure) states~\cite{zhou2018epileptic}. Five-class tasks refine this further by subdividing the preictal state into early, middle, and late stages~\cite{turk2019epilepsy}. The Temple University Seizure Corpus (TUSZ)~\cite{shah2018temple} supports detailed epilepsy studies, classifying events into pathological patterns like epileptiform discharges and seizure types (e.g., focal, generalized, tonic-clonic), as well as non-pathological signals such as background activity and artifacts (e.g., eye movements).
A detailed overview of all related works is provided in Appendix Table~\ref{tab:seizures}.


\subsubsection{Supervised Methods}
Supervised seizure detection using EEG/iEEG data has advanced alongside growing datasets and improved technology. Early studies relies on subject-specific or mixed-subject evaluations using short, pre-segmented EEG clips. For example, the Bonn dataset~\cite{andrzejak2001indications} consists of manually labeled seizure/non-seizure segments, leading to models optimized for fixed-length inputs. Approaches based on raw signals employ CNNs or RNNs to automatically extract spatiotemporal features from these standardized segments~\cite{ACHARYA2018270,ULLAH201861}, while feature-based methods derive handcrafted or transformed representations, such as scalograms~\cite{turk2019epilepsy} and wavelet-based features~\cite{Seizure58}, which are more suited for shallow classifiers. These techniques inherently assume limited temporal context and avoided segmentation challenges.

With the adoption of long-term recordings like CHB-MIT~\cite{shoeb2009application}, the focus shifts toward cross-subject paradigms. These datasets provide extensive seizure examples within continuous, long-term EEG streams, necessitating more flexible detection frameworks capable of handling variable-length inputs and identifying seizure boundaries in unsegmented data. Approaches integrate temporal modeling through sliding windows~\cite{xu2023patient}, sequence-aware architectures such as Transformers~\cite{lih2023epilepsynet}, or hybrid feature fusion techniques~\cite{dutta2024deep}. Concurrently, cross-subject validation becomes standard, reflecting clinical requirements that generalize across diverse conditions.

The necessity of cross-subject modeling in seizure detection stems from its critical role in ensuring clinical generalization.
The invasive nature of iEEG fundamentally differentiates its modeling requirements from EEG through distinct acquisition paradigms and neurophysiological characteristics, as its patient-specific recording conditions and electrode configurations lead to substantial inter-subject heterogeneity in temporal features and spatial sampling properties, unlike EEG's standardized scalp placement~\cite{zhang2024brant}. Balancing high-resolution spatiotemporal capture with robustness across patients, iEEG requires specialized methodologies to enhance generalizability while addressing its inherent complexities.
Spatial modeling is essential for capturing three-dimensional epileptogenic networks with depth electrodes. Graph-based methods model inter-channel dependencies via neuroanatomical~\cite{9345750} or dynamic functional connections~\cite{rahmani2023meta}, while Transformer architectures use attention mechanisms to adapt to varying electrode configurations~\cite{sun2022continuous}.
DMNet~\cite{tudmnet} improves domain generalization through self-comparison mechanisms.


\subsubsection{Semi- and Unsupervised Methods}
Semi-supervised and unsupervised learning techniques have become increasingly applied in deep learning for seizure detection, particularly when labeled data is limited. 
A common approach incorporates clustering paradigms for event-level segmentation, allowing the model to identify and segment seizure events~\cite{Zhan2020EpilepsyDetection}.
Another notable application involves using models such as Autoencoders, DBNs and GANs to automatically extract relevant features or augment the dataset, thereby enhancing the model’s robustness and generalizability~\cite{abdelhameed2018epileptic,turner2014deep,you2020unsupervised}. 


\subsubsection{Self-supervised Methods}
Self-supervised learning has emerged as an effective approach for seizure detection. 
Contrastive learning captures seizure-related patterns by forming positive pairs through segment augmentation and negative pairs based on feature differences.
For example, SLAM~\cite{XIAO2024105464} generates negative pairs by pairing the anchor with a randomly selected window from a distant time point. SPP-EEGNET~\cite{li2022spp} calculates the absolute difference between pairs to classify them as positive or negative.
Wagh et al.~\cite{wagh2021domain} employs cross-domain contrastive learning to mitigate individual differences by comparing subjects based on factors such as age. They use the delta/beta power ratio to estimate EEG-based behavioral states and distinguish pre- and post-seizure characteristics.
Zheng et al.\cite{zheng2022task} employ predictive-based SSL by designing classification pretext tasks that simulate key epileptic features, such as increased amplitude and abnormal frequencies, enabling the model to recognize epilepsy-related patterns. 
Tang et al.\cite{tang2021self} first combine graph-based modeling with pre-training for EEGs, where the model predicts the next set of EEG signals for a given time period.

EpilepsyNet~\cite{lih2023epilepsynet} employs reconstruction-based SSL, using Pearson Correlation Coefficients to capture spatial-temporal embeddings while preserving contextual features.
Wavelet2Vec~\cite{peng2023wavelet2vec} utilizes a frequency-aware masked autoencoder that reconstructs wavelet-transformed EEG patches in the time-frequency domain. By leveraging seizure-specific abnormal discharge patterns across frequency bands, it enhances feature extraction for seizure subtype classification.
EEG-CGS\cite{ho2023self} adopts a hybrid graph-based SSL approach, framing seizure detection as anomaly detection, integrating random walk-based subgraph sampling with contrastive and reconstruction-based learning.

The SSL paradigm is also commonly used in iEEG-based modeling. 
BrainNet~\cite{chen2022brainnet} employs bidirectional contrastive predictive coding to capture temporal correlation in SEEG signals.
MBrain~\cite{cai2023mbrain} models time-varying propagation patterns and inter-channel phase delays characteristic of epileptic activity through a multivariant contrastive-predictive learning framework, leveraging graph-based representations for spatial-temporal correlations across EEG and SEEG channels.
PPi~\cite{yuan2024ppi} accounts for regional seizure variability, employing a channel discrimination task to ensure the model captures distinct pathological patterns across brain regions rather than treating all channels uniformly.
%Besides, the key to joint training of EEG and iEEG lies in balancing the temporal and spatial information from both signal types. 

\begin{table}[t]
\renewcommand{\arraystretch}{1.2}
\caption{Public Sleep EEG Datasets, where \textbf{Recordings} denotes the number of whole-night PSG recordings.}
\label{tab:sleep}
\footnotesize
\centering
\begin{tabular}{lccc}
\hline
\textbf{Dataset}      & \textbf{Recordings}                     & \textbf{Frequency (Hz)} & \textbf{Channels} \\
\hline
Sleep-EDF~\cite{kemp2000analysis,goldberger2000physiobank}             & 197                 & 100          & 2                 \\
MASS~\cite{oreilly2014montreal}                  & 200                 & 256          & 4-20         \\
SHHS~\cite{quan1997sleep,zhang2018national}                  & 8362                     & 125          & 2                 \\
SVUH\_UCD~\cite{ucddb2007sleep,goldberger2000physiobank}              & 25              & 128          & 3                 \\
HMC~\cite{Alvarez-Estevez2022, goldberger2000physiobank} & 151 & 256 & 4\\
PC18~\cite{ghassemi2018you,goldberger2000physiobank}                  & 1985                     & 200          & 6                 \\
MIT-BIH~\cite{ichimaru1999development,goldberger2000physiobank}              & 16                   & 250          & 1                 \\
DOD-O~\cite{dod_dataset}                   & 55                   & 250          & 8                 \\
DOD-H~\cite{dod_dataset}                   & 25                   & 250          & 12                 \\
ISRUC~\cite{khalighi2016isruc}              & 126                      & 200          & 6                 \\
MGH~\cite{biswal2018expert}                  & 25941                   & 200          & 6                 \\
Piryatinska~\cite{piryatinska2009automated}           & 37         & 64           & 1                 \\
DRM-SUB~\cite{devuyst2005dreams} & 20 & 200 & 3 \\
SD-71~\cite{xiang2023resting} & 142 & 500 & 61 \\
\hline
\end{tabular}
\end{table}

\subsection{Sleep Staging}

\subsubsection{Task Description}
Sleep staging is critical to understanding sleep disorders like insomnia and sleep apnea, as well as the impact on overall health.
It is estimated that 20\% to 41\% of the global population is affected by sleep disorders, which are linked to an increased risk of obesity, cardiovascular diseases, and mental health issues~\cite{recoveryvillage_sleep_statistics_2023}. 
Therefore, accurately identifying sleep stages is essential for addressing these concerns.

Sleep staging involves segmenting signals into 30-second epochs and classifying them into stages: awake (W), rapid eye movement (REM), and three non-REM (NREM) stages (N1, N2, N3).
Wake is characterized by high-frequency $\beta$ and $\alpha$ waves. In N1, the transition from wakefulness to sleep, low-amplitude $\theta$ waves appear. N2, the light sleep stage, is marked by sleep spindles and K-complexes associated with sensory processing and memory consolidation. N3, or deep sleep, features slow-wave $\delta$ activity. REM sleep, essential for emotional regulation and dreaming, is characterized by rapid, low-voltage brain activities.

Multimodal modeling is fundamental for sleep analysis, as polysomnography (PSG) integrates EEG (e.g., Fpz-Cz, Pz-Oz), Electrooculography (EOG), and Electromyography (EMG) to enhance staging accuracy.
The public datasets listed in Table~\ref{tab:sleep} are frequently employed in sleep analysis. 
A detailed overview of all related works is provided in Appendix Table~\ref{tab:sleeps}.


%The Sleep-EDF dataset ~\cite{kemp2000analysis}, which includes polysomnography (PSG) recordings annotated by sleep stage at 30-second intervals, has been used in more than 70\% of related studies, with multiple incremental releases.

\subsubsection{Supervised methods}

Selecting biosignal modalities is critical for designing supervised learning frameworks in PSG-based sleep staging. Two primary paradigms are widely used. Single-channel EEG methods, preferred in resource-constrained settings, offer hardware simplicity, reduced cross-modal interference, and enhanced computational efficiency~\cite{tsinalis2016automatic, eldele2021attention}. However, relying solely on EEG limits the detection of complementary cues—such as ocular and muscular activities—essential for identifying ambiguous sleep stages like REM sleep.
Multimodal architectures integrating EEG, EOG, and EMG signals emulate the integrative analysis performed by sleep experts~\cite{chambon2018deep, alvarez2021inter}. Chambon et al.~\cite{chambon2018deep} employs techniques like spatial filtering to mitigate cross-modal interference. These designs align with clinical scoring protocols and compensate for the limited contextual information of individual modalities. Beyond these dominant approaches, hybrid models, such as EEG-EOG, balance diagnostic accuracy with computational efficiency~\cite{Sleep28}. 

%Ultimately, selecting appropriate signals requires balancing physiological comprehensiveness with operational practicality.
%The strong connection between sleep stages and frequency-specific EEG patterns highlights the importance of capturing spatial and spectral information in supervised learning. 
%CNN-based methods have proven effective for sleep staging, with early approaches demonstrating their potential and later advancements incorporating complex-valued processing and multimodal pipelines to handle heterogeneous signals~\cite{tsinalis2016automatic,eldele2021attention}.
%However, CNNs often struggle to capture sequential dependencies, whereas RNN-based models utilize sequence-to-sequence architectures to capture both short- and long-term dependencies~\cite{phan2018automatic, phan2019seqsleepnet}. 
%More recently, Transformers have become increasingly popular in sleep staging due to their capacity to efficiently focus on relevant temporal features using attention mechanisms~\cite{yao2023cnntransformer}. 

%Multimodal modeling leverages complementary insights from EEG, EOG, and EMG to enhance the accuracy and robustness of sleep staging.Cross-modal fusion, temporal modeling, and modality-specific feature extraction pipelines are frequently implemented in successful multimodal models to integrate features and capture sleep stage transitions. 
%Recent advances further address challenges in multimodal alignment through unified frameworks like Brant-X~\cite{zhang2024brantx}, which leverages EEG foundation models to transfer knowledge to other physiological signals (e.g., EOG, EMG) via contrastive learning. By aligning EEG and EXG signals at both the patch-level, which captures local waveform patterns, and the sequence-level, which captures global temporal dynamics, Brant-X effectively bridges the semantic gaps between different modalities.
%Linear spatial filtering, for example, can improve the quality of signals, while attention mechanisms or cross-modal Transformers can efficiently combine and evaluate modality-specific contributions. 
%Multimodal models are essential for the comprehensive staging of sleep signals, ensuring that they fully leverage the diversity of PSG data.

%Beyond these, graph-based methods addressed the limitations of conventional networks by modeling EEG channels as nodes in a graph, dynamically learning relationships between channels. This line of work progressed from focusing solely on functional connectivity to incorporating physical proximity and domain generalization, capturing richer spatial-temporal patterns in the data \cite{jia2020graphsleepnet,jia2021multi}. Together, these advancements highlight a shift from generic deep architectures to more specialized models that reflect the intrinsic complexities of sleep signals.

\subsubsection{Self-supervised methods}
Self-supervised contrastive-based methods enhance sleep representation by leveraging temporal and contextual patterns in unlabeled EEG data.
Early works explore tasks such as relative positioning, temporal shuffling, and autoregressive latent feature predictions to extract temporal structures from multivariate signals~\cite{banville2019self, oord2018representation}. 
Jiang and et al.~\cite{jiang2021self} extends these efforts with augmentation-based contrastive learning, generating positive and negative pairs from augmented EEG segments.
ContraWR~\cite{yang2023self} adopts constructing contrastive pairs from distinct time windows, prioritizing window-level temporal dependencies.
%Additionally, domain-guided methods integrats auxiliary tasks such as hemispheric symmetry and age estimation, capturing physiologically meaningful features~\cite{wagh2021domain}. 
%Recent methods have expanded contrastive frameworks by incorporating multi-view and domain-specific learning. For example, 
mulEEG~\cite{kumar2022muleeg} and CoSleep~\cite{ye2021cosleep} introduce multi-view contrastive strategies to integrate time-series and spectrogram representations of EEG data. 
mulEEG emphasizes cross-view consistency while encouraging modality-specific features, whereas CoSleep develops a time-frequency dual-view contrastive learning framework that implicitly captures sleep-staging-related temporal dynamics and spectral rhythmic patterns in EEG signals.

Multimodal modeling improves sleep staging accuracy by integrating complementary EEG, EOG, and EMG insights. Brant-X~\cite{zhang2024brantx} address alignment challenges using EEG foundation models and contrastive learning. By aligning EEG and EXG signals at both the local and global levels, Brant-X effectively bridges the semantic gaps between modalities.
%Approaches like attention-driven latent signal manipulation and multi-instance contrastive learning further enable models to uncover nuanced signal variations without labeled supervision~\cite{lee2022self, xiao2021self}.

%Masked modeling methods aim to compel the model to learn intrinsic data patterns.% by reconstructing missing portions of the signal. 




%\subsubsection{Semi- and Unsupervised Methods}
%Early unsupervised methods focused on automatically discovering meaningful representations from raw physiological signals without manual feature engineering, enabling models to capture subtle patterns inherent to sleep data \cite{langkvist2012sleep,zhang2016automatic}. Such approaches explored variants that emphasize feature sparsity, inspired by biological vision systems, which improved the model’s sensitivity to intricate EEG characteristics and enhanced classification outcomes \cite{lee2007sparse,zhang2016automatic}.

%Subsequent work introduced complex-valued inputs and unsupervised filter refinement, allowing networks to handle more nuanced signal attributes \cite{zhang2018complex}. Further innovations incorporated competition-based learning to bolster robustness against noise and better reflect the competitive dynamics of neural representations, offering more stable and effective sleep stage discrimination \cite{zhang2021competition}.

%\subsubsection{Semi-supervised methods}
%Manually labeled sleep recordings are scarce, but raw sleep signals are easier to acquire, prompting the development of semi-supervised models for sleep stage classification. For example, a semi-supervised Gaussian Mixture Model (SS-GMM) achieves comparable accuracy to fully-supervised models when more than 50\% of the data is labeled~\cite{munk2018semi}. Pseudo-labeling is another common approach, where labels are assigned to unlabeled data based on predicted probabilities~\cite{haoran2021semi}.

%More advanced methods include a bi-stream adversarial network (BiSALnet) that employs a Student-Teacher architecture with adversarial training to generate high-confidence pseudo-labels, improving classification performance~\cite{li2022adversarial}. Building on this, a multi-task contrastive learning strategy (MtCLSS) further enhances representation learning for sleep staging~\cite{li2022mtclss}.

\subsection{Depression Identification}

\begin{table}[t]
\renewcommand{\arraystretch}{1.2}
\caption{Public EEG Datasets for Depression Detection, where \textbf{Exp (n)} represents the number of depressed individuals and \textbf{Ctrl (n)} represents the healthy control group.}
\label{tab:dep}
\footnotesize
\centering
\begin{tabular}{lcccc}
\hline
\textbf{Dataset}     & \textbf{Exp (n)}                  & \textbf{Ctrl (n)} & \textbf{Frequency (Hz)} & \textbf{Channels} \\
\hline
HUSM~\cite{Mumtaz2016}      & 34                            & 30               & 256              & 22                \\
PRED+CT~\cite{cavanagh2017patient} & 46                            & 75               & 500              & 64                \\
EDRA~\cite{yang2023automatic} & 26                            & 24               & 500              & 63                \\
MODMA~\cite{cai2022multi}    & \begin{tabular}[c]{@{}l@{}}24 \\ 26 \end{tabular} & \begin{tabular}[c]{@{}l@{}}29\\ 29\end{tabular} & 250              & \begin{tabular}[c]{@{}l@{}}128\\ 3\end{tabular} \\
\hline
\end{tabular}
\end{table}

\subsubsection{Task Description}
Depression, particularly Major Depressive Disorder (MDD), is a psychological condition affecting 5\% of individuals worldwide, with a higher prevalence among women. In low- and middle-income countries, up to 75\% of individuals lack adequate care due to limited resources and stigma, despite effective treatments being available~\cite{WHO_depression}.

Depression severity is quantified using standardized scales like the Beck Depression Inventory (BDI) to differentiate clinical depression from normal mood variations. 
Existing studies adopt heterogeneous classification criteria: some focus on binary discrimination (e.g., patients vs. healthy controls), while others stratify cohorts by treatment status (medicated vs. non-medicated) or severity levels (mild vs. moderate/severe).
Table~\ref{tab:dep} summarizes datasets used in MDD research.
A detailed overview of all related works is provided in Appendix Table~\ref{tab:mdds}.

\subsubsection{Approach overview}
Depression impacts both superficial and deeper brain structures, presenting challenges for traditional handcrafted features.
Acharya introduces the first end-to-end DL model for EEG-based depression detection, showing that right-hemisphere signals are significantly more distinctive than left-hemisphere ones, which aligns with clinical findings~\cite{acharya2018automated}. 
This insight has driven further studies analyzing hemispheric EEG separately, often confirming similar patterns. For example, 
Ay et al. introduces a hybrid CNN-LSTM architecture, with experimental results revealing a more pronounced performance improvement in the right cerebral hemisphere~\cite{ay2019automated}.
DeprNet~\cite{seal2021deprnet} employs a CNN-based architecture with visualizations highlighting prominent activity in right-hemisphere electrodes for depressed subjects.

Spiking neural networks (SNNs) excel in EEG-based depression diagnosis, capturing brain-inspired spatiotemporal dynamics with biologically interpretable insights. 
Shah et al.~\cite{shah2019deep} employ the NeuCube SNN framework to encode EEG signals into temporal spike trains, mapping them onto a 3D spiking neural network reservoir (SNNr) aligned with the Talairach brain atlas.
The SNNr models spatiotemporal relationships between EEG channels using unsupervised spike-timing-dependent plasticity (STDP), offering interpretable brain connectivity visualizations.
Sam et al.~\cite{sam2023depression} integrates a 3D brain-inspired SNN with an LSTM, leveraging SNN’s energy efficiency with LSTM’s temporal modeling capabilities.

%\subsubsection{Unsupervised methods}
%Unsupervised methods effectively extract EEG patterns without relying on labeled data. NeuCube, an SNN-based architecture, identified neural markers in frontal, central, and parietal regions for early depression prediction, highlighting its potential in uncovering distinct neural activity patterns~\cite{shah2019deep}. Its outputs were further integrated into a supervised LSTM network for four-class depression classification based on Beck scores, showcasing its versatility in both unsupervised and hybrid frameworks~\cite{sam2023depression}.

%Another notable model, GCNs–FSMI, employed graph mutual information maximization and multi-band EEG signals to analyze mental illnesses, including depression and schizophrenia. By capturing high-level subject interactions and avoiding dependence on labeled data, it improved robustness and efficacy in multi-channel EEG-based analysis~\cite{li2023gcns}.

%\subsubsection{Semi-supervised methods}
%Labeled EEG data for depression identification is limited, making semi-supervised methods that utilize abundant unlabeled data a practical solution. One approach integrates self-organizing incremental neural networks (SOINN) with GCNs for self-training. By iteratively assigning pseudo-labels to high-confidence samples, this method achieved 92.23\% accuracy on the MODMA dataset with 600 labeled samples~\cite{wang2021identification}.


\subsection{Schizophrenia Identification}


\begin{table}[t]
\renewcommand{\arraystretch}{1.2}
\caption{Public EEG Datasets for Schizophrenia, where \textbf{Exp (n)} represents the number of schizophrenia patients and \textbf{Ctrl (n)} represents the control group.}
\label{tab:sz}
\footnotesize
\centering
\begin{tabular}{lcccc}
\hline
\textbf{Dataset}      & \textbf{Exp (n)} & \textbf{Ctrl (n)} & \textbf{Frequency (Hz)} & \textbf{Channels} \\
\hline
CeonRepod~\cite{olejarczyk2017graph}   & 14              & 14               & 250              & 19                \\
NIMH~\cite{ford2014did}                & 49              & 32               & 1024             & 64                \\
MHRC~\cite{borisov2005analysis}        & 45              & 39               & 128              & 16                \\
\hline
\end{tabular}
\end{table}


\subsubsection{Task Description}
Schizophrenia (SZ) is a psychiatric disorder affecting 24 million people worldwide, characterized by cognitive impairments, including memory deficits, delusions, and hallucinations~\cite{WHO_SZ}. 
SZ is associated with disruptions in structural and functional brain connectivity, marked by decreased global efficiency, weakened strength, and increased clustering~\cite{zalesky2011disrupted}. These abnormalities are detectable in EEG signals, making them useful for binary classification to distinguish SZ patients from healthy controls. Table~\ref{tab:sz} summarizes publicly available datasets for SZ research.
A detailed overview of all related works is provided in Appendix Table~\ref{tab:schis}.

\subsubsection{Approach overview}
Transfer learning has emerged as a powerful technique for fine-tuning pre-trained computer vision (CV) models in EEG-based schizophrenia diagnosis, enhancing performance with minimal training.
A common approach is converting EEG signals into 2D images for CNN-based models.
Aslan et al.~\cite{SZ16} feed spectrograms into a pre-trained VGG-16, applying Grad-CAM to highlight critical frequency components.
SchizoGoogLeNet~\cite{SZ21} fine-tunes the pre-trained GoogLeNet to process 2D EEG feature matrices, which are generated from preprocessed EEG signals through average filtering and resizing to align with the model's input dimensions.
Shalbaf et al.~\cite{SZ22} transform EEG into scalogram images via CWT, using ResNet-18 and VGG-19 to extract spatial-temporal features for classification.
%The results of these studies indicate that transfer learning enhances the scalability, adaptability, and classification performance of EEG data used to study schizophrenia.
%In schizophrenia detection using EEG, signal preprocessing methods often enhance feature extraction. For instance, Fast Fourier Transform (FFT) was used to extract features like spectral power and complexity, which were input into a hybrid CNN-LSTM network for SZ diagnosis~\cite{saeedi2022schizophrenia}. Similarly, smoothed pseudo-Wigner–Ville distribution (SPWVD) generated 2D time-frequency representations that were classified using a 4-layer 2D-CNN~\cite{khare2021spwvd}.

%Beyond generic features, some studies incorporated SZ-specific characteristics. For example, brain connectivity was analyzed using vector autoregressive coefficients (VAR), partial directed coherence (PDC), and network topology measures, which were processed through parallel CNNs before fusion for diagnosis~\cite{phang2019multi}.
%In contrast, task-oriented network designs eliminated manual feature engineering. An 11-layer 1D-CNN directly processed raw EEG data with minimal preprocessing, demonstrating the potential of concise architectures for SZ diagnosis~\cite{oh2019deep}.



\subsection{Alzheimer's Disease Diagnosis}
\begin{table}[t]
\renewcommand{\arraystretch}{1.2}
\caption{Public EEG Datasets for Alzheimer's Diagnosis, where \textbf{AD (n)} and \textbf{MCI (n)} represent the experimental groups, and \textbf{Ctrl (n)} represents the control group.}
\label{tab:ad}
\footnotesize
\centering
\begin{tabular}{p{50pt}p{20pt}p{20pt}p{20pt}p{30pt}p{30pt}}
\hline
\textbf{Dataset}            & \textbf{AD (n)} & \textbf{MCI (n)} & \textbf{Ctrl (n)} & \textbf{Frequency (Hz)} & \textbf{Channels} \\
\hline
FSA~\cite{ds_FSA_AD}        & 160            & -               & 24               & 128              & 21                \\
AD-65~\cite{ds004504:1.0.2} & 36             & -               & 29               & 250              & 19                \\
Fiscon~\cite{fiscon}         & 49             & 37              & 14               & 1024             & 19                \\
AD-59~\cite{cejnek2021novelty} & 59            & 7               & 102              & 128-256          & 21                \\
\hline
\end{tabular}
\end{table}

\subsubsection{Task Description}
Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that starts with mild memory loss and advances to severe cognitive impairment, affecting daily life. While medical interventions can improve quality of life, a definitive cure remains elusive~\cite{better2024alzheimer}. 
Alzheimer’s disease (AD) progresses through three stages: preclinical, mild cognitive impairment (MCI), and Alzheimer’s dementia.
Classification tasks typically distinguish MCI or Alzheimer’s dementia from healthy controls. 
EEG abnormalities, such as slowed brain rhythms and desynchronization, serve as biomarkers for AD-related neurodegeneration~\cite{labate2014eeg}. Table~\ref{tab:ad} summarizes publicly available datasets.
A detailed overview of all related works is provided in Appendix Table~\ref{tab:ads}.

\subsubsection{Approach overview}
EEG abnormalities in Alzheimer’s disease, such as disrupted functional connectivity and altered brain rhythms, provide critical insights into the neurological changes. Brain connectivity modeling in AD can be approached from several angles. 
One approach, as seen in ST-GCN~\cite{shan2022spatial}, generates functional connectivity matrices that incorporate metrics like wavelet coherence and phase-locking value to simulate spatial and temporal dependencies in EEG signals. 
Alves et al.\cite{AD1} uses functional connectivity matrices derived from Granger causality and correlation measures to emphasize the spatial structure of brain networks. 
Additionally, some studies focus on spectral analysis, such as Morabito et al.\cite{AD5}, who convert EEG data into 2D spectral images using FFT and process these images with techniques like discriminative DCssCDBM to identify hybrid features that highlight EEG patterns associated with AD.
%These methodologies lay the groundwork for new, scalable, and clinically significant approaches to EEG-based diagnostics for neurological disorders.


\subsection{Parkinson's Disease Diagnosis}

\begin{table}[t]
\renewcommand{\arraystretch}{1.2}
\caption{Public EEG Datasets for Parkinson's Disease Diagnosis, where \textbf{Exp (n)} represents the number of patients and \textbf{Ctrl (n)} represents the healthy control group.}
\label{tab:pd}
\footnotesize
\centering
\begin{tabular}{lcccc}
\hline
\textbf{Dataset}            & \textbf{Exp (n)}   & \textbf{Ctrl (n)}   & \textbf{Frequency (Hz)} & \textbf{Channels} \\
\hline
UCSD~\cite{ds002778:1.0.5}  & 15                & 16                & 512              & 32                \\
UNM~\cite{cavanagh2018diminished} & 27                & 27                & 500              & 64                \\
UI~\cite{singh2020frontal}   & 14                & 14                & 500              & 59                \\
\hline
\end{tabular}
\end{table}

\subsubsection{Task Description}
Parkinson’s disease (PD) is a progressive neurodegenerative disorder marked by motor symptoms (tremors, rigidity, bradykinesia) and non-motor symptoms (depression, sleep disturbances, cognitive decline). In 2019, over 8.5 million people worldwide were living with PD~\cite{who2023parkinson}.
EEG is widely used in PD research due to its noise resistance and sensitivity to neurological changes, such as slowing cortical oscillations and increased low-frequency power~\cite{morita2011relationship}. 
Most studies focus on supervised learning for binary classification, with some incorporating transfer learning. 
Table~\ref{tab:pd} summarizes publicly available datasets.
A detailed overview of all related works is provided in Appendix Table~\ref{tab:pds}.

\subsubsection{Approach overview}
Transforming raw EEG signals into 2D representations is a well-established approach for PD classification, with various techniques offering distinct insights.
Spectrograms, generated via Gabor Transform, as in GaborPDNet\cite{PD2}, preserve time-frequency characteristics while minimizing information loss. 
Scalograms, created using CWT, provide another effective representation\cite{shaban2022resting}.
According to Chu et al.\cite{PD8}, power spectral density (PSD) mapping is another method, where specific frequency bands like high-$\delta$ and low-$\alpha$ can serve as potential biomarkers for early PD diagnosis.
Connectivity-based 2D representations can be obtained, like those applied by Arasteh et al.~\cite{PD9},  compute directional connectivity and produce heatmaps that effectively capture inter-channel relationships across frequency bands.
%PDCNNet, a framework designed for PD detection, combines Smoothed Pseudo Wigner Ville Distribution (SPWVD) with CNN to process EEG signals. This approach transforms EEG signals into high-resolution time-frequency representations (TFRs), addressing limitations of manual preprocessing and enabling automatic feature extraction and classification~\cite{khare2021pdcnnet}. Another method utilizes continuous wavelet transform (CWT) on resting-state EEG for PD classification. This framework incorporates Grad-CAM to visualize discriminative features and evaluate medication effects~\cite{shaban2022resting}.
%A lightweight convolutional-recurrent neural network (CRNN) was introduced to capture temporal dependencies in multi-channel EEG signals. By integrating CNN and GRU, this model achieved 99.2\% accuracy and demonstrated sensitivity to dopaminergic drug effects~\cite{lee2021convolutional}.

\subsection{ADHD Identification}

\begin{table}[b]
\renewcommand{\arraystretch}{1}
\caption{Public EEG Datasets for ADHD Identification, where \textbf{Exp (n)} represents the number of ADHD patients and \textbf{Ctrl (n)} represents the healthy control group.}
\label{tab:adhd}
\footnotesize
\centering
\begin{tabular}{lcccc}
\hline
\textbf{Dataset}            & \textbf{Exp (n)}   & \textbf{Ctrl (n)}              & \textbf{Frequency (Hz)} & \textbf{Channels} \\
\hline
ADHD-79~\cite{sadeghibajestani2023dataset} & 37 & 42             & 256          & 2                \\
ADHD-121~\cite{rzfh-zn36-20}      & 61 & 60    & 128          & 19                \\
\hline
\end{tabular}
\end{table}
\subsubsection{Task Description}
Attention-deficit/hyperactivity disorder (ADHD) is a neurodevelopmental disorder affecting around 3.1\% of individuals aged 10–14 and 2.4\% of those aged 15–19~\cite{who_adolescent_mental_health}. 
It is categorized into three subtypes: Inattentive (ADHD-I), Hyperactive-Impulsive (ADHD-H), and Combined (ADHD-C)~\cite{nimh_adhd}.
EEG is widely used alongside neuroimaging and physiological measures for ADHD diagnosis. 
However, deep learning remains underexplored, with most existing approaches relying on supervised learning and feature-based classification. Research focuses on binary classification tasks, and Table~\ref{tab:adhd} lists two publicly available datasets.
A detailed overview of all related works is provided in Appendix Table~\ref{tab:adhds}.

\subsubsection{Approach overview}
Studies on ADHD diagnosis identify distinct EEG neurophysiological markers, particularly abnormalities in specific frequency bands. Chen et al.\cite{chen2019use} and Dubreuil-Vall et al.\cite{dubreuil2020deep} demonstrate the effectiveness of CNNs for ADHD detection.
Chen et al. report $\theta$ and $\beta$ abnormalities in children with ADHD, while Dubreuil-Vall et al. observe altered $\alpha$ and $\delta-\theta$ in frontal electrodes during executive function tasks, aligning with medical findings.
They also find that EEG data from executive function tasks outperform resting-state EEG for ADHD detection.

\begin{table*}[t]
\renewcommand{\arraystretch}{1.2}
\caption{Summary of pre-trained SSL frameworks for multi-task neurodiagnosis, focusing on relevant datasets and tasks, with paradigms such as Contrastive Learning (CL), Contrastive Predictive Coding (CPC), and Masked Autoencoding (MAE)}
\label{tab:pts}
\footnotesize
\centering
\begin{tabular}
{p{2.1cm}p{1.9cm}p{2.1cm}p{1.4cm}p{1.8cm}p{3.7cm}p{2.5cm}}
\hline
\textbf{Work}        & \textbf{SSL Paradigm}                                     & \textbf{Backbone}  & \textbf{Data Type} &\textbf{Partitioning}  & \textbf{pre-training Dataset}                          & \textbf{Downstream Tasks}                           \\
\hline
Banville et al.~\cite{banville2021uncovering} & CPC & CNN & EEG & dataset-specific & TUSZ, PC18  & Seizure, Sleep  \\
MBrain~\cite{cai2023mbrain} & CPC & CNN+LSTM+GNN & EEG, iEEG&dataset-specific & TUSZ, private & Seizure, etc. \\
TS-TCC~\cite{eldele2021time}               & CPC                       & CNN+Transformer   & EEG &cross-dataset     & Bonn, Sleep-EDF, etc.                                  & Seizure, Sleep, etc.                                    \\
SeqCLR~\cite{mohsenvand2020contrastive}               & CL                                            & CNN+GRU & EEG &mixed-dataset & TUSZ, Sleep-EDF, ISRUC, etc.      & Seizure, Sleep, etc. \\
TF-C~\cite{zhang2022self}                 & CL                              & CNN  & EEG                  &cross-dataset & Sleep-EDF, etc.         & Seizure, Sleep, etc.       \\
BIOT~\cite{yang2024biot}  & CL & Transformer & EEG, etc. & cross-dataset & SHHS, etc. & Seizure, etc \\
Jo et al.~\cite{jo2023channel} & Predictive & CNN  & EEG &mixed-dataset &CHB-MIT, Sleep-EDF & Seizure, Sleep  \\
neuro2vec~\cite{wu2022neuro2vec} & MAE & CNN+Transformer & EEG &cross-dataset& Bonn, Sleep-EDF, etc.         & Seizure, Sleep \\
CRT~\cite{zhang2023self} & MAE & Transformer & EEG &dataset-specific & Sleep-EDF, etc. & Sleep, etc.\\
NeuroBERT~\cite{wu2024neuro} & MAE & Transformer & EEG, etc. & dataset-specific & Bonn, SleepEDF, etc, & Seizure, Sleep,etc. \\
BENDR~\cite{Kostas2021BENDR} & CPC+MAE & CNN+Transformer & EEG &cross-dataset& TUEG & Sleep, etc. \\
CBRAMOD~\cite{wang2024cbramod} & MAE & Transformer & EEG & cross-dataset & TUEG & Seizure, Sleep, MDD \\
Brant~\cite{zhang2024brant} & MAE & Transformer & iEEG&cross-dataset & private & Seizure, etc.  \\  
Brainwave~\cite{yuan2024brainwavebrainsignalfoundation} & MAE & Transformer & EEG, iEEG&cross-dataset & TUEG, Siena, CCEP, Sleep-EDF, NIMH, FSA, private, etc.  & Seizure, Sleep,  MDD,\newline SZ, AD, ADHD \\ 
EEGFormer~\cite{chen2024eegformer} & VQ+MAE & Transformer & EEG & cross-dataset & TUEG & Seizure, etc. \\
LaBraM~\cite{jiang2024large} & VQ+MAE & Transformer & EEG & cross-dataset & TUEG, Siena, etc. & Seizure, etc. \\
NeuroLM~\cite{jiang2024neurolm} & VQ+MAE\newline+Predictive & Transformer & EEG & cross-dataset & TUEG, Siena, etc. & Seizure, Sleep, etc.\\
\hline
\end{tabular}
\end{table*}