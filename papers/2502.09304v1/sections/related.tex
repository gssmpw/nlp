

\section{Related Works}\label{sec:related}
Beyond Microsoft's \graphrag, we review other indexing and retrieval approaches within existing \graphrag frameworks. For a comprehensive review, we refer readers to related surveys~\cite{peng2024graph,fan24survey}.



\begin{algorithm}[!t]
\KwIn{A \textgraph{} index $\G=(\V_e\cup\V_t,\E)$, a query $q$, context length limit $\lambda$}
\KwOut{The context $C$} 
$\Sset_e \gets \argmink{v_i\in \V_e} \text{euc}(v_i,q)$, where $k=10$\;
$\Sset_r \gets \argmaxk{e_{i,j}\in \E} \text{adj}(\Sset_e,e_{i,j})$, s.t.\ ${\scriptstyle \left|\bigoplus(\Sset_r)\right|+\left|\bigoplus(\Sset_e)\right| = \lambda/2}$;\\
$\Sset_t \gets \argmaxk{v_{i}\in \V_t} \text{adj}(\Sset_e\cup\Sset_r,v_{i})$, s.t.\ ${\scriptstyle \left|\bigoplus(\Sset_t)\right| = \lambda/2}$;\\
\Return{$\bigoplus(\Sset_e\cup\Sset_r\cup\Sset_t)$;} 
\caption{\graphretrieval$(\G, q, \lambda)$}
\label{alg:graphrag-retrieval}
\end{algorithm}


% \stitle{KNN graph construction}
Given $\Tset$, the core of constructing a KNN graph is measuring text chunk similarity. In particular, \citet{li2024graph} consider both structural and lexical similarities. Structural similarity is based on the physical adjacency of text chunks, linking neighboring passages in $\G$. Lexical similarity connects chunk nodes that share common keywords, which are extracted using LLM-based prompting.
\citet{wang2024knowledge} leverage multiple lexical similarity measures. Two chunk nodes are connected if they share keywords extracted using TF-IDF~\cite{ramos2003using}, contain common Wikipedia entities identified via TAGME~\cite{min2019knowledge}, or exhibit semantic similarity based on text embeddings.
% \stitle{Knowledge graph construction}
Recent works~\cite{li2024dalk,delile2024graph,edge2024local,gutierrez2024hipporag} use LLMs to extract (entity, relation, entity) triplets from $\Tset$ to build knowledge graph indices, improving retrieval quality.
Akin to Algorithm~\ref{alg:graphrag-index}, 
\citet{delile2024graph} employ PubmedBERT~\cite{gu2021domain} to extract triplets from biomedical texts and link entities to the text chunks in which they appear. \citet{gutierrez2024hipporag} further enrich graph connectivity by linking semantically similar entities within the knowledge graph.
% \stitle{Other graph indexing approaches}
Several studies construct \textgraph{} indices using explicit relationships, such as co-authorship or citation links in academic papers~\cite{munikoti2023atlantic}, trade relationships between companies~\cite{cao24companykg}, and other structured connections~\cite{jin2024graph}. These publicly curated indices are beyond the scope of this work.
In summary, \knnrag is a more cost-effective solution but lacks fine-grained entity relationships. In contrast, \kgrag achieves higher effectiveness but incurs significant indexing costs, particularly for large $\Tset$.

% \stitle{Graph retrieval}
To retrieve the most relevant subgraph given a query, various local search strategies have been proposed. Below, we focus on methods that utilize heuristic or traditional graph algorithms. 
Similar to Algorithm~\ref{alg:graphrag-retrieval}, \citet{jin2024graph} extract ego networks from seed nodes to enhance retrieval precision. In addition, \citet{li2024dalk} propose a two-step approach that first extracts a k-hop subgraph from seeds, followed by reranking and pruning the subgraph using LLMs. Other approaches include shortest path retrieval, where \citet{delile2024graph} and \citet{mavromatis2024gnn} retrieve the shortest path between seed nodes. \citet{gutierrez2024hipporag} use personalized PageRank to extract relevant subgraphs. \textsf{G-Retriever}~\cite{he2024g} focuses on query-aware subgraph generation by balancing semantic similarity to the query with subgraph generation cost. Hybrid retrieval methods, such as \hybridrag~\cite{sarmah2024hybridrag} and \textsf{EWEK-QA}~\cite{dehghan2024ewek}, enhance retrieval by querying both text and knowledge graphs.



