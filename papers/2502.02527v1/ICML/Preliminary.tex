\section{Preliminary}
\label{sec:preliminary}

In this section, we provide a brief overview of TabPFN and analyze its properties, while also revisiting existing variants.\looseness=-1

\subsection{TabPFN}
We consider a tabular dataset consisting of $N$ examples and $d$ features. Each instance $\boldsymbol{x}_i \in \mathbb{R}^d$ is represented by $d$ feature values, where $\boldsymbol{x}_{i,j}$ denotes the $j$-th feature of instance $\boldsymbol{x}_i$. These features can be numerical ($\boldsymbol{x}_{i,j}^{\text{num}} \in \mathbb{R}$) or categorical ($\boldsymbol{x}_{i,j}^{\text{cat}}$), with categorical values often encoded as integers. Each instance is associated with a label $\boldsymbol{y}_i$, where $\boldsymbol{y}_i \in [C] = \{1, \dots, C\}$ for classification task, and $\boldsymbol{y}_i \in \mathbb{R}$ for regression task. Given a training dataset, $D_{\text{train}} = \{(\boldsymbol{x}_{\text{train}}^{(i)}, \boldsymbol{y}_{\text{train}}^{(i)})\}_{i=1}^{N_{\text{train}}}$, and test samples, $\boldsymbol{X}_{\text{test}} = [\boldsymbol{x}_{\text{test}}^{(i)}]_{i=1}^{N_{\text{test}}}$, the goal is to predict the corresponding labels, $\boldsymbol{Y}_{\text{test}} = [\boldsymbol{y}_{\text{test}}^{(i)}]_{i=1}^{N_{\text{test}}}$, as accurately as possible.\looseness=-1

TabPFN follows a two-stage process: a pre-training stage, where the model is trained on synthetic datasets by minimizing the discrepancy between the predicted label of the test instance and its true label, and an inference stage, where it directly predicts the labels of test samples given a set of labeled training examples.

Following pre-training, TabPFN takes the entire training dataset \(D_{\text{train}}=(\boldsymbol{X}_{\text{train}} ,\boldsymbol{y}_{\text{train}})\) and the features of query points \(\boldsymbol{X}_{\text{q}}\) as context to make predictions. This is done using \textbf{PFN-Style Batching}~\cite{Hollmann2022TabPFN}, where \(N_{\text{test}}\) test samples are batched into a single ``prompt,'' as illustrated in~\autoref{fig:TabPFN}. 
Since TabPFN is trained with a fixed input dimensionality, typically set to a predefined value \(d_{\max}\) (e.g., 100), datasets with fewer features (\(d < d_{\max}\)) need to be extended via zero-padding before being processed. Formally, given an input instance \(\boldsymbol{x}_i \in \mathbb{R}^d\), the padded input \(\tilde{\boldsymbol{x}}_i \in \mathbb{R}^{d_{\max}}\) is obtained as:
\begin{equation}
\tilde{\boldsymbol{x}}_i = \left[ \boldsymbol{x}_i, \boldsymbol{0} \right] \in \mathbb{R}^{d_{\max}},
\end{equation}
where \(\boldsymbol{0} \in \mathbb{R}^{d_{\max} - d}\) represents the zero-padding applied to match the required input dimensionality. However, if a dataset exceeds this limit (\(d > d_{\max}\)), TabPFN cannot directly process such datasets, as its architecture is not designed to accommodate higher-dimensional inputs.

TabPFN outputs a probability distribution over possible labels \(\boldsymbol{y}_{\text{q}} \in \{1, \dots, C\}\). Specifically, let \( q_\theta \) denote the logits produced by TabPFN, where \( \theta \) represents the parameters of the pre-trained model. The posterior predictive distribution is given by:
\vspace{-3mm}
\begin{equation} 
\label{eq:tabpfn_post_pred}
p_\theta(\boldsymbol{y}_{\text{q}} \mid \boldsymbol{X}_{\text{q}}, D_{\text{train}}) =  \frac{\exp(q_\theta(\tilde{\boldsymbol{X}}_{\text{q}}, \tilde{D}_{\text{train}})_{[\boldsymbol{y}_{\text{q}}]})}{\sum_{c=1}^C \exp(q_\theta(\tilde{\boldsymbol{X}}_{\text{q}}, \tilde{D}_{\text{train}})_{[c]})},  
\end{equation}

\vspace{-2mm}
where \(\tilde{D}_{\text{train}}\) denotes the zero-padded training dataset, acting as the support set for the context composition. Since TabPFN performs inference directly, the model typically applies multiple rounds of feature shuffling on the original features, followed by prediction. The final prediction is obtained by averaging the results from these multiple inferences. For more details about how the model processes inputs, please refer to Appendix~\ref{appendix:details_of_pfn}.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{files/PFN.pdf}
    \vspace{-5mm}
    \caption{The prediction process of TabPFN. The training set and test set are concatenated, with the training labels added to the input sequence. TabPFN then performs a single forward pass to generate predictions for all test samples.}
    \label{fig:TabPFN}
    \vspace{-5mm}
\end{figure}
\subsection{TabPFN Variants} 
Existing research to improve the performance of TabPFN has primarily focused on two different strategies, stemming from its dependency on $q_{\theta}$ and \(D_{\text{train}}\) in~\autoref{eq:tabpfn_post_pred}. One approach optimizes context selection, refining \(D_{\textbf{train}}\) to provide more informative support examples. The other concentrates on fine-tuning TabPFN, improving \(q_{\theta}\) to better adapt to downstream tasks. These two strategies offer complementary solutions for enhancing TabPFN's overall performance. 
% 下面这里结合公式来讲
\begin{figure*}[h]
\centering
\begin{minipage}{0.32\textwidth}
    \centering
    \includegraphics[width=\linewidth]{files/bias_variance/adult_loss_vs_size.pdf}
    % \caption{Generalization Error on the Adult Dataset.}
    {\scriptsize \mbox{(a) {\textit{Generalization error} on the Adult Dataset.}}}
    \label{fig:adult_generalization_error}
\end{minipage}%
\begin{minipage}{0.32\textwidth}
    \centering
    \includegraphics[width=\linewidth]{files/bias_variance/adult_bias_vs_size.pdf}
    {\scriptsize \mbox{(b) {\textit{Bias} on the Adult Dataset.}}}
    % \caption{Bias on the Adult Dataset.}
    \label{fig:adult_bias}
\end{minipage}%
\begin{minipage}{0.32\textwidth}
    \centering
    \includegraphics[width=\linewidth]{files/bias_variance/adult_variance_vs_size.pdf}
    {\scriptsize \mbox{(c) {\textit{Variance} on the Adult Dataset.}}}
    % \caption{Variance on the Adult Dataset.}
    \label{fig:adult_variance}
\end{minipage}

% \vspace{0.5cm} % vertical space between the rows

\begin{minipage}{0.32\textwidth}
    \centering
    \includegraphics[width=\linewidth]{files/bias_variance/bank_loss_vs_size.pdf}
    {\scriptsize \mbox{(d) {\textit{Generalization Error} on the Bank Dataset.}}}
    % \caption{Generalization Error on the Bank Dataset.}
    \label{fig:bank_generalization_error}
\end{minipage}%
\begin{minipage}{0.32\textwidth}
    \centering
    \includegraphics[width=\linewidth]{files/bias_variance/bank_bias_vs_size.pdf}
    {\scriptsize \mbox{(e) {\textit{Bias} on the Bank Dataset.}}}
    % \caption{Bias on the Bank Dataset.}
    \label{fig:bank_bias}
\end{minipage}%
\begin{minipage}{0.32\textwidth}
    \centering
    \includegraphics[width=\linewidth]{files/bias_variance/bank_variance_vs_size.pdf}
    {\scriptsize \mbox{(f) {\textit{Variance} on the Bank Dataset.}}}
    % \caption{Variance on the Bank Dataset.}
    \label{fig:bank_variance}
\end{minipage}
\caption{Generalization Error, Bias, and Variance for different methods on the Adult and Bank datasets. The methods shown include TabPFN-1000 (subsample size = 1000), TabPFN, TabPFN-en-16, TabPFN-Bagging, KNN-PFN, TabPFN-finetune, and Ours (\name). The legend is located in the top-right plot for clarity.}
\label{fig:generalization_bias_variance_plots}
\vspace{-5mm}
\end{figure*}
\textbf{Context Selection for Scaling TabPFN.}  The transformer architecture in TabPFN inherently leads to quadratic growth in memory usage as the context length increases.
As a result, the size of the support set used as context in each prediction is limited. Meanwhile, a well-chosen \(D_{\text{train}}\)
provides more relevant support examples, improving generalization. A simple approach is random subsampling~\cite{McElfreshKVCRGW23when}, but this can degrade performance, especially on large datasets~\cite{ICDPFN}. More structured methods include sketching techniques, such as CoreSet, K-Means, and Data Distillation~\cite{ICDPFN}, which aim to compress large datasets into representative subsets while preserving essential information~\cite{Scaling_TabPFN}. 
% Some sophisticated techniques~\cite{ICDPFN}~employ data distillation to learn context selection in an end-to-end manner. 
TuneTables~\cite{TuneTables}, on the other hand, attempts to encode the dataset into a compact learned representation, reducing memory overhead. Another class of methods selects sample-specific contexts instead of a fixed support set. For instance, MixturePFN~\cite{MixturePFN} partitions the training set into multiple subsets and assigns the most relevant one to each test sample. Similarity, LocalPFN~\cite{LocalPFN} and TabDPT~\cite{MaTabDPT}, instead use nearest neighbors to dynamically construct the support set \(D_{\text{train}}\) for each query (KNN-based selection). While these approaches improve TabPFN’s performance by refining \(D_{\text{train}}\), they disrupt PFN-style batching, significantly reducing inference efficiency.%\looseness=-1


\textbf{Fine-tuning Strategies for Enhancing TabPFN Performance.}
The second approach to improving TabPFN’s performance focuses on fine-tuning the pre-trained model to better adapt to downstream datasets. As shown in Equation~\ref{eq:tabpfn_post_pred}, the predictive distribution 
\( p_\theta(\boldsymbol{y}_{\text{q}} \mid \boldsymbol{X}_{\text{q}}, D_{\text{train}}) \) 
depends on both the training set \( D_{\text{train}} \) and the model parameters \( \theta \). While optimizing \( D_{\text{train}} \) improves the quality of support examples, fine-tuning enhances \( q_\theta \), enabling better alignment with downstream tasks.
A straightforward approach is to fine-tune all model parameters, as seen in TabForestPFN~\cite{TabForestPFN} and LocalPFN~\cite{LocalPFN}, which improves performance by adapting TabPFN’s learned prior to specific datasets. However, full fine-tuning incurs substantial computational costs due to the large number of model parameters. To mitigate this, TuneTables~\cite{TuneTables} offers a more efficient alternative by either fine-tuning the entire model or applying prompt-tuning~\cite{DBLP:conf/emnlp/LesterAC21}, which adjusts only a small set of parameters, reducing resource consumption.
Another efficient approach is adapter-based fine-tuning, as employed in MixturePFN~\cite{MixturePFN}, which fine-tunes additional adapter layers~\cite{Serial_Adapter} rather than modifying the entire model. This strategy provides a balance between computational efficiency and performance improvement, allowing the model to adapt while preserving the efficiency of the original pre-trained TabPFN.  A
detailed related work is presented in~\autoref{sec:related}.\looseness=-1
% While TabPFN demonstrates impressive performance in tabular classification tasks, it faces several limitations that hinder its broader applicability. In this work, we address four key challenges:

% \textbf{1) Scalability to Large Datasets.}
% One of the primary challenges with TabPFN, as well as with many other in-context learning models, is the quadratic complexity with respect to the size of the training dataset. As the training set grows large, the original TabPFN~\cite{Hollmann2022TabPFN} and several benchmarks~\cite{McElfreshKVCRGW23when,YeACloser} mitigate this issue by randomly sampling a fixed number of examples (e.g., 3000 samples) to form a manageable training subset. 
% % While this sampling strategy reduces computational overhead, it also limits the diversity of the information used during training, potentially leading to suboptimal predictions.
% Other approaches attempt to alleviate these constraints by grouping the dataset into smaller subsets~\cite{MixturePFN}, employing data distillation techniques~\cite{Scaling_TabPFN,ICDPFN}, or applying prompt tuning to reduce dataset size~\cite{TuneTables}.  Some methods further adapt TabPFN by utilizing nearest-neighbor techniques to identify similar samples and refine the model's predictions~\cite{LocalPFN,MaTabDPT}. These strategies also enable more effective handling of larger datasets by focusing the model's attention on specific parts of the data. However, they often disrupt the PFN-style batching process, which is essential for leveraging shared context across multiple test samples. This disruption diminishes the efficiency of in-context learning and significantly increases inference costs, making these methods difficult to scale for practical deploying.
% Given these challenges, there is a need for a lightweight solution to overcome the dataset size limitation while maintaining computational efficiency and preserving the key benefits of shared context during inference.

% \textbf{2) Fixed Feature Dimensionality.}
% TabPFN assumes a fixed input feature dimensionality, typically 100. Datasets with fewer features must be padded with zeros, while datasets with more features are downsampled or truncated, resulting in the loss of valuable information. Most existing methods, including TabPFN, address this limitation through simple feature transformation techniques, such as Principal Component Analysis (PCA)~\cite{MaTabDPT} and feature selection~\cite{TuneTables}. While these methods help manage feature space constraints, they often introduce artifacts, which can impair model flexibility and performance. This issue becomes particularly pronounced when working with high-dimensional datasets or datasets that include categorical features, where the reduction process may inadvertently discard useful information that could enhance model accuracy.
% % 这里还要提一下类别型特征, 还应该说一下，特征数非常多的时候可能不太行

% \textbf{3) Limited Capacity for Multi-Class Classification.}  
% % TabPFN is restricted to handling classification tasks with fewer than 10 classes, which is an inherent limitation when dealing with more complex real-world problems that involve larger class sets. Other methods often tackle this by training separate classifiers for each class, using one-vs-rest or multi-class classification schemes, but these techniques can be computationally expensive and do not fully leverage the model’s capacity for in-context learning.
% TabPFN is restricted to handling classification tasks with fewer than 10 classes, which limits its applicability to more complex real-world problems that involve larger class sets. To address this, existing methods often adjust the model’s output dimensions for fine-tuning to handle multiclass tasks~\cite{TuneTables}. However, this adjustment can create a significant gap between the task and the pre-training phase, making it difficult to directly enhance performance through fine-tuning alone.

% \textbf{4) Challenges in Fine-Tuning for Downstream Tasks.}  
% Like many deep learning models, TabPFN requires fine-tuning when applied to specific downstream datasets, as its pre-trained weights may not generalize well to unseen data distributions. Fine-tuning can be particularly challenging when the source and target datasets are misaligned. Existing methods often rely on conventional fine-tuning strategies, such as fine-tuning the entire model, which can be computationally expensive and time-consuming~\cite{TuneTables,TabForestPFN}. Given the substantial computational overhead of fine-tuning the full model, it is essential to explore more lightweight approaches that minimize resource consumption while ensuring effective adaptation to the target dataset.


% % \textbf{Approach.}

% % Several related approaches have made strides in addressing the limitations of TabPFN, but each has its own shortcomings, as summarized in the table below. To overcome these challenges, we propose several enhancements to the TabPFN framework. First, by introducing bagging, we reduce the computational overhead caused by quadratic complexity (Limitation 1), complementing existing feature-reordering ensemble methods. Next, we add an encoder at the input layer, fine-tuning it to map the original feature space into a fixed 100-dimensional representation, which helps resolve issues related to feature dimensionality (Limitation 2) and improves the handling of categorical features (Limitation 3). For tasks involving more than 10 classes (Limitation 3), our experimental results (TODO: reference section) demonstrate that these issues can be effectively addressed.
% % Despite these improvements, questions remain about the broader adaptability of TabPFN-like models and their generalization abilities across diverse datasets. To better understand these challenges, we next present an analysis of TabPFN's generalization behavior and discuss its implications for further adaptation.


% \textbf{Approach.}
% As discussed earlier, several related approaches have sought to address the limitations of TabPFN, each with its own set of trade-offs. ~\autoref{tab:limitations_comparison} presents a comparative analysis of TabPFN and other methods, emphasizing their ability to overcome challenges such as quadratic complexity, handling high-dimensional data, adapting to multi-class problems, maintaining efficient inference, and implementing fine-tuning techniques. To address these challenges, we propose several enhancements to the TabPFN framework. First, we introduce bagging to reduce computational overhead from quadratic complexity (Limitation 1). Next, we add an encoder at the input layer, fine-tuning it to map the feature space to a fixed 100-dimensional representation, addressing feature dimensionality and improving handling of categorical features (Limitation 2). For multi-class tasks with more than 10 classes (Limitation 3), we employ Error-Correcting Output Codes (ECOC), transforming multi-class classification into binary classification tasks. Following~\citealp{SF_PFN}, we analyze the generalization error of TabPFN and its more recent improved methods through targeted experiments. This analysis focuses on their bias and variance contributions, providing a detailed understanding of how these methods improve or limit generalization performance. The insights gained from the analysis inform the development of further adaptation strategies for TabPFN to diverse datasets.

% \subsection{Generalization Analysis of TabPFN}
% The generalization error of TabPFN can be attributed to two primary components: \textbf{bias} and \textbf{variance}. These components are influenced by the model’s architecture, pretraining assumptions, and the characteristics of the dataset. The generalization error can be mathematically decomposed by analyzing the discrepancy between the model’s predictions, \( q_\theta(y | x, D_n) \), and the true conditional distribution, \( p_0(y | x) \). Specifically, the generalization error can be expressed as:
% \begin{equation}    
% \begin{aligned} & q_{\boldsymbol{\theta}}\left(y \mid \boldsymbol{x}, \mathcal{D}_{n}\right)-p_{0}(y \mid \boldsymbol{x}) \\ = & \underbrace{q_{\boldsymbol{\theta}}\left(y \mid \boldsymbol{x}, \mathcal{D}_{n}\right)-\mathbb{E}_{\mathcal{D}_{n} \sim p_{0}^{n}}\left[q_{\boldsymbol{\theta}}\left(y \mid \boldsymbol{x}, \mathcal{D}_{n}\right)\right]}_{\text {variance }} \\ + & \underbrace{\mathbb{E}_{\mathcal{D}_{n} \sim p_{0}^{n}}\left[q_{\boldsymbol{\theta}}\left(y \mid \boldsymbol{x}, \mathcal{D}_{n}\right)\right]-p_{0}(y \mid \boldsymbol{x})}_{\text {bias }} .\end{aligned}
% \end{equation}
% where \( \mathbb{E}[\cdot] \) denotes the expectation over training datasets \( D_n \) sampled from the true distribution \( p_0 \). Understanding the sources of these errors is crucial for addressing the limitations of TabPFN and improving its performance across diverse tabular datasets.


% \textbf{Bias in TabPFN.} The bias in TabPFN arises from limitations in the prior-fitting procedure, where the model relies on a fixed prior \( p_{\text{prior}}(D_n) \) constructed using synthetic datasets generated by random neural networks. This approach leads to systematic misalignment with the true distribution \( p_0(D_n) \), especially when the target dataset deviates from the assumptions encoded during pretraining.
% \citealp{SF_PFN}~carefully analyzed this issue and showed that for a predictor to exhib vanishing bias over a sufficiently rich class of functions, it must be local. Specifically, \textit{only samples $(Y_i,X_i)\in D_n$ with $X_i$ close to $x$ should influence the prediction $q_\theta(y|x,D_n)$}. Building on this insight, a simple post-hoc KNN-based approach was proposed to reduce bias by aligning the model's inference with local data distributions.  This method has been adopted and extened by~\citealp{LocalPFN} and~\citealp{MaTabDPT}. 
% However, while the method helps mitigate bias, it distrupts \textbf{PFN-style batching}, sigificantly increases inference costs, and fails to fully leverage shared context across test instances.
% Another approach is fine-tuning TabPFN~\cite{TuneTables,TabForestPFN,LocalPFN}. By fine-tuning its parameters, the model can better align $q_{\theta}(y|x,D_n)$ with the true distribution $p_0$, adapting its prior to the specific characteristics of the dataset and reducing systematic errors. However, fine-tuning the entire model introduces significant computational overhead, making it impractical for many real-world applications. This highlights the need for a parameter-efficient fine-tuning strategy that can achieve similar alignment without excessive resource demands.

% \textbf{Variance in TabPFN.}
% Variance in TabPFN arises from the model’s sensitivity to variations in the training data $D_n$. Although TabPFN leverages the transformer architecture to effectively aggregate global information, the variance component remains significant due to constraints on context size and the model’s sensitivity to feature order. 
% One approach to mitigating variance is to increase the context length~\cite{SF_PFN}, enabling TabPFN to incorporate more training samples and mitigate the impact of individual data fluctuations. However, the quadratic computational cost of TabPFN’s transformer-based architecture makes this approach infeasible for large datasets. Another method involves feature order permutations. By permuting the order of tabular features and aggregating predictions across these permutations, ensemble diversity is introduced, which can reduce variance. However, this method provides limited diversity and lacks the guidance of supervised signals, restricting its effectiveness in improving model performance.

% % TODO：这部分是放在这，实验再讲一次，还是直接全放到实验部分？
% \textbf{Empirical Analysis on Real-World Datasets.} We conduct experiments using two real-world classification datasets, \textit{Bank}~\cite{bank_marketing_222} and \textit{Adult}~\cite{adult_2}. For each dataset, we sample multiple subsets of varying sizes from the training set and use these subsets as the support set for TabPFN. Each subset size is sampled 10 times to capture the variability across different data configurations. The test set remains fixed throughout the experiments, allowing for a consistent evaluation of the generalization error, bias, and variance of TabPFN variants, as well as the improvements made to TabPFN. 
% The experimental results, as shown in~\autoref{fig:generalization_bias_variance_plots}, reveal several important trends in the bias-variance behavior of TabPFN and its enhancements. These findings can be summarized as follows:
% % \begin{enumerate}[noitemsep,topsep=0pt,leftmargin=*]

% \textbf{1) Context Length and Bias-Variance Tradeoff}: As the context length increases to 1000, we observe that the \textbf{bias stops decreasing}, while the \textbf{variance continues to decrease}. This supports the findings of~\citealp{SF_PFN}, indicating that beyond a certain point, increasing the context length reduces variance without further improving bias.
    
% \textbf{2) KNN-Based Method and its Impact on Bias and Variance}: The use of \textbf{KNN-based context selection} (KNN + PFN)~\cite{SF_PFN,LocalPFN} effectively \textbf{decreases bias}, but at the cost of \textbf{increasing variance} compared to using the full dataset. This suggests that while KNN-based methods align the model with local data distributions, they introduce instability, which increases variance.

% \textbf{3) Ensemble Strategy in TabPFN}: For the \textit{Adult} dataset, the ensemble strategy (PFN\_ensemble) used by the original TabPFN model effectively \textbf{reduces variance}, but it may also result in an \textbf{increase in bias}, indicating that simple, unsupervised feature transformations do not always guarantee improvement.

% \textbf{4) Effectiveness of Bagging}: Implementing \textbf{Bagging} in TabPFN leads to a clear reduction in \textbf{variance}, improving generalization and reducing overall error. This method achieves a \textbf{substantial reduction in variance} without significantly affecting bias, making it a reliable technique for enhancing model performance without adding unnecessary complexity.


\subsection{Generalization Analysis of TabPFN Variants}
\label{sec:generalization_analysis_of_tabpfn}
\begin{table*}[h]
\caption{Comparison of TabPFN and related methods in terms of their impact on bias and variance, as well as their effectiveness in handling large datasets, high-dimensional features, adaptability to multiclass classification, and inference efficiency. The compared methods include TabPFN~\cite{Hollmann2022TabPFN}, TuneTables~\cite{TuneTables}, TabForestPFN~\cite{TabForestPFN}, LocalPFN~\cite{LocalPFN}, and MixturePFN~\cite{MixturePFN}. Our proposed method (\name) is distinguished for its ability to balance bias and variance while maintaining efficient scaling, adaptability to multiclass classification, and lightweight fine-tuning. %Different row colors indicate the \textit{strategies used for improving performance} (\raisebox{-0.3mm}{\tikz{\draw[white,fill=lightblue!30] (0,0) rectangle (0.3,0.3);}}), \textit{scalability} (\raisebox{-0.3mm}{\tikz{\draw[white,fill=mintgreen!30] (0,0) rectangle (0.3,0.3);}}), and \textit{efficiency} (\raisebox{-0.3mm}{\tikz{\draw[white,fill=cherrypink!30] (0,0) rectangle (0.3,0.3);}}).}
}
\vspace{1mm}
\centering
\setlength\tabcolsep{2.5pt}
\label{tab:limitations_comparison}
% \small{
\resizebox{16cm}{!}{
\begin{tabular}{lcccccccc}
    \toprule
    & \name~(Ours) & TabPFN & TuneTables & TabForestPFN & LocaLPFN &MixturePFN\\
    \midrule
     Reduces Bias  & \greencheck & \redx & \greencheck & \greencheck & \greencheck &  \greencheck \\
     Reduces Variance & \greencheck & \redx & \redx & \redx & \redx & \redx \\
     Scales to Large Datasets & \greencheck & \redx & \greencheck &  \redx & \greencheck & \greencheck\\
     Handles High-Dimensional Data & \greencheck & \redx & \redx & \redx & \redx  & \redx\\
     Adapts to More Than 10 Classes & \greencheck & \redx & \greencheck & \redx & \redx  &\redx \\
    % \textbf{Improves Feature Space Flexibility} & \greencheck & \redx & \greencheck & \redx & \greencheck & \greencheck \\
     No Additional Inference Cost & \greencheck &\greencheck & \greencheck & \greencheck & \redx & \redx \\
      % Fine-Tuning &  \multicolumn{1}{c}{\makecell{lightweight\\ encoder}} & \redx & \multicolumn{1}{c}{\makecell{prompt~\& \\ backbone}}  & backbone & backbone &adapter\\
       Fine-Tuning &  lightweight encoder & \redx & prompt~\&  backbone  & backbone & backbone &adapter\\
    \bottomrule
\end{tabular}
}
% }
% \vspace{-5mm}
\end{table*}
While various TabPFN variants have been proposed to enhance performance, their underlying mechanisms remain insufficiently understood. In this section, we leverage the \textbf{bias-variance decomposition framework}, as described in~\autoref{eq:bias-var}, which is introduced by~\citet{SF_PFN}, to analyze the generalization error of TabPFN and its variants on two real-world datasets: \textit{Adult}~\cite{adult_2} and \textit{Bank}~\cite{bank_marketing_222}. % To assess the impact of different strategies, we evaluate the original TabPFN (without context length restrictions) along with several representative variants, including TabPFN-1000 (random subsampling of 1000 samples), TabPFN-en-16 (randomly sample once and perform feature shuffling 16 times to form an ensemble of 16 predictions), TabPFN-KNN (KNN-based context selection), TabPFN-finetune (full model fine-tuning), and TabPFN-Bagging (bootstrapped sampling with 16 varying contexts).  
To assess the impact of different strategies, and based on our previous analysis, we evaluate the original TabPFN (without context length restrictions) alongside several representative variants. These include TabPFN-1000 (random subsampling of 1000 samples), TabPFN-en-16 (randomly sample once and perform feature shuffling 16 times to form an ensemble of 16 predictions), TabPFN-KNN (KNN-based context selection), TabPFN-finetune (full model fine-tuning), and TabPFN-Bagging (bootstrapped sampling with 16 varying contexts).
TabPFN-Bagging, unlike ensemble methods that require training multiple independent models, employs bootstrapped sampling to construct diverse support sets within a single inference process. 
A detailed description of its implementation is provided in Appendix~\ref{appendix:pfn-bagging}.

To further contextualize these findings, we compare all evaluated methods against our proposed approach,~\name. The experimental results, presented in~\autoref{fig:generalization_bias_variance_plots}, reveal several key trends in the bias-variance tradeoff across different TabPFN variants.  
As shown in \autoref{fig:generalization_bias_variance_plots} (b,c,e,f), increasing context length reduces variance while bias plateaus, consistent with prior findings~\cite{SF_PFN}. Similarly,  KNN-based context selection reduces bias but increases variance compared to using the full dataset, as it relies on localized subsets. Since these trends align with previous work, we focus on additional findings.  

\textbf{1) Fine-Tuning and its Impact:}  
\autoref{fig:generalization_bias_variance_plots} (b,e) shows that fine-tuning (TabPFN-finetune) effectively reduces bias by aligning the model’s prior with the characteristics of the dataset. However, it also increases variance, especially when the training set is small, where overfitting amplifies prediction variability, as shown in~\autoref{fig:generalization_bias_variance_plots} (c,f). These results suggest that fine-tuning requires careful regularization to balance bias and variance.  

\textbf{2) Ensemble Strategy and Bias-Variance Tradeoff:}  
\autoref{fig:generalization_bias_variance_plots} (b,c) indicates that ensemble-based methods (TabPFN-en-16) reduce variance but may increase bias due to unsupervised feature transformations. This observation highlights that ensemble methods, while helpful in reducing variance, may require additional bias-reducing strategies to optimize overall model performance. 

\textbf{3) Effectiveness of Bagging:}  
As shown in \autoref{fig:generalization_bias_variance_plots} (c,f), Bagging significantly reduces variance while maintaining stable bias. By introducing diversity through bootstrapped sampling, it achieves variance reduction comparable to ensemble methods but at a lower computational cost. These results highlight Bagging as a simple yet effective approach for improving TabPFN’s performance. 


% 每一点都要结合图来讲，比如从那一幅图……

% \textbf{Bias-Variance Insights and \name~Improvement.} The above results suggest that TabPFN variants generally affect either bias or variance, but rarely both simultaneously. For instance, KNN-based context selection helps reduce bias but at the expense of variance, while ensemble methods reduce variance but may increase bias. These findings motivate the development of \name, which addresses both bias and variance by combining effective context selection with a novel adaptation strategy. By carefully balancing bias and variance, \name~enhances TabPFN’s generalization performance across different datasets without introducing additional inference computational costs.

% \textbf{Insights from Bias-Variance Tradeoff.} The results above indicate that TabPFN variants typically impact either bias or variance, but rarely both simultaneously. For instance, KNN-based context selection reduces bias, but at the cost of increased variance, while ensemble methods decrease variance but may raise bias. These observations motivate the development of \name, which addresses both bias and variance through a novel adaptation strategy.\looseness=-1
% % 这里可以说based on the additional results not covered in ……
% Various approaches have been proposed to enhance TabPFN’s performance, each addressing specific limitations. Some focus on efficient context selection, while others explore fine-tuning strategies to adapt the model to downstream tasks. However, these methods often involves trade-offs among computational efficiency, scalability, and adaptability. 
% A detailed comparison of TabPFN and its variants is presented in~\autoref{tab:limitations_comparison}, which highlights the strengths of different approaches in terms of scaling to large datasets, handling high-dimensional features, and maintaining efficient inference. Additionally, various methods for reducing generalization error are discussed, emphasizing strategies that improve model robustness and performance across diverse downstream tasks. \looseness=-1
% % 在说表的时候思路要对的上，重点是bias variance，后面是附带的，
% \textbf{Insights from Bias-Variance Tradeoff.}  
The results above, based on additional findings not covered in~\cite{SF_PFN}, indicate that TabPFN variants typically impact either bias or variance, but rarely both simultaneously. For instance, KNN-based context selection reduces bias but increases variance, while the original ensemble strategy in~\citet{Hollmann2022TabPFN} (TabPFN-en-16) lowers variance but may increase bias. These observations highlight the need for a method that jointly optimizes both aspects, motivating the development of~\name.  

Existing approaches to improving TabPFN focus on context selection or fine-tuning, but often introduce trade-offs in computational efficiency, scalability, and adaptability. A comparison in~\autoref{tab:limitations_comparison} highlights how different strategies affect bias, variance, and their ability to handle large datasets and high-dimensional features efficiently.
% Existing approaches to improving TabPFN focus on optimizing context selection or fine-tuning the pre-trained model for better adaptation. However, these methods often introduce trade-offs among computational efficiency, scalability, and adaptability. A detailed comparison in~\autoref{tab:limitations_comparison} highlights how different strategies impact bias and variance, while also assessing their effectiveness in handling large datasets, high-dimensional features, and inference efficiency. 
%Additionally, various techniques for reducing generalization error are discussed, emphasizing approaches that enhance model robustness and performance across diverse downstream tasks.

