\section*{Impact Statement}
Our work advances the field of tabular learning and in-context learning (ICL) by introducing a method that significantly improves TabPFNâ€™s scalability, adaptability, and performance. Given that tabular data is widely used across industries such as finance, healthcare, and e-commerce, achieving state-of-the-art classification accuracy has far-reaching benefits. Our approach enhances the usability of tabular foundation models (TFMs), providing a more effective and scalable alternative to conventional methods while preserving inference efficiency.
We hope that our results inspire further research into ICL-driven approaches for tabular data and their applications in broader real-world tasks. As our method is built on pre-trained TabPFN, its deployment in high-stakes applications should consider potential limitations, such as reliance on the model's prior and sensitivity to dataset characteristics. We do not foresee significant negative societal impacts arising from our work.