@misc{A2PO,
      title={Order Matters: Agent-by-agent Policy Optimization}, 
      author={Xihuai Wang and Zheng Tian and Ziyu Wan and Ying Wen and Jun Wang and Weinan Zhang},
      year={2023},
      eprint={2302.06205},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2302.06205}, 
}

@misc{AdaPS,
      title={Adaptive parameter sharing for multi-agent reinforcement learning}, 
      author={Dapeng Li and Na Lou and Bin Zhang and Zhiwei Xu and Guoliang Fan},
      year={2023},
      eprint={2312.09009},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2312.09009}, 
}

@inproceedings{DynParamSharing,
  title     = {ADMN: Agent-Driven Modular Network for Dynamic Parameter Sharing in Cooperative Multi-Agent Reinforcement Learning},
  author    = {Yu, Yang and Yin, Qiyue and Zhang, Junge and Xu, Pei and Huang, Kaiqi},
  booktitle = {Proceedings of the Thirty-Third International Joint Conference on
               Artificial Intelligence, {IJCAI-24}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Kate Larson},
  pages     = {302--310},
  year      = {2024},
  month     = {8},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2024/34},
  url       = {https://doi.org/10.24963/ijcai.2024/34},
}

@article{HAPPO,
  author       = {Jakub Grudzien Kuba and
                  Ruiqing Chen and
                  Muning Wen and
                  Ying Wen and
                  Fanglei Sun and
                  Jun Wang and
                  Yaodong Yang},
  title        = {Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning},
  journal      = {CoRR},
  volume       = {abs/2109.11251},
  year         = {2021},
  url          = {https://arxiv.org/abs/2109.11251},
  eprinttype    = {arXiv},
  eprint       = {2109.11251},
  timestamp    = {Fri, 19 Aug 2022 14:57:46 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2109-11251.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{MTL,
author = {Caruana, Rich},
year = {1997},
month = {07},
pages = {},
title = {Multitask Learning},
volume = {28},
isbn = {978-1-4613-7527-2},
journal = {Machine Learning},
doi = {10.1023/A:1007379606734}
}

@article{MultiTaskMARL,
author = {Li, Chao and Dong, Shaokang and Yang, Shangdong and Hu, Yujing and Ding, Tianyu and li, Wenbin and Gao, Yang},
year = {2024},
month = {10},
pages = {},
title = {Multi-Task Multi-Agent Reinforcement Learning With Interaction and Task Representations},
volume = {PP},
journal = {IEEE transactions on neural networks and learning systems},
doi = {10.1109/TNNLS.2024.3475216}
}

@misc{PSNetworkPruning,
      title={Parameter Sharing with Network Pruning for Scalable Multi-Agent Deep Reinforcement Learning}, 
      author={Woojun Kim and Youngchul Sung},
      year={2023},
      eprint={2303.00912},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2303.00912}, 
}

@inproceedings{PrioritizedTasKMining,
author = {Yu, Yang and Yin, Qiyue and Zhang, Junge and Huang, Kaiqi},
title = {Prioritized Tasks Mining for Multi-Task Cooperative Multi-Agent Reinforcement Learning},
year = {2023},
isbn = {9781450394321},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
booktitle = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
pages = {1615–1623},
numpages = {9},
keywords = {multi-agent cooperation, multi-task learning, reinforcement learning},
location = {London, United Kingdom},
series = {AAMAS '23}
}

@misc{SelectiveSharingExp,
      title={Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning}, 
      author={Matthias Gerstgrasser and Tom Danino and Sarah Keren},
      year={2024},
      eprint={2311.00865},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2311.00865}, 
}

@misc{SharedExpAC,
      title={Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning}, 
      author={Filippos Christianos and Lukas Schäfer and Stefano V. Albrecht},
      year={2021},
      eprint={2006.07169},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2006.07169}, 
}

@article{li2021CDS,
  title={Celebrating diversity in shared multi-agent reinforcement learning},
  author={Li, Chenghao and Wang, Tonghan and Wu, Chengjie and Zhao, Qianchuan and Yang, Jun and Zhang, Chongjie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={3991--4002},
  year={2021}
}

@misc{omidshafiei2017deepdecentralizedmultitaskmultiagent,
      title={Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability}, 
      author={Shayegan Omidshafiei and Jason Pazis and Christopher Amato and Jonathan P. How and John Vian},
      year={2017},
      eprint={1703.06182},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1703.06182}, 
}

@article{terry2020revisiting,
  title={Revisiting parameter sharing in multi-agent deep reinforcement learning},
  author={Terry, Justin K and Grammel, Nathaniel and Son, Sanghyun and Black, Benjamin and Agrawal, Aakriti},
  journal={arXiv preprint arXiv:2005.13625},
  year={2020}
}

@misc{wang2023multitaskmultiagentsharedlayers,
      title={Multi-Task Multi-Agent Shared Layers are Universal Cognition of Multi-Agent Coordination}, 
      author={Jiawei Wang and Jian Zhao and Zhengtao Cao and Ruili Feng and Rongjun Qin and Yang Yu},
      year={2023},
      eprint={2312.15674},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2312.15674}, 
}

@misc{zhang2024hybridtrainingenhancedmultitask,
      title={Hybrid Training for Enhanced Multi-task Generalization in Multi-agent Reinforcement Learning}, 
      author={Mingliang Zhang and Sichang Su and Chengyang He and Guillaume Sartoretti},
      year={2024},
      eprint={2408.13567},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.13567}, 
}

