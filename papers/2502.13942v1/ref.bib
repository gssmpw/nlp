@article{hospedales2021meta,
  title={Meta-learning in neural networks: A survey},
  author={Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={9},
  pages={5149--5169},
  year={2021},
  publisher={IEEE}
}

@inproceedings{santoro2016meta,
  title={Meta-learning with memory-augmented neural networks},
  author={Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
  booktitle={International Conference on Machine Learning},
  pages={1842--1850},
  year={2016},
  organization={PMLR}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{zhu2023multilingual,
  title={Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis},
  author={Zhu, Wenhao and Liu, Hongyi and Dong, Qingxiu and Xu, Jingjing and Huang, Shujian and Kong, Lingpeng and Chen, Jiajun and Li, Lei},
  booktitle={Findings of the Association for Computational Linguistics: NAACL},
  pages={2765--2781},
  year={2024}
}

@inproceedings{xiao2023patterngpt,
  title={PatternGPT: A Pattern-Driven Framework for Large Language Model Text Generation},
  author={Xiao, Le and Shan, Xin and Chen, Xiaolin},
  booktitle={Proceedings of the International Conference on Computing and Pattern Recognition},
  pages={72--78},
  year={2023}
}

@inproceedings{robinson2022leveraging,
  title={Leveraging Large Language Models for MulIEEE Transactions on Image Processingle Choice Question Answering},
  author={Robinson, Joshua and Wingate, David},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{beal2022billion,
  title={Billion-scale pretraining with vision transformers for multi-task visual representations},
  author={Beal, Josh and Wu, Hao-Yu and Park, Dong Huk and Zhai, Andrew and Kislyuk, Dmitry},
  booktitle={IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={564--573},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Conference on Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{dehghani2023scaling,
  title={Scaling vision transformers to 22 billion parameters},
  author={Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas Peter and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and others},
  booktitle={International Conference on Machine Learning},
  pages={7480--7512},
  year={2023},
  organization={PMLR}
}

@inproceedings{singh2023effectiveness,
  title={The effectiveness of MAE pre-pretraining for billion-scale pretraining},
  author={Singh, Mannat and Duval, Quentin and Alwala, Kalyan Vasudev and Fan, Haoqi and Aggarwal, Vaibhav and Adcock, Aaron and Joulin, Armand and Doll{\'a}r, Piotr and Feichtenhofer, Christoph and Girshick, Ross and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5484--5494},
  year={2023}
}

@inproceedings{wang2022bevt,
  title={Bevt: Bert pretraining of video transformers},
  author={Wang, Rui and Chen, Dongdong and Wu, Zuxuan and Chen, Yinpeng and Dai, Xiyang and Liu, Mengchen and Jiang, Yu-Gang and Zhou, Luowei and Yuan, Lu},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={14733--14743},
  year={2022}
}

@article{wei2022emergent,
title={Emergent Abilities of Large Language Models},
author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Conference on Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{lester2021power,
  title={The Power of Scale for Parameter-Efficient Prompt Tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={3045--3059},
  year={2021}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Conference on Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@inproceedings{saparov2022language,
  title={Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought},
  author={Saparov, Abulhair and He, He},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Conference on Neural Information Processing Systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@inproceedings{qiao2022reasoning,
  title={Reasoning with Language Model Prompting: A Survey},
  author={Qiao, Shuofei and Ou, Yixin and Zhang, Ningyu and Chen, Xiang and Yao, Yunzhi and Deng, Shumin and Tan, Chuanqi and Huang, Fei and Chen, Huajun},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  pages={5368--5393},
  year={2023}
}

@inproceedings{bahdanau2015neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyung Hyun and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={4171--4186},
  year={2019}
}

@misc{openai2023chatgpt,
    author={{OpenAI}},
    title={Introducing ChatGPT},
    year={2023},
    howpublished = {\url{https://openai.com/blog/chatgpt}},
    note={[Online; accessed 2-August-2023]}
}

@article{openai2023gpt4,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={International Conference on Computer Vision},
  pages={10012--10022},
  year={2021}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@inproceedings{bao2021beit,
  title={BEiT: BERT Pre-Training of Image Transformers},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{chen2021pre,
  title={Pre-trained image processing transformer},
  author={Chen, Hanting and Wang, Yunhe and Guo, Tianyu and Xu, Chang and Deng, Yiping and Liu, Zhenhua and Ma, Siwei and Xu, Chunjing and Xu, Chao and Gao, Wen},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={12299--12310},
  year={2021}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{yu2022coca,
    title={CoCa: Contrastive Captioners are Image-Text Foundation Models},
    author={Jiahui Yu and Zirui Wang and Vijay Vasudevan and Legg Yeung and Mojtaba Seyedhosseini and Yonghui Wu},
    journal={Transactions on Machine Learning Research},
    issn={2835-8856},
    year={2022},
}

@inproceedings{wang2023image,
  title={Image as a Foreign Language: BEiT Pretraining for Vision and Vision-Language Tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={19175--19186},
  year={2023}
}

@article{wang2023review,
  title={Review of large vision models and visual prompt engineering},
  author={Wang, Jiaqi and Liu, Zhengliang and Zhao, Lin and Wu, Zihao and Ma, Chong and Yu, Sigang and Dai, Haixing and Yang, Qiushi and Liu, Yiheng and Zhang, Songyao and others},
  journal={Meta-Radiology},
  pages={100047},
  year={2023},
  publisher={Elsevier}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@inproceedings{petroni2019language,
  title={Language Models as Knowledge Bases?},
  author={Petroni, Fabio and Rockt{\"a}schel, Tim and Riedel, Sebastian and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing and the International Joint Conference on Natural Language Processing},
  pages={2463--2473},
  year={2019}
}

@inproceedings{gao2021making,
  title={Making Pre-trained Language Models Better Few-shot Learners},
  author={Gao, Tianyu and Fisch, Adam and Chen, Danqi},
  booktitle={The Joint Conference of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing},
  pages={3816--3830},
  year={2021}
}

@inproceedings{wang2022learning,
  title={Learning to prompt for continual learning},
  author={Wang, Zifeng and Zhang, Zizhao and Lee, Chen-Yu and Zhang, Han and Sun, Ruoxi and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and Pfister, Tomas},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={139--149},
  year={2022}
}

@inproceedings{shin2020autoprompt,
  title={AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts},
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing},
  pages={4222--4235},
  year={2020}
}

@article{chen2022adaptformer,
  title={Adaptformer: Adapting vision transformers for scalable visual recognition},
  author={Chen, Shoufa and Ge, Chongjian and Tong, Zhan and Wang, Jiangliu and Song, Yibing and Wang, Jue and Luo, Ping},
  journal={Conference on Neural Information Processing Systems},
  volume={35},
  pages={16664--16678},
  year={2022}
}

@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}

@inproceedings{zhou2022conditional,
  title={Conditional prompt learning for vision-language models},
  author={{Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei}},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={16816--16825},
  year={2022}
}

@inproceedings{huang2023inner,
  title={Inner Monologue: Embodied Reasoning through Planning with Language Models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  booktitle={Conference on Robot Learning},
  pages={1769--1782},
  year={2023},
  organization={PMLR}
}

@inproceedings{grant2018recasting,
  title={Recasting Gradient-Based Meta-Learning as Hierarchical Bayes},
  author={Grant, Erin and Finn, Chelsea and Levine, Sergey and Darrell, Trevor and Griffiths, Thomas},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
  journal={Conference on Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@article{snell2017prototypical,
  title={Prototypical networks for few-shot learning},
  author={Snell, Jake and Swersky, Kevin and Zemel, Richard},
  journal={Conference on Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{sung2018learning,
  title={Learning to compare: Relation network for few-shot learning},
  author={Sung, Flood and Yang, Yongxin and Zhang, Li and Xiang, Tao and Torr, Philip HS and Hospedales, Timothy M},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={1199--1208},
  year={2018}
}

@inproceedings{mishra2018simple,
  title={A Simple Neural Attentive Meta-Learner},
  author={Mishra, Nikhil and Rohaninejad, Mostafa and Chen, Xi and Abbeel, Pieter},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{munkhdalai2017meta,
  title={Meta networks},
  author={Munkhdalai, Tsendsuren and Yu, Hong},
  booktitle={International Conference on Machine Learning},
  pages={2554--2563},
  year={2017},
  organization={PMLR}
}

@inproceedings{munkhdalai2018rapid,
  title={Rapid adaptation with conditionally shifted neurons},
  author={Munkhdalai, Tsendsuren and Yuan, Xingdi and Mehri, Soroush and Trischler, Adam},
  booktitle={International Conference on Machine Learning},
  pages={3664--3673},
  year={2018},
  organization={PMLR}
}

@inproceedings{ravi2016optimization,
  title={Optimization as a model for few-shot learning},
  author={Ravi, Sachin and Larochelle, Hugo},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@article{tsimpoukelli2021multimodal,
  title={Multimodal few-shot learning with frozen language models},
  author={Tsimpoukelli, Maria and Menick, Jacob L and Cabi, Serkan and Eslami, SM and Vinyals, Oriol and Hill, Felix},
  journal={Conference on Neural Information Processing Systems},
  volume={34},
  pages={200--212},
  year={2021}
}

@inproceedings{song2022clip,
  title={CLIP Models are Few-Shot Learners: Empirical Studies on VQA and Visual Entailment},
  author={Song, Haoyu and Dong, Li and Zhang, Weinan and Liu, Ting and Wei, Furu},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  pages={6088--6100},
  year={2022}
}

@inproceedings{jin2022good,
  title={A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models},
  author={Jin, Woojeong and Cheng, Yu and Shen, Yelong and Chen, Weizhu and Ren, Xiang},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  pages={2763--2775},
  year={2022}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Conference on Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@inproceedings{najdenkoska2022meta,
  title={Meta Learning to Bridge Vision and Language Models for Multimodal Few-Shot Learning},
  author={Najdenkoska, Ivona and Zhen, Xiantong and Worring, Marcel},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{lee2019set,
  title={Set transformer: A framework for attention-based permutation-invariant neural networks},
  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  booktitle={International Conference on Machine Learning},
  pages={3744--3753},
  year={2019},
  organization={PMLR}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European Conference on Computer Vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{hodosh2013framing,
  title={Framing image description as a ranking task: Data, models and evaluation metrics},
  author={Hodosh, Micah and Young, Peter and Hockenmaier, Julia},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={853--899},
  year={2013}
}

@article{young2014image,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  journal={Transactions of the Association for Computational Linguistics},
  volume={2},
  pages={67--78},
  year={2014},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info}
}

@inproceedings{zhang2023recognize,
  title={Recognize anything: A strong image tagging model},
  author={Zhang, Youcai and Huang, Xinyu and Ma, Jinyu and Li, Zhaoyang and Luo, Zhaochuan and Xie, Yanchun and Qin, Yuzhuo and Luo, Tong and Li, Yaqian and Liu, Shilong and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1724--1732},
  year={2024}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{agarwal2008meteor,
  title={Meteor, m-bleu and m-ter: Evaluation metrics for high-correlation with human rankings of machine translation output},
  author={Agarwal, Abhaya and Lavie, Alon},
  booktitle={Proceedings of the Workshop on Statistical Machine Translation},
  pages={115--118},
  year={2008}
}

@inproceedings{rouge2004package,
  title={A package for automatic evaluation of summaries},
  author={ROUGE, Lin CY},
  booktitle={Proceedings of Workshop on Text Summarization of ACL},
  volume={5},
  year={2004}
}

@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={4566--4575},
  year={2015}
}

@inproceedings{chan2023ic,
  title={IC3: Image Captioning by Committee Consensus},
  author={Chan, David and Myers, Austin and Vijayanarasimhan, Sudheendra and Ross, David A and Canny, John},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year={2023}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the International Conference on Artificial Intelligence and Statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{loshchilov2018decoupled,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{hessel2021clipscore,
  title={CLIPScore: A Reference-free Evaluation Metric for Image Captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Le Bras, Ronan and Choi, Yejin},
  booktitle={EMNLP},
  pages={7514--7528},
  year={2021}
}

@article{li2021concise,
  title={A concise review of recent few-shot meta-learning methods},
  author={Li, Xiaoxu and Sun, Zhuo and Xue, Jing-Hao and Ma, Zhanyu},
  journal={Neurocomputing},
  volume={456},
  pages={463--468},
  year={2021},
  publisher={Elsevier}
}

@article{wang2020generalizing,
  title={Generalizing from a few examples: A survey on few-shot learning},
  author={Wang, Yaqing and Yao, Quanming and Kwok, James T and Ni, Lionel M},
  journal={ACM Computing Surveys},
  volume={53},
  number={3},
  pages={1--34},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{lu2022learn,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal={Conference on Neural Information Processing Systems},
  volume={35},
  pages={2507--2521},
  year={2022}
}

@inproceedings{jiang2022subspace,
  title={Subspace learning for effective meta-learning},
  author={Jiang, Weisen and Kwok, James and Zhang, Yu},
  booktitle={International Conference on Machine Learning},
  pages={10177--10194},
  year={2022},
  organization={PMLR}
}

@article{crystal1997cambridge,
  title={The Cambridge encyclopedia of Language.â€”2-nd edition},
  author={Crystal, David},
  journal={Cambridge: Cambridge University Press},
  year={1997}
}

@article{ghojogh2020attention,
  title={Attention mechanism, transformers, BERT, and GPT: tutorial and survey},
  author={Ghojogh, Benyamin and Ghodsi, Ali},
  year={2020},
  publisher={OSF Preprints}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@article{feng2024towards,
  title={Towards revealing the mystery behind chain of thought: a theoretical perspective},
  author={Feng, Guhao and Zhang, Bohang and Gu, Yuntian and Ye, Haotian and He, Di and Wang, Liwei},
  journal={Conference on Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{mu2024embodiedgpt,
  title={Embodiedgpt: Vision-language pre-training via embodied chain of thought},
  author={Mu, Yao and Zhang, Qinglong and Hu, Mengkang and Wang, Wenhai and Ding, Mingyu and Jin, Jun and Wang, Bin and Dai, Jifeng and Qiao, Yu and Luo, Ping},
  journal={Conference on Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{elsken2020meta,
  title={Meta-learning of neural architectures for few-shot learning},
  author={Elsken, Thomas and Staffler, Benedikt and Metzen, Jan Hendrik and Hutter, Frank},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={12365--12375},
  year={2020}
}

@inproceedings{huang20213d,
  title={3D-metaconnet: meta-learning for 3D shape classification and segmentation},
  author={Huang, Hao and Li, Xiang and Wang, Lingjing and Fang, Yi},
  booktitle={International Conference on 3D Vision},
  pages={982--991},
  year={2021},
  organization={IEEE}
}

@article{lang2023base,
  title={Base and meta: A new perspective on few-shot segmentation},
  author={Lang, Chunbo and Cheng, Gong and Tu, Binfei and Li, Chao and Han, Junwei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@inproceedings{zhu2023minigpt,
  title={MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@inproceedings{vinyals2015show,
  title={Show and tell: A neural image caption generator},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={3156--3164},
  year={2015}
}

@inproceedings{xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={2048--2057},
  year={2015},
  organization={PMLR}
}

@article{al2022image,
  title={Image captioning with novel topics guidance and retrieval-based topics re-weighting},
  author={Al-Qatf, Majjed and Wang, Xingfu and Hawbani, Ammar and Abdusallam, Amr and Alsamhi, Saeed Hammod},
  journal={IEEE Transactions on Multimedia},
  year={2022},
  publisher={IEEE}
}

@article{zhao2020cross,
  title={Cross-domain image captioning via cross-modal retrieval and model adaptation},
  author={Zhao, Wentian and Wu, Xinxiao and Luo, Jiebo},
  journal={IEEE Transactions on Image Processing},
  volume={30},
  pages={1180--1192},
  year={2020},
  publisher={IEEE}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@inproceedings{you2016image,
  title={Image captioning with semantic attention},
  author={You, Quanzeng and Jin, Hailin and Wang, Zhaowen and Fang, Chen and Luo, Jiebo},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={4651--4659},
  year={2016}
}

@article{yang2022human,
  title={Human-centric image captioning},
  author={Yang, Zuopeng and Wang, Pengbo and Chu, Tianshu and Yang, Jie},
  journal={Pattern Recognition},
  volume={126},
  pages={108545},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{wang2019hierarchical,
  title={Hierarchical attention network for image captioning},
  author={Wang, Weixuan and Chen, Zhihong and Hu, Haifeng},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={8957--8964},
  year={2019}
}

@inproceedings{girshick2015fast,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={International Conference on Computer Vision},
  pages={1440--1448},
  year={2015}
}

@inproceedings{anderson2016spice,
  title={Spice: Semantic propositional image caption evaluation},
  author={Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
  booktitle={European Conference on Computer Vision},
  pages={382--398},
  year={2016},
  organization={Springer}
}

@inproceedings{pan2020x,
  title={X-linear attention networks for image captioning},
  author={Pan, Yingwei and Yao, Ting and Li, Yehao and Mei, Tao},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={10971--10980},
  year={2020}
}

@inproceedings{yao2019hierarchy,
  title={Hierarchy parsing for image captioning},
  author={Yao, Ting and Pan, Yingwei and Li, Yehao and Mei, Tao},
  booktitle={International Conference on Computer Vision},
  pages={2621--2629},
  year={2019}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={European Conference on Computer Vision},
  pages={121--137},
  year={2020},
  organization={Springer}
}

@inproceedings{wang2022end,
  title={End-to-end transformer based model for image captioning},
  author={Wang, Yiyu and Xu, Jungang and Sun, Yingfei},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={36},
  number={3},
  pages={2585--2594},
  year={2022}
}

@inproceedings{zeng2022s2,
  title={S2 Transformer for Image Captioning.},
  author={Zeng, Pengpeng and Zhang, Haonan and Song, Jingkuan and Gao, Lianli},
  booktitle={International Joint Conference on Artificial Intelligence},
  pages={1608--1614},
  year={2022}
}

@inproceedings{ramos2023smallcap,
  title={Smallcap: lightweight image captioning prompted with retrieval augmentation},
  author={Ramos, Rita and Martins, Bruno and Elliott, Desmond and Kementchedjhieva, Yova},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  pages={2840--2849},
  year={2023}
}

@inproceedings{sarto2022retrieval,
  title={Retrieval-augmented transformer for image captioning},
  author={Sarto, Sara and Cornia, Marcella and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle={Proceedings of the International Conference on Content-based Multimedia Indexing},
  pages={1--7},
  year={2022}
}

@inproceedings{zhai2024investigating,
  title={Investigating the Catastrophic Forgetting in Multimodal Large Language Model Fine-Tuning},
  author={Zhai, Yuexiang and Tong, Shengbang and Li, Xiao and Cai, Mu and Qu, Qing and Lee, Yong Jae and Ma, Yi},
  booktitle={Conference on Parsimony and Learning},
  pages={202--227},
  year={2024},
  organization={PMLR}
}

@inproceedings{luo2022tuning,
  title={I-tuning: Tuning frozen language models with image for lightweight image captioning},
  author={Luo, Ziyang and Hu, Zhipeng and Xi, Yadong and Zhang, Rongsheng and Ma, Jing},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@article{yang2024exploring,
  title={Exploring diverse in-context configurations for image captioning},
  author={Yang, Xu and Wu, Yongliang and Yang, Mingzhuo and Chen, Haokun and Geng, Xin},
  journal={Conference on Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{franceschi2018bilevel,
  title={Bilevel programming for hyperparameter optimization and meta-learning},
  author={Franceschi, Luca and Frasconi, Paolo and Salzo, Saverio and Grazzi, Riccardo and Pontil, Massimiliano},
  booktitle={International Conference on Machine Learning},
  pages={1568--1577},
  year={2018},
  organization={PMLR}
}

@inproceedings{li2019feature,
  title={Feature-critic networks for heterogeneous domain generalization},
  author={Li, Yiying and Yang, Yongxin and Zhou, Wei and Hospedales, Timothy},
  booktitle={International Conference on Machine Learning},
  pages={3915--3924},
  year={2019},
  organization={PMLR}
}
