
\begin{table}[t]
\centering
\caption{Page size significantly impacts the LLM serving system's efficiency: Larger page size is more hardware-friendly as it improves contiguity of memory layout and the GPU bandwidth utilization during attention computation. For example, simply shrinking the page size in QServe~\cite{lin2024qserve} leads to prominent slow-down of the end-to-end system. We evaluate the per-step decoding latency (ms / step) of QServe on a single A100 GPU for demonstration. We use Llama3-8B model architecture, with the batch size of 32.
}
\vspace{5pt}
\footnotesize
\scalebox{1.0}{
\begin{tabular}{ccccc}
\toprule
\multirow{2.5}{*}{Seq\_len} 
& \multicolumn{4}{c}{Page Size} \\ 
\cmidrule{2-5} & 16 & 32 & \textbf{64} & 128 \\
\midrule
512 & 11.0 ms & 10.7 ms & \textbf{10.5 ms} & 10.5 ms\\
1024 & 13.8 ms & 13.0 ms & \textbf{12.7 ms} & 12.7 ms\\
2048 & 22.1 ms & 20.1 ms & \textbf{18.3 ms} & 18.2 ms\\
4096 & 35.7 ms & 31.6 ms & \textbf{28.1 ms} & 28.1 ms\\
8192 & \textcolor{red}{\textbf{77.1 ms}} & \textcolor{red}{\textbf{63.0 ms}} & \textbf{51.0 ms} & 50.6 ms\\
\midrule
Max Slowdown & 1.52$\times$ & 1.25$\times$ & 1.01$\times$ &  1.00$\times$ \\
\bottomrule
\end{tabular}
}
\label{tab:ana:page_size_speed}
\end{table}






