%%%% ijcai25.tex

\typeout{IJCAI--25 Instructions for Authors}

% These are the instructions for authors for IJCAI-25.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai25.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai25}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[switch]{lineno}

% User Add
\usepackage{threeparttable}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{amssymb}

% Comment out this line in the camera-ready submission
% \linenumbers




\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\usepackage{longtable}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{pifont}   % 用于 Ding 符号
\usepackage{tablefootnote} % 加载 tablefootnote 包
% \usepackage[table,dvipsnames]{xcolor}
\usepackage{colortbl} % 用于表格颜色设置

\newcommand{\qm}{\textcolor[HTML]{0402e1}{\textbf{\scriptsize\ding{108}}}}
\newcommand{\md}{\textcolor[HTML]{e06e2f}{\textbf{\scriptsize\ding{108}}}}
\newcommand{\oc}{\textcolor[HTML]{a961c8}{\textbf{\scriptsize\ding{108}}}}
\newcommand{\pcqm}{\textcolor[HTML]{55b838}{\textbf{\scriptsize\ding{108}}}}
\newcommand{\mol}{\textcolor[HTML]{3f68a0}{\textbf{\scriptsize\ding{108}}}}
\newcommand{\coll}{\textcolor[HTML]{8e3660}{\textbf{\scriptsize\ding{108}}}}
\newcommand{\zinc}{\textcolor[HTML]{337356}{\textbf{\scriptsize\ding{108}}}}


\newcommand{\tu}{\textcolor[HTML]{337356}{\textbf{\scriptsize\ding{110}}}}



\newcommand{\gdsc}{\textcolor[HTML]{337356}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\ccle}{\textcolor[HTML]{ea34da}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\tcga}{\textcolor[HTML]{8E44AD}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\prism}{\textcolor[HTML]{3498DB}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\nci}{\textcolor[HTML]{E74C3C}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\cosmic}{\textcolor[HTML]{16A085}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\pubchem}{\textcolor[HTML]{F1C40F}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\dmsz}{\textcolor[HTML]{9B59B6}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\ctrp}{\textcolor[HTML]{2ECC71}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\pdtc}{\textcolor[HTML]{E67E22}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\scRNA}{\textcolor[HTML]{A61E22}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\depmap}{\textcolor[HTML]{0e00d9}{\textbf{\scriptsize\ding{110}}}}
%========================DTI-DDI=================================
\newcommand{\OGBbiokg}{\textcolor[HTML]{A58745}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\ZhangDDI}{\textcolor[HTML]{1203d8}{\textbf{\scriptsize\ding{110}}}}
%\newcommand{\BioKG}{\textcolor[HTML]{B78045}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\PDBbind}{\textcolor[HTML]{C78045}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\Metz}{\textcolor[HTML]{ab7c77}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\LIT}{\textcolor[HTML]{6f1d44}{\textbf{\scriptsize\ding{110}}}}
\newcommand{\Karimi}{\textcolor[HTML]{F29115}{\textbf{\scriptsize\ding{110}}}}

\newcommand{\SB}{\textcolor[HTML]{1402e1}{\textbf{\scriptsize\ding{108}}}}
\newcommand{\UD}{\textcolor[HTML]{5a6e2f}{\textbf{\scriptsize\ding{108}}}}
\newcommand{\UP}{\textcolor[HTML]{9061c8}{\textbf{\scriptsize\ding{108}}}}
\newcommand{\UB}{\textcolor[HTML]{ff02e1}{\textbf{\scriptsize\ding{108}}}}

\newcommand{\MultiClass}{\textcolor[HTML]{CF1651}{\textbf{\scriptsize\ding{73}}}}
%\newcommand{\Classification}{\textcolor[HTML]{2ECC71}{\textbf{\scriptsize\ding{73}}}}

%========================DTI-DDI=================================


\newcommand{\Regression}{\textcolor[HTML]{9B59B6}{\textbf{\scriptsize\ding{72}}}}
\newcommand{\Classification}{\textcolor[HTML]{2ECC71}{\textbf{\scriptsize\ding{73}}}}
\newcommand{\Recommendation}{\textcolor[HTML]{E67E22}{\textbf{\scriptsize\ding{74}}}}


% \newcommand{\cls6}{\textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{115}$^\textbf{6}$}}}
% \newcommand{\cls7}{\textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{115}$^\textbf{7}$}}}
% \newcommand{\cls8}{\textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{115}$^\textbf{8}$}}}
% \newcommand{\cls9}{\textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{115}$^\textbf{9}$}}}
 


% PDF Info Is REQUIRED.

% Please leave this \pdfinfo block untouched both for the submission and
% Camera Ready Copy. Do not include Title and Author information in the pdfinfo section
\pdfinfo{
/TemplateVersion (IJCAI.2025.0)
}

% \title{Deep Learning for Small Molecule Drug Discovery:\\ Progress, Challenges, and Opportunities}


\title{Small Molecule Drug Discovery Through Deep Learning:\\ Progress, Challenges, and Opportunities}
 

% Single author syntax
% \author{
%     Author Name
%     \affiliations
%     Affiliation
%     \emails
%     email@example.com
% }

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)

\author{
Kun Li\thanks{These authors contributed to the work equally and should be regarded as co-first authors}\and
Yida Xiong$^{*}$ \and
Hongzhi Zhang$^{*}$ \and
Xiantao Cai \and
Bo Du \And
Wenbin Hu\thanks{Corresponding author}\\
\affiliations
School of Computer Science, Wuhan University, Wuhan, China\\
\emails
\{likun98, yidaxiong, zhanghongzhi, caixiantao, dubo, hwb\}@whu.edu.cn
}



\begin{document}

\maketitle

\begin{abstract}
% 小分子药物在治疗各种疾病中发挥着至关重要的作用，因此其设计与筛选是药物发现中的核心研究内容。随着深度学习（DL）技术的快速发展，基于人工智能的小分子药物发现取得了显著进展，并提出了多种创新方法。然而，关于深度学习辅助小分子药物发现的系统性总结仍然较为匮乏。为了推动该领域的进一步发展，本文旨在填补这一空白，提供深度学习在小分子药物发现中的广泛应用回顾。


% 小分子药物在治疗各种疾病中发挥着至关重要的作用，其筛选，设计，优化等环节是药物发现中的核心研究内容。随着深度学习（DL）技术的快速发展，针对这些环节的小分子药物发现取得了显著进展。已有的计算机辅助药物发现的综述涉及的相关方法已然无法满足现有研究的需求。为了推动该领域的进一步发展，本文旨在对基于深度学习的小分子药物发现相关重要任务和代表性技术系统性总结和归纳。具体来说，本文内容包括：1）首先，我们概述了小分子药物发现的主要任务需求，并总结了每个任务面临的核心挑战；2）然后，我们回顾了深度学习在药物-靶点相互作用预测、药物-细胞反应预测、药物间相互作用预测、分子性质预测以及分子生成与优化等任务中的应用，涵盖了相关模型、开源代码、数据集和评价指标；3）最后，我们分析了这些任务所面临的共同挑战，并分享了对未来深度学习辅助小分子药物发现研究方向的见解。

% Small molecule drugs are crucial in treating various diseases, making their design and screening central to drug discovery. With the rapid development of deep learning (DL) technologies, DL-based small molecule drug discovery has made significant progress, proposing various innovative methods. However, to the best of our knowledge, little effort has been made to systematically summarize these works. 

% Small molecule drugs play a crucial role in the treatment of various diseases, and the screening, design and optimization are the core stages in drug discovery. With the rapid development of deep learning (DL) technologies, small molecule drug discovery for these aspects has made significant progress, and a large number of new DL-based methods, techniques and datasets have introduced. As a result, early surveys on this subject have struggled to meet the needs of current research. 

% Among commonly used drugs, small molecules account for 98\% of the total. The discovery process involves key stages such as lead compound screening, optimization, biochemical property prediction, and so on.

Due to their excellent drug-like and pharmacokinetic properties, small molecule drugs are widely used to treat various diseases, making them a critical component of drug discovery.  In recent years, with the rapid development of deep learning (DL) techniques, DL-based small molecule drug discovery methods have achieved excellent performance in prediction accuracy, speed, and complex molecular relationship modeling compared to traditional machine learning approaches. These advancements enhance drug screening efficiency and optimization, and they provide more precise and effective solutions for various drug discovery tasks. Contributing to this field's development, this paper aims to systematically summarize and generalize the recent key tasks and representative techniques in DL-based small molecule drug discovery in recent years. Specifically, we provide an overview of the major tasks in small molecule drug discovery and their interrelationships. Next, we analyze the six core tasks, summarizing the related methods, commonly used datasets, and technological development trends. Finally, we discuss key challenges, such as interpretability and out-of-distribution generalization, and offer our insights into future research directions for DL-assisted small molecule drug discovery.

% Specifically, 1) we first outline the major tasks and their interrelationships in small molecule drug discovery; 2) we then review DL-based applications across six major tasks, including drug-target interaction \& affinity prediction, drug-cell response prediction, drug-drug interaction prediction, molecular property prediction, and molecular generation and optimization, including related methods, common datasets, and technological development trends; 3) finally, we analyze the critical challenges and share our insights on future potential research directions for DL-assisted small molecule drug discovery.

\end{abstract}

\section{Introduction}

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{main.pdf}
    \caption{Molecular representation methods and their drug discovery applications.}
    \label{fig:1}
\end{figure*}

% Small molecule drugs play a critical role in the treatment of various diseases, including cancer, metabolic disorders, and infectious diseases. The design and screening of small molecules are pivotal steps in the drug discovery process. However, the traditional drug discovery pipeline is often resource-intensive and time-consuming, with long development cycles and high costs. The rapid evolution of deep learning (DL) technologies has introduced new possibilities in this field, providing powerful tools to automate feature learning and prediction tasks, which significantly enhance the efficiency and accuracy of drug discovery. As a result, deep learning-based methods have gained widespread attention and have been increasingly integrated into small molecule drug discovery, promising to revolutionize this process.

% Despite the progress made in this promising area, there is a lack of systematic reviews that comprehensively summarize the applications of deep learning in small molecule drug discovery. Existing approaches, such as artificial intelligence-driven drug discovery (AIDD), structure-based drug discovery (SBDD), and ligand-based drug discovery (LBDD), have laid the foundation for drug development. However, these methods have limitations in addressing the complexity of biological systems and the vast scale of chemical space. Traditional models often struggle to capture the intricate relationships between molecular structures and biological targets, especially when dealing with high-dimensional data or when performing multi-task learning. In contrast, deep learning models, particularly those that leverage graph-based representations of molecules, can more effectively capture the underlying patterns and complex interactions that govern molecular behavior.

% This paper aims to bridge this gap by providing a broad review of the state-of-the-art deep learning techniques used in small molecule drug discovery. We focus on the key tasks within the field, including drug-target interaction prediction, drug-cell response prediction, drug-drug interaction prediction, molecular property prediction, and molecular generation and optimization. By examining recent developments in these areas, we highlight the various deep learning models and their applications, offering insights into the associated datasets, evaluation metrics, and open-source tools available to researchers. Furthermore, we discuss the challenges that still persist in the field, such as model interpretability, data quality, and the integration of multi-modal information, and offer perspectives on the future directions of deep learning in drug discovery.

% As the potential for deep learning to transform drug discovery continues to grow, it is crucial to understand its impact on current methods and identify avenues for further research. This review not only provides a comprehensive overview of the progress made but also aims to guide future research efforts by identifying critical challenges and opportunities for advancing deep learning-based approaches in small molecule drug discovery. Through this, we hope to contribute to the broader goal of accelerating the development of safe and effective therapeutic agents.


Small molecule drugs are chemically synthesized organic compounds with a molecular weight of less than 1,000. Due to their favorable drug-like and pharmacokinetic properties, these drugs play a critical role in the treatment of various diseases, accounting for about 98\% of the total number of commonly used drugs, and are the foundation of modern drug discovery. Small molecule drug discovery encompasses lead compound screening, optimization, biochemical property prediction, and so on. 

% However, due to the complexity of molecular structures and the intricate interactions between drugs and biological targets, traditional drug discovery methods face numerous challenges in the research and development process, such as limited prediction accuracy and low efficiency.



% Figure \ref{fig:1} illustrates how different
\begin{table*}[ht!]
    \centering
    \setlength\tabcolsep{8pt} % 列间距
    \begin{threeparttable}
    
    %\fontsize{9}{13}\selectfont % 设置适当字体大小
    \resizebox{0.98\linewidth}{!}{ % 设置适当字体大小
    \begin{tabular}{ccccccrr} % 确保列数与内容匹配
    \toprule
    \textbf{Methods} &  \# \textbf{Drug}  &  \# \textbf{DrugEn.}&  \# \textbf{Target} &  \# \textbf{TargetEn.} & \# \textbf{FusionM.} & \# \textbf{Data.\&Tasks} & \# \textbf{OOD} \\ \midrule
    DrugCLIP$^{[1]}$  &3D  & Uni-mol$^{[7]}$  & 3D Pocket & Uni-mol  & -  & \cosmic \LIT: \Classification  &  \UP \SB \\
    % APLM $^{[2]}$ &MFP & MLP  & Seq.   & PLM  & Concat  & \gdsc \pdtc \scRNA: \Classification  &  \UD \UP \SB \\
    DTI-MGNN$^{[2]}$ &SMILES & KGE  & Seq.   & KGE  & Attention  & \tcga: \Classification  & \SB \\
    % HyperAttentionDTI$^{[4]}$ &SMILES & CNNs  & Seq.   & CNNs  & Attention  &  \gdsc \ccle \tcga: \Classification  & \SB \\
    DrugBAN$^{[3]}$ &Graph & GNNs  & Seq.   & CNNs  & BAN  & \ctrp \pdtc: \Classification  &  \UB \SB \\
    PSC-CPI$^{[4]}$  &Graph & GNNs  &  Seq., Graph & HRNN, GAT  & MP & \gdsc \pdtc \Metz \Karimi: \Regression  & \UB \UD \UP \SB \\
    % Cross-interaction$^{[7]}$ &Graph & GNNs  & Seq.,Graph   & HRNN, GAT  & Concat  & \pdtc \PDBbind: \Classification  & \UB \UD \UP \SB   \\
    MGNDTI$^{[5]}$ &SMILES, Graph & GCNs, RN  &  Seq.& RN  & GN & \pubchem \ctrp \pdtc : \Classification  & \UB \UD \UP \SB \\
    Perceiver-CPI$^{[6]}$ &SMILES, MFP & GNNs, MLP  & Seq.   & CNN  & Attention  & \gdsc \ccle \PDBbind \Metz: \Regression  & \UB \UD \UP \SB \\
    
    
    
    \bottomrule
    \end{tabular}
    }
    \end{threeparttable} %添加此处
    
    \begin{minipage}{0.98\linewidth}
    \scriptsize
     
     $^{[1]}$\cite{gao2024drugclip}; $^{[2]}$\cite{li2022drug}; $^{[3]}$\cite{bai2023interpretable}; $^{[4]}$\cite{wu2024psc}; $^{[5]}$\cite{peng2024mgndti}; 
     $^{[6]}$\cite{nguyen2023perceiver}; 
     $^{[7]}$\cite{Uni-Mol}. %添加此处
     
     \textbf{Notations}: 
     
     \textcircled{\raisebox{-0.9pt}{1}} Techiques: Retentive Networks (\textbf{RN}),  Hierarchical Recurrent Neural Networks (\textbf{HRNN}), Manhattan Product (\textbf{MP}), Bilinear Attention Network (\textbf{BAN}),  Gating Network (\textbf{GN}), Transformer (\textbf{Trans.}).
    
    \textcircled{\raisebox{-0.9pt}{2}} Datasets: \gdsc~Davis, \ccle~KIBA,  \tcga~DrugBank, \cosmic~DUDE , \pubchem~C.elegans, \ctrp~Human, \pdtc~BindingDB, \Metz~Metz, \LIT~LIT-PCBA, \Karimi~Karimi.
    
    \textcircled{\raisebox{-0.9pt}{3}} Tasks: \Classification~classification task, \Regression~regression task.
    
    \textcircled{\raisebox{-0.9pt}{4}} Out-of-distribution: \SB~\textbf{Seen-Both}, \UD~\textbf{Unseen-Drug}, \UP~\textbf{Unseen-Target}, \UB~\textbf{Unseen-Both}.
    
    
    \end{minipage} 
    \caption{Summary of representative DTI/DTA tasks methods.}
    \label{tab:DTI}


\end{table*}


It also comprises several key stages, as shown in Figure \ref{fig:1}, including drug–target interaction and affinity (DTI/DTA), drug–cell response (DRP), drug–drug interaction (DDI), molecular property prediction (MPP). They also include molecular generation  (MG) and optimization (MO). These tasks primarily focus on three objects: small molecule drugs, cell lines with omics data, and target proteins. However, the representation methods for these objects are specific and vary considerably, necessitating customized approaches. Specifically, the DTI/DTA (target-based drug discovery) and DRP (phenotypic-based drug discovery) tasks are regarded as the two primary lead compound discovery approaches. Accordingly, the MPP and DDI tasks are primarily used to evaluate the physicochemical and pharmacokinetic properties, and potential adverse drug–drug interactions of small molecules. Subsequently, the MG and MO tasks are primarily aimed at expanding the drug candidate pool. In contrast, condition-based generation and optimization, leverage the predictive capabilities of the four tasks—DTI/DTA, DRP, MPP, and DDI—to design molecules with specific properties. These six tasks are closely interconnected and form the core of small molecule drug discovery. 

In recent years, the rapid development of DL technology has considerably improved small molecule drug discovery as computational power increases and data accumulates. DL-based methods have significantly surpassed traditional machine learning techniques in improving prediction accuracy, accelerating computation, enhancing molecular generation and optimization, and modeling complex molecular relationships. For example, deep (DNNs), convolutional (CNNs), and graph neural networks (GNNs) have been widely applied in automated feature extraction and multi-task learning, enabling the identification of potential patterns and improving prediction accuracy in large-scale biomedical data. These advances have improved drug screening efficiency and provided more accurate and effective solutions for various drug discovery tasks. Therefore, the rapid development of DL technology combined with increasingly rich small molecule datasets advances the drug discovery process.


% This paper focuses on analyzing the latest advancements and challenges of these tasks, and exploring the applications and potential of deep learning in this field.

% In recent years, the rapid development of deep learning (DL) techniques has brought significant improvements in small molecule drug discovery. DL-based methods have greatly surpassed traditional machine learning approaches in terms of improving prediction accuracy, accelerating computation speed, and modeling complex molecular relationships. These advancements have not only enhanced the efficiency of drug screening and optimization but also provided more precise and effective solutions for various tasks in the drug discovery process. The rapid development of deep learning, combined with increasingly rich molecular datasets, has opened up new opportunities for advancing the drug discovery process.

% This paper aims to systematically summarize the key tasks and challenges in DL-based small molecule drug discovery, exploring the latest advancements and techniques in the field. We will also analyze the current limitations and outline future research directions, with a focus on how deep learning can further drive the efficiency and accuracy of drug discovery.

% Deep learning (DL) has made significant strides in the field of drug discovery, providing powerful tools to enhance the efficiency and accuracy of the drug development process, particularly in areas such as molecular design, target prediction, and drug optimization. DL-based models, especially deep neural networks (DNNs), convolutional neural networks (CNNs), and graph neural networks (GNNs), have been widely applied in automated feature extraction and multi-task learning, enabling the identification of potential patterns and making accurate predictions from large-scale biomedical data. For instance, DL-based models can analyze chemical molecular structures to accurately predict pharmacological activity, toxicity, and pharmacokinetic properties, thus accelerating the screening and optimization of drug candidates. 



% Specifically, DL has been successfully applied in several stages of drug discovery, including drug–target interaction \& affinity prediction (DTI/DTA), drug-cell response prediction (DRP), drug-drug interaction prediction (DDI), molecular property prediction (MPP), molecular generation (MG) and molecular optimization (MO). These tasks primarily focus on small molecule drugs, cell lines with omics data, and target proteins.  



% The molecular representations, including graph-based, sequence-based, and fingerprint-based approaches. These methods enable efficient exploration of chemical space, aiding in the identification and optimization of potential drug candidates.

% , are employed across six key drug discovery tasks: (1) Drug Screening, (2) Target Binding Prediction, (3) Toxicity Prediction, (4) ADMET Prediction, (5) Drug Optimization, and (6) Drug Repositioning.



% In the DTI/DTA task, DL has significantly improved the accuracy of target identification and drug screening by learning the complex relationships between target proteins and small molecule compounds (Section \ref{3.1}). Through the representation methods of molecules and targets (e.g., DNNs, GNNs), researchers can predict the binding affinity between small molecules and targets, effectively screening potential drug candidates. The DRP task involves handling complex genomic and phenotypic data to support preclinical screening of drugs such as cancer therapies and antibiotics (see Section \ref{3.2}). This task requires leveraging different modal data from cell line omics, using techniques like CNNs and Transformers to capture complex cellular response patterns, thereby helping to predict the efficacy of candidate drugs. In the DDI task, DL-based models aid in identifying potential adverse drug reactions and drug interactions, thus reducing the risks in clinical trials (Section \ref{3.3}). Particularly in the context of polypharmacy, DL can analyze the cumulative effects of drug combinations on biological systems, identifying potentially harmful interactions. In the MPP task, molecular property information primarily refers to the physical, (quantum) chemical, and biological properties of molecules. By learning from a subset of molecular data, deep learning models can predict the properties of unknown molecular structures. This task provides essential information for molecular generation and optimization (see Section \ref{3.4}).  Lastly, in the MG and MO tasks, generative deep learning methods such as generative adversarial networks (GANs), variational autoencoders (VAEs), and Diffusion models are employed to design new molecular structures, expanding the chemical space of potential drugs (Section \ref{3.5} and Section \ref{3.6}). These models not only generate molecules with desired biological activity but also optimize existing structures to enhance drug properties, such as improving stability or reducing side effects.


% Models like graph convolutional networks (GCNs) and transformers capture complex relationships between molecular structures and their properties, leading to more accurate predictions.

% 近年来，尽管已有研究对药物发现相关技术和任务进行了总结，但随着深度学习（DL）技术的飞速发展，小分子药物发现领域在预测精度、计算效率等方面的瓶颈已得到显著缓解，并涌现出大量新方法、新技术和新标准。因此，早期的综述已难以全面反映当前研究进展。为弥补这一不足，本文系统梳理了近年来基于 DL 的小分子药物发现的关键任务与代表性技术，并深入探讨该领域面临的新挑战与机遇。

Several studies have introduced new methods and datasets to the small molecule drug discovery field. Consequently, early surveys on this subject have struggled to meet the needs of current research. To fill this gap, this paper systematically summarizes the key tasks and representative techniques in DL-based small molecule drug discovery over the past three years. According to the stages and requirements of small molecule drug discovery, we provide a detailed overview of various methods for six major tasks—DTI/DTA, DRP, DDI, MPP, MG, and MO—along with relevant datasets and specific technological trends to each task in Section \ref{sec:3}. Given the dataset complexity and diversity in drug discovery, this paper also summarizes the main small molecule datasets with access URLs (see Section \ref{sec:4} for details). Furthermore, we analyze the challenges associated with these tasks and provide insights into potential future research directions in Section \ref{sec:5}. To the best of our knowledge, this paper is the first attempt to present a systematic and comprehensive review of recent DL advancements in small molecule drug discovery.

% With the rapid development of deep learning (DL) technologies, small molecule drug discovery for these aspects has made significant progress, and a large number of new DL-based methods, techniques and datasets have introduced. As a result, early surveys on this subject have struggled to meet the needs of current research. To fill the gaps, this paper aims to systematically summarize the key tasks and representative techniques in DL-based small molecule drug discovery  over the past three years. According to the stages and requirements of small molecule drug discovery, we provide a detailed summary of various methods for six major tasks (i.e., DTI/DTA, DRP, DDI, MPP, MG, and MO), along with the datasets and the trends of technological development specific to each task in Section \ref{sec:3}. Due to the complexity and diversity of datasets in the field of drug discovery, this paper provides a summary of the main small molecule datasets with access URLs (see Section \ref{sec:4} for details). In addition, the challenges faced by these tasks are analyzed, and insights on future potential research directions are shared in Section \ref{sec:5}. To the best of our knowledge, this paper is the first attempt to present a systematic and comprehensive review of recent progress on deep learning for small molecule drug discovery. 

% We provide related practitioners with a comprehensive understanding of the drug discovery field and keep researchers informed about the latest advancements.

% 




\begin{table*}[htpb]
\centering
\renewcommand\arraystretch{1.0} % 行间距
\setlength\tabcolsep{7pt} % 列间距
\begin{threeparttable}
\resizebox{0.98\textwidth}{!}{
\begin{tabular}{ccccccr}
\toprule
    
    


\textbf{Methods} & \# \textbf{Cell profiles} & \# \textbf{Drug} & \# \textbf{Cell Line Arch.} & \# \textbf{Drug Arch.} & \# \textbf{Tech.} & \textbf{Datasets\&Tasks} \\

\midrule

SubCDR\tnote{[1]} & E, R & Subcomponent & CNNs & CNNs & Supervised Learning & \gdsc\cosmic\pubchem: \Classification\Regression \\
% DeepTTA\tnote{[2]} & E & Subcomponent & MLP & Trans. & Supervised Learning & \gdsc: \Classification \\
TGSA\tnote{[2]} & M, E, C, Net & Graph & GAT & GIN & Supervised Learning & \gdsc: \Regression \\ 
DIPK\tnote{[3]} & E, Net & Graph & GAE & GNNs, Trans. & Pre-training & \gdsc\ccle: \Regression \\
% GraphCDR\tnote{[5]} & M, E, C & Graph & DNNs & GNNs & Contrastive Learning & \gdsc\ccle: \Classification \\
CLDR\tnote{[4]} & No constr. & No constr. & Trans. & Trans. & Contrastive Learning & \gdsc: \Regression \\
MSDA\tnote{[5]} & No constr. & No constr. & No constr. & No constr. & Domain Generalization  & \gdsc\nci: \Regression \\
CODE-AE\tnote{[6]} & R & Not req. & AE & Not req. & Domain Generalization & \ccle\tcga\pdtc: \Classification \\
% scDEAL\tnote{[9]} & R, S & Not req. & AE & Not req. & Transfer Learning & \gdsc\ccle\scRNA: \Classification \\
% WISER\tnote{[10]} & R & Not req. & MLP & Not req. & Weak Supervision Learning & \tcga\depmap: \Classification \\
\bottomrule

\end{tabular}
}
\end{threeparttable}

\begin{minipage}{0.98\linewidth}
\scriptsize 
$^{[1]}$\cite{subcdr}; $^{[2]}$\cite{TGSA}; $^{[3]}$\cite{DIPK}; $^{[4]}$\cite{cldr}; $^{[5]}$\cite{MSDA}; $^{[6]}$\cite{code-ae}.

\textbf{Notations:}

\textcircled{\raisebox{-0.9pt}{1}} Datasets: \gdsc~GDSCv1/2, \ccle~CCLE, \tcga~TCGA,  \cosmic~COSMIC, \pubchem~PubChem.

\textcircled{\raisebox{-0.9pt}{2}} Profiles: mutation status (\textbf{M}), gene expression profiles (\textbf{E}), copy number variation (\textbf{C}), RNA sequence (\textbf{R}), gene interaction network/protein–protein association network from STRING dataset (\textbf{Net}), no need for special module or data (\textbf{Not req.}),  No restrictions on the type of module or data (\textbf{no constr.}).

\textcircled{\raisebox{-0.9pt}{3}} Techiques: Autoencoder (\textbf{AE}), Graph Autoencoder (\textbf{GAE}).
\end{minipage} 

\caption{Summary of representative DRP task methods.}
\label{DRP_table}
\end{table*}


     
\section{Problem Formulation}

% Let $M = (V,E)$ denote a molecule, which has the graph format $G = (X,A)$. For a 3D molecule, it can be represented as point clouds $(D, H)$, where $D$ is the atom coordinates matrix and $H$ is the node feature matrix.

A molecule $M$ with $N$ nodes can be represented by $\mathcal{G}=(\mathcal{X},\mathcal{A})$, where $\mathcal{X} \in \mathbb{R}^{N \times F}$ denotes node features and $\mathcal{A} \in \mathbb{R}^{N \times N}$ signifies the adjacency matrix ($F$ is the node feature dimension). Three-dimensional (3D) molecular structures are commonly represented as 3D graphs $\mathcal{G}_{3D}=(\mathcal{X},\mathcal{A},\mathcal{R})$ or point clouds $\mathcal{P}_{3D}=(\mathcal{X},\mathcal{R})$, where information on the node position in a coordinate system ($\mathbf{r}_{i} \in \mathcal{R}$) is encoded ($\mathcal{R}$ refers to the set of coordinates). 

In addition, the six main tasks in small molecule drug discovery can be abstractly represented as follows: 

The MPP task predicts the properties of a molecule $M$, such as solubility, polarity, and toxicity. This can be represented as:
\begin{equation}
    \text{Y}_{\text{MPP}} = f_{\text{model}}(M),
\end{equation}
\noindent where $f_{\text{model}}(\cdot)$ indicates the respective task's prediction model. The DRP, DTI/DTA, and DDI tasks can be collectively referred to as the \textbf{drug-X} format. Specifically, this format predicts whether two entities, $M$ and $X$ (where $X$ can be another drug $M$, a target $T$, or a cell line $C$) interact. It is can be formulated as:  
\begin{equation}
    Y_{\text{DX}} = f_{\text{model}}(M, X),
\end{equation}
Finally, the MG task generates new molecules $M_{\text{Gen}}$ with/without target property $C$, while the MO optimizes an existing molecule $M$, improving its properties $C$ while preserving its activity. Both tasks can be unified and represented as:
\begin{equation}
    M_{\text{Gen}/\text{Opt}} = \arg \min_{M} f_{\text{val}}(M, \emptyset / C).
\end{equation}
\noindent where $f_{\text{val}}(\cdot)$ is the molecular evaluation function, and $\emptyset$ represents unconditional generation.




\section{Methods}
\label{sec:3}

\subsection{Drug–Target Interaction and Affinity Prediction}
\label{3.1}

The DTI and DTA prediction tasks are extremely crucial for drug discovery. Typically, DTI prediction is formulated as a binary classification problem that determines a drug's interaction with a specific target, outputting a binary label. In contrast, DTA prediction is a regression problem that focuses on predicting the binding affinity between a drug and its target, often quantified by metrics such as the dissociation constant (Kd) value.
% The input for both tasks consists of drug data (e.g., simplified molecular input line entry specification (SMILES), molecular fingerprints, etc.) and target data (e.g., protein sequences, three-dimensional (3D) structure, etc.).

Moreover, DTI/DTA frameworks employ dual-encoder architectures for molecular and protein feature extraction, coupled with interaction or affinity predictors. Table \ref{tab:DTI} displays various DTI/DTA methods based on model structure differences. Early methods, such as CNNs, were inadequate in capturing the structural details of molecules. Meanwhile, GNNs have become the dominant paradigm for processing molecular data due to their ability to characterize the two-dimensional structure of molecules. Knowledge graph-based methods have improved performance by integrating multi-entity relationships (e.g., drugs, targets, and diseases). 

In recent years, out-of-distribution (OOD) data has emerged as a primary research focus. During the DTI/DTA task, test scenarios can be categorized into four types based on whether the drugs and targets in the test set are observed during training: \textbf{Seen-Both}: both the drugs and targets in the test set are present during training. \textbf{Unseen-Drug}: the drugs in the test set are not present in the training one. \textbf{Unseen-Target}: the targets in the test set are not present during training. \textbf{Unseen-Both}: both the drugs and targets in the test set are not present in the training one. All cases except Seen-Both represent OOD problems. For a detailed discussion of OOD issues, refer to Section \ref{5.2}. The predominant approaches to addressing this issue involve domain adaptation and pre-training techniques. Public databases, including Davis and KIBA offer an extensive array of binding data (for more datasets details, see Table \ref{Datasets}).




\subsection{Drug–Cell Response Prediction}
\label{3.2}



% 药物-细胞反应预测（Drug-cell response prediction, DRP）旨在预测特定细胞对药物的反应，这一研究对推动个性化医疗的发展具有重要意义。该任务的核心数据主要包括两类：细胞数据（如基因表达谱、突变信息等）和药物数据（如分子特性、药物靶点等）。目前，与DRP相关的主要数据集包括GDSCv1/2、CCLE等。这些数据集可分为两类：一类主要包含药物-细胞反应的量化数值；另一类则侧重于细胞的组学数据，如转录组学、突变组学及RNA序列等。

% 早期的研究方法，如tCNNs和MOLI，为DRP任务奠定了重要基础。然而，随着技术的快速发展，本文不再重点讨论这些传统方法，而是聚焦于2022年以来采用新技术的研究进展。近年来，DRP方法通过结合领域适应学习（domain adaptation）、多模态数据整合以及迁移学习等技术，取得了显著突破。表X详细总结了这些方法的特征与性能。从问题定义的角度来看，DRP可抽象为在不同条件下（即不同细胞系）预测药物分子单一属性的任务。基于这一视角，涌现出许多以领域适应为核心的新方法。此外，传统方法将药物和细胞系视为两个独立输入对象时，往往面临分布外泛化（out-of-distribution generalization）的挑战。近年来，DRP研究开始重点关注如何提升模型对未知细胞系或药物分子的预测精度。为此，基于对比学习（contrastive learning）和迁移学习（transfer learning）的新方法被提出并广泛应用。

% Drug-cell response prediction (DRP) aims to predict how cells respond to specific drugs, which is essential for personalized medicine. This task typically requires two types of data: cell data (e.g., gene expression or mutations) and drug data (e.g., molecular properties or drug targets). Early methods, such as tCNNs and MOLI, laid the baselines but are not the focus here. This review will summarize methods from 2022 onward, which have advanced through deep learning, multimodal data integration, and transfer learning. Table X provides a detailed overview of these methods, including their key features and performance.





\begin{table*}[ht!]
\centering
\renewcommand\arraystretch{1.1} % 行间距
\setlength\tabcolsep{12pt} % 列间距
\begin{threeparttable}
\resizebox{\textwidth}{!}{
\begin{tabular}{cccl|cccl}
\toprule
\textbf{Methods} & \# \textbf{Rep.} & \# \textbf{Arch.} & \textbf{Pre-train(Data.)} & \textbf{Methods} & \# \textbf{Rep.} & \# \textbf{Arch.} & \textbf{Pre-train(Data.)} \\ \midrule
GEM\tnote{[1]} & Graph, 3D & GNNs & SSL, \textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{115}$^\textbf{1-9}$}}\textcolor[HTML]{3069a5}{\textbf{\scriptsize\ding{115}$^\textbf{1-6}$}} & Uni-Mol\tnote{[2]} & 3D & Trans. & DN, \textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{115}$^\textbf{1-9}$}} \textcolor[HTML]{3069a5}{\textbf{\scriptsize\ding{115}$^\textbf{1-6}$}}  \\
% UniCorn\tnote{[3]} & Graph, 3D & GT & CL, \qm\md & MoLFormer\tnote{[4]} & SMILES & Trans. & SSL, \textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{115}$^\textbf{1-7}$}}\textcolor[HTML]{3069a5}{\textbf{\scriptsize\ding{115}$^\textbf{1-6}$}} \\
% Uni-Mol2\tnote{[5]} & Graph, 3D & Trans. & SSL, \qm\textcolor[HTML]{4e705a}{\textbf{\scriptsize\ding{115}}}  &   \\
GraphMVP\tnote{[3]} & Graph, 3D & GNNs & SSL, (\pcqm) \qm\md\textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{115}$^\textbf{1-8}$}} & GraphMAE\tnote{[4]} & Graph & GNNs & SSL, \textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{115}$^\textbf{1-6}$}} \\
Transformer-M\tnote{[5]} & Graph, 3D & Trans. & DN, (\pcqm) \qm & MolCLR\tnote{[6]} & Graph & GNNs & CL, \textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{115}$^\textbf{1-7}$}}\textcolor[HTML]{3069a5}{\textbf{\scriptsize\ding{115}$^\textbf{1-6}$}}\\ \bottomrule

\end{tabular}}
\end{threeparttable}

\begin{minipage}{\linewidth}
\scriptsize 
 $^{[1]}$\cite{GEM}; $^{[2]}$\cite{Uni-Mol}; $^{[3]}$\cite{GraphMVP}; $^{[4]}$\cite{GraphMAE}; $^{[5]}$\cite{Transformer-M}; $^{[6]}$\cite{MolCLR}.
 
 \textbf{Notations:}
 
 \textcircled{\raisebox{-0.9pt}{1}} Datasets:  \qm~QM9; \md~MD17/22; \pcqm~PCQM4Mv2; \textcolor[HTML]{3069a5}{\textbf{\scriptsize\ding{115}$^\textbf{6}$}}~Regression datasets, including FreeSolv, ESOL, Lipo, QM7, QM8, and QM9; \textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{115}$^\textbf{9}$}}~Classification datasets, including BBBP, Tox21, ClinTox, HIV, BACE, SIDER, MUV, ToxCast, and PCBA. 
 
 \textcircled{\raisebox{-0.9pt}{2}} Methods: Self-supervised Learning (\textbf{SSL}), Denoising Pre-training (\textbf{DN}).
 

\end{minipage} 

\caption{Summary of representative MPP task methods with pre-training.}
\label{MPP_W_PRE}
\end{table*}


% ; \textcolor[HTML]{4e705a}{\textbf{\scriptsize\ding{115}}}~COMPAS-1D

\begin{table*}[ht!]
\centering
\renewcommand\arraystretch{1.1} % 行间距
\setlength\tabcolsep{12pt} % 列间距
\begin{threeparttable}
\resizebox{\textwidth}{!}{
\begin{tabular}{cccl|cccl}
\toprule
\textbf{Methods} & \# \textbf{Rep.} & \# \textbf{Arch.} & \textbf{Dataset} & \textbf{Model Name} & \# \textbf{Rep.} & \# \textbf{Arch.} & \textbf{Dataset} \\ \midrule
SphereNet\tnote{[1]} & 3D graph & GNNs & \qm\md\oc  & Equiformer\tnote{[2]} & Graph & GNNs & \qm\md\oc  \\
ComENet\tnote{[3]} & 3D graph & GNNs & \qm\oc\mol & ViSNet\tnote{[4]} & Graph, 3D & Trans. & \qm\mol \\
TorchMD-NET\tnote{[5]} & 3D graph & GNNs & \qm\md\textcolor[HTML]{9f64c2}{\textbf{\scriptsize\ding{115}}} &  Allegro\tnote{[6]} & 1D Desc, 3D & MLP & \qm\md\textcolor[HTML]{d1743f}{\textbf{\scriptsize\ding{115}}}  \\
\bottomrule

\end{tabular}
}
\end{threeparttable}

\begin{minipage}{\linewidth} \scriptsize
$^{[1]}$\cite{SphereNet}; $^{[2]}$\cite{Equiformer}; $^{[3]}$\cite{ComENet}; $^{[4]}$\cite{ViSNet}; $^{[5]}$\cite{TorchMD-NET}; $^{[6]}$\cite{Allegro}.

%\footnotesize %
 \textbf{Notations:}
 \textcircled{\raisebox{-0.9pt}{1}} Datasets:  \oc~OC20, \mol~Molecule3D, \textcolor[HTML]{d1743f}{\textbf{\scriptsize\ding{115}}}~3BPA, \textcolor[HTML]{9f64c2}{\textbf{\scriptsize\ding{115}}}~ANI-1. 

% \textcircled{\raisebox{-0.9pt}{2}} Representations: 1D Desc means atoms info. seq,  SMILES, types; 2D Desc means xxx; 3D means xx; Atom means xxx; Motif and Frag means xxx; and xxx.   
 % \textcircled{\raisebox{-0.9pt}{3}} Methods: Graph Transformer (\textbf{GT}).
 
\end{minipage} 
\caption{Summary of representative MPP task methods without pre-training.}
\label{MPP_WO_PRE}
\end{table*}


% The DRP task aims to predict the response of a specific cell to a drug, and this research is of great significance in advancing the development of personalised medicine. The core inputs include two classes: the cell data (e.g., gene expression profiles, mutation information, etc.) and the drug data (e.g., molecular properties, drug targets, etc.). Currently, the main datasets related to DRP include GDSCv1/2, CCLE, and so on. These datasets can be divided into two categories: one mainly contains quantitative values of drug-cell responses; the other focuses on the genomic data of cells, such as transcriptomics, mutational genomics, and RNA sequences.

The DRP task predicts the response of specific cells to drugs, playing a crucial role in advancing personalized medicine. This task emphasizes the cellular context, making it particularly relevant for precision oncology and targeted therapies. It primarily determines a drug's efficacy against a given cell line, often represented by metrics such as IC50 values.
% The core inputs of the DRP task include cell lines (such as gene expression profiles, mutation information, etc.) and drugs. 

% Early research methods, such as tCNNs and MOLI, laid an important foundation for the DRP task. However, with the rapid technological development, this paper no longer focuses on these traditional methods, but rather on research advances using new technologies since 2022. 


Recently, DRP methods have made significant breakthroughs by combining techniques such as domain adaptation, multi-modal data integration, and transfer learning. Table \ref{DRP_table} provides a comprehensive summary of these methods' key features and properties. According to the problem definition, DRP can be abstracted as the single property prediction task of a drug molecule under various conditions (i.e., different cell lines). Accordingly, several methods focusing on OOD generalization have been proposed, particularly when treating drugs and cell lines as independent input objects. In the present time, DRP research has increasingly focused on improving model performance for unknown cell lines and drug molecules. This shift is crucial for practical applications in drug screening (i.e., predicting the efficacy of drug molecules not present in the training set) and precision medicine (i.e., predicting the effects of cell line genomics not included in the training set). Therefore, these independent inputs can be viewed as distinct domains. Therefore,  methods based on contrastive and transfer learning have been proposed and widely applied to enhance OOD generalization performance.

Currently, the main DRP datasets include GDSCv1/2 and CCLE (See Table \ref{Datasets} for details). These datasets can be divided into two categories: those primarily containing quantitative drug–cell response values and those focusing on genomic cell data, such as transcriptomics, mutational genomics, and ribonucleic acid (RNA) sequences. This distinction arises because cells in the DRP task can be described using various omics data. The first dataset category emphasizes statistical response values and only reports cell line types. Meanwhile, the second category mainly comprises the genomics data of specific cell lines. Similar to the DTI/DTA task discussed in Section \ref{3.1}, DRP also faces significant challenges related to OOD generalization, as models must accurately predict responses for unseen drug–cell combinations.

% In addition, traditional methods often face the challenge of OOD generalization when drug and cell line are considered as two independent input objects. Over recent years, the DRP research has come to focus on how to improve the prediction accuracy of models for unknown cell lines or drug molecules. To this end, new methods based on contrastive learning and transfer learning have been proposed and widely used.











\subsection{Drug–Drug Interaction Prediction}
\label{3.3}


\begin{table}[htpb]
    \centering
    \begin{threeparttable}
    \renewcommand\arraystretch{1.0} % 行间距
    \resizebox{\linewidth}{!}{ % 设置适当字体大小
    \begin{tabular}{cccr} % 确保列数与内容匹配
    \toprule

     \textbf{Model}& \# \textbf{Drug} & \# \textbf{Tech.}  & \# \textbf{Data.\&Tasks} \\ \midrule
    ZeroDDI$^{[1]}$   & SMILES  & SEL      &  \gdsc: \Recommendation \\
    MKG-FENN$^{[2]}$ & SMILES      & KG   & \gdsc: \MultiClass\\
    % TIGER$^{[3]}$  & Graph  & GNNs      & \gdsc \prism  \OGBbiokg: \MultiClass \\
    CGIB$^{[3]}$  & Graph       & GIB    & \ZhangDDI \pdtc: \MultiClass \Regression \\
    %IGIB-ISE$^{[5]}$  & Graph       & IGIB  & \ZhangDDI \pdtc: \MultiClass \Regression \\
    PHGL-DDI$^{[4]}$  & Graph       & CL  & \gdsc \pdtc: \MultiClass  \\
    DANN-DDI $^{[5]}$  & Graph       & Attention  & \gdsc \ccle: \MultiClass \\
    DDKG $^{[6]}$  & SMILES, Graph       & KG  & \ccle \OGBbiokg: \MultiClass \\
    
    \bottomrule
    
    \end{tabular}
    }
    \end{threeparttable} %添加此处
    
    \begin{minipage}{\linewidth}
    \scriptsize
     $^{[1]}$\cite{wang2024zeroddi}; $^{[2]}$\cite{wu2024mkg}; 
     % $^{[3]}$\cite{su2024dual};
     $^{[3]}$\cite{lee2023conditional}; $^{[4]}$\cite{yuan2025phgl}; $^{[5]}$\cite{liu2022enhancing}; $^{[6]}$\cite{DDKG}.
     
     
     \textbf{Notations}:
     
     \textcircled{\raisebox{-0.9pt}{1}} Techniques: Knowledge Graph (\textbf{KG}), Contrastive Learning (\textbf{CL}), Semantic Enhanced Learning (\textbf{SEL}), Graph Information Bottleneck (\textbf{GIB}), Central-Smoothing Hypergraph Neural Networks (\textbf{CSHNN}).
     
    \textcircled{\raisebox{-0.9pt}{2}} Datasets: \gdsc~DrugBank, \ccle~KEGG,  \cosmic~SIDER,   \pdtc~ChCh-Miner, \ZhangDDI~ZhangDDI.
    
    \textcircled{\raisebox{-0.9pt}{3}} Tasks: \MultiClass~multi-class classification task, \Recommendation~recommendation task.
    
    
    \end{minipage} 
    \caption{Summary of representative DDI task methods.}
    \label{tab:DDI}

\end{table}



The DDI prediction task is critical for identifying adverse pharmacological effects caused by combined drug use. This task mainly involves classifying interaction types between drug pairs, ranging from binary detection (i.e., presence/absence) to multi-class interaction mechanism categorization. 
% The input for the DDI prediction task consists of two drugs for which the potential interaction is to be predicted. 

Notably, GNNs have emerged as the dominant tools for DDI prediction tool due to their ability to model molecular structures and interactions using graph representations. Furthermore, knowledge graph methods improve performance by modeling the relationships between drugs, targets, and biological pathways. Recent advancements incorporate self-supervised techniques such as contrastive learning to address data scarcity in OOD scenarios. Grounded in information theory, graph information bottleneck (GIB)\cite{lee2023conditional} methods have demonstrated enhanced prediction accuracy by filtering irrelevant molecular features. Presently these methods highlight the shift toward robust feature learning and explainable models, positioning computational DDI prediction as a scalable complement to traditional approaches. Therefore, continuous progress in multi-modal data (e.g., 3D structures) integration and framework pre-training lead to broader in pharmacological safety assessment applications.  

Public databases can be categorized based on their content and functionality into drug omics, drug adverse effect, and knowledge graph databases. Drug omics databases are primarily composed of drug-related interaction data. Commonly used drug omics databases, such as DrugBank, KEGG, PubChem, and DrugCentral, play a crucial role in DDI prediction. The drug adverse effect datasets, such as TWOSIDES and SIDER are specifically utilized for predicting adverse effects. Finally, DRKG and Bio2RDF represent two comprehensive drug knowledge graph databases contribute significantly contribute to the drug discovery field (See Table \ref{Datasets} for details). The aforementioned datasets contribute to ensuring data feasibility for the DDI tasks. Similarly, DDI also encounters substantial obstacles pertaining to OOD generalization.



% ; \textbf{QM9Spectra (Qs)} (\textcolor[HTML]{3069a5}{\textbf{\scriptsize\ding{116}}}); \textbf{GEOM-QM9 (GQ)} (\textcolor[HTML]{9a2e61}{\textbf{\scriptsize\ding{116}}})

\subsection{Molecule Property Prediction}
\label{3.4}

% Molecular property prediction (MPP) is the task of predicting various physical, chemical, and biological properties of molecules based on their structure or composition. These properties include molecular weight, solubility, toxicity, and other characteristics that are important for drug design, materials science, and other applications. The representation of a molecule plays a critical role in determining the accuracy and effectiveness of the predictions, as a molecule's structure and the way it is encoded influence the model's ability to learn and make reliable predictions.

% In recent years, advancements in machine learning and deep learning techniques have greatly enhanced the ability to predict molecular properties. Different molecular representations, such as SMILES, graph-based representations, and molecular fingerprints, are used to encode the molecular structure, and the choice of representation directly impacts the performance of the prediction models. Table X provides a detailed overview of various methods and their corresponding performance in predicting different molecular properties. This table highlights the key techniques and the impact of different molecular representations on prediction accuracy.



% 分子性质预测（Molecular Property Prediction, MPP）是基于分子结构或组成预测其各种物理、化学和生物性质的任务，对于药物设计、材料科学及其他应用领域具有重要意义。分子性质包括溶解度、毒性、量子化学属性等，通常每种属性由不同的数据集提供。这些性质的准确预测能够加速新药研发、优化材料性能，并推动化学和生物领域的科学研究。

% 近年来，机器学习和深度学习技术的进步极大地提升了对分子性质的预测能力。不同的分子表示方法，如SMILES（简化分子线性输入系统）、基于图的表示（如分子图）和分子指纹等，被用于编码分子结构，而表示方式的选择直接影响了预测模型的性能。表X和表XX详细概述了有/无预训练下各种方法及其在预测不同分子性质的技术路线。由于不同的方法在数据集划分、评价指标、随机种子和实现细节上各有不同，我们选择了具有代表性的方法，只对分子表征方式和特征编码技术进行详细介绍，而不比较方法性能优劣。

% 近年来的方法更加偏重于预训练技术（如自监督学习、多模态对比学习、基于3D的去噪任务等），利用大型数据集对分子特征空间进行建模和优化，再基于特定数据集进行微调。这种预训练技术能够从海量未标注数据中学习到通用的分子特征表示，从而在小规模标注数据上表现出较强的泛化性能。


\begin{table*}[htpb]
  \centering
  \small  % 让表格的字体小一点
  \renewcommand \arraystretch{0.8}
  % \begin{threeparttable} %添加此处
  \begin{tabular}{p{2.3cm}<{\centering}|p{1.2cm}<{\centering}|p{11cm}<{\centering}|p{1.2cm}<{\centering}}
    \toprule
    Models & Category & Backbone & Condition
    \\ \midrule
    $\mathrm{TransORGAN}^{[1]}$ & GAN &
     $\begin{cases}
         M^{\prime} = \mathbf{G}_{\theta}(\hat{M}) \\
         \min\limits_{\theta} \max\limits_{\phi} \tilde{V}(\mathbf{G}_{\theta}, \mathbf{D}_{\phi}) = \mathbb{E}_{x\sim p_{\text{data}}(x)}[\log \mathbf{D}_{\phi}(x)] + \mathbb{E}_{z\sim p_{z}(z)}[\log(1-\mathbf{D}_{\phi}(\mathbf{G}_{\theta}(z)))]
     \end{cases}$
     & Property \\ \midrule
     % $\mathrm{GraphDG}^{[1]}$ & VAE &
     % $\begin{cases}
     %     p(\mathbf{d} | \mathbf{z}, \mathcal{G}) \\
     %     M^{\prime} = \mathrm{EDG}(\mathbf{d})
     % \end{cases}$
     % & - \\ \midrule
     $\mathrm{3DLinker}^{[2]}$ & VAE &
     $ p(\mathcal{G}^{\prime}, \mathcal{M}^{\prime} | \mathcal{G}_{\text{frag}}, \mathcal{M}_{\text{frag}}) $
     & - \\ \midrule
     % $\mathrm{GF\mbox{-}VAE}^{[3]}$ & Flow &
     % $ p(X^{\prime} | \mathbf{z}_{X}, A) p(A^{\prime} | \mathbf{z}_{A}) = p(\mathbf{z}_{X}) \big( \big| \mathrm{det}\big(\frac{\partial f^{atom}_{\omega}(X^{\prime}, A)}{\partial X^{\prime}} \big) \big| \big) 
     % p(\mathbf{z}_{A}) \big( \big| \mathrm{det}\big(\frac{\partial f^{bond}_{\theta}(A^{\prime})}{\partial A^{\prime}} \big) \big| \big) $
     % & Property \\ \midrule
     $\mathrm{MolHF}^{[3]}$ & Flow &
     $ \mathcal{G}^{\prime} = (\mathcal{X}^{\prime}, \mathcal{A}^{\prime}) = f^{-1}_{\mathcal{X}|\mathcal{A}}(\mathbf{z}_{\mathcal{X}}, f^{-1}_{\mathcal{A}}(\mathbf{z}_{\mathcal{A}})) $
     & Property \\ \midrule
     % $\mathrm{CGCF}^{[5]}$ & Flow & 
     % $ p_{\theta}(\mathbf{R} | \mathcal{G}) = \int p(\mathbf{R} | \mathbf{d}, \mathcal{G}) \cdot p_{\theta}(\mathbf{d} | \mathcal{G}) \, d\mathbf{d} $
     % & - \\ \midrule
     % $\mathrm{LatentGAN}^{[6]}$ & GAN &
     % $ p(M^{\prime} | \mathbf{z}_{M}, \mathbf{z}_{fake}) $
     % & - \\ \midrule
     $\mathrm{GDSS}^{[4]}$ & Diffusion &
     $\begin{cases}
         d\mathcal{X}_{t} = \mathrm{f}_{1, t}(\mathcal{X}_{t})dt + g_{1, t}d\mathrm{w}_{1} - g_{1, t}^{2}\mathrm{s}_{\theta, t}(\mathcal{X}_{t}, \mathcal{A}_{t})dt \\
         d\mathcal{A}_{t} = \mathrm{f}_{2, t}(\mathcal{A}_{t})dt + g_{2, t}d\mathrm{w}_{2} - g_{2, t}^{2}\mathrm{s}_{\theta, t}(\mathcal{X}_{t}, \mathcal{A}_{t})dt
     \end{cases}$
     & - \\ \midrule
     % $\mathrm{GeoLDM}^{[5]}$ & Diffusion &
     % $\begin{cases}
     %     p_{\theta}(\mathbf{z}_{\mathcal{X}, t-1}, \mathbf{z}_{\mathcal{R}, t-1} | \mathbf{z}_{\mathcal{X}, t}, \mathbf{z}_{\mathcal{R}, t}) = p_{\theta}(\text{C}\mathbf{z}_{\mathcal{X}, t-1}, \mathbf{z}_{\mathcal{R}, t-1} | \text{C}\mathbf{z}_{\mathcal{X}, t}, \mathbf{z}_{\mathcal{R}, t})), \forall \, \text{C} \\
     %     \text{C}\mathbf{z}_{\mathcal{X}, t-1} + t, \mathbf{z}_{\mathcal{R}, t-1} = \epsilon_{\theta}(\text{C}\mathbf{z}_{\mathcal{X}, t} + t, \mathbf{z}_{\mathcal{R}, t}, t), \forall \, \text{C}, \, t
     % \end{cases}$
     % & - \\ \midrule     
     $\mathrm{MOOD}^{[5]}$ & Diffusion &
     $ d \mathcal{G}_{t} = [\mathrm{f}_{t}(\mathcal{G}_{t}) - g_{t}^{2} \nabla_{\mathcal{G}_{t}} \log p_{t}(\mathcal{G}_{t} | \mathbf{y}_{o} = \lambda_{o})] dt + g_{t} dw $
     & Property \\ \midrule
     $\mathrm{DecompDiff}^{[6]}$ & Diffusion &
     $\begin{cases}
         p_{\theta}(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \mathbf{x}_{0}, \mathcal{P}) = \prod_{i=1}^{\mathcal{X}} \sum_{k=1}^{\mathcal{K}} \eta_{ik} \mathcal{N} \left( \mathbf{\tilde{x}}_{t-1,k}^{(i)}; \tilde{\mu}_t \left( \mathbf{\tilde{x}}_{t,k}^{(i)}, \mathbf{\tilde{x}}_{0,k}^{(i)} \right), \tilde{\beta}_{t} \Sigma_k \right) \\
         \tilde{\mu}_t \left( \mathbf{\tilde{x}}_{t,k}^{(i)}, \mathbf{\tilde{x}}_{0,k}^{(i)} \right) = \frac{\sqrt{\alpha_{t}}(1 - \overline{\alpha}_{t-1})}{1 - \overline{\alpha}_{t}} \mathbf{\tilde{x}}_{t,k}^{(i)} + \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_{t}}{1 - \overline{\alpha}_{t}} \mathbf{\tilde{x}}_{0,k}^{(i)}
     \end{cases}$
     & Protein \\ 
     % $\mathrm{Graph\,DiT}^{[8]}$ & Diffusion &
     % $ \hat{p}_{\theta}(\mathcal{G}_{t-1} | \mathcal{G}, \mathcal{C}) = \log p_{\theta}(\mathcal{G}_{t-1} | \mathcal{G}_{t}) + s(\log p_{\theta}(\mathcal{G}_{t-1} | \mathcal{G}_{t}, \mathcal{C}) - \log p_{\theta}(\mathcal{G}_{t-1} | \mathcal{G}_{t})) $
     % & Property 
     % \\ \bottomrule
     % EBD & Diffusion &
     % $p_{\theta}(\mathbf{x}_{t-1} | \mathbf{x}_{t}, \hat{\mathbf{x}}^\mathrm{f}, \mathcal{G}) = \mathcal{N} \left( x_{t-1}^a \Big| \mu_{\theta}(\mathbf{x}_{t}, \hat{\mathbf{x}}^\mathrm{f}, \mathcal{G}, t), \delta^2 \mathbf{I} \right)$
     % \\
     \bottomrule     
  \end{tabular}
  % \begin{tablenotes} %添加此处
  \begin{minipage}{\linewidth}
    \scriptsize 
    % \item $^{[1]}$ \cite{simm2020generative}; 
    $^{[1]}$\cite{ijcai2022p539}; 
    $^{[2]}$\cite{huang20223dlinker}; 
    % $^{[3]}$ \cite{ma2021gf}; 
    $^{[3]}$\cite{zhu2023molhf}; 
    % $^{[5]}$ \cite{xu2021learning}; 
    % $^{[6]}$ \cite{prykhodko2019novo}; 
    $^{[4]}$\cite{jo2022score}; 
    % $^{[5]}$\cite{xxx}; 
    $^{[5]}$\cite{lee2023exploring}; 
    $^{[6]}$\cite{guan2023decompdiff}; 
    % $^{[8]}$\cite{xxx}.
    
    \textbf{Notations}: 
    % A molecular graph of a molecule $M$ is defined as $G = (V, E)$, where $V$ is the set of atoms (vertices) and $E$ the set of bonds (edges). Correspondingly, the graph of a molecule can be represented by its atom matrix $X$ and adjacency matrix $A$. 
    % $\mathbf{z}$ is the latent representation.
    % $\mathbf{z}_{\mathcal{T}}, \mathbf{z}_{G}$ denote two-part latent representations of junction tree and graph structure. % JTVAE
    % $\mathbf{d}$ denotes a set of pairwise distances between atoms. $\mathrm{EDG}$ is an algorithm converts $\mathbf{d}$ to a confirmation. % GraphDG
    $ \mathbf{G}(\cdot) $ and $ \mathbf{D}(\cdot) $ are the generator and the discriminator, $\hat{M}$ denotes the variant SMILES and $\tilde{V}$ is the value function. % TransORGAN
    $\mathcal{G}_{\text{frag}}$ and $\mathcal{M}_{\text{frag}}$ are the graph and geometry per fragment. % 3DLinker
    % $f^{atom}_{\omega}$ and $f^{bond}_{\theta}$ are coupling layers which process atoms and bonds respectively. % GF-VAE
    % $\mathbf{R}$ denotes the distribution of atomic positions. $p_{\theta}(\mathbf{d} | \mathcal{G})$ models the distribution of inter-atomic distances given the graph $\mathcal{G}$ and $p(\mathbf{R} | \mathbf{d}, \mathcal{G})$ models the distribution of conformations given the distances $\mathbf{d}$. % CGCF
    % $\mathbf{z}_{fake}$ denotes the fake data generated by generator in GAN framework. % LatentGAN
    Meanwhile, $\mathrm{f}_{1, t}(\cdot)$ and $\mathrm{f}_{2, t}(\cdot)$ are linear drift coefficients, $g_{1, t}$ and $g_{2, t}$ are scalar diffusion coefficients, and $\mathrm{w}_{1}$, $\mathrm{w}_{2}$ are reverse-time standard Wiener processes. % GDSS
    % For a 3D molecule, it can be represented as point clouds $(\mathcal{X}, \mathcal{R})$, where $\mathcal{X}$ is the atom coordinates matrix and $\mathcal{R}$ is the node feature matrix. % GeoLDM
    $\mathbf{y}_{o}$ represents the OOD condition and $\lambda_{o}$ is the parameter controlling the OOD generative process. % MOOD
    Finally, $\mathcal{P}$ denotes the set of atoms of the binding site, $\mathcal{K}$ signifies the set of fragments per molecule, and $\Sigma_k \in \mathbb{R}^{3}$ is the prior covariance matrix. $\eta_{ik} = 1$ indicates that the $i$-th molecule atom corresponds to the $k$-th prior. $\alpha_{t}, \beta_{t}, \overline{\alpha}_{t}, \tilde{\beta}_{t}$ are noise parameters. % DecompDiff
    % $\mathcal{C}$ represents the generative conditions and $s$ denotes the scale of conditional guidance. % Graph DiT
    % $\mu_{\theta}$ is a parameterized mean function consisting of a deblurring network and $\delta$ is the small amount of standard deviation for noise. $\hat{\mathbf{x}}^\mathrm{f}$ denotes the 3D structure of fragment coordinates. % EBD
    
  % \end{tablenotes} %添加此处
  % \end{threeparttable} %添加此处
  \end{minipage}
  \caption{Summary of molecular generation methods.}
  \label{tab:MolGen}
\end{table*}


The MPP task predicts a molecule's physical, quantum chemical, and biological properties based on its structure or description. This is essential for applications such as drug design and materials science. Accurately predicting these properties can accelerate the development of new drugs, optimize material properties, and advance scientific research in chemistry and biology.

% Different molecular representations, such as SMILES, graph-based representations, and molecular fingerprints, are used to encode molecular structures, and the choice of representation directly affects the performance of prediction models. 

Various representations, such as SMILES, graph-based representations, and one-dimensional (1D) descriptions (e.g., molecular fingerprints and atom types), are used to encode molecular structures. The representation directly impacts prediction model performance. Tables \ref{MPP_W_PRE} and \ref{MPP_WO_PRE} provide a detailed overview of the various methods with or without pre-training and their technical routes in predicting different molecular properties. Since different methods vary in dataset partitioning, evaluation metrics, random seeds, and implementation details, we selected representative methods and provided detailed descriptions of molecular representation and feature encoding techniques without comparing performance. The recent methods emphasize pre-training techniques (e.g., self-supervised and multi-modal contrastive learning, and 3D-based denoising tasks), which use large datasets to model and optimize the molecular feature space, fine-tuning it according to specific datasets. This pre-training technique can learn generic molecular feature representations from large amounts of labeled (or unlabeled) 3D, textual, or image data, thereby demonstrating excellent generalization performance on small-scale labeled data. In addition, MPP also encounters OOD challenges, especially when dataset splits are based on molecular scaffolds or similarity features, leading to poor predictions for structurally distinct samples.


% In recent years, the advancement of machine learning and deep learning techniques has greatly improved the prediction of molecular properties.







\begin{table*}[htpb]
  \centering
  \small  % 让表格的字体小一点
  \renewcommand \arraystretch{0.8}
  % \begin{threeparttable} %添加此处
  \begin{tabular}{p{2.6cm}<{\centering}|p{1.25cm}<{\centering}|p{10cm}<{\centering}|p{1.8cm}<{\centering}}
    \toprule
    Models & Category & Backbone & Condition
    \\ \midrule
    $\mathrm{Prompt\mbox{-}MolOpt^{[1]}}$ & AutoReg &
     $p(M_{\text{tag}_{t+1}} | M_{\text{tag}_{1:t}}, \mathcal{C}) = \mathrm{Trans}(\text{Emb} + \sum \mathbf{z}_{\mathcal{C}})$
     & Property \\ \midrule
     % $\mathrm{JTVAE}^{[1]}$ & VAE & 
     % $ p(\mathcal{G}^{\prime} | \mathbf{z}_{\mathcal{T}}, \mathbf{z}_{\mathcal{G}}) $
     % & Property \\ \midrule
     $\mathrm{FFLOM^{[2]}}$ & Flow &
     $ \mathcal{G}^{\prime} = f_{\mathcal{G}}^{-1}(\mathbf{z}_{\mathcal{G}}) $
     & Protein \\ \midrule
     % $\mathrm{Mol\mbox{-}CycleGAN^{[3]}}$ & GAN &
     % $\begin{cases}
     %     M^{\prime} = \mathbf{G}_{1}(\mathbf{G}_{2}(M)) \\
     %     \mathbf{G}_{1}^{*}, \mathbf{G}_{2}^{*} = \mathrm{arg} \min\limits_{\mathbf{G}_{1}, \mathbf{G}_{2}} \max\limits_{\mathbf{D}_{1}, \mathbf{D}_{2}} \tilde{V}(\mathbf{G}_{1}, \mathbf{G}_{2}, \mathbf{D}_{1}, \mathbf{D}_{2})
     % \end{cases}$
     % & Property \\ \midrule
     % $\mathrm{DecompOpt^{[2]}}$ & Diffusion &
     % $\begin{cases}
     %     p_{\theta}(M_{0:T-1} | M_{T}, \mathcal{P}, \{ A_{k} \}) = \prod_{t=1}^{T} p_{\theta}(M_{t-1} | M_{t}, \mathcal{P}, \{ A_{k} \}) \\
     %     M_{0} \sim q(M' | \mathcal{P}, \{ A_{k} \})
     % \end{cases}$
     % & Protein \\ \midrule
     $\mathrm{PMDM}^{[3]}$ & Diffusion &
     $\begin{cases}
         p_{\theta}(\mathcal{G}_{t-1} | \mathcal{G}_{t}) = \mathcal{N}(\mathcal{G}_{t-1}; \mu_{\theta}(\mathcal{G}_{t}, t), \sigma_{t}^{2}I), p_{\theta}(\mathcal{G}_{0:T-1} | \mathcal{G}_{T}) \\
         \mu_{\theta}(\mathcal{G}_{t}, t) = \frac{1}{\sqrt{1 - \beta_{t}}} \Big ( \mathcal{G}_{t} - \frac{\beta_{t}}{\sqrt{1 - \overline{\alpha}_{t}}} \epsilon_{\theta}(\mathcal{G}_{t}, t) \Big )
     \end{cases}$
     & Protein \\ \midrule
     % $\mathrm{MARS^{[7]}}$ & Search &
     % $\begin{cases}
     %     (p_{add}, p_{frag}, p_{del}) = \mathcal{M}_{\theta}(M_{i}^{(t-1)}) \rightarrow \mathcal{S} \\
     %     M^{\prime} = \mathrm{arg} \max \log M_{\theta}(\mathcal{S})
     % \end{cases}$
     % & Property \\ \midrule
     % $\mathrm{MolEvol^{[8]}}$ & Search &
     % $ p_{\theta}(M) = \int_{s \in \mathcal{S}} p(s) p_{\theta}(M | s) ds $
     % & Property \\ \midrule
     % $\mathrm{MolSearch^{[4]}}$ & Search &
     % $\begin{cases}
     %     \mathbf{U}_{k} = \frac{\mathcal{F}_{k}}{n_{k}} + \lambda \sqrt{\frac{4 \ln n + \ln \mathrm{d}}{2n_{k}}} \quad \mathrm{for} \, k \, \mathrm{=} \, \mathrm{1, ..., K} \\
     %     V_{p} = \mathrm{P}(\mathbf{U}_{1}, ..., \mathbf{U}_{\mathrm{K}})
     % \end{cases}$
     % & Property \\ \midrule
     $\mathrm{DST^{[4]}}$ & Search &
     $ \tilde{\mathcal{X}}_{*}, \tilde{\mathcal{A}}_{*}, \tilde{\mathbf{w}}_{*} = \mathrm{arg} \max_{\{ \tilde{\mathcal{X}}_{M}, \tilde{\mathcal{A}}_{M}, \tilde{\mathbf{w}}_{M} \}} \mathrm{GNN}(\{ \tilde{\mathcal{X}}_{M}, \tilde{\mathcal{A}}_{M}, \tilde{\mathbf{w}}_{M} \}; \Theta_{*}) $
     & Property \\ \midrule
     $\mathrm{HN\mbox{-}GFN^{[5]}}$ & Search &
     $ \mathcal{S}_{i+1} = \mathcal{S}_{i} \cup \{ (M_{j}^{i}, f(M_{j}^{i})) \}_{j=1}^{b} $
     & Property \\ \midrule
     % $\mathrm{DyMol^{[8]}}$ & Search &
     % % $ p_{\theta}(x_{M} = x_{L}) = \prod_{j=0}^{L} p_{\theta}(x_{j} | x_{j-1}, x_{j-2}, ..., x_{0}) $
     % $\begin{cases}
     %     \mathbf{F}(\mathbf{z}_{x}, t) = \{ f_{1}(\mathbf{z}_{x}), f_{2}(\mathbf{z}_{x}), ..., f_{t}(\mathbf{z}_{x}) \} \\
     %     \mathbf{R}(x, t) = \sum_{i=1}^{t} w_{i}(t)f_{i}(\mathbf{z}_{x})
     % \end{cases}$
     % & Property \\ \midrule
     \end{tabular}
  % \begin{tablenotes} %添加此处
  \begin{minipage}{\linewidth}
    \scriptsize 
    % \item $^{[1]}$ \cite{jin2018junction}; 
    $^{[1]}$\cite{wu2024leveraging}; 
    $^{[2]}$\cite{jin2023fflom}; 
    % $^{[3]}$ \cite{maziarka2020mol}; 
    % $^{[2]}$\cite{zhoudecompopt}; 
    $^{[3]}$\cite{huang2024dual}; 
    % $^{[7]}$ \cite{xiemars2021mars}; 
    % $^{[8]}$ \cite{chen2021molecule}; 
    % $^{[4]}$\cite{sun2022molsearch}; 
    $^{[4]}$\cite{fudifferentiable}; 
    $^{[5]}$\cite{zhu2024sample}.
    % $^{[8]}$\cite{shin2024dynamic}. 
    
    \textbf{Notations}: 
    % $\mathbf{z}_{\mathcal{T}}, \mathbf{z}_{\mathcal{G}}$ denote two-part latent representations of junction tree and graph structure. % JTVAE
    % $A_{k}$ denotes a reference arm and % DecompOpt
    $\mathcal{C}$ represents the generative conditions, $M_{\text{tag}_{i}}$ represents $i$-th atomic tags for the molecules' SMILES strings, $\mathrm{Trans}(\cdot)$ is the Transformer framework and $\text{Emb}$ is the standard input for the transformer, encompassing both word and positional embeddings. % Prompt-MolOpt
    % $\mathcal{M}_{\theta}$ is the the molecular graph editing model and $\mathcal{S}$ is the constantly updated model training dataset. $p_{add}, p_{frag}, p_{del}$ are probability distributions with different operations on molecules. % MARS
    % $\mathrm{K}$ denotes the number of child nodes in the search procedure, $\mathcal{F}_{k}$ is the average reward of node $k$, $n_{k}$ is the number of times node $k$ is accessed, and $n$ is the iterative epochs. $\mathrm{d}$ is the reward vector dimension, $\lambda$ signifies an exploration parameter used to balance exploration and utilization, $\mathrm{P}(\cdot)$ denotes the set of nodes based on the Pareto optimality selection. % MolSearch
    Meanwhile, $\mathbf{w}$ denotes the node weight vector and $\mathrm{GNN}(\cdot)$ is the graph neural network whose parameters are $\Theta$, % DST
    Finally, $\mathcal{S}$ is the constantly updated model training dataset, and $b$ represents the batch size. % HN-GFN
    % $x$ is the element in the sequence of a molecule and $L$ is the maximum length of the sequence. % DyMol
    % Finally, $f_{i}(\cdot)$ represents the $i$-th objective score function, $\mathbf{F}(\cdot, t)$ is the set of objective functions at time $t$, and $\mathbf{R}(\cdot, t)$ and $w_{i}(t)$ represent the reward score and the weight of the $i$-th objective at time $t$. % DyMol
  % \end{tablenotes} %添加此处
  % \end{threeparttable} %添加此处
  \end{minipage}
  \caption{Summary of molecular optimization methods.}
  \label{tab:MolOpt}
\end{table*}


\begin{table}[htpb]
\centering
\renewcommand\arraystretch{0.99} % 行间距
\setlength\tabcolsep{3pt} % 列间距
\begin{threeparttable}
\resizebox{\columnwidth}{!}{
\begin{tabular}{cccr}
\toprule
\textbf{Datasets} & \# \textbf{Data Struc.}  & \# \textbf{Tasks} & \# \textbf{of Samples} \\
\midrule
\rowcolor{gray!20} \multicolumn{4}{c}{\textbf{Benchmark 1: TDC Datasets}$^{[1]}$} \vspace{0.1cm}  \\

BindingDB & Drug–Target & Reg. & 2,701,247 \\
DAVIS & Drug–Target &Reg. & 30,056 \\
KIBA & Drug–Target & Reg. & 118,254 \\
DrugBank & Drug–Drug &  Cla. & 191,808 \\
TWOSIDES & Drug–Drug & Cla. & 4,651,131 \\
GDSCv2 & Drug–Cell & Reg. & 243,466 \\
\midrule

\rowcolor{gray!20}  \multicolumn{4}{c}{\textbf{Benchmark 2: TUDataset}$^{[2]}$} \vspace{0.1cm}  \\
QM9 & Drug(Qm., 3D) & Reg. & 133,885 \\
ZINC & Drug(Qm.) & Reg. & 249,456 \\
\midrule

\rowcolor{gray!20}  \multicolumn{4}{c}{\textbf{Benchmark 3: Open Graph Benchmark}$^{[3]}$} \vspace{0.1cm}  \\
HIV & Drug(Bio.) & Cla. & 41,913 \\
Tox21 & Drug(Physio.)  & Cla. & 8,014 \\
ToxCast & Drug(Physio.)  & Cla. & 8,615 \\
BBBP & Drug(Physio.) & Cla. & 2,053 \\
PCQM4Mv2$^{[5]}$ & Drug(Qm.) &  Reg. & 3,746,619 \\
\midrule

\rowcolor{gray!20}  \multicolumn{4}{c}{\textbf{Benchmark 4: MoleculeNet}$^{[4]}$} \vspace{0.1cm}  \\
PCBA & Drug(Bio.) & Cla. & 439,863 \\
MUV & Drug(Bio.) & Cla. & 93,127 \\
BACE & Drug(Bio.) & Cla. & 1,522 \\
SIDER & Drug(Physio.)  & Cla. & 1,427 \\
ClinTox & Drug(Physio.)  & Cla. & 1,491 \\
QM7 & Drug(Qm., 3D) & Reg. & 7,165 \\
QM8 & Drug(Qm., 3D) & Reg. & 21,786 \\
ESOL & Drug(Phys. Chem.) & Reg. & 1,128 \\
FreeSolv & Drug(Phys. Chem.) & Reg. & 643 \\
Lipophilicity & Drug(Phys. Chem.) & Reg. & 4,200 \\
\midrule

\rowcolor{gray!25}  \multicolumn{4}{c}{\textbf{Others}} \\
MD17/22$^{[6]}$ & Drug(Qm.) &  Reg. & 99,999-627,983 / 5,032-85,109 \\
OC20/22$^{[7]}$ & Drug(Qm.) &  Reg. &  1,281,040 / 62,331 \\
Molecule3D$^{[8]}$ & Drug(Qm.) &  Reg. & 3,899,647 \\
3BPA$^{[9]}$ & Drug(Qm.) &  Reg. & 500 \\
ANI-1$^{[10]}$ & Drug(Qm.) &  Reg. & 24,416,306 \\

%===================DTI================
 &  &  & \multicolumn{1}{r}{\textbf{Drugs / Targets}} \\
LIT-PCBA$^{[11]}$ & Drug–Target &  Cla. & \multicolumn{1}{r}{415,225 / 15} \\
C.elegans$^{[12]}$ & Drug–Target &  Cla. & \multicolumn{1}{r}{1,434 / 2,504} \\
Human$^{[13]}$ & Drug–Target &  Cla. & \multicolumn{1}{r}{1,052 / 852} \\
DUD-E$^{[14]}$ & Drug–Target &  Cla. & \multicolumn{1}{r}{22,886 / 102} \\
Metz$^{[15]}$ & Drug–Target &   Reg. & \multicolumn{1}{r}{1,423 / 170} \\
Karimi$^{[16]}$ & Drug–Target &  Reg. & \multicolumn{1}{r}{3,672 / 1,287} \\
BioSNAP$^{[17]}$ & Drug–Target &  Reg. & \multicolumn{1}{r}{4,510 / 2,481} \\
%================DDI=================
 &  &  &  \multicolumn{1}{r}{\textbf{Drugs / Total}} \\
DRUGCOMBO$^{[18]}$ & Drug–Drug &  Cla. & \multicolumn{1}{r}{3,242 / 49,392} \\
KEGG$^{[19]}$ & Drug–Drug &  Cla. & \multicolumn{1}{r}{1,295 / 56,983} \\
%MIMIC-III$^{[14]}$ & Drug-Drug &  Cla. & \multicolumn{1}{c}{4,127 / 448} \\
SIDER$^{[20]}$ & Drug–Drug &  Cla. & \multicolumn{1}{r}{1,430 / 139,756} \\
%OFFSIDES$^{[16]}$ & Drug-Drug &  Cla. & \multicolumn{1}{c}{3,300 / 487,530} \\
ChCh-Miner$^{[21]}$ & Drug–Drug &  Cla. & \multicolumn{1}{r}{1,322 / 48,514} \\
OBG-biokg$^{[22]}$ & Drug–Drug &  Cla. & \multicolumn{1}{r}{808 / 111,520} \\
ZhangDDI$^{[23]}$ & Drug–Drug &  Reg. & \multicolumn{1}{r}{548 / 48,548} \\

%===================DRP================
 &  &  & \multicolumn{1}{r}{\textbf{Drugs / Cells}} \\
CCLE$^{[24]}$ & Drug–Cell & Reg. & \multicolumn{1}{r}{24 / 479} \\
NCI-60$^{[25]}$ & Drug–Cell & Reg. & \multicolumn{1}{r}{50,000 / 60}  \\


\bottomrule

\end{tabular}
}
\end{threeparttable}

\begin{minipage}{\linewidth} \scriptsize
% $^{[1]}$\cite{SphereNet}; $^{[2]}$\cite{Equiformer}; $^{[3]}$\cite{ComENet}; $^{[4]}$\cite{ViSNet}; $^{[5]}$\cite{TorchMD-NET}; $^{[6]}$\cite{Allegro}.

$^{[1]}$\href{https://tdcommons.ai}{The therapeutics data commons dataset}; 
$^{[2]}$\href{https://chrsmrrs.github.io/datasets/}{The collection of benchmark datasets for learning with graphs}; 
$^{[3]}$\href{https://ogb.stanford.edu}{The open graph benchmark}; 
$^{[4]}$\href{https://moleculenet.org}{The benchmark for molecular machine learning}; 
$^{[5]}$\href{https://ogb.stanford.edu/docs/lsc/pcqm4mv2/}{Two molecular dynamics benchmarks for evaluating force fields}; $^{[6]}$\href{http://www.sgdml.org}{Two molecular dynamics datasets}; 
$^{[7]}$\href{https://fair-chem.github.io/index.html}{Two DFT-based molecular datasets for computational chemistry};
$^{[8]}$\href{https://github.com/divelab/MoleculeX}{A 3D geometries benchmark};
$^{[9]}$\href{https://service.tib.eu/ldmservice/dataset/3bpa-dataset}{A benchmark dataset for equivariant many-body interaction operations};%metz
$^{[10]}$\href{https://materials.colabfit.org/id/DS_p4evspy1ntcs_0}{A dataset of 20 million conformations}; %karimi
$^{[11]}$\href{https://drugdesign.unistra.fr/LIT-PCBA/}{A dataset with high-confidence data}; %LIT-PCBA 
$^{[12]}$\href{https://snap.stanford.edu/data/C-elegans-frontal.html}{A Caenorhabditis elegans database};
$^{[13]}$\href{https://github.com/peizhenbai/DrugBAN/tree/main/datasets}{The human DTI dataset};
$^{[14]}$\href{https://dude.docking.org/}{A database of useful (docking) decoys-Enhanced};
$^{[15]}$\href{https://service.tib.eu/ldmservice/dataset/metz}{The G protein-coupled receptor focused dataset};%metz
$^{[16]}$\href{https://drive.google.com/file/d/1_iZ8B1JZkCKmKlQNewOCr3kbnWfAIc-r/view}{A DTA and side effect dataset}; %karimi
$^{[17]}$\href{https://snap.stanford.edu/biodata/datasets/10002/10002-ChG-Miner.html}{The biomedical network dataset}; %biosnap
$^{[18]}$\href{https://drive.google.com/file/d/1_iZ8B1JZkCKmKlQNewOCr3kbnWfAIc-r/view}{A drug combination synergy database}; %DRUGCOMBO
$^{[19]}$\href{https://www.genome.jp/kegg/}{The gene\&genome database};%KEGG
%$^{[14]}$\href{https://physionet.org/content/mimiciii/1.4/}{The ICU electronic health records}; %mimic
$^{[20]}$\href{http://sideeffects.embl.de/}{A drug-side effect association database};%SIDER
%$^{[16]}$\href{https://github.com/tatonetti-lab/offsides}{The off-label drug side effect database};%OFFSIDES
$^{[21]}$\href{https://snap.stanford.edu/biodata/datasets/10001/10001-ChCh-Miner.html}{A DDI network dataset};
$^{[22]}$\href{https://ogb.stanford.edu/docs/linkprop/}{The biological knowledge with gene-drug-disease triples};% OBG-biokg
$^{[23]}$\href{https://github.com/zw9977129/drug-drug-interaction/tree/master/dataset}{A multi-source dataset};
$^{[24]}$\href{https://sites.broadinstitute.org/ccle}{The cancer cell line encyclopedia}; 
$^{[25]}$\href{https://dtp.cancer.gov/discovery_development/nci-60/}{The NCI-60 human tumor cell lines screen}.


% $^{[20]}$\href{https://www.cancer.gov/ccg/research/genome-sequencing/tcga}{The cancer genome atlas};
% $^{[22]}$\href{https://cancer.sanger.ac.uk/cosmic}{The catalogue of somatic mutations in cancer};
% $^{[23]}$\href{https://pubchem.ncbi.nlm.nih.gov}{The open chemistry database at the national institutes of health};
% $^{[24]}$\href{http://caldaslab.cruk.cam.ac.uk/bcape}{The PDTX-derived tumor cells dataset};
% $^{[25]}$\href{https://depmap.org/portal/}{The cancer dependency map};
% TCGA$^{[2]}$ & Drug-Cell & Reg. & - \\
% COSMIC$^{[2]}$ & Drug-Cell & Reg. & - \\
% PubChem$^{[2]}$ & Drug-Cell & Reg. & - \\
% PDTC$^{[2]}$ & Drug-Cell & Reg. & - \\
% DepMap$^{[2]}$ & Drug-Cell & Reg. & - \\

\textbf{Notations}: Quantum mechanics (Qm.); Biophysics (Bio.); Physical chemistry (Phys. Chem.); Physiology (Physio.).

\end{minipage} 
\caption{Common datasets for small molecule drug discovery.}
\label{Datasets}
\end{table}




\subsection{Molecular Generation}
\label{3.5}
The chemical space is vast, with over $10^{33}$ possible compound structures \cite{zhu2023molhf}, making traditional methods slow and labor-intensive. Computational MG methods have thus become essential to accelerate molecule discovery with desired properties.

% Existing methods are categorized into four types: variational autoencoders (VAE) \cite{kingma2013auto}, flow-based models \cite{dinh2016density}, generative adversarial networks (GAN) \cite{goodfellow2014generative}, and diffusion-based models \cite{sohl2015deep}. VAE, GAN, and flow-based methods typically learn a low dimensional latent space representation $\mathbf{z}$ and then sample from the latent space to generate new molecules. Differently, diffusion-based methods start with pure noise and gradually obtains structured data through a series of denoising steps, without relying on a fixed hidden space representation. This fundamental difference allows diffusion models to generate more diverse and high-quality molecules while maintaining better control over the generation process.
Initially, MG methods were largely unconditional random generation \cite{huang20223dlinker,jo2022score}, which failed to meet practical requirements. As a result, conditional MG methods have emerged as the mainstream approach. Key trends include 1) Property-conditioned generation \cite{zhu2023molhf}, which targets molecules with specific properties. 2) Molecular (sub)structure-conditioned generation, which uses predefined structural elements for design. 3) Target-conditioned generation \cite{guan2023decompdiff}, which focuses on molecules with high binding affinity to biological targets. 4) Phenotype-conditioned generation, which guides molecular design towards desired biological outcomes. Diffusion models have recently become dominant in MG \cite{lee2023exploring}, as they iteratively refine molecular structures from noise, offering more flexibility and integration with conditional frameworks for targeted molecular design.

Despite these advancements, poor interpretability remains a challenge. Most DL-based models operate as black boxes, making it difficult to understand how molecular structures are generated or which features influence specific properties. This limits their reliability and practical application in drug discovery, where understanding structure–property relationships is essential. Addressing this requires developing more interpretable frameworks that incorporate mechanistic insights and knowledge-driven constraints.



\subsection{Molecular Optimization}
\label{3.6}

MO task plays a key role in drug discovery and material design, refining molecular structures to meet specific functional, chemical, and biological criteria. Unlike MG methods, which focuses on creating new molecules, MO adjusts existing molecules to enhance their properties for particular applications, such as binding affinity, solubility, stability, and toxicity.

% In addition to common methodologies, such as VAE, flow, GAN and diffusion, search-based and auto-regressive approaches are also major choices utilized in MO \cite{xiemars2021mars,wu2024leveraging}. Search-based approaches explore the chemical space by iteratively generating and evaluating candidate molecules based on predefined objectives or constraints. Auto-regressive methods generate molecules sequentially, with each step conditioned on the previous part of the molecule, allowing for fine-grained control over the structure. 

MO approaches can be broadly classified into two categories: generative models and search-based methods. Generative models like VAE, generative adversarial networks (GAN), flow-based methods, and diffusion models optimize molecules by manipulating their latent representations or refining structures iteratively from noise \cite{huang2024dual,xiong2024text}. In contrast, search-based methods, which use evolutionary algorithms \cite{fudifferentiable}, navigate the chemical space more directly. Additionally, auto-regressive models construct molecules sequentially, allowing precise control over the optimization process \cite{wu2024leveraging}. While early methods focused on latent space optimization, search-based approaches have gained popularity due to their superior interpretability and stability. Evolutionary algorithms evolve and eliminate molecules from a candidate set, while scoring functions modify molecules until the optimization objective is achieved. Other search-based methods map molecules to a high-dimensional solution space for optimization.


% Generally, search-based MO methods can be divided into three types: 1) Strategies that adopt an evolutionary algorithm and continuously evolve and eliminate molecules from a candidate set to obtain the final optimized molecular group. 2) Approaches that use a scoring function to continuously modify initial molecule until the optimization objective is achieved. 3) Techniques that map molecules to a high-dimensional solution space and search for optimized molecules. 
% Representatively, Xie et al. iteratively edited molecular graph fragments to optimize multiple objectives \cite{xxx}. Meanwhile, Chen et al. optimized molecular properties using an evolution algorithm-based search strategy \cite{xxx}.

Despite these advances, MO still faces challenges with poor interpretability, as the connection between structural modifications and property enhancements remains unclear. Many optimization techniques propose molecular changes without explicitly explaining the rationale, hindering the understanding of how modifications improve specific attributes.



\section{Datasets}
\label{sec:4}
% Data plays a crucial role in research within the field of small molecule drug discovery. The datasets typically encompass information on the chemical structures, biological activities, pharmacokinetic properties, toxicity, and other characteristics of small molecules, covering various stages ranging from target identification and lead compound screening to drug optimization. For the convenience of research and application, these datasets are categorized based on their data structures and task types, with the corresponding data volumes presented. These datasets are all suitable for model performance validation in molecular generation and optimization tasks, and thus no additional labeling for this purpose is required.

Small molecule drug discovery datasets form the foundation for research in this field. Typically, these datasets include information on the small molecules' characteristics such as their chemical structures, biological activities, pharmacokinetic properties, and toxicity, spanning multiple stages from target identification and lead compound screening to drug optimization. To facilitate research and application, these datasets are categorized based on their data structures and task types, with corresponding volumes provided. Since these datasets are suitable for molecular generation and optimization tasks, Table \ref{Datasets} does not specifically list the datasets related to these two tasks. Additionally, due to the large number and variety of datasets, we provide the access URLs for each dataset without citing the references individually.


% We present several commonly used benchmark datasets, as well as some datasets that are less widely applied. As shown in Table \ref{Datasets}, the TDC datasets cover various tasks in small molecule drug discovery and are relatively mainstream. Additionally, QM9 and ZINC from the TUDataset are two molecular datasets that include a wide range of properties such as quantum chemical properties, and are widely used in property prediction as well as conditional molecular generation and optimization tasks. The open graph benchmark (OGB) and MoleculeNet encompass numerous molecular property datasets, commonly used for performance validation of various molecular graph representation methods. Since the DRP, DDI, and DTI/DTA tasks investigate the complex relationships between drugs and other entities (such as targets, cell lines, and drugs), the datasets involved are diverse and complex, and are thus presented under the "Others" category.

We present several commonly used benchmark and non-benchmark datasets. As shown in Table \ref{Datasets}, the TDC datasets cover various tasks during small molecule drug discovery and are relatively mainstream. Additionally, QM9 and ZINC from TUDataset are molecular datasets that include a wide range of properties, such as quantum chemical properties, and are widely used in property prediction and conditional MG and MO tasks. Furthermore, the Open Graph Benchmark (OGB) and MoleculeNet databases include multiple molecular property datasets, which are commonly used for validating the performance of various molecular graph representation methods. For instance, MoleculeNet is a widely used benchmark dataset for molecular studies, encompassing four major categories: quantum mechanics, physical chemistry, biophysics, and physiology. Since the DRP, DDI, and DTI/DTA tasks investigate complex relationships between drugs and other entities (such as targets, cell lines, and drugs), the datasets involved are diverse and complex, and are thereby categorized under "Others." In addition, most small molecule datasets are regularly updated and expanded, and the dataset statistics are accurate as of February 4, 2025.

% It serves as a standard for molecular property prediction and drug discovery tasks.




% As shown in Table \ref{Datasets}, we present several commonly used benchmark datasets (covering different stages of small molecule drug discovery) alongside datasets that are less widely categorized. The benchmark datasets have undergone rigorous screening and validation, ensuring high reliability and representativeness, making them ideal for model training and performance evaluation. In contrast, datasets that are not widely categorized may offer more diverse information.


\section{Challenges and Opportunities}
\label{sec:5}





\paragraph{Poor Interpretability.}
% SubCDR
% MolSearch
% DST
% HN-GFN
% DyMol
% PMDM
% DTI-MGNN
% HyperAttentionDTI
% DrugBAN

% The lack of interpretability in AI-driven drug discovery models poses a critical challenge, particularly as complex deep learning architectures dominate tasks like drug-target interaction prediction and MO. These "black-box" models often obscure the mechanistic rationale behind their predictions, hindering trust and clinical translatability. For instance, in affinity prediction, models may fail to reveal binding hotspots or pharmacophore contributions, complicating structure-activity relationship (SAR) analysis. Similarly, generative models for de novo molecule design might produce chemically valid but biologically irrelevant structures due to opaque decision pathways. Such opacity raises ethical and regulatory concerns, especially when prioritizing candidates for costly preclinical validation.

% Opportunities lie in advancing explainable AI (XAI) frameworks tailored to biochemical contexts. Techniques like attention mechanisms, gradient-based attribution, or counterfactual explanations could decode model logic into biophysically meaningful insights—for example, identifying critical substructures governing potency or off-target risks. Integrating XAI with domain knowledge (e.g., molecular dynamics or crystallography data) may bridge empirical predictions with mechanistic hypotheses, accelerating lead optimization. Moreover, explainable models could enhance collaborative human-AI workflows, enabling medicinal chemists to iteratively refine generative outputs or validate predicted drug response biomarkers in heterogeneous patient data. Ultimately, interpretability is not merely a technical hurdle but a catalyst for hypothesis-driven discovery, fostering innovation while aligning AI with the rigorous causality standards of translational science.

% In the field of small molecule drug discovery, while interpretability through correlation (i.e., identifying which molecular features are strongly associated with predicted outcomes) is relatively straightforward to achieve, causal interpretability represents a far more complex and challenging task. Correlation interpretability can be assessed using traditional feature importance evaluation methods, such as SHapley Additive exPlanations or attention mechanisms based on models, which can reveal which features are strongly correlated with drug responses or drug-target interactions \cite{fudifferentiable,zhu2024sample,shin2024dynamic}. These methods, such as SubCDR \cite{subcdr}, decompose the molecule into multiple subcomponents and then quantify the contribution of each subcomponent to the prediction, providing a certain level of explanation and, to some extent, helping us understand the model's decision-making process.

% However, causal interpretability is much more difficult. Many tasks in drug discovery, especially DDI, DTI/DTA, and DRP, involve complex interactions between multiple molecules that are often not merely correlational. Extracting causal relationships from these data, understanding how one molecule influences the activity or response of another molecule through specific mechanisms, requires more complex models and methods. Causal inference typically relies on multi-gene regulatory networks, involving interactions among multiple factors. Therefore, accurately capturing causal relationships may require a deep understanding of biological background knowledge.

% To achieve causal interpretability, more specific techniques and experimental methods may be needed. For instance, constructing gene regulatory networks, integrating interdisciplinary datasets, or combining these with wet-lab experiment verification could offer viable solutions. Through experimental validation, researchers can progressively confirm whether the causal relationships identified by the model align with actual biological processes, thereby enhancing the credibility and interpretability of the model.


In the small molecule drug discovery field, achieving model interpretability through correlation (i.e., identifying which molecular features are strongly associated with the predicted outcomes) is relatively straightforward. This can be accomplished using traditional feature importance evaluation methods, such as SHapley Additive exPlanations or model-based attention mechanisms, which reveal the features that are strongly correlated with drug responses or drug–target interactions \cite{fudifferentiable,zhu2024sample}. For example, methods such as SubCDR \cite{subcdr} decomposed molecules into multiple subcomponents and quantified their contributions in the prediction, providing explanations and helping us understand the model's decision-making process. However, causal interpretability is more complex and challenging. Explaining the complex interactions between multiple entities requires understanding a molecule's influence on the activities and responses of another through specific mechanisms, necessitating more complex models and methods. Moreover, causal inference typically relies on multi-gene regulatory networks that involve interactions among various factors, requiring a deep understanding of biological background knowledge. Therefore, achieving causal interpretability may require more specific techniques and experimental methods. For instance, constructing gene regulatory networks, integrating interdisciplinary datasets, or combining these with wet-lab experimental validation could offer feasible solutions to address this challenge.


\paragraph{Low Out-of-Distribution Generalization Capability.}
\label{5.2}
% The 药物发现 tasks's  的 数据对象组合模式形如such as \textbf{Drug+X} combinations, often give rise to the potential issue of out-of-distribution scenarios。此外，分子属性预测任务通常面临分布外泛化的挑战，尤其是在数据集按照骨架或一定相似性特征划分后，模型对于特征跨度较大的样本表现出较差的预测性能。这种数据可以总结为$在M1集合训练，在M2集合测试$. For \textbf{Drug+X} combinations, 情况会复杂一些, test scenarios can be categorized into four types based on whether the drugs and \textbf{X} in the test set observed in the training set: \textbf{Seen-Both}: both drugs and X in the test set are present in the training set, \textbf{Unseen-Drug}: the drugs in the test set are not present in the training set, \textbf{Unseen-X}: the X in the test set are not present in the training set, and \textbf{Unseen-Both}: both drugs and X in the test set are not present in the training set.

The data combination patterns in drug discovery tasks, such as "drug+X" combinations, often give rise to potential OOD issues. Additionally, the MPP task commonly encounters OOD generalization challenges, particularly when datasets are divided based on molecular skeletons or certain similarity features, resulting in poor prediction performance for samples with significantly different characteristics. For "drug+X" combinations, the situation becomes more complex. Test scenarios can be categorized into four types based on whether the drugs and X in the test set have been observed in the training set. 1) Seen-Both: both drugs and X are present in the test and training sets. 2) Unseen-Drug: the drugs in the test set are not present in the training set. 3) Unseen-X: the X in the test set are not present in the training set. 4) Unseen-Both: both drugs and X in the test set are not present in the training set. All cases except Seen-Both represent OOD problems. 

% For "Drug+X" combinations, the situation becomes more complex. Test scenarios can be categorized into four types based on whether the drugs and "X" in the test set have been observed in the training set. 1) Seen-Both: both drugs and "X" in the test set are present in the training set; 2) Unseen-Drug: the drugs in the test set are not present in the training set; 3) Unseen-X: the "X" in the test set are not present in the training set; and 4) Unseen-Both: both drugs and "X" in the test set are not present in the training set. All cases except Seen-Both represent OOD problems. 


To improve model generalizability in OOD scenarios, several strategies may be useful. First, data augmentation and generative models, such as VAEs and GANs, can be used to simulate various "drug+X" combinations, introducing the model to a broader range of potential scenarios during training and enhancing its adaptability to new environments. Second, transfer learning can leverage knowledge from tasks with known drugs or targets and apply it to new ones, assisting the model to address unseen drugs or X. Finally, domain adaptation techniques have recently demonstrated the ability to reduce distributional discrepancies between training and testing datasets \cite{MSDA,code-ae} by learning the mapping relationships between the source and target domains, further enhancing the model's predictive ability on new data.


% Additionally, multi-task learning can enable the model to handle multiple related tasks simultaneously, sharing information and learning generalized features that improve performance in OOD settings. This approach involves intentionally leveraging inter-class correlations between different drug types or "X" types in different OOD scenarios, rather than simply mixing information related to multiple drugs and "X".

% In practice, the types of drugs, "X", and biological environments are often dynamic, with new drugs and targets continuously being discovered. Models trained only on known drugs or targets will struggle to predict interactions involving novel drugs or previously unseen targets. If a model performs well only in the seenBoth scenario, it will be unable to address novel drug or targets encountered in clinical or research settings. Therefore, improving a model’s generalization ability in OOD scenarios, can significantly enhance the applicability and reliability of drug screening, interaction prediction, and similar tasks in real-world settings, which is of paramount importance.

% However, existing methods often emphasize Seen-Both problems, and their generalization ability in OOD scenarios remains unsatisfactory. Therefore, enhancing model performance in OOD settings is a key challenge that needs to be addressed. The same issue arises in drug response prediction, drug interaction prediction, and similar tasks.



% Models trained only on known drugs or "X" will face difficulties when predicting interactions involving novel drugs or previously unseen "X." If a model performs well only in the Seen-Both scenario, it will struggle to handle new drugs or "X" encountered in clinical or research settings. Therefore, enhancing a model's generalization ability across the three OOD scenarios is critical for improving the applicability and reliability of drug screening, interaction prediction, and similar tasks in real-world environments.

% However, existing methods often focus on the Seen-Both problem, and their generalization capability in OOD scenarios remains insufficient. Therefore, improving model performance in OOD environments is a key challenge that must be addressed. This issue is equally prevalent in drug response prediction, drug interaction prediction, and similar tasks.


% In practice, the types of drugs, "X," and biological environments are often dynamic, with new drugs and "X" constantly being discovered. However, existing methods often focus on the Seen-Both problem, and their generalization capability in OOD scenarios remains insufficient.




% \subsection{Lack of Wet Lab Validation}
% In the field of drug discovery, the process from computational prediction to wet lab validation effectively screens potential drug candidates. However, the high costs and lengthy timelines associated with wet lab experiments present significant challenges \cite{karlov2019chemical}. Wet lab experiments require substantial financial investment, encompassing multiple stages such as compound synthesis, cell culture, and animal testing. These experiments not only consume considerable resources but also have extended timelines, significantly driving up overall research and development costs. Moreover, due to the complexity of biological systems, computational predictions often deviate from actual wet lab results, leading to some candidate drugs failing to meet expectations. This increases the risk of failure and results in substantial wastage of time and resources.

% With the continuous advancements in artificial intelligence, deep learning, and high-throughput screening technologies, these challenges in drug discovery are gradually giving rise to new opportunities. The primary goal of deep learning in drug discovery is to minimize reliance on wet lab experiments, thereby improving screening efficiency and reducing costs. Consequently, a critical challenge to address is how to discover more effective drug molecules within limited time and laboratory resources. 

% The integration of adaptive experimental design with computational model predictions may enable real-time adjustments to experimental strategies, potentially enhancing efficiency and success rates. Additionally, the combination of efficient screening strategies with high-throughput technologies could lead to more effective large-scale drug screening, accelerating experimental workflows, shortening screening timelines, and reducing R\&D costs. Furthermore, fostering closer integration between online deep learning prediction methods or platforms and experimental screening holds the potential to optimize resource utilization in real experiments, further enhancing the overall efficiency of drug discovery.


\paragraph{Model Training and Laboratory Validation Gap.}

% Current methods typically make predictions directly after training, lacking the capability to continuously learn and adapt to new experimental results. This limits the model's ability to effectively utilize new experimental data, and there exists a gap between preclinical datasets and the actual drug development processes in laboratories. By incorporating online learning and incremental learning techniques, models can continuously update during real-world applications, improving their adaptability and generalization to new data.

Current methods typically make predictions directly after training, and those used in real-world applications often lack the ability to continuously learn and adapt to new experimental results. This limitation restricts the model's ability to effectively utilize new experimental data. Specifically, there is a noticeable gap in performance between preclinical datasets and actual laboratory drug development processes. This is demonstrated by issues such as feature drift and sample bias. To address this, online and incremental learning techniques can be incorporated, allowing models to be updated continuously during real-world applications. For example, online reinforcement learning, commonly used in DL systems like large language models (LLMs), can adaptively adjust model parameters in response to new data streams, enhancing the model's ability to generalize and adapt to dynamic environments and new data.


% \paragraph{Complex Correlations Between Multi-task and Multi-modal Data.}

% Small molecule drug discovery involves multiple tasks and data types, such as DDI and DRP. These tasks and data types have complex interrelations, and effectively mining and utilizing this information to enhance performance remains a significant challenge. Hence, a multi-task learning framework that leverages shared information across tasks may improve the model's ability to handle complex data. Additionally, integrating multi-modal data, such as chemical structures and gene expression, can contribute to the development of more comprehensive prediction models, potentially improving prediction accuracy.


\paragraph{Lack of Fair Benchmarking Results.}

Although numerous machine learning methods have been developed, a lack of standardized and fair benchmarking results for key tasks exists. For example, many studies only use a small portion of the available data for training, limiting the model's scalability. Therefore, establishing standardized computational evaluation protocols and large-scale benchmark testing is critical for advancing drug discovery. By developing large-scale multi-task and multi-modal datasets and conducting standardized benchmarking tests, fair comparisons between different models and methods can be promoted, ultimately enhancing model scalability and generalizability.


\clearpage
% \clearpage

% \newpage


% \appendix



%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{ijcai25}

\end{document}

