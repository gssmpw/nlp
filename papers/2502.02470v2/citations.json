[
  {
    "index": 0,
    "papers": [
      {
        "key": "novelli2019deriving",
        "author": "Leonardo Novelli and\nFatihcan M. Atay and\nJ{\\\"{u}}rgen Jost and\nJoseph T. Lizier",
        "title": "Deriving pairwise transfer entropy from network structure and motifs"
      },
      {
        "key": "ursino2020transfer",
        "author": "Mauro Ursino and\nGiulia Ricci and\nElisa Magosso",
        "title": "Transfer Entropy as a Measure of Brain Connectivity: {A} Critical\nAnalysis With the Help of Neural Mass Models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "liu2023seeing",
        "author": "Ziming Liu and\nEric Gan and\nMax Tegmark",
        "title": "Seeing is Believing: Brain-Inspired Modular Training for Mechanistic\nInterpretability"
      },
      {
        "key": "liu2023growing",
        "author": "Ziming Liu and\nMikail Khona and\nIla R. Fiete and\nMax Tegmark",
        "title": "Growing Brains: Co-emergence of Anatomical and Functional Modularity\nin Recurrent Neural Networks"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "patil2023neural",
        "author": "Shreyas Malakarjun Patil and\nLoizos Michael and\nConstantine Dovrolis",
        "title": "Neural Sculpting: Uncovering hierarchically modular task structure\nin neural networks through pruning and network analysis"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "tsitsulin2023graph",
        "author": "Anton Tsitsulin and\nJohn Palowitch and\nBryan Perozzi and\nEmmanuel M{\\\"{u}}ller",
        "title": "Graph Clustering with Graph Neural Networks"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "salha2022modularity",
        "author": "Guillaume Salha{-}Galvan and\nJohannes F. Lutzeyer and\nGeorge Dasoulas and\nRomain Hennequin and\nMichalis Vazirgiannis",
        "title": "Modularity-aware graph autoencoders for joint community detection\nand link prediction"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "cloud2024gradient",
        "author": "Alex Cloud and\nJacob Goldman{-}Wetzler and\nEvzen Wybitul and\nJoseph Miller and\nAlexander Matt Turner",
        "title": "Gradient Routing: Masking Gradients to Localize Computation in Neural\nNetworks"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "park2024monet",
        "author": "Jungwoo Park and\nYoungjin Ahn and\nKee{-}Eung Kim and\nJaewoo Kang",
        "title": "Monet: Mixture of Monosemantic Experts for Transformers"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "watanabe2018modular",
        "author": "Chihiro Watanabe and\nKaoru Hiramatsu and\nKunio Kashino",
        "title": "Modular representation of layered neural networks"
      },
      {
        "key": "filan2021clusterability",
        "author": "Filan, Daniel and Casper, Stephen and Hod, Shlomi and Wild, Cody and Critch, Andrew and Russell, Stuart",
        "title": "Clusterability in neural networks"
      },
      {
        "key": "patil2023neural",
        "author": "Shreyas Malakarjun Patil and\nLoizos Michael and\nConstantine Dovrolis",
        "title": "Neural Sculpting: Uncovering hierarchically modular task structure\nin neural networks through pruning and network analysis"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "hod2022detecting",
        "author": "Shlomi Hod and Stephen Casper and Daniel Filan and Cody Wild and Andrew Critch and Stuart Russell",
        "title": "Detecting Modularity in Deep Neural Networks"
      },
      {
        "key": "lange2022clustering",
        "author": "Richard D. Lange and\nDavid Rolnick and\nKonrad P. Kording",
        "title": "Clustering units in neural networks: upstream vs downstream information"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "zhang2022moefication",
        "author": " Zhang, Zhengyan and\nLin, Yankai and\nLiu, Zhiyuan and\nLi, Peng and\nSun, Maosong and\nZhou, Jie",
        "title": "MoEfication: Transformer Feed-forward Layers are Mixtures of Experts"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "wang2022interpretability",
        "author": "Wang, Kevin and Variengien, Alexandre and Conmy, Arthur and Shlegeris, Buck and Steinhardt, Jacob",
        "title": "Interpretability in the wild: a circuit for llama object identification in gpt-2 small"
      },
      {
        "key": "olah2020zoom",
        "author": "Olah, Chris and Cammarata, Nick and Schubert, Ludwig and Goh, Gabriel and Petrov, Michael and Carter, Shan",
        "title": "Zoom in: An introduction to circuits"
      },
      {
        "key": "elhage2021mathematical",
        "author": "Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and others",
        "title": "A mathematical framework for transformer circuits"
      },
      {
        "key": "conmy2023towards",
        "author": "Conmy, Arthur and Mavor-Parker, Augustine and Lynch, Aengus and Heimersheim, Stefan and Garriga-Alonso, Adri{\\`a}",
        "title": "Towards automated circuit discovery for mechanistic interpretability"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wortsman2020supermasks",
        "author": "Mitchell Wortsman and\nVivek Ramanujan and\nRosanne Liu and\nAniruddha Kembhavi and\nMohammad Rastegari and\nJason Yosinski and\nAli Farhadi",
        "title": "Supermasks in Superposition"
      }
    ]
  }
]