[
  {
    "index": 0,
    "papers": [
      {
        "key": "schwinn2024soft",
        "author": "Schwinn, Leo and Dobre, David and Xhonneux, Sophie and Gidel, Gauthier and Gunnemann, Stephan",
        "title": "Soft prompt threats: Attacking safety alignment and unlearning in open-source llms through the embedding space"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "doshi2024doesunlearningtrulyunlearn",
        "author": "Jai Doshi and Asa Cooper Stickland",
        "title": "Does Unlearning Truly Unlearn? A Black Box Evaluation of LLM Unlearning Methods"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhang2024does",
        "author": "Zhang, Zhiwei and Wang, Fali and Li, Xiaomin and Wu, Zongyu and Tang, Xianfeng and Liu, Hui and He, Qi and Yin, Wenpeng and Wang, Suhang",
        "title": "Does your LLM truly unlearn? An embarrassingly simple approach to recover unlearned knowledge"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "lucki2024adversarial",
        "author": "{\\L}ucki, Jakub and Wei, Boyi and Huang, Yangsibo and Henderson, Peter and Tram{\\`e}r, Florian and Rando, Javier",
        "title": "An adversarial perspective on machine unlearning for ai safety"
      },
      {
        "key": "hu2024jogging",
        "author": "Hu, Shengyuan and Fu, Yiwei and Wu, Steven and Smith, Virginia",
        "title": "Jogging the Memory of Unlearned Models Through Targeted Relearning Attacks"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "lynch2024eight",
        "author": "Lynch, Aengus and Guo, Phillip and Ewart, Aidan and Casper, Stephen and Hadfield-Menell, Dylan",
        "title": "Eight methods to evaluate robust unlearning in llms"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "shi2024muse",
        "author": "Shi, Weijia and Lee, Jaechan and Huang, Yangsibo and Malladi, Sadhika and Zhao, Jieyu and Holtzman, Ari and Liu, Daogao and Zettlemoyer, Luke and Smith, Noah A and Zhang, Chiyuan",
        "title": "Muse: Machine unlearning six-way evaluation for language models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "qi2024unrelateddata",
        "author": "Xiangyu Qi and Boyi Wei and Nicholas Carlini and Yangsibo Huang and Tinghao Xie and Luxi He and Matthew Jagielski and Milad Nasr and Prateek Mittal and Peter Henderson",
        "title": "On Evaluating the Durability of Safeguards for Open-Weight LLMs"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "maini2024tofu",
        "author": "Maini, Pratyush and Feng, Zhili and Schwarzschild, Avi and Lipton, Zachary C and Kolter, J Zico",
        "title": "Tofu: A task of fictitious unlearning for llms"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "jin2024rwku",
        "author": "Zhuoran Jin and Pengfei Cao and Chenhao Wang and Zhitao He and Hongbang Yuan and Jiachun Li and Yubo Chen and Kang Liu and Jun Zhao",
        "title": "RWKU: Benchmarking Real-World Knowledge Unlearning for Large Language Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "li2024wmdp",
        "author": "Li, Nathaniel and Pan, Alexander and Gopal, Anjali and Yue, Summer and Berrios, Daniel and Gatti, Alice and Li, Justin D and Dombrowski, Ann-Kathrin and Goel, Shashwat and Phan, Long and others",
        "title": "The wmdp benchmark: Measuring and reducing malicious use with unlearning"
      }
    ]
  }
]