\documentclass{article}

\input{config}
% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:

\begin{document}

\twocolumn[
\icmltitle{Neural Force Field: Learning Generalized\\Physical Representation from a Few Examples}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Shiqian Li}{equal,pku,bigai}
\icmlauthor{Ruihong Shen}{equal,pku}
\icmlauthor{Chi Zhang}{bigai}
\icmlauthor{Yixin Zhu}{pku}
\end{icmlauthorlist}

\icmlaffiliation{pku}{Institute for Artificial Intelligence, Peking University}
\icmlaffiliation{bigai}{National Key Laboratory of General Artificial Intelligence, BIGAI}

\icmlcorrespondingauthor{Chi Zhang}{zhangchi@bigai.ai}
\icmlcorrespondingauthor{Yixin Zhu}{yixin.zhu@pku.edu.cn}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.25in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
% 1. Basic introduction to field
Physical reasoning is a remarkable human ability that enables rapid learning and generalization from limited experience.
% 2. More detailed background
Current AI models, despite extensive training, still struggle to achieve similar generalization, especially in \ac{ood} settings. This limitation stems from their inability to abstract core physical principles from observations.
% 3. Clear problem statement 
A key challenge is developing representations that can efficiently learn and generalize physical dynamics from minimal data.
% 4. Main result statement
Here we present \ac{nff}, a modeling framework built on \ac{node} that learns interpretable \textbf{force field} representations which can be efficiently integrated through an \ac{ode} solver to predict object trajectories.
% 5. Comparison to previous knowledge
Unlike existing approaches that rely on high-dimensional latent spaces, \ac{nff} captures fundamental physical concepts such as gravity, support, and collision in an interpretable manner. Experiments on two challenging physical reasoning tasks demonstrate that \ac{nff}, trained with only a few examples, achieves strong generalization to unseen scenarios.
% 6. General context
This physics-grounded representation enables efficient forward-backward planning and rapid adaptation through interactive refinement.
% 7. Broader perspective
Our work suggests that incorporating physics-inspired representations into learning systems can help bridge the gap between artificial and human physical reasoning capabilities.
% Humans can predict and interact with novel physical environments after only a few trials. Current AI models, however, even trained from a large amount of data, still fail to achieve the same level of generalization as humans, especially in \ac{ood} settings. We hypothesize the problems lie in the lack of proper representation that abstracts the core principles of physical dynamics from mere observation. Here we propose a new modeling framework, dubbed \ac{nff}, that enables few-shot learning of the underlying physical dynamics. Established on \ac{node}, the \ac{nff} consists of a force field predictor that extracts the latent forces from the field and an \ac{ode} solver that integrates the force field to obtain velocities and displacements. Experiments on two challenging physical reasoning tasks demonstrate that \ac{nff}, trained only with a few observed trajectories, can achieve high generalization ability on unseen scenarios. Unlike existing works, \ac{nff} captures explicit physical concepts studied in intuitive physics such as gravity, support, and collision in the force representation, enabling fast forward-backward planning and refinement from trials in goal-directed physical reasoning tasks.

\end{abstract}

\section{Introduction}

Physical reasoning, the ability to understand and predict how objects interact in the physical world, is fundamental to both human intelligence and artificial systems \citep{spelke2022babies}. This capability underlies crucial applications ranging from robotics to scientific discovery, making it a central challenge in AI research \citep{lake2017building}. One of the remarkable aspects of human cognitive capabilities is the ability to rapidly learn from limited examples \citep{kim2020few,jiang2022bongard,lake2023human,zhang2024human}, especially evident in intuitive physics \citep{kubricht2017intuitive,bear2021physion}. Humans can quickly abstract core physical principles after observing limited physical phenomena, enabling them to predict complex dynamics and interact with novel environments \citep{spelke2007core,battaglia2013simulation,bonawitz2019sticking,xu2021bayesian}.

In contrast, current AI systems face significant limitations in physical reasoning. Despite being trained on gigantic datasets, these models still struggle to achieve human-level generalization, particularly in \acf{ood} settings \citep{lake2017building,zhu2020dark}. The core issue lies in their tendency to overfit observed trajectories rather than capturing inherent physical principles, severely limiting their ability to compose known knowledge and predict outcomes in novel contexts \citep{qi2021learning,li2022learning,wu2022slotformer}. This stark contrast between human capabilities and current model limitations has motivated the search for new approaches that can learn generalizable physical representations from minimal data.
% In contrast, most of the current physical reasoning models, despite being trained on gigantic datasets, still struggle to achieve the same level of generalization as humans, especially in \acf{ood} settings \citep{lake2017building,zhu2020dark}. These models often fall short because they only overfit the observed trajectories instead of capturing the inherent physical principles, which limits their ability to compose known knowledge to predict interactions and outcomes in novel contexts \citep{qi2021learning,li2022learning,wu2022slotformer}. The contrast between humans' effortless physical understanding and current models' inability to generalize after intensive training sparked increasing interest in creating models that can efficiently learn generalized physical representation from minimal data, with robust reasoning across a wide range of environments.

To bridge this gap, we aim to develop agents with few-shot physical learning abilities that achieve robust generalization across diverse environments. This ambitious goal presents three fundamental challenges:
(i) \textbf{Diverse Physical Dynamics}: Physical systems exhibit intricate and nonlinear dynamics shaped by complex object properties and interactions. \ac{ood} scenarios often present drastically different dynamics from training examples, requiring sophisticated representations that explicitly capture core physical principles.
(ii) \textbf{Risk of Overfitting}: The few-shot learning setting dramatically increases the challenge of generalization compared to large-scale training approaches. Models must carefully balance between fitting observed examples and extracting broader physical principles.
(iii) \textbf{Interactive Reasoning}: Effective physical reasoning demands more than passive observation---agents must actively engage with their environment through experimentation and feedback, adapting their understanding based on limited examples.
% In this work, we aim to endow agents with few-shot physical learning abilities while achieving generalization, allowing them to efficiently reason about and interact with physical environments. Achieving this goal presents several challenges:
% (i) \textbf{Diverse Physical Dynamics}: Physical systems are governed by intricate and nonlinear dynamics shaped by object properties and interactions. \ac{ood} scenarios can exhibit drastically different dynamics from those encountered during training. Modeling these complex variations accurately with limited data demands sophisticated representation that explicitly capture core physical principles.
% (ii) \textbf{Risk of Overfitting}: Unlike large-scale training approaches, few-shot learning poses more challenges for AI models to generalize from minimal data. Without suitable representation, models are prone to overfitting, capturing specific details of the limited examples instead of the broader physical principles.
% (iii) \textbf{Interactive Reasoning}: Effective reasoning requires agents to go beyond passive observation, actively engaging with the environment through experimentation and feedback. Designing models that can perform meaningful interventions and adapt effectively based on limited examples presents additional challenges.

\setstretch{0.997}

To address these challenges, we introduce \acf{nff}, a physical reasoning framework building upon \acf{node} for efficient interactive learning and reasoning. At its core, \ac{nff} employs a neural network to learn dynamic latent force fields from external interventions and object interactions. These predicted forces are then integrated through an \ac{ode} solver to compute explicit physical variables such as velocity and displacement, producing interpretable results that align with established physical principles. 

Our framework offers three advantages. First, by representing physical interactions in low-dimensional force fields, \ac{nff} can rapidly learn fundamental physical concepts from just \textit{a few training examples}. Second, due to the \ac{ode}-grounded dynamic graph, \ac{nff} can effectively \textit{generalize to \ac{ood} scenarios}. Third, the integration of forces through an \ac{ode} solver enables \textit{fine-grained physical interactions}, supporting precise modeling of collisions, gravity effects, and real-time planning.

% Our framework offers three advantages. First, by representing physics through dynamic force fields, \ac{nff} captures essential interactions---including gravity, friction, collision, rotation, and spring forces---in a \textit{unified and concise framework}. Second, the integration of forces through an \ac{ode} solver enables \textit{fine-grained physical interactions}, supporting precise modeling of collisions, gravity effects, and real-time decision-making. Third, \ac{nff} learns these generalized representations \textit{solely from observations}, requiring \textbf{no additional priors} about the underlying physical variables.

% To answer the quest, we introduce \acf{nff}, a physical reasoning framework built on \acf{node} to facilitate efficient interactive learning and reasoning in novel physical environments. The core idea behind \ac{nff} is to leverage a neural network to learn a dynamic latent force field from external interventions and object interactions. The predicted latent forces are integrated through an \acf{ode} solver to obtain explicit physical variables like velocity and displacement, producing interpretable results that align with established physical principles. \ac{nff} brings multiple advantages: First, by adopting a dynamic force field as its representation, essential physical interactions can be captured, including gravity, friction, collision, rotation, and spring, in a \textbf{unified and concise framework}. Secondly, by integrating these forces through an \ac{ode} solver, \ac{nff} can derive trajectories in a continuous manner, supporting \textbf{fine-grained physical interactions} such as collisions, gravity forces, and real-time decision-making in physical reasoning tasks. Additionally, \ac{nff} learns the generalized representation \textbf{only from observed trajectories} without other assumptions or priors about the latent physical variables, such as their range of values or forms.

We validate our approach on two challenging physical reasoning benchmarks: \benchmark \citep{li2023phyre} and N-body problems \citep{newton1833philosophiae}. These tasks feature complex dynamics ranging from short-range forces (collision and sliding) to long-range forces (gravity), providing a comprehensive test of our framework's capabilities. Our experiments demonstrate that \ac{nff} not only learns dynamics efficiently by abstracting physical interactions into force fields but also achieves strong generalization in both within-scenario and cross-scenario settings. Moreover, the framework's physics-based representation enables effective forward and backward planning in goal-directed tasks, consistently outperforming existing approaches such as \ac{in} and transformer-based methods.
% We test our framework on \benchmark \citep{li2023phyre} and N-body problems, two challenging physical reasoning tasks that have complex dynamics including short-range forces like collision and sliding and long-range forces like gravity. The experiments on both within-scenario and cross-scenario generalization demonstrate that the framework not only learns the dynamics quickly by abstracting the physical interactions into dynamic force fields but also generalizes well on novel scenarios. Furthermore, the framework supports efficient planning of goal-driven physical reasoning tasks through forward and backward planning. The results show that the proposed framework outperforms previous dynamic modeling baselines such as \ac{in} and transformer-based methods.

\section{Related work}

\textbf{Physical reasoning\quad{}}
Research in physical reasoning has progressed along two main trajectories: passive observation and interactive platforms. The passive observation approach, exemplified by the \ac{voe} paradigm \citep{spelke1992origins}, evaluates physical understanding by measuring agents' ability to detect violations of intuitive physics principles \citep{ee1987object,hespos2001infants,dai2023x}. While this approach has provided valuable insights into basic physical comprehension, it is limited by its inability to assess active interventions and complex reasoning.

To enable more comprehensive evaluation, interactive platforms such as PHYRE \citep{bakhtin2019phyre}, the virtual tools game \citep{allen2020rapid}, and \benchmark \citep{li2023phyre} have emerged. These environments require agents to actively manipulate objects to achieve specific goals, testing not only prediction capabilities but also planning and reasoning skills. However, existing approaches in these platforms often struggle with generalization across diverse scenarios, particularly in few-shot settings where limited training data is available \citep{qi2021learning,li2023phyre}.

Current physical reasoning models face two primary challenges: the need for extensive training data and limited cross-scenario transferability. While some methods achieve strong performance within specific scenarios \citep{allen2020rapid}, they often fail to generalize their understanding to novel situations, falling short of human-level reasoning capabilities \citep{kang2024far}. Our work addresses these limitations by introducing a framework that unifies passive observation and interactive learning through dynamic \textbf{force fields}. The \ac{nff} approach enables few-shot learning of physical principles while supporting active reasoning through its interpretable force-based representation, facilitating both accurate prediction and effective intervention planning across diverse physical scenarios.

% Physical reasoning research has evolved significantly over the years, with studies spanning passive observation and interactive platforms. Passive observation frameworks, such as those leveraging the \ac{voe} paradigm \citep{spelke1992origins}, assess an agent's ability to predict physical outcomes by detecting unexpected events that violate intuitive physics principles \citep{ee1987object,hespos2001infants,dai2023x}. These methods provide insights into an agent's physical understanding through visual scenarios but lack the capacity to evaluate interventions. On the other hand, interactive platforms like PHYRE \citep{bakhtin2019phyre}, the virtual tools game \citep{allen2020rapid}, and \benchmark \citep{li2023phyre} address this limitation by presenting physical puzzles that require agents to interact with their environment to accomplish specific objectives. Such environments enable more comprehensive evaluation, encompassing not only prediction capabilities but also planning and reasoning skills \citep{allen2020rapid}. Nevertheless, challenges persist in generalizing to diverse scenarios and integrating effective representation into physical models to reach human-level reasoning \citep{qi2021learning,li2023phyre,kang2024far}.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\linewidth]{nff/nff}
    \caption{\textbf{Comparison between traditional interaction modeling and \ac{nff}.} (a) Traditional methods encode physical interactions as high-dimensional latent vectors and predict future states through learned transitions between these vectors. This approach requires extensive training data and often leads to overfitting, limiting generalization to novel scenarios. (b) Our \ac{nff} framework represents interactions as learnable force fields predicted from the dynamic object graphs, which are integrated through a differentiable \ac{ode} solver to predict trajectories. \ac{nff} enables few-shot learning of various interaction types from limited interventions while maintaining strong generalization capabilities. The framework consists of four key operators: \textbf{E} (encoder network for processing physical scenes), \textbf{D} (decoder network for state reconstruction), \textbf{F} (force field predictor), and \textbf{$\int$} (numerical integrator for computing trajectories).}
    % \caption{\textbf{Comparison between traditional interaction modeling and \ac{nff}.} (a) Traditional modeling methods, encoding object interactions in high-dimension latent vectors and transitioning them into future latent states, require a large amount of data to train and suffer from overfitting. (b) \ac{nff} learns interaction in the low-dimension representation of force fields, grounded in physics through a differentiable \ac{ode} solver. The \ac{nff} models can inverse the latent forces of various interaction types from a few interventions, and generalize well to \ac{ood} scenarios. The \textbf{E}, \textbf{D}, \textbf{F}, and \textbf{$\int$} operators indicate the encoder network, decoder network, force field predictor, and integrator, respectively.}
    \label{fig:overview}
\end{figure*}

\textbf{Dynamic prediction\quad{}}
The prediction of physical dynamics, fundamental to intuitive physics, has evolved along two methodological branches: discrete and continuous-time approaches. Discrete methods typically combine recurrent architectures with GNNs \citep{battaglia2016interaction,qi2021learning} or transformer modules \citep{wu2022slotformer} for modeling object interactions, while leveraging convolutional operators for processing pixel-based information \citep{shi2015convolutional,wang2022predrnn}. Despite their flexibility in handling various interaction types, these methods often struggle with two key limitations: difficulty in extracting robust physical representations and susceptibility to error accumulation over extended time horizons.

Continuous-time methods address these temporal consistency issues by incorporating physical inductive biases via explicit modeling of state derivatives within dynamical systems \citep{chen2018neural,greydanus2019hamiltonian,zhong2020symplectic,cranmer2020lagrangian,norcliffe2020second}. While this approach improves long-term prediction stability, current systems typically assume energy-conservative systems with simplified dynamics. More importantly, these methods face significant challenges in few-shot learning scenarios and struggle with cross-scenario generalization \citep{chen2020learning}, often requiring specific physical priors and grammars to achieve meaningful transfer \citep{xu2021bayesian}.

Our work advances continuous-time methods by introducing a more general physical representation framework via learnable \textbf{force fields}. This approach enables robust cross-scenario generalization while handling complex non-conservative energy systems. By combining the stability advantages of continuous-time modeling with flexible force field representations, \ac{nff} achieves both accurate long-term predictions and strong generalization capabilities without requiring explicit physical priors.

% Predicting future physical dynamics is a critical component of intuitive physics, essential for supporting downstream tasks such as planning and reasoning. Existing approaches can be broadly categorized into discrete and continuous-time methods. Discrete methods often employ recurrent architectures combined with GNNs \citep{battaglia2016interaction,qi2021learning} or transformer modules \citep{wu2022slotformer} to model object interactions, while convolutional operators are used to process pixel-based information \citep{shi2015convolutional,wang2022predrnn}. However, these methods frequently struggle with extracting robust representation and are prone to error accumulation over extended time horizons. In contrast, continuous-time methods incorporate physical inductive biases by explicitly modeling state derivatives within dynamical systems \citep{chen2018neural,greydanus2019hamiltonian,zhong2020symplectic,cranmer2020lagrangian,norcliffe2020second}, thereby improving long-term physical consistency. Despite these advantages, most studies assume energy-conservative systems with toy dynamics, limiting their applicability. Furthermore, few-shot learning and generalization across different system scenarios remains challenging \citep{chen2020learning} unless specific priors and grammars are given \citep{xu2021bayesian}. To address these limitations, we aim to extend continuous-time methods by introducing more general physical representation that enhances cross-scenario generalization, even in complex non-conservative energy systems.

\setstretch{1}

\section{Method}

\subsection{The \acf{nff} representation}

Traditional approaches to modeling physical interactions typically rely on implicit representations through hidden vectors to describe object interactions. These methods use neural networks to learn state transition functions that map current scene features to future states. However, this purely data-driven approach cannot guarantee physically grounded representations, leading to poor generalization despite intensive training. We introduce \ac{nff}, which addresses these limitations by learning physics-grounded, generalizable representations through explicit force field modeling; see \cref{fig:overview} for a comparison.
% Traditional methods to model interaction typically learn implicit representation realized as hidden vectors to describe how objects affect each other. Specifically, from deep features of the scene and potential actions, these methods train another neural-network based state transition function that predicts the deep features of the future state. Such an architecture depends entirely on the data it has been fed and cannot ensure that the learned hidden state vectors are grounded in physics, resulting in inferior generalization results despite of intensive training. In this section, we introduce how the proposed \ac{nff} learns physics-grounded and generalizable representation of interactions by modeling the force fields. See \cref{fig:overview} for a comparison with \ac{nff}.

\textbf{Prediction force field\quad{}}
The core of \ac{nff} is built on the physical concept of a force field---a vector field that determines the force experienced by any query object based on its state $\mathbf{z}^q$. For a scene with $N$ objects, we model the force field $\mathbf{F}(\cdot)$ at time $t$ using a neural network operating on a relation graph $\mathcal{G}$. The graph contains object nodes $V = \{\mathbf{z}^{0}(t), \mathbf{z}^{1}(t), ..., \mathbf{z}^{N-1}(t)\}$. Following neural operator methods \citep{lu2021learning} and graph neural models \citep{battaglia2018relational}, we formulate the force field function as:
% \ac{nff} builds on the physical concept of ``force field'', a vector field where the force a query object experiences can be directly read out based on its state $\mathbf{z}^q$. Suppose there are $N$ objects in the scene, we model the force field $\mathbf{F}(\cdot)$ at time $t$ with a neural network based on a relation graph $\mathcal{G}$ for all object nodes $V = \{\mathbf{z}^{0}(t), \mathbf{z}^{1}(t), ..., \mathbf{z}^{N-1}(t)\}$. Following neural operator methods \citep{lu2021learning} and graph neural models \citep{battaglia2018relational}, we formulate the force field function as the following,
\begin{equation}\label{eq:sum_force}
   \mathbf{F}(\mathbf{z}^q(t)) = \sum_{i \in \mathcal{G}(q)} \mathbf{W} \left( f_{\theta}(\mathbf{z}^{i}(t)) \cdot f_{\phi}(\mathbf{z}^q(t)) \right) + \mathbf{b},
\end{equation}
where $\mathcal{G}(q)$ represents the neighbors of query $q$, $f_{\theta}$ and $f_{\phi}$ are neural networks with parameters $\theta$ and $\phi$, and $\mathbf{W} \in \mathbb{R}^{d_{\text{hidden}} \times d_{\text{force}}}, \mathbf{b} \in \mathbb{R}^{d_{\text{force}}}$ map hidden features to low-dimensional forces. The state vector $\mathbf{z}$ incorporates zero-order (position, angle) and first-order (velocity, angular velocity) states. This representation naturally handles various physical interactions including collision, friction, spring forces, and rotation.
% where we denote the neighbors of the query $q$ as $\mathcal{G}(q)$, $f_{\theta}$ and $f_{\phi}$ are two neural networks parameterized by $\theta$ and $\phi$, respectively, and $\mathbf{W} \in \mathbb{R}^{d_{\text{hidden}} \times d_{\text{force}}}, \quad \mathbf{b} \in \mathbb{R}^{d_{\text{force}}}$ are the weights and biases of a linear layer to map the hidden feature to forces. We use zero-order states (\eg displacement and angle) and first-order states (\eg velocity and angular velocity) to represent $\mathbf{z}$. The graph can be built by connecting objects with direct contact or fully-connected for astrophysics. The representation of the force field can be applied to any type of \ac{ode} dynamic systems involving collision, falling, friction, spring, and rotation. 

\textbf{Computing trajectory with \ac{ode}\quad{}}
Rather than relying on neural decoders, \ac{nff} employs a second-order \ac{ode} integrator to compute object trajectories from the learned force field. This approach ensures physically consistent trajectories governed by fundamental principles. The dynamic change of motion for a query state follow:
% With a learned force field, we can use a second-order \ac{ode} integrator to obtain the trajectories of objects of interest, instead of relying on other neural networks for decoding. Such a process can ensure that the trajectories are grounded in more concise and inherent physical principles. The dynamic change of motion for the query state can be represented as
\begin{equation}
    \frac{d^2x^q(t)}{dt^2} =  \frac{dv^q(t)}{dt} \propto \mathbf{F}(\mathbf{z}^q(t)).
\end{equation}
While object mass theoretically affects acceleration, these mass constants are absorbed into the learned $F(\cdot)$.
% While in theory, the change of speed is also proportional to the mass of the object, in practice, the mass constant of each object can be absorbed into the learning process of $F(\cdot)$.

\textbf{Solving \acp{ode}\quad{}}
We solve the \ac{ode} system using numerical integration methods such as Runge-Kutta:
% The \ac{ode} system can be integrated using numerical methods such as the Runge-Kutta method,
\begin{equation}
    \mathbf{z}^q(t) = \text{ODESolve}\left(\mathbf{z}^q(0), \mathbf{F}, 0, t\right),
    \label{eq:solver}
\end{equation}
\begin{equation}
    \begin{dcases}
        \mathbf{x}(t) = \mathbf{x}(0) + \int_{0}^{t} \mathbf{v}(t) \, dt, \\
        \mathbf{v}(t) = \mathbf{v}(0) + \int_{0}^{t} \mathbf{F}(\mathbf{z}^q(t)) \, dt,
    \end{dcases}
    \label{eq:integration}
\end{equation}

The \ac{nff} framework offers three key advantages over existing approaches. First, it enables few-shot learning of force fields from minimal examples---even single trajectories---through its compact, physically-grounded representation $\mathbf{F}(\mathbf{z}^q(t))$. Second, by representing interactions as composable force fields, \ac{nff} naturally generalizes to novel scenarios with varying object configurations, interaction types, and time horizons. As shown in \cref{eq:sum_force}, this compositionality enables transfer of learned force patterns across physical scenarios through simple force summation. Third, the high-precision integration decoder, formulated in \cref{eq:solver,eq:integration}, enables both fine-grained modeling of continuous-time interactions and efficient optimization for planning tasks through its invertible information flow. This precision supports various applications, from determining initial conditions for desired outcomes to designing targeted force fields for specific behaviors. The effectiveness of these three components—low-dimensional representation, \ac{ode} grounding, and precise integration—is systematically validated through ablation studies in \cref{sec:ablation}.
% Third, the framework's versatility extends beyond conservative systems to handle any \ac{ode}-governed dynamics, including dissipative forces and complex multi-body interactions. Fourth, \ac{nff}'s fully differentiable architecture with invertible information flow enables efficient optimization for planning tasks, such as determining initial conditions to achieve desired outcomes or designing force fields for specific behavioral objectives.

% The \ac{nff} approach offers several key advantages compared to previous works.
% First, \ac{nff} can inverse the underlying force field from a few examples, even from a single trajectory, which is made possible because the learned representation of object interactions $\mathbf{F}(\mathbf{z}^q(t))$ is highly compact and low-dimensional.
% Second, \ac{nff} generalizes well to long-horizon predictions and cross-scenario scenarios. It can be transferred across various compositions, object configurations, and time durations by simply summing the forces.
% Additionally, the \ac{nff} framework is versatile and can handle a wide range of interactions that adhere to \ac{ode} dynamics. Moreover, it is fully differentiable with invertible information flow, making it particularly well-suited for planning tasks, such as determining initial conditions to achieve a desired final goal.

\textbf{Training \ac{nff}\quad{}}
The framework employs autoregressive prediction, using previously predicted states to generate current states. Network optimization minimizes the \ac{mse} loss between predictions and ground truth. To promote learning of local, generalizable dynamics rather than global patterns, we segment long trajectories into smaller units during training. Our experiments demonstrate that this approach significantly improves convergence.
% \ac{nff} predicts future trajectories in an autoregressive manner, taking the last predicted state to predict the current state. The networks in \ac{nff} are optimized by minimizing the \ac{mse} loss between the prediction and the ground truth. In experiments, we split long trajectories into multiple smaller segments to help the model learn local but generalizable dynamics instead of just fitting patterns. Such a training strategy makes convergence easier as shown in our experiments. 

\begin{figure}[t!]
    \centering
    \begin{subfigure}[b]{0.5\linewidth}
        \includegraphics[width=\linewidth]{learned_force_field/more_step_hole}
        \caption{\benchmark sim {\tiny \citep{li2023phyre}}}
        \label{fig:iphyre}
    \end{subfigure}%
    \hfill%
    \begin{subfigure}[b]{0.5\linewidth}
        \includegraphics[width=\linewidth]{learned_force_field/3body}
        \caption{N-body sim {\tiny \citep{rein2012rebound}}}
        \label{fig:3body}
    \end{subfigure}%
    \\%
    \begin{subfigure}[b]{\linewidth}
        \centering
        \begin{subfigure}[b]{0.25\linewidth}
            \centering
            \includegraphics[width=\linewidth,trim=0 1cm 0 0,clip]{learned_force_field/falling}
            \subcaption*{Falling}
        \end{subfigure}%
        \begin{subfigure}[b]{0.25\linewidth}
            \centering
            \includegraphics[width=\linewidth,trim=0 1cm 0 0,clip]{learned_force_field/sliding}
            \subcaption*{Sliding}
        \end{subfigure}%
        \begin{subfigure}[b]{0.25\linewidth}
            \centering
            \includegraphics[width=\linewidth,trim=0 1cm 0 0,clip]{learned_force_field/collision}
            \subcaption*{Collision}
        \end{subfigure}%
        \begin{subfigure}[b]{0.25\linewidth}
            \centering
            \includegraphics[width=\linewidth,trim=0 1cm 0 0,clip]{learned_force_field/spring}
            \subcaption*{Spring}
        \end{subfigure}%
        \caption{Visualization of learned physical concepts}
        \label{fig:concepts}
    \end{subfigure}%
    \\%
    \begin{subfigure}[b]{0.5\linewidth}
        \includegraphics[width=\linewidth]{learned_force_field/nbody_force_field_gt}
        \caption{\fontsize{8}{8}\selectfont{}Gravitational field ground truth}
        \label{fig:nbody_force_field_gt}
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\linewidth}
        \includegraphics[width=\linewidth]{learned_force_field/nbody_force_field}
        \caption{\fontsize{8}{8}\selectfont{}Learned gravitational field}
        \label{fig:nbody_force_field}
    \end{subfigure}%
    \caption{\textbf{Visualization of learned physical dynamics and force fields.} (a) \benchmark simulation environment demonstrating complex rigid body interactions. (b) N-body gravitational simulation showing orbital trajectories. (c) Examples of learned physical concepts demonstrated through trajectory predictions: falling under gravity, sliding with friction, collision with momentum transfer, and spring-like elastic interactions. (d-e) Comparison between ground truth and learned gravitational field distributions shows accurate force field reconstruction. Our \acs{nff} successfully captures these fundamental physical behaviors from few-shot learning.}
    \label{fig:ff}
\end{figure}

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{exp_prediction_qualitative/initial}
        \caption{Initial configuration}
        \label{fig:initial}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{exp_prediction_qualitative/true}
        \caption{Ground truth trajectory}
        \label{fig:true}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{exp_prediction_qualitative/nff}
        \caption{Our \ac{nff} prediction}
        \label{fig:nff}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{exp_prediction_qualitative/slotformer}
        \caption{SlotFormer {\tiny\citep{wu2022slotformer}}}
        \label{fig:slotformer}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{exp_prediction_qualitative/in}
        \caption{\acs{in} {\tiny\citep{battaglia2016interaction}}}
        \label{fig:in}
    \end{subfigure}%
    \caption{\textbf{Trajectory predictions on unseen scenarios after few-shot learning.} We compare model predictions across four physical scenarios: (i) A seesaw mechanism launching a ball over a wall, demonstrating complex contact dynamics and energy transfer, (ii) A path-building puzzle where white blocks can be eliminated during interaction, requiring the ball to roll across gaps, (iii) A dual-comet gravitational slingshot shows orbital deflection around a massive celestial body, and (iv) An eight-body gravitational system emulating solar system exhibits complex orbital dynamics around a central mass (\ie, Sun). Light trails indicate object trajectories over time. Notably, our \acs{nff} predictions closely match the ground truth behaviors across these diverse scenarios, from rigid body interactions to gravitational dynamics. Additional visualizations are provided in \cref{sec:supp:vis}.}
    % \caption{\textbf{Predicted trajectories on unseen scenarios after few-shot learning.} The first column presents the initial setups, while the subsequent columns display the ground truth trajectories alongside the predictions from different models. In the first row, a seesaw is used to lift the ball out of a wall, whereas the second row showcases filling a path to allow the ball to roll across the ground. Note that some of the white blocks will be eliminated during the process. The third row illustrates two comets passing by a massive celestial body, while the fourth row depicts eight bodies orbiting a massive celestial body. See more visualization in \cref{sec:supp:vis}.}
    \label{fig:pred}
\end{figure*}

\subsection{Interactive planning}

\ac{nff} extends beyond forward prediction to enable mental simulation for planning tasks. Given goal-directed scenarios, \ac{nff} can serve as a learned simulator to either search for action sequences that achieve the desired goal state through forward simulation, or optimize initial conditions and system parameters through backward computation.
% Beyond forward prediction of physical dynamics, \ac{nff} also provides a useful tool of mental simulation for planning. For goal-directed planning problems, we can use an \ac{nff} model as a learned simulator to either filter the action sequences that can lead to the goal in a forward manner or inversely derive the initial condition in a backward manner.

\textbf{Forward planning\quad{}}
For physical reasoning tasks requiring specific action sequences, we extend the \ac{nff} framework to incorporate action effects by including action features in $f_\theta$. Through forward simulation with the \ac{nff} model, we sample multiple action sequences $A = \{a_0,..., a_T\}$ and optimize according to evaluation metrics $R$:
% To find an action sequence that leads to the goal of a physical reasoning task, we can adapt the \ac{nff} form to also include the effects of actions. In our experiments, we include action features in $f_\theta$. Using \ac{nff} as a mental simulation model, we sample multiple action sequences $A = \{a_0,..., a_T\}$ and select the best one according to evaluation rubrics $R$. Formally:
\begin{equation}
    A^\star = \underset{A}{\text{argmax}} R(\mathbf{F}, A).
\end{equation}
The optimal sequence $A^\star$ can then be executed in the physical environment. While the forward simulation may initially deviate from actual observations, \ac{nff}'s physics-based design enables efficient adaptation through new experimental data. This capability for rapid model refinement mirrors human reasoning \citep{allen2020rapid} and overcomes the catastrophic forgetting challenges faced by pure neural network approaches \citep{dohare2024loss}. When executed trajectories deviate from the desired goal state, the new state sequences can be directly incorporated into model optimization through the \ac{mse} loss, following the same training procedure used in the initial learning phase.
% The selected sequence can then be executed in the real physical environment. In practice, the mental model simulation from \ac{nff} may deviate from the actual observation and it's crucial to update the model based on the newly collected results. This is a remarkable capability of human reasoning \citep{allen2020rapid} but challenging for previous pure neural-network-based methods due to catastrophic forgetting \citep{dohare2024loss}. However, \ac{nff} naturally supports learning from a few trajectories and can easily incorporate the new trial results thanks to its design following physical principles. Specifically, if the executed trajectory does not lead to the final goal position, the new sequence of states can be used to further update the model via the \ac{mse} loss as in training.

\textbf{Backward planning\quad{}}
By inverting the \ac{ode} integrator, \ac{nff} enables the computation of initial conditions given a desired goal state. Through backward integration, the initial conditions can be determined analytically:
% Taking the inverse of \ac{ode} integrator, we can use \ac{nff} to solve the initial conditions given a targeted goal state. Via backward planning, the initial conditions can be easily derived through one round of integration
\begin{equation}
    \begin{dcases}
        \mathbf{x}(0) = \mathbf{x}(t) + \int_{t}^{0} \mathbf{v}(t) \, dt, \\
        \mathbf{v}(0) = \mathbf{v}(t) + \int_{t}^{0} \mathbf{F}(\mathbf{z}^q(t)) \, dt.
    \end{dcases}
\end{equation}
The invertible nature of the \ac{nff} formulation makes this backward computation particularly efficient. By performing temporal integration in reverse, we obtain initial conditions consistent with both the goal state and the learned physical dynamics encoded in the \ac{nff} model.
% This approach leverages the invertible nature of the \ac{ode}-based \ac{nff}, allowing for efficient planning from the goal state back to the initial conditions. By integrating the dynamics backward in time, the method ensures that the computed initial conditions and states are consistent with the physical model encoded in \ac{nff}.

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[height=4cm,width=\linewidth]{force_response/force_response_qy}
        \caption{Support interaction}
        \label{fig:ball_y}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[height=4cm,width=\linewidth]{force_response/force_response_itheta}
        \caption{Platform orientation}
        \label{fig:block_angle}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[height=4cm,width=\linewidth]{force_response/force_response_qvy}
        \caption{Impact dynamics}
        \label{fig:ball_vy}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[height=4cm,width=\linewidth]{force_response/force_response_spring_qx}
        \caption{Spring mechanics}
        \label{fig:spring_x}
    \end{subfigure}%
    \caption{\textbf{Force response analysis under controlled state variations.} Each plot shows the predicted force components (Fx in blue, Fy in orange) from our trained \ac{nff} model, measured in normalized units against different state parameters. The subplots systematically analyze: (a) support forces as a function of ball height, showing characteristic contact response when the ball meets the platform, (b) force decomposition as the platform rotates from horizontal ($0^\degree$) to vertical ($90^\degree$), (c) impact forces scaling with the ball's downward velocity, and (d) spring forces varying with horizontal displacement from the equilibrium position. Each plot varies one parameter while keeping all other scene variables constant, demonstrating \acs{nff}'s learned physical principles, including contact mechanics, geometric reasoning, impact dynamics, and harmonic motion.}
    % \caption{\textbf{The force response under different state conditions while holding other state variables constant.} The diagram illustrates the force response in both the x and y directions from the trained \ac{nff} at specific states during the interaction of a ball with a block. Four key variables that significantly affect the dynamics are altered: (a) the ball's falling y-position, (b) the ball's y-direction velocity, (c) the platform's pose, and (d) the ball's x-position in the spring system. At the same time, other state variables in the scene remain unchanged. The force responses show that the \ac{nff} intuitively understands the following: (a) the platform supports the ball if it falls onto it, (b) the magnitude of the y-direction force decreases and the x-direction force increases as the block rotates from horizontal to vertical, (c) the collision force increases with larger falling velocities, and (d) the x-direction force of the spring exhibits central symmetry.} 
    \label{fig:force_response}
\end{figure*}

\section{Experiments}

\subsection{Environments and datasets}

We evaluate our approach on two physical reasoning tasks: \benchmark and N-body dynamics. Each task is evaluated across three distinct settings: within-scenario prediction, cross-scenario prediction, and planning. Detailed environment and dataset configurations are provided in \cref{sec:supp:data}.
% We conduct experiments on two physical reasoning tasks, \benchmark and N-body problems. We divide each task into three splits for evaluation: within-scenario prediction, cross-scenario prediction, and planning.

\textbf{\benchmark\quad{}}
\benchmark \citep{li2023phyre} presents a suite of complex physical reasoning puzzles requiring multi-step interventions. The environment incorporates diverse physical interactions including gravity, collision, friction, rotation, spring dynamics, and pendulum motion. It challenges AI agents to solve puzzles with minimal environmental interactions while generalizing to unseen scenarios. For within-scenario prediction, we evaluate on 10 training games that share similar scenarios but require different solutions. The cross-scenario prediction setting extends to 30 novel games featuring noise, compositional elements, and multi-ball scenarios, with varying object properties such as block lengths, ball sizes, and object positions. In the planning setting, models must generate optimal action sequences to successfully complete each game.
% \benchmark \citep{li2023phyre} is a challenging physical reasoning benchmark containing many physical puzzles requiring multiple-step interventions to solve. The environment consists of multiple dynamic interactions including falling, collision, friction, rotation, spring, and pendulum. It challenges AI agents to solve these problems with a limited number of interactions with the environment and generalize to previously unseen cross-scenario tasks. The within-scenario prediction setting contains the same 10 games in the training set with slightly different solutions. The cross-scenario prediction setting contains 30 unseen games including noisy games, compositional games, and multi-ball games that feature different overall scenarios and object properties such as the length of the block, size of the balls, and positions of the objects. In the planning split, the models are tasked to generate the best action sequence to finish the game.

\textbf{N-body\quad}
The N-body problem \citep{newton1833philosophiae} tests trajectory prediction for small comets orbiting a massive central planet. Using REBOUND simulator \citep{rein2012rebound}, we generate dynamics data by randomly sampling orbital parameters including radii, angles, and masses. This task evaluates the model's ability to infer gravitational laws from limited observations. The within-scenario prediction setting introduces novel initial conditions and masses, focusing on systems with 1-2 orbiting bodies tracked over 50 timesteps. Cross-scenario prediction significantly increases complexity by introducing systems with 8 orbiting bodies tracked over 100 timesteps. The planning setting challenges models to optimize initial conditions that will evolve to specified target states after 50 timesteps.
% In the N-body problem \citep{newton1833philosophiae}, the model is tasked with predicting the trajectories of small comets orbiting a massive central planet. We use REBOUND to simulate the dynamics of the planet and comets by randomly sampling the radii, angles, and masses. Our objective is to assess whether the model can infer the law of gravity with limited observations. The training data contains 1 or 2 small bodies moving across 50 steps. The within-scenario scenario contains unseen initial positions and masses. The cross-scenario scenario involves systems with 8 orbiting bodies moving across 100 steps. In the planning problem, the models are tasked to find the optimal initial conditions to make the bodies reach the specified state after 50 steps.

% The details of dataset configurations are illustrated in \cref{sec:supp:data}.

\subsection{Learning force fields from a few examples}

We qualitatively evaluate \ac{nff}'s ability to learn force fields \textbf{from limited training data}; training implementation details are provided in \cref{sec:supp:training}. For \benchmark, we train \ac{nff} on just 10 basic games with 10 trajectory samples each. From these 100 trajectories, the model successfully learns fundamental physical concepts including gravity, support, sliding, collision, friction, and spring dynamics, representing them through unified force fields (\cref{fig:concepts}). To verify that \ac{nff} learns generalizable physical principles, we examine force responses to varied ball-block interactions under controlled conditions. \Cref{fig:force_response} shows our systematic evaluation where we independently vary individual scene parameters such as position, velocity, and angle while holding others constant, demonstrating \ac{nff}'s accurate force response modeling.
% In this section, we qualitatively evaluate whether \ac{nff} can learn the force fields from a limited number of examples. In \benchmark, we train the \ac{nff} on 10 basic games with 10 trajectory samples for each. After observing these 100 trajectories, \ac{nff} can learn basic physical concepts studied in intuitive physics such as gravity, support, sliding, collision, friction, and spring, represented in the unified force fields (\cref{fig:ff}). To examine whether the \ac{nff} learns general physical principles, we further evaluate how the force will response to different interactions of a ball with a block under different conditions, such as positions, velocities, and angles. In \cref{fig:force_response}, we perform controlled experiments, holding other variables constant and only adjusting one state of the scene. The results demonstrate that \ac{nff} can well capture the change of force.

For the N-body system, we train \ac{nff} using 200 randomly sampled trajectories from 2-body and 3-body dynamics. As shown in \cref{fig:nbody_force_field}, the model successfully learns to capture the inverse gravitational field, correctly modeling the distance-dependent centripetal forces governing the mutual attraction between bodies.
% In the N-body task, the \ac{nff} is trained using 200 randomly sampled trajectories derived from 2-body and 3-body dynamics. The model successfully learns to reverse the gravitational field, accurately modeling the centripetal force field that governs the mutual attraction of the bodies, with the force diminishing in distance, as depicted in \cref{fig:ff}.

% The training details are illustrated in \cref{sec:supp:training}.

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[height=0.5cm]{exp_prediction_quantitative/legend}
    \end{subfigure}%
    \\%
    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{exp_prediction_quantitative/iphyre}
        \caption{\benchmark}
    \end{subfigure}%
    \\%
    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{exp_prediction_quantitative/nbody}
        \caption{N-body}
    \end{subfigure}%
    \caption{\textbf{\acs{nff} outperforms other baselines in prediction tasks.} Performance comparison between \acs{in} \citep{battaglia2016interaction}, SlotFormer \citep{wu2022slotformer}, and our \acs{nff} on (a) \benchmark and (b) N-body tasks. Box plots display median, quartiles, and outliers, with lower values $\downarrow$ better for error metrics (\acs{rmse}, \acs{fpe}, \acs{pce}) and higher values $\uparrow$ better for correlation (R). Our \ac{nff} consistently achieves lower errors and higher correlations across both simulation environments, particularly in challenging cross-scenario generalization.}
    % \caption{\textbf{\ac{nff} outperforms other baselines in prediction tasks}. The first and second rows show the results on \benchmark and N-body tasks, respectively. The evaluation metrics include \acs{rmse}, \acs{fpe}, \acs{pce}, and \acs{r} on within-scenario and cross-scenario scenarios. $\uparrow$ and $\downarrow$ indicate whether higher or lower values are better.}
    \label{fig:comp_pred}
\end{figure*}

\subsection{Prediction on unseen scenarios}

We evaluate the learned force fields' predictive accuracy in both within-scenario and cross-scenario settings. For \benchmark, we test against 20 ground truth trajectories per game, while for N-body systems, we evaluate using 200 novel initial conditions. We compare our results against established interaction modeling methods: \ac{in} \citep{battaglia2016interaction} and SlotFormer \citep{wu2022slotformer}.
% After learning the force fields, we evaluate how accurate the learned force fields are when predicting in both within-scenario and cross-scenario settings. For \benchmark, we select 20 ground truth trajectories for each of the games to evaluate the prediction performance of the trained models. In N-body, we select 200 unseen initial conditions to evaluate. We compare the prediction error with previous classic and state-of-the-art interaction modeling methods of \ac{in} \citep{battaglia2016interaction} and SlotFormer \citep{wu2022slotformer}.

\textbf{Evaluation metrics\quad{}}
We employ multiple complementary metrics to assess prediction quality. Beyond standard \ac{rmse}, we introduce \ac{fpe} (final position error) and \ac{pce} (position change error) for detailed performance analysis. \ac{fpe} quantifies terminal position accuracy, while \ac{pce} evaluates the model's ability to capture motion dynamics. Additionally, \ac{r} measures trajectory shape alignment independent of speed variations. This comprehensive metric suite enables thorough evaluation across temporal and spatial dimensions. Detailed definitions are provided in \cref{sec:supp:metrics}.
% We evaluate the performance of the prediction model using a variety of metrics that assess different aspects of the model's accuracy and robustness. While \ac{rmse} provides direct measures of error magnitude, we also introduce \ac{fpe} and \ac{pce} to take a detailed look at performance. Specifically, \ac{fpe} measures the difference between the predicted final position and the observed final position and \ac{pce} the rate of change in position. Finally, \ac{r} offers insight into the overall shape alignment of the predicted trajectory with the actual movement, regardless of speed. By using a combination of these metrics, we gain a more holistic view of how well the model performs in predicting physical trajectories across time. See details in \cref{sec:supp:metrics}. 

\textbf{Results\quad{}}
As shown in \cref{fig:pred}, \ac{nff} generates physically plausible trajectories that closely match ground truth behavior, even in previously unseen scenarios. Quantitative comparisons in \cref{fig:comp_pred} demonstrate \ac{nff}'s superior performance across all metrics for both \benchmark and N-body tasks, with particularly strong results in cross-scenario generalization. While SlotFormer exhibits overfitting tendencies that limit its cross-scenario performance (analyzed further in \cref{sec:supp:overfit}), \ac{nff}'s ability to learn generalizable physical principles from limited training data enables robust prediction across diverse scenarios.
% The predicted trajectories in \cref{fig:pred} demonstrate that \ac{nff} aligns well with ground-truth physical behavior in even the unseen scenarios. The quantitative results in \cref{fig:comp_pred} shows that \ac{nff} surpasses the previous methods on both \benchmark and N-body tasks across various metrics, especially on the cross-scenario setting. SlotFormer is prone to overfitting the training data and fails to generalize to the cross-scenario setting; see more analysis in \cref{sec:supp:overfit}. The results, together, indicate \ac{nff} can learn core physical principles that generalize well after learning from limited samples.

\subsection{Planning on unseen scenarios}

The trained \ac{nff} model can generate plans for novel tasks after learning from limited demonstrations. Unlike prediction tasks that evaluate trajectory accuracy, planning tasks require generating action sequences to achieve specific goals.

\textbf{\benchmark planning\quad{}}
We implement a 5-round interactive learning protocol. \ac{nff} acts as a mental simulator to evaluate 500 randomly sampled action candidates, selecting the optimal sequence for physical execution. After each execution, the model updates its parameters based on observed outcomes, refining its physics understanding. This updated model then guides subsequent action proposals.

% After learning from a limited set of demonstration trajectories, the \ac{nff} model can generate plans for each task. The planning splits of the tasks require the agent to generate a plan that can achieve the goal, unlike the prediction splits that only evaluate if the trajectories are accurate. In \benchmark, we evaluate the effectiveness of the learned force field in planning through a 5-round interactive play. The \ac{nff} model functions as a mental simulator to identify optimal action sequences by evaluating 500 randomly sampled candidates. The selected best sequence is then executed in the physical environment. The model subsequently updates its parameters based on the observed outcomes to improve its alignment with real-world physics. In following trials, this refined model serves as the mental simulator for action sequence proposals.

\begin{figure}[b!]
    \centering
    \includegraphics[width=\linewidth]{exp_planning/success_probability_plot}
    \caption{\textbf{Interactive planning performance on \benchmark.} Comparison of cumulative success probability over 5 planning rounds between different approaches: human performance random sampling, our \acs{nff}, \acs{in}, and SlotFormer. Solid and dashed lines indicate variants with and without the refinement mechanism \citep{allen2020rapid}, respectively. Error bars show \ac{sem} across trials. Our \acs{nff} with refinement (yellow) demonstrates continuous improvement across rounds, achieving performance comparable to human players (data from \citet{li2023phyre}), while baseline models show limited performance even with refinement.}
    % \caption{\textbf{Planning results in \benchmark across rounds.} The figure shows the cumulative probability of success after $n$ rounds from human playing, random planning, \ac{nff}, \ac{in}, and SlotFormer. Each model is evaluated both with and without the refinement mechanism. The \ac{nff} model with refinement after each round shows increasingly better results, reaching human-level performance.}
    \label{fig:iphyre_plan}
\end{figure}

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[height=0.5cm]{ablation/legend}
    \end{subfigure}%
    \\%
    \begin{subfigure}[b]{0.21\linewidth}
        \centering
        \includegraphics[width=\linewidth,height=4cm,trim=0 1cm 0 0,clip]{ablation/ablation_step_size}
        \caption{Euler step size}
        \label{fig:ablation_euler}
    \end{subfigure}%
    \begin{subfigure}[b]{0.21\linewidth}
        \centering
        \includegraphics[width=\linewidth,height=4cm,trim=0 1cm 0 0,clip]{ablation/ablation_ode_5e2}
        \caption{Step size $5e-2$}
        \label{fig:ablation_step_5e2}
    \end{subfigure}%
    \begin{subfigure}[b]{0.21\linewidth}
        \centering
        \includegraphics[width=\linewidth,height=4cm,trim=0 1cm 0 0,clip]{ablation/ablation_ode_5e3}
        \caption{Step size $5e-3$}
        \label{fig:ablation_step_5e3}
    \end{subfigure}%
    \begin{subfigure}[b]{0.21\linewidth}
        \centering
        \includegraphics[width=\linewidth,height=4cm,trim=0 1cm 0 0,clip]{ablation/ablation_latent_dim}
        \caption{Latent dimension}
        \label{fig:ablation_latent_dim}
    \end{subfigure}%
    \begin{subfigure}[b]{0.16\linewidth}
        \centering
        \begin{subfigure}[b]{0.5\linewidth}
            \centering
            \includegraphics[width=\linewidth,trim=0 1cm 0 0,clip]{ablation/umap_2d_gt.jpg}
            \subcaption*{\tiny Ground-truth}
        \end{subfigure}%
        \begin{subfigure}[b]{0.5\linewidth}
            \centering
            \includegraphics[width=\linewidth,trim=0 1cm 0 0,clip]{ablation/umap_2d_3.jpg}
            \subcaption*{\tiny Dim = 3}
        \end{subfigure}%
        \\%
        \begin{subfigure}[b]{0.5\linewidth}
            \centering
            \includegraphics[width=\linewidth,trim=0 1cm 0 0,clip]{ablation/umap_2d_16.jpg}
            \subcaption*{\tiny Dim = 16}
        \end{subfigure}%
        \begin{subfigure}[b]{0.5\linewidth}
            \centering
            \includegraphics[width=\linewidth,trim=0 1cm 0 0,clip]{ablation/umap_2d_256.jpg}
            \subcaption*{\tiny Dim = 256}
        \end{subfigure}%
        \caption{Latent space}
        \label{fig:ablation_latent_space}
    \end{subfigure}
    \caption{\textbf{Ablation studies on key model components in N-body systems.} Results averaged across test cases and five random seeds. (a) Model error \vs integration step size ($1e-3$ to $5e-2$), showing improved accuracy with finer Euler integration. (b-c) Performance comparison with and without \acs{ode} integration for within- and cross-scenario generalization, evaluated at different step sizes. (d) Impact of latent space dimensionality (3, 16, 256) on generalization, demonstrating optimal performance when matching the inherent 3D nature of gravitational forces. (e) \acs{umap} visualization of learned force field representations, revealing that lower dimensionality better captures the underlying gravitational field manifold compared to higher dimensions. Blue/orange indicates relative magnitude of projected interactions.}
    % \caption{\textbf{Ablation studies on integration precision, \ac{ode} integration, and latent dimension}. All the experiments were conducted using the N-body task. Results are averaged across cases and five random seeds. (a) The performance of \ac{nff} increases with the Euler integration precision. (b-c) Generalization benefits from \ac{ode} integration. (d) The generalization performance increases when the latent interaction dimension of \ac{nff} decreases to the exact number of force parameters (three in the N-body task). (e) \acf{umap} visualization results show that high-dimensional interaction representation fails to capture the manifold of gravitational fields.}
    \label{fig:ablation}
\end{figure*}

We quantitatively evaluate planning performance by calculating success probability $p_i$ for each game as the success rate over 20 trials in round $i$, with \ac{nff} updating after failures; see detailed results in \cref{sec:supp:plan}. \Cref{fig:iphyre_plan} compares \ac{nff} against random sampling, human performance (from \citet{li2023phyre}), \ac{in}, and SlotFormer using cumulative success probability: $1-\prod_{i=1}^{n} (1-p_i)$ for each trial $n$. \ac{nff} outperforms baselines and approaches human-level performance after refinement \citep{allen2020rapid}, demonstrating effective few-shot learning. The poor performance of \ac{in} and SlotFormer, falling below random sampling, indicates how inaccurate dynamics modeling compromises planning.
% To quantitatively measure the planning performance and account for variance, we calculate the success probability $p_i$ for each game as the success rate in 20 trials in the $i$-th round. Note that \ac{nff} is updated after each failure. In \cref{fig:iphyre_plan}, we show the comparison of \ac{nff} with random sampling, human performance, \ac{in}, and SlotFormer. For each trial $n$, we show the cumulative probability of success of these methods, computed as $1-\prod_{i=1}^{n} (1-p_i)$. The results suggest that \ac{nff} outperforms baseline models, particularly when incorporating the refinement mechanism, approaching human-level reasoning capabilities. The notable improvement of \ac{nff} after refinement further demonstrates its few-shot learning ability. \ac{in} and SlotFormer perform below random sampling, suggesting that inaccurate dynamics learning can lead to suboptimal planning decisions. The detailed planning results in \benchmark are shown in \cref{sec:supp:plan}.

\textbf{N-body planning\quad{}}
We focus on determining initial conditions that achieve desired final configurations under celestial dynamics. \ac{nff}'s inverse simulation capability enables direct computation of initial conditions through reverse time evolution, while \ac{in} and SlotFormer rely on iterative gradient-based refinement. As shown in \cref{tab:nbody_plan}, \ac{nff} achieves superior planning performance in both within-scenario and cross-scenario settings.
% We consider finding the initial conditions that best match the given final goal under the celestial dynamics, including positions and velocities of all the bodies. By leveraging the inverse simulation capabilities of the trained \ac{nff}, we can reverse the time evolution and directly calculate the initial conditions from the final state. When performing planning with \ac{in} and SlotFormer, we use gradient-based techniques to iteratively refine the initial conditions. The planning results, shown in \cref{tab:nbody_plan}, demonstrate that \ac{nff} outperforms other methods in both within-scenario and cross-scenario settings.

\begin{table}[ht!]
    \small
    \centering
    \setlength{\tabcolsep}{3pt}
    \caption{\textbf{N-body system initial condition reconstruction from target configurations.} \acs{mse} $\downarrow$ comparison between \acs{in}, SlotFormer, and our \acs{nff}. Results show average and \ac{sem} across trials for both within- and cross-scenario evaluations. Lower values indicate better reconstruction accuracy.}
    % \caption{\textbf{Planning results in N-body.} When given the final system states, the \ac{nff}'s backward planning approach shows improved capability in reconstructing initial conditions of N-body systems, achieving lower \ac{mse} than \ac{in} and SlotFormer in both within-scenario and cross-scenario settings.}
    \label{tab:nbody_plan}
    \begin{tabular}{lccc}
        \toprule
        Scenario    & IN               & SlotFormer       & NFF              \\
        \midrule
        Within $\downarrow$ & 0.651 $\pm$ 0.021 & 0.837 $\pm$ 0.029 & \textbf{0.067 $\pm$ 0.010} \\
        Cross $\downarrow$ & 4.654 $\pm$ 0.193 & 4.018 $\pm$ 0.133 & \textbf{0.140 $\pm$ 0.011} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Ablation study}\label{sec:ablation}

We investigate three key factors affecting model performance: integration precision, \ac{ode} grounding, and latent dimensionality.
For \textbf{integration precision}, we evaluate \ac{nff} on the N-body task using Euler integration at four precision levels: $1e-3$, $5e-3$, $1e-2$, and $5e-2$. \Cref{fig:ablation_euler} demonstrates that higher integration precision consistently yields better performance. We also explore more integration methods in \cref{sec:supp:integration}. 
To study \textbf{\ac{ode} grounding}'s impact on generalization, we compare two configurations: our \ac{nff} using predicted force fields with \ac{ode} integration, and \ac{in} using learned state transitions at matching step sizes. \Cref{fig:ablation_step_5e2,fig:ablation_step_5e3} shows that \ac{ode} integration enhances generalization performance. However, at coarser step sizes ($5e-2$), \ac{nff} slightly underperforms \ac{in}, indicating that \ac{ode}-based approaches require fine integration precision to realize their advantages.
For \textbf{latent dimensionality} analysis, we vary the latent interaction space dimension in \ac{nff} across 3, 16, and 256 dimensions. Results in \cref{fig:ablation_latent_dim} reveal that lower-dimensional representations improve generalization capability. The visualization in \cref{fig:ablation_latent_space} confirms this finding, showing that reduced dimensionality leads to latent representations more closely matching ground truth.
These ablation studies demonstrate that \ac{nff} achieves optimal few-shot learning of physical dynamics when combining high integration precision, low-dimensional latent space, and \ac{ode}-based integration.
% In this ablation study, we explore various factors that influence model performance, including integration precision, whether the model is grounded in \ac{ode}s, and latent dimension.
% First, we examine the effect of integration precision on model performance by testing \ac{nff} on the N-body task with Euler integration at different precision levels: 1e-3, 5e-3,  1e-2, and 5e-2. As shown in \cref{fig:ablation} (a), increasing integration precision leads to improved performance. Next, we investigate the impact on generalization by integrating the model with \ac{ode}. We compare two setups: \ac{nff} where the predicted force field is combined with \ac{ode} integration to derive future states and \ac{in} where we use the learned state transition model with the same step size as \ac{nff}. The results in \cref{fig:ablation} (b-c) show that the model integrated with \ac{ode} outperforms the alternative, suggesting that incorporating \ac{ode} is helpful for better generalization. However, the slight performance drop of \ac{nff} compared to \ac{in} at a step size of 5e-2 indicates that \ac{ode}-based methods require high integration precision to fully leverage its potential. Finally, we assess whether low-dimensional latent representation brings better generalization by varying the dimension of the latent interaction space in \ac{nff} across 3, 16, and 256. The results in \cref{fig:ablation} (d) demonstrate that using a low-dimensional representation could enhance the model’s generalization ability. The visualization in \cref{fig:ablation} (e) further illustrates that as the dimensionality decreases, the latent representation increasingly resembles the ground truth. Together, these ablation results highlight that \ac{nff}, when combined high integration precision, a low latent dimension, and \ac{ode}, is an effective approach for few-shot learning of physical dynamics.

\section{Discussion}

\textbf{Modeling diverse forces\quad{}}
While \ac{nff} has demonstrated effectiveness in modeling fundamental physical forces like gravity, support, and collision, its principles extend naturally to broader domains. The framework can potentially model social forces \citep{shu2015joint,xie2017learning,wei2017inferring,wei2018and,shu2021unified} and biological forces governing migration patterns and human motion \citep{netanyahu2024few}.
% While the \ac{nff} framework has already demonstrated its ability to capture fundamental physical forces like gravity, support, and collision, its underlying principles can be extended to model a diverse range of forces that govern different types of systems such as social forces \citep{shu2015joint,xie2017learning,wei2017inferring,wei2018and,shu2021unified} and biological forces in migration and human motion \citep{netanyahu2024few}.
% \textbf{A cognitive tool for intuitive physics\quad{}}
% One of the most significant questions studied in intuitive physics is whether the capability of human physical reasoning is inherent in the brain or learned from experience \citep{kubricht2017intuitive}. \ac{nff} may serve as a cognitive tool to study the quick acquisition of physical knowledge learned from minimal interactions to build intuitive physics capability.
\textbf{Limitations\quad{}}
Like existing approaches \citep{battaglia2016interaction}, \ac{nff} operates on symbolic states, setting aside perception challenges. The integration of raw sensory input with physics learning remains an open challenge, requiring investigation into various representation frameworks.
% Similar to baselines \citep{battaglia2016interaction,wu2022slotformer}, \ac{nff} is trained directly from symbolic states of objects in the scene with perception problems ignored. Integrating raw perception input and physics learning remains as challenging and various forms of representation and modeling frameworks demand examining. Besides, the computational complexity

\section{Conclusion}

We present \ac{nff}, a force field-based representation framework for modeling physical interactions that exhibits human-like few-shot learning, generalization, and reasoning capabilities. Our experiments on two challenging physical reasoning datasets demonstrate \ac{nff}'s ability to learn diverse physical concepts and rules from limited observations. This initial exploration of force field opens new possibilities for developing physical world models through representation learning, potentially bridging the gap between symbolic physics understanding and learning-based approaches.
% In this work, we propose \ac{nff}, a representation based on the force field for modeling complex physical interactions, featuring human-like few-shot learning, generalization, and reasoning abilities. The experiments on two challenging physical reasoning datasets show that \ac{nff} can learn a range of physical concepts and rules from limited observations. We hope that our preliminary attempts at modeling the force field may open a new avenue for building physical world models from the perspective of representation learning.

\section*{Impact statements}

This work contributes to advancing physics-informed machine learning with potential applications in robotics, simulation, and scientific discovery. The proposed \ac{nff} framework could enable more sample-efficient and interpretable physical modeling, reducing computational resources needed for training. While primarily focused on fundamental physics, the methodology could extend to social and biological systems modeling. We acknowledge potential risks if misused for simulating harmful physical scenarios. However, the research focuses on basic physical principles and publicly available phenomena, prioritizing transparent and reproducible science. The computational requirements for training \ac{nff} are moderate, making it accessible to most research institutions while maintaining a reasonable carbon footprint.

\section*{Acknowledgements}

The authors would like to thank Miss Chen Zhen (BIGAI) for making the nice figures, Prof. Yizhou Wang (Peking University) for the helpful discussion, and Minyang Yu (Peking University) for working on the GPT's results. S. Li, R. Shen, and Y. Zhu are supported in part by the National Natural Science Foundation of China (62376031), the Beijing Nova Program, the State Key Lab of General AI at Peking University, the PKU-BingJi Joint Laboratory for Artificial Intelligence, and the National Comprehensive Experimental Base for Governance of Intelligent Society, Wuhan East Lake High-Tech Development Zone.

\bibliography{reference_header,reference}
\bibliographystyle{icml2025}

\clearpage
\newpage

\appendix
\onecolumn
\renewcommand\thefigure{A\arabic{figure}}
\setcounter{figure}{0}
\renewcommand\thetable{A\arabic{table}}
\setcounter{table}{0}
\renewcommand\theequation{A\arabic{equation}}
\setcounter{equation}{0}
\pagenumbering{arabic}% resets `page` counter to 1
\renewcommand*{\thepage}{A\arabic{page}}
\setcounter{footnote}{0}

\section{Environment and dataset configurations}\label{sec:supp:data}

\subsection{\benchmark}

We adopt the original settings from the \benchmark work \citep{li2023phyre}. The training dataset consists of 10 basic games: support, hinder, direction, hole, fill, seesaw, angle, impulse, pendulum, and spring. For each game, we randomly generate 5 successful and 5 failed action sequences. The within-scenario setting includes an additional 10 successful and 10 failed action sequences for each of the 10 basic games. The cross-scenario setting contains 10 successful and 10 failed action sequences from 30 unseen games, which include 10 noisy games, 10 compositional games, and 10 multi-ball games. All object masses are set to be equal, and small friction and elasticity coefficients are applied. For each game, we record the center positions, lengths, angles, radii, horizontal velocities, vertical velocities, and rotational velocities of each object, as well as the spring pair indices. Each sequence contains up to 12 objects and spans 150 timesteps. 

\subsection{N-body}

We employed the REBOUND engine to simulate N-body dynamics and considered two types of N-body problems for 3D trajectories: the planetary n-body problem and the cometary n-body problem. In the planetary n-body problem, the comets are initialized with Keplerian velocities, while in the cometary n-body problem, the planets are initialized with escape velocities. Initial positions are sampled from the spherical coordinate system and then converted to Cartesian coordinates. The radii are sampled within the range of 1 to 3, azimuthal angles are sampled from 0 to $2\pi$, and polar angles are sampled from $-\pi/6$ to $\pi/6$. Masses are sampled from 0.05 to 0.1, while the central massive body is assigned a mass of 5. All sampling is performed using Latin Hypercube Sampling to ensure comprehensive space coverage, even with sparse samples. The training dataset includes 50 two-body planetary trajectories, 50 three-body planetary trajectories, 50 two-body cometary trajectories, and 50 three-body cometary trajectories, spanning across 50 timesteps. The within-scenario dataset consists of the same four trajectory types as the training set but with different initial conditions. The cross-scenario dataset contains 100 nine-body planetary trajectories with radii ranging from 1 to 11 and 100 nine-body cometary trajectories with radii ranging from 1 to 5. The trajectory length in the cross-scenario data is extended to 100 steps. We record the masses, 3D Cartesian coordinates, and velocities for training.
\section{Training details}\label{sec:supp:training}

\subsection{Hyperparameters}

In \benchmark, we train the models using a single NVIDIA A100 Tensor Core GPU. The force field predictor in \ac{nff} is based on a DeepONet architecture, consisting of trunk and branch networks, each a 3-layer MLP with a hidden size of 256. The \ac{ode} solver uses the Euler method with a step size of 0.005. The 150-step trajectories are divided into 6-step segments, with 6 trajectories per batch. The learning rate starts at 5e-4 and gradually decays to 1e-5 following a cosine annealing schedule. Training occurs over 3000 epochs with a weight decay of 1e-5 for regularization.

The interaction predictor in \ac{in} is a 3-layer MLP with a hidden size of 256, while the decoder is also an MLP of the same size. SlotFormer uses 3 transformer encoder layers, each with 4 attention heads and a feedforward network of size 256. Both \ac{in} and SlotFormer are trained with a batch size of 50 trajectories, employing the same segmentation technique. All other hyperparameters are kept consistent with those used in \ac{nff}.

In N-body, we train the models using a single NVIDIA GeForce RTX 3090 GPU. For all models, the 50-step trajectories are divided into 5-step segments, with 50 trajectories per batch. The learning rate starts at 5e-4 and gradually decays to 1e-7 following a cosine annealing schedule. Training occurs over 5000 epochs with a weight decay of 1e-5 for regularization. All the other hyperparameters are the same as those used in \benchmark.


\subsection{Evaluation metrics}\label{sec:supp:metrics}

In this study, the chosen evaluation metrics include, \ac{rmse}, \ac{fpe}, \ac{pce}, and \ac{r}. Each of these metrics provides valuable insights into different characteristics of the model's predictions, allowing for a comprehensive evaluation. 

% \paragraph{\acf{mae}}

% The \ac{mae} is a straighFPEtforward metric that quantifies the average magnitude of errors in the model's predictions without considering their direction. It is defined as the average of the absolute differences between predicted and actual positions over all time steps. \ac{mae} provides a clear sense of the typical error magnitude, making it easy to interpret and directly compare to the scale of the data.
% \begin{equation}
% \text{\acs{mae}} = \frac{1}{n} \sum_{t=1}^{n} | \hat{z}_t - z_t |
% \end{equation}

% \paragraph{\acf{mse}}

% The \ac{mse} is another widely-used metric that calculates the average of the squared differences between the predicted and actual values. \ac{mse} emphasizes larger errors by squaring the differences, which results in higher penalties for predictions that deviate significantly from the true trajectories.
% \begin{equation}
% \text{\acs{mse}} = \frac{1}{n} \sum_{t=1}^{n} (\hat{z}_t - z_t)^2
% \end{equation}

\paragraph{\acf{rmse}}

The \ac{rmse}, the square root of \ac{mse}, shares the same characteristics as \ac{mse} in terms of penalizing larger errors. However, it provides the error in the same units as the original data, allowing for a more intuitive understanding of how far off the model's predictions are, on average, in the context of physical trajectories:
\begin{equation}
    \text{\acs{rmse}} = \sqrt{\frac{1}{n} \sum_{t=1}^{n} (\hat{z}_t - z_t)^2}.
\end{equation}

\paragraph{\acf{fpe}}

The \ac{fpe} specifically measures the discrepancy between the predicted and actual final position of the object at the end of the trajectory. This metric is crucial for goal-driven physical reasoning tasks where the objects are expected to finally move into a specific area. \ac{fpe} helps ensure that the model is not only capturing the intermediate trajectory but also predicting the final destination with high accuracy:
\begin{equation}
    \text{\acs{fpe}} = \left|\hat{z}_{\text{final}} - z_{\text{final}}\right|.
\end{equation}

\paragraph{\acf{pce}}

The \ac{pce} quantifies the error in the predicted change of position over time, which can be interpreted as a measure of the model’s accuracy in tracking the object's velocity during its motion:
\begin{equation}
    \text{\acs{pce}} = \left|\Delta \hat{z}_t - \Delta z_t\right|.
\end{equation}

\paragraph{\acf{r}}

The \ac{r} measures the linear relationship between the predicted and actual trajectories. \ac{r} is useful for assessing how well the model captures the overall trend or pattern of the trajectory, even when the absolute errors might vary. A high correlation suggests that the model is effectively tracking the overall movement, while a low correlation might indicate that the model fails to capture the underlying trajectory pattern:
\begin{equation}
    \acs{r} = \frac{\sum_{t=1}^{n} ( \hat{z}_t - \bar{\hat{z}} )( z_t - \bar{z} )}{\sqrt{\sum_{t=1}^{n} ( \hat{z}_t - \bar{\hat{z}} )^2 \sum_{t=1}^{n} ( z_t - \bar{z} )^2}}.
\end{equation}

\section{Overfitting}\label{sec:supp:overfit}

\begin{wrapfigure}{r}{0.5\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/supp_overfitting.pdf}
    \caption{\textbf{SlotFormer overfitting on physical data.} While the performance improves in the within-scenario setting as training progresses, the cross-scenario setting experiences overfitting, resulting in increasing \acs{rmse} during training.}
    \label{fig:supp:overfit}
\end{wrapfigure}

We demonstrate that methods without interaction modeling are prone to overfitting on in-distribution physical data. While they perform well within the same scenario, they face significant challenges in cross-scenario settings. To illustrate this, we train a SlotFormer on N-body training data and validate it on a separate 4-body cross-scenario dataset. As shown in \cref{fig:supp:overfit}, the increase in overfitting leads to a decline in generalization performance.


\section{Ablation studies on integration methods}\label{sec:supp:integration}

In \cref{tab:supp:integration}, we present additional ablation studies comparing various integration methods. Specifically, we evaluate the performance of different integration orders on the N-body task, including Euler, Midpoint, Heun3, RK4, and adaptive methods. Computational complexity is measured by the average number of integration steps. The results indicate that Euler integration provides the best cross-scenario generalization, while Heun3 excels in within-scenario generalization. Despite this, Euler integration has lower computational complexity than the higher-order methods. These findings suggest that Euler integration is sufficient for our physical reasoning tasks.

\begin{table*}[t!]
    \centering
    \small
    \caption{\textbf{Results of different kinds of integration methods.} The computational complexity of the model is proportional to the number of average integration steps (relative to Euler $5e-3$). Among non-adaptive integration methods, the Euler method achieves the best generalization performance with relatively low computational complexity, whereas adaptive methods at different tolerance levels do not exhibit consistent performance improvements.}
    \label{tab:supp:integration}
    \begin{tabular}{lccc}
    \toprule
    Method & Average steps (relative) & Within  & Cross \\
    \midrule
    \multicolumn{4}{l}{\textbf{Adaptive methods (tolerance)}} \\
    Adaptive ($1e-3$)   & $0.20$ & $0.0725 \pm 0.0084 $ & $0.1537 \pm 0.0069$ \\
    Adaptive ($1e-4$)   & $0.28$ & $0.0582 \pm 0.0035$ & $0.1797 \pm 0.0125$ \\
    Adaptive ($1e-5$)   & $0.36$ & $0.0783 \pm0.0056$ & $0.1539 \pm 0.0056$ \\
    Adaptive ($1e-6$)   & $0.56 $&$ 0.0807 \pm 0.0053$ & $0.1668 \pm 0.0067 $\\
    Adaptive ($1e-7$)   & $1.07$ & $0.0811 \pm 0.0053$ & $0.1928 \pm 0.0077$ \\
    \midrule
    \multicolumn{4}{l}{\textbf{Non-adaptive methods (step size)}} \\
    Euler ($5e-3$) & $1.00$ & $0.0785\pm0.0069$ & \textbf{$0.1522 \pm 0.0066$} \\
    Midpoint ($5e-3$) & $2.00$ & $0.0671 \pm 0.0053$ & $0.1762 \pm 0.0071$ \\
    Heun3 ($5e-3$) & $3.00$ & \textbf{$0.0606 \pm 0.0041$} & $0.1550 \pm 0.0067$ \\
    RK4 ($5e-3$)   & $4.00$ & $0.0682 \pm 0.0048$ & $0.1626 \pm 0.0072$ \\
    \bottomrule
    \end{tabular}
\end{table*}




\section{Detailed planning results}\label{sec:supp:plan}

We present the detailed planning results of different models across trials in \cref{tab:supp:planning}. 

Besides those dynamic prediction models, we also benchmark the planning performance of the large language model GPT-4o with the refinement mechanism. The core idea is utilizing In-Context Learning (ICL) abilities and high-level reasoning abilities of large language models to find correct solutions. 

The prompt in Round 1 consists of 3 parts: (1) \benchmark description and an elaborately explained example. (2) Other training examples. (3) Description of the testing game setting. In Part 2, we provide GPT-4o with 1 successful solution and 1 wrong solution together with resulting trajectories of objects for each of the 10 basic games. In the refinement stage ({\it i.e.}, Round 2 and Round 3), we run the action sequence proposed by GPT-4o on the simulator, Then we offer GPT-4o the resulting trajectory and ask it to modify the previous solution or design a new one.

We test the performance of GPT-4o for both within-scenario planning and cross-scenario planning. Detailed results are presented in \cref{tab:supp:gpt4o}. Within-scenario games contains the same 10 games used in the prompt in Round 1. So the language model can memorize corresponding solutions provided in the prompt to achieve good performance. Cross-scenario games contains the other 30 game settings, on which the performance of GPT-4o is better than other baselines (Random, IN, SlotFormer) in \cref{tab:supp:planning}. The improvement of performance through refinement is witnessed in both within-scenario and cross-scenario games.

The prompt used in Round 1 is shown below.


\begin{table*}[t!]
    \centering
    \small
    \caption{\textbf{Planning results in \benchmark.} Average probability of succeeding cross-scenario games after \(n\) trails from \ac{in}, SlotFormer, \ac{nff}, human, w/o refining. The gray line indicates the best results among all the AI methods.}
    \label{tab:supp:planning}
    \begin{tabular}{ccccccc}
        \toprule
        Method & Refine & Round 1 & Round 2 & Round 3 & Round 4 & Round 5 \\
        \midrule
        Random & - & $0.24 \pm 0.04$ & $0.37 \pm 0.05$ & $0.45 \pm 0.06$ & $0.51 \pm 0.06$ & $0.56 \pm 0.06$\\
        \ac{in} & $\times$ & $0.25 \pm 0.06$ & $0.33 \pm 0.07$ & $0.39 \pm 0.07$ & $0.42 \pm 0.08$ & $0.45 \pm 0.08$ \\ 
        \ac{in} & $\checkmark$ & $0.25 \pm 0.06$ & $0.39 \pm 0.07$ & $0.48 \pm 0.07$ & $0.57 \pm 0.07$ & $0.63 \pm 0.06$ \\ 
        SlotFormer & $\times$ & $0.30 \pm 0.07$ & $0.36 \pm 0.08$ & $0.39 \pm 0.08$ & $0.41 \pm 0.08$ & $0.43 \pm 0.08$ \\ 
        SlotFormer & $\checkmark$ & $0.30 \pm 0.07$ & $0.42 \pm 0.08$ & $0.49 \pm 0.07$ & $0.55 \pm 0.07$ & $0.60 \pm 0.07$ \\ 
        \ac{nff} & $\times$ & $0.51 \pm 0.08$ & $0.55 \pm 0.08$ & $0.58 \pm 0.08$ & $0.60 \pm 0.08$ & $0.62 \pm 0.08$ \\ 
        \rowcolor[gray]{0.9}
        \ac{nff} & $\checkmark$ & $0.51 \pm 0.08$ & $0.62 \pm 0.08$ & $0.69 \pm 0.07$ & $0.74 \pm 0.06$ & $0.77 \pm 0.06$ \\ 
        \midrule
        Human & $\times$ & $0.52 \pm 0.06$ & $0.66 \pm 0.06$ & $0.73 \pm 0.06$ & $0.77 \pm 0.06$ & $0.80 \pm 0.05$ \\
        Human & $\checkmark$ & $0.52 \pm 0.06$ & $0.70 \pm 0.06$ & $0.79 \pm 0.05$ & $0.83 \pm 0.04$ & $0.86 \pm 0.04$ \\
    \bottomrule
    \end{tabular}
\end{table*}

\begin{table*}[t!]
    \centering
    \caption{\textbf{GPT-4o's planning results in \benchmark.} The GPT-4o refines itself after each round of play and shows increasingly better performance.}
    \label{tab:supp:gpt4o}
    \begin{tabular}{cccc}
        \toprule
        Scenario  & Round 1 & Round 2 & Round 3 \\
        \midrule
        Within & $0.74 \pm 0.08$ & $0.78 \pm 0.07$ & $0.82 \pm 0.07$\\
        Cross & $0.35 \pm 0.07$ & $0.45 \pm 0.08$ & $0.51 \pm 0.04$\\
        \bottomrule
    \end{tabular}
\end{table*}

\clearpage

\lstset{
    commentstyle= \color{red!50!green!50!blue!50}, 
    keywordstyle= \color{blue!70}, 
    numberstyle=\tiny\color{codegray}, 
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true, 
    captionpos=b,
    keepspaces=true,
    showspaces=false,
    showstringspaces=false, 
    showtabs=false,
    tabsize=2,
    frame=single 
}

\begin{lstlisting}[title={The prompt used in Round 1.}, label={code:prompt}]
    /* PART 1 */
        This is a 2D physics simulation environment. There will be one or few red balls, and may appear black blocks, grey blocks and blue blocks. Lengths of blocks are different.
        
        All these objects are rigid bodies. When we talk about physical laws, we consider gravity (there is gravity in this environment), friction (but the friction coefficients are small), collision between rigid bodies, rotation of balls and blocks.
        However, grey blocks and black blocks are fixed and stay still to their initial positions. They do not apply any laws of physics (even collision won't affect them). The red ball and blue blocks are controlled by physical laws.
        Initially, all objects are at rest (their velocity and angular velocity are all 0). 

        There may exist 2 types of constraints between two objects: spring or joint. "Spring" constraint means there is a spring linking 2 objects. Springs in all the games have the same rest length, stiffness and damping rate (You can infer these properties from trajectories provided below that contain springs). "Joint" constraint means there is a rod supporting 2 objects so their distance is fixed.
        We emphasize that grey and black blocks are not affected by any constraints. They are fixed to their initial positions.

        Now, we are going to play a game. The goal is to make all the red balls fall down to the bottom of the canvas.
        Let's first define a coordinate on the canvas. Let the origin be the top left corner. The x-axis is horizontal, from left to right. The y-axis is vertical, from top to bottom. The canvas size is (600, 600), so the coordinate of the lower-right corner is (600, 600).
        The only operation the player can do is to eliminate any grey blocks at any time they want (however, we limit the whole game in 15 seconds. If after 15s the red ball still doesn't reach the bottom, the player loses the game). The player cannot eliminate other objects, including the red ball, blue or black blocks. Note that if the player eliminates a grey block which is connected to some other object with a spring or joint, then the spring/joint between them will disappear.

        Now, I will show you a game named "fill". The name is actually the key to solve this problem. In this game, a blue block is placed above a grey block. You need to eliminate the grey block so that the blue block falls down to fill the pit on the "ground" (the ground and pit are built by a few black blocks). Otherwise, the red ball will roll into and get trapped in the pit.
        Below is the initial setting of the game. I will describe the meaning of each parameter.

    {'block': [[[100.0, 420.0], [400.0, 420.0]], [[100.0, 400.0], [250.0, 400.0]], [[350.0, 400.0], [400.0, 400.0]], [[270.0, 200.0], [330.0, 200.0]], [[270.0, 180.0], [330.0, 180.0]], [[100.0, 150.0], [180.0, 200.0]], [[150.0, 100.0], [150.0, 150.0]]], 'ball': [[120.0, 120.0, 20.0]], 'eli': [0, 0, 0, 1, 0, 1, 1, 0], 'dynamic': [0, 0, 0, 0, 1, 0, 0, 1]}
 
        First comes the `block` items. Each item is in the form of `[[left_x, left_y], [right_x, right_y]]`, namely, the coordinates of the left and right corner of the block. Note that each block is generated by moving a circle (radius = 10) centered from the left corner to the right corner.
        Next comes the `ball` items. Now we only have 1 ball in this game. This item looks like `[x, y, r]`, namely, the coordinates of the center and the radius of the ball.
        Then comes the `eli` item specifying which of these objects are eliminable. In this game, 'eli': [0, 0, 0, 1, 0, 1, 1, 0]. This is an 8-dimensional vector. The first 7 elements describes the 7 blocks (there are 7 elements in the `block` item), and the last element describes the ball. 0 means the object is not eliminable, and 1 means the object is eliminable.
        Finally comes the `dynamic` item, which specifies whether the objects are dynamic. In this game, 'dynamic': [0, 0, 0, 0, 1, 0, 0, 1]. The first 7 elements are the 7 blocks, and the last element is the ball. 0 means the object is static (not apply physical laws), and 1 means the object is dynamic (apply physical laws).
        You can infer from `eli` and `dynamic` that the 4th, 6th, and 7th blocks are grey, the 5th block is blue. All other blocks are black. 
        In other game settings, there may exist `spring` or `joint` items. They look like 'spring': [[6, 7]], which means there is only 1 spring connecting the 6th and 7th object (object can be blocks or balls). 'joint': [[6, 7]] means there is only 1 joint connecting the 6th and 7th object.
        Here, we also provide an image of the game.

        <image here>

        Now you are provided with a successful action sequence that can solve the game. The action sequence is as follows:

    [[150.0, 125.0, 0.3], [300.0, 200.0, 1.4000000000000004]]
 
        Action sequence is a list of eliminations [pos_x, pos_y, t], where `pos_x` and `pos_y` must be the center of some block (formally, the center is the average of the coordinates of 2 corners: pos_x = 1 / 2 * (left_x + right_x), pos_y = 1 / 2 * (left_y + right_y)), and `t` is the time when the block is eliminated (t should be in 0.1 ~ 15.0). In this example, there are 2 grey blocks to eliminate. [150, 125, 0.3] means eliminate the vertical block (next to the red ball) at t = 0.3s; [300.0, 200.0, 1.4] means eliminate the horizontal block (which supports the blue block from falling down) at t = 1.4s.
        In this setting, all positions that can be eliminated are [[300.0, 200.0], [140.0, 175.0], [150.0, 125.0]].
    
        Now you are provided with the trajectory of the red ball and the dynamic (blue) block. Other blocks are either static (the same as in the initial setting) or eliminated at some time. In this case, there is only one blue block. If there are multiple blue blocks, their position at some timestamp will be given by the same order as in `dyn` item. If there are no blue balls, the `dynamic` item will be an empty list.
        Below is the trajectory. 
        t =  0.000s: {'ball': [[120.0, 120.0]], 'dynamic_block': [[270.0, 180.0, 330.0, 180.0]]}
        t =  0.167s: {'ball': [[120.0, 121.25]], 'dynamic_block': [[270.0, 180.03, 330.0, 180.03]]}
        t =  0.333s: {'ball': [[120.0, 125.28]], 'dynamic_block': [[270.0, 180.03, 330.0, 180.03]]}
        ...
        
    /* PART 2 */
        Now we provide you with more examples from different game settings. We will provide 10 game settings. For each game setting, we will provide you with the initial setting (data + image), and 2 action sequence & trajectory (including 1 successful and 1 failed ones).
    
        Game 1: name:angle
            Initial setting: {'block': [[[100.0, 400.0], [400.0, 400.0]], [[200.0, 350.0], [210.0, 350.0]], [[200.0, 300.0], [210.0, 300.0]], [[480.0, 400.0], [550.0, 400.0]], [[390.0, 350.0], [400.0, 350.0]], [[390.0, 300.0], [400.0, 300.0]], [[100.0, 380.0], [100.0, 360.0]], [[550.0, 380.0], [550.0, 360.0]], [[200.0, 280.0], [400.0, 280.0]]], 'ball': [[300.0, 250.0, 20.0]], 'eli': [0, 1, 1, 0, 1, 1, 0, 0, 0, 0], 'dynamic': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
            Eliminable positions: [[205.0, 350.0], [205.0, 300.0], [395.0, 350.0], [395.0, 300.0]]
            Game setting image:

        <image here>

            Successful Case 1:
                Action sequence: [[395.0, 300.0, 1.4000000000000004], [205.0, 350.0, 2.900000000000001], [205.0, 300.0, 3.9000000000000012], [395.0, 350.0, 5.900000000000002]]
                This action sequence leads to success.
                Trajectory:
     
                t =  0.000s: {'ball': [[300.0, 250.0]], 'dynamic_block': [[200.0, 280.0, 400.0, 280.0]]}
                t =  0.167s: {'ball': [[300.0, 250.32]], 'dynamic_block': [[200.02, 280.3, 400.02, 280.3]]}
                ... 
                
            Failed Case 1:
                Actions: [[395.0, 350.0, 3.000000000000001], [205.0, 300.0, 4.800000000000002], [205.0, 350.0, 6.400000000000002], [395.0, 300.0, 6.700000000000002]]
                This action sequence leads to failure.
                Trajectory:
     
                t =  0.000s: {'ball': [[300.0, 250.0]], 'dynamic_block': [[200.0, 280.0, 400.0, 280.0]]}
                t =  0.167s: {'ball': [[300.0, 250.32]], 'dynamic_block': [[200.02, 280.3, 400.02, 280.3]]}
                ... 

        ... <more examples>
        
    /* PART 3 */
        Your goal is to provide a successful action sequence (that makes the red ball fall to the bottom of the canvas) under a new game setting. Below is the new game setting.
        Game name: "angle".
            Game setting:
                ...
            Eliminable positions: ...
            Game setting image:
 
        <image here>

        Your task is to provide a successful action sequence in the same format as examples given previously. You should make some analysis or explanations.
        Now please provide one successful action sequence. At the end of your response, please give the entire action sequence in the format of 
        " 
            Action sequnce: [[pos_1_x, pos_1_y, t_1], [pos_2_x, pos_2_y, t_2], ...]
        "
        so that we can extract and test your proposed action sequence easily.
                    
\end{lstlisting}

\clearpage

\section{More visualization}\label{sec:supp:vis}

We present additional visualization of learned forces along the trajectories in \benchmark in \cref{fig:supp:force_traj_within,fig:supp:force_traj_cross}. We also present more prediction results on N-body in \cref{fig:supp:nbody}.

% \begin{figure*}[t!]
%     \centering
%     \includegraphics[width=\linewidth]{supp_force_traj}
%     \caption{\textbf{The inverted forces from \ac{nff} and its predicted trajectories of dynamic objects in \benchmark within scenarios}. Ground-truth trajectories are represented by black dots, while predicted trajectories are shown with colorful dots. Horizontal and vertical forces are depicted as arrows, while rotational forces are indicated by red or blue dots, signifying negative and positive forces, respectively. The color of the forces indicates which object is exerting the force. Only the initial states are shown for static objects. Some objects will be eliminated during the process. Best seen in videos.}
%     \label{fig:supp:force_traj_within}
% \end{figure*}
\begin{figure*}[t!]
    \centering
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_0.pdf}
        \label{fig:sup:force_traj_within_0}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_1.pdf}
        \label{fig:sup:force_traj_within_1}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_2.pdf}
        \label{fig:sup:force_traj_within_2}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_3.pdf}
        \label{fig:sup:force_traj_within_3}
    \end{subfigure}%

    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_4.pdf}
        \label{fig:sup:force_traj_within_4}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_5.pdf}
        \label{fig:sup:force_traj_within_5}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_6.pdf}
        \label{fig:sup:force_traj_within_6}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_7.pdf}
        \label{fig:sup:force_traj_within_7}
    \end{subfigure}%

    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_8.pdf}
        \label{fig:sup:force_traj_within_8}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_9.pdf}
        \label{fig:sup:force_traj_within_9}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_10.pdf}
        \label{fig:sup:force_traj_within_10}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A2/supp_force_traj_within_11.pdf}
        \label{fig:sup:force_traj_within_11}
    \end{subfigure}%

    
    \caption{\textbf{The inverted forces from \ac{nff} and its predicted trajectories of dynamic objects in \benchmark within scenarios}. Ground-truth trajectories are represented by black dots, while predicted trajectories are shown with colorful dots. Horizontal and vertical forces are depicted as arrows, while rotational forces are indicated by red or blue dots, signifying negative and positive forces, respectively. The color of the forces indicates which object is exerting the force. Only the initial states are shown for static objects. Some objects will be eliminated during the process. Best seen in videos.}
    \label{fig:supp:force_traj_within}
\end{figure*}

\begin{figure*}[t!]
    \centering
    % \includegraphics[width=\linewidth]{supp_force_traj_cross}
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_0.pdf}
        \label{fig:sup:force_traj_cross_0}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_1.pdf}
        \label{fig:sup:force_traj_cross_1}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_2.pdf}
        \label{fig:sup:force_traj_cross_2}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_3.pdf}
        \label{fig:sup:force_traj_cross_3}
    \end{subfigure}%

    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_4.pdf}
        \label{fig:sup:force_traj_cross_4}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_5.pdf}
        \label{fig:sup:force_traj_cross_5}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_6.pdf}
        \label{fig:sup:force_traj_cross_6}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_7.pdf}
        \label{fig:sup:force_traj_cross_7}
    \end{subfigure}%

    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_8.pdf}
        \label{fig:sup:force_traj_cross_8}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_9.pdf}
        \label{fig:sup:force_traj_cross_9}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_10.pdf}
        \label{fig:sup:force_traj_cross_10}
    \end{subfigure}%
    \begin{subfigure}[b]{0.25\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A3/supp_force_traj_cross_11.pdf}
        \label{fig:sup:force_traj_cross_11}
    \end{subfigure}%
    
    \caption{\textbf{The inverted forces from \ac{nff} and its predicted trajectories of dynamic objects in \benchmark cross scenarios}. Ground-truth trajectories are represented by black dots, while predicted trajectories are shown with colorful dots. Horizontal and vertical forces are depicted as arrows, while rotational forces are indicated by red or blue dots, signifying negative and positive forces, respectively. The color of the forces indicates which object is exerting the force. Only the initial states are shown for static objects. Some objects will be eliminated during the process. Best seen in videos.}
    \label{fig:supp:force_traj_cross}
\end{figure*}

\begin{figure*}[t!]
    \centering
    % \includegraphics[width=0.8\linewidth]{supp_nbody_pred_trajectory}
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_0_True.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_0_NFF.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_0_Slotformer.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_0_IN.pdf}
    \end{subfigure}%

    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_52_True.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_52_NFF.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_52_Slotformer.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_52_True.pdf}
    \end{subfigure}%

    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_57_True.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_57_NFF.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_57_Slotformer.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/within_57_True.pdf}
    \end{subfigure}%

    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_gt_3.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_nff_3.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_slotformer_3.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_in_3.pdf}
    \end{subfigure}%

    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_gt_9.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_nff_9.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_slotformer_9.pdf}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_in_9.pdf}
    \end{subfigure}%

    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_gt_120.pdf}
        \caption{Ground truth trajectory}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_nff_120.pdf}
        \caption{Our \ac{nff} prediction}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_slotformer_120.pdf}
        \caption{SlotFormer {\tiny\citep{wu2022slotformer}}}
    \end{subfigure}%
    \begin{subfigure}[b]{0.2\linewidth}
        \includegraphics[width=\linewidth]{figures/figure_A4/cross_in_120.pdf}
        \caption{\acs{in} {\tiny\citep{battaglia2016interaction}}}
    \end{subfigure}%

    \caption{\textbf{Additional prediction results on N-body}.}
    \label{fig:supp:nbody}
\end{figure*}

\end{document}