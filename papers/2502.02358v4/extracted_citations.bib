@InProceedings{Guo_2022_CVPR,
    author    = {Guo, Chuan and Zou, Shihao and Zuo, Xinxin and Wang, Sen and Ji, Wei and Li, Xingyu and Cheng, Li},
    title     = {Generating Diverse and Natural 3D Human Motions From Text},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {5152-5161}
}

@InProceedings{Song_2024_CVPR,
    author    = {Song, Wenfeng and Jin, Xingliang and Li, Shuai and Chen, Chenglizhao and Hao, Aimin and Hou, Xia and Li, Ning and Qin, Hong},
    title     = {Arbitrary Motion Style Transfer with Multi-condition Motion Latent Diffusion Model},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {821-830}
}

@article{aberman2020unpaired,
  title={Unpaired motion style transfer from video to animation},
  author={Aberman, Kfir and Weng, Yijia and Lischinski, Dani and Cohen-Or, Daniel and Chen, Baoquan},
  journal={ACM Transactions on Graphics (TOG)},
  volume={39},
  number={4},
  pages={64--1},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{alexanderson2023listen,
  title={Listen, denoise, action! audio-driven motion synthesis with diffusion models},
  author={Alexanderson, Simon and Nagy, Rajmund and Beskow, Jonas and Henter, Gustav Eje},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={4},
  pages={1--20},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@inproceedings{athanasiou2024motionfix,
  title={MotionFix: Text-driven 3d human motion editing},
  author={Athanasiou, Nikos and Cseke, Alp{\'a}r and Diomataris, Markos and Black, Michael J and Varol, G{\"u}l},
  booktitle={SIGGRAPH Asia 2024 Conference Papers},
  pages={1--11},
  year={2024}
}

@inproceedings{chen2023executing,
  title={Executing your commands via motion diffusion in latent space},
  author={Chen, Xin and Jiang, Biao and Liu, Wen and Huang, Zilong and Fu, Bin and Chen, Tao and Yu, Gang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18000--18010},
  year={2023}
}

@article{chen2024motionclr,
  title={Motionclr: Motion generation and training-free editing via understanding attention mechanisms},
  author={Chen, Ling-Hao and Dai, Wenxun and Ju, Xuan and Lu, Shunlin and Zhang, Lei},
  journal={arXiv preprint arXiv:2410.18977},
  year={2024}
}

@inproceedings{cohan2024flexible,
  title={Flexible motion in-betweening with diffusion models},
  author={Cohan, Setareh and Tevet, Guy and Reda, Daniele and Peng, Xue Bin and van de Panne, Michiel},
  booktitle={ACM SIGGRAPH 2024 Conference Papers},
  pages={1--9},
  year={2024}
}

@inproceedings{dai2025motionlcm,
  title={Motionlcm: Real-time controllable motion generation via latent consistency model},
  author={Dai, Wenxun and Chen, Ling-Hao and Wang, Jingbo and Liu, Jinpeng and Dai, Bo and Tang, Yansong},
  booktitle={European Conference on Computer Vision},
  pages={390--408},
  year={2025},
  organization={Springer}
}

@inproceedings{fan2024everything2motion,
  title={Everything2Motion: Synchronizing Diverse Inputs via a Unified Framework for Human Motion Synthesis},
  author={Fan, Zhaoxin and Ji, Longbin and Xu, Pengxin and Shen, Fan and Chen, Kai},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={2},
  pages={1688--1697},
  year={2024}
}

@inproceedings{goel2024iterative,
  title={Iterative motion editing with natural language},
  author={Goel, Purvi and Wang, Kuan-Chieh and Liu, C Karen and Fatahalian, Kayvon},
  booktitle={ACM SIGGRAPH 2024 Conference Papers},
  pages={1--9},
  year={2024}
}

@inproceedings{guo2020action2motion,
  title={Action2motion: Conditioned generation of 3d human motions},
  author={Guo, Chuan and Zuo, Xinxin and Wang, Sen and Zou, Shihao and Sun, Qingyao and Deng, Annan and Gong, Minglun and Cheng, Li},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={2021--2029},
  year={2020}
}

@inproceedings{guo2022tm2t,
  title={Tm2t: Stochastic and tokenized modeling for the reciprocal generation of 3d human motions and texts},
  author={Guo, Chuan and Zuo, Xinxin and Wang, Sen and Cheng, Li},
  booktitle={European Conference on Computer Vision},
  pages={580--597},
  year={2022},
  organization={Springer}
}

@inproceedings{guo2024momask,
  title={Momask: Generative masked modeling of 3d human motions},
  author={Guo, Chuan and Mu, Yuxuan and Javed, Muhammad Gohar and Wang, Sen and Cheng, Li},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1900--1910},
  year={2024}
}

@article{jang2022motion,
  title={Motion puzzle: Arbitrary motion style transfer by body part},
  author={Jang, Deok-Kyeong and Park, Soomin and Lee, Sung-Hee},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={3},
  pages={1--16},
  year={2022},
  publisher={ACM New York, NY}
}

@article{jiang2023motiongpt,
  title={Motiongpt: Human motion as a foreign language},
  author={Jiang, Biao and Chen, Xin and Liu, Wen and Yu, Jingyi and Yu, Gang and Chen, Tao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={20067--20079},
  year={2023}
}

@inproceedings{jiang2025motionchain,
  title={Motionchain: Conversational motion controllers via multimodal prompts},
  author={Jiang, Biao and Chen, Xin and Zhang, Chi and Yin, Fukun and Li, Zhuoyuan and Yu, Gang and Fan, Jiayuan},
  booktitle={European Conference on Computer Vision},
  pages={54--74},
  year={2025},
  organization={Springer}
}

@inproceedings{karunratanakul2023guided,
  title={Guided motion diffusion for controllable human motion synthesis},
  author={Karunratanakul, Korrawe and Preechakul, Konpat and Suwajanakorn, Supasorn and Tang, Siyu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2151--2162},
  year={2023}
}

@inproceedings{kim2023flame,
  title={Flame: Free-form language-based motion synthesis \& editing},
  author={Kim, Jihoon and Kim, Jiseob and Choi, Sungjoon},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={7},
  pages={8255--8263},
  year={2023}
}

@article{li2024unimotion,
  title={Unimotion: Unifying 3D Human Motion Synthesis and Understanding},
  author={Li, Chuqiao and Chibane, Julian and He, Yannan and Pearl, Naama and Geiger, Andreas and Pons-Moll, Gerard},
  journal={arXiv preprint arXiv:2409.15904},
  year={2024}
}

@article{lin2023motion,
  title={Motion-x: A large-scale 3d expressive whole-body human motion dataset},
  author={Lin, Jing and Zeng, Ailing and Lu, Shunlin and Cai, Yuanhao and Zhang, Ruimao and Wang, Haoqian and Zhang, Lei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={25268--25280},
  year={2023}
}

@article{ling2024motionllama,
  title={MotionLLaMA: A Unified Framework for Motion Synthesis and Comprehension},
  author={Ling, Zeyu and Han, Bo and Li, Shiyang and Shen, Hongdeng and Cheng, Jikang and Zou, Changqing},
  journal={arXiv preprint arXiv:2411.17335},
  year={2024}
}

@article{lu2023humantomato,
  title={Humantomato: Text-aligned whole-body motion generation},
  author={Lu, Shunlin and Chen, Ling-Hao and Zeng, Ailing and Lin, Jing and Zhang, Ruimao and Zhang, Lei and Shum, Heung-Yeung},
  journal={arXiv preprint arXiv:2310.12978},
  year={2023}
}

@article{luo2024m,
  title={M3GPT: An Advanced Multimodal, Multitask Framework for Motion Comprehension and Generation},
  author={Luo, Mingshuang and Hou, Ruibing and Chang, Hong and Liu, Zimo and Wang, Yaowei and Shan, Shiguang},
  journal={arXiv preprint arXiv:2405.16273},
  year={2024}
}

@inproceedings{petrovich2021action,
  title={Action-conditioned 3d human motion synthesis with transformer vae},
  author={Petrovich, Mathis and Black, Michael J and Varol, G{\"u}l},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10985--10995},
  year={2021}
}

@inproceedings{pinyoanuntapong2024mmm,
  title={Mmm: Generative masked motion model},
  author={Pinyoanuntapong, Ekkasit and Wang, Pu and Lee, Minwoo and Chen, Chen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1546--1555},
  year={2024}
}

@article{plappert2016kit,
  title={The kit motion-language dataset},
  author={Plappert, Matthias and Mandery, Christian and Asfour, Tamim},
  journal={Big data},
  volume={4},
  number={4},
  pages={236--252},
  year={2016},
  publisher={Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA}
}

@article{qin2022motion,
  title={Motion In-Betweening via Two-Stage Transformers.},
  author={Qin, Jia and Zheng, Youyi and Zhou, Kun},
  journal={ACM Trans. Graph.},
  volume={41},
  number={6},
  pages={184--1},
  year={2022}
}

@article{shafir2023human,
  title={Human motion diffusion as a generative prior},
  author={Shafir, Yonatan and Tevet, Guy and Kapon, Roy and Bermano, Amit H},
  journal={arXiv preprint arXiv:2303.01418},
  year={2023}
}

@inproceedings{shrestha2025generating,
  title={Generating Physically Realistic and Directable Human Motions from Multi-modal Inputs},
  author={Shrestha, Aayam and Liu, Pan and Ros, German and Yuan, Kai and Fern, Alan},
  booktitle={European Conference on Computer Vision},
  pages={1--17},
  year={2025},
  organization={Springer}
}

@inproceedings{tevet2022motionclip,
  title={Motionclip: Exposing human motion generation to clip space},
  author={Tevet, Guy and Gordon, Brian and Hertz, Amir and Bermano, Amit H and Cohen-Or, Daniel},
  booktitle={European Conference on Computer Vision},
  pages={358--374},
  year={2022},
  organization={Springer}
}

@article{wang2024motiongpt,
  title={MotionGPT-2: A General-Purpose Motion-Language Model for Motion Generation and Understanding},
  author={Wang, Yuan and Huang, Di and Zhang, Yaqi and Ouyang, Wanli and Jiao, Jile and Feng, Xuetao and Zhou, Yan and Wan, Pengfei and Tang, Shixiang and Xu, Dan},
  journal={arXiv preprint arXiv:2410.21747},
  year={2024}
}

@article{wu2024motionllm,
  title={MotionLLM: Multimodal Motion-Language Learning with Large Language Models},
  author={Wu, Qi and Zhao, Yubo and Wang, Yifan and Tai, Yu-Wing and Tang, Chi-Keung},
  journal={arXiv preprint arXiv:2405.17013},
  year={2024}
}

@article{xie2023omnicontrol,
  title={Omnicontrol: Control any joint at any time for human motion generation},
  author={Xie, Yiming and Jampani, Varun and Zhong, Lei and Sun, Deqing and Jiang, Huaizu},
  journal={arXiv preprint arXiv:2310.08580},
  year={2023}
}

@article{yang2024unimumo,
  title={UniMuMo: Unified Text, Music and Motion Generation},
  author={Yang, Han and Su, Kun and Zhang, Yutong and Chen, Jiaben and Qian, Kaizhi and Liu, Gaowen and Gan, Chuang},
  journal={arXiv preprint arXiv:2410.04534},
  year={2024}
}

@article{zhang2022motiondiffuse,
  title={Motiondiffuse: Text-driven human motion generation with diffusion model},
  author={Zhang, Mingyuan and Cai, Zhongang and Pan, Liang and Hong, Fangzhou and Guo, Xinying and Yang, Lei and Liu, Ziwei},
  journal={arXiv preprint arXiv:2208.15001},
  year={2022}
}

@article{zhang2023finemogen,
  title={Finemogen: Fine-grained spatio-temporal motion generation and editing},
  author={Zhang, Mingyuan and Li, Huirong and Cai, Zhongang and Ren, Jiawei and Yang, Lei and Liu, Ziwei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={13981--13992},
  year={2023}
}

@inproceedings{zhang2023generating,
  title={Generating human motion from textual descriptions with discrete representations},
  author={Zhang, Jianrong and Zhang, Yangsong and Cun, Xiaodong and Zhang, Yong and Zhao, Hongwei and Lu, Hongtao and Shen, Xi and Shan, Ying},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={14730--14740},
  year={2023}
}

@inproceedings{zhang2025large,
  title={Large motion model for unified multi-modal motion generation},
  author={Zhang, Mingyuan and Jin, Daisheng and Gu, Chenyang and Hong, Fangzhou and Cai, Zhongang and Huang, Jingfang and Zhang, Chongzhi and Guo, Xinying and Yang, Lei and He, Ying and others},
  booktitle={European Conference on Computer Vision},
  pages={397--421},
  year={2025},
  organization={Springer}
}

@inproceedings{zhong2025smoodi,
  title={Smoodi: Stylized motion diffusion model},
  author={Zhong, Lei and Xie, Yiming and Jampani, Varun and Sun, Deqing and Jiang, Huaizu},
  booktitle={European Conference on Computer Vision},
  pages={405--421},
  year={2025},
  organization={Springer}
}

@inproceedings{zhou2023ude,
  title={Ude: A unified driving engine for human motion generation},
  author={Zhou, Zixiang and Wang, Baoyuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5632--5641},
  year={2023}
}

@article{zhou2023unified,
  title={A unified framework for multimodal, multi-part human motion synthesis},
  author={Zhou, Zixiang and Wan, Yu and Wang, Baoyuan},
  journal={arXiv preprint arXiv:2311.16471},
  year={2023}
}

@inproceedings{zhou2024avatargpt,
  title={AvatarGPT: All-in-One Framework for Motion Understanding Planning Generation and Beyond},
  author={Zhou, Zixiang and Wan, Yu and Wang, Baoyuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1357--1366},
  year={2024}
}

