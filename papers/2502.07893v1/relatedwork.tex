\section{Related Work}
\label{sec:related}

\subsection{Secondary studies of sentiment analysis in general domain}
Kumar and Jaiswal \cite{Kumar.2020} conducted an SLR with the goal of advancing the understanding of the feasibility, scope, and relevance of studies that apply soft computing techniques for sentiment analysis. They considered tools which used Twitter data and identified research gaps in the field. These gaps include an incessant need to enhance the performance of the sentiment classification tools and the usage of other data sets like Flickr\footnote{\url{https://www.flickr.com/}} or Tumblr\footnote{\url{https://www.tumblr.com/}}.
Abo et al. \cite{Mohamed.2019} conducted a systematic mapping study dealing with sentiment analysis for Arabic texts in social media. Devika et al. \cite{Devika.2016} looked at different approaches to sentiment analysis. Among other approaches such as support-vector machine (SVM), Naive Bayes classifier, they explained rule-based as well as lexicon-based methods.
Maitama et al. \cite{Maitama.2020} performed a systematic mapping study, which contains an examination of aspect-based sentiment analysis tools and an investigation of their approach, technique, diversity and demography.
Kastrati et al. \cite{app11093986} conducted a systematic mapping study regarding sentiment analysis of students' feedback. They identified 82 relevant studies and found a trend towards deep learning. They also highlighted the need for structured data sets and the focus on expressed emotion and its detection as an outcome.
Baragash and Aldowah \cite{Baragash_2021} also conducted a SMS in the field of higher education. They found 22 relevant papers. They have identified several application domains such as "course evaluation" or "teaching quality evaluation". In addition, their SMS showed as a result that sentiment analysis can help to improve the quality of teaching process and the performance of teachers.

However, all these SMSs and SLRs are not related to SE, and the data or tools are not designed for the domain of SE. Consequently, no information about areas or motivation to use the tools in the context of software development is offered. Besides, a need for SE-specific tools has already been identified by many studies \cite{Ahmed.2017, Calefato.2018, Chen.2019, Ding.2018, Islam.2018, Imtiaz.2018, StackEmo, F.Calefato.2015, Umer.2020, Werner.2018}.

\subsection{Secondary studies of sentiment analysis in SE domain}

Several authors analyzed the use of specific sentiment analysis tools in SE.
Zhang et al. \cite{9240704} compared sentiment analysis tools like Senti4SD \cite{Calefato.2018} and SentiCR \cite{Ahmed.2017} with each other. In addition, they described models based on the neural network BERT \cite{Devlin.2019}, which were trained with data related to SE such as GitHub\footnote{\url{https://github.com/}} or Stack Overflow\footnote{\url{https://stackoverflow.com/}}. In their replication study, Novielli et al. \cite{Novielli.replication2021} explained some sentiment analysis tools (e.g. Senti4SD \cite{Calefato.2018}) in great detail and described the underlying data.

Similarly, other papers compared sentiment analysis tools in their accuracy and described them in terms of their operation \cite{N.Novielli.2018,Novielli.}. Other papers mentioned some tools, too, but only briefly described them without going into details \cite{Biswas.2019,Chen.2019,Islam.2018c}.
In contrast to our work, the authors did not follow a systematic approach to consider the broad range of existing literature and tools, but rather focused on specific papers only. They did not go into detail about why they chose these tools or data and what tools are available.

Lin et al. conducted a systematic literature review on opinion mining in SE \cite{BinLin.2021}. Their scope was wide and included not only polarity detection and emotion detection, but also politeness detection and trust estimation. They focused on the data sets available, the performance comparison of the available tools, and the issues specific to tool adoption and customization. Their goal is to help researchers and developers adapt better tools.

In their SLR, Sánchez-Gordón and Colomo-Palacios \cite{SANCHEZGORDON201923} focused on the emotions of software developers. For this purpose, they examined 66 papers and identified, among other findings, the unreliability of sentiment analysis tools. As their focus was on developer-expressed emotions, they suggested other measures such as self-reported emotions or biometric sensors.

However, the focus of their work was not to provide an overview of sentiment analysis in the SE domain, e.g., which application scenarios they had, what the tools were used for, or which tool/machine learning algorithm perform how on average. Some papers compared and evaluated multiple tools on multiple data sets, but not all possible tools and data sets were included. Moreover, they do not provide a systematic overview of the application scenarios or potential problems in the whole area of sentiment analysis in SE.