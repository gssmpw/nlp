% CVPR 2025 Paper Template; see https://github.com/cvpr-org/author-kit

\documentclass[10pt,onecolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[review]{cvpr}      % To produce the REVIEW version
 \usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version
%%%% My packages %%%%
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{bm}
\graphicspath{{figures/}}

\usepackage[switch]{lineno}


\usepackage{tikz}
\usetikzlibrary{bayesnet}

% Import additional packages in the preamble file, before hyperref
\input{preamble}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, 
% e.g. with the file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete *.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,citecolor=cvprblue]{hyperref}

%% New commands
\newcommand{\card}[1]{\lvert\mathcal{#1}\rvert}
\def\thesection{\Alph{section}}
%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\paperID{15137} % *** Enter the Paper ID here
\def\confName{CVPR}
\def\confYear{2025}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Gradient-Guided Annealing for Domain Generalization}

%%%%%%%%% AUTHORS - PLEASE UPDATE
\author{Aristotelis Ballas\\
	Dpt of Informatics and Telematics\\
	Harokopio University of Athens\\
	Omirou 9, Tavros, Athens, Greece\\
	{\tt\small aballas@hua.gr}
	% For a paper whose authors are all at the same institution,
	% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Christos Diou\\
Dpt of Informatics and Telematics\\
Harokopio Univesity of Athens\\
Omirou 9, Tavros, Athens, Greece\\
{\tt\small cdiou@hua.gr}
}

\begin{document}
%\maketitle

\clearpage
\setcounter{page}{1}
\maketitlesupplementary

The following materials are provided in this supplementary file:
\begin{itemize}
	\item An extended literature review discussion, helpful for navigating the Domain Generalization literature under the scope of computer vision.
	\item A computational analysis regarding the application of GGA.
	\item Detailed results for each dataset domain and algorithm, presented in Table 2 of the main text, along with extra experiments on the ColoredMNIST and RotatedMNIST datasets.
\end{itemize}

\section{Extended Literature Review}
\label{sec:extended-lit-review}

Domain Generalization (DG) \cite{wang2022generalizing} is arguably one of the 
most difficult and fundamental problems of Machine Learning (ML) today. 
Unsurprisingly, a vast number of researchers have poured effort into advancing the field, where findings have been applied to various areas, such 
as Natural Language Processing \cite{hupkes2023taxonomy}, Reinforcement Learning \cite{li2018learning}, Healthcare and Medicine \cite{9298838, 10233054}, Time-Series forecasting \cite{du2021adarnn}, Fault Diagnosis 
\cite{9174912} and, of course, Computer Vision \cite{wang2022generalizing}. 
Even though not covering the entire field of DG, this section aims to present 
a taxonomy of the general DG methodologies developed in CV, for producing 
robust models that can generalize to previously unseen data, and attempts to 
assist potential readers navigate the past literature, while also 
categorizing our proposed method among its predecessors. 
Domain Generalization methods can be categorized into three major groups, depending on their operation during the process of model training, namely: 
(a) Data Manipulation, (b) Representation Learning and, (c) Learning 
Algorithm. Furthermore, as mentioned in the main text, DG algorithms can 
either leverage domain labels during training (multi-source), or completely
disregard the knowledge of existing domain shifts in their training data and 
handle them as a single distribution (single-source). 
%An illustration of the above taxonomy is presented in Fig. \ref{fig:taxonomy}. 

\textbf{Data Manipulation}. As its name suggests, methods 
included in this group focus on either perturbing existing samples (\textit{data augmentation}) or creating novel ones (\textit{data generation}), 
in order to regularize the training of machine learning models, avoid 
overfitting and improve their generalizability. The basic idea in data 
manipulation methodologies is to simulate domain shift by creating diverse 
data samples, which can in turn mimic the entirety of distributions present 
in the input space. Regarding data augmentation, most popular techniques 
include traditional image transformations, such as random flip, rotation and 
color distortion. Even though these augmentations can be randomly applied 
during training, without needing domain labels, it has been shown that their 
selection significantly affects model performance. For example, the 
authors of \cite{volpi2019addressing} define novel augmentation rules that 
push the perturbed images to diverge as much as possible from the original 
ones. Additionally, image augmentations prove effective towards overcoming 
domain shifts in medical image classification \cite{otalora2019staining, zhang2020generalizing}, where transformations can replicate shifts caused by 
the use of different devices. On the other hand, multiple data augmentation 
methods were also inspired by adversarial attacks and use adversarial gradients to distort the input images \cite{volpi2018generalizing, qiao2020learning}, or use randomly initialized convolutional networks for transforming samples \cite{choi2023progressive}. These techniques act as regularizers during model training, allowing them to learn generalizable image representations. The generation of novel data domains is also a well 
researched area in the data manipulation group. In addition to using domain gradients for synthesizing novel domains \cite{shankar2018generalizing}, 
several methods took advantage of style transfer \cite{huang2017arbitrary} 
and either map the styles of images to that existing source domains \cite{borlino2021rethinking} or create novel styles \cite{yue2019domain}. On a similar note, mixing the styles of training images by conventional methods  \cite{xu2020interdomain_mixup_aaai, zhou2021mixstyle} or with the generative models \cite{wang2024multi} also proves beneficial.



\textbf{Representation Learning}. This group of methods is arguably the most 
prominent in DG and has been the central focus of ML \cite{6472238}. 
Following the formulation in the main text, given a labeling function $h$ 
that maps input observations $\bm{x}$ to their labels $y$, we can decompose it into $h = f \circ g$, where $g$ is a parametric function that learns 
representations of $x$ and $f$ is the classifier function. The goal of 
representation learning can be summarized as follows:

\begin{equation}
	\min_{f, g} \mathbb{E}_{x,y} \ell(f(g(\bm{x}; \bm{\theta})), y) +\lambda\ell_\text{reg}
\end{equation}
where $\ell$ the loss function to be minimized and $\ell_\text{reg}$ a 
regularizer. Methods included in this group, focus on learning a robust and generalizable representation learning function $g$. The algorithms included 
in this group can be further categorized into three sub-groups. \textit{Feature disentanglement} \cite{Zhang_2022_CVPR} methods intend to extract disentangled feature vectors from samples, where each dimension can be linked to a subset of data generating factors. The main idea is to produce a model that extracts a representation that can be further decomposed into domain-specific, domain-invariant, and class-specific features. To that end, the authors of \cite{piratla2020efficient} present CSD, which jointly learns a domain-invariant and domain-specific component in the final embedding and enables the extraction of disentangled representations, whereas the authors of \cite{chattopadhyay2020learning} propose learning domain specific 
masks during training to improve model robustness. Generative models have also been proposed in the disentangled representation learning literature for DG, with variational autoencoders (VAEs) and GANs \cite{chen2016infogan} being utilized for learning distinct latent subspaces for class- and domain-specific features \cite{ilse2020diva}. Another promising category of 
methods aiming to produce disentangled representations is that of 
Causality-Inspired algorithms. In causal representation learning, a domain 
shift can be thought of as an intervention, subsequentially leading the development of models that aim to uncover the true causal data generating factors. Naturally, the prediction of a model should not be affected by interventions on spuriously correlated but irrelevant features, such as the background, color or style of the image. Under this causal consideration, the authors of \cite{mahajan2021domain} propose a structural causal model in 
order to model within-class variations and leverage the fact that inputs 
across domains should have the same representation, given that they derive 
from the same object. Similar to disentangled representations, there have 
been proposed methods in the literature that focus on completely disregarding 
domain-relevant from the final feature vectors, deriving solely 
domain-invariant representations. Based on the initial findings of \cite{ben2006analysis}, numerous works have presented algorithms that aim to minimize the representation differences across multiple source domains within a specific feature space, ensuring they become domain invariant, ultimately enabling the trained model to effectively generalize to previously unseen domains. In one of the most notable previous 
works in this category, Arjovsky et al. \cite{arjovsky2019irm} enforce the 
optimal classifier on top of the representation space to be the same across domains and simultaneously minimize the loss across distributions. The above 
idea of Invariant Risk Minimization (IRM) has been extended to several other
works. For example, the authors of \cite{krueger2021out} propose minimizing 
the variance of source-domain risks, by minimizing their extrapolated risk, 
while the authors of \cite{zhang2020arm} propose adapting to domain shift and 
producing invariant representations. Finally, an alternative route towards
learning generalized representations is via regularization strategies. 
The most representative group of methods in this category is \textit{Gradient-Based operations}, which utilize gradient information during 
model training. In \cite{huang2020rsc}, the authors propose learning robust
representations by discarding the most dominant gradients in each training 
iteration under the assumption that they are correlated with domain-specific
features present in the source data. Another popular strategy is to seek for 
flat minima \cite{foret2020sharpness, cha2021swad} in the loss landscape of 
neural networks during training, assuming that models that converge to flat minima exhibit increased generalization capabilities \cite{zhuang2022surrogate, wang2023sharpness}. 
What's more, Shi et al. \cite{shi2021gradient} hypothesized that gradients 
among domains should match and proposed an approximation of a loss inducing the maximization of the gradient inner product during training. Our method (GGA) can be categorized in this group of gradient operations, as it considers
the similarity of domain gradients in the early iterations of model training
and seeks for sets in the parameter space with increased gradient alignment, before continuing the optimization procedure. 

\textbf{Learning Algorithm}. In addition to manipulating the input space or 
feature extractor, DG methods were also researched under the scope of 
alternative ML learning paradigms, such as \textit{ensemble}, \textit{meta}, \textit{domain-adversarial}, \textit{self-supervised} and 
\textit{reinforcement} learning. In this section we present the most exemplary
works in each category. \textit{Ensemble-Learning} in DG initially combined
several copies of the same network, each of which is trained on a specific 
domain \cite{zhou2021domain, ding2017deep}. Alternatively, instead of using several networks, \cite{yosinski2014transferable} proposed sharing shallow 
layers among CNNs. During inference, the final prediction is produced by 
either simple \cite{zhou2021domain} or weighted averaging 
\cite{wang2020dofe}. In \textit{Meta-Learning} for DG, Li et al. \cite{li2018learning} propose MLDG and split the source domains into 
meta-train and meta-test splits to mimic the effects of domain shift during 
training. Similarly, \cite{balaji2018metareg} proposes learning a meta regularizer for the classifier, while MAML \cite{finn2017model} was proposed
for improved parameter initialization. Another approach is that of \textit{Adversarial Learning} (AL). In the context of DG, the aim of 
adversarial learning is to train a classifier to distinguish between source domains \cite{matsuura2020domain} and ultimately learn domain-agnostic 
features from the samples that can be generalized to unseen data 
\cite{li2018deep}. Other learning paradigms such as \textit{Self-Supervised} 
learning have also been explored in DG, which leverages unlabeled data 
samples to derive generalized representations. Notably, the authors of 
\cite{carlucci2019domain} introduce a self-supervised jigsaw-solving puzzle 
task to push the model to learn robust representations. Furthermore, 
contrastive learning has also been shown to improve model performance. 
Specifically, SelfReg \cite{kim2021selfreg} utilizes self-supervised contrastive losses to bring latent representations of same-class samples closer. Similarly, the authors of \cite{ballas2024multi} introduce 
a contrastive loss for representations extracted from intermediate 
layers of the network. Finally, \textit{Reinforcement learning} has also been 
applied in the context of DG. Indicatively, previous works have explored randomizing the environments of an RL agent for transferring them to 
real-world scenarios \cite{tobin2017domain,lee2019network}, whereas \cite{laskin2020curl} researches the combination of RL with contrastive 
learning.

\section{Computational Analyis}
\label{computation}

\subsection{Experiment Infrastructure}
\label{experiment-infra}

Each and every experiment is conducted on a cluster containing $4\times40$GB NVIDIA A$100$ GPU cards, split into $8$ $20$GB virtual MIG devices and $1\times24$GB NVIDIA RTX A$5000$ GPU card, via a SLURM workload manager.

\subsection{Complexity Analysis}
\label{sec:complexity}

Each GGA training iteration includes computing model gradients $S\cdot n_a$ times for each training step, where $S$ is the number of source domains and $n_a$ is the number of search steps. These GGA training iterations only take place in the early stages of training and for a small percentage of the total training iterations (2\% in our experiments). The rest of the iterations are vanilla ERM. Furthermore, inference is not affected by the application of GGA 
during training.

 
\section{Full Experimental Results}
\label{sec:full-results}
In this section, we show detailed results of Table 2 in the main text.
The results marked by $\dagger, \ddagger$ are copied from Gulrajani and
Lopez-Paz \cite{gulrajani2020domainbed} and Wang \etal 
\cite{wang2023sharpness}, respectively. Standard errors for the baseline methods are reported from three trials, if available from past literature.
In {\color{green} green} and {\color{red} red}, we highlight the performance boost and decrease of applying \textbf{GGA} on top of each algorithm respectively, averaged over three trials. In addition, we also present 
detailed results for the DomainNet benchmark, without however including 
results for the combination of GGA with the baseline algorithms, due to 
computational restrictions. We also include experiments for the ColoredMNIST and RotatedMNIST datasets, where we reproduced the results for all baselines and report the average results over 5 runs. The below tables are better read in color.

When applying GGA to existing methods, the only difference regarding the baseline algorithm training is that ``Algorithm 1'' (i.e. GGA)  is applied instead of the methodâ€™s update rules for the duration of the annealing process (training steps $A_s$ to $A_e$). The total epochs and method hyperparameters remain the same throughout training.


%\subsection{PACS}
\input{detailed_tables/pacs_detailed}

%\subsection{VLCS}
\input{detailed_tables/vlcs_detailed}

%\subsection{OfficeHome}
\input{detailed_tables/officehome_detailed}

%\subsection{TerraIncognita}
\input{detailed_tables/terrainc_detailed}

%\subsection{DomainNet}
\input{detailed_tables/domainnet_detailed}

%\subsection{CMNIST}
\input{detailed_tables/mnist_detailed}


\clearpage
\clearpage

\bibliographystyle{ieeenat_fullname}
\bibliography{supp}


% WARNING: do not forget to delete the supplementary pages from your submission 
% \input{sec/X_suppl}







\end{document}
