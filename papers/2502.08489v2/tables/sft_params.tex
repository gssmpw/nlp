\begin{table}[ht!]
\centering
\small
\begin{tabular}{lc}
\toprule
Hyperparameter & Value \\
\midrule
Optimizer & AdamW \\
Momentum ($\beta_1$,$\beta_2$) & [ 0.9 , 0.999 ] \\
Epsilon & 1e-8 \\
Learning Rate Schedule & Cosine \\
Warmup Ratio & 0.03 \\
Peak Learning Rate & 1e-5 \\
% Final Learning Rate & 0.0 \\
Sequence Length & 8192 \\
Global Batch Size & 256 \\
Weight Decay & 0.0 \\
Gradient Clipping & 1.0  \\
NEFTune Noise $\alpha$ & 5 \\
Epochs & 2  \\ \bottomrule
\end{tabular}
\caption{Instruction-tuning hyper-parameters\\ for Salamandra Instructed 2B and 7B.}
\label{tab:sft_params}
\end{table}