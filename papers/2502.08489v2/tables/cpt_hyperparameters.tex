\begin{table}[h!]
	\centering
	\begin{tabular}{l|ccc}
	\toprule
    & \textbf{2B}  & \textbf{7B}  & \textbf{40B}\\
	\midrule
	Peak Learning Rate & $2 \times 10^{-5}$ & $3  \times 10^{-5}$ & WiP \\
    Min. Learning Rate & $2 \times 10^{-6}$ & $3  \times 10^{-6}$ &  \\
    GQA & No & Yes &  \\
	Activation Function   & \multicolumn{3}{c}{SwiGLU} \\
	Vocabulary Size       & \multicolumn{3}{c}{256,000} \\
    Optimizer & \multicolumn{3}{c}{AdamW ($\beta_1=0.9, \beta_2=0.95, \epsilon=1^{-8}$)} \\
    Scheduler & \multicolumn{3}{c}{CosineAnnealing} \\
    Warmup Steps & \multicolumn{3}{c}{0} \\
    Constant Steps & \multicolumn{3}{c}{0} \\
	Positional Embeddings & \multicolumn{3}{c}{RoPE ($\theta=10,000$, $pctg=1.0$)} \\
    Gradient Clipping & \multicolumn{3}{c}{1.0} \\
    Weight Decay & \multicolumn{3}{c}{0.1} \\
    Floating-point Precision & \multicolumn{3}{c}{BFloat16} \\
	\bottomrule
	\end{tabular}
	\caption{Continued Training Phase hyper-parameters for Salamandra 2B, 7b and 40B.}
	\label{tab:continued_training}
\end{table}