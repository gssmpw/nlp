Tool use, also known as function calling, is the ability of an LLM to generate calls to external tools (e.g. APIs) and use the results from executing those calls to generate the response.

This capability is usually built on top of the multi-turn prompt-response paradigm used for instruction tuning, extending the alternating user-assistant turns to include the call and response to tools or functions. In practice, this means that the LLM on each assistant turn that it generates can either produce a response to be shown to the user, or a JSON structure representing the desired function call. In the latter case, the execution environment will need to execute the call and insert the result as a conversation turn (with a corresponding role labeled as "tool" or similar).

The ability to use tools can greatly augment the capabilities of an LLM and provides a convenient framework to connect an LLM to the external world, by allowing it to retrieve up-to-date information, interact with databases, or control potentially any kind of external systems that can expose functions or an API to do so. Tool use can also the LLMs own capabilities, e.g. by accessing a calculator to solve math problems, or even generate and execute code to solve a wide range of problems that are not well-suited for an LLM to resolve on its own.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/tools/tools.png}
    \caption{The diagram illustrates a simple workflow where the LLM receives a prompt from the user and processes it to understand the intent. Based on this, it either generates a direct response or connects to external tools or functions to perform specific tasks. Once the tools return their results, the LLM processes the tool response and provides a final answer to the user, showcasing seamless interaction between the user, the LLM, and the tools.}
    \label{fig:tool-usage"}
\end{figure}

\subsubsection{Frameworks and compatibility}
Recently, several frameworks have emerged that offer seamless compatibility with tool calls, simplifying their use and enhancing the capabilities of tools. For smooth integration between tools and frameworks, it is essential for the tool to adhere to a specific chat-template format. In our case, we adopted the chat-template from NousResearch's models, which utilizes the widely adopted and compatible ChatML format. This format is compatible with various frameworks, including vLLM. By leveraging this chat-template, we can efficiently deploy models through the vLLM API in the context of function calling.
With this configuration, the model generates responses for tool calls within the \texttt{<tool\_call>} tags. However, by passing a custom system prompt or directly modifying it within the chat-template, the model can produce responses in different formats. This flexibility is achieved by training the model on datasets that include diverse system prompts and corresponding tool response outputs, depending on the specific system prompt used.

The input format below in table \ref{tab:chatml_tools} is a direct extension of the instruction format shown in table \ref{tab:chatml}.

\input{tables/chatml_dialogue_tools}

Furthermore, by using the vLLM API, the model becomes compatible with the CHAT-UI framework from Hugging Face. This framework enables the model to interact with users and utilize Hugging Face's spaces as tools for problem-solving. Internally, this framework integrates web search functionality, allowing the model to perform real-time web searches during user interactions. This significantly enhances the model's retrieval-augmented generation (RAG) capabilities, enabling it to go beyond its static knowledge base and retrieve up-to-date information from external sources.

A complete example of using the tool use functionality can be found in Appendix \ref{app:tool_use_example}.

\subsubsection{Data Mixture}
For the instruction tuning of the model with compatibility in mind, we utilized various datasets in addition to those used for instruction tuning without tools.

We first leveraged existing openly available tool use datasets to add basic function calling capabilities to the model.

\begin{itemize}
    \item \textbf{Base datasets:} We used the dataset \texttt{glaiveai/glaive-function-calling-v2} from Hugging Face. This dataset was chosen for its diverse range of conversations involving tool usage and its substantial size, enabling the model to effectively learn and generalize from the data. 
    Additionally, we incorporated the dataset \texttt{NousResearch/hermes-function-calling-v1} from Hugging Face. This dataset was instrumental in training the model to generate responses in a specific format, enhancing its compatibility with a wider range of frameworks.
\end{itemize}

\begin{itemize}
    \item \textbf{Extended versatility:} we identified certain limitations with the initial datasets, as these primarily trained the model to respond in a single fixed format, even when instructed otherwise in the system prompt. To overcome this limitation and enable the model to understand and generate responses in different tool formats specified by the system prompt, we utilized the dataset \texttt{Team-ACE/ToolACE} from Hugging Face. This enhancement made the model more versatile, allowing users to instruct it to adopt one format or another for its responses.
\end{itemize}

We then created additional datasets to complement the training data, providing data in Catalan and Spanish, as well as reinforcing some of the application domains we had been working on. This work is currently in progress, and the datasets will be published upon completion. Both datasets are created using synthetic data generation using an LLM.

\begin{itemize}
    \item \textbf{RAG as tool use:} The first dataset is an automatic conversion of the RAG\_Multilingual dataset\footnote{\url{https://huggingface.co/datasets/projecte-aina/RAG_Multilingual}} to teach the model to make retrieval calls when necessary in order to answer questions.
    \item \textbf{Conversational agents:} The second is generated based on XitXat\footnote{\url{https://zenodo.org/records/7276036}}\cite{carme_armentano_oller_2022_7276036}, a multilingual dataset featuring a multi-turn conversational format. The original dataset contained conversations with intent annotations which have been automatically converted to corresponding tool calls.
\end{itemize}

\subsubsection{Preliminary results}
As mentioned, the function calling capability is still work-in-progress and is not currently included in the instructed Salamandra models. Experimental builds of Salamandra 7b with function calling are capable of making basic tool calls such as retrieving content from the web or internal databases, or using a calculator, when provided with such tools. However, no formal evaluation of the performance of this model has been done yet, and in particular the use of tools throughout more complex conversations is still being improved.

The Salamandra 7b model with tool use works well with Hugging Face's chat-ui frontend\footnote{\url{https://github.com/huggingface/chat-ui}}, and is capable of making use of custom functionality exposed through Hugging Face's Gradio-based Spaces. A demo is being prepared to be made publicly soon.