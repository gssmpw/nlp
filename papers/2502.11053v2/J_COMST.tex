% \newcommand{\CLASSINPUTbottomtextmargin}{1in}
% \newcommand{\CLASSINPUTtoptextmargin}{2.4cm}
 %\documentclass[journal, a4paper]{IEEEtran}
\documentclass[journal]{IEEEtran}
%\usepackage{flushend}
\def\subparagraph{} % because IEEE classes don't define this, but titlesec assumes it's present
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{*1}{*1}
\titlespacing{\subsection}{0pt}{*1}{*1}

\renewcommand{\thesubsubsection}{\arabic{subsubsection}}

\titleformat{\subsubsection}[runin]{\itshape}{\thesubsubsection)}{1em}{}
\titlespacing*{\subsubsection}{\parindent}{0pt}{*1}
%\setlength{\textfloatsep}{1\baselineskip plus 0.2\baselineskip minus 0.5\baselineskip}
% \usepackage{layout}
% \setlength{\textfloatsep}{\baselineskip plus 0.2\baselineskip minus 0.2\baselineskip}
\usepackage{verbatim}
\usepackage{amsmath,amssymb,amsfonts}
% \usepackage{algorithmic}
% \usepackage{algorithm}
\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}
\usepackage{algorithm2e}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage[sort&compress,numbers]{natbib}
%\usepackage[latin]{babel}
%\usepackage[latin]{babel}
%\usepackage{stfloats}
% macro in aux fileb
%\usepackage{hyperref}
\usepackage{acronym}
%\usepackage{multicols}
\usepackage[T1]{fontenc}
%\usepackage{libertine}
\usepackage{balance}
\usepackage{enumitem}
\usepackage{url}
\usepackage{cuted}%w<<<<<<<<<<
\usepackage[makeroom]{cancel}
\usepackage{lipsum}
%\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{pdfpages}
\usepackage{mathrsfs}
\usepackage{bm}
%\usepackage{float}
% \usepackage{dblfloatfix}%% float equations
% \usepackage{multicol}
% \usepackage{multicol}
%\usepackage{caption}
%\usepackage{subcaption}
%\usepackage{appendix}
\usepackage[caption=false]{subfig}
\captionsetup[subfigure]{font=footnotesize,labelfont=footnotesize}

\usepackage{amsthm}
\theoremstyle{definition}
%\newtheorem{theorem}{Theorem}
\newtheorem{theorem}{Theorem}%[subsubsection]
%\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
%\theoremstyle{definition}
\newtheorem{definition}{Definition}%[subsubsection]
%\theoremstyle{proposition}
\newtheorem{proposition}{Proposition}%[subsubsection]
%\theoremstyle{remark}
\newtheorem{remark}{Remark}%[subsubsection]

%\newtheorem{corollary}{Corollary}[proposition]
\newtheorem{corollary}{Corollary}%[subsubsection]
\usepackage{mathrsfs}
\hyphenation{op-tical net-works semi-conduc-tor}
%\usepackage[toc,page]{appendix}


\def\BibTeX{{\rm B\kern-.05emb{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\newcommand{\diag}[1]{\mathrm{diag}({#1})}


% Pie chart drawing library
%\usepackage{pgf-pie}

\usepackage{tikz}
\usepackage{circuitikz}
\usetikzlibrary{positioning}
%\usepackage{pgf}
\usepackage{pgfkeys}
\usetikzlibrary{spy}

\usepackage{pgfplots}

\usepgfplotslibrary{groupplots} % LATEX and plain TEX
\usepgfplotslibrary[groupplots] % ConTEXt
\usetikzlibrary{pgfplots.groupplots} % LATEX and plain TEX
\usetikzlibrary[pgfplots.groupplots] % ConTEXt


% and optionally (as of Pgfplots 1.3):
\pgfplotsset{compat=newest}
\pgfplotsset{plot coordinates/math parser=false}
\usepackage{pgfplotstable}
\newlength\figureheight
\newlength\figurewidth

\usetikzlibrary{positioning}
\usetikzlibrary{patterns}

\usetikzlibrary{arrows.meta,positioning}
\tikzset{block/.style={draw, rectangle, fill=cyan!90,
        minimum height=2em, minimum width=3em},
    sum/.style={draw, circle, node distance=1cm},
    input/.style={coordinate},
    output/.style={coordinate},
    pinstyle/.style={pin edge={to-,thin,black}},
        saturation block/.style={%
            draw,
            path picture={
                % Get the width and height of the path picture node
                \pgfpointdiff{\pgfpointanchor{path picture bounding box}{south west}}%
                {\pgfpointanchor{path picture bounding box}{north east}}
                \pgfgetlastxy\x\y
                % Scale the x and y vectors so that the range
                % -1 to 1 is slightly shorter than the size of the node
                \tikzset{x=\x*.4, y=\y*.4}
                %
                % Draw annotation
                \draw [very thin] (-1,0) -- (1,0) (0,-1) -- (0,1);
                \draw [very thick] (-1,-.7) -- (-.7,-.7) -- (.7,.7) -- (1,.7);
            },
        }
    }

\tikzset{%
        rateLimit block/.style={%
            draw,
            path picture={
                % Get the width and height of the path picture node
                \pgfpointdiff{\pgfpointanchor{path picture bounding box}{south west}}%
                {\pgfpointanchor{path picture bounding box}{north east}}
                \pgfgetlastxy\x\y
                % Scale the x and y vectors so that the range
                % -1 to 1 is slightly shorter than the size of the node
                \tikzset{x=\x*.4, y=\y*.4}
                %
                % Draw annotation
                %\draw [very thin] (-1,-1) -- (-1,1) (-1,-1) -- (1,-1);
                \draw [very thin] (-1,0) -- (1,0) (0,-1) -- (0,1);
                \draw [very thick] (-1,-1) -- (1, 1);
            },
        }
    }

     \usetikzlibrary{svg.path}
     \usepackage{scalerel}
\usepackage{hyperref}
%\usepackage[hidelinks]{hyperref}
    \definecolor{orcidlogocol}{HTML}{A6CE39}
    \tikzset{
      orcidlogo/.pic={
        \fill[orcidlogocol] svg{M256,128c0,70.7-57.3,128-128,128C57.3,256,0,198.7,0,128C0,57.3,57.3,0,128,0C198.7,0,256,57.3,256,128z};
        \fill[white] svg{M86.3,186.2H70.9V79.1h15.4v48.4V186.2z}
                     svg{M108.9,79.1h41.6c39.6,0,57,28.3,57,53.6c0,27.5-21.5,53.6-56.8,53.6h-41.8V79.1z M124.3,172.4h24.5c34.9,0,42.9-26.5,42.9-39.7c0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z}
                     svg{M88.7,56.8c0,5.5-4.5,10.1-10.1,10.1c-5.6,0-10.1-4.6-10.1-10.1c0-5.6,4.5-10.1,10.1-10.1C84.2,46.7,88.7,51.3,88.7,56.8z};
      }
    }

    \newcommand\orcidicon[1]{\href{https://orcid.org/#1}{\mbox{\scalerel*{
    \begin{tikzpicture}[yscale=-1,transform shape]
    \pic{orcidlogo};
    \end{tikzpicture}
    }{|}}}}


\begin{document}
%\title{Enhanced BICM Receiver Metrics for Ultra-Reliable\\Low-Latency Short Block Channel Communications}

\title{Demystifying 5G Polar and LDPC Codes: A Comprehensive Review and Foundations}

\author{\IEEEauthorblockN{ Mody~Sy~\textsuperscript{\orcidicon{0000-0003-2841-2181}}},~\IEEEmembership{Member IEEE}

\thanks{Manuscript prepared on February 11, 2025. The author is with the Department of Communication Systems, EURECOM, BIOT, 06410, France (e-mails: mody.sy@eurecom.fr).}
}
\makeatletter
\patchcmd{\@maketitle}
  {\addvspace{0.5\baselineskip}\egroup}
  {\addvspace{-1\baselineskip}\egroup}
  {}
  {}
\makeatother
% <-this % stops a space
%\thanks{Manuscript received April 19, 2021; revised August 16, 2021.}}
% The paper headers
%\markboth{IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS,~Vol.~14, No.~8, August~2021}%
%\markboth{IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS,~Vol.~x, No.~x, January~20xx}%
%{Sy \MakeLowercase{\textit{et al.}}: Enhanced BICM Receiver Metrics for Ultra-Reliable\\Low-Latency Short Block Channel Communications}
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

%\balance
\begin{abstract}
This paper serves as a comprehensive guide for practitioners and scholars aiming to understand the channel coding and decoding schemes integral to the 5G NR standard, with a particular focus on LDPC and polar codes. We start by explaining the design procedures that underlie these channel codes, offering fundamental information from perspectives of both encoding and decoding. In order to determine the present status of research in this area, we also provide a thorough literature review. Notably, we add comprehensive, standard-specific information to these foundational evaluations that is frequently difficult to extract from technical specification documents. The significance of reviewing and refining the foundations of the aforementioned codes lies in their potential to serve as candidate error-correcting codes for the future 6G standard and beyond.
\end{abstract}

\begin{IEEEkeywords}
Linear block codes,  5G NR Polar code, 5G NR LDPC code;
\end{IEEEkeywords}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:introduction}
\IEEEPARstart{T}{he} Channel coding emerged when Shannon applied probability theory to the study of communication systems \citet{Shannon48}. In his seminal work , Shannon demonstrated that errors introduced by a noisy channel can be reduced to a desired level through the use of an appropriate coding scheme, for a transmission rate that is less than or equal to the channel's capacity. To optimize the performance of communication channels, various techniques can be employed to mitigate the effects of noise, disturbances, or distortions, while increasing the channel throughput until it approaches its maximum capacity. This can be achieved either by physically modifying the signal through modulation or by altering its content through channel coding. Most error-correcting codes are linear codes, which, due to their systematic representation, are classified as systematic codes.  
Linear block codes can be understood in a variety of ways, and some of the most commonly used in many contexts are {\em Reed Solomon} (RS) codes \citep{Whitaker1991}, Hamming codes \citep{Hamming1950}, \acs{CRC} codes, {\em Bose–Chaudhuri–Hocquenghem} (BCH) codes \citep{Hocquenghem1969} and LDPC codes \citep{Gallager63}.
It is possible to represent a linear block code in matrix form or in the form of a graph factor.
\begin{itemize}
  \item\texttt{ Generator Matrix:}
  $\mathbf{G}$ is the generator matrix of dimension $\mathsf  K\times \mathsf N$.
  The matrix is said to be {\em systematic} if $\mathbf{G} = [\mathbf{P}\ \mathbf{I}_\mathsf K]$ where $\mathbf{I}_\mathsf K$ and $\mathbf{P}$ is called the parity matrix of dimension ($\mathsf K \times \mathsf{N - K}$). In this case, the code is formed by parity bits followed by message bits.\\
  The matrix $\mathbf{G}$ is said to be {\em non-systematic} if $ \mathbf{G} = [\mathbf{P}\ \mathbf{M}]$ where $\mathbf{M}$ is any matrix of size ($\mathsf K \times \mathsf K$).
  \item \texttt{Parity Check Matrix:}
$\mathbf{H}$ is called the parity check matrix denoted as $\mathbf{H} = [\mathbf{I}_\mathsf{N-K}\ \mathbf{P}^{\mathsf T}]$, where $\mathbf{P}^{\mathsf T}$ is the transpose of the parity matrix $\mathbf{P}$. Thus, it can be easily shown that $\mathbf{G} \cdot \mathbf{H}^{\mathsf T}= \mathbf  0$, where operations are performed in $\mathbb{F}_2$.
  \item \texttt{Syndrome Checking:}
  For each code word $\mathbf{c}$: $\mathbf{c} \cdot \mathbf{H}^{\mathsf T} = \mathbf m \cdot \mathbf{G} \cdot \mathbf{H}^{\mathsf T} = \mathbf 0 $, where $\mathbf m = [\mathrm m(0), \mathrm m(1), \ldots, \mathrm m(\mathsf K-1)]$.
  If $\mathbf{c} \cdot \mathbf{H}^{\mathsf T} \neq \mathbf{0}$, it means there are errors in the received bits.
\end{itemize}


In 5G NR, data and control streams from \acs{PHY} to \acs{MAC} layer are encoded /decoded to offer transport and control services over the radio transmission link. Channel coding scheme is a combination of error detection, error correcting, rate matching, interleaving and transport channel or control information mapping onto/splitting from physical channels.

Table \ref{tab:5.3-1} and Table \ref{tab:5.3-2} show
the usage of coding scheme for the different types of Transport channels and for the different control information types \citep{3GPP38212}.
\begin{table}[htbp]
  \centering
  \caption{ Usage of channel coding scheme for {\em transport channels} {(TrCHs)}. \citep{3GPP38212}}
    \begin{tabular}{l|l}
    %\toprule
     \hline
    TrCH  & Coding scheme \\
   \hline
    \acs{UL-SCH} & LDPC \\
    \hline
    \acs{DL-SCH} & LDPC \\
    \hline
     \acs{PCH}   &  Polar code\\
 \hline
     \acs{BCH}   & Polar code \\
    \hline

    \end{tabular}%
  \label{tab:5.3-1}%
\end{table}%


% Table generated by Excel2LaTeX from sheet 'page-1_table-1'
\begin{table}[htbp]
  \centering
  \caption{Usage of channel coding schemes within  5G NR UL/DL control channels \citep{3GPP38212}.}
    \begin{tabular}{l|l}
   % \toprule
   \hline
    Control Information & Coding scheme \\
    %\midrule
    \hline
    \acs{DCI} & Polar code \\& Block code \\
    \hline
    \acs{UCI}   & Polar code \\
     \hline
    %\bottomrule
    \end{tabular}%
  \label{tab:5.3-2}%
\end{table}%


This paper serves as a guide and reference for both practitioners and scholars interested in understanding channel coding and decoding schemes, particularly the Low-Density Parity-Check (LDPC) and polar coding methods adopted in \acs{5G} and beyond, in line with 3GPP standard specifications. It highlights important information that can be difficult to extract from the {\em technical specification} documents established by the standard.

Notably, we enrich the foundational reviews of the main features of these two coding schemes with many standard-specific details, such as rate adaptation procedures, the application of Cyclic Redundancy Check (CRC), and aspects like decoding algorithms. The refinement and deeper understanding of these coding schemes are particularly relevant, as they are strong candidates for error correction in future 6G standards and beyond.

The article  is structured as follows. Section II and Section III lays out the foundations and detailed reviews of 5G NR LDPC codes and 5G NR Polar codes respectively, Section IV presents the numerical results and performance analysis, and finally Section V concludes the paper.

Furthermore, the following is a list of acronyms that the reader will encounter throughout the manuscript:
%\subsection{Accronyms}
%\begin{verbatim}
\input{Figures/acronymes_sec}
%\end{verbatim}
\section{5G NR LDPC Codes}
 It is a curious twist of history that \acs{LDPC} codes should have been largely unnoticed for so long. LDPC codes were originally proposed in 1962 by Gallager \citep{Gallager63} . At that time, the codes might have been overlooked because contemporary investigations in concatenated coding overshadowed LDPC codes and because the hardware of the time could not support effective decoder implementations\citep{Moon2005}. They therefore remained discrete until 1996 after the introduction of iterative decoding, initiated by the turbo codes\citep{Berrou1993}.
 Since then, {LDPC} codes have shown interesting performance and a relatively uncomplicated implementation.
 MacKay, working on Turbo codes at that time, gave a second birth to {LDPC} codes \citep{MacKay1997} and brings {LDPC} codes back into fashion. This article by Mackay presents constructions of {LDPC} codes and shows their good performance.
 Later, Luby, introduces irregular {LDPC} codes \citep{Luby1998} characterized by a parity check matrix for which the distribution of the number of non-zero elements per row and/or column is not uniform. {LDPC} codes are linear block codes based on sparse parity-check matrix. It is forgotten for dozens of years because of the limited computation ability. In recent years, {LDPC} codes attract more attention because of their efficient decoding algorithms, excellent error-correcting capability, and their performance close to the Shannon limit for large code lengths.
 {LDPC} coding  is currently adopted in 5G NR for both uplink and downlink shared transport channels. Given that 5G must support high data rates of up to 20 Gbps and a wide range of block sizes with different coding rates for data channels and {\em hybrid automatic repeat request} (HARQ), {LDPC} codes are a de facto candidate to meet these requirements. Indeed, the base graphs defined in 3GPP TS 38.212 \citep{3GPP38212} are structured parity-check matrix, which can efficiently support HARQ and rate compatibility that can support arbitrary amount of transmitted information bits with variable code rates. While  Polar codes are applied to 5G {NR} control channels, {LDPC} codes are suitable for 5G NR shared channels due to its high throughput, low latency, low decoding complexity and rate compatibility. Another advantage of the NR 5G codes is that the performance of the LDPC codes has an error floor around or below the $10^5$ \acs{BLER} for all code width and code rates, making {LDPC} codes, an essential channel coding scheme for \acs{URLLC} application scenarios.
\subsection{State-of-art LDPC codes}
In reviewing the literature, significant efforts have been directed towards enhancing the error correction performance of 5G communication systems.
The discourse surrounding channel coding in cellular systems, particularly for 5G, initially emphasized turbo, \acs{LDPC}, and polar codes, with LDPC codes adopted for eMBB data and polar codes for control \citep{Shao2019}.  In this regard, \citet{Srisupha2022} developed an experimental kit demonstrating {LDPC} encoding processes, emphasizing flexibility between software and hardware {LDPC} encoders. Subsequently, \citet{Belhadj2021} compared error correction performance between {LDPC} and polar codes in 5G {\em machine-to-machine  ({M2M}) communications}, highlighting specific requirements for different {M2M} applications. Later on, \citet{Li2023} proposed dynamic scheduling strategies to reduce decoding complexity and improve error correction performance for short {LDPC} codes. Next, in a perspective of accelerated {LDPC} decoding, \citet{Tian2022} presented a base graph-based static scheduling method for layered decoding of 5G {LDPC} codes, achieving notable reductions in iteration numbers and performance enhancements. In \citep{Hamidi-Sepehr2018, bae2019}, authors investigated the structure and features of the base graphs \citep{3GPP38212}, showing that the usage of a circularly shifted identity matrix known as the permutation matrix can greatly reduce the memory requirement for implementation. Indeed, 5G {LDPC} base graphs design aims to provide row orthogonality for fast and reliable decoding. Row orthogonality in 5G {LDPC} base graphs design can somehow reduce decoding latency. Both base graphs and all code rates involve puncturing code bits associated with the first two circulant columns prior to transmission, targeting high-weight columns for performance enhancement. Therefore, puncturing serves as a means of improving overall system performance \citep{bae2019}. Additionally, 5G {LDPC} fully utilizes the double diagonal structure of the base graphs. Due to the characteristic of base graphs, the double-diagonal structure can make {LDPC} encoding more efficient. Conversely, \citep{Nguyen2019} proposed a novel efficient encoding method and a high-throughput low-complexity encoder architecture for 5G NR \acs{LDPC}.

Furthermore, efforts have been directed towards optimizing implementations of these codes for heightened performance on software and hardware targets. For instance, \citet{Liao2021} present a high-throughput LDPC encoding on a single {\em graphics processing unit} (GPU), while \citet{Tarver2021} explore GPU-based LDPC decoding, showcasing potential for high throughput and low latency applications in 5G and beyond. Additionally, hardware architectures have been developed to efficiently decode LDPC codes, as seen in the work of \citet{Nadal2021}, who propose a highly parallel {\em field-programmable gate array} (FPGA) architecture. Conversely, \citet{Xu2019} focus on software decoding with SIMD acceleration on Intel Xeon CPUs, achieving notable throughput with low latency. \citet{sy2023_ldpc} proposed optimisation strategies for low-latency 5G LDPC decoding over GPPs. Meanwhile, \citet{Li2021_ldpc} addressed the challenge of achieving high throughput rates, proposing a multicore LDPC decoder architecture achieving up to 1 Tb/s throughput for beyond 5G systems, while \citet{Aronov2019} compare LDPC decoding performance between GPU and FPGA platforms, stressing the need for further optimization, particularly in reducing latency for GPU-based solutions.

Moreover, the selection of coding schemes for 5G eMBB services has been a focus of interest, with {\em quasi-cyclic} LDPC and polar codes chosen for data and control channels, respectively. \citet{Rao2019} highlighted the importance of these codes, particularly QC-LDPC, and \citet{Wu2019} proposed an efficient QC-LDPC implementation for 5G NR, enhancing throughput by matrix pruning. \citet{Ivanov2023} introduced a novel concatenated code construction comprising outer and inner LDPC codes, demonstrating reduced decoding complexity and superior performance. Additionally, \citet{Song2023} emphasized the significance of well-designed LDPC codes, particularly QC-LDPC codes, in approaching channel capacity and enabling high-speed data transmission. In parallel, LDPC codes' adoption in 5G standards underscores their importance in broadcasting and cellular communication systems  \citet{Ahn2019}.  Moreover, \citet{Cui2021} tackled the challenge of designing high-performance and area-efficient decoders, while \citet{Trung2019} and \citet{Jayawickrama2022} proposed adaptations and improved algorithms for LDPC decoding in 5G NR. Additionally, \citet{Li2020} focused on LDPC code design for specific 5G scenarios, proposing optimization methods and an improved decoding algorithm. \citet{Wu02019} provided insights into LDPC decoding latency in 5G NR, guiding decoder design to meet high throughput and low latency requirements. In \citet{Sun2018} proposed a hybrid decoding algorithm for LDPC codes in 5G, where {normalized min-sum algorithm} (NMSA) decoding and linear approximation are combined, with only a slight increase in complexity for NMSA and an improved performance much closer to {\em belief propagation} \acs{BP} decoding, especially for low-rate codes.


Recently, there has been a growing interest in applying deep learning techniques to various aspects of 5G communications, as reviewed by \citet{Dai2021}. \citet{Shah2021} proposed {\em normalized least-mean-square} (NLMS) algorithms to enhance the decoding performance of 5G LDPC codes, leveraging {\em deep neural networks} (DNNs) to optimize parameters. \citet{Tang2021} introduced a scheme combining model-driven deep learning with traditional BP decoding algorithms to adapt LDPC codes for different 5G scenarios. Lastly, \citet{Andreev2021} investigated the application of DNNs to improve the decoding algorithms of short
QC-LDPC codes in the 5G standard, addressing the curse of dimensionality problem and enhancing performance.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Foundations and Fundamentals}
The LDPC code is presented in matrix form
$[\mathbf{G}, \mathbf{H}]$, where $\mathbf{G}$ is the generator matrix of the code and $\mathbf{H}$ is the {\em parity check matrix} (PCM). The parity matrix $\mathbf{H}$ is sparse, containing very few ones. It can be represented in the form of a {\em Tanner graph}. This graph consists of two types of nodes: {\em bit nodes} (BNs) and {\em check nodes} (CNs) which are connected by edges. The BNs and CNs correspond, respectively, to the columns (code word bits) and rows (parity constraints) of the matrix $\mathbf{H}$. A variable node $i$ is connected to a check node $j$ if $\mathbf{H}(i;j) = 1$. This graph is bipartite, since nodes of the same type cannot be connected (i.e., a CN cannot be connected to another CN). Tanner graphs are commonly used to represent the parity matrix in LDPC codes. A Tanner graph leads to decoding algorithms of fairly low complexity \citep{Moon2005}.

%%% insert
\begin{equation}\label{eqn:pcm_ldpc}
\mathbf H=
\left[\begin{array}{llllllll}
0 & 1 & 0 & 1 & 1 & 0 & 0 & 1 \\
1 & 1 & 1 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 1 & 1 & 1 \\
1 & 0 & 0 & 1 & 1 & 0 & 1 & 0
\end{array}\right]
\end{equation}

The number of variable nodes equals the number of received bits ($N$), which is equivalent to the number of columns in the matrix $\mathbf{H}$. Similarly, the number of parity check nodes corresponds to the number of rows $(\mathsf N-\mathsf K)$ in the matrix $\mathbf{H}$.
\begin{figure}[ht]
    \centering
      \includegraphics[width=0.8\linewidth]{Figures/ldpc/1_graph_tanner.pdf}
      %\input{Figures/ldpc/tanner_graph.tex}
       \caption{ Parity check matrix $\mathbf H (4, 8)$ and the corresponding Tanner graph.}
       \label{fig:tanner_graph}
\end{figure}

The most important element in the realization of a good LDPC code is the  $\mathbf H$ matrix which will condition the quality of the iterative decoding.
There are four important parameters to respect in order to obtain a good $\mathbf H$ parity check matrix.
\begin{enumerate}
  \item \emph{Code Rate}.
We can increase the rate of an LDPC code by adding 1s in the lines of the Matrix $\mathbf H$.

If the parity matrix is regular, it can also be denoted ($\mathrm N$, $w_c$, $w_d$), where $w_b$ represents the weight of a row and $w_b$ represents the weight of a column.
 The yield can be calculated as a function of $w_c$ and $w_b$ by $ \mathrm R=1-w_b/w_c$
  \item \emph{short cycles (girth)}. The generation of short cycles in the equivalent Tanner graph of the code must be avoided. A cycle represents from a given variable node the set of parity and variable nodes that will be connected to it until we fall back on the starting variable node.
We call girth the minimum cycle length that can be encountered in a Tanner graph.
Short cycles are very penalizing because they involve few intermediate nodes, and thus the extrinsic information they generate during decoding becomes quickly and strongly correlated.
\item \emph{Size of $\mathbf H$}. A large matrix allows better coding Rate and consequently better performance.
\item \emph{Construction algorithm of $\mathbf H$}. 
To construct the regular parity matrix, there are mainly two methods: the random method and the deterministic method.
The most known random methods in the literature for the construction of the $\mathbf H$-matrix are the Gallager method \citep{Gallager63} and the {\em progressive Edge Growth} (PEG) method \citep{Xiao-Yu2004} which makes it possible to create graphs with large girths. For the deterministic method, the most used is the Quasi-cyclic method. The latter uses a deterministic construction based on a circular permutation of the identity matrix \citep{Wu2019, Zhang2010}.
QC-LDPC codes belong to the class of structured codes that are relatively easier to implement without significantly compromising the performance of the code. Well-designed QC-LDPC codes have been shown to outperform computer-generated random LDPC codes, in terms of bit-error rate and block-error rate performance and the error floor. These codes also offer merits in decoder hardware implementation due to their cyclic symmetry, which results in simple regular interconnection and modular structure\citep{Ahmadi2018}.
\end{enumerate}

\subsection{3GPP 5G LDPC Codes}
NR LDPC code is a family of QC-LDPC codes. It is constructed from a matrix named $\mathbf H_{\mathsf{BG}}$ of dimension $M \times N$ called {\em base graph} matrix $\mathbf{BG}$. The $\mathbf H_{\mathsf{BG}}$ matrices are selected in the 5G NR coding process according to the coding rate and the length of the transport block or code block. Thus, for
$\mathbf{BG}_\mathsf 1$ ($N = 68$, $M = 46$) and for $\mathbf{BG}_\mathsf 2$ ($N = 52$, $M = 42$). Since $\mathbf{BG}_\mathsf 1$ is targeted for larger block length $\mathsf K \leq 8448$ and coding rates between $1/3 \leq \mathrm R \leq 8/9$, $\mathbf{BG}_\mathsf 2$ is employed for small blocks $\mathsf K \leq 3840$ and coding rates between $1/5 \leq \mathrm R \leq2/3$.

For $\mathbf{BG}_\mathsf{1}$, $\mathrm K=22\mathrm{Z_c}$ and for $\mathbf{BG}_\mathsf{2}$, $\mathrm K=10\mathrm{Z_c}$, where $\mathsf K$ is the maximum number of information bits, and $\mathrm{Z_c}$ is the lifting size shown in Table \ref{tab:lift_size}. There are 51 lifting sizes from 2 to 384 for each base graph. Both $\mathbf{BG}_\mathsf{1}$ and $\mathbf{BG}_\mathsf{2}$ have the same block structure. The columns include information columns, core parity columns, and extension parity columns. The rows are divided into core check rows and extension check rows.

For $\mathbf{BG}_\mathsf{1}$, $\mathbf A$ is a $4\times 22$ matrix; $\mathbf A$ is a $4 \times 4$ matrix; $\mathbf O$ is $4 \times 42$ all zero matrix; $\mathbf B$ is a $42 \times 22$ matrix; $\mathbf C$ is a $42 \times 4$ matrix; $\mathbf I$ is $42 \times 42$ identity matrix;\\
For $\mathbf{BG}_\mathsf{1}$, $\mathbf A$ is a $4 \times 10$ matrix; $\mathbf E$ is a $4\times 4$ matrix; $0$ is $4 \times 38$ all zero matrix;
$\mathbf B$ is a $38 \times10$ matrix; $\mathbf C$ is a $38 \times 4$ matrix; $\mathbf I$ is $38\times38$ identity matrix;
Sub-matrix $\mathbf E$ is a double diagonal matrix that is benefit for encoding. An example of $\mathbf{BG}_\mathsf{1}$ with set {\em index of listing size} (iLS) =$1$ in 3GPP TS 38.212\citep{3GPP38212} standard is shown in Figure~\ref{fig:BG_struct}. In order to distinguish with the number $1$ in base graphs in 3GPP TS 38.212 \citep{3GPP38212} standard, null value in the base graph will be replaced by $-1$.
\begin{figure}[ht]
    \centering
         \includegraphics[width=0.8\linewidth]{Figures/ldpc/bg_struc.pdf}%\input{Figures/ldpc/BG_struct.tex}
         \caption{ 3GPP NR Base graphs structure.}
       \label{fig:BG_struct}
\end{figure}
In 3GPP TS 38.212 \citep{3GPP38212} standard, the maximum lifting size value for each set of iLS is shown in Table~\ref{tab:lift_size}. The value of each element $\mathsf{p_{i,j}}$ also known as the circular shift value is from -1 to 383, which is a property of the $\mathbf{BG}$s.

\begin{table}[htbp]
  \centering
  \caption{Sets of LDPC lifting size \citep{3GPP38212}}
    \begin{tabular}{c|l}
    %\toprule
    \hline
    Set index (iLS) & Set of lifting sizes (Z) \\
    \hline
    0     & 2, 4, 8, 16, 32, 64, 128, 256 \\
    \hline
    1     & 3, 6, 12, 24, 48, 96, 192, 384 \\
    \hline
    2     & 5, 10, 20, 40, 80, 160, 320 \\
    \hline
    3     & 7, 14, 28, 56, 112, 224 \\
    \hline
    4     & 9, 18, 36, 72, 144, 288 \\
    \hline
    5     & 11, 22, 44, 88, 176, 352 \\
    \hline
    6     & 13, 26, 52, 104, 208 \\
    \hline
    7     & 15, 30, 60, 120, 240 \\
    %\bottomrule
    \hline
    \end{tabular}%
  \label{tab:lift_size}
\end{table}%

NR LDPC codes also offer an additional coding advantage at lower code rates, rendering them suitable for scenarios requiring high reliability. Regarding decoding complexity, opting for $\mathbf{BG}_\mathsf{2}$ proves advantageous due to its compactness and utilization of a larger lifting size element, translating to enhanced parallelism compared to $\mathbf{BG}_\mathsf{1}$. The decoding latency tends to correlate with the number of non-zero elements in the base graph, with $\mathbf{BG}_\mathsf{2}$ exhibiting significantly lower latency than $\mathbf{BG}_\mathsf{1}$ for a given code rate, owing to its fewer non-zero elements \citep{Ahmadi2018}.\\
Furthermore, the parity-check matrix $\mathbf H$ is obtained by replacing each element of the base graph $\mathbf H_{\mathsf{BG}}$ with a $\mathrm{Z_c} \times  \mathrm{Z_c}$ matrix, according to the following rules.
\begin{itemize}
  \item Each element of value $-1$ in $\mathbf H_{\mathsf{BG}}$ is replaced by a null matrix of size $\mathrm{Z_c} \times  \mathrm{Z_c}$.
  \item Each element of value $0$ in $\mathbf H_{\mathsf{BG}}$ is replaced by an identity matrix  $\mathbf I$  of size  $\mathrm{Z_c} \times  \mathrm{Z_c}$.
  \item Each element of value from 1 to $\mathrm{Z_c}-1$ in $\mathbf H_{\mathsf{BG}}$ which is denoted by $\mathsf{p_{i,j}}$ is replaced by a circular permutation matrix $\mathbf I(\mathsf{p_{i,j}})$ of size  $\mathrm{Z_c} \times  \mathrm{Z_c}$,
  where $i$ and $j$ are the row and column indices of the element, and $\mathbf I(\mathsf{p_{i,j}})$ is obtained by circularly shifting the identity matrix $\mathbf I$ of size  $\mathrm{Z_c} \times  \mathrm{Z_c}$ to the right $\mathsf{p_{i,j}}$ times \citep{3GPP38212}.
\end{itemize}

The main advantage of using a circularly shifting identity matrix is that it can reduce the memory requirement for implementation \citep{bae2019}.\\
To simplify, a small example can be used to explain the principle of obtaining the parity check matrix $\mathbf H$. Hence,  assuming that $\mathbf H_\mathsf{{BG}}$ is a given base graph matrix with lifting size $\mathrm{Z_c}$=4,
\begin{equation}
\mathbf H_{\mathsf{BG}}=\left[\begin{array}{cccccc}
\textcolor{cyan}{2} & \textcolor{violet}{-1} & \textcolor{orange}{1} & \textcolor{brown}{3} & \textcolor{green}{0} & \textcolor{violet}{-1} \\
\textcolor{orange}{1} & \textcolor{green}{0} & \textcolor{violet}{-1} & \textcolor{green}{0} & \textcolor{green}{0} & \textcolor{green}{0} \\
\textcolor{violet}{-1} & \textcolor{brown}{3} & \textcolor{cyan}{2} & \textcolor{orange}{1} & \textcolor{violet}{-1} & \textcolor{green}{0}
\end{array}\right],
\end{equation}
the corresponding parity check matrix $\mathbf H$ is shown to be:
%\input{Figures/ldpc/matrix_H}
\begin{equation}
\includegraphics[width=0.8\linewidth]{Figures/ldpc/H-MATRIX.pdf}.
\end{equation}
The overall LDPC transmission chain from  MAC/PHY layer processing schematic is depicted  in Figure~\ref{fig:ldpc_tranceiver_chain}, which describes the transmit-end for the PUSCH/PDSCH supporting a transport block CRC attachment, LDPC base graph selection,  code block segmentation and code block CRC attachment, LDPC encoding, rate matching code block concatenation. The receiver end is therefore  the transmitter end in the reverse flow.
\begin{figure*} [!ht]
    \centering
  \subfloat[\scriptsize {Transmitter end.}\label{fig:tx_ldpc}]{ %\input{Figures/ldpc/c1_v2.tex}
  \includegraphics[width=0.8\linewidth]{Figures/ldpc/tx_ldpc1.pdf}
  }
 \\
  \subfloat[\scriptsize {Receiver end.}\label{fig:rx_ldpc}]{  \includegraphics[width=0.9\linewidth]{Figures/ldpc/rx_ldpc1.pdf}}
\caption{Conceptual illustration of 5G LDPC transceiver chain.}
\label{fig:ldpc_tranceiver_chain}
\end{figure*}
At the transmitter end, we can list the following components.
\begin{enumerate}
  \item {\em Transport block CRC attachment}.\\
\acs{CRC} is an error detection code used to measure {BLER} after decoding. The entire transport block is used to calculate CRC parity bits. Assume that the transport message before CRC attachment is $a(0), a(1),\ldots, a(A-1)$, where A is the size of the transport block message. Parity bits are  $p(0), p(1),\ldots, p(L-1)$, where $L$ is the number of parity bits. The parity bits are generated by one of
the following cyclic generator polynomials\citep{3GPP38212}.
if $A > 3824$, the generator polynomial $\mathrm g_\mathsf{CRC24A}(\beta)$ is used.
\begin{equation}
\begin{array}{r}
\mathrm g_\mathsf{CRC24A}(\beta)=\left[\beta^{24}+\beta^{23}+\beta^{18}+\beta^{17}+\beta^{14}+\beta^{11}+\beta^{10}\right. \\
\left.+\beta^7+\beta^6+\beta^5+\beta^4+\beta^3+\beta+1\right].
\end{array}
\end{equation}
The length of parity bits $L= 24$.
Otherwise, the generator polynomial $\mathbf g_{CRC16}(\beta)$ is used.
\begin{equation}
\displaystyle\mathrm g_\mathsf{CRC16}(\beta)=\left[\beta^{16}+\beta^{12}+\beta^5+1\right].
\end{equation}
The length of parity bits $L=16$.
The message bits after attaching CRC are $b(1), b(2),\ldots, b(B)$, $B$ represents the transport block information size with CRC bits such that $B = A + L$.\\
\begin{equation}
b_k=\left\{\begin{array}{ll}
a_k, & \texttt { \footnotesize{for} } k=0,1, \ldots, A-1 \\
p_{k-A}, & \texttt { \footnotesize{for} } k=A, A+1, \ldots, A+L-1.
\end{array}\right.
\end{equation}
The CRC value  was determined to satisfy the probability of misdetection of the TB with BLER $\sim$ $10^6$ as well as the inherent error detection of LDPC code.
\item {\em LDPC base graph selection}.\\
LDPC $\mathbf{BG}$ is selected based on the transport block message size $A$ and transport block coding rate $\mathrm R$. If $A\leq292$, or if $A\leq3824$ and $\mathrm R\leq0.67$, or if $\mathrm R \leq 0.25$, LDPC $\mathbf{BG}_\mathsf{2}$ is used. Otherwise, LDPC $\mathbf{BG}_\mathsf{1}$ is used \citep{3GPP38212}.
\item Code block segmentation and code block CRC attachment.\\
The input message to CB segmentation is a transport message with CRC, denoted as $b(1), b(2),\ldots, b(B)$, where $B$ is the input message length. Assume that the maximum code block length is $\mathsf K_{cb}$, where $\mathsf K_{cb} = 8448$ for $\mathbf{BG}_\mathsf{1}$ and $\mathsf K_{cb} = 3840$ for $\mathbf{BG}_\mathsf{2}$. Code block segmentation is based on the following rules. \\
Assume that $C$ is the number of code blocks.\\
\texttt{if} $B \leq  \mathsf K_{cb} $,
\begin{equation}
C=1, \quad L=0, \quad B_r=B.
\end{equation}
\texttt{Otherwise,}
\begin{equation}
C=\left[B /\left(\mathsf K_{c b}- L\right)\right],  \quad L=24, \quad B_r=B+C \cdot L.
\end{equation}


Assume that the output of code block segmentation is  $c_r(0), c_r(1),\ldots, c_r(\mathrm K_r-1)$, $\mathrm K_r =\mathrm K $ is the number of bits for the $r$-th code block.
For $\mathbf{BG}_\mathsf{1}$, $\mathrm K= 22\mathrm{Z_c}$ and for $\mathbf{BG}_\mathsf{2}$, $\mathrm K=10\mathrm{Z_c}$, where $\mathrm{Z_c}$ is a lifting size that is the minimum value of $\mathrm{Z_c}$ in all sets of lifting sizes in Table \ref{tab:lift_size} which can meet formula (\ref{eqn:cb_seg_compute}).
\begin{equation}\label{eqn:cb_seg_compute}
\mathsf K_b \cdot \mathrm{Z_c} \geq \mathrm K_r
\end{equation}

Where $\mathrm K_r$ is the number of information and CRC bits in a code block and $\mathrm K_r = B_r/ C$. $\mathsf K_b$ is related with LDPC base graph type and the size of input message $B$, shown in Table \ref{tab:kb_value}.

\begin{table}[htbp]
\centering
\caption{$\mathsf K_b$ value [\citep{3GPP38212}}
\begin{tabular}{l|l|l}
\hline
$\mathbf{BG}$ & $ B$     & $\mathsf K_b$ \\
\hline
1     & all   & 22 \\
\hline
2     & $B$ $>$ 640 & 10 \\
\hline
2     & 560 $<$ $B$ $\leq$ 640 & 9 \\
\hline
2     & 192 $<$ $B$ $\leq$ 560 & 8 \\
\hline
2     & $B$ $\leq$192 & 6 \\
\hline
\end{tabular}%
\label{tab:kb_value}%
\end{table}%

The output of code block segmentation $c_{r,k}$ is calculated as following,\\
If $C = 1$,
\begin{equation}
c_{r,k}=\left\{\begin{array}{l l}
b_k, & \texttt { \footnotesize{for} } 1 \leq k \leq B \\
\texttt{NULL}, & \texttt { \footnotesize{for} }  B+1 \leq k \leq \mathrm K .
\end{array}\right.
\end{equation}
If $C > 1$, block code should be attached CRC using the generator polynomial $\mathrm g_\mathsf{CRC24B}(\beta)$, the length of parity bits $L = 24$.
\begin{equation}
\mathrm g_\mathsf{CRC24B}(\beta)=\left[\beta^{24}+\beta^{23}+\beta^6+\beta+1\right].
\end{equation}
Assume that CRC parity bits are $p_r(1), p_r(2),\ldots, p_r(L)$, 
\begin{equation}
c_{r,k}=\left\{\begin{array}{ll}
b_k, & \texttt { \footnotesize{for} } 1 \leq k \leq \mathrm K_r-\mathrm L \\
p_{r\left(k+ L-\mathrm K_r\right)}, & \texttt { \footnotesize{for} } \mathrm K_r-\mathrm L+1 \leq k \leq \mathrm K_r \\
\texttt{NULL}, & \texttt { \footnotesize{for} } \mathrm K_r+1 \leq k \leq \mathrm K,
\end{array}\right.
\end{equation}
where $1 \leq r \leq C$ and $\mathrm K$ is the maximum number of information bits for base graphs.

\item {\em LDPC encoding}.\\
Each  CB message is encoded independently. 
The input bit sequence in a CB to be passed to the LDPC encoder can be represented as $\mathbf c_r = [c_r(0), c_r(1),\ldots, c_r(\mathrm K_r-1)]^{\mathsf T}$, where $\mathrm K_r$ is the number of information bits within a CB to encode, the redundant bits are called parity bits denoted by $\mathbf w=[w(0), w(1),\ldots, w(\mathrm N_r+2 \mathrm{Z_c}-\mathrm K_r-1)]^{\mathsf T}$. The output LDPC coded bits are denoted by $d_r(0), d_r(1),\ldots, d_r(\mathrm N_r-1)$ where $\mathrm N_r=66\mathrm{Z_c}$ for $\mathbf{BG}_\mathsf{1}$ and $\mathrm N_r=50\mathrm{Z_c}$ for $\mathbf{BG}_\mathsf{2}$, where the value of lifting factor $\mathrm{Z_c}$ is given in Table \ref{tab:lift_size}. The LDPC encoding is based on the following procedure \citep{3GPP38212}.
\begin{enumerate}
  \item Find the set with index iLS in Table \ref{tab:lift_size} which contains $\mathrm{Z_c}$.
  \item Set $d_{r,{k-2 \mathrm{Z_c}}}=c_k, \forall k=2 \mathrm{Z_c}, \ldots, \mathrm K_r-1$.
  \item Generate $\mathrm N_r+2 \mathrm{Z_c}-\mathrm K_r$ parity bits $\mathbf w=[w(0), w(1),\ldots, w(\mathrm N_r+2 \mathrm{Z_c}-\mathrm K_r-1)]^{\mathsf T}$ such that $\mathbf H \times \left[ \mathbf c_r \ \mathbf w \right]^{\mathsf T}=\mathbf{\mathbf 0}$.
  \item The encoding is performed in $\mathbb F_2$.
  \item Set $d_{r,{k-2 \mathrm{Z_c}}}=w_{k-\mathrm K_r}, \forall k=\mathrm{K_r}, \ldots, \mathrm N_r+2 \mathrm{Z_c}-1$.

\end{enumerate}
  \item {\em Rate matching}:\\
  The rate matching aims to adapt different code rates. Rate matching is based on \emph{redundancy version} (RV) from 0 to 3 \citep{3GPP38212}. Each RV divides the base graph, excluding the first two columns, into four chunks at different positions. 
  Note that the first two columns are always punctured to improve performance. RV $0$ is well suited for the first transmission and has good self-decodability \citep{wang2021}. 
  
  Hence, the rate matching is carried out on each code block independently. Assume that the coded message bit output from the LDPC encoder of the $r-th$ code block is $d_r(1), d_r(2),\ldots, d_r(\mathrm N_r)$ and $E_r$ is the length of the output message after performing rate matching on this  $r-th$ coded message. Thus, the  output bit-message from the rate matcher is denoted by  $e_r(1), e_r(2),\ldots, e_r(E_r)$ which is calculated using the following equation:
\begin{equation}
e_{r,k}=d_{r,k}, \texttt{\footnotesize{ if }} d_{r,k} \neq \texttt{NULL},  \texttt{\footnotesize{ where }} 1 \leq k \leq  E_r.
\end{equation}

\item {\em Code block concatenation}:\\
The CB concatenation aims to concatenate all code blocks message to a sequence of transport block message, which will be transmitted through the physical channel.
Assume that the output message of code block concatenation is $g(1), g(2),\ldots, g(G)$, where $G$ is the desired length of the message of the transport block.
  \begin{equation}
  g_\ell=e_{r,k}, \texttt{\footnotesize{ where }} 1 \leq \ell \leq G, \quad 1 \leq k \leq E_r.
  \end{equation}
\end{enumerate}

%%%%%%%%%%%%%
Conversely, the receiver counterpart, is simply the reverse flow of the transmitter,  and set out as follows :
 \begin{enumerate}
   \item {\em Code block de-concatenation.}\\
   The CB de-concatenation is used to break the transport block message into C numbers of code blocks message. Assume that the input message to code block de-concatenation is $y(0), y(1),\ldots, y(G-1)$. The output message from code block de-concatenation is $f_r(0), f_r(1),\ldots, f_r(E_r-1)$ .
\begin{equation}
f_{r,k}=y_\ell,  \texttt{\footnotesize{ where }} 1 \leq \ell \leq G,\quad 1 \leq k \leq E_r.
\end{equation}

   \item {\em Rate de-matching.} \\
   The rate de-matching  aims to covert the code block message to the format that can be used for 5G LDPC parity-check matrix to process decoding. Rate de-matching is done on each code block independently. Assume that the input message is  $f_r(0), f_r(1),\ldots, f_r(E_r-1)$. The output message from rate de-matching is $g(0), g(1),\ldots, g(N_r+2\mathrm{Z_c}-1)$ 
   \begin{equation}
   g_k=\left\{\begin{array}{ll}
   0, & \texttt { \footnotesize{for} } 1 \leq k \leq 2 \mathrm{Z_c}, \\
   f_k, & \texttt { \footnotesize{for} } 2 \mathrm{Z_c}+1 \leq k \leq E_r ,\\
   0, & \texttt { \footnotesize{for} } E_r+1 \leq k \leq \mathrm N+2 \mathrm{Z_c}.
   \end{array}\right.
   \end{equation}

   \item {\em LDPC decoding}.\\
   The LDPC decoding is done on each code block independently, and many decoding algorithms can be used. Subsection~\ref{subsection:ldpc_decoding} highlights different LDPC decoding algorithms.
   \item Code block de-segmentation.
   The CB de-segmentation is used to extract the message bits and transport block attached CRC bits. Assume that the output from code block de-segmentation is $\hat{b}(0), \hat{b}(1),\ldots, \hat{b}(B-1)$, where $B$ is the size of original transport block information with attached CRC bits. The input to the code block de- segmentation is $h_r(0), h_r(1),\ldots, h_r(\mathrm N+2\mathrm{Z_c}-1)$

   \begin{equation}
   \hat{b}_k=h_{r,s}, \texttt{\footnotesize{ where }} 1 \leq k \leq B,\quad 1 \leq s \leq \mathrm K_r-L. 
   \end{equation}
    $\mathrm K_r$ is the number of information and CRC bits in a code block and
   $L$ is the length of CRC bits in a code block.

   \item {\em CRC check}:\\
   The CRC detachment is used to extract the CRC bits in transport block after the information transmitted in 5G NR shared channels. Then the extracted CRC bits will be checked with the original CRC bits attached to transport block information before transmitted.

 \end{enumerate}





\subsection{Soft-Decision based LDPC decoding Algorithms}\label{subsection:ldpc_decoding}
The optimal performing method is soft-decision decoding, involving the computation of {\em log-likelihood ratios} (LLRs) and the exchange of extrinsic information between variable and parity nodes. This method is known by various names in the literature, such as the {\em belief propagation algorithm} (BPA), or {\em message massing algorithm} (MPA), or {\em sum product} (SPA) algorithm. Additionally, there is the {\em min-sum algorithm}(MSA), an approximate method with lower complexity compared to SPA. Various algorithmic variants are available, tailored to specific practical applications and necessitating simplifications for tractable implementation.

The message passing decoding can be divided into bit or variable nodes' operation, also called row operation, and check nodes' operation, also called column operation. A MPA  based on Pearl’s belief algorithm describes the iterative decoding steps. The message probability passed between check nodes and variable nodes can be
 called belief, such as $\mathrm q_{ij}$ and $\mathrm r_{ji}$ in Figures   \ref{fig:cknode_update} and \ref{fig:bitnode_update}.

% \begin{figure*}
%     \centering
%   \subfloat[\scriptsize {$\mathsf{CN}_1 \longrightarrow \mathsf{BN}_2$ .}\label{fig:C1V1}]{ %\input{Figures/ldpc/c1_v2.tex}
%   \includegraphics[width=0.32\linewidth]{Figures/ldpc/2_b_update.pdf}
%   }
% \hspace{2em}
%   \subfloat[\scriptsize {$\mathsf{CN}_4 \longrightarrow \mathsf{BN}_5$ .}\label{fig:C4V5}]{ \includegraphics[width=0.32\linewidth]{Figures/ldpc/3_b_update.pdf}}
%   \caption{Check Node Updates}
% \label{fig:cknode_update}
% \end{figure*}

\begin{figure}
    \centering
%\input{Figures/ldpc/c1_v2.tex}
  \includegraphics[width=0.8\linewidth]{Figures/ldpc/5_C_update.pdf}
  \caption{Check Node Updates: \scriptsize {$\mathsf{CN}_4 \longrightarrow \mathsf{BN}_5$ .}}
\label{fig:cknode_update}
\end{figure}

% \begin{figure*}
%     \centering
%   \subfloat[\scriptsize {$\mathsf{BN}_2 \longrightarrow \mathsf{CN}_1$.}\label{fig:V2C1}]{   \includegraphics[width=0.32\linewidth]{Figures/ldpc/4_C_update.pdf}}
%     \hspace{2em}
%   \subfloat[\scriptsize {$\mathsf{BN}_5 \longrightarrow \mathsf{CN}_4$  .}\label{fig:V4C4}]{%
%   \includegraphics[width=0.32\linewidth]{Figures/ldpc/5_C_update.pdf}}
%   \caption{Bit Node Updates}
% \label{fig:bitnode_update}
% \end{figure*}

\begin{figure}
\centering
\includegraphics[width=0.8\linewidth]{Figures/ldpc/4_C_update.pdf}
  \caption{Bit Node Updates: \scriptsize {$\mathsf{BN}_5 \longrightarrow \mathsf{CN}_4$.}}
\label{fig:bitnode_update}
\end{figure}


Index sets $\mathsf{BN}_{j\backslash i}$ and $\mathsf{CN}_{i\backslash j}$  are  based on the {\em parity check matrix} (PCM). Index set $\mathsf{CN_i}$ and $\mathsf{BN_j}$ correspond to all non-zero element on column $i$ and row $j$ of the PCM,  respectively.
Figure~\ref{fig:node_index_proc} a simple conceptual illustration of BN and CN index sets within the PCM provided in (\ref{eqn:pcm_ldpc}) for the specified values of $i=3$ and $j=2$.

 \begin{figure}
\centering
\includegraphics[width=0.8\linewidth]{Figures/ldpc/cnbn_update_ldpc.pdf}
\caption{Conceptual Illustration of CNs and BNs processing Within BN and CN index sets for the specified values of $i$ and $j$.}
  \label{fig:node_index_proc}
\end{figure}


Furthermore, the beliefs can be described via the following equations.
Assume that a sequence of information bits are independently $\mathbf c= [\mathrm c(0), \mathrm c(1), \ldots, \mathrm c(\mathrm N-1)]$.

and consider the following notation :
\begin{itemize}
  \item  $\mathsf{BN}_j$ = {Bit nodes connected to check node $j$},
  \item  $\mathsf{BN}_{j\backslash i}$ ={bit nodes connected to check node $j$}, excluding {bit node $i$},
  \item  $\mathsf{CN}_{i}$ = {check nodes connected to variable node $i$},
  \item  $\mathsf{CN}_{i\backslash j}$ ={check nodes connected to bit node $i$}, excluding check node $j$,
  \item  $p_i = p_r(\mathrm c_i = 1|\mathrm  y_i )$ , is the probability of $\mathrm c_k$ = 1.
  \item $\mathrm y_i$ is the channel sample at variable node $i$.
  \item The check-to-variable extrinsic message passing to the $j-th$ variable node from the $i-th$ check node is denoted by $\mathscr L\left(\mathrm r_{j i}\right)$ and $\mathscr L\left(\mathrm q_{i j}\right)$ is the variable-to-check extrinsic message.
\end{itemize}

The belief propagation algorithm is adaptable to representation in both probability and log domains, wherein probabilities are expressed as LLRs. Employing LLR domain decoding offers a reduction in implementation complexity, since multiplications in the probability domain can be equivalently represented as additions in the log domain.
Besides, many multiplications of probabilities involved could become numerically unstable, so the log domain algorithm is preferred \citep{Moon2005}.


\subsubsection{Sum Product Algorithm (SPA)}
The Sum Product Algorithm, also known as (BPA), constitutes a fundamental soft decision decoding approach where messages are conveyed as probabilities. The implementation of Belief Propagation  relies on the decoding algorithm introduced by Gallager \citep{Gallager63}.
For a transmitted LDPC encoded codeword, $\mathbf c$, the input to the LDPC decoder is the LLR value defined as follows :
\begin{equation}
\mathscr L\left(\mathrm c_i\right)=\log \frac{p_r\left(\mathrm c_i=0 \mid \texttt {\footnotesize{channel output for}}\ \mathrm c_i
\right)}{p_r\left(\mathrm c_i=1 \mid \texttt {\footnotesize{channel output for}} \ \mathrm c_i
\right)}.%=\log \frac{p_r\left(x_i=+1 \mid y_i\right)}{p_r\left(x_i=-1 \mid y_i\right)}
\end{equation}


%Where $\mathscr L(\mathrm c_i)$ is the input LLR fed to the decoder.
In each iteration, the algorithm updates its key components through horizontal and vertical processing steps.

The check  nodes to bit nodes operation ({\em horizontal processing} ) is based on (\ref{eqn:cknod_update}).
\begin{equation}\label{eqn:cknod_update}
\begin{aligned}
&\mathscr L\left(\mathrm r_{j i}\right)=\log \frac{\mathrm r_{j i}(0)}{\mathrm r_{j i}(1)}\\&=2 \tanh ^{-1}\left(\prod_{i^{\prime} \in \mathsf{BN}_{j\backslash i}} \tanh \left(\frac{1}{2} \mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right)\right), 
\\&=\left(\prod_{i^{\prime} \in \mathsf{BN}_{j\backslash i}}\operatorname{sign}\left(\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right)\right) \phi\left(\sum_{i^{\prime} \in \mathsf{BN}_{j\backslash i}} \phi\left(\left|\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right|\right)\right).
\end{aligned}
\end{equation}

Where $\phi(\mathbf {x})=-\log \left[\tanh \left(\frac{|\mathbf {x}|}{2}\right)\right]=\log \left(\frac{\mathrm{e}^{\mathbf {x}}+1}{\mathrm{e}^{\mathbf {x}}-1}\right)$ .%$\phi(x) = \log \frac{e^x+1}{e^x-1}$

The bit nodes to check nodes' operation ({\em vertical processing})is given by.
\begin{equation}\label{eqn:bitnod_update}
\mathscr L\left(\mathrm q_{i j}\right)=\mathscr L\left(\mathrm c_i\right)+\sum_{j^{\prime} \in \mathsf{CN}_{i\backslash j} } \mathscr L\left(\mathrm r_{j^{\prime} i}\right).
\end{equation}

%At the end of each iteration, $\mathscr L\left(Q_i\right)$ is  an update estimate of the LLR value for the transmitted bit $\mathrm c_i$.

\begin{equation}
\mathscr L\left(Q_i\right)=\mathscr L\left(\mathrm c_i\right)+\sum_{j^{\prime} \in \mathsf{CN}_{i}} \mathscr L\left(\mathrm r_{j^{\prime} i}\right).
\end{equation}


Where $\mathscr L(Q_i)$ is the output LLR from the decoder and can be used to make decision.

\begin{equation}
\hat{\mathrm c}_i=\left\{\begin{array}{lc}
1, & \text { if } \mathscr L\left(Q_i\right)<0 ,\\
0, & \text { else .}
\end{array}\right.
\end{equation}

Repeat the steps until the maximum iterations are done or $\mathbf {H\hat c^{\mathsf T}}=\mathbf 0$.


 \begin{algorithm} [!ht]
\centering
\includegraphics[width=1\linewidth]{Figures/ldpc/algorithm_dec_ldpc2.pdf}

  \label{fig:algo_ldpc_dec_spa}
\end{algorithm}
 The BP algorithm achieves near-optimal decoding performance, but suffers from high computational complexity. In order to find a better trade-off between performance and complexity, a number of efficient decoding algorithms have been proposed in the scientific literature.

\subsubsection{Min-Sum Algorithm (MSA)}
Min-Sum Algorithm (MSA) for LDPC decoding is a reduced complexity decoding algorithm with min-sum approximation compared to sum product algorithm  or belief propagation algorithm.
Indeed, the value of $\phi(x)$ decreases sharply to almost  when $x$ increases. So the smallest $\left|\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right|$ value dominates the summation $\displaystyle \sum_{i^{\prime} \in \mathsf{BN}_{j\backslash i}} \phi\left(\left|\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right|\right)$.
Thus, it comes
\begin{equation}
\sum_{i^{\prime} \in \mathsf{BN}_{j\backslash i}} \phi\left(\left|\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right|\right) \approx \phi\left(\min _{i \prime \in \mathsf{BN}_{j\backslash i}}\left(\left|\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right|\right)\right).
\end{equation}

A such approximation is used for MSA. For MSA, other computations are the same with SPA, except $\mathscr L\left(\mathrm r_{j i}\right)$.

\begin{equation}\label{eqn:msa_algo}
\mathscr L\left(\mathrm r_{j i}\right)=\left(\prod_{i \prime \in \mathsf{BN}_{j\backslash i}}\operatorname{sign}\left(\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right)\right) \cdot \min _{i \prime \in \mathsf{BN}_{j\backslash i}}\left(\left|\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right|\right).
\end{equation}

\subsubsection{Optimized Min-Sum Decoding Algorithm}
It is shown that the magnitude  of $\displaystyle \phi\left(\min _{i'}\left(\left|\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right|\right)\right) $ obtained in MSA is always
greater than the magnitude of $\displaystyle \sum_{i^{\prime} \in \mathsf{BN}_{j\backslash i}} \phi\left(\left|\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right|\right)$ obtained in SPA.
Outputs from variable nodes in MSA decoding are overestimated compared to SPA due to the approximation. There are several methods to optimize MSA to make the approximation more accurate. The two most popular methods are \emph{normalized min-sum algorithm(NMSA)} and \emph{offset min-sum algorithm(OMSA)} and are presented in \citep{Jinghu2005}. The idea behind NMSA and OMSA is to reduce the magnitude of variable node outputs.
%Assume that the magnitudes of variable nodes output of MSA, NMSA and
%OMSA are $\mathscr L^{\text\tiny{MSA}}$ , $\mathscr L^{\text\tiny{NMSA}}$ and $\mathscr L^{\text\tiny{OMSA}}$, respectively.
\begin{enumerate}[label=(\alph*)]
\item Normalized Min-Sum Algorithm, (\ref{eqn:msa_algo}) simply becomes:
\begin{equation}
\begin{aligned}
\mathscr L_{\texttt{\tiny NMSA}}\left(\mathrm r_{j i}\right)&=\left(\prod_{i \prime \in \mathsf{BN}_{j\backslash i}}\operatorname{sign}\left(\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right)\right) \\&\cdot \min _{i \prime \in \mathsf{BN}_{j\backslash i}}\left(\alpha\cdot\left|\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right|\right),
\end{aligned}
\end{equation}
where $\alpha$ is called normalization or scaling factor,  $\alpha \in ]0, 1)$.


\item Offset Min-Sum Algorithm, (\ref{eqn:msa_algo})  becomes:
\begin{equation}
\begin{aligned}
\mathscr L_{\texttt{\tiny OMSA}}\left(\mathrm r_{j i}\right)=&\left(\prod_{i \prime \in \mathsf{BN}_{j\backslash i}}\operatorname{sign}\left(\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right)\right) \\&\cdot \max\left(\min _{i \prime \in \mathsf{BN}_{j\backslash i}}\left(\left|\mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right|-\beta\right), 0 \right),
\end{aligned}
\end{equation}
 where $\beta \geq 0$ is the offset value.
\end{enumerate}

\subsubsection{Layered Belief Propagation  Algorithm}
 {\em Layered belief propagation} (\acs{LBP}) algorithm  is an adaptation of  the decoding algorithm presented in \citep{Hocevar2004}. In the LBP algorithm, the decoder executes CNPs based on a node-by-node mode until all check functions are satisfied, or the iteration reaches the maximum value \citep{Zhang2014}.
 The decoding loop iterates over subsets of rows ({\em layers}) of the PCM.
 %For each row, $i$, in a layer and each bit index, $j$, the implementation updates the key components of the algorithm based on these equations:

 A CNP is composed of a series of operations that update the values of $\mathscr L\left(\mathrm Q_i\right)$ and $\mathscr L \left(\mathrm r_{ji}\right)$ as follows:

 \begin{equation}
\begin{array}{l}
 \texttt{(1) Update Input LLRs }:\\  \quad \mathscr L\left(\mathrm q_{i j}\right)=\mathscr L\left(\mathrm Q_i\right)- \mathscr L\left(\mathrm r_{ji}\right).\\
  \texttt{(2) Perform CNP}  \\ \quad \mathscr L^\prime \left(\mathrm r_{ji}\right) =2 \tanh ^{-1}\left(\displaystyle \prod_{i^{\prime} \in \mathsf{BN}_{j\backslash i}} \tanh \left(\frac{1}{2} \mathscr L\left(\mathrm q_{i^{\prime} j}\right)\right)\right). \\
   \texttt{(3) Perform Output LLRs}   \\ \quad   \mathscr L^\prime\left(\mathrm Q_{i}\right)=\mathscr L \left(\mathrm q_{i j}\right)+ \mathscr L^\prime \left(\mathrm r_{ji}\right).
\end{array}
\end{equation}
 For each layer, the decoding stage (3) works on the combined input obtained from the current LLR inputs $=\mathscr L\left(\mathrm q_{i j}\right)$ and the previous layer updates $\mathscr L^\prime \left(\mathrm r_{ji}\right)$.


Because only a subset of the nodes is updated in a layer, the layered belief propagation algorithm is faster compared to the belief propagation algorithm. As shown in \citep{Zhang2014},  the convergence speed of the \acs{LBP} algorithm is about twice as fast as that of the \acs{BP} algorithm. To achieve the same error rate as attained with belief propagation decoding, use half the number of decoding iterations when using the layered belief propagation algorithm.

In the layered decoding approach, each layer operates on variable nodes and check nodes independently. The input {\em log-likelihood ratio} (\acs{LLR}) for a given layer is derived from the output LLR of the preceding layer.

Ultimately, the output LLR of the final layer serves as the output LLR of the decoding process, thereby informing the decision-making process.



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%    5G NR Polar Codes
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{5G NR Polar Codes}
Polar codes were first proposed by \citet{Arikan2009} in 2009. It has quickly become a research hot spot in the coding community, with the advantages of theoretical accessibility to the Shannon limit and simple compiled code algorithms.
Using polar codes as the channel coding scheme for 5G control channels \citep{3GPP38212} has demonstrated the significance of Arikan's invention, and its applicability in commercial systems has been  proven. This coding family achieves capacity rather than merely approaching it, since it is based on the idea of channel polarization. Moreover, polar codes can be used for any code rate and for any code lengths shorter than the maximum code length due to their adaptability.

Polar codes are the first type of forward error correction codes achieving the symmetric capacity for arbitrary binary-input discrete memoryless channel under low-complexity encoding and low-complexity {\em successive cancellation} (\acs{SC}) decoding with order of $\mathcal O(N\log N)$ for infinite length codes.
Polar codes are founded based on several concepts including channel polarization, code construction, polar encoding, which is a special case of the normal encoding process (i.e., more structural) and its decoding concept \citep{Elkelesh}.
The polar code is a type of block code, {\em but it is not a linear code}. Polar codes are constructed from non-linear transformations called polar transformations. They exploit properties of certain transformations to make certain parts of the code carry useful information, while other parts act as frozen bits whose value is fixed. They are constructed using the polar channel transform, generally based on the Hadamard transform, and have the particularity of approaching the capacity limit of the communication channel efficiently.
In short, although polar codes are block codes, they differ from more conventional linear codes and use non-linear transformations to achieve decoding performance close to the theoretical channel limit.
Furthermore, from the standpoint of 5G's physical channels, control information is typically transmitted with a relatively small number of information bits and a small block width, so a low coding rate with good performance in a lower BLER is required, and polar codes can meet this requirement.
\subsection{State-of-art Polar codes}
Polar codes have emerged as a key channel coding scheme for 5G NR \citep{Bioglio2021}. The trend in polar code design and decoding techniques has been driven by the need for efficient and reliable communication. These codes exhibit promising characteristics such as rate flexibility and low decoding latency, addressing crucial requirements for 5G systems. However, challenges persist, particularly in reducing latency without compromising reliability \citep{Gamage2020}. Efforts have been made to enhance the decoding process, such as the development of low latency decoders for short block length polar codes. Thus, \citet{Gamage2020} highlighted decoders that utilize simplified \acs{SC} algorithms combined with list decoding techniques to achieve the desired balance between reliability and latency in ultra-reliable low-latency communication systems. Subsequently, \citet{Geiselhart2020} leveraged CRC codes to aid belief propagation list decoding, improving error-rate performance while optimizing decoding complexity. Meanwhile, \citet{Piao2019} proposed innovative decoding algorithms like CRC-aided sphere decoding to enhance the performance of short polar codes. By utilizing CRC information, these algorithms provide stable performance across various code rates. Additionally, \citet{Cavatassi2019} introduced asymmetric coding schemes to allow for arbitrary block lengths, reducing decoding complexity while maintaining error correction performance. \citet{Shen2022} explored fast iterative soft-output list decoding to improve error-rate performance and decoding efficiency. \citet{Kaykac2020} highlighted that understanding the operation and performance of 5G polar codes is crucial as they are integral to the functionality of 5G control channels. \citet{Ercan2020} optimized practical implementations of polar code decoders, developing dynamic SC-flip decoding algorithms with reduced complexity. \citet{Kestel2020} quantified trade-offs between error-correction capability and implementation costs, crucial for achieving efficient high-throughput decoding in 5G systems. Moreover, \citet{ArliGazi2021} and \citet{Sun2019} proposed adaptive belief propagation algorithms and low-complexity decoding schemes, respectively, to address challenges in decoding polar codes efficiently for high throughput applications.


Moreover, the advancements in polar code decoding algorithms and software and hardware architectures have paved the way for efficient and low-latency implementations, including 5G and beyond. \citet{Sarkis2014a} introduced a framework for generating high-speed software polar decoders, achieving significant throughput improvements. Meanwhile, in  \citep{Sarkis2014b}, simplified decoding algorithms have been proposed to enhance the speed of polar list decoders, maintaining error-correction performance. subsequently, \citet{Kam2021} addressed the latency issue in SC decoding by introducing tree-level parallelism and novel pruning methods, significantly reducing decoding latency. Moreover, \citet{Xiang2020} presented a reduced-complexity logarithmic SC stack (Log-SCS) polar decoding algorithm, achieving notable improvements in decoding latency and complexity. Additionally, \citet{Rezaei2022} focused on implementing ultra-fast polar decoders with new sub-codes and decoding algorithms for short to moderate block lengths, emphasizing hardware optimization techniques. Furthermore, \citet{Liu2022} proposed high-throughput adaptive list decoding architectures for polar codes on GPUs, leveraging adaptive mapping strategies to improve throughput and latency performance.


Recently, research in decoding algorithms, combining techniques from deep learning, reinforcement learning, and traditional decoding methods, offer promising solutions for efficient and low-latency decoding of polar codes  and is among the hot topics in the area. \citet{Doan2019a} introduced a novel approach, {\em neural belief propagation} (NBP), combining CRC with polar codes to enhance error-correction performance, particularly for parallel iterative BP decoders. Building upon this, \citet{Hashemi2019} proposed a deep-learning-aided successive-cancellation list (DL-SCL) decoding algorithm, leveraging deep learning techniques to optimize bit-flipping metrics and reduce computational complexity. Meanwhile, \citet{Doan2020} addressed factor-graph permutation selection in polar codes using reinforcement learning, achieving significant error-correction performance gains and expanding on this framework, fast SC-flip decoding, a bit-flipping algorithm optimized via reinforcement learning  have been introduced in  \citet{Doan2021} for improved error-correction performance in polar codes. Additionally, \citet{Wodiany2019} presented a low-precision {\em neural network} (NN) decoder to mitigate the scalability issues and high memory usage of conventional NN decoders, maintaining wireless performance with reduced computational complexity. In parallel, \citet{Wen2019} proposed a BP-NN decoding algorithm for polar codes, integrating neural network decoders into the belief propagation framework to reduce decoding delay while maintaining low bit error rates. These advancements in decoding algorithms, combining techniques from deep learning, reinforcement learning, and traditional decoding methods, offer promising solutions for efficient and low-latency decoding of polar codes in future communication systems.

Furthermore, the primary polar code decoding algorithms include the SC algorithm \citep{Arikan2009}, the SCL algorithm \citep{Stimming2014, Tal_vardy2015}, the CA-SCL algorithm \citep{Zhang2017}, the BP algorithm \citep{Arikan2008}, and the SCAN algorithm \citep{Fayyaz2013}. Originally proposed by Arikan, the SC algorithm's performance diminishes for finite length codes. SCL, an enhancement of SC, offers superior performance by providing multiple paths. CA-SCL, incorporating cyclic redundancy checks on message bits over SCL, significantly boosts performance through simple checksums. Currently, 3GPP polar decoding relies on the \acs{CA-SCL} algorithm, surpassing LDPC codes. Notably, SC, SCL, and CA-SCL algorithms are hard output, yielding bit sequences rather than LLR values. To facilitate joint designs, soft output algorithms providing LLR values are essential; BP and SCAN algorithms serve this purpose. Decoding delay varies between BP and SCAN: BP utilizes the {\em"flood"} rule for message passing \citep{Yuan2014}, while SCAN employs the serial elimination rule for SC-like algorithms. BP exhibits lower decoding delay, whereas SCAN demonstrates superior convergence speed. In terms of performance, these algorithms an be ranked as follows: $\texttt{CA-SCL} > \texttt{state of the art (LDPC, Turbo codes)} > \texttt{SCL} > \texttt{BP} = \texttt{SCAN} > \texttt{SC}$.

\subsection{Foundations and Fundamentals}
A polar code of length $\mathrm N =2^n$ is generated using a generator matrix $\mathbf {G}$  of size $\mathrm N \times \mathrm N$. A block of length $\mathrm N$, consisting of $\mathrm {N-K}$ frozen bits and $\mathrm K$ information bits, is multiplied by $\mathbf{G}$ to produce the polar codeword $\mathbf{x}=\mathbf{uG}$. 
The generation matrix can be expressed as follows:
\begin{equation}\label{eqn:gen_polar}
\mathbf {G}_{\mathsf N}=\mathbf B_{\mathsf N} \mathbf F^{\otimes n},
\end{equation}
where $\mathbf B_{\mathsf N}$ is the bit-reversal permutation matrix, $\mathbf F^{\otimes n}$ is the $n-fold$ Kronecker product of $\mathbf F$ with itself, defined recursively as 
\begin{equation}
\begin{array} {c c}
\mathbf F^{\otimes 1} = \mathbf F=\left[\begin{array}{ll}
1 & 0 \\
1 & 1
\end{array}\right], & \mathbf F^{\otimes n}=\left[\begin{array}{cc}
\mathbf F^{\otimes n-1} & \mathbf {0} \\
\mathbf F^{\otimes n-1} & \mathbf F^{\otimes n-1}
\end{array}\right].
\end{array}
\end{equation}
The encoding operation can be expressed as
\begin{equation}
\mathrm x_0^{\mathsf{N-1}}=\left(\mathrm  u_0^{\mathsf{N-1}}\right) \mathbf B_{\mathsf N} \mathbf F^{\otimes n},
\end{equation}
where $\otimes$ denotes the Kronecker product.

%\begin{remark}
The presence of the {\em bit-reverse permutation matrix} $\mathbf B_{\mathsf N}$ doesn't impact the code's distance properties. Some implementations omit it. When the bit-reverse permutation isn't utilized, the encoder is referred to as being in {\em natural order} \citep{Moon2005}.
%\end{remark}
For instance, considering a polar code of length $\mathrm N = 8$, once the positions of the fixed bits, termed {\em frozen bits}(i.e., magenta color), and the positions of the information bits(i.e., dark color) are determined, the encoder graph is depicted  in Figure \ref{fig:enc_polar}.  
\begin{figure} [!ht]
    \centering
 \includegraphics[width=0.8\linewidth]{Figures/polar/1_polar_graph4.pdf}
\caption{The graph  of an $(8, 4)$ polar code with bit reversed indexing.}
\label{fig:enc_polar}
\end{figure}
Consequently, the input/output relationship  in (\ref{eqn:io_polar_graph_enc}) is established according to the  encoder graph representation shown in Figure \ref{fig:enc_polar}.
\begin{equation}\label{eqn:io_polar_graph_enc}
\begin{array}{l l }
\begin{aligned}
&\mathrm x_0=\mathrm u_0 \oplus \mathrm  u_1 \oplus \mathrm u_2 \oplus \mathrm u_4,\\
&\mathrm  x_4=\mathrm u_1 \oplus \mathrm u_3 \oplus \mathrm u_6,\\
&\mathrm  x_2=\mathrm u_2 \oplus \mathrm u_3 \oplus \mathrm u_6,\\
&\mathrm  x_6=\mathrm u_3 \oplus \mathrm u_7,
\end{aligned}
&\begin{aligned}&\mathrm  x_1=\mathrm u_4 \oplus \mathrm u_5 \oplus \mathrm u_6,\\
&\mathrm  x_5=\mathrm u_5 \oplus \mathrm u_7,\\
&\mathrm  x_3= \mathrm u_6 \oplus \mathrm u_7,\\
&\mathrm x_7=\mathrm u_7,
\end{aligned}
\end{array}
\end{equation}
where $\oplus $ denotes addition in $\mathbb{F}_2$.
The codeword $[\mathrm x_0, \mathrm x_1, \ldots, \mathrm x_7]$ is transmitted through the physical channels $\mathrm W^8$, with channel outputs $[\mathrm y_0, \mathrm y_1, \ldots, \mathrm y_7]$. This structure, comprising coding and channel transmission, creates the channel $\mathrm W^8: \mathrm x_0, \mathrm x_1, \ldots, \mathrm x_7 \longmapsto \mathrm y_0, \mathrm y_1, \ldots, \mathrm y_7$.\\
%The subscript on $W^8$ denotes the synthesized channel.
% \begin{figure}[!ht]
%         \centering
%         \includegraphics[width=0.6\linewidth]{Figures/polar/1_polar_graph_chan4.pdf}
%         %\caption{Polar encoder of  Eight instances (N=8).}
%         \caption{The graph  of an $(8, 4)$ polar code with bit reversed indexing transmitted over physical channelS ($W$).}
%         \label{fig:enc_polar}
% \end{figure}
Initially, polar codes were nonsystematic, but they can be transformed into systematic codes like any linear code. Systematic polar encoding utilizes the standard non-systematic polar encoding apparatus. Systematic polar codes offer improved BER performance compared to non-systematic ones, yet both have identical BLER performance \citep{Ahmadi2018}. Systematic polar coding demonstrates greater resilience to error propagation with SC decoder than non-systematic polar coding.

In a linear code, a codeword is a point in the row space of the generator matrix $\mathbf G$, so that in $\mathbf {x=zG}$, $\mathbf z$ is a codeword, regardless of the particular values in $\mathbf z$. One way to do encoding might be to take a message vector $\mathbf u$, place it into $\mathrm K$ elements of the codeword $\mathbf x$, then find a vector $\mathbf z$ which fill in the remaining $\mathrm N - \mathrm K$ elements of $\mathbf x $ in such a way that $\mathbf x$ is in the row space of $\mathbf G$. If $\mathbf z$ can be found via linear operations from $\mathbf u$ in such a way that the message symbols appear explicitly in $\mathbf u$, then systematic encoding has been achieved \citep{Moon2005}.
\begin{equation}
\mathbf G_\mathsf 8=\mathbf F^{\otimes 3}=\left[\begin{array}{llllllll}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
1 & 1 & 0 & 0 & 1 & 1 & 0 & 0 \\
1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 \\
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1
\end{array}\right] .
\end{equation}
Note that we can perform systematic encoding via the \emph{encoder Graph, Arikan’s method, the bit reverse permutation, etc.} \citep{Moon2005}.

\subsection{3GPP 5G Polar Codes}
In NR, the polar code is used to encode {\em broadcast channel} (BCH) as well as {\em downlink control information} {DCI} and {\em uplink control information} ({UCI}).
The overall control streams transmission chain from MAC/PHY layer processing schematic is depicted in Figure~\ref{fig:polar_tranceiver_chain}, which describes the transmit-end for the physical uplink/downlink control channel supporting a transport block CRC attachment, code block segmentation and code block CRC attachment, Polar encoding, rate matching code block concatenation. The receiving chain is in line with the transmitting chain in the reverse flow.
\begin{figure*} [!ht]
    \centering
  \subfloat[\scriptsize {Tranmitter end.}\label{fig:tx_polar}]{ %\input{Figures/ldpc/c1_v2.tex}
  \includegraphics[width=0.9\linewidth]{Figures/ldpc/tx_polar1.pdf}
  }
 \\
  \subfloat[\scriptsize {Receiver end.}\label{fig:rx_polar}]{  \includegraphics[width=0.9\linewidth]{Figures/ldpc/rx_polar1.pdf}}
\caption{Conceptual illustration of 5G Polar transceiver chain.}
\label{fig:polar_tranceiver_chain}
\end{figure*}

3GPP NR uses a variant of the polar code called {\em distributed} CRC (D-CRC) polar code, that is, a combination of \emph{CRC-assisted and {\em polar codes} (PC}, which interleaves a CRC-concatenated block and relocates some of the PC bits into the middle positions of this block prior to performing the conventional polar encoding\citep{Ahmadi2018}. This allows a decoder to early terminate the decoding process as soon as any parity check is not successful. \emph{The D-CRC scheme is important for early termination of decoding process}, because the post-CRC interleaver can distribute information and CRC bits such that partial CRC checks can be performed during list decoding and paths failing partial CRC check can be pruned, leading to early termination of decoding. The post-CRC interleaver design is closely tied to the CRC generator polynomial, thus by appropriately selecting the CRC polynomial, one can achieve better early termination gains and maintain acceptable false alarm rate.
\begin{enumerate}
  \item {\em CRC attachment}.\\
Assume that the input message (control information) before CRC attachment is $a(0), a(1),\ldots, a(A-1)$, where $A$ is input sequence,  parity bits are  $p(0), p(2),\ldots, p(L-1)$, $L$ is the number of parity bits. The parity bits are generated by one of the following cyclic generator polynomials.

A CRC length $L=24$ bits is utilized for the downlink, and depending on the amount of $A$, CRCs of $L=6$ and $L=11$ bits are provided for the uplink.

For downlink channels, the generator polynomial $ \mathrm g_{\mathsf{CRC24A}}(\beta)$ is used.
\begin{equation}
\begin{array}{r}
 \mathrm g_{\mathsf{CRC24A}}(\beta)=\left[\beta^{24}+\beta^{23}+\beta^{18}+\beta^{17}+\beta^{14}+\beta^{11}\right. \\
\left.+\beta^{10}+\beta^7+\beta^6+\beta^5+\beta^4+\beta^3+\beta+1\right].
\end{array}
\end{equation}
And for uplink channels, the generator polynomial $ \mathrm g_{\mathsf{CRC11}}(\beta)$ or  $ \mathrm g_{\mathsf{CRC6}}(\beta)$ is used.
\begin{equation}
\begin{array}{ll}
 \mathrm g_{\mathsf{CRC11}}(\beta)=\left[\beta^{11}+\beta^{10}+\beta^9+\beta^5+1\right], \\   \mathrm g_{\mathsf{CRC6}}(\beta)=\left[\beta^6+\beta^5+1\right].
 \end{array}
\end{equation}

The message bits after attaching CRC are $b(1), b(2),\ldots, b(B)$, $B$ is the size of transport block information with CRC bits and $B = A + L$.
\begin{equation}
b_k=\left\{\begin{array}{l l}
a_k, & \texttt { \footnotesize{for} }  k=0,1, \ldots, A-1 \\
p_{k-A}, & \texttt { \footnotesize{for} }  k=A, A+1, \ldots, A+L-1
\end{array}\right.
\end{equation}
\item {\em Code block segmentation and code block CRC attachment}.\\
The input bit sequence to the code block segmentation is denoted $a(0), a(1),\ldots, a(A-1)$, where $A$ is no larger than $1706$.


Assume that the maximum code block size is $A^{\prime}$,  assume that $C$ is the total number of code blocks. Thus, 
\begin{equation}
A^{\prime}=\lceil A / C\rceil \cdot C.
\end{equation}
The sequence $c_r(0), c_r(1),\ldots, c_r(A'/C-1)$ is used to calculate the CRC parity bits
$p_r(0), p_r(1),\ldots, p_r(L-1)$, such that 
\begin{equation}
c_{r,k}=p_{r,\left(k-A^{\prime} / C\right)}, \quad
A^{\prime} / C \leq k \leq  A^{\prime} / C+L-1.
\end{equation}

%%%%%%%%%%%%%%
At the transmitter end, we have the following streamlines:\\
The bit sequence input for a given code block to channel coding is denoted by $c(0), c(1),\ldots, c(\mathrm K_r-1)$ , where $\mathrm K_r$ is the number of bits in code block number $r$, and each code block is individually encoded. %by the following:
After the encoding process, the resulting coded bit sequence within the $r-th$ code block is denoted by $d_r(0), d_r(1), \ldots,  d_r(\mathrm N_r-1)$  where $\mathrm N_r = 2^n$ (code length of the polar code) determined by the following:\\
\texttt{\footnotesize{if} } $ E_r \leq(9 / 8) \cdot 2^{\left(\left\lceil\log _2 E_r\right\rceil-1\right)}$ \texttt{\footnotesize{and}} $\mathrm K_r / E_r<9 / 16$,\\
 $ \quad n_1=\left\lceil\log _2 E_r\right\rceil-1$.\\
\texttt { \footnotesize{else} } $n_1=\left\lceil\log _2 E_r\right\rceil$.\\
$\mathrm r_{\min }=1 / 8$;
$n_2=\left\lceil\log _2\left(K / \mathrm r_{\text {min }}\right)\right\rceil$;\\
$n=\max \left\{\min \left\{n_1, n_2, n_{\max }\right\}, n_{\text {min }}\right\}$, \\
where $n_{\min }$ and $n_{\max }$ provide a lower and an upper bound on the code length, respectively. In particular, and $n_{\min }= 5$  and $n_{\max }=9$ for the downlink control channel, whereas $n_{\max }=10$ for the uplink control channel. $ E_r$ is the rate matching output sequence length.\\
UE is not expected to be configured with $\mathrm K_r + n_{PC} > E$ , where $n_{PC}$ is the number of parity check bits.
\begin{itemize}
  \item {\em Interleaving}.\\
  The bit sequence $c_r(0) , c_r(1), \ldots, c_r(\mathrm K_r-1)$ is interleaved into bit sequence $c_r^\prime(0), c_r^\prime(1), \ldots,  c_r^\prime(\mathrm K_r-1)$ a follows:
  \begin{equation}
  c_{r,k}^{\prime}=c_{r,\Pi(k)}, k=0,1, \ldots, \mathrm K_r-1, r=0,1, \ldots, C-1
  \end{equation}
  where $\Pi(k)$ is the interleaving pattern  \citep{3GPP38212}.
  \item {\em Polar encoding}.\\
  The interleaved vector $\mathbf c^\prime$ is assigned to the information set along with the PC bits, while the remaining bits in the $\mathrm N$-bit vector $\mathbf u$ are frozen. Hence,
$\mathbf u= u(0), u(1),\ldots, u(\mathrm N-1)$ is generated according to the clause 5.3.1.2 \citep{3GPP38212}.
% u = Subchannel allocation + PC bits calculation
Denote $\mathbf {G}_{\mathsf N_r}=\left(\mathbf {G}_2\right)^{\otimes n}$ as the $n-th$ Kronecker power of matrix $\mathbf G_2$ , where $\mathbf {G}_2=\left[\begin{array}{ll}1 & 0 \\ 1 & 1\end{array}\right]$,
the output after encoding $\mathbf d_r=d_r(0), d_r(1), \ldots,  d_r(\mathrm N_r-1)$ is obtained by $\mathbf d_r=\mathbf u_r\mathbf {G}_{\mathsf N_r}$, where encoding is performed in $\mathbb F_2$.

\end{itemize}
%%%%%%%%%%%%%%%%%
  \item {\em Rate matching}.\\
  The rate matching for polar code is defined per coded block and consists of \emph{sub-block interleaving}, bit collection, and bit interleaving. Sequence of coded bits at the rate matcher input is  $d_r(0), d_r(1),\ldots, d_r(\mathrm N_r-1)$, The output bit sequence from the  rate matcher is denoted as $f_r(0), f_r(1),\ldots, f_r(E-1)$.
   For rate matching, puncturing, shortening ($ E_r < \mathrm N_R$),  or repetition($ E_r \geq N_r$) are applied to change the $\mathrm N_r$-bit vector $\boldsymbol s_r$ into the $E_r$-bit vector $\boldsymbol e_r$.
   
Indeed, the rate matching process encapsulates the following steps:
  \begin{itemize}
    \item {\em Sub-block interleaving}.\\ 
    The bits input to the sub-block interleaver are the coded bits $d_r(0), d_r(1),\ldots, d_r(\mathrm N_r-1)$ . The coded bits  $d_r(0), d_r(1),\ldots, d(\mathrm N_r-1)$  are divided into 32 sub-blocks. The bits output from the sub-block interleaver are denoted as $s_r(0), s_r(1),\ldots, s_r(\mathrm N_r-1)$.

      \item {\em Bit selection}.\\ 
      The bit sequence after the sub-block interleaver $s_r(0), s_r(1),\ldots, s_r(\mathrm N_r-1)$  is written into a circular buffer of length $N$.
      Denoting by $E_r$ the rate matching output sequence length, the bit selection, output bit sequence  $e_r(0), e_r(1),\ldots, e_r(\mathrm E_r-1)$.
    \item {\em Interleaving of coded bits}.\\ 
        The bits sequence $e(0), e(1),\ldots, e(\mathrm E_r-1)$ is interleaved into bit sequence $f_r(0), f_r(1),\ldots, f_r(E-1)$., where the value of $E_r$ is no larger than $8192$.
  \end{itemize}

\item {\em Code block concatenation}.\\ 
The code block concatenation consists of sequentially concatenating the rate matching outputs for the different code blocks.

The input bit sequence for the code block concatenation block are the sequences $f_{r,k} $ , for $r = 0,\ldots, C-1$ and
$\mathrm k = 0,\ldots, E_r -1$, where $ E_r$ is the number of rate matched bits for the $r-th $ code block. The output bit sequence from the code block concatenation block is the sequence $g_\ell$ for $\ell= 0,\ldots, G -1$.
Therefore,
  \begin{equation}
  g_\ell=f_{r,k}, \texttt{\footnotesize{where}} \quad 1 \leq \ell \leq G, \quad 1 \leq k \leq E_r.
  \end{equation}
\end{enumerate}
At the receiver end, the procedure is as follows:
 \begin{enumerate}
   \item {\em Code block de-concatenation}.\\ 
    Assume that the input message to code block de-concatenation is $y(0), y(1),\ldots, y(G-1)$. The output message from code block de-concatenation is $f_{r,k}, \text{where} \quad 1 \leq \ell \leq G,\quad 1 \leq k \leq E_r$.
 \item {\em Rate de-matching}.\\ 
The purpose of rate de-matching is to convert the code block message to the format that can be used for 5G Polar decoder to process decoding. Rate de-matching is done on each code block independently.
   %%%%%%%%%%%%
\item {\em Polar decoding}.\\ 
The decoding process is done on each code block independently. The subsequent subsection~\ref{subsubsec:polar_dec_algo} provides more details on polar decoding algorithms.
\item {\em Code block de-segmentation}.\\
   % Code Block De-segmentation is used to extract the message bits and transport block attached CRC bits.
   Assume that the output from code block de-segmentation is $\hat{b}(0), \hat{b}(1),\ldots, \hat{b}(B-1)$, where $B$ is the size of original transport block information with attached CRC bits.

   \item {\em CRC check}.\\
CRC check is used to extract the CRC bits in {UCI}/{DCI} bits after the information transmitted  in 5G NR control channels. Then the extracted CRC bits will be checked with the original CRC bits attached to control information bits  before transmitted.
\end{enumerate}

\subsection{Polar Decoding Algorithms}\label{subsubsec:polar_dec_algo}
Two primary polar decoding methods are SC decoder and BP decoder. Unlike SC decoder, BP decoder doesn't have inter-bit dependence, preventing error propagation and avoiding intermediate hard decisions. It updates LLR values iteratively through right-to-left and left-to-right iterations using LDPC-like update functions. BP decoder supports parallel processing, enhancing throughput for high-speed applications, while SC decoder and its variants have serial decoding characteristics, making parallelization impossible \citep{Ahmadi2018} .
Moreover, polar decoding can employ various algorithms, including SC decoding and SCL decoding.
Polar decoders face challenges in hardware implementation compared to encoders due to complexities: they work with bit probabilities, consider all possible permutations of information blocks, and process each block multiple times for error correction. This leads to higher latency, hardware usage, and power consumption.
\subsubsection{Successive Cancellation Decoding}
The first polar code decoding method, known as successive cancellation (\acs{SC}), decodes bits one by one, using previous estimations to help determine new ones \citep{Moon2005}. SC builds on decoded bits sequentially but suffers from inter-bit dependence and error spread. While it doesn't perform as well as other decoders alone, it shows promise for list decoding because of its hierarchical structure. Polar codes achieve the Shannon capacity under SC decoding. The computation method for SC is akin to that of LDPC codes, using log-likelihood ratios (LLRs) to estimate bit likelihoods.
SC decoding algorithms utilize the log-likelihood function, which can be recursively computed due to the recursive nature of the channel transition function.

Let  \begin{equation}
\lambda_\mathsf{N}^{(i)}\left(\mathrm y_0^{\mathsf{N}-1}, \hat{\mathrm u}_0^{i-1}\right)=\frac{\mathrm W_\mathsf{N}^{(i)}\left(\mathrm y_0^{\mathsf{N}-1}, \hat{\mathrm u}_0^{i-1} \mid \mathrm u_i=0\right)}{\mathrm W_\mathsf{N}^{(i)}\left(\mathrm y_0^{\mathsf{N}-1}, \hat{\mathrm u}_0^{i-1} \mid \mathrm u_i=1\right)},
\end{equation}
and let
\begin{equation}
\mathscr L_\mathsf{N}^{(i)}\left(\mathrm y_0^{\mathsf{N}-1}, \hat{\mathrm u}_0^{i-1}\right)=\log \lambda_\mathsf{N}^{(i)}\left(\mathrm y_0^{\mathsf{N}-1}, \hat{\mathrm u}_0^{i-1}\right).
\end{equation}

This likelihood ratio can be used to estimate the value of the bit $\mathrm u_i$ using the function $\mathrm h_i$ defined as
\begin{equation}\label{eqn:scl_frozen_bit}
\mathrm h_i\left(\mathrm y_0^{\mathsf{N}-1}, \hat{\mathrm u}_0^{i-1}\right)= \begin{cases}0 & \text { if } \mathscr L_\mathsf{N}^{(i)}\left(\mathrm y_0^{\mathsf{N}-1}, \hat{\mathrm u}_0^{i-1}\right) \geq 0 ,\\ 1 & \text { otherwise .}\end{cases}
\end{equation}

For decoding, if $i \in \mathcal{A}^c$ (i.e., the set of frozen bits), then the decoded value is the frozen bit value. Otherwise, it is determined by the $\mathrm h$ function:
\begin{equation}\label{eqn:scl_unfrozen_bit}
\hat{\mathrm u}_i= \begin{cases}\mathrm u_i & i \in \mathcal{A}^c,\\ \mathrm h_i\left(\mathrm y_0^{\mathsf{N}-1}, \hat{\mathrm u}_0^{i-1}\right) & i \in \mathcal{A} \ .\end{cases}
\end{equation}
Note that $\hat{\mathrm u}^{i}$  depends on the previously estimated values $\hat{\mathrm u}_0^{i-1}$. This is the essence of SC: bits are estimated in order $\hat{\mathrm  u}_0, \hat{\mathrm  u}_1, \hat{\mathrm u}_2, \ldots, \hat{\mathrm  u}_{\mathsf{N}-1}$, with the estimate $\hat{\mathrm u}^{i}$ being based upon previously determined bits. Under the polarization idea, since the polarized channels used are assumed to be good, each of the previously determined bits $\hat{\mathrm u}_0^{i-1}$ are assumed to be good \citep{Moon2005}.

Moreover the SC decoding principle for polar codes requires only two clarifications: the first is the probability transfer formula on the unit factor graph, and the second is the recursive order. 
As Figure \ref{fig:dec_fact_diagram} shows the graph of the unit factor of the polar code, on which there are 8 values, $\mathscr L_1, \mathscr L_2, \mathscr L_3, \mathscr L_4$ for the LLR values passed to the left and $ \mathscr B_1, \mathscr B_2, \mathscr B_3, \mathscr B_4$ for the hard bit information passed to the right.

The transmission equation is
\begin{equation}\label{eqn:llr3_polar}
\mathscr L_3= \mathscr L_1 {\boxplus} \mathscr L_2,
\end{equation}
\begin{equation}\label{eqn:llr_i_polar}
\texttt{\small{where}} \ : \ \mathrm a \ {\boxplus} \ \mathrm b =2\tanh^{-1} \left[\tanh \left(\frac{a}{2}\right) \tanh \left(\frac{b}{2}\right)\right].
\end{equation}
\begin{equation}\label{eqn:llr4_polar}
\mathscr L_4= \begin{cases}\mathscr L_2+\mathscr L_1 & \texttt{\small{if }} \mathscr  B_3=0 \ . \\ \mathscr L_2-\mathscr L_1  & \texttt{\small{if }} \mathscr B_3=1 \ .\end{cases}
\end{equation}
\begin{equation}\label{eqn:B1_polar}
\begin{aligned}
   &\mathscr B_1=\mathscr B_3 \oplus \mathscr B_4,\\&\mathscr B_2=\mathscr B_4.
\end{aligned}
\end{equation}
\begin{figure}[!ht]
        \centering
        \includegraphics[width=0.75\linewidth]{Figures/polar/SC_Proc_elem_unit.pdf}
         \caption{Factor Graph of the SC decoding unit.}
        %\caption{SC Processing Element}
        \label{fig:dec_fact_diagram}
\end{figure}

In what follows, we'll describe how the recursive process works using the factor graph shown in Figure~\ref{fig:dec_recursive_order}.
First, the decoder needs to find the value called LLR at point 1. To do this, it has to know the LLR values at points 2 and 3. Similarly, to find the LLR at point 2, it needs the LLR values at points 4 and 5, and for point 3, it needs the LLR values at points 6 and 7. However, the LLR values at points 4, 5, 6, and 7 can be figured out directly from the LLR values sent through the channel.

Then, we use equation (\ref{eqn:llr3_polar}) to calculate the LLR value at point 8 using the LLR value at point 1. Since point 8 is in the bottom left of the {\em unit factor graph}, we already know the LLR values of points 2 and 3, so we don't need to do any more recursion. Once we find the LLR value for point 8, we make a firm decision. After finding the LLR value for the bottom left point, we know the bit decision should move to the right. In other words, we figure out the bit values for points 2 and 3 using equations (\ref{eqn:llr_i_polar}) and (\ref{eqn:llr4_polar}). Now that points 2 and 3 are in the top left of the unit factor graph, we don't need to pass hard decision bit values to the right anymore. Next, to find the LLR value at point 9, we first need to calculate the LLR values at points 10 and 11. Since points 10 and 11 are in the bottom left, we can use equation (\ref{eqn:llr3_polar}) along with the bit decisions of points 2 and 3. We don't need any more downward recursion. Similarly, we find the LLR value at point 12 using equation (\ref{eqn:llr3_polar}) and the bit decision of point 9, then we make a decision. As point 12 is in the bottom left, we move the hard decision bit value to the right. At this stage, we compute the binary values of points 10 and 11 using equations (\ref{eqn:llr_i_polar}) and (\ref{eqn:llr4_polar}), and since they are both in the bottom left, we continue moving binary values to the right for points 4, 5, 6, and 7. Once points 4, 5, 6, and 7 are all in the top left, we stop moving binary values to the right.
We repeat this process until the SC decoder has found all LLR values and assigned binary values.
\begin{figure}[!ht]
        \centering
        \includegraphics[width=0.98\linewidth]{Figures/polar/recursiv_polar_sc_dec.pdf}
        \caption{Illustrative instance of a recursive order.}
        \label{fig:dec_recursive_order}
\end{figure}
%\begin{remark}
Despite the recursive SC method, the SC method can also be calculated using the node labelling method. To program the LLR recursion process described above and the process of passing the hard decision bit value to the right, the points shown in Figure \ref{fig:dec_recursive_order} must be labelled so that they can be programmed in a certain order.
%\end{remark} 
\subsubsection{Successive Cancellation List Decoding }
The SCL decoder was introduced as an extension of the SC decoder.
Rather than sequentially computing hard decisions for each bit, it bifurcates into two parallel SC decoders at every decision stage, with each branch maintaining its path metric continuously updated for each path. It's demonstrated that a list size of 32 is nearly sufficient to reach the \acs{ML} bound \citep{Ahmadi2018}.

What is needed is a path metric, computing the likelihood along the entire path of bits. This path metric is established in the following theorem.
\begin{theorem} \citep[Theorem 1]{Stimming2014}.\\
 For a path $\ell$ having bits $\hat{\mathrm u}_0(\ell), \hat{\mathrm u}_1(\ell), \ldots, \hat{\mathrm u}_i(\ell)$ and bit number $i \in 0,1, \ldots, \mathrm N-1$ , define the path metric as

 \begin{equation}
\mathsf{PM}_{\ell}^{(i)}=\sum_{j=0}^i \ln \left(1+\exp \left[-\left(1-2 \hat{\mathrm u}_j(\ell)\right) \mathscr L_\mathsf{N}^{(j)}[\ell]\right]\right)
\end{equation}
where
\begin{equation}
\mathscr L_\mathsf{N}^{(i)}[\ell]=\ln \left(\frac{\mathrm W_\mathsf{N}^{(i)}\left(y_0^{\mathsf{N}-1}, \hat{\mathrm u}_0^{i-1}[\ell] \mid 0\right)}{\mathrm W_\mathsf{N}^{(i)}\left(\mathrm y_0^{\mathsf{N}-1}, \hat{\mathrm u}_0^{i-1}[\ell] \mid 1\right)}\right)
\end{equation}
is the LLR of the bit $\mathrm u_i$ given the channel output $\mathrm y_0^{\mathsf{N}-1}$ and the past trajectory of the path $\hat{u}_0^{i-1}[\ell]$. However, the path metric is computed using LLRs, in a numerically stable way\citep{Moon2005}.

\end{theorem}
Furthermore, CRC-aided SCL, an extension of the SCL decoder, incorporates a high-rate CRC code appended to the polar code. This addition facilitates the selection of the correct codeword from the final list of paths. It has been observed that in instances where an SCL decoder fails, the correct codeword remains within the list. Hence, the CRC serves as a validation check for each candidate codeword in the list.
Polar decoding via BP and SCAN is beyond the scope of this manuscript. Interested readers are encouraged to refer to \citep{ArliGazi2021, Wang2019} for BP decoding and \citep{Fayyaz2014} for SCAN decoding.
\section{Numerical Results}
We are interested in the short block regime, i.e. blocks of 20 to 100 bits, we will carry out simulations using a 100-bit block (\acs{TB}+\acs{CRC}), with different coding rates from low to high, QPSK modulation coupled with polar and LDPC coding.

\begin{figure*} [!ht]
    \centering
  \subfloat[\scriptsize {5G Polar codes.}\label{fig:ldpc_code_analysis}]{
 % \includegraphics[width=.48\linewidth]{Figures/numerical_result/polar_tdl.pdf}}
   \includegraphics[width=.48\linewidth]{Figures/numerical_result/bipcm_qpsk.pdf}}
    \hfill
  \subfloat[\scriptsize {5G LDPC codes.}\label{fig:polar_code_analysis}]{%
%ù\input{Figures/numerical_result/BILCM_QPSK}}
     %\includegraphics[width=.48\linewidth, height=7.3cm]{Figures/numerical_result/comp_bilcm.pdf}}
    % \includegraphics[width=.48\linewidth]{Figures/numerical_result/ldpc_tdl.pdf}}
     \includegraphics[width=.49\linewidth]{Figures/numerical_result/bilcm_qpsk.pdf}}
  \caption{Block Error Rate, 100 bits(TBs+CRC), R=\{1/4, 1/2, 3/4\}, NR LDPC (BP, LBP with Early Stop Criteria (ESC), MaxIter=10) and NR POLAR, (CA-SCL, L=1, 8, 32), QPSK modulations, over ($4\times1$) SIMO, on  Non Line-of-Sight (NLOS) TDL channel,  300ns of delay spread.}
  \label{fig:NRBICM_analysis}
\end{figure*}

%%%%%%%%%%%%
It can be noticed in Figures~\ref{fig:ldpc_code_analysis} that layered belief propagation (LBP) for LDPC decoding often outperforms standard belief propagation (BP) decoding due to its ability to exploit the structure of the LDPC code more efficiently. Concretely,
 LDPC codes are often constructed with a layered structure, which means that the parity-check matrix can be organized into layers of variable nodes and check nodes. Hence, LBP takes advantage of this structure by decoding the code layer by layer. This can lead to more efficient message passing compared to BP based on "{\em flood}" decoding, which updates messages across all variable nodes and check nodes simultaneously. Moreover, LBP typically has lower computational complexity. By decoding the code layer by layer, the complexity of message passing at each iteration can be reduced, since only messages within a layer need to be exchanged.
 Due to its improved convergence properties and efficient message passing, layered belief propagation decoding tends to provide better error correction performance compared to standard BP decoding. This is particularly advantageous in scenarios with higher levels of noise or more challenging channel conditions. In general, the layered structure and specialized message passing algorithms for layered belief propagation make it a preferred choice for LDPC decoding in many practical applications, offering improved performance, reduced complexity, and better convergence properties.
However, the effectiveness of LBP versus BP decoding can be influenced by factors such as the code rate, the operating {\em signal-to-noise ratio} (\acs{SNR})  region, the complexity of the LDPC code structure, and the computational resources available for decoding. For instance,  at lower code rate, performance gaps between LBP and standard BP are more pronounced. Conversely, in terms of convergence time, the merits of decoding paired with the {\em early stop criterion} (\acs{ESC}) can be exploited with the LBP decoding which is amenable to a very interesting trade-off between reliability and latency.

Besides, in setups using polar codes, the {\em CRC-aided successive cancellation list} ({CA-SCL}) decoder is highly regarded for its exceptional error correction capabilities compared to the state of art decoders. The performance of the SCL decoder improves with the number of lists ($L$). Increasing $L$ in the \acs{SCL} decoder enhances {BLER} performance, as shown in Figures~\ref{fig:polar_code_analysis}, but leads to higher decoding complexity, requiring more computational resources.
\section{Conclusions}
In conclusion, this paper has served as a comprehensive guide for practitioners and scholars seeking to understand the channel coding and decoding schemes embedded in the 5G NR standard, with a particular focus on LDPC and polar codes. We began by elucidating the design principles underlying these channel codes, providing essential knowledge from both encoding and decoding perspectives. In parallel, we conducted an extensive literature review to establish the current state of research in this field.
Notably, we enriched these foundational discussions with detailed, standard-specific insights that are often difficult to extract from technical specification documents. 
Through this structured approach, we aim to provide a valuable reference for those interested in the complexities of channel coding within the 5G NR framework.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\appendices



% \section*{Acknowledgment}
% The preferred spelling of the word ``acknowledgment'' in American English is
% without an ``e'' after the ``g.'' Use the singular heading even if you have
% many acknowledgments. Avoid expressions such as ``One of us (S.B.A.) would
% like to thank $\ldots$ .'' Instead, write ``F. A. Author thanks $\ldots$ .'' In most
% cases, sponsor and financial support acknowledgments are placed in the
% unnumbered footnote on the first page, not here.
%\usepackage{balance}
\bibliographystyle{unsrt}
\begin{thebibliography}{00}


 
  %\bibitem{3GPP38202}3GPP TS 38.212 V16.2.0, `` Technical Specification Group Radio Access Network, Services provided by the physical layer'', November 2020.

  %\bibitem{3GPP38211}3GPP TS 38.211 V16.5.0, `` Technical Specification Group Radio Access Network, Physical Channels and Modulation'', May 2021.

 %\bibitem{3GPP38901} 3GPP TR 38 901 v16.1.0,`` Technical Report, Study on channel model for frequencies from 0.5 to 100 GHz'', Nov 2020.
 \bibitem[Shannon (1948)]{Shannon48}C. E. Shannon, “A mathematical theory of communication,” Bell Labs Technical Journal, vol. 27, pp. 379 – 423, 623 – 656, October 1948.
%%% LDPC
 \bibitem{Whitaker1991}S. . R. Whitaker, J. Canaris et K. Cameron, `'Reed-Solomon VLSI Codec for advanced television,"  IEEE Trans. Circuits and Systems for video tech, vol. 1, 1991.
 
  \bibitem{Hamming1950}R. Hamming, `'Error detecting and error correcting codes," Bell System technical journal, vol. 29, pp. 147-160, 1950.
 
  \bibitem{Hocquenghem1969}A. Hocquenghem, `'Codes correcteurs d’erreurs,"  Chiffres, vol. 2, pp. 147- 156, 1959.

  \bibitem[Gallager (1963)]{Gallager63}R. G. Gallager, ``Low Density Parity Check Codes'', Cambridge, USA: MIT Press, July 1963.
   \bibitem{3GPP38212}3GPP TS 38.212 V16.2.0, `` Technical Specification Group Radio Access Network, Multiplexing and channel coding'', July 2020.
   \bibitem{Moon2005}Todd K. Moon,``Error Correction Coding: Mathematical Methods and Algorithms'', Wiley-Interscience605 Third Avenue New York, NYUnited States, May 2005.
      \bibitem{Berrou1993}C. Berrou, A. Glavieux et P. Thitimajshima, `'Near shannon limit error correcting coding and decoding :turbo-codes,"  IEEE International Conference on Communications, vol. 2, May 1993.
%\bibitem{Berrou1995}C. Berrou, `'Error-correction coding method with at least two systematic convolutional codings in parallel, corresponding iterative decoding method, decoding module and decoder,"  1995.
  \bibitem{MacKay1997}MacKay et Neal, `'Near Shannon limit performance of low density parity check codes,'' Electronics letters, 1997.
  \bibitem{Luby1998}M. Luby, M. Mitzenmacher, A. Shokrollahi et D. Spielman, `'Analysis of low density codes and improved designs using irregular graphs,"  Proceeding of 30th ACM Symp. on Theory of Computing, 1998.



%%%%%%%%%%%%%%%%%%%%%%% Ldpc litterature review  %%%%%%%%%
\bibitem[Shao \textit{et~al.}(2018)]{Shao2019} S. Shao et al., "Survey of Turbo, LDPC, and Polar Decoder ASIC Implementations," in IEEE Communications Surveys and Tutorials, vol. 21, no. 3, pp. 2309-2333, thirdquarter 2019.
\bibitem[Srisupha \textit{et~al.}(2022)]{Srisupha2022}	T. Srisupha, K. Mueadkhunthod, W. Phakphisut, S. Khittiwitchayakul, K. Puntsri and T. Sopon, "Development of 5G LDPC Experimental Kit," 2022 37th International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC), Phuket, Thailand, 2022, pp. 856-859.
\bibitem[Belhadj \textit{et~al.}(2021)]{Belhadj2021}S. Belhadj and M. L. Abdelmounaim, "On error correction performance of LDPC and Polar codes for the 5G Machine Type Communications," 2021 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS), Toronto, ON, Canada, 2021, pp. 1-4.
\bibitem[Li \textit{et~al.}(2018)]{Li2023}	K. -Y. Li, H. -Y. Li, L. Deng, X. -H. Sun, Y. Wang and Z. -P. Shi, "Improved Informed Dynamic Scheduling Strategies for 5G LDPC Codes," 2023 IEEE 23rd International Conference on Communication Technology (ICCT), Wuxi, China, 2023, pp. 74-78.
\bibitem[Tian and Wang (2022)]{Tian2022}	K. Tian and H. Wang, "A Novel Base Graph Based Static Scheduling Scheme for Layered Decoding of 5G LDPC Codes," in IEEE Communications Letters, vol. 26, no. 7, pp. 1450-1453, July 2022.
%\bibitem[Su \textit{et~al.}(2022)]{Su2022}	S. Su, C. -H. Lee and T. -D. Chiueh, "A 58.6/91.3 pJ/b Dual-Mode Belief-Propagation Decoder for LDPC and Polar Codes in the 5G Communications Standard," in IEEE Solid-State Circuits Letters, vol. 5, pp. 98-101, 2022.
%%%%%%%%%%

%%%%%%%%%%%%%







\bibitem{Hamidi-Sepehr2018} F. Hamidi-Sepehr, A. Nimbalker and G. Ermolaev, "Analysis of 5G LDPC Codes Rate-Matching Design," 2018 IEEE 87th Vehicular Technology Conference (VTC Spring), 2018, pp. 1-5.
\bibitem{bae2019}J.H. Bae, A.A. Abotabl, H. Lin, K. Song and  J. Lee ``An overview of channel coding for 5G NR cellular communications, " APSIPA Transactions on Signal and Information Processing, vol.8, p. e17 2019.
  \bibitem{Nguyen2019}T. Nguyen, T. N. Tan, and H. Lee, ``Efficient QC-LDPC Encoder for 5G New Radio'', Electronics, vol. 8, p. 668, June 2019.

%\bibitem{Bai2018}H. Li, B. Bai, X. Mu, J. Zhang and H. Xu, "Algebra-Assisted Construction of Quasi-Cyclic LDPC Codes for 5G New Radio," in IEEE Access, vol. 6, pp. 50229-50244, 2018.

%\bibitem{Xu2010}M. Xu, J.Wu and M. Zhang, "A modified Offset Min-Sum decoding algorithm for LDPC codes," 2010 3rd International Conference on Computer Science and Information Technology, 2010, pp. 19-22.
 % 
%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%
\bibitem[Liao \textit{et~al.}(2018)]{Liao2021}	S. Liao, Y. Zhan, Z. Shi and L. Yang, "A High Throughput and Flexible Rate 5G NR LDPC Encoder on a Single GPU," 2021 23rd International Conference on Advanced Communication Technology (ICACT), PyeongChang, Korea (South), 2021, pp. 29-34.

\bibitem[Tarver \textit{et~al.}(2021)]{Tarver2021} C. Tarver, M. Tonnemacher, H. Chen, J. Zhang and J. R. Cavallaro, "GPU-Based, LDPC Decoding for 5G and Beyond," in IEEE Open Journal of Circuits and Systems, vol. 2, pp. 278-290, 2021.

\bibitem[Nadal and Baghdadi (2021)]{Nadal2021} J. Nadal and A. Baghdadi, "Parallel and Flexible 5G LDPC Decoder Architecture Targeting FPGA," in IEEE Transactions on Very Large Scale Integration (VLSI) Systems, vol. 29, no. 6, pp. 1141-1151, June 2021.

\bibitem[Xu \textit{et~al.}(2021)]{Xu2019} Y. Xu, W. Wang, Z. Xu and X. Gao, "AVX-512 Based Software Decoding for 5G LDPC Codes," 2019 IEEE International Workshop on Signal Processing Systems (SiPS), Nanjing, China, 2019, pp. 54-59.

\bibitem[Sy (2023)]{sy2023_ldpc} Mody Sy, "Optimization Strategies for Low Latency 5G NR LDPC Decoding on General Purpose Processor", 5-th IEEE International Conference on Control, Communication and Computing (ICCC 2023),Thiruvananthapuram, India, May 19-20, 2023.
 
\bibitem[Li \textit{et~al.}(2021)]{Li2021_ldpc}2. M. Li, V. Derudder, K. Bertrand, C. Desset and A. Bourdoux, "High-Speed LDPC Decoders Towards 1 Tb/s," in IEEE Transactions on Circuits and Systems I: Regular Papers, vol. 68, no. 5, pp. 2224-2233, May 2021.
\bibitem[Aronov \textit{et~al.}(2019)]{Aronov2019} A. Aronov, L. Kazakevich, J. Mack, F. Schreider and S. Newton, "5G NR LDPC Decoding Performance Comparison between GPU and FPGA Platforms," 2019 IEEE Long Island Systems, Applications and Technology Conference (LISAT), Farmingdale, NY, USA, 2019, pp. 1-6.

%%%

\bibitem[Rao and~Babu.(2019)]{Rao2019}	K. D. Rao and T. A. Babu, "Performance Analysis of QC-LDPC and Polar Codes for eMBB in 5G Systems," 2019 International Conference on Electrical, Electronics and Computer Engineering (UPCON), Aligarh, India, 2019, pp. 1-6.
\bibitem[Wu  \textit{et~al.}(2019)]{Wu2019}H. Wu and H. Wang, "A High Throughput Implementation of QC-LDPC Codes for 5G NR," in IEEE Access, vol. 7, pp. 185373-185384, 2019.

\bibitem[Ivanov \textit{et~al.}(2023)]{Ivanov2023}F. Ivanov and A. Kuvshinov, "On the Serial Concatenation of LDPC Codes," 2023 16th International Conference on Advanced Technologies, Systems and Services in Telecommunications (TELSIKS), Nis, Serbia, 2023, pp. 228-231.
\bibitem[Song \textit{et~al.}(2023)]{Song2023}L. Song, S. Yu and Q. Huang, "Low-density parity-check codes: Highway to channel capacity," in China Communications, vol. 20, no. 2, pp. 235-256, Feb. 2023.
%%%%%%%%%%%%%%%%
\bibitem[Ahn \textit{et~al.}(2019)]{Ahn2019}	S. -K. Ahn, K. -J. Kim, S. Myung, S. -I. Park and K. Yang, "Comparison of Low-Density Parity-Check Codes in ATSC 3.0 and 5G Standards," in IEEE Transactions on Broadcasting, vol. 65, no. 3, pp. 489-495, Sept. 2019.

\bibitem[Cui \textit{et~al.}(2021)]{Cui2021}	H. Cui, F. Ghaffari, K. Le, D. Declercq, J. Lin and Z. Wang, "Design of High-Performance and Area-Efficient Decoder for 5G LDPC Codes," in IEEE Transactions on Circuits and Systems I: Regular Papers, vol. 68, no. 2, pp. 879-891, Feb. 2021.

\bibitem[Trung \textit{et~al.}(2019)]{Trung2019}	K. Le Trung, F. Ghaffari and D. Declercq, "An Adaptation of Min-Sum Decoder for 5G Low-Density Parity-Check Codes," 2019 IEEE International Symposium on Circuits and Systems (ISCAS), Sapporo, Japan, 2019.

\bibitem[Jayawickrama and He (2022)]{Jayawickrama2022}	B. A. Jayawickrama and Y. He, "Improved Layered Normalized Min-Sum Algorithm for 5G NR LDPC," in IEEE Wireless Communications Letters, vol. 11, no. 9, pp. 2015-2018, Sept. 2022.

\bibitem[Li \textit{et~al.}(2020)]{Li2020} L. Li, J. Xu, J. Xu and L. Hu, "LDPC design for 5G NR URLLC and mMTC," 2020 International Wireless Communications and Mobile Computing (IWCMC), Limassol, Cyprus, 2020, pp. 1071-1076.

\bibitem[Wu and Wang (2019)]{Wu02019}	H. Wu and H. Wang, "Decoding Latency of LDPC Codes in 5G NR," 2019 29th International Telecommunication Networks and Applications Conference (ITNAC), Auckland, New Zealand, 2019, pp. 1-5.
\bibitem[Sun and Jiang.(2018)]{Sun2018}K. Sun and M. Jiang, "A Hybrid Decoding Algorithm for Low-Rate LDPC codes in 5G," 2018 10th International Conference on Wireless Communications and Signal Processing (WCSP), 2018, pp. 1-5.

%%%%%%%%%%%
\bibitem[Dai \textit{et~al.}(2021)]{Dai2021}J. Dai et al., "Learning to Decode Protograph LDPC Codes," in IEEE Journal on Selected Areas in Communications, vol. 39, no. 7, pp. 1983-1999, July 2021.
\bibitem[Shah and Vasavada (2021)]{Shah2021}	N. Shah and Y. Vasavada, "Neural Layered Decoding of 5G LDPC Codes," in IEEE Communications Letters, vol. 25, no. 11, pp. 3590-3593, Nov. 2021.
\bibitem[Tang \textit{et~al.}(2021)]{Tang2021}Y. Tang, L. Zhou, S. Zhang, C. Chen and L. Wang, "Normalized Neural Network for Belief Propagation LDPC Decoding," 2021 IEEE International Conference on Networking, Sensing and Control (ICNSC), Xiamen, China, 2021, pp. 1-5.
\bibitem[Andreev \textit{et~al.}(2021)]{Andreev2021}K. Andreev, A. Frolov, G. Svistunov, K. Wu and J. Liang, "Deep Neural Network Based Decoding of Short 5G LDPC Codes," 2021 XVII International Symposium "Problems of Redundancy in Information and Control Systems" (REDUNDANCY), Moscow, Russian Federation, 2021, pp. 155-160


\bibitem{Xiao-Yu2004}H. Xiao-Yu, M. Fossorier et E. ELEFTHERIOU, `'On the computation of the minimum distance of low-density parity-check codes,"  IEEE International Conference on Communications, 2004.

\bibitem{Zhang2010}L. Zhang, Q. Huang, S. Lin, K. Abdel-Ghaffar et I. F. Blake, `'Quasi-cyclic LDPC codes: an algebraic construction rank analysis and codes on latin squares,"  IEEE Trans. Commun., vol. 58, pp. 3126-3139, Nov 2010.
\bibitem{Ahmadi2018}S. Ahmadi, `` 5G NR, Architecture, Technology, Implementation, and Operation of 3GPP New Radio Standard'',London, United Kingdom : Academic Press, an imprint of Elsevier, 2019.

\bibitem{wang2021}LIFANG WANG ``Implementation of Low-Density Parity-Check codes for 5G NR shared channels,'' master Thesis, August 30, 2021.


\bibitem{Jinghu2005}Jinghu Chen, R. M. Tanner, C. Jones and Yan Li, "Improved min-sum decoding algorithms for irregular LDPC codes," Proceedings. International Symposium on Information Theory, 2005. ISIT 2005., Adelaide, SA, Australia, 2005, pp. 449-453,

\bibitem{Hocevar2004} D. E. Hocevar, "A reduced complexity decoder architecture via layered decoding of LDPC codes," IEEE Workshop onSignal Processing Systems, 2004. SIPS 2004., Austin, TX, USA, 2004, pp. 107-112.

\bibitem{Zhang2014}J. Zhang, Y. Lei, and Y. Jin, "Check-node lazy scheduling approach for layered belief propagation decoding algorithm," Electron. Lett., vol. 50, no. 4, pp. 278–279, Feb. 2014.


%%%%%%%%%%%%%



% %%%%%%    POLAR 
 \bibitem[Arikan (2029)]{Arikan2009}E. Arikan, ``Channel Polarization: A Method for constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels'', IEEE Transactions on Information Theory, vol. 55, No. 7, pp. 3051-3073, July 2009.

\bibitem[Elkelesh \textit{et~al.}]{Elkelesh} A. Elkelesh, M. Ebada, ``Polar Codes", Institut fur Nachrichtenubertragung. WebDemos.

%%%%%%%%%%


%%%%%%%%%%%%%%

%%%%%%%%polar 5G design
\bibitem[Bioglio \textit{et~al.}(2021)]{Bioglio2021} V. Bioglio, C. Condo and I. Land, "Design of Polar Codes in 5G New Radio," in IEEE Communications Surveys and Tutorials, vol. 23, no. 1, pp. 29-40, Firstquarter 2021.

\bibitem[Gamage \textit{et~al.}(2020)]{Gamage2020} H. Gamage, V. Ranasinghe, N. Rajatheva and M. Latva-aho, "Low Latency Decoder for Short Blocklength Polar Codes," 2020 European Conference on Networks and Communications (EuCNC), Dubrovnik, Croatia, 2020, pp. 305-310.

\bibitem[Geiselhart \textit{et~al.}(2020)]{Geiselhart2020} M. Geiselhart, A. Elkelesh, M. Ebada, S. Cammerer and S. ten Brink, "CRC-Aided Belief Propagation List Decoding of Polar Codes," 2020 IEEE International Symposium on Information Theory (ISIT), Los Angeles, CA, USA, 2020, pp. 395-400, doi: 10.1109/ISIT44484.2020.9174249.

\bibitem[Piao \textit{et~al.}(2019)]{Piao2019} J. Piao, J. Dai and K. Niu, "CRC-Aided Sphere Decoding for Short Polar Codes," in IEEE Communications Letters, vol. 23, no. 2, pp. 210-213, Feb. 2019.

\bibitem[Cavatassi \textit{et~al.}(2019)]{Cavatassi2019} A. Cavatassi, T. Tonnellier and W. J. Gross, "Asymmetric Construction of Low-Latency and Length-Flexible Polar Codes," ICC 2019 - 2019 IEEE International Conference on Communications (ICC), Shanghai, China, 2019, pp. 1-6.
\bibitem[Shen \textit{et~al.}(2022)]{Shen2022}Y. Shen, W. Zhou, Y. Huang, Z. Zhang, X. You and C. Zhang, "Fast Iterative Soft-Output List Decoding of Polar Codes," in IEEE Transactions on Signal Processing, vol. 70, pp. 1361-1376, 2022.
\bibitem[Kaykac \textit{et~al.}(2020)]{Kaykac2020} Z. B. Kaykac Egilmez, L. Xiang, R. G. Maunder and L. Hanzo, "The Development, Operation and Performance of the 5G Polar Codes," in IEEE Communications Surveys and Tutorials, vol. 22, no. 1, pp. 96-122, Firstquarter 2020.

\bibitem[Ercan \textit{et~al.}(2020)]{Ercan2020} F. Ercan, T. Tonnellier, N. Doan and W. J. Gross, "Practical Dynamic SC-Flip Polar Decoders: Algorithm and Implementation," in IEEE Transactions on Signal Processing, vol. 68, pp. 5441-5456, 2020.

\bibitem[Kestel \textit{et~al.}(2020)]{Kestel2020} C. Kestel et al., "A 506Gbit/s Polar Successive Cancellation List Decoder with CRC," 2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications, London, UK, 2020.

\bibitem[Arli and Gazi(2021)]{ArliGazi2021} A. Ç. Arli and O. Gazi, "A survey on belief propagation decoding of polar codes," in China Communications, vol. 18, no. 8, pp. 133-168, Aug. 2021.

%\bibitem[Zhu \textit{et~al.}(2022)]{Zhu2022} M. Zhu, M. Jiang and C. Zhao, "Adaptive Belief Propagation Decoding of CRC Concatenated NR LDPC and Polar Codes," in IEEE Transactions on Communications, vol. 70, no. 8, pp. 4991-5003, Aug. 2022.

\bibitem[Sun \textit{et~al.}(2019)]{Sun2019} C. Sun, Z. Fei, C. Cao, X. Wang and D. Jia, "Low Complexity Polar Decoder for 5G Embb Control Channel," in IEEE Access, vol. 7, pp. 50710-50717, 2019.

% \bibitem[Ercan \textit{et~al.}(2020)]{ErcanICASSP2020} F. Ercan, T. Tonnellier, N. Doan and W. J. Gross, "Simplified Dynamic SC-Flip Polar Decoding," ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Barcelona, Spain, 2020, pp. 1733-1737.

%\bibitem[Wang \textit{et~al.}(2019)]{Wang2019} Y. Wang, S. Zhang, C. Zhang, X. Chen and S. Xu, "A Low-Complexity Belief Propagation Based Decoding Scheme for Polar Codes - Decodability Detection and Early Stopping Prediction," in IEEE Access, vol. 7, pp. 159808-159820, 2019.
%%%%%%polar and architecture

\bibitem[Sarkis \textit{et~al.}(2014a)]{Sarkis2014a} G. Sarkis, P. Giard, C. Thibeault and W. J. Gross, "Autogenerating software polar decoders," 2014 IEEE Global Conference on Signal and Information Processing (GlobalSIP), Atlanta, GA, USA, 2014, pp. 6-10.

\bibitem[Sarkis \textit{et~al.}(2014b)]{Sarkis2014b} G. Sarkis, P. Giard, A. Vardy, C. Thibeault and W. J. Gross, "Increasing the speed of polar list decoders," 2014 IEEE Workshop on Signal Processing Systems (SiPS), Belfast, UK, 2014, pp. 1-6.

\bibitem[Kam \textit{et~al.}(2021)]{Kam2021} D. Kam, H. Yoo and Y. Lee, "Ultralow-Latency Successive Cancellation Polar Decoding Architecture Using Tree-Level Parallelism," in IEEE Transactions on Very Large Scale Integration (VLSI) Systems, vol. 29, no. 6, pp. 1083-1094, June 2021.

\bibitem[Xiang \textit{et~al.}(2020)]{Xiang2020} L. Xiang, S. Zhong, R. G. Maunder and L. Hanzo, "Reduced-Complexity Low-Latency Logarithmic Successive Cancellation Stack Polar Decoding for 5G New Radio and Its Software Implementation," in IEEE Transactions on Vehicular Technology, vol. 69, no. 11, pp. 12449-12458, Nov. 2020.
\bibitem[Rezaei \textit{et~al.}(2022)]{Rezaei2022} H. Rezaei, V. Ranasinghe, N. Rajatheva, M. Latva-aho, G. Park and O. -S. Park, "Implementation of Ultra-Fast Polar Decoders," 2022 IEEE International Conference on Communications Workshops (ICC Workshops), Seoul, Korea, Republic of, 2022, pp. 235-241.
\bibitem[Liu \textit{et~al.}(2022)]{Liu2022} Z. Liu, R. Liu and H. Zhang, "High-Throughput Adaptive List Decoding Architecture for Polar Codes on GPU," in IEEE Transactions on Signal Processing, vol. 70, pp. 878-889, 2022.



%%%% polar and ML

\bibitem[Doan \textit{et~al.}(2019a)]{Doan2019a} N. Doan, S. A. Hashemi, E. N. Mambou, T. Tonnellier and W. J. Gross, "Neural Belief Propagation Decoding of CRC-Polar Concatenated Codes," ICC 2019 - 2019 IEEE International Conference on Communications (ICC), Shanghai, China, 2019, pp. 1-6.

\bibitem[Hashemi \textit{et~al.}(2019)]{Hashemi2019} S. A. Hashemi, N. Doan, T. Tonnellier and W. J. Gross, "Deep-Learning-Aided Successive-Cancellation Decoding of Polar Codes," 2019 53rd Asilomar Conference on Signals, Systems, and Computers, Pacific Grove, CA, USA, 2019, pp. 532-536.

\bibitem[Doan \textit{et~al.}(2020)]{Doan2020} N. Doan, S. A. Hashemi and W. J. Gross, "Decoding Polar Codes with Reinforcement Learning," GLOBECOM 2020 - 2020 IEEE Global Communications Conference, Taipei, Taiwan, 2020.

\bibitem[Doan \textit{et~al.}(2021)]{Doan2021} N. Doan, S. A. Hashemi, F. Ercan and W. J. Gross, "Fast SC-Flip Decoding of Polar Codes with Reinforcement Learning," ICC 2021 - IEEE International Conference on Communications, Montreal, QC, Canada, 2021, pp. 1-6.

\bibitem[Wodiany and Pop(2019)]{Wodiany2019} I. Wodiany and A. Pop, "Low-Precision Neural Network Decoding of Polar Codes," 2019 IEEE 20th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC), Cannes, France, 2019.

\bibitem[Wen \textit{et~al.}(2019)]{Wen2019} C. Wen, J. Xiong, L. Gui and L. Zhang, "A BP-NN Decoding Algorithm for Polar Codes," 2019 11th International Conference on Wireless Communications and Signal Processing (WCSP), Xi'an, China, 2019.

%\bibitem{Maunder2018} R.G. Maunder, `'The implementation challenges of polar codes", in: AccelerComm White Paper, February 2018, \url{https://artsdocbox.com/Television/89307954-The-implementation-challenges-of-polar-codes.html}




\bibitem[Stimming \textit{et~al.} (2015)]{Stimming2014}A. Balatsoukas-Stimming, M. B. Parizi and A. Burg, "LLR-Based Successive Cancellation List Decoding of Polar Codes," in IEEE Transactions on Signal Processing, vol. 63, no. 19, pp. 5165-5179, Oct.1, 2015.

\bibitem[Tal and Vardy. (2015)]{Tal_vardy2015}I. Tal and A. Vardy, "List Decoding of Polar Codes," in IEEE Transactions on Information Theory, vol. 61, no. 5, pp. 2213-2226, May 2015.

\bibitem[Zhang \textit{et~al.} (2017)]{Zhang2017}Q. Zhang, A. Liu, X. Pan and K. Pan, "CRC Code Design for List Decoding of Polar Codes," in IEEE Communications Letters, vol. 21, no. 6, pp. 1229-1232, June 2017.

%\bibitem[Niu \textit{et~al.} (2015)]{Niu2012}K. Niu and K. Chen, ``CRC-Aided Decoding of Polar Codes'', IEEE Communications Letters, vol. 16, No. 10,  pp.1668-167, October 2015.

\bibitem[Arikan (2008)]{Arikan2008}E. Arikan, "Channel polarization: A method for constructing capacity-achieving codes," 2008 IEEE International Symposium on Information Theory, Toronto, ON, Canada, 2008, pp. 1173-1177.
\bibitem[Fayyaz (2013)]{Fayyaz2013}U. U. Fayyaz and J. R. Barry, "Polar codes for partial response channels," 2013 IEEE International Conference on Communications (ICC), Budapest, Hungary, 2013, pp. 4337-4341.
\bibitem{Yuan2014} B. Yuan and K. K. Parhi, "Early Stopping Criteria for Energy-Efficient Low-Latency Belief-Propagation Polar Code Decoders," in IEEE Transactions on Signal Processing, vol. 62, no. 24, pp. 6496-6506, Dec.15, 2014.
\bibitem[Wang \textit{et~al.}(2019)]{Wang2019} Y. Wang, S. Zhang, C. Zhang, X. Chen and S. Xu, "A Low-Complexity Belief Propagation Based Decoding Scheme for Polar Codes - Decodability Detection and Early Stopping Prediction," in IEEE Access, vol. 7, pp. 159808-159820, 2019.
  
%%%%%%%%%%%%body_of chap4

\bibitem[Fayyaz (2014)]{Fayyaz2014}U. U. Fayyaz and J. R. Barry, "Low-Complexity Soft-Output Decoding of Polar Codes," in IEEE Journal on Selected Areas in Communications, vol. 32, no. 5, pp. 958-966, May 2014
 % \bibitem{Fayyaz2013} U. U. Fayyaz and J. R. Barry, "Polar codes for partial response channels," 2013 IEEE International Conference on Communications Giard, P., Balatsoukas-Stimming, A., Sarkis, G. et al., ``Fast Low-Complexity Decoders for Low-Rate Polar Codes", Journal of Signal Processing Systems,vol. 90, pp. 675–685, August 2016.




\balance
\end{thebibliography}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures/author/mody.pdf}}]{Mody Sy} received his Ph.D. in Engineering Sciences(specializing in Computer Science, Telecommunications, and Electronics) in 2024 from Sorbonne University, Paris, France. He also holds a Master of Engineering (M.Eng.), or Dipl. Ing., in Computer Engineering, majoring in Telecommunications and Networks, from École Supérieure Polytechnique (ESP) of Dakar in 2020. Mody is currently a postdoctoral researcher at EURECOM. His research interests are focused on wireless communications, with a particular emphasis on physical (PHY) layer fundamentals and designs for post-5G mobile communication systems.
% \end{IEEEbiography}


% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author2.png}}]{Second B. Author} (M'76--SM'81--F'87) and all authors may include
% biographies. Biographies are often not included in conference-related
% papers. This author became a Member (M) of IEEE in 1976, a Senior
% Member (SM) in 1981, and a Fellow (F) in 1987. The first paragraph may
% contain a place and/or date of birth (list place, then date). Next,
% the author's educational background is listed. The degrees should be
% listed with type of degree in what field, which institution, city,
% state, and country, and year the degree was earned. The author's major
% field of study should be lower-cased.

% The second paragraph uses the pronoun of the person (he or she) and not the
% author's last name. It lists military and work experience, including summer
% and fellowship jobs. Job titles are capitalized. The current job must have a
% location; previous positions may be listed
% without one. Information concerning previous publications may be included.
% Try not to list more than three books or published articles. The format for
% listing publishers of a book within the biography is: title of book
% (publisher name, year) similar to a reference. Current and previous research
% interests end the paragraph.

% The third paragraph begins with the author's
% title and last name (e.g., Dr.\ Smith, Prof.\ Jones, Mr.\ Kajor, Ms.\ Hunter).
% List any memberships in professional societies other than the IEEE. Finally,
% list any awards and work for IEEE committees and publications. If a
% photograph is provided, it should be of good quality, and
% professional-looking. Following are two examples of an author's biography.
% \end{IEEEbiography}



% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author3.png}}]{Third C. Author, Jr.} (M'87) received the B.S. degree in mechanical
% engineering from National Chung Cheng University, Chiayi, Taiwan, in 2004
% and the M.S. degree in mechanical engineering from National Tsing Hua
% University, Hsinchu, Taiwan, in 2006. He is currently pursuing the Ph.D.
% degree in mechanical engineering at Texas A{\&}M University, College
% Station, TX, USA.

% From 2008 to 2009, he was a Research Assistant with the Institute of
% Physics, Academia Sinica, Tapei, Taiwan. His research interest includes the
% development of surface processing and biological/medical treatment
% techniques using nonthermal atmospheric pressure plasmas, fundamental study
% of plasma sources, and fabrication of micro- or nanostructured surfaces.

% Mr. Author's awards and honors include the Frew Fellowship (Australian
% Academy of Science), the I. I. Rabi Prize (APS), the European Frequency and
% Time Forum Award, the Carl Zeiss Research Award, the William F. Meggers
% Award and the Adolph Lomb Medal (OSA).
% \end{IEEEbiography}

%\EOD



% %\newpage

% \section{Biography}

% \vspace{11pt}


% \vspace{-33pt}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{figures/author/mody.pdf}}]{Mody Sy} received the M. Eng. degree known as Dipl. Ing. in Computer Engineering with a major in Telecommunications and Networks from Ecole Supérieure Polytechnique (ESP ) of Dakar, Senegal, in 2020. Currently, he is a research assistant in the Communication Systems Department at EURECOM working towards a PhD degree in Computer Science and Telecommunications from the Doctoral School EDITE of Sorbonne University, Paris, France.

% His research interests are in the area of Wireless Communications with a special focus on Physical (PHY) layer fundamentals within Mobile Communication Systems.
% \end{IEEEbiography}
% \vspace{11pt}
% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{fig1}}]{Raymond Knopp}
% \lipsum[1-1]
% \end{IEEEbiography}
% \vspace{11pt}


\vfill

\end{document}
