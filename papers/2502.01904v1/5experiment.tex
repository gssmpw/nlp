\section{Experimental evaluation}
\label{sec:exp}

In this section, we evaluate the proposed common neighbor estimation algorithms under \epldp through experiments. 

\subsection{Experimental Settings}
\input{figtab}

\noindent
{\bf Datasets.}
We use 15 datasets from KONECT ({\url{http://konect.cc/}}). 
Table \ref{tab:summary} shows the statistics of the datasets. 
$|U|$ and $|L|$ are the number of vertices in the upper and lower layers. $|E|$ is the number of edges in the graph. 

\noindent
{\bf Algorithms.} 
We evaluate the following common neighborhood estimation algorithms under \epldp. 
\begin{itemize}
    \item \naive: the algorithm that returns the number of common neighbors between $u$ and $w$ on the noisy graph $G'$;
    \item \bs: the one-round algorithm returns an unbiased estimate of $\pqx$ based on the noisy graph $G'$;
    \item \advss: the multiple-round single-source algorithm that returns the unbiased estimator $\fq(u,w)$ by utilizing the local neighborhood of $u$;     
    \item \advds: the multiple-round double-source algorithm that returns the unbiased estimator $ \alpha \fq + (1 - \alpha) \fx$ ($\alpha \in [0,1]$) by utilizing the local neighborhoods of both $u$ and $w$.
\end{itemize}
{We also implement two variants of \advds: \advdsbasic and \advdeg. 
\advdsbasic returns the average of the two single-source estimators $\fq$ and $\fx$ ($ \frac{\fq +\fx}{2}$). It spends $\varepsilon_1$ on noisy graph construction and $1 - \varepsilon_1$ on the Laplace mechanism and does not estimate $deg(u)$ or $deg(w)$. 
Similarly to \advds, \advdeg returns $ \alpha \fq + (1 - \alpha) \fx$ ($\alpha \in [0,1]$) and adopts the same optimizations for the allocation of privacy budgets to find $\varepsilon_1$ and $\alpha$. 
The difference is that \advdeg assumes that the vertex degrees are public and it does not need an additional round for vertex degree estimation. }

{To better evaluate the edge LDP algorithms, we also implement the \cdp algorithm under the centralized model, which assumes the data curator has access to the entire bipartite graph. \cdp directly applies the Laplacian mechanism to the number of common neighbors of two query vertices. Since the global sensitivity of $\pqx$ in the central model is $1$, \cdp returns $\pqx + Lap(\frac{1}{\varepsilon})$. }
All algorithms are implemented in C++. The experiments are run on a Linux server with an Intel Xeon 6342 processor and 512GB memory.
% and let it run on varying $\varepsilon_1$ values

\noindent
{\bf Parameter settings.} 
By default, the privacy budget $\varepsilon$ is set to $2$. We also allow it to vary from $1$ to $3$ with increments of $0.5$. 
For \advss and \advdsbasic, $\varepsilon_1$ is set to $0.5 \varepsilon$ by default. 
For \advds, we set $\varepsilon_0 = 0.05 \varepsilon$ for degree estimations. 
For each algorithm, we uniformly sample $100$ vertex pairs on the same layer and report the mean absolute error, the average of the absolute differences between the predicted and true values across all sampled vertex pairs. 
To evaluate the performance of \advds, we use $\kappa$ to quantify the imbalance between two vertex degrees. 
Specifically, on a given pair of vertices ($u$ and $w$) with the parameter $\kappa$,
we have $\max(deg(u), deg(w)) > \kappa \times \min(deg(u), deg(w))$. 
% either either 
% $deg(u) > \kappa deg(v)$ or $deg(v) > \kappa deg(u)$.
% Specifically, in a sample of vertex pairs with $\kappa$, each pair $u$, $v$ exhibits one of two scenarios: either $deg(u) > \kappa deg(v)$ or $deg(v) > \kappa deg(u)$. 
% For each algorithm, we run it for $10$ rounds and report the average relative error. 


\noindent
\textbf{Evaluate the effectiveness of edge LDP algorithms across different datasets.} 
In Fig. \ref{default:effect}, we report the performances of the edge LDP algorithms including \naive, \bs, \advss, \advds, and \advdeg on $100$ uniformly sampled vertex pairs when $\varepsilon = 2$. 
{Note that we also include the performance of \cdp under the centralized model for comparison.} 
% Overall trend: 
First, we observe that the multiple-round algorithms (\advss, \advds, and \advdeg) significantly outperform \naive and \bs across all datasets. 
% Specifically, \advss and \advds significantly outperform \naive and \bs, achieving mean absolute errors lower by up to four and two orders of magnitude, respectively.
Specifically, \advss and \advds achieve mean absolute errors lower by up to four and two orders of magnitude, respectively. 
% by up to four and two orders of magnitude in mean absolute errors, respectively. 
% Specifically, \advss and \advds demonstrate significantly better performance than \naive and \bs, achieving mean absolute errors lower by up to four and two orders of magnitude, respectively.
% reason:
This is because \advss and \advds address the overcounting issue due to the dense noisy graph with \naive by deriving unbiased estimates. 
Meanwhile, compared to the \bs algorithm that produces unbiased estimates by considering all vertices on the opposite layers as possible common neighbors, \advss and \advds induce much smaller mean absolute errors by reducing the candidate pool common neighbors to the neighbors of query vertices. 
% pattern 2: \advds > advss
We also observe that \advds consistently produces smaller mean absolute errors than \advss. 
For example, on \texttt{Netflix}, the mean absolute error of \advds is approximately one-fifth that of \advss. 
% based on the local neighborhoods of both query vertices 
This is because \advds integrates the two single-source estimators and dynamically adjusts the privacy budget allocation based on the query vertices. 
%%% pattern new: advdeg better than advds. 
{
In \figuresixa, we observe that \advdeg generally produces slightly smaller mean absolute errors compared to \advds. 
%%% reason: 
This is because \advdeg does not need to spend an additional privacy budget for degree estimation, which leads to more privacy budgets for noisy graph construction and the Laplace mechanism (i.e., $\varepsilon_1$ and $\varepsilon_2$ becomes larger). }
% pattern 3: between \bs and \naive, with statistics.
We also observe that \bs achieves much lower mean absolute errors than \naive because \bs leverages flipping probability to obtain unbiased estimators, which mitigates the over-counting issue in \naive. 

%%% additional pattern: central is the best. 
{
In addition, \cdp results in lower errors than all algorithms with edge LDP. 
This illustrates the limitations of the local model in terms of data utility due to stronger privacy guarantees. 
}


\noindent
\textbf{Evaluate the computational time costs across datasets.} 
{
In Fig. \ref{default:time}, we report the computational time costs of \naive, \bs, \advss, \advds, and \advdeg on $100$ vertex pairs when $\varepsilon = 2$. }
Note that our evaluation focuses on the computational time costs incurred by both the vertex side and the data curator side. 
We can observe that the time costs of \naive, \bs, and \advss remain relatively comparable while \advds requires more time. 
This is because the time complexities of \naive, \bs, and \advss depend on the number of vertices on the opposite layers of the query vertices i.e., $O(n_1)$, which is incurred by noisy graph construction. 
Since \advds needs an additional $O( n_2)$ time for the estimation of the average degree, its total time complexity becomes $O(n)$ and exceeds the others. 
% its dominating time complexity is $O(|V(G)|)$, which arises from estimating the average degree of vertices sharing the same layer as the query vertices. 
Despite this, \advds remains highly efficient and can scale effectively to bipartite graphs with 300 million edges (i.e., \texttt{Orkut}). Also, in practice, the time required for average degree estimation is distributed across vertices. 
{Additionally, we observe that the \advdeg algorithm runs faster than \advds and incurs comparable time costs to \advss. This is because \advdeg does not need an additional round to estimate the vertex degrees. }

\noindent
\textbf{Evaluate the effect of the privacy budget $\varepsilon$.} 
As shown in Fig.~\ref{fig.vary}, we report the mean absolute errors of \naive, \bs, and \advds on 8 datasets, as $\varepsilon$ varies. 
{Note that we also include \cdp under central differential privacy for comparison.} 
% trend1: all become better as ep increases 
We observe that all algorithms produce smaller mean absolute errors as $\varepsilon$ increases, which is consistent with our L2 loss analysis. 
As $\varepsilon$ increases, the difference between any noisy graph constructed by randomized responses and the input graph becomes smaller. 
% For \naive, this means directly counting the number of common neighbors on the noisy graph will be more accurate. 
% for bs, 
Another pattern is that the multiple-round algorithms (\advss and \advds) significantly outperform \naive and \bs, with mean absolute errors up to four orders of magnitude lower. 
{This is because the expected L2 losses of \naive and \bs are $O(n_1^2)$ and $O(n_1)$, respectively, while the expected L2 losses of \advss and \advds only depend on vertex degrees.} 
\advds consistently outperforms \advss on varying values of $\varepsilon$ because \advds integrates both single-source estimators and employs privacy budget allocation optimizations for minimized L2 loss. 
We also observe that \bs consistently outperforms \naive as the privacy budget increases. 
{
As expected, \cdp produces smaller mean absolute errors than algorithms under edge LDP, which has stronger privacy guarantees. 
}

% This is because \bs leverages flipping probability during noisy graph construction to obtain unbiased estimators, which mitigates the over-counting issue in \naive.

\noindent
\textbf{Evaluate the effect of privacy budget allocation optimization on \advds. }
In Fig.~\ref{Fig.find}, we present the mean absolute errors of \advdsbasic in four datasets, as $\varepsilon_1$ ranges from $0.1 \varepsilon$ to $0.7 \varepsilon$, where $\varepsilon = 2$  and $\varepsilon_2 = \varepsilon - \varepsilon_1$. 
Note that \advdsbasic does not employ the privacy budget allocation optimization. 
% and its performance is based on a predetermined split between $\varepsilon_1$ and $\varepsilon_2$. 
In contrast, \advds adjusts $\varepsilon_1$ and the contribution of two single-source estimators (measured by $\alpha$) based on the query vertices. 
We use red dashed horizontal lines to indicate the mean absolute errors associated with \advds. 
First, the optimal budget allocation plan varies across datasets and it is unrealistic to fix $\varepsilon_1$ and $\varepsilon_2$ for all datasets. 
This is because optimal budget allocation depends on the degrees of the query vertices, as shown in Table \ref{tab:complexitycompare}. 
%%%% 
Also, for each dataset, the mean absolute error with \advds is close to or even smaller than the smallest mean absolute error of \advdsbasic on varying values of $\varepsilon_1$. 
% This implies that \advds can find the allocation of the privacy budget and the weights of two single-source estimators that result in near-optimal L2 loss. 
This implies that \advds can find $\varepsilon_1$ and $\alpha$ that result in near-optimal L2 loss. 

% {\color{red} as well as the weighting of two estimators} that approximates the optimum. 

%%% need to add more explanations to this experiment 
\noindent
\textbf{Evaluate the effectiveness of \advds on vertex pairs with imbalanced degrees.} 
In Fig.~\ref{fig.balance}, we report the mean absolute errors of \advss, \advdsbasic, and \advds across four datasets, as $\kappa$ ranges from $10^0$ to $10^3$, with $\varepsilon = 2$. 
Here, $\kappa$ quantifies the imbalance between two vertex degrees. 
% in a sample of vertex pairs. 
For \advdsbasic, $\varepsilon_1$ is set to $0.5 \varepsilon$. 
We observe that the mean absolute errors of \advss and \advdsbasic increase as $\kappa$ increases, while the performance of \advds remains relatively unchanged. 
%%% explain why advss and advds basic increases. 
This is because \advss only relies on one query vertex to construct the unbiased estimator $\fq$. 
Thus, if $deg(u,G)$ is large, the error increases accordingly, as indicated in Table \ref{tab:complexitycompare}. 
% as indicated by the expected L2 loss of \advss in Table \ref{tab:complexitycompare}. 
For \advdsbasic, it performs slightly better than \advss when $\kappa$ is small because it allows $\fq$ and $\fx$ to contribute equally (i.e., $(\fq + \fx)/2$). 
However, when the vertex degrees are highly imbalanced ($\kappa$ becomes large), the errors of \advdsbasic escalate rapidly. 
Also, neither \advss nor \advdsbasic can adjust privacy budget allocations based on the query vertices. 
% Also, \advss and \advdsbasic cannot adjust their privacy budget allocations. 
In contrast, \advds uses $\alpha$ to model the contribution of two query vertices and dynamically adjust privacy budgets to minimize L2 loss. 
(1) If the vertex degrees are large, \advds allocates more privacy budget to $\varepsilon_1$. 
(2) If the vertex degrees are imbalanced, \advds adjusts $\alpha$ so that the query vertex with a smaller degree has a greater contribution. 
% Additionally, we observe that \advds outperforms \advss in most settings. 
% This is because \advss only utilizes the local neighbors of $u$ and its performance is undermined when the degree of $u$ happens to be very big. \advss is more robust to imbalanced vertex pairs than \advss because it can allocate more privacy budget to $\varepsilon_1$ if the incoming vertex pairs have large degrees. 


\noindent
\textbf{Evaluate the communication costs of all algorithms.}
{
% All algorithms under \epldp must interact with the data curator.
In Fig.~\ref{fig.cost}, we report the communication costs (in MB) of each algorithm averaged across 100 randomly sampled vertex pairs in four datasets, as $\varepsilon$ varies. 
%%% pattern 1 
We observe that \naive and \bs require approximately the same message sizes. 
This is because \naive and \bs rely solely on randomized responses to satisfy edge LDP. Given a fixed $\varepsilon$, they apply randomized responses with the same flipping probability, resulting in the same expected number of noisy edges.
%%% pattern 2
% Another clear pattern is that 
Also, \advss and \advds incur higher communication costs than \naive and \bs, 
% For these multiple-round algorithms, their communication costs are incurred by 
which are incurred by 
(1) uploading the noisy edges to the data curator
(2) downloading the noisy edges to the query vertices 
(3) sending the estimators ($\fq$ or $\fx$) from the query vertices. 
For \advds, the communication costs are higher as it utilizes the noisy edges from both query vertices and also needs to send vertex degree estimated to the data curator. 
Note that the highest average communication cost for \advds across datasets is approximately $100$ MB, which is modest in practical terms. 
% Thus, when the download speed is 20 Mbps (recommended speed in YouTube[7]), the associated additional time cost is about 40 seconds. 
}


\noindent
\textbf{Evaluate the effect of the number of vertices.}
{
In Fig.~\ref{fig.scale}, we report the mean absolute errors of \cdp, \naive, \bs, \advss and \advds in four datasets as the number of vertices increases. 
Specifically, on each dataset, we uniformly sample $20\%$, $40\%$, $60\%$, $80\%$, and $100\%$ of all vertices and run the algorithms on the subgraphs induced by the sampled vertices. The privacy budget $\varepsilon$ is fixed at $2$. 
%%
First, we observe that the performances of \cdp, \advss, and \advds remain relatively unchanged. 
This aligns with our analysis for \advss and \advds, where their L2 losses depend solely on the allocation of the privacy budget, the degrees of the query vertices, and $\alpha$, the weighting parameter adjusting the contribution of $\fq$ and $\fx$. 
For \cdp, its errors come only from the added Laplacian noise, which is also not related to the number of vertices in the bipartite graph. 
%%  pattern 2: 
We also observe that the mean absolute errors of \naive and \bs increase steadily as the number of vertices increases. 
%% evidence: 
For instance, on \texttt{Dui} and \texttt{OG}, the mean absolute errors of \naive increase approximately fivefold when the number of vertices increases from $20\% \times |V|$ to $100\% \times  |V|$. 
Meanwhile, the mean absolute errors of \bs show less sensitivity, increasing approximately 2.3 times. 
%% reason
This is because the expected L2 losses of \naive and \bs are $O(n_1^2)$ and $O(n_1)$, respectively. }
