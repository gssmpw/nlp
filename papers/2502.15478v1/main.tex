% ICCV 2025 Paper Template; see https://github.com/cvpr-org/author-kit

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage{iccv}              % To produce the CAMERA-READY version
% \usepackage[review]{iccv}      % To produce the REVIEW version
% \usepackage[pagenumbers]{iccv} % To force page numbers, e.g. for an arXiv version

% Import additional packages in the preamble file, before hyperref
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs} % for professional tables
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{xspace}
\usepackage{lipsum}  
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{algorithmic}
\usepackage{tcolorbox}
\usepackage{colortbl}
\usepackage{float}
\usepackage[ruled, longend, linesnumbered]{algorithm2e}
\usepackage{wrapfig}
\usepackage{adjustbox}
\usepackage{bbding}
\usepackage{wrapfig}
\usepackage{svg}
\usepackage{nicefrac}
\usepackage{minitoc}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, 
% e.g. with the file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete *.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you should be clear).
\definecolor{iccvblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=iccvblue]{hyperref}

\definecolor{colorhead}{HTML}{e2ecda}
\newcommand{\colorhead}{e2ecda}

\providecommand{\yulun}[1]{\textcolor{red}{[{\bf #1}]}}
\providecommand{\kai}[1]{\textcolor{blue}{[{\bf #1}]}}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\paperID{0000} % *** Enter the Paper ID here
\def\confName{ICCV}
\def\confYear{2025}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{CondiQuant: Condition Number Based Low-Bit Quantization \\ for Image Super-Resolution}

%%%%%%%%% AUTHORS - PLEASE UPDATE
\author{
Kai Liu$^{1}$\thanks{Equal contribution.}, \enspace Dehui Wang$^{1*}$, \enspace Zhiteng Li$^{1}$, \enspace Zheng Chen$^{1}$,\\ \enspace Yong Guo$^{2}$, \enspace Wenbo Li$^{3}$, \enspace Linghe Kong$^{1}$\thanks{Corresponding authors: Yulun Zhang, yulun100@gmail.com; Linghe Kong, linghe.kong@sjtu.edu.cn}, \enspace Yulun Zhang$^{1\dagger}$\\
\textsuperscript{1}Shanghai Jiao Tong University,\enspace \textsuperscript{2}South China University of Technology,\enspace \textsuperscript{3}Huawei Noahâ€™s Ark Lab\\
}

\begin{document}
\maketitle
\begin{abstract}
Low-bit model quantization for image super-resolution (SR) is a longstanding task that is renowned for its surprising compression and acceleration ability.
However, accuracy degradation is inevitable when compressing the full-precision (FP) model to ultra-low bit widths ($2\sim4$ bits).
Experimentally, we observe that the degradation of quantization is mainly attributed to the quantization of activation instead of model weights.
In numerical analysis, the condition number of weights could measure how much the output value can change for a small change in the input argument, inherently reflecting the quantization error.
Therefore, we propose \textbf{CondiQuant}, a \textbf{condi}tion number based low-bit post-training \textbf{quant}ization for image super-resolution.
Specifically, we formulate the quantization error as the condition number of weight metrics.
By decoupling the representation ability and the quantization sensitivity, we design an efficient proximal gradient descent algorithm to iteratively minimize the condition number and maintain the output still.
With comprehensive experiments, we demonstrate that CondiQuant outperforms existing state-of-the-art post-training quantization methods in accuracy without computation overhead and gains the theoretically optimal compression ratio in model parameters.
Our code and model are released at \href{https://github.com/Kai-Liu001/CondiQuant}{https://github.com/Kai-Liu001/CondiQuant}.
\end{abstract}
\setlength{\abovedisplayskip}{2pt}
\setlength{\belowdisplayskip}{2pt}

\vspace{-6mm}
\section{Introduction}
\vspace{-2mm}
Image super-resolution (SR) aims to restore the high-resolution (HR) images from the low-resolution counterparts.
It is a foundational computer vision task in low-level vision and image processing, widely studied in medical imaging~\cite{TCJ2008SuperGreenspan,ICTSD2015SuperIsaac,CVPR2017SimultaneousHuang}, surveillance~\cite{ESP2010SuperZhang,AMDO2016ConvolutionalRasti}, remote sensing~\cite{Bandara_2022_CVPR}, and mobile phone photography~\cite{wu2024one}.
Nonetheless, the existing edge devices' notorious limited computation and memory ability hinder real-world deployment.
Therefore, it is increasingly urgent to develop model compression and acceleration techniques for SR models to reduce the redundancy in both model parameters and inference computation.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/sota.pdf}
    \vspace{-8mm}
    \caption{Comparison with SOTA PTQ methods on five benchmarks. Our CondiQuant gains consistently better performance.}
    \label{fig:intro-visual-comp}
    \vspace{-7.5mm}
\end{figure}

Model quantization~\cite{choukroun2019low,ding2022towards,hubara2021accurate,li2021brecq} is a powerful compression technique that compresses the model from full-precision to low-bit representations.
With quantization, the time-consuming floating-point operations are converted into efficient integer ones, making it an ideal candidate for model compression in resource-constrained edge devices.
However, the conversion inevitably leads to severe performance degradation, especially when compressing to ultra-low bit width (\ie $2\sim 4$ bits).
The situation is more severe in vision transformers (ViTs) due to the deterioration of self-attention.





The two branches of quantization, aka quantization-aware training (QAT) and post-training quantization (PTQ), deal with the degradation in different ways.
QAT, a firm adherent of backpropagation, concurrently optimizes the model weights and quantizers' parameters via straight-through estimator (STE)~\cite{courbariaux2016binarized}.
Though inspiring results are obtained, the ineluctable demand for large datasets and long-time training discourages the deployment.
Whereas, PTQ is much more efficient.
Most PTQ methods utilize efficient algorithms to calculate the quantizers' parameters in a small calibration set.
Given the complexity of both branches, PTQ is usually inferior to QAT and calls for advanced solutions.

To improve the inferior performance of PTQ, we observe two key experimental phenomena.
The first observation is about the attribution of degradation.

\vspace{-2mm}
\begin{tcolorbox}[colback=yellow!10, colframe=black, boxrule=0.5mm]
\textit{\textbf{Observation 1:} The degradation of quantization is mainly attributed to the quantization of \textbf{activations}.}
\end{tcolorbox}
\vspace{-2mm}

Therefore, we leverage condition number, a metric in numerical analysis, to reflect the changes caused by the quantization of activations.
In detail, condition number could measure how much the output value can change given a disturbance in the input value, \ie the quantization error of activation.
Considering a small disturbance, the smaller the condition number is, the smaller the output varies.
Thereafter, one way to reduce the quantization error is by minimizing the condition number of the weight matrix.

Inspired by MagR~\cite{zhang2024magr}, we verify that their observation in LLMs also holds in SR models, which is
\vspace{-2mm}
\begin{tcolorbox}[colback=yellow!10, colframe=black, boxrule=0.5mm]
\textit{\textbf{Observation 2:} The feature matrix $X$ across all linear layers is approximately \textbf{rank deficient}.}
\end{tcolorbox}
\vspace{-2mm}
In a linear layer, the output $Y$ can be expressed as matrix multiplication $Y=XW$, where $W$ is the weight matrix and $X$ is the feature matrix.
When $X$ is rank-deficient, there are infinite solutions for $W$ that satisfy the equation.
This desirable property allows a shift on the weight matrix to quantization friendliness while maintaining the output.

Based on the previous two observations, we focus on the impact of quantization of activation, establish its relationship with condition number, formulate the optimization problem, and derive proximal gradient descent to solve it efficiently.  
With the proposed CondiQuant, the restoration accuracy is improved evidently as shown in  \cref{fig:intro-visual-comp}.

To sum up, our main contributions are fourfold:
\begin{enumerate}
    \item We design CondiQuant, a novel PTQ method for image SR based on condition number. 
    CondiQuant gains theoretically optimal compression and speedup ratios with currently minimum performance degradation.
    \item We propose that the model's sensitivity to quantization is related to the condition number of weights in the linear layers and could be hereby optimized efficiently.
    \item We design an efficient algorithm based on proximal gradient descent to reduce the condition number of weight while approximately keeping the output still.
    \item Comprehensive comparison experiments are conducted to show the state-of-the-art performance on efficiency and effectiveness of our proposed CondiQuant. Besides, extensive ablation studies are conducted to prove the robustness and efficacy of our proposed CondiQuant. 
\end{enumerate}


\section{Related Work}
\vspace{-2mm}
\paragraph{Image Super-Resolution.}
The trailblazing research on image super-resolution with deep neural network is SRCNN~\cite{dong2016image}, which utilizes convolution layers to replace conventional methods in SR.
Since then, dazzling network architectures~\cite{chen2022cross,chen2023dual,lim2017enhanced,zhang2018image} are designed to achieve more stirring image restoration accuracy.
RDN~\cite{zhang2018residual} designs dense skip connection and global residual to utilize abundant local and global features.
With the advance of vision transformer, SwinIR~\cite{liang2021swinir} uses window-attention to fully make use of global information.
As reconstruction accuracy increases, researchers focus more on model parameters and operations.
Generally, the ViT-based SR networks are much smaller and faster than pure CNNs.
However, even the advanced SR networks like SwinIR, current SR models are still too large to be deployed on resource-constrained edge devices.
Therefore, research on quantization on ViT-based networks is urgently needed to make SR possible on mobile devices.

\vspace{-4mm}
\paragraph{Post-Training Quantization.}
PTQ is famous for its fast speed and low cost during quantization.
Recently, excellent PTQ methods have been proposed to advance its performance and efficiency.
As a PTQ method specifically for ViT, PTQ4ViT~\cite{yuan2022ptq4vit} proposed twin uniform quantization to reduce quantization error on the output of softmax and GELU.
RepQ~\cite{li2023repq} decouples the quantization and inference processes and ensures both accurate quantization and efficient inference.
NoisyQuant~\cite{liu2023noisyquant} surprisingly finds that adding a fixed Uniform noisy bias to the values being quantized can significantly reduce the quantization error.
However, most of the above PTQ methods are only for Transformer blocks and the generalization ability on SR tasks is relatively low.
Whereas, 
2DQuant~\cite{liu20242dquant} searches the clipping bounds in different ways on different distributions and is currently the best PTQ method on the SR task.
However, most of the above methods only concentrate on the quantization process and ignore adjustments in the weights. 

\vspace{-4mm}
\paragraph{Condition Number.}
The concept of the condition number originated and developed in numerical analysis~\cite{turing1948rounding, neumann1947numerical}.
It measures how much the output value of the system or function can change for a small change in the input.
A matrix with a high condition number is said to be ill-conditioned and leads to huge output changes given a small disturbance in input. 
It also plays an important role in machine learning (ML).
Freund proposed optimization algorithms generally converge faster when the condition number is low~\cite{freund2018condition}.
In causal inference, it is used to evaluate the numerical stability of causal effect estimation~\cite{spencer2021condition}.
Additionally, the condition number is leveraged to enhance the numerical stability of regression models by fine-tuning hidden layer parameters~\cite{xiao2018dynamical}.
In this work, we innovatively leverage the condition number into quantization to measure the quantization sensitivity.
We formulate the optimization of quantization error via condition number and propose CondiQuant to solve it efficiently.

\vspace{-2mm}
\section{Method}
\vspace{-1mm}
\subsection{Preliminaries}
\vspace{-1mm}
Given an SR network, we use upper and lower clipping bounds to quantize weights and activations~\cite{liu20242dquant}.
Usually, we leverage the fake quantization to simulate the quantization process with no simulation error.
The fake-quantize process, \ie quantization-dequantization, can be written as:
\begin{equation}
\begin{aligned}
    x_c = \text{Clip}(x, l, u),
    x_{r} =  \text{R}( s (x_c - l)),
    x_{q} = s x_{r} + l,
\end{aligned}\label{eq:fake_quant}
\end{equation}
where $x$ denotes weight $w$ or activation $a$ being quantized and $s = (2 ^ N - 1)/(u-l)$ is the quantization ratio.
$l$ and $u$ denote the lower bound and upper bound for clipping, respectively. 
$\text{Clip}(x, l, u)=\text{min}(\text{max}(x, l), u)$ constrains the input to be between $l$ and $u$, and $\text{R}(\cdot)$ rounds the input to its nearest integer.
With the above process, the continuous values are dispersed into discrete candidates.

\vspace{-1mm}
\subsection{Analysis}
\vspace{-1mm}
To analyze the loss attribution in quantization, we first rewrite the linear layer with quantization as follows:
\begin{align}
\hat{Y}&:=\hat {X} \hat{W}=(X + \delta X)(W+\delta W)\notag\\
&=X W+X \delta W + \delta XW + \delta X \delta W,
\label{eq:linear_func}
\end{align}
where $\hat{X}$ denotes the quantized value and $\delta X$ denotes the quantization error of $X$.
The second-order term $\delta X \delta W$ can be ignored due to its tiny impact on performance.
Thus~\cref{eq:linear_func} can be rewritten as:
\begin{equation}
\begin{aligned}
\hat{Y}\approx X W+X\delta W + \delta XW = Y +X \delta W + \delta XW.
\end{aligned}
\end{equation}
Additionally, we observe that the negative influence of $X \delta W$ and $\delta X \delta W$ is much smaller than $\delta XW$, shown in Table~\ref{tab:method-attribution}.
\begin{table}[t]
    \centering
    % \vspace{-2mm}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|cccc}
    \toprule
    \rowcolor[HTML]{\colorhead}     & $Y$ & $Y +X \delta W$ & $Y + \delta X W$ & $Y +\delta X \delta W  $ \\
    \midrule
    PSNR &32.2543 & 32.0117 & 31.3304 &32.2519 \\
    SSIM &0.9293 & 0.9270 & 0.9221 & 0.9293 \\
    \bottomrule
    \end{tabular}
    }
    \vspace{-3mm}
    \caption{Attribution of quantization loss. $Y$ denotes the FP model and the rest denotes performing quantization on $W$, $X$, and both.}
    \label{tab:method-attribution}
    \vspace{-3mm}
\end{table}
This result can be explained for two reasons.
First, the activation varies with different inputs while the weight is fixed. 
Therefore, the average value of the absolute value of the $\delta X$ elements is much greater than that of $\delta W$.
Second, the $W$ is sensitive to minor changes, \ie $\delta X$.
Hence, we only concentrate on $\delta X W$ and ignore $X \delta W$ in the following discussion.
So we can further approximate the loss:
\begin{equation}
\begin{aligned}
    \hat{Y} \approx XW + \delta XW,\quad
    \delta Y \approx \delta X W.
\end{aligned}\label{eq:ignore}
\end{equation}
\cref{eq:ignore} indicates that the degradation of model performance can be divided into two components: (1) the magnitude of activation quantization error and the sensitivity of the weight to disturbance.
To minimize the approximate loss, a naive solution is to reduce the Frobenius norm of $\delta X$ \ie $||\delta X||_F$.
However, it is unpractical as $\delta X$ varies with different inputs, and rounding-off errors are impossible to reduce especially with ultra-low bits.
Therefore, we focus on the model's sensitivity to quantization, related to condition number.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/rank.pdf}
    \vspace{-7.5mm}
    \caption{Distribution of activation ranks along the ($\times 2$) model depth.
    Most activations are severely rank deficient.
    }
    \label{fig:method-rank}
    \vspace{-5.5mm}
\end{figure}

\vspace{-6mm}
\subsection{CondiQuant}\label{sec:condiquant}
\vspace{-1mm}
We begin with the observation of rank deficiency of the feature matrix.
Then we derive the optimization objective and illustrate the methodology to arrive at the solution.

\noindent\textbf{Rank Deficiency.}
We visualize the rank ratio in \cref{fig:method-rank}.
Most of the layers are rank deficient and only two layers are full rank.
The mean value of the rank ratio is 0.626.
In the linear layer, the process is matrix multiplication, \ie $Y=XW$.
If $W$ is rank deficient, there exist infinite $W^{\prime}$ that satisfies $XW=XW^{\prime}$.
Hence, this result serves as a theory foundation to select $W^{\prime}$ to minimize $\delta X W$.


\noindent\textbf{Formulation.}
In this section, we formulate the relationship between model sensitivity and condition number.
We begin with the inequality of $ \|\delta Y \| _2$ and $\|Y\|_2$:
\begin{align}
    \left \| \delta Y \right \| _2 &= \left \|  \delta X W \right \| _2 \le \left \| \delta X \right \| _2 \left \|  W \right \|_2,
    \label{eq:condition_number1} \\
    \|Y\|_2 &= \|XW\|_2\ge \|X\|_2 \ \sigma_{min}(W),
    \label{eq:condition_number2}
\end{align}
where $\|\cdot \| _2$ is the bi-norm of the matrix, and $\sigma _{min}(\cdot)$ denotes the minimum singular value.
Combining~\cref{eq:condition_number1} and~\cref{eq:condition_number2}, we can establish the relationship between quantization loss and condition number, which can be written as:
\begin{equation}
\begin{aligned}
     \frac{\| \delta Y \|_2}{\|Y\|_2} \le \frac{\|\delta X\|_2\| W\|_2}{\|X \|_2\ \sigma _{min}(W) } = \kappa(W) \frac{\|\delta X\|_2}{\|X\|_2},
\end{aligned}
\end{equation}
where $\kappa(W)$ denotes the condition number of $W$.
This formula shows that under the same rounding-off error, the impact of quantization is greater with larger $\kappa(W)$.
Detailed derivation can be found in the supplementary materials.
Therefore, we minimize the condition number of $W$ and maintain the output.
The objective can be written as:
\begin{equation}
\begin{aligned}
     \min_{W} \kappa(W) = \frac{\sigma_{\max}(W)}{\sigma_{\min}(W)}, 
     \text{s.t.} ||XW - X\hat{W}||_F \le \epsilon,
\end{aligned}
\end{equation}
where $\epsilon$ is a small positive number that limits the magnitude of the loss.
However, it is a non-convex and non-smooth optimization when minimizing the condition number directly.
To address this, we construct a proxy objective function to enable optimization and propose the proximal gradient method as an effective approach for solving it.

\begin{figure*}[t!]
    \centering
    \includegraphics[width=\linewidth]{figs/overview.pdf}
    \vspace{-8.5mm}
    \caption{Overview of our proposed CondiQuant which employs iterative optimization to minimize the condition number of weight matrix while maintaining the output still. The gradient descent step updates the weight matrix with gradients to ensure the output is close to the original. The proximal descent step minimizes the condition number with the proximal operator. The above two steps are conducted iteratively before reaching the convergence criterion, \ie the max iteration step. We illustrate the effect of both steps. With CondiQuant, the weight matrix is converted into a quantization-friendly and well-conditioned one while the output is close to the original. 
}
    \label{fig:method-overview}
    \vspace{-5.5mm}
\end{figure*}

\noindent\textbf{Proxy objective function.}
To minimize the condition number, our strategy is to compact the distribution of all singular values as densely as possible.
Specifically, we design a regularization term to minimize the deviation of singular values:
\begin{equation}
\begin{aligned}
     \min_{W} \frac{1}{2} \|XW - Y\|_{F}^{2} + \lambda \cdot \mathcal{G} (W),
\end{aligned}
\end{equation}
where $\mathcal{G}(\cdot)$ is a regularization term used to compact the singular value distribution and $\lambda$ is the regularization strength parameter.
There are several forms of $\mathcal{G} (W)$ to compact the singular values' distribution.
Considering efficiency and effect, we choose the following form:
\vspace{-1mm}
\begin{equation}
\begin{aligned}
     \mathcal{G} (W) := \sum_{i=1}^{r} (\sigma_i(W) - t)^2,
\end{aligned}
\end{equation}
% \vspace{-1mm}
where $r=rank(W)$ represents the number of singular values and $t$ is a value between $\sigma_{min}(W)$ and $\sigma_{max}(W)$. 
The median or the mean of the singular values are possible candidates for $t$ and we choose the mean value form in CondiQuant.
With this form, we could provide a closed solution to minimize $\mathcal{G}(W)$ in the following section.

\vspace{-1mm}
\noindent\textbf{Proximal Operator for $\mathcal{G}(W)$.}
We utilize the proximal operator to minimize the $\mathcal{G}(W)$ part.
We define the proximal operator of function $\mathcal{G}(W)$ as follows:
\begin{equation}
\begin{aligned}
     \operatorname{prox}_{\lambda \mu  \mathcal{G} }(W) := \arg \min_{Z} \left\{ \frac{1}{2} \|Z - W\|_F^2 + \lambda \mu  \mathcal{G} (Z)\right\},
\end{aligned}\label{eq:prox}
\end{equation}
where $\mu$ is a hyper-parameter to balance the optimization.
The target of \cref{eq:prox} is to minimize $\mathcal{G}(Z)$ and keep $Z$ close to $W$.
To solve this problem, we perform singular value decomposition (SVD) on $W$ to extract the singular values:
\begin{equation}
\begin{aligned}
     W = U \Sigma _W V^T,
\end{aligned}\label{eq:svd}
\end{equation}
where $U$ and $V$ are orthogonal matrices and $\Sigma _W = \operatorname{diag}(\sigma_i(V)) $ is the diagonal matrix of singular values.
The problem could be reduced to optimize each singular value $\sigma _i(W)$ independently and can be written as:
\begin{equation}
\begin{aligned}
     \sigma_i^*(W) := \arg\min_{\sigma_i^{*}} \left\{ \frac{1}{2} (\sigma_i^{*} - \sigma_i(W))^2 + \lambda \mu (\sigma_i^{*} - t)^2 \right\}. 
\end{aligned}\label{eq:singular}
\end{equation}
We notice that \cref{eq:singular} is a quadratic minimization problem and a closed solution could be derived.
Specifically, after taking the derivative and setting it to zero, we have:
\begin{equation}
\begin{aligned}
     \sigma _ { i } ^ { * } ( W ) = \frac { \sigma _ { i } ( W ) + 2 \lambda \mu t } { 1 + 2 \lambda \mu } . 
\end{aligned}\label{eq:solution}
\end{equation}
Using the updated singular values $\sigma_i^*(W)$ , we reconstruct the matrix with lower condition number:
\begin{equation}
\begin{aligned}
     W^* = U \Sigma_{W^*} V^T , \quad \Sigma_{W^*} = \operatorname{diag}(\sigma_i^*(W)). 
\end{aligned}\label{eq:reconstruct}
\end{equation}
To conclude, with the proximal operator, we could update $W$ to $W^{*}$ to minimize $\mathcal{G}(W)$.
Hereby, the condition number of $W$ is reduced and the output is kept still.


\noindent\textbf{Proximal Gradient Descent.}
As discussed previously, the optimization problem contains both smooth and non-smooth components.
More specifically, $\frac{1}{2} \|XW - Y\|_{F}^{2}$ is a convex and differentiable function, while $\mathcal{G}(W)$ is a convex but non-differentiable function. 
With the proximal operator, we design the proximal gradient descent method to solve two components iteratively.
The iterative steps are as follows:

\begin{table*}
\centering
\subfloat[\small  Ablation study on learning rate $\eta$. \label{abl:eta}]{
        \scalebox{0.95}{
        \setlength{\tabcolsep}{2.6mm}
        \begin{tabular}{l|cccc}
        \toprule
        \rowcolor[HTML]{\colorhead} $\eta$ & $10^{-1}$ & $10^{-2}$ & $10^{-3}$ & $10^{-4}$\\
        \midrule
        PSNR$\uparrow$ & 37.13 & 37.15 & 37.15 & 37.08\\
        SSIM$\uparrow$ & 0.9568 & 0.9568 & 0.9567 & 0.9564\\
        \bottomrule
        \end{tabular}}}
\hfill
\subfloat[\small  Ablation study on target value $t$. \label{abl:t}]{
        \scalebox{0.95}{
        \setlength{\tabcolsep}{3.5mm}
        \begin{tabular}{c|ccc}
        \toprule
        \rowcolor[HTML]{\colorhead} $t$ & Mean value  & Median value & $(\sigma_{max}+\sigma_{min})/2$ \\
        \midrule
        PSNR$\uparrow$ & 37.15 & 37.12 & 37.11\\
        SSIM$\uparrow$ & 0.9567 & 0.9566 & 0.9567 \\
        \bottomrule
        \end{tabular}}}
% \vspace{-3.5mm}
\\
\subfloat[\small  Ablation study on Regularization coefficient $\lambda$. \label{abl:lambda}]{
        \scalebox{0.95}{
        \setlength{\tabcolsep}{2.0mm}
        \begin{tabular}{c|cccccc}
            \toprule
            \rowcolor{colorhead} $\lambda$  & 0.001 & 0.002 & 0.003 & 0.004 & 0.005 & 0.010 \\
            \midrule
            PSNR$\uparrow$ & 37.13 & 37.12 & 37.15 & 37.13 & 37.10 & 37.08 \\
            SSIM$\uparrow$ & 0.9567 & 0.9566 & 0.9567 & 0.9567 & 0.9566 & 0.9565\\
            \bottomrule
            \end{tabular}}}\hfill
% \vspace{-3.5mm}
\subfloat[\small  Ablation study on CondiQuant. \label{abl:cq}]{
        \scalebox{0.95}{
        \setlength{\tabcolsep}{1.5mm}
        \begin{tabular}{c|ccc}
        \toprule
        % \rowcolor[HTML]{\colorhead} $\eta$ & w/ CondiQuant & w/o CondiQuant  \\
        \rowcolor[HTML]{\colorhead} & 2DQuant & w/o CondiQuant & w/ CondiQuant    \\
        \midrule
        PSNR$\uparrow$ & 36.00   & 37.08  & 37.15  \\
         SSIM$\uparrow$& 0.9497  & 0.9557 & 0.9567 \\
        \bottomrule
        \end{tabular}}}
\vspace{-3mm}
\caption{\small Ablation studies of CondiQuant on Set5 ($\times 2$, 2 bits). The selections of hyper-parameters and the effect of CondiQuant are detailedly evaluated. The results demonstrate that CondiQuant is robust and can improve performance significantly. }
\vspace{-6mm}

\end{table*}

\textbf{Step1. Gradient Descent.}
Compute the updated value of the smooth part $\frac{1}{2} \|XW - Y\|_{F}^{2}$ with the gradient descent: 
\begin{align}
    W_{k+\frac{1}{2}} = W_k - \eta \, \nabla_{W} \frac{1}{2}\| XW - Y\|^2 \bigg|_{W = W_k},  
\end{align}
where $\eta>0$ is the step size, and $\nabla_W$ is the gradient of $\frac{1}{2} \|XW - Y\|_{F}^{2}$ at $W_k$.
With this step, we ensure the output is as consistent as possible with the original value.



\textbf{Step2. Proximal Step.}
Apply the proximal operator to the non-smooth part $\mathcal{G}(W)$ with \cref{eq:svd}, \cref{eq:solution} and \cref{eq:reconstruct} to minimize the condition number:
\begin{align}
    W_k = \operatorname{prox}_{\lambda \mu \mathcal{G}}(W_{k + \frac{1}{2}})=U \Sigma_{W^{*}} V^{T}.
     \notag \label{eq:fake_quantw}
\end{align} 
    
\textbf{Step3. Repeat.}
Iterate the above two steps until reaching the convergence criterion, \ie $k\geq K$.
$k$ is the iteration step while $K$ is the total step of iteration.
We select a desired $K$ such that the difference between consecutive iterates is sufficiently small while the iteration is not too long.

We illustrate our proposed CondiQuant in \cref{fig:method-overview}.
With the proposed CondiQuant, we convert the weight metric from the quantization-unfriendly position into a friendly position.
Besides, both gradient descent and proximal descent steps are calculation efficient and the cost is inexpensive.
Moreover, we introduce no additional module.
Therefore, no computation and storage overhead is caused during the inference stage and we obtain the theoretic optimal compression and speedup ratio in post-training quantization.
After the conversion, we leverage the previous work's scheme~\cite{liu20242dquant} to perform quantization and calibration with modification and the details are described in the supplementary materials.

\vspace{-1.5mm}
\section{Experiments}
\vspace{-1mm}
To exhibit the outstanding performance of our proposed CondiQuant, comparisons with SOTA methods are also provided in both quantitative and qualitative forms.
Extensive ablation studies are conducted to show the robustness and effectiveness of our elaborate designs.

\vspace{-1mm}
\subsection{Experimental Settings}
\vspace{-1mm}
\textbf{Data and Evaluation.}
We employ DF2K~\cite{timofte2017ntire,lim2017enhanced} as the calibration set, which combines DIV2K~\cite{timofte2017ntire} and Flickr2K~\cite{lim2017enhanced}.
During calibration, we only use low-resolution ones and the FP model.
Thereafter, CondiQuant is tested on five commonly used benchmarks in the SR field, including Set5~\cite{bevilacqua2012low}, Set14~\cite{zeyde2012single}, B100~\cite{martin2001database}, Urban100~\cite{huang2015single}, and Manga109~\cite{matsui2017sketch}.
The evaluation metrics include PSNR and SSIM~\cite{wang2004image}, which are calculated on the Y channel of the YCbCr space.

\noindent\textbf{Implementation Details.}
The backbone of CondiQuant is SwinIR-light~\cite{liang2021swinir}, a small and efficient ViT for image restoration.
The scale factors include $\times$2, $\times$3, and $\times$4, and bit-width includes 2, 3, and 4 bits.
During condition number optimization, the calibration set size is 100 images, randomly selected from DF2K and cropped to 3$\times$64$\times$64.
We set step size $\eta=10^{-2}$, regularization coefficient $\lambda=0.003, \mu=1$, and max iteration $K=50$.
The target value $t$ is the mean value of singular values.
Our code is written with PyTorch~\cite{paszke2019pytorch} and runs on an NVIDIA A800-80GB GPU.
\vspace{-2mm}
\subsection{Ablation Study}
\vspace{-1mm}
In this section, we conduct four ablation studies on Set5 ($\times 2$) with 2 bits to evaluate the robustness of our design.

\noindent\textbf{Learning Rate $\eta$.}
In CondiQuant, $\eta$ decides the step size of the gradient descent step.
We evaluate $\eta$ from $10^{-4}$ to $10^{-1}$. 
As shown in \cref{abl:eta}, the impact of $\eta$ is minor in the evaluation range.
We attribute this minor impact to the rank deficiency across the network and the design of proximal descent.
Rank deficiency allows multiple candidates for $W$ while the SVD reconstruction also guarantees the output remains the same.
Therefore, the difference between $W_{k+\frac{1}{2}}$ and $W_{k}$ is small enough.
However, the gradient step is not unnecessary as it ensures the output won't change much.

\noindent\textbf{Selection of $t$.}
As discussed in \cref{sec:condiquant}, there are several ways to select the target value $t$ in $\mathcal{G}(W)$, including the mean value and median value of all singular values and $(\sigma_{min}+\sigma_{max})/2$.
We try these variants and the result is shown in \cref{abl:t}.
The stable performance with different variants indicates that so long as the singular values are compacted, the performance could be therefore improved.
So we choose the mean value of singular values to assign $t$.

\noindent\textbf{Regularization Coefficient $\lambda$.}
As shown in \cref{abl:lambda}, we test different $\lambda$ from 0.001 to 0.01. 
The optimal results could be obtained when $\lambda$ is set to 0.003 while other values also provide well enough PSNR and SSIM.

\noindent\textbf{CondiQuant.}
As shown in \cref{abl:cq}, the existence of CondiQuant is impactful.
2DQuant provides relatively inferior results while our modification improves the performance significantly.
Besides, CondiQuant could ease the quantization difficulty and further improve the performance.
Moreover, CondiQuant only takes less than 19.0 seconds to perform and the computation overhead is minor.
Hence, CondiQuant could serve as an efficient pre-processing technique before model quantization, especially with ultra-low bit width. 

\begin{table*}[t!]
\centering
\renewcommand\arraystretch{0.90}
\caption{
Quantitative comparison with SOTA methods. The first and second highest methods are marked with \textcolor{red}{\textbf{red}} and \textcolor{blue}{\textbf{blue}} respectively.
Our proposed CondiQuant remarkably outperforms \textbf{all} other methods in \textbf{all} settings on \textbf{all} benchmarks. 
}
\vspace{-2mm}
\label{tab:quantitative-comparison}
\setlength{\tabcolsep}{4.0mm}
\resizebox{\textwidth}{!}{%
\begin{tabular}{llrrrrrrrrrr}
\hline
\toprule[0.15em]
\rowcolor[HTML]{\colorhead} 
\cellcolor[HTML]{\colorhead} & \cellcolor[HTML]{\colorhead} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Set5 ($\times 2$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Set14 ($\times 2$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}B100 ($\times 2$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Urban100 ($\times 2$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Manga109 ($\times 2$)} \\
\rowcolor[HTML]{\colorhead} 
\multirow{-2}{*}{\cellcolor[HTML]{\colorhead}Method} & \multirow{-2}{*}{\cellcolor[HTML]{\colorhead}Bit} & \cellcolor[HTML]{\colorhead}PSNR$\uparrow$ & \cellcolor[HTML]{\colorhead}SSIM$\uparrow$ & PSNR$\uparrow$ & SSIM$\uparrow$ & PSNR$\uparrow$ & SSIM$\uparrow$ & PSNR$\uparrow$ & SSIM$\uparrow$ & PSNR$\uparrow$ & SSIM$\uparrow$ \\ 
\midrule[0.15em]
\multicolumn{1}{l|}{SwinIR-light~\cite{liang2021swinir}} & \multicolumn{1}{c|}{32}     & 38.15 & 0.9611 & 33.86 & 0.9206 & 32.31 & 0.9012 & 32.76 & 0.9340 & 39.11 & 0.9781   \\
\multicolumn{1}{l|}{Bicubic} & \multicolumn{1}{c|}{32}      & 32.25 & 0.9118 & 29.25 & 0.8406 & 28.68 & 0.8104 & 25.96 & 0.8088 & 29.17 & 0.9128  \\ 
\midrule
\multicolumn{1}{l|}{DBDC+Pac~\cite{tu2023toward}} & \multicolumn{1}{c|}{4}      & 37.18 & 0.9550 & 32.86 & 0.9106 & 31.56 & 0.8908 & 30.66 & 0.9110 & 36.76 & 0.9692 \\
\multicolumn{1}{l|}{PTQ4ViT~\cite{yuan2022ptq4vit}}                    & \multicolumn{1}{c|}{4}    & 37.43 & 0.9571 & 33.19 & 0.9139 & 31.84 & 0.8950 & 31.54 & 0.9212 & 37.59 & 0.9735     \\
\multicolumn{1}{l|}{RepQ~\cite{li2023repq}}                       & \multicolumn{1}{c|}{4}    & \textcolor{blue}{37.89} & \textcolor{blue}{0.9600} & \textcolor{blue}{33.47} & \textcolor{blue}{0.9174} & \textcolor{blue}{32.08} & \textcolor{blue}{0.8975} & \textcolor{blue}{31.98} & \textcolor{blue}{0.9269} & \textcolor{blue}{38.37} & \textcolor{blue}{0.9763}     \\
\multicolumn{1}{l|}{NoisyQuant~\cite{liu2023noisyquant}}                 & \multicolumn{1}{c|}{4}    & 37.50 & 0.9570 & 33.06 & 0.9101 & 31.73 & 0.8936 & 31.31 & 0.9181 & 37.47 & 0.9723     \\
\multicolumn{1}{l|}{2DQuant~\cite{liu20242dquant}} & \multicolumn{1}{c|}{4} & 37.87 & 0.9594 & 33.41 & 0.9161 & 32.02 & 0.8971 & 31.84 & 0.9251 & 38.31 & 0.9761 \\
\multicolumn{1}{l|}{CondiQuant (ours)} & \multicolumn{1}{c|}{4} & \textcolor{red}{38.03} & \textcolor{red}{0.9605} & \textcolor{red}{33.50} & \textcolor{red}{0.9180} & \textcolor{red}{32.16} & \textcolor{red}{0.8993} & \textcolor{red}{32.03} & \textcolor{red}{0.9282} & \textcolor{red}{38.57} & \textcolor{red}{0.9769} \\

\midrule
\multicolumn{1}{l|}{DBDC+Pac~\cite{tu2023toward}} & \multicolumn{1}{c|}{3}      & 35.07 & 0.9350 & 31.52 & 0.8873 & 30.47 & 0.8665 & 28.44 & 0.8709 & 34.01 & 0.9487 \\
\multicolumn{1}{l|}{PTQ4ViT~\cite{yuan2022ptq4vit}}                    & \multicolumn{1}{c|}{3}    & 36.49 & 0.9510 & 32.49 & 0.9045 & 31.27 & 0.8854 & 30.16 & 0.9027 & 36.41 & 0.9673     \\
\multicolumn{1}{l|}{RepQ~\cite{li2023repq}}                       & \multicolumn{1}{c|}{3}    & 35.06 & 0.9325 & 31.29 & 0.8719 & 30.04 & 0.8512 & 29.17 & 0.8726 & 34.89 & 0.9518     \\
\multicolumn{1}{l|}{NoisyQuant~\cite{liu2023noisyquant}}                 & \multicolumn{1}{c|}{3}    & 35.32 & 0.9334 & 31.88 & 0.8911 & 30.73 & 0.8710 & 29.28 & 0.8835 & 35.30 & 0.9537     \\
\multicolumn{1}{l|}{2DQuant~\cite{liu20242dquant}} & \multicolumn{1}{c|}{3} & \textcolor{blue}{37.32} & \textcolor{blue}{0.9567} & \textcolor{blue}{32.85} & \textcolor{blue}{0.9106} & \textcolor{blue}{31.60} & \textcolor{blue}{0.8911} & \textcolor{blue}{30.45} & \textcolor{blue}{0.9086} & \textcolor{blue}{37.24} & \textcolor{blue}{0.9722} \\
\multicolumn{1}{l|}{CondiQuant (ours)} & \multicolumn{1}{c|}{3} & \textcolor{red}{37.77} & \textcolor{red}{0.9594} & \textcolor{red}{33.21} & \textcolor{red}{0.9151} & \textcolor{red}{31.94} & \textcolor{red}{0.8966} & \textcolor{red}{31.18} & \textcolor{red}{0.9197} & \textcolor{red}{38.01} & \textcolor{red}{0.9755} \\
\midrule
\multicolumn{1}{l|}{DBDC+Pac~\cite{tu2023toward}} & \multicolumn{1}{c|}{2}      & 34.55 & 0.9386 & 31.12 & 0.8912 & 30.27 & 0.8706 & 27.63 & 0.8649 & 32.15 & 0.9467 \\
\multicolumn{1}{l|}{PTQ4ViT~\cite{yuan2022ptq4vit}}                    & \multicolumn{1}{c|}{2}    & 33.25 & 0.8923 & 30.22 & 0.8402 & 29.21 & 0.8066 & 27.31 & 0.8111 & 32.75 & 0.9093     \\
\multicolumn{1}{l|}{RepQ~\cite{li2023repq}}                       & \multicolumn{1}{c|}{2}    & 31.65 & 0.8327 & 29.19 & 0.7789 & 28.27 & 0.7414 & 26.56 & 0.7455 & 30.46 & 0.8268     \\
\multicolumn{1}{l|}{NoisyQuant~\cite{liu2023noisyquant}}                 & \multicolumn{1}{c|}{2}    & 30.13 & 0.7620 & 28.80 & 0.7556 & 28.26 & 0.7421 & 26.68 & 0.7627 & 30.40 & 0.8204     \\
\multicolumn{1}{l|}{2DQuant~\cite{liu20242dquant}}                    & \multicolumn{1}{c|}{2} & \textcolor{blue}{36.00} & \textcolor{blue}{0.9497} & \textcolor{blue}{31.98} & \textcolor{blue}{0.9012} & \textcolor{blue}{30.91} & \textcolor{blue}{0.8810} & \textcolor{blue}{28.62} & \textcolor{blue}{0.8819} & \textcolor{blue}{34.40} & \textcolor{blue}{0.9602} \\
\multicolumn{1}{l|}{CondiQuant (ours)} & \multicolumn{1}{c|}{2} & \textcolor{red}{37.15} & \textcolor{red}{0.9567} & \textcolor{red}{32.74} & \textcolor{red}{0.9103} & \textcolor{red}{31.55} & \textcolor{red}{0.8912} & \textcolor{red}{29.96} & \textcolor{red}{0.9047} & \textcolor{red}{36.63} & \textcolor{red}{0.9713} \\

\midrule[0.15em]
\rowcolor[HTML]{\colorhead} 
\cellcolor[HTML]{\colorhead} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Set5 ($\times 3$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Set14 ($\times 3$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}B100 ($\times 3$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Urban100 ($\times 3$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Manga109 ($\times 3$)} \\
\rowcolor[HTML]{\colorhead} 
\multirow{-2}{*}{\cellcolor[HTML]{\colorhead}Method} & \multicolumn{1}{l}{\multirow{-2}{*}{\cellcolor[HTML]{\colorhead}Bit}} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}PSNR$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}SSIM$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}PSNR$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}SSIM$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}PSNR$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}SSIM$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}PSNR$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}SSIM$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}PSNR$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}SSIM$\uparrow$} \\
\midrule[0.15em]
\multicolumn{1}{l|}{SwinIR-light~\cite{liang2021swinir}} & \multicolumn{1}{c|}{32}     & 34.63 & 0.9290 & 30.54 & 0.8464 & 29.20 & 0.8082 & 28.66 & 0.8624 & 33.99 & 0.9478   \\
\multicolumn{1}{l|}{Bicubic} & \multicolumn{1}{c|}{32}      & 29.54 & 0.8516 & 27.04 & 0.7551 & 26.78 & 0.7187 & 24.00 & 0.7144 & 26.16 & 0.8384  \\ 
\midrule
\multicolumn{1}{l|}{DBDC+Pac~\cite{tu2023toward}} & \multicolumn{1}{c|}{4}      & 33.42 & 0.9143 & 29.69 & 0.8261 & 28.51 & 0.7869 & 27.05 & 0.8217 & 31.89 & 0.9274 \\
\multicolumn{1}{l|}{PTQ4ViT~\cite{yuan2022ptq4vit}}                    & \multicolumn{1}{c|}{4}    & 33.77 & 0.9201 & 29.75 & 0.8272 & 28.62 & 0.7942 & 27.43 & 0.8361 & 32.50 & 0.9360 \\
\multicolumn{1}{l|}{RepQ~\cite{li2023repq}}                       & \multicolumn{1}{c|}{4}    & \textcolor{blue}{34.08} & \textcolor{blue}{0.9232} & 30.04 & 0.8345 & 28.88 & \textcolor{blue}{0.8013} & \textcolor{blue}{27.87} & \textcolor{blue}{0.8462} & \textcolor{blue}{32.98} & \textcolor{blue}{0.9401} \\
\multicolumn{1}{l|}{NoisyQuant~\cite{liu2023noisyquant}}                 & \multicolumn{1}{c|}{4}    & 33.13 & 0.9122 & 29.06 & 0.8093 & 27.93 & 0.7754 & 26.66 & 0.8143 & 31.94 & 0.9293 \\
\multicolumn{1}{l|}{2DQuant~\cite{liu20242dquant}}             & \multicolumn{1}{c|}{4}    & 34.06 & 0.9231 & \textcolor{blue}{30.12} & \textcolor{blue}{0.8374} & \textcolor{blue}{28.89} & 0.7988 & 27.69 & 0.8405 & 32.88 & 0.9389    \\
\multicolumn{1}{l|}{CondiQuant (ours)} & \multicolumn{1}{c|}{4} & \textcolor{red}{34.32} & \textcolor{red}{0.9260} & \textcolor{red}{30.29} & \textcolor{red}{0.8417} & \textcolor{red}{29.05} & \textcolor{red}{0.8039} & \textcolor{red}{28.05} & \textcolor{red}{0.8506} & \textcolor{red}{33.23} & \textcolor{red}{0.9431} \\

\midrule
\multicolumn{1}{l|}{DBDC+Pac~\cite{tu2023toward}} & \multicolumn{1}{c|}{3}      & 30.91 & 0.8445 & 28.02 & 0.7538 & 26.99 & 0.6937 & 25.10 & 0.7122 & 28.84 & 0.8403 \\
\multicolumn{1}{l|}{PTQ4ViT~\cite{yuan2022ptq4vit}}                    & \multicolumn{1}{c|}{3}    & 32.75 & 0.9028 & 29.14 & 0.8113 & 28.06 & 0.7712 & 26.43 & 0.8014 & 31.20 & 0.9131    \\
\multicolumn{1}{l|}{RepQ~\cite{li2023repq}}                       & \multicolumn{1}{c|}{3}    & 31.04 & 0.8548 & 28.04 & 0.7572 & 26.83 & 0.7019 & 25.56 & 0.7493 & 30.16 & 0.8904   \\
\multicolumn{1}{l|}{NoisyQuant~\cite{liu2023noisyquant}}                 & \multicolumn{1}{c|}{3}    & 30.78 & 0.8511 & 27.94 & 0.7624 & 26.98 & 0.7153 & 25.43 & 0.7481 & 29.64 & 0.8792    \\
\multicolumn{1}{l|}{2DQuant~\cite{liu20242dquant}} & \multicolumn{1}{c|}{3} & \textcolor{blue}{33.24} & \textcolor{blue}{0.9135} & \textcolor{blue}{29.56} & \textcolor{blue}{0.8255} & \textcolor{blue}{28.50} & \textcolor{blue}{0.7873} & \textcolor{blue}{26.65} & \textcolor{blue}{0.8116} & \textcolor{blue}{31.46} & \textcolor{blue}{0.9235} \\
\multicolumn{1}{l|}{CondiQuant (ours)} & \multicolumn{1}{c|}{3} & \textcolor{red}{33.92} & \textcolor{red}{0.9224} & \textcolor{red}{30.02} & \textcolor{red}{0.8367} & \textcolor{red}{28.84} & \textcolor{red}{0.7986} & \textcolor{red}{27.37} & \textcolor{red}{0.8356} & \textcolor{red}{32.48} & \textcolor{red}{0.9367} \\

\midrule
\multicolumn{1}{l|}{DBDC+Pac~\cite{tu2023toward}} & \multicolumn{1}{c|}{2}      & 29.96 & 0.8254 & 27.53 & 0.7507 & 27.05 & 0.7136 & 24.57 & 0.7117 & 27.23 & 0.8213 \\
\multicolumn{1}{l|}{PTQ4ViT~\cite{yuan2022ptq4vit}}                    & \multicolumn{1}{c|}{2}    & 29.96 & 0.7901 & 27.36 & 0.7030 & 26.74 & 0.6590 & 24.56 & 0.6460 & 27.37 & 0.7390    \\
\multicolumn{1}{l|}{RepQ~\cite{li2023repq}}                       & \multicolumn{1}{c|}{2}    & 27.32 & 0.6478 & 25.63 & 0.5918 & 25.44 & 0.5652 & 23.42 & 0.5582 & 24.51 & 0.5721    \\
\multicolumn{1}{l|}{NoisyQuant~\cite{liu2023noisyquant}}                 & \multicolumn{1}{c|}{2}    & 27.53 & 0.6641 & 25.77 & 0.5952 & 25.37 & 0.5613 & 23.59 & 0.5739 & 26.03 & 0.6632    \\
\multicolumn{1}{l|}{2DQuant~\cite{liu20242dquant}} & \multicolumn{1}{c|}{2} & \textcolor{blue}{31.62} & \textcolor{blue}{0.8887} & \textcolor{blue}{28.54} & \textcolor{blue}{0.8038} & \textcolor{blue}{27.85} & \textcolor{blue}{0.7679} & \textcolor{blue}{25.30} & \textcolor{blue}{0.7685} & \textcolor{blue}{28.46} & \textcolor{blue}{0.8814} \\
\multicolumn{1}{l|}{CondiQuant (ours)} & \multicolumn{1}{c|}{2} & \textcolor{red}{33.00} & \textcolor{red}{0.9130} & \textcolor{red}{29.44} & \textcolor{red}{0.8253} & \textcolor{red}{28.45} & \textcolor{red}{0.7882} & \textcolor{red}{26.36} & \textcolor{red}{0.8080} & \textcolor{red}{30.88} & \textcolor{red}{0.9203} \\

\midrule[0.15em]
\rowcolor[HTML]{\colorhead} 
\cellcolor[HTML]{\colorhead} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Set5 ($\times 4$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Set14 ($\times 4$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}B100 ($\times 4$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Urban100 ($\times 4$)} & \multicolumn{2}{c}{\cellcolor[HTML]{\colorhead}Manga109 ($\times 4$)} \\
\rowcolor[HTML]{\colorhead} 
\multirow{-2}{*}{\cellcolor[HTML]{\colorhead}Method} & \multicolumn{1}{l}{\multirow{-2}{*}{\cellcolor[HTML]{\colorhead}Bit}} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}PSNR$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}SSIM$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}PSNR$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}SSIM$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}PSNR$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}SSIM$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}PSNR$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}SSIM$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}PSNR$\uparrow$} & \multicolumn{1}{l}{\cellcolor[HTML]{\colorhead}SSIM$\uparrow$} \\
\midrule[0.15em]
\multicolumn{1}{l|}{SwinIR-light~\cite{liang2021swinir}} & \multicolumn{1}{c|}{32}     & 32.45 & 0.8976 & 28.77 & 0.7858 & 27.69 & 0.7406 & 26.48 & 0.7980 & 30.92 & 0.9150   \\
\multicolumn{1}{l|}{Bicubic} & \multicolumn{1}{c|}{32}      & 27.56 & 0.7896 & 25.51 & 0.6820 & 25.54 & 0.6466 & 22.68 & 0.6352 & 24.19 & 0.7670  \\ 
\midrule
\multicolumn{1}{l|}{DBDC+Pac~\cite{tu2023toward}} & \multicolumn{1}{c|}{4}      & 30.74 & 0.8609 & 27.66 & 0.7526 & 26.97 & 0.7104 & 24.94 & 0.7369 & 28.52 & 0.8697 \\
\multicolumn{1}{l|}{PTQ4ViT~\cite{yuan2022ptq4vit}}                    & \multicolumn{1}{c|}{4}    & 31.49  & 0.8831 & 28.04  & 0.7680 & 27.20  & 0.7240 & 25.53  & 0.7660 & 29.52  & 0.8940    \\
\multicolumn{1}{l|}{RepQ~\cite{li2023repq}}                       & \multicolumn{1}{c|}{4}    & 31.77 & \textcolor{blue}{0.8880} & \textcolor{blue}{28.32} & \textcolor{blue}{0.7750} & \textcolor{blue}{27.40} & \textcolor{blue}{0.7310} & \textcolor{blue}{25.83} & \textcolor{blue}{0.7780} & \textcolor{blue}{29.88} & \textcolor{blue}{0.9010}    \\
\multicolumn{1}{l|}{NoisyQuant~\cite{liu2023noisyquant}}                 & \multicolumn{1}{c|}{4}    & 31.09  & 0.8751 & 27.75  & 0.7591 & 26.91  & 0.7151 & 25.07  & 0.7500 & 28.96  & 0.8820    \\
\multicolumn{1}{l|}{2DQuant~\cite{liu20242dquant}} & \multicolumn{1}{c|}{4} & \textcolor{blue}{31.77} & 0.8867 & 28.30 & 0.7733 & 27.37 & 0.7278 & 25.71 & 0.7712 & 29.71 & 0.8972 \\
\multicolumn{1}{l|}{CondiQuant (ours)} & \multicolumn{1}{c|}{4} & \textcolor{red}{32.09} & \textcolor{red}{0.8923} & \textcolor{red}{28.50} & \textcolor{red}{0.7792} & \textcolor{red}{27.52} & \textcolor{red}{0.7345} & \textcolor{red}{25.97} & \textcolor{red}{0.7831} & \textcolor{red}{30.16} & \textcolor{red}{0.9054} \\

\midrule
\multicolumn{1}{l|}{DBDC+Pac~\cite{tu2023toward}} & \multicolumn{1}{c|}{3}      & 27.91 & 0.7250 & 25.86 & 0.6451 & 25.65 & 0.6239 & 23.45 & 0.6249 & 26.03 & 0.7321 \\
\multicolumn{1}{l|}{PTQ4ViT~\cite{yuan2022ptq4vit}}                    & \multicolumn{1}{c|}{3}    & 29.77 & 0.8337 & 27.00 & 0.7248 & 26.21 & 0.6735 & 24.22 & 0.6983 & 27.94 & 0.8479    \\
\multicolumn{1}{l|}{RepQ~\cite{li2023repq}}                       & \multicolumn{1}{c|}{3}    & 27.52 & 0.7419 & 24.84 & 0.5996 & 23.99 & 0.5351 & 22.42 & 0.5739 & 26.58 & 0.7838    \\
\multicolumn{1}{l|}{NoisyQuant~\cite{liu2023noisyquant}}                 & \multicolumn{1}{c|}{3}    & 28.90 & 0.7972 & 26.50 & 0.6970 & 26.16 & 0.6628 & 23.86 & 0.6667 & 27.17 & 0.8116    \\
\multicolumn{1}{l|}{2DQuant~\cite{liu20242dquant}} & \multicolumn{1}{c|}{3} & \textcolor{blue}{30.90} & \textcolor{blue}{0.8704} & \textcolor{blue}{27.75} & \textcolor{blue}{0.7571} & \textcolor{blue}{26.99} & \textcolor{blue}{0.7126} & \textcolor{blue}{24.85} & \textcolor{blue}{0.7355} & \textcolor{blue}{28.21} & \textcolor{blue}{0.8683} \\
\multicolumn{1}{l|}{CondiQuant (ours)} & \multicolumn{1}{c|}{3} & \textcolor{red}{31.62} & \textcolor{red}{0.8855} & \textcolor{red}{28.20} & \textcolor{red}{0.7715} & \textcolor{red}{27.31} & \textcolor{red}{0.7269} & \textcolor{red}{25.39} & \textcolor{red}{0.7624} & \textcolor{red}{29.29} & \textcolor{red}{0.8915} \\
\midrule
\multicolumn{1}{l|}{DBDC+Pac~\cite{tu2023toward}} & \multicolumn{1}{c|}{2}      & 25.01 & 0.5554 & 23.82 & 0.4995 & 23.64 & 0.4544 & 21.84 & 0.4631 & 23.63 & 0.5854 \\
\multicolumn{1}{l|}{PTQ4ViT~\cite{yuan2022ptq4vit}}                    & \multicolumn{1}{c|}{2}    & 27.23 & 0.6702 & 25.38 & 0.5914 & 25.15 & 0.5621 & 22.94 & 0.5587 & 24.66 & 0.6132    \\
\multicolumn{1}{l|}{RepQ~\cite{li2023repq}}                       & \multicolumn{1}{c|}{2}    & 25.55 & 0.5834 & 23.54 & 0.4751 & 23.30 & 0.4298 & 21.62 & 0.4493 & 23.60 & 0.5561    \\
\multicolumn{1}{l|}{NoisyQuant~\cite{liu2023noisyquant}}                 & \multicolumn{1}{c|}{2}    & 25.94 & 0.5862 & 24.33 & 0.5067 & 24.16 & 0.4718 & 22.32 & 0.4841 & 23.82 & 0.5403    \\
\multicolumn{1}{l|}{2DQuant~\cite{liu20242dquant}} & \multicolumn{1}{c|}{2} & \textcolor{blue}{29.53} & \textcolor{blue}{0.8372} & \textcolor{blue}{26.86} & \textcolor{blue}{0.7322} & \textcolor{blue}{26.46} & \textcolor{blue}{0.6927} & \textcolor{blue}{23.84} & \textcolor{blue}{0.6912} & \textcolor{blue}{26.07} & \textcolor{blue}{0.8163} \\
\multicolumn{1}{l|}{CondiQuant (ours)} & \multicolumn{1}{c|}{2} & \textcolor{red}{30.64} & \textcolor{red}{0.8671} & \textcolor{red}{27.59} & \textcolor{red}{0.7567} & \textcolor{red}{26.93} & \textcolor{red}{0.7136} & \textcolor{red}{24.54} & \textcolor{red}{0.7282} & \textcolor{red}{27.67} & \textcolor{red}{0.8613} \\
\bottomrule[0.15em]
\end{tabular}%
}
% \vspace{-5mm}
\end{table*}





\begin{figure*}[t]
\scriptsize
\centering
\scalebox{1.2}{
\begin{tabular}{cccc}
%% one row begins
\hspace{-6mm}
\begin{adjustbox}{valign=t}
\begin{tabular}{c}
\includegraphics[width=0.215\textwidth]{figs/visual/024-full.png}
\\
Urban100: 024
\end{tabular}
\end{adjustbox}
\hspace{-0.46cm}
\begin{adjustbox}{valign=t}
\begin{tabular}{cccccc}
\includegraphics[width=0.149\textwidth]{figs/visual/024-hr.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/024-bicubic.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/024-fp.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/024-ptq4vit.png} \hspace{-4mm} 
\\
HR \hspace{-4mm} &
Bicubic \hspace{-4mm} &
SwinIR-light (FP)~\cite{liang2021swinir} \hspace{-4mm} &
PTQ4ViT~\cite{yuan2022ptq4vit} \hspace{-4mm} &
\\
\includegraphics[width=0.149\textwidth]{figs/visual/024-noisyquant.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/024-DBDC+pac.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/024-tdquant.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/024-condiquant.png} \hspace{-4mm}
\\ 
NoisyQuant~\cite{liu2023noisyquant} \hspace{-4mm} &
DBDC+Pac~\cite{tu2023toward}\hspace{-4mm} &
2DQuant~\cite{liu20242dquant}  \hspace{-4mm} &
CondiQuant (ours)  \hspace{-4mm}

\\
\end{tabular}
\end{adjustbox}
%% one row ends
\\
%% one row begins
\hspace{-6mm}
\begin{adjustbox}{valign=t}
\begin{tabular}{c}
\includegraphics[width=0.215\textwidth]{figs/visual/061-full.png}
\\
Urban100: 061
\end{tabular}
\end{adjustbox}
\hspace{-0.46cm}
\begin{adjustbox}{valign=t}
\begin{tabular}{cccccc}
\includegraphics[width=0.149\textwidth]{figs/visual/061-hr.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/061-bicubic.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/061-fp.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/061-ptq4vit.png} \hspace{-4mm} 
\\
HR \hspace{-4mm} &
Bicubic \hspace{-4mm} &
SwinIR-light (FP)~\cite{liang2021swinir} \hspace{-4mm} &
PTQ4ViT~\cite{yuan2022ptq4vit} \hspace{-4mm} &
\\
\includegraphics[width=0.149\textwidth]{figs/visual/061-noisyquant.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/061-DBDC+pac.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/061-tdquant.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/061-condiquant.png} \hspace{-4mm}
\\ 
NoisyQuant~\cite{liu2023noisyquant} \hspace{-4mm} &
DBDC+Pac~\cite{tu2023toward}\hspace{-4mm} &
2DQuant~\cite{liu20242dquant}  \hspace{-4mm} &
CondiQuant (ours)  \hspace{-4mm}

\\
\end{tabular}
\end{adjustbox}
%% one row ends
\\
%% one row begins
\hspace{-6mm}
\begin{adjustbox}{valign=t}
\begin{tabular}{c}
\includegraphics[width=0.215\textwidth]{figs/visual/092-full.png}
\\
Urban100: 092
\end{tabular}
\end{adjustbox}
\hspace{-0.46cm}
\begin{adjustbox}{valign=t}
\begin{tabular}{cccccc}
\includegraphics[width=0.149\textwidth]{figs/visual/092-hr.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/092-bicubic.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/092-fp.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/092-ptq4vit.png} \hspace{-4mm} 
\\
HR \hspace{-4mm} &
Bicubic \hspace{-4mm} &
SwinIR-light (FP)~\cite{liang2021swinir} \hspace{-4mm} &
PTQ4ViT~\cite{yuan2022ptq4vit} \hspace{-4mm} &
\\
\includegraphics[width=0.149\textwidth]{figs/visual/092-noisyquant.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/092-DBDC+pac.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/092-tdquant.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/092-condiquant.png} \hspace{-4mm}
\\ 
NoisyQuant~\cite{liu2023noisyquant} \hspace{-4mm} &
DBDC+Pac~\cite{tu2023toward}\hspace{-4mm} &
2DQuant~\cite{liu20242dquant}  \hspace{-4mm} &
CondiQuant (ours)  \hspace{-4mm}

\\
\end{tabular}
\end{adjustbox}
%% one row ends
\\
%% one row begins
\hspace{-6mm}
\begin{adjustbox}{valign=t}
\begin{tabular}{c}
\includegraphics[width=0.215\textwidth]{figs/visual/095-full.png}
\\
Urban100: 095
\end{tabular}
\end{adjustbox}
\hspace{-0.46cm}
\begin{adjustbox}{valign=t}
\begin{tabular}{cccccc}
\includegraphics[width=0.149\textwidth]{figs/visual/095-hr.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/095-bicubic.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/095-fp.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/095-ptq4vit.png} \hspace{-4mm} 
\\
HR \hspace{-4mm} &
Bicubic \hspace{-4mm} &
SwinIR-light (FP)~\cite{liang2021swinir} \hspace{-4mm} &
PTQ4ViT~\cite{yuan2022ptq4vit} \hspace{-4mm} &
\\
\includegraphics[width=0.149\textwidth]{figs/visual/095-noisyquant.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/095-DBDC+pac.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/095-tdquant.png} \hspace{-4mm} &
\includegraphics[width=0.149\textwidth]{figs/visual/095-condiquant.png} \hspace{-4mm}
\\ 
NoisyQuant~\cite{liu2023noisyquant} \hspace{-4mm} &
DBDC+Pac~\cite{tu2023toward}\hspace{-4mm} &
2DQuant~\cite{liu20242dquant}  \hspace{-4mm} &
CondiQuant (ours)  \hspace{-4mm}

\\
\end{tabular}
\end{adjustbox}
%% one row ends
\\
\end{tabular}}
\vspace{-3.5mm}
\caption{\small{Visual comparison for image SR. We compare our proposed CondiQuant with current competitive quantization methods and the full-precision (FP) model. The visual results illustrate that CondiQuant gains sharper edges and reasonable textures.}}
\label{fig:visual}
\vspace{-5mm}
\end{figure*}

\subsection{Comparison with State-of-the-Art Methods}
\vspace{-2mm}
We adopt two kinds of SOTA PTQ methods for comparison.
The first kind is PTQ methods specifically for SR, including DBDC+Pac~\cite{tu2023toward}, 2DQuant~\cite{liu20242dquant}.
The second kind includes PTQ4ViT~\cite{yuan2022ptq4vit}, RepQ~\cite{li2023repq}, and NoisyQuant~\cite{liu2023noisyquant}, which are designed for general vision transformers.

\begin{figure*}[htbp]
    \centering
    \begin{subfigure}[b]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/condinumber/CN-depth.pdf}
        \caption{Condition number with model depth.}
        \label{fig:condition-number-depth}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \includegraphics[width=\textwidth]{figs/condinumber/CN-depth-0.pdf}
        \caption{Q}
        \label{fig:condition-number-Q}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \includegraphics[width=\textwidth]{figs/condinumber/CN-depth-1.pdf}
        \caption{K}
        \label{fig:condition-number-K}
    \end{subfigure}
    
    % \vspace{-2mm}
    
    \begin{subfigure}[b]{0.475\textwidth}
        \includegraphics[width=\textwidth]{figs/condinumber/CN-descend.pdf}
        \caption{Condition number with descending order.}
        \label{fig:condition-number-descend}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \includegraphics[width=\textwidth]{figs/condinumber/CN-depth-2.pdf}
        \caption{V}
        \label{fig:condition-number-V}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \includegraphics[width=\textwidth]{figs/condinumber/CN-depth-3.pdf}
        \caption{Projection}
        \label{fig:condition-number-proj}
    \end{subfigure}
    \vspace{-3mm}
    \caption{
    Condition number before and after CondiQuant on $\times 2$ model.
    Before CondiQuant, the distribution of condition numbers is extremely high, with an average of nearly 3k. 
    After CondiQuant, the average value of condition numbers is significantly reduced to 28.37.
    }
    \vspace{-6mm}
    \label{fig:condition-number}
\end{figure*}

\noindent\textbf{Quantitative Results.}
Table~\ref{tab:quantitative-comparison} shows the comprehensive results comparing with edge PTQ methods with $2\sim4$ bits and $2\sim4$ scale factors on five common SR benchmarks.
With two universally accepted metrics, our proposed CondiQuant outperforms all other methods on all benchmarks regardless of bit-width, and scale factor.
Specifically, CondiQuant has a huge improvement of 1.11 dB and 1.60 dB on $\times4$, 2-bit on Set5 and Manga109 datasets respectively.
Besides, the average difference between $\times2$, 4 bits CondiQuant, and the full-precision model is 0.38 dB.
This means the quantization degradation when compressing to only 4 bits is minimal, and small enough for real-world deployment on edge devices.

With condition number optimization, the model's sensitivity to the quantization error is reduced. 
Thereafter, the weight matrix is efficiently converted into a more quantization-friendly representation.
Furthermore, the quantized model enjoys significant improvement during the following calibration and distillation stage.
Besides, the oscillation during distillation is reduced, and detailed supporting information is in supplemental material.


\noindent\textbf{Visual Results.}
We present the visual comparison results of $\times4$ in \cref{fig:visual}.
The competing methods are struggling to recover inerratic textures and often generate artifacts.
On the contrary, with our proposed CondiQuant, the quantized model could reconstruct HR with rich details and reasonable structures.
In 024 and 061, the direction of the texture is distorted, and jagged edges are generated with Bicubic.
Given the misleading input, other methods can not provide robust restoration like the FP model.
However, our proposed CondiQuant can still guarantee fidelity to the greatest extent.

Even more, in 092, the FP model can not provide results with accurate direction on the wall while CondiQuant can correct the error and provide sharp contents.
This is because the FP model suffers from over-fitting and CondiQuant could ease this phenomenon.
Besides, in 095, the competing methods recover bricks with vague texture while CondiQuant keeps aligned with the FP model.
In conclusion, compared to other methods, CondiQuant achieves the minimum information loss after low bit quantization and restores images with high-fidelity, rich details, and shaper edges.

\vspace{-1mm}
\subsection{Condition Number Analysis}
\vspace{-1mm}
The excellent results are closely related to the decrease in condition number.
Therefore, we visualize the condition number shifts in \cref{fig:condition-number} on the SR model with the scale factor of 2.
Figures~\ref{fig:condition-number-depth} and~\ref{fig:condition-number-descend} show the condition number of all layers (including Q, K, V, projection, FC1, and FC2) with different sequences.
\cref{fig:condition-number-depth} is about model depth and \cref{fig:condition-number-descend} sorts the condition number before CondiQuant with descending order.
The other four figures show different layers with model depth as the X-axis.

Overall, the average condition number is hugely reduced from nearly 3k to merely 28.37.
This evident decrease shows the effectiveness of the proximal descent step in CondiQuant.
To be specific, a regular pattern is observed with model depth.
The condition numbers of the FC1 and FC2 in the MLP layer are distinctly smaller than those of other layers, and their influence is also minor.
Hence, considering efficiency, we do not perform CondiQuant on FC1 and FC2.
The condition number of the K matrix in self-attention is usually extremely great.
This is also consistent with the claim that the quantization degradation of ViT is mainly attributed to self-attention.
Moreover, the distribution of the condition number after CondiQuant is greater in the middle and smaller in both ends.
This indicates that the beginning and end modules are more important and insensitive in image restoration.
To conclude, our proposed CondiQuant significantly reduces the condition number with high efficiency.

\vspace{-1mm}
\section{Conclusion}
\vspace{-1mm}
In this paper, we propose CondiQuant, a condition number based post-training quantization method for image super-resolution.
We analyze that the degradation of quantization is attributed to the quantization of activation and build its relationship with condition number.
Thereafter, we formulate the optimization problem to minimize the condition number while maintaining the output as it is.
To optimize, we design the gradient descent step to keep the output still and the proximal descent step to reduce the condition number.
Both steps are calculation efficient and the entire iteration process takes only 19.0 seconds.
As there's no additional module, we reach the theoretically optimal compression and speedup ratio.
Specifically, when quantized to 2 bits, the compression ratio is $3.60\times$ and the speedup ratio is $5.08\times$.
The comparison experiments demonstrate the excellent performance of CondiQuant while the ablation studies present its robustness.

\newpage
{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{main}
}



\end{document}
