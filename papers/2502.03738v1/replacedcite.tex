\section{Related Work}
\label{sec:rel}

\textbf{Generic visual backbones.} The development of visual backbones has fundamentally shaped the field of computer vision. Initially dominated by Convolutional Neural Networks (CNNs), these architectures have evolved to gain increasing capabilities for visual representation learning. Pioneering works such as LeNet____ and AlexNet____ have proven the significant effectiveness of convolutional architectures in large-scale image classification tasks. Following these foundational models, the architecture has been refined with the innovations in model depth____, residual connection____, and efficient neural architecture search____.

The landscape of visual backbones underwent another round of significant transformation with the introduction of ViTs____ in late 2020, where a novel plain architecture was proposed that treats images akin to language sequences. This model utilizes a simple patchification layer to convert images into sequences of tokens, which are then processed using mechanisms adapted from language models. This approach opened new avenues in handling visual data without the inductive biases inherent in CNNs, demonstrating competitive performance on several benchmarks. The success of ViTs have spurred rapid development and innovations in data-efficient training strategies____, self-supervised learning techniques____, vision-language understanding____, and hierarchical architecture designs____.

Inspired by the patchification design of transformers, there have been many CNN-based____ and State Space Model____ based architectures____ following the same paradigm. Notably, the Mamba____ token mixer, due to its advantage of linear complexity, has recently been widely used to explore vision tasks and has achieved competitive results____. Among them, the Adventurer____ architecture, which significantly simplifies the overall model, has demonstrated superior speed compared to the Transformer. In this paper, we employ it as one of the primary experimental models.

\textbf{Visual architecture scaling.} Scaling laws was initially studied in natural language processing____. In vision, a similar concept has guided the community to scale up foundational models in both parameter size and data volume. For example, in the age of CNNs, EfficientNets____ have proposed to scale-up the models in depth, width, and  resolution. These advancements were then integrated into ResNets, leading to nearly Billion-level parameter CNNs____. Scaling the parameter count of Vision Transformers has also shown a great success in modern visual understanding benchmarks and has exhibited state-of-the-art results____.