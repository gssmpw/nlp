

\section{Conclusion}
In our study, we introduce \methodname, an LLM-guided conversation framework that offers a promising shift from the commonly used user-guided paradigm. \methodname's ability to facilitate informative and creative dialogues through goal navigation, context management, and empathetic engagement proves effective, particularly in challenging tasks like autobiography interviewing. Our assessments on event extraction correctness, conversation, and autobiography quality show \methodname's distinct edge over baseline LLMs.

\section{Limitation}
Our study has several limitations, one of which is the prompt sensitivity. Variations in the phrasing of the prompts can significantly impact the model's responses Future work may aim to standardize prompt structures or develop models that are more robust to prompt variations. Another limitation is the evaluation metric. Evaluating the quality of autobiographical content, interviews, and conversations generated by the model is inherently subjective. While we employed multiple evaluation metrics, including interviewing coverage and correctness, these measures depend heavily on individual perceptions. Future research could benefit from developing more standardized and objective evaluation metrics.

\section*{Acknowledgement}
Y. D would like to acknowledge support from NIH OT2OD032581, NIH OTA-21-008, and NIH R01LM014306-01.
J. H is partially supported by the OpenAI Researcher Access Program. M. L is partially supported by Good Systems, a UT Austin Grand Challenge for developing responsible AI technologies\footnote{https://goodsystems.utexas.edu}. This work was partially supported by the NSF award No. 2319242.
