
\section{Human Subject Experiments}


\begin{figure*}[t]
\vspace{-1mm}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/distribution_age.pdf}
        % \caption{Subfigure 1}
        % \caption{Age}
    \end{subfigure}
    % \hfill
    %\hspace{-0.02\textwidth}
    \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/distribution_gender.pdf}
        % \caption{Subfigure 2}
        % \caption{Gender}
    \end{subfigure}
        \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/distribution_race.pdf}
        % \caption{Subfigure 2}
        % \caption{Race}
    \end{subfigure}
        \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/distribution_ai.pdf}
        % \caption{Subfigure 2}
        % \caption{AI Familiarity}
    \end{subfigure}
        \begin{subfigure}[b]{0.2\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/distribution_ai_usage.pdf}
        % \caption{Subfigure 2}
        % \caption{AI Usage}
    \end{subfigure}
        
    }
    \vspace{-8mm}
    \caption{ The demographics of participants on (a) age, (b) gender, (c) race, (d) AI familiarity, and (e) AI usage. }
    \label{fig:human_eval_distribution}
    \vspace{-4mm}
\end{figure*}

\textbf{Experimental Configuration.}
A within-subject study with 45 participants was conducted at a large urban university campus in the US. Participants interact with the interviewing agents powered by GPT-4o and ours \methodname, discussing the topic \textit{Key Scenes in the Life Story: Positive Childhood Memory} (\cref{appendix:interview_protocol}) with each chatbot. To remove any biased factors, we use the nickname \textit{Breeze} and \textit{Echo} for the GPT-4o baseline and \methodname to make sure participants are unaware of the identity of the chatbot. The order to interact with chatbots is also randomized for each participant. Due to resource constraints, each participant spent only 8 minutes chatting with each chatbot on a single topic. This differs significantly from the automatic evaluation protocols (\cref{sec:automatic_eval_exp}). As a result, the capabilities of \methodname, such as context management, goal navigation, and evaluation metrics, will be substantially affected and limited. 

In a follow-up survey (\cref{appendix: Questionnaire}), participants indicated which model performed better, or it was a tie, and provided reasonings. 
Participation is voluntary, with informed consent obtained online, and participants are compensated with a cookie. The study received IRB approval from the university where the study was conducted.

\noindent\textbf{Findings.}
Overall, \methodname was preferred for conversation quality (\cref{fig:win_rate_conv}), particularly in fluency and question identification (Fluency: \methodname Win Rate=40\%, Baseline Win Rate$\approx$33\%; Identification: \methodname$\approx$53.3\%, GPT-4o$\approx$42.2\%). However, in terms of comfort, \methodname had a 31.1\% win rate, while baseline had a 40\% win rate. In autobiography quality, we do not observe significant differences emerged, possibly because this study used one topic and allowed a short interaction. Since the \methodname uses modules such as context management and goal navigation for insightful and consistent narratives, longer engagement across multiple topics might have better highlighted the differences in autobiography generation. We further conduct LLM-as-a-judge evaluation by prompting LLMs to compare the two human-interviewed autobiographies. As shown in~\cref{fig:win_rate_autobio}, we obtained consistent results as in~\cref{section:autobio_eval}: \methodname achieves higher autobiography quality in general.

Previous AI experience affects participants' perceptions of the models:
\textbf{Participants who frequently used AI (4-7 days weekly) tended to prefer \methodname for overall conversation quality (Chi-squared = 16.56, df = 8, p-value = 0.03)}. Open-ended responses indicated that daily AI users felt \methodname ``asked questions to get a better understanding'', ``made more sense'', was ``more interactive'', and asked ``more personal questions''. One user appreciated that ``\methodname is more in-depth as it tries to connect my past experience to my current life''. Overall, frequent AI users perceived \methodname as asking more focused and personal questions to explore in-depth childhood experiences. This aligns with \methodname’s Memory Graph Extrapolation (MGE), which allows it to explore unique properties and offer adaptive, personalized interview questions.
\begin{figure}[t]
\vspace{-1mm}
    \centering
    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[width=\textwidth]{figures/comf_iden_flu.pdf}
        \caption{Win Rate of human preference on conversation quality.}
        \label{fig:win_rate_conv}
    \end{subfigure}
    
    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[width=\textwidth]{figures/insight_narra_emo.pdf}
        \caption{Win Rate of LLM-as-a-judge results on human-interviewed autobiographies.}
        \label{fig:win_rate_autobio}
    \end{subfigure}
    \vspace{-5mm}
    \caption{The Win Rates (WR) of human evaluation.}
    \label{fig:win_rate}
    \vspace{-6mm}
\end{figure}
\noindent \textbf{Frequent AI users favored \methodname for its emotional impact on autobiography (Chi-squared = 14.24, df = 8, p-value = 0.07). }One user noted that \methodname ``truly laid out what it felt like to be at a dance competition pretty much just as I remembered it'', while another mentioned it ``described in immense detail my exact experience and made me feel like I was reliving it''. This suggests how frequently AI users recognized \methodname’s training with the emotion detection module, which analyzes the emotions in user responses and assigns emotion categories and strengths to their utterances.
