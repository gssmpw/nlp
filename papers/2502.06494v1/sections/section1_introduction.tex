
\section{Introduction}
Large Language Models (LLMs) have demonstrated their effectiveness in \textit{human-guided} dialogue, in which LLMs are tasked with producing responses according to specific commands from human operators, such as instruction following~\cite{ouyang2022training} and question answering~\cite{chang2024survey}. In this type of task, the primary duty of  LLMs is to adhere to the instructions given by humans to ensure the generated output is accurate and close to human expectations, as shown in~\cref{fig:human_guided_vs_llm_guided}(a).

However, tasks in the real world are more complex, necessitating greater autonomy from LLMs~\cite{wang2024survey,duan2022survey,wu2023autogen}. For example, tasks such as interviewing are dramatically different from traditional tasks as interviewing is open-ended, without definitive or ``perfect'' outcomes. Interviewing tasks demand that LLMs plan the interview procedure, manage the objectives, e.g., \textit{exploring the user's memory and life experiences in autobiography interviewing}, and offer adaptive and personalized inquiries based on the users' responses. This conversation paradigm requiring LLMs to guide and manage the conversation, ensuring the conversation flows smoothly and the objectives are met, is termed as \textit{LLM-guided} conversation (~\cref{fig:human_guided_vs_llm_guided}(b)).

There have been related works in the LLM-guided conversation, such as role-play~\cite{wang2024incharacter,wang2023rolellm,chen2024roleinteract,tao2023rolecraft,li2023chatharuhi} and goal-oriented LLMs~\cite{ham-etal-2020-end,NEURIPS2020_e9462095,wu-etal-2020-tod,MehriDialoGLUE2020,Inagaki2023LLMsCG}. For role-play LLMs, they either prompt LLMs to perform specific roles such as a patient~\cite{wang2024patient}, doctor~\cite{panagoulias2024augmenting}, gamer~\cite{duan-etal-2024-reta, duan2024gtbench}, or investigate the human-like features of LLMs, e.g., emotions~\cite{li2023large} and personalities~\cite{safdari2023personality}. 
Goal-oriented LLMs enable the model to attain greater levels of autonomy, particularly in fields such as space exploration~\cite{maranto2024llmsat}.
While role-play and goal-oriented LLMs provide some autonomy and allow for the simulation of a specific role, their ability to actively control and effectively handle a full conversation is still underexplored. 


\begin{figure*}[t]
    \centering
    \includegraphics[width=1\linewidth]{figures/human_vs_llm.pdf}
    \caption{Comparison between human-guided conversation and LLM-guided conversation. (a) Human-Guided: Human dominates the conversation, providing feedback and instruction to LLMs. (b) LLM-Guided: LLMs navigate the goal by automatically extrapolating interview questions.}
    \label{fig:human_guided_vs_llm_guided}
    \vspace{-5mm}
\end{figure*}

In this paper, we investigate the LLM-guided conversation from framework design to autobiography interviewing applications. 
Inspired by popular social science theories, PEACE Model~\cite{clarke2001national} and Motivational Interviewing (MI)~\cite{hettema2005motivational}, we design
\methodname to comply with these models by comprising three pivotal components: (\textit{i}) \textbf{Goal Navigation} module, as the cornerstone of the framework, steers the conversation with pre-defined interviewing protocols and dynamic memory graphs for extrapolating dialogue trajectories. (\textit{ii}) \textbf{Context Management} module iteratively distills the main idea of each session into a contextual summary for subsequent sessions.
(\textit{iii}) \textbf{Empathetic Engagement} module refines LLM response with expression strategies by the real-time monitoring of user emotion. 

For evaluation, we create an interviewing environment where \methodname is tasked with conducting interviews over 23 different topics, ultimately producing an autobiography based on the outcomes of these interviews. Then, the behaviors of \methodname and baselines are evaluated in three-folds: (\textit{i}) {Interviewing Quality}, {e.g., event coverage and correctness}; (\textit{ii}) {Conversation Quality} {e.g., communication fluency, identification, and comforting}; (\textit{iii}) {Generation Quality}, {e.g., the insightfulness, narrativity, and emotional impact of the generated autobiography}. We also carry out human-involved experiments with 45 participants, prompting them to engage in conversations with \methodname and baseline models. Following these interactions, we gather feedback, preferences, and ratings from the participants.
Our contributions can be summarized as the following:
\begin{itemize}

    \item \textbf{Framework.} We define the realm of LLM-guided conversations and propose \methodname as an installation within this conversational paradigm. There are three components comprised in \methodname: Goal Navigation, Context Management, and Empathetic Engagement.

    \item \textbf{Technique.} \methodname effectively harnesses a variety of techniques such as Retrieval Augmented Generation (RAG) and long-context summarization to boost the ability of LLMs to effectively lead and steer a conversation. Moreover, a memory graph is designed to drive memory extrapolation, thereby enhancing the goal navigation capabilities of \methodname.

    \item \textbf{Application.} We present the autobiography interviewing environment as a practical application of LLM-guided conversations. Within this setting, LLMs are tasked with initiating and steering the interview with users, aiming to generate a comprehensive autobiography.

    \item \textbf{Evaluation.} We propose a comprehensive evaluation protocol for our LLM-guided autobiography interviewing environment, including interview quality, conversation quality, and autobiography generation evaluation, encompassing both LLM-as-a-judge evaluation and human subjects evaluations.
\end{itemize}