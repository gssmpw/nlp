\section{LLM-Guided Autobiography Interview}
In this section, we first introduce LLM-guided conversation and its general framework. Then, we introduce \methodname as an implementation of LLM-guided conversation, centering on interviewing.

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{figures/framework.pdf}
    \caption{The overall pipeline of \methodname in the guided conversation environment.}
    \label{fig:llm_as_autobiographer}
    \vspace{-5mm}
\end{figure*}

\subsection{LLM-Guided Conversation}
Several theories from social science research provide comprehensive protocols for how to conduct guided conversations, e.g., interviewing. For instance, the PEACE Model~\cite{clarke2001national} and Motivational Interviewing (MI)~\cite{hettema2005motivational} highlight ``\textit{engage and explain}'' and ``\textit{planning and preparation}''. To comply with these theories, \methodname is designed from three essential qualities that an LLM should possess for effective conversation guidance:

\paragraph{\textit{Goal Navigation.}} LLM steers the conversation and determines pivotal transitions, initiatively exploring and extrapolating new components that can shift the conversation toward the intended outcome.
\paragraph{\textit{Context Management.}} LLMs summarize the ongoing dialogue, resuming previous discussions, connecting current conversations with past ones, and managing historical data exchanged between the LLM and users.
\paragraph{\textit{Empathetic Engagement.}} LLMs interact with the user by providing empathetic responses, delivering suitable tone and content, and demonstrating sensitivity towards the user's emotional state.

LLM-guided conversations extend to numerous practical applications. For instance, in {\textit{Interviews}}, they can frame pertinent questions, guiding the conversation. In {\textit{Educational Tutoring}}~\cite{nye2023generative}, LLM-guided conversations can assess the user's state, crafting specific and personalized plans to facilitate the learning process. Another promising application is {\textit{Mental Health Therapy}}~\cite{demszky2023using,hong2024conect}, where the LLM can guide the conversation, applying personalized therapy based on the user's responses. \cref{fig:llm_as_autobiographer} provides a overall pipeline for \methodname in guided conversations. We will use the autobiography interviewing task as an example of guided conversations for the rest of this paper.

\subsection{Goal Navigation}
In guided conversations, LLMs are responsible for guiding the conversation, delivering adaptive responses to users, and ensuring that the conversation objectives are met.
To accomplish this, we utilize a hybrid approach, combining \textit{Verbalized Interviewing Protocol (VIP)}~\cite{2016maunsell,castillo2016preparing,lamb2007structured} with \textit{Memory Graph-Driven Extrapolation (MGE)}:


\paragraph{Verbalized Interviewing Protocol (VIP).} We leverage the popular interviewing protocol, \textit{``The Life Story Interview''}~\cite{mcadams2008life}, as the general guidance. 
This protocol covers essential topics including \underline{\textit{Life Chapters}}, \underline{\textit{Key Scene in Life}}, \underline{\textit{Future}}, \underline{\textit{Challenges}}, and \underline{\textit{Personal Ideology}}. For instance, in the \textit{Challenges} area, topics such as \textit{Life Challenges}, \textit{Health}, \textit{Loss}, and \textit{Regrets} will be covered. We design system prompts according to specific topics, containing basic seed questions, to make LLMs primarily focus on one topic during each session. In this way, the entire interviewing process could be structured into 23 sessions of conversations between the user and the LLM chatbot. 
Please refer to~\cref{appendix:interview_protocol} for more details of the interviewing protocol and the prompt templates.

\paragraph{Memory Graph Extrapolation (MGE).}\label{sec:memory_graph}
The objective of MGE is to explore unique characteristics and generate adaptive questions for personalized interviewing. MGE operates as an LLM-driven function, performing various operations on memories, including (i) \textit{extracting} events from conversations, (ii) \textit{inserting} new events into the graph, (iii) \textit{merging} existing events, and (iv) \textit{extrapolating} queries based on current events. Each event is associated with properties such as Date, People Involved, and Event Description.

In essence, MGE follows an ``extract, merge, then extrapolate'' process: initially, memory is initialized based on the user utterance. Next, the extraction process identifies and lists any events mentioned by the user, which are then merged with the existing events. Finally, MGE generates personalized questions from the event nodes by uncovering various relationships, such as identifying individuals who are mentioned frequently. These questions are stored in a "question cache" for use in the subsequent turn of the conversation. For details on the prompt templates used for event extraction and memory extrapolation, please refer to~\cref{appendix:mge}.


\subsection{Context Management}
Context is a crucial information source for long conversations where each autobiographer has a unique and lengthy personal experience.
However, LLMs have limited context lengths that can be easily exceeded when processing autobiographies~\cite{dai2019transformer}. Besides, long-context input may bring performance decrease~\cite{Liu2023LostIT} and huge financial cost for the close-sourced. To tackle this, we incorporate a context management module in our framework capable of progressively summarizing and retrieving conversation history.

\paragraph{Conversation History Summarizing.}
Inspired by~\citeauthor{Chang2023BooookScoreAS,maharana2024lococmo}, we implement an iterative summarization process that generates a summary for the current session based on the summaries from previous sessions, providing additional context for the chatbot. When initializing the chatbot, if a history conversation file is present in the configuration, we first generate a summary of the loaded conversation. At the start of each conversation after the first, the system prompt of the LLM chatbot includes a summarization section (see Appendix~\ref{appendix:system_prompt}), beginning with an instruction indicating that it has previously conversed with the user, followed by the specific summary of the prior session. The prompt and summarization pipeline are detailed in Appendix~\ref{appendix:summary_prompt} and Figure~\ref{fig:summary_pipe}.

\subsection{Empathetic Engagement}\label{sec:empathetic_engagement}
LLM-guided conversations should accurately understand the user's state and respond appropriately. This involves empathetic interaction, creating a space where users feel at ease to share more about themselves.  We accomplish this by enhancing \textit{Expression Strategies} and \textit{Emotion Detection}:


\input{tables/memory_exploration}
\input{tables/jane_eyre}

\paragraph{Expression Strategy.} To enhance the expression capability of LLMs, we draw inspiration from popular mental health therapy strategies, including Reflective Listening~\cite{rautalinko2007reflective}, Cognitive-Behavior Therapy (CBT)~\cite{beck2020cognitive}, and Psychodynamic Therapy~\cite{leichsenring2003effectiveness}. Although originally designed to address mental health issues, these therapeutic strategies offer insightful guidance on effective communication with users and provide meaningful advice on interaction techniques. The introduction to therapy strategy and prompts are in~\cref{appendix:therapy_strategy}.

\paragraph{Emotion Detection.} Emotion sensitivity is a critical element in conveying the state of individuals that has been significantly underscored in human-computer interaction~\cite{cowie2001emotion, brave2007emotion} and LLMs~\cite{li2023large}. 
To enhance the emotional sensitivity of LLMs, we employ EmoLlama-7b~\cite{liu2024emollms} for the emotion detection of user utterances. Specifically, we prompt EmoLlama to provide both the emotion category (one of the emotions including \textit{anger, anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, trust}) and its intensity (\textit{from 0 to 1}) for user response. We then guide the LLM to generate suitable responses that align well with the user's emotional state, e.g., including expressions of empathy or comfort when detecting an upset user. Please refer to~\cref{appendix:emotion} for more details.

\subsection{Autobiography Generation}
\input{tables/statistics}

Autobiography holds a distinctive form in comparison to other book categories, as an autobiography typically consists of numerous individual chapters, each of which relays a specific spirit or theme intimately tied to the author's life. This format aligns seamlessly with our structured interview protocol; the scope and topics encompassed in the interview protocols are similarly singular and targeted, allowing for a thorough exploration of each subject.

Therefore, when generating an autobiography, we generate each 
chapter by sequentially building upon each interviewing session.
Specifically, for each session, we meld the conversation history and memory nodes derived from the current session, then prompt GPT-4 to emphasize the key areas and topics discussed in that particular session.
Please refer to~\cref{appendix:autobiography_generation} for more details of autobiography generation.

