\section{Related Work}

\noindent\textbf{Role-Play LLM.} Role-playing agents (RPAs) powered by large language models (LLMs) are challenged by the evaluation of fidelity to target personas. Traditional methods focus on replicating characters' knowledge and linguistic patterns, requiring character-specific datasets. ~\citet{huang2023psychobench} evaluate LLM personalities with self-report scales (BFI and MBTI), targeting LLM psychometric properties but not specifically addressing persona adherence.~\citet{li2023chatharuhi} and~\citet{wang2023rolellm} develop character-specific RPAs to enhance conversational abilities, human-likeness, and multi-turn consistency. 
However, they have not deeply explored character fidelity. 
\citet{tao2024chatgpt} found that adapting responses based on emotional cues significantly improved user satisfaction in role-playing scenarios. \citet{tao2023rolecraft} also demonstrated that with a scalable and controlled learning environment, LLM-driven simulations could effectively mimic real-life interactions.

\noindent\textbf{Long Text Generation and Management.}
The key techniques for long text generation and management considered in this study include summarization and Retrieval Augmented Generation (RAG).
\citet{luo2023chatgpt} explore using ChatGPT to evaluate factual consistency in summarization. \citet{zhong2022dialoglm} propose a pre-training framework for long dialogue understanding and summarization using a window-based denoising approach. \citet{xu2022sequence} introduce a contrastive learning model, SeqCo, to improve the faithfulness of abstractive text summarization. \citet{zhang2021summ} efficiently processes long texts by dividing them into manageable segments and summarizing each iteratively.
\citet{gao2023retrieval} overview RAG, which integrates external knowledge from databases to enhance LLM-generated content's reliability. 
