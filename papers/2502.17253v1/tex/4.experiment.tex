\subsection{Settings}

\begin{table*}[ht]
\centering
\tiny
\input{tab/main}
\caption{
EM (above) and F1 (below) of different models and baselines across languages on \ourdataset.
Avg. denotes the average performance of the baseline across all languages.
The best results of each model under each language are annotated in \textbf{bold}. 
}
\label{tab:main}
\end{table*}

\paragraph{Metrics}
% 我们使用Exact Match (EM)和F1衡量答案的正确性，follow前人工作
We use Exact Match (EM) and F1 score to evaluate the answers, following prior works \cite{chen-etal-2020-hybridqa,zhu-etal-2021-tat}. 
% EM是指模型的预测结果与目标答案完全一致的比例
EM refers to the proportion of predictions that exactly match the gold answer, and F1 measures the degree of overlap between the predicted and the gold answer in terms of their bag-of-words representation.
% F1则衡量了预测答案和真实答案之间词袋的重叠程度

\paragraph{Models}
% 我们使用了开源模型Llama3.1-Instruct (Llama3.1)和闭源模型gpt-4o来评测我们的数据集
We evaluate \ourdataset using the open-source model Llama3.1-Instruct (Llama3.1)~\cite{dubey-etal-2024-llama3.1} and the closed-source model \texttt{gpt-4o}~\cite{openai2024gpt4technicalreport}. 
% Llama3.1是目前表现最好的开源模型之一
Llama3.1 is currently one of the best-performing open-source models, and \texttt{gpt-4o} is considered one of the leading closed-source models.
% gpt-4o则是当前最优秀的闭源模型之一


\paragraph{Baselines}
% 我们将我们的方法和以下baseline比较,follow前人工作
We compare \ourmethod with the following baselines with three-shot prompts, following previous works \cite{shi2023MGSM,li-etal-2024-eliciting-Multilingual-code}.
\begin{itemize}
    % - Native-CoT：用原语言的CoT解答问题
    \item Native-CoT: solving the question using CoT~\cite{wei2022chain-of-thought} in the native language
    % - En-CoT:用英语CoT解答问题
    \item En-CoT: solving the question using CoT in English
    % - Native-PoT：用原语言的instruction提示LLM生成代码回答问题
    \item Native-PoT: prompting the LLM to generate code in the native language \cite{pal,pot}
    % - En-PoT:用英语的instruction提示LLM生成代码回答问题
    \item En-PoT: prompting the LLM to generate code in English 
    % Three-Agent是TAT-QA数据集上的SOTA方法，由3个agent构成：analyst agent负责抽取相关数据并计算，两个critic agent分别负责判断抽取和计算的正确性，并据此进行修改
    \item Three-Agent~\cite{fatemi2024three-agent} is the state-of-the-art method on the TAT-QA dataset. It consists of three agents: the analyst agent extracts relevant data and performs computations, and two critic agents evaluate the correctness of extraction and computation, respectively, and refine the results accordingly. 
    % 受限于计算资源，我们没有在gpt-4o上评测Three-Agent在我们数据集上的性能
    Due to computational resource limitations, we do not evaluate the performance of Three-Agent on \ourdataset using \texttt{gpt-4o}.
\end{itemize}
We present prompts for baselines and \ourmethod in Appendix~\ref{sec:prompt}.
% 我们还在附录中提供了直接回答和将输入翻译为英文之后推理的结果
Additionally, we provide results for both directly answering the question and reasoning after translating the input into English in Appendix~\ref{subsec:otherbaselines}.


\subsection{Main Experiments}
\label{subsec:main experiments}
% 在不同语言上我们的方法和其他baseline的对比如表所示
A comparison of \ourmethod with other baselines across different languages is presented in Table~\ref{tab:main}. 
% 可以发现
We observe that:
% 1. 非英语语言的TATQA性能相比英语性能平均下降%，证明了我们数据集的必要性
(\emph{i})~The performance on \ourdataset in non-English languages shows an average decrease of $19.4\%$ compared to English, underscoring the necessity of \ourdataset.
% 2. 我们的方法相比其他baseline平均提升%，弥合了%不同语言之间的性能差距，证明了我们方法的有效性
(\emph{ii})~\ourmethod demonstrates an average improvement of $3.3$ on EM and F1 over other baselines, reducing the performance gap between different languages by $23.2\%$, which validates the effectiveness.
% 3. 即使提升，所有baseline在所有语言上的EM和F1均低于40，证明了我们数据集的挑战性
(\emph{iii})~Despite these improvements, the EM and F1 of all baselines remain below $40$, highlighting the challenges of \ourdataset.


\paragraph{Baselines}
% 我们方法一致地超越了Three-Agent，是因为Three-Agent不完全适用于不需要计算的HybridQA数据集，和需要复杂计算很难依靠模型本身计算能力求解的SciTAT数据集，并且在非英语语言上，multi-agent的性能下降
(\emph{i})~\ourmethod consistently outperforms Three-Agent because Three-Agent is not fully suited to HybridQA, which does not require computations \cite{chen-etal-2020-hybridqa}, or SciTAT, which involves complex calculations that are challenging to the inherent capabilities of models \cite{zhang2024scitat}. 
Additionally, the performance of multi-agent declines in non-English languages \cite{beyer2024clembench,chen-etal-2024-Cross-Agent}.
% 用原语言推理和用英语推理之间的性能差异不大
(\emph{ii})~The performance difference between reasoning in the native language and English is minimal. 
% 虽然模型在英文上展现出更强的推理能力，但由于TATQA任务相比其他任务，如数值推理任务，更需要模型将问题中的实体对应到文本或表格中的实体的能力，而这一问题在跨语言推理时会更具有挑战
Although LLMs demonstrate stronger reasoning capabilities in English, the TATQA, compared to other tasks, relies more heavily on the capabilities of linking information, which presents greater challenges in cross-lingual reasoning \cite{min-etal-2019-cspider}. 
% 而我们的方法缓解了这一挑战，所以提升了性能
Therefore, \ourmethod mitigates this challenge, leading to improved performance. 
% 并且，PoT方法在我们数据集上的性能普遍优于CoT，因为我们数据集中数值推理类问题占较大比例（见表1），所以更适合PoT方法求解
(\emph{iii})~PoT consistently outperforms CoT because numerical reasoning questions constitute a significant proportion of \ourdataset (see Table~\ref{tab:answer_statistics}), making PoT more suitable for solving these questions \cite{pot,zhao-etal-2024-docmath}.

\paragraph{Languages}
% 模型普遍表现出在高资源语言，包括英语，德语，西班牙语，法语，俄语和中文上的性能普遍较高，而在低资源语言上的性能较差
The models generally exhibit high performance on high-resource languages, such as English, German, Spanish, French, Russian, and Chinese, while their performance on low-resource languages tends to be poor. 
% 而多语言能力越强的模型，在不同语言之间性能的差距越小，其中gpt-4o展现出了最强的性能
Moreover, models with stronger multilingual capabilities show smaller performance gaps across languages, with \texttt{gpt-4o} demonstrating the highest performance. 
% 这也证明了在有挑战的任务上评测模型多语言性能的必要性
This also underscores the necessity of evaluating multilingual performance on challenging tasks.

% \begin{figure*}[t]
%     \centering
%     \input{fig/answer_source}
%     \vspace{-0.5em}
%     \caption{
%         The EM of \ourmethod across different answer sources on Llama3.1-70B.
%     }
%     \label{fig:answer_source}
%     \vspace{-1em}
% \end{figure*}

\begin{figure}[t]
    \centering
    \input{fig/answer_source}
    \caption{
        The EM of \ourmethod across different answer sources on \ourdataset using Llama3.1-70B.
    }
    \label{fig:answer_source}
\end{figure}

\paragraph{Answer Source}
% 我们分析了我们的方法使用Llama3.1-70B时在不同答案来源上的性能，如图所示
We analyze the performance of \ourmethod using Llama3.1-70B across different answer sources, as shown in Figure~\ref{fig:answer_source}. 
% 使用其他模型时以及不同的基线在不同来源上的性能在附录中提供
The performance with other models and baselines across answer sources is provided in Appendix~\ref{subsec:appendix_answer_source}. 
% 可以发现
The results show that:
% 1. 答案来源为Hybrid的问题的性能整体上优于单一答案来源的问题
(\emph{i})~The performance of the hybrid answer source generally outperforms those with a single answer source. 
% 因为我们的方法相比基线（见表）可以同时从表格和文本中链接到相关信息，整合了异质的相关上下文，一定程度上缓解了混合的答案来源的挑战
Since \ourmethod, compared to other baselines (see Figure~\ref{fig:answer_sources_other_baselines}), enhances the links between the question and the context, integrating hybrid contextual information and alleviating the challenge.
% 2. 虽然整体上英语的性能最佳，但在不同的答案来源上不同语言展现出了不同的趋势
% While English performs best overall, different languages exhibit varying trends across answer sources. 
% 不同语言在答案来源上的性能除了与高资源或低资源有关，还与语言本身的特性有关
(\emph{ii})~The performance across answer sources is influenced not only by the availability of language-specific resources but also by the characteristics of the language.
% 比如，词法结构复杂的语言在答案来源是text上的性能较差，如德语、俄语等
For instance, languages with complex morphological structures, such as German and Russian, perform worse when the answer source is text. 
% 而斯瓦希里语在文本上的性能最高，因为其有着较为简单的词法结构，能相对容易地根据问题中的实体链接到文本中的实体
In contrast, Swahili shows the highest performance on text-based sources, as its simpler morphology allows for easier linking of entities in the text to those in question \cite{tuan-nguyen-etal-2020-Vietnamese,zhang-etal-2023-xsemplr}.

% \begin{figure*}[t]
%     \centering
%     \input{fig/answer_type}
%     \vspace{-0.5em}
%     \caption{
%         The EM of \ourmethod across different answer types on Llama3.1-70B.
%     }
%     \label{fig:answer_type}
%     \vspace{-1em}
% \end{figure*}

\begin{figure}[t]
    \centering
    \input{fig/answer_type}
    \vspace{-0.5em}
    \caption{
        The EM of \ourmethod across different answer types on \ourdataset using Llama3.1-70B.
    }
    \label{fig:answer_type}
    \vspace{-1em}
\end{figure}

\paragraph{Answer Type}
% 我们比较了我们方法在Llama3.1-70B上在不同答案类型上的性能，如图所示
We compare the performance of \ourmethod using Llama3.1-70B on different answer types, as shown in Figure~\ref{fig:answer_type}. 
% 我们在附录提供了其他模型和基线在不同答案类型上的性能
Results of other models and baselines across answer types are provided in Appendix~\ref{subsec:appendix_answer_types}. 
% 我们发现
We observe that:
% 1. 模型在Span类型和Arithmetic上的性能不好，而在Count类型上的性能最高
% (\emph{i})~The model performs poorly on Span and Arithmetic types, while it performs best on the Count type. 
(\emph{i})~The model performs best on the Count type. 
% 因为span类型的答案需要从表格和文本中抽取出短语，或用几句话总结分析，相比较Arithmetic和Count的答案都为数字，对词语的构成和顺序更为敏感
This is because Span answers require extracting short phrases or summarizing conclusions from tables and text, making them more sensitive to word composition and order. 
% 而Arithmetic类型相比较Count类型需要模型进行更加复杂的运算
Additionally, Arithmetic answers involve more complex computations than Count answers.
% 2. 模型在不同答案类型上的性能整体上呈现高资源语言优于低资源语言
(\emph{ii})~The model performs better on high-resource languages than low-resource languages across answer types overall. 
% 即使我们的方法减小了性能差距，但低资源语言和高资源语言之间仍在不同的答案类型上均存在较大的性能差距
Although \ourmethod narrows the performance gap, there remains a significant difference between high-resource and low-resource languages for all answer types.

\subsection{Analysis}
% 在本小节，我们主要分析模型在TATQA任务上的跨语言能力

\begin{table*}[ht]
\centering
\tiny
\input{tab/prompt_language}
\caption{
EM (above) and F1 (below) of \ourmethod using the instructions and demonstrations of different languages on Llama3.1-70B.
The best results under each language are annotated in \textbf{bold}. 
% Multi指的是由多种语言（英语、西班牙语和中文）组成的示例
Demo refers to demonstrations. 
Multi refers to demonstrations composed of multiple languages (English, Spanish, and Chinese).
Avg. denotes the average performance of the baseline across all languages.
}
\label{tab:prompt_language}
\end{table*}

% prompt的语言如何影响我们方法的性能
% How does the language of prompt affect the performance of our method?
% \subsubsection{Prompt Language}
\subsubsection{How does the Prompt Language Affect \ourmethod?}
% 我们分析了使用不同语言的instruction和示例对我们方法性能的影响，如表所示
We analyze the impact of using instructions and demonstrations in different languages on the performance of \ourmethod, as shown in Table~\ref{tab:prompt_language}. 
% 其中，多语言示例我们选择了分别是英语、西班牙语和中文的各一个示例，因为模型在这三个高资源语言上的性能较高，且包含两个语系
For the multilingual demonstrations, we select one demonstration each from English, Spanish, and Chinese, as the models perform well on these three high-resource languages, which also cover two language families. 
% 而英文instruction和英文示例是我们主实验采用的设置
The English instruction and English demonstrations are the settings of \ourmethod used in the main experiments. 
% 可以发现，
The results indicate that:


% 1. 使用英文instruction整体上优于使用原语言instruction
(\emph{i})~Using English instructions generally outperforms using native instructions.
% 2. 使用多语言示例打败了原语言和英语示例，说明当在某些语言上没有足够的TATQA示例时，可以采用同一语系或高资源语言的示例来提升模型性能
(\emph{ii})~Multilingual demonstrations outperform both native language and English demonstrations, suggesting that when sufficient native demonstrations are not available on the TATQA task, using demonstrations from the same language family or high-resource languages can also enhance performance.
% 同时，斯瓦希里语在使用原语言的instruction和示例时达到最高性能，说明了这种语言的独特性，模型不容易将在高资源语言上的知识和推理能力迁移到斯瓦西里语上
Additionally, Swahili achieves the highest performance when using instructions and examples in the native language, highlighting its uniqueness. 
% This suggests that it is difficult for the model to transfer knowledge and reasoning capabilities from high-resource languages to Swahili.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{fig/heatmap_cross.pdf}
    \caption{
    % 被各个表示正确解决的instance之间的重复率
    The EM/F1 of \ourmethod with questions and context (table and text) of different languages on \ourdataset using Llama3.1-70B. 
    }
    \label{fig:heatmap_cross}
\end{figure}

% 跨语言
% \subsubsection{Cross-lingual QA}
\subsubsection{How does the Language Affect \ourmethod in the Cross-lingual Setting?}
% 我们评测了在跨语言QA，即问题和文本、表格的语言不一致的设置下我们的方法在我们数据集上的性能，如图所示
We evaluate the performance of \ourmethod in the cross-lingual setting, where the languages of the question and context are inconsistent, with results in Figure~\ref{fig:heatmap_cross}. 
% 我们分别选取了高资源语言法语和中文，以及低资源语言孟加拉语、斯瓦希里语和泰卢固语，涉及4个语系
We select high-resource languages (French and Chinese), and low-resource languages (Bengali, Swahili, and Telugu), covering $4$ language families. 
% 我们发现
Our findings include:
% 1. 普遍来讲，模型从低资源跨到高资源时会带来性能提升，反过来则下降
(\emph{i})~Generally, \ourmethod shows improved performance when transitioning from low-resource to high-resource languages, while the opposite results in a decline. 
% 比如用法语和中文对法语上下文提问的性能较高，而用三种低资源语言提问的性能较低
For instance, the performances on the French context with French and Chinese questions are relatively high, whereas the performances with three low-resource languages are lower.
% 2. 斯瓦希里语在跨语言的设置上表现出较为稳定的性能，且在同语言QA上达到最佳性能
(\emph{ii})~The model achieves the best performance when the question and context are both Swahili. 
% 因为斯瓦希里语较为规则的语法和词法结构，使其在我们的任务上受益，尤其是需要链接相关信息时相比其他语言更加容易
This can be attributed to its relatively regular grammatical and lexical structures, which provide advantages when linking related information.
% making it easier compared to other languages.

% \begin{table*}[ht]
% \centering
% \small
% \input{tab/error}
% \caption{
%     % 我们方法上非英语相比英语性能落后的错误原因，及比例
%     The error types and the proportion of non-English performance in \ourmethod are lagging behind that of English.
% }
% \label{tab:error}
% \end{table*}

\begin{figure}[t]
    \centering
    \input{fig/error}
    % \vspace{-0.5em}
    \caption{
    % 我们方法上非英语相比英语性能落后的错误原因，及比例
    The error types and their proportion of non-English performance in \ourmethod are inferior compared with English. 
    \textbf{Linking} refers to mapping entities in the question with incorrect information in the table or text. 
    \textbf{Formula} refers to using an incorrect formula. 
    \textbf{Redundancy} refers to outputting irrelevant information beyond the correct answer. 
    }
    \label{fig:error}
    \vspace{-1em}
\end{figure}

\subsection{Error Analysis}
\label{subsec:Error Analysis}
% 我们分析了我们方法在非英语语言上相比英语落后的原因，如图所示
We analyze the reasons for the inferior performance of \ourmethod on non-English languages compared to English, as shown in Figure~\ref{fig:error}. 
% 具体来说，我们选取Llama3.1-70B上我们的方法在英语上达到EM为1，而在非英语上EM为0的问题，每种语言随机sample 5个，共50个错误进行对比分析
Specifically, we select instances where \ourmethod achieved an EM of $1$ in English using Llama3.1-70B, but an EM of $0$ in non-English languages. 
For each language, we randomly sample five instances, with a total of $50$ errors for comparative analysis. 
% 我们在附录中展示了每种类型对应错误的示例
Examples of errors corresponding to each type are provided in Appendix~\ref{subsec:case study}. 
% 下面我们具体介绍每种错误
Below, we present a detailed discussion of each error type:

% 1. 链接：指模型将问题中的实体对应到了不想关的表格或文本中的信息，导致模型回答错误
(\emph{i})~\textbf{Linking}: 
% refers to associating entities in the question with incorrect information in tables or text. 
% 由于模型在非英语语言上的理解以及推理能力落后于英语，即使我们方法首先令模型专注于链接，模型仍然在链接上展现出了非常的挑战
Due to the relatively weaker abilities in non-English languages compared to English, even though \ourmethod initially prompts the model to focus on linking, the model still faces significant challenges in linking. 
% 尤其是在一些语言上，比如日语的平假名和片假名，或法语、德语等词法变化复杂的语言上，链接的挑战进一步加剧
These challenges are particularly pronounced in languages with complex orthographies, such as Japanese (with its hiragana and katakana scripts), or morphologically rich languages like French and German.
% 2. 公式：指模型在找到相关信息后，使用了错误的公式，导致代码返回了错误的结果
(\emph{ii})~\textbf{Formula} 
% pertains to situations where, after identifying relevant information, the model uses an incorrect formula, resulting in erroneous output. 
% 这也表明了模型在非英语语言上的数值推理能力相比英语仍存在差距
highlights the gap in the numerical reasoning abilities between non-English languages and English.
% 3. 多余信息：指模型没有按照指令的要求，输出了除正确答案之外的多余信息，导致EM为0
(\emph{iii})~\textbf{Redundancy}  
% refers to outputting irrelevant information beyond the correct answer, not as instructed, leading to an EM of $0$. 
% 这体现了模型相对较差的指令遵循能力
reflects the relatively weaker ability of instruction-following.

% 总之，模型在非英语语言上的能力落后，以及语言特殊的属性，令我们的方法在非英语语言上落后于英语，也证明了我们数据集的挑战性
In summary, the inferior performance on non-English languages and the specific properties of languages leads to the lower performance of \ourmethod on non-English languages, which also demonstrates the necessity of \ourdataset.