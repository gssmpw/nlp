\section{Comparison with Previous Datasets}
\label{sec:comparison}
% 在这节，我们将我们的数据集和前人的相关数据集进行详细比较，如表所示
In this section, we make a detailed comparison between \ourdataset and previous TATQA datasets, as shown in Table.
% 可以看到，我们的数据集是第一个多语言TATQA数据集，并且集合了前人来自三个领域的数据集
It can be seen that \ourdataset is the first multilingual TATQA dataset, and it gathers previous datasets from three mainstream fields.

\begin{table*}[ht]
    \centering
    \small
    \input{tab/comparison_tat}
    \caption{
        Comparison of \ourdataset to previous TATQA datasets.
        % Wiki denotes Wikipedia.
    }
    \label{tab:comparison_tat}
\end{table*}


\section{Manual Annotation Process}

\subsection{Annotator Training Process}
\label{subsec:Annotator Training Process}
% 我们雇佣的是计算机科学专业的研究生并且有意愿进行标注的
We hire graduate students majoring in Computer Science who are willing to participate in the annotation process. 
% 我们提供一条数据一元的标注报酬
% We offer a payment rate of one yuan per data instance.
% 我们首先告诉标注者任务的定义，具体需要做的检查及修改（如S2.3所讲），以及标注界面如何使用
First, we provide annotators with a clear definition of the task, the specific checks and revisions required (as described in Section \S\ref{subsec:Rationale Annotation} and \S\ref{subsec:Instance Translation}), and instructions on how to use the annotation interface. 
% 标注界面如所示
The annotation interface is shown in \S\ref{subsec:Annotation Interface}. 
% 最后，我们告知他们标注的截止日期，并鼓励他们遇到不确定的问题及时和我们讨论
We also inform them of the annotation deadline and encourage them to discuss any uncertainties with us promptly.
% 总共有5位标注人员完成了2.2和2.3节的标注，共用时一个月
Finally, a total of five annotators complete the annotation for \S\ref{subsec:Rationale Annotation} and \S\ref{subsec:Instance Translation}, with a combined time of one month.

\subsection{Annotation Interface}
\label{subsec:Annotation Interface}
\begin{figure*}
    \centering
    \includegraphics[width=.95\linewidth]{fig/rationale_check_tool.pdf}
    \vspace{-0.5em}
    \caption{
    % 提供给标注者用于检查回译和原英文instance一致性并修改的标注界面
    The annotation interface is provided to annotators to check the accuracy of the generated rationales.
    }
    \label{fig:rationale_check_tool}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=.95\linewidth]{fig/translation_check_tool.pdf}
    \vspace{-0.5em}
    \caption{
    % 提供给标注者用于检查回译和原英文instance一致性并修改的标注界面
    The annotation interface is provided to annotators to check the consistency of the back translation and the original English instance and refine the translated instances.
    }
    \label{fig:translation_check_tool}
\end{figure*}
% 在本小节，我们展示了标注者标注的界面，which是我们自己开发的，如图所示
In this subsection, we show the interfaces annotated by the annotator, which are developed by ourselves, as shown in Figure~\ref{fig:rationale_check_tool} and Figure~\ref{fig:translation_check_tool}.

% % 母语标注者的信息
% \subsection{Information of Native Annotators}
% \label{subsec:Information of Native Annotators}

% % 翻译的打分
% \subsection{Scores of Translation}
% \label{subsec:Scores of Translation}

\section{Prompt}
\label{sec:prompt}
% 在本节，我们展示我们合成数据和进行实验时使用的prompt
In this section, we show the prompts we use to conduct experiments.
% 表7和表8分别展示了我们实验中构建基线方法的prompt和我们方法使用的prompt，我们以中文为例
Table~\ref{tab:prompt_baseline} and Table~\ref{tab:prompt_our_method} show the prompts of the baselines and \ourmethod in experiments respectively, with French as the example language.
% Three-Agent使用的prompt沿用原论文提供的prompt
The prompt of Three-Agent~\cite{fatemi2024three-agent} follows the prompt provided in the original paper.
% 我们在不同语言和baselines之间保持了示例的统一，如表所示
We maintain the unity of demonstrations between different languages and baselines, as shown in Table~\ref{tab:prompt_our_method}.

\begin{table*}[ht]
    \centering
    \small
    \input{tab/prompt_baseline}
    \caption{
    The prompts of baselines for French.
    }
    \label{tab:prompt_baseline}
\end{table*}

\begin{table*}[ht]
    \centering
    \small
    \input{tab/prompt_our_method}
    \caption{
    The prompts of \ourmethod for French.
    }
    \label{tab:prompt_our_method}
\end{table*}


\section{Additional Experiments}
\label{sec:Additional Experiments}

\subsection{Other Baselines}
\label{subsec:otherbaselines}

\begin{table*}[ht]
\centering
\small
\input{tab/other_baselines}
\caption{
EM/F1 of different models and baselines across languages on \ourdataset.
The best results of each model under each language are annotated in \textbf{bold}. 
}
\label{tab:other_baselines}
\end{table*}

% 在本小节，我们展示了直接问答的结果，如表所示
In this subsection, we show the results of directly answering the questions (Direct), solving the question with English CoT (Trans-CoT) and PoT (Trans-PoT) after translating the question and context (including the table and text) to English, as shown in Table~\ref{tab:other_baselines}.
% 我们的方法一致且显著地超越了所有基线方法，证明了我们方法的有效性
\ourmethod consistently and significantly outperforms all baseline methods, demonstrating its effectiveness. 
% 我们还观察到

Additionally, we observe the following:
% 1. 相比直接问答，Native-CoT, Native-PoT和En-CoT, En-PoT的性能整体上提升
(\emph{i})~Compared to direct question answering, the overall performance of Native-CoT, Native-PoT, En-CoT, and En-PoT shows substantial improvement (see Table~\ref{tab:main}).
% 2. Trans-CoT和Trans-PoT的性能不稳定，主要是因为受限于谷歌翻译的质量。一方面，谷歌翻译不能在翻译中很好地保持表格的格式，尤其是在低资源语言，比如孟加拉语、斯瓦希里语，导致了信息损失；另一方面，在使用谷歌翻译回译时，也不能保证回译的token和表格或文字中出现的一致
(\emph{i})~The performance of Trans-CoT and Trans-PoT is unstable, primarily due to limitations in the quality of Google Translation. 
On the one hand, Google Translation struggles to maintain table formatting during translation, especially for low-resource languages such as Bengali and Swahili, leading to information loss \cite{MultiSpider}. 
On the other hand, when utilizing back-translation via Google Translation, token consistency with the original table or text cannot be guaranteed.


\subsection{Answer Sources}
\label{subsec:appendix_answer_source}

\begin{figure*}[t]
    \centering
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \input{fig/answer_source_8b}
    \end{subfigure}
    \hfill % 在两个子图之间添加一些水平空间
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \input{fig/answer_source_4o}
    \end{subfigure}
    \vspace{-1em}
    \caption{
        The left part is the EM of \ourmethod across different answer sources on \ourdataset using Llama3.1-8B.
        The right part is the EM of \ourmethod across different answer sources on \ourdataset using \texttt{gpt-4o}.
    } 
    \label{fig:answer_sources_other_models}
    \vspace{-1em}
\end{figure*}

\begin{figure*}[t]
    \centering
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \input{fig/answer_source_en_CoT}
    \end{subfigure}
    \hfill % 在两个子图之间添加一些水平空间
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \input{fig/answer_source_en_PoT}
    \end{subfigure}
    \vspace{-1em}
    \caption{
        The left part is the EM of En-CoT across different answer sources on \ourdataset using Llama3.1-70B.
        The right part is the EM of En-PoT across different answer sources on \ourdataset using Llama3.1-70B.
    } 
    \label{fig:answer_sources_other_baselines}
    \vspace{-1em}
\end{figure*}

% 在本小节，我们展示了使用不同模型和不同基线在我们数据集的不同答案来源上的性能，如图所示
In this subsection, we present the performance of different models and baselines on various answer sources in our dataset, as illustrated in Figure~\ref{fig:answer_sources_other_models} and Figure~\ref{fig:answer_sources_other_baselines}.
% 从图一观察到：多语言性能更好的模型在不同语言之间的性能差距会缩小，但也无法做到真正消弭
From Figure~\ref{fig:answer_sources_other_models}, it can be observed that multilingual models with better overall performance tend to exhibit smaller performance gaps across different languages. 
However, even \texttt{gpt-4o} still cannot entirely eliminate the discrepancies.
% 从图二观察到：语图1对比，我们的方法在不同答案来源上都提升了性能，尤其在hybrid的答案来源上提升较为显著，因为我们的方法能更好地链接到相关信息，缓解了答案来源异质的挑战
From Figure~\ref{fig:answer_sources_other_baselines}, in comparison with Figure~\ref{fig:answer_source}, \ourmethod demonstrates performance improvements across all answer sources, with a particularly significant enhancement for hybrid answer sources. 
This is attributed to the ability to better establish connections to relevant information of \ourmethod, thereby mitigating the challenges posed by the heterogeneity of answer sources.


\subsection{Answer Types}
\label{subsec:appendix_answer_types}

\begin{figure*}[t]
    \centering
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \input{fig/answer_type_8b}
    \end{subfigure}
    \hfill % 在两个子图之间添加一些水平空间
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \input{fig/answer_type_4o}
    \end{subfigure}
    \vspace{-1em}
    \caption{
        The left part is the EM of \ourmethod across different answer types on \ourdataset using Llama3.1-8B.
        The right part is the EM of \ourmethod across different answer types on \ourdataset using \texttt{gpt-4o}.
    } 
    \label{fig:answer_types_other_models}
    \vspace{-1em}
\end{figure*}

\begin{figure*}[t]
    \centering
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \input{fig/answer_type_en_CoT}
    \end{subfigure}
    \hfill % 在两个子图之间添加一些水平空间
    \begin{subfigure}[b]{0.48\linewidth}
        \centering
        \input{fig/answer_type_en_PoT}
    \end{subfigure}
    \vspace{-1em}
    \caption{
        The left part is the EM of En-CoT across different answer types on \ourdataset using Llama3.1-70B.
        The right part is the EM of En-PoT across different answer types on \ourdataset using Llama3.1-70B.
    } 
    \label{fig:answer_types_other_baselines}
    \vspace{-1em}
\end{figure*}

% 在本小节，我们展示了不同模型和基线在我们数据集的答案类型上的性能，如图所示
In this subsection, we present the performance of different models and baselines across various answer types in \ourdataset, as illustrated in Figure~\ref{fig:answer_types_other_models} and Figure~\ref{fig:answer_types_other_baselines}.
% 从图7可以看出，在不同答案类型上，即使gpt-4o也体现出高资源语言的性能高于低资源语言的性能
As shown in Figure~\ref{fig:answer_types_other_models}, even for \texttt{gpt-4o}, the performance for high-resource languages is consistently superior to that for low-resource languages across different answer types.
% 从图8可以看出，与图5相比，我们的方法一定长度上减小了不同语言之间性能的差距，并且在不同答案类型上都均匀地提升了性能
Figure~\ref{fig:answer_types_other_baselines} demonstrates that, compared to Figure~\ref{fig:answer_type}, \ourmethod reduces the performance gap between languages of varying resource levels to some extent and uniformly improves performance across different answer types.


\subsection{Case Study}
\label{subsec:case study}

\begin{figure*}[t]
    \centering
    \includegraphics[width=.85\linewidth]{fig/case_linking.pdf}
    % \vspace{-0.5em}
    \caption{
    The case for the error type of "Linking".
    }
    \label{fig:case_linking}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=.85\linewidth]{fig/case_formular.pdf}
    % \vspace{-0.5em}
    \caption{
    The case for the error type of "Formula".
    }
    \label{fig:case_formular}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=.85\linewidth]{fig/case_redundancy.pdf}
    % \vspace{-0.5em}
    \caption{
    The case for the error type of "Redundancy".
    }
    \label{fig:case_redundancy}
\end{figure*}

% 在本节，我们展示了4.4节分析的错误类型对应的例子，如图所示
In this subsection, we show the cases of error types corresponding to the analysis in \S\ref{subsec:Error Analysis}, as shown in Figure~\ref{fig:case_linking}, Figure~\ref{fig:case_formular}, and Figure~\ref{fig:case_redundancy}.