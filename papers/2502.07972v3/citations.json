[
  {
    "index": 0,
    "papers": [
      {
        "key": "shazeer2017outrageouslylargeneuralnetworks",
        "author": "Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean",
        "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "hochreiter1997lstm",
        "author": "Hochreiter, Sepp and Schmidhuber, J\u00fcrgen",
        "title": "{Long Short-Term Memory}"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "lepikhin2020gshardscalinggiantmodels",
        "author": "Dmitry Lepikhin and HyoukJoong Lee and Yuanzhong Xu and Dehao Chen and Orhan Firat and Yanping Huang and Maxim Krikun and Noam Shazeer and Zhifeng Chen",
        "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "fedus2022switchtransformersscalingtrillion",
        "author": "William Fedus and Barret Zoph and Noam Shazeer",
        "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zoph2022stmoedesigningstabletransferable",
        "author": "Barret Zoph and Irwan Bello and Sameer Kumar and Nan Du and Yanping Huang and Jeff Dean and Noam Shazeer and William Fedus",
        "title": "ST-MoE: Designing Stable and Transferable Sparse Expert Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "komatsuzaki2023sparseupcyclingtrainingmixtureofexperts",
        "author": "Aran Komatsuzaki and Joan Puigcerver and James Lee-Thorp and Carlos Riquelme Ruiz and Basil Mustafa and Joshua Ainslie and Yi Tay and Mostafa Dehghani and Neil Houlsby",
        "title": "Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "gale2022megablocksefficientsparsetraining",
        "author": "Trevor Gale and Deepak Narayanan and Cliff Young and Matei Zaharia",
        "title": "MegaBlocks: Efficient Sparse Training with Mixture-of-Experts"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "hallee2024contrastivelearningmixtureexperts",
        "author": "Logan Hallee and Rohan Kapur and Arjun Patel and Jason P. Gleghorn and Bohdan Khomtchouk",
        "title": "Contrastive Learning and Mixture of Experts Enables Precise Vector Embeddings"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "li2024mixtureofexpertsllmsecretlyembedding",
        "author": "Ziyue Li and Tianyi Zhou",
        "title": "Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "muennighoff2024generativerepresentationalinstructiontuning",
        "author": "Niklas Muennighoff and Hongjin Su and Liang Wang and Nan Yang and Furu Wei and Tao Yu and Amanpreet Singh and Douwe Kiela",
        "title": "Generative Representational Instruction Tuning"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "wang2022text",
        "author": "Liang Wang and Nan Yang and Xiaolong Huang and Binxing Jiao and Linjun Yang and Daxin Jiang and Rangan Majumder and Furu Wei",
        "title": "Text Embeddings by Weakly-Supervised Contrastive Pre-training"
      },
      {
        "key": "li2023general",
        "author": "Zehan Li and Xin Zhang and Yanzhao Zhang and Dingkun Long and Pengjun Xie and Meishan Zhang",
        "title": "Towards General Text Embeddings with Multi-stage Contrastive Learning"
      },
      {
        "key": "g\u00fcnther2023jina",
        "author": "Michael G\u00fcnther and Louis Milliken and Jonathan Geuter and Georgios Mastrapas and Bo Wang and Han Xiao",
        "title": "Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models"
      },
      {
        "key": "nussbaum2024nomicembedtrainingreproducible",
        "author": "Zach Nussbaum and John X. Morris and Brandon Duderstadt and Andriy Mulyar",
        "title": "Nomic Embed: Training a Reproducible Long Context Text Embedder"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "xiao2023cpack",
        "author": "Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff",
        "title": "C-Pack: Packaged Resources To Advance General Chinese Embedding"
      },
      {
        "key": "wang2022text",
        "author": "Liang Wang and Nan Yang and Xiaolong Huang and Binxing Jiao and Linjun Yang and Daxin Jiang and Rangan Majumder and Furu Wei",
        "title": "Text Embeddings by Weakly-Supervised Contrastive Pre-training"
      },
      {
        "key": "li2023general",
        "author": "Zehan Li and Xin Zhang and Yanzhao Zhang and Dingkun Long and Pengjun Xie and Meishan Zhang",
        "title": "Towards General Text Embeddings with Multi-stage Contrastive Learning"
      },
      {
        "key": "g\u00fcnther2023jina",
        "author": "Michael G\u00fcnther and Louis Milliken and Jonathan Geuter and Georgios Mastrapas and Bo Wang and Han Xiao",
        "title": "Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models"
      },
      {
        "key": "nussbaum2024nomicembedtrainingreproducible",
        "author": "Zach Nussbaum and John X. Morris and Brandon Duderstadt and Andriy Mulyar",
        "title": "Nomic Embed: Training a Reproducible Long Context Text Embedder"
      },
      {
        "key": "merrick2024arcticembedscalableefficientaccurate",
        "author": "Luke Merrick and Danmei Xu and Gaurav Nuti and Daniel Campos",
        "title": "Arctic-Embed: Scalable, Efficient, and Accurate Text Embedding Models"
      },
      {
        "key": "yu2024arcticembed20multilingualretrieval",
        "author": "Puxuan Yu and Luke Merrick and Gaurav Nuti and Daniel Campos",
        "title": "Arctic-Embed 2.0: Multilingual Retrieval Without Compromise"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "wang2023improving",
        "author": "Liang Wang and Nan Yang and Xiaolong Huang and Linjun Yang and Rangan Majumder and Furu Wei",
        "title": "Improving Text Embeddings with Large Language Models"
      },
      {
        "key": "lee2024nvembedimprovedtechniquestraining",
        "author": "Chankyu Lee and Rajarshi Roy and Mengyao Xu and Jonathan Raiman and Mohammad Shoeybi and Bryan Catanzaro and Wei Ping",
        "title": "NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "devlin2019bert",
        "author": "Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova",
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "conneau2020unsupervisedcrosslingualrepresentationlearning",
        "author": "Alexis Conneau and Kartikay Khandelwal and Naman Goyal and Vishrav Chaudhary and Guillaume Wenzek and Francisco Guzm\u00e1n and Edouard Grave and Myle Ott and Luke Zettlemoyer and Veselin Stoyanov",
        "title": "Unsupervised Cross-lingual Representation Learning at Scale"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "reimers2020makingmonolingualsentenceembeddings",
        "author": "Nils Reimers and Iryna Gurevych",
        "title": "Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "wang2024multilinguale5textembeddings",
        "author": "Liang Wang and Nan Yang and Xiaolong Huang and Linjun Yang and Rangan Majumder and Furu Wei",
        "title": "Multilingual E5 Text Embeddings: A Technical Report"
      },
      {
        "key": "chen2024bgem3embeddingmultilingualmultifunctionality",
        "author": "Jianlv Chen and Shitao Xiao and Peitian Zhang and Kun Luo and Defu Lian and Zheng Liu",
        "title": "BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "yu2024arcticembed20multilingualretrieval",
        "author": "Puxuan Yu and Luke Merrick and Gaurav Nuti and Daniel Campos",
        "title": "Arctic-Embed 2.0: Multilingual Retrieval Without Compromise"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "hinton2015distillingknowledgeneuralnetwork",
        "author": "Geoffrey Hinton and Oriol Vinyals and Jeff Dean",
        "title": "Distilling the Knowledge in a Neural Network"
      },
      {
        "key": "sanh2020distilbertdistilledversionbert",
        "author": "Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf",
        "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "zhang2024jasperstelladistillationsota",
        "author": "Unknown",
        "title": "Unknown"
      },
      {
        "key": "lee2024geckoversatiletextembeddings",
        "author": "Jinhyuk Lee and Zhuyun Dai and Xiaoqi Ren and Blair Chen and Daniel Cer and Jeremy R. Cole and Kai Hui and Michael Boratko and Rajvi Kapadia and Wen Ding and Yi Luan and Sai Meher Karthik Duddu and Gustavo Hernandez Abrego and Weiqiang Shi and Nithi Gupta and Aditya Kusupati and Prateek Jain and Siddhartha Reddy Jonnalagadda and Ming-Wei Chang and Iftekhar Naim",
        "title": "Gecko: Versatile Text Embeddings Distilled from Large Language Models"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "Salinas2022KnowledgeDF",
        "author": "Andres Felipe Cruz Salinas and Ken'ichi Kumatani and Robert Gmyr and Linquan Liu and Yu Shi",
        "title": "Knowledge Distillation for Mixture of Experts Models in Speech Recognition"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "fedus2022switchtransformersscalingtrillion",
        "author": "William Fedus and Barret Zoph and Noam Shazeer",
        "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"
      }
    ]
  }
]