\begin{table} [t]
\centering
\resizebox{\linewidth}{!} {
\begin{tabular}{l|c|c|c|c}
\toprule
\multirow{2}{*}{\textbf{Method}}  & \textbf{AUTO-J}   & \multirow{2}{*}{\textbf{LLMBar}}  & \multirow{2}{*}{\textbf{MT-Bench}} & \multirow{2}{*}{\textbf{Avg.}} \\
 & \textbf{(Eval-P)} & & & \\
\midrule
 MT-Bench  & 0.792 & 0.619 & 0.765 &  0.725 \\
 Metrics+Reference*  & 0.800 & 0.724 & 0.778 & 0.767\\
\cmidrule{1-5}
APE & 0.799\scriptnumber{0.005} & 0.670\scriptnumber{0.032} & 0.774\scriptnumber{0.008} & 0.748 \\
OPRO & \textbf{0.847}\scriptnumber{0.000} & 0.695\scriptnumber{0.000} & \textbf{0.791}\scriptnumber{0.005} & 0.778 \\
Greedy & 0.820\scriptnumber{0.019} &  0.774\scriptnumber{0.005} & 0.775\scriptnumber{0.013} & 0.790 \\
Stepwise-Greedy  & \textbf{0.847}\scriptnumber{0.000} & 0.743\scriptnumber{0.000} & 0.784\scriptnumber{0.000} & 0.791 \\
HPSS (Ours) & \textbf{0.847}\scriptnumber{0.000} & \textbf{0.778}\scriptnumber{0.005} & 0.789\scriptnumber{0.015} & \textbf{0.805} \\
\bottomrule
\end{tabular}
}
\vspace{-2mm}
\caption{Accuracy of different prompting methods based on Qwen-2.5-14B-Instruct on pairwise comparison datasets including AUTO-J (Eval-P), LLMBar, and MT-Bench.}
\label{tab:pairwise_results}
\vspace{-4mm}
\end{table}