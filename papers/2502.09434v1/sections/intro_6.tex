\section{Introduction}
\IEEEPARstart{R}{ecent} advancements in diffusion models have significantly transformed the landscape of image generation~\cite{croitoru2023diffusion,zhan2023multimodal,zhu2024vision+}. Modern diffusion models, such as Stable Diffusion~\cite{rombach2022high}, Midjourney~\cite{midjourney2022}, and SORA~\cite{sora2024}, can generate realistic images that are hard for humans to distinguish, demonstrating the unparalleled capabilities in producing diverse images. However, recent works~\cite{carlini2023extracting,somepalli2024understanding,wen2023detecting} suggested that diffusion models can memorize images from the training set and reproduce them directly. \gxlnote{This raises privacy concerns, as sensitive information, such as identifiable faces or private documents, may be generated and inadvertently exposed.} To address the critical issue, some works~\cite{zhang2023forget,ni2023degeneration,gandikota2024unified,kumari2023ablating} proposed to make diffusion models ``forget'' specific concepts such as a portrait of a certain celebrity, or the style of a particular artist. However, these works can only blacklist specific content that users want to conceal, but cannot completely cover the privacy-sensitive information that the model might remember, still posing a risk of privacy leakage.

\begin{figure}[tb]
  \centering
  \setlength{\abovecaptionskip}{7pt} % 设置标题上方的间距为 -5pt
  \setlength{\belowcaptionskip}{-7pt} % 设置标题下方的间距为 -5pt
  \includegraphics[width=1.0\linewidth]{imgs/problem.pdf}
  \caption{\gxlnote{Prior methods focus solely on the captions associated with the memorized images, such as caption augmentation. In contrast, our approach takes a more generalizable framework by considering aspects from the visual modality.}}
  \label{fig:problem}
\end{figure}
 
Recently, some works~\cite{somepalli2023diffusion,daras2024ambient,somepalli2024understanding,wen2023detecting} have proposed to mitigate diffusion memorization without specific content limitations, thus reducing the risk of diffusion models leaking privacy-sensitive training data. Most of them focused on tackling the training data memorization in text-to-image diffusion models, and proposed data augmentation for captions/sentences to reduce model memorization.  For instance, Somepalli \MakeLowercase{\textit{et al.}}~\cite{somepalli2024understanding} found that the insufficient diversity in captions easily leads to training data generation and thus utilized random caption replacement, random token replacement, and caption word repetition, \MakeLowercase{\textit{etc.}}, to reduce memorization. 
Based on the discovery that memorized prompts tend to exhibit larger magnitudes, which refers to the difference between the text-conditioned and unconditioned noise prediction, Wen \MakeLowercase{\textit{et al.}}~\cite{wen2023detecting} introduced methods for mitigating memorization through filtering high-magnitude sample during training and minimizing magnitudes during inference. Although these works have made significant progress in understanding the memorization issue in diffusion models, \gxlnote{they only focused on easily memorable images related to specific captions in cross-modal generation tasks as shown in ~\cref{fig:problem}. 
However, they do not directly tackle the memorization problem in image generation. While manipulating captions may reduce the likelihood of memorization being triggered in text-to-image models, the model’s inherent ability to memorize images remains. Memorization can still occur under different conditions~\cite{carlini2023extracting,somepalli2024understanding}.
Therefore, we propose a novel framework for diffusion models from the perspective of the visual modality, which not only mitigates memorization more fundamentally but also provides a more generic approach.}



Following these insights,  in our preliminary ECCV 2024 version~\cite{liu2024iterative}, we propose the first module: \textbf{Iterative Ensemble Training (IET)} framework from the perspective of parameter aggregation as shown in ~\cref{fig:problem}. Transmitting data directly to the model increases the likelihood of memorizing easy samples. \gxlnote{However, if the model learns from parameters of other models, rather than directly from the data, it may help to mitigate the direct memorization}. Specifically, we divide the data into multiple data shards and train several proxy models. These models are then aggregated to form the final model. Inspired by federated learning~\cite{mcmahan2017communication}, we iteratively ensemble the proxy models during training, which helps reduce memorization through multiple aggregations and preserves the generation performance. 
Besides, we suspect that images with varying degrees of memorization might exhibit different behaviors during the training process. Therefore, we analyze the training process and find that the loss of easily memorable images tends to be obviously lower than that of less memorable images. Based on this analysis, we propose the second module: \textbf{Anti-Gradient Control (AGC)} to further reduce memorization of training data. In particular, we skip the samples with abnormally small loss values from the current mini-batch to avoid memorizing these samples. During training, as the diffusion model exhibits varying average loss values across different time steps, we maintain a memory bank to track the average loss at each step. Building on this, we skip samples whose loss ratio—defined as the ratio of the sample's loss to the average loss—falls below a predefined skipping threshold as shown in ~\cref{fig:AGC+_s}.



\gxlnote{
However, the AGC strategy might excessively skip highly memorizable samples, leading to a reduction in available training data and potential degradation of image quality.
This drives us to pursue a better approach that strikes a balance between mitigating memorization and maintaining image quality.
Following these insights, in this paper, we introduce IET-AGC+ building on our ECCV2024 framework~\cite{liu2024iterative}.}
\gxlnote{To address the issue of excessively skipping, we propose a \textbf{Memory Samples Redistribute (MSR)} strategy to ensure that these samples are learned but not easily memorized. In the IET framework, each proxy model learns from its shard, where the same data may be interpreted differently.
\emph{In particular, when a sample is frequently memorized in its original shard, it may not have the same memorization tendency in a new shard}. As the saying goes: One man's meat is another man's poison. This inspires us to exchange easily memorized samples from one shard with another to prevent them from being skipped too frequently as shown in ~\cref{fig:problem}.  Therefore, in the training process, we track the number of times each sample is skipped to identify whether it is most easily memorized. During the interaction, each shard allocates its most frequently skipped samples to the next shard in a circular manner.}


\begin{figure}[tb]
  \centering
  \setlength{\abovecaptionskip}{7pt} % 设置标题上方的间距为 -5pt
  \setlength{\belowcaptionskip}{-10pt} % 设置标题下方的间距为 -5pt
  \includegraphics[width=1.0\linewidth]{imgs/simple_AGC+.pdf}
  \caption{\gxlnote{Threshold-Aware Augmentation (TAA) collaborated with Anti-Gradient Control. We apply three different treatments based on the comparison between the sample's loss ratio and the skipping threshold. }}
  \label{fig:AGC+_s}
\end{figure}
% \vspace{-0.5em}
\gxlnote{
On the other hand, in AGC, images below the threshold are more likely to be memorized, making their exclusion a reasonable choice. However, memorization varies in degree and cannot be simply addressed with a hard threshold. Samples should be dynamically processed based on their level of memorization risk. To address this, we propose a new strategy called \textbf{Threshold-Aware Augmentation (TAA)} collaborated with Anti-Gradient Control as shown in ~\cref{fig:AGC+_s}. For samples that are not skipped but whose loss values are close to the threshold, we apply augmentation to increase their diversity, thereby reducing memorization. 
A lower loss value indicates a higher risk of memorization, so we use dynamic visual augmentation based on sample distance from the threshold. Samples closer to the threshold receive stronger augmentation.}

Extensive experiments on four datasets highlight the importance of our framework. 
Our method significantly reduces the memorized quantity by \gxlnote{90.1\%, 74.6\%, and 91.2\% }compared with the default training (DDPM~\cite{ho2020denoising}) on CIFAR-10~\cite{krizhevsky2009learning} and CIFAR-100~\cite{krizhevsky2009learning} and AFHQ-DOG~\cite{choi2020stargan}, respectively. Furthermore, when fine-tuning the text-conditional diffusion model, Stable Diffusion~\cite{rombach2022high}, our approach decreases the memorization score by \gxlnote{46.7\%} compared to conventional fine-tuning method~\cite{rombach2022high}. In addition, our method can also be applied to existing inference phase mitigation mechanisms~\cite{somepalli2024understanding,wen2023detecting}, further reducing memorization and improving image quality. These results demonstrate the effectiveness of our method.

\gxlnote{Our main contributions are summarized as follows:
\begin{itemize}
\item {
We introduce a generalized method to mitigate memorization from the perspective of the visual modality, which consists of two main parts: leveraging multiple model ensembles for training and skipping easily memorized samples based on the training loss.
}
\item{
We propose Memory Samples Redistribute (MSR), which redistributes easily memorized samples across shards in the above framework while maintaining a balance between memorization reduction and image quality.
}
\item{
We suggest Threshold-Aware Augmentation (TAA), a strategy that adapts the level of augmentation based on the distance between the sample's loss and the skipping threshold, effectively addressing the risk of overlooking memorized samples.
}
\end{itemize}}



