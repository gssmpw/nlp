\documentclass[lettersize,journal]{IEEEtran}
\input{preamble}%before hyperref
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage[ruled,linesnumbered]{algorithm2e}
% \usepackage{algorithm2e}

% \usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{utfsym}

\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\usepackage{balance}
%%%%% new package

\usepackage{times}
\usepackage{fancyhdr,graphicx,amsmath,amssymb}

% \usepackage[ruled,vlined]{algorithm2e}

\usepackage{multirow, bigstrut} 
% \usepackage{arydshln}

\usepackage{url}
\usepackage{graphicx}
\usepackage{booktabs} 
% \usepackage[inkscapelatex=false]{svg}
% \svgpath{{images/}}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage[capitalize]{cleveref}
\definecolor{deepgreen}{rgb}{0.0, 0.5, 0.0}
\newcommand{\pyh}[1]{\textcolor{deepgreen}{#1}}
\newcommand{\wry}[1]{\textcolor{orange}{\@#1}}
\newcommand{\pyhshan}[1]{\textcolor{red}{#1}}
\newcommand{\darkedred}[1]{\textcolor{red!80!black}{#1}}
\newcommand{\gxlnote}[1]{\textcolor{black}{#1}}
\newcommand{\crnote}[1]{\textcolor{black}{#1}}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
% \newcommand{\pyh}[1]{\textcolor{black}{#1}}
% \newcommand{\wry}[1]{\textcolor{black}{\@#1}}
% \newcommand{\pyhshan}[1]{\textcolor{black}{#1}}



\begin{document}
\include{pythonlisting}
% \title{A Sample Article Using IEEEtran.cls\\ for IEEE Journals and Transactions}
% \bibliographystyle{IEEEtran}


\title{Redistribute Ensemble Training for Mitigating Memorization in Diffusion Models}



% \author{IEEE Publication Technology,~\IEEEmembership{Staff,~IEEE,}

\author{Xiaoliu Guan, Yu Wu, Huayang Huang, Xiao Liu, Jiaxu Miao, Yi Yang
% <-this % stops a space
\thanks{X. Guan,  Y. Wu, H. Huang, and  X. Liu are with the School of Computer Science, Wuhan University, China. E-mail: liuxiaoguan, wuyucs, hyhuang, xiaoliu@whu.edu.cn}% <-this % stops a space
\thanks{J. Miao is with the School of Cyber Science and Technology, Sun Yat-sen University, China. E-mail: miaojx@mail.sysu.edu.cn }
\thanks{Y. Yang is with the College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China. E-mail: yangyics@zju.edu.cn}
\thanks{(Corresponding author: Yu Wu.)}}

\maketitle


\input{sections/abstract_2}

\input{sections/intro_6}

\input{sections/related_work_0}

\input{sections/method_2}


\input{sections/experiment}




\section{Conclusion}
\gxlnote{This paper presents a novel and effective training method aimed at mitigating the memorization problem in diffusion models. By analyzing the relationship between training loss and memorization, we apply different treatments to samples based on their degree of memorization, minimizing the risk of memorization. Additionally, considering that model directly learning from data can increase the likelihood of memorization and the same data may have
different interpretations on different shards, we employ several data shards to train multiple proxy diffusion models. Through multiple proxy diffusion models aggregation and redistribution of easily memorable samples cross shards, we obtain the final model, achieving a balance between mitigating memorization and maintaining image quality. We experimentally show that our method performs favorably with many existing related methods in different scenarios and datasets.}
We firmly believe that this training strategy has a broad application prospect and great development potential in the field of data privacy protection.


\bibliographystyle{IEEEtran}

\bibliography{arxiv}

\input{sections/author_page}
\clearpage
\newpage
% \input{sections/supp_1}

\end{document}