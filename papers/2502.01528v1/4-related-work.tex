\section{Related Work}
\label{s:4-squash-related-work}

Solutions for vector similarity search (nearest-neighbor search (NNS) / approximate nearest neighbor search (ANNS)) fall into categories including hashing \cite{db-lsh-hashing-2, AndoniOptimal-Hashing-3, ANN-Hashing-5, IntelligentProbingLv-Hashing-8, ParkNeighbor-Hashing-9, PM-LSH-Hashing-11}, trees \cite{HouleRankBasedTree, LuVHPHypersphere, Muja2014ScalableNN, SilpaAnan2008OptimizedKDTree}, quantization \cite{ferhatosmanoglu2001approximate, TuncelFerhatosmanoglu2002VQIndex, Ferhatosmanoglu2006VAPlusApprox, Jegou2011PQ, OptimizedProductQuantization, Wang2020DeltaPQ, VarianceAwareQuantization, Aguerrebere2023, aguerrebere2024locallyadaptivequantizationstreamingvector, PQCacheLocality2015, RabitQ2024} and proximity graphs (PG) \cite{FuFastApproximate, Gollapudi2023FilteredDiskANN, NEURIPS2019-DISKANN, Jaiswal2022OODDiskANN, MALKOV201461, Malkov2020HNSW, singh2021freshdiskannfastaccurategraphbased, Zhao2020SONGGPU}, with a multitude of variations/combinations of these themes. 
Scalar quantization methods generate highly compressed and parallelizable representations with lower reproduction errors \cite{douze2024faisslibraryivfsq8}. 
Approaches based on scalar and vector quantization, such as the VA$^+$-file \cite{Ferhatosmanoglu2000VAPlus}, VQ-Index \cite{TuncelFerhatosmanoglu2002VQIndex}, and Product Quantization (PQ) \cite{Jegou2011PQ} are standalone solutions, and are also applied to compress the vectors within coarse index structures such as IVF \cite{TuncelFerhatosmanoglu2002VQIndex, douze2024faisslibraryivfsq8} and proximity graph (PG)-based approaches, such as HNSW \cite{Malkov2020HNSW, FaissMissingManual} and DiskANN \cite{NEURIPS2019-DISKANN}.


\textit{Attributed} vector similarity search based on non-PG solutions has primarily been addressed through two methods: pre-filtering and post-filtering. 
Pre-filtering, used by systems such as AnalyticDB-V \cite{Wei2020AnalyticDBV} and Milvus \cite{Wang2021Milvus}, first searches a separately maintained attribute index using a query predicate supplied with the query feature vector; the filtered candidate list is then used to reduce the scope of the vector similarity search. 
Post-filtering, seen in approaches such as VBASE \cite{Zhang2023VBASE}, first performs the vector similarity search and then prunes the results using the attribute index. 
In some solutions the post-filtering is done alongside the vector search phase, via the inclusion of attribute data in the vector index. 

As PG-based ANNS solutions have performed well in terms of recall and throughput in the \textit{unfiltered} version of the problem, these have been extended for \textit{filtered} ANNS solutions \cite{NEURIPS2023-Wang-NHQ, wang2022navigableproximitygraphdrivennative-NHQ-2, Patel2024ACORN, zhao2022constrainedapproximatesimilaritysearchAIRSHIP, Gollapudi2023FilteredDiskANN}. 
For example, ACORN \cite{Patel2024ACORN} presents a `predicate-agnostic' indexing approach. 
However, the `decomposition-assembly model' \cite{NEURIPS2023-Wang-NHQ} whereby hybrid queries are split into two problems, addressed by different indexing solutions, is difficult to apply to PGs. 
Uncorrelated attribute/vector data may lead to incorrect graph traversal paths; assumptions about query predicates and selectivity may be required; multiple sub-graphs may need to be built to cater for different attributes or assumed filter predicates. 
As a result, filtered PG-based approaches often restrict predicates to only include a single attribute, or only support low-cardinality `tag'-based attributes, with only equality operators catered for. In contrast, SQUASH caters for unrestricted numbers/types of attributes and predicates. 

Bitwise distance comparisons based on the low-bit OSQ index in SQUASH are used to avoid expensive Euclidean query-to-vector distance calculations;
the use of Hamming distances on binary-quantized data enables rapid pruning without compromising accuracy, particularly in constrained environments \cite{MARUKATAT20131101, Martin2015}. Recent work has shown that randomized bit string-based quantization schemes can be effective \cite{RabitQ2024}; further work could apply these techniques in the context of filtered, distributed and serverless search. Another complementary direction is to adapt optimizations in data warehouses and data lakes, such as mechanisms for fine-grained data skipping based on query patterns \cite{2014SunDataSkipping}.
 
While cloud providers offer various server configurations (e.g., CPU, GPU, HPC), these solutions lack dynamic scaling to meet fluctuating demand. Serverless FaaS has been applied to data-intensive tasks such as TPC-H queries \cite{Muller2020Lambada, Perron2020} and ML inference \cite{Oakley2024FSDInference, Gillis2021, Jarachanthan2021AMPS, Oakley2024ForesightPlus}. Several commercial serverless ANNS solutions have been developed \cite{Weaviate, DatastaxAstraDB,Pinecone-Serverless, TurboPuffer, Upstash}.
The only FaaS-based system for vector similarity search, Vexless \cite{Su2024Vexless}, lacks attribute filtering support. 
It utilizes stateful cloud functions to alleviate communication requests, employs HNSW as the indexing solution (making it challenging to extend Vexless to support rich hybrid search functionality), and introduces a workload generator to model large-scale vector search workloads; Vexless then uses these workloads to perform result caching, but its performance is unclear without this advantage.
In contrast, SQUASH leverages synchronous FaaS invocation to achieve communication at high parallelism levels, and offers rich hybrid search support.
% , and does not rely on caching to achieve high levels of throughput.
