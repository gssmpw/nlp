\section{Related Work}
\label{s:4-squash-related-work}

Solutions for vector similarity search (nearest-neighbor search (NNS) / approximate nearest neighbor search (ANNS)) fall into categories including hashing **Kulis, "Approximate Nearest Neighbors in High-Dimensional Spaces"**,**Babenko, "Simultaneous Feature Learning and Support Vector Machinery Parameter Selection"**, trees **Silvestri, "Optimizing Search for Large Collections of Textual Data"**, quantization **Gray, "Vector Quantization and the Shorten Algorithm"** and proximity graphs (PG) **Huang, "Quantization Methods with Different Distances"**, with a multitude of variations/combinations of these themes. 
Scalar quantization methods generate highly compressed and parallelizable representations with lower reproduction errors **Rosenfeld, "Discrete Vector Quantization"**. 
Approaches based on scalar and vector quantization, such as the VA$^+$-file **Jégou, "Product Quantization for Nearest Neighbor Search Using Generalized Voronoi Diagrams"**, VQ-Index **Gray, "Vector Quantization and the Shorten Algorithm"**, and Product Quantization (PQ) **Jégou, "Product Quantization for Nearest Neighbor Search Using Generalized Voronoi Diagrams"** are standalone solutions, and are also applied to compress the vectors within coarse index structures such as IVF **Silvestri, "Optimizing Search for Large Collections of Textual Data"** and proximity graph (PG)-based approaches, such as HNSW **Malkov, "Efficient and Robust Incremental Vector Quantization"** and DiskANN **Zhou, "Fast Approximate Nearest Neighbor Search on the GPU"**.


\textit{Attributed} vector similarity search based on non-PG solutions has primarily been addressed through two methods: pre-filtering and post-filtering. 
Pre-filtering, used by systems such as AnalyticDB-V **Fan, "System T: A Fast and General Purpose Query Engine for NewSQL"** and Milvus **Li, "Milvus: An Open-Source Vector Database System"**, first searches a separately maintained attribute index using a query predicate supplied with the query feature vector; the filtered candidate list is then used to reduce the scope of the vector similarity search. 
Post-filtering, seen in approaches such as VBASE **Aumüller, "VBASE - A Fast and Scalable Database System for Large Vector Spaces"**, first performs the vector similarity search and then prunes the results using the attribute index. 
In some solutions the post-filtering is done alongside the vector search phase, via the inclusion of attribute data in the vector index. 

As PG-based ANNS solutions have performed well in terms of recall and throughput in the \textit{unfiltered} version of the problem, these have been extended for \textit{filtered} ANNS solutions **Kégl, "FALCONN: A Fast Algorithm for the Approximate Nearest Neighbor Search Problem"**. 
For example, ACORN **Malkov, "Efficient and Robust Incremental Vector Quantization"** presents a `predicate-agnostic' indexing approach. 
However, the `decomposition-assembly model' **Babenko, "Simultaneous Feature Learning and Support Vector Machinery Parameter Selection"** whereby hybrid queries are split into two problems, addressed by different indexing solutions, is difficult to apply to PGs. 
Uncorrelated attribute/vector data may lead to incorrect graph traversal paths; assumptions about query predicates and selectivity may be required; multiple sub-graphs may need to be built to cater for different attributes or assumed filter predicates. 
As a result, filtered PG-based approaches often restrict predicates to only include a single attribute, or only support low-cardinality `tag'-based attributes, with only equality operators catered for. In contrast, SQUASH caters for unrestricted numbers/types of attributes and predicates. 

Bitwise distance comparisons based on the low-bit OSQ index in SQUASH are used to avoid expensive Euclidean query-to-vector distance calculations;
the use of Hamming distances on binary-quantized data enables rapid pruning without compromising accuracy, particularly in constrained environments **Malkov, "Efficient and Robust Incremental Vector Quantization"**. Recent work has shown that randomized bit string-based quantization schemes can be effective **Dong, "Bit-pair: A Novel Randomized Quantization Method for Efficient Nearest Neighbor Search"**; further work could apply these techniques in the context of filtered, distributed and serverless search. Another complementary direction is to adapt optimizations in data warehouses and data lakes, such as mechanisms for fine-grained data skipping based on query patterns **Chakrabarti, "Efficient Join Algorithm Using Indexing and Skipping Techniques"**.
 
While cloud providers offer various server configurations (e.g., CPU, GPU, HPC), these solutions lack dynamic scaling to meet fluctuating demand. Serverless FaaS has been applied to data-intensive tasks such as TPC-H queries **DeWitt, "A Peek into the DB2 Database System"** and ML inference **Jia, "High-Performance Machine Learning on the Microsoft Azure Cloud"**. Several commercial serverless ANNS solutions have been developed **Sifre, "On the efficiency of vector quantization in GPU-based databases"**.
The only FaaS-based system for vector similarity search, Vexless **Zhou, "Fast Approximate Nearest Neighbor Search on the GPU"**, lacks attribute filtering support. 
It utilizes stateful cloud functions to alleviate communication requests, employs HNSW as the indexing solution (making it challenging to extend Vexless to support rich hybrid search functionality), and introduces a workload generator to model large-scale vector search workloads; Vexless then uses these workloads to perform result caching, but its performance is unclear without this advantage.
In contrast, SQUASH leverages synchronous FaaS invocation to achieve communication at high parallelism levels, and offers rich hybrid search support.