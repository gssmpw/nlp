We introduced DUNIA, a novel framework for Earth Observation applications that learns dense representations through mono-modal and cross-modal alignment. This strategy enables our model to perform mono-modal and cross-modal retrieval tasks on several datasets with very high precision. It also allows novel capabilities like retrieving or generating highly complex outputs from pixel inputs. To the best of our knowledge, this is the only model capable of generating GEDI waveforms at this scale. 

Our main contributions lie in several design choices at the decoding stage. The proposed pre-trained model encoder is flexible and can be adapted to components from other existing approaches; for instance, modules that support multi-temporal input, or handle images with varying resolutions. Nonetheless, in this work we focused on input data - Sentinel- 1 \&2, alongside GEDI - that are freely accessible globally to promote easier adoption.   

One of the main limitations of this work is also coincidentally the reliance on static inputs from Sentinel- 1\& 2 data, which has limitations for datasets requiring multi-temporal images, such as crop type mapping. However, our design choices prioritize mono-temporal data to reduce storage requirements and enable applications in areas where time series data are not readily available. Another limitation, common to all EO models, is that the current pre-trained model is tailored to the area and year on which it was trained on; we expect that it will require pre-training when used elsewhere. Nonetheless, the model was designed to not be computationally expensive and can be performed with limited computational resources.