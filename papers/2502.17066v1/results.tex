\subsubsection{Zero-Shot Classification Performance}

\begin{table*}[t]
\caption{Top-1 retrieval-based zero-shot classification performance of DUNIA for different retrieval settings. SOTA results, when available, represent the best-performing supervised model for any given dataset. M1 are from Schwartz et al. (\citeyear{schwartz2023forms}), M1\textsuperscript{\textdagger} are retrained models from M1 for that particular dataset. M2 comes from Garnot \& Landrieu (\citeyear{garnot2021pastis}). M3 comes from the model trained with very high-resolution aerial imagery developed in Gaydon \& Roche (\citeyear{gaydon2024pureforest}). \colorbox{cgreen!50}{\textcolor{cgreen!50}{---}} and \colorbox{cblue!50}{\textcolor{cblue!50}{---}} are DUNIA query embeddings from $\mathcal{O^V}$ and $\mathcal{O^H}$ respectively. S represents the number of samples in the retrieval database, with \textit{im} meaning a $64\times64$ pixels fully annotated image, and \textit{l} meaning a single annotated pixel. KNN represents the K nearest neighbors used in the distance-weighted voting. $\text{KNN}_b$ represents the best KNN value for a given dataset. $\mathcal{W}^{**}$ represents performance results for vertical structures higher than 5 m. Best results for each metric are highlighted in \textbf{bold}.}
\label{table:retrieval_performance}
\begin{center}
\begin{small}
\begin{sc}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccc}
\toprule
\multirow[t]{2}{*}{Dataset} & \multirow[t]{2}{*}{Metric} & \multirow[t]{2}{*}{SOTA} & \multirow[t]{2}{*}{S} & \multicolumn{5}{c}{DUNIA}                                  \\
\cmidrule(lr){1-1} \cmidrule(lr){2-2} \cmidrule(lr){3-3} \cmidrule(lr){4-4} \cmidrule(lr){5-9}                       
                         &            &     &       & KNN = 50 & KNN = 5 & KNN =1 & 10\%S, $\text{KNN}_b$ & 5\%S, $\text{KNN}_b$  \\
\midrule                         
\cellcolor{cgreen!50}$\mathcal{W}_{rh}$                 &$rmse$ $(r)$            & \multicolumn{1}{l}{[M1]} 5.2 (.77)        & 50K \textit{l} $^*$    &\textbf{2.0} (.93)        &2.1 (.93)        &2.1 (.91) &2.1 (.92) &2.1 (.92)   \\
\cellcolor{cgreen!50}$\mathcal{W}_c$                    &$rmse$ $(r)$            &  \multicolumn{1}{l}{[M1]\textsuperscript{\textdagger}} 22.1 (.54)        &50K \textit{l}      &\textbf{11.7} (.89)       &12.1 (.84)        &12.3 (.86) &12.4 (.86) &12.0 (.84)     \\
\cellcolor{cgreen!50}$\mathcal{W}_{pai}$                &$rmse$ $(r)$            &  \multicolumn{1}{l}{[M1]\textsuperscript{\textdagger}}  1.5 (.35)       &50K \textit{l}      & \textbf{0.71} (.75)      &0.74 (.73)        &0.74 (.72) &0.72 (.75) &0.72 (.74)    \\
\cellcolor{cblue!50}$CLC_+$                  &$wF1$            &  ---        &500 \textit{im}      &\textbf{80.1\%}        &74.3\% &69.5\% &75.2\% &70.2\%   \\
\cellcolor{cblue!50}$PASTIS$                 &$OA$             & \multicolumn{1}{l}{[M2]} \textbf{84.2\%}          &500 \textit{im}      &56.2\%        &54.1\%  &49.5\% &52.4\% &48.3\%   \\
\cellcolor{cblue!50}$PF$                     &$wF1$            & \multicolumn{1}{l}{[M3]} 74.6\%          &50K \textit {l}      &73.8\%        &\textbf{76.0\% }       &75.8\% &73.5\% & 70.9\%     \\
\cellcolor{cgreen!50}$\mathcal{W}^{**}$            &$r$           & ---          &50K \textit{l}      & ---       &---        &\textbf{.70}  &.67 &.66   \\
\bottomrule
\end{tabular}%
}
\end{sc}
\end{small}
\end{center}
\vspace{-1em}
{\scriptsize $^*$  This number of samples is considered as a low data regime due to: 1) a total coverage area of $\approx31Km^2$ 2) only $\approx0.25\%$ of data required compared to supervised models.}  
\vskip-0.1cm
\end{table*} 

\begin{table*}[t]

\caption{Finetuning performance of DUNIA and the two competing models (i.e., AnySat \cite{astruc2024anysat}, and CROMA \cite{fuller2023croma}). \colorbox{cgreen!50}{\textcolor{cgreen!50}{---}} and \colorbox{cblue!50}{\textcolor{cblue!50}{---}} are DUNIA's embeddings from $\mathcal{O^V}$ and $\mathcal{O^H}$ respectively. S represents the number of samples used for the finetuning, with \textit{im} meaning a $64\times64$ pixels fully annotated image, and \textit{l} meaning a single annotated pixel. $\mathcal{W}^{**}$ represents performance results for vertical structures higher than 5 m. Best results for each metric are highlighted in \textbf{bold} for the first set of samples configuration and \underline{underlined} for the second set of samples.   }

\label{table:finetune_performance}
\vskip-0.25cm
\begin{center}
\begin{small}
\begin{sc}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccccccc}
\toprule
Dataset & Metric & Samples (S) & DUNIA & AnySat & Croma & S & DUNIA & AnySat & Croma\\
\cmidrule(lr){1-1} \cmidrule(lr){2-2} \cmidrule(lr){3-3} \cmidrule(lr){4-6} \cmidrule(lr){7-7} \cmidrule(lr){8-10}\\                       
\cellcolor{cgreen!50}$\mathcal{W}_{rh}$                 &$rmse$ $(r)$    &5K \textit{im} &\textbf{1.34} (.95) &2.75 (.89) &3.52 (.78)  &1K \textit{im}  &\underline{1.44} (.93) &2.80 (.89) &3.62 (.76)   \\
\cellcolor{cgreen!50}$\mathcal{W}_c$                    &$rmse$ $(r)$    &5K \textit{im}&\textbf{9.8} (.85) &12.1 (.79) &14.2 (.73) &1K \textit{im} &\underline{10.0} (.83) &12.4 (.79) &14.5 (.72)    \\
\cellcolor{cgreen!50}$\mathcal{W}_{pai}$                &$rmse$ $(r)$    &5K \textit{im}&\textbf{0.62} (.71) &0.95 (.67) & 1.2 (.61) &1K \textit{im} & \underline{0.61} (.70) &0.94 (.67) & 1.5 (.60)    \\
\cellcolor{cblue!50}$CLC_+$                  &$wF1$         &5K \textit{im} &\textbf{90.3\%} &90.1\% &86.4\%  &1K \textit{im}  &89.4\% &\underline{89.5}\% &85.9\%\\
\cellcolor{cblue!50}$PASTIS$                 &$wF1$          &1.5K \textit{im} &77.0\% &\textbf{81.1\%} &73.3\%  &\textit{300 \textit{im}}  &75.3\% &\underline{80.2}\% &71.0\%\\
\cellcolor{cblue!50}$PF$                     &$wF1$         &50K \textit{l}&82.2\% &\textbf{82.3\%} &80.5\%  &10K \textit{l}  &80.1\% &80.0\% &\underline{80.2}\%\\
\cellcolor{cgreen!50}$\mathcal{W}^{**}$ & $r$ & $\approx$19M \textit{l} & .78 &--- &--- & $\approx$3.8M \textit{l} &.75 &--- &--- \\
\bottomrule
\end{tabular}%
}
\end{sc}
\end{small}
\end{center}
\vskip-0.3cm
\end{table*} 

Zero-shot results in \cref{table:retrieval_performance} demonstrate that for vertical structure products ($\mathcal{W}_{rh}$, $\mathcal{W}_{c}$, $\mathcal{W}_{pai}$) and tree species identification ($PF$), DUNIA with S samples and KNN=50 outperforms specialist models. It achieves RMSE (r) improvements of 3.2 m (.16), 10.4\% (.35), and 0.79 (.4) for canopy height, cover, and plant area index, and matching the mapping quality of supervised methods (\cref{fig:result_maps}). For tree species identification, DUNIA slightly underperforms by 0.8\% at (S=20, KNN=50) but exceeds the baseline by 1.4\% when decreasing the number of neighbors (KNN=5) used for the distance-weighted voting. For land cover mapping ($CLC_+$), DUNIA achieves strong performance with a $wF1$ score of 80.1\% (S=500 \textit{im}, KNN=50). However, for crop type mapping ($PASTIS$), DUNIA significantly underperforms compared to the state-of-the-art, which is likely due to the variability of the phenological cycles of crops that cannot be well captured by a single median composite.

For lower KNN values, the performance of vertical structure-related products and tree species identification remains stable. In contrast, land cover and crop type mapping experience significant performance drops, indicating that the model needs more samples for accurate classification. For retrieval databases with fewer samples, vertical structure-related products ($\mathcal{W}_{rh}$, $\mathcal{W}_c$, $\mathcal{W}_{pai}$) maintain their performance and map qualities (\cref{fig:high_vs_low_samples}), while other products ($CLC_+$, $PASTIS$, $PF$) show a substantial degradation in performance.

Regarding waveform ($\mathcal{W}$) retrieval performance, we observe that our model is able to retrieve relevant waveforms given a pixel embedding as a query, with a correlation coefficient of .70\% for S=50k \textit{l}, and decreases by a small factor with smaller retrieval database sizes. This is to be expected given the small subset of waveforms in the retrieval database that might not reflect all possible variations for a particular height class. Retrieved vs. reference waveforms can be found in \cref{fig:result_waveforms,fig:result_waveforms_set_2,fig:result_waveforms_set_3,fig:result_waveforms_set_4}.  

\subsubsection{Finetuning Performance}
Finetuning results in \cref{table:finetune_performance} demonstrate that DUNIA outperforms the other models in vertical structure-related products, surpassing both AnySat and CROMA, with CROMA trailing significantly. In comparison to DUNIA's zero-shot results, all the models underperformed in the finetuning setting for $\mathcal{W}_c$ and $\mathcal{W}_{pai}$ due 
to the long-tailed distribution of these two products that are not well modeled with the simple $L_1$ loss that we used. Qualitatively, as shown in \cref{fig:result_maps}, DUNIA and AnySat show a similar level of detail; however, DUNIA is capable of producing higher values, which we attribute to the alignment with the vertical structure in the pre-training stage. For CROMA, \cref{fig:result_maps} shows that this model produces much smoother maps than the two other models.

For $CLC_+$ and $PF$, DUNIA's performance in the fine-tuning setting increased in comparison to the zero-shot setting with results on par with the much more data-heavy AnySat model (\cref{table:finetune_performance}). However, DUNIA underperformed by a significant margin ($\downarrow4.1\%$) in comparison to AnySat for the $PASTIS$ dataset. Qualitatively (\cref{fig:result_maps}) both DUNIA and AnySat show similar level of detail for the $CLC_+$ dataset, in contrast to CROMA which also showed very smooth maps with fewer details.

In the novel task of waveform generation, we observed a correlation ($r$) increase of .08 between reference and generated waveforms compared to retrieval ($r$=.70 with S=50K \textit{l}, KNN=1). This correlation dropped to .75 when the diffusion model was trained on just 20\% of the available waveforms. Retrieved vs. generated waveforms can be found in \cref{fig:result_waveforms,fig:result_waveforms_set_2,fig:result_waveforms_set_3,fig:result_waveforms_set_4}.

To further analyze the contributions of different architectural choices, including the use of separate decoders and the impact of our alignment strategies, we provide additional ablation studies in \autoref{appendix:ablations}
