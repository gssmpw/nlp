In this section, we introduce the structural causal model framework that we will use. We also shortly introduce concurrent game structures and give a formal definition of agent strategies. 

\begin{definition}[Causal Model, Causal Setting \cite{halpern2016actual}] \label{def:causal model}
    A \emph{causal model} $\mathcal{M}$ is a pair $(\mathcal{S},\mathcal{F})$, where $\mathcal{S}$ is a signature and $\mathcal{F}$ defines a set of structural equations, relating the values of the variables.
    A \emph{signature} $\mathcal{S}$ is a tuple $(\mathcal{U},\mathcal{V},\mathcal{R})$, where $\mathcal{U}$ is a set of exogenous variables, $\mathcal{V}$ is a set of endogenous variables and $\mathcal{R}$ associates with every variable $X\in \mathcal{U}\cup \mathcal{V}$ a nonempty set $\mathcal{R}(X)$ of possible values for $X$.
    
    A \emph{causal setting} is a tuple $(\mathcal{M},\mathbf{u})$, where $\mathcal{M}$ is a causal model and $\mathbf{u}$ a setting for the exogenous variables in $\mathcal{U}$.
\end{definition}

The \emph{exogenous variables} are variables whose values depend on factors outside of the model, their causes are not explained by the model \cite{halpern2016actual,Pearl2016causal}.
On the other hand, the \emph{endogenous variables} are fully determined by the variables in the model. 
Note that with $\myvec{u}$, we use the bold-face notation to denote that $\mathbf{u}$ is a tuple.
When we use this bold-face notation for capital letters $\myvec{X}$ and $\myvec{Y}$, we are slightly abusing notation by treating them both as tuples and as sets. This follows Halpern's use of the vector notation for both concepts \cite{halpern2016actual}.
This means that we can write $\myvec{X} = \myvec{x}$ to indicate that the first element of $\myvec{X}$ gets assigned the value of the first element of $\myvec{x}$ and so on, but that we can also write $\myvec{X}'\subseteq \myvec{X}$.

\begin{example}\label{ex:causal model}
    Consider the semi-autonomous vehicle example we discussed in the introduction. 
    We can model this example with exogenous binary variables $U_O$ that determines whether there will be an obstacle on the route, and $U_{Att}$ that determines whether the human driver is paying attention.
    For the endogenous variables we introduce the binary variables $O$, indicating that there is an obstacle, $Att$, indicating that the human driver is paying attention, $HD$ for whether the human driver keeps driving or brakes. Note that we use $HD$ when the human driver keeps driving ($\neg HD$ indicates that they brake). $ODS$, indicating that the obstacle detection system detects an obstacle, $DA$, for whether the driving assistant keeps driving or brakes. Note that we use $DA$ when the human driver keeps driving ($\neg DA$ indicates that they brake). And $Col$, indicating a collision.
    The set $\mathcal{U}$ is hence $\set{U_O,U_{Att}}$ and the set $\mathcal{V}$ is hence $\set{O,Att, HD, ODS,DA, Col}$.
    We consider all variables to be Boolean, so for any variable $X \in \mathcal{U} \cup \mathcal{V}$, $\mathcal{R}(X) = \set{0,1}$.

    The following structural equations are defined for this model:
    \begin{equation*}
        \begin{array}{ll}
            O := U_O & Att:= U_{Att}  \\
            HD := \neg O \vee (O \wedge \neg Att) & ODS:= O \\
            DA := HD \wedge \neg ODS & Col := DA \wedge HD \wedge O.
        \end{array}
    \end{equation*}
\end{example}


A \emph{causal network} is a directed graph with nodes corresponding to the causal variables in $\mathcal{V}$ (and $\mathcal{U}$) with an edge from the node labelled $X$ to the node labelled $Y$ if and only if the structural equation for $Y$ depends on $X$.
In other words, we put an edge from node $X$ to node $Y$ if and only if $X$ can influence the value of $Y$ \cite{halpern2005causes}.
We call $Y$ a \emph{descendant} of $X$ if the graph contains a path from $X$ to $Y$.

A model that has an acyclic causal network is called strongly recursive \cite{halpern2016actual}. In such models, a setting $\mathbf{u}$ of the exogenous variables $\mathcal{U}$ fully determines the values of all other (endogenous) variables. We call a causal model with an acyclic causal network recursive because the exogenous variables determine the values of the endogenous variables in a recursive manner. 
As Halpern explains, some endogenous variables only depend on exogenous variables, we call them first-level variables \cite{halpern2016actual}. 
They get their value directly from the causal setting.
After that there are the second-level variables, the endogenous variables that depend on both the first-level variables and possibly on the exogenous variables.
Likewise the third-level variables depend on the second-level variables, and possibly on the exogenous and the first-level variables, and so on for higher levels.
We only focus on strongly recursive models in this paper.

\begin{example}\label{ex:causal network}
    The causal network for the causal model as described in Example \ref{ex:causal model} is given in Figure \ref{fig:ex causal network} (the exogenous variables are not drawn).
    The graph makes it easy to see that the causal model is recursive, i.e. the causal network does not contain cycles.
    \begin{figure}[b]
        \centering
        \setlength{\unitlength}{1cm}
        \begin{picture}(5,3.05)(-0.5,0)
            \put(0,0){\circle*{0.1}}
            \put(0,1.5){\circle*{0.1}}
            \put(2,0){\circle*{0.1}}
            \put(2,1.5){\circle*{0.15}}
            \put(2,3){\circle*{0.1}}
            \put(4,1.5){\circle*{0.1}}

            \put(0,0){\vector(1,0){1.95}}
            \put(0,1.5){\vector(4,3){1.95}}
            \put(0,1.5){\vector(1,0){1.95}}
            \put(0,1.5){\vector(4,-3){1.95}}
            \put(2,0){\vector(4,3){1.95}}
            \put(2,0){\vector(0,1){1.45}}
            \put(2,3){\vector(4,-3){1.95}}
            \put(4,1.5){\vector(-1,0){1.95}}
            

            \put(-0.15,0){\makebox(0,0)[r]{{$Att$}}}
            \put(-0.15,1.5){\makebox(0,0)[r]{{$O$}}}
            \put(2.15,-0.05){\makebox(0,0)[l]{{$HD$}}}
            \put(2,1.65){\makebox(0,0)[b]{\Large{$Col$}}}
            \put(1.85,3.05){\makebox(0,0)[r]{{$ODS$}}}
            \put(4.15,1.5){\makebox(0,0)[l]{{$DA$}}}
        \end{picture}
        \caption{The causal network for the causal model for the semi-autonomous vehicle example described in Example \ref{ex:causal model}.}
        \label{fig:ex causal network}
        \Description{A graph depicting the causal network of the causal model corresponding to the running semi-automated vehicle example. The graph has 6 nodes, each corresponding to one of the variables of the causal model, Att, O, HD, ODS, DA, and Col. Att has an edge to HD, O has edges to HD, Col and ODS. HD has an edge to DA and Col, ODS has an edge to DA, and DA has an edge to Col. There are no other edges.}
    \end{figure}
%
    We can also see the variable levels. 
    $O$ and $Att$ are first-level variables, they only depend on the exogenous variables.
    $HD$ and $ODS$ only depend on $O$ and $Att$ and hence are second-level variables. 
    $DA$ is a third-level variable, as it depends on second-level variables, and $Col$ is a fourth-level variable, as it depends on both $DA$ and lower-level variables.
\end{example}

Given a signature $\mathcal{S} = (\mathcal{U},\mathcal{V},\mathcal{R})$, a formula of the form $X=x$, for $X\in \mathcal{V}$ and $x\in\mathcal{R}(X)$ is called a \emph{primitive event} \cite{halpern2005causes,halpern2016actual}. These primitive events can be combined with the Boolean connectives $\wedge, \vee$ and $\neg$, to form a \emph{Boolean combinations of primitive events} \cite{halpern2005causes,halpern2016actual}. 
We follow Halpern and use $\csetting \models \phi$ to denote that formula $\phi$ holds given the values of all variables determined by the causal setting $\csetting$ (see~\cite{halpern2016actual} for details).
A \emph{causal formula} has the form $[Y_1\leftarrow y_1, ... , Y_k \leftarrow y_k]\varphi$, where $\varphi$ is a Boolean combination of primitive events, $Y_1,...,Y_k \in \mathcal{V}$ with
$Y_i = Y_j$ if and only if $i = j$, and $y_i\in\mathcal{R}(Y_i) \text{ for all } 1 \leq i \leq k$. Such a formula can be shortened to $[\myvec{Y}\leftarrow\mathbf{y}]\varphi$, and when $k=0$ it is written as just $\varphi$ \cite{halpern2005causes}.
$\csetting \models [\myvec{Y}\leftarrow\mathbf{y}](X = x)$ says that after an intervention that sets all variables of $\myvec{Y}$ to $\mathbf{y}$, it must be the case that $X = x$ holds in the causal setting $\csetting$ (see~\cite{halpern2005causes,halpern2016actual} for more details).
We call $\mathbf{y}$ a \emph{setting} for the variables in $\mathbf{Y}$.
We now have the necessary background to give the modified HP definition of causality:
\begin{definition}[modified HP Definition \cite{halpern2016actual}]\label{def:HP}
$\myvec{X} = \myvec{x}$ is an \emph{actual cause} of $\vphi$ in the causal setting $(\mathcal{M},\mathbf{u})$ if the following 3 conditions hold:
\begin{itemize}
    \item[\textnormal{AC1.}]  $(\mathcal{M},\mathbf{u})\models \myvec{X} = \myvec{x}$ and $(\mathcal{M},\mathbf{u})\models \vphi$;
    \item[\textnormal{AC2.}] There is a set $\myvec{W}$ of variables in $\mathcal{V}$ and a setting $\myvec{x}'$ of variables in $\myvec{X}$ s.t. if $(\mathcal{M},\mathbf{u})\models \myvec{W} = \mathbf{w}^\ast$, then $(\mathcal{M},\mathbf{u}) \models [\myvec{X} \leftarrow \myvec{x}', \myvec{W} \leftarrow \mathbf{w}^\ast] \neg \vphi$.
    \item[\textnormal{AC3.}] $X$ is minimal; there is no strict subset $\myvec{X}'$ of $\myvec{X}$ s.t. $\myvec{X}' = \myvec{x}'$ satisfies \textnormal{AC1} and \textnormal{AC2}, where $\myvec{x}'$ is the restriction of $\mathbf{x}$ to the variables in $\myvec{X}'$.
\end{itemize}
\end{definition}
If $\myvec{W} = \emptyset$, we call $\myvec{X} = \myvec{x}$ a \emph{but-for cause} of $\vphi$.

\begin{example}\label{ex:causes}
    Consider our semi-autonomous vehicle example again. 
    Take the causal setting where $\mathbf{u} = (1,0)$, i.e. $U_O = 1$, there is an obstacle on the route, and $U_{Att} = 0$, the human driver is not paying attention.
    Following the equations provided in Example~\ref{ex:causal model}, we have that $\csetting \models O \wedge \neg Att \wedge HD \wedge ODS \wedge \neg DA \wedge \neg Col$. 
    We want to know which agent was the cause of there being no collision.
    It turns out that both $ODS$ and $\neg DA$ are but-for causes of $\neg Col$, i.e., $\csetting \models [ODS \leftarrow 0] Col$ and $\csetting \models [DA \leftarrow 1] Col$.
    After all, if we intervene by turning off the object detection system $ODS$ (setting its value to $0$ in our model, i.e., replacing equation $ODS=1$ in our model with $ODS=0$, which is formally represented as $[ODS \leftarrow 0]$), the driving assistant $DA$ will no longer get a signal that there is an obstacle on the route.
    This gives $DA =1$, meaning that the driving assistant will not brake. 
    Because the human driver is distracted in this setting, they will also not brake, and so there will be a collision. 
    Similarly we can also directly intervene on the driving assistant by turning it off (setting its value to $1$, not braking, in our model by replacing the equation for $DA$ with $DA:=1$, represented by $[DA \leftarrow 1]$) and there will be a collision as well.
\end{example}

The aim of this work is to connect this concept of structural causal models and causality to concurrent game structures. We use the following definition of concurrent game structures:
\begin{definition}[Concurrent Game Structures \cite{alur2002alternating}]\label{def:concurrent game structures}
    A \emph{concurrent game structure} (CGS) is a tuple $GS = \langle N, Q, d, \delta, \Pi, \pi \rangle$ with the following components:
    \begin{itemize}
        \item A natural number $N \geq 1$ of agents. We identify the \emph{agents} with the numbers $1, . . . , N$.
        \item A finite set $Q$ of states. 
        \item For each agent $a \in \{1, . . . , N\}$ and each state $q \in Q$, a natural number $d_a (q) \geq 1$ of moves available at state $q$ to agent $a$. We identify the moves of agent $a$ at state $q$ with the numbers $1, . . . , d_a (q)$. For each state $q \in Q$, a move vector at $q$ is a tuple $\langle j_1, . . . , j_N\rangle$  such that $1 \leq j_a \leq d_a (q)$ for each agent $a$. Given a state $q \in Q$, we write $D(q)$ for the set $\{1, . . . , d_1 (q)\} \times \dots \times \{1, . . . , d_N (q)\}$ of \emph{move vectors}. The function $D$ is called \emph{move function}.  
        \item For each state $q \in Q$ and each move vector $\langle j_1, . . . , j_N\rangle \in D(q)$, a state $\delta(q, j_1, . . . , j_N ) \in Q$ that results from state $q$ if every agent $a \in \{1, . . . , N\}$ chooses move $j_a$ . The function $\delta$ is called \emph{transition function}.
        \item A finite set $\Pi$ of \emph{propositions}. 
        \item For each state $q \in Q$, a set $\pi (q) \subseteq \Pi$ of propositions true at q. The function $\pi$ is the \emph{labelling function}. 
    \end{itemize}
\end{definition}


When we have a CGS, we can reason about what the optimal actions for a coalition of agents would be in a certain situation. We often use the concept of strategies for this.


\begin{definition}[Strategy in Concurrent Game Structures \cite{alur2002alternating}]
    Given a concurrent game structure $S = \langle N, Q, d, \delta, \Pi, \pi \rangle$, a \emph{strategy} for agent $a\in\set{1,...,N}$ is a function $f_a$, that maps any (non-empty) finite sequence $\lambda$ of states in $Q$ to an action the agent can take at the last state of the sequence. I.e. if $q$ is the last state of $\lambda$, then $f_a(\lambda) \leq d_a(q)$.
    We write $F_A = \{f_a\ | \ a \in A\}$ for a set of strategies of the agents in $A\subseteq \set{1,...,N}$. 
\end{definition}

We now have all preliminaries ready to move on and combine causality with concurrent game structures.
