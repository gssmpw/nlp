This section will consider a two-spacial-dimensional, synthetic problem, inverse problem to show the capabilities of the proposed framework. Our goals are as follows
\begin{itemize}
    \item Show the capability of the framework to correctly identify regions where the assumed constitutive are valid/invalid and
    \item In parts of the domain where the constitutive equation is valid, the method should be able to identify the correct material parameters.
\end{itemize}
\subsection{Problem setup and implementation details}
The problem is modeled like an elastography problem, i.e., we aim to identify a Youngs Modulus field $m = E$ with inclusion in a constant background from noisy displacement observations $\hu$, where the problem is governed by the PDE in Eq. \ref{eqn:PDE}. The domain and boundary conditions are as shown in Figure \ref{fig:problem}. The synthetic data (ground truth) was generated with the finite element software Fenics on a triangular $128 \times 128$ grid. From this, displacement data $\hu$ was generated on a $32 \times 32$ grid, including the domain boundary, and contaminated with known Gaussian noise $\tau$.

\begin{figure}
    \centering
    \includegraphics{pics/problem.png}
    \caption{Problem setup.}
    \label{fig:problem}
\end{figure}

The discretization is as follows:
\begin{itemize}
    \item The Youngs modulus field $m=E$ as based on an element-wise constant triangular $32 \times 32$ grid, i.e., $\dim(\x) = 1922$,
    \item The stress field $\sig$ has three fields ($\sigma_{11}$, $\sigma_{12}$, and $\sigma_{22}$), each of which is modeled by an element-wise constant triangular $32 \times 32$ grid, i.e., $\dim(\ve \chi) = 5766$,
    \item The weight functions $\w$ are two linear triangular elements on a $32 \times 32$ grid, i.e., $\dim(\w)=2048$.
    \item The displacement field is modeled by a 7-layer neural network with 40 neurons and a tanh activation function each, which takes the position vector $\s$ as an input. The last layer has a sigmoid activation function and 50 outputs, multiplied with $\z$ to obtain the value $\uv$ at a given location.
\end{itemize}

All priors are modeled independently and are selected as follows:
\begin{itemize}
    \item We employ a standard normal prior on $\z$: $p(\z) = \prod_{i=1}^{\dim(\z)} \mathcal{N}(z_i| 0, 1)$
    \item We employ an informative prior on $\ve \chi$, as we have no information about its value a-prior: $p(\ve \chi) = \prod_{i=1}^{\dim(\ve \chi)} \mathcal{N}(\chi_i| 0, 10^{16})$
    \item For $\x$, we denote with $\ve{J}_x=\ve{B~x}$ the vector of jumps between neighboring points of dimension $d_{jumps}$. We imposed a hierarchical prior on $\ve{J}_x$ that consists of:
    \begin{equation}
        \label{eqn:jump_prior}
        \begin{array}{c}
        p(\x| \ve{\theta})=\mathcal{N}( \ve{J}_x ~|\ve{0}, diag(\ve{\theta}^{-1})) \\
        p(\ve{\theta}) =\prod_{j=1}^{d_{jumps}} Gamma(\theta_j | a_0 = 10^{-8},b_0 = 10^{-8}).
        \end{array}
    \end{equation}
    The precision hyper-parameters $\ve \theta$ promote sparsity in the number of jumps, i.e., piece-wise constant solutions \cite{bardsley2013gaussian}.
    \item For $\vlamc$, we select a similar Gamma prior, so we can update the posterior later in closed form as described in Appendix \ref{app:lame}: $p(\vlamc) =\prod_{j=1}^{d_{\vlamc}} Gamma(\lamc_j | a_0 = 10^{-8},b_0 = 10^{-8})$.
\end{itemize}

The approximate posterior $\q$ will be constructed as noted in section \ref{subsec:q}. We employ the following architectures:
\begin{itemize}
    \item The mean $\ve{\mu}_{\x;\ve \xi_x}$ takes the $50$ $\z$ values as input for a 3-hidden-layer neural network with $2000$ neurons and SiLU activation function in each layer. The reduced dimension for the covariance matrix is $\times d_{\tilde{\ve x}}=10$.
    \item The mean $\ve{\mu}_{\ve \chi;\ve \xi_\chi}$ takes the $50$ $\z$ values as input for a 3-hidden-layer neural network with $\{ 3000, 4000, 6000 \}$ neurons and SiLU activation function in each layer. The reduced dimension for the covariance matrix is $\times d_{\tilde{\ve \chi}}=10$. 
\end{itemize}
For weight functions $\w$, we subsample $K=200$ out of $N=24,576$ in each iteration, constructed similarly as in \cite{scholz2025weak}. Further, we samples $L=10$ tuples of $\{ \z, \x, \ve \chi \}$ per iterations. We select $\lame = 10^{10}$. The program is implemented in PyTorch and trained on a Nvidea RTX 4090 GPU.

\subsection{Experiment I)}
In this experiment, the ground truth material field consists of a background with linear elastic material behavior governed by
\begin{equation}
    \sig = \lambda \varepsilon_{kk} \delta_{ij} + 2 \mu \varepsilon_{ij},
\end{equation}
where $\varepsilon_{ij} = 0.5 \left( \nabla \uv + \left( \nabla \uv \right)^T \right)$ and $\lambda$ and $\mu$ are first and second Lam√©e parameters, which relate to the Youngs Modulus field as $\lambda = \nu E / \left( \left( 1-2\nu \right) \left(1+\nu \right) \right)$ and $\mu = E / \left(2 \left(1+\nu \right) \right)$, with constant $\nu = 0.3$ and $E=1.0$. Within this background is a circular inclusion with a radius $r=0.2$, which is governed by a transversely isotropic material behavior (formula in Appendix \ref{app:transverse}), where the vertical stiffness is $E_\mathrm{vert} = 3.0$ and the horizontal stiffness is $E_\mathrm{hori} = 1.0$. The inverse problem model, however, assumes a linear elastic material behavior over the whole domain.

The convergence of our method can be observed in Figure \ref{fig:r}, where the expected squared weighted residual $\rc$ drops by two orders of magnitude during the simulation. Further, the inferred displacement fields $\uv$ are depicted in Figure \ref{fig:u}, where the posterior fields coincide with the observations. 
\begin{figure}
    \centering
    \includegraphics[width=0.4\linewidth]{pics/residual.png}
    \caption{Expected weighted squared residual $\rc$ over the iterations ($1$ unit = $10,000$ iterations)}
    \label{fig:r}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.45\linewidth]{pics/u1.png}
    \hfill
    \includegraphics[width=0.45\linewidth]{pics/u2.png}
    \caption{Displacement fields $u_1$ (left) and $u_2$ (right). On both subfigures: The observations $\hu$ are in the top left, the inferred posterior mean of the displacement fields  $\mu_{u_i}$ are in the top right, the absolute error of these two are in the bottom left, and the absolute errors normed by the observation noise $\tau^{-1}$ are the bottom right subplot.}
    \label{fig:u}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{pics/sigma.png}
    \caption{First line shows the stress means $\ve \mu_{\sig}$ and second line shows the $95\%$ credibility intervals. In the columns (f.l.t.r.) are shown the components $\sigma_{11}$, $\sigma_{12}$ and $\sigma_{22}$. }
    \label{fig:sigma}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{pics/logE.png}
    \hfill
    \includegraphics[width=0.39\linewidth]{pics/lnlmbdac.png}
    \caption{Shows Logarithmic Young's modulus field $\ln E$ on the left and the precision $\vlamc$ on the right. In the left subplot, the top left plot shows the true field (but transverse isotropic cannot be depicted), the top right shows the approximate posterior mean, the bottom left shows the $95\%$ credibility intervals, and the bottom right shows where approximation envelopes the ground truth.}
    \label{fig:E_lame}
\end{figure}

From the stress fields $\sig$ in Figure \ref{fig:sigma}, we can see that the stresses in the inclusion in the vertical direction ($\sigma_{11}$) are higher than in the horizontal direction ($\sigma_{22}$), due to the transverse-isotropic material behavior there. In contrast, the algorithm predicts a constant Young's Modulus $E$ over the whole domain, as in Figure \ref{fig:E_lame}, which can not capture material behavior dictated by the stresses $\sig$ inferred from the conservation law. Thus, we turn to the last plot, which shows us the precision parameter $\vlamc$ located at the finite element grid node points in Figure \ref{fig:E_lame}. This parameter determines how tightly the predicted stresses by the conservation law $\sig$ coincide with the stresses predicted by the constitutive equation $\tsig$. The plot shows that the algorithm gives the expected result, i.e., the material law is not valid for the (transverse-isotopic) inclusion. At the same time, it is valid for the linear-elastic background material.

