\section{Ensuring Factuality for LVLMs}
\subsection{Problem Formulation}
Given a pair of image and text prompt $(I_{n+1}, X_{n+1})$
and a set of $n$ calibration data points, our goal is to generate a reliable response $Y^*_{n+1}$ using the LVLM, such that it contains a low error
with high probability; i.e.,
\begin{equation}\label{eq:obj}
    \prob(\gL(Y^*_{n+1}, I_{n+1}) \leq \lambda) \geq 1- \alpha,
\end{equation}
where $\gL:\gY \times \gI \rightarrow \sR^+_0$ is a monotonic \textit{loss} function that measures the level of misalignment between the statement and the image (e.g., the occurrence of object hallucination, or inaccuracy in item attribute or quantity)
and $\lambda$ is a user-specified tolerance. A larger loss indicates a greater amount of error, while a loss of zero indicates that the statement made in the response is \textit{factual} with respect to the provided image. %
We define $\gL(\varnothing, \cdot) = 0$, which indicates that we do not penalize the model for abstaining from responding when it is uncertain, as here we only focus on the assurance of factuality while neglecting other aspects of reliability such as omission of information.

\subsection{Error Control in LVLMs}

Due to the open-set and free-form nature of the natural language output, directly attempting to construct prediction sets is not attainable for generative models like LVLMs.
Instead, we adapt the recently proposed \textit{conformal factuality}~\cite{mohrilanguage,cherian2024large} framework to the multi-modal setting as the central tool for achieving statistical guarantees on the factuality of LVLM outputs.
The key idea is to exploit the connection between linguistic entailments and uncertainty sets to back off from the original statement (uncensored response from LVLM)
by gradually removing unreliable claims with high uncertainty until the desired level of correctness is achieved.


\paragraph{Error Control Procedure.}
We start by defining a scoring function $r(C^j_{n+1}, I_{n+1})\in \sR$ that captures the system's
confidence about the claim concerning the provided visual context, where a larger score indicates that the claim is more aligned with the provided image and, thus, is more likely to be true.
Given $I_{n+1}$ and $X_{n+1}$, we execute the following steps to generate a more reliable response $Y^*_{n+1}$:

\begin{enumerate}[label={(\arabic*)}]
    \item \textit{Initial Hypothesis Generation}: Sample an initial response $Y_{n+1}$ from the LVLM $p_\vtheta(Y|X_{n+1},V_{n+1})$, where $V_{n+1}=g\circ h(I_{n+1})$.
    \item \textit{Decomposition}: Apply a \textit{decomposition}
    operator $D$ to breakdown the initial response into a set of individual claims: $\mC_{n+1} = D(Y_{n+1}) = \{C^j_{n+1}\}^{s_i}_{j=1}$.
    \item \textit{Individual Hypothesis Testing}: Define the \textit{filtering} operator as $F(\mC_{n+1}; \tau) \coloneq \{C^j_{n+1}: r(C^j_{n+1}, I_{n+1}) > \tau\}$. Generate a filtered set of claims $F(\mC_{n+1}; \tau) \subseteq \mC_{n+1}$.
    This step can be thought of as testing each individual hypothesis $C^j_{n+1}$ and accepting the hypothesis only if the test statistic $r(C^j_{n+1}, I_{n+1})$ is greater than the chosen threshold $\tau$.
    \item \textit{Combination}: Apply a \textit{merge}
    operator $M$ to combine the filtered claims into the final response $Y^*_{n+1} = M\big(F(\mC_{n+1}; \tau)\big)$.
\end{enumerate}

\paragraph{Calibration.}
Next, to calibrate the filtering operator $F$, we set the conformity score $S$ for each set of claims to be the minimum threshold that ensures the loss of the filtered set of claims is controlled to be within tolerance:
\begin{equation*}
    S(\mC_{n+1}, I_{n+1})=\inf\{ \tau: \gL \big(F(\mC_{n+1}; \tau), I_{n+1} \big) \leq \lambda\}.
\end{equation*}
Finally, we implement the calibrated filtering operator as $\hat{F}(\mC_{n+1}) \coloneq F(\mC_{n+1}; \hat{\tau}) = \{C^j_{n+1}: r(I, C^j_{n+1}) > \hat{\tau}\}$, where $\hat{\tau}$ is set to be the $\frac{\ceil{(n+1)(1-\alpha)}}{n}$-th quantile of the conformity scores $\{S(\mC_{i}, I_{i}) \}_{i=1}^n$ estimated on the calibration dataset.

The following %
theorem indicates
that if the data are exchangeable, the response produced using the calibrated filtering operator 
will satisfy the error control objective in Ineq.~\ref{eq:obj}.

\begin{theorem}[SCP Coverage Guarantee~\cite{shafer2008tutorial,mohrilanguage}]
Define the error scores $\mE_{i} \coloneq \{\gL (C_i^j, I_i): C_i^j \in \mC_i\}$.
Let $\{(X_i, I_i,\mC_i, \mE_i)\}_{i=1}^{n+1}$ be exchangeable, then the following lower bound holds for any $\alpha \in (\frac{1}{n+1}, 1)$:
\begin{equation*}
     \prob\Big(\gL\big(\hat{F}(\mC_{n+1}), I_{n+1}\big) \leq \lambda\Big) \geq 1-\alpha.
\end{equation*}

If the loss function is monotonic, meaning that $\gL(\hat{F}_1(\mC_i, I_i)) \leq \gL(\hat{F}_2(\mC_i, I_i))$ for any $\hat{F}_1(\mC_i, I_i) \subseteq \hat{F}_2(\mC_i, I_i)$, then the following upper bound also holds:
\begin{equation*}
     1 - \alpha + \frac{1}{n+1} \geq \prob\Big(\gL\big(\hat{F}(\mC_{n+1}), I_{n+1}\big) \leq \lambda\Big).
\end{equation*}

\end{theorem}

\begin{proof}
Without loss of generality, let us assume that the conformity scores are sorted as $s_1 < s_2  < ... s_n$, where $s_i = S(\mC_{i}, I_{i})$.
Notice that under the definition of $S$, the event $\{s_{n+1} \leq \hat{\tau}\}$ implies $\{ \gL \big(\hat{F}(\mC_{n+1}), I_{n+1} \big) \leq \lambda \}$.
By exchangeability, $\prob(s_{n+1} \leq s_{\ceil{(n+1)(1-\alpha)}}) = \frac{\ceil{(n+1)(1-\alpha)}}{n+1} \geq 1 - \alpha$, which implies the result.
To prove the upper bound, notice that the two events $\{s_{n+1} \leq \hat{\tau}\}$ and $\{ \gL \big(\hat{F}(\mC_{n+1}), I_{n+1} \big) \leq \lambda \}$ are now equivalent if the loss function is monotone. The result can then be obtained through $\prob(s_{n+1} \leq s_{\ceil{(n+1)(1-\alpha)}}) = \frac{\ceil{(n+1)(1-\alpha)}}{n+1} \leq \frac{(1-\alpha)(n+1) +1}{n+1} = 1 - \alpha + \frac{1}{n+1}$.

\end{proof}

\subsection{Deriving Conformity Scores}

In practice, the decomposition operator can be implemented by prompting the language model part of the LVLM, which does not rely on any external resources.
To derive the conformity scores, we will need to find a suitable scoring function $r(C_i, I_i)$.
Built on conformal prediction, our framework should maintain valid coverage with any arbitrary heuristic scores. However, in practice, a score that better captures the relevance between a claim $C_i$ and the given image $I_i$ can enable a better tradeoff (i.e., allowing the same coverage guarantee while filtering out less content).
We primarily consider the following two types of scores.

\paragraph{Internal Scores.}
We consider the following scores to capture the internal confidence of an LVLM regarding a statement.
(1) \textit{Log Probability of Text Tokens}: we compute the log probability of text tokens from the claim given only the text prompt as $r(C_i, I_i) = \log p_\vtheta(C_i|X_i)$, which does not make use of the visual context and thus serves as a language prior baseline.
(2) \textit{Log Probability of Text Tokens Conditioned on Image}: we compute the log probability of text tokens from the claim conditioned on both the visual and the text prompt as $r(C_i, I_i) = \log p_\vtheta(C_i|X_i, V_i)$, which is the visual instruction tuning objective~\cite{liu2024visual} of most LVLMs.
(3) \textit{Log Probability Ratio}: finally, we consider the ratio between the two probabilities, i.e.,  $r(C_i, I_i) = \log \frac{p_\vtheta(C_i|X_i, V_i)}{p_\vtheta(C_i|X_i)}$. This is motivated by the observation that most hallucinations in LVLMs occur because their language prior tend to dominate visual perception during decoding~\cite{favero2024multi,leng2024mitigating,liu2024paying}, and the probability ratio can be an informative measure of the true influence of the visual prompt regardless of the language prior.

\paragraph{External Scores.}
In addition to internal scores, we also consider capturing the confidence in a statement regarding an image using a (lightweight) external model. \textit{Energy-based models}~\cite{lecun2006tutorial} $E: \gY \times \gI \rightarrow \sR$ are particularly suited for this task as they are trained to map image-text pairs to a scalar energy score so that $e^{-E(Y, I)} \propto \prob(Y, I)$. As such, we can simply set the scoring function to return the negative energy score, 
$r(C_i, I_i)=-E(C_i, I_i)$.
