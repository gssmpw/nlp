\newpage
\appendix

\section{Implementation Details}

\paragraph{Prompts for Image-conditioned Free-text Generation.} We use the following prompt for evaluating LVLMs on the scene and document understanding tasks: \textit{``$\langle \texttt{Image} \rangle$ Provide a detailed description of the given image.''}.
To evaluate medical (radiology) report generation, we use the following prompt for \modelname{LLaVA-Med}: \textit{``$\langle \texttt{Image} \rangle$ What does the chest X-ray show?''}, whereas \modelname{CvT2DistilGPT2} and \modelname{MAIRA-2} do not require any text prompt for generating reports.

\paragraph{Prompts for Error Annotation.} We include our prompts for LLM-assisted error annotation of the scene understanding, medical report generation, and document understanding tasks in Table~\ref{tab:label_prompt}.

\begin{table*}[ht]
    \centering
    \caption{Prompts for error annotation.}
    \label{tab:label_prompt}
\resizebox{0.8\linewidth}{!}{
\begin{tcolorbox}[breakable,title=Error annotation prompt for scene understanding]
        \textbf{System} \textit{``You are an expert annotator tasked with evaluating statements generated by a vision-language model (VLM).\
Given an image and a claim, your task is to verify the factuality of the claim based on how well it aligns with the provided image.\
You should focus only on significant or material correctness, ignoring minor differences or non-essential details, especially in spatial relationships or specific object types.}


\textit{The errors are categorized as follows:
1. **Object Identification (Object)**: The claim involves hallucinated or wrongly identified objects. Ignore minor distinctions between similar objects (e.g., slotted spoon vs regular spoon) unless it fundamentally changes the meaning of the claim.
2. **Attribute Accuracy (Attribute)**: The claim involves incorrect attributes (e.g., color, size, shape). Only flag attributes if they are critical to the understanding of the claim.
3. **Spatial Relations (Spatial)**: The claim involves incorrect spatial relationships between objects. Only flag spatial errors if they significantly change the scene (e.g., "above the water" vs. "in the water" can be ignored unless the context requires precision).
4. **Interaction/Action Accuracy (Interaction)**: The claim involves incorrect or hallucinated action or interaction.
5. **Quantitative Information (Quantitative)**: The claim involves incorrect numeric details (e.g., wrong object count).
}

\textit{For each claim, generate a JSON object with four fields:
- "reasoning": a brief explanation of why the claim is correct or incorrect.
- "label": a boolean value (True or False) where True means the claim is factually correct, and False means it is incorrect.
- "error\textunderscore type": a list of error types (e.g., ["Object", "Attribute"]) if the claim contains errors, or an empty list if the claim is fully correct.
}

\textit{
Example:
Given an image of two orange cats, and the following list of claims:
1. This image features several cute cats.
2. There are a total number of three cats.
3. One cat is orange, the others are black.
4. There is also a dog behind the cats.
}

\textit{
Return:
[
    \{"reasoning": "The claim is general and no significant error can be found.", "label": true, "error\textunderscore type": []\},
    \{"reasoning": "There are two cats in the image, not three.", "label": false, "error\textunderscore type": ["Quantitative"]\},
    \{"reasoning": "One cat is orange, but the other is not black.", "label": false, "error\textunderscore type": ["Quantitative", "Attribute"]\},
    \{"reasoning": "There is no dog in the image.", "label": false, "error\textunderscore type": ["Object"]\}
]
''}

\textbf{User} \textit{``List of claims:
\{claims\}
For each claim, return a JSON object with "reasoning", "label" (true or false),
"error\textunderscore type" (might contain multiple types from ["Object", "Attribute", "Spatial", "Interaction", "Quantitative"]).
''}
        
    \end{tcolorbox}
    }


\resizebox{0.8\linewidth}{!}{
\begin{tcolorbox}[breakable,title=Error annotation prompt for medical report generation]
        \textbf{System} \textit{``You are an experienced radiologist tasked with evaluating statements generated by a Medical AI model.\
Given a chest x-ray image, a ground truth report generated by expert human radiologist, and a claim generated by the AI model, your task is to verify the factuality of the claim based on how well it aligns with the provided ground truth report. IMPORTANT: A claim should be deemed correct only if it is directly entailed by the ground truth report.}


\textit{The errors are categorized as follows:
1. **Conflicting Error (Conflicting)**: The claim directly contradicts information provided in the ground truth report.
2. **Implausible Error (Implausible)**: The claim does not directly conflict with or align with the ground truth report, and is implausible within the given context.
3. **Plausible Error (Plausible)**: The claim does not directly conflict with or align with the ground truth report, but remains plausible within the given context.
}

\textit{For each claim, generate a JSON object with four fields:
- "reasoning": a brief explanation of why the claim is correct or incorrect.
- "label": a boolean value (True or False) where True means the claim is factually correct, and False means it is incorrect.
- "error\textunderscore type": a list of error types (e.g., ["Conflicting", "Plausible"]) if the claim contains errors, or an empty list if the claim is fully correct.
}

\textit{
Example:
Given a chest x-ray report and the following list of claims:
1. There is no evidence of lung consolidation.
2. The heart size is mildly enlarged.
3. There are signs of a pleural effusion.
}

\textit{
Return:
[
    {"reasoning": "The ground truth report confirms no lung consolidation.", "label": true, "error\textunderscore type": []},
    {"reasoning": "The ground truth report describes the heart size as normal.", "label": false, "error\textunderscore type": ["Conflicting"]},
    {"reasoning": "The ground truth report does not mention a pleural effusion, but it is a plausible interpretation in some cases.", "label": false, "error\textunderscore type": ["Plausible"]}
]
''}

\textbf{User} \textit{``List of claims:
\{claims\}
For each claim, return a JSON object with "reasoning", "label" (true or false),
"error\textunderscore type" (might contain multiple types from ["Conflicting", "Implausible", "Plausible"]).
''}
        
    \end{tcolorbox}
    }


\resizebox{0.8\linewidth}{!}{
    \begin{tcolorbox}[breakable,title=Error annotation prompt for document understanding]
        \textbf{System} \textit{``You are an expert annotator tasked with evaluating statements generated by a Document AI model.\
Given a ground truth document (image and text) and a claim, your task is to verify the factuality of the claim based on how well it aligns with the provided document.
}


\textit{The errors are categorized as follows:
1. **Field Misinterpretation (Field)**: Incorrectly identify important fields such as mistaking "Invoice Date" for "Due Date", "Subtotal" for "Total Amount", or misrecognize non-existing field.
2. **Numerical and Quantitative Errors (Numerical)**: Incorrect amounts, totals, or quantity values, as well as calculation discrepancies (e.g., subtotal, tax, and total relationship).
3. **Date Error (Date)**: Misrecongizing date or misinterpreting date formats.
4. **Item Error (Item)**: Misrecongizing item or item details, or falsely identifying non-existing item.
5. **Other Errors (Other)**: Other errors such as misspell or misrecognize character, layout and alignment issues.
}

\textit{For each claim, generate a JSON object with four fields:
- "reasoning": a brief explanation of why the claim is correct or incorrect.
- "label": a boolean value (True or False) where True means the claim is factually correct, and False means it is incorrect.
- "error\textunderscore type": a list of error types (e.g., ["Numerical", "Item"]) if the claim contains errors, or an empty list if the claim is fully correct.
}

\textit{
Example:
Given an invoice of buying a Chopping Board at a shop named \"Walmart\", and the following list of claims:
1. This image is a printed invoice.
2. The merchant name is \"Wallmart\".
3. The items listed on the receipt include two Chopping Board, and a Knife.
}

\textit{
Return:
[
    {"reasoning": "The image shows a printed invoice.", "label": true, "error\textunderscore type": []},
    {"reasoning": "The merchant name is spelled incorrectly.", "label": false, "error\textunderscore type": ["Other"]},
    {"reasoning": "Only one Chopping Board, and no Knife purchased.", "label": false, "error\textunderscore type": ["Numerical", "Item"]},
]
''}

\textbf{User} \textit{``List of claims:
\{claims\}
For each claim, return a JSON object with "reasoning", "label" (true or false),\
"error\textunderscore type" (might contain multiple types from ["Field", "Numerical", "Date", "Item", "Other"]).
''}
        
    \end{tcolorbox}}
\end{table*}




\paragraph{Decomposition and Merge Operators.}
We implement the decomposition and merging operations by prompting the language model part of the LVLM. 
For rare cases where the LVLM does not support or cannot correctly implement the decomposing operation (e.g., dedicated models such as \modelname{MAIRA-2} and \modelname{CvT2DistilGPT2}), we use \modelname{GPT-4o-mini} as the substitute model to implement the decomposition and combination operations.
The prompt for decomposing claims is \textit{``Breakdown the above statement into a set of indepedent and self-contained claims. Each claim should be a short sentence. Output only a numbered list of claims.''}.
The prompt for merging claims is \textit{``Merge the above claims about an image into a cohesive statement. Reuse the words from the original claims and do not generate any new claims.''}.


\section{Additional Results}

\subsection{Annotation Reliability}
\paragraph{Human Raters.} We used \modelname{GPT-4o} for assisting with annotating error types. To verify its annotation quality, we randomly select a subset of $50$ images and $1,182$ associating claims generated by \modelname{LLaVA-1.5} on the scene understanding task, and recruit two human annotators to generate independent error type annotations.
The measured averaged Intraclass Correlation Coefficient (ICC) between \modelname{GPT-4o} and human annotations is $0.85$, with the $95\%$ CI being $[0.82, 0.87]$. This result confirmed that the annotations show high inter-rater reliability (by convention, any ICC value above 0.75 is considered to be good reliability~\cite{koo2016guideline}).

\paragraph{LVLM Raters.} We measured the averaged ICC between GPT-4o and Gemini-1.5-pro on the scene understanding task to be $0.81$, with the $95\%$ CI being $[0.77, 0.85]$, which shows high inter-rater reliability.


\subsection{LVLM Output Distribution}

In Fig.~\ref{fig:vlm_out_dist}, we compare the quality of vanilla LVLM outputs (i.e., raw responses without filtering any claim) by visualizing the distribution of the number of claims and loss per response.
An ideal LVLM should be expressive (output more claims) while maintaining a low risk of hallucination (yield low loss values).
On the scene understanding task, \modelname{GPT-4o-mini} clearly outperforms other models but is still prone to errors. On the medical report generation task, \modelname{CvT2DistilGPT2} and \modelname{MAIRA-2} both outperform \modelname{LLaVA-Med} by a large margin, but still have very high loss values in most responses.
Similarly, on the document understanding tasks, both model show a long tail in loss distribution.
These observations necessitate the adoption of error control methods with statistical guarantees.



\begin{figure}[t]
     \centering
     \begin{subfigure}[b]{0.7\linewidth}
         \centering
        \includegraphics[width=0.9\linewidth]{figs/pope_vlm_violin_plot.pdf}
         \caption{Scene understanding}
         \label{subfig:pope_vlm}
     \end{subfigure}

     \begin{subfigure}[b]{0.7\linewidth}
         \centering
        \includegraphics[width=0.9\linewidth]{figs/mimic_vlm_violin_plot.pdf}
         \caption{Medical report generation}
         \label{subfig:mimic_vlm}
     \end{subfigure}

     \begin{subfigure}[b]{0.7\linewidth}
         \centering
        \includegraphics[width=0.9\linewidth]{figs/sroie_vlm_violin_plot.pdf}
         \caption{Document understanding}
         \label{subfig:sroie_vlm}
         
     \end{subfigure}
        \caption{Comparison of the quality of raw LVLM responses.}
        \label{fig:vlm_out_dist}
\end{figure}


\subsection{Comparison to Heuristic-based Mitigation}
Heuristic-based mitigation, such as Woodpecker~\cite{yin2023woodpecker}, relies on a series of external models, including BLIP-2, GroundingDINO, and proprietary models such as GPT, to reduce object hallucination, and thus it is not readily applicable to the specialized domains considered in our paper (i.e., medicine and finance).
Even if Woodpecker is applicable, unlike our method which is driven by a confidence score, Woodpecker is driven by the matching of textual claims to objects extracted from the image. In this sense, when Woodpecker fails to match an object, it filters out the claim. As such, our method offers a continuous confidence score that is tunable, whereas Woodpecker only offers a binary match/no match strategy.
We conducted additional experiments on the scene understanding task by randomly selecting $100$ images and measuring Woodpecker's claim filtering efficiency (in terms of TPR) and final response accuracy, with results shown in Table~\ref{tab:woodpecker}.
We observe that Woodpecker suffers from low TPR in claim filtering and low final response accuracy, partially due to GroundingDINO's high FPR in open-set object detection.

\begin{table}[h]
    \centering
    \caption{Comparision to heuristic-based mitigation.}
    \label{tab:woodpecker}
    \vspace{2mm}
    \resizebox{0.62\linewidth}{!}{
    \begin{tabular}{c|c|c}
    \toprule
                        & \textbf{Claim Filtering Efficiency (TPR) $\uparrow$} & \textbf{Response Accuracy $\uparrow$} \\ \midrule
    \textbf{Woodpecker} & 59.1\%                                    & 41\%                       \\ 
    \textbf{\textsc{ConfLVLM}}   & \textbf{95.3\%}                           & \textbf{90\%}              \\ \bottomrule
    \end{tabular}
    }

\end{table}

\subsection{Omitted Results from Main Paper}
Here we provide the omitted results from main paper for medical report generation and document understanding.

\paragraph{Medical Report Generation.}
Fig.~\ref{fig:mimic_coverage} compares the empirical and desired coverage of \modelname{LlaVa-Med}, \modelname{CvT2DistilGPT2}, and \modelname{MAIRA-2} on the medical report generation task.
The same conclusion is drawn as in the general scene understanding setting: \methodName~
achieves the desired level of coverage across all types of scoring functions, whereas Vanilla LVLM (i.e., responses without any filtration) produces significantly low coverage. 
Fig.~\ref{fig:mimic_cont} shows the average ratio of filtered claims  across a range of desired coverage, whereas Fig.~\ref{fig:mimic_abstention} presents the abstention rate as a function of desired coverage.



\begin{figure}[t]
    \centering
\includegraphics[width=0.86\linewidth]{figs/mimic_coverage_err=0.pdf}
    \caption{Alignment between the empirical and desired (theoretical) coverage on the \textit{medical report generation} task (with $\lambda=0$). Vanilla LVLM (red dashed line) refers to the base setting where the LVLM-generated responses are returned to users without using \methodName.}
    \label{fig:mimic_coverage}
\end{figure}

\begin{figure}[t]
    \centering
\includegraphics[width=0.86\linewidth]{figs/mimic_avg_cont_err=0.pdf}
    \caption{Average ratio of claims filtered with varying coverage using different scoring functions on the \textit{medical report generation} task (with $\lambda=0$).}
    \label{fig:mimic_cont}
\end{figure}

\begin{figure}[t]
    \centering
\includegraphics[width=0.86\linewidth]{figs/mimic_abstent_err=0.pdf}
    \caption{Abstention rate with varying coverage using different scoring functions on the \textit{medical report generation} task (with $\lambda=0$).}
    \label{fig:mimic_abstention}
\end{figure}



\begin{figure}[t]
    \centering
\includegraphics[width=0.8\linewidth]{figs/sroie_coverage_err=0.pdf}
    \caption{Alignment between the empirical and desired (theoretical) coverage on the \textit{document understanding} task (with $\lambda=0$). Vanilla LVLM (red dashed line) refers to the base setting where the LVLM-generated responses are returned to users without using \methodName.}
    \label{fig:sroie_coverage}
\end{figure}


\paragraph{Document Understanding.}
Fig.~\ref{fig:sroie_coverage} shows the alignment between the empirical and desired coverage of \modelname{LLaVA-Next} and \modelname{Phi-3.5-vision-instruct} using \methodName~on the document understanding task. The same conclusions regarding model coverage are reached as in the other two image understanding settings.
Fig.~\ref{fig:sroie_cont} shows the average ratio of filtered claims  across a range of desired coverage, whereas
Fig.~\ref{fig:sroie_abstention} presents the abstention rate as a function of desired coverage.
In Fig.~\ref{fig:sroie_err}, we compare \modelname{LLaVa-NeXT}'s response with different error tolerances and a fixed error rate.


\begin{figure}[t]
    \centering
\includegraphics[width=0.7\linewidth]{figs/sroie_avg_cont_err=0.pdf}
    \caption{Average ratio of claims filtered with varying coverage using different scoring functions on the \textit{document understanding} task (with $\lambda=0$).}
    \label{fig:sroie_cont}
\end{figure}

\begin{figure}[t]
    \centering
\includegraphics[width=0.7\linewidth]{figs/sroie_abstent_err=0.pdf}
    \caption{Abstention rate with varying coverage using different scoring functions on the \textit{document understanding} task (with $\lambda=0$).}
    \label{fig:sroie_abstention}
\end{figure}



\begin{figure}[t]
    \centering
    \includegraphics[width=0.7\linewidth]{figs/LLaVa-NeXT_vary_err.pdf}
    \caption{Comparison of \modelname{LLaVa-NeXT}'s response with different error tolerances ($\lambda$) while fixing $\alpha=0.1$ on the \textit{document understanding} task.}
    \label{fig:sroie_err}
\end{figure}


\subsection{Response-level and Claim-level Results}
In Table~\ref{tab:pope_res_extend}, we show the response-level (rate of responses containing at least one error and the average loss per response) and claim-level (TPR, FNR, and F1 for detecting erroneous responses) results under various $\alpha, \lambda$ configurations on the scene understanding task. Results are averaged over $50$ random data splits.


\begin{table}[t]
    \centering
    \resizebox{0.78\linewidth}{!}{
    \begin{tabular}{l|c|cc|ccc}
\hline
                                          &                                             & \multicolumn{2}{c|}{\textbf{Response-level}}                    & \multicolumn{3}{c}{\textbf{Claim-level}}                                                         \\ \cline{3-7} 
\multirow{-2}{*}{\textbf{LVLM}}           & \multirow{-2}{*}{\textbf{Configuration}}    & \textbf{Error Rate}            & \textbf{Average Loss}          & \textbf{TPR}                   & \textbf{FNR}                   & \textbf{F1}                    \\ \hline
                                          & Vanilla                                     & 0.8782                         & 5.5028                         & 0.0                            & 1.0                            & 0.0                            \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.1, \lambda=0$ & \cellcolor[HTML]{EFEFEF}0.102 & \cellcolor[HTML]{EFEFEF}0.206 & \cellcolor[HTML]{EFEFEF}0.953 & \cellcolor[HTML]{EFEFEF}0.047 & \cellcolor[HTML]{EFEFEF}0.504 \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.1, \lambda=2$ & \cellcolor[HTML]{EFEFEF}0.212 & \cellcolor[HTML]{EFEFEF}0.529 & \cellcolor[HTML]{EFEFEF}0.886 & \cellcolor[HTML]{EFEFEF}0.114 & \cellcolor[HTML]{EFEFEF}0.507 \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.3, \lambda=0$ & \cellcolor[HTML]{EFEFEF}0.291 & \cellcolor[HTML]{EFEFEF}0.780 & \cellcolor[HTML]{EFEFEF}0.836 & \cellcolor[HTML]{EFEFEF}0.164 & \cellcolor[HTML]{EFEFEF}0.503 \\
\multirow{-5}{*}{\modelname{LLaVA-1.5}}               & \cellcolor[HTML]{EFEFEF}$\alpha=0.3, \lambda=2$ & \cellcolor[HTML]{EFEFEF}0.536 & \cellcolor[HTML]{EFEFEF}1.771 & \cellcolor[HTML]{EFEFEF}0.637 & \cellcolor[HTML]{EFEFEF}0.363 & \cellcolor[HTML]{EFEFEF}0.499 \\ \hline
                                          & Vanilla                                     & 0.850                         & 3.895                         & 0.0                            & 1.0                            & 0.0                            \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.1, \lambda=0$ & \cellcolor[HTML]{EFEFEF}0.094 & \cellcolor[HTML]{EFEFEF}0.147 & \cellcolor[HTML]{EFEFEF}0.945 & \cellcolor[HTML]{EFEFEF}0.055 & \cellcolor[HTML]{EFEFEF}0.401 \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.1, \lambda=2$ & \cellcolor[HTML]{EFEFEF}0.288 & \cellcolor[HTML]{EFEFEF}0.611 & \cellcolor[HTML]{EFEFEF}0.829 & \cellcolor[HTML]{EFEFEF}0.171 & \cellcolor[HTML]{EFEFEF}0.392 \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.3, \lambda=0$ & \cellcolor[HTML]{EFEFEF}0.306 & \cellcolor[HTML]{EFEFEF}0.655 & \cellcolor[HTML]{EFEFEF}0.818 & \cellcolor[HTML]{EFEFEF}0.182 & \cellcolor[HTML]{EFEFEF}0.390 \\
\multirow{-5}{*}{\modelname{Phi-3.5-vision-instruct}} & \cellcolor[HTML]{EFEFEF}$\alpha=0.3, \lambda=2$ & \cellcolor[HTML]{EFEFEF}0.648 & \cellcolor[HTML]{EFEFEF}1.911 & \cellcolor[HTML]{EFEFEF}0.480 & \cellcolor[HTML]{EFEFEF}0.520 & \cellcolor[HTML]{EFEFEF}0.345 \\ \hline
                                          & Vanilla                                     & 0.793                         & 3.129                         & 0.0                            & 1.0                            & 0.0                            \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.1, \lambda=0$ & \cellcolor[HTML]{EFEFEF}0.105 & \cellcolor[HTML]{EFEFEF}0.205 & \cellcolor[HTML]{EFEFEF}0.936 & \cellcolor[HTML]{EFEFEF}0.064 & \cellcolor[HTML]{EFEFEF}0.269 \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.1, \lambda=2$ & \cellcolor[HTML]{EFEFEF}0.232 & \cellcolor[HTML]{EFEFEF}0.543 & \cellcolor[HTML]{EFEFEF}0.831 & \cellcolor[HTML]{EFEFEF}0.169 & \cellcolor[HTML]{EFEFEF}0.266 \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.3, \lambda=0$ & \cellcolor[HTML]{EFEFEF}0.306 & \cellcolor[HTML]{EFEFEF}0.714  & \cellcolor[HTML]{EFEFEF}0.772 & \cellcolor[HTML]{EFEFEF}0.228 & \cellcolor[HTML]{EFEFEF}0.264 \\
\multirow{-5}{*}{\modelname{Llama-3.2-11B-vision}}    & \cellcolor[HTML]{EFEFEF}$\alpha=0.3, \lambda=2$ & \cellcolor[HTML]{EFEFEF}0.628 & \cellcolor[HTML]{EFEFEF}1.805 & \cellcolor[HTML]{EFEFEF}0.408 & \cellcolor[HTML]{EFEFEF}0.592 & \cellcolor[HTML]{EFEFEF}0.227 \\ \hline
                                          & Vanilla                                     & 0.493                         & 1.265                         & 0.0                            & 1.0                            & 0.0                            \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.1, \lambda=0$ & \cellcolor[HTML]{EFEFEF}0.097 & \cellcolor[HTML]{EFEFEF}0.168 & \cellcolor[HTML]{EFEFEF}0.850 & \cellcolor[HTML]{EFEFEF}0.150 & \cellcolor[HTML]{EFEFEF}0.100 \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.1, \lambda=2$ & \cellcolor[HTML]{EFEFEF}0.285 & \cellcolor[HTML]{EFEFEF}0.552 & \cellcolor[HTML]{EFEFEF}0.544 & \cellcolor[HTML]{EFEFEF}0.456 & \cellcolor[HTML]{EFEFEF}0.099 \\
                                          & \cellcolor[HTML]{EFEFEF}$\alpha=0.3, \lambda=0$ & \cellcolor[HTML]{EFEFEF}0.300 & \cellcolor[HTML]{EFEFEF}0.589 & \cellcolor[HTML]{EFEFEF}0.510 & \cellcolor[HTML]{EFEFEF}0.490 & \cellcolor[HTML]{EFEFEF}0.0988 \\
\multirow{-5}{*}{\modelname{GPT-4o-mini}}             & \cellcolor[HTML]{EFEFEF}$\alpha=0.3, \lambda=2$ & \cellcolor[HTML]{EFEFEF}0.493 & \cellcolor[HTML]{EFEFEF}1.265 & \cellcolor[HTML]{EFEFEF}0.0    & \cellcolor[HTML]{EFEFEF}1.0    & \cellcolor[HTML]{EFEFEF}0.0    \\ \hline
\end{tabular}
    }
    \vspace{2mm}
    \caption{Response- and claim-level results on the \textit{scene understanding} task (averaged over $50$ random splits).}
    \label{tab:pope_res_extend}
\end{table}



\subsection{Empirical Coverage and Utility with $\lambda > 0$}

In addition to the plots in the main paper with $\lambda = 0$, we plot the empirical coverage, ratio of claims filtered, and abstention rate with error tolerance $\lambda = 1,2$ for scene understanding in Fig.~\ref{fig:pope_coverage_lambda}, Fig.~\ref{fig:pope_cont_lambda}, and Fig.~\ref{fig:pope_abstent_lambda},
for medical report generation in Fig.~\ref{fig:mimic_coverage_lambda}, Fig.~\ref{fig:mimic_cont_lambda}, and Fig.~\ref{fig:mimic_abstent_lambda}, and for document understanding in Fig.~\ref{fig:sroie_coverage_lambda}, Fig.~\ref{fig:sroie_cont_lambda}, and Fig.~\ref{fig:sroie_abstent_lambda}, respectively.


\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[width=0.6\linewidth]{figs/pope_coverage_err=1.pdf}
        \caption{$\lambda=1$}
    \end{subfigure}

    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[width=0.6\linewidth]{figs/pope_coverage_err=2.pdf}
        \caption{$\lambda=2$}
    \end{subfigure}

    \caption{Comparison of empirical and desired (theoretical) coverage on the scene understanding task with different error tolerances ($\lambda$).}
    \label{fig:pope_coverage_lambda}
\end{figure}


\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[width=0.6\linewidth]{figs/pope_avg_cont_err=1.pdf}
        \caption{$\lambda=1$}
    \end{subfigure}

    \begin{subfigure}[b]{\linewidth}
        \centering
        \includegraphics[width=0.6\linewidth]{figs/pope_avg_cont_err=2.pdf}
        \caption{$\lambda=2$}
    \end{subfigure}

    \caption{Average ratio of claims filtered with varying coverage using different scoring functions on the scene understanding task with different error tolerances ($\lambda$).}
    \label{fig:pope_cont_lambda}
\end{figure}


\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{\linewidth}
        \centering
    \includegraphics[width=0.6\linewidth]{figs/pope_abstent_err=1.pdf}
        \caption{$\lambda=1$}
    \end{subfigure}

    \begin{subfigure}[b]{\linewidth}
        \centering
    \includegraphics[width=0.6\linewidth]{figs/pope_abstent_err=2.pdf}
        \caption{$\lambda=2$}
    \end{subfigure}

    \caption{Abstention rate with varying coverage using different scoring functions on the scene understanding task with different error tolerances ($\lambda$).}
    \label{fig:pope_abstent_lambda}
\end{figure}



\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.72\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/mimic_coverage_err=1.pdf}
        \caption{$\lambda=1$}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.72\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/mimic_coverage_err=2.pdf}
        \caption{$\lambda=2$}
    \end{subfigure}

    \caption{Comparison of empirical and desired (theoretical) coverage on the medical report generation task with different error tolerances ($\lambda$).}
    \label{fig:mimic_coverage_lambda}
\end{figure}


\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.72\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/mimic_avg_cont_err=1.pdf}
        \caption{$\lambda=1$}
    \end{subfigure}

    \begin{subfigure}[b]{0.72\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/mimic_avg_cont_err=2.pdf}
        \caption{$\lambda=2$}
    \end{subfigure}

    \caption{Average ratio of claims filtered with varying coverage using different scoring functions on the medical report generation task with different error tolerances ($\lambda$).}
    \label{fig:mimic_cont_lambda}
\end{figure}

\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.72\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/mimic_abstent_err=1.pdf}
        \caption{$\lambda=1$}
    \end{subfigure}

    \begin{subfigure}[b]{0.72\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/mimic_abstent_err=2.pdf}
        \caption{$\lambda=2$}
    \end{subfigure}

    \caption{Abstention rate with varying coverage using different scoring functions on the medical report generation task with different error tolerances ($\lambda$).}
    \label{fig:mimic_abstent_lambda}
\end{figure}



\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.7\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/sroie_coverage_err=1.pdf}
        \caption{$\lambda=1$}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.7\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/sroie_coverage_err=2.pdf}
        \caption{$\lambda=2$}
    \end{subfigure}

    \caption{Comparison of empirical and desired (theoretical) coverage on the document understanding task with different error tolerances ($\lambda$).}
    \label{fig:sroie_coverage_lambda}
\end{figure}


\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.7\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/sroie_avg_cont_err=1.pdf}
        \caption{$\lambda=1$}
    \end{subfigure}

    \begin{subfigure}[b]{0.7\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/sroie_avg_cont_err=2.pdf}
        \caption{$\lambda=2$}
    \end{subfigure}

    \caption{Average ratio of claims filtered with varying coverage using different scoring functions on the document understanding task with different error tolerances ($\lambda$).}
    \label{fig:sroie_cont_lambda}
\end{figure}

\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.7\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/sroie_abstent_err=1.pdf}
        \caption{$\lambda=1$}
    \end{subfigure}

    \begin{subfigure}[b]{0.7\linewidth}
        \centering
    \includegraphics[width=\linewidth]{figs/sroie_abstent_err=2.pdf}
        \caption{$\lambda=2$}
    \end{subfigure}

    \caption{Abstention rate with varying coverage using different scoring functions on the document understanding task with different error tolerances ($\lambda$).}
    \label{fig:sroie_abstent_lambda}
\end{figure}


\subsection{Examples}
We include additional examples of applying \methodName~to control error in responses from LVLMs for scene understanding (Fig.~\ref{fig:pope_example}), medical report generation (Fig.~\ref{fig:mimic_example}), and document understanding (Fig.~\ref{fig:sroie_example}).

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/VLM_example_pope_v2.pdf}
    \caption{Examples of responses on the scene understanding task.}
    \label{fig:pope_example}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/VLM_example_mimic.pdf}
    \caption{Examples of responses on the medical report generation task.}
    \label{fig:mimic_example}
\end{figure*}


\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/VLM_example_sroie.pdf}
    \caption{Examples of responses on the document understanding task.}
    \label{fig:sroie_example}
\end{figure*}


\section{Additional Discussions}

Our LVLM factuality framework follows the standard conformal prediction setting by assuming data exchangeability (a weaker notion than IID). In cases where this may not hold, there are alternative strategies that one could invoke, such as periodically updating the calibration set or applying a discount factor to older samples, as discussed in the theoretical analysis by Barber \textit{et al.}~\cite{barber2023conformal}.
For significant shifts, such as out-of-domain data, incorporating an additional OOD detection layer~\cite{li2024you} can help to empirically preserve coverage.