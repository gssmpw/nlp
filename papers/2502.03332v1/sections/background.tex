\subsection{Diffusion models} 
\label{sec:diffusion}
DDMs define a generative process for a data distribution $\pdata{0}{}{}$ on $\rset^d$ by sequentially sampling from a series of progressively less smoothed distributions $(\pdata{t}{}{})_{t=T}^0$, starting from a highly smoothed prior $\pdata{T}{}{}$ and ending at the data distribution $\pdata{0}{}{}$. For all $s, t \in \intset{0}{T}$ with $s < t$, define the noising Markov transition kernels 
\begin{equation}
\fw{t|s}{\bx_s}{\bx_t} = \normpdf(\bx_t; (\a_t / \a_s) \bx_s, \std^2 _{t|s} \Id_\dimx) \eqsp,
\label{eq:def_gauss_transition}
\end{equation} 
where $(\a_t)_{t = 0}^T$ is monotonically decreasing with $\a_0 = 1$, $\a_T \approx 0$, and $\std^2 _{\smash{t|s}} = 1 - (\a_t / \a_s)^2$. 
Each smoothed distribution is a noised version of $\pdata{0}{}{}$ and has density  
$\pdata{t}{}{\bx_t} \eqdef \int \fw{t|0}{\bx_0}{\bx_t} \pdata{0}{}{\bx_0} \, \rmd \bx_0$. The final distribution $\pdata{T}{}{}$ is close to $\gauss(\zero_\dimx, \Id_\dimx)$.   Moreover, define the backward Markov transition kernels $\pdata{s|t}{\bx_t}{\bx_s} \propto \pdata{s}{}{\bx_s} \fw{t|s}{\bx_s}{\bx_t}$ with $s < t$.
Note that for all $\ell < s$, the backward transitions satisfy 
\begin{equation}
\label{eq:back_chapman}
\pdata{\ell|t}{\bx_t}{\bx_\ell} = \int \pdata{\ell|s}{\bx_s}{\bx_\ell} \pdata{s|t}{\bx_t}{\bx_s} \, \rmd \bx_s \eqsp.
\end{equation}
Consecutive distributions $\pdata{t}{}{}$ and $\pdata{t+1}{}{}$ are linked through the identity $\pdata{t+1}{}{\bx_{t+1}} = \int \fw{t+1|t}{\bx_t}{\bx_{t+1}} \pdata{t}{}{\bx_t} \, \rmd \bx_t$. 
Hence, given a sample $\bX_{t+1} \sim \pdata{t+1}{}{}$, $\bX_t \sim \pdata{t|t+1}{\bX_{t+1}}{\cdot}$ is an exact sample from $\pdata{t}{}{}$. 
This procedure defines a generative model, in the sense that the last state $X_0$ of the Markov chain $(\bX_{t})_{t = T} ^0$,  where the initial state $X_T$ is sampled from $\pdata{T}{}{}$, is a sample from $\pdata{0}{}{}$.

%This procedure defines a generative model; \emph{i.e.} a Markov chain $(\bX_{t})_{t = T} ^0$ where the initial state is sampled from $\gauss(\zero_\dimx, \Id_\dimx)$ and the final one $\bX_0$ is an exact sample from $\pdata{0}{}{}$. 
However, simulating the backward transitions is impracticable in most applications, so the following Gaussian approximation is used in practice. 
First, for $s \in \intset{1}{t-1}$, define the conditional density of $\bX_s$ given $\bX_0$ and $\bX_{t}$: 
\begin{align}
    \label{eq:bridge}
    & \fw{s|0, t}{\bx_0, \bx_{t}}{\bx_s} \\
    & \hspace{.2cm} = \normpdf(\bx_s; \gamma_{t|s} \a_{s|0} \bx_0 + (1 - \gamma_{t|s}) \a^{-1} _{t|s} \bx_{t}, \std^2 _{s|0,t} \Id_\dimx) \eqsp,\nonumber 
\end{align}
where $\gamma_{t|s} \eqdef \std^2 _{t|s} / \std^2 _{t|0}$ and $\std^2 _{s|0,t} \eqdef \std^2 _{t|s}  \std^2 _{s|0} / \std^2 _{t|0}$. Next, define by $\denoiser{t+1}{}{\bx_{t+1}} \eqdef \int \bx_0 \, \pdata{0|t+1}{\bx_{t+1}}{\bx_0} \, \rmd \bx_0$ the conditional expectation of $\bX_0$ given $\bX_{t+1} = \bx_{t+1}$ (referred to as the denoiser). Denote by $\denoiser{t+1}{}{}[\param]$  a parametric approximation of $\denoiser{t+1}{}{}$. 
Following \citet{ho2020denoising} and given an approximate sample $\smash{\vX_{t+1}}$ from  $\pdata{t+1}{}{}$, sampling from 
the bridge kernel $\fw{t|0, t+1}{\denoiser{t+1}{}{\vX_{t+1}}[\param], \smash{\vX_{t+1}}}{}$, where $\bx_0$ is replaced by the estimate $\denoiser{t+1}{}{\vX_{t+1}}[\param]$, 
%the bridge kernel $\fw{t|0, t+1}{}{}$ \eqref{eq:bridge} with the estimate $\denoiser{t+1}{}{\vX_{t+1}}[\param]$ in place of $\bx_0$ 
yields an approximate sample from $\pdata{t}{}{}$. The complete sampling process proceeds as follows: first, $\hat\bX_T \sim \gauss(\zero_\dimx, \Id_\dimx)$; then, recursively, for every $t \geq 1$, $\smash{\hat\bX_t \sim \pdata{t|t+1}{\hat\bX_{t+1}}{\cdot}[\param]}$, where for all $s < t$, 
 \begin{equation}
    \label{eq:ddpm-transition}
    \pdata{s|t}{\bx_{t}}{\bx_s}[\param] \eqdef \fw{s|0, t}{\denoiser{t}{}{\bx_{t}}[\param], \bx_{t}}{\bx_s} \eqsp.
\end{equation} 
The final sample is defined as $\hat\bX_0 \eqdef \denoiser{1}{}{\hat\bX_1}[\param]$ and serves as an approximate sample from $\pdata{0}{}{}$. The parametric approximations 
%$\denoiser{\cdot}{}{}[\param]$ 
of the denoisers are trained by minimizing, with respect to the parameter $\param$, an $L_2$ denoising loss across all time steps. Finally, using the Tweedie formula 
\cite{robbins1956empirical}, we obtain the identity $\denoiser{t}{}{\bx_t} = \a^{-1}_t \big(\bx_t + \std^2_t \nabla \log \pdata{t}{}{\bx_t}\big)$. Consequently, the trained denoisers not only serve as generative models but also provide parametric approximations of the score functions $\nabla \log \pdata{t}{}{\bx_t}$.

\subsection{Training-free guidance.}
After training a diffusion model for the data distribution $\pdata{0}{}{}$, it can be leveraged through \emph{guidance} to address various downstream tasks without the need for additional fine-tuning. This line of research was pioneered in the seminal works of \citet{song2019generative}, \citet{kadkhodaie2020solving}, \citet{song2021score}, and \citet{kawar2021snips}, where the sampling process described in the previous section is adapted on-the-fly to address Bayesian inverse problems. In this setting, the user observes a realization $\obs$ of a random variable $\bY \in \rset^\dimobs$, assumed to be drawn from the distribution with density 
$p_{\bY}(\obs) \eqdef \int \pot{0}{\bx}  \pdata{0}{}{\bx} \, \rmd \bx$, where $\pot{0}{\bx}$ is a likelihood term that encapsulates the knowledge of the \emph{forward model}. A typical example is inverse problems with Gaussian noise, \emph{i.e.} $\pot{0}{\bx} = \normpdf(\obs; \bfA(\bx), \bm\Sigma_\obs)$, where $\bfA : \rset^\dimx \to \rset^\dimobs$ and $\bm\Sigma_\obs$ is a covariance matrix. 
The objective is to recover plausible underlying signals $\bx$, for which prior information is encoded in $\pdata{0}{}{}$. This recovery is achieved by sampling from the posterior distribution
\[
\post{0}{}{\bx_0} \propto \pot{0}{\bx_0}  \pdata{0}{}{\bx_0}\eqsp.
\]
A common approach to constructing a sampler for this posterior distribution is to adopt the diffusion model framework by sequentially sampling from the smoothed distributions $\post{T}{}{}, \dotsc, \post{1}{}{}$, which are defined analogously to those introduced in the previous section:
\begin{equation}
    \label{eq:smoothed-posterior}
    \post{t}{}{\bx_t} \eqdef \int \fw{t|0}{\bx_0}{\bx_t}  \post{0}{}{\bx_0} \, \rmd \bx_0 \eqsp.
\end{equation}
Following the derivations above, sampling these distributions backwards in time is feasible provided that the conditional denoisers $(\denoiser{t}{}{}[\obs])_{t=1}^T$ are accessible. Each conditional denoiser is  defined by
\[
\denoiser{t}{}{\bx_t}[\obs] \eqdef \int \bx_0 \, \post{0|t}{\bx_t}{\bx_0} \, \rmd \bx_0,
\]
where the conditional posterior $\post{0|t}{\bx_t}{\bx_0}$ is given by
$\post{0|t}{\bx_t}{\bx_0} \propto \post{0}{}{\bx_0} \fw{t|0}{\bx_0}{\bx_t}$.
By analogy with the smoothed distributions defined for the prior, we obtain that
\begin{align}
    \label{eq:posterior-prior}
\post{t}{}{\bx_t} & \propto \int  \pot{0}{\bx_0} \fw{t|0}{\bx_0}{\bx_t} \pdata{0}{}{\bx_0} \, \rmd \bx_0 \nonumber \\
& \propto \pot{t}{\bx_t} \pdata{t}{}{\bx_t}, 
\end{align}
where 
\begin{equation}
    \label{eq:pot-defn}
    \pot{t}{\bx_t} \eqdef \int \pot{0}{\bx_0} \pdata{0|t}{\bx_t}{\bx_0} \, \rmd \bx_0, 
\end{equation} and we used that $\pdata{0}{}{\bx_0} \fw{t|0}{\bx_0}{\bx_t} =  \pdata{0|t}{\bx_t}{\bx_0} \pdata{t}{}{\bx_t}$.
Next, using the Tweedie formula, the posterior and prior denoisers can be related as 
\begin{equation} 
    \label{eq:posterior-denoiser}
    \denoiser{t}{}{\bx_t}[\obs] = \denoiser{t}{}{\bx_t} + \a^{-1} _t \std^2 _t \nabla \log \pot{t}{\bx_t} \eqsp. 
\end{equation}
This shows that in order to estimate $\denoiser{t}{}{}[\obs]$ we only need to estimate $\nabla \log \pot{t}{}$, as we already have access to a pre-trained parametric approximation of $\denoiser{t}{}{}$. A widely used approximation of this likelihood term \cite{ho2022video, chung2023diffusion}, which we will also use in the next section, is 
\begin{equation}
    \label{eq:dps}
    \hpot{t}{\bx_t}[\param] \eqdef \pot{}{\denoiser{t}{}{\bx_t}[\param]}, 
\end{equation} 
and amounts to approximating the posterior distribution $\pdata{0|t}{\bx_t}{\cdot}$ with a Dirac mass at $\denoiser{t}{}{\bx_t}[\theta]$, which we express as $\pdata{0|t}{\bx_t}{\cdot} \approx \delta_{\denoiser{t}{}{\bx_t}[\theta]}$ with a slight abuse of notation. To improve the quality of the sample, $\nabla \log \hpot{t}{\bx_t}[\param]$ is rescaled with a suitable weight (possibly depending on $\bx_t$); see \citep[Equation 8]{ho2022video} and \citep[Algorithm 1]{chung2023diffusion}. 
    Compared to previous works, methods that perform guidance using the approximation \eqref{eq:dps} incur additional computational overhead due to the calculation of a vector-Jacobian product when evaluating $\nabla \log \hpot{t}{\bx_t}[\param]$. Nevertheless, subsequent works using this approximation have shown remarkable improvements in performance across various applications; see for example \cite{song2022pseudoinverse, rozet2023score, yu2023freedom, wu2023practical,jiang2023motiondiffuser,rozet2024learning, moufad2024variational}. 

% , where the likelihood function $\bx \mapsto \pot{}{\bx}$ is assumed to be known in closed form,