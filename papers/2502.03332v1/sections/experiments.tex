\begin{table*}[t]
    \centering
    \captionsetup{font=small}
    \caption{Mean LPIPS for linear/nonlinear imaging tasks on the \ffhq\ and \imagenet\ datasets with $\stdobs = 0.05$. Lower metrics are better.
    % First is \first{\transparent{0}{tx}}, second \second{\transparent{0}{tx}} and third \third{\transparent{0}{tx}}
    }
    \resizebox{\textwidth}{!}{
    \begin{tabular}{l cccccccc | cccccccc}
        \toprule
        \vspace{1mm}
        & \multicolumn{8}{c}{\bf{\ffhq}} & \multicolumn{8}{c}{\bf{\imagenet}} \\
        % \cmidrule(lr){2-7} \cmidrule(lr){8-13}
        \textbf{Task} & {\bf \algo} & \dps & \pgdm & \ddnm & \diffpir & \reddiff & \daps & \pnpdm \ &\ {\bf \algo} & \dps & \pgdm & \ddnm & \diffpir & \reddiff & \daps & \pnpdm \\
        \midrule
        SR ($\times 4$)        & \first{0.09} & \first{0.09} & 0.30 & \third{0.15} & \second{0.10} & 0.39 & 0.16 & \second{0.10} \ &\ \second{0.26} & \first{0.25} & 0.56 & 0.34 & \third{0.31} & 0.57 & 0.37 & 0.66 \\
        SR ($\times 16$)       & \second{0.24} & \first{0.23} & 0.42 & 0.33 & \first{0.23} & 0.55 & 0.40 & \third{0.29} \ &\ \third{0.55} & \first{0.44} & 0.62 & 0.71 & \second{0.50} & 0.85 & 0.75 & 1.03 \\
        Box inpainting         & \first{0.10} & 0.17 & 0.17 & \second{0.12} & 0.14 & 0.19 & \third{0.13} & 0.18 \ &\ \first{0.23} & 0.35 & \third{0.29} & \second{0.28} & 0.30 & 0.36 & 0.30 & 0.42 \\
        Half mask              & \first{0.20} & \third{0.24} & \third{0.24} & \second{0.23} & 0.25 & 0.28 & \second{0.23} & 0.32 \ &\ \first{0.31} & 0.40 & \second{0.34} & \third{0.38} & 0.40 & 0.46 & 0.40 & 0.54 \\
        Gaussian Deblur        & \first{0.12} & \third{0.17} & 0.87 & 0.20 & \first{0.12} & 0.24 & 0.24 & \second{0.14} \ &\ \first{0.30} & \second{0.37} & 1.00 & \third{0.45} & \first{0.30} & 0.53 & 0.59 & 0.76 \\
        % \vspace{2mm} % hack to leave space between linear and nonlinear task
        Motion Deblur          & \first{0.09} & \second{0.17} & $-$ & $-$ & $-$ & 0.22 & \third{0.19} & 0.21 \ &\ \first{0.22} & \third{0.40} & $-$ & $-$ & $-$ & \second{0.39} & 0.42 & 0.52 \\
        % \cmidrule(lr){1-13}
        JPEG (QF = 2)          & \first{0.14} & 0.34 & 1.12 & $-$ & $-$ & 0.32 & \second{0.22} & \third{0.29} \ &\ \first{0.38} & 0.60 & 1.32 & $-$ & $-$ & \third{0.49} & \second{0.45} & 0.56 \\
        Phase retrieval        & \first{0.11} & 0.40  & $-$ & $-$ & $-$ & \third{0.26} & \second{0.14} & 0.34 \ &\ \second{0.55} & 0.62 & $-$ & $-$ & $-$ & \third{0.61} & \second{0.50} & 0.66 \\
        Nonlinear deblur       & \first{0.27} & 0.51 & $-$ & $-$ & $-$ & 0.68 & \second{0.28} & \third{0.31} \ &\ \first{0.41} & 0.82 & $-$ & $-$ & $-$ & \third{0.66} & \first{0.41} & \second{0.49} \\
        HDR    & \second{0.12} & 0.40 & $-$ & $-$ & $-$ & 0.20 & \second{0.10} & \third{0.19} \ &\ \third{0.21} & 0.84 & $-$ & $-$ & $-$ & \second{0.19} & \first{0.14} & 0.31 \\
        \bottomrule
    \end{tabular}
    }
    \label{table:lpips-ffhq-imagenet}
\end{table*}
We evaluate \algo\ on image inverse problems using both pixel-space and latent-space diffusion, as well as on musical source separation tasks. 
For the pixel-space diffusion and the audio diffusion model, we compare \algo\ against \emph{eight} competitors: \dps\ \cite{chung2023diffusion}, \pgdm\ \cite{song2022pseudoinverse}, \ddnm\ \cite{wang2023zeroshot}, \diffpir\ \cite{zhu2023denoising}, \reddiff\ \cite{mardani2024a}, \daps\ \cite{zhang2024daps}, and \pnpdm\ \cite{wu2024pnpdm}.
In the latent space setting, we benchmark against \emph{four} competitors: \psld\ \cite{rout2024solving}, \resample\ \cite{song2024solving}, \daps\ \cite{zhang2024daps}, and \pnpdm\ \cite{wu2024pnpdm}. In Appendixes~\ref{apdx-sec:hyperparameters}-\ref{apdx:competitors}, we provide a complete formal description of the parameters of our algorithm as well as the implementation details of each competitor and its hyperparameters. We emphasize that we have tuned the parameters of our algorithm per dataset and not per task. 

\emph{Index sampling and Gibbs steps.} During the first $75\%$ of the diffusion process, at timestep $t_i$, we sample the index $s$ from $\mbox{Uniform}[\tau, t_{i-1}]$ with $\tau = 10$ to mitigate instabilities. In the final $25\%$ of the steps we set $s = t_{i-1}$ as this yields slightly improved results. On the image inverse problems we use $100$ diffusion steps with $R=1$ Gibbs step. On the source separation task we use $20$ diffusion steps with $R=6$ Gibbs steps. The choice of weight sequence $\{\wght^\ell _t\}^{2, t-1} _{t=T, \ell=1}$ plays an important role for the algorithm's performance. Intuitively, it holds that that $\hpot{t}{}[s] \approx \pot{t}{}$ when $s \approx 0$, suggesting that for all $t \in \intset{2}{T}$, the weights should be set to $0$ beyond a certain threshold to ensure that $s$ is sampled near $0$. We found, however, that this strategy does not yield good performance for our algorithm. Instead, sampling the index uniformly leads to a faster mixing. On high-dimensional image datasets, we observe that when $s$ is consistently sampled near $0$ at all iterations, the algorithm struggles to overcome the errors that accumulate at initialization, leading to suboptimal reconstructions. We provide both quantitative and qualitative evidence in \Cref{apdx-sec:weight-seq}. 

\textbf{Images.} 
We evaluate our method on a diverse set of six linear inverse problems and four nonlinear inverse problems with three different image priors with $256\times256$ resolution: the pixel-space \ffhq\ model of \citet{choi2021ilvr}, the latent-space \ffhq\ of  \citet{rombach2022high}, and the \imagenet\ model of \citet{dhariwal2021diffusion}. We use the noise level $\stdobs = 0.05$ for all tasks. The linear problems include image inpainting with two masking configurations: a $150 \times 150$ central box mask and a half-mask covering the right side of the image; Super Resolution (SR) tasks with upscaling factors of $\times 4$ and $\times 16$;
Gaussian and motion deblurring, both using a kernel size of $61 \times 61$ following the experimental setup described by \citet[Section 4]{chung2023diffusion}.
For the nonlinear setting, we consider JPEG dequantization with a quality factor of $2\%$, implemented using the differentiable operator proposed by \citet{shin2017jpeg}; phase retrieval with an oversampling factor of $\times 2$; non-uniform deblurring using the operator introduced by \citet{tran2021non-uniform-deblurring}; High Dynamic Range (HDR) reconstruction following the setup detailed in \citet[Section 5.2]{mardani2024a}. The evaluation is done on a subset of 300 validation images per dataset. For \ffhq, we use the first 300 images, while for \imagenet, we randomly sample 300 images to avoid class bias. We report the LPIPS metric \cite{zhang2018lpips} in Tables~\ref{table:lpips-ffhq-imagenet} and \ref{table:lpips-ffhq-ldm} and defer the complete tables with PSNR and SSIM to Tables~\ref{table:extended-ffhq-imagenet} and \ref{table:extended-ffhq-ldm}. For the phase retrieval task specifically, we draw 4 samples for each algorithm and keep only the best scoring one in terms of LPIPS. A similar strategy is used in \cite{chung2023diffusion,zhang2024daps,wu2024principled}. 
% in \Cref{table:extended-ffhq-imagenet} and \Cref{table:extended-ffhq-ldm}.
Across table rows, we highlight the best value in \first{\transparent{0}{tx}}, the 2\textsuperscript{nd} best in \second{\transparent{0}{tx}} and 3\textsuperscript{rd} best in \third{\transparent{0}{tx}}. We provide a large gallery of exemplar reconstructions in \Cref{apdx-sec:visual-reconstructions}. 

\emph{Results.} Our method with a single Gibbs step consistently achieves competitive performance, ranking first on most tasks and standing out as the only approach to maintain robust performance across all tasks. On latent \ffhq, we outperform \resample\ and \psld, both of which are specifically designed for latent problems, while our method is applied seamlessly off-the-shelf without any adaptation to latent diffusion. Qualitative comparisons in \Cref{fig:main-reconstructions} and in \Cref{apdx-sec:visual-reconstructions} reveal that our method provides diverse, visually coherent and sharp reconstructions. In contrast, \daps, \ddnm\ and \diffpir, despite scoring higher in PSNR and SSIM on some tasks, provide less coherent reconstructions; see \Cref{apdx:extended-results} for a discussion and examples. 
Finally, a key strength of our algorithm is its ability to improve performance by increasing the number  $R$  of Gibbs steps. This is demonstrated for the most challenging task, phase retrieval, in \Cref{fig:scaling}. In this experiment, we compute the LPIPS using a single sample per image (instead of four) and achieve a threefold reduction in average LPIPS simply by increasing the compute time in the right direction. Indeed, increasing the number of gradient steps brings only marginal gains in this case whereas increasing the number of Gibbs steps leads to significant performance gains.
\begin{table}[t]
    \centering
    \captionsetup{font=small}
    \caption{Mean LPIPS for linear/nonlinear imaging tasks on \ffhq\ dataset with LDM prior and $\stdobs = 0.05$.
    Lower metrics are better.
    % First is \first{\transparent{0}{tx}}, second \second{\transparent{0}{tx}} and third \third{\transparent{0}{tx}}
    }
    \resizebox{0.45\textwidth}{!}{
    \begin{tabular}{l ccccc}
        \toprule
        Task & \algo\ & \resample & \psld & \daps & \pnpdm \\
        \midrule
        SR ($\times 4$) & \first{0.14} & \third{0.22} & \second{0.21} & 0.28 & 0.40 \\
        SR ($\times 16$) & \first{0.30} & \third{0.38} & \second{0.36} & 0.52 & 0.71 \\
        Box inpainting & \first{0.18} & \second{0.22} & \third{0.27} & 0.37 & 0.31 \\
        Half mask & \first{0.26} & \second{0.30} & \third{0.32} & 0.49 & 0.44 \\
        Gaussian Deblur & \second{0.18} & \first{0.16} & 0.59 & \third{0.32} & 0.32 \\
        % \vspace{2mm} % hack to leave space between linear and nonlinear task
        Motion Deblur & \second{0.22} & \first{0.20} & 0.70 & \third{0.36} & 0.36 \\
        % \cmidrule(lr){1-6}
        JPEG (QF = 2) & \first{0.23} & \second{0.26} & $-$ & \third{0.32} & 0.36 \\
        Phase retrieval & \second{0.29} & \third{0.39} & $-$ & \first{0.25} & 0.50 \\
        Nonlinear deblur & \first{0.29} & \second{0.33} & $-$ & \third{0.37} & 0.37 \\
        High dynamic range & \second{0.16} & \first{0.12} & $-$ & \third{0.24} & 0.24 \\
        \bottomrule
    \end{tabular}
    }
    \label{table:lpips-ffhq-ldm}
\end{table}
\begin{figure}
    \centering
    \renewcommand{\arraystretch}{1.2} % Adjust row spacing if needed
    \resizebox{0.482\textwidth}{!}{
    \begin{tabular}{c  r}
        % First column: Table
        \raisebox{112pt}[0pt][0pt]{
        % \resizebox{0.70\textwidth}{!}{
        %     \begin{tabular}{l>{\columncolor{babypink!60}}ccc}
        %         \toprule
        %         Task & $\mu_{\mathrm{mixt.}}$ & $\mu_{\mathrm{zero}}$ & $\mu_{\mathrm{det.}}$  \\
        %         \midrule
        %         Phase retrieval  & {\bf 0.10} & 0.53 & 0.43  \\
        %         SR ($\times 16$) & - & - & - \\
        %         Box inpainting & - & - & -  \\
        %         Half mask & - & - & -  \\
        %         \bottomrule
        %     \end{tabular}
        % } 
        \resizebox{0.82\textwidth}{!}{
        \begin{tabular}{l cccc | c}
            \toprule
                & $R=1$ & $R=2$ & $R=4$ & $R=6$ & $R=1,G\gg1$ \\
            \midrule
            Bass & 15.46 & 18.07 & \second{18.53}  & \third{ 18.49}  & \first{19.89} \\
            Drums & 16.28 & 17.93 & \second{18.19} & \third{ 18.07} & \first{18.95} \\
            Guitar & 12.58 & 14.73 & \third{16.26} & \first{ 16.68} & \second{16.07} \\
            Piano & 11.82 & 14.34 & \third{15.38}  & \second{16.17} & \first{16.50} \\
            \bottomrule
            All & 14.03 & 16.27 & \third{17.09} & \second{17.35} & \first{17.85} \\
            \bottomrule
        \end{tabular}
        }
        }
        &
        % Second column: Figure
        \includegraphics[width=0.5\textwidth]{figures/phase_retrieval.pdf}
    \end{tabular}
    }
    \vspace*{-1mm}
    \captionsetup{font=small}
    \caption{Performance of \algo\ as a function of the number of Gibbs steps $R$.
    The setup $R=1,G\gg1$ represents \algo\ with $R=1$ and a number of gradient steps resulting in a runtime equivalent to using $R=6$.
    Left: Mean \sisdri\ for multisource--audio separation task on \slakh\ test dataset.
    Right: Mean LPIPS for the phase retrieval task on \ffhq.}
    \vspace*{-3mm}
    \label{fig:scaling}
\end{figure}

\textbf{Source separation.} 
We now consider a linear inverse problem with an audio diffusion prior that generates four dependent instrument soundtracks: bass, drums, guitar, and piano. The task involves separating the individual sources from a mixture $\obs$ of these four instruments; \emph{i.e.} denoting by $\dimx^\prime$ the dimension of one instrument soundtrack, the linear operator is $\bfA: \bx \in \rset^{4 \times \dimx^\prime} \mapsto \sum_{i = 1}^4 \bx_i \in \rset^{\dimx^\prime}$. We assume \emph{no noise} in the measurement and use the audio diffusion model of \citet{mariani2023multi}. The evaluation is conducted on the publicly available \slakh\ test dataset \cite{Manilow2019slakh} with the scale-invariant SDR improvement ($\text{SI-SDR}_\text{I}$) metric \cite{le2019sdr}. The $\text{SI-SDR}_\text{I}$ metric measures the improvement between the original audio source $\mathbf{x}_i$ and the generated source $\hat{\mathbf{x}}_i$, relative to the mixture baseline $\mathbf{y}$, \emph{i.e.} it computes the difference $\text{SI-SDR}(\mathbf{x}_i, \hat{\mathbf{x}}_i) - \text{SI-SDR}(\mathbf{x}_i, \mathbf{y})$ where 
\[
\text{SI-SDR}(\mathbf{x}_i, \hat{\mathbf{x}}_i) = 10 \log_{10} \frac{\| \alpha \mathbf{x}_i \|^2 + \epsilon}{\| \alpha \mathbf{x}_i - \hat{\mathbf{x}}_i \|^2 + \epsilon} \eqsp,
\] where $\alpha = \frac{\mathbf{x}_i ^\top \hat{\mathbf{x}}_i  + \epsilon}{\| \mathbf{x}_i \|^2 + \epsilon}$, and $\epsilon = 10^{-8}$. Following \citet[Section 5.2]{mariani2023multi}, tracks from the test dataset are evaluated using a sliding window approach with 4-second chunks and a 2-second overlap. We report the $\text{SI-SDR}_\text{I}$ metric in Table \ref{table:si-snri}. 
For this task we compare against three other competing algorithms. First, the best version of the MSDM algorithm in \cite{mariani2023multi} which uses the same pre-trained model and is directly comparable to our method. Then, the ISDM algorithm from the same paper and which relies on separate pre-trained models for each instrument, as well as the Demucs model \cite{defossez2019music}, trained with supervision to specifically solve source separation, augmented with 512 Gibbs sampling steps \cite{manilow2022improving} and is, to the best of our knowledge, considered to be state-of-the-art. We refer to it as \demucs. Finally, since the inverse problem is noiseless, we smooth it by using the likelihood $\pot{0}{\bx} = \normpdf(\obs; \bfA(\bx), \std^2 _\obs \Id_\dimobs)$ with $\std_\obs = 10^{-4}$. This smoothing is applied consistently across all competitors except the best-performing versions of MSDM and ISDM, which are tailored for noiseless problems, and \(\demucs\). The results are reported in \Cref{table:si-snri} \footnote{Due to space constraints we only show the best performing competitors and defer the complete table to \Cref{apdx:extended-results}}. 

\emph{Results.} We outperform, on average, the other training-free competitors that use the same pre-trained model by a substantial margin. In particular, we outperform the MSDM algorithm of \citet{mariani2023multi} as well as ISDM which uses a different model. With $R = 6$ Gibbs steps \algo\ falls short of matching the performance \demucs. We found instead that setting $R = 1$ and using a number of gradient steps ensuring equivalent runtime, as we did for the phase retrieval example, allows to achieve superior performance; see \Cref{fig:scaling}. It is also seen that the average \sisdri\ increases monotonically with the number of Gibbs steps. 
 
\begin{table}[t]
    \centering
    \captionsetup{font=small}
    \caption{Mean \sisdri\ on \slakh\ test dataset. The last row displays the mean over the four stems. Higher metrics are better.}
    \resizebox{0.48\textwidth}{!}{
    \begin{tabular}{l ccccc | cc}
        \toprule
        Stems  & \algo\         & \dps              & \pgdm             & \ddnm             &  \msdm            & \isdm             & \demucs \\
        \midrule
        Bass   & \first{18.49}  &  \third{16.50}    &  16.41            & 14.94             &  \second{17.12}   & 19.36     & 17.16   \\
        Drums  & 18.07          &  \third{18.29}    & 18.14             & \first{19.05}     &  \second{18.68}   & 20.90     & 19.61   \\
        Guitar & \first{16.68}  &   9.90            &  12.84            & \third{14.38}     &  \second{15.38}   & 14.70     & 17.82   \\
        Piano  & \first{16.17}  &  10.41            &  \third{12.31}    & 11.46             &  \second{14.73}   & 14.13     & 16.32   \\
        \midrule
        All    & \first{17.35}  &  13.77            &  14.92            & \third{14.96}     &  \second{16.48}   & 17.27     & 17.73   \\
        \bottomrule
    \end{tabular}
    }
    \label{table:si-snri}
\end{table}
