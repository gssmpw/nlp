\section{Related Work}
\textbf{Ensemble Learning:} 
Ensemble learning intends to combine models to produce more accurate and reliable predictions. Similar to our work, the error correlation between these models is of interest. The greater the extent of error independence between the models, the better the performance of the ensemble \cite{Breiman1996BaggingP,Kuncheva2003MeasuresOD}. Several measures have been introduced in the literature to quantify this concept of diversity, including pairwise measures such as the Q-statistic, correlation coefficient, and disagreement measure \cite{Kuncheva2003MeasuresOD, disagreement}. Non-pairwise measures are also widely employed, often based on the average variation in models' losses \cite{Wood2023AUT}. In addition to improving performance, research shows that diverse ensembles are robust against adversarial attacks \cite{Biggio2011, Pang2019ImprovingAR} and can counteract covariate shift \cite{sinha2021dibs}. These benefits have also motivated the investigation into understanding and quantifying model diversity and correlations in this paper. 

\textbf{Error variance analysis:} Model selection in ML is often done by computing errors either on a hold-out set or via cross-validation. For reliable model selection, an accurate grasp on the variance of these errors and its estimation is paramount. Several previous works have developed theoretical framework to analyze this variance. Already in \cite{PatternRecog}, authors derived bounds for the variance of cross-validation for nearest neighbor type algorithms. The difficulty of accurately estimating this variance has been studied extensively in \cite{StatisticalTestsDietterich,InferenceGeneralizationError,NoUnbiasedYoshau}. Furthermore, the authors in \cite{InferenceGeneralizationError} investigated the theoretical and practical merits of different variance estimation techniques for cross-validation. We refer to \cite{BiasErrorEstimation,ResidualVariance,VarianceAnalysisCV,ProblemCV} for additional works on the same topic.

\textbf{Comparison to current work:} While the ensemble model literature primarily emphasizes leveraging diversity to enhance an ensemble model's predictive performance and robustness, this study focuses on identifying scenarios where models exhibit significant correlations. Recognizing such scenarios is crucial for developing strategies to mitigate risks, such as widespread failures caused by adversarial attacks and data drift. By studying these correlations, we aim to establish a robust framework for risk management, which would help in enhancing the reliability and resilience of machine learning models in real-world applications.

The aforementioned error variance analysis has focused primarily on errors resulting from one model. However, the current work is concerned with identifying scenarios where errors from \textit{different} models could be correlated, and numerically investigating these correlations for state-of-the-art models. To the best of our knowledge, ours is the only work that examines such correlations. We argue that our framework that considers multiple models deployed simultaneously is closer to real life scenarios where multiple models are deployed for similar applications, resulting in correlations.