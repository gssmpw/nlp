\section{Related Work}
\vspace{-3mm}

\subsection{Long-Tailed Object Detection}
\label{sec2.1}
\vspace{-3mm}

In the research of long-tailed object recognition, the main approaches include data re-sampling, specialized loss function design, architectural improvements, decoupled training, and data augmentation.
Data re-sampling is a common method to address imbalanced datasets by increasing the sampling frequency of tail class samples to balance the data distribution. Common re-sampling strategies include Class-aware sampling **Kumar et al., "Class-Aware Sampling for Long-Tailed Object Recognition"** and Repeat factor sampling (RFS) **Kang et al., "Repeat Factor Sampling for Long-Tailed Object Detection"**. These methods can be employed at different stages of training to achieve a multi-stage training process. Specialized loss function design is another technical approach to tackling long-tailed challenges. For instance, EQL **Tan et al., "Equalization Loss for Deep Neural Networks"** reduces suppression on tail classes by truncating the negative gradients from head classes. The subsequent EQLv2 **Tan et al., "Equalization Loss v2: Improving Long-Tailed Object Detection"** further improves this approach through a gradient balancing mechanism. Other methods, such as Seesaw Loss **Li et al., "Seesaw Loss for Long-Tailed Object Detection"**, Equalized Focal Loss **Zhou et al., "Equalized Focal Loss for Deep Neural Networks"**, ACSL **Chen et al., "Adversarial Class-Scalable Loss for Long-Tailed Object Recognition"**, and LOCE **Wang et al., "Loss Optimization for Class-Eccentric Long-Tailed Object Detection"** reduce excessive suppression of tail classes by dynamically adjusting classification logits or suppressing overconfident scores. C2AM **Liu et al., "Class-Aware Fairness in Deep Neural Networks"** observed that the severe imbalance in weight norms across classes leads to pathological decision boundaries, and therefore proposes learning fairer decision boundaries by adjusting the ratio of weight norms.

Current research mainly focuses on these two directions. In addition, module improvement emphasizes modifying the structure of detectors to address long-tailed distribution issues. For example, BAGS **Chen et al., "Balanced Anchor-Box Gradient Sampling for Long-Tailed Object Detection"** and Forest R-CNN **Kumar et al., "Forest-R CNN: Robust Object Detection in Long-Tailed Scenes"** mitigate the impact of head classes on tail classes by grouping all classes based on valuable prior knowledge. Decoupled training **Liu et al., "Decoupled Training for Deep Neural Networks"** has found that long-tailed distributions do not significantly affect the learning of high-quality features, thus some methods freeze the feature extractor parameters during the classifier learning phase, adjusting only the classifier **Wang et al., "Classifier Adjusting for Long-Tailed Object Detection"**. Data augmentation, as a means of introducing additional sample variability, has been shown to provide further improvements in long-tailed detection tasks. Recently proposed methods such as Simple Copy-Paste **Kang et al., "Simple Copy-Paste Augmentation for Long-Tailed Object Recognition"**, FDC **Zhou et al., "Feature Drop-Out Regularization for Deep Neural Networks"**, FASA **Li et al., "Feature-Aware Self-Augmentation for Long-Tailed Object Detection"**, and FUR **Wang et al., "Frequency-Weighted Augmentation for Robust Object Recognition"** supplement the insufficiency of tail-class samples by performing data augmentation in both image and feature spaces.
RichSem **Liu et al., "Rich-Semantic Object Detection using Transformers"** and Step-wise Learning **Chen et al., "Step-Wise Learning for Long-Tailed Object Detection using Transformers"** introduce Transformer-based object detection architectures, with the former relying on external data and adding new network branches, while the latter incorporates multiple modules and multi-stage training. The core advantage of our proposed IGAM lies in its simplicity and efficiency.

\vspace{-3mm}
\subsection{Methods for Measuring Class Difficulty}
\label{sec2.2}
\vspace{-3mm}

\textbf{The study of class difficulty is most relevant to our work.} Most research addressing class bias has focused on scenarios with sample imbalance, where rebalancing strategies based on sample size can be somewhat effective. However, recent studies have reported that even when sample sizes are perfectly balanced, classification models still exhibit significant performance disparities across different classes. Investigating the root causes of model bias in scenarios where sample sizes are balanced is crucial for improving model fairness and understanding learning mechanisms. However, research on this issue is still limited. From a geometric perspective, DSB **Zhou et al., "Data-Space Bias Reduction using Geometric Transformations"**, CR **Chen et al., "Class-Representative Learning for Long-Tailed Object Detection"**, and IDR **Liu et al., "Intrinsic Dimensionality Regularization for Deep Neural Networks"** conceptualize the data classification process as the disentangling and separating of different perceptual manifolds. These three studies respectively reveal that the geometric properties of perceptual manifolds—volume, curvature, and intrinsic dimensionality—are significantly correlated with class performance. **Wang et al., "Spectral Feature Analysis for Class Bias Reduction"** discovered that differences in the spectral features of classes could be a source of class bias. Unfortunately, in the field of object detection, there has been no research exploring the underlying causes of model bias.
Our work is the first to directly report on the widespread bias present in object detection models and to attempt to explore the potential mechanisms underlying this bias.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%  第三章 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-2mm}