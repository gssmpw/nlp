Large language models (LLM) have revolutionized the landscape of natural language processing, emerging as general-purpose foundation models with remarkable abilities across multiple  domains~\cite{achiam2023gpt,touvron2023llama}.
% Beyond traditional text tasks, LLMs have demonstrated their effectiveness in various domains.
In particular, their application in biomolecular studies has recently gained significant interest, motivated by the potential to profoundly accelerate scientific innovation and drug discovery applications~\cite{zhang2024scientific,pei2024leveraging,chaves2024tx}. LLMs provide novel ways to understand and reason about molecular data, building on the wealth of available scientific literature. Additionally, their reasoning and zero-shot abilities help overcome the limitations of task-specific deep learning models, streamlining data needs and improving human-AI collaboration \cite{fang2023mol,yu2024llasmol}. 

However, given the inherent complexity and specialized nature of the field, recent works emphasize the importance of domain-specific fine-tuning to boost tasks such as molecular captioning, property prediction, or binding affinity prediction~\cite{fang2023mol,chaves2024tx,yu2024llasmol,edwards2024molcap}. Consequently, rather than employing readily available general-purpose LLMs, most efforts in drug discovery have focused on fine-tuning LLMs using biochemical annotations or instruction-tuning datasets.
%While promising, solely relying on such approaches poses critical challenges hindering the application of recent advancements in AI to drug discovery applications.

While promising, solely relying on these approaches poses significant challenges that can limit applications.
On one hand, the rapid emergence of new LLM architectures and techniques \cite{minaee2024large,zhao2023survey} complicates maintaining domain-specific models obtained through expensive fine-tuning.
More importantly, drug discovery applications often require promptly incorporating new insights as they become available, for example, as a result of new experiments or through the scientific literature---a process exacerbated by the automation of experimental workflows~\cite{tom2024self}. In addition to being impractical, regular rounds of fine-tuning to keep LLMs up-to-date with the latest scientific advances also introduce challenges such as catastrophic forgetting~\cite{luo2023empirical}.
% However, continuously incorporating new knowledge into already fine-tuned domain-specific or general-purpose LLMs is complex and impractical, also introducing challenges such as catastrophic forgetting~\cite{luo2023empirical}.
% , where the model loses previously learned information~\cite{luo2023empirical}. Therefore, we identify the need to develop methods that can readily incorporate new data in a flexible way, empowering general-purpose LLMs with such information tackling drug discovery questions. 

From this perspective, retrieval-augmented generation (RAG) methods offer a promising solution that enables dynamic adaptation of the model's knowledge without the need for expensive fine-tuning \cite{gao2023retrieval,fan2024survey}.
%RAG-based systems have found success across many domains, dynamically and adaptively incorporating information from search queries, documents, and knowledge bases, grounding LLM outputs.
However, applying this paradigm in the drug discovery domain presents important obstacles. First, retrieving relevant knowledge is difficult due to the limited domain expertise of general-purpose LLMs, combined with the vastness of the chemical space \cite{bohacek1996art} that renders exact retrieval suboptimal.
%\footnote{The chemical space is estimated to encompass up to $10^{60}$ drug-like compounds \cite{bohacek1996art}
% rendering exact retrieval impractical.
Second, biochemical data is extremely heterogeneous, spanning diverse modalities such as molecules, proteins, diseases, and complex relationships between them~\cite{wang2023scientific}. Such data can also exist across multiple sources, introducing challenges in factual integration~\cite{harris2023large}.
Finally, the available information is not necessarily relevant to the query, as it may be too general, ambiguous, or partial \cite{vamathevan2019applications}.

% In this study, we tackle these challenges introducing~\proposed, a RAG-empowered LLM multi-agent framework for molecular question-answering, with a primary focus on drug discovery. 
In this study, we tackle these challenges by introducing a \textbf{C}ollaborative framework of \textbf{L}LM \textbf{A}gents for \textbf{D}rug \textbf{D}iscovery (\proposed).
We assume a general setting where external knowledge is available as expert annotations associated with molecules or as knowledge graphs that flexibly represent diverse biochemical entities and their relationships. 
% ~\proposed leverages external knowledge for diverse drug discovery tasks.
% \proposed is powered by general-purpose LLMs and the external knowledge can be updated dynamically without LLM fine-tuning, ensuring adaptability.
\proposed is powered by general-purpose LLMs, while also integrating domain-specific LMs, when necessary, to improve molecular understanding. Notably, external knowledge can be updated dynamically without LLM fine-tuning. %, ensuring adaptability.

The multi-agent collaborative framework enables each agent to specialize in a specific data source and/or role based on their team, offering a modular solution that can improve overall information processing~\cite{chan2024chateval}. 
In particular, \proposed includes a \emph{Planning Team} to determine relevant data sources, 
a \emph{Knowledge Graph Team} to retrieve  external heterogeneous information in the knowledge graph and summarize it, also through a novel anchoring approach to retrieve related information when the query molecule is not present in the knowledge base, 
and a \emph{Molecule Understanding Team}, which analyzes the query molecule based on its structure along with summaries of external data and tools.
The flexibility of the framework enables \proposed~to address a wide range of tasks for drug discovery, including zero-shot settings, while also improving interpretability through the transparent interaction of its agents.

% The flexibility of the question-answering setting enables addressing a wide range of tasks, including zero-shot settings,
% %making it particularly effective for complex scenarios and low-data regimes,
% while also improving interpretability in the process.

Overall, we highlight the following contributions:
\begin{itemize}[leftmargin=.1in]
    \item We present~\proposed, a multi-agent framework for RAG-based question-answering in drug discovery applications. The framework leverages generalist LLMs and dynamically integrates external biochemical data from multiple sources without requiring fine-tuning.
    \item We demonstrate the flexibility of the framework by tackling diverse applications, including property-specific molecular captioning, drug-target prediction, and molecular toxicity prediction. %, and single-cell perturbation prediction tasks.
    \item We provide comprehensive experimental results showcasing the effectiveness of \proposed compared to general-purpose and domain-specific LLMs, as well as standard deep learning approaches. A further appeal of \proposed~is its flexibility and explainability, improving the interaction between scientists and AI.
    % Extensive ablation studies and case analyses highlight the framework's seamless ability to retrieve, integrate, and utilize external knowledge to address drug discovery-related questions. 
\end{itemize}

\begin{figure*}[t]
\vspace{-6pt}
    \centering
    \includegraphics[width=0.85\linewidth]{imgs/Figure1.pdf}
    \vspace{-5pt}
    \caption{
    \textbf{Overview of \proposed}.
    \textbf{(a)} General overview. Given a question about a molecule (SMILES representation), the Planning Team first evaluates the relevant data sources and models.  
    If the knowledge graph is considered relevant, a dedicated report will be created by the Knowledge Graph Team.
    The Molecule Understanding Team creates a report on the molecule based on the relevant annotation databases and tools.
    The generated reports are integrated by the Prediction Agent and used to produce the final answer. 
    \textbf{(b)} Detailed overview of the Planning Team. The Molecular Annotation Planner decides whether to use additional captioning tools to complement the information associated with the molecule. \textbf{(c)} Detailed overview of the Knowledge Graph Team. The Drug Relation and Biological Relation Agents retrieve information from the knowledge graph based on the anchor drug, the related drugs, and the set of relations between the anchor and related drugs (cfr. Section~\ref{sec:KnowledgeGraphTeam}).
    % (b) Detailed overview of the Planning Team. The Molecular Annotation Planner assesses the quality of the available evidence in the molecular annotation database and can decide to use additional captioning tools. 
    % The Knowledge Graph Planner computes the similarity between the query molecule and the most similar drug in the KG (anchor drug). Based on this information, it decides whether to use the KG by calling the Knowledge Graph Team.
    % (c) Overview of the KG retrieval process. The Drug Relation Agent computes a report based on the query drug, the anchor drug, and related drugs. The Biological Relation Agent computes a report based on the anchor drug, the related drugs, and the set of relations between the anchor and related drugs. See Section~\ref{sec:KnowledgeGraphTeam} for the definition of related drugs.
    }
    \label{fig:fig1}
    \vspace{-10pt}
\end{figure*}
