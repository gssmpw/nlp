\begin{table}[thpb]
\centering
\caption{Ablation on masking used for the pretraining of \tokenizer on TUEV Dataset}
\label{tab:masking_ablation}
\resizebox{\linewidth}{!}{%
% \begin{tabular}{l p{2.2cm} p{2.7cm} p{2.7cm} p{2.7cm} p{2.7cm} p{2.7cm} p{2.7cm}} %{lccccccc}
\begin{tabular}{lccc}
\toprule
\textbf{Masking Strategy}  &  \textbf{Balanced Acc.} & \textbf{Cohen's Kappa} & \textbf{Weighted F1} \\
\midrule


Random Masking &  $0.4351\pm0.0462$ &	$0.4772\pm0.0140$&	$0.7296\pm0.0076$\\
Frequency Bin Masking & $0.4673\pm0.0540$ &	$0.5193\pm0.0243$	&$0.7536\pm0.0125$\\
Frequency Bin  &  \multirow{2}{*}{$\mathbf{0.4946\pm0.0392}$} &	 \multirow{2}{*}{$0.5045\pm0.0221$}	& \multirow{2}{*}{$0.7462\pm0.0116$}\\
+ Temporal Masking & & & \\
\hline
Frequency Bin   & \multirow{3}{*}{$0.4943\pm 0.0516$}  &  \multirow{3}{*}{$\mathbf{0.5337\pm 0.0306}$}  &  \multirow{3}{*}{$\mathbf{0.7570\pm 0.0163}$}\\
+ Temporal Masking\\
+ Symmetric Masking\\
% & $0.5487\pm0.0038$ &	$0.4589\pm0.0045$ &	$0.5549\pm0.0044$  \\

\bottomrule

\end{tabular}
}
% \multicolumn{8}{l}{1. The number of parameters for LaBraM is only considering their classifier model. The size of their neural tokenizer used for masked EEG modeling training was 8.6M.} \\
\end{table}