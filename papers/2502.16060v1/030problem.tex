\begin{figure*}[t]
    \centering
    \includegraphics[width=0.98\linewidth]{FIG/TFM_main_method_fig_new_3.pdf}
    %{KDD2025_EEG_Tokenization/FIG/TFM_token_method_2.pdf}
    % \vspace{-.5cm}
    \caption{Overview of the \method framework. (a) \tokenizer Pretraining: Through dual-path encoding and masked prediction, learns to capture time-frequency motifs into discrete tokens. (b) \encoder Pretraining: Trains on learned EEG tokens using masked token prediction. (c) Masking Strategy: A combination of frequency band masking and temporal masking is used for \tokenizer pretraining. (d) Localized Spectral Window Encoder: Processes individual spectral windows from $\mathbf{S}$, extracts frequency band information, and aggregates features across all bands into a single compact embedding per window. }
    \label{fig:tfm_token}
\end{figure*}

\subsection{Notations and Problem Statements}
\noindent\textbf{EEG Data.}
Let $\X\in\mathbb{R}^{C\times T}$ denote a multi-channel EEG recording with $C$ channels and $T$ time samples. For each channel $c\in\{1,...,C\}$, we denote a single channel EEG by $x^c\in\mathbb{R}^T$. 
To capture complementary structures in both the time and frequency domains, we decompose $x^c$ into: (1) time-frequency representation $\mathbf{S}$ and (2) raw EEG patches $\{x_i\}_{i=1}^N$. For simplicity, we omit the channel index; henceforth, $x$ will refer to a single-channel EEG signal unless otherwise specified. 

\noindent\textbf{Short-Time Fourier Transform (STFT).}
To obtain the time-frequency representation, i.e.g, spectrogram, $\mathbf{S}$, we apply a STFT to $x$ using a windowing function $w(.)$ of length $L$ and a hop size $H$:
\begin{equation}
    \mathbf{S}(\omega,\tau) = \left|\sum_{l=0}^{L-1}x(\tau H +l)w(l)e^{\frac{-j2\pi\omega l}{L}} \right|
\end{equation}
where $\omega$ indexes the discrete frequencies and $\tau$ indexes the time segments (i.e., time windows shifted by $H$). We retain only the magnitude $|.|$ to form $\mathbf{S}\in \mathbb{R}^{F\times N}$, where $F$ is the number of frequency bins and $N$ is the number of time windows.
\\

% Additionally, we define an EEG token vocabulary $\mathcal{V}$ consisting of $k$ discrete tokens, $\mathcal{V}=\{v^1,v^2,...,v^k\}$. 

\noindent\textbf{Problem Statement 1 (EEG Tokenization):} Given a single channel EEG $x$, we aim to learn a tokenization function 
$$
f_{\text{tokenizer}}: \mathbb{R}^T \rightarrow \mathcal{V}^{N \times D}
$$
where $\mathcal{V}$ is a finite EEG token vocabulary of size $k$, and $D$ is the dimension of each token embedding. 
The tokenizer function $f_{\text{tokenizer}}$ should project $x$ (or transformations) into a sequence of discrete tokens $\{v_i\}_{i=1}^N$,
where each $v_i\in \mathcal{V}$.
These tokens represent various temporal and frequency ``\textit{motifs}'': meaningful EEG patterns characterized by distinct temporal and frequency characteristics. Therefore, $\mathcal{V}$ is learnbale from $\mathbf{S}$ and the temporal patches $\{x_i\}_{i=1}^N$.\\
\textbf{Remark.}
We here hold several expectations for the learned motif tokens.
First, these tokens are expected to reduce redundancy, noise, and complexity, providing a compact, sparse, and informative representation of EEGs.
Second, these motifs should effectively capture essential neurophysiological patterns from both temporal and frequency domains.
Third, the tokens should generalize well across different EEG tasks, enhancing the efficiency and interpretability of the data.
We set up related research questions to evaluate these expectations in Section.~\ref{sec:exp}.


\noindent\textbf{Problem Statement 2 (Multi-Channel EEG Classification):} 
% \noindent\textbf{Problem Statement 2 (Multi-Channel EEG Classification):} 
Given EEGs $\X$ and a fixed, learned single-channel tokenizer $f_{\text{tokenizer}}$, we apply $f_{\text{tokenizer}}$ independently to each channel $c$ to obtain a tokenization representation  $\Bigl\{\{v_i^c\}_{i=1}^N\Bigr\}_{c=1}^C$. 
Then, these tokens can serve various downstream tasks. For classification tasks, they are mapped to labels by:
$$
f_{\text{classifier}}: (\mathcal{V}^D)^{N \times C}\rightarrow \mathbf{Y}
$$
where $Y$ is the target labels (e.g., EEG events, seizure types). 
% Task-specific fine-tuning can then be performed.
By aggregating and processing the tokens across all channels, $f_{\text{classifier}}$ predicts a label $y\in\mathbf{Y}$. 
Notably, $f_{\text{classifier}}$ can be any downstream-oriented model, and its training is performed separately from the EEG tokenizer $f_{\text{tokenizer}}$.
% The learning objective is to minimize a loss function $\mathcal{L}_{\text{cls}}$, that measures the discrepancy between the prediction $\hat{y}$ and the ground-truth label $y$.


