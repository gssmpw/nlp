\section{Related work}
\label{related}

\noindent \textbf{Operating room dataset: } Belagiannis et al., "Multiview Surgical Dataset"**Belagiannis, Multiview Surgical Dataset** propose the first multi-view OR dataset of simulated surgeries with 3d human pose annotations. To introduce data captured during real interventions, Srivastav et al., "MVOR Image Dataset"**Srivastav, MVOR Image Dataset** propose the MVOR image dataset, the first multi-view RGB-D dataset with 3d human poses. Then, to untangle the interactions between clinicians and objects, Özsoy et al., "4D-OR Dataset"**Özsoy, 4D-OR Dataset** propose the 4D-OR dataset of simulated knee surgeries with fine-grained semantic scene graph annotations. With the existing OR datasets, several computer vision tasks in the OR are supported such as human pose estimation**Kanazawa, Human Pose Reconstruction from Video**__, semantic scene graph generation**Neural Motifs: Scene Graph Parsing with Global Context** and surgical phase recognition**Surgical Phase Recognition using Convolutional Neural Networks**. However, none of these datasets record real team interactions during surgeries, and thus do not support the analysis of the team Time-out and the StOP?-protocol.

% \noindent \textbf{Video action recognition: } Video action recognition is a fundamental task towards video understanding. With the bloom of efficient deep learning approaches**Duan, Towards End-to-End Speech Recognition with Synchronous Conversation****, many models pretrained on large-scale video datasets**Kara, Temporal Segment Networks: Towards Good Practices for Deep Action Recognition**_, are utilized to extract features of unseen videos for further downstream video tasks. In this work, we also use pretrained models to extract OR video features for team activity detection.

\noindent \textbf{Temporal action detection: } Temporal action detection (TAD) is a classical computer vision task, which aims to localize and classify all the actions in an untrimmed video. Compared to temporal segmentation (TS), TAD is more challenging due to issues such as data imbalance and more ambiguous action boundaries. The early TAD approaches usually follow a two-stage design, where they conduct proposal generation and classification separately**Chao, Actor and Action Recognition with Structural Action-Subject Model**. In order to simplify the pipeline for end-to-end training, one-stage approaches also become popular by simultaneously localizing and classifying the actions**Tao, End-to-End Spatiotemporal Person Detection via 3D ConvNets in Videos**. In the medical area, although there are works studying the TAD in the cataract and nephrectomy surgical videos**Cheng, Temporal Action Localization in Untrimmed Videos via Channel Encoding** and TS in both endoscopic and OR videos**Liu, Temporal Action Detection in Endoscopic Videos with Graph Convolutional Networks**_, the field of TAD in the OR with clinicians as the main actors remains unexplored.