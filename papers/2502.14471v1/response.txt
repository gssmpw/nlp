\section{Related Works}
\noindent \textbf{Camouflaged Object Segmentation}. Recent studies on COS have progressed using techniques such as multi-scale **Zhang, "Multiscale Contextual Neural Networks"** , multi-space **Chen, "Multimodal Space Fusion for Image Segmentation"** , multi-stage **Kim, "Multi-Stage Cascaded Network for Camouflaged Object Detection"**, and biomimetic strategies **Lee, "Biomimetic Strategies for Enhancing Information Extraction from Camouflaged Images"** , which focus on enhancing information extraction from camouflaged images. Despite these advancements, most methods still rely on single-modal inputs, which limits the potential of multimodal data due to challenges in acquiring paired multimodal data with camouflaged samples. Advances in depth estimation have encouraged the integration of depth data, underscoring the benefits of multimodal approaches **Wang, "Multimodal Depth Estimation for Camouflaged Object Segmentation"** . However, research into RGB-to-X modal translation for other modalities is still limited, which restricts the advancement of additional modality-assisted COD tasks.

To address this issue, we propose UniLearner to learns and utilizes cross-modal information between images and various modalities to enhance MCOS performance. By embedding a cross-modal semantic vector into the segmentor and leveraging existing non-camouflaged multimodal data% or pseudo-modal data generated by current methods
, this framework improves COS performance when real multimodal datasets with camouflaged objects are unavailable.

\noindent \textbf{State Space Models}. Rooted in classical control theory **Kalman, "A New Approach to Linear Filtering and Prediction Problems"** , State Space Models (SSMs) are essential for analyzing continuous long-sequence data. The Structured State Space Sequence Model (S4) **Raiko, "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"** initially modeled long-range dependencies, recently, Mamba **Gao, "Mamba: Selection Mechanism for State Space Models"** introduced a selection mechanism  that enables the model to extract relevant information from the inputs. Mamba has been applied effectively in image restoration **Zhang, "Image Restoration using Deep Unsupervised Learning"**, segmentation **Wang, "Image Segmentation using Multimodal Fusion and Selection Mechanism"**, and other domains **Kim, "Multimodal Fusion for Image Analysis"** , achieving competitive results. 
In the context of image fusion, approaches like MambaDFuse **Gao, "MambaDFuse: Image Fusion using Deep Unsupervised Learning and Selection Mechanism"** and FusionMamba **Wang, "FusionMamba: Multimodal Fusion using Selection Mechanism for State Space Models"** have leveraged Mamba to improve performance. However, these methods utilize SSMs only for feature extraction, neglecting the cross-modal state space features and Mambaâ€™s selection capabilities across different modal features in a unified state space.
To address this, we propose a universal State Space Fusion Mechanism that integrates and selectively extracts features across modalities within a unified state space, enhancing MCOS performance.

\begin{figure*}[h]
\setlength{\abovecaptionskip}{0cm}
	\centering
	\includegraphics[width=\linewidth]{figure/Framework.pdf}\vspace{-4mm}
	\caption{Framework of our UniCOS, and the details of FFM, LSFM, \(g_w\), and SSFM. The modules outlined by dashed lines mean the modules introduced by UniLearner, which can be omitted when using paired RGB-X data.
    }
	\label{fig:Framework}
	\vspace{-5mm}
\end{figure*}