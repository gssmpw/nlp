\section{Computing Skyline Sets}
\label{sec-methods}

%%% Justify why we need a PTIME 
% approximation scheme rather than 
% computing a Pareto optimal set. 
% Kung's algorithm wil be too expensive. 


\subsection{Approximating Skyline Sets}
\label{sec-apxmodis}

%\warn{add what $(1+\epsilon)$-Pareteo set; and 
%what is an FPTAS for the problem. Justify 
%why it is still a good solution~\cite{tsaggouris2009multiobjective}. } 

%\stitle{$\epsilon$-approximation}. 
%We consider a set $\D_F$ as a 
%Pareto optimal set under configuration $(s_M, \O, M)$.  
%To characterize a feasible
% approximate 
%algorithm for data discovery 
%with size-bounded solutions 
We next present our first algorithm that generates a size-bounded set, which %solution that 
approximates a Skyline set in $\D_F$.  
To characterize the approximation quality, 
we introduce a notion of 
$\epsilon$-skyline set. 
%followed by an optimality 
%measure. 

\stitle{$\epsilon$-Skyline set}. 
Given a data discovery system $\T$ with 
a configuration $C$, % $(s_M, \O, M)$. 
Let $\D_\S$ be a set of $N$ valuated datasets 
in the running of $\T$. 
%that contains $N$ datasets. 
Given a pair of datasets $(D, D')$ from $\D_\S$, and a constant $\epsilon\textgreater 0$,  
we say $D'$ {\em $\epsilon$-dominates} 
$D$, denoted as 
$D'\succeq_\epsilon D$, 
if for the corresponding 
tests $t$ = $(M, D)$ and $t'$ = $(M, D')$, 
%$t'.p \leq (1+\epsilon) t.p$ 
%for each $p\in\P$, 
\tbi
\item $t'.p \leq (1+\epsilon) t.p$ 
for each $p\in \P$, and  % \setminus \{p^*\})$
\item there exists a measure $p^*\in \P$, 
such that $t'.p^* \leq t.p^*$. 
\ei

In particular, we call $p^*$ a 
{\em decisive measure}. Note that 
$p^*$ can be any $p\in \P$ and 
may not be fixed. 

%We call the measure $p^*$ a ``decisive measure''. 
\vspace{.5ex}
A set of datasets $\D_\epsilon\subseteq \D_\S$ 
is an {\em $\epsilon$-Skyline set} of 
$\D_\S$, if 
\tbi 
\item for any dataset $D\in \D_\epsilon$, 
and any performance measure $p\in\P$, 
there exists a corresponding 
test $t\in T$, such that 
$t.p\in [p_l, p_u]$; and 
\item 
for every dataset $D'\in \D_\S$, 
there exists a dataset 
$D\in \D_\epsilon$ such that 
$D \succeq_\epsilon D'$. 
\ei 
%This balances a trade-off between computational efficiency and solution quality by allowing a state to be within an $\epsilon$-threshold instead of strictly dominating another. 
%Moreover, our layer-wise structure, perfectly complementing the Skyline set, allows for the inclusion of initially suboptimal states that may evolve into competitive solutions in the future.

% MY: Add this as, if we choose to strictly prune the dominated path, we must assume that a path that is less effective at an earlier stage will not lead to a more effective combination in later stages, which is not hold. We can say that by providing a feasible solution for an $\epsilon$-Skyline set, we ensure that the paths we pruned are the ones with intolerant performance.

\stitle{$(N,\epsilon)$-approximation}. We say an algorithm 
is an {\em $(N,\epsilon)$-approximation} for \modis, 
if it satisfies the following: 
\tbi 
\item it explores and valuates at most $N$ states; 
%takes a
%transition graph $G_\T$ as input,
% with in total $N$ {\em unevaluated} state nodes; 
% \item 
\item for any constant $\epsilon\textgreater 0$, the system correctly outputs an $\epsilon$-Skyline set, as an approximation of a Skyline set defined over $N$ {\em valuated} states; and 
\item the time cost is polynomial determined by $|\D|$, $N$, and$\frac{1}{\epsilon}$.
\ei

Below we present our 
main result. 

\begin{theorem}
\label{thm-fptas}
Given %a fixed deterministic model $M$, 
datasets $\D$, 
% performance measures $\P$,
% a data discovery system $\T$, 
 configuration $C$, %=$(S_M, M, T, \E)$, 
 and a number $N$, 
 %and a set of tests $T$, 
there exists an $(N,\epsilon)$-approximation for \modis in 
$O\left(\min(N_u^{|R_u|}, N)\cdot \left(\left(\frac{\log(p_m)}{\epsilon}\right)^{|\P|-1}+I\right)\right)$ time, where $|R_u|$ is the size of the universal 
schema, 
%$|R_u|$ is the number of 
%attributes in $\D$, 
$N_u$ = $|R_u|+|\ad_m|$ 
($\ad_m$ the largest active domain), $p_m$ = 
$\max\frac{p_u}{p_l}$
as the measure $p$ ranges over $\P$; and $I$ is the 
unit valuation cost per test. 
%% with other performance guarantees. 
\end{theorem}

\stitle{Remarks}. 
The above result captures a {\em relative}
guarantee \wrt $\epsilon$ 
and $N$. When %$\mathcal{T}$ is exhaustively  and 
$N = \D_F$, an $(N,\epsilon)$-approximation ensures to output a $\epsilon$-Skyline set. 
%The time cost is in PTIME 
%\wrt input size $|\D|$, 
%as $N$ can be exponential. On the other hand, %we consider
The paradigm is feasible as one can explicitly trade the `closeness' of the output 
to a Skyline set with affordable time cost, by explicitly tuning 
$\epsilon$ and $N$. % to a managable size. 
Moreover, 
the worst-case factor $|\ad_m|$ 
can also be ``tightened'' by 
a bound 
%the number of value clusters 
determined by
the value constraints posed by 
the literals. For example, an attribute 
$A$ %having %$5$ values $\{1, \ldots 5\}$ 
may contribute up to two necessary values 
in the search if 
the literals involving $A$ only enforce 
two equality conditions ``A=2'' and ``A=5'', 
regardless of how large $|\ad(A)|$ is 
(see 
Sections~\ref{sec-system} and~\ref{sec:exp}).
%\{2, 5\}$  if values $A_i$ are grouped by comparisons with $2$ and $5$. 


\eat{
\revise{Note that $\vert\ad(A_i)\vert$ is not necessarily the total distinct literals in $A_i$, but can be kept finite by grouping values, such as using comparison constraints. For example, $\ad(A_i) = \{2, 5\}$  if values $A_i$ are grouped by comparisons with $2$ and $5$, ensuring efficient representation and processing.}
}



\begin{figure}
\centering
\begin{algorithm}[H]
\caption{:\apxmodis}
\label{alg:forward}
\begin{algorithmic}[1]
\algtext*{EndFor}
\algtext*{EndIf}
\algtext*{EndWhile}
\algtext*{EndFunction}
\algtext*{EndProcedure}

\State \textbf{Input:} 
    Configuration $C$ = $(s_U, \O, M, T, \E)$, 
    a number $N$, \\ a constant $\epsilon>0$, 
    a decisive measure $p_d$;
    user-specified upper bound $p_u$ for $p \in \P$;
\State \textbf{Output:} 
     $\epsilon$-Skyline set $\mathcal{D}_F$.

     \vspace{1ex}
%\Procedure{\apxmodis}{$C$, $\epsilon$, $\boldsymbol{t}$}
    \State \textbf{Queue} $Q := \varnothing$, integer $i$ := 0, $Q$.enqueue(($s_U$, 0));\label{apx:initialize}  
    \While{$Q \neq \varnothing$ %\textbf{or} 
    \textbf{and}
    number of valuated states $< N$} \label{apx:main:s} %or less than $N$ states are evaluated 
        \State ($s$, i) := $Q$.dequeue();
        ${\D_F}^{i+1} := {\D_F}^i$; 
        \For{each ($s'$, $D_{s'}$) $\in$ \opg($s$)}
            \State $Q$.enqueue(($s'$, i + 1));
            \State ${\D_F}^{i + 1}$ := \upi($s'$, %$D_{s'}$, 
            ${\D_F}^{i + 1}$, $\epsilon$);
        \EndFor
    \EndWhile \label{apx:main:e}
%\EndProcedure
 \State \Return ${\D_F}$ \label{apx:return}

\vspace{1ex}
\Procedure{\opg}{s}
    \State \textbf{set} $Q':=\varnothing$; \label{apx:opg:s}
    \For{each entry $l \in s.L$} 
    %\warn{s.L is a map, should $l$ be $L[i,j]$?}
        \If{$l = 1$}
            \State $l := 0$;  
            \State create a new state $s'$; 
            $s'.L := s.L$; 
            \State generate dataset $D_{s'}$ accordingly; 
            \State $Q'$.append(($s'$, $D_{s'}$)); 
        \EndIf
    \EndFor
    \State \Return $Q'$
\EndProcedure \label{apx:opg:e}


\vspace{1ex}
\Procedure{\upi}{$s'$, %$D_{s'}$, 
${\D_F}^{i + 1}$, $\epsilon$} \label{apx:upi:s}
\State {update %$\P_{s'}$ 
$s'.\P$ with estimator $\E$;
% \For{$i \gets 1$ \textbf{to} $|\P_{s'}|$}
%     \If{$\P_{s'}[i] >\boldsymbol{t}[i]$} 
\For{each $p \in \P$} %\P_{s'}$}
    \If{$s'.\P(p) > p_u$} 
    \Return ${\D_F}^{i + 1}$;
    \EndIf
\EndFor
%    \For{each $D \in {\D_F}^i$} 
    %\warn{is $\rho_d$ a path or a dataset?}
 %       \State $\rho' := \rho_d \cup \{s'\}$, $cost(\rho') = \P_{s'}-\P_{s_U}$;  
        \State update $\operatorname{pos}(s')$ with Equation~(\ref{eq:pos});
 %       \State choose a decisive measure $p\in \P$; % \textbf{as}  metric; 
 \State 
 %\textbf{get} $D_{s''}$ with $\operatorname{pos}(s')$ \textbf{in} ${\D_F}^{i + 1}$ \textbf{with} its state $s''$, if any;
        retrieve state 
        $s''$ where $\operatorname{pos}(s'')$ =  $\operatorname{pos}(s')$; 
        % \State $D' := {\D_F}^{i + 1}[\operatorname{pos}(s')]$; 
        \If{no such %$D_{s''}$ 
        $s''$ exists} 
        \State ${\D_F}^{i + 1}$ := ${\D_F}^{i + 1}\cup \{D_s'\}$; 
        \EndIf
        \State \textbf{else if} $s'.\P(p_d) < s''.\P(p_d)$ \textbf{then}
        \State \hspace{3ex} ${\D_F}^{i + 1}$ := ${\D_F}^{i + 1}\setminus \{D_{s''}\} \cup \{D_{s'}\}$;
    \State \Return ${\D_F}^{i + 1}$
\EndProcedure \label{apx:upi:e}


       %     \textbf{or} $s'.\P(p_d) < s''.\P(p_d)$} \label{apx:merge}
            % \State ${\D_F}^{i + 1}[\operatorname{pos}(s')]=s'$;
     %       \State 
            %\textbf{insert} $D_{s'}$ \textbf{into} $\operatorname{pos}(s')$ \textbf{in} ${\D_F}^{i + 1}$
  %          ${\D_F}^{i + 1}$ := ${\D_F}^{i + 1}\cup \{D_s'\}$; 
  
    % \For{each $\rho_d \in {\D_F}^d$}
    %     \State \textbf{compute} $\P_{s'}$ by invoking $\E$; 
    %     \State $\rho' = \rho'' \cup \{s'\}$, \textbf{set} $\rho'$ with $\P_{s'}$; 
    %     \For{$i \gets 1$ \textbf{to} $|\P_{s'}|$}
    %         \If{$\P_{s'}[i] >\boldsymbol{t}[i]$} %\warn{p_u}
    %         continue;
    %         \EndIf
    %     \EndFor
    %     \State \textbf{compute} $\operatorname{pos}(\rho')$ \textbf{with} Equation~(\ref{eq:pos});
    %     \State \textbf{choose} a deterministic measure $p\in \P$; % \textbf{as}  metric; 
    %     \State $\rho = {\D_F}^{d + 1}[\operatorname{pos}(\rho')]$; 
    %     \If{$\rho = null$ \textbf{or} $\rho'.p < \rho.p$} \label{apx:merge}
    %         \State ${\D_F}^{d + 1}[\operatorname{pos}(\rho')]=\rho'$;
    %     \EndIf
    % \EndFor
    % \State \Return ${\D_F}^{d + 1}$
\eat{
\vspace{1ex}
\setcounter{ALG@line}{0}
\Procedure{\upi}{$s$, $R$, $Q$, $\epsilon$} 
\warn{the parameters do not match with line 9. }\label{apx:upi:s}
    \For{each $\rho \in Q$}
        \State \textbf{compute} $\P_s$ by invoking $\E$; set $\rho$ with $\P_s$; 
        \For{$i \gets 1$ \textbf{to} $|\P_s|$}
            \If{$\P_s[i] >\boldsymbol{t}[i]$} %\warn{p_u}
            continue;
            \EndIf
        \EndFor
        \State \textbf{compute} $\operatorname{pos}(\rho)$ \textbf{with} Equation~(\ref{eq:pos});
        \State \textbf{set} $p$ \textbf{as} a next deterministic metric;  
        \If{$R[\operatorname{pos}(\rho)] = null$ \textbf{or} $R[\operatorname{pos}(\rho)].p < \rho.p$} \label{apx:merge}
            \State $R[\operatorname{pos}(\rho)]=\rho$;
        \EndIf
    \EndFor
    \State \Return $R$
\EndProcedure \label{apx:upi:e}
}}
\end{algorithmic}
\end{algorithm}
\vspace{-3ex}
\caption{\apxmodis: Approximating Skyline sets}
% \warn{Reset line number for 
% UPareto and OpGen.}
\vspace{-3ex}
\label{fig:approx}
\end{figure}

\subsection{Approximation Algorithm}
\label{sec-approx}
%FPTAS Framework: 
 
As a constructive 
proof of Theorem~\ref{thm-fptas}, 
we next present an $(N,\epsilon)$-approximation algorithm, denoted as \apxmodis.   

\stitle{``Reduce-from-Universal''}. 
Algorithm \apxmodis simulates the running of $\T$ from a start state $s_U$. 
The start state is initialized with a ``universal'' dataset $D_U$, 
which carries the universal schema $R_U$, and is populated by 
joining all the tables (with outer join to preserve 
all the values besides common attributes, by default). 
This is to enforce the search 
from a set of rows that 
preserve all the attribute values 
as much as possible to maximize 
the chance of sequential 
applications of reduction only. 
It transforms state dominance into a ``path dominance'' counterpart. 
For a transition edge $(s,\ominus, s')$, 
a weight is assigned 
to quantify the gap between 
the estimated model performance 
over datasets $D_s$ and its ``reduced'' 
counterpart $D_s'$. 
The ``length'' of a path from $s_U$ to $s$ aggregates 
the edge weights towards  
the estimated performance of 
its result. 


\eat{
% \mengying{that includes all attributes and active domains.
\mengying{During each transition (edge), one attribute or active domain is reduced, and the edge is weighted based on the performance variance caused by the transition.
The ``depth'' refers to the number of transitions from the initial state to the current state, while the ``shortest path'' denotes the path from the initial state to a target state that yields the dataset with the best performance measures for the given model.
\apxmodis "transforms" state dominance into a "path dominance" counterpart by assigning the valuated measures of end nodes to the paths from the initial state at runtime.}
}
% which aggregates valuated measures   
% from nodes to the end of the paths at runtime.
\eat{
\warn{How do we characterize a 
``shortest path'': give the 
definition/intuition of the 
path length, and define a 
version of shortest path.}
\warn{``depth'': undefined.}\mengying{[MY: path length is defined in Running Graph in section III]}
}

\eetitle{Advantage}. We justify the ``reduce-from-universal'' 
strategy in the following context. 
%as justified below. 
(1) As the measures are 
to be minimized, 
we can extend ``shortest'' paths 
by prioritizing the valuation of datasets 
towards user-defined upper bounds 
with early pruning, to avoid   
unnecessary reduction. 
(2) Starting from a universal dataset allows early exploration of ``dense'' datasets, over which the model always tends to have higher accuracy in practice. 


%develop cost-effective approximation-preserving algorithm to solve a 
%{\em multi-objective shortest 
%path} counterpart. 
%%%% give the forward-only algorithm. 

We next present the details of our algorithm. 

\stitle{Auxiliary structure}. 
~\apxmodis follows a dynamic 
levelwise state generation 
and valuation process, 
which yields
a running graph $G_\T$ 
with up to $N$  %unvaluated 
nodes. 
%It follows a levelwise 
%state generation and valuation 
%process. 
It %enhances $G_\T$ to a weighted DAG, with 
maintains the following. 

\sstab 
(1) $Q$ is a queue that maintains 
the dynamically generated and 
valuated state nodes. 
Each entry of $Q$ is a pair 
$(s, i)$ that records 
a state and the level it resides. 


\sstab
(2) $\D_F$ is a list of datasets.  
$\D_F^i$ specifies the datasets 
processed at level $i$. 
Each state node $s$ is associate with a bitmap $L$ %(a bit vector) 
to encode if its schema $s.R_s$ 
contains an attribute $A$ in $D_U$, and if $D_s$ 
contains a value from its %finite 
active domain $\ad(A)$. 
The map is consulted to assert the applicability of reduct operators at runtime. 
%avoids generating redundant datasets without additional costs. 

\sstab 
(3) Each state $s$ is associated with 
a position $pos(s)$ in a {\em discretized} $|\P-1|$-ary 
space, which is defined as 
\begin{small}
\begin{equation}
\operatorname{pos}(s) = 
\left[\left\lfloor\log _{1+\epsilon} \frac{s.\P(p_1)}{p_{l_1}}\right\rfloor, \ldots, \left\lfloor\log _{1+\epsilon} \frac{s.\P(p_{|\P|-1})}{p_{l_{|\P|-1}}}\right\rfloor\right]
\label{eq:pos}
\end{equation}
\end{small}

By default, we set the last measure 
in $\P$ as {\em a} decisive measure. 
We remark that one can choose 
any measure as decisive measure, 
and our results carry over. 

\eat{
\sstab
(3) Each transition (edge) $r$ = $(s, \kw{op}, s')$ has a vector of weights $\mathbf{c}(r)$ of 
length $|\P|$, 
where each entry $\mathbf{c}(r)_p$ = $t.p$ - $t'.p$ records the difference of valuated measure as 
$p$ ranges over $\P$. 
%Here for any edge from 
%${\D_F}^0[pos(\rho_U)] = \P_{s_U}$;

\sstab
(4) As paths are spawned in $G_\T$,   
%at a ``depth'', 
it  maintains at runtime for each path $\rho = \{r_1, \ldots r_k\}$ a 
{\em path label} 
as a pair $(\P(\rho), \operatorname{pos}(\rho))$, where 
(a) 
$\P(\rho)$ is a $|\P|$-ary 
vector, where each entry $\P(\rho).p$ aggregates, for each measure $p\in \P$ as 
$\sum_{r \in \rho}
\mathbf{c}(r).p$, 
and (b) 
$\operatorname{pos}(\rho)$ 
is the ``position'' of 
$\rho$  in a {\em discretized} $|\P-1|$-ary 
space \mengying{(Skyline set)}:  
\eat{
\[
\operatorname{pos}(\rho) = 
\left[\left\lfloor\log _{1+\epsilon} \frac{c_{1}(\rho)}{c_{1}^{\min }}\right\rfloor, \ldots, \left\lfloor\log _{1+\epsilon} \frac{c_{d_c}(\rho)}{c_{d_c}^{\min }}\right\rfloor\right]
\]
}
\begin{small}
\begin{equation}
\operatorname{pos}(\rho) = 
\left[\left\lfloor\log _{1+\epsilon} \frac{\P(\rho).p_1}{p_{l1}}\right\rfloor, \ldots, \left\lfloor\log _{1+\epsilon} \frac{\P(\rho).p_{|\P-1|}}{p_{l|\P-1|}}\right\rfloor\right]
\label{eq:pos}
\end{equation}
\end{small}
which captures a relaxed ``envelope'' 
of valuated performance, that allows us to decide $\epsilon$-dominance 
by a simple comparison. 
\mengying{The last measure in $\P$ is set as the {\em deterministic measure} $p*$, which ensures the Skyline set's size is polynomially bounded.}
}
 

\eat{
a {\em path label}, which is a tuple  $(l(s_k), \P(\rho), pred(\rho))$, where $l(s_k)$ is the label of the last state $s_k$, $\P(\rho)$ = $\sum_{r \in \rho}
\mathbf{c}(r)$, 
%\P(r)$, 
%, %\P({r})$, 
and $pred(\rho)$ is a 
pointer to the label of the subpath $\rho' = \{r_1, \ldots r_{k-1}\}$. 
As will be shown, this construction 
allows us to reduce the process 
to a shortest path 


It discretizes $\P(\rho)$ in each measure and computes a ``coordinate'' of a path $\rho$ in the Skyline set with the following Equation~\ref{eq:pos}. 
\begin{align}
\label{eq:pos}
\operatorname{pos}(\rho) = &\left[\left\lfloor\log _{1+\epsilon} \frac{c_{1}(\rho)}{c_{1}^{\min }}\right\rfloor, \ldots, \left\lfloor\log _{1+\epsilon} \frac{c_{d_c}(\rho)}{c_{d_c}^{\min }}\right\rfloor, \right. \nonumber\\
&\left.\left\lfloor\log _{1-\epsilon} \frac{b_{1}(\rho)}{b_{1}^{\max }}\right\rfloor, \ldots, \left\lfloor\log _{1-\epsilon} \frac{b_{d_b}(\rho)}{b_{d_b}^{\max }}\right\rfloor\right]^{T}
\end{align}
}

 \eat{
traverse 
It 
enhances $G_\T$ with additional 
run-time structure as follows. 
(1) For each path 

From transducer $\T=(s_M, \S, \O, \S_F, \delta)$, we formalize a transition graph $G_\T = (\S, \delta)$, where vertices $s \in \S$ represent states of the dataset $D$. Each vertex is labeled with a universal schema that includes the features’ states. Start state $s_M$ represents the state of the initial dataset $D_M$. By performing an operation $op \in \O$ on a state $s$, a new state $s'$ is generated along with a transition $r$ = $(s, op, s')$. The cost of this transition $\mathbf{c}(r)$ is determined by the performance variances between two tests $t=(M, D_s)$ and $t'=(M, D_{s'})$, denoted as $\P_i(r) = t.p_i - t'.p_i$, $\forall p_i \in \P$. 
}

\eat{
A {\em path} $\rho = \{r_1, \ldots r_k\}$ is labeled with a tuple $(l(s_k), \P(\rho), pred(\rho))$, where $l(s_k)$ is the label of the last state $s_k$, $\mathbf{p}(\rho) = \sum_{r \in \rho}\P(r)$, and $pred(\rho)$ is the label of the {\em subpath} $\rho' = \{r_1, \ldots r_{k-1}\}$. We discretize the $\P(\rho)$ in each objective and compute the position for a path $\rho$ in the Skyline set using Equation~\ref{eq:pos}. 
\begin{align}
\label{eq:pos}
\operatorname{pos}(\rho) = &\left[\left\lfloor\log _{1+\epsilon} \frac{c_{1}(\rho)}{c_{1}^{\min }}\right\rfloor, \ldots, \left\lfloor\log _{1+\epsilon} \frac{c_{d_c}(\rho)}{c_{d_c}^{\min }}\right\rfloor, \right. \nonumber\\
&\left.\left\lfloor\log _{1-\epsilon} \frac{b_{1}(\rho)}{b_{1}^{\max }}\right\rfloor, \ldots, \left\lfloor\log _{1-\epsilon} \frac{b_{d_b}(\rho)}{b_{d_b}^{\max }}\right\rfloor\right]^{T}
\end{align}
Consider $\P$ may encompass costs (\eg training time) and benefits (\eg accuracy), which we represent as $c$ and $b$ respectively, $d_c$ and $d_b$ as their total count. For each $c_i \in c$, we capture the base-$(1+\epsilon)$ logarithm of the ratio between the specific cost value $c_i(\rho)$ and its minimum counterpart $c_i^{min}$, and then floor the result. Benefits are computed similarly to costs, with some modifications: the logarithmic base is $1 - \epsilon$, and we normalize against $b_i^{\text{max}}$. The position vector $pos(p)$ is constructed by combining the results of the costs and benefits and then scaled to [0, 1] as normalized $\P$ for path $\rho$, all $p \in \P$ aim to minimize. In \apxmodis, we calculate the position of a path based on its first $d-1$ objectives and set the $d_{th}$ one as a deterministic metric to ensure the Skyline set remains polynomial-size bounded, specifically within the dimensions of $[\mathbb{N}_{0}]^{d-1}$.
}

\eat{
Input size: $n = \#nodes$ ($l=|\A|, k=|adom|$. At least $d\%$ of the features and $m\%$ active domains of each feature remain active): 
$$\left(\sum_{i=\lfloor d\% l\rfloor}^l\left(\begin{array}{l} l \\ i
\end{array}\right)\right) \times\left(\sum_{j=\lceil m\% k\rceil}^k\left(\begin{array}{l} k \\ j
\end{array}\right)\right)$$ 
Size of Skyline set - $\epsilon$, $\operatorname{pos}: 2^{E} \rightarrow[\mathbb{N}_{0}]^{d-1}$. This matrix has a dimension of $d-1$. Within each dimension, the maximum length for costs is given by $log_{1+\epsilon}\frac{c_{i}^{\max}}{c_{i}^{\min}}$, and for benefits by $log_{1-\epsilon}\frac{b_{i}^{\min}}{b_{i}^{\max}}$. }






\stitle{Algorithm}. The algorithm \apxmodis is illustrated in Fig.~\ref{fig:approx}. 
%, which induces an $\epsilon$-Skyline set $\D_F$ from a data discovery system $\T$. 
It initializes a queue $Q$ with a start state $s_U$, and set a position to $s_U$ (line~\ref{apx:initialize}). In lines~\ref{apx:main:s} to \ref{apx:main:e}, it update the Skyline set $\D_F$ for each level iteratively. 
% We first construct a transition graph $G_\T$ using states $\S$ and transitions $\delta$, with a maximum depth of $n$. 
% In line~\ref{ls:initialize} to \ref{le:initialize}, for each state $s \in \S$, we initialize the initial layer of $\D_{F_s}$ as an empty set and compute all $p \in \P$ for the current state $s$ over $M$.
% At line ~\ref{a:sm}, we assign the label of path $\rho_M$, with length 0, to position $\operatorname{pos}(\rho_M)$ in $\D_{F_{s_M}}$. 
% The iteration in line~\ref{its:main} to \ref{ite:main} is refining the Skyline set $\D_F$ at each depth. 
At level $d$, for each state $s \in Q$, 
%we carry over the Skyline set from the previous round. 
procedure \opg (line~\ref{apx:opg:s} to \ref{apx:opg:e}) explores all one-flip transitions in $s.L$ and generates a set with applicable reduct operators. 
\apxmodis 
%iterates over all states $s'$ in the output of \opg, 
enqueue %a new tuple with $s'$ and incremented depth, and 
new states and update the Skyline set ${\D_F}^{d+1}$ at next level accordingly by invoking Procedure \upi. 
%(lines~\ref{apx:upi:s} to \ref{apx:upi:e}).
This process terminations until 
$N$ states are valuated, or 
no new state can be generated. 

\begin{figure}[tb!]
\centerline{\includegraphics[width =0.45\textwidth]{fig/apxmodis}}%apxmodis1
\centering
\vspace{-1ex}
\caption{``Reduct-from-Universal'': an illustration of two-level computation. It performs multiple level-wise spawns and updates the $\epsilon$-Skyline set.}
 \vspace{-3ex}
\label{fig:reduct}
\end{figure}


\stitle{Procedure \upi}. Given a 
new state $s'$, procedure \upi 
determines if $s'$ should be included 
in the current Skyline set. 
(1) It updates $s'.\P$ by consulting the estimator $\E$ 
(line 1), and decide an early skipping 
if its performance fails to satisfy 
the upperbound $p_u$ for some measure $p\in \P$. 
(2) Otherwise, \upi updates the 
position of state $s'$, and decides  
if $s'$ ``replaces'' 
a valuated state $s''$ at the same position 
due to $(1+\epsilon)$-dominance (lines 6-9). 
The Skyline set at current level 
is updated accordingly with 
dataset $D_{s'}$. % and returned.  

\eat{
\mengying{It evaluates if a dataset $D_{s'}$ is qualified to be put into Preto set ${\D_F}^{d+1}$; if it is, insert and merge it at position $pos(s')$.
In line 1, it computes $s'.\P$ by consulting the estimator $\E$.
In lines 2-3, $D_{s'}$ will be discarded if for any measure $p \in \P$, the corresponding value for state $s'$, which is $s'.\P(p)$, is larger than the user-specified thresholds $p_u$. 
The position of $D_{s'}$ in ${\D_F}^{d+1}$ is computed using Equation~\ref{eq:pos} in line 4. 
The $\operatorname{pos}(\rho')$ is a $(|\P|-1)$-vector, indexing a position in the discretized $|\P-1|$-ary space ${\D_F}^{d+1}$.
Paths falling into the same position are considered approximately equivalent in cost. 
Next, in lines 5-7, we check if a dataset $D_{s''}$ exists at $pos(s')$.
If $\operatorname{pos}(s')$ is empty in the current ${\D_F}^{d+1}$, we insert $D_{s'}$ here;
otherwise, the dataset with the lower value of the decisive measure $p_d$ between $D_{s'}$ and $D_{s''}$ is retained.
The updated ${\D_F}^{d+1}$ with dataset $D_{s'}$ will be returned at last.}
}

\eat{
\mengying{For each path $\rho''$ stored in the Skyline set at depth $d$, in lines 3-4, it will be extended to depth $d+1$ by appending state $s'$ to create path $\rho'$, computing $\P_{s'}$ by consulting the estimator $\E$, and assigning $\P_{s'}$ as path $\rho'$'s cost.
In lines 5-6, $\rho'$ will be discarded if any measures in $\P_{s'}$ exceed the user-specified thresholds $\mathbf{ts}$, which correspond to the range $(p_l, p_u]$ for each $p \in \P$. 
In line 7, the position of $\rho'$ in $\D_F$ is  computed using Equation~\ref{eq:pos}. 
Paths falling into the same position are considered approximately equivalent in cost. 
The $\operatorname{pos}(\rho')$ will be a $(len(\P)-1)$-vector, excluding a deterministic metric  $p$. deterministic metric remains unapproximated to ensure only one optimal path is retained in each position of $\D_F$, maintaining its size polynomially bounded.
In lines 9-10, the dominance of paths is compared. 
If $\operatorname{pos}(\rho')$ is empty in the current $\D_F$, $\rho'$ is stored; otherwise, the path with the lower $p$ between $\rho'$ and the original path is retained.
After iterating through all depths, \apxmodis returns the refined $\epsilon$-Skyline set $\D_F$ in line 11.}}


\eat{
\begin{figure}
\centering
\begin{algorithm}[H]
\caption{Algorithm \apxmodis 
}
\label{alg:forward}
\begin{algorithmic}[1]
\algtext*{EndFor}
\algtext*{EndIf}
\State \textbf{input:} 
    Initial dataset $D_M$, 
    $\epsilon$, 
    maximum depth $n$,
    data discovery system $\T$ = $(s_M, \S, \O, M, \D_F$, $\delta)$, 
    thresholds on costs $\boldsymbol{ts}$
\State \textbf{output:} 
    Skyline set $\mathcal{D}_F$
\Procedure{\apxmodis}{$D_M$, $\T$, $n$, $\epsilon$, $\boldsymbol{t}$}
    \State \textbf{construct} trans. graph $G_\T=(\S, \delta)$ \textbf{with} max depth $n$;
    \For{each state $s=(D_s, R_s, \ad_s) \in \S$} \label{ls:initialize}
        \State ${\D_F}_s^0[0] = \varnothing$;
        \For{each metric $p \in \P$} 
            \State $\P_s$.append($f(D_s, M).p$); 
            % \State \mengying{estimator can output multiple p by one inference};
        \EndFor
    \EndFor \label{le:initialize}
    
    \State ${\D_F}_{s_M}^0[pos(\rho_M)] = \{(( R_{s_M}, \ad_{s_M}), \P_{s_M}, null, null)\}$; \label{a:sm}
    \For{$i \gets 1$ \textbf{to} $n$} \label{its:main}
        \For{all states $s \in \S$}
            \State ${\D_F}_s^i = {\D_F}_s^{i-1}$;
            \For{all $r = (s', \op, s) \in \delta$}
                \State ${\D_F}_s^i$ = Extend-\&-Merge($s$, ${\D_F}_s^i$, ${\D_F}_{s'}^{i-1}$, $\epsilon$);
            \EndFor
        \EndFor
    \EndFor \label{ite:main}
    \State \Return ${\D_F}^n_{s \in \S}$;
\EndProcedure

\Function{Extend-$\&$-Merge}{$s$, $R$, $Q$, $\epsilon$}
    \For{each $\rho' \in Q$}
        \State $\rho = (( R_s, \ad_s), \P_s, \rho', (s', \op, s))$;
        \For{$i \gets 1$ \textbf{to} $|\P_s|$}
            \If{$\P_s[i] > \boldsymbol{ts}[i]$} 
            continue;
            \EndIf
        \EndFor
        \State \textbf{compute} $\operatorname{pos}(\rho)$ \textbf{with} $\epsilon$ \textbf{by} Equation~(\ref{eq:pos});
        \State \textbf{set} $p$ \textbf{as} deterministic metric, skip = False;
        % SSMOSP returns the Skyline set for each end node separately, and we need a global Skyline set
        \eat{
        \If{$R[\operatorname{pos}(D_s)] = null$ \textbf{or} $R[\operatorname{pos}(D_s)].p < D_s.p$}
            \State $R[\operatorname{pos}(D_s)]=D_s$;
        \EndIf}
        \For{$s' \in \S$} \label{ls:merge}
            \If{${\D_F}_{s'}^i[\operatorname{pos}(\rho)].p > \rho.p$} skip = True; 
            \State Continue;
            \EndIf
            \State \textbf{del} ${\D_F}_{s'}^i[\operatorname{pos}(\rho)]$
        \EndFor
        \If{skip $\neq$ True} $R[\operatorname{pos}(\rho)]=\rho$;\EndIf
    \EndFor \label{le:merge}
    \State \Return $R$;
\EndFunction
\end{algorithmic}
\end{algorithm}
\vspace{-3ex}
\caption{\apxmodis: Approximating Skyline sets}
% \vspace{-3ex}
\label{fig:approx}
\end{figure}
}

\begin{example}
\label{exa-apxmodis}
Fig.~\ref{fig:reduct} illustrates data discovery 
of 
%how~\apxmodis 
\apxmodis with $N$=$5$ and $\epsilon$=$0.3$, 
over a table set $\D$ = $\{D_1, \ldots, D_3\}$ and 
measures $\P$ = $\textless p_1, p_2\textgreater$. The operator set $O$ contains 
four reduct operators $\{\ominus_1, \ldots \ominus_4\}$. 
(1) It first constructs a 
universal dataset $D_U$ with universal schema $R_U$. $D_U$ can be 
obtained by 
optimized multi-way join~\cite{zhao2020efficient}, augmentation~\cite{li2021data}, or UDFs~\cite{dong2017arrayudf}. 
 % \warn{give some references}. 
The bitmap $D_U.L$ is 
initialized accordingly. 
% $s \succeq_{0.3} s'$ if $s$ falls within the dominance region (shaded area) emanating from $s'$.
Procedure \kw{OpGen} 
then generates applicable reductions by ``flipping'' the entries in $D_U.L$.  
This spawns states $s_1$ and $s_2$ obtained by 
applying reduct $\ominus_1$ and $\ominus_2$, 
respectively
%(generated by the procedure 
%\kw{OpGen} by ``flipping'' the attributes and selection condition). 
It then consults 
the estimator $\E$ to valuate model performances, and identified that 
$D_1\not\succeq_{0.3} D_2$ and vice versa. Thus 
\apxmodis sets the current $0.3$-Skyline set 
as $\{D_1, D_2\}$.  

\apxmodis next spawns states with %with 
applicable reductions $\ominus_3$ and $\ominus_4$, 
extending $\rho_1$ that leads to 
$s_1$, and $\rho_2$ that leads to $s_2$, 
This generates new extended paths $\rho_3$ and $\rho_4$ 
with results $D_3$ and $D_4$, respectively. 
%\warn{The following is not consistent %with 
%Fig 5.}
It verfies that 
$\D_3 \succeq_{0.3} D_1$, but 
$D_2 \succeq_{0.3} D_4$; and $D_2 \not\succeq_{0.3} D_3$ 
and vice versa. This yields an updated  
$0.3$-Skyline set $\{D_2, D_3\}$, 
after valuating $5$ states. 
%As the total evaluated nodes reach $5$, which is equal to the value of $N$ we set as the upper bound for total nodes, the output is $\{D_2, D_3\}$.
\end{example}

\stitle{Correctness \& Approximability}. ~\apxmodis 
terminates as it spawns $N$ nodes with at most  
$|R_U||\ad_m|$ distinct reduction, 
where $|\ad_m|$ refers to the size 
of the largest active domain. 

\vspace{2ex}
For approximability, we present the result below. 
% Following Proposition~\ref{prop-equivalent}, 
% it also correctly processes over a complete  
% solution space.

\begin{lemma}
\label{lm-approximability}
For any constant $\epsilon$, \apxmodis correctly computes an $\epsilon$-Skyline set $\D_F$ as an approximated Skyline set 
defined on the $N$ states it valuated. 
\end{lemma}

\begin{proofS}
We verify the $\epsilon$-approximability, 
with a reduction to the multi-objective 
shortest path problem (\mos)~\cite{tsaggouris2009multiobjective}. 
Given an edge-weighted graph $G_w$, 
where each edge carries a $d$-dimensional 
attribute vector $e_w.c$, it computes a Skyline set of 
paths from a start node $u$. 
The cost of a path $\rho_w$ in $G_w$ is 
defined as $\rho_w.c$ = $\sum_{e_w\in\rho_w}$ $e_w.c$. 
The dominance relation between two paths 
is determined by 
the dominance relation of their cost. 
Our reduction (1) constructs $G_w$ 
as the running graph $G_\T$ with 
$N$ valuated state nodes and 
spawned transition edges; and 
(2) for each edge $(s, s')$, 
sets an edge weight as 
$e_w$ = $s.\P - s'.\P$. 
Given a solution $\Pi_w$ 
of the above instance of \mos, 
for each path $\rho_w\in\Pi$, 
we set a corresponding path $\rho$ 
in $G_\T$ with result dataset $D$, 
and adds it into $\D_F$. 
%%%%%%%%%%%%%%%%
We can verify that 
$\Pi_w$ is an $\epsilon$-Skyline set 
of paths $\Pi_w$, if and only 
if $\D_F$ is an $\epsilon$-Skyline set 
of $\D_S$ that contains the
datasets from the set of $N$ valuated 
states in $G_\T$. 
We then show that~\apxmodis 
is an optimized process of 
the algorithm in~\cite{tsaggouris2009multiobjective}, 
which correctly computes 
$\Pi_w$ for $G_w$. 
\end{proofS} 


\eat{
Given a graph $G$ with a set of states $\S$ and set of transitions $\delta$, each transition $r=(s', \op, s)$ will be assigned a set of performance measures $\P$, the multi-objective path search problem(\mos) is to compute a Skyline set $\Pi$, which consists of a set of paths such that no path dominates others. 
Here a path $\rho$ dominates another $\rho'$, if its performance measures $\P(\rho)$, computed as $\sum_{r\in\rho} \P(r)$, dominates $\P(\rho')$, similarly as defined as in state dominance. 
By transforming an instance of \mos to an instance of \modis, \apxmodis leverages an algorithm designed for \mos to approximate solutions for \modis. Suppose an FPTAS schema exists for \mos, we can also achieve a solution for \modis by \apxmodis that adheres to the same approximation quality.
}

\eat{Given a graph $G$ with a set of states $V$ and edge set $E$, a cost function $C$ that assigns each edge to a cost vector $c(e)$, as 
well as a start node $v_s$ and a goal node 
$v_g$, the multi-objective path search 
problem is to compute a Skyline set $\Pi$, which consists of a set of 
paths such that no path dominates others. 
Here a path $\rho$ dominates another $\rho'$, if 
its cost $c(\rho)$, computed as 
$\sum_{e\in\rho} c(e)$, dominates 
$c(\rho')$, similarly as defined as in 
state dominance.} 

%%%%%%%%%%%%% move this to full version %%%%%%
\eat{\begin{proofS} 
To prove the approximability of \modis, we construct an approximation preserving reduction from it to \mos. 
We define a function $f$ to convert an instance of \modis to \mos in PTIME by constructing the transition graph $G_{\T}$, which we show in the Auxiliary structure. 
Then we map paths in $\Pi$ from \mos to dataset states using function $g$, forming the $\epsilon$-Skyline set $\Pi'$ for \modis. The dominance principle ensures quality preservation.
Based on this reduction, we show that \apxmodis provides an FPTAS schema for \mos, which outputs an $\epsilon$-Skyline set in polynomial time \wrt input size and $\frac{1}{\epsilon}$.  
This confirms the approximability of \modis. Detailed proof can be found in the Appendix.
\end{proofS}
}

\eat{
%%%%%%%%%%%%%%%%%%%%%%%%%
\stitle{Space Complexity}. 
\mengying{For each valuedated path $\rho$, we use $(|\P|-1)$ measures in $|\P|$ (except the deterministic measure $p*$) to calculate its ``position'' $pos(\rho)$ in a ($|\P|-1$)-ary space, which we use as the Skyline set.
Here, the last measure in $\P$ is set as $p*$ by default.
When multiple paths are allocated to the same position in the Skyline set, only the one with the lowest $p^*$ is retained.
This ensures that each position in the Skyline set holds at most one path,
so the {\em Space Complexity} equals the size of the array for the Skyline set. Assuming all performance metrics are costs, according to Equation~\ref{eq:pos}, the Space Complexity is $O\left(\prod_{i=1}^{|\P|-1}\left(\left\lfloor\log _{1+\epsilon}\frac{p^{max}_i}{p^{min}_i}\right\rfloor+1\right)\right)$.}
}

\stitle{Time cost}. 
Let $|R_u|$ be the total number of 
attributes in the universal schema 
$R_u$ of $D_u$, and $|\ad_m|$ be the size of the largest active domain. \apxmodis performs 
$|R_u|$ levels of  
spawning, and at each node, 
it spawns at most $|R_u|$ + $|\ad_m|$ 
children, given that it 
``flips'' one attribute for each reduction, and for 
each attribute, at most one domain value 
to mask. Let $N_u$ be $|R_u|$+$|\ad_m|$. 
Thus, \apxmodis valuates 
at most $\min(N_u^{|R_u|}, N)$ 
nodes (datasets), taking $I\cdot \min(N_u^{|R_u|}, N)$ 
time, where $I$ 
refers to a polynomial time 
valuation cost of $\E$ per test. 
For each node, it then takes at most $\prod_{i=1}^{|\P|-1}\left(\left\lfloor\log _{1+\epsilon}\frac{p_{u_i}}{p_{l_i}}\right\rfloor+1\right))$ 
time to update the $\epsilon$-Skyline set. 
Given $\epsilon$ is small, $\log (1 + \epsilon) \approx \epsilon$, and the total cost is 
in $O\left(\min(N_u^{|R_u|}, N)\cdot \left(\left(\frac{\log(p_m)}{\epsilon}\right)^{|\P|-1}+I\right)\right)$ time. 
 %%%%%%%
Given $|R_u|$ and $|\P|$ are small constants, 
the cost is polynomial in the 
input size $|D_u|$, $N$ and $\frac{1}{\epsilon}$. 
Theorem~\ref{thm-fptas} thus follows. 
%The above analysis also suggests that 
%The analysis also suggests that 

\stitle{An FPTAS case}. 
We next present a case when \apxmodis 
ensures a stronger optimality guarantee. 
We say an $(N, \epsilon)$-approximation 
is a {\em fully polynomial time} approximation (FPTAS) 
for \modis, if 
(1) it computes 
an $\epsilon$-Skyline set 
for $\D_S$, where $\D_S$ 
refers to all possible datasets 
that can be generated from $D_U$, 
and (2) it runs in 
time polynomial in the size of 
$|D_U|$ and $\frac{1}{\epsilon}$. 

%confirms that 
%\apxmodis provides a stronger guarantee for \modis 
%when $N$ is polynomially bounded by the universal dataset size $|D_U|$. 
%Given a data discovery system $\T$ and configuration $C$, let 
%$\D_S$ be the finite set of all the datasets 
%that can be generated by $\T$. 

\begin{lemma}
\label{cor-fptas}
Given a skyline dataset generator $\T$ with configuration $C$, 
if $|\D_S|$ has a size that is polynomially bounded in $O(f(|D_U|))$, 
then \apxmodis is an FPTAS for \modis. 
\end{lemma}

\begin{proofS}
We show this by a reduction from 
\modis to \mos, similarly as 
in the approximability analysis. \mos 
is known to have a fully polynomial 
time approximable (FPTAS) in terms of 
$\epsilon$-dominance. We set \apxmodis to run as 
a $(|\D_S|, \epsilon)$-approximation, 
which is a simplified implementation of an  
FPTAS in~\cite{tsaggouris2009multiobjective} with multiple 
rounds of ``replacement'' 
strategy following path dominance. 
As 
$|\D_S|$ is bounded by a polynomial of  
the input size $|D_U|$, 
it approximates 
a Skyline set for all in PTME. 
\end{proofS}

The size bound of $\D_S$ is  
pragmatic and practical due to 
that the attributes often bear 
active domains that are 
much smaller than 
dataset size. 
Indeed, data science applications  
typically consider data with values 
under task-specific constraints.  
%(\eg 
%gender/age groups, physical models, 
%types of ). 
These suggest practical 
application of \apxmodis 
with affordable setting of 
$N$ and $\epsilon$. 
%approximation solutions for \modis. 
We present the detailed analysis in~\cite{full}. 

\eat{
it processes at most $N$ 
state nodes. At each node, it takes $O(|\ad_m|)$ 
time to spawn the children, and let each spawned edge 
take a valuation time of $I_\E$. 
Thus the total verification time takes 
$O(N|R_u||\ad_m|I_\E)$. 

in the main iteration (line~\ref{its:main} to \ref{ite:main}), for each depth from 1 to n, we evaluate all possible incoming transitions into the state at that depth. In the Extend\&Merge function, we may reach out to all paths in the Skyline set. So the Time Complexity is $O\left(n|D_U|^n\prod_{i=1}^{|\P|-1}\left(\left\lfloor\log _{1+\epsilon}\frac{p^{max}_i}{p^{min}_i}\right\rfloor+1\right)\right)$. Let's denote $P^{max}$ as the maximum value of $\frac{p_i^{max}}{p_i^{min}}$, given $\epsilon$ is small enough, so $\log (1 + \epsilon) \approx \epsilon$, then Time Complexity is $O\left(n|D_U|^n\left(\frac{\log(P^{max})}{\epsilon}\right)^{|\P|-1}\right)$.
}
