\section{Background}
\label{sec:background}
\subsection{DRAM Organization and Operation}
\label{sec:dram_organization}

\head{Organization}
\figref{fig:dram_organization} shows the hierarchical organization of a modern DRAM-based main memory. The memory controller connects to a DRAM module over a memory channel. A module contains one or multiple DRAM ranks that time-share the memory channel.
A rank consists of multiple DRAM chips.
Each DRAM chip has multiple DRAM banks each of which contains multiple subarrays. A DRAM bank is organized as a two-dimensional array of DRAM cells, where a row of cells is called a DRAM row. A DRAM cell consists of 1) a storage capacitor, which stores one bit of information in the form of electrical charge, and 2) an access transistor.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures/background.png}
    \caption{DRAM organization}
    \label{fig:dram_organization}
\end{figure}

\head{Operation}
To access a DRAM row, the memory controller issues a set of commands to DRAM over the memory channel. The memory controller sends an $ACT$ command to activate a DRAM row, which asserts the corresponding wordline and loads the row data into the row buffer. Then, the memory controller can issue \emph{RD}/\emph{WR} \om{3}{commands} to read from/write into the DRAM row.
\om{3}{An access} to the row \om{3}{that is already in the row buffer causes} a row hit.
To access a different row, the memory controller must \ous{4}{first close the opened row and prepare the bank for a new activation} by issuing a $PRE$ command.
Therefore, accessing a different row \om{3}{from the one in the row buffer} causes a row conflict \om{3}{in the row buffer}.

DRAM cells are inherently leaky and lose their charge over time due to charge leakage in the access transistor and the storage capacitor.
\om{3}{To} maintain data integrity, the memory controller periodically refreshes each row in a time interval called \gls{trefw} ($32 ms$ for DDR5~\cite{jedec2020ddr5} and $64 ms$ for DDR4~\cite{jedec2017ddr4}).
To ensure all rows are refreshed every \gls{trefw}, the memory controller issues $REF$ commands with a time interval called \gls{trefi} ($3.9 \mu s$ for DDR5~\cite{jedec2020ddr5} and $7.8 \mu s$ for DDR4~\cite{jedec2017ddr4}).

\head{Timing Parameters}
To ensure correct operation, the memory controller must obey specific timing parameters while accessing DRAM.
In addition to \gls{trefw} and \gls{trefi}, we explain \param{three} timing parameters related to the rest of the paper:
i) the minimum time interval between two consecutive ACT commands targeting the same bank ($t_{RC}$),
ii) the minimum time needed to issue a PRE command following an ACT command ($t_{RAS}$), and
iii) the minimum time needed to issue an ACT command following a PRE command ($t_{RP}$).
\om{3}{Detailed explanations of these parameters can be found in \cite{kim2012acase, lee2013tiered, lee2015adaptive}}.

\subsection{DRAM Read Disturbance}
As DRAM manufacturing technology node size shrinks, interference across rows increases, \om{3}{exacerbating} circuit-level read disturbance mechanisms.
Two prime examples of read disturbance mechanisms are RowHammer~\cite{kim2014flipping} and RowPress~\cite{luo2023rowpress}, where repeatedly activating \ous{3}{(i.e., hammering)} a DRAM row (i.e., aggressor row) or keeping the aggressor row active for a long time \ous{3}{(i.e., pressing)} induces bitflips in physically nearby rows (i.e., victim rows), respectively.
\ous{3}{To induce read disturbance bitflips, 1) an aggressor row needs to be hammered more than a threshold value called \gls{nrh}~\cite{kim2014flipping} or 2) an aggressor needs to be pressed for long enough~\cite{kim2020revisiting, orosa2021deeper, yaglikci2022understanding, luo2023rowpress}}.\omcomment{3}{define and use hammer and press. Background is similar to PACRAM and same mistakes are repeated. Can we make them less similar?}\ouscomment{3}{Acknowledged. This background should be from our DRAMSec version and BreakHammer but I will revisit the background and improve it.}
\om{3}{Various} characterization studies~\understandingRowHammerAllCitations{} show that as DRAM \om{3}{technology} scaling continues to smaller \om{4}{technology} node \om{3}{sizes}, DRAM chips are \om{3}{becoming} more vulnerable to \ous{3}{read disturbance} (i.e., newer chips have lower \gls{nrh} values).
For example, one can induce RowHammer bitflips \ous{4}{by activating two aggressors that are physically adjacent to a victim row (i.e., double-sided RowHammer) 4.8K times each} in the chips manufactured in 2020 while a row needs to be hammered \ous{4}{69.2K times in older chips manufactured in 2013~\cite{kim2020revisiting}}.\omcomment{5}{Please find out if this issue exists elsewhere.}\ouscomment{5}{Acknowledged. The following papers seem fine: DRAMSec version, BreakHammer, PACRAM, and VRD.}
To make matters worse, RowPress~\cite{luo2023rowpress} reduces \gls{nrh} by \om{3}{1-2 orders} of magnitude. 

\head{DRAM Read Disturbance Mitigation Mechanisms}
Many prior works propose mitigation techniques~\mitigatingRowHammerAllCitations{} to protect DRAM chips against RowHammer bitflips leveraging different approaches.
These mechanisms perform two tasks: 1)~execute a trigger algorithm and 2)~perform preventive actions.
The trigger algorithm observes the memory access patterns and triggers a preventive action based on the result of a probabilistic or a deterministic process. The preventive action is one of  1)~preventively refreshing victim row~\refreshBasedRowHammerDefenseCitations{},
2) dynamically remapping aggressor rows~\cite{saileshwar2022randomized, saxena2022aqua, wi2023shadow, woo2023scalable}, and
3)~throttling unsafe accesses~\cite{greenfield2012throttling, yaglikci2021blockhammer}.
Existing RowHammer mitigation mechanisms can also prevent RowPress bitflips when their trigger algorithms are configured to be more aggressive, which is practically equivalent to configuring them for sub-1K \gls{nrh} values~\cite{luo2023rowpress}.
Unfortunately, existing RowHammer mitigation mechanisms incur prohibitively large performance overheads at low \gls{nrh} values (i.e., sub-1K) \om{3}{because they more aggressively perform} preventive actions.
Given that DRAM read disturbance worsens with shrinking technology node size, \gls{nrh} values are expected to reduce even more~\cite{yaglikci2024spatial, kim2014flipping, orosa2021deeper}.
Therefore, reducing the performance overhead of existing RowHammer mitigation mechanisms is critical.

\head{\gls{prac}}
Various prior works discuss the use of per-row activation counters to detect how many times each row in DRAM is activated within a refresh interval~\cite{kim2014flipping,kim2014architectural,bennett2021panopticon,kim2023ddr5,yaglikci2021security}.
A recent update (as of April 2024) of the JEDEC DDR5 specification~\cite{saroiu2024ddr5, jedec2024jesd795c} introduces a similar on-DRAM-die read disturbance mitigation mechanism called \gls{prac} (explained in \secref{sec:briefsummary}), which aims to ensure robust operation at low overhead by preventively refreshing victim rows when necessary.
Although \gls{prac} is a promising DRAM specification advancement, \emph{no} prior work rigorously analyzes \gls{prac}'s impact on security, performance, energy, and cost for modern and future systems.\footnote{\om{3}{An earlier version of this paper was presented at DRAMSec 2024~\cite{canpolat2024understanding}}.}