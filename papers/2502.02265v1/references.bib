

@inproceedings{moro_goal-directed_2022,
  title={Goal-directed planning via hindsight experience replay},
  author={Moro, Lorenzo and Likmeta, Amarildo and Prati, Enrico and Restelli, Marcello and others},
  booktitle={10th International Conference on Learning Representations, ICLR 2022},
  pages={1--16},
  year={2022}
}

@inproceedings{pathak_curiosity-driven_2017,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={2778--2787},
  year={2017},
  organization={PMLR}
}

@article{liu_goal-conditioned_2022,
  title={Goal-conditioned reinforcement learning: Problems and solutions},
  author={Liu, Minghuan and Zhu, Menghui and Zhang, Weinan},
  journal={arXiv preprint arXiv:2201.08299},
  year={2022}
}

@article{tracey_towards_2023,
  title={Towards practical reinforcement learning for tokamak magnetic control},
  author={Tracey, Brendan D and Michi, Andrea and Chervonyi, Yuri and Davies, Ian and Paduraru, Cosmin and Lazic, Nevena and Felici, Federico and Ewalds, Timo and Donner, Craig and Galperti, Cristian and others},
  journal={Fusion Engineering and Design},
  volume={200},
  pages={114161},
  year={2024},
  publisher={Elsevier}
}

@article{kiran_deep_2021,
  title={Deep reinforcement learning for autonomous driving: A survey},
  author={Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Al Sallab, Ahmad A and Yogamani, Senthil and P{\'e}rez, Patrick},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={6},
  pages={4909--4926},
  year={2021},
  publisher={IEEE}
}

@article{andrychowicz_hindsight_2018,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{lillicrap_continuous_2019,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, TP},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{haarnoja_soft_2018,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@inproceedings{rusu_sim--real_2018,
  title={Sim-to-real robot learning from pixels with progressive nets},
  author={Rusu, Andrei A and Ve{\v{c}}er{\'\i}k, Matej and Roth{\"o}rl, Thomas and Heess, Nicolas and Pascanu, Razvan and Hadsell, Raia},
  booktitle={Conference on robot learning},
  pages={262--270},
  year={2017},
  organization={PMLR}
}

@article{nachum_data-efficient_2018,
  title={Data-efficient hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang Shane and Lee, Honglak and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{hu_learning_2020,
  title={Learning to utilize shaping rewards: A new approach of reward shaping},
  author={Hu, Yujing and Wang, Weixun and Jia, Hangtian and Wang, Yixiang and Chen, Yingfeng and Hao, Jianye and Wu, Feng and Fan, Changjie},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15931--15941},
  year={2020}
}

@inproceedings{zhao_sim--real_2020,
  title={Sim-to-real transfer in deep reinforcement learning for robotics: a survey},
  author={Zhao, Wenshuai and Queralta, Jorge Pe{\~n}a and Westerlund, Tomi},
  booktitle={2020 IEEE symposium series on computational intelligence (SSCI)},
  pages={737--744},
  year={2020},
  organization={IEEE}
}

@inproceedings{ramakrishnan_discovering_2018,
  title={Discovering Blind Spots in Reinforcement Learning},
  author={Ramakrishnan, Ramya and Kamar, Ece and Dey, Debadeepta and Shah, Julie and Horvitz, Eric},
  booktitle={Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={1017--1025},
  year={2018}
}

@article{breyer_comparing_2019,
  title={Comparing task simplifications to learn closed-loop object picking using deep reinforcement learning},
  author={Breyer, Michel and Furrer, Fadri and Novkovic, Tonci and Siegwart, Roland and Nieto, Juan},
  journal={IEEE Robotics and Automation Letters},
  volume={4},
  number={2},
  pages={1549--1556},
  year={2019},
  publisher={IEEE}
}

@inproceedings{zhao_towards_2020,
  title={Towards closing the sim-to-real gap in collaborative multi-robot deep reinforcement learning},
  author={Zhao, Wenshuai and Queralta, Jorge Pena and Qingqing, Li and Westerlund, Tomi},
  booktitle={2020 5th International conference on robotics and automation engineering (ICRAE)},
  pages={7--12},
  year={2020},
  organization={IEEE}
}

@inproceedings{james_sim--real_2019,
  title={Sim-to-real via sim-to-sim: Data-efficient robotic grasping via randomized-to-canonical adaptation networks},
  author={James, Stephen and Wohlhart, Paul and Kalakrishnan, Mrinal and Kalashnikov, Dmitry and Irpan, Alex and Ibarz, Julian and Levine, Sergey and Hadsell, Raia and Bousmalis, Konstantinos},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12627--12637},
  year={2019}
}

@article{li_pid_2006,
  title={PID control system analysis and design},
  author={Li, Yun and Ang, Kiam Heong and Chong, Gregory CY},
  journal={IEEE Control Systems Magazine},
  volume={26},
  number={1},
  pages={32--41},
  year={2006},
  publisher={IEEE}
}

@article{darby_mpc_2012,
  title={MPC: Current practice and challenges},
  author={Darby, Mark L and Nikolaou, Michael},
  journal={Control Engineering Practice},
  volume={20},
  number={4},
  pages={328--342},
  year={2012},
  publisher={Elsevier}
}

@article{zhuang_comprehensive_2020,
  title={A comprehensive survey on transfer learning},
  author={Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
  journal={Proceedings of the IEEE},
  volume={109},
  number={1},
  pages={43--76},
  year={2020},
  publisher={Ieee}
}

@article{schulman_proximal_2017,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{levine_end--end_2016,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={39},
  pages={1--40},
  year={2016}
}

@article{busoniu_reinforcement_2018,
  title={Reinforcement learning for control: Performance, stability, and deep approximators},
  author={Bu{\c{s}}oniu, Lucian and De Bruin, Tim and Toli{\'c}, Domagoj and Kober, Jens and Palunko, Ivana},
  journal={Annual Reviews in Control},
  volume={46},
  pages={8--28},
  year={2018},
  publisher={Elsevier}
}

@article{zhang_brief_2023,
  title={A brief survey on nonlinear control using adaptive dynamic programming under engineering-oriented complexities},
  author={Zhang, Yuhan and Zou, Lei and Liu, Yang and Ding, Derui and Hu, Jun},
  journal={International Journal of Systems Science},
  volume={54},
  number={8},
  pages={1855--1872},
  year={2023},
  publisher={Taylor \& Francis}
}

@article{mayne_constrained_2000,
  title={Constrained model predictive control: Stability and optimality},
  author={Mayne, David Q and Rawlings, James B and Rao, Christopher V and Scokaert, Pierre OM},
  journal={Automatica},
  volume={36},
  number={6},
  pages={789--814},
  year={2000},
  publisher={Elsevier}
}

@article{borase_review_2021,
  title={A review of PID control, tuning methods and applications},
  author={Borase, Rakesh P and Maghade, DK and Sondkar, SY and Pawar, SN},
  journal={International Journal of Dynamics and Control},
  volume={9},
  pages={818--827},
  year={2021},
  publisher={Springer}
}

@inproceedings{gu_continuous_2016,
  title={Continuous deep q-learning with model-based acceleration},
  author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={2829--2838},
  year={2016},
  organization={PMLR}
}

@inproceedings{badnava_new_2023,
  title={A new potential-based reward shaping for reinforcement learning agent},
  author={Badnava, Babak and Esmaeili, Mona and Mozayani, Nasser and Zarkesh-Ha, Payman},
  booktitle={2023 IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC)},
  pages={01--06},
  year={2023},
  organization={IEEE}
}

@inproceedings{burda_exploration_2018,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  booktitle={Seventh International Conference on Learning Representations},
  pages={1--17},
  year={2019}
}

@article{cheng_neural-network-based_2024,
  title={Neural-network-based nonlinear optimal terminal guidance with impact angle constraints},
  author={Cheng, Lin and Wang, Han and Gong, Shengping and Huang, Xu},
  journal={IEEE Transactions on Aerospace and Electronic Systems},
  year={2023},
  publisher={IEEE}
}

@article{qu_dynamic-matching_2024,
  title={Dynamic-matching adaptive sliding mode control for hypersonic vehicles},
  author={Qu, Chaoran and Cheng, Lin and Gong, Shengping and Huang, Xu},
  journal={Aerospace Science and Technology},
  volume={149},
  pages={109159},
  year={2024},
  publisher={Elsevier}
}

#added by pyb
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group UK London}
}
@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}
@inproceedings{hutter2016anymal,
  title={Anymal-a highly mobile and dynamic quadrupedal robot},
  author={Hutter, Marco and Gehring, Christian and Jud, Dominic and Lauber, Andreas and Bellicoso, C Dario and Tsounis, Vassilios and Hwangbo, Jemin and Bodie, Karen and Fankhauser, Peter and Bloesch, Michael and others},
  booktitle={2016 IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  pages={38--44},
  year={2016},
  organization={IEEE}
}
@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}
@article{liu2019review,
  title={A review of industrial MIMO decoupling control},
  author={Liu, Lu and Tian, Siyuan and Xue, Dingyu and Zhang, Tao and Chen, YangQuan and Zhang, Shuo},
  journal={International Journal of Control, Automation and Systems},
  volume={17},
  number={5},
  pages={1246--1254},
  year={2019},
  publisher={Springer}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={International conference on machine learning},
  pages={387--395},
  year={2014},
  organization={Pmlr}
}

@inproceedings{tessler2019action,
  title={Action robust reinforcement learning and applications in continuous control},
  author={Tessler, Chen and Efroni, Yonathan and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={6215--6224},
  year={2019},
  organization={PMLR}
}

@inproceedings{cao2023learning,
  title={Learning sim-to-real dense object descriptors for robotic manipulation},
  author={Cao, Hoang-Giang and Zeng, Weihao and Wu, I-Chen},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={9501--9507},
  year={2023},
  organization={IEEE}
}

@inproceedings{flet2021adversarially,
  title={Adversarially Guided Actor-Critic},
  author={Flet-Berliac, Yannis and Ferret, Johan and Pietquin, Olivier and Preux, Philippe and Geist, Matthieu},
  booktitle={ICLR 2021-International Conference on Learning Representations},
  year={2021}
}