It is well known that the randomized $4$-approximation algorithm for max-dicut can be derandomized \citep{halperin2001combinatorial,bar2012online}.
For completeness, we reproduce the derandomization due to Theorem 3 of \citet{bar2012online} below.
Additionally, we show that this algorithm can be implemented to run in $\order(|V|^2)$.

Let $G=(V, E)$ be a directed graph with edge weights $w:E \to \mathbb{R}_{\geq 0}$.
In the following, let $S, \bar{S} \subseteq V$ with $S \cap \bar{S} = \emptyset$.
They define the partial dicut $\{ij \in E \mid i \in S, j \in \bar{S}\}$.
We denote the expected value of the dicut that is obtained by randomly assigning elements in $V \setminus (S \cup \bar{S})$ to either $S$ or $\bar{S}$ by $E_{S\bar{S}}$.
It holds that
\begin{align*}
    E_{S\bar{S}} = 
        &   \sum_{\substack{ij \in E: \\ i \in S, j \in \bar{S}}} w_{ij} 
          + \sum_{\substack{ij \in E: i \in S, \\ j \in V \setminus (S \cup \bar{S})}} \frac{w_{ij}}{2} \\
        & + \sum_{\substack{ij \in E: j \in \bar{S}, \\ i \in V \setminus (S \cup \bar{S})}} \frac{w_{ij}}{2} 
          + \sum_{\substack{ij \in E: \\ i,j \in V \setminus (S \cup \bar{S})}} \frac{w_{ij}}{4} \enspace . 
\end{align*}
For $k \in V \setminus (S \cup \bar{S})$, let $g_k$ denote the change in the expected value after assigning $k$ to $S$.
A simple calculation yields
\begin{align*}
    g_k = & E_{S\cup\{k\}\bar{S}} - E_{S\bar{S}} = 
        \sum_{\substack{j \in \bar{S}: \\ kj \in E}} \frac{w_{kj}}{2}
        - \sum_{\substack{i \in S: \\ ik \in E}} \frac{w_{ik}}{2} \\
        & + \sum_{\substack{j \in V \setminus (S \cup \{k\} \cup \bar{S}): \\ kj \in E}} \frac{w_{kj}}{4}
        - \sum_{\substack{i \in V \setminus (S \cup \{k\} \cup \bar{S}): \\ ik \in E}} \frac{w_{ik}}{4}
\end{align*}
and 
\begin{align*}
    E_{S\bar{S}\cup\{k\}} &- E_{S\bar{S}} = - g_k \enspace .
\end{align*}
If $g_k$ is non-negative, assigning $k$ to $S$ does not decrease the expected value; otherwise, assigning $k$ to $\bar{S}$ does not decrease the expected value.

When assigning all elements randomly, the expected value is $E_{\emptyset\emptyset} = \sum_{ij \in E} \frac{w_{ij}}{4}$.
By iteratively assigning elements $k \in V \setminus (S \cup \bar{S})$ to $S$ or $\bar{S}$ based on the sign of $g_k$, a dicut is obtained with value at least $E_{\emptyset\emptyset}$ and, therefore, a $4$-approximation to the max-dicut problem.

\Cref{alg:max-di-cut} implements this algorithm with two additional improvements:
Firstly, in each iteration, the element $k \in V \setminus (S \cup \bar{S})$ for which $|g_k|$ is greatest is selected.
This maximizes the expected value after assigning $k$.
Secondly, the values $g_k$ for $k \in V \setminus (S \cup \bar{S})$ are not computed from scratch in each iteration.
Instead, they are computed once for $S=\bar{S}=\emptyset$, and after each iteration, these values are updated.
With this, each iteration runs in time $\order(|V|)$ instead of $\order(|V|^2)$ that would be required to compute all $g$ values according to the formula above.

