\section{Related Work}
\label{related_work_section}

%Here just discuss other literature reviews related to AI ethics. You can just build on "related work" from this and modify slightly: https://helda.helsinki.fi/server/api/core/bitstreams/6996a645-6972-472d-87f7-7b60349e37b9/content

In the context of this study, we examine previous literature reviews related to LLM and genAI trust/trustworthiness and ethics in the context of this study. Among the most relevant works is that of Liu et al., "A Taxonomy for Evaluating Trustworthiness in LLM," which proposes a taxonomy for evaluating trustworthiness in LLM in seven major categories: reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness. Although the paper is not a literature review, it does describe each of the major categories with examples. However, the authors fail to provide a clear definition of what is trustworthy and do not provide practical guidance for developers on how to operationalise their taxonomy.

Albahri et al., "Systematic Science Mapping Analysis in Trustworthy and Explainable AI (XAI) in Healthcare Systems," conducted a systematic science mapping analysis in the context of trustworthy and explainable AI (XAI) in healthcare systems, and found various XAI techniques for developers to operationalise. Unlike their approach, we aim to provide means to operationalise more of the trustworthiness categories.

It can be seen that many scholars have provided reviews of AI ethical principles, such as Floridi et al., "The Ethics of Information," Amoore et al., "Cloud Ethics: A Politics of Practices, Dispositions and Movements," Castelluccia et al., "Big Data and the Future of Privacy," Sadowska et al., "Fairness in Machine Learning," and Mittelstadt et al., "Assuring Transparency and Accountability in AI Development," also providing an overview of publicly available tools that can help operationalise ethical principles in AI. However, they are not as relevant to our review as they appeared before the LLM and genAI hype, and we want to explore the notion of trustworthiness in LLM and genAI and how it relates to ethics in AI, also providing practical guidance for developers to operationalise it.

%Eu adicionei esse aqui pq usa Bibliometrix
%A systematic review of trustworthy and explainable artificial intelligence in healthcare: Assessment of quality, bias risk, and data fusion