\section{Related Work}
\label{related_work_section}

%Here just discuss other literature reviews related to AI ethics. You can just build on "related work" from this and modify slightly: https://helda.helsinki.fi/server/api/core/bitstreams/6996a645-6972-472d-87f7-7b60349e37b9/content

In the context of this study, we examine previous literature reviews related to LLM and genAI trust/trustworthiness and ethics in the context of this study. Among the most relevant works is that of Liu et al. ____, which proposes a taxonomy for evaluating trustworthiness in LLM in seven major categeories: reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness. Although the paper is not a literature review, it does describe each of the major categories with examples. However, the authors fail to provide a clear definition of what is trustworthy and do not provide practical guidance for developers on how to operationalise their taxonomy.

Albahri et al. ____ conducted a systematic science mapping analysis in the context of trustworthy and explainable AI (XAI) in healthcare systems, and found various XAI techniques for developers to operationalise. Unlike their approach, we aim to provide means to operationalise more of the trustworthiness categories.

It can be seen that many scholars have provided reviews of AI ethical principles, such as ____, ____, ____, ____, ____, also providing an overview of publicly available tools that can help operationalise ethical principles in AI ____. However, they are not as relevant to our review as they appeared before the LLM and genAI hype, and we want to explore the notion of trustworthiness in LLM and genAI and how it relates to ethics in AI, also providing practical guidance for developers to operationalise it.

%Eu adicionei esse aqui pq usa Bibliometrix
%A systematic review of trustworthy and explainable artificial intelligence in healthcare: Assessment of quality, bias risk, and data fusion