
@inproceedings{35,
	address = {Barcelona, Spain},
	title = {Coupled {Generative} {Adversarial} {Networks}},
	volume = {29},
	url = {https://proceedings.neurips.cc/paper_files/paper/2016/hash/502e4a16930e414107ee22b6198c578f-Abstract.html},
	abstract = {We propose the coupled generative adversarial nets (CoGAN) framework for generating pairs of corresponding images in two different domains. The framework consists of a pair of generative adversarial nets, each responsible for generating images in one domain. We show that by enforcing a simple weight-sharing constraint, the CoGAN learns to generate pairs of corresponding images without existence of any pairs of corresponding images in the two domains in the training set. In other words, the CoGAN learns a joint distribution of images in the two domains from images drawn separately from the marginal distributions of the individual domains. This is in contrast to the existing multi-modal generative models, which require corresponding images for training. We apply the CoGAN to several pair image generation tasks. For each task, the CoGAN learns to generate convincing pairs of corresponding images. We further demonstrate the applications of the CoGAN framework for the domain adaptation and cross-domain image generation tasks.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Liu, Ming-Yu and Tuzel, Oncel},
	year = {2016},
	pages = {--},
}

@inproceedings{2,
	address = {Virtual event},
	series = {8},
	title = {Evaluation of {Risk} {Factors} for {Fall} in {Elderly} {People} from {Imbalanced} {Data} using the {Oversampling} {Technique} {SMOTE}},
	volume = {8},
	isbn = {978-989-758-566-1},
	shorttitle = {Evaluation of {Risk} {Factors} for {Fall} in {Elderly} {People} from {Imbalanced} {Data} using the {Oversampling} {Technique} {SMOTE}},
	doi = {10.5220/0011041200003188},
	abstract = {Prevention of falls requires providing a small number of recommendations based on the risk factors present for a person. This article deals with the evaluation of 12 modiﬁable risk factors for fall, based on a selection of 45 variables from a real data set. The results of four classiﬁers (Logistic Regression, Random Forest, Artiﬁcial Neural Networks, and Bayesian Networks) are compared when using the initial imbalanced data set, and after using the balancing method SMOTE. We have compared the results using four different measures to evaluate their performance (balanced accuracy, area under the Receiver Operating Characteristic (ROC) curve F1-score, and F2-score). The results show that there is a signiﬁcant improvement for all the classiﬁers when classifying each target risk factor using the data after balancing with SMOTE.},
	language = {en},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Information} and {Communication} {Technologies} for {Ageing} {Well} and e-{Health}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Sihag, Gulshan and Yadav, Pankaj and Delcroix, Veronique and Vijay, Vivek and Siebert, Xavier and Yadav, Sandeep and Puisieux, François},
	year = {2022},
	pages = {50--58},
}

@article{154,
	title = {Credit {Card} {Fraud} {Detection} {Based} on {Improved} {Variational} {Autoencoder} {Generative} {Adversarial} {Network}},
	volume = {11},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2023.3302339},
	abstract = {The rapid spread of mobile banking and e-commerce has coincided with a dramatic increase in fraudulent online payments in recent years. Although machine learning and deep learning are widely used in credit card fraud detection, the typical credit card transaction data set is unbalanced, and the fraud data is much less than the normal transaction data, limiting the effectiveness of traditional binary classification algorithms. To overcome this issue, researchers oversample minority class data and utilize ensemble learning classification algorithms. However, oversampling still has disadvantages. Hence, we improve the generator part of the Variational Autoencoder Generative Adversarial Network (VAEGAN) and propose a new oversampling method that generates convincing and diverse minority class data. The training set is enhanced by generating minority class fraud data to train the ensemble learning classification model. The method is tested on an open credit card dataset, with the experimental results demonstrating that the oversampling method utilizing the improved VAEGAN is superior to the oversampling method of Generative Adversarial Network (GAN), Variational Autoencoder (VAE), and Synthetic Minority Oversampling Technique (SMOTE) in terms of Precision, F1\_score, and other indicators. The oversampling method based on the improved VAEGAN effectively deals with the classification problem of imbalanced data.},
	journal = {IEEE Access},
	author = {Ding, Yuanming and Kang, Wei and Feng, Jianxin and Peng, Bo and Yang, Anna},
	year = {2023},
	keywords = {Banking, Credit card fraud, Credit cards, Data models, Electronic commerce, Encoding, Ensemble learning, Fraud, Generative adversarial networks, Machine learning algorithms, ensemble learning, oversampling, variational autoencoder generative adversarial network},
	pages = {83680--83691},
}

@article{hoang_mgan_2018,
	title = {{MGAN}: {TRAINING} {GENERATIVE} {ADVERSARIAL} {NETS} {WITH} {MULTIPLE} {GENERATORS}},
	abstract = {We propose in this paper a new approach to train the Generative Adversarial Nets (GANs) with a mixture of generators to overcome the mode collapsing problem. The main intuition is to employ multiple generators, instead of using a single one as in the original GAN. The idea is simple, yet proven to be extremely effective at covering diverse data modes, easily overcoming the mode collapsing problem and delivering state-of-the-art results. A minimax formulation was able to establish among a classiﬁer, a discriminator, and a set of generators in a similar spirit with GAN. Generators create samples that are intended to come from the same distribution as the training data, whilst the discriminator determines whether samples are true data or generated by generators, and the classiﬁer speciﬁes which generator a sample comes from. The distinguishing feature is that internal samples are created from multiple generators, and then one of them will be randomly selected as ﬁnal output similar to the mechanism of a probabilistic mixture model. We term our method Mixture Generative Adversarial Nets (MGAN). We develop theoretical analysis to prove that, at the equilibrium, the Jensen-Shannon divergence (JSD) between the mixture of generators’ distributions and the empirical data distribution is minimal, whilst the JSD among generators’ distributions is maximal, hence effectively avoiding the mode collapsing problem. By utilizing parameter sharing, our proposed model adds minimal computational cost to the standard GAN, and thus can also efﬁciently scale to large-scale datasets. We conduct extensive experiments on synthetic 2D data and natural image databases (CIFAR-10, STL-10 and ImageNet) to demonstrate the superior performance of our MGAN in achieving state-of-the-art Inception scores over latest baselines, generating diverse and appealing recognizable objects at different resolutions, and specializing in capturing different types of objects by the generators.},
	language = {en},
	author = {Hoang, Quan and Nguyen, Tu Dinh and Le, Trung and Phung, Dinh},
	year = {2018},
}

@article{hoang_mgan_2018-1,
	title = {{MGAN}: {TRAINING} {GENERATIVE} {ADVERSARIAL} {NETS} {WITH} {MULTIPLE} {GENERATORS}},
	abstract = {We propose in this paper a new approach to train the Generative Adversarial Nets (GANs) with a mixture of generators to overcome the mode collapsing problem. The main intuition is to employ multiple generators, instead of using a single one as in the original GAN. The idea is simple, yet proven to be extremely effective at covering diverse data modes, easily overcoming the mode collapsing problem and delivering state-of-the-art results. A minimax formulation was able to establish among a classiﬁer, a discriminator, and a set of generators in a similar spirit with GAN. Generators create samples that are intended to come from the same distribution as the training data, whilst the discriminator determines whether samples are true data or generated by generators, and the classiﬁer speciﬁes which generator a sample comes from. The distinguishing feature is that internal samples are created from multiple generators, and then one of them will be randomly selected as ﬁnal output similar to the mechanism of a probabilistic mixture model. We term our method Mixture Generative Adversarial Nets (MGAN). We develop theoretical analysis to prove that, at the equilibrium, the Jensen-Shannon divergence (JSD) between the mixture of generators’ distributions and the empirical data distribution is minimal, whilst the JSD among generators’ distributions is maximal, hence effectively avoiding the mode collapsing problem. By utilizing parameter sharing, our proposed model adds minimal computational cost to the standard GAN, and thus can also efﬁciently scale to large-scale datasets. We conduct extensive experiments on synthetic 2D data and natural image databases (CIFAR-10, STL-10 and ImageNet) to demonstrate the superior performance of our MGAN in achieving state-of-the-art Inception scores over latest baselines, generating diverse and appealing recognizable objects at different resolutions, and specializing in capturing different types of objects by the generators.},
	language = {en},
	author = {Hoang, Quan and Nguyen, Tu Dinh and Le, Trung and Phung, Dinh},
	year = {2018},
}

@article{hoang_mgan_2018-2,
	title = {{MGAN}: {TRAINING} {GENERATIVE} {ADVERSARIAL} {NETS} {WITH} {MULTIPLE} {GENERATORS}},
	abstract = {We propose in this paper a new approach to train the Generative Adversarial Nets (GANs) with a mixture of generators to overcome the mode collapsing problem. The main intuition is to employ multiple generators, instead of using a single one as in the original GAN. The idea is simple, yet proven to be extremely effective at covering diverse data modes, easily overcoming the mode collapsing problem and delivering state-of-the-art results. A minimax formulation was able to establish among a classiﬁer, a discriminator, and a set of generators in a similar spirit with GAN. Generators create samples that are intended to come from the same distribution as the training data, whilst the discriminator determines whether samples are true data or generated by generators, and the classiﬁer speciﬁes which generator a sample comes from. The distinguishing feature is that internal samples are created from multiple generators, and then one of them will be randomly selected as ﬁnal output similar to the mechanism of a probabilistic mixture model. We term our method Mixture Generative Adversarial Nets (MGAN). We develop theoretical analysis to prove that, at the equilibrium, the Jensen-Shannon divergence (JSD) between the mixture of generators’ distributions and the empirical data distribution is minimal, whilst the JSD among generators’ distributions is maximal, hence effectively avoiding the mode collapsing problem. By utilizing parameter sharing, our proposed model adds minimal computational cost to the standard GAN, and thus can also efﬁciently scale to large-scale datasets. We conduct extensive experiments on synthetic 2D data and natural image databases (CIFAR-10, STL-10 and ImageNet) to demonstrate the superior performance of our MGAN in achieving state-of-the-art Inception scores over latest baselines, generating diverse and appealing recognizable objects at different resolutions, and specializing in capturing different types of objects by the generators.},
	language = {en},
	author = {Hoang, Quan and Nguyen, Tu Dinh and Le, Trung and Phung, Dinh},
	year = {2018},
}

@article{hoang_mgan_2018-3,
	title = {{MGAN}: {TRAINING} {GENERATIVE} {ADVERSARIAL} {NETS} {WITH} {MULTIPLE} {GENERATORS}},
	abstract = {We propose in this paper a new approach to train the Generative Adversarial Nets (GANs) with a mixture of generators to overcome the mode collapsing problem. The main intuition is to employ multiple generators, instead of using a single one as in the original GAN. The idea is simple, yet proven to be extremely effective at covering diverse data modes, easily overcoming the mode collapsing problem and delivering state-of-the-art results. A minimax formulation was able to establish among a classiﬁer, a discriminator, and a set of generators in a similar spirit with GAN. Generators create samples that are intended to come from the same distribution as the training data, whilst the discriminator determines whether samples are true data or generated by generators, and the classiﬁer speciﬁes which generator a sample comes from. The distinguishing feature is that internal samples are created from multiple generators, and then one of them will be randomly selected as ﬁnal output similar to the mechanism of a probabilistic mixture model. We term our method Mixture Generative Adversarial Nets (MGAN). We develop theoretical analysis to prove that, at the equilibrium, the Jensen-Shannon divergence (JSD) between the mixture of generators’ distributions and the empirical data distribution is minimal, whilst the JSD among generators’ distributions is maximal, hence effectively avoiding the mode collapsing problem. By utilizing parameter sharing, our proposed model adds minimal computational cost to the standard GAN, and thus can also efﬁciently scale to large-scale datasets. We conduct extensive experiments on synthetic 2D data and natural image databases (CIFAR-10, STL-10 and ImageNet) to demonstrate the superior performance of our MGAN in achieving state-of-the-art Inception scores over latest baselines, generating diverse and appealing recognizable objects at different resolutions, and specializing in capturing different types of objects by the generators.},
	language = {en},
	author = {Hoang, Quan and Nguyen, Tu Dinh and Le, Trung and Phung, Dinh},
	year = {2018},
}

@misc{46,
	title = {{MGAN}: {Training} {Generative} {Adversarial} {Nets} with {Multiple} {Generators} {\textbar} {OpenReview}},
	url = {https://openreview.net/forum?id=rkmu5b0a-},
	author = {Hoang, Quan and Nguyen, Tu Dinh and Le, Trung and Phung, Dinh},
}

@article{70,
	title = {A generative adversarial network–based method for generating negative financial samples},
	volume = {16},
	issn = {1550-1329},
	url = {https://doi.org/10.1177/1550147720907053},
	doi = {10.1177/1550147720907053},
	abstract = {In financial anti-fraud field, negative samples are small and sparse with serious sample imbalanced problem. Generating negative samples consistent with original data to naturally solve imbalanced problem is a serious problem. This article proposes a new method to solve this problem. We introduce a new generation model, combined Generative Adversarial Network with Long Short-Term Memory network for one-dimensional negative financial samples. The characteristic association between transaction sequences can be learned by long short-term memory layer, and the generator covers real data distribution by the adversarial discriminator with time-sequence. Mapping data distribution to feature space is a common evaluation method of synthetic data; however, relationships between data attributes have been ignored in online transactions. We define a comprehensive evaluation method to evaluate the validity of generated samples from data distribution and attribute characteristics. Experimental results on real bank B2B transaction data show that the proposed model has higher overall ratings, which is 10\% higher than traditional generation models. Finally, well-trained model is used to generate negative samples and form new dataset. The classification results on new datasets show that precision and recall are all higher than baseline models. Our work has a certain practical value and provides a new idea to solve imbalanced problem in whatever fields.},
	number = {2},
	urldate = {2025-01-25},
	journal = {International Journal of Distributed Sensor Networks},
	author = {Zhang, Zhaohui and Yang, Lijun and Chen, Ligong and Liu, Qiuwen and Meng, Ying and Wang, Pengwei and Li, Maozhen},
	month = feb,
	year = {2020},
	pages = {1550147720907053},
}

@article{54,
	title = {Augmenting data with generative adversarial networks: {An} overview},
	volume = {26},
	issn = {1088-467X},
	shorttitle = {Augmenting data with generative adversarial networks},
	url = {https://journals.sagepub.com/doi/abs/10.3233/IDA-215735},
	doi = {10.3233/IDA-215735},
	abstract = {Performance of neural networks greatly depends on quality, size and balance of training dataset. In a real environment datasets are rarely balanced and training deep models over such data is one of the main challenges of deep learning. In order to reduce this problem, methods and techniques are borrowed from the traditional machine learning. Conversely, generative adversarial networks (GAN) were created and developed, a relatively new type of generative models that are based on game theory and consist of two neural networks, a generator and a discriminator. The generator?s task is to create a sample from the input noise that is based on training data distribution and the discriminator should detect those samples as fake. This process goes through a finite number of iterations until the generator successfully fools the discriminator. When this occurs, sample becomes a part of new (augmented) dataset. Even though the original GAN creates unlabeled samples, variants that soon appeared removed that limitation. Generating artificial data through these networks appears to be a meaningful solution to the imbalance problem since it turned out that artificial samples created by GAN are difficult to differentiate from the real ones. In this manner, new samples of minority class could be created and dataset imbalance ratio lowered.},
	number = {2},
	urldate = {2025-01-25},
	journal = {Intelligent Data Analysis},
	author = {Ljubić, Hrvoje and Martinović, Goran and Volarić, Tomislav},
	month = mar,
	year = {2022},
	pages = {361--378},
}

@inproceedings{49,
	title = {{MD}-{GAN}: {Multi}-{Discriminator} {Generative} {Adversarial} {Networks} for {Distributed} {Datasets}},
	shorttitle = {{MD}-{GAN}},
	doi = {10.1109/IPDPS.2019.00095},
	abstract = {A recent technical breakthrough in the domain of machine learning is the discovery and the multiple applications of Generative Adversarial Networks (GANs). Those generative models are computationally demanding, as a GAN is composed of two deep neural networks, and because it trains on large datasets. A GAN is generally trained on a single server. In this paper, we address the problem of distributing GANs so that they are able to train over datasets that are spread on multiple workers. MD-GAN is exposed as the first solution for this problem: we propose a novel learning procedure for GANs so that they fit this distributed setup. We then compare the performance of MD-GAN to an adapted version of federated learning to GANs, using the MNIST, CIFAR10 and CelebA datasets. MD-GAN exhibits a reduction by a factor of two of the learning complexity on each worker node, while providing better or identical performances with the adaptation of federated learning. We finally discuss the practical implications of distributing GANs.},
	booktitle = {2019 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} ({IPDPS})},
	author = {Hardy, Corentin and Le Merrer, Erwan and Sericola, Bruno},
	month = may,
	year = {2019},
	keywords = {Computational modeling, Deep Learning, Distributed Datasets, Gallium nitride, Generative Adversarial Network, Generative adversarial networks, Generators, Machine learning, Servers, Training},
	pages = {866--877},
}

@inproceedings{39,
	address = {Taichung Taiwan},
	title = {Missing {Data} {Imputation} {Using} {Data} {Generated} {By} {GAN}},
	isbn = {978-1-4503-8786-6},
	url = {https://dl.acm.org/doi/10.1145/3418688.3418701},
	doi = {10.1145/3418688.3418701},
	language = {en},
	urldate = {2025-01-25},
	booktitle = {2020 the 3rd {International} {Conference} on {Computing} and {Big} {Data}},
	publisher = {ACM},
	author = {Hammad Alharbi, Hanan and Kimura, Masaomi},
	month = aug,
	year = {2020},
	pages = {73--77},
}

@article{36,
	title = {Adversarial {Learning} {Targeting} {Deep} {Neural} {Network} {Classification}: {A} {Comprehensive} {Review} of {Defenses} {Against} {Attacks}},
	volume = {108},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0018-9219, 1558-2256},
	shorttitle = {Adversarial {Learning} {Targeting} {Deep} {Neural} {Network} {Classification}},
	doi = {10.1109/JPROC.2020.2970615},
	abstract = {With the wide deployment of machine learning (ML) based systems for a variety of applications including medical, military, automotive, genomic, as well as multimedia and social networking, there is great potential for damage from adversarial learning (AL) attacks. In this paper, we provide a contemporary survey of AL, focused particularly on defenses against attacks on deep neural network classiﬁers. After introducing relevant terminology and the goals and range of possible knowledge of both attackers and defenders, we survey recent work on test-time evasion (TTE), data poisoning (DP), backdoor DP, and reverse engineering (RE) attacks and particularly defenses against same. In so doing, we distinguish robust classiﬁcation from anomaly detection (AD), unsupervised from supervised, and statistical hypothesis-based defenses from ones that do not have an explicit null (no attack) hypothesis. We also consider several scenarios for detecting backdoors. We provide a technical assessment for reviewed works, including identifying any issues/limitations, required hyperparameters, needed computational complexity, as well as the performance measures evaluated and the obtained quality. We then dig deeper, providing novel insights that challenge conventional AL wisdom and that target unresolved issues, including: 1) robust classiﬁcation versus AD as a defense strategy; 2) the belief that attack success increases with attack strength, which ignores susceptibility to AD; 3) small perturbations for testtime evasion attacks: a fallacy or a requirement?; 4) validity of the universal assumption that a TTE attacker knows the groundtruth class for the example to be attacked; 5) black, grey, or white box attacks as the standard for defense evaluation; 6) susceptibility of query-based RE to an AD defense. We also discuss attacks on the privacy of training data. We then present benchmark comparisons of several defenses against TTE, RE, and backdoor DP attacks on images. The paper concludes with a discussion of continuing research directions, including the supreme challenge of detecting attacks whose goal is not to alter classiﬁcation decisions, but rather simply to embed, without detection, “fake news” or other false content.},
	language = {en},
	number = {3},
	journal = {Proceedings of the IEEE},
	author = {Miller, David J. and Xiang, Zhen and Kesidis, George},
	month = mar,
	year = {2020},
	pages = {402--433},
}

@inproceedings{10,
	title = {A hybrid sampling method for imbalanced data},
	doi = {10.1109/SSD.2015.7348093},
	abstract = {With the diversification of applications and the emergence of new trends in challenging applications such as in the computer vision domain, classical machine learning systems usually perform poorly while confronting two common problems: the training data of negative examples, which outnumber the positive ones, and the large intra-class variations. These problems lead to a drop in the system performances. In this work, we propose to improve the classification accuracy in the case of imbalanced training data by equally balancing a training data set using a hybrid approach which consists in over-sampling the minority class using a “SMOTE star topology”, and under-sampling the majority class by removing instances that are considered less relevant. The feature vector deletion has been performed with respect to intra-class variations, based on the distribution criterion. The experimental results, achieved in bio-metric data, show that the proposed approach significantly improves the overall performances measured in terms of true-positive rate.},
	booktitle = {2015 {IEEE} 12th {International} {Multi}-{Conference} on {Systems}, {Signals} \& {Devices} ({SSD15})},
	author = {Gazzah, Sami and Hechkel, Amina and Essoukri Ben Amara, Najoua},
	month = mar,
	year = {2015},
	keywords = {Correlation, Data analysis, Databases, Feature extraction, Imbalanced data sets, Intra-class variations, One-against-all SVM, Principal component analysis, Support vector machines, Training, Training data},
	pages = {1--6},
}

@inproceedings{9,
	title = {A {Comparative} {Study} of {SMOTE}, {Borderline}-{SMOTE}, and {ADASYN} {Oversampling} {Techniques} using {Different} {Classifiers}},
	doi = {10.1109/ICSMDI57622.2023.00060},
	abstract = {With the advent of machine learning and its numerous techniques, many real-world problems have been solved like credit card fraud detection, cancer susceptibility and survival prediction, identification of spam, and customer segmentation, to name a few. Machine learning works on huge loads of data to give the correct prediction and maximum accuracy. Now, accuracy of any machine learning model depends on the dataset been fed into that model, in the first place. And from here comes the concept of oversampling and under-sampling. Under-sampling is the process of shortening the majority class or deleting samples from the majority class in order to balance the dataset, and over-sampling is the process of adding additional synthetic samples to the minority class. So, this study is based on the three methods namely, SMOTE, Borderline-SMOTE, and ADASYN. This study includes the collation of the above-mentioned oversampling techniques based on their accuracy, precision, recall, F1-measure and ROC curve.},
	booktitle = {2023 3rd {International} {Conference} on {Smart} {Data} {Intelligence} ({ICSMDI})},
	author = {Dey, Ishani and Pratap, Vibha},
	month = mar,
	year = {2023},
	keywords = {ADASYN, Borderline-SMOTE, Cancer, Credit cards, Decision trees, Fraud, Imbalanced datasets, Load modeling, Machine learning, Oversampling, Random forests, SMOTE, Support vector machines, Under-sampling},
	pages = {294--302},
}

@misc{7,
	title = {Prediction model of crash severity in imbalanced dataset using data leveling methods and metaheuristic optimization algorithms},
	url = {https://doi.org/10.1080/13588265.2022.2028471},
	author = {Danesh, Akbar and Ehsani, Mehrdad and Nejad, Fereidoon Moghadas and Zakeri, Hamzeh},
}

@misc{8,
	title = {{SMOTE}: {Synthetic} {Minority} {Over}-sampling {Technique} {\textbar} {Journal} of {Artificial} {Intelligence} {Research}},
	url = {https://doi.org/10.1613/jair.953},
	author = {Chawla, N. V. and Bowyer, K. W. and Hall, L. O. and Kegelmeyer, W. P.},
}

@inproceedings{6,
	title = {Facing {Imbalanced} {Data}–{Recommendations} for the {Use} of {Performance} {Metrics}},
	doi = {10.1109/ACII.2013.47},
	abstract = {Recognizing facial action units (AUs) is important for situation analysis and automated video annotation. Previous work has emphasized face tracking and registration and the choice of features classifiers. Relatively neglected is the effect of imbalanced data for action unit detection. While the machine learning community has become aware of the problem of skewed data for training classifiers, little attention has been paid to how skew may bias performance metrics. To address this question, we conducted experiments using both simulated classifiers and three major databases that differ in size, type of FACS coding, and degree of skew. We evaluated influence of skew on both threshold metrics (Accuracy, F-score, Cohen's kappa, and Krippendorf's alpha) and rank metrics (area under the receiver operating characteristic (ROC) curve and precision-recall curve). With exception of area under the ROC curve, all were attenuated by skewed distributions, in many cases, dramatically so. While ROC was unaffected by skew, precision-recall curves suggest that ROC may mask poor performance. Our findings suggest that skew is a critical factor in evaluating performance metrics. To avoid or minimize skew-biased estimates of performance, we recommend reporting skew-normalized scores along with the obtained ones.},
	booktitle = {2013 {Humaine} {Association} {Conference} on {Affective} {Computing} and {Intelligent} {Interaction}},
	author = {Jeni, László A. and Cohn, Jeffrey F. and De La Torre, Fernando},
	month = sep,
	year = {2013},
	keywords = {Accuracy, Databases, Gold, Measurement, Pain, Shape, Three-dimensional displays, action unit detection, imbalanced data, performance metrics, skew normalization},
	pages = {245--251},
}

@inproceedings{42,
	title = {{DOPING}: {Generative} {Data} {Augmentation} for {Unsupervised} {Anomaly} {Detection} with {GAN}},
	shorttitle = {{DOPING}},
	doi = {10.1109/ICDM.2018.00146},
	abstract = {Recently, the introduction of the generative adversarial network (GAN) and its variants has enabled the generation of realistic synthetic samples, which has been used for enlarging training sets. Previous work primarily focused on data augmentation for semi-supervised and supervised tasks. In this paper, we instead focus on unsupervised anomaly detection and propose a novel generative data augmentation framework optimized for this task. By using a GAN variant known as the adversarial autoencoder (AAE), we impose a distribution on the latent space of the dataset and systematically sample the latent space to generate artificial samples. To the best of our knowledge, our method is the first data augmentation technique focused on improving performance in unsupervised anomaly detection. We validate our method by demonstrating consistent improvements across several real-world datasets.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM})},
	author = {Lim, Swee Kiat and Loo, Yi and Tran, Ngoc-Trung and Cheung, Ngai-Man and Roig, Gemma and Elovici, Yuval},
	month = nov,
	year = {2018},
	keywords = {Anomaly detection, Decoding, Doping, Gallium nitride, Gaussian distribution, Standards, Training, adversarial autoencoders, anomaly detection, data augmentation, generative adversarial networks, unsupervised learning},
	pages = {1122--1127},
}

@article{45,
	title = {Time-series {Generative} {Adversarial} {Networks}},
	volume = {32},
	doi = {https://proceedings.neurips.cc/paper/2019/hash/c9efe5f26cd17ba6216bbe2a7d26d490-Abstract.html?ref=https://githubhelp.com},
	language = {en},
	journal = {Advances in Neural Information Processing Systems},
	author = {Yoon, Jinsung and Jarrett, Daniel and van der Schaar, Mihaela},
	year = {2019},
}

@article{55,
	title = {Improvement of {Generative} {Adversarial} {Network} and {Its} {Application} in {Bearing} {Fault} {Diagnosis}: {A} {Review}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2075-4442},
	shorttitle = {Improvement of {Generative} {Adversarial} {Network} and {Its} {Application} in {Bearing} {Fault} {Diagnosis}},
	doi = {10.3390/lubricants11020074},
	abstract = {A small sample size and unbalanced sample distribution are two main problems when data-driven methods are applied for fault diagnosis in practical engineering. Technically, sample generation and data augmentation have proven to be effective methods to solve this problem. The generative adversarial network (GAN) has been widely used in recent years as a representative generative model. Besides the general GAN, many variants have recently been reported to address its inherent problems such as mode collapse and slow convergence. In addition, many new techniques are being proposed to increase the sample generation quality. Therefore, a systematic review of GAN, especially its application in fault diagnosis, is necessary. In this paper, the theory and structure of GAN and variants such as ACGAN, VAEGAN, DCGAN, WGAN, et al. are presented first. Then, the literature on GANs is mainly categorized and analyzed from two aspects: improvements in GAN’s structure and loss function. Specifically, the improvements in the structure are classified into three types: information-based, input-based, and layer-based. Regarding the modification of the loss function, it is sorted into two aspects: metric-based and regularization-based. Afterwards, the evaluation metrics of the generated samples are summarized and compared. Finally, the typical applications of GAN in the bearing fault diagnosis field are listed, and the challenges for further research are also discussed.},
	language = {en},
	number = {2},
	journal = {Lubricants},
	author = {Ruan, Diwang and Chen, Xuran and Gühmann, Clemens and Yan, Jianping},
	month = feb,
	year = {2023},
	keywords = {GAN review, GAN structure improvement, bearing fault diagnosis, data augmentation, generative adversarial network (GAN), loss function modification},
	pages = {74},
}

@inproceedings{65,
	title = {{GANs} for {Class}-{Imbalanced} {Data}: {A} {Meta}-{Analysis} of {GitHub} {Projects}},
	shorttitle = {{GANs} for {Class}-{Imbalanced} {Data}},
	doi = {10.1109/ICTAI56018.2022.00214},
	abstract = {Generative Adversarial Networks (GANs) have increasingly been the subject of intense research interest for their ability to augment datasets to correct for class imbalance. The collaborative and complex code bases for these GANs are often written in a high-level, general-purpose programming language such as Python and housed on the GitHub platform. The goal of this work is to summarize the research aims of 18 GitHub repositories of projects that implement GANs in regimes of class imbalance, in both tabular and non-tabular settings, as well to summarize and analyze the patterns and characteristics of these code bases. With respect to the latter task, we conduct our analysis from a perspective of library reliance and from the structural properties of the code base. The insights discovered herein are meant to serve as a gentle introduction to the various tools available and recommended best practices for the enterprising researcher seeking to apply GANs as data augmenters in imbalanced settings.},
	booktitle = {2022 {IEEE} 34th {International} {Conference} on {Tools} with {Artificial} {Intelligence} ({ICTAI})},
	author = {Sauber-Cole, Rick and Khoshgoftaar, Taghi M. and Johnson, Justin M.},
	month = oct,
	year = {2022},
	keywords = {Codes, Computer vision, Data engineering, Deep learning, Focusing, Generative adversarial networks, GitHub, Libraries, PyTorch, TensorFlow, class imbalance, generative adversarial networks},
	pages = {1419--1424},
}

@article{71,
	title = {Alleviating {Class} {Imbalance} in {Actuarial} {Applications} {Using} {Generative} {Adversarial} {Networks}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-9091},
	doi = {10.3390/risks9030049},
	abstract = {To build adequate predictive models, a substantial amount of data is desirable. However, when expanding to new or unexplored territories, this required level of information is rarely always available. To build such models, actuaries often have to: procure data from local providers, use limited unsuitable industry and public research, or rely on extrapolations from other better-known markets. Another common pathology when applying machine learning techniques in actuarial domains is the prevalence of imbalanced classes where risk events of interest, such as mortality and fraud, are under-represented in data. In this work, we show how an implicit model using the Generative Adversarial Network (GAN) can alleviate these problems through the generation of adequate quality data from very limited or highly imbalanced samples. We provide an introduction to GANs and how they are used to synthesize data that accurately enhance the data resolution of very infrequent events and improve model robustness. Overall, we show a significant superiority of GANs for boosting predictive models when compared to competing approaches on benchmark data sets. This work offers numerous of contributions to actuaries with applications to inter alia new sample creation, data augmentation, boosting predictive models, anomaly detection, and missing data imputation.},
	language = {en},
	number = {3},
	journal = {Risks},
	author = {Ngwenduna, Kwanda Sydwell and Mbuvha, Rendani},
	month = mar,
	year = {2021},
	keywords = {SMOTE, actuarial science, class imbalance, data augmentation, generative adversarial network, generative models, synthetic sampling},
	pages = {49},
}

@article{72,
	title = {Generative {Adversarial} {Networks} for {Synthetic} {Data} {Generation} in {Finance}: {Evaluating} {Statistical} {Similarities} and {Quality} {Assessment}},
	volume = {5},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2673-2688},
	shorttitle = {Generative {Adversarial} {Networks} for {Synthetic} {Data} {Generation} in {Finance}},
	doi = {10.3390/ai5020035},
	abstract = {Generating synthetic data is a complex task that necessitates accurately replicating the statistical and mathematical properties of the original data elements. In sectors such as finance, utilizing and disseminating real data for research or model development can pose substantial privacy risks owing to the inclusion of sensitive information. Additionally, authentic data may be scarce, particularly in specialized domains where acquiring ample, varied, and high-quality data is difficult or costly. This scarcity or limited data availability can limit the training and testing of machine-learning models. In this paper, we address this challenge. In particular, our task is to synthesize a dataset with similar properties to an input dataset about the stock market. The input dataset is anonymized and consists of very few columns and rows, contains many inconsistencies, such as missing rows and duplicates, and its values are not normalized, scaled, or balanced. We explore the utilization of generative adversarial networks, a deep-learning technique, to generate synthetic data and evaluate its quality compared to the input stock dataset. Our innovation involves generating artificial datasets that mimic the statistical properties of the input elements without revealing complete information. For example, synthetic datasets can capture the distribution of stock prices, trading volumes, and market trends observed in the original dataset. The generated datasets cover a wider range of scenarios and variations, enabling researchers and practitioners to explore different market conditions and investment strategies. This diversity can enhance the robustness and generalization of machine-learning models. We evaluate our synthetic data in terms of the mean, similarities, and correlations.},
	language = {en},
	number = {2},
	journal = {AI},
	author = {Ramzan, Faisal and Sartori, Claudio and Consoli, Sergio and Reforgiato Recupero, Diego},
	month = jun,
	year = {2024},
	keywords = {data augmentation, deep learning, generative adversarial networks, synthetic data},
	pages = {667--685},
}

@article{81,
	title = {The {PRISMA} 2020 statement: an updated guideline for reporting systematic reviews},
	volume = {372},
	copyright = {© Author(s) (or their employer(s)) 2019. Re-use permitted under CC                 BY. No commercial re-use. See rights and permissions. Published by                 BMJ.. http://creativecommons.org/licenses/by/4.0/This is an Open Access article distributed in accordance with the terms of the Creative Commons Attribution (CC BY 4.0) license, which permits others to distribute, remix, adapt and build upon this work, for commercial use, provided the original work is properly cited. See: http://creativecommons.org/licenses/by/4.0/.},
	issn = {1756-1833},
	shorttitle = {The {PRISMA} 2020 statement},
	doi = {10.1136/bmj.n71},
	abstract = {{\textless}p{\textgreater}The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews.{\textless}/p{\textgreater}},
	language = {en},
	journal = {BMJ},
	author = {Page, Matthew J. and McKenzie, Joanne E. and Bossuyt, Patrick M. and Boutron, Isabelle and Hoffmann, Tammy C. and Mulrow, Cynthia D. and Shamseer, Larissa and Tetzlaff, Jennifer M. and Akl, Elie A. and Brennan, Sue E. and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M. and Hróbjartsson, Asbjørn and Lalu, Manoj M. and Li, Tianjing and Loder, Elizabeth W. and Mayo-Wilson, Evan and McDonald, Steve and McGuinness, Luke A. and Stewart, Lesley A. and Thomas, James and Tricco, Andrea C. and Welch, Vivian A. and Whiting, Penny and Moher, David},
	month = mar,
	year = {2021},
	pages = {n71},
}

@article{132,
	title = {{SMOTified}-{GAN} for {Class} {Imbalanced} {Pattern} {Classification} {Problems}},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3158977},
	abstract = {Class imbalance in a dataset is a major problem for classifiers that results in poor prediction with a high true positive rate (TPR) but a low true negative rate (TNR) for a majority positive training dataset. Generally, the pre-processing technique of oversampling of minority class(es) are used to overcome this deficiency. Our focus is on using the hybridization of Generative Adversarial Network (GAN) and Synthetic Minority Over-Sampling Technique (SMOTE) to address class imbalanced problems. We propose a novel two-phase oversampling approach involving knowledge transfer that has the synergy of SMOTE and GAN. The unrealistic or overgeneralized samples of SMOTE are transformed into realistic distribution of data by GAN where there is not enough minority class data available for GAN to process them by itself effectively. We named it SMOTified-GAN as GAN works on pre-sampled minority data produced by SMOTE rather than randomly generating the samples itself. The experimental results prove the sample quality of minority class(es) has been improved in a variety of tested benchmark datasets. Its performance is improved by up to 9\% from the next best algorithm tested on F1-score measurements. Its time complexity is also reasonable which is around O(N{\textasciicircum}2d{\textasciicircum}2T) for a sequential algorithm.},
	journal = {IEEE Access},
	author = {Sharma, Anuraganand and Singh, Prabhat Kumar and Chandra, Rohitash},
	year = {2022},
	keywords = {Costs, Generative adversarial network (GAN), Generative adversarial networks, Generators, Interpolation, Prediction algorithms, SMOTified-GAN, Training, Training data, class imbalance problem, synthetic minority over-sampling technique (SMOTE)},
	pages = {30655--30665},
}

@inproceedings{166,
	title = {Limitations and applicability of {GANs} in banking domain},
	volume = {2692},
	url = {https://api.semanticscholar.org/CorpusID:229357084},
	abstract = {Threats due to payment-related frauds are always a primary concern for financial institutions (FIs), often leading to huge losses and impacting consumer experience. To combat emerging frauds and improve the system's robustness, FIs need an efficient system to detect fraud while authorizing payments. The biggest challenge in developing a fraud detection system is a high degree of class imbalance between fraudulent and legitimate transactions. Recently, Generative Adversarial Networks (GANs) are employed as an oversampling technique to augment the dataset with synthetic minority samples. In this paper, we present a systematic study to train GANs for synthetic fraud generation, demonstrating improved classifier performance detecting fraud. Training of GANs is conducted in various settings, including min-max objective and with or without auxiliary loss discriminating synthetic fraud and real fraud from non-fraud samples. Auxiliary loss is obtained using contrastive loss or triplet loss. Quality of trained GANs is estimated by evaluating the lift in classifier performance when trained with dataset augmented with synthetic fraud. Further, the effect of Discriminator Rejection Sampling (DRS) is studied in synthetic sample selection used for training data augmentation. The performance comparison of different settings proposed in this study is evaluated using a publicly available Credit-Card dataset and showed an absolute improvement of up to 6\% in Recall and 3\% in precision. We hope this paper will help advance the applicability of GANs with a practical insight into the research that has been done on this topic so far and open doors to interesting future research direction. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)},
	author = {Pandey, A. and Bhatt, D. and Bhowmik, T.},
	year = {2020},
}

@inproceedings{170,
	title = {Study on the {Prediction} of {Imbalanced} {Bank} {Customer} {Churn} {Based} on {Generative} {Adversarial} {Network}},
	volume = {1624},
	doi = {10.1088/1742-6596/1624/3/032054},
	abstract = {The imbalanced commercial bank customer data will lead to the unpredictability of the minority class. Therefore, this paper proposes an imbalanced data method based on generative adversarial network to deal the problem of poor prediction performance of traditional classifiers for minority class. This paper method is based on the generative adversarial network to generate minority class samples to improve imbalanced data. Finally, the classifier is used to train the balanced data to improve the prediction performance of minority class. In this experiment, the data of a commercial bank customer were measured with indicators such as F1, Precision, and compared with traditional data sampling methods such as SMOTE, BSSMOTE. This method is feasible and applicable to the classification of imbalanced data of banks by observing the experimental results, which has better application value. © Published under licence by IOP Publishing Ltd.},
	author = {Li, B. and Xie, J.},
	year = {2020},
}

@inproceedings{171,
	title = {{CTAB}-{GAN}: {Effective} {Table} {Data} {Synthesizing}},
	volume = {157},
	shorttitle = {{CTAB}-{GAN}},
	doi = {10.3389/fdata.2023.1296508},
	abstract = {While data sharing is crucial for knowledge development, privacy concerns and strict regulation (e.g., European General Data Protection Regulation (GDPR)) unfortunately limit its full effectiveness. Synthetic tabular data emerges as an alternative to enable data sharing while fulfilling regulatory and privacy constraints. The state-of-the-art tabular data synthesizers draw methodologies from Generative Adversarial Networks (GAN) and address two main data types in industry, i.e., continuous and categorical. In this paper, we develop CTAB-GAN, a novel conditional table GAN architecture that can effectively model diverse data types, including a mix of continuous and categorical variables. Moreover, we address data imbalance and long tail issues, i.e., certain variables have drastic frequency differences across large values. To achieve those aims, we first introduce the information loss, classification loss and generator loss to the conditional GAN. Secondly, we design a novel conditional vector, which efficiently encodes the mixed data type and skewed distribution of data variable. We extensively evaluate CTAB-GAN with the state of the art GANs that generate synthetic tables, in terms of data similarity and analysis utility. The results on five datasets show that the synthetic data of CTAB-GAN remarkably resembles the real data for all three types of variables and results into higher accuracy for five machine learning algorithms, by up to 17\%. © 2021 Z. Zhao, A. Kunar, R. Birke \& L.Y. Chen.},
	author = {Zhao, Z. and Kunar, A. and Birke, R. and Chen, L.Y.},
	year = {2021},
	keywords = {Data synthesis, GAN, Imbalanced distribution, Tabular data},
	pages = {97--112},
}

@inproceedings{180,
	title = {{OAGAN}: an oversampling approach for imbalanced data problems},
	volume = {2023},
	shorttitle = {{OAGAN}},
	doi = {10.1049/icp.2023.1722},
	abstract = {Imbalanced data problems are prevalent in our daily lives. When conducted on this kind of data, many classification models may encounter many difficulties and produce ineffective performance due to a high training bias towards the majority of class instances. In order to solve the imbalanced data problem, many effective oversampling methods have been proposed. However, few methods in previous work consider different weights for minority class samples. Therefore, we proposed an oversampling method for the minority class by Adaptive Synthetic Sampling with Conditional Tabular Generative Adversarial Network (OAGAN) in this study. Firstly, Adaptive Synthetic Sampling is used to assign different weights to each minority class sample, based on which new similar samples are generated by the Conditional Tabular Generative Adversarial Network. In other words, the weights of different minority class samples are considered when generating data using the Conditional Tabular Generative Adversarial Network, thus improving the method. The proposed OAGAN method was evaluated on ten imbalanced datasets and three standard oversampling algorithms, which achieved better learning performance.},
	booktitle = {13th {International} {Conference} on {Quality}, {Reliability}, {Risk}, {Maintenance}, and {Safety} {Engineering} ({QR2MSE} 2023)},
	author = {Cheng, J. and Wei, B. and Liu, F. and Han, S. and Cai, Z. and Si, S.},
	month = jul,
	year = {2023},
	pages = {734--739},
}

@inproceedings{163,
	title = {A novel hybrid sampling method based on {CWGAN} for extremely imbalanced backorder prediction},
	doi = {10.1109/SMC53654.2022.9945161},
	abstract = {Product backorder is a common problem in supply chain management systems. It is essential for entrepreneurs to predict the likelihood of backorder accurately to minimize a company’s losses. However, existing methods are hard to achieve satisfactory results since the number of backorders and non-backorders are extremely imbalanced. Besides, the backorder data’s attributes are complex to oversample them effectively. To address these problems, a novel hybrid sampling method is proposed to help predict extremely imbalanced backorder. The Randomized Undersampling (RUS) and a Conditional Wasserstein Generative Adversarial Network (CWGAN) are innovatively introduced into backorder prediction. First, RUS is used to reduce the majority non-backorder samples. Second, CWGAN is served as an oversampling technique to generate high-quality backorder samples. It utilizes unique structures in the generator and the discriminator to effectively model both numerical and categorical variables. Finally, the training dataset is balanced, and the Random Forest Classifier (RFC) is adopted to make backordering prediction. In the experiments of Kaggle’s dataset ‘Can you predict product backorder?’, our proposed method is superior to all benchmark methods in terms of standard evaluation metrics. The results show that our proposed product backorder prediction model is effective.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	author = {Liu, Haoyue and Liu, Qing and Liu, Min},
	month = oct,
	year = {2022},
	keywords = {Generative adversarial networks, Generators, Measurement, Predictive models, Sampling methods, Supply chain management, Supply chains, Training, backorder prediction, extremely class imbalance problem, hybrid sampling},
	pages = {768--773},
}

@inproceedings{162,
	title = {Electronic {Health} {Data} in the {Context} of {Patient} {Length}-of-{Stay} {Prediction}: {Using} {Generative} {Adversarial} {Nets} for {Synthetic} {Data} {Creation}},
	shorttitle = {Electronic {Health} {Data} in the {Context} of {Patient} {Length}-of-{Stay} {Prediction}},
	doi = {10.1109/CSCE60160.2023.00262},
	abstract = {While generative artificial intelligence has gained popularity (e.g., for the creation of images) it can also be used for the creation of synthetic tabular data. This bears great potential, especially for the healthcare industry where data is oftentimes scarce and underlies privacy restrictions. For instance, the creation of synthetic electronic health records (EHR) promises to improve the usage of machine learning (ML) algorithms, which normally work with large amounts of data. This also applies for the prediction of the patient length of stay (LOS), a key measure for hospitals. Thereby, the LOS represents one of the core tools for decision-makers to plan the allocation of resources. This paper aims to add to the young research concerning the application of generative adversarial nets (GAN) on tabular EHR. The intention is to leverage the advantages of synthetic data for the prediction of the LOS in order to contribute to the efficiency -enhancing and cost-saving aspirations of hospitals and insurance companies. Therefore, the applicability of synthetic data generated by GANs as a proxy for scarce real-world EHR for the patient LOS multi-class classification task is examined. In this context the Conditional Tabular GAN (CTGAN) and the Copula GAN are selected. The CTGAN is found to be the superior model for the underlying use case. Nevertheless, the paper shows that there is still room for improvement when applying state-of-the-art GAN architectures to EHR.},
	booktitle = {2023 {Congress} in {Computer} {Science}, {Computer} {Engineering}, \& {Applied} {Computing} ({CSCE})},
	author = {Bietsch, Dominik and Stahlbock, Robert and Voß, Stefan},
	month = jul,
	year = {2023},
	keywords = {Computer architecture, Data models, Electronic Health Data, Generative AI, Generative Adversarial Nets, Generative adversarial networks, Hospitals, Machine Learning, Machine learning algorithms, Prediction algorithms, Synthetic Data Generation, Training},
	pages = {1597--1604},
}

@article{161,
	title = {Predicting {Credit} {Bond} {Default} with {Deep} {Learning}: {Evidence} from {China}},
	volume = {5},
	issn = {2688-5255},
	shorttitle = {Predicting {Credit} {Bond} {Default} with {Deep} {Learning}},
	doi = {10.23919/JSC.2024.0005},
	abstract = {China's credit bond market has rapidly expanded in recent years. However, since 2014, the number of credit bond defaults has been increasing rapidly, posing enormous potential risks to the stability of the financial market. This study proposed a deep learning approach to predict credit bond defaults in the Chinese market. A convolutional neural network (CNN) was selected as the classification model and to reduce the extreme imbalance between defaulted and non-defaulted bonds, and a generative adversarial network (GAN) was used as the oversampling model. Based on 31 financial and 20 non-financial indicators, we collected Wind data on all credit bonds issued and matured or defaulted from 2014 to 2021. The experimental results showed that our GAN+CNN approach had superior predictive performance with an area under the curve (AUC) of 0.9157 and precision of 0.8871 compared to previous research and other commonly used classification models-including the logistic regression, support vector machine, and fully connected neural network models-and oversampling techniques-including the synthetic minority oversampling technique (SMOTE) and Borderline SMOTE model. For one-year predictions, indicators of solvency, capital structure, and fundamental properties of bonds are proved to be the most important indicators.},
	number = {1},
	journal = {Journal of Social Computing},
	author = {Zhang, Ning and Li, Wenhe and Chen, Haoxiang and Jia, Binshu and Deng, Pei},
	month = mar,
	year = {2024},
	keywords = {Deep learning, Feature extraction, Generative adversarial networks, Neural networks, Predictive models, Social computing, Support vector machines, convolutional neural network, credit bond default, generative adversarial network, imbalanced data processing, prediction},
	pages = {36--45},
}

@inproceedings{167,
	title = {Effective {Data} {Generation} for {E}-banking {Transactions} {Using} {Cycle}-{Consistent} {Adversarial} {Networks}},
	volume = {1575},
	doi = {10.1088/1742-6596/1575/1/012070},
	abstract = {In the anti-fraud research, the small amount of fraudulent transactions leads to extremely class imbalanced data. This problem becomes a bottleneck of fraud detection. In this paper, we apply the Cycle-Consistent Adversarial Networks (CycleGAN) to generate data for the minority class. Based on real e-banking transaction data, generators and discriminators are designed to generate synthetic data that meets the characteristics of e-banking transactions. Synthetic samples and real samples are mixed into the training of fraud detection model, and multiple metrics are used to verify the effect. Experimental results show that the synthetic data generated by CycleGAN can effectively improve the performance of the fraud detection model. © 2020 Published under licence by IOP Publishing Ltd.},
	author = {Wang, X. and Zhao, H.},
	year = {2020},
}

@inproceedings{160,
	title = {{GAN}-generated {Synthetic} {Data} and {SVM}-based {Feature} {Selection} for {Improved} {Cardiovascular} {Disease} {Prediction}},
	doi = {10.1109/TIPTEKNO59875.2023.10359220},
	abstract = {Early diagnosis requires cardiovascular disease forecasting. Past patient interests can improve machine learning predictions. This study uses a Generative Adversarial Network (GAN) to augment data to address the issue of insufficient datasets. Our objective is to use the GAN and feature selection (FS) to tackle the issue of class imbalance. The study assesses the efficacy of three different machine learning (ML) algorithms in predicting coronary artery disease (CAD). The UCI repository provided the Z-Alizadeh sani dataset for our analysis. A GAN was used to balance an imbalanced dataset. We used GAN to augment data and synthesise data to improve the models. Support Vector Machine (SVM) as feature selection tool was used to extract more effective attributes. We trained and tested CAD prediction using machine learning algorithms using 5-fold cross validation. We compared the machine-learning algorithm’s outcomes with and without GAN-based data enhancement and feature selection to evaluate its predicted accuracy. According to results GAN and feature selection improved accuracy, sensitivity, and specificity for all algorithms, suggesting that generated data and selected attributes can identify positive and negative cases.},
	booktitle = {2023 {Medical} {Technologies} {Congress} ({TIPTEKNO})},
	author = {Mandan, Amel Sulaiman and Hazzaa, Nidhal Mohsin and Yildiz, Oktay},
	month = nov,
	year = {2023},
	keywords = {Coronary Artery Disease (CAD), Data Augmentation, Feature extraction, Generative Adversarial Network (GAN), Generative adversarial networks, Machine Learning, Machine learning, Machine learning algorithms, Prediction algorithms, Solid modeling, Support vector machines},
	pages = {1--4},
}

@inproceedings{159,
	title = {{HAR}-{CTGAN}: {A} {Mobile} {Sensor} {Data} {Generation} {Tool} for {Human} {Activity} {Recognition}},
	shorttitle = {{HAR}-{CTGAN}},
	doi = {10.1109/BigData55660.2022.10020848},
	abstract = {Human activity recognition (HAR) is the process of using mobile sensor data to determine the physical activities performed by individuals. HAR is the backbone of many mobile healthcare applications, such as passive health monitoring systems, early diagnosing systems, and fall detection systems. Effective HAR models rely on deep learning architectures and big data in order to accurately classify activities. Unfortunately, HAR datasets are expensive to collect, are often mislabeled, and have large class imbalances. State-of-the-art approaches to address these challenges utilize Generative Adversarial Networks (GANs) for generating additional synthetic data along with their labels. Problematically, these HAR GANs only synthesize continuous features — features that are represented by real numbers — recorded from gyroscopes, accelerometers, and other sensors that produce continuous data. This is limiting since mobile sensor data commonly has discrete features that provide additional context such as device location and the time-of-day, which have been shown to substantially improve HAR classification. Hence, we studied Conditional Tabular Generative Adversarial Networks (CTGANs) for data generation to synthesize mobile sensor data containing both continuous and discrete features, a task never been done by state-of-the-art approaches. We show HAR-CTGANs generate data with greater realism resulting in allowing better downstream performance in HAR models, and when state-of-the-art models were modified with HAR-CTGAN characteristics, downstream performance also improves.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {DeOliveira, Joshua and Gerych, Walter and Koshkarova, Aruzhan and Rundensteiner, Elke and Agu, Emmanuel},
	month = dec,
	year = {2022},
	keywords = {Big Data, CTGAN, Data models, GAN, Generative adversarial networks, Human activity recognition, Medical services, Stability analysis, Training, discrete features, human activity recognition, mobile healthcare, sensor data, synthetic data generation},
	pages = {5233--5242},
}

@article{158,
	title = {{CTGAN}-{MOS}: {Conditional} {Generative} {Adversarial} {Network} {Based} {Minority}-{Class}-{Augmented} {Oversampling} {Scheme} for {Imbalanced} {Problems}},
	volume = {11},
	issn = {2169-3536},
	shorttitle = {{CTGAN}-{MOS}},
	doi = {10.1109/ACCESS.2023.3303509},
	abstract = {This paper proposes a novel data augmentation scheme called the conditional generative adversarial network minority-class-augmented oversampling scheme (CTGAN-MOS) for solving class imbalance problems. Our methodology encompassed six key steps: data engineering using sophisticated pre-processing techniques, identifying the type of vulnerabilities present in the data, curating good quality synthetic data using the CTGAN model, the intelligent fusion of real and synthetic data, noise removal from the augmented data using coin-throwing algorithm, and building classifiers with the high-quality augmented data. Our scheme maintains higher structural similarity (data truthfulness) between the original and the resampled data by intelligently adding high-quality samples only to the minority class, whereas some augmentation techniques add records to the majority class, leading to poor-quality resampled data. Our scheme removes noisy samples from the data, which has remained unexplored in the CTGAN-based data augmentation. Furthermore, it augments data by adding fewer records compared to existing schemes, while offering comparable performance. Experiments are conducted on benchmark datasets to prove the feasibility of the proposed CTGAN-MOS in realistic scenarios. Results prove the improvement by CTGAN-MOS over existing state-of-the-art (SOTA) techniques in terms of accuracy, recall, precision, F₁ score, and G -mean score. Specifically, the CTGAN-MOS has yielded accuracy values of 100\% and 99.83\% on two datasets which are higher than recent SOTA techniques. On average, it has yielded the 22.58\% and 29.47\% improvements w.r.t. G -mean score on two different datasets. On average, it adds 8.26\% and 26.01\% fewer records than the existing SOTA methods in the two datasets. Lastly, our scheme yields highly balanced confusion matrices compared to recent SOTA data augmentation techniques.},
	journal = {IEEE Access},
	author = {Majeed, Abdul and Hwang, Seong Oun},
	year = {2023},
	keywords = {Costs, Data augmentation, Data models, Generative adversarial networks, Imbalanced problem, Noise measurement, Predictive models, Sampling methods, Synthetic data, Training data, classifiers, data augmentation, data engineering, data truthfulness, intelligent fusion, machine learning, majority class, minority class, model training, noise, samples},
	pages = {85878--85899},
}

@inproceedings{157,
	title = {Handling {Imbalanced} {Data} for {Credit} {Card} {Fraud} {Detection}},
	doi = {10.1109/ICCIT54785.2021.9689866},
	abstract = {With the rising trend in online transactions, the threat of financial fraud is also rising. This makes the necessity for an effective Fraud Detection System (FDS) more than ever before. To develop such a system the financial institutes are moving towards machine learning-based approaches due to their effectiveness. Machine learning-based systems need historical data to learn. As fraud cases take place rarely, the number of positive labeled classes in financial fraud datasets are very small and the datasets remain imbalanced. For this, the possibility for machine learning-based FDS to produce misleading results is high. To counter this problem Machine Learning (ML) researchers use multiple solutions from the perspective of data-level approach, algorithm-level approach, feature engineering, ensemble models, or any combination of them. In this paper, we propose to use Generative Adversarial Network (GAN) based synthetic data generation to handle the data imbalance problem followed by an ensemble classifier for classification. We have used a standard benchmark dataset of credit card fraud data. In our experiments, we have used both traditional oversampling/undersampling and GAN-based techniques from the data-level approach and investigated their effectiveness using ML algorithms and ensemble models. We have found Generative Adversarial Network (GAN) to be more effective and stable in performance compared to traditional oversampling techniques for both ML and ensemble models. Experiments also suggest that the combination of GAN-based sampling and ensemble models provides the best results. We also have found Synthetic Minority Oversampling Technique (SMOTE) to provide more stable results compared to Adaptive Synthetic Sample (ADASYN) from the traditional oversampling technique.},
	booktitle = {2021 24th {International} {Conference} on {Computer} and {Information} {Technology} ({ICCIT})},
	author = {Mondal, Istiak Ahmed and Haque, Md. Enamul and Hassan, Al-Maruf and Shatabda, Swakkhar},
	month = dec,
	year = {2021},
	keywords = {Adaptation models, Adaptive Synthetic Sampling(ADASYN), Class Imbalance Problem, Computational modeling, Credit cards, Ensemble Models, Generative Adversarial Network(GAN), Generative adversarial networks, Machine learning, Machine learning algorithms, Market research, Synthetic Minority Oversampling Technique(SMOTE)},
	pages = {1--6},
}

@inproceedings{156,
	title = {Genetic {Algorithm} and {GAN} based {Hybrid} {Model} for {Bankruptcy} {Prediction}},
	doi = {10.1109/OCIT59427.2023.10430554},
	abstract = {In the field of bankruptcy prediction, this work focuses on developing a trustworthy prediction model to address issues with data imbalance and the removal of unnecessary information. The majority of bankruptcy datasets have an unbalanced structure and may contain useless data, which could lower the model's effectiveness. Thus, creating trustworthy models becomes necessary and difficult. Here, synthesized data is generated using a Generative Adversarial Network (GAN) in order to balance the datasets. Next, a Genetic Algorithm (GA) is used to pick significant features. This process is compared to other methods such as the Chi-square test and Backward Elimination (BE). Here, predictions are made using four distinct models of bankruptcy: Support Vector Machine (SVM), Random Forest (RF), Decision Tree (DT), and Logistic Regression(LR). Observations reveal that Random Forest outperforms the other three predictive models in terms of prediction accuracy, while the genetic algorithm, when used as a feature selection tool, produces better results.},
	booktitle = {2023 {OITS} {International} {Conference} on {Information} {Technology} ({OCIT})},
	author = {Nayak, Sasmita Manjari and Rout, Minakhi},
	month = dec,
	year = {2023},
	keywords = {Bankruptcy, Bankruptcy Prediction, Data models, Feature Selection (FS), Feature extraction, GAN (Generative Adversarial Network), Generative adversarial networks, Genetic Algorithm (GA), Genetic algorithms, Predictive models, Random forests},
	pages = {473--478},
}

@article{155,
	title = {When {Two} are {Better} {Than} {One}: {Synthesizing} {Heavily} {Unbalanced} {Data}},
	volume = {9},
	issn = {2169-3536},
	shorttitle = {When {Two} are {Better} {Than} {One}},
	doi = {10.1109/ACCESS.2021.3126656},
	abstract = {Nowadays, data is king and if treated and used properly it promises to give organizations a competitive edge over rivals by enabling them to develop and design Intelligent Systems to improve their services. However, they need to fully comply with not only ethical but also regulatory obligations, where, e.g., privacy (strictly) needs to be respected when using or sharing data, thus protecting both the interests of users and organizations. Fraud Detection systems are examples of such systems where Machine Learning algorithms leverage information to classify financial transactions as legitimate or illicit. The data used to create these solutions is usually highly structured and contains categorical and continuous features characterised by complex distributions. One of the main challenges of fraud detection is concerned with the scarcity of fraudulent instances which results in highly unbalanced datasets. Additionally, privacy is crucial, and it is usually forbidden, or not possible, to share the data of organizations and individuals for creating or improving models.In this paper we propose a framework for private data sharing based on synthetic data generation using Generative Adversarial Networks (GAN) that learns the specificities of financial transactions data and generates fictitious data that keeps the utility of the original datasets. Our proposal, called Duo-GAN, uses two GAN generators to handle the data imbalance problem, one generator for fraudulent instances and the other for legitimate instances. With this approach, we observed, at most, a 5\% disparity in F1 scores between classifiers trained and tested with actual data and the ones trained with synthetic data and tested with actual data.},
	journal = {IEEE Access},
	author = {Ferreira, Francisco and Lourenço, Nuno and Cabral, Bruno and Fernandes, João Paulo},
	year = {2021},
	keywords = {Data models, Data privacy, Feeds, Fraud detection, Generative adversarial networks, Generators, Image synthesis, Training, generative adversarial networks, machine learning, privacy, synthetic data generation, tabular data},
	pages = {150459--150469},
}

@inproceedings{153,
	title = {Towards data generation to alleviate privacy concerns for cybersecurity applications},
	doi = {10.1109/COMPSAC57700.2023.00222},
	abstract = {While sharing of data is vital for learning progression and knowledge development, its full effectiveness is limited due to concerns about privacy and the presence of stringent regulations. This issue is particularly grave in the domain of cybersecurity applications where client data often comprises confidential and sensitive information. Furthermore, cybersecurity datasets tend to suffer from class imbalance, where data related to cyber attacks are rare compared to the benign conditions. Hence, performing machine learning (ML) tasks such as attack detection and classification becomes a challenging endeavor. Synthetic tabular data has emerged as a viable alternative to enable data sharing while satisfying regulatory and privacy constraints. In this paper, we present a methodology that utilizes the Intrusion Detection System (IDS) dataset to generate synthetic tabular representational data from raw dataset while addressing class imbalance issues during the data generation process. The methodology incorporates a feature selection process that identifies the most important features that help with accurate data generation, and demonstrates comparable performance using popular machine learning (ML) techniques on the anomaly detection task. The similarity between the original and generated datasets is evaluated using two metrics - distribution metric and data reduction metric - achieving up to 0.97 similarity score on the data reduction metric, outperforming a baseline approach that uses all input features by up to 11\%.},
	booktitle = {2023 {IEEE} 47th {Annual} {Computers}, {Software}, and {Applications} {Conference} ({COMPSAC})},
	author = {Ganji, Dhiraj and Chakraborttii, Chandranil},
	month = jun,
	year = {2023},
	keywords = {Data generation, Data privacy, Feature extraction, Generative Adversarial Networks, Intrusion Detection, Intrusion detection, Machine learning, Measurement, Regulation, Software},
	pages = {1447--1452},
}

@inproceedings{152,
	title = {Latent {Posterior} {Based} {Generative} {Adversarial} {Network} for {Imbalance} {Classification}},
	doi = {10.1109/CCDC49329.2020.9164226},
	abstract = {The imbalance classification problem arises when certain class is underrepresented in comparison with other classes, leading to a classifier partial to the majority classes. Existing interpolation-based oversampling methods for handling this problem characteristically do not make full use of the probability distribution of data. To overcome this weakness, this study proposes latent posterior based generative adversarial network oversampling approach(LPGOS), which uses a variational encoder to obtain the posterior distribution of latent variables. In addition, giving the high correlation between generated synthetic data and original data, we introduce a transfer learning approach with weight scaling factor namely TrWSBoost in which the generated minority class samples are treated as source domain data. Visual results prove that the proposed approach LPGOS is capable of approximate high dimensional data distribution and outperform other existing oversampling techniques. The performance of binary classifiers verify the effectiveness of proposed approaches.},
	booktitle = {2020 {Chinese} {Control} {And} {Decision} {Conference} ({CCDC})},
	author = {He, Xinlin and Cai, Meng and Li, Jianxun},
	month = aug,
	year = {2020},
	keywords = {Gallium nitride, Generative adversarial network, Generative adversarial networks, Generators, Imbalance classification, Latent variable, Learning systems, Probability distribution, Training, Training data, Transfer learning},
	pages = {3449--3454},
}

@inproceedings{151,
	title = {Improving {Attack} {Detection} {Performance} in {NIDS} {Using} {GAN}},
	doi = {10.1109/COMPSAC48688.2020.0-162},
	abstract = {Nowadays, various methods are proposed to build effective anomaly-based Network Intrusion Detection System (NIDS). However, malicious packets are extremely less than normal packets and this class imbalance problem will result in low performance of attack detection. In this study, we have proposed a new hybrid oversampling model using GAN to improve attack detection performance in anomaly-based NIDS. It contains three main steps: feature extraction by Information Gain and PCA, data clustering by DBSCAN and data generation by WGAN-DIV. For performance evaluation, three HTTP only datasets: NSL-KDD-HTTP, UNSW-NB15-HTTP and Kyoto2006-Plus-HTTP are used. Six machine learning methods are utilized as anomaly-based NIDS and SMOTE is also used for comparison. Our model with XGBoost has achieved best F1-score in these three datasets from the results.},
	booktitle = {2020 {IEEE} 44th {Annual} {Computers}, {Software}, and {Applications} {Conference} ({COMPSAC})},
	author = {Li, Dongyang and Kotani, Daisuke and Okabe, Yasuo},
	month = jul,
	year = {2020},
	keywords = {Data models, Feature extraction, GAN, Gallium nitride, Generative adversarial networks, Intrusion detection, NIDS, Oversampling, Principal component analysis, Training},
	pages = {817--825},
}

@inproceedings{150,
	title = {Data {Augmentation} using {Generative} models for {Credit} {Card} {Fraud} {Detection}},
	doi = {10.1109/CCAA.2018.8777628},
	abstract = {Credit card transactions have become the preferred mode of payments in developed countries and its utility is rapidly growing in developing countries making frauds an increasingly consequential problem leading to financial losses and erosion of consumer confidence. Although, credit card data is highly class imbalanced and this makes training of models to classify fraud data difficult. This study employs the use of multiple adversarial networks to generate pseudo data to enhance model performance. This study uses the vanilla implementation, Least Squares, Wasserstein, Margin Adaptive, Relaxed Wasserstein of GANs. The distribution of the generated data against original fraud data, the classifier accuracy, convergence for each model and an optimal number of data generations is analyzed. The generated data is then augmented and tested using an Artificial Neural Network model and a 12.86 \% increase in recall for a dataset with a class imbalance of initial 579 to 1 is recorded.},
	booktitle = {2018 4th {International} {Conference} on {Computing} {Communication} and {Automation} ({ICCCA})},
	author = {Sethia, Akhil and Patel, Raj and Raut, Purva},
	month = dec,
	year = {2018},
	keywords = {Anomaly detection, Convergence, Credit Card fraud, Credit cards, Data models, Gallium nitride, Generative Adversarial Networks Wasserstein GAN, Generators, Least Squares GAN, Margin Adaptive GAN, Mathematical model, Training},
	pages = {1--6},
}

@inproceedings{149,
	title = {{GAN}-based {Data} {Augmentation} for {Credit} {Card} {Fraud} {Detection}},
	doi = {10.1109/BigData55660.2022.10020419},
	abstract = {Deep generative approaches, such as GANs (generative adversarial networks), can be used to efficiently generate new data points that are similar to existing ones. This can be useful for increasing the size of a dataset or for creating synthetic data points that can be used in place of real ones. In this study, we trained classifiers using our novel K-CGAN approach and compared them to other oversampling approaches. We achieved higher F1 score performance metrics than the other methods. After conducting several experiments, we found that classifiers based on a Random Forest, Nearest Neighbor, Logistic Regression, MLP or Adaboost algorithm trained on the augmented set performed much better than those trained on the original data. This effectively creates a fraud detection mechanism.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Strelcenia, Emilija and Prakoonwit, Simant},
	month = dec,
	year = {2022},
	keywords = {Big Data, Classification algorithms, Credit cards, Fraud, Generators, Measurement, Network architecture, credit card fraud, data imbalance, gans},
	pages = {6812--6814},
}

@inproceedings{148,
	title = {Generative {Adversarial} {Neural} {Networks} based {Oversampling} {Technique} for {Imbalanced} {Credit} {Card} {Dataset}},
	doi = {10.1109/SLAAI-ICAI56923.2022.10002630},
	abstract = {The imbalanced dataset is a challenging issue in many classification tasks. Because it leads a machine learning algorithm to poor generalization and performance. The imbalanced dataset is characterized as having a huge difference between the number of samples that contain each class. Unfortunately, various resampling methods are proposed to solve this problem. In our work, we target enhancing the handling of the imbalanced dataset using a new oversampling technique based on generative adversarial neural networks. Our method is benchmarked against the widely used oversampling technique including the synthetic minority oversampling technique (SMOTE), random oversampling technique (ROS), and the adaptive synthetic sampling approach(ADSYN). Additionally, three machine learning algorithms are used for evaluation. The outcome of our experiments on a real-world credit card dataset shows the strong ability of the proposed solution against the competitive oversampling techniques to overcome the imbalanced problem in the European credit card dataset.},
	booktitle = {2022 6th {SLAAI} {International} {Conference} on {Artificial} {Intelligence} ({SLAAI}-{ICAI})},
	author = {El Kafhali, Said and Tayebi, Mohammed},
	month = dec,
	year = {2022},
	keywords = {Artificial intelligence, Benchmark testing, Credit cards, Europe, Imbalanced classification, Machine learning algorithms, Neural networks, Task analysis, generative adversarial neural networks, oversampling techniques},
	pages = {1--5},
}

@inproceedings{147,
	title = {Adversarial {Training} {Classifier} for {Imbalanced} and {Semi}-{Supervised} {Learning}},
	doi = {10.1109/CAC59555.2023.10451563},
	abstract = {The imbalanced learning research has made great progress due to the introduction of generative adversarial networks (GANs). However, most studies focus on combining GAN models with oversampling techniques which could potentially compromise the distribution of the original training dataset. This study presents a cost-sensitive classifier based on the adversarial training framework that can not only deal with imbalanced data distribution but also utilize the unlabeled sample sets for semi-supervised learning. Extensive experiments are carried out to compare the classification performance on imbalanced datasets with the resampling and balanced ensemble method, as well as class-imbalanced semi-supervised scenarios, to demonstrate the advantages of the proposed method.},
	booktitle = {2023 {China} {Automation} {Congress} ({CAC})},
	author = {Liu, Weiqiang and Chen, Mengting and Chen, Rui},
	month = nov,
	year = {2023},
	keywords = {Automation, Classification algorithms, Ensemble learning, Generative adversarial networks, Generative adversarial networks(GANs), Semisupervised learning, Training, cost-sensitive, focal loss, imbalanced learning, semi-supervised learning},
	pages = {5980--5985},
}

@inproceedings{146,
	title = {Gaussian {Mixture} {Conditional} {Tabular} {Generative} {Adversarial} {Network} for {Data} {Imbalance} {Problem}},
	doi = {10.1109/SRSE59585.2023.10336134},
	abstract = {It is common for the collected data to have inconsistent numbers of some classes. The data imbalance problem causes machine learning algorithms in prediction tasks to encounter serious difficulties. To solve this issue, many effective oversampling algorithms have been proposed, but few methods pay attention to clustering analysis on data labels. In this paper, the two-stage oversampling method called Gaussian Mixture Conditional Tabular Generative Adversarial Network (GMM\_CTGAN) improved based on Conditional Tabular Generative Adversarial Network (CTGAN) with the Gaussian Mixture Model (GMM) is proposed. Firstly, GMM is used as a clustering algorithm to divide the original dataset into multiple subsets. Secondly, CTGAN generates synthetic data for each class independently. Eventually, the synthetic data of all classes and original data are united to form the final training dataset. The experimental results reveal our proposed method shows more excellent performance than others and effectively solves the data imbalance problem.},
	booktitle = {2023 5th {International} {Conference} on {System} {Reliability} and {Safety} {Engineering} ({SRSE})},
	author = {Ke, Yongwei and Cheng, Jiali and Cai, Zhiqiang},
	month = oct,
	year = {2023},
	keywords = {Clustering algorithms, Gaussian Mixture Model, Generative Adversarial Network, Generative adversarial networks, Machine learning algorithms, Predictive models, Reliability, Safety, Training, data imbalance problem, oversample, synthetic data},
	pages = {93--97},
}

@inproceedings{145,
	title = {Tabular {GAN}-{Based} {Oversampling} of {Imbalanced} {Time}-to-{Event} {Data} for {Survival} {Prediction}},
	doi = {10.1109/ICCCBDA56900.2023.10154883},
	abstract = {Class imbalance causes an underestimation (overestimation) of the hazard of minority class in survival prediction. A common strategy to handle class imbalance is to oversample the minority class by generating synthetic samples. This paper explores the potential of tabular Generative Adversarial Networks (GANs) for oversampling based on real world survival datasets and simulated imbalanced datasets. We compare GAN-based oversampling methods with traditional methods on generation of minority instances and balanced survival prediction. Experimental results show that balanced survival prediction after GAN-based oversampling can outperforms baseline in some situations, and also demonstrate that traditional oversampling methods perform better than GAN-based methods on both minority samples generation and balanced survival prediction.},
	booktitle = {2023 8th {International} {Conference} on {Cloud} {Computing} and {Big} {Data} {Analytics} ({ICCCBDA})},
	author = {Tan, Huaning and Chen, Renxing and Qin, Meng and Tang, Lining and Wu, Zhibing and Luo, Qianlin and Quan, Yujuan},
	month = apr,
	year = {2023},
	keywords = {Big Data, Class imbalance, Cloud computing, Generative adversarial networks, Hazards, Measurement, Oversampling, Predictive models, Survival Analysis, Tabular data generation, Training},
	pages = {376--380},
}

@article{144,
	title = {A {Hybrid} {GAN}-{Based} {Approach} to {Solve} {Imbalanced} {Data} {Problem} in {Recommendation} {Systems}},
	volume = {10},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2022.3141776},
	abstract = {With the advent of information technology, the amount of online data generation has been massive. Recommendation systems have become an effective tool in filtering information and solving the problem of information overload. Machine learning algorithms to build these recommendation systems require well-balanced data in terms of class distribution, but real-world datasets are mostly imbalanced in nature. Imbalanced data imposes a classifier to focus more on the majority class, neglecting other classes of interests and thus hindering the predictive performance of any classification model. There exist many traditional techniques for oversampling minority classes. Still, generative adversarial networks (GAN) have been showing excellent results in generating realistic synthetic tabular data that keeps the probability distribution of the original data intact. In this paper, we propose a hybrid GAN approach to solve the data imbalance problem to enhance recommendation systems’ performance. We implemented conditional Wasserstein GAN with gradient penalty to generate tabular data containing both numerical and categorical values. We also augmented auxiliary classifier loss to enforce the model to explicitly generate data belonging to the minority class. We designed the discriminator architecture with the concept of PacGAN to receive m-packed samples as input instead of a single input. This inclusion of the PacGAN architecture eliminated the mode collapse problem in our proposed model. We did a two-fold evaluation of our model. Firstly based on the quality of the generated data and secondly on how different recommendation models perform using the generated data compared to original data.},
	journal = {IEEE Access},
	author = {Shafqat, Wafa and Byun, Yung-Cheol},
	year = {2022},
	keywords = {Data mining, Data models, GAN, Generative adversarial networks, Generators, IP networks, Numerical models, PacGAN, Training, WGAN-GP, condition GAN, imbalanced data, oversampling, recommendation systems, synthetic data},
	pages = {11036--11047},
}

@inproceedings{143,
	title = {Targeting class imbalance problem using {GAN}},
	doi = {10.1109/ICEECCOT52851.2021.9708011},
	abstract = {Imbalanced data categorization is inescapable, and it has an impact on the model’s classification problem, which can cause false results. The purpose of this paper is to propose a generative adversarial network (GAN) for restoring balance in imbalanced datasets. This is a challenge since the limited minority data may not be sufficient for GAN training. The proposed article overcomes this issue by adversarial training all available data of minority and majority classes. The data for the minority class is generated using the generative model, which learns all of the useful features from the majority class. The generator in the GAN generates realistic-looking minority class samples. To validate the given method’s classification performance, experiments are performed on a credit card fraud detection dataset. This paper uses a Generative Adversarial Network to give an appropriate solution for imbalanced data classification.},
	booktitle = {2021 5th {International} {Conference} on {Electrical}, {Electronics}, {Communication}, {Computer} {Technologies} and {Optimization} {Techniques} ({ICEECCOT})},
	author = {Bhagwani, Hitesh and Agarwal, Sonali and Kodipalli, Ashwini and Martis, Roshan Joy},
	month = dec,
	year = {2021},
	keywords = {Credit cards, Data models, GAN, Generative adversarial networks, Generators, Imbalanced, Optimization, Support vector machines, Training, generator, high-dimensional},
	pages = {318--322},
}

@inproceedings{140,
	title = {A {Comparative} {Analysis} of {GAN} and {VAE} based {Synthetic} {Data} {Generators} for {High} {Dimensional}, {Imbalanced} {Tabular} data},
	doi = {10.1109/INOCON57975.2023.10101315},
	abstract = {Synthetic data has emerged as an acceptable solution in machine learning that overcomes the constraints of data availability due to data privacy restrictions. Other major challenge with machine learning is dealing with imbalanced dataset. Several techniques exist to deal with the data imbalance, however, the problem continues to exist when using synthetic data generators dealing with highly imbalanced datasets. Generative Adversarial Network is already proven to be an excellent model to generate synthetic data, especially for high-dimensional datasets. There are other deep learning models that use Variational Autoencoders and Recurrent Neural Networks which are also being explored. To understand how these generators perform when presented situations dealing with highly imbalanced datasets, we experimentally evaluate two deep-learning synthetic data generators, one is based on Generative Adversarial Network (CTGAN) and the other is on Variational Auto Encoder (TVAE). We assess how each of these performs when presented with two datasets of distinct characteristics. The datasets used are high dimensional, highly imbalanced tabular data with one dataset having 19.3\% minority class and the other having only 5.68\% of minority class. Our test results find that TVAE fails to generate minority data when the minority class is very small in number.},
	booktitle = {2023 2nd {International} {Conference} for {Innovation} in {Technology} ({INOCON})},
	author = {Kiran, A and Kumar, S Saravana},
	month = mar,
	year = {2023},
	keywords = {ADASYN, CTGAN, Data privacy, Deep learning, Generative adversarial networks, Generators, Industries, Recurrent neural networks, Synthetic Data Vault, TVAE, Technological innovation},
	pages = {1--6},
}

@inproceedings{142,
	title = {Performance {Enhancement} of {Malware} {Classifiers} {Using} {Generative} {Adversarial} {Networks}},
	doi = {10.1109/BigData55660.2022.10020505},
	abstract = {This study presents comprehensive experimental results for the IEEE BigData 2022 Cup, using a generative adversarial network (GAN) to generate appropriate malign samples to improve a malware classifier’s performance. For the experiments, we employed conditional tabular GAN (CTGAN), conditional table GAN (CTAB-GAN), and complementary GAN architectures to deal with the data imbalance problem commonly encountered in classification tasks. The results showed that CTAB-GAN outperformed the other GANs in producing synthetic data that are statistically comparable to the given training data. This shows that the classifier’s performance improved on the validation dataset, and suggests that better classification performance can be achieved in terms of machine learning efficacy using better quality synthetic data. Although CTAB-GAN performed better than CTGAN and Complementary GAN in terms of statistical similarity and machine learning efficacy, it could overfit on the training data. Therefore, we used both CTGAN and CTAB-GAN to produce a balanced dataset to train the classifier for the final solution. The root mean square error of the classifier was 0.103, which is an improvement of 0.066 from the baseline performance of 0.169.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Shin, Donghwa and Han, Daehee and Kyeong, Sunghyon},
	month = dec,
	year = {2022},
	keywords = {Big Data, Generative adversarial networks, Machine learning, Malware, Probability distribution, Task analysis, Training data, data augmentation, deep learning, generative adversarial networks, malware classification},
	pages = {6528--6533},
}

@inproceedings{141,
	title = {{MLGAN}: {Addressing} {Imbalance} in {Multilabel} {Learning} {Using} {Generative} {Adversarial} {Networks}},
	shorttitle = {{MLGAN}},
	doi = {10.1109/ICETCI58599.2023.10331105},
	abstract = {A common problem while training supervised deep learning models is the lack of labeled training data. Often real-life datasets such as multilabel datasets suffer from class Imbalance problem, which is inescapable. The limited minority data may not be sufficient for efficient learning and often can cause the networks to overfit. This paper considers the potential appli-cation of Generative Adversarial Networks to restore balance in imbalanced multilabel datasets. We will generate new data for the minority labels and use multilabel learning algorithms to handle multilabel data. We compare our model with MLSMOTE with local label imbalance to validate the effectiveness of our model. Experiments over six real datasets using five different multilabel learning algorithms and five evaluation measures show that our strategy of resampling the multilabel data constantly outperforms MLSMOTE with local label imbalance. Results indicate that imbalance in multilabel datasets is reduced in a classifier-independent way; that is, the classifier should have a deplorable influence on the effectiveness of the resampling strategy. While generating new samples from GAN architecture, we use representative class samples to represent each class distribution which further reduces the training time.},
	booktitle = {2023 {International} {Conference} on {Emerging} {Techniques} in {Computational} {Intelligence} ({ICETCI})},
	author = {Dar, Aatif Nisar and Rastogi, Reshma},
	month = sep,
	year = {2023},
	keywords = {Class Imbalance, Classification algorithms, Computer architecture, Data models, Deep learning, Generative Adversarial Networks, Generative adversarial networks, Multi-Label learning, Training, Training data},
	pages = {324--331},
}

@inproceedings{139,
	title = {Comparative {Analysis} of {Machine} {Learning} {Algorithms} using {GANs} through {Credit} {Card} {Fraud} {Detection}},
	doi = {10.1109/CoNTESA57046.2022.10011268},
	abstract = {In more recent years, credit card fraudulent transactions became a major problem. These fraudulent transactions not only incur huge monetary losses to commercial banks and financial institutions, but also stress and trouble to the lives of customers. Furthermore, with the passage of time this issue is increasing and the monetary loss is expected to increase significantly. However, efficient fraud detecting and prevention measures can trim down the monetary loss due to financial fraud activities. Credit card fraud detection has gained much interest from academia. Generative Adversarial Networks (GANs) are an effective class of generative approaches that has been able to generate synthetic data to assist with the classification of credit card fraudulent activities. In this research study we’re going to compare architectures of various GAN models which demonstrate the evolution of these models. It was observed that GANs have received much attention from researchers and also attained promising results in the field of credit card fraud detection.},
	booktitle = {2022 {International} {Conference} on {Computing}, {Networking}, {Telecommunications} \& {Engineering} {Sciences} {Applications} ({CoNTESA})},
	author = {Strelcenia, Emilija and Prakoonwit, Simant},
	month = dec,
	year = {2022},
	keywords = {Credit cards, GANs, Generative adversarial networks, Imbalanced data, Loss measurement, Machine learning algorithms, Solids, Training, Training data, component, fraud detection, hyperparameter setting},
	pages = {1--5},
}

@inproceedings{138,
	title = {A {K}-means {Improved} {CTGAN} {Oversampling} {Method} for {Data} {Imbalance} {Problem}},
	doi = {10.1109/QRS54544.2021.00097},
	abstract = {CTGAN is a tabular data synthesis method for privacy preservation, which is used in this paper for data imbalance problem. This paper proposes a method for dealing with imbalanced data sets that combines K-means clustering and CTGAN to address the imbalanced distribution of minority class examples that result from oversampling with CTGAN. By conducting experiments with the LightGBM algorithm on home loan and online shopping datasets, it is demonstrated that the CTGAN method achieves superior learning results in f1-score and G-mean metrics compared to the interpolation-based oversampling technique represented by SMOTE. The preceding results indicate that by applying the method described in this paper to handle an imbalanced dataset, one can obtain a dataset with more examples, a more uniform distribution, and less overfitting while still satisfying the original dataset's probability distribution.},
	booktitle = {2021 {IEEE} 21st {International} {Conference} on {Software} {Quality}, {Reliability} and {Security} ({QRS})},
	author = {An, Chunsheng and Sun, Jingtong and Wang, Yifeng and Wei, Qingjie},
	month = dec,
	year = {2021},
	keywords = {CTGAN, Clustering algorithms, Conferences, Data privacy, K-means, Measurement, Probability distribution, Software algorithms, Software quality, data imbalance, oversampling},
	pages = {883--887},
}

@article{137,
	title = {Ensemble {Synthesized} {Minority} {Oversampling}-{Based} {Generative} {Adversarial} {Networks} and {Random} {Forest} {Algorithm} for {Credit} {Card} {Fraud} {Detection}},
	volume = {11},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2023.3306621},
	abstract = {The recent increase in credit card fraud is rapidly has caused huge monetary losses for individuals and financial institutions. Most credit card frauds are conducted online by illegally obtaining payment credentials through data breaches, phishing, or scamming. Many solutions have been suggested to address the credit card fraud problem for online transactions. However, the high-class imbalance is the major challenge that faces the existing solutions to construct an effective detection model. Most of the existing techniques used for class imbalance overestimate the distribution of the minority class, resulting in highly overlapped or noisy and unrepresentative features, which cause either overfitting or imprecise learning. In this study, a credit card fraud detection model (CCFDM) is proposed based on ensemble learning and a generative adversarial network (GAN) assisted by Ensemble Synthesized Minority Oversampling techniques (ESMOTE-GAN). Multiple subsets were extracted using under-sampling and SMOTE was applied to generate less skewed sets to prevent the GAN from modeling the noise. These subsets were used to train diverse sets of GAN models to generate the synthesized subsets. A set of Random Forest classifiers was then trained based on the proposed ESMOTE-GAN technique. The probabilistic outputs of the trained classifiers were combined using a weighted voting scheme for decision-making. The results show that the proposed model achieved 1.9\%, and 3.2\% improvements in overall performance and the detection rate, respectively, with a 0\% false alarm rate. Due to the massive number of transactions, even a tiny false positive rate can overwhelm the analysis team. Thus, the proposed model has improved the detection performance and reduced the cost needed for manual analysis.},
	journal = {IEEE Access},
	author = {Ghaleb, Fuad A. and Saeed, Faisal and Al-Sarem, Mohammed and Qasem, Sultan Noman and Al-Hadhrami, Tawfik},
	year = {2023},
	keywords = {Class imbalance, Classification algorithms, Credit cards, Feature extraction, Fraud, GAN, Generative adversarial networks, Noise measurement, Random Forest, SMOTE, Training, credit card fraud detection},
	pages = {89694--89710},
}

@inproceedings{136,
	title = {Security-{Alert} {Screening} with {Oversampling} {Based} on {Conditional} {Generative} {Adversarial} {Networks}},
	doi = {10.1109/AsiaJCIS57030.2022.00011},
	abstract = {Imbalanced class distribution can cause information loss and missed/false alarms for deep learning and machine-learning algorithms. The detection performance of traditional intrusion detection systems tend to degenerate due to skewed class distribution caused by the uneven allocation of observations in different kinds of attacks. To combat class imbalance and improve network intrusion detection performance, we adopt the conditional generative adversarial network (CTGAN) that enables the generation of samples of specific classes of interest. CTGAN builds on the generative adversarial networks (GAN) architecture to model tabular data and generate high quality synthetic data by conditionally sampling rows from the generated model. Oversampling using CTGAN adds instances to the minority class such that both data in the majority and the minority class are of equal distribution. The generated security alerts are used for training classifiers that realize critical alert detection. The proposed scheme is evaluated on a real-world dataset collected from security operation center of a large enterprise. The experiment results show that detection accuracy can be substantially improved when CTGAN is adopted to produce a balanced security-alert dataset. We believe the proposed CTGAN-based approach can cast new light on building effective systems for critical alert detection with reduced missed/false alarms.},
	booktitle = {2022 17th {Asia} {Joint} {Conference} on {Information} {Security} ({AsiaJCIS})},
	author = {Ndichu, Samuel and Ban, Tao and Takahashi, Takeshi and Inoue, Daisuke},
	month = jul,
	year = {2022},
	keywords = {Buildings, Data models, Deep learning, Generative adversarial networks, Network intrusion detection, Security alert screening, Synthesizers, Training, conditional generative adversarial networks, oversampling, skewed class distribution},
	pages = {1--7},
}

@inproceedings{133,
	title = {Generative {Adversarial} {Networks} for {Bitcoin} {Data} {Augmentation}},
	doi = {10.1109/BRAINS49436.2020.9223269},
	abstract = {In Bitcoin entity classification, results are strongly conditioned by the ground-truth dataset, especially when applying supervised machine learning approaches. However, these ground-truth datasets are frequently affected by significant class imbalance as generally they contain much more information regarding legal services (Exchange, Gambling), than regarding services that may be related to illicit activities (Mixer, Service). Class imbalance increases the complexity of applying machine learning techniques and reduces the quality of classification results, especially for underrepresented, but critical classes.In this paper, we propose to address this problem by using Generative Adversarial Networks (GANs) for Bitcoin data augmentation as GANs recently have shown promising results in the domain of image classification. However, there is no “one-fits-all” GAN solution that works for every scenario. In fact, setting GAN training parameters is non-trivial and heavily affects the quality of the generated synthetic data. We therefore evaluate how GAN parameters such as the optimization function, the size of the dataset and the chosen batch size affect GAN implementation for one underrepresented entity class (Mining Pool) and demonstrate how a “good” GAN configuration can be obtained that achieves high similarity between synthetically generated and real Bitcoin address data. To the best of our knowledge, this is the first study presenting GANs as a valid tool for generating synthetic address data for data augmentation in Bitcoin entity classification.},
	booktitle = {2020 2nd {Conference} on {Blockchain} {Research} \& {Applications} for {Innovative} {Networks} and {Services} ({BRAINS})},
	author = {Zola, Francesco and Bruse, Jan Lukas and Barrio, Xabier Etxeberria and Galar, Mikel and Urrutia, Raul Orduna},
	month = sep,
	year = {2020},
	keywords = {Bitcoin, Bitcoin classifier, Complexity theory, Data mining, Generative Adversarial Network, Generative adversarial networks, Law, Machine learning, Training, address behaviour, class imbalance, data augmentation},
	pages = {136--143},
}

@inproceedings{135,
	title = {Conditional {Data} {Synthesis} with {Deep} {Generative} {Models} for {Imbalanced} {Dataset} {Oversampling}},
	doi = {10.1109/ICTAI59109.2023.00071},
	abstract = {The problem of data imbalance is defined as the uneven distribution of the training examples to the existing classes of a dataset. Among a wide variety of solutions, the oversampling techniques try to mitigate the problem by synthesizing artificial examples associated with the minority class. The huge success of Generative Adversarial Networks (GANs) rendered them an attractive choice for oversampling and numerous researchers proposed modifications of GANs for imbalanced datasets. Nevertheless, the existing models employ the entire minority class for sample generation, thus being vulnerable to outliers and noisy data instances. In addition, the majority of the relevant research concerns image classification tasks, leaving a large gap for research with tabular data. Finally, another powerful and popular generative model, the Variational Autoencoder (VAE) has been rather overlooked by the community in class imbalance solutions. In this paper we present SB-GAN and SB-VAE, two generative models that identify borderline and noisy samples before they are trained. In this manner SB-GAN and SB-VAE learn better class distributions that are not distorted by the existence of outliers. The experimental evaluation of SB-GAN and SB-VAE with 4 tabular datasets revealed a superior performance against 8 state-of-the-art oversampling techniques.},
	booktitle = {2023 {IEEE} 35th {International} {Conference} on {Tools} with {Artificial} {Intelligence} ({ICTAI})},
	author = {Akritidis, Leonidas and Fevgas, Athanasios and Alamaniotis, Miltiadis and Bozanis, Panayiotis},
	month = nov,
	year = {2023},
	keywords = {Artificial intelligence, Data models, GAN, Generative adversarial networks, Image classification, Noise measurement, Task analysis, Training, VAE, generative models, imbalanced datasets, oversampling},
	pages = {444--451},
}

@article{134,
	title = {Generative {Adversarial} {Networks}-{Based} {Novel} {Approach} for {Fraud} {Detection} for the {European} {Cardholders} 2013 {Dataset}},
	volume = {11},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2023.3320072},
	abstract = {Credit card use poses a significant security issue on a global scale, with rule-based algorithms and traditional anomaly detection being two of the most often used methods. However, they are resource-intensive, time-consuming, and erroneous. Given fewer instances than legal payments, the dataset imbalance has become a serious issue. On the other hand, the generative technique is considered an effective way to rebalance the imbalanced class issue, as this technique balances both minority and majority classes before the training. In a more recent period, GAN is considered one of the most popular data generative techniques, as it is used in significant data settings. Hence, the research under study explores a classification system to detect fraudulent credit card transactions that are being trained using the European Cardholders 2013 dataset. It has 30 features, 28 of which are hidden due to sensitive information. Fraud activity accounts for less than 1\% of the entire transaction volume of \vphantom{\{}\}\$ 284807. Additionally, GANs is a generative model based on game theory, in which a generator G and a discriminator D compete with one another. The generator’s goal is to make the discriminator uncertain. Distinguishing between instances from the generator and those from the original dataset is the discriminator’s goal, and we can increase classifiers’ discriminating strength by training GANs on a set of fraudulent credit card transactions. According to the outcome, our model outperformed the earlier experiments with an AUC score of 0.999. Additionally, it creates artificial data using GANs, enabling the production of a sizable volume of high-quality data. In terms of innovation and performance, this technique substantially improves over earlier research.},
	journal = {IEEE Access},
	author = {Almarshad, Fahdah A. and Gashgari, Ghada Abdalaziz and Alzahrani, Abdullah I. A.},
	year = {2023},
	keywords = {Credit card fraud detection, Credit cards, Deep learning, Feature extraction, Fraud, Generative adversarial networks, Hidden Markov models, Machine learning, Support vector machines, deep learning, fraud detection, generative adversarial networks, imbalanced data},
	pages = {107348--107368},
}

@inproceedings{131,
	title = {Leveraging {Artificial} {Intelligence} for {Enhanced} {Data} {Generation} in {Addressing} {Imbalance} in {Binary} {Classification} {System}},
	volume = {2},
	doi = {10.1109/IATMSI60426.2024.10503258},
	abstract = {This paper delves into the challenges of binary classification using imbalanced datasets, particularly when instances of interest are infrequent. It explores a comprehensive approach that integrates Synthetic Minority Over-sampling Technique (SMOTE), Generative Adversarial Networks (GANs), and Variational Autoencoders (VAEs) to enhance classification outcomes. Traditional classification models tend to favor the majority class, while the impact of imbalanced misclassification costs is often overlooked. The integration of SMOTE, GANs, and VAEs in binary classification, or SMOTE-GAN-VAE, addresses these challenges by generating synthetic instances, refining data representations, and capturing latent features. To evaluate the effectiveness of various data generation methods, a credit card fraud dataset is used. The performance metrics considered include F0.5-score, F1-score, and F2-score, which account for both precision and recall. The results indicate that SMOTE-GAN-VAE outperforms individual methods, such as SMOTE, GANs, and VAEs, demonstrating its potential to enhance data representation and classification accuracy, and outperformed the β- VAE filtered approach employed in previous literature.},
	booktitle = {2024 {IEEE} {International} {Conference} on {Interdisciplinary} {Approaches} in {Technology} and {Management} for {Social} {Innovation} ({IATMSI})},
	author = {Bandopadhyay, Srijita and Dutta, Srimonti and Haider, Imran and Anuraag, Bhavaraju and Zhu, Jerry and Bazaz, Saad Ahmed},
	month = mar,
	year = {2024},
	keywords = {Binary classification, Costs, Credit cards, Data generation, Fraud, Generative adversarial networks, Imbalanced data, Measurement, Refining, Technological innovation},
	pages = {1--4},
}

@inproceedings{130,
	title = {An early malware threat detection model using {Conditional} {Tabular} {Generative} {Adversarial} {Network}},
	doi = {10.1109/ICCCNT56998.2023.10307903},
	abstract = {In this paper, we propose the use of CT-GAN, a novel conditional table GAN architecture, to address the challenges of limited data availability in the field of malware detection. The current state-of-the-art data synthesizers for tabular data focus on continuous and categorical variables separately, while our approach combines both types of variables in a unified framework.To evaluate our method, we employed the KDD\_cup99 dataset provided by the University of New Brunswick and used CT-GAN to generate a similar dataset. We trained the CT-GAN model using the generated dataset and assessed its performance by testing it on the original dataset. Surprisingly, our evaluation revealed consistently high accuracies exceeding 93\% across various models, including basic machine learning algorithms, when trained on the CT-GAN generated dataset. By employing different train-test splits, we determined that a split of 67-33 yielded the best results. The generated data closely resembled the original data but exhibited a good partition between different classes, which facilitated more effective training of the models. We experimented with several classifier models, such as Gaussian-NB, decision tree classifier, and random forest, to train the GAN-generated dataset. The accuracy of these different models is also presented in the paper.GANs are particularly advantageous in their ability to generate novel data samples through an adversarial training process involving a generator and discriminator. Our CT-GAN approach leverages this capability to overcome the limitations posed by limited data availability in the domain of malware detection.},
	booktitle = {2023 14th {International} {Conference} on {Computing} {Communication} and {Networking} {Technologies} ({ICCCNT})},
	author = {Amrith, V and S, Darshan and S, Suriya K and Vajipayajula, Sulakshan and Srinivasan, Kartik and Thangavel, Senthil Kumar and Kumar, T. Gireesh},
	month = jul,
	year = {2023},
	keywords = {CT-GAN, Data models, Decision tree classifier, Gaussian NB, Generative adversarial networks, KDD, Malware, Random Forest classifier, Reliability, Synthesizers, Threat assessment, Training},
	pages = {1--8},
}

@inproceedings{129,
	title = {{ccfDetector}: {Utilizing} {GAN} and {Deep} {Learning} for {Credit} {Card} {Fraud} {Detection}},
	shorttitle = {{ccfDetector}},
	doi = {10.1109/ASET56582.2023.10180825},
	abstract = {In recent years, the widespread adoption of e-commerce has led to a corresponding growth in credit card fraud. To combat this issue, organizations have begun implementing fraud detection systems using machine learning techniques. However, most credit card fraud detection datasets suffer from imbalanced data, which can impact the performance of these systems. In this study, we propose using Generative Adversarial Networks (GANs) to address this problem. By training the GAN on the unbalanced dataset of credit card fraud detection, we can generate additional synthetic records belonging to the underrepresented class (e.g. fraudulent transactions) to balance the dataset. Moreover, we propose a deep learning model based on Artificial Neural Networks to classify the dataset. Also, we examine the impact of feature selection on the performance of the model and demonstrate that our approach results in improved sensitivity. We combined these three components in a system called ccffDetector. Our results show that using generated records merged with the training dataset results in the highest sensitivity of 0.9024\%. This indicates that our approach has the potential to improve the credit card fraud detection system's effectiveness.},
	booktitle = {2023 {Advances} in {Science} and {Engineering} {Technology} {International} {Conferences} ({ASET})},
	author = {Khaled, Mohammed M. and AL Aghbari, Zaher},
	month = feb,
	year = {2023},
	keywords = {Artificial neural networks, Credit card fraud detection, Credit cards, Deep learning, Feature extraction, Generative adversarial networks, Sensitivity, Tabular data, Training},
	pages = {1--6},
}

@inproceedings{128,
	title = {Research on {Oversampling} {Method} of {Imbalanced} {Dataset} {Based} on {Improved} {Generative} {Adversarial} {Network}},
	volume = {1},
	doi = {10.1109/NTCI60157.2023.10403663},
	abstract = {Binary classification frequently entails the challenge of imbalanced datasets, characterized by substantial disparities in sample sizes between the two different classes. The data imbalance usually makes it difficult for classifiers to learn positive samples, leading to unsatisfactory classification effects. Generative adversarial network (GAN) can be used as an oversampling method to rectify data imbalance by generating positive samples. However, when confronted with a multi-cluster distribution of positive samples, GAN often experiences a mode collapse, that is, only a partial distribution of a few samples can be learned, resulting in the aggregation of generated data into a cluster or a segment. To solve this problem, this paper proposes a novel method MIX-NOISE GAN. It employs Gaussian Mixture Model (GMM) to generate GMM noise that aligns with the distribution of positive samples. The GMM noise is then combined with traditional random noise as the generator input, referred to as the mixture of noise. Empirical results and visualizations from experiments conducted on simulated and benchmark datasets demonstrate that MIX-NOISE GAN significantly enhances classification performance on 17 imbalanced datasets compared to six classical sampling methods in terms of G-mean, F-measure, and AVC.},
	booktitle = {2023 {International} {Conference} on {New} {Trends} in {Computational} {Intelligence} ({NTCI})},
	author = {Tao, Yu and Chen, Yueqi and Yang, Jie},
	month = nov,
	year = {2023},
	keywords = {Computational intelligence, GAN, Gaussian mixture model, Generative adversarial networks, Generators, Market research, Mixture models, Sampling methods, imbalanced dataset, mode collapse},
	pages = {112--116},
}

@inproceedings{127,
	title = {Unrolled {GAN}-based {Oversampling} of {Credit} {Card} {Dataset} for {Fraud} {Detection}},
	doi = {10.1109/ICAICA54878.2022.9844421},
	abstract = {The excellent performance of most classification algorithms is based on the balance of classes. However, in anomaly detection, the classes are mostly biased. The performance of traditional machine learning algorithms applied to anomaly detection of ten fails to achieve the target effect. Considering the data source, oversampling method addresses class imbalance from data source. In light of the capability of capturing the original sample data distribution, Generative Adversarial Networks offer an inspiring oversampling solution. In this research we demonstrate the applicability of an oversampling method based on Unrolled GAN with credit card data sets. We contrast that method with traditional oversampling methods. Empirical results show the capacity of Unrolled GAN-based oversampling.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Artificial} {Intelligence} and {Computer} {Applications} ({ICAICA})},
	author = {Wang, Jingzhong and Yao, Lin},
	month = jun,
	year = {2022},
	keywords = {Computer applications, Conferences, Credit cards, Generative adversarial networks, Machine learning algorithms, Soft sensors, Training, Unrolled GAN, class imbalance, fraud detection, oversampling},
	pages = {858--861},
}

@article{86,
	title = {Searching for {Optimal} {Oversampling} to {Process} {Imbalanced} {Data}: {Generative} {Adversarial} {Networks} and {Synthetic} {Minority} {Over}-{Sampling} {Technique}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-7390},
	shorttitle = {Searching for {Optimal} {Oversampling} to {Process} {Imbalanced} {Data}},
	doi = {10.3390/math11163605},
	abstract = {Classification problems due to data imbalance occur in many fields and have long been studied in the machine learning field. Many real-world datasets suffer from the issue of class imbalance, which occurs when the sizes of classes are not uniform; thus, data belonging to the minority class are likely to be misclassified. It is particularly important to overcome this issue when dealing with medical data because class imbalance inevitably arises due to incidence rates within medical datasets. This study adjusted the imbalance ratio (IR) within the National Biobank of Korea dataset “Epidemiologic data of Parkinson’s disease dementia patients” to values of 6.8 (raw data), 9, and 19 and compared four traditional oversampling methods with techniques using the conditional generative adversarial network (CGAN) and conditional tabular generative adversarial network (CTGAN). The results showed that when the classes were balanced with CGAN and CTGAN, they showed a better classification performance than the more traditional oversampling techniques based on the AUC and F1-score. We were able to expand the application scope of GAN, widely used in unstructured data, to structured data. We also offer a better solution for the imbalanced data problem and suggest future research directions.},
	language = {en},
	number = {16},
	journal = {Mathematics},
	author = {Eom, Gayeong and Byeon, Haewon},
	month = jan,
	year = {2023},
	keywords = {CGAN, CTGAN, class imbalance, oversampling, tabular data},
	pages = {3605},
}

@article{84,
	title = {Improving irregular temporal modeling by integrating synthetic data to the electronic medical record using conditional {GANs}: a case study of fluid overload prediction in the intensive care unit},
	shorttitle = {Improving irregular temporal modeling by integrating synthetic data to the electronic medical record using conditional {GANs}},
	doi = {10.1101/2023.06.20.23291680},
	abstract = {OBJECTIVE: The challenge of irregular temporal data, which is particularly prominent for medication use in the critically ill, limits the performance of predictive models. The purpose of this evaluation was to pilot test integrating synthetic data within an existing dataset of complex medication data to improve machine learning model prediction of fluid overload.
MATERIALS AND METHODS: This retrospective cohort study evaluated patients admitted to an ICU ≥ 72 hours. Four machine learning algorithms to predict fluid overload after 48-72 hours of ICU admission were developed using the original dataset. Then, two distinct synthetic data generation methodologies (synthetic minority over-sampling technique (SMOTE) and conditional tabular generative adversarial network (CT-GAN)) were used to create synthetic data. Finally, a stacking ensemble technique designed to train a meta-learner was established. Models underwent training in three scenarios of varying qualities and quantities of datasets.
RESULTS: Training machine learning algorithms on the combined synthetic and original dataset overall increased the performance of the predictive models compared to training on the original dataset. The highest performing model was the metamodel trained on the combined dataset with 0.83 AUROC while it managed to significantly enhance the sensitivity across different training scenarios.
DISCUSSION: The integration of synthetically generated data is the first time such methods have been applied to ICU medication data and offers a promising solution to enhance the performance of machine learning models for fluid overload, which may be translated to other ICU outcomes. A meta-learner was able to make a trade-off between different performance metrics and improve the ability to identify the minority class.},
	language = {eng},
	journal = {medRxiv: The Preprint Server for Health Sciences},
	author = {Rafiei, Alireza and Rad, Milad Ghiasi and Sikora, Andrea and Kamaleswaran, Rishikesan},
	month = jun,
	year = {2023},
	pages = {2023.06.20.23291680},
}

@article{85,
	title = {A {Hybrid} {GAN}-{Based} {DL} {Approach} for the {Automatic} {Detection} of {Shockable} {Rhythms} in {AED} for {Solving} {Imbalanced} {Data} {Problems}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	doi = {10.3390/electronics12010013},
	abstract = {Sudden cardiac arrest (SCA) is one of the global health issues causing high mortality. Hence, timely and agile detection of such arrests and immediate defibrillation support to SCA victims is of the utmost importance. An automated external defibrillator (AED) is a medical device used to treat patients suffering from SCA by delivering an electric shock. An AED implements the machine learning (ML)- or deep learning (DL)-based approach to detect whether the patient needs an electric shock and then automates the shock if needed. However, the effectiveness of these models has relied on the availability of well-balanced data in class distribution. Due to privacy concerns, collecting sufficient data is more challenging in the medical domain. Generative adversarial networks (GAN) have been successfully used to create synthetic data and are far better than standard oversampling techniques in maintaining the original data’s probability distribution. We, therefore, proposed a GAN-based DL approach, external classifier–Wasserstein conditional generative adversarial network (EC–WCGAN), to detect the shockable rhythms in an AED on an imbalanced ECG dataset. Our experiments demonstrate that the classifier trained with real and generated data via the EC–WCGAN significantly improves the performance metrics on the imbalanced dataset. Additionally, the WCGAN for generating synthetic data outperformed the standard oversampling technique, such as adaptive synthetic (ADASYN). In addition, our model achieved a high sensitivity, specificity, and F1-score (more than 99\%) and a low balanced error rate (0.005) on the balanced 4-s segmented public Holter databases, meeting the American Health Association criteria for AEDs.},
	language = {en},
	number = {1},
	journal = {Electronics},
	author = {Dahal, Kamana and Ali, Mohd Hasan},
	month = jan,
	year = {2023},
	keywords = {ADASYN, AED, EC–GAN, GAN, SCA, WCGAN, imbalanced data, tabular synthetic data generation},
	pages = {13},
}

@article{83,
	title = {Updating guidance for reporting systematic reviews: development of the {PRISMA} 2020 statement},
	volume = {134},
	issn = {0895-4356},
	shorttitle = {Updating guidance for reporting systematic reviews},
	doi = {10.1016/j.jclinepi.2021.02.003},
	abstract = {Objectives
To describe the processes used to update the PRISMA 2009 statement for reporting systematic reviews, present results of a survey conducted to inform the update, summarize decisions made at the PRISMA update meeting, and describe and justify changes made to the guideline.
Methods
We reviewed 60 documents with reporting guidance for systematic reviews to generate suggested modifications to the PRISMA 2009 statement. We invited 220 systematic review methodologists and journal editors to complete a survey about the suggested modifications. The results of these projects were discussed at a 21-member in-person meeting. Following the meeting, we drafted the PRISMA 2020 statement and refined it based on feedback from co-authors and a convenience sample of 15 systematic reviewers.
Results
The review of 60 documents revealed that all topics addressed by the PRISMA 2009 statement could be modified. Of the 110 survey respondents, more than 66\% recommended keeping six of the original checklist items as they were and modifying 15 of them using wording suggested by us. Attendees at the in-person meeting supported the revised wording for several items but suggested rewording for most to enhance clarity, and further refinements were made over six drafts of the guideline.
Conclusions
The PRISMA 2020 statement consists of updated reporting guidance for systematic reviews. We hope that providing this detailed description of the development process will enhance the acceptance and uptake of the guideline and assist those developing and updating future reporting guidelines.},
	journal = {Journal of Clinical Epidemiology},
	author = {Page, Matthew J and McKenzie, Joanne E and Bossuyt, Patrick M and Boutron, Isabelle and Hoffmann, Tammy C and Mulrow, Cynthia D and Shamseer, Larissa and Tetzlaff, Jennifer M and Moher, David},
	month = jun,
	year = {2021},
	keywords = {Meta-analysis, Reporting guidelines, Reproducibility, Systematic reviews, Transparency},
	pages = {103--112},
}

@article{82,
	title = {How to properly use the {PRISMA} {Statement}},
	volume = {10},
	issn = {2046-4053},
	doi = {10.1186/s13643-021-01671-z},
	language = {en},
	number = {1},
	journal = {Systematic Reviews},
	author = {Sarkis-Onofre, Rafael and Catalá-López, Ferrán and Aromataris, Edoardo and Lockwood, Craig},
	month = apr,
	year = {2021},
	pages = {117},
}

@article{80,
	title = {Abstract screening using the automated tool {Rayyan}: results of effectiveness in three diagnostic test accuracy systematic reviews},
	volume = {22},
	issn = {1471-2288},
	shorttitle = {Abstract screening using the automated tool {Rayyan}},
	doi = {10.1186/s12874-022-01631-8},
	abstract = {To evaluate the performance of the automated abstract screening tool Rayyan.},
	language = {en},
	number = {1},
	journal = {BMC Medical Research Methodology},
	author = {Valizadeh, Amir and Moassefi, Mana and Nakhostin-Ansari, Amin and Hosseini Asl, Seyed  Hossein and Saghab Torbati, Mehrnush and Aghajani, Reyhaneh and Maleki Ghorbani, Zahra and Faghani, Shahriar},
	month = jun,
	year = {2022},
	keywords = {Abstract screening, Methodology, Rayyan, Systematic reviews},
	pages = {160},
}

@article{79,
	title = {How to read a paper},
	volume = {37},
	issn = {0146-4833},
	doi = {10.1145/1273445.1273458},
	abstract = {Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-pass method for reading research papers. I also describe how to use this method to do a literature survey.},
	number = {3},
	journal = {SIGCOMM Comput. Commun. Rev.},
	author = {Keshav, S.},
	month = jul,
	year = {2007},
	pages = {83--84},
}

@article{78,
	title = {Guidelines for conducting systematic mapping studies in software engineering: {An} update},
	volume = {64},
	issn = {0950-5849},
	shorttitle = {Guidelines for conducting systematic mapping studies in software engineering},
	doi = {10.1016/j.infsof.2015.03.007},
	abstract = {Context
Systematic mapping studies are used to structure a research area, while systematic reviews are focused on gathering and synthesizing evidence. The most recent guidelines for systematic mapping are from 2008. Since that time, many suggestions have been made of how to improve systematic literature reviews (SLRs). There is a need to evaluate how researchers conduct the process of systematic mapping and identify how the guidelines should be updated based on the lessons learned from the existing systematic maps and SLR guidelines.
Objective
To identify how the systematic mapping process is conducted (including search, study selection, analysis and presentation of data, etc.); to identify improvement potentials in conducting the systematic mapping process and updating the guidelines accordingly.
Method
We conducted a systematic mapping study of systematic maps, considering some practices of systematic review guidelines as well (in particular in relation to defining the search and to conduct a quality assessment).
Results
In a large number of studies multiple guidelines are used and combined, which leads to different ways in conducting mapping studies. The reason for combining guidelines was that they differed in the recommendations given.
Conclusion
The most frequently followed guidelines are not sufficient alone. Hence, there was a need to provide an update of how to conduct systematic mapping studies. New guidelines have been proposed consolidating existing findings.},
	journal = {Information and Software Technology},
	author = {Petersen, Kai and Vakkalanka, Sairam and Kuzniarz, Ludwik},
	month = aug,
	year = {2015},
	keywords = {Guidelines, Software engineering, Systematic mapping studies},
	pages = {1--18},
}

@article{77,
	title = {A {Comprehensive} {Survey} of {Generative} {Adversarial} {Networks} ({GANs}) in {Cybersecurity} {Intrusion} {Detection}},
	volume = {11},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2023.3296707},
	abstract = {Generative Adversarial Networks (GANs) have seen significant interest since their introduction in 2014. While originally focused primarily on image-based tasks, their capacity for generating new, synthetic data has brought them into many different fields of Machine Learning research. Their use in cybersecurity has grown swiftly, especially in tasks which require training on unbalanced datasets of attack classes. In this paper we examine the use of GANs in Intrusion Detection Systems (IDS) and how they are currently being employed in this area of research. GANs are currently in use for the creation of adversarial examples, editing the semantic information of data, creating polymorphic samples of malware, augmenting data for rare classes, and much more. We have endeavored to create a paper that may act as a primer for cybersecurity specialists and machine learning researchers alike. This paper details what GANs are and how they work, the current types of GAN in use in the area, datasets used in this research, metrics for evaluation, current areas of use in intrusion detection, and when and how they are best used.},
	journal = {IEEE Access},
	author = {Dunmore, Aeryn and Jang-Jaccard, Julian and Sabrina, Fariza and Kwak, Jin},
	year = {2023},
	keywords = {Computer security, Data augmentation, Games, Generative adversarial networks, Generative adversarial networks (GAN), Generators, Intrusion detection, Machine learning, Surveys, Training, adversarial examples, attack modeling, data augmentation, intrusion detection systems, machine learning, research survey, threat detection, zero-day attacks},
	pages = {76071--76094},
}

@article{76,
	title = {A {New} {Data}-{Balancing} {Approach} {Based} on {Generative} {Adversarial} {Network} for {Network} {Intrusion} {Detection} {System}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	doi = {10.3390/electronics12132851},
	abstract = {An intrusion detection system (IDS) plays a critical role in maintaining network security by continuously monitoring network traffic and host systems to detect any potential security breaches or suspicious activities. With the recent surge in cyberattacks, there is a growing need for automated and intelligent IDSs. Many of these systems are designed to learn the normal patterns of network traffic, enabling them to identify any deviations from the norm, which can be indicative of anomalous or malicious behavior. Machine learning methods have proven to be effective in detecting malicious payloads in network traffic. However, the increasing volume of data generated by IDSs poses significant security risks and emphasizes the need for stronger network security measures. The performance of traditional machine learning methods heavily relies on the dataset and its balanced distribution. Unfortunately, many IDS datasets suffer from imbalanced class distributions, which hampers the effectiveness of machine learning techniques and leads to missed detection and false alarms in conventional IDSs. To address this challenge, this paper proposes a novel model-based generative adversarial network (GAN) called TDCGAN, which aims to improve the detection rate of the minority class in imbalanced datasets while maintaining efficiency. The TDCGAN model comprises a generator and three discriminators, with an election layer incorporated at the end of the architecture. This allows for the selection of the optimal outcome from the discriminators’ outputs. The UGR’16 dataset is employed for evaluation and benchmarking purposes. Various machine learning algorithms are used for comparison to demonstrate the efficacy of the proposed TDCGAN model. Experimental results reveal that TDCGAN offers an effective solution for addressing imbalanced intrusion detection and outperforms other traditionally used oversampling techniques. By leveraging the power of GANs and incorporating an election layer, TDCGAN demonstrates superior performance in detecting security threats in imbalanced IDS datasets.},
	language = {en},
	number = {13},
	journal = {Electronics},
	author = {Jamoos, Mohammad and Mora, Antonio M. and AlKhanafseh, Mohammad and Surakhi, Ola},
	month = jan,
	year = {2023},
	keywords = {Generative Adversarial Network, Intrusion Detection System, imbalanced dataset, machine learning, unsupervised learning},
	pages = {2851},
}

@inproceedings{74,
	title = {Addressing {Imbalanced} {Data} {Problem} with {Generative} {Adversarial} {Network} {For} {Intrusion} {Detection}},
	doi = {10.1109/IRI49571.2020.00012},
	abstract = {Machine learning techniques help to understand underlying patterns in datasets to develop defense mechanisms against cyber attacks. Multilayer Perceptron (MLP) technique is a machine learning technique used in detecting attack vs. benign data. However, it is difficult to construct any effective model when there are imbalances in the dataset that prevent proper classification of attack samples in data. In this research, we use UGR'16 dataset to conduct data wrangling initially. This technique helps to prepare a test set from the original dataset to train the neural network model effectively. We experimented with a series of inputs of varying sizes (i.e. 10000, 50000, 1 million) to observe the performance of the MLP neural network model with distribution of features over accuracy. Later, we use Generative Adversarial Network (GAN) model that produces samples of different attack labels (e.g. blacklist, anomaly spam, ssh scan) for balancing the dataset. These samples are generated based on data from the UGR'16 dataset. Further experiments with MLP neural network model shows that a balanced attack sample dataset, made possible with GAN, produces more accurate results than an imbalanced one.},
	booktitle = {2020 {IEEE} 21st {International} {Conference} on {Information} {Reuse} and {Integration} for {Data} {Science} ({IRI})},
	author = {Yilmaz, Ibrahim and Masum, Rahat and Siraj, Ambareen},
	month = aug,
	year = {2020},
	keywords = {Adversarial Samples, Data models, Gallium nitride, Generative Adversarial Network (GAN), Generative adversarial networks, Generators, Imbalanced Dataset, Intrusion detection, Network security., Neural Network (NN), Neural networks, Training},
	pages = {25--30},
}

@article{75,
	title = {Synthetic attack data generation model applying generative adversarial network for intrusion detection},
	volume = {125},
	issn = {0167-4048},
	doi = {10.1016/j.cose.2022.103054},
	abstract = {Detecting a large number of attack classes accurately applying machine learning (ML) and deep learning (DL) techniques depends on the number of representative samples available for each attack class. In most cases, the data samples are highly imbalanced that results in a biased intrusion detection model towards the majority classes. Under-sampling, over-sampling and SMOTE are some techniques among the solutions that turn the imbalanced dataset to balanced one. These techniques have not had much impact on the improvement of detection accuracy. To deal with this problem, this paper proposes a Wasserstein Conditional Generative Adversarial Network (WCGAN) combined with an XGBoost Classifier. Gradient penalty along with the WCGAN is used for stable learning of the model. The proposed model is evaluated with some other GAN models (i.e., standard/vanilla GAN, Conditional GAN) which shows the significance of applying WCGAN in this paper. The loss on generated and real data shows a similar pattern and is lower for the Wasserstein variants of GAN compared to the other variants of the GAN model. The performance is benchmarked on three datasets NSL-KDD, UNSW-NB15 and BoT-IoT. The comparison of performance metrics before and after using the proposed framework with XGBoost classifier shows improvement in terms of higher precision, recall and F-1 score. However, comparatively less improvement is observed in FAR compared to other classifiers such as Random Forest (RF), Decision Tree (DT), Support Vector Machine (SVM). The proposed work is also compared with a recent similar technique called DGM, which uses conditional GAN along with different ML classification models. The performance of the proposed model outperforms DGM. The proposed model creates a significant footprint (or, attack signatures) to tackle with the problem of data-imbalance during the design of the Intrusion Detection System (IDS).},
	journal = {Computers \& Security},
	author = {Kumar, Vikash and Sinha, Ditipriya},
	month = feb,
	year = {2023},
	keywords = {Cyber-attack, Data imbalance, Data synthetization, Generative adversarial networks, Intrusion detection system},
	pages = {103054},
}

@article{73,
	title = {Predicting startup success using two bias-free machine learning: resolving data imbalance using generative adversarial networks},
	volume = {11},
	issn = {2196-1115},
	shorttitle = {Predicting startup success using two bias-free machine learning},
	doi = {10.1186/s40537-024-00993-8},
	abstract = {The success of newly established companies holds significant implications for community development and economic growth. However, startups often grapple with heightened vulnerability to market volatility, which can lead to early-stage failures. This study aims to predict startup success by addressing biases in existing predictive models. Previous research has examined external factors such as market dynamics and internal elements like founder characteristics.While such efforts have contributed to understanding success mechanisms, challenges persist, including predictor and learning data biases. This study proposes a novel approach by constructing independent variables using early-stage information, incorporating founder attributes, and mitigating class imbalance through generative adversarial networks (GAN). Our proposed model aims to enhance investment decision-making efficiency and effectiveness, offering a valuable decision support system for various venture capital funds.},
	language = {en},
	number = {1},
	journal = {Journal of Big Data},
	author = {Park, Jungryeol and Choi, Saesol and Feng, Yituo},
	month = sep,
	year = {2024},
	keywords = {Artificial Intelligence, Crunchbase, Generative adversarial networks, Imbalanced data, Predicting startup success, Two bias-free machine learning},
	pages = {122},
}

@article{68,
	title = {Cancer diagnosis using generative adversarial networks based on deep learning from imbalanced data},
	volume = {135},
	issn = {0010-4825},
	doi = {10.1016/j.compbiomed.2021.104540},
	abstract = {Background and objective
Cancer is a serious global disease due to its high mortality, and the key to effective treatment is accurate diagnosis. However, limited by sampling difficulty and actual sample size in clinical practice, data imbalance is a common problem in cancer diagnosis, while most conventional classification methods assume balanced data distribution. Therefore, addressing the imbalanced learning problem to improve the predictive performance of cancer diagnosis is significant.
Methods
In the study, we dissect the data imbalance prevalent in cancer gene expression data and present an improved deep learning based Wasserstein generative adversarial network (WGAN) model, which provides a reliable training progress indicator and deeply explores the characteristics of data. The WGAN generates new samples from the minority class and solves the imbalance problem at the data level.
Results
We analyze three publicly available data sets on RNA-seq of three kinds of cancer using the proposed WGAN and compare the results with those from two commonly adopted sampling methods. According to the results, through addressing the data imbalance problem, the balanced data distribution and the expanding sample size increase the prediction accuracy in all three data sets.
Conclusions
Therefore, the proposed WGAN method is superior in solving the imbalanced learning problem of gene expression data, providing significantly better prediction performance in cancer diagnosis.},
	journal = {Computers in Biology and Medicine},
	author = {Xiao, Yawen and Wu, Jun and Lin, Zongli},
	month = aug,
	year = {2021},
	keywords = {Cancer diagnosis, Deep learning, Gene expression data, Imbalanced data, Wasserstein generative adversarial networks},
	pages = {104540},
}

@article{67,
	title = {Generating synthetic clinical data that capture class imbalanced distributions with generative adversarial networks: {Example} using antiretroviral therapy for {HIV}},
	volume = {144},
	issn = {1532-0464},
	shorttitle = {Generating synthetic clinical data that capture class imbalanced distributions with generative adversarial networks},
	doi = {10.1016/j.jbi.2023.104436},
	abstract = {Objective:
Clinical data’s confidential nature often limits the development of machine learning models in healthcare. Generative adversarial networks (GANs) can synthesise realistic datasets, but suffer from mode collapse, resulting in low diversity and bias towards majority demographics and common clinical practices. This work proposes an extension to the classic GAN framework that includes a variational autoencoder (VAE) and an external memory mechanism to overcome these limitations and generate synthetic data accurately describing imbalanced class distributions commonly found in clinical variables.
Methods:
The proposed method generated a synthetic dataset related to antiretroviral therapy for human immunodeficiency virus (ART for HIV). We evaluated it based on five metrics: (1) accurately representing imbalanced class distribution; (2) the realism of the individual variables; (3) the realism among variables; (4) patient disclosure risk; and (5) the utility of the generated dataset for developing downstream machine learning models.
Results:
The proposed method overcomes the issue of mode collapse and generates a synthetic dataset that accurately describes imbalanced class distributions commonly found in clinical variables. The generated data has a patient disclosure risk of 0.095\%, lower than the 9\% threshold stated by Health Canada and the European Medicines Agency, making it suitable for distribution to the research community with high security. The generated data also has high utility, indicating the potential of the proposed method to enable the development of downstream machine learning algorithms for healthcare applications using synthetic data.
Conclusion:
Our proposed extension to the classic GAN framework, which includes a VAE and an external memory mechanism, represents a promising approach towards generating synthetic data that accurately describe imbalanced class distributions commonly found in clinical variables. This method overcomes the limitations of GANs and creates more realistic datasets with higher patient cohort diversity, facilitating the development of downstream machine learning algorithms for healthcare applications.},
	journal = {Journal of Biomedical Informatics},
	author = {Kuo, Nicholas I-Hsien and Garcia, Federico and Sönnerborg, Anders and Böhm, Michael and Kaiser, Rolf and Zazzi, Maurizio and Polizzotto, Mark and Jorm, Louisa and Barbieri, Sebastiano},
	month = aug,
	year = {2023},
	keywords = {Generative adversarial networks, Human immunodeficiency virus, Machine learning},
	pages = {104436},
}

@article{66,
	title = {A {Systematic} {Review} on {Generative} {Adversarial} {Network} ({GAN}): {Challenges} and {Future} {Directions}},
	volume = {31},
	issn = {1886-1784},
	shorttitle = {A {Systematic} {Review} on {Generative} {Adversarial} {Network} ({GAN})},
	doi = {10.1007/s11831-024-10119-1},
	abstract = {Generative adversarial network, in short GAN, is a new convolution neural network (CNN) based framework with the great potential to determine high dimensional data from its feedback. It is a generative model built using two CNN blocks named generator and discriminator. GAN is a recent and trending innovation in CNN with evident progress in applications like computer vision, cyber security, medical and many more. This paper presents a complete overview of GAN with its structure, variants, application and current existing work. Our primary focus is to review the growth of GAN in the computer vision domain, specifically on image enhancement techniques. In this paper, the review is carried out in a funnel approach, starting with a broad view of GAN in all domains and then narrowing down to GAN in computer vision and, finally, GAN in image enhancement. Since GAN has cleverly acquired its position in various disciplines, we are showing a comparative analysis of GAN v/s ML v/s MATLAB computer vision methods concerning image enhancement techniques in existing work. The primary objective of the paper is to showcase the systematic literature survey and execute a comparative analysis of GAN with various existing research works in different domains and understand how GAN is a better approach compared to existing models using PRISMA guidelines. In this paper, we have also studied the current GAN model for image enhancement techniques and compared it with other methods concerning PSNR and SSIM.},
	language = {en},
	number = {8},
	journal = {Archives of Computational Methods in Engineering},
	author = {Nayak, Ankitha A. and Venugopala, P. S. and Ashwini, B.},
	month = dec,
	year = {2024},
	keywords = {Artificial Intelligence},
	pages = {4739--4772},
}

@article{64,
	title = {The use of generative adversarial networks to alleviate class imbalance in tabular data: a survey},
	volume = {9},
	issn = {2196-1115},
	shorttitle = {The use of generative adversarial networks to alleviate class imbalance in tabular data},
	doi = {10.1186/s40537-022-00648-6},
	abstract = {The existence of class imbalance in a dataset can greatly bias the classifier towards majority classification. This discrepancy can pose a serious problem for deep learning models, which require copious and diverse amounts of data to learn patterns and output classifications. Traditionally, data-level and algorithm-level techniques have been instrumental in mitigating the adverse effect of class imbalance. With the recent development and proliferation of Generative Adversarial Networks (GANs), researchers across a variety of disciplines have adapted the architecture of GANs and implemented them on imbalanced datasets to generate instances of the underrepresented class(es). Though the bulk of research has been centered on the application of this methodology in computer vision tasks, GANs are likewise being appropriated for use in tabular data, or data consisting of rows and columns with traditional structured data types. In this survey paper, we assess the methodology and efficacy of these modifications on tabular datasets, across domains such network traffic classification and financial transactions over the past seven years. We examine what methodologies and experimental factors have resulted in the greatest machine learning efficacy, as well as the research works and frameworks which have proven most influential in the development of the application of GANs in tabular data settings. Specifically, we note the prevalence of the CGAN architecture, the optimality of novel methods with CNN learners and minority-class sensitive measures such as F1 score, the popularity of SMOTE as a baseline technique, and the improved performance in the year-over-year use of GANs in imbalanced tabular datasets.},
	number = {1},
	journal = {Journal of Big Data},
	author = {Sauber-Cole, Rick and Khoshgoftaar, Taghi M.},
	month = aug,
	year = {2022},
	keywords = {Class imbalance, Deep learning, Generative adversarial networks, Tabular data},
	pages = {98},
}

@article{63,
	title = {A survey on generative adversarial networks for imbalance problems in computer vision tasks},
	volume = {8},
	issn = {2196-1115},
	doi = {10.1186/s40537-021-00414-0},
	abstract = {Any computer vision application development starts off by acquiring images and data, then preprocessing and pattern recognition steps to perform a task. When the acquired images are highly imbalanced and not adequate, the desired task may not be achievable. Unfortunately, the occurrence of imbalance problems in acquired image datasets in certain complex real-world problems such as anomaly detection, emotion recognition, medical image analysis, fraud detection, metallic surface defect detection, disaster prediction, etc., are inevitable. The performance of computer vision algorithms can significantly deteriorate when the training dataset is imbalanced. In recent years, Generative Adversarial Neural Networks (GANs) have gained immense attention by researchers across a variety of application domains due to their capability to model complex real-world image data. It is particularly important that GANs can not only be used to generate synthetic images, but also its fascinating adversarial learning idea showed good potential in restoring balance in imbalanced datasets.},
	number = {1},
	journal = {Journal of Big Data},
	author = {Sampath, Vignesh and Maurtua, Iñaki and Aguilar Martín, Juan José and Gutierrez, Aitor},
	month = jan,
	year = {2021},
	keywords = {Classification, Deep generative model, Deep learning, Generative adversarial neural networks, Imbalanced data, Object detection, Segmentation},
	pages = {27},
}

@misc{62,
	title = {A {State}-of-the-{Art} {Review} on {Image} {Synthesis} {With} {Generative} {Adversarial} {Networks} {\textbar} {IEEE} {Journals} \& {Magazine} {\textbar} {IEEE} {Xplore}},
	url = {https://doi.org/10.1109/ACCESS.2020.2982224},
	author = {Wang, Lei and Chen, Wei and Yang, Wenjia and Bi, Fangming and Richard Yu, Fei},
}

@article{61,
	title = {A {Survey} on {Generative} {Adversarial} {Networks}: {Variants}, {Applications}, and {Training}},
	volume = {54},
	issn = {0360-0300},
	shorttitle = {A {Survey} on {Generative} {Adversarial} {Networks}},
	doi = {10.1145/3463475},
	abstract = {The Generative Models have gained considerable attention in unsupervised learning via a new and practical framework called Generative Adversarial Networks (GAN) due to their outstanding data generation capability. Many GAN models have been proposed, and several practical applications have emerged in various domains of computer vision and machine learning. Despite GANs excellent success, there are still obstacles to stable training. The problems are Nash equilibrium, internal covariate shift, mode collapse, vanishing gradient, and lack of proper evaluation metrics. Therefore, stable training is a crucial issue in different applications for the success of GANs. Herein, we survey several training solutions proposed by different researchers to stabilize GAN training. We discuss (I) the original GAN model and its modified versions, (II) a detailed analysis of various GAN applications in different domains, and (III) a detailed study about the various GAN training obstacles as well as training solutions. Finally, we reveal several issues as well as research outlines to the topic.},
	number = {8},
	journal = {ACM Comput. Surv.},
	author = {Jabbar, Abdul and Li, Xi and Omar, Bourahla},
	month = oct,
	year = {2021},
	pages = {157:1--157:49},
}

@article{60,
	title = {How {Generative} {Adversarial} {Networks} and {Their} {Variants} {Work}: {An} {Overview}},
	volume = {52},
	issn = {0360-0300},
	shorttitle = {How {Generative} {Adversarial} {Networks} and {Their} {Variants} {Work}},
	doi = {10.1145/3301282},
	abstract = {Generative Adversarial Networks (GANs) have received wide attention in the machine learning field for their potential to learn high-dimensional, complex real data distribution. Specifically, they do not rely on any assumptions about the distribution and can generate real-like samples from latent space in a simple manner. This powerful property allows GANs to be applied to various applications such as image synthesis, image attribute editing, image translation, domain adaptation, and other academic fields. In this article, we discuss the details of GANs for those readers who are familiar with, but do not comprehend GANs deeply or who wish to view GANs from various perspectives. In addition, we explain how GANs operates and the fundamental meaning of various objective functions that have been suggested recently. We then focus on how the GAN can be combined with an autoencoder framework. Finally, we enumerate the GAN variants that are applied to various tasks and other fields for those who are interested in exploiting GANs for their research.},
	number = {1},
	journal = {ACM Comput. Surv.},
	author = {Hong, Yongjun and Hwang, Uiwon and Yoo, Jaeyoon and Yoon, Sungroh},
	month = feb,
	year = {2019},
	pages = {10:1--10:43},
}

@article{59,
	title = {Generative {Adversarial} {Networks} in the built environment: {A} comprehensive review of the application of {GANs} across data types and scales},
	volume = {223},
	issn = {0360-1323},
	shorttitle = {Generative {Adversarial} {Networks} in the built environment},
	doi = {10.1016/j.buildenv.2022.109477},
	abstract = {Generative Adversarial Networks (GANs) are a type of deep neural network that have achieved many state-of-the-art results for generative tasks. GANs can be useful in the built environment, from processing large-scale urban mobility data and remote sensing images at the regional level, to performance analysis and design generation at the building level. We analyzed 100 articles to provide a comprehensive state-of-the-art review on how GANs are currently applied to solve challenging tasks in the built environment. Our results show that: (i) GANs are replacing older methods in some problems and setting state-of-the-art performances; (ii) GANs are opening new frontiers in previously overlooked problems, such as automatically generating spatially accurate floorplan layouts; (iii) GANs can be applied to different scales in the built environment, from entire cities to neighborhoods and buildings; and (iv) GANs are being used in a variety of problems and data types, from remote sensing data augmentation, vector data generation, spatio-temporal data privacy protection, to building design generation. In total, there are 26 unique application domains enabled by GANs; (v) however, one common challenge in this field currently is the lack of high-quality datasets curated specifically for problems in the built environment. With more data in the future, GANs could potentially produce even better results than today.},
	journal = {Building and Environment},
	author = {Wu, Abraham Noah and Stouffs, Rudi and Biljecki, Filip},
	month = sep,
	year = {2022},
	keywords = {Generative design, GeoAI, Machine learning, Urban AI, Urban planning},
	pages = {109477},
}

@article{58,
	title = {Generic image application using {GANs} ({Generative} {Adversarial} {Networks}): {A} {Review}},
	volume = {14},
	issn = {1868-6486},
	shorttitle = {Generic image application using {GANs} ({Generative} {Adversarial} {Networks})},
	doi = {10.1007/s12530-022-09464-y},
	abstract = {The generative adversarial network (GAN), which has received considerable notice for its outstanding data generating abilities, is one of the most intriguing fields of artificial intelligence study. Large volumes of data are required to develop generalizable deep learning models. GANs are a highly strong class of networks capable of producing believable new pictures from unlabeled source prints and labeled medical imaging data is scarce and costly to produce. Despite GAN’s remarkable outcomes, steady training remains a challenge. The goal of this study is to perform a complete evaluation of the GAN-related literature and to present a succinct summary of existing knowledge on GAN, including the theory following it, its intended purpose, potential base model alterations, and latest breakthroughs in the area. This article will aid you in gaining a comprehensive grasp of GAN and provide an overview of GAN and its many model types, as well as common implementations, measurement parameter suggestions, and GAN applications in image processing. It will also go over the several applications of GANs in image processing, as well as their benefits and limitations, as well as its prospective reach.},
	language = {en},
	number = {5},
	journal = {Evolving Systems},
	author = {Porkodi, S. P. and Sarada, V. and Maik, Vivek and Gurushankar, K.},
	month = oct,
	year = {2023},
	keywords = {Artificial Intelligence, Artificial intelligence, Generative adversarial networks, Image processing, Neural network, Semi-supervised learning, Supervised learning},
	pages = {903--917},
}

@article{57,
	title = {Generative adversarial networks: a survey on applications and challenges},
	volume = {10},
	issn = {2192-662X},
	shorttitle = {Generative adversarial networks},
	doi = {10.1007/s13735-020-00196-w},
	abstract = {Deep neural networks have attained great success in handling high dimensional data, especially images. However, generating naturalistic images containing ginormous subjects for different tasks like image classification, segmentation, object detection, reconstruction, etc., is continued to be a difficult task. Generative modelling has the potential to learn any kind of data distribution in an unsupervised manner. Variational autoencoder (VAE), autoregressive models, and generative adversarial network (GAN) are the popular generative modelling approaches that generate data distributions. Among these, GANs have gained much attention from the research community in recent years in terms of generating quality images and data augmentation. In this context, we collected research articles that employed GANs for solving various tasks from popular databases and summarized them based on their application. The main objective of this article is to present the nuts and bolts of GANs, state-of-the-art related work and its applications, evaluation metrics, challenges involved in training GANs, and benchmark datasets that would benefit naive and enthusiastic researchers who are interested in working on GANs.},
	language = {en},
	number = {1},
	journal = {International Journal of Multimedia Information Retrieval},
	author = {Pavan Kumar, M. R. and Jayagopal, Prabhu},
	month = mar,
	year = {2021},
	keywords = {Artificial Intelligence, Convolutional neural network, Generative adversarial network, Generative model, Object detection, segmentation},
	pages = {1--24},
}

@article{56,
	title = {Systematic {Review} of {Generative} {Adversarial} {Networks} ({GANs}) for {Medical} {Image} {Classification} and {Segmentation}},
	volume = {35},
	issn = {1618-727X},
	doi = {10.1007/s10278-021-00556-w},
	abstract = {In recent years, generative adversarial networks (GANs) have gained tremendous popularity for various imaging related tasks such as artificial image generation to support AI training. GANs are especially useful for medical imaging–related tasks where training datasets are usually limited in size and heavily imbalanced against the diseased class. We present a systematic review, following the PRISMA guidelines, of recent GAN architectures used for medical image analysis to help the readers in making an informed decision before employing GANs in developing medical image classification and segmentation models. We have extracted 54 papers that highlight the capabilities and application of GANs in medical imaging from January 2015 to August 2020 and inclusion criteria for meta-analysis. Our results show four main architectures of GAN that are used for segmentation or classification in medical imaging. We provide a comprehensive overview of recent trends in the application of GANs in clinical diagnosis through medical image segmentation and classification and ultimately share experiences for task-based GAN implementations.},
	language = {en},
	number = {2},
	journal = {Journal of Digital Imaging},
	author = {Jeong, Jiwoong J. and Tariq, Amara and Adejumo, Tobiloba and Trivedi, Hari and Gichoya, Judy W. and Banerjee, Imon},
	month = apr,
	year = {2022},
	keywords = {Generative adversarial networks, Image classification, Image generation, Image segmentation, Medical Imaging, Medical imaging},
	pages = {137--152},
}

@article{53,
	title = {Generative adversarial networks in electrocardiogram synthesis: {Recent} developments and challenges},
	volume = {143},
	issn = {0933-3657},
	shorttitle = {Generative adversarial networks in electrocardiogram synthesis},
	url = {https://www.sciencedirect.com/science/article/pii/S093336572300146X},
	doi = {10.1016/j.artmed.2023.102632},
	abstract = {Training deep neural network classifiers for electrocardiograms (ECGs) requires sufficient data. However, imbalanced datasets pose a major problem for the training process and hence data augmentation is commonly performed. Generative adversarial networks (GANs) can create synthetic ECG data to augment such imbalanced datasets. This review aims at identifying the present literature concerning synthetic ECG signal generation using GANs to provide a comprehensive overview of architectures, quality evaluation metrics, and classification performances. Thirty publications from the years 2019 to 2022 were selected from three separate databases. Nine publications used a quality evaluation metric neglecting classification, eleven performed a classification but omitted a quality evaluation metric, and ten publications performed both. Twenty different quality evaluation metrics were observed. Overall, the classification performance of databases augmented with synthetically created ECG signals increased by 7 \% to 98 \% in accuracy and 6 \% to 97 \% in sensitivity. In conclusion, synthetic ECG signal generation using GANs represents a promising tool for data augmentation of imbalanced datasets. Consistent quality evaluation of generated signals remains challenging. Hence, future work should focus on the establishment of a gold standard for quality evaluation metrics for GANs.},
	journal = {Artificial Intelligence in Medicine},
	author = {Berger, Laurenz and Haberbusch, Max and Moscato, Francesco},
	month = sep,
	year = {2023},
	keywords = {Artificial intelligence, Data augmentation, Deep learning, Electrocardiogram, Generative adversarial networks},
	pages = {102632},
}

@article{52,
	title = {Review of imbalanced fault diagnosis technology based on generative adversarial networks},
	volume = {11},
	issn = {2288-5048},
	url = {https://doi.org/10.1093/jcde/qwae075},
	doi = {10.1093/jcde/qwae075},
	abstract = {In the field of industrial production, machine failures not only negatively affect productivity and product quality, but also lead to safety accidents, so it is crucial to accurately diagnose machine failures in time and take appropriate measures. However, machines cannot operate with faults for extended periods, and the diversity of fault modes results in limited data collection, posing challenges to building accurate fault prediction models. Despite recent advancements, intelligent fault diagnosis methods based on traditional sampling and machine learning have shown notable progress. Nonetheless, these methods heavily rely on human expertise, making it challenging to extract comprehensive feature information. To address these challenges, numerous imbalance fault diagnosis methods based on generative adversarial networks (GANs) have emerged, GANs can generate realistic samples that conform to the distribution of the original data, showing promising results in diagnosing imbalances in critical components such as bearings and gears, despite their great potential, GAN methods also face challenges, including difficulties in training and generating abnormal samples. However, whether it is GAN-based resampling technology or traditional sampling technology, there are fewer reviews on noise-containing imbalance, intra- and inter-class dual imbalance, multi-class imbalance, time series imbalance and other problems in small samples, and there is a lack of a more comprehensive summary of the solutions to the above imbalance problems. Therefore, the purpose of this paper is to deeply explore the imbalance problems under various failure modes, and review and analyze the research methods and results based on GANs on this basis. By suggesting future research directions, this paper aims to provide guidance and reference for research in the field of industrial production maintenance.},
	number = {5},
	journal = {Journal of Computational Design and Engineering},
	author = {Chen, Hualin and Wei, Jianan and Huang, Haisong and Yuan, Yage and Wang, Jiaxin},
	month = oct,
	year = {2024},
	pages = {99--124},
}

@article{50,
	title = {{DDcGAN}: {A} {Dual}-{Discriminator} {Conditional} {Generative} {Adversarial} {Network} for {Multi}-{Resolution} {Image} {Fusion}},
	volume = {29},
	issn = {1941-0042},
	shorttitle = {{DDcGAN}},
	doi = {10.1109/TIP.2020.2977573},
	abstract = {In this paper, we proposed a new end-to-end model, termed as dual-discriminator conditional generative adversarial network (DDcGAN), for fusing infrared and visible images of different resolutions. Our method establishes an adversarial game between a generator and two discriminators. The generator aims to generate a real-like fused image based on a specifically designed content loss to fool the two discriminators, while the two discriminators aim to distinguish the structure differences between the fused image and two source images, respectively, in addition to the content loss. Consequently, the fused image is forced to simultaneously keep the thermal radiation in the infrared image and the texture details in the visible image. Moreover, to fuse source images of different resolutions, e.g., a low-resolution infrared image and a high-resolution visible image, our DDcGAN constrains the downsampled fused image to have similar property with the infrared image. This can avoid causing thermal radiation information blurring or visible texture detail loss, which typically happens in traditional methods. In addition, we also apply our DDcGAN to fusing multi-modality medical images of different resolutions, e.g., a low-resolution positron emission tomography image and a high-resolution magnetic resonance image. The qualitative and quantitative experiments on publicly available datasets demonstrate the superiority of our DDcGAN over the state-of-the-art, in terms of both visual effect and quantitative metrics. Our code is publicly available at https://github.com/jiayi-ma/DDcGAN.},
	journal = {IEEE Transactions on Image Processing},
	author = {Ma, Jiayi and Xu, Han and Jiang, Junjun and Mei, Xiaoguang and Zhang, Xiao-Ping},
	year = {2020},
	keywords = {Biomedical imaging, Deep learning, Feature extraction, Generators, Image fusion, Image resolution, Thermal sensors, different resolutions, generative adversarial network, infrared image, medical image},
	pages = {4980--4995},
}

@article{51,
	title = {Sequence generative adversarial nets with a conditional discriminator},
	volume = {429},
	issn = {0925-2312},
	doi = {10.1016/j.neucom.2020.10.108},
	abstract = {The success of Generative Adversarial Networks (GANs) in image generation attracts researchers to design sequence GANs in text generation. However, the discriminators of those sequence GANs usually provide only one signal per sequence, which can not reflect detailed information, e.g. whether a token is appropriate in a sequence. In addition, maximum likelihood pre-training is typically used in those models, which is time-consuming and obscures the effects of adversarial training. To cope with these problems, we propose a new sequence GAN that consists of a conditional discriminator and a discriminator-augmented generator. The conditional discriminator provides a sequence with token-level signals. The generator is designed to approximate a discriminator-augmented distribution, which avoids pre-training. Experiments show that the conditional discriminator provides more informative guidance, and our model outperforms existing models according to metrics involving both sampling quality and sampling diversity.},
	journal = {Neurocomputing},
	author = {Yan, Yongfei and Shen, Gehui and Zhang, Song and Huang, Ting and Deng, Zhi-Hong and Yun, Unil},
	month = mar,
	year = {2021},
	keywords = {Adversarial neural networks, Algorithm, Deep learning, Natural language processing, Text generation},
	pages = {69--76},
}

@inproceedings{48,
	title = {A {U}-{Net} {Based} {Discriminator} for {Generative} {Adversarial} {Networks}},
	url = {https://openaccess.thecvf.com/content_CVPR_2020/html/Schonfeld_A_U-Net_Based_Discriminator_for_Generative_Adversarial_Networks_CVPR_2020_paper.html},
	author = {Schonfeld, Edgar and Schiele, Bernt and Khoreva, Anna},
	year = {2020},
	pages = {8207--8216},
}

@inproceedings{47,
	title = {Dual {Discriminator} {Generative} {Adversarial} {Nets}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/e60e81c4cbe5171cd654662d9887aec2-Abstract.html},
	abstract = {We propose in this paper a novel approach to tackle the problem of mode collapse encountered in generative adversarial network (GAN). Our idea is intuitive but proven to be very effective, especially in addressing some key limitations of GAN. In essence, it combines the Kullback-Leibler (KL) and reverse KL divergences into a unified objective function, thus it exploits the complementary statistical properties from these divergences to effectively diversify the estimated density in capturing multi-modes. We term our method dual discriminator generative adversarial nets (D2GAN) which, unlike GAN, has two discriminators; and together with a generator, it also has the analogy of a minimax game, wherein a discriminator rewards high scores for samples from data distribution whilst another discriminator, conversely, favoring data from the generator, and the generator produces data to fool both two discriminators. We develop theoretical analysis to show that, given the maximal discriminators, optimizing the generator of D2GAN reduces to minimizing both KL and reverse KL divergences between data distribution and the distribution induced from the data generated by the generator, hence effectively avoiding the mode collapsing problem. We conduct extensive experiments on synthetic and real-world large-scale datasets (MNIST, CIFAR-10, STL-10, ImageNet), where we have made our best effort to compare our D2GAN with the latest state-of-the-art GAN's variants in comprehensive qualitative and quantitative evaluations. The experimental results demonstrate the competitive and superior performance of our approach in generating good quality and diverse samples over baselines, and the capability of our method to scale up to ImageNet database.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Nguyen, Tu and Le, Trung and Vu, Hung and Phung, Dinh},
	year = {2017},
}

@inproceedings{44,
	title = {{StoryGAN}: {A} {Sequential} {Conditional} {GAN} for {Story} {Visualization}},
	shorttitle = {{StoryGAN}},
	url = {https://openaccess.thecvf.com/content_CVPR_2019/html/Li_StoryGAN_A_Sequential_Conditional_GAN_for_Story_Visualization_CVPR_2019_paper.html},
	author = {Li, Yitong and Gan, Zhe and Shen, Yelong and Liu, Jingjing and Cheng, Yu and Wu, Yuexin and Carin, Lawrence and Carlson, David and Gao, Jianfeng},
	year = {2019},
	pages = {6329--6338},
}

@inproceedings{43,
	title = {Least {Squares} {Generative} {Adversarial} {Networks}},
	url = {https://openaccess.thecvf.com/content_iccv_2017/html/Mao_Least_Squares_Generative_ICCV_2017_paper.html},
	author = {Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond Y. K. and Wang, Zhen and Paul Smolley, Stephen},
	year = {2017},
	pages = {2794--2802},
}

@inproceedings{41,
	address = {New York, NY, USA},
	series = {{GECCO} '24},
	title = {Multi-objective evolutionary {GAN} for tabular data synthesis},
	isbn = {9798400704949},
	doi = {10.1145/3638529.3654052},
	abstract = {Synthetic data has a key role to play in data sharing by statistical agencies and other generators of statistical data products. Generative Adversarial Networks (GANs), typically applied to image synthesis, are also a promising method for tabular data synthesis. However, there are unique challenges in tabular data compared to images, eg tabular data may contain both continuous and discrete variables and conditional sampling, and, critically, the data should possess high utility and low disclosure risk (the risk of re-identifying a population unit or learning something new about them), providing an opportunity for multi-objective (MO) optimization. Inspired by MO GANs for images, this paper proposes a smart MO evolutionary conditional tabular GAN (SMOE-CTGAN). This approach models conditional synthetic data by applying conditional vectors in training, and uses concepts from MO optimisation to balance disclosure risk against utility. Our results indicate that SMOE-CTGAN is able to discover synthetic datasets with different risk and utility levels for multiple national census datasets. We also find a sweet spot in the early stage of training where a competitive utility and extremely low risk are achieved, by using an Improvement Score. The full code can be downloaded from github1.},
	booktitle = {Proceedings of the {Genetic} and {Evolutionary} {Computation} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Ran, Nian and Nasution, Bahrul and Little, Claire and Allmendinger, Richard and Elliot, Mark},
	month = jul,
	year = {2024},
	pages = {394--402},
}

@article{40,
	title = {Conditional {Wasserstein} {GAN}-based oversampling of tabular data for imbalanced learning},
	volume = {174},
	issn = {0957-4174},
	doi = {10.1016/j.eswa.2021.114582},
	abstract = {Class imbalance impedes the predictive performance of classification models. Popular countermeasures include oversampling minority class cases by creating synthetic examples. The paper examines the potential of Generative Adversarial Networks (GANs) for oversampling. A few prior studies have used GANs for this purpose but do not reflect recent methodological advancements for generating tabular data using GANs. The paper proposes an approach based on a conditional Wasserstein GAN that can effectively model tabular datasets with numerical and categorical variables and pays special attention to the down-stream classification task through an auxiliary classifier loss. We focus on a credit scoring context in which binary classifiers predict the default risk of loan applications. Empirical comparisons in this context evidence the competitiveness of GAN-based oversampling compared to several standard oversampling regimes. We also clarify the conditions under which oversampling in general and the proposed GAN-based approach in particular raise predictive performance. In sum, our findings suggest that GAN architectures for tabular data and our extensions deserve a place in data scientists’ modelling toolbox.},
	journal = {Expert Systems with Applications},
	author = {Engelmann, Justin and Lessmann, Stefan},
	month = jul,
	year = {2021},
	keywords = {Credit scoring, Generative adversarial networks, Imbalanced learning, Oversampling},
	pages = {114582},
}

@inproceedings{38,
	title = {Modeling {Tabular} data using {Conditional} {GAN}},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper/2019/hash/254ed7d2de3b23ab10936522dd547b78-Abstract.html},
	abstract = {Modeling the probability distribution of rows in tabular data and generating realistic synthetic data is a non-trivial task. Tabular data usually contains a mix of discrete and continuous columns. Continuous columns may have multiple modes whereas discrete columns are sometimes imbalanced making the modeling difficult. Existing statistical and deep neural network models fail to properly model this type of data. We design CTGAN, which uses a conditional generative adversarial network to address these challenges. To aid in a fair and thorough comparison, we design a benchmark with 7 simulated and 8 real datasets and several Bayesian network baselines. CTGAN outperforms Bayesian methods on most of the real datasets whereas other deep learning methods could not.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Xu, Lei and Skoularidou, Maria and Cuesta-Infante, Alfredo and Veeramachaneni, Kalyan},
	year = {2019},
}

@inproceedings{37,
	address = {New York, NY, USA},
	series = {{AIES} '18},
	title = {Mitigating {Unwanted} {Biases} with {Adversarial} {Learning}},
	isbn = {978-1-4503-6012-8},
	doi = {10.1145/3278721.3278779},
	abstract = {Machine learning is a tool for building models that accurately represent input training data. When undesired biases concerning demographic groups are in the training data, well-trained models will reflect those biases. We present a framework for mitigating such biases by including a variable for the group of interest and simultaneously learning a predictor and an adversary. The input to the network X, here text or census data, produces a prediction Y, such as an analogy completion or income bracket, while the adversary tries to model a protected variable Z, here gender or zip code. The objective is to maximize the predictor's ability to predict Y while minimizing the adversary's ability to predict Z. Applied to analogy completion, this method results in accurate predictions that exhibit less evidence of stereotyping Z. When applied to a classification task using the UCI Adult (Census) Dataset, it results in a predictive model that does not lose much accuracy while achieving very close to equality of odds (Hardt, et al., 2016). The method is flexible and applicable to multiple definitions of fairness as well as a wide range of gradient-based learning models, including both regression and classification tasks.},
	booktitle = {Proceedings of the 2018 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Brian Hu and Lemoine, Blake and Mitchell, Margaret},
	month = dec,
	year = {2018},
	pages = {335--340},
}

@article{34,
	title = {Adversarial {Algorithm} {Unrolling} {Network} for {Interpretable} {Mechanical} {Anomaly} {Detection}},
	volume = {35},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2023.3250664},
	abstract = {In mechanical anomaly detection, algorithms with higher accuracy, such as those based on artificial neural networks, are frequently constructed as black boxes, resulting in opaque interpretability in architecture and low credibility in results. This article proposes an adversarial algorithm unrolling network (AAU-Net) for interpretable mechanical anomaly detection. AAU-Net is a generative adversarial network (GAN). Its generator, composed of an encoder and a decoder, is mainly produced by algorithm unrolling of a sparse coding model, which is specially designed for feature encoding and decoding of vibration signals. Thus, AAU-Net has a mechanism-driven and interpretable network architecture. In other words, it is ad hoc interpretable. Moreover, a multiscale feature visualization approach for AAU-Net is introduced to verify that meaningful features are encoded by AAU-Net, helping users to trust the detection results. The feature visualization approach enables the results of AAU-Net to be interpretable, i.e., post hoc interpretable. To verify AAU-Net’s capability of feature encoding and anomaly detection, we designed and performed simulations and experiments. The results show that AAU-Net can learn signal features that match the dynamic mechanism of the mechanical system. Considering the excellent feature learning ability, unsurprisingly, AAU-Net achieves the best overall anomaly detection performance compared with other algorithms.},
	number = {5},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {An, Botao and Wang, Shibin and Qin, Fuhua and Zhao, Zhibin and Yan, Ruqiang and Chen, Xuefeng},
	month = may,
	year = {2024},
	keywords = {Adversarial training, Anomaly detection, Codes, Decoding, Encoding, Feature extraction, Training, Vibrations, algorithm unrolling, anomaly detection, interpretable neural network, representation learning},
	pages = {6007--6020},
}

@article{33,
	title = {A {Review} on {Generative} {Adversarial} {Networks}: {Algorithms}, {Theory}, and {Applications}},
	volume = {35},
	issn = {1558-2191},
	shorttitle = {A {Review} on {Generative} {Adversarial} {Networks}},
	doi = {10.1109/TKDE.2021.3130191},
	abstract = {Generative adversarial networks (GANs) have recently become a hot research topic; however, they have been studied since 2014, and a large number of algorithms have been proposed. Nevertheless, few comprehensive studies explain the connections among different GAN variants and how they have evolved. In this paper, we attempt to provide a review of the various GAN methods from the perspectives of algorithms, theory, and applications. First, the motivations, mathematical representations, and structures of most GAN algorithms are introduced in detail, and we compare their commonalities and differences. Second, theoretical issues related to GANs are investigated. Finally, typical applications of GANs in image processing and computer vision, natural language processing, music, speech and audio, the medical field, and data science are discussed.},
	number = {4},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Gui, Jie and Sun, Zhenan and Wen, Yonggang and Tao, Dacheng and Ye, Jieping},
	month = apr,
	year = {2023},
	keywords = {Data models, Deep learning, Generative adversarial networks, Generators, Inference algorithms, Linear programming, Machine learning algorithms, Natural language processing, algorithm, applications, generative adversarial networks, theory},
	pages = {3313--3332},
}

@article{32,
	title = {Generative adversarial network: {An} overview of theory and applications},
	volume = {1},
	issn = {2667-0968},
	shorttitle = {Generative adversarial network},
	doi = {10.1016/j.jjimei.2020.100004},
	abstract = {In recent times, image segmentation has been involving everywhere including disease diagnosis to autonomous vehicle driving. In computer vision, this image segmentation is one of the vital works and it is relatively complicated than other vision undertakings as it needs low-level spatial data. Especially, Deep Learning has impacted the field of segmentation incredibly and gave us today different successful models. The deep learning associated Generated Adversarial Networks (GAN) has presenting remarkable outcomes on image segmentation. In this study, the authors have presented a systematic review analysis on recent publications of GAN models and their applications. Three libraries such as Embase (Scopus), WoS, and PubMed have been considered for searching the relevant papers available in this area. Search outcomes have identified 2084 documents, after two-phase screening 52 potential records are included for final review. The following applications of GAN have been emerged: 3D object generation, medicine, pandemics, image processing, face detection, texture transfer, and traffic controlling. Before 2016, research in this field was limited and thereafter its practical usage came into existence worldwide. The present study also envisions the challenges associated with GAN and paves the path for future research in this realm.},
	number = {1},
	journal = {International Journal of Information Management Data Insights},
	author = {Aggarwal, Alankrita and Mittal, Mamta and Battineni, Gopi},
	month = apr,
	year = {2021},
	keywords = {Big data, Deep learning, GAN, Image mining, Literature review, Neural networks},
	pages = {100004},
}

@article{27,
	title = {Entropy-based hybrid sampling ensemble learning for imbalanced data},
	volume = {36},
	copyright = {© 2021 Wiley Periodicals LLC},
	issn = {1098-111X},
	doi = {10.1002/int.22388},
	abstract = {Sampling method is one of the most commonly used techniques in dealing with imbalanced data. Most of the existing undersampling methods randomly select samples from negative class with replacement. However, it may lose some important information of the training data. Moreover, increasing the positive data by oversampling in high imbalanced situations may cause the overlapping problem. To overcome these problems, this paper proposes a hybrid sampling method. The method takes the distributions of the training data into consideration by the information entropy, thus distinguishing the important samples in the undersampling procedure. Meanwhile, since the positive data only extend to the size of each subset of the negative class in the oversampling, the overlapping problem is relieved. Further, the method retains all the data in the training procedure and generates various data views from the original training data. Then each view is handled with an individual basic classifier. Finally, all the basic classifiers are combined by the ensemble method. The newly proposed method is named as Entropy-based Hybrid Sampling Ensemble Learning (EHSEL). In addition, the EHSEL is applied to three different kinds of basic classifiers to validate its robustness. Experiments results show the great effectiveness of the EHSEL on real-world imbalanced data sets.},
	language = {en},
	number = {7},
	journal = {International Journal of Intelligent Systems},
	author = {Dongdong, Li and Ziqiu, Chi and Bolu, Wang and Zhe, Wang and Hai, Yang and Wenli, Du},
	year = {2021},
	keywords = {ensemble, hybrid sampling, imbalanced data, information entropy, pattern recognition},
	pages = {3039--3067},
}

@article{26,
	title = {The {Distance}-{Based} {Balancing} {Ensemble} {Method} for {Data} {With} a {High} {Imbalance} {Ratio}},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2917920},
	abstract = {Many classification tasks suffer from the class imbalance problem that seriously hinders the precision of classifiers. The existing algorithms frequently incorrectly categorize new instances into the majority class. The ensemble learning is an effective method to address the imbalance problem, as is the Splitting Balancing Ensemble (SBE) method that learns the unbalanced dataset by converting it into multiple balanced subsets on which sub-classifiers are built. However, the SBE generates balanced subsets that are too small when learning a highly unbalanced dataset and lead to under-fitting. We propose the Distance-based Balancing Ensemble (DBE) method to deal with this issue and improve the generalization performance of the classification algorithm. The DBE divides highly unbalanced learning set into multiple unbalanced subsets with a much lower imbalance ratio and then applies a modified adaptive semi-unsupervised weighted oversampling method to each subset to obtain balanced subsets for the sub-classifiers. We further propose our Distance-based Combination Rule (DCR) as a more effective method for combining the ensemble results. Tests with 48 public unbalanced datasets from public repositories are performed to demonstrate the effectiveness of the DBE model with the DCR. The results show that the DBE-DCR model outperforms other ensemble models.},
	journal = {IEEE Access},
	author = {Chen, Dong and Wang, Xiao-Jun and Zhou, Changjun and Wang, Bin},
	year = {2019},
	keywords = {Buildings, Classification, Classification algorithms, Clustering algorithms, Data mining, Data models, Error analysis, Prediction algorithms, ensemble learning, imbalanced datasets, oversampling},
	pages = {68940--68956},
}

@inproceedings{31,
	title = {Generative {Adversarial} {Nets}},
	volume = {27},
	url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
	abstract = {We propose a new framework for estimating generative models via adversarial nets, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitatively evaluation of the generated samples.},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	year = {2014},
	pages = {2672 -- 2680},
}

@article{30,
	title = {Comparison of ensemble hybrid sampling with bagging and boosting machine learning approach for imbalanced data},
	volume = {29},
	copyright = {http://creativecommons.org/licenses/by-nc/4.0},
	issn = {2502-4760, 2502-4752},
	doi = {10.11591/ijeecs.v29.i1.pp598-608},
	abstract = {Training an imbalanced dataset can cause classifiers to overfit the majority class and increase the possibility of information loss for the minority class. Moreover, accuracy may not give a clear picture of the classifier’s performance. This paper utilized decision tree (DT), support vector machine (SVM), artificial neural networks (ANN), K-nearest neighbors (KNN) and Naïve Bayes (NB) besides ensemble models like random forest (RF) and gradient boosting (GB), which use bagging and boosting methods, three sampling approaches and seven performance metrics to investigate the effect of class imbalance on water quality data. Based on the results, the best model was gradient boosting without resampling for almost all metrics except balanced accuracy, sensitivity and area under the curve (AUC), followed by random forest model without resampling in term of specificity, precision and AUC. However, in term of balanced accuracy and sensitivity, the highest performance was achieved by random forest with a random under-sampling dataset. Focusing on each performance metric separately, the results showed that for specificity and precision, it is better not to preprocess all the ensemble classifiers. Nevertheless, the results for balanced accuracy and sensitivity showed improvement for both ensemble classifiers when using all the resampled dataset.},
	language = {en},
	number = {1},
	journal = {Indonesian Journal of Electrical Engineering and Computer Science},
	author = {Malek, Nur Hanisah Abdul and Yaacob, Wan Fairos Wan and Wah, Yap Bee and Md Nasir, Syerina Azlin and Shaadan, Norshahida and Indratno, Sapto Wahyu},
	month = jan,
	year = {2022},
	pages = {598},
}

@inproceedings{29,
	title = {A {New} {Hybrid} {Sampling} {Approach} for {Classification} of {Imbalanced} {Datasets}},
	doi = {10.1109/CCOMS.2018.8463228},
	abstract = {Nowadays it is an era of data driven. Many organizations around the world including bank, industry, commercial, and medical intend to extract knowledge from a huge of data. But in the real-word datasets, most of them occur class imbalance problems. This paper presents a new algorithm to handle an imbalanced classification. The proposed technique is a hybrid sampling approach which is the combination of a well know oversampling algorithm called SMOTE and the undersampling technique by removing the ambiguous instances from the majority class instances. The experimental results show that the new hybrid sampling method yields the better predictive performance in term of F-measure when compare with other sampling techniques. In addition, it can improve f-measure up to 59.73\% and 412.26\% when compare with the original dataset based on decision tree learning and naïve bayes classifiers respectively.},
	booktitle = {2018 3rd {International} {Conference} on {Computer} and {Communication} {Systems} ({ICCCS})},
	author = {Hanskunatai, Anantaporn},
	month = apr,
	year = {2018},
	keywords = {Biological system modeling, Classification algorithms, DBSCAN, Decision trees, Machine learning algorithms, Prediction algorithms, SMOTE, Sampling methods, Training, decision tree, hybrid sampling, imbalanced dataset, naï ve bayes},
	pages = {67--71},
}

@article{28,
	title = {A hybrid sampling algorithm combining {M}-{SMOTE} and {ENN} based on {Random} forest for medical imbalanced data},
	volume = {107},
	issn = {1532-0464},
	doi = {10.1016/j.jbi.2020.103465},
	abstract = {The problem of imbalanced data classification often exists in medical diagnosis. Traditional classification algorithms usually assume that the number of samples in each class is similar and their misclassification cost during training is equal. However, the misclassification cost of patient samples is higher than that of healthy person samples. Therefore, how to increase the identification of patients without affecting the classification of healthy individuals is an urgent problem. In order to solve the problem of imbalanced data classification in medical diagnosis, we propose a hybrid sampling algorithm called RFMSE, which combines the Misclassification-oriented Synthetic minority over-sampling technique (M-SMOTE) and Edited nearset neighbor (ENN) based on Random forest (RF). The algorithm is mainly composed of three parts. First, M-SMOTE is used to increase the number of samples in the minority class, while the over-sampling rate of M-SMOTE is the misclassification rate of RF. Then, ENN is used to remove the noise ones from the majority samples. Finally, RF is used to perform classification prediction for the samples after hybrid sampling, and the stopping criterion for iterations is determined according to the changes of the classification index (i.e. Matthews Correlation Coefficient (MCC)). When the value of MCC continuously drops, the process of iterations will be stopped. Extensive experiments conducted on ten UCI datasets demonstrate that RFMSE can effectively solve the problem of imbalanced data classification. Compared with traditional algorithms, our method can improve F-value and MCC more effectively.},
	journal = {Journal of Biomedical Informatics},
	author = {Xu, Zhaozhao and Shen, Derong and Nie, Tiezheng and Kou, Yue},
	month = jul,
	year = {2020},
	keywords = {Data resampling, Imbalanced data classification, Medical diagnosis, Random forest},
	pages = {103465},
}

@article{25,
	title = {An automatic sampling ratio detection method based on genetic algorithm for imbalanced data classification},
	volume = {216},
	issn = {0950-7051},
	doi = {10.1016/j.knosys.2021.106800},
	abstract = {Imbalanced data are a common phenomenon in both theoretical research and real-world applications. At a data level, standard classification algorithms cannot effectively learn and make predictions from imbalanced data, and this problem is generally solved by using oversampling, undersampling, or hybrid sampling methods. However, most of the current sampling methods use random sampling ratios, and the resulting classification performance can be undesirable and unstable. To obtain satisfactory and stable classification performance, we proposed three algorithms to automatically determine the sampling ratios for oversampling, undersampling, and hybrid sampling methods, based on a genetic algorithm. Experiments were performed to test the algorithms’ effectiveness by utilizing five widely used standard classification algorithms on 14 different imbalanced datasets using two oversampling, two undersampling, and four hybrid sampling methods. The statistical test results showed that for all five standard classification algorithms, sampling methods that used our proposed algorithms achieved the best classification results. Using area under the receiver operating characteristic curve (AUC) as the evaluation metric, it was demonstrated that the proposed algorithms for automatically determining the sampling ratio outperformed the random sampling ratio.},
	journal = {Knowledge-Based Systems},
	author = {Zheng, Ming and Li, Tong and Sun, Liping and Wang, Taochun and Jie, Biao and Yang, Weiyi and Tang, Mingjing and Lv, Changlong},
	month = mar,
	year = {2021},
	keywords = {Genetic algorithm, Imbalanced data classification, Sampling methods, Sampling ratio},
	pages = {106800},
}

@article{24,
	title = {Learning from imbalanced data: open challenges and future directions},
	volume = {5},
	issn = {2192-6360},
	shorttitle = {Learning from imbalanced data},
	doi = {10.1007/s13748-016-0094-0},
	abstract = {Despite more than two decades of continuous development learning from imbalanced data is still a focus of intense research. Starting as a problem of skewed distributions of binary tasks, this topic evolved way beyond this conception. With the expansion of machine learning and data mining, combined with the arrival of big data era, we have gained a deeper insight into the nature of imbalanced learning, while at the same time facing new emerging challenges. Data-level and algorithm-level methods are constantly being improved and hybrid approaches gain increasing popularity. Recent trends focus on analyzing not only the disproportion between classes, but also other difficulties embedded in the nature of data. New real-life problems motivate researchers to focus on computationally efficient, adaptive and real-time methods. This paper aims at discussing open issues and challenges that need to be addressed to further develop the field of imbalanced learning. Seven vital areas of research in this topic are identified, covering the full spectrum of learning from imbalanced data: classification, regression, clustering, data streams, big data analytics and applications, e.g., in social media and computer vision. This paper provides a discussion and suggestions concerning lines of future research for each of them.},
	language = {en},
	number = {4},
	journal = {Progress in Artificial Intelligence},
	author = {Krawczyk, Bartosz},
	month = nov,
	year = {2016},
	keywords = {Artificial Intelligence, Big data, Data streams, Imbalanced clustering, Imbalanced data, Imbalanced regression, Machine learning, Multi-class imbalance},
	pages = {221--232},
}

@inproceedings{22,
	title = {Handling class imbalance problem using oversampling techniques: {A} review},
	shorttitle = {Handling class imbalance problem using oversampling techniques},
	doi = {10.1109/ICACCI.2017.8125820},
	abstract = {The objective of classifier is to classify objects of a data set into one or more classes based on its characteristics. In real life applications, classifiers are applied on data sets which are unbalanced i.e. some classes having very less number of instances known as minority classes as compared to other classes known as majority classes. Classification algorithms are highly accurate for the majority classes but significantly less accurate for the minority classes. Unbalanced data sets have a negative effect on classification performance of traditional classification algorithms. Analyzing such problem is called class imbalance problem. To solve Class Imbalance Problem different techniques have been proposed at the Data level, Algorithm level and at the Hybrid level. Most commonly used data balancing techniques are over and under sampling for handling the class imbalance problem. In our paper we compare various oversampling techniques which are SMOTE (Synthetic minority oversampling approach), ADASYN, Borderline-SMOTE, Safe-Level SMOTE by applying different classifiers to the problem and observing various performance metrics.},
	booktitle = {2017 {International} {Conference} on {Advances} in {Computing}, {Communications} and {Informatics} ({ICACCI})},
	author = {Gosain, Anjana and Sardana, Saanchi},
	month = sep,
	year = {2017},
	keywords = {ADASYN, BORDERLINE SMOTE, Classification algorithms, Diabetes, Heart, Oversampling, Prediction algorithms, Radar, SAFE LEVEL SMOTE, SMOTE, Sensitivity, class imbalance problem},
	pages = {79--85},
}

@article{21,
	title = {Relevant information undersampling to support imbalanced data classification},
	volume = {436},
	issn = {0925-2312},
	doi = {10.1016/j.neucom.2021.01.033},
	abstract = {Traditional classification algorithms suppose that the sample distribution among classes is balanced. Yet, such an assumption leads to biased performance over the majority class. This paper proposes a Relevant Information-based UnderSampling (RIUS) approach to select the most relevant examples from the majority class to improve the classification performance for imbalanced data scenarios. RIUS builds on the information-preservation principle that extracts the majority class’s underlying structure with fewer samples. Additionally, we couple our RIUS approach to the well-known Clustering-based Undersampling algorithm (CBUS) to enhance the data representation, and named this RIUS enhancement as CRIUS. Experimental results show that RIUS and CRIUS reveal the data’s relevant structure and reduce the loss of information by selecting the most informative instances.},
	journal = {Neurocomputing},
	author = {Hoyos-Osorio, J. and Alvarez-Meza, A. and Daza-Santacoloma, G. and Orozco-Gutierrez, A. and Castellanos-Dominguez, G.},
	month = may,
	year = {2021},
	keywords = {Binary classification, Imbalanced data, Information theoretic learning, Undersampling},
	pages = {136--146},
}

@article{20,
	title = {Undersampling method based on minority class density for imbalanced data},
	volume = {249},
	issn = {0957-4174},
	doi = {10.1016/j.eswa.2024.123328},
	abstract = {Imbalanced data severely hinder the classification performance of learning-based algorithms and attract a great deal of attention from researchers. The undersampling method of selecting the majority class from samples through the prototype is one of the most common techniques to address class imbalance. However, traditional undersampling-based methods inherently lead to information loss. Meanwhile, they tend to perform undersampling for the majority class using distance-based locality methods, resulting in completely ignoring the density of the minority class samples. To this end, this paper proposes a novel undersampling method that incorporates the density distribution information of the minority class. Specifically, the probability density distribution of the minority class samples is learned by kernel density estimation, and the majority class samples located in the high-density band of the minority class are removed through filtering. Based on this, sampling fitness is proposed to evaluate the desirable value of each majority class sample to select information-rich samples. The research was carried out in 25 publicly available datasets and compared with state-of-art methods. The results show that our approach offers clear superiority.},
	journal = {Expert Systems with Applications},
	author = {Sun, Zhongqiang and Ying, Wenhao and Zhang, Wenjin and Gong, Shengrong},
	month = sep,
	year = {2024},
	keywords = {Classification, Data mining, Imbalanced data, Kernel density estimation, Undersampling},
	pages = {123328},
}

@article{19,
	title = {Radial-{Based} {Undersampling} for imbalanced data classification},
	volume = {102},
	issn = {0031-3203},
	doi = {10.1016/j.patcog.2020.107262},
	abstract = {Data imbalance remains one of the most widespread problems affecting contemporary machine learning. The negative effect data imbalance can have on the traditional learning algorithms is most severe in combination with other dataset difficulty factors, such as small disjuncts, presence of outliers and insufficient number of training observations. Aforementioned difficulty factors can also limit the applicability of some of the methods of dealing with data imbalance, in particular the neighborhood-based oversampling algorithms based on SMOTE. Radial-Based Oversampling (RBO) was previously proposed to mitigate some of the limitations of the neighborhood-based methods. In this paper we examine the possibility of utilizing the concept of mutual class potential, used to guide the oversampling process in RBO, in the undersampling procedure. Conducted computational complexity analysis indicates a significantly reduced time complexity of the proposed Radial-Based Undersampling algorithm, and the results of the performed experimental study indicate its usefulness, especially on difficult datasets.},
	journal = {Pattern Recognition},
	author = {Koziarski, Michał},
	month = jun,
	year = {2020},
	keywords = {Classification, Imbalanced data, Machine learning, Radial basis functions, Undersampling},
	pages = {107262},
}

@article{18,
	title = {Clustering-based undersampling in class-imbalanced data},
	volume = {409-410},
	issn = {0020-0255},
	doi = {10.1016/j.ins.2017.05.008},
	abstract = {Class imbalance is often a problem in various real-world data sets, where one class (i.e. the minority class) contains a small number of data points and the other (i.e. the majority class) contains a large number of data points. It is notably difficult to develop an effective model using current data mining and machine learning algorithms without considering data preprocessing to balance the imbalanced data sets. Random undersampling and oversampling have been used in numerous studies to ensure that the different classes contain the same number of data points. A classifier ensemble (i.e. a structure containing several classifiers) can be trained on several different balanced data sets for later classification purposes. In this paper, we introduce two undersampling strategies in which a clustering technique is used during the data preprocessing step. Specifically, the number of clusters in the majority class is set to be equal to the number of data points in the minority class. The first strategy uses the cluster centers to represent the majority class, whereas the second strategy uses the nearest neighbors of the cluster centers. A further study was conducted to examine the effect on performance of the addition or deletion of 5 to 10 cluster centers in the majority class. The experimental results obtained using 44 small-scale and 2 large-scale data sets revealed that the clustering-based undersampling approach with the second strategy outperformed five state-of-the-art approaches. Specifically, this approach combined with a single multilayer perceptron classifier and C4.5 decision tree classifier ensembles delivered optimal performance over both small- and large-scale data sets.},
	journal = {Information Sciences},
	author = {Lin, Wei-Chao and Tsai, Chih-Fong and Hu, Ya-Han and Jhang, Jing-Shang},
	month = oct,
	year = {2017},
	keywords = {Class imbalance, Classifier ensembles, Clustering, Imbalanced data, Machine learning},
	pages = {17--26},
}

@article{17,
	title = {A three-way decision ensemble method for imbalanced data oversampling},
	volume = {107},
	issn = {0888-613X},
	doi = {10.1016/j.ijar.2018.12.011},
	abstract = {Synthetic Minority Over-sampling Technique (SMOTE) is an effective method for imbalanced data classification. Many variants of SMOTE have been proposed in the past decade. These methods mainly focused on how to select the crucial minority samples which implicitly assume the selection of key minority samples is binary. Thus, the cost of key sample selection is seldom considered. To this end, this paper proposes a three-way decision model (CTD) by considering the differences in the cost of selecting key samples. CTD first uses Constructive Covering Algorithm (CCA) to divide the minority samples into several covers. Then, a three-way decision model for key sample selection is constructed according to the density of the cover on minority samples. Finally, the corresponding threshold α and β of CTD are obtained based on the pattern of cover distribution on minority samples, after that key samples can be selected for SMOTE oversampling. Moreover, to overcome the shortage of CCA which may contain non-optimal by randomly selecting the cover center, an ensemble model based on CTD (CTDE) is further proposed to improve the performance of CTD. Numerical experiments on 10 imbalanced datasets show that our method is superior to the comparison methods. By constructing the ensemble of the three-way decision based key sample selection, performance of the model can be effectively improved compared with several state-of-the-art methods.},
	journal = {International Journal of Approximate Reasoning},
	author = {Yan, Yuan Ting and Wu, Zeng Bao and Du, Xiu Quan and Chen, Jie and Zhao, Shu and Zhang, Yan Ping},
	month = apr,
	year = {2019},
	keywords = {CCA, Ensemble learning, Imbalanced data, SMOTE, Three-way decision},
	pages = {1--16},
}

@article{15,
	title = {Training cost-sensitive neural networks with methods addressing the class imbalance problem},
	volume = {18},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2006.17},
	abstract = {This paper studies empirically the effect of sampling and threshold-moving in training cost-sensitive neural networks. Both oversampling and undersampling are considered. These techniques modify the distribution of the training data such that the costs of the examples are conveyed explicitly by the appearances of the examples. Threshold-moving tries to move the output threshold toward inexpensive classes such that examples with higher costs become harder to be misclassified. Moreover, hard-ensemble and soft-ensemble, i.e., the combination of above techniques via hard or soft voting schemes, are also tested. Twenty-one UCl data sets with three types of cost matrices and a real-world cost-sensitive data set are used in the empirical study. The results suggest that cost-sensitive learning with multiclass tasks is more difficult than with two-class tasks, and a higher degree of class imbalance may increase the difficulty. It also reveals that almost all the techniques are effective on two-class tasks, while most are ineffective and even may cause negative effect on multiclass tasks. Overall, threshold-moving and soft-ensemble are relatively good choices in training cost-sensitive neural networks. The empirical study also suggests that some methods that have been believed to be effective in addressing the class imbalance problem may, in fact, only be effective on learning with imbalanced two-class data sets.},
	number = {1},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Zhou, Zhi-Hua and Liu, Xu-Ying},
	month = jan,
	year = {2006},
	keywords = {Costs, Data mining, Decision trees, Index Terms- Machine learning, Learning systems, Machine learning, Neural networks, Sampling methods, Testing, Training data, Voting, class imbalance learning, cost-sensitive learning, data mining, ensemble learning., neural networks, sampling, threshold-moving},
	pages = {63--77},
}

@article{13,
	title = {Performance analysis of cost-sensitive learning methods with application to imbalanced medical data},
	volume = {25},
	issn = {2352-9148},
	doi = {10.1016/j.imu.2021.100690},
	abstract = {Many real-world machine learning applications require building models using highly imbalanced datasets. Usually, in medical datasets, the healthy patients or samples are dominant, making them the majority class, while the sick patients are few, making them the minority class. Researchers have proposed numerous machine learning methods to predict medical diagnosis. Still, the class imbalance problem makes it difficult for classifiers to adequately learn and distinguish between the minority and majority classes. Cost-sensitive learning and resampling techniques are used to deal with the class imbalance problem. This research focuses on developing robust cost-sensitive classifiers by modifying the objective functions of some well-known algorithms, such as logistic regression, decision tree, extreme gradient boosting, and random forest, which are then used to efficiently predict medical diagnosis. Meanwhile, as opposed to resampling techniques, our approach does not alter the original data distribution. Firstly, we implement the standard versions of these algorithms to provide a baseline for performance comparison. Secondly, we develop their corresponding cost-sensitive algorithms. For the proposed approaches, it is not necessary to change the distribution of the original data as the modified algorithms consider the imbalanced class distribution during training, thereby resulting in more reliable performance than when the data is resampled. Four popular medical datasets, including the Pima Indians Diabetes, Haberman Breast Cancer, Cervical Cancer Risk Factors, and Chronic Kidney Disease datasets, are used in the experiments to validate the performance of the proposed approach. The experimental results show that the cost-sensitive methods yield superior performance compared to the standard algorithms.},
	journal = {Informatics in Medicine Unlocked},
	author = {Mienye, Ibomoiye Domor and Sun, Yanxia},
	month = jan,
	year = {2021},
	keywords = {Cost-sensitive learning, Imbalanced classification, Machine learning, Medical diagnosis},
	pages = {100690},
}

@article{12,
	title = {A weighted hybrid ensemble method for classifying imbalanced data},
	volume = {203},
	issn = {0950-7051},
	doi = {10.1016/j.knosys.2020.106087},
	abstract = {In real datasets, most are unbalanced. Data imbalance can be defined as the number of instances in some classes greatly exceeds the number of instances in other classes. Whether in the field of data mining or machine learning, data imbalance can have adverse effects. At present, the methods to solve the problem of data imbalance can be divided into data-level methods, algorithm-level methods and hybrid methods. In this paper, we propose a weighted hybrid ensemble method for classifying imbalanced data in binary classification tasks, called WHMBoost. In the framework of the boosting algorithm, the presented method combines two data sampling methods and two base classifiers, and each sampling method and each base classifier is assigned corresponding weights, which makes them have better complementary advantages. The performance of WHMBoost has been evaluated on 40 benchmark imbalanced datasets with state of the art ensemble methods like AdaBoost, RUSBoost, SMOTEBoost using AUC, F-Measure and Geometric Mean as the performance evaluation criteria. Experimental results show significant improvement over the other methods and it can be concluded that WHMBoost is a promising and effective algorithm to deal with imbalance datasets.},
	journal = {Knowledge-Based Systems},
	author = {Zhao, Jiakun and Jin, Ju and Chen, Si and Zhang, Ruifeng and Yu, Bilin and Liu, Qingfang},
	month = sep,
	year = {2020},
	keywords = {Base classifiers, Binary classification, Boosting algorithm, Data imbalance, Data sampling methods},
	pages = {106087},
}

@article{11,
	title = {A novel ensemble method for classifying imbalanced data},
	volume = {48},
	issn = {0031-3203},
	doi = {10.1016/j.patcog.2014.11.014},
	abstract = {The class imbalance problems have been reported to severely hinder classification performance of many standard learning algorithms, and have attracted a great deal of attention from researchers of different fields. Therefore, a number of methods, such as sampling methods, cost-sensitive learning methods, and bagging and boosting based ensemble methods, have been proposed to solve these problems. However, these conventional class imbalance handling methods might suffer from the loss of potentially useful information, unexpected mistakes or increasing the likelihood of overfitting because they may alter the original data distribution. Thus we propose a novel ensemble method, which firstly converts an imbalanced data set into multiple balanced ones and then builds a number of classifiers on these multiple data with a specific classification algorithm. Finally, the classification results of these classifiers for new data are combined by a specific ensemble rule. In the empirical study, different class imbalance data handling methods including three conventional sampling methods, one cost-sensitive learning method, six Bagging and Boosting based ensemble methods, our previous method EM1vs1 and two fuzzy-rule based classification methods were compared with our method. The experimental results on 46 imbalanced data sets show that our proposed method is usually superior to the conventional imbalance data handling methods when solving the highly imbalanced problems.},
	number = {5},
	journal = {Pattern Recognition},
	author = {Sun, Zhongbin and Song, Qinbao and Zhu, Xiaoyan and Sun, Heli and Xu, Baowen and Zhou, Yuming},
	month = may,
	year = {2015},
	keywords = {Classification, Ensemble learning, Imbalanced data},
	pages = {1623--1637},
}

@article{4,
	title = {Adjusting the imbalance ratio by the dimensionality of imbalanced data},
	volume = {133},
	issn = {0167-8655},
	doi = {10.1016/j.patrec.2020.03.004},
	abstract = {Class-imbalance extent metrics measure how imbalanced the data are. In pattern classification, it is usually expected that the higher the imbalance extent, the worse the classification performance, and thus an appropriate imbalance extent metric should show a negative correlation with the classification performance. Existing metrics, such as the popular imbalance ratio (IR), only consider the effect of the sample sizes of different classes. However, we note that the dimensionality of imbalanced data also affects the classification performance. Datasets with the same IR can present distinct classification performances when their dimensionalities are different, making IR suboptimal to reflect the imbalance extent for classification. We also observe that the classification performance becomes better with more discriminative features. Inspired by these observations, we propose a new imbalance extent metric, the adjusted IR, by adding a penalty term of the number of discriminative features that is effectively determined by the Pearson correlation test. The adjusted IR adaptively revises the IR when the number of discriminative features varies. The empirical studies demonstrate the effectiveness of the adjusted IR, in terms of its better negative correlation with the classification performance.},
	journal = {Pattern Recognition Letters},
	author = {Zhu, Rui and Guo, Yiwen and Xue, Jing-Hao},
	month = may,
	year = {2020},
	keywords = {Imbalance extent, Imbalance ratio, Imbalanced data, Imbalanced learning, Pearson correlation test},
	pages = {217--223},
}

@article{3,
	title = {A data augmentation approach based on various {GAN} models to address class imbalance in fine-grained multimodal fake news datasets},
	volume = {107},
	issn = {1436-5057},
	url = {https://doi.org/10.1007/s00607-025-01413-2},
	doi = {10.1007/s00607-025-01413-2},
	abstract = {In recent years, social media platforms have become a primary source for news consumption, often featuring articles paired with images or videos. However, the widespread dissemination of fake news on these platforms poses significant risks to individuals and society, driving the need for robust multimodal fake news detection models. These models, typically reliant on supervised learning, are highly sensitive to the size and distribution of their training datasets. A critical challenge in this domain is the prevalence of small or imbalanced datasets, particularly within fine-grained categories, which can lead to issues such as overfitting, underfitting, misclassification, and diminished accuracy. To address these challenges, we propose a novel data augmentation technique termed DA-LGS, which leverages Generative Adversarial Networks. Specifically, we employ LeakGAN for generating textual content and a combination of GAN and StackGAN for producing image samples. This approach aims to expand datasets and correct class imbalances while preserving the essential correlations between text and images. We evaluated our method using the Fakeddit multimodal, fine-grained dataset, assessing performance through precision, recall, and F1-score metrics for individual classes, alongside a macro-average for overall accuracy. Our findings demonstrate that the DA-LGS method effectively mitigates overfitting and significantly enhances classification accuracy across various classes, leading to a substantial improvement in overall model performance. Compared to existing state-of-the-art methods, our model achieved superior detection accuracy, recording a notable accuracy rate of 90.1\%, which is a 2.9\% improvement over the best-performing baseline model.},
	language = {en},
	number = {1},
	journal = {Computing},
	author = {Hamed, Suhaib Kh. and Ab Aziz, Mohd Juzaiddin and Yaakub, Mohd Ridzwan},
	month = jan,
	year = {2025},
	keywords = {62H30, 68T01, 68T05, 68T07, 68T09, Artificial Intelligence, Data augmentation, Fake news detection, Generative adversarial network, Multimodal imbalanced dataset, Overfitting/underfitting},
	pages = {52},
}

@article{1,
	title = {Learning from class-imbalanced data: {Review} of methods and applications},
	volume = {73},
	issn = {0957-4174},
	shorttitle = {Learning from class-imbalanced data},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417416307175},
	doi = {10.1016/j.eswa.2016.12.035},
	abstract = {Rare events, especially those that could potentially negatively impact society, often require humans’ decision-making responses. Detecting rare events can be viewed as a prediction task in data mining and machine learning communities. As these events are rarely observed in daily life, the prediction task suffers from a lack of balanced data. In this paper, we provide an in depth review of rare event detection from an imbalanced learning perspective. Five hundred and seventeen related papers that have been published in the past decade were collected for the study. The initial statistics suggested that rare events detection and imbalanced learning are concerned across a wide range of research areas from management science to engineering. We reviewed all collected papers from both a technical and a practical point of view. Modeling methods discussed include techniques such as data preprocessing, classification algorithms and model evaluation. For applications, we first provide a comprehensive taxonomy of the existing application domains of imbalanced learning, and then we detail the applications for each category. Finally, some suggestions from the reviewed papers are incorporated with our experiences and judgments to offer further research directions for the imbalanced learning and rare event detection fields.},
	journal = {Expert Systems with Applications},
	author = {Haixiang, Guo and Yijing, Li and Shang, Jennifer and Mingyun, Gu and Yuanyue, Huang and Bing, Gong},
	month = may,
	year = {2017},
	keywords = {Data mining, Imbalanced data, Machine learning, Rare events},
	pages = {220--239},
}

@article{183,
	title = {Improving mixed-integer temporal modeling by generating synthetic data using conditional generative adversarial networks: {A} case study of fluid overload prediction in the intensive care unit},
	volume = {168},
	shorttitle = {Improving mixed-integer temporal modeling by generating synthetic data using conditional generative adversarial networks},
	doi = {10.1016/j.compbiomed.2023.107749},
	abstract = {Objective: The challenge of mixed-integer temporal data, which is particularly prominent for medication use in the critically ill, limits the performance of predictive models. The purpose of this evaluation was to pilot test integrating synthetic data within an existing dataset of complex medication data to improve machine learning model prediction of fluid overload. Materials and methods: This retrospective cohort study evaluated patients admitted to an ICU ≥ 72 h. Four machine learning algorithms to predict fluid overload after 48–72 h of ICU admission were developed using the original dataset. Then, two distinct synthetic data generation methodologies (synthetic minority over-sampling technique (SMOTE) and conditional tabular generative adversarial network (CTGAN)) were used to create synthetic data. Finally, a stacking ensemble technique designed to train a meta-learner was established. Models underwent training in three scenarios of varying qualities and quantities of datasets. Results: Training machine learning algorithms on the combined synthetic and original dataset overall increased the performance of the predictive models compared to training on the original dataset. The highest performing model was the meta-model trained on the combined dataset with 0.83 AUROC while it managed to significantly enhance the sensitivity across different training scenarios. Discussion: The integration of synthetically generated data is the first time such methods have been applied to ICU medication data and offers a promising solution to enhance the performance of machine learning models for fluid overload, which may be translated to other ICU outcomes. A meta-learner was able to make a trade-off between different performance metrics and improve the ability to identify the minority class. © 2023 Elsevier Ltd},
	journal = {Computers in Biology and Medicine},
	author = {Rafiei, A. and Ghiasi Rad, M. and Sikora, A. and Kamaleswaran, R.},
	year = {2024},
	keywords = {Critical care, Fluid overload, GAN, Machine learning, Mixed-integer temporal modeling, Synthetic data},
}

@article{182,
	title = {A new imbalanced data oversampling method based on {Bootstrap} method and {Wasserstein} {Generative} {Adversarial} {Network}},
	volume = {21},
	doi = {10.3934/mbe.2024190},
	abstract = {Due to their high bias in favor of the majority class, traditional machine learning classifiers face a great challenge when there is a class imbalance in biological data. More recently, generative adversarial networks (GANs) have been applied to imbalanced data classification. For GANs, the distribution of the minority class data fed into discriminator is unknown. The input to the generator is random noise (z) drawn from a standard normal distribution N(0, 1). This method inevitably increases the training difficulty of the network and reduces the quality of the data generated. In order to solve this problem, we proposed a new oversampling algorithm by combining the Bootstrap method and the Wasserstein GAN Network (BM-WGAN). In our approach, the input to the generator network is the data (z) drawn from the distribution of minority class estimated by the BM. The generator was used to synthesize minority class data when the network training is completed. Through the above steps, the generator model can learn the useful features from the minority class and generate realistic-looking minority class samples. The experimental results indicate that BM-WGAN improves the classification performance greatly compared to other oversampling algorithms. The BM-WGAN implementation is available at: https://github.com/ithbjgit1/BMWGAN.git. © 2024 the Author(s), licensee AIMS Press.},
	number = {3},
	journal = {Mathematical Biosciences and Engineering},
	author = {Hou, B. and Chen, G.},
	year = {2024},
	keywords = {Bootstrap method (BM), data generation, generative adversarial networks (GANs), imbalanced data, probability distribution},
	pages = {4309--4327},
}

@inproceedings{181,
	title = {A {Study} on the {GAN}-{Stacking} {Model} {Framework} for {Fraud} {Dataset}},
	doi = {10.1145/3650215.3650270},
	abstract = {Considering the high dimensionality and imbalanced distribution of fraud datasets, this study employs the Spearman's rank correlation coefficient for feature selection and utilizes Generative Adversarial Networks (GANs) to address the data imbalance issue and achieve data augmentation. Through experimental comparisons with four other data processing algorithms, namely BorderlineSMOTE, ENN, SMOTE, and ADASYN, using F1 score and G-mean as comprehensive evaluation metrics, the results demonstrate that GANs exhibit superior performance and stronger stability in handling imbalanced data. Furthermore, a GAN-Stacking model is constructed for classification prediction, achieving an F1 score of 0.936 and a G-mean of 0.941, indicating better performance of the GAN-Stacking model. © 2023 ACM.},
	author = {Zhang, W. and Ding, G.},
	year = {2023},
	keywords = {GAN, Lmbalanced Data, Stacking},
	pages = {310--315},
}

@inproceedings{179,
	title = {Predicting diabetes in imbalanced datasets using neural networks},
	doi = {10.1145/3535508.3545540},
	abstract = {Diabetes is a long-standing disease caused by high blood sugar over a long period of time and one in every ten Americans has diabetes. The neural networks have gained attention in large-scale genetic research because of its ability in non-linear relationships. However, the data imbalance problem, which is caused by the disproportion between the number of disease samples and the number of healthy samples, will decrease the prediction accuracy. In this project, we tackle the data imbalance problem when predicting diabetes with genotype SNP data and phenotype data provided by UK BioBank. The dataset is highly skewed with healthy samples with the ratio of 20. We build a phenotype neural network and a genotype neural network, which uses two sampling techniques and a data augmentation method by generative adversarial neural network (GAN) to counter the data imbalance problem before feeding the data to the neural networks. We found out that the phenotype neural network outperforms the genotype neural network and achieves 90\% accuracy. We reach the conclusion that undersampling performs better than both oversampling and the GAN, and the phenotype is better than the genotype in terms of predicting diabetes. We have identified key phenotype and genotype features that contributed to the effectiveness of the prediction. © 2022 ACM.},
	author = {Guan, H. and Zhang, C.},
	year = {2022},
	keywords = {Generative adversarial neural networks, Imbalance datasets, Neural networks, Oversampling, Undersampling},
}

@inproceedings{178,
	title = {Adversarial {Fraud} {Generation} for {Improved} {Detection}},
	doi = {10.1145/3533271.3561723},
	abstract = {Generative Adversarial Networks (GANs) are known for their ability to learn data distribution and hence exist as a suitable alternative to handle class imbalance through oversampling. However, it still fails to capture the diversity of the minority class owing to their limited representation, for example, frauds in our study. Particularly the fraudulent patterns closer to the class boundary get missed by the model. This paper proposes using GANs to simulate fraud transaction patterns conditioned on genuine transactions, thereby enabling the model to learn a translation function between both spaces. Further to synthesize fraudulent samples from the class boundary, we trained GANs using losses inspired by data poisoning attack literature and discussed their efficacy in improving fraud detection classifier performance. The efficacy of our proposed framework is demonstrated through experimental results on the publicly available European Credit-Card Dataset and CIS Fraud Dataset. © 2022 ACM.},
	author = {Pandey, A. and Bhatraju, A. and Markam, S. and Bhatt, D.},
	year = {2022},
	pages = {123--129},
}

@inproceedings{177,
	title = {Research on {Credit} {Card} {Fraud} {Detection} {Based} on {GAN}},
	doi = {10.1145/3584376.3584529},
	abstract = {With the advancement of technology, credit card transactions have become more and more popular, and the number of credit card frauds has also increased at the same time. In order to reduce property loss of cardholders and banks, many traditional machine learning algorithms based on binary classification are applied to detect fraudulent transactions. However, the number of fraudulent transactions and normal transactions in the dataset used to train the classifier is seriously imbalanced, which causes the classifier with the goal of accuracy to tend to classify all transactions as normal transactions. It is meaningless to detect fraudulent transactions with this trained classifier. Oversampling the minority fraudulent transaction classes to rebalance the training set is an effective way to address the problem of class imbalance. The method proposed in this paper uses an improved conditional generative adversarial network to rebalance dataset, then combines with random forests classifier for fraud detection, and experiments prove that the proposed method is effective for credit card fraud detection. © 2022 ACM.},
	author = {Ge, J. and Liao, X. and Fang, Y.},
	year = {2022},
	keywords = {GAN, credit card fraud detection, imbalanced class},
	pages = {857--861},
}

@article{176,
	title = {A {GAN}-based hybrid sampling method for imbalanced customer classification},
	volume = {609},
	doi = {10.1016/j.ins.2022.07.145},
	abstract = {Class imbalance is a critical issue in customer classification, for which a plethora of techniques have been proposed in the current body of literature. In particular, generative adversarial network (GAN)-based oversampling can capture the true data distribution of minority class samples and generate new samples, and this approach has demonstrated an outstanding ability to address class imbalance. However, GAN-based oversampling suffers from the issue of class overlap. As a result, in this work, we propose a novel a novel GAN-based hybrid sampling method. The new approach first uses GAN-based oversampling to generate the initial balanced dataset and then applies a novel adaptive neighborhood-based weighted undersampling method to remove generated instances and original majority class instances. This approach not only produces instances that fit the actual data distribution but also significantly reduces the influence of class overlap. Experimental results on artificial data and real-world customer datasets show that the proposed GAN-based hybrid sampling method has better performance than other benchmark methods with both accuracy-based and profit-based evaluation metrics. © 2022 Elsevier Inc.},
	journal = {Information Sciences},
	author = {Zhu, B. and Pan, X. and vanden Broucke, S. and Xiao, J.},
	year = {2022},
	keywords = {Class imbalance, Class overlap, Customer classification, GAN-based sampling},
	pages = {1397--1411},
}

@article{175,
	title = {{OBGAN}: {Minority} oversampling near borderline with generative adversarial networks},
	volume = {197},
	shorttitle = {{OBGAN}},
	doi = {10.1016/j.eswa.2022.116694},
	abstract = {Class imbalance is a major issue that degrades the performance of machine learning classifiers in real-world problems. Oversampling methods have been widely used to overcome this issue by generating synthetic data from minority classes. However, conventional oversampling methods often focus only on the minority class and ignore relationships between the minority and majority classes. In this study, we propose an oversampling method called minority oversampling near the borderline with a generative adversarial network (OBGAN). To consider the minority and majority classes, OBGAN employs one independent discriminator for each class. Each discriminator competitively affects the generator to be trained to capture each region of the minority and majority classes. However, the sensitivity of the generator to the discriminator of the minority class is greater than that of the majority class. Hence, the generator learns the minority class with a focus near the borderline. In addition, the architecture and loss function of OBGAN are designed to avoid the mode collapse problem, which commonly occurs in GANs trained on relatively small datasets. Experimental results, involving 21 datasets and 6 benchmark methods, reveal that OBGAN exhibits excellent performance and stability. © 2022 Elsevier Ltd},
	journal = {Expert Systems with Applications},
	author = {Jo, W. and Kim, D.},
	year = {2022},
	keywords = {Class imbalance problem, Deep learning, Generative adversarial networks, Generative learning, Neural networks, Oversampling},
}

@article{174,
	title = {Binary imbalanced data classification based on diversity oversampling by generative models},
	volume = {585},
	doi = {10.1016/j.ins.2021.11.058},
	abstract = {In many practical applications, the data are class imbalanced. Accordingly, it is very meaningful and valuable to investigate the classification of imbalanced data. In the framework of binary imbalanced data classification, the synthetic minority oversampling technique (SMOTE) is the best-known oversampling method. However, for each positive sample, SMOTE generates only k synthetic samples on the lines between the positive sample and its k-nearest neighbors, resulting in three drawbacks: (1) SMOTE cannot effectively extend the training field of positive samples; (2) the generated positive samples lack diversity; (3) SMOTE does not accurately approximate the probability distribution of the positive samples. Therefore, two binary imbalanced data classification methods named BIDC1 and BIDC2 based on diversity oversampling by generative models are proposed. The BIDC1 and BIDC2 conduct diversity oversampling using extreme learning machine autoencoder and generative adversarial network, respectively. Extensive experiments on 26 data sets are conducted to compare the two methods with 14 state-of-the-art methods using five metrics: F-measure, G-means, AUC-area, MMD-score, and Silhouette-score. The experimental results demonstrate that the two methods outperform the other 14 methods. © 2021 Elsevier Inc.},
	journal = {Information Sciences},
	author = {Zhai, J. and Qi, J. and Shen, C.},
	year = {2022},
	keywords = {Binary imbalanced data classification, Diversity oversampling, Extreme learning machine autoencoder, Generative adversarial network, Imbalanced learning},
	pages = {313--343},
}

@article{173,
	title = {A {ResNet}-{LSTM} {Based} {Credit} {Scoring} {Approach} for {Imbalanced} {Data}},
	volume = {2022},
	doi = {10.1155/2022/9103437},
	abstract = {Detecting potential defaults or bad debt with limited information has become a huge challenge. The main difficulties faced by the credit scoring are sample imbalance and poor classification performance. For this reason, we first proposed the auxiliary conditional tabular generative adversarial network (ACTGAN) to generate sufficient default transaction samples from the original data, then we designed a model based on ResNet-LSTM used for feature extraction, which includes two submodels of ResNet and LSTM to extract static local features and dynamic temporal features from the original data, respectively. After that, a spatiotemporal attention module is added to calculate the importance of the two submodel's output in order to extract more critical information. Finally, we applied the focus loss function into the XGBoost classifier to improve the probability output of the credit default risk. We verified the designed credit scoring model in two real-world datasets. The experimental results showed that ACTGAN can effectively solve the problem of data imbalance. The ResNet-LSTM+XGBoost model for classification is better than other traditional algorithms in F1 value, AUC, and KS value, which proves the effectiveness and portability of this model in the field of credit scoring. © 2022 Anqin Zhang et al.},
	journal = {Mobile Information Systems},
	author = {Zhang, A. and Peng, B. and Chen, J. and Liu, Q. and Jiang, S. and Zhou, Y.},
	year = {2022},
}

@article{172,
	title = {Balancing sequential data to predict students at-risk using adversarial networks},
	volume = {93},
	doi = {10.1016/j.compeleceng.2021.107274},
	abstract = {Class imbalance is a challenging problem especially in a supervised learning setup, as most classification algorithms are designed for balanced class distributions. Although various up-sampling approaches exist for eliminating the class imbalance, however, they do not handle the complexities of sequential data. In this study, using the data of over 30,000 students from the Open University (UK), we implement a deep-learning-based approach using adversarial networks, Sequential Conditional Generative Adversarial Network (SC-GAN) that encapsulates the past behavior of each student for its previous sequences and generates synthetic student records for the next timestamp. The proposed approach is devised to generate instances, which are augmented with the actual data to eliminate class imbalance. A performance comparison of the proposed SC-GAN with the standard up-sampling methods is also presented and the results validate the proposed method with an improved AUC of 7.07\% and 6.53\%, respectively, when compared with conventional Random Over-sampling and Sythetic Minority Oversampling techniques. © 2021 Elsevier Ltd},
	journal = {Computers and Electrical Engineering},
	author = {Waheed, H. and Anas, M. and Hassan, S.-U. and Aljohani, N.R. and Alelyani, S. and Edifor, E.E. and Nawaz, R.},
	year = {2021},
	keywords = {CGAN, Class Imbalance, Sequential Data, Students At-Risk, Sythetic Minority Oversampling technique, Time-Series},
}

@article{169,
	title = {Oversampling {Imbalanced} {Data} {Based} on {Convergent} {WGAN} for {Network} {Threat} {Detection}},
	volume = {2021},
	doi = {10.1155/2021/9206440},
	abstract = {Class imbalance is a common problem in network threat detection. Oversampling the minority class is regarded as a popular countermeasure by generating enough new minority samples. Generative adversarial network (GAN) is a typical generative model that can generate any number of artificial minority samples, which are close to the real data. However, it is difficult to train GAN, and the Nash equilibrium is almost impossible to achieve. Therefore, in order to improve the training stability of GAN for oversampling to detect the network threat, a convergent WGAN-based oversampling model called convergent WGAN (CWGAN) is proposed in this paper. The training process of CWGAN contains multiple iterations. In each iteration, the training epochs of the discriminator are dynamic, which is determined by the convergence of discriminator loss function in the last two iterations. When the discriminator is trained to convergence, the generator will then be trained to generate new minority samples. The experiment results show that CWGAN not only improve the training stability of WGAN on the loss smoother and closer to 0 but also improve the performance of the minority class through oversampling, which means that CWGAN can improve the performance of network threat detection. Copyright © 2021 Yanping Xu et al. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
	journal = {Security and Communication Networks},
	author = {Xu, Y. and Zhang, X. and Qiu, Z. and Zhang, X. and Qiu, J. and Zhang, H.},
	year = {2021},
}

@article{168,
	title = {Conditional {Wasserstein} generative adversarial network-gradient penalty-based approach to alleviating imbalanced data classification},
	volume = {512},
	doi = {10.1016/j.ins.2019.10.014},
	abstract = {In data mining, common classification algorithms cannot effectively learn from imbalanced data. Oversampling addresses this problem by creating data for the minority class in order to balance the class distribution before the model is trained. The Traditional oversampling approaches are based on Synthetic Minority Oversampling TEchnique (SMOTE), which focus on local information but generates insufficiently realistic data. In contrast, the Generative Adversarial Network (GAN) captures the true data distribution in order to generate data for the minority class. However, both approaches are problematic owing to mode collapse and unstable training. To overcome these problems, we propose Conditional Wasserstein GAN- Gradient Penalty (CWGAN-GP), a novel and efficient synthetic oversampling approach for imbalanced datasets, which can be constructed by adding auxiliary conditional information to the WGAN-GP. CWGAN-GP generates more realistic data and overcomes the aforementioned problems. Experiments on 15 different benchmarked datasets and two real imbalanced datasets empirically demonstrate that CWGAN-GP increases the quality of synthetic data; furthermore, our approach outperforms the other oversampling approaches based on three evaluation metrics (F-measure, G-mean, and the area under the receiver operating characteristic curve) for five classifiers. Friedman and Nemenyi post hoc statistical tests also confirm that CWGAN-GP is superior to the other oversampling approaches. © 2019 Elsevier Inc.},
	journal = {Information Sciences},
	author = {Zheng, M. and Li, T. and Zhu, R. and Tang, Y. and Tang, M. and Lin, L. and Ma, Z.},
	year = {2020},
	keywords = {GAN, Imbalanced learning, Oversampling approach, SMOTE, WGAN-GP},
	pages = {1009--1023},
}

@article{165,
	title = {Oversampling method using outlier detectable generative adversarial network},
	volume = {133},
	doi = {10.1016/j.eswa.2019.05.006},
	abstract = {A class imbalance problem occurs when a particular class of data is significantly more or less than another class of data. This problem is difficult to solve; however, solutions such as the oversampling method using synthetic minority oversampling technique (SMOTE) or conditional generative adversarial network (cGAN) have been suggested recently to solve this problem. In the case of SMOTE and their variations, it is possible to generate biased artificial data because it does not consider the entire data in the minority class. To overcome this problem, an oversampling method using cGAN has been proposed. However, such a method does not consider the majority class that affects the classification boundary. In particular, if there is an outlier in the majority class, the classification boundary may be biased. This paper presents an oversampling method using outlier detectable generative adversarial network (OD-GAN) to solve this problem. We use a discriminator, which is used only for training purposes in cGAN, as an outlier detector to quantify the difference between the distributions of the majority and minority classes. The discriminator can detect and remove outliers. This prevents the distortion of the classification boundary caused by outliers. The generator imitates the distribution of the minority class and generates artificial data to balance the dataset. We experiment with various datasets, oversampling techniques, and classifiers. The empirical results show that the performance of OD-GAN is better than those of other oversampling methods for imbalanced datasets with outliers. © 2019 Elsevier Ltd},
	journal = {Expert Systems with Applications},
	author = {Oh, J.-H. and Hong, J.Y. and Baek, J.-G.},
	year = {2019},
	keywords = {Class imbalance problem, Generative adversarial network, Outlier detection, Oversampling},
	pages = {1--8},
}

@article{164,
	title = {Effective data generation for imbalanced learning using conditional generative adversarial networks},
	volume = {91},
	doi = {10.1016/j.eswa.2017.09.030},
	abstract = {Learning from imbalanced datasets is a frequent but challenging task for standard classification algorithms. Although there are different strategies to address this problem, methods that generate artificial data for the minority class constitute a more general approach compared to algorithmic modifications. Standard oversampling methods are variations of the SMOTE algorithm, which generates synthetic samples along the line segment that joins minority class samples. Therefore, these approaches are based on local information, rather on the overall minority class distribution. Contrary to these algorithms, in this paper the conditional version of Generative Adversarial Networks (cGAN) is used to approximate the true data distribution and generate data for the minority class of various imbalanced datasets. The performance of cGAN is compared against multiple standard oversampling algorithms. We present empirical results that show a significant improvement in the quality of the generated data when cGAN is used as an oversampling algorithm. © 2017},
	journal = {Expert Systems with Applications},
	author = {Douzas, G. and Bacao, F.},
	year = {2018},
	keywords = {Artificial data, GAN, Imbalanced learning, Minority class},
	pages = {464--471},
}

@article{126,
	title = {A {Sustainable} {Approach} to {Asthma} {Diagnosis}: {Classification} with {Data} {Augmentation}, {Feature} {Selection}, and {Boosting} {Algorithm}},
	volume = {14},
	shorttitle = {A {Sustainable} {Approach} to {Asthma} {Diagnosis}},
	doi = {10.3390/diagnostics14070723},
	abstract = {Asthma is a diverse disease that affects over 300 million individuals globally. The prevalence of asthma has increased by 50\% every decade since the 1960s, making it a serious global health issue. In addition to its associated high mortality, asthma generates large economic losses due to the degradation of patients’ quality of life and the impairment of their physical fitness. Asthma research has evolved in recent years to fully analyze why certain diseases develop based on a variety of data and observations of patients’ performance. The advent of new techniques offers good opportunities and application prospects for the development of asthma diagnosis methods. Over the last few decades, techniques like data mining and machine learning have been utilized to diagnose asthma. Nevertheless, these traditional methods are unable to address all of the difficulties associated with improving a small dataset to increase its quantity, quality, and feature space complexity at the same time. In this study, we propose a sustainable approach to asthma diagnosis using advanced machine learning techniques. To be more specific, we use feature selection to find the most important features, data augmentation to improve the dataset’s resilience, and the extreme gradient boosting algorithm for classification. Data augmentation in the proposed method involves generating synthetic samples to increase the size of the training dataset, which is then utilized to enhance the training data initially. This could lessen the phenomenon of imbalanced data related to asthma. Then, to improve diagnosis accuracy and prioritize significant features, the extreme gradient boosting technique is used. The outcomes indicate that the proposed approach performs better in terms of diagnostic accuracy than current techniques. Furthermore, five essential features are extracted to help physicians diagnose asthma. © 2024 by the authors.},
	number = {7},
	journal = {Diagnostics},
	author = {Lee, Z.-J. and Yang, M.-R. and Hwang, B.-J.},
	year = {2024},
	keywords = {asthma, data augmentation, extreme gradient boosting algorithm, feature selection, generative adversarial networks},
}

@article{125,
	title = {A multi-source credit data fusion approach based on federated distillation learning},
	volume = {15},
	doi = {10.1007/s13042-023-02032-z},
	abstract = {Data imbalance and privacy disclosure shortcomings have become the main problems in the process of multi-source credit data fusion, the former causes conflicts during the fusion process, the latter brings huge security risks. While federated learning is used for data privacy protection, communication cost defects and inaccurate fusion results will follow. In order to effectively unify data fusion, the paper proposes an approach based on federated distillation learning, which uses synthetic distillation data instead of traditional parameter transfer models to fuse to reduce time cost and improve accuracy without compromising data privacy,simultaneously utilizing local data to train the model and conducting interactive learning with the server's model. Specifically, it uses a decision tree model to distill knowledge from credit data, replacing the traditional parameter transfer model. At the same time, the Generic Adversarial Network is used to balance data distribution and solve the problem of data imbalance on the server. The experimental results show that the method proposed has improved both utilization performance and unbalanced data processing by at least 3\%. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2023.},
	number = {3},
	journal = {International Journal of Machine Learning and Cybernetics},
	author = {Zhang, X. and Sun, Z. and Mao, L. and Li, X.},
	year = {2024},
	keywords = {Data fusion, Data imbalance, Federated distillation learning, Generative adversarial network},
	pages = {1153--1164},
}

@article{124,
	title = {Enhancing and improving the performance of imbalanced class data using novel {GBO} and {SSG}: {A} comparative analysis},
	volume = {173},
	shorttitle = {Enhancing and improving the performance of imbalanced class data using novel {GBO} and {SSG}},
	doi = {10.1016/j.neunet.2024.106157},
	abstract = {Class imbalance problem (CIP) in a dataset is a major challenge that significantly affects the performance of Machine Learning (ML) models resulting in biased predictions. Numerous techniques have been proposed to address CIP, including, but not limited to, Oversampling, Undersampling, and cost-sensitive approaches. Due to its ability to generate synthetic data, oversampling techniques such as the Synthetic Minority Oversampling Technique (SMOTE) are the most widely used methodology by researchers. However, one of SMOTE's potential disadvantages is that newly created minor samples overlap with major samples. Therefore, the probability of ML models’ biased performance toward major classes increases. Generative adversarial network (GAN) has recently garnered much attention due to their ability to create real samples. However, GAN is hard to train even though it has much potential. Considering these opportunities, this work proposes two novel techniques: GAN-based Oversampling (GBO) and Support Vector Machine-SMOTE-GAN (SSG) to overcome the limitations of the existing approaches. The preliminary results show that SSG and GBO performed better on the nine imbalanced benchmark datasets than several existing SMOTE-based approaches. Additionally, it can be observed that the proposed SSG and GBO methods can accurately classify the minor class with more than 90\% accuracy when tested with 20\%, 30\%, and 40\% of the test data. The study also revealed that the minor sample generated by SSG demonstrates Gaussian distributions, which is often difficult to achieve using original SMOTE and SVM-SMOTE. © 2024 Elsevier Ltd},
	journal = {Neural Networks},
	author = {Ahsan, M.M. and Ali, M.S. and Siddique, Z.},
	year = {2024},
	keywords = {GAN, Imbalanced class data, Minor sample, Neural network, Oversampling, SMOTE},
}

@article{123,
	title = {{VGAN}-{BL}: imbalanced data classification based on generative adversarial network and biased loss},
	volume = {36},
	shorttitle = {{VGAN}-{BL}},
	doi = {10.1007/s00521-023-09180-x},
	abstract = {The purpose of imbalanced data classification is to solve the problem of unfair learning caused by the large difference in data distribution. Traditional classifiers are designed on the basis of balanced data, but the performance of imbalanced data will decline sharply. Therefore, balancing the majority class and minority class samples before classification is a popular strategy for solving imbalanced learning. Current methods for data balance mainly include oversampling and undersampling. However, the existing undersampling will face the problem of losing important sample information, while oversampling cannot effectively fit the global distribution and generate noise. In recent years, generative adversarial network (GAN) has shown great potential in fitting real sample distributions. Based on this, this paper proposes an improved GAN and biased loss combined model, namely VGAN-BL, to solve the learning problem under imbalanced conditions. In the improvement based on GAN, VAE is used to generate latent vectors with posterior distribution as the input of GAN, and KL similarity measurement loss is introduced into the generator to improve the quality of minority samples generated by GAN. In addition, we propose a biased loss definition method based on the discriminator to improve the performance of classifier. Experiments on 20 real datasets show that the classification performance of the proposed method is significantly improved compared with other advanced methods. The source code can be found here: https://github.com/universuen/VGAN-BL . © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.},
	number = {6},
	journal = {Neural Computing and Applications},
	author = {Ding, H. and Sun, Y. and Huang, N. and Cui, X.},
	year = {2024},
	keywords = {Imbalanced data, Oversampling, Undersampling, VGAN-BL},
	pages = {2883--2899},
}

@article{122,
	title = {{AWGAN}: {An} adaptive weighting {GAN} approach for oversampling imbalanced datasets},
	volume = {663},
	shorttitle = {{AWGAN}},
	doi = {10.1016/j.ins.2024.120311},
	abstract = {Oversampling is a widely employed technique for addressing imbalanced datasets, facing challenges like class overlaps, intra-class imbalance, and noise. In this paper, we introduce an adaptive weighted oversampling algorithm grounded in generative adversarial networks, which we term AWGAN. To begin, our method computes the local and global densities for each instance, confirming its distribution within its local neighborhood, thereby enabling accurate identification and elimination of noisy instances. Subsequently, we devise a weight calculation strategy based on boundary division. Minority class instances are classified into safe and boundary instances, and weights are calculated based on the density of each instance and its distance from the surrounding instances, assigning different weights to overlapping and non-overlapping regions, and sparse and dense region instances, in order to solve the problems of class overlap and intra-class imbalance. Finally, GAN is used to construct a balanced dataset by adaptively generating minority class instances that match the real data distribution based on the weights. We evaluate AWGAN against six traditional oversampling methods and five GAN-based oversampling methods. The experimental results demonstrate that AWGAN significantly enhances classifier performance, as evident in its F1-Score, AUC, G-mean, and MCC on 21 diverse datasets. © 2024 Elsevier Inc.},
	journal = {Information Sciences},
	author = {Guan, S. and Zhao, X. and Xue, Y. and Pan, H.},
	year = {2024},
	keywords = {Generative adversarial networks, Imbalanced dataset, Intra-class imbalance, Overlapping, Oversampling technique},
}

@article{121,
	title = {{ConvGeN}: {A} convex space learning approach for deep-generative oversampling and imbalanced classification of small tabular datasets},
	volume = {147},
	shorttitle = {{ConvGeN}},
	doi = {10.1016/j.patcog.2023.110138},
	abstract = {Oversampling is commonly used to improve classifier performance for small tabular imbalanced datasets. State-of-the-art linear interpolation approaches can be used to generate synthetic samples from the convex space of the minority class. Generative networks are common deep learning approaches for synthetic sample generation. However, their scope on synthetic tabular data generation in the context of imbalanced classification is not adequately explored. In this article, we show that existing deep generative models perform poorly compared to linear interpolation-based approaches for imbalanced classification problems on small tabular datasets. To overcome this, we propose a deep generative model, ConvGeN that combines the idea of convex space learning with deep generative models. ConvGeN learns coefficients for the convex combinations of the minority class samples, such that the synthetic data is distinct enough from the majority class. Our benchmarking experiments demonstrate that our proposed model ConvGeN improves imbalanced classification on such small datasets, as compared to existing deep generative models, while being on par with the existing linear interpolation approaches. Moreover, we discuss how our model can be used for synthetic tabular data generation in general, even outside the scope of data imbalance, and thus improves the overall applicability of convex space learning. © 2023 Elsevier Ltd},
	journal = {Pattern Recognition},
	author = {Schultz, K. and Bej, S. and Hahn, W. and Wolfien, M. and Srivastava, P. and Wolkenhauer, O.},
	year = {2024},
	keywords = {Convex space learning, GAN, Imbalanced data, LoRAS, Tabular data},
}

@article{120,
	title = {Generative adversarial minority enlargement—{A} local linear over-sampling synthetic method},
	volume = {237},
	doi = {10.1016/j.eswa.2023.121696},
	abstract = {The imbalanced data problem is widely recognized in real-world datasets. To avoid learning bias on imbalanced data, the over-sampling strategy is well studied and adopted for generating synthetic minority samples. Wherein, the Synthetic Minority Over-sampling Technology and its improved algorithms become standard baselines. In recent years, the popular Generative Adversarial Networks and its enhanced variants, introduced from the computer vision community, are believed to generate better samples, by approximating the true data distribution. Yet, we notice that the synthetic samples for the minority category in these existing methods is usually restrained in a limited samples space known in advance, which may mislead the classifiers trained on them to take data in the unsampled region of the minority category as from the majority category. Given such limitations, we propose a Generative Adversarial Minority Enlargement (GAME) method to intentionally extend the sampling margin during data generative and adversarial phases. This is accomplished by adjusting the parameters of a local linear model to approach the majority category. We conduct an extensive evaluation on 28 datasets of different domains, extracted from the UCI real-world datasets. The results show that GAME can achieve more balanced and stable results efficiently than 18 state-of-the-art methods. © 2023 Elsevier Ltd},
	journal = {Expert Systems with Applications},
	author = {Wang, K. and Zhou, T. and Luo, M. and Li, X. and Cai, Z.},
	year = {2024},
	keywords = {Generative adversarial model, Imbalanced data problem, Local linear property of samples, Over-sampling strategy, Synthetic numerical samples},
}

@article{119,
	title = {Discriminative boundary generation for effective outlier detection},
	volume = {66},
	doi = {10.1007/s10115-023-02012-3},
	abstract = {Outlier detection is often considered a challenge due to the inherent class imbalance in datasets, with the small number of available outliers that are insufficient to describe their overall distribution. This makes it difficult for classifiers to effectively learn the demarcation (boundary) between normal samples and outliers, which is the key for accurate detection. In this paper, we propose a novel discriminative boundary generation framework, called BoG. The framework extracts the border samples in the dataset and expands them to form the initial boundary outliers. With the adversarial training in GAN, the boundary outliers are further augmented, which, together with the boundary normal data, provides the valuable demarcation information for the classifier. Two method variants are proposed under our BoG framework to achieve a balance between detection efficiency and effectiveness. Extensive experiments show that our proposed framework achieves significant improvements compared to the existing outlier detection methods. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.},
	number = {5},
	journal = {Knowledge and Information Systems},
	author = {Zhang, J. and Liang, Q. and Bah, M.J. and Li, H. and Chang, L. and Kiran, R.U.},
	year = {2024},
	keywords = {Boundary generation, GAN, Outlier detection},
	pages = {2987--3004},
}

@article{118,
	title = {An improved generative adversarial network to oversample imbalanced datasets},
	volume = {132},
	doi = {10.1016/j.engappai.2024.107934},
	abstract = {Many oversampling methods applied to imbalanced data generate samples according to local density distribution of minority samples. However, samples generated by these methods can only present a non-deterministic relationship between the local and global distributions. A generative adversarial network (GAN) is a suitable tool to learn an unknown global probability distribution. In this paper, we propose an improved GAN (I-GAN) to oversample according to the global underlying structure of minority samples. The originality of I-GAN stems from the fact it provides additional density distribution information of minority samples for GAN and generated samples. By building on this idea, three detailed strategies are presented: input random vectors of the generator are sampled from a rough estimate of the distribution of minority samples to orientate fake samples more believable; a residual about minority samples is added into the discriminator to strengthen the constraint of loss function; generated samples are redistributed with a reshaper. These three strategies provide innovative methodologies at various stages of GANs for the oversampling task. Compared with 22 classical and popular imbalanced sampling methods under metrics of Gm, F1, and AUC on 24 benchmark imbalanced datasets, it is shown that I-GAN is effective and robust. The I-GAN implementation line procedure has been uploaded to Github (https://github.com/flowerbloom000/I-GAN). © 2024},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Pan, T. and Pedrycz, W. and Yang, J. and Wang, J.},
	year = {2024},
	keywords = {Generative adversarial network (GAN), Imbalanced learning, Oversampling, Probability distribution},
}

@article{117,
	title = {Applying data augmentation technique on blast-induced overbreak prediction: {Resolving} the problem of data shortage and data imbalance},
	volume = {237},
	shorttitle = {Applying data augmentation technique on blast-induced overbreak prediction},
	doi = {10.1016/j.eswa.2023.121616},
	abstract = {Blast-induced overbreak in tunnels can cause severe damage and has therefore been a main concern in tunnel blasting. Researchers have developed many machine learning-based models to predict overbreak. Collecting overbreak data manually, however, can be challenging and might obtain insufficient or poorly structured data. Thus, this study aims to utilise a deep generative model, namely the Conditional Tabular Generative Adversarial Network (CTGAN), to establish an acceptable dataset for overbreak prediction. The CTGAN model was applied to overbreak data collected from paired tunnels: a left-line tunnel and a right-line tunnel. The overbreak dataset collected from the left-line tunnel—nominated as the true dataset—served to train the CTGAN model. Then the well-trained CTGAN model generated a synthetic overbreak dataset. Statistical-based approaches verified the similarity between the true and synthetic datasets; machine learning-based approaches verified the feasibility of using the synthetic dataset to train overbreak prediction model. Lastly, this study clarified how to resolve the problem of data shortage and data imbalance by leveraging the CTGAN model. The results evidence that the CTGAN model can effectively generate a high-quality synthetic overbreak dataset. The synthetic overbreak dataset not only greatly retains the properties of the true dataset but also effectively enhances its diversity. The way, integrating the true and synthetic overbreak datasets, can dramatically resolve the problem of data shortage and data imbalance in overbreak prediction. The findings in this study, therefore, highlight it as a promising perspective to resolve such a particular engineering problem. © 2023 Elsevier Ltd},
	journal = {Expert Systems with Applications},
	author = {He, B. and Jahed Armaghani, D. and Hin Lai, S. and Samui, P. and Tonnizam Mohamad, E.},
	year = {2024},
	keywords = {CTGAN, Data augmentation, Environmental issue, Machine learning, Overbreak, Tunnel blasting},
}

@article{116,
	title = {Fault {Diagnosis} {Method} of {Box}-{Type} {Substation} {Based} on {Improved} {Conditional} {Tabular} {Generative} {Adversarial} {Network} and {AlexNet}},
	volume = {14},
	doi = {10.3390/app14073112},
	abstract = {To solve the problem of low diagnostic accuracy caused by the scarcity of fault samples and class imbalance in the fault diagnosis task of box-type substations, a fault diagnosis method based on self-attention improvement of conditional tabular generative adversarial network (CTGAN) and AlexNet was proposed. The self-attention mechanism is introduced into the generator of CTGAN to maintain the correlation between the indicators of the input data, and a large amounts of high-quality data are generated according to the small number of fault samples. The generated data are input into the AlexNet model for fault diagnosis. The experimental results demonstrate that compared with the SMOTE and CTGAN methods, the dataset generated by the self-attention-conditional tabular generative adversarial network (SA-CTGAN) model has better data relevance. The accuracy of fault diagnosis by the proposed method reaches 94.81\%, which is improved by about 11\% compared with the model trained on the original data. © 2024 by the authors.},
	number = {7},
	journal = {Applied Sciences (Switzerland)},
	author = {Liu, Y. and Zhou, J. and Zhang, D. and Wei, S. and Yang, M. and Gao, X.},
	year = {2024},
	keywords = {box-type substation, fault diagnosis, generative adversarial networks, self-attention mechanism},
}

@article{115,
	title = {A distributed approach to meteorological predictions: addressing data imbalance in precipitation prediction models through federated learning and {GANs}},
	volume = {21},
	shorttitle = {A distributed approach to meteorological predictions},
	doi = {10.1007/s10287-024-00504-3},
	abstract = {The classification of weather data involves categorizing meteorological phenomena into classes, thereby facilitating nuanced analyses and precise predictions for various sectors such as agriculture, aviation, and disaster management. This involves utilizing machine learning models to analyze large, multidimensional weather datasets for patterns and trends. These datasets may include variables such as temperature, humidity, wind speed, and pressure, contributing to meteorological conditions. Furthermore, it’s imperative that classification algorithms proficiently navigate challenges such as data imbalances, where certain weather events (e.g., storms or extreme temperatures) might be underrepresented. This empirical study explores data augmentation methods to address imbalanced classes in tabular weather data in centralized and federated settings. Employing data augmentation techniques such as the Synthetic Minority Over-sampling Technique or Generative Adversarial Networks can improve the model’s accuracy in classifying rare but critical weather events. Moreover, with advancements in federated learning, machine learning models can be trained across decentralized databases, ensuring privacy and data integrity while mitigating the need for centralized data storage and processing. Thus, the classification of weather data stands as a critical bridge, linking raw meteorological data to actionable insights, enhancing our capacity to anticipate and prepare for diverse weather conditions. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.},
	number = {1},
	journal = {Computational Management Science},
	author = {Jafarigol, E. and Trafalis, T.B.},
	year = {2024},
	keywords = {Deep learning, Federated learning, Generative Adversarial Networks, Imbalanced learning, Weather prediction},
}

@article{114,
	title = {An intra-class distribution-focused generative adversarial network approach for imbalanced tabular data learning},
	volume = {15},
	doi = {10.1007/s13042-023-02048-5},
	abstract = {Data imbalance is a critical factor that adversely affects the performance of machine learning algorithms. It leads to deviations in decision boundaries, resulting in biased predictions towards the majority class and inaccurate classification of the minority class. Although oversampling the minority class using deep generative models is a popular strategy, many existing methods focus solely on enhancing data for the minority class while overlooking the distribution relationship within and between classes. Therefore, we propose an oversampling method that merges unsupervised clustering and generative adversarial network (GAN) to facilitate the imbalanced tabular data learning. First, we perform preprocessing (clustering) on the original data, remove clusters that do not require sampling and generate more samples for sparsely distributed minority class clusters to achieve sample balance within the minority class. Moreover, we design a CTGAN-based auxiliary classifier GAN (ACCTGAN) to generate the minority class. It enhances the semantic integrity of the synthetic data and avoids generating noisy samples. We conducted validation experiments comparing our approach to 7 typical methods on 12 real tabular datasets. Our method shows excellent performance in F1-measure and area under the curve (AUC), obtaining 19 and 20 best results on the three classifiers, respectively. It significantly enhances classification results and demonstrates good robustness and stability. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.},
	number = {7},
	journal = {International Journal of Machine Learning and Cybernetics},
	author = {Chen, Q. and Ye, A. and Zhang, Y. and Chen, J. and Huang, C.},
	year = {2024},
	keywords = {Clustering, Generative adversarial network, Imbalanced data learning, Oversampling},
	pages = {2551--2572},
}

@article{113,
	title = {Enhancing network intrusion detection: a dual-ensemble approach with {CTGAN}-balanced data and weak classifiers},
	volume = {80},
	shorttitle = {Enhancing network intrusion detection},
	doi = {10.1007/s11227-024-06108-7},
	abstract = {With the expansion of the Internet, Internet of Things devices, and related services, effective intrusion detection systems are vital in cybersecurity. This study presents a significant advancement in cybersecurity by leveraging ensemble learning techniques alongside generative adversarial networks, proposing a novel framework for network behavior classification using the UNSW-NB15 dataset. Similar to any other real-world dataset, the UNSW-NB15 dataset poses inherent challenges of data imbalance, with significantly fewer instances of intrusion compared to normal network behavior. Our main contribution to the existing literature is the introduction of a conditional tabular generative adversarial network (CTGAN), aimed at addressing the existing issue of data imbalance in the dataset. In previous approaches, this issue was often overlooked; however, the proposed framework achieves a substantial improvement in model performance by balancing this dataset. Through training three shallow binary classification algorithms (decision trees, logistic regression, and Gaussian naive Bayes) on both the CTGAN-balanced data and the original imbalanced dataset, we uncover remarkable improvements in identifying network intrusion. Our study employs a novel two-stage label-wise ensembling process, notably resulting in a final XGBoost meta-classifier. The ultimate achievement of our framework demonstrates 98\% accuracy for binary classification and 95\% for multi-class classification, outperforming existing state-of-the-art models. By offering a robust framework for effective intrusion detection, this work marks a substantial step forward in addressing data imbalance challenges within the UNSW-NB15 dataset. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	number = {11},
	journal = {Journal of Supercomputing},
	author = {Soflaei, M.R.A.B. and Salehpour, A. and Samadzamini, K.},
	year = {2024},
	keywords = {Conditional tabular generative adversarial network (CTGAN), Ensemble learning, Machine learning, Network intrusion detection},
	pages = {16301--16333},
}

@article{112,
	title = {Utilizing {GANs} for {Credit} {Card} {Fraud} {Detection}: {A} {Comparison} of {Supervised} {Learning} {Algorithms}},
	volume = {13},
	shorttitle = {Utilizing {GANs} for {Credit} {Card} {Fraud} {Detection}},
	doi = {10.48084/etasr.6434},
	abstract = {The evolution and improvements in electronic commerce and communications around the world have stimulated credit card use. With the support of smartphone wallets, electronic payments have become the most popular payment method for personal and business use; however, the past few years have also seen a major increase in fraudulent transactions. Corporations and individuals experience very negative impacts from such fraud. Therefore, fraud detection systems have received a lot of attention recently from major financial institutions. This paper proposes a fraud detection approach that deals with small and imbalanced datasets using Generative Adversarial Networks (GANs) for sample generation. Six machine-learning algorithms were applied to real-world data. The accuracy of all six algorithms was above 85\% and the precision was above 95\%. Five of the six algorithms had a recall score greater than 90\%. Furthermore, the Receiver Operating Characteristics (ROC), which measure performance at different thresholds, demonstrated scores greater than 0.90, except Naïve Bayes, which scored 0.81. The proposed approach outperformed the same algorithms in other studies. © 2023, Dr D. Pylarinos. All rights reserved.},
	number = {6},
	journal = {Engineering, Technology and Applied Science Research},
	author = {Alshawi, B.},
	year = {2023},
	keywords = {credit card fraud, decision tree, fraud detection, generative adversarial network, imbalance datasets, naive bayes, supervised learning},
	pages = {12264--12270},
}

@article{111,
	title = {Exploring the {Potential} of {GANs} in {Biological} {Sequence} {Analysis}},
	volume = {12},
	doi = {10.3390/biology12060854},
	abstract = {Biological sequence analysis is an essential step toward building a deeper understanding of the underlying functions, structures, and behaviors of the sequences. It can help in identifying the characteristics of the associated organisms, such as viruses, etc., and building prevention mechanisms to eradicate their spread and impact, as viruses are known to cause epidemics that can become global pandemics. New tools for biological sequence analysis are provided by machine learning (ML) technologies to effectively analyze the functions and structures of the sequences. However, these ML-based methods undergo challenges with data imbalance, generally associated with biological sequence datasets, which hinders their performance. Although various strategies are present to address this issue, such as the SMOTE algorithm, which creates synthetic data, however, they focus on local information rather than the overall class distribution. In this work, we explore a novel approach to handle the data imbalance issue based on generative adversarial networks (GANs), which use the overall data distribution. GANs are utilized to generate synthetic data that closely resembles real data, thus, these generated data can be employed to enhance the ML models’ performance by eradicating the class imbalance problem for biological sequence analysis. We perform four distinct classification tasks by using four different sequence datasets (Influenza A Virus, PALMdb, VDjDB, Host) and our results illustrate that GANs can improve the overall classification performance. © 2023 by the authors.},
	number = {6},
	journal = {Biology},
	author = {Murad, T. and Ali, S. and Patterson, M.},
	year = {2023},
	keywords = {GANs, bio-sequence analysis, class imbalance, sequence classification},
}

@article{110,
	title = {A clustering and generative adversarial networks-based hybrid approach for imbalanced data classification},
	volume = {14},
	doi = {10.1007/s12652-023-04610-z},
	abstract = {Imbalanced data often exists in related fields such as banking, insurance, security and medical care. The imbalanced distribution of data will lead to the deviation of decision-making, making it easy for a small number of samples to be divided incorrectly. Therefore, as a challenging task, imbalanced data classification has attracted extensive research in many disciplines. In this study, we propose a method based on the combination of clustering and generative adversarial network (GAN) to deal with the problem of imbalanced data classification. Firstly, we divide the majority class samples into three types according to the K-nearest neighbor algorithm. Secondly, undersampling is performed on the three types of data in the majority class through the clustering method. Then, a GAN model for tabular data generation is designed for oversampling of minority class samples. Finally, the preprocessed majority and minority data are used to train the machine learning model. We used real-world data sets to conduct relevant test experiments. The experimental results show that the imbalanced data processed by the method in this paper have achieved excellent results in the two evaluation indicators of the three common classification methods. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
	number = {6},
	journal = {Journal of Ambient Intelligence and Humanized Computing},
	author = {Ding, H. and Cui, X.},
	year = {2023},
	keywords = {Imbalanced data, Oversampling, TWGAN-GP, Undersampling},
	pages = {8003--8018},
}

@article{109,
	title = {A {Wasserstein} {Generative} {Adversarial} {Network}–{Gradient} {Penalty}-{Based} {Model} with {Imbalanced} {Data} {Enhancement} for {Network} {Intrusion} {Detection}},
	volume = {13},
	doi = {10.3390/app13148132},
	abstract = {In today’s network intrusion detection systems (NIDS), certain types of network attack packets are sparse compared to regular network packets, making them challenging to collect, and resulting in significant data imbalances in public NIDS datasets. With respect to attack types with rare data, it is difficult to classify them, even by using various algorithms such as machine learning and deep learning. To address this issue, this study proposes a data augmentation technique based on the WGAN-GP model to enhance the recognition accuracy of sparse attacks in network intrusion detection. The enhanced performance of the WGAN-GP model on sparse attack classes is validated by evaluating three sparse data generation methods, namely Gaussian noise, WGAN-GP, and SMOTE, using the NSL-KDD dataset. Additionally, machine learning algorithms, including KNN, SVM, random forest, and XGBoost, as well as neural network models such as multilayer perceptual neural networks (MLP) and convolutional neural networks (CNN), are applied to classify the enhanced NSL-KDD dataset. Experimental results revealed that the WGAN-GP generation model is the most effective for detecting sparse data probes. Furthermore, a two-stage fine-tuning algorithm based on the WGAN-GP model is developed, fine-tuning the classification algorithms and model parameters to optimize the recognition accuracy of the sparse data probes. The final experimental results demonstrate that the MLP classifier significantly increases the accuracy rate from 74\% to 80\% after fine tuning, surpassing all other classifiers. The proposed method exhibits a 10\%, 7\%, and 13\% improvement over untuned Gaussian noise enhancement, untuned SMOTE enhancement, and no enhancement. © 2023 by the authors.},
	number = {14},
	journal = {Applied Sciences (Switzerland)},
	author = {Lee, G.-C. and Li, J.-H. and Li, Z.-Y.},
	year = {2023},
	keywords = {convolutional neural networks, generative adversarial networks, imbalanced data, machine learning, network intrusion detection},
}

@article{108,
	title = {Synthesizing credit data using autoencoders and generative adversarial networks},
	volume = {274},
	doi = {10.1016/j.knosys.2023.110646},
	abstract = {Data quality is an essential element necessary for the development of a successful machine-learning project. One of the biggest challenges in various real-world application domains is class imbalance. This paper proposes a new framework for oversampling credit data by combining two deep learning techniques: autoencoders and generative adversarial networks. A trivial autoencoder (TAE) is used to change data representation, and modified generative adversarial networks (GAN) are used to create new instances from random noise. The experiment on three different datasets demonstrates that the same classifier achieves a better area under the receiver operating characteristic curve (AUC) on datasets augmented by the proposed framework compared to datasets oversampled by other techniques. Additionally, the results show that datasets balanced by the new framework influence the classifier to change the prediction error types, significantly reducing false negatives; more expensive misclassification case in the imbalance learning. The improvements are significant, and considering the change in error distribution, the proposed technique is an excellent complement to existing oversampling techniques. © 2023 Elsevier B.V.},
	journal = {Knowledge-Based Systems},
	author = {Oreski, G.},
	year = {2023},
	keywords = {Autoencoders, Credit risk data, Generative adversarial networks, Tabular data},
}

@article{107,
	title = {{EvaGoNet}: {An} integrated network of variational autoencoder and {Wasserstein} generative adversarial network with gradient penalty for binary classification tasks},
	volume = {629},
	shorttitle = {{EvaGoNet}},
	doi = {10.1016/j.ins.2023.01.133},
	abstract = {Feature engineering is an effective method for solving classification problems. Many existing feature engineering studies have focused on image or video data and not on structured data. This study proposes EvaGoNet, which refines the decoder module of the Gaussian mixture variational autoencoder using the Wasserstein generative adversarial network with gradient penalty (WGANgp) and embeds the top-ranked original features to update the latent features based on their discriminative powers. Comprehensive experiments show that EvaGoNet-encoded features outperform existing classifiers on 12 benchmark datasets, particularly on the small, imbalanced datasets col (accuracy = 0.8581), spe (accuracy = 1.0000), and leu (accuracy = 0.8021). EvaGoNet-engineered features improve binary classification task outcomes on six high-dimensional, imbalanced bioOMIC datasets. EvaGoNet achieves a medium-ranked training speed among the compared algorithms and considerably fast prediction speeds in the predictions of the testing samples. Therefore, EvaGoNet can be a candidate feature engineering framework for many practical applications that require one training procedure and many prediction tasks of the testing samples. EvaGoNet is implemented in Python TensorFlow and is available at https://healthinformaticslab.org/supp/resources.php. © 2023 Elsevier Inc.},
	journal = {Information Sciences},
	author = {Luo, C. and Xu, Y. and Shao, Y. and Wang, Z. and Hu, J. and Yuan, J. and Liu, Y. and Duan, M. and Huang, L. and Zhou, F.},
	year = {2023},
	keywords = {EvaGoNet, Feature engineering, Gaussian mixture VAE, VAE, WGANgp, bioOMIC data.},
	pages = {109--122},
}

@article{106,
	title = {An ensemble oversampling method for imbalanced classification with prior knowledge via generative adversarial network},
	volume = {235},
	doi = {10.1016/j.chemolab.2023.104775},
	abstract = {Currently, an increasing number of real-world applications show characteristics of class-imbalance classification suffering from severe class distribution skewing, thus requiring brand new algorithms to learn from imbalanced datasets. In this paper, a novel oversampling method using GAN framework is proposed for numerical imbalanced data, namely G-GAN. In the method, a Gaussian distribution of minority samples is estimated to get prior knowledge of minority class for the latent space of GAN. In order to increase the randomness of the generated samples, noises are obtained by a mixed strategy, that is, some noises of generator obey Gaussian distribution and others obey random distribution. Then G-GAN is trained to generate dispersive positive samples with the idea of Bagging, which could avoid the occurrence of overfitting. G-GAN is different from other literatures in that GAN does not directly generate minority samples, but adds the distribution information of minority samples to the latent space of GAN, and then generates minority samples. Compared with 11 commonly used oversampling methods, G-GAN obtains promising results in terms of G-mean, AUC, F-measure and ROC utilizing three classifiers on 11 benchmark imbalanced datasets. Furthermore, G-GAN is also validated on AUC metrics of a real Diabetes imbalanced dataset. The results demonstrate that G-GAN can provide great potential for imbalanced classification in the two numerical experiments. © 2023 Elsevier B.V.},
	journal = {Chemometrics and Intelligent Laboratory Systems},
	author = {Zhang, Y. and Liu, Y. and Wang, Y. and Yang, J.},
	year = {2023},
	keywords = {Bagging, Generative adversarial network, Imbalanced data, Oversampling},
}

@article{105,
	title = {{RVGAN}-{TL}: {A} generative adversarial networks and transfer learning-based hybrid approach for imbalanced data classification},
	volume = {629},
	shorttitle = {{RVGAN}-{TL}},
	doi = {10.1016/j.ins.2023.01.147},
	abstract = {Imbalanced data distribution is the main reason for the performance degradation of most supervised classification algorithms. When dealing with imbalanced learning problems, the prediction of traditional classifiers tends to favor the majority class and ignore the minority class which is often much more important. Therefore, it is necessary to balance majority data and minority data before classification. A popular strategy for balancing the two data classes is synthesizing minority data. In recent years, generative adversarial networks (GAN) have shown great potential in fitting sample distributions. Based on this, this paper proposes a model combining improved GAN and transfer learning, RVGAN-TL, to solve the imbalanced learning problem of tabular data. As for the improvement of GAN, variational autoencoder (VAE) is used to generate latent variables with a posterior distribution as the input of GAN, and similarity measure loss is introduced into the generator to improve the quality of the minority data generated by GAN. In addition, a roulette wheel selection method is applied to the training data selection in GAN to rebalance data in the overlapping area. When data is balanced, the generated data is used as the source domain and the original data as the target domain, and the transfer learning method is used to train the final classifier. Experiments on 20 real datasets show that the classification performance of the proposed method is significantly improved compared with other popular methods. © 2023 Elsevier Inc.},
	journal = {Information Sciences},
	author = {Ding, H. and Sun, Y. and Huang, N. and Shen, Z. and Wang, Z. and Iftekhar, A. and Cui, X.},
	year = {2023},
	keywords = {Generative adversarial networks, Imbalanced data, Roulette wheel selection, Transfer learning},
	pages = {184--203},
}

@article{104,
	title = {Evaluation of {Synthetic} {Categorical} {Data} {Generation} {Techniques} for {Predicting} {Cardiovascular} {Diseases} and {Post}-{Hoc} {Interpretability} of the {Risk} {Factors}},
	volume = {13},
	doi = {10.3390/app13074119},
	abstract = {Machine Learning (ML) methods have become important for enhancing the performance of decision-support predictive models. However, class imbalance is one of the main challenges for developing ML models, because it may bias the learning process and the model generalization ability. In this paper, we consider oversampling methods for generating synthetic categorical clinical data aiming to improve the predictive performance in ML models, and the identification of risk factors for cardiovascular diseases (CVDs). We performed a comparative study of several categorical synthetic data generation methods, including Synthetic Minority Oversampling Technique Nominal (SMOTEN), Tabular Variational Autoencoder (TVAE) and Conditional Tabular Generative Adversarial Networks (CTGANs). Then, we assessed the impact of combining oversampling strategies and linear and nonlinear supervised ML methods. Lastly, we conducted a post-hoc model interpretability based on the importance of the risk factors. Experimental results show the potential of GAN-based models for generating high-quality categorical synthetic data, yielding probability mass functions that are very close to those provided by real data, maintaining relevant insights, and contributing to increasing the predictive performance. The GAN-based model and a linear classifier outperform other oversampling techniques, improving the area under the curve by 2\%. These results demonstrate the capability of synthetic data to help with both determining risk factors and building models for CVD prediction. © 2023 by the authors.},
	number = {7},
	journal = {Applied Sciences (Switzerland)},
	author = {García-Vicente, C. and Chushig-Muzo, D. and Mora-Jiménez, I. and Fabelo, H. and Gram, I.T. and Løchen, M.-L. and Granja, C. and Soguero-Ruiz, C.},
	year = {2023},
	keywords = {CTGAN, cardiovascular disease, generative adversarial networks, imbalance learning, interpretable machine learning, synthetic categorical data generation},
}

@article{103,
	title = {Enhancing {Financial} {Fraud} {Detection} through {Addressing} {Class} {Imbalance} {Using} {Hybrid} {SMOTE}-{GAN} {Techniques}},
	volume = {11},
	doi = {10.3390/ijfs11030110},
	abstract = {The class imbalance problem in finance fraud datasets often leads to biased prediction towards the nonfraud class, resulting in poor performance in the fraud class. This study explores the effects of utilizing the Synthetic Minority Oversampling TEchnique (SMOTE), a Generative Adversarial Network (GAN), and their combinations to address the class imbalance issue. Their effectiveness was evaluated using a Feed-forward Neural Network (FNN), Convolutional Neural Network (CNN), and their hybrid (FNN+CNN). This study found that regardless of the data generation techniques applied, the classifier’s hyperparameters can affect classification performance. The comparisons of various data generation techniques demonstrated the effectiveness of the hybrid SMOTE and GAN, including SMOTified-GAN, SMOTE+GAN, and GANified-SMOTE, compared with SMOTE and GAN. The SMOTified-GAN and the proposed GANified-SMOTE were able to perform equally well across different amounts of generated fraud samples. © 2023 by the authors.},
	number = {3},
	journal = {International Journal of Financial Studies},
	author = {Cheah, P.C.Y. and Yang, Y. and Lee, B.G.},
	year = {2023},
	keywords = {class imbalance, data generation, deep learning, financial fraud detection},
}

@article{102,
	title = {Addressing the class imbalance in tabular datasets from a generative adversarial network approach in supervised machine learning},
	volume = {17},
	doi = {10.1177/17483026231215186},
	abstract = {One common issue with datasets used for supervised classification tasks is data imbalance or the unequal distribution of classes within a dataset. The class imbalance may cause biased machine learning models to favor the dominant class, misclassifying the minority class. Specific techniques can be employed to deal with the issue of class imbalance, including resampling by oversampling or undersampling and ensemble approaches. Besides, generative adversarial networks, a deep learning technique for building generative models, offer an alternative machine learning technique that is particularly well suited to address the class imbalance problem. This work introduces a machine learning-based approach to deal with the class imbalance in a cancer intracellular signaling dataset produced by a verified and validated computer simulation. Specifically, we use synthetic data generation to increase and balance the dataset generated by the computational simulation. The used approach simulates the oversampling method by employing a generative adversarial network to produce new examples for the minority class. Subsequently, we applied supervised machine learning methods, such as the K-NN algorithm, to assess whether or not the classification accuracy improved relative to the unbalanced dataset. The results presented in this work have shown an accuracy increase in the classification of patterns belonging to the minority class, with an improvement of (Formula presented.). © The Author(s) 2023.},
	journal = {Journal of Algorithms and Computational Technology},
	author = {Sánchez-Gutiérrez, M.E. and González-Pérez, P.P.},
	year = {2023},
	keywords = {Cancer cell signaling dataset, K-NN algorithm, class imbalance, generative adversarial networks, supervised classification},
}

@article{94,
	title = {Oversampling based on generative adversarial networks to overcome imbalance data in predicting fraud insurance claim},
	volume = {49},
	doi = {10.48129/kjs.splml.19119},
	abstract = {Fraud on health insurance impacts cost overruns and a quality decline in health services in the long term. The use of machine learning to detect fraud on health insurance is increasingly popular. However, one challenge in predicting health insurance fraud is the data imbalance. The data imbalance can cause a bias towards the majority class in many machine learning methods. Oversampling is a solution for data imbalance by augmenting new data based on the existing minority class data. Recently, there has been growing interest in employing deep learning for data augmentation. One of them is using Generative Adversarial Networks (GAN). This paper proposes using GAN as an oversampling method to generate additional data for minority classes. Since data for detecting health insurance fraud are tabular, we adopt Conditional Tabular GAN (CTGAN) architecture where the generator is conditioned to adjust the tabular data input and receive additional information to produce samples according to the specified class conditions. The new balanced data are used to train 17 classification algorithms. Our experiments showed that the proposed method performs better than other oversampling methods on several evaluation metrics, i.e., accuracy, precision score, F1-score, and ROC. © 2022 University of Kuwait. All rights reserved.},
	journal = {Kuwait Journal of Science},
	author = {Nugraha, R.A. and Pardede, H.F. and Subekti, A.},
	year = {2022},
	keywords = {Fraud insurance detection, generative adversarial networks, imbalance data, oversampling, tabular GAN},
}

@article{101,
	title = {Improving {Classification} {Performance} in {Credit} {Card} {Fraud} {Detection} by {Using} {New} {Data} {Augmentation}},
	volume = {4},
	doi = {10.3390/ai4010008},
	abstract = {In many industrialized and developing nations, credit cards are one of the most widely used methods of payment for online transactions. Credit card invention has streamlined, facilitated, and enhanced internet transactions. It has, however, also given criminals more opportunities to commit fraud, which has raised the rate of fraud. Credit card fraud has a concerning global impact; many businesses and ordinary users have lost millions of US dollars as a result. Since there is a large number of transactions, many businesses and organizations rely heavily on applying machine learning techniques to automatically classify or identify fraudulent transactions. As the performance of machine learning techniques greatly depends on the quality of the training data, the imbalance in the data is not a trivial issue. In general, only a small percentage of fraudulent transactions are presented in the data. This greatly affects the performance of machine learning classifiers. In order to deal with the rarity of fraudulent occurrences, this paper investigates a variety of data augmentation techniques to address the imbalanced data problem and introduces a new data augmentation model, K-CGAN, for credit card fraud detection. A number of the main classification techniques are then used to evaluate the performance of the augmentation techniques. These results show that B-SMOTE, K-CGAN, and SMOTE have the highest Precision and Recall compared with other augmentation methods. Among those, K-CGAN has the highest F1 Score and Accuracy. © 2023 by the authors. Licensee MDPI, Basel, Switzerland..},
	number = {1},
	journal = {AI (Switzerland)},
	author = {Strelcenia, E. and Prakoonwit, S.},
	year = {2023},
	keywords = {B-SMOTE, GANs, K-CGAN, SMOTE, credit cards, data augmentation, fraud detection, fraud transactions, imbalanced data},
	pages = {172--198},
}

@article{100,
	title = {{MCGAN}: {Modified} {Conditional} {Generative} {Adversarial} {Network} ({MCGAN}) for {Class} {Imbalance} {Problems} in {Network} {Intrusion} {Detection} {System}},
	volume = {13},
	shorttitle = {{MCGAN}},
	doi = {10.3390/app13042576},
	abstract = {With developing technologies, network security is critical, predominantly active, and distributed ad hoc in networks. An intrusion detection system (IDS) plays a vital role in cyber security in detecting malicious activities in network traffic. However, class imbalance has triggered a challenging issue where many instances of some classes are more than others. Therefore, traditional classifiers suffer in classifying malicious activities and result in low robustness to unidentified glitches. This paper introduces a novel technique based on a modified conditional generative adversarial network (MCGAN) to address the class imbalance problem. The proposed MCGAN handles the class imbalance issue by generating oversamples to balance the minority and majority classes. Then, the Bi-LSTM technique is incorporated to classify the multi-class intrusion efficiently. This formulated model is experimented on using the NSL-KDD+ dataset with the aid of accuracy, precision, recall, FPR, and F-score to validate the efficacy of the proposed system. The simulation results of the proposed method are associated with other existing models. It achieved an accuracy of 95.16\%, precision of 94.21\%, FPR of 2.1\%, and F1-score of 96.7\% for the NSL-KDD+ dataset with 20 selected features. © 2023 by the authors.},
	number = {4},
	journal = {Applied Sciences (Switzerland)},
	author = {Babu, K.S. and Rao, Y.N.},
	year = {2023},
	keywords = {NSL-KDD dataset, accuracy, class imbalance problem, deep convolution generative adversarial network, intrusion detection system},
}

@article{99,
	title = {{FinGAN}: {Chaotic} generative adversarial network for analytical customer relationship management in banking and insurance},
	volume = {35},
	shorttitle = {{FinGAN}},
	doi = {10.1007/s00521-022-07968-x},
	abstract = {Credit card churn prediction, insurance fraud detection, and loan default prediction are all critical analytical customer relationship management (ACRM) problems. Since these events occur infrequently, datasets for these problems are highly unbalanced. Consequently, when trained on such unbalanced datasets, all machine learning classifiers tend to produce high false positive rates. We propose two methods for data balancing. To oversample the minority class, we proposed an innovative GAN called chaoticGAN, where we employed chaotic noise as input for the generator. We also employed the traditional GAN (Goodfellow et al. in Adv Neural Inf Process Syst, 2014. https://doi.org/10.1145/3422622), Wasserstein GAN (Arjovsky et al. in Wasserstein GAN, 2017. https://arxiv.org/abs/1701.07875), and CTGAN (Xu et al. in Modeling Tabular Data using Conditional GAN. https://arxiv.org/pdf/1907.00503) independently for baseline comparison. On the data balanced by GANs, we employed a host of machine learning classifiers, including Random Forest, Decision Tree, Support Vector Machine (SVM), Logistic Regression (LR), multi-layer perceptron (MLP) and Light gradient boosting machine (LGBM) to demonstrate the efficacy of our approaches. In the second approach, we augment the oversampled synthetic minority class data obtained by GAN and its variants with the undersampled majority class data obtained by one class support vector machine (OCSVM) (Tax et al. in Mach Learn 54:45–66, 2014). We passed the entire modified dataset to build the classifiers. Our proposed approaches outperform earlier studies on the same datasets in terms of the area under the ROC curve (AUC). Further, our proposed chaoticGAN and its hybrid turned out to be statistically similar to the state-of-the-art CTGAN on all datasets while being significant over other methods w.r.t AUC over tenfold cross-validation. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.},
	number = {8},
	journal = {Neural Computing and Applications},
	author = {Kate, P. and Ravi, V. and Gangwar, A.},
	year = {2023},
	keywords = {Chaotic generative adversarial network, Churn prediction, Default prediction, Fraud detection, One class support vector machine},
	pages = {6015--6028},
}

@article{98,
	title = {{HT}-{Fed}-{GAN}: {Federated} {Generative} {Model} for {Decentralized} {Tabular} {Data} {Synthesis}},
	volume = {25},
	shorttitle = {{HT}-{Fed}-{GAN}},
	doi = {10.3390/e25010088},
	abstract = {In this paper, we study the problem of privacy-preserving data synthesis (PPDS) for tabular data in a distributed multi-party environment. In a decentralized setting, for PPDS, federated generative models with differential privacy are used by the existing methods. Unfortunately, the existing models apply only to images or text data and not to tabular data. Unlike images, tabular data usually consist of mixed data types (discrete and continuous attributes) and real-world datasets with highly imbalanced data distributions. Existing methods hardly model such scenarios due to the multimodal distributions in the decentralized continuous columns and highly imbalanced categorical attributes of the clients. To solve these problems, we propose a federated generative model for decentralized tabular data synthesis (HT-Fed-GAN). There are three important parts of HT-Fed-GAN: the federated variational Bayesian Gaussian mixture model (Fed-VB-GMM), which is designed to solve the problem of multimodal distributions; federated conditional one-hot encoding with conditional sampling for global categorical attribute representation and rebalancing; and a privacy consumption-based federated conditional GAN for privacy-preserving decentralized data modeling. The experimental results on five real-world datasets show that HT-Fed-GAN obtains the best trade-off between the data utility and privacy level. For the data utility, the tables generated by HT-Fed-GAN are the most statistically similar to the original tables and the evaluation scores show that HT-Fed-GAN outperforms the state-of-the-art model in terms of machine learning tasks. © 2022 by the authors.},
	number = {1},
	journal = {Entropy},
	author = {Duan, S. and Liu, C. and Han, P. and Jin, X. and Zhang, X. and He, T. and Pan, H. and Xiang, X.},
	year = {2023},
	keywords = {Gaussian mixture model, decentralized tabular data synthesis, federated generative model, federated learning, privacy-preserving data synthesis},
}

@article{97,
	title = {Gradually {Generative} {Adversarial} {Networks} {Method} for {Imbalanced} {Datasets}},
	volume = {14},
	doi = {10.14569/IJACSA.2023.0140408},
	abstract = {Imbalanced dataset can cause obstacles to classification and result in a decrease in classification performance. There are several methods that can be used to deal the data imbalances, such as methods based on SMOTE and Generative Adversarial Networks (GAN). These methods are used for overcoming data oversampling so that the amount of minority data can increase and it can reach a balance with the majority data. In this research, the selected dataset is classified as a small imbalanced dataset of less than 200 records. The proposed method is the Gradually Generative Adversarial Network (GradGAN) model which aims to handle data imbalances gradually. The stages of the GradGAN model are adding the original minority dataset gradually so that it will create new minority datasets until a balance of data is created. Based on the algorithm flow described, the minority data is multiplied by the value of the variable that has been determined repeatedly to produce new balanced minority data. The test results on the classification of datasets from the GradGAN model produce an accuracy value of 8.3\% when compare to that without GradGAN © 2023, International Journal of Advanced Computer Science and Applications.All Rights Reserved.},
	number = {4},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {Misdram, M. and {Muljono} and {Purwanto} and Noersasongko, E.},
	year = {2023},
	keywords = {Classification, GAN model, GradGAN model, imbalance, significant oversampling},
	pages = {51--58},
}

@article{96,
	title = {{CTCN}: a novel credit card fraud detection method based on {Conditional} {Tabular} {Generative} {Adversarial} {Networks} and {Temporal} {Convolutional} {Network}},
	volume = {9},
	shorttitle = {{CTCN}},
	doi = {10.7717/PEERJ-CS.1634},
	abstract = {Credit card fraud can lead to significant financial losses for both individuals and financial institutions. In this article, we propose a novel method called CTCN, which uses Conditional Tabular Generative Adversarial Networks (CTGAN) and temporal convolutional network (TCN) for credit card fraud detection. Our approach includes an oversampling algorithm that uses CTGAN to balance the dataset, and Neighborhood Cleaning Rule (NCL) to filter out majority class samples that overlap with the minority class. We generate synthetic minority class samples that conform to the original data distribution, resulting in a balanced dataset. We then employ TCN to analyze transaction sequences and capture long-term dependencies between data, revealing potential relationships between transaction sequences, thus achieving accurate credit card fraud detection. Experiments on three public datasets demonstrate that our proposed method outperforms current machine learning and deep learning methods, as measured by recall, F1-Score, and AUC-ROC. © 2023 Zhao and Guan},
	journal = {PeerJ Computer Science},
	author = {Zhao, X. and Guan, S.},
	year = {2023},
	keywords = {Conditional tabular generative adversarial network, Credit card fraud detection, Neighborhood cleaning rule, Temporal convolutional network},
}

@article{95,
	title = {Low-sample classification in {NIDS} using the {EC}-{GAN} method},
	volume = {28},
	doi = {10.3897/JUCS.85703},
	abstract = {Numerous advanced methods have been applied throughout the years for the use in Network Intrusion Detection Systems (NIDS). Among these are various Deep Learning models, which have shown great success for attack classification. Nevertheless, false positive rate and detection rate of these systems remains a concern. This is mostly because of the low-sample, imbalanced nature of realistic datasets, which make models challenging to train. Considering this, we applied a novel semi-supervised EC-GAN method for network flow classification of CIC-IDS-2017 dataset. EC-GAN uses synthetic data to aid the training of a supervised classifier on low-sample data. To achieve this, we modified the original EC-GAN to work with tabular data. In our approach, WCGAN-GP is used for synthetic tabular data generation, while a simple deep neural network is used for classification. The conditional nature of WCGAN-GP diminishes the class imbalance problem, while GAN itself solves the low-sample problem. This approach was successful in generating believable synthetic data, which was consequently used for training and testing the EC-GAN. To obtain our results, we trained a classifier on progressively smaller versions of the CIC-DIS-2017 dataset, first via a novel EC-GAN method and then in the conventional way, without the help of synthetic data. We then compared these two sets of results with another author’s results using accuracy, false positive rate, detection rate and macro F1 score as metrics. Our results showed that supervised classifier trained with EC-GAN can achieve significant results even when trained on as little as 25\% of the original imbalanced dataset. © 2022, IICM. All rights reserved.},
	number = {12},
	journal = {Journal of Universal Computer Science},
	author = {Zekan, M. and Tomičić, I. and Schatten, M.},
	year = {2022},
	keywords = {GAN, NIDS, Wasserstein GAN, classification, cybersecurity, network security, semi-supervised learning, synthetic tabular data},
	pages = {1330--1346},
}

@article{93,
	title = {{ACWGAN}: {AN} {AUXILIARY} {CLASSIFIER} {WASSERSTEIN} {GAN}-{BASED} {OVERSAMPLING} {APPROACH} {FOR} {MULTI}-{CLASS} {IMBALANCED} {LEARNING}},
	volume = {18},
	shorttitle = {{ACWGAN}},
	doi = {10.24507/ijicic.18.03.703},
	abstract = {Learning from multi-class imbalance data is a common but challenging task in machine learning community. Oversampling method based on Generative Adversarial Networks (GAN) is an effective countermeasure. However, due to the scarce number of trainable minority samples, existing methods may produce noise or low-quality minority samples; besides, they may suffer from mode collapse. To address the issues, we propose an Auxiliary Classifier Wasserstein Generative Adversarial Networks (ACW-GAN) for imbalanced dataset. An independent auxiliary classifier is introduced to help discriminator determine whether the minority samples match the corresponding labels, more importantly, to improve the quality of generated minority samples. Furthermore, we use Wasserstein distance instead of Jensen-Shannon divergence in ACWGAN as the distance measure of the probability distribution to alleviate the mode collapse. Extensive experimental testing is performed on 16 multi-class imbalanced benchmarks and two real imbalanced datasets in comparison with several popular oversampling approaches. The experiment result demonstrates that our method is superior to other oversampling ap-proaches. © 2022, ICIC International.},
	number = {3},
	journal = {International Journal of Innovative Computing, Information and Control},
	author = {Liao, C. and Dong, M.},
	year = {2022},
	keywords = {GAN, Imbalanced learning, Independent auxilary classifier, Multi-class, Oversampling approach},
	pages = {703--721},
}

@article{92,
	title = {Imputation of missing data with class imbalance using conditional generative adversarial networks},
	volume = {453},
	doi = {10.1016/j.neucom.2021.04.010},
	abstract = {Missing data is a common problem faced with real-world datasets. Imputation is a widely used technique to estimate the missing data. State-of-the-art imputation approaches model the distribution of observed data to approximate the missing values. Such an approach usually models a single distribution for the entire dataset, which overlooks the class-specific characteristics of the data. Class-specific characteristics are especially useful when there is a class imbalance. We propose a new method for imputing missing data based on its class-specific characteristics by adapting the popular Conditional Generative Adversarial Networks (CGAN). Our Conditional Generative Adversarial Imputation Network (CGAIN) imputes the missing data using class-specific distributions, which can produce the best estimates for the missing values. We tested our approach on baseline datasets and achieved superior performance compared with the state-of-the-art and popular imputation approaches. © 2021 Elsevier B.V.},
	journal = {Neurocomputing},
	author = {Awan, S.E. and Bennamoun, M. and Sohel, F. and Sanfilippo, F. and Dwivedi, G.},
	year = {2021},
	keywords = {Class imbalance, Conditional generative adversarial network, Generative adversarial network, Missing data imputation},
	pages = {164--171},
}

@article{91,
	title = {{BCGAN}: {A} {CGAN}-based over-sampling model using the boundary class for data balancing},
	volume = {77},
	shorttitle = {{BCGAN}},
	doi = {10.1007/s11227-021-03688-6},
	abstract = {A class imbalance problem occurs when a dataset is decomposed into one majority class and one minority class. This problem is critical in the machine learning domains because it induces bias in training machine learning models. One popular method to solve this problem is using a sampling technique to balance the class distribution by either under-sampling the majority class or over-sampling the minority class. So far, diverse over-sampling techniques have suffered from overfitting and noisy data generation problems. In this paper, we propose an over-sampling scheme based on the borderline class and conditional generative adversarial network (CGAN). More specifically, we define a borderline class based on the minority class data near the majority class. Then, we generate data for the borderline class using the CGAN for data balancing. To demonstrate the performance of the proposed scheme, we conducted various experiments on diverse imbalanced datasets. We report some of the results. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.},
	number = {9},
	journal = {Journal of Supercomputing},
	author = {Son, M. and Jung, S. and Jung, S. and Hwang, E.},
	year = {2021},
	keywords = {Borderline minority class, Conditional generative adversarial network (CGAN), Imbalanced data, Over-sampling},
	pages = {10463--10487},
}

@article{90,
	title = {Conditional {Wasserstein} {GAN}-based oversampling of tabular data for imbalanced learning},
	volume = {174},
	doi = {10.1016/j.eswa.2021.114582},
	abstract = {Class imbalance impedes the predictive performance of classification models. Popular countermeasures include oversampling minority class cases by creating synthetic examples. The paper examines the potential of Generative Adversarial Networks (GANs) for oversampling. A few prior studies have used GANs for this purpose but do not reflect recent methodological advancements for generating tabular data using GANs. The paper proposes an approach based on a conditional Wasserstein GAN that can effectively model tabular datasets with numerical and categorical variables and pays special attention to the down-stream classification task through an auxiliary classifier loss. We focus on a credit scoring context in which binary classifiers predict the default risk of loan applications. Empirical comparisons in this context evidence the competitiveness of GAN-based oversampling compared to several standard oversampling regimes. We also clarify the conditions under which oversampling in general and the proposed GAN-based approach in particular raise predictive performance. In sum, our findings suggest that GAN architectures for tabular data and our extensions deserve a place in data scientists’ modelling toolbox. © 2021 Elsevier Ltd},
	journal = {Expert Systems with Applications},
	author = {Engelmann, J. and Lessmann, S.},
	year = {2021},
	keywords = {Credit scoring, Generative adversarial networks, Imbalanced learning, Oversampling},
}

@article{89,
	title = {Synthetic minority oversampling of vital statistics data with generative adversarial networks},
	volume = {27},
	doi = {10.1093/jamia/ocaa127},
	abstract = {Objective: Minority oversampling is a standard approach used for adjusting the ratio between the classes on imbalanced data. However, established methods often provide modest improvements in classification performance when applied to data with extremely imbalanced class distribution and to mixed-type data. This is usual for vital statistics data, in which the outcome incidence dictates the amount of positive observations. In this article, we developed a novel neural network-based oversampling method called actGAN (activation-specific generative adversarial network) that can derive useful synthetic observations in terms of increasing prediction performance in this context. Materials and Methods: From vital statistics data, the outcome of early stillbirth was chosen to be predicted based on demographics, pregnancy history, and infections. The data contained 363 560 live births and 139 early stillbirths, resulting in class imbalance of 99.96\% and 0.04\%. The hyperparameters of actGAN and a baseline method SMOTE-NC (Synthetic Minority Over-sampling Technique-Nominal Continuous) were tuned with Bayesian optimization, and both were compared against a cost-sensitive learning-only approach. Results: While SMOTE-NC provided mixed results, actGAN was able to improve true positive rate at a clinically significant false positive rate and area under the curve from the receiver-operating characteristic curve consistently. Discussion: Including an activation-specific output layer to a generator network of actGAN enables the addition of information about the underlying data structure, which overperforms the nominal mechanism of SMOTE-NC. Conclusions: actGAN provides an improvement to the prediction performance for our learning task. Our developed method could be applied to other mixed-type data prediction tasks that are known to be afflicted by class imbalance and limited data availability. © 2020 The Author(s) 2020. Published by Oxford University Press on behalf of the American Medical Informatics Association.},
	number = {11},
	journal = {Journal of the American Medical Informatics Association},
	author = {Koivu, A. and Sairanen, M. and Airola, A. and Pahikkala, T.},
	year = {2020},
	keywords = {artificial intelligence, deep learning, machine learning, stillbirth, vital statistics},
	pages = {1667--1674},
}

@article{88,
	title = {Generative adversarial fusion network for class imbalance credit scoring},
	volume = {32},
	doi = {10.1007/s00521-019-04335-1},
	abstract = {Credit scoring on class imbalance data, where the class of defaulters is insufficiently represented compared with the class of non-defaulters, is an important but challenging task. In this paper, we propose an imbalanced generative adversarial fusion network (IGAFN) to cope with the class imbalance credit scoring based on multi-source heterogeneous credit data. Concretely, we design a fusion module to integrate the heterogeneous credit data from multiple sources into a unified latent feature space. A generative adversarial network-based balance module is then designed to generate latent representations of new samples for the minority class of the imbalanced datasets. The performance of IGAFN is compared against multiple conventional machine learning and deep learning algorithms. Extensive experiments show that the proposed IGAFN exhibits significantly better performance than the compared methods on two real-life datasets. © 2019, Springer-Verlag London Ltd., part of Springer Nature.},
	number = {12},
	journal = {Neural Computing and Applications},
	author = {Lei, K. and Xie, Y. and Zhong, S. and Dai, J. and Yang, M. and Shen, Y.},
	year = {2020},
	keywords = {Class imbalance, Credit scoring, Feature fusion, Generative adversarial network},
	pages = {8451--8462},
}

@article{87,
	title = {An {Efficient} {Domain}-{Adaptation} {Method} using {GAN} for {Fraud} {Detection}},
	volume = {11},
	doi = {10.14569/IJACSA.2020.0111113},
	abstract = {In this paper, an efficient domain-adaptation method is proposed for fraud detection. The proposed method employs the discriminative characteristics used in feature maps and generative adversarial networks (GANs), to minimize the deviation that occurs when a common feature is shifted between two domains. To solve class imbalance problem and increase the model’s detection accuracy, new data samples are generated by applying a minority class data augmentation method, which uses a GAN. We evaluate the classification performance of the proposed domain-adaption model by comparing it against support vector machine (SVM) and convolutional neural network (CNN) models, using classification performance evaluation indicators. The experimental results indicated that the proposed model is applicable to both test datasets; furthermore, it requires less time for learning. Although the SVM offers a better detection performance than the CNN and proposed domain-adaptation model, its learning time exceeds those of the other two models when dataset increases. Also, although the detection performance of the CNN-based model is similar to that of the proposed domain-adaptation model, its learning process is longer. In addition, although the GAN used to solve the class imbalance problem of the two datasets requires slightly more time than SMOTE (synthetic minority oversampling technique), it shows a better classification performance and is effective for datasets featuring class imbalances. © 2020. All Rights Reserved.},
	number = {11},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {Hwang, J. and Kim, K.},
	year = {2020},
	keywords = {Fraud detection, GAN, data augmentation, deep learning, domain adaptation},
	pages = {94--103},
}

@inproceedings{69,
	address = {Cham},
	title = {Generation of {Synthetic} {Tabular} {Healthcare} {Data} {Using} {Generative} {Adversarial} {Networks}},
	isbn = {978-3-031-27077-2},
	doi = {10.1007/978-3-031-27077-2_34},
	abstract = {High-quality tabular data is a crucial requirement for developing data-driven applications, especially healthcare-related ones, because most of the data nowadays collected in this context is in tabular form. However, strict data protection laws complicates the access to medical datasets. Thus, synthetic data has become an ideal alternative for data scientists and healthcare professionals to circumvent such hurdles. Although many healthcare institutions still use the classical de-identification and anonymization techniques for generating synthetic data, deep learning-based generative models such as generative adversarial networks (GANs) have shown a remarkable performance in generating tabular datasets with complex structures. This paper examines the GANs’ potential and applicability within the healthcare industry, which often faces serious challenges with insufficient training data and patient records sensitivity. We investigate several state-of-the-art GAN-based models proposed for tabular synthetic data generation. Healthcare datasets with different sizes, numbers of variables, column data types, feature distributions, and inter-variable correlations are examined. Moreover, a comprehensive evaluation framework is defined to evaluate the quality of the synthetic records and the viability of each model in preserving the patients’ privacy. The results indicate that the proposed models can generate synthetic datasets that maintain the statistical characteristics, model compatibility and privacy of the original data. Moreover, synthetic tabular healthcare datasets can be a viable option in many data-driven applications. However, there is still room for further improvements in designing a perfect architecture for generating synthetic tabular data.},
	language = {en},
	booktitle = {{MultiMedia} {Modeling}},
	publisher = {Springer International Publishing},
	author = {Nik, Alireza Hossein Zadeh and Riegler, Michael A. and Halvorsen, Pål and Storås, Andrea M.},
	editor = {Dang-Nguyen, Duc-Tien and Gurrin, Cathal and Larson, Martha and Smeaton, Alan F. and Rudinac, Stevan and Dao, Minh-Son and Trattner, Christoph and Chen, Phoebe},
	year = {2023},
	keywords = {Deep learning, Medical data, Synthetic data generation},
	pages = {434--446},
}

@inproceedings{23,
	address = {Cham},
	title = {Sampling {Approaches} for {Imbalanced} {Data} {Classification} {Problem} in {Machine} {Learning}},
	isbn = {978-3-030-29407-6},
	doi = {10.1007/978-3-030-29407-6_17},
	abstract = {Real-world datasets in many domains like medical, intrusion detection, fraud transactions and bioinformatics are highly imbalanced. In classification problems, imbalanced datasets negatively affect the accuracy of class predictions. This skewness can be handled either by oversampling minority class examples or by undersampling majority class. In this work, popular methods of both categories have been evaluated for their capability of improving the imbalanced ratio of five highly imbalanced datasets from different application domains. Effect of balancing on classification results has been also investigated. It has been observed that adaptive synthetic oversampling approach can best improve the imbalance ratio as well as classification results. However, undersampling approaches gave better overall performance on all datasets.},
	language = {en},
	booktitle = {Proceedings of {ICRIC} 2019},
	publisher = {Springer International Publishing},
	author = {Tyagi, Shivani and Mittal, Sangeeta},
	editor = {Singh, Pradeep Kumar and Kar, Arpan Kumar and Singh, Yashwant and Kolekar, Maheshkumar H. and Tanwar, Sudeep},
	year = {2020},
	pages = {209--221},
}

@inproceedings{16,
	address = {Cham},
	title = {Learning from {Imbalanced} {Data} {Using} {Ensemble} {Methods} and {Cluster}-{Based} {Undersampling}},
	isbn = {978-3-319-17876-9},
	doi = {10.1007/978-3-319-17876-9_5},
	abstract = {Imbalanced data, where the number of instances of one class is much higher than the others, are frequent in many domains such as fraud detection, telecommunications management, oil spill detection, and text classification. Traditional classifiers do not perform well when considering data that are susceptible to both within-class and between-class imbalances. In this paper, we propose the ClusFirstClass algorithm that employs cluster analysis to aid classifiers when aiming to build accurate models against such imbalanced datasets. In order to work with balanced classes, all minority instances are used together with the same number of majority instances. To further reduce the impact of within-class imbalance, majority instances are clustered into different groups and at least one instance is selected from each cluster. Experimental results demonstrate that our proposed ClusFirstClass algorithm yields promising results compared to the state-of-the art classification approaches, when evaluated against a number of highly imbalanced datasets.},
	language = {en},
	booktitle = {New {Frontiers} in {Mining} {Complex} {Patterns}},
	publisher = {Springer International Publishing},
	author = {Sobhani, Parinaz and Viktor, Herna and Matwin, Stan},
	editor = {Appice, Annalisa and Ceci, Michelangelo and Loglisci, Corrado and Manco, Giuseppe and Masciari, Elio and Ras, Zbigniew W.},
	year = {2015},
	keywords = {Cluster analysis, Ensemble learning, Imbalanced data, Undersampling},
	pages = {69--83},
}

@inproceedings{14,
	address = {Berlin, Heidelberg},
	title = {An {Optimized} {Cost}-{Sensitive} {SVM} for {Imbalanced} {Data} {Learning}},
	isbn = {978-3-642-37456-2},
	doi = {10.1007/978-3-642-37456-2_24},
	abstract = {Class imbalance is one of the challenging problems for machine learning in many real-world applications. Cost-sensitive learning has attracted significant attention in recent years to solve the problem, but it is difficult to determine the precise misclassification costs in practice. There are also other factors that influence the performance of the classification including the input feature subset and the intrinsic parameters of the classifier. This paper presents an effective wrapper framework incorporating the evaluation measure (AUC and G-mean) into the objective function of cost sensitive SVM directly to improve the performance of classification by simultaneously optimizing the best pair of feature subset, intrinsic parameters and misclassification cost parameters. Experimental results on various standard benchmark datasets and real-world data with different ratios of imbalance show that the proposed method is effective in comparison with commonly used sampling techniques.},
	language = {en},
	booktitle = {Advances in {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Springer},
	author = {Cao, Peng and Zhao, Dazhe and Zaiane, Osmar},
	editor = {Pei, Jian and Tseng, Vincent S. and Cao, Longbing and Motoda, Hiroshi and Xu, Guandong},
	year = {2013},
	keywords = {Feature Selection, Feature Subset, Intrinsic Parameter, Minority Class, Particle Swarm Optimization},
	pages = {280--292},
}

@inproceedings{5,
	address = {Singapore},
	title = {Handling {Imbalanced} {Ratio} for {Class} {Imbalance} {Problem} {Using} {SMOTE}},
	isbn = {9789811372797},
	doi = {10.1007/978-981-13-7279-7_3},
	abstract = {There are many issues regarding datasets classification. One such issue is class imbalance classification, which often occurs with extreme skewness across many real-world domains. The issue presents itself as one of the fundamental difficulties to form robust classifiers. In this paper, a sampling method was used to identify the performance of classification for k-NN classifier and C4.5 classifier with a ten-fold cross validation. Experimental results conducted showed that sampling greatly benefited the performance of classification in class imbalance problem, by improving class boundary region especially with extremely imbalanced datasets (extreme number of imbalanced ratio). This result demonstrates that class imbalance can affect many domains in real-world applications.},
	language = {en},
	booktitle = {Proceedings of the {Third} {International} {Conference} on {Computing}, {Mathematics} and {Statistics} ({iCMS2017})},
	publisher = {Springer},
	author = {Noorhalim, Nurulfitrah and Ali, Aida and Shamsuddin, Siti Mariyam},
	editor = {Kor, Liew-Kee and Ahmad, Abd-Razak and Idrus, Zanariah and Mansor, Kamarul Ariffin},
	year = {2019},
	pages = {19--30},
}

@misc{liu_kan_2024,
	title = {{KAN}: {Kolmogorov}-{Arnold} {Networks}},
	shorttitle = {{KAN}},
	url = {http://arxiv.org/abs/2404.19756},
	abstract = {Inspired by the Kolmogorov-Arnold representation theorem, we propose Kolmogorov-Arnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs). While MLPs have fixed activation functions on nodes ("neurons"), KANs have learnable activation functions on edges ("weights"). KANs have no linear weights at all -- every weight parameter is replaced by a univariate function parametrized as a spline. We show that this seemingly simple change makes KANs outperform MLPs in terms of accuracy and interpretability. For accuracy, much smaller KANs can achieve comparable or better accuracy than much larger MLPs in data fitting and PDE solving. Theoretically and empirically, KANs possess faster neural scaling laws than MLPs. For interpretability, KANs can be intuitively visualized and can easily interact with human users. Through two examples in mathematics and physics, KANs are shown to be useful collaborators helping scientists (re)discover mathematical and physical laws. In summary, KANs are promising alternatives for MLPs, opening opportunities for further improving today's deep learning models which rely heavily on MLPs.},
	urldate = {2024-11-15},
	publisher = {arXiv},
	author = {Liu, Ziming and Wang, Yixuan and Vaidya, Sachin and Ruehle, Fabian and Halverson, James and Soljačić, Marin and Hou, Thomas Y. and Tegmark, Max},
	month = apr,
	year = {2024},
	note = {arXiv:2404.19756 
version: 1},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks, KAN, Statistics - Machine Learning},
}
