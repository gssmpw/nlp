\section{Related Work}
Our approach is in line with methodologies employing a two-stage architecture for semantic parsing tasks, akin to works such as Coarse2Fine____, STaG-QA____, and HGNet____, where questions are first mapped to an initial outline and then filled in details later. However, they overlook condition expressions or constraints in SPARQL queries, whereas OntoSCPrompt's SPARQL structure representation is more comprehensive, enhancing KGQA generalization.
Most existing KGQA systems lack generalization as they are either typically tailored to a specific KG or focus only on within-a-KG generalization. While some methods have demonstrated limited ability to generalize across KGs, particularly in handling assertion heterogeneity between datasets such as WebQSP (Freebase) and MetaQA (Wikimovies), they fail to generalize across different schemas or topologies. LLMs also suffer from issues like hallucinations and factual inaccuracy when answering questions____, specifically in the knowledge-intensive task KGQA____. Some studies____ resort to KG-augmented prompt, i.e., injecting question-related factual information (e.g., KG triples) into predefined templates. Hallucinations still remain in the context of KGQA generalization as they adapt to heterogeneous KGs. In this work, we integrate the ontology verbalized in a unified way into the prompt and guide LLMs to fulfil our task, facilitating reasoning over KG ontology.