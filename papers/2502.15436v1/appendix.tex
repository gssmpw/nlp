\clearpage


\section{Proof of Lemma \ref{lemma:privacy} } \label{app:proof_priv}
\begin{tcolorbox}[colback=cyan!10,colframe=black]
\begin{lemma*}
    Consider a model with \( d \) learnable parameters trained using DP-SGD. The privacy parameter \( \epsilon \) for \( \delta \)-approximate differential privacy, given \( T \) training steps and a batch size of \( q \), is expressed as:
\begin{align}
    \epsilon = O(q \sqrt{T d \log (1 / \delta)}) = O(\sqrt{d}).
\end{align}
\end{lemma*}
\end{tcolorbox}

\begin{proof}
    The following result from \citet{dgsgd} describes the relationship between noise variance, privacy parameters, number of optimization steps, batch size, and sample size in DP-SGD.

\begin{theorem*}
    There exist constants \( c_1 \) and \( c_2 \) such that, given the sampling probability \( q = L / N \) and the number of optimization steps \( T \), for any \( \epsilon < c_1 q^2 T \), DP-SGD is \( (\epsilon, \delta) \)-differentially private for any \( \delta > 0 \) if the noise scale satisfies:
    \begin{align}
        \sigma \geq c_2 \frac{q \sqrt{T \log (1 / \delta)}}{\epsilon}.
    \end{align}
\end{theorem*}

Each DP-SGD step introduces noise following \( \mathcal{N}\left(0, \sigma^2 C^2 \mathbf{I}_d\right) \) and satisfies \( (\alpha, \alpha / (2 \sigma^2)) \)-RDP (Rényi DP) for the Gaussian mechanism. For a function with \( \ell_2 \)-sensitivity \( \Delta_2 \), the Gaussian mechanism satisfies \( (\alpha, \epsilon) \)-RDP with:
\begin{align}
    \epsilon(\alpha) = \frac{\alpha \Delta_2^2}{2 \sigma_{\text{noise}}^2}.
\end{align}
Since DP-SGD has \( \Delta_2 = C \) and \( \sigma_{\text{noise}} = \sigma C \), applying privacy amplification due to sampling probability \( q \) results in each step satisfying \( (\alpha, \gamma) \)-RDP, where, for small \( q \):
\begin{align}
    \gamma = O\left(\frac{q^2 \alpha}{\sigma^2}\right).
\end{align}
Using composition over \( T \) steps, the total RDP privacy parameter becomes:
\begin{align}
    \gamma_{\text{total}} = O\left(\frac{q^2 T \alpha}{\sigma^2}\right).
\end{align}
Converting this RDP bound back to \( (\epsilon, \delta) \)-DP and setting \( \alpha \) proportional to \( 1 / \sqrt{d} \), given that the \( \ell_2 \)-norm of the gradient scales as \( \sqrt{d} \), we obtain:
\begin{align}
    \epsilon = O\left(\frac{q^2 T \alpha}{\sigma^2} + \frac{\log (1 / \delta)}{\alpha - 1}\right).
\end{align}
Substituting \( \sigma \propto 1 / \sqrt{d} \), we derive:
\begin{align}
    \epsilon = O(q \sqrt{T d \log (1 / \delta)}) = O(\sqrt{d}).
\end{align}
\end{proof}


% \begin{proof}
%     The following result from \cite{dgsgd} describes the dependence between the noise variance, the privacy parameters, number of optimization steps, batch-size and sample-size upon applying DP-SGD. 

% \begin{theorem*}
%     There exist constants $c_1$ and $c_2$ so that given the sampling probability $q=L / N$ and the number of steps $T$, for any $\epsilon<c_1 q^2 T$, Algorithm 1 is $(\epsilon, \delta)$-differentially private for any $\delta>0$ if we choose

% $$
% \sigma \geq c_2 \frac{q \sqrt{T \log (1 / \delta)}}{\epsilon}
% $$
% \end{theorem*}
% Each DP-SGD step has noise $\mathcal{N}\left(0, \sigma^2 C^2 \mathbf{I}_d\right)$ and is $\left(\alpha, \alpha /\left(2 \sigma^2\right)\right)$-RDP for the Gaussian mechanism. This is because, for functions with $\ell_2$-sensitivity $\Delta_2$, the Gaussian mechanism satisfies $(\alpha, \epsilon)$-RDP with $
% \epsilon(\alpha)=\frac{\alpha \Delta_2^2}{2 \sigma_{\text {noise }}^2}
% $ and in DP-SGD, we have $\Delta_2=C$ and $\sigma_{\text {noise }}=\sigma C$. Now, even upon using privacy amplification due to sampling with probability $q$, each step becomes $(\alpha, \gamma)$-RDP, where $\gamma=O\left(\frac{q^2 \alpha}{\sigma^2}\right)$ for small $q$. Upon applying
% composition over $T$ steps, the total RDP privacy parameter becomes
% $$
% \gamma_{\mathrm{total}}=O\left(\frac{q^2 T \alpha}{\sigma^2}\right)
% $$ Upon converting this RDP back to $(\epsilon, \delta)$-DP, we get that for $\delta>0$, and setting $\alpha$ to be proportional to $1 / \sqrt{d}$, as the $\ell_2$-norm of the gradient grows as $\sqrt{d}$, we have
% $$
% \epsilon=O\left(\frac{q^2 T \alpha}{\sigma^2}+\frac{\log (1 / \delta)}{\alpha-1}\right)
% $$ Upon substituting $\sigma \propto 1 / \sqrt{d}$ ,
% $$
% \epsilon=O(q \sqrt{T d \log (1 / \delta)})=\Omega(\sqrt{d})
% $$
% \end{proof}

\input{related-work}

\section{Experiment Details} \label{app:hyperparams}

We conduct experiments on a single NVIDIA A6000 GPU (48 GB) and report the average results from three independent runs. All non-private models are trained using the AdamW optimizer \citep{loshchilov2019decoupledweightdecayregularization}. 
In line with \citet{ponkshe2024initialization}, we initialize the adapter matrices using just $1/{1000}$ of the respective training dataset size.
\\

\textbf{Instruction Tuning.}
Table \ref{tab:hyper_it} presents the key hyperparameters and configurations for Mistral-7B, Gemma-2 9B, and Llama-3.2 3B. 
Our setup closely follows previous works \citep{cr-dataset, ponkshe2024initialization}, ensuring consistency with established best practices.
For the baseline experiments, we further set $\alpha = 16$, consistent with prior literature \citep{singhal2024exact, sun2024improving}.
We additionally perform a sweep over the learning rate for our experiments.
\\

\textbf{(Federated) Private Fine-Tuning.}
Table \ref{tab:hyper_bert} outlines the key hyperparameters and configurations for BERT-base in both centralized private and federated private settings. 
We train our models using the Opacus library \citep{yousefpour2021opacus} with the DP-SGD optimizer \citep{dgsgd}. 
Following standard DP practices, we set the privacy parameter as \(\delta = \frac{1}{|\text{trainset}|}\). 
To ensure adherence to best practices, we adopt hyperparameter choices from prior works \citep{singhal2024exact, lora}. For baseline experiments, we additionally set \(\alpha = 16\), aligning with previous literature \citep{singhal2024exact, sun2024improving}. 
We additionally perform a sweep over the learning rate and maximum gradient norm in DP-SGD for our experiments.


\begin{table*}[!h]
\centering
\begin{tabular}{lccc}
\toprule
 & \textbf{Mistral-7B} & \textbf{Gemma-2 9B} & \textbf{Llama-3.2 3B}\\
\midrule
Optimizer        & AdamW      & AdamW      & AdamW      \\
Learning Rate    & $5\mathrm{e}{-4}$ & $5\mathrm{e}{-4}$ & $2\mathrm{e}{-4}$ \\
LR Scheduler     & Cosine     & Cosine     & Linear     \\
Warmup Ratio     & $0.02$     & $0.02$     & $0.02$     \\
Batch Size       & $1$        & $1$        & $8$        \\
Grad Acc. Steps  & $32$       & $32$       & $24$       \\
Max. Seq. Len    & $512$      & $512$      & $256$      \\
Dropout          & $0$        & $0$        & $0$        \\
\# Clients   & $25$       & $25$       & $5$        \\
Local Epochs     & $1$        & $2$        & $2$        \\
Rounds           & $1$        & $1$        & $1$        \\
\bottomrule
\end{tabular}
\caption{Hyperparameter settings for Mistral-7B, Gemma-2 9B, and Llama-3.2 3B.}
\label{tab:hyper_it}
\end{table*}

\begin{table*}[!h]
\centering
\begin{tabular}{lcc}
\toprule
 & \textbf{BERT-base (centralized)} & \textbf{BERT-base (federated)} \\
\midrule
Optimizer        & DP-SGD      & DP-SGD      \\
Learning Rate    & $5\mathrm{e}{-4}$ & $5\mathrm{e}{-4}$ \\
LR Scheduler     & -    & -   \\
Warmup Ratio     & 0     & 0 \\
Batch Size       & $32$        & $32$\\
Max. Phy. Batch Size       & $8$        & $8$\\
Max. Seq. Len    & $128$      & $128$\\
Dropout          & $0.05$        & $0.05$\\
Max. Grad. Norm & $0.1$ & $0.1$ \\
Epochs & $3$ & - \\
\midrule
\# Clients   & -      & $3$\\
Local Epochs     & -        & $6$\\
Rounds           & -        & $1$\\
\bottomrule
\end{tabular}
\caption{Hyperparameter settings for BERT-base in centralized private and federated private setups.}
\label{tab:hyper_bert}
\end{table*}



\section{Dataset Details} \label{app:datasets}


\textsc{\textbf{CommonSense170K}} is a large-scale dataset that brings together eight benchmarks designed to assess various aspects of commonsense reasoning \citep{cr-dataset}. Below is an overview of its constituent datasets:

\begin{enumerate}
\item \textbf{PIQA} \citep{bisk2020piqa} evaluates physical commonsense by asking models to determine the most reasonable action in a given scenario.
\item \textbf{ARC Easy (ARC-e)} \citep{clark2018think} consists of elementary-level science questions, serving as a fundamental test of a model’s reasoning abilities.
\item \textbf{OBQA} \citep{mihaylov2018can} presents knowledge-intensive, open-book multiple-choice questions that require multi-step reasoning and retrieval.
\item \textbf{HellaSwag} \citep{zellers2019hellaswag} tests contextual reasoning by asking models to predict the most plausible continuation of a passage from a set of candidates.
\item \textbf{SIQA} \citep{sap2019socialiqa} examines social intelligence, requiring models to predict human actions and their social consequences.
\item \textbf{ARC Challenge (ARC-c)} \citep{clark2018think} includes difficult multiple-choice science questions that demand deeper logical inference beyond statistical co-occurrence.
\item \textbf{BoolQ} \citep{clark2019boolq} consists of naturally occurring yes/no questions, requiring models to infer relevant information from provided contexts.
\item \textbf{WinoGrande} \citep{sakaguchi2021winogrande} assesses commonsense knowledge through binary-choice sentence completion tasks that require resolving ambiguities.
\end{enumerate}


The \textbf{MetaMathQA} dataset \citep{metamathqa} constructs mathematical questions by reformulating them from different viewpoints while preserving their original knowledge content. We assess its performance using two well-established benchmarks: (1) \textbf{GSM8K} \citep{gsm8k}, a collection of grade-school-level math problems requiring step-by-step reasoning to reach a solution, and (2) \textbf{MATH} \citep{math}, which consists of high-difficulty, competition-style problems designed to test advanced mathematical skills.
\\

\textbf{Stanford Natural Language Inference (SNLI)} is a widely used benchmark for assessing textual entailment models in natural language understanding. 
It contains approximately 570,000 sentence pairs, each categorized into one of three classes: entailment, contradiction, or neutral, requiring models to infer the relationship between a given premise and hypothesis.

\section{Additional Plots} \label{app:plots}
\begin{figure*}[!h]
    \centering
    % First subfigure
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/pareto-mistral-final-2.png}
        \caption{Mistral-7B (GSM8K)}
        \label{fig:fed-mistral}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/pareto-gemma-final-2.png}
        \caption{Gemma-2 9B (MATH)}
        \label{fig:fed-math}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/pareto-llama.png}
        \caption{Llama-3.2 3B (Commonsense)}
        \label{fig:fed-llama}
    \end{subfigure}
    \caption{Performance vs. number of communicated parameters (in log scale) for various methods in federated fine-tuning across multiple models on arithmetic and commonsense reasoning tasks.}
    \label{fig:results-it}
\end{figure*}

\begin{figure*}[!h]
    \centering
    % First subfigure
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_central_vary_eps.png}
        \caption{Centralized Private}
        \label{fig:dp-central-vary}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_fed_vary_eps.png}
        \caption{Federated Private}
        \label{fig:dp-fed-vary}
    \end{subfigure}
    \caption{Performance comparison of various methods in centralized (Cent.) private and federated private fine-tuning (BERT-base) on SNLI across varying values of $\epsilon$.}
    \label{fig:plots-dp-vary}
\end{figure*}




\begin{figure*}[!h]
    \centering
    % First subfigure
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_central_eps_1.png}
        \caption{$\epsilon = 1$}
        \label{fig:dp-central-eps-1}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_central_eps_3.png}
        \caption{$\epsilon = 3$}
        \label{fig:dp-central-eps-3}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_central_eps_5.png}
        \caption{$\epsilon = 5$}
        \label{fig:dp-central-eps-5}
    \end{subfigure}
    %\hfill
    % Second subfigure
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_central_eps_7.5.png}
        \caption{$\epsilon = 7.5$}
        \label{fig:dp-central-eps-7.5}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_central_eps_10.png}
        \caption{$\epsilon = 10$}
        \label{fig:dp-central-eps-10}
    \end{subfigure}
    \caption{Performance vs. number of trainable parameters (in log scale) for various methods in centralized private fine-tuning (BERT-base) across different privacy budgets ($\epsilon$).}
    \label{fig:plots-dp-central-eps}
\end{figure*}


\begin{figure*}[ht]
    \centering
    % First subfigure
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_fed_eps_1.png}
        \caption{$\epsilon = 1$}
        \label{fig:dp-fed-eps-1}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_fed_eps_3.png}
        \caption{$\epsilon = 3$}
        \label{fig:dp-fed-eps-3}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_fed_eps_5.png}
        \caption{$\epsilon = 5$}
        \label{fig:dp-fed-eps-5}
    \end{subfigure}
    %\hfill
    % Second subfigure
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_fed_eps_7.5.png}
        \caption{$\epsilon = 7.5$}
        \label{fig:dp-fed-eps-7.5}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{latex/figures/dp_fed_eps_10.png}
        \caption{$\epsilon = 10$}
        \label{fig:dp-fed-eps-10}
    \end{subfigure}
    \caption{Performance vs. number of communicated parameters (in log scale) for various methods in federated private fine-tuning (BERT-base) across different privacy budgets ($\epsilon$).}
    \label{fig:plots-dp-fed-eps}
\end{figure*}