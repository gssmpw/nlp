We conduct user studies on two decision-making tasks: the \textbf{ARC} task and the \textbf{Diagnosis} task.

\paragraph{ARC Task.} This task consists of answering science questions. 
Questions are sourced from the ARC dataset~\cite{allenai:arc}, which consists of more than 7000 grade-school science multiple-choice questions written for examinations. 
The authors manually reviewed questions from this dataset and selected questions that were challenging (i.e. the correct answer is not immediately obvious, and at least one option was not obviously incorrect) but still understandable (did not contain any scientific jargon that laypeople may not be familiar with). 
All questions in the original dataset had four options, but the author only selected the correct answer and the most plausible incorrect option for the decision-making problem. 
The final filtered set consisted of 39 questions. 
For each of the 10 problem sequences that users solve, we sample 30 of the 39 questions without repetition.

\paragraph{Diagnosis Task.} This task consists of diagnosing patients based on patient symptoms. 
Patient symptoms are sourced from the DDXPlus dataset~\cite{fansi2022ddxplus}, which contains 1.3 million synthetic patients with a differential diagnosis. 
The symptoms are presented as either binary, categorical or continuous variables, but each symptom has a corresponding patient intake question and answer in English, which we translate into a descriptive third-person statement using GPT-4o.. 
For example, the intake question ``Do you feel pain somewhere?'' and patient response ``Knee (R)'' is translated into ``The patient feels pain in their right knee.''. 
We filter down to questions with only 10--15 intake responses so that users do not need to spend a long time understanding the problem. 
To convert the task into a multiple-choice problem, we select the top three negative conditions from the differential diagnosis as the incorrect options. 
Our final set of problems includes 55 cases corresponding to eleven different conditions, which we use to sample 10 sequences of 30 problems each.

Table~\ref{tab:sample_explanations} contains examples of decision-making problems from both tasks.