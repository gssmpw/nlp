
We report macro-aggregation results, where we first compute our metrics for each user, and then aggregate across all users. 
Because some users may only have a few interactions that fit the required criteria for computing metrics, the metrics for those users are very sensitive to a single interactions. 
Therefore, when computing metrics, we filter out users with fewer than 3 interactions that meet the required criteria ($\aidecision_i \neq \userdecision{\init}_i$, and user trust being below/above the corresponding threshold for the ``low trust''/``high trust'' interaction subsets). 
For the \underreliance\ metric we also need at least 3 interactions where the AI prediction is correct, and for the \overreliance\ metric we need at least 3 interactions where the AI prediction is incorrect.
For the \totalinapprel\ metric we \emph{both} need 3 interactions where the AI prediction is correct and 3 interactions where the AI is incorrect (so that we can calculate both \underreliance\ and \overreliance\ for that user).

In Figure~\ref{fig:macro-aggregation}, we observe trends similar to those observed in Section~\ref{sec:mitigations}. However, when looking at the low/high trust subsets, most conditions have fewer than 10 users for calculating \underreliance\ and \overreliance, and fewer than 5 users for \totalinapprel.