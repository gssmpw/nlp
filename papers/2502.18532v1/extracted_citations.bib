@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{azar2024dpo_variant,
  title={A general theoretical paradigm to understand learning from human preferences},
  author={Azar, Mohammad Gheshlaghi and Guo, Zhaohan Daniel and Piot, Bilal and Munos, Remi and Rowland, Mark and Valko, Michal and Calandriello, Daniele},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4447--4455},
  year={2024},
  organization={PMLR}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}

@article{brown2020GPT,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chang2021does,
  title={Does the order of training samples matter? improving neural data-to-text generation with curriculum learning},
  author={Chang, Ernie and Yeh, Hui-Syuan and Demberg, Vera},
  journal={arXiv preprint arXiv:2102.03554},
  year={2021}
}

@article{christiano2017RLHF,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{de2015lean,
  title={The Lean theorem prover (system description)},
  author={De Moura, Leonardo and Kong, Soonho and Avigad, Jeremy and Van Doorn, Floris and von Raumer, Jakob},
  booktitle={Automated Deduction-CADE-25: 25th International Conference on Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceedings 25},
  pages={378--388},
  year={2015},
  organization={Springer}
}

@misc{dpo2024,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2024},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.18290}, 
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{ethayarajh2024kto,
  title={Kto: Model alignment as prospect theoretic optimization},
  author={Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe},
  journal={arXiv preprint arXiv:2402.01306},
  year={2024}
}

@article{han2021PACT,
  title={Proof artifact co-training for theorem proving with language models},
  author={Han, Jesse Michael and Rute, Jason and Wu, Yuhuai and Ayers, Edward W and Polu, Stanislas},
  journal={arXiv preprint arXiv:2102.06203},
  year={2021}
}

@inproceedings{hong2024orpo,
  title={Orpo: Monolithic preference optimization without reference model},
  author={Hong, Jiwoo and Lee, Noah and Thorne, James},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={11170--11189},
  year={2024}
}

@article{jiang2022dsp,
  title={Draft, sketch, and prove: Guiding formal theorem provers with informal proofs},
  author={Jiang, Albert Q and Welleck, Sean and Zhou, Jin Peng and Li, Wenda and Liu, Jiacheng and Jamnik, Mateja and Lacroix, Timoth{\'e}e and Wu, Yuhuai and Lample, Guillaume},
  journal={arXiv preprint arXiv:2210.12283},
  year={2022}
}

@article{jiang2022thor,
  title={Thor: Wielding hammers to integrate language models and automated theorem provers},
  author={Jiang, Albert Qiaochu and Li, Wenda and Tworkowski, Szymon and Czechowski, Konrad and Odrzyg{\'o}{\'z}d{\'z}, Tomasz and Mi{\l}o{\'s}, Piotr and Wu, Yuhuai and Jamnik, Mateja},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8360--8373},
  year={2022}
}

@article{jiao2024learning,
  title={Learning planning-based reasoning by trajectories collection and process reward synthesizing},
  author={Jiao, Fangkai and Qin, Chengwei and Liu, Zhengyuan and Chen, Nancy F and Joty, Shafiq},
  journal={arXiv preprint arXiv:2402.00658},
  year={2024}
}

@article{kumarappan2024leanagent,
  title={LeanAgent: Lifelong Learning for Formal Theorem Proving},
  author={Kumarappan, Adarsh and Tiwari, Mo and Song, Peiyang and George, Robert Joseph and Xiao, Chaowei and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2410.06209},
  year={2024}
}

@article{lai2024stepdpo,
  title={Step-dpo: Step-wise preference optimization for long-chain reasoning of llms},
  author={Lai, Xin and Tian, Zhuotao and Chen, Yukang and Yang, Senqiao and Peng, Xiangru and Jia, Jiaya},
  journal={arXiv preprint arXiv:2406.18629},
  year={2024}
}

@article{lample2022hypertree,
  title={Hypertree proof search for neural theorem proving},
  author={Lample, Guillaume and Lacroix, Timothee and Lachaux, Marie-Anne and Rodriguez, Aurelien and Hayat, Amaury and Lavril, Thibaut and Ebner, Gabriel and Martinet, Xavier},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={26337--26349},
  year={2022}
}

@article{lin2024leanstar,
  title={Lean-star: Learning to interleave thinking and proving},
  author={Lin, Haohan and Sun, Zhiqing and Yang, Yiming and Welleck, Sean},
  journal={arXiv preprint arXiv:2407.10040},
  year={2024}
}

@article{lu2024step-controlled-dpo,
  title={Step-controlled dpo: Leveraging stepwise error for enhanced mathematical reasoning},
  author={Lu, Zimu and Zhou, Aojun and Wang, Ke and Ren, Houxing and Shi, Weikang and Pan, Junting and Zhan, Mingjie and Li, Hongsheng},
  journal={arXiv preprint arXiv:2407.00782},
  year={2024}
}

@inproceedings{majumder2024tango,
  title={Tango 2: Aligning diffusion-based text-to-audio generations through direct preference optimization},
  author={Majumder, Navonil and Hung, Chia-Yu and Ghosal, Deepanway and Hsu, Wei-Ning and Mihalcea, Rada and Poria, Soujanya},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={564--572},
  year={2024}
}

@book{megill2019metamath,
  title={Metamath: a computer language for mathematical proofs},
  author={Megill, Norman and Wheeler, David A},
  year={2019},
  publisher={Lulu. com}
}

@article{narvekar2020curriculumSurvey,
  title={Curriculum learning for reinforcement learning domains: A framework and survey},
  author={Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E and Stone, Peter},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={181},
  pages={1--50},
  year={2020}
}

@inproceedings{paulson1990isabelle,
  title={Isabelle: The next 700 theorem provers},
  author={Paulson, Lawrence C},
  booktitle={Logic and computer science},
  volume={31},
  pages={361--386},
  year={1990},
  organization={Citeseer}
}

@article{polu2020gpt-f,
  title={Generative language modeling for automated theorem proving},
  author={Polu, Stanislas and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2009.03393},
  year={2020}
}

@article{polu2022formalCL,
  title={Formal mathematics statement curriculum learning},
  author={Polu, Stanislas and Han, Jesse Michael and Zheng, Kunhao and Baksys, Mantas and Babuschkin, Igor and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2202.01344},
  year={2022}
}

@article{radford2018GPT,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec},
  year={2018}
}

@article{radford2019lGPT,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{schulman2017PPO,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{wang2023lego,
  title={Lego-prover: Neural theorem proving with growing libraries},
  author={Wang, Haiming and Xin, Huajian and Zheng, Chuanyang and Li, Lin and Liu, Zhengying and Cao, Qingxing and Huang, Yinya and Xiong, Jing and Shi, Han and Xie, Enze and others},
  journal={arXiv preprint arXiv:2310.00656},
  year={2023}
}

@article{xu2024chatglm,
  title={ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline},
  author={Xu, Yifan and Liu, Xiao and Liu, Xinghan and Hou, Zhenyu and Li, Yueyan and Zhang, Xiaohan and Wang, Zihan and Zeng, Aohan and Du, Zhengxiao and Zhao, Wenyi and others},
  journal={arXiv preprint arXiv:2404.02893},
  year={2024}
}

@article{xu2024contrastive,
  title={Contrastive preference optimization: Pushing the boundaries of llm performance in machine translation},
  author={Xu, Haoran and Sharaf, Amr and Chen, Yunmo and Tan, Weiting and Shen, Lingfeng and Van Durme, Benjamin and Murray, Kenton and Kim, Young Jin},
  journal={arXiv preprint arXiv:2401.08417},
  year={2024}
}

@article{zeng2024token,
  title={Token-level Direct Preference Optimization},
  author={Zeng, Yongcheng and Liu, Guoqing and Ma, Weiyu and Yang, Ning and Zhang, Haifeng and Wang, Jun},
  journal={arXiv preprint arXiv:2404.11999},
  year={2024}
}

@inproceedings{zombori2019curriculumTP,
  title={Curriculum learning and theorem proving},
  author={Zombori, Zsolt and Csisz{\'a}rik, Adri{\'a}n and Michalewski, Henryk and Kaliszyk, Cezary and Urban, Josef},
  booktitle={Conference on Artificial Intelligence and Theorem Proving},
  pages={37},
  year={2019}
}

