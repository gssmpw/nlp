\label{sec:ethics}

We have taken the following steps to minimize ethical concerns related to the data collection and evaluation experiments in this work:

\begin{itemize}
      [noitemsep,topsep=3pt,parsep=1pt,partopsep=0pt,leftmargin=0.4cm]
    \item \textbf{Data Safety and Label Accuracy}. Most of the data in \benchmark\ are sourced from public benchmarks with human-annotated labels. While part of the Rule Following data are generated using Claude, every Claude-generated example is further reviewed by the authors of this paper, during which low-quality data are re-written. Therefore, all data in \benchmark\ are verified by humans, which minimizes the risk of containing inaccurate annotations or unsafe AI-generated content.
    \item \textbf{Data Sensitivity}. All safety-related tasks are built upon simulated scenarios without any real-world data. For instance, tasks from the Safety Defense category simulates the LM as a security system with a secret password. User attacks collected by~\citet{TensorTrust} are also based on this assumption, ensuring that no real security attacks or user information are included. Similarly, the \textit{injected instruction} task in the Tool Use category simulates a tool call returning Slack usernames which are sampled from common first names in English. The injected questions are sourced from~\citet{SEP} and focus on commonsense knowledge. In addition, \benchmark\ does not include any data related to real-world security attacks, such as LM jailbreaking (see Appendix~\ref{sec:safety-defense} for discussion on the exclusion of jailbreaking evaluations).
    \item \textbf{Data Bias}. Data in \benchmark\ do not include any information linked to specific users or user groups, which minimizes the likelihood of demographic bias within the dataset.
    \item \textbf{Evaluation Bias}. All tasks in \benchmark\ are designed for programmatic evaluation. This eliminates the potential bias in model-based evaluation, \textit{e.g.}, using GPT-4 as the judge to assess other models' outputs.
\end{itemize}

In conclusion, based on these precautions, the risks associated with the data collection of \benchmark\ and the usage of this benchmark for evaluating LMs should be minimal.

