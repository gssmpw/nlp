While we identified the challenge LMs face in following the instruction hierarchy, this paper did not propose specific solutions to address this issue. We acknowledge the importance of designing training methods which optimize models to better follow the instruction hierarchy, such as constructing data for supervised fine-tuning or preference tuning, but we believe that such optimizations would not produce great research impact without comprehensive evaluation data and in-depth analyses of model behavior. Therefore, this paper focused on bridging the evaluation gap, with the development of solutions being a priority for future work.
