

Instruction-tuned language models (LMs) are increasingly deployed as interactive services across various applications \citep{GPT4,qwen2,deepseek}. To ensure consistent performance and safety, developers typically seek to regulate the model's behavior, such as fine-tuning the model on responding to certain instructions \citep{llama2}, using post-processing techniques to edit model outputs \citep{output-edit-black-box-lm}, and detailing system messages to impose constraints\citep{claude-system-prompt}. However, in real-world applications, these pre-defined regulations frequently struggle to cover the full range of possible user inputs. For instance, users may request tasks beyond the model's intended scope \citep{model_spec}, or the integrated tools may return unexpected content \citep{injecagent}. 
The LM may risk misbehavior if higher-level instructions, such as regulative system messages, are overridden by subsequent conflicting inputs.

This highlights the need for LMs to possess an inherent capacity to follow an \textbf{instruction hierarchy}, where instructions of high-level regulations are always prioritized over low-level inputs. The order of priority -- ranked from highest to lowest -- should be: \textit{system messages}, \textit{user messages}, \textit{conversation history}, and \textit{tool outputs}. This hierarchy was first proposed by \citet{instruction_hierarchy} and aligns with typical practices when using language models. A model that adheres to this hierarchy would be able to spontaneously resolve instruction conflicts by prioritizing higher-order ones, which reduces the dependency on complex regulation methods while also mitigating the risk of misbehavior\footnote{We target scenarios where users can't modify developer-set system messages (\textit{e.g.}, ChatGPT). In contrast, when users can customize prompts, conflicts are rarer unless by mistake.}.

\begin{figure*}[t]
      \centering
      \includegraphics[width=1.0\textwidth]{Figures/1_example.pdf}
      \vspace{-0.6cm}
      \caption{Four categories of the instruction hierarchy and the corresponding priority orders of instructions. Conflict instructions are shown in {\color{red}red}. Models are expected to follow the instruction with the higher priority.}
      \label{fig:example}
      \vspace{-0.2cm}
\end{figure*}

\begin{figure*}[t]
      \centering
      \includegraphics[width=0.8\textwidth]{Figures/1_histogram.pdf}
      \vspace{-0.55cm}
      \caption{Results of mainstream LMs on \benchmark. The reference setting represents original task performance without hierarchical inputs. We observe large performance drops when models face conflicting hierarchical instructions.}
      \vspace{-0.15cm}
      \label{fig:intro_results}
\end{figure*}

Despite its significance, the instruction hierarchy paradigm does not receive much attention in LM research and evaluation. In some models, system messages -- an important tool for giving high-level instructions -- are either not supported \citep{gemma2}, not distinguished from user messages \citep{mistral-large-2}, or exhibit limited variation during training \citep{tulu2}. While many recent models have supported multi-level inputs, the related training details are rarely disclosed. A notable advancement in this area comes from OpenAI's study \citep{instruction_hierarchy}, but their evaluation was limited to GPT models and unreleased proprietary data, focusing solely on safety-related instructions. This constrains its general applicability to a wider range of use cases. To date, there remains no comprehensive benchmark to evaluate how well different LMs adhere to the instruction hierarchy.

In order to bridge this gap and highlight the vital role of the instruction hierarchy, we create \benchmark, a comprehensive benchmark for \textbf{I}nstruction \textbf{H}ierarchy \textbf{Eval}uation. It is designed with the following characteristics:

\begin{enumerate}
      [noitemsep,topsep=3pt,parsep=1pt,partopsep=0pt,leftmargin=0.4cm]
      \item \textbf{Diverse scenarios}: Consisting of 3,538 examples and nine tasks, it spans four key scenarios involving hierarchical instructions: rule following, task execution, safety defense, and tool use.
      \item \textbf{Comprehensive input hierarchy:} It covers four types of input: system messages, user messages, conversation history, and tool outputs.
      \item \textbf{Instruction alignments and conflicts}: It includes both settings where (1) low-priority inputs align with high-level regulations, and (2) low-priority inputs contain additional instructions that conflict with those regulations.
      \item \textbf{Varied task difficulties}: It offers various task difficulty settings by adjusting the strictness of the instruction phrasing, such as intensifying conflicts by requiring the model to exclusively follow specific instructions.
      \item \textbf{Programmable evaluation}: All tasks are evaluated programmatically, ensuring the efficiency and reproducibility of the evaluation process.
\end{enumerate}

We evaluate a variety of mainstream LMs using \benchmark\ and observe several key insights: (1) LMs struggle to prioritize high-level instructions when conflicts arise, with open-source models showing less than 50\% accuracy in resolving these conflicts. This performance significantly lags behind both GPT-4o and their original instruction-following accuracy, as shown in Figure~\ref{fig:intro_results}; (2) Even without conflicts, model performance on hierarchical inputs is inconsistent with the single-input reference setting; (3) Models' handling of conflicts is easily influenced by superficial factors like the strictness of instructions, and does not scale effectively with model size. These findings suggest that current LMs are not fully optimized for following the instruction hierarchy, leading to performance degradation or even unsafe behavior. We hope that our study can spark deeper research into this direction.

We summarize the main contributions of this work as follows:

\begin{itemize}
      [noitemsep,topsep=3pt,parsep=1pt,partopsep=0pt,leftmargin=0.4cm]
      \item We design a comprehensive evaluation for assessing LMs' compliance with the instruction hierarchy, covering diverse scenarios where LMs face instructions of different priorities.
      \item We collect a benchmark to support this evaluation, including settings where hierarchical instructions either align or conflict, all of which are programmatically evaluated.
      \item We evaluate a wide selection of LMs and find that they are not sufficiently optimized for the instruction hierarchy, highlighting potential risks in their real-world applications.
\end{itemize}
