% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@inproceedings{GPT3,
  author       = {Tom B. Brown and
                  Benjamin Mann and
                  Nick Ryder and
                  Melanie Subbiah and
                  Jared Kaplan and
                  Prafulla Dhariwal and
                  Arvind Neelakantan and
                  Pranav Shyam and
                  Girish Sastry and
                  Amanda Askell and
                  Sandhini Agarwal and
                  Ariel Herbert{-}Voss and
                  Gretchen Krueger and
                  Tom Henighan and
                  Rewon Child and
                  Aditya Ramesh and
                  Daniel M. Ziegler and
                  Jeffrey Wu and
                  Clemens Winter and
                  Christopher Hesse and
                  Mark Chen and
                  Eric Sigler and
                  Mateusz Litwin and
                  Scott Gray and
                  Benjamin Chess and
                  Jack Clark and
                  Christopher Berner and
                  Sam McCandlish and
                  Alec Radford and
                  Ilya Sutskever and
                  Dario Amodei},
  editor       = {Hugo Larochelle and
                  Marc'Aurelio Ranzato and
                  Raia Hadsell and
                  Maria{-}Florina Balcan and
                  Hsuan{-}Tien Lin},
  title        = {Language Models are Few-Shot Learners},
  booktitle    = {Processing of NeurIPS 2020},
  year         = {2020},
 }
@article{opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021}
}

@article{PaLM,
  author       = {Aakanksha Chowdhery and
                  Sharan Narang and
                  Jacob Devlin and
                  Maarten Bosma and
                  Gaurav Mishra and
                  Adam Roberts and
                  Paul Barham and
                  Hyung Won Chung and
                  Charles Sutton and
                  Sebastian Gehrmann and
                  Parker Schuh and
                  Kensen Shi and
                  Sasha Tsvyashchenko and
                  Joshua Maynez and
                  Abhishek Rao and
                  Parker Barnes and
                  Yi Tay and
                  Noam Shazeer and
                  Vinodkumar Prabhakaran and
                  Emily Reif and
                  Nan Du and
                  Ben Hutchinson and
                  Reiner Pope and
                  James Bradbury and
                  Jacob Austin and
                  Michael Isard and
                  Guy Gur{-}Ari and
                  Pengcheng Yin and
                  Toju Duke and
                  Anselm Levskaya and
                  Sanjay Ghemawat and
                  Sunipa Dev and
                  Henryk Michalewski and
                  Xavier Garcia and
                  Vedant Misra and
                  Kevin Robinson and
                  Liam Fedus and
                  Denny Zhou and
                  Daphne Ippolito and
                  David Luan and
                  Hyeontaek Lim and
                  Barret Zoph and
                  Alexander Spiridonov and
                  Ryan Sepassi and
                  David Dohan and
                  Shivani Agrawal and
                  Mark Omernick and
                  Andrew M. Dai and
                  Thanumalayan Sankaranarayana Pillai and
                  Marie Pellat and
                  Aitor Lewkowycz and
                  Erica Moreira and
                  Rewon Child and
                  Oleksandr Polozov and
                  Katherine Lee and
                  Zongwei Zhou and
                  Xuezhi Wang and
                  Brennan Saeta and
                  Mark Diaz and
                  Orhan Firat and
                  Michele Catasta and
                  Jason Wei and
                  Kathy Meier{-}Hellstern and
                  Douglas Eck and
                  Jeff Dean and
                  Slav Petrov and
                  Noah Fiedel},
  title        = {PaLM: Scaling Language Modeling with Pathways},
  journal      = {J. Mach. Learn. Res.},
  volume       = {24},
  pages        = {240:1--240:113},
  year         = {2023},
  url          = {https://jmlr.org/papers/v24/22-1144.html},
  timestamp    = {Wed, 11 Sep 2024 14:41:28 +0200},
  biburl       = {https://dblp.org/rec/journals/jmlr/ChowdheryNDBMRBCSGSSTMRBTSPRDHPBAI23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{T5,
  author       = {Colin Raffel and
                  Noam Shazeer and
                  Adam Roberts and
                  Katherine Lee and
                  Sharan Narang and
                  Michael Matena and
                  Yanqi Zhou and
                  Wei Li and
                  Peter J. Liu},
  title        = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text
                  Transformer},
  journal      = {J. Mach. Learn. Res.},
  volume       = {21},
  pages        = {140:1--140:67},
  year         = {2020},
  url          = {https://jmlr.org/papers/v21/20-074.html},
  timestamp    = {Wed, 11 Sep 2024 14:41:27 +0200},
  biburl       = {https://dblp.org/rec/journals/jmlr/RaffelSRLNMZLL20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{Pengi,
  author       = {Soham Deshmukh and
                  Benjamin Elizalde and
                  Rita Singh and
                  Huaming Wang},
  title        = {Pengi: An Audio Language Model for Audio Tasks},
  booktitle    = {Proceeding of NeurIPS 2023},
  year         = {2023},
}

@article{zhou2024lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@article{chen2025minmo,
  title={Minmo: A multimodal large language model for seamless voice interaction},
  author={Chen, Qian and Chen, Yafeng and Chen, Yanni and Chen, Mengzhe and Chen, Yingda and Deng, Chong and Du, Zhihao and Gao, Ruize and Gao, Changfeng and Gao, Zhifu and others},
  journal={arXiv preprint arXiv:2501.06282},
  year={2025}
}
@article{geng2025osum,
  title={OSUM: Advancing Open Speech Understanding Models with Limited Resources in Academia},
  author={Geng, Xuelong and Wei, Kun and Shao, Qijie and Liu, Shuiyun and Lin, Zhennan and Zhao, Zhixian and Li, Guojian and Tian, Wenjie and Chen, Peikun and Li, Yangze and others},
  journal={arXiv preprint arXiv:2501.13306},
  year={2025}
}
@article{fang2024llama,
  title={Llama-omni: Seamless speech interaction with large language models},
  author={Fang, Qingkai and Guo, Shoutao and Zhou, Yan and Ma, Zhengrui and Zhang, Shaolei and Feng, Yang},
  journal={arXiv preprint arXiv:2409.06666},
  year={2024}
}
@inproceedings{post-2018-call,
  title = "A Call for Clarity in Reporting {BLEU} Scores",
  author = "Post, Matt",
  booktitle = "Proceedings of the Third Conference on Machine Translation: Research Papers",
  month = oct,
  year = "2018",
  address = "Belgium, Brussels",
  publisher = "Association for Computational Linguistics",
  url = "https://www.aclweb.org/anthology/W18-6319",
  pages = "186--191",
}
@article{arivazhagan2019massively,
  title={Massively multilingual neural machine translation in the wild: Findings and challenges},
  author={Arivazhagan, Naveen and Bapna, Ankur and Firat, Orhan and Lepikhin, Dmitry and Johnson, Melvin and Krikun, Maxim and Chen, Mia Xu and Cao, Yuan and Foster, George and Cherry, Colin and others},
  journal={arXiv preprint arXiv:1907.05019},
  year={2019}
}
@article{chen2024allava,
  title={Allava: Harnessing gpt4v-synthesized data for a lite vision-language model},
  author={Chen, Guiming Hardy and Chen, Shunian and Zhang, Ruifei and Chen, Junying and Wu, Xiangbo and Zhang, Zhiyi and Chen, Zhihong and Li, Jianquan and Wan, Xiang and Wang, Benyou},
  journal={arXiv preprint arXiv:2402.11684},
  year={2024}
}

@article{defossez2022high,
  title={High fidelity neural audio compression},
  author={D{\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  journal={arXiv preprint arXiv:2210.13438},
  year={2022}
}

@inproceedings{song-etal-2025-less,
    title = "Less is More: A Simple yet Effective Token Reduction Method for Efficient Multi-modal {LLM}s",
    author = "Song, Dingjie  and
      Wang, Wenjun  and
      Chen, Shunian  and
      Wang, Xidong  and
      Guan, Michael X.  and
      Wang, Benyou",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.508/",
    pages = "7614--7623",

}

@inproceedings{WizardLM,
  author       = {Can Xu and
                  Qingfeng Sun and
                  Kai Zheng and
                  Xiubo Geng and
                  Pu Zhao and
                  Jiazhan Feng and
                  Chongyang Tao and
                  Qingwei Lin and
                  Daxin Jiang},
  title        = {WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex
                  Instructions},
  booktitle    = {Proceeding of {ICLR} 2024},
  year         = {2024},
}
@article{InstructTTS,
  author       = {Dongchao Yang and
                  Songxiang Liu and
                  Rongjie Huang and
                  Chao Weng and
                  Helen Meng},
  title        = {InstructTTS: Modelling Expressive {TTS} in Discrete Latent Space With
                  Natural Language Style Prompt},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  year         = {2024},
}

@article{diff_deepfake,
  title={Diffuse or Confuse: A Diffusion Deepfake Speech Dataset},
  author={Firc, Anton and Malinka, Kamil and Han{\'a}{\v{c}}ek, Petr},
  journal={arXiv preprint arXiv:2410.06796},
  year={2024}
}
@inproceedings{zhang2023rethinking,
  title={Rethinking and Improving Multi-task Learning for End-to-end Speech Translation},
  author={Zhang, Yuhao and Xu, Chen and Li, Bei and Chen, Hao and Xiao, Tong and Zhang, Chunliang and Zhu, Jingbo},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={10753--10765},
  year={2023}
}

@inproceedings{graves2006connectionist,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}

@article{gulati2020conformer,
  title={Conformer: Convolution-augmented transformer for speech recognition},
  author={Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others},
  journal={arXiv preprint arXiv:2005.08100},
  year={2020}
}

@inproceedings{whisper,
  author       = {Alec Radford and
                  Jong Wook Kim and
                  Tao Xu and
                  Greg Brockman and
                  Christine McLeavey and
                  Ilya Sutskever},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {Robust Speech Recognition via Large-Scale Weak Supervision},
  booktitle    = {Proceedings of  {ICML},2023},
  year         = {2023},
}

@book{SRbook,
  title={Statistical methods for speech recognition},
  author={Jelinek, Frederick},
  year={1998},
  publisher={MIT press}
}

@misc{ljspeech,
  author       = {Keith Ito and Linda Johnson},
  title        = {The LJ Speech Dataset},
  howpublished = {\url{https://keithito.com/LJ-Speech-Dataset/}},
  year         = 2017
}

@inproceedings{gigaSpeech,
  author       = {Guoguo Chen and
                  Shuzhou Chai and
                  Guan{-}Bo Wang and
                  Jiayu Du and
                  Wei{-}Qiang Zhang and
                  Chao Weng and
                  Dan Su and
                  Daniel Povey and
                  Jan Trmal and
                  Junbo Zhang and
                  Mingjie Jin and
                  Sanjeev Khudanpur and
                  Shinji Watanabe and
                  Shuaijiang Zhao and
                  Wei Zou and
                  Xiangang Li and
                  Xuchen Yao and
                  Yongqing Wang and
                  Zhao You and
                  Zhiyong Yan},
  editor       = {Hynek Hermansky and
                  Honza Cernock{\'{y}} and
                  Luk{\'{a}}s Burget and
                  Lori Lamel and
                  Odette Scharenborg and
                  Petr Motl{\'{\i}}cek},
  title        = {GigaSpeech: An Evolving, Multi-Domain {ASR} Corpus with 10, 000 Hours
                  of Transcribed Audio},
  booktitle    = {Proceeding of Interspeech, 2021},
  year         = {2021},
}

@article{BigSSL,
  author       = {Yu Zhang and
                  Daniel S. Park and
                  Wei Han and
                  James Qin and
                  Anmol Gulati and
                  Joel Shor and
                  Aren Jansen and
                  Yuanzhong Xu and
                  Yanping Huang and
                  Shibo Wang and
                  Zongwei Zhou and
                  Bo Li and
                  Min Ma and
                  William Chan and
                  Jiahui Yu and
                  Yongqiang Wang and
                  Liangliang Cao and
                  Khe Chai Sim and
                  Bhuvana Ramabhadran and
                  Tara N. Sainath and
                  Fran{\c{c}}oise Beaufays and
                  Zhifeng Chen and
                  Quoc V. Le and
                  Chung{-}Cheng Chiu and
                  Ruoming Pang and
                  Yonghui Wu},
  title        = {BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning
                  for Automatic Speech Recognition},
  journal      = {{IEEE} J. Sel. Top. Signal Process.},
  volume       = {16},
  number       = {6},
  pages        = {1519--1532},
  year         = {2022},
  doi          = {10.1109/JSTSP.2022.3182537},
  timestamp    = {Sun, 13 Nov 2022 17:53:25 +0100},
}
@inproceedings{huggingGPT,
  author       = {Yongliang Shen and
                  Kaitao Song and
                  Xu Tan and
                  Dongsheng Li and
                  Weiming Lu and
                  Yueting Zhuang},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {HuggingGPT: Solving {AI} Tasks with ChatGPT and its Friends in Hugging
                  Face},
  booktitle    = {Processing of NeurIPS 2023},
  year         = {2023},
}
@article{wildbench,
  title={WILDBENCH: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild},
  author={Lin, Bill Yuchen and Deng, Yuntian and Chandu, Khyathi and Brahman, Faeze and Ravichander, Abhilasha and Pyatkin, Valentina and Dziri, Nouha and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2406.04770},
  year={2024}
}

@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{Make-An-Audio,
  author       = {Rongjie Huang and
                  Jiawei Huang and
                  Dongchao Yang and
                  Yi Ren and
                  Luping Liu and
                  Mingze Li and
                  Zhenhui Ye and
                  Jinglin Liu and
                  Xiang Yin and
                  Zhou Zhao},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion
                  Models},
  booktitle    = {Proceeding of {ICML} 2023},
  year         = {2023},
}

@article{human_center_bench,

    	title={A User-Centric Benchmark for Evaluating Large Language Models},
	author={Jiayin Wang and Fengran Mo and Weizhi Ma and Peijie Sun and Min Zhang and Jian-Yun Nie},
	year={2024},
  journal={arXiv preprint arXiv:2404.13940},
  year={2024}
}

@article{fireredtts,
  title={FireRedTTS: A Foundation Text-To-Speech Framework for Industry-Level Generative Speech Applications},
  author={Guo, Hao-Han and Liu, Kun and Shen, Fei-Yu and Wu, Yi-Chen and Xie, Feng-Long and Xie, Kun and Xu, Kai-Tuo},
  journal={arXiv preprint arXiv:2409.03283},
  year={2024}
}

@inproceedings{CM_TTS,
  author       = {Xiang Li and
                  FanBu FanBu and
                  Ambuj Mehrish and
                  Yingting Li and
                  Jiale Han and
                  Bo Cheng and
                  Soujanya Poria},
  editor       = {Kevin Duh and
                  Helena G{\'{o}}mez{-}Adorno and
                  Steven Bethard},
  title        = {{CM-TTS:} Enhancing Real Time Text-to-Speech Synthesis Efficiency
                  through Weighted Samplers and Consistency Models},
  booktitle    = {Proceedings of {NAACL}
                  2024},
  year         = {2024},
}

@inproceedings{PromptTTS2,
  author       = {Yichong Leng and
                  Zhifang Guo and
                  Kai Shen and
                  Zeqian Ju and
                  Xu Tan and
                  Eric Liu and
                  Yufei Liu and
                  Dongchao Yang and
                  Leying Zhang and
                  Kaitao Song and
                  Lei He and
                  Xiangyang Li and
                  Sheng Zhao and
                  Tao Qin and
                  Jiang Bian},
  title        = {PromptTTS 2: Describing and Generating Voices with Text Prompt},
  booktitle    = {Proceeding of {ICLR} 2024},
  year         = {2024},
}

@article{InstructTTS,
  author       = {Dongchao Yang and
                  Songxiang Liu and
                  Rongjie Huang and
                  Chao Weng and
                  Helen Meng},
  title        = {InstructTTS: Modelling Expressive {TTS} in Discrete Latent Space With
                  Natural Language Style Prompt},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {32},
  pages        = {2913--2925},
  year         = {2024},
}

@inproceedings{fastspeech2,
  author       = {Yi Ren and
                  Chenxu Hu and
                  Xu Tan and
                  Tao Qin and
                  Sheng Zhao and
                  Zhou Zhao and
                  Tie{-}Yan Liu},
  title        = {FastSpeech 2: Fast and High-Quality End-to-End Text to Speech},
  booktitle    = {Proceeding of {ICLR} 2021},
  year         = {2021},
}
@article{audioLM,
  author       = {Zal{\'{a}}n Borsos and
                  Rapha{\"{e}}l Marinier and
                  Damien Vincent and
                  Eugene Kharitonov and
                  Olivier Pietquin and
                  Matthew Sharifi and
                  Dominik Roblek and
                  Olivier Teboul and
                  David Grangier and
                  Marco Tagliasacchi and
                  Neil Zeghidour},
  title        = {AudioLM: {A} Language Modeling Approach to Audio Generation},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {31},
  pages        = {2523--2533},
  year         = {2023},
}
@inproceedings{audioGen,
  author       = {Felix Kreuk and
                  Gabriel Synnaeve and
                  Adam Polyak and
                  Uriel Singer and
                  Alexandre D{\'{e}}fossez and
                  Jade Copet and
                  Devi Parikh and
                  Yaniv Taigman and
                  Yossi Adi},
  title        = {AudioGen: Textually Guided Audio Generation},
  booktitle    = {Proceeding of {ICLR} 2023},
  year         = {2023},
}
@article{diffSound,
  author       = {Dongchao Yang and
                  Jianwei Yu and
                  Helin Wang and
                  Wen Wang and
                  Chao Weng and
                  Yuexian Zou and
                  Dong Yu},
  title        = {Diffsound: Discrete Diffusion Model for Text-to-Sound Generation},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {31},
  pages        = {1720--1733},
  year         = {2023},
}

@article{liu2022diffgan,
  title={Diffgan-tts: High-fidelity and efficient text-to-speech with denoising diffusion gans},
  author={Liu, Songxiang and Su, Dan and Yu, Dong},
  journal={arXiv preprint arXiv:2201.11972},
  year={2022}
}


@inproceedings{AlignBench,
  author       = {Xiao Liu and
                  Xuanyu Lei and
                  Shengyuan Wang and
                  Yue Huang and
                  Andrew Feng and
                  Bosi Wen and
                  Jiale Cheng and
                  Pei Ke and
                  Yifan Xu and
                  Weng Lam Tam and
                  Xiaohan Zhang and
                  Lichao Sun and
                  Xiaotao Gu and
                  Hongning Wang and
                  Jing Zhang and
                  Minlie Huang and
                  Yuxiao Dong and
                  Jie Tang},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {AlignBench: Benchmarking Chinese Alignment of Large Language Models},
  booktitle    = {Proceedings of {ACL} 2024},
  year         = {2024},
  url          = {https://doi.org/10.18653/v1/2024.acl-long.624},
}

% 主要优势在于语速可控。
@article{F5TTS,
  title={F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching},
  author={Chen, Yushen and Niu, Zhikang and Ma, Ziyang and Deng, Keqi and Wang, Chunhui and Zhao, Jian and Yu, Kai and Chen, Xie},
  journal={arXiv preprint arXiv:2410.06885},
  year={2024}
}

@inproceedings{Nearest_Neighbors_voice_conversion,
  author       = {Matthew Baas and
                  Benjamin van Niekerk and
                  Herman Kamper},
  editor       = {Naomi Harte and
                  Julie Carson{-}Berndsen and
                  Gareth Jones},
  title        = {Voice Conversion With Just Nearest Neighbors},
  booktitle    = {Proceeding of Interspeech 2023},
  year         = {2023},
}

@article{RefXVC,
  author       = {Mingyang Zhang and
                  Yi Zhou and
                  Yi Ren and
                  Chen Zhang and
                  Xiang Yin and
                  Haizhou Li},
  title        = {RefXVC: Cross-Lingual Voice Conversion With Enhanced Reference Leveraging},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {32},
  pages        = {4146--4156},
  year         = {2024},
}

@inproceedings{emotion_VC,
  author       = {Kun Zhou and
                  Berrak Sisman and
                  Rui Liu and
                  Haizhou Li},
  title        = {Seen and Unseen Emotional Style Transfer for Voice Conversion with
                  {A} New Emotional Speech Dataset},
  booktitle    = {Processing of {ICASSP} 2021},
  year         = {2021},

}

@article{timeSP,
  author       = {Tingting Wang and
                  Zexu Pan and
                  Meng Ge and
                  Zhen Yang and
                  Haizhou Li},
  title        = {Time-Domain Speech Separation Networks With Graph Encoding Auxiliary},
  journal      = {{IEEE} Signal Process. Lett.},
  volume       = {30},
  pages        = {110--114},
  year         = {2023},
}

@inproceedings{LSTMSP,
  author       = {Chenglin Xu and
                  Wei Rao and
                  Xiong Xiao and
                  Eng Siong Chng and
                  Haizhou Li},
  title        = {Single Channel Speech Separation with Constrained Utterance Level
                  Permutation Invariant Training Using Grid {LSTM}},
  booktitle    = {Processing of {ICASSP} 2018},
  year         = {2018},
}

@inproceedings{SEGAN,
  author       = {Santiago Pascual and
                  Antonio Bonafonte and
                  Joan Serr{\`{a}}},
  editor       = {Francisco Lacerda},
  title        = {{SEGAN:} Speech Enhancement Generative Adversarial Network},
  booktitle    = {Proceeding of Interspeech 2017},
  year         = {2017},
}

@inproceedings{realtimeSE,
  author       = {Alexandre D{\'{e}}fossez and
                  Gabriel Synnaeve and
                  Yossi Adi},
  editor       = {Helen Meng and
                  Bo Xu and
                  Thomas Fang Zheng},
  title        = {Real Time Speech Enhancement in the Waveform Domain},
  booktitle    = {Proceeding of Interspeech 2020},
  year         = {2020},
}

@inproceedings{cDiffSE,
  author       = {Yen{-}Ju Lu and
                  Zhong{-}Qiu Wang and
                  Shinji Watanabe and
                  Alexander Richard and
                  Cheng Yu and
                  Yu Tsao},
  title        = {Conditional Diffusion Probabilistic Model for Speech Enhancement},
  booktitle    = {Processing of {ICASSP} 2022},
  year         = {2022},
}

@article{DiffSE,
  author       = {Julius Richter and
                  Simon Welker and
                  Jean{-}Marie Lemercier and
                  Bunlong Lay and
                  Timo Gerkmann},
  title        = {Speech Enhancement and Dereverberation With Diffusion-Based Generative
                  Models},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {31},
  pages        = {2351--2364},
  year         = {2023},
}

@inproceedings{AttentionSP,
  author       = {Cem Subakan and
                  Mirco Ravanelli and
                  Samuele Cornell and
                  Mirko Bronzi and
                  Jianyuan Zhong},
  title        = {Attention Is All You Need In Speech Separation},
  booktitle    = {Processing of {ICASSP} 2021},
  year         = {2021},
}

@inproceedings{singing_VC,
  title={The singing voice conversion challenge 2023},
  author={Huang, Wen-Chin and Violeta, Lester Phillip and Liu, Songxiang and Shi, Jiatong and Toda, Tomoki},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@inproceedings{Freevc,
  author       = {Jingyi Li and
                  Weiping Tu and
                  Li Xiao},
  title        = {Freevc: Towards High-Quality Text-Free One-Shot Voice Conversion},
  booktitle    = {Processing of {ICASSP} 2023},
  year         = {2023},
}


@article{hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}

@article{accent_detection,
  title={Language accent detection with CNN using sparse data from a crowd-sourced speech archive},
  author={Mikhailava, Veranika and Lesnichaia, Mariia and Bogach, Natalia and Lezhenin, Iurii and Blake, John and Pyshkin, Evgeny},
  journal={Mathematics},
  volume={10},
  number={16},
  pages={2913},
  year={2022},
  publisher={MDPI}
}

@inproceedings{shanghaiACCENT,
  author       = {Yanli Zheng and
                  Richard Sproat and
                  Liang Gu and
                  Izhak Shafran and
                  Haolang Zhou and
                  Yi Su and
                  Daniel Jurafsky and
                  Rebecca Starr and
                  Su{-}Youn Yoon},
  title        = {Accent detection and speech recognition for Shanghai-accented Mandarin},
  booktitle    = {Proceeding of INTERSPEECH-Eurospeech 2005},
  year         = {2005},
}

@inproceedings{ParalinguisticAnalysis,
  author       = {Alena Velichko and
                  Maxim Markitantov and
                  Heysem Kaya and
                  Alexey Karpov},
  editor       = {Hanseok Ko and
                  John H. L. Hansen},
  title        = {Complex Paralinguistic Analysis of Speech: Predicting Gender, Emotions
                  and Deception in a Hierarchical Framework},
  booktitle    = {Proceeding of Interspeech 2022},
  year         = {2022},
}

@inproceedings{ageDetection,
  author       = {Maxim Markitantov and
                  Oxana Verkholyak},
  editor       = {Albert Ali Salah and
                  Alexey Karpov and
                  Rodmonga Potapova},
  title        = {Automatic Recognition of Speaker Age and Gender Based on Deep Neural
                  Networks},
  booktitle    = {Proceeding of {SPECOM} 2019},
  year         = {2019},
}

@inproceedings{Unispeech-Sat,
  author       = {Sanyuan Chen and
                  Yu Wu and
                  Chengyi Wang and
                  Zhengyang Chen and
                  Zhuo Chen and
                  Shujie Liu and
                  Jian Wu and
                  Yao Qian and
                  Furu Wei and
                  Jinyu Li and
                  Xiangzhan Yu},
  title        = {Unispeech-Sat: Universal Speech Representation Learning With Speaker
                  Aware Pre-Training},
  booktitle    = {Processing of {ICASSP} 2022},
  year         = {2022},
  url          = {https://doi.org/10.1109/ICASSP43922.2022.9747077},
}


@article{funaudiollm,
  title={FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs},
  author={SpeechTeam, Tongyi},
  journal={arXiv preprint arXiv:2407.04051},
  year={2024}
}


@article{huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, Alexander M. Rush},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@article{wavllm,
  title={Wavllm: Towards robust and adaptive speech large language model},
  author={Hu, Shujie and Zhou, Long and Liu, Shujie and Chen, Sanyuan and Hao, Hongkun and Pan, Jing and Liu, Xunying and Li, Jinyu and Sivasankaran, Sunit and Liu, Linquan and others},
  journal={arXiv preprint arXiv:2404.00656},
  year={2024}
}

@article{GAMA,
  author       = {Sreyan Ghosh and
                  Sonal Kumar and
                  Ashish Seth and
                  Chandra Kiran Reddy Evuru and
                  Utkarsh Tyagi and
                  Sakshi Singh and
                  Oriol Nieto and
                  Ramani Duraiswami and
                  Dinesh Manocha},
  title        = {{GAMA:} {A} Large Audio-Language Model with Advanced Audio Understanding
                  and Complex Reasoning Abilities},
  journal      = {arXiv preprint arXiv:2406.11768},
  year         = {2024},
}

@article{qwen2audio,
  title={Qwen2-Audio Technical Report},
  author={Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others},
  journal={arXiv preprint arXiv:2407.10759},
  year={2024}
}

@article{qwenaudio,
  title={Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models},
  author={Chu, Yunfei and Xu, Jin and Zhou, Xiaohuan and Yang, Qian and Zhang, Shiliang and Yan, Zhijie and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.07919},
  year={2023}
}



@inproceedings{VoiceCraft,
  author       = {Puyuan Peng and
                  Po{-}Yao Huang and
                  Shang{-}Wen Li and
                  Abdelrahman Mohamed and
                  David Harwath},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild},
  booktitle    = {Proceedings of {ACL} 2024},
  year         = {2024},
}

@article{audiobox,
  title={Audiobox: Unified audio generation with natural language prompts},
  author={Vyas, Apoorv and Shi, Bowen and Le, Matthew and Tjandra, Andros and Wu, Yi-Chiao and Guo, Baishan and Zhang, Jiemin and Zhang, Xinyue and Adkins, Robert and Ngan, William and others},
  journal={arXiv preprint arXiv:2312.15821},
  year={2023}
}

@inproceedings{PromptTTS2,
  author       = {Yichong Leng and
                  Zhifang Guo and
                  Kai Shen and
                  Zeqian Ju and
                  Xu Tan and
                  Eric Liu and
                  Yufei Liu and
                  Dongchao Yang and
                  Leying Zhang and
                  Kaitao Song and
                  Lei He and
                  Xiangyang Li and
                  Sheng Zhao and
                  Tao Qin and
                  Jiang Bian},
  title        = {PromptTTS 2: Describing and Generating Voices with Text Prompt},
  booktitle    = {Proceeding of {ICLR} 2024},
  year         = {2024},
}

@article{audiobox,
  title={Audiobox: Unified audio generation with natural language prompts},
  author={Vyas, Apoorv and Shi, Bowen and Le, Matthew and Tjandra, Andros and Wu, Yi-Chiao and Guo, Baishan and Zhang, Jiemin and Zhang, Xinyue and Adkins, Robert and Ngan, William and others},
  journal={arXiv preprint arXiv:2312.15821},
  year={2023}
}

@inproceedings{PromptTTS,
  author       = {Zhifang Guo and
                  Yichong Leng and
                  Yihan Wu and
                  Sheng Zhao and
                  Xu Tan},
  title        = {Prompttts: Controllable Text-To-Speech With Text Descriptions},
  booktitle    = {Processing of 
                  {ICASSP} 2023},
  year         = {2023},
}
@article{opt_iml,
  title={Opt-iml: Scaling language model instruction meta learning through the lens of generalization},
  author={Iyer, Srinivasan and Lin, Xi Victoria and Pasunuru, Ramakanth and Mihaylov, Todor and Simig, Daniel and Yu, Ping and Shuster, Kurt and Wang, Tianlu and Liu, Qing and Koura, Punit Singh and others},
  journal={arXiv preprint arXiv:2212.12017},
  year={2022}
}

@article{airbench,
  title={AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension},
  author={Yang, Qian and Xu, Jin and Liu, Wenrui and Chu, Yunfei and Jiang, Ziyue and Zhou, Xiaohuan and Leng, Yichong and Lv, Yuanjun and Zhao, Zhou and Zhou, Chang and others},
  journal={arXiv preprint arXiv:2402.07729},
  year={2024}
}

@article{sdeval,
  title={SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond Words},
  author={Ao, Junyi and Wang, Yuancheng and Tian, Xiaohai and Chen, Dekun and Zhang, Jun and Lu, Lu and Wang, Yuxuan and Li, Haizhou and Wu, Zhizheng},
  journal={arXiv preprint arXiv:2406.13340},
  year={2024}
}

@article{audiobench,
  title={Audiobench: A universal benchmark for audio large language models},
  author={Wang, Bin and Zou, Xunlong and Lin, Geyu and Sun, Shuo and Liu, Zhuohan and Zhang, Wenyu and Liu, Zhengyuan and Aw, AiTi and Chen, Nancy F},
  journal={arXiv preprint arXiv:2406.16020},
  year={2024}
}

@inproceedings{speechGPT,
  author       = {Dong Zhang and
                  Shimin Li and
                  Xin Zhang and
                  Jun Zhan and
                  Pengyu Wang and
                  Yaqian Zhou and
                  Xipeng Qiu},
  editor       = {Houda Bouamor and
                  Juan Pino and
                  Kalika Bali},
  title        = {SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal
                  Conversational Abilities},
  booktitle    = {Proceedings of  {EMNLP}, 2023},
  year         = {2023},
}
@article{ji2024wavchat,
  title={WavChat: A Survey of Spoken Dialogue Models},
  author={Ji, Shengpeng and Chen, Yifu and Fang, Minghui and Zuo, Jialong and Lu, Jingyu and Wang, Hanting and Jiang, Ziyue and Zhou, Long and Liu, Shujie and Cheng, Xize and others},
  journal={arXiv preprint arXiv:2411.13577},
  year={2024}
}
@inproceedings{LoRA,
  author       = {Edward J. Hu and
                  Yelong Shen and
                  Phillip Wallis and
                  Zeyuan Allen{-}Zhu and
                  Yuanzhi Li and
                  Shean Wang and
                  Lu Wang and
                  Weizhu Chen},
  title        = {LoRA: Low-Rank Adaptation of Large Language Models},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}
                  2022, Virtual Event, April 25-29, 2022},
  publisher    = {OpenReview.net},
  year         = {2022},
  url          = {https://openreview.net/forum?id=nZeVKeeFYf9},
  timestamp    = {Sat, 20 Aug 2022 01:15:42 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/HuSWALWWC22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{BEATs,
  author       = {Sanyuan Chen and
                  Yu Wu and
                  Chengyi Wang and
                  Shujie Liu and
                  Daniel Tompkins and
                  Zhuo Chen and
                  Wanxiang Che and
                  Xiangzhan Yu and
                  Furu Wei},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {BEATs: Audio Pre-Training with Acoustic Tokenizers},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {5178--5193},
  publisher    = {{PMLR}},
  year         = {2023},
  url          = {https://proceedings.mlr.press/v202/chen23ag.html},
  timestamp    = {Wed, 12 Jun 2024 14:22:04 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/ChenW00T0CYW23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{WavLM,
  author       = {Sanyuan Chen and
                  Chengyi Wang and
                  Zhengyang Chen and
                  Yu Wu and
                  Shujie Liu and
                  Zhuo Chen and
                  Jinyu Li and
                  Naoyuki Kanda and
                  Takuya Yoshioka and
                  Xiong Xiao and
                  Jian Wu and
                  Long Zhou and
                  Shuo Ren and
                  Yanmin Qian and
                  Yao Qian and
                  Jian Wu and
                  Michael Zeng and
                  Xiangzhan Yu and
                  Furu Wei},
  title        = {WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech
                  Processing},
  journal      = {{IEEE} J. Sel. Top. Signal Process.},
  volume       = {16},
  number       = {6},
  pages        = {1505--1518},
  year         = {2022},
  url          = {https://doi.org/10.1109/JSTSP.2022.3188113},
  doi          = {10.1109/JSTSP.2022.3188113},
  timestamp    = {Fri, 13 Dec 2024 07:52:49 +0100},
  biburl       = {https://dblp.org/rec/journals/jstsp/ChenWCWLCLKYXWZ22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{dynamic_superb,
  author       = {Chien{-}Yu Huang and
                  Ke{-}Han Lu and
                  Shih{-}Heng Wang and
                  Chi{-}Yuan Hsiao and
                  Chun{-}Yi Kuan and
                  Haibin Wu and
                  Siddhant Arora and
                  Kai{-}Wei Chang and
                  Jiatong Shi and
                  Yifan Peng and
                  Roshan S. Sharma and
                  Shinji Watanabe and
                  Bhiksha Ramakrishnan and
                  Shady Shehata and
                  Hung{-}Yi Lee},
  title        = {Dynamic-Superb: Towards a Dynamic, Collaborative, and Comprehensive
                  Instruction-Tuning Benchmark For Speech},
  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing,
                  {ICASSP} 2024, Seoul, Republic of Korea, April 14-19, 2024},
  pages        = {12136--12140},
  publisher    = {{IEEE}},
  year         = {2024},
  url          = {https://doi.org/10.1109/ICASSP48485.2024.10448257},
  doi          = {10.1109/ICASSP48485.2024.10448257},
  timestamp    = {Wed, 07 Aug 2024 12:26:13 +0200},
  biburl       = {https://dblp.org/rec/conf/icassp/HuangLWHKWACSPS24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{yang2024large,
  title={A Large-Scale Evaluation of Speech Foundation Models},
  author={Yang, Shu-wen and Chang, Heng-Jui and Huang, Zili and Liu, Andy T and Lai, Cheng-I and Wu, Haibin and Shi, Jiatong and Chang, Xuankai and Tsai, Hsiang-Sheng and Huang, Wen-Chin and others},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2024},
  publisher={IEEE}
}

@article{defossez2024moshi,
  title={Moshi: a speech-text foundation model for real-time dialogue},
  author={D{\'e}fossez, Alexandre and Mazar{\'e}, Laurent and Orsini, Manu and Royer, Am{\'e}lie and P{\'e}rez, Patrick and J{\'e}gou, Herv{\'e} and Grave, Edouard and Zeghidour, Neil},
  journal={arXiv preprint arXiv:2410.00037},
  year={2024}
}

@article{speechHallucination,
  title={Understanding Sounds, Missing the Questions: The Challenge of Object Hallucination in Large Audio-Language Models},
  author={Kuan, Chun-Yi and Huang, Wei-Ping and Lee, Hung-yi},
  journal={arXiv preprint arXiv:2406.08402},
  year={2024}
}
@article{flan,
  author       = {Hyung Won Chung and
                  Le Hou and
                  Shayne Longpre and
                  Barret Zoph and
                  Yi Tay and
                  William Fedus and
                  Yunxuan Li and
                  Xuezhi Wang and
                  Mostafa Dehghani and
                  Siddhartha Brahma and
                  Albert Webson and
                  Shixiang Shane Gu and
                  Zhuyun Dai and
                  Mirac Suzgun and
                  Xinyun Chen and
                  Aakanksha Chowdhery and
                  Alex Castro{-}Ros and
                  Marie Pellat and
                  Kevin Robinson and
                  Dasha Valter and
                  Sharan Narang and
                  Gaurav Mishra and
                  Adams Yu and
                  Vincent Y. Zhao and
                  Yanping Huang and
                  Andrew M. Dai and
                  Hongkun Yu and
                  Slav Petrov and
                  Ed H. Chi and
                  Jeff Dean and
                  Jacob Devlin and
                  Adam Roberts and
                  Denny Zhou and
                  Quoc V. Le and
                  Jason Wei},
  title        = {Scaling Instruction-Finetuned Language Models},
  journal      = {J. Mach. Learn. Res.},
  volume       = {25},
  pages        = {70:1--70:53},
  year         = {2024},
  url          = {https://jmlr.org/papers/v25/23-0870.html},
  timestamp    = {Mon, 16 Sep 2024 17:07:54 +0200},
  biburl       = {https://dblp.org/rec/journals/jmlr/ChungHLZTFL00BW24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{instructGPTinstructionHumanFeedback,
  author       = {Long Ouyang and
                  Jeffrey Wu and
                  Xu Jiang and
                  Diogo Almeida and
                  Carroll L. Wainwright and
                  Pamela Mishkin and
                  Chong Zhang and
                  Sandhini Agarwal and
                  Katarina Slama and
                  Alex Ray and
                  John Schulman and
                  Jacob Hilton and
                  Fraser Kelton and
                  Luke Miller and
                  Maddie Simens and
                  Amanda Askell and
                  Peter Welinder and
                  Paul F. Christiano and
                  Jan Leike and
                  Ryan Lowe},
  title        = {Training language models to follow instructions with human feedback},
  booktitle    = {Proceeding of {ICLR} 2022},
  year         = {2022},
}

@inproceedings{SelfInstruction,
  author       = {Yizhong Wang and
                  Yeganeh Kordi and
                  Swaroop Mishra and
                  Alisa Liu and
                  Noah A. Smith and
                  Daniel Khashabi and
                  Hannaneh Hajishirzi},
  editor       = {Anna Rogers and
                  Jordan L. Boyd{-}Graber and
                  Naoaki Okazaki},
  title        = {Self-Instruct: Aligning Language Models with Self-Generated Instructions},
  booktitle    = {Proceedings {ACL} 2023, Toronto, Canada,},
  year         = {2023},
}

@inproceedings{crossTask,
  author       = {Swaroop Mishra and
                  Daniel Khashabi and
                  Chitta Baral and
                  Hannaneh Hajishirzi},
  editor       = {Smaranda Muresan and
                  Preslav Nakov and
                  Aline Villavicencio},
  title        = {Cross-Task Generalization via Natural Language Crowdsourcing Instructions},
  booktitle    = {Proceedings of {ACL} 2022,},
  year         = {2022},
}

@article{bu2024roadmap,
  title={Roadmap towards superhuman speech understanding using large language models},
  author={Bu, Fan and Zhang, Yuhao and Wang, Xidong and Wang, Benyou and Liu, Qun and Li, Haizhou},
  journal={arXiv preprint arXiv:2410.13268},
  year={2024}
}

@article{zhan2024anygpt,
  title={AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling},
  author={Zhan, Jun and Dai, Junqi and Ye, Jiasheng and Zhou, Yunhua and Zhang, Dong and Liu, Zhigeng and Zhang, Xin and Yuan, Ruibin and Zhang, Ge and Li, Linyang and others},
  journal={arXiv preprint arXiv:2402.12226},
  year={2024}
}

@inproceedings{MLS,
  author       = {Vineel Pratap and
                  Qiantong Xu and
                  Anuroop Sriram and
                  Gabriel Synnaeve and
                  Ronan Collobert},
  editor       = {Helen Meng and
                  Bo Xu and
                  Thomas Fang Zheng},
  title        = {{MLS:} {A} Large-Scale Multilingual Dataset for Speech Research},
  booktitle    = {21st Annual Conference of the International Speech Communication Association,
                  Interspeech 2020, Virtual Event, Shanghai, China, October 25-29, 2020},
  pages        = {2757--2761},
  publisher    = {{ISCA}},
  year         = {2020},
  url          = {https://doi.org/10.21437/Interspeech.2020-2826},
  doi          = {10.21437/INTERSPEECH.2020-2826},
  timestamp    = {Sun, 19 Jan 2025 13:13:53 +0100},
  biburl       = {https://dblp.org/rec/conf/interspeech/PratapXSSC20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{TED-LIUM,
  title={TED-LIUM 3: Twice as much data and corpus repartition for experiments on speaker adaptation},
  author={Hernandez, Fran{\c{c}}ois and Nguyen, Vincent and Ghannay, Sahar and Tomashenko, Natalia and Esteve, Yannick},
  booktitle={Speech and Computer: 20th International Conference, SPECOM 2018, Leipzig, Germany, September 18--22, 2018, Proceedings 20},
  pages={198--208},
  year={2018},
  organization={Springer}
}
@inproceedings{lirbiTTS,
  author       = {Heiga Zen and
                  Viet Dang and
                  Rob Clark and
                  Yu Zhang and
                  Ron J. Weiss and
                  Ye Jia and
                  Zhifeng Chen and
                  Yonghui Wu},
  editor       = {Gernot Kubin and
                  Zdravko Kacic},
  title        = {LibriTTS: {A} Corpus Derived from LibriSpeech for Text-to-Speech},
  booktitle    = {20th Annual Conference of the International Speech Communication Association,
                  Interspeech 2019, Graz, Austria, September 15-19, 2019},
  pages        = {1526--1530},
  publisher    = {{ISCA}},
  year         = {2019},
  url          = {https://doi.org/10.21437/Interspeech.2019-2441},
  doi          = {10.21437/INTERSPEECH.2019-2441},
  timestamp    = {Sun, 06 Oct 2024 21:08:29 +0200},
  biburl       = {https://dblp.org/rec/conf/interspeech/ZenDCZWJCW19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{Crema-d,
  title={Crema-d: Crowd-sourced emotional multimodal actors dataset},
  author={Cao, Houwei and Cooper, David G and Keutmann, Michael K and Gur, Ruben C and Nenkova, Ani and Verma, Ragini},
  journal={IEEE transactions on affective computing},
  volume={5},
  number={4},
  pages={377--390},
  year={2014},
  publisher={IEEE}
}

@misc{librispeech_asr_test_clean_word_timestamp,
  author       = {Olympusmons},
  title        = {Librispeech ASR Test Clean Word Timestamp},
  year         = {2021},
  url          = {https://huggingface.co/datasets/olympusmons/librispeech_asr_test_clean_word_timestamp},
  note         = {Accessed: 2024-12-23},
}
@article{wang2023blsp,
  title={Blsp: Bootstrapping language-speech pre-training via behavior alignment of continuation writing},
  author={Wang, Chen and Liao, Minpeng and Huang, Zhongqiang and Lu, Jinliang and Wu, Junhong and Liu, Yuchen and Zong, Chengqing and Zhang, Jiajun},
  journal={arXiv preprint arXiv:2309.00916},
  year={2023}
}
@article{speechverse,
  title={Speechverse: A large-scale generalizable audio language model},
  author={Das, Nilaksh and Dingliwal, Saket and Ronanki, Srikanth and Paturi, Rohit and Huang, Zhaocheng and Mathur, Prashant and Yuan, Jie and Bekal, Dhanush and Niu, Xing and Jayanthi, Sai Muralidhar and others},
  journal={arXiv preprint arXiv:2405.08295},
  year={2024}
}


@article{SALMONN,
  title={Salmonn: Towards generic hearing abilities for large language models},
  author={Tang, Changli and Yu, Wenyi and Sun, Guangzhi and Chen, Xianzhao and Tan, Tian and Li, Wei and Lu, Lu and Ma, Zejun and Zhang, Chao},
  journal={arXiv preprint arXiv:2310.13289},
  year={2023}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@inproceedings{MELD,
  author       = {Soujanya Poria and
                  Devamanyu Hazarika and
                  Navonil Majumder and
                  Gautam Naik and
                  Erik Cambria and
                  Rada Mihalcea},
  editor       = {Anna Korhonen and
                  David R. Traum and
                  Llu{\'{\i}}s M{\`{a}}rquez},
  title        = {{MELD:} {A} Multimodal Multi-Party Dataset for Emotion Recognition
                  in Conversations},
  booktitle    = {Proceedings of the 57th Conference of the Association for Computational
                  Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,
                  Volume 1: Long Papers},
  pages        = {527--536},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/p19-1050},
  doi          = {10.18653/V1/P19-1050},
  timestamp    = {Sun, 06 Oct 2024 20:55:33 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/PoriaHMNCM19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{IEMOCAP,
  title={IEMOCAP: Interactive emotional dyadic motion capture database},
  author={Busso, Carlos and Bulut, Murtaza and Lee, Chi-Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N and Lee, Sungbok and Narayanan, Shrikanth S},
  journal={Language resources and evaluation},
  volume={42},
  pages={335--359},
  year={2008},
  publisher={Springer}
}
@article{RAVDESS,
  title={The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English},
  author={Livingstone, Steven R and Russo, Frank A},
  journal={PloS one},
  volume={13},
  number={5},
  pages={e0196391},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}
@article{ardila2019common_voice,
  title={Common voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={arXiv preprint arXiv:1912.06670},
  year={2019}
}
@inproceedings{wang2021covost,
  title={CoVoST 2 and Massively Multilingual Speech Translation.},
  author={Wang, Changhan and Wu, Anne and Gu, Jiatao and Pino, Juan},
  booktitle={Interspeech},
  pages={2247--2251},
  year={2021}
}
@inproceedings{cieri2004fisher,
  title={The Fisher corpus: A resource for the next generations of speech-to-text.},
  author={Cieri, Christopher and Miller, David and Walker, Kevin},
  booktitle={LREC},
  volume={4},
  pages={69--71},
  year={2004}
}
@article{CochlScene,
  author       = {Il{-}Young Jeong and
                  Jeongsoo Park},
  title        = {CochlScene: Acquisition of acoustic scene data using crowdsourcing},
  journal      = {CoRR},
  volume       = {abs/2211.02289},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2211.02289},
  doi          = {10.48550/ARXIV.2211.02289},
  eprinttype    = {arXiv},
  eprint       = {2211.02289},
  timestamp    = {Thu, 10 Nov 2022 11:08:40 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2211-02289.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{TUTscene,
  title={Ensemble of deep neural networks for acoustic scene classification},
  author={Duppada, Venkatesh and Hiray, Sushant},
  journal={arXiv preprint arXiv:1708.05826},
  year={2017}
}
@inproceedings{VocalSound,
  author       = {Yuan Gong and
                  Jin Yu and
                  James R. Glass},
  title        = {Vocalsound: {A} Dataset for Improving Human Vocal Sounds Recognition},
  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing,
                  {ICASSP} 2022, Virtual and Singapore, 23-27 May 2022},
  pages        = {151--155},
  publisher    = {{IEEE}},
  year         = {2022},
  url          = {https://doi.org/10.1109/ICASSP43922.2022.9746828},
  doi          = {10.1109/ICASSP43922.2022.9746828},
  timestamp    = {Tue, 05 Mar 2024 16:17:02 +0100},
  biburl       = {https://dblp.org/rec/conf/icassp/GongYG22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{Europarl-ST,
  author       = {Javier Iranzo{-}S{\'{a}}nchez and
                  Joan Albert Silvestre{-}Cerd{\`{a}} and
                  Javier Jorge and
                  Nahuel Rosell{\'{o}} and
                  Adri{\`{a}} Gim{\'{e}}nez and
                  Albert Sanch{\'{\i}}s and
                  Jorge Civera and
                  Alfons Juan},
  title        = {Europarl-ST: {A} Multilingual Corpus for Speech Translation of Parliamentary
                  Debates},
  booktitle    = {2020 {IEEE} International Conference on Acoustics, Speech and Signal
                  Processing, {ICASSP} 2020, Barcelona, Spain, May 4-8, 2020},
  pages        = {8229--8233},
  publisher    = {{IEEE}},
  year         = {2020},
  url          = {https://doi.org/10.1109/ICASSP40776.2020.9054626},
  doi          = {10.1109/ICASSP40776.2020.9054626},
  timestamp    = {Sun, 02 Oct 2022 16:03:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icassp/Iranzo-SanchezS20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{MuST-C,
  author       = {Roldano Cattoni and
                  Mattia Antonino Di Gangi and
                  Luisa Bentivogli and
                  Matteo Negri and
                  Marco Turchi},
  title        = {MuST-C: {A} multilingual corpus for end-to-end speech translation},
  journal      = {Comput. Speech Lang.},
  volume       = {66},
  pages        = {101155},
  year         = {2021},
  url          = {https://doi.org/10.1016/j.csl.2020.101155},
  doi          = {10.1016/J.CSL.2020.101155},
  timestamp    = {Sat, 30 Sep 2023 10:11:12 +0200},
  biburl       = {https://dblp.org/rec/journals/csl/CattoniGBNT21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{LibriSpeech,
  author       = {Vassil Panayotov and
                  Guoguo Chen and
                  Daniel Povey and
                  Sanjeev Khudanpur},
  title        = {Librispeech: An {ASR} corpus based on public domain audio books},
  booktitle    = {2015 {IEEE} International Conference on Acoustics, Speech and Signal
                  Processing, {ICASSP} 2015, South Brisbane, Queensland, Australia,
                  April 19-24, 2015},
  pages        = {5206--5210},
  publisher    = {{IEEE}},
  year         = {2015},
  url          = {https://doi.org/10.1109/ICASSP.2015.7178964},
  doi          = {10.1109/ICASSP.2015.7178964},
  timestamp    = {Fri, 25 Dec 2020 01:15:12 +0100},
  biburl       = {https://dblp.org/rec/conf/icassp/PanayotovCPK15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@INPROCEEDINGS{FoR,
  author={Reimao, Ricardo and Tzerpos, Vassilios},
  booktitle={2019 International Conference on Speech Technology and Human-Computer Dialogue (SpeD)}, 
  title={FoR: A Dataset for Synthetic Speech Detection}, 
  year={2019},
  volume={},
  number={},
  pages={1-10},
  keywords={synthetic speech detection;deep neural networks;machine learning;text to speech},
  doi={10.1109/SPED.2019.8906599}}
@inproceedings{WaveFake,
  author       = {Joel Frank and
                  Lea Sch{\"{o}}nherr},
  editor       = {Joaquin Vanschoren and
                  Sai{-}Kit Yeung},
  title        = {WaveFake: {A} Data Set to Facilitate Audio Deepfake Detection},
  booktitle    = {Proceedings of the Neural Information Processing Systems Track on
                  Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December
                  2021, virtual},
  year         = {2021},
  url          = {https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/c74d97b01eae257e44aa9d5bade97baf-Abstract-round2.html},
  timestamp    = {Thu, 05 May 2022 16:53:59 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/FrankS21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{VoxCeleb,
  author       = {Arsha Nagrani and
                  Joon Son Chung and
                  Andrew Zisserman},
  editor       = {Francisco Lacerda},
  title        = {VoxCeleb: {A} Large-Scale Speaker Identification Dataset},
  booktitle    = {18th Annual Conference of the International Speech Communication Association,
                  Interspeech 2017, Stockholm, Sweden, August 20-24, 2017},
  pages        = {2616--2620},
  publisher    = {{ISCA}},
  year         = {2017},
  url          = {https://doi.org/10.21437/Interspeech.2017-950},
  doi          = {10.21437/INTERSPEECH.2017-950},
  timestamp    = {Tue, 11 Jun 2024 16:45:43 +0200},
  biburl       = {https://dblp.org/rec/conf/interspeech/NagraniCZ17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{SLURP,
  author       = {Emanuele Bastianelli and
                  Andrea Vanzo and
                  Pawel Swietojanski and
                  Verena Rieser},
  editor       = {Bonnie Webber and
                  Trevor Cohn and
                  Yulan He and
                  Yang Liu},
  title        = {{SLURP:} {A} Spoken Language Understanding Resource Package},
  booktitle    = {Proceedings of the 2020 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2020, Online, November 16-20, 2020},
  pages        = {7252--7262},
  publisher    = {Association for Computational Linguistics},
  year         = {2020},
  url          = {https://doi.org/10.18653/v1/2020.emnlp-main.588},
  doi          = {10.18653/V1/2020.EMNLP-MAIN.588},
  timestamp    = {Tue, 20 Aug 2024 07:54:43 +0200},
  biburl       = {https://dblp.org/rec/conf/emnlp/BastianelliVSR20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{aishell3,
  title={Aishell-3: A multi-speaker mandarin tts corpus and the baselines},
  author={Shi, Yao and Bu, Hui and Xu, Xin and Zhang, Shaoji and Li, Ming},
  journal={arXiv preprint arXiv:2010.11567},
  year={2020}
}
@article{europarlASR,
  title={Europarl-ASR: A large corpus of parliamentary debates for streaming ASR benchmarking and speech data filtering/verbatimization},
  author={Garc{\'e}s D{\'\i}az-Mun{\'\i}o, Gon{\c{c}}al and Silvestre Cerd{\`a}, Joan Albert and Jorge-Cano, Javier and Gim{\'e}nez Pastor, Adri{\'a}n and Iranzo-S{\'a}nchez, Javier and Baquero-Arnal, Pau and Rosell{\'o}, Nahuel and P{\'e}rez-Gonz{\'a}lez de Martos, Alejandro Manuel and Civera Saiz, Jorge and Sanchis Navarro, Jos{\'e} Alberto and others},
  journal={Proc. Interspeech 2021},
  pages={3695--3699},
  year={2021},
  publisher={International Speech Communication Association (ISCA)}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{TextrolSpeech,
  author       = {Shengpeng Ji and
                  Jialong Zuo and
                  Minghui Fang and
                  Ziyue Jiang and
                  Feiyang Chen and
                  Xinyu Duan and
                  Baoxing Huai and
                  Zhou Zhao},
  title        = {TextrolSpeech: {A} Text Style Control Speech Corpus with Codec Language
                  Text-to-Speech Models},
  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing,
                  {ICASSP} 2024, Seoul, Republic of Korea, April 14-19, 2024},
  pages        = {10301--10305},
  publisher    = {{IEEE}},
  year         = {2024},
  url          = {https://doi.org/10.1109/ICASSP48485.2024.10445879},
  doi          = {10.1109/ICASSP48485.2024.10445879},
  timestamp    = {Sun, 19 Jan 2025 13:18:23 +0100},
  biburl       = {https://dblp.org/rec/conf/icassp/JiZ00CDHZ24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{seamless2025joint,
  title={Joint speech and text machine translation for up to 100 languages},
  author = {Seamless Communication},
  journal={Nature},
  volume={637},
  number={8046},
  pages={587--593},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@article{park2019specaugment,
  title={Specaugment: A simple data augmentation method for automatic speech recognition},
  author={Park, Daniel S and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D and Le, Quoc V},
  journal={arXiv preprint arXiv:1904.08779},
  year={2019}
}

@article{copet2024simple,
  title={Simple and controllable music generation},
  author={Copet, Jade and Kreuk, Felix and Gat, Itai and Remez, Tal and Kant, David and Synnaeve, Gabriel and Adi, Yossi and D{\'e}fossez, Alexandre},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{NeuralBSS,
  author       = {Alexander Richard and
                  Dejan Markovic and
                  Israel D. Gebru and
                  Steven Krenn and
                  Gladstone Alexander Butler and
                  Fernando De la Torre and
                  Yaser Sheikh},
  title        = {Neural Synthesis of Binaural Speech From Mono Audio},
  booktitle    = {Proceeding of {ICLR} 2021},
  year         = {2021},
}

@inproceedings{BinauralAudio,
  title={Visually informed binaural audio generation without binaural audios},
  author={Xu, Xudong and Zhou, Hang and Liu, Ziwei and Dai, Bo and Wang, Xiaogang and Lin, Dahua},
  booktitle={Proceedings of CVPR 2021},
  year={2021}
}

@inproceedings{xin2022audio,
  title={Audio Pyramid Transformer with Domain Adaption for Weakly Supervised Sound Event Detection and Audio Classification.},
  author={Xin, Yifei and Yang, Dongchao and Zou, Yuexian},
  booktitle={Proceeding of INTERSPEECH 2022},
  year={2022}
}

@article{Llava-plus,
  title={Llava-plus: Learning to use tools for creating multimodal agents},
  author={Liu, Shilong and Cheng, Hao and Liu, Haotian and Zhang, Hao and Li, Feng and Ren, Tianhe and Zou, Xueyan and Yang, Jianwei and Su, Hang and Zhu, Jun and others},
  journal={arXiv preprint arXiv:2311.05437},
  year={2023}
}

@inproceedings{CLOVA,
  author       = {Zhi Gao and
                  Yuntao Du and
                  Xintong Zhang and
                  Xiaojian Ma and
                  Wenjuan Han and
                  Song{-}Chun Zhu and
                  Qing Li},
  title        = {{CLOVA:} {A} Closed-LOop Visual Assistant with Tool Usage and Update},
  booktitle    = {Proceeding of {CVPR} 2024},
  year         = {2024},
  url          = {https://doi.org/10.1109/CVPR52733.2024.01259},
}

@inproceedings{CogAgent,
  author       = {Wenyi Hong and
                  Weihan Wang and
                  Qingsong Lv and
                  Jiazheng Xu and
                  Wenmeng Yu and
                  Junhui Ji and
                  Yan Wang and
                  Zihan Wang and
                  Yuxiao Dong and
                  Ming Ding and
                  Jie Tang},
  title        = {CogAgent: {A} Visual Language Model for {GUI} Agents},
  booktitle    = {Proceeding of {CVPR} 2024},
  year         = {2024},
  url          = {https://doi.org/10.1109/CVPR52733.2024.01354},
}

@article{controlllm,
  title={Controlllm: Augment language models with tools by searching on graphs},
  author={Liu, Zhaoyang and Lai, Zeqiang and Gao, Zhangwei and Cui, Erfei and Li, Ziheng and Zhu, Xizhou and Lu, Lewei and Chen, Qifeng and Qiao, Yu and Dai, Jifeng and others},
  journal={arXiv preprint arXiv:2310.17796},
  year={2023}
}

@article{Mm-react,
  title={Mm-react: Prompting chatgpt for multimodal reasoning and action},
  author={Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Azarnasab, Ehsan and Ahmed, Faisal and Liu, Zicheng and Liu, Ce and Zeng, Michael and Wang, Lijuan},
  journal={arXiv preprint arXiv:2303.11381},
  year={2023}
}

@inproceedings{ViperGPT,
  author       = {D{\'{\i}}dac Sur{\'{\i}}s and
                  Sachit Menon and
                  Carl Vondrick},
  title        = {ViperGPT: Visual Inference via Python Execution for Reasoning},
  booktitle    = {Proceeding of {ICCV} 2023},
  year         = {2023},
  url          = {https://doi.org/10.1109/ICCV51070.2023.01092},
}

@article{visualChatGPT,
  title={Visual chatgpt: Talking, drawing and editing with visual foundation models},
  author={Wu, Chenfei and Yin, Shengming and Qi, Weizhen and Wang, Xiaodong and Tang, Zecheng and Duan, Nan},
  journal={arXiv preprint arXiv:2303.04671},
  year={2023}
}

@inproceedings{AudioGPT,
  author       = {Rongjie Huang and
                  Mingze Li and
                  Dongchao Yang and
                  Jiatong Shi and
                  Xuankai Chang and
                  Zhenhui Ye and
                  Yuning Wu and
                  Zhiqing Hong and
                  Jiawei Huang and
                  Jinglin Liu and
                  Yi Ren and
                  Yuexian Zou and
                  Zhou Zhao and
                  Shinji Watanabe},
  editor       = {Michael J. Wooldridge and
                  Jennifer G. Dy and
                  Sriraam Natarajan},
  title        = {AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking
                  Head},
  booktitle    = {Proceeding of {IAAI} 2024},
  year         = {2024},
  url          = {https://doi.org/10.1609/aaai.v38i21.30570},
}

@inproceedings{few_shot_learner,
  author       = {Tom B. Brown and
                  Benjamin Mann and
                  Nick Ryder and
                  Melanie Subbiah and
                  Jared Kaplan and
                  Prafulla Dhariwal and
                  Arvind Neelakantan and
                  Pranav Shyam and
                  Girish Sastry and
                  Amanda Askell and
                  Sandhini Agarwal and
                  Ariel Herbert{-}Voss and
                  Gretchen Krueger and
                  Tom Henighan and
                  Rewon Child and
                  Aditya Ramesh and
                  Daniel M. Ziegler and
                  Jeffrey Wu and
                  Clemens Winter and
                  Christopher Hesse and
                  Mark Chen and
                  Eric Sigler and
                  Mateusz Litwin and
                  Scott Gray and
                  Benjamin Chess and
                  Jack Clark and
                  Christopher Berner and
                  Sam McCandlish and
                  Alec Radford and
                  Ilya Sutskever and
                  Dario Amodei},
  editor       = {Hugo Larochelle and
                  Marc'Aurelio Ranzato and
                  Raia Hadsell and
                  Maria{-}Florina Balcan and
                  Hsuan{-}Tien Lin},
  title        = {Language Models are Few-Shot Learners},
  booktitle    = {Advances in Neural Information Processing Systems 33: Annual Conference
                  on Neural Information Processing Systems 2020, NeurIPS 2020, December
                  6-12, 2020, virtual},
  year         = {2020},
  url          = {https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
  timestamp    = {Thu, 25 May 2023 10:38:31 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/BrownMRSKDNSSAA20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{xin2023improving,
  title={Improving weakly supervised sound event detection with causal intervention},
  author={Xin, Yifei and Yang, Dongchao and Cui, Fan and Wang, Yujun and Zou, Yuexian},
  booktitle={Proceeding of ICASSP 2023},
  year={2023},
}

@inproceedings{BinauralGrad,
  author       = {Yichong Leng and
                  Zehua Chen and
                  Junliang Guo and
                  Haohe Liu and
                  Jiawei Chen and
                  Xu Tan and
                  Danilo P. Mandic and
                  Lei He and
                  Xiangyang Li and
                  Tao Qin and
                  Sheng Zhao and
                  Tie{-}Yan Liu},
  editor       = {Sanmi Koyejo and
                  S. Mohamed and
                  A. Agarwal and
                  Danielle Belgrave and
                  K. Cho and
                  A. Oh},
  title        = {BinauralGrad: {A} Two-Stage Conditional Diffusion Probabilistic Model
                  for Binaural Audio Synthesis},
  booktitle    = {Proceeding of NeurIPS 2022},
  year         = {2022},
}

@inproceedings{learning_dereverberation,
  title={Learning audio-visual dereverberation},
  author={Chen, Changan and Sun, Wei and Harwath, David and Grauman, Kristen},
  booktitle={Processing of ICASSP 2023},
  year={2023},
}

@article{2016dereverberation,
  title={A reverberation-time-aware approach to speech dereverberation based on deep neural networks},
  author={Wu, Bo and Li, Kehuang and Yang, Minglei and Lee, Chin-Hui},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={25},
  number={1},
  pages={102--111},
  year={2016},
  publisher={IEEE}
}

@article{monaural_dereverberation,
  title={Monaural speech dereverberation using temporal convolutional networks with self attention},
  author={Zhao, Yan and Wang, DeLiang and Xu, Buye and Zhang, Tao},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={28},
  pages={1598--1607},
  year={2020},
  publisher={IEEE}
}

@article{audit,
  title={Audit: Audio editing by following instructions with latent diffusion models},
  author={Wang, Yuancheng and Ju, Zeqian and Tan, Xu and He, Lei and Wu, Zhizheng and Bian, Jiang and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={71340--71357},
  year={2023}
}
@article{musiclm,
  title={Musiclm: Generating music from text},
  author={Agostinelli, Andrea and Denk, Timo I and Borsos, Zal{\'a}n and Engel, Jesse and Verzetti, Mauro and Caillon, Antoine and Huang, Qingqing and Jansen, Aren and Roberts, Adam and Tagliasacchi, Marco and others},
  journal={arXiv preprint arXiv:2301.11325},
  year={2023}
}

@article{noise2music,
  title={Noise2music: Text-conditioned music generation with diffusion models},
  author={Huang, Qingqing and Park, Daniel S and Wang, Tao and Denk, Timo I and Ly, Andy and Chen, Nanxin and Zhang, Zhengdong and Zhang, Zhishuai and Yu, Jiahui and Frank, Christian and others},
  journal={arXiv preprint arXiv:2302.03917},
  year={2023}
}

@inproceedings{task1600,
  author       = {Yizhong Wang and
                  Swaroop Mishra and
                  Pegah Alipoormolabashi and
                  Yeganeh Kordi and
                  Amirreza Mirzaei and
                  Atharva Naik and
                  Arjun Ashok and
                  Arut Selvan Dhanasekaran and
                  Anjana Arunkumar and
                  David Stap and
                  Eshaan Pathak and
                  Giannis Karamanolakis and
                  Haizhi Gary Lai and
                  Ishan Purohit and
                  Ishani Mondal and
                  Jacob Anderson and
                  Kirby Kuznia and
                  Krima Doshi and
                  Kuntal Kumar Pal and
                  Maitreya Patel and
                  Mehrad Moradshahi and
                  Mihir Parmar and
                  Mirali Purohit and
                  Neeraj Varshney and
                  Phani Rohitha Kaza and
                  Pulkit Verma and
                  Ravsehaj Singh Puri and
                  Rushang Karia and
                  Savan Doshi and
                  Shailaja Keyur Sampat and
                  Siddhartha Mishra and
                  Sujan Reddy A and
                  Sumanta Patro and
                  Tanay Dixit and
                  Xudong Shen},
  title        = {Super-NaturalInstructions: Generalization via Declarative Instructions
                  on 1600+ {NLP} Tasks},
  booktitle    = {Proceedings of  {EMNLP} 2022},
  year         = {2022},
}

@misc{VCTK,
  author    = {Junichi Yamagishi and Christophe Veaux and Kirsten MacDonald},
  title     = {CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit (version 0.92)},
  publisher = {University of Edinburgh. The Centre for Speech Technology Research (CSTR)},
  year      = {2019},
  doi       = {10.7488/ds/2645}
}
