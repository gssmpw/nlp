\section{Related Work}
Speech contains rich non-semantic information compared to text____. For LLMs to achieve an accurate understanding of audio, they must have a comprehensive perception of speech rather than relying solely on text____. As a result, many researchers have studied how to build end-to-end speech LLMs____. 

Some studies have found the \textit{less is more} phenomenon in LLMs with respect to data usage ____, meaning that efficient use of data can also achieve good performance. However, for speech LLMs, data efficiency has not been fully explored. Therefore, this work addresses this issue by focusing on the key challenge of speech-text alignment.

The acoustic features and text features differ significantly in both their representation space and length. To address this issue, ____ employ convolution network to down-sample the speech, while others opt for solutions with more learnable parameters, such as Q-Former____ and linear layers____. Unlike previous work, the proposed Soundwave implements two adapters to address differences in representation and length, which also make training more efficient.


Speech LLMs are primarily designed for two capabilities: Speech and Sound. ____ combine Whisper with other feature extractors, such as BEATs____ and WavLM____, to process sound features. 
____ show that a fully fine-tuned encoder can also capture sound information. Our work demonstrates that a frozen encoder can efficiently process both types of features when provided with the proper data and training strategy.