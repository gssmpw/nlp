\section{Related Work}
\paragraph{LLMs in Peer Review}
Modern Large Language Models have enabled automated or semi-automated pipelines for academic reviewing ____, already adopted in up to 15.8\% of AI-conference reviews ____. While AI-generated comments can partially align with human judgments ____, concerns persist regarding hallucinations ____, biases ____, and susceptibility to adversarial inputs ____. Studies have also raised the risks of flawed critique interpretation, anonymity breaches, and undue reviewer influence in fully automated setups ____.

\paragraph{Perturbation Analysis in NLP}
Synthetic perturbations---ranging from minor lexical edits to deeper semantic shifts---serve as
stress tests for model robustness across many NLP tasks ____. Even subtle modifications, such as
inserting factual errors or flipping a stance, can destabilize an LLMâ€™s output
____, particularly when
models struggle to distinguish misleading from valid context ____. Although some peer-review studies apply single-level perturbations
____, most ignore how perturbations to the \emph{review} or \emph{rebuttal} also skew
recommendations. Our approach broadens these evaluations by systematically altering all three
elements (paper, review, rebuttal) and assessing LLM responses through both \emph{directional}
and \emph{invariance} tests.