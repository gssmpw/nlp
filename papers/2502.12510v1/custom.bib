% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@article{wilcoxon,
 ISSN = {00994987},
 URL = {http://www.jstor.org/stable/3001968},
 author = {Frank Wilcoxon},
 journal = {Biometrics Bulletin},
 number = {6},
 pages = {80--83},
 publisher = {[International Biometric Society, Wiley]},
 title = {Individual Comparisons by Ranking Methods},
 urldate = {2025-02-16},
 volume = {1},
 year = {1945}
}



@misc{geminiteam2024geminifamilyhighlycapable,
      title={Gemini: A Family of Highly Capable Multimodal Models}, 
      author={Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M. Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R. Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian Güra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and Ágoston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W. Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and Iñaki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco and Adrià Puigdomènech Badia and David Reitter and Mianna Chen and Jenny Brennan and Clara Rivera and Sergey Brin and Shariq Iqbal and Gabriela Surita and Jane Labanowski and Abhi Rao and Stephanie Winkler and Emilio Parisotto and Yiming Gu and Kate Olszewska and Ravi Addanki and Antoine Miech and Annie Louis and Denis Teplyashin and Geoff Brown and Elliot Catt and Jan Balaguer and Jackie Xiang and Pidong Wang and Zoe Ashwood and Anton Briukhov and Albert Webson and Sanjay Ganapathy and Smit Sanghavi and Ajay Kannan and Ming-Wei Chang and Axel Stjerngren and Josip Djolonga and Yuting Sun and Ankur Bapna and Matthew Aitchison and Pedram Pejman and Henryk Michalewski and Tianhe Yu and Cindy Wang and Juliette Love and Junwhan Ahn and Dawn Bloxwich and Kehang Han and Peter Humphreys and Thibault Sellam and James Bradbury and Varun Godbole and Sina Samangooei and Bogdan Damoc and Alex Kaskasoli and Sébastien M. R. Arnold and Vijay Vasudevan and Shubham Agrawal and Jason Riesa and Dmitry Lepikhin and Richard Tanburn and Srivatsan Srinivasan and Hyeontaek Lim and Sarah Hodkinson and Pranav Shyam and Johan Ferret and Steven Hand and Ankush Garg and Tom Le Paine and Jian Li and Yujia Li and Minh Giang and Alexander Neitz and Zaheer Abbas and Sarah York and Machel Reid and Elizabeth Cole and Aakanksha Chowdhery and Dipanjan Das and Dominika Rogozińska and Vitaliy Nikolaev and Pablo Sprechmann and Zachary Nado and Lukas Zilka and Flavien Prost and Luheng He and Marianne Monteiro and Gaurav Mishra and Chris Welty and Josh Newlan and Dawei Jia and Miltiadis Allamanis and Clara Huiyi Hu and Raoul de Liedekerke and Justin Gilmer and Carl Saroufim and Shruti Rijhwani and Shaobo Hou and Disha Shrivastava and Anirudh Baddepudi and Alex Goldin and Adnan Ozturel and Albin Cassirer and Yunhan Xu and Daniel Sohn and Devendra Sachan and Reinald Kim Amplayo and Craig Swanson and Dessie Petrova and Shashi Narayan and Arthur Guez and Siddhartha Brahma and Jessica Landon and Miteyan Patel and Ruizhe Zhao and Kevin Villela and Luyu Wang and Wenhao Jia and Matthew Rahtz and Mai Giménez and Legg Yeung and James Keeling and Petko Georgiev and Diana Mincu and Boxi Wu and Salem Haykal and Rachel Saputro and Kiran Vodrahalli and James Qin and Zeynep Cankara and Abhanshu Sharma and Nick Fernando and Will Hawkins and Behnam Neyshabur and Solomon Kim and Adrian Hutter and Priyanka Agrawal and Alex Castro-Ros and George van den Driessche and Tao Wang and Fan Yang and Shuo-yiin Chang and Paul Komarek and Ross McIlroy and Mario Lučić and Guodong Zhang and Wael Farhan and Michael Sharman and Paul Natsev and Paul Michel and Yamini Bansal and Siyuan Qiao and Kris Cao and Siamak Shakeri and Christina Butterfield and Justin Chung and Paul Kishan Rubenstein and Shivani Agrawal and Arthur Mensch and Kedar Soparkar and Karel Lenc and Timothy Chung and Aedan Pope and Loren Maggiore and Jackie Kay and Priya Jhakra and Shibo Wang and Joshua Maynez and Mary Phuong and Taylor Tobin and Andrea Tacchetti and Maja Trebacz and Kevin Robinson and Yash Katariya and Sebastian Riedel and Paige Bailey and Kefan Xiao and Nimesh Ghelani and Lora Aroyo and Ambrose Slone and Neil Houlsby and Xuehan Xiong and Zhen Yang and Elena Gribovskaya and Jonas Adler and Mateo Wirth and Lisa Lee and Music Li and Thais Kagohara and Jay Pavagadhi and Sophie Bridgers and Anna Bortsova and Sanjay Ghemawat and Zafarali Ahmed and Tianqi Liu and Richard Powell and Vijay Bolina and Mariko Iinuma and Polina Zablotskaia and James Besley and Da-Woon Chung and Timothy Dozat and Ramona Comanescu and Xiance Si and Jeremy Greer and Guolong Su and Martin Polacek and Raphaël Lopez Kaufman and Simon Tokumine and Hexiang Hu and Elena Buchatskaya and Yingjie Miao and Mohamed Elhawaty and Aditya Siddhant and Nenad Tomasev and Jinwei Xing and Christina Greer and Helen Miller and Shereen Ashraf and Aurko Roy and Zizhao Zhang and Ada Ma and Angelos Filos and Milos Besta and Rory Blevins and Ted Klimenko and Chih-Kuan Yeh and Soravit Changpinyo and Jiaqi Mu and Oscar Chang and Mantas Pajarskas and Carrie Muir and Vered Cohen and Charline Le Lan and Krishna Haridasan and Amit Marathe and Steven Hansen and Sholto Douglas and Rajkumar Samuel and Mingqiu Wang and Sophia Austin and Chang Lan and Jiepu Jiang and Justin Chiu and Jaime Alonso Lorenzo and Lars Lowe Sjösund and Sébastien Cevey and Zach Gleicher and Thi Avrahami and Anudhyan Boral and Hansa Srinivasan and Vittorio Selo and Rhys May and Konstantinos Aisopos and Léonard Hussenot and Livio Baldini Soares and Kate Baumli and Michael B. Chang and Adrià Recasens and Ben Caine and Alexander Pritzel and Filip Pavetic and Fabio Pardo and Anita Gergely and Justin Frye and Vinay Ramasesh and Dan Horgan and Kartikeya Badola and Nora Kassner and Subhrajit Roy and Ethan Dyer and Víctor Campos Campos and Alex Tomala and Yunhao Tang and Dalia El Badawy and Elspeth White and Basil Mustafa and Oran Lang and Abhishek Jindal and Sharad Vikram and Zhitao Gong and Sergi Caelles and Ross Hemsley and Gregory Thornton and Fangxiaoyu Feng and Wojciech Stokowiec and Ce Zheng and Phoebe Thacker and Çağlar Ünlü and Zhishuai Zhang and Mohammad Saleh and James Svensson and Max Bileschi and Piyush Patil and Ankesh Anand and Roman Ring and Katerina Tsihlas and Arpi Vezer and Marco Selvi and Toby Shevlane and Mikel Rodriguez and Tom Kwiatkowski and Samira Daruki and Keran Rong and Allan Dafoe and Nicholas FitzGerald and Keren Gu-Lemberg and Mina Khan and Lisa Anne Hendricks and Marie Pellat and Vladimir Feinberg and James Cobon-Kerr and Tara Sainath and Maribeth Rauh and Sayed Hadi Hashemi and Richard Ives and Yana Hasson and Eric Noland and Yuan Cao and Nathan Byrd and Le Hou and Qingze Wang and Thibault Sottiaux and Michela Paganini and Jean-Baptiste Lespiau and Alexandre Moufarek and Samer Hassan and Kaushik Shivakumar and Joost van Amersfoort and Amol Mandhane and Pratik Joshi and Anirudh Goyal and Matthew Tung and Andrew Brock and Hannah Sheahan and Vedant Misra and Cheng Li and Nemanja Rakićević and Mostafa Dehghani and Fangyu Liu and Sid Mittal and Junhyuk Oh and Seb Noury and Eren Sezener and Fantine Huot and Matthew Lamm and Nicola De Cao and Charlie Chen and Sidharth Mudgal and Romina Stella and Kevin Brooks and Gautam Vasudevan and Chenxi Liu and Mainak Chain and Nivedita Melinkeri and Aaron Cohen and Venus Wang and Kristie Seymore and Sergey Zubkov and Rahul Goel and Summer Yue and Sai Krishnakumaran and Brian Albert and Nate Hurley and Motoki Sano and Anhad Mohananey and Jonah Joughin and Egor Filonov and Tomasz Kępa and Yomna Eldawy and Jiawern Lim and Rahul Rishi and Shirin Badiezadegan and Taylor Bos and Jerry Chang and Sanil Jain and Sri Gayatri Sundara Padmanabhan and Subha Puttagunta and Kalpesh Krishna and Leslie Baker and Norbert Kalb and Vamsi Bedapudi and Adam Kurzrok and Shuntong Lei and Anthony Yu and Oren Litvin and Xiang Zhou and Zhichun Wu and Sam Sobell and Andrea Siciliano and Alan Papir and Robby Neale and Jonas Bragagnolo and Tej Toor and Tina Chen and Valentin Anklin and Feiran Wang and Richie Feng and Milad Gholami and Kevin Ling and Lijuan Liu and Jules Walter and Hamid Moghaddam and Arun Kishore and Jakub Adamek and Tyler Mercado and Jonathan Mallinson and Siddhinita Wandekar and Stephen Cagle and Eran Ofek and Guillermo Garrido and Clemens Lombriser and Maksim Mukha and Botu Sun and Hafeezul Rahman Mohammad and Josip Matak and Yadi Qian and Vikas Peswani and Pawel Janus and Quan Yuan and Leif Schelin and Oana David and Ankur Garg and Yifan He and Oleksii Duzhyi and Anton Älgmyr and Timothée Lottaz and Qi Li and Vikas Yadav and Luyao Xu and Alex Chinien and Rakesh Shivanna and Aleksandr Chuklin and Josie Li and Carrie Spadine and Travis Wolfe and Kareem Mohamed and Subhabrata Das and Zihang Dai and Kyle He and Daniel von Dincklage and Shyam Upadhyay and Akanksha Maurya and Luyan Chi and Sebastian Krause and Khalid Salama and Pam G Rabinovitch and Pavan Kumar Reddy M and Aarush Selvan and Mikhail Dektiarev and Golnaz Ghiasi and Erdem Guven and Himanshu Gupta and Boyi Liu and Deepak Sharma and Idan Heimlich Shtacher and Shachi Paul and Oscar Akerlund and François-Xavier Aubet and Terry Huang and Chen Zhu and Eric Zhu and Elico Teixeira and Matthew Fritze and Francesco Bertolini and Liana-Eleonora Marinescu and Martin Bölle and Dominik Paulus and Khyatti Gupta and Tejasi Latkar and Max Chang and Jason Sanders and Roopa Wilson and Xuewei Wu and Yi-Xuan Tan and Lam Nguyen Thiet and Tulsee Doshi and Sid Lall and Swaroop Mishra and Wanming Chen and Thang Luong and Seth Benjamin and Jasmine Lee and Ewa Andrejczuk and Dominik Rabiej and Vipul Ranjan and Krzysztof Styrc and Pengcheng Yin and Jon Simon and Malcolm Rose Harriott and Mudit Bansal and Alexei Robsky and Geoff Bacon and David Greene and Daniil Mirylenka and Chen Zhou and Obaid Sarvana and Abhimanyu Goyal and Samuel Andermatt and Patrick Siegler and Ben Horn and Assaf Israel and Francesco Pongetti and Chih-Wei "Louis" Chen and Marco Selvatici and Pedro Silva and Kathie Wang and Jackson Tolins and Kelvin Guu and Roey Yogev and Xiaochen Cai and Alessandro Agostini and Maulik Shah and Hung Nguyen and Noah Ó Donnaile and Sébastien Pereira and Linda Friso and Adam Stambler and Adam Kurzrok and Chenkai Kuang and Yan Romanikhin and Mark Geller and ZJ Yan and Kane Jang and Cheng-Chun Lee and Wojciech Fica and Eric Malmi and Qijun Tan and Dan Banica and Daniel Balle and Ryan Pham and Yanping Huang and Diana Avram and Hongzhi Shi and Jasjot Singh and Chris Hidey and Niharika Ahuja and Pranab Saxena and Dan Dooley and Srividya Pranavi Potharaju and Eileen O'Neill and Anand Gokulchandran and Ryan Foley and Kai Zhao and Mike Dusenberry and Yuan Liu and Pulkit Mehta and Ragha Kotikalapudi and Chalence Safranek-Shrader and Andrew Goodman and Joshua Kessinger and Eran Globen and Prateek Kolhar and Chris Gorgolewski and Ali Ibrahim and Yang Song and Ali Eichenbaum and Thomas Brovelli and Sahitya Potluri and Preethi Lahoti and Cip Baetu and Ali Ghorbani and Charles Chen and Andy Crawford and Shalini Pal and Mukund Sridhar and Petru Gurita and Asier Mujika and Igor Petrovski and Pierre-Louis Cedoz and Chenmei Li and Shiyuan Chen and Niccolò Dal Santo and Siddharth Goyal and Jitesh Punjabi and Karthik Kappaganthu and Chester Kwak and Pallavi LV and Sarmishta Velury and Himadri Choudhury and Jamie Hall and Premal Shah and Ricardo Figueira and Matt Thomas and Minjie Lu and Ting Zhou and Chintu Kumar and Thomas Jurdi and Sharat Chikkerur and Yenai Ma and Adams Yu and Soo Kwak and Victor Ähdel and Sujeevan Rajayogam and Travis Choma and Fei Liu and Aditya Barua and Colin Ji and Ji Ho Park and Vincent Hellendoorn and Alex Bailey and Taylan Bilal and Huanjie Zhou and Mehrdad Khatir and Charles Sutton and Wojciech Rzadkowski and Fiona Macintosh and Konstantin Shagin and Paul Medina and Chen Liang and Jinjing Zhou and Pararth Shah and Yingying Bi and Attila Dankovics and Shipra Banga and Sabine Lehmann and Marissa Bredesen and Zifan Lin and John Eric Hoffmann and Jonathan Lai and Raynald Chung and Kai Yang and Nihal Balani and Arthur Bražinskas and Andrei Sozanschi and Matthew Hayes and Héctor Fernández Alcalde and Peter Makarov and Will Chen and Antonio Stella and Liselotte Snijders and Michael Mandl and Ante Kärrman and Paweł Nowak and Xinyi Wu and Alex Dyck and Krishnan Vaidyanathan and Raghavender R and Jessica Mallet and Mitch Rudominer and Eric Johnston and Sushil Mittal and Akhil Udathu and Janara Christensen and Vishal Verma and Zach Irving and Andreas Santucci and Gamaleldin Elsayed and Elnaz Davoodi and Marin Georgiev and Ian Tenney and Nan Hua and Geoffrey Cideron and Edouard Leurent and Mahmoud Alnahlawi and Ionut Georgescu and Nan Wei and Ivy Zheng and Dylan Scandinaro and Heinrich Jiang and Jasper Snoek and Mukund Sundararajan and Xuezhi Wang and Zack Ontiveros and Itay Karo and Jeremy Cole and Vinu Rajashekhar and Lara Tumeh and Eyal Ben-David and Rishub Jain and Jonathan Uesato and Romina Datta and Oskar Bunyan and Shimu Wu and John Zhang and Piotr Stanczyk and Ye Zhang and David Steiner and Subhajit Naskar and Michael Azzam and Matthew Johnson and Adam Paszke and Chung-Cheng Chiu and Jaume Sanchez Elias and Afroz Mohiuddin and Faizan Muhammad and Jin Miao and Andrew Lee and Nino Vieillard and Jane Park and Jiageng Zhang and Jeff Stanway and Drew Garmon and Abhijit Karmarkar and Zhe Dong and Jong Lee and Aviral Kumar and Luowei Zhou and Jonathan Evens and William Isaac and Geoffrey Irving and Edward Loper and Michael Fink and Isha Arkatkar and Nanxin Chen and Izhak Shafran and Ivan Petrychenko and Zhe Chen and Johnson Jia and Anselm Levskaya and Zhenkai Zhu and Peter Grabowski and Yu Mao and Alberto Magni and Kaisheng Yao and Javier Snaider and Norman Casagrande and Evan Palmer and Paul Suganthan and Alfonso Castaño and Irene Giannoumis and Wooyeol Kim and Mikołaj Rybiński and Ashwin Sreevatsa and Jennifer Prendki and David Soergel and Adrian Goedeckemeyer and Willi Gierke and Mohsen Jafari and Meenu Gaba and Jeremy Wiesner and Diana Gage Wright and Yawen Wei and Harsha Vashisht and Yana Kulizhskaya and Jay Hoover and Maigo Le and Lu Li and Chimezie Iwuanyanwu and Lu Liu and Kevin Ramirez and Andrey Khorlin and Albert Cui and Tian LIN and Marcus Wu and Ricardo Aguilar and Keith Pallo and Abhishek Chakladar and Ginger Perng and Elena Allica Abellan and Mingyang Zhang and Ishita Dasgupta and Nate Kushman and Ivo Penchev and Alena Repina and Xihui Wu and Tom van der Weide and Priya Ponnapalli and Caroline Kaplan and Jiri Simsa and Shuangfeng Li and Olivier Dousse and Fan Yang and Jeff Piper and Nathan Ie and Rama Pasumarthi and Nathan Lintz and Anitha Vijayakumar and Daniel Andor and Pedro Valenzuela and Minnie Lui and Cosmin Paduraru and Daiyi Peng and Katherine Lee and Shuyuan Zhang and Somer Greene and Duc Dung Nguyen and Paula Kurylowicz and Cassidy Hardin and Lucas Dixon and Lili Janzer and Kiam Choo and Ziqiang Feng and Biao Zhang and Achintya Singhal and Dayou Du and Dan McKinnon and Natasha Antropova and Tolga Bolukbasi and Orgad Keller and David Reid and Daniel Finchelstein and Maria Abi Raad and Remi Crocker and Peter Hawkins and Robert Dadashi and Colin Gaffney and Ken Franko and Anna Bulanova and Rémi Leblond and Shirley Chung and Harry Askham and Luis C. Cobo and Kelvin Xu and Felix Fischer and Jun Xu and Christina Sorokin and Chris Alberti and Chu-Cheng Lin and Colin Evans and Alek Dimitriev and Hannah Forbes and Dylan Banarse and Zora Tung and Mark Omernick and Colton Bishop and Rachel Sterneck and Rohan Jain and Jiawei Xia and Ehsan Amid and Francesco Piccinno and Xingyu Wang and Praseem Banzal and Daniel J. Mankowitz and Alex Polozov and Victoria Krakovna and Sasha Brown and MohammadHossein Bateni and Dennis Duan and Vlad Firoiu and Meghana Thotakuri and Tom Natan and Matthieu Geist and Ser tan Girgin and Hui Li and Jiayu Ye and Ofir Roval and Reiko Tojo and Michael Kwong and James Lee-Thorp and Christopher Yew and Danila Sinopalnikov and Sabela Ramos and John Mellor and Abhishek Sharma and Kathy Wu and David Miller and Nicolas Sonnerat and Denis Vnukov and Rory Greig and Jennifer Beattie and Emily Caveness and Libin Bai and Julian Eisenschlos and Alex Korchemniy and Tomy Tsai and Mimi Jasarevic and Weize Kong and Phuong Dao and Zeyu Zheng and Frederick Liu and Fan Yang and Rui Zhu and Tian Huey Teh and Jason Sanmiya and Evgeny Gladchenko and Nejc Trdin and Daniel Toyama and Evan Rosen and Sasan Tavakkol and Linting Xue and Chen Elkind and Oliver Woodman and John Carpenter and George Papamakarios and Rupert Kemp and Sushant Kafle and Tanya Grunina and Rishika Sinha and Alice Talbert and Diane Wu and Denese Owusu-Afriyie and Cosmo Du and Chloe Thornton and Jordi Pont-Tuset and Pradyumna Narayana and Jing Li and Saaber Fatehi and John Wieting and Omar Ajmeri and Benigno Uria and Yeongil Ko and Laura Knight and Amélie Héliou and Ning Niu and Shane Gu and Chenxi Pang and Yeqing Li and Nir Levine and Ariel Stolovich and Rebeca Santamaria-Fernandez and Sonam Goenka and Wenny Yustalim and Robin Strudel and Ali Elqursh and Charlie Deck and Hyo Lee and Zonglin Li and Kyle Levin and Raphael Hoffmann and Dan Holtmann-Rice and Olivier Bachem and Sho Arora and Christy Koh and Soheil Hassas Yeganeh and Siim Põder and Mukarram Tariq and Yanhua Sun and Lucian Ionita and Mojtaba Seyedhosseini and Pouya Tafti and Zhiyu Liu and Anmol Gulati and Jasmine Liu and Xinyu Ye and Bart Chrzaszcz and Lily Wang and Nikhil Sethi and Tianrun Li and Ben Brown and Shreya Singh and Wei Fan and Aaron Parisi and Joe Stanton and Vinod Koverkathu and Christopher A. Choquette-Choo and Yunjie Li and TJ Lu and Abe Ittycheriah and Prakash Shroff and Mani Varadarajan and Sanaz Bahargam and Rob Willoughby and David Gaddy and Guillaume Desjardins and Marco Cornero and Brona Robenek and Bhavishya Mittal and Ben Albrecht and Ashish Shenoy and Fedor Moiseev and Henrik Jacobsson and Alireza Ghaffarkhah and Morgane Rivière and Alanna Walton and Clément Crepy and Alicia Parrish and Zongwei Zhou and Clement Farabet and Carey Radebaugh and Praveen Srinivasan and Claudia van der Salm and Andreas Fidjeland and Salvatore Scellato and Eri Latorre-Chimoto and Hanna Klimczak-Plucińska and David Bridson and Dario de Cesare and Tom Hudson and Piermaria Mendolicchio and Lexi Walker and Alex Morris and Matthew Mauger and Alexey Guseynov and Alison Reid and Seth Odoom and Lucia Loher and Victor Cotruta and Madhavi Yenugula and Dominik Grewe and Anastasia Petrushkina and Tom Duerig and Antonio Sanchez and Steve Yadlowsky and Amy Shen and Amir Globerson and Lynette Webb and Sahil Dua and Dong Li and Surya Bhupatiraju and Dan Hurt and Haroon Qureshi and Ananth Agarwal and Tomer Shani and Matan Eyal and Anuj Khare and Shreyas Rammohan Belle and Lei Wang and Chetan Tekur and Mihir Sanjay Kale and Jinliang Wei and Ruoxin Sang and Brennan Saeta and Tyler Liechty and Yi Sun and Yao Zhao and Stephan Lee and Pandu Nayak and Doug Fritz and Manish Reddy Vuyyuru and John Aslanides and Nidhi Vyas and Martin Wicke and Xiao Ma and Evgenii Eltyshev and Nina Martin and Hardie Cate and James Manyika and Keyvan Amiri and Yelin Kim and Xi Xiong and Kai Kang and Florian Luisier and Nilesh Tripuraneni and David Madras and Mandy Guo and Austin Waters and Oliver Wang and Joshua Ainslie and Jason Baldridge and Han Zhang and Garima Pruthi and Jakob Bauer and Feng Yang and Riham Mansour and Jason Gelman and Yang Xu and George Polovets and Ji Liu and Honglong Cai and Warren Chen and XiangHai Sheng and Emily Xue and Sherjil Ozair and Christof Angermueller and Xiaowei Li and Anoop Sinha and Weiren Wang and Julia Wiesinger and Emmanouil Koukoumidis and Yuan Tian and Anand Iyer and Madhu Gurumurthy and Mark Goldenson and Parashar Shah and MK Blake and Hongkun Yu and Anthony Urbanowicz and Jennimaria Palomaki and Chrisantha Fernando and Ken Durden and Harsh Mehta and Nikola Momchev and Elahe Rahimtoroghi and Maria Georgaki and Amit Raul and Sebastian Ruder and Morgan Redshaw and Jinhyuk Lee and Denny Zhou and Komal Jalan and Dinghua Li and Blake Hechtman and Parker Schuh and Milad Nasr and Kieran Milan and Vladimir Mikulik and Juliana Franco and Tim Green and Nam Nguyen and Joe Kelley and Aroma Mahendru and Andrea Hu and Joshua Howland and Ben Vargas and Jeffrey Hui and Kshitij Bansal and Vikram Rao and Rakesh Ghiya and Emma Wang and Ke Ye and Jean Michel Sarr and Melanie Moranski Preston and Madeleine Elish and Steve Li and Aakash Kaku and Jigar Gupta and Ice Pasupat and Da-Cheng Juan and Milan Someswar and Tejvi M. and Xinyun Chen and Aida Amini and Alex Fabrikant and Eric Chu and Xuanyi Dong and Amruta Muthal and Senaka Buthpitiya and Sarthak Jauhari and Nan Hua and Urvashi Khandelwal and Ayal Hitron and Jie Ren and Larissa Rinaldi and Shahar Drath and Avigail Dabush and Nan-Jiang Jiang and Harshal Godhia and Uli Sachs and Anthony Chen and Yicheng Fan and Hagai Taitelbaum and Hila Noga and Zhuyun Dai and James Wang and Chen Liang and Jenny Hamer and Chun-Sung Ferng and Chenel Elkind and Aviel Atias and Paulina Lee and Vít Listík and Mathias Carlen and Jan van de Kerkhof and Marcin Pikus and Krunoslav Zaher and Paul Müller and Sasha Zykova and Richard Stefanec and Vitaly Gatsko and Christoph Hirnschall and Ashwin Sethi and Xingyu Federico Xu and Chetan Ahuja and Beth Tsai and Anca Stefanoiu and Bo Feng and Keshav Dhandhania and Manish Katyal and Akshay Gupta and Atharva Parulekar and Divya Pitta and Jing Zhao and Vivaan Bhatia and Yashodha Bhavnani and Omar Alhadlaq and Xiaolin Li and Peter Danenberg and Dennis Tu and Alex Pine and Vera Filippova and Abhipso Ghosh and Ben Limonchik and Bhargava Urala and Chaitanya Krishna Lanka and Derik Clive and Yi Sun and Edward Li and Hao Wu and Kevin Hongtongsak and Ianna Li and Kalind Thakkar and Kuanysh Omarov and Kushal Majmundar and Michael Alverson and Michael Kucharski and Mohak Patel and Mudit Jain and Maksim Zabelin and Paolo Pelagatti and Rohan Kohli and Saurabh Kumar and Joseph Kim and Swetha Sankar and Vineet Shah and Lakshmi Ramachandruni and Xiangkai Zeng and Ben Bariach and Laura Weidinger and Tu Vu and Alek Andreev and Antoine He and Kevin Hui and Sheleem Kashem and Amar Subramanya and Sissie Hsiao and Demis Hassabis and Koray Kavukcuoglu and Adam Sadovsky and Quoc Le and Trevor Strohman and Yonghui Wu and Slav Petrov and Jeffrey Dean and Oriol Vinyals},
      year={2024},
      eprint={2312.11805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.11805}, 
}




@book{strauss1998basics,
  title={Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory},
  author={Strauss, A. and Corbin, J.M.},
  isbn={9780803959408},
  lccn={98025369},
  url={https://books.google.de/books?id=wTwYUnHYsmMC},
  year={1998},
  publisher={SAGE Publications}
}


@misc{blecher2023nougat,
      title={Nougat: Neural Optical Understanding for Academic Documents}, 
      author={Lukas Blecher and Guillem Cucurull and Thomas Scialom and Robert Stojnic},
      year={2023},
      eprint={2308.13418},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{du2024llms,
  title={Llms assist nlp researchers: Critique paper (meta-) reviewing},
  author={Du, Jiangshu and Wang, Yibo and Zhao, Wenting and Deng, Zhongfen and Liu, Shuaiqi and Lou, Renze and Zou, Henry Peng and Venkit, Pranav Narayanan and Zhang, Nan and Srinath, Mukund and others},
  journal={arXiv preprint arXiv:2406.16253},
  year={2024}
}

@article{DANTONI20062,
title = {Applications of the Mind Map Learning Technique in Chiropractic Education: A Pilot Study and Literature Review},
journal = {Journal of Chiropractic Humanities},
volume = {13},
pages = {2-11},
year = {2006},
issn = {1556-3499},
doi = {https://doi.org/10.1016/S1556-3499(13)60153-9},
url = {https://www.sciencedirect.com/science/article/pii/S1556349913601539},
author = {Anthony V. D'Antoni and Genevieve Pinto Zipp},
keywords = {Chiropractic, Education, Professional, Learning, Problem-Based Learning},
abstract = {ABSTRACT
Objective
To present a review of the literature and survey results of student satisfaction after using the mind map learning technique.
Methods
Fourteen third-year physical therapy students enrolled in a doctoral neurorehabilitation course were required to create a mind map based upon the lecture presentation and assigned reading for 6 diagnoses. The students were asked to complete a post-course survey to assess their perceptions of the usefulness of the mind map learning technique in improving organization and integration of course material.
Results
Although the subject pool was limited to 14 students, 10 out of 14 agreed that the mind map learning technique enabled them to better organize/integrate material presented in the course, while only 2 disagreed. The final 2 students responded neutrally when asked if the mind map learning technique assisted them in organizing/integrating course material. However, these 2 students did agree the technique enabled them to recognize areas in which further study was necessary for them to adequately master the course material.
Conclusion
While the data obtained from this limited educational experience offers some support for the use of the mind map learning technique in promoting course material integration and learning in physical therapy education, further work is needed to explore its usefulness in chiropractic education.}
}



@article{liu2023reviewergpt,
  title={Reviewergpt? an exploratory study on using large language models for paper reviewing},
  author={Liu, Ryan and Shah, Nihar B},
  journal={arXiv preprint arXiv:2306.00622},
  year={2023}
}


@article{liang2023can,
  title={Can large language models provide useful feedback on research papers? A large-scale empirical analysis},
  author={Liang, Weixin and Zhang, Yuhui and Cao, Hancheng and Wang, Binglu and Ding, Daisy and Yang, Xinyu and Vodrahalli, Kailas and He, Siyu and Smith, Daniel and Yin, Yian and others},
  journal={arXiv preprint arXiv:2310.01783},
  year={2023}
}


@article{lin2023automated,
  title={Automated scholarly paper review: concepts, technologies, and challenges},
  author={Lin, Jialiang and Song, Jiaxin and Zhou, Zhangping and Chen, Yidong and Shi, Xiaodong},
  journal={Information fusion},
  volume={98},
  pages={101830},
  year={2023},
  publisher={Elsevier}
}


@article{academicgpt,
  title={AcademicGPT: Empowering Academic Research},
  author={Wei, Shufa and Xu, Xiaolong and Qi, Xianbiao and Yin, Xi and Xia, Jun and Ren, Jingyi and Tang, Peijun and Zhong, Yuxiang and Chen, Yihao and Ren, Xiaoqin and others},
  journal={arXiv preprint arXiv:2311.12315},
  year={2023}
}


@inproceedings{nougat,
  title={Nougat: Neural Optical Understanding for Academic Documents},
  author={Blecher, Lukas and Cucurull, Guillem and Scialom, Thomas and Stojnic, Robert},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}


@software{spacy2,
  author = {Explosion AI},
  title = {spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing},
  url = {https://spacy.io/},
  year = {2017}
}


@article{graphrag,
  title={From local to global: A graph rag approach to query-focused summarization},
  author={Edge, Darren and Trinh, Ha and Cheng, Newman and Bradley, Joshua and Chao, Alex and Mody, Apurva and Truitt, Steven and Larson, Jonathan},
  journal={arXiv preprint arXiv:2404.16130},
  year={2024}
}




@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@article{ma2023query,
  title={Query rewriting for retrieval-augmented large language models},
  author={Ma, Xinbei and Gong, Yeyun and He, Pengcheng and Zhao, Hai and Duan, Nan},
  journal={arXiv preprint arXiv:2305.14283},
  year={2023}
}

@inproceedings{peng2024large,
  title={Large language model based long-tail query rewriting in taobao search},
  author={Peng, Wenjun and Li, Guiyang and Jiang, Yue and Wang, Zilong and Ou, Dan and Zeng, Xiaoyi and Xu, Derong and Xu, Tong and Chen, Enhong},
  booktitle={Companion Proceedings of the ACM on Web Conference 2024},
  pages={20--28},
  year={2024}
}

@article{zheng2023take,
  title={Take a step back: Evoking reasoning via abstraction in large language models},
  author={Zheng, Huaixiu Steven and Mishra, Swaroop and Chen, Xinyun and Cheng, Heng-Tze and Chi, Ed H and Le, Quoc V and Zhou, Denny},
  journal={arXiv preprint arXiv:2310.06117},
  year={2023}
}

@article{sepasdar2024enhancing,
  title={Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study},
  author={Sepasdar, Zahra and Gautam, Sushant and Midoglu, Cise and Riegler, Michael A and Halvorsen, P{\aa}l},
  journal={arXiv preprint arXiv:2409.17580},
  year={2024}
}
@article{wu2024medical,
  title={Medical graph rag: Towards safe medical large language model via graph retrieval-augmented generation},
  author={Wu, Junde and Zhu, Jiayuan and Qi, Yunli and Chen, Jingkun and Xu, Min and Menolascina, Filippo and Grau, Vicente},
  journal={arXiv preprint arXiv:2408.04187},
  year={2024}
}

@article{peng2024graph,
  title={Graph retrieval-augmented generation: A survey},
  author={Peng, Boci and Zhu, Yun and Liu, Yongchao and Bo, Xiaohe and Shi, Haizhou and Hong, Chuntao and Zhang, Yan and Tang, Siliang},
  journal={arXiv preprint arXiv:2408.08921},
  year={2024}
}


@article{yu2024your,
  title={Is your paper being reviewed by an llm? investigating ai text detectability in peer review},
  author={Yu, Sungduk and Luo, Man and Madasu, Avinash and Lal, Vasudev and Howard, Phillip},
  journal={arXiv preprint arXiv:2410.03019},
  year={2024}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}


@article{reviewer2,
  title={Reviewer2: Optimizing Review Generation Through Prompt Generation},
  author={Gao, Zhaolin and Brantley, Kiant{\'e} and Joachims, Thorsten},
  journal={arXiv preprint arXiv:2402.10886},
  year={2024}
}


@article{ye2024we,
  title={Are We There Yet? Revealing the Risks of Utilizing Large Language Models in Scholarly Peer Review},
  author={Ye, Rui and Pang, Xianghe and Chai, Jingyi and Chen, Jiaao and Yin, Zhenfei and Xiang, Zhen and Dong, Xiaowen and Shao, Jing and Chen, Siheng},
  journal={arXiv preprint arXiv:2412.01708},
  year={2024}
}



@article{li2024sentiment,
  title={A Sentiment Consolidation Framework for Meta-Review Generation},
  author={Li, Miao and Lau, Jey Han and Hovy, Eduard},
  journal={arXiv preprint arXiv:2402.18005},
  year={2024}
}



@article{cheng2024lift,
  title={Lift yourself up: Retrieval-augmented text generation with self-memory},
  author={Cheng, Xin and Luo, Di and Chen, Xiuying and Liu, Lemao and Zhao, Dongyan and Yan, Rui},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{jiang2023active,
  title={Active retrieval augmented generation},
  author={Jiang, Zhengbao and Xu, Frank F and Gao, Luyu and Sun, Zhiqing and Liu, Qian and Dwivedi-Yu, Jane and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  journal={arXiv preprint arXiv:2305.06983},
  year={2023}
}

@article{bornmann2015growth,
  title={Growth rates of modern science: A bibliometric analysis based on the number of publications and cited references},
  author={Bornmann, Lutz and Mutz, R{\"u}diger},
  journal={Journal of the association for information science and technology},
  volume={66},
  number={11},
  pages={2215--2222},
  year={2015},
  publisher={Wiley Online Library}
}

@article{lin2023moprd,
  title={Moprd: A multidisciplinary open peer review dataset},
  author={Lin, Jialiang and Song, Jiaxin and Zhou, Zhangping and Chen, Yidong and Shi, Xiaodong},
  journal={Neural Computing and Applications},
  volume={35},
  number={34},
  pages={24191--24206},
  year={2023},
  publisher={Springer}
}


@article{li2024generation,
  title={From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge},
  author={Li, Dawei and Jiang, Bohan and Huang, Liangjie and Beigi, Alimohammad and Zhao, Chengshuai and Tan, Zhen and Bhattacharjee, Amrita and Jiang, Yuxuan and Chen, Canyu and Wu, Tianhao and others},
  journal={arXiv preprint arXiv:2411.16594},
  year={2024}
}


@article{sentence-bert,
  title={Sentence-bert: Sentence embeddings using siamese bert-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@article{cao2024lego,
  title={LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration},
  author={Cao, Yukun and Gao, Zengyi and Li, Zhiyang and Xie, Xike and Zhou, S Kevin},
  journal={arXiv preprint arXiv:2411.05844},
  year={2024}
}

@article{yu2022generate,
  title={Generate rather than retrieve: Large language models are strong context generators},
  author={Yu, Wenhao and Iter, Dan and Wang, Shuohang and Xu, Yichong and Ju, Mingxuan and Sanyal, Soumya and Zhu, Chenguang and Zeng, Michael and Jiang, Meng},
  journal={arXiv preprint arXiv:2209.10063},
  year={2022}
}
@article{shao2023enhancing,
  title={Enhancing retrieval-augmented large language models with iterative retrieval-generation synergy},
  author={Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Huang, Minlie and Duan, Nan and Chen, Weizhu},
  journal={arXiv preprint arXiv:2305.15294},
  year={2023}
}

@article{lee2013bias,
  title={Bias in peer review},
  author={Lee, Carole J and Sugimoto, Cassidy R and Zhang, Guo and Cronin, Blaise},
  journal={Journal of the American Society for information Science and Technology},
  volume={64},
  number={1},
  pages={2--17},
  year={2013},
  publisher={Wiley Online Library}
}


@article{bjork2013publishing,
  title={The publishing delay in scholarly peer-reviewed journals},
  author={Bj{\"o}rk, Bo-Christer and Solomon, David},
  journal={Journal of informetrics},
  volume={7},
  number={4},
  pages={914--923},
  year={2013},
  publisher={Elsevier}
}


@article{li2022survey,
  title={A survey on retrieval-augmented text generation},
  author={Li, Huayang and Su, Yixuan and Cai, Deng and Wang, Yan and Liu, Lemao},
  journal={arXiv preprint arXiv:2202.01110},
  year={2022}
}


@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}


@article{checco2021ai,
  title={AI-assisted peer review},
  author={Checco, Alessandro and Bracciale, Lorenzo and Loreti, Pierpaolo and Pinfield, Stephen and Bianchi, Giuseppe},
  journal={Humanities and Social Sciences Communications},
  volume={8},
  number={1},
  pages={1--11},
  year={2021},
  publisher={Palgrave}
}


@article{horbach2018changing,
  title={The changing forms and expectations of peer review},
  author={Horbach, SPJM ( Serge) and Halffman, W ( Willem)},
  journal={Research integrity and peer review},
  volume={3},
  pages={1--15},
  year={2018},
  publisher={Springer}
}


@inproceedings{verma2022lack,
  title={The lack of theory is painful: Modeling harshness in peer review comments},
  author={Verma, Rajeev and Roychoudhury, Rajarshi and Ghosal, Tirthankar},
  booktitle={Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={925--935},
  year={2022}
}

@article{oscopilot,
  title={Os-copilot: Towards generalist computer agents with self-improvement},
  author={Wu, Zhiyong and Han, Chengcheng and Ding, Zichen and Weng, Zhenmin and Liu, Zhoumianze and Yao, Shunyu and Yu, Tao and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2402.07456},
  year={2024}
}

@article{autogen,
  title={Autogen: Enabling next-gen llm applications via multi-agent conversation framework},
  author={Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Zhang, Shaokun and Zhu, Erkang and Li, Beibin and Jiang, Li and Zhang, Xiaoyun and Wang, Chi},
  journal={arXiv preprint arXiv:2308.08155},
  year={2023}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}
@article{lbs3,
  title={Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models},
  author={Luo, Kangyang and Ding, Zichen and Weng, Zhenmin and Qiao, Lingfeng and Zhao, Meng and Li, Xiang and Yin, Di and Shu, Jinlong},
  journal={arXiv preprint arXiv:2410.21728},
  year={2024}
}


@misc{ye2024yetrevealingrisksutilizing,
      title={Are We There Yet? Revealing the Risks of Utilizing Large Language Models in Scholarly Peer Review}, 
      author={Rui Ye and Xianghe Pang and Jingyi Chai and Jiaao Chen and Zhenfei Yin and Zhen Xiang and Xiaowen Dong and Jing Shao and Siheng Chen},
      year={2024},
      eprint={2412.01708},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.01708}, 
}

@misc{du2024llmsassistnlpresearchers,
      title={LLMs Assist NLP Researchers: Critique Paper (Meta-)Reviewing}, 
      author={Jiangshu Du and Yibo Wang and Wenting Zhao and Zhongfen Deng and Shuaiqi Liu and Renze Lou and Henry Peng Zou and Pranav Narayanan Venkit and Nan Zhang and Mukund Srinath and Haoran Ranran Zhang and Vipul Gupta and Yinghui Li and Tao Li and Fei Wang and Qin Liu and Tianlin Liu and Pengzhi Gao and Congying Xia and Chen Xing and Jiayang Cheng and Zhaowei Wang and Ying Su and Raj Sanjay Shah and Ruohao Guo and Jing Gu and Haoran Li and Kangda Wei and Zihao Wang and Lu Cheng and Surangika Ranathunga and Meng Fang and Jie Fu and Fei Liu and Ruihong Huang and Eduardo Blanco and Yixin Cao and Rui Zhang and Philip S. Yu and Wenpeng Yin},
      year={2024},
      eprint={2406.16253},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.16253}, 
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021}
}

@article{llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={NIPS},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{openai2023gpt4,
  title={GPT-4 Technical Report},
  author={{OpenAI}},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{kirk2023past,
  title={The past, present and better future of feedback learning in large language models for subjective human preferences and values},
  author={Kirk, Hannah Rose and Bean, Andrew M and Vidgen, Bertie and R{\"o}ttger, Paul and Hale, Scott A},
  journal={arXiv preprint arXiv:2310.07629},
  year={2023}
}

@article{ji2023ai,
  title={Ai alignment: A comprehensive survey},
  author={Ji, Jiaming and Qiu, Tianyi and Chen, Boyuan and Zhang, Borong and Lou, Hantao and Wang, Kaile and Duan, Yawen and He, Zhonghao and Zhou, Jiayi and Zhang, Zhaowei and others},
  journal={arXiv preprint arXiv:2310.19852},
  year={2023}
}

@article{bengio2023managing,
  title={Managing ai risks in an era of rapid progress},
  author={Bengio, Yoshua and Hinton, Geoffrey and Yao, Andrew and Song, Dawn and Abbeel, Pieter and Harari, Yuval Noah and Zhang, Ya-Qin and Xue, Lan and Shalev-Shwartz, Shai and Hadfield, Gillian and others},
  journal={arXiv preprint arXiv:2310.17688},
  year={2023}
}

@article{anwar2024foundational,
  title={Foundational challenges in assuring alignment and safety of large language models},
  author={Anwar, Usman and Saparov, Abulhair and Rando, Javier and Paleka, Daniel and Turpin, Miles and Hase, Peter and Lubana, Ekdeep Singh and Jenner, Erik and Casper, Stephen and Sourbut, Oliver and others},
  journal={arXiv preprint arXiv:2404.09932},
  year={2024}
}

@article{sun2024trustllm,
  title={Trustllm: Trustworthiness in large language models},
  author={Sun, Lichao and Huang, Yue and Wang, Haoran and Wu, Siyuan and Zhang, Qihui and Gao, Chujie and Huang, Yixin and Lyu, Wenhan and Zhang, Yixuan and Li, Xiner and others},
  journal={arXiv preprint arXiv:2401.05561},
  year={2024}
}

@article{liu2023reviewergpt,
  title={Reviewergpt? an exploratory study on using large language models for paper reviewing},
  author={Liu, Ryan and Shah, Nihar B},
  journal={arXiv preprint arXiv:2306.00622},
  year={2023}
}

@article{mccook2006peer,
  title={Is peer review broken? Submissions are up, reviewers are overtaxed, and authors are lodging complaint after complaint about the process at top-tier journals. What's wrong with peer review?},
  author={McCook, Alison},
  journal={The scientist},
  volume={20},
  number={2},
  pages={26--35},
  year={2006},
  publisher={Scientist Inc.}
}

@article{shah2022challenges,
  title={Challenges, experiments, and computational solutions in peer review},
  author={Shah, Nihar B},
  journal={Communications of the ACM},
  volume={65},
  number={6},
  pages={76--87},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@article{horbach2018changing,
  title={The changing forms and expectations of peer review},
  author={Horbach, SPJM ( Serge) and Halffman, W ( Willem)},
  journal={Research integrity and peer review},
  volume={3},
  pages={1--15},
  year={2018},
  publisher={Springer}
}

@article{aczel2021billion,
  title={A billion-dollar donation: estimating the cost of researchers’ time spent on peer review},
  author={Aczel, Balazs and Szaszi, Barnabas and Holcombe, Alex O},
  journal={Research Integrity and Peer Review},
  volume={6},
  pages={1--8},
  year={2021},
  publisher={Springer}
}

@article{kovanis2016global,
  title={The global burden of journal peer review in the biomedical literature: Strong imbalance in the collective enterprise},
  author={Kovanis, Michail and Porcher, Rapha{\"e}l and Ravaud, Philippe and Trinquart, Ludovic},
  journal={PloS one},
  volume={11},
  number={11},
  pages={e0166387},
  year={2016},
  publisher={Public Library of Science San Francisco, CA USA}
}

@misc{alberts2008reviewing,
  title={Reviewing peer review},
  author={Alberts, Bruce and Hanson, Brooks and Kelner, Katrina L},
  journal={Science},
  volume={321},
  number={5885},
  pages={15--15},
  year={2008},
  publisher={American Association for the Advancement of Science}
}

@article{lee2013bias,
  title={Bias in peer review},
  author={Lee, Carole J and Sugimoto, Cassidy R and Zhang, Guo and Cronin, Blaise},
  journal={Journal of the American Society for information Science and Technology},
  volume={64},
  number={1},
  pages={2--17},
  year={2013},
  publisher={Wiley Online Library}
}

@article{patel2014training,
  title={Why training and specialization is needed for peer review: a case study of peer review for randomized controlled trials},
  author={Patel, Jigisha},
  journal={BMC medicine},
  volume={12},
  pages={1--7},
  year={2014},
  publisher={Springer}
}

@article{hosseini2023fighting,
  title={Fighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of ChatGPT and other large language models in scholarly peer review},
  author={Hosseini, Mohammad and Horbach, Serge PJM},
  journal={Research integrity and peer review},
  volume={8},
  number={1},
  pages={4},
  year={2023},
  publisher={Springer}
}

@book{chubin1990peerless,
  title={Peerless science: Peer review and US science policy},
  author={Chubin, Daryl E and Hackett, Edward J},
  year={1990},
  publisher={State University of New York Press}
}

@article{smith2006peer,
  title={Peer review: a flawed process at the heart of science and journals},
  author={Smith, Richard},
  journal={Journal of the royal society of medicine},
  volume={99},
  number={4},
  pages={178--182},
  year={2006},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{fox2017recruitment,
  title={Recruitment of reviewers is becoming harder at some journals: a test of the influence of reviewer fatigue at six journals in ecology and evolution},
  author={Fox, Charles W and Albert, Arianne YK and Vines, Timothy H},
  journal={Research Integrity and Peer Review},
  volume={2},
  pages={1--6},
  year={2017},
  publisher={Springer}
}

@article{arns2014open,
  title={Open access is tiring out peer reviewers},
  author={Arns, Martijn},
  journal={Nature},
  volume={515},
  number={7528},
  pages={467--467},
  year={2014},
  publisher={Nature Publishing Group UK London}
}



@article{schulz2022future,
  title={Is the future of peer review automated?},
  author={Schulz, Robert and Barnett, Adrian and Bernard, Ren{\'e} and Brown, Nicholas JL and Byrne, Jennifer A and Eckmann, Peter and Gazda, Ma{\l}gorzata A and Kilicoglu, Halil and Prager, Eric M and Salholz-Hillel, Maia and others},
  journal={BMC research notes},
  volume={15},
  number={1},
  pages={203},
  year={2022},
  publisher={Springer}
}

@article{weissgerber2021automated,
  title={Automated screening of COVID-19 preprints: can we help authors to improve transparency and reproducibility?},
  author={Weissgerber, Tracey and Riedel, Nico and Kilicoglu, Halil and Labb{\'e}, Cyril and Eckmann, Peter and Ter Riet, Gerben and Byrne, Jennifer and Cabanac, Guillaume and Capes-Davis, Amanda and Favier, Bertrand and others},
  journal={Nature medicine},
  volume={27},
  number={1},
  pages={6--7},
  year={2021},
  publisher={Nature Publishing Group US New York}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{liang2024can,
  title={Can large language models provide useful feedback on research papers? A large-scale empirical analysis},
  author={Liang, Weixin and Zhang, Yuhui and Cao, Hancheng and Wang, Binglu and Ding, Daisy Yi and Yang, Xinyu and Vodrahalli, Kailas and He, Siyu and Smith, Daniel Scott and Yin, Yian and others},
  journal={NEJM AI},
  volume={1},
  number={8},
  pages={AIoa2400196},
  year={2024},
  publisher={Massachusetts Medical Society}
}

@inproceedings{liangmonitoring,
  title={Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews},
  author={Liang, Weixin and Izzo, Zachary and Zhang, Yaohui and Lepp, Haley and Cao, Hancheng and Zhao, Xuandong and Chen, Lingjiao and Ye, Haotian and Liu, Sheng and Huang, Zhi and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{tyser2024ai,
  title={Ai-driven review systems: Evaluating llms in scalable and bias-aware academic reviews},
  author={Tyser, Keith and Segev, Ben and Longhitano, Gaston and Zhang, Xin-Yu and Meeks, Zachary and Lee, Jason and Garg, Uday and Belsten, Nicholas and Shporer, Avi and Udell, Madeleine and others},
  journal={arXiv preprint arXiv:2408.10365},
  year={2024}
}

@article{latona2024ai,
  title={The AI Review Lottery: Widespread AI-Assisted Peer Reviews Boost Paper Scores and Acceptance Rates},
  author={Latona, Giuseppe Russo and Ribeiro, Manoel Horta and Davidson, Tim R and Veselovsky, Veniamin and West, Robert},
  journal={arXiv preprint arXiv:2405.02150},
  year={2024}
}

@article{lu2024ai,
  title={The ai scientist: Towards fully automated open-ended scientific discovery},
  author={Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David},
  journal={arXiv preprint arXiv:2408.06292},
  year={2024}
}

@article{zeng2024johnny,
  title={How johnny can persuade llms to jailbreak them: Rethinking persuasion to challenge ai safety by humanizing llms},
  author={Zeng, Yi and Lin, Hongpeng and Zhang, Jingwen and Yang, Diyi and Jia, Ruoxi and Shi, Weiyan},
  journal={arXiv preprint arXiv:2401.06373},
  year={2024}
}

@inproceedings{deshpande2023toxicity,
  title={Toxicity in chatgpt: Analyzing persona-assigned language models},
  author={Deshpande, Ameet and Murahari, Vishvak and Rajpurohit, Tanmay and Kalyan, Ashwin and Narasimhan, Karthik},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={1236--1270},
  year={2023}
}

@article{gallegos2024bias,
  title={Bias and fairness in large language models: A survey},
  author={Gallegos, Isabel O and Rossi, Ryan A and Barrow, Joe and Tanjim, Md Mehrab and Kim, Sungchul and Dernoncourt, Franck and Yu, Tong and Zhang, Ruiyi and Ahmed, Nesreen K},
  journal={Computational Linguistics},
  pages={1--79},
  year={2024},
  publisher={MIT Press 255 Main Street, 9th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{schramowski2022large,
  title={Large pre-trained language models contain human-like biases of what is right and wrong to do},
  author={Schramowski, Patrick and Turan, Cigdem and Andersen, Nico and Rothkopf, Constantin A and Kersting, Kristian},
  journal={Nature Machine Intelligence},
  volume={4},
  number={3},
  pages={258--268},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@misc{neurips2024checklist,
  title        = {Paper Checklist},
  author       = {NeurIPS},
  year         = {2024},
  howpublished = {\url{https://neurips.cc/public/guides/PaperChecklist}},
  note         = {Accessed: 2024-11-04}
}

@misc{iclr2025llm,
  title        = {Assisting ICLR 2025 reviewers with feedback},
  author       = {ICLR},
  year         = {2025},
  howpublished = {\url{https://blog.iclr.cc/2024/10/09/iclr2025-assisting-reviewers/}},
  note         = {Accessed: 2024-11-30}
}

@inproceedings{jin2024agentreview,
    title = "{A}gent{R}eview: Exploring Peer Review Dynamics with {LLM} Agents",
    author = "Jin, Yiqiao  and
      Zhao, Qinlin  and
      Wang, Yiyang  and
      Chen, Hao  and
      Zhu, Kaijie  and
      Xiao, Yijia  and
      Wang, Jindong",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.70",
    pages = "1208--1226",
}

@article{mcfadden1974conditional,
  title={Conditional Logit Analysis of Qualitative Choice Behavior},
  author={MCFADDEN, D},
  journal={Frontiers in Econometrics},
  year={1974},
  publisher={Academic Press}
}

@article{fawcett2006introduction,
  title={An introduction to ROC analysis},
  author={Fawcett, Tom},
  journal={Pattern recognition letters},
  volume={27},
  number={8},
  pages={861--874},
  year={2006},
  publisher={Elsevier}
}

@inproceedings{zheng2023large,
  title={Large language models are not robust multiple choice selectors},
  author={Zheng, Chujie and Zhou, Hao and Meng, Fandong and Zhou, Jie and Huang, Minlie},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{wang2023large,
  title={Large language models are not fair evaluators},
  author={Wang, Peiyi and Li, Lei and Chen, Liang and Cai, Zefan and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang},
  journal={arXiv preprint arXiv:2305.17926},
  year={2023}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@article{wu2023style,
  title={Style over substance: Evaluation biases for large language models},
  author={Wu, Minghao and Aji, Alham Fikri},
  journal={arXiv preprint arXiv:2307.03025},
  year={2023}
}

@misc{qs2024,
  author = "{QS Top Universities}",
  title = "{QS World University Rankings by Subject 2024: Computer Science \& Information Systems}",
  year = 2024,
  url = {https://www.topuniversities.com/university-subject-rankings/computer-science-information-systems},
  note = "Accessed: 2024-11-19"
}

@article{zhang2023siren,
  title={Siren's song in the AI ocean: a survey on hallucination in large language models},
  author={Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
  journal={arXiv preprint arXiv:2309.01219},
  year={2023}
}

@inproceedings{manakul2023selfcheckgpt,
  title={SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models},
  author={Manakul, Potsawee and Liusie, Adian and Gales, Mark},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={9004--9017},
  year={2023}
}

@article{ecer2017sciencebeam,
  title={ScienceBeam—using computer vision to extract PDF data},
  author={Ecer, D and Maciocci, G},
  journal={Elife [Internet]},
  volume={4},
  year={2017}
}

@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={arXiv preprint arXiv:2311.05232},
  year={2023}
}

@inproceedings{kubat1997addressing,
  title={Addressing the curse of imbalanced training sets: one-sided selection},
  author={Kubat, Miroslav and Matwin, Stan and others},
  booktitle={Icml},
  volume={97},
  number={1},
  pages={179},
  year={1997},
  organization={Citeseer}
}

@article{he2009learning,
  title={Learning from imbalanced data},
  author={He, Haibo and Garcia, Edwardo A},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={21},
  number={9},
  pages={1263--1284},
  year={2009},
  publisher={Ieee}
}

@inproceedings{yu2024automated,
  title={Automated Peer Reviewing in Paper SEA: Standardization, Evaluation, and Analysis},
  author={Yu, Jianxiang and Ding, Zichen and Tan, Jiaqi and Luo, Kangyang and Weng, Zhenmin and Gong, Chenghua and Zeng, Long and Cui, RenJing and Han, Chengcheng and Sun, Qiushi and others},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={10164--10184},
  year={2024}
}

@inproceedings{koo-etal-2024-benchmarking,
    title = "Benchmarking Cognitive Biases in Large Language Models as Evaluators",
    author = "Koo, Ryan  and
      Lee, Minhwa  and
      Raheja, Vipul  and
      Park, Jong Inn  and
      Kim, Zae Myung  and
      Kang, Dongyeop",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.29",
    doi = "10.18653/v1/2024.findings-acl.29",
    pages = "517--545",
    abstract = "Large Language Models (LLMs) have recently been shown to be effective as automatic evaluators with simple prompting and in-context learning. In this work, we assemble 16 LLMs encompassing four different size ranges and evaluate their output responses by preference ranking from the other LLMs as evaluators, such as System Star is better than System Square. We then evaluate the quality of ranking outputs introducing the Cognitive Bias Benchmark for LLMs as Evaluators (CoBBLer), a benchmark to measure six different cognitive biases in LLM evaluation outputs, such as the Egocentric bias where a model prefers to rank its own outputs highly in evaluation. We find that LLMs are biased text quality evaluators, exhibiting strong indications on our bias benchmark (40{\%} of comparisons made by all models) within each of their evaluations that question their robustness as evaluators. Furthermore, we examine the correlation between human and machine preferences and calculate the average Rank-Biased Overlap (RBO) score to be 44{\%}, indicating that machine preferences are misaligned with humans. According to our findings, LLMs may still be unable to be utilized for automatic annotation aligned with human preferences.",
}

@article{xie2023defending,
  title={Defending chatgpt against jailbreak attack via self-reminders},
  author={Xie, Yueqi and Yi, Jingwei and Shao, Jiawei and Curl, Justin and Lyu, Lingjuan and Chen, Qifeng and Xie, Xing and Wu, Fangzhao},
  journal={Nature Machine Intelligence},
  volume={5},
  number={12},
  pages={1486--1496},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{echterhoff-etal-2024-cognitive,
    title = "Cognitive Bias in Decision-Making with {LLM}s",
    author = "Echterhoff, Jessica Maria  and
      Liu, Yao  and
      Alessa, Abeer  and
      McAuley, Julian  and
      He, Zexue",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.739",
    pages = "12640--12653",
    abstract = "Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. Given their training on human (created) data, LLMs have been shown to inherit societal biases against protected groups, as well as be subject to bias functionally resembling cognitive bias. Human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive science, we develop a dataset containing 13,465 prompts to evaluate LLM decisions on different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, while proposing a novel method utilizing LLMs to debias their own human-like cognitive bias within prompts. Our analysis provides a comprehensive picture of the presence and effects of cognitive bias across commercial and open-source models. We demonstrate that our selfhelp debiasing effectively mitigates model answers that display patterns akin to human cognitive bias without having to manually craft examples for each bias.",
}

@article{dubois2024length,
  title={Length-controlled alpacaeval: A simple way to debias automatic evaluators},
  author={Dubois, Yann and Galambosi, Bal{\'a}zs and Liang, Percy and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2404.04475},
  year={2024}
}

@article{yu2024your,
  title={Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review},
  author={Yu, Sungduk and Luo, Man and Madasu, Avinash and Lal, Vasudev and Howard, Phillip},
  journal={arXiv preprint arXiv:2410.03019},
  year={2024}
}

@article{wei2024jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{deepseekv2,
      title={DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model}, 
      author={DeepSeek-AI},
      year={2024},
      eprint={2405.04434},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{qwen2.5,
    title = {Qwen2.5: A Party of Foundation Models},
    url = {https://qwenlm.github.io/blog/qwen2.5/},
    author = {{Qwen Team}},
    month = {September},
    year = {2024}
}

@misc{chiang2024chatbot,
    title={Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference},
    author={Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Hao Zhang and Banghua Zhu and Michael Jordan and Joseph E. Gonzalez and Ion Stoica},
    year={2024},
    eprint={2403.04132},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@inproceedings{DBLP:conf/inlg/BelzMH20,
  author    = {Anya Belz and Simon Mille and David M. Howcroft},
  title     = {Disentangling the properties of human evaluation methods: A classification system to support comparability, meta-evaluation and reproducibility testing},
  booktitle = {INLG},
  pages     = {183--194},
  year      = {2020},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/emnlp/Chen0Q21,
  author    = {Yiran Chen and Pengfei Liu and Xipeng Qiu},
  title     = {Are factuality checkers reliable? adversarial meta-evaluation of factuality in summarization},
  booktitle = {EMNLP (Findings)},
  pages     = {2082--2095},
  year      = {2021},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/acl/ChiangL23,
  author    = {David Cheng-Han Chiang and Hung-yi Lee},
  title     = {Can large language models be an alternative to human evaluations?},
  booktitle = {ACL (1)},
  pages     = {15607--15631},
  year      = {2023},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/emnlp/ChiangL23,
  author    = {David Cheng-Han Chiang and Hung-yi Lee},
  title     = {A closer look into using large language models for automatic evaluation},
  booktitle = {EMNLP (Findings)},
  pages     = {8928--8942},
  year      = {2023},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/emnlp/ErnstSD023,
  author    = {Ori Ernst and Ori Shapira and Ido Dagan and Ran Levy},
  title     = {Re-examining summarization evaluation across multiple quality criteria},
  booktitle = {EMNLP (Findings)},
  pages     = {13829--13838},
  year      = {2023},
  publisher = {Association for Computational Linguistics}
}

@article{DBLP:journals/tacl/FabbriKMXSR21,
  author  = {Alexander R. Fabbri and Wojciech Kryscinski and Bryan McCann and Caiming Xiong and Richard Socher and Dragomir R. Radev},
  title   = {Summeval: Re-evaluating summarization evaluation},
  journal = {Transactions of the Association for Computational Linguistics},
  volume  = {9},
  pages   = {391--409},
  year    = {2021}
}

@misc{DBLP:journals/corr/abs-2304-02554,
  author       = {Mingqi Gao and Jie Ruan and Renliang Sun and Xunjian Yin and Shiping Yang and Xiaojun Wan},
  title        = {Human-like summarization evaluation with ChatGPT},
  howpublished = {\url{https://arxiv.org/abs/2304.02554}},
  year         = {2023},
  note         = {CoRR, abs/2304.02554}
}

@inproceedings{DBLP:conf/acl/GardentSNP17,
  author    = {Claire Gardent and Anastasia Shimorina and Shashi Narayan and Laura Perez-Beltrachini},
  title     = {Creating training corpora for NLG micro-planners},
  booktitle = {ACL (1)},
  pages     = {179--188},
  year      = {2017},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{gliwa-etal-2019-samsum,
  author    = {Bogdan Gliwa and Iwona Mochol and Maciej Biesek and Aleksander Wawer},
  title     = {{SAMS}um corpus: A human-annotated dialogue dataset for abstractive summarization},
  booktitle = {Proceedings of the 2nd Workshop on New Frontiers in Summarization},
  pages     = {70--79},
  address   = {Hong Kong, China},
  year      = {2019},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/D19-5409}
}

@misc{DBLP:journals/corr/abs-2312-10355,
  author       = {Peiyuan Gong and Jiaxin Mao},
  title        = {Coascore: Chain-of-aspects prompting for NLG evaluation},
  howpublished = {\url{https://arxiv.org/abs/2312.10355}},
  year         = {2023},
  note         = {CoRR, abs/2312.10355}
}

@misc{DBLP:journals/corr/abs-2309-07462,
  author       = {Rishav Hada and Varun Gumma and Adrian de Wynter and Harshita Diddee and Mohamed Ahmed and Monojit Choudhury and Kalika Bali and Sunayana Sitaram},
  title        = {Are large language model-based evaluators the solution to scaling up multilingual evaluation?},
  howpublished = {\url{https://arxiv.org/abs/2309.07462}},
  year         = {2023},
  note         = {CoRR, abs/2309.07462}
}

@inproceedings{DBLP:conf/acl/HeZ0KCGT23,
  author    = {Tianxing He and Jingyu Zhang and Tianle Wang and Sachin Kumar and Kyunghyun Cho and James R. Glass and Yulia Tsvetkov},
  title     = {On the blind spots of model-based evaluation metrics for text generation},
  booktitle = {ACL (1)},
  pages     = {12067--12097},
  year      = {2023},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/nips/HermannKGEKSB15,
  author    = {Karl Moritz Hermann and Tom{\'a}s Kocisk{\'y} and Edward Grefenstette and Lasse Espeholt and Will Kay and Mustafa Suleyman and Phil Blunsom},
  title     = {Teaching machines to read and comprehend},
  booktitle = {NIPS},
  pages     = {1693--1701},
  year      = {2015}
}

@inproceedings{DBLP:conf/inlg/HowcroftBCGHMMM20,
  author    = {David M. Howcroft and Anya Belz and Miruna-Adriana Clinciu and Dimitra Gkatzia and Sadid A Hasan and Saad Mahamood and Simon Mille and Emiel van Miltenburg and Sashank Santhanam and Verena Rieser},
  title     = {Twenty years of confusion in human evaluation: NLG needs evaluation sheets and standardised definitions},
  booktitle = {INLG},
  pages     = {169--182},
  year      = {2020},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/emnlp/KarpinskaRTSGI22,
  author    = {Marzena Karpinska and Nishant Raj and Katherine Thai and Yixiao Song and Ankita Gupta and Mohit Iyyer},
  title     = {DEMETR: diagnosing evaluation metrics for translation},
  booktitle = {EMNLP},
  pages     = {9540--9561},
  year      = {2022},
  publisher = {Association for Computational Linguistics}
}

@misc{DBLP:journals/corr/abs-2310-08491,
  author       = {Seungone Kim and Jamin Shin and Yejin Cho and Joel Jang and Shayne Longpre and Hwaran Lee and Sangdoo Yun and Seongjin Shin and Sungdong Kim and James Thorne and Minjoon Seo},
  title        = {Prometheus: Inducing fine-grained evaluation capability in language models},
  howpublished = {\url{https://arxiv.org/abs/2310.08491}},
  year         = {2023},
  note         = {CoRR, abs/2310.08491}
}

@misc{DBLP:journals/corr/abs-2309-13633,
  author       = {Tae Soo Kim and Yoonjoo Lee and Jamin Shin and Young-Ho Kim and Juho Kim},
  title        = {Evallm: Interactive evaluation of large language model prompts on user-defined criteria},
  howpublished = {\url{https://arxiv.org/abs/2309.13633}},
  year         = {2023},
  note         = {CoRR, abs/2309.13633}
}

@inproceedings{DBLP:conf/eamt/KocmiF23,
  author    = {Tom Kocmi and Christian Federmann},
  title     = {Large language models are state-of-the-art evaluators of translation quality},
  booktitle = {EAMT},
  pages     = {193--203},
  year      = {2023},
  publisher = {European Association for Machine Translation}
}

@inproceedings{DBLP:conf/emnlp/KryscinskiKMXS19,
  author    = {Wojciech Kryscinski and Nitish Shirish Keskar and Bryan McCann and Caiming Xiong and Richard Socher},
  title     = {Neural text summarization: A critical evaluation},
  booktitle = {EMNLP/IJCNLP (1)},
  pages     = {540--551},
  year      = {2019},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/emnlp/KryscinskiMXS20,
  author    = {Wojciech Kryscinski and Bryan McCann and Caiming Xiong and Richard Socher},
  title     = {Evaluating the factual consistency of abstractive text summarization},
  booktitle = {EMNLP (1)},
  pages     = {9332--9346},
  year      = {2020},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{lin-2004-rouge,
  author    = {Chin-Yew Lin},
  title     = {{ROUGE}: A package for automatic evaluation of summaries},
  booktitle = {Text Summarization Branches Out},
  pages     = {74--81},
  year      = {2004},
  publisher = {Association for Computational Linguistics}
}

@misc{DBLP:journals/corr/abs-2311-08788,
  author       = {Minqian Liu and Ying Shen and Zhiyang Xu and Yixin Cao and Eunah Cho and Vaibhav Kumar and Reza Ghanadan and Lifu Huang},
  title        = {X-eval: Generalizable multi-aspect text evaluation via augmented instruction tuning with auxiliary evaluation aspects},
  howpublished = {\url{https://arxiv.org/abs/2311.08788}},
  year         = {2023},
  note         = {CoRR, abs/2311.08788}
}

@inproceedings{DBLP:conf/emnlp/LiuIXWXZ23,
  author    = {Yang Liu and Dan Iter and Yichong Xu and Shuohang Wang and Ruochen Xu and Chenguang Zhu},
  title     = {G-eval: NLG evaluation using GPT-4 with better human alignment},
  booktitle = {EMNLP},
  pages     = {2511--2522},
  year      = {2023},
  publisher = {Association for Computational Linguistics}
}

@misc{liu2023geval,
  author       = {Yang Liu and Dan Iter and Yichong Xu and Shuohang Wang and Ruochen Xu and Chenguang Zhu},
  title        = {G-eval: NLG evaluation using GPT-4 with better human alignment},
  howpublished = {\url{http://arxiv.org/abs/2303.16634}},
  year         = {2023},
  note         = {arXiv preprint}
}

@misc{DBLP:journals/corr/abs-2305-14658,
  author       = {Yongkang Liu and Shi Feng and Daling Wang and Yifei Zhang and Hinrich Sch{\"u}tze},
  title        = {Evaluate what you can't evaluate: Unassessable generated responses quality},
  howpublished = {\url{https://arxiv.org/abs/2305.14658}},
  year         = {2023},
  note         = {CoRR, abs/2305.14658}
}

@misc{DBLP:journals/corr/abs-2309-13308,
  author       = {Yuxuan Liu and Tianchi Yang and Shaohan Huang and Zihan Zhang and Haizhen Huang and Furu Wei and Weiwei Deng and Feng Sun and Qi Zhang},
  title        = {Calibrating LLM-based evaluator},
  howpublished = {\url{https://arxiv.org/abs/2309.13308}},
  year         = {2023},
  note         = {CoRR, abs/2309.13308}
}

@misc{DBLP:journals/corr/abs-2303-15621,
  author       = {Zheheng Luo and Qianqian Xie and Sophia Ananiadou},
  title        = {ChatGPT as a factual inconsistency evaluator for abstractive text summarization},
  howpublished = {\url{https://arxiv.org/abs/2303.15621}},
  year         = {2023},
  note         = {CoRR, abs/2303.15621}
}

@inproceedings{DBLP:conf/acl/MehriE20,
  author    = {Shikib Mehri and Maxine Esk{\'e}nazi},
  title     = {USR: an unsupervised and reference free evaluation metric for dialog generation},
  booktitle = {ACL},
  pages     = {681--707},
  year      = {2020},
  publisher = {Association for Computational Linguistics}
}

@misc{DBLP:journals/corr/abs-2308-16797,
  author       = {John Mendon{\c{c}}a and Patr{\'{\i}}cia Pereira and Jo{\~a}o~Paulo Carvalho and Alon Lavie and Isabel Trancoso},
  title        = {Simple LLM prompting is state-of-the-art for robust and multilingual dialogue evaluation},
  howpublished = {\url{https://arxiv.org/abs/2308.16797}},
  year         = {2023},
  note         = {CoRR, abs/2308.16797}
}

@inproceedings{DBLP:conf/acl/PapineniRWZ02,
  author    = {Kishore Papineni and Salim Roukos and Todd Ward and Wei-Jing Zhu},
  title     = {BLEU: A method for automatic evaluation of machine translation},
  booktitle = {ACL},
  pages     = {311--318},
  year      = {2002},
  publisher = {ACL}
}

@inproceedings{DBLP:conf/wmt/Popovic17,
  author    = {Maja Popovic},
  title     = {chrf++: words helping character n-grams},
  booktitle = {WMT},
  pages     = {612--618},
  year      = {2017},
  publisher = {Association for Computational Linguistics}
}

@misc{DBLP:journals/corr/abs-2309-09558,
  author       = {Xiao Pu and Mingqi Gao and Xiaojun Wan},
  title        = {Summarization is (almost) dead},
  howpublished = {\url{https://arxiv.org/abs/2309.09558}},
  year         = {2023},
  note         = {CoRR, abs/2309.09558}
}

@inproceedings{DBLP:conf/emnlp/ReiSFL20,
  author    = {Ricardo Rei and Craig Stewart and Ana C. Farinha and Alon Lavie},
  title     = {COMET: A neural framework for MT evaluation},
  booktitle = {EMNLP (1)},
  pages     = {2685--2702},
  year      = {2020},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/acl/RibeiroWGS20,
  author    = {Marco T{\'u}lio Ribeiro and Tongshuang Wu and Carlos Guestrin and Sameer Singh},
  title     = {Beyond accuracy: Behavioral testing of NLP models with checklist},
  booktitle = {ACL},
  pages     = {4902--4912},
  year      = {2020},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/emnlp/SaiDSMK21,
  author    = {Ananya B. Sai and Tanay Dixit and Dev Yashpal Sheth and Sreyas Mohan and Mitesh M. Khapra},
  title     = {Perturbation checklists for evaluating NLG evaluation metrics},
  booktitle = {EMNLP (1)},
  pages     = {7219--7234},
  year      = {2021},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/acl/SellamDP20,
  author    = {Thibault Sellam and Dipanjan Das and Ankur P. Parikh},
  title     = {BLEURT: learning robust metrics for text generation},
  booktitle = {ACL},
  pages     = {7881--7892},
  year      = {2020},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/emnlp/SottanaLZY23,
  author    = {Andrea Sottana and Bin Liang and Kai Zou and Zheng Yuan},
  title     = {Evaluation metrics in the era of GPT-4: reliably evaluating large language models on sequence to sequence tasks},
  booktitle = {EMNLP},
  pages     = {8776--8788},
  year      = {2023},
  publisher = {Association for Computational Linguistics}
}

@misc{DBLP:journals/corr/abs-2307-09288,
  author       = {Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton-Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aur{\'e}lien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  title        = {Llama 2: Open foundation and fine-tuned chat models},
  howpublished = {\url{https://arxiv.org/abs/2307.09288}},
  year         = {2023},
  note         = {CoRR, abs/2307.09288}
}

@misc{DBLP:journals/corr/abs-2303-04048,
  author       = {Jiaan Wang and Yunlong Liang and Fandong Meng and Haoxiang Shi and Zhixu Li and Jinan Xu and Jianfeng Qu and Jie Zhou},
  title        = {Is ChatGPT a good NLG evaluator? A preliminary study},
  howpublished = {\url{https://arxiv.org/abs/2303.04048}},
  year         = {2023},
  note         = {CoRR, abs/2303.04048}
}

@misc{DBLP:conf/emnlp/ShenCNYB23,
  author       = {Peiyi Wang and Lei Li and Liang Chen and Dawei Zhu and Binghuai Lin and Yunbo Cao and Qi Liu and Tianyu Liu and Zhifang Sui},
  title        = {Large language models are not fair evaluators},
  howpublished = {\url{https://arxiv.org/abs/2305.17926}},
  year         = {2023},
  note         = {CoRR, abs/2305.17926}
}

@inproceedings{DBLP:conf/inlg/XieCL23,
  author    = {Zhuohan Xie and Trevor Cohn and Jey Han Lau},
  title     = {The next chapter: A study of large language models in storytelling},
  booktitle = {INLG},
  pages     = {323--351},
  year      = {2023},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/emnlp/XieLCL23,
  author    = {Zhuohan Xie and Miao Li and Trevor Cohn and Jey Han Lau},
  title     = {Deltascore: Fine-grained story evaluation with perturbations},
  booktitle = {EMNLP (Findings)},
  pages     = {5317--5331},
  year      = {2023},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{DBLP:conf/emnlp/XuWPSFWL23,
  author    = {Wenda Xu and Danqing Wang and Liangming Pan and Zhenqiao Song and Markus Freitag and William Wang and Lei Li},
  title     = {INSTRUCTSCORE: towards explainable text generation evaluation with automatic feedback},
  booktitle = {EMNLP},
  pages     = {5967--5994},
  year      = {2023},
  publisher = {Association for Computational Linguistics}
}

@misc{DBLP:journals/corr/abs-2312-15407,
  author       = {Chen Zhang and Luis Fernando D'Haro and Yiming Chen and Malu Zhang and Haizhou Li},
  title        = {A comprehensive analysis of the effectiveness of large language models as automatic dialogue evaluators},
  howpublished = {\url{https://arxiv.org/abs/2312-15407}},
  year         = {2023},
  note         = {CoRR, abs/2312-15407}
}

@inproceedings{DBLP:conf/iclr/ZhangKWWA20,
  author    = {Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
  title     = {BERTscore: Evaluating text generation with {BERT}},
  booktitle = {ICLR},
  year      = {2020},
  note      = {OpenReview.net}
}

@misc{DBLP:journals/corr/abs-2306-05685,
  author       = {Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
  title        = {Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
  howpublished = {\url{https://arxiv.org/abs/2306-05685}},
  year         = {2023},
  note         = {CoRR, abs/2306-05685}
}

@inproceedings{DBLP:conf/naacl/ZhouBTDSO22,
  author    = {Kaitlyn Zhou and Su Lin Blodgett and Adam Trischler and Hal Daum{\'e} III and Kaheer Suleman and Alexandra Olteanu},
  title     = {Deconstructing NLG evaluation: Evaluation practices, assumptions, and their implications},
  booktitle = {NAACL-HLT},
  pages     = {314--324},
  year      = {2022},
  publisher = {Association for Computational Linguistics}
}

@article{lakens2017equivalence,
author = {Lakens, Daniël},
year = {2017},
month = {05},
pages = {194855061769717},
title = {Equivalence Tests: A Practical Primer for t Tests, Correlations, and Meta-Analyses},
volume = {8},
journal = {Social Psychological and Personality Science},
doi = {10.1177/1948550617697177}
}

@article{achiam2023gpt,
  title        = {Gpt-4 technical report},
  author       = {Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  year         = 2023,
  journal      = {arXiv:2303.08774}
}
@article{angrist2014perils,
  title        = {The perils of peer effects},
  author       = {Angrist, Joshua D},
  year         = 2014,
  journal      = {Labour Economics},
  publisher    = {Elsevier},
  volume       = 30,
  pages        = {98--108}
}


@article{li2023prd,
  title={Prd: Peer rank and discussion improve large language model based evaluations},
  author={Li, Ruosen and Patel, Teerth and Du, Xinya},
  journal={arXiv preprint arXiv:2307.02762},
  year={2023}
}

@article{zhu2024dyval,
  title={DyVal 2: Dynamic Evaluation of Large Language Models by Meta Probing Agents},
  author={Zhu, Kaijie and Wang, Jindong and Zhao, Qinlin and Xu, Ruochen and Xie, Xing},
  journal={arXiv:2402.14865},
  year={2024}
}

@article{fan2024nphardeval4v,
  title={NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language Models},
  author={Fan, Lizhou and Hua, Wenyue and Li, Xiang and Zhu, Kaijie and Jin, Mingyu and Li, Lingyao and Ling, Haoyang and Chi, Jinkui and Wang, Jindong and Ma, Xin and others},
  journal={arXiv:2403.01777},
  year={2024}
}


@article{hua2024disentangling,
  title={Disentangling Logic: The Role of Context in Large Language Model Reasoning Capabilities},
  author={Hua, Wenyue and Zhu, Kaijie and Li, Lingyao and Fan, Lizhou and Lin, Shuhang and Jin, Mingyu and Xue, Haochen and Li, Zelong and Wang, JinDong and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2406.02787},
  year={2024}
}


@inproceedings{zhang2024prototypical,
  title={Prototypical Reward Network for Data-Efficient RLHF},
  author={Zhang, Jinghan and Wang, Xiting and Jin, Yiqiao and Chen, Changyu and Zhang, Xinhao and Liu, Kunpeng},
  booktitle={ACL},
  year={2024}
}

@article{liu2023testing,
  title={Testing for Reviewer Anchoring in Peer Review: A Randomized Controlled Trial},
  author={Liu, Ryan and Jecmen, Steven and Conitzer, Vincent and Fang, Fei and Shah, Nihar B},
  journal={arXiv:2307.05443},
  year={2023}
}


@article{d2024marg,
  title={MARG: Multi-Agent Review Generation for Scientific Papers},
  author={D'Arcy, Mike and Hope, Tom and Birnbaum, Larry and Downey, Doug},
  journal={arXiv:2401.04259},
  year={2024}
}


@misc{wang2024mars,
      title={MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset}, 
      author={Weiqi Wang and Yangqiu Song},
      year={2024},
      eprint={2406.02106},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{xie2024can,
  title={Can Large Language Model Agents Simulate Human Trust Behaviors?},
  author={Xie, Chengxing and Chen, Canyu and Jia, Feiran and Ye, Ziyu and Shu, Kai and Bibi, Adel and Hu, Ziniu and Torr, Philip and Ghanem, Bernard and Li, Guohao},
  journal={arXiv:2402.04559},
  year={2024}
}


@article{wang2023backdoor,
  title={Backdoor activation attack: Attack large language models using activation steering for safety-alignment},
  author={Wang, Haoran and Shu, Kai},
  journal={arXiv:2311.09433},
  year={2023}
}
@article{liu2023scelmo,
  title={scELMo: Embeddings from Language Models are Good Learners for Single-cell Data Analysis},
  author={Liu, Tianyu and Chen, Tianqi and Zheng, Wangjie and Luo, Xiao and Zhao, Hongyu},
  journal={bioRxiv},
  pages={2023--12},
  year={2023},
  publisher={Cold Spring Harbor Laboratory}
}


@misc{AutoGPT,
  title        = {AutoGPT},
  author       = {Significant-Gravitas},
  year         = 2023,
  howpublished = {\url{https://github.com/Significant-Gravitas/AutoGPT}}
}
@article{bai2023benchmarking,
  title        = {Benchmarking Foundation Models with Language-Model-as-an-Examiner},
  author       = {Bai, Yushi and Ying, Jiahao and Cao, Yixin and Lv, Xin and He, Yuze and Wang, Xiaozhi and Yu, Jifan and Zeng, Kaisheng and Xiao, Yijia and Lyu, Haozhe and others},
  year         = 2023,
  journal      = {arXiv:2306.04181}
}
@book{bartos2002using,
  title        = {Using conflict theory},
  author       = {Bartos, Otomar J and Wehr, Paul},
  year         = 2002,
  publisher    = {Cambridge University Press}
}
@article{burns2023weak,
  title        = {Weak-to-strong generalization: Eliciting strong capabilities with weak supervision},
  author       = {Burns, Collin and Izmailov, Pavel and Kirchner, Jan Hendrik and Baker, Bowen and Gao, Leo and Aschenbrenner, Leopold and Chen, Yining and Ecoffet, Adrien and Joglekar, Manas and Leike, Jan and others},
  year         = 2023,
  journal      = {arXiv:2312.09390}
}
@inproceedings{chan2023chateval,
  title        = {ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate},
  author       = {Chan, Chi-Min and Chen, Weize and Su, Yusheng and Yu, Jianxuan and Xue, Wei and Zhang, Shanghang and Fu, Jie and Liu, Zhiyuan},
  year         = 2023,
  booktitle    = {ICLR}
}
@misc{ChatArena,
  title        = {ChatArena: Multi-Agent Language Game Environments for Large Language Models},
  author       = {Wu, Yuxiang and Jiang, Zhengyao and Khan, Akbir and Fu, Yao and Ruis, Laura and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  year         = 2023,
  publisher    = {GitHub},
  url          = {https://github.com/chatarena/chatarena},
  howpublished = {GitHub repository},
  version      = {0.1}
}
@inproceedings{chen2023agentverse,
  title        = {Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors},
  author       = {Chen, Weize and Su, Yusheng and Zuo, Jingwei and Yang, Cheng and Yuan, Chenfei and Chan, Chi-Min and Yu, Heyang and Lu, Yaxi and Hung, Yi-Hsin and Qian, Chen and others},
  year         = 2023,
  booktitle    = {ICLR}
}
@article{cialdini2004social,
  title        = {Social influence: Compliance and conformity},
  author       = {Cialdini, Robert B and Goldstein, Noah J},
  year         = 2004,
  journal      = {Annu. Rev. Psychol.},
  publisher    = {Annual Reviews},
  volume       = 55,
  pages        = {591--621}
}
@article{cinelli2021echo,
  title        = {The echo chamber effect on social media},
  author       = {Cinelli, Matteo and De Francisci Morales, Gianmarco and Galeazzi, Alessandro and Quattrociocchi, Walter and Starnini, Michele},
  year         = 2021,
  journal      = {PNAS},
  publisher    = {National Acad Sciences},
  volume       = 118,
  number       = 9,
  pages        = {e2023301118}
}
@misc{claude3,
  title        = {Introducing the next generation of Claude},
  author       = {Anthropic},
  year         = 2024,
  url          = {https://www.anthropic.com/news/claude-3-family},
  urldate      = {March 9, 2023}
}
@article{cortes2021inconsistency,
  title        = {Inconsistency in conference peer review: revisiting the 2014 neurips experiment},
  author       = {Cortes, Corinna and Lawrence, Neil D},
  year         = 2021,
  journal      = {arXiv:2109.09774}
}
@article{del2017modeling,
  title        = {Modeling confirmation bias and polarization},
  author       = {Del Vicario, Michela and Scala, Antonio and Caldarelli, Guido and Stanley, H Eugene and Quattrociocchi, Walter},
  year         = 2017,
  journal      = {Scientific reports},
  publisher    = {Nature Publishing Group UK London},
  volume       = 7,
  number       = 1,
  pages        = 40391
}
@article{dubois2023alpacafarm,
  title        = {Alpacafarm: A simulation framework for methods that learn from human feedback},
  author       = {Dubois, Yann and Li, Xuechen and Taori, Rohan and Zhang, Tianyi and Gulrajani, Ishaan and Ba, Jimmy and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  year         = 2023,
  journal      = {arXiv:2305.14387}
}
@inproceedings{elazar2024estimating,
  title        = {Estimating the Causal Effect of Early ArXiving on Paper Acceptance},
  author       = {Elazar, Yanai and Zhang, Jiayao and Wadden, David and Zhang, Bo and Smith, Noah A},
  year         = 2024,
  booktitle    = {CLeaR},
  pages        = {913--933},
  organization = {PMLR}
}
@article{fernandes2023devil,
  title        = {The devil is in the errors: Leveraging large language models for fine-grained machine translation evaluation},
  author       = {Fernandes, Patrick and Deutsch, Daniel and Finkelstein, Mara and Riley, Parker and Martins, Andr{\'e} FT and Neubig, Graham and Garg, Ankush and Clark, Jonathan H and Freitag, Markus and Firat, Orhan},
  year         = 2023,
  journal      = {arXiv:2308.07286}
}
@article{fox2023double,
  title        = {Double-blind peer review affects reviewer ratings and editor decisions at an ecology journal},
  author       = {Fox, Charles W and Meyer, Jennifer and Aim{\'e}, Emilie},
  year         = 2023,
  journal      = {Functional Ecology},
  publisher    = {Wiley Online Library},
  volume       = 37,
  number       = 5,
  pages        = {1144--1157}
}
@inproceedings{hardy2023large,
  title        = {Large language models meet cognitive science: Llms as tools, models, and participants},
  author       = {Hardy, Mathew and Sucholutsky, Ilia and Thompson, Bill and Griffiths, Tom},
  year         = 2023,
  booktitle    = {COGSCI},
  volume       = 45,
  number       = 45
}
@article{hong2023metagpt,
  title        = {Metagpt: Meta programming for multi-agent collaborative framework},
  author       = {Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng, Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and others},
  year         = 2023,
  journal      = {arXiv:2308.00352}
}
@misc{hua2024war,
  title        = {War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars},
  author       = {Wenyue Hua and Lizhou Fan and Lingyao Li and Kai Mei and Jianchao Ji and Yingqiang Ge and Libby Hemphill and Yongfeng Zhang},
  year         = 2024,
  eprint       = {2311.17227},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI}
}
@article{huang2023makes,
  title        = {What makes a successful rebuttal in computer science conferences?: A perspective on social interaction},
  author       = {Huang, Junjie and Huang, Win-bin and Bu, Yi and Cao, Qi and Shen, Huawei and Cheng, Xueqi},
  year         = 2023,
  journal      = {Journal of Informetrics},
  publisher    = {Elsevier},
  volume       = 17,
  number       = 3,
  pages        = 101427
}
@article{janis2008groupthink,
  title        = {Groupthink},
  author       = {Janis, Irving L},
  year         = 2008,
  journal      = {IEEE Engineering Management Review},
  publisher    = {THE IEEE, INC.},
  volume       = 36,
  number       = 1,
  pages        = 36
}
@article{jansen2023employing,
  title        = {Employing large language models in survey research},
  author       = {Jansen, Bernard J and Jung, Soon-gyo and Salminen, Joni},
  year         = 2023,
  journal      = {Natural Language Processing Journal},
  publisher    = {Elsevier},
  volume       = 4,
  pages        = 100020
}
@inproceedings{jin2024better,
  title        = {Better to Ask in English: Cross-Lingual Evaluation of Large Language Models for Healthcare Queries},
  author       = {Jin, Yiqiao and Chandra, Mohit and Verma, Gaurav and Hu, Yibo and De Choudhury, Munmun and Kumar, Srijan},
  year         = 2024,
  booktitle    = {Web Conference}
}
@inproceedings{jin2024mm,
  title        = {MM-Soc: Benchmarking Multimodal Large Language Models in Social Media Platforms},
  author       = {Jin, Yiqiao and Choi, Minje and Verma, Gaurav and Wang, Jindong and Kumar, Srijan},
  year         = {2024},
  booktitle      = {ACL}
}
@article{jovanovic2023reviewer,
  title        = {Reviewer assignment problem: A scoping review},
  author       = {Jovanovic, Jelena and Bagheri, Ebrahim},
  year         = 2023,
  journal      = {arXiv:2305.07887}
}
@article{kousha2024artificial,
  title        = {Artificial intelligence to support publishing and peer review: A summary and review},
  author       = {Kousha, Kayvan and Thelwall, Mike},
  year         = 2024,
  journal      = {Learned Publishing},
  publisher    = {Wiley Online Library},
  volume       = 37,
  number       = 1,
  pages        = {4--12}
}
@article{lee2023surveying,
  title        = {Surveying (dis) parities and concerns of compute hungry NLP research},
  author       = {Lee, Ji-Ung and Puerto, Haritz and van Aken, Betty and Arase, Yuki and Forde, Jessica Zosa and Derczynski, Leon and R{\"u}ckl{\'e}, Andreas and Gurevych, Iryna and Schwartz, Roy and Strubell, Emma and others},
  year         = 2023,
  journal      = {arXiv:2306.16900}
}
@misc{li2023alpacaeval,
  title        = {Alpacaeval: An automatic evaluator of instruction-following models},
  author       = {Li, Xuechen and Zhang, Tianyi and Dubois, Yann and Taori, Rohan and Gulrajani, Ishaan and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  year         = 2023
}
@misc{li2023large,
  title        = {Large Language Model-Empowered Agents for Simulating Macroeconomic Activities},
  author       = {Nian Li and Chen Gao and Yong Li and Qingmin Liao},
  year         = 2023,
  eprint       = {2310.10436},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI}
}
@article{li2024exploring,
  title        = {Exploring Multi-Document Information Consolidation for Scientific Sentiment Summarization},
  author       = {Li, Miao and Lau, Jey Han and Hovy, Eduard},
  year         = 2024,
  journal      = {arXiv:2402.18005}
}
@inproceedings{li2024league++,
  title={LEAGUE++: Empowering Continual Robot Learning Through Guided Skill Acquisition With Large Language Models},
  author={Li, Zhaoyi and Yu, Kelin and Cheng, Shuo and Xu, Danfei},
  booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
  year={2024}
}

@inproceedings{chen2023semi,
	title        = {Semi-Offline Reinforcement Learning for Optimized Text Generation},
	author       = {Chen, Changyu and Wang, Xiting and Jin, Yiqiao and Dong, Victor Ye and Dong, Li and Cao, Jie and Liu, Yi and Yan, Rui},
	year         = 2023,
	booktitle    = {ICML}
}

@article{liang2023can,
  title        = {Can large language models provide useful feedback on research papers? A large-scale empirical analysis},
  author       = {Liang, Weixin and Zhang, Yuhui and Cao, Hancheng and Wang, Binglu and Ding, Daisy and Yang, Xinyu and Vodrahalli, Kailas and He, Siyu and Smith, Daniel and Yin, Yian and others},
  year         = {2023},
  journal      = {arXiv:2310.01783}
}
@article{liang2024monitoring,
  title        = {Monitoring ai-modified content at scale: A case study on the impact of chatgpt on ai conference peer reviews},
  author       = {Liang, Weixin and Izzo, Zachary and Zhang, Yaohui and Lepp, Haley and Cao, Hancheng and Zhao, Xuandong and Chen, Lingjiao and Ye, Haotian and Liu, Sheng and Huang, Zhi and others},
  year         = 2024,
  journal      = {arXiv:2403.07183}
}
@article{liu2023shackles,
  title        = {The Shackles of Peer Review: Unveiling the Flaws in the Ivory Tower},
  author       = {Liu, Ying and Yang, Kaiqi and Liu, Yue and Drew, Michael GB},
  year         = 2023,
  journal      = {arXiv:2310.05966}
}
@article{liu2024augmenting,
  title        = {Augmenting Math Word Problems via Iterative Question Composing},
  author       = {Liu, Haoxiong and Yao, Andrew Chi-Chih},
  year         = 2024,
  journal      = {arXiv:2401.09003}
}
@article{lu2024calibrating,
  title        = {Calibrating “Cheap Signals” in Peer Review without a Prior},
  author       = {Lu, Yuxuan and Kong, Yuqing},
  year         = 2024,
  journal      = {NeurIPS},
  volume       = 36
}
@inproceedings{ma2022image,
  title        = {Image as Set of Points},
  author       = {Ma, Xu and Zhou, Yuqian and Wang, Huan and Qin, Can and Sun, Bin and Liu, Chang and Fu, Yun},
  year         = 2022,
  booktitle    = {ICLR}
}
@inproceedings{maddi2023peer,
  title        = {On the peer review reports: It's not the size that matters... really?},
  author       = {Maddi, Abdelghani and Miotti, Egidio Luis},
  year         = 2023,
  booktitle    = {ISSI}
}
@article{mcintosh2023safeguarding,
  title        = {Safeguarding Scientific Integrity: Examining Conflicts of Interest in the Peer Review Process},
  author       = {McIntosh, Leslie D and Vitale, Cynthia Hudson},
  year         = 2023,
  journal      = {arXiv:2308.04297}
}
@article{nisbett1977halo,
  title        = {The halo effect: Evidence for unconscious alteration of judgments.},
  author       = {Nisbett, Richard E and Wilson, Timothy D},
  year         = 1977,
  journal      = {Journal of personality and social psychology},
  publisher    = {American Psychological Association},
  volume       = 35,
  number       = 4,
  pages        = 250
}
@article{niu2023unveiling,
  title        = {Unveiling the Sentinels: Assessing AI Performance in Cybersecurity Peer Review},
  author       = {Niu, Liang and Xue, Nian and P{\"o}pper, Christina},
  year         = 2023,
  journal      = {arXiv:2309.05457}
}
@inproceedings{nourani2021anchoring,
  title        = {Anchoring bias affects mental model formation and user reliance in explainable ai systems},
  author       = {Nourani, Mahsan and Roy, Chiradeep and Block, Jeremy E and Honeycutt, Donald R and Rahman, Tahrima and Ragan, Eric and Gogate, Vibhav},
  year         = 2021,
  booktitle    = {IUI},
  pages        = {340--350}
}
@article{openai2023gpt4,
  title        = {GPT-4 Technical Report},
  author       = {OpenAI},
  year         = 2023,
  journal      = {Arxiv Preprint},
  volume       = {arXiv:2303.08774},
  url          = {https://arxiv.org/abs/2303.08774},
  eprint       = {2303.08774},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL}
}
@article{pandalm2024,
  title        = {PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization},
  author       = {Wang, Yidong and Yu, Zhuohao and Zeng, Zhengran and Yang, Linyi and Wang, Cunxiang and Chen, Hao and Jiang, Chaoya and Xie, Rui and Wang, Jindong and Xie, Xing and Ye, Wei and Zhang, Shikun and Zhang, Yue},
  year         = 2024,
  booktitle    = {ICLR}
}
@inproceedings{park2023generative,
  title        = {Generative agents: Interactive simulacra of human behavior},
  author       = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  year         = 2023,
  booktitle    = {UIST},
  pages        = {1--22}
}
@inproceedings{reimers2019sentence,
  title        = {Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author       = {Reimers, Nils and Gurevych, Iryna},
  year         = 2019,
  booktitle    = {EMNLP},
  pages        = {3982--3992}
}
@article{saveski2024counterfactual,
  title        = {Counterfactual evaluation of peer-review assignment policies},
  author       = {Saveski, Martin and Jecmen, Steven and Shah, Nihar and Ugander, Johan},
  year         = 2024,
  journal      = {NeurIPS},
  volume       = 36
}
@article{shamsabadi2024fair,
  title        = {A FAIR and Free Prompt-based Research Assistant},
  author       = {Shamsabadi, Mahsa and D'Souza, Jennifer},
  year         = 2024,
  journal      = {arXiv:2405.14601}
}
@article{stelmakh2021prior,
  title        = {Prior and prejudice: The novice reviewers' bias against resubmissions in conference peer review},
  author       = {Stelmakh, Ivan and Shah, Nihar B and Singh, Aarti and Daum{\'e} III, Hal},
  year         = 2021,
  journal      = {HCI},
  publisher    = {ACM New York, NY, USA},
  volume       = 5,
  number       = {CSCW1},
  pages        = {1--17}
}
@article{stephen2024distinguishing,
  title        = {Distinguishing articles in questionable and non-questionable journals using quantitative indicators associated with quality},
  author       = {Stephen, Dimity},
  year         = 2024,
  journal      = {arXiv:2405.06308}
}
@article{sun2022does,
  title        = {Does double-blind peer review reduce bias? Evidence from a top computer science conference},
  author       = {Sun, Mengyi and Barry Danfa, Jainabou and Teplitskiy, Misha},
  year         = 2022,
  journal      = {Journal of the Association for Information Science and Technology},
  publisher    = {Wiley Online Library},
  volume       = 73,
  number       = 6,
  pages        = {811--819}
}
@article{team2023gemini,
  title        = {Gemini: a family of highly capable multimodal models},
  author       = {Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  year         = 2023,
  journal      = {arXiv:2312.11805}
}
@article{touvron2023llama,
  title        = {Llama 2: Open foundation and fine-tuned chat models},
  author       = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  year         = 2023,
  journal      = {arXiv:2307.09288}
}
@book{turner1991social,
  title        = {Social influence.},
  author       = {Turner, John C},
  year         = 1991,
  publisher    = {Thomson Brooks/Cole Publishing Co}
}
@article{ugarov2023peer,
  title        = {Peer prediction for peer review: designing a marketplace for ideas},
  author       = {Ugarov, Alexander},
  year         = 2023,
  journal      = {arXiv:2303.16855}
}
@article{verharen2023chatgpt,
  title        = {ChatGPT identifies gender disparities in scientific peer review},
  author       = {Verharen, Jeroen PH},
  year         = 2023,
  journal      = {Elife},
  publisher    = {eLife Sciences Publications Limited},
  volume       = 12,
  pages        = {RP90230}
}
@article{wang2022self,
  title        = {Self-instruct: Aligning language model with self generated instructions},
  author       = {Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  year         = 2022,
  journal      = {arXiv:2212.10560}
}
@article{wu2023autogen,
  title        = {Autogen: Enabling next-gen llm applications via multi-agent conversation framework},
  author       = {Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Zhang, Shaokun and Zhu, Erkang and Li, Beibin and Jiang, Li and Zhang, Xiaoyun and Wang, Chi},
  year         = 2023,
  journal      = {arXiv:2308.08155}
}
@inproceedings{xiao2023large,
  title        = {Large Language Models Can Be Good Privacy Protection Learners},
  author       = {Xiao, Yijia and Jin, Yiqiao and Bai, Yushi and Wu, Yue and Yang, Xianjun and Luo, Xiao and Yu, Wenchao and Zhao, Xujiang and Liu, Yanchi and Chen, Haifeng and others},
  year         = {2024},
  booktitle      = {EMNLP}
}
@article{xu2024one,
  title        = {A One-Size-Fits-All Approach to Improving Randomness in Paper Assignment},
  author       = {Xu, Yixuan and Jecmen, Steven and Song, Zimeng and Fang, Fei},
  year         = 2024,
  journal      = {NeurIPS},
  volume       = 36
}
@article{yin2023lumos,
  title        = {{Lumos: Learning Agents with Unified Data, Modular Design, and Open-Source LLMs}},
  author       = {Yin, Da and Brahman, Faeze and Ravichander, Abhilasha and Chandu, Khyathi and Chang, Kai-Wei and Choi, Yejin and Lin, Bill Yuchen},
  year         = 2023,
  journal      = {arXiv:2311.05657}
}
@article{yu2023metamath,
  title        = {Metamath: Bootstrap your own mathematical questions for large language models},
  author       = {Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},
  year         = 2023,
  journal      = {arXiv:2309.12284}
}
@article{yuan2024self,
  title        = {Self-Rewarding Language Models},
  author       = {Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and Sukhbaatar, Sainbayar and Xu, Jing and Weston, Jason},
  year         = 2024,
  journal      = {arXiv:2401.10020}
}
@article{zhang2021conspicuous,
  title        = {Do conspicuous manuscripts experience shorter time in the duration of peer review?},
  author       = {Zhang, Guangyao and Shang, Furong and Xie, Weixi and Guo, Yuhan and Jiang, Chunlin and Wang, Xianwen},
  year         = 2021,
  journal      = {arXiv:2112.09360}
}
@article{zhang2022investigating,
  title        = {Investigating fairness disparities in peer review: A language model enhanced approach},
  author       = {Zhang, Jiayao and Zhang, Hongming and Deng, Zhun and Roth, Dan},
  year         = 2022,
  journal      = {arXiv:2211.06398}
}
@inproceedings{zhang2022system,
  title        = {A System-Level Analysis of Conference Peer Review},
  author       = {Zhang, Yichi and Yu, Fang-Yi and Schoenebeck, Grant and Kempe, David},
  year         = 2022,
  booktitle    = {EC},
  pages        = {1041--1080}
}
@inproceedings{zhangbertscore,
  title        = {BERTScore: Evaluating Text Generation with BERT},
  author       = {Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  year         = 2020,
  booktitle    = {ICLR}
}
@inproceedings{zhao2023competeai,
  title        = {Competeai: Understanding the competition behaviors in large language model-based agents},
  author       = {Zhao, Qinlin and Wang, Jindong and Zhang, Yixuan and Jin, Yiqiao and Zhu, Kaijie and Chen, Hao and Xie, Xing},
  year         = 2024,
  booktitle    = {ICML}
}
@article{zheng2024judging,
  title        = {Judging llm-as-a-judge with mt-bench and chatbot arena},
  author       = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  year         = 2024,
  journal      = {NeurIPS},
  volume       = 36
}
@inproceedings{zhu2024dynamic,
  title        = {Dynamic Evaluation of Large Language Models by Meta Probing Agents},
  author       = {Zhu, Kaijie and Wang, Jindong and Zhao, Qinlin and Xu, Ruochen and Xie, Xing},
  year         = 2024,
  booktitle    = {ICML}
}


@inproceedings{Feldman2015Bias,
author = {Feldman, Michael and Friedler, Sorelle A. and Moeller, John and Scheidegger, Carlos and Venkatasubramanian, Suresh},
title = {Certifying and Removing Disparate Impact},
year = {2015},
isbn = {9781450336642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2783258.2783311},
doi = {10.1145/2783258.2783311},
abstract = {What does it mean for an algorithm to be biased? In U.S. law, unintentional bias is encoded via disparate impact, which occurs when a selection process has widely different outcomes for different groups, even as it appears to be neutral. This legal determination hinges on a definition of a protected class (ethnicity, gender) and an explicit description of the process.When computers are involved, determining disparate impact (and hence bias) is harder. It might not be possible to disclose the process. In addition, even if the process is open, it might be hard to elucidate in a legal setting how the algorithm makes its decisions. Instead of requiring access to the process, we propose making inferences based on the data it uses.We present four contributions. First, we link disparate impact to a measure of classification accuracy that while known, has received relatively little attention. Second, we propose a test for disparate impact based on how well the protected class can be predicted from the other attributes. Third, we describe methods by which data might be made unbiased. Finally, we present empirical evidence supporting the effectiveness of our test for disparate impact and our approach for both masking bias and preserving relevant information in the data. Interestingly, our approach resembles some actual selection practices that have recently received legal scrutiny.},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {259–268},
numpages = {10},
keywords = {machine learning, fairness, disparate impact},
location = {Sydney, NSW, Australia},
series = {KDD '15}
}

@inproceedings{pruthi-etal-2019-combating,
    title = "Combating Adversarial Misspellings with Robust Word Recognition",
    author = "Pruthi, Danish  and
      Dhingra, Bhuwan  and
      Lipton, Zachary C.",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1561/",
    doi = "10.18653/v1/P19-1561",
    pages = "5582--5591",
    abstract = "To combat adversarial spelling mistakes, we propose placing a word recognition model in front of the downstream classifier. Our word recognition models build upon the RNN semi-character architecture, introducing several new backoff strategies for handling rare and unseen words. Trained to recognize words corrupted by random adds, drops, swaps, and keyboard mistakes, our method achieves 32{\%} relative (and 3.3{\%} absolute) error reduction over the vanilla semi-character model. Notably, our pipeline confers robustness on the downstream classifier, outperforming both adversarial training and off-the-shelf spell checkers. Against a BERT model fine-tuned for sentiment analysis, a single adversarially-chosen character attack lowers accuracy from 90.3{\%} to 45.8{\%}. Our defense restores accuracy to 75{\%}. Surprisingly, better word recognition does not always entail greater robustness. Our analysis reveals that robustness also depends upon a quantity that we denote the sensitivity."
}
@misc{ebrahimi2018hotflipwhiteboxadversarialexamples,
      title={HotFlip: White-Box Adversarial Examples for Text Classification}, 
      author={Javid Ebrahimi and Anyi Rao and Daniel Lowd and Dejing Dou},
      year={2018},
      eprint={1712.06751},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1712.06751}, 
}

@misc{ribeiro2016mattersmodelagnosticexplanationsidentifying,
      title={Nothing Else Matters: Model-Agnostic Explanations By Identifying Prediction Invariance}, 
      author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
      year={2016},
      eprint={1611.05817},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1611.05817}, 
}

@inproceedings{Hardmeier2014BiasMT,
author = {Vanmassenhove, Eva and Hardmeier, Christian and Way, Andy},
year = {2018},
month = {01},
pages = {3003-3008},
title = {Getting Gender Right in Neural Machine Translation},
doi = {10.18653/v1/D18-1334}
}

@misc{feldman2015certifyingremovingdisparateimpact,
      title={Certifying and removing disparate impact}, 
      author={Michael Feldman and Sorelle Friedler and John Moeller and Carlos Scheidegger and Suresh Venkatasubramanian},
      year={2015},
      eprint={1412.3756},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1412.3756}, 
}


@inproceedings{Bender2021Dangers,
author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
title = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ��},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445922},
doi = {10.1145/3442188.3445922},
abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {610–623},
numpages = {14},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}
@misc{brown2020languagemodelsfewshotlearners,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}, 
}

@book{grounded1,
  title={Theoretical sensitivity},
  author={Glaser, Barney G},
  year={1978},
  publisher={University of California,}
}

@article{grounded2,
author = {Connor, Justine and Flenady, Tracy and Massey, Deb and Dwyer, Trudy},
title = {Classic grounded theory: identifying the main concern},
journal = {Research in Nursing \& Health},
volume = {47},
number = {3},
pages = {277-288},
keywords = {Classic grounded theory, main concern, methodology, nursing research},
doi = {https://doi.org/10.1002/nur.22381},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nur.22381},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/nur.22381},
abstract = {Abstract Grounded theory comprises a family of research approaches designed to support the generation of a theory explaining a phenomenon experienced by a group of participants. One style of grounded theory, Classic grounded theory, is used less often than other types of grounded theory. The less frequent use of Classic grounded theory may be attributed to the limited availability of clearly articulated processes for conducting this method. Particularly important within Classic grounded theory, and not used in other forms of grounded theory, is identifying the participants' main concern. Identifying the participants' main concern is a signature feature of Classic grounded theory and is a prerequisite for ascertaining the core category and subsequent discovery of theory. In this article we provide a detailed explanation of how to identify the participants' main concern, and in so doing, we offer an exemplar to illustrate the process involved.},
year = {2024}
}

@article{thematiccoding,
author = {Muhammad Naeem and Wilson Ozuem and Kerry Howell and Silvia Ranfagni},
title ={A Step-by-Step Process of Thematic Analysis to Develop a Conceptual Model in Qualitative Research},

journal = {International Journal of Qualitative Methods},
volume = {22},
number = {},
pages = {16094069231205789},
year = {2023},
doi = {10.1177/16094069231205789},

URL = { 
    
        https://doi.org/10.1177/16094069231205789
    
    

},
eprint = { 
    
        https://doi.org/10.1177/16094069231205789
    
    

}
,
    abstract = { Thematic analysis is a highly popular technique among qualitative researchers for analyzing qualitative data, which usually comprises thick descriptive data. However, the application and use of thematic analysis has also involved complications due to confusion regarding the final outcome’s presentation as a conceptual model. This paper develops a systematic thematic analysis process for creating a conceptual model from qualitative research findings. It explores the adaptability of the proposed process across various research methodologies, including constructivist methodologies, positivist methodologies, grounded theory, and interpretive phenomenology, and justifies their application. The paper distinguishes between inductive and deductive coding approaches and emphasizes the merits of each. It suggests that the derived systematic thematic analysis model is valuable across multiple disciplines, particularly in grounded theory, ethnographic approaches, and narrative approaches, while also being adaptable to more descriptive, positivist-based methodologies. By providing a methodological roadmap, this study enhances the rigor and replicability of thematic analysis and offers a comprehensive strategy for theoretical conceptualization in qualitative research. The contribution of this paper is a systematic six-step thematic analysis process that leads to the development of a conceptual model; each step is described in detail and examples are given. }
}
@misc{panickssery2024llmevaluatorsrecognizefavor,
      title={LLM Evaluators Recognize and Favor Their Own Generations}, 
      author={Arjun Panickssery and Samuel R. Bowman and Shi Feng},
      year={2024},
      eprint={2404.13076},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.13076}, 
}