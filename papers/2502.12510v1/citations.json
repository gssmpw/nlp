[
  {
    "index": 0,
    "papers": [
      {
        "key": "liang2024can",
        "author": "Liang, Weixin and Zhang, Yuhui and Cao, Hancheng and Wang, Binglu and Ding, Daisy Yi and Yang, Xinyu and Vodrahalli, Kailas and He, Siyu and Smith, Daniel Scott and Yin, Yian and others",
        "title": "Can large language models provide useful feedback on research papers? A large-scale empirical analysis"
      },
      {
        "key": "jin2024agentreview",
        "author": "Jin, Yiqiao  and\nZhao, Qinlin  and\nWang, Yiyang  and\nChen, Hao  and\nZhu, Kaijie  and\nXiao, Yijia  and\nWang, Jindong",
        "title": "{A}gent{R}eview: Exploring Peer Review Dynamics with {LLM} Agents"
      },
      {
        "key": "yu2024automated",
        "author": "Yu, Jianxiang and Ding, Zichen and Tan, Jiaqi and Luo, Kangyang and Weng, Zhenmin and Gong, Chenghua and Zeng, Long and Cui, RenJing and Han, Chengcheng and Sun, Qiushi and others",
        "title": "Automated Peer Reviewing in Paper SEA: Standardization, Evaluation, and Analysis"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "liangmonitoring",
        "author": "Liang, Weixin and Izzo, Zachary and Zhang, Yaohui and Lepp, Haley and Cao, Hancheng and Zhao, Xuandong and Chen, Lingjiao and Ye, Haotian and Liu, Sheng and Huang, Zhi and others",
        "title": "Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews"
      },
      {
        "key": "latona2024ai",
        "author": "Latona, Giuseppe Russo and Ribeiro, Manoel Horta and Davidson, Tim R and Veselovsky, Veniamin and West, Robert",
        "title": "The AI Review Lottery: Widespread AI-Assisted Peer Reviews Boost Paper Scores and Acceptance Rates"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "liang2024can",
        "author": "Liang, Weixin and Zhang, Yuhui and Cao, Hancheng and Wang, Binglu and Ding, Daisy Yi and Yang, Xinyu and Vodrahalli, Kailas and He, Siyu and Smith, Daniel Scott and Yin, Yian and others",
        "title": "Can large language models provide useful feedback on research papers? A large-scale empirical analysis"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zeng2024johnny",
        "author": "Zeng, Yi and Lin, Hongpeng and Zhang, Jingwen and Yang, Diyi and Jia, Ruoxi and Shi, Weiyan",
        "title": "How johnny can persuade llms to jailbreak them: Rethinking persuasion to challenge ai safety by humanizing llms"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "gallegos2024bias",
        "author": "Gallegos, Isabel O and Rossi, Ryan A and Barrow, Joe and Tanjim, Md Mehrab and Kim, Sungchul and Dernoncourt, Franck and Yu, Tong and Zhang, Ruiyi and Ahmed, Nesreen K",
        "title": "Bias and fairness in large language models: A survey"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "liang2024can",
        "author": "Liang, Weixin and Zhang, Yuhui and Cao, Hancheng and Wang, Binglu and Ding, Daisy Yi and Yang, Xinyu and Vodrahalli, Kailas and He, Siyu and Smith, Daniel Scott and Yin, Yian and others",
        "title": "Can large language models provide useful feedback on research papers? A large-scale empirical analysis"
      },
      {
        "key": "lu2024ai",
        "author": "Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David",
        "title": "The ai scientist: Towards fully automated open-ended scientific discovery"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "ye2024we",
        "author": "Ye, Rui and Pang, Xianghe and Chai, Jingyi and Chen, Jiaao and Yin, Zhenfei and Xiang, Zhen and Dong, Xiaowen and Shao, Jing and Chen, Siheng",
        "title": "Are We There Yet? Revealing the Risks of Utilizing Large Language Models in Scholarly Peer Review"
      },
      {
        "key": "yu2024automated",
        "author": "Yu, Jianxiang and Ding, Zichen and Tan, Jiaqi and Luo, Kangyang and Weng, Zhenmin and Gong, Chenghua and Zeng, Long and Cui, RenJing and Han, Chengcheng and Sun, Qiushi and others",
        "title": "Automated Peer Reviewing in Paper SEA: Standardization, Evaluation, and Analysis"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "DBLP:conf/emnlp/SaiDSMK21",
        "author": "Ananya B. Sai and Tanay Dixit and Dev Yashpal Sheth and Sreyas Mohan and Mitesh M. Khapra",
        "title": "Perturbation checklists for evaluating NLG evaluation metrics"
      },
      {
        "key": "DBLP:conf/acl/HeZ0KCGT23",
        "author": "Tianxing He and Jingyu Zhang and Tianle Wang and Sachin Kumar and Kyunghyun Cho and James R. Glass and Yulia Tsvetkov",
        "title": "On the blind spots of model-based evaluation metrics for text generation"
      },
      {
        "key": "DBLP:conf/emnlp/KarpinskaRTSGI22",
        "author": "Marzena Karpinska and Nishant Raj and Katherine Thai and Yixiao Song and Ankita Gupta and Mohit Iyyer",
        "title": "DEMETR: diagnosing evaluation metrics for translation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "DBLP:journals/corr/abs-2312-15407",
        "author": "Chen Zhang and Luis Fernando D'Haro and Yiming Chen and Malu Zhang and Haizhou Li",
        "title": "A comprehensive analysis of the effectiveness of large language models as automatic dialogue evaluators"
      },
      {
        "key": "DBLP:journals/corr/abs-2305-14658",
        "author": "Yongkang Liu and Shi Feng and Daling Wang and Yifei Zhang and Hinrich Sch{\\\"u}tze",
        "title": "Evaluate what you can't evaluate: Unassessable generated responses quality"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "zeng2024johnny",
        "author": "Zeng, Yi and Lin, Hongpeng and Zhang, Jingwen and Yang, Diyi and Jia, Ruoxi and Shi, Weiyan",
        "title": "How johnny can persuade llms to jailbreak them: Rethinking persuasion to challenge ai safety by humanizing llms"
      },
      {
        "key": "deshpande2023toxicity",
        "author": "Deshpande, Ameet and Murahari, Vishvak and Rajpurohit, Tanmay and Kalyan, Ashwin and Narasimhan, Karthik",
        "title": "Toxicity in chatgpt: Analyzing persona-assigned language models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "ye2024we",
        "author": "Ye, Rui and Pang, Xianghe and Chai, Jingyi and Chen, Jiaao and Yin, Zhenfei and Xiang, Zhen and Dong, Xiaowen and Shao, Jing and Chen, Siheng",
        "title": "Are We There Yet? Revealing the Risks of Utilizing Large Language Models in Scholarly Peer Review"
      }
    ]
  }
]