% * This paper deals with the problem of identifying and quantifying hallucinations in asr systems.

% * LLMs and related foundation models are prone to hallucination.  Hallucinations in this context are [[[[ CHECK THIS;  WE MUST GIVE A CORRECT DEFINITION WITH CITATION: understood to be outputs that are not grounded in reality. OBSERVE THAT HALLUCINATION IN THE CONTEXT OF LLMS MAY BE DIFFERENTLY DEFINED THAN HALLUCINATIONS IN THE CONTEXT OF ASR]].  The seriousness of the problem is understood, and much work has gone into solving this problem.\textcolor{blue}{Researchers in the field of NLG defined hallucination as text that is nonsensical, or unfaithful to the
% provided source input \cite{maynez2020faithfulness,parikh2020totto,ji2023survey,mittal2024towards}.fluent but unsupported text.\cite{filippova2020controlled} 
% and categorize as Extrinsic and intrinsic \cite{zhou2020detecting}}

% * Most work on hallucinations on *text* \textcolor{blue}{so much that there is a leaderboard for hallucination in text models https://github.com/vectara/hallucination-leaderboard, values computed using Vectara's Hughes Hallucination Evaluation Model} and images \textcolor{blue}{\cite{ji2023survey}}.  Hallucinations are generic phenomena, and also affect ASR systems and can in fact be a serious problem.

% * However, little formally reported work on hallucinations in asr systems.  we identify only \textcolor{blue}{5} papers?\textcolor{blue}{\cite{koenecke2024careless,frieske2024hallucinations,kim2024automatic,serai2021hallucinationspeechrecognitionerrors,baranski2025investigation}}

% \textcolor{blue}{* Hallucination is an important metric for evaluating the quality of ASR because WER is misleading in some cases (digits vs numbers) or (it overestimated the maximum values and underestimated the minimum values - in quality)}

% * The problem is that even the definition of 'hallucination' is unclear in the ASR context.  We only find one vague definition in XX (what is it).  All subsequent work has used this definition as basis.

% * Even under this definition,  it remains hard to determine when an ASR system has hallucinated, vs when it has merely misrecognized.  [WHAT IS THE STATE OF THIS]
% \textcolor{blue}{still true, which is why some researcher tried to detetct hallucination by feeding speech model with silence or audio only \cite{baranski2025investigation}, 
% and tools (vectara) used for text would misidentify phonetic errors as hallucination, stimulus is acoustic}


% * Any tests and analyses so far are restricted to [WHAT] \textcolor{blue}{limited models (mainly whisper) and limited datasets- case specific}


% * Conclusions made are [WHAT ARE THEY AND HOW ARE THEY INCOMPLETE, INACCURATE OR INSUFFICIENT].

% \textcolor{blue}{whisper hallucinates (reported 1 percent but that was for one aphasia dateset \cite{koenecke2024careless}, whisper hallucination rate maybe related to SNR \cite{kim2024automatic}, \cite{frieske2024hallucinations}  propose a method to distinguish hallucination
% from phonetic ASR errors using combination of WER, cosine similarity and perplexity and report on one dataset. \cite{baranski2025investigation} propose to identify hallucination by providing a list of commonly hallucinated phrases by whisper. 
% }

% * We do what?
% \begin{table*}[ht!]
% \small  % Reduce font size slightly
% \begin{tabular}{|p{2cm}|p{2cm}|p{2cm}|p{1cm}|p{1cm}|p{2.5cm}|p{2.5cm}|}
% \hline
% \textbf{Paper} & \textbf{Models} & \textbf{Datasets} & \textbf{Detection} & \textbf{ Evaluation} & \textbf{Hallucination Definition} & \textbf{Comments} \\
% \hline
% \cite{koenecke2024careless} & Whisper & Aphasia & Y & Y & Defined as undesirable generated text "that is nonsensical, or unfaithful to the provided source input." & Focused on heuristic-based hallucination detection. Detects potential hallucinations by comparing the same audio segments when run through Whisper twice in close succession + manual check. \\
% \hline
% \cite{frieske2024hallucinations} & Whisper & Common Voice, Librispeech & Y & Y & Generated content that is nonsensical or unfaithful to the provided source content. They divide hallucinations into intrinsic (contradicts source) and extrinsic (unverifiable). & Uses a heuristic method to define thresholds for WER > 30 and perplexity > 200 to evaluate fluency of a sentence. \\
% \hline
% \cite{kim2024automatic} & Whisper & ALLSSTAR corpus & - & Y & When a word absent in the target appears in a listener's response. & Focuses on listener responses for hallucination detection. \\
% \hline
% \cite{serai2021hallucinationspeechrecognitionerrors} & Sequence-to-Sequence Models & Fisher corpus, Virtual Patient project & Y & Y & Predicting or simulating ASR errors (e.g., phonetic confusions, substitutions, deletions) in text data. & describe the hallucination in ASR (Automatic Speech Recognition) and present a model predicting hallucinated word sequences.  Allows the model to see multiple plausible errorful transcripts per training example. \\
% \hline
% \cite{baranski2025investigation} & Whisper & The dataset consists of 301,317 non-speech audio files from Audioset, Musan, UrbanSound8K, and FSD50K, augmented with white/pink noise & Y & Y & Defined as predictions without phonetic or semantic connection to the reference, a definition they agree on but find problematic. & Uses transcriptions generated by ASR from non-speech audio, resulting in a list of most commonly generated texts and a filtered Bag of Hallucinations (BoH) for hallucination detection. \\
% \hline
% \textbf{Our Work} & Whisper-Large-v3, Wav2Vec2, SpeechT5, Seamless-M4T, HuBERT, Distil-Whisper, SpeechLLM, Whisper-Tiny & LibriSpeech, Primock, SPGISpeech, GLOBE, AMI, ATCOsim, Adversarial, BERSt, VoxCeleb & Y & Y & Errors classified into coarse-grained (e.g., "Hallucination Error") and fine-grained (e.g., Language, Phonetic, Oscillation Errors). & Comprehensive evaluation of hallucination errors across models and datasets. \\
% \hline
% \end{tabular}
% \caption{Summary of Papers and Contributions}
% \label{tab:papers}
% \end{table*}


%     \item \textbf{Training Data Influence:} The Whisper family's strong performance (e.g., 2.2/0.3 on LS\_clean) demonstrates:
%     \begin{itemize}
%         \item Benefits of massive multilingual pretraining (680k hours)
%         \item Multitask learning (transcription + language identification)
%         \item Noise robustness from diverse audio conditions
%     \end{itemize}

  