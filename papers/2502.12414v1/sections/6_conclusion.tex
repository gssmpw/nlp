\section{Conclusion}\label{sec:conclusion}

In our work, we introduce the Hallucination Error Rate (HER) as a crucial complement to traditional ASR evaluation metrics like WER, especially in high-risk applications where model reliability is critical. By developing a robust LLM-based hallucination detection framework, we present a comprehensive evaluation of ASR models across both synthetic and natural distribution shifts, highlighting the specific challenges ASR systems face under real-world conditions. Our findings emphasize the importance of incorporating HER into standard ASR evaluation practices, particularly for applications in safety-critical domains such as healthcare, legal, and aviation. Through detailed analysis, we show that traditional metrics like WER can mask significant hallucinations, emphasizing the need for more holistic evaluation methods. Our work lays the ground for future work in ASR model reliability, aiming to ensure that ASR systems not only produce accurate transcriptions but also avoid generating misleading, harmful, and unfaithful to input speech transcriptions. In future work, we plan to expand our evaluation to cover additional evaluation setups, ensuring a comprehensive set of assessments. Additionally, we aim to explore mitigation strategies, which are critical for enhancing the reliability of ASR systems.