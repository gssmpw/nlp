
\begin{table*}[h!]
\renewcommand{\arraystretch}{1.2}
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{p{0.2\textwidth} p{0.15\textwidth} p{0.2\textwidth} p{0.45\textwidth}}
\hline
\textbf{Model Type and Models} & \textbf{Parameters} & \textbf{Architecture} & \textbf{Pre-Training Objective and Training Data} \\ \hline

\textbf{wav2vec2}~\cite{baevski2020wav2vec} \newline 
-- wav2vec2-large-xlsr-53-english & 
315M & 
7-Conv (Kernel 10/3/3/3/3/2/2) + 24-Trans & 
Self-supervised pre-training on raw audio via contrastive loss. \newline 
Training data: Common Voice 6.1 (53 languages). \\ \hline

\textbf{hubert}~\cite{hsu2021hubert}\newline  
-- hubert-large-ls960-ft & 
316M & 
7-Conv (Kernel 10/3/3/3/3/2/2) + 24-Trans & 
Masked prediction pre-training. \newline 
Training data: Libri-Light (60k hours). \\ \hline

\textbf{seamless}~\cite{seamless2023} \newline 
-- hf-seamless-m4t-large \newline 
-- hf-seamless-m4t-medium & 
2.3B \newline 
1.2B & 
UnitY2 (Enc-Dec + Text Decoder) & 
Multilingual ASR/translation. \newline 
Training data: 443k hours of aligned speech-text (29 languages). \\ \hline

\textbf{speechllm}~\cite{Rajaa_SpeechLLM_Multi-Modal_LLM} \newline 
-- speechllm-1.5B & 
1.5B & 
HubertX encoder + TinyLlama decoder & 
Audio-text alignment via multi-task learning. \newline 
Training data: Proprietary ASR datasets. \\ \hline

\textbf{whisper}~\cite{radford2022robustspeechrecognitionlargescale} \newline 
-- whisper-large-v3 \newline 
-- distil-large-v3 \newline 
-- whisper-large-v2 \newline 
-- whisper-large-v3-turbo \newline 
-- distil-large-v2 \newline 
-- whisper-large \newline 
-- whisper-tiny \newline 
-- whisper-tiny.en \newline 
-- whisper-medium \newline 
-- whisper-medium.en \newline 
-- distil-medium.en \newline 
-- distil-small.en \newline 
-- whisper-small \newline 
-- whisper-small.en & 
1.55B \newline 
756M \newline 
769M \newline 
244M \newline
39M &
2-Conv (Kernel 3x3, stride 2) + 32-Trans (large) \newline 
2-Conv + 24-Trans (medium) \newline 
2-Conv + 12-Trans (small) & 
Multilingual ASR/translation. \newline 
Pre-training: 680k hours of web-crawled audio. \\ \hline

\textbf{Qwen}~\cite{chu2024qwen2}\newline 
-- Qwen2-Audio-7B & 
7B & 
Audio encoder + QwenLM decoder & 
Multi-task pretraining (ASR, TTS, alignment). \newline 
Training data: 3M audio-text pairs. \\ \hline

\end{tabular}%
}
\caption{Model architectures, parameters, and training details. Whisper variants include convolutional layers for spectrogram downsampling.}
\label{tab:models}
\end{table*}
