\section{Introduction}
Caching is an intuitive and pervasive technique employed in modern large-scale web service architectures for high performance and better resource utilization. These web services range across various domains e.g., social networks, microblogging platforms, and emerging IoT applications, to name a few~\cite{berg2020cachelib, twemcache, mcallister2021kangaroo, BronsonACCDDFGKLMPPSV13:tao-fb}. \textit{The challenges in the design of the caching solutions for this domain are (1) the large working set size and (2) the problem of caching objects of different sizes, especially dominated by numerous small-sized objects~\cite{berg2020cachelib, mcallister2021kangaroo, twemcache}}. The use of Flash-based SSDs has become popular in the design of these caches given their excellent performance cost tradeoff compared to DRAM and HDD~\cite{TangHLKL15:ripq, EisenmanCPHSAK19:flashield, WongWMGLKSBBG24:baleen, berg2020cachelib, mcallister2021kangaroo}. However, managing the limited write endurance of Flash in these caches remains a challenge~\cite{LeeSHC15:f2fs, HeKAA17:ssd-contract, JungK13:ssd-expectations}. To maximize Flash lifetime in Flash caches, extensive research has gone into admission policies, application write amplification, and caching algorithms. However, the problem of device-level write amplification (DLWA) in Flash caches has not received much attention.

The problem of device-level write amplification is important today given the increased focus on data center carbon emissions. As multiple data center operators e.g., Amazon~\cite{amazon-sustainability}, Google~\cite{google-sustainability}, Meta~\cite{meta-sustainability}, and Microsoft~\cite{microsoft-sustainability} are aiming to achieve Net Zero greenhouse emissions, they are focusing on cutting down on embodied carbon emissions. Reductions in embodied carbon emission will constitute the bulk of data center emissions post their switch to renewable sources of energy~\cite{GuptaEHWL0W22:act}. Since Flash is more carbon-efficient than DRAM per bit~\cite{GuptaEHWL0W22:act, embodiedcarbon}, it is important to cache more data in Flash than DRAM and increase the lifetime of Flash devices for carbon-efficient deployment of Flash caches at scale. 

State of the art Flash caches~\cite{berg2020cachelib, mcallister2021kangaroo} employ specialized engines for caching small and large objects. A set-associative cache design is used to minimize the tracking overhead of numerous small objects while a log-structured design is used to cache large objects to generate Flash-friendly writes. These two cache designs have distinct write patterns on the SSD. The set-associative cache produces frequent updates in a random fashion while the log-structured cache produces infrequent updates in a sequential fashion on the SSD. To counteract high DLWA, production deployments of these caches underutilize the Flash device leading to a large embodied carbon footprint. Production deployments of CacheLib~\cite{berg2020cachelib} which is an open-source Flash cache used as a caching building block to build and deploy 100s of services at Meta only utilizes 50\% of the Flash capacity~\cite{berg2020cachelib,mcallister2021kangaroo}. \textit{Our analysis shows that the cause of high DLWA in these cache designs is the intermixing of data from the two different caching engines. Targeted data placement on Flash to isolate data from the specialized engines holds promise to reduce DLWA and embodied carbon footprint.}

The ratified NVMe Flexible Data Placement technical proposal~\cite{fdp_tp} is the latest technical proposal on data placement that incorporates lessons learned from previous proposals (e.g., Multi-Stream SSDs~\cite{kang2014multi}, Open-Channel~\cite{bjorling2017lightnvm}, ZNS~\cite{bjorlingAHRMGA21}) to improve adoption. It provides abstractions for isolating data on NAND media without incurring the software engineering cost of garbage collection or NAND media management. FDP is backward compatible so an application can run unchanged on it. This is particularly important for the adoption of FDP SSDs by production systems that favour stability and are sensitive to maintenance burden of emerging storage interfaces over time.

We designed and implemented data isolation modules by harnessing FDP features to reduce data intermixing in Flash media from Flash caches. \textit{Our key insight is that the high invalidation rate of set-associative cache design over a small LBA space can be harnessed along with device overprovisioning to ensure the availability of spare blocks for writing new incoming data for it.} This is important in maintaining a low predictable DLWA and reduces embodied carbon emissions. 

Our design utilizing FDP data placement features is non-invasive to the architecture of Flash caches. We observe that the specialized architecture of Flash caches, designed for both small and large objects, can efficiently tag the objects stored within it along the I/O path. This aligns well with the feature set of FDP which allows applications to experiment with data placement only.  Our design allows the automatic discovery of FDP features and adaptability to the SSD topology. It also enables the pluggability of various placement decisions to allow extensibility. 

We designed and implemented our data isolation features for small and large objects in a state-of-the-art open-source caching library CacheLib~\cite{berg2020cachelib}. \textit{Our changes have been merged in the upstream repository and deployed at scale ~\cite{fdp-pr}}. To quantify the gains of data isolation in Flash caches, we also devised a theoretical model for DLWA. We present a comprehensive evaluation of our design and implementation using multiple publicly available production workloads from Meta and Twitter, used in past research~\cite{berg2020cachelib, mcallister2021kangaroo, twemcache}, to quantify the benefits and limitations of our approach. Our experiments demonstrate that data separation in flash caches can result in a 2x reduction in SSD device costs and a 4x reduction in embodied carbon footprint. Moreover, our results also highlight opportunities to reduce the DRAM sizes in Flash cache deployments and explore multi-tenant deployments that were not possible earlier due to host overprovisioning.  At scale, this translates to massive cost benefits and embodied carbon emission reductions. 

Concretely, this paper makes the following contributions.
We review the concepts of the FDP storage interface, its limitations, and its connection to previous data placement proposals (Section \ref{sec:fdp}). We analyze the advantages of data segregation by leveraging FDP features in Flash cache architectures equipped with specialized engines for storing objects of varying sizes (Section \ref{sec:observations}). Additionally, we present a theoretical model to quantify DLWA. We present the design and implementation details of Flash cache data segregation by incorporating FDP features into CacheLib, a popular state-of-the-art open-source caching library, without altering its architecture or user-facing API (Section \ref{sec:implementation}). Our experiments show that separating small, hot data from large, cold data in Flash caches can reach an optimal DLWA of \textasciitilde1 without requiring any host overprovisioning, even with multiple challenging read- and write-intensive workloads with billions of small object accesses.

