@article{agiza2024analyzing,
  title={Analyzing the Impact of Data Selection and Fine-Tuning on Economic and Political Biases in LLMs},
  author={Agiza, Ahmed and Mostagir, Mohamed and Reda, Sherief},
  journal={arXiv preprint arXiv:2404.08699},
  year={2024}
}

@article{buyl2024large,
  title={Large language models reflect the ideology of their creators},
  author={Buyl, Maarten and Rogiers, Alexander and Noels, Sander and Dominguez-Catena, Iris and Heiter, Edith and Romero, Raphael and Johary, Iman and Mara, Alexandru-Cristian and Lijffijt, Jefrey and De Bie, Tijl},
  journal={arXiv preprint arXiv:2410.18417},
  year={2024}
}

@inproceedings{dev2020measuring,
  title={On measuring and mitigating biased inferences of word embeddings},
  author={Dev, Sunipa and Li, Tao and Phillips, Jeff M and Srikumar, Vivek},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={7659--7666},
  year={2020}
}

@inproceedings{dhamala2021bold,
  title={Bold: Dataset and metrics for measuring biases in open-ended language generation},
  author={Dhamala, Jwala and Sun, Tony and Kumar, Varun and Krishna, Satyapriya and Pruksachatkun, Yada and Chang, Kai-Wei and Gupta, Rahul},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={862--872},
  year={2021}
}

@article{gabriel2020artificial,
  title={Artificial intelligence, values, and alignment},
  author={Gabriel, Iason},
  journal={Minds and machines},
  volume={30},
  number={3},
  pages={411--437},
  year={2020},
  publisher={Springer}
}

@article{giray2023prompt,
  title={Prompt engineering with ChatGPT: a guide for academic writers},
  author={Giray, Louie},
  journal={Annals of biomedical engineering},
  volume={51},
  number={12},
  pages={2629--2633},
  year={2023},
  publisher={Springer}
}

@inproceedings{grabowicz2022marrying,
  title={Marrying fairness and explainability in supervised learning},
  author={Grabowicz, Przemyslaw A and Perello, Nicholas and Mishra, Aarshee},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1905--1916},
  year={2022}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@inproceedings{hertweck2021moral,
  title={On the moral justification of statistical parity},
  author={Hertweck, Corinna and Heitz, Christoph and Loi, Michele},
  booktitle={Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages={747--757},
  year={2021}
}

@article{jiang2022communitylm,
  title={CommunityLM: Probing partisan worldviews from language models},
  author={Jiang, Hang and Beeferman, Doug and Roy, Brandon and Roy, Deb},
  journal={arXiv preprint arXiv:2209.07065},
  year={2022}
}

@incollection{kahneman2013prospect,
  title={Prospect theory: An analysis of decision under risk},
  author={Kahneman, Daniel and Tversky, Amos},
  booktitle={Handbook of the fundamentals of financial decision making: Part I},
  pages={99--127},
  year={2013},
  publisher={World Scientific}
}

@article{kazenwadel2023user,
  title={How User Language Affects Conflict Fatality Estimates in ChatGPT},
  author={Kazenwadel, Daniel and Steinert, Christoph V},
  journal={arXiv preprint arXiv:2308.00072},
  year={2023}
}

@article{kenton2021alignment,
  title={Alignment of language agents},
  author={Kenton, Zachary and Everitt, Tom and Weidinger, Laura and Gabriel, Iason and Mikulik, Vladimir and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2103.14659},
  year={2021}
}

@article{kirk2024prism,
  title={The PRISM Alignment Project: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models},
  author={Kirk, Hannah Rose and Whitefield, Alexander and R{\"o}ttger, Paul and Bean, Andrew and Margatina, Katerina and Ciro, Juan and Mosquera, Rafael and Bartolo, Max and Williams, Adina and He, He and others},
  journal={arXiv preprint arXiv:2404.16019},
  year={2024}
}

@article{lakoff1973hedges,
  title={Hedges: A study in meaning criteria and the logic of fuzzy concepts},
  author={Lakoff, George},
  journal={Journal of philosophical logic},
  volume={2},
  number={4},
  pages={458--508},
  year={1973},
  publisher={Springer}
}

@article{li2023survey,
  title={A survey on fairness in large language models},
  author={Li, Yingji and Du, Mengnan and Song, Rui and Wang, Xin and Wang, Ying},
  journal={arXiv preprint arXiv:2308.10149},
  year={2023}
}

@article{liu2023jailbreaking,
  title={Jailbreaking chatgpt via prompt engineering: An empirical study},
  author={Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Wang, Kailong and Liu, Yang},
  journal={arXiv preprint arXiv:2305.13860},
  year={2023}
}

@article{lu2021fantastically,
  title={Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity},
  author={Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
  journal={arXiv preprint arXiv:2104.08786},
  year={2021}
}

@article{lum2024bias,
  title={Bias in Language Models: Beyond Trick Tests and Toward RUTEd Evaluation},
  author={Lum, Kristian and Anthis, Jacy Reese and Nagpal, Chirag and D'Amour, Alexander},
  journal={arXiv preprint arXiv:2402.12649},
  year={2024}
}

@article{mesko2023prompt,
  title={Prompt engineering as an important emerging skill for medical professionals: tutorial},
  author={Mesk{\'o}, Bertalan},
  journal={Journal of medical Internet research},
  volume={25},
  pages={e50638},
  year={2023},
  publisher={JMIR Publications Toronto, Canada}
}

@article{meyer1997hedging,
  title={Hedging strategies in written academic discourse: Strengthening the argument by weakening the claim},
  author={Meyer, PG},
  journal={Hedging and discourse: Approaches to the analysis of a pragmatic phenomenon in academic texts/Walter de Gruyter \& Co},
  year={1997}
}

@article{moore2024large,
  title={Are Large Language Models Consistent over Value-laden Questions?},
  author={Moore, Jared and Deshpande, Tanvi and Yang, Diyi},
  journal={arXiv preprint arXiv:2407.02996},
  year={2024}
}

@inreference{mw_hedge,
  author    = {Merriam-Webster},
  title     = {Hedge},
  booktitle = {Merriam-Webster.com dictionary},
  url       = {https://www.merriam-webster.com/dictionary/hedge},
  urldate   = {2025-01-10},
}

@online{pro_publica,
    author = {Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, ProPublica},
    title = {Machine Bias},
    year = {2016},
    url = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
    urldate = {2016-05-23}
}

@inproceedings{raz2021group,
  title={Group fairness: Independence revisited},
  author={R{\"a}z, Tim},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={129--137},
  year={2021}
}

@inproceedings{reynolds2021prompt,
  title={Prompt programming for large language models: Beyond the few-shot paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  booktitle={Extended abstracts of the 2021 CHI conference on human factors in computing systems},
  pages={1--7},
  year={2021}
}

@inproceedings{santurkar2023whose,
  title={Whose opinions do language models reflect?},
  author={Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori},
  booktitle={International Conference on Machine Learning},
  pages={29971--30004},
  year={2023},
  organization={PMLR}
}

@article{scherrer2024evaluating,
  title={Evaluating the moral beliefs encoded in llms},
  author={Scherrer, Nino and Shi, Claudia and Feder, Amir and Blei, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{schramowski2022large,
  title={Large pre-trained language models contain human-like biases of what is right and wrong to do},
  author={Schramowski, Patrick and Turan, Cigdem and Andersen, Nico and Rothkopf, Constantin A and Kersting, Kristian},
  journal={Nature Machine Intelligence},
  volume={4},
  number={3},
  pages={258--268},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{sorensen2024value,
  title={Value kaleidoscope: Engaging ai with pluralistic human values, rights, and duties},
  author={Sorensen, Taylor and Jiang, Liwei and Hwang, Jena D and Levine, Sydney and Pyatkin, Valentina and West, Peter and Dziri, Nouha and Lu, Ximing and Rao, Kavel and Bhagavatula, Chandra and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={18},
  pages={19937--19947},
  year={2024}
}

@incollection{strack1987thinking,
  title={Thinking, judging, and communicating: A process account of context effects in attitude surveys},
  author={Strack, Fritz and Martin, Leonard L},
  booktitle={Social information processing and survey methodology},
  pages={123--148},
  year={1987},
  publisher={Springer}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{yona2024can,
  title={Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?},
  author={Yona, Gal and Aharoni, Roee and Geva, Mor},
  journal={arXiv preprint arXiv:2405.16908},
  year={2024}
}

