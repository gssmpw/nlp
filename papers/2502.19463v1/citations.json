[
  {
    "index": 0,
    "papers": [
      {
        "key": "agiza2024analyzing",
        "author": "Agiza, Ahmed and Mostagir, Mohamed and Reda, Sherief",
        "title": "Analyzing the Impact of Data Selection and Fine-Tuning on Economic and Political Biases in LLMs"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "santurkar2023whose",
        "author": "Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori",
        "title": "Whose opinions do language models reflect?"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "jiang2022communitylm",
        "author": "Jiang, Hang and Beeferman, Doug and Roy, Brandon and Roy, Deb",
        "title": "CommunityLM: Probing partisan worldviews from language models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "buyl2024large",
        "author": "Buyl, Maarten and Rogiers, Alexander and Noels, Sander and Dominguez-Catena, Iris and Heiter, Edith and Romero, Raphael and Johary, Iman and Mara, Alexandru-Cristian and Lijffijt, Jefrey and De Bie, Tijl",
        "title": "Large language models reflect the ideology of their creators"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "moore2024large",
        "author": "Moore, Jared and Deshpande, Tanvi and Yang, Diyi",
        "title": "Are Large Language Models Consistent over Value-laden Questions?"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "hendrycks2020measuring",
        "author": "Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob",
        "title": "Measuring massive multitask language understanding"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "scherrer2024evaluating",
        "author": "Scherrer, Nino and Shi, Claudia and Feder, Amir and Blei, David",
        "title": "Evaluating the moral beliefs encoded in llms"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "schramowski2022large",
        "author": "Schramowski, Patrick and Turan, Cigdem and Andersen, Nico and Rothkopf, Constantin A and Kersting, Kristian",
        "title": "Large pre-trained language models contain human-like biases of what is right and wrong to do"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "gabriel2020artificial",
        "author": "Gabriel, Iason",
        "title": "Artificial intelligence, values, and alignment"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "kenton2021alignment",
        "author": "Kenton, Zachary and Everitt, Tom and Weidinger, Laura and Gabriel, Iason and Mikulik, Vladimir and Irving, Geoffrey",
        "title": "Alignment of language agents"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "kenton2021alignment",
        "author": "Kenton, Zachary and Everitt, Tom and Weidinger, Laura and Gabriel, Iason and Mikulik, Vladimir and Irving, Geoffrey",
        "title": "Alignment of language agents"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "gabriel2020artificial",
        "author": "Gabriel, Iason",
        "title": "Artificial intelligence, values, and alignment"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "sorensen2024value",
        "author": "Sorensen, Taylor and Jiang, Liwei and Hwang, Jena D and Levine, Sydney and Pyatkin, Valentina and West, Peter and Dziri, Nouha and Lu, Ximing and Rao, Kavel and Bhagavatula, Chandra and others",
        "title": "Value kaleidoscope: Engaging ai with pluralistic human values, rights, and duties"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "kirk2024prism",
        "author": "Kirk, Hannah Rose and Whitefield, Alexander and R{\\\"o}ttger, Paul and Bean, Andrew and Margatina, Katerina and Ciro, Juan and Mosquera, Rafael and Bartolo, Max and Williams, Adina and He, He and others",
        "title": "The PRISM Alignment Project: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "mw_hedge",
        "author": "Merriam-Webster",
        "title": "Hedge"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "lakoff1973hedges",
        "author": "Lakoff, George",
        "title": "Hedges: A study in meaning criteria and the logic of fuzzy concepts"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "meyer1997hedging",
        "author": "Meyer, PG",
        "title": "Hedging strategies in written academic discourse: Strengthening the argument by weakening the claim"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "yona2024can",
        "author": "Yona, Gal and Aharoni, Roee and Geva, Mor",
        "title": "Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "hertweck2021moral",
        "author": "Hertweck, Corinna and Heitz, Christoph and Loi, Michele",
        "title": "On the moral justification of statistical parity"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "raz2021group",
        "author": "R{\\\"a}z, Tim",
        "title": "Group fairness: Independence revisited"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "li2023survey",
        "author": "Li, Yingji and Du, Mengnan and Song, Rui and Wang, Xin and Wang, Ying",
        "title": "A survey on fairness in large language models"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "grabowicz2022marrying",
        "author": "Grabowicz, Przemyslaw A and Perello, Nicholas and Mishra, Aarshee",
        "title": "Marrying fairness and explainability in supervised learning"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "pro_publica",
        "author": "Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, ProPublica",
        "title": "Machine Bias"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "dev2020measuring",
        "author": "Dev, Sunipa and Li, Tao and Phillips, Jeff M and Srikumar, Vivek",
        "title": "On measuring and mitigating biased inferences of word embeddings"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "dhamala2021bold",
        "author": "Dhamala, Jwala and Sun, Tony and Kumar, Varun and Krishna, Satyapriya and Pruksachatkun, Yada and Chang, Kai-Wei and Gupta, Rahul",
        "title": "Bold: Dataset and metrics for measuring biases in open-ended language generation"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "li2023survey",
        "author": "Li, Yingji and Du, Mengnan and Song, Rui and Wang, Xin and Wang, Ying",
        "title": "A survey on fairness in large language models"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "lum2024bias",
        "author": "Lum, Kristian and Anthis, Jacy Reese and Nagpal, Chirag and D'Amour, Alexander",
        "title": "Bias in Language Models: Beyond Trick Tests and Toward RUTEd Evaluation"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "kazenwadel2023user",
        "author": "Kazenwadel, Daniel and Steinert, Christoph V",
        "title": "How User Language Affects Conflict Fatality Estimates in ChatGPT"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "reynolds2021prompt",
        "author": "Reynolds, Laria and McDonell, Kyle",
        "title": "Prompt programming for large language models: Beyond the few-shot paradigm"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "wei2022chain",
        "author": "Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others",
        "title": "Chain-of-thought prompting elicits reasoning in large language models"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "lu2021fantastically",
        "author": "Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus",
        "title": "Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "giray2023prompt",
        "author": "Giray, Louie",
        "title": "Prompt engineering with ChatGPT: a guide for academic writers"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "mesko2023prompt",
        "author": "Mesk{\\'o}, Bertalan",
        "title": "Prompt engineering as an important emerging skill for medical professionals: tutorial"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "liu2023jailbreaking",
        "author": "Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Wang, Kailong and Liu, Yang",
        "title": "Jailbreaking chatgpt via prompt engineering: An empirical study"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "kahneman2013prospect",
        "author": "Kahneman, Daniel and Tversky, Amos",
        "title": "Prospect theory: An analysis of decision under risk"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "strack1987thinking",
        "author": "Strack, Fritz and Martin, Leonard L",
        "title": "Thinking, judging, and communicating: A process account of context effects in attitude surveys"
      }
    ]
  }
]