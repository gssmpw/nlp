\section{Related Work}
\textbf{Model interventions.} Model interventions are a family of approaches that manipulate model activations to control generations \cite{li_activation_steering, turner2024_steering, rodriguez2024controlling}. \citet{pmlr-v162-cuadros22a} propose a method to identify neurons in pre-trained transformer models that are most predictive of a particular concept (\textit{expert neurons}) and show that setting the activations of these experts to their mean value can induce the presence of the target concept in model generations. \citet{suau2024whispering} find the expert neurons for toxic language and steer the LLM to generate less toxic text by dampening these neurons, while \citet{turner2024_steering} achieve detoxification by using a contrastive prompt. \citet{rimsky_steering} propose a method to control generations by leveraging the differences in residual stream activations between pairs of positive and negative examples. In mLLMs,  \citet{Kojima_et_al} use this approach to produce more target language tokens in open-ended generation. However, prior work does not analyze the changes these interventions introduce in the representational space of mLLMs nor does it explore the impact of the interventions on cross-lingual alignment.


\paragraph{Aligning multilingual representations in mLLMs.} 
Research on LLM representation alignment falls into two broad categories:  1) Improving model performance on downstream tasks via post-training methods such as prompt-based techniques \cite{huang-etal-mprompt, tanwar-prompt_multi}, fine-tuning, or continuous pre-training \cite{zhang2023_crosslingualalignment, li2024_align}. 2)  Understanding where and how representation alignment is achieved in mLLMs. For example, \citet{wendler2024llamasworkenglishlatent} show that English-dominated mLLMs like Llama-2 use English as a pivot language and \citealt{zhao_llama} systematically evaluate factor contributing to successful cross-lingual transfer in such models.