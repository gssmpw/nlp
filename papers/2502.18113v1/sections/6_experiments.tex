\setlength{\textfloatsep}{12pt plus 2pt minus 2pt}
\section{Evaluation}
\label{sec: experiments}
We conduct a comprehensive experimental evaluation to answer the following research questions:

\noindent\textbf{Q1}: What impact do mainstream compact coding algorithms have on HNSW construction? (Sections \ref{subsec: index perf} and \ref{subsec: search perf})

\noindent\textbf{Q2}: How does \texttt{Flash} affect HNSW's construction efficiency, index size, and search performance? (Sections \ref{subsec: index perf} and \ref{subsec: search perf})

\noindent\textbf{Q3}: How does \texttt{Flash} scale across varying data volumes and segment counts (Section \ref{subsec: scalability})?


\noindent{
\textbf{Q4}: How general is \texttt{Flash} with respect to various graph algorithms, HNSW optimizations, and SIMD instructions (Section \ref{subsec: generality})?
}

\noindent\textbf{Q5}: To what extent does \texttt{Flash} optimize memory accesses and arithmetic operations during index construction? (Section \ref{subsec: ablation})

\noindent\textbf{Q6}: How do the parameters of \texttt{Flash} influence construction efficiency and index quality? (Section \ref{subsec: param sensitivity})

All source codes and datasets are publicly available at: \url{https://github.com/ZJU-DAILY/HNSW-Flash}.

\subsection{Experimental Settings}

\begin{table}[t]
% \vspace{-0.2cm}
 \setstretch{0.9}
 \fontsize{7.5pt}{4mm}\selectfont
  \caption{Statistics of experimental datasets.}
  \vspace{-0.4cm}
  \label{tab:datasets}
  \setlength{\tabcolsep}{.02\linewidth}{
  \begin{tabular}{l|l|l|l|l}
    \hline
    \textbf{Datasets} & \textbf{Data Volume} & \textbf{Size (GB)} & \textbf{Dim.} & \textbf{Query Volume} \\
    \hline
    \hline
    ARGILLA \cite{argilla} & 21,071,228 & 81 & 1,024 & 100,000 \\
    \hline
    ANTON \cite{anton} & 19,399,177 & 75 & 1,024 & 100,000 \\
    \hline
    LAION \cite{laion} & 100,000,000 & 293 & 768 & 100,000 \\
    \hline
    IMAGENET \cite{imagenet} & 13,158,856 & 38 & 768 & 100,000 \\
    \hline
    COHERE \cite{cohere} & 10,124,929 & 30 & 768 & 100,000 \\
    \hline
    DATACOMP \cite{datacomp} & 12,800,000 & 37 & 768 & 100,000 \\
    \hline
    BIGCODE \cite{bigcode} & 10,404,628 & 30 & 768 & 100,000 \\
    \hline
    SSNPP \cite{bigann} & 1,000,000,000 & 960 & 256 & 100,000 \\
    % \hline
    % DEEP \cite{bigann} & 1,000,000,000 & 367 & 96 & 100,000 \\
    \hline
  \end{tabular}
  }\vspace{-0.3cm}
\end{table}

\subsubsection{\textbf{Dataset}}
We use eight real-world vector datasets of diverse volumes and dimensions from deep embedding models, all of which are publicly accessible on Hugging Face and Big ANN Benchmarks websites \cite{huggingface, bigann}. A detailed summary of these datasets is presented in Table \ref{tab:datasets}. The query set is sampled from the dataset, with the corresponding ground truth generated through a linear scan.

\begin{figure*}
% \vspace{-0.4cm}
  \setlength{\abovecaptionskip}{0cm}
  \setlength{\belowcaptionskip}{0cm}
  \centering
  \footnotesize
  \hspace{2cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.25]{figures/index_perf/indexing_perf_legend.pdf}}{}
  \newline
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_time_perf_ssnpp10m.pdf}}{(a) SSNPP (10M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_time_perf_laion10m.pdf}}{(b) LAION (10M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_time_perf_cohere10m.pdf}}{(c) COHERE (10M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_time_perf_bigcode10m.pdf}}{(d) BIGCODE (10M)}
  \newline
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_time_perf_imagenet10m.pdf}}{(e) IMAGENET (13M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_time_perf_datacomp10m.pdf}}{(f) DATACOMP (12M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_time_perf_anton19m.pdf}}{(g) ANTON (19M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_time_perf_argilla20m.pdf}}{(h) ARGILLA (21M)}
  \newline
  \caption{Indexing times for all methods across eight datasets (red values at the top of each bar indicate speedup ratios).}
  \label{fig: index time}
  \vspace{-0.3cm}
\end{figure*}

\begin{figure*}
  \setlength{\abovecaptionskip}{0cm}
  \setlength{\belowcaptionskip}{0cm}
  \centering
  \footnotesize
  \hspace{2cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.25]{figures/index_perf/indexing_perf_legend.pdf}}{}
  \newline
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_size_perf_ssnpp10m.pdf}}{(a) SSNPP (10M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_size_perf_laion10m.pdf}}{(b) LAION (10M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_size_perf_cohere10m.pdf}}{(c) COHERE (10M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_size_perf_bigcode10m.pdf}}{(d) BIGCODE (10M)}
  \newline
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_size_perf_imagenet10m.pdf}}{(e) IMAGENET (13M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_size_perf_datacomp10m.pdf}}{(f) DATACOMP (12M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_size_perf_anton19m.pdf}}{(g) ANTON (19M)}
  \hspace{0.4cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.27]{figures/index_perf/index_size_perf_argilla20m.pdf}}{(h) ARGILLA (21M)}
  \newline
  \caption{Index sizes for all methods across eight datasets (red values at the top of each bar indicate compression ratios).}
  \label{fig: index size}
  \vspace{-0.3cm}
\end{figure*}

\subsubsection{\textbf{Compared Methods}}
We employ an advanced HNSW implementation from the latest \textit{hnswlib} repository \cite{hnswlib} as our benchmark, recognized as a standard in the field \cite{FosterK23, KhanAJ23}. This implementation is widely referenced by industrial vector databases \cite{SingleStore-V,hnsqlite,knowhere} and is a preferred choice for ANNS research \cite{ADSampling,PengZLJR23,IndykX23}. To accelerate index construction, three established compact coding methods are integrated into the repository, forming three baseline solutions. Additionally, the proposed \texttt{Flash} method is also incorporated into the repository for fair comparisons. {The generality of \texttt{Flash} is further evaluated on two recently optimized HNSW implementations (ADSampling \cite{ADSampling} and VBase \cite{zhang2023vbase}) and two additional graph algorithms (NSG \cite{NSG} and $\tau$-MG \cite{tau-MG}).}

\noindent$\bullet$ \textbf{HNSW} \cite{HNSW}. HNSW is a prominent graph-based ANNS algorithm \cite{graph_survey_vldb2021, DPG, ADSampling}. Its prevalence in industrial applications \cite{zhang2023vbase,PASE,ADBV} and extensive academic research \cite{LiZAH20,ZhangLW24,ZuoQZLD24} underscore its significance (see Section \ref{subsec: Related Work}). Given its representativeness, HNSW serves as a key graph index example in this research.

\noindent$\bullet$ \textbf{HNSW-PQ}. Product Quantization (PQ) is a recognized vector compression method in high-dimensional vector search \cite{PQ,OPQ,ScaNN}. We integrate PQ into the HNSW index construction process to accelerate graph indexing (see Section \ref{subsubsec: HNSW PQ} for details).

\noindent$\bullet$ \textbf{HNSW-SQ}. Scalar Quantization (SQ) converts floating-point values to integers, reducing memory overhead and enhancing search performance \cite{LVQ,LeanVec,qdrant-sq}. We integrate it into HNSW construction according to Section \ref{subsubsec: HNSW SQ}, and implement an optimized version to avoid decoding overhead based on a recent technical report \cite{qdrant-sq}.

\noindent$\bullet$ \textbf{HNSW-PCA}. Principal Component Analysis (PCA) is a classical dimensionality reduction method that enhances calculation efficiency by reducing the need to scan all dimensions \cite{ADSampling,yang2024bridging}. We integrate PCA into the construction process following Section \ref{subsubsec: HNSW PCA}.

\noindent$\bullet$ \textbf{HNSW-Flash}. We incorporate the proposed compact coding method, \texttt{Flash}, into the HNSW construction process. This method thoughtfully considers the unique characteristics of HNSW construction, optimizing memory layout and arithmetic operations to minimize random memory accesses and enhance SIMD utilization.

\subsubsection{\textbf{Parameter Settings}}
\label{subsubsec: param set}
For all methods compared, we set the maximum number of candidates ($C$) to 1024 and the maximum number of neighbors ($R$) to 32, following prior research recommendations\cite{HVS}. For compact coding parameters, we use established conventions to determine optimal settings. Specifically, the dimension of principal components ($d_{PCA}$) is chosen to ensure accumulated variance exceeds 0.9 in HNSW-PCA, as guided by our evaluations (see Section \ref{subsubsec: HNSW PCA}). For HNSW-SQ, we set the number of bits ($L_{SQ}$) to 8, which has been demonstrated as optimal in our experiments and existing literature \cite{qdrant-sq,LeanVec}. In HNSW-PQ, the number of subspaces ($M_{PQ}$) is identified through grid search, with bits per subspace ($L_{PQ}$) set to 8, consistent with common configurations in the literature \cite{PQ,OPQ,ZhanM0GZM21,PQfast}. For HNSW-Flash, we maintain the same subspace count ($M_{F}$) as HNSW-PQ; and the dimension of principal components ($d_{F}$) is selected via grid search. The bits per subspace ($L_{F}$) are set to 4, while each distance value is allocated 8 bits ($H=8$), enabling the ADT within a subspace to fit entirely within a SIMD register. Additionally, the batch size ($B$) for organizing the neighbor list is set to 16 to adapt to the number of distances within an ADT ($B=K=2^{L_F}$) and optimize register loading, resulting in each neighbor list comprising two blocks for separate execution of distance computations ($R/B=2$).

\subsubsection{\textbf{Performance Metrics}}
\label{subsubsec: perf metrics}
To evaluate index construction efficiency, we record indexing time, which includes data preprocessing times for algorithms with coding techniques. We assess index quality by measuring both search efficiency and accuracy for the query set. Search efficiency is quantified in Queries Per Second ($QPS$), representing the number of queries processed per second. {Search accuracy is measured through \textit{Recall} and the \textit{average distance ratio} (\textit{ADR}).} \textit{Recall} is defined as $Recall=\frac{|G\cup S|}{k}$, where $G$ is the ground truth set of the $k$ nearest vectors, and $S$ denotes the set of $k$ results returned by the algorithm, with $k$ set to 1 by default. {\textit{ADR}, defined in \cite{PatellaC08,TaoYSK10}, represents the average of the distance ratios between the retrieved $k$ database vectors and the ground truth nearest vectors.} All experimental results are derived from three repeated executions.

\subsubsection{\textbf{Environment Configuration}}
The experiments are conducted on a Linux server with dual Intel Xeon E5-2620 v3 CPUs (2.40GHz, 24 logical processors). The server employs an x86\_64 architecture with multiple cache levels (32KB L1, 256KB L2, and 15MB L3) and 378GB RAM. All methods are implemented in C++ using intrinsics for SIMD access, compiled with g++ 9.3.1 using the \textit{-Ofast} and \textit{-march=native} options. {SSE instructions are used by default for SIMD acceleration, and we also compare SSE (128-bit), AVX (256-bit), and AVX512 (512-bit)\footnote{{A new server is used for this evaluation due to the default does not support AVX512.}}.} The Eigen library \cite{eigen} optimizes matrix manipulations, while OpenMP facilitates parallel index construction and search execution across 24 threads.

\subsection{Indexing Performance}
\label{subsec: index perf}
The indexing times and index sizes for different methods are presented in Figures \ref{fig: index time} and \ref{fig: index size}, respectively. The indexing time for HNSW reflects only the graph index construction, while other methods include extra coding preprocessing. The results show that optimized methods exhibit shorter indexing times than the original HNSW, indicating that compact coding techniques effectively accelerate HNSW construction. HNSW-Flash consistently outperforms other methods across almost all datasets, achieving speedups of 10.4$\times$ to 22.9$\times$, highlighting \texttt{Flash}'s superiority in expediting index construction. Among baseline methods, HNSW-PCA and HNSW-SQ yield less than 2$\times$ speedup on most datasets, whereas HNSW-PQ demonstrates a better speedup ratio.
Figure \ref{fig: index size} illustrates that all optimized methods decrease the index size compared to the original HNSW by replacing high-dimensional vectors with compact vector codes. HNSW-PQ achieves the highest compression ratio, explaining its superior speedup in index construction. HNSW-Flash’s memory layout optimization, which stores neighbor codewords alongside IDs, results in a lower compression ratio than HNSW-PQ; however, it reaches a better speedup due to efficient memory access and arithmetic operations. Notably, HNSW-PQ suffers from a significant reduction in search performance (Figure \ref{fig: search perf}) due to its high compression error, indicating the poor index quality.

\begin{figure*}
% \vspace{-0.4cm}
  \setlength{\abovecaptionskip}{0cm}
  \setlength{\belowcaptionskip}{0cm}
  \centering
  \footnotesize
  \hspace{2cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.25]{figures/search_perf/search_perf_legend.pdf}}{}
  \newline
  % \hspace{-1cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/search_perf/search_perf_ssnpp10m.pdf}}{(a) SSNPP (10M)}
  \hspace{0.29cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/search_perf/search_perf_laion10m.pdf}}{(b) LAION (10M)}
  \hspace{0.26cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/search_perf/search_perf_cohere10m.pdf}}{(c) COHERE (10M)}
  \hspace{0.26cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/search_perf/search_perf_bigcode10m.pdf}}{(d) BIGCODE (10M)}
  \newline
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/search_perf/search_perf_imagenet10m.pdf}}{(e) IMAGENET (13M)}
  \hspace{0.25cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/search_perf/search_perf_datacomp10m.pdf}}{(f) DATACOMP (12M)}
  \hspace{0.22cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/search_perf/search_perf_anton19m.pdf}}{(g) ANTON (19M)}
  \hspace{0.35cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/search_perf/search_perf_argilla20m.pdf}}{(h) ARGILLA (21M)}
  \newline
  \caption{Comparison of search performance across eight datasets (the top right indicates better performance).}
  \label{fig: search perf}
  \vspace{-0.3cm}
\end{figure*}

\begin{figure}
\vspace{-0.1cm}
  \setlength{\abovecaptionskip}{0cm}
  \setlength{\belowcaptionskip}{0cm}
  \centering
  \footnotesize
  \stackunder[0.5pt]{\includegraphics[scale=0.17]{figures/search_perf/search_perf_legend.pdf}}{}
  \newline
  \stackunder[0.5pt]{\includegraphics[scale=0.25]{figures/search_adr_log/search_adr_laion10m_log.pdf}}{(a) LAION (10M)}
  % \hspace{0.15cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.25]{figures/search_adr_log/search_adr_ssnpp10m_log.pdf}}{(b) SSNPP (10M)}
  \newline
  \caption{{The \textit{QPS}-\textit{ADR} curves (the top left is better).}}
  \label{fig: search adr}
  \vspace{-0.2cm}
\end{figure}

\subsection{Search Performance}
\label{subsec: search perf}

{Figure \ref{fig: search perf} presents the \textit{QPS}-\textit{Recall} curves for all evaluated datasets, while Figure \ref{fig: search adr} shows the \textit{QPS}-\textit{ADR} curves for two representative datasets, with analogous trends observed for the remaining datasets.} The results indicate that HNSW-Flash consistently outperforms other methods across nearly all datasets, demonstrating its ability to accelerate index construction without compromising search performance. Additionally, the optimizations in the Candidate Acquisition (CA) stage can be seamlessly integrated into the search procedure, as it shares similar steps with the CA process.
The search performance of baseline methods varies significantly across datasets. For instance, HNSW-PCA achieves the best performance on ARGILLA but the worst on LAION, indicating sensitivity to data distribution. While HNSW-PQ offers considerable speedup in index construction, its search performance is inferior to standard HNSW due to degraded index quality. HNSW-SQ shows consistent search performance gains on most datasets, aligning with prior studies that optimizes search procedure using SQ \cite{LVQ}. However, HNSW-SQ provides limited indexing speedup, suggesting that a compact coding method suitable for search may not be ideal for index construction. This occurs because index construction involves an additional Neighbor Selection (NS) step and is therefore more complex than the search process. {In addition, different methods may exhibit varying search performance rankings regarding \textit{Recall} and \textit{ADR} for the same dataset, indicating their false positive results are obviously different. Notably, \texttt{Flash} demonstrates substantial advantages in retrieving results closer to the ground truth vectors.}

\begin{figure}
\vspace{-0.1cm}
  \setlength{\abovecaptionskip}{0cm}
  \setlength{\belowcaptionskip}{0cm}
  \centering
  \footnotesize
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/scalability/scalability_single_seg_laion.pdf}}{(a) LAION-30M}
  \hspace{0.15cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/scalability/scalability_single_seg_ssnpp.pdf}}{(b) SSNPP-50M}
  \newline
  \caption{Scalability over different data volumes.}
  \label{fig: scalability data volume}
  \vspace{-0.2cm}
\end{figure}

\subsection{Scalability}
\label{subsec: scalability}
We evaluate the scalability of HNSW-Flash regarding data volume and the number of data segments, benchmarking its performance against standard HNSW. Indexing times for both HNSW and HNSW-Flash are assessed on the LAION-100M and SSNPP-1B datasets. Figure \ref{fig: scalability data volume} presents indexing times across varying data volumes, with the data size within a single segment progressively increasing, while Figure \ref{fig: scalability segments} depicts indexing times for different segment counts, maintaining consistent data size per segment. For multi-segment evaluation, we accumulate the indexing times of each segment. The results demonstrate that HNSW-Flash significantly outperforms HNSW across all data volumes and segment counts. This highlights HNSW-Flash's superiority, particularly with larger datasets where HNSW incurs considerably higher indexing times. Consequently, HNSW-Flash achieves a notable reduction in absolute indexing times. In addition, HNSW-Flash can be seamlessly integrated into current distributed systems to expedite index construction within each segment, thereby providing cumulative acceleration.

\begin{figure}
% \vspace{-0.1cm}
  \setlength{\abovecaptionskip}{0cm}
  \setlength{\belowcaptionskip}{0cm}
  \centering
  \footnotesize
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/scalability/scalability_multi_seg_laion.pdf}}{(a) LAION-100M}
  \hspace{0.15cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/scalability/scalability_multi_seg_ssnpp.pdf}}{(b) SSNPP-1B}
  \newline
  \caption{Scalability over different segment counts.}
  \label{fig: scalability segments}
  \vspace{-0.2cm}
\end{figure}

\begin{figure}
\vspace{-0.2cm}
  \setlength{\abovecaptionskip}{0cm}
  \setlength{\belowcaptionskip}{0cm}
  \centering
  \footnotesize
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/generality/index_time_simd_laion10m.pdf}}{(a) LAION (10M)}
  \hspace{0.15cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/generality/index_time_simd_ssnpp10m.pdf}}{(b) SSNPP (10M)}
  \newline
  \caption{{Generality across different SIMD instruction sets.}}
  \label{fig: generality simd}
  \vspace{-0.2cm}
\end{figure}

\subsection{Generality}
\label{subsec: generality}
\subsubsection{{\textbf{SIMD Instructions}}}
\label{subsubsec: simd instructions}
{We integrate \texttt{Flash} into various SIMD instruction sets with differing register sizes to confirm its generality. We highlight \texttt{Flash} can be extended to 256-bit and 512-bit registers without altering its fundamental design principle. As shown in Figure \ref{fig: generality simd}, more advanced SIMD instructions with larger registers exhibit faster indexing processes. This is because SIMD instructions with larger registers can process more asymmetric distance tables (ADTs) per operation, resulting in more efficient arithmetic operations compared to those with smaller registers. Notably, the acceleration gained from larger registers is not strictly linear. Other factors, such as memory access patterns, also significantly impact indexing time. Moreover, the specific latency and throughput of instructions (such as register load times) vary across different SIMD instruction sets \cite{Intel-SIMD}, further affecting the overall speedup.}

\begin{figure}
\vspace{-0.2cm}
  \setlength{\abovecaptionskip}{0cm}
  \setlength{\belowcaptionskip}{0cm}
  \centering
  \footnotesize
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/generality/search_perf_vbase_flash_laion10m.pdf}}{(a) VBase}
  \hspace{0.15cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.26]{figures/generality/search_perf_adsampling_flash_laion10m.pdf}}{(b) ADSampling}
  \newline
  \caption{{Generality across different implementations.}}
  \label{fig: generality impl}
  \vspace{-0.2cm}
\end{figure}

\subsubsection{\textbf{{Optimized HNSW Implementations}}}
\label{subsubsec: opt hnsw impl}
{We apply \texttt{Flash} to optimized HNSW implementations, ADSampling \cite{ADSampling} and VBase \cite{zhang2023vbase}. These optimizations retain the standard HNSW construction process, enabling \texttt{Flash} to directly accelerate indexing, as shown in Figure \ref{fig: index time}. Figure \ref{fig: generality impl} presents the search performance of these implementations on LAION-10M before and after integrating \texttt{Flash}, demonstrating that \texttt{Flash} further improves search efficiency. This improvement stems from the fact that ADSampling’s enhancements to distance comparisons and VBase’s adjustments to the termination condition are orthogonal to \texttt{Flash}.}

\begin{figure}
% \vspace{-0.2cm}
  \setlength{\abovecaptionskip}{0cm}
  \setlength{\belowcaptionskip}{0cm}
  \centering
  \footnotesize
  \stackunder[0.5pt]{\includegraphics[scale=0.25]{figures/generality/combine_nsg_laion10m.pdf}}{(a) NSG}
  \hspace{0.15cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.25]{figures/generality/combine_taumg_laion10m.pdf}}{(b) $\tau$-MG}
  \newline
  \caption{{Generality across different graph algorithms.}}
  \label{fig: generality graph}
  \vspace{-0.2cm}
\end{figure}

\subsubsection{\textbf{{Graph Algorithms}}}
\label{subsubsec: graph algorithms}
{We apply \texttt{Flash} to two other representative graph algorithms, NSG \cite{NSG} and $\tau$-MG \cite{tau-MG}. Figure \ref{fig: generality graph} presents the indexing time and search performance on LAION-10M. The results indicate that \texttt{Flash} significantly accelerates the indexing process of NSG and $\tau$-MG while improving their search performance. These findings are consistent with those observed in HNSW. Both algorithms and HNSW share two key components—Candidate Acquisition (CA) and Neighbor Selection (NS)—in their indexing processes. Consequently, enhancing the CA and NS steps accelerates the indexing procedure across these graph algorithms.}

\subsection{Ablation Study}
\label{subsec: ablation}

\begin{table}[t]
\vspace{-0.2cm}
 \setstretch{0.9}
 \fontsize{7.5pt}{4mm}\selectfont
  \caption{L1 cache misses before and after optimization.}
  \vspace{-0.4cm}
  \label{tab:cache misses}
  \setlength{\tabcolsep}{.007\linewidth}{
  \begin{tabular}{l|l|l|l|l|l|l|l|l}
    \hline
     & SSNPP & LAION & COHE. & BIGC. & IMAGE. & DATAC. & ANTON & ARGIL. \\
    \hline
    \hline
     \textbf{w/o opt.} & 19.08\% & 24.20\% & 24.97\% & 25.09\% & 23.02\% & 24.03\% & 25.92\% & 25.98\% \\
    \hline
     \textbf{w. opt.} & 5.21\% & 7.90\% & 6.17\% & 6.72\% & 7.38\% & 7.05\% & 5.81\% & 4.86\% \\
    \hline
  \end{tabular}
  }\vspace{-0.3cm}
\end{table}

\subsubsection{\textbf{Memory Accesses}}
\label{subsubsec: memory access}
We utilize the \textit{perf} tool to record CPU hardware counters for data reads and cache hits. Table \ref{tab:cache misses} shows the L1 cache misses during index construction before and after our optimization across eight datasets. Each evaluation is conducted on one million samples per dataset, maintaining consistent indexing parameters. The results indicate a consistent reduction in cache misses across all eight datasets with \texttt{Flash}, demonstrating its efficacy in accelerating index construction by minimizing random memory accesses. Given that cache access is approximately 100 times faster than RAM access, even minor reductions in cache misses can significantly enhance the speed of distance computations \cite{ColemanSSS22}.

\subsubsection{\textbf{Arithmetic Operations}}

\begin{table}[t]
\vspace{-0.1cm}
 \setstretch{0.9}
 \fontsize{7.5pt}{4mm}\selectfont
  \caption{Indexing time without and with SIMD optimization.}
  \vspace{-0.4cm}
  \label{tab:SIMD opt}
  \setlength{\tabcolsep}{.0045\linewidth}{
  \begin{tabular}{l|l|l|l|l|l|l|l|l}
    \hline
     & SSNPP & LAION & COHE. & BIGC. & IMAGE. & DATAC. & ANTON & ARGIL. \\
    \hline
    \hline
     \textbf{w/o opt. (s)} & 233 & 154 & 270 & 214 & 88 & 154 & 157 & 140 \\
    \hline
     \textbf{w. opt. (s)} & 129 & 131 & 164 & 147 & 84 & 135 & 138 & 111 \\
    \hline
  \end{tabular}
  }\vspace{-0.2cm}
\end{table}

To assess the impact of SIMD optimization, we compare indexing times with and without this option in Table \ref{tab:SIMD opt}, using the same dataset settings as described in Section \ref{subsubsec: memory access}. The results indicate that SIMD optimization can reduce indexing time by up to 45\%, highlighting its effectiveness in accelerating index construction through efficient arithmetic operations. Notably, the indexing times in Table \ref{tab:SIMD opt} include vector coding time, which constitutes approximately 10\% of the total indexing time; however, SIMD optimization does not affect the coding time.

\begin{table}[t]
% \vspace{-0.1cm}
 \setstretch{0.9}
 \fontsize{7.5pt}{4mm}\selectfont
  \caption{Coding time (CT) and total indexing time (TIT).}
  \vspace{-0.4cm}
  \label{tab:coding time}
  \setlength{\tabcolsep}{.007\linewidth}{
  \begin{tabular}{l|l|l|l|l|l|l|l|l}
    \hline
     & SSNPP & LAION & COHE. & BIGC. & IMAGE. & DATAC. & ANTON & ARGIL. \\
    \hline
    \hline
     \textbf{CT (h)} & 0.016 & 0.049 & 0.049 & 0.048 & 0.060 & 0.087 & 0.165 & 0.164 \\
    \hline
     \textbf{TIT (h)} & 0.599 & 0.542 & 0.668 & 0.619 & 0.487 & 0.730 & 1.035 & 1.083 \\
    \hline
  \end{tabular}
  }\vspace{-0.3cm}
\end{table}

\begin{figure}
  \setlength{\abovecaptionskip}{0cm}
  \setlength{\belowcaptionskip}{-0.4cm}
  \centering
  \footnotesize
  \stackunder[0.5pt]{\includegraphics[scale=0.33]{figures/illustration/profile-indexing-ours-laion.pdf}}{(a) LAION-1M ($D=768$)}
  \hspace{0.15cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.32]{figures/illustration/profile-indexing-ours-argilla.pdf}}{(b) ARGILLA-1M ($D=1024$)}
  \newline
  \caption{Profiling of graph index construction time in HNSW-Flash. The distance computation time (\textit{B}+\textit{C}) consists of memory accesses (\textit{B}) and arithmetic operations (\textit{C}). \textit{A} is the time of other tasks, such as data structure maintenance.}
  \label{fig: graph construction time profile}
  \vspace{-0.1cm}
\end{figure}

\subsubsection{\textbf{Profiling of indexing time}}
Table \ref{tab:coding time} presents the coding time (CT) for \texttt{Flash} alongside the total indexing time (TIT) for HNSW-Flash, with TIT encompassing both CT and the graph index construction time (GIT). Data scales for all datasets align with those in Figure \ref{fig: index time}.
The results show that CT constitutes only 10\% of TIT, demonstrating that \texttt{Flash} requires little processing time. We further profile GIT using the \textit{perf} tool in Figure \ref{fig: graph construction time profile}. The results indicate that distance computation occupies a small fraction of GIT for HNSW-Flash. This suggests the primary bottlenecks associated with memory accesses and arithmetic operations in HNSW have been removed through the integration of \texttt{Flash}.

\subsection{Parameter Sensitivity}
\label{subsec: param sensitivity}

\begin{figure}
  \setlength{\abovecaptionskip}{0cm}
  \setlength{\belowcaptionskip}{0cm}
  \centering
  \footnotesize
  \stackunder[0.5pt]{\includegraphics[scale=0.2]{figures/params/flash_dF_laion1m.pdf}}{(a) LAION-1M ($M_{F}=16$)}
  \hspace{0.15cm}
  \stackunder[0.5pt]{\includegraphics[scale=0.2]{figures/params/flash_MF_laion1m.pdf}}{(b) LAION-1M ($d_{F}=64$)}
  \newline
  \caption{Effect of parameters within \texttt{Flash}.}
  \label{fig: HNSW-Flash param}
  \vspace{-0.3cm}
\end{figure}

HNSW-Flash has two adjustable parameters to balance construction efficiency and index quality: the dimensions of principal components ($d_F$) and the number of subspaces ($M_F$). Other parameters, like bits per subspace ($L_F$) are fixed to align with index features and hardware constraints.
Figure \ref{fig: HNSW-Flash param} illustrates indexing time and search accuracy across varying $d_F$ and $M_F$, using the recall rate at a given latency as a measure of index quality. In Figure \ref{fig: HNSW-Flash param}(a), with $M_F$ fixed at 16, index quality improves with increasing $d_F$ initially but subsequently declines beyond a certain threshold. Correspondingly, indexing time decreases initially, then rises after reaching a critical point. This phenomenon arises from potential information loss at lower dimensions and redundancy at higher dimensions, given the fixed $L_F$. Notably, the optimal points for indexing time and search accuracy occur at different $d_F$, reflecting the distinct sensitivities of index construction and search procedures to information content. While the search focuses on nearest neighbors, index construction requires navigable neighbors, even if more distant \cite{HNSW,NSG}.
In Figure \ref{fig: HNSW-Flash param}(b), with $d_F$ set to 64, increasing $M_F$ extends indexing time. The search accuracy improves initially but later declines due to increased computational overhead and additional register loads.