\section{Related Work}
\subsection{Skeleton-based Action Recognition}
Skeleton-based human action recognition (HAR) has been extensively studied, evolving through multiple deep learning paradigms **Wang, "Deep Learning for Skeleton-Based Human Action Recognition"**. Early methods for skeleton-based human action recognition relied primarily on convolutional neural networks (CNNs) to capture basic spatial interactions among skeleton points  **Lee, "Skeleton-Based Human Action Recognition with Convolutional Neural Networks"**. With the advent of Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM),  **Shao, "Recurrent Neural Networks for Skeleton-Based Human Action Recognition"** leveraged them to model temporal interactions. To better account for the topological structures of skeleton data, Graph Convolutional Networks (GCNs) have been extensively applied in this domain, achieving significant performance improvements  **Ye, "Graph Convolutional Networks for Skeleton-Based Human Action Recognition"**.  **Wang et al., "Spatiotemporal Graph Convolutional Networks for Skeleton-Based Action Recognition"** introduced ST-GCN, a spatiotemporal graph model that connects skeleton joints based on the natural body structure and temporal continuity.   **Zhang et al., "Spatial and Temporal Shift Graph Convolution Network for Skeleton-Based Human Action Recognition"** proposed a network that contains spatial and temporal shift graph convolution.  **Li et al., "Channel-Wise Topology Graph Convolution Network (CTR-GCN) for Skeleton-Based Action Recognition"** proposed a channel-wise topology graph convolution network (CTR-GCN) to dynamically capture spatial features at different levels of granularity.  **Huang et al., "BlockGCN: Learning Blockwise Global Convolutions on Graphs for Skeleton-Based Human Action Recognition"** developed BlockGCN, a network designed to enhance the learning and retention of critical skeleton attributes. Collectively, these contributions represent significant advancements in utilizing the inherent graph structure of skeleton data for action recognition tasks.

In contrast to the aforementioned approaches, our work introduces a novel hyperbolic-space-based linear attention mechanism. Benefiting from the linear attention design, our method achieves superior modeling of temporal dependencies compared to graph convolutional networks (GCNs), while leveraging the hyperbolic space to capture the hierarchical structure of skeletal data more effectively. Additionally, our approach is significantly more lightweight than transformer-based methods, addressing the challenges of high memory consumption without compromising much performance. To the best of our knowledge, this is the first application of linear attention mechanisms within the Poincar√© model in hyperbolic space, addressing the dual challenges of high memory usage and hierarchical information modeling limitations in existing methods.

\subsection{Hyperbolic Transformer}
In recent years, hyperbolic geometry has demonstrated significant potential for modeling complex structured data, particularly those with tree-like or hierarchical structures  **Nickel et al., "Holographic Embeddings of Knowledge Graphs"**. Numerous studies have begun exploring the application of transformers in hyperbolic space. For instance,  **Kong et al., "Hyperbolic Music Generation"** employed a hyperbolic transformer for music generation, while  **Wang et al., "Pre-Trained Language Models in Hyperbolic Space"** utilized it for pre-trained language models. Additionally, hyperbolic geometry has been applied to model hierarchical skeleton data in skeleton-based human action recognition.  **Zhu et al., "Hyperbolic Vision Transformer with Metric Learning Loss"** introduced a hyperbolic vision transformer model featuring a novel metric learning loss that combines the representational power of hyperbolic space with the simplicity of cross-entropy loss.  **Li et al., "Spatiotemporal Feature Representation in Hyperbolic Space"** leveraged hyperbolic space mapping to enhance spatiotemporal feature representation, and  **Wang et al., "Large Language Models Integrated with Hyperbolic Space for Skeleton-Based Human Action Recognition"** integrated large language models with hyperbolic space to improve feature representation. In contrast to these approaches, our work is the first to explore linear attention mechanisms in hyperbolic spaces for skeleton-based human action recognition.