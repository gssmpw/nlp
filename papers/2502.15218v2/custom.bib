@article{gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{mlm_survey,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and others},
  journal={National Science Review},
  pages={nwae403},
  year={2024},
  publisher={Oxford University Press}
}

@article{slm_survey1,
  title={Recent Advances in Speech Language Models: A Survey},
  author={Cui, Wenqian and others},
  journal={arXiv preprint arXiv:2410.03751},
  year={2024}
}

@article{slm_survey2,
  title={A Survey on Speech Large Language Models},
  author={Peng, Jing and others},
  journal={arXiv preprint arXiv:2410.18908},
  year={2024}
}

@article{vlm_survey,
  title={Vision-language models for vision tasks: A survey},
  author={Zhang, Jingyi and others},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@article{valle,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Wang, Chengyi and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}

@article{speartts,
  title={Speak, read and prompt: High-fidelity text-to-speech with minimal supervision},
  author={Kharitonov, Eugene and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={1703--1718},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~â€¦}
}

@inproceedings{
uniaudio,
title={UniAudio: Towards Universal Audio Generation with Large Language Models},
author={Dongchao Yang and others},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}

@article{instruct_following,
  title={Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data},
  author={Lu, Ke-Han and others},
  journal={arXiv preprint arXiv:2409.20007},
  year={2024}
}

@article{moshi,
  title={Moshi: a speech-text foundation model for real-time dialogue},
  author={D{\'e}fossez, Alexandre and others},
  journal={arXiv preprint arXiv:2410.00037},
  year={2024}
}

@article{mini_omni,
  title={Mini-omni: Language models can hear, talk while thinking in streaming},
  author={Xie, Zhifei and Wu, Changqiao},
  journal={arXiv preprint arXiv:2408.16725},
  year={2024}
}

@article{scaling,
  title={Scaling Properties of Speech Language Models},
  author={Cuervo, Santiago and Marxer, Ricard},
  journal={arXiv preprint arXiv:2404.00685},
  year={2024}
}

@inproceedings{
uniaudio1.5,
title={UniAudio 1.5: Large Language Model-Driven Audio Codec is A Few-Shot Audio Task Learner},
author={Dongchao Yang and others},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
}

@inproceedings{voxtlm,
  title={VoxtLM: Unified Decoder-Only Models for Consolidating Speech Recognition, Synthesis and Speech, Text Continuation Tasks},
  author={Maiti, Soumi and others},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={13326--13330},
  year={2024},
  organization={IEEE}
}

@inproceedings{deepspeed,
  title={Zero: Memory optimizations toward training trillion parameter models},
  author={Rajbhandari, Samyam and others},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--16},
  year={2020},
  organization={IEEE}
}

@article{flashattention,
  title={Flashattention-2: Faster attention with better parallelism and work partitioning},
  author={Dao, Tri},
  journal={arXiv preprint arXiv:2307.08691},
  year={2023}
}

@misc{fish-speech-v1.4,
      title={Fish-Speech: Leveraging Large Language Models for Advanced Multilingual Text-to-Speech Synthesis},
      author={Shijia Liao and others},
      year={2024},
      eprint={2411.01156},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
}

@misc{glmvoice,
      title={GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot}, 
      author={Aohan Zeng and others},
      year={2024},
      eprint={2412.02612},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@inproceedings{amphion,
    author={Zhang, Xueyao and others},
    title={Amphion: An Open-Source Audio, Music and Speech Generation Toolkit},
    booktitle={{IEEE} Spoken Language Technology Workshop, {SLT} 2024},
    year={2024}
}

@article{vita,
  title={Vita: Towards open-source interactive omni multimodal llm},
  author={Fu, Chaoyou and others},
  journal={arXiv preprint arXiv:2408.05211},
  year={2024}
}

@article{gpt4o,
  title={Gpt-4o system card},
  author={Hurst, Aaron and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}

@inproceedings{espnet,
  author={Shinji Watanabe and others},
  title={{ESPnet}: End-to-End Speech Processing Toolkit},
  year={2018},
  booktitle={Proceedings of Interspeech},
  pages={2207--2211},
  doi={10.21437/Interspeech.2018-1456},
}

@article{huang2024opencoder,
  title={Opencoder: The open cookbook for top-tier code large language models},
  author={Huang, Siming and Cheng, Tianhao and Liu, Jason Klein and Hao, Jiaran and Song, Liuyihan and Xu, Yang and Yang, J and Liu, JH and Zhang, Chenchen and Chai, Linzheng and others},
  journal={arXiv preprint arXiv:2411.04905},
  year={2024}
}

@misc{speechbrain,
  title={{SpeechBrain}: A General-Purpose Speech Toolkit},
  author={Mirco Ravanelli and others},
  year={2021},
  eprint={2106.04624},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  note={arXiv:2106.04624}
}

@article{nemo,
  title={Nemo: a toolkit for building ai applications using neural modules},
  author={Kuchaiev, Oleksii and others},
  journal={arXiv preprint arXiv:1909.09577},
  year={2019}
}

@inproceedings{fairseq,
    title = "fairseq: A Fast, Extensible Toolkit for Sequence Modeling",
    author = "Ott, Myle and others",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N19-4009",
    pages = "48--53",
}

@article{llm_scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and others},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and others},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{encodec,
  title={High fidelity neural audio compression},
  author={D{\'e}fossez, Alexandre and others},
  journal={arXiv preprint arXiv:2210.13438},
  year={2022}
}

@article{soundstream,
  title={Soundstream: An end-to-end neural audio codec},
  author={Zeghidour, Neil and others},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={495--507},
  year={2021},
  publisher={IEEE}
}

@article{megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and others},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@inproceedings{whisper,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and others},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@inproceedings{owsm3.1,
  title     = {OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer},
  author    = {Yifan Peng and others},
  year      = {2024},
  booktitle = {Interspeech 2024},
  pages     = {352--356},
  issn      = {2958-1796},
}

@inproceedings{s3prl,
  author={Shu-Wen Yang and others},
  title={{SUPERB: Speech Processing Universal PERformance Benchmark}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={1194--1198},
}

@inproceedings{llamafactory,
  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
  author={Yaowei Zheng and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  address={Bangkok, Thailand},
  publisher={Association for Computational Linguistics},
  year={2024},
}

@article{musicgen,
  title={Simple and controllable music generation},
  author={Copet, Jade and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{espnet_codec,
  title={Espnet-codec: Comprehensive training and evaluation of neural codecs for audio, music, and speech},
  author={Shi, Jiatong and others},
  journal={arXiv preprint arXiv:2409.15897},
  year={2024}
}

@article{dpo,
  title={Preference Alignment Improves Language Model-Based TTS},
  author={Tian, Jinchuan and others},
  journal={arXiv preprint arXiv:2409.12403},
  year={2024}
}

@article{dac,
  title={High-fidelity audio compression with improved rvqgan},
  author={Kumar, Rithesh and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{xeus,
  title={Towards robust speech representation learning for thousands of languages},
  author={Chen, William and others},
  journal={arXiv preprint arXiv:2407.00837},
  year={2024}
}

@inproceedings{muskits,
  title={Muskits-ESPnet: A Comprehensive Toolkit for Singing Voice Synthesis in New Paradigm},
  author={Wu, Yuning and others},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={11279--11281},
  year={2024}
}

@inproceedings{
avhubert,
title={Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction},
author={Bowen Shi and others},
booktitle={International Conference on Learning Representations},
year={2022},
}

@article{swuggy,
  title={The zero resource speech benchmark 2021: Metrics and baselines for unsupervised spoken language modeling},
  author={Nguyen, Tu Anh and others},
  journal={arXiv preprint arXiv:2011.11588},
  year={2020}
}

@article{mmlu,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and others},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{arc,
  title={Think you have solved question answering? try arc, the ai2 reasoning challenge},
  author={Clark, Peter and others},
  journal={arXiv preprint arXiv:1803.05457},
  year={2018}
}

@article{hellaswag,
  title={Hellaswag: Can a machine really finish your sentence?},
  author={Zellers, Rowan and others},
  journal={arXiv preprint arXiv:1905.07830},
  year={2019}
}

@inproceedings{triviaqa,
    title = "{T}rivia{QA}: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    author = "Joshi, Mandar  and others",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    pages = "1601--1611",
}

@article{openbookqa,
  title={Can a suit of armor conduct electricity? a new dataset for open book question answering},
  author={Mihaylov, Todor and others},
  journal={arXiv preprint arXiv:1809.02789},
  year={2018}
}

@article{humaneval,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@misc{chattss2024,
  author       = {2Noise},
  title        = {ChatTTS: A generative speech model for daily dialogue.},
  year         = {2024},
  url          = {https://github.com/2noise/ChatTTS},
  note         = {Available at \url{https://github.com/2noise/ChatTTS}}
}

@article{du2024cosyvoice,
  title={Cosyvoice: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens},
  author={Du, Zhihao and others},
  journal={arXiv preprint arXiv:2407.05407},
  year={2024}
}

@misc{emotivoice2024,
  author       = {NetEase Youdao},
  title        = {EmotiVoice: a Multi-Voice and Prompt-Controlled TTS Engine},
  year         = {2024},
  url          = {https://github.com/netease-youdao/EmotiVoice},
  note         = {Available at \url{https://github.com/netease-youdao/EmotiVoice}}
}

@misc{zhao2024melo,
  author={Zhao, Wenliang and others},
  title = {MeloTTS: High-quality Multi-lingual Multi-accent Text-to-Speech},
  url = {https://github.com/myshell-ai/MeloTTS},
  year = {2023}
}

@misc{lacombe-etal-2024-parler-tts,
  author = {Yoach Lacombe and others},
  title = {Parler-TTS},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository}
}

@misc{whisperspeech2024,
  author       = {Collabora},
  title        = {WhisperSpeech: A Speech Processing Toolkit},
  year         = {2024},
  url          = {https://github.com/collabora/WhisperSpeech},
  note         = {Available at \url{https://github.com/collabora/WhisperSpeech}}
}

@article{zhang2023speak,
  title={Speak foreign languages with your own voice: Cross-lingual neural codec language modeling},
  author={Zhang, Ziqiang and others},
  journal={arXiv preprint arXiv:2303.03926},
  year={2023}
}

@article{espnet_tts,
  title={ESPnet2-TTS: Extending the edge of tts research},
  author={Hayashi, Tomoki and others},
  journal={arXiv preprint arXiv:2110.07840},
  year={2021}
}

@article{valle2,
  title={VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers},
  author={Chen, Sanyuan and others},
  journal={arXiv preprint arXiv:2406.05370},
  year={2024}
}

@inproceedings{librispeech,
  title={Librispeech: an {ASR} corpus based on public domain audio books},
  author={Panayotov, Vassil and others},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

@inproceedings{mls,
  title={{MLS}: A large-scale multilingual dataset for speech research},
  author={Pratap, Vineel and others},
  booktitle={Interspeech},
  year={2020}
}

@inproceedings{wsj,
  title={{The design for the Wall Street Journal-based CSR corpus}},
  author={Paul, Douglas B and Baker, Janet},
  booktitle={Proc. Workshop on Speech and Natural Language},
  year={1992}
}

@inproceedings{FLEURS,
  title={{FLEURS: Few-Shot Learning Evaluation of Universal Representations of Speech}},
  author={Alexis Conneau and others},
  booktitle={SLT},
  year={2022},
}

@inproceedings{tedlium3,
  title={{TED-LIUM} 3: Twice as much data and corpus repartition for experiments on speaker adaptation},
  author={Hernandez, Fran{\c{c}}ois and others},
  booktitle={Speech \& Computer},
  pages={198--208},
  year={2018},
}

@article{llamaomni,
  title={Llama-omni: Seamless speech interaction with large language models},
  author={Fang, Qingkai and Guo, Shoutao and Zhou, Yan and Ma, Zhengrui and Zhang, Shaolei and Feng, Yang},
  journal={arXiv preprint arXiv:2409.06666},
  year={2024}
}

@article{mfu,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@inproceedings{vllm,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and others},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@inproceedings{owsm3.2,
  title     = {On the Effects of Heterogeneous Data Sources on Speech-to-Text Foundation Models},
  author    = {Jinchuan Tian and others},
  year      = {2024},
  booktitle = {Interspeech 2024},
  pages     = {3959--3963},
}

@article{he2024emilia,
  title={Emilia: An extensive, multilingual, and diverse speech dataset for large-scale speech generation},
  author={He, Haorui and others},
  journal={arXiv preprint arXiv:2407.05361},
  year={2024}
}

@INPROCEEDINGS{yodas,
  author={Li, Xinjian and others},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={Yodas: Youtube-Oriented Dataset for Audio and Speech}, 
  year={2023},
  volume={},
  number={},
  pages={1-8}
}