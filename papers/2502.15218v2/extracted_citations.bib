@inproceedings{amphion,
    author={Zhang, Xueyao and others},
    title={Amphion: An Open-Source Audio, Music and Speech Generation Toolkit},
    booktitle={{IEEE} Spoken Language Technology Workshop, {SLT} 2024},
    year={2024}
}

@inproceedings{deepspeed,
  title={Zero: Memory optimizations toward training trillion parameter models},
  author={Rajbhandari, Samyam and others},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--16},
  year={2020},
  organization={IEEE}
}

@inproceedings{espnet,
  author={Shinji Watanabe and others},
  title={{ESPnet}: End-to-End Speech Processing Toolkit},
  year={2018},
  booktitle={Proceedings of Interspeech},
  pages={2207--2211},
  doi={10.21437/Interspeech.2018-1456},
}

@inproceedings{fairseq,
    title = "fairseq: A Fast, Extensible Toolkit for Sequence Modeling",
    author = "Ott, Myle and others",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N19-4009",
    pages = "48--53",
}

@article{flashattention,
  title={Flashattention-2: Faster attention with better parallelism and work partitioning},
  author={Dao, Tri},
  journal={arXiv preprint arXiv:2307.08691},
  year={2023}
}

@misc{glmvoice,
      title={GLM-4-Voice: Towards Intelligent and Human-Like End-to-End Spoken Chatbot}, 
      author={Aohan Zeng and others},
      year={2024},
      eprint={2412.02612},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
}

@inproceedings{llamafactory,
  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
  author={Yaowei Zheng and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  address={Bangkok, Thailand},
  publisher={Association for Computational Linguistics},
  year={2024},
}

@article{megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and others},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@article{mini_omni,
  title={Mini-omni: Language models can hear, talk while thinking in streaming},
  author={Xie, Zhifei and Wu, Changqiao},
  journal={arXiv preprint arXiv:2408.16725},
  year={2024}
}

@article{moshi,
  title={Moshi: a speech-text foundation model for real-time dialogue},
  author={D{\'e}fossez, Alexandre and others},
  journal={arXiv preprint arXiv:2410.00037},
  year={2024}
}

@article{nemo,
  title={Nemo: a toolkit for building ai applications using neural modules},
  author={Kuchaiev, Oleksii and others},
  journal={arXiv preprint arXiv:1909.09577},
  year={2019}
}

@inproceedings{s3prl,
  author={Shu-Wen Yang and others},
  title={{SUPERB: Speech Processing Universal PERformance Benchmark}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={1194--1198},
}

@misc{speechbrain,
  title={{SpeechBrain}: A General-Purpose Speech Toolkit},
  author={Mirco Ravanelli and others},
  year={2021},
  eprint={2106.04624},
  archivePrefix={arXiv},
  primaryClass={eess.AS},
  note={arXiv:2106.04624}
}

@inproceedings{voxtlm,
  title={VoxtLM: Unified Decoder-Only Models for Consolidating Speech Recognition, Synthesis and Speech, Text Continuation Tasks},
  author={Maiti, Soumi and others},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={13326--13330},
  year={2024},
  organization={IEEE}
}

