\section{Evaluation}

This section provides an evaluation of the proposed IDS. We begin by introducing the simulation environment used to model an EC and collect data for assessment. Next, we outline various attack scenarios, followed by a description of the model's architecture, its parameters, and the feature vector. Finally, a detailed assessment of the detection performance for the investigated attacks is presented.

\subsection{Simulation Environment}
%While several simulators are available in the literature, as discussed in Section~\ref{section:related_work}, they present limitations that hinder their use for our goal. 

\begin{figure}[htbp!] 
\centering
\includegraphics[width=25cm,height=12cm,keepaspectratio, angle=90]{figures/model2.png}
\caption{Simulink model for a small EC.}
\label{fig:model}
\end{figure}

We employ simulations to gather data for training and testing our proposed detection system as it is not possible to access data from live and real-world systems due to data privacy and other regulations. The model is implemented in Matlab/Simulink  and builds on top of the model available at~\cite{ec-model}. It illustrates the behavior of a small-scale EC over a 24-hour period. An overall scheme is shown in Figure~\ref{fig:model}. The model represents an EC designed to simulate energy generation, storage, consumption, and control. It is connected to single-phase electrical grid that serves as the primary power source via a transformer, which reduces the voltage from 6.6 kV to 200 V. The EC has two local generators: a solar power generation system and a storage battery. The solar power system generates renewable energy with output varying depending on sunlight, peaking at 5 kW between 14:00 and 15:00 while producing no power from 20:00 to 04:00. To represent variable generation due to weather conditions such a cloud cover, the solar system only generates lower power from 11.00 to 12.00. The storage battery acts as a buffer, storing excess power when generation surpasses consumption and supplying power during shortages. The battery is managed by a battery controller, which ensures efficient power distribution. The controller ensures that the batter absorbs surplus power when energy generation exceeds the EC's needs and provides additional power during shortages. Two households with controllable and flexible loads inside are connected to the EC. Each household consumes a maximum of 2.5 kW of power with variations throughout the day based on typical consumption patterns. Peak consumption occurs at 09:00 (around 4 kW), as well as at 19:00 and 22:00 (around 5 kW). Both the solar power system and storage battery, being DC power sources, rely on converters to produce single-phase current suitable for the grid.



The control strategy for the EC is designed to minimize dependence on the main power grid, ensuring that the combined power from solar generation and the storage battery meets the households' demands whenever possible. The battery controller operates during specific periods to achieve this. From 00:00 to 12:00 and again from 18:00 to 24:00, the battery controller actively manages the battery's charge and discharge to ensure that the active power flowing into the system from the transformer is approximately zero. During this period, the storage battery supplies power during shortages and absorbs excess energy when available.

Between 12:00 and 18:00, the battery controller is inactive. During this time, the battery’s State of Charge (SOC) remains constant as it neither charges nor discharges. Any power shortages during this period are supplied by the grid, while any surplus power is fed back. In summary, the households in the model receive electrical power as their primary input to meet their energy demands. The output from the households is the electrical load they present to the EC. The model effectively demonstrates the behavior of a small-scale EC, showcasing how it balances energy generation, consumption, and storage while maintaining reliable operation. Figure~\ref{fig:ec-plot} shows plots for normal operation of the EC. 

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/normal-plot.png}
    %.png[width=1.0\textwidth]{figures/comparison-detection-performance.eps}
    \caption{Plots for normal operation of the EC.}
    \centering
    \label{fig:ec-plot}
\end{figure}

    
\subsection{Attack Scenarios}
% As the grid has less inertia and higher variability in energy production, it is more vulnerable to changes in demand and bidirectional energy flow, which refers to the ability of specific FERs, such as batteries, to both consume power from the grid (charging) and supply energy back to the grid (discharging). Adversaries could exploit this vulnerability by manipulating FERs to increase their demand or inject energy into the grid. This vulnerability is further exaggerated by the growing number of remotely controlled flexible resources integrated into the power grid. The ability to remotely control these devices introduces the potential for attackers to execute manipulation attacks on a scale large enough to impact the stability of the power grid. As more of these devices are connected to the grid, the risk and impact of a coordinated attack increases, making it crucial to assess and develop robust cybersecurity and defense mechanisms. 

The aim of the proposed IDS is to detect anomalies that indicate disruption or manipulation of the normal operation of an EC as described above. In this context, we are interested in detecting the effects of attacks rather than their actual mechanisms. The focus is on detecting threats that can manipulate power generation, its storage, and the demand of flexible loads or assets. We consider that the adversaries can exploit vulnerabilities to launch many common attacks including FDI and DoS attacks to control and manipulate the growing number of remotely controlled flexible assets in ECs, potentially affecting stability of the power grid. For instance, an adversary can intercept communication data or signals between assets and manipulate them, in order to control what the receiver sees. In the context of an EC, an adversary can modify the control signals exchanged between the community manager and generators such as storage batteries. By injecting malicious data, power set-points could be modified allowing the attackers to mislead assets into making decisions based on falsified information, potentially leading to incorrect decisions and resulting in attacks such as power injection or absorption from the grid.

On the other hand, adversaries can also target the demand side to launch load altering attacks (LA). These attacks manipulate the demand of remotely controlled flexible loads such as electrical heaters and other smart appliances that have the potential to consume large amounts of energy, in order to disrupt the balance between power supply and demand. Increasing or decreasing power consumption of a single asset may not be critical in isolation, but if an attacker can manipulate demand of multiple assets, which is a real possibility in ECs, grid stability could be in danger. The following four attack scenarios form the basis of our investigation.

\begin{itemize}
    \item \textbf{Power Injection (PI)}: An attacker increases the power supplied to the electrical grid by unexpectedly discharging controlled flexible assets, such as batteries.%, causing the grid frequency in the grid to increase abruptly. 
    \item \textbf{Power Absorption (PA)}: An attacker decreases the power supplied to the electrical grid by unexpectedly charging controlled flexible assets, such as batteries.%, leading to reduced grid frequency abruptly. 
    \item \textbf{Load Increase (LI)}: An attacker increases the energy demand of controlled assets, resulting in an imbalance between generation and consumption.%, leading to reduced grid frequency.
    \item \textbf{Load Reduction (LR)}: An attacker decreases the energy demand of controlled resources, resulting in an imbalance between generation and consumption.%, leading to increased grid frequency. 
\end{itemize}

\subsection{Detection Model Architecture}
%\subsubsection{Autoencoder Architecture}

% we employ a LSTM with X layers (32 and 64 filters of size 3x3), followed by X activations. The output is then flattened and passed through X fully connected layers (600 and 120 units) with a X% dropout.

%We implement an autoencoder based on Long Short-Term Memory (LSTM) networks for time series anomaly detection in python using Keras API. The encoder consists of two stacked LSTM layers. The first LSTM layer comprises 128 units and processes input sequences of length \textit{TIME\_STEPS} (10 in our case) with a feature dimension equal to the number of variables in the dataset. We set option \textit{return\_sequences} set to True, which captures temporal dependencies in the input sequences. The second LSTM layer has 64 units and does not return sequences, effectively capturing a compressed latent representation of the input. 

%To reconstruct the original sequence, the decoder begins with a \textit{RepeatVector} layer, which replicates the latent representation. This is followed by two LSTM layers mirroring the encoder’s structure but in reverse order: a 64-unit LSTM layer that returns sequences, followed by a 128-unit LSTM layer that also returns sequences. Finally, a \textit{TimeDistributed} dense layer with a linear activation function is applied to generate the output sequence, ensuring that each time step has the same dimensionality as the input. 

We implement an autoencoder using Long Short-Term Memory (LSTM) networks for time series anomaly detection in Python using Keras API. The model consists of two main parts: an \textbf{encoder} and a \textbf{decoder}.  

\subsection*{Encoder}  
The encoder is composed of two stacked LSTM layers:  
\begin{itemize}  
    \item The first LSTM layer has \textit{128 units} and processes input sequences of length \textit{TIME\_STEPS} (10 in our case). The feature dimension corresponds to the number of variables in the dataset. We set \texttt{return\_sequences=True} to preserve temporal dependencies in the data.  
    \item The second LSTM layer has \textit{64 units} and does not return sequences, meaning it compresses the input into a lower-dimensional latent representation.  
\end{itemize}  

\subsection*{Decoder}  
To reconstruct the original sequence, the decoder follows these steps:  
\begin{enumerate}  
    \item A \textit{RepeatVector} layer replicates the latent representation across the required time steps.  
    \item Two LSTM layers mirror the encoder’s structure but in reverse:  
    \begin{itemize}  
        \item A \textit{64-unit LSTM layer} that returns sequences.  
        \item A \textit{128-unit LSTM layer} that also returns sequences.  
    \end{itemize}  
    \item Finally, a \textit{TimeDistributed Dense layer} with a linear activation function generates the output sequence, ensuring each time step has the same dimensionality as the input.  
\end{enumerate}  


\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/training-loss.png}
    \caption{Training Loss}
    \centering
    \label{fig:training1}
\end{figure}

The model is trained using the \textit{Adam} optimizer with a \textit{mean squared error} (MSE) loss function, optimizing its ability to reconstruct input sequences. Based on the observed losses over epochs during training, as shown in Figure~\ref{fig:training1}, hyperparameters are determined. Epochs are set to 50 with a batch size of 128, using a 90-10\% train-validation split. An early stopping mechanism is implemented to prevent overfitting, monitoring the validation loss and halting training if no improvement is observed for five consecutive epochs. Anomalies are detected based on reconstruction error, calculated as the mean absolute error (MAE) between input and reconstructed sequences. Since the model processes time series sequences in a sequential manner, the total count of trainable parameters, including all LSTM weight matrices, bias terms, and the dense layer, results in 256,270 trainable parameters. 


%# Define the model
%model = keras.Sequential([
%    layers.LSTM(128, input_shape=(TIME_STEPS, df_training_value.shape[1]), return_sequences=True),
%    layers.LSTM(64, return_sequences=False),
%    layers.RepeatVector(TIME_STEPS),
%    layers.LSTM(64, return_sequences=True),
%    layers.LSTM(128, return_sequences=True),
%    layers.TimeDistributed(layers.Dense(df_training_value.shape[1]))
%])
%model.compile(optimizer='adam', loss='mse')
%model.summary()

%#Train the model. We are using `x_train` as both the input and the target since this is a reconstruction model.

%history = model.fit(
%    x_train,
%    x_train,
%    epochs=50,
%    batch_size=128,
%    validation_split=0.1,
%    callbacks=[
%        keras.callbacks.EarlyStopping(monitor="val_loss", patience=5, mode="min")
%    ],
%)

\subsection{Data}

Table~\ref{tab:data} represents the measures extracted from the simulated model. Together, these measures form the feature vector $X_t$ extracted at time $t$ and are used in training and testing of the detection model. The dataset used for training consists of simulating the EC for 24 hours of typical (normal) operating conditions. %In total, the training dataset has 1839 samples with 14 features. 
However, as LSTM autoencoders can benefit from learning how features evolve over time leveraging their memory capabilities to differentiate between normal variations and genuine anomalies, we create sequences of input data to capture the temporal dependencies in the data. The data is structured into overlapping sequences of 10 time steps.%, resulting in a final training input shape of (1830, 10, 14), where 1830 is the number of valid sequences, 10 is the sequence length, and 14 represents the number of features. 
 The test dataset is separately collected and contains time series data structured into sequences of 10 time steps.


%Number of training samples: 1839
%Number of trainable parameters: 256, 270
%Training input shape (1830, 10, 14)
%Test input shape (1709, 10, 14)

\begin{table}[htbp!] 
\centering
\caption{Features used for training and detection.}
\begin{tabular}{| p{0.2\linewidth} | p{0.2\linewidth} | p{0.2\linewidth} |}
\hline
\textbf{Feature vector} & \textbf{Measurement} & \textbf{Description}
\\ \hline
$X_1$ & $V_{\text{sec}}$ & Voltage secondary
\\ \hline
$X_2$ & $V_{\text{PV}}$ & Voltage solar
\\ \hline
$X_3$ & $V_{\text{L1}}$ & Voltage load 1
\\ \hline
$X_4$ & $V_{\text{L2}}$ & Voltage load 2
\\ \hline
$X_5$ & $I_{\text{sec}}$ & Current secondary
\\ \hline
$X_6$ & $I_{\text{PV}}$ & Current solar
\\ \hline
$X_7$ & $I_{\text{L1}}$ & Current load 1
\\ \hline
$X_8$ & $I_{\text{L2}}$ & Current load 2
\\ \hline
$X_9$ & $I_{\text{battery}}$ & Current battery
\\ \hline
$X_{\text{10}}$ & $P_{\text{PV}}$ & Power Solar
\\ \hline
$X_{\text{11}}$ & $P_{\text{L1}}$ & Power load 1
\\ \hline
$X_{\text{12}}$ & $P_{\text{L2}}$ & Power load 2
\\ \hline
$X_{\text{13}}$ & $battery_{\text{soc}}$ & Battery soc
\\ \hline
$X_{\text{14}}$ & $battery_{\text{ah}}$ & Batter Ah
\\ \hline

\end{tabular}
\centering
\label{tab:data}
\end{table}


\subsection{Anomaly Threshold}



%#threshold = np.max(train_mae_loss)
%threshold = np.percentile(train_mae_loss, 95)
%print("Reconstruction error threshold: ", threshold)
%anomalies = test_mae_loss > threshold

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/distribution.png}
    \caption{Distribution}
    \centering
    \label{fig:training2}
\end{figure}

After the training process, we study the reconstruction error over the training dataset. Figure~\ref{fig:training2} shows the distribution of reconstruction error over the training dataset. A threshold for anomaly detection can then be determined, and anomalies can be detected by comparing test reconstruction errors against this threshold to flag samples with errors exceeding the threshold. There are different ways to determine and optimize a threshold, depending upon the needs on precision and accuracy. We define threshold $\tau$ as the 95th percentile of the training loss. A sample $X$ is thus classified as anomalous if: \[ e(X) > \tau \quad \text{where} \quad \tau = \text{percentile}(e(X), 95) 
\]

\subsection{Results}
\label{results}

In the following subsection, an evaluation of the detection performance for the various cyberattacks discussed above is provided. To simulate attacks, we employ the gain block in Simulink which multiplies the given input by a constant value or gain. Thus, attacks are imitated by maliciously amplifying or curtailing the magnitude of the control signals. This results in many attack scenarios, for example, the battery may charge or discharge, regardless of the actual grid conditions and capacity, if the signal from controller to battery is compromised. The magnitude of the signal to the battery determines the charging rate of the battery, with a larger and positive amplitude telling the battery to charge faster (store energy) and a negative signal instructing the battery to discharge. Similarly, manipulation on the load side can result in an increase or decrease of the signals, triggering cascading events and incorrect controller actions. 

\subsubsection{Power Absorption Attacks}

PA attacks force the battery to increase the charging rate and store more energy than expected. For this scenario, we experiment with two different variations. In the first instance, the control signal between controller and battery is doubled in amplitude to essentially tell the battery to charge at a rate that is twice than what is normal. Then, we further amplify the charging rate of the battery by multiplying the signal by five times resulting in a difference of 500\%. Figure~\ref{fig:PA1} shows the distribution of reconstruction error for these attack samples. The dotted line (T) indicates the detection threshold. Figure~\ref{fig:PA2} plots the detection performance of the model with attacks starting from sample 0.%all samples representing anomalous behavior. 

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1\textwidth]{figures/reconstruction-error-distribution-PA.png}
    \caption{Distribution of Reconstruction error for PA attacks.}
    \centering
    \label{fig:PA1}
\end{figure}

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.1\textwidth]{figures/detection-performance-PA.png}
    \caption{Detection performance for PA attacks.}
    \centering
    \label{fig:PA2}
\end{figure}

It can be seen from  the plot that the model struggles to detect the attack samples when the amplitude is twice (PA x2) as normal, with a majority of attack samples achieving a lower reconstruction error than the threshold, resulting in them being classified as false negatives. However, the detection performance improves as the amplitude increases (PA x5) with the attack samples correctly classified as attacks by the model. We hypothesize that the detection model needs a bigger deviation from normality in this case to be more accurate in its detection. At the same time, although the model misses attack samples in the PA x2 scenario, it can still be useful as the attack can still be detected as long as there are large enough samples.




%Figures~\ref{fig:PA3} show a confusion matriCES to assess the detection performance for these attacks. 

\iffalse
\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/confusion_matrix_PAx2.png}
    \caption{Confusion matrix PA x2}
    \centering
    \label{fig:PA3}
\end{figure}


\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/confusion_matrix_PAx5.png}
    \caption{Confusion matrix PA x5}
    \centering
    \label{fig:PA4}
\end{figure}
\fi


%\subsubsection{Denial of Service}

To imitate a denial-of-service attack on the controller-battery signal, we force the signal to always be zero. This results in the battery never charging or discharging in a 24 hours period and remaining in a constant state. However, this behavior is in violation of the expected normal and operational behavior of a EC. Figure~\ref{fig:dos1} shows the distribution of reconstruction error for this variation of attack while Figure~\ref{fig:dos2} plots the detection performance of the model. The results show that the model is good at detecting this attack, with a high detection rate and only a few false negatives.

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/reconstruction-error-distribution-dos.png}
    \caption{Distribution of Reconstruction error for DoS attack.}
    \centering
    \label{fig:dos1}
\end{figure}


\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.1\textwidth]{figures/detection-performance-dos.png}
    \caption{Detection performance for DoS.}
    \centering
    \label{fig:dos2}
\end{figure}

 %Figure~\ref{fig:dos3} shows a confusion matrix to assess the detection performance for this attack.

\iffalse
\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/confusion_matrix_DoS.png}
    \caption{Confusion matrix DoS}
    \centering
    \labeld{dos3}
\end{figure}
\fi
%%%%%%%%%%%%%%%%%%%%5%%%%%%%%%%%%%%%%

\subsubsection{Power Injection Attacks}

%The attacker injects false current readings into the system, tricking the BMS into miscalculating charge levels.

In PI attacks, an adversary aims to discharge the battery in an unsafe and unexpected manner to inject maximum possible power. A battery normally discharges when it supplies power to connected loads. However, an adversary can also artificially force the battery to discharge, essentially making the battery act like it is supplying power to loads. This discharging action results in the battery injecting its stored power. To simulate PI attacks, we apply negative scaling of different proportions of the original value to the controller-battery signal. 

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1\textwidth]{figures/reconstruction-error-distribution-PI.png}
    \caption{Distribution of Reconstruction error for PI attacks.}
    \centering
    \label{fig:PI1}
\end{figure}

For these attacks, we experiment with three different variations. The first attack simply reverses the input signal. The second reverses and amplifies the signal by twice while the third reverses and amplifies the signal by five times. Figure~\ref{fig:PI1} shows the distribution of reconstruction error for PI attack samples. The dotted line (T) indicates the detection threshold. Figure~\ref{fig:PI2} depicts the detection performance of the model. In the figures, PI-1 represents reversal of the original value with same magnitude, while PI-2 and PI-5 represent reversal and amplification by a factor of two and five, respectively. The model shows good performance for all variations of this attack with the observation that the higher the deviation from normality (higher the amplification), the higher the reconstruction error, and the easier it is for the model to detect the attack. 

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1\textwidth]{figures/detection-performance-PI.png}
    \caption{Detection performance for PI attacks.}
    \centering
    \label{fig:PI2}
\end{figure}

\iffalse
\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/confusion_matrix_PI-1.png}
    \caption{Confusion matrix PI -1}
    \centering
    \label{fig:PI3}
\end{figure}


\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/confusion_matrix_PI-2.png}
    \caption{Confusion matrix PI -2}
    \centering
    \label{fig:PI4}
\end{figure}
\begin{figure}[h!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/confusion_matrix_PI-5.png}
    \caption{Confusion matrix -5}
    \centering
    \label{fig:PI5}
\end{figure}
\fi

\subsubsection{Load Reduction Attacks}

%load is turned off for 10 seconds using a breaker. This event causes a noticeable spike in active power on the transformer's secondary side and affects the storage battery's power output.

Load altering attacks imitate the scenario where an attack increases or decreases demand of the controllable loads within the households. LR attacks result in a reduction of demand. We simulate these attacks using signal disturbance in Simulink so that within the specified time range defined by start and duration parameters, output is set to a factor of the original value. Outside the specified time range output is kept at 1.0. 

Two variations of LR attacks are studied. First, we scale down the input signal to half of the original value (LR x0.5), resulting in significant reduction in power consumption. To imitate an attacker taking over multiple flexible assets, both the households have their demand reduced at the same time. Secondly, we force the demand to be 0 (LR x0) resulting in unexpected behavior as in reality the demand is never exactly 0. 
 

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/reconstruction-error-distribution-LR.png}
    \caption{Distribution of Reconstruction error for LR attacks.}
    \centering
    \label{fig:LR1}
\end{figure}

Figure~\ref{fig:LR1} shows the distribution of reconstruction error for LR attack samples. The dotted line (T) indicates the detection threshold. Figure~\ref{fig:LR2} depicts the detection performance of the model. The model shows good detection performance for both variations. 

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.1\textwidth]{figures/detection-performance-LR.png}
    \caption{Detection performance for LR attacks.}
    \centering
    \label{fig:LR2}
\end{figure}


%%%%%%%%%%%%%%%%%%%%5%%%%%%%%%%%%%%%%

\subsubsection{Load Increase Attacks}

LI attacks are represented by abruptly amplifying the consumption or demand of controllable loads within households from the normal value. This results in the grid needing to supply unexpectedly extra power to meet the increased demand. Two variations are investigated for these attacks where first the demand is doubled (LI x2), and then the demand is increased by a factor of five (LI x5).  


\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/reconstruction-error-distribution-LI.png}
    \caption{Distribution of Reconstruction error for LI attacks.}
    \centering
    \label{fig:LI1}
\end{figure}


Figure~\ref{fig:LI1} shows the distribution of reconstruction error for LI attack samples. The dotted line (T) indicates the detection threshold. Figure~\ref{fig:LI2} depicts the detection performance of the model. The model shows good detection performance for both variations. 

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.1\textwidth]{figures/detection-performance-LI.png}
    \caption{Detection performance for LI attacks.}
    \centering
    \label{fig:LI2}
\end{figure}

\iffalse
\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/confusion-matrix-LIx2.png}
    \caption{Confusion matrix x2}
    \centering
    \label{fig:LI3}
\end{figure}

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/confusion-matrix-LIx5.png}
    \caption{Confusion matrix x5}
    \centering
    \label{fig:LI4}
\end{figure}

\fi

\subsubsection{Other Metrics}

To evaluate the detection performance of the model using metrics such as precision, recall, and F1-score, we collect an additional test dataset. This dataset includes both normal and abnormal data, enabling calculation of these metrics. Table~\ref{tab:conclusion_evaluation} summarizes the evaluation metrics for different attacks. 

%PA x2
%[[1281  119]
% [1451  220]]

%PA x5
%[[1281  119]
%[ 980  677]]

%Dos
%[[1281  119]
% [  75 1447]]

%PI-1
%[[1281  119]
% [  54 1533]]

%PI-2
%[[1281  119]
% [  49 1548]]

%PI-5
%[[1281  119]
% [  42 1568]]

%LR x0
%[[1281  119]
% [ 409 1207]]

%LR x0.5
%[[1281  119]
% [ 711  946]]

%LI x2
%[[1281  119]
% [ 218 1466]]

%LI x5
%[[1281  119]
% [  17 1616]]


\begin{table}[htbp!] 
\centering
\caption{Summary of evaluation results.}
\begin{tabular}{| p{0.2\linewidth} | p{0.2\linewidth} | p{0.2\linewidth} | p{0.2\linewidth} |}
\hline
\textbf{Attack Type} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score}
\\ \hline
PA x2 & 0.6490 & 0.1317 & 0.2189 
\\ \hline
PA x5 &  0.8505 & 0.4086 & 0.5520 
\\ \hline
DoS &  0.9240 & 0.9507 & 0.9372 
\\ \hline
PI-1 &  0.9280 & 0.9660 & 0.9466 
\\ \hline
PI-2 &  0.9286 & 0.9693 & 0.9485 
\\ \hline
PI-5 & 0.9295 & 0.9739 & 0.9512 
\\ \hline
LR x0 &  0.9103 & 0.7469 & 0.8205 
\\ \hline
LR x0.5 &  0.8883 & 0.5709 & 0.6951 
\\ \hline
LI x2 &  0.9249 & 0.8705 & 0.8969 
\\ \hline
LI x5 &  0.9314 & 0.9896 & 0.9596 
\\ \hline
\end{tabular}
\centering
\label{tab:conclusion_evaluation}
\end{table}

%Metrics for evaluation (based on confusion matrix):
%    Accuracy: Proportion of correctly identified instances.
%    Precision: Proportion of true positives among detected anomalies.
%    Recall: Ability to detect all anomalies.
%    F1-score: Balance between precision and recall.
%    False positive rate: Measure of false alarms.


%\subsection{Comparative Analysis}
%Comparison of the autoencoder-based IDS with alternative techniques 

\subsection{Collaborative Learning}

The centralized autoencoder model as discussed thus far performs well but depends on raw data to train on and learn the normal operational patterns. Since the data can be sensitive and belongs to private individuals, this dependency can hinder its real world potential. To assess the approach in a more practical and privacy-preserving setting, we train an autoencoder using FL. We use the Flower framework~\cite{flower} to implement the FL process. We experiment with a configuration of three clients that communicate with a server using the Flower API. The server is configured to run the training process for three full rounds where training in each round takes the model closer to convergence and losses reduce. The server aggregates model updates from clients using the FedAvg~\cite{fedavg} algorithm. 

%round 1: 0.37044168669291494
%round 2: 0.17228727384816483
%round 3: 0.1116605883098441

Once the FL process is complete, we use the final global model to detect the same attacks as the centralized autoencoder model in Section~\ref{results}. Figure~\ref{fig:FL1} shows a comparison between the performance of the centralized and federated models for a selection of attacks. The federated model shows comparable performance to the centralized model for all attacks. This motivates the potential for using the proposed approach in a real-world setting, as it ensures data privacy.

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/comparison-detection-performance.png}
    %.png[width=1.0\textwidth]{figures/comparison-detection-performance.eps}
    \caption{Comparison of centralized and federated model performance.}
    \centering
    \label{fig:FL1}
\end{figure}



\iffalse
\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/reconstruction-error-distribution-FL.png}
    \caption{Distribution of Reconstruction error using FL.}
    \centering
    \label{fig:FL1}
\end{figure}

\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/detection-performance-FL.png}
    \caption{Detection Performance using FL.}
    \centering
    \label{fig:FL2}
\end{figure}


\begin{figure}[htbp!] 
    \centering 
    \includegraphics[width=1.0\textwidth]{figures/comparison-recall.png}
    \caption{Distribution of Reconstruction error using FL.}
    \centering
    \label{fig:FL2}
\end{figure}
\fi

