\section{Privacy-Preserving Intrusion Detection} 
\label{section:approach}

This section provides an overview of our approach towards a privacy-preserving anomaly-based IDS. It describes the proposed data-driven detection model together with problem formalization, and an approach to enable privacy-friendly detection using federated learning.

\subsection{Autoencoder-based Intrusion Detection}

Autoencoders have emerged as an effective tool for anomaly detection, particularly in cyber-physical systems. By learning compressed representations of normal system behavior, these models are efficient at reconstructing input data with lower error under normal conditions. Anomalies, which deviate significantly from learned patterns, result in higher reconstruction errors, enabling their identification. This data-driven approach is particularly advantageous for cyber-physical systems, where anomalies are often rare, and explicit labeling is impractical. In detail, the application of autoencoders involves the following key steps:

\begin{enumerate}
    \item Training: The autoencoder is trained using data representing the normal operation of the system. During training, the network learns to encode input data into a lower-dimensional latent space and reconstruct it back to its original form. The goal is to minimize the reconstruction error.
    \item Reconstruction Error: Once trained, the autoencoder can process new data and attempt to reconstruct it. For normal data, reconstruction errors are typically small, as the autoencoder has learned these patterns during training. However, for anomalous data, which deviates significantly from normal patterns, reconstruction errors tend to be larger.
    \item Setting a Threshold: To distinguish between normal and anomalous behavior, a reconstruction error threshold is determined. This threshold is often set based on statistical measures (e.g., mean and standard deviation of reconstruction errors on the training set) or by analyzing the error distribution during validation.
    \item  Testing and Detection: During testing, the autoencoder processes new data and computes the reconstruction error for each sample. If the error exceeds the predefined threshold, the data point is flagged as an anomaly. This enables both real-time or offline anomaly detection in dynamic systems.
\end{enumerate}
    

\subsection{Problem Definition}

We focus on detecting anomalies in the ECâ€™s operational data using a time-series anomaly detection model based on a reconstruction autoencoder model. The problem is formalized as follows. Let the energy community's operational data be represented as a multivariate time series:

\begin{equation}
\mathcal{X} = \{X_1, X_2, \dots, X_T\},
\end{equation}
%T represents total number of time steps

where each $X_t \in \mathbb{R}^d$ is a feature vector of $d$ dimensions at time step $t$, meaning there are $d$ different numerical measurements recorded at each time step. Each feature represents an energy or power related measurement, such as battery current ($I_{\text{batt}}$), load power ($P_{\text{load}}$), and voltage ($V$). The goal is to distinguish between normal operational data and anomalous data based on probability distributions. The model assumes two types of data distributions, as described below.

\begin{itemize} 
    \item \textbf{Normal Data:} When the energy system operates under normal conditions, its data follows a probability distribution:
    \begin{equation}
    X_t \sim p_{\text{normal}}(X).
    \end{equation}

    \item \textbf{Anomalous Data:} Attacks cause deviations from $p_{\text{normal}}(X)$, generating out-of-distribution samples:
    \begin{equation}
    X_t \sim p_{\text{attack}}(X), \quad \text{where} \quad p_{\text{attack}}(X) \neq p_{\text{normal}}(X).
    \end{equation}


An autoencoder $f_\theta: \mathbb{R}^{d \times T} \to \mathbb{R}^{d \times T}$ where d x T represents operating on an entire segment of length T, learns to reconstruct normal data. The goal is to train the autoencoder to learn an identity mapping:
    \begin{equation}
        f_\theta(X) \approx X.
    \end{equation}
    where \( f_\theta(X) \) is the autoencoder function parametrized by \( \theta \).  Given an input $X$, the model reconstructs it as:
    \begin{equation}
        \hat{X} = f_\theta(X).
    \end{equation}
   

The model is trained only on normal data, so it becomes good at reconstructing normal patterns but struggles with anomalous data. In other words, it has low reconstruction error for normal samples and high reconstruction error for anomalies. The reconstruction error $e$ is computed using the \textit{Mean Absolute Error (MAE)}:
    \begin{equation}
        e(X) = \frac{1}{dT} \sum_{i=1}^{d} \sum_{t=1}^{T} |X_{t, i} - \hat{X}_{t, i}|.
    \end{equation}
This calculates the average difference between the original and reconstructed data. Higher error means the model failed to reconstruct the input well, indicating a potential anomaly. For anomaly classification, a threshold $\tau$ is determined from the reconstruction error $e$ distribution of normal data. A given sample $X$ is thus classified as anomalous if:
    \begin{equation}
        e(X) > \tau.
    \end{equation}
    Otherwise, it is considered normal.

\end{itemize}

\subsection{Private Anomaly Detection}

In traditional and centralized machine learning, data from different sources is aggregated into a single dataset and transferred to a central server, where the model is trained. Since raw data is required to be sent to a central location, this approach suffers from several drawbacks. First, there are privacy risks with collecting and transferring raw sensitive data. Second, this approach requires high network bandwidth, and third, the central server could prove to be a single point of failure. Federated learning (FL) on the other hand is a decentralized machine learning approach which allows multiple devices or nodes to collaboratively train a shared model without sharing their local raw data. Instead of transferring data to a single central server, federated learning allows each node to train the model on its local data and share only the updated model parameters. This approach preserves data privacy as instead of data moving towards the model, the model is essentially moved closer to the data, reduces communication costs, and is particularly valuable in scenarios where data is sensitive or distributed across various locations, such as in ECs.

%each client aims to minimize a loss function related to their data

The FL process begins with the server initializing a global model and distributing its parameters to the clients. Each client trains the model on its local dataset, which consists of normal data, and computes updates to the model parameters. These updates are then sent back to the server, which is responsible for aggregation to improve the global model and distribution of the global model parameters to the clients. This process repeats for a predefined number of communication rounds until the training process is complete, and the trained global model is distributed to all the clients.

In ECs, where multiple households or facilities generate and consume energy, detecting anomalies is critical for ensuring reliable and efficient grid operations. By combining FL with autoencoders, it is possible to build a robust, privacy-preserving anomaly detection system tailored to such communities. Each node in the EC (e.g., a household or facility) can train an autoencoder locally using its energy consumption and generation data. The autoencoder learns to reconstruct normal patterns specific to the node. When new data deviates significantly, resulting in high reconstruction errors, anomalies can be detected locally. This combination offers several advantages: it preserves the privacy of individual nodes by keeping their data local, accommodates the heterogeneity of energy patterns across the community, and ensures a more accurate and adaptive anomaly detection system through collaborative learning. 


%Deployment architecture of the IDPS:    Placement within the REC infrastructure.     Interaction with the local area network (LAN). Real-time detection and mitigation capabilities.

%\begin{figure}
%    \centering
%    \includegraphics[width=0.7\linewidth]{FL-IDS.png}
%    \caption{Federated approach to model training in ECs}
%    \label{fig:FL-IDS}
%\end{figure}


