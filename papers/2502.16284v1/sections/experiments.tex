\section{Experiments}

To comprehensively evaluate the impact of molecular spectra on molecular tasks, we first 
verify the effectiveness of molecular spectra in the training-from-scratch method for the downstream task.
Furthermore, we evaluate the effectiveness of our pre-training framework \themodel.

\subsection{Effectiveness of molecular spectra in training from scratch}\label{sec:exp-train-from-scratch}
This pilot experiment aims to demonstrate the rationality for incorporating molecular spectra into pre-training. We introduce additional spectral features into a train-from-scratch molecular property prediction model to observe the impact of spectral information on prediction outcomes. We employ EGNN~\citep{EGNN}, a representative 3D molecular encoder, equipped with an MLP-based prediction head as the baseline model. While EGNN encodes the 3D representations, {the UV-Vis spectrum of each molecule provided by the QM9S~\citep{DetaNet} dataset} is encoded into spectral representations by a spectrum encoder. Before making predictions with the final MLP, we concatenate the spectral and 3D representations for prediction. The results are presented in \cref{tab:train-from-scratch}.

\begin{table}[th]
  \caption{Performance (MAE $\downarrow$) when training from scratch on QM9 dataset.}
  \label{tab:train-from-scratch}
  \centering
  \resizebox{\textwidth}{!}{
  \begin{tabular}{l c c c c c c c c c c c c}
  \toprule
    Task &  \makecell[c]{$\mu$} &  \makecell[c]{$\alpha$ } &  \makecell[c]{homo } & \makecell[c]{lumo} & \makecell[c]{gap} & \makecell[c]{$R^2$ } & \makecell[c]{ZPVE } & \makecell[c]{$U_0$ } & \makecell[c]{$U$ } & \makecell[c]{$H$ } & \makecell[c]{$G$} & \makecell[c]{$C_v$ }
    \\
    Units &  \scriptsize (D) &  \scriptsize ($a_0^3$) & \scriptsize  (meV) &\scriptsize (meV) &\scriptsize (meV) & \scriptsize($a_0^2$) &\scriptsize (meV) &\tiny (meV) &\tiny (meV) &\tiny (meV) &\tiny (meV) & \tiny\makecell[c]{($\frac{cal}{mol\cdot K}$)}\\
    \midrule
    w/o spectra & 0.029 & 0.071 & 29 & 25 & 48 & 0.106 & 1.55 & 11 & 12 & 12 & 12 & 0.031 \\
    \midrule
    w/ spectra & \first{0.027} & \first{0.049} & \first{28} & \first{24} & \first{43} & \first{0.084} & \first{1.45} & \first{10} & \first{11} & \first{10} & \first{10} & \first{0.030} \\
    \bottomrule
  \end{tabular}
  }
\end{table}

We observe that by directly concatenating spectral representations, the performance of molecular property prediction can be effectively enhanced. This indicates that the information from molecular spectra is beneficial for downstream molecular property prediction. Further incorporating molecular spectra into the pre-training phase of molecular representation has the potential to enhance the informativeness and generalization capability of the representations, thereby broadly improving the performance of downstream tasks.

\subsection{Effectiveness of molecular spectra in representation pre-training}

We conduct experiments to evaluate MolSpectra by first introducing spectral data into the pre-training of 3D representations, followed by evaluating the performance on downstream tasks.
For a comprehensive comparison, two types of baselines are adopted: (1) training-from-scratch methods, including SchNet~\citep{SchNet}, EGNN, DimeNet~\citep{DimeNet}, DimeNet++~\citep{DimeNet++}, PaiNN~\citep{PaiNN}, SphereNet~\citep{SphereNet}, and TorchMD-Net~\citep{TorchMD-Net}; and (2) pre-training methods, including Transformer-M~\citep{Transformer-M}, SE(3)-DDM~\citep{SE3-DDM}, 3D-EMGP~\citep{3D-EMGP}, and Coord. 

\themodel can be seamlessly plugged into any existing denoising method. To evaluate the enhancement provided by our method compared to denoising alone, we select the representative coordinate denoising (Coord) as our denoising sub-objective. This method also serves as our primary baseline.

\subsubsection{Pre-training dataset.}
As described in \cref{sec:two-stage}, we first perform denoising pre-training on the PCQM4Mv2~\citep{PCQM} dataset, followed by a second stage of pre-training on the QM9Spectra (QM9S)~\citep{DetaNet} dataset, which includes multi-modal molecular energy spectra.  {In both stages, we adopt the denoising objective provided by Coord~\citep{Coord}, as defined in \cref{eq:coord}.}

The QM9S dataset comprises organic molecules from the QM9~\citep{QM9} dataset.
The UV-Vis, IR, and Raman spectra of the molecules are calculated at the B3LYP/def-TZVP level of theory, through frequency analysis and time-dependent density functional theory (TD-DFT).


\begin{table}[h]
\setlength{\tabcolsep}{4pt}
    \caption{Performance (MAE$\downarrow$) on QM9 dataset. The compared methods are divided into two groups: training from scratch and pre-training then fine-tuning. The best results are highlighted in bold.}
    \label{tab:qm9}
    \begin{center}
    \begin{footnotesize}
    \scalebox{0.96}{
    \begin{tabular}{lrrrrrrrrrrrr}
    \toprule
    &  \makecell[c]{$\mu$} &  \makecell[c]{$\alpha$ } &  \makecell[c]{homo } & \makecell[c]{lumo} & \makecell[c]{gap} & \makecell[c]{$R^2$ } & \makecell[c]{ZPVE } & \makecell[c]{$U_0$ } & \makecell[c]{$U$ } & \makecell[c]{$H$ } & \makecell[c]{$G$} & \makecell[c]{$C_v$ }
 \\
 &  \makecell[c]{\scriptsize (D)} &  \makecell[c]{\scriptsize ($a_0^3$)} & \makecell[c]{\scriptsize  (meV)} &  \makecell[c]{\scriptsize (meV)} & 
    \makecell[c]{\scriptsize (meV)} & \makecell[c]{\scriptsize($a_0^2$)} &  \makecell[c]{\scriptsize (meV)} &  \makecell[c]{\tiny (meV)} &  \makecell[c]{\tiny (meV)} &  \makecell[c]{\tiny (meV)} &  \makecell[c]{\tiny (meV)} & \makecell[c]{\tiny\makecell[c]{($\frac{cal}{mol\cdot K}$)}}\\
    \midrule
  SchNet & 0.033 & 0.235 & 41.0 & 34.0 & 63.0 & 0.070 & 1.70 & 14.00 & 19.00 & 14.00 & 14.00 & 0.033\\
  EGNN & 0.029 & 0.071 & 29.0 & 25.0 & 48.0 & 0.106 &   1.55 & 11.00 & 12.00 & 12.00 & 12.00 & 0.031\\
  DimeNet++ & 0.030 & 0.044 & 24.6 & 19.5 & 32.6 & 0.330 & 1.21 & 6.32 & 6.28 & 6.53 & 7.56 & 0.023\\
  PaiNN & 0.012 & 0.045 & 27.6 & 20.4 & 45.7 & 0.070 & 1.28 & 5.85 & 5.83 & 5.98 & 7.35 & 0.024\\
  SphereNet & 0.025 & 0.045 & 22.8 & 18.9 & 31.1  & 0.270 & \first{1.12} & 6.26&  6.36 & 6.33 &7.78 &0.022\\ 
    TorchMD-Net & 0.011 & 0.059 & 20.3 & 17.5 & 36.1 & \first{0.033} & 1.84 & 6.15 & 6.38 & 6.16 & 7.62 & 0.026 \\
   \midrule 
    Transformer-M & 0.037 & \first{0.041} & 17.5 & 16.2 & 27.4 & 0.075 & 1.18 & 9.37 & 9.41 & 9.39 & 9.63 & 0.022 \\
    SE(3)-DDM  & 0.015 & 0.046 & 23.5 & 19.5 & 40.2 & 0.122 & 1.31 & 6.92 & 6.99 & 7.09 & 7.65 & 0.024 \\
    3D-EMGP & 0.020 & 0.057 & 21.3 & 18.2 & 37.1 & 0.092 & 1.38 & 8.60 & 8.60 & 8.70 & 9.30 & 0.026 \\
    Coord & 0.016 & 0.052 & 17.7 & 14.7 & 31.8 & 0.450 & 1.71 & 6.57  &  6.11  &  6.45  &  6.91  & \first{0.020}    \\  
    MolSpectra & {\gtcoord\first{0.011}} & {\gtcoord0.048} & {\gtcoord\first{15.5}} & {\gtcoord\first{13.1}} & {\gtcoord\first{26.8}} & {\gtcoord0.410} & {\eqcoord1.71} & {\gtcoord\first{5.67}} & {\gtcoord\first{5.45}} & {\gtcoord\first{5.87}} & {\gtcoord\first{6.18}} & {0.021} \\
    \bottomrule
    \end{tabular}
    }
    \end{footnotesize}
    \end{center}
    \vskip -0.2in
\end{table}


\subsubsection{QM9}
The QM9 dataset is a quantum chemistry dataset comprising over 134,000 small molecules, each consisting of up to 9 hydrogen (H), carbon (C), nitrogen (N), oxygen (O), and fluorine (F) atoms. This dataset provides an equilibrium geometric conformation for each molecule along with 12 property labels.
The dataset is divided into a training set of 110k molecules, a validation set of 10k molecules, and a test set containing the remaining over 10k molecules.
Prediction errors are measured using the mean absolute error (MAE). The experimental results are presented in \cref{tab:qm9}.

The 3D molecular representations pre-trained using our method are fine-tuned and used for prediction across various properties, 
{achieving state-of-the-art performance in 8 out of 12 properties and outperforms Coord in 10 out of 12 properties.}
In conjunction with the observations in \cref{sec:exp-train-from-scratch}, the performance improvement can be attributed to our incorporation of an understanding of molecular spectra and the knowledge they entail into the 3D molecular representations.


\begin{table}[h]
\setlength{\tabcolsep}{4pt}
    \caption{Performance (MAE$\downarrow$) on MD17 force prediction (kcal/mol/ $\mathring{\textnormal{A}}$). {The methods are divided into two groups: training from scratch and pre-training then fine-tuning.} The best results are in bold. 
    }
    \label{tab:md17}
    \begin{center}
    \begin{footnotesize}
    \begin{tabular}{lccccccccc}
    \toprule
    & Aspirin & Benzene & Ethanol & \makecell[c]{ Malonal\\-dehyde} & \makecell[c]{Naphtha\\-lene} & \makecell[c]{Salicy\\-lic Acid} & Toluene & Uracil \\ 
    \midrule   
    SphereNet & 0.430 & 0.178 & 0.208 & 0.340 & 0.178 & 0.360 & 0.155 & 0.267 \\ 
    SchNet  & 1.350  & 0.310  & 0.390  & 0.660  & 0.580  & 0.850  & 0.570  & 0.560 \\ 
    DimeNet  & 0.499  & 0.187  & 0.230  & 0.383  & 0.215  & 0.374  & 0.216  & 0.301 \\  
    PaiNN  & 0.338  & -  & 0.224  & 0.319  & 0.077  & 0.195   & 0.094  & 0.139 \\ 
    TorchMD-Net
    & 0.245 & 0.219 & 0.107 & 0.167  & 0.059 & 0.128  & 0.064 & 0.089\\ 
    \midrule   
    SE(3)-DDM*  & 0.453 & - & 0.166 & 0.288 & 0.129 & 0.266 & 0.122 & 0.183\\ 
    Coord & 0.211  &  {0.169}  &  0.096  &  {0.139}  &  \first{0.053}  &  0.109  &  \first{0.058}  &  \first{0.074}\\
    MolSpectra  & \first{0.099} & \first{0.097} & \first{0.052} & \first{0.077} & {0.085} & \first{0.093} & {0.075} & 0.095\\
    \bottomrule
    \end{tabular}
    \end{footnotesize}
    \end{center}
\end{table}

\subsubsection{MD17}

The MD17 dataset contains molecular dynamics trajectories for eight organic molecules, including aspirin, benzene, and ethanol. It offers 150k to nearly 1M conformations per molecule, with energy and force labels. Unlike QM9, MD17 emphasizes dynamic behavior in addition to static properties. We use a standard limited data split: models train on 1k samples, validate on 50, and test on the rest. Performance is evaluated using MAE, with results in \cref{tab:md17}.

Our approach also results in the expected performance improvement on MD17. MD17 is a dataset comprising a large number of non-equilibrium molecular structures and their corresponding force fields, which serves to evaluate a model's understanding of molecular dynamics. However, previous pre-training methods based solely on denoising have only learned force field patterns at static equilibrium states, failing to adequately capture the dynamic evolution of molecular systems. In contrast, our \themodel learns the dynamic evolution of molecules by understanding energy level transition patterns, thereby outperforming denoising-based pre-training methods.

\subsection{Sensitivity analysis of patch length $P_i$, stride $D_i$, and mask ratio $\alpha$}\label{sec:sensitivity}
\vspace{-7pt}
\begin{table}[h]
\setlength{\tabcolsep}{4pt}
\begin{minipage}[t]{0.55\textwidth}
    \caption{Sensitivity of patch length and stride.}
    \label{tab:ablation-1}
    \begin{center}
    \begin{small}
    \begin{tabular}{cc|c|ccc}
    \toprule
    patch length & stride & overlap ratio & \makecell[c]{homo} & \makecell[c]{lumo} & \makecell[c]{gap} \\
    \midrule
    20 & 5  & {75\%}    & {15.9} & {13.7} & {28.0} \\
    20 & 10 & 50\%     & {\first{15.5}} & {\first{13.1}} & {\first{26.8}}\\
    20 & 15 & {25\%}    &  {16.1} & {13.6} & {28.1}\\
    20 & 20 &  0\%     & {15.7} & {13.5} & {27.5} \\
    16 & 8  & 50\%     & {16.0} & {13.4} & {27.6} \\
    30 & 15 & 50\%     & {15.9} & {14.0} & {28.1} \\
    \bottomrule
    \end{tabular}
    % \end{sc}
    \end{small}
    \end{center}
\end{minipage}
\begin{minipage}[t]{0.01\textwidth}
    \begin{tabular}{l}
 \\
    \end{tabular}
\end{minipage}
\begin{minipage}[t]{0.4\textwidth}
\caption{Sensitivity of mask ratio.}
    \label{tab:ablation-2}
    \begin{center}
    \begin{small}
    \begin{tabular}{c|ccc}
    \toprule
    mask ratio & \makecell[c]{homo} & \makecell[c]{lumo} & \makecell[c]{gap} \\
    \midrule
    % Train from scratch & 20.3 & 17.5 & 36.1\\
    0.05 & {15.7} & {13.4} & {29.7} \\
    0.10  & {\first{15.5}} & {\first{13.1}} & {\first{26.8}}\\
    0.15 & {15.7} & {13.5} & {28.0} \\
    0.20 & {16.0} & {13.6} & {28.1} \\
    0.25 & {16.3} & {13.5} & {28.0} \\
    0.30 & {16.2} & {13.7} & {29.0} \\
    \bottomrule
    \end{tabular}
    % \end{sc}
    \end{small}
    \end{center}
\end{minipage}
\end{table}
We conduct experiments to evaluate the impact of patch length $P_i$, stride $D_i$, and mask ratio $\alpha$. Results are summarized in \cref{tab:ablation-1} and \cref{tab:ablation-2}.

From \cref{tab:ablation-1}, we observe that when consecutive patches have overlap ($D_i<P_i$), the performance of pre-training is superior compared to scenarios without overlap ($D_i=P_i$). Specifically, the performance is optimal when the stride is half of the patch length. This is because appropriate overlap can better preserve and capture local features, particularly the information at the patch boundaries. 
Additionally, we find that choosing an appropriate patch length further enhances performance. In our experiments, the configuration of $P_i=20, D_i=10$ {yields} the best results.

Regarding the mask ratio, $\alpha=0.10$ is a preferable choice. A small mask ratio results in insufficient MPR optimization, hindering SpecFormer training. Conversely, a large mask ratio causes excessive spectral perturbation, degrading performance when aligning with the 3D representations with the contrastive objective. An appropriate mask ratio strikes a balance between these two aspects.

\subsection{{Ablation study}}
{To rigorously demonstrate the contributions of masked patches reconstruction, the incorporation of molecular spectra, and each spectral modality, 
we conducted an ablation study on them.}

\begin{wraptable}[8]{r}{0.45\linewidth}
\vspace{-8pt}
\caption{Ablation of optimization objectives.}
    \label{tab:ablation-3}
    \vspace{-6pt}
    \begin{center}
    \begin{small}
    \begin{tabular}{lccc}
    \toprule
    & \makecell[c]{homo} & \makecell[c]{lumo} & \makecell[c]{gap} \\
    \midrule
    \themodel & {{15.5}} & {{13.1}} & {{26.8}}\\
    w/o MPR & {16.4} & {14.1} & {29.7} \\
    {w/o MPR, Contrast} & {17.5} & {14.4} & {31.2} \\
    \bottomrule
    \end{tabular}
    \end{small}
    \end{center}
\end{wraptable}
\textbf{Ablation study of masked patches reconstruction.}
We remove the MPR loss to analyze the impact of masked patches reconstruction, referred to as ``w/o MPR" in \cref{tab:ablation-3}. 
Removing the MPR objective leads to performance deterioration. This is consistent with the sensitivity analysis of the mask ratio $\alpha$ in \cref{sec:sensitivity}, as removing MPR is an extreme case where $\alpha=0$.
This decline is due to the lack of effective guidance in training SpecFormer.
Using an undertrained SpecFormer for contrastive learning with 3D encoder outputs limits performance improvement.

\textbf{Ablation study of molecular spectra.}
We retain only the denoising loss, removing both the MPR loss and contrastive loss, referred to as ``w/o MPR, Contrast" in \cref{tab:ablation-3}. The only difference between this variant and \themodel is the incorporation of molecular spectra into the pre-training.
The "w/o MPR, Contrast" results are inferior to those of MolSpectra, highlighting that incorporating molecular spectra effectively enhances the quality and generalizability of molecular 3D representations.


\begin{wraptable}[8]{r}{0.47\linewidth}
\vspace{-10pt}
\caption{Ablation of spectral modalities.}
    \label{tab:ablation-4}
    \vspace{-6pt}
    \begin{center}
    \begin{small}
    \resizebox{0.98\linewidth}{!}{%
    \begin{tabular}{ccc|ccc}
    \toprule
     UV-Vis & IR & Raman & \makecell[c]{homo}		& \makecell[c]{lumo}		& \makecell[c]{gap}	\\
    \midrule
    \Checkmark & \Checkmark & \Checkmark  & {15.5} & {13.1} & {26.8}\\
    - & \Checkmark & \Checkmark  & {15.8} & {13.3} & {27.1}\\
    \Checkmark & - & \Checkmark  & {16.6} & {14.1} & {28.9}\\
    \Checkmark & \Checkmark & - & {16.1} & {13.9} & {28.3}\\
    \bottomrule
    \end{tabular}
    }
    \end{small}
    \end{center}
\end{wraptable}
\textbf{Ablation study of each spectral modality.}
To evaluate the contributions of each spectral modality to the performance, we conduct an ablation study for each modality. The results are presented in \cref{tab:ablation-4}. It can be observed that each spectral modality contributes differently, with the UV-Vis spectrum having the smallest contribution and the IR spectrum the largest, likely due to the varying information content in each modality.