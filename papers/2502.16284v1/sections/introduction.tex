\section{Introduction}

Learning 3D molecular representations from geometric conformations offers a promising approach for understanding molecular geometry and predicting quantum properties and interactions, which is significant in drug discovery and materials science~\citep{Allegro,MACE,Equiformer,HMR,LEFTNet}. Given the scarcity of molecular property labels, self-supervised representation pre-training has been proposed and utilized to provide generalizable representations~\citep{Pre-GNN,GROVER,doi:10.1089/cmb.2023.0187}.

In contrast to contrastive learning~\citep{MolCLR,D-SLA} and masked modeling~\citep{GraphMAE,SimSGT,AUG-MAE} on 2D molecular graphs and molecular languages (e.g., SMILES), the design of pre-training strategies on 3D molecular geometries is more closely aligned with physical principles. Previous studies~\citep{Coord,3D-EMGP} have guided representation learning through denoising processes on 3D molecular geometries, theoretically demonstrating that denoising 3D geometries is equivalent to learning molecular force fields, specifically the negative gradient of molecular potential energy with respect to position. Essentially, these studies reveal that \textit{establishing the relationship between 3D geometries and the energy states of molecular systems is an effective pathway to learn 3D molecular representations.}

However, existing methods are limited to the continuous description (i.e., the potential energy function) of the molecular energy states within the classical mechanics, overlooking the quantized (discrete) energy level structures from the quantum mechanical perspective. 
From the quantum  perspective, molecular systems exhibit quantized energy level structures, meaning that energy states can only assume specific discrete values. 
Specifically, different types of molecular motion, such as electronic, vibrational, and rotational motion, correspond to different energy level structures. Knowledge of these energy levels is crucial in molecular physics and quantum chemistry, as they determine the spectroscopic characteristics, chemical reactivity, and many other important molecular properties. Fortunately, experimental measurements of molecular energy spectra can reflect these structures. Meanwhile, there are many molecular spectra data obtained through experimental measurements or simulations~\citep{DetaNet, multimodal-spectra}. Therefore, \textit{incorporating the knowledge of energy levels into molecular representation learning is expected to facilitate the development of more informative molecular representations.}

\begin{figure}
\begin{center}
\includegraphics[width=\linewidth]{figures/1_conceptual_view.pdf}
\end{center}
\caption{
The conceptual view of \themodel, which leverages both molecular conformation and spectra for pre-training.
Prior works only model classical mechanics by denoising on conformations.
}
\label{fig:principle}
\end{figure}

In this paper, we propose \themodel, a framework that incorporates molecular spectra into the pre-training of 3D molecular representations, 
thereby infusing the knowledge of quantized energy level structures into the representations, as shown in \cref{fig:principle}. 
In \themodel, we introduce a multi-spectrum encoder, SpecFormer, to capture both intra-spectrum and inter-spectrum peak correlations by training with a masked patches reconstruction (MPR) objective. 
Additionally, we employ a contrastive objective to distills the spectral features and its inherent knowledge into the learning of 3D representations. 
After pre-training, the resulting 3D encoder can be fine-tuned for downstream tasks, providing expressive 3D molecular representations without the need for associated spectral data.
Extensive experiments over different downstream molecular property prediction benchmarks shows the superiority of \themodel.

In summary, our contributions are as follows:
\begin{itemize}[leftmargin=*]
    \item We introduce quantized energy level structures and molecular spectra into 3D molecular representation pre-training for the first time, surpassing previous work that relied solely on physical knowledge within the scope of classical mechanics.
    \item We propose SpecFormer as an expressive multi-spectrum encoder, along with the masked patches reconstruction objective for spectral representation learning.
    \item We propose a contrastive objective to align molecular representations in the 3D modality and spectral modalities, enabling the pre-trained 3D encoder to infer molecular spectral features in downstream tasks without relying on spectral data.
    \item Experiments across different downstream benchmarks demonstrate that our method effectively enhances the expressiveness of the pre-trained 3D molecular representations.
\end{itemize}