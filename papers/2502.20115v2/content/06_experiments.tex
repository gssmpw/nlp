
\section{Experiments}
\label{sec:experiments}

Our Python code for the following experiments is available at the following link \url{https://github.com/AmbroiseHeurtebise/MICaDo}. It is heavily based on the Python library for causal discovery \url{https://github.com/cdt15/lingam}.

\begin{figure*}[!t]
\centerline{\includegraphics[width=0.98\linewidth]{image/simulation_shared_P.pdf}}
\caption{
Separation performance of ICA-LiNGAM~\citep{shimizu2006linear}, MultiGroupDirectLiNGAM~\citep{shimizu2012joint} and two versions of our MICaDo  method (depending on which version of ShICA is chosen) in the \emph{shared causal ordering} context and while varying the number of samples. Left column: all disturbances are Gaussian. Middle column: all disturbances are non-Gaussian and the noise variances are equal. Right column: half of the disturbances are Gaussian and the other half are non-Gaussian.
There are three different metrics: the $\ell_2$-distance between true and estimated causal effect matrices $\mB^i$ (upper row), the $\ell_2$-distance between true and estimated matrices $\mT^i$ (middle row), and the rate of failed estimated causal orderings $\mP$ over all repetitions (lower row; lower is better).
We used 50 different seeds.}
\label{fig:simulation_study}
\end{figure*}

\subsection{Simulations}
In the following synthetic experiment, data are generated according to the LiMVAM model~\eqref{eq:multiview_causal_model} with $m=5$ views, $p=4$ variables, and a shared causal ordering $\mP$.
The case with view-specific orderings $\mP^i$ is explored in Appendix~\ref{app:ssec:additional_simulations}.
The disturbances in $\vs$ can be either Gaussian or non-Gaussian: Gaussian disturbances $s_j$ are generated from a standardized Gaussian and their corresponding noises $n^i_j$ have standard deviation $\Sigma^i_{jj}$ obtained by sampling from a uniform density between 0 and 1, while non-Gaussian disturbances are generated from a Laplace distribution (with scale parameter equal to $\frac12$) and their corresponding noises all have a standard deviation of $\frac12$.
The practical generation proceeds by the equivalent Shared ICA model in \eqref{eq:multiview_ica_model}, where the mixing matrices are generated according to $\mA^i = \mP^\top (\mI - \mT^i)^{-1} \mP$, where $\mP$ is a randomly chosen permutation matrix and $\mT^i$ are strictly lower triangular matrices whose non-zero entries are standardized Gaussian.

As in~\citet{richard2021sharedica}, we study three cases where either all disturbances are Gaussian, all disturbances are non-Gaussian, or half of the disturbances are Gaussian and the other half are non-Gaussian.
We vary the number of samples $n$ between $10^2$ and $10^4$ and display in~Fig.~\ref{fig:simulation_study} the $\ell_2$ distance between true and estimated causal effect matrices $\mB^i$, the $\ell_2$ distance between true and estimated matrices $\mT^i$, and the rate of unsuccessfully estimated causal orders $\mP$.
Specifically, for each run, the measure of error in estimating $\mP$ is 1 if the permutation was not recovered and 0 otherwise.

We plot two different versions of our method. First, MICaDo-ML, which relies on ShICA-ML, a likelihood-based method that can handle both Gaussian and non-Gaussian disturbances (sources). Second, MICaDo-J, which relies on ShICA-J, a method based on joint-diagonalization of covariances, which does not use non-Gaussianity but is faster.
These we compare to MultiGroupDirectLiNGAM~\citep{shimizu2012joint} and ICA-LiNGAM~\citep{shimizu2006linear}.
Given that ICA-LiNGAM is a single-view algorithm, we apply it separately to each view.
The experiment is repeated 50 times using different seeds.

We can see in Figure~\ref{fig:simulation_study} that MICaDo-ML achieves the best results (just ahead of MICaDo-J) when disturbances are Gaussian and the sample size is just above 100.
The performance gap increases with the sample size, as MultiGroupDirectLiNGAM and ICA-LiNGAM completely fail to recover the parameters to the point where they do not even seem to depend on the number of samples.
This was expected as these methods are not designed to deal with Gaussian sources.
On the other hand, in the classical context of non-Gaussian disturbances, MultiGroupDirectLiNGAM seems to produce slightly better results than MICaDo-ML, but the results of the two methods remain close.
ICA-LiNGAM achieves a low error in the estimation of the matrices $\mB^i$, but, as a single-view algorithm, it is not designed to look for a shared matrix $\mP$, which causes the drop in performance in the second and third rows.
In turn, MICaDo-J fails to estimate the parameters because it is designed to search for noise diversity, making this context its adversarial case.
Finally, when half of the disturbances are Gaussian and the other half are non-Gaussian, MICaDo-ML outperforms the other methods. 
MultiGroupDirectLiNGAM is close behind in terms of estimating $\mB^i$ and $\mT^i$ but has more difficulty with the estimation of the ordering $\mP$.
In addition, MICaDo-J (and ICA-LiNGAM respectively) perform better than in the pure Gaussian (and pure non-Gaussian) case, but they struggle to improve performance as the sample size increases.

Overall, MICaDo-ML is the only one of the four methods that produces good results in all scenarios, making it a safe choice when no information on the Gaussianity of the disturbances is available.
Further experiments are conducted in Appendix~\ref{app:ssec:additional_simulations}.

\subsection{Real brain imaging data} Next, we performed experiments on magnetoencephalography (MEG) data measuring human brain activity.
MEG data has a high temporal resolution, so typically methods related to Granger causality are used. However, we are here interested in analyzing the \emph{envelopes}, \emph{energies}, or \emph{powers} (these three terms meaning essentially the same thing) of \emph{oscillatory} signals. Such energies are correlates of brain activity that are not captured in the raw amplitudes of the signals. The energies also change very slowly (on the time-scale of one second), while the underlying brain activity being measured is likely to change much more quickly. Thus, it is appropriate to use a model of instantaneous causality, as in a SEM or our model, to analyze causal connections between the energies (or rather, the brain activity that they reflect).

\subsubsection{Data and preprocessing}
We used the Cam-CAN dataset, which is the largest publicly available MEG dataset~\citep{shafto2014camcan,taylor2017camcan}.
We considered the "sensorimotor task" during which each participant had to respond with a right index finger button press to auditory/visual stimuli.
The auditory stimuli were binaural pure tones.
The visual stimuli were checkerboards presented both to the left and right of a central fixation for 34-ms duration.
Given the nature of the stimuli and the active task, the neural activity involves multiple brain regions spread over the cortex (visual, auditory, and motor areas).
Also, this task leads to strong signal power modulations during the motor preparation and motor execution. This makes it relevant to the approach at hand.

\begin{figure*}[!t]
\centerline{\includegraphics[width=0.98\linewidth]{image/two_brains.pdf}}
\caption{
Top ten most important causal effects on two different runs. Each run was performed on the data of 49 randomly chosen subjects. We took the median of the causal effect matrices and picked the 10 highest entries in absolute value.
Red arrows represent positive effects and blue arrows negative effects.}
\label{fig:two_brains}
\end{figure*}

The original MEG data were acquired with 306 sensors, recorded at 1000~Hz, and band-pass filtered between 0.03 and 330~Hz. 
All MEG processing was done using the MNE-Python library~\citep{gramfort2013mnepython,gramfort2014mnepython} and we largely followed the pre-processing steps used in~\citet{power2023camcandictionarylearning}.
We applied a Maxwell filter \cite{Taulu_2006} to improve data quality and a band-pass filter between 8 and 27~Hz to focus on power effects spread over the alpha and beta bands of the brain.
This range of waves is supposed to be particularly active in sensorimotor tasks, especially during movement preparation and execution, and it typically shows a characteristic suppression (event-related desynchronization) during movement, followed by a rebound (event-related synchronization) after movement cessation, which is thought to reflect sensorimotor processing and inhibitory mechanisms.
In particular, the suppression and rebound are reflected in the energies of the signals, not raw signals.

The data was then parsed into trials synchronized to each button press, with a duration of 4.5~s, including a 1.5~s pre-movement interval.
The 4.5~s window length was selected to ensure a sufficient post-movement interval to capture the entire beta rebound response.
Trials were excluded if the button press occurred more than 1~s after the audiovisual cue (indicating poor task performance) or if another button press occurred within the time window.
Then, a baseline correction was applied using the pre-movement interval $(-1.5\,\text{s}, -1\,\text{s})$. The procedure led to about 60 trials per participant on average.

Next, we performed a cortical projection.
First, each participantâ€™s MRI (additionally given in the Cam-CAN database) was segmented using FreeSurfer~\cite{dale1999cortical}.
The segmentation provided a digitization of the cortical surface for source estimation, a transformation to the average brain (i.e. fsaverage) for spatial normalization and group statistics, and a boundary element model of the head to provide more accurate calculation of the forward solution.
The inverse solution, based on the MNE method \cite{hamalainen-mne}, allowed to consider cortical region activations for further analysis.

We used the cortical parcellation from~\cite{KHAN201857} to divide the cortical mantel (both hemispheres) into 448 distinct regions and summarized each region by an averaged time course.
Then, we selected 10 of the 448 regions based on their known importance in sensorimotor tasks.
Specifically, we picked for each hemisphere three regions in the motor cortex (two parcels in the ``postcentral" and one in the ``precentral"; visible in blue in Fig.~\ref{fig:two_brains}), one region in the auditory cortex (``superiortemporal" parcel; highlighted in pink), and one region in the visual cortex (``pericalcarine" parcel; not visible in the figure).
Note again that the task for the participant is active as right index button presses are triggered by audiovisual stimulations.

For each participant, we thus extracted one time series for each of the 10 regions and fixed the number of trials to 40.
Participants with less than 40 trials were discarded and extra trials were averaged.
Participants for whom some of the parcels did not have any vertex in the source space were also discarded, resulting in a total of 98 available participants.
We performed a Z-score normalization of the time series to correct the depth bias and, importantly, computed the Hilbert \textit{envelope} of the signals to study modulations in cortical source power.
Finally, the signals were centered and downsampled from 1000~Hz to 10~Hz due to the slowly changing nature of the envelopes (energies).
The final dataset consisted of 98 subjects, 10 brain regions, and 1760 time points.

\subsubsection{Causal analysis methods and results}
We applied MICaDo-ML to these data to recover the causal effect matrices $\mB^i$ and $\mT^i$ and the shared permutation $\mP$.
Although not assumed in the model, one can assume that the causal effects present some similarities among views. 
For example, causal effects from one brain region to another might be comparable from one participant to another.
So, we computed the element-wise median of the $\mB^i$ matrices to study shared effects.
Fig.~\ref{fig:two_brains} shows the top ten highest causal effects in absolute value for two repetitions of this experiment with 49 randomly chosen subjects each. 
Red arrows represent positive effects and blue arrows negative effects.

We can see in the figure that many arrows point from one hemisphere to the corresponding region in the other hemisphere (especially in the primary motor cortex and the primary somatosensory cortex) which confirms the fact that symmetric regions are highly correlated \cite{Li651}.
We can also see that many arrows point to or from the postcentral regions of the brain, in particular the ``postcentral-8" parcel which is thought to be deeply involved in motor processing tasks involving the hand~\cite{braun2002functional}.
Four more brain plots are displayed in Appendix~\ref{app:ssec:additional_simulations} and confirm these observations.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.39\textwidth]{image/histogram_spearmanr_coefs_P_shica_ml.pdf}
    \caption{Histogram of the Spearman's rank correlations between permutation matrices $\mP$. Each of the 50 runs was performed on the data of 50\% randomly chosen participants and outputted a matrix $\mP$, resulting in a total of 1225 correlations.}
    \label{fig:histogram_spearmanr_coefs_P}
\end{figure}

To evaluate the consistency of the results, we performed 50 runs of the same experiment.
In each run, we randomly drew 50\% of the participants and used MICaDo-ML to recover the parameters.
We focused here on measuring the consistency of the common causal ordering, which is a quantity specific to our multi-view framework.
To measure the correlation between the estimated permutations $\mP$, we used Spearman's rank correlation on the orderings. 
The obtained correlation matrix is displayed in Appendix~\ref{app:sec:additional_experiments} and the 1225 correlations are given in the histogram in Fig.~\ref{fig:histogram_spearmanr_coefs_P}.
We can see that the obtained orderings are mainly positively correlated across runs and the average correlation is 0.24.
This suggests that the estimated parameters are reasonably consistent across runs.
