
\section{Estimation of the model}
\label{sec:estimation}

Next, we propose an estimation algorithm for our new model. It is essentially a combination of the ICA-based estimation procedure by~\citet{shimizu2006linear}, combined with the Shared ICA methods by \citet{richard2021sharedica}.
Thus, we call it Multi-view ICA-based Causal Discovery (MICaDo). 

The method consists of two steps: first, find the causal matrices $\mB^i$ by means of Shared ICA, then find their DAG decomposition into $\mT^i$ and $\mP^i$. The procedure is summarized in Algorithm~\ref{alg:causal_discovery}. 
Next, we describe the method in more detail.

\paragraph{Finding the causal matrices}
In general, an ICA algorithm yields $\mW^i$ which is the inverse of the true underlying $\mA^i=(\mI-\mB^i)^{-1}$, up to an unknown scale-permutation matrix $\mM$
\begin{align}
    (\mA^i)^{-1} = \mM \mW^i
    \enspace.
\end{align}
To determine $\mM$, we use the structure of the underlying $(\mA^i)^{-1}=(\mI-\mB^i)$: it has diagonal of ones.
As a first approach, we could determine $\mM$ by solving
\begin{align}
    \min_{\mK} \sum_{j=1}^p 
    \big( (\mK \mW^i)_{jj} - 1 \big)^2
\end{align}
over scale-permutation matrices, and separately for each view. However, we know from the theory of Shared ICA \citep{richard2021sharedica} that the unknown permutation matrix is the same for all views. Thus, we can adapt the simple two-step approach by \citet{shimizu2006linear}. We propose to compute, rather heuristically: 
\begin{enumerate}
    \item Find a permutation matrix $\mK$ such that $\mK \mW$ has a non-zero diagonal, by solving:
    \begin{align}
        \min_{\mK} \sum_{j=1}^p 
        \frac{1}{| (\mK \mW)_{jj} |}
        \;, \quad
        \mW = \sum_{i=1}^m \operatorname{abs}(\mW^i) \;,
    \end{align}
    where the $\operatorname{abs}$ operator takes the absolute value of each entry.
    \item Rescale the rows of $\mK$ to ensure that $\mK \mW$ has a diagonal of ones. Specifically, update for all $j,k$:
    \begin{equation}
    \mK_{jk} \leftarrow \frac{\mK_{jk}}{(\mK \mW)_{jj}} \enspace.
    \end{equation}
\end{enumerate}

Now that $\mM$ is determined, we know the true $\mA^i$ and use the identity $\mB^i = \mI - (\mA^i)^{-1}$ to obtain the causal matrix~$\mB^i$. 

\paragraph{Find the DAG decompositions}
In the case of multiple causal orderings, once each $\mB^i$ is obtained, we find its DAG decomposition using the structure of
\begin{align}
    \mT^i = \mP^i \mB^i (\mP^i)^\top
\end{align}
which is strictly lower triangular. Hence we can jointly obtain $\mT^i$ and $\mP^i$ by solving 
\begin{align}
    \min_{\mK^i} \sum_{l \geq k} \big(
    \mK^i \mB^i (\mK^i)^\top
    \big)_{kl}^2 \enspace .
\end{align}
The minimizer is the permutation matrix $\mP^i$, and at the minimum, the matrix from which we take squared elements is $\mT^i$. On the other hand, if the causal orderings are shared across views, we instead solve
\begin{align}
    \min_{\mK} \sum_{l \geq k} \big(
    \mK \mB {\mK}^\top
    \big)_{kl}^2
    \;, \quad
    \mB = \sum_{i=1}^m \operatorname{abs}(\mB^i) \;.
\end{align}


\begin{algorithm}[th]
    \caption{MICaDo}
    \label{alg:causal_discovery}
    \begin{enumerate}
        
        \item Determine the unmixing matrices $\mW^i$, by running the Shared ICA estimation algorithm on the data.
        
        \item Determine the permutation indeterminacy $\mM$. To do this, first solve
        \begin{align}
            \min_{\mM} \sum_{j=1}^p 
            \frac{1}{| (\mM \mW)_{jj} |}
            \;, \quad
            \mW = \sum_{i=1}^m \operatorname{abs}(\mW^i) \;,
        \end{align}
        and then update
        \begin{align}
            \mM_{ij} \leftarrow \frac{\mM_{ij}}{(\mM \mW)_{ii}} \enspace.
        \end{align}
        
        \item Determine the causal matrices $\mB^i = \mI - \mM \mW^i$.
        
        \item Determine the causal ordering. If the causal ordering $\mP^i$ is view-dependent, solve
        \begin{align}
            \min_{\mP^i} \sum_{l \geq k} \big(
            \mP^i \mB^i (\mP^i)^\top
            \big)_{kl}^2 \enspace.
        \end{align}
        If the causal ordering $\mP$ is shared across views, solve instead
        \begin{align}
            \min_{\mP} \sum_{l \geq k} \big(
            \mP \mB {\mP}^\top
            \big)_{kl}^2
            \;, \quad
            \mB = \sum_{i=1}^m \operatorname{abs}(\mB^i) \;.
        \end{align}
        
    \end{enumerate}
\end{algorithm}

Note that in the special case when there is only a single view and at most one Gaussian disturbance, our estimation algorithm for MICaDo recovers the ICA-based estimation for LiNGAM proposed by~\citet{shimizu2006linear}.
