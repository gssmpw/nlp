
\section{A Linear Multi-View Acyclic Model} 
\label{sec:theory}
Next, we propose a new multi-view model for causal discovery. It is a generalization of LiNGAM, but we generalize its identifiability to the Gaussian case.

\paragraph{Definition of a multi-view model for causal discovery}
We can extend the model in \eqref{eq:causal_model} to the setup where the observations are collected from different views $i \in \llbracket 1, m \rrbracket$.
In such a multi-view context, one can impose different conditions to exploit the group structure: for example, the causal order $\mP$ could be common over the views, or there might be some similarities between the disturbances.

We choose to model the disturbances as a sum of \textit{common disturbances} $\vs$ and \textit{view-specific noises} $\vn^i$, inspired by multi-view ICA in \eqref{eq:multiview_ica_model}.
We thus define a generalization of the model in~\eqref{eq:causal_model} as
\begin{align}
    \label{eq:multiview_causal_model}
    \vx^i = \mB^i \vx^i + \vs + \vn^i
\end{align}
where each $\mB^i$ is a DAG, and we make the following statistical assumptions: 1) The common disturbances $s_j$ (i.e.\ the entries of $\vs$) are all mutually independent, but no assumption is made on their marginal distributions, such as their non-Gaussianity. 2) The view-specific noises $n_j^i$ are assumed to depend on the view $i$, in the sense of satisfying $\vn^i \sim \cN(\vzero, \mSigma^i)$, where the $\mSigma^i$ are diagonal matrices. 3) The vectors $\vs$ and $\vn^i,i=1\ldots,m$ are assumed mutually independent.

\paragraph{Two scenarios for causal ordering}
We consider two different scenarios for the $\mB^i$. 
On the one hand, we can assume that the $\mB^i$ are independent of each other. That means that each $\mB^i$ can be decomposed with its own causal ordering matrix $\mP^i$ and lower diagonal matrix $\mT^i$ as
\begin{equation}
    \label{eq:decomposition_multiple_causal_orderings}
    \mB^i = (\mP^i)^\top \mT^i \mP^i
    \enspace.
\end{equation}
This we call the model with \textit{multiple causal orderings}.
On the other hand, we consider a constrained case where the causal orders are shared by all views.
This means that each $\mB^i$ is decomposed as
\begin{equation}
    \label{eq:def_B_tilde_i}
    \mB^i = \mP^\top \mT^i \mP
\end{equation}
where the causal ordering $\mP$ of the DAGs is the same across views. This latter case we call the model with \textit{shared causal ordering}.
Such a shared $\mP$ or causal order contains information about all views and can be very useful when estimating view-specific causalities is too inaccurate. If the amount of data per view is very limited, such a shared causal ordering may be the only quantity that can be reliably estimated from the data.

This completes the definition of our Linear Multi-View Acyclic Model (LiMVAM). It has two variants depending on whether the causal orderings are constrained to be shared or not.

\paragraph{Relation to Multi-view ICA}
Our model can be rewritten as a multi-view ICA model as in \eqref{eq:multiview_ica_model}, just like in the case of LiNGAM.
Thus, the methods developed for multi-view ICA can be used to estimate the matrices $\mA^i$, as well as to analyze its identifiability.
Again, it is important to note that the view-dependent mixing matrix $\mA^i$ is structured: it is specifically equal to 
$\mA^i = (\mI - \mB^i)^{-1}$; in the shared causal ordering case, even further structure is imposed.
Importantly, the theory of Shared ICA \textit{does not require the common disturbances $\vs$ to be non-Gaussian}~\citep{richard2021sharedica,anderson2013multiviewidentifiability}, as soon as there are at least 3 views and there is sufficient diversity in the view-specific noises; this condition will be made rigorous in the next section. This makes our multi-view model more widely applicable as well: we can prove its identifiability regardless of the Gaussianity of the common disturbances $\vs$.

\section{Identifiability theory}
Now we proceed to show the identifiability of the proposed model, in its different variants.
As in~\citet{richard2021sharedica}, the following assumption is central.
\begin{assumption}[Noise diversity]
    \label{assump:noise_diversity}
    Let $j$ and $j'$, $j \neq j'$, be the indices of two Gaussian common disturbances in $\vs$.
    Then, the sequences $(\mSigma^i_{jj})_{i=1, \dots, m}$ and $(\mSigma^i_{j'j'})_{i=1, \dots, m}$ are different.
\end{assumption}

The following theorem gives a fundamental identifiability result, ensuring the identifiability of the causal matrices ${\mB}^i$ under Assumption~\ref{assump:noise_diversity}.

\begin{theorem}(Identifiability of the causal matrices)          
\label{theorem:identifiability_B_tilde_i}
     Under Assumption~\ref{assump:noise_diversity}, the LiMVAM model (whether with multiple or shared causal orderings)
    is identifiable in the sense that the parameters $\mB^i$ and $\mSigma^i$ are identifiable.    
\end{theorem}
We reiterate that no assumption of non-Gaussianity is made here, only that shared Gaussian disturbances have enough noise diversity according to Assumption~\ref{assump:noise_diversity}.

Next, we proceed to the question of the identifiability of the causal ordering.
As mentioned above, the identifiability of the $\mB^i$ does not necessarily mean that their decomposition in~\eqref{eq:def_B_tilde_i} with $\mT^i$ and $\mP$ (or in~\eqref{eq:decomposition_multiple_causal_orderings} with $\mT^i$ and $\mP^i$) is unique.
Here, with possible abuse of terminology, we say that the $\mP$ is ``identifiable" if it can be uniquely defined based on the $\mB^i$ (see footnote~\ref{footnote:1} above for a discussion on this point), and we thus consider $\mP$ as if it were a parameter of the model.

It turns out that in the view-specific $\mP^i$ case, identifiability is obtained by assuming that the directed acyclic graph $\mB^i$ is dense enough in each view, as formalized in the following assumption.
However, since the $\mB^i$ can be permuted to strictly lower triangular matrices, they cannot have more than $\frac{p(p-1)}{2}$ non-zero entries.
\begin{assumption}[Dense connectivity in each view]
\label{assump:total_order_different_Pi}
    For each view $i$, the matrix $\mB^i$ has exactly $\frac{p(p-1)}{2}$ non-zero entries. 
\end{assumption}

Using Assumption~\ref{assump:total_order_different_Pi}, the following theorem states that, in addition to identifying $\mB^i$ and $\mSigma^i$, one can also identify $\mT^i$ and $\mP^i$.

\begin{theorem}(Identifiability of multiple causal orderings)
    \label{theorem:identifiability_multiview_different_Pi}
    Consider the LiMVAM model with multiple causal orderings. Consider the quantities $(\mSigma^1, \dots, \mSigma^m, \mP^1, \dots, \mP^m, \mT^1, \dots, \mT^m)$ as the set of parameters to be estimated. 
    Under Assumptions~\ref{assump:noise_diversity} and~\ref{assump:total_order_different_Pi}, all these parameters are identifiable.
\end{theorem}
However, Assumption~\ref{assump:total_order_different_Pi} may be considered rather severe because it prevents the strictly lower triangular part of $\mT^i$ matrices from being sparse.
Moreover, in the case of view-specific orderings $\mP^i$, the main quantity of interest is probably $\mB^i$ rather than $\mT^i$ and $\mP^i$, which limits the interest of Theorem~\ref{theorem:identifiability_multiview_different_Pi}.

On the other hand, the scenario of a shared $\mP$ is very interesting and specific to the multi-view model. 
In fact, the identifiability in this scenario can be obtained with weaker conditions. Consider the following assumption.

\begin{assumption}[Dense connectivity when pooled across views]
\label{assump:total_order_shared_P}
    There exists a permutation $\bar{\mP}$ such that the matrices $\bar{\mT}^i = \bar{\mP} \mB^i \bar{\mP}^\top$ are strictly lower triangular, and for each entry $(j, k)$ with $j > k$, there is at least one view $i$ such that $\bar{\mT}^i_{j, k} \neq 0$.
\end{assumption}

Under the DAG constraint with shared causal ordering, Assumption~\ref{assump:total_order_different_Pi} implies Assumption~\ref{assump:total_order_shared_P}.
So, Assumption~\ref{assump:total_order_shared_P} is much weaker than Assumption~\ref{assump:total_order_different_Pi}, as it allows the $\mT^i$ to be very sparse. This is especially the case when the number of views is large, since only one non-zero entry is required over all views.
The following theorem states the identifiability of our model in the case of a shared $\mP$ and under Assumptions~\ref{assump:noise_diversity} and~\ref{assump:total_order_shared_P}.

\begin{theorem}(Identifiability of a shared causal ordering)
\label{theorem:identifiability_multiview_shared_P}
    Consider the LiMVAM model with shared causal ordering.
    Consider the quantities $(\mSigma^1, \dots, \mSigma^m, \mP, \mT^1, \dots, \mT^m)$ as the set of parameters to be estimated.
    Under Assumptions~\ref{assump:noise_diversity} and~\ref{assump:total_order_shared_P},
    all these parameters are identifiable.
\end{theorem}
In other words, the \textit{common} causal ordering $\mP$ is now perfectly identifiable, and under weaker conditions than above. We point out that this last part of our identifiability theory is based on a very novel approach specific to the multi-view case.
The proofs of the theorems are given in Appendix~\ref{app:sec:multiview_lingam}.
