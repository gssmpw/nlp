
\section{Introduction}
\label{sec:intro}

Causal discovery is a fundamental problem in scientific data analysis as well as several technological applications \citep{peters2017elements}. The basic problem is that we are given a number of observed variables, and we need to infer or learn which variables cause which, and with what ``connection strengths". In the typical case, we only observe the data passively without any possibility of performing interventions, and this purely observational quality of the data makes the problem difficult.

Typically, the problem is formalized as a structural equation model (SEM)~\citep{bollen1989structural}, also called a functional causal model. Then the question is how to estimate the SEM using statistical theory. In fact, before even considering estimation methods, we need to know if it is at all possible to solve the problem. This is the question of \textit{identifiability} of the model: can the parameters that describe the causal relations and directions be (uniquely) estimated?

A well-known fact is that if all the variables are Gaussian, the model is \textit{not} identifiable without further strong assumptions. The literature proposes different kinds of further assumptions to actually enable identifiability. Some of the earliest work showed the directions can sometimes be recovered by an analysis of the \textit{conditional independencies} \citep{spirtes2001causation}; however, this is only possible in some special cases and notably not possible in the case of observing only two variables. A major advance was to consider a linear model together with \textit{non-Gaussianity} \citep{shimizu2006linear}, which leads to full identifiability of the model under weak conditions such as notably acyclicity; however, such non-Gaussianity may not be clearly visible in many data sets. A related framework was proposed by assuming that the cause undergoes a \textit{nonlinear transform}, while the disturbance is still additive \citep{hoyer2008nonlinear}; however the nonlinearity may not be clearly visible in many applications, and it slightly contradicts the additivity of the disturbance. Further frameworks were proposed by \citet{peters2014identifiability,Zhang09UAI,Monti19UAI}.

Here, we consider the linear, multi-view case, i.e.\ we assume that several related data sets are observed, and the model is linear. In particular, we assume that the disturbances (also called external influences, or noise)  have some shared information among the data sets, but are not identical. The main novelty in our framework is that we show how the multi-view information leads to a new kind of identifiability result: the model is fully identifiable even if all the variables are Gaussian, and without any special assumptions on the structure of the SEM, other than the ubiquituous acyclicity (``DAG") assumption. To compensate the lack of non-Gaussianity, we do need an assumption that the variances of the disturbances in different views are distinct; thus, it is the variability over views that allows for identifiability. While the multi-view case has been considered by \citet{shimizu2012joint}, he did not consider disturbances with some shared information among the data sets. Furthermore, he only showed how to use the multiple views to improve the estimation, still assuming non-Gaussianity of the disturbances.

We also develop new algorithms for such multi-view causal discovery. These are based on a recent theory of multi-view independent component analysis (ICA) proposed by \citet{richard2021sharedica}, and they can handle both Gaussian and non-Gaussian disturbances. As a practical application of the methods, we analyze brain imaging data where the different views are data from different subjects under the same stimulation. This sheds light on the causal connections between different brain regions.
