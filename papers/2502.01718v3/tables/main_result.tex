\begin{table*}[!t]
\centering
\caption{\RM's best-of-n results on several benchmarks. Specifically, -C means completion split and -I means instruct split of BigCodeBench. The $\Delta$ might be off by 0.1 due to rounding.}
\label{tab:main_bon_results}
\small
\resizebox{\textwidth}{!}{%
\begin{tabular}{lccccccccccc}
\toprule
\multirow{2}{*}{Mehod} & \multirow{2}{*}{\# N} & \multicolumn{2}{c}{HumanEval} & \multicolumn{2}{c}{MBPP} & \multicolumn{2}{c}{BigCodeBench-C} & \multicolumn{2}{c}{BigCodeBench-I} & LiveCodeBench & \multirow{2}{*}{\textbf{Average}} \\
 &  & - & Plus & - & Plus & Full & Hard & Full & Hard & V4 &  \\
 \midrule
GPT-4o (0806)       & 1 & 92.7  & 87.2 & 87.6 & 72.2 & 58.9 & 36.5 & 48.0 & 25.0 & 43.6 & 61.3  \\
DeepSeek-V2.5       & 1 & 90.2  & 83.5 & 87.6 & 74.1 & 53.2 & 29.1 & 48.9 & 27.0 & 41.8 & 59.5 \\
DeepSeek-V3         & 1 & 91.5  & 86.6 & 87.6 & 73.0 & 62.2 & 39.9 & 50.0 & 27.7 & 63.5 & 64.6 \\
Qwen2.5-Coder-32B   & 1 & 92.1  & 87.2 & 90.5 & 77.0 & 58.0 & 33.8 & 49.0 & 27.7 & 48.3 &  62.6 \\
 \midrule
\multicolumn{12}{c}{Inference Model = Mistral-7B-Instruct-V0.3} \\
 \midrule
Greedy & 1 & 36.6 & 31.1 & 49.5 & 41.3 & 25.9 & 6.1 & 20.1 & 5.4 & 7.3 & 24.8 \\
Average & 64 & 37.1 & 30.8 & 45.1 & 38.0 & 21.7 & 4.2 & 17.6 & 3.0 & 4.0 & 22.4 \\
Oracle & 64 & 87.2 & 78.0 & 83.9 & 73.5 & 68.4 & 37.8 & 58.5 & 31.1 & 24.3 & 60.3 \\
\midrule
\multirow{3}{*}{AceCodeRM-7B} & 16 & 65.9 & 56.7 & 59.3 & \textbf{52.4} & 35.1 & 10.1 & 29.3 & 8.8 & 11.9 & 36.6 \\
 & 32 & 68.3 & 58.5 & 59.8 & 51.6 & 37.4 & 8.8 & 30.7 & 10.8 & 14.6 & 37.8 \\
 & 64 & 71.3 & 61.6 & 59.8 & 51.6 & 39.4 & 6.8 & 31.8 & 9.5 & 15.4 & 38.6 \\
\rowcolor{LightCyan}
 $\Delta$ (RM-greedy) & - & +34.8 & +30.5 & +10.3 & +11.1 & +13.5 & +4.1 & +11.7 & +5.4 & +8.1 & +13.8 \\
\midrule
\multirow{3}{*}{AceCodeRM-32B} & 16 & 68.3 & 61.0 & 58.7 & 49.5 & 37.7 & 11.5 & 30.9 & 10.1 & 12.9 & 37.8 \\
 & 32 & 72.6 & \textbf{65.9} & \textbf{61.6} & 51.6 & 40.5 & 9.5 & 33.9 & 13.5 & 16.1 & 40.6 \\
 & 64 & \textbf{75.0} & 64.6 & 60.6 & 50.0 & \textbf{42.7} & \textbf{15.5} & \textbf{35.6} & \textbf{13.5} & \textbf{17.4} & \textbf{41.7} \\
\rowcolor{LightCyan}
$\Delta$ (RM-greedy) & - & +38.4 & +34.8 & +12.2 & +11.1 & +16.8 & +9.5 & +15.5 & +8.1 & +10.1 & +16.9 \\
\midrule
\multicolumn{12}{c}{Inference Model = Llama-3.1-8B-Instruct} \\
 \midrule
Greedy & 1 & 68.9 & 62.2 & 67.2 & 54.8 & 38.5 & 12.8 & 31.8 & 13.5 & 18.0 & 40.9 \\
Average & 64 & 61.7 & 54.9 & 64.5 & 54.5 & 32.8 & 10.1 & 26.6 & 9.0 & 13.8 & 36.4 \\
Oracle & 64 & 93.9 & 90.2 & 92.1 & 82.3 & 80.0 & 54.7 & 67.9 & 48.6 & 40.8 & 72.3 \\
\midrule  
\multirow{3}{*}{AceCodeRM-7B} & 16 & 77.4 & 70.7 & \textbf{76.5} & \textbf{64.3} & 45.8 & 20.3 & 36.4 & 12.2 & 26.1 & 47.7 \\
 & 32 & 79.9 & 72.6 & 76.2 & 62.4 & 47.6 & 23.0 & 37.3 & 13.5 & 27.3 & 48.9 \\
 & 64 & 81.7 & 74.4 & 74.6 & 61.9 & 47.8 & \textbf{23.6} & 38.1 & 13.5 & 27.6 & 49.3 \\
\rowcolor{LightCyan}
 $\Delta$ (RM-greedy) & - & +12.8 & +12.2 & +9.3 & +9.5 & +9.3 & +10.8 & +6.2 & 0.0 & +9.6 & +8.4 \\
 \midrule
\multirow{3}{*}{AceCodeRM-32B} & 16 & 82.3 & 74.4 & 72.8 & 60.6 & 49.8 & 20.3 & 38.4 & 13.5 & 27.5 & 48.8 \\
 & 32 & 81.7 & 76.2 & 72.8 & 60.6 & \textbf{50.4} & 22.3 & 39.1 & 13.5 & 30.3 & 49.6 \\
 & 64 & \textbf{85.4} & \textbf{79.3} & 72.0 & 59.0 & 48.5 & 19.6 & \textbf{40.0} & \textbf{13.5} & \textbf{31.0} & \textbf{49.8} \\
\rowcolor{LightCyan}
$\Delta$ (RM-greedy) & - & +16.5 & +17.1 & +9.3 & +9.5 & +11.8 & +10.8 & +8.2 & +0.0 & +13.0 & +9.0 \\
\midrule
\multicolumn{12}{c}{Inference Model = Qwen2.5-Coder-7B-Instruct} \\
 \midrule
Greedy & 1 & \textbf{91.5} & 86.0 & 82.8 & 71.4 & 49.5 & 19.6 & 41.8 & 20.3 & 34.2 & 55.2 \\
Average & 64 & 86.0 & 80.1 & 77.9 & 65.6 & 45.3 & 18.6 & 37.3 & 16.2 & 31.8 & 51.0 \\
Oracle & 64 & 98.2 & 95.7 & 97.4 & 90.7 & 80.9 & 62.8 & 73.5 & 53.4 & 57.4 & 78.9 \\
\midrule
\multirow{3}{*}{AceCodeRM-7B} & 16 & 90.2 & 82.9 & \textbf{88.6} & 74.9 & 53.8 & 20.9 & 45.0 & 21.6 & 40.1 & 57.6 \\
 & 32 & 90.9 & 86.0 & 87.8 & 74.1 & 53.4 & 25.0 & 43.9 & 19.6 & 39.8 & 57.8 \\
 & 64 & 90.9 & 85.4 & 87.6 & 73.8 & 52.9 & 24.3 & 43.5 & 21.6 & 40.1 & 57.8 \\
\rowcolor{LightCyan}
 $\Delta$ (RM-greedy) & - & -0.6 & 0.0 & +5.8 & +3.4 & +4.3 & +5.4 & +3.2 & +1.4 & +5.9 & +2.6 \\
 \midrule
\multirow{3}{*}{AceCodeRM-32B} & 16 & 90.2 & 86.6 & 88.4 & 74.9 & 53.9 & 25.0 & 45.4 & 19.6 & 44.0 & 58.7 \\
 & 32 & 90.2 & \textbf{86.6} & 88.4 & \textbf{75.4} & \textbf{55.4} & \textbf{29.7} & 45.6 & 21.6 & 43.5 & \textbf{59.6}     \\
 & 64 & 89.6 & 86.0 & 87.8 & 75.1 & 55.0 & 26.4 & \textbf{46.1} & \textbf{22.3} & \textbf{44.5} & 59.2 \\
\rowcolor{LightCyan}
$\Delta$ (RM-greedy) & - & -0.6 & +0.6 & +5.8 & +4.0 & +6.0 & +10.1 & +4.3 & +2.0 & +10.3 & +4.4 \\
\bottomrule
\end{tabular}
}
\end{table*}