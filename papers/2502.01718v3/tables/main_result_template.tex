\begin{table*}[!tbh]
    \centering
    \caption{CodeRM's best-of-n results. We evaluated the model on MBPP, HumanEval (HE), BigCodeBench (BCB), and LiveCodeBench (LCB). Specifically, we have evaluated the Completion (C) and Instruct (I) splits of BCB for both Hard (H) and Full (F) versions, and also the plus version for MBPP and HE.}
    \label{tab:wide-table}
    \small
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{llccccccccc}
        \toprule
        \makecell{Policy Model} & 
        \makecell{Method} & 
        \makecell{BCB-C-F} & 
        \makecell{BCB-C-H} & 
        \makecell{BCB-I-F} &
        \makecell{BCB-I-H} &
        \makecell{HE} & 
        \makecell{HE+} & 
        \makecell{LCB} &
        \makecell{MBPP} & 
        \makecell{MBPP+} \\
        \midrule
        \multirow[c]{4}{*}{CodeLlama-Ins} & CodeRM & \bfseries 32.46 & \bfseries 9.46 & \bfseries 26.84 & \bfseries 5.41 & \bfseries 59.15 & \bfseries 51.22 & \bfseries 16.69 & \bfseries 61.11 & \bfseries 51.32 \\
        & average & 14.84 & 2.53 & 11.06 & 1.60 & 31.10 & 26.64 & 8.81 & 46.28 & 39.37 \\
        & greedy & 24.21 & 4.05 & 22.54 & 4.05 & 40.24 & 34.76 & 9.47 & 54.23 & 45.50 \\
        & oracle & 51.49 & 22.30 & 42.98 & 14.86 & 75.00 & 69.51 & 19.78 & 82.28 & 71.43 \\
        \midrule
        \multirow[c]{4}{*}{Llama-3.1-Ins} & CodeRM & \bfseries 43.51 & \bfseries 17.57 & \bfseries 34.39 & \bfseries 16.22 & \bfseries 73.17 & \bfseries 66.46 & \bfseries 25.67 & \bfseries 76.19 & \bfseries 63.23 \\
        & average & 31.09 & 8.83 & 25.87 & 9.04 & 61.43 & 54.19 & 13.83 & 64.70 & 54.81 \\
        & greedy & 38.51 & 12.84 & 31.84 & 13.51 & 68.90 & 62.20 & 17.99 & 67.20 & 54.76 \\
        & oracle & 65.96 & 39.86 & 58.60 & 31.08 & 89.02 & 82.93 & 32.82 & 88.62 & 79.10 \\
        \midrule
        \multirow[c]{4}{*}{Mistral-Ins V0.3} & CodeRM & \bfseries 34.04 & \bfseries 7.43 & \bfseries 27.54 & \bfseries 7.43 & \bfseries 61.59 & \bfseries 53.05 & nan & \bfseries 58.99 & \bfseries 49.74 \\
        & average & 20.33 & 4.10 & 16.04 & 2.70 & 37.04 & 30.95 & nan & 44.59 & 37.78 \\
        & greedy & 25.88 & 6.08 & 20.09 & 5.41 & 36.59 & 31.10 & nan & 49.47 & 41.27 \\
        & oracle & 52.72 & 25.68 & 44.04 & 18.92 & 75.00 & 68.90 & nan & 75.93 & 65.61 \\
        \midrule
        \multirow[c]{4}{*}{Qwen-Coder-2.5} & CodeRM & \bfseries 50.18 & \bfseries 27.70 & \bfseries 44.91 & \bfseries 22.97 & 90.85 & 85.37 & \bfseries 38.29 & \bfseries 85.19 & \bfseries 72.22 \\
        & average & 42.69 & 16.34 & 37.75 & 14.95 & 85.21 & 79.23 & 31.74 & 77.60 & 64.83 \\
        & greedy & 49.47 & 19.59 & 41.84 & 20.27 & \bfseries 91.46 & \bfseries 85.98 & 34.19 & 82.80 & 71.43 \\
        & oracle & 69.74 & 50.00 & 66.40 & 41.22 & 96.34 & 92.68 & 51.47 & 96.03 & 87.30 \\
        \bottomrule
        \end{tabular}
        }
\end{table*}


\begin{table*}[!tbh]
\centering
    \caption{CodeRM's best-of-n results. We evaluated the model on MBPP, HumanEval (HE), BigCodeBench (BCB), and LiveCodeBench (LCB). Specifically, we have evaluated the Completion (C) and Instruct (I) splits of BCB for both Hard (H) and Full (F) versions, and also the plus version for MBPP and HE.}
    \label{tab:wide-table}
    \small
    \resizebox{\textwidth}{!}{
        \begin{tabular}{ccclllllllll}
            \toprule
            \multirow{2}{*}{Policy Model} & \multirow{2}{*}{Method} & \multirow{2}{*}{\# N} & \multicolumn{2}{c}{HumanEval} & \multicolumn{2}{c}{MBPP} & \multicolumn{2}{c}{BigCode (C)} & \multicolumn{2}{c}{BigCode (I)} & \multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}LiveCode\\ V4\end{tabular}} \\
             &  &  & \multicolumn{1}{c}{Base} & \multicolumn{1}{c}{Plus} & \multicolumn{1}{c}{Base} & \multicolumn{1}{c}{Plus} & \multicolumn{1}{c}{Full} & \multicolumn{1}{c}{Hard} & \multicolumn{1}{c}{Full} & \multicolumn{1}{c}{Hard} &  \\
             \midrule
            \multirow{9}{*}{\begin{tabular}[c]{@{}c@{}}CodeLlama\\ -Ins-7B\end{tabular}} & Greedy & 1 &  &  &  &  &  &  &  &  &  \\
             & Random & 64 &  &  &  &  &  &  &  &  &  \\
             & Oracle & 64 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 16 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 32 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 64 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 16 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 32 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 64 &  &  &  &  &  &  &  &  &  \\
             \midrule
            \multirow{9}{*}{\begin{tabular}[c]{@{}c@{}}Llama-3.1\\ -Ins-8B\end{tabular}} & Greedy & 1 &  &  &  &  &  &  &  &  &  \\
             & Random & 64 &  &  &  &  &  &  &  &  &  \\
             & Oracle & 64 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 16 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 32 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 64 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 16 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 32 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 64 &  &  &  &  &  &  &  &  &  \\
             \midrule
            \multirow{9}{*}{\begin{tabular}[c]{@{}c@{}}Mistral\\ -Ins-V0.3-7B\end{tabular}} & Greedy & 1 &  &  &  &  &  &  &  &  &  \\
             & Random & 64 &  &  &  &  &  &  &  &  &  \\
             & Oracle & 64 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 16 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 32 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 64 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 16 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 32 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 64 &  &  &  &  &  &  &  &  &  \\
             \midrule
            \multirow{9}{*}{\begin{tabular}[c]{@{}c@{}}Qwen\\ -Coder-2.5-7B\end{tabular}} & Greedy & 1 &  &  &  &  &  &  &  &  &  \\
             & Random & 64 &  &  &  &  &  &  &  &  &  \\
             & Oracle & 64 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 16 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 32 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-7B & 64 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 16 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 32 &  &  &  &  &  &  &  &  &  \\
             & CodeRM-32B & 64 &  &  &  &  &  &  &  &  &  \\
             \bottomrule
            \end{tabular}
     }
\end{table*}


