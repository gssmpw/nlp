\section{Related Work}
\vspace{-0.1cm}
\label{related_work}
\subsection{Vision Foundation Models}
Vision-Language Models (VLMs) ____ are trained using massive datasets that pair images with text. These models utilize distinct encoders for image modality and text modality to generate embeddings, respectively. During training, they employ a contrastive learning objective to enhance the alignment of embeddings from positively correlated image-text pairs. A primary use of these models is in tasks such as zero-shot image-text retrieval or zero-shot classification through textual prompts ____. Additionally, models like ViLT____, VLMo____, and BLIP____ have been designed to enhance zero-shot capabilities of visual question answering and image captioning. Methods such as LiT____, and BLIP-2____ have been developed to minimize the training expenses for CLIP-like architectures by utilizing pre-trained unimodal models. SAM ____ can produce segmentation masks effectively, while it is hindered in widely practical use owing to prompt necessity, coarser segmentation, and slow segmentation speed. To tackle SAM's such weaknesses, this paper proposes an interpretable, high-fidelity and prompt-free annotator LAM by leveraging an unrolling optimization mechanism and a single pre-annotated RGB seed image. 

\subsection{Prompt Engineering}
\vspace{-0.1cm}
Prompt engineering ____ has become a pivotal strategy for boosting the functionality of pre-trained large language models (LLMs) ____ and VLMs ____. It entails the deliberate creation of task-specific directives (known as prompts) to direct the output of models without modifying their parameters. Prompt engineering is particularly prominent in enhancing the flexibility of LLMs and VLMs ____, which allows these models to perform excellently across a variety of tasks and fields. This flexibility marks a departure from conventional methods that typically require retraining or extensive fine-tuning for specific task. As prompt engineering continues to evolve, ongoing research continually uncovers new methods ____ and applications ____. Current researches on prompt engineering include a range of techniques, such as zero-shot prompts ____, few-shot prompts ____, etc. Despite such achievements of prompt engineering, crafting effective prompts often requires deep expertise not only in the model's workings but also in the specific domain knowledge ____. This can limit the application of prompt engineering. To surmount such prompt's limitations, this paper proposes to provide a pre-annotated RGB seed image instead of image-specific prompts to enhance the quality of annotations.