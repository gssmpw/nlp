\section{RELATED WORK}
\subsection{Multi-modal datasets}
The availability of high-quality datasets has significantly advanced research in 3D perception tasks, such as segmentation, object detection, and tracking. However, existing datasets often differ in their design focus, environmental settings, and annotation granularity. To provide a structured overview, we categorize related datasets into three types.

\textbf{Structrured.} Structured datasets, designed for controlled environments like urban roads, focus on vehicular scenarios with annotations for vehicles and traffic-related objects. The KITTI dataset~\cite{kitti} pioneered 3D object detection with LiDAR and image data, but the limited size and pedestrian diversity restrict its use in studying pedestrian dynamics. Datasets like nuScenes~\cite{nuscenes} and Waymo Open Dataset~\cite{waymo} expanded the scope with multimodal data, including LiDAR, cameras, and radar, alongside 3D annotations. Other structured datasets, such as ApolloScape~\cite{huang2018apolloscape} and Argoverse~\cite{chang2019argoverse}, offer traffic-related annotations but lack focus on complex pedestrian dynamics. However, these datasets are primarily vehicle-centric, with limited attention to pedestrian behavior in dense or unstructured settings.

\textbf{Semi-Structured.} Semi-structured datasets capture environments like campus paths and parking lots, where irregular pedestrian flows and occlusions present unique challenges. Datasets such as H3D~\cite{h3d} and PandaSet~\cite{pandaset} offer multimodal annotations for 3D detection and segmentation in semi-structured settings but are not abundant. Our dataset, PFSD, fills this gap by focusing on dynamic pedestrian interactions in irregular environments, with rich annotations for segmentation, detection, and tracking.

\textbf{Unstructured.} Unstructured environments feature minimal organization and no clearly defined pathways, such as forests, disaster zones, and rural areas. Rellis-3D~\cite{rellis}, which focuses on segmentation and obstacle detection in unstructured rural settings but typically lacks pedestrian annotations and fails to capture pedestrian-specific dynamics. This makes it unsuitable for studying pedestrian perception in mixed environments, leaving a gap in research that datasets like PFSD aim to address.

\begin{figure}[t!]
    \centering
    \includegraphics[width=8.5cm]{detection1.pdf}
    \caption{Illustration of pedestrian detection in various semi-structured scenes, highlighting the richness of pedestrian annotations and the complexity of semi-structured environments in both images and point clouds.}
    \label{fig:detection}
\end{figure}

\subsection{3D object detection}

3D object detection has made significant strides in recent years and various approaches have been developed to handle the unique challenges of point-cloud data, which are inherently unstructured and sparse. The primary approaches can be categorized into different methods, each offering distinct advantages and facing specific limitations. 

\textbf{Point-based} methods operate directly on raw point clouds, preserving fine details. PointNet~\cite{qi2017pointnet} introduced this approach using MLPs but struggled with local structure. PointNet++~\cite{qi2017pointnet++} improved this by introducing multi-scale grouping. PointRCNN~\cite{shi2019pointrcnn} further refined this with a two-stage 3D bounding box prediction to enhance accuracy.

\textbf{Voxel-based} methods convert point clouds into voxel grids and use 3D convolutions. VoxelNet~\cite{zhou2018voxelnet} showed the potential of 3D CNNs, though it was computationally expensive. SECOND~\cite{yan2018second} reduced computational costs using sparse convolutions, enabling real-time tasks.

\textbf{Pillar-based} methods convert point clouds into vertical pillars for efficient 2D convolutions, improving detection speed. PointPillars~\cite{lang2019pointpillars} pioneered this approach, while PillarNet~\cite{qi2017pointnet} enhanced it with sparse convolutions.