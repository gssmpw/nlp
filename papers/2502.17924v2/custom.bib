% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}


@article{chen2023vlp,
  title={Vlp: A survey on vision-language pre-training},
  author={Chen, Fei-Long and Zhang, Du-Zhen and Han, Ming-Lun and Chen, Xiu-Yi and Shi, Jing and Xu, Shuang and Xu, Bo},
  journal={Machine Intelligence Research},
  volume={20},
  number={1},
  pages={38--56},
  year={2023},
  publisher={Springer}
}
@article{zhang2024mm,
  title={Mm-llms: Recent advances in multimodal large language models},
  author={Zhang, Duzhen and Yu, Yahan and Li, Chenxing and Dong, Jiahua and Su, Dan and Chu, Chenhui and Yu, Dong},
  journal={arXiv preprint arXiv:2401.13601},
  year={2024}
}

@misc{li2024mmcode,
	title={MMCode: Evaluating Multi-Modal Code Large Language Models with Visually Rich Programming Problems}, 
	author={Kaixin Li and Yuchen Tian and Qisheng Hu and Ziyang Luo and Jing Ma},
	year={2024},
	eprint={2404.09486},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@inproceedings{NEURIPS2023_98d0ad88,
	author = {Li, Ting and Shi, Chengchun and Wang, Jianing and Zhou, Fan and zhu, hongtu},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {A. Oh and T. Neumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
	pages = {48890--48905},
	publisher = {Curran Associates, Inc.},
	title = {Optimal Treatment Allocation for Efficient Policy Evaluation in Sequential Decision Making},
	url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/98d0ad88db1e51bd0aa341a823290ece-Paper-Conference.pdf},
	volume = {36},
	year = {2023}
}


@InProceedings{Rombach_2022_CVPR,
	author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
	title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
	booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	month     = {June},
	year      = {2022},
	pages     = {10684-10695}
}


@misc{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{hudson2019gqa,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6700--6709},
  year={2019}
}

@article{lu2022learn,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2507--2521},
  year={2022}
}

@article{fu2023mme,
  title={MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models},
  author={Fu, Chaoyou and Chen, Peixian and Shen, Yunhang and Qin, Yulei and Zhang, Mengdan and Lin, Xu and Qiu, Zhenyu and Lin, Wei and Yang, Jinrui and Zheng, Xiawu and others},
  journal={arXiv preprint arXiv:2306.13394},
  year={2023}
}

@misc{xu2023wizardlm,
      title={WizardLM: Empowering Large Language Models to Follow Complex Instructions}, 
      author={Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Daxin Jiang},
      year={2023},
      eprint={2304.12244},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhou2023lima,
      title={LIMA: Less Is More for Alignment}, 
      author={Chunting Zhou and Pengfei Liu and Puxin Xu and Srini Iyer and Jiao Sun and Yuning Mao and Xuezhe Ma and Avia Efrat and Ping Yu and Lili Yu and Susan Zhang and Gargi Ghosh and Mike Lewis and Luke Zettlemoyer and Omer Levy},
      year={2023},
      eprint={2305.11206},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wang2023selfinstruct,
      title={Self-Instruct: Aligning Language Models with Self-Generated Instructions}, 
      author={Yizhong Wang and Yeganeh Kordi and Swaroop Mishra and Alisa Liu and Noah A. Smith and Daniel Khashabi and Hannaneh Hajishirzi},
      year={2023},
      eprint={2212.10560},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{li2023selfalignment,
      title={Self-Alignment with Instruction Backtranslation}, 
      author={Xian Li and Ping Yu and Chunting Zhou and Timo Schick and Luke Zettlemoyer and Omer Levy and Jason Weston and Mike Lewis},
      year={2023},
      eprint={2308.06259},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{mukherjee2023orca,
      title={Orca: Progressive Learning from Complex Explanation Traces of GPT-4}, 
      author={Subhabrata Mukherjee and Arindam Mitra and Ganesh Jawahar and Sahaj Agarwal and Hamid Palangi and Ahmed Awadallah},
      year={2023},
      eprint={2306.02707},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{luo2023wizardmath,
      title={WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct}, 
      author={Haipeng Luo and Qingfeng Sun and Can Xu and Pu Zhao and Jianguang Lou and Chongyang Tao and Xiubo Geng and Qingwei Lin and Shifeng Chen and Dongmei Zhang},
      year={2023},
      eprint={2308.09583},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{opt,
      title={OPT: Open Pre-trained Transformer Language Models}, 
      author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
      year={2022},
      eprint={2205.01068},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zeng2023glm130b,
      title={GLM-130B: An Open Bilingual Pre-trained Model}, 
      author={Aohan Zeng and Xiao Liu and Zhengxiao Du and Zihan Wang and Hanyu Lai and Ming Ding and Zhuoyi Yang and Yifan Xu and Wendi Zheng and Xiao Xia and Weng Lam Tam and Zixuan Ma and Yufei Xue and Jidong Zhai and Wenguang Chen and Peng Zhang and Yuxiao Dong and Jie Tang},
      year={2023},
      eprint={2210.02414},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{tay2023ul2,
      title={UL2: Unifying Language Learning Paradigms}, 
      author={Yi Tay and Mostafa Dehghani and Vinh Q. Tran and Xavier Garcia and Jason Wei and Xuezhi Wang and Hyung Won Chung and Siamak Shakeri and Dara Bahri and Tal Schuster and Huaixiu Steven Zheng and Denny Zhou and Neil Houlsby and Donald Metzler},
      year={2023},
      eprint={2205.05131},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{black2022gptneox20b,
      title={GPT-NeoX-20B: An Open-Source Autoregressive Language Model}, 
      author={Sid Black and Stella Biderman and Eric Hallahan and Quentin Anthony and Leo Gao and Laurence Golding and Horace He and Connor Leahy and Kyle McDonell and Jason Phang and Michael Pieler and USVSN Sai Prashanth and Shivanshu Purohit and Laria Reynolds and Jonathan Tow and Ben Wang and Samuel Weinbach},
      year={2022},
      eprint={2204.06745},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gopher,
      title={Scaling Language Models: Methods, Analysis \& Insights from Training Gopher}, 
      author={Jack W. Rae and Sebastian Borgeaud and Trevor Cai and Katie Millican and Jordan Hoffmann and Francis Song and John Aslanides and Sarah Henderson and Roman Ring and Susannah Young and Eliza Rutherford and Tom Hennigan and Jacob Menick and Albin Cassirer and Richard Powell and George van den Driessche and Lisa Anne Hendricks and Maribeth Rauh and Po-Sen Huang and Amelia Glaese and Johannes Welbl and Sumanth Dathathri and Saffron Huang and Jonathan Uesato and John Mellor and Irina Higgins and Antonia Creswell and Nat McAleese and Amy Wu and Erich Elsen and Siddhant Jayakumar and Elena Buchatskaya and David Budden and Esme Sutherland and Karen Simonyan and Michela Paganini and Laurent Sifre and Lena Martens and Xiang Lorraine Li and Adhiguna Kuncoro and Aida Nematzadeh and Elena Gribovskaya and Domenic Donato and Angeliki Lazaridou and Arthur Mensch and Jean-Baptiste Lespiau and Maria Tsimpoukelli and Nikolai Grigorev and Doug Fritz and Thibault Sottiaux and Mantas Pajarskas and Toby Pohlen and Zhitao Gong and Daniel Toyama and Cyprien de Masson d'Autume and Yujia Li and Tayfun Terzi and Vladimir Mikulik and Igor Babuschkin and Aidan Clark and Diego de Las Casas and Aurelia Guy and Chris Jones and James Bradbury and Matthew Johnson and Blake Hechtman and Laura Weidinger and Iason Gabriel and William Isaac and Ed Lockhart and Simon Osindero and Laura Rimell and Chris Dyer and Oriol Vinyals and Kareem Ayoub and Jeff Stanway and Lorrayne Bennett and Demis Hassabis and Koray Kavukcuoglu and Geoffrey Irving},
      year={2022},
      eprint={2112.11446},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{Chinchilla,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={Proceedings of the 34th International Conference on Neural Information Processing Systems},
  pages={1877--1901},
  year={2020}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@inproceedings{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Gray, Alex and others},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{guo2023close,
  title={How close is chatgpt to human experts? comparison corpus, evaluation, and detection},
  author={Guo, Biyang and Zhang, Xin and Wang, Ziyuan and Jiang, Minqi and Nie, Jinran and Ding, Yuxuan and Yue, Jianwei and Wu, Yupeng},
  journal={arXiv preprint arXiv:2301.07597},
  year={2023}
}

@article{jeblick2023chatgpt,
  title={ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports},
  author={Jeblick, Katharina and Schachtner, Balthasar and Dexl, Jakob and Mittermeier, Andreas and St{\"u}ber, Anna Theresa and Topalis, Johanna and Weber, Tobias and Wesp, Philipp and Sabel, Bastian Oliver and Ricke, Jens and others},
  journal={European Radiology},
  pages={1--9},
  year={2023},
  publisher={Springer}
}

@article{luo2023wizardcoder,
  title={WizardCoder: Empowering Code Large Language Models with Evol-Instruct},
  author={Luo, Ziyang and Xu, Can and Zhao, Pu and Sun, Qingfeng and Geng, Xiubo and Hu, Wenxiang and Tao, Chongyang and Ma, Jing and Lin, Qingwei and Jiang, Daxin},
  journal={arXiv preprint arXiv:2306.08568},
  year={2023}
}

@article{zhang2022would,
  title={How would stance detection techniques evolve after the launch of chatgpt?},
  author={Zhang, Bowen and Ding, Daijun and Jing, Liwen},
  journal={arXiv preprint arXiv:2212.14548},
  year={2022}
}

@article{OpenAI2023GPT4TR,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.08774},
  url={https://api.semanticscholar.org/CorpusID:257532815}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@inproceedings{liu2023visual,
  title={Visual Instruction Tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@article{gong2023multimodal,
  title={Multimodal-gpt: A vision and language model for dialogue with humans},
  author={Gong, Tao and Lyu, Chengqi and Zhang, Shilong and Wang, Yudong and Zheng, Miao and Zhao, Qian and Liu, Kuikun and Zhang, Wenwei and Luo, Ping and Chen, Kai},
  journal={arXiv preprint arXiv:2305.04790},
  year={2023}
}

@article{Dai2023InstructBLIPTG,
  title={InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning},
  author={Wenliang Dai and Junnan Li and Dongxu Li and Anthony Meng Huat Tiong and Junqi Zhao and Weisheng Wang and Boyang Albert Li and Pascale Fung and Steven C. H. Hoi},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.06500},
  url={https://api.semanticscholar.org/CorpusID:258615266}
}

@inproceedings{huang2023chatgpt,
  title={Is ChatGPT better than Human Annotators? Potential and Limitations of ChatGPT in Explaining Implicit Hate Speech},
  author={Huang, Fan and Kwak, Haewoon and An, Jisun},
  booktitle={Companion Proceedings of the ACM Web Conference 2023},
  pages={294--297},
  year={2023}
}

@inproceedings{an2021predicting,
  title={Predicting Anti-Asian Hateful Users on Twitter during COVID-19},
  author={An, Jisun and Kwak, Haewoon and Lee, Claire Seungeun and Jun, Bogang and Ahn, Yong-Yeol},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021},
  pages={4655--4666},
  year={2021}
}

@inproceedings{pramanick2021momenta,
  title={MOMENTA: A Multimodal Framework for Detecting Harmful Memes and Their Targets},
  author={Pramanick, Shraman and Sharma, Shivam and Dimitrov, Dimitar and Akhtar, Md Shad and Nakov, Preslav and Chakraborty, Tanmoy},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2021},
  pages={4439--4455},
  year={2021}
}

@inproceedings{sharma2022detecting,
  title={Detecting and understanding harmful memes: A survey},
  author={Sharma, Shivam and Alam, Firoj and Akhtar, Md Shad and Dimitrov, Dimitar and Da San Martino, Giovanni and Firooz, Hamed and Halevy, Alon and Silvestri, Fabrizio and Nakov, Preslav and Chakraborty, Tanmoy},
  booktitle={Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence},
  pages={5597--5606},
  year={2022}
}

@inproceedings{suryawanshi2020multimodal,
  title={Multimodal meme dataset (MultiOFF) for identifying offensive content in image and text},
  author={Suryawanshi, Shardul and Chakravarthi, Bharathi Raja and Arcan, Mihael and Buitelaar, Paul},
  booktitle={Proceedings of the second workshop on trolling, aggression and cyberbullying},
  pages={32--41},
  year={2020}
}

@inproceedings{kiela2020hateful,
  title={The hateful memes challenge: detecting hate speech in multimodal memes},
  author={Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Ringshia, Pratik and Testuggine, Davide},
  booktitle={Proceedings of the 34th International Conference on Neural Information Processing Systems},
  pages={2611--2624},
  year={2020}
}

@inproceedings{fersini2022semeval,
  title={SemEval-2022 Task 5: Multimedia automatic misogyny identification},
  author={Fersini, Elisabetta and Gasparini, Francesca and Rizzi, Giulia and Saibene, Aurora and Chulvi, Berta and Rosso, Paolo and Lees, Alyssa and Sorensen, Jeffrey},
  booktitle={Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022)},
  pages={533--549},
  year={2022}
}

@inproceedings{chauhan2020all,
  title={All-in-one: A deep attentive multi-task learning framework for humour, sarcasm, offensive, motivation, and sentiment on memes},
  author={Chauhan, Dushyant Singh and Dhanush, SR and Ekbal, Asif and Bhattacharyya, Pushpak},
  booktitle={Proceedings of the 1st conference of the Asia-Pacific chapter of the association for computational linguistics and the 10th international joint conference on natural language processing},
  pages={281--290},
  year={2020}
}

@article{drakett2018old,
  title={Old jokes, new media--Online sexism and constructions of gender in Internet memes},
  author={Drakett, Jessica and Rickett, Bridgette and Day, Katy and Milnes, Kate},
  journal={Feminism \& psychology},
  volume={28},
  number={1},
  pages={109--127},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}


@inproceedings{cai2019multi,
  title={Multi-modal sarcasm detection in twitter with hierarchical fusion model},
  author={Cai, Yitao and Cai, Huiyu and Wan, Xiaojun},
  booktitle={Proceedings of the 57th annual meeting of the association for computational linguistics},
  pages={2506--2515},
  year={2019}
}

@inproceedings{pramanick2021detecting,
  title={Detecting Harmful Memes and Their Targets},
  author={Pramanick, Shraman and Dimitrov, Dimitar and Mukherjee, Rituparna and Sharma, Shivam and Akhtar, Md Shad and Nakov, Preslav and Chakraborty, Tanmoy},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={2783--2796},
  year={2021}
}

@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@inproceedings{agrawal2019nocaps,
  title={Nocaps: Novel object captioning at scale},
  author={Agrawal, Harsh and Desai, Karan and Wang, Yufei and Chen, Xinlei and Jain, Rishabh and Johnson, Mark and Batra, Dhruv and Parikh, Devi and Lee, Stefan and Anderson, Peter},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8948--8957},
  year={2019}
}

@inproceedings{zellers2019recognition,
  title={From recognition to cognition: Visual commonsense reasoning},
  author={Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6720--6731},
  year={2019}
}


@article{liu2023mmbench,
  title={MMBench: Is Your Multi-modal Model an All-around Player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  journal={arXiv preprint arXiv:2307.06281},
  year={2023}
}

@article{yu2023mm,
  title={Mm-vet: Evaluating large multimodal models for integrated capabilities},
  author={Yu, Weihao and Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Liu, Zicheng and Wang, Xinchao and Wang, Lijuan},
  journal={arXiv preprint arXiv:2308.02490},
  year={2023}
}

@article{li2023seed,
  title={Seed-bench: Benchmarking multimodal llms with generative comprehension},
  author={Li, Bohao and Wang, Rui and Wang, Guangzhi and Ge, Yuying and Ge, Yixiao and Shan, Ying},
  journal={arXiv preprint arXiv:2307.16125},
  year={2023}
}

@article{yin2023lamm,
  title={LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark},
  author={Yin, Zhenfei and Wang, Jiong and Cao, Jianjian and Shi, Zhelun and Liu, Dingning and Li, Mukai and Sheng, Lu and Bai, Lei and Huang, Xiaoshui and Wang, Zhiyong and others},
  journal={arXiv preprint arXiv:2306.06687},
  year={2023}
}

@inproceedings{alayrac2022flamingo,
  title={Flamingo: a Visual Language Model for Few-Shot Learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}


@article{yang2023dawn,
  title={The dawn of lmms: Preliminary explorations with gpt-4v (ision)},
  author={Yang, Zhengyuan and Li, Linjie and Lin, Kevin and Wang, Jianfeng and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
  journal={arXiv preprint arXiv:2309.17421},
  volume={9},
  number={1},
  year={2023}
}

@article{ye2023mplug,
  title={mplug-owl: Modularization empowers large language models with multimodality},
  author={Ye, Qinghao and Xu, Haiyang and Xu, Guohai and Ye, Jiabo and Yan, Ming and Zhou, Yiyang and Wang, Junyang and Hu, Anwen and Shi, Pengcheng and Shi, Yaya and others},
  journal={arXiv preprint arXiv:2304.14178},
  year={2023}
}

@article{bai2023qwen,
  title={Qwen-vl: A frontier large vision-language model with versatile abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}

@article{wang2023cogvlm,
  title={Cogvlm: Visual expert for pretrained language models},
  author={Wang, Weihan and Lv, Qingsong and Yu, Wenmeng and Hong, Wenyi and Qi, Ji and Wang, Yan and Ji, Junhui and Yang, Zhuoyi and Zhao, Lei and Song, Xixuan and others},
  journal={arXiv preprint arXiv:2311.03079},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: A family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@misc{fuyu-8b,
  author = {Bavishi, Rohan and Elsen, Erich and Hawthorne, Curtis and Nye, Maxwell and Odena, Augustus and Somani, Arushi and  Ta\c{s}\i{}rlar, Sa\u{g}nak},
  title = {Introducing our Multimodal Models},
  url = {https://www.adept.ai/blog/fuyu-8b},
  year = {2023}
}

@article{holland2006social,
  title={From social abuse to social action A neighbourhood psychotherapy and social},
  author={Holland, Sue},
  journal={Gender issues in clinical psychology},
  pages={68},
  year={2006},
  publisher={Routledge}
}

@article{awadalla2023openflamingo,
  title={Openflamingo: An open-source framework for training large autoregressive vision-language models},
  author={Awadalla, Anas and Gao, Irena and Gardner, Josh and Hessel, Jack and Hanafy, Yusuf and Zhu, Wanrong and Marathe, Kalyani and Bitton, Yonatan and Gadre, Samir and Sagawa, Shiori and others},
  journal={arXiv preprint arXiv:2308.01390},
  year={2023}
}

@article{chen2023minigpt,
  title={Minigpt-v2: large language model as a unified interface for vision-language multi-task learning},
  author={Chen, Jun and Zhu, Deyao and Shen, Xiaoqian and Li, Xiang and Liu, Zechun and Zhang, Pengchuan and Krishnamoorthi, Raghuraman and Chandra, Vikas and Xiong, Yunyang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2310.09478},
  year={2023}
}

@article{zenner2018one,
  title={One does not simply process memes: Image macros as multimodal constructions},
  author={Zenner, Eline and Geeraerts, Dirk},
  journal={Cultures and traditions of wordplay and wordplay research},
  pages={167--194},
  year={2018},
  publisher={De Gruyter Berlin}
}

@inproceedings{Gemini,
  title={Gemini: A Family of Highly Capable Multimodal Models},
  author={Gemini Team Google},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:266361876}
}

@inproceedings{lin2023beneath,
  title={Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models},
  author={Lin, Hongzhan and Luo, Ziyang and Ma, Jing and Chen, Long},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year={2023}
}

@article{wei2023zero,
  title={Zero-shot information extraction via chatting with chatgpt},
  author={Wei, Xiang and Cui, Xingyu and Cheng, Ning and Wang, Xiaobin and Zhang, Xin and Huang, Shen and Xie, Pengjun and Xu, Jinan and Chen, Yufeng and Zhang, Meishan and others},
  journal={arXiv preprint arXiv:2302.10205},
  year={2023}
}

@inproceedings{lin2023zero,
  title={Zero-shot rumor detection with propagation structure via prompt learning},
  author={Lin, Hongzhan and Yi, Pengyao and Ma, Jing and Jiang, Haiyun and Luo, Ziyang and Shi, Shuming and Liu, Ruifang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={4},
  pages={5213--5221},
  year={2023}
}

@inproceedings{wei2021finetuned,
  title={Finetuned Language Models are Zero-Shot Learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{kojima2022large,
  title={Large Language Models are Zero-Shot Reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}


@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  year={2023}
}

@inproceedings{hu2021lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{li2022lavis,
  title={Lavis: A library for language-vision intelligence},
  author={Li, Dongxu and Li, Junnan and Le, Hung and Wang, Guangsen and Savarese, Silvio and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2209.09019},
  year={2022}
}

@inproceedings{wei2022chain,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed H and Le, Quoc V and Zhou, Denny and others},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{mchugh2012interrater,
  title={Interrater reliability: the kappa statistic},
  author={McHugh, Mary L},
  journal={Biochemia medica},
  volume={22},
  number={3},
  pages={276--282},
  year={2012},
  publisher={Medicinska naklada}
}

@article{landis1977measurement,
  title={The measurement of observer agreement for categorical data},
  author={Landis, J Richard and Koch, Gary G},
  journal={biometrics},
  pages={159--174},
  year={1977},
  publisher={JSTOR}
}

@article{mishra2023memotion,
  title={Memotion 3: Dataset on sentiment and emotion analysis of codemixed Hindi-English Memes},
  author={Mishra, Shreyash and Suryavardan, S and Patwa, Parth and Chakraborty, Megha and Rani, Anku and Reganti, Aishwarya and Chadha, Aman and Das, Amitava and Sheth, Amit and Chinnakotla, Manoj and others},
  journal={arXiv preprint arXiv:2303.09892},
  year={2023}
}


@article{chang2023survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={ACM Transactions on Intelligent Systems and Technology},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{hu2024large,
  title={Do Large Language Models Know about Facts?},
  author={Hu, Xuming and Chen, Junzhe and Li, Xiaochuan and Guo, Yufei and Wen, Lijie and Philip, S Yu and Guo, Zhijiang},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{akhtar2023multimodal,
  title={Multimodal Automated Fact-Checking: A Survey},
  author={Akhtar, Mubashara and Schlichtkrull, Michael and Guo, Zhijiang and Cocarascu, Oana and Simperl, Elena and Vlachos, Andreas},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={5430--5448},
  year={2023}
}

@inproceedings{thorne2018fever,
  title={FEVER: a Large-scale Dataset for Fact Extraction and VERification},
  author={Thorne, James and Vlachos, Andreas and Christodoulopoulos, Christos and Mittal, Arpit},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  pages={809--819},
  year={2018}
}

@article{guo2022survey,
  title={A Survey on Automated Fact-Checking},
  author={Guo, Zhijiang and Schlichtkrull, Michael and Vlachos, Andreas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={178--206},
  year={2022}
}

@article{newman2012nonprobative,
  title={Nonprobative photographs (or words) inflate truthiness},
  author={Newman, Eryn J and Garry, Maryanne and Bernstein, Daniel M and Kantner, Justin and Lindsay, D Stephen},
  journal={Psychonomic Bulletin \& Review},
  volume={19},
  pages={969--974},
  year={2012},
  publisher={Springer}
}

@article{li2020picture,
  title={Is a picture worth a thousand words? An empirical study of image content and social media engagement},
  author={Li, Yiyi and Xie, Ying},
  journal={Journal of marketing research},
  volume={57},
  number={1},
  pages={1--19},
  year={2020},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}


% datasets
@inproceedings{nakamura-etal-2020-fakeddit,
    title = "{F}akeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection",
    author = "Nakamura, Kai  and
      Levy, Sharon  and
      Wang, William Yang",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.755",
    pages = "6149--6157",
    abstract = "Fake news has altered society in negative ways in politics and culture. It has adversely affected both online social network systems as well as offline communities and conversations. Using automatic machine learning classification models is an efficient way to combat the widespread dissemination of fake news. However, a lack of effective, comprehensive datasets has been a problem for fake news research and detection model development. Prior fake news datasets do not provide multimodal text and image data, metadata, comment data, and fine-grained fake news categorization at the scale and breadth of our dataset. We present Fakeddit, a novel multimodal dataset consisting of over 1 million samples from multiple categories of fake news. After being processed through several stages of review, the samples are labeled according to 2-way, 3-way, and 6-way classification categories through distant supervision. We construct hybrid text+image models and perform extensive experiments for multiple variations of classification, demonstrating the importance of the novel aspect of multimodality and fine-grained classification unique to Fakeddit.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@InProceedings{Shao_2023_CVPR,
    author    = {Shao, Rui and Wu, Tianxing and Liu, Ziwei},
    title     = {Detecting and Grounding Multi-Modal Media Manipulation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {6904-6913}
}

@inproceedings{luo-etal-2021-newsclippings,
    title = "{N}ews{CLIP}pings: {A}utomatic {G}eneration of {O}ut-of-{C}ontext {M}ultimodal {M}edia",
    author = "Luo, Grace  and
      Darrell, Trevor  and
      Rohrbach, Anna",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.545",
    doi = "10.18653/v1/2021.emnlp-main.545",
    pages = "6801--6817",
    abstract = "Online misinformation is a prevalent societal issue, with adversaries relying on tools ranging from cheap fakes to sophisticated deep fakes. We are motivated by the threat scenario where an image is used out of context to support a certain narrative. While some prior datasets for detecting image-text inconsistency generate samples via text manipulation, we propose a dataset where both image and text are unmanipulated but mismatched. We introduce several strategies for automatically retrieving convincing images for a given caption, capturing cases with inconsistent entities or semantic context. Our large-scale automatically generated the NewsCLIPpings Dataset: (1) demonstrates that machine-driven image repurposing is now a realistic threat, and (2) provides samples that represent challenging instances of mismatch between text and image in news that are able to mislead humans. We benchmark several state-of-the-art multimodal models on our dataset and analyze their performance across different pretraining domains and visual backbones.",
}

@inproceedings{10.1145/3539618.3591879,
author = {Yao, Barry Menglong and Shah, Aditya and Sun, Lichao and Cho, Jin-Hee and Huang, Lifu},
title = {End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591879},
doi = {10.1145/3539618.3591879},
abstract = {We propose end-to-end multimodal fact-checking and explanation generation, where the input is a claim and a large collection of web sources, including articles, images, videos, and tweets, and the goal is to assess the truthfulness of the claim by retrieving relevant evidence and predicting a truthfulness label (e.g., support, refute or not enough information), and to generate a statement to summarize and explain the reasoning and ruling process. To support this research, we construct MOCHEG, a large-scale dataset consisting of 15,601 claims where each claim is annotated with a truthfulness label and a ruling statement, and 33,880 textual paragraphs and 12,112 images in total as evidence. To establish baseline performances on MOCHEG, we experiment with several state-of-the-art neural architectures on the three pipelined subtasks: multimodal evidence retrieval, claim verification, and explanation generation, and demonstrate that the performance of the state-of-the-art end-to-end multimodal fact-checking does not provide satisfactory outcomes. To the best of our knowledge, we are the first to build the benchmark dataset and solutions for end-to-end multimodal fact-checking and explanation generation. The dataset, source code and model checkpoints are available at https://github.com/VT-NLP/Mocheg.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2733–2743},
numpages = {11},
keywords = {evidence retrieval, explainable fact-checking, explanation generation, multimodal fact-checking, stance detection},
location = {<conf-loc>, <city>Taipei</city>, <country>Taiwan</country>, </conf-loc>},
series = {SIGIR '23}
}

@inproceedings{petroni2019language,
  title={Language Models as Knowledge Bases?},
  author={Petroni, Fabio and Rockt{\"a}schel, Tim and Riedel, Sebastian and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={2463--2473},
  year={2019}
}

@inproceedings{petroni2020context,
  title={How Context Affects Language Models' Factual Predictions},
  author={Petroni, Fabio and Lewis, Patrick and Piktus, Aleksandra and Rockt{\"a}schel, Tim and Wu, Yuxiang and Miller, Alexander H and Riedel, Sebastian},
  booktitle={Automated Knowledge Base Construction},
  year={2020}
}

@inproceedings{heinzerling2021language,
  title={Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries},
  author={Heinzerling, Benjamin and Inui, Kentaro},
  booktitle={Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
  pages={1772--1791},
  year={2021}
}

@inproceedings{roberts2020much,
  title={How Much Knowledge Can You Pack Into the Parameters of a Language Model?},
  author={Roberts, Adam and Raffel, Colin and Shazeer, Noam},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={5418--5426},
  year={2020}
}

@inproceedings{yu2022generate,
  title={Generate rather than Retrieve: Large Language Models are Strong Context Generators},
  author={Yu, Wenhao and Iter, Dan and Wang, Shuohang and Xu, Yichong and Ju, Mingxuan and Sanyal, Soumya and Zhu, Chenguang and Zeng, Michael and Jiang, Meng},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{pan2023fact,
  title={Fact-Checking Complex Claims with Program-Guided Reasoning},
  author={Pan, Liangming and Wu, Xiaobao and Lu, Xinyuan and Luu, Anh Tuan and Wang, William Yang and Kan, Min-Yen and Nakov, Preslav},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={6981--7004},
  year={2023}
}

@inproceedings{jiang2020x,
  title={X-FACTR: Multilingual factual knowledge retrieval from pretrained language models},
  author={Jiang, Zhengbao and Anastasopoulos, Antonios and Araki, Jun and Ding, Haibo and Neubig, Graham},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={5943--5959},
  year={2020}
}

@article{elazar2021measuring,
  title={Measuring and improving consistency in pretrained language models},
  author={Elazar, Yanai and Kassner, Nora and Ravfogel, Shauli and Ravichander, Abhilasha and Hovy, Eduard and Sch{\"u}tze, Hinrich and Goldberg, Yoav},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={1012--1031},
  year={2021},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{cao2021knowledgeable,
  title={Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge Bases},
  author={Cao, Boxi and Lin, Hongyu and Han, Xianpei and Sun, Le and Yan, Lingyong and Liao, Meng and Xue, Tong and Xu, Jin},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={1860--1874},
  year={2021}
}

@inproceedings{varshney2022investigating,
  title={Investigating Selective Prediction Approaches Across Several Tasks in IID, OOD, and Adversarial Settings},
  author={Varshney, Neeraj and Mishra, Swaroop and Baral, Chitta},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={1995--2002},
  year={2022}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022}
}

@article{lin2022teaching,
  title={Teaching models to express their uncertainty in words},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2205.14334},
  year={2022}
}

@article{lin2024goat,
  title={GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse},
  author={Lin, Hongzhan and Luo, Ziyang and Wang, Bo and Yang, Ruichao and Ma, Jing},
  journal={arXiv preprint arXiv:2401.01523},
  year={2024}
}


@inproceedings{Agarwal2019ProtectingWL,
  title={Protecting World Leaders Against Deep Fakes},
  author={Shruti Agarwal and Hany Farid and Yuming Gu and Mingming He and Koki Nagano and Hao Li},
  booktitle={CVPR Workshops},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:195732375}
}


@inproceedings{aneja2021cosmos,
    title={{COSMOS}: Catching {O}ut-of-{C}ontext {M}isinformation with {S}elf-{S}upervised {L}earning}, 
    author={Shivangi Aneja and Chris Bregler and Matthias Nie{\ss}ner},
    booktitle={ArXiv preprint arXiv:2101.06278},
    year={2021}
}


@article{Maras2018DeterminingAO,
  title={Determining authenticity of video evidence in the age of artificial intelligence and in the wake of Deepfake videos},
  author={Marie-Helen Maras and Alex Alexandrou},
  journal={The International Journal of Evidence \& Proof},
  year={2018},
  volume={23},
  pages={255 - 262},
  url={https://api.semanticscholar.org/CorpusID:150336977}
}

@article{Dolhansky2019TheDD,
  title={The Deepfake Detection Challenge (DFDC) Preview Dataset},
  author={Brian Dolhansky and Russ Howes and Ben Pflaum and Nicole Baram and Cristian Canton-Ferrer},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.08854},
  url={https://api.semanticscholar.org/CorpusID:204800939}
}

@article{Ramesh2022HierarchicalTI,
  title={Hierarchical Text-Conditional Image Generation with CLIP Latents},
  author={Aditya Ramesh and Prafulla Dhariwal and Alex Nichol and Casey Chu and Mark Chen},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.06125},
  url={https://api.semanticscholar.org/CorpusID:248097655}
}


@article{DBLP:journals/corr/abs-1810-04805,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  archivePrefix = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Liu2023GroundingDM,
  title={Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection},
  author={Shilong Liu and Zhaoyang Zeng and Tianhe Ren and Feng Li and Hao Zhang and Jie Yang and Chun-yue Li and Jianwei Yang and Hang Su and Jun-Juan Zhu and Lei Zhang},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.05499},
  url={https://api.semanticscholar.org/CorpusID:257427307}
}

@inproceedings{lample2016neural,
  title={Neural Architectures for Named Entity Recognition},
  author={Lample, Guillaume and Ballesteros, Miguel and Subramanian, Sandeep and Kawakami, Kazuya and Dyer, Chris},
  booktitle={Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={260--270},
  year={2016}
}

@article{Wang2020SBERTWKAS,
  title={SBERT-WK: A Sentence Embedding Method by Dissecting BERT-Based Word Models},
  author={Bin Wang and C.-C. Jay Kuo},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2020},
  volume={28},
  pages={2146-2157},
  url={https://api.semanticscholar.org/CorpusID:211133229}
}


@article{Young2024YiOF,
  title={Yi: Open Foundation Models by 01.AI},
  author={01.AI Alex Young and Bei Chen and Chao Li and Chengen Huang and Ge Zhang and Guanwei Zhang and Heng Li and Jiangcheng Zhu and Jianqun Chen and Jing Chang and Kaidong Yu and Peng Liu and Qiang Liu and Shawn Yue and Senbin Yang and Shiming Yang and Tao Yu and Wen Xie and Wenhao Huang and Xiaohui Hu and Xiaoyi Ren and Xinyao Niu and Pengcheng Nie and Yuchi Xu and Yudong Liu and Yue Wang and Yuxuan Cai and Zhenyu Gu and Zhiyuan Liu and Zonghong Dai},
  journal={ArXiv},
  year={2024},
  volume={abs/2403.04652},
  url={https://api.semanticscholar.org/CorpusID:268264158}
}

@article{Ye2023mPLUGOwlME,
  title={mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality},
  author={Qinghao Ye and Haiyang Xu and Guohai Xu and Jiabo Ye and Ming Yan and Yi Zhou and Junyan Wang and Anwen Hu and Pengcheng Shi and Yaya Shi and Chenliang Li and Yuanhong Xu and Hehong Chen and Junfeng Tian and Qiang Qi and Ji Zhang and Feiyan Huang},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.14178},
  url={https://api.semanticscholar.org/CorpusID:258352455}
}

@article{Chen2023MiniGPTv2LL,
  title={MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning},
  author={Jun Chen and Deyao Zhu and Xiaoqian Shen and Xiang Li and Zechun Liu and Pengchuan Zhang and Raghuraman Krishnamoorthi and Vikas Chandra and Yunyang Xiong and Mohamed Elhoseiny},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.09478},
  url={https://api.semanticscholar.org/CorpusID:264146906}
}


@article{Wang2023CogVLMVE,
  title={CogVLM: Visual Expert for Pretrained Language Models},
  author={Weihan Wang and Qingsong Lv and Wenmeng Yu and Wenyi Hong and Ji Qi and Yan Wang and Junhui Ji and Zhuoyi Yang and Lei Zhao and Xixuan Song and Jiazheng Xu and Bin Xu and Juanzi Li and Yuxiao Dong and Ming Ding and Jie Tang},
  journal={ArXiv},
  year={2023},
  volume={abs/2311.03079},
  url={https://api.semanticscholar.org/CorpusID:265034288}
}

@article{Lin2023VILAOP,
  title={VILA: On Pre-training for Visual Language Models},
  author={Ji Lin and Hongxu Yin and Wei Ping and Yao Lu and Pavlo Molchanov and Andrew Tao and Huizi Mao and Jan Kautz and Mohammad Shoeybi and Song Han},
  journal={ArXiv},
  year={2023},
  volume={abs/2312.07533},
  url={https://api.semanticscholar.org/CorpusID:266174746}
}


@article{Chen2023InternVLSU,
  title={InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks},
  author={Zhe Chen and Jiannan Wu and Wenhai Wang and Weijie Su and Guo Chen and Sen Xing and Zhong Muyan and Qinglong Zhang and Xizhou Zhu and Lewei Lu and Bin Li and Ping Luo and Tong Lu and Yu Qiao and Jifeng Dai},
  journal={ArXiv},
  year={2023},
  volume={abs/2312.14238},
  url={https://api.semanticscholar.org/CorpusID:266521410}
}


@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}


@article{Sun2023GenerativeMM,
  title={Generative Multimodal Models are In-Context Learners},
  author={Quan Sun and Yufeng Cui and Xiaosong Zhang and Fan Zhang and Qiying Yu and Zhengxiong Luo and Yueze Wang and Yongming Rao and Jingjing Liu and Tiejun Huang and Xinlong Wang},
  journal={ArXiv},
  year={2023},
  volume={abs/2312.13286},
  url={https://api.semanticscholar.org/CorpusID:266374640}
}

@inproceedings{qi2019exploiting,
  title={Exploiting multi-domain visual information for fake news detection},
  author={Qi, Peng and Cao, Juan and Yang, Tianyun and Guo, Junbo and Li, Jintao},
  booktitle={2019 IEEE international conference on data mining (ICDM)},
  pages={518--527},
  year={2019},
  organization={IEEE}
}

@inproceedings{bonettini2021video,
  title={Video face manipulation detection through ensemble of cnns},
  author={Bonettini, Nicolo and Cannas, Edoardo Daniele and Mandelli, Sara and Bondi, Luca and Bestagini, Paolo and Tubaro, Stefano},
  booktitle={2020 25th international conference on pattern recognition (ICPR)},
  pages={5012--5019},
  year={2021},
  organization={IEEE}
}

@article{hu2024minicpm,
  title={Minicpm: Unveiling the potential of small language models with scalable training strategies},
  author={Hu, Shengding and Tu, Yuge and Han, Xu and He, Chaoqun and Cui, Ganqu and Long, Xiang and Zheng, Zhi and Fang, Yewei and Huang, Yuxiang and Zhao, Weilin and others},
  journal={arXiv preprint arXiv:2404.06395},
  year={2024}
}

@article{gemma,
  author       = {Thomas Mesnard and
                  Cassidy Hardin and
                  Robert Dadashi and
                  Surya Bhupatiraju and
                  Shreya Pathak and
                  Laurent Sifre and
                  Morgane Rivi{\`{e}}re and
                  Mihir Sanjay Kale and
                  Juliette Love and
                  Pouya Tafti and
                  L{\'{e}}onard Hussenot and
                  Aakanksha Chowdhery and
                  Adam Roberts and
                  Aditya Barua and
                  Alex Botev and
                  Alex Castro{-}Ros and
                  Ambrose Slone and
                  Am{\'{e}}lie H{\'{e}}liou and
                  Andrea Tacchetti and
                  Anna Bulanova and
                  Antonia Paterson and
                  Beth Tsai and
                  Bobak Shahriari and
                  Charline Le Lan and
                  Christopher A. Choquette{-}Choo and
                  Cl{\'{e}}ment Crepy and
                  Daniel Cer and
                  Daphne Ippolito and
                  David Reid and
                  Elena Buchatskaya and
                  Eric Ni and
                  Eric Noland and
                  Geng Yan and
                  George Tucker and
                  George{-}Cristian Muraru and
                  Grigory Rozhdestvenskiy and
                  Henryk Michalewski and
                  Ian Tenney and
                  Ivan Grishchenko and
                  Jacob Austin and
                  James Keeling and
                  Jane Labanowski and
                  Jean{-}Baptiste Lespiau and
                  Jeff Stanway and
                  Jenny Brennan and
                  Jeremy Chen and
                  Johan Ferret and
                  Justin Chiu and
                  et al.},
  title        = {Gemma: Open Models Based on Gemini Research and Technology},
  journal      = {CoRR},
  volume       = {abs/2403.08295},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2403.08295},
  doi          = {10.48550/ARXIV.2403.08295},
  eprinttype    = {arXiv},
  eprint       = {2403.08295},
  timestamp    = {Tue, 21 May 2024 14:56:02 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2403-08295.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{llama3,
    author = {Meta},
    title = {Introducing Meta Llama 3: The most capable openly available LLM to date},
    year = {2024},
    howpublished = {\url{https://ai.meta.com/blog/meta-llama-3/}},
}

@article{mistral,
  author       = {Albert Q. Jiang and
                  Alexandre Sablayrolles and
                  Arthur Mensch and
                  Chris Bamford and
                  Devendra Singh Chaplot and
                  Diego de Las Casas and
                  Florian Bressand and
                  Gianna Lengyel and
                  Guillaume Lample and
                  Lucile Saulnier and
                  L{\'{e}}lio Renard Lavaud and
                  Marie{-}Anne Lachaux and
                  Pierre Stock and
                  Teven Le Scao and
                  Thibaut Lavril and
                  Thomas Wang and
                  Timoth{\'{e}}e Lacroix and
                  William El Sayed},
  title        = {Mistral 7B},
  journal      = {CoRR},
  volume       = {abs/2310.06825},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.06825},
  doi          = {10.48550/ARXIV.2310.06825},
  eprinttype    = {arXiv},
  eprint       = {2310.06825},
  timestamp    = {Thu, 26 Oct 2023 16:46:26 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2310-06825.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{fawcett2006introduction,
  title={An introduction to ROC analysis},
  author={Fawcett, Tom},
  journal={Pattern recognition letters},
  volume={27},
  number={8},
  pages={861--874},
  year={2006},
  publisher={Elsevier}
}

@article{powers2020evaluation,
  title={Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation},
  author={Powers, David MW},
  journal={arXiv preprint arXiv:2010.16061},
  year={2020}
}

@inproceedings{liu-etal-2021-visual,
    title = "Visual News: Benchmark and Challenges in News Image Captioning",
    author = "Liu, Fuxiao  and
      Wang, Yinghan  and
      Wang, Tianlu  and
      Ordonez, Vicente",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.542",
    doi = "10.18653/v1/2021.emnlp-main.542",
    pages = "6761--6771",
    abstract = "We propose Visual News Captioner, an entity-aware model for the task of news image captioning. We also introduce Visual News, a large-scale benchmark consisting of more than one million news images along with associated news articles, image captions, author information, and other metadata. Unlike the standard image captioning task, news images depict situations where people, locations, and events are of paramount importance. Our proposed method can effectively combine visual and textual features to generate captions with richer information such as events and entities. More specifically, built upon the Transformer architecture, our model is further equipped with novel multi-modal feature fusion techniques and attention mechanisms, which are designed to generate named entities more accurately. Our method utilizes much fewer parameters while achieving slightly better prediction results than competing methods. Our larger and more diverse Visual News dataset further highlights the remaining challenges in captioning news images.",
}

@inproceedings{10.1145/3240508.3240707,
author = {Sabir, Ekraam and AbdAlmageed, Wael and Wu, Yue and Natarajan, Prem},
title = {Deep Multimodal Image-Repurposing Detection},
year = {2018},
isbn = {9781450356657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240508.3240707},
doi = {10.1145/3240508.3240707},
abstract = {Nefarious actors on social media and other platforms often spread rumors and falsehoods through images whose metadata (e.g., captions) have been modified to provide visual substantiation of the rumor/falsehood. This type of modification is referred to as image repurposing, in which often an unmanipulated image is published along with incorrect or manipulated metadata to serve the actor's ulterior motives. We present the Multimodal Entity Image Repurposing (MEIR) dataset, a substantially challenging dataset over that which has been previously available to support research into image repurposing detection. The new dataset includes location, person, and organization manipulations on real-world data sourced from Flickr. We also present a novel, end-to-end, deep multimodal learning model for assessing the integrity of an image by combining information extracted from the image with related information from a knowledge base. The proposed method is compared against state-of-the-art techniques on existing datasets as well as MEIR, where it outperforms existing methods across the board, with AUC improvement up to 0.23.},
booktitle = {Proceedings of the 26th ACM International Conference on Multimedia},
pages = {1337–1345},
numpages = {9},
keywords = {computer vision, deep learning, fake news, multi-task learning, rumor detection},
location = {Seoul, Republic of Korea},
series = {MM '18}
}


@inproceedings{da-etal-2021-edited,
    title = "Edited Media Understanding Frames: Reasoning About the Intent and Implications of Visual Misinformation",
    author = "Da, Jeff  and
      Forbes, Maxwell  and
      Zellers, Rowan  and
      Zheng, Anthony  and
      Hwang, Jena D.  and
      Bosselut, Antoine  and
      Choi, Yejin",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.158",
    doi = "10.18653/v1/2021.acl-long.158",
    pages = "2026--2039",
    abstract = "Understanding manipulated media, from automatically generated {`}deepfakes{'} to manually edited ones, raises novel research challenges. Because the vast majority of edited or manipulated images are benign, such as photoshopped images for visual enhancements, the key challenge is to understand the complex layers of underlying intents of media edits and their implications with respect to disinformation. In this paper, we study Edited Media Frames, a new formalism to understand visual media manipulation as structured annotations with respect to the intents, emotional reactions, attacks on individuals, and the overall implications of disinformation. We introduce a dataset for our task, EMU, with 56k question-answer pairs written in rich natural language. We evaluate a wide variety of vision-and-language models for our task, and introduce a new model PELICAN, which builds upon recent progress in pretrained multimodal representations. Our model obtains promising results on our dataset, with humans rating its answers as accurate 48.2{\%} of the time. At the same time, there is still much work to be done {--} and we provide analysis that highlights areas for further progress.",
}

@inproceedings{10.1145/3123266.3123385,
author = {Jaiswal, Ayush and Sabir, Ekraam and AbdAlmageed, Wael and Natarajan, Premkumar},
title = {Multimedia Semantic Integrity Assessment Using Joint Embedding Of Images And Text},
year = {2017},
isbn = {9781450349062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123266.3123385},
doi = {10.1145/3123266.3123385},
abstract = {Real-world multimedia data is often composed of multiple modalities such as an image or a video with associated text (e.g., captions, user comments, etc.) and metadata. Such multimodal data packages are prone to manipulations, where a subset of these modalities can be altered to misrepresent or repurpose data packages, with possible malicious intent. It is therefore important to develop methods to assess or verify the integrity of these multimedia packages. Using computer vision and natural language processing methods to directly compare the image (or video) and the associated caption to verify the integrity of a media package is only possible for a limited set of objects and scenes. In this paper we present a novel deep-learning-based approach that uses a reference set of multimedia packages to assess the semantic integrity of multimedia packages containing images and captions. We construct a joint embedding of images and captions with deep multimodal representation learning on the reference dataset in a framework that also provides image-caption consistency scores (ICCSs). The integrity of query media packages is assessed as the inlierness of the query ICCSs with respect to the reference dataset. We present the MultimodAl Information Manipulation dataset (MAIM), a new dataset of media packages from Flickr, which we are making available to the research community. We use both the newly created dataset as well as Flickr30K and MS COCO datasets to quantitatively evaluate our proposed approach. The reference dataset does not contain unmanipulated versions of tampered query packages. Our method is able to achieve F-1 scores of 0.75, 0.89 and 0.94 on MAIM, Flickr30K and MS COCO, respectively, for detecting semantically incoherent media packages.},
booktitle = {Proceedings of the 25th ACM International Conference on Multimedia},
pages = {1465–1471},
numpages = {7},
keywords = {semantic integrity assemessment, multimodal semantic integrity, multimedia data},
location = {Mountain View, California, USA},
series = {MM '17}
}

@inproceedings{10.1609/aaai.v37i12.26648,
author = {Aneja, Shivangi and Bregler, Chris and Nie\ss{}ner, Matthias},
title = {COSMOS: catching out-of-context image misuse with self-supervised learning},
year = {2023},
isbn = {978-1-57735-880-0},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v37i12.26648},
doi = {10.1609/aaai.v37i12.26648},
abstract = {Despite the recent attention to DeepFakes, one of the most prevalent ways to mislead audiences on social media is the use of unaltered images in a new but false context. We propose a new method that automatically highlights out-of-context image and text pairs, for assisting fact-checkers. Our key insight is to leverage the grounding of image with text to distinguish out-of-context scenarios that cannot be disambiguated with language alone. We propose a self-supervised training strategy where we only need a set of captioned images. At train time, our method learns to selectively align individual objects in an image with textual claims, without explicit supervision. At test time, we check if both captions correspond to the same object(s) in the image but are semantically different, which allows us to make fairly accurate out-of-context predictions. Our method achieves 85\% out-of-context detection accuracy. To facilitate benchmarking of this task, we create a large-scale dataset of 200K images with 450K textual captions from a variety of news websites, blogs, and social media posts.},
booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence},
articleno = {1579},
numpages = {9},
series = {AAAI'23/IAAI'23/EAAI'23}
}

@misc{liu2024mmfakebenchmixedsourcemultimodalmisinformation,
      title={MMFakeBench: A Mixed-Source Multimodal Misinformation Detection Benchmark for LVLMs}, 
      author={Xuannan Liu and Zekun Li and Peipei Li and Shuhan Xia and Xing Cui and Linzhi Huang and Huaibo Huang and Weihong Deng and Zhaofeng He},
      year={2024},
      eprint={2406.08772},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.08772}, 
}



@misc{deitke2024molmopixmoopenweights,
      title={Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models}, 
      author={Matt Deitke and Christopher Clark and Sangho Lee and Rohun Tripathi and Yue Yang and Jae Sung Park and Mohammadreza Salehi and Niklas Muennighoff and Kyle Lo and Luca Soldaini and Jiasen Lu and Taira Anderson and Erin Bransom and Kiana Ehsani and Huong Ngo and YenSung Chen and Ajay Patel and Mark Yatskar and Chris Callison-Burch and Andrew Head and Rose Hendrix and Favyen Bastani and Eli VanderBilt and Nathan Lambert and Yvonne Chou and Arnavi Chheda and Jenna Sparks and Sam Skjonsberg and Michael Schmitz and Aaron Sarnat and Byron Bischoff and Pete Walsh and Chris Newell and Piper Wolters and Tanmay Gupta and Kuo-Hao Zeng and Jon Borchardt and Dirk Groeneveld and Jen Dumas and Crystal Nam and Sophie Lebrecht and Caitlin Wittlif and Carissa Schoenick and Oscar Michel and Ranjay Krishna and Luca Weihs and Noah A. Smith and Hannaneh Hajishirzi and Ross Girshick and Ali Farhadi and Aniruddha Kembhavi},
      year={2024},
      eprint={2409.17146},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.17146}, 
}

@article{Qwen2VL,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Fan, Yang and Dang, Kai and Du, Mengfei and Ren, Xuancheng and Men, Rui and Liu, Dayiheng and Zhou, Chang and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@misc{xue2024xgenmmblip3familyopen,
      title={xGen-MM (BLIP-3): A Family of Open Large Multimodal Models}, 
      author={Le Xue and Manli Shu and Anas Awadalla and Jun Wang and An Yan and Senthil Purushwalkam and Honglu Zhou and Viraj Prabhu and Yutong Dai and Michael S Ryoo and Shrikant Kendre and Jieyu Zhang and Can Qin and Shu Zhang and Chia-Chih Chen and Ning Yu and Juntao Tan and Tulika Manoj Awalgaonkar and Shelby Heinecke and Huan Wang and Yejin Choi and Ludwig Schmidt and Zeyuan Chen and Silvio Savarese and Juan Carlos Niebles and Caiming Xiong and Ran Xu},
      year={2024},
      eprint={2408.08872},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.08872}, 
}

@article{yao2024minicpm,
  title={MiniCPM-V: A GPT-4V Level MLLM on Your Phone},
  author={Yao, Yuan and Yu, Tianyu and Zhang, Ao and Wang, Chongyi and Cui, Junbo and Zhu, Hongji and Cai, Tianchi and Li, Haoyu and Zhao, Weilin and He, Zhihui and others},
  journal={arXiv preprint arXiv:2408.01800},
  year={2024}
}

@misc{li2024llavaonevisioneasyvisualtask,
      title={LLaVA-OneVision: Easy Visual Task Transfer}, 
      author={Bo Li and Yuanhan Zhang and Dong Guo and Renrui Zhang and Feng Li and Hao Zhang and Kaichen Zhang and Yanwei Li and Ziwei Liu and Chunyuan Li},
      year={2024},
      eprint={2408.03326},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.03326}, 
}

@article{chang2024survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={3},
  pages={1--45},
  year={2024},
  publisher={ACM New York, NY}
}

@inproceedings{lin2024towards,
  title={Towards explainable harmful meme detection through multimodal debate between large language models},
  author={Lin, Hongzhan and Luo, Ziyang and Gao, Wei and Ma, Jing and Wang, Bo and Yang, Ruichao},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={2359--2370},
  year={2024}
}

@inproceedings{wang2024explainable,
  title={Explainable Fake News Detection With Large Language Model via Defense Among Competing Wisdom},
  author={Wang, Bo and Ma, Jing and Lin, Hongzhan and Yang, Zhiwei and Yang, Ruichao and Tian, Yuan and Chang, Yi},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={2452--2463},
  year={2024}
}

@article{jiang2020can,
  title={How can we know what language models know?},
  author={Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={423--438},
  year={2020}
}

@inproceedings{yu2023generate,
  title={Generate rather than Retrieve: Large Language Models are Strong Context Generators},
  author={Yu, Wenhao and Iter, Dan and Wang, Shuohang and Xu, Yichong and Ju, Mingxuan and Sanyal, Soumya and Zhu, Chenguang and Zeng, Michael and Jiang, Meng},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@article{ribeiro2016model,
  title={Model-agnostic interpretability of machine learning},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  journal={arXiv preprint arXiv:1606.05386},
  year={2016}
}

@article{belinkov2019analysis,
  title={Analysis methods in neural language processing: A survey},
  author={Belinkov, Yonatan and Glass, James},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={49--72},
  year={2019}
}

@inproceedings{de2021editing,
  title={Editing Factual Knowledge in Language Models},
  author={De Cao, Nicola and Aziz, Wilker and Titov, Ivan},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={6491--6506},
  year={2021}
}

@inproceedings{dong2022calibrating,
  title={Calibrating Factual Knowledge in Pretrained Language Models},
  author={Dong, Qingxiu and Dai, Damai and Song, Yifan and Xu, Jingjing and Sui, Zhifang and Li, Lei},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={5937--5947},
  year={2022}
}

@inproceedings{lin2022truthfulqa,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3214--3252},
  year={2022}
}

@inproceedings{sathe2020automated,
  title={Automated fact-checking of claims from Wikipedia},
  author={Sathe, Aalok and Ather, Salar and Le, Tuan Manh and Perry, Nathan and Park, Joonsuk},
  booktitle={Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages={6874--6882},
  year={2020}
}

@inproceedings{schuster2021get,
  title={Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence},
  author={Schuster, Tal and Fisch, Adam and Barzilay, Regina},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={624--643},
  year={2021}
}

@inproceedings{buntain2017automatically,
  title={Automatically identifying fake news in popular twitter threads},
  author={Buntain, Cody and Golbeck, Jennifer},
  booktitle={2017 IEEE international conference on smart cloud (smartCloud)},
  pages={208--215},
  year={2017},
  organization={IEEE}
}

@article{shu2020fakenewsnet,
  title={Fakenewsnet: A data repository with news content, social context, and spatiotemporal information for studying fake news on social media},
  author={Shu, Kai and Mahudeswaran, Deepak and Wang, Suhang and Lee, Dongwon and Liu, Huan},
  journal={Big data},
  volume={8},
  number={3},
  pages={171--188},
  year={2020}
}

@inproceedings{ma2015detect,
  title={Detect rumors using time series of social context information on microblogging websites},
  author={Ma, Jing and Gao, Wei and Wei, Zhongyu and Lu, Yueming and Wong, Kam-Fai},
  booktitle={Proceedings of the 24th ACM international on conference on information and knowledge management},
  pages={1751--1754},
  year={2015}
}

@inproceedings{ma2017detect,
  title={Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning},
  author={Ma, Jing and Gao, Wei and Wong, Kam-Fai},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={708--717},
  year={2017}
}

@inproceedings{lin2022detect,
  title={Detect Rumors in Microblog Posts for Low-Resource Domains via Adversarial Contrastive Learning},
  author={Lin, Hongzhan and Ma, Jing and Chen, Liangliang and Yang, Zhiwei and Cheng, Mingfei and Guang, Chen},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2022},
  pages={2543--2556},
  year={2022}
}

@inproceedings{jiang2020hover,
  title={HoVer: A Dataset for Many-Hop Fact Extraction And Claim Verification},
  author={Jiang, Yichen and Bordia, Shikha and Zhong, Zheng and Dognin, Charles and Singh, Maneesh and Bansal, Mohit},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={3441--3460},
  year={2020}
}

@inproceedings{aly2021feverous,
  title={FEVEROUS: Fact Extraction and VERification Over Unstructured and Structured information},
  author={Aly, Rami and Guo, Zhijiang and Schlichtkrull, Michael Sejr and Thorne, James and Vlachos, Andreas and Christodoulopoulos, Christos and Cocarascu, Oana and Mittal, Arpit},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},
  year={2021}
}

@inproceedings{wadden2022scifact,
  title={SciFact-Open: Towards open-domain scientific claim verification},
  author={Wadden, David and Lo, Kyle and Kuehl, Bailey and Cohan, Arman and Beltagy, Iz and Wang, Lucy Lu and Hajishirzi, Hannaneh},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={4719--4734},
  year={2022}
}

@inproceedings{gupta2021x,
  title={X-Fact: A New Benchmark Dataset for Multilingual Fact Checking},
  author={Gupta, Ashim and Srikumar, Vivek},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  pages={675--682},
  year={2021}
}

@inproceedings{nakov2022clef,
  title={The clef-2022 checkthat! lab on fighting the covid-19 infodemic and fake news detection},
  author={Nakov, Preslav and Barr{\'o}n-Cede{\~n}o, Alberto and Da San Martino, Giovanni and Alam, Firoj and Stru{\ss}, Julia Maria and Mandl, Thomas and M{\'\i}guez, Rub{\'e}n and Caselli, Tommaso and Kutlu, Mucahid and Zaghouani, Wajdi and others},
  booktitle={European Conference on Information Retrieval},
  pages={416--428},
  year={2022},
  organization={Springer}
}

@inproceedings{chen2024can,
  title={Can LLM-Generated Misinformation Be Detected?},
  author={Chen, Canyu and Shu, Kai},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{hu2024bad,
  title={Bad actor, good advisor: Exploring the role of large language models in fake news detection},
  author={Hu, Beizhe and Sheng, Qiang and Cao, Juan and Shi, Yuhui and Li, Yang and Wang, Danding and Qi, Peng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={20},
  pages={22105--22113},
  year={2024}
}

@article{yang2024reinforcement,
  title={Reinforcement Tuning for Detecting Stances and Debunking Rumors Jointly with Large Language Models},
  author={Yang, Ruichao and Gao, Wei and Ma, Jing and Lin, Hongzhan and Wang, Bo},
  journal={arXiv preprint arXiv:2406.02143},
  year={2024}
}

@inproceedings{atanasova2020generating,
  title={Generating Fact Checking Explanations},
  author={Atanasova, Pepa and Simonsen, Jakob Grue and Lioma, Christina and Augenstein, Isabelle},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={7352--7364},
  year={2020}
}

@inproceedings{wang2023voyager,
  title={Voyager: An Open-Ended Embodied Agent with Large Language Models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  booktitle={Intrinsically-Motivated and Open-Ended Learning Workshop@ NeurIPS2023},
  year={2023}
}

@inproceedings{yao2022react,
  title={ReAct: Synergizing Reasoning and Acting in Language Models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik R and Cao, Yuan},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{shen2023hugginggpt,
  title={HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@inproceedings{mu2023embodiedgpt,
  title={EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought},
  author={Mu, Yao and Zhang, Qinglong and Hu, Mengkang and Wang, Wenhai and Ding, Mingyu and Jin, Jun and Wang, Bin and Dai, Jifeng and Qiao, Yu and Luo, Ping},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@inproceedings{hong2023metagpt,
  title={MetaGPT: Meta Programming for Multi-Agent Collaborative Framework},
  author={Hong, Sirui and Zhuge, Mingchen and Chen, Jonathan and Zheng, Xiawu and Cheng, Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{liu2023agentbench,
  title={AgentBench: Evaluating LLMs as Agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{sun2023adaplanner,
  title={AdaPlanner: Adaptive Planning from Feedback with Language Models},
  author={Sun, Haotian and Zhuang, Yuchen and Kong, Lingkai and Dai, Bo and Zhang, Chao},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@article{qian2023communicative,
  title={Communicative agents for software development},
  author={Qian, Chen and Cong, Xin and Yang, Cheng and Chen, Weize and Su, Yusheng and Xu, Juyuan and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2307.07924},
  year={2023}
}

@inproceedings{chen2022codet,
  title={CodeT: Code Generation with Generated Tests},
  author={Chen, Bei and Zhang, Fengji and Nguyen, Anh and Zan, Daoguang and Lin, Zeqi and Lou, Jian-Guang and Chen, Weizhu},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{chen2023teaching,
  title={Teaching Large Language Models to Self-Debug},
  author={Chen, Xinyun and Lin, Maxwell and Schaerli, Nathanael and Zhou, Denny},
  booktitle={The 61st Annual Meeting Of The Association For Computational Linguistics},
  year={2023}
}

@inproceedings{madaan2023self,
  title={Self-Refine: Iterative Refinement with Self-Feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@inproceedings{shinn2023reflexion,
  title={Reflexion: language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  booktitle={Proceedings of the 37th International Conference on Neural Information Processing Systems},
  pages={8634--8652},
  year={2023}
}

@inproceedings{eldifrawi2024automated,
  title={Automated Justification Production for Claim Veracity in Fact Checking: A Survey on Architectures and Approaches},
  author={Eldifrawi, Islam and Wang, Shengrui and Trabelsi, Amine},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={6679--6692},
  year={2024}
}

@article{allport1947psychology,
  title={The psychology of rumor},
  author={Allport, Gordon W},
  journal={Holt, Rinehart \&Winston},
  year={1947}
}

@article{waldrop2017genuine,
  title={The genuine problem of fake news},
  author={Waldrop, M Mitchell},
  journal={Proceedings of the National Academy of Sciences},
  volume={114},
  number={48},
  pages={12631--12634},
  year={2017},
  publisher={National Acad Sciences}
}

@article{metropolis1949monte,
  title={The monte carlo method},
  author={Metropolis, Nicholas and Ulam, Stanislaw},
  journal={Journal of the American statistical association},
  volume={44},
  number={247},
  pages={335--341},
  year={1949},
  publisher={Taylor \& Francis}
}

@article{kahn1953methods,
  title={Methods of reducing sample size in Monte Carlo computations},
  author={Kahn, Herman and Marshall, Andy W},
  journal={Journal of the Operations Research Society of America},
  volume={1},
  number={5},
  pages={263--278},
  year={1953},
  publisher={INFORMS}
}

@article{metropolis1953equation,
  title={Equation of state calculations by fast computing machines},
  author={Metropolis, Nicholas and Rosenbluth, Arianna W and Rosenbluth, Marshall N and Teller, Augusta H and Teller, Edward},
  journal={The journal of chemical physics},
  volume={21},
  number={6},
  pages={1087--1092},
  year={1953},
  publisher={American Institute of Physics}
}

@article{owen2000safe,
  title={Safe and effective importance sampling},
  author={Owen, Art and Zhou, Yi},
  journal={Journal of the American Statistical Association},
  volume={95},
  number={449},
  pages={135--143},
  year={2000},
  publisher={Taylor \& Francis}
}


@inproceedings{zheng2023judging,
  title={Judging LLM-as-a-judge with MT-bench and Chatbot Arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P and others},
  booktitle={Proceedings of the 37th International Conference on Neural Information Processing Systems},
  pages={46595--46623},
  year={2023}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}


@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{yang2024qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}

@article{glm2024chatglm,
  title={Chatglm: A family of large language models from glm-130b to glm-4 all tools},
  author={GLM, Team and Zeng, Aohan and Xu, Bin and Wang, Bowen and Zhang, Chenhui and Yin, Da and Zhang, Dan and Rojas, Diego and Feng, Guanyu and Zhao, Hanlin and others},
  journal={arXiv preprint arXiv:2406.12793},
  year={2024}
}

@article{team2024gemma,
  title={Gemma 2: Improving open language models at a practical size},
  author={Team, Gemma and Riviere, Morgane and Pathak, Shreya and Sessa, Pier Giuseppe and Hardin, Cassidy and Bhupatiraju, Surya and Hussenot, L{\'e}onard and Mesnard, Thomas and Shahriari, Bobak and Ram{\'e}, Alexandre and others},
  journal={arXiv preprint arXiv:2408.00118},
  year={2024}
}

@inproceedings{lee2021towards,
  title={Towards Few-shot Fact-Checking via Perplexity},
  author={Lee, Nayeon and Bang, Yejin and Madotto, Andrea and Fung, Pascale},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={1971--1981},
  year={2021}
}

@inproceedings{ma2019sentence,
  title={Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks},
  author={Ma, Jing and Gao, Wei and Joty, Shafiq and Wong, Kam-Fai},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={2561--2571},
  year={2019}
}

@inproceedings{shu2019defend,
  title={defend: Explainable fake news detection},
  author={Shu, Kai and Cui, Limeng and Wang, Suhang and Lee, Dongwon and Liu, Huan},
  booktitle={Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={395--405},
  year={2019}
}

@inproceedings{lin2021rumor,
  title={Rumor Detection on Twitter with Claim-Guided Hierarchical Graph Attention Networks},
  author={Lin, Hongzhan and Ma, Jing and Cheng, Mingfei and Yang, Zhiwei and Chen, Liangliang and Chen, Guang},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={10035--10047},
  year={2021}
}

@inproceedings{abney2002bootstrapping,
  title={Bootstrapping},
  author={Abney, Steven},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={360--367},
  year={2002}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th annual acm symposium on user interface software and technology},
  pages={1--22},
  year={2023}
}

@article{dubois2024length,
  title={Length-controlled alpacaeval: A simple way to debias automatic evaluators},
  author={Dubois, Yann and Galambosi, Bal{\'a}zs and Liang, Percy and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2404.04475},
  year={2024}
}

@inproceedings{cheng2024autodetect,
  title={AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models},
  author={Cheng, Jiale and Lu, Yida and Gu, Xiaotao and Ke, Pei and Liu, Xiao and Dong, Yuxiao and Wang, Hongning and Tang, Jie and Huang, Minlie},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={6786--6803},
  year={2024}
}

@article{wang2024mfc,
  title={MFC-Bench: Benchmarking Multimodal Fact-Checking with Large Vision-Language Models},
  author={Wang, Shengkang and Lin, Hongzhan and Luo, Ziyang and Ye, Zhen and Chen, Guang and Ma, Jing},
  journal={arXiv preprint arXiv:2406.11288},
  year={2024}
}

@inproceedings{lin2022amif,
  title={Amif: A hybrid model for improving fact checking in product question answering},
  author={Lin, Hongzhan and Chen, Liangliang and Ma, Jing and Yang, Zhiwei and Chen, Guang},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2022},
  organization={IEEE}
}