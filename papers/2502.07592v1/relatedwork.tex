\section{Literature Review}
There has been limited research on automated defect detection in optical lenses. Existing studies predominantly focus on two key approaches: traditional image processing techniques and deep learning-based object detection models. Image processing techniques often leverage specialized lighting setups, such as fringe deflectometry and dark-field illumination, to enhance defect visibility. Deep learning approaches, on the other hand, aim to automate feature extraction and improve detection accuracy through advanced neural networks. While both methods have demonstrate effectiveness, they have various trade-offs in terms of accuracy, computational complexity, and real time application.

Starting with image processing techniques, Pan et al. \cite{pan2019comprehensive} proposed a comprehensive, automated defect-detection system for small-sized curved optical lenses using fringe deflectometry, dark-field illumination, and light transmission. Their system achieved an impressive detection accuracy of up to 6 µm for three major defect types: surface-profile defects, internal impurities, and haze defects. However, while their system provided high precision, its reliance on specialized lighting conditions and controlled environments raises concerns about scalability in real-world factory settings.

Similarly, Ding et al. \cite{ding2020automatic} developed a machine vision-based system for detecting dispersed defects in resin eyeglasses. Their approach combined transmission and reflection imaging to enhance gray-scale gradient contrasts in defect regions. A specialized image processing algorithm was then applied for segmentation and enhancement. The system achieved a detection accuracy of 97.5\% with an average processing time of 0.636 seconds per lens, making it well-suited for online inspection systems. However, this method's dependence on predefined lighting conditions and handcrafted features limits its adaptability to lenses of varying shapes, materials, and defect types.

Xian Tao et al. [7] \cite{tao2015novel} extended the use of bright-field and dark-field illumination techniques to inspect large-aperture optical elements. Their system could scan 810 mm × 460 mm lenses in under six minutes, effectively detecting scratches, pits, and dust. However, it was incapable of identifying fine surface watermarks, which are common defects in smaller, curved optical lenses. Additionally, the mechanical setup and operational constraints made the method impractical for high-speed production lines.

Focusing on limited literature specific to machine learning techniques for defect detection in optical lenses, Yang et al. \cite{yang2023deep} introduced MVIS (Micro Vision Inspection System) combined with an enhanced deep-learning model (ISE-YOLO) to detect weak micro-defects on optical lenses. Their model incorporated an Improved Squeeze-and-Excitation (ISE) module and a PolyLoss function to correct class imbalance and enhance feature extraction. Experimental results showed that ISE-YOLO outperformed Faster R-CNN, YOLOv3, YOLOv5, YOLOv6, and YOLOv7, achieving an mAP of 94.23\% and an F1 score of 90.60\%. However, despite its strong performance, ISE-YOLO’s computational cost was not analyzed, raising questions about its feasibility for real-time defect detection on edge devices.

Tang et al. \cite{tang2023improved} proposed STMask R-CNN, a deep-learning approach designed to detect low-contrast, varying-size, and overlapping defects in optical lenses. By incorporating a Swin Transformer, the model improved feature representation and detection accuracy. Using a dataset of 3,800 images with five different defect types, STMask R-CNN outperformed SSD, Faster R-CNN, RetinaNet, and YOLOv5, achieving 98.2\% precision, 97.7\% recall, and an mAP@0.5 of 98.1\%. However, Mask R-CNN-based architectures are computationally expensive, making them less practical for real-time deployment in industrial environments.

Lin et al. \cite{lin2024optical} introduced WGSO-YOLO, an improved optical lens defect detection model that builds upon the YOLO framework. Their approach incorporates three key enhancements: GSConv (a lightweight convolution module) to reduce computational complexity, SOCA (Second-Order Channel Attention) to enhance feature extraction, and WIoU (Wise-IoU loss function) to improve localization accuracy and handle low-quality samples more effectively. The model was evaluated on a custom optical lens defect dataset containing 1,059 images and achieved a mean average precision (mAP@0.5) of 0.927 with a processing speed of 96 FPS. The performance on unseen defect types and real-world variations (e.g., lighting changes, motion blur) remains unclear.

While the image processing techniques reviewed provide high detection accuracy, they are heavily dependent on controlled environments and specific lighting conditions, limiting their adaptability in dynamic manufacturing settings. These methods also struggle with generalizing to different lens types and defect variations.On the other hand, deep learning-based models have shown promising improvements in detection accuracy and robustness. Most studies focus primarily on accuracy metrics (mAP, precision, recall) without considering computational feasibility for real-time industrial deployment.

Considering these limitations, this study adopts YOLOv8 for optical lens defect detection, as it offers a balanced trade-off between accuracy, speed, and computational efficiency. Compared to previous YOLO versions, YOLOv8 features an improved backbone, advanced anchor-free detection, and better feature aggregation, making it well-suited for real-time industrial deployment. Furthermore, YOLOv8’s lighter architecture allows it to be deployed on edge computing devices, enabling real-time defect detection in factory environments.