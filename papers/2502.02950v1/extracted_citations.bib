@article{anastassiou2024seedtts,
  title={Seed-TTS: A Family of High-Quality Versatile Speech Generation Models},
  author={Anastassiou, Philip and Chen, Jiawei and Chen, Jitong and Chen, Yuanzhe and Chen, Zhuo and Chen, Ziyi and Cong, Jian and Deng, Lelai and Ding, Chuang and Gao, Lu and others},
  journal={arXiv preprint arXiv:2406.02430},
  year={2024}
}

@article{borsos2022audiolm,
  title={Audiolm: a language modeling approach to audio generation.(2022)},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and Zeghidour, Neil},
  journal={arXiv preprint arXiv:2209.03143},
  year={2022}
}

@article{chen2024uno,
  title={Enhancing Zero-shot Text-to-Speech Synthesis with Human Feedback},
  author={Chen, Chen and Hu, Yuchen and Wu, Wen and Wang, Helin and Chng, Eng Siong and Zhang, Chao},
  journal={arXiv preprint arXiv:2406.00654},
  year={2024}
}

@article{defossez2022high,
  title={High fidelity neural audio compression},
  author={D{\'e}fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
  journal={arXiv preprint arXiv:2210.13438},
  year={2022}
}

@article{du2024cosyvoice,
  title={{CosyVoice}: A scalable multilingual zero-shot text-to-speech synthesizer based on supervised semantic tokens},
  author={Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others},
  journal={arXiv preprint arXiv:2407.05407},
  year={2024}
}

@article{hu2024rio,
  title={Robust Zero-Shot Text-to-Speech Synthesis with Reverse Inference Optimization},
  author={Hu, Yuchen and Chen, Chen and Wang, Siyin and Chng, Eng Siong and Zhang, Chao},
  journal={arXiv preprint arXiv:2407.02243},
  year={2024}
}

@article{kharitonov2023speak,
  title={Speak, read and prompt: High-fidelity text-to-speech with minimal supervision},
  author={Kharitonov, Eugene and Vincent, Damien and Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Girgin, Sertan and Pietquin, Olivier and Sharifi, Matt and Tagliasacchi, Marco and Zeghidour, Neil},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={1703--1718},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~â€¦}
}

@article{lajszczak2024base,
  title={BASE TTS: Lessons from building a billion-parameter text-to-speech model on 100K hours of data},
  author={{\L}ajszczak, Mateusz and C{\'a}mbara, Guillermo and Li, Yang and Beyhan, Fatih and van Korlaar, Arent and Yang, Fan and Joly, Arnaud and Mart{\'\i}n-Cortinas, {\'A}lvaro and Abbas, Ammar and Michalski, Adam and others},
  journal={arXiv preprint arXiv:2402.08093},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{peng2024voicecraft,
  title={Voicecraft: Zero-shot speech editing and text-to-speech in the wild},
  author={Peng, Puyuan and Huang, Po-Yao and Li, Shang-Wen and Mohamed, Abdelrahman and Harwath, David},
  journal={arXiv preprint arXiv:2403.16973},
  year={2024}
}

@article{rafailov2024dpo,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{tian2024tx_rl,
  title={Preference Alignment Improves Language Model-Based TTS},
  author={Tian, Jinchuan and Zhang, Chunlei and Shi, Jiatong and Zhang, Hao and Yu, Jianwei and Watanabe, Shinji and Yu, Dong},
  journal={arXiv preprint arXiv:2409.12403},
  year={2024}
}

@article{wang2023valle,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}

@article{xin2024ralle,
  title={Rall-e: Robust codec language modeling with chain-of-thought prompting for text-to-speech synthesis},
  author={Xin, Detai and Tan, Xu and Shen, Kai and Ju, Zeqian and Yang, Dongchao and Wang, Yuancheng and Takamichi, Shinnosuke and Saruwatari, Hiroshi and Liu, Shujie and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2404.03204},
  year={2024}
}

@article{zeghidour2021soundstream,
  title={Soundstream: An end-to-end neural audio codec},
  author={Zeghidour, Neil and Luebs, Alejandro and Omran, Ahmed and Skoglund, Jan and Tagliasacchi, Marco},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={495--507},
  year={2021},
  publisher={IEEE}
}

@article{zhang2023speechgpt,
  title={Speechgpt: Empowering large language models with intrinsic cross-modal conversational abilities},
  author={Zhang, Dong and Li, Shimin and Zhang, Xin and Zhan, Jun and Wang, Pengyu and Zhou, Yaqian and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2305.11000},
  year={2023}
}

@article{zhang2024speechalign,
  title={SpeechAlign: Aligning Speech Generation to Human Preferences},
  author={Zhang, Dong and Li, Zhaowei and Li, Shimin and Zhang, Xin and Wang, Pengyu and Zhou, Yaqian and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2404.05600},
  year={2024}
}

