% 如果您使用 overleaf，您只需单击“提交”图标并选择“Arxiv”选项，它将为您提供所需的所有文件。


% edit link: https://www.overleaf.com/7243917635qvjxbtpbhxbg#f5184e

%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,9pt]{acmart}

\makeatletter
\def\@ACM@checkaffil{% Only warnings
    \if@ACM@instpresent\else
    \ClassWarningNoLine{\@classname}{No institution present for an affiliation}%
    \fi
    \if@ACM@citypresent\else
    \ClassWarningNoLine{\@classname}{No city present for an affiliation}%
    \fi
    \if@ACM@countrypresent\else
        \ClassWarningNoLine{\@classname}{No country present for an affiliation}%
    \fi
}
\makeatother

% \documentclass[sigconf,9pt]{manuscript}
% \documentclass[manuscript, anonymous, sigconf]{acmart}
%% NOTE that a single column version may be required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


% \renewcommand\footnotetextcopyrightpermission[1]{}
\setcopyright{acmcopyright}
\settopmatter{printacmref=true, printccs=true, printfolios=false}
% Rights management information.  This information is sent to you
% when you complete the rights form.  These commands have SAMPLE
% values in them; it is your responsibility as an author to replace
% the commands and values with those provided to you when you
% complete the rights form.
% \setcopyright{acmcopyright}
% \copyrightyear{2018}
% \acmYear{2018}
% \acmDOI{XXXXXXX.XXXXXXX}
% \renewcommand{\baselinestretch}{0.95}


% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[Conference acronym 'XX]{Make sure to enter the correct
%   conference title from your rights confirmation emai}{June 03--05,
%   2018}{Woodstock, NY}

 % Uncomment \acmBooktitle if th title of the proceedings is different
 % from ``Proceedings of ...''!

% \acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}
% \renewcommand{\baselinestretch}{.95} % line space
% Systems (SenSys '22), November 6--9, 2022, Boston, MA, USA}

\copyrightyear{2025}
\acmYear{2025}
\setcopyright{rightsretained}
\acmConference[ACM SenSys '25]{The 23th ACM Conference on Embedded Networked Sensor Systems}{May 6-9, 2025}{Irvine, USA}
\acmBooktitle{The 23th ACM Conference on Embedded Networked Sensor Systems (SenSys '25), May 6-9, 2025, Irvine, USA}
\acmDOI{xx.xxxx/xxxxxxx.xxxxxxx}
\acmISBN{xxx-x-xxxx-xxxx-x/xx/xx}
%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command. 
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{subfigure}
\usepackage{multicol}
% \usepackage{subcaption}
\setlength\columnsep{0.33in}
% \renewcommand{\baselinestretch}{0.97}
% \usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{caption}
\captionsetup{labelfont=bf}
\usepackage{bbding}
\usepackage{pifont}
\usepackage{graphicx} % 引入 graphicx 包
\usepackage{url}
\usepackage{gensymb}
% \usepackage[colorlinks,linkcolor=blue]{hyperref}


%=== Editing tools ============
\ifodd 1
\newcommand{\rev}[1]{{\color{blue}#1}} %revise of the text
\newcommand{\com}[1]{\textbf{\color{red}(COMMENT: #1)}} %comment of the 
\else
\newcommand{\rev}[1]{#1}
\newcommand{\com}[1]{}
\fi

\newcommand{\term}[1]{{\it #1}}
\newcommand{\empha}[1]{{\bf #1}}
\newcommand{\head}[1]{{\bf #1}}
\newcommand{\scare}[1]{`#1'}
\newcommand{\code}[1]{{\tt #1}}
\newcommand{\lnote}[1]{Lognfei: {\color{red}{#1}}}
\newcommand{\notsure}[1]{{\color[rgb]{0.7,0.7,0.7}{#1}}}
\newcommand{\todo}[1]{{\color{red}{\textbf{TODO:} #1}}}
\newcommand{\notice}[1]{{\color{red}{#1}}}
\newcommand{\bsymb}[1]{{\boldsymbol #1}}
\newcommand{\tocite}{\rev{[?]}}
\newcommand{\toref}{\rev{?}}
% \newcommand{\revise}[1]{{\color{blue}{#1}}}
\newcommand{\revise}[1]{{\color{black}{#1}}}

\def\fig{Fig.}
\def\sec{Section}
\def\tab{Table}
\def\eg{e.g.}
\def\ie{i.e.}
\def\aka{a.k.a.}
\def\eqn{Eqn.}
\def\eq{Eq.}
\def\alg{Algorithm}
\def\etc{etc.}

% \copyrightyear{2022}
% \acmYear{2022}
% \setcopyright{rightsretained}
% \acmConference[SenSys '22]{The 20th ACM Conference on Embedded
% Networked Sensor Systems}{November 6--9, 2022}{Boston, MA, USA}
% \acmBooktitle{The 20th ACM Conference on Embedded Networked Sensor
% Systems (SenSys '22), November 6--9, 2022, Boston, MA, USA}
% \acmDOI{10.1145/3560905.3568432}
% \acmISBN{978-1-4503-9886-2/22/11}

\begin{document}
% \begin{figure*}[t]
%     \setlength{\abovecaptionskip}{-0cm} % height above Figure X caption
%     \setlength{\belowcaptionskip}{-0.24cm}
%     \setlength{\subfigcapskip}{-0.25cm}
%     \centering
%         \includegraphics[width=1.\columnwidth]{Figs/introall.png}
%         % \vspace{-0.2cm}
%     \caption{Illustration of the airport and landing of the delivery drone. \textnormal{(a) The self-collection airport is equipped with multiple delivery drones for package distribution. (b) A delivery drone descends onto the landing platform.}}
%     \label{intro}
%     % \vspace{-0.2cm}
% \end{figure*} 

% \let\oldtwocolumn\twocolumn
% \renewcommand\twocolumn[1][]{%
%     \oldtwocolumn[{#1}{
%     \begin{center}
%     \vspace{-0.5cm}
%     \setlength{\belowcaptionskip}{0.24cm}
%     \setlength{\abovecaptionskip}{-0.cm}
%            \includegraphics[width=2.1\columnwidth]{Figs/introall.png}
%            \captionof{figure}{Illustration of airport, landing of the delivery drone, sensors and algorithms performance. \textnormal{(a) The self-collection airport is equipped with multiple delivery drones for package distribution. (b) A delivery drone lands onto the platform. (c) Enhancing mmWave radar with event camera could have high spatial-temporal resolution and depth sensing capability. (d) Field study system performance comparison: green circles represent frame camera-based solutions, purple for mmWave radar-based, blue for radar-camera fusion, and red for event camera-based solutions.}}
%            \label{intro}
%         \end{center}
%     }]
% }


% \thispagestyle{empty} % no page number for the first page
% \pagestyle{empty}  % no page number for the second and the later pages

\newcommand{\mycustomsize}{\fontsize{21}{\baselineskip}\selectfont}
% \newcommand{\mycustomsize}{\fontsize{20}{\baselineskip}\selectfont}

% \title[EventLoc]{\mycustomsize{EventLoc: Unleashing the Potential of Event Camera in Low Latency 3D Object Localization with mmWave Radar}}
% \title[mmE-Loc]{\mycustomsize{High-Resolution Temporal Consistency Matters: Enhancing mmWave Radar with Event Camera for Accurate Drone Landing }}
% \title[mmE-Loc]{\mycustomsize{Ultra-High-Frequency Harmony: mmWave Radar and \\ Event Camera Orchestrate Accurate Drone Landing}}
\title[Ultra-High-Frequency Harmony: \\mmWave Radar and Event Camera Orchestrate Accurate Drone Landing]
{Ultra-High-Frequency Harmony: mmWave Radar and \\ Event Camera Orchestrate Accurate Drone Landing }
% 1. EventLoc: Enhancing mmWave Radars with Event Cameras for Low Latency Landing Drone Ground Localization 
% 2. mmEvent: Enhancing mmWave Radars with Event Cameras for Low Latency Landing Drone Ground Localization 
% 3. mmE-Loc: Enhancing mmWave Radars with Event Cameras for Low Latency Landing Drone Ground Localization 
% 4. FLASH：Enhancing mmWave Radars with Event Cameras for Low Latency Landing Drone Ground Localization 
% 5. mmE-$L^4$oc：Enhancing mmWave Radars with Event Cameras for Low Latency Landing Drone Ground Localization 
% 6. FLARE：Enhancing mmWave Radars with Event Cameras for Fast Landing Drone Ground Localization 
% 7. EventNest：Enhancing mmWave Radars with Event Cameras for Fast Landing Drone Ground Localization  

\author{Haoyang Wang$^{1}$, Jingao Xu$^{2}$, Xinyu Luo$^{1}$, Xuecheng Chen$^{1}$, Ting Zhang$^{1}$, \\ Ruiyang Duan$^3$, Yunhao Liu$^{4}$, Xinlei Chen$^{1, 5, 6}$\textsuperscript{\Envelope}}

\renewcommand{\authors}{Haoyang Wang, Jingao Xu, Xinyu Luo, Xuecheng Chen, Ting Zhang, Ruiyang Duan, Yunhao Liu, Xinlei Chen}

\affiliation{%
    \institution{$^1$ Shenzhen International Graduate School, Tsinghua University, China; $^2$ Carnegie Mellon University; \\$^3$ Meituan Academy of Robotics Shenzhen, China; $^4$ School of Software, Tsinghua University, China; \\$^5$ Pengcheng Laboratory, Shenzhen, China; $^6$ RISC-V International Open Source Laboratory, Shenzhen, China}
    \country{}
    \city{}
}

% \affiliation{%
%  \institution{$^1$ Shenzhen International Graduate School, Tsinghua University, China; $^2$ Carnegie Mellon University; $^3$ Meituan Technology, Shenzhen, China; $^4$ School of Software, Tsinghua University, China; $^5$ Pengcheng Laboratory, Shenzhen, China; $^6$ RISC-V International Open Source Laboratory, Shenzhen, China}
% }

\affiliation{%
  \institution{Email: \{haoyang-22, luo-xy23, chenxc21, yunhao\}@mails.tsinghua.edu.cn, \{xujingao13, zhangt2112\}@gmail.com, \\ duanruiyang@meituan.com, chen.xinlei@sz.tsinghua.edu.cn}
}

\renewcommand{\shortauthors}{Haoyang Wang, et al.}

% mmE$L^4$oc

% mmE-Loc: Enhancing mmWave Radars with Event Cameras for Low Latency Landing Drone Ground Localization 

% Low Latency 
% 3D Localization
% Landing drone ground Localization

% Temporal Consistency Matters: Enhancing mmWave Radars with Event Cameras for Low Latency Landing Drone Ground Localization 

% Temporal Consistency Matters: Enhancing mmWave Radar with Event Camera for Accurate Drone Landing 

% High Temporal Resolution Consistency Matters: Enhancing mmWave Radar with Event Camera for Accurate Drone Landing 

% Baseline: 
% High-Resolution Temporal Consistency Matters: Enhancing mmWave Radar with Event Camera for Accurate Drone Landing 
% 缩写：mmE-Loc

% \title[EventLoc]{EventLoc: Enhancing Event Cameras for Low Latency 3D Object Localization with mmWave Radar Integration}
% EventLoc: Leveraging mmWave Radar for Enhanced Low Latency 3D Object Localization with Event Cameras
% EventLoc: Enhancing Low Latency 3D Object Localization in Event Cameras with mmWave Radar Integration
% Unleashing the Potential of Event Camera in 3D localization with mmWave Radar: A Case for Landing Drone Tracking

% \author{Anonymous}

% \authornote{Both authors contributed equally to this research.}
% \affiliation{%
%   \institution{Shenzhen International Graduate School, Tsinghua University}
%     \city{Shenzhen}
%   \country{China}
% }
% \email{haoyang-22@mails.tsinghua.edu.cn}

% \author{Xuecheng Chen}
% \authornotemark[1]
% \affiliation{%
%   \institution{Tsinghua-Berkeley Shenzhen Institute, Tsinghua University}
%   \city{Shenzhen}
%   \country{China}
% }
% \email{chenxc21@mails.tsinghua.edu.cn}

% \author{Yuhan Cheng}
% \affiliation{%
%   \institution{Shenzhen International Graduate School, Tsinghua University}
%   \city{Shenzhen}
%   \country{China}
% }
% \email{cyh22@mails.tsinghua.edu.cn}

% \author{Chenye Wu}
% \affiliation{%
%   \institution{The Chinese University of Hong Kong, Shenzhen}
%   \city{Shenzhen}
%   \country{China}
% }
% \email{chenyewu@yeah.net}

% \author{Fan Dang}
% \affiliation{%
%   \institution{Global Innovation Exchange, Tsinghua University}
%     \city{Beijing}
%   \country{China}
% }
% \email{dangfan@tsinghua.edu.cn}

% \author{Xinlei Chen}
% \authornote{Xinlei Chen is the corresponding author.}
% \affiliation{%
%   \institution{Shenzhen International Graduate School, Tsinghua University}
%    \institution{Peng Cheng Laboratory}
%     \city{Shenzhen}
%   \country{China}
% }
% \email{chen.xinlei@sz.tsinghua.edu.cn}


%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.

% \renewcommand{\shortauthors}{Wang, et al.}



\begin{abstract}

For precise, efficient, and safe drone landings, ground platforms should real-time, accurately locate descending drones and guide them to designated spots.
% While mmWave sensing combined with cameras improves localization accuracy, 
% % frame cameras introduce latency and throughput bottlenecks that limit location update rates.
% the lower sampling frequencies of traditional frame cameras compared to mmWave radar introduce localization latency and create bottlenecks in system throughput.
While mmWave sensing combined with cameras improves localization accuracy, the lower sampling frequency of traditional frame cameras compared to mmWave radar creates bottlenecks in system throughput. 
In this work, we replace the traditional frame camera with event camera, a novel sensor that harmonizes in sampling frequency with mmWave radar within the ground platform setup, and introduce mmE-Loc, a high-precision, low-latency ground localization system designed for drone landings.
To fully leverage the \textit{temporal consistency} and \textit{spatial complementarity} between these modalities, we propose two innovative modules, \textit{consistency-instructed collaborative tracking} and \textit{graph-informed adaptive joint optimization}, for accurate drone measurement extraction and efficient sensor fusion.
% We propose two novel algorithms: Consistency-Instructed Collaborative Tracking and Graph-Informed Adaptive Joint Optimization, which leverage \textit{temporal consistency} and \textit{spatial complementarity} between modalities for accurate drone measurements extraction and efficient sensor fusion.
% Extensive real-world experiments in landing scenarios from, conducted with a leading drone delivery company demonstrate that mmE-Loc outperforms state-of-the-art methods in both localization accuracy and latency.
Extensive real-world experiments in landing scenarios from a leading drone delivery company demonstrate that mmE-Loc outperforms state-of-the-art methods in both localization accuracy and latency. 
\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010520.10010553.10003238</concept_id>
       <concept_desc>Computer systems organization~Sensor networks</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010178.10010199.10010201</concept_id>
       <concept_desc>Computing methodologies~Planning under uncertainty</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[500]{Information systems~Location based services}
% \ccsdesc[500]{Computing methodologies~Planning under uncertainty}

%
% Keywords. The author(s) should pick words that accurately describe
% the work being presented. Separate the keywords with commas.
\keywords{Drone Ground Localization; Event Camera; mmWave Radar}

\maketitle 

\renewcommand{\thefootnote}{}
\footnotetext{\Envelope\ Corresponding author.}
\footnotetext{Project homepage: \href{https://mmE-Loc.github.io/}{\color{blue}{https://mmE-Loc.github.io/}}}

\input{intro_SenSys25}
\input{Overview}
\input{Design}
\input{implementation}
\input{Evaluation}
\input{relatedWork}
\input{Discussion}
\input{Conclusion}
\input{acknowledegement}
\newpage
\balance



% \input{RelatedWork}

% \section{Acknowledgments}

% Identification of funding sources and other support, and thanks to
% individuals and groups that assisted in the research and the
% preparation of the work should be included in an acknowledgment
% section, which is placed just before the reference section in your
% document.

% This section has a special environment:
% \begin{verbatim}
%   \begin{acks}
%   ...
%   \end{acks}
% \end{verbatim}
% so that the information contained therein can be more easily collected
% during the article metadata extraction phase, and to ensure
% consistency in the spelling of the section heading.

% Authors should not prepare this section as a numbered or unnumbered {\verb|\section|}; please use the ``{\verb|acks|}'' environment.

% \section{Appendices}

% If your work needs an appendix, add it before the
% ``\verb|\end{document}|'' command at the conclusion of your source
% document.

% Start the appendix with the ``\verb|appendix|'' command:
% \begin{verbatim}
%   \appendix
% \end{verbatim}
% and note that in the appendix, sections are lettered, not
% numbered. This document has two appendices, demonstrating the section
% and subsection identification method.

% \section{SIGCHI Extended Abstracts}

% The ``\verb|sigchi-a|'' template style (available only in \LaTeX\ and
% not in Word) produces a landscape-orientation formatted article, with
% a wide left margin. Three environments are available for use with the
% ``\verb|sigchi-a|'' template style, and produce formatted output in
% the margin:
% \begin{itemize}
% \item {\verb|sidebar|}:  Place formatted text in the margin.
% \item {\verb|marginfigure|}: Place a figure in the margin.
% \item {\verb|margintable|}: Place a table in the margin.
% \end{itemize}

% %%
% %% The acknowledgments section is defined using the "acks" environment
% %% (and NOT an unnumbered section). This ensures the proper
% %% identification of the section in the article metadata, and the
% %% consistent spelling of the heading.
% \begin{acks}
% To Robert, for the bagels and explaining CMYK and color spaces.
% \end{acks}

% %%
% %% The next two lines define the bibliography style to be used, and
% %% the bibliography file.
\bibliographystyle{unsrt}
% \bibliography{sample-base}
\bibliography{reference}

% %%
% %% If your work has an appendix, this is the place to put it.
% \appendix

% \section{Research Methods}

% \subsection{Part One}

% Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi
% malesuada, quam in pulvinar varius, metus nunc fermentum urna, id
% sollicitudin purus odio sit amet enim. Aliquam ullamcorper eu ipsum
% vel mollis. Curabitur quis dictum nisl. Phasellus vel semper risus, et
% lacinia dolor. Integer ultricies commodo sem nec semper.

% \subsection{Part Two}

% Etiam commodo feugiat nisl pulvinar pellentesque. Etiam auctor sodales
% ligula, non varius nibh pulvinar semper. Suspendisse nec lectus non
% ipsum convallis congue hendrerit vitae sapien. Donec at laoreet
% eros. Vivamus non purus placerat, scelerisque diam eu, cursus
% ante. Etiam aliquam tortor auctor efficitur mattis.

% \section{Online Resources}

% Nam id fermentum dui. Suspendisse sagittis tortor a nulla mollis, in
% pulvinar ex pretium. Sed interdum orci quis metus euismod, et sagittis
% enim maximus. Vestibulum gravida massa ut felis suscipit
% congue. Quisque mattis elit a risus ultrices commodo venenatis eget
% dui. Etiam sagittis eleifend elementum.

% Nam interdum magna at lectus dignissim, ac dignissim lorem
% rhoncus. Maecenas eu arcu ac neque placerat aliquam. Nunc pulvinar
% massa et mattis lacinia.

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
