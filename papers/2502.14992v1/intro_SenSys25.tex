\vspace{-0.8cm}
\section{Introduction}

Projected to soar to a \$1 trillion market by 2040 \cite{low_altitude_eco}, the drone-driven low-altitude economy is transforming sectors with revolutionary applications such as on-demand delivery \cite{wang2022micnest, chen2024ddl, chen2022deliversense}, meticulous industrial inspections \cite{xu2022swarmmap, li2024quest, xu2019vehicle, liu2024mobiair}, and rapid relief-and-rescue \cite{zhang2023rf, chi2022wi, chen2024soscheduler}. 
Of paramount importance within this burgeoning sector is the \textit{landing phase}, where ground platforms locate drones descending from below 10 meters and guide them to accurately land at designated spots (\fig\ref{intro}a) \cite{he2023acoustic, sun2022aim}.
Situated near populated and commercial zones, these operations emphasize safety and reliability: our research with a leading drone delivery company reveals that a landing bias of just 10$cm$ will result in drones damaging delivery targets or missing their charging ports \cite{gonzalez2021visual}. 
Such inaccuracies disrupt the operational efficiency of this swiftly growing economic sector, with potentially severe consequences.

\begin{figure}[t]
    \setlength{\abovecaptionskip}{0.25cm} % height above Figure X caption
    \setlength{\belowcaptionskip}{-0.3cm}
    \setlength{\subfigcapskip}{-0.5cm}
    \centering
        \includegraphics[width=0.92\columnwidth]{Figs/intro_v.png}
        \vspace{-0.2cm}
    \caption{Snapshot of drone landing phase, airport, and sensors performance. \textnormal{(a) A delivery drone lands on the platform. (b) The real-world drone airport is equipped with multiple drones for package delivery. 
    (c) Integrating mmWave radar with event camera combines reliable depth sensing and 2D imaging at ultra-high sampling frequencies, enabling high spatial-temporal resolution and depth sensing, while ensuring compatibility with flight controllers.}}
    \label{intro}
\end{figure} 

Widely adopted and straightforward approaches involve installing cameras at the center or edges of drone landing pads and employing computer vision algorithms for drone localization \cite{li2018real,xia2023anemoi,zhang2019eye}.
However, traditional frame cameras' Achilles heel is capturing only 2D images without depth information, leading to scale uncertainty that limits the 3D localization accuracy \cite{zhang2022mobidepth,xie2023mozart,10.1145/3517260}.
To address this shortcoming, current practices have incorporated mmWave sensing to provide the lacked depth information for better localization accuracy and reliability in various conditions \cite{deng2022geryon, lu2020smokerobustindoormapping,zhang2023mmhawkeye, sie2023batmobility, iizuka2023millisign, lu2020see, lu2020milliego}.

Albeit inspiring, our benchmark study with a world-leading drone delivery company in landing scenarios (\fig \ref{intro}b) reveals another critical drawback (\fig \ref{intro}c): the exposure times of frame cameras (>20$ms$) prevent their sampling rates from matching the high frequency of mmWave radars (\eg, 200Hz). 
This limitation creates system efficiency and throughput bottlenecks, restricting drone location updates to below 50Hz.
In contrast, drone flight controllers typically require location input rates over 150Hz to precisely adjust the drone's flight attitude for safe landing \cite{8412592, 10.1145/3570361.3592532}.
The inefficiency originates from the inherent physical limitations of conventional frame cameras and cannot be easily solved by software solutions.


\noindent \textbf{Upgrade frame camera to event camera.}
Event cameras are bio-inspired sensors that report pixel-wise intensity changes with $ms$-level resolution \cite{gallego2020event, ruan2024distill}, capturing high-speed motions without blurring \cite{he2024microsaccade}, ideal for fast-tracking tasks \cite{xu2023taming, luo2024eventtracker}.
Event cameras offer $ms$-level sampling latency, which harmonizes exceptionally with the high sampling frequencies of mmWave radar.
Their 2D imaging capability also complements radars' limited spatial resolution, similar to how traditional frame cameras operate.
Such \textit{temporal-consistency} and \textit{spatial-complementarity} across both modalities inspire us to upgrade frame cameras with event cameras to pair with radar for accurate and fast drone localization.


\noindent \textbf{Our work.}
Following the above insight, we present \textbf{mmE-Loc}, the first active, high-precision, and low-latency landing drone ground localization system that enhances mmWave radar functionality with event cameras. 
mmE-Loc works in scenarios where urban canyon environments degrade the accuracy of GPS or RTK systems as altitude decreases, rendering them nearly ineffective for the landing phase. 
With mmE-Loc, drones achieve reliable localization even under challenging conditions (\eg, weak illumination), ensuring stable and efficient landing.

However, our benchmark study at a real-world drone delivery airport (\fig \ref{relatedwork}a) highlights several challenges that have been solved in making \textbf{mmE-Loc} a viable system outdoors:
$(i)$ \textit{How to accurately extract drone-related measurements} given the immense noisy output of event cameras and mmWave radars, which also lack inherent drone semantic information and differ greatly in dimension and pattern?
Both modalities are sensitive to environmental variations (\eg, changes in lighting conditions), as shown in \fig \ref{relatedwork}b.
Existing algorithms \cite{cao2024virteach, liu2024pmtrack, wang2021asynchronous, alzugaray2018asynchronous} are typically designed for single-modality, resulting in low noise filtering rates (recall and precision < 65\% in \fig \ref{relatedwork}c).
$(ii)$ \textit{How to efficiently fuse event camera and mmWave readings} that are heterogeneous in measurement precision, scale, and density? 
Existing EKF (extended Kalman filter) or PF (particle filter) based approaches \cite{falanga2020dynamic,zhao20213d, mitrokhin2018event}, suffer from cumulative drift errors, making them insufficient for precise localization (\fig \ref{relatedwork}d).
$(iii)$ \textit{How to optimize the efficiency of the fusion algorithm} to achieve high-frequency drone ground localization, given the limited computational resources on landing platforms?
Existing methods experience significant processing delays, rendering them unsuitable for low-latency localization tasks (\fig \ref{relatedwork}d) \cite{zhao20213d, falanga2020dynamic, mitrokhin2018event}.

To solve the above challenges, the design and implementation of mmE-Loc excel in the three aspects of drone ground localization:

\noindent $\bullet$ \textit{On system architecture front.}
Upgrading frame camera to event camera with $ms$-level latency to pair the mmWave radar, mmE-Loc improves drone ground localization at data source.
The system architecture tightly integrates both modalities, from early-stage noise filtering and drone detection to later-stage fusion and optimization, fully leveraging the unique advantages of both sensors (ยง\ref{3.2}).\\
\noindent $\bullet$ \textit{On system algorithm front.}
We introduce a Consistency-Instructed Collaborative Tracking (\textit{CCT}) algorithm, which leverages the drone's periodic micro-motion and cross-modal \textit{temporal-consistency} to filter environment-triggered noise, achieving accurate drone detection (ยง\ref{4.1}). 
We then present a Graph-Informed Adaptive Joint Optimization (\textit{GAJO}) algorithm, which fuses \textit{spatial-complementarity} with a novel factor graph to boost drone ground localization, resulting in a trajectory with minimal bias and low cumulative drift(ยง\ref{4.2}). \\
\noindent $\bullet$ \textit{On system implementation front.}
We further analyze the sources of latency and propose an Adaptive Optimization method to improve the efficiency of the \textit{GAJO} algorithm.
This approach allows \textit{GAJO} to dynamically optimize a set of locations, maintaining accuracy while reducing latency (ยง\ref{I}).

\begin{figure}[t]
    \setlength{\belowcaptionskip}{-0.3cm}
    \setlength{\subfigcapskip}{-0.25cm}
    \centering
        \includegraphics[width=0.9\columnwidth]{Figs/relatedall_4.png}
        \vspace{-0.4cm}
    \caption{
    Benchmark study on drone localization.
    \textnormal{(a) Benchmark study at a real-world drone delivery airport; (b) Both sensors are sensitive to environmental variations; (c) Existing algorithms suffer from low noise filtering rates; (d) Existing algorithms experience cumulative drift errors and delays. }}
    \label{relatedwork}
    \vspace{-0.5cm}
\end{figure} 

\begin{figure*}[t]
    \setlength{\abovecaptionskip}{0.2cm} % height above Figure X caption
    \setlength{\belowcaptionskip}{-0.5cm}
    \setlength{\subfigcapskip}{-0.25cm}
    \centering
        \includegraphics[width=1.9\columnwidth]{Figs/overview.png}
        \vspace{-0.1cm}
    \caption{System architecture of mmE-Loc.}
    \label{overview}
    % \vspace{-0.2cm}
\end{figure*} 


We fully implement mmE-Loc using a COTS event camera and mmWave radar. 
Over 30+ hours of indoor and outdoor experiments under various drone flight conditions assess its localization accuracy and end-to-end latency performance against four SOTA methods.
mmE-Loc achieves an average localization accuracy of 0.083$m$ and latency of 5.15$ms$, surpassing baselines by >48\% and >62\%, respectively, and showing minimal sensitivity to drone type and environment.
We also deploy mmE-Loc at a real-world drone delivery airport (\fig \ref{relatedwork}a) for 10 hours, demonstrating its practicality for commercial-level drone landing requirements. 

In summary, this paper makes the following contributions.\\
\noindent $(1)$ We explore a fresh sensor configuration, event camera plus mmWave radar, that embraces and harmonizes ultra-high sampling frequencies and propose mmE-Loc, a ground localization system for drone landings that delivers $cm$ accuracy and $ms$ latency.\\
\noindent $(2)$ We present $CCT$, which leverages \textit{temporal consistency} and the drone's periodic micro-motions for precise drone detection; and $GAJO$, which employs \textit{spatial complementarity} with a novel factor graph to enhance drone localization.\\
\noindent $(3)$ We implement and extensively evaluate mmE-Loc by comparing it with four SOTA methods, showing its effectiveness. We also deploy mmE-Loc in a real-world drone delivery airport, demonstrating feasibility of mmE-Loc.
