% Please download the latest anthology.bib from
%
% http://aclweb.org/anthology/anthology.bib.gz

@inproceedings{lin-etal-2022-shot,
    title = "Few-shot Learning with Multilingual Generative Language Models",
    author = "Lin, Xi Victoria  and
      Mihaylov, Todor  and
      Artetxe, Mikel  and
      Wang, Tianlu  and
      Chen, Shuohui  and
      Simig, Daniel  and
      Ott, Myle  and
      Goyal, Naman  and
      Bhosale, Shruti  and
      Du, Jingfei  and
      Pasunuru, Ramakanth  and
      Shleifer, Sam  and
      Koura, Punit Singh  and
      Chaudhary, Vishrav  and
      O{'}Horo, Brian  and
      Wang, Jeff  and
      Zettlemoyer, Luke  and
      Kozareva, Zornitsa  and
      Diab, Mona  and
      Stoyanov, Veselin  and
      Li, Xian",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.616/",
    doi = "10.18653/v1/2022.emnlp-main.616",
    pages = "9019--9052",
    abstract = "Large-scale generative language models such as GPT-3 are competitive few-shot learners. While these models are known to be able to jointly represent many different languages, their training data is dominated by English, potentially limiting their cross-lingual generalization. In this work, we train multilingual generative language models on a corpus covering a diverse set of languages, and study their few- and zero-shot learning capabilities in a wide range of tasks. Our largest model with 7.5 billion parameters sets new state of the art in few-shot learning in more than 20 representative languages, outperforming GPT-3 of comparable size in multilingual commonsense reasoning (with +7.4{\%} absolute accuracy improvement in 0-shot settings and +9.4{\%} in 4-shot settings) and natural language inference (+5.4{\%} in each of 0-shot and 4-shot settings). On the FLORES-101 machine translation benchmark, our model outperforms GPT-3 on 171 out of 182 directions with 32 training examples, while surpassing the official supervised baseline in 45 directions. We conduct an in-depth analysis of different multilingual prompting approaches, showing in particular that strong few-shot learning performance across languages can be achieved via cross-lingual transfer through both templates and demonstration examples."
}


@article{chowdhery-etal-2023-PaLM,
  author  = {Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
  title   = {PaLM: Scaling Language Modeling with Pathways},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {240},
  pages   = {1--113},
  url     = {http://jmlr.org/papers/v24/22-1144.html}
}

@article{vasco-castellano,
author = {Ibarra Murillo, Orreaga},
year = {2014},
month = {10},
pages = {23-40},
title = {Tipología y pragmática del code-switching vasco-castellano en el habla informal de jóvenes bilingües},
journal = {Lapurdum},
doi = {10.4000/lapurdum.2485}
}

@article{interlingual-online,
  author    = {Sarkisov, E.},
  year      = {2021},
  title     = {Interlingual interference as a linguistic and cultural characteristic of the current online communication},
  journal   = {Russian Journal of Bilingualism Studies},
  volume    = {3},
  pages     = {16-21}
}

@article{joulin2016fasttext,
  title={FastText.zip: Compressing text classification models},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Douze, Matthijs and J{\'e}gou, H{\'e}rve and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1612.03651},
  year={2016}
}

@inproceedings{alvarez-mellado-lignos-2022-detecting,
    title = "Detecting Unassimilated Borrowings in {S}panish: {A}n Annotated Corpus and Approaches to Modeling",
    author = "{\'A}lvarez-Mellado, Elena  and
      Lignos, Constantine",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.268",
    doi = "10.18653/v1/2022.acl-long.268",
    pages = "3868--3888",
    abstract = "This work presents a new resource for borrowing identification and analyzes the performance and errors of several models on this task. We introduce a new annotated corpus of Spanish newswire rich in unassimilated lexical borrowings{---}words from one language that are introduced into another without orthographic adaptation{---}and use it to evaluate how several sequence labeling models (CRF, BiLSTM-CRF, and Transformer-based models) perform. The corpus contains 370,000 tokens and is larger, more borrowing-dense, OOV-rich, and topic-varied than previous corpora available for this task. Our results show that a BiLSTM-CRF model fed with subword embeddings along with either Transformer-based embeddings pretrained on codeswitched data or a combination of contextualized word embeddings outperforms results obtained by a multilingual BERT-based model.",
}

@inproceedings{aguilar-etal-2020-lince,
    title = "{L}in{CE}: A Centralized Benchmark for Linguistic Code-switching Evaluation",
    author = "Aguilar, Gustavo  and
      Kar, Sudipta  and
      Solorio, Thamar",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.223",
    pages = "1803--1813",
    abstract = "Recent trends in NLP research have raised an interest in linguistic code-switching (CS); modern approaches have been proposed to solve a wide range of NLP tasks on multiple language pairs. Unfortunately, these proposed methods are hardly generalizable to different code-switched languages. In addition, it is unclear whether a model architecture is applicable for a different task while still being compatible with the code-switching setting. This is mainly because of the lack of a centralized benchmark and the sparse corpora that researchers employ based on their specific needs and interests. To facilitate research in this direction, we propose a centralized benchmark for Linguistic Code-switching Evaluation (LinCE) that combines eleven corpora covering four different code-switched language pairs (i.e., Spanish-English, Nepali-English, Hindi-English, and Modern Standard Arabic-Egyptian Arabic) and four tasks (i.e., language identification, named entity recognition, part-of-speech tagging, and sentiment analysis). As part of the benchmark centralization effort, we provide an online platform where researchers can submit their results while comparing with others in real-time. In addition, we provide the scores of different popular models, including LSTM, ELMo, and multilingual BERT so that the NLP community can compare against state-of-the-art systems. LinCE is a continuous effort, and we will expand it with more low-resource languages and tasks.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@misc{Label-Studio,
  title={{Label Studio}: Data labeling software},
  url={https://github.com/heartexlabs/label-studio},
  note={Open source software available from https://github.com/heartexlabs/label-studio},
  author={
    Maxim Tkachenko and
    Mikhail Malyuk and
    Andrey Holmanyuk and
    Nikolai Liubimov},
  year={2020-2022},
}

@inproceedings{winata-etal-2023-decades,
    title = "The Decades Progress on Code-Switching Research in {NLP}: A Systematic Survey on Trends and Challenges",
    author = "Winata, Genta  and
      Aji, Alham Fikri  and
      Yong, Zheng Xin  and
      Solorio, Thamar",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.185",
    doi = "10.18653/v1/2023.findings-acl.185",
    pages = "2936--2978",
    abstract = "Code-Switching, a common phenomenon in written text and conversation, has been studied over decades by the natural language processing (NLP) research community. Initially, code-switching is intensively explored by leveraging linguistic theories and, currently, more machine-learning oriented approaches to develop models. We introduce a comprehensive systematic survey on code-switching research in natural language processing to understand the progress of the past decades and conceptualize the challenges and tasks on the code-switching topic. Finally, we summarize the trends and findings and conclude with a discussion for future direction and open questions for further investigation.",
}


@inproceedings{fernandez-de-landa-etal-2024-uncovering,
    title = "Uncovering Social Changes of the {B}asque Speaking {T}witter Community During {COVID}-19 Pandemic",
    author = "Fernandez de Landa, Joseba  and
      Garc{\'\i}a-Ferrero, Iker  and
      Salaberria, Ander  and
      Campos, Jon Ander",
    editor = "Melero, Maite  and
      Sakti, Sakriani  and
      Soria, Claudia",
    booktitle = "Proceedings of the 3rd Annual Meeting of the Special Interest Group on Under-resourced Languages @ LREC-COLING 2024",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.sigul-1.44",
    pages = "363--371",
    abstract = "The aim of this work is to study the impact of the COVID-19 pandemic on the Basque speaking Twitter community by applying Natural Language Processing unsupervised techniques. In order to carry out this study, we collected and publicly released the biggest dataset of Basque tweets containing up to 8M tweets from September 2019 to February 2021. To analyze the impact of the pandemic, the variability of the content over time was studied through quantitative and qualitative analysis of words and emojis. For the quantitative analysis, the shift at the frequency of the terms was calculated using linear regression over frequencies. On the other hand, for the qualitative analysis, word embeddings were used to study the changes in the meaning of the most significant words and emojis at different periods of the pandemic. Through this multifaceted approach, we discovered noteworthy alterations in the political inclinations exhibited by Basque users throughout the course of the pandemic.",
}

@inproceedings{khanuja-etal-2020-gluecos,
    title = "{GLUEC}o{S}: An Evaluation Benchmark for Code-Switched {NLP}",
    author = "Khanuja, Simran  and
      Dandapat, Sandipan  and
      Srinivasan, Anirudh  and
      Sitaram, Sunayana  and
      Choudhury, Monojit",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.329",
    doi = "10.18653/v1/2020.acl-main.329",
    pages = "3575--3585",
    abstract = "Code-switching is the use of more than one language in the same conversation or utterance. Recently, multilingual contextual embedding models, trained on multiple monolingual corpora, have shown promising results on cross-lingual and multilingual tasks. We present an evaluation benchmark, GLUECoS, for code-switched languages, that spans several NLP tasks in English-Hindi and English-Spanish. Specifically, our evaluation benchmark includes Language Identification from text, POS tagging, Named Entity Recognition, Sentiment Analysis, Question Answering and a new task for code-switching, Natural Language Inference. We present results on all these tasks using cross-lingual word embedding models and multilingual models. In addition, we fine-tune multilingual models on artificially generated code-switched data. Although multilingual models perform significantly better than cross-lingual models, our results show that in most tasks, across both language pairs, multilingual models fine-tuned on code-switched data perform best, showing that multilingual models can be further optimized for code-switching tasks.",
}

@inproceedings{guzman17_interspeech,
  author={Gualberto Guzmán and Joseph Ricard and Jacqueline Serigos and Barbara E. Bullock and Almeida Jacqueline Toribio},
  title={{Metrics for Modeling Code-Switching Across Corpora}},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={67--71},
  doi={10.21437/Interspeech.2017-1429},
  issn={2958-1796}
}

@article{10.1145/3392846,
author = {Bawa, Anshul and Khadpe, Pranav and Joshi, Pratik and Bali, Kalika and Choudhury, Monojit},
title = {Do Multilingual Users Prefer Chat-bots that Code-mix? Let's Nudge and Find Out!},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {CSCW1},
url = {https://doi.org/10.1145/3392846},
doi = {10.1145/3392846},
abstract = {Despite their pervasiveness, current text-based conversational agents (chatbots) are predominantly monolingual, while users are often multilingual. It is well-known that multilingual users mix languages while interacting with others, as well as in their interactions with computer systems (such as query formulation in text-/voice-based search interfaces and digital assistants). Linguists refer to this phenomenon as code-mixing or code-switching. Do multilingual users also prefer chatbots that can respond in a code-mixed language over those which cannot? In order to inform the design of chatbots for multilingual users, we conduct a mixed-method user-study (N=91) where we examine how conversational agents, that code-mix and reciprocate the users' mixing choices over multiple conversation turns, are evaluated and perceived by bilingual users. We design a human-in-the-loop chatbot with two different code-mixing policies -- (a) always code-mix irrespective of user behavior, and (b) nudge with subtle code-mixed cues and reciprocate only if the user, in turn, code-mixes. These two are contrasted with a monolingual chatbot that never code-mixed. Users are asked to interact with the bots, and provide ratings on perceived naturalness and personal preference. They are also asked open-ended questions around what they (dis)liked about the bots. Analysis of the chat logs, users' ratings, and qualitative responses reveal that multilingual users strongly prefer chatbots that can code-mix. We find that self-reported language proficiency is the strongest predictor of user preferences. Compared to the Always code-mix policy, Nudging emerges as a low-risk low-gain policy which is equally acceptable to all users. Nudging as a policy is further supported by the observation that users who rate the code-mixing bot higher typically tend to reciprocate the language mixing pattern of the bot. These findings present a first step towards developing conversational systems that are more human-like and engaging by virtue of adapting to the users' linguistic style.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {may},
articleno = {41},
numpages = {23},
keywords = {multilingual interfaces, intelligent personal assistants, human-centered ai, human-agent interaction, code-mixing}
}

@inproceedings{ormazabal-etal-2022-poelm,
    title = "{P}oe{LM}: A Meter- and Rhyme-Controllable Language Model for Unsupervised Poetry Generation",
    author = "Ormazabal, Aitor  and
      Artetxe, Mikel  and
      Agirrezabal, Manex  and
      Soroa, Aitor  and
      Agirre, Eneko",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.268",
    doi = "10.18653/v1/2022.findings-emnlp.268",
    pages = "3655--3670",
    abstract = "Formal verse poetry imposes strict constraints on the meter and rhyme scheme of poems. Most prior work on generating this type of poetry uses existing poems for supervision, which are difficult to obtain for most languages and poetic forms. In this work, we propose an unsupervised approach to generate poems that follow any given meter and rhyme scheme, without requiring any poetic text for training. Our method works by splitting a regular, non-poetic corpus into phrases, prepending control codes that describe the length and end rhyme of each phrase, and training a transformer language model in the augmented corpus. The transformer learns to link the structure descriptor with the control codes to the number of lines, their length and their end rhyme. During inference, we build control codes for the desired meter and rhyme scheme, and condition our language model on them to generate formal verse poetry. Experiments in Spanish and Basque show that our approach is able to generate valid poems, which are often comparable in quality to those written by humans.",
}


@inproceedings{zhu-etal-2024-multilingual,
    title = "Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis",
    author = "Zhu, Wenhao  and
      Liu, Hongyi  and
      Dong, Qingxiu  and
      Xu, Jingjing  and
      Huang, Shujian  and
      Kong, Lingpeng  and
      Chen, Jiajun  and
      Li, Lei",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-naacl.176",
    doi = "10.18653/v1/2024.findings-naacl.176",
    pages = "2765--2781",
    abstract = "Large language models (LLMs) have demonstrated remarkable potential in handling multilingual machine translation (MMT). In this paper, we systematically investigate the advantages and challenges of LLMs for MMT by answering two questions: 1) How well do LLMs perform in translating massive languages? 2) Which factors affect LLMs{'} performance in translation? We thoroughly evaluate eight popular LLMs, including ChatGPT and GPT-4. Our empirical results show that translation capabilities of LLMs are continually involving. GPT-4 has beat the strong supervised baseline NLLB in 40.91{\%} of translation directions but still faces a large gap towards the commercial translation system like Google Translate, especially on low-resource languages. Through further analysis, we discover that LLMs exhibit new working patterns when used for MMT. First, LLM can acquire translation ability in a resource-efficient way and generate moderate translation even on zero-resource languages. Second, instruction semantics can surprisingly be ignored when given in-context exemplars. Third, cross-lingual exemplars can provide better task guidance for low-resource translation than exemplars in the same language pairs. Code will be released at: https://github.com/NJUNLP/MMT-LLM.",
}
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@inproceedings{gregorius-okadome-2022-generating-dependency,
    title = "Generating Code-Switched Text from Monolingual Text with Dependency Tree",
    author = "Gregorius, Bryan  and
      Okadome, Takeshi",
    editor = "Parameswaran, Pradeesh  and
      Biggs, Jennifer  and
      Powers, David",
    booktitle = "Proceedings of the 20th Annual Workshop of the Australasian Language Technology Association",
    month = dec,
    year = "2022",
    address = "Adelaide, Australia",
    publisher = "Australasian Language Technology Association",
    url = "https://aclanthology.org/2022.alta-1.12",
    pages = "90--97",
}

@inproceedings{gupta-etal-2020-semi,
    title = "A Semi-supervised Approach to Generate the Code-Mixed Text using Pre-trained Encoder and Transfer Learning",
    author = "Gupta, Deepak  and
      Ekbal, Asif  and
      Bhattacharyya, Pushpak",
    editor = "Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.206",
    doi = "10.18653/v1/2020.findings-emnlp.206",
    pages = "2267--2280",
    abstract = "Code-mixing, the interleaving of two or more languages within a sentence or discourse is ubiquitous in multilingual societies. The lack of code-mixed training data is one of the major concerns for the development of end-to-end neural network-based models to be deployed for a variety of natural language processing (NLP) applications. A potential solution is to either manually create or crowd-source the code-mixed labelled data for the task at hand, but that requires much human efforts and often not feasible because of the language specific diversity in the code-mixed text. To circumvent the data scarcity issue, we propose an effective deep learning approach for automatically generating the code-mixed text from English to multiple languages without any parallel data. In order to train the neural network, we create synthetic code-mixed texts from the available parallel corpus by modelling various linguistic properties of code-mixing. Our codemixed text generator is built upon the encoder-decoder framework, where the encoder is augmented with the linguistic and task-agnostic features obtained from the transformer based language model. We also transfer the knowledge from a neural machine translation (NMT) to warm-start the training of code-mixed generator. Experimental results and in-depth analysis show the effectiveness of our proposed code-mixed text generation on eight diverse language pairs.",
}

@inproceedings{popovic-2015-chrf,
    title = "chr{F}: character n-gram {F}-score for automatic {MT} evaluation",
    author = "Popovi{\'c}, Maja",
    editor = "Bojar, Ond{\v{r}}ej  and
      Chatterjee, Rajan  and
      Federmann, Christian  and
      Haddow, Barry  and
      Hokamp, Chris  and
      Huck, Matthias  and
      Logacheva, Varvara  and
      Pecina, Pavel",
    booktitle = "Proceedings of the Tenth Workshop on Statistical Machine Translation",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W15-3049",
    doi = "10.18653/v1/W15-3049",
    pages = "392--395",
}

@inproceedings{papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    editor = "Isabelle, Pierre  and
      Charniak, Eugene  and
      Lin, Dekang",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}

@misc{zhang2020bertscoreevaluatingtextgeneration,
      title={BERTScore: Evaluating Text Generation with BERT}, 
      author={Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
      year={2020},
      eprint={1904.09675},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1904.09675}, 
}

@misc {cohere_for_ai_2024,
	author       = { {Cohere For AI} },
	title        = { c4ai-command-r-v01 (Revision 8089a08) },
	year         = 2024,
	url          = { https://huggingface.co/CohereForAI/c4ai-command-r-v01 },
	doi          = { 10.57967/hf/3139 },
	publisher    = { Hugging Face }
}

@misc{jiang2023mistral7b,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.06825}, 
}

@Inbook{Popović2018errorclassification,
author="Popovi{\'{c}}, Maja",
title="Error Classification and Analysis for Machine Translation Quality Assessment",
bookTitle="Translation Quality Assessment: From Principles to Practice",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="129--158",
abstract="This chapter presents an overview of different approaches and tasks related to classification and analysis of errors in machine translation (MT) output. Manual error classification is a resource- and time-intensive task which suffers from low inter-evaluator agreement, especially if a large number of error classes have to be distinguished. Automatic error analysis can overcome these deficiencies, but state-of-the-art tools are still not able to distinguish detailed error classes, and are prone to confusion between mistranslations, omissions, and additions. Despite these disadvantages, automatic tools can efficiently replace human evaluators both for estimating the distribution of error classes in a given translation output, as well as for comparing different translation outputs. They can also facilitate manual error classification by pre-annotation, since correcting or expanding existing error tags requires less time and effort than assigning error tags from scratch. Classification of post-editing operations is more convenient both for manual and for automatic processing, and also enables more reliable assessment of automatic tools. Apart from assigning error tags to incorrectly translated (groups of) words, error analysis can be performed by examining unmatched sequences of words, part-of-speech (POS) tags or other units, as well as by identifying language-related and linguistically-motivated issues. These linguistic categories can be then used to perform automatic evaluation specifically on these units, or to analyse their frequency and nature. Due to its complexity and variety, error analysis is an active field of research with many possible directions for development and innovation.",
isbn="978-3-319-91241-7",
doi="10.1007/978-3-319-91241-7_7",
url="https://doi.org/10.1007/978-3-319-91241-7_7"
}

@inproceedings{dogruoz-etal-2021-survey,
    title = "A Survey of Code-switching: Linguistic and Social Perspectives for Language Technologies",
    author = {Do{\u{g}}ru{\"o}z, A. Seza  and
      Sitaram, Sunayana  and
      Bullock, Barbara E.  and
      Toribio, Almeida Jacqueline},
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.131",
    doi = "10.18653/v1/2021.acl-long.131",
    pages = "1654--1666",
    abstract = "The analysis of data in which multiple languages are represented has gained popularity among computational linguists in recent years. So far, much of this research focuses mainly on the improvement of computational methods and largely ignores linguistic and social aspects of C-S discussed across a wide range of languages within the long-established literature in linguistics. To fill this gap, we offer a survey of code-switching (C-S) covering the literature in linguistics with a reflection on the key issues in language technologies. From the linguistic perspective, we provide an overview of structural and functional patterns of C-S focusing on the literature from European and Indian contexts as highly multilingual areas. From the language technologies perspective, we discuss how massive language models fail to represent diverse C-S types due to lack of appropriate training data, lack of robust evaluation benchmarks for C-S (across multilingual situations and types of C-S) and lack of end-to- end systems that cover sociolinguistic aspects of C-S as well. Our survey will be a step to- wards an outcome of mutual benefit for computational scientists and linguists with a shared interest in multilingualism and C-S.",
}

@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@inproceedings{bawden-yvon-2023-investigating-translation-bloom,
    title = "Investigating the Translation Performance of a Large Multilingual Language Model: the Case of {BLOOM}",
    author = "Bawden, Rachel  and
      Yvon, Fran{\c{c}}ois",
    editor = "Nurminen, Mary  and
      Brenner, Judith  and
      Koponen, Maarit  and
      Latomaa, Sirkku  and
      Mikhailov, Mikhail  and
      Schierl, Frederike  and
      Ranasinghe, Tharindu  and
      Vanmassenhove, Eva  and
      Vidal, Sergi Alvarez  and
      Aranberri, Nora  and
      Nunziatini, Mara  and
      Escart{\'\i}n, Carla Parra  and
      Forcada, Mikel  and
      Popovic, Maja  and
      Scarton, Carolina  and
      Moniz, Helena",
    booktitle = "Proceedings of the 24th Annual Conference of the European Association for Machine Translation",
    month = jun,
    year = "2023",
    address = "Tampere, Finland",
    publisher = "European Association for Machine Translation",
    url = "https://aclanthology.org/2023.eamt-1.16",
    pages = "157--170",
    abstract = "The NLP community recently saw the release of a new large open-access multilingual language model, BLOOM (BigScience et al., 2022) covering 46 languages. We focus on BLOOM{'}s multilingual ability by evaluating its machine translation performance across several datasets (WMT, Flores-101 and DiaBLa) and language pairs (high- and low-resourced). Our results show that 0-shot performance suffers from overgeneration and generating in the wrong language, but this is greatly improved in the few-shot setting, with very good results for a number of language pairs. We study several aspects including prompt design, model sizes, cross-lingual transfer and the use of discursive context.",
}

@misc{dettmers2023qloraefficientfinetuningquantized,
      title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.14314}, 
}


@inproceedings{koehn-etal-2007-moses,
    title = "{M}oses: Open Source Toolkit for Statistical Machine Translation",
    author = "Koehn, Philipp  and
      Hoang, Hieu  and
      Birch, Alexandra  and
      Callison-Burch, Chris  and
      Federico, Marcello  and
      Bertoldi, Nicola  and
      Cowan, Brooke  and
      Shen, Wade  and
      Moran, Christine  and
      Zens, Richard  and
      Dyer, Chris  and
      Bojar, Ond{\v{r}}ej  and
      Constantin, Alexandra  and
      Herbst, Evan",
    editor = "Ananiadou, Sophia",
    booktitle = "Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P07-2045",
    pages = "177--180",
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@article{global-bilingualism-tucker,
author = {Tucker, G Richard},
year = {2001},
month = {01},
pages = {},
title = {A Global Perspective on Bilingualism and Bilingual Education},
journal = {Georgetown University Round table on Languages and Linguistics 1999}
}

@book{language-contact-appel-muysken, 
title={Language Contact and Bilingualism}, 
publisher={Amsterdam University Press}, 
author={Appel, Rene and Muysken, Pieter C.}, 
year={2005}}

@article{dewaele-attitudes,
author = {Jean-Marc Dewaele and Li Wei},
title = {Attitudes towards code-switching among adult mono- and multilingual language users},
journal = {Journal of Multilingual and Multicultural Development},
volume = {35},
number = {3},
pages = {235--251},
year = {2014},
publisher = {Routledge},
doi = {10.1080/01434632.2013.859687},
URL = {  
        https://doi.org/10.1080/01434632.2013.859687
},
eprint = { 
        https://doi.org/10.1080/01434632.2013.859687
}}

@article{survey-nlg-metrics,
author = {Sai, Ananya B. and Mohankumar, Akash Kumar and Khapra, Mitesh M.},
title = {A Survey of Evaluation Metrics Used for NLG Systems},
year = {2022},
issue_date = {February 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3485766},
doi = {10.1145/3485766},
abstract = {In the last few years, a large number of automatic evaluation metrics have been proposed for evaluating Natural Language Generation (NLG) systems. The rapid development and adoption of such automatic evaluation metrics in a relatively short time has created the need for a survey of these metrics. In this survey, we (i) highlight the challenges in automatically evaluating NLG systems, (ii) propose a coherent taxonomy for organising existing evaluation metrics, (iii) briefly describe different existing metrics, and finally (iv) discuss studies criticising the use of automatic evaluation metrics. We then conclude the article highlighting promising future directions of research.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {26},
numpages = {39},
keywords = {Automatic evaluation metrics, abstractive summarization, image captioning, question answering, question generation, data-to-text generation, correlations}
}

@inproceedings{nimah-etal-2023-nlg-metrics-correlation,
    title = "{NLG} Evaluation Metrics Beyond Correlation Analysis: An Empirical Metric Preference Checklist",
    author = "Nimah, Iftitahu  and
      Fang, Meng  and
      Menkovski, Vlado  and
      Pechenizkiy, Mykola",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.69/",
    doi = "10.18653/v1/2023.acl-long.69",
    pages = "1240--1266",
    abstract = "In this study, we analyze automatic evaluation metrics for Natural Language Generation (NLG), specifically task-agnostic metrics and human-aligned metrics. Task-agnostic metrics, such as Perplexity, BLEU, BERTScore, are cost-effective and highly adaptable to diverse NLG tasks, yet they have a weak correlation with human. Human-aligned metrics (CTC, CtrlEval, UniEval) improves correlation level by incorporating desirable human-like qualities as training objective. However, their effectiveness at discerning system-level performance and quality of system outputs remain unclear. We present metric preference checklist as a framework to assess the effectiveness of automatic metrics in three NLG tasks: Text Summarization, Dialogue Response Generation, and Controlled Generation. Our proposed framework provides access: (i) for verifying whether automatic metrics are faithful to human preference, regardless of their correlation level to human; and (ii) for inspecting the strengths and limitations of NLG systems via pairwise evaluation. We show that automatic metrics provide a better guidance than human on discriminating system-level performance in Text Summarization and Controlled Generation tasks. We also show that multi-aspect human-aligned metric (UniEval) is not necessarily dominant over single-aspect human-aligned metrics (CTC, CtrlEval) and task-agnostic metrics (BLEU, BERTScore), particularly in Controlled Generation tasks."
}

@inproceedings{winata-etal-2021-multilingual,
    title = "Are Multilingual Models Effective in Code-Switching?",
    author = "Winata, Genta Indra  and
      Cahyawijaya, Samuel  and
      Liu, Zihan  and
      Lin, Zhaojiang  and
      Madotto, Andrea  and
      Fung, Pascale",
    editor = "Solorio, Thamar  and
      Chen, Shuguang  and
      Black, Alan W.  and
      Diab, Mona  and
      Sitaram, Sunayana  and
      Soto, Victor  and
      Yilmaz, Emre  and
      Srinivasan, Anirudh",
    booktitle = "Proceedings of the Fifth Workshop on Computational Approaches to Linguistic Code-Switching",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.calcs-1.20/",
    doi = "10.18653/v1/2021.calcs-1.20",
    pages = "142--153",
    abstract = "Multilingual language models have shown decent performance in multilingual and cross-lingual natural language understanding tasks. However, the power of these multilingual models in code-switching tasks has not been fully explored. In this paper, we study the effectiveness of multilingual language models to understand their capability and adaptability to the mixed-language setting by considering the inference speed, performance, and number of parameters to measure their practicality. We conduct experiments in three language pairs on named entity recognition and part-of-speech tagging and compare them with existing methods, such as using bilingual embeddings and multilingual meta-embeddings. Our findings suggest that pre-trained multilingual models do not necessarily guarantee high-quality representations on code-switching, while using meta-embeddings achieves similar results with significantly fewer parameters."
}
@article{poplack-sometimes,
author = {Poplack, Shana},
year = {1980},
month = {01},
pages = {581-618},
title = {Sometimes I’ll start a sentence in Spanish Y TERMINO EN ESPAÑOL: toward a typology of code-switching 1},
volume = {18},
journal = {Linguistics},
doi = {10.1515/ling.1980.18.7-8.581}
}

@inproceedings{pratapa-etal-2018-language-modeling-synthetic,
    title = "Language Modeling for Code-Mixing: The Role of Linguistic Theory based Synthetic Data",
    author = "Pratapa, Adithya  and
      Bhat, Gayatri  and
      Choudhury, Monojit  and
      Sitaram, Sunayana  and
      Dandapat, Sandipan  and
      Bali, Kalika",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1143/",
    doi = "10.18653/v1/P18-1143",
    pages = "1543--1553",
    abstract = "Training language models for Code-mixed (CM) language is known to be a difficult problem because of lack of data compounded by the increased confusability due to the presence of more than one language. We present a computational technique for creation of grammatically valid artificial CM data based on the Equivalence Constraint Theory. We show that when training examples are sampled appropriately from this synthetic data and presented in certain order (aka training curriculum) along with monolingual and real CM data, it can significantly reduce the perplexity of an RNN-based language model. We also show that randomly generated CM data does not help in decreasing the perplexity of the LMs."
}

@inproceedings{tarunesh-etal-2021-machine-translation,
    title = "From Machine Translation to Code-Switching: Generating High-Quality Code-Switched Text",
    author = "Tarunesh, Ishan  and
      Kumar, Syamantak  and
      Jyothi, Preethi",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.245/",
    doi = "10.18653/v1/2021.acl-long.245",
    pages = "3154--3169",
    abstract = "Generating code-switched text is a problem of growing interest, especially given the scarcity of corpora containing large volumes of real code-switched text. In this work, we adapt a state-of-the-art neural machine translation model to generate Hindi-English code-switched sentences starting from monolingual Hindi sentences. We outline a carefully designed curriculum of pretraining steps, including the use of synthetic code-switched text, that enable the model to generate high-quality code-switched text. Using text generated from our model as data augmentation, we show significant reductions in perplexity on a language modeling task, compared to using text from other generative models of CS text. We also show improvements using our text for a downstream code-switched natural language inference task. Our generated text is further subjected to a rigorous evaluation using a human evaluation study and a range of objective metrics, where we show performance comparable (and sometimes even superior) to code-switched text obtained via crowd workers who are native Hindi speakers."
}


@inproceedings{solorio-etal-2014-first-shared-task,
    title = "Overview for the First Shared Task on Language Identification in Code-Switched Data",
    author = "Solorio, Thamar  and
      Blair, Elizabeth  and
      Maharjan, Suraj  and
      Bethard, Steven  and
      Diab, Mona  and
      Ghoneim, Mahmoud  and
      Hawwari, Abdelati  and
      AlGhamdi, Fahad  and
      Hirschberg, Julia  and
      Chang, Alison  and
      Fung, Pascale",
    editor = "Diab, Mona  and
      Hirschberg, Julia  and
      Fung, Pascale  and
      Solorio, Thamar",
    booktitle = "Proceedings of the First Workshop on Computational Approaches to Code Switching",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W14-3907/",
    doi = "10.3115/v1/W14-3907",
    pages = "62--72"
}

@inproceedings{molina-etal-2016-overview-second-shared-task,
    title = "Overview for the Second Shared Task on Language Identification in Code-Switched Data",
    author = "Molina, Giovanni  and
      AlGhamdi, Fahad  and
      Ghoneim, Mahmoud  and
      Hawwari, Abdelati  and
      Rey-Villamizar, Nicolas  and
      Diab, Mona  and
      Solorio, Thamar",
    editor = "Diab, Mona  and
      Fung, Pascale  and
      Ghoneim, Mahmoud  and
      Hirschberg, Julia  and
      Solorio, Thamar",
    booktitle = "Proceedings of the Second Workshop on Computational Approaches to Code Switching",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W16-5805/",
    doi = "10.18653/v1/W16-5805",
    pages = "40--49"
}

@inproceedings{patwa-etal-2020-semeval,
    title = "{S}em{E}val-2020 Task 9: Overview of Sentiment Analysis of Code-Mixed Tweets",
    author = {Patwa, Parth  and
      Aguilar, Gustavo  and
      Kar, Sudipta  and
      Pandey, Suraj  and
      PYKL, Srinivas  and
      Gamb{\"a}ck, Bj{\"o}rn  and
      Chakraborty, Tanmoy  and
      Solorio, Thamar  and
      Das, Amitava},
    editor = "Herbelot, Aurelie  and
      Zhu, Xiaodan  and
      Palmer, Alexis  and
      Schneider, Nathan  and
      May, Jonathan  and
      Shutova, Ekaterina",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    url = "https://aclanthology.org/2020.semeval-1.100/",
    doi = "10.18653/v1/2020.semeval-1.100",
    pages = "774--790",
    abstract = "In this paper, we present the results of the SemEval-2020 Task 9 on Sentiment Analysis of Code-Mixed Tweets (SentiMix 2020). We also release and describe our Hinglish (Hindi-English)and Spanglish (Spanish-English) corpora annotated with word-level language identification and sentence-level sentiment labels. These corpora are comprised of 20K and 19K examples, respectively. The sentiment labels are - Positive, Negative, and Neutral. SentiMix attracted 89 submissions in total including 61 teams that participated in the Hinglish contest and 28 submitted systems to the Spanglish competition. The best performance achieved was 75.0{\%} F1 score for Hinglish and 80.6{\%} F1 for Spanglish. We observe that BERT-like models and ensemble methods are the most common and successful approaches among the participants."
}

@inproceedings{bali-etal-2014-borrowing-social-media,
    title = "{\textquotedblleft}{I} am borrowing ya mixing ?'' An Analysis of {E}nglish-{H}indi Code Mixing in {F}acebook",
    author = "Bali, Kalika  and
      Sharma, Jatin  and
      Choudhury, Monojit  and
      Vyas, Yogarshi",
    editor = "Diab, Mona  and
      Hirschberg, Julia  and
      Fung, Pascale  and
      Solorio, Thamar",
    booktitle = "Proceedings of the First Workshop on Computational Approaches to Code Switching",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W14-3914/",
    doi = "10.3115/v1/W14-3914",
    pages = "116--126"
}

@inproceedings{yong-etal-2023-prompting,
    title = "Prompting Multilingual Large Language Models to Generate Code-Mixed Texts: The Case of South {E}ast {A}sian Languages",
    author = "Yong, Zheng Xin  and
      Zhang, Ruochen  and
      Forde, Jessica  and
      Wang, Skyler  and
      Subramonian, Arjun  and
      Lovenia, Holy  and
      Cahyawijaya, Samuel  and
      Winata, Genta  and
      Sutawika, Lintang  and
      Cruz, Jan Christian Blaise  and
      Tan, Yin Lin  and
      Phan, Long  and
      Phan, Long  and
      Garcia, Rowena  and
      Solorio, Thamar  and
      Aji, Alham Fikri",
    editor = "Winata, Genta  and
      Kar, Sudipta  and
      Zhukova, Marina  and
      Solorio, Thamar  and
      Diab, Mona  and
      Sitaram, Sunayana  and
      Choudhury, Monojit  and
      Bali, Kalika",
    booktitle = "Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.calcs-1.5/",
    pages = "43--63",
    abstract = "While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research. The recent proliferation of Large Language Models (LLMs) compels one to ask: how capable are these systems in generating code-mixed data? In this paper, we explore prompting multilingual LLMs in a zero-shot manner to generate code-mixed data for seven languages in South East Asia (SEA), namely Indonesian, Malay, Chinese, Tagalog, Vietnamese, Tamil, and Singlish. We find that publicly available multilingual instruction-tuned models such as BLOOMZ and Flan-T5-XXL are incapable of producing texts with phrases or clauses from different languages. ChatGPT exhibits inconsistent capabilities in generating code-mixed texts, wherein its per-formance varies depending on the prompt template and language pairing. For instance, ChatGPT generates fluent and natural Singlish texts (an English-based creole spoken in Singapore), but for English-Tamil language pair, the system mostly produces grammatically incorrect or semantically meaningless utterances. Furthermore, it may erroneously introduce languages not specified in the prompt. Based on our investigation, existing multilingual LLMs exhibit a wide range of proficiency in code-mixed data generation for SEA languages. As such, we advise against using LLMs in this context without extensive human checks."
}

@misc{kuwanto2024linguisticstheorymeetsllm,
      title={Linguistics Theory Meets LLM: Code-Switched Text Generation via Equivalence Constrained Large Language Models}, 
      author={Garry Kuwanto and Chaitanya Agarwal and Genta Indra Winata and Derry Tanti Wijaya},
      year={2024},
      eprint={2410.22660},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.22660}, 
}

@inproceedings{xu-yvon-2021-traducir,
    title = "Can You Traducir This? Machine Translation for Code-Switched Input",
    author = "Xu, Jitao  and
      Yvon, Fran{\c{c}}ois",
    editor = "Solorio, Thamar  and
      Chen, Shuguang  and
      Black, Alan W.  and
      Diab, Mona  and
      Sitaram, Sunayana  and
      Soto, Victor  and
      Yilmaz, Emre  and
      Srinivasan, Anirudh",
    booktitle = "Proceedings of the Fifth Workshop on Computational Approaches to Linguistic Code-Switching",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.calcs-1.11/",
    doi = "10.18653/v1/2021.calcs-1.11",
    pages = "84--94",
    abstract = "Code-Switching (CSW) is a common phenomenon that occurs in multilingual geographic or social contexts, which raises challenging problems for natural language processing tools. We focus here on Machine Translation (MT) of CSW texts, where we aim to simultaneously disentangle and translate the two mixed languages. Due to the lack of actual translated CSW data, we generate artificial training data from regular parallel texts. Experiments show this training strategy yields MT systems that surpass multilingual systems for code-switched texts. These results are confirmed in an alternative task aimed at providing contextual translations for a L2 writing assistant."
}

@inproceedings{parikh-solorio-2021-normalization,
    title = "Normalization and Back-Transliteration for Code-Switched Data",
    author = "Parikh, Dwija  and
      Solorio, Thamar",
    editor = "Solorio, Thamar  and
      Chen, Shuguang  and
      Black, Alan W.  and
      Diab, Mona  and
      Sitaram, Sunayana  and
      Soto, Victor  and
      Yilmaz, Emre  and
      Srinivasan, Anirudh",
    booktitle = "Proceedings of the Fifth Workshop on Computational Approaches to Linguistic Code-Switching",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.calcs-1.15/",
    doi = "10.18653/v1/2021.calcs-1.15",
    pages = "119--124",
    abstract = "Code-switching is an omnipresent phenomenon in multilingual communities all around the world but remains a challenge for NLP systems due to the lack of proper data and processing techniques. Hindi-English code-switched text on social media is often transliterated to the Roman script which prevents from utilizing monolingual resources available in the native Devanagari script. In this paper, we propose a method to normalize and back-transliterate code-switched Hindi-English text. In addition, we present a grapheme-to-phoneme (G2P) conversion technique for romanized Hindi data. We also release a dataset of script-corrected Hindi-English code-switched sentences labeled for the named entity recognition and part-of-speech tagging tasks to facilitate further research."
}

@inproceedings{krishna-2017-synthesis,
  title={On Building Mixed Lingual Speech Synthesis Systems},
  author={Sai Krishna Rallabandi and Alan W. Black},
  booktitle={Interspeech},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:2564341}
}


@inproceedings{gonen-goldberg-2019-language-modeling,
    title = "Language Modeling for Code-Switching: Evaluation, Integration of Monolingual Data, and Discriminative Training",
    author = "Gonen, Hila  and
      Goldberg, Yoav",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1427/",
    doi = "10.18653/v1/D19-1427",
    pages = "4175--4185",
    abstract = "We focus on the problem of language modeling for code-switched language, in the context of automatic speech recognition (ASR). Language modeling for code-switched language is challenging for (at least) three reasons: (1) lack of available large-scale code-switched data for training; (2) lack of a replicable evaluation setup that is ASR directed yet isolates language modeling performance from the other intricacies of the ASR system; and (3) the reliance on generative modeling. We tackle these three issues: we propose an ASR-motivated evaluation setup which is decoupled from an ASR system and the choice of vocabulary, and provide an evaluation dataset for English-Spanish code-switching. This setup lends itself to a discriminative training approach, which we demonstrate to work better than generative language modeling. Finally, we explore a variety of training protocols and verify the effectiveness of training with large amounts of monolingual data followed by fine-tuning with small amounts of code-switched data, for both the generative and discriminative cases."
}

@inproceedings{huzaifah-etal-2024-evaluating-MT-CS-LLMs,
    title = "Evaluating Code-Switching Translation with Large Language Models",
    author = "Huzaifah, Muhammad  and
      Zheng, Weihua  and
      Chanpaisit, Nattapol  and
      Wu, Kui",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.565/",
    pages = "6381--6394",
    abstract = "Recent advances in large language models (LLMs) have shown they can match or surpass finetuned models on many natural language processing tasks. Currently, more studies are being carried out to assess whether this performance carries over across different languages. In this paper, we present a thorough evaluation of LLMs for the less well-researched code-switching translation setting, where inputs include a mixture of different languages. We benchmark the performance of six state-of-the-art LLMs across seven datasets, with GPT-4 and GPT-3.5 displaying strong ability relative to supervised translation models and commercial engines. GPT-4 was also found to be particularly robust against different code-switching conditions. Several methods to further improve code-switching translation are proposed including leveraging in-context learning and pivot translation. Through our code-switching experiments, we argue that LLMs show promising ability for cross-lingual understanding."
}

@article{2025-heredia-actitudes,
   author = "Heredia, Maite and Fernández Trinidad, Marianela and Jiménez-Bravo, Miguel",
   title = "Actitudes lingüísticas hacia el cambio de código entre valenciano y castellano",
   journal = "Revista Española de Lingüística Aplicada/Spanish Journal of Applied Linguistics",
   issn = "0213-2028",
   year = "2025",
   publisher = "John Benjamins",
   url = "https://www.jbe-platform.com/content/journals/10.1075/resla.22066.her",
   doi = "https://doi.org/10.1075/resla.22066.her",
   keywords = "actitudes lingüísticas",
   keywords = "Valencian",
   keywords = "bilingüismo",
   keywords = "bilingualism",
   keywords = "valenciano",
   keywords = "language attitudes",
   keywords = "code-switching",
   keywords = "cambio de código",
   keywords = "pares ocultos",
   keywords = "matched-guise",
   abstract = "Este estudio constituye un primer acercamiento a las actitudes lingüísticas hacia el cambio de código que se da en una comunidad bilingüe valenciano-castellano. Los fragmentos de audio utilizados como estímulos contenían muestras de habla espontánea obtenidas del programa televisivo À Punt e incluían casos de cambio de código inter- e intraoracional. Los estímulos fueron administrados a un total de 10 jueces mediante la técnica de pares ocultos para que valorasen mediante una encuesta la competencia lingüística de los hablantes. Los resultados mostraron juicios significativamente más negativos hacia los estímulos donde el hablante empleaba el cambio de código. Además, en un análisis más detallado, se observó que, en cada una de las cuatro preguntas realizadas, otras variables como la identidad lingüística de los jueces, su género y su nivel de estudios tuvieron un efecto en las valoraciones de estos hacia el cambio de código realizado por los hablantes."
}

@inproceedings{junczys-dowmunt-etal-2018-marian,
    title = "{M}arian: Fast Neural Machine Translation in {C}++",
    author = "Junczys-Dowmunt, Marcin  and
      Grundkiewicz, Roman  and
      Dwojak, Tomasz  and
      Hoang, Hieu  and
      Heafield, Kenneth  and
      Neckermann, Tom  and
      Seide, Frank  and
      Germann, Ulrich  and
      Aji, Alham Fikri  and
      Bogoychev, Nikolay  and
      Martins, André F. T.  and
      Birch, Alexandra",
    booktitle = "Proceedings of {ACL} 2018, System Demonstrations",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-4020",
    doi = "10.18653/v1/P18-4020",
    pages = "116--121",
}
@inproceedings{Kingma2015adam,
  author    = {Diederik P. Kingma and Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {Proceedings of the 3rd International Conference on Learning Representations},
  address = {San Diego, CA, USA},
  year      = {2015},
}
@inproceedings{fu-etal-2024-disperse,
    title = "Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via Alignment Tax Reduction",
    author = "Fu, Tingchen  and
      Cai, Deng  and
      Liu, Lemao  and
      Shi, Shuming  and
      Yan, Rui",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.175/",
    doi = "10.18653/v1/2024.findings-acl.175",
    pages = "2967--2985",
    abstract = "Supervised fine-tuning (SFT) on instruction-following corpus is a crucial approach toward the alignment of large language models (LLMs). However, the performance of LLMs on standard knowledge and reasoning benchmarks tends to suffer from deterioration at the latter stage of the SFT process, echoing the phenomenon of alignment tax. Through our pilot study, we put a hypothesis that the data biases are probably one cause behind the phenomenon. To address the issue, we introduce a simple disperse-then-merge framework. To be concrete, we disperse the instruction-following data into portions and then train multiple sub-models using different data portions. Lastly, we merge multiple models into a single one via model merging techniques. Despite its simplicity, our framework outperforms various sophisticated methods such as data curation and training regularization on a series of standard knowledge and reasoning benchmarks."
}

@article{clyne-constraints,
url = {https://doi.org/10.1515/ling.1987.25.4.739},
title = {Constraints on code switching: how universal are they?},
title = {},
author = {Michael Clyne},
pages = {739--764},
volume = {25},
number = {4},
journal = {Linguistics},
doi = {doi:10.1515/ling.1987.25.4.739},
year = {1987},
lastchecked = {2025-02-14}
}
