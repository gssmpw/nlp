\section{Related work}
\label{sec:2}

\subsection{Behavioural evaluation of LLMs}\label{sec:2.1}
Recent reviews of the evaluation landscape indicate that SOTA evaluation largely consists of single-turn, static benchmarks that may overlook interactive behaviours ____. When evaluations \emph{are} multi-turn, they largely focus on users with malicious intent, rather than simulate innocuous use of AI systems ____. Red teaming approaches incorporate multiple turns and are sometimes automated, but they are highly adaptive, making results difficult to compare ____. Other multi-turn investigations of human-AI interaction are large-scale human subject studies, akin to traditional social science experiments, that can be difficult to repeat and scale ____. Here, we build on research from automated red-teaming and human subject studies to introduce a non-adversarial automated multi-turn evaluation: we utilise interactive user simulations to thoroughly explore our target construct, then employ human subject studies in a one-off \textit{interactive} validation step ____. 

\subsection{Measuring anthropomorphisation of LLMs}\label{sec:2.2}
Anthropomorphism is a largely instinctive, unconscious response whereby humans attribute human-like traits to non-human entities ____.  Anthropomorphic behaviours of AI systems can lead to users developing anthropomorphic \emph{perceptions} of these systems, which can in turn influence downstream user behaviours ____. In that way, anthropomorphic behaviours can have significant safety implications. Prior user studies examining these implications have shown that anthropomorphic AI systems can enhance perceptions of system accuracy ____ and induce unrealistic or ungrounded emotional attachments to AI systems ____. Other research examining how academic papers and news articles \textit{describe} technologies shows that articles discussing natural language processing (NLP) systems and language models contain the highest levels of implicit anthropomorphisation ____. In this work, we provide the first comprehensive, quantitative snapshot of anthropomorphic language use by current SOTA AI systems, which may drive some of these well-studied implications on human-AI interaction. Importantly, we present an evaluation methodology that can be re-used to assess new systems as they emerge.