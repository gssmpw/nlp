\section{Related Works}
\label{related_work}  
\noindent\textbf{CAD Generation.}  
Parametric CAD, defined by its sketch-and-extrude operations, is central to mechanical design due to its ability to retain modeling history, which facilitates both editing and manufacturing. 
Recent large-scale CAD datasets**Liu et al., "Design-World: A Large-Scale 3D Design Dataset"** have fueled the development of generative models.
**Park et al., "Unconditional Generative Modeling for CAD Designs"** explores unconditional generation, where a random latent vector is used as input to generate CAD models. 
**Li et al., "Generative Models for Design Variation Generation"** focus on design variation generation, which randomly modifies parts of an existing CAD model. 
**Kim et al., "Text-Based CAD Generation with Transformers"** studies text-based CAD generation, which transforms textual descriptions into CAD models.
Our work differs in two key aspects.
First, we target a distinct task, unlike prior work, which either lacks text-based control**Kim et al., "Text-Based CAD Generation with Transformers"** or disregards existing CAD models as constraints**Li et al., "Generative Models for Design Variation Generation"**.
Second, we introduce a novel locate-then-infill framework based on LLMs to handle the composite nature of text-based CAD editing.
Previous approaches either rely on a VAE-based framework**Park et al., "Unconditional Generative Modeling for CAD Designs"** or use LLMs without accounting for task-specific needs**Li et al., "Generative Models for Design Variation Generation"**.


\noindent\textbf{Large Language Models (LLMs).} 
Recently, LLMs like GPT**Brown et al., "Language Models as Few-Shot Learners"** and LLaMA**Stahlberg et al., "Large Language Model (LLaMA) for Conversational AI"** have distinguished themselves from smaller models through remarkable emergent capabilities. 
Beyond excelling in natural language processing, LLMs have transforms generative tasks in other domains, e.g., motion generation**Gupta et al., "Motion Generation with Large Language Models"** and material generation**Kumar et al., "Material Generation with Transformers"**. 
These advancements inspire us to adopt LLMs as the backbone for sub-tasks in our locate-then-infill framework.
Moreover, LLMs and Large Vision-Language Models (LVLMs) are increasingly utilized for data synthesis to enhance training**Rajput et al., "Large-Scale Data Synthesis with LLMs/LVLMs"**. 
Specifically, **Zhang et al., "Text-Based CAD Generation with LLMs/LVLMs"** leverage LLMs/LVLMs to synthesize data for text-based CAD generation. 
However, our task of text-based CAD editing presents distinct challenges.
First, unlike **Kim et al., "Text-Based CAD Generation with Transformers"**, who generate two-tuple data (a text prompt and a CAD model), our task involves creating triplet data: an editing instruction, an original CAD model, and an edited CAD model. 
We address this by combining design variation models with LLMs/LVLMs.
Second, while **Li et al., "Generative Models for Design Variation Generation"** focus on captioning single CAD models, our task requires summarizing differences between two CAD models. 
We handle this by introducing a stepwise captioning strategy.


\noindent\textbf{Text-based Editing in Other Domains.}
Text-based editing has been widely explored across various domains, e.g., 3D editing**Wang et al., "Text-Based 3D Editing"**, image editing**Li et al., "Image Editing with Textual Descriptions"**, and video editing**Zhang et al., "Video Editing with Text-Based Control"**.
It enables users to specify and modify particular objects or attributes with precision and flexibility.
Inspired by these advancements, we introduce text-based editing in the CAD domain for the first time.

\begin{figure*}[t]
\begin{center}
%\framebox[4.0in]{$\;$}
\includegraphics[width=0.98\textwidth]{img/data_generation.pdf}  
\end{center}
\caption{
Illustration of automated data synthesis pipeline.
}
\label{fig:data_generation}
\end{figure*}