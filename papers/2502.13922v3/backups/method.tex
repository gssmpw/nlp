\section{Methodology}
\label{sec:method}
\subsection{Position Embedding Scaling: A Unified View}
Given the various methods that extend models' context length through position indices scaling  and frequency basis scaling, we first show that the transformations applied to position indices are de facto casting the frequency basis, which is formalised in Theorem 1.

\paragraph{Theorem 1.} \textit{For the transformation $\mathcal{T}$ to position index $m$, there exists an equivalent transformation $\bm{\mathcal{T}}$ to frequency basis $\vtheta$ in~\Cref{eq:rope}, namely}
\begin{equation}
\label{eq:eq_of_pi_fb}
    f(\vx, \mathcal{T} \cdot m, \vtheta) = f(\vx, m, \bm{\mathcal{T}} \odot \vtheta),
\end{equation}
\textit{where $\bm{\mathcal{T}}=\left[\mathcal{T}\right]_{i=1}^{d/2} $ and $\odot$ denotes the element-wise transformation.}

Hence, we can derive a unified form for PE scaling methods that consistently projects the frequency basis by $\valpha(t)$:
\begin{equation}
    f_t(\vx, m, \vtheta) = f\left(\vx, m,  \valpha(t) \odot \vtheta \right),
\end{equation}
where $\valpha(t)$ is the transformation variable corresponds to length scaling factor $t$. For example, the $\valpha(t)=\left[1/t\right]_{i=1}^{d/2}$ in case of PI and $\valpha(t)=\left[(s \cdot t)^{-2i/(d-2)}\right]_{i=1}^{d/2}$ for Yarn.




% Now we access the unified continuous view of off-the-shelf position extending methods: 
% \begin{equation}
% \label{eq:unified_view}
%     \vz_t = \vz_{1} + \int \frac{d \log \valpha(t) } {d t},
% \end{equation}

% \subsection{State-Dependent Context Length Extending}

To be simplified, we define $\vy(t) \!=\! \valpha(t) \odot \vtheta$ as the scaling frequency basis at context length of $t \cdot L$. As  $\vy(1) \!=\!  \vtheta$ namely $\valpha(1) \!=\! 1$, we have $\vy(t) \!=\! \valpha(t) \odot \vy(1)$. This indicates a progressive chain across discrete $t$ values that 
\begin{equation}
\label{eq:unified}
    \vz(t) = \vz(1) + \log \valpha(t) = \vz(t-1) + \log \frac{\valpha(t)}{\valpha(t-1)},
\end{equation}
where $\vz(t) \!=\! \log \vy(t)$.
% \begin{equation}
%     \vz_t = \vz_{t-1} + \log \frac{\valpha_t}{\valpha_{t-1}}.
% \end{equation}
Let us now consider a continuous dynamics of frequency basis ${d \vz(t)} / {d t}$, we can easily derive
\begin{equation}
\label{eq:continuous_dynamic}
    \frac{d \vz(t)} {d t} = \frac{d \log \valpha(t) } {d t}.
\end{equation}
In essence, recent PE scaling methods primarily concentrate on formulating suitable dynamics for frequency basis that enable models to adapt to longer contexts.
% \paragraph{Theorem 2.} For any continuous function




\begin{figure}[!t]
\centering
\includegraphics[width=\textwidth]{figures/model.pdf}
\vspace{-2em}
\caption{The graphical model of discrete PE scaling (left) and our continuous PE scaling (right).}
\label{fig:model}
\end{figure}



\subsection{Continuous PE Scaling via Neural ODE}
Even given the continuous dynamics of frequency basis, previous methods typically extend context length at discrete $t$ values, e.g., PI fine-tunes model on a specific length $t \cdot L$. Such methods are susceptible to overfitting the fine-tuned length, leading to either poor extrapolation ability or performance drops within shorter lengths, or both in some cases. Therefore, our method aims for a \textit{continuous} position extending. We first utilise the function $g\colon \mathbb{R}^{d/2} \to \mathbb{R}^{d/2}$ to model the dynamics as:
\begin{equation}
    \frac{d \vz(t)} {d t} = g(\vz(t), t).
\end{equation}
By restricting the function to be associated to the latent states $\vz(t)$, $g$ is capable of capturing the fine-grained changes of frequency basis during the extending process. However, it is non-trivial to manually design the $\vz(t)$-aware function $g$. Here, we directly parameterise the function using the neural network $\vphi$. Hence, for any $t^{\prime} \in [1, t]$, there is a neural ODE models the scaling of frequency basis as
\begin{equation}
\label{eq:ode}
    \vz(t^\prime) = \vz(1) + \int_1^{t^\prime} g_\vphi(\vz(t), t) d t,
\end{equation}
where the frequency basis at the length $t^{\prime} \!\cdot\! L$ can be derived by $\vtheta_{t^\prime}=\exp(\vz(t^\prime))$.

More specifically, we adopt a up-and-down projection as the neural network, expressed as:
\begin{equation}
\label{eq:network}
    g_\vphi(\vz(t), t) = \mW_{\text{down}} \cdot \sigma\left( \mW_{\text{up}}\cdot \vz(t)\right) + \rvxi_t,
\end{equation}
where $\mW_{\text{up}} \in \mathbb{R}^{\frac{d}{2} \times \lambda d}$ and $\mW_{\text{down}} \in \mathbb{R}^{\lambda d \times \frac{d}{2} }$; $\lambda$ is the amplification factor, $\sigma$ is the SiLU activation function and $\rvxi_t$ is the scalar time embedding.
% \gc{data-dependent}
% casts the frequency basis controlled by the continuous variable $t$.

% \gc{Inference mode: for example, change the basis as long as generating one new word or block-wise.}



\subsection{Train on Short, Test on Long}
\label{subsec:training_testing}
To learn the ODE in~\Cref{eq:ode} for continuous $t$, we randomly sample $t^{\prime} \in [1, t]$ for each training step, enabling the model to adjust to the frequency basis without overfitting a specific length. However, it is infeasible to actually train LLMs with variable sequence lengths at different training steps. To overcome this, we disentangle the desired context length and trained sequence length. In other words, we train sequences to adapt to the frequency basis corresponding to longer context lengths.  By setting the length scaling factor $t$ larger than $L^{\text{Train}}/L$, our method has the potential to extrapolate the context length to $t\cdot L$ even when trained on shorter $L^{\text{Train}}$.

Note that the frequency basis is bound with the position index in~\Cref{eq:rope}. This reveals the aforementioned training involves inconsistency between the frequency basis and position index. Here, we propose the \textit{position extrapolation} strategy to address this consistency. Contradict to PI that shrinks the position indices into the range of context length, we scale the position indices $\{1, 2, \dots, L^{\text{Train}}\}$ of the trained sequences up to the range $[1, t^\prime\!\cdot\! L]$. The position indices can be uniformly scaled to $\{1\!\cdot\! s, 2 \!\cdot\! s, \dots, L^{\text{Train}} \!\cdot\! s\}$ where $s=t^\prime\!\cdot\! L/L^{\text{Train}}$, or by selecting $L^{\text{Train}}$ indices randomly sampled from $[1, t^\prime\!\cdot\! L]$. Empirically, we found the random-sampling position indices generally perform better, where we discuss more in~\Cref{sec:experiment}.

During inference, the ideal scenario is to acquire the frequency basis corresponding to each sequence length. However, this approach is computationally demanding. To improve efficiency,  we first cache some frequency basis derived from $g_\vphi$ for $K$ discrete $t$ values as $t_k$. For each inference sequence with $L^{\text{Infer}}$, we employ the frequency basis corresponding to the nearest upper bound within $t_k \!\cdot\! L$ for $k=1,\dots, K$. Through this, our method introduces negligible latency compared to naive inference of LLMs.

