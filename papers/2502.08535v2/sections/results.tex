\section{Experimental results}
\label{sec:results}

In this section, we present our experimental setup,
and the results obtained from applying our framework to it.
%We assess the device's network communication robustness, at boot and for each type of interaction with the device.
% For the results, we first show an example of a complete event signature tree
% generated by our framework,
% then present metrics, computed over all the obtained trees,
% with the goal of assessing each event's robustness.

%% Legacy paragraph, from when the paper's focus was not really over robustness
% Every event showcasing new communication flows at a tree depth higher than 1
% backs up our initial claim that devices provide hidden communication patterns,
% which must be taken into account for an exhaustive device profiling.
% Additionally, it shows that the devices reveal some robustness to network instability,
% as events might still succeed if its first-level traffic is unsuccessful.


\subsection{Experiment setup}

We apply our methodology to a controlled testbed network comprised of real-world devices,
mimicking a typical Smart Home network, depicted in Fig.~\ref{fig:testbed}.
We instrument an array of commercial, off-the-shelf Smart Home devices,
including four power plugs, three cameras, and three light bulbs.
The profiled interactions, per device category, are the following:
\begin{itemize}
  \item For all devices: booting the device;
  \item Power plugs: toggling them on/off;
  \item Cameras: streaming their video feed;
  \item Light bulbs: toggling them on/off, changing their brightness, changing their color.
\end{itemize}

\input{figures/tikz/testbed.tex}


For all interactions other than booting,
we derive up to three usage scenarios,
to account for various ways of controlling the device:
% the default usage scenario involves controlling the device under test
% through its official companion app;
% nonetheless, it is also possible to leverage a \emph{Smart Home automation platform},
% which can control the device on behalf of the official app.
% To account for both scenarios,
% we derive up to three usage scenarios per device:
\begin{itemize}
  \item For all devices, we issue their interactions using their official companion app;
  \item For devices that support it, we also control them using the app of the popular home automation platform \emph{SmartThings}~\cite{smartthings};
  \item For the TP-Link plug and the Hue light bulb, we also experiment with other apps; respectively, \emph{TP-Link Tapo} \cite{app-tapo} (another app from the same manufacturer, targeted toward \emph{Tapo}-branded devices) and \emph{Hue Essentials} \cite{app-hue-essentials} (third-party app for Hue devices).
  %\item The TP-Link plug and the Hue light bulb could also be controlled through another app than the officially suggested one, respectively the \emph{TP-Link Tapo} \cite{app-tapo} app and the \emph{Hue Essentials} app \cite{app-hue-essentials}.
\end{itemize}

The smartphone running the device-specific apps is a Crosscall CORE-X4 \cite{phone},
running Android 10.

\input{figures/tables/devices_id.tex}

The complete device references are listed in Table~\ref{tab:devices_id},
along with the corresponding smartphone apps and interactions instrumented.
We only consider IP traffic,
whether over Ethernet or Wi-Fi.
Therefore, for the two devices communicating using Zigbee,
we profile the traffic issued by their hub,
i.e. the Hue bridge for the Hue lamp,
and the SmartThings hub for the SmartThings Outlet,
respectively.
For the \emph{boot} interaction experiments over those devices,
we synchronously power-cycle both the device itself and its hub.

Our practical experimental parameters, inspired by related works \emph{PingPong} \cite{ping-pong} and \emph{IoTAthena} \cite{wan_iotathena_2022}, are the following:
\begin{itemize}
  \item Number of event iterations: $m = 20$;
  \item Traffic capture timeout: $d = 20$ seconds (90 seconds for event \emph{boot});
  % \item Number of event iterations (defined as $m$ in Section~\ref{sec:traffic-capture}): $m = 20$;
  % \item Traffic capture timeout (defined as $d$ in Section~\ref{sec:traffic-capture}): $d = 20$ seconds (90 for event \emph{boot});
  \item Duration between two event iterations: randomly chosen between 40 (120 for event \emph{boot}) and 150 seconds.
\end{itemize}


\subsection{Example signature tree}

As an example of our framework's results,
we present the event signature tree
generated for one device of our corpus,
namely the TP-Link HS110 smart plug \cite{hs110}.
This device being a smart power plug,
it provides one interaction, i.e. toggling it on and off.
For this experiment, we controlled the device using its official Android companion app,
i.e. Kasa Smart \cite{app-kasa}. The resulting signature tree
is displayed in Fig.~\ref{fig:device-tree}.
To avoid unnecessarily cluttering the figure,
we only show the first occurrence of each unique flow.
In general, every \emph{first-level} flow occurs as a child of every tree node.
In certain cases, a \emph{hidden} flow will appear at deeper levels,
which embodies a backup communication strategy
when the default one fails.
%\CP{Are there many repeating flows?}
%\FDK{A lot. Basically, each first-level flow appears as a child of every other.}
%\CP{We need to say something about this.}
%\FDK{Reworked the paragraph to address this.}

%\newcommand*\circled[1]{\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {#1}}}}
\input{figures/tikz/tree_concrete.tex}

By default, toggling the plug triggers seven different flows:
\begin{itemize}
  \item[\circled{A}] between the phone and the plug's TCP port 9999;
  \item[\circled{B}] between the phone and the plug's UDP port 9999;
  \item[\circled{C}] from the phone to the mDNS multicast address (224.0.0.251, UDP port 5353);
  \item[\circled{D}] from the phone to the broadcast address' (255.255.255.255) UDP port 9999;
  \item[\circled{E}] HTTPS between the phone and the server \texturl{xx-device-telemetry-gw.iot.i.tplinknbu.com};
  \item[\circled{F}] DNS query/response from the plug to the LAN gateway, for the domain name \texturl{use1-api.tplinkra.com};
  \item[\circled{G}] HTTPS between the plug and the server \texturl{use1-api.tplinkra.com}.
\end{itemize}
Flows \circled{C} and \circled{D} are unidirectional,
while the remaining ones are bidirectional.

When one of those flows is blocked,
the device might issue different network traffic to perform its event.
Indeed, when the TCP communication \circled{A} on the plug's port 9999 is blocked,
we see two new HTTPS flows appearing:
between the phone and the server \texturl{n-wap.tplinkcloud.com}, and
between the plug and the IPv4 address \texturl{79.125.56.92}.
The former also occurs when other first-level flows are blocked,
including the similar pattern using UDP instead of TCP.
Both flows are part of a backup strategy,
going through the internet,
if the device is not able to communicate locally with the controlling phone.
Such \emph{hidden}, backup flows also appear as children of the \emph{first-level} flow \circled{D}.


\subsection{Assessing device event robustness}
\label{sec:robustness}

%% Legacy paragraphs, when the plots were in the body text instead of the appendix

% As a quantitative evaluation of our framework,
% we derived various descriptive metrics over our experimental corpus.
% The first one is the count of unique Flow IDs discovered,
% which represents the variability of our devices' communication patterns.
% This metric was further split into two following groups bearing different semantics:
% the count of unique \emph{first-level} Flow IDs,
% and the count of unique \emph{hidden} Flow IDs.
% The former exhibits the patterns that state-of-the-art techniques could discover,
% as they appear without disturbing the traffic.
% The latter, however, illustrates the patterns which appear at tree depths of two and above,
% and can thus be discovered only through our multi-level approach.
% Fig.~\ref{fig:count_flow_id} depicts such metrics;
% the first 10 events being the \emph{boot} events,
% and the subsequent ones the remaining user-triggered events.

% The count of unique \emph{hidden} Flow IDs
% can be used as an indicator of the robustness of the device.
% Indeed, it embodies the alternative communication strategies
% that a device might use if the default one fails,
% effectively enhancing the device's robustness to network instability.
% As such, we rebrand this number as the \emph{robustness score}.
% Fig~\ref{fig:robustness-score} depicts this count across all device events,
% as well as its mean, which is 1.94.

The experiments in our testbed of devices result in
the extraction of 254 unique Flow IDs,
of which 70 are \emph{hidden} ones
(i.e. 27.56\%).
\emph{Hidden} Flow IDs embody the alternative communication strategies
that a device might use if the default one fails,
effectively enhancing the device's robustness to network instability (remember that we only keep Flow IDs associated with successful event executions).
As such, we rebrand the count of hidden Flow IDs
as the \emph{robustness score},
and compute it over all the instrumented device events.
Out of the 36 instrumented events,
23 (63.9\%) have a robustness score of at least one (mean 1.94).
This value is encouraging:
most types of interactions dispose of at least one backup strategy
in the case of a failure.
Comprehensive results over all events are shown in the appendix:
Fig.~\ref{fig:count_flow_id} shows the count of
\emph{first-level} and \emph{hidden} Flow IDs;
Fig.~\ref{fig:robustness-score} shows the \emph{robustness score}.

To gain further insight into the distribution of robustness scores,
%and inspired by the categorization done by Hu \textit{et al.} \cite{iot_ipv6} for IPv6 usage behavior,
Fig.~\ref{fig:robustness-grouped} shows the same \emph{robustness score},
grouped along three categories, namely:
\begin{itemize}
  \item Device category;
  \item Controlling app;
  \item Manufacturer.
\end{itemize}
%\CP{Hu \textit{et al.} \cite{iot_ipv6} look at the robustness score?}
%\FDK{They do not, but they analyze the IPv6 behavior of smart home devices, and group their results in similar categories.}
%\RS{I have removed the reference to Hu et al., because the reviewers could think that their work is related}

\begin{figure}
  \centering
  \includegraphics{figures/graphs/robustness_grouped.pdf}
  \caption{\emph{Robustness score} for all device interactions, grouped per device type, app, and manufacturer. Each marker represents the robustness score of one event.}
  \label{fig:robustness-grouped}
\end{figure}

We observe that the different device categories do not provide the same robustness.
The most robust devices seem to be the power plugs.
A rationale might be that,
as the plugs' operation (switching on or off) is the most simple,
it takes less effort to the manufacturers to provide backup strategies.

Regarding the companion app,
Tuya seems to be less robust than the others.
While most apps provide device control
either via the local network or through the cloud,
Tuya devices are notoriously reluctant to LAN-based control,
preferring cloud-based communication.
This decision reduces their robustness by design,
as, when the cloud endpoints cannot be reached,
the device cannot function properly.
SmartThings boasts a good score,
both as a controlling app and a manufacturer,
helped by a very high robustness score for the SmartThings Outlet's \emph{boot} interaction.
We can also see that the "other" app category provides no backup strategy whatsoever,
suggesting that a user should prefer using trusted and official apps, even if the devices' API is theoretically open.

%\FDK{Added the following paragraph under Cristel's advice.}
We illustrate the effect of the choice of the app with the Philips Hue lamp device and its \emph{toggle} interaction,
which we have triggered by the official app (Philips Hue),
the SmartThings app, and a third-party app (Hue Essentials).
The official app and SmartThings show similar results:
five and six \emph{first-level} Flow IDs respectively,
and one \emph{hidden} flow for each.
However, when using the Hue Essentials app,
only three \emph{first-level} flows are extracted,
and no \emph{hidden} flow.



Among the manufacturers,
the most robust one seems to be Xiaomi,
for which the only device in our testbed was a camera.
As cameras are usually tied to more critical functions,
such as monitoring a home against potential intrusions,
Xiaomi followed a respectable rationale here.
TP-Link seems quite robust,
while Philips, even as a trusted device manufacturer,
disappoints in terms of robustness.

% \FDK{This paragraph has been kept from the previous version. Still relevant ?}
% A possible way to increase the number of interactions to investigate, and potentially the number of discovered communication patterns, is to include experimental setups where two or more IoT devices communicate with each other. In most home automation solutions, actions involving multiple devices, such as switching on a lamp by a movement sensor, are centrally managed by a dedicated hub, but some devices on the market support control message exchanges between devices without a hub. We deem as future work to cover this kind of traffic. We argue that our methodology can still be applied, albeit with some modifications: on the one hand, the setup of such device interactions on a home automation platform, and on the other hand a broader traffic filter inside the LAN, to accommodate all devices potentially taking part to the interactions. \CP{rephrase this last sentence.}
%It should however be noted that the signature tree for events involving multiple devices might undergo a state space explosion problem. 


\subsection{A closer look at DNS data}

% A primordial implementation of network communication robustness
% lies within interactions with the DNS protocol.
The Domain Name System (DNS), which allows communicating with hosts
by providing a domain name instead of their IP address, 
is a useful tool to provide application robustness.
% serves network robustness by design:
% a same name can point to different and/or multiple addresses,
% depending on the network's state.
% With this in mind,
Here, we steer our analysis towards interactions with the DNS protocol,
guided by two questions:
\begin{itemize}
  \item If the servers the device tries contacting are unresponsive,
  will it contact servers with other domain names?
  \item If the device's default DNS resolver is unreachable,
  will the device try other ones?
\end{itemize}

We focus on event signatures related to \emph{boot} interactions,
as those proved to provide the most information concerning DNS usage.
Fig.~\ref{fig:count_dns_boot} shows the data related to both questions:
the count of unique domain names contacted,
and that of DNS resolvers queried.
In both cases, the \emph{first-level} and the \emph{hidden} count are shown.
The results for all types of interactions is shown in Fig.~\ref{fig:count_dns_all}
in the appendix.


\begin{figure}
  \centering
  \stackengine{0.4\linewidth}{% Adjust overlap amount
    \includegraphics{figures/graphs/count_dns_boot.pdf}
  }{
    \includegraphics{figures/graphs/count_dns_boot_legend.pdf}
  }{O}{c}{F}{F}{L}
  \caption{Count of unique domain names / DNS resolvers contacted per device issuing the event \emph{boot}}
  \label{fig:count_dns_boot}
\end{figure}


\subsubsection{Server's domain names}

We observe that, out of the 10 \emph{boot} events,
six consider contacting at least one alternative domain name
if the default one fails.


\subsubsection{DNS resolvers}

Out of the 17 DNS resolvers contacted,
only two are \emph{hidden} resolvers.
One of them is simply the LAN gateway (\texttt{192.168.1.1}),
meaning the only real new DNS resolver discovered at a level deeper than one is the Chinese public DNS resolver \texttt{114.114.114.114},
contacted by the Xiaomi camera when the LAN gateway is not responsive.
This result shows that, regarding domain name resolving,
Smart Home devices still lack robustness.
Indeed, every device should try contacting a backup resolver if the primary one fails,
as this has been made easy thanks to publicly available resolvers such as Cloudflare's \texttt{1.1.1.1} or Google's \texttt{8.8.8.8}.


\subsection{Comparison with related work}

In this last part of the evaluation,
we compare the profiles generated by our framework
with those generated by methods proposed in related work,
namely \emph{PingPong} \cite{ping-pong},
\emph{BehavIoT} \cite{behaviot},
and \emph{MUDgee} \cite{mudgee},
for the devices present in both their testbed and ours.
The former two contributions profile specific individual events, 
whereas the latter profiles the device as a whole.
Table~\ref{tab:devices_coverage} summarizes the devices and interactions covered by each work.

\begin{table}
  \centering
  \begin{tabular}{c|c|c|c}
   & \textbf{PingPong}  & \textbf{BehavIoT} & \textbf{MUDgee} \\
	 & \cite{mudgee} & \cite{ping-pong} & \cite{behaviot} \\
  \hline
  TP-Link HS110 \cite{hs110} & toggle & toggle & device \\
  Philips Hue lamp \cite{hue-lamp} & toggle & \xmark & device \\
  SmartThings Outlet \cite{st-outlet} & toggle & boot & device \\
  D-Link camera \cite{dlink-cam} & \xmark & stream & \xmark \\
  \end{tabular}
  \caption{Related work device \& interaction coverage}
  \label{tab:devices_coverage}
\end{table}

\begin{figure}
  \centering
  \includegraphics{figures/graphs/comparison_all.pdf}
  \caption{Comparison of discovered unique Flow IDs between three related works and ours.}
  \label{fig:comparison_all}
\end{figure}

Data from \emph{PingPong} and \emph{MUDgee} were taken from their reported results,
whereas \emph{BehavIoT}'s results were reproduced on our side.
% \CP{This shows one side of the picture. It is interesting to also mention the number of devices they have that we do not support. Maybe in appendix.}
% \FDK{Not sure if it is really relevant. The appendices' length is limited.}
%\CP{Do you reproduce the other works or cite the results that are expressed in the paper ? If you reproduce and share the code, this is added value for your papers.}
%\FDK{For PingPong and MUDgee, I simply took their reported results. For BehavIoT, I reproduced their experiments. I explained that explicitly.}
Fig.~\ref{fig:comparison_all} compares the count of unique Flow IDs discovered by each work.
The three covered related works, by design,
do not explore the event signature tree deeper than the first level.
Considering event-level profiling,
our methodology is, as expected, able to extract more Flow IDs
than \emph{PingPong} and \emph{BehavIoT},
thanks to a deeper tree inspection,
and also a more thorough communication pattern extraction, even at the first level.
For device-level profiling,
the value representing our work has been computed by merging the event signature trees
extracted from all events of the given device.
For two of the instrumented devices,
our strategy is again able to extract a significantly higher number of Flow IDs than \emph{MUDgee}.
However, the number of Flow IDs is identical for the TP-Link HS110.
After manual investigation,
it appears the extracted Flow IDs are different:
10 out of 14 \emph{MUDgee} flows are NTP traffic towards various servers,
whereas our solution did not extract any NTP patterns.
This traffic might therefore be part of periodic patterns,
which are not covered by our strategy.
On the other hand, we extract 10 non-NTP traffic patterns
which were not detected by \emph{MUDgee}.
