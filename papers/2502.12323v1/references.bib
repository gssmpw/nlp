
@misc{arnold_building_2024,
	type = {Working {Paper}},
	series = {Working {Paper} {Series}},
	title = {Building {Non}-{Discriminatory} {Algorithms} in {Selected} {Data}},
	url = {https://www.nber.org/papers/w32403},
	doi = {10.3386/w32403},
	abstract = {We develop new quasi-experimental tools to understand algorithmic discrimination and build non-discriminatory algorithms when the outcome of interest is only selectively observed. These tools are applied in the context of pretrial bail decisions, where conventional algorithmic predictions are generated using only the misconduct outcomes of released defendants. We first show that algorithmic discrimination arises in such settings when the available algorithmic inputs are systematically different for white and Black defendants with the same objective misconduct potential. We then show how algorithmic discrimination can be eliminated by measuring and purging these conditional input disparities. Leveraging the quasi-random assignment of bail judges in New York City, we find that our new algorithms not only eliminate algorithmic discrimination but also generate more accurate predictions by correcting for the selective observability of misconduct outcomes.},
	urldate = {2024-11-20},
	publisher = {National Bureau of Economic Research},
	author = {Arnold, David and Dobbie, Will S. and Hull, Peter},
	month = may,
	year = {2024},
	doi = {10.3386/w32403},
	file = {Full Text:/Users/matthewgordon/Zotero/storage/4Q2QMM9V/Arnold et al. - 2024 - Building Non-Discriminatory Algorithms in Selected.pdf:application/pdf},
}

@misc{angelopoulos_prediction-powered_2023,
	title = {Prediction-{Powered} {Inference}},
	url = {http://arxiv.org/abs/2301.09633},
	abstract = {Prediction-powered inference is a framework for performing valid statistical inference when an experimental dataset is supplemented with predictions from a machine-learning system. The framework yields simple algorithms for computing provably valid confidence intervals for quantities such as means, quantiles, and linear and logistic regression coefficients, without making any assumptions on the machine-learning algorithm that supplies the predictions. Furthermore, more accurate predictions translate to smaller confidence intervals. Prediction-powered inference could enable researchers to draw valid and more data-efficient conclusions using machine learning. The benefits of prediction-powered inference are demonstrated with datasets from proteomics, astronomy, genomics, remote sensing, census analysis, and ecology.},
	urldate = {2024-11-20},
	publisher = {arXiv},
	author = {Angelopoulos, Anastasios N. and Bates, Stephen and Fannjiang, Clara and Jordan, Michael I. and Zrnic, Tijana},
	month = nov,
	year = {2023},
	note = {arXiv:2301.09633},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Quantitative Biology - Quantitative Methods, Statistics - Machine Learning, Statistics - Methodology},
	file = {Preprint PDF:/Users/matthewgordon/Zotero/storage/NUISGSJE/Angelopoulos et al. - 2023 - Prediction-Powered Inference.pdf:application/pdf;Snapshot:/Users/matthewgordon/Zotero/storage/GWISSWYE/2301.html:text/html},
}

@misc{lu_quantifying_2024,
	title = {Quantifying uncertainty in area and regression coefficient estimation from remote sensing maps},
	url = {http://arxiv.org/abs/2407.13659},
	doi = {10.48550/arXiv.2407.13659},
	abstract = {Remote sensing map products are used to obtain estimates of environmental quantities, such as deforested area or the effect of conservation zones on deforestation. However, the quality of map products varies, and - because maps are outputs of complex machine learning algorithms that take in a variety of remotely sensed variables as inputs - errors are difficult to characterize. Thus, population-level estimates from such maps may be biased. In this paper, we compare several uncertainty quantification methods - stratified estimator, post-stratified estimator, and prediction-powered inference - that combine a small amount of randomly sampled ground truth data with large-scale remote sensing map products to generate unbiased estimates. Applying these methods across four remote sensing use cases in area and regression coefficient estimation, we find that they result in estimates that are more reliable than using the map product as if it were 100\% accurate and have lower uncertainty than using only the ground truth and ignoring the map product. Prediction-powered inference uses ground truth data to correct for bias in the map product estimate and (unlike stratification) does not require us to choose a map product before sampling. This is the first work to (1) apply prediction-powered inference to remote sensing estimation tasks, and (2) perform uncertainty quantification on remote sensing regression coefficients without assumptions on the structure of map product errors. To improve the utility of machine learning-generated remote sensing maps for downstream applications, we recommend that map producers provide a randomly sampled holdout ground truth dataset to be used for calibration in uncertainty quantification alongside their maps. Data and code are available at https://github.com/Earth-Intelligence-Lab/uncertainty-quantification.},
	urldate = {2024-11-20},
	publisher = {arXiv},
	author = {Lu, Kerri and Bates, Stephen and Wang, Sherrie},
	month = sep,
	year = {2024},
	note = {arXiv:2407.13659},
	keywords = {Economics - General Economics, Electrical Engineering and Systems Science - Signal Processing, Quantitative Finance - Economics, Statistics - Applications},
	file = {Preprint PDF:/Users/matthewgordon/Zotero/storage/5MT7BDXA/Lu et al. - 2024 - Quantifying uncertainty in area and regression coe.pdf:application/pdf;Snapshot:/Users/matthewgordon/Zotero/storage/7AXRC82D/2407.html:text/html},
}

@article{kim_universal_2022,
	title = {Universal adaptability: {Target}-independent inference that competes with propensity scoring},
	volume = {119},
	shorttitle = {Universal adaptability},
	url = {https://www.pnas.org/doi/10.1073/pnas.2108097119},
	doi = {10.1073/pnas.2108097119},
	abstract = {The gold-standard approaches for gleaning statistically valid conclusions from data involve random sampling from the population. Collecting properly randomized data, however, can be challenging, so modern statistical methods, including propensity score reweighting, aim to enable valid inferences when random sampling is not feasible. We put forth an approach for making inferences based on available data from a source population that may differ in composition in unknown ways from an eventual target population. Whereas propensity scoring requires a separate estimation procedure for each different target population, we show how to build a single estimator, based on source data alone, that allows for efficient and accurate estimates on any downstream target data. We demonstrate, theoretically and empirically, that our target-independent approach to inference, which we dub “universal adaptability,” is competitive with target-specific approaches that rely on propensity scoring. Our approach builds on a surprising connection between the problem of inferences in unspecified target populations and the multicalibration problem, studied in the burgeoning field of algorithmic fairness. We show how the multicalibration framework can be employed to yield valid inferences from a single source population across a diverse set of target populations.},
	number = {4},
	urldate = {2024-11-20},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kim, Michael P. and Kern, Christoph and Goldwasser, Shafi and Kreuter, Frauke and Reingold, Omer},
	month = jan,
	year = {2022},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2108097119},
	file = {Full Text PDF:/Users/matthewgordon/Zotero/storage/ZURVWVYJ/Kim et al. - 2022 - Universal adaptability Target-independent inferen.pdf:application/pdf},
}

@misc{dell_deep_2024,
	title = {Deep {Learning} for {Economists}},
	url = {http://arxiv.org/abs/2407.15339},
	abstract = {Deep learning provides powerful methods to impute structured information from large-scale, unstructured text and image datasets. For example, economists might wish to detect the presence of economic activity in satellite images, or to measure the topics or entities mentioned in social media, the congressional record, or firm filings. This review introduces deep neural networks, covering methods such as classifiers, regression models, generative AI, and embedding models. Applications include classification, document digitization, record linkage, and methods for data exploration in massive scale text and image corpora. When suitable methods are used, deep learning models can be cheap to tune and can scale affordably to problems involving millions or billions of data points.. The review is accompanied by a companion website, EconDL, with user-friendly demo notebooks, software resources, and a knowledge base that provides technical details and additional applications.},
	urldate = {2024-11-20},
	publisher = {arXiv},
	author = {Dell, Melissa},
	month = nov,
	year = {2024},
	note = {arXiv:2407.15339},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Economics - General Economics, Quantitative Finance - Economics},
	file = {Preprint PDF:/Users/matthewgordon/Zotero/storage/SYMENQIK/Dell - 2024 - Deep Learning for Economists.pdf:application/pdf;Snapshot:/Users/matthewgordon/Zotero/storage/RPPDS6FP/2407.html:text/html},
}

@article{tibshirani_regression_1996,
	title = {Regression {Shrinkage} and {Selection} via the {Lasso}},
	volume = {58},
	issn = {0035-9246},
	url = {https://www.jstor.org/stable/2346178},
	abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
	number = {1},
	urldate = {2024-06-28},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Tibshirani, Robert},
	year = {1996},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	pages = {267--288},
	file = {JSTOR Full Text PDF:/Users/matthewgordon/Zotero/storage/HGXM6GK7/Tibshirani - 1996 - Regression Shrinkage and Selection via the Lasso.pdf:application/pdf},
}


@article{imbens_nonparametric_2004,
	title = {Nonparametric {Estimation} of {Average} {Treatment} {Effects} {Under} {Exogeneity}: {A} {Review}},
	volume = {86},
	issn = {0034-6535},
	shorttitle = {Nonparametric {Estimation} of {Average} {Treatment} {Effects} {Under} {Exogeneity}},
	url = {https://doi.org/10.1162/003465304323023651},
	doi = {10.1162/003465304323023651},
	abstract = {Recently there has been a surge in econometric work focusing on estimating average treatment effects under various sets of assumptions. One strand of this literature has developed methods for estimating average treatment effects for a binary treatment under assumptions variously described as exogeneity, unconfoundedness, or selection on observables. The implication of these assumptions is that systematic (for example, average or distributional) differences in outcomes between treated and control units with the same values for the covariates are attributable to the treatment. Recent analysis has considered estimation and inference for average treatment effects under weaker assumptions than typical of the earlier literature by avoiding distributional and functional-form assumptions. Various methods of semiparametric estimation have been proposed, including estimating the unknown regression functions, matching, methods using the propensity score such as weighting and blocking,
and combinations of these approaches. In this paper I review the state of this literature and discuss some of its unanswered questions, focusing in particular on the practical implementation of these methods, the plausibility of this exogeneity assumption in economic applications, the relative performance of the various semiparametric estimators when the key assumptions (unconfoundedness and overlap) are satisfied, alternative estimands such as quantile treatment effects, and alternate methods such as Bayesian inference.},
	number = {1},
	urldate = {2024-06-26},
	journal = {The Review of Economics and Statistics},
	author = {Imbens, Guido W.},
	month = feb,
	year = {2004},
	pages = {4--29},
	file = {Full Text:/Users/matthewgordon/Zotero/storage/2JHIR49H/Imbens - 2004 - Nonparametric Estimation of Average Treatment Effe.pdf:application/pdf;Snapshot:/Users/matthewgordon/Zotero/storage/HDNBU26Z/Nonparametric-Estimation-of-Average-Treatment.html:text/html},
}


@article{kleinberg_algorithmic_2018,
	title = {Algorithmic {Fairness}},
	volume = {108},
	issn = {2574-0768, 2574-0776},
	url = {https://pubs.aeaweb.org/doi/10.1257/pandp.20181018},
	doi = {10.1257/pandp.20181018},
	abstract = {Concerns that algorithms may discriminate against certain groups have led to numerous efforts to ‘blind’ the algorithm to race. We argue that this intuitive perspective is misleading and may do harm. Our primary result is exceedingly simple, yet often overlooked. A preference for fairness should not change the choice of estimator. Equity preferences can change how the estimated prediction function is used (e.g., different threshold for different groups) but the function itself should not change. We show in an empirical example for college admissions that the inclusion of variables such as race can increase both equity and efficiency.},
	language = {en},
	urldate = {2024-06-25},
	journal = {AEA Papers and Proceedings},
	author = {Kleinberg, Jon and Ludwig, Jens and Mullainathan, Sendhil and Rambachan, Ashesh},
	month = may,
	year = {2018},
	pages = {22--27},
	file = {Kleinberg et al. - 2018 - Algorithmic Fairness.pdf:/Users/matthewgordon/Zotero/storage/PT8VQRLB/Kleinberg et al. - 2018 - Algorithmic Fairness.pdf:application/pdf},
}

@misc{kleinberg_inherent_2016,
	title = {Inherent {Trade}-{Offs} in the {Fair} {Determination} of {Risk} {Scores}},
	url = {http://arxiv.org/abs/1609.05807},
	doi = {10.48550/arXiv.1609.05807},
	abstract = {Recent discussion in the public sphere about algorithmic classification has involved tension between competing notions of what it means for a probabilistic classification to be fair to different groups. We formalize three fairness conditions that lie at the heart of these debates, and we prove that except in highly constrained special cases, there is no method that can satisfy these three conditions simultaneously. Moreover, even satisfying all three conditions approximately requires that the data lie in an approximate version of one of the constrained special cases identified by our theorem. These results suggest some of the ways in which key notions of fairness are incompatible with each other, and hence provide a framework for thinking about the trade-offs between them.},
	urldate = {2024-06-25},
	publisher = {arXiv},
	author = {Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
	month = nov,
	year = {2016},
	note = {arXiv:1609.05807 [cs, stat]},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/matthewgordon/Zotero/storage/6S67CZET/Kleinberg et al. - 2016 - Inherent Trade-Offs in the Fair Determination of R.pdf:application/pdf;arXiv.org Snapshot:/Users/matthewgordon/Zotero/storage/A3V6QSP8/1609.html:text/html},
}


@article{torchiana_improving_2023,
	title = {Improving {Estimates} of {Transitions} from {Satellite} {Data}: {A} {Hidden} {Markov} {Model} {Approach}},
	issn = {0034-6535},
	shorttitle = {Improving {Estimates} of {Transitions} from {Satellite} {Data}},
	url = {https://doi.org/10.1162/rest_a_01301},
	doi = {10.1162/rest_a_01301},
	abstract = {Satellite-based image classification facilitates low-cost measurement of the Earth's surface composition. However, misclassified imagery can lead to misleading conclusions about transition processes. We propose a correction for transition rate estimates based on the econometric measurement error literature to extract the signal (truth) from its noisy measurement (satellite-based classifications). No ground-truth data is required in the implementation. Our proposed correction produces consistent estimates of transition rates, confirmed by longitudinal validation data, while transition rates without correction are severely biased. Using our approach, we show how eliminating deforestation in Brazil's Atlantic forest region through 2040 could save \$100 billion in CO2 emissions.},
	urldate = {2024-06-25},
	journal = {The Review of Economics and Statistics},
	author = {Torchiana, Adrian L. and Rosenbaum, Ted and Scott, Paul T. and Souza-Rodrigues, Eduardo},
	month = mar,
	year = {2023},
	pages = {1--45},
	file = {Submitted Version:/Users/matthewgordon/Zotero/storage/4LBPPSSG/Torchiana et al. - 2023 - Improving Estimates of Transitions from Satellite .pdf:application/pdf},
}


@article{burgess_political_2012,
	title = {The {Political} {Economy} of {Deforestation} in the {Tropics}*},
	volume = {127},
	issn = {0033-5533},
	url = {https://doi.org/10.1093/qje/qjs034},
	doi = {10.1093/qje/qjs034},
	abstract = {Tropical deforestation accounts for almost one-fifth of greenhouse gas emissions and threatens the world’s most diverse ecosystems. Much of this deforestation is driven by illegal logging. We use novel satellite data that tracks annual deforestation across eight years of Indonesian institutional change to examine how local officials’ incentives affect deforestation. Increases in the number of political jurisdictions lead to increased deforestation and lower timber prices, consistent with Cournot competition between jurisdictions. Illegal logging and local oil and gas rents are short-run substitutes, but this effect disappears over time with political turnover. The results illustrate how local officials’ incentives affect deforestation and show how standard economic theories can explain illegal behavior.},
	number = {4},
	urldate = {2024-06-24},
	journal = {The Quarterly Journal of Economics},
	author = {Burgess, Robin and Hansen, Matthew and Olken, Benjamin A. and Potapov, Peter and Sieber, Stefanie},
	month = nov,
	year = {2012},
	pages = {1707--1754},
	file = {Full Text:/Users/matthewgordon/Zotero/storage/ELGE9PXH/Burgess et al. - 2012 - The Political Economy of Deforestation in the Trop.pdf:application/pdf;Snapshot:/Users/matthewgordon/Zotero/storage/PI923R9E/1844248.html:text/html},
}

@misc{jack_money_2022,
	type = {Working {Paper}},
	series = {Working {Paper} {Series}},
	title = {Money ({Not}) to {Burn}: {Payments} for {Ecosystem} {Services} to {Reduce} {Crop} {Residue} {Burning}},
	shorttitle = {Money ({Not}) to {Burn}},
	url = {https://www.nber.org/papers/w30690},
	doi = {10.3386/w30690},
	abstract = {Particulate matter significantly reduces life expectancy in India. We use a randomized controlled trial in the Indian state of Punjab to evaluate the effectiveness of conditional cash transfers (also known as payments for ecosystem services, or PES) in reducing crop residue burning, which is a major contributor to the region’s poor air quality. Credit constraints and distrust may make farmers less likely to comply with standard PES contracts, which only pay the participant after verification of compliance. We randomize paying a portion of the money upfront and unconditionally. Despite receiving a lower reward for compliance, farmers offered partial upfront payment are 8-12 percentage points more likely to comply than are farmers offered the standard contract. Burning measures derived from satellite imagery indicate that PES with upfront payments significantly reduced burning, while standard PES payments were inframarginal. We also show that PES with an upfront component is a cost-effective way to improve India’s air quality.},
	urldate = {2024-06-24},
	publisher = {National Bureau of Economic Research},
	author = {Jack, B. Kelsey and Jayachandran, Seema and Kala, Namrata and Pande, Rohini},
	month = nov,
	year = {2022},
	doi = {10.3386/w30690},
	file = {Full Text PDF:/Users/matthewgordon/Zotero/storage/EU2R8CMM/Jack et al. - 2022 - Money (Not) to Burn Payments for Ecosystem Servic.pdf:application/pdf},
}

@article{asher_ecological_2020,
	title = {The {Ecological} {Impact} of {Transportation} {Infrastructure}},
	volume = {130},
	issn = {0013-0133},
	url = {https://doi.org/10.1093/ej/ueaa013},
	doi = {10.1093/ej/ueaa013},
	abstract = {There is a long-standing debate over whether new roads unavoidably lead to environmental damage, especially forest loss, but causal identification has been elusive. Using multiple causal identification strategies, we study the construction of new rural roads to over 100,000 villages and the upgrading of 10,000 kilometers of national highways in India. The new rural roads had precisely zero effect on local deforestation. In contrast, the highway upgrades caused substantial forest loss, which appears to be driven by increased timber demand along the transportation corridors. In terms of forests, last mile connectivity had a negligible environmental cost, while expansion of major corridors had important environmental impacts.},
	number = {629},
	urldate = {2024-06-24},
	journal = {The Economic Journal},
	author = {Asher, Sam and Garg, Teevrat and Novosad, Paul},
	month = jul,
	year = {2020},
	pages = {1173--1199},
	file = {Snapshot:/Users/matthewgordon/Zotero/storage/CR8YPNUE/5798996.html:text/html;Submitted Version:/Users/matthewgordon/Zotero/storage/ENKUGAYC/Asher et al. - 2020 - The Ecological Impact of Transportation Infrastruc.pdf:application/pdf},
}

@article{alix-garcia_ecological_2013,
	title = {The {Ecological} {Footprint} of {Poverty} {Alleviation}: {Evidence} from {Mexico}'s {Oportunidades} {Program}},
	volume = {95},
	issn = {0034-6535},
	shorttitle = {The {Ecological} {Footprint} of {Poverty} {Alleviation}},
	url = {https://doi.org/10.1162/REST_a_00349},
	doi = {10.1162/REST_a_00349},
	abstract = {We study the consequences of poverty-alleviation programs for environmental degradation. We exploit the community-level eligibility discontinuity for a conditional cash transfer program in Mexico to identify the impacts of income increases on deforestation and use the program's initial randomized rollout to explore household responses. We find that additional income raises consumption of land-intensive goods and increases deforestation. The observed production response and deforestation increase are larger in communities with poor road infrastructure. This suggests that better access to markets disperses environmental harm and that the full effects of poverty alleviation on the environment can be observed only where poor infrastructure localizes them.},
	number = {2},
	urldate = {2024-06-24},
	journal = {The Review of Economics and Statistics},
	author = {Alix-Garcia, Jennifer and McIntosh, Craig and Sims, Katharine R. E. and Welch, Jarrod R.},
	month = may,
	year = {2013},
	pages = {417--435},
	file = {Full Text:/Users/matthewgordon/Zotero/storage/IDZQNGBN/Alix-Garcia et al. - 2013 - The Ecological Footprint of Poverty Alleviation E.pdf:application/pdf},
}


@article{guo_global_2022,
	title = {A global forest reference set with time series annual change information from 2000 to 2020},
	volume = {43},
	issn = {0143-1161},
	url = {https://doi.org/10.1080/01431161.2022.2088256},
	doi = {10.1080/01431161.2022.2088256},
	abstract = {Mapping and monitoring forest with time-series remote sensing methodologies requires reference data constructed in a sampling framework. Few worldwide reference data sets with time-series information are currently available for large areas. We produced a global forest reference set at 30 m with time-series information from 2000 to 2020 based on a stratified random sampling scheme. All available Landsat, high-resolution Google Earth images and other relative land cover/land change products were used in a visual interpretation approach. This reference dataset contains 10339 sample units (6252 persisting forest sample units, 2049 change sample units and 2038 persisting non-forest sample units) attributed with annual forest/non-forest information from 2000 to 2020. The results of our analysis highlight many cases of undetected forest change due to definition and other factors, and suggest that change of forest canopy cover could be monitored instead of land cover types. The reference set can be potentially used for many large-area applications such as validation of forest mapping projects or as auxiliary data for forest monitoring analysis. And this reference set will be available online (https://doi.org/10.5281/zenodo.5524258).},
	number = {9},
	urldate = {2024-06-09},
	journal = {International Journal of Remote Sensing},
	author = {Guo, Jing and Zhu, Zhiliang and Gong, Peng},
	month = may,
	year = {2022},
	keywords = {Forest, forest change, Landsat, stratified sample, time series images},
	pages = {3152--3162},
}


@misc{kallus_role_2024,
	title = {On the role of surrogates in the efficient estimation of treatment effects with limited outcome data},
	url = {http://arxiv.org/abs/2003.12408},
	abstract = {In many experiments and observational studies, the outcome of interest is often difficult or expensive to observe, reducing effective sample sizes for estimating average treatment effects (ATEs) even when identifiable. We study how incorporating data on units for which only surrogate outcomes not of primary interest are observed can increase the precision of ATE estimation. We refrain from imposing stringent surrogacy conditions, which permit surrogates as perfect replacements for the target outcome. Instead, we supplement the available, albeit limited, observations of the target outcome (which by themselves identify the ATE) with abundant observations of surrogate outcomes, without any assumptions beyond random assignment and missingness and corresponding overlap conditions. To quantify the potential gains, we derive the difference in efficiency bounds on ATE estimation with and without surrogates, both when an overwhelming or comparable number of units have missing outcomes. We develop robust ATE estimation and inference methods that realize these efficiency gains. We empirically demonstrate the gains by studying long-term-earning effects of job training.},
	language = {en},
	urldate = {2024-06-09},
	publisher = {arXiv},
	author = {Kallus, Nathan and Mao, Xiaojie},
	month = may,
	year = {2024},
	note = {arXiv:2003.12408 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
}


@book{hansen_robustness_2008,
	address = {Princeton},
	title = {Robustness},
	isbn = {978-0-691-17097-8 978-0-691-11442-2},
	abstract = {The authors adapt modern control theoretic techniques based on robust control theory to economic modelling and decision making. The main motivation behind the proposed approach is that concern about model misspecification in economics leads to decision strategies that work over the set of nearby models which may generate the specific set of data. The authors propose to measure discrepancies between models of this set (or in other words a quality of an approximating model) by the relative entropy and in this sense the robust control theory is not only adapted but also extended in the book. The main issues discussed in the book can be collected into six important sets of problems: 1. Formulation of discounted problems that preserve the recursive structure of decision problems (the authors seem not to know the monograph by Bertsekas and Rhodes in which such problems were discussed). 2. Representation of worst-case shock based on reformulation of misspecification perturbation to an approximating model. 3. Formulation of the role and use of multiple agents under assumption that although a common approximating model is created the agents have different interests and different concerns about robustness. 4. Interpretation of relationships between stochastic and nonstochastic models of uncertainty and resulting decision strategies. 5. Calibration of the measure of model uncertainty basing on detection of error probabilities. 6. Formulation of some robust filtering and estimation problems both in the case when a peculiar form of commitment to model distortions is chosen and when there is no commitment to the prior distortions. All ideas discussed in the book are illustrated by a variety of problems in dynamic macroeconomics. The authors concentrate on time-domain analysis and apply different techniques from dynamic noncooperative game theory to solve the formulated decision making problems. The book is self-contained and rigorous and may be interesting not only for macroeconomists who seek to improve the robustness of decision making process but also for control engineers interested in different applications of their professional abilities},
	language = {eng},
	publisher = {Princeton Univ. Press},
	author = {Hansen, Lars Peter and Sargent, Thomas J.},
	year = {2008},
	annote = {Literaturverz. S. 413 - 425},
	file = {Table of Contents PDF:/Users/mdgordo/Zotero/storage/T3TD6LJI/Hansen and Sargent - 2008 - Robustness.pdf:application/pdf},
}


@misc{liang_algorithm_2023,
	title = {Algorithm {Design}: {A} {Fairness}-{Accuracy} {Frontier}},
	shorttitle = {Algorithm {Design}},
	url = {http://arxiv.org/abs/2112.09975},
	abstract = {Algorithm designers increasingly optimize not only for accuracy, but also for the fairness of the algorithm across pre-defined groups. We study the tradeoff between fairness and accuracy for any given set of inputs to the algorithm. We propose and characterize a fairness-accuracy frontier, which consists of the optimal points across a broad range of preferences over fairness and accuracy. Our results identify a simple property of the inputs, group-balance, which qualitatively determines the shape of the frontier. We further study an information-design problem where the designer flexibly regulates the inputs (e.g., by coarsening an input or banning its use) but the algorithm is chosen by another agent. Whether it is optimal to ban an input generally depends on the designer's preferences. But when inputs are group-balanced, then excluding group identity is strictly suboptimal for all designers, and when the designer has access to group identity, then it is strictly suboptimal to exclude any informative input.},
	urldate = {2023-09-21},
	publisher = {arXiv},
	author = {Liang, Annie and Lu, Jay and Mu, Xiaosheng},
	month = jul,
	year = {2023},
	note = {arXiv:2112.09975 [econ]},
	keywords = {Economics - Theoretical Economics},
}

@article{aigner_regression_1973,
	title = {Regression with a binary independent variable subject to errors of observation},
	volume = {1},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0304407673900055},
	doi = {10.1016/0304-4076(73)90005-5},
	language = {en},
	number = {1},
	urldate = {2023-04-11},
	journal = {Journal of Econometrics},
	author = {Aigner, Dennis J.},
	month = mar,
	year = {1973},
	pages = {49--59},
}



@article{ditraglia_identifying_2019,
	title = {Identifying the effect of a mis-classified, binary, endogenous regressor},
	volume = {209},
	issn = {03044076},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407619300181},
	doi = {10.1016/j.jeconom.2019.01.007},
	language = {en},
	number = {2},
	urldate = {2023-04-11},
	journal = {Journal of Econometrics},
	author = {DiTraglia, Francis J. and García-Jimeno, Camilo},
	month = apr,
	year = {2019},
	pages = {376--390},
	file = {Submitted Version:/Users/mdgordo/Zotero/storage/EJPH5YQN/DiTraglia and García-Jimeno - 2019 - Identifying the effect of a mis-classified, binary.pdf:application/pdf},
}


@misc{padilla_compilation_2021,
	title = {Compilation of {Geospatial} {Data} ({GIS}) for the {Mineral} {Industries} and {Related} {Infrastructure} of {Africa}},
	url = {https://www.sciencebase.gov/catalog/item/607611a9d34e018b3201cbbf},
	abstract = {This geodatabase reflects the U.S. Geological Survey's (USGS) ongoing commitment to its mission of understanding the nature and distribution of global mineral commodity supply chains by updating and publishing the georeferenced locations of mineral commodity production and processing facilities, mineral exploration and development sites, and mineral commodity exporting ports in Africa. The geodatabase and geospatial data layers serve to create a new geographic information product in the form of a geospatial portable document format (PDF) map. The geodatabase contains data layers from USGS, foreign governmental, and open-source sources as follows: (1) mineral production and processing facilities, (2) mineral exploration and development sites, (3) mineral occurrence sites and deposits, (4) undiscovered mineral resource tracts for Gabon and Mauritania, (5) undiscovered mineral resource tracts for potash, platinum-group elements, and copper, (6) coal occurrence areas, (7) electric power generating facilities, (8) electric power transmission lines, (9) liquefied natural gas terminals, (10) oil and gas pipelines, (11) undiscovered, technically recoverable conventional and continuous hydrocarbon resources (by USGS geologic/petroleum province), (12) cumulative production, and recoverable conventional resources (by oil- and gas-producing nation), (13) major mineral exporting maritime ports, (14) railroads, (15) major roads, (16) major cities, (17) major lakes, (18) major river systems, (19) first-level administrative division (ADM1) boundaries for all countries in Africa, and (20) international boundaries for all countries in Africa.},
	urldate = {2023-04-06},
	publisher = {U.S. Geological Survey},
	author = {Padilla, Abraham D et al.},
	year = {2021},
	doi = {10.5066/P97EQWXP},
	note = {Type: dataset},
	keywords = {Economic Geology, Energy Resources, Geography, Information Sciences, Mineral Resources},
}

@article{maus_global-scale_2020,
	title = {Global-scale mining polygons ({Version} 1)},
	copyright = {info:eu-repo/semantics/openAccess},
	url = {https://doi.pangaea.de/10.1594/PANGAEA.910894},
	doi = {10.1594/PANGAEA.910894},
	abstract = {Maus, Victor; Giljum, Stefan; Gutschlhofer, Jakob; da Silva, Dieison M; Probst, Michael; Gass, Sidnei L B; Luckeneder, Sebastian; Lieber, Mirko; McCallum, Ian (2020): Global-scale mining polygons (Version 1). PANGAEA, https://doi.org/10.1594/PANGAEA.910894},
	language = {en},
	urldate = {2023-04-06},
	author = {Maus, Victor and Giljum, Stefan and Gutschlhofer, Jakob and da Silva, Dieison M. and Probst, Michael and Gass, Sidnei L. B. and Luckeneder, Sebastian and Lieber, Mirko and McCallum, Ian},
	month = jan,
	year = {2020},
	note = {Publisher: PANGAEA
Type: dataset},
	file = {Snapshot:/Users/mdgordo/Zotero/storage/3SW5VFPK/PANGAEA.html:text/html},
}



@data{DVN/H8SFD2_2019,
author = {The Growth Lab at Harvard University},
publisher = {Harvard Dataverse},
title = {{International Trade Data (SITC, Rev. 2)}},
UNF = {UNF:6:wyfe4C4khU8K83BuJzRgcA==},
year = {2019},
version = {V6},
doi = {10.7910/DVN/H8SFD2},
url = {https://doi.org/10.7910/DVN/H8SFD2}
}

@article{yeh2020using,
    author = {Yeh, Christopher and Perez, Anthony and Driscoll, Anne and Azzari, George and Tang, Zhongyi and Lobell, David and Ermon, Stefano and Burke, Marshall},
    day = {22},
    doi = {10.1038/s41467-020-16185-w},
    issn = {2041-1723},
    journal = {Nature Communications},
    month = {5},
    number = {1},
    title = {{Using publicly available satellite imagery and deep learning to understand economic well-being in Africa}},
    url = {https://www.nature.com/articles/s41467-020-16185-w},
    volume = {11},
    year = {2020}
}

@misc{chernozhukov_adversarial_2020,
	title = {Adversarial {Estimation} of {Riesz} {Representers}},
	url = {http://arxiv.org/abs/2101.00009},
	abstract = {We provide an adversarial approach to estimating Riesz representers of linear functionals within arbitrary function spaces. We prove oracle inequalities based on the localized Rademacher complexity of the function space used to approximate the Riesz representer and the approximation error. These inequalities imply fast finite sample mean-squared-error rates for many function spaces of interest, such as high-dimensional sparse linear functions, neural networks and reproducing kernel Hilbert spaces. Our approach offers a new way of estimating Riesz representers with a plethora of recently introduced machine learning techniques. We show how our estimator can be used in the context of de-biasing structural/causal parameters in semi-parametric models, for automated orthogonalization of moment equations and for estimating the stochastic discount factor in the context of asset pricing.},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Chernozhukov, Victor and Newey, Whitney and Singh, Rahul and Syrgkanis, Vasilis},
	month = dec,
	year = {2020},
	note = {arXiv:2101.00009 [cs, econ, stat]},
	keywords = {Computer Science - Machine Learning, Economics - Econometrics, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/mdgordo/Zotero/storage/SWXYZLQF/Chernozhukov et al. - 2020 - Adversarial Estimation of Riesz Representers.pdf:application/pdf;arXiv.org Snapshot:/Users/mdgordo/Zotero/storage/4MYDLKU4/2101.html:text/html},
}


@article{giljum_pantropical_2022,
	title = {A pantropical assessment of deforestation caused by industrial mining},
	volume = {119},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.2118273119},
	doi = {10.1073/pnas.2118273119},
	abstract = {Growing demand for minerals continues to drive deforestation worldwide. Tropical forests are particularly vulnerable to the environmental impacts of mining and mineral processing. Many local- to regional-scale studies document extensive, long-lasting impacts of mining on biodiversity and ecosystem services. However, the full scope of deforestation induced by industrial mining across the tropics is yet unknown. Here, we present a biome-wide assessment to show where industrial mine expansion has caused the most deforestation from 2000 to 2019. We find that 3,264 km2 of forest was directly lost due to industrial mining, with 80\% occurring in only four countries: Indonesia, Brazil, Ghana, and Suriname. Additionally, controlling for other nonmining determinants of deforestation, we find that mining caused indirect forest loss in two-thirds of the investigated countries. Our results illustrate significant yet unevenly distributed and often unmanaged impacts on these biodiverse ecosystems. Impact assessments and mitigation plans of industrial mining activities must address direct and indirect impacts to support conservation of the world’s tropical forests.},
	number = {38},
	urldate = {2023-04-05},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Giljum, Stefan and Maus, Victor and Kuschnig, Nikolas and Luckeneder, Sebastian and Tost, Michael and Sonter, Laura J. and Bebbington, Anthony J.},
	month = sep,
	year = {2022},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2118273119},
	file = {Full Text PDF:/Users/mdgordo/Zotero/storage/GA95IN5Q/Giljum et al. - 2022 - A pantropical assessment of deforestation caused b.pdf:application/pdf},
}


@misc{metzger_adversarial_2022,
	title = {Adversarial {Estimators}},
	url = {http://arxiv.org/abs/2204.10495},
	abstract = {We develop an asymptotic theory of adversarial estimators ('A-estimators'). They generalize maximum-likelihood-type estimators ('M-estimators') as their average objective is maximized by some parameters and minimized by others. This class subsumes the continuous-updating Generalized Method of Moments, Generative Adversarial Networks and more recent proposals in machine learning and econometrics. In these examples, researchers state which aspects of the problem may in principle be used for estimation, and an adversary learns how to emphasize them optimally. We derive the convergence rates of A-estimators under pointwise and partial identification, and the normality of functionals of their parameters. Unknown functions may be approximated via sieves such as deep neural networks, for which we provide simplified low-level conditions. As a corollary, we obtain the normality of neural-net M-estimators, overcoming technical issues previously identified by the literature. Our theory yields novel results about a variety of A-estimators, providing intuition and formal justification for their success in recent applications.},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Metzger, Jonas},
	month = jun,
	year = {2022},
	note = {arXiv:2204.10495 [cs, econ, math, stat]},
	keywords = {Computer Science - Machine Learning, Economics - Econometrics, Mathematics - Statistics Theory, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/mdgordo/Zotero/storage/88METZX6/Metzger - 2022 - Adversarial Estimators.pdf:application/pdf;arXiv.org Snapshot:/Users/mdgordo/Zotero/storage/EDLRL7A9/2204.html:text/html},
}

@misc{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1406.2661},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	month = jun,
	year = {2014},
	note = {arXiv:1406.2661 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/mdgordo/Zotero/storage/KL4G73W8/Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/mdgordo/Zotero/storage/2P86NZB5/1406.html:text/html},
}

@misc{chernozhukov_automatic_2021,
	title = {Automatic {Debiased} {Machine} {Learning} via {Neural} {Nets} for {Generalized} {Linear} {Regression}},
	url = {http://arxiv.org/abs/2104.14737},
	abstract = {We give debiased machine learners of parameters of interest that depend on generalized linear regressions, which regressions make a residual orthogonal to regressors. The parameters of interest include many causal and policy effects. We give neural net learners of the bias correction that are automatic in only depending on the object of interest and the regression residual. Convergence rates are given for these neural nets and for more general learners of the bias correction. We also give conditions for asymptotic normality and consistent asymptotic variance estimation of the learner of the object of interest.},
	urldate = {2023-04-05},
	publisher = {arXiv},
	author = {Chernozhukov, Victor and Newey, Whitney K. and Quintas-Martinez, Victor and Syrgkanis, Vasilis},
	month = apr,
	year = {2021},
	note = {arXiv:2104.14737 [econ, math, stat]},
	keywords = {Economics - Econometrics, Mathematics - Statistics Theory},
	file = {arXiv Fulltext PDF:/Users/mdgordo/Zotero/storage/NTB5PJEF/Chernozhukov et al. - 2021 - Automatic Debiased Machine Learning via Neural Net.pdf:application/pdf;arXiv.org Snapshot:/Users/mdgordo/Zotero/storage/MWFKKVQ8/2104.html:text/html},
}



@article{tropek_comment_2014,
	title = {Comment on “{High}-resolution global maps of 21st-century forest cover change”},
	volume = {344},
	url = {https://www.science.org/doi/10.1126/science.1248753},
	doi = {10.1126/science.1248753},
	abstract = {Hansen et al. (Reports, 15 November 2013, p. 850) published a high-resolution global forest map with detailed information on local forest loss and gain. We show that their product does not distinguish tropical forests from plantations and even herbaceous crops, which leads to a substantial underestimate of forest loss and compromises its value for local policy decisions.},
	number = {6187},
	urldate = {2023-04-05},
	journal = {Science},
	author = {Tropek, Robert and Sedláček, Ondřej and Beck, Jan and Keil, Petr and Musilová, Zuzana and Šímová, Irena and Storch, David},
	month = may,
	year = {2014},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {981--981},
}

@article{benshaul-tolonen_local_2019,
	title = {Local {Industrial} {Shocks} and {Infant} {Mortality}},
	volume = {129},
	issn = {0013-0133},
	url = {https://doi.org/10.1111/ecoj.12625},
	doi = {10.1111/ecoj.12625},
	abstract = {Local industrial development has the potential to improve health and well-being, while also damaging health through exposure to harmful pollution. It is an empirical question which of these effects dominate. Exploiting the quasi-experimental expansion of African large-scale gold mining, I find that local infant mortality rates decrease by more than 50\% alongside rapid economic growth. The instantaneous reduction is comparable to overall gains in infant survival rates in the study countries from 1970 to today. The results are robust to migration. Local industrial development – despite risk of pollution – may be an effective tool to reduce infant mortality in developing countries.},
	number = {620},
	urldate = {2023-04-05},
	journal = {The Economic Journal},
	author = {Benshaul-Tolonen, Anja},
	month = may,
	year = {2019},
	pages = {1561--1592},
	file = {Full Text PDF:/Users/mdgordo/Zotero/storage/DK6XQRE5/Benshaul-Tolonen - 2019 - Local Industrial Shocks and Infant Mortality.pdf:application/pdf},
}

@article{foster_economic_2003,
	title = {Economic {Growth} and the {Rise} of {Forests}},
	volume = {118},
	issn = {0033-5533},
	url = {https://www.jstor.org/stable/25053915},
	abstract = {Although forests have diminished globally over the past 400 years, forest cover has increased in some areas, including India in the last two decades. Aggregate time-series evidence on forest growth rates and income growth across countries and within India and a newly assembled data set that combines national household survey data, census data, and satellite images of land use in rural India at the village level over a 29-year period are used to explore the hypothesis that increases in the demand for forest products associated with income and population growth lead to forest growth. The evidence is consistent with this hypothesis, which also shows that neither the expansion of agricultural productivity nor rising wages in India Increased local forest cover.},
	number = {2},
	urldate = {2023-04-05},
	journal = {The Quarterly Journal of Economics},
	author = {Foster, Andrew D. and Rosenzweig, Mark R.},
	year = {2003},
	note = {Publisher: Oxford University Press},
	pages = {601--637},
	file = {JSTOR Full Text PDF:/Users/mdgordo/Zotero/storage/7DYKHVX5/Foster and Rosenzweig - 2003 - Economic Growth and the Rise of Forests.pdf:application/pdf},
}


@article{mullainathan_machine_2017,
	title = {Machine {Learning}: {An} {Applied} {Econometric} {Approach}},
	volume = {31},
	issn = {0895-3309},
	shorttitle = {Machine {Learning}},
	url = {https://pubs.aeaweb.org/doi/10.1257/jep.31.2.87},
	doi = {10.1257/jep.31.2.87},
	abstract = {Machines are increasingly doing “intelligent” things. Face recognition algorithms use a large dataset of photos labeled as having a face or not to estimate a function that predicts the presence y of a face from pixels x. This similarity to econometrics raises questions: How do these new empirical tools fit with what we know? As empirical economists, how can we use them? We present a way of thinking about machine learning that gives it its own place in the econometric toolbox. Machine learning not only provides new tools, it solves a different problem. Specifically, machine learning revolves around the problem of prediction, while many economic applications revolve around parameter estimation. So applying machine learning to economics requires finding relevant tasks. Machine learning algorithms are now technically easy to use: you can download convenient packages in R or Python. This also raises the risk that the algorithms are applied naively or their output is misinterpreted. We hope to make them conceptually easier to use by providing a crisper understanding of how these algorithms work, where they excel, and where they can stumble—and thus where they can be most usefully applied.},
	language = {en},
	number = {2},
	urldate = {2023-02-21},
	journal = {Journal of Economic Perspectives},
	author = {Mullainathan, Sendhil and Spiess, Jann},
	month = may,
	year = {2017},
	pages = {87--106},
	file = {Mullainathan and Spiess - 2017 - Machine Learning An Applied Econometric Approach.pdf:/Users/mdgordo/Zotero/storage/5KTVQ7L7/Mullainathan and Spiess - 2017 - Machine Learning An Applied Econometric Approach.pdf:application/pdf},
}



@article{meinshausen_quantile_nodate,
	title = {Quantile {Regression} {Forests}},
	abstract = {Random forests were introduced as a machine learning tool in Breiman (2001) and have since proven to be very popular and powerful for high-dimensional regression and classiﬁcation. For regression, random forests give an accurate approximation of the conditional mean of a response variable. It is shown here that random forests provide information about the full conditional distribution of the response variable, not only about the conditional mean. Conditional quantiles can be inferred with quantile regression forests, a generalisation of random forests. Quantile regression forests give a non-parametric and accurate way of estimating conditional quantiles for high-dimensional predictor variables. The algorithm is shown to be consistent. Numerical examples suggest that the algorithm is competitive in terms of predictive power.},
	language = {en},
	author = {Meinshausen, Nicolai},
	pages = {17},
	file = {Meinshausen - Quantile Regression Forests.pdf:/Users/mdgordo/Zotero/storage/9E7UN39X/Meinshausen - Quantile Regression Forests.pdf:application/pdf},
}

@article{jain_benefits_2020,
	title = {The {Benefits} and {Pitfalls} of {Using} {Satellite} {Data} for {Causal} {Inference}},
	volume = {14},
	issn = {1750-6816},
	url = {https://academic.oup.com/reep/article/14/1/157/5735430},
	doi = {10.1093/reep/rez023},
	abstract = {Abstract.  There has been growing interest in using satellite data in environmental economics research. This is because satellite data are available for any reg},
	language = {en},
	number = {1},
	urldate = {2020-10-30},
	journal = {Review of Environmental Economics and Policy},
	author = {Jain, Meha},
	month = jan,
	year = {2020},
	note = {Publisher: Oxford Academic},
	keywords = {bias\_in\_RS\_outcomes},
	pages = {157--169},
	file = {Jain_2020_The Benefits and Pitfalls of Using Satellite Data for Causal Inference.pdf:/Users/mdgordo/Zotero/storage/JJET2WRK/Jain_2020_The Benefits and Pitfalls of Using Satellite Data for Causal Inference.pdf:application/pdf;Snapshot:/Users/mdgordo/Zotero/storage/TS9K9WXQ/5735430.html:text/html;Snapshot:/Users/mdgordo/Zotero/storage/P4LQARS6/5735430.html:text/html},
}

@article{tuia_survey_2011,
	title = {A survey of active learning algorithms for supervised remote sensing image classification},
	volume = {5},
	issn = {1932-4553, 1941-0484},
	url = {http://arxiv.org/abs/2104.07784},
	doi = {10.1109/JSTSP.2011.2139193},
	abstract = {Defining an efficient training set is one of the most delicate phases for the success of remote sensing image classification routines. The complexity of the problem, the limited temporal and financial resources, as well as the high intraclass variance can make an algorithm fail if it is trained with a suboptimal dataset. Active learning aims at building efficient training sets by iteratively improving the model performance through sampling. A user-defined heuristic ranks the unlabeled pixels according to a function of the uncertainty of their class membership and then the user is asked to provide labels for the most uncertain pixels. This paper reviews and tests the main families of active learning algorithms: committee, large margin and posterior probability-based. For each of them, the most recent advances in the remote sensing community are discussed and some heuristics are detailed and tested. Several challenging remote sensing scenarios are considered, including very high spatial resolution and hyperspectral image classification. Finally, guidelines for choosing the good architecture are provided for new and/or unexperienced user.},
	number = {3},
	urldate = {2022-07-14},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Tuia, Devis and Volpi, Michele and Copa, Loris and Kanevski, Mikhail and Munoz-Mari, Jordi},
	month = jun,
	year = {2011},
	note = {arXiv:2104.07784 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {606--617},
	file = {arXiv Fulltext PDF:/Users/mdgordo/Zotero/storage/ARYPVCS2/Tuia et al. - 2011 - A survey of active learning algorithms for supervi.pdf:application/pdf;arXiv.org Snapshot:/Users/mdgordo/Zotero/storage/9QMPPKS7/2104.html:text/html},
}

@article{tuia_active_2009,
	title = {Active {Learning} {Methods} for {Remote} {Sensing} {Image} {Classification}},
	volume = {47},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2008.2010404},
	abstract = {In this paper, we propose two active learning algorithms for semiautomatic definition of training samples in remote sensing image classification. Based on predefined heuristics, the classifier ranks the unlabeled pixels and automatically chooses those that are considered the most valuable for its improvement. Once the pixels have been selected, the analyst labels them manually and the process is iterated. Starting with a small and nonoptimal training set, the model itself builds the optimal set of samples which minimizes the classification error. We have applied the proposed algorithms to a variety of remote sensing data, including very high resolution and hyperspectral images, using support vector machines. Experimental results confirm the consistency of the methods. The required number of training samples can be reduced to 10\% using the methods proposed, reaching the same level of accuracy as larger data sets. A comparison with a state-of-the-art active learning method, margin sampling, is provided, highlighting advantages of the methods proposed. The effect of spatial resolution and separability of the classes on the quality of the selection of pixels is also discussed.},
	number = {7},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Tuia, Devis and Ratle, FrÉdÉric and Pacifici, Fabio and Kanevski, Mikhail F. and Emery, William J.},
	month = jul,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Remote sensing, Active learning, entropy, hyperspectral imagery, Hyperspectral imaging, Hyperspectral sensors, Image classification, image information mining, Image resolution, Image sampling, Learning systems, margin sampling (MS), query learning, Spatial resolution, Support vector machine classification, Support vector machines, support vector machines (SVMs), very high resolution (VHR) imagery},
	pages = {2218--2232},
	file = {IEEE Xplore Abstract Record:/Users/mdgordo/Zotero/storage/TIH5EJVA/4812037.html:text/html;IEEE Xplore Full Text PDF:/Users/mdgordo/Zotero/storage/P43AT9U3/Tuia et al. - 2009 - Active Learning Methods for Remote Sensing Image C.pdf:application/pdf},
}

@misc{bengar_class-balanced_2021,
	title = {Class-{Balanced} {Active} {Learning} for {Image} {Classification}},
	url = {http://arxiv.org/abs/2110.04543},
	abstract = {Active learning aims to reduce the labeling effort that is required to train algorithms by learning an acquisition function selecting the most relevant data for which a label should be requested from a large unlabeled data pool. Active learning is generally studied on balanced datasets where an equal amount of images per class is available. However, real-world datasets suffer from severe imbalanced classes, the so called long-tail distribution. We argue that this further complicates the active learning process, since the imbalanced data pool can result in suboptimal classifiers. To address this problem in the context of active learning, we proposed a general optimization framework that explicitly takes class-balancing into account. Results on three datasets showed that the method is general (it can be combined with most existing active learning algorithms) and can be effectively applied to boost the performance of both informative and representative-based active learning methods. In addition, we showed that also on balanced datasets our method generally results in a performance gain.},
	urldate = {2022-07-14},
	publisher = {arXiv},
	author = {Bengar, Javad Zolfaghari and van de Weijer, Joost and Fuentes, Laura Lopez and Raducanu, Bogdan},
	month = oct,
	year = {2021},
	note = {arXiv:2110.04543 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/mdgordo/Zotero/storage/LLHQND4Q/Bengar et al. - 2021 - Class-Balanced Active Learning for Image Classific.pdf:application/pdf;arXiv.org Snapshot:/Users/mdgordo/Zotero/storage/Y5KYM9BD/2110.html:text/html},
}

@article{balboni_cycles_2021,
	title = {Cycles of {Fire}? {Politics} and {Forest} {Burning} in {Indonesia}},
	volume = {111},
	issn = {2574-0768},
	shorttitle = {Cycles of {Fire}?},
	url = {https://www.aeaweb.org/articles?id=10.1257/pandp.20211005},
	doi = {10.1257/pandp.20211005},
	abstract = {This paper examines the link between electoral incentives and environmental degradation by exploiting a satellite dataset on 107,000 forest fires and 879 asynchronous district elections in Indonesia. Fires represent a cheap but illegal means of converting forested land to other uses, but they risk burning out of control and creating substantial negative environmental externalities. We find a significant electoral cycle in forest fires. Ignitions and area burned decline during election years but steeply increase in the year after. The results suggest that politicians may suppress this activity at times when it might particularly dent their electoral chances.},
	language = {en},
	urldate = {2022-07-12},
	journal = {AEA Papers and Proceedings},
	author = {Balboni, Clare and Burgess, Robin and Heil, Anton and Old, Jonathan and Olken, Benjamin A.},
	month = may,
	year = {2021},
	keywords = {Environment, Energy, Natural Resources, Natural Disasters and Their Management, Housing, Global Warming, Formal and Informal Sectors, Infrastructure, Institutional Arrangements, Economic Development: Urban, Rural, Regional, and Transportation Analysis, Other Primary Products, Renewable Resources and Conservation: Forestry, Climate, Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior, Economic Development: Agriculture, Shadow Economy},
	pages = {415--419},
	file = {Balboni et al. - 2021 - Cycles of Fire Politics and Forest Burning in Ind.pdf:/Users/mdgordo/Zotero/storage/ZJHUJNUX/Balboni et al. - 2021 - Cycles of Fire Politics and Forest Burning in Ind.pdf:application/pdf;Snapshot:/Users/mdgordo/Zotero/storage/JXNQBQG3/articles.html:text/html},
}

@techreport{zhang_how_2021,
	type = {preprint},
	title = {How {Using} {Machine} {Learning} {Classification} as a {Variable} in {Regression} {Leads} to {Attenuation} {Bias} and {What} to {Do} {About} {It}},
	url = {https://osf.io/453jk},
	abstract = {Social scientists have increasingly been applying machine learning algorithms to  big data  to measure theoretical concepts they cannot easily measure before, and then been using these machine-predicted variables in a regression. This article  rst demonstrates that directly inserting binary predictions (i.e., classi cation) without regard for prediction error will generally lead to attenuation biases of either slope coe cients or marginal e ect estimates. We then propose four estimators to obtain consistent estimates of coe cients. The estimators require validation data, of which researchers have both machine prediction and true values. Monte Carlo simulations demonstrate the e ectiveness and robustness of the proposed estimators. We summarize the usage pattern of machine learning predictions in 18 recent publications in top social science journals, apply our proposed estimators to four of them, and o er some practical recommendations. We develop an R package CCER to help researchers use the proposed estimators.},
	language = {en},
	urldate = {2022-07-14},
	institution = {SocArXiv},
	author = {Zhang, Han},
	month = may,
	year = {2021},
	doi = {10.31235/osf.io/453jk},
	file = {Zhang - 2021 - How Using Machine Learning Classification as a Var.pdf:/Users/mdgordo/Zotero/storage/HUW7QTFB/Zhang - 2021 - How Using Machine Learning Classification as a Var.pdf:application/pdf},
}

@misc{egami_using_2023,
  title = {Using {{Large Language Model Annotations}} for {{Valid Downstream Statistical Inference}} in {{Social Science}}: {{Design-Based Semi-Supervised Learning}}},
  shorttitle = {Using {{Large Language Model Annotations}} for {{Valid Downstream Statistical Inference}} in {{Social Science}}},
  author = {Egami, Naoki and {Jacobs-Harukawa}, Musashi and Stewart, Brandon M. and Wei, Hanying},
  year = {2023},
  month = jun,
  number = {arXiv:2306.04746},
  eprint = {2306.04746},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-07-09},
  abstract = {In computational social science (CSS), researchers analyze documents to explain social and political phenomena. In most scenarios, CSS researchers first obtain labels for documents and then explain labels using interpretable regression analyses in the second step. The recent advancements in large language models (LLMs) can lower costs for CSS research by annotating documents cheaply at scale, but such surrogate labels are often imperfect and biased. We present a new algorithm for using outputs from LLMs for downstream statistical analyses while guaranteeing statistical properties\textemdash like asymptotic unbiasedness and proper uncertainty quantification\textemdash which are fundamental to CSS research. We show that direct use of LLM-predicted surrogate labels in downstream statistical analyses leads to substantial bias and invalid confidence intervals, even with high surrogate accuracy of 80\textendash 90\%. To address this, we build on debiased machine learning to propose the design-based semi-supervised learning (DSL) estimator. DSL employs a doubly-robust procedure to combine surrogate labels with a smaller number of gold-standard labels. Our approach guarantees valid inference for downstream statistical analyses, even when surrogates are arbitrarily biased, without requiring stringent assumptions, by controlling the probability of sampling documents for gold-standard labeling. Both our theoretical analysis and experimental results show that DSL provides valid statistical inference while achieving root mean squared errors comparable to existing alternatives that focus only on prediction without statistical guarantees.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/ls2375/Zotero/storage/9LRL7QRT/Egami et al. - 2023 - Using Large Language Model Annotations for Valid D.pdf}
}

@article{fong_machine_2021,
	title = {Machine {Learning} {Predictions} as {Regression} {Covariates}},
	volume = {29},
	issn = {1047-1987, 1476-4989},
	url = {https://www.cambridge.org/core/journals/political-analysis/article/machine-learning-predictions-as-regression-covariates/462A74A46A97C20A17CF640BDA72B826},
	doi = {10.1017/pan.2020.38},
	abstract = {In text, images, merged surveys, voter files, and elsewhere, data sets are often missing important covariates, either because they are latent features of observations (such as sentiment in text) or because they are not collected (such as race in voter files). One promising approach for coping with this missing data is to find the true values of the missing covariates for a subset of the observations and then train a machine learning algorithm to predict the values of those covariates for the rest. However, plugging in these predictions without regard for prediction error renders regression analyses biased, inconsistent, and overconfident. We characterize the severity of the problem posed by prediction error, describe a procedure to avoid these inconsistencies under comparatively general assumptions, and demonstrate the performance of our estimators through simulations and a study of hostile political dialogue on the Internet. We provide software implementing our approach.},
	language = {en},
	number = {4},
	urldate = {2022-07-14},
	journal = {Political Analysis},
	author = {Fong, Christian and Tyler, Matthew},
	month = oct,
	year = {2021},
	note = {Publisher: Cambridge University Press},
	keywords = {classification, inference, instrumental variables, machine learning},
	pages = {467--484},
	file = {Full Text PDF:/Users/mdgordo/Zotero/storage/VF2NLCP2/Fong and Tyler - 2021 - Machine Learning Predictions as Regression Covaria.pdf:application/pdf;Snapshot:/Users/mdgordo/Zotero/storage/VUNUSFXC/462A74A46A97C20A17CF640BDA72B826.html:text/html},
}

@article{fong_causal_2021,
	title = {Causal {Inference} with {Latent} {Treatments}},
	volume = {n/a},
	issn = {1540-5907},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12649},
	doi = {10.1111/ajps.12649},
	abstract = {Social scientists are interested in the effects of low-dimensional latent treatments within texts, such as the effect of an attack on a candidate in a political advertisement. We provide a framework for causal inference with latent treatments in high-dimensional interventions. Using this framework, we show that the randomization of texts alone is insufficient to identify the causal effects of latent treatments, because other unmeasured treatments in the text could confound the measured treatment's effect. We provide a set of assumptions that is sufficient to identify the effect of latent treatments and a set of strategies to make these assumptions more plausible, including explicitly adjusting for potentially confounding text features and nontraditional experimental designs involving many versions of the text. We apply our framework to a survey experiment and an observational study, demonstrating how our framework makes text-based causal inferences more credible.},
	language = {en},
	number = {n/a},
	urldate = {2022-07-14},
	journal = {American Journal of Political Science},
	author = {Fong, Christian and Grimmer, Justin},
	month = sep,
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12649},
	file = {Full Text PDF:/Users/mdgordo/Zotero/storage/G93SU2PE/Fong and Grimmer - Causal Inference with Latent Treatments.pdf:application/pdf},
}

@misc{zhang_mitigating_2018,
	title = {Mitigating {Unwanted} {Biases} with {Adversarial} {Learning}},
	url = {http://arxiv.org/abs/1801.07593},
	abstract = {Machine learning is a tool for building models that accurately represent input training data. When undesired biases concerning demographic groups are in the training data, well-trained models will reflect those biases. We present a framework for mitigating such biases by including a variable for the group of interest and simultaneously learning a predictor and an adversary. The input to the network X, here text or census data, produces a prediction Y, such as an analogy completion or income bracket, while the adversary tries to model a protected variable Z, here gender or zip code. The objective is to maximize the predictor's ability to predict Y while minimizing the adversary's ability to predict Z. Applied to analogy completion, this method results in accurate predictions that exhibit less evidence of stereotyping Z. When applied to a classification task using the UCI Adult (Census) Dataset, it results in a predictive model that does not lose much accuracy while achieving very close to equality of odds (Hardt, et al., 2016). The method is flexible and applicable to multiple definitions of fairness as well as a wide range of gradient-based learning models, including both regression and classification tasks.},
	urldate = {2022-07-20},
	publisher = {arXiv},
	author = {Zhang, Brian Hu and Lemoine, Blake and Mitchell, Margaret},
	month = jan,
	year = {2018},
	note = {arXiv:1801.07593 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/mdgordo/Zotero/storage/CK3I946Q/Zhang et al. - 2018 - Mitigating Unwanted Biases with Adversarial Learni.pdf:application/pdf;arXiv.org Snapshot:/Users/mdgordo/Zotero/storage/N6G2WQH5/1801.html:text/html},
}

@article{meng_estimated_2019,
	title = {Estimated {Long}-{Term} (1981–2016) {Concentrations} of {Ambient} {Fine} {Particulate} {Matter} across {North} {America} from {Chemical} {Transport} {Modeling}, {Satellite} {Remote} {Sensing}, and {Ground}-{Based} {Measurements}},
	volume = {53},
	issn = {0013-936X},
	url = {https://doi.org/10.1021/acs.est.8b06875},
	doi = {10.1021/acs.est.8b06875},
	abstract = {Accurate data concerning historical fine particulate matter (PM2.5) concentrations are needed to assess long-term changes in exposure and associated health risks. We estimated historical PM2.5 concentrations over North America from 1981 to 2016 for the first time by combining chemical transport modeling, satellite remote sensing, and ground-based measurements. We constrained and evaluated our estimates with direct ground-based PM2.5 measurements when available and otherwise with historical estimates of PM2.5 from PM10 measurements or total suspended particle (TSP) measurements. The estimated PM2.5 concentrations were generally consistent with direct ground-based PM2.5 measurements over their duration from 1988 onward (R2 = 0.6 to 0.85) and to a lesser extent with PM2.5 inferred from PM10 measurements from 1985 to 1998 (R2 = 0.5 to 0.6). The collocated comparison of the trends of population-weighted annual average PM2.5 from our estimates and ground-based measurements was highly consistent (RMSD = 0.66 μg m–3). The population-weighted annual average PM2.5 over North America decreased from 22 ± 6.4 μg m–3 in 1981, to 12 ± 3.2 μg m–3 in 1998, and to 7.9 ± 2.1 μg m–3 in 2016, with an overall trend of −0.33 μg m–3 yr–1 (95\% CI: −0.35, −0.31).},
	number = {9},
	urldate = {2022-07-27},
	journal = {Environmental Science \& Technology},
	author = {Meng, Jun and Li, Chi and Martin, Randall V. and van Donkelaar, Aaron and Hystad, Perry and Brauer, Michael},
	month = may,
	year = {2019},
	note = {Publisher: American Chemical Society},
	pages = {5071--5079},
	file = {ACS Full Text Snapshot:/Users/mdgordo/Zotero/storage/LJQYQDRG/acs.est.html:text/html;Full Text PDF:/Users/mdgordo/Zotero/storage/2E77TB7K/Meng et al. - 2019 - Estimated Long-Term (1981–2016) Concentrations of .pdf:application/pdf},
}

@article{slough_satellite-based_2021,
	title = {Satellite-based deforestation alerts with training and incentives for patrolling facilitate community monitoring in the {Peruvian} {Amazon}},
	volume = {118},
	url = {https://www.pnas.org/doi/10.1073/pnas.2015171118},
	doi = {10.1073/pnas.2015171118},
	number = {29},
	urldate = {2022-08-03},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Slough, Tara and Kopas, Jacob and Urpelainen, Johannes},
	month = jul,
	year = {2021},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2015171118},
	file = {Full Text PDF:/Users/mdgordo/Zotero/storage/7NLL85UY/Slough et al. - 2021 - Satellite-based deforestation alerts with training.pdf:application/pdf},
}

@article{slough_adoption_2021,
	title = {Adoption of community monitoring improves common pool resource management across contexts},
	volume = {118},
	url = {https://www.pnas.org/doi/10.1073/pnas.2015367118},
	doi = {10.1073/pnas.2015367118},
	number = {29},
	urldate = {2022-08-03},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Slough, Tara et al.},
	month = jul,
	year = {2021},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2015367118},
	file = {Full Text PDF:/Users/mdgordo/Zotero/storage/NWYCQ7KH/Slough et al. - 2021 - Adoption of community monitoring improves common p.pdf:application/pdf},
}

@article{wren-lewis_formalizing_2020,
	title = {Formalizing land rights can reduce forest loss: {Experimental} evidence from {Benin}},
	volume = {6},
	issn = {2375-2548},
	shorttitle = {Formalizing land rights can reduce forest loss},
	doi = {10.1126/sciadv.abb6914},
	abstract = {Many countries are formalizing customary land rights systems with the aim of improving agricultural productivity and facilitating community forest management. This paper evaluates the impact on tree cover loss of the first randomized control trial of such a program. Around 70,000 landholdings were demarcated and registered in randomly chosen villages in Benin, a country with a high rate of deforestation driven by demand for agricultural land. We estimate that the program reduced the area of forest loss in treated villages, with no evidence of anticipatory deforestation or negative spillovers to other areas. Surveys indicate that possible mechanisms include an increase in tenure security and an improvement in the effectiveness of community forest management. Overall, our results suggest that formalizing customary land rights in rural areas can be an effective way to reduce forest loss while improving agricultural investments.},
	language = {eng},
	number = {26},
	journal = {Science Advances},
	author = {Wren-Lewis, Liam and Becerra-Valbuena, Luis and Houngbedji, Kenneth},
	month = jun,
	year = {2020},
	pmid = {32637624},
	pmcid = {PMC7319749},
	keywords = {Conservation of Natural Resources, Forests, Trees, Agriculture, Benin},
	pages = {eabb6914},
	file = {Full Text:/Users/mdgordo/Zotero/storage/PJXRSBK8/Wren-Lewis et al. - 2020 - Formalizing land rights can reduce forest loss Ex.pdf:application/pdf},
}

@article{henderson_measuring_2012,
	title = {Measuring {Economic} {Growth} from {Outer} {Space}},
	volume = {102},
	issn = {0002-8282},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.102.2.994},
	doi = {10.1257/aer.102.2.994},
	abstract = {We develop a statistical framework to use satellite data on night lights to augment official income growth measures. For countries with poor national income accounts, the optimal estimate of growth is a composite with roughly equal weights on conventionally measured growth and growth predicted from lights. Our estimates differ from official data by up to three percentage points annually. Using lights, empirical analyses of growth need no longer use countries as the unit of analysis; we can measure growth for sub- and supranational regions. We show, for example, that coastal areas
in sub-Saharan Africa are growing slower than the hinterland. (JEL E01, E23, O11, 047, 057)},
	language = {en},
	number = {2},
	urldate = {2022-08-03},
	journal = {American Economic Review},
	author = {Henderson, J. Vernon and Storeygard, Adam and Weil, David N.},
	month = apr,
	year = {2012},
	keywords = {Aggregate Productivity, Cross-Country Output Convergence, Comparative Studies of Countries, Environmental Accounts, Macroeconomics: Production, Macroeconomic Analyses of Economic Development, Measurement of Economic Growth, Measurement and Data on National Income and Product Accounts and Wealth},
	pages = {994--1028},
	file = {Accepted Version:/Users/mdgordo/Zotero/storage/W84A3LBC/Henderson et al. - 2012 - Measuring Economic Growth from Outer Space.pdf:application/pdf;Snapshot:/Users/mdgordo/Zotero/storage/RXC3XA59/articles.html:text/html},
}

@article{henderson_bright_2011,
	title = {A {Bright} {Idea} for {Measuring} {Economic} {Growth}},
	volume = {101},
	issn = {0002-8282},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.101.3.194},
	doi = {10.1257/aer.101.3.194},
	abstract = {The quantity of human-generated light visible from outer space reflects variation in both population density and income per capita. In this paper we explore the usefulness of the change in visible light as a measure of GDP growth. We discuss the data, and then present a statistical framework that uses lights growth to augment existing income growth measures, assuming that measurement errors in the two series are uncorrelated. For some countries with very poor income measurement, we significantly revise estimates of growth. Our technique also produces growth estimates for cities or regions where no other data are available.},
	language = {en},
	number = {3},
	urldate = {2022-08-03},
	journal = {American Economic Review},
	author = {Henderson, Vernon and Storeygard, Adam and Weil, David N.},
	month = may,
	year = {2011},
	keywords = {Aggregate Productivity, Cross-Country Output Convergence, Data Access, Macroeconomics: Production, Measurement of Economic Growth, Methodology for Collecting, Estimating, and Organizing Macroeconomic Data},
	pages = {194--199},
	file = {Accepted Version:/Users/mdgordo/Zotero/storage/P5M5TPF3/Henderson et al. - 2011 - A Bright Idea for Measuring Economic Growth.pdf:application/pdf;Snapshot:/Users/mdgordo/Zotero/storage/M6KTU548/articles.html:text/html},
}

@article{gibson_which_2021,
	title = {Which night lights data should we use in economics, and where?},
	volume = {149},
	issn = {0304-3878},
	url = {https://www.sciencedirect.com/science/article/pii/S0304387820301772},
	doi = {10.1016/j.jdeveco.2020.102602},
	abstract = {Popular DMSP night lights data are flawed by blurring, top-coding, and lack of calibration. Yet newer and better VIIRS data are rarely used in economics. We compare these two data sources for predicting GDP, especially at the second subnational level, for Indonesia, China and South Africa. The DMSP data are a poor proxy for GDP outside of cities. The gap in predictive performance between DMSP data and VIIRS data is especially apparent at lower levels of the spatial hierarchy, such as for counties, and for lower density areas. The city lights-GDP relationship is twice as noisy with DMSP data than with VIIRS data. Spatial inequality is considerably understated with DMSP data, especially for the urban sector and in higher density areas. A Pareto adjustment to correct for top-coding in DMSP data has a modest effect but still understates spatial inequality and misses key features of economic activity in big cities.},
	language = {en},
	urldate = {2022-08-03},
	journal = {Journal of Development Economics},
	author = {Gibson, John and Olivia, Susan and Boe-Gibson, Geua and Li, Chao},
	month = mar,
	year = {2021},
	keywords = {Inequality, Indonesia, Density, DMSP, Night lights, VIIRS, bias\_in\_RS\_outcomes},
	pages = {102602},
	file = {ScienceDirect Full Text PDF:/Users/mdgordo/Zotero/storage/3B7T6AFN/Gibson et al. - 2021 - Which night lights data should we use in economics.pdf:application/pdf;ScienceDirect Snapshot:/Users/mdgordo/Zotero/storage/VMSGF87N/S0304387820301772.html:text/html},
}

@article{seydgar_semi-supervised_2022,
	title = {Semi-{Supervised} {Hyperspectral} {Image} {Classification} {Using} a {Probabilistic} {Pseudo}-{Label} {Generation} {Framework}},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2022.3195924},
	abstract = {Deep neural networks (DNNs) show impressive performance for hyperspectral image (HSI) classification when abundant labeled samples are available. The problem is that HSI sample annotation is extremely costly and the budget for this task is usually limited. To reduce the reliance on labeled samples, deep semi-supervised learning (SSL), which jointly learns from labeled and unlabeled samples, has been introduced in the literature. However, learning robust and discriminative features from unlabeled data is a challenging task due to various noise effects and ambiguity of unlabeled samples. As a result, recent advances are constrained, mainly in the pre-training or warm-up stage. In this paper, we propose a deep probabilistic framework to generate reliable pseudo labels to explicitly learn discriminative features from unlabeled samples. The generated pseudo labels of our proposed framework can be fed to various DNNs to improve their generalization capacity. Our proposed framework takes only 10 labeled samples per class to represent the label set as an uncertainty-aware distribution in the latent space. The pseudo labels are then generated for those unlabeled samples whose feature values match the distribution with high probability. By performing extensive experiments on four publicly available datasets, we show that our framework can generate reliable pseudo labels to significantly improve the generalization capacity of several state-of-the-art DNNs. In addition, we introduce a new DNN for HSI classification that demonstrates outstanding accuracy results in comparison with its rivals.},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Seydgar, Majid and Rahnamayan, Shahryar and Ghamisi, Pedram and Bidgoli, Azam Asilian},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Geoscience and Remote Sensing},
	keywords = {Uncertainty, Reliability, Deep neural network (DNN), Feature extraction, Generative adversarial networks, hyperspectral image (HSI) classification, probabilistic embedding, Probabilistic logic, pseudo labeling, semi-supervised learning (SSL), Task analysis, Training},
	pages = {1--1},
	file = {IEEE Xplore Abstract Record:/Users/mdgordo/Zotero/storage/CQXG3ZEZ/9849704.html:text/html;IEEE Xplore Full Text PDF:/Users/mdgordo/Zotero/storage/64WBARSB/Seydgar et al. - 2022 - Semi-Supervised Hyperspectral Image Classification.pdf:application/pdf},
}

@article{hansen_high-resolution_2013,
	title = {High-{Resolution} {Global} {Maps} of 21st-{Century} {Forest} {Cover} {Change}},
	volume = {342},
	url = {https://www.science.org/doi/10.1126/science.1244693},
	doi = {10.1126/science.1244693},
	number = {6160},
	urldate = {2022-09-13},
	journal = {Science},
	author = {Hansen, M. C. and Potapov, P. V. and Moore, R. and Hancher, M. and Turubanova, S. A. and Tyukavina, A. and Thau, D. and Stehman, S. V. and Goetz, S. J. and Loveland, T. R. and Kommareddy, A. and Egorov, A. and Chini, L. and Justice, C. O. and Townshend, J. R. G.},
	month = nov,
	year = {2013},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {850--853},
	file = {Hansen et al_2013_High-Resolution Global Maps of 21st-Century Forest Cover Change.pdf:/Users/mdgordo/Zotero/storage/23YNLTTB/Hansen et al_2013_High-Resolution Global Maps of 21st-Century Forest Cover Change.pdf:application/pdf;hansen.sm.pdf:/Users/mdgordo/Zotero/storage/25KKZZEX/hansen.sm.pdf:application/pdf},
}

@article{bluhm_what_2022,
	title = {What {Can} {We} {Learn} from {Nighttime} {Lights} for {Small} {Geographies}? {Measurement} {Errors} and {Heterogeneous} {Elasticities}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	shorttitle = {What {Can} {We} {Learn} from {Nighttime} {Lights} for {Small} {Geographies}?},
	url = {https://www.mdpi.com/2072-4292/14/5/1190},
	doi = {10.3390/rs14051190},
	abstract = {Nighttime lights are routinely used as a proxy for economic activity when official statistics are unavailable and are increasingly applied to study the effects of shocks or policy interventions at small geographic scales. The implicit assumption is that the ability of nighttime lights to pick up changes in GDP does not depend on local characteristics of the region under investigation or the scale of aggregation. This study uses panel data on regional GDP growth from six countries, and nighttime lights from the Defense Meteorological Satellite Program (DMSP) to investigate potential nonlinearities and measurement errors in the light production function. Our results for high statistical capacity countries (the United States and Germany) show that nightlights are significantly less responsive to changes in GDP at higher baseline level of GDP, higher population densities, and for agricultural GDP. We provide evidence that these nonlinearities are too large to be caused by differences in measurement errors across regions. We find similar but noisier relationships in other high-income countries (Italy and Spain) and emerging economies (Brazil and China). We also present results for different aggregation schemes and find that the overall relationship, including the nonlinearity, is stable across regions of different shapes and sizes but becomes noisier when regions become few and large. These findings have important implications for studies using nighttime lights to evaluate the economic effects of shocks or policy interventions. On average, nighttime lights pick up changes in GDP across many different levels of aggregation, down to relatively small geographies. However, the nonlinearity we document in this paper implies that some studies may fail to detect policy-relevant effects in places where lights react little to changes in economic activity or they may mistakenly attribute this heterogeneity to the treatment effect of their independent variable of interest.},
	language = {en},
	number = {5},
	urldate = {2022-09-12},
	journal = {Remote Sensing},
	author = {Bluhm, Richard and McCord, Gordon C.},
	month = jan,
	year = {2022},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {bias\_in\_RS\_outcomes, aggregation, GDP, MAUP, nighttime lights, nonlinearity, panel data},
	pages = {1190},
	file = {Bluhm_McCord_2022_What Can We Learn from Nighttime Lights for Small Geographies.pdf:/Users/mdgordo/Zotero/storage/NQQ9G8S6/Bluhm_McCord_2022_What Can We Learn from Nighttime Lights for Small Geographies.pdf:application/pdf;Snapshot:/Users/mdgordo/Zotero/storage/DGQT83QH/htm.html:text/html},
}

@article{fowlie_bringing_2019,
	title = {Bringing {Satellite}-{Based} {Air} {Quality} {Estimates} {Down} to {Earth}},
	volume = {109},
	issn = {2574-0768},
	url = {https://www.aeaweb.org/articles?id=10.1257/pandp.20191064},
	doi = {10.1257/pandp.20191064},
	abstract = {We use state-of-the-art, satellite-based PM 2.5 data products to assess the extent to which the Environmental Protection Agency's existing, monitor-based measurements over- or underestimate true exposure to PM 2.5 pollution. Treating satellite-based estimates as truth implies a substantial number of "policy errors"—overregulating areas that are in compliance with the air quality standards and under-regulating other areas that appear to be in violation. We investigate the health implications of these apparent errors. We also highlight the importance of accounting for prediction error in satellite-based estimates. Once prediction errors are accounted for, conclusions with regards to "policy errors" become substantially more uncertain.},
	language = {en},
	urldate = {2022-09-12},
	journal = {AEA Papers and Proceedings},
	author = {Fowlie, Meredith and Rubin, Edward and Walker, Reed},
	month = may,
	year = {2019},
	keywords = {bias\_in\_RS\_outcomes, Hazardous Waste, Health Behavior, Economics of Regulation, Valuation of Environmental Effects, Air Pollution, Noise, Recycling, Environmental Economics: Government Policy, Solid Waste, Water Pollution},
	pages = {283--288},
	file = {Fowlie et al_2019_Bringing Satellite-Based Air Quality Estimates Down to Earth.pdf:/Users/mdgordo/Zotero/storage/AFGNA5NW/Fowlie et al_2019_Bringing Satellite-Based Air Quality Estimates Down to Earth.pdf:application/pdf;Snapshot:/Users/mdgordo/Zotero/storage/XHXC6PEB/articles.html:text/html},
}

@misc{garcia_conservation_2022,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Conservation {Impact} {Evaluation} {Using} {Remotely} {Sensed} {Data}},
	url = {https://papers.ssrn.com/abstract=4179782},
	doi = {10.2139/ssrn.4179782},
	abstract = {Conservation scientists are increasingly measuring the impacts of conservation interventions by applying quasiexperimental impact evaluation to remotely sensed panel data on land use change. However, these applications come with new challenges. Using Monte Carlo simulations and analytical proofs, we demonstrate that many of the panel econometric models employed for conservation impact evaluation are biased - the significance, magnitude and even direction of estimated effects from many studies are likely incorrect. These errors threaten to undermine the evidence base that underpins conservation policy adoption and design. We review the methods in this burgeoning literature and develop guidance for the design of econometric models quantifying conservation policy effectiveness.},
	language = {en},
	urldate = {2022-09-12},
	author = {Garcia, Alberto and Heilmayr, Robert},
	month = aug,
	year = {2022},
	keywords = {bias\_in\_RS\_outcomes, Conservation, Deforestation, Impact evaluation, Remote sensing},
	file = {Garcia_Heilmayr_2022_Conservation Impact Evaluation Using Remotely Sensed Data.pdf:/Users/mdgordo/Zotero/storage/6TZR6CBT/Garcia_Heilmayr_2022_Conservation Impact Evaluation Using Remotely Sensed Data.pdf:application/pdf;Snapshot:/Users/mdgordo/Zotero/storage/A3N5ZQF5/papers.html:text/html},
}

@techreport{souza-rodrigues_improving_2020,
	title = {Improving {Estimates} of {Transitions} from {Satellite} {Data}: {A} {Hidden} {Markov} {Model} {Approach}},
	shorttitle = {Improving {Estimates} of {Transitions} from {Satellite} {Data}},
	url = {https://ideas.repec.org/p/tor/tecipa/tecipa-672.html},
	abstract = {Satellite-based image classification facilitates low-cost measurement of the Earth's surface composition. However, image classification techniques can lead to misleading conclusions about transition processes (e.g., deforestation, urbanization, and industrialization). We propose a correction for transition rate estimates based on the econometric measurement error literature to extract the signal (truth) from its noisy measurement (satellite-based classifications). No ground-level truth data is required to implement the correction. Our proposed correction produces consistent estimates of transition rates, confirmed by Monte Carlo simulations and panel validation data. In contrast, transition rates without correction for misclassifications are severely biased.},
	language = {en},
	number = {tecipa-672},
	urldate = {2022-09-12},
	institution = {University of Toronto, Department of Economics},
	author = {Souza-Rodrigues, Eduardo and Torchiana, Adrian L. and Rosenbaum, Ted and Scott, Paul T.},
	month = jul,
	year = {2020},
	note = {Publication Title: Working Papers},
	keywords = {bias\_in\_RS\_outcomes, Hidden Markov Model, Land Cover, Measurement Error, Remote-Sensing Data},
	file = {Snapshot:/Users/mdgordo/Zotero/storage/X9ZQSQUF/tecipa-672.html:text/html;Souza-Rodrigues et al_2020_Improving Estimates of Transitions from Satellite Data.pdf:/Users/mdgordo/Zotero/storage/7KF8RVQQ/Souza-Rodrigues et al_2020_Improving Estimates of Transitions from Satellite Data.pdf:application/pdf},
}

@article{avelino_goldilocks_2016,
	title = {Goldilocks and the {Raster} {Grid}: {Selecting} {Scale} when {Evaluating} {Conservation} {Programs}},
	volume = {11},
	issn = {1932-6203},
	shorttitle = {Goldilocks and the {Raster} {Grid}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167945},
	doi = {10.1371/journal.pone.0167945},
	abstract = {Access to high quality spatial data raises fundamental questions about how to select the appropriate scale and unit of analysis. Studies that evaluate the impact of conservation programs have used multiple scales and areal units: from 5x5 km grids; to 30m pixels; to irregular units based on land uses or political boundaries. These choices affect the estimate of program impact. The bias associated with scale and unit selection is a part of a well-known dilemma called the modifiable areal unit problem (MAUP). We introduce this dilemma to the literature on impact evaluation and then explore the tradeoffs made when choosing different areal units. To illustrate the consequences of the MAUP, we begin by examining the effect of scale selection when evaluating a protected area in Mexico using real data. We then develop a Monte Carlo experiment that simulates a conservation intervention. We find that estimates of treatment effects and variable coefficients are only accurate under restrictive circumstances. Under more realistic conditions, we find biased estimates associated with scale choices that are both too large or too small relative to the data generating process or decision unit. In our context, the MAUP may reflect an errors in variables problem, where imprecise measures of the independent variables will bias the coefficient estimates toward zero. This problem may be pronounced at small scales of analysis. Aggregation may reduce this bias for continuous variables, but aggregation exacerbates bias when using a discrete measure of treatment. While we do not find a solution to these issues, even though treatment effects are generally underestimated. We conclude with suggestions on how researchers might navigate their choice of scale and aerial unit when evaluating conservation policies.},
	language = {en},
	number = {12},
	urldate = {2022-09-12},
	journal = {PLOS ONE},
	author = {Avelino, Andre Fernandes Tomon and Baylis, Kathy and Honey-Rosés, Jordi},
	month = dec,
	year = {2016},
	note = {Publisher: Public Library of Science},
	keywords = {Decision making, Land use, Conservation science, Forests, Trees, Deforestation, bias\_in\_RS\_outcomes, Monte Carlo method, Temperate forests},
	pages = {e0167945},
	file = {Avelino et al_2016_Goldilocks and the Raster Grid.pdf:/Users/mdgordo/Zotero/storage/F7SJTFFB/Avelino et al_2016_Goldilocks and the Raster Grid.pdf:application/pdf;Snapshot:/Users/mdgordo/Zotero/storage/R2MPMEVA/article.html:text/html},
}

@misc{ratledge_using_2021,
	type = {Working {Paper}},
	series = {Working {Paper} {Series}},
	title = {Using {Satellite} {Imagery} and {Machine} {Learning} to {Estimate} the {Livelihood} {Impact} of {Electricity} {Access}},
	url = {https://www.nber.org/papers/w29237},
	doi = {10.3386/w29237},
	abstract = {In many regions of the world, sparse data on key economic outcomes inhibits the development, targeting, and evaluation of public policy. We demonstrate how advancements in satellite imagery and machine learning can help ameliorate these data and inference challenges. In the context of an expansion of the electrical grid across Uganda, we show how a combination of satellite imagery and computer vision can be used to develop local-level livelihood measurements appropriate for inferring the causal impact of electricity access on livelihoods. We then show how ML-based inference techniques deliver more reliable estimates of the causal impact of electrification than traditional alternatives when applied to these data. We estimate that grid access improves village-level asset wealth in rural Uganda by 0.17 standard deviations, more than doubling the growth rate over our study period relative to untreated areas. Our results provide country-scale evidence on the impact of a key infrastructure investment, and provide a low-cost, generalizable approach to future policy evaluation in data sparse environments.},
	urldate = {2022-09-12},
	publisher = {National Bureau of Economic Research},
	author = {Ratledge, Nathan and Cadamuro, Gabriel and De la Cuesta, Brandon and Stigler, Matthieu and Burke, Marshall},
	month = sep,
	year = {2021},
	doi = {10.3386/w29237},
	keywords = {bias\_in\_RS\_outcomes},
	file = {Ratledge et al_2021_Using Satellite Imagery and Machine Learning to Estimate the Livelihood Impact.pdf:/Users/mdgordo/Zotero/storage/FQVP9US2/Ratledge et al_2021_Using Satellite Imagery and Machine Learning to Estimate the Livelihood Impact.pdf:application/pdf},
}

@article{balboni_economics_2022,
	title = {The {Economics} of {Tropical} {Deforestation}},
	url = {https://economics.mit.edu/sites/default/files/2022-09/ARE_Tropical_Deforestation-3.pdf},
	abstract = {Two factors have elevated recent academic and policy interest in tropical deforestation: first, the realization that it is a major contributor to climate change; and second, a revolution in satellitebased measurement that has revealed that it is proceeding at a rapid rate. We begin by reviewing the methodological advances that have enabled measurement of forest loss at a fine spatial resolution across the globe. We then develop a simple benchmark model of deforestation based on classic models of natural resource extraction. Extending this approach to incorporate features that characterize deforestation in developing countries—pressure for land use change, significant local and global externalities, weak property rights, and political economy constraints—provides us with a framework for reviewing the fast-growing empirical literature on the economics of deforestation in the tropics. This combination of theory and empirics provides insights not only into the economic drivers and impacts of tropical deforestation but also into policies that may affect its progression. We conclude by identifying areas where more work is needed in this important body of research.},
	language = {en},
	urldate = {2022-09-12},
	journal = {Working Paper},
	author = {Balboni, Claire and Berman, Aaron and Burgess, Robin and Olken, Benjamin},
	year = {2022},
	file = {Barbier and Burgess - 2002 - The Economics of Tropical Deforestation.pdf:/Users/mdgordo/Zotero/storage/LP4AWNHF/Barbier and Burgess - 2002 - The Economics of Tropical Deforestation.pdf:application/pdf},
}

@article{bastin_extent_2017,
	title = {The extent of forest in dryland biomes},
	volume = {356},
	url = {https://www.science.org/doi/10.1126/science.aam6527},
	doi = {10.1126/science.aam6527},
	number = {6338},
	urldate = {2022-09-06},
	journal = {Science},
	author = {Bastin, Jean-François et al.},
	month = may,
	year = {2017},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {635--638},
	file = {aam6527-bastin-sm.pdf:/Users/mdgordo/Zotero/storage/VVR72VBG/aam6527-bastin-sm.pdf:application/pdf;Bastin et al_2017_The extent of forest in dryland biomes.pdf:/Users/mdgordo/Zotero/storage/6UYPMRS2/Bastin et al_2017_The extent of forest in dryland biomes.pdf:application/pdf},
}

@article{tipton_stratified_2013,
	title = {Stratified {Sampling} {Using} {Cluster} {Analysis}: {A} {Sample} {Selection} {Strategy} for {Improved} {Generalizations} {From} {Experiments}},
	volume = {37},
	issn = {0193-841X, 1552-3926},
	shorttitle = {Stratified {Sampling} {Using} {Cluster} {Analysis}},
	url = {http://journals.sagepub.com/doi/10.1177/0193841X13516324},
	doi = {10.1177/0193841X13516324},
	abstract = {Background:
              An important question in the design of experiments is how to ensure that the findings from the experiment are generalizable to a larger population. This concern with generalizability is particularly important when treatment effects are heterogeneous and when selecting units into the experiment using random sampling is not possible—two conditions commonly met in large-scale educational experiments.
            
            
              Method:
              This article introduces a model-based balanced-sampling framework for improving generalizations, with a focus on developing methods that are robust to model misspecification. Additionally, the article provides a new method for sample selection within this framework: First units in an inference population are divided into relatively homogenous strata using cluster analysis, and then the sample is selected using distance rankings.
            
            
              Result:
              In order to demonstrate and evaluate the method, a reanalysis of a completed experiment is conducted. This example compares samples selected using the new method with the actual sample used in the experiment. Results indicate that even under high nonresponse, balance is better on most covariates and that fewer coverage errors result.
            
            
              Conclusion:
              The article concludes with a discussion of additional benefits and limitations of the method.},
	language = {en},
	number = {2},
	urldate = {2022-10-18},
	journal = {Evaluation Review},
	author = {Tipton, Elizabeth},
	month = apr,
	year = {2013},
	pages = {109--139},
	file = {Tipton - 2013 - Stratified Sampling Using Cluster Analysis A Samp.pdf:/Users/mdgordo/Zotero/storage/YH9JCX9C/Tipton - 2013 - Stratified Sampling Using Cluster Analysis A Samp.pdf:application/pdf},
}

@article{knox_testing_2022,
	title = {Testing {Causal} {Theories} with {Learned} {Proxies}},
	volume = {25},
	url = {https://doi.org/10.1146/annurev-polisci-051120-111443},
	doi = {10.1146/annurev-polisci-051120-111443},
	abstract = {Social scientists commonly use computational models to estimate proxies of unobserved concepts, then incorporate these proxies into subsequent tests of their theories. The consequences of this practice, which occurs in over two-thirds of recent computational work in political science, are underappreciated. Imperfect proxies can reflect noise and contamination from other concepts, producing biased point estimates and standard errors. We demonstrate how analysts can use causal diagrams to articulate theoretical concepts and their relationships to estimated proxies, then apply straightforward rules to assess which conclusions are rigorously supportable. We formalize and extend common heuristics for “signing the bias”—a technique for reasoning about unobserved confounding—to scenarios with imperfect proxies. Using these tools, we demonstrate how, in often-encountered research settings, proxy-based analyses allow for valid tests for the existence and direction of theorized effects. We conclude with best-practice recommendations for the rapidly growing literature using learned proxies to test causal theories.},
	number = {1},
	urldate = {2022-10-19},
	journal = {Annual Review of Political Science},
	author = {Knox, Dean and Lucas, Christopher and Cho, Wendy K. Tam},
	year = {2022},
	note = {\_eprint: https://doi.org/10.1146/annurev-polisci-051120-111443},
	keywords = {causal inference, machine learning, measurement, proxies, supervised learning},
	pages = {419--441},
	file = {Knox et al_2022_Testing Causal Theories with Learned Proxies.pdf:/Users/mdgordo/Zotero/storage/KZ5CUJMJ/Knox et al_2022_Testing Causal Theories with Learned Proxies.pdf:application/pdf},
}

@article{ordway_mapping_2022,
	title = {Mapping tropical forest functional variation at satellite remote sensing resolutions depends on key traits},
	volume = {3},
	copyright = {2022 The Author(s)},
	issn = {2662-4435},
	url = {https://www.nature.com/articles/s43247-022-00564-w},
	doi = {10.1038/s43247-022-00564-w},
	abstract = {Although tropical forests differ substantially in form and function, they are often represented as a single biome in global change models, hindering understanding of how different tropical forests will respond to environmental change. The response of the tropical forest biome to environmental change is strongly influenced by forest type. Forest types differ based on functional traits and forest structure, which are readily derived from high resolution airborne remotely sensed data. Whether the spatial resolution of emerging satellite-derived hyperspectral data is sufficient to identify different tropical forest types is unclear. Here, we resample airborne remotely sensed forest data at spatial resolutions relevant to satellite remote sensing (30 m) across two sites in Malaysian Borneo. Using principal component and cluster analysis, we derive and map seven forest types. We find ecologically relevant variations in forest type that correspond to substantial differences in carbon stock, growth, and mortality rate. We find leaf mass per area and canopy phosphorus are critical traits for distinguishing forest type. Our findings highlight the importance of these parameters for accurately mapping tropical forest types using space borne observations.},
	language = {en},
	number = {1},
	urldate = {2022-10-26},
	journal = {Communications Earth \& Environment},
	author = {Ordway, Elsa M. and Asner, Gregory P. and Burslem, David F. R. P. and Lewis, Simon L. and Nilus, Reuben and Martin, Roberta E. and O’Brien, Michael J. and Phillips, Oliver L. and Qie, Lan and Vaughn, Nicholas R. and Moorcroft, Paul R.},
	month = oct,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Forest ecology, bias\_in\_RS\_outcomes, Ecosystem ecology},
	pages = {1--11},
	file = {Ordway et al_2022_Mapping tropical forest functional variation at satellite remote sensing.pdf:/Users/mdgordo/Zotero/storage/TKXQ9JHI/Ordway et al_2022_Mapping tropical forest functional variation at satellite remote sensing.pdf:application/pdf;Snapshot:/Users/mdgordo/Zotero/storage/V2ZKELJE/s43247-022-00564-w.html:text/html},
}

@article{alix-garcia_remotely_2022,
	title = {Remotely {Incorrect}? {Accounting} for {Nonclassical} {Measurement} {Error} in {Satellite} {Data} on {Deforestation}},
	issn = {2333-5955},
	shorttitle = {Remotely {Incorrect}?},
	url = {https://www.journals.uchicago.edu/doi/10.1086/723723},
	doi = {10.1086/723723},
	urldate = {2022-12-09},
	journal = {Journal of the Association of Environmental and Resource Economists},
	author = {Alix-Garcia, Jennifer and Millimet, Daniel},
	month = dec,
	year = {2022},
	note = {Publisher: The University of Chicago Press},
	file = {Alix-Garcia_Millimet_2022_Remotely Incorrect.pdf:/Users/mdgordo/Zotero/storage/LNFFDHSZ/Alix-Garcia_Millimet_2022_Remotely Incorrect.pdf:application/pdf},
}

@article{proctor_parameter_2023,
	title = {Parameter {Recovery} {Using} {Remotely} {Sensed} {Variables}},
	journal = {NBER Working Paper},
	author = {Proctor, Jonathan and Carleton, Tamma and Sum, Sandy},
	year = {2023},
	file = {w30861.pdf:/Users/mdgordo/Zotero/storage/5HS68JUK/w30861.pdf:application/pdf},
}

@article{sanford_democratization_2021,
	title = {Democratization, {Elections}, and {Public} {Goods}: {The} {Evidence} from {Deforestation}},
	volume = {n/a},
	issn = {1540-5907},
	shorttitle = {Democratization, {Elections}, and {Public} {Goods}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12662},
	doi = {10.1111/ajps.12662},
	abstract = {This article shows that over the last three decades, competitive elections were associated with increased deforestation. Protection of forested areas provides long-term public goods, while their destruction provides short-term private goods for particular voters. Politicians facing a competitive election offer voters access to forested areas mainly for small-scale farming or commercial use of timber in exchange for electoral support. I test this theory of political deforestation using satellite generated global forest cover data and the results of over 1,000 national-level elections between 1982 and 2016. I find that countries that undergo a democratic transition lose an additional 0.8 percentage points of their forest cover each year, that years with close elections have over 1 percentage point per year higher forest cover loss compared to nonelection years, and that as the margin of victory in an election decreases by 10 points, the amount of deforestation increases by 0.7 percentage points per year. These increases are on the order of 5–10 times the average rate of forest loss globally. This suggests democratization is associated with underprovision of environmental public goods and contested elections are partially responsible for this underprovision.},
	language = {en},
	number = {n/a},
	urldate = {2023-02-17},
	journal = {American Journal of Political Science},
	author = {Sanford, Luke},
	year = {2021},
	file = {Snapshot:/Users/mdgordo/Zotero/storage/P35E9ICS/ajps.html:text/html},
}

@article{meijer_global_2018,
  title = {Global Patterns of Current and Future Road Infrastructure},
  author = {Meijer, Johan R. and Huijbregts, Mark A. J. and Schotten, Kees C. G. J. and Schipper, Aafke M.},
  year = {2018},
  month = may,
  journal = {Environmental Research Letters},
  volume = {13},
  number = {6},
  pages = {064006},
  publisher = {{IOP Publishing}},
  issn = {1748-9326},
  doi = {10.1088/1748-9326/aabd42},
  urldate = {2023-06-29},
  abstract = {Georeferenced information on road infrastructure is essential for spatial planning, socio-economic assessments and environmental impact analyses. Yet current global road maps are typically outdated or characterized by spatial bias in coverage. In the Global Roads Inventory Project we gathered, harmonized and integrated nearly 60 geospatial datasets on road infrastructure into a global roads dataset. The resulting dataset covers 222 countries and includes over 21 million km of roads, which is two to three times the total length in the currently best available country-based global roads datasets. We then related total road length per country to country area, population density, GDP and OECD membership, resulting in a regression model with adjusted R2 of 0.90, and found that that the highest road densities are associated with densely populated and wealthier countries. Applying our regression model to future population densities and GDP estimates from the Shared Socioeconomic Pathway (SSP) scenarios, we obtained a tentative estimate of 3.0\textendash 4.7 million km additional road length for the year 2050. Large increases in road length were projected for developing nations in some of the world's last remaining wilderness areas, such as the Amazon, the Congo basin and New Guinea. This highlights the need for accurate spatial road datasets to underpin strategic spatial planning in order to reduce the impacts of roads in remaining pristine ecosystems.},
  langid = {english},
  file = {/Users/ls2375/Zotero/storage/C49EX6J8/Meijer et al_2018_Global patterns of current and future road infrastructure.pdf}
}
