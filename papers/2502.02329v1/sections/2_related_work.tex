\section{Related Work}

In this section, we summarize the prior studies related to our work, encompassing authoring tools for data-driven storytelling, reuse in data analysis, and LLM applications for data analysis.

\subsection{Authoring Tools for Data-driven Storytelling}

Data-driven storytelling leverages narratives and visualizations to convey data insights. 
It takes various forms, such as articles, infographics, and videos~\cite{segel2010narrative, masry2022chartqa, kang2021toonnote}.
With the growing influx of data, data-driven storytelling is gaining significant traction, making data-driven storytelling authoring an emerging research topic. 
Previous studies have discussed the workflow of authoring data-driven storytelling~\cite{li2023wherearewesofar}, which mainly consists of three stages: 
(1) \textit{analysis}, to explore the data and obtain data insights, 
(2) \textit{planning}, to prepare the core message and outline, and
(3) \textit{implementation}, to write text and create visualizations. 
This process demands advanced skills in both data analysis and storytelling, posing challenges for beginners to produce content efficiently.

To address these challenges,  researchers have developed interactive tools to aid data story authoring~\cite{kim2019datatoon}. 
While these tools alleviate the burden of manual coding and context switching, they still rely heavily on data scientists' decision-making and manual input, which can be tedious and time-consuming. 
Other authoring tools utilized algorithms or AI techniques to streamline the workflow~\cite{wang2019datashot, lu2021scrollytelling}. 
For example, Calliope~\cite{shi2020calliope} employs algorithms to automatically extract data insights and structure them into an orderly narrative. 
Specifically, some tools focus on a special data type, such as time series~\cite{shin2022roslingifier} and network data~\cite{chen2023calliopeNet}. 
These tools automate the authoring process and reduce tedious operations. 
However, they overlook the semantic information in the data, which can hinder the effective extraction of insights. 
In this study, we use existing data reports as a reference, aiming to reconstruct their analytical workflows and apply them to new datasets, thereby incorporating the semantic richness to enhance the extraction and presentation of insights.

\subsection{Reuse in Data Analysis}
Several surveys have investigated various aspects of reusing scenarios in data analysis, particularly focusing on code reuse. 
Kery and Myers~\cite{kery2017exploring} noted that data scientists commonly reuse prior code versions during data exploration, and Koenzen et al.~\cite{koenzen2020code} noted the reuse of code from online external sources. 
Ritta et al.~\cite{ritta2022reusingMyOwnCode} studied the reuse patterns of expert data scientists and highlighted the frequent reuse of common abstraction codes such as package imports and visualizations. 
Additionally, Epperson et al.~\cite{epperson2022strategiesReuseTeam} discussed the strategies for code reuse in both personal and collaborative settings, identifying challenges such as the lack of modular code.
Other studies have explored the evolution of computational notebooks during reuse~\cite{liu2023refactoring, raghunandan2023codeEvolution}. 
Based on these surveys, researchers have developed tools to facilitate code reuse, including visualizing notebook changes~\cite{eckelt2024loops}, generating documents for notebooks~\cite{wang2022documentation}, and enabling parameter passing to notebooks~\cite{papermill}. 

However, these studies primarily focus on reusing functional code snippets, such as plotting graphs or importing packages, while overlooking the reuse of data analysis ideas and frameworks.
The study most closely related to our approach is retrieve-then-adapt~\cite{qian2020retrieve}, which focuses on retrieving existing infographics as a basis for creating new ones.
In this study, inspired by the retrieve-then-adapt idea, we retrieve the reference report, identify similar analytical frameworks in it, and design a tool to leverage this similarity for reusing the reference report on new data.


\subsection{LLMs for Data Analysis}

Recent advancements in large language models (LLMs), particularly GPT-4~\cite{openai2023gpt4} and ChatGPT~\cite{chatgpt}, have shown great performance in semantic understanding and generation. 
Given appropriate prompts, these models can be utilized to perform various downstream tasks, including code generation~\cite{wang2023dataFormulator}, information gathering~\cite{suh2023Sensecape}, and web design~\cite{kim2022stylette}.
The most recent iterations of GPT models have been integrated with a Code Interpreter~\cite{codeinterpreter}, enabling them to generate and execute Python code independently. 
With these LLMs' robust performance and prompt-driven nature, researchers have begun exploring their potential in data analysis tasks. 

One of the representative directions is to generate visualizations from data and natural language queries~\cite{maddigan2023chat2vis}.
For example, LIDA~\cite{dibia2023lida} and ChartGPT~\cite{tian2024chartgpt} decomposed visualization generation into several steps and processed them sequentially.
Data Formulator~\cite{wang2023dataFormulator} employed LLMs to generate data transformation code to help data visualization. 
Other studies have applied LLMs to generate data insight narrations within charts~\cite{ying2023livecharts}. 
Furthermore, some studies have extended the use of LLMs to broader data analysis tasks, for example, generating visualizations and analysis narrations together. 
Specifically, Cheng et al.~\cite{cheng2023gpt4analyst} utilized GPT-4 to generate both visualization code and analysis narrations from data and queries, with optional Google search integration for external knowledge. 
AI Threads~\cite{hong2023aithreads} supported continuous and multi-thread conversations for progressive visualization and narration generation. 
InsightPilot~\cite{ma2023insightpilot} combines LLMs with insight search engines to explore data and generate insights automatically based on user queries. 

Similar to these studies, we consider both visualization and narration to create data reports. 
However, these studies primarily focus on generating a single visualization and narration snippet for a round of user input. 
In this study, we aim to reuse an existing report as an additional reference, thereby facilitating the generation of data reports with comprehensive narrative structures and multiple visualizations.