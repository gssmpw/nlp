

\section{Problem Formulation}

In this section, we introduce the problem formulation of \system{}. 
First, based on the retrieve-then-adapt idea~\cite{qian2020retrieve}, we discuss our approach for generating data reports by breaking it down into retrieving a related report, deducing, and reproducing a sequence of data analysis segments, each comprising analytical objectives, data processing, and insights.
Based on the formulation, we further conduct a preliminary study to understand the detailed design requirements of what can be reused from previous reports and how to rectify the new data. 
Based on the findings, we propose \system{}'s design considerations.

\subsection{Definition of Data Reports}
\label{subsec:problem_formulation}

To create a data report, data scientists need to explore and analyze the data, obtain data insights, and organize them into coherent narratives and charts~\cite{li2023wherearewesofar}. 
A shortcut for this process might be referring to an existing report and attempting to adapt it with new datasets.
To begin, it is required to retrieve a report that shares a similar topic with the current dataset.
In this section, we assume the retrieval is performed with a reliable search engine or by the users and focus on the parsing and reconstruction of the report.

Given a report, the key to its reconstruction is to decompose the report into logically coherent segments and validate whether the new data can fulfill the needs of different segments or provide similar insights supporting the argument. 
If not, how can adequate transformation of the original segments or new data be employed to make the whole process successful? 

Previous research~\cite{bar2020automatically, li2023edassistant, batch2017interactive} has outlined the analysis workflow as the three steps: 
1) Given a dataset to analyze, a data scientist usually begins by viewing the data and setting an analytical objective. 
2) Then, the data scientist would perform various data transformation steps, usually writing and executing code, and potentially encode the transformed data into a chart~\cite{wang2023dataFormulator}. 
3) Finally, the scientist inspects the results of the analysis and obtains insights into the data. 
We define an ``analysis segment''  as a triplet:
$$ segment := (objective, transformation, insight).$$

After completing an analysis segment, data scientists continue the analysis by creating new analytical objectives from previous ones, hustling to gain new insights, and generating a subsequent analysis segment. 
By repeating this process, the data scientists create a report with a complete analysis workflow and data insights. 
In this study, the segment is considered a basic building block of a data report.

Based on the definitions, we formulate the analysis workflow as a sequence of interconnected analysis segments $S = \{s_0, s_1, \cdots, s_N\}$, where $N$ is the number of segments in a data report.
Each segment $s_j$ is defined by three key components $(o_j, t_j, i_j)$, where $o_j$ is the analytical objective that guides the inquiry, $t_j$ is the data transformations that process the data, and $i_j$ is the insights that emerge from this exploration. 
Moreover, these analysis segments have interdependent dependencies $D = \{d_0, d_1, \cdots\}$, as the objective for one segment might stem from either insight of a previous segment or the data.
Each dependency $d\in D$ denotes a directed link of a tuple of segments $(s_i, s_j)$, representing that the segment $s_j$ stems from $s_i$.
In this light, the analysis workflow can be organized into a tree~\autoref{fig:formulation}a1, where each node denotes an analysis segment, and each edge denotes a dependency. 
Specifically, the initial analysis segment depends on the data. 
Based on this formulation, a data report is essentially a structural form of insights $S = \{s_0, s_1, ..., s_N\}$ distilled from these segments of analysis. 

Therefore, our method revolves around deducing and reproducing the sequence of analysis segments $S$ from the reference report, including analytical objectives, data processing, and insights. 
Finally, we organize the newly gleaned insights into a coherent and informative report, thereby reviving the original report with fresh data insights.

\begin{figure}[!htb] 
  \centering
  \includegraphics[width=0.5\linewidth]{figs/formulation.png}
  \caption{
  Producing a data report (c1) involves analyzing the data (a) and summarizing the analyzed insights into a data report (b). 
  Specifically, the data analysis workflow (a) includes a series of interdependent analysis segments (a1), each corresponding to an analytical objective, data transformation steps, and data insights (a2). 
  To reuse an existing report on a new dataset, we first deduce the data analysis workflow and reproduce it on the new data (c2). 
  }
  \label{fig:formulation}
\end{figure}

\subsection{Preliminary Study}
\label{subsec:preliminary_study_settings}

Based on the definitions, we aim to decompose a data report into segments and apply them to new data. 
However, the organization of data reports is flexible, highly depending on user preference and experiences. 
Besides, the aspects of a report that can be inherited and need adjustment remain unclear. 
To bridge this gap, we conducted a preliminary study with two main objectives:
(1) Investigate the relationship between the narrative structure of data reports and the corresponding analysis segments. 
(2) Identify the similarities and differences in analysis segments among data reports on the same topic and analyze how the differences stem from the data.

We collected data reports of different topics from well-known organizations that publish data reports, such as ONS~\cite{ons}, YouGov~\cite{yougov}, Pew Research Center~\cite{pewResearchCenter} and PPIC~\cite{ppic}. 
% \todo{based on the collected report, make a report repository. }
For the first objective, we analyzed the narrative structures of these reports to assess their alignment with our analysis segments. 

For the second objective, we observed that these organizations often publish reports on similar datasets, such as epidemic data collected at different times, typically issuing one report per dataset. 
These reports usually look similar but vary subtly in their analysis and content, which can be evidence to inspect which features are inherited and which require adjustment. 
Therefore, we further constructed 39 pairs of data reports that share the same topics and conducted pair-wise analysis on them. 
We identified the similarities and differences in each report pair and analyzed how the differences were sourced from the data. 
Treating a data report containing a series of analysis segments, including \textbf{analytical objectives}, \textbf{data transformations}, and \textbf{report content}, we summarized the patterns of similarities and differences regarding these elements.

\subsubsection{Narrative Structure of Reports}

To extract analysis segments from a report, we identified how the report's content aligns with these segments, defined as \textbf{analytical objectives}, \textbf{data transformations}, and \textbf{report content}. 
We explored whether the narrative structure could be segmented so that each part corresponds to a distinct analysis segment.

Our analysis of 35 reports showed that in most cases (32/35), the analytical content was presented as distinct segments, each focused on a single objective rather than interspersed with multiple topics, with related text and possibly a chart grouped together.
Additionally, 11 out of 35 reports included non-analytical content, such as background information, which could either supplement a specific analysis or the entire report and appeared flexibly throughout. 
Some reports (23/35) also included a summary of key insights at the beginning or end, which we excluded to concentrate on the main analytical content.

\subsubsection{Similarities and Differences in Pair Reports}

We summarize the patterns of similarities and differences between the data reports on similar topics. 
These findings lay the foundation for designing and implementing a method to reuse data reports with new data. 

\paragraph{Analytical Objectives}
Analytical objectives are guidance for the exploration of insights and findings from the data.
For example, the report of internet users~\footnote{https://www.ons.gov.uk/businessindustryandtrade/itandinternetindustry/\\bulletins/internetusers/2018} holds an analytical objective to explore the Internet use among each different age group. 
Therefore, we identified the analytical objectives in the collected reports by inspecting the aspects of the data findings that were discussed. 
After identification, we compared the analytical objectives between each pair of reports and analyzed their alignment and variations. 

As a result, all of our collected pair reports reflect similar analytical objectives.
Specifically, 34/39 of them involve analytical objectives that are exactly the same, while 35/39 of them involve slight differences.
Most slight differences source from different \textbf{data contexts and scopes}. 
For example, the analytical objectives of two data with different time ranges will also focus on distinct time frames. 
Others stem from the \textbf{dependencies to previous data insights}. 
Analytical objectives may be formed based on previous insights through logical dependencies, e.g., exploring the reason for an increasing trend. 
Therefore, the changes in previous insights may also cause adjustments in the latter objectives. 
Additionally, some pair reports involve completely different analytical objectives (18/39), which mainly source from \textbf{different data fields}. 
For example, newer data may introduce additional data fields, thus triggering new analysis objectives.
Reports may also incorporate insights from external data sources (4/39), spanning different contexts, scopes, and fields. 
These insights typically maintain a logical dependency on previously established insights, such as generalizing from local to national trends, which also introduces varied analytical objectives. 


\paragraph{Transformation Operations}
Data transformation operations are not explicitly outlined within the data reports. 
Moreover, most of the source data provided by our collected reports have been processed (34/39), making it harder to infer the specific data processing conducted. 
Nonetheless, two facets of data processing can still be discerned from the reports. 
Firstly, the reports mirror the output of the data processing, as the charts and narratives presenting data insights directly originate from these outputs.
Secondly, they also reflect detailed data processing choices, particularly regarding charts, which involve decisions on chart type, encoding, binning, etc. 

Considering these factors, we compared the content referring to similar analytical objectives between each pair of reports and analyzed their similarities and differences in analysis outputs and data processing choices. 
Consequently, we observed that similar analytical objectives always yield similar \textbf{analysis output forms}.
For example, the objective of analyzing trends always results in a chart with the temporal field on the x-axis, indicating a transformed dataset measuring variables across time periods.
However, the \textbf{detailed data processing choices} may vary to accommodate the data difference (13/39). 
Varied formats and scopes of data fields could potentially result in different chart types or levels of binning granularity to better align with visualization rules.

\paragraph{Report Content}
The report content, comprising both textual information and charts, is directly derived from the result of data processing. 
Since analysis results from different datasets naturally differ, resulting in varying values in the report content, our primary focus lies in the similarities and differences beyond mere numerical distinctions. 

As a result, regarding the similarity of report content, we observe that each pair of reports shares a similar \textbf{narrative and visual style}, such as the formality degree in tone and infographic design. 
As our main objective is to reuse the analysis workflow, the inheritance of content style is not our primary focus and is therefore not considered in this study.
The differences primarily manifest in the textual descriptions of data insights. 
Different reports may describe varying types of data insights. 
For example, one report might focus on detailing an outlier, while another might only describe overall trends. 
This difference stems essentially from \textbf{distinct analysis results}, which not only result in numerical disparities but also lead to variations in the reflected data insights.
Under the same data processing steps, one dataset may exhibit a highly significant outlier in the results, while another dataset may not.

\subsection{Expert Interview}
The findings of the preliminary study revealed that various aspects of existing data reports can be leveraged to generate new reports, but these elements require adjustments to align with the new data. 
The study also provides theoretical guidance on how to identify incompatible aspects and the directions in which adjustments should be made. 

To further understand the user requirements in reusing existing reports to analyze data, we conducted an expert interview with two experienced data analysts, EA and EB. 
EA has over two years of experience working as an actuary at an insurance company, where they frequently analyze data, organize results, and present them to clients to guide future decision-making. 
EB is a seasoned researcher in data storytelling and an experienced data journalist. 

We conducted 45-minute interviews with each expert, during which we discussed the following questions: (1) What formats do they typically use to present data analysis results, such as data reports, data stories, or others? (2) Do they encounter scenarios in which they reuse or refer to existing data analysis materials for analyzing new data and proposing new presentation materials? (3) If so, what is their workflow?

For the first two questions, EA noted that he use different formats depending on the case, including Excel files, slides, and data reports. 
He noted that for all three formats, he often refers to existing analysis materials. 
For example, to analyze and present data for a new insurance product,  he may refer to past reports or related reports from other products. 
In these cases, both the data and analysis goals are usually quite similar, making existing materials particularly useful.
EB, on the other hand, discussed the distinction between data reports and data stories. 
She pointed out that data reports are highly structured and commonly used in formal settings such as official documents, presentations, and communications. 
These reports often follow stable templates, making it easy to refer to existing materials when generating new reports. 
In contrast, EB sees data stories as a more creative format and tends not to reference previous materials. 
She prefers to avoid replicating others' approaches and focuses on originality in crafting data stories.

For the third question, Although EA acknowledged using existing materials in multiple formats, he emphasized that the aspects reused and the workflow vary depending on the format. 
For Excel files, these existing files are often with previous SQL scripts and formulas, which can be seen as preserved analysis code. 
In these cases, small modifications (e.g., updating SQL query conditions for new data) are typically sufficient. 
For data reports and slides, however, the process is different. 
These formats often lack original analysis files, and while existing materials can inspire analysis goals, chart creation, and textual descriptions, the data analysis still needs to be conducted manually.
EA further elaborated on the differences between slides and data reports. 
While slides typically feature relevant charts, they can lack detailed narrative descriptions, as slides are often presented orally. 
In contrast, data reports are expected to contain more comprehensive written content, including detailed explanations.


EA and EB further elaborated on the workflow of reusing and referring to previous data reports. 
For cases where the data fields are similar, or the analysis goals remain consistent, both EA and EB noted that these cases allow simply replacing charts with new charts and replacing the numerical conclusions to align with the new data. 
However, when the fields differ, EA mentioned that adjustments are necessary, either by modifying the analysis goals or removing irrelevant sections of the report. 
For new fields, EA would develop new analysis goals and rewrite the descriptive analysis accordingly. In cases where the insights change, the analysis may need to be entirely redone to accommodate the new findings.

\subsection{Expert Interview}

The findings of the preliminary study reveal that various aspects of existing data reports can be leveraged to generate new reports, but these elements require adjustments to align with the new data. 
The study also provides guidance on how to identify incompatible aspects and the directions in which adjustments should be made. However, it is unclear how users reuse past analysis reports for new scenarios.

Therefore, we conducted an expert interview targeted at data analysts who frequently explore new data and compose reports to communicate insights to leaders or clients. Moreover, we expected the interviewees to have certain experience in using LLMs in their analysis and prototyping process.
We interviewed two experienced data analysts, EA and EB. 
EA has over two years of experience working as an actuary at an insurance company, where they frequently analyze a variety of data, including claims history, policyholder demographics, risk factors, and market trends.
Findings are presented to a range of clients, including internal stakeholders (such as underwriters, product managers, and senior executives) and external clients (such as brokers, corporate policyholders, or regulatory bodies), to guide strategic decision-making and ensure compliance with industry standards. 
EB is an assistant professor in the Department of Journalism of a top-tier university. She also holds a Ph.D. in data science and frequently writes data journalism for news media.


We conducted 45-minute interviews with each expert, during which we raised the following questions: (1) What formats do they typically use to present data analysis results, such as slides, reports, dashboards, and spreadsheets? (2) Do they encounter scenarios in which they reuse or refer to existing data analysis materials for analyzing new data and proposing new presentation materials? (3) If so, what is their workflow?

For the first two questions, EA mentioned that he uses different formats depending on the specific case, including Excel files, slides, and data reports. He emphasized that for all three formats, he frequently refers to existing analysis materials. For instance, when analyzing and presenting data for a new insurance product, he often consults past reports or related analyses from similar products. In such cases, both the data and the analysis objectives tend to align closely, making existing materials particularly valuable for efficiency and consistency. Additionally, EA noted that reports are his primary format for conveying data insights, particularly in formal settings.
On the other hand, EB explained that her approach to data presentation is more scenario-dependent, and her use of previous materials varies accordingly. She highlighted that data reports, which are highly structured and commonly employed in formal contexts such as official documents, presentations, and communications, often follow standardized templates. This structure makes it straightforward to adapt or reference existing materials when creating new reports.
However, EB also expressed her interest in crafting ``data stories,'' which, while similar to data reports in format, are more creative and exploratory. Unlike reports, she tends to avoid relying on specific pre-existing materials for data stories, as doing so might constrain her thinking. Instead, she prioritizes originality and creativity, focusing on developing unique narratives that reflect her individual insights and perspectives.


For the third question, Although EA acknowledged using existing materials in multiple formats, he emphasized that the aspects reused and the workflow vary depending on the format. 
For Excel files, these existing files are often with previous SQL scripts and formulas, which can be seen as preserved analysis code. 
In these cases, small modifications (e.g., updating SQL query conditions for new data) are typically sufficient. 
For data reports and slides, however, the process is different. 
These formats often lack original analysis files, and while existing materials can inspire analysis goals, chart creation, and textual descriptions, the data analysis still needs to be conducted manually.
EA further elaborated on the differences between slides and data reports. 
While slides typically feature relevant charts, they can lack detailed narrative descriptions, as slides are often presented orally. 
In contrast, data reports are expected to contain more comprehensive written content, including detailed explanations.


EA and EB further elaborated on the workflow of reusing and referring to previous data reports. 
For cases where the data fields are similar, or the analysis goals remain consistent, both EA and EB noted that these cases allow simply replacing charts with new charts and replacing the numerical conclusions to align with the new data. 
However, when the fields differ, EA mentioned that adjustments are necessary, either by modifying the analysis goals or removing irrelevant sections of the report. 
For new fields, EA would develop new analysis goals and rewrite the descriptive analysis accordingly. In cases where the insights change, the analysis may need to be entirely redone to accommodate the new findings.

\subsection{Design Considerations}

Based on the problem formulation and the findings of the preliminary study, we summarize five design considerations (\textbf{C1}-\textbf{C5}) for an automatic method of reusing data reports with new data. 

\begin{enumerate}[label=\textbf{C\arabic*}]
\item \textbf{Support analytical objectives extraction, correction, and addition. } 
The key of the method is to extract and re-execute the analysis workflow of the existing report, which corresponds to a series of interdependent analytical objectives. 
To achieve this, the method should first split the report to identify distinct analysis segments and then extract the analytical objectives and their dependencies. 
Additionally, it should support smart objective correction and addition based on the dependencies and data features.

\item \textbf{Generate appropriate data processing steps automatically. } 
Based on the preliminary study, the data processing steps are not reflected directly in the existing report. 
Therefore, the method necessitates autonomous reasoning about appropriate data processing steps that yield outputs similar to those in the existing report while also making informed data processing choices adaptable to the new dataset. 

\item \textbf{Produce insightful report content derived from analysis. } 
The textual and visual content that presents data insights constitutes the primary component of a data report. 
The method should produce content that effectively presents new data insights derived from analysis. 
Our preliminary study also revealed that reports often include non-analytical content, such as background information. 
As LLMs are pre-trained on extensive background knowledge, we allow them to generate this content. 
However, any generated non-analytical content will be highlighted, as it may not always be reliable.

\item \textbf{Enable real-time output observation and report modification. } 
Given the complexity of the method, which involves analytical objectives, data processing, report content, and structure, uncertainties naturally arise, potentially leading to deviations from user expectations. 
To address this, the method should provide an interactive interface, enabling users to observe generated outputs in real-time and make necessary adjustments. This ensures that the final report aligns closely with user expectations. 

\item \textbf{Facilitate report structure organization and modification.}
Since the report is generated based on the reference report's workflow, it will naturally exhibit a similar narrative structure. 
The method should allow for re-organizing this inherited structure, including adding and generating (sub-)titles, to ensure the report is well-structured and tailored to the new content.
\end{enumerate}

Based on the design considerations, we develop an intelligent method, \system{}, to deduce and reproduce the authoring workflow of existing data reports on the new data. 
The pipeline of \system{} consists of three stages. 
\textbf{In the pre-processing stage,} \system{} recommends the most relevant reports from a built repository, ranked by similarity to the user's dataset. 
It then dissects the existing report into interconnected segments, each corresponding to the data insights of an analysis segment (\textbf{C1}). 
Based on the segmentation, it extracts the analytical objectives of each segment and deduces their dependencies (\textbf{C1}). 
\textbf{In the analysis stage,} \system{} executes each segment by reusing the information from the original report, identifying the inconsistencies, and customizing the analytical objectives, approaches, and report contents based on the new data (\textbf{C1-C3}). 
\textbf{In the organization stage,} \system{} inherits the original report structure and enables title re-generation (\textbf{C5}). 
Moreover, to enhance usability, we integrate an interactive interface for \system{}, allowing users to inspect real-time outputs, add new analytical objectives, and modify report content as needed (\textbf{C2, C5}). 


