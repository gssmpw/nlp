
\section{Flag Decomposition (FD)}\label{sec:methods}
We will now introduce our novel Flag Decomposition (FD) that, given $\D$, outputs a hierarchy-preserving flag $[\![\Q]\!]$. From this point on, $[\cdot,\cdot,\cdot]$ denotes column space and $[\cdot|\cdot|\cdot]$ block matrices. Let $\cB_i = \cA_i \setminus \cA_{i-1}$ be the difference of sets for $i=1,2,\dots, k$ and $\B_i = \D_{\cB_i}$ so that $[\D_{\cA_i}] = [\B_1,\B_2,\dots,\B_i]$. We define the permutation matrix $\bP$ so $\B = [\B_1|\B_2| \cdots | \B_k] = \D\bP$. Also, denote the projection matrix onto the null space of $[\Q_i]$ with $\Q_i \in St(m_i,n)$ as $\boldsymbol{\Pi}_{\Q_i^\perp} = \I - \Q_i\Q_i^\top$. We use $n_0 = 0$, $\cA_0 = \emptyset$, and $\boldsymbol{\Pi}_{\Q_0^\perp} = \I$. 



\begin{dfn}[Hierarchy-preserving flags]
     A flag $[\![\X]\!] \in \flag(n_1,n_2,\dots, n_k;n)$ is said to preserve the hierarchy of $\D$ if $[\D_{\cA_i}] = [\X_1,\X_2,\dots,\X_i]\,$ for each $i=1,2,\dots,k$. 
\end{dfn}

If $\mathcal{A}_1 \subset \mathcal{A}_2 \subset \cdots \subset \mathcal{A}_k$ is a column hierarchy for $\D$, then a hierarchy-preserving flag results in the three, equivalent, nested sequences of subspaces
\begin{equation*}
    \begin{matrix}
        [\D_{\cA_1}] & \subset & [\D_{\cA_2}] & \subset & \cdots & \subset & [\D_{\cA_k}]\\    
        [\B_1] & \subset & [\B_1,\B_2] & \subset & \cdots & \subset & [\B_1,\B_2, \dots,\B_k]\\
        [\X_1] & \subset & [\X_1,\X_2] & \subset & \cdots & \subset & [\X_1,\X_2,\dots,\X_k].
    \end{matrix}
\end{equation*}
SVD and QR decomposition can recover flags from data with certain, limited column hierarchies (see suppl. material for details). However, when faced with a more complex column hierarchy, both QR and SVD cannot recover the entire hierarchy-preserving flag (see~\cref{fig:flag cartoon1}).



These examples motivate a generalized decomposition of $\D$ that outputs a hierarchy-preserving flag. In particular, unlike in QR decomposition, $\D$ can be rank-deficient (\eg, $\mathrm{rank}(\D) < p$); and unlike the SVD, we can decompose into flags of type $(n_1,n_2,\dots,n_k;n)$ with $n_k \leq p$. 

\begin{figure}[t]
    \centering
    %\vspace{-4mm}
    \includegraphics[width=.95\linewidth]{figures/advantage0.pdf}
    \vspace{-1mm}
    \caption{We recover a flag from $\D$ with hierarchy $\cA_1 \subset \cA_2$. Columns of $\D$ are plotted as points with $\cA_1$ in blue and $\cA_2 \setminus \cA_1$ in orange. FD is the only method that recovers the flag (line inside plane). SVD correctly recovers the plane but not the line whereas QR only recovers the line and the plane misses the orange points.}\vspace{-4mm}
    \label{fig:flag cartoon1}
\end{figure}
\begin{dfn}[\textbf{Flag Decomposition (FD)}]
    Let $\D \in \R^{n \times p}$ be data with the hierarchically nested sequence of column indices $\cA_1 \subset \cA_2 \subset \cdots \subset \cA_k$. A flag decomposition of type $(n_1,n_2, \cdots, n_k; n)$ is the matrix factorization
    \begin{equation}
        \D = \Q \bR \bP^\top
    \end{equation}
    where the block structures are
    \begin{align}
        \Q &= [\underbrace{\Q_1}_{n \times m_1} | \underbrace{\Q_2}_{n \times m_2} | \cdots | \underbrace{\Q_k}_{n \times m_k} ] \in \R^{n \times n_k},\\
        \bR &= \begin{bmatrix}
            \bR_{11} & \bR_{12} & \cdots & \bR_{1k}\\
            \mathbf{0} & \bR_{22} & \cdots & \bR_{2k}\\
            \vdots & \vdots & \ddots & \vdots\\
            \mathbf{0} & \mathbf{0} & \cdots & \bR_{kk} \end{bmatrix} \in \R^{n_k \times p}, \\
        \bP &= [\bP_1 \,|\, \bP_2 \,|\, \cdots \,|\, \bP_k] \in \R^{p \times p}.
    \end{align}
    Here, $\Q$ corresponds to the Stiefel coordinates for the hierarchy-preserving flag $[\![\Q]\!] \in \flag(n_1,n_2,\dots, n_k;n)$ with $m_i=n_i - n_{i-1}$ and $n_k \leq p$, $\bR$ is a block upper-triangular matrix, and $\bP$ is a permutation matrix so that $\B = \D \bP$.
\end{dfn}



We now use~\cref{prop:stiefel_coords} to determine when we can recover a hierarchy-preserving flag from data and then we use~\cref{prop:proj_prop_and_flags} to show how to construct $\bR$ and $\bP$ from this flag. Finally, we combine ~\cref{prop:stiefel_coords,prop:proj_prop_and_flags} to define when we can find an FD~\cref{prop:fd_def} and investigate its uniqueness~\cref{prop:block_amb}.


\begin{prop}\label{prop:stiefel_coords}
    Suppose $\cA_1 \subset \cA_2 \subset \cdots \subset \cA_k$ is a column hierarchy for $\D$. Then there exists $\Q= [\Q_1\,|\,\Q_2\,|\, \cdots\,|\,\Q_k]$ that are coordinates for the flag $[\![\Q]\!]\in\flag(n_1,n_2,\dots,n_k;n)$ where $n_i = \mathrm{rank}(\D_{\mathcal{A}_i})$ that satisfies $[\Q_i] = [\boldsymbol{\Pi}_{\Q_{i-1}^\perp}\cdots \boldsymbol{\Pi}_{\Q_1^\perp}\B_i]$ and the \textbf{projection property} (for $i=1,2\dots,k$): 
    \begin{equation}\label{eq:projection_property}
    \boldsymbol{\Pi}_{\Q_i^\perp}\boldsymbol{\Pi}_{\Q_{i-1}^\perp}\cdots \boldsymbol{\Pi}_{\Q_1^\perp} \B_i = 0.
    \end{equation}
\end{prop}
\begin{proof}
    Define (for $i=2,3,\dots,k$) the projector onto the null space of $[\Q_1,\Q_2,\dots,\Q_i]$, as $\boldsymbol{\Pi}_{\Q_{:i}^\perp} = \I - \Q_{:i}\Q_{:i}^\top$. We use this to define $\C_i = \boldsymbol{\Pi}_{\Q_{:i-1}^\perp}\B_i$ and $\Q_i \in St(m_i,n)$ so that $[\Q_i] = [\C_i]$. Then we use mathematical induction to show results ending in ~\cref{eq:projection_property} and $\Q_i \in St(m_i,n)$ with $m_i = n_i - n_{i-1}$ where $n_i = \mathrm{rank}(\D_{\cA_i})$.
\end{proof}

The simplest methods for recovering $\Q$ so that $[\Q_i] = [\boldsymbol{\Pi}_{\Q_{i-1}^\perp}\cdots \boldsymbol{\Pi}_{\Q_1^\perp}\B_i]$ include the left singular vectors from the truncated SVD and the $\Q$ matrix from the QR decomposition with pivoting. We will now use $\Q$ and the projection property to construct $\bR$ and $\bP$ for the FD.

%for the QR decomposition with pivoting, we have $\boldsymbol{\Pi}_{\Q^\perp_{i-1}} \cdots \boldsymbol{\Pi}_{\Q^\perp_0} \B_i = \Q_i' \bR_i'{\boldsymbol{\Pi}_i'}^\top$, the columns of $\Q_i$ correspond to columns of $\Q_i'$ associated with non-zero rows of $\bR_i'$. For the case of SVD where $\boldsymbol{\Pi}_{\Q^\perp_{i-1}} \cdots \boldsymbol{\Pi}_{\Q^\perp_0} \B_i = \U_i \bm{\Sigma}_i \V_i^\top$, the columns of $\Q_i$ are the columns of $\U_i$ associated with the non-zero singular values.


%and develop an algorithm for finding it.
\begin{prop}\label{prop:proj_prop_and_flags}
 Suppose $\cA_1 \subset \cA_2 \subset \cdots \subset \cA_k$ is a column hierarchy for $\D$. Then there exists some hierarchy-preserving 
 $[\![\Q]\!] \in \flag(n_1,n_2,\dots, n_k;n)$ (with $n_i = \mathrm{rank}(\D_{\mathcal{A}_i})$) 
 that satisfies the projection property of $\D$ and can be used for a flag decomposition of $\D$ with
    \begin{align}
        \bR_{i,j} &= 
        \begin{cases}
            \Q_i^\top\boldsymbol{\Pi}_{\Q_{i-1}^\perp}\cdots \boldsymbol{\Pi}_{\Q_1^\perp} \B_i, &i=j\\
            \Q_i^\top\boldsymbol{\Pi}_{\Q_{i-1}^\perp}\cdots \boldsymbol{\Pi}_{\Q_1^\perp} \B_j, &i < j
        \end{cases},\label{eq:onlyR}\\
        \bP_i &= \left[ \,\mathbf{e}_{b_{i,1}}\,|\, \mathbf{e}_{b_{i,2}}\,|\, \cdots\,|\, \mathbf{e}_{b_{i,|\cB_i|}} \right]\label{eq:onlyP}
    \end{align}
    where $\{b_{i,j}\}_{j=1}^{|\cB_i|} = \cB_i$ and $\mathbf{e}_{b}$ is the $b_{i,j}$$^{\mathrm{th}}$ standard basis vector.
\end{prop}
\begin{proof}[Proof sketch]
    This is proved using the previous proposition.
\end{proof}

\begin{prop}\label{prop:fd_def}
    A data matrix $\D$ admits a flag decomposition of type $(n_1,n_2, \cdots, n_k; n)$ if and only if $\cA_1 \subset \cA_2 \subset \cdots \subset \cA_k$ is a column hierarchy for $\D$.
\end{prop}
\begin{proof}[Proof sketch]
    We use~\cref{prop:stiefel_coords,prop:proj_prop_and_flags} and the definition of a column hierarchy for $\D$. Details in suppl. material.
\end{proof}
\emph{Therefore, any $\D$ with an associated column hierarchy admits a hierarchy-preserving FD.} Now we state a uniqueness result for the FD.

\begin{prop}[Block rotational ambiguity]\label{prop:block_amb}
    Given the FD $\D = \Q \bR \bP^\top$, any other Stiefel coordinates for the flag $[\![\Q]\!]$ produce an FD of $\D$ (via~\cref{prop:proj_prop_and_flags}). Furthermore, different Stiefel coordinates for $[\![\Q]\!]$ produce the same objective function values in~\cref{eq:general_opt} and~\cref{eq:iterative_opt} (for $i=1,\cdots,k$).
\end{prop}
\begin{proof}[Proof sketch]
    Notice $\Q_i \Q_i^T = (\Q_i\mathbf{M}_i)  (\Q_i\mathbf{M}_i)^\top$ for any $\Q_i \in St(m_i,n)$ and $\mathbf{M}_i \in O(m_i)$. See our suppl. material for details.
\end{proof}



\subsection{Flag recovery}
In this section, we introduce an approach for recovering the FD $\D = \Q \bR \bP^\top$ from a given, corrupted version of the dataset, $\tilde{\D}$ and the column hierarchy $\cA_1 \subset \cA_2 \subset \cdots \subset \cA_k$ for $\D$. We call recovering $[\![ \Q ]\!]$ from $\tilde{\D}$ and $\cA_1 \subset \cA_2 \subset \cdots \subset \cA_k$ the \emph{flag recovery}.


Recall that any $[\![ \Q ]\!]$ satisfying the projection property of $\D$ can be used for a FD (see~\cref{prop:proj_prop_and_flags}). However, since we only have access to $\tilde{\D}$, we may not be able to satisfy this property. As a remedy, we try to get as close as possible to satisfying the projection property by optimizing for $[\![\Q]\!]$ such that $\boldsymbol{\Pi}_{\Q_i^\perp} \cdots \boldsymbol{\Pi}_{\Q_1^\perp}\tilde{\B}_i \approx \bm{0}$ for each $i=1,2,\dots,k$. We minimize this cost column-wise to solve the problem in maximum generality. Specifically, we propose the following minimization:
\begin{equation}\label{eq:general_opt}
    [\![\Q]\!] = \argmin_{[\![\X]\!] \in \flag(n_1,n_2, \dots, n_k;n)} \sum_{i=1}^k \sum_{j \in \cB_i}\| \boldsymbol{\Pi}_{\X_i^\perp} \cdots \boldsymbol{\Pi}_{\X_1^\perp} \tilde{\mathbf{d}}_j \|_r^q
\end{equation}
for $r\geq 0$, $q > 0$. Choosing small $r$ and $q$ (\eg, $r =0$ and $q=1$) would result in a robust flag recovery, optimal for recovering $\D$ in the presence of outlier columns in $\tilde{D}$. This problem is difficult, even after restricting $q$ and $r$, so we address the iterative optimization for each $\Q_i$ for $i=1$, then $i=2$, and so on until $i=k$.
\begin{equation}\label{eq:iterative_opt}
    \Q_i =  \argmin_{\X \in St(m_i,n)} \sum_{j \in \cB_j}\| \boldsymbol{\Pi}_{\X^\perp} \boldsymbol{\Pi}_{\Q^\perp_{i-1}} \cdots \boldsymbol{\Pi}_{\Q^\perp_1} \tilde{\mathbf{d}}_j \|_r^q.
\end{equation}
The solution to the case where $r=q=2$ is obtained by the first $m_i$ left singular vectors of $\boldsymbol{\Pi}_{\Q^\perp_{i-1}} \cdots \boldsymbol{\Pi}_{\Q^\perp_1} \tilde{\D}_{\mathcal{B}_j}$.
In general, solving~\cref{eq:iterative_opt} for some $i$ recovers $\Q_i$ whose columns form a basis for a $m_i$ dimensional subspace in $\R^n$.
Although outputting a truncated basis via QR with pivoting or rank-revealing QR decompositions would offer faster alternatives to SVD for solving~\cref{eq:iterative_opt}, SVD offers more reliable subspace recovery~\cite{demmel1997applied}. Thus, we use SVD-based algorithms and leave QR methods for future work.

For cases where $\tilde{\D}$ has outlier columns, we use an $L_1$ penalty, \ie, $q=1$, and introduce an \textbf{IRLS-SVD solver}\footnote{IRLS denotes iteratively reweighted least squares.}, a simple method that resembles IRLS algorithms for subspace recovery~\cite{zhang2014novel,lerman2015robust,vidal2018dpcp,lerman2018fast,lerman2018overview,garg2019subspace,mankovich2022flag}. In practice, we implement a vanilla IRLS-SVD algorithm which could further be made faster and provably convergent using tools from~\cite{aftab2014generalized,beck2015weiszfeld,kummerle2021iteratively,kummerle2021scalable,verdun2024fast}. We leave more advanced solvers, as well as working with other values of $r$ and $q$ (e.g., $r=0$~\cite{liu2012robust}), for future work.



\subsection{\algname}
We now propose~\algname, an algorithm for finding FD and its robust version, Robust FD (RFD). Our algorithm is inspired by the Block Modified Gram-Schmidt (BMGS) procedure~\cite{jalby1991stability,barlow2019block}. Modified Gram-Schmidt (MGS) is a more numerically stable implementation of the classical Gram-Schmidt orthogonalization. BMGS runs an MGS algorithm on block matrices, iteratively projecting and ortho-normalizing matrices rather than vectors, to output a QR decomposition. In contrast, we use~\algname~on a data matrix with a column hierarchy to produce a hierarchy-preserving FD. We summarize the properties of Gram-Schmidt variants in~\cref{tab:alg_table1}. 
\begin{table}[ht!]
    \centering
    \caption{A summary of GS algorithms and their properties.}
    \footnotesize
    \label{tab:alg_table1}
    \begin{tabular}{c|cccc}
        \toprule
        Algorithm & GS & MGS & BMGS & \algname \\
        \midrule
        Stable & \xmark & \cmark & \cmark & \cmark \\ 
        Block-wise & \xmark & \xmark & \cmark & \cmark \\ 
        Hier.-pres. & \xmark & \xmark & \xmark & \cmark \\ 
        \bottomrule
    \end{tabular}    
    \vspace{-4mm}
\end{table}


\algname~operates by first generating a permutation matrix $\bP$ (see~\cref{eq:onlyP}) to extract the matrix $\B = \D\bP^\top$, using the column hierarchy. Then each iteration $i=1,2,\dots,k$ constructs $\boldsymbol{\Pi}_{\Q_{i-1}^\perp}\cdots \boldsymbol{\Pi}_{\Q_1^\perp} \B_i$, solves an optimization of the form~\cref{eq:iterative_opt}, and then constructs each $\bR_{i,j}$ for $j \leq i$ (see~\cref{eq:onlyR}). In experiments, we call FD the output of~\algname~using SVD with $r=q=2$ and Robust FD (RFD) the iterative variant using $r=2$ and $q=1$ to solve~\cref{eq:iterative_opt} and algorithm details are in suppl. material.



Stability results and the search for more optimal algorithms, such as those using block Householder transformations~\cite{griem2024block} are left to future work. Many other block matrix decompositions exist and a brief discussion of such a low-rank block matrix decomposition~\cite{ong2016beyond} can be found in suppl. material.







 

\paragraph{On the flag type}
% As stated before, we may have the column hierarchy for $\D$ but only have access to a corrupted version of $\D$, namely $\tilde{\D}$. In this case, we need a method for detecting the flag type from $\tilde{\D}$.
Flag type is an input to~\algname. \emph{Detecting} or selecting an adapted flag type from data rather than relying on a heuristic choice, is recently addressed by Szwagier~\etal in principal subspace analysis~\cite{szwagier2024curseisotropyprincipalcomponents}. 
The FD model does not benefit from this advance because it preserves hierarchies rather than directions of maximum variance. We now discuss methods for estimating flag type.

%Yet, our FD model includes a block upper triangular matrix $\bR$ and does not involve a latent variable generative model. Hence, a novel method is needed to detect flag types.  

Assuming full access to $\D$, the flag type is $(n_1,n_2,\dots,n_k;n)$ where $n_i = \mathrm{rank}(\D_{\cA_i})$ (see~\cref{prop:stiefel_coords}). 
Yet, the data can be corrupted, \ie, we observe only $\tilde{\mathbf{D}} = \mathbf{D} + \bm{\epsilon}$ ($ \bm{\epsilon} $ denotes random noise) instead of the true $\D$. This leads to an estimation problem of the flag type of the FD assuming access to $\tilde{\D}$ and the true (known) column hierarchy for $\D$.     

A naive approach to address the problem of flag type estimation for our FD is to run the FD along with a singular value truncation in each SVD. Methods for truncating the SVs include the \emph{elbow} and \emph{Gavish-Dohono}~\cite{gavish2014optimal,falini2022review}. In this work, given a column hierarchy and $\tilde{\D}$ (but not $\D$) we choose a flag type where $n_k < p$ and input it to FD. In doing so, the output of FD forms a reduced-rank approximation of $\D$ denoted $\hat{\D} = \Q \bR \bP^\top$. 

A promising future research direction involves exploring smarter truncation methods for extracting the flag type of $\D$ under specific contamination criteria. 

    









