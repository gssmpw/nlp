\vspace{-1mm}\section{Preliminaries}\vspace{-1mm}\label{sec:bg}
We begin by formalizing hierarchical datasets. Then, build to a definition of flags by providing the necessary background in matrix spaces. For notation, italicized capital letters (\eg, $\cA$) denote sets, and boldface letters denote matrices and column vectors (\eg, $\mathbf{X}$ and $\mathbf{x}_i$). $[\X]$ denotes the subspace spanned by the columns of $\X$.

Consider the data matrix $\D \in \R^{n \times p}$ with a hierarchy defined by the subsets of column indices
\begin{equation}
    \emptyset = \mathcal{A}_0 \subset \mathcal{A}_1 \subset \mathcal{A}_2 \subset \cdots \subset \mathcal{A}_k = \{1,2,\dots,p\}.
\end{equation}
Let $\D_{\cA_i}$ be the matrix containing only columns of $\D$ in $\mathcal{A}_i$.
\begin{dfn}[Column hierarchy for $\D$]\label{def:col_hierarchy}
    We call $\mathcal{A}_1 \subset \mathcal{A}_2 \subset \cdots \subset \mathcal{A}_k$ a column hierarchy for $\D \in \R^{n \times p}$ when
    \begin{equation}
        \mathrm{dim}([\D_{\cA_{i-1}}]) < \mathrm{dim}([\D_{\cA_i}]) \text{ for } i=1,2,\dots,k.
    \end{equation}
\end{dfn}

Given a column hierarchy for $\D$~\footnote{A similar, complex, and well-studied notion of hierarchical matrices is H-matrices~\cite{borm2003introduction}.}, there is a natural correspondence between column and subspace hierarchies
\begin{equation*}
    \begin{matrix}
        \text{columns:} & \cA_1 & \subset & \cA_2 & \subset & \cdots & \subset & \cA_k\\
        \text{subspaces:} & [\D_{\cA_1}] & \subset & [\D_{\cA_2}] & \subset & \cdots & \subset & [\D_{\cA_k}].
    \end{matrix}
\end{equation*}
These hierarchies can include coarse-to-fine neighborhoods (\eg,~\cref{ex:pixel_hierarchy}), spectral hierarchies (\eg,~\cref{ex:spectrum_hierarchy}), and feature representations (\eg,~\cref{ex:feature_hierarchy}).
\begin{exmp}[Neighborhood Hierarchy]\label{ex:pixel_hierarchy}
    Consider $(p_i\times p_i)$ concentric RGB image patches increasing in size with $i=1,2,3$. We store the last image patch in $\D \in \R^{3 \times p_3^2}$. $\cA_1$ contains the column indices of the smallest image patch ($i=1$) in $\D$, $\cA_2$ contains those of the next smallest image patch ($i=2)$. This results in the neighborhood column hierarchy $\cA_1 \subset \cA_2 \subset \cA_3$ for the data matrix $\D$.    
\end{exmp}

\begin{exmp}[Spectral Hierarchy]\label{ex:spectrum_hierarchy}
    Let $\D \in \R^{n \times p}$ be a hyperspectral image with $n$ pixels and $p$ bands. A hierarchy is imposed on the bands by grouping wavelengths into: 
    \begin{figure}[H]
        \vspace{-4mm}
        \centering
        \includegraphics[width=\linewidth, trim = 7mm 0mm 4mm 0mm, clip]{figures/spectrum_sampling.pdf}
        \vspace{-8mm}
    \end{figure}
\end{exmp}

\begin{exmp}[Feature Hierarchy]\label{ex:feature_hierarchy}
    Consider a feature extractor (\eg, deep network) admitting the following decomposition: $f_\Theta = f^{(2)}_\Theta \circ f^{(1)}_\Theta: \R^N \rightarrow \R^{n}$ where $f^{(1)}_\Theta:\R^{N} \rightarrow \R^{n}$. $s$ samples $\bm{x}_1,\cdots,\bm{x}_s$ are used to obtain 
    \begin{equation*}
         \mathbf{D} = \left[ f^{(1)}_\Theta(\bm{x}_1)\,|\, \cdots\,|\, f^{(1)}_\Theta(\bm{x}_s)\,|\,f_\Theta(\bm{x}_1)\,|\, \cdots| f_\Theta(\bm{x}_s) \right] .
    \end{equation*}
    Since information flows from $f^{(1)}_\Theta$ to  $f^{(2)}_\Theta$, it is natural to assume that features extracted by $f^{(1)}_\Theta$ span a subspace of the features extracted by $f_{\Theta}$. Therefore, we propose the hierarchy $\{ 1,2,\dots, s\} \subset \{ 1,2,\dots,2s\}$.
\end{exmp}
    \begin{comment}
    \begin{equation*}
         \mathbf{D} = \left[ f_\Theta(\bm{x}_1)\,|\, \cdots\,|\, f_\Theta(\bm{x}_s)\,|\,f^{(2)}_\Theta(\bm{x}_1)\,|\, \cdots| f^{(2)}_\Theta(\bm{x}_s) \right] .
    \end{equation*}
    The most discriminatory representations are likely closer to the classification head of the feature extractor (e.g., $f_{\Theta}$). Therefore we propose the hierarchy $\{ 1,2,\dots, s\} \subset \{ 1,2,\dots,2s\}$ because, with this, the features extracted by $f_{\Theta}$ appear in both sets of the hierarchy. 
    \end{comment}


\begin{comment}
\begin{table}[t]
    \centering
    \caption{Computing the chordal distance on Stiefel, Grassmann, and flag manifolds using matrix representatives.}
    \setlength{\tabcolsep}{2pt}
    \small 
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{l|l}
        \toprule
        \textbf{Representation / Manifold} & \textbf{Chordal Distance} \\
        \midrule
        $\mathrm{St}(n_k,n)$ & $\|\X - \Y\|_F$ \\
        $\mathrm{Gr}(n_k,n)$ & $\dfrac{1}{\sqrt{2}}\,\|\X\X^\top - \Y\Y^\top\|_F$ \\
        $\mathrm{Flag}(n_1,...,n_k;n)$ & $\sqrt{\dfrac{1}{2}\sum_{i=1}^k\|\X_i\X_i^\top - \Y_i\Y_i^\top\|_F^2}$ \\
        \bottomrule
    \end{tabular}
    \label{tab:chordaldist}
\end{table}
\end{comment}

\noindent Next, we build a mathematical formalization of flags.

\begin{dfn}[Matrix spaces] The \textbf{orthogonal group} $O(n)$ denotes the group of distance-preserving transformations of a Euclidean space of dimension $n$:
\begin{align}
    O(n) := \{ \M \in \R^{n \times n} : \M^\top \M =\M\M^\top = \I\}.
\end{align}
A \textbf{permutation matrix} is a square matrix $\bP \in \R^{n \times n}$ where each column and each row contains only a single $1$ value and the rest are $0$. $\D\bP$ permutes the columns of $\D$.
An important property of permutation matrices is $\bP^{-1} = \bP^\top$.
\noindent The \textbf{Stiefel manifold} $St(k,n)$, a.k.a. the set of all orthonormal $k$-frames in $\R^n$, can be represented as the quotient: $St(k,n) = O(n)/O(n-k)$. A point on the Stiefel manifold is parameterized by a tall-skinny $n \times k$ real matrix with orthonormal columns, \ie $\X \in \R^{n \times k}$ where $\X^\top \X = \I$.
\noindent The \textbf{Grassmannian}, $ Gr(k, n) $ represents the set of all $k $-dimensional subspaces of $ \mathbb{R}^n $. Each point in $ Gr(k, n) $ can be identified with an equivalence class of matrices in the Stiefel manifold, where two matrices are equivalent if their columns span the same subspace. 
We represent $[\X] \in Gr(k,n)$ using the Stiefel coordinates
$\X \in St(k,n)$.
\end{dfn}


\begin{dfn}[Flag]
    Let $\mathcal{V}_i$ be an $n_i$-dimensional subspace of a vector space $\mathcal{V}$ of dimension $n$. A \emph{flag} of type $(n_1,n_2,\dots, n_k;n)$, is the nested sequence of subspaces
    \begin{equation}
        \emptyset \subset \mathcal{V}_1 \subset \mathcal{V}_2 \subset \cdots \subset \mathcal{V}_k \subset \mathcal{V}.
    \end{equation}
\end{dfn}
The \emph{flag manifold} $\flag(n_1,n_2,\dots, n_k;n)$, is the Riemannian manifold, which is the collection of all flags of type, a.k.a. signature, $(n_1,n_2,\dots, n_k;n)$~\cite{szwagier2023rethinking,ye2022optimization}. The first empty subspace, $\emptyset$ with dimension $n_0 = 0$, is now mentioned for completeness but will be dropped from notation and implicit from here on. In this work, we will work with real flags, namely $\mathcal{V} = \mathbb{R}^n$. 




\begin{remark}[Flag manifold as a quotient of groups]
Ye et al.~\cite[Proposition 4.10]{ye2022optimization} prove that $\flag(n_1,\dots,n_k;n)$ is diffeomorphic to the quotient space $St(n_k,n)/(O(m_1) \times O(m_2) \times \cdots \times O(m_{k}))$ where $m_i = n_i - n_{i-1}$. This fact gives a Stiefel manifold coordinate representation of a flag.
\end{remark}

\begin{dfn}[Stiefel coordinates for flags~\cite{ye2022optimization}]
A flag is represented by $\X  = [ \X_1 | \X_2 | \cdots | \X_k ] \in St(n_k,n)$ where $\X_i \in \R^{n \times m_i}$. Specifically, $\X$ represents the flag 
\begin{equation}
    [\![ \X ]\!] = [\X_1] \subset [\X_1, \X_2] \subset \cdots \subset [\X_1, \X_2,\dots \X_k] \subset \R^n
\end{equation}
We say $[\![ \X ]\!]$ represents a flag of type (or signature) $(n_1,n_2,\dots, n_k;n)$ and $[\X_1, \X_2,\dots \X_i]$ denotes the span of $[\X_1| \X_2 |\cdots |\X_i]$ (for $i=1,2,\dots,k$).
\end{dfn}


\begin{table*}[t]
    \centering
    \caption{Computing the chordal distance on Steifel, Grassmann, and flag manifolds using matrix representatives. $\|\cdot\|_F$ is Frobenius norm.}
    \setlength{\tabcolsep}{4mm} 
    {%
    \begin{tabular}{l| c | c |c}
        Representation / Manifold & $\X,\Y \in St(n_k,n)$ & $[\X],[\Y] \in Gr(n_k,n)$  &  $[\![\X]\!],[\![\Y]\!] \in \flag(1,\dots,n_k;n)$\\
        \midrule
        Chordal distance & $\|\X - \Y\|_F$ &  $\frac{1}{\sqrt{2}}\|\X\X^\top - \Y\Y^\top\|_F$ & $\sqrt{\frac{1}{2}\sum_{i=1}^k\|\X_i\X_i^\top - \Y_i\Y_i^\top\|_F^2}$
    \end{tabular}
    }
    \label{tab:chordaldist}
\end{table*}



Given the tall-skinny orthonormal matrix representatives $\X,\Y \in \R^{n \times n_k}$, we also utilize their \emph{chordal distances} as given in~\cref{tab:chordaldist}. 
The chordal distance on the Stiefel manifold measures the $2$-norm of the vectorized matrices. In contrast, the Grassmannian chordal distance measures the $2$-norm of the vector of sines of the principal angles~\cite{bjorck1973numerical} between the subspaces through the Frobenius norm of the projection matrices~\cite{edelman1998geometry}. The chordal distance on the flag manifold arises from the fact that it is a closed submanifold of $\Gr(m_1,n) \times \cdots \times \Gr(m_k,n)$ as shown by Ye et al.~\cite[Proposition 3.2]{ye2022optimization}. This distance is similar to the Grassmannian chordal distance between subsequent pieces of the flags (\eg, $[\X_i]$ and $[\Y_i]$ for $i=1,\dots,k$).



