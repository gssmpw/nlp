\section{Relations to existing work}
\label{sec:related_work}

We connect questions of \emph{identifiability} with results from \emph{differential geometry}. To our knowledge, no previous studies have formally connected these otherwise disjoint fields. Our work is, however, linked to a large body of prior works.\looseness=-1

\textbf{Identifiability} is well studied in the ICA or source separation literature \citep{ICA1, ICA2}. The analysis of identifiability in deep generative models stems from a connection between VAEs and ICA first noticed by \citet{khemakhem2020variationalautoencodersnonlinearica}. Many works either focus on formulating identifiability-enhancing constraints, typically placed on the decoder or latent distribution, or obtaining data from more diverse sources, e.g., multiple environments or multiple views \citep{kivva2022identifiabilitydeepgenerativemodels,hyvarinen2019nonlinearicausingauxiliary, gresele2019incompleterosettastoneproblem, pmlr-v119-locatello20a, locatello2019disentangling, shu2019weakly}. On the other hand, few works exist that characterize when, and what types of non-identifiability are acceptable in deployments of deep generative models without significant constraints.

\textbf{Latent space geometries} have been studied in various contexts to define more `meaningful' latent interpolations and distances \citep{Tosi:UAI:2014, arvanitidis2021latentspaceodditycurvature, hadi:rss:2021}. While \citet{hauberg:only:2018} alludes to connections between latent space geometries and identifiability, no formal statement has previously been made. Our work, thus, brings further mathematical justification to the algorithmic tools developed for latent space geometries. \citet{Detlefsen_2022} has previously demonstrated that latent space geometries recover evolutionary structures from models of proteins that are invisible under an Euclidean latent geometry. Our work adds credibility to these findings, which can now be seen as identifiable.

\textbf{Causality} strongly relies on identifiability as there is little point in recovering the `true' causal model if it is not guaranteed to be unique. The goal of \emph{causal representation learning} \citep{scholkopf2021toward} is closely linked to our quest for identifiable representations, or, at least, relationships between such. Our approach, however, is not immediately applicable to many questions of causality as these often amount to establishing \emph{independence} between variables \citep{peters2017elements}. Under the geometric lens, we do not have a canonical coordinate system in the latent space, which complicates splitting the latent space into factors to be considered independent.

\textbf{Disentanglement} can be seen as a `poor man's causality' \citep{detlefsen2019explicit}, where the key generating factors are sought to be axis-aligned in the latent space. This is generally known to be mathematically impossible \citep{pmlr-v97-locatello19a}, much in line with proposition~\ref{prop:flat_models}. Similar to identifiability, this difficulty has been addressed by inductive biases \citep{bouchacourt2018multi} or (weak) data labels \citep{pmlr-v119-locatello20a, locatello2019disentangling, shu2019weakly}. Empirical studies, however, hint that some key factors can be recovered in practice \citep{higgins2016beta, dittadi2020transfer, pmlr-v97-suter19a}. \citet{rolinek2019variational} noted that standard disentanglement pipelines only work when the variational distribution, parametrized by the encoder, is restricted to a diagonal covariance. This suggests that current results in disentanglement may be artifacts of a poor Bayesian approximation. Our work suggests that disentanglement is perhaps better achieved by looking for `geometric factors', such as \emph{principal geodesics} \citep{fletcher2004principal}.

\textbf{Relative representations} consider pairwise latent Euclidean distances as a form of representation \citep{moschella2022relative}. This is well-aligned with the ideas we put forward. Empirically, \citet{moschella2022relative} reports that latent Euclidean distances are sufficiently robust to be of practical value. We find that identifiable geodesic distances are significantly more robust, such that our approach should bring both mathematical guarantees and empirical improvements.



 






% In our work, we take a very different approach insofar: 
% \begin{itemize}
%     \item we focus on identifiability by considering the geometry of the decoder
%     \item consider identifiability of "tasks" or metric structures in the latent space induced by the modelled manifold. Do not consider the identifiability of the latent codes themselves. 
%     \item give strong identifiability guarantees in very usefuls settings
% \end{itemize}

