\section{Background and notation}
\label{sec:background}
Before stating our main questions and results, we recap the prerequisite background information. We position our work relative to the existing literature in Sec.~\ref{sec:related_work}.

\textbf{Deep latent variable models} learn densities of data $X \in \mathcal{D}$ parametrized by latent variables $Z \in \mathcal{Z}$, such that $p(X) = \int p(X|Z) p(Z) \mathrm{d}Z$ \citep{tomczak2024deep}. We consider models with \emph{continuous} latent variables, i.e., $\mathcal{Z} \subseteq \mathbb{R}^n$. Examples of this model class includes \emph{probabilistic PCA} \citep{tipping1999probabilistic}, \emph{variational autoencoders} \citep{VAE, rezende2014stochastic}, \emph{normalizing flows} \citep{tabak2010density, lipman2022flow}, \emph{diffusion models} \citep{ho2020denoising} and more.

Formally, we define a model as a tuple of random variables $(Z, X)$ where the latent $Z$ drives the observations $X$ through a measurable \emph{generator function} $f:\mathcal{Z}\to \mathcal{D}$, often called \emph{the decoder}, and a \emph{noise mechanism} $h:\mathcal{D}\times \mathcal{D}\to \mathcal{D}$ that makes the relationship stochastic through a noise term $\epsilon$,
\begin{equation}
   Z^i \sim P_Z, \quad \epsilon^i \sim P_{\epsilon}, \quad X^i = h (f(Z^i), \epsilon^i) 
\end{equation}
where $Z^i$ and $\epsilon^i$ are assumed independent. We further adopt a standard regularity assumption that $h$ and $P_{\epsilon}$ are such that $\epsilon^a \eqdistrib \epsilon^b$, $h(f(Z^a), \epsilon^a) \eqdistrib h(f(Z^b), \epsilon^b)$ if and only if $f(Z^a) \eqdistrib f(Z^b)$. Here $\eqdistrib$ denotes equality in distribution and the assumption ensures that the noise $\epsilon$ does not interfere with the causal relationship between $X$ and $Z$. 

\textbf{Statistical model} arises when we learn the parameters of the generative model given realizations $\mathbf{x}$ of $X$. Learning the generative model means estimating its parameters $\theta = (f, P_Z)$, which represent the decoder and the latent distribution, respectively. These give rise to the marginal distribution of the data $P_{\theta}$ that quantifies model fit. Formally, we define a model $M$ as
\begin{equation} \label{eq:StatModLvm}
    M\left(\mathcal{F}, \mathcal{P}_Z\right)=\left\{P_\theta \text { on } \mathcal{D} \mid \theta=\left(f, P_Z\right) \in \mathcal{F} \times \mathcal{P}_Z\right\},
\end{equation}
where $\mathcal{F}$ and $\mathcal{P}_Z$ are the sets of possible generator functions and distributions on the latent space, respectively. Designing a deep latent variable model means specifying $\mathcal{F}$ and $\mathcal{P}_Z$.

\textbf{Identifiability} concerns the uniqueness of parametrizations. We say that two parameters $\theta$ and $\theta'$ are equivalent, $\theta \sim \theta'$, if the resulting distributions $P_{\theta}$ and $P_{\theta'}$ are the same. The induced \emph{equivalence class} is denoted $[\theta]=\left\{ \theta': P_{\theta} = P_{\theta'} \right\}$. Informally, this class captures the different ways in which a specific density can be parameterized. Following \citet{xi2023indeterminacy}, we say that a model is \emph{strongly identifiable} if $[\theta]$ is a singleton, i.e.\@ the model parametrization is unique, while a model is \emph{weakly identifiable} if it can be identified up to the equivalence class $[\theta]$. 

As an example, in probabilistic PCA \citep{tipping1999probabilistic}, the latent variables can only be identified up to an unknown rotation due to the rotational symmetry of the Gaussian distribution. We then write the equivalence class as $[\theta] = \{R\theta\}$, where $R$ is any rotation matrix (Fig.~\ref{fig:automorph}, top).

\begin{figure}
    \centering
    \footnotesize{Latent space~~~~~~~~~~~~~~~~~~~~~~~~~~Observation space}\\
    \rotatebox{90}{\footnotesize{~~~Probabilistic PCA}}
    \includegraphics[width=0.9\linewidth]{pics/ppca.pdf} \\ \vspace{1mm}
    \rotatebox{90}{\footnotesize{~~~~~~~General case}}
    \includegraphics[width=0.9\linewidth]{pics/automorph.pdf}
    \vspace{-2mm}
    \caption{Indeterminacy transformations characterize the identifiability equivalence class.
      \emph{Top row:} Probabilistic PCA has linear decoders, such that the indeterminacy transformations are rotations.
      \emph{Bottom row:} In general deep latent variable models the indeterminacy transformations are the general class of diffeomorphisms acting on the latent space.}
    \label{fig:automorph}
\end{figure}

\textbf{Indeterminacy transformations} provide means to characterizing the equivalence class of a latent variable model $M$ \citep{xi2023indeterminacy}. Given two parametrizations of a model $\theta_a=\left(f_a, P_{Z_a}\right)$ and $\theta_b=\left(f_b, P_{Z_b}\right)$ with resulting marginal distributions $P_{\theta_a}=P_{\theta_b}$, an \emph{indeterminacy transformation} at $(\theta_a, \theta_b)$ is a measurable function $A_{a,b}: \mathcal{Z} \rightarrow \mathcal{Z}$ such that $P_{\theta_a}=P_{\theta_b}$ and $f_a \circ A_{a,b}^{-1}=f_b$; c.f.\@ bottom panel of Fig.~\ref{fig:automorph}. \citet{xi2023indeterminacy} prove that the set of all indeterminacy transformations, denoted $\mathbf{A}(M)$, fully determines the equivalence class $[\theta]$.  \emph{This result establishes the equivalence between parameter identifiability and indeterminacy transformations of the latent space and their associated decoders}.

\textbf{Identifiable task} captures latent computations with identifiable outcomes \citep{xi2023indeterminacy}. Here, a task is defined by first \emph{selecting} latent points $\mathbf{z}_n = s(\theta,\mathbf{x}_m) \in  \mathcal{Z}$, and secondly by evaluating the task $t(\theta,\mathbf{x}_m,\mathbf{z}_n)$. The selection mechanism can e.g.\@ be the inverse decoder, while a task could be independence testing in causal discovery or measuring the distance between latent representations.

Following Proposition~3.1 from \citet{xi2023indeterminacy}, we can state the sufficient condition for the identifiability of a task in terms of indeterminacy transformations.
%
\begin{definition}
\label{def:task_identifiability}
A task $(s, t)$ is identifiable up to $[\theta]$ if, for each $A\in \mathbf{A}(M)$ and  $\mathbf{x}_m \in \mathcal{D}$ with $\mathbf{z}_n \in \mathcal{Z}$:
\begin{equation}
\begin{aligned}
    t(\theta, \mathbf{x}_m ,  \mathbf{z}_n) = t(A\theta, \mathbf{x}_m , A( \mathbf{z}_n)) \\
    \text{and } s(A\theta, \mathbf{x}_m ) = A(s(\theta, \mathbf{x}_m )),
\end{aligned}
\label{eq:task_identifiability}
\end{equation}    
where with $\theta_a, \theta_b \in [\theta]$, we have $A\theta_a=\theta_b=(f_a \circ A^{-1}, A_{\#}P_{Z_a}) = (f_b, P_{Z_b})$ and $A_{\#}P_{Z_a}$ denotes the pushforward of the probability measure $P_{Z_a}$. 
\end{definition}