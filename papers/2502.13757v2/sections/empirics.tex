\section{Experiments}
\label{sec:experiments}

Theorem~\ref{thrm:identifiable_dist_func} states that geodesic distances are identifiable while Euclidean ones are not. This suggests that geodesic distances should be more stable under model retraining than the Euclidean counterpart. To test this hypothesis, we train 30 models with different initial seeds and compute both Euclidean and geodesic distances between 100 randomly chosen point pairs from the test set. We emphasize that the pairs are the same across all models, which allows us to measure the variances of the distances across models.

\begin{SCfigure}[100][b]
    \includegraphics[width=0.55\linewidth]{pics/8decoders_pair1_v3.pdf}
    \caption{An example latent geodesic from a $\mathcal{M}$-flow model trained on three classes from \textsc{mnist}. The background color indicates model uncertainty.\looseness=-1}
    \label{fig:godesic}
\end{SCfigure}

%To demonstrate the practical benefit of geodesic distances in the latent space, we compare them to the Euclidean. For each of the experiments, we are training 30 models with different initial seeds and compute Euclidean and geodesic distances between 100 randomly chosen and fixed point pairs from the test set. Thus, for all 30 models, the pairs are the same and the experiment produces 30 distance measurements for each point pair. 

To assess the stability of the distance measures, we compute the coefficient of variation for each pair, which is evaluated as $\text{CV}(m_{pair}) = \sfrac{\sigma(m_{pair})}{\mu(m_{pair})}$ with $\sigma$ and $\mu$ denoting standard deviation and the mean, respectively. The coefficient of variation is a unitless measure of variability, where low values indicate less variability. We use this to compare the variability of Euclidean and geodesic distances.


We consider two models and datasets. First, a smaller model that satisfies all our assumptions, and second a larger model where we disregard the injectivity assumption. %Since computing geodesic distances is more involved than computing the Euclidean norm, the primary goal of our experiments is to demonstrate that our methodology is effective and feasible for modern deep latent variable models. The secondary goal is to show the efficacy of our method while relaxing assumption~\ref{ass:2} by choosing a modern and flexible architecture that is not guaranteed to be injective.
To compute geodesics we parametrize them by a spline connecting two points in the latent space and minimize its energy. The discussion around Definition~\ref{def:geodesics} in Appendix~\ref{appendix:diffgeom} covers how this leads to a geodesic. %To compute the energy, we discretize the curve, decode the line segments and compute the sum. 
It has been noted that taking decoder uncertainty into account is key to good performance \citep{arvanitidis2021latentspaceodditycurvature, hauberg:only:2018} and we follow the ensemble-based approach from \citet{pmlr-v251-syrota24a}, implying that we train an ensemble of 8 decoders. Details are in Appendix~\ref{appendix:geodesics} and the code to reproduce our results is available at the \href{https://github.com/mustass/identifiable-latent-metric-space/}{project GitHub repository}. \looseness=-1 

\textbf{\textsc{mnist} with \ref{ass:1}-\ref{ass:4} satisfied.~~}
We use $\mathcal{M}$-flows \citep{brehmer2020flows} to construct a VAE with an injective decoder. %maps lower dimensional representation to the observational space by a decoder that consists of a padding operation followed by a bijection.
%
We train this model on a 3-class subset of \textsc{mnist} with a 2D latent space for visualization purposes. An example of a geodesic curve from digit 7 to digit 0 from the test set is visualized in Fig.~\ref{fig:godesic}. The geodesic crosses class boundaries where they are well-explored by the model and offer little uncertainty.

The left panel of Fig.~\ref{fig:histogram-mnist-celeba} shows a histogram of the coefficient of variation for the 100 point-pairs,  where we see a narrower distribution with both a lower mean and spread for geodesic distances. We perform a one-sided Student's $t$-test for the null hypothesis that geodesic distances vary less than the Euclidean (Table~\ref{tab:t_tests}) and find strong evidence for the hypothesis. This demonstrates that identifiability improves reliability.


\begin{SCfigure*}[1][t]
  \includegraphics[width=0.8\textwidth]{pics/celeba_geodesic.pdf} 
  \caption{Geodesic (top) and Euclidean (bottom) interpolations, are highly similar, but distances still differ significantly (Fig.~\ref{fig:histogram-mnist-celeba}). \looseness=-1}
  \label{fig:celeba_interp}
\end{SCfigure*}


\textbf{\textsc{celeba} with \ref{ass:2} relaxed and \ref{ass:3} verified.~~}
The general VAE model is known to be effective due to its flexible decoder parametrized by a neural network with arbitrary architecture that is not guaranteed to be globally injective (\ref{ass:2}) nor to have full rank Jacobian (\ref{ass:3}). We train this model on the \textsc{celeba} dataset \cite{liu2015faceattributes} where the architecture is composed of convolutional and dense layers with ELU activation functions. The latent space dimension is 64 and we further employ Resize-Conv layers \cite{odena2016deconvolution} to improve image quality.
We follow the approach from \citet{8575533} to validate that the decoder Jacobian is, indeed, always full rank. An example geodesic is shown in Fig.~\ref{fig:celeba_interp} alongside a Euclidean counterpart, where we do not observe a significant difference between generated images.

%Since calculating the geodesics post-training requires \ref{ass:3} to be satisfied, we can verify it using approaches outlined in \cite{8575533}. A necessary prerequisite for the post-training test to be valid is that the activation functions used are monotonically increasing, which excludes e.g. ReLU and GELU functions.

Fig.~\ref{fig:histogram-mnist-celeba}(right) shows that the coefficient of variation for geodesic distances has both lower mean and standard deviation than Euclidean distances. The one-sided Student's $t$-test again validates this observation (Table~\ref{tab:t_tests}). This demonstrates that geodesic distances remain more reliable than Euclidean ones even when the injectivity assumption may be violated.


% \subsection{Implementation and experimental setup}

% To compute geodesics we parametrize them by a spline connecting two points in the latent space and minimize its energy. The discussion around Definition~\ref{def:geodesics} in Appendix~\ref{appendix:diffgeom} covers how this leads to a geodesic. %To compute the energy, we discretize the curve, decode the line segments and compute the sum. 
% It has been noted that taking decoder uncertainty into account is key to good performance \citep{arvanitidis2021latentspaceodditycurvature, hauberg:only:2018} and we follow the ensemble-based approach from \citet{pmlr-v251-syrota24a}, implying that we train an ensemble of 8 decoders. Details are in Appendix~\ref{appendix:geodesics} and the code to reproduce our results is in the supplements. \looseness=-1 %presented in this section is available at [\texttt{link redacted}]
% %Our implementation details are in Appendix~\ref{appendix:models} and code to reproduce the results presented in this section is available at [\texttt{link redacted}].
 
%\subsection{Results}

% The results from both experiments demonstrate that the geodesic distance is more robust than the Euclidean distance in the latent space of a deep latent variable model. Figure~\ref{fig:histogram-mnist-celeba} shows the histograms of coefficient of variation across 100 point pairs for both experiments where we see that on \textsc{mnist} we get a narrower distribution with both a lower mean and spread for geodesic distances.  Geodesic distances on \textsc{celeba} similarly show a distribution with a lower mean, whereas the spread that looks comparable. Another view of the results is offered in Table~\ref{tab:t_tests} that shows a One-sided Student's $t$-test for the Null hypothesis that geodesic distances vary less than the Euclidean and finds strong evidence for the hypothesis. 

\begin{SCtable}[0.7][t]
    \centering
    \begin{tabular}{lccc}
    \toprule
    & \textsc{mnist} & \textsc{celeba} \\ 
    \midrule
    $t$-statistic    & -8.64 & -22.33 \\ 
    $p$-value        & 1.00  & 1.00  \\ 
    \bottomrule
    \end{tabular}
    \caption{One-sided Student's $t$-test for the variability of geodesic versus Euclidean distances} % Geodesic distances vary significantly less.}
    \label{tab:t_tests}
\end{SCtable}


\begin{SCfigure*}[5][t]
    %\centering
        \includegraphics[width=0.8\columnwidth]{pics/mnist_prob.pdf}
        \includegraphics[width=0.8\columnwidth]{pics/celeba_prob.pdf}
    \caption{Histograms of coefficients of variation for Euclidean and geodesic distances on \textsc{mnist} (left) and \textsc{celeba} (right). Geodesic distances vary significantly less, which is quantified in Table~\ref{tab:t_tests}.}
    \label{fig:histogram-mnist-celeba}
\end{SCfigure*}