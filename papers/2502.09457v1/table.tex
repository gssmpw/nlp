\begin{center}
\begin{table*}[h!]
\centering
\footnotesize
% \scriptsize
\scalebox{0.85}{
\begin{tabular}{|l|c|c|c|c|}
\hline
Category & \begin{tabular}[c]{@{}c@{}}Prompting Technique \end{tabular} & \begin{tabular}[c]{@{}c@{}}Evaluated \\ LLM(s) \end{tabular} & Dataset(s) & \begin{tabular}[c]{@{}c@{}}Task(s) \end{tabular} \\
\hline
\begin{tabular}[c]{@{}c@{}}New Tasks Without \\Training Data \end{tabular}  & Zero-shot Prompting  & - & - & - \\ 
\cline{2-5}

& Few-shot Prompting  & - & - & - \\ 
\hline

 & Chain-of-Thought~\cite{wei2022chain} & \begin{tabular}[c]{@{}c@{}}PaLM 540B, \\ code-davinci-002, \\text-davinci-002,\\LaMDA 137B  \end{tabular}  
 & \begin{tabular}[c]{@{}c@{}}Arithmetic Reasoning[\\ GSM8K, \\SVAMP,\\ASDiv, \\ AQuA, \\MAWPS] \\ Commonsense \\ Reasoning [\\ CSQA,\\StrategyQA,\\ Date, \\Sports, \\SayCan] \\ Symbolic\\ Reasoning [ \\Letter, \\ Coin] \end{tabular}  & \\ 
 
 \cline{2-5}

%  arithmetic(GSM8K ,SVAMP ,ASDiv ,AQuA ,MAWPS)
% commonsense reasoning (CSQA ,StrategyQA, Date, Sports, SayCan)
% symbolic reasoning(Letter, Coin) 
 
 & \begin{tabular}[c]{@{}c@{}}Automatic \\ Chain-of-Thought~\cite{zhang2022automatic} \end{tabular} & \begin{tabular}[c]{@{}c@{}}PaLM 540B, \\GPT-3,\\LaMDA 137B \end{tabular} & \begin{tabular}[c]{@{}c@{}}Arithmetic Reasoning[\\ GSM8K, \\SVAMP,\\ASDiv, \\ AQuA, \\MAWPS] \\ Commonsense \\ Reasoning [\\ CSQA,\\StrategyQA,\\ Date, \\Sports, \\SayCan] \\ Symbolic\\ Reasoning [ \\Letter, \\ Coin] \end{tabular}  & \\ 
 \cline{2-5}

Reasoning and Logic   & Self-Consistency~\cite{wang2022self} &
\begin{tabular}[c]{@{}c@{}} UL2-20B,\\PaLM 540B,\\code-davinci-002,\\
text-davinci-002,\\ LaMDA 137B \end{tabular} & \begin{tabular}[c]{@{}c@{}}Arithmetic Reasoning[\\ GSM8K, \\SVAMP,\\ASDiv, \\ AQuA, \\MAWPS] \\ Commonsense \\ Reasoning [\\ CSQA,\\StrategyQA,\\ Date, \\Sports, \\SayCan] \\ Symbolic\\ Reasoning [ \\Letter, \\ Coin] \end{tabular}  &  \\ 
  \cline{2-5}
  
& Tree-of-Thoughts~\cite{yao2023tree} & GPT-4 & \begin{tabular}[c]{@{}c@{}} Game of 24,\\ Creative Writing,\\ Mini Crosswords \end{tabular} & \\
\cline{2-5}

& Graph-of-Thought~\cite{yao2023beyond}  & \begin{tabular}[c]{@{}c@{}} GPT-3, \\GPT-3.5,\\GPT-4,\\code-davinci-002,\\T5(base \& large) \end{tabular}& \begin{tabular}[c]{@{}c@{}} GSM8K,\\ ScienceQA\end{tabular} &  \\ 
\cline{2-5}

& System 2 Attention~\cite{weston2023system}  & \begin{tabular}[c]{@{}c@{}} GPT-4, \\ LLaMA-2-70B\end{tabular}& \begin{tabular}[c]{@{}c@{}} QA,\\ math word problems\\longform \end{tabular} &  \\ 

  \hline
 & Chain-of-Verification~\cite{dhuliawala2023chain} & \begin{tabular}[c]{@{}c@{}} Llama 2 70B Chat,\\ Llama 65B \end{tabular} & \begin{tabular}[c]{@{}c@{}} Wikidata,\\ QUEST,\\ MultiSpanQA\end{tabular}&  \\  
 \cline{2-5}
 
 &  ReAct Prompting~\cite{yao2022react} & \begin{tabular}[c]{@{}c@{}}PaLM-540B,\\ GPT-3\end{tabular} & \begin{tabular}[c]{@{}c@{}} HotpotQA,\\ Fever,\\ALFWorld,\\ WebShop\end{tabular}&  \\  
 \cline{2-5}
 
Reduce Hallucination & \begin{tabular}[c]{@{}c@{}}Retrieval Augmented \\ Generation~\cite{lewis2020retrieval} \end{tabular} & \begin{tabular}[c]{@{}c@{}}T5-11B, \\RAG-Token,\\ RAG-Seq.,\\REALM,\\DPR \end{tabular} &  \begin{tabular}[c]{@{}c@{}} Natural Questions,\\ TriviaQA,\\WebQuestions \\and CuratedTrec,\\MSMARCO NLG\\ task v2.1,\\SearchQA, \\Fever \end{tabular} & \\  
\cline{2-5}
\end{tabular}
}
\caption{A comparative summary of the literature and the proposed model}
\label{tab:comparison}
\end{table*}
\end{center}


\begin{center}
\begin{table*}[h!]
\centering
\footnotesize
% \scriptsize
\scalebox{0.85}{
\begin{tabular}{|l|c|c|c|c|}
\hline
Category & \begin{tabular}[c]{@{}c@{}}Prompting Technique \end{tabular} & \begin{tabular}[c]{@{}c@{}}Evaluated \\ LLM(s) \end{tabular} & Dataset(s) & \begin{tabular}[c]{@{}c@{}}Task(s) \end{tabular} \\
\hline

 & Chain-of-Note~\cite{yu2023chainofnote} & \begin{tabular}[c]{@{}c@{}} LLaMa-2,\\ DPR \end{tabular} & \begin{tabular}[c]{@{}c@{}} NQ,\\ TriviaQA, \\WebQ \end{tabular} &  \\ \cline{2-5}
 
 & Chain-of-Knowledge~\cite{li2023chainofknowledge} & gpt-3.5-turbo-0613 & \begin{tabular}[c]{@{}c@{}} Factual [\\ FEVER,\\ HotpotQA,\\FeTaQA]\\
Medical [\\MedMCQA] \\ Physics [ \\MMLU Physics]\\Biology [\\MMLU Biology]\end{tabular} &  \\  \hline 

 User Interaction & Active-Prompt~\cite{diao2023active} & \begin{tabular}[c]{@{}c@{}} CodeX code-davinci-002, \\text-davinci-002, \\ text-davinci-003 \end{tabular} & \begin{tabular}[c]{@{}c@{}}Arithmetic [\\ GSM8K, \\SVAMP,\\ASDiv, \\ AQuA, \\MAWPS] \\ Commonsense \\ Reasoning [\\ CSQA,\\StrategyQA,\\ Date, \\Sports, \\SayCan] \\ Symbolic\\ Reasoning [ \\Letter, \\ Coin] \end{tabular}  &  \\ 
 \hline
 % & Instruction Prompting and Tuning &  & \xmark &  \\ \hline

 % & & \xmark & \cmark& FedAWA \\ \hline 

\begin{tabular}[c]{@{}c@{}} Fine-Tuning and \\ Optimization \end{tabular}   & \begin{tabular}[c]{@{}c@{}}Automatic Prompt \\ Engineer~\cite{zhang2022automatic} \end{tabular}   & \begin{tabular}[c]{@{}c@{}} Ada, \\ babbage,\\ curie,\\ davinci,\\ text-ada-001,\\ text-babbage-001,\\ text-curie-001,\\ text-davanci-002 \end{tabular} & \begin{tabular}[c]{@{}c@{}} 24 Instruction Induction,\\
BIG-Bench Instruction Induction \\(emotional understanding,\\ context-free question answering,\\ reading comprehension,\\ summarization, \\algorithms,\\ and various reasoning tasks) \\
TruthfulQA \end{tabular}&  \\ \hline

% & Automatic Prompt Engineer (APE) & \xmark & \cmark& FAVOR \\ \hline

\begin{tabular}[c]{@{}c@{}} Knowledge-Based\\Reasoning and
Generation \end{tabular}  & \begin{tabular}[c]{@{}c@{}} Automatic Reasoning\\and Tool-use~\cite{paranjape2023art} \end{tabular}  & \begin{tabular}[c]{@{}c@{}} GPT-3 (175B),\\Toolformer,\\InstructGPT \\(text-davinci-002)\end{tabular}  & \begin{tabular}[c]{@{}c@{}}SQUAD, \\TriviaQA,\\ SVAMP,\\ MAWPS,\\ MMLU \end{tabular} &  \\ \hline

 % & Retrieval Augmented Generation (RAG) & \xmark & \cmark& FAVOR \\ \hline

\begin{tabular}[c]{@{}c@{}} Improving Consistency\\and Coherence \end{tabular} & \begin{tabular}[c]{@{}c@{}} Contrastive\\Chain-of-Thought~\cite{chia2023contrastive} \end{tabular}   & GPT-3.5-Turbo (0301) & \begin{tabular}[c]{@{}c@{}} arithmetic [ \\GSM8K,\\SVAMP,\\ASDiv,\\AQuA,\\GSM-Hard] \\Factual QA [\\Bamboogle\\ StrategyQA] \end{tabular}&  \\ \hline

\begin{tabular}[c]{@{}c@{}} Managing Emotions\\and Tone \end{tabular} 
   & Emotion Prompting~\cite{li2023large} & \begin{tabular}[c]{@{}c@{}} T5,\\ Vicuna,\\ BLOOM,\\ Llama 2,\\ gpt-3.5-turbo,\\ GPT-4 \end{tabular}& \begin{tabular}[c]{@{}c@{}} 24 instruction \\ induction tasks, \\BIG-Bench \\Instruction \\Induction (BBII) \end{tabular}&  \\ \hline

 & \begin{tabular}[c]{@{}c@{}}Structured  \\ Chain-of-Thought~\cite{zhang2022automatic}\end{tabular} & \begin{tabular}[c]{@{}c@{}} ChatGPT, \\Codex \end{tabular}& \begin{tabular}[c]{@{}c@{}} HumanEval,\\ MBPP,\\MBCPP \end{tabular} & \\
 \cline{2-5}
  %& Program of Thoughts & \cmark& FAVOR \\ \cline{2-5}

 & Program of Thoughts~\cite{chen2022program} & \begin{tabular}[c]{@{}c@{}}code-davinci-002,\\ text-davinci-002,\\
 gpt-3.5-turbo,\\PaLM,\\codegen-16B\end{tabular} &\begin{tabular}[c]{@{}c@{}} GSM8K,\\AQuA,\\SVAMP,\\TabWMP,\\FinQA,\\ConvFin,\\TATQA \end{tabular}&  \\ \cline{2-5}

\begin{tabular}[c]{@{}c@{}}Code Generation and \\ Execution\end{tabular}   & Chain of Code Prompting~\cite{li2023chain} & \begin{tabular}[c]{@{}c@{}}text-ada-001, \\text-baggage-001, \\text-curie-001,\\text-davinci-003,\\gpt-3.5-turbo,\\gpt-4 \end{tabular} & \begin{tabular}[c]{@{}c@{}} BIG-Bench\\ Hard (BBH) - 23 tasks[ \\semantic reasoning, \\numerical reasoning, \\combination of \\semantic and \\numerical reasoning] \end{tabular} &  \\ \cline{2-5}

 & Scratchpad Prompting~\cite{nye2021show} & GPT  & \begin{tabular}[c]{@{}c@{}} MBPP,\\MBPP-aug \end{tabular}&  \\ \hline

\begin{tabular}[c]{@{}c@{}}Optimization \\and Efficiency\end{tabular}  & Optimization by Prompting~\cite{yang2023large} & \begin{tabular}[c]{@{}c@{}} text-bison,\\ PaLM 2-L,\\PaLM 2-L-IT,\\ gpt-3.5-turbo,\\gpt-4 \end{tabular}& \begin{tabular}[c]{@{}c@{}}GSM8,\\Multi-Arith,\\AQuA \end{tabular}&  \\ \hline

Understanding User Intent & Rephrase and Respond~\cite{deng2023rephrase} & \begin{tabular}[c]{@{}c@{}}GPT-3.5-turbo-0613,\\ Vicuna-13b-v1.5, \\GPT-4-0613 \end{tabular}  & \begin{tabular}[c]{@{}c@{}}Knowledge Classification [\\Even day,\\Even month,\\Even year,\\Compare age]\\Commonsense Reasoning [\\CSQA,\\Dates]\\Symbolic Reasoning [ \\Last letter (2), \\Last letter (4),\\ Coin flip,\\ Sports] \end{tabular} &  \\ \hline

\begin{tabular}[c]{@{}c@{}} Metacognition and\\Reflection \end{tabular} & \begin{tabular}[c]{@{}c@{}}Take a Step \\Back ~\cite{zheng2023take} \end{tabular}   &\begin{tabular}[c]{@{}c@{}} PALM2-L,\\ GPT-4 \end{tabular}&\begin{tabular}[c]{@{}c@{}} TimeQA,\\ StrategyQA,\\ MMLU high-school\\ Physics,\\MuSiQue \end{tabular}&  \\ \hline

\end{tabular}
}
\caption{A comparative summary of the literature and the proposed model}
\label{tab:comparison}
\end{table*}
\end{center}


