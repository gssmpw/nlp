Our main result is the following theorem:

\begin{theorem}
\label{thm:main}
Assuming $\sum_i\lambda_i < \frac{1}{3} \sum_j \mu_j$, $\lambda_i < \frac12$ for all $i$, and all queues use a form of learning guaranteeing no-regret with high probability to identify servers they can use, the system remains stable with the expected number of packets in the system bounded by a (time-independent) constant at all times. 
\end{theorem}

The key tool in our analysis is the following theorem of \cite{pemantle1999moment}:
\begin{theorem}
\label{thm:pemantle}
Let $X_1,X_2,\ldots$ be a sequence of nonnegative random variables with the property that
\begin{enumerate}
    \item There exist constants $\alpha,\beta>0$ such that  
    $
        \mathbb{E}[X_{t+1}-X_t\vert \mathcal{F}_t \& X_t\ge \beta]<-\alpha,
  $ 
    where $\mathcal{F}_t$
    denotes the history
    until period $t$. 
    
    \item There exist $p>2$ and a constant $\theta>0$ such that for any history, 
   $ 
        \mathbb{E}[\vert X_{t+1}-X_t\vert^p\vert \mathcal{F}_t]\leq \theta.
    $
\end{enumerate}
Then, for any $0<r<p-1$, there exists an absolute constant $M=M(\alpha,\beta,\theta,p,r)$ not depending on $t$ such that $\mathbb{E}[X_t^r]\leq M$ for all $t$.
\end{theorem}
To use this theorem we will consider a long enough time in period of length $T$ and use a potential function that depends on the number of packets in each of the queues at the start of periods of length $T$. Assume that queue $i$ has $N_i$ packets at the start of the period. We will use the potential function $\Phi=\sum_i (N_i-(\lambda^2_i+3\delta) T)^+$, where $x^+=\max(x,0)$, and will aim to show that between the beginning and end of a $T$ long period the change in this potential satisfies the conditions of Theorem \ref{thm:main}. 

For a long enough period $T$, we expect that the packet arrivals and the servers' service rates are all close enough to their expectations, and each queue has small enough regret in their learning algorithm. We will call a period of length $T$ \emph{good}$_\delta$ for a parameter $\delta>0$ (to be chosen later) if the following three conditions are all satisfied. Later, we will also account for what happens when \emph{good}$_\delta$ does not occur. 

\begin{condition}
\label{con:queue_arrival}
    The number of packets arriving to each queue $i$ in each period of length $\hat T \le T$ is at most $\lambda_i\hat T+\delta T$.
\end{condition}

\begin{condition}
\label{con:service_rate}
    Each server $j$ that has a packet in its buffer (possibly one that just arrived)  for at least half of the steps during this $T$-length period succeeds in serving at least $(\frac12\mu_j-\delta) T$ packets. 
\end{condition}
\begin{condition}\label{con:learning}
The learning algorithm of each queue $i$ accumulates regret at most $\delta T$ during the $T$-length period.
\end{condition}

We use Chernoff and union bounds to bound from below the probability that conditions \ref{con:queue_arrival} and \ref{con:service_rate} hold when choosing a high enough $T$.


\begin{lemma}
\label{lm:Chernoff}
For any constants $\delta>0$ and $\eta>0$, by choosing the period length $T$ high enough, we can guarantee that the probability that conditions \ref{con:queue_arrival} or \ref{con:service_rate} fail to hold for a single queue or single server is bounded by $\eta$, and hence with probability $(1-\eta(n+m))$ the conditions hold. 
\end{lemma}

To guarantee that Condition \ref{con:learning} holds with high probability, we will assume that queues use a learning algorithm with a high probability regret guarantee, such as EXP3.P.1, of \cite{DBLP:journals/siamcomp/AuerCFS02}, which offers a regret guarantee of $\sqrt{Tm\ln(m T/\eta)}$ with probability $1-\eta$.

\begin{lemma}
\label{lm:learning}
For any constants $\delta>0$ and $\eta>0$, by choosing the period length $T$ high enough we can guarantee that if all queues use  EXP3.P.1 as their learning algorithm,  the probability that Condition \ref{con:learning} holds for a single queue is at least $1-\eta$. Hence, the condition holds with probability $(1-n\eta).$ 
\end{lemma}

Now we are ready to start proving the main result. To show the expected decrease in the potential function, we consider whether a period of length $T$ satisfied the condition of being 
\emph{good}$_\delta$. By Lemmas \ref{lm:Chernoff} and \ref{lm:learning}, we see that the probability that \emph{good$_\delta$} fails to hold is bounded by $(m+2n)\eta$. The maximum possible increase in the potential function during a period of $T$ steps is at most $nT$ (if packets arrive during each step at each of the queues, and none reach the servers), so bad events contribute at most $(m+2n)\eta nT$ to the expected change in potential over the $T$ steps. 

Next, we consider the change in potential for a \emph{good$_\delta$} period of length $T$.

\begin{lemma}
\label{lm:full_server}
  If all servers have a packet in their buffer (possibly one that just arrived) for more than half of the iterations, and we are in the \emph{good$_\delta$} case, the total number of packets at the queues decreases by at least  $(\frac12 \sum_j \mu_j-\sum_i\lambda_i -(n+m)\delta) T$.

\end{lemma}

\begin{proof}
By condition \ref{con:service_rate} the total number of packets served is at least $\sum_j (\frac12\mu_j -\delta)T$. By condition \ref{con:queue_arrival} the total number of arriving packets is at most $\sum_i (\lambda_i+\delta)T$. Combining these two bounds establishes the lemma. 
\end{proof}

\begin{lemma}\label{lm:open_server}
   Suppose there is a server whose buffer is empty more than half of the $T$ iterations, and we are in the \emph{good$_\delta$} case. Consider a queue $i$ and assume that $\delta < \frac12 (\frac12-\lambda_i)$, and $\delta < \lambda_i$. Then, the number of packets at this queue will decrease, unless the number $N'_i$ left at the end the period is at most $N'_i \le (\lambda^2_i+3\delta) T$. If at the start there are at least $T$ packets in the queue, then the number decreases by at least $\left(\frac12-(\lambda_i+2\delta)\right)T$.
\end{lemma}
\begin{proof}
Consider a queue $i$. Suppose that the queue starts with $N_i$ packets and ends the period with $N'_i$. If the server was sending a packet in every step, then by condition \ref{con:learning} it cleared at least $(\frac12-\delta)T$ packets, and by condition \ref{con:queue_arrival} at most $(\lambda_i+\delta)T$ arrived, decreasing the total by at least $(\frac12-(\lambda_i+2\delta))T$. This proves the second part of the claim, as $T$ packets (or more) at the start will guarantee sending a packet in every step.


Now suppose that the queue has packets in the last $\hat T$ steps but was empty in the previous step. Let $S_i$ denote the number of packets it successfully cleared in this $\hat T$-step period. Assume that some $(T-\hat T)\lambda_i +X_i$ packets arrived during the first $(T-\hat T)$ steps with $X_i\le \delta T$ by Condition \ref{con:queue_arrival}. Now by the no-regret Condition \ref{con:learning} we get that 
$$N_i+\lambda_i(T-\hat T)+X_i+S_i \ge \frac12 (N_i+\lambda_i(T-\hat T)+X_i+\hat T)-\delta T,$$ which implies (using that $X_i \le \delta T$)
$$
N_i \ge \hat T-\lambda_i(T-\hat T)-2S_i-3\delta T.
$$


By condition \ref{con:queue_arrival} the final number of packets in the queue at the end of the period is at most $N'_i\le\lambda_i \hat T+\delta T-S_i$. 

Putting these two inequalities together we get that 
\begin{eqnarray*}
    N_i-N'_i &\ge &\hat T-\lambda_i(T-\hat T)-2S_i-3 \delta T\\
 &  & -  (\lambda_i \hat T+\delta T-S_i)\\
    &\ge & \hat T-\lambda_i T -4\delta T -S_i.
\end{eqnarray*}


This shows that the number of packets at queue $i$ decreases, unless $\hat T \le (\lambda_i +4\delta) T+S_i$. However, in this case we get that the number of packets at the end of the period is at most $N_i'\le \lambda_i\hat T+\delta T-S_i\le (\lambda^2_i +4\lambda_i \delta)+\delta)T-(1-\lambda_i)S_i \le (\lambda^2_i +3\delta)T$, as $\lambda_i < 1/2$, proving the claim.
\end{proof}

Now we are ready to prove Theorem \ref{thm:main}.
\begin{proof} (Theorem \ref{thm:main}) 
Recall the potential function $\Phi=\sum_i (N_i-(\lambda^2_i+3\delta) T)^+$. Clearly, $\Phi$ has bounded moments, as the maximum possible increase in the potential function over a period of length $T$ is when a packet arrives at every single queue during each step and no packets are accepted at any of the servers. That is a total increase of $nT$. Similarly, the maximum possible decrease in the potential function over a period of length $T$ is when no packets arrive, and each queue succeeds in sending a packet to a server at each step. That is a total decrease of $nT$. 

Next, we want to prove that when $\Phi>Tn$, the potential is expected to decrease. Recall that when \emph{good}$_\delta$ fails to hold the potential can increase by as much as $nT$. By Lemmas \ref{lm:Chernoff} and \ref{lm:learning} this can contribute at most $\eta (m+2n)nT$ to the expectation.

To analyze the case when \emph{good}$_\delta$ holds we consider two cases separately. If all servers have packets to try to serve (in their buffer, or just arriving) at least half of the time, then by Lemma \ref{lm:full_server} the total number of packets decreases by at least $(\frac12 \sum_j \mu_j -\sum_i\lambda_i -(n+m)\delta)T$. Some of this decrease may not affect the potential function, since some of the cleared packets can come from queues that contribute zero to the potential. However, this can only affect $\sum_i (\lambda^2_i+3\delta) T$ packets in queue $i$, and so the potential is decreasing by at least 
\begin{equation}
\label{eq:decrease2}
\Big(\frac12 \sum_j \mu_j -\sum_i(\lambda_i+\lambda_i^2) -(4n+m)\delta \Big)T. 
\end{equation}
By the assumption that $\lambda_i< \frac12$ and $\sum_j \mu_j >3\sum_i \lambda_i$, this is an $\Omega(T)$ decrease, assuming we choose a small enough $\delta$.

Now consider the case where a server is open (i.e., its buffer is empty, and no new packet arrived) half the time. If $\Phi>nT$ then some queue $i$ will have at least $T$ packets. In this case, by Lemma \ref{lm:open_server} this queue will have its packet count decrease by at least
$(\frac12 -\lambda_i-2\delta)T$, contributing this decrease to the potential function. Lemma \ref{lm:open_server} also shows that all other queues will have their contribution to the potential decrease, unless it is zero at the end of the $T$-length period. This shows a total decrease in the potential of at least 
$(\frac12 -\lambda_i-2\delta)T=\Omega(T)$, again assuming $\delta$ is small enough. 

Putting together the expected increase when \emph{good}$_\delta$ fails and expected decrease in the two cases when \emph{good}$_\delta$ holds (and using that $\lambda_i \le \frac12$), we get that the potential function is expected to decrease after a $T$-length period by at least

\begin{eqnarray*}
&T\min\big(\frac12 -\lambda_i-2\delta,\frac12 \sum_j \mu_j -\frac{3}{2} \sum_i\lambda_i  -(4n+m)\delta\big)\\
& - T\eta (m+2n)n.
\end{eqnarray*}
To guarantee the required expected decrease of the potential, we choose $\delta$ small enough so both terms in the $\min$ are at least a constant (so in the case  \emph{good}$_\delta$ happens the potential decreases by $\Omega(T)$) and then choose $\eta$ small enough to make the total positive.
\end{proof}
\begin{remark}\label{remark:lambda-dependent-factor}
  Note that the proof actually shows a slightly stronger statement dependent on the $\lambda_i$ values. Using equation (\ref{eq:decrease2}), it is enough to require
  $\sum_i (\lambda_i +\lambda_i^2)< \frac12 \sum_j \mu_j$ in place of $\sum_i \lambda_i < \frac13\sum \mu_j$. This improves the bound when the arrival rates are small, approaching a factor of 2 in this case.   
\end{remark}
    

% \begin{proof}
% \textbf{Case 1.} For our first case, we assume that the condition for Theorem 1 holds: each server is free less than $x$ of the time. We now show that $\Phi_T < \Phi_0$.
% \vspace{5pt}
% \noindent
% Let $C$ denote the set of queues that contribute to the potential function, i.e. queues $i$ such that $N_i > \lambda_i T$. We can now express the potential function as $\Phi = \sum\limits_{i \in C} (N_i - \alpha\lambda_i T)$. It is evident that $\Phi$ must be less than the total buildup in the queues, which is $\sum_{i=1}^n N_i$. After a window of $T$ iterations, the expected total buildup $B_T$ can be expressed in terms of the buildup at the start of the window, the arrival rates of the queues, and the number of packets cleared (for this section, $N_i$ refers to the buildup at the start of the window):

% \begin{align*}
%      B_T &= \sum_{i=1} (N_i + \lambda_i T) - \sum_{j=1}^m a_j \\
%     & = \sum_{i \in C} (N_i + \lambda_i T) + \sum_{i \not\in C} (N_i + \lambda_i T) - \sum_{j=1}^m a_j
% \end{align*}

% \noindent
% For all $i \not\in C$, $N_i \leq \alpha\lambda_i T$, so $N_i + \lambda_i T \leq (1+\alpha)\lambda_i T$. Also, Theorem 1 tells us that $\sum_{j=1}^m a_j > cx\sum_{i=1}^n \lambda_i T$. Together, these inequalities give us an upper bound on $B_T$:

% $$B_T < \sum_{i\in C} N_i + \lambda_i T + (1+\alpha)\sum_{i \not\in C} \lambda_i T - cx\sum_{i=1}^n \lambda_i T$$

% Now, choosing $cx \geq (1+\alpha)$, this allows us to bound $\Phi_T$:
% \aacomment{3rd line too long, where should it be split?}
% \begin{eqnarray*}
%     \Phi_T &\leq& B_T\\
%     &<& \sum_{i\in C} (N_i + \lambda_i T) + (1+\alpha)\sum_{i \not\in C} \lambda_i T - cx\sum_{i=1}^n \lambda_i T\\
%     &=& \sum_{i\in C} (N_i + \lambda_i T) + (1+\alpha)\sum_{i \not\in C} \lambda_i T \\
%     &&- cx\sum_{i\in C}^n \lambda_i T - cx\sum_{i \not\in C} \lambda_i T\\
%     &\leq& \sum_{i \in C} (N_i - \alpha\lambda_i T)\\
%     &=& \Phi_0
% \end{eqnarray*}

% Therefore, $\Phi_T < \Phi_0$.
% \vspace{5pt}

% \noindent
% \textbf{Case 2.} Assume that the conditions for Theorem 1 do not hold, so there is at least one server which is empty $\geq x$ amount of the time. Due to no-regret, it must be the case that each queue experiences an average packet acceptance rate of $x$ or better. Otherwise, they would have done better by always sending to the this server, violating the no-regret guarantee. \jmcomment{I imagine we will have to formalize this a little more}. First, we find an expression for the worst case buildup each queue can experience during a window of $T$ iterations. We then use this to show that the potential function is non-increasing in expectation.

% \paragraph{Worst case buildup:} When $N_i + \lambda_i T$ is large enough, a queue will send a packet every iteration, or $T$ total packets. In this case, to experience an average clearing rate of at least $x$, $xT$ or more packets must clear. By assumption, $\lambda_i < x$ for all $i$, so $xT > \lambda_i T$. Since the queue cleared more packets than the number of new arrivals, it must be that it also cleared some of its buildup, meaning $N_i^* < N_i$.
% \vspace{5pt}
% \noindent
% Now assume that a queue sends less than $T$ total packets. In the worst case, there must be a period of time $\hat T$ at the end of the $T$ iterations during which the queue always sends a packet. Otherwise, the queue would have cleared all of its packets and its buildup would necessarily be less than if it had failed repeatedly. Let $Y$ be the number of packets cleared during $\hat T$ Using the lowest possible average clearing rate of $x$, we have

% $$\frac{N_i + \lambda_i(T-\hat T) + Y}{N_i + \lambda_i(T-\hat T) + \hat T} = x$$ 

% This allows us to express $\hat T$ as a function of $Y$:
% \begin{align*}
%     &xN_i + x\lambda_iT - x\lambda_i\hat T + x\hat T = N_i + \lambda_i T - \lambda_i \hat T + Y \\
%     & \iff T(Y) = \frac{N_i + \lambda_i T + Y - xN_i + x\lambda_i T}{x + \lambda_i - x\lambda_i}. 
% \end{align*}
% Thus, $\frac{d}{dY} \hat T(Y) = \frac{1}{x + \lambda_i - x\lambda_i}$.

% \vspace{5pt}
% Since we are considering the worst case for packet buildup, we want to minimize the expression $\lambda_i \hat T(Y) - Y$, which is the total buildup at the end of the $T$ iterations. Differentiating with respect to $Y$ gives us $\lambda_i \frac{d}{dY}\hat T(Y) - 1 = \frac{1}{x + \lambda_i - x\lambda_i} - 1 < 0$. Since the expression is decreasing in $Y$, setting it as low as possible will minimize the expression. Thus, $Y= 0$ produces the worst case package buildup. Therefore, we use the expression with this value of $Y$ from now on:
% \aacomment{also not sure how to split up this one}
% \begin{align*}
%     \frac{N_i + \lambda_i(T-\hat T) + Y}{N_i + \lambda_i(T-\hat T) + \hat T} &= x
%      \iff \\(1-x)(N_i + \lambda_i(T-\hat T)) &= x\hat T \  \mathrm{and} \\ \ N_i + \lambda_i(T-\hat T) &\leq T - \hat T
% \end{align*}


% The equality ensures an average clearing rate of exactly $x$, while the inequality enforces the intuitive condition that there must be enough iterations to clear the packets sent. \jmcomment{The inequality isn't explicitly used, but it implicitly imposes restrictions on $x$.}

% Rearranging, we see that $\hat T = (N_i+\lambda_i T)\frac{1-x}{\lambda_i(1-x) + x}$, so the worst-case expected buildup of packets for each queue is $B_i := \lambda_i \hat T = \displaystyle (N_i\lambda_i+\lambda_i^2 T)\frac{1-x}{\lambda_i(1-x) + x}$

% \paragraph{Non-increasing potential function:} Note that, when considering the change in the potential function evaluated at the start of one time period ($T$ iterations) to the beginning of the next, the buildup of packets during the first one, $B_i$, is the value for $N_i$ during the next, which we write as $N_i^*$. In other words, $B_i = N_i^*$, so if $B_i \leq N_i$, the term $(N_i - \lambda_i T)^+$ will not increase from one time period to the next, as $(N_i^* - \lambda_i T) \leq (N_i - \lambda_i T)$. Using the expression for $B_i$ found above,


% \begin{align*}
%     B_i &\geq N_i \iff\\
%     (N_i\lambda_i+\lambda_i^2 T)\frac{1-x}{\lambda_i(1-x) + x} &\geq N_i \iff\\
%     N_i\lambda_i + \lambda_i^2 T- xN_i\lambda_i - x\lambda_i^2T &\geq N_i\lambda_i - xN_i\lambda_i + xN_i\iff\\
%     \lambda_i^2 T - x\lambda_i^2 T &\geq xN_i\iff\\
%     N_i &\leq \frac{1-x}{x}\lambda_i^2 T
% \end{align*}

% \noindent
% This tells us that, given $N_i > \frac{1-x}{x}\lambda_i^2 T$, $B_i < N_i$. However, if $N_i \leq \frac{1-x}{x}\lambda_i^2 T$, 

% \begin{align*}
%     B_i &= (N_i\lambda_i + \lambda_i^2 T)\frac{1-x}{\lambda_i(1-x) + x}\\
%     &\leq \left(\frac{1-x}{x}\lambda_i^3 T + \lambda_i^2 T\right)\frac{1-x}{\lambda_i(1-x) + x}\\
%     &= \lambda_i^2T\left(\frac{\lambda_i(1-x)}{x} + 1\right)\frac{1-x}{\lambda_i(1-x) + x}\\
%     &= \lambda_i^2 T\frac{1-x}{x}\\
% \end{align*}

% In order to guarantee that the potential function does not increase, we want to have $B_i = \lambda_i^2 T\frac{1-x}{x} < \alpha\lambda_i T$, which is true for $\alpha > \frac{1-x}{x}\lambda_i$ As $\lambda_i < x$ for all $i$, $\alpha > 1 - x$ is enough to ensure this. Thus, using an appropriate $\alpha$, even if $N_i$ increases, at the start of the next time period the term $B_i - \lambda_i T = N_i^* - \lambda_i T < 0$, so $(N_i - \lambda_i T)^+$ does not increase. Either way, for all $i$, $(N_i - \lambda_i T)^+$ is not increasing in expectation. It follows that $\Phi_T \leq \Phi_0$. In fact, if $N_i > \lambda_i^2 T\frac{1-x}{x}$ for any $i$, $N_i^* = B_i < N_i$, so we would have $\Phi_T < \Phi_0$. 

% \end{proof}

While we do not know if the factor of 3 in the main theorem is a tight worst-case bound even when arrival rates $\lambda_i$ are close to $\frac12$ (in which case $\sum_i (\lambda_i +\lambda_i^2)=\sum_i \lambda_i(1 +\lambda_i) = \frac{3}{2}\sum_i \lambda_i$ yields this factor), the following example shows that we need at least a factor of 2 to ensure stability. 

\begin{theorem}\label{thm:lower-bound-example} [Lower Bound Example]
Consider a queue with $1/2$ arrival rate, facing $k$ servers, each with only capacity $1/n$. Assume that the server is choosing a uniform random server at each step. This sending plan will clearly satisfy the no-regret condition of Condition \ref{con:learning}. We claim that we need at least $n$ servers to make the solution stable proving a lower bound of 2 needed for the needed increase in server capacity. 
\end{theorem}
\begin{proof}
So with $k$ servers, the chance that when the queue sends to a server, the previous time it did so was $i$ steps ago is $1/k \cdot (1-1/k)^{i-1}$. If the previous time the queue did sent there, the chance that the server is still busy is $(1-1/n)^i$, so the chance that the new packet gets accepted is
\begin{eqnarray*}
&& \sum_{i=1}^{\infty}    1/k \cdot (1-1/k)^{i-1} (1-(1-1/n)^i)\\
&=& \frac{1}{k}\sum_{i=1} (1-\frac{1}{k})^{i-1}-\frac{n-1}{nk}\sum_{i=1}^{\infty} ((1-\frac{1}{k})(1-\frac{1}{n}))^{i-1}\\
&=& 1-\frac{n-1}{nk}\frac{1}{1-(1-1/k)(1-1/n)}
%&=&1-\frac{n-1}{nk}\frac{nk}{n+k-1}
=1-\frac{n-1}{n+k-1}
\end{eqnarray*}
To make this stable we need this value to be above $1/2$, so we need %$\frac{n-1}{n+k-1}$ to be below $1/2$. This means, we need 
$k>n-1$. This results in a total capacity of $\frac{k}{n}>\frac{n-1}{n}$, essentially double the arrival rate of the queue.
\end{proof}

% Note that the queue can do better even without full information on the state of the servers. For example, if instead of choosing servers uniformly random, we use round robin scheduling, then we get the exactly $k$ times before repeating the same server, resulting in the success rate of $(1-(1-1/n)^k$. If we use $k=xn$, than we get the success rate of $1-(1-1/n)^{xn}\approx (1-e^{-x})$. To get this to be at least $1/2$ all we need is $e^{-x}<1/2$, which is that $x>\ln 2\approx 0.7$, so a ratio of less than 1.4 of server capacity to arrival rate is enough in this example.
