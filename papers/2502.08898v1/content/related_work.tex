The classical focus of work on scheduling in queuing systems is aimed at finding schedules that achieve optimal throughput (see, e.g., the textbook of \cite{queuing_theory}). For work evaluating efficiency loss due to selfishness in different classical queuing systems, see the book of Hassin \cite{hassin2020rational} and survey of \cite{hassin2003queue}. Closer to our motivation, there is a growing literature that aims to understand how systems perform when the queues use simple learning algorithm to find good service.  \cite{DBLP:conf/nips/KrishnasamySJS16} considers a queue using a no-regret learning algorithm to find what may be the best servers, but does not consider multiple queues competing for service. Their primary goal is to study the expected size of the queue of packets as a function of time. They also extend the result to the case of multiple queues scheduled by a single coordinated scheduling algorithm, assuming there is a perfect matching between queues and optimal servers that can serve them. \cite{DBLP:conf/nips/SentenacBP21} and \cite{DBLP:conf/colt/FreundLW22} extended this work to decentralized learning dynamics in bipartite queuing systems that attain near-optimal performance without the matching assumption. For a survey on the role of learning and information in queuing systems see \cite{doi:10.1287/educ.2021.0235}. 

In our work, we focus on a game-theoretic model: queues using learning algorithms to best distribute their packets to get good service, while also competing for servers. We assume that each queue separately learns to selfishly make sure its own packets are served at the highest possible rate, offering a strategic model of scheduling packets in a queuing system. Closest to our model from this literature is the work \cite{DBLP:conf/sigecom/GaitondeT20,DBLP:journals/jacm/GaitondeT23}, who consider the same bipartite model of queues and servers as we do, but without buffers. They show the exact condition to make such a system stable with central coordination of packets and prove that no-regret learning by the queues guarantees stability of the system if it has double the capacity needed for central coordination, assuming packets carry a timestamp and servers choose the oldest packet to serve. 
 \cite{DBLP:conf/wine/FuHL22} extended this work to a general network.
 \cite{DBLP:journals/corr/abs-2302-03614}  propose an alternative, episodic queuing system where agents have incentives to hold jobs in an episode before sending to a central server, but suffer penalties should their jobs not be completed before the end of the episode. They show that both equilibrium and no-regret outcomes ensure stability, so long as these costs are sufficiently large. 

In the works discussed so far, the servers receiving the packets have no buffers: all unserved packets are held in a queue and get resent to be served later. 
In queuing systems aimed at modeling networking, the receivers (servers) each do have a very small buffer, and can hold on to a couple of packets to be served later. It turns out that even having a buffer for a single packet significantly changes the effective service capacity of the network, as already explained above. 

In the case without such buffers, it was feasible to exactly characterize the capacity needed to be able to make the system stable with central coordination by an elegant use of linear programming duality (see \cite{DBLP:conf/wine/FuHL22}). 
In the presence of limited buffer capacity at the servers, the rate at which a server accepts a packet depends on the state of the buffers. This is in contrast to a system without buffers, where the probability that a server accepts a packet is the service rate of the server, and is stable over time. There is some recent work considering queuing systems with such evolving service probabilities, see for example \cite{DBLP:journals/sigmetrics/GrosofHHS24,DBLP:journals/corr/abs-2405-04102}. The goal of that work is to characterize the exact condition that allows the system to remain stable with central coordination of the schedule. Our work is the first to consider stability in such a system assuming each queue independently aims to optimize its own service rate running a no-regret learning algorithm. 

There is a large literature on bounding the price of anarchy for various games, beginning with \cite{DBLP:conf/stacs/KoutsoupiasP99}. These results extend to analyzing outcomes in repeated games assuming players are no-regret learners \cite{DBLP:journals/siamcomp/BalcanBM13,DBLP:journals/jacm/Roughgarden15,DBLP:conf/stoc/SyrgkanisT13}. However, these works make the strong assumption that games in different rounds are independent. By contrast, different rounds in queuing games are not independent: the number of packets in the system depends on the success in previous periods. Work on games with carryover effects, or context, are considered in multi-agent reinforcement learning as well as in Markov games, see for example \cite{littman1994markov,busoniu2008comprehensive,zhang2021multi}. However, this line of work does not focus on the overall quality of learning outcomes. Another line of work on repeated games with such carryover effect between rounds, focusing on such overall learning outcomes, is the repeated ad-auction game with limited budgets, where the remaining budgets make the games no longer independent. See  
for example \cite{DBLP:journals/mansci/BalseiroG19,DBLP:conf/innovations/GaitondeLLLS23,fikioris2023liquid,fikioris2024learning}. 
