% This file was created with JabRef 2.10.
% Encoding: UTF-8

@article{tiboni2023domain,
  title={Domain Randomization via Entropy Maximization},
  author={Tiboni, Gabriele and Klink, Pascal and Peters, Jan and Tommasi, Tatiana and D'Eramo, Carlo and Chalvatzaki, Georgia},
  journal={arXiv preprint arXiv:2311.01885},
  year={2023}
}

@article{tiboni2023dropo,
  title={DROPO: Sim-to-real transfer with offline domain randomization},
  author={Tiboni, Gabriele and Arndt, Karol and Kyrki, Ville},
  journal={Robotics and Autonomous Systems},
  volume={166},
  pages={104432},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{pinto2018asymmetric,
  title={Asymmetric Actor Critic for Image-Based Robot Learning},
  author={Pinto, Lerrel and Andrychowicz, Marcin and Welinder, Peter and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={14th Robotics: Science and Systems, RSS 2018},
  year={2018},
  organization={MIT Press Journals}
}

@inproceedings{haarnojasac,
  author       = {Tuomas Haarnoja and
                  Aurick Zhou and
                  Pieter Abbeel and
                  Sergey Levine},
  title        = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
                  with a Stochastic Actor},
  booktitle    = {ICML},
  year         = {2018},
  url          = {http://proceedings.mlr.press/v80/haarnoja18b.html}
}

@inproceedings{li21horizon,
  author       = {Yuanzhi Li and
                  Ruosong Wang and
                  Lin F. Yang},
  title        = {Settling the Horizon-Dependence of Sample Complexity in Reinforcement
                  Learning},
  booktitle    = {62nd {IEEE} Annual Symposium on Foundations of Computer Science, {FOCS}
                  2021, Denver, CO, USA, February 7-10, 2022},
  pages        = {965--976},
  publisher    = {{IEEE}},
  year         = {2021},
  url          = {https://doi.org/10.1109/FOCS52979.2021.00097},
  doi          = {10.1109/FOCS52979.2021.00097},
  timestamp    = {Sat, 30 Sep 2023 09:41:24 +0200},
  biburl       = {https://dblp.org/rec/conf/focs/LiWY21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{laidlaw2023bridging,
  title={Bridging RL Theory and Practice with the Effective Horizon},
  author={Laidlaw, Cassidy and Russell, Stuart J. and Dragan, Anca},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  pages={58953--59007},
  year={2023}
}

@article{torne24rialto,
  author       = {Marcel Torne and
                  Anthony Simeonov and
                  Zechu Li and
                  April Chan and
                  Tao Chen and
                  Abhishek Gupta and
                  Pulkit Agrawal},
  title        = {Reconciling Reality through Simulation: {A} Real-to-Sim-to-Real Approach
                  for Robust Manipulation},
  journal      = {CoRR},
  volume       = {abs/2403.03949},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2403.03949},
  doi          = {10.48550/ARXIV.2403.03949},
  eprinttype    = {arXiv},
  eprint       = {2403.03949},
  timestamp    = {Mon, 29 Jul 2024 16:18:15 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2403-03949.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{procthor,
  author       = {Matt Deitke and
                  Eli VanderBilt and
                  Alvaro Herrasti and
                  Luca Weihs and
                  Kiana Ehsani and
                  Jordi Salvador and
                  Winson Han and
                  Eric Kolve and
                  Aniruddha Kembhavi and
                  Roozbeh Mottaghi},
  title        = {Proc{THOR}: Large-Scale Embodied
                  {AI} Using Procedural Generation},
  booktitle    = {Advances in Neural Information Processing Systems 35: Annual Conference
                  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,
                  LA, USA, November 28 - December 9, 2022},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/27c546ab1e4f1d7d638e6a8dfbad9a07-Abstract-Conference.html},
}

@article{chen2024urdformer,
  title={URDFormer: A Pipeline for Constructing Articulated Simulation Environments from Real-World Images},
  author={Zoey Chen and Aaron Walsman and Marius Memmel and Kaichun Mo and Alex Fang and Karthikeya Vemuri and Alan Wu and Dieter Fox and Abhishek Gupta},
  journal={arXiv preprint arXiv:2405.11656},
  year={2024}
}

@inproceedings{huang23compass,
  author       = {Peide Huang and
                  Xilun Zhang and
                  Ziang Cao and
                  Shiqi Liu and
                  Mengdi Xu and
                  Wenhao Ding and
                  Jonathan Francis and
                  Bingqing Chen and
                  Ding Zhao},
  editor       = {Jie Tan and
                  Marc Toussaint and
                  Kourosh Darvish},
  title        = {What Went Wrong? Closing the Sim-to-Real Gap via Differentiable Causal
                  Discovery},
  booktitle    = {Conference on Robot Learning, CoRL 2023, 6-9 November 2023, Atlanta,
                  GA, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {229},
  pages        = {734--760},
  publisher    = {{PMLR}},
  year         = {2023},
  url          = {https://proceedings.mlr.press/v229/huang23c.html},
  timestamp    = {Tue, 20 Feb 2024 17:19:52 +0100},
  biburl       = {https://dblp.org/rec/conf/corl/HuangZCLXDFCZ23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{gupta21rs,
  author       = {Abhishek Gupta and
                  Aldo Pacchiano and
                  Yuexiang Zhai and
                  Sham M. Kakade and
                  Sergey Levine},
  title        = {Unpacking Reward Shaping: Understanding the Benefits of Reward Engineering
                  on Sample Complexity},
  booktitle    = {NeurIPS},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/6255f22349da5f2126dfc0b007075450-Abstract-Conference.html}
}


@article{dota2,
  author       = {Christopher Berner and
                  Greg Brockman and
                  Brooke Chan and
                  Vicki Cheung and
                  Przemyslaw Debiak and
                  Christy Dennison and
                  David Farhi and
                  Quirin Fischer and
                  Shariq Hashme and
                  Christopher Hesse and
                  Rafal J{\'{o}}zefowicz and
                  Scott Gray and
                  Catherine Olsson and
                  Jakub Pachocki and
                  Michael Petrov and
                  Henrique Pond{\'{e}} de Oliveira Pinto and
                  Jonathan Raiman and
                  Tim Salimans and
                  Jeremy Schlatter and
                  Jonas Schneider and
                  Szymon Sidor and
                  Ilya Sutskever and
                  Jie Tang and
                  Filip Wolski and
                  Susan Zhang},
  title        = {Dota 2 with Large Scale Deep Reinforcement Learning},
  journal      = {CoRR},
  volume       = {abs/1912.06680},
  year         = {2019},
  url          = {http://arxiv.org/abs/1912.06680},
  eprinttype    = {arXiv},
  eprint       = {1912.06680},
  timestamp    = {Wed, 03 Jun 2020 10:56:28 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1912-06680.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{margolisrapid,
  author       = {Gabriel B. Margolis and
                  Ge Yang and
                  Kartik Paigwar and
                  Tao Chen and
                  Pulkit Agrawal},
  title        = {Rapid locomotion via reinforcement learning},
  journal      = {Int. J. Robotics Res.},
  volume       = {43},
  number       = {4},
  pages        = {572--587},
  year         = {2024},
  url          = {https://doi.org/10.1177/02783649231224053},
  doi          = {10.1177/02783649231224053},
  timestamp    = {Sun, 02 Jun 2024 13:06:46 +0200},
  biburl       = {https://dblp.org/rec/journals/ijrr/MargolisYPCA24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{cherrypick,
  author       = {Yunchu Zhang and
                  Liyiming Ke and
                  Abhay Deshpande and
                  Abhishek Gupta and
                  Siddhartha S. Srinivasa},
  title        = {Cherry-Picking with Reinforcement Learning},
  booktitle    = {RSS},
  year         = {2023},
}

@inproceedings{smith22legged,
  author       = {Laura M. Smith and
                  J. Chase Kew and
                  Xue Bin Peng and
                  Sehoon Ha and
                  Jie Tan and
                  Sergey Levine},
  title        = {Legged Robots that Keep on Learning: Fine-Tuning Locomotion Policies
                  in the Real World},
  booktitle    = {ICRA},
  year         = {2022},
}

@inproceedings{yu17prep,
  author       = {Wenhao Yu and
                  Jie Tan and
                  C. Karen Liu and
                  Greg Turk},
  title        = {Preparing for the Unknown: Learning a Universal Policy with Online
                  System Identification},
  booktitle    = {RSS},
  year         = {2017},
  url          = {http://www.roboticsproceedings.org/rss13/p48.html}
}

@inproceedings{haozhirma,
  author       = {Haozhi Qi and
                  Ashish Kumar and
                  Roberto Calandra and
                  Yi Ma and
                  Jitendra Malik},
  title        = {In-Hand Object Rotation via Rapid Motor Adaptation},
  booktitle    = {CoRL},
  year         = {2022},
  url          = {https://proceedings.mlr.press/v205/qi23a.html}
}

@inproceedings{rma,
  author       = {Ashish Kumar and
                  Zipeng Fu and
                  Deepak Pathak and
                  Jitendra Malik},
  title        = {{RMA:} Rapid Motor Adaptation for Legged Robots},
  booktitle    = {RSS},
  year         = {2021}
}

@article{memmel24asid,
  author       = {Marius Memmel and
                  Andrew Wagenmaker and
                  Chuning Zhu and
                  Patrick Yin and
                  Dieter Fox and
                  Abhishek Gupta},
  title        = {{ASID:} Active Exploration for System Identification in Robotic Manipulation},
  journal      = {CoRR},
  volume       = {abs/2404.12308},
  year         = {2024},
}

@inproceedings{ramos19bayessim,
  author       = {Fabio Ramos and
                  Rafael Possas and
                  Dieter Fox},
  title        = {BayesSim: Adaptive Domain Randomization Via Probabilistic Inference
                  for Robotics Simulators},
  booktitle    = {RSS},
  year         = {2019}
}

@inproceedings{chebotar19close,
  author       = {Yevgen Chebotar and
                  Ankur Handa and
                  Viktor Makoviychuk and
                  Miles Macklin and
                  Jan Issac and
                  Nathan D. Ratliff and
                  Dieter Fox},
  title        = {Closing the Sim-to-Real Loop: Adapting Simulation Randomization with
                  Real World Experience},
  booktitle    = {ICRA},
  year         = {2019},
}

@article{chen2023visual,
    author = {Tao Chen  and Megha Tippur  and Siyang Wu  and Vikash Kumar  and Edward Adelson  and Pulkit Agrawal },
    title = {Visual dexterity: In-hand reorientation of novel and complex object shapes},
    journal = {Science Robotics},
    volume = {8},
    number = {84},
    pages = {eadc9244},
    year = {2023},
    doi = {10.1126/scirobotics.adc9244},
    URL = {https://www.science.org/doi/abs/10.1126/scirobotics.adc9244},
    eprint = {https://www.science.org/doi/pdf/10.1126/scirobotics.adc9244},
}

@inproceedings{retingan,
  author       = {Daniel Ho and
                  Kanishka Rao and
                  Zhuo Xu and
                  Eric Jang and
                  Mohi Khansari and
                  Yunfei Bai},
  title        = {RetinaGAN: An Object-aware Approach to Sim-to-Real Transfer},
  booktitle    = {{IEEE} International Conference on Robotics and Automation, {ICRA}
                  2021, Xi'an, China, May 30 - June 5, 2021},
  pages        = {10920--10926},
  publisher    = {{IEEE}},
  year         = {2021},
  url          = {https://doi.org/10.1109/ICRA48506.2021.9561157},
  doi          = {10.1109/ICRA48506.2021.9561157},
  timestamp    = {Mon, 25 Oct 2021 11:20:08 +0200},
  biburl       = {https://dblp.org/rec/conf/icra/HoRXJKB21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{James2019SimToReal,
  title={Sim-to-Real via Sim-to-Sim: Data-efficient Robotic Grasping via Randomized-to-Canonical Adaptation Networks},
  author={Stephen James and Paul Wohlhart and Mrinal Kalakrishnan and Dmitry Kalashnikov and Alex Irpan and Julian Ibarz and Sergey Levine and Raia Hadsell and Konstantinos Bousmalis},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019},
  pages={12619-12629},
  url={https://openaccess.thecvf.com/content_CVPR_2019/papers/James_Sim-To-Real_via_Sim-To-Sim_Data-Efficient_Robotic_Grasping_via_Randomized-To-Canonical_Adaptation_Networks_CVPR_2019_paper.pdf}
}

@Article{Gauss1857,
  Title                    = {Theory of the motion of the heavenly bodies moving about the sun in conic sections},
  Author                   = {Carl Friedrich Gauss and Charles Henry Davis},
  Journal                  = {Gauss's Theoria Motus},
  Year                     = {1857},
  Number                   = {1},
  Pages                    = {5--23},
  Volume                   = {76}
}

@Book{Lagrange1788,
  title		= {M{\'e}canique Analytique},
  author	= {Joseph-Louis Lagrange},
  publisher	= {Desaint, Paris},
  year		= {1788}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={IROS},
  year={2012},
}

@inproceedings{walke2023bridgedata,
    title={BridgeData V2: A Dataset for Robot Learning at Scale},
    author={Walke, Homer and Black, Kevin and Lee, Abraham and Kim, Moo Jin and Du, Max and Zheng, Chongyi and Zhao, Tony and Hansen-Estruch, Philippe and Vuong, Quan and He, Andre and Myers, Vivek and Fang, Kuan and Finn, Chelsea and Levine, Sergey},
    booktitle={Conference on Robot Learning (CoRL)},
    year={2023}
}

@inproceedings{embodimentcollaboration2024open,
      title={Open X-Embodiment: Robotic Learning Datasets and RT-X Models}, 
      author={Open-X-Embodiment Collaboration},
      booktitle={ICRA},
      year={2024}
}

@inproceedings{khazatsky2024droid,
    title   = {DROID: A Large-Scale In-The-Wild Robot Manipulation Dataset},
    author  = {DROID Collaboration team},
    booktitle={Robotics Science and Systems (RSS)},
    year    = {2024},
}

 @inproceedings{mandlekar2018roboturk,
          title={Roboturk: A crowdsourcing platform for robotic skill learning through imitation},
          author={Mandlekar, Ajay and Zhu, Yuke and Garg, Animesh and Booher, Jonathan and Spero, Max and Tung, Albert and Gao, Julian and Emmons, John and Gupta, Anchit and Orbay, Emre and others},
          booktitle={Conference on Robot Learning},
          year={2018}
        }

@INPROCEEDINGS{mujoco,
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={IROS}, 
  title={MuJoCo: A physics engine for model-based control}, 
  year={2012}
}

@inproceedings{makoviychuk2021isaac,
      title={Isaac Gym: High Performance GPU-Based Physics Simulation For Robot Learning}, 
      author={Viktor Makoviychuk and Lukasz Wawrzyniak and Yunrong Guo and Michelle Lu and Kier Storey and Miles Macklin and David Hoeller and Nikita Rudin and Arthur Allshire and Ankur Handa and Gavriel State},
        booktitle={NeurIPS-2021 Datasets and Benchmarks Track},
      year={2021}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={Icml},
  volume={99},
  pages={278--287},
  year={1999}
}

% Perception Sim2Real 
@inproceedings{tobin2017domain,
    title={Domain randomization for transferring deep neural networks from simulation to the real world},
    author={Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
    booktitle={IROS},
    year={2017},
}


@inproceedings{nair2023r3m,
  title={R3M: A Universal Visual Representation for Robot Manipulation},
  author={Nair, Suraj and Rajeswaran, Aravind and Kumar, Vikash and Finn, Chelsea and Gupta, Abhinav},
  booktitle={CoRL},
  year={2023}
}

@article{torne2024reconciling,
  title={Reconciling reality through simulation: A real-to-sim-to-real approach for robust manipulation},
  author={Torne, Marcel and Simeonov, Anthony and Li, Zechu and Chan, April and Chen, Tao and Gupta, Abhishek and Agrawal, Pulkit},
  journal={arXiv preprint arXiv:2403.03949},
  year={2024}
}

# RL Finetuning
@INPROCEEDINGS{Rajeswaran-RSS-18,
    AUTHOR    = {Aravind Rajeswaran AND Vikash Kumar AND Abhishek Gupta AND
                 Giulia Vezzani AND John Schulman AND Emanuel Todorov AND Sergey Levine},
    TITLE     = "{Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations}",
    BOOKTITLE = {Proceedings of Robotics: Science and Systems (RSS)},
    YEAR      = {2018},
}

@article{nair2020awac,
  title={Awac: Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@inproceedings{kostrikov2021offline,
  title={Offline Reinforcement Learning with Implicit Q-Learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{hu2023imitation,
  title={Imitation bootstrapped reinforcement learning},
  author={Hu, Hengyuan and Mirchandani, Suvir and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2311.02198},
  year={2023}
}

@article{nakamoto2024cal,
  title={Cal-ql: Calibrated offline rl pre-training for efficient online fine-tuning},
  author={Nakamoto, Mitsuhiko and Zhai, Simon and Singh, Anikait and Sobol Mark, Max and Ma, Yi and Finn, Chelsea and Kumar, Aviral and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

# Rewards
@inproceedings{ziebart2008maxentirl,
author = {Ziebart, Brian D. and Maas, Andrew and Bagnell, J. Andrew and Dey, Anind K.},
title = {Maximum entropy inverse reinforcement learning},
year = {2008},
isbn = {9781577353683},
publisher = {AAAI Press},
abstract = {Recent research has shown the benefit of framing problems of imitation learning as solutions to Markov Decision Problems. This approach reduces learning to the problem of recovering a utility function that makes the behavior induced by a near-optimal policy closely mimic demonstrated behavior. In this work, we develop a probabilistic approach based on the principle of maximum entropy. Our approach provides a well-defined, globally normalized distribution over decision sequences, while providing the same performance guarantees as existing methods.We develop our technique in the context of modeling real-world navigation and driving behaviors where collected data is inherently noisy and imperfect. Our probabilistic approach enables modeling of route preferences as well as a powerful new approach to inferring destinations and routes based on partial trajectories.},
booktitle = {Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 3},
pages = {1433–1438},
numpages = {6},
location = {Chicago, Illinois},
series = {AAAI'08}
}

@article{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{fu2018variational,
  title={Variational inverse control with events: A general framework for data-driven reward definition},
  author={Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  journal={NeurIPS},
  year={2018}
}

@inproceedings{li2021mural,
  title={Mural: Meta-learning uncertainty-aware rewards for outcome-driven reinforcement learning},
  author={Li, Kevin and Gupta, Abhishek and Reddy, Ashwin and Pong, Vitchyr H and Zhou, Aurick and Yu, Justin and Levine, Sergey},
  booktitle={ICML},
  year={2021}
}

@article{ma2023eureka,
  title={Eureka: Human-level reward design via coding large language models},
  author={Ma, Yecheng Jason and Liang, William and Wang, Guanzhi and Huang, De-An and Bastani, Osbert and Jayaraman, Dinesh and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2310.12931},
  year={2023}
}

@article{yu2023language,
  title={Language to rewards for robotic skill synthesis},
  author={Yu, Wenhao and Gileadi, Nimrod and Fu, Chuyuan and Kirmani, Sean and Lee, Kuang-Huei and Arenas, Montse Gonzalez and Chiang, Hao-Tien Lewis and Erez, Tom and Hasenclever, Leonard and Humplik, Jan and others},
  journal={arXiv preprint arXiv:2306.08647},
  year={2023}
}

# MBRL
# [MILO, METRPO]
@article{sutton1991dyna,
author = {Sutton, Richard S.},
title = {Dyna, an integrated architecture for learning, planning, and reacting},
year = {1991},
issue_date = {Aug. 1991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {0163-5719},
url = {https://doi.org/10.1145/122344.122377},
doi = {10.1145/122344.122377},
abstract = {Dyna is an AI architecture that integrates learning, planning, and reactive execution. Learning methods are used in Dyna both for compiling planning results and for updating a model of the effects of the agent's actions on the world. Planning is incremental and can use the probabilistic and ofttimes incorrect world models generated by learning processes. Execution is fully reactive in the sense that no planning intervenes between perception and action. Dyna relies on machine learning methods for learning from examples---these are among the basic building blocks making up the architecture---yet is not tied to any particular method. This paper briefly introduces Dyna and discusses its strengths and weaknesses with respect to other architectures.},
journal = {SIGART Bull.},
month = {jul},
pages = {160–163},
numpages = {4}
}

@article{wang2019exploring,
  title={Exploring model-based planning with policy networks},
  author={Wang, Tingwu and Ba, Jimmy},
  journal={arXiv preprint arXiv:1906.08649},
  year={2019}
}

@article{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14129--14142},
  year={2020}
}
@article{sun2018truncated,
  title={Truncated horizon policy search: Combining reinforcement learning \& imitation learning},
  author={Sun, Wen and Bagnell, J Andrew and Boots, Byron},
  journal={arXiv preprint arXiv:1805.11240},
  year={2018}
}

@article{brogliato2007dissipative,
  title={Dissipative systems analysis and control},
  author={Brogliato, Bernard and Lozano, Rogelio and Maschke, Bernhard and Egeland, Olav and others},
  publisher={Springer}
}

@article{yang2023learning,
  title={Learning interactive real-world simulators},
  author={Yang, Mengjiao and Du, Yilun and Ghasemipour, Kamyar and Tompson, Jonathan and Schuurmans, Dale and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2310.06114},
  year={2023}
}

@article{wolczyk2024fine,
  title={Fine-tuning Reinforcement Learning Models is Secretly a Forgetting Mitigation Problem},
  author={Wo{\l}czyk, Maciej and Cupia{\l}, Bart{\l}omiej and Ostaszewski, Mateusz and Bortkiewicz, Micha{\l} and Zajkac, Michal and Pascanu, Razvan and Kucinski, Lukasz and Milo's, Piotr},
  journal={arXiv preprint arXiv:2402.02868},
  year={2024}
}

@article{zhou2024efficient,
  title={Efficient Online Reinforcement Learning Fine-Tuning Need Not Retain Offline Data},
  author={Zhou, Zhiyuan and Peng, Andy and Li, Qiyang and Levine, Sergey and Kumar, Aviral},
  journal={arXiv preprint arXiv:2412.07762},
  year={2024}
}
@article{jadbabaie2001unconstrained,
  title={Unconstrained receding-horizon control of nonlinear systems},
  journal={IEEE Transactions on Automatic Control},
  Author = {Ali Jadbabaie and  Jie Yu and and John Hauser},
  volume={46},
  number={5},
  pages={776--783},
  year={2001},
  publisher={IEEE}
}


@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}
@inproceedings{du2021auto,
  title={Auto-tuned sim-to-real transfer},
  author={Du, Yuqing and Watkins, Olivia and Darrell, Trevor and Abbeel, Pieter and Pathak, Deepak},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1290--1296},
  year={2021},
  organization={IEEE}
}

@inproceedings{bruce2024genie,
  title={Genie: Generative interactive environments},
  author={Bruce, Jake and Dennis, Michael D and Edwards, Ashley and Parker-Holder, Jack and Shi, Yuge and Hughes, Edward and Lai, Matthew and Mavalankar, Aditi and Steigerwald, Richie and Apps, Chris and others},
  booktitle={Forty-first International Conference on Machine Learning}
}


@article{yang2023learning,
  title={Learning interactive real-world simulators},
  author={Yang, Mengjiao and Du, Yilun and Ghasemipour, Kamyar and Tompson, Jonathan and Schuurmans, Dale and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2310.06114},
  year={2023}
}


@article{chen2021randomized,
  title={Randomized ensembled double q-learning: Learning fast without a model},
  author={Chen, Xinyue and Wang, Che and Zhou, Zijian and Ross, Keith},
  journal={arXiv preprint arXiv:2101.05982},
  year={2021}
}
@article{hiraoka2021dropout,
  title={Dropout q-functions for doubly efficient reinforcement learning},
  author={Hiraoka, Takuya and Imagawa, Takahisa and Hashimoto, Taisei and Onishi, Takashi and Tsuruoka, Yoshimasa},
  journal={arXiv preprint arXiv:2110.02034},
  year={2021}
}

@inproceedings{gu2016continuous,
  title={Continuous deep q-learning with model-based acceleration},
  author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={2829--2838},
  year={2016},
  organization={PMLR}
}

@inproceedings{
levy2024learning,
title={Learning to Walk from Three Minutes of Data with Semi-structured Dynamics Models},
author={Jacob Levy and Tyler Westenbroek and David Fridovich-Keil},
booktitle={8th Annual Conference on Robot Learning},
year={2024},
url={https://openreview.net/forum?id=evCXwlCMIi}
}

@article{acosta2022validating,
  title={Validating robotics simulators on real-world impacts},
  author={Acosta, Brian and Yang, William and Posa, Michael},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={3},
  pages={6471--6478},
  year={2022},
  publisher={IEEE}
}

@article{liu2022dara,
  title={Dara: Dynamics-aware reward augmentation in offline reinforcement learning},
  author={Liu, Jinxin and Zhang, Hongyin and Wang, Donglin},
  journal={arXiv preprint arXiv:2203.06662},
  year={2022}
}
@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{williams2017model,
  title={Model predictive path integral control: From theory to parallel computation},
  author={Williams, Grady and Aldrich, Andrew and Theodorou, Evangelos A},
  journal={Journal of Guidance, Control, and Dynamics},
  volume={40},
  number={2},
  pages={344--357},
  year={2017},
  publisher={American Institute of Aeronautics and Astronautics}
}

@inproceedings{hafner2019learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle={International conference on machine learning},
  pages={2555--2565},
  year={2019},
  organization={PMLR}
}

@inproceedings{zhang2019solar,
  title={Solar: Deep structured representations for model-based reinforcement learning},
  author={Zhang, Marvin and Vikram, Sharad and Smith, Laura and Abbeel, Pieter and Johnson, Matthew and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={7444--7453},
  year={2019},
  organization={PMLR}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@article{eysenbach2020off,
  title={Off-dynamics reinforcement learning: Training for transfer with domain classifiers},
  author={Eysenbach, Benjamin and Asawa, Swapnil and Chaudhari, Shreyas and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2006.13916},
  year={2020}
}


@inproceedings{ball2023efficient,
  title={Efficient online reinforcement learning with offline data},
  author={Ball, Philip J and Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1577--1594},
  year={2023},
  organization={PMLR}
}

@article{smith2022walk,
  title={A walk in the park: Learning to walk in 20 minutes with model-free reinforcement learning},
  author={Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2208.07860},
  year={2022}
}
@inproceedings{peng2018sim,
  title={Sim-to-real transfer of robotic control with dynamics randomization},
  author={Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={3803--3810},
  year={2018},
  organization={IEEE}
}

@article{lee2020learning,
  title={Learning quadrupedal locomotion over challenging terrain},
  author={Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
  journal={Science robotics},
  volume={5},
  number={47},
  pages={eabc5986},
  year={2020},
  publisher={American Association for the Advancement of Science}
}

@article{niu2022trust,
  title={When to trust your simulator: Dynamics-aware hybrid offline-and-online reinforcement learning},
  author={Niu, Haoyi and Qiu, Yiwen and Li, Ming and Zhou, Guyue and Hu, Jianming and Zhan, Xianyuan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36599--36612},
  year={2022}
}

@article{xu2023cross,
  title={Cross-domain policy adaptation via value-guided data filtering},
  author={Xu, Kang and Bai, Chenjia and Ma, Xiaoteng and Wang, Dong and Zhao, Bin and Wang, Zhen and Li, Xuelong and Li, Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={73395--73421},
  year={2023}
}

@article{wang2022dynamic,
  title={Dynamic analysis of simple pendulum model under variable damping},
  author={Wang, Jin and Xue, Qilong and Li, Lixin and Liu, Baolin and Huang, Leilei and Chen, Yang},
  journal={Alexandria Engineering Journal},
  volume={61},
  number={12},
  pages={10563--10575},
  year={2022},
  publisher={Elsevier}
}

@article{westenbroek2022lyapunov,
  title={Lyapunov design for robust and efficient robotic reinforcement learning},
  author={Westenbroek, Tyler and Castaneda, Fernando and Agrawal, Ayush and Sastry, Shankar and Sreenath, Koushil},
  journal={arXiv preprint arXiv:2208.06721},
  year={2022}
}

@article{grune2008infinite,
  title={On the infinite horizon performance of receding horizon controllers},
  author={Grune, Lars and Rantzer, Anders},
  journal={IEEE Transactions on Automatic Control},
  volume={53},
  number={9},
  pages={2100--2111},
  year={2008},
  publisher={IEEE}
}

@incollection{sutton1990integrated,
  title={Integrated architectures for learning, planning, and reacting based on approximating dynamic programming},
  author={Sutton, Richard S},
  booktitle={Machine learning proceedings 1990},
  pages={216--224},
  year={1990},
  publisher={Elsevier}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{bhardwaj2020blending,
  title={Blending mpc \& value function approximation for efficient reinforcement learning},
  author={Bhardwaj, Mohak and Choudhury, Sanjiban and Boots, Byron},
  journal={arXiv preprint arXiv:2012.05909},
  year={2020}
}

@inproceedings{
hansen2024tdmpc,
title={{TD}-{MPC}2: Scalable, Robust World Models for Continuous Control},
author={Nicklas Hansen and Hao Su and Xiaolong Wang},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=Oxh5CstDJU}
}

@article{kidambi2020morel,
  title={Morel: Model-based offline reinforcement learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21810--21823},
  year={2020}
}




@article{cheng2021heuristic,
  title={Heuristic-guided reinforcement learning},
  author={Cheng, Ching-An and Kolobov, Andrey and Swaminathan, Adith},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={13550--13563},
  year={2021}
}

@inproceedings{chebotar2017combining,
  title={Combining model-based and model-free updates for trajectory-centric reinforcement learning},
  author={Chebotar, Yevgen and Hausman, Karol and Zhang, Marvin and Sukhatme, Gaurav and Schaal, Stefan and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={703--711},
  year={2017},
  organization={PMLR}
}

@inproceedings{cheng2019predictor,
  title={Predictor-corrector policy optimization},
  author={Cheng, Ching-An and Yan, Xinyan and Ratliff, Nathan and Boots, Byron},
  booktitle={International Conference on Machine Learning},
  pages={1151--1161},
  year={2019},
  organization={PMLR}
}

@inproceedings{cheng2020trajectory,
  title={Trajectory-wise control variates for variance reduction in policy gradient methods},
  author={Cheng, Ching-An and Yan, Xinyan and Boots, Byron},
  booktitle={Conference on Robot Learning},
  pages={1379--1394},
  year={2020},
  organization={PMLR}
}

@article{grathwohl2017backpropagation,
  title={Backpropagation through the void: Optimizing control variates for black-box gradient estimation},
  author={Grathwohl, Will and Choi, Dami and Wu, Yuhuai and Roeder, Geoffrey and Duvenaud, David},
  journal={arXiv preprint arXiv:1711.00123},
  year={2017}
}

@article{che2018combining,
  title={Combining model-based and model-free RL via multi-step control variates},
  author={Che, Tong and Lu, Yuchen and Tucker, George and Bhupatiraju, Surya and Gu, Shane and Levine, Sergey and Bengio, Yoshua},
  year={2018}
}

@misc{heo2023furniturebenchreproduciblerealworldbenchmark,
      title={FurnitureBench: Reproducible Real-World Benchmark for Long-Horizon Complex Manipulation}, 
      author={Minho Heo and Youngwoon Lee and Doohyun Lee and Joseph J. Lim},
      year={2023},
      eprint={2305.12821},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2305.12821}, 
}