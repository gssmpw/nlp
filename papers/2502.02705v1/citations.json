[
  {
    "index": 0,
    "papers": [
      {
        "key": "chebotar19close",
        "author": "Yevgen Chebotar and\nAnkur Handa and\nViktor Makoviychuk and\nMiles Macklin and\nJan Issac and\nNathan D. Ratliff and\nDieter Fox",
        "title": "Closing the Sim-to-Real Loop: Adapting Simulation Randomization with\nReal World Experience"
      },
      {
        "key": "ramos19bayessim",
        "author": "Fabio Ramos and\nRafael Possas and\nDieter Fox",
        "title": "BayesSim: Adaptive Domain Randomization Via Probabilistic Inference\nfor Robotics Simulators"
      },
      {
        "key": "memmel24asid",
        "author": "Marius Memmel and\nAndrew Wagenmaker and\nChuning Zhu and\nPatrick Yin and\nDieter Fox and\nAbhishek Gupta",
        "title": "{ASID:} Active Exploration for System Identification in Robotic Manipulation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "haozhirma",
        "author": "Haozhi Qi and\nAshish Kumar and\nRoberto Calandra and\nYi Ma and\nJitendra Malik",
        "title": "In-Hand Object Rotation via Rapid Motor Adaptation"
      },
      {
        "key": "rma",
        "author": "Ashish Kumar and\nZipeng Fu and\nDeepak Pathak and\nJitendra Malik",
        "title": "{RMA:} Rapid Motor Adaptation for Legged Robots"
      },
      {
        "key": "yu17prep",
        "author": "Wenhao Yu and\nJie Tan and\nC. Karen Liu and\nGreg Turk",
        "title": "Preparing for the Unknown: Learning a Universal Policy with Online\nSystem Identification"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "smith2022walk",
        "author": "Smith, Laura and Kostrikov, Ilya and Levine, Sergey",
        "title": "A walk in the park: Learning to walk in 20 minutes with model-free reinforcement learning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "Rajeswaran-RSS-18",
        "author": "Aravind Rajeswaran AND Vikash Kumar AND Abhishek Gupta AND\nGiulia Vezzani AND John Schulman AND Emanuel Todorov AND Sergey Levine",
        "title": "{Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations}"
      },
      {
        "key": "nair2020awac",
        "author": "Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey",
        "title": "Awac: Accelerating online reinforcement learning with offline datasets"
      },
      {
        "key": "kostrikov2021offline",
        "author": "Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey",
        "title": "Offline Reinforcement Learning with Implicit Q-Learning"
      },
      {
        "key": "hu2023imitation",
        "author": "Hu, Hengyuan and Mirchandani, Suvir and Sadigh, Dorsa",
        "title": "Imitation bootstrapped reinforcement learning"
      },
      {
        "key": "nakamoto2024cal",
        "author": "Nakamoto, Mitsuhiko and Zhai, Simon and Singh, Anikait and Sobol Mark, Max and Ma, Yi and Finn, Chelsea and Kumar, Aviral and Levine, Sergey",
        "title": "Cal-ql: Calibrated offline rl pre-training for efficient online fine-tuning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "torne24rialto",
        "author": "Marcel Torne and\nAnthony Simeonov and\nZechu Li and\nApril Chan and\nTao Chen and\nAbhishek Gupta and\nPulkit Agrawal",
        "title": "Reconciling Reality through Simulation: {A} Real-to-Sim-to-Real Approach\nfor Robust Manipulation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "smith2022walk",
        "author": "Smith, Laura and Kostrikov, Ilya and Levine, Sergey",
        "title": "A walk in the park: Learning to walk in 20 minutes with model-free reinforcement learning"
      },
      {
        "key": "ball2023efficient",
        "author": "Ball, Philip J and Smith, Laura and Kostrikov, Ilya and Levine, Sergey",
        "title": "Efficient online reinforcement learning with offline data"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "eysenbach2020off",
        "author": "Eysenbach, Benjamin and Asawa, Swapnil and Chaudhari, Shreyas and Levine, Sergey and Salakhutdinov, Ruslan",
        "title": "Off-dynamics reinforcement learning: Training for transfer with domain classifiers"
      },
      {
        "key": "liu2022dara",
        "author": "Liu, Jinxin and Zhang, Hongyin and Wang, Donglin",
        "title": "Dara: Dynamics-aware reward augmentation in offline reinforcement learning"
      },
      {
        "key": "xu2023cross",
        "author": "Xu, Kang and Bai, Chenjia and Ma, Xiaoteng and Wang, Dong and Zhao, Bin and Wang, Zhen and Li, Xuelong and Li, Wei",
        "title": "Cross-domain policy adaptation via value-guided data filtering"
      },
      {
        "key": "niu2022trust",
        "author": "Niu, Haoyi and Qiu, Yiwen and Li, Ming and Zhou, Guyue and Hu, Jianming and Zhan, Xianyuan and others",
        "title": "When to trust your simulator: Dynamics-aware hybrid offline-and-online reinforcement learning"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhou2024efficient",
        "author": "Zhou, Zhiyuan and Peng, Andy and Li, Qiyang and Levine, Sergey and Kumar, Aviral",
        "title": "Efficient Online Reinforcement Learning Fine-Tuning Need Not Retain Offline Data"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "chebotar19close",
        "author": "Yevgen Chebotar and\nAnkur Handa and\nViktor Makoviychuk and\nMiles Macklin and\nJan Issac and\nNathan D. Ratliff and\nDieter Fox",
        "title": "Closing the Sim-to-Real Loop: Adapting Simulation Randomization with\nReal World Experience"
      },
      {
        "key": "ramos19bayessim",
        "author": "Fabio Ramos and\nRafael Possas and\nDieter Fox",
        "title": "BayesSim: Adaptive Domain Randomization Via Probabilistic Inference\nfor Robotics Simulators"
      },
      {
        "key": "memmel24asid",
        "author": "Marius Memmel and\nAndrew Wagenmaker and\nChuning Zhu and\nPatrick Yin and\nDieter Fox and\nAbhishek Gupta",
        "title": "{ASID:} Active Exploration for System Identification in Robotic Manipulation"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "haozhirma",
        "author": "Haozhi Qi and\nAshish Kumar and\nRoberto Calandra and\nYi Ma and\nJitendra Malik",
        "title": "In-Hand Object Rotation via Rapid Motor Adaptation"
      },
      {
        "key": "rma",
        "author": "Ashish Kumar and\nZipeng Fu and\nDeepak Pathak and\nJitendra Malik",
        "title": "{RMA:} Rapid Motor Adaptation for Legged Robots"
      },
      {
        "key": "yu17prep",
        "author": "Wenhao Yu and\nJie Tan and\nC. Karen Liu and\nGreg Turk",
        "title": "Preparing for the Unknown: Learning a Universal Policy with Online\nSystem Identification"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "torne24rialto",
        "author": "Marcel Torne and\nAnthony Simeonov and\nZechu Li and\nApril Chan and\nTao Chen and\nAbhishek Gupta and\nPulkit Agrawal",
        "title": "Reconciling Reality through Simulation: {A} Real-to-Sim-to-Real Approach\nfor Robust Manipulation"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "smith2022walk",
        "author": "Smith, Laura and Kostrikov, Ilya and Levine, Sergey",
        "title": "A walk in the park: Learning to walk in 20 minutes with model-free reinforcement learning"
      },
      {
        "key": "ball2023efficient",
        "author": "Ball, Philip J and Smith, Laura and Kostrikov, Ilya and Levine, Sergey",
        "title": "Efficient online reinforcement learning with offline data"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "eysenbach2020off",
        "author": "Eysenbach, Benjamin and Asawa, Swapnil and Chaudhari, Shreyas and Levine, Sergey and Salakhutdinov, Ruslan",
        "title": "Off-dynamics reinforcement learning: Training for transfer with domain classifiers"
      },
      {
        "key": "liu2022dara",
        "author": "Liu, Jinxin and Zhang, Hongyin and Wang, Donglin",
        "title": "Dara: Dynamics-aware reward augmentation in offline reinforcement learning"
      },
      {
        "key": "xu2023cross",
        "author": "Xu, Kang and Bai, Chenjia and Ma, Xiaoteng and Wang, Dong and Zhao, Bin and Wang, Zhen and Li, Xuelong and Li, Wei",
        "title": "Cross-domain policy adaptation via value-guided data filtering"
      },
      {
        "key": "niu2022trust",
        "author": "Niu, Haoyi and Qiu, Yiwen and Li, Ming and Zhou, Guyue and Hu, Jianming and Zhan, Xianyuan and others",
        "title": "When to trust your simulator: Dynamics-aware hybrid offline-and-online reinforcement learning"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "zhou2024efficient",
        "author": "Zhou, Zhiyuan and Peng, Andy and Li, Qiyang and Levine, Sergey and Kumar, Aviral",
        "title": "Efficient Online Reinforcement Learning Fine-Tuning Need Not Retain Offline Data"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "Rajeswaran-RSS-18",
        "author": "Aravind Rajeswaran AND Vikash Kumar AND Abhishek Gupta AND\nGiulia Vezzani AND John Schulman AND Emanuel Todorov AND Sergey Levine",
        "title": "{Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations}"
      },
      {
        "key": "nair2020awac",
        "author": "Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey",
        "title": "Awac: Accelerating online reinforcement learning with offline datasets"
      },
      {
        "key": "kostrikov2021offline",
        "author": "Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey",
        "title": "Offline Reinforcement Learning with Implicit Q-Learning"
      },
      {
        "key": "hu2023imitation",
        "author": "Hu, Hengyuan and Mirchandani, Suvir and Sadigh, Dorsa",
        "title": "Imitation bootstrapped reinforcement learning"
      },
      {
        "key": "nakamoto2024cal",
        "author": "Nakamoto, Mitsuhiko and Zhai, Simon and Singh, Anikait and Sobol Mark, Max and Ma, Yi and Finn, Chelsea and Kumar, Aviral and Levine, Sergey",
        "title": "Cal-ql: Calibrated offline rl pre-training for efficient online fine-tuning"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "ziebart2008maxentirl",
        "author": "Ziebart, Brian D. and Maas, Andrew and Bagnell, J. Andrew and Dey, Anind K.",
        "title": "Maximum entropy inverse reinforcement learning"
      },
      {
        "key": "ho2016generative",
        "author": "Ho, Jonathan and Ermon, Stefano",
        "title": "Generative adversarial imitation learning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "fu2018variational",
        "author": "Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey",
        "title": "Variational inverse control with events: A general framework for data-driven reward definition"
      },
      {
        "key": "li2021mural",
        "author": "Li, Kevin and Gupta, Abhishek and Reddy, Ashwin and Pong, Vitchyr H and Zhou, Aurick and Yu, Justin and Levine, Sergey",
        "title": "Mural: Meta-learning uncertainty-aware rewards for outcome-driven reinforcement learning"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "ma2023eureka",
        "author": "Ma, Yecheng Jason and Liang, William and Wang, Guanzhi and Huang, De-An and Bastani, Osbert and Jayaraman, Dinesh and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima",
        "title": "Eureka: Human-level reward design via coding large language models"
      },
      {
        "key": "yu2023language",
        "author": "Yu, Wenhao and Gileadi, Nimrod and Fu, Chuyuan and Kirmani, Sean and Lee, Kuang-Huei and Arenas, Montse Gonzalez and Chiang, Hao-Tien Lewis and Erez, Tom and Hasenclever, Leonard and Humplik, Jan and others",
        "title": "Language to rewards for robotic skill synthesis"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "margolisrapid",
        "author": "Gabriel B. Margolis and\nGe Yang and\nKartik Paigwar and\nTao Chen and\nPulkit Agrawal",
        "title": "Rapid locomotion via reinforcement learning"
      },
      {
        "key": "dota2",
        "author": "Christopher Berner and\nGreg Brockman and\nBrooke Chan and\nVicki Cheung and\nPrzemyslaw Debiak and\nChristy Dennison and\nDavid Farhi and\nQuirin Fischer and\nShariq Hashme and\nChristopher Hesse and\nRafal J{\\'{o}}zefowicz and\nScott Gray and\nCatherine Olsson and\nJakub Pachocki and\nMichael Petrov and\nHenrique Pond{\\'{e}} de Oliveira Pinto and\nJonathan Raiman and\nTim Salimans and\nJeremy Schlatter and\nJonas Schneider and\nSzymon Sidor and\nIlya Sutskever and\nJie Tang and\nFilip Wolski and\nSusan Zhang",
        "title": "Dota 2 with Large Scale Deep Reinforcement Learning"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "ng1999policy",
        "author": "Ng, Andrew Y and Harada, Daishi and Russell, Stuart",
        "title": "Policy invariance under reward transformations: Theory and application to reward shaping"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "cheng2021heuristic",
        "author": "Cheng, Ching-An and Kolobov, Andrey and Swaminathan, Adith",
        "title": "Heuristic-guided reinforcement learning"
      },
      {
        "key": "westenbroek2022lyapunov",
        "author": "Westenbroek, Tyler and Castaneda, Fernando and Agrawal, Ayush and Sastry, Shankar and Sreenath, Koushil",
        "title": "Lyapunov design for robust and efficient robotic reinforcement learning"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "eysenbach2020off",
        "author": "Eysenbach, Benjamin and Asawa, Swapnil and Chaudhari, Shreyas and Levine, Sergey and Salakhutdinov, Ruslan",
        "title": "Off-dynamics reinforcement learning: Training for transfer with domain classifiers"
      },
      {
        "key": "liu2022dara",
        "author": "Liu, Jinxin and Zhang, Hongyin and Wang, Donglin",
        "title": "Dara: Dynamics-aware reward augmentation in offline reinforcement learning"
      },
      {
        "key": "xu2023cross",
        "author": "Xu, Kang and Bai, Chenjia and Ma, Xiaoteng and Wang, Dong and Zhao, Bin and Wang, Zhen and Li, Xuelong and Li, Wei",
        "title": "Cross-domain policy adaptation via value-guided data filtering"
      },
      {
        "key": "niu2022trust",
        "author": "Niu, Haoyi and Qiu, Yiwen and Li, Ming and Zhou, Guyue and Hu, Jianming and Zhan, Xianyuan and others",
        "title": "When to trust your simulator: Dynamics-aware hybrid offline-and-online reinforcement learning"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "sutton1991dyna",
        "author": "Sutton, Richard S.",
        "title": "Dyna, an integrated architecture for learning, planning, and reacting"
      },
      {
        "key": "wang2019exploring",
        "author": "Wang, Tingwu and Ba, Jimmy",
        "title": "Exploring model-based planning with policy networks"
      },
      {
        "key": "janner2019trust",
        "author": "Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey",
        "title": "When to trust your model: Model-based policy optimization"
      },
      {
        "key": "yu2020mopo",
        "author": "Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu",
        "title": "Mopo: Model-based offline policy optimization"
      },
      {
        "key": "kidambi2020morel",
        "author": "Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten",
        "title": "Morel: Model-based offline reinforcement learning"
      },
      {
        "key": "ebert2018visual",
        "author": "Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey",
        "title": "Visual foresight: Model-based deep reinforcement learning for vision-based robotic control"
      },
      {
        "key": "zhang2019solar",
        "author": "Zhang, Marvin and Vikram, Sharad and Smith, Laura and Abbeel, Pieter and Johnson, Matthew and Levine, Sergey",
        "title": "Solar: Deep structured representations for model-based reinforcement learning"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "hansen2024tdmpc",
        "author": "Nicklas Hansen and Hao Su and Xiaolong Wang",
        "title": "{TD}-{MPC}2: Scalable, Robust World Models for Continuous Control"
      },
      {
        "key": "bhardwaj2020blending",
        "author": "Bhardwaj, Mohak and Choudhury, Sanjiban and Boots, Byron",
        "title": "Blending mpc \\& value function approximation for efficient reinforcement learning"
      },
      {
        "key": "hafner2019learning",
        "author": "Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James",
        "title": "Learning latent dynamics for planning from pixels"
      },
      {
        "key": "jadbabaie2001unconstrained",
        "author": "Ali Jadbabaie and  Jie Yu and and John Hauser",
        "title": "Unconstrained receding-horizon control of nonlinear systems"
      },
      {
        "key": "grune2008infinite",
        "author": "Grune, Lars and Rantzer, Anders",
        "title": "On the infinite horizon performance of receding horizon controllers"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "ziebart2008maxentirl",
        "author": "Ziebart, Brian D. and Maas, Andrew and Bagnell, J. Andrew and Dey, Anind K.",
        "title": "Maximum entropy inverse reinforcement learning"
      },
      {
        "key": "ho2016generative",
        "author": "Ho, Jonathan and Ermon, Stefano",
        "title": "Generative adversarial imitation learning"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "fu2018variational",
        "author": "Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey",
        "title": "Variational inverse control with events: A general framework for data-driven reward definition"
      },
      {
        "key": "li2021mural",
        "author": "Li, Kevin and Gupta, Abhishek and Reddy, Ashwin and Pong, Vitchyr H and Zhou, Aurick and Yu, Justin and Levine, Sergey",
        "title": "Mural: Meta-learning uncertainty-aware rewards for outcome-driven reinforcement learning"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "ma2023eureka",
        "author": "Ma, Yecheng Jason and Liang, William and Wang, Guanzhi and Huang, De-An and Bastani, Osbert and Jayaraman, Dinesh and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima",
        "title": "Eureka: Human-level reward design via coding large language models"
      },
      {
        "key": "yu2023language",
        "author": "Yu, Wenhao and Gileadi, Nimrod and Fu, Chuyuan and Kirmani, Sean and Lee, Kuang-Huei and Arenas, Montse Gonzalez and Chiang, Hao-Tien Lewis and Erez, Tom and Hasenclever, Leonard and Humplik, Jan and others",
        "title": "Language to rewards for robotic skill synthesis"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "margolisrapid",
        "author": "Gabriel B. Margolis and\nGe Yang and\nKartik Paigwar and\nTao Chen and\nPulkit Agrawal",
        "title": "Rapid locomotion via reinforcement learning"
      },
      {
        "key": "dota2",
        "author": "Christopher Berner and\nGreg Brockman and\nBrooke Chan and\nVicki Cheung and\nPrzemyslaw Debiak and\nChristy Dennison and\nDavid Farhi and\nQuirin Fischer and\nShariq Hashme and\nChristopher Hesse and\nRafal J{\\'{o}}zefowicz and\nScott Gray and\nCatherine Olsson and\nJakub Pachocki and\nMichael Petrov and\nHenrique Pond{\\'{e}} de Oliveira Pinto and\nJonathan Raiman and\nTim Salimans and\nJeremy Schlatter and\nJonas Schneider and\nSzymon Sidor and\nIlya Sutskever and\nJie Tang and\nFilip Wolski and\nSusan Zhang",
        "title": "Dota 2 with Large Scale Deep Reinforcement Learning"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "westenbroek2022lyapunov",
        "author": "Westenbroek, Tyler and Castaneda, Fernando and Agrawal, Ayush and Sastry, Shankar and Sreenath, Koushil",
        "title": "Lyapunov design for robust and efficient robotic reinforcement learning"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "ng1999policy",
        "author": "Ng, Andrew Y and Harada, Daishi and Russell, Stuart",
        "title": "Policy invariance under reward transformations: Theory and application to reward shaping"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "cheng2021heuristic",
        "author": "Cheng, Ching-An and Kolobov, Andrey and Swaminathan, Adith",
        "title": "Heuristic-guided reinforcement learning"
      },
      {
        "key": "westenbroek2022lyapunov",
        "author": "Westenbroek, Tyler and Castaneda, Fernando and Agrawal, Ayush and Sastry, Shankar and Sreenath, Koushil",
        "title": "Lyapunov design for robust and efficient robotic reinforcement learning"
      }
    ]
  }
]